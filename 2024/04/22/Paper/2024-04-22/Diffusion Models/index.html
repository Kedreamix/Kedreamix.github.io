<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Diffusion Models | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-04-22  Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models"><meta property="og:type" content="article"><meta property="og:title" content="Diffusion Models"><meta property="og:url" content="https://kedreamix.github.io/2024/04/22/Paper/2024-04-22/Diffusion%20Models/index.html"><meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World"><meta property="og:description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-04-22  Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://pic1.zhimg.com/v2-0aba7591bd6a8a973210ed734d1006c9.jpg"><meta property="article:published_time" content="2024-04-22T09:18:09.000Z"><meta property="article:modified_time" content="2024-04-22T09:18:09.823Z"><meta property="article:author" content="Kedreamix"><meta property="article:tag" content="Diffusion Models"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://pic1.zhimg.com/v2-0aba7591bd6a8a973210ed734d1006c9.jpg"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/2024/04/22/Paper/2024-04-22/Diffusion%20Models/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-74LZ5BEQQ1")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!0,languages:{hits_empty:"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}",hits_stats:"å…±æ‰¾åˆ° ${hits} ç¯‡æ–‡ç« "}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"ç¹",msgToSimplifiedChinese:"ç®€"},noticeOutdate:{limitDay:500,position:"top",messagePrev:"It has been",messageNext:"days since the last update, the content of the article may be outdated."},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"å¤åˆ¶æˆåŠŸ",error:"å¤åˆ¶é”™è¯¯",noSupport:"æµè§ˆå™¨ä¸æ”¯æŒ"},relativeDate:{homepage:!0,post:!0},runtime:"å¤©",dateSuffix:{just:"åˆšåˆš",min:"åˆ†é’Ÿå‰",hour:"å°æ—¶å‰",day:"å¤©å‰",month:"ä¸ªæœˆå‰"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js",buttonText:"åŠ è½½æ›´å¤š"},isPhotoFigcaption:!0,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Diffusion Models",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-04-22 17:18:09"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme"),o=(new Date).getHours();void 0===t?o<=6||o>=24?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode();const a=saveToLocal.get("aside-status");void 0!==a&&("hide"===a?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 7.0.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml"></head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",(()=>{o()}))})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">137</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://pic1.zhimg.com/v2-0aba7591bd6a8a973210ed734d1006c9.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Diffusion Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2024-04-22T09:18:09.000Z" title="å‘è¡¨äº 2024-04-22 17:18:09">2024-04-22</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2024-04-22T09:18:09.823Z" title="æ›´æ–°äº 2024-04-22 17:18:09">2024-04-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">å­—æ•°æ€»è®¡:</span><span class="word-count">13.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»æ—¶é•¿:</span><span>47åˆ†é’Ÿ</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Diffusion Models"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-04-22-æ›´æ–°"><a href="#2024-04-22-æ›´æ–°" class="headerlink" title="2024-04-22 æ›´æ–°"></a>2024-04-22 æ›´æ–°</h1><h2 id="Zero-Shot-Medical-Phrase-Grounding-with-Off-the-shelf-Diffusion-Models"><a href="#Zero-Shot-Medical-Phrase-Grounding-with-Off-the-shelf-Diffusion-Models" class="headerlink" title="Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models"></a>Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models</h2><p><strong>Authors:Konstantinos Vilouras, Pedro Sanchez, Alison Q. Oâ€™Neil, Sotirios A. Tsaftaris</strong></p><p>Localizing the exact pathological regions in a given medical scan is an important imaging problem that requires a large amount of bounding box ground truth annotations to be accurately solved. However, there exist alternative, potentially weaker, forms of supervision, such as accompanying free-text reports, which are readily available. The task of performing localization with textual guidance is commonly referred to as phrase grounding. In this work, we use a publicly available Foundation Model, namely the Latent Diffusion Model, to solve this challenging task. This choice is supported by the fact that the Latent Diffusion Model, despite being generative in nature, contains mechanisms (cross-attention) that implicitly align visual and textual features, thus leading to intermediate representations that are suitable for the task at hand. In addition, we aim to perform this task in a zero-shot manner, i.e., without any further training on target data, meaning that the modelâ€™s weights remain frozen. To this end, we devise strategies to select features and also refine them via post-processing without extra learnable parameters. We compare our proposed method with state-of-the-art approaches which explicitly enforce image-text alignment in a joint embedding space via contrastive learning. Results on a popular chest X-ray benchmark indicate that our method is competitive wih SOTA on different types of pathology, and even outperforms them on average in terms of two metrics (mean IoU and AUC-ROC). Source code will be released upon acceptance.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12920v1">PDF</a> 8 pages, 3 figures, submitted to IEEE J-BHI Special Issue on Foundation Models in Medical Imaging</p><p><strong>Summary</strong><br>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚éšæ‰©æ•£æ¨¡å‹ï¼‰å³ä½¿åœ¨æ²¡æœ‰ç›®æ ‡æ•°æ®è®­ç»ƒçš„æƒ…å†µä¸‹ä¹Ÿèƒ½æ‰§è¡Œæ–‡æœ¬å¼•å¯¼å®šä½ä»»åŠ¡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>éšæ‰©æ•£æ¨¡å‹å…·æœ‰éšå¼å¯¹é½è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾çš„æœºåˆ¶ï¼Œé€‚ç”¨äºæ–‡æœ¬å¼•å¯¼å®šä½ä»»åŠ¡ã€‚</li><li>è¯¥æ–¹æ³•é‡‡ç”¨é›¶æ ·æœ¬æ–¹å¼ï¼Œæ— éœ€å¯¹ç›®æ ‡æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥è®­ç»ƒã€‚</li><li>é€šè¿‡ç‰¹å¾é€‰æ‹©å’Œåå¤„ç†ç­–ç•¥ï¼Œåœ¨ä¸å¢åŠ å¯å­¦ä¹ å‚æ•°çš„æƒ…å†µä¸‹ä¼˜åŒ–ç‰¹å¾ã€‚</li><li>è¯¥æ–¹æ³•ä¸é‡‡ç”¨å¯¹æ¯”å­¦ä¹ æ˜¾å¼å¼ºåˆ¶å›¾åƒå’Œæ–‡æœ¬å¯¹é½çš„å…ˆè¿›æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚</li><li>åœ¨èƒ¸éƒ¨ X å°„çº¿åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒç±»å‹çš„ç—…ç†ä¸Šä¸ SOTA æŒå¹³ï¼Œåœ¨å¹³å‡ IoU å’Œ AUC-ROC ä¸¤ä¸ªæŒ‡æ ‡ä¸Šç”šè‡³ä¼˜äº SOTAã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li><p></p><p>Title: é›¶æ ·æœ¬åŒ»å­¦çŸ­è¯­å®šä½</p></li><li><p>Authors: Konstantinos Vilouras, Pedro Sanchez, Alison Q. O'Neil, Sotirios A. Tsaftaris</p></li><li><p>Affiliation: çˆ±ä¸å ¡å¤§å­¦å·¥ç¨‹å­¦é™¢</p></li><li><p>Keywords: æ·±åº¦å­¦ä¹ , æ‰©æ•£æ¨¡å‹, åŒ»å­¦å½±åƒ, çŸ­è¯­å®šä½, é›¶æ ·æœ¬å­¦ä¹ </p></li><li><p>Urls: Paper: https://arxiv.org/abs/2404.12920, Github: None</p></li><li><p>Summary:</p></li></ol><p>(1): æœ¬æ–‡ç ”ç©¶èƒŒæ™¯æ˜¯åŒ»å­¦å½±åƒä¸­ç—…ç†åŒºåŸŸå®šä½ä»»åŠ¡éœ€è¦å¤§é‡è¾¹ç•Œæ¡†æ ‡æ³¨ï¼Œè€Œæ–‡æœ¬å¼•å¯¼å®šä½ä»»åŠ¡ï¼ˆçŸ­è¯­å®šä½ï¼‰å¯ä»¥æä¾›ä¸€ç§æ›¿ä»£çš„å¼±ç›‘ç£å½¢å¼ã€‚</p><p>(2): ç°æœ‰æ–¹æ³•é€šè¿‡å¯¹æ¯”å­¦ä¹ åœ¨è”åˆåµŒå…¥ç©ºé—´ä¸­å¼ºåˆ¶æ‰§è¡Œå›¾åƒ-æ–‡æœ¬å¯¹é½ï¼Œä½†å­˜åœ¨æ˜¾å¼å¯¹é½è®¡ç®—é‡å¤§ã€æ³›åŒ–æ€§å·®çš„é—®é¢˜ã€‚</p><p>(3): æœ¬æ–‡æå‡ºäº†ä¸€ç§é›¶æ ·æœ¬çŸ­è¯­å®šä½æ–¹æ³•ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶éšå¼å¯¹é½å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾ï¼Œå¹¶é€šè¿‡ç‰¹å¾é€‰æ‹©å’Œåå¤„ç†ç­–ç•¥åœ¨ä¸å¢åŠ å¯å­¦ä¹ å‚æ•°çš„æƒ…å†µä¸‹æå‡å®šä½ç²¾åº¦ã€‚</p><p>(4): è¯¥æ–¹æ³•åœ¨èƒ¸éƒ¨ X å°„çº¿åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†ä¸ç°æœ‰æ–¹æ³•ç›¸å½“çš„å®šä½æ€§èƒ½ï¼Œåœ¨å¹³å‡ IoU å’Œ AUC-ROC ä¸¤ä¸ªæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨åŒ»å­¦å½±åƒé¢†åŸŸé›¶æ ·æœ¬å­¦ä¹ çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚</p><ol><li>æ–¹æ³•ï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šé‡‡ç”¨ Latent Diffusion Modelï¼ˆLDMï¼‰ï¼Œé€šè¿‡åå‘æ‰©æ•£è¿‡ç¨‹é€æ­¥æ¢å¤å›¾åƒï¼Œå¹¶åˆ©ç”¨ U-Net æ¨¡å‹ä¸­çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å¯¹å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾è¿›è¡Œéšå¼å¯¹é½ï¼›</p><p>ï¼ˆ2ï¼‰ï¼šæ”¶é›†ä¸åŒå±‚çº§å’Œæ—¶é—´æ­¥é•¿çš„äº¤å‰æ³¨æ„åŠ›å›¾ï¼Œå¹¶é€šè¿‡ç‰¹å¾é€‰æ‹©å’Œåå¤„ç†ç­–ç•¥ä¼˜åŒ–å®šä½ç²¾åº¦ï¼›</p><p>ï¼ˆ3ï¼‰ï¼šåœ¨ä¸å¢åŠ å¯å­¦ä¹ å‚æ•°çš„æƒ…å†µä¸‹ï¼Œåœ¨èƒ¸éƒ¨ X å°„çº¿åŸºå‡†æµ‹è¯•ä¸Šå–å¾—ä¸ç°æœ‰æ–¹æ³•ç›¸å½“çš„å®šä½æ€§èƒ½ï¼Œåœ¨å¹³å‡ IoU å’Œ AUC-ROC ä¸¤ä¸ªæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p><ol><li>ç»“è®ºï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡ŒçŸ­è¯­å®šä½çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨ä¸æ”¹å˜ç”Ÿæˆæ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨æ¨¡å‹ä¸­è§†è§‰å’Œæ–‡æœ¬ç‰¹å¾èåˆçš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°äº†é›¶æ ·æœ¬çŸ­è¯­å®šä½ï¼Œä¸ºåŒ»å­¦å½±åƒé¢†åŸŸé›¶æ ·æœ¬å­¦ä¹ æä¾›äº†æ–°çš„æ€è·¯ï¼›</p><p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶éšå¼å¯¹é½å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾ï¼Œå®ç°é›¶æ ·æœ¬çŸ­è¯­å®šä½ï¼›æ€§èƒ½ï¼šåœ¨èƒ¸éƒ¨ X å°„çº¿åŸºå‡†æµ‹è¯•ä¸Šå–å¾—ä¸ç°æœ‰æ–¹æ³•ç›¸å½“çš„å®šä½æ€§èƒ½ï¼Œåœ¨å¹³å‡ IoU å’Œ AUC-ROC ä¸¤ä¸ªæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼›å·¥ä½œé‡ï¼šåœ¨ä¸å¢åŠ å¯å­¦ä¹ å‚æ•°çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç‰¹å¾é€‰æ‹©å’Œåå¤„ç†ç­–ç•¥ä¼˜åŒ–å®šä½ç²¾åº¦ï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-edc65b84041a4ffbf6fad90dfbf52862.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-42ab68ed87191afb18c00170b44f792e.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-d782a2682f47c83a60efe8ef4da1aeb0.jpg" align="middle"></details><h2 id="Robust-CLIP-Based-Detector-for-Exposing-Diffusion-Model-Generated-Images"><a href="#Robust-CLIP-Based-Detector-for-Exposing-Diffusion-Model-Generated-Images" class="headerlink" title="Robust CLIP-Based Detector for Exposing Diffusion Model-Generated Images"></a>Robust CLIP-Based Detector for Exposing Diffusion Model-Generated Images</h2><p><strong>Authors: Santosh, Li Lin, Irene Amerini, Xin Wang, Shu Hu</strong></p><p>Diffusion models (DMs) have revolutionized image generation, producing high-quality images with applications spanning various fields. However, their ability to create hyper-realistic images poses significant challenges in distinguishing between real and synthetic content, raising concerns about digital authenticity and potential misuse in creating deepfakes. This work introduces a robust detection framework that integrates image and text features extracted by CLIP model with a Multilayer Perceptron (MLP) classifier. We propose a novel loss that can improve the detectorâ€™s robustness and handle imbalanced datasets. Additionally, we flatten the loss landscape during the model training to improve the detectorâ€™s generalization capabilities. The effectiveness of our method, which outperforms traditional detection techniques, is demonstrated through extensive experiments, underscoring its potential to set a new state-of-the-art approach in DM-generated image detection. The code is available at <a target="_blank" rel="noopener" href="https://github.com/Purdue-M2/Robust_DM_Generated_Image_Detection">https://github.com/Purdue-M2/Robust_DM_Generated_Image_Detection</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12908v1">PDF</a></p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒçš„çœŸå®æ€§é‰´åˆ«æ¡†æ¶ï¼Œåˆ©ç”¨ CLIP æ¨¡å‹æå–å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾ï¼Œå¹¶é€šè¿‡ MLP åˆ†ç±»å™¨åˆ¤åˆ«çœŸå®æ€§å’Œåˆæˆæ€§ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›¾åƒçœŸå®æ€§é‰´åˆ«æŒ‘æˆ˜æ€§ã€‚</li><li>æå‡ºåˆ©ç”¨ CLIP æ¨¡å‹æå–å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾çš„é‰´åˆ«æ¡†æ¶ã€‚</li><li>è®¾è®¡æ”¹è¿›é‰´åˆ«å™¨é²æ£’æ€§çš„æŸå¤±å‡½æ•°ï¼Œå¹¶å¤„ç†ä¸å¹³è¡¡æ•°æ®é›†ã€‚</li><li>å¯¹æŸå¤±å‡½æ•°è¿›è¡Œå¹³æ»‘å¤„ç†ï¼Œæå‡é‰´åˆ«æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚</li><li>å®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•ä¼˜äºä¼ ç»Ÿé‰´åˆ«æŠ€æœ¯ã€‚</li><li>ä»£ç å·²å¼€æºï¼š<a target="_blank" rel="noopener" href="https://github.com/Purdue-M2/Robust_DM_Generated_Image_Detectionã€‚">https://github.com/Purdue-M2/Robust_DM_Generated_Image_Detectionã€‚</a></li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li><p></p><p>Title: åŸºäºCLIPçš„ç¨³å¥æ£€æµ‹å™¨ç”¨äºæ­éœ²æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒ</p></li><li><p>Authors: Santosh, Li Lin, Irene Amerini, Xin Wang, Shu Hu</p></li><li><p>Affiliation: æ™®æ¸¡å¤§å­¦</p></li><li><p>Keywords: Diffusion models, CLIP, Robust, AI images</p></li><li><p>Urls: https://arxiv.org/abs/2404.12908, Github:https://github.com/Purdue-M2/Robust DM Generated Image Detection</p></li><li><p>Summary:</p></li></ol><p>(1):éšç€æ‰©æ•£æ¨¡å‹ï¼ˆDiffusion modelsï¼ŒDMsï¼‰åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—é‡å¤§è¿›å±•ï¼Œå…¶ç”Ÿæˆçš„å›¾åƒè´¨é‡ä¸æ–­æå‡ï¼Œåº”ç”¨èŒƒå›´ä¹Ÿä¸æ–­æ‰©å¤§ã€‚ç„¶è€Œï¼ŒDMç”Ÿæˆå›¾åƒçš„é€¼çœŸæ€§ä¹Ÿç»™åŒºåˆ†çœŸå®å›¾åƒå’Œåˆæˆå›¾åƒå¸¦æ¥äº†å·¨å¤§æŒ‘æˆ˜ï¼Œå¼•å‘äº†å¯¹æ•°å­—å†…å®¹çœŸå®æ€§å’Œæ½œåœ¨æ»¥ç”¨ï¼ˆå¦‚ç”Ÿæˆæ·±åº¦ä¼ªé€ å†…å®¹ï¼‰çš„æ‹…å¿§ã€‚</p><p>(2):ä¼ ç»Ÿæ–¹æ³•ä¸»è¦åˆ©ç”¨CLIPå›¾åƒç‰¹å¾æˆ–å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾ï¼Œç»“åˆå¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰åˆ†ç±»å™¨å’ŒäºŒå…ƒäº¤å‰ç†µï¼ˆBCEï¼‰æŸå¤±å‡½æ•°è¿›è¡ŒDMç”Ÿæˆå›¾åƒæ£€æµ‹ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨é²æ£’æ€§å·®ã€å¯¹ä¸å¹³è¡¡æ•°æ®é›†å¤„ç†èƒ½åŠ›å¼±ç­‰é—®é¢˜ã€‚</p><p>(3):æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºCLIPå›¾åƒå’Œæ–‡æœ¬ç‰¹å¾çš„ç¨³å¥æ£€æµ‹æ¡†æ¶ï¼Œé‡‡ç”¨MLPåˆ†ç±»å™¨å’Œæ¡ä»¶é£é™©ä»·å€¼ï¼ˆCVaRï¼‰æŸå¤±å‡½æ•°ä¸é¢ç§¯ä¸‹æ›²çº¿ï¼ˆAUCï¼‰æŸå¤±å‡½æ•°çš„ç»„åˆï¼Œå¹¶åœ¨å¹³å¦åŒ–çš„æŸå¤±å‡½æ•°æ›²é¢ä¸‹è¿›è¡Œè®­ç»ƒï¼Œä»¥æé«˜æ£€æµ‹å™¨çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p><p>(4):åœ¨DMç”Ÿæˆå›¾åƒæ£€æµ‹ä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œè¡¨æ˜äº†å…¶åœ¨è¯¥ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œæœ‰æœ›æˆä¸ºDMç”Ÿæˆå›¾åƒæ£€æµ‹é¢†åŸŸçš„æ–°æŠ€æœ¯æ ‡æ†ã€‚</p><ol><li>æ–¹æ³•ï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§åŸºäº CLIP å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾çš„ç¨³å¥æ£€æµ‹æ¡†æ¶ï¼Œé‡‡ç”¨ MLP åˆ†ç±»å™¨å’Œæ¡ä»¶é£é™©ä»·å€¼ (CVaR) æŸå¤±å‡½æ•°ä¸é¢ç§¯ä¸‹æ›²çº¿ (AUC) æŸå¤±å‡½æ•°çš„ç»„åˆã€‚</p><p>ï¼ˆ2ï¼‰ï¼šåœ¨å¹³å¦åŒ–çš„æŸå¤±å‡½æ•°æ›²é¢ä¸‹è¿›è¡Œè®­ç»ƒï¼Œä»¥æé«˜æ£€æµ‹å™¨çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p><p>ï¼ˆ3ï¼‰ï¼šåœ¨ DM ç”Ÿæˆå›¾åƒæ£€æµ‹ä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œè¡¨æ˜äº†å…¶åœ¨è¯¥ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚</p><ol><li>ç»“è®ºï¼š</li></ol><p>ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨DMç”Ÿæˆå›¾åƒæ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œæœ‰æœ›æˆä¸ºè¯¥é¢†åŸŸçš„æ–°æŠ€æœ¯æ ‡æ†ã€‚</p><p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºCLIPå›¾åƒå’Œæ–‡æœ¬ç‰¹å¾çš„ç¨³å¥æ£€æµ‹æ¡†æ¶ï¼Œé‡‡ç”¨MLPåˆ†ç±»å™¨å’ŒCVaRæŸå¤±å‡½æ•°ä¸AUCæŸå¤±å‡½æ•°çš„ç»„åˆï¼Œå¹¶åœ¨å¹³å¦åŒ–çš„æŸå¤±å‡½æ•°æ›²é¢ä¸‹è¿›è¡Œè®­ç»ƒã€‚</p><p>æ€§èƒ½ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œè¡¨æ˜äº†å…¶åœ¨è¯¥ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚</p><p>å·¥ä½œé‡ï¼šä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•çš„è®­ç»ƒæ—¶é—´æ›´é•¿ï¼Œéœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-4d2d3895766f30bd509b9a3d935d9804.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-4bf1ac8a20b7e67bfd03bc5cca10058c.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f6f7856d5aaeb46c1d7aa9023b3a02ae.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-ce9de0cd6eee8dc551b4cd04b517c61c.jpg" align="middle"></details><h2 id="Training-and-prompt-free-General-Painterly-Harmonization-Using-Image-wise-Attention-Sharing"><a href="#Training-and-prompt-free-General-Painterly-Harmonization-Using-Image-wise-Attention-Sharing" class="headerlink" title="Training-and-prompt-free General Painterly Harmonization Using   Image-wise Attention Sharing"></a>Training-and-prompt-free General Painterly Harmonization Using Image-wise Attention Sharing</h2><p><strong>Authors:Teng-Fang Hsiao, Bo-Kai Ruan, Hong-Han Shuai</strong></p><p>Painterly Image Harmonization aims at seamlessly blending disparate visual elements within a single coherent image. However, previous approaches often encounter significant limitations due to training data constraints, the need for time-consuming fine-tuning, or reliance on additional prompts. To surmount these hurdles, we design a Training-and-prompt-Free General Painterly Harmonization method using image-wise attention sharing (TF-GPH), which integrates a novel â€œshare-attention moduleâ€. This module redefines the traditional self-attention mechanism by allowing for comprehensive image-wise attention, facilitating the use of a state-of-the-art pretrained latent diffusion model without the typical training data limitations. Additionally, we further introduce â€œsimilarity reweightingâ€ mechanism enhances performance by effectively harnessing cross-image information, surpassing the capabilities of fine-tuning or prompt-based approaches. At last, we recognize the deficiencies in existing benchmarks and propose the â€œGeneral Painterly Harmonization Benchmarkâ€, which employs range-based evaluation metrics to more accurately reflect real-world application. Extensive experiments demonstrate the superior efficacy of our method across various benchmarks. The code and web demo are available at <a target="_blank" rel="noopener" href="https://github.com/BlueDyee/TF-GPH">https://github.com/BlueDyee/TF-GPH</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12900v1">PDF</a></p><p><strong>Summary</strong></p><p>å›¾åƒé£æ ¼ç»Ÿä¸€æ–¹æ³•TF-GPHé€šè¿‡å›¾åƒæ³¨æ„åŠ›å…±äº«ï¼Œä¸éœ€è®­ç»ƒå’Œæç¤ºï¼Œå³å¯å®ç°å¤šæ ·è§†è§‰å…ƒç´ çš„æ— ç¼èåˆã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>è®¾è®¡äº†ä¸€ç§ä¸éœ€è®­ç»ƒå’Œæç¤ºçš„é€šç”¨å›¾åƒé£æ ¼ç»Ÿä¸€æ–¹æ³• TF-GPHã€‚</li><li>å¼•å…¥å›¾åƒçº§æ³¨æ„åŠ›å…±äº«ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿè‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å±€é™ã€‚</li><li>æå‡ºç›¸ä¼¼æ€§é‡æ–°åŠ æƒæœºåˆ¶ï¼Œæœ‰æ•ˆåˆ©ç”¨è·¨å›¾åƒä¿¡æ¯ï¼Œæå‡æ€§èƒ½ã€‚</li><li>æå‡ºé€šç”¨å›¾åƒé£æ ¼ç»Ÿä¸€åŸºå‡†ï¼Œé‡‡ç”¨åŸºäºèŒƒå›´çš„è¯„ä¼°æŒ‡æ ‡ï¼Œæ›´è´´è¿‘çœŸå®åº”ç”¨ã€‚</li><li>å®éªŒè¡¨æ˜ï¼ŒTF-GPH åœ¨å¤šä¸ªåŸºå‡†ä¸Šå‡è¡¨ç°ä¼˜å¼‚ã€‚</li><li>ä»£ç å’Œç½‘ç»œæ¼”ç¤ºå¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/BlueDyee/TF-GPH">https://github.com/BlueDyee/TF-GPH</a> è·å–ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li>æ ‡é¢˜ï¼šè®­ç»ƒä¸æç¤ºæ— å…³çš„é€šç”¨ç»˜ç”»è°ƒå’Œ</li><p></p><p></p><li>ä½œè€…ï¼šTeng-Fang Hsiao, Bo-Kai Ruan, Hong-Han Shuai</li><p></p><p></p><li>å•ä½ï¼šå›½ç«‹é˜³æ˜äº¤é€šå¤§å­¦</li><p></p><p></p><li>å…³é”®è¯ï¼šdiffusion model, attention, image editing, image harmonization, painterly harmonization, style transfer</li><p></p><p></p><li>è®ºæ–‡é“¾æ¥ï¼šxxxï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/BlueDyee/TF-GPH</li><p></p><p></p><li><p></p><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç»˜ç”»å›¾åƒè°ƒå’Œæ—¨åœ¨æ— ç¼åœ°å°†ä¸åŒçš„è§†è§‰å…ƒç´ èåˆåˆ°ä¸€ä¸ªè¿è´¯çš„å›¾åƒä¸­ã€‚ç„¶è€Œï¼Œç”±äºè®­ç»ƒæ•°æ®é™åˆ¶ã€éœ€è¦è€—æ—¶çš„å¾®è°ƒæˆ–ä¾èµ–é¢å¤–çš„æç¤ºï¼Œä»¥å‰çš„æ–¹æ³•ç»å¸¸é‡åˆ°é‡å¤§é™åˆ¶ã€‚ ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•åŒ…æ‹¬ä½¿ç”¨åŒåŸŸç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„åŒåŸŸç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼Œä»¥åŠå°†å›¾åƒèåˆåˆ°ç»˜ç”»ä¸­çš„ PHDiffusion æ¨¡å‹ã€‚è¿™äº›æ–¹æ³•å­˜åœ¨è®­ç»ƒæ•°æ®é™åˆ¶ã€éœ€è¦å¾®è°ƒå’Œä¾èµ–æç¤ºçš„é—®é¢˜ã€‚ ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨å›¾åƒçº§æ³¨æ„åŠ›å…±äº«ï¼ˆTF-GPHï¼‰çš„è®­ç»ƒå’Œæç¤ºæ— å…³çš„é€šç”¨ç»˜ç”»è°ƒå’Œæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é›†æˆäº†ä¸€ä¸ªæ–°é¢–çš„â€œå…±äº«æ³¨æ„åŠ›æ¨¡å—â€ã€‚è¯¥æ¨¡å—é€šè¿‡å…è®¸å…¨é¢çš„å›¾åƒçº§æ³¨æ„åŠ›æ¥é‡æ–°å®šä¹‰ä¼ ç»Ÿçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œä»è€Œä¿ƒè¿›ä½¿ç”¨æœ€å…ˆè¿›çš„é¢„è®­ç»ƒæ½œåœ¨æ‰©æ•£æ¨¡å‹è€Œæ²¡æœ‰å…¸å‹çš„è®­ç»ƒæ•°æ®é™åˆ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†â€œç›¸ä¼¼æ€§é‡æ–°åŠ æƒâ€æœºåˆ¶ï¼Œé€šè¿‡æœ‰æ•ˆåˆ©ç”¨è·¨å›¾åƒä¿¡æ¯æ¥å¢å¼ºæ€§èƒ½ï¼Œè¶…è¶Šäº†å¾®è°ƒæˆ–åŸºäºæç¤ºçš„æ–¹æ³•çš„èƒ½åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬è®¤è¯†åˆ°ç°æœ‰åŸºå‡†çš„ç¼ºé™·ï¼Œå¹¶æå‡ºäº†â€œé€šç”¨ç»˜ç”»è°ƒå’ŒåŸºå‡†â€ï¼Œè¯¥åŸºå‡†é‡‡ç”¨åŸºäºèŒƒå›´çš„è¯„ä¼°æŒ‡æ ‡æ¥æ›´å‡†ç¡®åœ°åæ˜ å®é™…åº”ç”¨ã€‚ ï¼ˆ4ï¼‰ï¼šä»»åŠ¡å’Œæ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•åœ¨å„ç§åŸºå‡†ä¸Šå±•ç¤ºäº†å…¶å“è¶Šçš„åŠŸæ•ˆã€‚è¯¥æ–¹æ³•åœ¨é€šç”¨ç»˜ç”»è°ƒå’ŒåŸºå‡†ä¸Šçš„ FID å¾—åˆ†ä¸º 10.6ï¼Œåœ¨ç»˜ç”»å›¾åƒè°ƒå’ŒåŸºå‡†ä¸Šçš„ FID å¾—åˆ†ä¸º 10.3ï¼Œåœ¨å›¾åƒç¼–è¾‘åŸºå‡†ä¸Šçš„ FID å¾—åˆ†ä¸º 11.2ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³æä¾›ä¸€ç§è®­ç»ƒå’Œæç¤ºæ— å…³çš„é€šç”¨ç»˜ç”»è°ƒå’Œæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥åœ¨å„ç§ä»»åŠ¡ä¸Šå®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p></li><li><p>Methods:</p></li></ol><p>ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§ä½¿ç”¨å›¾åƒçº§æ³¨æ„åŠ›å…±äº«ï¼ˆTF-GPHï¼‰çš„è®­ç»ƒå’Œæç¤ºæ— å…³çš„é€šç”¨ç»˜ç”»è°ƒå’Œæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é›†æˆäº†ä¸€ä¸ªæ–°é¢–çš„â€œå…±äº«æ³¨æ„åŠ›æ¨¡å—â€ã€‚</p><p>ï¼ˆ2ï¼‰ï¼šè¯¥æ¨¡å—é€šè¿‡å…è®¸å…¨é¢çš„å›¾åƒçº§æ³¨æ„åŠ›æ¥é‡æ–°å®šä¹‰ä¼ ç»Ÿçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œä»è€Œä¿ƒè¿›ä½¿ç”¨æœ€å…ˆè¿›çš„é¢„è®­ç»ƒæ½œåœ¨æ‰©æ•£æ¨¡å‹è€Œæ²¡æœ‰å…¸å‹çš„è®­ç»ƒæ•°æ®é™åˆ¶ã€‚</p><p>ï¼ˆ3ï¼‰ï¼šè¿›ä¸€æ­¥å¼•å…¥äº†â€œç›¸ä¼¼æ€§é‡æ–°åŠ æƒâ€æœºåˆ¶ï¼Œé€šè¿‡æœ‰æ•ˆåˆ©ç”¨è·¨å›¾åƒä¿¡æ¯æ¥å¢å¼ºæ€§èƒ½ï¼Œè¶…è¶Šäº†å¾®è°ƒæˆ–åŸºäºæç¤ºçš„æ–¹æ³•çš„èƒ½åŠ›ã€‚</p><p>ï¼ˆ4ï¼‰ï¼šæå‡ºäº†â€œé€šç”¨ç»˜ç”»è°ƒå’ŒåŸºå‡†â€ï¼Œè¯¥åŸºå‡†é‡‡ç”¨åŸºäºèŒƒå›´çš„è¯„ä¼°æŒ‡æ ‡æ¥æ›´å‡†ç¡®åœ°åæ˜ å®é™…åº”ç”¨ã€‚</p><ol><li>ç»“è®ºï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§è®­ç»ƒå’Œæç¤ºæ— å…³çš„é€šç”¨ç»˜ç”»è°ƒå’Œæ–¹æ³• TF-GPHï¼Œè¯¥æ–¹æ³•é›†æˆäº†æ–°é¢–çš„â€œå…±äº«æ³¨æ„åŠ›æ¨¡å—â€ï¼Œå¹¶å¼•å…¥äº†â€œç›¸ä¼¼æ€§é‡æ–°åŠ æƒâ€æœºåˆ¶ï¼Œæœ‰æ•ˆåˆ©ç”¨è·¨å›¾åƒä¿¡æ¯ï¼Œè¶…è¶Šäº†å¾®è°ƒæˆ–åŸºäºæç¤ºçš„æ–¹æ³•çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæå‡ºäº†â€œé€šç”¨ç»˜ç”»è°ƒå’ŒåŸºå‡†â€ï¼Œé‡‡ç”¨åŸºäºèŒƒå›´çš„è¯„ä¼°æŒ‡æ ‡æ¥æ›´å‡†ç¡®åœ°åæ˜ å®é™…åº”ç”¨ã€‚</p><p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†â€œå…±äº«æ³¨æ„åŠ›æ¨¡å—â€ï¼Œé‡æ–°å®šä¹‰äº†ä¼ ç»Ÿçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå…è®¸å…¨é¢çš„å›¾åƒçº§æ³¨æ„åŠ›ï¼›å¼•å…¥äº†â€œç›¸ä¼¼æ€§é‡æ–°åŠ æƒâ€æœºåˆ¶ï¼Œæœ‰æ•ˆåˆ©ç”¨è·¨å›¾åƒä¿¡æ¯å¢å¼ºæ€§èƒ½ã€‚</p><p>æ€§èƒ½ï¼šåœ¨é€šç”¨ç»˜ç”»è°ƒå’ŒåŸºå‡†ä¸Šçš„ FID å¾—åˆ†ä¸º 10.6ï¼Œåœ¨ç»˜ç”»å›¾åƒè°ƒå’ŒåŸºå‡†ä¸Šçš„ FID å¾—åˆ†ä¸º 10.3ï¼Œåœ¨å›¾åƒç¼–è¾‘åŸºå‡†ä¸Šçš„ FID å¾—åˆ†ä¸º 11.2ï¼Œè¶…è¶Šäº†å¾®è°ƒæˆ–åŸºäºæç¤ºçš„æ–¹æ³•ã€‚</p><p>å·¥ä½œé‡ï¼šæ— éœ€å…¸å‹çš„è®­ç»ƒæ•°æ®é™åˆ¶ï¼Œæ— éœ€è€—æ—¶çš„å¾®è°ƒæˆ–ä¾èµ–é¢å¤–çš„æç¤ºï¼Œé™ä½äº†ä½¿ç”¨é—¨æ§›ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-23788675c99f2a6910d21b93d104c6ba.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-be289866fd46a1130a926aac4953f56b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-3005a952210df9687a21ac0bd5813a2c.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-340d1d74c9871713d3a7044daea486c2.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ed1fb496bff0b4f7658cf7a6aba9a5a2.jpg" align="middle"></details><h2 id="Detecting-Out-Of-Distribution-Earth-Observation-Images-with-Diffusion-Models"><a href="#Detecting-Out-Of-Distribution-Earth-Observation-Images-with-Diffusion-Models" class="headerlink" title="Detecting Out-Of-Distribution Earth Observation Images with Diffusion   Models"></a>Detecting Out-Of-Distribution Earth Observation Images with Diffusion Models</h2><p><strong>Authors:Georges Le Bellier, Nicolas Audebert</strong></p><p>Earth Observation imagery can capture rare and unusual events, such as disasters and major landscape changes, whose visual appearance contrasts with the usual observations. Deep models trained on common remote sensing data will output drastically different features for these out-of-distribution samples, compared to those closer to their training dataset. Detecting them could therefore help anticipate changes in the observations, either geographical or environmental. In this work, we show that the reconstruction error of diffusion models can effectively serve as unsupervised out-of-distribution detectors for remote sensing images, using them as a plausibility score. Moreover, we introduce ODEED, a novel reconstruction-based scorer using the probability-flow ODE of diffusion models. We validate it experimentally on SpaceNet 8 with various scenarios, such as classical OOD detection with geographical shift and near-OOD setups: pre/post-flood and non-flooded/flooded image recognition. We show that our ODEED scorer significantly outperforms other diffusion-based and discriminative baselines on the more challenging near-OOD scenarios of flood image detection, where OOD images are close to the distribution tail. We aim to pave the way towards better use of generative models for anomaly detection in remote sensing.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12667v1">PDF</a> EARTHVISION 2024 IEEE/CVF CVPR Workshop. Large Scale Computer Vision for Remote Sensing Imagery, Jun 2024, Seattle, United States</p><p><strong>æ‘˜è¦</strong><br>æ‰©æ•£æ¨¡å‹çš„é‡å»ºè¯¯å·®å¯ä»¥ä½œä¸ºé¥æ„Ÿå›¾åƒçš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹å™¨ï¼Œå…¶å¯¹ç½•è§äº‹ä»¶çš„æ£€æµ‹æ•ˆæœä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p><p><strong>å…³é”®è¦ç‚¹</strong></p><ul><li>æ‰©æ•£æ¨¡å‹çš„é‡å»ºè¯¯å·®å¯ä»¥ä½œä¸ºé¥æ„Ÿå›¾åƒçš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹æŒ‡æ ‡ã€‚</li><li>ODEED æ˜¯ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹æ¦‚ç‡æµ ODE çš„é‡å»ºå‹è¯„åˆ†å™¨ï¼Œæ€§èƒ½ä¼˜å¼‚ã€‚</li><li>ODEED åœ¨åœ°ç†åç§»å’Œè¿‘å¼‚å¸¸åœºæ™¯ä¸‹å‡è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯æ´ªæ°´å›¾åƒæ£€æµ‹ç­‰åˆ†å¸ƒå°¾éƒ¨å¼‚å¸¸æ£€æµ‹ä»»åŠ¡ã€‚</li><li>ODEED ä¼˜äºå…¶ä»–åŸºäºæ‰©æ•£æ¨¡å‹å’Œåˆ¤åˆ«æ¨¡å‹çš„åŸºçº¿æ–¹æ³•ã€‚</li><li>æœ¬ç ”ç©¶ä¸ºåˆ©ç”¨ç”Ÿæˆæ¨¡å‹è¿›è¡Œé¥æ„Ÿå¼‚å¸¸æ£€æµ‹é“ºå¹³äº†é“è·¯ã€‚</li><li>ç½•è§äº‹ä»¶çš„è§†è§‰å¤–è§‚ä¸å¸¸è§è§‚æµ‹å­˜åœ¨å·®å¼‚ï¼Œæ£€æµ‹è¿™äº›äº‹ä»¶æœ‰åŠ©äºé¢„æµ‹è§‚æµ‹çš„å˜åŒ–ã€‚</li><li>æ‰©æ•£æ¨¡å‹å¯ä»¥è¾“å‡ºä¸è®­ç»ƒæ•°æ®é›†æ›´æ¥è¿‘çš„æ ·æœ¬çš„æˆªç„¶ä¸åŒçš„ç‰¹å¾ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li><p></p><p>Title: æ‰©æ•£æ¨¡å‹æ£€æµ‹åœ°çƒè§‚æµ‹å›¾åƒçš„åˆ†å¸ƒå¤–æƒ…å†µ</p></li><li><p>Authors: Georges Le Bellier, Nicolas Audebert</p></li><li><p>Affiliation: æ³•å›½å·´é»å›½ç«‹å·¥è‰ºæŠ€æœ¯å­¦é™¢</p></li><li><p>Keywords: Out-of-Distribution, Remote Sensing, Diffusion Model, Anomaly Detection</p></li><li><p>Urls: Paper: https://arxiv.org/pdf/2404.12667.pdf , Github:None</p></li><li><p>Summary:</p></li></ol><p>(1): é¥æ„Ÿå›¾åƒå¯ä»¥æ•æ‰åˆ°ç½•è§å’Œå¼‚å¸¸äº‹ä»¶ï¼Œä¾‹å¦‚ç¾å®³å’Œé‡å¤§æ™¯è§‚å˜åŒ–ï¼Œå…¶è§†è§‰å¤–è§‚ä¸é€šå¸¸çš„è§‚æµ‹ç»“æœå½¢æˆå¯¹æ¯”ã€‚åœ¨å¸¸è§é¥æ„Ÿæ•°æ®ä¸Šè®­ç»ƒçš„æ·±åº¦æ¨¡å‹å°†ä¸ºè¿™äº›åˆ†å¸ƒå¤–æ ·æœ¬è¾“å‡ºæˆªç„¶ä¸åŒçš„ç‰¹å¾ï¼Œè€Œä¸é‚£äº›æ›´æ¥è¿‘å…¶è®­ç»ƒæ•°æ®é›†çš„æ ·æœ¬ç›¸æ¯”ã€‚å› æ­¤ï¼Œæ£€æµ‹å®ƒä»¬æœ‰åŠ©äºé¢„æµ‹è§‚æµ‹ç»“æœçš„å˜åŒ–ï¼Œæ— è®ºæ˜¯åœ°ç†ä¸Šçš„è¿˜æ˜¯ç¯å¢ƒä¸Šçš„ã€‚</p><p>(2): è¿‡å»çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºåˆ¤åˆ«æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹éœ€è¦ç›‘ç£å­¦ä¹ æ¥åŒºåˆ†åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–æ ·æœ¬ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨è¿‘åˆ†å¸ƒå¤–è®¾ç½®ä¸­è¡¨ç°ä¸ä½³ï¼Œå…¶ä¸­åˆ†å¸ƒå¤–æ ·æœ¬ä¸è®­ç»ƒåˆ†å¸ƒçš„å°¾éƒ¨æ¥è¿‘ã€‚</p><p>(3): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œç§°ä¸º ODEEDï¼Œå®ƒåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ¦‚ç‡æµå¸¸å¾®åˆ†æ–¹ç¨‹ (ODE) æ¥è®¡ç®—é‡å»ºç›¸ä¼¼æ€§ã€‚ODEED å°†æ‰©æ•£æ¨¡å‹é‡å»ºè¯¯å·®ç”¨ä½œéç›‘ç£åˆ†å¸ƒå¤–æ£€æµ‹å™¨ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å„ç§åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬ç»å…¸åˆ†å¸ƒå¤–æ£€æµ‹å’Œè¿‘åˆ†å¸ƒå¤–è®¾ç½®ã€‚</p><p>(4): åœ¨ SpaceNet 8 æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒODEED åœ¨æ´ªæ°´å›¾åƒæ£€æµ‹çš„æ›´å…·æŒ‘æˆ˜æ€§çš„è¿‘åˆ†å¸ƒå¤–åœºæ™¯ä¸­æ˜æ˜¾ä¼˜äºå…¶ä»–åŸºäºæ‰©æ•£å’Œåˆ¤åˆ«çš„æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³ä¸ºé¥æ„Ÿä¸­çš„å¼‚å¸¸æ£€æµ‹æ›´å¥½åœ°åˆ©ç”¨ç”Ÿæˆæ¨¡å‹ã€‚</p><ol><li>æ–¹æ³•ï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º ODEED çš„æ–°é¢–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ¦‚ç‡æµå¸¸å¾®åˆ†æ–¹ç¨‹ (ODE) æ¥è®¡ç®—é‡å»ºç›¸ä¼¼æ€§ï¼Œå°†æ‰©æ•£æ¨¡å‹é‡å»ºè¯¯å·®ç”¨ä½œéç›‘ç£åˆ†å¸ƒå¤–æ£€æµ‹å™¨ï¼›</p><p>ï¼ˆ2ï¼‰ï¼šODEED é€šè¿‡ç§¯åˆ†æ¦‚ç‡æµå¸¸å¾®åˆ†æ–¹ç¨‹ (PF-ODE) ä»æ•°æ®åˆ†å¸ƒå°†æ ·æœ¬ç¼–ç åˆ°å…ˆéªŒåˆ†å¸ƒï¼Œåä¹‹äº¦ç„¶ï¼Œå¹¶åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›å’Œé‡å»ºæ€§èƒ½æ¥æ£€æµ‹åˆ†å¸ƒå¤–æ ·æœ¬ï¼›</p><p>ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡ä½¿ç”¨ä¸‰ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„è¯„åˆ†å™¨æ¥è¯„ä¼°é‡å»ºæ€§èƒ½ï¼ŒåŒ…æ‹¬åŸºäºæ—¶é—´æˆªæ–­æ‰©æ•£æŸå¤±çš„æ‰©æ•£æŸå¤±è¯„åˆ†å™¨ã€ä¸“æ³¨äºå›ºå®šæ—¶é—´æ­¥é•¿å»å™ªæ€§èƒ½çš„ä¸€æ­¥å»å™ªè¯„åˆ†å™¨ï¼Œä»¥åŠåˆ©ç”¨ PF-ODE è½¨è¿¹ç²¾åº¦ä½œä¸ºåŒºåˆ†åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–æ ·æœ¬çš„æ–¹æ³•çš„ ODEEDï¼ˆODE ç¼–ç è§£ç ï¼‰è¯„åˆ†å™¨ã€‚</p><ol><li>ç»“è®ºï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡è¯„ä¼°äº†æ‰©æ•£æ¨¡å‹æ£€æµ‹åœ°çƒè§‚æµ‹å›¾åƒåˆ†å¸ƒå¤–æƒ…å†µçš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬å¼•å…¥äº† ODEED è¯„åˆ†å™¨ï¼Œå®ƒåˆ©ç”¨è¿ç»­æ—¶é—´æ‰©æ•£æ¨¡å‹çš„ç¡®å®šæ€§é‡å»ºèƒ½åŠ›ã€‚æˆ‘ä»¬é’ˆå¯¹ 1ï¼‰äº‘æ£€æµ‹å’Œ 2ï¼‰Space-Net 8 æ•°æ®é›†ä¸Šå…·æœ‰æŒ‘æˆ˜æ€§çš„ OOD æ£€æµ‹ä»»åŠ¡é›†åˆè¯„ä¼°äº†è¿™äº›æ–¹æ³•ã€‚æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„ ODEED è¯„åˆ†å™¨åœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„æ´ªæ°´ç›¸å…³åœºæ™¯ä¸­æ˜æ˜¾ä¼˜äºåŸºçº¿ï¼Œå±•ç¤ºäº†æ‰©æ•£æ¨¡å‹æ£€æµ‹â€œæ¥è¿‘åˆ†å¸ƒå¤–â€é¥æ„Ÿå›¾åƒï¼ˆä¾‹å¦‚æ´ªæ°´å›¾åƒï¼‰çš„æ„ä¹‰ã€‚è¿™äº›å‘ç°ä¸ºåˆ©ç”¨ç”Ÿæˆæ¨¡å‹ä»æœªæ ‡è®°çš„ EO æ•°æ®ä¸­æ£€æµ‹ç½•è§äº‹ä»¶å¼€è¾Ÿäº†æ–°çš„é€”å¾„ã€‚</p><p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ¦‚ç‡æµå¸¸å¾®åˆ†æ–¹ç¨‹ (ODE) æ¥è®¡ç®—é‡å»ºç›¸ä¼¼æ€§çš„æ–°é¢–æ–¹æ³• ODEEDï¼›æ€§èƒ½ï¼šåœ¨ SpaceNet 8 æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒODEED åœ¨æ´ªæ°´å›¾åƒæ£€æµ‹çš„æ›´å…·æŒ‘æˆ˜æ€§çš„è¿‘åˆ†å¸ƒå¤–åœºæ™¯ä¸­æ˜æ˜¾ä¼˜äºå…¶ä»–åŸºäºæ‰©æ•£å’Œåˆ¤åˆ«çš„æ–¹æ³•ï¼›å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡ä¸­ç­‰ï¼Œéœ€è¦å¯¹æ‰©æ•£æ¨¡å‹å’Œæ¦‚ç‡æµå¸¸å¾®åˆ†æ–¹ç¨‹æœ‰åŸºæœ¬çš„äº†è§£ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-a861c2c676669b5a005a8c6460157c23.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-a94e85aaa5cc539ad5464e2facd58f70.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-166f6cfb38b037adea4b992761e7f8c9.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-bb4eaeab52bbd1091417582a1679d9b4.jpg" align="middle"></details><h2 id="Learning-the-Domain-Specific-Inverse-NUFFT-for-Accelerated-Spiral-MRI-using-Diffusion-Models"><a href="#Learning-the-Domain-Specific-Inverse-NUFFT-for-Accelerated-Spiral-MRI-using-Diffusion-Models" class="headerlink" title="Learning the Domain Specific Inverse NUFFT for Accelerated Spiral MRI   using Diffusion Models"></a>Learning the Domain Specific Inverse NUFFT for Accelerated Spiral MRI using Diffusion Models</h2><p><strong>Authors:Trevor J. Chan, Chamith S. Rajapakse</strong></p><p>Deep learning methods for accelerated MRI achieve state-of-the-art results but largely ignore additional speedups possible with noncartesian sampling trajectories. To address this gap, we created a generative diffusion model-based reconstruction algorithm for multi-coil highly undersampled spiral MRI. This model uses conditioning during training as well as frequency-based guidance to ensure consistency between images and measurements. Evaluated on retrospective data, we show high quality (structural similarity &gt; 0.87) in reconstructed images with ultrafast scan times (0.02 seconds for a 2D image). We use this algorithm to identify a set of optimal variable-density spiral trajectories and show large improvements in image quality compared to conventional reconstruction using the non-uniform fast Fourier transform. By combining efficient spiral sampling trajectories, multicoil imaging, and deep learning reconstruction, these methods could enable the extremely high acceleration factors needed for real-time 3D imaging.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12361v1">PDF</a></p><p><strong>Summary</strong><br>æ·±åº¦å­¦ä¹ æ–¹æ³•å¯åŠ é€Ÿç£å…±æŒ¯æˆåƒï¼Œè¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ï¼Œä½†å¹¶æœªå……åˆ†åˆ©ç”¨éç¬›å¡å°”é‡‡æ ·è½¨è¿¹å¯èƒ½å®ç°çš„é¢å¤–åŠ é€Ÿã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>åˆ›å»ºåŸºäºç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„é‡å»ºç®—æ³•ï¼Œç”¨äºå¤šçº¿åœˆé«˜æ¬ é‡‡æ ·èºæ—‹ç£å…±æŒ¯æˆåƒã€‚</li><li>è¯¥æ¨¡å‹åˆ©ç”¨è®­ç»ƒæœŸé—´çš„è°ƒèŠ‚å’ŒåŸºäºé¢‘ç‡çš„å¼•å¯¼ï¼Œç¡®ä¿å›¾åƒå’Œæµ‹é‡å€¼çš„ä¸€è‡´æ€§ã€‚</li><li>åœ¨å›é¡¾æ€§æ•°æ®ä¸Šè¯„ä¼°ï¼Œæ˜¾ç¤ºå‡ºé«˜å›¾åƒè´¨é‡ï¼ˆç»“æ„ç›¸ä¼¼åº¦&gt; 0.87ï¼‰ï¼Œæ‰«ææ—¶é—´æå¿«ï¼ˆ2D å›¾åƒä¸º 0.02 ç§’ï¼‰ã€‚</li><li>ä½¿ç”¨è¯¥ç®—æ³•è¯†åˆ«äº†ä¸€ç»„ä¼˜åŒ–çš„å¯å˜å¯†åº¦èºæ—‹è½¨è¿¹ï¼Œä¸ä½¿ç”¨éå‡åŒ€å¿«é€Ÿå‚…é‡Œå¶å˜æ¢çš„ä¼ ç»Ÿé‡å»ºç›¸æ¯”ï¼Œå›¾åƒè´¨é‡æœ‰äº†å¾ˆå¤§æé«˜ã€‚</li><li>é€šè¿‡ç»“åˆæœ‰æ•ˆçš„èºæ—‹é‡‡æ ·è½¨è¿¹ã€å¤šçº¿åœˆæˆåƒå’Œæ·±åº¦å­¦ä¹ é‡å»ºï¼Œè¿™äº›æ–¹æ³•å¯ä»¥å®ç°å®æ—¶ 3D æˆåƒæ‰€éœ€çš„æé«˜åŠ é€Ÿå› å­ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li><p></p><p>Title: åŠ é€Ÿèºæ—‹MRIçš„åŸŸç‰¹å®šé€†éå‡åŒ€å¿«é€Ÿå‚…é‡Œå¶å˜æ¢å­¦ä¹ </p></li><li><p>Authors: Trevor J. Chan, Chamith S. Rajapakse</p></li><li><p>Affiliation: å®¾å¤•æ³•å°¼äºšå¤§å­¦ç”Ÿç‰©å·¥ç¨‹ç³»</p></li><li><p>Keywords: åŠ é€ŸMRIï¼Œèºæ—‹MRIï¼Œæ·±åº¦å­¦ä¹ ï¼Œå›¾åƒé‡å»º</p></li><li><p>Urls: Paper: https://arxiv.org/abs/2404.12361, Github: None</p></li><li><p>Summary:</p></li></ol><p>(1): MRIæˆåƒé€Ÿåº¦æ…¢ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸´åºŠä¸­çš„åº”ç”¨ã€‚åŠ é€ŸMRIé‡‡é›†æ˜¯è§£å†³è¿™ä¸€é—®é¢˜çš„å…³é”®ï¼Œå…¶ä¸­éç¬›å¡å°”é‡‡æ ·è½¨è¿¹å’Œæ·±åº¦å­¦ä¹ é‡å»ºæ–¹æ³•æ˜¯ä¸¤ä¸ªé‡è¦çš„æ–¹å‘ã€‚</p><p>(2): ç°æœ‰çš„æ·±åº¦å­¦ä¹ é‡å»ºæ–¹æ³•ä¸»è¦é’ˆå¯¹ç¬›å¡å°”é‡‡æ ·MRIï¼Œå¿½ç•¥äº†éç¬›å¡å°”é‡‡æ ·è½¨è¿¹å¸¦æ¥çš„é¢å¤–åŠ é€Ÿæ½œåŠ›ã€‚</p><p>(3): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„ã€è½¨è¿¹æ— å…³çš„å¤šçº¿åœˆèºæ—‹MRIæ¬ é‡‡æ ·å›¾åƒé‡å»ºæ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ¡ä»¶è®­ç»ƒå’Œé¢‘ç‡å¼•å¯¼ï¼Œç¡®ä¿å›¾åƒå’Œæµ‹é‡å€¼ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚</p><p>(4): åœ¨å›é¡¾æ€§æ•°æ®ä¸Šï¼Œè¯¥æ–¹æ³•é‡å»ºçš„å›¾åƒè´¨é‡é«˜ï¼ˆç»“æ„ç›¸ä¼¼æ€§&gt;0.87ï¼‰ï¼Œæ‰«ææ—¶é—´æå¿«ï¼ˆ2Då›¾åƒ0.02ç§’ï¼‰ã€‚è¯¥æ–¹æ³•è¿˜ç”¨äºè¯†åˆ«ä¸€ç»„æœ€ä¼˜çš„å¯å˜å¯†åº¦èºæ—‹è½¨è¿¹ï¼Œä¸ä½¿ç”¨éå‡åŒ€å¿«é€Ÿå‚…é‡Œå¶å˜æ¢çš„ä¼ ç»Ÿé‡å»ºæ–¹æ³•ç›¸æ¯”ï¼Œå›¾åƒè´¨é‡æœ‰å¾ˆå¤§æé«˜ã€‚é€šè¿‡ç»“åˆé«˜æ•ˆçš„èºæ—‹é‡‡æ ·è½¨è¿¹ã€å¤šçº¿åœˆæˆåƒå’Œæ·±åº¦å­¦ä¹ é‡å»ºï¼Œè¯¥æ–¹æ³•æœ‰æœ›å®ç°å®æ—¶3Dæˆåƒæ‰€éœ€çš„é«˜åŠ é€Ÿå› å­ã€‚</p><ol><li>æ–¹æ³•ï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶å›é¡¾æ€§ä½¿ç”¨[12]å…¬å¼€è·å–çš„äººç±»å—è¯•è€…æ•°æ®è¿›è¡Œã€‚æ— éœ€ä¼¦ç†æ‰¹å‡†ã€‚</p><p>ï¼ˆ2ï¼‰ï¼šæˆ‘ä»¬ä½¿ç”¨NYU FastMRIæ•°æ®é›†[12]ï¼Œè¯¥æ•°æ®é›†åŒ…å«6970ä¸ªåœ¨4åˆ°24ä¸ªçº¿åœˆçš„ç¡¬ä»¶ä¸Šå®Œå…¨é‡‡æ ·çš„2Dè„‘éƒ¨æ‰«æã€‚å¯¹äºè®­ç»ƒå’Œæµ‹è¯•ï¼Œæˆ‘ä»¬è€ƒè™‘ä»¥ä¸‹åºåˆ—å‚æ•°æ¥è¡¨å¾è½´å‘T2åŠ æƒæ¶¡æ—‹è‡ªæ—‹å›æ³¢åºåˆ—ï¼šæ‰«ææ—¶é—´=140sï¼ŒTR=6sï¼ŒTE=113msï¼Œåˆ‡ç‰‡=30ï¼Œåˆ‡ç‰‡åšåº¦=5mmï¼Œè§†é‡=22cmï¼ŒçŸ©é˜µå¤§å°=320x320ã€‚2562åˆ†è¾¨ç‡çš„2Dåˆ‡ç‰‡çš„æœ‰æ•ˆæ‰«ææ—¶é—´ä¸º140s/320 âˆ— 256/30 â‰ˆ 3.7sã€‚ç”±äºè¿™äº›æ•°æ®æœ€åˆæ˜¯ä½¿ç”¨ç¬›å¡å°”åºåˆ—è·å–çš„ï¼Œå› æ­¤å›¾2ã€‚ç»™å®šæµ‹é‡å€¼y0ï¼Œé‡å»ºéµå¾ªä¿®æ”¹åçš„æ‰©æ•£é‡‡æ ·è¿‡ç¨‹ã€‚åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿ï¼Œä¸€ä¸ªæœ‰å™ªå£°çš„æ½œåœ¨xtä¸å…ˆéªŒp0è¿æ¥ï¼Œå¹¶ä¼ é€’åˆ°å»å™ªæ¨¡å‹ä»¥è·å¾—Ëœxtâˆ’1ã€‚ä¸ºäº†å¼ºåˆ¶ä¸y0ä¸€è‡´ï¼Œæˆ‘ä»¬è®¡ç®—é¢‘ç‡æ¢¯åº¦âˆ‡ytâˆ’1å¹¶ä½¿ç”¨ä¿®æ”¹åçš„è¿­ä»£é€†nufftï¼ˆç¬¬3.3èŠ‚ï¼‰æ±‚è§£å›¾åƒæ¢¯åº¦ã€‚xtâˆ’1å’Œâˆ‡xtâˆ’1çš„åŠ æƒå’Œäº§ç”Ÿæ ¡æ­£åçš„å›¾åƒxtâˆ’1ã€‚é‡å¤æ­¤æ“ä½œï¼Œç›´åˆ°t = 0ã€‚</p><p>ï¼ˆ3ï¼‰ï¼šæˆ‘ä»¬æ¨¡æ‹Ÿèºæ—‹é‡‡é›†ï¼Œæ–¹æ³•æ˜¯å›é¡¾æ€§åœ°åœ¨kç©ºé—´ä¸­æ’å€¼ï¼Œä»¥è·å¾—æ²¿ç”Ÿæˆèºæ—‹è½¨è¿¹çš„å¤å€¼æµ‹é‡å€¼ã€‚</p><p>ï¼ˆ4ï¼‰ï¼šæ ¹æ®Kimç­‰äºº[13]ï¼Œæˆ‘ä»¬è€ƒè™‘ä»¥ä¸‹å½¢å¼çš„èºæ—‹è½¨è¿¹ï¼šk(Ï„) = ï¿½ Ï„ 0 1 Ï(Ï•)dÏ•ejÏ‰Ï„ â‰ˆ Î»Ï„ Î±ejÏ‰Ï„ã€‚ï¼ˆ3ï¼‰æ­¤å¤„ï¼ŒÏè¡¨ç¤ºé‡‡æ ·å¯†åº¦ï¼ŒÏ„æ˜¯æ—¶é—´çš„å‡½æ•°ï¼ŒÏ•æ˜¯è§’åº¦ä½ç½®ï¼ŒÏ‰ = 2Ï€næ˜¯é¢‘ç‡ï¼Œnæ˜¯kç©ºé—´ä¸­çš„è½¬æ•°ï¼ŒÎ»æ˜¯ç¼©æ”¾å› å­ï¼Œç­‰äºçŸ©é˜µå¤§å°/(2âˆ— FOV)ï¼ŒÎ±æ˜¯ç›¸å¯¹äºè¾¹ç¼˜è¿‡åº¦é‡‡æ ·kç©ºé—´ä¸­å¿ƒçš„åå·®é¡¹ã€‚åœ¨æ¢¯åº¦å›è½¬ç‡ä¸Šé™å’Œæ¢¯åº¦å¹…åº¦ä¸Šé™çš„çº¦æŸä¸‹æ±‚è§£è¿™ä¸ªå‚æ•°æ–¹ç¨‹ï¼Œäº§ç”Ÿæ¢¯åº¦ï¼ˆgx(t)å’Œgy(t)ï¼‰ä»¥åŠkx,kyå¹³é¢çš„èºæ—‹è½¨è¿¹ï¼ˆå›¾1ï¼‰ã€‚è¿™æ ·åšï¼Œæˆ‘ä»¬å¯ä»¥è°ƒæ•´é‡‡æ ·å‚æ•°ä»¥æ§åˆ¶è¯¸å¦‚è¯»å‡ºæŒç»­æ—¶é—´å’Œåœç•™æ—¶é—´ä¹‹ç±»çš„å› ç´ ï¼ŒåŒæ—¶æ”¹å˜äº¤é”™æ•°å’Œä½é¢‘åˆ°é«˜é¢‘è¿‡é‡‡æ ·ç‡ã€‚</p><p>ï¼ˆ5ï¼‰ï¼šå›¾åƒé‡å»ºæ˜¯é€†é—®é¢˜æ±‚è§£MRIæ¬ é‡‡æ ·é‡‡é›†ç­‰åŒäºé€šè¿‡æŸç§ä¸å®Œç¾çš„é‡‡æ ·å‡½æ•°Aæµ‹é‡æœªçŸ¥ä¿¡å·xï¼šy = Ax + Ïµã€‚è¿™é‡Œï¼Œyæ˜¯æµ‹é‡å¤šçº¿åœˆkç©ºé—´æ•°æ®ï¼ŒAæ˜¯éå‡åŒ€å‚…é‡Œå¶å˜æ¢ã€‚Ïµæ˜¯æµ‹é‡å™ªå£°ï¼Œä¸yå­˜åœ¨äºåŒä¸€åŸŸä¸­ï¼›åœ¨MRIä¸­ï¼Œå¯¹äºæ¯ä¸ªçº¿åœˆï¼Œå™ªå£°åœ¨yçš„å®éƒ¨å’Œè™šéƒ¨ä¸­å‘ˆé«˜æ–¯åˆ†å¸ƒã€‚é‡å»ºæ˜¯ä»ä¸€ç»„ä¸å®Œæ•´çš„kç©ºé—´æµ‹é‡å€¼yä¸­æ¢å¤å›¾åƒä¿¡å·xçš„ä¸é€‚å®šé€†é—®é¢˜ã€‚ç”±äºxå’Œyå­˜åœ¨äºä¸åŒçš„åŸŸä¸­ï¼Œå› æ­¤xéšè—åœ¨é‡‡æ ·ç®—å­Açš„åé¢ã€‚è§£å†³è¿™ä¸ªé—®é¢˜éœ€è¦å…ˆéªŒçŸ¥è¯†ã€‚åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ å›¾åƒçš„æ½œåœ¨æ¡ä»¶åˆ†å¸ƒå¹¶å¯»æ±‚é‡å»º</p><ol><li>ç»“è®ºï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„èºæ—‹MRIæ¬ é‡‡æ ·å›¾åƒé‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†å¤šçº¿åœˆæˆåƒã€èºæ—‹æ‰«æå’Œæ¬ é‡‡æ ·ï¼Œå®ç°äº†æå¿«çš„æˆåƒé€Ÿåº¦ï¼Œæœ‰æœ›å®ç°å®æ—¶3Dæˆåƒæ‰€éœ€çš„æé«˜åŠ é€Ÿå› å­ã€‚</p><p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒé‡å»ºæ–¹æ³•ï¼›å¤šçº¿åœˆæˆåƒå’Œèºæ—‹æ‰«æçš„ç»“åˆï¼›å¯å˜å¯†åº¦èºæ—‹è½¨è¿¹çš„ä¼˜åŒ–ã€‚æ€§èƒ½ï¼šå›¾åƒè´¨é‡é«˜ï¼ˆç»“æ„ç›¸ä¼¼æ€§&gt;0.87ï¼‰ï¼Œæ‰«ææ—¶é—´æå¿«ï¼ˆ2Då›¾åƒ0.02ç§’ï¼‰ã€‚å·¥ä½œé‡ï¼šéœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-dad46f934fa27aedf6f5bcc658a1e97b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-7ca2a2a56eaf899a4ab5fb7f25a2d0dd.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-09dc794137fef040d7fe26326b8c5bd2.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-1377428c568ca550e4683544f87b3da2.jpg" align="middle"></details><h2 id="AniClipart-Clipart-Animation-with-Text-to-Video-Priors"><a href="#AniClipart-Clipart-Animation-with-Text-to-Video-Priors" class="headerlink" title="AniClipart: Clipart Animation with Text-to-Video Priors"></a>AniClipart: Clipart Animation with Text-to-Video Priors</h2><p><strong>Authors:Ronghuan Wu, Wanchao Su, Kede Ma, Jing Liao</strong></p><p>Clipart, a pre-made graphic art form, offers a convenient and efficient way of illustrating visual content. Traditional workflows to convert static clipart images into motion sequences are laborious and time-consuming, involving numerous intricate steps like rigging, key animation and in-betweening. Recent advancements in text-to-video generation hold great potential in resolving this problem. Nevertheless, direct application of text-to-video generation models often struggles to retain the visual identity of clipart images or generate cartoon-style motions, resulting in unsatisfactory animation outcomes. In this paper, we introduce AniClipart, a system that transforms static clipart images into high-quality motion sequences guided by text-to-video priors. To generate cartoon-style and smooth motion, we first define B\â€™{e}zier curves over keypoints of the clipart image as a form of motion regularization. We then align the motion trajectories of the keypoints with the provided text prompt by optimizing the Video Score Distillation Sampling (VSDS) loss, which encodes adequate knowledge of natural motion within a pretrained text-to-video diffusion model. With a differentiable As-Rigid-As-Possible shape deformation algorithm, our method can be end-to-end optimized while maintaining deformation rigidity. Experimental results show that the proposed AniClipart consistently outperforms existing image-to-video generation models, in terms of text-video alignment, visual identity preservation, and motion consistency. Furthermore, we showcase the versatility of AniClipart by adapting it to generate a broader array of animation formats, such as layered animation, which allows topological changes.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12347v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://aniclipart.github.io/">https://aniclipart.github.io/</a></p><p><strong>Summary</strong><br>é€šè¿‡ä½¿ç”¨æ–‡ç”Ÿå›¾è¯­è¨€æ¨¡å‹ï¼ŒAniClipartå¯ä»¥å°†é™æ€å‰ªè´´ç”»å›¾åƒè½¬æ¢ä¸ºé«˜è´¨é‡çš„åŠ¨æ€åºåˆ—ï¼Œå¹¶ä¸”å§‹ç»ˆä¼˜äºç°æœ‰çš„å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>AniClipart å°†é™æ€å‰ªè´´ç”»è½¬æ¢ä¸ºåŠ¨ç”»åºåˆ—ï¼Œä¿ç•™äº†å‰ªè´´ç”»çš„è§†è§‰ç‰¹å¾å¹¶ç”Ÿæˆäº†å¡é€šé£æ ¼çš„åŠ¨ä½œã€‚</li><li>AniClipart ä½¿ç”¨è´å¡å°”æ›²çº¿å¯¹å‰ªè´´ç”»å›¾åƒçš„å…³é”®ç‚¹è¿›è¡Œè¿åŠ¨æ­£åˆ™åŒ–ã€‚</li><li>AniClipart é€šè¿‡ä¼˜åŒ–è§†é¢‘è¯„åˆ†è’¸é¦é‡‡æ · (VSDS) æŸå¤±å°†å…³é”®ç‚¹çš„è¿åŠ¨è½¨è¿¹ä¸æä¾›çš„æ–‡æœ¬æç¤ºå¯¹é½ã€‚</li><li>VSDS æŸå¤±ç¼–ç äº†é¢„è®­ç»ƒæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­è‡ªç„¶è¿åŠ¨çš„å……åˆ†çŸ¥è¯†ã€‚</li><li>AniClipart ä½¿ç”¨å¯å¾®åˆ†åƒµç¡¬å½¢çŠ¶å˜å½¢ç®—æ³•ï¼Œå¯ä»¥åœ¨ä¿æŒå˜å½¢åˆšæ€§çš„åŒæ—¶è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚</li><li>AniClipart åœ¨æ–‡æœ¬-è§†é¢‘å¯¹é½ã€è§†è§‰ç‰¹å¾ä¿ç•™å’Œè¿åŠ¨ä¸€è‡´æ€§æ–¹é¢å§‹ç»ˆä¼˜äºç°æœ‰çš„å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚</li><li>AniClipart å¯ä»¥é€‚åº”æ›´å¹¿æ³›çš„åŠ¨ç”»æ ¼å¼ï¼Œä¾‹å¦‚å…è®¸æ‹“æ‰‘æ›´æ”¹çš„åˆ†å±‚åŠ¨ç”»ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li><p></p><p>Title: AniClipartï¼šåŸºäºæ–‡æœ¬åˆ°è§†é¢‘å…ˆéªŒçš„å‰ªè¾‘ç”»åŠ¨ç”»</p></li><li><p>Authors: RONGHUAN WU, WANCHAO SU, KEDE MA, JING LIAO</p></li><li><p>Affiliation: é¦™æ¸¯åŸå¸‚å¤§å­¦</p></li><li><p>Keywords: Clipart Animation, Text-to-Video Diffusion, Score Distillation Sampling, As-Rigid-As-Possible Shape Deformation</p></li><li><p>Urls: Paper:https://arxiv.org/abs/2404.12347v1 Github:None</p></li><li><p>Summary:</p></li></ol><p>(1):å‰ªè¾‘ç”»æ˜¯ä¸€ç§é¢„å…ˆåˆ¶ä½œçš„å›¾å½¢è‰ºæœ¯å½¢å¼ï¼Œå®ƒæä¾›äº†ä¸€ç§æ–¹ä¾¿ä¸”æœ‰æ•ˆçš„æ–¹æ³•æ¥æ’å›¾è§†è§‰å†…å®¹ã€‚å°†é™æ€å‰ªè¾‘ç”»å›¾åƒè½¬æ¢ä¸ºè¿åŠ¨åºåˆ—çš„ä¼ ç»Ÿå·¥ä½œæµç¨‹æ—¢è´¹åŠ›åˆè´¹æ—¶ï¼Œæ¶‰åŠè®¸å¤šå¤æ‚çš„æ­¥éª¤ï¼Œå¦‚è£…é…ã€å…³é”®åŠ¨ç”»å’Œä¸­é—´åŠ¨ç”»ã€‚</p><p>(2):æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ–¹é¢çš„æœ€æ–°è¿›å±•åœ¨è§£å†³è¿™ä¸ªé—®é¢˜æ–¹é¢å…·æœ‰å·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç›´æ¥åº”ç”¨æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹é€šå¸¸éš¾ä»¥ä¿ç•™å‰ªè¾‘ç”»å›¾åƒçš„è§†è§‰æ ‡è¯†æˆ–ç”Ÿæˆå¡é€šé£æ ¼çš„åŠ¨ä½œï¼Œä»è€Œå¯¼è‡´åŠ¨ç”»ç»“æœä¸ä»¤äººæ»¡æ„ã€‚</p><p>(3):æœ¬æ–‡ä»‹ç»äº† AniClipartï¼Œè¿™æ˜¯ä¸€ä¸ªå°†é™æ€å‰ªè¾‘ç”»å›¾åƒè½¬æ¢ä¸ºé«˜è´¨é‡è¿åŠ¨åºåˆ—çš„ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿç”±æ–‡æœ¬åˆ°è§†é¢‘å…ˆéªŒæŒ‡å¯¼ã€‚ä¸ºäº†ç”Ÿæˆå¡é€šé£æ ¼å’Œæµç•…çš„åŠ¨ä½œï¼Œæˆ‘ä»¬é¦–å…ˆå°†è´å¡å°”æ›²çº¿å®šä¹‰ä¸ºå‰ªè¾‘ç”»å›¾åƒå…³é”®ç‚¹çš„è¿åŠ¨æ­£åˆ™åŒ–å½¢å¼ã€‚ç„¶åï¼Œé€šè¿‡ä¼˜åŒ–è§†é¢‘è¯„åˆ†è’¸é¦é‡‡æ · (VSDS) æŸå¤±å°†å…³é”®ç‚¹çš„è¿åŠ¨è½¨è¿¹ä¸æä¾›çš„æ–‡æœ¬æç¤ºå¯¹é½ï¼Œè¯¥æŸå¤±å¯¹é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„è‡ªç„¶è¿åŠ¨çŸ¥è¯†è¿›è¡Œäº†å……åˆ†ç¼–ç ã€‚é€šè¿‡å¯å¾®åˆ†å°½å¯èƒ½åˆšæ€§å½¢çŠ¶å˜å½¢ç®—æ³•ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åœ¨ä¿æŒå˜å½¢åˆšæ€§çš„åŒæ—¶è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚</p><p>(4):å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ–‡æœ¬è§†é¢‘å¯¹é½ã€è§†è§‰æ ‡è¯†ä¿ç•™å’Œè¿åŠ¨ä¸€è‡´æ€§æ–¹é¢ï¼Œæ‰€æå‡ºçš„ AniClipart å§‹ç»ˆä¼˜äºç°æœ‰çš„å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº† AniClipart çš„å¤šåŠŸèƒ½æ€§ï¼Œé€šè¿‡å¯¹å…¶è¿›è¡Œè°ƒæ•´ä»¥ç”Ÿæˆæ›´å¹¿æ³›çš„åŠ¨ç”»æ ¼å¼ï¼Œä¾‹å¦‚å…è®¸æ‹“æ‰‘å˜åŒ–çš„åˆ†å±‚åŠ¨ç”»ã€‚</p><ol><li>æ–¹æ³•ï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬åˆ°è§†é¢‘å…ˆéªŒçš„å‰ªè¾‘ç”»åŠ¨ç”»ç³»ç»Ÿ AniClipartã€‚</p><p>ï¼ˆ2ï¼‰ï¼šAniClipart ç”±ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„ä»¶ç»„æˆï¼šè´å¡å°”æ›²çº¿è¿åŠ¨æ­£åˆ™åŒ–ã€è§†é¢‘è¯„åˆ†è’¸é¦é‡‡æ ·ï¼ˆVSDSï¼‰æŸå¤±å’Œå¯å¾®åˆ†å°½å¯èƒ½åˆšæ€§å½¢çŠ¶å˜å½¢ç®—æ³•ã€‚</p><p>ï¼ˆ3ï¼‰ï¼šè´å¡å°”æ›²çº¿è¿åŠ¨æ­£åˆ™åŒ–å°†å‰ªè¾‘ç”»å›¾åƒå…³é”®ç‚¹çš„è¿åŠ¨å®šä¹‰ä¸ºè´å¡å°”æ›²çº¿ï¼Œä»è€Œç¡®ä¿äº†è¿åŠ¨çš„å¹³æ»‘æ€§å’Œè¿ç»­æ€§ã€‚</p><p>ï¼ˆ4ï¼‰ï¼šVSDS æŸå¤±å°†å…³é”®ç‚¹çš„è¿åŠ¨è½¨è¿¹ä¸æä¾›çš„æ–‡æœ¬æç¤ºå¯¹é½ï¼Œä»è€Œå°†æ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ä¸­çš„è‡ªç„¶è¿åŠ¨çŸ¥è¯†èå…¥åˆ°åŠ¨ç”»ä¸­ã€‚</p><p>ï¼ˆ5ï¼‰ï¼šå¯å¾®åˆ†å°½å¯èƒ½åˆšæ€§å½¢çŠ¶å˜å½¢ç®—æ³•å…è®¸åœ¨ä¿æŒå˜å½¢åˆšæ€§çš„åŒæ—¶è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œä»è€Œç”Ÿæˆå…·æœ‰æ¸…æ™°è§†è§‰æ ‡è¯†çš„åŠ¨ç”»ã€‚</p><p><strong>8. ç»“è®ºï¼š</strong></p><p>ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºçš„ AniClipart ç³»ç»Ÿï¼Œé€šè¿‡å°†æ–‡æœ¬åˆ°è§†é¢‘å…ˆéªŒèå…¥å‰ªè¾‘ç”»åŠ¨ç”»ç”Ÿæˆä¸­ï¼Œä¸ºé™æ€å‰ªè¾‘ç”»å›¾åƒèµ‹äºˆäº†ç”ŸåŠ¨æ€§ï¼Œç®€åŒ–äº†åŠ¨ç”»åˆ¶ä½œæµç¨‹ï¼Œå…·æœ‰é‡è¦çš„åˆ›æ–°æ„ä¹‰ã€‚</p><p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šAniClipart åˆ›æ–°æ€§åœ°é‡‡ç”¨äº†è´å¡å°”æ›²çº¿è¿åŠ¨æ­£åˆ™åŒ–ã€è§†é¢‘è¯„åˆ†è’¸é¦é‡‡æ ·æŸå¤±å’Œå¯å¾®åˆ†å°½å¯èƒ½åˆšæ€§å½¢çŠ¶å˜å½¢ç®—æ³•ï¼Œå®ç°äº†å‰ªè¾‘ç”»å›¾åƒçš„å…³é”®ç‚¹è¿åŠ¨è½¨è¿¹ä¸æ–‡æœ¬æç¤ºçš„ç²¾ç¡®å¯¹é½ï¼Œä»¥åŠå˜å½¢åˆšæ€§çš„ä¿æŒï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡çš„å‰ªè¾‘ç”»åŠ¨ç”»ã€‚</p><p>æ€§èƒ½ï¼šAniClipart åœ¨æ–‡æœ¬è§†é¢‘å¯¹é½ã€è§†è§‰æ ‡è¯†ä¿ç•™å’Œè¿åŠ¨ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰çš„å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå±•ç°å‡ºå‡ºè‰²çš„åŠ¨ç”»ç”Ÿæˆèƒ½åŠ›ã€‚</p><p>å·¥ä½œé‡ï¼šAniClipart é‡‡ç”¨ç«¯åˆ°ç«¯ä¼˜åŒ–ï¼Œç®€åŒ–äº†å‰ªè¾‘ç”»åŠ¨ç”»åˆ¶ä½œæµç¨‹ï¼Œé™ä½äº†å·¥ä½œé‡ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-7f003c736b9e8d225fc78c7b356b7e25.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-33e8a11d43dfdfe88d324da3694df802.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-b455537a4612c5459d9162e1601fc155.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-0aba7591bd6a8a973210ed734d1006c9.jpg" align="middle"></details><h2 id="StyleBooth-Image-Style-Editing-with-Multimodal-Instruction"><a href="#StyleBooth-Image-Style-Editing-with-Multimodal-Instruction" class="headerlink" title="StyleBooth: Image Style Editing with Multimodal Instruction"></a>StyleBooth: Image Style Editing with Multimodal Instruction</h2><p><strong>Authors:Zhen Han, Chaojie Mao, Zeyinzi Jiang, Yulin Pan, Jingfeng Zhang</strong></p><p>Given an original image, image editing aims to generate an image that align with the provided instruction. The challenges are to accept multimodal inputs as instructions and a scarcity of high-quality training data, including crucial triplets of source/target image pairs and multimodal (text and image) instructions. In this paper, we focus on image style editing and present StyleBooth, a method that proposes a comprehensive framework for image editing and a feasible strategy for building a high-quality style editing dataset. We integrate encoded textual instruction and image exemplar as a unified condition for diffusion model, enabling the editing of original image following multimodal instructions. Furthermore, by iterative style-destyle tuning and editing and usability filtering, the StyleBooth dataset provides content-consistent stylized/plain image pairs in various categories of styles. To show the flexibility of StyleBooth, we conduct experiments on diverse tasks, such as text-based style editing, exemplar-based style editing and compositional style editing. The results demonstrate that the quality and variety of training data significantly enhance the ability to preserve content and improve the overall quality of generated images in editing tasks. Project page can be found at <a target="_blank" rel="noopener" href="https://ali-vilab.github.io/stylebooth-page/">https://ali-vilab.github.io/stylebooth-page/</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.12154v1">PDF</a></p><p><strong>Summary</strong><br>StyleBoothæ˜¯ä¸€ä¸ªå›¾åƒç¼–è¾‘æ¡†æ¶ï¼Œé›†æˆäº†æ–‡æœ¬å’Œå›¾åƒæŒ‡ä»¤ï¼Œå¹¶æä¾›é«˜è´¨é‡çš„é£æ ¼ç¼–è¾‘æ•°æ®é›†ï¼Œå¯ç”¨äºå„ç§ç¼–è¾‘ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬é£æ ¼ç¼–è¾‘å’Œç¤ºä¾‹é£æ ¼ç¼–è¾‘ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>StyleBooth æ¡†æ¶å°†æ–‡æœ¬æŒ‡ä»¤å’Œå›¾åƒç¤ºä¾‹æ•´åˆä¸ºæ‰©æ•£æ¨¡å‹çš„ç»Ÿä¸€æ¡ä»¶ï¼Œå®ç°å›¾åƒé£æ ¼ç¼–è¾‘ã€‚</li><li>StyleBooth æ•°æ®é›†é€šè¿‡è¿­ä»£çš„é£æ ¼-å»é£æ ¼è°ƒæ•´å’Œç¼–è¾‘ä»¥åŠå¯ç”¨æ€§è¿‡æ»¤ï¼Œæä¾›äº†å†…å®¹ä¸€è‡´çš„é£æ ¼åŒ–/æ™®é€šå›¾åƒå¯¹ã€‚</li><li>StyleBooth é€šè¿‡é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®å¢å¼ºäº†ç¼–è¾‘ä»»åŠ¡ä¸­ä¿ç•™å†…å®¹å’Œæé«˜ç”Ÿæˆå›¾åƒæ•´ä½“è´¨é‡çš„èƒ½åŠ›ã€‚</li><li>StyleBooth å¯ç”¨äºæ–‡æœ¬é£æ ¼ç¼–è¾‘ã€ç¤ºä¾‹é£æ ¼ç¼–è¾‘å’Œåˆæˆé£æ ¼ç¼–è¾‘ç­‰å¤šç§ä»»åŠ¡ã€‚</li><li>StyleBooth é¡¹ç›®ä¸»é¡µï¼š<a target="_blank" rel="noopener" href="https://ali-vilab.github.io/stylebooth-page/ã€‚">https://ali-vilab.github.io/stylebooth-page/ã€‚</a></li><li>å¤šæ¨¡æ€è¾“å…¥å’Œé«˜è´¨é‡è®­ç»ƒæ•°æ®å¯¹äºå›¾åƒç¼–è¾‘è‡³å…³é‡è¦ã€‚</li><li>StyleBooth æä¾›äº†ä¸€ä¸ªå…¨é¢çš„å›¾åƒç¼–è¾‘æ¡†æ¶å’Œè®­ç»ƒæ•°æ®çš„æ„å»ºç­–ç•¥ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li><p></p><p>Title: StyleBooth: ä½¿ç”¨å¤šæ¨¡æ€æŒ‡ä»¤è¿›è¡Œå›¾åƒé£æ ¼ç¼–è¾‘</p></li><li><p>Authors: Zhen Han, Chaojie Mao, Zeyinzi Jiang, Yulin Pan, Jingfeng Zhang</p></li><li><p>Affiliation: é˜¿é‡Œå·´å·´é›†å›¢</p></li><li><p>Keywords: Text-based style editing Â· Exemplar-based style editing Â· Multimodal instruction-tuning</p></li><li><p>Urls: https://arxiv.org/abs/2404.12154, Github:None</p></li><li><p>Summary:</p></li></ol><p>(1):å›¾åƒç¼–è¾‘æ—¨åœ¨æ ¹æ®æä¾›çš„æŒ‡ä»¤ç”Ÿæˆä¸åŸå›¾åƒå¯¹é½çš„å›¾åƒã€‚æŒ‘æˆ˜åœ¨äºæ¥å—å¤šæ¨¡æ€è¾“å…¥ä½œä¸ºæŒ‡ä»¤ï¼Œä»¥åŠç¼ºä¹é«˜è´¨é‡è®­ç»ƒæ•°æ®ï¼ŒåŒ…æ‹¬æº/ç›®æ ‡å›¾åƒå¯¹å’Œå¤šæ¨¡æ€ï¼ˆæ–‡æœ¬å’Œå›¾åƒï¼‰æŒ‡ä»¤çš„å…³é”®ä¸‰å…ƒç»„ã€‚</p><p>(2):ä»¥å¾€çš„æ–¹æ³•ä¸»è¦åŒ…æ‹¬æ“çºµæ³¨æ„åŠ›æœºåˆ¶çš„ç‰¹å¾ã€åœ¨å»å™ªæ­¥éª¤ä¸­å®ç°å¼•å¯¼æ‰©æ•£ã€ä½¿ç”¨å›¾åƒå¯¹è¿›è¡Œç›‘ç£æ¥è°ƒæ•´ T2I æ¨¡å‹ç­‰ã€‚è¿™äº›æ–¹æ³•éƒ½é¢ä¸´ç€åªæ”¯æŒå•æ¨¡æ€è¾“å…¥ã€ç¼ºä¹é«˜è´¨é‡è®­ç»ƒæ•°æ®ã€éš¾ä»¥ä¿æŒå†…å®¹ä¸€è‡´æ€§ç­‰é—®é¢˜ã€‚</p><p>(3):æœ¬æ–‡æå‡º StyleBooth æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æå‡ºäº†ä¸€ä¸ªç”¨äºå›¾åƒç¼–è¾‘çš„ç»¼åˆæ¡†æ¶å’Œæ„å»ºé«˜è´¨é‡é£æ ¼ç¼–è¾‘æ•°æ®é›†çš„å¯è¡Œç­–ç•¥ã€‚æˆ‘ä»¬å°†ç¼–ç çš„æ–‡æœ¬æŒ‡ä»¤å’Œå›¾åƒç¤ºä¾‹æ•´åˆä¸ºæ‰©æ•£æ¨¡å‹çš„ç»Ÿä¸€æ¡ä»¶ï¼Œä»è€Œèƒ½å¤Ÿæ ¹æ®å¤šæ¨¡æ€æŒ‡ä»¤ç¼–è¾‘åŸå§‹å›¾åƒã€‚æ­¤å¤–ï¼Œé€šè¿‡è¿­ä»£çš„é£æ ¼-å»é£æ ¼è°ƒæ•´å’Œç¼–è¾‘ä»¥åŠå¯ç”¨æ€§è¿‡æ»¤ï¼ŒStyleBooth æ•°æ®é›†æä¾›äº†å„ç§é£æ ¼ç±»åˆ«ä¸­å†…å®¹ä¸€è‡´çš„é£æ ¼åŒ–/-æ™®é€šå›¾åƒå¯¹ã€‚</p><p>(4):å®éªŒç»“æœè¡¨æ˜ï¼Œè®­ç»ƒæ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§æ˜¾ç€å¢å¼ºäº†åœ¨ç¼–è¾‘ä»»åŠ¡ä¸­ä¿ç•™å†…å®¹å’Œæé«˜ç”Ÿæˆå›¾åƒæ•´ä½“è´¨é‡çš„èƒ½åŠ›ã€‚</p><ol><li>æ–¹æ³•ï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šStyleBooth æ–¹æ³•æå‡ºäº†ä¸€ç§ç”¨äºå›¾åƒç¼–è¾‘çš„ç»¼åˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ç¼–ç çš„æ–‡æœ¬æŒ‡ä»¤å’Œå›¾åƒç¤ºä¾‹æ•´åˆä¸ºæ‰©æ•£æ¨¡å‹çš„ç»Ÿä¸€æ¡ä»¶ï¼Œèƒ½å¤Ÿæ ¹æ®å¤šæ¨¡æ€æŒ‡ä»¤ç¼–è¾‘åŸå§‹å›¾åƒï¼›</p><p>ï¼ˆ2ï¼‰ï¼šStyleBooth æ•°æ®é›†é€šè¿‡è¿­ä»£çš„é£æ ¼-å»é£æ ¼è°ƒæ•´å’Œç¼–è¾‘ä»¥åŠå¯ç”¨æ€§è¿‡æ»¤ï¼Œæä¾›äº†å„ç§é£æ ¼ç±»åˆ«ä¸­å†…å®¹ä¸€è‡´çš„é£æ ¼åŒ–/-æ™®é€šå›¾åƒå¯¹ï¼Œæé«˜äº†è®­ç»ƒæ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼Œå¢å¼ºäº†åœ¨ç¼–è¾‘ä»»åŠ¡ä¸­ä¿ç•™å†…å®¹å’Œæé«˜ç”Ÿæˆå›¾åƒæ•´ä½“è´¨é‡çš„èƒ½åŠ›ï¼›</p><p>ï¼ˆ3ï¼‰ï¼šScale Weighting Mechanism æœºåˆ¶é€šè¿‡å¯¹éšè—ç©ºé—´åµŒå…¥è¿›è¡Œç¼©æ”¾åŠ æƒï¼Œå¹³è¡¡äº†ä¸åŒæ¨¡æ€çš„é£æ ¼è¡¨ç°ï¼Œä¿è¯äº†å›¾åƒç¼–è¾‘çš„è´¨é‡ã€‚</p><ol><li>ç»“è®ºï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡º StyleBoothï¼Œè¿™æ˜¯ä¸€ç§å¤šæ¨¡æ€æŒ‡ä»¤å›¾åƒé£æ ¼ç¼–è¾‘æ–¹æ³•ã€‚å®ƒç‹¬ç«‹ç¼–ç å‚è€ƒå›¾åƒå’Œæ–‡æœ¬ï¼Œéšååœ¨æ½œåœ¨ç©ºé—´å†…å¯¹å…¶è¿›è¡Œè½¬æ¢å’Œå¯¹é½ï¼Œç„¶åæ³¨å…¥éª¨å¹²ç½‘ç»œä»¥è¿›è¡Œç”ŸæˆæŒ‡å¯¼ï¼Œä»¥å®ç°åŸºäºæ–‡æœ¬å’Œç¤ºä¾‹çš„æŒ‡ä»¤ç¼–è¾‘ã€‚åŒæ—¶ï¼ŒStyleBooth è¿˜å¯ä»¥èåˆå¤šæ¨¡æ€ä¿¡æ¯è¿›è¡Œåˆæˆåˆ›é€ æ€§ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç”¨äºé£æ ¼ç¼–è¾‘çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç”±å„ç§å†…å®¹ä¸€è‡´çš„é£æ ¼åŒ–å’Œæ™®é€šå›¾åƒå¯¹ç»„æˆï¼Œè¿™æœ‰åŠ©äºæˆ‘ä»¬æ„å»ºæ›´å¥½çš„ç¼–è¾‘æ¨¡å‹ã€‚å±€é™æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç”¨äºé£æ ¼ç¼–è¾‘çš„ä¸°å¯Œæ•°æ®é›†ã€‚ç„¶è€Œï¼Œæ•°æ®æ„å»ºåŸºäºç‰¹å®šé£æ ¼çš„æ–‡æœ¬æè¿°ï¼Œä¾‹å¦‚æ°´å½©ç”»ï¼Œè¿™æå¤§åœ°é™åˆ¶äº†é£æ ¼çš„æ•°é‡ã€‚æ”¶é›†æ›´å¹¿æ³›ã€æ›´å¹¿æ³›çš„ç¼–è¾‘æ•°æ®é›†å°†æ˜¯æˆ‘ä»¬æœªæ¥çš„å·¥ä½œã€‚</p><p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡º StyleBooth æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†ç¼–ç çš„æ–‡æœ¬æŒ‡ä»¤å’Œå›¾åƒç¤ºä¾‹æ•´åˆä¸ºæ‰©æ•£æ¨¡å‹çš„ç»Ÿä¸€æ¡ä»¶ï¼Œèƒ½å¤Ÿæ ¹æ®å¤šæ¨¡æ€æŒ‡ä»¤ç¼–è¾‘åŸå§‹å›¾åƒï¼›æ„å»º StyleBooth æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†é€šè¿‡è¿­ä»£çš„é£æ ¼-å»é£æ ¼è°ƒæ•´å’Œç¼–è¾‘ä»¥åŠå¯ç”¨æ€§è¿‡æ»¤ï¼Œæä¾›äº†å„ç§é£æ ¼ç±»åˆ«ä¸­å†…å®¹ä¸€è‡´çš„é£æ ¼åŒ–/-æ™®é€šå›¾åƒå¯¹ï¼Œæé«˜äº†è®­ç»ƒæ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼›æå‡º Scale Weighting Mechanism æœºåˆ¶ï¼Œé€šè¿‡å¯¹éšè—ç©ºé—´åµŒå…¥è¿›è¡Œç¼©æ”¾åŠ æƒï¼Œå¹³è¡¡äº†ä¸åŒæ¨¡æ€çš„é£æ ¼è¡¨ç°ï¼Œä¿è¯äº†å›¾åƒç¼–è¾‘çš„è´¨é‡ã€‚ æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè®­ç»ƒæ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§æ˜¾ç€å¢å¼ºäº†åœ¨ç¼–è¾‘ä»»åŠ¡ä¸­ä¿ç•™å†…å®¹å’Œæé«˜ç”Ÿæˆå›¾åƒæ•´ä½“è´¨é‡çš„èƒ½åŠ›ã€‚ å·¥ä½œé‡ï¼šæœ¬æ–‡çš„æ–¹æ³•å’Œæ•°æ®é›†çš„æ„å»ºè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒå¤§çš„è®¡ç®—èµ„æºå’ŒäººåŠ›æŠ•å…¥ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-b55633af77d0cb6e6dbf35b308d980ca.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-8f75d6d068abc3a313d3144833482a9f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-f20cb7f7a36d3c7049b18131117bc5cd.jpg" align="middle"></details><h2 id="IntrinsicAnything-Learning-Diffusion-Priors-for-Inverse-Rendering-Under-Unknown-Illumination"><a href="#IntrinsicAnything-Learning-Diffusion-Priors-for-Inverse-Rendering-Under-Unknown-Illumination" class="headerlink" title="IntrinsicAnything: Learning Diffusion Priors for Inverse Rendering Under   Unknown Illumination"></a>IntrinsicAnything: Learning Diffusion Priors for Inverse Rendering Under Unknown Illumination</h2><p><strong>Authors:Xi Chen, Sida Peng, Dongchen Yang, Yuan Liu, Bowen Pan, Chengfei Lv, Xiaowei Zhou</strong></p><p>This paper aims to recover object materials from posed images captured under an unknown static lighting condition. Recent methods solve this task by optimizing material parameters through differentiable physically based rendering. However, due to the coupling between object geometry, materials, and environment lighting, there is inherent ambiguity during the inverse rendering process, preventing previous methods from obtaining accurate results. To overcome this ill-posed problem, our key idea is to learn the material prior with a generative model for regularizing the optimization process. We observe that the general rendering equation can be split into diffuse and specular shading terms, and thus formulate the material prior as diffusion models of albedo and specular. Thanks to this design, our model can be trained using the existing abundant 3D object data, and naturally acts as a versatile tool to resolve the ambiguity when recovering material representations from RGB images. In addition, we develop a coarse-to-fine training strategy that leverages estimated materials to guide diffusion models to satisfy multi-view consistent constraints, leading to more stable and accurate results. Extensive experiments on real-world and synthetic datasets demonstrate that our approach achieves state-of-the-art performance on material recovery. The code will be available at <a target="_blank" rel="noopener" href="https://zju3dv.github.io/IntrinsicAnything">https://zju3dv.github.io/IntrinsicAnything</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.11593v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://zju3dv.github.io/IntrinsicAnything">https://zju3dv.github.io/IntrinsicAnything</a></p><p><strong>Summary</strong><br>åˆ©ç”¨ç”Ÿæˆæ¨¡å‹å­¦ä¹ æè´¨å…ˆéªŒï¼Œä»¥æ­£åˆ™åŒ–ä¼˜åŒ–è¿‡ç¨‹ï¼Œä»è€Œæ¢å¤æœªçŸ¥é™æ€å…‰ç…§æ¡ä»¶ä¸‹å§¿åŠ¿å›¾åƒä¸­çš„ç‰©ä½“æè´¨ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>å°†é€šç”¨æ¸²æŸ“æ–¹ç¨‹æ‹†åˆ†ä¸ºæ¼«åå°„å’Œé•œé¢åå°„ç€è‰²é¡¹ï¼Œå¹¶å°†æè´¨å…ˆéªŒè¡¨è¿°ä¸ºæ¼«åå°„ç‡å’Œé•œé¢çš„æ‰©æ•£æ¨¡å‹ã€‚</li><li>ä½¿ç”¨ç°æœ‰çš„ä¸°å¯Œ 3D ç‰©ä½“æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œå°†å…¶ä½œä¸ºè§£å†³ä» RGB å›¾åƒæ¢å¤æè´¨è¡¨ç¤ºæ—¶æ¨¡ç³Šæ€§çš„é€šç”¨å·¥å…·ã€‚</li><li>å¼€å‘äº†ä¸€ç§ç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œåˆ©ç”¨ä¼°è®¡çš„æè´¨æ¥å¼•å¯¼æ‰©æ•£æ¨¡å‹æ»¡è¶³å¤šè§†å›¾ä¸€è‡´æ€§çº¦æŸï¼Œä»è€Œè·å¾—æ›´ç¨³å®šå’Œå‡†ç¡®çš„ç»“æœã€‚</li><li>åœ¨çœŸå®ä¸–ç•Œå’Œåˆæˆæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æè´¨æ¢å¤æ–¹é¢è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li><p></p><p>è®ºæ–‡æ ‡é¢˜ï¼šIntrinsicAnything: å­¦ä¹ æ‰©æ•£å…ˆéªŒä»¥åœ¨æœªçŸ¥å…‰ç…§ä¸‹è¿›è¡Œé€†å‘æ¸²æŸ“</p></li><li><p>ä½œè€…ï¼šXi Chen, Sida Peng, Dongchen Yang, Yuan Liu, Bowen Pan, Chengfei Lv, Xiaowei Zhou</p></li><li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæµ™æ±Ÿå¤§å­¦è®¡ç®—æœºè¾…åŠ©è®¾è®¡ä¸å›¾å½¢å­¦å›½å®¶é‡ç‚¹å®éªŒå®¤</p></li><li><p>å…³é”®è¯ï¼šInverse Rendering, Material Recovery, Diffusion Model, Generative Prior</p></li><li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2404.11593 , Githubï¼šNone</p></li><li><p>æ‘˜è¦ï¼š</p></li></ol><p>(1) ç ”ç©¶èƒŒæ™¯ï¼šä»æ•è·çš„å›¾åƒä¸­æ¢å¤ç‰©ä½“çš„å‡ ä½•ã€æè´¨å’Œå…‰ç…§ï¼Œå³é€†å‘æ¸²æŸ“ï¼Œæ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­ä¸€é¡¹é•¿æœŸå­˜åœ¨çš„ä»»åŠ¡ã€‚è¿™äº› 3D ç‰©ä½“çš„ç‰©ç†å±æ€§å¯¹äºè®¸å¤šåº”ç”¨ç¨‹åºè‡³å…³é‡è¦ï¼Œä¾‹å¦‚ VR/ARã€ç”µå½±åˆ¶ä½œå’Œè§†é¢‘æ¸¸æˆã€‚ç”±äºç°å®ä¸–ç•Œç‰©ä½“ä¸ç¯å¢ƒå…‰ç…§ä¹‹é—´ç›¸äº’ä½œç”¨çš„å›ºæœ‰å¤æ‚æ€§ï¼Œé€†å‘æ¸²æŸ“ä»ç„¶æ˜¯ä¸€ä¸ªä¸é€‚å®šé—®é¢˜ã€‚</p><p>(2) è¿‡å¾€æ–¹æ³•åŠé—®é¢˜ï¼šä»¥å¾€çš„å·¥ä½œé€šè¿‡å¤æ‚çš„æ•è·ç³»ç»Ÿ[16,20]æˆ–åœ¨é»‘æš—ç¯å¢ƒä¸­å…±åŒå®šä½çš„æ‰‹ç”µç­’å’Œç›¸æœº[5,50,84]æ¥å…‹æœè¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éœ€è¦ç‰¹æ®Šçš„ç¡¬ä»¶è®¾å¤‡æˆ–å—é™çš„ç¯å¢ƒï¼Œé™åˆ¶äº†å®ƒä»¬çš„åº”ç”¨ã€‚</p><p>(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å…‹æœè¿™ä¸ªä¸é€‚å®šé—®é¢˜ï¼Œæˆ‘ä»¬çš„å…³é”®æ€æƒ³æ˜¯å­¦ä¹ ä¸€ä¸ªç”Ÿæˆæ¨¡å‹ä½œä¸ºæè´¨å…ˆéªŒæ¥æ­£åˆ™åŒ–ä¼˜åŒ–è¿‡ç¨‹ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œä¸€èˆ¬çš„æ¸²æŸ“æ–¹ç¨‹å¯ä»¥åˆ†è§£ä¸ºæ¼«åå°„å’Œé•œé¢åå°„é˜´å½±é¡¹ï¼Œå› æ­¤å°†æè´¨å…ˆéªŒè¡¨è¿°ä¸ºæ¼«åå°„å’Œé•œé¢åå°„çš„æ‰©æ•£æ¨¡å‹ã€‚ç”±äºè¿™ç§è®¾è®¡ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨ç°æœ‰çš„ä¸°å¯Œ 3D å¯¹è±¡æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”è‡ªç„¶åœ°å……å½“äº†ä¸€ç§å¤šåŠŸèƒ½å·¥å…·ï¼Œå¯ä»¥åœ¨ä» RGB å›¾åƒä¸­æ¢å¤æè´¨è¡¨ç¤ºæ—¶è§£å†³æ­§ä¹‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ä»ç²—åˆ°ç²¾çš„è®­ç»ƒç­–ç•¥ï¼Œåˆ©ç”¨ä¼°è®¡çš„æè´¨æ¥å¼•å¯¼æ‰©æ•£æ¨¡å‹æ»¡è¶³å¤šè§†å›¾ä¸€è‡´æ€§çº¦æŸï¼Œä»è€Œå¾—åˆ°æ›´ç¨³å®šå’Œå‡†ç¡®çš„ç»“æœã€‚</p><p>(4) æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼šåœ¨çœŸå®ä¸–ç•Œå’Œåˆæˆæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æè´¨æ¢å¤æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¯¥æ€§èƒ½å¯ä»¥æ”¯æŒä»–ä»¬çš„ç›®æ ‡ã€‚</p><ol><li>æ–¹æ³•ï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæå‡ºå­¦ä¹ æ‰©æ•£æ¨¡å‹ä½œä¸ºæè´¨å…ˆéªŒï¼Œæ­£åˆ™åŒ–é€†å‘æ¸²æŸ“ä¼˜åŒ–è¿‡ç¨‹ã€‚</p><p>ï¼ˆ2ï¼‰ï¼šå°†æ¸²æŸ“æ–¹ç¨‹åˆ†è§£ä¸ºæ¼«åå°„å’Œé•œé¢åå°„é˜´å½±é¡¹ï¼Œå°†æè´¨å…ˆéªŒè¡¨è¿°ä¸ºæ¼«åå°„å’Œé•œé¢åå°„çš„æ‰©æ•£æ¨¡å‹ã€‚</p><p>ï¼ˆ3ï¼‰ï¼šé‡‡ç”¨ä»ç²—åˆ°ç²¾çš„è®­ç»ƒç­–ç•¥ï¼Œåˆ©ç”¨ä¼°è®¡çš„æè´¨å¼•å¯¼æ‰©æ•£æ¨¡å‹æ»¡è¶³å¤šè§†å›¾ä¸€è‡´æ€§çº¦æŸï¼Œå¾—åˆ°æ›´ç¨³å®šå’Œå‡†ç¡®çš„ç»“æœã€‚</p><ol><li>ç»“è®ºï¼š</li></ol><p>ï¼ˆ1ï¼‰ï¼šæå‡ºäº† IntrinsicAnything æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨æ‰©æ•£æ¨¡å‹ä½œä¸ºæè´¨å…ˆéªŒï¼Œåœ¨æœªçŸ¥é™æ€å…‰ç…§æ¡ä»¶ä¸‹è¿›è¡Œé€†å‘æ¸²æŸ“ã€‚</p><p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºå°†æè´¨å…ˆéªŒè®¾è®¡ä¸ºæ¼«åå°„å’Œé•œé¢åå°„çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼›å¼€å‘äº†ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ¡ˆï¼Œåˆ©ç”¨ç²—ç•¥æè´¨å¼•å¯¼æ‰©æ•£æ¨¡å‹æ»¡è¶³å¤šè§†å›¾ä¸€è‡´æ€§çº¦æŸã€‚æ€§èƒ½ï¼šåœ¨çœŸå®ä¸–ç•Œå’Œåˆæˆæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æè´¨æ¢å¤æ€§èƒ½ã€‚å·¥ä½œé‡ï¼šéœ€è¦è¾ƒå¤§çš„æ•°æ®é›†å’Œè¾ƒé•¿çš„è®­ç»ƒæ—¶é—´ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2e3e705009374322a07a0404ed794846.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-b8b028549fe12e9acbbb7374c824289a.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-474fe30507cc76c6aa5c2fec1a6e92ad.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-ffae13d6e393c5f464c5f05ee6f4295a.jpg" align="middle"></details><h2 id="MoA-Mixture-of-Attention-for-Subject-Context-Disentanglement-in-Personalized-Image-Generation"><a href="#MoA-Mixture-of-Attention-for-Subject-Context-Disentanglement-in-Personalized-Image-Generation" class="headerlink" title="MoA: Mixture-of-Attention for Subject-Context Disentanglement in   Personalized Image Generation"></a>MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation</h2><p><strong>Authors: Kuan-Chieh, Wang, Daniil Ostashev, Yuwei Fang, Sergey Tulyakov, Kfir Aberman</strong></p><p>We introduce a new architecture for personalization of text-to-image diffusion models, coined Mixture-of-Attention (MoA). Inspired by the Mixture-of-Experts mechanism utilized in large language models (LLMs), MoA distributes the generation workload between two attention pathways: a personalized branch and a non-personalized prior branch. MoA is designed to retain the original modelâ€™s prior by fixing its attention layers in the prior branch, while minimally intervening in the generation process with the personalized branch that learns to embed subjects in the layout and context generated by the prior branch. A novel routing mechanism manages the distribution of pixels in each layer across these branches to optimize the blend of personalized and generic content creation. Once trained, MoA facilitates the creation of high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model. Crucially, MoA enhances the distinction between the modelâ€™s pre-existing capability and the newly augmented personalized intervention, thereby offering a more disentangled subject-context control that was previously unattainable. Project page: <a target="_blank" rel="noopener" href="https://snap-research.github.io/mixture-of-attention">https://snap-research.github.io/mixture-of-attention</a></p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2404.11565v1">PDF</a> Project Website: <a target="_blank" rel="noopener" href="https://snap-research.github.io/mixture-of-attention">https://snap-research.github.io/mixture-of-attention</a></p><p><strong>Summary</strong><br>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸ªæ€§åŒ–çš„æ··åˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œåœ¨é¢„å…ˆå›ºå®šçš„éä¸ªæ€§åŒ–åŸºç¡€åˆ†æ”¯ä¸Šå åŠ å¯å­¦ä¹ çš„ä¸ªæ€§åŒ–åˆ†æ”¯ï¼Œä¼˜åŒ–ä¸ªæ€§åŒ–å’Œé€šç”¨å†…å®¹åˆ›å»ºçš„æ··åˆï¼Œå®ç°æ›´è§£è€¦çš„ä¸»é¢˜-ä¸Šä¸‹æ–‡æ§åˆ¶ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡ºæ··åˆæ³¨æ„æœºåˆ¶ï¼ˆMoAï¼‰æ¶æ„ï¼Œç”¨äºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ä¸ªæ€§åŒ–ã€‚</li><li>MoA åˆ†å‘ç”Ÿæˆå·¥ä½œè´Ÿè½½åˆ°ä¸ªæ€§åŒ–åˆ†æ”¯å’Œéä¸ªæ€§åŒ–å…ˆéªŒåˆ†æ”¯ã€‚</li><li>ä¸ªæ€§åŒ–åˆ†æ”¯åœ¨å…ˆéªŒåˆ†æ”¯ç”Ÿæˆçš„å¸ƒå±€å’Œä¸Šä¸‹æ–‡ä¸­åµŒå…¥ä¸»é¢˜ã€‚</li><li>æ–°é¢–çš„è·¯ç”±æœºåˆ¶ä¼˜åŒ–äº†è·¨åˆ†æ”¯çš„åƒç´ åˆ†é…ã€‚</li><li>MoA å…è®¸åˆ›å»ºé«˜è´¨é‡çš„ä¸ªæ€§åŒ–å›¾åƒï¼Œå…·æœ‰å¤šç§ä¸»é¢˜å’Œäº¤äº’ã€‚</li><li>MoA å¢å¼ºäº†æ¨¡å‹çš„å…ˆéªŒåŠŸèƒ½å’Œä¸ªæ€§åŒ–å¹²é¢„ä¹‹é—´çš„åŒºåˆ«ã€‚</li><li>MoA æä¾›äº†ä»¥å‰æ— æ³•å®ç°çš„æ›´è§£è€¦çš„ä¸»é¢˜-ä¸Šä¸‹æ–‡æ§åˆ¶ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li><p></p><p>Title: MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation</p></li><li><p>Authors: Kuan-Chieh (Jackson) Wang, Daniil Ostashev, Yuwei Fang, Sergey Tulyakov, Kfir Aberman</p></li><li><p>Affiliation: Snap Inc., USA</p></li><li><p>Keywords: Personalization, Text-to-image Generation, Diffusion Models</p></li><li><p>Urls: https://arxiv.org/abs/2404.11565, Github:None</p></li><li><p>Summary:</p></li></ol><p>(1): The research background of this article is the rapid progress in foundation text-conditioned image synthesis with diffusion models. Personalized generation focuses on adapting and contextualizing the generation to a set of desired subjects using limited input images, while retaining the powerful generative capabilities of the foundation model.</p><p>(2): Past methods for personalized generation include fine-tuning-based personalization techniques and approaches optimized for multi-subject generation. However, fine-tuning-based methods tend to overfit to certain attributes in the distribution of the input images or struggle to adhere adequately to the input prompt. Approaches optimized for multi-subject generation often modify the original model's weights, resulting in compositions that lack diversity and naturalness.</p><p>(3): The research methodology proposed in this paper is Mixture-of-Attention (MoA), which extends the vanilla attention mechanism into multiple attention blocks (i.e. experts), and has a router network that softly combines the different experts. MoA distributes the generation between personalized and non-personalized attention pathways. It is designed to retain the original model's prior by fixing its attention layers in the prior (non-personalized) branch, while minimally intervening in the generation process with the personalized branch.</p><p>(4): MoA is evaluated on the task of personalized image generation. The results show that MoA can generate high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model. MoA also enhances the distinction between the model's pre-existing capability and the newly augmented personalized intervention, thereby offering a more disentangled subject-context control that was previously unattainable.</p><ol><li><p>æ–¹æ³•ï¼š</p><pre><code>            (1): æå‡ºMixture-of-Attentionï¼ˆMoAï¼‰å±‚ï¼Œå°†vanillaæ³¨æ„åŠ›æœºåˆ¶æ‰©å±•ä¸ºå¤šä¸ªæ³¨æ„åŠ›æ¨¡å—ï¼ˆå³ä¸“å®¶ï¼‰ï¼Œå¹¶ä½¿ç”¨è·¯ç”±å™¨ç½‘ç»œå¯¹ä¸åŒä¸“å®¶è¿›è¡Œè½¯ç»„åˆã€‚

            (2): MoAå°†ç”Ÿæˆåˆ†é…åˆ°ä¸ªæ€§åŒ–å’Œéä¸ªæ€§åŒ–æ³¨æ„åŠ›è·¯å¾„ä¹‹é—´ã€‚å®ƒé€šè¿‡å›ºå®šå…ˆéªŒï¼ˆéä¸ªæ€§åŒ–ï¼‰åˆ†æ”¯ä¸­çš„æ³¨æ„åŠ›å±‚æ¥ä¿ç•™åŸå§‹æ¨¡å‹çš„å…ˆéªŒï¼ŒåŒæ—¶é€šè¿‡ä¸ªæ€§åŒ–åˆ†æ”¯å¯¹ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œæœ€å°å¹²é¢„ã€‚

            (3): å°†MoAåº”ç”¨äºæ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹ä¸­ï¼Œç”¨äºä¸»é¢˜é©±åŠ¨çš„ç”Ÿæˆã€‚è¯¥æ¶æ„ä½¿æˆ‘ä»¬èƒ½å¤Ÿå¢å¼ºT2Iæ¨¡å‹çš„èƒ½åŠ›ï¼Œä»¥æ‰§è¡Œä¸»é¢˜é©±åŠ¨çš„ç”Ÿæˆï¼ŒåŒæ—¶å¯¹ä¸»é¢˜å’Œä¸Šä¸‹æ–‡è¿›è¡Œè§£è€¦æ§åˆ¶ï¼Œä»è€Œä¿ç•™å…ˆéªŒæ¨¡å‹ä¸­å›ºæœ‰çš„å¤šæ ·åŒ–å›¾åƒåˆ†å¸ƒã€‚
</code></pre></li><li><p>ç»“è®ºï¼š</p></li></ol><p>ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„æ„ä¹‰åœ¨äºï¼šæå‡ºäº†ä¸€ç§æ–°çš„ä¸ªæ€§åŒ–ç”Ÿæˆæ¶æ„ Mixture-of-Attentionï¼ˆMoAï¼‰ï¼Œè¯¥æ¶æ„å¢å¼ºäº†åŸºç¡€æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ³¨å…¥ä¸»é¢˜å›¾åƒï¼ŒåŒæ—¶ä¿ç•™äº†æ¨¡å‹çš„å…ˆå‰èƒ½åŠ›ã€‚ä¸ç°æœ‰ä¸»é¢˜é©±åŠ¨ç”Ÿæˆæ–¹æ³•ç”Ÿæˆçš„å›¾åƒç›¸æ¯”ï¼ŒMoA æ— ç¼åœ°ç»Ÿä¸€äº†ä¸¤ç§èŒƒå¼ï¼Œé€šè¿‡æ‹¥æœ‰ä¸¤ä¸ªä¸åŒçš„ä¸“å®¶å’Œä¸€ä¸ªè·¯ç”±å™¨æ¥åŠ¨æ€åˆå¹¶ä¸¤ä¸ªè·¯å¾„ã€‚MoA å±‚èƒ½å¤Ÿåœ¨ä¸€æ¬¡åå‘æ‰©æ•£ä¼ é€’ä¸­ä»å…·æœ‰ä¸°å¯Œäº¤äº’çš„å¤šä¸ªè¾“å…¥ä¸»é¢˜ç”Ÿæˆä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡ï¼Œå¹¶ä¸”ä¸éœ€è¦æµ‹è¯•æ—¶å¾®è°ƒæ­¥éª¤ï¼Œä»è€Œè§£é”äº†ä»¥å‰æ— æ³•è¾¾åˆ°çš„ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å±•ç¤ºäº†ç”Ÿæˆå›¾åƒä¸­ä»¥å‰æœªè§çš„å¸ƒå±€å˜åŒ–ï¼Œä»¥åŠå¤„ç†ç‰©ä½“æˆ–å…¶ä»–ä¸»é¢˜é®æŒ¡çš„èƒ½åŠ›ï¼Œå¹¶ä¸”æ— éœ€æ˜¾å¼æ§åˆ¶å³å¯å¤„ç†ä¸åŒçš„èº«ä½“å½¢çŠ¶ã€‚æœ€åï¼Œç”±äºå…¶ç®€å•æ€§ï¼ŒMoA ä¸ä¼—æ‰€å‘¨çŸ¥çš„åŸºäºæ‰©æ•£çš„ç”Ÿæˆå’Œç¼–è¾‘æŠ€æœ¯ï¼ˆå¦‚ ControlNet å’Œ DDIM Inversionï¼‰å¤©ç„¶å…¼å®¹ã€‚ä¾‹å¦‚ï¼ŒMoA å’Œ DDIM Inversion çš„ç»“åˆè§£é”äº†åœ¨çœŸå®ç…§ç‰‡ä¸­è¿›è¡Œä¸»é¢˜äº¤æ¢çš„åº”ç”¨ã€‚å±•æœ›æœªæ¥ï¼Œæˆ‘ä»¬è®¾æƒ³é€šè¿‡ä¸“é—¨é’ˆå¯¹ä¸åŒä»»åŠ¡æˆ–è¯­ä¹‰æ ‡ç­¾çš„ä¸åŒä¸“å®¶è¿›ä¸€æ­¥å¢å¼º MoA æ¶æ„ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨æå°å¹²é¢„ä¸ªæ€§åŒ–çš„æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å„ç§åŸºç¡€æ¨¡å‹ï¼ˆä¾‹å¦‚è§†é¢‘å’Œ 3D/4D ç”Ÿæˆï¼‰ï¼Œä»è€Œä¿ƒè¿›ä½¿ç”¨ç°æœ‰å’Œæœªæ¥ç”Ÿæˆæ¨¡å‹åˆ›å»ºä¸ªæ€§åŒ–å†…å®¹ã€‚</p><p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°çš„ Mixture-of-Attentionï¼ˆMoAï¼‰æ¶æ„ï¼Œè¯¥æ¶æ„å¢å¼ºäº†åŸºç¡€æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ³¨å…¥ä¸»é¢˜å›¾åƒï¼ŒåŒæ—¶ä¿ç•™äº†æ¨¡å‹çš„å…ˆå‰èƒ½åŠ›ã€‚MoA å±‚èƒ½å¤Ÿåœ¨ä¸€æ¬¡åå‘æ‰©æ•£ä¼ é€’ä¸­ä»å…·æœ‰ä¸°å¯Œäº¤äº’çš„å¤šä¸ªè¾“å…¥ä¸»é¢˜ç”Ÿæˆä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡ï¼Œå¹¶ä¸”ä¸éœ€è¦æµ‹è¯•æ—¶å¾®è°ƒæ­¥éª¤ï¼Œä»è€Œè§£é”äº†ä»¥å‰æ— æ³•è¾¾åˆ°çš„ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å±•ç¤ºäº†ç”Ÿæˆå›¾åƒä¸­ä»¥å‰æœªè§çš„å¸ƒå±€å˜åŒ–ï¼Œä»¥åŠå¤„ç†ç‰©ä½“æˆ–å…¶ä»–ä¸»é¢˜é®æŒ¡çš„èƒ½åŠ›ï¼Œå¹¶ä¸”æ— éœ€æ˜¾å¼æ§åˆ¶å³å¯å¤„ç†ä¸åŒçš„èº«ä½“å½¢çŠ¶ã€‚</p><p>æ€§èƒ½ï¼šåœ¨ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ MoA å¯ä»¥ç”Ÿæˆé«˜è´¨é‡ã€ä¸ªæ€§åŒ–çš„å›¾åƒï¼Œå…¶ç‰¹å¾æ˜¯å…·æœ‰ä¸åŸå§‹æ¨¡å‹ç”Ÿæˆå›¾åƒä¸€æ ·å¤šæ ·åŒ–çš„æ„å›¾å’Œäº¤äº’ã€‚MoA è¿˜å¢å¼ºäº†æ¨¡å‹ç°æœ‰èƒ½åŠ›å’Œæ–°å¢å¼ºä¸ªæ€§åŒ–å¹²é¢„ä¹‹é—´çš„åŒºåˆ«ï¼Œä»è€Œæä¾›äº†ä»¥å‰æ— æ³•å®ç°çš„æ›´åˆ†ç¦»çš„ä¸»é¢˜-ä¸Šä¸‹æ–‡æ§åˆ¶ã€‚</p><p>å·¥ä½œé‡ï¼šMoA å…·æœ‰ç®€å•æ€§ï¼Œä¸ä¼—æ‰€å‘¨çŸ¥çš„åŸºäºæ‰©æ•£çš„ç”Ÿæˆå’Œç¼–è¾‘æŠ€æœ¯ï¼ˆå¦‚ ControlNet å’Œ DDIM Inversionï¼‰å¤©ç„¶å…¼å®¹ã€‚ä¾‹å¦‚ï¼ŒMoA å’Œ DDIM Inversion çš„ç»“åˆè§£é”äº†åœ¨çœŸå®ç…§ç‰‡ä¸­è¿›è¡Œä¸»é¢˜äº¤æ¢çš„åº”ç”¨ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-65299f0067c3022cccf14b21e08de1a6.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-058ccecf97ed2df42286d132194a3ffe.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-577cd46daa6ad37536d9e75f13d51239.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-728a034564b4e30499365332b12dfe09.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c4cd4a1d04735a77754757aa6e384614.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-fdeae7faf257d15601bbe1c62a204408.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-5c3251b1f6745891a76c08f07664b47d.jpg" align="middle"></details></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io/2024/04/22/Paper/2024-04-22/Diffusion%20Models/">https://kedreamix.github.io/2024/04/22/Paper/2024-04-22/Diffusion Models/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜:</span> <span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Diffusion-Models/">Diffusion Models</a></div><div class="post_share"><div class="social-share" data-image="https://pic1.zhimg.com/v2-0aba7591bd6a8a973210ed734d1006c9.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>èµåŠ©</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/04/22/Paper/2024-04-22/Talking%20Head%20Generation/" title="Talking Head Generation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3fe7530e7260eff001a6736622671663.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">Talking Head Generation</div></div></a></div><div class="next-post pull-right"><a href="/2024/04/17/Paper/2024-04-17/NeRF/" title="NeRF"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-8ada6cbf2edd7e1759c7ba909af2521f.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">NeRF</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>ç›¸å…³æ¨è</span></div><div class="relatedPosts-list"><div><a href="/2024/03/03/Paperscape/EMO/" title="EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6492e24fb03ffa98135dc584535ab7d9.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-03</div><div class="title">EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC</div></div></a></div><div><a href="/2024/01/24/Paper/2024-01-24/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-71a37c439c6714e8867560f580599d2f.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-24</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/02/Paper/2024-02-02/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-5920453c69c00995f18077b22d4a790e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-02</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/01/30/Paper/2024-01-30/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-e55358c77a9d65f15701e8f33262e2a4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/13/Paper/2024-02-13/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3709a9941aada6c4d3ed35934e311765.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-13</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/09/Paper/2024-02-09/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-32488f736ee10537497afccc3a1a1d76.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-09</div><div class="title">Diffusion Models</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-04-22-%E6%9B%B4%E6%96%B0"><span class="toc-text">2024-04-22 æ›´æ–°</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Zero-Shot-Medical-Phrase-Grounding-with-Off-the-shelf-Diffusion-Models"><span class="toc-text">Zero-Shot Medical Phrase Grounding with Off-the-shelf Diffusion Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Robust-CLIP-Based-Detector-for-Exposing-Diffusion-Model-Generated-Images"><span class="toc-text">Robust CLIP-Based Detector for Exposing Diffusion Model-Generated Images</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Training-and-prompt-free-General-Painterly-Harmonization-Using-Image-wise-Attention-Sharing"><span class="toc-text">Training-and-prompt-free General Painterly Harmonization Using Image-wise Attention Sharing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Detecting-Out-Of-Distribution-Earth-Observation-Images-with-Diffusion-Models"><span class="toc-text">Detecting Out-Of-Distribution Earth Observation Images with Diffusion Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Learning-the-Domain-Specific-Inverse-NUFFT-for-Accelerated-Spiral-MRI-using-Diffusion-Models"><span class="toc-text">Learning the Domain Specific Inverse NUFFT for Accelerated Spiral MRI using Diffusion Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AniClipart-Clipart-Animation-with-Text-to-Video-Priors"><span class="toc-text">AniClipart: Clipart Animation with Text-to-Video Priors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#StyleBooth-Image-Style-Editing-with-Multimodal-Instruction"><span class="toc-text">StyleBooth: Image Style Editing with Multimodal Instruction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#IntrinsicAnything-Learning-Diffusion-Priors-for-Inverse-Rendering-Under-Unknown-Illumination"><span class="toc-text">IntrinsicAnything: Learning Diffusion Priors for Inverse Rendering Under Unknown Illumination</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MoA-Mixture-of-Attention-for-Subject-Context-Disentanglement-in-Personalized-Image-Generation"><span class="toc-text">MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image:url('https://pic1.zhimg.com/v2-0aba7591bd6a8a973210ed734d1006c9.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>æ¡†æ¶</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="ç®€ç¹è½¬æ¢">ç°¡</button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const e of document.querySelectorAll('script[type^="math/tex"]')){const a=!!e.type.match(/; *mode=display/),n=new t.options.MathItem(e.textContent,t.inputJax[0],a),s=document.createTextNode("");e.parentNode.replaceChild(s,e),n.start={node:s,delim:"",n:0},n.end={node:s,delim:"",n:0},t.math.push(n)}},""]}}};const t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t)}</script></div><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("å·²æŒ‚è½½butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/25/Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="2024/01/25/Paper/3DGS Survey/" alt="">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting ä»Šå¤©æƒ³ä»‹ç»çš„æ˜¯`ZJU`å¸¦æ¥çš„`3DGS`çš„é¦–ç¯‡ç»¼è¿°`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="2024/01/25/Paper/3DGS Survey/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">CUDAç¼–ç¨‹å­¦ä¹ ï¼šè‡ªå®šä¹‰Pytorch+cpp/cuda extension</a><div class="blog-slider__text">è™½ç„¶è¯´PyTorchæä¾›äº†ä¸°å¯Œçš„ä¸ç¥ç»ç½‘ç»œã€å¼ é‡ä»£æ•°ã€æ•°æ®å¤„ç†ç­‰ç›¸å…³çš„æ“ä½œï¼Œä½†æ˜¯æœ‰æ—¶å€™ä½ å¯èƒ½éœ€è¦**æ›´å®šåˆ¶åŒ–çš„æ“ä½œ**ï¼Œæ¯”å¦‚ä½¿ç”¨è®ºæ–‡ä¸­çš„æ–°å‹æ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…å®ç°ä½œä¸ºç ”ç©¶ä¸€éƒ¨åˆ†å¼€å‘çš„æ“ä½œã€‚åœ¨PyTorchä¸­ï¼Œæœ€ç®€å•çš„é›†æˆè‡ªå®šä¹‰æ“ä½œçš„æ–¹å¼æ˜¯åœ¨Pythonä¸­ç¼–å†™ï¼Œé€šè¿‡æ‰©å±•Functionå’ŒModuleæ¥å®ç°ï¼Œ</div><a class="blog-slider__button" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesisï¼Œ è¿™ä»½èµ„æºåº“æ•´ç†äº†ä¸ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)å’Œç¥ç»è¾å°„åœº(NeRF)ç›¸å…³çš„è®ºæ–‡ã€ä»£ç å’Œèµ„æº,é‡ç‚¹å…³æ³¨åŸºäºå›¾åƒå’ŒéŸ³é¢‘çš„è™šæ‹Ÿè®²è¯å¤´åˆæˆè®ºæ–‡åŠå·²å‘å¸ƒä»£ç ã€‚å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªä»“åº“æœ‰ç”¨,è¯·starâ­æ”¯æŒ!</div><a class="blog-slider__button" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/17/Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023/12/17/Project/ChatPaperFree/" alt="">ChatPaperFree GeminiProï¼ˆä¸€åˆ†é’Ÿè¯»è®ºæ–‡ï¼‰</a><div class="blog-slider__text">ChatPaperFreeæ˜¯ä¸€ä¸ªåŸºäºChatGPTçš„è‡ªåŠ¨è®ºæ–‡æ‘˜è¦ç”Ÿæˆå™¨ï¼Œåœ¨ChatPaperçš„åŸºç¡€ä¸Šè¿›è¡Œçš„æ›´æ–°ï¼Œé‡‡ç”¨äº†æœ€è¿‘ç”±Googleå¼€æºçš„Gemini Proå¤§æ¨¡å‹ã€‚ç›®å‰,æˆ‘ä»¬èƒ½å¤Ÿå¯¹ç”¨æˆ·è¾“å…¥çš„è®ºæ–‡è¿›è¡Œè‡ªåŠ¨æ€»ç»“ã€‚æœªæ¥,æˆ‘è¿˜è®¡åˆ’åŠ å…¥å¯¹è®ºæ–‡å›¾ç‰‡/è¡¨æ ¼/å…¬å¼çš„è¯†åˆ« extraction,ä»è€Œç”Ÿæˆæ›´å…¨é¢è€Œæ˜“è¯»çš„æ€»ç»“ã€‚</div><a class="blog-slider__button" href="2023/12/17/Project/ChatPaperFree/" alt="">è¯¦æƒ…   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script></body></html>