<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动” | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。"><meta property="og:type" content="article"><meta property="og:title" content="数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”"><meta property="og:url" content="https://kedreamix.github.io/2024/01/20/Project/Linly-Talker/index.html"><meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World"><meta property="og:description" content="Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png"><meta property="article:published_time" content="2024-01-19T16:00:00.000Z"><meta property="article:modified_time" content="2024-02-04T10:35:10.909Z"><meta property="article:author" content="Kedreamix"><meta property="article:tag" content="Talking Head Generation"><meta property="article:tag" content="LLM"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/2024/01/20/Project/Linly-Talker/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-74LZ5BEQQ1")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!0,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},noticeOutdate:{limitDay:500,position:"top",messagePrev:"It has been",messageNext:"days since the last update, the content of the article may be outdated."},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!0,post:!0},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!0,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-02-04 18:35:10"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme"),o=(new Date).getHours();void 0===t?o<=6||o>=24?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode();const a=saveToLocal.get("aside-status");void 0!==a&&("hide"===a?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 7.0.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml"></head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",(()=>{o()}))})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">145</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-01-19T16:00:00.000Z" title="发表于 2024-01-20 00:00:00">2024-01-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-04T10:35:10.909Z" title="更新于 2024-02-04 18:35:10">2024-02-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Project/">Project</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><strong>2023.12 更新</strong> 📆</p><p><strong>用户可以上传任意图片进行对话</strong></p><p><strong>2024.01 更新</strong> 📆</p><ul><li><strong>令人兴奋的消息！我现在已经将强大的GeminiPro和Qwen大模型融入到我们的对话场景中。用户现在可以在对话中上传任何图片，为我们的互动增添了全新的层面。</strong></li><li><strong>更新了FastAPI的部署调用方法。</strong></li><li><strong>更新了微软TTS的高级设置选项，增加声音种类的多样性，以及加入视频字幕加强可视化。</strong></li><li><strong>更新了GPT多轮对话系统，使得对话有上下文联系，提高数字人的交互性和真实感</strong></li></ul><p><strong>2024.02 更新</strong> 📆</p><ul><li><strong>更新了Gradio的版本为最新版本4.16.0，使得界面拥有更多的功能，比如可以摄像头拍摄图片构建数字人等</strong></li><li><strong>更新了ASR和THG，其中ASR加入了阿里的FunASR，具体更快的速度；THG部分加入了Wav2Lip模型，ER-NeRF在准备中(Comming Soon)</strong></li></ul><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-b38722d9d71153dec12acbb9e020a5b4.png" alt="The system architecture of multimodal human–computer interaction."></p><h2 id="TO-TO-DO-LIST"><a href="#TO-TO-DO-LIST" class="headerlink" title="TO## TO DO LIST"></a>TO## TO DO LIST</h2><ul><li>[x] 基本完成对话系统流程，能够<code>语音对话</code></li><li>[x] 加入了LLM大模型，包括<code>Linly</code>，<code>Qwen</code>和<code>GeminiPro</code>的使用</li><li>[x] 可上传<code>任意数字人照片</code>进行对话</li><li>[x] Linly加入<code>FastAPI</code>调用方式</li><li>[x] 利用微软<code>TTS</code>加入高级选项，可设置对应人声以及音调等参数，增加声音的多样性</li><li>[x] 视频生成加入<code>字幕</code>，能够更好的进行可视化</li><li>[x] GPT<code>多轮对话</code>系统（提高数字人的交互性和真实感，增强数字人的智能）</li><li>[x] 优化Gradio界面，加入更多模型，如Wav2Lip，FunASR等</li><li>[ ] <code>语音克隆</code>技术（语音克隆合成自己声音，提高数字人分身的真实感和互动体验）</li><li>[ ] 加入<code>Langchain</code>的框架，建立本地知识库</li><li>[ ] <code>实时</code>语音识别（人与数字人之间就可以通过语音进行对话交流)</li></ul><p>🔆 该项目 Linly-Talker 正在进行中 - 欢迎提出PR请求！如果您有任何关于新的模型方法、研究、技术或发现运行错误的建议，请随时编辑并提交 PR。您也可以打开一个问题或通过电子邮件直接联系我。📩⭐ 如果您发现这个Github Project有用，请给它点个星！🤩</p><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><div class="table-container"><table><thead><tr><th style="text-align:center">文字/语音对话</th><th style="text-align:center">数字人回答</th></tr></thead><tbody><tr><td style="text-align:center">应对压力最有效的方法是什么？</td><td style="text-align:center"><video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/f1deb189-b682-4175-9dea-7eeb0fb392ca"></video></td></tr><tr><td style="text-align:center">如何进行时间管理？</td><td style="text-align:center"><video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/968b5c43-4dce-484b-b6c6-0fd4d621ac03"></video></td></tr><tr><td style="text-align:center">撰写一篇交响乐音乐会评论，讨论乐团的表演和观众的整体体验。</td><td style="text-align:center"><video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/f052820f-6511-4cf0-a383-daf8402630db"></video></td></tr><tr><td style="text-align:center">翻译成中文：Luck is a dividend of sweat. The more you sweat, the luckier you get.</td><td style="text-align:center"><video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/118eec13-a9f7-4c38-b4ad-044d36ba9776"></video></td></tr></tbody></table></div><h2 id="创建环境"><a href="#创建环境" class="headerlink" title="创建环境"></a>创建环境</h2><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">conda create -n linly python=3.9 </span><br><span class="line">conda activate linly</span><br><span class="line"></span><br><span class="line"><span class="comment"># pytorch安装方式1：conda安装（推荐）</span></span><br><span class="line">conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch</span><br><span class="line"></span><br><span class="line"><span class="comment"># pytorch安装方式2：pip 安装</span></span><br><span class="line">pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113</span><br><span class="line"></span><br><span class="line">conda install -q ffmpeg <span class="comment"># ffmpeg==4.2.2</span></span><br><span class="line"></span><br><span class="line">pip install -r requirements_app.txt</span><br></pre></td></tr></tbody></table></figure><p>为了大家的部署使用方便，更新了一个<code>configs.py</code>文件，可以对其进行一些超参数修改即可</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设备运行端口 (Device running port)</span></span><br><span class="line">port = 7870</span><br><span class="line"><span class="comment"># api运行端口及IP (API running port and IP)</span></span><br><span class="line">ip = <span class="string">'127.0.0.1'</span> </span><br><span class="line">api_port = 7871</span><br><span class="line"><span class="comment"># Linly模型路径 (Linly model path)</span></span><br><span class="line">mode = <span class="string">'api'</span> <span class="comment"># api 需要先运行Linly-api-fast.py</span></span><br><span class="line">mode = <span class="string">'offline'</span></span><br><span class="line">model_path = <span class="string">'Linly-AI/Chinese-LLaMA-2-7B-hf'</span></span><br><span class="line"><span class="comment"># ssl证书 (SSL certificate) 麦克风对话需要此参数</span></span><br><span class="line">ssl_certfile = <span class="string">"/path/to/Linly-Talker/https_cert/cert.pem"</span></span><br><span class="line">ssl_keyfile = <span class="string">"/path/to/Linly-Talker/https_cert/key.pem"</span></span><br></pre></td></tr></tbody></table></figure><h2 id="ASR-Speech-Recognition"><a href="#ASR-Speech-Recognition" class="headerlink" title="ASR - Speech Recognition"></a>ASR - Speech Recognition</h2><h3 id="Whisper"><a href="#Whisper" class="headerlink" title="Whisper"></a>Whisper</h3><p>借鉴OpenAI的Whisper实现了ASR的语音识别，具体使用方法参考 <a target="_blank" rel="noopener" href="https://github.com/openai/whisper">https://github.com/openai/whisper</a></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">https://github.com/openai/whisper</span></span><br><span class="line"><span class="string">pip install -U openai-whisper</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> whisper</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WhisperASR</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_path</span>):</span><br><span class="line">        self.LANGUAGES = {</span><br><span class="line">            <span class="string">"en"</span>: <span class="string">"english"</span>,</span><br><span class="line">            <span class="string">"zh"</span>: <span class="string">"chinese"</span>,</span><br><span class="line">        }</span><br><span class="line">        self.model = whisper.load_model(model_path)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transcribe</span>(<span class="params">self, audio_file</span>):</span><br><span class="line">        result = self.model.transcribe(audio_file)</span><br><span class="line">        <span class="keyword">return</span> result[<span class="string">"text"</span>]</span><br></pre></td></tr></tbody></table></figure><h3 id="FunASR"><a href="#FunASR" class="headerlink" title="FunASR"></a>FunASR</h3><p>阿里的<code>FunASR</code>的语音识别效果也是相当不错，而且时间也是比whisper更快的，更能达到实时的效果，所以也将FunASR添加进去了，在ASR文件夹下的FunASR文件里可以进行体验，需要注意的是，在第一次运行的时候，需要安装以下库，参考 <a target="_blank" rel="noopener" href="https://github.com/alibaba-damo-academy/FunASR">https://github.com/alibaba-damo-academy/FunASR</a></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install funasr</span><br><span class="line">pip install modelscope</span><br><span class="line">pip install -U rotary_embedding_torch</span><br></pre></td></tr></tbody></table></figure><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Reference: https://github.com/alibaba-damo-academy/FunASR</span></span><br><span class="line"><span class="string">pip install funasr</span></span><br><span class="line"><span class="string">pip install modelscope</span></span><br><span class="line"><span class="string">pip install -U rotary_embedding_torch</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"如果想使用FunASR，请先安装funasr，若使用Whisper，请忽略此条信息"</span>)   </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FunASR</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.model = AutoModel(model=<span class="string">"paraformer-zh"</span>, model_revision=<span class="string">"v2.0.4"</span>,</span><br><span class="line">                vad_model=<span class="string">"fsmn-vad"</span>, vad_model_revision=<span class="string">"v2.0.4"</span>,</span><br><span class="line">                punc_model=<span class="string">"ct-punc-c"</span>, punc_model_revision=<span class="string">"v2.0.4"</span>,</span><br><span class="line">                <span class="comment"># spk_model="cam++", spk_model_revision="v2.0.2",</span></span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transcribe</span>(<span class="params">self, audio_file</span>):</span><br><span class="line">        res = self.model.generate(<span class="built_in">input</span>=audio_file, </span><br><span class="line">            batch_size_s=<span class="number">300</span>)</span><br><span class="line">        <span class="built_in">print</span>(res)</span><br><span class="line">        <span class="keyword">return</span> res[<span class="number">0</span>][<span class="string">'text'</span>]</span><br></pre></td></tr></tbody></table></figure><h2 id="TTS-Edge-TTS"><a href="#TTS-Edge-TTS" class="headerlink" title="TTS - Edge TTS"></a>TTS - Edge TTS</h2><p>使用微软语音服务,具体使用方法参考<a target="_blank" rel="noopener" href="https://github.com/rany2/edge-tts">https://github.com/rany2/edge-tts</a></p><p>我编写了一个 <code>EdgeTTS</code> 的类，能够更好的使用，并且增加了保存字幕文件的功能</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EdgeTTS</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, list_voices = <span class="literal">False</span>, proxy = <span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        voices = list_voices_fn(proxy=proxy)</span><br><span class="line">        self.SUPPORTED_VOICE = [item[<span class="string">'ShortName'</span>] <span class="keyword">for</span> item <span class="keyword">in</span> voices]</span><br><span class="line">        self.SUPPORTED_VOICE.sort(reverse=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> list_voices:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">", "</span>.join(self.SUPPORTED_VOICE))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">self, rate, volume, pitch</span>):</span><br><span class="line">        <span class="keyword">if</span> rate &gt;= <span class="number">0</span>:</span><br><span class="line">            rate = <span class="string">f'+<span class="subst">{rate}</span>%'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            rate = <span class="string">f'<span class="subst">{rate}</span>%'</span></span><br><span class="line">        <span class="keyword">if</span> pitch &gt;= <span class="number">0</span>:</span><br><span class="line">            pitch = <span class="string">f'+<span class="subst">{pitch}</span>Hz'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pitch = <span class="string">f'<span class="subst">{pitch}</span>Hz'</span></span><br><span class="line">        volume = <span class="number">100</span> - volume</span><br><span class="line">        volume = <span class="string">f'-<span class="subst">{volume}</span>%'</span></span><br><span class="line">        <span class="keyword">return</span> rate, volume, pitch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,TEXT, VOICE, RATE, VOLUME, PITCH, OUTPUT_FILE=<span class="string">'result.wav'</span>, OUTPUT_SUBS=<span class="string">'result.vtt'</span>, words_in_cue = <span class="number">8</span></span>):</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">amain</span>() -&gt; <span class="literal">None</span>:</span><br><span class="line">            <span class="string">"""Main function"""</span></span><br><span class="line">            rate, volume, pitch = self.preprocess(rate = RATE, volume = VOLUME, pitch = PITCH)</span><br><span class="line">            communicate = Communicate(TEXT, VOICE, rate = rate, volume = volume, pitch = pitch)</span><br><span class="line">            subs: SubMaker = SubMaker()</span><br><span class="line">            sub_file: <span class="type">Union</span>[TextIOWrapper, TextIO] = (</span><br><span class="line">                <span class="built_in">open</span>(OUTPUT_SUBS, <span class="string">"w"</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> communicate.stream():</span><br><span class="line">                <span class="keyword">if</span> chunk[<span class="string">"type"</span>] == <span class="string">"audio"</span>:</span><br><span class="line">                    <span class="comment"># audio_file.write(chunk["data"])</span></span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">                <span class="keyword">elif</span> chunk[<span class="string">"type"</span>] == <span class="string">"WordBoundary"</span>:</span><br><span class="line">                    <span class="comment"># print((chunk["offset"], chunk["duration"]), chunk["text"])</span></span><br><span class="line">                    subs.create_sub((chunk[<span class="string">"offset"</span>], chunk[<span class="string">"duration"</span>]), chunk[<span class="string">"text"</span>])</span><br><span class="line">            sub_file.write(subs.generate_subs(words_in_cue))</span><br><span class="line">            <span class="keyword">await</span> communicate.save(OUTPUT_FILE)</span><br><span class="line">            </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># loop = asyncio.get_event_loop_policy().get_event_loop()</span></span><br><span class="line">        <span class="comment"># try:</span></span><br><span class="line">        <span class="comment">#     loop.run_until_complete(amain())</span></span><br><span class="line">        <span class="comment"># finally:</span></span><br><span class="line">        <span class="comment">#     loop.close()</span></span><br><span class="line">        asyncio.run(amain())</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(OUTPUT_SUBS, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> file:</span><br><span class="line">            vtt_lines = file.readlines()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 去掉每一行文字中的空格</span></span><br><span class="line">        vtt_lines_without_spaces = [line.replace(<span class="string">" "</span>, <span class="string">""</span>) <span class="keyword">if</span> <span class="string">"--&gt;"</span> <span class="keyword">not</span> <span class="keyword">in</span> line <span class="keyword">else</span> line <span class="keyword">for</span> line <span class="keyword">in</span> vtt_lines]</span><br><span class="line">        <span class="comment"># print(vtt_lines_without_spaces)</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(OUTPUT_SUBS, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> output_file:</span><br><span class="line">            output_file.writelines(vtt_lines_without_spaces)</span><br><span class="line">        <span class="keyword">return</span> OUTPUT_FILE, OUTPUT_SUBS</span><br></pre></td></tr></tbody></table></figure><p>同时在<code>src</code>文件夹下，写了一个简易的<code>WebUI</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python TTS_app.py</span><br></pre></td></tr></tbody></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-570f3c9a069358e4d4a7b7c008e99cb7.png" alt="TTS"></p><h2 id="THG-Avatar"><a href="#THG-Avatar" class="headerlink" title="THG - Avatar"></a>THG - Avatar</h2><h3 id="SadTalker"><a href="#SadTalker" class="headerlink" title="SadTalker"></a>SadTalker</h3><p>数字人生成可使用SadTalker（CVPR 2023）,详情介绍见 <a target="_blank" rel="noopener" href="https://sadtalker.github.io">https://sadtalker.github.io</a></p><p>在使用前先下载SadTalker模型:</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash scripts/sadtalker_download_models.sh  </span><br></pre></td></tr></tbody></table></figure><p><a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1eF13O-8wyw4B3MtesctQyg?pwd=linl">Baidu (百度云盘)</a> (Password: <code>linl</code>)</p><blockquote><p>如果百度网盘下载，记住是放在checkpoints文件夹下，百度网盘下载的默认命名为sadtalker，实际应该重命名为checkpoints</p></blockquote><h3 id="Wav2Lip"><a href="#Wav2Lip" class="headerlink" title="Wav2Lip"></a>Wav2Lip</h3><p>数字人生成还可使用Wav2Lip（ACM 2020），详情介绍见 <a target="_blank" rel="noopener" href="https://github.com/Rudrabha/Wav2Lip">https://github.com/Rudrabha/Wav2Lip</a></p><p>在使用前先下载Wav2Lip模型：</p><div class="table-container"><table><thead><tr><th>Model</th><th>Description</th><th>Link to the model</th></tr></thead><tbody><tr><td>Wav2Lip</td><td>Highly accurate lip-sync</td><td><a target="_blank" rel="noopener" href="https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW">Link</a></td></tr><tr><td>Wav2Lip + GAN</td><td>Slightly inferior lip-sync, but better visual quality</td><td><a target="_blank" rel="noopener" href="https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA?e=n9ljGW">Link</a></td></tr><tr><td>Expert Discriminator</td><td>Weights of the expert discriminator</td><td><a target="_blank" rel="noopener" href="https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQRvmiZg-HRAjvI6zqN9eTEBP74KefynCwPWVmF57l-AYA?e=ZRPHKP">Link</a></td></tr><tr><td>Visual Quality Discriminator</td><td>Weights of the visual disc trained in a GAN setup</td><td><a target="_blank" rel="noopener" href="https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQVqH88dTm1HjlK11eNba5gBbn15WMS0B0EZbDBttqrqkg?e=ic0ljo">Link</a></td></tr></tbody></table></div><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Wav2Lip</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path = <span class="string">'checkpoints/wav2lip.pth'</span></span>):</span><br><span class="line">        self.fps = <span class="number">25</span></span><br><span class="line">        self.resize_factor = <span class="number">1</span></span><br><span class="line">        self.mel_step_size = <span class="number">16</span></span><br><span class="line">        self.static = <span class="literal">False</span></span><br><span class="line">        self.img_size = <span class="number">96</span></span><br><span class="line">        self.face_det_batch_size = <span class="number">2</span></span><br><span class="line">        self.box = [-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>]</span><br><span class="line">        self.pads = [<span class="number">0</span>, <span class="number">10</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">        self.nosmooth = <span class="literal">False</span></span><br><span class="line">        self.device = <span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span></span><br><span class="line">        self.model = self.load_model(path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_model</span>(<span class="params">self, checkpoint_path</span>):</span><br><span class="line">        model = wav2lip_mdoel()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"Load checkpoint from: {}"</span>.<span class="built_in">format</span>(checkpoint_path))</span><br><span class="line">        <span class="keyword">if</span> self.device == <span class="string">'cuda'</span>:</span><br><span class="line">            checkpoint = torch.load(checkpoint_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            checkpoint = torch.load(checkpoint_path,</span><br><span class="line">                                    map_location=<span class="keyword">lambda</span> storage, loc: storage)</span><br><span class="line">        s = checkpoint[<span class="string">"state_dict"</span>]</span><br><span class="line">        new_s = {}</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> s.items():</span><br><span class="line">            new_s[k.replace(<span class="string">'module.'</span>, <span class="string">''</span>)] = v</span><br><span class="line">        model.load_state_dict(new_s)</span><br><span class="line"></span><br><span class="line">        model = model.to(self.device)</span><br><span class="line">        <span class="keyword">return</span> model.<span class="built_in">eval</span>()</span><br></pre></td></tr></tbody></table></figure><h3 id="ER-NeRF（Comming-Soon）"><a href="#ER-NeRF（Comming-Soon）" class="headerlink" title="ER-NeRF（Comming Soon）"></a>ER-NeRF（Comming Soon）</h3><p>ER-NeRF（ICCV2023）是使用最新的NeRF技术构建的数字人，拥有定制数字人的特性，只需要一个人的五分钟左右到视频即可重建出来，具体可参考 <a target="_blank" rel="noopener" href="https://github.com/Fictionarry/ER-NeRF">https://github.com/Fictionarry/ER-NeRF</a></p><p>后续会针对此更新</p><h2 id="LLM-Conversation"><a href="#LLM-Conversation" class="headerlink" title="LLM - Conversation"></a>LLM - Conversation</h2><h3 id="Linly-AI"><a href="#Linly-AI" class="headerlink" title="Linly-AI"></a>Linly-AI</h3><p>Linly来自深圳大学数据工程国家重点实验室,参考<a target="_blank" rel="noopener" href="https://github.com/CVI-SZU/Linly">https://github.com/CVI-SZU/Linly</a></p><p>下载Linly模型:<a target="_blank" rel="noopener" href="https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf">https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf</a></p><p>可以使用<code>git</code>下载</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git lfs install</span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf</span><br></pre></td></tr></tbody></table></figure><p>或者使用<code>huggingface</code>的下载工具<code>huggingface-cli</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置镜像加速</span></span><br><span class="line"><span class="comment"># Linux</span></span><br><span class="line"><span class="built_in">export</span> HF_ENDPOINT=<span class="string">"https://hf-mirror.com"</span></span><br><span class="line"><span class="comment"># windows powershell</span></span><br><span class="line"><span class="variable">$env</span>:HF_ENDPOINT=<span class="string">"https://hf-mirror.com"</span></span><br><span class="line"></span><br><span class="line">huggingface-cli download --resume-download Linly-AI/Chinese-LLaMA-2-7B-hf --local-dir Linly-AI/Chinese-LLaMA-2-7B-hf</span><br></pre></td></tr></tbody></table></figure><p>或使用API:</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令行</span></span><br><span class="line">curl -X POST -H <span class="string">"Content-Type: application/json"</span> -d <span class="string">'{"question": "北京有什么好玩的地方?"}'</span> http://url:port  </span><br><span class="line"></span><br><span class="line"><span class="comment"># Python</span></span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://url:port"</span></span><br><span class="line">headers = {</span><br><span class="line">  <span class="string">"Content-Type"</span>: <span class="string">"application/json"</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">data = {</span><br><span class="line">  <span class="string">"question"</span>: <span class="string">"北京有什么好玩的地方?"</span> </span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">response = requests.post(url, headers=headers, json=data)</span><br><span class="line"><span class="comment"># response_text = response.content.decode("utf-8")</span></span><br><span class="line">answer, tag = response.json()</span><br><span class="line"><span class="comment"># print(answer)</span></span><br><span class="line"><span class="keyword">if</span> tag == <span class="string">'success'</span>:</span><br><span class="line">    response_text =  answer[0]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"fail"</span>)</span><br><span class="line"><span class="built_in">print</span>(response_text)</span><br></pre></td></tr></tbody></table></figure><p>API部署推荐<strong>FastAPI</strong>，现在更新了 FastAPI 的API使用版本，FastAPI 是一个高性能、易用且现代的Python Web 框架，它通过使用最新的Python 特性和异步编程，提供了快速开发Web API 的能力。 该框架不仅易于学习和使用，还具有自动生成文档、数据验证等强大功能。 无论是构建小型项目还是大型应用程序，FastAPI 都是一个强大而有效的工具。</p><p>首先安装部署API所使用的库</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install fastapi==0.104.1</span><br><span class="line">pip install uvicorn==0.24.0.post1</span><br></pre></td></tr></tbody></table></figure><p>其他使用方法大致相同，主要是不同代码实现方式，会更加简单边界，并且处理并发也会更好</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM, GenerationConfig</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> configs <span class="keyword">import</span> model_path, api_port</span><br><span class="line"><span class="comment"># 设置设备参数</span></span><br><span class="line">DEVICE = <span class="string">"cuda"</span>  <span class="comment"># 使用CUDA</span></span><br><span class="line">DEVICE_ID = <span class="string">"0"</span>  <span class="comment"># CUDA设备ID，如果未设置则为空</span></span><br><span class="line">CUDA_DEVICE = <span class="string">f"<span class="subst">{DEVICE}</span>:<span class="subst">{DEVICE_ID}</span>"</span> <span class="keyword">if</span> DEVICE_ID <span class="keyword">else</span> DEVICE  <span class="comment"># 组合CUDA设备信息</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清理GPU内存函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">torch_gc</span>():</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():  <span class="comment"># 检查是否可用CUDA</span></span><br><span class="line">        <span class="keyword">with</span> torch.cuda.device(CUDA_DEVICE):  <span class="comment"># 指定CUDA设备</span></span><br><span class="line">            torch.cuda.empty_cache()  <span class="comment"># 清空CUDA缓存</span></span><br><span class="line">            torch.cuda.ipc_collect()  <span class="comment"># 收集CUDA内存碎片</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建FastAPI应用</span></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理POST请求的端点</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">"/"</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_item</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="keyword">global</span> model, tokenizer  <span class="comment"># 声明全局变量以便在函数内部使用模型和分词器</span></span><br><span class="line">    json_post_raw = <span class="keyword">await</span> request.json()  <span class="comment"># 获取POST请求的JSON数据</span></span><br><span class="line">    json_post = json.dumps(json_post_raw)  <span class="comment"># 将JSON数据转换为字符串</span></span><br><span class="line">    json_post_list = json.loads(json_post)  <span class="comment"># 将字符串转换为Python对象</span></span><br><span class="line">    prompt = json_post_list.get(<span class="string">'prompt'</span>)  <span class="comment"># 获取请求中的提示</span></span><br><span class="line">    history = json_post_list.get(<span class="string">'history'</span>)  <span class="comment"># 获取请求中的历史记录</span></span><br><span class="line">    max_length = json_post_list.get(<span class="string">'max_length'</span>)  <span class="comment"># 获取请求中的最大长度</span></span><br><span class="line">    top_p = json_post_list.get(<span class="string">'top_p'</span>)  <span class="comment"># 获取请求中的top_p参数</span></span><br><span class="line">    temperature = json_post_list.get(<span class="string">'temperature'</span>)  <span class="comment"># 获取请求中的温度参数</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 调用模型进行对话生成</span></span><br><span class="line">    prompt = <span class="string">f"请用少于25个字回答以下问题 ### Instruction:<span class="subst">{prompt}</span>  ### Response:"</span></span><br><span class="line">    inputs = tokenizer(prompt, return_tensors=<span class="string">"pt"</span>).to(<span class="string">"cuda:0"</span>)</span><br><span class="line">    generate_ids = model.generate(inputs.input_ids, </span><br><span class="line">                                  max_new_tokens=max_length <span class="keyword">if</span> max_length <span class="keyword">else</span> <span class="number">2048</span>,</span><br><span class="line">                                  do_sample=<span class="literal">True</span>, </span><br><span class="line">                                  top_k=<span class="number">20</span>,</span><br><span class="line">                                  top_p=top_p,</span><br><span class="line">                                  temperature=temperature <span class="keyword">if</span> temperature <span class="keyword">else</span> <span class="number">0.84</span>,</span><br><span class="line">                                  repetition_penalty=<span class="number">1.15</span>, eos_token_id=<span class="number">2</span>, bos_token_id=<span class="number">1</span>,pad_token_id=<span class="number">0</span>)</span><br><span class="line">    response = tokenizer.batch_decode(generate_ids, skip_special_tokens=<span class="literal">True</span>, clean_up_tokenization_spaces=<span class="literal">False</span>)[<span class="number">0</span>]</span><br><span class="line">    response = response.split(<span class="string">"### Response:"</span>)[-<span class="number">1</span>]</span><br><span class="line">    now = datetime.datetime.now()  <span class="comment"># 获取当前时间</span></span><br><span class="line">    time = now.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>)  <span class="comment"># 格式化时间为字符串</span></span><br><span class="line">    <span class="comment"># 构建响应JSON</span></span><br><span class="line">    answer = {</span><br><span class="line">        <span class="string">"response"</span>: response,</span><br><span class="line">        <span class="comment"># "history": history,</span></span><br><span class="line">        <span class="string">"status"</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">"time"</span>: time</span><br><span class="line">    }</span><br><span class="line">    <span class="comment"># 构建日志信息</span></span><br><span class="line">    log = <span class="string">"["</span> + time + <span class="string">"] "</span> + <span class="string">'", prompt:"'</span> + prompt + <span class="string">'", response:"'</span> + <span class="built_in">repr</span>(response) + <span class="string">'"'</span></span><br><span class="line">    <span class="built_in">print</span>(log)  <span class="comment"># 打印日志</span></span><br><span class="line">    torch_gc()  <span class="comment"># 执行GPU内存清理</span></span><br><span class="line">    <span class="keyword">return</span> answer  <span class="comment"># 返回响应</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 加载预训练的分词器和模型</span></span><br><span class="line">    model = AutoModelForCausalLM.from_pretrained(model_path, device_map=<span class="string">"cuda:0"</span>,</span><br><span class="line">                                                    torch_dtype=torch.bfloat16, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=<span class="literal">False</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># 设置模型为评估模式</span></span><br><span class="line">    <span class="comment"># 启动FastAPI应用</span></span><br><span class="line">    uvicorn.run(app, host=<span class="string">'0.0.0.0'</span>, port=api_port, workers=<span class="number">1</span>)  <span class="comment"># 在指定端口和主机上启动应用</span></span><br></pre></td></tr></tbody></table></figure><p>默认部署在 7871 端口，通过 POST 方法进行调用，可以使用curl调用，如下所示：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST <span class="string">"http://127.0.0.1:7871"</span> \</span><br><span class="line">     -H <span class="string">'Content-Type: application/json'</span> \</span><br><span class="line">     -d <span class="string">'{"prompt": "如何应对压力"}'</span></span><br></pre></td></tr></tbody></table></figure><p>也可以使用python中的requests库进行调用，如下所示：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_completion</span>(<span class="params">prompt</span>):</span><br><span class="line">    headers = {<span class="string">'Content-Type'</span>: <span class="string">'application/json'</span>}</span><br><span class="line">    data = {<span class="string">"prompt"</span>: prompt}</span><br><span class="line">    response = requests.post(url=<span class="string">'http://127.0.0.1:7871'</span>, headers=headers, data=json.dumps(data))</span><br><span class="line">    <span class="keyword">return</span> response.json()[<span class="string">'response'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="built_in">print</span>(get_completion(<span class="string">'你好如何应对压力'</span>))</span><br></pre></td></tr></tbody></table></figure><p>得到的返回值如下所示：</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">{</span><br><span class="line">  <span class="string">"response"</span>:<span class="string">"寻求支持和放松，并采取积极的措施解决问题。"</span>,</span><br><span class="line">  <span class="string">"status"</span>:200,</span><br><span class="line">  <span class="string">"time"</span>:<span class="string">"2024-01-12 01:43:37"</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3 id="Qwen"><a href="#Qwen" class="headerlink" title="Qwen"></a>Qwen</h3><p>来自阿里云的Qwen，查看 <a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen">https://github.com/QwenLM/Qwen</a></p><p>下载 Qwen 模型: <a target="_blank" rel="noopener" href="https://huggingface.co/Qwen/Qwen-1_8B-Chat">https://huggingface.co/Qwen/Qwen-1_8B-Chat</a></p><p>可以使用<code>git</code>下载</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git lfs install</span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/Qwen/Qwen-1_8B-Chat</span><br></pre></td></tr></tbody></table></figure><p>或者使用<code>huggingface</code>的下载工具<code>huggingface-cli</code></p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置镜像加速</span></span><br><span class="line"><span class="comment"># Linux</span></span><br><span class="line"><span class="built_in">export</span> HF_ENDPOINT=<span class="string">"https://hf-mirror.com"</span></span><br><span class="line"><span class="comment"># windows powershell</span></span><br><span class="line"><span class="variable">$env</span>:HF_ENDPOINT=<span class="string">"https://hf-mirror.com"</span></span><br><span class="line"></span><br><span class="line">huggingface-cli download --resume-download Qwen/Qwen-1_8B-Chat --local-dir Qwen/Qwen-1_8B-Chat</span><br></pre></td></tr></tbody></table></figure><h3 id="Gemini-Pro"><a href="#Gemini-Pro" class="headerlink" title="Gemini-Pro"></a>Gemini-Pro</h3><p>来自 Google 的 Gemini-Pro，了解更多请访问 <a target="_blank" rel="noopener" href="https://deepmind.google/technologies/gemini/">https://deepmind.google/technologies/gemini/</a></p><p>请求 API 密钥: <a target="_blank" rel="noopener" href="https://makersuite.google.com/">https://makersuite.google.com/</a></p><h3 id="LLM-模型选择"><a href="#LLM-模型选择" class="headerlink" title="LLM 模型选择"></a>LLM 模型选择</h3><p>在 app.py 文件中，轻松选择您需要的模型。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 取消注释并设置您选择的模型:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># llm = Gemini(model_path='gemini-pro', api_key=None, proxy_url=None) # 不要忘记加入您自己的 Google API 密钥</span></span><br><span class="line"><span class="comment"># llm = Qwen(mode='offline', model_path="Qwen/Qwen-1_8B-Chat")</span></span><br><span class="line"><span class="comment"># 自动下载</span></span><br><span class="line"><span class="comment"># llm = Linly(mode='offline', model_path="Linly-AI/Chinese-LLaMA-2-7B-hf")</span></span><br><span class="line"><span class="comment"># 手动下载到指定路径</span></span><br><span class="line">llm = Linly(mode=<span class="string">'offline'</span>, model_path=<span class="string">"Linly-AI/Chinese-LLaMA-2-7B-hf"</span>)</span><br></pre></td></tr></tbody></table></figure><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>一些优化:</p><ul><li>使用固定的输入人脸图像,提前提取特征,避免每次读取</li><li>移除不必要的库,缩短总时间</li><li>只保存最终视频输出,不保存中间结果,提高性能</li><li>使用OpenCV生成最终视频,比mimwrite更快</li></ul><h2 id="Gradio"><a href="#Gradio" class="headerlink" title="Gradio"></a>Gradio</h2><p>Gradio是一个Python库,提供了一种简单的方式将机器学习模型作为交互式Web应用程序来部署。</p><p>对Linly-Talker而言,使用Gradio有两个主要目的:</p><ol><li><p><strong>可视化与演示</strong>:Gradio为模型提供一个简单的Web GUI,上传图片和文本后可以直观地看到结果。这是展示系统能力的有效方式。</p></li><li><p><strong>用户交互</strong>:Gradio的GUI可以作为前端,允许用户与Linly-Talker进行交互对话。用户可以上传自己的图片并输入问题,实时获取回答。这提供了更自然的语音交互方式。</p></li></ol><p>具体来说,我们在app.py中创建了一个Gradio的Interface,接收图片和文本输入,调用函数生成回应视频,在GUI中显示出来。这样就实现了浏览器交互而不需要编写复杂的前端。</p><p>总之,Gradio为Linly-Talker提供了可视化和用户交互的接口,是展示系统功能和让最终用户使用系统的有效途径。</p><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>现在的启动一共有几种模式，可以选择特定的场景进行设置</p><p>第一种只有固定了人物问答，设置好了人物，省去了预处理时间</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python app.py</span><br></pre></td></tr></tbody></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/80/v2-fc37a5490a674e2194b88714d38f986e.png" alt=""></p><p>第二种是可以任意上传图片进行对话</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python app_img.py</span><br></pre></td></tr></tbody></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-7c863c3992beef67953d7ab378be99d9.png" alt=""></p><p>第三种是在第一种的基础上加入了大语言模型，加入了多轮的GPT对话</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python app_multi.py</span><br></pre></td></tr></tbody></table></figure><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-802165f64f307dd204b04b9725626cd7.png" alt=""></p><p>文件夹结构如下</p><p>权重部分可以从这下载：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1eF13O-8wyw4B3MtesctQyg?pwd=linl">Baidu (百度云盘)</a> (Password: <code>linl</code>)</p><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">Linly-Talker/ </span><br><span class="line">├── app.py</span><br><span class="line">├── app_img.py</span><br><span class="line">├── utils.py</span><br><span class="line">├── Linly-api.py</span><br><span class="line">├── Linly-api-fast.py</span><br><span class="line">├── Linly-example.ipynb</span><br><span class="line">├── README.md</span><br><span class="line">├── README_zh.md</span><br><span class="line">├── request-Linly-api.py</span><br><span class="line">├── requirements_app.txt</span><br><span class="line">├── scripts</span><br><span class="line">│   └── download_models.sh</span><br><span class="line">├──	src</span><br><span class="line">│&nbsp;&nbsp; ├── audio2exp_models</span><br><span class="line">│&nbsp;&nbsp; ├── audio2pose_models</span><br><span class="line">│&nbsp;&nbsp; ├── config</span><br><span class="line">│&nbsp;&nbsp; ├── cost_time.py</span><br><span class="line">│&nbsp;&nbsp; ├── face3d</span><br><span class="line">│&nbsp;&nbsp; ├── facerender</span><br><span class="line">│&nbsp;&nbsp; ├── generate_batch.py</span><br><span class="line">│&nbsp;&nbsp; ├── generate_facerender_batch.py</span><br><span class="line">│&nbsp;&nbsp; ├── Record.py</span><br><span class="line">│&nbsp;&nbsp; ├── test_audio2coeff.py</span><br><span class="line">│&nbsp;&nbsp; └── utils</span><br><span class="line">├── inputs</span><br><span class="line">│   ├── example.png</span><br><span class="line">│   └── first_frame_dir</span><br><span class="line">│       ├── example_landmarks.txt</span><br><span class="line">│       ├── example.mat</span><br><span class="line">│       └── example.png</span><br><span class="line">├── examples</span><br><span class="line">│   └── source_image</span><br><span class="line">│       ├── art_0.png</span><br><span class="line">│       ├── ......</span><br><span class="line">│       └── sad.png</span><br><span class="line">├── TFG</span><br><span class="line">│&nbsp;&nbsp; ├── __init__.py</span><br><span class="line">│&nbsp;  ├── Wav2Lip.py</span><br><span class="line">│&nbsp;&nbsp; └── SadTalker.py</span><br><span class="line">└── TTS</span><br><span class="line">│&nbsp;&nbsp; ├── __init__.py</span><br><span class="line">│&nbsp;  ├── EdgeTTS.py</span><br><span class="line">│&nbsp;  └── TTS_app.py</span><br><span class="line">├── ASR</span><br><span class="line">│&nbsp;&nbsp; ├── __init__.py</span><br><span class="line">│&nbsp;&nbsp; ├── FunASR.py</span><br><span class="line">│&nbsp;&nbsp; └── Whisper.py</span><br><span class="line">├── LLM</span><br><span class="line">│&nbsp;&nbsp; ├── __init__.py</span><br><span class="line">│&nbsp;&nbsp; ├── Gemini.py</span><br><span class="line">│&nbsp;&nbsp; ├── Linly.py</span><br><span class="line">│&nbsp;&nbsp; └── Qwen.py</span><br><span class="line">....... // 以下是需要下载的权重路径（可选）</span><br><span class="line">├── checkpoints // SadTalker 权重路径</span><br><span class="line">│   ├── mapping_00109-model.pth.tar</span><br><span class="line">│   ├── mapping_00229-model.pth.tar</span><br><span class="line">│   ├── SadTalker_V0.0.2_256.safetensors</span><br><span class="line">│   └── SadTalker_V0.0.2_512.safetensors</span><br><span class="line">│   ├── lipsync_expert.pth</span><br><span class="line">│   ├── visual_quality_disc.pth</span><br><span class="line">│   ├── wav2lip_gan.pth</span><br><span class="line">│   └── wav2lip.pth // Wav2Lip 权重陆军</span><br><span class="line">├── gfpgan // GFPGAN 权重路径</span><br><span class="line">│   └── weights</span><br><span class="line">│       ├── alignment_WFLW_4HG.pth</span><br><span class="line">│       └── detection_Resnet50_Final.pth</span><br><span class="line">├── Linly-AI // Linly 权重路径</span><br><span class="line">│   └── Chinese-LLaMA-2-7B-hf </span><br><span class="line">│       ├── config.json</span><br><span class="line">│       ├── generation_config.json</span><br><span class="line">│       ├── pytorch_model-00001-of-00002.bin</span><br><span class="line">│       ├── pytorch_model-00002-of-00002.bin</span><br><span class="line">│       ├── pytorch_model.bin.index.json</span><br><span class="line">│       ├── README.md</span><br><span class="line">│       ├── special_tokens_map.json</span><br><span class="line">│       ├── tokenizer_config.json</span><br><span class="line">│       └── tokenizer.model</span><br><span class="line">├── Qwen // Qwen 权重路径</span><br><span class="line">│   └── Qwen-1_8B-Chat</span><br><span class="line">│       ├── cache_autogptq_cuda_256.cpp</span><br><span class="line">│       ├── cache_autogptq_cuda_kernel_256.cu</span><br><span class="line">│       ├── config.json</span><br><span class="line">│       ├── configuration_qwen.py</span><br><span class="line">│       ├── cpp_kernels.py</span><br><span class="line">│       ├── examples</span><br><span class="line">│       │   └── react_prompt.md</span><br><span class="line">│       ├── generation_config.json</span><br><span class="line">│       ├── LICENSE</span><br><span class="line">│       ├── model-00001-of-00002.safetensors</span><br><span class="line">│       ├── model-00002-of-00002.safetensors</span><br><span class="line">│       ├── modeling_qwen.py</span><br><span class="line">│       ├── model.safetensors.index.json</span><br><span class="line">│       ├── NOTICE</span><br><span class="line">│       ├── qwen_generation_utils.py</span><br><span class="line">│       ├── qwen.tiktoken</span><br><span class="line">│       ├── README.md</span><br><span class="line">│       ├── tokenization_qwen.py</span><br><span class="line">│       └── tokenizer_config.json</span><br></pre></td></tr></tbody></table></figure><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li><a target="_blank" rel="noopener" href="https://github.com/openai/whisper">https://github.com/openai/whisper</a></li><li><a target="_blank" rel="noopener" href="https://github.com/rany2/edge-tts">https://github.com/rany2/edge-tts</a></li><li><a target="_blank" rel="noopener" href="https://github.com/CVI-SZU/Linly">https://github.com/CVI-SZU/Linly</a></li><li><a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen">https://github.com/QwenLM/Qwen</a></li><li><a target="_blank" rel="noopener" href="https://deepmind.google/technologies/gemini/">https://deepmind.google/technologies/gemini/</a></li><li><a target="_blank" rel="noopener" href="https://github.com/OpenTalker/SadTalker">https://github.com/OpenTalker/SadTalker</a></li></ul><h2 id="Star-History"><a href="#Star-History" class="headerlink" title="Star History"></a>Star History</h2><p><a target="_blank" rel="noopener" href="https://star-history.com/#Kedreamix/Linly-Talker&amp;Date"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://api.star-history.com/svg?repos=Kedreamix/Linly-Talker&amp;type=Date" alt="Star History Chart"></a></p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io/2024/01/20/Project/Linly-Talker/">https://kedreamix.github.io/2024/01/20/Project/Linly-Talker/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Talking-Head-Generation/">Talking Head Generation</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a></div><div class="post_share"><div class="social-share" data-image="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/01/20/Project/Linly-Talker%20-%20GPT-SoVITS/" title="数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</div></div></a></div><div class="next-post pull-right"><a href="/2024/01/19/Note/fastapi/" title="FastAPI 快速教程: 从零开始构建你的第一个API项目"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-f7dc5c12cb693d83a113359819a1f26e_720w.png?source=d16d100b" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">FastAPI 快速教程: 从零开始构建你的第一个API项目</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/01/20/Project/Linly-Talker%20-%20GPT-SoVITS/" title="数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</div></div></a></div><div><a href="/2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" title="超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-01</div><div class="title">超赞的数字人生成知识库 Awesome-Talking-Head-Synthesis</div></div></a></div><div><a href="/2024/03/18/Project/SyncTalk/" title="SyncTalk实验笔记"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-3866dff2d07194c235eefab923f694c5.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-18</div><div class="title">SyncTalk实验笔记</div></div></a></div><div><a href="/2024/01/24/Paper/2024-01-24/Talking%20Head%20Generation/" title="Talking Head Generation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-b072ca131954e5aa54fae54f90858dae.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-24</div><div class="title">Talking Head Generation</div></div></a></div><div><a href="/2024/01/30/Paper/2024-01-30/Talking%20Head%20Generation/" title="Talking Head Generation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-55f96488825fc7af3820d32c3f4ac6ff.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">Talking Head Generation</div></div></a></div><div><a href="/2024/02/09/Paper/2024-02-09/Talking%20Head%20Generation/" title="Talking Head Generation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-6bacdbeff940a1345ff38f8b1dc2680f.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-09</div><div class="title">Talking Head Generation</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TO-TO-DO-LIST"><span class="toc-number">2.</span> <span class="toc-text">TO## TO DO LIST</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.</span> <span class="toc-text">示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E7%8E%AF%E5%A2%83"><span class="toc-number">4.</span> <span class="toc-text">创建环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ASR-Speech-Recognition"><span class="toc-number">5.</span> <span class="toc-text">ASR - Speech Recognition</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Whisper"><span class="toc-number">5.1.</span> <span class="toc-text">Whisper</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FunASR"><span class="toc-number">5.2.</span> <span class="toc-text">FunASR</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TTS-Edge-TTS"><span class="toc-number">6.</span> <span class="toc-text">TTS - Edge TTS</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#THG-Avatar"><span class="toc-number">7.</span> <span class="toc-text">THG - Avatar</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SadTalker"><span class="toc-number">7.1.</span> <span class="toc-text">SadTalker</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Wav2Lip"><span class="toc-number">7.2.</span> <span class="toc-text">Wav2Lip</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ER-NeRF%EF%BC%88Comming-Soon%EF%BC%89"><span class="toc-number">7.3.</span> <span class="toc-text">ER-NeRF（Comming Soon）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LLM-Conversation"><span class="toc-number">8.</span> <span class="toc-text">LLM - Conversation</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Linly-AI"><span class="toc-number">8.1.</span> <span class="toc-text">Linly-AI</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Qwen"><span class="toc-number">8.2.</span> <span class="toc-text">Qwen</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Gemini-Pro"><span class="toc-number">8.3.</span> <span class="toc-text">Gemini-Pro</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LLM-%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9"><span class="toc-number">8.4.</span> <span class="toc-text">LLM 模型选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E5%8C%96"><span class="toc-number">9.</span> <span class="toc-text">优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Gradio"><span class="toc-number">10.</span> <span class="toc-text">Gradio</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8"><span class="toc-number">11.</span> <span class="toc-text">启动</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">12.</span> <span class="toc-text">参考</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Star-History"><span class="toc-number">13.</span> <span class="toc-text">Star History</span></a></li></ol></div></div></div></div></main><footer id="footer" style="background-image:url('https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">簡</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"></div><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("已挂载butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/25/Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="2024/01/25/Paper/3DGS Survey/" alt="">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting 今天想介绍的是`ZJU`带来的`3DGS`的首篇综述`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="2024/01/25/Paper/3DGS Survey/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/12/CUDA/Pytorch+cppcuda extension 学习/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="2023/12/12/CUDA/Pytorch+cppcuda extension 学习/" alt="">CUDA编程学习：自定义Pytorch+cpp/cuda extension</a><div class="blog-slider__text">虽然说PyTorch提供了丰富的与神经网络、张量代数、数据处理等相关的操作，但是有时候你可能需要**更定制化的操作**，比如使用论文中的新型激活函数，或者实现作为研究一部分开发的操作。在PyTorch中，最简单的集成自定义操作的方式是在Python中编写，通过扩展Function和Module来实现，</div><a class="blog-slider__button" href="2023/12/12/CUDA/Pytorch+cppcuda extension 学习/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker/" alt="">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</a><div class="blog-slider__text">Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</a><div class="blog-slider__text">Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis， 这份资源库整理了与生成对抗网络(GAN)和神经辐射场(NeRF)相关的论文、代码和资源,重点关注基于图像和音频的虚拟讲话头合成论文及已发布代码。如果您觉得这个仓库有用,请star⭐支持!</div><a class="blog-slider__button" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/17/Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023/12/17/Project/ChatPaperFree/" alt="">ChatPaperFree GeminiPro（一分钟读论文）</a><div class="blog-slider__text">ChatPaperFree是一个基于ChatGPT的自动论文摘要生成器，在ChatPaper的基础上进行的更新，采用了最近由Google开源的Gemini Pro大模型。目前,我们能够对用户输入的论文进行自动总结。未来,我还计划加入对论文图片/表格/公式的识别 extraction,从而生成更全面而易读的总结。</div><a class="blog-slider__button" href="2023/12/17/Project/ChatPaperFree/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script></body></html>