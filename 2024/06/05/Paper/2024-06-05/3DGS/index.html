<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>3DGS | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-06-05  DDGS-CT Direction-Disentangled Gaussian Splatting for Realistic Volume   Rendering"><meta property="og:type" content="article"><meta property="og:title" content="3DGS"><meta property="og:url" content="https://kedreamix.github.io/2024/06/05/Paper/2024-06-05/3DGS/index.html"><meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World"><meta property="og:description" content="3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-06-05  DDGS-CT Direction-Disentangled Gaussian Splatting for Realistic Volume   Rendering"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://picx.zhimg.com/v2-2196bb11e15de7b5d3440823b4c92ca5.jpg"><meta property="article:published_time" content="2024-06-05T10:59:51.000Z"><meta property="article:modified_time" content="2024-06-05T10:59:51.809Z"><meta property="article:author" content="Kedreamix"><meta property="article:tag" content="3DGS"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://picx.zhimg.com/v2-2196bb11e15de7b5d3440823b4c92ca5.jpg"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/2024/06/05/Paper/2024-06-05/3DGS/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-74LZ5BEQQ1")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!0,languages:{hits_empty:"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}",hits_stats:"å…±æ‰¾åˆ° ${hits} ç¯‡æ–‡ç« "}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"ç¹",msgToSimplifiedChinese:"ç®€"},noticeOutdate:{limitDay:500,position:"top",messagePrev:"It has been",messageNext:"days since the last update, the content of the article may be outdated."},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"å¤åˆ¶æˆåŠŸ",error:"å¤åˆ¶é”™è¯¯",noSupport:"æµè§ˆå™¨ä¸æ”¯æŒ"},relativeDate:{homepage:!0,post:!0},runtime:"å¤©",dateSuffix:{just:"åˆšåˆš",min:"åˆ†é’Ÿå‰",hour:"å°æ—¶å‰",day:"å¤©å‰",month:"ä¸ªæœˆå‰"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js",buttonText:"åŠ è½½æ›´å¤š"},isPhotoFigcaption:!0,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"3DGS",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-06-05 18:59:51"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme"),o=(new Date).getHours();void 0===t?o<=6||o>=24?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode();const a=saveToLocal.get("aside-status");void 0!==a&&("hide"===a?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 7.0.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml"></head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",(()=>{o()}))})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">146</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://picx.zhimg.com/v2-2196bb11e15de7b5d3440823b4c92ca5.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">3DGS</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2024-06-05T10:59:51.000Z" title="å‘è¡¨äº 2024-06-05 18:59:51">2024-06-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2024-06-05T10:59:51.809Z" title="æ›´æ–°äº 2024-06-05 18:59:51">2024-06-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">å­—æ•°æ€»è®¡:</span><span class="word-count">12.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»æ—¶é•¿:</span><span>48åˆ†é’Ÿ</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="3DGS"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-06-05-æ›´æ–°"><a href="#2024-06-05-æ›´æ–°" class="headerlink" title="2024-06-05 æ›´æ–°"></a>2024-06-05 æ›´æ–°</h1><h2 id="DDGS-CT-Direction-Disentangled-Gaussian-Splatting-for-Realistic-Volume-Rendering"><a href="#DDGS-CT-Direction-Disentangled-Gaussian-Splatting-for-Realistic-Volume-Rendering" class="headerlink" title="DDGS-CT: Direction-Disentangled Gaussian Splatting for Realistic Volume   Rendering"></a>DDGS-CT: Direction-Disentangled Gaussian Splatting for Realistic Volume Rendering</h2><p><strong>Authors:Zhongpai Gao, Benjamin Planche, Meng Zheng, Xiao Chen, Terrence Chen, Ziyan Wu</strong></p><p>Digitally reconstructed radiographs (DRRs) are simulated 2D X-ray images generated from 3D CT volumes, widely used in preoperative settings but limited in intraoperative applications due to computational bottlenecks, especially for accurate but heavy physics-based Monte Carlo methods. While analytical DRR renderers offer greater efficiency, they overlook anisotropic X-ray image formation phenomena, such as Compton scattering. We present a novel approach that marries realistic physics-inspired X-ray simulation with efficient, differentiable DRR generation using 3D Gaussian splatting (3DGS). Our direction-disentangled 3DGS (DDGS) method separates the radiosity contribution into isotropic and direction-dependent components, approximating complex anisotropic interactions without intricate runtime simulations. Additionally, we adapt the 3DGS initialization to account for tomography data properties, enhancing accuracy and efficiency. Our method outperforms state-of-the-art techniques in image accuracy. Furthermore, our DDGS shows promise for intraoperative applications and inverse problems such as pose registration, delivering superior registration accuracy and runtime performance compared to analytical DRR methods.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.02518v1">PDF</a></p><p><strong>Summary</strong><br>ä½¿ç”¨åŸºäºç‰©ç†çš„3Dé«˜æ–¯ç‚¹æ¸²æŸ“ï¼ˆ3DGSï¼‰æ–¹æ³•ç”Ÿæˆæ•°å­—é‡å»ºå°„çº¿å›¾åƒï¼ˆDRRï¼‰ï¼Œå®ç°é«˜æ•ˆå’Œé«˜ç²¾åº¦çš„Xå°„çº¿æ¨¡æ‹Ÿã€‚</p><p><strong>Key Takeaways</strong><br>â€¢ æ•°å­—é‡å»ºå°„çº¿å›¾åƒï¼ˆDRRï¼‰åœ¨preoperative settingsä¸­å¹¿æ³›åº”ç”¨ï¼Œä½†åœ¨intraoperativeåº”ç”¨ä¸­å—åˆ°è®¡ç®—ç“¶é¢ˆçš„é™åˆ¶ã€‚<br>â€¢ ç‰©ç†åŸºäºè’™ç‰¹å¡ç½—æ–¹æ³•å‡†ç¡®ä½†è®¡ç®—å¯†é›†ï¼Œè€Œanalytical DRR renderer-efficientä½†å¿½è§†éå„å‘åŒæ€§Xå°„çº¿æˆåƒç°è±¡ã€‚<br>â€¢ æœ¬æ–‡æå‡ºäº†ä¸€ç§novelæ–¹æ³•ï¼Œä½¿ç”¨3Dé«˜æ–¯ç‚¹æ¸²æŸ“ï¼ˆ3DGSï¼‰å®ç°é«˜æ•ˆå’Œé«˜ç²¾åº¦çš„Xå°„çº¿æ¨¡æ‹Ÿã€‚<br>â€¢ æœ¬æ–¹æ³•å°†radiosityè´¡çŒ®åˆ†ç¦»ä¸ºå„å‘åŒæ€§å’Œæ–¹å‘ä¾èµ–ç»„ä»¶ï¼Œè¿‘ä¼¼å¤æ‚éå„å‘åŒæ€§ç›¸äº’ä½œç”¨ã€‚<br>â€¢ æœ¬æ–¹æ³•åœ¨å›¾åƒå‡†ç¡®æ€§ä¸Šä¼˜äºstate-of-the-artæŠ€æœ¯ã€‚<br>â€¢ æœ¬æ–¹æ³•é€‚ç”¨äºintraoperativeåº”ç”¨å’Œé€†é—®é¢˜ï¼Œå¦‚pose registrationï¼Œæä¾›æ›´é«˜çš„æ³¨å†Œå‡†ç¡®æ€§å’Œè¿è¡Œæ€§èƒ½ã€‚</p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: DDGS-CT: Direction-Disentangled Gaussian Splatting (åŸºäºæ–¹å‘è§£è€¦é«˜æ–¯ç‚¹æ¸²æŸ“çš„DRRç”Ÿæˆ)</p></li><li><p>Authors: Zhongpai Gao, Benjamin Planche, Meng Zheng, Xiao Chen, Terrence Chen, Ziyan Wu</p></li><li><p>Affiliation:æ³¢å£«é¡¿ç¾å›½æˆåƒæ™ºèƒ½å…¬å¸ (United Imaging Intelligence, Boston, MA)</p></li><li><p>Keywords: Digitally Reconstructed Radiographs, 3D Gaussian Splatting, Direction-Disentangled Gaussian Splatting, X-ray Simulation</p></li><li><p>Urls: arXiv:2406.02518v1, Github: None</p></li><li><p>Summary:</p><ul><li><p>(1):æœ¬æ–‡ç ”ç©¶çš„èƒŒæ™¯æ˜¯ç”ŸæˆDigitally Reconstructed Radiographs (DRRs)ï¼Œå³ä»3D CTä½“æ•°æ®ç”Ÿæˆ2D Xå°„çº¿å›¾åƒã€‚è¿™ç§æŠ€æœ¯å¹¿æ³›åº”ç”¨äºå¤–ç§‘æ‰‹æœ¯å‰è§„åˆ’ï¼Œä½†æ˜¯åœ¨å¤–ç§‘æ‰‹æœ¯ä¸­åº”ç”¨å—åˆ°è®¡ç®—ç“¶é¢ˆçš„é™åˆ¶ã€‚</p></li><li><p>(2):è¿‡å»çš„æ–¹æ³•æœ‰åŸºäºè’™ç‰¹å¡ç½—æ–¹æ³•çš„ç‰©ç†æ¨¡å‹å’ŒåŸºäºå°„çº¿è¿½è¸ªçš„åˆ†ææ–¹æ³•ã€‚ç„¶è€Œï¼Œç‰©ç†æ¨¡å‹è®¡ç®—å¤æ‚ï¼Œè€Œåˆ†ææ–¹æ³•å¿½è§†äº†Xå°„çº¿æˆåƒä¸­çš„å„å‘å¼‚æ€§æ•ˆåº”ï¼Œå¦‚Comptonæ•£å°„ã€‚</p></li><li><p>(3):æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç§°ä¸ºDirection-Disentangled Gaussian Splatting (DDGS)ï¼Œè¯¥æ–¹æ³•å°†è¾å°„åº¦è´¡çŒ®åˆ†è§£ä¸ºå„å‘åŒæ€§å’Œæ–¹å‘ç›¸å…³çš„ç»„ä»¶ï¼Œè¿‘ä¼¼å¤æ‚çš„å„å‘å¼‚æ€§ç›¸äº’ä½œç”¨ï¼Œè€Œä¸éœ€è¦å¤æ‚çš„runtimeæ¨¡æ‹Ÿã€‚</p></li><li><p>(4):æœ¬æ–‡çš„æ–¹æ³•åœ¨å›¾åƒå‡†ç¡®æ€§æ–¹é¢ä¼˜äºstate-of-the-artæŠ€æœ¯ï¼Œå¹¶ä¸”åœ¨å¤–ç§‘æ‰‹æœ¯åº”ç”¨å’Œé€†é—®é¢˜ï¼ˆå¦‚å§¿æ€æ³¨å†Œï¼‰ä¸­æ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ€§èƒ½å’Œæ³¨å†Œå‡†ç¡®æ€§ã€‚</p></li></ul></li><li>æ–¹æ³•ï¼š</li></ol><ul><li><p>(1):åŸºäº3Dé«˜æ–¯ç‚¹æ¸²æŸ“ï¼ˆ3D Gaussian Splattingï¼Œ3DGSï¼‰æŠ€æœ¯ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç§°ä¸ºæ–¹å‘è§£è€¦é«˜æ–¯ç‚¹æ¸²æŸ“ï¼ˆDirection-Disentangled Gaussian Splattingï¼ŒDDGSï¼‰ï¼Œå°†è¾å°„åº¦è´¡çŒ®åˆ†è§£ä¸ºå„å‘åŒæ€§å’Œæ–¹å‘ç›¸å…³çš„ç»„ä»¶ã€‚</p></li><li><p>(2):å°†é«˜æ–¯ç‚¹äº‘åˆå§‹åŒ–ç­–ç•¥æ”¹é©ä¸ºè€ƒè™‘CTä½“æ•°æ®çš„å‡ ä½•å’Œææ–™å±æ€§ï¼Œä»è€Œæé«˜æ¨¡å‹æ”¶æ•›é€Ÿåº¦å’Œå›¾åƒå‡†ç¡®æ€§ã€‚</p></li><li><p>(3):å¼•å…¥æ–¹å‘ä¾èµ–çš„è¾å°„å‡½æ•°ï¼Œè¿‘ä¼¼å¤æ‚çš„å„å‘å¼‚æ€§ç›¸äº’ä½œç”¨ï¼Œè€Œä¸éœ€è¦å¤æ‚çš„runtimeæ¨¡æ‹Ÿã€‚</p></li><li><p>(4):å°†è¾å°„å‡½æ•°åˆ†è§£ä¸ºå„å‘åŒæ€§å’Œæ–¹å‘ç›¸å…³çš„ç»„ä»¶ï¼Œåˆ†åˆ«ç”¨sigmoidå‡½æ•°å’Œçƒè°å‡½æ•°è¡¨ç¤ºï¼Œæé«˜æ¨¡å‹çš„æ¨¡å—åŒ–å’Œå‡†ç¡®æ€§ã€‚</p></li><li><p>(5):ä½¿ç”¨DDGSæ–¹æ³•ç”ŸæˆDigitally Reconstructed Radiographsï¼ˆDRRsï¼‰ï¼Œå®ç°å¿«é€Ÿå’Œå‡†ç¡®çš„Xå°„çº¿å›¾åƒç”Ÿæˆã€‚</p></li><li><p>(6):é€šè¿‡å®éªŒéªŒè¯ï¼ŒDDGSæ–¹æ³•åœ¨å›¾åƒå‡†ç¡®æ€§æ–¹é¢ä¼˜äºstate-of-the-artæŠ€æœ¯ï¼Œå¹¶ä¸”åœ¨å¤–ç§‘æ‰‹æœ¯åº”ç”¨å’Œé€†é—®é¢˜ï¼ˆå¦‚å§¿æ€æ³¨å†Œï¼‰ä¸­æ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ€§èƒ½å’Œæ³¨å†Œå‡†ç¡®æ€§ã€‚</p></li></ul><ol><li>ç»“è®ºï¼š</li></ol><ul><li><p>(1):æœ¬æ–‡æå‡ºçš„Direction-Disentangled Gaussian Splattingï¼ˆDDGSï¼‰æ–¹æ³•å¯¹äºDigitally Reconstructed Radiographsï¼ˆDRRsï¼‰çš„ç”Ÿæˆå…·æœ‰é‡è¦çš„æ„ä¹‰ï¼Œå¯ä»¥æé«˜å¤–ç§‘æ‰‹æœ¯å‰è§„åˆ’å’Œé€†é—®é¢˜è§£å†³çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</p></li><li><p>(2):åˆ›æ–°ç‚¹ï¼šDDGSæ–¹æ³•å°†è¾å°„åº¦è´¡çŒ®åˆ†è§£ä¸ºå„å‘åŒæ€§å’Œæ–¹å‘ç›¸å…³çš„ç»„ä»¶ï¼Œä¼¼å¤æ‚çš„å„å‘å¼‚æ€§ç›¸äº’ä½œç”¨ï¼›æ€§èƒ½ï¼šDDGSæ–¹æ³•åœ¨å›¾åƒå‡†ç¡®æ€§æ–¹é¢ä¼˜äºstate-of-the-artæŠ€æœ¯ï¼Œå¹¶ä¸”åœ¨å¤–ç§‘æ‰‹æœ¯åº”ç”¨å’Œé€†é—®é¢˜ä¸­æ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ€§èƒ½å’Œæ³¨å†Œå‡†ç¡®æ€§ï¼›å·¥ä½œé‡ï¼šDDGSæ–¹æ³•å¯ä»¥å‡å°‘è®¡ç®—ç“¶é¢ˆçš„é™åˆ¶ï¼Œæé«˜æ¨¡å‹æ”¶æ•›é€Ÿåº¦å’Œå›¾åƒå‡†ç¡®æ€§ï¼Œä½†éœ€è¦offline DRR rendereræ¥äº§ç”ŸçœŸå®çš„ground truthä»¥è®­ç»ƒDDGSã€‚</p></li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-8b3318acd0f86deae773881806828424.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ba0d027e2ea11b7e2dabed9efbf6103a.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-940fd606a5c57a9e6fa75ff759d3c33a.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-5cb52f82edf660328efd02928ca40b9c.jpg" align="middle"></details><h2 id="WE-GS-An-In-the-wild-Efficient-3D-Gaussian-Representation-for-Unconstrained-Photo-Collections"><a href="#WE-GS-An-In-the-wild-Efficient-3D-Gaussian-Representation-for-Unconstrained-Photo-Collections" class="headerlink" title="WE-GS: An In-the-wild Efficient 3D Gaussian Representation for   Unconstrained Photo Collections"></a>WE-GS: An In-the-wild Efficient 3D Gaussian Representation for Unconstrained Photo Collections</h2><p><strong>Authors:Yuze Wang, Junyi Wang, Yue Qi</strong></p><p>Novel View Synthesis (NVS) from unconstrained photo collections is challenging in computer graphics. Recently, 3D Gaussian Splatting (3DGS) has shown promise for photorealistic and real-time NVS of static scenes. Building on 3DGS, we propose an efficient point-based differentiable rendering framework for scene reconstruction from photo collections. Our key innovation is a residual-based spherical harmonic coefficients transfer module that adapts 3DGS to varying lighting conditions and photometric post-processing. This lightweight module can be pre-computed and ensures efficient gradient propagation from rendered images to 3D Gaussian attributes. Additionally, we observe that the appearance encoder and the transient mask predictor, the two most critical parts of NVS from unconstrained photo collections, can be mutually beneficial. We introduce a plug-and-play lightweight spatial attention module to simultaneously predict transient occluders and latent appearance representation for each image. After training and preprocessing, our method aligns with the standard 3DGS format and rendering pipeline, facilitating seamlessly integration into various 3DGS applications. Extensive experiments on diverse datasets show our approach outperforms existing approaches on the rendering quality of novel view and appearance synthesis with high converge and rendering speed.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.02407v1">PDF</a> Our project page is available at <a target="_blank" rel="noopener" href="https://yuzewang1998.github.io/we-gs.github.io/">https://yuzewang1998.github.io/we-gs.github.io/</a></p><p><strong>Summary</strong><br>åŸºäº3Dé«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯ï¼Œæå‡ºäº†ä¸€ç§ç‚¹äº‘åŸºäºå¯å¾®åˆ†æ¸²æŸ“æ¡†æ¶ï¼Œç”¨äºä»ç…§ç‰‡é›†åˆé‡å»ºåœºæ™¯ï¼Œå¹¶å®ç°äº†å®æ—¶çš„æ–°è§†å›¾åˆæˆå’Œå¤–è§‚åˆæˆã€‚</p><p><strong>Key Takeaways</strong><br>â€¢ åŸºäº3Dé«˜æ–¯æ¶‚æŠ¹æŠ€æœ¯ï¼Œæå‡ºäº†ä¸€ç§ç‚¹äº‘åŸºäºå¯å¾®åˆ†æ¸²æŸ“æ¡†æ¶ï¼Œç”¨äºä»ç…§ç‰‡é›†åˆé‡å»ºåœºæ™¯ã€‚<br>â€¢ æå‡ºäº†æ®‹å·®åŸºäºçƒè°ç³»æ•°ä¼ è¾“æ¨¡å—ï¼Œé€‚åº”å˜åŒ–çš„ç…§æ˜æ¡ä»¶å’Œå…‰åº¦åå¤„ç†ã€‚<br>â€¢ å¼•å…¥äº†è½»é‡çº§ç©ºé—´æ³¨æ„åŠ›æ¨¡å—ï¼Œé¢„æµ‹ç¬æ€é®æŒ¡ç‰©å’Œæ½œåœ¨å¤–è§‚è¡¨ç¤ºã€‚<br>â€¢ æ–¹æ³•ä¸æ ‡å‡†3DGSæ ¼å¼å’Œæ¸²æŸ“ç®¡é“å…¼å®¹ï¼Œæ˜“äºé›†æˆåˆ°å„ç§3DGSåº”ç”¨ä¸­ã€‚<br>â€¢ å®éªŒç»“æœè¡¨æ˜ï¼Œæ–¹æ³•åœ¨æ–°è§†å›¾å’Œå¤–è§‚åˆæˆçš„æ¸²æŸ“è´¨é‡ä¸Šä¼˜äºç°æœ‰çš„æ–¹æ³•ï¼ŒåŒæ—¶å…·æœ‰é«˜æ”¶æ•›é€Ÿå’Œæ¸²æŸ“é€Ÿåº¦ã€‚<br>â€¢ æ–¹æ³•èƒ½å¤Ÿæ—¶ç”Ÿæˆé«˜è´¨é‡çš„æ–°è§†å›¾å’Œå¤–è§‚å›¾åƒã€‚<br>â€¢ æ–¹æ³•å¯ä»¥å¹¿æ³›åº”ç”¨äºè®¡ç®—æœºå›¾å½¢å­¦å’Œè™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚</p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>Title: WE-GSï¼šä¸€ç§åœ¨é‡é«˜æ•ˆ3Dé«˜æ–¯è¡¨ç¤ºNovel View Synthesis for Unconstrained Photo Collections</li></ol><ol><li>Authors: Yuze Wang, Junyi Wang, Yue Qi</li></ol><ol><li>Affiliation: æœªæä¾›</li></ol><ol><li>Keywords: Novel View Synthesis, Unconstrained Photo Collection, Appearance Modeling, Real-time Rendering, 3D Gaussian Splatting</li></ol><ol><li>Urls: <a target="_blank" rel="noopener" href="https://yuzewang1998.github.io/we-gs.github.io/">https://yuzewang1998.github.io/we-gs.github.io/</a>, Github:None</li></ol><ol><li>Summary:</li></ol><pre><code>- (1):æœ¬æ–‡ç ”ç©¶èƒŒæ™¯æ˜¯ä»ä¸å—çº¦æŸçš„ç…§ç‰‡é›†åˆä¸­é‡å»ºçœŸå®ä¸–ç•Œåœºæ™¯ï¼Œå¹¶å®ç°æ–°è§†å›¾åˆæˆï¼ˆNovel View Synthesisï¼‰ï¼Œè¿™æ˜¯è®¡ç®—æœºå›¾å½¢å­¦å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­çš„ä¸€ä¸ªæŒ‘æˆ˜æ€§ä»»åŠ¡ã€‚


- (2):è¿‡å»çš„æ–¹æ³•åŒ…æ‹¬NeRFã€3DGSç­‰ï¼Œä½†è¿™äº›æ–¹æ³•å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œä¾‹å¦‚éœ€è¦å¤§é‡è®¡ç®—èµ„æºã€æ¨¡å‹å‚æ•°å¤šã€è®­ç»ƒæ—¶é•¿ç­‰ã€‚æ­¤å¤–ï¼ŒNeRF-Wã€SWAGå’ŒGS-Wç­‰æ–¹æ³•è™½ç„¶å¯ä»¥å¤„ç†ä¸å—çº¦æŸçš„ç…§ç‰‡é›†åˆï¼Œä½†å®ƒä»¬ä¹Ÿå­˜åœ¨ä¸€äº›ç¼ºé™·ï¼Œä¾‹å¦‚è®¡ç®—æ•ˆç‡ä½ã€æ¨¡å‹å‚æ•°å¤šã€æ— æ³•å®æ—¶æ¸²æŸ“ç­‰ã€‚


- (3):æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºç‚¹çš„å¯å¾®åˆ†æ¸²æŸ“æ¡†æ¶ï¼Œä½¿ç”¨æ®‹å·®åŸºäºçƒè°å‡½æ•°ç³»æ•°ä¼ è¾“æ¨¡å—æ¥é€‚åº”å˜åŒ–çš„ç…§æ˜æ¡ä»¶å’Œå…‰åº¦åå¤„ç†ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„ç©ºé—´_attentionæ¨¡å—æ¥åŒæ—¶é¢„æµ‹ç¬æ€é®æŒ¡å’Œæ½œåœ¨å¤–è§‚è¡¨ç¤ºã€‚


- (4):æœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œå¯ä»¥å®ç°é«˜è´¨é‡çš„æ–°è§†å›¾å’Œå¤–è§‚åˆæˆï¼ŒåŒæ—¶å…·æœ‰é«˜æ”¶æ•›é€Ÿåº¦å’Œæ¸²æŸ“é€Ÿåº¦ï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
</code></pre><ol><li>æ–¹æ³•ï¼š</li></ol><ul><li><p>(1): æå‡ºäº†ä¸€ä¸ªåŸºäºç‚¹çš„å¯å¾®åˆ†æ¸²æŸ“æ¡†æ¶ï¼Œä½¿ç”¨æ®‹å·®åŸºäºçƒè°å‡½æ•°ç³»æ•°ä¼ è¾“æ¨¡å—æ¥é€‚åº”å˜åŒ–çš„ç…§æ˜æ¡ä»¶å’Œå…‰åº¦åå¤„ç†ã€‚</p></li><li><p>(2): å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„ç©ºé—´_attentionæ¨¡å—æ¥åŒæ—¶é¢„æµ‹ç¬æ€é®æŒ¡å’Œæ½œåœ¨å¤–è§‚è¡¨ç¤ºã€‚</p></li><li><p>(3): ä½¿ç”¨æ®‹å·®åŸºäºçƒè°å‡½æ•°ç³»æ•°ä¼ è¾“æ¨¡å—å°†æ¯ä¸ª3Dé«˜æ–¯Gjå­¦ä¹ åˆ°å›¾åƒç‰¹å®šçš„æ®‹å·®çƒè°ç³»æ•°âˆ†shjkï¼Œä»¥é€‚åº”ä¸å—çº¦æŸçš„ç…§ç‰‡é›†åˆä¸­çš„å¤–è§‚å˜åŒ–ã€‚</p></li><li><p>(4): ä½¿ç”¨è½»é‡çº§çš„ç©ºé—´_attentionæ¨¡å—æ¥é¢„æµ‹ç¬æ€é®æŒ¡å’Œæ½œåœ¨å¤–è§‚è¡¨ç¤ºï¼Œå®ç°å¯¹ç¬æ€é®æŒ¡å’Œå¤–è§‚çš„åŒæ—¶é¢„æµ‹ã€‚</p></li><li><p>(5): é€šè¿‡ä¼˜åŒ–è¿‡ç¨‹ï¼Œå­¦ä¹ æ¯ä¸ª3Dé«˜æ–¯çš„radiance fieldå’Œç¬æ€é®æŒ¡ï¼Œå®ç°å¯¹ä¸å—çº¦æŸçš„ç…§ç‰‡é›†åˆçš„æ–°è§†å›¾åˆæˆã€‚</p></li><li><p>(6): ä½¿ç”¨WE-GSæ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œå¯ä»¥å®ç°é«˜è´¨é‡çš„æ–°è§†å›¾å’Œå¤–è§‚åˆæˆï¼ŒåŒæ—¶å…·æœ‰é«˜æ”¶æ•›é€Ÿåº¦å’Œæ¸²æŸ“é€Ÿåº¦ï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p></li><li><p>(7): é€šè¿‡å¯¹ç…§å®éªŒï¼ŒéªŒè¯äº†WE-GSæ–¹æ³•çš„ä¼˜è¶Šæ€§å’Œé²æ£’æ€§ï¼Œè¯æ˜äº†å…¶åœ¨ä¸å—çº¦æŸçš„ç…§ç‰‡é›†åˆä¸­çš„æ–°è§†å›¾åˆæˆä»»åŠ¡ä¸­çš„åº”ç”¨ä»·å€¼ã€‚</p></li></ul><ol><li>Conclusion:</li></ol><ul><li>(1):æœ¬æ–‡çš„å·¥ä½œå¯¹è®¡ç®—æœºå›¾å½¢å­¦å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­çš„æ–°è§†å›¾åˆæˆä»»åŠ¡å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå¯ä»¥å®ç°é«˜è´¨é‡çš„æ–°è§†å›¾å’Œå¤–è§‚åˆæˆï¼ŒåŒæ—¶å…·æœ‰é«˜æ”¶æ•›é€Ÿåº¦å’Œæ¸²æŸ“é€Ÿåº¦ï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li></ul><ul><li>(2):Innovation point: æœ¬æ–‡æå‡ºçš„åŸºäºç‚¹çš„å¯å¾®åˆ†æ¸²æŸ“æ¡†æ¶å’Œè½»é‡çº§çš„ç©º_attentionæ¨¡å—æ˜¯è¯¥é¢†åŸŸçš„åˆ›æ–°ç‚¹ï¼Œè§£å†³äº†è¿‡å»æ–¹æ³•ä¸­çš„è®¡ç®—æ•ˆç‡ä½ã€æ¨¡å‹å‚æ•°å¤šã€æ— æ³•å®æ—¶æ¸²æŸ“ç­‰é—®é¢˜ã€‚Performance: æœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œå¯ä»¥å®ç°é«˜è´¨é‡çš„æ–°è§†å›¾å’Œå¤–è§‚åˆæˆï¼ŒåŒæ—¶å…·æœ‰é«˜æ”¶æ•›é€Ÿåº¦å’Œæ¸²æŸ“é€Ÿåº¦ã€‚Workload: æœ¬æ–‡çš„æ–¹æ³•å¯ä»¥å®æ—¶æ¸²æŸ“ï¼Œå…·æœ‰é«˜æ”¶æ•›é€Ÿåº¦å’Œæ¸²æŸ“é€Ÿåº¦ï¼Œè¯æ˜äº†æ–¹æ³•çš„å®æ—¶æ€§å’Œé«˜æ•ˆæ€§ã€‚</li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-97ed0af94488d838444ce09b850244d2.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-560238e8fd8e314b5603a7e532c6b0c1.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-5d888159ce7037f6f69e8e35f606741f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3bc8e67380a38526e522265c420f422b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2196bb11e15de7b5d3440823b4c92ca5.jpg" align="middle"></details><h2 id="OpenGaussian-Towards-Point-Level-3D-Gaussian-based-Open-Vocabulary-Understanding"><a href="#OpenGaussian-Towards-Point-Level-3D-Gaussian-based-Open-Vocabulary-Understanding" class="headerlink" title="OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary   Understanding"></a>OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understanding</h2><p><strong>Authors:Yanmin Wu, Jiarui Meng, Haijie Li, Chenming Wu, Yahao Shi, Xinhua Cheng, Chen Zhao, Haocheng Feng, Errui Ding, Jingdong Wang, Jian Zhang</strong></p><p>This paper introduces OpenGaussian, a method based on 3D Gaussian Splatting (3DGS) capable of 3D point-level open vocabulary understanding. Our primary motivation stems from observing that existing 3DGS-based open vocabulary methods mainly focus on 2D pixel-level parsing. These methods struggle with 3D point-level tasks due to weak feature expressiveness and inaccurate 2D-3D feature associations. To ensure robust feature presentation and 3D point-level understanding, we first employ SAM masks without cross-frame associations to train instance features with 3D consistency. These features exhibit both intra-object consistency and inter-object distinction. Then, we propose a two-stage codebook to discretize these features from coarse to fine levels. At the coarse level, we consider the positional information of 3D points to achieve location-based clustering, which is then refined at the fine level. Finally, we introduce an instance-level 3D-2D feature association method that links 3D points to 2D masks, which are further associated with 2D CLIP features. Extensive experiments, including open vocabulary-based 3D object selection, 3D point cloud understanding, click-based 3D object selection, and ablation studies, demonstrate the effectiveness of our proposed method. Project page: <a target="_blank" rel="noopener" href="https://3d-aigc.github.io/OpenGaussian">https://3d-aigc.github.io/OpenGaussian</a></p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.02058v1">PDF</a> technical report, 15 pages</p><p><strong>Summary</strong><br>æœ¬æ–‡æå‡ºOpenGaussianæ–¹æ³•ï¼ŒåŸºäº3D Gaussian Splattingï¼ˆ3DGSï¼‰ï¼Œå®ç°3Dç‚¹çº§å¼€æ”¾è¯æ±‡ç†è§£ã€‚</p><p><strong>Key Takeaways</strong><br>â€¢ OpenGaussianæ–¹æ³•åŸºäº3D Gaussian Splattingï¼ˆ3DGSï¼‰ï¼Œå®ç°3Dç‚¹çº§å¼€æ”¾è¯æ±‡ç†è§£ã€‚<br>â€¢ ç°æœ‰çš„3DGS-basedå¼€æ”¾è¯æ±‡æ–¹æ³•ä¸»å…³æ³¨2Dåƒç´ çº§è§£æï¼Œæ— æ³•è¿›è¡Œ3Dç‚¹çº§ä»»åŠ¡ã€‚<br>â€¢ æœ¬æ–¹æ³•ä½¿ç”¨SAM masksè®­ç»ƒå®ä¾‹ç‰¹å¾ï¼Œå…·æœ‰3Dä¸€è‡´æ€§å’Œå¯¹è±¡é—´åŒºåˆ†æ€§ã€‚<br>â€¢ è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µä»£ç ç°¿å°†ç‰¹å¾ä»ç²—åˆ°ç»†çº§åˆ«ç¦»æ•£åŒ–ã€‚<br>â€¢ å®éªŒç»“æœè¡¨æ˜OpenGaussianæ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡åŸºäº3Då¯¹è±¡é€‰æ‹©ã€3Dç‚¹äº‘ç†è§£ã€ç‚¹å‡»åŸºäº3Då¯¹è±¡é€‰æ‹©ç­‰ä»»åŠ¡ä¸­å…·æœ‰å¾ˆé«˜çš„æœ‰æ•ˆæ€§ã€‚</p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: OpenGaussianï¼šç‚¹çº§3Dé«˜æ–¯ç†è§£ï¼ˆOpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understandingï¼‰</p></li><li><p>Authors: Yanmin Wu, Jiarui Meng, Haijie Li, Chenming Wu, Yahao Shi, Xinhua Cheng, Chen Zhao, Haocheng Feng, Errui Ding, Jingdong Wang, Jian Zhang</p></li><li><p>Affiliation: åŒ—äº¬å¤§å­¦ï¼ˆPeking Universityï¼‰</p></li><li><p>Keywords: 3D Gaussian Splatting, Open Vocabulary Understanding, Point-Level Understanding, 3D Scene Understanding</p></li><li><p>Urls: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.02058v1">https://arxiv.org/abs/2406.02058v1</a>, Github:None</p></li><li><p>Summary:</p></li></ol><ul><li><p>(1):æœ¬æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯åŸºäº3D Gaussian Splattingï¼ˆ3DGSï¼‰æ¡†æ¶çš„3Dåœºæ™¯ç†è§£ï¼Œæ—¨åœ¨å®ç°ç‚¹çº§å¼€æ”¾è¯æ±‡ç†è§£ã€‚</p></li><li><p>(2):è¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨2Dåƒç´ çº§åˆ«çš„å¼€æ”¾è¯æ±‡ç†è§£ï¼Œå­˜åœ¨ç‰¹å¾è¡¨è¾¾èƒ½åŠ›å¼±å’Œ2D-3Dç‰¹å¾å…³è”ä¸å‡†ç¡®çš„é—®é¢˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•motivated byè¿™äº›é—®é¢˜ã€‚</p></li><li><p>(3):æœ¬æ–‡æå‡ºçš„æ–¹æ³•é¦–å…ˆä½¿ç”¨SAM masksè®­ç»ƒå®ä¾‹ç‰¹å¾ï¼Œä»¥ç¡®ä¿ç‰¹å¾çš„robustnesså’Œ3Dç‚¹çº§åˆ«çš„ç†è§£ã€‚ç„¶åï¼Œæå‡ºä¸€ä¸ªä¸¤é˜¶æ®µçš„codebookæ¥ç¦»æ•£è¿™äº›ç‰¹å¾ï¼Œä»ç²—ç³™åˆ°ç»†è…»çš„çº§åˆ«ã€‚æœ€åï¼Œå¼•å…¥å®ä¾‹çº§åˆ«çš„3D-2Dç‰¹å¾å…³è”æ–¹æ³•ï¼Œå°†3Dç‚¹å…³è”åˆ°2D masksï¼Œå¹¶ä¸2D CLIPç‰¹å¾å…³è”ã€‚</p></li><li><p>(4):æœ¬æ–‡çš„æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡åŸºäº3Då¯¹è±¡é€‰æ‹©ã€3Dç‚¹äº‘ç†è§£ã€ç‚¹å‡»åŸºäº3Då¯¹è±¡é€‰æ‹©ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œæ”¯æŒäº†è®ºæ–‡çš„ç›®æ ‡ã€‚</p></li></ul><ol><li>æ–¹æ³•ï¼š</li></ol><ul><li><p>(1):ä½¿ç”¨ SAM æ©è†œè®­ç»ƒå®ä¾‹ç‰¹å¾ï¼Œä»¥ç¡®ä¿ç‰¹å¾çš„é²æ£’æ€§å’Œ 3D ç‚¹çº§åˆ«çš„ç†è§£ã€‚</p></li><li><p>(2):æå‡ºä¸€ä¸ªä¸¤é˜¶æ®µçš„ codebook æ¥ç¦»æ•£è¿™äº›ç‰¹å¾ï¼Œä»ç²—ç³™åˆ°ç»†è…»çš„çº§åˆ«ã€‚</p></li><li><p>(3):å¼•å…¥å®ä¾‹çº§åˆ«çš„ 3D-2D ç‰¹å¾å…³è”æ–¹æ³•ï¼Œå°† 3D ç‚¹å…³è”åˆ° 2D æ©è†œï¼Œå¹¶ä¸ 2D CLIP ç‰¹å¾å…³è”ã€‚</p></li><li><p>(4):ä½¿ç”¨ä¸¤ç§æŸå¤±å‡½æ•°ï¼šintra-mask å¹³æ»‘æŸå¤±å’Œ inter-mask å¯¹æ¯”æŸå¤±ï¼Œæ¥çº¦æŸå®ä¾‹ç‰¹å¾çš„å­¦ä¹ ã€‚</p></li><li><p>(5):ä½¿ç”¨ codebook ç¦»æ•£åŒ–æ¥ç¡®ä¿åŒä¸€å®ä¾‹çš„é«˜æ–¯ç‚¹å…·æœ‰ç›¸åŒçš„ç‰¹å¾ï¼Œä»è€Œæé«˜å®ä¾‹ç‰¹å¾çš„ distinctivenessã€‚</p></li><li><p>(6):æå‡ºä¸¤çº§ codebook ç¦»æ•£åŒ–æ–¹æ³•ï¼Œé¦–å…ˆä½¿ç”¨é«˜æ–¯ç‚¹çš„ 3D åæ ‡å’Œå®ä¾‹ç‰¹å¾è¿›è¡Œç²—ç³™çº§åˆ«çš„ç¦»æ•£åŒ–ï¼Œç„¶ååœ¨æ¯ä¸ªç²—ç³™ç°‡ä¸­è¿›ä¸€æ­¥ç¦»æ•£åŒ–å®ä¾‹ç‰¹å¾ã€‚</p></li><li><p>(7):ä½¿ç”¨ä¼ªç‰¹å¾æŸå¤±å‡½æ•°æ¥ä¼˜åŒ– codebook çš„å­¦ä¹ è¿‡ç¨‹ï¼Œæé«˜å®ä¾‹ç‰¹å¾çš„å‡†ç¡®æ€§ã€‚</p></li></ul><ol><li>Conclusion:</li></ol><ul><li><p>(1):æœ¬æ–‡çš„å·¥ä½œæ„ä¹‰åœ¨äºæ¨åŠ¨ä¸‰ç»´åœºæ™¯ç†è§£çš„å‘å±•ï¼Œå®ç°ç‚¹çº§å¼€æ”¾è¯æ±‡ç†è§£ï¼Œæé«˜ä¸‰ç»´ç‚¹äº‘ç†è§£çš„ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p></li><li><p>(2):åˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸‰ç»´é«˜æ–¯ç‚¹çš„å¼€æ”¾è¯æ±‡ç†è§£æ–¹æ³•å¼•å…¥äº†å®ä¾‹çº§åˆ«çš„ä¸‰ç»´-äºŒç»´ç‰¹ï¿½ï¿½å…³è”æ–¹æ³•ï¼Œæé«˜äº†ä¸‰ç»´ç‚¹äº‘ç†è§£çš„ç²¾åº¦å’Œrobustnessï¼›æ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨å¼€æ”¾è¯æ±‡åŸºäºä¸‰ç»´å¯¹è±¡é€‰æ‹©ã€ troisç‚¹äº‘ç†è§£ã€ç‚¹å‡»åŸºäºä¸‰ç»´å¯¹è±¡é€‰æ‹©ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼›å·¥ä½œè´Ÿè½½ï¼šæœ¬æ–‡çš„æ–¹æ³•éœ€è¦å¤§é‡çš„è®¡èµ„æºå’Œæ•°æ®æ”¯æŒï¼Œä¸”éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ä»£ç å®ç°ä»¥æé«˜æ•ˆç‡ã€‚</p></li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-2be9af96961d59f11698f2c5bcd330a2.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-a911eb9df51d9d27ce9eaa83b8c2dc27.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-156984d4ba895cb35d5d6806f6c11e48.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-ee276cabd836736f8ee107c9dee10a2e.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-469659c7608d57f9e72a22a8abc4c5d0.jpg" align="middle"></details><h2 id="FastLGS-Speeding-up-Language-Embedded-Gaussians-with-Feature-Grid-Mapping"><a href="#FastLGS-Speeding-up-Language-Embedded-Gaussians-with-Feature-Grid-Mapping" class="headerlink" title="FastLGS: Speeding up Language Embedded Gaussians with Feature Grid   Mapping"></a>FastLGS: Speeding up Language Embedded Gaussians with Feature Grid Mapping</h2><p><strong>Authors:Yuzhou Ji, He Zhu, Junshu Tang, Wuyi Liu, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan</strong></p><p>The semantically interactive radiance field has always been an appealing task for its potential to facilitate user-friendly and automated real-world 3D scene understanding applications. However, it is a challenging task to achieve high quality, efficiency and zero-shot ability at the same time with semantics in radiance fields. In this work, we present FastLGS, an approach that supports real-time open-vocabulary query within 3D Gaussian Splatting (3DGS) under high resolution. We propose the semantic feature grid to save multi-view CLIP features which are extracted based on Segment Anything Model (SAM) masks, and map the grids to low dimensional features for semantic field training through 3DGS. Once trained, we can restore pixel-aligned CLIP embeddings through feature grids from rendered features for open-vocabulary queries. Comparisons with other state-of-the-art methods prove that FastLGS can achieve the first place performance concerning both speed and accuracy, where FastLGS is 98x faster than LERF and 4x faster than LangSplat. Meanwhile, experiments show that FastLGS is adaptive and compatible with many downstream tasks, such as 3D segmentation and 3D object inpainting, which can be easily applied to other 3D manipulation systems.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.01916v1">PDF</a></p><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>Title: FastLGSï¼šSpeeding up Language Embedded Gaussians with Feature Grid / FastLGSï¼šä½¿ç”¨ç‰¹å¾ç½‘æ ¼åŠ é€Ÿè¯­è¨€åµŒå…¥é«˜æ–¯</li></ol><ol><li>Authors: Yuzhou Ji, He Zhu, Junshu Tang, Wuyi Liu, Zhizhong Zhang, Yuan Xie, Lizhuang Ma, Xin Tan</li></ol><ol><li>Affiliation: ä¸œåå¸ˆèŒƒå¤§å­¦</li></ol><ol><li>Keywords: open-vocabulary detection, zero-shot learning, semantic 3D field</li></ol><ol><li>Urls: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.01916">https://arxiv.org/abs/2406.01916</a> , Github:None</li></ol><ol><li>Summary:</li></ol><pre><code>- (1):ç ”ç©¶èƒŒæ™¯æ˜¯ä¸‰ç»´åœºæ™¯ç†è§£ï¼Œç›®æ ‡æ˜¯å­¦ä¹ é«˜æ•ˆã€å‡†ç¡®çš„ä¸‰ç»´è¯­ä¹‰è¡¨ç¤ºï¼Œå¹¶æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢å’Œäº¤äº’å¼åœºæ™¯æ“ä½œã€‚


- (2):è¿‡å»çš„æ–¹æ³•ï¼Œå¦‚Semantic-NeRFã€N3Fã€Panoptic Liftingç­‰ï¼Œä¸»è¦å…³æ³¨å¯¹è±¡çš„åˆ†å‰²å’Œè¯†åˆ«ï¼Œä½†è¿™äº›æ–¹æ³•å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå¦‚é€Ÿåº¦æ…¢ã€å‡†ç¡®æ€§ä¸é«˜ã€ä¸æ”¯æŒé›¶æ ·æœ¬å­¦ä¹ ç­‰ã€‚æ­¤å¤–ï¼ŒLERFå’ŒLangSplatç­‰æ–¹æ³•å¯ä»¥å®ç°é›¶æ ·æœ¬å­¦ä¹ å’Œå¼€æ”¾è¯æ±‡æŸ¥è¯¢ï¼Œä½†å®ƒä»¬ä¹Ÿå­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå¦‚ç»“æœä¸å¤Ÿå‡†ç¡®ã€ä¸æ”¯æŒäº¤äº’å¼æŸ¥è¯¢ç­‰ã€‚


- (3):æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜¯FastLGSï¼Œä½¿ç”¨ç‰¹å¾ç½‘æ ¼æ˜ å°„ç­–ç•¥åœ¨ä¸‰ç»´é«˜æ–¯splattedï¼ˆ3DGSï¼‰ä¸­æ„å»ºä¸‰ç»´è¯­ä¹‰åœºï¼Œé¦–å…ˆæå–å¯¹è±¡é®ç½©ï¼Œç„¶åä½¿ç”¨CLIP encoderæå–å¯¹è±¡çº§å›¾åƒç‰¹å¾ï¼Œå¹¶å°†å…¶æ˜ å°„åˆ°ä½ç»´ç‰¹å¾ç©ºé—´ï¼Œæœ€ååœ¨æ¨ç†é˜¶æ®µæ¢å¤è¯­ä¹‰ç‰¹å¾ä»¥ç”ŸæˆæŸ¥è¯¢ç»“æœã€‚


- (4):æœ¬æ–‡æ–¹æ³•åœ¨ä¸‰ç»´åœºæ™¯ç†è§£ä»»åŠ¡ä¸Šå–å¾—äº†ç«äº‰æ€§çš„æ€§èƒ½ï¼Œæ”¯æŒå®æ—¶äº¤äº’å¼æŸ¥è¯¢ï¼Œé€Ÿåº¦æ¯”LERFå¿«98å€ã€æ¯”LangSplatå¿«4å€ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒå¤šå¯¹è±¡æŸ¥è¯¢å’Œè°ƒæ•´ã€‚
</code></pre><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><ol><li>Conclusion:</li></ol><ul><li>(1):æœ¬æ–‡æå‡ºçš„FastLGSæ–¹æ³•åœ¨ä¸‰ç»´åœºæ™¯ç†è§£é¢†åŸŸå…·æœ‰é‡è¦çš„ç ”ç©¶ä»·å€¼ï¼Œèƒ½å¤Ÿå®ç°é«˜æ•ˆã€å‡†ç¡®çš„ä¸‰ç»´è¯­ä¹‰è¡¨ç¤ºï¼Œå¹¶æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢å’Œäº¤äº’å¼åœºæ™¯æ“ä½œï¼Œå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚</li></ul><ul><li>(2):åˆ›æ–°ç‚¹ï¼šFastLGSæ–¹æ³•æå‡ºäº†ç‰¹å¾ç½‘æ ¼æ˜ å°„ç­–ç•¥ï¼Œåœ¨ä¸‰ç»´é«˜æ–¯splattedï¼ˆ3DGSï¼‰ä¸­æ„å»ºä¸‰ç»´è¯­ä¹‰åœºï¼Œå®ç°äº†å®æ—¶äº¤äº’å¼æŸ¥è¯¢å’Œé›¶æ ·æœ¬å­¦ä¹ ï¼›æ€§èƒ½ï¼šFastLGSæ–¹æ³•åœ¨ä¸‰ç»´åœºæ™¯ç†è§£ä»»åŠ¡ä¸Šå–å¾—äº†ç«äº‰æ€§çš„æ€§èƒ½ï¼Œé€Ÿåº¦æ¯”LERFå¿«98å€ã€æ¯”LangSplatå¿«4å€ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒå¤šå¯¹è±¡æŸ¥è¯¢å’Œè°ƒæ•´ï¼›å·¥ä½œé‡ï¼šFastLGSæ–¹æ³•çš„è®¡ç®—å¤æ‚åº¦è¾ƒä½ï¼Œå¯ä»¥å®æ—¶å¤„ç†å¤§è§„æ¨¡ä¸‰ç»´åœºæ™¯æ•°æ®ã€‚</li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-d4170698dae988cb090141684c9112f2.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-540d2a4b100c2bf1d6286f366b6c2a8f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-022dd2df1dd7f0502d71536cf740dac3.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-aa2aac627a35c0864283eead0500c353.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-bf66f18dd9ece3d86d3323a4a75057f1.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-080db73849e866a47f863184c0b8e203.jpg" align="middle"></details><h2 id="DreamPhysics-Learning-Physical-Properties-of-Dynamic-3D-Gaussians-with-Video-Diffusion-Priors"><a href="#DreamPhysics-Learning-Physical-Properties-of-Dynamic-3D-Gaussians-with-Video-Diffusion-Priors" class="headerlink" title="DreamPhysics: Learning Physical Properties of Dynamic 3D Gaussians with   Video Diffusion Priors"></a>DreamPhysics: Learning Physical Properties of Dynamic 3D Gaussians with Video Diffusion Priors</h2><p><strong>Authors:Tianyu Huang, Yihan Zeng, Hui Li, Wangmeng Zuo, Rynson W. H. Lau</strong></p><p>Dynamic 3D interaction has witnessed great interest in recent works, while creating such 4D content remains challenging. One solution is to animate 3D scenes with physics-based simulation, and the other is to learn the deformation of static 3D objects with the distillation of video generative models. The former one requires assigning precise physical properties to the target object, otherwise the simulated results would become unnatural. The latter tends to formulate the video with minor motions and discontinuous frames, due to the absence of physical constraints in deformation learning. We think that video generative models are trained with real-world captured data, capable of judging physical phenomenon in simulation environments. To this end, we propose DreamPhysics in this work, which estimates physical properties of 3D Gaussian Splatting with video diffusion priors. DreamPhysics supports both image- and text-conditioned guidance, optimizing physical parameters via score distillation sampling with frame interpolation and log gradient. Based on a material point method simulator with proper physical parameters, our method can generate 4D content with realistic motions. Experimental results demonstrate that, by distilling the prior knowledge of video diffusion models, inaccurate physical properties can be gradually refined for high-quality simulation. Codes are released at: <a target="_blank" rel="noopener" href="https://github.com/tyhuang0428/DreamPhysics">https://github.com/tyhuang0428/DreamPhysics</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.01476v1">PDF</a> Technical report. Codes are released at: <a target="_blank" rel="noopener" href="https://github.com/tyhuang0428/DreamPhysics">https://github.com/tyhuang0428/DreamPhysics</a></p><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>Title: DreamPhysics: Learning Physical Properties of Dynamic 3D Gaussians with Video Diffusion Priors (DreamPhysicsï¼šä½¿ç”¨è§†é¢‘æ‰©æ•£å…ˆéªŒå­¦ä¹ åŠ¨æ€3Dé«˜æ–¯ä½“çš„ç‰©ç†å±æ€§)</li></ol><ol><li>Authors: Tianyu Huang, Yihan Zeng, Hui Li, Wangmeng Zuo, Rynson W. H. Lau</li></ol><ol><li>Affiliation: é¦™æ¸¯åŸå¸‚å¤§å­¦</li></ol><ol><li>Keywords: Dynamic 3D interaction, physics-based simulation, video generative models, physical properties estimation</li></ol><ol><li>Urls: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.01476v1">https://arxiv.org/abs/2406.01476v1</a> , Github: <a target="_blank" rel="noopener" href="https://github.com/tyhuang0428/DreamPhysics">https://github.com/tyhuang0428/DreamPhysics</a></li></ol><ol><li>Summary:</li></ol><pre><code>- (1):è¯¥è®ºæ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯åŠ¨æ€3Däº¤äº’ï¼Œæ—¨åœ¨ç”Ÿæˆé€¼çœŸçš„4Då†…å®¹ã€‚


- (2):è¿‡å»çš„æ–¹æ³•æœ‰ä¸¤ç§ï¼šç‰©ç†åŸºäºæ¨¡æ‹Ÿå’Œè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œä½†å‰è€…éœ€è¦æ‰‹åŠ¨æŒ‡å®šç‰©ç†å‚æ•°ï¼Œåˆ™æ¨¡æ‹Ÿç»“æœä¸è‡ªç„¶ï¼›åè€…ç”Ÿæˆçš„è§†é¢‘å‘ˆç°å°å¹…åº¦è¿åŠ¨å’Œä¸è¿ç»­çš„å¸§ï¼Œç¼ºä¹ç‰©ç†çº¦æŸã€‚


- (3):æœ¬æ–‡æå‡ºäº†DreamPhysicsæ–¹æ³•ï¼Œä½¿è§†é¢‘æ‰©æ•£å…ˆéªŒä¼°è®¡3Dé«˜æ–¯ä½“çš„ç‰©ç†å±æ€§ï¼Œæ”¯æŒå›¾åƒå’Œæ–‡æœ¬æ¡ä»¶æŒ‡å¯¼ï¼Œé€šè¿‡åˆ†æ•°è’¸é¦é‡‡æ ·å’Œå¸§æ’å€¼å’Œå¯¹æ•°æ¢¯åº¦ä¼˜åŒ–ç‰©ç†å‚æ•°ã€‚


- (4):å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡é¦è§†é¢‘æ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¯ä»¥é€æ­¥æ”¹è¿›ç‰©ç†å‚æ•°çš„ä¸å‡†ç¡®æ€§ï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡çš„æ¨¡æ‹Ÿç»“æœã€‚
</code></pre><ol><li>æ–¹æ³•ï¼š</li></ol><ul><li><p>(1): DreamPhysics æ–¹æ³•çš„ç¬¬ä¸€æ­¥æ˜¯åˆå§‹åŒ–ä¸€ç³»åˆ—å‚æ•° $\theta^{(0)}_G$ï¼Œå¹¶é€šè¿‡åŸºäº Material Point Methodï¼ˆMPMï¼‰çš„æ¨¡æ‹Ÿå™¨æ¸²æŸ“ä¸€ä¸ªé•¿åº¦ä¸º T çš„è§†é¢‘ $V^{(0)} = {I^{(0)}_1, I^{(0)}_2, â€¦, I^{(0)}_T}$ã€‚</p></li><li><p>(2): ç„¶åï¼Œå°†æ¸²æŸ“çš„è§†é¢‘ $V^{(0)}$ é€å…¥ Score Distillation Samplingï¿½ï¿½ï¿½SDS-Tï¼‰ä¼˜åŒ–å™¨ï¼Œdistill è§†é¢‘æ‰©æ•£å…ˆéªŒåˆ°å‚æ•° $\theta^{(1)}_G$ã€‚</p></li><li><p>(3): å¯¹äºæ¯ä¸ªè®­ç»ƒ epoch kï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ SDS-T ä¼˜åŒ–å™¨æ¥è·å¾—ä¸€ä¸ªä¼˜åŒ–çš„å‚æ•° $\theta^{(k+1)}_G$ï¼Œé€šè¿‡ distill è§†é¢‘ $V^{(k)}$ã€‚</p></li><li><p>(4): é€šè¿‡å¤šæ¬¡è¿­ä»£ä¼˜åŒ–ï¼Œå‚æ•° $\theta_G$ å°†æ”¶æ•›åˆ°ä¸€ä¸ªåˆç†çš„èŒƒå›´ï¼Œå®ç°ç‰©ç†å‚æ•°çš„ä¼°è®¡ã€‚</p></li><li><p>(5): åœ¨ä¼°è®¡ç‰©ç†å‚æ•°çš„åŒæ—¶ï¼ŒDreamPhysics æ–¹æ³•è¿˜æ”¯æŒå›¾åƒå’Œæ–‡æœ¬æ¡ä»¶æŒ‡å¯¼ï¼Œé€šè¿‡å¯¹æ•°æ¢¯åº¦ä¼˜åŒ–ç‰©ç†å‚æ•°ã€‚</p></li><li><p>(6): æœ€ç»ˆï¼ŒDreamPhysics æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„æ¨¡æ‹Ÿç»“æœï¼Œå®ç°åŠ¨æ€ 3D äº¤äº’çš„é€¼çœŸæ¨¡æ‹Ÿã€‚</p></li></ul><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-3b5f7a74c5f7cfa121fbdc0c6a5c2e55.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-0396fa459472e29b46aa5af33ea5941e.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-a40536c6f67882b579ec742261eacada.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f82f9a57aa613a59ab05429bfbaaa47c.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-af6bdc5f2b23662bbbbc8a2da5064695.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-32fb319f07fc7904ec45c112004295ae.jpg" align="middle"></details><h2 id="Self-Calibrating-4D-Novel-View-Synthesis-from-Monocular-Videos-Using-Gaussian-Splatting"><a href="#Self-Calibrating-4D-Novel-View-Synthesis-from-Monocular-Videos-Using-Gaussian-Splatting" class="headerlink" title="Self-Calibrating 4D Novel View Synthesis from Monocular Videos Using   Gaussian Splatting"></a>Self-Calibrating 4D Novel View Synthesis from Monocular Videos Using Gaussian Splatting</h2><p><strong>Authors:Fang Li, Hao Zhang, Narendra Ahuja</strong></p><p>Gaussian Splatting (GS) has significantly elevated scene reconstruction efficiency and novel view synthesis (NVS) accuracy compared to Neural Radiance Fields (NeRF), particularly for dynamic scenes. However, current 4D NVS methods, whether based on GS or NeRF, primarily rely on camera parameters provided by COLMAP and even utilize sparse point clouds generated by COLMAP for initialization, which lack accuracy as well are time-consuming. This sometimes results in poor dynamic scene representation, especially in scenes with large object movements, or extreme camera conditions e.g. small translations combined with large rotations. Some studies simultaneously optimize the estimation of camera parameters and scenes, supervised by additional information like depth, optical flow, etc. obtained from off-the-shelf models. Using this unverified information as ground truth can reduce robustness and accuracy, which does frequently occur for long monocular videos (with e.g. &gt; hundreds of frames). We propose a novel approach that learns a high-fidelity 4D GS scene representation with self-calibration of camera parameters. It includes the extraction of 2D point features that robustly represent 3D structure, and their use for subsequent joint optimization of camera parameters and 3D structure towards overall 4D scene optimization. We demonstrate the accuracy and time efficiency of our method through extensive quantitative and qualitative experimental results on several standard benchmarks. The results show significant improvements over state-of-the-art methods for 4D novel view synthesis. The source code will be released soon at <a target="_blank" rel="noopener" href="https://github.com/fangli333/SC-4DGS">https://github.com/fangli333/SC-4DGS</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.01042v1">PDF</a> GitHub Page: <a target="_blank" rel="noopener" href="https://github.com/fangli333/SC-4DGS">https://github.com/fangli333/SC-4DGS</a></p><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: è‡ªé€‚åº”4Dæ–°è§†å›¾åˆæˆæ¥è‡ªå•ç›®è§†é¢‘çš„é«˜æ–¯æ–‘ç‚¹ï¼ˆSelf-Calibrating 4D Novel View Synthesis from Monocular Videos Using Gaussian Splattingï¼‰</p></li><li><p>Authors: Fang Li, Hao Zhang, Narendra Ahuja</p></li><li><p>Affiliation: ä¼Šåˆ©è¯ºä¼Šå¤§å­¦å„å·´çº³-é¦™æ§Ÿåˆ†æ ¡</p></li><li><p>Keywords: Novel View Synthesis, Gaussian Splatting, 4D Reconstruction, Self-Calibration</p></li><li><p>Urls: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.01042v1">https://arxiv.org/abs/2406.01042v1</a> , Github: <a target="_blank" rel="noopener" href="https://github.com/fangli333/SC-4DGS">https://github.com/fangli333/SC-4DGS</a></p></li><li><p>Summary:</p></li></ol><pre><code>- (1):æœ¬æ–‡ç ”ç©¶çš„æ˜¯ä»å•ç›®è§†é¢‘ä¸­ç”Ÿæˆé«˜ä¿çœŸ4Dæ–°è§†å›¾çš„ä»»åŠ¡ï¼Œå½“å‰æ–¹æ³•å­˜åœ¨ä¸€äº›é™åˆ¶ï¼Œä¾‹å¦‚ä¾èµ–COLMAPæä¾›çš„æ‘„åƒæœºå‚æ•°å’Œç¨€ç–ç‚¹äº‘åˆå§‹åŒ–ï¼Œç¼ºä¹å‡†ç¡®æ€§å’Œæ—¶é—´æ•ˆç‡ã€‚

- (2):è¿‡å»çš„æ–¹æ³•ä¸»è¦åŸºäºNeRFå’ŒGaussian Splattingï¼Œç„¶è€Œè¿™äº›æ–¹æ³•å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå¦‚ä¾èµ–å¤–éƒ¨ä¿¡æ¯ã€é•¿æ—¶é—´çš„é¢„å¤„ç†å’Œè®­ç»ƒæ—¶é—´ã€å¯¹åŠ¨æ€åœºæ™¯çš„è¡¨ç¤ºä¸å¤Ÿå‡†ç¡®ç­‰ã€‚

- (3):æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè‡ªé€‚åº”çš„æ–¹æ³•ï¼Œå­¦ä¹ é«˜ä¿çœŸ4Dåœºæ™¯è¡¨ç¤ºï¼Œå¹¶è‡ªé€‚åº”æ‘„åƒæœºå‚æ•°ã€‚è¯¥æ–¹æ³•åŒ…æ‹¬æå–2Dç‚¹ç‰¹å¾æ¥è¡¨ç¤º3Dç»“æ„ï¼Œç„¶åè”åˆä¼˜åŒ–æ‘„åƒæœºå‚æ•°å’Œ3Dç»“æ„æ¥å®ç°4Dåœºæ™¯ä¼˜åŒ–ã€‚

- (4):æœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªæ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ï¼Œè¯æ˜äº†å…¶åœ¨4Dæ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚
</code></pre><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-301d49be2f4e8a22c8b77021a373d934.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-943f2448f91afb60a72f6a93466398e1.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-46743dd4fd6de272e99deea3ad94b4ac.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-cb752928248c98233389d6a68f5cbb84.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-94b1a6297fd9bb1be9cdc3fbe53fc163.jpg" align="middle"></details><h2 id="Topo4D-Topology-Preserving-Gaussian-Splatting-for-High-Fidelity-4D-Head-Capture"><a href="#Topo4D-Topology-Preserving-Gaussian-Splatting-for-High-Fidelity-4D-Head-Capture" class="headerlink" title="Topo4D: Topology-Preserving Gaussian Splatting for High-Fidelity 4D Head   Capture"></a>Topo4D: Topology-Preserving Gaussian Splatting for High-Fidelity 4D Head Capture</h2><p><strong>Authors:X. Li, Y. Cheng, X. Ren, H. Jia, D. Xu, W. Zhu, Y. Yan</strong></p><p>4D head capture aims to generate dynamic topological meshes and corresponding texture maps from videos, which is widely utilized in movies and games for its ability to simulate facial muscle movements and recover dynamic textures in pore-squeezing. The industry often adopts the method involving multi-view stereo and non-rigid alignment. However, this approach is prone to errors and heavily reliant on time-consuming manual processing by artists. To simplify this process, we propose Topo4D, a novel framework for automatic geometry and texture generation, which optimizes densely aligned 4D heads and 8K texture maps directly from calibrated multi-view time-series images. Specifically, we first represent the time-series faces as a set of dynamic 3D Gaussians with fixed topology in which the Gaussian centers are bound to the mesh vertices. Afterward, we perform alternative geometry and texture optimization frame-by-frame for high-quality geometry and texture learning while maintaining temporal topology stability. Finally, we can extract dynamic facial meshes in regular wiring arrangement and high-fidelity textures with pore-level details from the learned Gaussians. Extensive experiments show that our method achieves superior results than the current SOTA face reconstruction methods both in the quality of meshes and textures. Project page: <a target="_blank" rel="noopener" href="https://xuanchenli.github.io/Topo4D/">https://xuanchenli.github.io/Topo4D/</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.00440v1">PDF</a></p><p><strong>Summary</strong><br>ä½¿ç”¨Topo4Dæ¡†æ¶è‡ªåŠ¨ç”Ÿæˆ4Då¤´éƒ¨ç½‘æ ¼å’Œ8Kçº¹ç†å›¾ï¼Œä»è€Œç®€åŒ–ç”µå½±å’Œæ¸¸æˆindustryä¸­çš„é¢éƒ¨æ•æ‰è¿‡ç¨‹ã€‚</p><p><strong>Key Takeaways</strong><br>â€¢ Topo4Dæ¡†æ¶ï¿½ï¿½ä»¥è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„4Då¤´éƒ¨ç½‘æ ¼å’Œ8Kçº¹ç†å›¾ã€‚<br>â€¢ è¯¥æ–¹æ³•å¯ä»¥ç›´æ¥ä»calibrated multi-view time-series imagesä¸­å­¦ä¹ é«˜è´¨é‡çš„å‡ ä½•å½¢çŠ¶å’Œçº¹ç†ã€‚<br>â€¢ Topo4Dä½¿ç”¨åŠ¨æ€3Dé«˜æ–¯åˆ†å¸ƒæ¥è¡¨ç¤ºæ—¶é—´åºåˆ—é¢éƒ¨ï¼Œä»¥ä¿æŒæ—¶é—´æ‹“æ‰‘ç¨³å®šæ€§ã€‚<br>â€¢ æ–¹æ³•å¯ä»¥æå–å…·æœ‰è§„åˆ™wireframeæ’åˆ—çš„åŠ¨æ€é¢éƒ¨ç½‘æ ¼å’Œé«˜ä¿çœŸåº¦çº¹ç†ã€‚<br>â€¢ å®éªŒç»“æœæ˜ï¼ŒTopo4Dæ–¹æ³•ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„é¢éƒ¨é‡å»ºæ–¹æ³•<br>â€¢ è¯¥æ–¹æ³•å¯ä»¥åº”ç”¨äºç”µå½±å’Œæ¸¸æˆindustryä¸­çš„é¢éƒ¨æ•æ‰è¿‡ç¨‹ã€‚<br>â€¢ é¡¹ç›®é¡µé¢ä¸º<a target="_blank" rel="noopener" href="https://xuanchenli.github.io/Topo4D/ã€‚">https://xuanchenli.github.io/Topo4D/ã€‚</a></p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: Topo4Dï¼šTopology-Preserving Gaussian Splattingï¼ˆæ‹“æ‰‘ä¿æŒé«˜æ–¯Splatingï¼‰</p></li><li><p>Authors: Xuanchen Li, Yuhao Cheng, Xingyu Ren, Haozhe Jia, Di Xu, Wenhan Zhu, Yichao Yan</p></li><li><p>Affiliation: ä¸Šæµ·äº¤é€šå¤§å­¦äººå·¥æ™ºèƒ½ç ”ç©¶æ‰€</p></li><li><p>Keywords: 4D Face Modeling Â· High Resolution Texture Generation</p></li><li><p>Urls: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.00440v1">https://arxiv.org/abs/2406.00440v1</a> , Github:None</p></li><li><p>Summary:</p></li></ol><ul><li><p>(1):æœ¬æ–‡ç ”ç©¶çš„èƒŒæ™¯æ˜¯å››ç»´å¤´éƒ¨æ•æ‰ï¼Œæ—¨åœ¨ä»è§†é¢‘ä¸­ç”Ÿï¿½ï¿½ï¿½åŠ¨æ€æ‹“æ‰‘ç½‘æ ¼å’Œå¯¹åº”çš„çº¹ç†å›¾ï¼Œå¹¿æ³›åº”ç”¨äºç”µå½±å’Œæ¸¸æˆä¸­æ¨¡æ‹Ÿé¢éƒ¨è‚Œè‚‰è¿åŠ¨å’Œæ¢å¤åŠ¨æ€çº¹ç†ç»†èŠ‚ã€‚</p></li><li><p>(2):è¿‡å»çš„æ–¹æ³•ä¸»è¦é‡‡ç”¨å¤šè§†å›¾ç«‹ä½“å’Œéåˆšæ€§å¯¹é½ï¼Œä½†æ˜¯è¿™ç§æ–¹æ³•æ˜“å‡ºé”™ä¸”éœ€è¦è‰ºæœ¯å®¶è€—æ—¶_manual_processingã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•æ—¨åœ¨ç®€åŒ–è¿™ä¸ªè¿‡ç¨‹ã€‚</p></li><li><p>(3):æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜¯Topo4Dæ¡†æ¶ï¼Œé¦–å…ˆå°†æ—¶åºé¢éƒ¨è¡¨ç¤ºä¸ºä¸€ç»„å…·æœ‰å›ºå®šæ‹“æ‰‘ç»“æ„çš„ä¸‰ç»´é«˜æ–¯å‡½æ•°ï¼Œç„¶åé€å¸§è¿›è¡Œå‡ ä½•å’Œçº¹ç†ä¼˜åŒ–ï¼Œä»¥å­¦ä¹ é«˜è´¨é‡çš„å‡ ä½•å’Œçº¹ç†åŒæ—¶ä¿æŒæ—¶åŸŸæ‹“æ‰‘ç¨³å®šæ€§ã€‚</p></li><li><p>(4):æœ¬æ–‡çš„æ–¹æ³•åœ¨å››ç»´å¤´éƒ¨æ•æ‰ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜äºå½“å‰æœ€ä¼˜æ–¹æ³•çš„ç»“æœï¼Œç”Ÿæˆçš„ç½‘æ ¼å’Œçº¹ç†è´¨é‡é«˜æ”¯æŒäº†ç”µå½±å’Œæ¸¸æˆä¸­çš„åº”ç”¨ç›®æ ‡ã€‚<br>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p></li></ul><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-044930c455fa1fcb8db237a77e2f901e.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-81f2cfd9126d74c5f6a8c92db3a7a1b9.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-3eba255e0bedcac1c79c02965998ba33.jpg" align="middle"></details><h2 id="MoDGS-Dynamic-Gaussian-Splatting-from-Causually-captured-Monocular-Videos"><a href="#MoDGS-Dynamic-Gaussian-Splatting-from-Causually-captured-Monocular-Videos" class="headerlink" title="MoDGS: Dynamic Gaussian Splatting from Causually-captured Monocular   Videos"></a>MoDGS: Dynamic Gaussian Splatting from Causually-captured Monocular Videos</h2><p><strong>Authors:Qingming Liu, Yuan Liu, Jiepeng Wang, Xianqiang Lv, Peng Wang, Wenping Wang, Junhui Hou</strong></p><p>In this paper, we propose MoDGS, a new pipeline to render novel-view images in dynamic scenes using only casually captured monocular videos. Previous monocular dynamic NeRF or Gaussian Splatting methods strongly rely on the rapid movement of input cameras to construct multiview consistency but fail to reconstruct dynamic scenes on casually captured input videos whose cameras are static or move slowly. To address this challenging task, MoDGS adopts recent single-view depth estimation methods to guide the learning of the dynamic scene. Then, a novel 3D-aware initialization method is proposed to learn a reasonable deformation field and a new robust depth loss is proposed to guide the learning of dynamic scene geometry. Comprehensive experiments demonstrate that MoDGS is able to render high-quality novel view images of dynamic scenes from just a casually captured monocular video, which outperforms baseline methods by a significant margin.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.00434v1">PDF</a></p><p><strong>Summary</strong><br>ä½¿ç”¨MoDGS.pipelineï¼Œä»…éœ€å•ç›®è§†é¢‘å³å¯æ¸²æŸ“åŠ¨æ€åœºæ™¯ä¸­çš„æ–°è§†å›¾å›¾åƒã€‚</p><p><strong>Key Takeaways</strong><br>â€¢ MoDGS.pipelineå¯ä»¥æ¸²æŸ“åŠ¨æ€åœºæ™¯ä¸­çš„æ–°è§†å›¾å›¾åƒï¼Œä»…éœ€å•ç›®è§†é¢‘ã€‚<br>â€¢ ä¹‹å‰çš„å•ç›®åŠ¨æ€NeRFæˆ–é«˜æ–¯å–·å°„æ–¹æ³•éœ€è¦å¿«é€Ÿç§»åŠ¨çš„è¾“å…¥æ‘„åƒæœºï¼Œä½†MoDGSå¯ä»¥å¤„ç†é™æ€æˆ–æ…¢é€Ÿç§»åŠ¨æ‘„åƒæœºçš„è¾“å…¥è§†é¢‘ã€‚<br>â€¢ MoDGSé‡‡ç”¨å•è§†å›¾æ·±åº¦ä¼°è®¡æ–¹æ³•æŒ‡å¯¼åŠ¨æ€åœºæ™¯çš„å­¦ä¹ ã€‚<br>â€¢ MoDGSæå‡ºäº†ä¸€ç§æ–°å‹çš„ä¸‰ç»´æ„ŸçŸ¥åˆå§‹åŒ–æ–¹æ³•æ¥å­¦ä¹ åˆç†çš„å˜å½¢åœºå’Œæ–°çš„é²æ£’æ·±åº¦æŸå¤±æ¥æŒ‡å¯¼åŠ¨æ€åœºæ™¯å‡ ä½•å­¦çš„å­¦ä¹ ã€‚<br>â€¢ å®éªŒç»“æœè¡¨æ˜ï¼ŒMoDGSå¯ä»¥æ¸²æŸ“é«˜è´¨é‡çš„åŠ¨æ€åœºæ™¯æ–°è§†å›¾å›¾åƒï¼Œè¿œè¶…baselineæ–¹æ³•ã€‚<br>â€¢ MoDGSå¯ä»¥å¤„ç†casually captured monocular videosã€‚<br>â€¢ MoDGSçš„æ–¹æ³•å¯ä»¥å­¦ä¹ åŠ¨æ€åœºæ™¯çš„å‡ ä½•å­¦å’Œå˜å½¢åœºã€‚</p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: Monocular Dynamic Gaussian Splatting (å•ç›®åŠ¨æ€é«˜æ–¯æ¶‚æŠ¹)</p></li><li><p>Authors: Liu et al.</p></li><li><p>Affiliation: æœªæä¾›</p></li><li><p>Keywords: Novel View Synthesis, Dynamic Scene, Monocular Video, Gaussian Splatting</p></li><li><p>Urls: None, Github:None</p></li><li><p>Summary:</p></li></ol><ul><li><p>(1):è¯¥è®ºæ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯æ–°è§†å›¾åˆæˆï¼ˆNovel View Synthesisï¼‰åœ¨åŠ¨æ€åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œè€Œç°æœ‰çš„æ–¹æ³•åœ¨å¤„ç†å•ç›®è§†é¢‘æ—¶å­˜åœ¨é™åˆ¶ã€‚</p></li><li><p>(2):è¿‡å»çš„æ–¹æ³•éœ€è¦å¤šè§†å›¾è§†é¢‘æˆ–å…·æœ‰æå¤§è¿åŠ¨çš„å•ç›®è§†é¢‘æ¥å®ç°é«˜è´¨é‡çš„æ–°è§†å›¾åˆæˆï¼Œä½†è¿™äº›æ–¹æ³•åœ¨å¤„ç†å¸¸è§„æ‹æ‘„çš„å•ç›®è§†é¢‘æ—¶æ•ˆæœä¸ä½³ã€‚</p></li><li><p>(3):æœ¬æ–‡æå‡ºäº†Monocular Dynamic Gaussian Splattingï¼ˆå•ç›®åŠ¨æ€é«˜æ–¯æ¶‚æŠ¹ï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡é‡‡ç”¨å•ç›®æ·±åº¦ä¼°è®¡ä¸‰ç»´awareåˆå§‹åŒ–æ¥å­¦ä¹ æ—¶é—´ç›¸å…³çš„å˜å½¢åœºï¼Œå¹¶ä½¿ç”¨ ordinal depth loss æ¥ç›‘ç£æ¸²æŸ“æ·±åº¦å›¾ã€‚</p></li><li><p>(4):æœ¬æ–‡çš„æ–¹æ³•åœ¨ä¸¤ç§æ•°æ®é›†å’Œä¸€ä¸ªè‡ªæ”¶é›†çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•å¯ä»¥å®ç°é«˜è´¨é‡çš„æ–°è§†å›¾åˆæˆï¼Œå¹¶ä¸”æ¯”ç°æœ‰çš„æ–¹æ³•æœ‰å¤§çš„æ€§èƒ½ä¼˜åŠ¿ã€‚</p></li></ul><ol><li>æ–¹æ³•ï¼š</li></ol><ul><li><p>(1)ï¼šç»™å®šä¸€æ®µéšæ„æ‹æ‘„çš„å•ç›®è§†é¢‘ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä»è¯¥è§†é¢‘ä¸­åˆæˆæ–°è§†å›¾å›¾åƒã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†è§†é¢‘æ‹†åˆ†æˆä¸€ç³»åˆ—å›¾åƒ{ğ¼ğ‘¡ |ğ‘¡ = 1, â€¦,ğ‘‡ }ï¼Œå¹¶å‡è®¾æ‰€æœ‰å›¾åƒçš„ç›¸æœºä½å§¿éƒ½æ˜¯å·²çŸ¥çš„ã€‚</p></li><li><p>(2)ï¼šå¯¹äºæ¯ä¸ªå›¾åƒ ğ¼ğ‘¡ï¼Œæˆ‘ä»¬ä½¿ç”¨å•è§†å›¾æ·±åº¦ä¼°ç®—å™¨ GeoWizard [Fu et al. 2024] ä¼°ç®—ä¸€ä¸ªæ·±åº¦å›¾ ğ·ğ‘¡ï¼Œå¹¶ä½¿ç”¨æµä¼°ç®—æ–¹æ³• RAFT [Teed and Deng 2020] ä¼°ç®—ä¸€ä¸ªäºŒç»´å…‰æµ ğ¹ğ‘¡ğ‘–â†’ğ‘¡ğ‘— ä¹‹é—´ ğ¼ğ‘¡ğ‘– å’Œ ğ¼ğ‘¡ğ‘— ã€‚</p></li><li><p>(3)ï¼šæˆ‘ä»¬åˆå§‹åŒ–å˜å½¢åœº ğ‘‡ğ‘¡ é€šè¿‡ä¸€ä¸ªä¸‰ç»´æ„ŸçŸ¥åˆå§‹åŒ–æ–¹æ¡ˆï¼Œå¦‚ Sec. 3.2 æ‰€è¿°ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ¸²æŸ“æŸå¤±å’Œä¸€ä¸ªæ–°å¼•å…¥çš„æ·±åº¦æŸå¤±æ¥è®­ç»ƒé«˜æ–¯ä½“å’Œå˜å½¢åœºï¼Œå¦‚ Sec. 3.3 æ‰€è¿°ã€‚</p></li><li><p>(4)ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ç»„é«˜æ–¯ä½“åœ¨å…¸å‹ç©ºé—´ä¸­ï¼Œæ¯ä¸ªé«˜æ–¯ä½“éƒ½æœ‰ä¸€ä¸ªä¸‰ç»´ä½ç½®ã€ä¸€ä¸ªå°ºåº¦å‘é‡ã€ä¸€ä¸ªæ—‹è½¬å’Œä¸€ä¸ªé¢œè‰²ï¼Œä»¥çƒè°å‡½æ•°è¡¨ç¤ºã€‚</p></li><li><p>(5)ï¼šæˆ‘ä»¬ä½¿ç”¨å˜å½¢åœº ğ‘‡ğ‘¡ å°†é«˜æ–¯ä½“ä»å…¸å‹ç©ºé—´å˜å½¢åˆ°ç‰¹å®šçš„æ—¶é—´æ­¥ ğ‘¡ï¼Œç„¶åä½¿ç”¨åˆ†è£‚æŠ€æœ¯æ¥æ¸²æŸ“å›¾åƒã€‚</p></li><li><p>(6)ï¼šåœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éµå¾ª 3D GS [Kerbl et al. 2023] ä¸­çš„åˆ†è£‚æŠ€æœ¯æ¥æ¸²æŸ“å›¾åƒã€‚</p></li></ul><ol><li>Conclusion:</li></ol><ul><li><p>(1):è¯¥ç¯‡å·¥ä½œçš„æ„ä¹‰åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„å•ç›®åŠ¨æ€é«˜æ–¯æ¶‚æŠ¹ï¼ˆMonocular Dynamic Gaussian Splattingï¼‰æ–¹æ³•ï¼Œèƒ½å¤Ÿä»éšæ„æ‹æ‘„çš„å•ç›®è§†é¢‘ä¸­åˆæˆé«˜è´¨é‡çš„æ–°è§†å›¾å›¾åƒï¼Œè¿™å¯¹æ–°è§†å›¾åˆæˆæŠ€æœ¯çš„å‘å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚</p></li><li><p>(2):åˆ›æ–°ç‚¹ï¼šè¯¥æ–¹æ³•å¼•å…¥äº†ä¸‰ç»´æ„ŸçŸ¥åˆå§‹åŒ–æ–¹æ¡ˆå’Œordinal depth lossï¼Œè§£å†³äº†å•ç›®è§†é¢‘æ–°è§†å›¾åˆæˆä¸­çš„æ·±åº¦ä¼°è®¡å’Œå˜å½¢åœºä¼˜åŒ–é—®é¢˜ï¼›æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªæ•°æ®é›†ä¸Šçš„æ€§èƒ½ä¼˜äºåŸºçº¿æ–¹æ³•ï¼›å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ•°æ®é›†æ¥è®­ç»ƒé«˜æ–¯ä½“å’Œå˜å½¢åœºã€‚</p></li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-1549178cb60d7f194174a1a27981ffde.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-037f8718c0a69bdd6927b8e59f439157.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-31d5b80b1fb6a6d144c84378c897ddf5.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ac6f4ffe1bf67aaa2e7f9e977ced2e27.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-29da24b0057e96725725e8333552d5e6.jpg" align="middle"></details><h2 id="ContextGS-Compact-3D-Gaussian-Splatting-with-Anchor-Level-Context-Model"><a href="#ContextGS-Compact-3D-Gaussian-Splatting-with-Anchor-Level-Context-Model" class="headerlink" title="ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model"></a>ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model</h2><p><strong>Authors:Yufei Wang, Zhihao Li, Lanqing Guo, Wenhan Yang, Alex C. Kot, Bihan Wen</strong></p><p>Recently, 3D Gaussian Splatting (3DGS) has become a promising framework for novel view synthesis, offering fast rendering speeds and high fidelity. However, the large number of Gaussians and their associated attributes require effective compression techniques. Existing methods primarily compress neural Gaussians individually and independently, i.e., coding all the neural Gaussians at the same time, with little design for their interactions and spatial dependence. Inspired by the effectiveness of the context model in image compression, we propose the first autoregressive model at the anchor level for 3DGS compression in this work. We divide anchors into different levels and the anchors that are not coded yet can be predicted based on the already coded ones in all the coarser levels, leading to more accurate modeling and higher coding efficiency. To further improve the efficiency of entropy coding, e.g., to code the coarsest level with no already coded anchors, we propose to introduce a low-dimensional quantized feature as the hyperprior for each anchor, which can be effectively compressed. Our work pioneers the context model in the anchor level for 3DGS representation, yielding an impressive size reduction of over 100 times compared to vanilla 3DGS and 15 times compared to the most recent state-of-the-art work Scaffold-GS, while achieving comparable or even higher rendering quality.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.20721v1">PDF</a></p><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>Title: ContextGSï¼šç´§å‡‘çš„ä¸‰ç»´é«˜æ–¯ Splatting å¸¦é”šç‚¹çº§åˆ«ä¸Šä¸‹æ–‡æ¨¡å‹ (Compact 3D Gaussian Splatting with Anchor Level Context Model)</li></ol><ol><li>Authors: Yufei Wang, Zhihao Li, Lanqing Guo, Wenhan Yang, Alex C. Kot, Bihan Wen</li></ol><ol><li>Affiliation: å—æ´‹ç†å·¥å¤§å­¦</li></ol><ol><li>Keywords: 3D Gaussian Splatting, novel view synthesis, compression, autoregressive model</li></ol><ol><li>Urls: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2405.20721">https://arxiv.org/abs/2405.20721</a>, Github: <a target="_blank" rel="noopener" href="https://github.com/wyf0912/ContextGS">https://github.com/wyf0912/ContextGS</a></li></ol><ol><li>Summary:</li></ol><pre><code>- (1):æœ€è¿‘ï¼Œä¸‰ç»´é«˜æ–¯ Splattingï¼ˆ3DGSï¼‰æ¡†æ¶åœ¨æ–°è§†å›¾åˆæˆæ–¹é¢å±•ç°å‡ºå¾ˆé«˜çš„æ½œåŠ›ï¼Œæä¾›äº†å¿«é€Ÿçš„æ¸²æŸ“é€Ÿåº¦å’Œé«˜ä¿çœŸåº¦ã€‚ç„¶è€Œï¼Œé«˜æ–¯ä½“çš„æ•°é‡åŠå…¶å…³è”å±æ€§éœ€è¦æœ‰æ•ˆçš„å‹ç¼©æŠ€æœ¯ã€‚


- (2):ç°æœ‰çš„æ–¹æ³•ä¸»è¦ç‹¬ç«‹åœ°å‹ç¼©ç¥ç»é«˜æ–¯ä½“ï¼Œå¿½è§†äº†å®ƒä»¬ä¹‹é—´çš„äº¤äº’å’Œç©ºé—´ä¾èµ–æ€§ã€‚è¿™ç§æ–¹æ³•å­˜åœ¨ç©ºé—´å†—ä½™çš„é—®é¢˜ï¼Œå½±å“äº†å‹ç¼©æ•ˆç‡ã€‚


- (3):æœ¬æ–‡æå‡ºäº†ä¸€ç§é”šç‚¹çº§åˆ«çš„è‡ªå›å½’æ¨¡å‹ï¼Œç”¨äºå‹ç¼©ä¸‰ç»´é«˜æ–¯ Splattingã€‚æˆ‘ä»¬å°†é”šç‚¹åˆ†ä¸ºä¸åŒçš„çº§åˆ«ï¼Œå¹¶ä½¿ç”¨å·²ç»ç¼–ç çš„é”šç‚¹æ¥é¢„æµ‹æœªç¼–ç çš„é”šç‚¹ï¼Œæé«˜äº†å‹ç¼©æ•ˆç‡ã€‚


- (4):æœ¬æ–‡çš„æ–¹æ³•åœ¨æ–°è§†å›¾åˆæˆä»»åŠ¡å–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ï¼Œæ¸²æŸ“è´¨é‡å’Œé€Ÿåº¦éƒ½å¾—åˆ°äº†æï¼ŒåŒæ—¶ä¹Ÿå®ç°äº†é«˜è¾¾15å€çš„å‹ç¼©æ¯”ã€‚
</code></pre><ol><li>æ–¹æ³•ï¼š</li></ol><ul><li>(1)ï¼šå°†é”šç‚¹åˆ†ä¸ºä¸åŒçš„çº§åˆ«ï¼Œä½¿ç”¨å¯è¿½æº¯çš„æ˜ å°„å…³ç³»åœ¨ç›¸é‚»çº§åˆ«ä¹‹é—´ï¼ˆanchor partitioning strategyï¼‰ï¼Œä»¥å®ç°é«˜æ•ˆçš„å‹ç¼©å’Œè§£å‹ç¼©ã€‚</li></ul><ul><li>(2)ï¼šä½¿ç”¨è‡ªå›å½’æ¨¡å‹å¯¹é”šç‚¹è¿›è¡Œç¼–ç ï¼Œä»¥é¢„æµ‹æœªç¼–ç çš„é”šç‚¹æé«˜å‹ç¼©æ•ˆç‡ï¼ˆautoregressive model for anchor codingï¼‰ï¼›</li></ul><ul><li>(3)ï¼šä½¿ç”¨åŸºäºhyperpriorçš„ä¸Šä¸‹æ–‡æ¨¡å‹æ¥æµ‹é”šç‚¹çš„å±æ€§ï¼Œè¿›ä¸€æ­¥æé«˜å‹ç¼©æ•ˆç‡ï¼ˆhyperprior-based context model for anchor attribute predictionï¼‰ï¼›</li></ul><ul><li>(4)ï¼šä½¿ç”¨åŸºäºvoxel sizeçš„æ–¹æ³•å¯¹é”šç‚¹è¿›è¡Œåˆ†åŒºï¼Œå®ç°é«˜æ•ˆçš„å‹ç¼©å’Œè§£å‹ç¼©ï¼ˆvoxel size-based method for anchor partitioningï¼‰ï¼›</li></ul><ul><li>(5)ï¼šä½¿ç”¨ binary search æ¥ç¡®å®švoxel sizeçš„å‚æ•°ï¼Œä»¥é¿å…å¯¹æ¯ä¸ªåœºæ™¯çš„å‚æ•°å¾®è°ƒï¼ˆbinary search for voxel size parameter determinationï¼‰ï¼›</li></ul><ul><li>(6)ï¼šä½¿ç”¨åŸºäº entropy çš„æ–¹æ³•å¯¹é”šç‚¹çš„å±æ€§è¿›è¡Œç¼–ç ï¼Œå®ç°é«˜æ•ˆçš„å‹ç¼©ï¼ˆentropy-based method for anchor attribute codingï¼‰ï¼›</li></ul><ul><li>(7)ï¼šä½¿ç”¨joint optimization çš„æ–¹æ³•åŒæ—¶ä¼˜åŒ– bitrate å’Œ rendering lossï¼Œä»¥å®ç°é«˜è´¨é‡çš„æ–°è§†å›¾åˆæˆï¼ˆjoint optimization for bitrate and rendering lossï¼‰</li></ul><ul><li>(8)ï¼šä½¿ç”¨ Scaffold-GS æ¡†æ¶æ¥å®ç°æ–°è§†å›¾åˆæˆï¼Œå¹¶åœ¨æµ‹è¯•é˜¶æ®µä¸éœ€è¦å¼•å…¥é¢å¤–çš„å¼€é”€ï¼ˆScaffold-GS framework for novel view synthesisï¼‰.</li></ul><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6a81c98ff4646b8801ce48fd00017484.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-4f113e2e6fa2e780c2e467c1b0df0909.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-ea99a9dead64e65ce89c907d223689ca.jpg" align="middle"></details><h2 id="NPGA-Neural-Parametric-Gaussian-Avatars"><a href="#NPGA-Neural-Parametric-Gaussian-Avatars" class="headerlink" title="NPGA: Neural Parametric Gaussian Avatars"></a>NPGA: Neural Parametric Gaussian Avatars</h2><p><strong>Authors:Simon Giebenhain, Tobias Kirschstein, Martin RÃ¼nz, Lourdes Agapito, Matthias NieÃŸner</strong></p><p>The creation of high-fidelity, digital versions of human heads is an important stepping stone in the process of further integrating virtual components into our everyday lives. Constructing such avatars is a challenging research problem, due to a high demand for photo-realism and real-time rendering performance. In this work, we propose Neural Parametric Gaussian Avatars (NPGA), a data-driven approach to create high-fidelity, controllable avatars from multi-view video recordings. We build our method around 3D Gaussian Splatting for its highly efficient rendering and to inherit the topological flexibility of point clouds. In contrast to previous work, we condition our avatarsâ€™ dynamics on the rich expression space of neural parametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we distill the backward deformation field of our underlying NPHM into forward deformations which are compatible with rasterization-based rendering. All remaining fine-scale, expression-dependent details are learned from the multi-view videos. To increase the representational capacity of our avatars, we augment the canonical Gaussian point cloud using per-primitive latent features which govern its dynamic behavior. To regularize this increased dynamic expressivity, we propose Laplacian terms on the latent features and predicted dynamics. We evaluate our method on the public NeRSemble dataset, demonstrating that NPGA significantly outperforms the previous state-of-the-art avatars on the self-reenactment task by 2.6 PSNR. Furthermore, we demonstrate accurate animation capabilities from real-world monocular videos.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2405.19331v1">PDF</a> Project Page: see <a target="_blank" rel="noopener" href="https://simongiebenhain.github.io/NPGA/">https://simongiebenhain.github.io/NPGA/</a> ; Youtube Video: see <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=NGRxAYbIkus">https://www.youtube.com/watch?v=NGRxAYbIkus</a></p><p>sorry, æ‚¨çš„ipå·²ç”±äºè§¦å‘é˜²æ»¥ç”¨æ£€æµ‹è€Œè¢«å°ç¦,å¯èƒ½æ˜¯å› ä¸ºä½¿ç”¨äº‘æœåŠ¡å™¨å¦‚è…¾è®¯äº‘æˆ–è€…å›½å¤–ä»£ç†(vpn)è®¿é—®æœ¬ç½‘ç«™ï¼Œå¦‚æœä½¿ç”¨äº†vpnï¼Œå…³é—­vpnæˆ–ä»£ç†å³å¯ç»§ç»­ä½¿ç”¨,æœ¬æœåŠ¡ç½‘å€æ˜¯<a target="_blank" rel="noopener" href="https://chat18.aichatos8.com">https://chat18.aichatos8.com</a> å¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123 æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://binjie09.shop">https://binjie09.shop</a> è‡ªåŠ©è´­ä¹°key, è®¤ä¸ºæ˜¯è¯¯å°éœ€è¦è§£å°çš„è¯·å‰å¾€<a target="_blank" rel="noopener" href="https://www.ip.cn/">https://www.ip.cn/</a> æŸ¥è¯¢ipä¿¡æ¯,å¹¶å‘é€ä¿¡æ¯è‡³é‚®ä»¶ gpt33@binjie.site ï¼Œç«™é•¿ä¼šå®šæœŸçœ‹é‚®ä»¶å¹¶å¤„ç†è§£å°å’Œåˆä½œé—®é¢˜ï¼Œå¦‚éœ€è°ƒç”¨æ¥å£è¯·è§æ¥å£æ–‡æ¡£<a target="_blank" rel="noopener" href="https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123">https://apifox.com/apidoc/shared-803d9df6-a071-4b3e-9d69-ea1281614d82ï¼Œå¦‚éœ€åˆä½œæ¥å£è°ƒç”¨è¯·è”ç³»å¾®ä¿¡chatkf123</a> æˆ–è€…å‰å¾€ <a target="_blank" rel="noopener" href="https://cat.gptxyy.cn">https://cat.gptxyy.cn</a> æ³¨å†Œä½¿ç”¨ï¼ˆå¯ä»˜è´¹ä½¿ç”¨gpt4 æ³¨å†Œå¯å…è´¹ä½¿ç”¨3.5ï¼‰</p><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: NPGAï¼š Neural Parametric Gaussian Avatarsï¼ˆNPGAï¼šç¥ç»å‚æ•°é«˜æ–¯å¤´åƒï¼‰</p></li><li><p>Authors: SIMON GIEBENHAIN, TOBIAS KIRSCHSTEIN, MARTIN RÃœNZ, LOURDES AGAPITO, MATTHIAS NIESSNER</p></li><li><p>Affiliation: å¾·å›½æ…•å°¼é»‘å·¥ä¸šå¤§å­¦</p></li><li><p>Keywords: Neural Parametric Gaussian Avatars, 3D Gaussian Splatting, Digital Humans, Avatar Reconstruction</p></li><li><p>Urls: <a target="_blank" rel="noopener" href="https://simongiebenhain.github.io/NPGA/">https://simongiebenhain.github.io/NPGA/</a>, Github:None</p></li><li><p>Summary:</p></li></ol><ul><li>(1):æœ¬æ–‡çš„ç ”ç©¶èƒŒæ™¯æ˜¯åˆ›å»ºé«˜åº¦é€¼çœŸçš„æ•°å­—å¤´åƒï¼Œç”¨äºç”µå½±ã€æ¸¸æˆã€AR/VR ç”µä¿¡ä¼šè®®å’Œå…ƒå®‡å®™ç­‰é¢†åŸŸã€‚</li></ul><ul><li>(2):è¿‡å»çš„æ–¹æ³•ä¸»è¦åŸºäºä¸‰ç»´å¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰ï¼Œä½†æ˜¯è¿™äº›æ–¹æ³•å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œä¾‹å¦‚ç»†èŠ‚ä¸å¤Ÿä¸°å¯Œã€èº«ä»½å’Œè¡¨æƒ…æè¿°ä¸å¤Ÿåˆ†ç¦»ç­‰ã€‚æœ¬æ–‡çš„æ–¹æ³•motivated byè¿™äº›é—®é¢˜ï¼Œæ—¨åœ¨åˆ›å»ºæ›´åŠ é€¼çœŸçš„æ•°å­—å¤´åƒã€‚</li></ul><ul><li>(3):æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•æ˜¯åŸºäºç¥ç»å‚æ•°é«˜æ–¯å¤´åƒï¼ˆNPGAï¼‰ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ä¸‰ç»´é«˜æ–¯ç‚¹äº‘å’Œç¥ç»å‚æ•°å¤´æ¨¡å‹ï¼ˆNPHMï¼‰æ¥åˆ›å»ºæ•°å­—å¤´åƒï¼Œå¹¶ä½¿ç”¨per-primitiveç‰¹å¾æ¥å¢å¼ºå¤´åƒçš„åŠ¨æ€è¡¨è¾¾èƒ½åŠ›ã€‚</li></ul><ul><li>(4):æœ¬æ–‡çš„æ–¹æ³•åœ¨NeRSembleæ•°æ®é›†ä¸Šçš„è‡ªreenactmentä»»åŠ¡ä¸Šå–å¾—äº†çº¦2.6 PSNRçš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜å±•ç¤ºäº†ä»çœŸå®ä¸–ç•Œå•ç›®è§†é¢‘çš„ç²¾å‡†åŠ¨ç”»èƒ½åŠ›ã€‚</li></ul><ol><li>æ–¹æ³•ï¼š</li></ol><ul><li><p>(1):é¦–å…ˆï¼Œä½œè€…ä½¿ç”¨ä¸‰ç»´é«˜æ–¯ç‚¹äº‘ï¼ˆ3D Gaussian Splattingï¼‰å°†å¤´åƒè¡¨é¢è¡¨ç¤ºä¸ºä¸€ç»„é«˜æ–¯åˆ†å¸ƒï¼Œè¿™äº›åˆ†å¸ƒå¯ä»¥æ•æ‰å¤´åƒçš„å±€éƒ¨å‡ ä½•å½¢çŠ¶å’Œç»†èŠ‚ç‰¹å¾ã€‚</p></li><li><p>(2):ç„¶åï¼Œä½œè€…å¼•å…¥ç¥ç»å‚æ•°å¤´æ¨¡å‹ï¼ˆNPHMï¼‰ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨ç¥ç»ç½‘ç»œå­¦ä¹ å¤´åƒçš„å‚æ•°è¡¨ç¤ºï¼ŒåŒ…æ‹¬èº«ä»½ã€è¡¨æƒ…å’Œå§¿æ€ä¿¡æ¯ã€‚</p></li><li><p>(3):æ¥ç€ï¼Œä½œè€…ä½¿ç”¨ä¸‰ç»´é«˜æ–¯ç‚¹äº‘å’Œç¥ç»å‚æ•°å¤´æ¨¡å‹ç»“åˆï¼Œç”Ÿæˆæ•°å­—å¤´åƒçš„per-primitiveç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯ä»¥å¢å¼ºå¤´åƒçš„åŠ¨æ€è¡¨è¾¾èƒ½åŠ›ã€‚</p></li><li><p>(4):åœ¨å¤´åƒé‡å»ºé˜¶æ®µï¼Œä½œè€…ä½¿ç”¨per-primitiveç‰¹å¾å’Œä¸‰ç»´é«˜æ–¯ç‚¹äº‘è¿›è¡Œå¤´åƒé‡å»ºï¼Œç”Ÿæˆé«˜è´¨é‡çš„æ•°å­—å¤´åƒã€‚</p></li><li><p>(5):æœ€åï¼Œä½œè€…åœ¨NeRSembleæ•°æ®é›†ä¸Šè¿›è¡Œè‡ªreenactmentä»»åŠ¡çš„å®éªŒï¼Œè¯æ˜äº†NPGAæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å±•ç¤ºäº†ä»çœŸå®ä¸–ç•Œå•ç›®è§†é¢‘çš„ç²¾å‡†åŠ¨ç”»èƒ½åŠ›ã€‚</p></li><li><p>(6):ä½œè€…è¿˜è®¨è®ºäº†NPGAæ–¹æ³•çš„ä¼˜ç‚¹ï¼ŒåŒ…æ‹¬å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„æ•°å­—å¤´åƒã€èƒ½å¤Ÿæ•æ‰å¤´åƒçš„ç»†èŠ‚ç‰¹å¾å’ŒåŠ¨æ€è¡¨è¾¾èƒ½åŠ›ç­‰ã€‚</p></li></ul><ol><li>ç»“è®ºï¼š</li></ol><ul><li><p>(1):æœ¬æ–‡çš„ç ”ç©¶å·¥ä½œå¯¹äºåˆ›å»ºé«˜åº¦é€¼çœŸçš„æ•°å­—å¤´åƒå…·æœ‰é‡è¦æ„ä¹‰ï¼Œå¯ä»¥åº”ç”¨äºç”µå½±ã€æ¸¸æˆã€AR/VR ç”µä¿¡ä¼šè®®å’Œå…ƒå®‡å®™ç­‰é¢†åŸŸï¼Œæé«˜æ•°å­—å¤´åƒçš„è¡¨è¾¾èƒ½åŠ›å’Œé€¼çœŸåº¦ã€‚</p></li><li><p>(2):åˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºçš„NPGAæ–¹æ³•å°†ä¸‰ç»´é«˜æ–¯ç‚¹äº‘å’Œç¥ç»å‚æ•°å¤´æ¨¡å‹ç»“åˆï¼Œç”Ÿæˆæ•°å­—å¤´åƒçš„per-primitiveç‰¹å¾ï¼Œæé«˜äº†å¤´åƒçš„åŠ¨æ€è¡¨è¾¾èƒ½åŠ›å’Œç»†èŠ‚ç‰¹å¾æ•æ‰èƒ½åŠ›ï¼›æ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨NeRSembleæ•°æ®é›†ä¸Šçš„è‡ªreenactmentä»»åŠ¡ä¸Šå–å¾—äº†çº¦2.6 PSNRçš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼›å·¥ä½œé‡ï¼šæœ¬æ–‡çš„æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä½¿ç”¨èŒƒå›´ã€‚</p></li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-e1ebdb40880659f3f276da0e13675a00.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-fc4ed51dc083b8b6a51414491a73d806.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f81503095d5f9b2100c356802a0daa7c.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3db991818ec4bced433235a789fd7993.jpg" align="middle"></details></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io/2024/06/05/Paper/2024-06-05/3DGS/">https://kedreamix.github.io/2024/06/05/Paper/2024-06-05/3DGS/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜:</span> <span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/3DGS/">3DGS</a></div><div class="post_share"><div class="social-share" data-image="https://picx.zhimg.com/v2-2196bb11e15de7b5d3440823b4c92ca5.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>èµåŠ©</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/06/05/Paper/2024-06-05/NeRF/" title="NeRF"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2bdb0ecbbc3a0a2420781e472b68ba52.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">NeRF</div></div></a></div><div class="next-post pull-right"><a href="/2024/06/05/Paper/2024-06-05/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/80/v2-890676236f48f9a7d915a0c42c40aa38.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">Diffusion Models</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>ç›¸å…³æ¨è</span></div><div class="relatedPosts-list"><div><a href="/2024/01/25/Paper/3DGS%20Survey/" title="3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-25</div><div class="title">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting</div></div></a></div><div><a href="/2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" title="è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesis"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-01</div><div class="title">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“ Awesome-Talking-Head-Synthesis</div></div></a></div><div><a href="/2024/01/24/Paper/2024-01-24/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-3d3dcd00c27bc3d320b23d4247ae79f3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-24</div><div class="title">3DGS</div></div></a></div><div><a href="/2024/01/30/Paper/2024-01-30/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2032721a60695f2d41ac96f75dec65a2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">3DGS</div></div></a></div><div><a href="/2024/02/13/Paper/2024-02-13/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-785f0dd46228bdf108d1677b776eeb58.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-13</div><div class="title">3DGS</div></div></a></div><div><a href="/2024/02/02/Paper/2024-02-02/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-e4e5570dfa99dfac9b297f7650c717c3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-02</div><div class="title">3DGS</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-06-05-%E6%9B%B4%E6%96%B0"><span class="toc-text">2024-06-05 æ›´æ–°</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#DDGS-CT-Direction-Disentangled-Gaussian-Splatting-for-Realistic-Volume-Rendering"><span class="toc-text">DDGS-CT: Direction-Disentangled Gaussian Splatting for Realistic Volume Rendering</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#WE-GS-An-In-the-wild-Efficient-3D-Gaussian-Representation-for-Unconstrained-Photo-Collections"><span class="toc-text">WE-GS: An In-the-wild Efficient 3D Gaussian Representation for Unconstrained Photo Collections</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#OpenGaussian-Towards-Point-Level-3D-Gaussian-based-Open-Vocabulary-Understanding"><span class="toc-text">OpenGaussian: Towards Point-Level 3D Gaussian-based Open Vocabulary Understanding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#FastLGS-Speeding-up-Language-Embedded-Gaussians-with-Feature-Grid-Mapping"><span class="toc-text">FastLGS: Speeding up Language Embedded Gaussians with Feature Grid Mapping</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DreamPhysics-Learning-Physical-Properties-of-Dynamic-3D-Gaussians-with-Video-Diffusion-Priors"><span class="toc-text">DreamPhysics: Learning Physical Properties of Dynamic 3D Gaussians with Video Diffusion Priors</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Self-Calibrating-4D-Novel-View-Synthesis-from-Monocular-Videos-Using-Gaussian-Splatting"><span class="toc-text">Self-Calibrating 4D Novel View Synthesis from Monocular Videos Using Gaussian Splatting</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Topo4D-Topology-Preserving-Gaussian-Splatting-for-High-Fidelity-4D-Head-Capture"><span class="toc-text">Topo4D: Topology-Preserving Gaussian Splatting for High-Fidelity 4D Head Capture</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MoDGS-Dynamic-Gaussian-Splatting-from-Causually-captured-Monocular-Videos"><span class="toc-text">MoDGS: Dynamic Gaussian Splatting from Causually-captured Monocular Videos</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ContextGS-Compact-3D-Gaussian-Splatting-with-Anchor-Level-Context-Model"><span class="toc-text">ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NPGA-Neural-Parametric-Gaussian-Avatars"><span class="toc-text">NPGA: Neural Parametric Gaussian Avatars</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image:url('https://picx.zhimg.com/v2-2196bb11e15de7b5d3440823b4c92ca5.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>æ¡†æ¶</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="ç®€ç¹è½¬æ¢">ç°¡</button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const e of document.querySelectorAll('script[type^="math/tex"]')){const a=!!e.type.match(/; *mode=display/),n=new t.options.MathItem(e.textContent,t.inputJax[0],a),s=document.createTextNode("");e.parentNode.replaceChild(s,e),n.start={node:s,delim:"",n:0},n.end={node:s,delim:"",n:0},t.math.push(n)}},""]}}};const t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t)}</script></div><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("å·²æŒ‚è½½butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/25/Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="2024/01/25/Paper/3DGS Survey/" alt="">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting ä»Šå¤©æƒ³ä»‹ç»çš„æ˜¯`ZJU`å¸¦æ¥çš„`3DGS`çš„é¦–ç¯‡ç»¼è¿°`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="2024/01/25/Paper/3DGS Survey/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">CUDAç¼–ç¨‹å­¦ä¹ ï¼šè‡ªå®šä¹‰Pytorch+cpp/cuda extension</a><div class="blog-slider__text">è™½ç„¶è¯´PyTorchæä¾›äº†ä¸°å¯Œçš„ä¸ç¥ç»ç½‘ç»œã€å¼ é‡ä»£æ•°ã€æ•°æ®å¤„ç†ç­‰ç›¸å…³çš„æ“ä½œï¼Œä½†æ˜¯æœ‰æ—¶å€™ä½ å¯èƒ½éœ€è¦**æ›´å®šåˆ¶åŒ–çš„æ“ä½œ**ï¼Œæ¯”å¦‚ä½¿ç”¨è®ºæ–‡ä¸­çš„æ–°å‹æ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…å®ç°ä½œä¸ºç ”ç©¶ä¸€éƒ¨åˆ†å¼€å‘çš„æ“ä½œã€‚åœ¨PyTorchä¸­ï¼Œæœ€ç®€å•çš„é›†æˆè‡ªå®šä¹‰æ“ä½œçš„æ–¹å¼æ˜¯åœ¨Pythonä¸­ç¼–å†™ï¼Œé€šè¿‡æ‰©å±•Functionå’ŒModuleæ¥å®ç°ï¼Œ</div><a class="blog-slider__button" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesisï¼Œ è¿™ä»½èµ„æºåº“æ•´ç†äº†ä¸ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)å’Œç¥ç»è¾å°„åœº(NeRF)ç›¸å…³çš„è®ºæ–‡ã€ä»£ç å’Œèµ„æº,é‡ç‚¹å…³æ³¨åŸºäºå›¾åƒå’ŒéŸ³é¢‘çš„è™šæ‹Ÿè®²è¯å¤´åˆæˆè®ºæ–‡åŠå·²å‘å¸ƒä»£ç ã€‚å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªä»“åº“æœ‰ç”¨,è¯·starâ­æ”¯æŒ!</div><a class="blog-slider__button" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/17/Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023/12/17/Project/ChatPaperFree/" alt="">ChatPaperFree GeminiProï¼ˆä¸€åˆ†é’Ÿè¯»è®ºæ–‡ï¼‰</a><div class="blog-slider__text">ChatPaperFreeæ˜¯ä¸€ä¸ªåŸºäºChatGPTçš„è‡ªåŠ¨è®ºæ–‡æ‘˜è¦ç”Ÿæˆå™¨ï¼Œåœ¨ChatPaperçš„åŸºç¡€ä¸Šè¿›è¡Œçš„æ›´æ–°ï¼Œé‡‡ç”¨äº†æœ€è¿‘ç”±Googleå¼€æºçš„Gemini Proå¤§æ¨¡å‹ã€‚ç›®å‰,æˆ‘ä»¬èƒ½å¤Ÿå¯¹ç”¨æˆ·è¾“å…¥çš„è®ºæ–‡è¿›è¡Œè‡ªåŠ¨æ€»ç»“ã€‚æœªæ¥,æˆ‘è¿˜è®¡åˆ’åŠ å…¥å¯¹è®ºæ–‡å›¾ç‰‡/è¡¨æ ¼/å…¬å¼çš„è¯†åˆ« extraction,ä»è€Œç”Ÿæˆæ›´å…¨é¢è€Œæ˜“è¯»çš„æ€»ç»“ã€‚</div><a class="blog-slider__button" href="2023/12/17/Project/ChatPaperFree/" alt="">è¯¦æƒ…   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script></body></html>