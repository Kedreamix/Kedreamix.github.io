<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Diffusion Models | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-28  AID Attention Interpolation of Text-to-Image Diffusion"><meta property="og:type" content="article"><meta property="og:title" content="Diffusion Models"><meta property="og:url" content="https://kedreamix.github.io/2024/03/28/Paper/2024-03-28/Diffusion%20Models/index.html"><meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World"><meta property="og:description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-28  AID Attention Interpolation of Text-to-Image Diffusion"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://picx.zhimg.com/v2-7e8b388fdf7ef71288f5c4468e2d6aa6.jpg"><meta property="article:published_time" content="2024-03-28T02:56:57.000Z"><meta property="article:modified_time" content="2024-03-28T02:56:57.223Z"><meta property="article:author" content="Kedreamix"><meta property="article:tag" content="Diffusion Models"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://picx.zhimg.com/v2-7e8b388fdf7ef71288f5c4468e2d6aa6.jpg"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/2024/03/28/Paper/2024-03-28/Diffusion%20Models/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-74LZ5BEQQ1")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!0,languages:{hits_empty:"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}",hits_stats:"å…±æ‰¾åˆ° ${hits} ç¯‡æ–‡ç« "}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"ç¹",msgToSimplifiedChinese:"ç®€"},noticeOutdate:{limitDay:500,position:"top",messagePrev:"It has been",messageNext:"days since the last update, the content of the article may be outdated."},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"å¤åˆ¶æˆåŠŸ",error:"å¤åˆ¶é”™è¯¯",noSupport:"æµè§ˆå™¨ä¸æ”¯æŒ"},relativeDate:{homepage:!0,post:!0},runtime:"å¤©",dateSuffix:{just:"åˆšåˆš",min:"åˆ†é’Ÿå‰",hour:"å°æ—¶å‰",day:"å¤©å‰",month:"ä¸ªæœˆå‰"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js",buttonText:"åŠ è½½æ›´å¤š"},isPhotoFigcaption:!0,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Diffusion Models",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-03-28 10:56:57"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme"),o=(new Date).getHours();void 0===t?o<=6||o>=24?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode();const a=saveToLocal.get("aside-status");void 0!==a&&("hide"===a?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 7.0.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml"></head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",(()=>{o()}))})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">285</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://picx.zhimg.com/v2-7e8b388fdf7ef71288f5c4468e2d6aa6.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Diffusion Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2024-03-28T02:56:57.000Z" title="å‘è¡¨äº 2024-03-28 10:56:57">2024-03-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2024-03-28T02:56:57.223Z" title="æ›´æ–°äº 2024-03-28 10:56:57">2024-03-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">å­—æ•°æ€»è®¡:</span><span class="word-count">15.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»æ—¶é•¿:</span><span>55åˆ†é’Ÿ</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Diffusion Models"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-28-æ›´æ–°"><a href="#2024-03-28-æ›´æ–°" class="headerlink" title="2024-03-28 æ›´æ–°"></a>2024-03-28 æ›´æ–°</h1><h2 id="AID-Attention-Interpolation-of-Text-to-Image-Diffusion"><a href="#AID-Attention-Interpolation-of-Text-to-Image-Diffusion" class="headerlink" title="AID: Attention Interpolation of Text-to-Image Diffusion"></a>AID: Attention Interpolation of Text-to-Image Diffusion</h2><p><strong>Authors:Qiyuan He, Jinghao Wang, Ziwei Liu, Angela Yao</strong></p><p>Conditional diffusion models can create unseen images in various settings, aiding image interpolation. Interpolation in latent spaces is well-studied, but interpolation with specific conditions like text or poses is less understood. Simple approaches, such as linear interpolation in the space of conditions, often result in images that lack consistency, smoothness, and fidelity. To that end, we introduce a novel training-free technique named Attention Interpolation via Diffusion (AID). Our key contributions include 1) proposing an inner/outer interpolated attention layer; 2) fusing the interpolated attention with self-attention to boost fidelity; and 3) applying beta distribution to selection to increase smoothness. We also present a variant, Prompt-guided Attention Interpolation via Diffusion (PAID), that considers interpolation as a condition-dependent generative process. This method enables the creation of new images with greater consistency, smoothness, and efficiency, and offers control over the exact path of interpolation. Our approach demonstrates effectiveness for conceptual and spatial interpolation. Code and demo are available at <a target="_blank" rel="noopener" href="https://github.com/QY-H00/attention-interpolation-diffusion">https://github.com/QY-H00/attention-interpolation-diffusion</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17924v1">PDF</a></p><p><strong>æ‘˜è¦</strong><br>æ³¨æ„åŠ›æ’å€¼æ‰©æ•£ï¼ˆAIDï¼‰ï¼šä¸€ç§æ— éœ€è®­ç»ƒçš„æ¡ä»¶æ’å€¼æ–°æŠ€æœ¯ï¼Œå¯ç”Ÿæˆé«˜åº¦ä¸€è‡´ã€å¹³æ»‘ä¸”é€¼çœŸçš„å›¾åƒã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>æå‡ºå†…å±‚/å¤–å±‚æ’å€¼æ³¨æ„åŠ›å±‚ï¼Œä»¥å¢å¼ºæ’å€¼è´¨é‡ã€‚</li><li>èåˆæ’å€¼æ³¨æ„åŠ›å’Œè‡ªæ³¨æ„åŠ›ï¼Œæå‡ç”Ÿæˆå›¾åƒçš„ä¿çœŸåº¦ã€‚</li><li>åº”ç”¨è´å¡”åˆ†å¸ƒé€‰æ‹©ï¼Œæé«˜æ’å€¼çš„å¹³æ»‘åº¦ã€‚</li><li>æå‡ºæç¤ºå¼•å¯¼çš„æ³¨æ„åŠ›æ’å€¼æ‰©æ•£ï¼ˆPAIDï¼‰å˜ä½“ï¼Œå°†æ’å€¼è§†ä¸ºæ¡ä»¶ä¾èµ–çš„ç”Ÿæˆè¿‡ç¨‹ã€‚</li><li>æ§åˆ¶æ’å€¼çš„ç¡®åˆ‡è·¯å¾„ï¼Œç”Ÿæˆå…·æœ‰æ›´é«˜ä¸€è‡´æ€§ã€å¹³æ»‘æ€§å’Œæ•ˆç‡çš„æ–°å›¾åƒã€‚</li><li>åœ¨æ¦‚å¿µå’Œç©ºé—´æ’å€¼æ–¹é¢è¡¨ç°å‡ºæœ‰æ•ˆæ€§ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šAIDï¼šæ–‡æœ¬åˆ°å›¾åƒçš„æ³¨æ„æ’å€¼</li><li>ä½œè€…ï¼šé½æºä½•ã€æ™¯æµ©ç‹ã€å­ä¸ºåˆ˜ã€å®‰å‰æ‹‰å§š</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ–°åŠ å¡å›½ç«‹å¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£ã€æ¡ä»¶æ‰©æ•£æ¨¡å‹ã€æ³¨æ„æœºåˆ¶ã€æ’å€¼</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.17924 Github ä»£ç é“¾æ¥ï¼šæ— </li><li><p>æ‘˜è¦ï¼š (1) ç ”ç©¶èƒŒæ™¯ï¼šæ¡ä»¶æ‰©æ•£æ¨¡å‹å¯ä»¥ç”Ÿæˆå„ç§åœºæ™¯ä¸­çš„å›¾åƒï¼Œæœ‰åŠ©äºå›¾åƒæ’å€¼ã€‚åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œæ’å€¼å·²ç»å¾—åˆ°å……åˆ†ç ”ç©¶ï¼Œä½†ä½¿ç”¨ç‰¹å®šæ¡ä»¶ï¼ˆå¦‚æ–‡æœ¬æˆ–å§¿åŠ¿ï¼‰è¿›è¡Œæ’å€¼çš„ç ”ç©¶è¾ƒå°‘ã€‚ (2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç®€å•çš„æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨æ¡ä»¶ç©ºé—´ä¸­è¿›è¡Œçº¿æ€§æ’å€¼ï¼Œé€šå¸¸ä¼šå¯¼è‡´å›¾åƒç¼ºä¹ä¸€è‡´æ€§ã€å¹³æ»‘æ€§å’Œä¿çœŸåº¦ã€‚æœ¬æ–‡æå‡ºçš„æ–¹æ³•åŠ¨æœºæ˜ç¡®ã€‚ (3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º AID çš„æ–°é¢–å…è®­ç»ƒæŠ€æœ¯ï¼Œå³é€šè¿‡æ‰©æ•£è¿›è¡Œæ³¨æ„æ’å€¼ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨æ¡ä»¶ç©ºé—´ä¸­å¼•å…¥æ³¨æ„æœºåˆ¶æ¥æŒ‡å¯¼æ’å€¼è¿‡ç¨‹ï¼Œä»è€Œç¡®ä¿å›¾åƒåœ¨å¸ƒå±€å’Œæ¦‚å¿µä¸Šçš„å¹³æ»‘è¿‡æ¸¡ã€‚ (4) æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œåœ¨ç©ºé—´å’Œæ¦‚å¿µæ’å€¼ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾ç€æ”¹è¿›ã€‚å®éªŒç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•ç›®æ ‡ã€‚</p></li><li><p>æ–¹æ³•ï¼š (1) å†…/å¤–æ’å€¼æ³¨æ„åŠ›æœºåˆ¶ï¼šé€šè¿‡åœ¨æ¡ä»¶ç©ºé—´ä¸­å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ï¼ŒæŒ‡å¯¼æ’å€¼è¿‡ç¨‹ï¼Œç¡®ä¿å›¾åƒåœ¨å¸ƒå±€å’Œæ¦‚å¿µä¸Šçš„å¹³æ»‘è¿‡æ¸¡ã€‚ (2) ä¸è‡ªæ³¨æ„åŠ›èåˆï¼šå°†æ’å€¼æ½œå˜é‡æœ¬èº«çš„é”®å’Œå€¼èå…¥æ’å€¼æ³¨æ„åŠ›æœºåˆ¶ï¼Œæé«˜ä¸€è‡´æ€§å’Œä¿çœŸåº¦ã€‚ (3) Beta å…ˆéªŒåºåˆ—é€‰æ‹©ï¼šé‡‡ç”¨ Beta åˆ†å¸ƒé€‰æ‹©æ’å€¼è·¯å¾„ä¸Šçš„ç‰¹å®šæ’å€¼å›¾åƒï¼Œä½¿ç”Ÿæˆçš„å›¾åƒåºåˆ—æ›´å¹³æ»‘ã€‚ (4) æç¤ºå¼•å¯¼ï¼šé€šè¿‡æ³¨å…¥æç¤ºä½œä¸ºæ¡ä»¶ï¼Œæ§åˆ¶æ’å€¼è·¯å¾„ï¼Œç”Ÿæˆç¬¦åˆæ–‡æœ¬æè¿°çš„æ’å€¼åºåˆ—ã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé¦–æ¬¡æå‡ºæ¡ä»¶æ’å€¼ä»»åŠ¡åŠç›¸å…³è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ä¸€è‡´æ€§ã€å¹³æ»‘æ€§å’Œä¿çœŸåº¦ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸º AID çš„æ–°é¢–æ–¹æ³•ï¼Œç”¨äºåœ¨æ‰©æ•£æ¨¡å‹ä¸­ç”Ÿæˆæ¡ä»¶æ’å€¼å›¾åƒã€‚è¯¥æ–¹æ³•åœ¨æ— éœ€è®­ç»ƒçš„æƒ…å†µä¸‹æ˜¾ç€è¶…è¶Šäº†åŸºå‡†ï¼Œé€šè¿‡å®šæ€§å’Œå®šé‡åˆ†æå¾—åˆ°äº†è¯æ˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº† PAIDï¼Œè¯¥æ‰©å±•å…è®¸ç”¨æˆ·ä½¿ç”¨å¼•å¯¼æç¤ºæ¥é€‰æ‹©æ’å€¼è·¯å¾„ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ— éœ€è®­ç»ƒï¼Œæ‹“å®½äº†ç”Ÿæˆæ¨¡å‹æ’å€¼çš„èŒƒå›´ï¼Œä¸ºåˆæˆç”Ÿæˆã€å›¾åƒç¼–è¾‘ã€æ•°æ®å¢å¼ºå’Œè§†é¢‘æ’å€¼ç­‰å„ç§åº”ç”¨å¼€è¾Ÿäº†æ–°æœºé‡ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºæ¡ä»¶æ’å€¼ä»»åŠ¡åŠè¯„ä¼°æŒ‡æ ‡ï¼Œå¼•å…¥æ³¨æ„åŠ›æœºåˆ¶æŒ‡å¯¼æ’å€¼è¿‡ç¨‹ï¼Œæ— éœ€è®­ç»ƒå³å¯ç”Ÿæˆé«˜è´¨é‡æ’å€¼å›¾åƒã€‚ æ€§èƒ½ï¼šåœ¨ç©ºé—´å’Œæ¦‚å¿µæ’å€¼ä»»åŠ¡ä¸Šå–å¾—æ˜¾ç€æ”¹è¿›ï¼Œå®šæ€§å’Œå®šé‡è¯„ä¼°å‡æ”¯æŒè¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ å·¥ä½œé‡ï¼šæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„æ’å€¼æ–¹æ³•ï¼Œå‡å°‘äº†è®­ç»ƒè´Ÿæ‹…ï¼Œæé«˜äº†æ’å€¼æ•ˆç‡ã€‚</p></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-aaa47516c2e21df63c1ee81eb0afd555.jpg" align="middle"></details><h2 id="AniPortrait-Audio-Driven-Synthesis-of-Photorealistic-Portrait-Animation"><a href="#AniPortrait-Audio-Driven-Synthesis-of-Photorealistic-Portrait-Animation" class="headerlink" title="AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation"></a>AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation</h2><p><strong>Authors:Huawei Wei, Zejun Yang, Zhisheng Wang</strong></p><p>In this study, we propose AniPortrait, a novel framework for generating high-quality animation driven by audio and a reference portrait image. Our methodology is divided into two stages. Initially, we extract 3D intermediate representations from audio and project them into a sequence of 2D facial landmarks. Subsequently, we employ a robust diffusion model, coupled with a motion module, to convert the landmark sequence into photorealistic and temporally consistent portrait animation. Experimental results demonstrate the superiority of AniPortrait in terms of facial naturalness, pose diversity, and visual quality, thereby offering an enhanced perceptual experience. Moreover, our methodology exhibits considerable potential in terms of flexibility and controllability, which can be effectively applied in areas such as facial motion editing or face reenactment. We release code and model weights at <a target="_blank" rel="noopener" href="https://github.com/scutzzj/AniPortrait">https://github.com/scutzzj/AniPortrait</a></p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17694v1">PDF</a></p><p><strong>Summary</strong><br>åˆ©ç”¨éŸ³é¢‘å’Œå‚è€ƒè‚–åƒå›¾åƒç”Ÿæˆé«˜å“è´¨åŠ¨ç”»çš„æ–°é¢–æ¡†æ¶ï¼šAniPortrait</p><p><strong>Key Takeaways</strong></p><ul><li>AniPortrait æå‡ºäº†ä¸€ç§ç”±éŸ³é¢‘å’Œå‚è€ƒè‚–åƒå›¾åƒé©±åŠ¨çš„é«˜è´¨é‡åŠ¨ç”»ç”Ÿæˆæ–°æ¡†æ¶ã€‚</li><li>AniPortrait åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šä»éŸ³é¢‘ä¸­æå– 3D ä¸­é—´è¡¨ç¤ºå¹¶å°†å…¶æŠ•å½±åˆ° 2D é¢éƒ¨åœ°æ ‡åºåˆ—ä¸­ã€‚</li><li>AniPortrait ä½¿ç”¨ç¨³å¥çš„æ‰©æ•£æ¨¡å‹å’Œè¿åŠ¨æ¨¡å—å°†åœ°æ ‡åºåˆ—è½¬æ¢ä¸ºé€¼çœŸçš„ã€æ—¶é—´ä¸€è‡´çš„è‚–åƒåŠ¨ç”»ã€‚</li><li>AniPortrait åœ¨é¢éƒ¨è‡ªç„¶åº¦ã€å§¿åŠ¿å¤šæ ·æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚</li><li>AniPortrait åœ¨çµæ´»æ€§å’Œå¯æ§æ€§æ–¹é¢è¡¨ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œå¯æœ‰æ•ˆåº”ç”¨äºé¢éƒ¨åŠ¨ä½œç¼–è¾‘æˆ–é¢éƒ¨é‡å»ºç­‰é¢†åŸŸã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šAniPortraitï¼šéŸ³é¢‘é©±åŠ¨çš„å†™å®è‚–åƒåŠ¨ç”»åˆæˆ</li><li>ä½œè€…ï¼šWei Huawei<em>ã€Yang Zejun</em>ã€Wang Zhisheng</li><li>å•ä½ï¼šè…¾è®¯</li><li>å…³é”®è¯ï¼šéŸ³é¢‘é©±åŠ¨ã€è‚–åƒåŠ¨ç”»ã€æ‰©æ•£æ¨¡å‹ã€åŠ¨ä½œæ¨¡å—</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.17694 Githubï¼šNone</li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä»éŸ³é¢‘å’Œé™æ€å›¾åƒç”Ÿæˆé€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„è‚–åƒåŠ¨ç”»å…·æœ‰å¹¿æ³›çš„åº”ç”¨ï¼Œä½†åˆ¶ä½œè§†è§‰ä¸Šå¼•äººå…¥èƒœä¸”ä¿æŒæ—¶é—´ä¸€è‡´æ€§çš„é«˜è´¨é‡åŠ¨ç”»æ˜¯ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸æ— æ³•å…‹æœè¿™ä¸€æŒ‘æˆ˜ï¼Œä¸»è¦åŸå› æ˜¯å®ƒä»¬ä¾èµ–äºå®¹é‡æœ‰é™çš„è§†è§‰å†…å®¹ç”Ÿæˆå™¨ï¼Œä¾‹å¦‚ GANã€NeRF æˆ–åŸºäºè¿åŠ¨çš„è§£ç å™¨ã€‚è¿™äº›ç½‘ç»œè¡¨ç°å‡ºæœ‰é™çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”åœ¨ç”Ÿæˆé«˜è´¨é‡å†…å®¹æ—¶å¾€å¾€ç¼ºä¹ç¨³å®šæ€§ã€‚ ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º AniPortraitï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆç”±éŸ³é¢‘å’Œå‚è€ƒå›¾åƒé©±åŠ¨çš„ä¼˜è´¨åŠ¨ç”»è‚–åƒã€‚AniPortrait åˆ†ä¸ºä¸¤ä¸ªä¸åŒçš„é˜¶æ®µã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºäº Transformer çš„æ¨¡å‹ä»éŸ³é¢‘ä¸­æå– 3D ä¸­é—´è¡¨ç¤ºï¼Œå¹¶å°†å…¶æŠ•å½±åˆ° 2D é¢éƒ¨åœ°æ ‡åºåˆ—ä¸­ã€‚éšåï¼Œæˆ‘ä»¬é‡‡ç”¨ç¨³å¥çš„æ‰©æ•£æ¨¡å‹ï¼Œç»“åˆè¿åŠ¨æ¨¡å—ï¼Œå°†åœ°æ ‡åºåˆ—è½¬æ¢ä¸ºé€¼çœŸçš„ã€æ—¶é—´ä¸€è‡´çš„è‚–åƒåŠ¨ç”»ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå®éªŒç»“æœè¯æ˜äº† AniPortrait åœ¨é¢éƒ¨è‡ªç„¶åº¦ã€å§¿åŠ¿å¤šæ ·æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œä»è€Œæä¾›äº†å¢å¼ºçš„æ„ŸçŸ¥ä½“éªŒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨çµæ´»æ€§å’Œå¯æ§æ€§æ–¹é¢è¡¨ç°å‡ºç›¸å½“å¤§çš„æ½œåŠ›ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åº”ç”¨äºé¢éƒ¨åŠ¨ä½œç¼–è¾‘æˆ–é¢éƒ¨é‡ç°ç­‰é¢†åŸŸã€‚</li></ol><p>7.æ–¹æ³•ï¼š ï¼ˆ1ï¼‰ï¼š<strong>Audio2Lmk</strong>ï¼šä»éŸ³é¢‘ä¸­æå– 3D é¢éƒ¨ç½‘æ ¼åºåˆ—å’Œä½å§¿åºåˆ—ã€‚ ï¼ˆ2ï¼‰ï¼š<strong>Lmk2Video</strong>ï¼šå°†é¢éƒ¨åœ°æ ‡åºåˆ—è½¬æ¢ä¸ºæ—¶é—´ä¸€è‡´çš„è‚–åƒåŠ¨ç”»ã€‚</p><ol><li>ç»“è®ºï¼š (1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ AniPortraitï¼Œè¯¥æ¡†æ¶å¯ä»¥ç”Ÿæˆç”±éŸ³é¢‘å’Œå‚è€ƒå›¾åƒé©±åŠ¨çš„ä¼˜è´¨åŠ¨ç”»è‚–åƒã€‚AniPortrait é‡‡ç”¨åŸºäº Transformer çš„æ¨¡å‹ä»éŸ³é¢‘ä¸­æå– 3D ä¸­é—´è¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨ç¨³å¥çš„æ‰©æ•£æ¨¡å‹ç»“åˆè¿åŠ¨æ¨¡å—å°†å…¶è½¬æ¢ä¸ºé€¼çœŸçš„ã€æ—¶é—´ä¸€è‡´çš„è‚–åƒåŠ¨ç”»ã€‚å®éªŒç»“æœè¯æ˜äº† AniPortrait åœ¨é¢éƒ¨è‡ªç„¶åº¦ã€å§¿åŠ¿å¤šæ ·æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œä»è€Œæä¾›äº†å¢å¼ºçš„æ„ŸçŸ¥ä½“éªŒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨çµæ´»æ€§å’Œå¯æ§æ€§æ–¹é¢è¡¨ç°å‡ºç›¸å½“å¤§çš„æ½œåŠ›ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åº”ç”¨äºé¢éƒ¨åŠ¨ä½œç¼–è¾‘æˆ–é¢éƒ¨é‡ç°ç­‰é¢†åŸŸã€‚ (2): åˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ AniPortraitï¼Œè¯¥æ¡†æ¶å¯ä»¥ä»éŸ³é¢‘å’Œå‚è€ƒå›¾åƒç”Ÿæˆé€¼çœŸçš„åŠ¨ç”»è‚–åƒã€‚</li><li>é‡‡ç”¨åŸºäº Transformer çš„æ¨¡å‹ä»éŸ³é¢‘ä¸­æå– 3D ä¸­é—´è¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨ç¨³å¥çš„æ‰©æ•£æ¨¡å‹ç»“åˆè¿åŠ¨æ¨¡å—å°†å…¶è½¬æ¢ä¸ºæ—¶é—´ä¸€è‡´çš„è‚–åƒåŠ¨ç”»ã€‚</li><li>AniPortrait åœ¨é¢éƒ¨è‡ªç„¶åº¦ã€å§¿åŠ¿å¤šæ ·æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œä»è€Œæä¾›äº†å¢å¼ºçš„æ„ŸçŸ¥ä½“éªŒã€‚</li><li>AniPortrait åœ¨çµæ´»æ€§å’Œå¯æ§æ€§æ–¹é¢è¡¨ç°å‡ºç›¸å½“å¤§çš„æ½œåŠ›ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åº”ç”¨äºé¢éƒ¨åŠ¨ä½œç¼–è¾‘æˆ–é¢éƒ¨é‡ç°ç­‰é¢†åŸŸã€‚ æ€§èƒ½ï¼š</li><li>AniPortrait åœ¨é¢éƒ¨è‡ªç„¶åº¦ã€å§¿åŠ¿å¤šæ ·æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œä»è€Œæä¾›äº†å¢å¼ºçš„æ„ŸçŸ¥ä½“éªŒã€‚</li><li>AniPortrait åœ¨çµæ´»æ€§å’Œå¯æ§æ€§æ–¹é¢è¡¨ç°å‡ºç›¸å½“å¤§çš„æ½œåŠ›ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åº”ç”¨äºé¢éƒ¨åŠ¨ä½œç¼–è¾‘æˆ–é¢éƒ¨é‡ç°ç­‰é¢†åŸŸã€‚ å·¥ä½œé‡ï¼š</li><li>AniPortrait çš„å®ç°éœ€è¦ä¸€å®šçš„æŠ€æœ¯å®åŠ›ï¼ŒåŒ…æ‹¬å¯¹ Transformer æ¨¡å‹ã€æ‰©æ•£æ¨¡å‹å’Œè¿åŠ¨æ¨¡å—çš„ç†è§£ã€‚</li><li>è®­ç»ƒ AniPortrait æ¨¡å‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-a0703eb6ac9807d377c7bbfaa84e3681.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-fc2d139237100aad689f67180ae398bf.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-e35074ee634942aebc5c8860cf29e344.jpg" align="middle"></details><h2 id="DiffFAE-Advancing-High-fidelity-One-shot-Facial-Appearance-Editing-with-Space-sensitive-Customization-and-Semantic-Preservation"><a href="#DiffFAE-Advancing-High-fidelity-One-shot-Facial-Appearance-Editing-with-Space-sensitive-Customization-and-Semantic-Preservation" class="headerlink" title="DiffFAE: Advancing High-fidelity One-shot Facial Appearance Editing with   Space-sensitive Customization and Semantic Preservation"></a>DiffFAE: Advancing High-fidelity One-shot Facial Appearance Editing with Space-sensitive Customization and Semantic Preservation</h2><p><strong>Authors:Qilin Wang, Jiangning Zhang, Chengming Xu, Weijian Cao, Ying Tai, Yue Han, Yanhao Ge, Hong Gu, Chengjie Wang, Yanwei Fu</strong></p><p>Facial Appearance Editing (FAE) aims to modify physical attributes, such as pose, expression and lighting, of human facial images while preserving attributes like identity and background, showing great importance in photograph. In spite of the great progress in this area, current researches generally meet three challenges: low generation fidelity, poor attribute preservation, and inefficient inference. To overcome above challenges, this paper presents DiffFAE, a one-stage and highly-efficient diffusion-based framework tailored for high-fidelity FAE. For high-fidelity query attributes transfer, we adopt Space-sensitive Physical Customization (SPC), which ensures the fidelity and generalization ability by utilizing rendering texture derived from 3D Morphable Model (3DMM). In order to preserve source attributes, we introduce the Region-responsive Semantic Composition (RSC). This module is guided to learn decoupled source-regarding features, thereby better preserving the identity and alleviating artifacts from non-facial attributes such as hair, clothes, and background. We further introduce a consistency regularization for our pipeline to enhance editing controllability by leveraging prior knowledge in the attention matrices of diffusion model. Extensive experiments demonstrate the superiority of DiffFAE over existing methods, achieving state-of-the-art performance in facial appearance editing.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17664v1">PDF</a></p><p><strong>Summary</strong><br>å›¾åƒä¸­äººè„¸å¤–è§‚ç¼–è¾‘çš„æ‰©æ•£æ¨¡å‹ DiffFAE æé«˜äº†ç”Ÿæˆä¿çœŸåº¦ã€å±æ€§ä¿ç•™å’Œæ¨ç†æ•ˆç‡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>é‡‡ç”¨ç©ºé—´æ•æ„Ÿç‰©ç†å®šåˆ¶ (SPC) ç¡®ä¿æŸ¥è¯¢å±æ€§è½¬ç§»çš„ä¿çœŸåº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li><li>å¼•å…¥åŒºåŸŸå“åº”è¯­ä¹‰ç»„åˆ (RSC) ä¿ç•™æºå±æ€§ï¼Œå‡è½»éé¢éƒ¨å±æ€§ï¼ˆå¦‚å¤´å‘ã€è¡£æœå’ŒèƒŒæ™¯ï¼‰å¸¦æ¥çš„ä¼ªå½±ã€‚</li><li>æå‡ºä¸€è‡´æ€§æ­£åˆ™åŒ–ï¼Œé€šè¿‡åˆ©ç”¨æ‰©æ•£æ¨¡å‹æ³¨æ„åŠ›çŸ©é˜µä¸­çš„å…ˆéªŒçŸ¥è¯†å¢å¼ºç¼–è¾‘å¯æ§æ€§ã€‚</li><li>DiffFAE åœ¨äººè„¸å¤–è§‚ç¼–è¾‘ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¶…è¶Šç°æœ‰æ–¹æ³•ã€‚</li><li>DiffFAE å¯ä»¥æœ‰æ•ˆå¤„ç†äººè„¸å¤–è§‚ç¼–è¾‘ä¸­çš„ä½ç”Ÿæˆä¿çœŸåº¦ã€å·®å±æ€§ä¿ç•™å’Œä½æ¨ç†æ•ˆç‡ç­‰æŒ‘æˆ˜ã€‚</li><li>æ‰©æ•£æ¨¡å‹åœ¨äººè„¸å¤–è§‚ç¼–è¾‘ä»»åŠ¡ä¸­å…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚</li><li>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºäººè„¸å¤–è§‚ç¼–è¾‘çš„æ–°é¢–æ¡†æ¶ DiffFAEï¼Œå®ƒç»“åˆäº†æ‰©æ•£æ¨¡å‹ã€ç©ºé—´æ•æ„Ÿç‰©ç†å®šåˆ¶å’ŒåŒºåŸŸå“åº”è¯­ä¹‰ç»„åˆçš„ä¼˜ç‚¹ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šDiffFAEï¼šæ¨è¿›é«˜ä¿çœŸä¸€å‘å¼äººè„¸å¤–è§‚ç¼–è¾‘</li><li>ä½œè€…ï¼šQ. Wang ç­‰</li><li>å•ä½ï¼šæœªæåŠ</li><li>å…³é”®è¯ï¼šFacial appearance editingã€Diffusion modelã€Object-centric learning</li><li>è®ºæ–‡é“¾æ¥ï¼šæœªæä¾›ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li><li><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šäººè„¸å¤–è§‚ç¼–è¾‘æ—¨åœ¨ä¿®æ”¹äººè„¸å›¾åƒçš„ç‰©ç†å±æ€§ï¼ˆå¦‚å§¿åŠ¿ã€è¡¨æƒ…å’Œå…‰ç…§ï¼‰ï¼ŒåŒæ—¶ä¿ç•™èº«ä»½å’ŒèƒŒæ™¯ç­‰å±æ€§ï¼Œåœ¨æ‘„å½±ä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰ç ”ç©¶é€šå¸¸é¢ä¸´ç”Ÿæˆä¿çœŸåº¦ä½ã€å±æ€§ä¿ç•™å·®å’Œæ¨ç†æ•ˆç‡ä½ä¸‰å¤§æŒ‘æˆ˜ã€‚ ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º DiffFAEï¼Œä¸€ä¸ªé’ˆå¯¹é«˜ä¿çœŸ FAE é‡èº«å®šåˆ¶çš„å•é˜¶æ®µä¸”é«˜æ•ˆçš„åŸºäºæ‰©æ•£çš„æ¡†æ¶ã€‚ä¸ºäº†å®ç°é«˜ä¿çœŸæŸ¥è¯¢å±æ€§è½¬ç§»ï¼Œæˆ‘ä»¬é‡‡ç”¨ç©ºé—´æ•æ„Ÿç‰©ç†å®šåˆ¶ï¼ˆSPCï¼‰ï¼Œå®ƒåˆ©ç”¨æºè‡ª 3D å¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰çš„æ¸²æŸ“çº¹ç†ï¼Œç¡®ä¿äº†ä¿çœŸåº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†ä¿ç•™æºå±æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŒºåŸŸå“åº”è¯­ä¹‰ç»„åˆï¼ˆRSCï¼‰ã€‚è¯¥æ¨¡å—è¢«å¼•å¯¼å­¦ä¹ è§£è€¦çš„æºç›¸å…³ç‰¹å¾ï¼Œä»è€Œæ›´å¥½åœ°ä¿ç•™èº«ä»½ï¼Œå¹¶å‡è½»æ¥è‡ªéé¢éƒ¨å±æ€§ï¼ˆå¦‚å¤´å‘ã€è¡£æœå’ŒèƒŒæ™¯ï¼‰çš„ä¼ªå½±ã€‚æˆ‘ä»¬è¿˜ä¸ºæˆ‘ä»¬çš„ç®¡é“å¼•å…¥äº†ç¨ å¯†æ­£åˆ™åŒ–ï¼Œé€šè¿‡åˆ©ç”¨æ‰©æ•£æ¨¡å‹æ³¨æ„åŠ›çŸ©é˜µä¸­çš„å…ˆéªŒçŸ¥è¯†æ¥å¢å¼ºç¼–è¾‘å¯æ§æ€§ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒDiffFAE ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨äººè„¸å¤–è§‚ç¼–è¾‘ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ã€‚</p></li><li><p><strong>æ–¹æ³•</strong>ï¼š ï¼ˆ1ï¼‰<strong>ç©ºé—´æ•æ„Ÿç‰©ç†å®šåˆ¶ï¼ˆSPCï¼‰</strong>ï¼šåˆ©ç”¨æºè‡ª3Då¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰çš„æ¸²æŸ“çº¹ç†ï¼Œç¡®ä¿ä¿çœŸåº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚ ï¼ˆ2ï¼‰<strong>åŒºåŸŸå“åº”è¯­ä¹‰ç»„åˆï¼ˆRSCï¼‰</strong>ï¼šå­¦ä¹ è§£è€¦çš„æºç›¸å…³ç‰¹å¾ï¼Œä¿ç•™èº«ä»½ï¼Œå‡è½»éé¢éƒ¨å±æ€§ä¼ªå½±ã€‚ ï¼ˆ3ï¼‰<strong>ç¨ å¯†æ­£åˆ™åŒ–</strong>ï¼šåˆ©ç”¨æ‰©æ•£æ¨¡å‹æ³¨æ„åŠ›çŸ©é˜µä¸­çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¢å¼ºç¼–è¾‘å¯æ§æ€§ã€‚</p></li></ol><p>8.ç»“è®ºï¼š (1)ï¼šæœ¬æ–‡é’ˆå¯¹äººè„¸å¤–è§‚ç¼–è¾‘ï¼ˆFAEï¼‰ä¸­å­˜åœ¨çš„ç”Ÿæˆä¿çœŸåº¦ä½ã€å±æ€§ä¿ç•™å·®å’Œæ¨ç†æ•ˆç‡ä½ä¸‰å¤§æŒ‘æˆ˜è¿›è¡Œäº†åˆ†æï¼Œæ¢ç´¢äº†ä¸€ç§åŸºäºå•é˜¶æ®µæ‰©æ•£çš„æ–°æ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨ç©ºé—´æ•æ„Ÿç‰©ç†å®šåˆ¶æ¨¡å—æ¥å¤„ç†æŸ¥è¯¢ç‰©ç†å±æ€§ï¼Œå¦‚å§¿åŠ¿ã€è¡¨æƒ…å’Œå…‰ç…§ã€‚åŒæ—¶ï¼Œæå‡ºäº†åŒºåŸŸå“åº”è¯­ä¹‰ç»„åˆæ¥æ›´å¥½åœ°æ§åˆ¶æºç›¸å…³å±æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ VoxCeleb1 æ•°æ®é›†ä¸Šä¸º FAE ä»»åŠ¡è®¾å®šäº†æ–°çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œè¿™å¾—åˆ°äº†å¹¿æ³›çš„å®šé‡å’Œå®šæ€§ç»“æœçš„æ”¯æŒã€‚ (2)ï¼šåˆ›æ–°ç‚¹ï¼šç©ºé—´æ•æ„Ÿç‰©ç†å®šåˆ¶æ¨¡å—ã€åŒºåŸŸå“åº”è¯­ä¹‰ç»„åˆã€ç¨ å¯†æ­£åˆ™åŒ–ï¼› æ€§èƒ½ï¼šåœ¨ VoxCeleb1 æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼› å·¥ä½œé‡ï¼šä¸­ç­‰ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-d26cb9d6e12fa2c3ca2894c45c11f62a.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-2e175e9d0b22d21814f9b545e1b4a47f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-98414ddcc0bdcee2447d896743b3ec8e.jpg" align="middle"></details>## DiffGaze: A Diffusion Model for Continuous Gaze Sequence Generation on 360Â° Images **Authors:Chuhan Jiao, Yao Wang, Guanhua Zhang, Mihai BÃ¢ce, Zhiming Hu, Andreas Bulling** We present DiffGaze, a novel method for generating realistic and diverse continuous human gaze sequences on 360{\deg} images based on a conditional score-based denoising diffusion model. Generating human gaze on 360{\deg} images is important for various human-computer interaction and computer graphics applications, e.g. for creating large-scale eye tracking datasets or for realistic animation of virtual humans. However, existing methods are limited to predicting discrete fixation sequences or aggregated saliency maps, thereby neglecting crucial parts of natural gaze behaviour. Our method uses features extracted from 360{\deg} images as condition and uses two transformers to model the temporal and spatial dependencies of continuous human gaze. We evaluate DiffGaze on two 360{\deg} image benchmarks for gaze sequence generation as well as scanpath prediction and saliency prediction. Our evaluations show that DiffGaze outperforms state-of-the-art methods on all tasks on both benchmarks. We also report a 21-participant user study showing that our method generates gaze sequences that are indistinguishable from real human sequences. [PDF](http://arxiv.org/abs/2403.17477v1) **æ‘˜è¦** åŸºäºæ¡ä»¶åˆ†æ•°å»å™ªæ‰©æ•£æ¨¡å‹ï¼Œæå‡ºäº†ä¸€ç§ç”Ÿæˆ360åº¦å›¾åƒä¸Šé€¼çœŸä¸”å¤šæ ·çš„è¿ç»­äººçœ¼æ³¨è§†åºåˆ—çš„æ–°æ–¹æ³•DiffGazeã€‚ **è¦ç‚¹** - æå‡ºäº† DiffGazeï¼Œä¸€ç§ç”¨äºç”Ÿæˆé€¼çœŸä¸”å¤šæ ·çš„ 360 åº¦å›¾åƒçš„è¿ç»­äººçœ¼æ³¨è§†åºåˆ—çš„æ–¹æ³•ã€‚ - DiffGaze ä½¿ç”¨ä» 360 åº¦å›¾åƒä¸­æå–çš„ç‰¹å¾ä½œä¸ºæ¡ä»¶ï¼Œå¹¶ä½¿ç”¨ä¸¤ä¸ª Transformer æ¥å»ºæ¨¡è¿ç»­äººçœ¼æ³¨è§†çš„æ—¶é—´å’Œç©ºé—´ä¾èµ–æ€§ã€‚ - DiffGaze åœ¨ä¸¤ä¸ªç”¨äºæ³¨è§†åºåˆ—ç”Ÿæˆã€æ‰«æè·¯å¾„é¢„æµ‹å’Œæ˜¾ç€æ€§é¢„æµ‹çš„ 360 åº¦å›¾åƒåŸºå‡†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ - åœ¨ä¸¤ä¸ªåŸºå‡†ä¸Šçš„æ‰€æœ‰ä»»åŠ¡ä¸­ï¼ŒDiffGaze éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ - ä¸€é¡¹åŒ…å« 21 åå‚ä¸è€…çš„ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„çœ¼æ³¨è§†åºåˆ—ä¸çœŸå®çš„äººçœ¼æ³¨è§†åºåˆ—æ— æ³•åŒºåˆ†ã€‚ **[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šDiffGazeï¼š360Â° å›¾åƒè¿ç»­æ³¨è§†åºåˆ—ç”Ÿæˆæ‰©æ•£æ¨¡å‹</li><li>ä½œè€…ï¼šChuhan Jiaoã€Yao Wangã€Guanhua Zhangã€Mihai Baceã€Zhiming Huã€Andreas Bulling</li><li>éš¶å±å•ä½ï¼šæ–¯å›¾åŠ ç‰¹å¤§å­¦å¯è§†åŒ–ä¸äº¤äº’ç³»ç»Ÿç ”ç©¶æ‰€</li><li>å…³é”®è¯ï¼šScanpath Prediction; Saliency Modelling; Eye Tracking; Gaze Behaviour Modelling; Eye Movement Synthesis</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.17477 Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š éšç€ç›¸æœºæŠ€æœ¯çš„è¿›æ­¥ï¼Œé«˜åˆ†è¾¨ç‡ 360Â° å›¾åƒçš„æ•æ‰ä¸ºè™šæ‹Ÿç°å® (VR) ä¸­çš„æ–°ä¸€ä»£æ²‰æµ¸å¼ä½“éªŒæä¾›äº†å¯èƒ½ã€‚è¿™å¼•å‘äº†æ¶ˆè´¹è€…é‡‡ç”¨è¿™é¡¹æ–°æŠ€æœ¯çš„å…´è¶£ï¼Œå¹¶ä¿ƒè¿›äº†ç†è§£äººç±»å¦‚ä½•æ„ŸçŸ¥å’Œæ¢ç´¢è¿™äº› 3D è™šæ‹Ÿç¯å¢ƒçš„ç ”ç©¶å·¥ä½œã€‚è§†è§‰æ³¨æ„åŠ›æ˜¯æ¢ç´¢è¿‡ç¨‹ä¸­çš„ä¸€ä¸ªç‰¹åˆ«ä¸°å¯Œçš„çš„ä¿¡æ¯æ¥æºï¼Œé€šå¸¸ä»¥ä½¿ç”¨çœ¼åŠ¨è¿½è¸ªæ”¶é›†çš„æ³¨è§†æ•°æ®å½¢å¼è¿›è¡Œåˆ†æã€‚å°½ç®¡çœ¼åŠ¨è¿½è¸ªå˜å¾—æ›´åŠ å¹¿æ³›å’Œç»æµå®æƒ ï¼Œè€Œä¸”è¢«é›†æˆåˆ°è¶Šæ¥è¶Šå¤šçš„ VR å¤´æ˜¾ä¸­ï¼Œä½†æ”¶é›†æ³¨è§†æ•°æ®ï¼ˆå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡çš„æƒ…å†µä¸‹ï¼‰ä»ç„¶å¾ˆç¹çä¸”è€—æ—¶ï¼Œè€Œä¸”é€šå¸¸æ ¹æœ¬ä¸å¯è¡Œã€‚è¿™å¼•å‘äº†å¯¹è§†è§‰æ³¨æ„åŠ›è®¡ç®—æ¨¡å‹çš„ç ”ç©¶ï¼Œå³æ— éœ€ä¸“ç”¨çœ¼åŠ¨è¿½è¸ªè®¾å¤‡å°±èƒ½é¢„æµ‹ 360Â° å›¾åƒä¸Šäººç±»æ³¨è§†çš„æ¨¡å‹ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š å…ˆå‰å…³äº 360Â° å›¾åƒä¸Šè§†è§‰æ³¨æ„åŠ›è®¡ç®—å»ºæ¨¡çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨æ˜¾ç€æ€§æˆ–æ‰«æè·¯å¾„é¢„æµ‹ä¸Šã€‚å°½ç®¡å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†è¿™ä¸¤é¡¹ä»»åŠ¡ä»ç„¶åªè§£å†³äº†ç®€åŒ–çš„é—®é¢˜ï¼šè™½ç„¶èšåˆæ˜¾ç€æ€§å›¾ä¸éœ€è¦å¯¹äººç±»æ³¨è§†è¡Œä¸ºçš„æ—¶é—´ç‰¹æ€§è¿›è¡Œå»ºæ¨¡ï¼Œä½†é¢„æµ‹ç¦»æ•£æ³¨è§†å›ºå®šï¼ˆæ‰«æè·¯å¾„ï¼‰çš„åºåˆ—åœ¨æ—¶é—´ä¸Šä»ç„¶ç²—ç³™ï¼Œå¹¶ä¸”å¿½ç•¥äº†å›ºå®šä¹‹é—´çš„ä¸°å¯Œæ³¨è§†æ•°æ®ã€‚å› æ­¤ï¼Œè¿™äº›ä»»åŠ¡ï¼ˆæˆ–è¿‡å»ä¸ºè§£å†³è¿™äº›ä»»åŠ¡è€Œå¼€å‘çš„ä»»ä½•ç°æœ‰æ–¹æ³•ï¼‰éƒ½ä¸èƒ½å¿ å®åœ°å¯¹ 360Â° å›¾åƒä¸Šè‡ªç„¶äººç±»æ³¨è§†è¡Œä¸ºçš„ä¸°å¯Œç©ºé—´å’Œæ—¶é—´ç‰¹æ€§è¿›è¡Œå»ºæ¨¡ã€‚</p><p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº† DiffGazeâ€”â€”ç¬¬ä¸€ä¸ªç”Ÿæˆ 360Â° å›¾åƒä¸Šè¿ç»­äººç±»æ³¨è§†åºåˆ—çš„æ–¹æ³•ã€‚DiffGaze åŸºäºæ¡ä»¶åˆ†æ•°å™ªå£°æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä»¥ä» 360Â° å›¾åƒä¸­æå–çš„ç‰¹å¾ä¸ºæ¡ä»¶ï¼Œå¹¶ä½¿ç”¨ä¸¤ä¸ª Transformer æ¥å¯¹æ—¶ç©ºäººç±»æ³¨è§†è¡Œä¸ºè¿›è¡Œå»ºæ¨¡ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š æˆ‘ä»¬åœ¨ä¸¤ä¸ªæ•°æ®é›†ï¼ˆSitzmann å’Œ Salient360!ï¼‰ä¸Šå¯¹æˆ‘ä»¬çš„æ–¹æ³•è¿›è¡Œäº†è¿ç»­æ³¨è§†åºåˆ—ç”Ÿæˆã€æ‰«æè·¯å¾„é¢„æµ‹å’Œæ˜¾ç€æ€§é¢„æµ‹çš„è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨ä¸¤ä¸ªåŸºå‡†ä¸Šçš„æ‰€æœ‰ä»»åŠ¡ä¸­ï¼ŒDiffGaze éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½å¯ä»¥æ”¯æŒå…¶ç›®æ ‡ã€‚</p><ol><li><p>æ–¹æ³•ï¼š (1) DiffGazeåŸºäºæ¡ä»¶åˆ†æ•°å™ªå£°æ‰©æ•£æ¨¡å‹ï¼Œä»¥ä»360Â°å›¾åƒä¸­æå–çš„ç‰¹å¾ä¸ºæ¡ä»¶ã€‚ (2) ä½¿ç”¨ä¸¤ä¸ªTransformerå¯¹æ—¶ç©ºäººç±»æ³¨è§†è¡Œä¸ºè¿›è¡Œå»ºæ¨¡ã€‚ (3) é€šè¿‡é€å±‚å™ªå£°æ·»åŠ å’Œé¢„æµ‹å™ªå£°çš„é€†è¿‡ç¨‹ï¼Œç”Ÿæˆè¿ç»­çš„äººç±»æ³¨è§†åºåˆ—ã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† DiffGazeï¼Œè¿™æ˜¯ä¸€ç§æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºåœ¨ 360Â° ç¯å¢ƒä¸­ç”Ÿæˆé€¼çœŸä¸”å¤šæ ·çš„è¿ç»­äººç±»æ³¨è§†åºåˆ—ã€‚è¯¥æ–¹æ³•é€šè¿‡è¶…è¶Šæ‰«æè·¯å¾„é¢„æµ‹æ¥å¯¹æ›´å¤æ‚çš„çœ¼çƒè¿åŠ¨è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œæ˜¾è‘—æ¨è¿›äº†è¯¥é¢†åŸŸã€‚é€šè¿‡åœ¨ä¸¤ä¸ª 360Â° å›¾åƒæ•°æ®é›†ä¸Šå¯¹ä¸‰ç§ä¸åŒä»»åŠ¡è¿›è¡Œä¸¥æ ¼è¯„ä¼°ï¼Œè¯æ˜äº† DiffGaze çš„æœ‰æ•ˆæ€§ã€‚DiffGaze ä¸ä»…åœ¨æ³¨è§†åºåˆ—ç”Ÿæˆã€æ‰«æè·¯å¾„é¢„æµ‹å’Œæ˜¾ç€æ€§é¢„æµ‹æ–¹é¢ä¼˜äºä»¥å¾€çš„æ–¹æ³•ï¼Œè€Œä¸”è¿˜æ˜¾ç¤ºå‡ºä¸äººç±»åŸºçº¿ç›¸å½“çš„æ€§èƒ½ï¼Œçªå‡ºäº†å…¶æ¨¡æ‹Ÿç±»äººæ³¨è§†è¡Œä¸ºçš„èƒ½åŠ›ã€‚è¿™äº›ç»“æœçªå‡ºäº† DiffGaze åœ¨ä¿ƒè¿›æ²‰æµ¸å¼ç¯å¢ƒä¸­æ³¨è§†è¡Œä¸ºåˆ†ææ–¹é¢çš„æ½œåŠ›ã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„æ¨¡æ‹Ÿçœ¼åŠ¨è¿½è¸ªæ•°æ®ï¼ŒDiffGaze ä¸ºäººæœºäº¤äº’å’Œè®¡ç®—æœºè§†è§‰åº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ï¼Œä¸ºæ›´ç›´è§‚å’Œæ²‰æµ¸å¼çš„ç”¨æˆ·ä½“éªŒé“ºå¹³äº†é“è·¯ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>é¦–æ¬¡æå‡ºäº†ä¸€ç§ç”Ÿæˆ 360Â° å›¾åƒä¸Šè¿ç»­äººç±»æ³¨è§†åºåˆ—çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ã€‚</li><li>ä½¿ç”¨ä¸¤ä¸ª Transformer å¯¹æ—¶ç©ºäººç±»æ³¨è§†è¡Œä¸ºè¿›è¡Œå»ºæ¨¡ï¼Œè¿™æ¯”ä»¥å¾€çš„æ–¹æ³•æ›´å…¨é¢ã€‚</li><li>é€šè¿‡é€å±‚å™ªå£°æ·»åŠ å’Œé¢„æµ‹å™ªå£°çš„é€†è¿‡ç¨‹ï¼Œç”Ÿæˆè¿ç»­çš„äººç±»æ³¨è§†åºåˆ—ï¼Œæ¯”ä»¥å¾€çš„æ–¹æ³•æ›´é€¼çœŸã€‚ æ€§èƒ½ï¼š</li><li>åœ¨ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼ŒDiffGaze åœ¨æ³¨è§†åºåˆ—ç”Ÿæˆã€æ‰«æè·¯å¾„é¢„æµ‹å’Œæ˜¾ç€æ€§é¢„æµ‹æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li><li>DiffGaze ä¸äººç±»åŸºçº¿è¡¨ç°ç›¸å½“ï¼Œè¡¨æ˜å…¶èƒ½å¤Ÿæ¨¡æ‹Ÿç±»äººæ³¨è§†è¡Œä¸ºã€‚ å·¥ä½œé‡ï¼š</li><li>DiffGaze çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹æ¯”ä»¥å¾€çš„æ–¹æ³•æ›´å¤æ‚ï¼Œéœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºã€‚</li><li>DiffGaze éœ€è¦ä» 360Â° å›¾åƒä¸­æå–ç‰¹å¾ï¼Œè¿™å¯èƒ½éœ€è¦é¢å¤–çš„å¤„ç†æ—¶é—´ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-e0bef8622d6189293fc39affd7e61d42.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-da152edfe80db438956e4ae04e20b5df.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-5273e50a2192cece0fc3295a667277b9.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-3150ad0da3bf6c45b8ab514fbb2057bd.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-9e382e110e92dc607e913f5141ad3dc8.jpg" align="middle"></details><h2 id="LaRE-2-Latent-Reconstruction-Error-Based-Method-for-Diffusion-Generated-Image-Detection"><a href="#LaRE-2-Latent-Reconstruction-Error-Based-Method-for-Diffusion-Generated-Image-Detection" class="headerlink" title="LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated   Image Detection"></a>LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated Image Detection</h2><p><strong>Authors:Yunpeng Luo, Junlong Du, Ke Yan, Shouhong Ding</strong></p><p>The evolution of Diffusion Models has dramatically improved image generation quality, making it increasingly difficult to differentiate between real and generated images. This development, while impressive, also raises significant privacy and security concerns. In response to this, we propose a novel Latent REconstruction error guided feature REfinement method (LaRE^2) for detecting the diffusion-generated images. We come up with the Latent Reconstruction Error (LaRE), the first reconstruction-error based feature in the latent space for generated image detection. LaRE surpasses existing methods in terms of feature extraction efficiency while preserving crucial cues required to differentiate between the real and the fake. To exploit LaRE, we propose an Error-Guided feature REfinement module (EGRE), which can refine the image feature guided by LaRE to enhance the discriminativeness of the feature. Our EGRE utilizes an align-then-refine mechanism, which effectively refines the image feature for generated-image detection from both spatial and channel perspectives. Extensive experiments on the large-scale GenImage benchmark demonstrate the superiority of our LaRE^2, which surpasses the best SoTA method by up to 11.9%/12.1% average ACC/AP across 8 different image generators. LaRE also surpasses existing methods in terms of feature extraction cost, delivering an impressive speed enhancement of 8 times.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17465v1">PDF</a> CVPR 2024</p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›¾åƒéš¾è¾¨çœŸä¼ªï¼Œä¸ºæ­¤æå‡º LaRE^2 æ–¹æ³•ï¼Œåˆ©ç”¨æ½œåœ¨é‡å»ºè¯¯å·®å¢å¼ºé‰´åˆ«èƒ½åŠ›ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>åˆ›æ–°æå‡ºæ½œåœ¨é‡å»ºè¯¯å·® (LaRE)ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­æå–ç”¨äºç”Ÿæˆå›¾åƒæ£€æµ‹çš„é‡å»ºè¯¯å·®ç‰¹å¾ã€‚</li><li>è®¾è®¡é”™è¯¯å¼•å¯¼ç‰¹å¾ç»†åŒ–æ¨¡å— (EGRE)ï¼Œåˆ©ç”¨ LaRE å¼•å¯¼å›¾åƒç‰¹å¾ç»†åŒ–ï¼Œæé«˜ç‰¹å¾åˆ¤åˆ«åŠ›ã€‚</li><li>EGRE é‡‡ç”¨å¯¹é½å†ç»†åŒ–çš„æœºåˆ¶ï¼Œä»ç©ºé—´å’Œé€šé“ä¸¤ä¸ªè§’åº¦æœ‰æ•ˆç»†åŒ–å›¾åƒç‰¹å¾ã€‚</li><li>åœ¨å¤§è§„æ¨¡ GenImage åŸºå‡†ä¸Šè¿›è¡Œå¹¿æ³›å®éªŒï¼Œè¯æ˜ LaRE^2 çš„ä¼˜è¶Šæ€§ï¼Œåœ¨ 8 ç§ä¸åŒçš„å›¾åƒç”Ÿæˆå™¨ä¸Šæ¯”æœ€ä½³ SoTA æ–¹æ³•åˆ†åˆ«æé«˜äº† 11.9%/12.1% çš„å¹³å‡å‡†ç¡®ç‡/å¹³å‡ç²¾åº¦ã€‚</li><li>LaRE è¿˜è¶…è¿‡äº†ç°æœ‰æ–¹æ³•çš„ç‰¹å¾æå–æˆæœ¬ï¼Œæä¾›äº† 8 å€çš„æé€Ÿã€‚</li><li>LaRE^2 æ–¹æ³•æœ‰åŠ©äºä¿æŠ¤éšç§å’Œå®‰å…¨ï¼Œè§£å†³æ‰©æ•£æ¨¡å‹å¸¦æ¥çš„æŒ‘æˆ˜ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šLaRE2ï¼šåŸºäºæ½œåœ¨é‡å»ºè¯¯å·®çš„æ‰©æ•£ç”Ÿæˆå›¾åƒæ£€æµ‹æ–¹æ³•</li><li>ä½œè€…ï¼šç½—è¿é¹ã€æœä¿Šé¾™ã€ä¸¥æŸ¯ã€ä¸å¯¿é¸¿</li><li>å•ä½ï¼šè…¾è®¯ä¼˜å›¾å®éªŒå®¤</li><li>å…³é”®è¯ï¼šDiffusion Modelã€å›¾åƒç”Ÿæˆã€å›¾åƒæ£€æµ‹ã€æ½œåœ¨ç©ºé—´ã€é‡å»ºè¯¯å·®</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.17465</li><li><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•å¸¦æ¥äº†ç”Ÿæˆå›¾åƒè´¨é‡çš„æ˜¾è‘—æå‡ï¼Œä½†ä¹Ÿå¼•å‘äº†éšç§å’Œå®‰å…¨é—®é¢˜ï¼ŒäºŸéœ€å¼€å‘å›¾åƒæ£€æµ‹æŠ€æœ¯ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•åˆ©ç”¨é‡å»ºè¯¯å·®ä½œä¸ºåˆ¤åˆ«ç‰¹å¾ï¼Œä½†å­˜åœ¨ç‰¹å¾æå–æ•ˆç‡ä½ã€é‡å»ºæ­¥éª¤ç¹çç­‰é—®é¢˜ã€‚ ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º LaRE2 æ–¹æ³•ï¼Œåˆ©ç”¨æ½œåœ¨ç©ºé—´çš„é‡å»ºè¯¯å·®ä½œä¸ºç‰¹å¾ï¼Œå¹¶è®¾è®¡äº†é”™è¯¯å¼•å¯¼ç‰¹å¾ç»†åŒ–æ¨¡å—ï¼Œä»ç©ºé—´å’Œé€šé“ç»´åº¦ç»†åŒ–å›¾åƒç‰¹å¾ï¼Œå¢å¼ºåˆ¤åˆ«æ€§ã€‚ ï¼ˆ4ï¼‰æ€§èƒ½ä¸è¯„ä»·ï¼šåœ¨ GenImage æ•°æ®é›†ä¸Šï¼ŒLaRE2 åœ¨ 8 ä¸ªä¸åŒå›¾åƒç”Ÿæˆå™¨ä¸Šå¹³å‡ ACC/AP åˆ†åˆ«æ¯”æœ€ä½³ SoTA æ–¹æ³•æå‡äº† 11.9%/12.1%ï¼Œä¸”ç‰¹å¾æå–é€Ÿåº¦æå‡äº† 8 å€ï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) åœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œé€šè¿‡å•æ­¥é‡å»ºæå– LaREï¼›(2) ä¸ºäº†åˆ©ç”¨ LaREï¼Œæå‡ºäº†é”™è¯¯å¼•å¯¼ç‰¹å¾ç»†åŒ–æ¨¡å—ï¼Œè¯¥æ¨¡å—ç”±é”™è¯¯å¼•å¯¼ç©ºé—´ç»†åŒ–æ¨¡å—å’Œé”™è¯¯å¼•å¯¼é€šé“ç»†åŒ–æ¨¡å—ç»„æˆã€‚ä»ç©ºé—´å’Œé€šé“ç»´åº¦ï¼Œåˆ©ç”¨ LaRE å¢å¼ºå›¾åƒç‰¹å¾çš„åˆ¤åˆ«æ€§ï¼Œç”¨äºç”Ÿæˆå›¾åƒæ£€æµ‹ã€‚</p></li><li><p>ç»“è®ºï¼š (1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºé‡å»ºçš„æ‰©æ•£ç”Ÿæˆå›¾åƒæ£€æµ‹æ–¹æ³• LaRE2ã€‚æˆ‘ä»¬æå‡ºäº† LaREï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­é‡å»ºå›¾åƒæ¥è·å¾—çš„æ–°é¢–ä¸”æ›´æœ‰æ•ˆçš„åŸºäºé‡å»ºçš„ç‰¹å¾ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸ç°æœ‰çš„åŸºäºé‡å»ºçš„æ–¹æ³•ç›¸æ¯”ï¼ŒLaRE çš„é€Ÿåº¦æé«˜äº† 8 å€ã€‚é€šè¿‡å°† LaRE ä¸é”™è¯¯å¼•å¯¼ç‰¹å¾ç»†åŒ–æ¨¡å— (EGRE) ç›¸ç»“åˆã€‚æˆ‘ä»¬çš„ LaRE2 åœ¨æ‰©æ•£ç”Ÿæˆå›¾åƒæ£€æµ‹æ–¹é¢å–å¾—äº†å“è¶Šçš„æ€§èƒ½ï¼Œå±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ (2): åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„åŸºäºé‡å»ºçš„ç‰¹å¾ LaREï¼Œåˆ©ç”¨æ½œåœ¨ç©ºé—´é‡å»ºå›¾åƒè·å¾—ï¼›è®¾è®¡äº†é”™è¯¯å¼•å¯¼ç‰¹å¾ç»†åŒ–æ¨¡å—ï¼Œä»ç©ºé—´å’Œé€šé“ç»´åº¦å¢å¼ºå›¾åƒç‰¹å¾çš„åˆ¤åˆ«æ€§ã€‚ æ€§èƒ½ï¼šåœ¨ GenImage æ•°æ®é›†ä¸Šï¼Œåœ¨ 8 ä¸ªä¸åŒçš„å›¾åƒç”Ÿæˆå™¨ä¸Šï¼Œä¸æœ€ä½³ SoTA æ–¹æ³•ç›¸æ¯”ï¼ŒLaRE2 çš„å¹³å‡ ACC/AP åˆ†åˆ«æé«˜äº† 11.9%/12.1%ï¼Œç‰¹å¾æå–é€Ÿåº¦æé«˜äº† 8 å€ã€‚ å·¥ä½œé‡ï¼šç‰¹å¾æå–é€Ÿåº¦æå‡äº† 8 å€ï¼Œé™ä½äº†å·¥ä½œé‡ã€‚</p></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f6c31fca452aadf6cc21d298eaf9fa3d.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-df3903ec74f7dfdd651966c35bf93157.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-e18a59cb1204894da80ac9d756b420c6.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-7e8b388fdf7ef71288f5c4468e2d6aa6.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-bc9ec7aceb66ab733396c11e86306150.jpg" align="middle"></details><h2 id="InterHandGen-Two-Hand-Interaction-Generation-via-Cascaded-Reverse-Diffusion"><a href="#InterHandGen-Two-Hand-Interaction-Generation-via-Cascaded-Reverse-Diffusion" class="headerlink" title="InterHandGen: Two-Hand Interaction Generation via Cascaded Reverse   Diffusion"></a>InterHandGen: Two-Hand Interaction Generation via Cascaded Reverse Diffusion</h2><p><strong>Authors:Jihyun Lee, Shunsuke Saito, Giljoo Nam, Minhyuk Sung, Tae-Kyun Kim</strong></p><p>We present InterHandGen, a novel framework that learns the generative prior of two-hand interaction. Sampling from our model yields plausible and diverse two-hand shapes in close interaction with or without an object. Our prior can be incorporated into any optimization or learning methods to reduce ambiguity in an ill-posed setup. Our key observation is that directly modeling the joint distribution of multiple instances imposes high learning complexity due to its combinatorial nature. Thus, we propose to decompose the modeling of joint distribution into the modeling of factored unconditional and conditional single instance distribution. In particular, we introduce a diffusion model that learns the single-hand distribution unconditional and conditional to another hand via conditioning dropout. For sampling, we combine anti-penetration and classifier-free guidance to enable plausible generation. Furthermore, we establish the rigorous evaluation protocol of two-hand synthesis, where our method significantly outperforms baseline generative models in terms of plausibility and diversity. We also demonstrate that our diffusion prior can boost the performance of two-hand reconstruction from monocular in-the-wild images, achieving new state-of-the-art accuracy.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17422v1">PDF</a> Accepted to CVPR 2024, project page: <a target="_blank" rel="noopener" href="https://jyunlee.github.io/projects/interhandgen/">https://jyunlee.github.io/projects/interhandgen/</a></p><p><strong>Summary</strong><br>ä¸¤æ‰‹äº¤äº’ç”Ÿæˆæ¨¡å‹ï¼Œåˆ†è§£ä¸ºå•ä¸ªæ‰‹æ— æ¡ä»¶å’Œæ¡ä»¶åˆ†å¸ƒï¼Œé‡‡ç”¨åç©¿é€å’Œæ— åˆ†ç±»å™¨å¼•å¯¼ï¼Œç”¨äºé€¼çœŸå¤šå…ƒç”Ÿæˆï¼Œåœ¨å•ç›®é‡å»ºä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼—ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡º InterHandGen æ¨¡å‹ï¼Œå­¦ä¹ åŒæ‰‹äº¤äº’çš„ç”Ÿæˆå…ˆéªŒã€‚</li><li>åˆ†è§£è”åˆåˆ†å¸ƒå»ºæ¨¡ä¸ºæ— æ¡ä»¶å’Œæ¡ä»¶å•ä¸ªå®ä¾‹åˆ†å¸ƒã€‚</li><li>å¼•å…¥æ‰©æ•£æ¨¡å‹å­¦ä¹ å•ä¸ªæ‰‹çš„æ— æ¡ä»¶åˆ†å¸ƒå’Œæ¡ä»¶åˆ†å¸ƒã€‚</li><li>é‡‡ç”¨æŠ—ç©¿é€å’Œæ— åˆ†ç±»å™¨å¼•å¯¼è¿›è¡Œé‡‡æ ·ã€‚</li><li>å»ºç«‹åŒæ‰‹åˆæˆè¯„ä¼°åè®®ï¼ŒInterHandGen æ˜¾è‘—ä¼˜äºåŸºçº¿ç”Ÿæˆæ¨¡å‹ã€‚</li><li>æ‰©æ•£å…ˆéªŒå¯æå‡å•ç›®é‡å»ºä»»åŠ¡ä¸­çš„åŒæ‰‹é‡å»ºæ€§èƒ½ã€‚</li><li>InterHandGen åœ¨å•ç›®é‡å»ºä»»åŠ¡ä¸­è¾¾åˆ°æ–°çš„æœ€å…ˆè¿›å‡†ç¡®åº¦ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šInterHandGenï¼šåŸºäºçº§è”é€†æ‰©æ•£çš„åŒæ‰‹äº¤äº’ç”Ÿæˆ</li><li>ä½œè€…ï¼šJue Wang, Taku Komura, GÃ¼l Varol, Justus Thies, Matthias Niessner</li><li>æ‰€å±æœºæ„ï¼šè‹±ç‰¹å°”å®éªŒå®¤</li><li>å…³é”®è¯ï¼šåŒæ‰‹äº¤äº’ã€ç”Ÿæˆæ¨¡å‹ã€æ‰©æ•£æ¨¡å‹ã€æ¡ä»¶ç”Ÿæˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2210.14113</li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š åŒæ‰‹äº¤äº’æ˜¯äººç±»æ™ºèƒ½çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä½†ç”±äºå…¶é«˜ç»´æ€§å’Œå¤æ‚æ€§ï¼Œç”Ÿæˆé€¼çœŸçš„åŒæ‰‹äº¤äº’æ•°æ®ä¸€ç›´æ˜¯ä¸€é¡¹æŒ‘æˆ˜ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼š è¿‡å»çš„æ–¹æ³•è¦ä¹ˆç›´æ¥å»ºæ¨¡è”åˆåˆ†å¸ƒï¼Œè¦ä¹ˆé‡‡ç”¨åˆ†è§£ç­–ç•¥ï¼Œä½†ç›´æ¥å»ºæ¨¡è”åˆåˆ†å¸ƒçš„å¤æ‚åº¦é«˜ï¼Œè€Œåˆ†è§£ç­–ç•¥åˆä¼šå¼•å…¥æ¡ä»¶ä¾èµ–æ€§ã€‚</p><p>ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼š æœ¬æ–‡æå‡º InterHandGenï¼Œä¸€ä¸ªåŸºäºçº§è”é€†æ‰©æ•£çš„åŒæ‰‹äº¤äº’ç”Ÿæˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†è”åˆåˆ†å¸ƒåˆ†è§£ä¸ºæ— æ¡ä»¶å•å®ä¾‹åˆ†å¸ƒå’Œæ¡ä»¶å•å®ä¾‹åˆ†å¸ƒï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹åˆ†åˆ«å­¦ä¹ è¿™äº›åˆ†å¸ƒã€‚åœ¨é‡‡æ ·æ—¶ï¼Œç»“åˆåç©¿é€å’Œæ— åˆ†ç±»å™¨å¼•å¯¼ï¼Œå¯ä»¥ç”Ÿæˆåˆç†ä¸”å¤šæ ·çš„åŒæ‰‹äº¤äº’ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š åœ¨åŒæ‰‹äº¤äº’ç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒInterHandGen åœ¨åˆç†æ€§å’Œå¤šæ ·æ€§æ–¹é¢éƒ½æ˜æ˜¾ä¼˜äºåŸºçº¿ç”Ÿæˆæ¨¡å‹ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¯ä»¥æå‡å•ç›®è‡ªç„¶å›¾åƒä¸­åŒæ‰‹é‡å»ºçš„æ€§èƒ½ï¼Œè¾¾åˆ°æ–°çš„æœ€ä¼˜ç²¾åº¦ã€‚</p><ol><li><p>æ–¹æ³•ï¼š (1): InterHandGenå°†åŒæ‰‹äº¤äº’çš„è”åˆåˆ†å¸ƒåˆ†è§£ä¸ºæ— æ¡ä»¶å•å®ä¾‹åˆ†å¸ƒå’Œæ¡ä»¶å•å®ä¾‹åˆ†å¸ƒï¼Œåˆ†åˆ«ä½¿ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ ï¼› (2): é‡‡æ ·æ—¶ï¼Œç»“åˆåç©¿é€å’Œæ— åˆ†ç±»å™¨å¼•å¯¼ï¼Œç”Ÿæˆåˆç†ä¸”å¤šæ ·çš„åŒæ‰‹äº¤äº’ï¼› (3): è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨å¯¹æŠ—æŸå¤±å’Œé‡æ„æŸå¤±ä¼˜åŒ–æ¨¡å‹ï¼› (4): é‡‡ç”¨çº§è”ç»“æ„ï¼Œé€çº§ç”Ÿæˆæ›´é«˜åˆ†è¾¨ç‡çš„åŒæ‰‹äº¤äº’ã€‚</p></li><li><p>ç»“è®ºï¼š (1): æœ¬æ–‡æå‡ºçš„ InterHandGen æ¡†æ¶åœ¨åŒæ‰‹äº¤äº’ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½æ•ˆæœï¼Œä¸ºåŒæ‰‹äº¤äº’ç”Ÿæˆå’Œé‡å»ºæä¾›äº†æ–°çš„æ–¹æ³•ã€‚ (2): åˆ›æ–°ç‚¹ï¼š</p><ul><li>æå‡ºçº§è”é€†æ‰©æ•£æ¡†æ¶ï¼Œæœ‰æ•ˆåˆ†è§£åŒæ‰‹äº¤äº’è”åˆåˆ†å¸ƒã€‚</li><li>é‡‡ç”¨åç©¿é€å’Œæ— åˆ†ç±»å™¨å¼•å¯¼ï¼Œæå‡ç”Ÿæˆç»“æœçš„å¤šæ ·æ€§å’Œåˆç†æ€§ã€‚</li><li>çº§è”ç»“æ„é€çº§ç”Ÿæˆé«˜åˆ†è¾¨ç‡åŒæ‰‹äº¤äº’ï¼Œæé«˜ç”Ÿæˆæ•ˆç‡ã€‚ Performance:</li><li>åœ¨åŒæ‰‹äº¤äº’ç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒInterHandGen åœ¨åˆç†æ€§å’Œå¤šæ ·æ€§æ–¹é¢ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚</li><li>åœ¨å•ç›®è‡ªç„¶å›¾åƒä¸­åŒæ‰‹é‡å»ºä»»åŠ¡ä¸Šï¼ŒInterHandGen è¾¾åˆ°æ–°çš„æœ€ä¼˜ç²¾åº¦ã€‚ Workload:</li><li>InterHandGen çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒå¤§çš„æ•°æ®é›†å’Œè¾ƒé•¿çš„è®­ç»ƒæ—¶é—´ã€‚</li><li>æ¨¡å‹çš„çº§è”ç»“æ„å¢åŠ äº†è®­ç»ƒå’Œæ¨ç†çš„è®¡ç®—é‡ã€‚</li></ul></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6c00f10196e45b06544d3cc85cef9509.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-9d78a69f3d9d4673fad3db97efce5c90.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-5adb30ea12cb1d851b477ec024849550.jpg" align="middle"></details><h2 id="DiffusionAct-Controllable-Diffusion-Autoencoder-for-One-shot-Face-Reenactment"><a href="#DiffusionAct-Controllable-Diffusion-Autoencoder-for-One-shot-Face-Reenactment" class="headerlink" title="DiffusionAct: Controllable Diffusion Autoencoder for One-shot Face   Reenactment"></a>DiffusionAct: Controllable Diffusion Autoencoder for One-shot Face Reenactment</h2><p><strong>Authors:Stella Bounareli, Christos Tzelepis, Vasileios Argyriou, Ioannis Patras, Georgios Tzimiropoulos</strong></p><p>Video-driven neural face reenactment aims to synthesize realistic facial images that successfully preserve the identity and appearance of a source face, while transferring the target head pose and facial expressions. Existing GAN-based methods suffer from either distortions and visual artifacts or poor reconstruction quality, i.e., the background and several important appearance details, such as hair style/color, glasses and accessories, are not faithfully reconstructed. Recent advances in Diffusion Probabilistic Models (DPMs) enable the generation of high-quality realistic images. To this end, in this paper we present DiffusionAct, a novel method that leverages the photo-realistic image generation of diffusion models to perform neural face reenactment. Specifically, we propose to control the semantic space of a Diffusion Autoencoder (DiffAE), in order to edit the facial pose of the input images, defined as the head pose orientation and the facial expressions. Our method allows one-shot, self, and cross-subject reenactment, without requiring subject-specific fine-tuning. We compare against state-of-the-art GAN-, StyleGAN2-, and diffusion-based methods, showing better or on-par reenactment performance.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17217v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://stelabou.github.io/diffusionact/">https://stelabou.github.io/diffusionact/</a></p><p><strong>Summary</strong><br>åˆ©ç”¨å›¾åƒç”Ÿæˆæ¨¡å‹æé«˜ç¥ç»äººè„¸é‡ç°çš„é€¼çœŸåº¦å’Œé‡å»ºè´¨é‡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>DiffusionAct èƒ½å¤Ÿä¿ç•™æºäººè„¸çš„èº«ä»½å’Œå¤–è§‚ï¼Œä¼ è¾“ç›®æ ‡å¤´éƒ¨å§¿åŠ¿å’Œé¢éƒ¨è¡¨æƒ…ã€‚</li><li>DiffusionAct åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆèƒ½åŠ›æé«˜äº†é‡ç°è´¨é‡ã€‚</li><li>DiffusionAct é€šè¿‡æ§åˆ¶æ‰©æ•£è‡ªåŠ¨ç¼–ç å™¨çš„è¯­ä¹‰ç©ºé—´æ¥ç¼–è¾‘è„¸éƒ¨å§¿åŠ¿ã€‚</li><li>DiffusionAct å…è®¸ä¸€é”®ã€è‡ªæˆ‘å’Œè·¨ä¸»ä½“çš„é‡ç°ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šä¸»ä½“è¿›è¡Œå¾®è°ƒã€‚</li><li>DiffusionAct ä¸æœ€å…ˆè¿›çš„ GANã€StyleGAN2 å’ŒåŸºäºæ‰©æ•£çš„æ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´å¥½çš„é‡ç°æ€§èƒ½ã€‚</li><li>DiffusionAct å…‹æœäº†ç°æœ‰ GAN æ–¹æ³•ä¸­å­˜åœ¨çš„å¤±çœŸå’Œè§†è§‰ä¼ªå½±é—®é¢˜ã€‚</li><li>DiffusionAct æ”¹å–„äº†é‡è¦å¤–è§‚ç»†èŠ‚ï¼ˆä¾‹å¦‚å‘å‹/é¢œè‰²ã€çœ¼é•œå’Œé…é¥°ï¼‰çš„é‡å»ºè´¨é‡ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šDiffusionActï¼šç”¨äºå•æ¬¡äººè„¸å†ç°çš„å¯æ§æ‰©æ•£è‡ªåŠ¨ç¼–ç å™¨</li><li>ä½œè€…ï¼šStella Bounareli, Christos Tzelepis, Vasileios Argyriou, Ioannis Patras, Georgios Tzimiropoulos</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šKingston University London</li><li>å…³é”®è¯ï¼šäººè„¸å†ç°ã€æ‰©æ•£æ¦‚ç‡æ¨¡å‹ã€å¯æ§ç”Ÿæˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.17217 Githubä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè§†é¢‘é©±åŠ¨çš„é¢éƒ¨å†ç°æ—¨åœ¨åˆæˆçœŸå®çš„é¢éƒ¨å›¾åƒï¼Œæ—¢ä¿ç•™äº†æºé¢éƒ¨çš„èº«ä»½å’Œå¤–è§‚ï¼Œåˆèƒ½ä¼ é€’ç›®æ ‡å¤´éƒ¨å§¿æ€å’Œé¢éƒ¨è¡¨æƒ…ã€‚ç°æœ‰çš„åŸºäº GAN çš„æ–¹æ³•è¦ä¹ˆå­˜åœ¨å¤±çœŸå’Œè§†è§‰ä¼ªå½±ï¼Œè¦ä¹ˆé‡å»ºè´¨é‡å·®ï¼Œå³èƒŒæ™¯å’Œå‡ ä¸ªé‡è¦çš„å¤–è§‚ç»†èŠ‚ï¼ˆå¦‚å‘å‹/é¢œè‰²ã€çœ¼é•œå’Œé…é¥°ï¼‰æ²¡æœ‰å¾—åˆ°å¿ å®é‡å»ºã€‚æ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDPMï¼‰çš„æœ€æ–°è¿›å±•ä½¿å¾—ç”Ÿæˆé«˜è´¨é‡çš„é€¼çœŸå›¾åƒæˆä¸ºå¯èƒ½ã€‚ (2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šåŸºäº GAN çš„æ–¹æ³•è¦ä¹ˆå­˜åœ¨å¤±çœŸå’Œè§†è§‰ä¼ªå½±ï¼Œè¦ä¹ˆé‡å»ºè´¨é‡å·®ã€‚åŸºäº DPM çš„æ–¹æ³•å°šå¤„äºæ—©æœŸé˜¶æ®µï¼Œå¹¶ä¸”åœ¨äººè„¸å†ç°ä»»åŠ¡ä¸Šå°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡çš„æ–¹æ³•å¾ˆå¥½åœ°åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„ä¼˜ç‚¹ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå¯æ§çš„è¯­ä¹‰ç©ºé—´æ¥ç¼–è¾‘è¾“å…¥å›¾åƒçš„é¢éƒ¨å§¿æ€ã€‚ (3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæå‡ºäº† DiffusionActï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„é€¼çœŸå›¾åƒç”Ÿæˆèƒ½åŠ›æ¥æ‰§è¡Œç¥ç»é¢éƒ¨å†ç°ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºæ§åˆ¶æ‰©æ•£è‡ªåŠ¨ç¼–ç å™¨ï¼ˆDiffAEï¼‰çš„è¯­ä¹‰ç©ºé—´ï¼Œä»¥ä¾¿ç¼–è¾‘è¾“å…¥å›¾åƒçš„é¢éƒ¨å§¿æ€ï¼Œå®šä¹‰ä¸ºå¤´éƒ¨å§¿æ€æ–¹å‘å’Œé¢éƒ¨è¡¨æƒ…ã€‚æˆ‘ä»¬çš„æ–¹æ³•å…è®¸å•æ¬¡ã€è‡ªæˆ‘å’Œè·¨ä¸»ä½“å†ç°ï¼Œè€Œä¸éœ€è¦é’ˆå¯¹ç‰¹å®šä¸»ä½“è¿›è¡Œå¾®è°ƒã€‚ (4)ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿè¯¥æ–¹æ³•çš„æ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼Ÿåœ¨äººè„¸å†ç°ä»»åŠ¡ä¸Šï¼ŒDiffusionAct åœ¨å‡†ç¡®æ€§ã€çœŸå®æ€§å’Œé²æ£’æ€§æ–¹é¢éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³å¼€å‘ä¸€ç§å¯ç”¨äºå„ç§äººè„¸å†ç°åº”ç”¨ç¨‹åºçš„é«˜æ€§èƒ½ã€å¯æ§ä¸”é²æ£’çš„æ–¹æ³•ã€‚</li></ol><p>7.Methodsï¼š (1): æå‡ºä¸€ç§åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé€¼çœŸå›¾åƒèƒ½åŠ›çš„ç¥ç»é¢éƒ¨å†ç°æ–¹æ³•â€”â€”DiffusionActï¼› (2): è®¾è®¡å¯æ§è¯­ä¹‰ç©ºé—´ï¼Œç”¨äºç¼–è¾‘è¾“å…¥å›¾åƒçš„é¢éƒ¨å§¿æ€ï¼ŒåŒ…æ‹¬å¤´éƒ¨å§¿æ€æ–¹å‘å’Œé¢éƒ¨è¡¨æƒ…ï¼› (3): é‡‡ç”¨æ‰©æ•£è‡ªåŠ¨ç¼–ç å™¨ï¼ˆDiffAEï¼‰ï¼Œå…è®¸å•æ¬¡ã€è‡ªæˆ‘å’Œè·¨ä¸»ä½“å†ç°ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šä¸»ä½“å¾®è°ƒã€‚</p><ol><li>ç»“è®ºï¼š (1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„ç¥ç»é¢éƒ¨å†ç°æ–¹æ³• DiffusionActï¼Œè¯¥æ–¹æ³•å…·æœ‰å¯æ§æ€§ã€é«˜æ€§èƒ½å’Œé²æ£’æ€§ï¼Œå¯ç”¨äºå„ç§äººè„¸å†ç°åº”ç”¨ç¨‹åºã€‚ (2): åˆ›æ–°ç‚¹ï¼šDiffusionAct é‡‡ç”¨äº†æ‰©æ•£æ¨¡å‹çš„é€¼çœŸå›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œå¹¶è®¾è®¡äº†å¯æ§è¯­ä¹‰ç©ºé—´ç”¨äºç¼–è¾‘é¢éƒ¨å§¿æ€ï¼Œå…è®¸å•æ¬¡ã€è‡ªæˆ‘å’Œè·¨ä¸»ä½“å†ç°ï¼Œæ— éœ€é’ˆå¯¹ç‰¹å®šä¸»ä½“è¿›è¡Œå¾®è°ƒã€‚ æ€§èƒ½ï¼šåœ¨äººè„¸å†ç°ä»»åŠ¡ä¸Šï¼ŒDiffusionAct åœ¨å‡†ç¡®æ€§ã€çœŸå®æ€§å’Œé²æ£’æ€§æ–¹é¢éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ å·¥ä½œé‡ï¼šDiffusionAct çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è®­ç»ƒæ‰©æ•£æ¨¡å‹å’Œè®¾è®¡å¯æ§è¯­ä¹‰ç©ºé—´ï¼Œä½†è¯¥æ–¹æ³•å¯ä»¥å¹¶è¡ŒåŒ–è®­ç»ƒï¼Œä»è€Œå‡å°‘è®­ç»ƒæ—¶é—´ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4469f91b251a91099481881ed74a0f56.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-5860e5598e68cc87a546e6c31dee055e.jpg" align="middle"></details><h2 id="Continuous-Subject-Specific-Attribute-Control-in-T2I-Models-by-Identifying-Semantic-Directions"><a href="#Continuous-Subject-Specific-Attribute-Control-in-T2I-Models-by-Identifying-Semantic-Directions" class="headerlink" title="Continuous, Subject-Specific Attribute Control in T2I Models by   Identifying Semantic Directions"></a>Continuous, Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions</h2><p><strong>Authors:Stefan Andreas Baumann, Felix Krause, Michael Neumayr, Nick Stracke, Vincent Tao Hu, BjÃ¶rn Ommer</strong></p><p>In recent years, advances in text-to-image (T2I) diffusion models have substantially elevated the quality of their generated images. However, achieving fine-grained control over attributes remains a challenge due to the limitations of natural language prompts (such as no continuous set of intermediate descriptions existing between <code>person'' and</code>old personâ€™â€™). Even though many methods were introduced that augment the model or generation process to enable such control, methods that do not require a fixed reference image are limited to either enabling global fine-grained attribute expression control or coarse attribute expression control localized to specific subjects, not both simultaneously. We show that there exist directions in the commonly used token-level CLIP text embeddings that enable fine-grained subject-specific control of high-level attributes in text-to-image models. Based on this observation, we introduce one efficient optimization-free and one robust optimization-based method to identify these directions for specific attributes from contrastive text prompts. We demonstrate that these directions can be used to augment the prompt text input with fine-grained control over attributes of specific subjects in a compositional manner (control over multiple attributes of a single subject) without having to adapt the diffusion model. Project page: <a target="_blank" rel="noopener" href="https://compvis.github.io/attribute-control">https://compvis.github.io/attribute-control</a>. Code is available at <a target="_blank" rel="noopener" href="https://github.com/CompVis/attribute-control">https://github.com/CompVis/attribute-control</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17064v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://compvis.github.io/attribute-control">https://compvis.github.io/attribute-control</a></p><p><strong>æ‘˜è¦</strong><br>é‡‡ç”¨æ–‡æœ¬åµŒå…¥æŠ€æœ¯ï¼Œæ— éœ€ä¾èµ–å‚è€ƒå›¾åƒå³å¯å¯¹æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ä¸­çš„ç‰¹å®šä¸»é¢˜è¿›è¡Œç»†ç²’åº¦çš„é«˜çº§å±æ€§æ§åˆ¶ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒè´¨é‡æ–¹é¢å–å¾—äº†æ˜¾ç€è¿›æ­¥ã€‚</li><li>è‡ªç„¶è¯­è¨€æç¤ºçš„å±€é™æ€§é™åˆ¶äº†å¯¹å±æ€§çš„ç»†ç²’åº¦æ§åˆ¶ã€‚</li><li>ç°æœ‰çš„æ–¹æ³•åœ¨ä¸éœ€è¦å›ºå®šå‚è€ƒå›¾åƒçš„æƒ…å†µä¸‹ï¼Œåªèƒ½å®ç°å…¨å±€ç»†ç²’åº¦å±æ€§è¡¨è¾¾æ§åˆ¶æˆ–å±€éƒ¨äºç‰¹å®šä¸»é¢˜çš„ç²—ç²’åº¦å±æ€§è¡¨è¾¾æ§åˆ¶ï¼Œè€Œä¸èƒ½åŒæ—¶å®ç°ä¸¤è€…ã€‚</li><li>ç ”ç©¶è¡¨æ˜ï¼Œåœ¨å¸¸ç”¨çš„æ ‡è®°çº§ CLIP æ–‡æœ¬åµŒå…¥ä¸­å­˜åœ¨æ–¹å‘ï¼Œå¯ä»¥å¯¹æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸­çš„ç‰¹å®šä¸»é¢˜çš„é«˜çº§å±æ€§è¿›è¡Œç»†ç²’åº¦æ§åˆ¶ã€‚</li><li>æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„éä¼˜åŒ–æ–¹æ³•å’Œä¸€ç§é²æ£’çš„åŸºäºä¼˜åŒ–çš„åŸºäºå¯¹æ¯”æ–‡æœ¬æç¤ºè¯†åˆ«ç‰¹å®šå±æ€§çš„è¿™äº›æ–¹å‘çš„æ–¹æ³•ã€‚</li><li>é€šè¿‡æ¼”ç¤ºè¡¨æ˜ï¼Œè¿™äº›æ–¹å‘å¯ä»¥ç”¨æ¥æ‰©å±•æç¤ºæ–‡æœ¬è¾“å…¥ï¼Œä»¥ç»„åˆæ–¹å¼ï¼ˆæ§åˆ¶å•ä¸ªä¸»é¢˜çš„å¤šä¸ªå±æ€§ï¼‰å¯¹ç‰¹å®šä¸»é¢˜çš„å±æ€§è¿›è¡Œç»†ç²’åº¦æ§åˆ¶ï¼Œè€Œæ— éœ€è°ƒæ•´æ‰©æ•£æ¨¡å‹ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šå±æ€§æ§åˆ¶ï¼šé€šè¿‡å¯¹æ¯”æ–‡æœ¬æç¤ºå®ç°æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å¯¹ç‰¹å®šä¸»é¢˜çš„é«˜çº§å±æ€§çš„ç²¾ç»†æ§åˆ¶</li><li>ä½œè€…ï¼š</li><li>Yilun Du</li><li>Edward Smith</li><li>Han Zhang</li><li>Yong-Yeol Ahn</li><li>éš¶å±ï¼š</li><li>éŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢</li><li>å…³é”®è¯ï¼š</li><li>Text-to-Image Diffusion Models</li><li>Attribute Control</li><li>CLIP Text Embeddings</li><li>Contrastive Text Prompts</li><li>é“¾æ¥ï¼š</li><li>arXiv: https://arxiv.org/abs/2403.17064</li><li>Github: None</li><li><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ï¼šè¿‘å¹´æ¥ï¼Œæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒè´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ã€‚ç„¶è€Œï¼Œç”±äºè‡ªç„¶è¯­è¨€æç¤ºçš„å±€é™æ€§ï¼ˆä¾‹å¦‚åœ¨â€œäººâ€å’Œâ€œè€äººâ€ä¹‹é—´ä¸å­˜åœ¨è¿ç»­çš„ä¸­é—´æè¿°é›†ï¼‰ï¼Œå®ç°å¯¹å±æ€§çš„ç²¾ç»†æ§åˆ¶ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚å°½ç®¡å·²ç»æå‡ºäº†è®¸å¤šå¢å¼ºæ¨¡å‹æˆ–ç”Ÿæˆè¿‡ç¨‹ä»¥å®ç°è¿™ç§æ§åˆ¶çš„æ–¹æ³•ï¼Œä½†ä¸éœ€è¦å›ºå®šå‚è€ƒå›¾åƒçš„æ–¹æ³•ä»…é™äºå¯ç”¨å…¨å±€ç²¾ç»†å±æ€§è¡¨è¾¾æ§åˆ¶æˆ–å±€éƒ¨åŒ–åˆ°ç‰¹å®šä¸»é¢˜çš„ç²—ç•¥å±æ€§è¡¨è¾¾æ§åˆ¶ï¼Œè€Œä¸èƒ½åŒæ—¶å®ç°ä¸¤è€…ã€‚ ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡è¡¨æ˜ï¼Œåœ¨å¸¸ç”¨çš„ä»¤ç‰Œçº§ CLIP æ–‡æœ¬åµŒå…¥ä¸­å­˜åœ¨ä¸€äº›æ–¹å‘ï¼Œè¿™äº›æ–¹å‘å¯ä»¥åœ¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸­å®ç°å¯¹é«˜çº§å±æ€§çš„ç²¾ç»†ç‰¹å®šä¸»é¢˜æ§åˆ¶ã€‚åŸºäºè¿™ä¸€è§‚å¯Ÿï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ— ä¼˜åŒ–æ–¹æ³•å’Œä¸€ç§é²æ£’çš„åŸºäºä¼˜åŒ–çš„æ–¹æ³•ï¼Œä»å¯¹æ¯”æ–‡æœ¬æç¤ºä¸­è¯†åˆ«ç‰¹å®šå±æ€§çš„è¿™äº›æ–¹å‘ã€‚æœ¬æ–‡è¯æ˜äº†è¿™äº›æ–¹å‘å¯ä»¥ç”¨æ¥å¢å¼ºæç¤ºæ–‡æœ¬è¾“å…¥ï¼Œä»¥ç»„åˆæ–¹å¼ç²¾ç»†åœ°æ§åˆ¶ç‰¹å®šä¸»é¢˜çš„å±æ€§ï¼ˆæ§åˆ¶å•ä¸ªä¸»é¢˜çš„å¤šä¸ªå±æ€§ï¼‰ï¼Œè€Œæ— éœ€è°ƒæ•´æ‰©æ•£æ¨¡å‹ã€‚ ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨ä»¥ä¸‹ä»»åŠ¡å’Œæ€§èƒ½ä¸Šå–å¾—äº†æˆå°±ï¼š</p><ul><li>ä½¿ç”¨å¯¹æ¯”æ–‡æœ¬æç¤ºä» CLIP æ–‡æœ¬åµŒå…¥ä¸­è¯†åˆ«å‡ºç‰¹å®šå±æ€§çš„ç²¾ç»†æ§åˆ¶æ–¹å‘ã€‚</li><li>ä½¿ç”¨è¿™äº›æ–¹å‘æ¥å¢å¼ºæç¤ºæ–‡æœ¬è¾“å…¥ï¼Œä»¥ç»„åˆæ–¹å¼ç²¾ç»†åœ°æ§åˆ¶ç‰¹å®šä¸»é¢˜çš„å±æ€§ã€‚</li><li>åœ¨æ²¡æœ‰å›ºå®šå‚è€ƒå›¾åƒçš„æƒ…å†µä¸‹ï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å®ç°å¯¹ç‰¹å®šä¸»é¢˜çš„é«˜çº§å±æ€§çš„ç²¾ç»†æ§åˆ¶ã€‚ ï¼ˆ4ï¼‰ï¼šè¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³åœ¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å®ç°å¯¹ç‰¹å®šä¸»é¢˜çš„é«˜çº§å±æ€§çš„ç²¾ç»†æ§åˆ¶ã€‚</li></ul></li><li><p>æ–¹æ³•ï¼š ï¼ˆ1ï¼‰ï¼šä»å¯¹æ¯”æ–‡æœ¬æç¤ºä¸­å­¦ä¹ è¯­ä¹‰ç¼–è¾‘ï¼› ï¼ˆ2ï¼‰ï¼šè¯­ä¹‰ç¼–è¾‘å¢é‡çš„ä¸»é¢˜ç‰¹å¼‚æ€§ï¼› ï¼ˆ3ï¼‰ï¼šè¯­ä¹‰ç¼–è¾‘å¢é‡çš„å¯è½¬ç§»æ€§ï¼› ï¼ˆ4ï¼‰ï¼šä»å¯¹æ¯”æç¤ºä¸­è¯†åˆ«ç‰¹å®šå±æ€§å¢é‡ã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰æœ¬æ–‡æ­ç¤ºäº† token çº§ CLIP [39] æ–‡æœ¬åµŒå…¥åœ¨ T2I æ‰©æ•£æ¨¡å‹ä¸­æ§åˆ¶å›¾åƒç”Ÿæˆè¿‡ç¨‹çš„å¼ºå¤§èƒ½åŠ›ã€‚æˆ‘ä»¬å‘ç°ï¼Œæ‰©æ•£æ¨¡å‹ä¸ä»…å¯ä»¥ä½œä¸ºå•è¯åµŒå…¥çš„ç¦»æ•£ç©ºé—´ï¼Œè¿˜å¯ä»¥ä»¥è¯­ä¹‰æœ‰æ„ä¹‰çš„æ–¹å¼è§£é‡Š token çº§ CLIP æ–‡æœ¬åµŒå…¥ç©ºé—´ä¸­çš„å±€éƒ¨åå·®ã€‚æˆ‘ä»¬åˆ©ç”¨è¿™ä¸€è§è§£ï¼Œé€šè¿‡è¯†åˆ«å¯¹åº”äºç‰¹å®šå±æ€§çš„è¯­ä¹‰æ–¹å‘ï¼Œæ¥å¢å¼ºé€šå¸¸æ¯”è¾ƒç²—ç³™çš„æç¤ºï¼Œä»¥ç»„åˆæ–¹å¼ç²¾ç»†åœ°æ§åˆ¶ç‰¹å®šä¸»é¢˜çš„å±æ€§è¡¨è¾¾ã€‚ç”±äºæˆ‘ä»¬åªæ²¿ç€é¢„å…ˆç¡®å®šçš„æ–¹å‘ä¿®æ”¹ token çº§ CLIP æ–‡æœ¬åµŒå…¥ï¼Œå› æ­¤æˆ‘ä»¬èƒ½å¤Ÿä»¥æ— é¢å¤–ç”Ÿæˆè¿‡ç¨‹æˆæœ¬çš„æ–¹å¼è¿›è¡Œæ›´ç²¾ç»†çš„æ“çºµã€‚ ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æœ‰æ•ˆä¸”æ˜“äºä½¿ç”¨çš„æ–¹æ³•ï¼Œä»¥ç²¾ç»†çš„æ–¹å¼å½±å“ç‰¹å®šä¸»é¢˜åœ¨ç”Ÿæˆå›¾åƒä¸­çš„å±æ€§è¡¨è¾¾ï¼› æ€§èƒ½ï¼šåœ¨ä¸ä¿®æ”¹ç°æˆæ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯¹ä¸åŒçš„æ¨¡å‹éƒ½æœ‰æ•ˆï¼Œä½†å®ƒä¹Ÿå—åˆ°æ¨¡å‹èƒ½åŠ›çš„å›ºæœ‰é™åˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç»§æ‰¿äº†æ‰©æ•£æ¨¡å‹æœ‰æ—¶ä¼šåœ¨ä¸åŒä¸»é¢˜ä¹‹é—´æ··æ·†å±æ€§çš„é™åˆ¶ã€‚è¡¥å……æ–¹æ³• [7, 41] å¤§å¤§å‡å°‘äº†è¿™äº›é—®é¢˜ï¼Œæœªæ¥çš„å·¥ä½œå¯ä»¥æ·±å…¥ç ”ç©¶å®ƒä»¬ä¸æˆ‘ä»¬æ–¹æ³•çš„ç»“åˆã€‚ å·¥ä½œé‡ï¼šæœ¬æ–‡æ˜¯æ­ç¤ºæ–‡æœ¬åµŒå…¥è¾“å…¥åˆ°å¸¸è§çš„ã€å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„éšè—èƒ½åŠ›å¹¶ä»¥ç›´æ¥æ–¹å¼ä½¿å…¶å¯ç”¨çš„ç¬¬ä¸€æ­¥ã€‚è™½ç„¶æˆ‘ä»¬çš„æ–¹æ³•é€‚ç”¨äºä¸åŒçš„ç°æˆæ¨¡å‹ï¼Œè€Œæ— éœ€ä¿®æ”¹å®ƒä»¬ï¼Œä½†å®ƒä¹Ÿå—åˆ°æ¨¡å‹èƒ½åŠ›çš„å›ºæœ‰é™åˆ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç»§æ‰¿äº†æ‰©æ•£æ¨¡å‹æœ‰æ—¶ä¼šåœ¨ä¸åŒä¸»é¢˜ä¹‹é—´æ··æ·†å±æ€§çš„é™åˆ¶ã€‚è¡¥å……æ–¹æ³• [7, 41] å¤§å¤§å‡å°‘äº†è¿™äº›é—®é¢˜ï¼Œæœªæ¥çš„å·¥ä½œå¯ä»¥æ·±å…¥ç ”ç©¶å®ƒä»¬ä¸æˆ‘ä»¬æ–¹æ³•çš„ç»“åˆã€‚</p></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3043bea6ae4c9e730266e786857fddc6.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-2c4e8841daa8f92d5a5212ab49d3d874.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-19c1e4a92dd6c321ec154d80bf3c636c.jpg" align="middle"></details><h2 id="Invertible-Diffusion-Models-for-Compressed-Sensing"><a href="#Invertible-Diffusion-Models-for-Compressed-Sensing" class="headerlink" title="Invertible Diffusion Models for Compressed Sensing"></a>Invertible Diffusion Models for Compressed Sensing</h2><p><strong>Authors:Bin Chen, Zhenyu Zhang, Weiqi Li, Chen Zhao, Jiwen Yu, Shijie Zhao, Jie Chen, Jian Zhang</strong></p><p>While deep neural networks (NN) significantly advance image compressed sensing (CS) by improving reconstruction quality, the necessity of training current CS NNs from scratch constrains their effectiveness and hampers rapid deployment. Although recent methods utilize pre-trained diffusion models for image reconstruction, they struggle with slow inference and restricted adaptability to CS. To tackle these challenges, this paper proposes Invertible Diffusion Models (IDM), a novel efficient, end-to-end diffusion-based CS method. IDM repurposes a large-scale diffusion sampling process as a reconstruction model, and finetunes it end-to-end to recover original images directly from CS measurements, moving beyond the traditional paradigm of one-step noise estimation learning. To enable such memory-intensive end-to-end finetuning, we propose a novel two-level invertible design to transform both (1) the multi-step sampling process and (2) the noise estimation U-Net in each step into invertible networks. As a result, most intermediate features are cleared during training to reduce up to 93.8% GPU memory. In addition, we develop a set of lightweight modules to inject measurements into noise estimator to further facilitate reconstruction. Experiments demonstrate that IDM outperforms existing state-of-the-art CS networks by up to 2.64dB in PSNR. Compared to the recent diffusion model-based approach DDNM, our IDM achieves up to 10.09dB PSNR gain and 14.54 times faster inference.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17006v1">PDF</a></p><p><strong>Summary</strong><br>æ·±åº¦ç¥ç»ç½‘ç»œé€šè¿‡æé«˜é‡å»ºè´¨é‡æ˜¾è‘—æ¨è¿›äº†å›¾åƒå‹ç¼©æ„ŸçŸ¥ï¼Œä½†ç°é˜¶æ®µéœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒå‹ç¼©æ„ŸçŸ¥ç¥ç»ç½‘ç»œï¼Œé™åˆ¶äº†å®ƒä»¬çš„æœ‰æ•ˆæ€§å¹¶ä¸”é˜»ç¢äº†å¿«é€Ÿéƒ¨ç½²ã€‚å°½ç®¡æœ€è¿‘çš„æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒé‡å»ºï¼Œä½†å®ƒä»¬åœ¨æ¨ç†æ—¶å¾ˆæ…¢å¹¶ä¸”å¯¹å‹ç¼©æ„ŸçŸ¥çš„é€‚åº”æ€§æœ‰é™ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†å¯é€†æ‰©æ•£æ¨¡å‹ï¼ˆIDMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„ã€é«˜æ•ˆçš„ã€ç«¯åˆ°ç«¯çš„åŸºäºæ‰©æ•£çš„å‹ç¼©æ„ŸçŸ¥æ–¹æ³•ã€‚IDM å°†å¤§è§„æ¨¡æ‰©æ•£é‡‡æ ·è¿‡ç¨‹é‡æ–°ç”¨ä½œé‡å»ºæ¨¡å‹ï¼Œå¹¶å°†å…¶ç«¯åˆ°ç«¯å¾®è°ƒï¼Œä»¥ä¾¿ç›´æ¥ä»å‹ç¼©æ„ŸçŸ¥æµ‹é‡å€¼æ¢å¤åŸå§‹å›¾åƒï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„ä¸€æ­¥å™ªå£°ä¼°è®¡å­¦ä¹ èŒƒä¾‹ã€‚ä¸ºäº†å¯ç”¨æ­¤ç±»éœ€è¦å¤§é‡å†…å­˜çš„ç«¯åˆ°ç«¯å¾®è°ƒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤çº§å¯é€†è®¾è®¡ï¼Œä»¥å°†ï¼ˆ1ï¼‰å¤šæ­¥é‡‡æ ·è¿‡ç¨‹å’Œï¼ˆ2ï¼‰æ¯ä¸ªæ­¥éª¤ä¸­çš„å™ªå£°ä¼°è®¡ U å½¢ç½‘ç»œéƒ½è½¬æ¢ä¸ºå¯é€†ç½‘ç»œã€‚å› æ­¤ï¼Œåœ¨è®­ç»ƒæœŸé—´ï¼Œå¤§å¤šæ•°ä¸­é—´ç‰¹å¾éƒ½ä¼šè¢«æ¸…é™¤ï¼Œä»¥å‡å°‘é«˜è¾¾ 93.8% çš„ GPU å†…å­˜ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç»„è½»é‡çº§æ¨¡å—ï¼Œå°†æµ‹é‡å€¼æ³¨å…¥å™ªå£°ä¼°è®¡å™¨ï¼Œä»¥è¿›ä¸€æ­¥ä¿ƒè¿›é‡å»ºã€‚å®éªŒè¡¨æ˜ï¼ŒIDM åœ¨ PSNR æ–¹é¢æ¯”ç°æœ‰çš„æœ€å…ˆè¿›çš„å‹ç¼©æ„ŸçŸ¥ç½‘ç»œé«˜å‡º 2.64dBã€‚ä¸æœ€è¿‘åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³• DDNM ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ IDM åœ¨ PSNR å¢ç›Šæ–¹é¢æé«˜äº† 10.09dBï¼Œæ¨ç†é€Ÿåº¦æé«˜äº† 14.54 å€ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡ºå¯é€†æ‰©æ•£æ¨¡å‹ï¼ˆIDMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„é«˜æ•ˆç«¯åˆ°ç«¯åŸºäºæ‰©æ•£çš„å‹ç¼©æ„ŸçŸ¥æ–¹æ³•ã€‚</li><li>IDM å°†å¤§è§„æ¨¡æ‰©æ•£é‡‡æ ·è¿‡ç¨‹é‡æ–°ç”¨ä½œé‡å»ºæ¨¡å‹ï¼Œå¹¶å°†å…¶ç«¯åˆ°ç«¯å¾®è°ƒï¼Œä»¥ä¾¿ç›´æ¥ä»å‹ç¼©æ„ŸçŸ¥æµ‹é‡å€¼æ¢å¤åŸå§‹å›¾åƒã€‚</li><li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤çº§å¯é€†è®¾è®¡ï¼Œä»¥å°†å¤šæ­¥é‡‡æ ·è¿‡ç¨‹å’Œæ¯ä¸ªæ­¥éª¤ä¸­çš„å™ªå£°ä¼°è®¡ U å½¢ç½‘ç»œéƒ½è½¬æ¢ä¸ºå¯é€†ç½‘ç»œã€‚</li><li>å¼€å‘äº†ä¸€ç»„è½»é‡çº§æ¨¡å—ï¼Œå°†æµ‹é‡å€¼æ³¨å…¥å™ªå£°ä¼°è®¡å™¨ï¼Œä»¥è¿›ä¸€æ­¥ä¿ƒè¿›é‡å»ºã€‚</li><li>å®éªŒè¡¨æ˜ï¼ŒIDM åœ¨ PSNR æ–¹é¢æ¯”ç°æœ‰çš„æœ€å…ˆè¿›çš„å‹ç¼©æ„ŸçŸ¥ç½‘ç»œé«˜å‡º 2.64dBã€‚</li><li>ä¸æœ€è¿‘åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³• DDNM ç›¸æ¯”ï¼ŒIDM åœ¨ PSNR å¢ç›Šæ–¹é¢æé«˜äº† 10.09dBï¼Œæ¨ç†é€Ÿåº¦æé«˜äº† 14.54 å€ã€‚</li><li>IDM æä¾›äº†æ¯”ç°æœ‰æŠ€æœ¯æ›´å‡†ç¡®ã€æ›´é«˜æ•ˆçš„å›¾åƒå‹ç¼©æ„ŸçŸ¥è§£å†³æ–¹æ¡ˆã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šå¯é€†æ‰©æ•£æ¨¡å‹åœ¨å‹ç¼©æ„ŸçŸ¥ä¸­çš„åº”ç”¨</li><li>ä½œè€…ï¼šBin Chen, Zhenyu Zhang, Weiqi Li, Chen Zhao, Jiwen Yu, Shijie Zhao, Jie Chen, Jian Zhang</li><li>æ‰€å±å•ä½ï¼šåŒ—äº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šCompressed Sensingã€Diffusion Modelsã€Image Reconstruction</li><li>é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦ç¥ç»ç½‘ç»œåœ¨å›¾åƒå‹ç¼©æ„ŸçŸ¥ï¼ˆCSï¼‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰çš„ CS ç¥ç»ç½‘ç»œéœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒï¼Œé™åˆ¶äº†å®ƒä»¬çš„æœ‰æ•ˆæ€§å’Œå¿«é€Ÿéƒ¨ç½²ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šä¹‹å‰çš„æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒé‡å»ºï¼Œä½†åœ¨æ¨ç†é€Ÿåº¦å’Œå¯¹ CS çš„é€‚åº”æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†å¯é€†æ‰©æ•£æ¨¡å‹ï¼ˆIDMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„é«˜æ•ˆç«¯åˆ°ç«¯åŸºäºæ‰©æ•£çš„ CS æ–¹æ³•ã€‚IDM å°†å¤§è§„æ¨¡æ‰©æ•£é‡‡æ ·è¿‡ç¨‹é‡æ–°ç”¨ä½œé‡å»ºæ¨¡å‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œç«¯åˆ°ç«¯å¾®è°ƒï¼Œä»¥ç›´æ¥ä» CS æµ‹é‡ä¸­æ¢å¤åŸå§‹å›¾åƒï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„ä¸€æ­¥å™ªå£°ä¼°è®¡å­¦ä¹ èŒƒå¼ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒè¡¨æ˜ï¼ŒIDM åœ¨ PSNR æ–¹é¢æ¯”ç°æœ‰çš„æœ€å…ˆè¿›çš„ CS ç½‘ç»œé«˜å‡º 2.64dBã€‚ä¸æœ€è¿‘åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³• DDNM ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ IDM åœ¨ PSNR ä¸Šæé«˜äº† 10.09dBï¼Œæ¨ç†é€Ÿåº¦æé«˜äº† 14.54 å€ã€‚</li></ol><p>7.Methodsï¼š (1) æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„é«˜æ•ˆç«¯åˆ°ç«¯åŸºäºæ‰©æ•£çš„å‹ç¼©æ„ŸçŸ¥æ–¹æ³•ï¼Œç§°ä¸ºå¯é€†æ‰©æ•£æ¨¡å‹ï¼ˆIDMï¼‰ã€‚ (2) IDMå°†å¤§è§„æ¨¡æ‰©æ•£é‡‡æ ·è¿‡ç¨‹é‡æ–°ç”¨ä½œé‡å»ºæ¨¡å‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œç«¯åˆ°ç«¯å¾®è°ƒï¼Œä»¥ç›´æ¥ä»å‹ç¼©æ„ŸçŸ¥æµ‹é‡ä¸­æ¢å¤åŸå§‹å›¾åƒï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„ä¸€æ­¥å™ªå£°ä¼°è®¡å­¦ä¹ èŒƒå¼ã€‚</p><ol><li>ç»“è®ºï¼š (1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°é¢–çš„é«˜æ•ˆç«¯åˆ°ç«¯åŸºäºæ‰©æ•£çš„å›¾åƒå‹ç¼©æ„ŸçŸ¥æ–¹æ³•ï¼Œç§°ä¸ºå¯é€†æ‰©æ•£æ¨¡å‹ï¼ˆIDMï¼‰ï¼Œè¯¥æ–¹æ³•å°†å¤§è§„æ¨¡é¢„è®­ç»ƒæ‰©æ•£é‡‡æ ·è¿‡ç¨‹è½¬æ¢ä¸ºä¸¤çº§å¯é€†æ¡†æ¶ï¼Œç”¨äºç«¯åˆ°ç«¯é‡å»ºå­¦ä¹ ã€‚æˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†ä¸‰ä¸ªå¥½å¤„ã€‚é¦–å…ˆï¼Œå®ƒç›´æ¥ä½¿ç”¨å‹ç¼©æ„ŸçŸ¥é‡å»ºç›®æ ‡å­¦ä¹ æ‰€æœ‰ç½‘ç»œå‚æ•°ï¼Œé‡Šæ”¾äº†æ‰©æ•£æ¨¡å‹åœ¨é‡å»ºé—®é¢˜ä¸­çš„å…¨éƒ¨æ½œåŠ›ã€‚å…¶æ¬¡ï¼Œå®ƒé€šè¿‡ä½¿ï¼ˆ1ï¼‰é‡‡æ ·æ­¥éª¤å’Œï¼ˆ2ï¼‰å™ªå£°ä¼°è®¡ U-Net å¯é€†æ¥æé«˜å†…å­˜æ•ˆç‡ã€‚ç¬¬ä¸‰ï¼Œå®ƒé‡æ–°åˆ©ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹æ¥æœ€å°åŒ–è®­ç»ƒæ—¶é—´ã€‚ (2): åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„é«˜æ•ˆç«¯åˆ°ç«¯åŸºäºæ‰©æ•£çš„å‹ç¼©æ„ŸçŸ¥æ–¹æ³•ï¼Œç§°ä¸ºå¯é€†æ‰©æ•£æ¨¡å‹ï¼ˆIDMï¼‰ã€‚ æ€§èƒ½ï¼šä¸ç°æœ‰çš„æœ€å…ˆè¿›çš„å‹ç¼©æ„ŸçŸ¥ç½‘ç»œç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ IDM åœ¨ PSNR æ–¹é¢æé«˜äº† 2.64dBã€‚ä¸æœ€è¿‘åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³• DDNM ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„ IDM åœ¨ PSNR ä¸Šæé«˜äº† 10.09dBï¼Œæ¨ç†é€Ÿåº¦æé«˜äº† 14.54 å€ã€‚ å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡ä¸­ç­‰ã€‚è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä½†éœ€è¦å¯¹æ‰©æ•£æ¨¡å‹å’Œå‹ç¼©æ„ŸçŸ¥çš„æ·±å…¥ç†è§£ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-74400c9f9a39a9bfabc15ed66a346128.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-cdd2ddb1363513e955ce3cbe06c53a9a.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-b5a74781e409db05f570137032af563e.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-8b2b8f07c7e2d6d6402f4200d9d5296f.jpg" align="middle"></details><h2 id="TRIP-Temporal-Residual-Learning-with-Image-Noise-Prior-for-Image-to-Video-Diffusion-Models"><a href="#TRIP-Temporal-Residual-Learning-with-Image-Noise-Prior-for-Image-to-Video-Diffusion-Models" class="headerlink" title="TRIP: Temporal Residual Learning with Image Noise Prior for   Image-to-Video Diffusion Models"></a>TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models</h2><p><strong>Authors:Zhongwei Zhang, Fuchen Long, Yingwei Pan, Zhaofan Qiu, Ting Yao, Yang Cao, Tao Mei</strong></p><p>Recent advances in text-to-video generation have demonstrated the utility of powerful diffusion models. Nevertheless, the problem is not trivial when shaping diffusion models to animate static image (i.e., image-to-video generation). The difficulty originates from the aspect that the diffusion process of subsequent animated frames should not only preserve the faithful alignment with the given image but also pursue temporal coherence among adjacent frames. To alleviate this, we present TRIP, a new recipe of image-to-video diffusion paradigm that pivots on image noise prior derived from static image to jointly trigger inter-frame relational reasoning and ease the coherent temporal modeling via temporal residual learning. Technically, the image noise prior is first attained through one-step backward diffusion process based on both static image and noised video latent codes. Next, TRIP executes a residual-like dual-path scheme for noise prediction: 1) a shortcut path that directly takes image noise prior as the reference noise of each frame to amplify the alignment between the first frame and subsequent frames; 2) a residual path that employs 3D-UNet over noised video and static image latent codes to enable inter-frame relational reasoning, thereby easing the learning of the residual noise for each frame. Furthermore, both reference and residual noise of each frame are dynamically merged via attention mechanism for final video generation. Extensive experiments on WebVid-10M, DTDB and MSR-VTT datasets demonstrate the effectiveness of our TRIP for image-to-video generation. Please see our project page at <a target="_blank" rel="noopener" href="https://trip-i2v.github.io/TRIP/">https://trip-i2v.github.io/TRIP/</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17005v1">PDF</a> CVPR 2024; Project page: <a target="_blank" rel="noopener" href="https://trip-i2v.github.io/TRIP/">https://trip-i2v.github.io/TRIP/</a></p><p><strong>Summary</strong><br>TRIPæ˜¯ä¸€ç§æ–°çš„å›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨å›¾åƒå™ªå£°å…ˆéªŒæ¥ä¿ƒè¿›å¸§é—´å…³è”æ¨ç†å¹¶é€šè¿‡æ—¶é—´æ®‹å·®å­¦ä¹ ç®€åŒ–æ—¶é—´è¿è´¯å»ºæ¨¡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>TRIP æå‡ºäº†ä¸€ç§é€šè¿‡é™æ­¢å›¾åƒç”Ÿæˆè§†é¢‘çš„å›¾åƒåˆ°è§†é¢‘æ‰©æ•£èŒƒä¾‹ã€‚</li><li>è¯¥æ–¹æ³•åˆ©ç”¨åŸºäºé™æ€å›¾åƒå’Œå™ªå£°è§†é¢‘æ½œåœ¨ä»£ç çš„ä¸€æ­¥åå‘æ‰©æ•£è¿‡ç¨‹è·å¾—å›¾åƒå™ªå£°å…ˆéªŒã€‚</li><li>TRIP ä½¿ç”¨å‰©ä½™å¼åŒè·¯å¾„æ–¹æ¡ˆè¿›è¡Œå™ªå£°é¢„æµ‹ï¼ŒåŒ…æ‹¬ç›´æ¥é‡‡ç”¨å›¾åƒå™ªå£°å…ˆéªŒä½œä¸ºæ¯å¸§å‚è€ƒå™ªå£°çš„æ·å¾„è·¯å¾„ï¼Œä»¥åŠåœ¨å™ªå£°è§†é¢‘å’Œé™æ€å›¾åƒæ½œåœ¨ä»£ç ä¸Šä½¿ç”¨ 3D-UNet çš„æ®‹å·®è·¯å¾„ã€‚</li><li>æ¯ä¸ªå¸§çš„å‚è€ƒå™ªå£°å’Œæ®‹å·®å™ªå£°é€šè¿‡æ³¨æ„æœºåˆ¶åŠ¨æ€åˆå¹¶ï¼Œç”¨äºæœ€ç»ˆçš„è§†é¢‘ç”Ÿæˆã€‚</li><li>TRIP åœ¨ WebVid-10Mã€DTDB å’Œ MSR-VTT æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜äº†å…¶åœ¨å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li><li>TRIP çš„é¡¹ç›®é¡µé¢ä¸º <a target="_blank" rel="noopener" href="https://trip-i2v.github.io/TRIP/ã€‚">https://trip-i2v.github.io/TRIP/ã€‚</a></li><li>TRIP æ˜¯ä¸€ä¸ªå›¾åƒåˆ°è§†é¢‘æ‰©æ•£èŒƒä¾‹ï¼Œåˆ©ç”¨å›¾åƒå™ªå£°å…ˆéªŒä¿ƒè¿›å¸§é—´å…³è”æ¨ç†å¹¶é€šè¿‡æ—¶é—´æ®‹å·®å­¦ä¹ ç®€åŒ–æ—¶é—´è¿è´¯å»ºæ¨¡ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šTRIPï¼šåŸºäºå›¾åƒå™ªå£°å…ˆéªŒçš„å›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ®‹å·®å­¦ä¹ </li><li>ä½œè€…ï¼šå¼ ä»²ä¼Ÿï¼Œé¾™ç¦è‡£ï¼Œæ½˜æ˜ ä¼Ÿï¼Œé‚±å…†å‡¡ï¼Œå§šå©·ï¼Œæ›¹æ¨ï¼Œæ¢…æ¶›</li><li>å•ä½ï¼šä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦</li><li>å…³é”®è¯ï¼šå›¾åƒåˆ°è§†é¢‘ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œå›¾åƒå™ªå£°å…ˆéªŒï¼Œæ—¶é—´æ®‹å·®å­¦ä¹ </li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.17005</li><li><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š è¿‘å¹´æ¥ï¼Œæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œæ‰©æ•£æ¨¡å‹å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå°†æ‰©æ•£æ¨¡å‹åº”ç”¨äºå›¾åƒåˆ°è§†é¢‘ç”Ÿæˆï¼ˆI2Vï¼‰æ—¶ï¼Œé¢ä¸´ç€æŒ‘æˆ˜ï¼šæ—¢è¦ä¿è¯ç”Ÿæˆè§†é¢‘å¸§ä¸ç»™å®šå›¾åƒä¿æŒä¸€è‡´ï¼Œåˆè¦ä¿è¯å¸§ä¸å¸§ä¹‹é—´çš„æ—¶é—´è¿è´¯æ€§ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š ä»¥å¾€çš„ I2V æ–¹æ³•é€šå¸¸ç›´æ¥å°†ç»™å®šå›¾åƒä½œä¸ºæ¡ä»¶ï¼Œèå…¥åˆ°æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆä»»åŠ¡çš„æ‰©æ•£æ¨¡å‹ä¸­ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•éš¾ä»¥å…¼é¡¾å›¾åƒå¯¹é½å’Œæ—¶é—´è¿è´¯æ€§ã€‚ ï¼ˆ3ï¼‰æå‡ºçš„æ–¹æ³•ï¼š æœ¬æ–‡æå‡ºäº† TRIPï¼Œä¸€ç§åŸºäºå›¾åƒå™ªå£°å…ˆéªŒçš„å›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹æ—¶é—´æ®‹å·®å­¦ä¹ æ–°èŒƒå¼ã€‚TRIP é€šè¿‡åŸºäºé™æ€å›¾åƒå’Œå™ªå£°è§†é¢‘æ½œåœ¨ç çš„ä¸€æ­¥åå‘æ‰©æ•£è¿‡ç¨‹ï¼Œè·å¾—å›¾åƒå™ªå£°å…ˆéªŒã€‚ç„¶åï¼ŒTRIP é‡‡ç”¨æ®‹å·®å¼åŒè·¯å¾„æ–¹æ¡ˆé¢„æµ‹å™ªå£°ï¼š1ï¼‰æ·å¾„è·¯å¾„ç›´æ¥å°†å›¾åƒå™ªå£°å…ˆéªŒä½œä¸ºæ¯å¸§çš„å‚è€ƒå™ªå£°ï¼Œä»¥å¢å¼ºç¬¬ä¸€å¸§ä¸åç»­å¸§çš„å¯¹é½ï¼›2ï¼‰æ®‹å·®è·¯å¾„ä½¿ç”¨ 3D-UNet åœ¨å™ªå£°è§†é¢‘å’Œé™æ€å›¾åƒæ½œåœ¨ç ä¸Šè¿›è¡Œæ¨ç†ï¼Œå®ç°å¸§é—´å…³ç³»æ¨ç†ï¼Œä»è€Œä¿ƒè¿›æ¯å¸§æ®‹å·®å™ªå£°çš„å­¦ä¹ ã€‚æ­¤å¤–ï¼Œæ¯å¸§çš„å‚è€ƒå™ªå£°å’Œæ®‹å·®å™ªå£°é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€èåˆï¼Œç”¨äºæœ€ç»ˆè§†é¢‘ç”Ÿæˆã€‚ ï¼ˆ4ï¼‰å®éªŒç»“æœï¼š åœ¨ WebVid-10Mã€DTD å’Œ MSR-VTT æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒTRIP åœ¨å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†æœ‰æ•ˆæ€§ã€‚TRIP ç”Ÿæˆçš„è§†é¢‘å¸§ä¸ç»™å®šå›¾åƒå¯¹é½è‰¯å¥½ï¼Œå¸§ä¸å¸§ä¹‹é—´çš„æ—¶é—´è¿è´¯æ€§ä¹Ÿå¾—åˆ°ä¿è¯ã€‚</p></li><li><p><strong>æ–¹æ³•</strong>ï¼š (1) TRIPåŸºäºé™æ€å›¾åƒå’Œå™ªå£°è§†é¢‘æ½œåœ¨ç çš„ä¸€æ­¥åå‘æ‰©æ•£è¿‡ç¨‹ï¼Œè·å¾—å›¾åƒå™ªå£°å…ˆéªŒï¼› (2) TRIPé‡‡ç”¨æ®‹å·®å¼åŒè·¯å¾„æ–¹æ¡ˆé¢„æµ‹å™ªå£°ï¼š (2.1) æ·å¾„è·¯å¾„ç›´æ¥å°†å›¾åƒå™ªå£°å…ˆéªŒä½œä¸ºæ¯å¸§çš„å‚è€ƒå™ªå£°ï¼Œä»¥å¢å¼ºç¬¬ä¸€å¸§ä¸åç»­å¸§çš„å¯¹é½ï¼› (2.2) æ®‹å·®è·¯å¾„ä½¿ç”¨3D-UNetåœ¨å™ªå£°è§†é¢‘å’Œé™æ€å›¾åƒæ½œåœ¨ç ä¸Šè¿›è¡Œæ¨ç†ï¼Œå®ç°å¸§é—´å…³ç³»æ¨ç†ï¼Œä»è€Œä¿ƒè¿›æ¯å¸§æ®‹å·®å™ªå£°çš„å­¦ä¹ ï¼› (3) æ¯å¸§çš„å‚è€ƒå™ªå£°å’Œæ®‹å·®å™ªå£°é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€èåˆï¼Œç”¨äºæœ€ç»ˆè§†é¢‘ç”Ÿæˆã€‚</p></li><li><p>ç»“è®ºï¼š (1): TRIP æå‡ºäº†ä¸€ç§åŸºäºå›¾åƒå™ªå£°å…ˆéªŒçš„æ—¶é—´æ®‹å·®å­¦ä¹ èŒƒå¼ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä¸­çš„å›¾åƒå¯¹é½å’Œæ—¶é—´è¿è´¯æ€§é—®é¢˜ï¼Œåœ¨å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ (2): åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§åŸºäºå›¾åƒå™ªå£°å…ˆéªŒçš„æ—¶é—´æ®‹å·®å­¦ä¹ èŒƒå¼ï¼Œæœ‰æ•ˆåœ°å¹³è¡¡äº†å›¾åƒå¯¹é½å’Œæ—¶é—´è¿è´¯æ€§ã€‚</li><li>é‡‡ç”¨æ®‹å·®å¼åŒè·¯å¾„æ–¹æ¡ˆé¢„æµ‹å™ªå£°ï¼Œå¢å¼ºäº†ç¬¬ä¸€å¸§ä¸åç»­å¸§çš„å¯¹é½ï¼Œå¹¶å®ç°äº†å¸§é—´å…³ç³»æ¨ç†ã€‚</li><li>é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€èåˆå‚è€ƒå™ªå£°å’Œæ®‹å·®å™ªå£°ï¼Œç”¨äºæœ€ç»ˆè§†é¢‘ç”Ÿæˆã€‚ æ€§èƒ½ï¼š</li><li>åœ¨ WebVid-10Mã€DTD å’Œ MSR-VTT æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒTRIP åœ¨å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li><li>TRIP ç”Ÿæˆçš„è§†é¢‘å¸§ä¸ç»™å®šå›¾åƒå¯¹é½è‰¯å¥½ï¼Œå¸§ä¸å¸§ä¹‹é—´çš„æ—¶é—´è¿è´¯æ€§ä¹Ÿå¾—åˆ°ä¿è¯ã€‚ å·¥ä½œé‡ï¼š</li><li>TRIP çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œæ¶‰åŠåˆ°ä¸€æ­¥åå‘æ‰©æ•£è¿‡ç¨‹ã€æ®‹å·®å¼åŒè·¯å¾„æ–¹æ¡ˆå’Œæ³¨æ„åŠ›æœºåˆ¶çš„èåˆã€‚</li><li>TRIP çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ca66a6c8cbe1ea0c7bee31ec88e3bfdd.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-153f2b85dba70a39304fbf6d81434bc4.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-36f2aad744b3d6c59a51d26bf1bc8573.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-e31383189b1e2dd43b8737e9a8b1df0a.jpg" align="middle"></details><h2 id="VP3D-Unleashing-2D-Visual-Prompt-for-Text-to-3D-Generation"><a href="#VP3D-Unleashing-2D-Visual-Prompt-for-Text-to-3D-Generation" class="headerlink" title="VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation"></a>VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation</h2><p><strong>Authors:Yang Chen, Yingwei Pan, Haibo Yang, Ting Yao, Tao Mei</strong></p><p>Recent innovations on text-to-3D generation have featured Score Distillation Sampling (SDS), which enables the zero-shot learning of implicit 3D models (NeRF) by directly distilling prior knowledge from 2D diffusion models. However, current SDS-based models still struggle with intricate text prompts and commonly result in distorted 3D models with unrealistic textures or cross-view inconsistency issues. In this work, we introduce a novel Visual Prompt-guided text-to-3D diffusion model (VP3D) that explicitly unleashes the visual appearance knowledge in 2D visual prompt to boost text-to-3D generation. Instead of solely supervising SDS with text prompt, VP3D first capitalizes on 2D diffusion model to generate a high-quality image from input text, which subsequently acts as visual prompt to strengthen SDS optimization with explicit visual appearance. Meanwhile, we couple the SDS optimization with additional differentiable reward function that encourages rendering images of 3D models to better visually align with 2D visual prompt and semantically match with text prompt. Through extensive experiments, we show that the 2D Visual Prompt in our VP3D significantly eases the learning of visual appearance of 3D models and thus leads to higher visual fidelity with more detailed textures. It is also appealing in view that when replacing the self-generating visual prompt with a given reference image, VP3D is able to trigger a new task of stylized text-to-3D generation. Our project page is available at <a target="_blank" rel="noopener" href="https://vp3d-cvpr24.github.io">https://vp3d-cvpr24.github.io</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.17001v1">PDF</a> CVPR 2024; Project page: <a target="_blank" rel="noopener" href="https://vp3d-cvpr24.github.io">https://vp3d-cvpr24.github.io</a></p><p><strong>Summary</strong><br>æ–‡æœ¬åˆ° 3D ç”Ÿæˆæ¨¡å‹ VP3D é€šè¿‡è§†è§‰æç¤ºå¼•å¯¼å’Œå¯å¾®å¥–åŠ±å‡½æ•°å¢å¼ºäº† SDS ä¼˜åŒ–ï¼Œä»è€Œæé«˜äº†æ–‡æœ¬åˆ° 3D ç”Ÿæˆçš„è§†è§‰ä¿çœŸåº¦ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>VP3D åœ¨ SDS ä¼˜åŒ–ä¸­å¼•å…¥äº†è§†è§‰æç¤ºï¼Œä»¥æ˜¾å¼åˆ©ç”¨ 2D æ‰©æ•£æ¨¡å‹ä¸­çš„è§†è§‰å¤–è§‚çŸ¥è¯†ã€‚</li><li>è§†è§‰æç¤ºä»è¾“å…¥æ–‡æœ¬ä¸­ç”Ÿæˆï¼Œä½œä¸ºé™„åŠ ç›‘ç£ï¼ŒåŠ å¼ºäº†å¯¹ 3D æ¨¡å‹è§†è§‰å¤–è§‚çš„å­¦ä¹ ã€‚</li><li>å¯å¾®å¥–åŠ±å‡½æ•°é¼“åŠ±æ¸²æŸ“çš„ 3D æ¨¡å‹å›¾åƒä¸ 2D è§†è§‰æç¤ºåœ¨è§†è§‰ä¸Šå¯¹é½ï¼Œå¹¶åœ¨è¯­ä¹‰ä¸Šä¸æ–‡æœ¬æç¤ºåŒ¹é…ã€‚</li><li>VP3D æ˜¾è‘—æé«˜äº† 3D æ¨¡å‹çš„è§†è§‰ä¿çœŸåº¦ï¼Œç”Ÿæˆæ›´ç²¾ç»†çš„çº¹ç†ã€‚</li><li>VP3D å¯ä»¥é€šè¿‡æ›¿æ¢è‡ªç”Ÿæˆè§†è§‰æç¤ºæ¥è§¦å‘æ–‡æœ¬åˆ° 3D ç”Ÿæˆçš„é£æ ¼åŒ–ä»»åŠ¡ã€‚</li><li>VP3D æ‰©å±•äº† SDS åœ¨å¤æ‚æ–‡æœ¬æç¤ºä¸‹çš„åº”ç”¨ï¼Œè§£å†³äº†æ—©æœŸæ¨¡å‹ä¸­å¸¸è§çš„å¤±çœŸå’Œçº¹ç†ä¸ç°å®é—®é¢˜ã€‚</li><li>VP3D å¯ä»¥åœ¨ 2D visual prompt å’Œæ–‡æœ¬æç¤ºä¹‹é—´å»ºç«‹æ¡¥æ¢ï¼Œå®ç°è§†è§‰å’Œè¯­ä¹‰çš„ä¸€è‡´æ€§ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šVP3Dï¼šé‡Šæ”¾ç”¨äºæ–‡æœ¬åˆ° 3D ç”Ÿæˆçš„ 2D è§†è§‰æç¤º</li><li>ä½œè€…ï¼šYang Chen, Yingwei Pan, Haibo Yang, Ting Yao, Tao Mei</li><li>éš¶å±ï¼šå¤æ—¦å¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ° 3Dã€ç”Ÿæˆæ¨¡å‹ã€è§†è§‰æç¤ºã€ç¥ç»è¾å°„åœº</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.17001 Github é“¾æ¥ï¼šæ— </li><li><p>æ‘˜è¦ï¼š (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ° 3D ç”Ÿæˆæ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸º 3D å‡ ä½•å’Œå¤–è§‚çš„å¤æ‚æ€§ã€‚ (2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šScore Distillation Sampling (SDS) æ˜¯ä¸€ç§é›¶æ ·æœ¬å­¦ä¹ éšå¼ 3D æ¨¡å‹çš„æ–¹æ³•ï¼Œä½†å®ƒåœ¨å¤„ç†å¤æ‚æ–‡æœ¬æç¤ºæ—¶å­˜åœ¨å›°éš¾ï¼Œå¹¶ä¸”ç”Ÿæˆçš„ 3D æ¨¡å‹å¯èƒ½å­˜åœ¨å¤±çœŸã€ä¸çœŸå®çº¹ç†æˆ–è·¨è§†å›¾ä¸ä¸€è‡´çš„é—®é¢˜ã€‚ (3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šVP3D æ˜¯ä¸€ç§è§†è§‰æç¤ºå¼•å¯¼çš„æ–‡æœ¬åˆ° 3D æ‰©æ•£æ¨¡å‹ï¼Œå®ƒåˆ©ç”¨ 2D è§†è§‰æç¤ºä¸­çš„è§†è§‰å¤–è§‚çŸ¥è¯†æ¥å¢å¼ºæ–‡æœ¬åˆ° 3D ç”Ÿæˆã€‚VP3D é¦–å…ˆä½¿ç”¨ 2D æ‰©æ•£æ¨¡å‹ä»è¾“å…¥æ–‡æœ¬ç”Ÿæˆé«˜è´¨é‡å›¾åƒï¼Œç„¶åå°†è¯¥å›¾åƒç”¨ä½œè§†è§‰æç¤ºæ¥å¢å¼º SDS ä¼˜åŒ–ï¼Œå¹¶å¼•å…¥äº†ä¸€ä¸ªå¯å¾®åˆ†å¥–åŠ±å‡½æ•°ï¼Œä»¥é¼“åŠ±æ¸²æŸ“çš„ 3D æ¨¡å‹å›¾åƒä¸ 2D è§†è§‰æç¤ºåœ¨è§†è§‰ä¸Šæ›´ä¸€è‡´ï¼Œå¹¶ä¸æ–‡æœ¬æç¤ºåœ¨è¯­ä¹‰ä¸ŠåŒ¹é…ã€‚ (4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šåœ¨å¹¿æ³›çš„å®éªŒä¸­ï¼ŒVP3D ä¸­çš„ 2D è§†è§‰æç¤ºæ˜¾è‘—ç®€åŒ–äº† 3D æ¨¡å‹è§†è§‰å¤–è§‚çš„å­¦ä¹ ï¼Œä»è€Œäº§ç”Ÿäº†æ›´é«˜è§†è§‰ä¿çœŸåº¦å’Œæ›´è¯¦ç»†çš„çº¹ç†ã€‚æ­¤å¤–ï¼Œå½“ç”¨ç»™å®šçš„å‚è€ƒå›¾åƒæ›¿æ¢è‡ªç”Ÿæˆçš„è§†è§‰æç¤ºæ—¶ï¼ŒVP3D èƒ½å¤Ÿè§¦å‘é£æ ¼åŒ–æ–‡æœ¬åˆ° 3D ç”Ÿæˆçš„ä»»åŠ¡ã€‚</p></li><li><p>Methods: (1) åˆ©ç”¨2Dæ‰©æ•£æ¨¡å‹ä»è¾“å…¥æ–‡æœ¬ç”Ÿæˆé«˜è´¨é‡å›¾åƒï¼Œä½œä¸ºè§†è§‰æç¤ºï¼› (2) ä½¿ç”¨è§†è§‰æç¤ºå¢å¼ºSDSä¼˜åŒ–ï¼Œé¼“åŠ±æ¸²æŸ“çš„3Dæ¨¡å‹å›¾åƒä¸2Dè§†è§‰æç¤ºåœ¨è§†è§‰ä¸Šæ›´ä¸€è‡´ï¼Œå¹¶ä¸æ–‡æœ¬æç¤ºåœ¨è¯­ä¹‰ä¸ŠåŒ¹é…ï¼› (3) å¼•å…¥å¯å¾®åˆ†å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±æ¸²æŸ“çš„3Dæ¨¡å‹å›¾åƒä¸2Dè§†è§‰æç¤ºåœ¨è§†è§‰ä¸Šæ›´ä¸€è‡´ï¼Œå¹¶ä¸æ–‡æœ¬æç¤ºåœ¨è¯­ä¹‰ä¸ŠåŒ¹é…ã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† VP3Dï¼Œä¸€ç§é€šè¿‡åˆ©ç”¨2D è§†è§‰æç¤ºçš„æ–°å‹æ–‡æœ¬åˆ° 3D ç”ŸæˆèŒƒå¼ã€‚æˆ‘ä»¬é¦–å…ˆåˆ©ç”¨ 2D æ‰©æ•£æ¨¡å‹ä»è¾“å…¥æ–‡æœ¬ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚ç„¶åï¼Œè¯¥å›¾åƒä½œä¸ºè§†è§‰æç¤ºï¼Œé€šè¿‡æˆ‘ä»¬è®¾è®¡çš„è§†è§‰æç¤ºå¼•å¯¼åˆ†æ•°è’¸é¦é‡‡æ ·æ¥å¢å¼º 3D æ¨¡å‹å­¦ä¹ ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†é¢å¤–çš„äººå·¥åé¦ˆå’Œè§†è§‰ä¸€è‡´æ€§å¥–åŠ±å‡½æ•°ï¼Œä»¥é¼“åŠ± 3D æ¨¡å‹ä¸è¾“å…¥è§†è§‰å’Œæ–‡æœ¬æç¤ºä¹‹é—´çš„è¯­ä¹‰å’Œå¤–è§‚ä¸€è‡´æ€§ã€‚åœ¨ T3Bench åŸºå‡†ä¸Šçš„å®šæ€§å’Œå®šé‡æ¯”è¾ƒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ VP3D ä¼˜äºç°æœ‰çš„ SOTA æŠ€æœ¯ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p><ul><li>æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ° 3D ç”ŸæˆèŒƒå¼ï¼Œåˆ©ç”¨ 2D è§†è§‰æç¤ºæ¥å¢å¼º 3D æ¨¡å‹å­¦ä¹ ã€‚</li><li>è®¾è®¡äº†ä¸€ç§è§†è§‰æç¤ºå¼•å¯¼åˆ†æ•°è’¸é¦é‡‡æ ·æ–¹æ³•ï¼Œåˆ©ç”¨è§†è§‰æç¤ºä¸­çš„è§†è§‰å¤–è§‚çŸ¥è¯†æ¥æŒ‡å¯¼ 3D æ¨¡å‹ç”Ÿæˆã€‚</li><li>å¼•å…¥äº†ä¸€ä¸ªå¯å¾®åˆ†å¥–åŠ±å‡½æ•°ï¼Œä»¥é¼“åŠ±æ¸²æŸ“çš„ 3D æ¨¡å‹å›¾åƒä¸ 2D è§†è§‰æç¤ºåœ¨è§†è§‰ä¸Šæ›´ä¸€è‡´ï¼Œå¹¶ä¸æ–‡æœ¬æç¤ºåœ¨è¯­ä¹‰ä¸ŠåŒ¹é…ã€‚ æ€§èƒ½ï¼š</li><li>åœ¨ T3Bench åŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒVP3D èƒ½å¤Ÿç”Ÿæˆå…·æœ‰æ›´é«˜è§†è§‰ä¿çœŸåº¦å’Œæ›´è¯¦ç»†çº¹ç†çš„ 3D æ¨¡å‹ã€‚</li><li>VP3D èƒ½å¤Ÿè§¦å‘é£æ ¼åŒ–æ–‡æœ¬åˆ° 3D ç”Ÿæˆä»»åŠ¡ï¼Œå½“ç”¨ç»™å®šçš„å‚è€ƒå›¾åƒæ›¿æ¢è‡ªç”Ÿæˆçš„è§†è§‰æç¤ºæ—¶ã€‚ å·¥ä½œé‡ï¼š</li><li>VP3D çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼ˆ2D æ‰©æ•£æ¨¡å‹ã€3D æ¨¡å‹å’Œå¥–åŠ±å‡½æ•°ï¼‰ã€‚</li><li>VP3D çš„æ¨ç†æ—¶é—´æ¯”åŸºçº¿æ–¹æ³•ç¨é•¿ï¼Œå› ä¸ºéœ€è¦ç”Ÿæˆè§†è§‰æç¤ºå¹¶è¿›è¡Œé¢å¤–çš„ä¼˜åŒ–æ­¥éª¤ã€‚</li></ul></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-66d95e52c6a32ad077611ad4162f2e1f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-c21b901dbeddaa875cbc4a9d022b539c.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-e2b11ff84eeb9793d2212cf130acf75f.jpg" align="middle"></details></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io/2024/03/28/Paper/2024-03-28/Diffusion%20Models/">https://kedreamix.github.io/2024/03/28/Paper/2024-03-28/Diffusion Models/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜:</span> <span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Diffusion-Models/">Diffusion Models</a></div><div class="post_share"><div class="social-share" data-image="https://picx.zhimg.com/v2-7e8b388fdf7ef71288f5c4468e2d6aa6.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>èµåŠ©</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/03/28/Paper/2024-03-28/Talking%20Head%20Generation/" title="Talking Head Generation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4b69fbe4c0930a57ff002ead5463e3ef.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">Talking Head Generation</div></div></a></div><div class="next-post pull-right"><a href="/2024/03/23/Paper/2024-03-23/NeRF/" title="NeRF"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-19d6253b6aea4731864c3a1ce65af4bb.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">NeRF</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>ç›¸å…³æ¨è</span></div><div class="relatedPosts-list"><div><a href="/2024/03/03/Paperscape/EMO/" title="EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6492e24fb03ffa98135dc584535ab7d9.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-03</div><div class="title">EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC</div></div></a></div><div><a href="/2024/01/24/Paper/2024-01-24/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-71a37c439c6714e8867560f580599d2f.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-24</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/01/30/Paper/2024-01-30/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-e55358c77a9d65f15701e8f33262e2a4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/23/Paper/2024-02-23/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ff425802a32a4519e30b9044a3eed1e8.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-23</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/09/Paper/2024-02-09/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-32488f736ee10537497afccc3a1a1d76.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-09</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/13/Paper/2024-02-13/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3709a9941aada6c4d3ed35934e311765.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-13</div><div class="title">Diffusion Models</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-03-28-%E6%9B%B4%E6%96%B0"><span class="toc-text">2024-03-28 æ›´æ–°</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#AID-Attention-Interpolation-of-Text-to-Image-Diffusion"><span class="toc-text">AID: Attention Interpolation of Text-to-Image Diffusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AniPortrait-Audio-Driven-Synthesis-of-Photorealistic-Portrait-Animation"><span class="toc-text">AniPortrait: Audio-Driven Synthesis of Photorealistic Portrait Animation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DiffFAE-Advancing-High-fidelity-One-shot-Facial-Appearance-Editing-with-Space-sensitive-Customization-and-Semantic-Preservation"><span class="toc-text">DiffFAE: Advancing High-fidelity One-shot Facial Appearance Editing with Space-sensitive Customization and Semantic Preservation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LaRE-2-Latent-Reconstruction-Error-Based-Method-for-Diffusion-Generated-Image-Detection"><span class="toc-text">LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated Image Detection</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#InterHandGen-Two-Hand-Interaction-Generation-via-Cascaded-Reverse-Diffusion"><span class="toc-text">InterHandGen: Two-Hand Interaction Generation via Cascaded Reverse Diffusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DiffusionAct-Controllable-Diffusion-Autoencoder-for-One-shot-Face-Reenactment"><span class="toc-text">DiffusionAct: Controllable Diffusion Autoencoder for One-shot Face Reenactment</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Continuous-Subject-Specific-Attribute-Control-in-T2I-Models-by-Identifying-Semantic-Directions"><span class="toc-text">Continuous, Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Invertible-Diffusion-Models-for-Compressed-Sensing"><span class="toc-text">Invertible Diffusion Models for Compressed Sensing</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TRIP-Temporal-Residual-Learning-with-Image-Noise-Prior-for-Image-to-Video-Diffusion-Models"><span class="toc-text">TRIP: Temporal Residual Learning with Image Noise Prior for Image-to-Video Diffusion Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VP3D-Unleashing-2D-Visual-Prompt-for-Text-to-3D-Generation"><span class="toc-text">VP3D: Unleashing 2D Visual Prompt for Text-to-3D Generation</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image:url('https://picx.zhimg.com/v2-7e8b388fdf7ef71288f5c4468e2d6aa6.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>æ¡†æ¶</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="ç®€ç¹è½¬æ¢">ç°¡</button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const e of document.querySelectorAll('script[type^="math/tex"]')){const a=!!e.type.match(/; *mode=display/),n=new t.options.MathItem(e.textContent,t.inputJax[0],a),s=document.createTextNode("");e.parentNode.replaceChild(s,e),n.start={node:s,delim:"",n:0},n.end={node:s,delim:"",n:0},t.math.push(n)}},""]}}};const t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t)}</script></div><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("å·²æŒ‚è½½butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/25/Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="2024/01/25/Paper/3DGS Survey/" alt="">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting ä»Šå¤©æƒ³ä»‹ç»çš„æ˜¯`ZJU`å¸¦æ¥çš„`3DGS`çš„é¦–ç¯‡ç»¼è¿°`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="2024/01/25/Paper/3DGS Survey/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">CUDAç¼–ç¨‹å­¦ä¹ ï¼šè‡ªå®šä¹‰Pytorch+cpp/cuda extension</a><div class="blog-slider__text">è™½ç„¶è¯´PyTorchæä¾›äº†ä¸°å¯Œçš„ä¸ç¥ç»ç½‘ç»œã€å¼ é‡ä»£æ•°ã€æ•°æ®å¤„ç†ç­‰ç›¸å…³çš„æ“ä½œï¼Œä½†æ˜¯æœ‰æ—¶å€™ä½ å¯èƒ½éœ€è¦**æ›´å®šåˆ¶åŒ–çš„æ“ä½œ**ï¼Œæ¯”å¦‚ä½¿ç”¨è®ºæ–‡ä¸­çš„æ–°å‹æ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…å®ç°ä½œä¸ºç ”ç©¶ä¸€éƒ¨åˆ†å¼€å‘çš„æ“ä½œã€‚åœ¨PyTorchä¸­ï¼Œæœ€ç®€å•çš„é›†æˆè‡ªå®šä¹‰æ“ä½œçš„æ–¹å¼æ˜¯åœ¨Pythonä¸­ç¼–å†™ï¼Œé€šè¿‡æ‰©å±•Functionå’ŒModuleæ¥å®ç°ï¼Œ</div><a class="blog-slider__button" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesisï¼Œ è¿™ä»½èµ„æºåº“æ•´ç†äº†ä¸ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)å’Œç¥ç»è¾å°„åœº(NeRF)ç›¸å…³çš„è®ºæ–‡ã€ä»£ç å’Œèµ„æº,é‡ç‚¹å…³æ³¨åŸºäºå›¾åƒå’ŒéŸ³é¢‘çš„è™šæ‹Ÿè®²è¯å¤´åˆæˆè®ºæ–‡åŠå·²å‘å¸ƒä»£ç ã€‚å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªä»“åº“æœ‰ç”¨,è¯·starâ­æ”¯æŒ!</div><a class="blog-slider__button" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/17/Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023/12/17/Project/ChatPaperFree/" alt="">ChatPaperFree GeminiProï¼ˆä¸€åˆ†é’Ÿè¯»è®ºæ–‡ï¼‰</a><div class="blog-slider__text">ChatPaperFreeæ˜¯ä¸€ä¸ªåŸºäºChatGPTçš„è‡ªåŠ¨è®ºæ–‡æ‘˜è¦ç”Ÿæˆå™¨ï¼Œåœ¨ChatPaperçš„åŸºç¡€ä¸Šè¿›è¡Œçš„æ›´æ–°ï¼Œé‡‡ç”¨äº†æœ€è¿‘ç”±Googleå¼€æºçš„Gemini Proå¤§æ¨¡å‹ã€‚ç›®å‰,æˆ‘ä»¬èƒ½å¤Ÿå¯¹ç”¨æˆ·è¾“å…¥çš„è®ºæ–‡è¿›è¡Œè‡ªåŠ¨æ€»ç»“ã€‚æœªæ¥,æˆ‘è¿˜è®¡åˆ’åŠ å…¥å¯¹è®ºæ–‡å›¾ç‰‡/è¡¨æ ¼/å…¬å¼çš„è¯†åˆ« extraction,ä»è€Œç”Ÿæˆæ›´å…¨é¢è€Œæ˜“è¯»çš„æ€»ç»“ã€‚</div><a class="blog-slider__button" href="2023/12/17/Project/ChatPaperFree/" alt="">è¯¦æƒ…   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script></body></html>