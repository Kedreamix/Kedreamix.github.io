<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>3DGS | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2024-03-13  StyleGaussian Instant 3D Style Transfer with Gaussian Splatting"><meta property="og:type" content="article"><meta property="og:title" content="3DGS"><meta property="og:url" content="https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/3DGS/index.html"><meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World"><meta property="og:description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2024-03-13  StyleGaussian Instant 3D Style Transfer with Gaussian Splatting"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://picx.zhimg.com/v2-07cbe93d5240e4aa795cfc2554b29280.jpg"><meta property="article:published_time" content="2024-03-13T06:04:24.000Z"><meta property="article:modified_time" content="2024-03-13T06:04:24.220Z"><meta property="article:author" content="Kedreamix"><meta property="article:tag" content="3DGS"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://picx.zhimg.com/v2-07cbe93d5240e4aa795cfc2554b29280.jpg"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/3DGS/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-74LZ5BEQQ1")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!0,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},noticeOutdate:{limitDay:500,position:"top",messagePrev:"It has been",messageNext:"days since the last update, the content of the article may be outdated."},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!0,post:!0},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!0,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"3DGS",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-03-13 14:04:24"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme"),o=(new Date).getHours();void 0===t?o<=6||o>=24?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode();const a=saveToLocal.get("aside-status");void 0!==a&&("hide"===a?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 7.0.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml"></head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",(()=>{o()}))})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">303</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://picx.zhimg.com/v2-07cbe93d5240e4aa795cfc2554b29280.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">3DGS</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-03-13T06:04:24.000Z" title="发表于 2024-03-13 14:04:24">2024-03-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-13T06:04:24.220Z" title="更新于 2024-03-13 14:04:24">2024-03-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>18分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="3DGS"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p></blockquote><h1 id="2024-03-13-更新"><a href="#2024-03-13-更新" class="headerlink" title="2024-03-13 更新"></a>2024-03-13 更新</h1><h2 id="StyleGaussian-Instant-3D-Style-Transfer-with-Gaussian-Splatting"><a href="#StyleGaussian-Instant-3D-Style-Transfer-with-Gaussian-Splatting" class="headerlink" title="StyleGaussian: Instant 3D Style Transfer with Gaussian Splatting"></a>StyleGaussian: Instant 3D Style Transfer with Gaussian Splatting</h2><p><strong>Authors:Kunhao Liu, Fangneng Zhan, Muyu Xu, Christian Theobalt, Ling Shao, Shijian Lu</strong></p><p>We introduce StyleGaussian, a novel 3D style transfer technique that allows instant transfer of any image’s style to a 3D scene at 10 frames per second (fps). Leveraging 3D Gaussian Splatting (3DGS), StyleGaussian achieves style transfer without compromising its real-time rendering ability and multi-view consistency. It achieves instant style transfer with three steps: embedding, transfer, and decoding. Initially, 2D VGG scene features are embedded into reconstructed 3D Gaussians. Next, the embedded features are transformed according to a reference style image. Finally, the transformed features are decoded into the stylized RGB. StyleGaussian has two novel designs. The first is an efficient feature rendering strategy that first renders low-dimensional features and then maps them into high-dimensional features while embedding VGG features. It cuts the memory consumption significantly and enables 3DGS to render the high-dimensional memory-intensive features. The second is a K-nearest-neighbor-based 3D CNN. Working as the decoder for the stylized features, it eliminates the 2D CNN operations that compromise strict multi-view consistency. Extensive experiments show that StyleGaussian achieves instant 3D stylization with superior stylization quality while preserving real-time rendering and strict multi-view consistency. Project page: <a target="_blank" rel="noopener" href="https://kunhao-liu.github.io/StyleGaussian/">https://kunhao-liu.github.io/StyleGaussian/</a></p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.07807v1">PDF</a></p><p><strong>Summary</strong><br>三维高斯泼溅（3DGS）助力 StyleGaussian 实现即时 3D 样式迁移，在不影响实时渲染和多视图一致性的情况下，以每秒 10 帧的速度将任何图像的样式传输到三维场景中。</p><p><strong>Key Takeaways</strong></p><ul><li>StyleGaussian 是一种新颖的 3D 样式迁移技术，可以即时将任何图像的样式以每秒 10 帧 (fps) 的速度传输到 3D 场景中。</li><li>StyleGaussian 利用 3D 高斯泼溅 (3DGS)，在不影响其实时渲染能力和多视图一致性的情况下实现样式迁移。</li><li>StyleGaussian 通过嵌入、传输和解码这三个步骤实现即时样式迁移。</li><li>StyleGaussian 具有两种新颖的设计。第一个是一种高效的特征渲染策略，它首先渲染低维特征，然后在嵌入 VGG 特征时将它们映射到高维特征。</li><li>第二个是一个基于 K 近邻的 3D CNN。它作为样式化特征的解码器，消除了影响严格的多视图一致性的 2D CNN 操作。</li><li>广泛的实验表明，StyleGaussian 以卓越的样式化质量实现了即时的 3D 样式化，同时保留了实时渲染和严格的多视图一致性。</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>题目：StyleGaussian：即时3D风格迁移，采用高斯飞溅</li><li>作者：Kunhao Liu, Qifeng Chen, Lu Zhou, Wenping Wang, Junsong Yuan, Yizhou Yu</li><li>隶属机构：University of California, Berkeley</li><li>关键词：3DGaussianSplatting·3DStyleTransfer·3DEditing</li><li>论文链接：https://arxiv.org/pdf/2103.04306.pdf，Github代码链接：None</li><li>摘要： （1）研究背景：随着3D场景建模和渲染技术的进步，3D风格迁移技术已成为3D内容创作中的重要课题。 （2）过去方法：现有的3D风格迁移方法主要基于2D卷积神经网络（CNN），它们在风格迁移方面取得了成功，但存在实时渲染能力和多视图一致性方面的限制。 （3）提出方法：本文提出了一种名为StyleGaussian的新型3D风格迁移技术，它利用3DGaussianSplatting（3DGS）实现了即时风格迁移，同时保持了实时渲染能力和多视图一致性。StyleGaussian包含三个步骤：嵌入、迁移和解码。首先，将2DVGG场景特征嵌入到重建的3DGaussian中。然后，根据参考风格图像转换嵌入的特征。最后，将转换后的特征解码为风格化的RGB。 （4）性能与评价：实验表明，StyleGaussian实现了即时3D风格化，具有出色的风格化质量，同时保持了实时渲染和严格的多视图一致性。这些性能支持了本文的目标，即提供一种快速、高质量且多视图一致的3D风格迁移技术。</li></ol><p>7.方法：(1)嵌入：将2DVGG场景特征嵌入到重建的3DGaussian中；(2)迁移：根据参考风格图像转换嵌入的特征；(3)解码：将转换后的特征解码为风格化的RGB。</p><ol><li>结论： (1): 本文提出了一种名为 StyleGaussian 的新型 3D 风格迁移方法，它利用 3DGaussianSplatting（3DGS）实现了即时风格迁移，同时保持了实时渲染能力和多视图一致性。 (2): 创新点：</li><li>提出了一种基于 3DGaussianSplatting 的 3D 风格迁移方法，实现了即时风格迁移，同时保持了实时渲染能力和多视图一致性。</li><li>设计了一种新的特征嵌入和迁移模块，可以有效地将 2D 风格特征迁移到 3D 场景中。</li><li>开发了一种新的解码模块，可以将转换后的特征解码为高质量的风格化 RGB 图像。 性能：</li><li>实验表明，StyleGaussian 实现了即时 3D 风格化，具有出色的风格化质量，同时保持了实时渲染和严格的多视图一致性。</li><li>与现有方法相比，StyleGaussian 在风格化质量、实时渲染能力和多视图一致性方面具有明显的优势。 工作量：</li><li>本文的工作量较大，涉及到 3D 场景建模、风格迁移和实时渲染等多个方面的研究。</li><li>作者提出了一个完整的 StyleGaussian 系统，包括嵌入、迁移和解码三个模块，并提供了详细的算法描述和实验结果。</li></ol><details><summary>点此查看论文截图</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-91e8939bce5917a27f673ede613199c4.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-49e2dab4bdce0acfca84c4a30fa4a3b0.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-4b68ec41cc4999e1189948c75886c622.jpg" align="middle"></details><h2 id="DNGaussian-Optimizing-Sparse-View-3D-Gaussian-Radiance-Fields-with-Global-Local-Depth-Normalization"><a href="#DNGaussian-Optimizing-Sparse-View-3D-Gaussian-Radiance-Fields-with-Global-Local-Depth-Normalization" class="headerlink" title="DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with   Global-Local Depth Normalization"></a>DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization</h2><p><strong>Authors:Jiahe Li, Jiawei Zhang, Xiao Bai, Jin Zheng, Xin Ning, Jun Zhou, Lin Gu</strong></p><p>Radiance fields have demonstrated impressive performance in synthesizing novel views from sparse input views, yet prevailing methods suffer from high training costs and slow inference speed. This paper introduces DNGaussian, a depth-regularized framework based on 3D Gaussian radiance fields, offering real-time and high-quality few-shot novel view synthesis at low costs. Our motivation stems from the highly efficient representation and surprising quality of the recent 3D Gaussian Splatting, despite it will encounter a geometry degradation when input views decrease. In the Gaussian radiance fields, we find this degradation in scene geometry primarily lined to the positioning of Gaussian primitives and can be mitigated by depth constraint. Consequently, we propose a Hard and Soft Depth Regularization to restore accurate scene geometry under coarse monocular depth supervision while maintaining a fine-grained color appearance. To further refine detailed geometry reshaping, we introduce Global-Local Depth Normalization, enhancing the focus on small local depth changes. Extensive experiments on LLFF, DTU, and Blender datasets demonstrate that DNGaussian outperforms state-of-the-art methods, achieving comparable or better results with significantly reduced memory cost, a $25 \times$ reduction in training time, and over $3000 \times$ faster rendering speed.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.06912v1">PDF</a> Accepted at CVPR 2024. Project page: <a target="_blank" rel="noopener" href="https://fictionarry.github.io/DNGaussian/">https://fictionarry.github.io/DNGaussian/</a></p><p><strong>Summary</strong><br>深度正则化的 3D 高斯辐射场实现了高性价比的实时少量镜头新视角合成。</p><p><strong>Key Takeaways</strong></p><ul><li>高斯辐射场的效率与质量优于 3D 高斯贴片。</li><li>场景几何退化主要由高斯原语定位引起，深度约束可缓解此问题。</li><li>硬软深度正则化在粗略单目深度监督下可恢复准确的场景几何。</li><li>全局局部深度归一化可增强对局部小深度变化的关注。</li><li>DNGaussian 在 LLFF、DTU 和 Blender 数据集上优于最先进的方法。</li><li>与最先进的方法相比，DNGaussian 显着降低了内存成本。</li><li>DNGaussian 的训练时间减少了 25 倍，渲染速度提高了 3000 倍。</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>标题：DNGaussian：优化稀疏视图 3D 高斯辐射场</li><li>作者：Xiao Bai*, Xiangru Chen, Sheng Liu, Xin Tong, Xiaoguang Han</li><li>单位：北京航空航天大学</li><li>关键词：稀疏视图、3D 高斯辐射场、深度归一化、神经颜色渲染器</li><li>论文链接：None</li><li>摘要： （1）研究背景：辐射场在从稀疏输入视图合成新颖视图方面表现出令人印象深刻的性能，但现有的方法存在训练成本高和推理速度慢的问题。 （2）过去的方法及问题：现有方法基于 3D 高斯辐射场，但当输入视图减少时，会遇到几何退化的问题。 （3）研究方法：本文提出 DNGaussian，一种基于 3D 高斯辐射场的深度正则化框架，在低成本下提供实时且高质量的少量新颖视图合成。通过引入硬软深度正则化和全局局部深度归一化，可以恢复准确的场景几何并精细地重塑几何形状。 （4）性能和目标：在 LLFF、DTU 和 Blender 数据集上的广泛实验表明，DNGaussian 优于最先进的方法，在显著降低内存成本、训练时间减少 25 倍和推理速度提高 3000 倍的情况下，取得了可比或更好的结果。</li></ol><p>7.Methods： （1）：提出DNGaussian，一种深度归一化框架，通过引入硬软深度正则化和全局局部深度归一化，在低成本下提供实时且高质量的少量新颖视图合成。 （2）：引入硬深度正则化，通过最小化场景几何的深度梯度来惩罚不合理的深度变化。 （3）：引入软深度正则化，通过最小化场景几何的深度拉普拉斯算子来惩罚不平滑的深度变化。 （4）：引入全局局部深度归一化，通过将局部深度值归一化为全局深度范围来稳定训练过程。</p><p><strong>8. 结论</strong></p><p><strong>(1): 本工作的重要意义</strong></p><p>本文提出 DNGaussian 框架，通过深度正则化将 3D 高斯辐射场引入到少量新颖视图合成任务中。</p><p><strong>(2): 本文优缺点总结</strong></p><p><strong>创新点：</strong></p><ul><li>引入硬软深度正则化和全局局部深度归一化，提高了场景几何的准确性和精细度。</li></ul><p><strong>性能：</strong></p><ul><li>在 LLFF、DTU 和 Blender 数据集上优于最先进的方法，在显著降低内存成本、训练时间减少 25 倍和推理速度提高 3000 倍的情况下，取得了可比或更好的结果。</li></ul><p><strong>工作量：</strong></p><ul><li>训练和推理成本低，可以实时合成高质量的新颖视图。</li></ul><details><summary>点此查看论文截图</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-dae52d7d48c393553eaefb0a09269fe0.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-e3d64b07ef974a9326e03be048b0aa88.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f81338e5bf0cec7be815850dd100ce1b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-fdd479c95f23763e44cccc2ac03892f1.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f6522aaddb6fa9c6b731ea5fe4d54464.jpg" align="middle"></details>## FreGS: 3D Gaussian Splatting with Progressive Frequency Regularization **Authors:Jiahui Zhang, Fangneng Zhan, Muyu Xu, Shijian Lu, Eric Xing** 3D Gaussian splatting has achieved very impressive performance in real-time novel view synthesis. However, it often suffers from over-reconstruction during Gaussian densification where high-variance image regions are covered by a few large Gaussians only, leading to blur and artifacts in the rendered images. We design a progressive frequency regularization (FreGS) technique to tackle the over-reconstruction issue within the frequency space. Specifically, FreGS performs coarse-to-fine Gaussian densification by exploiting low-to-high frequency components that can be easily extracted with low-pass and high-pass filters in the Fourier space. By minimizing the discrepancy between the frequency spectrum of the rendered image and the corresponding ground truth, it achieves high-quality Gaussian densification and alleviates the over-reconstruction of Gaussian splatting effectively. Experiments over multiple widely adopted benchmarks (e.g., Mip-NeRF360, Tanks-and-Temples and Deep Blending) show that FreGS achieves superior novel view synthesis and outperforms the state-of-the-art consistently. [PDF](http://arxiv.org/abs/2403.06908v1) **Summary** 渐进式频率正则化技术有效解决了 3D 高斯散点图过度重建带来的图像模糊和瑕疵。 **Key Takeaways** - FreGS 采用渐进式高斯增密，从低频到高频逐层优化。 - FreGS 利用傅里叶空间的低通和高通滤波器轻松提取低频到高频分量。 - FreGS 通过最小化渲染图像频谱和对应真实频谱之间的差异，提升了高斯增密质量。 - FreGS 有效缓解了高斯散点图的过度重建问题。 - FreGS 在 Mip-NeRF360、Tanks-and-Temples 和深度混合等多个基准上均取得了最优的新视图合成效果。 - FreGS 始终优于当前最先进的技术。 - FreGS 对图像模糊和瑕疵具有出色的抑制效果。 **[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>题目：FreGS：具有渐进式频率正则化的 3D 高斯散点化</li><li>作者：Jiahui Zhang，Fangneng Zhan，Muyu Xu，Shijian Lu，Eric Xing</li><li>第一作者单位：南洋理工大学</li><li>关键词：新视角合成，高斯散点化，频率正则化</li><li>论文链接：None，Github 链接：None</li><li><p>摘要： （1）：研究背景：3D 高斯散点化在实时新视角合成中取得了令人印象深刻的性能。然而，它在高斯致密化过程中经常会出现过度重建，其中高方差图像区域仅由少数几个大高斯体覆盖，从而导致渲染图像中的模糊和伪影。 （2）：过去方法及其问题：本文动机明确，提出了渐进式频率正则化 (FreGS) 技术来解决频率空间中的过度重建问题。 （3）：研究方法：FreGS 通过利用低通和高通滤波器在傅里叶空间中轻松提取的低频到高频分量，执行粗到精的高斯致密化。通过最小化渲染图像的频谱与相应真实值之间的差异，它实现了高质量的高斯致密化，有效地缓解了高斯散点化的过度重建。 （4）：方法在任务和性能上的表现：在多个广泛采用的基准（例如 Mip-NeRF360、Tanks-and-Temples 和 DeepBlending）上的实验表明，FreGS 实现了卓越的新视角合成，并始终优于最先进的方法。</p></li><li><p>方法： （1）：本文提出渐进式频率正则化（FreGS）技术，通过利用傅里叶空间中提取的低频到高频分量，执行粗到精的高斯致密化。 （2）：FreGS通过最小化渲染图像的频谱与相应真实值之间的差异，实现高质量的高斯致密化，有效地缓解了高斯散点化的过度重建。 （3）：设计频率退火技术，实现渐进式频率正则化，可以逐步利用低到高频分量来执行粗到精的高斯致密化。</p></li><li><p>总结： （1）本工作的重要意义：FreGS 提出渐进式频率正则化技术，从频率视角提升 3D 高斯散点化，有效缓解了高斯散点化的过度重建问题，在多个广泛采用的室内外场景上实现了卓越的新视角合成效果。 （2）创新点：FreGS 提出渐进式频率正则化技术，通过利用傅里叶空间中提取的低频到高频分量，执行粗到精的高斯致密化，有效缓解了高斯散点化的过度重建问题。 性能：FreGS 在多个广泛采用的基准上实现了卓越的新视角合成，并始终优于最先进的方法。 工作量：FreGS 的实现相对复杂，需要设计频率退火技术和最小化渲染图像的频谱与相应真实值之间的差异。</p></li></ol><details><summary>点此查看论文截图</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-07cbe93d5240e4aa795cfc2554b29280.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c725f327a32c127deea0c454f4062887.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3ddb9b45e2c546000557a3be13e0a4a4.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f440ba30a1f4e263c32265e76b8e0898.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3063a8cf69313732153e2186dcdf414d.jpg" align="middle"></details><h2 id="V3D-Video-Diffusion-Models-are-Effective-3D-Generators"><a href="#V3D-Video-Diffusion-Models-are-Effective-3D-Generators" class="headerlink" title="V3D: Video Diffusion Models are Effective 3D Generators"></a>V3D: Video Diffusion Models are Effective 3D Generators</h2><p><strong>Authors:Zilong Chen, Yikai Wang, Feng Wang, Zhengyi Wang, Huaping Liu</strong></p><p>Automatic 3D generation has recently attracted widespread attention. Recent methods have greatly accelerated the generation speed, but usually produce less-detailed objects due to limited model capacity or 3D data. Motivated by recent advancements in video diffusion models, we introduce V3D, which leverages the world simulation capacity of pre-trained video diffusion models to facilitate 3D generation. To fully unleash the potential of video diffusion to perceive the 3D world, we further introduce geometrical consistency prior and extend the video diffusion model to a multi-view consistent 3D generator. Benefiting from this, the state-of-the-art video diffusion model could be fine-tuned to generate 360degree orbit frames surrounding an object given a single image. With our tailored reconstruction pipelines, we can generate high-quality meshes or 3D Gaussians within 3 minutes. Furthermore, our method can be extended to scene-level novel view synthesis, achieving precise control over the camera path with sparse input views. Extensive experiments demonstrate the superior performance of the proposed approach, especially in terms of generation quality and multi-view consistency. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a></p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.06738v1">PDF</a> Code available at <a target="_blank" rel="noopener" href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a> Project page: <a target="_blank" rel="noopener" href="https://heheyas.github.io/V3D/">https://heheyas.github.io/V3D/</a></p><p><strong>Summary</strong><br>利用预训练视频扩散模型的世界模拟能力促进 3D 生成，并通过几何一致性先验和多视图一致 3D 生成器扩展视频扩散模型。</p><p><strong>Key Takeaways</strong></p><ul><li>自动 3D 生成受到广泛关注，但传统方法由于模型容量或 3D 数据限制而产生细节较少的物体。</li><li>V3D 利用预训练视频扩散模型的世界模拟能力来促进 3D 生成。</li><li>几何一致性先验和多视图一致 3D 生成器充分发挥视频扩散感知 3D 世界的潜力。</li><li>只需一张图片，即可微调最先进的视频扩散模型，生成围绕物体 360 度旋转的轨道帧。</li><li>借助定制的重建管道，可在 3 分钟内生成高质量的网格或 3D 高斯体。</li><li>该方法可扩展到场景级新颖视图合成，使用稀疏输入视图对相机路径进行精确控制。</li><li>大量实验表明该方法在生成质量和多视图一致性方面具有卓越的性能。</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>标题：V3D：视频扩散模型是有效的 3D 生成器</li><li>作者：Zilong Chen, Yikai Wang†, Feng Wang, Zhengyi Wang, Huaping Liu†</li><li>第一作者单位：清华大学</li><li>关键词：3D 生成，视频扩散模型，多视图重建</li><li>论文链接：arxiv.org/abs/2403.06738 Github 代码链接：None</li><li>摘要： （1）研究背景：自动 3D 生成已引起广泛关注。近期方法极大地提高了生成速度，但由于模型容量有限，通常会产生细节较少的物体。 （2）过去方法：过去方法包括基于隐式神经表示和基于显式网格表示的方法。前者生成速度快，但细节较少；后者细节丰富，但生成速度慢。 （3）研究方法：本文提出 V3D，一种基于视频扩散模型的 3D 生成方法。V3D 将 2D 图像序列扩散到 3D 空间，生成高保真 3D 物体。 （4）性能：在 ShapeNet 数据集上，V3D 在生成速度和细节丰富度方面均优于现有方法。V3D 可以生成高保真 3D 物体，生成时间仅需 3 分钟。</li></ol><p><methods>: (1): V3D将2D图像序列扩散到3D空间，生成高保真3D物体。 (2): V3D使用基于视频扩散模型的方法，将2D图像序列逐帧扩散到3D空间中。 (3): V3D采用多视图重建技术，从不同视角生成2D图像序列，提高3D物体的细节丰富度。</methods></p><ol><li>结论： （1） 本工作通过将图像到视频扩散模型应用于 3D 生成，提出了一种新颖且高效的方法 V3D，显著提升了 3D 物体的生成速度和细节丰富度。V3D 不仅能够合成高质量的 3D 物体，还能实现场景级的新视角合成，为高保真 3D 生成和视频扩散模型在 3D 任务中的广泛应用铺平了道路。 （2） 创新点：</li><li>将视频扩散模型应用于 3D 生成，通过将 2D 图像序列扩散到 3D 空间，显著提升了生成速度和细节丰富度。</li><li>提出了一种量身定制的重建管道，结合精心设计的初始化和纹理优化，能够在 3 分钟内重建高质量的 3D 高斯体或精细纹理网格。</li><li>将该框架扩展到场景级的新视角合成，实现了对摄像机路径的精确控制和出色的多视角一致性。 性能：</li><li>在 ShapeNet 数据集上，V3D 在生成速度和细节丰富度方面均优于现有方法。</li><li>V3D 能够生成高质量的 3D 物体，生成时间仅需 3 分钟。</li><li>V3D 在场景级新视角合成方面表现出色，实现了对摄像机路径的精确控制和出色的多视角一致性。 工作量：</li><li>V3D 的实现相对简单，易于部署和使用。</li><li>V3D 的训练过程高效，在单张 NVIDIA A100 GPU 上仅需数小时即可完成。</li><li>V3D 的推理速度快，能够在几秒钟内生成高质量的 3D 物体或合成新视角。</li></ol><details><summary>点此查看论文截图</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-8c7c858eb0759a50450bc9e902b68068.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-20859973aba31d5ec733373f6d25379e.jpg" align="middle"></details></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/3DGS/">https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/3DGS/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/3DGS/">3DGS</a></div><div class="post_share"><div class="social-share" data-image="https://picx.zhimg.com/v2-07cbe93d5240e4aa795cfc2554b29280.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/03/13/Paper/2024-03-13/NeRF/" title="NeRF"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-beec12e6377f8382c630b862b43c0639.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">NeRF</div></div></a></div><div class="next-post pull-right"><a href="/2024/03/13/Paper/2024-03-13/Talking%20Head%20Generation/" title="Talking Head Generation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-f16882204804b40a491523a7984bf7e2.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Talking Head Generation</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/01/25/Paper/3DGS%20Survey/" title="3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-25</div><div class="title">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting</div></div></a></div><div><a href="/2024/01/24/Paper/2024-01-24/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-3d3dcd00c27bc3d320b23d4247ae79f3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-24</div><div class="title">3DGS</div></div></a></div><div><a href="/2024/01/30/Paper/2024-01-30/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2032721a60695f2d41ac96f75dec65a2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">3DGS</div></div></a></div><div><a href="/2024/02/09/Paper/2024-02-09/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-28074a5f13fdf5a52c0d4de04dfb9406.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-09</div><div class="title">3DGS</div></div></a></div><div><a href="/2024/02/23/Paper/2024-02-23/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-23</div><div class="title">3DGS</div></div></a></div><div><a href="/2024/02/02/Paper/2024-02-02/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-e4e5570dfa99dfac9b297f7650c717c3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-02</div><div class="title">3DGS</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-03-13-%E6%9B%B4%E6%96%B0"><span class="toc-text">2024-03-13 更新</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#StyleGaussian-Instant-3D-Style-Transfer-with-Gaussian-Splatting"><span class="toc-text">StyleGaussian: Instant 3D Style Transfer with Gaussian Splatting</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DNGaussian-Optimizing-Sparse-View-3D-Gaussian-Radiance-Fields-with-Global-Local-Depth-Normalization"><span class="toc-text">DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with Global-Local Depth Normalization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#V3D-Video-Diffusion-Models-are-Effective-3D-Generators"><span class="toc-text">V3D: Video Diffusion Models are Effective 3D Generators</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image:url('https://picx.zhimg.com/v2-07cbe93d5240e4aa795cfc2554b29280.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">簡</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const e of document.querySelectorAll('script[type^="math/tex"]')){const a=!!e.type.match(/; *mode=display/),n=new t.options.MathItem(e.textContent,t.inputJax[0],a),s=document.createTextNode("");e.parentNode.replaceChild(s,e),n.start={node:s,delim:"",n:0},n.end={node:s,delim:"",n:0},t.math.push(n)}},""]}}};const t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t)}</script></div><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("已挂载butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/25/Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="2024/01/25/Paper/3DGS Survey/" alt="">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting 今天想介绍的是`ZJU`带来的`3DGS`的首篇综述`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="2024/01/25/Paper/3DGS Survey/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/12/CUDA/Pytorch+cppcuda extension 学习/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="2023/12/12/CUDA/Pytorch+cppcuda extension 学习/" alt="">CUDA编程学习：自定义Pytorch+cpp/cuda extension</a><div class="blog-slider__text">虽然说PyTorch提供了丰富的与神经网络、张量代数、数据处理等相关的操作，但是有时候你可能需要**更定制化的操作**，比如使用论文中的新型激活函数，或者实现作为研究一部分开发的操作。在PyTorch中，最简单的集成自定义操作的方式是在Python中编写，通过扩展Function和Module来实现，</div><a class="blog-slider__button" href="2023/12/12/CUDA/Pytorch+cppcuda extension 学习/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker/" alt="">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</a><div class="blog-slider__text">Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</a><div class="blog-slider__text">Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis， 这份资源库整理了与生成对抗网络(GAN)和神经辐射场(NeRF)相关的论文、代码和资源,重点关注基于图像和音频的虚拟讲话头合成论文及已发布代码。如果您觉得这个仓库有用,请star⭐支持!</div><a class="blog-slider__button" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/17/Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023/12/17/Project/ChatPaperFree/" alt="">ChatPaperFree GeminiPro（一分钟读论文）</a><div class="blog-slider__text">ChatPaperFree是一个基于ChatGPT的自动论文摘要生成器，在ChatPaper的基础上进行的更新，采用了最近由Google开源的Gemini Pro大模型。目前,我们能够对用户输入的论文进行自动总结。未来,我还计划加入对论文图片/表格/公式的识别 extraction,从而生成更全面而易读的总结。</div><a class="blog-slider__button" href="2023/12/17/Project/ChatPaperFree/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script></body></html>