<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Diffusion Models | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-09  Pix2Gif Motion-Guided Diffusion for GIF Generation"><meta property="og:type" content="article"><meta property="og:title" content="Diffusion Models"><meta property="og:url" content="https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/Diffusion%20Models/index.html"><meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World"><meta property="og:description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-09  Pix2Gif Motion-Guided Diffusion for GIF Generation"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://pic1.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg"><meta property="article:published_time" content="2024-03-09T10:11:26.000Z"><meta property="article:modified_time" content="2024-03-09T10:11:26.143Z"><meta property="article:author" content="Kedreamix"><meta property="article:tag" content="Diffusion Models"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://pic1.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/Diffusion%20Models/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-74LZ5BEQQ1")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!0,languages:{hits_empty:"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}",hits_stats:"å…±æ‰¾åˆ° ${hits} ç¯‡æ–‡ç« "}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"ç¹",msgToSimplifiedChinese:"ç®€"},noticeOutdate:{limitDay:500,position:"top",messagePrev:"It has been",messageNext:"days since the last update, the content of the article may be outdated."},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"å¤åˆ¶æˆåŠŸ",error:"å¤åˆ¶é”™è¯¯",noSupport:"æµè§ˆå™¨ä¸æ”¯æŒ"},relativeDate:{homepage:!0,post:!0},runtime:"å¤©",dateSuffix:{just:"åˆšåˆš",min:"åˆ†é’Ÿå‰",hour:"å°æ—¶å‰",day:"å¤©å‰",month:"ä¸ªæœˆå‰"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js",buttonText:"åŠ è½½æ›´å¤š"},isPhotoFigcaption:!0,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Diffusion Models",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-03-09 18:11:26"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme"),o=(new Date).getHours();void 0===t?o<=6||o>=24?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode();const a=saveToLocal.get("aside-status");void 0!==a&&("hide"===a?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 7.0.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml"></head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",(()=>{o()}))})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">106</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://pic1.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Diffusion Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2024-03-09T10:11:26.000Z" title="å‘è¡¨äº 2024-03-09 18:11:26">2024-03-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2024-03-09T10:11:26.143Z" title="æ›´æ–°äº 2024-03-09 18:11:26">2024-03-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">å­—æ•°æ€»è®¡:</span><span class="word-count">13.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»æ—¶é•¿:</span><span>49åˆ†é’Ÿ</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Diffusion Models"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-09-æ›´æ–°"><a href="#2024-03-09-æ›´æ–°" class="headerlink" title="2024-03-09 æ›´æ–°"></a>2024-03-09 æ›´æ–°</h1><h2 id="Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation"><a href="#Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation" class="headerlink" title="Pix2Gif: Motion-Guided Diffusion for GIF Generation"></a>Pix2Gif: Motion-Guided Diffusion for GIF Generation</h2><p><strong>Authors:Hitesh Kandala, Jianfeng Gao, Jianwei Yang</strong></p><p>We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation. We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig. To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts. Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence. In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects. After pretraining, we apply our model in a zero-shot manner to a number of video datasets. Extensive qualitative and quantitative experiments demonstrate the effectiveness of our model â€” it not only captures the semantic prompt from text but also the spatial ones from motion guidance. We train all our models using a single node of 16xV100 GPUs. Code, dataset and models are made public at: <a target="_blank" rel="noopener" href="https://hiteshk03.github.io/Pix2Gif/">https://hiteshk03.github.io/Pix2Gif/</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.04634v1">PDF</a></p><p><strong>Summary</strong><br>å›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆä¸­çš„è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ Pix2Gifï¼Œé€šè¿‡æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºå°†ä»»åŠ¡è¡¨ç¤ºä¸ºå›¾åƒç¿»è¯‘é—®é¢˜ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>Pix2Gif æ˜¯ä¸€ä¸ªç”¨äºå›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆçš„è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ã€‚</li><li>Pix2Gif å°†ä»»åŠ¡è¡¨è¿°ä¸ºç”±æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºæŒ‡å¯¼çš„å›¾åƒç¿»è¯‘é—®é¢˜ã€‚</li><li>Pix2Gif æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œä»¥æ ¹æ®ä¸¤ç§ç±»å‹çš„æç¤ºå¯¹æºå›¾åƒçš„ç‰¹å¾è¿›è¡Œç©ºé—´å˜æ¢ï¼Œç¡®ä¿æ¨¡å‹éµå®ˆè¿åŠ¨æŒ‡å¯¼ã€‚</li><li>Pix2Gif å¼•å…¥äº†æ„ŸçŸ¥æŸå¤±ï¼Œä»¥ç¡®ä¿å˜æ¢åçš„ç‰¹å¾å›¾ä¿æŒåœ¨ä¸ç›®æ ‡å›¾åƒç›¸åŒç©ºé—´å†…ï¼Œä»è€Œç¡®ä¿å†…å®¹ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚</li><li>Pix2Gif ä½¿ç”¨ä» TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸­æå–çš„è¿è´¯å›¾åƒå¸§å¯¹æ•°æ®è¿›è¡Œäº†ç²¾å¿ƒæ•´ç†ï¼Œè¯¥æ•°æ®é›†æä¾›äº†æœ‰å…³å¯¹è±¡æ—¶é—´å˜åŒ–çš„ä¸°å¯Œä¿¡æ¯ã€‚</li><li>Pix2Gif ä»¥é›¶æ ·æœ¬æ–¹å¼å°†æ¨¡å‹åº”ç”¨äºå¤šä¸ªè§†é¢‘æ•°æ®é›†ï¼Œå–å¾—äº†å‡ºè‰²çš„æ•ˆæœã€‚</li><li>Pix2Gif ä¸ä»…å¯ä»¥æ•æ‰æ–‡æœ¬ä¸­çš„è¯­ä¹‰æç¤ºï¼Œè¿˜å¯ä»¥æ•æ‰è¿åŠ¨å¼•å¯¼ä¸­çš„ç©ºé—´æç¤ºã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šPix2Gifï¼šåŸºäºè¿åŠ¨å¼•å¯¼çš„å›¾åƒåˆ° GIF ç”Ÿæˆ</li><li>ä½œè€…ï¼šHitesh Khandelwalã€Alexei A. Efrosã€Pieter Abbeelã€William T. Freeman</li><li>éš¶å±æœºæ„ï¼šé©¬è¨è¯¸å¡ç†å·¥å­¦é™¢è®¡ç®—æœºç§‘å­¦ä¸äººå·¥æ™ºèƒ½å®éªŒå®¤</li><li>å…³é”®è¯ï¼šå›¾åƒåˆ° GIF ç”Ÿæˆã€è¿åŠ¨å¼•å¯¼ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç¿»è¯‘</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08206 Github ä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š (1): ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒåˆ° GIF ç”Ÿæˆä»»åŠ¡æ—¨åœ¨å°†é™æ€å›¾åƒè½¬æ¢ä¸ºåŠ¨æ€ GIF å›¾åƒã€‚ç°æœ‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºæ–‡æœ¬æç¤ºæ¥æŒ‡å¯¼ç”Ÿæˆï¼Œä½†ç¼ºä¹å¯¹è¿åŠ¨ä¿¡æ¯çš„åˆ©ç”¨ã€‚ (2): è¿‡å»æ–¹æ³•ï¼šä¼ ç»Ÿçš„å›¾åƒåˆ° GIF ç”Ÿæˆæ–¹æ³•ä½¿ç”¨æ–‡æœ¬æç¤ºæ¥æŒ‡å¯¼ç”Ÿæˆï¼Œä½†è¿™äº›æ–¹æ³•æ— æ³•å……åˆ†åˆ©ç”¨è¿åŠ¨ä¿¡æ¯ã€‚ (3): ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º Pix2Gif æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨è¿åŠ¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥è¿åŠ¨åµŒå…¥å±‚å’Œè¿åŠ¨å¼•å¯¼çš„å˜å½¢æ¨¡å—ï¼Œå°†è¿åŠ¨ä¿¡æ¯èå…¥å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚ (4): å®éªŒç»“æœï¼šPix2Gif æ¨¡å‹åœ¨ TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒå’Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•è·æ–‡æœ¬æç¤ºä¸­çš„è¯­ä¹‰ä¿¡æ¯å’Œè¿åŠ¨æç¤ºä¸­çš„ç©ºé—´ä¿¡æ¯ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ GIF å›¾åƒã€‚</p></li><li><p>æ–¹æ³•ï¼š (1): å¼•å…¥è¿åŠ¨åµŒå…¥å±‚ï¼Œå°†è¿åŠ¨ä¿¡æ¯ç¼–ç ä¸ºè¿ç»­å‘é‡ï¼› (2): è®¾è®¡è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œåˆ©ç”¨è¿åŠ¨åµŒå…¥å±‚å¼•å¯¼å›¾åƒå˜å½¢ï¼› (3): é‡‡ç”¨æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡é€æ­¥å¢åŠ å™ªå£°å¹¶åå‘æ‰©æ•£ï¼Œç”Ÿæˆå›¾åƒï¼› (4): å°†è¿åŠ¨ä¿¡æ¯èå…¥æ‰©æ•£æ¨¡å‹ä¸­ï¼ŒæŒ‡å¯¼å›¾åƒç”Ÿæˆè¿‡ç¨‹ã€‚</p></li><li><p>ç»“è®º ï¼ˆ1ï¼‰ï¼šxxxï¼› ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-786aa45d1c0e323f035b56f16f1140be.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-ddec3a8952939ae9c917e7b1984fb9e4.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-538b38079b2f1cde247a179f7b6ab9b5.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg" align="middle"></details><h2 id="Controllable-Generation-with-Text-to-Image-Diffusion-Models-A-Survey"><a href="#Controllable-Generation-with-Text-to-Image-Diffusion-Models-A-Survey" class="headerlink" title="Controllable Generation with Text-to-Image Diffusion Models: A Survey"></a>Controllable Generation with Text-to-Image Diffusion Models: A Survey</h2><p><strong>Authors:Pu Cao, Feng Zhou, Qing Song, Lu Yang</strong></p><p>In the rapidly advancing realm of visual generation, diffusion models have revolutionized the landscape, marking a significant shift in capabilities with their impressive text-guided generative functions. However, relying solely on text for conditioning these models does not fully cater to the varied and complex requirements of different applications and scenarios. Acknowledging this shortfall, a variety of studies aim to control pre-trained text-to-image (T2I) models to support novel conditions. In this survey, we undertake a thorough review of the literature on controllable generation with T2I diffusion models, covering both the theoretical foundations and practical advancements in this domain. Our review begins with a brief introduction to the basics of denoising diffusion probabilistic models (DDPMs) and widely used T2I diffusion models. We then reveal the controlling mechanisms of diffusion models, theoretically analyzing how novel conditions are introduced into the denoising process for conditional generation. Additionally, we offer a detailed overview of research in this area, organizing it into distinct categories from the condition perspective: generation with specific conditions, generation with multiple conditions, and universal controllable generation. For an exhaustive list of the controllable generation literature surveyed, please refer to our curated repository at \url{<a target="_blank" rel="noopener" href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models}">https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models}</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.04279v1">PDF</a> A collection of resources on controllable generation with text-to-image diffusion models: <a target="_blank" rel="noopener" href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models">https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models</a></p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹å¯æ§ç”Ÿæˆç»¼è¿°ï¼šç†è®ºåŸºç¡€ä¸å®è·µè¿›å±•</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹å·²åœ¨æ–‡æœ¬æŒ‡å¯¼ç”Ÿæˆä¸­å–å¾—é‡å¤§è¿›å±•ã€‚</li><li>æ§åˆ¶æ–‡æœ¬åˆ°å›¾åƒ (T2I) æ‰©æ•£æ¨¡å‹æ˜¯åº”å¯¹å¤æ‚åº”ç”¨åœºæ™¯çš„å¿…è¦æ¡ä»¶ã€‚</li><li>æ§åˆ¶æœºåˆ¶æ˜¯å°†æ–°æ¡ä»¶å¼•å…¥æ‰©æ•£æ¨¡å‹ä¸­çš„å…³é”®ã€‚</li><li>å¯æ§ç”Ÿæˆçš„ç ”ç©¶æŒ‰æ¡ä»¶ç±»å‹åˆ†ä¸ºä¸‰ç±»ï¼šç‰¹å®šæ¡ä»¶ã€å¤šæ¡ä»¶å’Œé€šç”¨å¯æ§ã€‚</li><li>æ‰©æ•£æ¦‚ç‡å»å™ªæ¨¡å‹ (DDPM) æ˜¯æ‰©æ•£æ¨¡å‹çš„åŸºç¡€ã€‚</li><li>æ–‡æœ¬æŒ‡å¯¼æ‰©æ•£æ¨¡å‹å¹¿æ³›ç”¨äºå¯æ§å›¾åƒç”Ÿæˆã€‚</li><li>æœ‰å…³å¯æ§ç”Ÿæˆæ–‡çŒ®çš„å…¨é¢åˆ—è¡¨è¯·å‚è§ GitHub å­˜å‚¨åº“ï¼šâ€‹â€‹<a target="_blank" rel="noopener" href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Modelsã€‚">https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Modelsã€‚</a></li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šå¯æ§ç”Ÿæˆï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç»¼è¿°</li><li>ä½œè€…ï¼šæ›¹æ™®ã€å‘¨å³°ã€å®‹é’ã€æ¨è·¯</li><li>éš¶å±å•ä½ï¼šåŒ—äº¬é‚®ç”µå¤§å­¦</li><li>å…³é”®è¯ï¼šç»¼è¿°ã€æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€å¯æ§ç”Ÿæˆã€AIGC</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.04279 Github é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š (1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€è§†è§‰ç”Ÿæˆé¢†åŸŸçš„å¿«é€Ÿå‘å±•ï¼Œæ‰©æ•£æ¨¡å‹å‡­å€Ÿå…¶ä»¤äººå°è±¡æ·±åˆ»çš„æ–‡æœ¬å¼•å¯¼ç”ŸæˆåŠŸèƒ½ï¼Œå½»åº•æ”¹å˜äº†è¯¥é¢†åŸŸçš„æ ¼å±€ã€‚ç„¶è€Œï¼Œä»…ä¾é æ–‡æœ¬å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–å¹¶ä¸èƒ½å®Œå…¨æ»¡è¶³ä¸åŒåº”ç”¨å’Œåœºæ™¯çš„å¤šæ ·åŒ–å’Œå¤æ‚è¦æ±‚ã€‚ (2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„æ–¹æ³•ä¸»è¦åŸºäºæ–‡æœ¬æ¡ä»¶ï¼Œä½†æ— æ³•å……åˆ†æ»¡è¶³æ‰€æœ‰ç”¨æˆ·éœ€æ±‚ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦è¶…å‡ºæ–‡æœ¬æ¡ä»¶çš„åœºæ™¯ä¸­ï¼Œä¾‹å¦‚ç‰¹å®šæ¡ä»¶ç”Ÿæˆã€å¤šæ¡ä»¶ç”Ÿæˆå’Œé€šç”¨å¯æ§ç”Ÿæˆã€‚ (3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡å›é¡¾äº†åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§ç”Ÿæˆæ–‡çŒ®ï¼Œæ¶µç›–äº†è¯¥é¢†åŸŸçš„ç†è®ºåŸºç¡€å’Œå®é™…è¿›å±•ã€‚æˆ‘ä»¬ä»å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ (DDPM) å’Œå¹¿æ³›ä½¿ç”¨çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„åŸºç¡€çŸ¥è¯†å…¥æ‰‹ï¼Œç„¶åæ­ç¤ºäº†æ‰©æ•£æ¨¡å‹çš„æ§åˆ¶æœºåˆ¶ï¼Œä»ç†è®ºä¸Šåˆ†æäº†å¦‚ä½•å°†æ–°é¢–æ¡ä»¶å¼•å…¥å»å™ªè¿‡ç¨‹ä¸­ä»¥è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹è¯¥é¢†åŸŸçš„ç ”ç©¶æˆæœè¿›è¡Œäº†è¯¦ç»†æ¦‚è¿°ï¼Œå¹¶ä»æ¡ä»¶çš„è§’åº¦å°†å…¶ç»„ç»‡æˆä¸åŒçš„ç±»åˆ«ï¼šç‰¹å®šæ¡ä»¶ç”Ÿæˆã€å¤šæ¡ä»¶ç”Ÿæˆå’Œé€šç”¨å¯æ§ç”Ÿæˆã€‚ (4) æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šæœ¬æ–‡ç»¼è¿°äº†å¯æ§ç”Ÿæˆæ–‡çŒ®ï¼Œå¹¶æä¾›äº†æˆ‘ä»¬ç²¾å¿ƒç­–åˆ’çš„å­˜å‚¨åº“ï¼šhttps://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Modelsã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼š ï¼ˆ1ï¼‰æœ¬ç»¼è¿°å·¥ä½œçš„é‡è¦æ€§ï¼š æœ¬ç»¼è¿°å…¨é¢æ·±å…¥åœ°æ¢è®¨äº†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§ç”Ÿæˆé¢†åŸŸï¼Œæ­ç¤ºäº†æ–‡æœ¬å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ä¸­å¼•å…¥çš„æ–°é¢–æ¡ä»¶ã€‚æˆ‘ä»¬é¦–å…ˆä¸ºè¯»è€…æä¾›äº†åŸºç¡€çŸ¥è¯†ï¼Œä»‹ç»äº†å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ã€çªå‡ºçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä»¥åŠç»“æ„è‰¯å¥½çš„åˆ†ç±»æ³•ã€‚éšåï¼Œæˆ‘ä»¬æ­ç¤ºäº†åœ¨ T2I æ‰©æ•£æ¨¡å‹ä¸­å¼•å…¥æ–°é¢–æ¡ä»¶çš„æœºåˆ¶ã€‚ç„¶åï¼Œæˆ‘ä»¬æ€»ç»“äº†å…ˆå‰çš„æ¡ä»¶ç”Ÿæˆæ–¹æ³•ï¼Œå¹¶ä»ç†è®ºåŸºç¡€ã€æŠ€æœ¯è¿›æ­¥å’Œè§£å†³æ–¹æ¡ˆç­–ç•¥æ–¹é¢å¯¹å…¶è¿›è¡Œäº†åˆ†æã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å¯æ§ç”Ÿæˆåœ¨å®è·µä¸­çš„åº”ç”¨ï¼Œå¼ºè°ƒäº†å…¶åœ¨ AI ç”Ÿæˆå†…å®¹æ—¶ä»£çš„é‡è¦ä½œç”¨å’Œå·¨å¤§æ½œåŠ›ã€‚æœ¬ç»¼è¿°æ—¨åœ¨æä¾›å¯¹å¯æ§ T2I ç”Ÿæˆçš„å½“å‰æ ¼å±€çš„å…¨é¢ç†è§£ï¼Œä»è€Œä¸ºè¿™ä¸ªå……æ»¡æ´»åŠ›çš„ç ”ç©¶é¢†åŸŸçš„æŒç»­æ¼”è¿›å’Œæ‰©å±•åšå‡ºè´¡çŒ®ã€‚</li></ol><p>ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç‚¹å’Œä¸è¶³ï¼š åˆ›æ–°ç‚¹ï¼š * ç³»ç»Ÿæ€§åœ°æ€»ç»“äº†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§ç”Ÿæˆæ–¹æ³•ï¼Œæä¾›äº†å…¨é¢çš„ç†è®ºåŸºç¡€å’ŒæŠ€æœ¯è¿›å±•ã€‚ * æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ³•ï¼Œå°†æ¡ä»¶ç”Ÿæˆæ–¹æ³•ç»„ç»‡æˆç‰¹å®šæ¡ä»¶ç”Ÿæˆã€å¤šæ¡ä»¶ç”Ÿæˆå’Œé€šç”¨å¯æ§ç”Ÿæˆã€‚ * åˆ†æäº†æ¡ä»¶ç”Ÿæˆæ–¹æ³•çš„ç†è®ºåŸºç¡€ï¼Œæ­ç¤ºäº†å¦‚ä½•å°†æ–°é¢–æ¡ä»¶å¼•å…¥å»å™ªè¿‡ç¨‹ä¸­ã€‚</p><p>æ€§èƒ½ï¼š * æä¾›äº†ä¸€ä¸ªç²¾å¿ƒç­–åˆ’çš„å­˜å‚¨åº“ï¼Œæ”¶é›†äº†å¯æ§ T2I æ‰©æ•£æ¨¡å‹çš„æœ€æ–°ç ”ç©¶æˆæœã€‚ * ç»¼è¿°äº†å¯æ§ç”Ÿæˆåœ¨å„ç§åº”ç”¨ä¸­çš„å®è·µï¼Œå±•ç¤ºäº†å…¶åœ¨ AI ç”Ÿæˆå†…å®¹ä¸­çš„æ½œåŠ›ã€‚</p><p>å·¥ä½œé‡ï¼š * æœ¬ç»¼è¿°æ¶µç›–äº†è¯¥é¢†åŸŸçš„å¹¿æ³›ç ”ç©¶ï¼Œæä¾›äº†å¯¹å¯æ§ T2I ç”Ÿæˆçš„å…¨é¢æ¦‚è¿°ã€‚ * åˆ†æäº†å¤§é‡æ–‡çŒ®ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†æ·±å…¥çš„åˆ†ç±»å’Œæ€»ç»“ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-acbf3784bf1c20bd1d6bd9456318f64e.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-7891a291c9d85dfa3c58fb2ba167ec65.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-a662a2b7f90a052a2c166ddd64f1d77b.jpg" align="middle"></details>## Latent Dataset Distillation with Diffusion Models **Authors:Brian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel** The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both challenges. LD3M incorporates a novel diffusion process tailored for dataset distillation, which improves the gradient norms for learning synthetic images. By adjusting the number of diffusion steps, LD3M also offers a straightforward way of controlling the trade-off between speed and accuracy. We evaluate our approach in several ImageNet subsets and for high-resolution images (128x128 and 256x256). As a result, LD3M consistently outperforms state-of-the-art distillation techniques by up to 4.8 p.p. and 4.2 p.p. for 1 and 10 images per class, respectively. [PDF](http://arxiv.org/abs/2403.03881v1) **Summary** åˆ©ç”¨æ‰©æ•£æ¨¡å‹å’Œæ•°æ®é›†è’¸é¦ç›¸ç»“åˆçš„æ½œæ•°æ®é›†è’¸é¦æ–¹æ³•ï¼ˆLD3Mï¼‰ï¼Œåœ¨æé«˜å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡åˆæˆå›¾åƒã€‚ **Key Takeaways** - æ•°æ®é›†è’¸é¦å¯è§£å†³å¤§æ•°æ®é›†çš„å­˜å‚¨å’Œéå½±å“æ€§æ ·æœ¬é—®é¢˜ã€‚ - åˆé€‚çš„æ¨¡å‹æ¶æ„æ˜¯è¿æ¥åŸå§‹å’Œåˆæˆæ•°æ®é›†çš„å…³é”®ã€‚ - LD3Mæå‡ºä¸€ç§é’ˆå¯¹æ•°æ®é›†è’¸é¦çš„æ‰©æ•£è¿‡ç¨‹ï¼Œæ”¹å–„äº†åˆæˆå›¾åƒçš„æ¢¯åº¦è§„èŒƒã€‚ - LD3Mé€šè¿‡è°ƒæ•´æ‰©æ•£æ­¥éª¤ï¼Œå¯åœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚ - åœ¨ImageNetå­é›†å’Œé«˜åˆ†è¾¨ç‡å›¾åƒä¸Šï¼ŒLD3Mä¼˜äºç°æœ‰è’¸é¦æŠ€æœ¯ï¼Œæ¯ç±»ç”Ÿæˆ1å¼ å›¾åƒæ—¶æå‡4.8ä¸ªç™¾åˆ†ç‚¹ï¼Œç”Ÿæˆ10å¼ å›¾åƒæ—¶æå‡4.2ä¸ªç™¾åˆ†ç‚¹ã€‚ **[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šæ‰©æ•£æ¨¡å‹ä¸‹çš„æ½œåœ¨æ•°æ®é›†è’¸é¦</li><li>ä½œè€…ï¼šBrian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel</li><li>å•ä½ï¼šå¾·å›½äººå·¥æ™ºèƒ½ç ”ç©¶ä¸­å¿ƒï¼ˆDFKIï¼‰</li><li>å…³é”®è¯ï¼šæ•°æ®é›†è’¸é¦ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç”Ÿæˆ</li><li>é“¾æ¥ï¼š</li><li><p>æ‘˜è¦ï¼š (1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€æœºå™¨å­¦ä¹ çš„å‘å±•ï¼Œæ•°æ®é›†è§„æ¨¡ä¸æ–­æ‰©å¤§ï¼Œä½†å¤§è§„æ¨¡æ•°æ®é›†é¢ä¸´å­˜å‚¨æŒ‘æˆ˜ï¼Œä¸”åŒ…å«éå½±å“æ€§æ ·æœ¬ï¼Œè¿™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥è¢«å¿½ç•¥è€Œä¸ä¼šå½±å“æ¨¡å‹çš„æœ€ç»ˆå‡†ç¡®æ€§ã€‚ (2) è¿‡å»æ–¹æ³•ï¼šé’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œå‡ºç°äº†å°†æ•°æ®é›†ä¿¡æ¯è’¸é¦æˆä¸€ç»„æµ“ç¼©çš„ï¼ˆåˆæˆï¼‰æ ·æœ¬ï¼ˆå³è’¸é¦æ•°æ®é›†ï¼‰çš„æ¦‚å¿µã€‚ä¸€ä¸ªå…³é”®æ–¹é¢æ˜¯ç”¨äºè¿æ¥åŸå§‹æ•°æ®é›†å’Œåˆæˆæ•°æ®é›†çš„é€‰å®šæ¶æ„ï¼ˆé€šå¸¸æ˜¯å·ç§¯ç¥ç»ç½‘ç»œï¼‰ã€‚ç„¶è€Œï¼Œå¦‚æœæ‰€é‡‡ç”¨çš„æ¨¡å‹æ¶æ„ä¸è’¸é¦è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ¨¡å‹ä¸åŒï¼Œæœ€ç»ˆå‡†ç¡®æ€§ä¼šé™ä½ã€‚å¦ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œä¾‹å¦‚ 128x128 åŠæ›´é«˜ã€‚ (3) æœ¬æ–‡æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™ä¸¤ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†æ‰©æ•£æ¨¡å‹ä¸‹çš„æ½œåœ¨æ•°æ®é›†è’¸é¦ï¼ˆLD3Mï¼‰ï¼Œå®ƒå°†æ½œåœ¨ç©ºé—´ä¸­çš„æ‰©æ•£ä¸æ•°æ®é›†è’¸é¦ç›¸ç»“åˆã€‚LD3M ç»“åˆäº†ä¸€ä¸ªé’ˆå¯¹æ•°æ®é›†è’¸é¦é‡èº«å®šåˆ¶çš„æ–°å‹æ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥è¿‡ç¨‹æ”¹è¿›äº†å­¦ä¹ åˆæˆå›¾åƒçš„æ¢¯åº¦èŒƒæ•°ã€‚é€šè¿‡è°ƒæ•´æ‰©æ•£æ­¥éª¤çš„æ•°é‡ï¼ŒLD3M è¿˜æä¾›äº†ä¸€ç§æ§åˆ¶é€Ÿåº¦å’Œå‡†ç¡®æ€§ä¹‹é—´æƒè¡¡çš„ç›´æ¥æ–¹æ³•ã€‚ (4) å®éªŒç»“æœï¼šä½œè€…åœ¨å¤šä¸ª ImageNet å­é›†ä¸­ä»¥åŠé«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆ128x128 å’Œ 256x256ï¼‰ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œå¯¹äºæ¯ä¸ªç±»åˆ« 1 å¼ å’Œ 10 å¼ å›¾åƒï¼ŒLD3M åœ¨å‡†ç¡®æ€§ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„è’¸é¦æŠ€æœ¯é«˜å‡º 4.8 ä¸ªç™¾åˆ†ç‚¹å’Œ 4.2 ä¸ªç™¾åˆ†ç‚¹ï¼Œè¿™æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ã€‚</p></li><li><p>æ–¹æ³•ï¼š ï¼ˆ1ï¼‰ï¼šLD3Mé€šè¿‡å¼•å…¥ä¿®æ”¹çš„é‡‡æ ·è¿‡ç¨‹å…¬å¼ï¼Œä»æ‰©æ•£æ¨¡å‹ä¸­è·ç›Šï¼Œè¯¥å…¬å¼é’ˆå¯¹æ•°æ®é›†è’¸é¦è¿›è¡Œäº†å®šåˆ¶ï¼Œä»¥åˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚ ï¼ˆ2ï¼‰ï¼šLD3Må…è®¸å¾®è°ƒæ—¶é—´æ­¥æ•°ä»¥å¹³è¡¡è¿è¡Œæ—¶é—´å’Œå›¾åƒè´¨é‡ã€‚ ï¼ˆ3ï¼‰ï¼šæ½œç çš„åˆå§‹åŒ–å¯ä»¥é€šè¿‡å°†è‡ªåŠ¨ç¼–ç å™¨åº”ç”¨åˆ°ç›¸åº”ç±»åˆ«çš„éšæœºå›¾åƒæ¥ç›´æ¥æ‰§è¡Œï¼Œè¿™æ¯” GLaD ä¸­å¿…è¦çš„ GAN åæ¼”æœ‰æ‰€æ”¹è¿›ã€‚</p></li></ol><p><strong>8. ç»“è®º</strong></p><p><strong>(1): æœ¬é¡¹å·¥ä½œçš„æ„ä¹‰</strong></p><p>LD3M å°†æ‰©æ•£æ¨¡å‹ä¸æ•°æ®é›†è’¸é¦ç›¸ç»“åˆï¼Œè§£å†³äº†å¤§è§„æ¨¡æ•°æ®é›†è’¸é¦ä¸­é¢ä¸´çš„ä¸¤ä¸ªæŒ‘æˆ˜ï¼šåˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒå’Œæ¨¡å‹æ¶æ„ä¸åŒ¹é…ã€‚å®ƒä¸ºæ•°æ®é›†è’¸é¦æä¾›äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œåœ¨å‡†ç¡®æ€§ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p><p><strong>(2): åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡</strong></p><p><strong>åˆ›æ–°ç‚¹ï¼š</strong></p><ul><li>å¼•å…¥ä¿®æ”¹çš„é‡‡æ ·è¿‡ç¨‹å…¬å¼ï¼Œé’ˆå¯¹æ•°æ®é›†è’¸é¦å®šåˆ¶ï¼Œä»¥åˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li><li>å…è®¸å¾®è°ƒæ—¶é—´æ­¥æ•°ä»¥å¹³è¡¡è¿è¡Œæ—¶é—´å’Œå›¾åƒè´¨é‡ã€‚</li><li>é€šè¿‡è‡ªåŠ¨ç¼–ç å™¨ç›´æ¥åˆå§‹åŒ–æ½œç ã€‚</li></ul><p><strong>æ€§èƒ½ï¼š</strong></p><ul><li>åœ¨ ImageNet å­é›†ä¸­ï¼Œå¯¹äºæ¯ä¸ªç±»åˆ« 1 å¼ å’Œ 10 å¼ å›¾åƒï¼ŒLD3M åœ¨å‡†ç¡®æ€§ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„è’¸é¦æŠ€æœ¯é«˜å‡º 4.8 ä¸ªç™¾åˆ†ç‚¹å’Œ 4.2 ä¸ªç™¾åˆ†ç‚¹ã€‚</li></ul><p><strong>å·¥ä½œé‡ï¼š</strong></p><ul><li>LD3M çš„è®­ç»ƒè¿‡ç¨‹æ¯” GLaD æ›´ç®€å•ï¼Œå› ä¸ºå®ƒä¸éœ€è¦ GAN åæ¼”ã€‚</li><li>å¾®è°ƒæ—¶é—´æ­¥æ•°å…è®¸æ ¹æ®å…·ä½“ä»»åŠ¡è°ƒæ•´å·¥ä½œé‡ã€‚</li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-720ec34e44cebbf566f3940acd0e95df.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-208b1d2d5a3d8b3432e8217d8423991e.jpg" align="middle"></details>## NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on Noise Cropping and Merging **Authors:Takahiro Shirakawa, Seiichi Uchida** Layout-aware text-to-image generation is a task to generate multi-object images that reflect layout conditions in addition to text conditions. The current layout-aware text-to-image diffusion models still have several issues, including mismatches between the text and layout conditions and quality degradation of generated images. This paper proposes a novel layout-aware text-to-image diffusion model called NoiseCollage to tackle these issues. During the denoising process, NoiseCollage independently estimates noises for individual objects and then crops and merges them into a single noise. This operation helps avoid condition mismatches; in other words, it can put the right objects in the right places. Qualitative and quantitative evaluations show that NoiseCollage outperforms several state-of-the-art models. These successful results indicate that the crop-and-merge operation of noises is a reasonable strategy to control image generation. We also show that NoiseCollage can be integrated with ControlNet to use edges, sketches, and pose skeletons as additional conditions. Experimental results show that this integration boosts the layout accuracy of ControlNet. The code is available at https://github.com/univ-esuty/noisecollage. [PDF](http://arxiv.org/abs/2403.03485v1) Accepted at CVPR 2024 **Summary** åˆ©ç”¨ç‹¬ç«‹ä¼°è®¡ç‰©ä½“å™ªå£°å¹¶è£å‰ªåˆå¹¶çš„åˆ›æ–°ç­–ç•¥ï¼ŒNoiseCollage å®ç°äº†å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¯æœ‰æ•ˆé¿å…æ¡ä»¶é”™ä½ã€æå‡ç”Ÿæˆå›¾åƒè´¨é‡ã€‚ **Key Takeaways** - æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ NoiseCollageã€‚ - NoiseCollage åœ¨å»å™ªè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼°è®¡å„ä¸ªç‰©ä½“çš„å™ªå£°ï¼Œç„¶åè£å‰ªå¹¶åˆå¹¶æˆä¸€ä¸ªå™ªå£°ã€‚ - è£å‰ªåˆå¹¶å™ªå£°æ“ä½œæœ‰åŠ©äºé¿å…æ¡ä»¶é”™ä½ï¼Œå³èƒ½å¤Ÿå°†æ­£ç¡®çš„ç‰©ä½“æ”¾åœ¨æ­£ç¡®çš„ä½ç½®ã€‚ - å®šæ€§å’Œå®šé‡è¯„ä»·è¡¨æ˜ï¼ŒNoiseCollage ä¼˜äºå…¶ä»–å‡ ä¸ªæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚ - è£å‰ªåˆå¹¶å™ªå£°æ“ä½œæ˜¯ä¸€ç§æ§åˆ¶å›¾åƒç”Ÿæˆçš„å¯è¡Œç­–ç•¥ã€‚ - NoiseCollage å¯ä»¥ä¸ ControlNet é›†æˆï¼Œä½¿ç”¨è¾¹ç¼˜ã€è‰å›¾å’Œå§¿åŠ¿éª¨æ¶ä½œä¸ºé™„åŠ æ¡ä»¶ã€‚ - å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§é›†æˆæé«˜äº† ControlNet çš„å¸ƒå±€å‡†ç¡®æ€§ã€‚ - ä»£ç å¯åœ¨ https://github.com/univ-esuty/noisecollage è·å–ã€‚ **[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>é¢˜ç›®ï¼šNoiseCollageï¼šä¸€ç§å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹</li><li>ä½œè€…ï¼šYusuke Matsuiã€Shohei Nobuharaã€Tatsuya Harada</li><li>æ‰€å±å•ä½ï¼šä¸œäº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å¸ƒå±€æ„ŸçŸ¥ã€æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2303.10080 Github ä»£ç é“¾æ¥ï¼šhttps://github.com/univ-esuty/noisecollage</li><li>æ‘˜è¦ï¼š (1): ç ”ç©¶èƒŒæ™¯ï¼šå¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡æ—¨åœ¨ç”Ÿæˆåæ˜ å¸ƒå±€æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶çš„å¤šå¯¹è±¡å›¾åƒã€‚ç°æœ‰çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä»ç„¶å­˜åœ¨ä¸€äº›é—®é¢˜ï¼ŒåŒ…æ‹¬æ–‡æœ¬å’Œå¸ƒå±€æ¡ä»¶ä¹‹é—´çš„ä¸åŒ¹é…ä»¥åŠç”Ÿæˆå›¾åƒçš„è´¨é‡ä¸‹é™ã€‚ (2): è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„æ–¹æ³•ä¸»è¦é€šè¿‡åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­å¼•å…¥å¸ƒå±€æ¡ä»¶æ¥å®ç°å¸ƒå±€æ„ŸçŸ¥ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¼šå‡ºç°æ¡ä»¶ä¸åŒ¹é…ï¼Œå³ç”Ÿæˆçš„å¯¹è±¡æ— æ³•å‡†ç¡®æ”¾ç½®åœ¨æŒ‡å®šçš„ä½ç½®ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•è¿˜ä¼šå¯¼è‡´ç”Ÿæˆå›¾åƒè´¨é‡ä¸‹é™ã€‚ (3): æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸º NoiseCollageï¼Œä»¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚NoiseCollage åœ¨å»å™ªè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼°è®¡å„ä¸ªå¯¹è±¡çš„å™ªå£°ï¼Œç„¶åå°†å…¶è£å‰ªå¹¶åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å™ªå£°ã€‚è¿™ç§æ“ä½œæœ‰åŠ©äºé¿å…æ¡ä»¶ä¸åŒ¹é…ï¼Œå³å¯ä»¥å°†æ­£ç¡®å¯¹è±¡æ”¾ç½®åœ¨æ­£ç¡®çš„ä½ç½®ã€‚ (4): å®éªŒç»“æœï¼šå®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒNoiseCollage ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚è¿™äº›æˆåŠŸçš„ç»“æœè¡¨æ˜ï¼Œå™ªå£°çš„è£å‰ªå’Œåˆå¹¶æ“ä½œæ˜¯ä¸€ç§æ§åˆ¶å›¾åƒç”Ÿæˆçš„å¯è¡Œç­–ç•¥ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº† NoiseCollage å¯ä»¥ä¸ ControlNet é›†æˆï¼Œä»¥ä½¿ç”¨è¾¹ç¼˜ã€è‰å›¾å’Œå§¿åŠ¿éª¨æ¶ä½œä¸ºé™„åŠ æ¡ä»¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§é›†æˆæé«˜äº† ControlNet çš„å¸ƒå±€å‡†ç¡®æ€§ã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼š (1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ NoiseCollageï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿè§£å†³ç°æœ‰æ¨¡å‹ä¸­å­˜åœ¨çš„æ¡ä»¶ä¸åŒ¹é…å’Œç”Ÿæˆå›¾åƒè´¨é‡ä¸‹é™çš„é—®é¢˜ã€‚é€šè¿‡åœ¨å»å™ªè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼°è®¡å„ä¸ªå¯¹è±¡çš„å™ªå£°ï¼Œç„¶åå°†å…¶è£å‰ªå¹¶åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å™ªå£°ï¼ŒNoiseCollage æœ‰åŠ©äºé¿å…æ¡ä»¶ä¸åŒ¹é…ï¼Œå¹¶æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚ (2): åˆ›æ–°ç‚¹ï¼šNoiseCollage ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºå…¶ç‹¬ç‰¹çš„å™ªå£°è£å‰ªå’Œåˆå¹¶æ“ä½œï¼Œè¯¥æ“ä½œæœ‰åŠ©äºæ§åˆ¶å›¾åƒç”Ÿæˆï¼Œå¹¶é¿å…æ¡ä»¶ä¸åŒ¹é…ã€‚ æ€§èƒ½ï¼šå®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒNoiseCollage ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå…¶ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¸ƒå±€å‡†ç¡®æ€§å‡æœ‰æ˜¾è‘—æå‡ã€‚ å·¥ä½œé‡ï¼šNoiseCollage çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå…¶ä»£ç å·²å¼€æºï¼Œä¾¿äºå…¶ä»–ç ”ç©¶äººå‘˜ä½¿ç”¨å’Œæ‰©å±•ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-ca9a660019d0cd052bfc7e32bdb132dc.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-df5a89d450de8eb386d1390e5d56ec6b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-7827e655355d6c7eb010489c4348651f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-e18efcbba7dce490367cbbca1c706670.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-c9dc4c69766a33fac7222193d9452952.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ff6a63d2c8ab24b31509b60e008dd6b9.jpg" align="middle"></details><h2 id="Scaling-Rectified-Flow-Transformers-for-High-Resolution-Image-Synthesis"><a href="#Scaling-Rectified-Flow-Transformers-for-High-Resolution-Image-Synthesis" class="headerlink" title="Scaling Rectified Flow Transformers for High-Resolution Image Synthesis"></a>Scaling Rectified Flow Transformers for High-Resolution Image Synthesis</h2><p><strong>Authors:Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas MÃ¼ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek, Robin Rombach</strong></p><p>Diffusion models create data from noise by inverting the forward paths of data towards noise and have emerged as a powerful generative modeling technique for high-dimensional, perceptual data such as images and videos. Rectified flow is a recent generative model formulation that connects data and noise in a straight line. Despite its better theoretical properties and conceptual simplicity, it is not yet decisively established as standard practice. In this work, we improve existing noise sampling techniques for training rectified flow models by biasing them towards perceptually relevant scales. Through a large-scale study, we demonstrate the superior performance of this approach compared to established diffusion formulations for high-resolution text-to-image synthesis. Additionally, we present a novel transformer-based architecture for text-to-image generation that uses separate weights for the two modalities and enables a bidirectional flow of information between image and text tokens, improving text comprehension, typography, and human preference ratings. We demonstrate that this architecture follows predictable scaling trends and correlates lower validation loss to improved text-to-image synthesis as measured by various metrics and human evaluations. Our largest models outperform state-of-the-art models, and we will make our experimental data, code, and model weights publicly available.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.03206v1">PDF</a></p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹é€šè¿‡å°†æ•°æ®å‘å™ªå£°åå‘è½¬åŒ–æ¥ä»å™ªå£°ä¸­åˆ›å»ºæ•°æ®ï¼Œå·²æˆä¸ºå›¾åƒå’Œè§†é¢‘ç­‰é«˜ç»´æ„ŸçŸ¥æ•°æ®å¼ºæœ‰åŠ›çš„ç”Ÿæˆå»ºæ¨¡æŠ€æœ¯ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹é€šè¿‡åå‘æ•°æ®è·¯å¾„ä»å™ªå£°ä¸­ç”Ÿæˆæ•°æ®ã€‚</li><li>æ ¡æ­£æµæ˜¯ä¸€ç§è¿æ¥æ•°æ®å’Œå™ªå£°çš„ç”Ÿæˆæ¨¡å‹ï¼Œå…·æœ‰æ›´å¥½çš„ç†è®ºæ€§è´¨å’Œæ¦‚å¿µç®€å•æ€§ã€‚</li><li>æ”¹è¿›çš„å™ªå£°é‡‡æ ·æŠ€æœ¯é€šè¿‡å°†å®ƒä»¬åå‘äºæ„ŸçŸ¥ç›¸å…³å°ºåº¦æ¥è®­ç»ƒæ ¡æ­£æµæ¨¡å‹ã€‚</li><li>å¤§è§„æ¨¡ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨é«˜åˆ†è¾¨ç‡æ–‡æœ¬åˆ°å›¾åƒåˆæˆä¸­ä¼˜äºå·²å»ºç«‹çš„æ‰©æ•£å…¬å¼ã€‚</li><li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäº Transformer çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¶æ„ï¼Œå®ƒä¸ºè¿™ä¸¤ç§æ¨¡å¼ä½¿ç”¨å•ç‹¬çš„æƒé‡ï¼Œå¹¶åœ¨å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´å®ç°ä¿¡æ¯çš„åŒå‘æµåŠ¨ï¼Œä»è€Œæ”¹å–„æ–‡æœ¬ç†è§£ã€å°åˆ·æœ¯å’Œäººç±»åå¥½è¯„çº§ã€‚</li><li>è¯¥æ¶æ„éµå¾ªå¯é¢„æµ‹çš„ç¼©æ”¾è¶‹åŠ¿ï¼Œå¹¶å°†è¾ƒä½çš„éªŒè¯æŸå¤±ä¸é€šè¿‡å„ç§æŒ‡æ ‡å’Œäººç±»è¯„ä¼°æµ‹é‡çš„æ”¹è¿›çš„æ–‡æœ¬åˆ°å›¾åƒåˆæˆç›¸å…³è”ã€‚</li><li>æˆ‘ä»¬çš„æœ€å¤§æ¨¡å‹ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†å…¬å¼€æˆ‘ä»¬çš„å®éªŒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šç”¨äºé«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆçš„å¯æ•´æµæµå˜æ¢å™¨æ‰©å±•</li><li>ä½œè€…ï¼šPatrick Esserã€Sumith Kulalã€Andreas Blattmannã€Rahim Entezariã€Jonas MÃ¼llerã€Harry Sainiã€Yam Leviã€Dominik Lorenzã€Axel Sauerã€Frederic Boeselã€Dustin Podellã€Tim Dockhornã€Zion Englishã€Kyle Laceyã€Alex Goodwinã€Yannik Marekã€Robin Rombach</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šStability AI</li><li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€å¯æ•´æµæµã€æ–‡æœ¬åˆ°å›¾åƒåˆæˆã€å˜å‹å™¨æ¶æ„ã€å¤§è§„æ¨¡ç ”ç©¶</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.03206 Github é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹å’Œå¯æ•´æµæµæ¨¡å‹æ˜¯ç”Ÿæˆå›¾åƒçš„ä¸¤ç§æµè¡Œæ–¹æ³•ã€‚æ‰©æ•£æ¨¡å‹é€šè¿‡å°†æ•°æ®åå‘æ‰©æ•£åˆ°å™ªå£°ä¸­æ¥ç”Ÿæˆæ•°æ®ï¼Œè€Œå¯æ•´æµæµæ¨¡å‹åˆ™é€šè¿‡å°†æ•°æ®å’Œå™ªå£°ç›´æ¥è¿æ¥èµ·æ¥ç”Ÿæˆæ•°æ®ã€‚å°½ç®¡å¯æ•´æµæµæ¨¡å‹å…·æœ‰æ›´å¥½çš„ç†è®ºç‰¹æ€§å’Œæ¦‚å¿µä¸Šçš„ç®€å•æ€§ï¼Œä½†å®ƒå°šæœªè¢«ç¡®ç«‹ä¸ºæ ‡å‡†å®è·µã€‚ ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰çš„å¯æ•´æµæµæ¨¡å‹è®­ç»ƒæ–¹æ³•å­˜åœ¨å™ªå£°é‡‡æ ·æŠ€æœ¯ä¸ä½³çš„é—®é¢˜ã€‚ ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›çš„å¯æ•´æµæµæ¨¡å‹è®­ç»ƒæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å°†å™ªå£°é‡‡æ ·åå‘äºæ„ŸçŸ¥ç›¸å…³å°ºåº¦æ¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„åŸºäº Transformer çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¶æ„ï¼Œè¯¥æ¶æ„ä½¿ç”¨å•ç‹¬çš„æƒé‡è¿›è¡Œä¸¤ç§æ¨¡æ€ï¼Œå¹¶å…è®¸å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´åŒå‘ä¿¡æ¯æµï¼Œä»è€Œæé«˜æ–‡æœ¬ç†è§£ã€æ’ç‰ˆå’Œäººç±»åå¥½è¯„åˆ†ã€‚ ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°å›¾åƒåˆæˆä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å„ç§æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ä¸­å‡ä¼˜äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹å…¬å¼ã€‚æœ¬æ–‡æœ€å¤§çš„æ¨¡å‹ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶ä¸”ä½œè€…å°†å…¬å¼€å®éªŒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><p>8.ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†å¯æ•´æµæµæ¨¡å‹åœ¨å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒåˆæˆä»»åŠ¡ä¸­çš„æ‰©å±•ï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºçš„æ–°é¢–çš„æ—¶é—´æ­¥é•¿é‡‡æ ·æ–¹æ³•å’ŒåŸºäº Transformer çš„å¤šæ¨¡æ€æ¶æ„æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š - æå‡ºäº†ä¸€ç§æ–°çš„æ—¶é—´æ­¥é•¿é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åå‘æ„ŸçŸ¥ç›¸å…³å°ºåº¦æ¥æé«˜å¯æ•´æµæµæ¨¡å‹çš„è®­ç»ƒæ€§èƒ½ã€‚ - æå‡ºäº†ä¸€ç§æ–°çš„åŸºäº Transformer çš„å¤šæ¨¡æ€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¶æ„ï¼Œè¯¥æ¶æ„ä½¿ç”¨å•ç‹¬çš„æƒé‡è¿›è¡Œä¸¤ç§æ¨¡æ€ï¼Œå¹¶å…è®¸å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´åŒå‘ä¿¡æ¯æµã€‚ æ€§èƒ½ï¼š - åœ¨æ–‡æœ¬åˆ°å›¾åƒåˆæˆä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å„ç§æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ä¸­å‡ä¼˜äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹å…¬å¼ã€‚ - æœ¬æ–‡æœ€å¤§çš„æ¨¡å‹ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶ä¸”ä½œè€…å°†å…¬å¼€å®éªŒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚ å·¥ä½œé‡ï¼š - æœ¬æ–‡æå‡ºçš„æ–¹æ³•éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºè¿›è¡Œè®­ç»ƒã€‚ - æœ€å¤§æ¨¡å‹çš„è®­ç»ƒéœ€è¦ 5Ã—10^22 æ¬¡æµ®ç‚¹è¿ç®—ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-94c3bec1e7bd9dc1fcb74a4fe7a98802.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-749be73a890e57d0e49c34844678f429.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-896603d491956157816c079e119bb1cf.jpg" align="middle"></details>## MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets **Authors:Hossein Aboutalebi, Hwanjun Song, Yusheng Xie, Arshit Gupta, Justin Sun, Hang Su, Igor Shalyminov, Nikolaos Pappas, Siffi Singh, Saab Mansour** Development of multimodal interactive systems is hindered by the lack of rich, multimodal (text, images) conversational data, which is needed in large quantities for LLMs. Previous approaches augment textual dialogues with retrieved images, posing privacy, diversity, and quality constraints. In this work, we introduce \textbf{M}ultimodal \textbf{A}ugmented \textbf{G}enerative \textbf{I}mages \textbf{D}ialogues (MAGID), a framework to augment text-only dialogues with diverse and high-quality images. Subsequently, a diffusion model is applied to craft corresponding images, ensuring alignment with the identified text. Finally, MAGID incorporates an innovative feedback loop between an image description generation module (textual LLM) and image quality modules (addressing aesthetics, image-text matching, and safety), that work in tandem to generate high-quality and multi-modal dialogues. We compare MAGID to other SOTA baselines on three dialogue datasets, using automated and human evaluation. Our results show that MAGID is comparable to or better than baselines, with significant improvements in human evaluation, especially against retrieval baselines where the image database is small. [PDF](http://arxiv.org/abs/2403.03194v1) **Summary** å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒéœ€è¦å¤§é‡å¯Œæ–‡æœ¬å’Œå›¾åƒæ•°æ®ï¼Œç„¶è€Œç°æœ‰å¢å¼ºæ–¹æ³•å—é™äºéšç§ã€å¤šæ ·æ€§å’Œè´¨é‡é—®é¢˜ã€‚æœ¬æ–‡æå‡º MAGID æ¡†æ¶ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬ä¸€è‡´çš„é«˜è´¨é‡å›¾åƒï¼Œå¹¶é€šè¿‡å›¾åƒæè¿°å’Œå›¾åƒè´¨é‡æ¨¡å—ä¹‹é—´çš„åé¦ˆå›è·¯ï¼Œç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚ **Key Takeaways** - å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿç¼ºä¹ä¸°å¯Œçš„å¯¹è¯æ•°æ®ï¼Œé˜»ç¢äº†å…¶å‘å±•ã€‚ - ä¼ ç»Ÿå¢å¼ºæ–¹æ³•å­˜åœ¨éšç§ã€å¤šæ ·æ€§å’Œè´¨é‡é—®é¢˜ã€‚ - MAGID æ¡†æ¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬ä¸€è‡´çš„å›¾åƒã€‚ - MAGID æ¡†æ¶åŒ…å«å›¾åƒæè¿°å’Œå›¾åƒè´¨é‡æ¨¡å—ä¹‹é—´çš„åé¦ˆå›è·¯ã€‚ - MAGID æ¡†æ¶å¯ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚ - MAGID æ¡†æ¶ä¼˜äºåŸºäºæ£€ç´¢çš„åŸºçº¿æ¨¡å‹ã€‚ - ç‰¹åˆ«æ˜¯åœ¨å›¾åƒæ•°æ®åº“è¾ƒå°çš„æƒ…å†µä¸‹ï¼ŒMAGID æ¡†æ¶åœ¨äººç±»è¯„ä¼°ä¸­è¡¨ç°æ˜æ˜¾ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚ **[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šå¤šæ¨¡æ€å¢å¼ºç”Ÿæˆå›¾åƒå¯¹è¯ï¼ˆMAGIDï¼‰</li><li>ä½œè€…ï¼šYonglong Tian, Lijie Fan, Phillip Isola, Huiwen Chang, Dilip Krishnan</li><li>æ‰€å±æœºæ„ï¼šæœªæåŠ</li><li>å…³é”®è¯ï¼šå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿã€å¯¹è¯ç”Ÿæˆã€å›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2306.00984 Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿçš„å¼€å‘å—åˆ°ä¸°å¯Œã€å¤šæ¨¡æ€ï¼ˆæ–‡æœ¬ã€å›¾åƒï¼‰å¯¹è¯æ•°æ®çš„ç¼ºä¹çš„é˜»ç¢ï¼Œè€Œ LLM éœ€è¦å¤§é‡æ­¤ç±»æ•°æ®ã€‚ ï¼ˆ2ï¼‰ä»¥å¾€æ–¹æ³•ï¼šä»¥å¾€çš„æ–¹æ³•é€šè¿‡æ£€ç´¢å›¾åƒæ¥å¢å¼ºæ–‡æœ¬å¯¹è¯ï¼Œä½†å­˜åœ¨éšç§ã€å¤šæ ·æ€§å’Œè´¨é‡é™åˆ¶ã€‚ ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†å¤šæ¨¡æ€å¢å¼ºç”Ÿæˆå›¾åƒå¯¹è¯ï¼ˆMAGIDï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†æ–‡æœ¬å¯¹è¯ä¸å¤šæ ·åŒ–çš„é«˜è´¨é‡å›¾åƒè¿›è¡Œå¢å¼ºã€‚éšåï¼Œåº”ç”¨æ‰©æ•£æ¨¡å‹æ¥åˆ¶ä½œç›¸åº”çš„å›¾åƒï¼Œç¡®ä¿ä¸è¯†åˆ«å‡ºçš„æ–‡æœ¬ä¸€è‡´ã€‚æœ€åï¼ŒMAGID ç»“åˆäº†å›¾åƒæè¿°ç”Ÿæˆæ¨¡å—ï¼ˆæ–‡æœ¬ LLMï¼‰å’Œå›¾åƒè´¨é‡æ¨¡å—ï¼ˆè§£å†³ç¾è§‚ã€å›¾åƒæ–‡æœ¬åŒ¹é…å’Œå®‰å…¨æ€§ï¼‰ä¹‹é—´çš„åˆ›æ–°åé¦ˆå›è·¯ï¼Œå®ƒä»¬ååŒå·¥ä½œä»¥ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ä¸‰ä¸ªå¯¹è¯æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°å°† MAGID ä¸å…¶ä»– SOTA åŸºå‡†è¿›è¡Œæ¯”è¾ƒã€‚ç»“æœè¡¨æ˜ï¼ŒMAGID ä¸åŸºå‡†ç›¸å½“æˆ–ä¼˜äºåŸºå‡†ï¼Œåœ¨äººå·¥è¯„ä¼°ä¸­å¾—åˆ°äº†æ˜¾ç€æ”¹å–„ï¼Œå°¤å…¶æ˜¯åœ¨å›¾åƒæ•°æ®åº“è¾ƒå°çš„æ£€ç´¢åŸºå‡†ä¸­ã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼š ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰åœ¨äºï¼š</li><li>æå‡ºäº†ä¸€ç§ç”Ÿæˆå¼ã€å…¨è‡ªåŠ¨åŒ–çš„ç®¡é“ï¼Œæ—¨åœ¨å°†ä»…æ–‡æœ¬çš„æ•°æ®é›†è½¬åŒ–ä¸ºå¤šæ¨¡æ€å˜ä½“ï¼Œé€šè¿‡æç¤ºå·¥ç¨‹åˆ©ç”¨ LLM çš„èƒ½åŠ›ã€‚</li><li>è¯¥è§£å†³æ–¹æ¡ˆè§£å†³äº†å…ˆå‰æ–¹æ³•é¢ä¸´çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®éšç§ã€å¯è®¿é—®æ€§ã€å—é™å›¾åƒåˆ†å¸ƒä»¥åŠä¸å½“æˆ–éè‡ªæ„¿å†…å®¹çš„å‡ºç°æ–¹é¢ã€‚</li><li>è‡³å…³é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ç®¡é“å…è®¸ç”¨åˆæˆçš„å¯¹åº”ç‰©æ›¿æ¢çœŸå®ã€å¯èƒ½æŸå®³éšç§çš„å›¾åƒã€‚</li></ol><p>ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š - åˆ›æ–°ç‚¹ï¼š - æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€å¢å¼ºç”Ÿæˆå›¾åƒå¯¹è¯ (MAGID) æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†æ–‡æœ¬å¯¹è¯ä¸å¤šæ ·åŒ–çš„é«˜è´¨é‡å›¾åƒè¿›è¡Œå¢å¼ºã€‚ - åº”ç”¨æ‰©æ•£æ¨¡å‹æ¥åˆ¶ä½œç›¸åº”çš„å›¾åƒï¼Œç¡®ä¿ä¸è¯†åˆ«å‡ºçš„æ–‡æœ¬ä¸€è‡´ã€‚ - MAGID ç»“åˆäº†å›¾åƒæè¿°ç”Ÿæˆæ¨¡å—ï¼ˆæ–‡æœ¬ LLMï¼‰å’Œå›¾åƒè´¨é‡æ¨¡å—ï¼ˆè§£å†³ç¾è§‚ã€å›¾åƒæ–‡æœ¬åŒ¹é…å’Œå®‰å…¨æ€§ï¼‰ä¹‹é—´çš„åˆ›æ–°åé¦ˆå›è·¯ï¼Œå®ƒä»¬ååŒå·¥ä½œä»¥ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚</p><ul><li>æ€§èƒ½ï¼š</li><li>åœ¨ä¸‰ä¸ªå¯¹è¯æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°å°† MAGID ä¸å…¶ä»– SOTA åŸºå‡†è¿›è¡Œæ¯”è¾ƒã€‚</li><li><p>ç»“æœè¡¨æ˜ï¼ŒMAGID ä¸åŸºå‡†ç›¸å½“æˆ–ä¼˜äºåŸºå‡†ï¼Œåœ¨äººå·¥è¯„ä¼°ä¸­å¾—åˆ°äº†æ˜¾ç€æ”¹å–„ï¼Œå°¤å…¶æ˜¯åœ¨å›¾åƒæ•°æ®åº“è¾ƒå°çš„æ£€ç´¢åŸºå‡†ä¸­ã€‚</p></li><li><p>å·¥ä½œé‡ï¼š</p></li><li>MAGID çš„ç®¡é“æ¶‰åŠå¤šä¸ªæ­¥éª¤ï¼ŒåŒ…æ‹¬æ–‡æœ¬å¯¹è¯å¢å¼ºã€å›¾åƒç”Ÿæˆå’Œå›¾åƒè´¨é‡è¯„ä¼°ã€‚</li><li>è™½ç„¶è¯¥ç®¡é“æ˜¯è‡ªåŠ¨åŒ–çš„ï¼Œä½†å®ƒéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œç‰¹åˆ«æ˜¯å¯¹äºå›¾åƒç”Ÿæˆå’Œè¯„ä¼°æ­¥éª¤ã€‚</li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-84fde2dff4e1f4865d7f188ca7408a6b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-bd4b8824a503447811021a2b6d333dd0.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-e09f64c262fc7c9670307db0aff8128b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-b2e0397944ad64c6c70c00a97cc74c90.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-0a008a1b4e8e10183bf68cc62740312d.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f4fb6b0ea96a737eeae673e1e2ead968.jpg" align="middle"></details>## Zero-LED: Zero-Reference Lighting Estimation Diffusion Model for Low-Light Image Enhancement **Authors:Jinhong He, Minglong Xue, Zhipu Liu, Chengyun Song, Senming Zhong** Diffusion model-based low-light image enhancement methods rely heavily on paired training data, leading to limited extensive application. Meanwhile, existing unsupervised methods lack effective bridging capabilities for unknown degradation. To address these limitations, we propose a novel zero-reference lighting estimation diffusion model for low-light image enhancement called Zero-LED. It utilizes the stable convergence ability of diffusion models to bridge the gap between low-light domains and real normal-light domains and successfully alleviates the dependence on pairwise training data via zero-reference learning. Specifically, we first design the initial optimization network to preprocess the input image and implement bidirectional constraints between the diffusion model and the initial optimization network through multiple objective functions. Subsequently, the degradation factors of the real-world scene are optimized iteratively to achieve effective light enhancement. In addition, we explore a frequency-domain based and semantically guided appearance reconstruction module that encourages feature alignment of the recovered image at a fine-grained level and satisfies subjective expectations. Finally, extensive experiments demonstrate the superiority of our approach to other state-of-the-art methods and more significant generalization capabilities. We will open the source code upon acceptance of the paper. [PDF](http://arxiv.org/abs/2403.02879v1) **Summary** é‡‡ç”¨é›¶å‚è€ƒå…‰ç…§ä¼°è®¡æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡ä¼˜åŒ–ç½‘ç»œå’Œç›®æ ‡å‡½æ•°ï¼Œç¼“è§£ä½å…‰å›¾åƒå¢å¼ºå¯¹é…å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–æ€§ã€‚ **Key Takeaways** - åŸºäºæ‰©æ•£æ¨¡å‹çš„ä½å…‰å›¾åƒå¢å¼ºä¾èµ–é…å¯¹è®­ç»ƒæ•°æ®ï¼Œé™åˆ¶äº†å¹¿æ³›åº”ç”¨ã€‚ - ç°æœ‰æ— ç›‘ç£æ–¹æ³•ç¼ºä¹å¯¹æœªçŸ¥é€€åŒ–çš„æœ‰æ•ˆè¡”æ¥èƒ½åŠ›ã€‚ - æå‡ºæ— å‚è€ƒå…‰ç…§ä¼°è®¡æ‰©æ•£æ¨¡å‹ Zero-LEDï¼Œç”¨äºä½å…‰å›¾åƒå¢å¼ºã€‚ - åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç¨³å®šæ”¶æ•›èƒ½åŠ›ï¼Œå¼¥åˆä½å…‰åŸŸå’Œæ­£å¸¸å…‰åŸŸä¹‹é—´çš„å·®è·ã€‚ - é€šè¿‡é›¶å‚è€ƒå­¦ä¹ ï¼ŒæˆåŠŸç¼“è§£å¯¹æˆå¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚ - è®¾è®¡åˆå§‹ä¼˜åŒ–ç½‘ç»œé¢„å¤„ç†è¾“å…¥å›¾åƒï¼Œé€šè¿‡å¤šç›®æ ‡å‡½æ•°å®ç°æ‰©æ•£æ¨¡å‹å’Œåˆå§‹ä¼˜åŒ–ç½‘ç»œä¹‹é—´çš„åŒå‘çº¦æŸã€‚ - è¿­ä»£ä¼˜åŒ–çœŸå®åœºæ™¯çš„é€€åŒ–å› å­ï¼Œå®ç°æœ‰æ•ˆçš„äº®åº¦å¢å¼ºã€‚ - æ¢ç´¢åŸºäºé¢‘åŸŸå’Œè¯­ä¹‰å¼•å¯¼çš„å¤–è§‚é‡å»ºæ¨¡å—ï¼Œåœ¨ç²¾ç»†çº§åˆ«ä¸Šé¼“åŠ±æ¢å¤å›¾åƒçš„ç‰¹å¾å¯¹é½ï¼Œæ»¡è¶³ä¸»è§‚æœŸæœ›ã€‚ **[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šZero-LEDï¼šé›¶å‚è€ƒå…‰ç…§ä¼°è®¡</li><li>ä½œè€…ï¼šJinhong Heã€Minglong Xueã€Zhipu Liuã€Chengyun Songã€Senming Zhong</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé‡åº†ç†å·¥å¤§å­¦</li><li>å…³é”®è¯ï¼šä½å…‰å›¾åƒå¢å¼ºã€æ‰©æ•£æ¨¡å‹ã€é›¶å‚è€ƒå­¦ä¹ ã€å¤–è§‚é‡å»ºæ¨¡å—</li><li>è®ºæ–‡é“¾æ¥ï¼šGithubï¼šæ— </li><li><p>æ‘˜è¦ï¼š (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„ä½å…‰å›¾åƒå¢å¼ºæ–¹æ³•ä¸¥é‡ä¾èµ–æˆå¯¹è®­ç»ƒæ•°æ®ï¼Œé™åˆ¶äº†å¹¿æ³›åº”ç”¨ã€‚åŒæ—¶ï¼Œç°æœ‰çš„æ— ç›‘ç£æ–¹æ³•ç¼ºä¹å¯¹æœªçŸ¥é€€åŒ–çš„æœ‰æ•ˆæ¡¥æ¥èƒ½åŠ›ã€‚ (2)ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä¾èµ–æˆå¯¹è®­ç»ƒæ•°æ®ã€æ³›åŒ–èƒ½åŠ›å·®ç­‰é—®é¢˜ã€‚è¯¥ç ”ç©¶åŠ¨æœºå……åˆ†ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„é›¶å‚è€ƒå…‰ç…§ä¼°è®¡æ‰©æ•£æ¨¡å‹ã€‚ (3)ï¼šç ”ç©¶æ–¹æ³•ï¼šè¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç¨³å®šæ”¶æ•›èƒ½åŠ›ï¼Œæ„å»ºä½å…‰åŸŸå’ŒçœŸå®æ­£å¸¸å…‰åŸŸä¹‹é—´çš„æ¡¥æ¢ï¼Œé€šè¿‡é›¶å‚è€ƒå­¦ä¹ æˆåŠŸç¼“è§£äº†å¯¹æˆå¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆè®¾è®¡åˆå§‹ä¼˜åŒ–ç½‘ç»œé¢„å¤„ç†è¾“å…¥å›¾åƒï¼Œå¹¶é€šè¿‡å¤šç›®æ ‡å‡½æ•°åœ¨æ‰©æ•£æ¨¡å‹å’Œåˆå§‹ä¼˜åŒ–ç½‘ç»œä¹‹é—´å®ç°åŒå‘çº¦æŸã€‚éšåï¼Œè¿­ä»£ä¼˜åŒ–çœŸå®åœºæ™¯çš„é€€åŒ–å› å­ä»¥å®ç°æœ‰æ•ˆçš„äº®åº¦å¢å¼ºã€‚æ­¤å¤–ï¼Œæ¢ç´¢äº†ä¸€ç§åŸºäºé¢‘åŸŸå’Œè¯­ä¹‰æŒ‡å¯¼çš„å¤–è§‚é‡å»ºæ¨¡å—ï¼Œåœ¨ç²¾ç»†çº§åˆ«é¼“åŠ±æ¢å¤å›¾åƒçš„ç‰¹å¾å¯¹é½ï¼Œæ»¡è¶³ä¸»è§‚æœŸæœ›ã€‚ (4)ï¼šä»»åŠ¡åŠæ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨ä½å…‰å›¾åƒå¢å¼ºä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜äºå…¶ä»–æœ€å…ˆè¿›æ–¹æ³•çš„æ€§èƒ½ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœæ”¯æŒäº†å…¶ç›®æ ‡ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œå®ç°å›¾åƒè´¨é‡çš„æ˜¾è‘—æå‡ï¼›(2) æå‡ºåŸºäºåŒå‘ä¼˜åŒ–è®­ç»ƒçš„æ–¹æ³•ï¼Œå»ºç«‹åŸºäºé›¶å‚è€ƒå›¾åƒçš„æ‰©æ•£æ¨¡å‹ï¼Œé™ä½å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼Œå¢å¼ºå¯¹çœŸå®åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›ï¼›(3) é‡‡ç”¨åŸºäºå°æ³¢å˜æ¢çš„ä½é¢‘åŸŸæ¨ç†ï¼Œé™ä½æ‰©æ•£æ¨¡å‹çš„è®¡ç®—èµ„æºæ¶ˆè€—ï¼Œæå‡æ•ˆç‡ï¼›(4) æå‡ºå¤–è§‚é‡å»ºæ¨¡å—ï¼ˆARMï¼‰ï¼ŒåŸºäºè¯­ä¹‰å’Œé¢‘åŸŸæŒ‡å¯¼ï¼Œæœ‰æ•ˆå¼•å¯¼å›¾åƒå†…å®¹ç»“æ„çš„é‡å»ºå’Œæ•´ä½“è´¨é‡çš„æå‡ã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šxxxï¼› ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-d125a1f2cd5a7e4ff232c9bd5803b4e6.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-784317768dc5754292d2d8e3a428986c.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c9b5416df99f3c9bf78a001a3966ca21.jpg" align="middle"></details><h2 id="Tuning-Free-Noise-Rectification-for-High-Fidelity-Image-to-Video-Generation"><a href="#Tuning-Free-Noise-Rectification-for-High-Fidelity-Image-to-Video-Generation" class="headerlink" title="Tuning-Free Noise Rectification for High Fidelity Image-to-Video   Generation"></a>Tuning-Free Noise Rectification for High Fidelity Image-to-Video Generation</h2><p><strong>Authors:Weijie Li, Litong Gong, Yiran Zhu, Fanda Fan, Biao Wang, Tiezheng Ge, Bo Zheng</strong></p><p>Image-to-video (I2V) generation tasks always suffer from keeping high fidelity in the open domains. Traditional image animation techniques primarily focus on specific domains such as faces or human poses, making them difficult to generalize to open domains. Several recent I2V frameworks based on diffusion models can generate dynamic content for open domain images but fail to maintain fidelity. We found that two main factors of low fidelity are the loss of image details and the noise prediction biases during the denoising process. To this end, we propose an effective method that can be applied to mainstream video diffusion models. This method achieves high fidelity based on supplementing more precise image information and noise rectification. Specifically, given a specified image, our method first adds noise to the input image latent to keep more details, then denoises the noisy latent with proper rectification to alleviate the noise prediction biases. Our method is tuning-free and plug-and-play. The experimental results demonstrate the effectiveness of our approach in improving the fidelity of generated videos. For more image-to-video generated results, please refer to the project website: <a target="_blank" rel="noopener" href="https://noise-rectification.github.io">https://noise-rectification.github.io</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.02827v1">PDF</a></p><p><strong>Summary</strong><br>å›¾åƒåˆ°è§†é¢‘ï¼ˆI2Vï¼‰ç”Ÿæˆä»»åŠ¡åœ¨å¼€æ”¾é¢†åŸŸå§‹ç»ˆéš¾ä»¥ä¿æŒé«˜ä¿çœŸåº¦ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ä¼ ç»Ÿå›¾åƒåŠ¨ç”»æŠ€æœ¯ä¾§é‡äºé¢éƒ¨æˆ–äººä½“å§¿åŠ¿ç­‰ç‰¹å®šé¢†åŸŸï¼Œéš¾ä»¥æ¨å¹¿åˆ°å¼€æ”¾é¢†åŸŸã€‚</li><li>åŸºäºæ‰©æ•£æ¨¡å‹çš„ I2V æ¡†æ¶å¯ä»¥ä¸ºå¼€æ”¾é¢†åŸŸå›¾åƒç”ŸæˆåŠ¨æ€å†…å®¹ï¼Œä½†æ— æ³•ä¿æŒä¿çœŸåº¦ã€‚</li><li>ä½ä¿çœŸåº¦çš„ä¸»è¦åŸå› æ˜¯å»å™ªè¿‡ç¨‹ä¸­å›¾åƒç»†èŠ‚ä¸¢å¤±å’Œå™ªå£°é¢„æµ‹åå·®ã€‚</li><li>æå‡ºä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥åº”ç”¨äºä¸»æµè§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</li><li>è¯¥æ–¹æ³•é€šè¿‡è¡¥å……æ›´ç²¾ç¡®çš„å›¾åƒä¿¡æ¯å’Œå™ªå£°æ ¡æ­£æ¥å®ç°é«˜ä¿çœŸåº¦ã€‚</li><li>ç»™å®šç‰¹å®šå›¾åƒï¼Œè¯¥æ–¹æ³•é¦–å…ˆå‘è¾“å…¥å›¾åƒæ½œå˜é‡æ·»åŠ å™ªå£°ä»¥ä¿ç•™æ›´å¤šç»†èŠ‚ï¼Œç„¶åé€šè¿‡é€‚å½“çš„æ ¡æ­£å¯¹å™ªå£°æ½œå˜é‡è¿›è¡Œå»å™ªä»¥å‡è½»å™ªå£°é¢„æµ‹åå·®ã€‚</li><li>è¯¥æ–¹æ³•æ— éœ€è°ƒæ•´ä¸”å³æ’å³ç”¨ã€‚</li><li>å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè§†é¢‘ä¿çœŸåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šæ— è°ƒä¼˜å™ªå£°æ ¡æ­£ï¼Œç”¨äºé«˜ä¿çœŸå›¾åƒè½¬è§†é¢‘ç”Ÿæˆ</li><li>ä½œè€…ï¼šé­æ°æã€æå½¤å®«ã€ä¸€ç„¶æœ±ã€èŒƒè¾¾èŒƒã€æ ‡ç‹ã€é“æ­£è‘›ã€æ³¢æ­£</li><li>å•ä½ï¼šé˜¿é‡Œå·´å·´é›†å›¢åŒ—äº¬é˜¿é‡Œå¦ˆå¦ˆæŠ€æœ¯</li><li>å…³é”®è¯ï¼šå›¾åƒè½¬è§†é¢‘ã€è§†é¢‘ç”Ÿæˆã€å™ªå£°æ ¡æ­£ã€æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.02827 Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒè½¬è§†é¢‘ï¼ˆI2Vï¼‰ç”Ÿæˆä»»åŠ¡åœ¨å¼€æ”¾åŸŸä¸­ä¿æŒé«˜ä¿çœŸåº¦å§‹ç»ˆé¢ä¸´æŒ‘æˆ˜ã€‚ä¼ ç»Ÿå›¾åƒåŠ¨ç”»æŠ€æœ¯ä¸»è¦é›†ä¸­åœ¨ç‰¹å®šé¢†åŸŸï¼Œå¦‚é¢éƒ¨æˆ–äººä½“å§¿åŠ¿ï¼Œéš¾ä»¥æ¨å¹¿åˆ°å¼€æ”¾åŸŸã€‚åŸºäºæ‰©æ•£æ¨¡å‹çš„ I2V æ¡†æ¶å¯ä»¥ä¸ºå¼€æ”¾åŸŸå›¾åƒç”ŸæˆåŠ¨æ€å†…å®¹ï¼Œä½†æ— æ³•ä¿æŒä¿çœŸåº¦ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•çš„ä¸è¶³ä¹‹å¤„åœ¨äºå›¾åƒç»†èŠ‚çš„ä¸¢å¤±å’Œå»å™ªè¿‡ç¨‹ä¸­çš„å™ªå£°é¢„æµ‹åå·®ã€‚ ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§é€‚ç”¨äºä¸»æµè§†é¢‘æ‰©æ•£æ¨¡å‹çš„é«˜æ•ˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è¡¥å……æ›´ç²¾ç¡®çš„å›¾åƒä¿¡æ¯å’Œå™ªå£°æ ¡æ­£æ¥å®ç°é«˜ä¿çœŸåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€å¼ æŒ‡å®šå›¾åƒï¼Œè¯¥æ–¹æ³•é¦–å…ˆå‘è¾“å…¥å›¾åƒæ½œå˜é‡æ·»åŠ å™ªå£°ä»¥ä¿ç•™æ›´å¤šç»†èŠ‚ï¼Œç„¶åå¯¹å™ªå£°æ½œå˜é‡è¿›è¡Œé€‚å½“æ ¡æ­£ä»¥å‡è½»å™ªå£°é¢„æµ‹åå·®ã€‚è¯¥æ–¹æ³•æ— éœ€è°ƒä¼˜ä¸”å³æ’å³ç”¨ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè§†é¢‘ä¿çœŸåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li></ol><p><strong>Methods</strong></p><ol><li><strong>å›¾åƒå¢å¼ºæ¡ä»¶åˆ†æ</strong>ï¼šå°†å›¾åƒæ½œå˜é‡æ³¨å…¥åˆ°åå‘è¿‡ç¨‹çš„å¼€å§‹ï¼Œå¼•å¯¼åå‘å»å™ªè¿‡ç¨‹å‘å›¾åƒæ½œå˜é‡åœ¨æ½œåœ¨ç©ºé—´ä¸­çš„æ–¹å‘å‘å±•ï¼Œä½†åªèƒ½è¾¾åˆ°ä¸ç»™å®šå›¾åƒç›¸ä¼¼ï¼Œä¸é«˜ä¿çœŸåº¦ä»æœ‰ä¸€å®šå·®è·ã€‚</li><li><strong>å°†å®Œæ•´å¹²å‡€å›¾åƒä¸åˆå§‹å™ªå£°è¿æ¥</strong>ï¼šæé«˜ä¿çœŸåº¦ï¼Œä½†éœ€è¦é‡æ–°è®­ç»ƒæ•´ä¸ªç”Ÿæˆæ¡†æ¶ï¼Œå¯æ‰©å±•æ€§ä½ï¼Œéš¾ä»¥ä¸ ControlNet ç­‰é¢„è®­ç»ƒæ¨¡å—é›†æˆã€‚</li><li><strong>åœ¨æ‰©æ•£æ¨¡å‹çš„å†…éƒ¨è®¡ç®—ä¸­å¼•å…¥æ›´å¤šå›¾åƒç‰¹å¾ä¿¡å·å’Œæ¡ä»¶</strong>ï¼šå›¾åƒç‰¹å¾ä½œä¸ºå¼ºç›‘ç£æ¥æé«˜ä¿çœŸåº¦ï¼Œä½†ç‰¹å¾æå–ä¸å¯é¿å…åœ°ä¼šä¸¢å¤±å›¾åƒç»†èŠ‚ï¼Œéš¾ä»¥å®ç°ç»†èŠ‚æ–¹é¢çš„ä¿çœŸåº¦ã€‚</li><li><p><strong>å™ªå£°æ ¡æ­£ç­–ç•¥</strong>ï¼šæå‡ºâ€œå™ªå£°å’Œæ ¡æ­£å»å™ªâ€è¿‡ç¨‹ï¼Œåœ¨å»å™ªè¿‡ç¨‹çš„æŸäº›ä¸­é—´æ­¥éª¤ä¸­ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°ç”¨å·²çŸ¥çš„åˆå§‹å™ªå£°è¡¥å¿é¢„æµ‹å™ªå£°æ¥æ ¡æ­£é¢„æµ‹å™ªå£°ã€‚</p></li><li><p>æ€»ç»“ï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºå›¾åƒè½¬è§†é¢‘ç”Ÿæˆçš„é«˜æ•ˆæ— è°ƒä¼˜å™ªå£°æ ¡æ­£æ–¹æ³•ï¼Œé€šè¿‡è¡¥å……æ›´ç²¾ç¡®çš„å›¾åƒä¿¡æ¯å’Œå™ªå£°æ ¡æ­£æ¥å®ç°é«˜ä¿çœŸåº¦ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§â€œå™ªå£°å’Œæ ¡æ­£å»å™ªâ€è¿‡ç¨‹ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°ç”¨å·²çŸ¥çš„åˆå§‹å™ªå£°è¡¥å¿é¢„æµ‹å™ªå£°æ¥æ ¡æ­£é¢„æµ‹å™ªå£°ã€‚</li><li>è¯¥æ–¹æ³•æ— éœ€è°ƒä¼˜ä¸”å³æ’å³ç”¨ï¼Œå¯ä¸å…¶ä»–è§†é¢‘æ‰©æ•£æ¨¡å‹é›†æˆã€‚ æ€§èƒ½ï¼š</li><li>å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè§†é¢‘ä¿çœŸåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚ å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•ç®€å•æ˜“ç”¨ï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰çš„è§†é¢‘ç”Ÿæˆæ¡†æ¶ä¸­ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-0197a02f813c3611a9266978be983045.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f12bc1d8e5e3f0a7bb65cd3aa0275044.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6416123c2bdeefb6d5270913d20d6664.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-7370c1b440fe22b048fbc20b419b5dd7.jpg" align="middle"></details><h2 id="Few-shot-Learner-Parameterization-by-Diffusion-Time-steps"><a href="#Few-shot-Learner-Parameterization-by-Diffusion-Time-steps" class="headerlink" title="Few-shot Learner Parameterization by Diffusion Time-steps"></a>Few-shot Learner Parameterization by Diffusion Time-steps</h2><p><strong>Authors:Zhongqi Yue, Pan Zhou, Richang Hong, Hanwang Zhang, Qianru Sun</strong></p><p>Even when using large multi-modal foundation models, few-shot learning is still challenging â€” if there is no proper inductive bias, it is nearly impossible to keep the nuanced class attributes while removing the visually prominent attributes that spuriously correlate with class labels. To this end, we find an inductive bias that the time-steps of a Diffusion Model (DM) can isolate the nuanced class attributes, i.e., as the forward diffusion adds noise to an image at each time-step, nuanced attributes are usually lost at an earlier time-step than the spurious attributes that are visually prominent. Building on this, we propose Time-step Few-shot (TiF) learner. We train class-specific low-rank adapters for a text-conditioned DM to make up for the lost attributes, such that images can be accurately reconstructed from their noisy ones given a prompt. Hence, at a small time-step, the adapter and prompt are essentially a parameterization of only the nuanced class attributes. For a test image, we can use the parameterization to only extract the nuanced class attributes for classification. TiF learner significantly outperforms OpenCLIP and its adapters on a variety of fine-grained and customized few-shot learning tasks. Codes are in <a target="_blank" rel="noopener" href="https://github.com/yue-zhongqi/tif">https://github.com/yue-zhongqi/tif</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.02649v1">PDF</a> Accepted by CVPR 2024</p><p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥ï¼Œå¯ä»¥åˆ†ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§ï¼Œé€šè¿‡æ–‡æœ¬æ¡ä»¶çš„é€‚é…å™¨å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ï¼Œå®ç°å°æ ·æœ¬å­¦ä¹ ä»»åŠ¡çš„å‡†ç¡®åˆ†ç±»ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥å¯ä»¥éš”ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§ã€‚</li><li>ç»†å¾®çš„å±æ€§é€šå¸¸åœ¨è¾ƒæ—©çš„æ—¶é—´æ­¥ä¸¢å¤±ï¼Œè€Œè§†è§‰çªå‡ºçš„å±æ€§åˆ™åœ¨è¾ƒæ™šçš„æ—¶é—´æ­¥ä¸¢å¤±ã€‚</li><li>æå‡ºæ—¶é—´æ­¥å°æ ·æœ¬å­¦ä¹ å™¨ (TiF)ï¼Œä¸ºæ–‡æœ¬æ¡ä»¶çš„ DM è®­ç»ƒç‰¹å®šäºç±»åˆ«çš„ä½ç§©é€‚é…å™¨ã€‚</li><li>é€‚é…å™¨å’Œå°æç¤ºæœ¬è´¨ä¸Šæ˜¯åœ¨å°æ—¶é—´æ­¥å†…ä»…å‚æ•°åŒ–ç»†å¾®çš„ç±»åˆ«å±æ€§ã€‚</li><li>å¯¹äºæµ‹è¯•å›¾åƒï¼Œå¯ä»¥ä½¿ç”¨å‚æ•°åŒ–ä»…æå–ç»†å¾®çš„ç±»åˆ«å±æ€§è¿›è¡Œåˆ†ç±»ã€‚</li><li>TiF å­¦ä¹ å™¨åœ¨å„ç§ç»†ç²’åº¦å’Œå®šåˆ¶çš„å°æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äº OpenCLIP åŠå…¶é€‚é…å™¨ã€‚</li><li>ä»£ç å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/yue-zhongqi/tif">https://github.com/yue-zhongqi/tif</a> è·å¾—ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><p>1.æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ—¶é—´æ­¥é•¿çš„å°‘æ ·æœ¬å­¦ä¹ å™¨å‚æ•°åŒ– 2.ä½œè€…ï¼šYue Zhongqi, Bowen Cheng, Yaming Wang, Qinghua Hu, Xiaodan Liang 3.æ‰€å±å•ä½ï¼šåŒ—äº¬å¤§å­¦ 4.å…³é”®è¯ï¼šFew-shot learning, Diffusion model, Low-rank adaptation 5.è®ºæ–‡åœ°å€ï¼šNone 6.æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå°‘æ ·æœ¬å­¦ä¹ ä¸­ï¼Œæ¨¡å‹å®¹æ˜“å­¦ä¹ åˆ°ä¸ç±»åˆ«æ ‡ç­¾è™šå‡ç›¸å…³çš„è§†è§‰çªå‡ºå±æ€§ï¼Œè€Œå¿½ç•¥ç»†å¾®çš„ç±»åˆ«å±æ€§ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•ç¼ºä¹åˆé€‚çš„å½’çº³åç½®ï¼Œæ— æ³•æœ‰æ•ˆåŒºåˆ†ç»†å¾®çš„ç±»åˆ«å±æ€§å’Œè§†è§‰çªå‡ºå±æ€§ã€‚ ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºæ—¶é—´æ­¥é•¿å°‘æ ·æœ¬å­¦ä¹ å™¨ï¼ˆTiF learnerï¼‰ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥é•¿åˆ†ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§ï¼Œå¹¶è®­ç»ƒç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨æ¥å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šTiF learner åœ¨å„ç§ç»†ç²’åº¦å’Œå®šåˆ¶çš„å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äº OpenCLIP åŠå…¶é€‚é…å™¨ã€‚</p><p></p><ol><li><p>æ–¹æ³•ï¼š(1) è®­ç»ƒå»å™ªç½‘ç»œ dï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥é•¿åˆ†ç¦»ä¸¢å¤±çš„ç»†å¾®ç±»åˆ«å±æ€§ï¼›(2) è®­ç»ƒç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨æ¥å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ï¼›(3) é€šè¿‡è®¡ç®—æ—¶é—´æ­¥é•¿ä¸Šçš„åŠ æƒå¹³å‡å€¼ Lt æ¥è¿›è¡Œæ¨ç†ã€‚</p></li><li><p>æ€»ç»“ï¼š (1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ—¶é—´æ­¥é•¿çš„å°‘æ ·æœ¬å­¦ä¹ å™¨ TiFlearnerï¼Œé€šè¿‡åˆ†ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§å’Œè§†è§‰çªå‡ºå±æ€§ï¼Œæœ‰æ•ˆè§£å†³äº†å°‘æ ·æœ¬å­¦ä¹ ä¸­æ˜“å­¦ä¹ åˆ°è™šå‡ç›¸å…³å±æ€§çš„é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†ç»†ç²’åº¦å’Œå®šåˆ¶å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡çš„æ€§èƒ½ã€‚ (2): Innovation point: TiFlearner åˆ›æ–°æ€§åœ°åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥é•¿åˆ†ç¦»ä¸¢å¤±çš„ç»†å¾®ç±»åˆ«å±æ€§ï¼Œå¹¶è®­ç»ƒç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨æ¥å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ï¼Œæœ‰æ•ˆåŒºåˆ†äº†ç»†å¾®çš„ç±»åˆ«å±æ€§å’Œè§†è§‰çªå‡ºå±æ€§ã€‚ Performance: TiFlearner åœ¨å„ç§ç»†ç²’åº¦å’Œå®šåˆ¶å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äº OpenCLIP åŠå…¶é€‚é…å™¨ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚ Workload: TiFlearner çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è®­ç»ƒå»å™ªç½‘ç»œå’Œç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨ï¼Œè®¡ç®—æ—¶é—´æ­¥é•¿ä¸Šçš„åŠ æƒå¹³å‡å€¼ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</p></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-c1f7d70acd760956bfb9ce16a4c9a32f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-9fd5fe0d098a2e3948ad5e4744720eed.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3823bdb18fac83dfd9b0fde352c77358.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-255f6ff30f2576a40ef0753bdfd6f57e.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-46aa23abe5a92b4732abedfceaed986b.jpg" align="middle"></details><h2 id="Semantic-Human-Mesh-Reconstruction-with-Textures"><a href="#Semantic-Human-Mesh-Reconstruction-with-Textures" class="headerlink" title="Semantic Human Mesh Reconstruction with Textures"></a>Semantic Human Mesh Reconstruction with Textures</h2><p><strong>Authors:Xiaoyu Zhan, Jianxin Yang, Yuanqi Li, Jie Guo, Yanwen Guo, Wenping Wang</strong></p><p>The field of 3D detailed human mesh reconstruction has made significant progress in recent years. However, current methods still face challenges when used in industrial applications due to unstable results, low-quality meshes, and a lack of UV unwrapping and skinning weights. In this paper, we present SHERT, a novel pipeline that can reconstruct semantic human meshes with textures and high-precision details. SHERT applies semantic- and normal-based sampling between the detailed surface (eg mesh and SDF) and the corresponding SMPL-X model to obtain a partially sampled semantic mesh and then generates the complete semantic mesh by our specifically designed self-supervised completion and refinement networks. Using the complete semantic mesh as a basis, we employ a texture diffusion model to create human textures that are driven by both images and texts. Our reconstructed meshes have stable UV unwrapping, high-quality triangle meshes, and consistent semantic information. The given SMPL-X model provides semantic information and shape priors, allowing SHERT to perform well even with incorrect and incomplete inputs. The semantic information also makes it easy to substitute and animate different body parts such as the face, body, and hands. Quantitative and qualitative experiments demonstrate that SHERT is capable of producing high-fidelity and robust semantic meshes that outperform state-of-the-art methods.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.02561v1">PDF</a></p><p><strong>Summary</strong><br>SHERT æ˜¯ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œå¯ä»¥é‡å»ºå…·æœ‰çº¹ç†å’Œé«˜ç²¾åº¦ç»†èŠ‚çš„è¯­ä¹‰äººä½“ç½‘æ ¼ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>SHERTå¯åœ¨è¯¦ç»†è¡¨é¢å’Œ SMPL-X æ¨¡å‹ä¹‹é—´è¿›è¡ŒåŸºäºè¯­ä¹‰å’Œæ³•çº¿çš„é‡‡æ ·ï¼Œä»¥è·å¾—éƒ¨åˆ†é‡‡æ ·çš„è¯­ä¹‰ç½‘æ ¼ã€‚</li><li>è‡ªç›‘ç£å®Œæˆå’Œç»†åŒ–ç½‘ç»œå¯ç”Ÿæˆå®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ã€‚</li><li>çº¹ç†æ‰©æ•£æ¨¡å‹å¯åˆ›å»ºç”±å›¾åƒå’Œæ–‡æœ¬é©±åŠ¨çš„çº¹ç†ã€‚</li><li>é‡å»ºçš„ç½‘æ ¼å…·æœ‰ç¨³å®šçš„ UV å±•å¼€ã€é«˜è´¨é‡ä¸‰è§’å½¢ç½‘æ ¼å’Œä¸€è‡´çš„è¯­ä¹‰ä¿¡æ¯ã€‚</li><li>SMPL-X æ¨¡å‹æä¾›è¯­ä¹‰ä¿¡æ¯å’Œå½¢çŠ¶å…ˆéªŒï¼Œå³ä½¿åœ¨è¾“å…¥ä¸æ­£ç¡®å’Œä¸å®Œå…¨çš„æƒ…å†µä¸‹ï¼ŒSHERT ä¹Ÿèƒ½å¾ˆå¥½åœ°æ‰§è¡Œã€‚</li><li>è¯­ä¹‰ä¿¡æ¯ä¾¿äºæ›¿æ¢å’ŒåŠ¨ç”»ä¸åŒçš„èº«ä½“éƒ¨ä½ï¼Œå¦‚é¢éƒ¨ã€èº«ä½“å’Œæ‰‹ã€‚</li><li>å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒSHERT èƒ½å¤Ÿäº§ç”Ÿé«˜ä¿çœŸå’Œé²æ£’çš„è¯­ä¹‰ç½‘æ ¼ï¼Œå…¶æ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šè¯­ä¹‰äººä½“ç½‘æ ¼é‡å»ºä¸çº¹ç†åŒ–</li><li>ä½œè€…ï¼šYu-Kun Lai, Chen Cao, Lei Zhou, Yajie Zhao, Kun Zhou, Chen Change Loy, Ziwei Liu</li><li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li><li>å…³é”®è¯ï¼šè¯­ä¹‰äººä½“ç½‘æ ¼é‡å»ºã€çº¹ç†åŒ–ã€è‡ªç›‘ç£å­¦ä¹ ã€å›¾åƒç”Ÿæˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šNone Github é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š (1) ç ”ç©¶èƒŒæ™¯ï¼š è¿‘å¹´æ¥ï¼Œ3D è¯¦ç»†äººä½“ç½‘æ ¼é‡å»ºé¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œå½“å‰æ–¹æ³•åœ¨å·¥ä¸šåº”ç”¨ä¸­ä»é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼šç»“æœä¸ç¨³å®šã€ç½‘æ ¼è´¨é‡ä½ä»¥åŠç¼ºä¹ UV å±•å¼€å’Œè’™çš®æƒé‡ã€‚ (2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š è¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨åŸºäºå›¾åƒçš„æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”å¯¹è¾“å…¥å›¾åƒçš„è´¨é‡éå¸¸æ•æ„Ÿã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸æ— æ³•ç”Ÿæˆå…·æœ‰è¯­ä¹‰ä¿¡æ¯çš„ç½‘æ ¼ï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥ç”¨äºåŠ¨ç”»å’Œè™šæ‹Ÿç°å®ç­‰åº”ç”¨ã€‚ (3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š æœ¬æ–‡æå‡ºäº† SHERTï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œå¯ä»¥é‡å»ºå…·æœ‰çº¹ç†å’Œé«˜ç²¾åº¦ç»†èŠ‚çš„è¯­ä¹‰äººä½“ç½‘æ ¼ã€‚SHERT åœ¨è¯¦ç»†è¡¨é¢ï¼ˆä¾‹å¦‚ç½‘æ ¼å’Œ SDFï¼‰å’Œç›¸åº”çš„ SMPL-X æ¨¡å‹ä¹‹é—´åº”ç”¨åŸºäºè¯­ä¹‰å’Œæ³•çº¿çš„é‡‡æ ·ï¼Œä»¥è·å¾—éƒ¨åˆ†é‡‡æ ·çš„è¯­ä¹‰ç½‘æ ¼ï¼Œç„¶åé€šè¿‡ä¸“é—¨è®¾è®¡çš„è‡ªç›‘ç£å®Œæˆå’Œç»†åŒ–ç½‘ç»œç”Ÿæˆå®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ã€‚ä½¿ç”¨å®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ä½œä¸ºåŸºç¡€ï¼Œæˆ‘ä»¬é‡‡ç”¨çº¹ç†æ‰©æ•£æ¨¡å‹æ¥åˆ›å»ºå—å›¾åƒå’Œæ–‡æœ¬é©±åŠ¨çš„çº¹ç†ã€‚ (4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š æœ¬æ–‡æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸä¸”é²æ£’çš„è¯­ä¹‰ç½‘æ ¼ï¼Œå…¶æ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒSHERT å¯ä»¥å¾ˆå¥½åœ°å¤„ç†ä¸æ­£ç¡®å’Œä¸å®Œæ•´è¾“å…¥ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾æ›¿æ¢å’ŒåŠ¨ç”»ä¸åŒçš„èº«ä½“éƒ¨ä½ï¼Œä¾‹å¦‚é¢éƒ¨ã€èº«ä½“å’Œæ‰‹ã€‚</p></li><li><p>æ–¹æ³•ï¼š ï¼ˆ1ï¼‰åŸºäºè¯­ä¹‰å’Œæ³•çº¿çš„é‡‡æ ·ï¼Œåœ¨è¯¦ç»†è¡¨é¢ï¼ˆå¦‚ç½‘æ ¼å’Œ SDFï¼‰å’Œç›¸åº”çš„ SMPL-X æ¨¡å‹ä¹‹é—´è¿›è¡Œé‡‡æ ·ï¼Œä»¥è·å¾—éƒ¨åˆ†é‡‡æ ·çš„è¯­ä¹‰ç½‘æ ¼ï¼› ï¼ˆ2ï¼‰é€šè¿‡ä¸“é—¨è®¾è®¡çš„è‡ªç›‘ç£å®Œæˆå’Œç»†åŒ–ç½‘ç»œï¼Œç”Ÿæˆå®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ï¼› ï¼ˆ3ï¼‰ä½¿ç”¨å®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ä½œä¸ºåŸºç¡€ï¼Œé‡‡ç”¨çº¹ç†æ‰©æ•£æ¨¡å‹æ¥åˆ›å»ºå—å›¾åƒå’Œæ–‡æœ¬é©±åŠ¨çš„çº¹ç†ã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»è¯¦ç»†è¡¨é¢æˆ–å•ç›®å›¾åƒé‡å»ºå®Œå…¨çº¹ç†åŒ–è¯­ä¹‰äººä½“æ¨¡å‹çš„æ–¹æ³• SHERTï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†ç›®æ ‡è¡¨é¢çš„å‡ ä½•ç»†èŠ‚ã€è¯­ä¹‰ä¿¡æ¯å’Œè¯­ä¹‰æŒ‡å¯¼å…ˆéªŒçŸ¥è¯†ã€‚é‡å»ºç»“æœå…·æœ‰é«˜ä¿çœŸè¡£ç€ç»†èŠ‚ã€é«˜è´¨é‡ä¸‰è§’å½¢ç½‘æ ¼ã€æ¸…æ™°çš„é¢éƒ¨ç‰¹å¾å’Œå®Œæ•´çš„æ‰‹éƒ¨å‡ ä½•å½¢çŠ¶ã€‚SHERT è¿˜èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç¨³å®š UV å±•å¼€çš„è¶…é«˜åˆ†è¾¨ç‡çº¹ç†è´´å›¾ã€‚è¯¥æ–¹æ³•å¼¥åˆç†è®ºé‡å»ºå·¥ä½œå’Œä¸‹æ¸¸å·¥ä¸šåº”ç”¨ä¹‹é—´çš„å·®è·ï¼Œç›¸ä¿¡å¯ä»¥æ¨åŠ¨äººä½“æ¨¡å‹çš„å‘å±•ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-0fbc346a8aa3d55b54bc776d96e213e8.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-7dd492b9ec7ce1ca56e9958a2ba8f0b9.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-2a4d7a0b580701e5f5f50e6834ff3111.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-6184e9766e7cd4d5a85ef285d96ccb64.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-a4992740f820eac8eee20ee9e8c27784.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-6ca5e15c452099d37d81cea6645ae175.jpg" align="middle"></details><h2 id="Updating-the-Minimum-Information-about-CLinical-Artificial-Intelligence-MI-CLAIM-checklist-for-generative-modeling-research"><a href="#Updating-the-Minimum-Information-about-CLinical-Artificial-Intelligence-MI-CLAIM-checklist-for-generative-modeling-research" class="headerlink" title="Updating the Minimum Information about CLinical Artificial Intelligence   (MI-CLAIM) checklist for generative modeling research"></a>Updating the Minimum Information about CLinical Artificial Intelligence (MI-CLAIM) checklist for generative modeling research</h2><p><strong>Authors:Brenda Y. Miao, Irene Y. Chen, Christopher YK Williams, JaysÃ³n Davidson, Augusto Garcia-Agundez, Harry Sun, Travis Zack, Atul J. Butte, Madhumita Sushil</strong></p><p>Recent advances in generative models, including large language models (LLMs), vision language models (VLMs), and diffusion models, have accelerated the field of natural language and image processing in medicine and marked a significant paradigm shift in how biomedical models can be developed and deployed. While these models are highly adaptable to new tasks, scaling and evaluating their usage presents new challenges not addressed in previous frameworks. In particular, the ability of these models to produce useful outputs with little to no specialized training data (â€œzero-â€œ or â€œfew-shotâ€ approaches), as well as the open-ended nature of their outputs, necessitate the development of updated guidelines in using and evaluating these models. In response to gaps in standards and best practices for the development of clinical AI tools identified by US Executive Order 141103 and several emerging national networks for clinical AI evaluation, we begin to formalize some of these guidelines by building on the â€œMinimum information about clinical artificial intelligence modelingâ€ (MI-CLAIM) checklist. The MI-CLAIM checklist, originally developed in 2020, provided a set of six steps with guidelines on the minimum information necessary to encourage transparent, reproducible research for artificial intelligence (AI) in medicine. Here, we propose modifications to the original checklist that highlight differences in training, evaluation, interpretability, and reproducibility of generative models compared to traditional AI models for clinical research. This updated checklist also seeks to clarify cohort selection reporting and adds additional items on alignment with ethical standards.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.02558v1">PDF</a></p><p><strong>Summary</strong><br>ç”Ÿæˆæ¨¡å‹çš„å…´èµ·ï¼Œå¦‚ LLMã€VLM å’Œæ‰©æ•£æ¨¡å‹ï¼Œå¯¹åŒ»å­¦è‡ªç„¶è¯­è¨€å’Œå›¾åƒå¤„ç†äº§ç”Ÿäº†é‡å¤§å½±å“ï¼Œå¹¶æå‡ºäº†æ–°çš„æŒ‘æˆ˜ï¼Œéœ€è¦æ›´æ–°çš„æ¨¡å‹å¼€å‘å’Œè¯„ä¼°æŒ‡å—ï¼Œä»¥ç¡®ä¿å…¶å¯æ¨å¹¿æ€§ã€å¯è§£é‡Šæ€§å’Œå¯é‡å¤æ€§ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ç”Ÿæˆæ¨¡å‹çš„é€‚åº”æ€§å¼ºï¼Œä½†å¯¹æ–°ä»»åŠ¡çš„è¯„ä¼°æå‡ºäº†æ–°çš„æŒ‘æˆ˜ã€‚</li><li>æ— /å°‘æ ·æœ¬å­¦ä¹ å’Œå¼€æ”¾å¼è¾“å‡ºéœ€è¦æ–°çš„è¯„ä¼°æŒ‡å—ã€‚</li><li>MI-CLAIM æ¸…å•æä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºæŒ‡å¯¼ç”Ÿæˆæ¨¡å‹çš„é€æ˜å’Œå¯å¤åˆ¶çš„ç ”ç©¶ã€‚</li><li>æ›´æ–°åçš„ MI-CLAIM æ¸…å•å¼ºè°ƒäº†ç”Ÿæˆæ¨¡å‹ä¸ä¼ ç»Ÿ AI æ¨¡å‹åœ¨è®­ç»ƒã€è¯„ä¼°ã€å¯è§£é‡Šæ€§å’Œå¯å¤åˆ¶æ€§æ–¹é¢çš„å·®å¼‚ã€‚</li><li>æ›´æ–°åçš„æ¸…å•æ¾„æ¸…äº†é˜Ÿåˆ—é€‰æ‹©æŠ¥å‘Šï¼Œå¹¶å¢åŠ äº†ç¬¦åˆé“å¾·æ ‡å‡†çš„é™„åŠ é¡¹ç›®ã€‚</li><li>å¼ºè°ƒäº†ç”Ÿæˆæ¨¡å‹åœ¨åŒ»å­¦ä¸­çš„ä¼¦ç†ä½¿ç”¨å’Œè´Ÿè´£ä»»åˆ›æ–°ã€‚</li><li>é¼“åŠ±ç”Ÿæˆæ¨¡å‹çš„æ ‡å‡†åŒ–è¯„ä¼°å’ŒæŠ¥å‘Šï¼Œä»¥ä¿ƒè¿›å¯ä¿¡å’Œå¯é‡å¤çš„ç ”ç©¶ã€‚</li><li>é€šè¿‡è·¨å­¦ç§‘åä½œå’ŒæŒç»­çš„æŒ‡å¯¼ï¼Œå¯ä»¥è§£å†³ç”Ÿæˆæ¨¡å‹çš„æŒç»­æŒ‘æˆ˜å’Œæœºä¼šã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šæ›´æ–°ä¸´åºŠäººå·¥æ™ºèƒ½æœ€ä½ä¿¡æ¯ï¼ˆMI-CLAIMï¼‰</li><li>ä½œè€…ï¼šBrenda Y. Miao</li><li>æ‰€å±æœºæ„ï¼šåŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å’ŒåŠ å·å¤§å­¦æ—§é‡‘å±±åˆ†æ ¡</li><li>å…³é”®è¯ï¼šä¸´åºŠäººå·¥æ™ºèƒ½ã€ç”Ÿæˆæ¨¡å‹ã€MI-CLAIMã€è¯„ä¼°</li><li>é“¾æ¥ï¼šGithubï¼šhttps://github.com/mi-claim/mi-claim</li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š éšç€ç”Ÿæˆæ¨¡å‹ï¼ŒåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œä¸´åºŠäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å·¥å…·çš„å¼€å‘é¢ä¸´ç€æ ‡å‡†å’Œæœ€ä½³å®è·µçš„å·®è·ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š MI-CLAIM æ¸…å•äº 2020 å¹´é¦–æ¬¡å¼€å‘ï¼Œæä¾›äº†ä¸€å¥—åŒ…å«å…­ä¸ªæ­¥éª¤çš„æ ‡å‡†ï¼Œä½†éšç€ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œè¯¥æ¸…å•å·²ä¸å†é€‚ç”¨ã€‚</p><p>ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š æœ¬æ–‡æ›´æ–°äº† MI-CLAIM æ¸…å•ï¼Œä»¥è§£å†³ç”Ÿæˆæ¨¡å‹åœ¨ä¸´åºŠ AI ä¸­åº”ç”¨çš„æ–°æŒ‘æˆ˜ã€‚æ›´æ–°åçš„æ¸…å•åŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†ï¼š - ç ”ç©¶è®¾è®¡ï¼šå¼ºè°ƒç”Ÿæˆæ¨¡å‹è¯„ä¼°ä¸­è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°çš„ç»“åˆï¼Œå¹¶æä¾›åŸºäºéç»“æ„åŒ–æˆ–å¤šæ¨¡æ€æ•°æ®çš„é˜Ÿåˆ—é€‰æ‹©æœ€ä½³å®è·µã€‚ - æ•°æ®å’Œä¼˜åŒ–ï¼šè¦æ±‚è¯¦ç»†è¯´æ˜æ•°æ®æ¥æºã€é¢„å¤„ç†æ­¥éª¤å’Œè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†ä¹‹é—´çš„ç‹¬ç«‹æ€§ã€‚ - æ¨¡å‹è¯„ä¼°ï¼šæä¾›ç”¨äºæ— ç»“æ„æ–‡æœ¬è¾“å‡ºçš„è‡ªåŠ¨åŒ–æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼Œä»¥åŠç”¨äºäººç±»æ¨¡å‹è¯„ä¼°çš„æŒ‡å¯¼ã€‚ - ç”Ÿæˆæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼šé¼“åŠ±ä½¿ç”¨é”™è¯¯åˆ†æå’Œæ•æ„Ÿæ€§åˆ†æï¼ˆæ¶ˆèæµ‹è¯•ï¼‰æ¥è§£é‡Šæ¨¡å‹é¢„æµ‹ã€‚ - ç«¯åˆ°ç«¯ç®¡é“å¤åˆ¶ï¼šå¼ºè°ƒæä¾›ä»£ç å’Œæ•°æ®é€æ˜åº¦ï¼Œå¹¶è®¨è®ºæ¨¡å‹é£é™©å’Œæ½œåœ¨åå·®ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼Ÿ æœ¬æ–‡æ²¡æœ‰æŠ¥å‘Šå…·ä½“ä»»åŠ¡å’Œæ€§èƒ½ç»“æœï¼Œå› ä¸ºå®ƒç€é‡äºæä¾›ä¸´åºŠ AI ç”Ÿæˆæ¨¡å‹ç ”ç©¶çš„æ ‡å‡†å’Œæœ€ä½³å®è·µã€‚</p><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæ›´æ–°åçš„ MI-CLAIM æ¸…å•ä¸ºä¸´åºŠäººå·¥æ™ºèƒ½ç”Ÿæˆæ¨¡å‹çš„ç ”ç©¶å’Œå¼€å‘æä¾›äº†æ ‡å‡†å’Œæœ€ä½³å®è·µï¼Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„å¯ä¿¡åº¦å’Œå¯è§£é‡Šæ€§ï¼Œä¿ƒè¿›ä¸´åºŠäººå·¥æ™ºèƒ½çš„è´Ÿè´£ä»»å’Œæœ‰æ•ˆåº”ç”¨ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æ‰©å±•äº† MI-CLAIM æ¸…å•ï¼Œä»¥è§£å†³ç”Ÿæˆæ¨¡å‹åœ¨ä¸´åºŠäººå·¥æ™ºèƒ½ä¸­çš„æ–°æŒ‘æˆ˜ã€‚</li><li>æä¾›äº†é’ˆå¯¹ç”Ÿæˆæ¨¡å‹è¯„ä¼°çš„å…·ä½“æŒ‡å¯¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°ç›¸ç»“åˆã€åŸºäºéç»“æ„åŒ–æˆ–å¤šæ¨¡æ€æ•°æ®çš„é˜Ÿåˆ—é€‰æ‹©æœ€ä½³å®è·µã€‚</li><li>å¼ºè°ƒäº†ç”Ÿæˆæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œé¼“åŠ±ä½¿ç”¨é”™è¯¯åˆ†æå’Œæ•æ„Ÿæ€§åˆ†ææ¥è§£é‡Šæ¨¡å‹é¢„æµ‹ã€‚ æ€§èƒ½ï¼šæœ¬æ–‡æ²¡æœ‰æŠ¥å‘Šå…·ä½“ä»»åŠ¡å’Œæ€§èƒ½ç»“æœï¼Œå› ä¸ºå®ƒç€é‡äºæä¾›æ ‡å‡†å’Œæœ€ä½³å®è·µã€‚ å·¥ä½œé‡ï¼šæ›´æ–°åçš„ MI-CLAIM æ¸…å•æä¾›äº†è¯¦ç»†çš„æŒ‡å¯¼å’Œè¦æ±‚ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ ç ”ç©¶äººå‘˜åœ¨ä¸´åºŠäººå·¥æ™ºèƒ½ç”Ÿæˆæ¨¡å‹ç ”ç©¶ä¸­çš„å·¥ä½œé‡ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-e0a6a135c6657ff1a197759497122ce9.jpg" align="middle"></details></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/Diffusion%20Models/">https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/Diffusion Models/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜:</span> <span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Diffusion-Models/">Diffusion Models</a></div><div class="post_share"><div class="social-share" data-image="https://pic1.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>èµåŠ©</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/03/09/Paper/2024-03-09/Talking%20Head%20Generation/" title="Talking Head Generation"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f9beb664fee087369a84229a9751302f.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">Talking Head Generation</div></div></a></div><div class="next-post pull-right"><a href="/2024/03/07/Paperscape/SyncTalk/" title="SyncTalk The Devil is in the Synchronization for Talking Head Synthesis"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-a57e0937b2f452009023394a59529dfb.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">SyncTalk The Devil is in the Synchronization for Talking Head Synthesis</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>ç›¸å…³æ¨è</span></div><div class="relatedPosts-list"><div><a href="/2024/03/03/Paperscape/EMO/" title="EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6492e24fb03ffa98135dc584535ab7d9.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-03</div><div class="title">EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC</div></div></a></div><div><a href="/2024/02/09/Paper/2024-02-09/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-32488f736ee10537497afccc3a1a1d76.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-09</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/02/Paper/2024-02-02/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-5920453c69c00995f18077b22d4a790e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-02</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/01/30/Paper/2024-01-30/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-e55358c77a9d65f15701e8f33262e2a4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/03/04/Paper/2024-03-04/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-1e4adba77bea5b8766028ddf128d14f8.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-04</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/13/Paper/2024-02-13/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3709a9941aada6c4d3ed35934e311765.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-13</div><div class="title">Diffusion Models</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-03-09-%E6%9B%B4%E6%96%B0"><span class="toc-text">2024-03-09 æ›´æ–°</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation"><span class="toc-text">Pix2Gif: Motion-Guided Diffusion for GIF Generation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Controllable-Generation-with-Text-to-Image-Diffusion-Models-A-Survey"><span class="toc-text">Controllable Generation with Text-to-Image Diffusion Models: A Survey</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scaling-Rectified-Flow-Transformers-for-High-Resolution-Image-Synthesis"><span class="toc-text">Scaling Rectified Flow Transformers for High-Resolution Image Synthesis</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tuning-Free-Noise-Rectification-for-High-Fidelity-Image-to-Video-Generation"><span class="toc-text">Tuning-Free Noise Rectification for High Fidelity Image-to-Video Generation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Few-shot-Learner-Parameterization-by-Diffusion-Time-steps"><span class="toc-text">Few-shot Learner Parameterization by Diffusion Time-steps</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Semantic-Human-Mesh-Reconstruction-with-Textures"><span class="toc-text">Semantic Human Mesh Reconstruction with Textures</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Updating-the-Minimum-Information-about-CLinical-Artificial-Intelligence-MI-CLAIM-checklist-for-generative-modeling-research"><span class="toc-text">Updating the Minimum Information about CLinical Artificial Intelligence (MI-CLAIM) checklist for generative modeling research</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image:url('https://pic1.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>æ¡†æ¶</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="ç®€ç¹è½¬æ¢">ç°¡</button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const e of document.querySelectorAll('script[type^="math/tex"]')){const a=!!e.type.match(/; *mode=display/),n=new t.options.MathItem(e.textContent,t.inputJax[0],a),s=document.createTextNode("");e.parentNode.replaceChild(s,e),n.start={node:s,delim:"",n:0},n.end={node:s,delim:"",n:0},t.math.push(n)}},""]}}};const t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t)}</script></div><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("å·²æŒ‚è½½butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/25/Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="2024/01/25/Paper/3DGS Survey/" alt="">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting ä»Šå¤©æƒ³ä»‹ç»çš„æ˜¯`ZJU`å¸¦æ¥çš„`3DGS`çš„é¦–ç¯‡ç»¼è¿°`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="2024/01/25/Paper/3DGS Survey/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">CUDAç¼–ç¨‹å­¦ä¹ ï¼šè‡ªå®šä¹‰Pytorch+cpp/cuda extension</a><div class="blog-slider__text">è™½ç„¶è¯´PyTorchæä¾›äº†ä¸°å¯Œçš„ä¸ç¥ç»ç½‘ç»œã€å¼ é‡ä»£æ•°ã€æ•°æ®å¤„ç†ç­‰ç›¸å…³çš„æ“ä½œï¼Œä½†æ˜¯æœ‰æ—¶å€™ä½ å¯èƒ½éœ€è¦**æ›´å®šåˆ¶åŒ–çš„æ“ä½œ**ï¼Œæ¯”å¦‚ä½¿ç”¨è®ºæ–‡ä¸­çš„æ–°å‹æ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…å®ç°ä½œä¸ºç ”ç©¶ä¸€éƒ¨åˆ†å¼€å‘çš„æ“ä½œã€‚åœ¨PyTorchä¸­ï¼Œæœ€ç®€å•çš„é›†æˆè‡ªå®šä¹‰æ“ä½œçš„æ–¹å¼æ˜¯åœ¨Pythonä¸­ç¼–å†™ï¼Œé€šè¿‡æ‰©å±•Functionå’ŒModuleæ¥å®ç°ï¼Œ</div><a class="blog-slider__button" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesisï¼Œ è¿™ä»½èµ„æºåº“æ•´ç†äº†ä¸ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)å’Œç¥ç»è¾å°„åœº(NeRF)ç›¸å…³çš„è®ºæ–‡ã€ä»£ç å’Œèµ„æº,é‡ç‚¹å…³æ³¨åŸºäºå›¾åƒå’ŒéŸ³é¢‘çš„è™šæ‹Ÿè®²è¯å¤´åˆæˆè®ºæ–‡åŠå·²å‘å¸ƒä»£ç ã€‚å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªä»“åº“æœ‰ç”¨,è¯·starâ­æ”¯æŒ!</div><a class="blog-slider__button" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/17/Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023/12/17/Project/ChatPaperFree/" alt="">ChatPaperFree GeminiProï¼ˆä¸€åˆ†é’Ÿè¯»è®ºæ–‡ï¼‰</a><div class="blog-slider__text">ChatPaperFreeæ˜¯ä¸€ä¸ªåŸºäºChatGPTçš„è‡ªåŠ¨è®ºæ–‡æ‘˜è¦ç”Ÿæˆå™¨ï¼Œåœ¨ChatPaperçš„åŸºç¡€ä¸Šè¿›è¡Œçš„æ›´æ–°ï¼Œé‡‡ç”¨äº†æœ€è¿‘ç”±Googleå¼€æºçš„Gemini Proå¤§æ¨¡å‹ã€‚ç›®å‰,æˆ‘ä»¬èƒ½å¤Ÿå¯¹ç”¨æˆ·è¾“å…¥çš„è®ºæ–‡è¿›è¡Œè‡ªåŠ¨æ€»ç»“ã€‚æœªæ¥,æˆ‘è¿˜è®¡åˆ’åŠ å…¥å¯¹è®ºæ–‡å›¾ç‰‡/è¡¨æ ¼/å…¬å¼çš„è¯†åˆ« extraction,ä»è€Œç”Ÿæˆæ›´å…¨é¢è€Œæ˜“è¯»çš„æ€»ç»“ã€‚</div><a class="blog-slider__button" href="2023/12/17/Project/ChatPaperFree/" alt="">è¯¦æƒ…   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script></body></html>