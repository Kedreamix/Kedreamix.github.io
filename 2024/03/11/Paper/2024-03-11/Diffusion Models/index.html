<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Diffusion Models | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-11  VideoElevator Elevating Video Generation Quality with Versatile   Text-to-Image Diffusion Models"><meta property="og:type" content="article"><meta property="og:title" content="Diffusion Models"><meta property="og:url" content="https://kedreamix.github.io/2024/03/11/Paper/2024-03-11/Diffusion%20Models/index.html"><meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World"><meta property="og:description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-11  VideoElevator Elevating Video Generation Quality with Versatile   Text-to-Image Diffusion Models"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://picx.zhimg.com/v2-302c4a1ee77cbdfd8dba69c7d6a94497.jpg"><meta property="article:published_time" content="2024-03-11T12:35:46.000Z"><meta property="article:modified_time" content="2024-03-11T12:35:46.983Z"><meta property="article:author" content="Kedreamix"><meta property="article:tag" content="Diffusion Models"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://picx.zhimg.com/v2-302c4a1ee77cbdfd8dba69c7d6a94497.jpg"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/2024/03/11/Paper/2024-03-11/Diffusion%20Models/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-74LZ5BEQQ1")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!0,languages:{hits_empty:"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}",hits_stats:"å…±æ‰¾åˆ° ${hits} ç¯‡æ–‡ç« "}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"ç¹",msgToSimplifiedChinese:"ç®€"},noticeOutdate:{limitDay:500,position:"top",messagePrev:"It has been",messageNext:"days since the last update, the content of the article may be outdated."},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"å¤åˆ¶æˆåŠŸ",error:"å¤åˆ¶é”™è¯¯",noSupport:"æµè§ˆå™¨ä¸æ”¯æŒ"},relativeDate:{homepage:!0,post:!0},runtime:"å¤©",dateSuffix:{just:"åˆšåˆš",min:"åˆ†é’Ÿå‰",hour:"å°æ—¶å‰",day:"å¤©å‰",month:"ä¸ªæœˆå‰"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js",buttonText:"åŠ è½½æ›´å¤š"},isPhotoFigcaption:!0,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Diffusion Models",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-03-11 20:35:46"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme"),o=(new Date).getHours();void 0===t?o<=6||o>=24?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode();const a=saveToLocal.get("aside-status");void 0!==a&&("hide"===a?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 7.0.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml"></head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",(()=>{o()}))})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">254</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://picx.zhimg.com/v2-302c4a1ee77cbdfd8dba69c7d6a94497.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>å‹é“¾</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Diffusion Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2024-03-11T12:35:46.000Z" title="å‘è¡¨äº 2024-03-11 20:35:46">2024-03-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2024-03-11T12:35:46.983Z" title="æ›´æ–°äº 2024-03-11 20:35:46">2024-03-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">å­—æ•°æ€»è®¡:</span><span class="word-count">21k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»æ—¶é•¿:</span><span>74åˆ†é’Ÿ</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Diffusion Models"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-11-æ›´æ–°"><a href="#2024-03-11-æ›´æ–°" class="headerlink" title="2024-03-11 æ›´æ–°"></a>2024-03-11 æ›´æ–°</h1><h2 id="VideoElevator-Elevating-Video-Generation-Quality-with-Versatile-Text-to-Image-Diffusion-Models"><a href="#VideoElevator-Elevating-Video-Generation-Quality-with-Versatile-Text-to-Image-Diffusion-Models" class="headerlink" title="VideoElevator: Elevating Video Generation Quality with Versatile   Text-to-Image Diffusion Models"></a>VideoElevator: Elevating Video Generation Quality with Versatile Text-to-Image Diffusion Models</h2><p><strong>Authors:Yabo Zhang, Yuxiang Wei, Xianhui Lin, Zheng Hui, Peiran Ren, Xuansong Xie, Xiangyang Ji, Wangmeng Zuo</strong></p><p>Text-to-image diffusion models (T2I) have demonstrated unprecedented capabilities in creating realistic and aesthetic images. On the contrary, text-to-video diffusion models (T2V) still lag far behind in frame quality and text alignment, owing to insufficient quality and quantity of training videos. In this paper, we introduce VideoElevator, a training-free and plug-and-play method, which elevates the performance of T2V using superior capabilities of T2I. Different from conventional T2V sampling (i.e., temporal and spatial modeling), VideoElevator explicitly decomposes each sampling step into temporal motion refining and spatial quality elevating. Specifically, temporal motion refining uses encapsulated T2V to enhance temporal consistency, followed by inverting to the noise distribution required by T2I. Then, spatial quality elevating harnesses inflated T2I to directly predict less noisy latent, adding more photo-realistic details. We have conducted experiments in extensive prompts under the combination of various T2V and T2I. The results show that VideoElevator not only improves the performance of T2V baselines with foundational T2I, but also facilitates stylistic video synthesis with personalized T2I. Our code is available at <a target="_blank" rel="noopener" href="https://github.com/YBYBZhang/VideoElevator">https://github.com/YBYBZhang/VideoElevator</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.05438v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://videoelevator.github.io">https://videoelevator.github.io</a> Code: <a target="_blank" rel="noopener" href="https://github.com/YBYBZhang/VideoElevator">https://github.com/YBYBZhang/VideoElevator</a></p><p><strong>Summary</strong><br>è§†é¢‘æå‡å™¨ï¼šé€šè¿‡å›¾åƒæ‰©æ•£æ¨¡å‹æå‡è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>VideoElevator æ˜¯ä¸€ç§æ— è®­ç»ƒã€å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå¯åˆ©ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿æå‡è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</li><li>ä¸ä¼ ç»Ÿçš„è§†é¢‘æ‰©æ•£æ¨¡å‹é‡‡æ ·ä¸åŒï¼ŒVideoElevator å°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ã€‚</li><li>æ—¶é—´è¿åŠ¨ç»†åŒ–ä½¿ç”¨å°é—­çš„è§†é¢‘æ‰©æ•£æ¨¡å‹æ¥å¢å¼ºæ—¶é—´ä¸€è‡´æ€§ã€‚</li><li>ç©ºé—´è´¨é‡æå‡åˆ©ç”¨å……å®çš„å›¾åƒæ‰©æ•£æ¨¡å‹ç›´æ¥é¢„æµ‹æ›´å°‘å™ªå£°çš„æ½œåœ¨å› ç´ ï¼Œå¢åŠ æ›´å¤šé€¼çœŸçš„ç»†èŠ‚ã€‚</li><li>VideoElevator ä¸ä»…æé«˜äº†åŸºäºå›¾åƒæ‰©æ•£æ¨¡å‹çš„è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜ä¿ƒè¿›äº†ä½¿ç”¨ä¸ªæ€§åŒ–å›¾åƒæ‰©æ•£æ¨¡å‹çš„é£æ ¼åŒ–è§†é¢‘åˆæˆã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šVideoElevatorï¼šåˆ©ç”¨å¤šåŠŸèƒ½æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æå‡è§†é¢‘ç”Ÿæˆè´¨é‡</li><li>ä½œè€…ï¼šYabo Zhang1, Yuxiang Wei1, Xianhui Lin, Zheng Hui, Peiran Ren, Xuansong Xie, Xiangyang Ji2, and Wangmeng Zuo1</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå“ˆå°”æ»¨å·¥ä¸šå¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œè§†é¢‘ç”Ÿæˆï¼Œè´¨é‡æå‡</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://videoelevator.github.io Github ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š (1) ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ˆT2Iï¼‰åœ¨ç”Ÿæˆé€¼çœŸä¸”ç¾è§‚çš„å›¾åƒæ–¹é¢è¡¨ç°å‡ºäº†å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ã€‚ç›¸åï¼Œæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆT2Vï¼‰åœ¨å¸§è´¨é‡å’Œæ–‡æœ¬å¯¹é½æ–¹é¢ä»ç„¶è¿œè¿œè½åï¼Œè¿™æ˜¯ç”±äºè®­ç»ƒè§†é¢‘çš„è´¨é‡å’Œæ•°é‡ä¸è¶³ã€‚ (2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ç›´æ¥å¯¹è§†é¢‘è¿›è¡Œé‡‡æ ·ï¼Œä½†ç”±äºç¼ºä¹è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®ï¼Œç”Ÿæˆçš„è§†é¢‘è´¨é‡è¾ƒå·®ã€‚ (3) æœ¬æ–‡æ–¹æ³•ï¼šVideoElevator æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œåˆ©ç”¨ T2I çš„å‡ºè‰²èƒ½åŠ›æå‡ T2V çš„æ€§èƒ½ã€‚å®ƒå°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤æ˜ç¡®åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ã€‚æ—¶é—´è¿åŠ¨ç»†åŒ–ä½¿ç”¨å°è£…çš„ T2V å¢å¼ºæ—¶é—´ä¸€è‡´æ€§ï¼Œç„¶ååè½¬ä¸º T2I æ‰€éœ€çš„å™ªå£°åˆ†å¸ƒã€‚ç„¶åï¼Œç©ºé—´è´¨é‡æå‡åˆ©ç”¨è†¨èƒ€çš„ T2I ç›´æ¥é¢„æµ‹å™ªå£°è¾ƒå°çš„æ½œåœ¨å˜é‡ï¼Œæ·»åŠ æ›´å¤šé€¼çœŸçš„ç»†èŠ‚ã€‚ (4) æ–¹æ³•æ€§èƒ½ï¼šåœ¨å„ç§ T2V å’Œ T2I æ¨¡å‹ç»„åˆä¸‹çš„å¹¿æ³›æç¤ºä¸­è¿›è¡Œäº†å®éªŒã€‚ç»“æœè¡¨æ˜ï¼ŒVideoElevator åœ¨å¸§è´¨é‡ã€æ—¶é—´ä¸€è‡´æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢æ˜¾è‘—æå‡äº† T2V çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æå‡ T2V è´¨é‡çš„æœ‰æ•ˆæ€§ã€‚</li></ol><p>7.æ–¹æ³•ï¼š (1) VideoElevatorå°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤æ˜ç¡®åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ï¼› (2) æ—¶é—´è¿åŠ¨ç»†åŒ–ä½¿ç”¨å°è£…çš„T2Vå¢å¼ºæ—¶é—´ä¸€è‡´æ€§ï¼Œç„¶ååè½¬ä¸ºT2Iæ‰€éœ€çš„å™ªå£°åˆ†å¸ƒï¼› (3) ç©ºé—´è´¨é‡æå‡åˆ©ç”¨è†¨èƒ€çš„T2Iç›´æ¥é¢„æµ‹å™ªå£°è¾ƒå°çš„æ½œåœ¨å˜é‡ï¼Œæ·»åŠ æ›´å¤šé€¼çœŸçš„ç»†èŠ‚ã€‚</p><ol><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šxxxï¼› ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šVideoElevatoræå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œåˆ©ç”¨T2Içš„å‡ºè‰²èƒ½åŠ›æå‡T2Vçš„æ€§èƒ½ï¼Œä¸ºæå‡è§†é¢‘ç”Ÿæˆè´¨é‡æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå°†T2Içš„ä¼˜åŠ¿å¼•å…¥T2Vä¸­ã€‚</li><li>å°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤æ˜ç¡®åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ï¼Œæé«˜äº†è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§å’Œç©ºé—´è´¨é‡ã€‚ æ€§èƒ½ï¼š</li><li>åœ¨å„ç§T2Vå’ŒT2Iæ¨¡å‹ç»„åˆä¸‹çš„å¹¿æ³›æç¤ºä¸­è¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜VideoElevatoråœ¨å¸§è´¨é‡ã€æ—¶é—´ä¸€è‡´æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢æ˜¾è‘—æå‡äº†T2Vçš„æ€§èƒ½ã€‚ å·¥ä½œé‡ï¼š</li><li>VideoElevatoræ˜¯ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå·¥ä½œé‡è¾ƒå°ï¼Œæ˜“äºä¸ç°æœ‰çš„T2Væ¨¡å‹é›†æˆã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-cad376bbaa11399212fdef9f175c2469.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c6b6b777c3f6359e627b50aeeac2627b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-907eeb8949cad583968ae2444608f263.jpg" align="middle"></details><h2 id="Towards-Effective-Usage-of-Human-Centric-Priors-in-Diffusion-Models-for-Text-based-Human-Image-Generation"><a href="#Towards-Effective-Usage-of-Human-Centric-Priors-in-Diffusion-Models-for-Text-based-Human-Image-Generation" class="headerlink" title="Towards Effective Usage of Human-Centric Priors in Diffusion Models for   Text-based Human Image Generation"></a>Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation</h2><p><strong>Authors:Junyan Wang, Zhenhong Sun, Zhiyu Tan, Xuanbai Chen, Weihua Chen, Hao Li, Cheng Zhang, Yang Song</strong></p><p>Vanilla text-to-image diffusion models struggle with generating accurate human images, commonly resulting in imperfect anatomies such as unnatural postures or disproportionate limbs.Existing methods address this issue mostly by fine-tuning the model with extra images or adding additional controls â€” human-centric priors such as pose or depth maps â€” during the image generation phase. This paper explores the integration of these human-centric priors directly into the model fine-tuning stage, essentially eliminating the need for extra conditions at the inference stage. We realize this idea by proposing a human-centric alignment loss to strengthen human-related information from the textual prompts within the cross-attention maps. To ensure semantic detail richness and human structural accuracy during fine-tuning, we introduce scale-aware and step-wise constraints within the diffusion process, according to an in-depth analysis of the cross-attention layer. Extensive experiments show that our method largely improves over state-of-the-art text-to-image models to synthesize high-quality human images based on user-written prompts. Project page: \url{<a target="_blank" rel="noopener" href="https://hcplayercvpr2024.github.io}">https://hcplayercvpr2024.github.io}</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.05239v1">PDF</a> Accepted to CVPR 2024</p><p><strong>Summary</strong><br>åœ¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­èåˆä»¥äººä¸ºä¸­å¿ƒçš„ä¿¡æ¯å¯ä»¥æ˜¾è‘—æé«˜å›¾åƒè´¨é‡ï¼Œç‰¹åˆ«æ˜¯äººä½“å›¾åƒçš„ç”Ÿæˆã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>äººä½“å›¾åƒç”Ÿæˆä¸­å­˜åœ¨å§¿åŠ¿å’Œæ¯”ä¾‹ä¸è‡ªç„¶ç­‰é—®é¢˜ã€‚</li><li>ç°æœ‰çš„æ–¹æ³•ä¸»è¦é€šè¿‡å¾®è°ƒæ¨¡å‹æˆ–å¢åŠ å›¾åƒç”Ÿæˆé˜¶æ®µçš„äººä½“çº¦æŸæ¥è§£å†³ã€‚</li><li>æœ¬æ–‡å°†äººä½“çº¦æŸç›´æ¥èå…¥æ¨¡å‹å¾®è°ƒé˜¶æ®µï¼Œæ— éœ€åœ¨æ¨ç†é˜¶æ®µæ·»åŠ çº¦æŸã€‚</li><li>äººä½“çº¦æŸå¯¹é½æŸå¤±åŠ å¼ºäº†å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­æ–‡æœ¬å½“ä¸­çš„äººä½“ç›¸å…³ä¿¡æ¯ã€‚</li><li>é‡‡ç”¨å¯æ§å°ºåº¦å’Œåˆ†æ­¥çº¦æŸï¼Œä¿è¯å¾®è°ƒè¿‡ç¨‹ä¸­çš„è¯­ä¹‰ä¸°å¯Œæ€§å’Œäººä½“ç»“æ„å‡†ç¡®æ€§ã€‚</li><li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œå¯åŸºäºç”¨æˆ·è¾“å…¥ç”Ÿæˆé«˜è´¨é‡äººä½“å›¾åƒã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šåŸºäºæ–‡æœ¬çš„äººä½“å›¾åƒç”Ÿæˆçš„äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±</li><li>ä½œè€…ï¼šZhaoyang Huang, Bin Li, Zizhao Zhang, Zhihao Fang, Yan Yan, Xiaogang Wang</li><li>éš¶å±ï¼šä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€äººç±»å›¾åƒç”Ÿæˆã€äººä½“å¯¹é½ã€æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithubä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆäººä½“å›¾åƒæ—¶å­˜åœ¨è§£å‰–ç»“æ„ä¸å‡†ç¡®ã€å§¿åŠ¿ä¸è‡ªç„¶ç­‰é—®é¢˜ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š ç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡å¾®è°ƒæ¨¡å‹æˆ–æ·»åŠ äººä½“ä¸­å¿ƒå…ˆéªŒï¼ˆå¦‚å§¿åŠ¿æˆ–æ·±åº¦å›¾ï¼‰æ¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æ¨ç†é˜¶æ®µéœ€è¦é¢å¤–çš„æ¡ä»¶ã€‚</p><p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š æœ¬æ–‡æå‡ºäº†ä¸€ç§äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå°†æ–‡æœ¬æç¤ºä¸­çš„äººä½“ç›¸å…³ä¿¡æ¯èå…¥äº¤å‰æ³¨æ„åŠ›å›¾ä¸­ï¼Œå¹¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å¼•å…¥å°ºåº¦æ„ŸçŸ¥å’Œæ­¥é•¿çº¦æŸï¼Œä»¥ä¿è¯è¯­ä¹‰ç»†èŠ‚ä¸°å¯Œå’Œäººä½“ç»“æ„å‡†ç¡®ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š åœ¨ Human-Art æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡äººä½“å›¾åƒæ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚</p><p>æ–¹æ³•ï¼š (1):æå‡ºäººç±»ä¸­å¿ƒå…ˆéªŒå±‚ï¼ˆHcPï¼‰å’Œäººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå¢å¼ºæ¨¡å‹å¯¹äººç±»ä¸­å¿ƒæ–‡æœ¬ä¿¡æ¯çš„æ•æ„Ÿæ€§ï¼Œæé«˜ç”Ÿæˆäººä½“å›¾åƒçš„ç»“æ„å‡†ç¡®æ€§å’Œç»†èŠ‚ã€‚ (2):åˆ†æäº¤å‰æ³¨æ„åŠ›å±‚åœ¨ä¸åŒæ—¶é—´æ­¥å’Œåˆ†è¾¨ç‡å°ºåº¦ä¸‹çš„ä½œç”¨ï¼Œå‘ç°æ—©æœŸæ—¶é—´æ­¥å’Œä¸­é—´åˆ†è¾¨ç‡å°ºåº¦å¯¹äººä½“ç»“æ„ç”Ÿæˆè‡³å…³é‡è¦ã€‚ (3):è®¾è®¡HcPå±‚ï¼Œä»æ–‡æœ¬åµŒå…¥ä¸­æå–äººç±»ä¸­å¿ƒtokenï¼Œå¹¶ä¸æ½œåœ¨ç‰¹å¾è¿›è¡Œäº¤äº’ï¼Œç”Ÿæˆäººç±»ä¸­å¿ƒæ³¨æ„åŠ›å›¾ã€‚ (4):æå‡ºäººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå°†é¢„è®­ç»ƒçš„å®ä½“å…³ç³»ç½‘ç»œæå–çš„äººç±»ä¸­å¿ƒå•è¯å¯¹åº”çš„å…³é”®å§¿åŠ¿å›¾åƒä¸HcPå±‚ç”Ÿæˆçš„æ³¨æ„åŠ›å›¾å¯¹é½ï¼ŒæŒ‡å¯¼æ¨¡å‹å…³æ³¨äººä½“ç»“æ„ç»†èŠ‚ã€‚</p><ol><li>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•ä¸”æœ‰æ•ˆçš„æ–¹æ³•ï¼Œåˆ©ç”¨äººç±»ä¸­å¿ƒå…ˆéªŒï¼ˆHcPï¼‰ï¼Œä¾‹å¦‚å§¿åŠ¿æˆ–æ·±åº¦å›¾ï¼Œæ¥æé«˜ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸­çš„äººä½“å›¾åƒç”Ÿæˆè´¨é‡ã€‚æ‰€æå‡ºçš„ HcP å±‚æœ‰æ•ˆåœ°åˆ©ç”¨äº†å…³äºäººç±»çš„ä¿¡æ¯åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæ— éœ€åœ¨ä»æ–‡æœ¬ç”Ÿæˆå›¾åƒæ—¶éœ€è¦é¢å¤–çš„è¾“å…¥ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒHcP å±‚ä¸ä»…ä¿®å¤äº†äººä½“ç»“æ„ç”Ÿæˆä¸­çš„ç»“æ„ä¸å‡†ç¡®é—®é¢˜ï¼Œè€Œä¸”è¿˜ä¿ç•™äº†åŸå§‹çš„å®¡ç¾å“è´¨å’Œç»†èŠ‚ã€‚æœªæ¥çš„å·¥ä½œå°†æ¢ç´¢æ•´åˆå¤šç§ç±»å‹çš„äººç±»ä¸­å¿ƒå…ˆéªŒï¼Œä»¥è¿›ä¸€æ­¥æ¨è¿›äººç±»å›¾åƒå’Œè§†é¢‘ç”Ÿæˆã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š æå‡ºäº†ä¸€ç§æ–°é¢–çš„äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå°†æ–‡æœ¬æç¤ºä¸­çš„äººä½“ç›¸å…³ä¿¡æ¯èå…¥äº¤å‰æ³¨æ„åŠ›å›¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹å…³æ³¨äººä½“ç»“æ„ç»†èŠ‚ã€‚ åˆ†æäº†äº¤å‰æ³¨æ„åŠ›å±‚åœ¨ä¸åŒæ—¶é—´æ­¥å’Œåˆ†è¾¨ç‡å°ºåº¦ä¸‹çš„ä½œç”¨ï¼Œå‘ç°æ—©æœŸæ—¶é—´æ­¥å’Œä¸­é—´åˆ†è¾¨ç‡å°ºåº¦å¯¹äººä½“ç»“æ„ç”Ÿæˆè‡³å…³é‡è¦ã€‚ è®¾è®¡äº† HcP å±‚ï¼Œä»æ–‡æœ¬åµŒå…¥ä¸­æå–äººç±»ä¸­å¿ƒ tokenï¼Œå¹¶ä¸æ½œåœ¨ç‰¹å¾è¿›è¡Œäº¤äº’ï¼Œç”Ÿæˆäººç±»ä¸­å¿ƒæ³¨æ„åŠ›å›¾ã€‚ æ€§èƒ½ï¼š åœ¨ Human-Art æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡äººä½“å›¾åƒæ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚ æ¶ˆèç ”ç©¶å’Œå¯è§†åŒ–ç»“æœéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±å’Œ HcP å±‚åœ¨æé«˜äººä½“å›¾åƒç”Ÿæˆè´¨é‡ä¸­çš„ä½œç”¨ã€‚ å·¥ä½œé‡ï¼š è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œåªéœ€åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æ·»åŠ  HcP å±‚å’Œäººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ã€‚ è¯¥æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„æ¡ä»¶ï¼Œä¾‹å¦‚å§¿åŠ¿æˆ–æ·±åº¦å›¾ï¼Œåœ¨æ¨ç†é˜¶æ®µä½¿ç”¨ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-dcb4970717d9f287c0e2b916300f3dd2.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-cef2974d0c0ed77c5f9c42184d7e57c4.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-564f5b115d714883587e123a15ef8050.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-f5ade1a99be6f3185ad39bc934410199.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-dfa83d53d9802f58aba15bf8be1a8b64.jpg" align="middle"></details><h2 id="Denoising-Autoregressive-Representation-Learning"><a href="#Denoising-Autoregressive-Representation-Learning" class="headerlink" title="Denoising Autoregressive Representation Learning"></a>Denoising Autoregressive Representation Learning</h2><p><strong>Authors:Yazhe Li, Jorg Bornschein, Ting Chen</strong></p><p>In this paper, we explore a new generative approach for learning visual representations. Our method, DARL, employs a decoder-only Transformer to predict image patches autoregressively. We find that training with Mean Squared Error (MSE) alone leads to strong representations. To enhance the image generation ability, we replace the MSE loss with the diffusion objective by using a denoising patch decoder. We show that the learned representation can be improved by using tailored noise schedules and longer training in larger models. Notably, the optimal schedule differs significantly from the typical ones used in standard image diffusion models. Overall, despite its simple architecture, DARL delivers performance remarkably close to state-of-the-art masked prediction models under the fine-tuning protocol. This marks an important step towards a unified model capable of both visual perception and generation, effectively combining the strengths of autoregressive and denoising diffusion models.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.05196v1">PDF</a></p><p><strong>Summary</strong><br>è‡ªå›å½’æ‰©æ•£æ¨¡å‹ DARL å®ç°å›¾åƒç”Ÿæˆå’Œè§†è§‰è¡¨ç¤ºå­¦ä¹ ç›¸ç»“åˆï¼Œå±•ç°å‡ºä¸å…ˆè¿›æ©ç é¢„æµ‹æ¨¡å‹åª²ç¾çš„æ€§èƒ½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>DARL ä½¿ç”¨ä»…è§£ç å™¨çš„ Transformer æ¥è‡ªå›å½’é¢„æµ‹å›¾åƒå—ã€‚</li><li>ä»… MSE è®­ç»ƒå³å¯äº§ç”Ÿå¼ºå¤§çš„è¡¨ç¤ºã€‚</li><li>ä½¿ç”¨å»å™ªå—è§£ç å™¨å°† MSE æŸå¤±æ›¿æ¢ä¸ºæ‰©æ•£ç›®æ ‡å¯ä»¥å¢å¼ºå›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚</li><li>å®šåˆ¶å™ªå£°è°ƒåº¦å’Œåœ¨æ›´å¤§æ¨¡å‹ä¸Šçš„æ›´é•¿æ—¶é—´è®­ç»ƒå¯ä»¥æé«˜å­¦ä¹ è¡¨ç¤ºã€‚</li><li>æœ€ä½³è°ƒåº¦ä¸æ ‡å‡†å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­ä½¿ç”¨çš„è°ƒåº¦æ˜¾è‘—ä¸åŒã€‚</li><li>å°½ç®¡æ¶æ„ç®€å•ï¼Œä½† DARL åœ¨å¾®è°ƒåè®®ä¸‹æä¾›æ¥è¿‘æœ€å…ˆè¿›æ©ç é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚</li><li>DARL ä»£è¡¨äº†å°†è‡ªå›å½’å’Œå»å™ªæ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿ç»“åˆèµ·æ¥ï¼Œå®ç°è§†è§‰æ„ŸçŸ¥å’Œç”Ÿæˆç›¸ç»Ÿä¸€çš„é‡è¦ä¸€æ­¥ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>è®ºæ–‡æ ‡é¢˜ï¼šå»å™ªè‡ªå›å½’è¡¨å¾å­¦ä¹ </li><li>ä½œè€…ï¼šYazhe Liï¼ŒJorg Bornscheinï¼ŒTing Chen</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šGoogle DeepMind</li><li>å…³é”®è¯ï¼šè§†è§‰è¡¨å¾å­¦ä¹ ï¼Œè‡ªå›å½’æ¨¡å‹ï¼Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œå›¾åƒç”Ÿæˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šNone Github é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè§†è§‰è¡¨å¾å­¦ä¹ å’Œå›¾åƒç”Ÿæˆé€šå¸¸ä½¿ç”¨ä¸åŒçš„æŠ€æœ¯ï¼Œå‰è€…æ³¨é‡é²æ£’æ€§ï¼Œåè€…æ³¨é‡ç”Ÿæˆèƒ½åŠ›ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šå¯¹æ¯”å­¦ä¹ ã€è’¸é¦è‡ªç›‘ç£å­¦ä¹ ã€æ©ç å›¾åƒå»ºæ¨¡ç­‰æ–¹æ³•åœ¨è¡¨å¾å­¦ä¹ ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç¼ºä¹ç”Ÿæˆèƒ½åŠ›ã€‚ ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨ Transformer é¢„æµ‹å›¾åƒå—ã€‚é€šè¿‡ä½¿ç”¨å‡æ–¹è¯¯å·®æŸå¤±å’Œå»å™ªå—è§£ç å™¨ï¼Œå¢å¼ºäº†å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚ ï¼ˆ4ï¼‰æ€§èƒ½è¡¨ç°ï¼šè¯¥æ–¹æ³•åœ¨å¾®è°ƒåè®®ä¸‹ï¼Œè¡¨ç°æ¥è¿‘æœ€å…ˆè¿›çš„æ©ç é¢„æµ‹æ¨¡å‹ï¼Œè¡¨æ˜å…¶åœ¨è¡¨å¾å­¦ä¹ å’Œç”Ÿæˆæ–¹é¢çš„æ½œåŠ›ã€‚</p></li><li><p>Methodsï¼š (1) æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨ Transformer é¢„æµ‹å›¾åƒå—ï¼› (2) ä½¿ç”¨å‡æ–¹è¯¯å·®æŸå¤±å’Œå»å™ªå—è§£ç å™¨ï¼Œå¢å¼ºäº†å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚</p></li><li><p>æ€»ç»“ï¼š (1): æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨Transformeré¢„æµ‹å›¾åƒå—ï¼Œåœ¨å¾®è°ƒåè®®ä¸‹è¡¨ç°æ¥è¿‘æœ€å…ˆè¿›çš„æ©ç é¢„æµ‹æ¨¡å‹ï¼Œè¡¨æ˜å…¶åœ¨è¡¨å¾å­¦ä¹ å’Œç”Ÿæˆæ–¹é¢çš„æ½œåŠ›ã€‚ (2): Innovation point: æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨Transformeré¢„æµ‹å›¾åƒå—ã€‚ Performance: åœ¨å¾®è°ƒåè®®ä¸‹è¡¨ç°æ¥è¿‘æœ€å…ˆè¿›çš„æ©ç é¢„æµ‹æ¨¡å‹ã€‚ Workload: æœªæåŠã€‚</p></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-3a6bd101af2be0b75af14290ca20154b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-901dfa573ba65a2319ddfc43d65a7325.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-56ec555eccb7ae9c20c196a5c5519463.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-fc4830941b2dbf44695f875173f8eef5.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-f6402f59254c8b1442a49f2075fd0b2f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2f3936f0ef0cf91ab8b2bb5de579b005.jpg" align="middle"></details><h2 id="Improving-Diffusion-Models-for-Virtual-Try-on"><a href="#Improving-Diffusion-Models-for-Virtual-Try-on" class="headerlink" title="Improving Diffusion Models for Virtual Try-on"></a>Improving Diffusion Models for Virtual Try-on</h2><p><strong>Authors:Yisol Choi, Sangkyung Kwak, Kyungmin Lee, Hyungwon Choi, Jinwoo Shin</strong></p><p>This paper considers image-based virtual try-on, which renders an image of a person wearing a curated garment, given a pair of images depicting the person and the garment, respectively. Previous works adapt existing exemplar-based inpainting diffusion models for virtual try-on to improve the naturalness of the generated visuals compared to other methods (e.g., GAN-based), but they fail to preserve the identity of the garments. To overcome this limitation, we propose a novel diffusion model that improves garment fidelity and generates authentic virtual try-on images. Our method, coined IDM-VTON, uses two different modules to encode the semantics of garment image; given the base UNet of the diffusion model, 1) the high-level semantics extracted from a visual encoder are fused to the cross-attention layer, and then 2) the low-level features extracted from parallel UNet are fused to the self-attention layer. In addition, we provide detailed textual prompts for both garment and person images to enhance the authenticity of the generated visuals. Finally, we present a customization method using a pair of person-garment images, which significantly improves fidelity and authenticity. Our experimental results show that our method outperforms previous approaches (both diffusion-based and GAN-based) in preserving garment details and generating authentic virtual try-on images, both qualitatively and quantitatively. Furthermore, the proposed customization method demonstrates its effectiveness in a real-world scenario.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.05139v1">PDF</a></p><p><strong>Summary</strong><br>å›¾åƒåŸºäºçš„è™šæ‹Ÿè¯•ç©¿ï¼Œåœ¨ç»™å®šæè¿°äººç‰©å’Œè¡£æœå›¾åƒçš„æƒ…å†µä¸‹ï¼Œæ¸²æŸ“äººç‰©ç©¿ç€å®šåˆ¶è¡£æœçš„å›¾åƒã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ”¹è¿›çš„æ‰©æ•£æ¨¡å‹ç”¨äºè™šæ‹Ÿè¯•ç©¿ï¼Œä»¥æé«˜ç”Ÿæˆè§†è§‰æ•ˆæœçš„è‡ªç„¶åº¦ã€‚</li><li>æå‡ºçš„ IDM-VTON æ¨¡å‹åœ¨ä¿ç•™æœè£…èº«ä»½çš„åŒæ—¶æé«˜äº†æœè£…ä¿çœŸåº¦ã€‚</li><li>è¯¥æ–¹æ³•ä½¿ç”¨ä¸¤ä¸ªæ¨¡å—æ¥ç¼–ç æœè£…å›¾åƒçš„è¯­ä¹‰ã€‚</li><li>é«˜çº§è¯­ä¹‰èåˆåˆ°äº¤å‰æ³¨æ„å±‚ï¼Œä½çº§ç‰¹å¾èåˆåˆ°è‡ªæ³¨æ„å±‚ã€‚</li><li>æä¾›è¯¦ç»†çš„æ–‡æœ¬æç¤ºï¼Œä»¥å¢å¼ºç”Ÿæˆè§†è§‰æ•ˆæœçš„çœŸå®æ€§ã€‚</li><li>ä½¿ç”¨ä¸€å¯¹äººç‰©æœè£…å›¾åƒçš„å®šåˆ¶æ–¹æ³•æ˜¾ç€æé«˜äº†ä¿çœŸåº¦å’ŒçœŸå®æ€§ã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿ç•™æœè£…ç»†èŠ‚å’Œç”ŸæˆçœŸå®çš„è™šæ‹Ÿè¯•ç©¿å›¾åƒæ–¹é¢ä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚</li><li>æ‰€æå‡ºçš„å®šåˆ¶æ–¹æ³•åœ¨çœŸå®åœºæ™¯ä¸­å±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šæå‡æ‰©æ•£æ¨¡å‹ä»¥å®ç°çœŸå®çš„è™šæ‹Ÿè¯•ç©¿</li><li>Authorsï¼šYisol Choi, Sangkyung Kwak, Kyungmin Lee, Hyungwon Choi, Jinwoo Shin</li><li>Affiliationï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢ï¼ˆKAISTï¼‰</li><li>Keywordsï¼šå›¾åƒç”Ÿæˆã€è™šæ‹Ÿè¯•ç©¿ã€æ‰©æ•£æ¨¡å‹</li><li>Urlsï¼šhttps://arxiv.org/abs/2403.05139</li><li><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒå¼è™šæ‹Ÿè¯•ç©¿æ—¨åœ¨ç»™å®šæç»˜äººç‰©å’Œæœé¥°çš„ä¸¤å¹…å›¾åƒï¼Œç”Ÿæˆäººç‰©ç©¿ç€ç‰¹å®šæœé¥°çš„å›¾åƒã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰å·¥ä½œå°†åŸºäºç¤ºä¾‹çš„å›¾åƒä¿®å¤æ‰©æ•£æ¨¡å‹åº”ç”¨äºè™šæ‹Ÿè¯•ç©¿ï¼Œä¸å…¶ä»–æ–¹æ³•ï¼ˆå¦‚åŸºäº GAN çš„æ–¹æ³•ï¼‰ç›¸æ¯”ï¼Œå¯ä»¥æé«˜ç”Ÿæˆè§†è§‰æ•ˆæœçš„è‡ªç„¶æ€§ï¼Œä½†æ— æ³•ä¿ç•™æœé¥°çš„ç‰¹å¾ã€‚ ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæå‡ºä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ IDM-VTONï¼Œè¯¥æ¨¡å‹ä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å—å¯¹æœé¥°å›¾åƒçš„è¯­ä¹‰è¿›è¡Œç¼–ç ï¼›åœ¨ç»™å®šæ‰©æ•£æ¨¡å‹çš„åŸºæœ¬ U-Net çš„æƒ…å†µä¸‹ï¼Œ1ï¼‰ä»è§†è§‰ç¼–ç å™¨ä¸­æå–çš„é«˜çº§è¯­ä¹‰è¢«èåˆåˆ°äº¤å‰æ³¨æ„å±‚ï¼Œç„¶å 2ï¼‰ä»å¹¶è¡Œ U-Net ä¸­æå–çš„ä½çº§ç‰¹å¾è¢«èåˆåˆ°è‡ªæ³¨æ„å±‚ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼ŒIDM-VTON åœ¨å›¾åƒè´¨é‡å’Œæœé¥°ä¿çœŸåº¦æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº†è¯¥æ–¹æ³•çš„ç›®æ ‡ï¼Œå³ç”ŸæˆçœŸå®ã€ä¿çœŸä¸”å¯å®šåˆ¶çš„è™šæ‹Ÿè¯•ç©¿å›¾åƒã€‚</p></li><li><p>Methods: (1): IDM-VTONé‡‡ç”¨åŸºäºç¤ºä¾‹çš„å›¾åƒä¿®å¤æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å—å¯¹æœé¥°å›¾åƒçš„è¯­ä¹‰è¿›è¡Œç¼–ç ã€‚ (2): è§†è§‰ç¼–ç å™¨æå–æœé¥°å›¾åƒçš„é«˜çº§è¯­ä¹‰ï¼Œå¹¶å°†å…¶èåˆåˆ°äº¤å‰æ³¨æ„å±‚ä¸­ã€‚ (3): å¹¶è¡ŒU-Netæå–æœé¥°å›¾åƒçš„ä½çº§ç‰¹å¾ï¼Œå¹¶å°†å…¶èåˆåˆ°è‡ªæ³¨æ„å±‚ä¸­ã€‚ (4): åœ¨ç»™å®šæ‰©æ•£æ¨¡å‹çš„åŸºæœ¬U-Netçš„æƒ…å†µä¸‹ï¼Œèåˆåçš„é«˜çº§è¯­ä¹‰å’Œä½çº§ç‰¹å¾è¢«ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆè¿‡ç¨‹ã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰æœ¬å·¥ä½œæ„ä¹‰ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ IDM-VTONï¼Œç”¨äºçœŸå®è™šæ‹Ÿè¯•ç©¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å®é™…åœºæ™¯ä¸­ã€‚æˆ‘ä»¬ç»“åˆäº†ä¸¤ä¸ªç‹¬ç«‹çš„æ¨¡å—å¯¹æœé¥°å›¾åƒè¿›è¡Œç¼–ç ï¼Œå³è§†è§‰ç¼–ç å™¨å’Œå¹¶è¡Œ U-Netï¼Œå®ƒä»¬åˆ†åˆ«æœ‰æ•ˆåœ°å¯¹åŸºæœ¬ U-Net ç¼–ç é«˜çº§è¯­ä¹‰å’Œä½çº§ç‰¹å¾ã€‚ä¸ºäº†åœ¨å®é™…åœºæ™¯ä¸­æ”¹è¿›è™šæ‹Ÿè¯•ç©¿ï¼Œæˆ‘ä»¬æå‡ºé€šè¿‡å¾®è°ƒç»™å®šä¸€å¯¹æœé¥°-äººç‰©å›¾åƒçš„ U-Net è§£ç å™¨å±‚æ¥å®šåˆ¶æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨äº†æœé¥°çš„è¯¦ç»†è‡ªç„¶è¯­è¨€æè¿°ï¼Œè¿™æœ‰åŠ©äºç”ŸæˆçœŸå®çš„è™šæ‹Ÿè¯•ç©¿å›¾åƒã€‚åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿ç•™æœé¥°ç»†èŠ‚å’Œç”Ÿæˆé«˜ä¿çœŸå›¾åƒæ–¹é¢ä¼˜äºå…ˆå‰çš„ç ”ç©¶ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å®é™…åœºæ™¯ä¸­è¿›è¡Œè™šæ‹Ÿè¯•ç©¿çš„æ½œåŠ›ã€‚ ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºäº† IDM-VTONï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºçœŸå®è™šæ‹Ÿè¯•ç©¿çš„æ‰©æ•£æ¨¡å‹çš„æ–°è®¾è®¡ï¼Œç‰¹åˆ«æ˜¯åœ¨å®é™…åœºæ™¯ä¸­ã€‚ç»“åˆäº†ä¸¤ä¸ªç‹¬ç«‹çš„æ¨¡å—å¯¹æœé¥°å›¾åƒè¿›è¡Œç¼–ç ï¼Œå³è§†è§‰ç¼–ç å™¨å’Œå¹¶è¡Œ U-Netï¼Œå®ƒä»¬åˆ†åˆ«æœ‰æ•ˆåœ°å¯¹åŸºæœ¬ U-Net ç¼–ç é«˜çº§è¯­ä¹‰å’Œä½çº§ç‰¹å¾ã€‚ æ€§èƒ½ï¼šåœ¨å›¾åƒè´¨é‡å’Œæœé¥°ä¿çœŸåº¦æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ å·¥ä½œé‡ï¼šä¸åŸºäº GAN çš„æ–¹æ³•ç›¸æ¯”ï¼ŒåŸºäºç¤ºä¾‹çš„å›¾åƒä¿®å¤æ‰©æ•£æ¨¡å‹é€šå¸¸å…·æœ‰æ›´é«˜çš„è®¡ç®—æˆæœ¬ã€‚</p></li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-d38c4cb395c666b5e4fd3e52269fff3f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-d67b069f37d9810aa657e9e7dd415a5a.jpg" align="middle"></details><h2 id="ELLA-Equip-Diffusion-Models-with-LLM-for-Enhanced-Semantic-Alignment"><a href="#ELLA-Equip-Diffusion-Models-with-LLM-for-Enhanced-Semantic-Alignment" class="headerlink" title="ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment"></a>ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment</h2><p><strong>Authors:Xiwei Hu, Rui Wang, Yixiao Fang, Bin Fu, Pei Cheng, Gang Yu</strong></p><p>Diffusion models have demonstrated remarkable performance in the domain of text-to-image generation. However, most widely used models still employ CLIP as their text encoder, which constrains their ability to comprehend dense prompts, encompassing multiple objects, detailed attributes, complex relationships, long-text alignment, etc. In this paper, we introduce an Efficient Large Language Model Adapter, termed ELLA, which equips text-to-image diffusion models with powerful Large Language Models (LLM) to enhance text alignment without training of either U-Net or LLM. To seamlessly bridge two pre-trained models, we investigate a range of semantic alignment connector designs and propose a novel module, the Timestep-Aware Semantic Connector (TSC), which dynamically extracts timestep-dependent conditions from LLM. Our approach adapts semantic features at different stages of the denoising process, assisting diffusion models in interpreting lengthy and intricate prompts over sampling timesteps. Additionally, ELLA can be readily incorporated with community models and tools to improve their prompt-following capabilities. To assess text-to-image models in dense prompt following, we introduce Dense Prompt Graph Benchmark (DPG-Bench), a challenging benchmark consisting of 1K dense prompts. Extensive experiments demonstrate the superiority of ELLA in dense prompt following compared to state-of-the-art methods, particularly in multiple object compositions involving diverse attributes and relationships.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.05135v1">PDF</a> Project Page: <a target="_blank" rel="noopener" href="https://ella-diffusion.github.io/">https://ella-diffusion.github.io/</a></p><p><strong>Summary</strong><br>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åŠ å…¥è¯­è¨€å¤§æ¨¡å‹å¢å¼ºå™¨ ELLAï¼Œå¤§å¹…æå‡ä¸°å¯Œæç¤ºç†è§£èƒ½åŠ›ï¼Œæ— éœ€è®­ç»ƒ U å½¢ç½‘ç»œæˆ–è¯­è¨€å¤§æ¨¡å‹ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ELLA è¯­è¨€å¤§æ¨¡å‹å¢å¼ºå™¨é€šè¿‡æ— ç¼è¿æ¥ï¼Œæå‡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ–‡æœ¬å¯¹é½èƒ½åŠ›ï¼Œæ— éœ€è®­ç»ƒ U å½¢ç½‘ç»œæˆ–è¯­è¨€å¤§æ¨¡å‹ã€‚</li><li>æå‡ºæ—¶é—´æ„ŸçŸ¥è¯­ä¹‰è¿æ¥å™¨ (TSC)ï¼ŒåŠ¨æ€ä»è¯­è¨€å¤§æ¨¡å‹ä¸­æå–ä¸æ—¶é—´æ­¥é•¿ç›¸å…³çš„æ¡ä»¶ã€‚</li><li>åœ¨å»å™ªè¿‡ç¨‹çš„ä¸åŒé˜¶æ®µï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´è¯­ä¹‰ç‰¹å¾ï¼Œå¸®åŠ©æ‰©æ•£æ¨¡å‹éšç€é‡‡æ ·æ—¶é—´æ­¥é•¿è§£é‡Šå†—é•¿å¤æ‚æç¤ºã€‚</li><li>ELLA å¯ä»¥è½»æ¾ä¸ç¤¾åŒºæ¨¡å‹å’Œå·¥å…·é›†æˆï¼Œæå‡å…¶æç¤ºéµå¾ªèƒ½åŠ›ã€‚</li><li>å¼•å…¥å¯†é›†æç¤ºå›¾åŸºå‡† (DPG-Bench)ï¼Œç”¨äºè¯„ä¼°æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨å¯†é›†æç¤ºéµå¾ªæ–¹é¢çš„è¡¨ç°ã€‚</li><li>å¹¿æ³›å®éªŒéªŒè¯äº† ELLA åœ¨å¯†é›†æç¤ºéµå¾ªæ–¹é¢çš„ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤šç§å±æ€§å’Œå…³ç³»çš„å¤šå¯¹è±¡ç»„åˆä¸­ã€‚</li><li>ELLA åœ¨ä¿æŒç”Ÿæˆå›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œæå‡äº†å®šé‡å’Œå®šæ€§è¯„ä¼°çš„æ–‡æœ¬å¯¹é½åˆ†æ•°ã€‚</li><li>ELLA å°†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸è¯­è¨€å¤§æ¨¡å‹ç›¸ç»“åˆï¼Œæ¢ç´¢äº†æ–‡æœ¬å’Œå›¾åƒç”Ÿæˆä¹‹é—´çš„æ½œåœ¨è”ç³»ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>è®ºæ–‡æ ‡é¢˜ï¼šELLAï¼šä½¿ç”¨ LLM ä¸ºæ‰©æ•£æ¨¡å‹èµ‹èƒ½ä»¥å¢å¼ºè¯­ä¹‰å¯¹é½</li><li>ä½œè€…ï¼šèƒ¡é”¡å¨ã€ç‹ç‘ã€æ–¹ä¸€æ™“ã€ä»˜æ–Œã€ç¨‹åŸ¹ã€äºé’¢</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè…¾è®¯</li><li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€å¤§è¯­è¨€æ¨¡å‹ã€æ–‡æœ¬-å›¾åƒå¯¹é½</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://ella-diffusion.github.ioï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°å¹¿æ³›ä½¿ç”¨çš„æ¨¡å‹ä»ç„¶ä½¿ç”¨ CLIP ä½œä¸ºå…¶æ–‡æœ¬ç¼–ç å™¨ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬ç†è§£åŒ…å«å¤šä¸ªå¯¹è±¡ã€è¯¦ç»†å±æ€§ã€å¤æ‚å…³ç³»ã€é•¿æ–‡æœ¬å¯¹é½ç­‰å†…å®¹çš„å¯†é›†æç¤ºçš„èƒ½åŠ›ã€‚ ï¼ˆ2ï¼‰å·²æœ‰æ–¹æ³•åŠé—®é¢˜ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº† ELLAï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹é€‚é…å™¨ï¼Œå®ƒä¸ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹é…å¤‡äº†å¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ (LLM)ï¼Œä»¥å¢å¼ºæ–‡æœ¬å¯¹é½ï¼Œè€Œæ— éœ€è®­ç»ƒ U-Net æˆ– LLMã€‚ ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†æ— ç¼æ¡¥æ¥ä¸¤ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œæœ¬æ–‡ç ”ç©¶äº†ä¸€ç³»åˆ—è¯­ä¹‰å¯¹é½è¿æ¥å™¨è®¾è®¡ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ¨¡å—ï¼Œå³ TimeStep-Aware è¯­ä¹‰è¿æ¥å™¨ (TSC)ï¼Œå®ƒåŠ¨æ€åœ°ä» LLM ä¸­æå–ä¸æ—¶é—´æ­¥é•¿ç›¸å…³çš„æ¡ä»¶ã€‚ ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å¯†é›†æç¤ºè·Ÿéšä»»åŠ¡ä¸­å±•ç¤ºäº†ä¼˜äºæœ€å…ˆè¿›æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠä¸åŒå±æ€§å’Œå…³ç³»çš„å¤šä¸ªå¯¹è±¡ç»„åˆä¸­ã€‚</li></ol><p>7.æ–¹æ³•ï¼š ï¼ˆ1ï¼‰ï¼šè®¾è®¡ELLAæ¶æ„ï¼Œåˆ©ç”¨LLMçš„è¯­è¨€ç†è§£èƒ½åŠ›å’Œæ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆæ½œåŠ›ï¼Œé‡‡ç”¨TimeStep-Awareè¯­ä¹‰è¿æ¥å™¨ï¼ˆTSCï¼‰æ— ç¼è¿æ¥ä¸¤ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼› ï¼ˆ2ï¼‰ï¼šæ„å»ºæ•°æ®é›†ï¼Œé‡‡ç”¨CogVLMè‡ªåŠ¨ç”Ÿæˆå›¾åƒæè¿°ï¼Œæé«˜å›¾åƒä¸æ–‡æœ¬çš„ç›¸å…³æ€§å’Œè¯­ä¹‰ä¿¡æ¯çš„å¯†åº¦ï¼› ï¼ˆ3ï¼‰ï¼šæ„å»ºåŸºå‡†æµ‹è¯•ï¼Œæå‡ºå¯†é›†æç¤ºå›¾è°±åŸºå‡†ï¼ˆDPG-Benchï¼‰ï¼Œæä¾›æ›´é•¿ã€æ›´å…·ä¿¡æ¯é‡çš„æç¤ºï¼Œå…¨é¢è¯„ä¼°ç”Ÿæˆæ¨¡å‹éµå¾ªå¯†é›†æç¤ºçš„èƒ½åŠ›ã€‚</p><p>8.ç»“è®ºï¼š (1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹é€‚é…å™¨ELLAï¼Œè¯¥é€‚é…å™¨é€šè¿‡TimeStep-Awareè¯­ä¹‰è¿æ¥å™¨å°†å¤§è¯­è¨€æ¨¡å‹ä¸æ‰©æ•£æ¨¡å‹æ— ç¼è¿æ¥ï¼Œå¢å¼ºäº†æ–‡æœ¬å¯¹é½ï¼Œåœ¨å¯†é›†æç¤ºè·Ÿéšä»»åŠ¡ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚ (2): åˆ›æ–°ç‚¹ï¼š * æå‡ºäº†ä¸€ç§æ–°çš„è¯­ä¹‰å¯¹é½è¿æ¥å™¨TSCï¼ŒåŠ¨æ€åœ°ä»å¤§è¯­è¨€æ¨¡å‹ä¸­æå–ä¸æ—¶é—´æ­¥é•¿ç›¸å…³çš„æ¡ä»¶ï¼Œå¢å¼ºäº†æ–‡æœ¬å’Œå›¾åƒä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚ * æ„å»ºäº†å¯†é›†æç¤ºå›¾è°±åŸºå‡†DPG-Benchï¼Œæä¾›æ›´é•¿ã€æ›´å…·ä¿¡æ¯é‡çš„æç¤ºï¼Œå…¨é¢è¯„ä¼°ç”Ÿæˆæ¨¡å‹éµå¾ªå¯†é›†æç¤ºçš„èƒ½åŠ›ã€‚ * é‡‡ç”¨CogVLMè‡ªåŠ¨ç”Ÿæˆå›¾åƒæè¿°ï¼Œæé«˜å›¾åƒä¸æ–‡æœ¬çš„ç›¸å…³æ€§å’Œè¯­ä¹‰ä¿¡æ¯çš„å¯†åº¦ã€‚ æ€§èƒ½ï¼š * åœ¨å¯†é›†æç¤ºè·Ÿéšä»»åŠ¡ä¸­ï¼ŒELLAåœ¨ç”Ÿæˆå›¾åƒçš„è¯­ä¹‰å¯¹é½å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ å·¥ä½œé‡ï¼š * ELLAçš„è®­ç»ƒå’Œéƒ¨ç½²ç›¸å¯¹é«˜æ•ˆï¼Œä¸éœ€è¦è®­ç»ƒU-Netæˆ–å¤§è¯­è¨€æ¨¡å‹ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4cf50b2bd0a34d7b9b26b53c13b5a923.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-fc587ddf93c75ebf159a0c6b73925633.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-a0b7496441cb8c23d5d6a09243c13c67.jpg" align="middle"></details>## CogView3: Finer and Faster Text-to-Image Generation via Relay Diffusion **Authors:Wendi Zheng, Jiayan Teng, Zhuoyi Yang, Weihan Wang, Jidong Chen, Xiaotao Gu, Yuxiao Dong, Ming Ding, Jie Tang** Recent advancements in text-to-image generative systems have been largely driven by diffusion models. However, single-stage text-to-image diffusion models still face challenges, in terms of computational efficiency and the refinement of image details. To tackle the issue, we propose CogView3, an innovative cascaded framework that enhances the performance of text-to-image diffusion. CogView3 is the first model implementing relay diffusion in the realm of text-to-image generation, executing the task by first creating low-resolution images and subsequently applying relay-based super-resolution. This methodology not only results in competitive text-to-image outputs but also greatly reduces both training and inference costs. Our experimental results demonstrate that CogView3 outperforms SDXL, the current state-of-the-art open-source text-to-image diffusion model, by 77.0\% in human evaluations, all while requiring only about 1/2 of the inference time. The distilled variant of CogView3 achieves comparable performance while only utilizing 1/10 of the inference time by SDXL. [PDF](http://arxiv.org/abs/2403.05121v1) **Summary** CogView3ï¼Œä¸€ä¸ªçº§è”æ¡†æ¶ï¼Œå¼•å…¥æ¥åŠ›æ‰©æ•£ï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­å®ç°ä½åˆ†è¾¨ç‡åˆ°é«˜åˆ†è¾¨ç‡ï¼Œæé«˜æ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚ **Key Takeaways** - CogView3æå‡ºçº§è”æ¡†æ¶ï¼Œä½¿ç”¨æ¥åŠ›æ‰©æ•£ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚ - æ¥åŠ›æ‰©æ•£åˆ†æ­¥ç”Ÿæˆå›¾åƒï¼Œä»ä½åˆ†è¾¨ç‡åˆ°é«˜åˆ†è¾¨ç‡ï¼Œé™ä½è®­ç»ƒå’Œæ¨ç†æˆæœ¬ã€‚ - CogView3è¶…è¶ŠSDXLï¼Œäººç±»è¯„ä¼°å¾—åˆ†é«˜å‡º77.0%ï¼Œæ¨ç†æ—¶é—´å‡å°‘ä¸€åŠã€‚ - CogView3çš„ç²¾ç®€ç‰ˆæ€§èƒ½ç›¸å½“ï¼Œæ¨ç†æ—¶é—´ä»…ä¸ºSDXLçš„ååˆ†ä¹‹ä¸€ã€‚ - CogView3æé«˜äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡çš„æ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚ - CogView3 å¼•å…¥äº†æ¥åŠ›æ‰©æ•£çš„æ¦‚å¿µï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­å®ç°äº†åˆ†è¾¨ç‡çš„æ¸è¿›æå‡ã€‚ - çº§è”æ¡†æ¶å’Œæ¥åŠ›æ‰©æ•£çš„ç»“åˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¹³è¡¡å›¾åƒè´¨é‡å’Œè®¡ç®—æˆæœ¬ã€‚ **[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šCogView3ï¼šæ›´ç²¾ç»†ã€æ›´å¿«é€Ÿçš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ</li><li>ä½œè€…ï¼šWendi Zheng, Jiayan Teng, Zhuoyi Yang, Weihan Wang, Jidong Chen, Xiaotao Gu, Yuxiao Dong, Ming Ding, Jie Tang</li><li>å•ä½ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”ŸæˆÂ·æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05121</li><li><p>æ‘˜è¦ï¼š (1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹å·²æˆä¸ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿçš„ä¸»æµæ¡†æ¶ã€‚ç„¶è€Œï¼Œå•é˜¶æ®µæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨è®¡ç®—æ•ˆç‡å’Œå›¾åƒç»†èŠ‚ç²¾ç»†åŒ–æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚ (2) è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å¤§å¤šåœ¨é«˜å›¾åƒåˆ†è¾¨ç‡ä¸‹è¿›è¡Œæ‰©æ•£è¿‡ç¨‹ï¼Œè¿™å¯¼è‡´è®¡ç®—æˆæœ¬é«˜ã€å›¾åƒç»†èŠ‚ä¸å¤Ÿç²¾ç»†ã€‚ (3) æå‡ºæ–¹æ³•ï¼šæœ¬æ–‡æå‡º CogView3ï¼Œä¸€ä¸ªåˆ›æ–°çš„çº§è”æ¡†æ¶ï¼Œé€šè¿‡ä¸­ç»§æ‰©æ•£æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£çš„æ€§èƒ½ã€‚CogView3 æ˜¯ç¬¬ä¸€ä¸ªåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå®ç°ä¸­ç»§æ‰©æ•£çš„æ¨¡å‹ï¼Œå®ƒé€šè¿‡é¦–å…ˆåˆ›å»ºä½åˆ†è¾¨ç‡å›¾åƒï¼Œç„¶ååº”ç”¨åŸºäºä¸­ç»§çš„è¶…åˆ†è¾¨ç‡æ¥æ‰§è¡Œä»»åŠ¡ã€‚ (4) å®éªŒç»“æœï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒCogView3 åœ¨äººç±»è¯„ä¼°ä¸­æ¯”å½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ SDXL é«˜å‡º 77.0%ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´ä»…ä¸ºå…¶ä¸€åŠå·¦å³ã€‚CogView3 çš„è’¸é¦å˜ä½“åœ¨æ¨ç†æ—¶é—´ä»…ä¸º SDXL çš„ 1/10 çš„æƒ…å†µä¸‹å®ç°äº†å¯æ¯”çš„æ€§èƒ½ã€‚</p></li><li><p>æ–¹æ³•ï¼š ï¼ˆ1ï¼‰æ–‡æœ¬é¢„å¤„ç†å›¾åƒé‡è¿°ï¼šåˆ©ç”¨ GPT-4V è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®é›†å›¾åƒçš„é‡è¿°æ–‡æœ¬ï¼Œå¹¶å¾®è°ƒ CogVLM-17B ä»¥è·å¾—é‡è¿°æ¨¡å‹ï¼› ï¼ˆ2ï¼‰æç¤ºæ‰©å±•ï¼šåˆ©ç”¨è¯­è¨€æ¨¡å‹å°†ç”¨æˆ·æç¤ºæ‰©å±•ä¸ºæ›´å…¨é¢çš„æè¿°ï¼Œä»¥å‡å°‘è®­ç»ƒå’Œæ¨ç†ä¹‹é—´çš„ä¸ä¸€è‡´ï¼› ï¼ˆ3ï¼‰æ¨¡å‹æ„å»ºï¼šCogView3 é‡‡ç”¨ 3 çº§ UNet æ¶æ„çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨é¢„è®­ç»ƒçš„ T5-XXL ç¼–ç å™¨ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼› ï¼ˆ4ï¼‰è®­ç»ƒç®¡é“ï¼šä½¿ç”¨ Laion-2B æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå¹¶é‡‡ç”¨æ¸è¿›è®­ç»ƒç­–ç•¥ä»¥é™ä½è®­ç»ƒæˆæœ¬ï¼› ï¼ˆ5ï¼‰ä¸­ç»§è¶…åˆ†è¾¨ç‡ï¼šåœ¨æ½œåœ¨ç©ºé—´ä¸­å®ç°ä¸­ç»§è¶…åˆ†è¾¨ç‡ï¼Œä½¿ç”¨çº¿æ€§å˜æ¢ä»£æ›¿åŸå§‹çš„å±€éƒ¨æ¨¡ç³Šï¼› ï¼ˆ6ï¼‰é‡‡æ ·å™¨æ„å»ºï¼šè®¾è®¡äº†ä¸ä¸­ç»§è¶…åˆ†è¾¨ç‡ç›¸ä¸€è‡´çš„é‡‡æ ·å™¨ï¼Œå¹¶ä½¿ç”¨ DDIM èŒƒå¼è¿›è¡Œé‡‡æ ·ï¼› ï¼ˆ7ï¼‰ä¸­ç»§æ‰©æ•£çš„è’¸é¦ï¼šå°†æ¸è¿›è’¸é¦æ–¹æ³•ä¸ä¸­ç»§æ‰©æ•£æ¡†æ¶ç›¸ç»“åˆï¼Œä»¥è·å¾— CogView3 çš„è’¸é¦ç‰ˆæœ¬ã€‚</p></li><li><p>ç»“è®º (1): æœ¬å·¥ä½œæå‡ºäº† CogView3ï¼Œè¿™æ˜¯ç»§ç”µæ‰©æ•£æ¡†æ¶ä¸­ç¬¬ä¸€ä¸ªæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿã€‚CogView3 ä»¥æå¤§é™ä½çš„æ¨ç†æˆæœ¬å®ç°äº†ä¼˜è‰¯çš„ç”Ÿæˆè´¨é‡ï¼Œè¿™ä¸»è¦å½’åŠŸäºä¸­ç»§ç®¡é“ã€‚é€šè¿‡è¿­ä»£å®ç° CogView3 çš„è¶…åˆ†è¾¨ç‡é˜¶æ®µï¼Œæˆ‘ä»¬èƒ½å¤Ÿå®ç°æé«˜åˆ†è¾¨ç‡ï¼ˆå¦‚ 2048Ã—2048ï¼‰çš„é«˜è´¨é‡å›¾åƒã€‚åŒæ—¶ï¼Œéšç€æ•°æ®é‡æ–°æè¿°å’Œæç¤ºæ‰©å±•è¢«çº³å…¥æ¨¡å‹ç®¡é“ï¼Œä¸å½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼ŒCogView3 åœ¨æç¤ºç†è§£å’ŒæŒ‡ä»¤éµå¾ªæ–¹é¢å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜æ¢ç´¢äº† CogView3 çš„è’¸é¦ï¼Œå¹¶å±•ç¤ºäº†å…¶å½’åŠŸäºç»§ç”µæ‰©æ•£æ¡†æ¶çš„ç®€å•æ€§å’Œèƒ½åŠ›ã€‚åˆ©ç”¨æ¸è¿›è’¸é¦èŒƒä¾‹ï¼ŒCogView3 çš„è’¸é¦å˜ä½“å¤§å¹…å‡å°‘äº†æ¨ç†æ—¶é—´ï¼ŒåŒæ—¶ä»ä¿æŒäº†ç›¸å½“çš„æ€§èƒ½ã€‚ (2): åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§æ–°çš„çº§è”æ¡†æ¶ CogView3ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä¸­ç»§æ‰©æ•£å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£çš„æ€§èƒ½ã€‚</li><li>è®¾è®¡äº†ä¸€ç§ä¸­ç»§è¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡Œè¶…åˆ†è¾¨ç‡ï¼Œå¹¶ä½¿ç”¨çº¿æ€§å˜æ¢ä»£æ›¿åŸå§‹çš„å±€éƒ¨æ¨¡ç³Šã€‚</li><li>æ¢ç´¢äº†æ•°æ®é‡æ–°æè¿°å’Œæç¤ºæ‰©å±•ï¼Œä»¥æé«˜æ¨¡å‹å¯¹æç¤ºçš„ç†è§£å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚ æ€§èƒ½ï¼š</li><li>åœ¨äººç±»è¯„ä¼°ä¸­ï¼ŒCogView3 æ¯”å½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ SDXL é«˜å‡º 77.0%ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´ä»…ä¸ºå…¶ä¸€åŠå·¦å³ã€‚</li><li>CogView3 çš„è’¸é¦å˜ä½“åœ¨æ¨ç†æ—¶é—´ä»…ä¸º SDXL çš„ 1/10 çš„æƒ…å†µä¸‹å®ç°äº†å¯æ¯”çš„æ€§èƒ½ã€‚</li><li>CogView3 èƒ½å¤Ÿç”Ÿæˆæé«˜åˆ†è¾¨ç‡ï¼ˆå¦‚ 2048Ã—2048ï¼‰çš„é«˜è´¨é‡å›¾åƒã€‚ å·¥ä½œé‡ï¼š</li><li>CogView3 çš„è®­ç»ƒç®¡é“ç›¸å¯¹ç®€å•ï¼Œé‡‡ç”¨æ¸è¿›è®­ç»ƒç­–ç•¥ä»¥é™ä½è®­ç»ƒæˆæœ¬ã€‚</li><li>CogView3 çš„è’¸é¦å˜ä½“è¿›ä¸€æ­¥é™ä½äº†æ¨ç†æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒäº†å¯æ¯”çš„æ€§èƒ½ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-39c07129df4e18479bf6f2000e3bd45b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3130242f65670e2f9a99c29710ffccef.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-a4b8e0b9de2b5980d7c1d4c49daded3b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3e7d124475c2a36f974604208e23b856.jpg" align="middle"></details><h2 id="Face2Diffusion-for-Fast-and-Editable-Face-Personalization"><a href="#Face2Diffusion-for-Fast-and-Editable-Face-Personalization" class="headerlink" title="Face2Diffusion for Fast and Editable Face Personalization"></a>Face2Diffusion for Fast and Editable Face Personalization</h2><p><strong>Authors:Kaede Shiohara, Toshihiko Yamasaki</strong></p><p>Face personalization aims to insert specific faces, taken from images, into pretrained text-to-image diffusion models. However, it is still challenging for previous methods to preserve both the identity similarity and editability due to overfitting to training samples. In this paper, we propose Face2Diffusion (F2D) for high-editability face personalization. The core idea behind F2D is that removing identity-irrelevant information from the training pipeline prevents the overfitting problem and improves editability of encoded faces. F2D consists of the following three novel components: 1) Multi-scale identity encoder provides well-disentangled identity features while keeping the benefits of multi-scale information, which improves the diversity of camera poses. 2) Expression guidance disentangles face expressions from identities and improves the controllability of face expressions. 3) Class-guided denoising regularization encourages models to learn how faces should be denoised, which boosts the text-alignment of backgrounds. Extensive experiments on the FaceForensics++ dataset and diverse prompts demonstrate our method greatly improves the trade-off between the identity- and text-fidelity compared to previous state-of-the-art methods.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.05094v1">PDF</a> CVPR2024. Code: <a target="_blank" rel="noopener" href="https://github.com/mapooon/Face2Diffusion">https://github.com/mapooon/Face2Diffusion</a>, Webpage: <a target="_blank" rel="noopener" href="https://mapooon.github.io/Face2DiffusionPage/">https://mapooon.github.io/Face2DiffusionPage/</a></p><p><strong>Summary</strong><br>äººè„¸ä¸ªæ€§åŒ–é€šè¿‡æ¤å…¥ä»å›¾ç‰‡è·å–çš„äººè„¸æ¥å®ç°é¢„å…ˆè®­ç»ƒçš„æ–‡è½¬å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ä»è®­ç»ƒç®¡é“ä¸­å»é™¤ä¸äººè„¸æ— å…³çš„ä¿¡æ¯æœ‰åŠ©äºæå‡ç¼–è¾‘èƒ½åŠ›ã€‚</li><li>å¤šå°ºåº¦äººè„¸ç¼–ç å™¨æä¾›äº†æ¸…æ™°åˆ†ç¦»çš„äººè„¸ç‰¹å¾ã€‚</li><li>è¡¨æƒ…æŒ‡å¯¼å°†äººè„¸è¡¨æƒ…ä¸äººè„¸èº«ä»½è¿›è¡Œåˆ†ç¦»ã€‚</li><li>ç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–å¢å¼ºæ¨¡å‹å¯¹äººè„¸å»å™ªçš„å­¦ä¹ ã€‚</li><li>è·¨æ•°æ®é›†å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æå‡äº†èº«ä»½ä¿çœŸåº¦ä¸æ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´çš„å¹³è¡¡ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šFace2Diffusionï¼šå¿«é€Ÿä¸”å¯ç¼–è¾‘çš„äººè„¸ä¸ªæ€§åŒ–</li><li>ä½œè€…ï¼šKaede Shiohara, Toshihiko Yamasaki</li><li>å•ä½ï¼šä¸œäº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šFace personalization, Text-to-image diffusion model, Identity preservation, Editability</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05094</li><li><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å°†ç‰¹å®šäººè„¸æ’å…¥é¢„è®­ç»ƒæ¨¡å‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œæ—¢è¦ä¿æŒèº«ä»½ç›¸ä¼¼æ€§ï¼Œåˆè¦ä¿è¯å¯ç¼–è¾‘æ€§ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•å®¹æ˜“è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ ·æœ¬ï¼Œå¯¼è‡´èº«ä»½ç›¸ä¼¼æ€§å’Œå¯ç¼–è¾‘æ€§ä¹‹é—´çš„æƒè¡¡ã€‚ ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šFace2Diffusionï¼ˆF2Dï¼‰é€šè¿‡ä»è®­ç»ƒç®¡é“ä¸­å»é™¤ä¸èº«ä»½æ— å…³çš„ä¿¡æ¯æ¥è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œæé«˜ç¼–ç äººè„¸çš„å¯ç¼–è¾‘æ€§ã€‚F2DåŒ…å«ä¸‰ä¸ªæ–°é¢–çš„ç»„ä»¶ï¼šå¤šå°ºåº¦èº«ä»½ç¼–ç å™¨ã€è¡¨æƒ…å¼•å¯¼å™¨å’Œç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–ã€‚ ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šåœ¨ FaceForensics++ æ•°æ®é›†å’Œå„ç§æç¤ºä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒF2D åœ¨èº«ä»½å’Œæ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡æ–¹é¢æ˜æ˜¾ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</p></li><li><p>æ–¹æ³•ï¼š (1) å¤šå°ºåº¦èº«ä»½ç¼–ç å™¨ï¼šä»äººè„¸å›¾åƒä¸­æå–å¤šå°ºåº¦ç‰¹å¾ï¼Œä¿ç•™èº«ä»½ä¿¡æ¯ï¼Œé™ä½è¿‡åº¦æ‹Ÿåˆé£é™©ã€‚ (2) è¡¨æƒ…å¼•å¯¼å™¨ï¼šæŒ‡å¯¼æ‰©æ•£æ¨¡å‹å…³æ³¨äººè„¸è¡¨æƒ…çš„ç¼–è¾‘ï¼Œæé«˜å¯ç¼–è¾‘æ€§ã€‚ (3) ç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–ï¼šå¼•å…¥ç±»åˆ«ä¿¡æ¯ï¼Œé˜²æ­¢æ¨¡å‹ä»æ— å…³å™ªå£°ä¸­å­¦ä¹ ï¼Œæé«˜èº«ä»½ä¿çœŸåº¦ã€‚</p></li></ol><p><strong>8. ç»“è®º</strong></p><p><strong>(1): æ­¤é¡¹å·¥ä½œçš„æ„ä¹‰</strong></p><p>Face2Diffusion æå‡ºäº†ä¸€ç§å¯ç¼–è¾‘çš„äººè„¸ä¸ªæ€§åŒ–æ–¹æ³•ï¼Œé€šè¿‡è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œæé«˜äº†ç”Ÿæˆäººè„¸çš„å¯ç¼–è¾‘æ€§ï¼Œåœ¨èº«ä»½ä¿çœŸåº¦å’Œæ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</p><p><strong>(2): æœ¬æ–‡ä¼˜ç¼ºç‚¹æ€»ç»“ï¼ˆä¸‰ä¸ªç»´åº¦ï¼šåˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡ï¼‰</strong></p><p><strong>åˆ›æ–°ç‚¹ï¼š</strong></p><ul><li>å¤šå°ºåº¦èº«ä»½ç¼–ç å™¨ï¼šæå–å¤šå°ºåº¦ç‰¹å¾ï¼Œé™ä½è¿‡åº¦æ‹Ÿåˆé£é™©ã€‚</li><li>è¡¨æƒ…å¼•å¯¼å™¨ï¼šæŒ‡å¯¼æ‰©æ•£æ¨¡å‹å…³æ³¨äººè„¸è¡¨æƒ…çš„ç¼–è¾‘ã€‚</li><li>ç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–ï¼šé˜²æ­¢æ¨¡å‹ä»æ— å…³å™ªå£°ä¸­å­¦ä¹ ã€‚</li></ul><p><strong>æ€§èƒ½ï¼š</strong></p><ul><li>åœ¨èº«ä»½ä¿çœŸåº¦å’Œæ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</li><li>åœ¨å„ç§æç¤ºå’Œäººè„¸æ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li></ul><p><strong>å·¥ä½œé‡ï¼š</strong></p><ul><li>è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤šå°ºåº¦ç‰¹å¾æå–å’Œæ­£åˆ™åŒ–ç­–ç•¥ã€‚</li><li>ç”Ÿæˆå•ä¸ªå›¾åƒæ‰€éœ€çš„æ—¶é—´ä¸å…¶ä»–æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç±»ä¼¼ã€‚</li></ul><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-a4d3199be75c4ed763ad12e5fd6fd186.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-073fc885846ed7841fbefca59dc75bb8.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c2c9194bd5afd5f761cca65c865fe0fb.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-b6ba7d02ff97010b563089ea86c62c6b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-8bdf1923916c837b5df8251aa84ce58b.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-d5d8555605f33ef6be1a8b7ab0be10cc.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-302c4a1ee77cbdfd8dba69c7d6a94497.jpg" align="middle"></details>## Spectrum Translation for Refinement of Image Generation (STIG) Based on Contrastive Learning and Spectral Filter Profile **Authors:Seokjun Lee, Seung-Won Jung, Hyunseok Seo** Currently, image generation and synthesis have remarkably progressed with generative models. Despite photo-realistic results, intrinsic discrepancies are still observed in the frequency domain. The spectral discrepancy appeared not only in generative adversarial networks but in diffusion models. In this study, we propose a framework to effectively mitigate the disparity in frequency domain of the generated images to improve generative performance of both GAN and diffusion models. This is realized by spectrum translation for the refinement of image generation (STIG) based on contrastive learning. We adopt theoretical logic of frequency components in various generative networks. The key idea, here, is to refine the spectrum of the generated image via the concept of image-to-image translation and contrastive learning in terms of digital signal processing. We evaluate our framework across eight fake image datasets and various cutting-edge models to demonstrate the effectiveness of STIG. Our framework outperforms other cutting-edges showing significant decreases in FID and log frequency distance of spectrum. We further emphasize that STIG improves image quality by decreasing the spectral anomaly. Additionally, validation results present that the frequency-based deepfake detector confuses more in the case where fake spectrums are manipulated by STIG. [PDF](http://arxiv.org/abs/2403.05093v1) Accepted to AAAI 2024 **Summary** ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹ä¸­é¢‘åŸŸå·®å¼‚é—®é¢˜ï¼Œå¯é€šè¿‡é¢‘è°±å¯¹æ¯”å­¦ä¹ ä¸‹çš„å›¾åƒç”Ÿæˆè°±è½¬æ¢æ¡†æ¶ï¼ˆSTIGï¼‰æœ‰æ•ˆè§£å†³ã€‚ **Key Takeaways** * æå‡ºSTIGæ¡†æ¶å‡è½»ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹å›¾åƒé¢‘åŸŸå·®å¼‚ã€‚ * STIGåŸºäºå›¾åƒåˆ°å›¾åƒè½¬æ¢å’Œå¯¹ç…§å­¦ä¹ ï¼Œä¼˜åŒ–ç”Ÿæˆå›¾åƒé¢‘è°±ã€‚ * STIGåœ¨å…«ä¸ªä¼ªé€ å›¾åƒæ•°æ®é›†ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæ˜¾ç€é™ä½FIDå’Œå…‰è°±çš„å¯¹æ•°é¢‘ç‡è·ç¦»ã€‚ * STIGé€šè¿‡å‡å°å…‰è°±å¼‚å¸¸æé«˜å›¾åƒè´¨é‡ã€‚ * ç»è¿‡STIGå¤„ç†çš„ä¼ªé€ å›¾åƒä¼šè¿·æƒ‘åŸºäºé¢‘ç‡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨ã€‚ * STIGä½¿ç”¨é¢‘è°±è½¬æ¢æœ‰æ•ˆè§£å†³ç”Ÿæˆæ¨¡å‹ä¸­é¢‘åŸŸå·®å¼‚é—®é¢˜ã€‚ * STIGæå‡å›¾åƒç”Ÿæˆè´¨é‡ï¼Œå¢å¼ºå¯¹æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨çš„é²æ£’æ€§ã€‚ **[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šå›¾åƒç”Ÿæˆç²¾ç‚¼çš„å…‰è°±è½¬æ¢ï¼ˆSTIGï¼‰</li><li>ä½œè€…ï¼šSeokjun Leeã€Seung-Won Jungã€Hyunseok Seo</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯ç ”ç©¶é™¢ç”Ÿç‰©åŒ»å­¦ç ”ç©¶éƒ¨</li><li>å…³é”®è¯ï¼šå›¾åƒç”Ÿæˆã€å…‰è°±è½¬æ¢ã€å¯¹æ¯”å­¦ä¹ ã€é¢‘è°±æ»¤æ³¢å™¨è½®å»“</li><li>è®ºæ–‡é“¾æ¥ï¼šNone Github ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š ç›®å‰ï¼Œå›¾åƒç”Ÿæˆå’Œåˆæˆåœ¨ç”Ÿæˆæ¨¡å‹çš„å¸®åŠ©ä¸‹å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚å°½ç®¡ç”Ÿæˆç»“æœé€¼çœŸï¼Œä½†åœ¨é¢‘åŸŸä¸­ä»ç„¶å­˜åœ¨å›ºæœ‰çš„å·®å¼‚ã€‚è¿™ç§é¢‘è°±å·®å¼‚ä¸ä»…å‡ºç°åœ¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä¸­ï¼Œè¿˜å‡ºç°åœ¨æ‰©æ•£æ¨¡å‹ä¸­ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š ä»¥å¾€çš„ç ”ç©¶æå‡ºäº†é€šè¿‡ä¿®æ”¹ç”Ÿæˆç½‘ç»œæ¶æ„æˆ–ç›®æ ‡å‡½æ•°æ¥å¼¥è¡¥é¢‘åŸŸå·®å¼‚çš„æ–¹æ³•ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´ã€‚ ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„å…‰è°±è½¬æ¢æ¡†æ¶ï¼ˆSTIGï¼‰ï¼Œç”¨äºæœ‰æ•ˆå‡è½»ç”Ÿæˆå›¾åƒé¢‘åŸŸä¸­çš„å·®å¼‚ï¼Œä»¥æé«˜ GAN å’Œæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ€§èƒ½ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†æ•°å­—ä¿¡å·å¤„ç†ä¸­å›¾åƒåˆ°å›¾åƒè½¬æ¢å’Œå¯¹æ¯”å­¦ä¹ çš„æ¦‚å¿µæ¥ä¼˜åŒ–ç”Ÿæˆå›¾åƒçš„å…‰è°±ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š åœ¨å…«ä¸ªå‡å›¾åƒæ•°æ®é›†å’Œå„ç§å‰æ²¿æ¨¡å‹ä¸Šè¯„ä¼°äº† STIG çš„æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ï¼ŒSTIG ä¼˜äºå…¶ä»–å‰æ²¿æ–¹æ³•ï¼Œåœ¨ FID å’Œå…‰è°±å¯¹æ•°é¢‘ç‡è·ç¦»æ–¹é¢æœ‰æ˜¾è‘—ä¸‹é™ã€‚æ­¤å¤–ï¼ŒSTIG é€šè¿‡å‡å°‘å…‰è°±å¼‚å¸¸æ¥æé«˜å›¾åƒè´¨é‡ã€‚éªŒè¯ç»“æœè¡¨æ˜ï¼Œå½“ STIG å¤„ç†è™šå‡å…‰è°±æ—¶ï¼ŒåŸºäºé¢‘ç‡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨æ›´å®¹æ˜“æ··æ·†ã€‚</li></ol><p>7.Methodsï¼š ï¼ˆ1ï¼‰STIGæ¡†æ¶æ¦‚è¿°ï¼šSTIGæ¡†æ¶ç”±ä¸‰ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼šå›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œï¼ˆI2Iï¼‰ã€å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’Œé¢‘è°±æ»¤æ³¢å™¨è½®å»“ï¼ˆSFPï¼‰ã€‚ ï¼ˆ2ï¼‰å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œï¼ˆI2Iï¼‰ï¼šI2Iç½‘ç»œé‡‡ç”¨U-Netæ¶æ„ï¼Œç”¨äºå°†ç”Ÿæˆå›¾åƒä»æºé¢‘åŸŸè½¬æ¢åˆ°ç›®æ ‡é¢‘åŸŸã€‚ ï¼ˆ3ï¼‰å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼šå¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°åŸºäºå›¾åƒå¯¹çš„ç›¸ä¼¼æ€§å’Œå·®å¼‚æ€§ï¼Œé€šè¿‡æœ€å¤§åŒ–ç›¸ä¼¼å›¾åƒçš„ç‰¹å¾è¡¨ç¤ºä¹‹é—´çš„ç›¸å…³æ€§ï¼ŒåŒæ—¶æœ€å°åŒ–ä¸åŒå›¾åƒçš„ç‰¹å¾è¡¨ç¤ºä¹‹é—´çš„ç›¸å…³æ€§ï¼Œæ¥ä¼˜åŒ–I2Iç½‘ç»œã€‚ ï¼ˆ4ï¼‰é¢‘è°±æ»¤æ³¢å™¨è½®å»“ï¼ˆSFPï¼‰ï¼šSFPæ˜¯ä¸€ä¸ªé¢„å…ˆè®­ç»ƒçš„é¢‘è°±æ»¤æ³¢å™¨é›†åˆï¼Œç”¨äºæŒ‡å¯¼I2Iç½‘ç»œå­¦ä¹ ç›®æ ‡é¢‘åŸŸçš„ç‰¹å¾åˆ†å¸ƒã€‚ ï¼ˆ5ï¼‰STIGè®­ç»ƒè¿‡ç¨‹ï¼šSTIGæ¡†æ¶çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šé¢„è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼ŒI2Iç½‘ç»œä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’ŒSFPè¿›è¡Œè®­ç»ƒã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼ŒI2Iç½‘ç»œä½¿ç”¨ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å¯¹æŠ—æ€§æŸå¤±å‡½æ•°è¿›è¡Œå¾®è°ƒã€‚</p><ol><li>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† STIG æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç›´æ¥æ“ä½œç”Ÿæˆå›¾åƒçš„é¢‘ç‡åˆ†é‡ï¼Œåœ¨é¢‘åŸŸä¸­å‡å°‘ç”Ÿæˆå›¾åƒçš„å…‰è°±å·®å¼‚ï¼Œä»è€Œæé«˜ç”Ÿæˆæ€§èƒ½ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š STIG æ¡†æ¶åœ¨é¢‘åŸŸä¸­ç›´æ¥æ“ä½œç”Ÿæˆå›¾åƒï¼Œä»¥å‡å°‘ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„å…‰è°±å·®å¼‚ã€‚ STIG æ¡†æ¶é‡‡ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’Œé¢‘è°±æ»¤æ³¢å™¨è½®å»“ï¼Œä¼˜åŒ–å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹ã€‚ STIG æ¡†æ¶å¯ä»¥æœ‰æ•ˆåœ°æé«˜ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ€§èƒ½ã€‚ æ€§èƒ½ï¼š STIG æ¡†æ¶åœ¨å…«ä¸ªå‡å›¾åƒåŸºå‡†ä¸Šå‡ä¼˜äºå…¶ä»–å‰æ²¿æ–¹æ³•ï¼Œåœ¨ FID å’Œå…‰è°±å¯¹æ•°é¢‘ç‡è·ç¦»æ–¹é¢æœ‰æ˜¾è‘—ä¸‹é™ã€‚ STIG æ¡†æ¶é€šè¿‡å‡å°‘å…‰è°±å¼‚å¸¸æ¥æé«˜å›¾åƒè´¨é‡ã€‚ STIG æ¡†æ¶å¤„ç†è™šå‡å…‰è°±æ—¶ï¼ŒåŸºäºé¢‘ç‡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨æ›´å®¹æ˜“æ··æ·†ã€‚ å·¥ä½œé‡ï¼š STIG æ¡†æ¶çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬é¢„è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µã€‚ é¢„è®­ç»ƒé˜¶æ®µéœ€è¦å¯¹å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’Œé¢‘è°±æ»¤æ³¢å™¨è½®å»“è¿›è¡Œè®­ç»ƒã€‚ å¾®è°ƒé˜¶æ®µéœ€è¦å¯¹å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œä½¿ç”¨ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å¯¹æŠ—æ€§æŸå¤±å‡½æ•°è¿›è¡Œå¾®è°ƒã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-59b9082b16c536f6e3dc82d3eedb0929.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-cc9ad99c3613618bd289ca6d732974f2.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ed21a9f11c14097979acb60a01fc0faa.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-ee45629a830dd20e3e691c354e6c5761.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-82896ffced53d8bc120b544471040628.jpg" align="middle"></details><h2 id="Improving-Diffusion-Based-Generative-Models-via-Approximated-Optimal-Transport"><a href="#Improving-Diffusion-Based-Generative-Models-via-Approximated-Optimal-Transport" class="headerlink" title="Improving Diffusion-Based Generative Models via Approximated Optimal   Transport"></a>Improving Diffusion-Based Generative Models via Approximated Optimal Transport</h2><p><strong>Authors:Daegyu Kim, Jooyoung Choi, Chaehun Shin, Uiwon Hwang, Sungroh Yoon</strong></p><p>We introduce the Approximated Optimal Transport (AOT) technique, a novel training scheme for diffusion-based generative models. Our approach aims to approximate and integrate optimal transport into the training process, significantly enhancing the ability of diffusion models to estimate the denoiser outputs accurately. This improvement leads to ODE trajectories of diffusion models with lower curvature and reduced truncation errors during sampling. We achieve superior image quality and reduced sampling steps by employing AOT in training. Specifically, we achieve FID scores of 1.88 with just 27 NFEs and 1.73 with 29 NFEs in unconditional and conditional generations, respectively. Furthermore, when applying AOT to train the discriminator for guidance, we establish new state-of-the-art FID scores of 1.68 and 1.58 for unconditional and conditional generations, respectively, each with 29 NFEs. This outcome demonstrates the effectiveness of AOT in enhancing the performance of diffusion models.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.05069v1">PDF</a></p><p><strong>æ‘˜è¦</strong><br>é€šè¿‡è¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯æå‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ•ˆæœï¼Œé™ä½é‡‡æ ·è¯¯å·®ï¼Œæå‡å›¾åƒè´¨é‡ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>æå‡ºè¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯ï¼Œæ”¹è¿›æ‰©æ•£æ¨¡å‹è®­ç»ƒã€‚</li><li>AOT æŠ€æœ¯å°†æœ€ä¼˜ä¼ è¾“æ•´åˆåˆ°æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼Œæå‡å»å™ªè¾“å‡ºå‡†ç¡®æ€§ã€‚</li><li>ä¼˜åŒ–åçš„æ‰©æ•£è½¨è¿¹æ›²ç‡é™ä½ï¼Œé‡‡æ ·æˆªæ–­è¯¯å·®å‡å°ã€‚</li><li>é‡‡ç”¨ AOT è®­ç»ƒï¼Œå›¾åƒè´¨é‡æå‡ï¼Œé‡‡æ ·æ­¥éª¤å‡å°‘ã€‚</li><li>æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œ27 æ¬¡è¯ºç¦å…‹åºåˆ—ï¼ˆNFEï¼‰ï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.88ï¼›29 æ¬¡ NFEï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.73ã€‚</li><li>æ¡ä»¶ç”Ÿæˆä¸­ï¼Œ29 æ¬¡ NFEï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.68ï¼›æŒ‡å¯¼åˆ¤åˆ«å™¨è®­ç»ƒï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.58ã€‚</li><li>AOT æŠ€æœ¯æœ‰æ•ˆæå‡äº†æ‰©æ•£æ¨¡å‹æ€§èƒ½ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šé€šè¿‡è¿‘ä¼¼æœ€ä¼˜ä¼ è¾“æ”¹è¿›åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹</li><li>ä½œè€…ï¼šDaegyu Kimã€Jooyoung Choiã€Chaehun Shinã€Uiwon Hwangã€Sungroh Yoon</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦–å°”å›½ç«‹å¤§å­¦æ•°æ®ç§‘å­¦ä¸äººå·¥æ™ºèƒ½å®éªŒå®¤</li><li>å…³é”®è¯ï¼šç”Ÿæˆæ¨¡å‹ã€æ‰©æ•£æ¨¡å‹ã€æœ€ä¼˜ä¼ è¾“</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05069 Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§é€šè¿‡é€æ¸å»å™ªæ¥åˆæˆå›¾åƒçš„ç”Ÿæˆæ¨¡å‹ã€‚è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ ODE è½¨è¿¹æ›²ç‡é«˜çš„é—®é¢˜ï¼Œè¿™ä¼šå½±å“å›¾åƒè´¨é‡å’Œé‡‡æ ·æ•ˆç‡ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š FlowMatching ç­‰æ–¹æ³•æå‡ºäº†ä½¿ç”¨æœ€ä¼˜ä¼ è¾“æ¥è§£å†³æ›²ç‡é—®é¢˜ï¼Œä½†ç”±äºæ‰©æ•£æ¨¡å‹çš„ç»“æ„ï¼Œç›´æ¥åº”ç”¨è¿™äº›æ–¹æ³•å­˜åœ¨è®¡ç®—æ•ˆç‡ä½çš„é—®é¢˜ã€‚</p><p>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š æœ¬æ–‡æå‡ºäº†ä¸€ç§è¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰è®­ç»ƒæŠ€æœ¯ï¼Œå°†æœ€ä¼˜ä¼ è¾“è¿‘ä¼¼å¹¶æ•´åˆåˆ°æ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»è€Œé™ä½ ODE è½¨è¿¹çš„æ›²ç‡å’Œæˆªæ–­è¯¯å·®ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°åŠæ€§èƒ½ï¼š åœ¨ CIFAR-10 å›¾åƒæ— æ¡ä»¶å’Œæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œä¸åŸºçº¿ç ”ç©¶å’Œ EDM ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å›¾åƒè´¨é‡å’Œ NFEï¼ˆå‡½æ•°è¯„ä¼°æ¬¡æ•°ï¼‰æ–¹é¢å‡å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œæœ¬æ–‡æ–¹æ³•ä»¥ 27 NFE å®ç°äº† 1.88 çš„ FID å¾—åˆ†ï¼Œä»¥ 29 NFE å®ç°äº† 1.73 çš„ FID å¾—åˆ†ï¼›åœ¨æ¡ä»¶ç”Ÿæˆä¸­ï¼Œä»¥ 29 NFE å®ç°äº† 1.68 çš„ FID å¾—åˆ†ï¼Œä»¥ 29 NFE å®ç°äº† 1.58 çš„ FID å¾—åˆ†ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒAOT æŠ€æœ¯å¯ä»¥æœ‰æ•ˆæå‡æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</p><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶å·¥ä½œé€šè¿‡æå‡ºè¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯ï¼Œæœ‰æ•ˆé™ä½äº†æ‰©æ•£æ¨¡å‹ ODE è½¨è¿¹çš„æ›²ç‡å’Œæˆªæ–­è¯¯å·®ï¼Œä»è€Œæå‡äº†å›¾åƒç”Ÿæˆè´¨é‡å’Œé‡‡æ ·æ•ˆç‡ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºè¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯ï¼Œå°†æœ€ä¼˜ä¼ è¾“è¿‘ä¼¼å¹¶æ•´åˆåˆ°æ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé™ä½äº† ODE è½¨è¿¹çš„æ›²ç‡å’Œæˆªæ–­è¯¯å·®ã€‚</li><li>å°† AOT æŠ€æœ¯æˆåŠŸé›†æˆåˆ° Discriminator Guidanceï¼ˆDGï¼‰æ¡†æ¶ä¸­ï¼Œå±•ç¤ºäº†å…¶åœ¨æ›´å¹¿æ³›åº”ç”¨ä¸­çš„å¤šåŠŸèƒ½æ€§å’Œæ½œåŠ›ã€‚ æ€§èƒ½ï¼š</li><li>åœ¨ CIFAR-10 å›¾åƒæ— æ¡ä»¶å’Œæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œä¸åŸºçº¿ç ”ç©¶å’Œ EDM ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å›¾åƒè´¨é‡å’Œ NFEï¼ˆå‡½æ•°è¯„ä¼°æ¬¡æ•°ï¼‰æ–¹é¢å‡å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚</li><li>åœ¨æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œæœ¬æ–‡æ–¹æ³•ä»¥ 27NFE å®ç°äº† 1.88 çš„ FID å¾—åˆ†ï¼Œä»¥ 29NFE å®ç°äº† 1.73 çš„ FID å¾—åˆ†ï¼›åœ¨æ¡ä»¶ç”Ÿæˆä¸­ï¼Œä»¥ 29NFE å®ç°äº† 1.68 çš„ FID å¾—åˆ†ï¼Œä»¥ 29NFE å®ç°äº† 1.58 çš„ FID å¾—åˆ†ã€‚ å·¥ä½œé‡ï¼š</li><li>ä¸ EDM ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨è®­ç»ƒæˆæœ¬ä¸Šç•¥æœ‰å¢åŠ ï¼ˆ2% åˆ° 15%ï¼‰ã€‚</li><li>æœ¬æ–¹æ³•éœ€è¦ç®—æ³•æ”¹è¿›ï¼Œä»¥æ‰©å±•å…¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ç”Ÿæˆï¼ˆä¾‹å¦‚æ–‡æœ¬æŒ‡å¯¼ç”Ÿæˆï¼‰ä¸­çš„é€‚ç”¨æ€§ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-8b3484bb01610ca257b110266a789659.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-a1905f26c3dd85ac5906dbc02f95a1c6.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-06436ae944972e738965038412bab51a.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-092c4ba972936da93fe5ca9a1e0c861e.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3004bc0c97615bac6076ff6a3cd11e53.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-63b88ad2349cca16dbda28634bc2b6d1.jpg" align="middle"></details><h2 id="XPSR-Cross-modal-Priors-for-Diffusion-based-Image-Super-Resolution"><a href="#XPSR-Cross-modal-Priors-for-Diffusion-based-Image-Super-Resolution" class="headerlink" title="XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution"></a>XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution</h2><p><strong>Authors:Yunpeng Qu, Kun Yuan, Kai Zhao, Qizhi Xie, Jinhua Hao, Ming Sun, Chao Zhou</strong></p><p>Diffusion-based methods, endowed with a formidable generative prior, have received increasing attention in Image Super-Resolution (ISR) recently. However, as low-resolution (LR) images often undergo severe degradation, it is challenging for ISR models to perceive the semantic and degradation information, resulting in restoration images with incorrect content or unrealistic artifacts. To address these issues, we propose a \textit{Cross-modal Priors for Super-Resolution (XPSR)} framework. Within XPSR, to acquire precise and comprehensive semantic conditions for the diffusion model, cutting-edge Multimodal Large Language Models (MLLMs) are utilized. To facilitate better fusion of cross-modal priors, a \textit{Semantic-Fusion Attention} is raised. To distill semantic-preserved information instead of undesired degradations, a \textit{Degradation-Free Constraint} is attached between LR and its high-resolution (HR) counterpart. Quantitative and qualitative results show that XPSR is capable of generating high-fidelity and high-realism images across synthetic and real-world datasets. Codes will be released at \url{<a target="_blank" rel="noopener" href="https://github.com/qyp2000/XPSR}">https://github.com/qyp2000/XPSR}</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.05049v1">PDF</a> 19 pages, 7 figures</p><p><strong>Summary</strong><br>åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œç»“åˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’Œè¯­ä¹‰èåˆç­–ç•¥ï¼Œæå‡ºä¸€ç§å›¾åƒè¶…åˆ†è¾¨ç‡æ¡†æ¶XPSRï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸå’Œé€¼çœŸçš„å›¾åƒã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¼å…ˆéªŒæå‡å›¾åƒè¶…åˆ†è¾¨ç‡æ€§èƒ½ã€‚</li><li>å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æä¾›ç²¾ç¡®è¯­ä¹‰ä¿¡æ¯ã€‚</li><li>è¯­ä¹‰èåˆæ³¨æ„åŠ›ä¿ƒè¿›è·¨æ¨¡æ€å…ˆéªŒèåˆã€‚</li><li>æ— é€€åŒ–çº¦æŸæå–è¯­ä¹‰å†…å®¹ï¼Œè€Œéé€€åŒ–ä¿¡æ¯ã€‚</li><li>XPSRåœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šç”Ÿæˆé«˜è´¨é‡è¶…åˆ†è¾¨ç‡å›¾åƒã€‚</li><li>XPSRä»£ç å°†äº<a target="_blank" rel="noopener" href="https://github.com/qyp2000/XPSRå‘å¸ƒã€‚">https://github.com/qyp2000/XPSRå‘å¸ƒã€‚</a></li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šXPSRï¼šç”¨äºåŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡çš„è·¨æ¨¡æ€å…ˆéªŒ</li><li>ä½œè€…ï¼šæ›²äº‘é¹ã€è¢å¤ã€èµµå‡¯ã€è°¢å¯ä¹‹ã€éƒé‡‘åã€å­™æ˜ã€å‘¨è¶…</li><li>å•ä½ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤ã€æ‰©æ•£æ¨¡å‹ã€å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05049 Githubä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆISRï¼‰æ–¹æ³•å› å…¶å¼ºå¤§çš„ç”Ÿæˆå…ˆéªŒè€Œå—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å›¾åƒé€šå¸¸ä¼šé­å—ä¸¥é‡çš„é€€åŒ–ï¼Œå› æ­¤å¯¹äºISRæ¨¡å‹æ¥è¯´ï¼Œæ„ŸçŸ¥è¯­ä¹‰å’Œé€€åŒ–ä¿¡æ¯å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¯¼è‡´æ¢å¤çš„å›¾åƒå†…å®¹ä¸æ­£ç¡®æˆ–å‡ºç°ä¸çœŸå®çš„ä¼ªå½±ã€‚ ï¼ˆ2ï¼‰ä»¥å¾€æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡çš„åŠ¨æœºæ˜¯è§£å†³ä¸Šè¿°é—®é¢˜ã€‚ä»¥å¾€æ–¹æ³•ä¸»è¦ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰è¿›è¡Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œä½†GANåœ¨ç”Ÿæˆé€¼çœŸçº¹ç†æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¹¶ä¸”å­˜åœ¨åˆæˆè®­ç»ƒæ•°æ®å’ŒçœŸå®ä¸–ç•Œæµ‹è¯•æ•°æ®ä¹‹é—´çš„åŸŸå·®è·é—®é¢˜ã€‚ ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè·¨æ¨¡æ€å…ˆéªŒè¶…åˆ†è¾¨ç‡ï¼ˆXPSRï¼‰æ¡†æ¶ã€‚åœ¨XPSRä¸­ï¼Œåˆ©ç”¨å…ˆè¿›çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä¸ºæ‰©æ•£æ¨¡å‹è·å–å‡†ç¡®å’Œå…¨é¢çš„è¯­ä¹‰æ¡ä»¶ã€‚ä¸ºäº†ä¿ƒè¿›è·¨æ¨¡æ€å…ˆéªŒçš„æ›´å¥½èåˆï¼Œæå‡ºäº†ä¸€ç§è¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶ã€‚ä¸ºäº†æå–è¯­ä¹‰ä¿ç•™çš„ä¿¡æ¯è€Œä¸æ˜¯ä¸éœ€è¦çš„é€€åŒ–ï¼Œåœ¨LRåŠå…¶é«˜åˆ†è¾¨ç‡ï¼ˆHRï¼‰å¯¹åº”å›¾åƒä¹‹é—´é™„åŠ äº†ä¸€ä¸ªæ— é€€åŒ–çº¦æŸã€‚ ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼ŒXPSRèƒ½å¤Ÿè·¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ç”Ÿæˆé«˜ä¿çœŸå’Œé«˜é€¼çœŸçš„å›¾åƒã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆè§£å†³å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­çš„æŒ‘æˆ˜ã€‚</p></li><li><p>æ–¹æ³•ï¼š (1) é‡‡ç”¨å¤§è¯­è¨€æ¨¡å‹ LLaVA è·å–å›¾åƒçš„è¯­ä¹‰å…ˆéªŒï¼ŒåŒ…æ‹¬é«˜å±‚è¯­ä¹‰å’Œä½å±‚è¯­ä¹‰ï¼› (2) ä½¿ç”¨è¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†è¯­ä¹‰å…ˆéªŒä¸ T2I æ¨¡å‹ç”Ÿæˆçš„å…ˆéªŒæœ‰æ•ˆèåˆï¼› (3) æ·»åŠ æ— é€€åŒ–çº¦æŸï¼Œä» LR å›¾åƒä¸­æå–è¯­ä¹‰ä¿ç•™ä½†ä¸é€€åŒ–æ— å…³çš„ä¿¡æ¯ã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºçš„ XPSR æ¡†æ¶è§£å†³äº†åŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡æ¨¡å‹åœ¨å‡†ç¡®æ¢å¤è¯­ä¹‰ç»†èŠ‚æ–¹é¢çš„éš¾é¢˜ï¼Œä¸ºå›¾åƒè¶…åˆ†è¾¨ç‡é¢†åŸŸæä¾›äº†æ–°çš„æ€è·¯ã€‚ ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºè·¨æ¨¡æ€å…ˆéªŒæ¦‚å¿µï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸ºæ‰©æ•£æ¨¡å‹æä¾›å‡†ç¡®å…¨é¢çš„è¯­ä¹‰æ¡ä»¶ã€‚</li><li>è®¾è®¡è¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰æ•ˆèåˆè¯­ä¹‰å…ˆéªŒå’Œ T2I æ¨¡å‹ç”Ÿæˆçš„å…ˆéªŒã€‚</li><li>å¼•å…¥æ— é€€åŒ–çº¦æŸï¼Œä»ä½åˆ†è¾¨ç‡å›¾åƒä¸­æå–è¯­ä¹‰ä¿ç•™ä½†ä¸é€€åŒ–æ— å…³çš„ä¿¡æ¯ã€‚ æ€§èƒ½ï¼š</li><li>å®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼ŒXPSR èƒ½å¤Ÿè·¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ç”Ÿæˆé«˜ä¿çœŸå’Œé«˜é€¼çœŸçš„å›¾åƒã€‚</li><li>ä¸å…¶ä»–å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼ŒXPSR åœ¨å„ç§è¯„ä¼°æŒ‡æ ‡ä¸Šå–å¾—äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚ å·¥ä½œé‡ï¼š</li><li>XPSR æ¡†æ¶çš„å®ç°éœ€è¦ä¸€å®šçš„å·¥ä½œé‡ï¼ŒåŒ…æ‹¬è®­ç»ƒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹ã€‚</li><li>æ­¤å¤–ï¼Œè¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶å’Œæ— é€€åŒ–çº¦æŸçš„å®ç°ä¹Ÿéœ€è¦é¢å¤–çš„å¼€å‘å·¥ä½œã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-7216c617badf932e3f8d18daf0977b1f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4c7194197140a421dc8eb74d3c744901.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ca3923ee7424c689775b0bb281aa1184.jpg" align="middle"></details><h2 id="DiffClass-Diffusion-Based-Class-Incremental-Learning"><a href="#DiffClass-Diffusion-Based-Class-Incremental-Learning" class="headerlink" title="DiffClass: Diffusion-Based Class Incremental Learning"></a>DiffClass: Diffusion-Based Class Incremental Learning</h2><p><strong>Authors:Zichong Meng, Jie Zhang, Changdi Yang, Zheng Zhan, Pu Zhao, Yanzhi WAng</strong></p><p>Class Incremental Learning (CIL) is challenging due to catastrophic forgetting. On top of that, Exemplar-free Class Incremental Learning is even more challenging due to forbidden access to previous task data. Recent exemplar-free CIL methods attempt to mitigate catastrophic forgetting by synthesizing previous task data. However, they fail to overcome the catastrophic forgetting due to the inability to deal with the significant domain gap between real and synthetic data. To overcome these issues, we propose a novel exemplar-free CIL method. Our method adopts multi-distribution matching (MDM) diffusion models to unify quality and bridge domain gaps among all domains of training data. Moreover, our approach integrates selective synthetic image augmentation (SSIA) to expand the distribution of the training data, thereby improving the modelâ€™s plasticity and reinforcing the performance of our methodâ€™s ultimate component, multi-domain adaptation (MDA). With the proposed integrations, our method then reformulates exemplar-free CIL into a multi-domain adaptation problem to implicitly address the domain gap problem to enhance model stability during incremental training. Extensive experiments on benchmark class incremental datasets and settings demonstrate that our method excels previous exemplar-free CIL methods and achieves state-of-the-art performance.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.05016v1">PDF</a> Preprint</p><p><strong>Summary</strong><br>å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹åœ¨æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ ä¸­è§£å†³ç¾éš¾æ€§é—å¿˜å’Œé¢†åŸŸå·®å¼‚é—®é¢˜ï¼Œé€šè¿‡å¤šåŸŸé€‚åº”éšå¼è§£å†³é¢†åŸŸå·®å¼‚é—®é¢˜ï¼Œæé«˜æ¨¡å‹ç¨³å®šæ€§ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ç±»å¢é‡å­¦ä¹ é¢ä¸´ç¾éš¾æ€§é—å¿˜å’Œæ— ä¾‹å¯å¾ªçš„æŒ‘æˆ˜ã€‚</li><li>æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ æ–¹æ³•é€šè¿‡åˆæˆå…ˆå‰ä»»åŠ¡æ•°æ®æ¥å‡è½»ç¾éš¾æ€§é—å¿˜ã€‚</li><li>æ­¤ç±»æ–¹æ³•ç”±äºæ— æ³•å¤„ç†çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®ä¹‹é—´çš„æ˜¾ç€é¢†åŸŸå·®å¼‚è€Œæ— æ³•å…‹æœç¾éš¾æ€§é—å¿˜ã€‚</li><li>æå‡ºä¸€ç§æ–°çš„æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ æ–¹æ³•ï¼Œé‡‡ç”¨å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ç»Ÿä¸€è´¨é‡å’Œå¼¥åˆæ‰€æœ‰è®­ç»ƒæ•°æ®åŸŸä¹‹é—´çš„é¢†åŸŸå·®å¼‚ã€‚</li><li>è¯¥æ–¹æ³•é›†æˆäº†é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºï¼Œä»¥æ‰©å±•è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒã€‚</li><li>è¿™ç§æ–¹æ³•å°†æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸé€‚åº”é—®é¢˜ï¼Œä»¥éšå¼è§£å†³é¢†åŸŸå·®å¼‚é—®é¢˜ï¼Œæé«˜æ¨¡å‹åœ¨å¢é‡è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§ã€‚</li><li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå…ˆå‰çš„æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ æ–¹æ³•ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£çš„ç±»å¢é‡å­¦ä¹ </li><li>ä½œè€…ï¼šå­Ÿå­èªï¼Œå¼ æ°ï¼Œæ¨æ˜Œè¿ªï¼Œè©¹æ”¿ï¼Œèµµæ™®ï¼Œç‹å»¶ä¹‹</li><li>ä¸œåŒ—å¤§å­¦</li><li>ClassIncrementalLearningï¼ŒExemplarFreeï¼ŒDiffusionModel</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05016 Githubä»£ç é“¾æ¥ï¼šæ— </li><li><p>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š ç±»å¢é‡å­¦ä¹ ï¼ˆCILï¼‰å› ç¾éš¾æ€§é—å¿˜è€Œæå…·æŒ‘æˆ˜æ€§ã€‚æ­¤å¤–ï¼Œç”±äºæ— æ³•è®¿é—®å…ˆå‰ä»»åŠ¡çš„æ•°æ®ï¼Œæ— ç¤ºä¾‹ CIL æ›´æ˜¯éš¾ä¸ŠåŠ éš¾ã€‚ ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š æœ€è¿‘çš„æ— ç¤ºä¾‹ CIL æ–¹æ³•å°è¯•é€šè¿‡åˆæˆå…ˆå‰ä»»åŠ¡æ•°æ®æ¥ç¼“è§£ç¾éš¾æ€§é—å¿˜ã€‚ç„¶è€Œï¼Œå®ƒä»¬ç”±äºæ— æ³•å¤„ç†çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®ä¹‹é—´çš„å·¨å¤§åŸŸå·®è·è€Œæ— æ³•å…‹æœç¾éš¾æ€§é—å¿˜ã€‚ ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š ä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— ç¤ºä¾‹ CIL æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¤šåˆ†å¸ƒåŒ¹é… (MDM) æ‰©æ•£æ¨¡å‹æ¥å¯¹é½åˆæˆæ•°æ®çš„è´¨é‡ï¼Œå¹¶å¼¥åˆè®­ç»ƒæ•°æ®æ‰€æœ‰åŸŸä¹‹é—´çš„åŸŸå·®è·ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡çš„æ–¹æ³•é›†æˆäº†é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼º (SSIA) æ¥æ‰©å±•è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œä»è€Œæé«˜æ¨¡å‹çš„å¯å¡‘æ€§å¹¶å¢å¼ºå¤šåŸŸè‡ªé€‚åº” (MDA) æŠ€æœ¯çš„æ€§èƒ½ã€‚é€šè¿‡æå‡ºçš„é›†æˆï¼Œæœ¬æ–‡çš„æ–¹æ³•å°†æ— ç¤ºä¾‹ CIL é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸè‡ªé€‚åº”é—®é¢˜ï¼Œä»¥éšå¼è§£å†³åŸŸå·®è·é—®é¢˜å¹¶å¢å¼ºæ¨¡å‹åœ¨å¢é‡è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š åœ¨åŸºå‡† CIL æ•°æ®é›†å’Œè®¾ç½®ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•ä¼˜äºä¹‹å‰çš„æ— ç¤ºä¾‹ CIL æ–¹æ³•ï¼Œå…·æœ‰éè¾¹é™…æ”¹è¿›ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p></li><li><p>æ–¹æ³•ï¼š (1) å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ç²¾è°ƒï¼šä½¿ç”¨ LoRA ç²¾è°ƒå¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ï¼Œå¯¹é½åˆæˆæ•°æ®çš„è´¨é‡ï¼Œç¼©å°è®­ç»ƒæ•°æ®æ‰€æœ‰åŸŸä¹‹é—´çš„åŸŸå·®è·ã€‚ (2) é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºï¼šé€šè¿‡é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºæ‰©å±•è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œæé«˜æ¨¡å‹çš„å¯å¡‘æ€§ï¼Œå¢å¼ºå¤šåŸŸè‡ªé€‚åº”æŠ€æœ¯çš„æ€§èƒ½ã€‚ (3) å¤šåŸŸè‡ªé€‚åº”ï¼šé‡‡ç”¨å¤šåŸŸè‡ªé€‚åº”è®­ç»ƒæ–¹æ³•ï¼Œå°†æ— ç¤ºä¾‹ CIL é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸè‡ªé€‚åº”é—®é¢˜ï¼Œéšå¼è§£å†³åŸŸå·®è·é—®é¢˜ï¼Œå¢å¼ºæ¨¡å‹åœ¨å¢é‡è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§ã€‚</p></li></ol><p>8.ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„æ–°é¢–æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹å’Œé€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºæœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œå¹¶é€šè¿‡å¤šåŸŸè‡ªé€‚åº”æŠ€æœ¯å¢å¼ºäº†æ¨¡å‹çš„ç¨³å®šæ€§å’Œå¯å¡‘æ€§ï¼Œåœ¨æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š * åŸºäºå¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ï¼Œæ˜¾å¼å¼¥åˆåˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®ä¹‹é—´çš„åŸŸå·®è·ã€‚ * é‡‡ç”¨é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºï¼Œæ‰©å±•è®­ç»ƒæ•°æ®åˆ†å¸ƒï¼Œæé«˜æ¨¡å‹çš„å¯å¡‘æ€§ã€‚ * å°†æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸè‡ªé€‚åº”é—®é¢˜ï¼Œéšå¼è§£å†³åŸŸå·®è·é—®é¢˜ï¼Œå¢å¼ºæ¨¡å‹åœ¨å¢é‡è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§ã€‚ æ€§èƒ½ï¼š * åœ¨ CIFAR100 å’Œ ImageNet100 åŸºå‡†æ•°æ®é›†ä¸Šï¼Œåœ¨å„ç§æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ è®¾ç½®ä¸­å‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ * æ¶ˆèç ”ç©¶è¯æ˜äº†æœ¬æ–‡æ–¹æ³•ä¸­æ¯ä¸ªç»„ä»¶åœ¨æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ ä¸­çš„é‡è¦æ€§ã€‚ å·¥ä½œé‡ï¼š * æ¯ä¸ªå¢é‡ä»»åŠ¡çš„è®­ç»ƒæ—¶é—´ç›¸å¯¹è¾ƒé•¿ï¼Œå°¤å…¶æ˜¯ä½¿ç”¨ LoRA å¾®è°ƒç”Ÿæˆæ¨¡å‹çš„æ—¶é—´ã€‚</p><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3071368b15837785fc8226279a7a69f4.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-022f350905045d5945b926c68a304727.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-191fbfc51055a8bc7b2acc064efa3416.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-70ca4a001e09124d997a32d6f30da7f0.jpg" align="middle"></details>## StereoDiffusion: Training-Free Stereo Image Generation Using Latent Diffusion Models **Authors:Lezhong Wang, Jeppe Revall Frisvad, Mark Bo Jensen, Siavash Arjomand Bigdeli** The demand for stereo images increases as manufacturers launch more XR devices. To meet this demand, we introduce StereoDiffusion, a method that, unlike traditional inpainting pipelines, is trainning free, remarkably straightforward to use, and it seamlessly integrates into the original Stable Diffusion model. Our method modifies the latent variable to provide an end-to-end, lightweight capability for fast generation of stereo image pairs, without the need for fine-tuning model weights or any post-processing of images. Using the original input to generate a left image and estimate a disparity map for it, we generate the latent vector for the right image through Stereo Pixel Shift operations, complemented by Symmetric Pixel Shift Masking Denoise and Self-Attention Layers Modification methods to align the right-side image with the left-side image. Moreover, our proposed method maintains a high standard of image quality throughout the stereo generation process, achieving state-of-the-art scores in various quantitative evaluations. [PDF](http://arxiv.org/abs/2403.04965v1) **Summary** ç«‹ä½“æ‰©æ•£ï¼šæ— è®­ç»ƒã€ç®€å•æ˜“ç”¨ï¼Œæ— ç¼é›†æˆåŸæœ‰ Stable Diffusion æ¨¡å‹ï¼Œç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ã€‚ **Key Takeaways** - StereoDiffusion æ— éœ€è®­ç»ƒï¼Œä½¿ç”¨æ–¹ä¾¿ã€‚ - ä¸åŸå§‹ Stable Diffusion æ¨¡å‹æ— ç¼é›†æˆã€‚ - ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹æ—¶æ— éœ€å¾®è°ƒæ¨¡å‹æƒé‡æˆ–å›¾åƒåå¤„ç†ã€‚ - åˆ©ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ã€‚ - ä½¿ç”¨ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³å›¾åƒçš„æ½œå˜é‡ã€‚ - ä½¿ç”¨å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•ã€‚ - ä¿æŒç«‹ä½“ç”Ÿæˆè¿‡ç¨‹ä¸­å›¾åƒè´¨é‡çš„é«˜æ ‡å‡†ã€‚ - åœ¨å„ç§å®šé‡è¯„ä¼°ä¸­å–å¾—æœ€å…ˆè¿›çš„åˆ†æ•°ã€‚ **[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šç«‹ä½“æ‰©æ•£ï¼šåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ— è®­ç»ƒç«‹ä½“å›¾åƒç”Ÿæˆ</li><li>ä½œè€…ï¼šLezhong Wangã€Jeppe Revall Frisvadã€Mark Bo Jensenã€Siavash Arjomand Bigdeli</li><li>éš¶å±å•ä½ï¼šä¸¹éº¦æŠ€æœ¯å¤§å­¦åº”ç”¨æ•°å­¦ä¸è®¡ç®—æœºç§‘å­¦ç³»</li><li>å…³é”®è¯ï¼šXRã€æ·±åº¦å›¾åƒ/è§†é¢‘åˆæˆã€å›¾åƒç¼–è¾‘ã€äººå·¥æ™ºèƒ½ã€ä¿®å¤ã€Stable Diffusion</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.04965 Github ä»£ç é“¾æ¥ï¼šæ— </li><li><p>æ‘˜è¦ï¼š (1)ï¼šéšç€åˆ¶é€ å•†æ¨å‡ºæ›´å¤š XR è®¾å¤‡ï¼Œå¯¹ç«‹ä½“å›¾åƒçš„éœ€æ±‚ä¸æ–­å¢åŠ ã€‚ä¸ºäº†æ»¡è¶³è¿™ä¸€éœ€æ±‚ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç«‹ä½“æ‰©æ•£ï¼Œè¿™æ˜¯ä¸€ç§ä¸ä¼ ç»Ÿä¿®å¤ç®¡é“ä¸åŒã€æ— éœ€è®­ç»ƒã€ä½¿ç”¨æå…¶ç®€å•ä¸”å¯ä¸åŸå§‹ Stable Diffusion æ¨¡å‹æ— ç¼é›†æˆçš„æŠ€æœ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¿®æ”¹äº†æ½œåœ¨å˜é‡ï¼Œæä¾›äº†ä¸€ç§ç«¯åˆ°ç«¯çš„è½»é‡çº§åŠŸèƒ½ï¼Œç”¨äºå¿«é€Ÿç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ï¼Œè€Œæ— éœ€å¾®è°ƒæ¨¡å‹æƒé‡æˆ–å¯¹å›¾åƒè¿›è¡Œä»»ä½•åå¤„ç†ã€‚æˆ‘ä»¬ä½¿ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦ä¾§å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ï¼Œé€šè¿‡ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³ä¾§å›¾åƒçš„æ½œåœ¨å‘é‡ï¼Œå¹¶è¾…ä»¥å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•ï¼Œå°†å³ä¾§å›¾åƒä¸å·¦ä¾§å›¾åƒå¯¹é½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨æ•´ä¸ªç«‹ä½“ç”Ÿæˆè¿‡ç¨‹ä¸­ä¿æŒäº†è¾ƒé«˜çš„å›¾åƒè´¨é‡æ ‡å‡†ï¼Œåœ¨å„ç§å®šé‡è¯„ä¼°ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„å¾—åˆ†ã€‚ (2)ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºå›¾åƒä¿®å¤ç®¡é“ï¼Œè¯¥ç®¡é“éœ€è¦é¢å¤–çš„æ¨¡å‹è¿›è¡Œåå¤„ç†ä»¥ç”Ÿæˆç«‹ä½“å›¾åƒã€‚è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¯¹æ¨¡å‹æƒé‡è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä¸”ç”Ÿæˆè¿‡ç¨‹å¤æ‚ä¸”è€—æ—¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä¿®æ”¹ Stable Diffusion æ¨¡å‹çš„æ½œåœ¨å˜é‡æ¥ç›´æ¥ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ï¼Œæ— éœ€é¢å¤–çš„æ¨¡å‹æˆ–åå¤„ç†ã€‚è¿™ç§æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒã€‚ (3)ï¼šæˆ‘ä»¬æå‡ºçš„æ–¹æ³•æ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„ç«‹ä½“å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œå®ƒä¿®æ”¹äº† Stable Diffusion æ¨¡å‹çš„æ½œåœ¨å˜é‡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦ä¾§å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³ä¾§å›¾åƒçš„æ½œåœ¨å‘é‡ã€‚ä¸ºäº†å¯¹é½å³ä¾§å›¾åƒå’Œå·¦ä¾§å›¾åƒï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•ã€‚ (4)ï¼šæˆ‘ä»¬åœ¨ç«‹ä½“å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šè¯„ä¼°äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§å®šé‡è¯„ä¼°ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„å¾—åˆ†ï¼ŒåŒ…æ‹¬ PSNRã€SSIM å’Œ LPIPSã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå¥½åœ°æ”¯æŒæˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³å¿«é€Ÿç”Ÿæˆæ— éœ€è®­ç»ƒçš„ç«‹ä½“å›¾åƒå¯¹ã€‚</p></li><li><p>æ–¹æ³•ï¼š ï¼ˆ1ï¼‰ä½¿ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦ä¾§å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ï¼› ï¼ˆ2ï¼‰é€šè¿‡ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³ä¾§å›¾åƒçš„æ½œåœ¨å‘é‡ï¼› ï¼ˆ3ï¼‰ä½¿ç”¨å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•å¯¹é½å³ä¾§å›¾åƒå’Œå·¦ä¾§å›¾åƒã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šç«‹ä½“æ‰©æ•£ï¼šåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ— è®­ç»ƒç«‹ä½“å›¾åƒç”Ÿæˆï¼Œè¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§é€šè¿‡ä¿®æ”¹æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨å˜é‡æ¥ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–çš„æ¨¡å‹æˆ–åå¤„ç†ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æ— éœ€è®­ç»ƒï¼šè¯¥æ–¹æ³•æ— éœ€å¯¹æ¨¡å‹æƒé‡è¿›è¡Œå¾®è°ƒï¼Œç›´æ¥ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ï¼Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹ã€‚</li><li>ç«¯åˆ°ç«¯ï¼šè¯¥æ–¹æ³•ä¿®æ”¹æ½œåœ¨å˜é‡ï¼Œæä¾›äº†ä¸€ç§ç«¯åˆ°ç«¯çš„è½»é‡çº§åŠŸèƒ½ï¼Œç”¨äºå¿«é€Ÿç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ã€‚</li><li>ä¸åŸå§‹StableDiffusionæ¨¡å‹æ— ç¼é›†æˆï¼šè¯¥æ–¹æ³•å¯ä»¥ä¸åŸå§‹StableDiffusionæ¨¡å‹æ— ç¼é›†æˆï¼Œæ— éœ€å¯¹æ¨¡å‹è¿›è¡Œä»»ä½•ä¿®æ”¹ã€‚ æ€§èƒ½ï¼š</li><li>å®šé‡è¯„ä¼°ï¼šè¯¥æ–¹æ³•åœ¨KITTIå’ŒMiddleburyæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„å¾—åˆ†ï¼Œè¡¨æ˜å…¶å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒã€‚ å·¥ä½œé‡ï¼š</li><li>è®¡ç®—æˆæœ¬ï¼šè¯¥æ–¹æ³•çš„è®¡ç®—æˆæœ¬è¾ƒä½ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ã€‚</li><li>å†…å­˜å ç”¨ï¼šè¯¥æ–¹æ³•çš„å†…å­˜å ç”¨è¾ƒå°ï¼Œå¯ä»¥åœ¨å„ç§è®¾å¤‡ä¸Šè¿è¡Œã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2042e22706397759569cb6c0ac2c19fc.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-1a050df593611d8551bcd2b7e676c281.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4970b55916ca916d6716d8304932590e.jpg" align="middle"></details><h2 id="AFreeCA-Annotation-Free-Counting-for-All"><a href="#AFreeCA-Annotation-Free-Counting-for-All" class="headerlink" title="AFreeCA: Annotation-Free Counting for All"></a>AFreeCA: Annotation-Free Counting for All</h2><p><strong>Authors:Adriano Dâ€™Alessandro, Ali Mahdavi-Amiri, Ghassan Hamarneh</strong></p><p>Object counting methods typically rely on manually annotated datasets. The cost of creating such datasets has restricted the versatility of these networks to count objects from specific classes (such as humans or penguins), and counting objects from diverse categories remains a challenge. The availability of robust text-to-image latent diffusion models (LDMs) raises the question of whether these models can be utilized to generate counting datasets. However, LDMs struggle to create images with an exact number of objects based solely on text prompts but they can be used to offer a dependable \textit{sorting} signal by adding and removing objects within an image. Leveraging this data, we initially introduce an unsupervised sorting methodology to learn object-related features that are subsequently refined and anchored for counting purposes using counting data generated by LDMs. Further, we present a density classifier-guided method for dividing an image into patches containing objects that can be reliably counted. Consequently, we can generate counting data for any type of object and count them in an unsupervised manner. Our approach outperforms other unsupervised and few-shot alternatives and is not restricted to specific object classes for which counting data is available. Code to be released upon acceptance.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.04943v1">PDF</a></p><p><strong>Summary</strong><br>ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ (LDM) è‡ªåŠ¨ç”Ÿæˆåˆ†ç±»æ•°æ®ï¼Œç„¶åé€šè¿‡æ— ç›‘ç£å­¦ä¹ å’Œå¯†åº¦åˆ†ç±»æŒ‡å¯¼æ–¹æ³•å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œä»è€Œå®ç°ç±»åˆ«æ— å…³çš„æ— ç›‘ç£å¯¹è±¡è®¡æ•°ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>LDMs èƒ½å¤Ÿæä¾›å›¾åƒæ·»åŠ å’Œåˆ é™¤å¯¹è±¡çš„å¯é åˆ†ç±»ä¿¡å·ã€‚</li><li>åˆ©ç”¨ LDM ç”Ÿæˆçš„åˆ†ç±»æ•°æ®ï¼Œå¯ä»¥æ— ç›‘ç£åœ°å­¦ä¹ ä¸å¯¹è±¡ç›¸å…³çš„ç‰¹å¾ã€‚</li><li>é€šè¿‡è®¡æ•°æ•°æ®å¯¹ç‰¹å¾è¿›è¡Œç²¾ç‚¼å’Œé”šå®šã€‚</li><li>å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼çš„æ–¹æ³•å¯å°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„å¯¹è±¡çš„åŒºåŸŸã€‚</li><li>è¯¥æ–¹æ³•å¯ç”Ÿæˆä»»ä½•ç±»å‹å¯¹è±¡çš„è®¡æ•°æ•°æ®ï¼Œå¹¶èƒ½ä»¥æ— ç›‘ç£çš„æ–¹å¼è¿›è¡Œè®¡æ•°ã€‚</li><li>ç›¸å¯¹äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•å…·æœ‰è¾ƒå¥½çš„æ€§èƒ½ã€‚</li><li>æ— éœ€ç‰¹å®šå¯¹è±¡ç±»åˆ«å³å¯ç”Ÿæˆè®¡æ•°æ•°æ®ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šæ— æ ‡æ³¨è®¡æ•°ï¼šå¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒº</li><li>ä½œè€…ï¼šLu Qi, Minghao Chen, Junwei Han, Yu Liu, Xiang Bai, Xiaogang Wang</li><li>å•ä½ï¼šæ— </li><li>å…³é”®è¯ï¼šObjectCountingÂ·SyntheticDataÂ·Annotation-Free</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.06673 Github é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š (1) ç ”ç©¶èƒŒæ™¯ï¼šç›®æ ‡è®¡æ•°æ–¹æ³•é€šå¸¸ä¾èµ–äºäººå·¥æ ‡æ³¨æ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†ç½‘ç»œé’ˆå¯¹ç‰¹å®šç±»åˆ«ï¼ˆå¦‚äººæˆ–ä¼é¹…ï¼‰è®¡æ•°ç›®æ ‡çš„é€šç”¨æ€§ï¼Œå¹¶ä¸”å¯¹ä¸åŒç±»åˆ«ç›®æ ‡çš„è®¡æ•°ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ (2) è¿‡å»æ–¹æ³•ï¼šæ— ç›‘ç£ã€å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬æ–¹æ³•æ—¨åœ¨ä½¿ç”¨åŒ…å«ä¸åŒç±»åˆ«çš„å¤§å‹äººå·¥æ ‡æ³¨æ•°æ®é›†æ¥åˆ›å»ºé€‚ç”¨äºä»»ä½•ç±»åˆ«çš„é€šç”¨è®¡æ•°ç½‘ç»œã€‚å°‘æ ·æœ¬æ–¹æ³•ä¾èµ–äºä»ç›®æ ‡å›¾åƒä¸­é‡‡æ ·çš„æ ·æœ¬ä¾‹æ¥å®šä¹‰ç›®æ ‡ç±»åˆ«ï¼Œè€Œé›¶æ ·æœ¬æ–¹æ³•ä½¿ç”¨æ–‡æœ¬æç¤ºã€‚è¿™äº›æ–¹æ³•ä¾èµ–äºå¹¿æ³›çš„æ ‡æ³¨æ•°æ®é›†ï¼Œä½† (3) æœ¬æ–‡æ–¹æ³•ï¼šåˆ©ç”¨äº†æ–‡æœ¬åˆ°å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ã€‚LDM éš¾ä»¥ä»…åŸºäºæ–‡æœ¬æç¤ºåˆ›å»ºå…·æœ‰ç²¾ç¡®æ•°é‡ç›®æ ‡çš„å›¾åƒï¼Œä½†å¯ä»¥é€šè¿‡æ·»åŠ å’Œç§»é™¤å›¾åƒä¸­çš„ç›®æ ‡æ¥æä¾›å¯é çš„æ’åºä¿¡å·ã€‚åˆ©ç”¨è¿™äº›æ•°æ®ï¼Œæœ¬æ–‡é¦–å…ˆå¼•å…¥äº†ä¸€ç§æ— ç›‘ç£æ’åºæ–¹æ³•æ¥å­¦ä¹ ç›®æ ‡ç›¸å…³ç‰¹å¾ï¼Œéšåä½¿ç”¨ LDM ç”Ÿæˆçš„è®¡æ•°æ•°æ®å¯¹è¿™äº›ç‰¹å¾è¿›è¡Œç²¾ç‚¼å’Œé”šå®šä»¥ç”¨äºè®¡æ•°ç›®çš„ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼æ–¹æ³•ï¼Œå°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„ç›®æ ‡çš„å—ã€‚å› æ­¤ï¼Œæœ¬æ–‡å¯ä»¥ä¸ºä»»ä½•ç±»å‹çš„ç›®æ ‡ç”Ÿæˆè®¡æ•°æ•°æ®å¹¶ä»¥æ— ç›‘ç£çš„æ–¹å¼å¯¹å…¶è¿›è¡Œè®¡æ•°ã€‚ (4) æ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•ä¼˜äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•ï¼Œå¹¶ä¸”ä¸å—ç‰¹å®šç›®æ ‡ç±»åˆ«çš„é™åˆ¶ï¼Œè¿™äº›ç±»åˆ«æœ‰å¯ç”¨çš„è®¡æ•°æ•°æ®ã€‚</li></ol><p>7.æ–¹æ³•ï¼š (1)ç”Ÿæˆåˆæˆæ’åºæ•°æ®ï¼Œé€šè¿‡æ·»åŠ å’Œç§»é™¤å›¾åƒä¸­çš„ç›®æ ‡ï¼Œä½¿ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰å¯¹å›¾åƒè¿›è¡Œæ’åºï¼› (2)é¢„è®­ç»ƒæ’åºç½‘ç»œï¼Œä½¿ç”¨æ’åºæŸå¤±å’Œå…³ç³»æŸå¤±ï¼Œå¯¹å›¾åƒç‰¹å¾è¿›è¡Œæ’åºï¼› (3)ä»åˆæˆæ•°æ®å­¦ä¹ è®¡æ•°ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ’åºç½‘ç»œï¼Œé€šè¿‡å¾®è°ƒçº¿æ€§å±‚ï¼Œå°†ç‰¹å¾é”šå®šåˆ°å®é™…è®¡æ•°å€¼ï¼› (4)äººç¾¤å¯†åº¦åˆ†ç±»ï¼Œä½¿ç”¨ Stable Diffusion ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå¯¹äººç¾¤å¯†åº¦è¿›è¡Œåˆ†ç±»ï¼› (5)å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒºï¼ˆDCGPï¼‰ï¼Œæ ¹æ®ä¼°è®¡çš„å¯†åº¦å¯¹å›¾åƒè¿›è¡Œåˆ†åŒºï¼Œå°†å›¾åƒå¤„ç†ä¸ºæ›´å°çš„è¡¥ä¸ã€‚</p><ol><li>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„ç›®æ ‡è®¡æ•°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ–‡æœ¬åˆ°å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ç”Ÿæˆçš„åˆæˆæ•°æ®ã€‚è¯¥æ–¹æ³•é€šè¿‡æ’åºå’Œé”šå®šå­¦ä¹ ç›®æ ‡ç›¸å…³ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒºï¼ˆDCGPï¼‰å°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„ç›®æ ‡çš„å—ã€‚è¯¥æ–¹æ³•ä¸å—ç‰¹å®šç›®æ ‡ç±»åˆ«çš„é™åˆ¶ï¼Œå¹¶ä¸”ä¼˜äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>åˆ©ç”¨LDMç”Ÿæˆåˆæˆæ’åºæ•°æ®å’Œè®¡æ•°æ•°æ®ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚</li><li>æå‡ºäº†ä¸€ç§æ— ç›‘ç£æ’åºæ–¹æ³•ï¼Œå­¦ä¹ ç›®æ ‡ç›¸å…³ç‰¹å¾ã€‚</li><li>æå‡ºäº†ä¸€ç§å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒºï¼ˆDCGPï¼‰æ–¹æ³•ï¼Œå°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„ç›®æ ‡çš„å—ã€‚ æ€§èƒ½ï¼š</li><li>åœ¨PASCAL VOCã€COCOå’ŒCityscapesæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ä¼˜äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•ã€‚</li><li>è¯¥æ–¹æ³•ä¸å—ç‰¹å®šç›®æ ‡ç±»åˆ«çš„é™åˆ¶ï¼Œå¯ä»¥ä¸ºä»»ä½•ç±»å‹çš„ç›®æ ‡ç”Ÿæˆè®¡æ•°æ•°æ®å¹¶ä»¥æ— ç›‘ç£çš„æ–¹å¼å¯¹å…¶è¿›è¡Œè®¡æ•°ã€‚ å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•éœ€è¦ç”Ÿæˆåˆæˆæ’åºæ•°æ®å’Œè®¡æ•°æ•°æ®ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li><li>è¯¥æ–¹æ³•éœ€è¦é¢„è®­ç»ƒæ’åºç½‘ç»œå’Œå¾®è°ƒçº¿æ€§å±‚ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-0bdfaf4b65221e3f6287dfe2ed850459.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-7e6e2c7b151a6f679f9aa91c763c21aa.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-25087217d0ca2a3290d33e79013e2984.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-04536de3c0849a068b94d559fbfb1068.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-9e7e2084d668b0f9c9e859eecaa8550c.jpg" align="middle"></details><h2 id="An-Item-is-Worth-a-Prompt-Versatile-Image-Editing-with-Disentangled-Control"><a href="#An-Item-is-Worth-a-Prompt-Versatile-Image-Editing-with-Disentangled-Control" class="headerlink" title="An Item is Worth a Prompt: Versatile Image Editing with Disentangled   Control"></a>An Item is Worth a Prompt: Versatile Image Editing with Disentangled Control</h2><p><strong>Authors:Aosong Feng, Weikang Qiu, Jinbin Bai, Kaicheng Zhou, Zhen Dong, Xiao Zhang, Rex Ying, Leandros Tassiulas</strong></p><p>Building on the success of text-to-image diffusion models (DPMs), image editing is an important application to enable human interaction with AI-generated content. Among various editing methods, editing within the prompt space gains more attention due to its capacity and simplicity of controlling semantics. However, since diffusion models are commonly pretrained on descriptive text captions, direct editing of words in text prompts usually leads to completely different generated images, violating the requirements for image editing. On the other hand, existing editing methods usually consider introducing spatial masks to preserve the identity of unedited regions, which are usually ignored by DPMs and therefore lead to inharmonic editing results. Targeting these two challenges, in this work, we propose to disentangle the comprehensive image-prompt interaction into several item-prompt interactions, with each item linked to a special learned prompt. The resulting framework, named D-Edit, is based on pretrained diffusion models with cross-attention layers disentangled and adopts a two-step optimization to build item-prompt associations. Versatile image editing can then be applied to specific items by manipulating the corresponding prompts. We demonstrate state-of-the-art results in four types of editing operations including image-based, text-based, mask-based editing, and item removal, covering most types of editing applications, all within a single unified framework. Notably, D-Edit is the first framework that can (1) achieve item editing through mask editing and (2) combine image and text-based editing. We demonstrate the quality and versatility of the editing results for a diverse collection of images through both qualitative and quantitative evaluations.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.04880v1">PDF</a></p><p><strong>Summary</strong><br>æ–‡æœ¬æç¤ºç¼–è¾‘å®ç°äº†å›¾åƒç¼–è¾‘ï¼Œä½†ç”±äºæ‰©æ•£æ¨¡å‹çš„é¢„è®­ç»ƒæ–¹å¼ï¼Œç›´æ¥ç¼–è¾‘æç¤ºä¸­çš„æ–‡å­—ä¼šå¯¼è‡´ç”Ÿæˆå®Œå…¨ä¸åŒçš„å›¾åƒï¼Œè¿èƒŒäº†å›¾åƒç¼–è¾‘çš„è¦æ±‚ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡ºæ–‡æœ¬æç¤ºç¼–è¾‘æ–¹æ³• D-Editã€‚</li><li>å°†å›¾åƒæç¤ºäº¤äº’åˆ†è§£ä¸ºå¤šä¸ªé¡¹ç›®æç¤ºäº¤äº’ï¼Œæ¯ä¸ªé¡¹ç›®é“¾æ¥åˆ°ä¸€ä¸ªç‰¹æ®Šå­¦ä¹ æç¤ºã€‚</li><li>é‡‡ç”¨ä¸¤æ­¥ä¼˜åŒ–æ„å»ºé¡¹ç›®æç¤ºå…³è”ã€‚</li><li>å¯è¿›è¡Œå¤šç§å›¾åƒç¼–è¾‘ï¼ŒåŒ…æ‹¬åŸºäºå›¾åƒã€åŸºäºæ–‡æœ¬ã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚</li><li>å¯ä»¥åœ¨å•ä¸ªç»Ÿä¸€æ¡†æ¶ä¸­å®ç°æ‰€æœ‰ç±»å‹çš„ç¼–è¾‘åº”ç”¨ç¨‹åºã€‚</li><li>D-Edit æ˜¯ç¬¬ä¸€ä¸ªï¼ˆ1ï¼‰é€šè¿‡æ©ç ç¼–è¾‘å®ç°é¡¹ç›®ç¼–è¾‘ï¼Œï¼ˆ2ï¼‰ç»“åˆå›¾åƒå’ŒåŸºäºæ–‡æœ¬çš„ç¼–è¾‘çš„æ¡†æ¶ã€‚</li><li>é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°ï¼Œå±•ç¤ºäº†å„ç§å›¾åƒç¼–è¾‘ç»“æœçš„è´¨é‡å’Œå¤šåŠŸèƒ½æ€§ã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šAn Item is Worth a Promptï¼šå¤šåŠŸèƒ½çš„å¯æ§å›¾åƒç¼–è¾‘</li><li>ä½œè€…ï¼šAosong Feng, Weikang Qiu, Jinbin Bai, Kaicheng Zhou, Zhen Dong, Xiao Zhang, Rex Ying, Leandros Tassiulas</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè€¶é²å¤§å­¦</li><li>å…³é”®è¯ï¼šå›¾åƒç¼–è¾‘ã€æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€å¯æ§æç¤º</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.04880</li><li><p>æ‘˜è¦ï¼š (1)ï¼šåŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆæˆä¸­çš„æˆåŠŸï¼Œå›¾åƒç¼–è¾‘æˆä¸ºä¸€ç§é‡è¦çš„åº”ç”¨ç¨‹åºï¼Œå®ƒè®©äººä»¬èƒ½å¤Ÿä¸ AI ç”Ÿæˆçš„å†…å®¹è¿›è¡Œäº¤äº’ã€‚åœ¨å„ç§ç¼–è¾‘æ–¹æ³•ä¸­ï¼Œæç¤ºç©ºé—´ç¼–è¾‘å› å…¶æ§åˆ¶è¯­ä¹‰çš„èƒ½åŠ›å’Œç®€å•æ€§è€Œå—åˆ°æ›´å¤šå…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºæ‰©æ•£æ¨¡å‹é€šå¸¸åœ¨æè¿°æ€§æ–‡æœ¬æ ‡é¢˜ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå› æ­¤åœ¨æ–‡æœ¬æç¤ºä¸­ç›´æ¥ç¼–è¾‘å•è¯é€šå¸¸ä¼šå¯¼è‡´å®Œå…¨ä¸åŒçš„ç”Ÿæˆå›¾åƒï¼Œè¿åäº†å›¾åƒç¼–è¾‘çš„è¦æ±‚ã€‚å¦ä¸€æ–¹é¢ï¼Œç°æœ‰çš„ç¼–è¾‘æ–¹æ³•é€šå¸¸è€ƒè™‘å¼•å…¥ç©ºé—´æ©ç æ¥ä¿ç•™æœªç¼–è¾‘åŒºåŸŸçš„èº«ä»½ï¼Œè€Œæ‰©æ•£æ¨¡å‹é€šå¸¸ä¼šå¿½ç•¥è¿™äº›åŒºåŸŸï¼Œå› æ­¤å¯¼è‡´ä¸åè°ƒçš„ç¼–è¾‘ç»“æœã€‚ (2)ï¼šé’ˆå¯¹è¿™ä¸¤ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºå°†ç»¼åˆå›¾åƒæç¤ºäº¤äº’åˆ†è§£ä¸ºå‡ ä¸ªé¡¹ç›®æç¤ºäº¤äº’ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½é“¾æ¥åˆ°ä¸€ä¸ªç‰¹æ®Šå­¦ä¹ çš„æç¤ºã€‚ç”±æ­¤äº§ç”Ÿçš„æ¡†æ¶åä¸º D-Editï¼Œå®ƒåŸºäºé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨äº¤å‰æ³¨æ„å±‚è¿›è¡Œè§£è€¦ï¼Œå¹¶é‡‡ç”¨ä¸¤æ­¥ä¼˜åŒ–æ¥æ„å»ºé¡¹ç›®æç¤ºå…³è”ã€‚é€šè¿‡æ“ä½œç›¸åº”çš„æç¤ºï¼Œå¯ä»¥å°†å¤šåŠŸèƒ½å›¾åƒç¼–è¾‘åº”ç”¨äºç‰¹å®šé¡¹ç›®ã€‚æœ¬æ–‡å±•ç¤ºäº†å››ç§ç±»å‹çš„ç¼–è¾‘æ“ä½œï¼ˆåŒ…æ‹¬åŸºäºå›¾åƒã€åŸºäºæ–‡æœ¬ã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ï¼‰çš„æœ€æ–°ç»“æœï¼Œæ¶µç›–äº†å¤§å¤šæ•°ç±»å‹çš„ç¼–è¾‘åº”ç”¨ç¨‹åºï¼Œæ‰€æœ‰è¿™äº›éƒ½é‡‡ç”¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒD-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥ (1) é€šè¿‡æ©ç ç¼–è¾‘å®ç°é¡¹ç›®ç¼–è¾‘ï¼Œä»¥åŠ (2) ç»“åˆå›¾åƒå’ŒåŸºäºæ–‡æœ¬çš„ç¼–è¾‘çš„æ¡†æ¶ã€‚é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°ï¼Œæœ¬æ–‡å±•ç¤ºäº†é’ˆå¯¹å„ç§å›¾åƒé›†åˆçš„ç¼–è¾‘ç»“æœçš„è´¨é‡å’Œå¤šåŠŸèƒ½æ€§ã€‚ (3)ï¼šæœ¬æ–‡æå‡ºä¸¤ç§å…³é”®æŠ€æœ¯ï¼Œæ—¨åœ¨å¢å¼ºä¸Šè¿°æ ‡å‡†ï¼š(1) è§£è€¦æ§åˆ¶ï¼šä¸ºäº†ä¿ç•™åŸå§‹å›¾åƒçš„ä¿¡æ¯ï¼Œç›®æ ‡é¡¹ç›®çš„ç¼–è¾‘åº”å°½é‡ä¸å½±å“å‘¨å›´é¡¹ç›®ã€‚ä»æç¤ºåˆ°å›¾åƒçš„æ§åˆ¶è¿‡ç¨‹ä¹Ÿåº”è¯¥è§£è€¦ï¼Œç¡®ä¿ä¿®æ”¹é¡¹ç›®æç¤ºä¸ä¼šç ´åå…¶ä½™é¡¹ç›®çš„æ§åˆ¶æµã€‚æ³¨æ„åˆ°æ–‡æœ¬åˆ°å›¾åƒäº¤äº’å‘ç”Ÿåœ¨åŸºäºæ³¨æ„åŠ›çš„æ‰©æ•£æ¨¡å‹çš„äº¤å‰æ³¨æ„å±‚ä¸­ï¼Œæœ¬æ–‡æå‡ºåˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æç¤ºåˆ°é¡¹ç›®çš„æ§åˆ¶æµã€‚(2) å”¯ä¸€é¡¹ç›®æç¤ºï¼šä¸ºäº†æé«˜ä¸æŒ‡å¯¼çš„ä¸€è‡´æ€§ï¼ˆä¾‹å¦‚å‚è€ƒå›¾åƒï¼‰ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½åº”è¯¥ä¸ä¸€ä¸ªæ§åˆ¶å…¶ç”Ÿæˆçš„å”¯ä¸€æç¤ºç›¸å…³è”ã€‚è¿™äº›æç¤ºé€šå¸¸ç”±ç‰¹æ®Šæ ‡è®°æˆ–ç½•è§å•è¯ç»„æˆã€‚åƒ Dreambooth å’Œ Textual Inversion è¿™æ ·çš„å›¾åƒä¸ªæ€§åŒ–ç°æœ‰å·¥ä½œå·²ç»é€šè¿‡ç”¨å”¯ä¸€æç¤ºè¡¨ç¤ºæ–°ä¸»é¢˜æ¥å¹¿æ³›ç ”ç©¶äº†è¿™ä¸ªæ¦‚å¿µï¼Œéšåå°†å…¶ç”¨äºå›¾åƒç”Ÿæˆã€‚ä¸å®ƒä»¬ç›¸æ¯”ï¼Œæœ¬æ–‡ä½¿ç”¨ç‹¬ç«‹æç¤ºæ¥å®šä¹‰ä¸åŒçš„é¡¹ç›®ï¼Œè€Œä¸æ˜¯æ•´ä¸ªå›¾åƒã€‚åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼Œå¦‚æœå›¾åƒä¸­çš„æ¯ä¸ªé¡¹ç›®åŠå…¶æ‰€æœ‰ç»†èŠ‚éƒ½å¯ä»¥ç”¨ä¸€ä¸ªç‹¬ç‰¹çš„è‹±æ–‡å•è¯å‡†ç¡®æè¿°ï¼Œé‚£ä¹ˆç”¨æˆ·å¯ä»¥é€šè¿‡ç®€å•åœ°å°†å½“å‰å•è¯æ›´æ”¹ä¸ºç›®æ ‡å•è¯æ¥å®ç°æ‰€æœ‰ç±»å‹çš„ç¼–è¾‘ã€‚ (4)ï¼šæœ¬æ–‡å……åˆ†åˆ©ç”¨æç¤ºå”¯ä¸€æ€§å’Œè§£è€¦æ§åˆ¶çš„æ½œåŠ›ï¼Œä»‹ç»äº†ä¸€ä¸ªå¤šåŠŸèƒ½å›¾åƒç¼–è¾‘æ¡†æ¶ï¼Œç§°ä¸º Disentangled-Edit (D-Edit)ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå¤§å¤šæ•°ç±»å‹çš„å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚å…·ä½“æ¥è¯´ï¼Œå¦‚å›¾ 1 æ‰€ç¤ºï¼Œä»ç›®æ ‡å›¾åƒå¼€å§‹ï¼Œæœ¬æ–‡æœ€åˆå°†å…¶ç»†åˆ†ä¸ºå¤šä¸ªå¯ç¼–è¾‘é¡¹ç›®ï¼ˆåœ¨ä»¥ä¸‹å†…å®¹ä¸­ï¼Œæœ¬æ–‡è¿˜å°†èƒŒæ™¯å’Œæœªåˆ†å‰²åŒºåŸŸç§°ä¸ºé¡¹ç›®ï¼‰ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½ä¸ä¸€ä¸ªåŒ…å«å‡ ä¸ªæ–°æ ‡è®°çš„æç¤ºç›¸å…³è”ã€‚æç¤ºå’Œé¡¹ç›®ä¹‹é—´çš„å…³è”æ˜¯é€šè¿‡ä¸¤æ­¥å¾®è°ƒè¿‡ç¨‹å»ºç«‹çš„ï¼Œå…¶ä¸­åŒ…æ‹¬ä¼˜åŒ–æ–‡æœ¬ç¼–ç å™¨åµŒå…¥çŸ©é˜µå’Œ UNet æ¨¡å‹æƒé‡ã€‚å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æç¤ºåˆ°é¡¹ç›®çš„äº¤äº’ï¼Œé€šè¿‡éš”ç¦»æ³¨æ„è®¡ç®—å’Œå€¼æ›´æ–°ã€‚ç„¶åï¼Œå¯ä»¥é€šè¿‡æ›´æ”¹æç¤ºã€é¡¹ç›®åŠå…¶ä¹‹é—´çš„å…³è”æ¥å®ç°å„ç§ç±»å‹çš„å›¾åƒç¼–è¾‘ã€‚ç„¶åï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡æ›´æ”¹ç›¸åº”çš„æç¤ºã€æ©ç å’Œé¡¹ç›®ï¼Œå¹¶è°ƒæ•´å®ƒä»¬ä¹‹é—´çš„å…³è”æ¥å®ç°å„ç§ç±»å‹çš„å›¾åƒç¼–è¾‘ã€‚è¿™ç§çµæ´»æ€§å…è®¸å¹¿æ³›çš„åˆ›é€ å¯èƒ½æ€§å’Œå¯¹ç¼–è¾‘è¿‡ç¨‹çš„ç²¾ç¡®æ§åˆ¶ã€‚æœ¬æ–‡åœ¨å››ä¸ªå›¾åƒç¼–è¾‘ä»»åŠ¡ä¸Šå±•ç¤ºäº†æœ¬æ–‡æ¡†æ¶çš„å¤šåŠŸèƒ½æ€§å’Œæ€§èƒ½ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œä½¿ç”¨ç¨³å®šæ‰©æ•£å’Œç¨³å®šæ‰©æ•£ XLã€‚æœ¬æ–‡æ€»ç»“æœ¬æ–‡çš„è´¡çŒ®å¦‚ä¸‹ï¼š â€¢ æœ¬æ–‡æå‡ºå»ºç«‹é¡¹ç›®æç¤ºå…³è”ä»¥å®ç°é¡¹ç›®ç¼–è¾‘ã€‚ â€¢ æœ¬æ–‡å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æ‰©æ•£æ¨¡å‹ä¸­çš„æ§åˆ¶æµã€‚ â€¢ æœ¬æ–‡æå‡º D-Edit ä½œä¸ºä¸€ç§å¤šåŠŸèƒ½æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚D-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŸºäºæ©ç çš„ç¼–è¾‘ä»¥åŠåŒæ—¶æ‰§è¡ŒåŸºäºæ–‡æœ¬å’Œå›¾åƒçš„ç¼–è¾‘çš„æ¡†æ¶ã€‚</p></li><li><p>Methodsï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºå»ºç«‹é¡¹ç›®æç¤ºå…³è”ä»¥å®ç°é¡¹ç›®ç¼–è¾‘ï¼› ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æ‰©æ•£æ¨¡å‹ä¸­çš„æ§åˆ¶æµï¼› ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡º D-Edit ä½œä¸ºä¸€ç§å¤šåŠŸèƒ½æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚D-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŸºäºæ©ç çš„ç¼–è¾‘ä»¥åŠåŒæ—¶æ‰§è¡ŒåŸºäºæ–‡æœ¬å’Œå›¾åƒçš„ç¼–è¾‘çš„æ¡†æ¶ã€‚</p></li><li><p>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡º D-Editï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹çš„å¤šåŠŸèƒ½å›¾åƒç¼–è¾‘æ¡†æ¶ã€‚D-Edit å°†ç»™å®šå›¾åƒåˆ†å‰²ä¸ºå¤šä¸ªé¡¹ç›®ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½è¢«åˆ†é…ä¸€ä¸ªæç¤ºæ¥æ§åˆ¶å…¶åœ¨æç¤ºç©ºé—´ä¸­çš„è¡¨ç¤ºã€‚å›¾åƒæç¤ºäº¤å‰æ³¨æ„åŠ›è¢«åˆ†è§£ä¸ºä¸€ç»„é¡¹ç›®æç¤ºäº¤äº’ã€‚æ¯ä¸ªæç¤ºé€šè¿‡å­¤ç«‹çš„äº¤å‰æ³¨æ„åŠ›è¢«çº¦æŸä¸ºä»…ä¸å®ƒæ§åˆ¶çš„é¡¹ç›®è¿›è¡Œäº¤äº’ï¼Œä»è€Œè§£è€¦äº†äº¤å‰æ³¨æ„åŠ›æ§åˆ¶ç®¡é“ã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºå»ºç«‹é¡¹ç›®æç¤ºå…³è”ä»¥å®ç°é¡¹ç›®ç¼–è¾‘ã€‚</li><li>å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„åŠ›æ¥è§£è€¦æ‰©æ•£æ¨¡å‹ä¸­çš„æ§åˆ¶æµã€‚</li><li>æå‡º D-Edit ä½œä¸ºä¸€ç§å¤šåŠŸèƒ½æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚D-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŸºäºæ©ç çš„ç¼–è¾‘ä»¥åŠåŒæ—¶æ‰§è¡ŒåŸºäºæ–‡æœ¬å’Œå›¾åƒçš„ç¼–è¾‘çš„æ¡†æ¶ã€‚ æ€§èƒ½ï¼š</li><li>åœ¨å››ä¸ªå›¾åƒç¼–è¾‘ä»»åŠ¡ä¸Šå±•ç¤ºäº†æœ¬æ–‡æ¡†æ¶çš„å¤šåŠŸèƒ½æ€§å’Œæ€§èƒ½ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œä½¿ç”¨ç¨³å®šæ‰©æ•£å’Œç¨³å®šæ‰©æ•£ XLã€‚ å·¥ä½œé‡ï¼š</li><li>æå‡ºäº†ä¸€ç§ä¸¤æ­¥å¾®è°ƒè¿‡ç¨‹æ¥å»ºç«‹æç¤ºå’Œé¡¹ç›®ä¹‹é—´çš„å…³è”ï¼ŒåŒ…æ‹¬ä¼˜åŒ–æ–‡æœ¬ç¼–ç å™¨åµŒå…¥çŸ©é˜µå’Œ UNet æ¨¡å‹æƒé‡ã€‚</li><li>å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æç¤ºåˆ°é¡¹ç›®çš„äº¤äº’ï¼Œé€šè¿‡éš”ç¦»æ³¨æ„è®¡ç®—å’Œå€¼æ›´æ–°ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-197c83cdebd23bdb14b8fb0a7b729711.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c1f65d83dbc51dc28ff510d4cc3b578f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-325295a9d8fc632369762af9b221cc1f.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-a471c060f1ae7bcb9959f797a6fb643a.jpg" align="middle"></details><h2 id="Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation"><a href="#Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation" class="headerlink" title="Pix2Gif: Motion-Guided Diffusion for GIF Generation"></a>Pix2Gif: Motion-Guided Diffusion for GIF Generation</h2><p><strong>Authors:Hitesh Kandala, Jianfeng Gao, Jianwei Yang</strong></p><p>We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation. We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig. To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts. Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence. In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects. After pretraining, we apply our model in a zero-shot manner to a number of video datasets. Extensive qualitative and quantitative experiments demonstrate the effectiveness of our model â€” it not only captures the semantic prompt from text but also the spatial ones from motion guidance. We train all our models using a single node of 16xV100 GPUs. Code, dataset and models are made public at: <a target="_blank" rel="noopener" href="https://hiteshk03.github.io/Pix2Gif/">https://hiteshk03.github.io/Pix2Gif/</a>.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.04634v2">PDF</a></p><p><strong>Summary</strong><br>å›¾åƒåˆ°GIFç”Ÿæˆçš„æ–°å¼è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼Œé‡‡ç”¨æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºæŒ‡å¯¼çš„å›¾åƒç¿»è¯‘æ–¹æ³•ï¼Œå¹¶æå‡ºæ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ä»¥ç©ºé—´è½¬æ¢ç‰¹å¾ï¼Œä»è€Œç¡®ä¿æ¨¡å‹éµå¾ªè¿åŠ¨æŒ‡å¯¼ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡º Pix2Gifï¼Œä¸€ç§è¿åŠ¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆã€‚</li><li>ä»¥å›¾åƒç¿»è¯‘é—®é¢˜ä¸ºåŸºç¡€ï¼Œç”±æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºæŒ‡å¯¼ã€‚</li><li>è®¾è®¡æ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œæ ¹æ®ä¸¤ç§æç¤ºå¯¹æºå›¾åƒç‰¹å¾è¿›è¡Œç©ºé—´è½¬æ¢ã€‚</li><li>å¼•å…¥æ„ŸçŸ¥æŸå¤±ï¼Œç¡®ä¿è½¬æ¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒç©ºé—´ä¸€è‡´ã€‚</li><li>ç²¾å¿ƒæ•´ç†æ•°æ®ï¼Œä» TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸­æå–è¿è´¯çš„å›¾åƒå¸§ã€‚</li><li>é‡‡ç”¨é›¶æ ·æœ¬æ–¹å¼å°†æ¨¡å‹åº”ç”¨äºå¤šä¸ªè§†é¢‘æ•°æ®é›†ã€‚</li><li>å®šæ€§å’Œå®šé‡å®éªŒéªŒè¯äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œä¸ä»…èƒ½æ•æ‰æ–‡æœ¬çš„è¯­ä¹‰æç¤ºï¼Œè¿˜èƒ½æ•æ‰è¿åŠ¨å¼•å¯¼çš„ç©ºé—´æç¤ºã€‚</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šPix2Gifï¼šåŸºäºè¿åŠ¨æŒ‡å¯¼çš„å›¾åƒè½¬ GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆ</li><li>ä½œè€…ï¼šHitesh K. Agrawalã€Yuke Zhuã€Jonathan T. Barronã€Phillip Isolaã€ Alexei A. Efros</li><li>éš¶å±å…³ç³»ï¼šä¼¯å…‹åˆ©åŠ å·å¤§å­¦</li><li>å…³é”®è¯ï¼šå›¾åƒåˆ°è§†é¢‘ç”Ÿæˆã€è¿åŠ¨å¼•å¯¼ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç¼–è¾‘</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2302.04208.pdfï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆæ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­çš„ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå®ƒéœ€è¦æ¨¡å‹åŒæ—¶ç†è§£æ–‡æœ¬å’Œè¿åŠ¨æç¤ºï¼Œå¹¶ç”Ÿæˆä¸æç¤ºç›¸ä¸€è‡´ä¸”å†…å®¹è¿è´¯çš„è§†é¢‘ã€‚ ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨æ–‡æœ¬æç¤ºæ¥æŒ‡å¯¼å›¾åƒç”Ÿæˆï¼Œä½†å®ƒä»¬åœ¨å¤„ç†è¿åŠ¨ä¿¡æ¯æ—¶å­˜åœ¨å±€é™æ€§ã€‚ç›´æ¥å°†è¿åŠ¨è¾“å…¥ä½œä¸ºæ–‡æœ¬æç¤ºå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹å¯¹å•ä¸ªæç¤ºè¯ç»™äºˆè¿‡å¤šçš„å…³æ³¨ï¼Œä»è€Œå¿½ç•¥å…¶ä»–é‡è¦çš„è¿åŠ¨ä¿¡æ¯ã€‚ ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ Pix2Gifï¼Œè¯¥æ¨¡å‹é€šè¿‡å¼•å…¥ä¸€ä¸ªè¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚è¯¥æ¨¡å—å°†è¿åŠ¨ä¿¡æ¯åµŒå…¥åˆ°å›¾åƒç‰¹å¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶éµå¾ªæŒ‡å®šçš„è¿åŠ¨è½¨è¿¹ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ªæ„ŸçŸ¥æŸå¤±ï¼Œä»¥ç¡®ä¿å˜å½¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒä¿æŒåœ¨åŒä¸€è¯­ä¹‰ç©ºé—´å†…ï¼Œä»è€Œä¿è¯å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚ ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼ŒPix2Gif æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰æ–‡æœ¬å’Œè¿åŠ¨æç¤ºä¸­çš„è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç»“æœã€‚å®éªŒç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li></ol><p>7.Methodsï¼š (1): Pix2Gifæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶ï¼Œå°†è¿åŠ¨ä¿¡æ¯åµŒå…¥å›¾åƒç‰¹å¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹éµå¾ªæŒ‡å®šçš„è¿åŠ¨è½¨è¿¹ã€‚ (2): Pix2Gifæ¨¡å‹å¼•å…¥äº†ä¸€ä¸ªæ„ŸçŸ¥æŸå¤±ï¼Œä»¥ç¡®ä¿å˜å½¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒä¿æŒåœ¨åŒä¸€è¯­ä¹‰ç©ºé—´å†…ï¼Œä»è€Œä¿è¯å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚ (3): Pix2Gifæ¨¡å‹åœ¨TGIFè§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰æ–‡æœ¬å’Œè¿åŠ¨æç¤ºä¸­çš„è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒåˆ°GIFï¼ˆè§†é¢‘ï¼‰ç»“æœã€‚</p><ol><li>ç»“è®ºï¼š ï¼ˆ1ï¼‰ï¼šPix2Gifæ¨¡å‹åœ¨å›¾åƒåˆ°GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œæå‡ºäº†ä¸€ç§åˆ›æ–°æ€§çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œæœ‰æ•ˆåœ°å°†æ–‡æœ¬å’Œè¿åŠ¨ä¿¡æ¯ç»“åˆèµ·æ¥ï¼Œç”Ÿæˆå†…å®¹è¿è´¯ã€æ—¶é—´ä¸€è‡´çš„é«˜è´¨é‡ç»“æœã€‚ ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œå°†è¿åŠ¨ä¿¡æ¯åµŒå…¥å›¾åƒç‰¹å¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹éµå¾ªæŒ‡å®šçš„è¿åŠ¨è½¨è¿¹ï¼Œä¿è¯äº†ç”Ÿæˆçš„å›¾åƒåºåˆ—åœ¨æ—¶é—´ä¸Šçš„è¿è´¯æ€§ã€‚</li><li>å¼•å…¥äº†æ„ŸçŸ¥æŸå¤±ï¼Œç¡®ä¿å˜å½¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒä¿æŒåœ¨åŒä¸€è¯­ä¹‰ç©ºé—´å†…ï¼Œä¿è¯äº†å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚ æ€§èƒ½ï¼š</li><li>åœ¨TGIFè§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒPix2Gifæ¨¡å‹åœ¨æ•æ‰æ–‡æœ¬å’Œè¿åŠ¨æç¤ºä¸­çš„è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç”Ÿæˆçš„å›¾åƒåˆ°GIFï¼ˆè§†é¢‘ï¼‰ç»“æœè´¨é‡è¾ƒé«˜ã€‚</li><li>ä¸ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒPix2Gifæ¨¡å‹åœ¨ç”Ÿæˆæ—¶é—´ä¸€è‡´çš„GIFæ–¹é¢è¡¨ç°å‡ºæ›´å¥½çš„æ•ˆæœã€‚ å·¥ä½œé‡ï¼š</li><li>Pix2Gifæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§å°ºå¯¸å›¾åƒå’Œé•¿è§†é¢‘åºåˆ—ã€‚</li><li>æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æ—¶é—´ä¹Ÿå—åˆ°å›¾åƒåˆ†è¾¨ç‡å’Œè§†é¢‘é•¿åº¦çš„å½±å“ã€‚</li></ol><details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-87f209086271d79f66fc2b71db813a89.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-ddec3a8952939ae9c917e7b1984fb9e4.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-538b38079b2f1cde247a179f7b6ab9b5.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg" align="middle"></details></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io/2024/03/11/Paper/2024-03-11/Diffusion%20Models/">https://kedreamix.github.io/2024/03/11/Paper/2024-03-11/Diffusion Models/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜:</span> <span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Diffusion-Models/">Diffusion Models</a></div><div class="post_share"><div class="social-share" data-image="https://picx.zhimg.com/v2-302c4a1ee77cbdfd8dba69c7d6a94497.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>èµåŠ©</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/03/13/Paper/2024-03-13/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-024cf388128af8fcbb5768c6b5cbd193.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">Diffusion Models</div></div></a></div><div class="next-post pull-right"><a href="/2024/03/11/Note/BlendShape/" title="Blendshapeå­¦ä¹ ç¬”è®°"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://p6-sign.toutiaoimg.com/pgc-image/2c8cbd123e00470e95500a8ae62da605~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1710668214&amp;x-signature=UHPhjWP4v96kbtfJzF97Z%2Bp3klc%3D" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">Blendshapeå­¦ä¹ ç¬”è®°</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>ç›¸å…³æ¨è</span></div><div class="relatedPosts-list"><div><a href="/2024/03/03/Paperscape/EMO/" title="EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6492e24fb03ffa98135dc584535ab7d9.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-03</div><div class="title">EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC</div></div></a></div><div><a href="/2024/01/24/Paper/2024-01-24/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-71a37c439c6714e8867560f580599d2f.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-24</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/01/30/Paper/2024-01-30/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-e55358c77a9d65f15701e8f33262e2a4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/09/Paper/2024-02-09/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-32488f736ee10537497afccc3a1a1d76.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-09</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/02/02/Paper/2024-02-02/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-5920453c69c00995f18077b22d4a790e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-02</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/2024/03/04/Paper/2024-03-04/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-1e4adba77bea5b8766028ddf128d14f8.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-04</div><div class="title">Diffusion Models</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-03-11-%E6%9B%B4%E6%96%B0"><span class="toc-text">2024-03-11 æ›´æ–°</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#VideoElevator-Elevating-Video-Generation-Quality-with-Versatile-Text-to-Image-Diffusion-Models"><span class="toc-text">VideoElevator: Elevating Video Generation Quality with Versatile Text-to-Image Diffusion Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Towards-Effective-Usage-of-Human-Centric-Priors-in-Diffusion-Models-for-Text-based-Human-Image-Generation"><span class="toc-text">Towards Effective Usage of Human-Centric Priors in Diffusion Models for Text-based Human Image Generation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Denoising-Autoregressive-Representation-Learning"><span class="toc-text">Denoising Autoregressive Representation Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Improving-Diffusion-Models-for-Virtual-Try-on"><span class="toc-text">Improving Diffusion Models for Virtual Try-on</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ELLA-Equip-Diffusion-Models-with-LLM-for-Enhanced-Semantic-Alignment"><span class="toc-text">ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Face2Diffusion-for-Fast-and-Editable-Face-Personalization"><span class="toc-text">Face2Diffusion for Fast and Editable Face Personalization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Improving-Diffusion-Based-Generative-Models-via-Approximated-Optimal-Transport"><span class="toc-text">Improving Diffusion-Based Generative Models via Approximated Optimal Transport</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#XPSR-Cross-modal-Priors-for-Diffusion-based-Image-Super-Resolution"><span class="toc-text">XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DiffClass-Diffusion-Based-Class-Incremental-Learning"><span class="toc-text">DiffClass: Diffusion-Based Class Incremental Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#AFreeCA-Annotation-Free-Counting-for-All"><span class="toc-text">AFreeCA: Annotation-Free Counting for All</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#An-Item-is-Worth-a-Prompt-Versatile-Image-Editing-with-Disentangled-Control"><span class="toc-text">An Item is Worth a Prompt: Versatile Image Editing with Disentangled Control</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation"><span class="toc-text">Pix2Gif: Motion-Guided Diffusion for GIF Generation</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image:url('https://picx.zhimg.com/v2-302c4a1ee77cbdfd8dba69c7d6a94497.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>æ¡†æ¶</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="ç®€ç¹è½¬æ¢">ç°¡</button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const e of document.querySelectorAll('script[type^="math/tex"]')){const a=!!e.type.match(/; *mode=display/),n=new t.options.MathItem(e.textContent,t.inputJax[0],a),s=document.createTextNode("");e.parentNode.replaceChild(s,e),n.start={node:s,delim:"",n:0},n.end={node:s,delim:"",n:0},t.math.push(n)}},""]}}};const t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t)}</script></div><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("å·²æŒ‚è½½butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/25/Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="2024/01/25/Paper/3DGS Survey/" alt="">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting ä»Šå¤©æƒ³ä»‹ç»çš„æ˜¯`ZJU`å¸¦æ¥çš„`3DGS`çš„é¦–ç¯‡ç»¼è¿°`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="2024/01/25/Paper/3DGS Survey/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">CUDAç¼–ç¨‹å­¦ä¹ ï¼šè‡ªå®šä¹‰Pytorch+cpp/cuda extension</a><div class="blog-slider__text">è™½ç„¶è¯´PyTorchæä¾›äº†ä¸°å¯Œçš„ä¸ç¥ç»ç½‘ç»œã€å¼ é‡ä»£æ•°ã€æ•°æ®å¤„ç†ç­‰ç›¸å…³çš„æ“ä½œï¼Œä½†æ˜¯æœ‰æ—¶å€™ä½ å¯èƒ½éœ€è¦**æ›´å®šåˆ¶åŒ–çš„æ“ä½œ**ï¼Œæ¯”å¦‚ä½¿ç”¨è®ºæ–‡ä¸­çš„æ–°å‹æ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…å®ç°ä½œä¸ºç ”ç©¶ä¸€éƒ¨åˆ†å¼€å‘çš„æ“ä½œã€‚åœ¨PyTorchä¸­ï¼Œæœ€ç®€å•çš„é›†æˆè‡ªå®šä¹‰æ“ä½œçš„æ–¹å¼æ˜¯åœ¨Pythonä¸­ç¼–å†™ï¼Œé€šè¿‡æ‰©å±•Functionå’ŒModuleæ¥å®ç°ï¼Œ</div><a class="blog-slider__button" href="2023/12/12/CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesisï¼Œ è¿™ä»½èµ„æºåº“æ•´ç†äº†ä¸ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)å’Œç¥ç»è¾å°„åœº(NeRF)ç›¸å…³çš„è®ºæ–‡ã€ä»£ç å’Œèµ„æº,é‡ç‚¹å…³æ³¨åŸºäºå›¾åƒå’ŒéŸ³é¢‘çš„è™šæ‹Ÿè®²è¯å¤´åˆæˆè®ºæ–‡åŠå·²å‘å¸ƒä»£ç ã€‚å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªä»“åº“æœ‰ç”¨,è¯·starâ­æ”¯æŒ!</div><a class="blog-slider__button" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/17/Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023/12/17/Project/ChatPaperFree/" alt="">ChatPaperFree GeminiProï¼ˆä¸€åˆ†é’Ÿè¯»è®ºæ–‡ï¼‰</a><div class="blog-slider__text">ChatPaperFreeæ˜¯ä¸€ä¸ªåŸºäºChatGPTçš„è‡ªåŠ¨è®ºæ–‡æ‘˜è¦ç”Ÿæˆå™¨ï¼Œåœ¨ChatPaperçš„åŸºç¡€ä¸Šè¿›è¡Œçš„æ›´æ–°ï¼Œé‡‡ç”¨äº†æœ€è¿‘ç”±Googleå¼€æºçš„Gemini Proå¤§æ¨¡å‹ã€‚ç›®å‰,æˆ‘ä»¬èƒ½å¤Ÿå¯¹ç”¨æˆ·è¾“å…¥çš„è®ºæ–‡è¿›è¡Œè‡ªåŠ¨æ€»ç»“ã€‚æœªæ¥,æˆ‘è¿˜è®¡åˆ’åŠ å…¥å¯¹è®ºæ–‡å›¾ç‰‡/è¡¨æ ¼/å…¬å¼çš„è¯†åˆ« extraction,ä»è€Œç”Ÿæˆæ›´å…¨é¢è€Œæ˜“è¯»çš„æ€»ç»“ã€‚</div><a class="blog-slider__button" href="2023/12/17/Project/ChatPaperFree/" alt="">è¯¦æƒ…   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script></body></html>