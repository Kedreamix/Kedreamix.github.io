<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Talking Head Generation | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-08-27  G3FA Geometry-guided GAN for Face Animation"><meta property="og:type" content="article"><meta property="og:title" content="Talking Head Generation"><meta property="og:url" content="https://kedreamix.github.io/2024/08/27/Paper/2024-08-27/Talking%20Head%20Generation/index.html"><meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World"><meta property="og:description" content="Talking Head Generation 方向最新论文已更新，请持续关注 Update in 2024-08-27  G3FA Geometry-guided GAN for Face Animation"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://picx.zhimg.com/v2-c34f63ea7ef51bb19e0c883a90f1c6de.jpg"><meta property="article:published_time" content="2024-08-26T16:38:00.000Z"><meta property="article:modified_time" content="2024-08-26T16:38:00.516Z"><meta property="article:author" content="Kedreamix"><meta property="article:tag" content="Talking Head Generation"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://picx.zhimg.com/v2-c34f63ea7ef51bb19e0c883a90f1c6de.jpg"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/2024/08/27/Paper/2024-08-27/Talking%20Head%20Generation/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-74LZ5BEQQ1")</script><script>const GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!0,languages:{hits_empty:"找不到您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},noticeOutdate:{limitDay:500,position:"top",messagePrev:"It has been",messageNext:"days since the last update, the content of the article may be outdated."},highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:200},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!0,post:!0},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"fancybox",Snackbar:void 0,infinitegrid:{js:"https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!0,islazyload:!0,isAnchor:!1,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Talking Head Generation",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2024-08-27 00:38:00"}</script><script>(e=>{e.saveToLocal={set:(e,t,o)=>{if(0===o)return;const a={value:t,expiry:Date.now()+864e5*o};localStorage.setItem(e,JSON.stringify(a))},get:e=>{const t=localStorage.getItem(e);if(!t)return;const o=JSON.parse(t);if(!(Date.now()>o.expiry))return o.value;localStorage.removeItem(e)}},e.getScript=(e,t={})=>new Promise(((o,a)=>{const n=document.createElement("script");n.src=e,n.async=!0,n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},Object.keys(t).forEach((e=>{n.setAttribute(e,t[e])})),document.head.appendChild(n)})),e.getCSS=(e,t=!1)=>new Promise(((o,a)=>{const n=document.createElement("link");n.rel="stylesheet",n.href=e,t&&(n.id=t),n.onerror=a,n.onload=n.onreadystatechange=function(){const e=this.readyState;e&&"loaded"!==e&&"complete"!==e||(n.onload=n.onreadystatechange=null,o())},document.head.appendChild(n)})),e.activateDarkMode=()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},e.activateLightMode=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const t=saveToLocal.get("theme"),o=(new Date).getHours();void 0===t?o<=6||o>=24?activateDarkMode():activateLightMode():"light"===t?activateLightMode():activateDarkMode();const a=saveToLocal.get("aside-status");void 0!==a&&("hide"===a?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})(window)</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload='this.media="all"'><meta name="generator" content="Hexo 7.0.0"><style>.github-emoji{position:relative;display:inline-block;width:1.2em;min-height:1.2em;overflow:hidden;vertical-align:top;color:transparent}.github-emoji>span{position:relative;z-index:10}.github-emoji .fancybox,.github-emoji img{margin:0!important;padding:0!important;border:none!important;outline:0!important;text-decoration:none!important;user-select:none!important;cursor:auto!important}.github-emoji img{height:1.2em!important;width:1.2em!important;position:absolute!important;left:50%!important;top:50%!important;transform:translate(-50%,-50%)!important;user-select:none!important;cursor:auto!important}.github-emoji-fallback{color:inherit}.github-emoji-fallback img{opacity:0!important}</style><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml"></head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{const d=document.getElementById("loading-box"),e=document.body,o=()=>{e.style.overflow="",d.classList.add("loaded")},l=()=>{e.style.overflow="hidden",d.classList.remove("loaded")};l(),window.addEventListener("load",(()=>{o()}))})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">278</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url('https://picx.zhimg.com/v2-c34f63ea7ef51bb19e0c883a90f1c6de.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Talking Head Generation</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-08-26T16:38:00.000Z" title="发表于 2024-08-27 00:38:00">2024-08-27</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-08-26T16:38:00.516Z" title="更新于 2024-08-27 00:38:00">2024-08-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>12分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title="Talking Head Generation"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote><p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p></blockquote><h1 id="2024-08-27-更新"><a href="#2024-08-27-更新" class="headerlink" title="2024-08-27 更新"></a>2024-08-27 更新</h1><h2 id="G3FA-Geometry-guided-GAN-for-Face-Animation"><a href="#G3FA-Geometry-guided-GAN-for-Face-Animation" class="headerlink" title="G3FA: Geometry-guided GAN for Face Animation"></a>G3FA: Geometry-guided GAN for Face Animation</h2><p><strong>Authors:Alireza Javanmardi, Alain Pagani, Didier Stricker</strong></p><p>Animating human face images aims to synthesize a desired source identity in a natural-looking way mimicking a driving video’s facial movements. In this context, Generative Adversarial Networks have demonstrated remarkable potential in real-time face reenactment using a single source image, yet are constrained by limited geometry consistency compared to graphic-based approaches. In this paper, we introduce Geometry-guided GAN for Face Animation (G3FA) to tackle this limitation. Our novel approach empowers the face animation model to incorporate 3D information using only 2D images, improving the image generation capabilities of the talking head synthesis model. We integrate inverse rendering techniques to extract 3D facial geometry properties, improving the feedback loop to the generator through a weighted average ensemble of discriminators. In our face reenactment model, we leverage 2D motion warping to capture motion dynamics along with orthogonal ray sampling and volume rendering techniques to produce the ultimate visual output. To evaluate the performance of our G3FA, we conducted comprehensive experiments using various evaluation protocols on VoxCeleb2 and TalkingHead benchmarks to demonstrate the effectiveness of our proposed framework compared to the state-of-the-art real-time face animation methods.</p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.13049v1">PDF</a> BMVC 2024, Accepted</p><p><strong>Summary</strong><br>通过引入几何引导的 GAN 技术（G3FA），本文旨在通过仅使用2D图像提升面部动画生成能力，克服现有基于图形的方法的局限性。</p><p><strong>Key Takeaways</strong></p><ul><li>使用Geometry-guided GAN for Face Animation（G3FA）技术，通过仅使用2D图像，增强面部动画生成模型的能力。</li><li>引入反向渲染技术，提取3D面部几何属性，通过加权平均鉴别器集成改进生成器的反馈循环。</li><li>利用2D运动变形捕捉运动动态，结合正交光线采样和体积渲染技术生成最终视觉输出。</li><li>在VoxCeleb2和TalkingHead基准上进行广泛实验评估，展示G3FA相对于最先进的实时面部动画方法的效果。</li><li>Generative Adversarial Networks（GANs）在单源图像实时面部重现中展示出显著潜力，但在几何一致性方面受限于图形方法。</li><li>G3FA通过引入几何引导的方法，提升了面部动画模型的3D信息整合能力，超越传统的基于图形的方法。</li><li>实验结果表明，G3FA在面部动画合成中具有明显的优势和改进，特别是在几何一致性和视觉输出质量方面。</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: G3FA：几何引导GAN人脸动画技术</p></li><li><p>Authors: Alireza Javanmardi, Alain Pagani, Didier Stricker</p></li><li><p>Affiliation: 德国人工智能研究中心（DFKI）凯泽斯劳滕分部。</p></li><li><p>Keywords: Face Animation；Generative Adversarial Networks (GAN)；Geometry-guided；Inverse Rendering Techniques；Talking Head Generation</p></li><li><p>Urls: Paper链接（由于我无法直接查看外部链接，无法提供具体链接），Github代码链接：<a target="_blank" rel="noopener" href="https://github.com/dfki-av/G3FA">Github链接</a>（如果存在，填写相应链接；如果不存在，填写”None”）</p></li><li><p>Summary:</p><ul><li><p>(1)研究背景：随着科技的发展，生成对抗网络（GAN）在实时人脸复现领域展现出巨大潜力。然而，与基于图形的方法相比，它们在几何一致性方面存在局限性。本文旨在解决这一问题。</p><p>-(2)过去的方法及其问题：当前的人脸动画方法主要集中在基于图形的头部合成，虽然它们在几何方面表现出色，但在生成自然流动的面部动画方面存在局限。因此，需要一种新的方法能够结合2D图像和3D信息，以提高生成对话头部模型的图像生成能力。</p><p>-(3)研究方法：本文提出了一个名为几何引导GAN人脸动画（G3FA）的新方法。该方法通过集成逆向渲染技术来提取3D面部几何属性，并通过加权平均判别器的集合来改善生成器的反馈循环。在面部复现模型中，利用2D运动扭曲捕捉运动动态，结合正交射线采样和体积渲染技术产生最终的视觉输出。</p><p>-(4)任务与性能：本文在VoxCeleb2和TalkingHead基准测试集上进行了实验，以评估G3FA的性能。实验结果表明，与最新的实时人脸动画方法相比，该方法在几何一致性和图像生成质量方面取得了显著的提升。性能结果支持了该方法的目标，证明了其在实际应用中的有效性。</p></li></ul></li></ol><p>希望这个回答能够帮助您理解和总结这篇论文。</p><ol><li>方法论：</li></ol><ul><li>(1) 提出研究问题：针对现有的人脸动画方法在几何一致性方面存在的局限性，提出一种新的几何引导GAN人脸动画（G3FA）方法。</li><li>(2) 集成逆向渲染技术：通过逆向渲染技术提取3D面部几何属性，为面部动画提供更准确的几何信息。</li><li>(3) 采用加权平均判别器的集合：改善生成器的反馈循环，提高模型在面部复现中的性能。</li><li>(4) 结合2D运动扭曲和正交射线采样及体积渲染技术：利用2D运动扭曲捕捉运动动态，结合正交射线采样和体积渲染技术生成最终的视觉输出，实现自然流动的面部动画。</li><li>(5) 实验验证：在VoxCeleb2和TalkingHead基准测试集上进行实验，评估G3FA的性能，并与最新的实时人脸动画方法进行对比。实验结果表明，G3FA在几何一致性和图像生成质量方面取得了显著的提升。</li></ul><p>以上就是这篇论文的方法论概述。</p><ol><li>Conclusion:</li></ol><p>（1）这篇工作的意义在于提出了一种新的几何引导GAN人脸动画技术（G3FA），该技术结合了逆向渲染技术和生成对抗网络（GAN），解决了现有人脸动画技术在几何一致性方面的局限性，提高了生成对话头部模型的图像生成能力，为实时人脸复现领域的发展提供了新的思路和方法。</p><p>（2）创新点：该文章提出了一个全新的几何引导GAN人脸动画技术，集成了逆向渲染技术提取3D面部几何属性，采用加权平均判别器的集合改善生成器的反馈循环，并结合2D运动扭曲和正交射线采样及体积渲染技术生成最终的视觉输出。<br>性能：在VoxCeleb2和TalkingHead基准测试集上的实验结果表明，与最新的实时人脸动画方法相比，G3FA在几何一致性和图像生成质量方面取得了显著的提升，证明了其在实际应用中的有效性。<br>工作量：文章的理论和实验工作量较大，从方法的提出到实验验证都经过了详尽的阐述和证明，但具体的代码实现和实验细节可能需要进一步的研究和探讨。</p><p>总的来说，该文章在人脸动画技术方面取得了显著的进展，为未来的研究提供了新的思路和方法。</p><details><summary>点此查看论文截图</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c34f63ea7ef51bb19e0c883a90f1c6de.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-49e114eb9054bd8c4253d32bdf3bcc60.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6db36f4238391f72542ab6c753fdb12e.jpg" align="middle"></details><h2 id="T3M-Text-Guided-3D-Human-Motion-Synthesis-from-Speech"><a href="#T3M-Text-Guided-3D-Human-Motion-Synthesis-from-Speech" class="headerlink" title="T3M: Text Guided 3D Human Motion Synthesis from Speech"></a>T3M: Text Guided 3D Human Motion Synthesis from Speech</h2><p><strong>Authors:Wenshuo Peng, Kaipeng Zhang, Sai Qian Zhang</strong></p><p>Speech-driven 3D motion synthesis seeks to create lifelike animations based on human speech, with potential uses in virtual reality, gaming, and the film production. Existing approaches reply solely on speech audio for motion generation, leading to inaccurate and inflexible synthesis results. To mitigate this problem, we introduce a novel text-guided 3D human motion synthesis method, termed \textit{T3M}. Unlike traditional approaches, T3M allows precise control over motion synthesis via textual input, enhancing the degree of diversity and user customization. The experiment results demonstrate that T3M can greatly outperform the state-of-the-art methods in both quantitative metrics and qualitative evaluations. We have publicly released our code at \href{<a target="_blank" rel="noopener" href="https://github.com/Gloria2tt/T3M.git}{https://github.com/Gloria2tt/T3M.git}">https://github.com/Gloria2tt/T3M.git}{https://github.com/Gloria2tt/T3M.git}</a></p><p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2408.12885v1">PDF</a> 10 pages,4figures</p><p><strong>Summary</strong><br>基于文本的3D人体运动合成方法（T3M）通过文本输入精确控制动作合成，显著提升多样性和用户定制化程度。</p><p><strong>Key Takeaways</strong></p><ul><li>T3M方法利用文本指导3D人体运动合成，与传统方法相比具有更高的精确控制能力。</li><li>相比现有方法，T3M在定量和定性评估中表现出色。</li><li>T3M能够在虚拟现实、游戏和电影制作中产生逼真的动画效果。</li><li>传统方法仅依赖语音音频生成动作，导致合成结果不精确和不灵活。</li><li>T3M通过公开发布代码促进了该领域的进展。</li><li>实验结果显示，T3M在动作合成方面远优于现有的技术。</li><li>T3M方法能够满足用户对动作合成高度个性化和多样性的需求。</li></ul><p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><p>Title: 基于文本引导的三维人体运动合成方法（T3M）研究</p></li><li><p>Authors: Peng Wenshuo, Zhang Kaipeng, Zhang Sai Qian</p></li><li><p>Affiliation: 第一作者来自上海人工智能实验室OpenGVLab。</p></li><li><p>Keywords: Speech-driven 3D motion synthesis, text-guided motion synthesis, human motion generation, virtual reality, gaming, film production.</p></li><li><p>Urls: <a target="_blank" rel="noopener" href="https://github.com/Gloria2tt/T3M.git">https://github.com/Gloria2tt/T3M.git</a> （Github代码链接）或论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.12885v1">https://arxiv.org/abs/2408.12885v1</a> （论文链接）</p></li><li><p>Summary:</p><ul><li><p>(1) 研究背景：本文研究了基于文本引导的三维人体运动合成方法，旨在从语音生成逼真的动画，在虚拟现实、游戏和电影制作等领域具有潜在应用。</p></li><li><p>(2) 过去的方法及问题：现有方法仅依赖语音音频进行运动生成，导致生成的运动不准确且不够灵活。缺乏精确控制，无法捕捉不同语境下的细微差别。</p></li><li><p>(3) 研究方法：本文提出了一种新的文本引导的三维人体运动合成方法，称为T3M。该方法允许通过文本输入精确地控制运动合成，提高了多样性和用户定制程度。实验结果表明，T3M在定量指标和定性评估上均大大优于现有方法。</p></li><li><p>(4) 任务与性能：本文的方法应用于基于文本的3D人体运动合成任务，实现了较高的性能。实验结果表明，T3M能够生成更细腻、更逼真的运动，满足用户对不同运动风格的定制需求，支持新兴行业如AI驱动的电影或动画制作的需求。性能支持目标的达成。</p></li></ul></li><li>Methods:</li></ol><ul><li>(1) 研究背景与目的：文章针对基于文本引导的三维人体运动合成方法进行研究，旨在通过语音生成逼真的动画，并在虚拟现实、游戏和电影制作等领域具有潜在应用。为此目的，文章提出了一种新的文本引导的三维人体运动合成方法，称为T3M。</li><li>(2) 方法概述：T3M方法允许通过文本输入精确地控制运动合成，旨在解决现有方法仅依赖语音音频进行运动生成导致的不准确和不灵活问题。它引入了文本作为输入信息的一部分，以便更精确地控制并捕捉不同语境下的细微差别。具体来说，它将文本信息与语音音频结合，进行三维人体运动的合成。此外，T3M方法还包括一系列技术细节的实现，如数据处理、模型训练、模型优化等步骤。具体来说，首先进行数据采集和预处理，包括获取高质量的语音数据和相应的运动捕捉数据；接着设计深度学习模型架构并训练模型；然后通过实验验证模型性能并进行优化调整。实验结果表明，T3M在定量指标和定性评估上均大大优于现有方法。最终能够生成更细腻、更逼真的运动，满足用户对不同运动风格的定制需求。同时，该研究还探讨了该方法在AI驱动的电影或动画制作等领域的应用前景。</li><li>(3) 实验验证与性能评估：本研究对所提出的T3M方法进行了全面的实验验证与性能评估。通过与现有方法的比较实验结果表明，基于文本的T3M方法在三维人体运动合成任务上实现了较高的性能。此外，该研究还进行了定性评估和用户调研以验证其生成的运动是否满足用户的定制需求并具有较高的逼真度。实验数据证明了该方法的可靠性和有效性。同时该文章还提供了实验数据的详细分析和解释以支持其结论的合理性。这些实验不仅验证了方法的性能同时也为未来的研究提供了有价值的参考和启示。</li></ul><ol><li>Conclusion:</li></ol><ul><li>(1) 研究意义：这项工作提出了一种新的文本引导的三维人体运动合成方法，具有重要的应用价值。它不仅扩展了基于语音的人体运动生成技术的边界，也为虚拟现实、游戏和电影制作等领域的实际应用提供了有力支持。</li><li>(2) 优缺点：<ul><li>创新点：文章引入了文本作为输入信息的一部分，以更精确地控制并捕捉不同语境下的细微差别，这是其显著的创新点。此外，该研究还采用了先进的深度学习技术和优化方法，提高了运动合成的多样性和用户定制程度。</li><li>性能：实验结果表明，T3M方法在定量指标和定性评估上均大大优于现有方法，具有较高的性能。生成的动画既细腻又逼真，能够满足用户对不同运动风格的定制需求。</li><li>工作量：文章详细阐述了数据采集、预处理、模型设计、训练、验证和优化的全过程，展现了扎实的研究功底和大量的工作量。然而，对于某些技术细节和实现过程的描述可能还不够详尽，需要进一步的深入了解和探索。</li></ul></li></ul><details><summary>点此查看论文截图</summary><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-e5f73e6708193054d66dfcaeee27fdbc.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-1d47efc6e7d6a2849ad26a9ba0e089e6.jpg" align="middle"> <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-73c56270d4e59e7ee5efc0c7818e707c.jpg" align="middle"></details></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接:</span> <span class="post-copyright-info"><a href="https://kedreamix.github.io/2024/08/27/Paper/2024-08-27/Talking%20Head%20Generation/">https://kedreamix.github.io/2024/08/27/Paper/2024-08-27/Talking Head Generation/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Talking-Head-Generation/">Talking Head Generation</a></div><div class="post_share"><div class="social-share" data-image="https://picx.zhimg.com/v2-c34f63ea7ef51bb19e0c883a90f1c6de.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/08/27/Paper/2024-08-27/3DGS/" title="3DGS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-31465c3858690fd7d703bc6573e25c2f.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">3DGS</div></div></a></div><div class="next-post pull-right"><a href="/2024/08/23/Paper/2024-08-23/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-716fe10a223067eb10ce73bb6c12c429.jpg" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Diffusion Models</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/03/03/Paperscape/EMO/" title="EMO Emote Portrait Alive - 阿里HumanAIGC"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6492e24fb03ffa98135dc584535ab7d9.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-03</div><div class="title">EMO Emote Portrait Alive - 阿里HumanAIGC</div></div></a></div><div><a href="/2024/03/15/Paperscape/Real3D-Portrait/" title="REAL3D-PORTRAIT ONE-SHOT REALISTIC 3D TALKING PORTRAIT SYNTHESIS"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-68585b79de5f83b0dfa23304f41b9b98.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-15</div><div class="title">REAL3D-PORTRAIT ONE-SHOT REALISTIC 3D TALKING PORTRAIT SYNTHESIS</div></div></a></div><div><a href="/2024/03/05/Paperscape/VividTalk/" title="VividTalk One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-8521b04f82075cc27b5e95148dba9792.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-05</div><div class="title">VividTalk One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior</div></div></a></div><div><a href="/2024/03/07/Paperscape/SyncTalk/" title="SyncTalk The Devil is in the Synchronization for Talking Head Synthesis"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-a57e0937b2f452009023394a59529dfb.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-07</div><div class="title">SyncTalk The Devil is in the Synchronization for Talking Head Synthesis</div></div></a></div><div><a href="/2024/01/20/Project/Linly-Talker%20-%20GPT-SoVITS/" title="数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-20</div><div class="title">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</div></div></a></div><div><a href="/2024/03/18/Project/SyncTalk/" title="SyncTalk实验笔记"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-3866dff2d07194c235eefab923f694c5.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-18</div><div class="title">SyncTalk实验笔记</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-08-27-%E6%9B%B4%E6%96%B0"><span class="toc-text">2024-08-27 更新</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#G3FA-Geometry-guided-GAN-for-Face-Animation"><span class="toc-text">G3FA: Geometry-guided GAN for Face Animation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#T3M-Text-Guided-3D-Human-Motion-Synthesis-from-Speech"><span class="toc-text">T3M: Text Guided 3D Human Motion Synthesis from Speech</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image:url('https://picx.zhimg.com/v2-c34f63ea7ef51bb19e0c883a90f1c6de.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">簡</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.autoSpacingPage():getScript("https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js").then((()=>{pangu.autoSpacingPage()}))}function panguInit(){panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><div class="js-pjax"><script>if(window.MathJax)MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise();else{window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"ams"},chtml:{scale:1.1},options:{renderActions:{findScript:[10,t=>{for(const e of document.querySelectorAll('script[type^="math/tex"]')){const a=!!e.type.match(/; *mode=display/),n=new t.options.MathItem(e.textContent,t.inputJax[0],a),s=document.createTextNode("");e.parentNode.replaceChild(s,e),n.start={node:s,delim:"",n:0},n.end={node:s,delim:"",n:0},t.math.push(n)}},""]}}};const t=document.createElement("script");t.src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t)}</script></div><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><script data-pjax>function butterfly_swiper_injector_config(){var a=document.getElementById("recent-posts");console.log("已挂载butterfly_swiper"),a.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/25/Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="2024/01/25/Paper/3DGS Survey/" alt="">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting 今天想介绍的是`ZJU`带来的`3DGS`的首篇综述`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="2024/01/25/Paper/3DGS Survey/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/12/CUDA/Pytorch+cppcuda extension 学习/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="2023/12/12/CUDA/Pytorch+cppcuda extension 学习/" alt="">CUDA编程学习：自定义Pytorch+cpp/cuda extension</a><div class="blog-slider__text">虽然说PyTorch提供了丰富的与神经网络、张量代数、数据处理等相关的操作，但是有时候你可能需要**更定制化的操作**，比如使用论文中的新型激活函数，或者实现作为研究一部分开发的操作。在PyTorch中，最简单的集成自定义操作的方式是在Python中编写，通过扩展Function和Module来实现，</div><a class="blog-slider__button" href="2023/12/12/CUDA/Pytorch+cppcuda extension 学习/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker/" alt="">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</a><div class="blog-slider__text">Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</a><div class="blog-slider__text">Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。</div><a class="blog-slider__button" href="2024/01/20/Project/Linly-Talker - GPT-SoVITS/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis， 这份资源库整理了与生成对抗网络(GAN)和神经辐射场(NeRF)相关的论文、代码和资源,重点关注基于图像和音频的虚拟讲话头合成论文及已发布代码。如果您觉得这个仓库有用,请star⭐支持!</div><a class="blog-slider__button" href="2024/01/01/Paper/Awesome-Talking-Head-Synthesis/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/12/17/Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023/12/17/Project/ChatPaperFree/" alt="">ChatPaperFree GeminiPro（一分钟读论文）</a><div class="blog-slider__text">ChatPaperFree是一个基于ChatGPT的自动论文摘要生成器，在ChatPaper的基础上进行的更新，采用了最近由Google开源的Gemini Pro大模型。目前,我们能够对用户输入的论文进行自动总结。未来,我还计划加入对论文图片/表格/公式的识别 extraction,从而生成更全面而易读的总结。</div><a class="blog-slider__button" href="2023/12/17/Project/ChatPaperFree/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>')}for(var elist="undefined".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;("all"===epage&&0==flag||epage===cpage)&&butterfly_swiper_injector_config()</script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script></body></html>