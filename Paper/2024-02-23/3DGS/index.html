<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>3DGS | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2024-02-23  Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting">
<meta property="og:type" content="article">
<meta property="og:title" content="3DGS">
<meta property="og:url" content="https://kedreamix.github.io/Paper/2024-02-23/3DGS/index.html">
<meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World">
<meta property="og:description" content="3DGS 方向最新论文已更新，请持续关注 Update in 2024-02-23  Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg">
<meta property="article:published_time" content="2024-02-22T17:38:45.000Z">
<meta property="article:modified_time" content="2024-02-22T17:38:45.284Z">
<meta property="article:author" content="Kedreamix">
<meta property="article:tag" content="3DGS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/Paper/2024-02-23/3DGS/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-74LZ5BEQQ1');
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":true,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '3DGS',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-23 01:38:45'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 24
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"  media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">304</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"/><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">3DGS</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-22T17:38:45.000Z" title="发表于 2024-02-23 01:38:45">2024-02-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-22T17:38:45.284Z" title="更新于 2024-02-23 01:38:45">2024-02-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>30分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="3DGS"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>⚠️ 以下所有内容总结都来自于 Google的大语言模型<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>的能力，如有错误，仅供参考，谨慎使用<br>🔴 请注意：千万不要用于严肃的学术场景，只能用于论文阅读前的初筛！<br>💗 如果您觉得我们的项目对您有帮助 <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ，还请您给我们一些鼓励！⭐️ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFace免费体验</a></p>
</blockquote>
<h1 id="2024-02-23-更新"><a href="#2024-02-23-更新" class="headerlink" title="2024-02-23 更新"></a>2024-02-23 更新</h1><h2 id="Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting"><a href="#Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting" class="headerlink" title="Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting"></a>Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting</h2><p><strong>Authors:Joongho Jo, Hyeongwon Kim, Jongsun Park</strong></p>
<p>3D Gaussian splatting (3D-GS) is a new rendering approach that outperforms the neural radiance field (NeRF) in terms of both speed and image quality. 3D-GS represents 3D scenes by utilizing millions of 3D Gaussians and projects these Gaussians onto the 2D image plane for rendering. However, during the rendering process, a substantial number of unnecessary 3D Gaussians exist for the current view direction, resulting in significant computation costs associated with their identification. In this paper, we propose a computational reduction technique that quickly identifies unnecessary 3D Gaussians in real-time for rendering the current view without compromising image quality. This is accomplished through the offline clustering of 3D Gaussians that are close in distance, followed by the projection of these clusters onto a 2D image plane during runtime. Additionally, we analyze the bottleneck associated with the proposed technique when executed on GPUs and propose an efficient hardware architecture that seamlessly supports the proposed scheme. For the Mip-NeRF360 dataset, the proposed technique excludes 63% of 3D Gaussians on average before the 2D image projection, which reduces the overall rendering computation by almost 38.3% without sacrificing peak-signal-to-noise-ratio (PSNR). The proposed accelerator also achieves a speedup of 10.7x compared to a GPU. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.13827v1">PDF</a> </p>
<p><strong>Summary</strong><br>3D 高斯散splatting 通过聚类 和 投影优化，减少了 38.3% 的渲染计算，且不损失图像质量。</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D 高斯散splatting（3D-GS）是一种新的渲染方法，在速度和图像质量上优于神经辐射场（NeRF）。</li>
<li>3D-GS 使用数百万个 3D 高斯表示 3D 场景，并将这些高斯投影到 2D 图像平面上进行渲染。</li>
<li>在渲染过程中，大量不必要的高斯存在于当前视图方向，导致与识别它们相关的计算成本巨大。</li>
<li>提出了一种计算简化技术，可在运行时快速识别出不必要的高斯，用于渲染当前视图，且不损害图像质量。</li>
<li>这种简化技术方法是离线对距离相近的高斯进行聚类，然后在运行时将这些集群投影到 2D 图像平面上。</li>
<li>对该技术在 GPU 上执行时的瓶颈进行了分析，并提出了一种与该方案无缝兼容的高效硬件架构。</li>
<li>对于 Mip-NeRF360 数据集，该技术在 2D 图像投影之前平均排除了 63% 的高斯，将整体渲染计算减少了 38.3%，且不损失峰值信噪比 (PSNR)。</li>
<li>该加速器与 GPU 相比，还实现了 10.7 倍的加速。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>题目：使用聚类识别不必要的 3D 高斯体，以快速渲染 3D 高斯体飞溅</li>
<li>作者：Joongho Jo、Hyeongwon Kim 和 Jongsun Park</li>
<li>隶属机构：韩国大学电气工程学院</li>
<li>关键词：3D 高斯体飞溅、渲染、NeRF、神经辐射场、硬件加速器</li>
<li>论文链接：Paper_info:Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering of 3D Gaussian Splatting，Github 链接：无</li>
<li>摘要：</li>
</ol>
<p>（1）研究背景：在计算机视觉应用中，例如增强现实 (AR)、虚拟现实 (VR) 和元宇宙，快速且高质量的图像渲染非常重要。虽然已经广泛研究了使用深度神经网络的渲染技术，例如神经辐射场 (NeRF)，但 3D 高斯体飞溅 (3D-GS) 作为一种新的渲染方法，最近因其与传统 NeRF 相比能够快速渲染高质量图像而备受关注。3D-GS 利用数百万个 3D 高斯体来表示复杂的 3D 场景，并通过将 3D 高斯体投影到 2D 图像平面上来渲染 3D 场景。</p>
<p>（2）过去的方法及其问题：3D-GS 渲染过程主要分为两步：首先，将所有 3D 高斯体投影到 2D 图像平面上，并识别影响 2D 图像颜色的 3D 高斯体。然后，使用影响颜色的已识别 3D 高斯体计算 2D 图像中每个像素的颜色。在渲染过程的第一步中，高斯体投影到 2D 图像上后，如果被识别为不影响 2D 图像的颜色，那么投影就变成了计算浪费。在 Mip-NeRF360 数据集中，平均约有 67.6% 的 3D 高斯体不影响 2D 图像的颜色。因此，这些高斯体可以从当前视图渲染过程中排除。但是，由于影响 2D 图像颜色的 3D 高斯体可能会随着渲染视点的方向和位置而改变，因此在将 3D 高斯体投影到 2D 图像平面上之前识别不必要的高斯体仍然具有挑战性。因此，这些不必要的高斯体仍然会进行投影计算。因此，如果可以开发出一种简单而有效的方法来预测不会影响 2D 图像颜色的 3D 高斯体，并在渲染过程开始之前将它们排除，那么可以显着降低整个 3D-GS 过程的总体计算复杂度。</p>
<p>（3）本文提出的研究方法：本文提出了一种基于聚类的方案，通过识别不影响 2D 图像颜色的簇来排除当前视图渲染过程中的不必要 3D 高斯体。聚类的目标是将位置相近的 3D 高斯体分组在一起，并且簇的形状应该是球形的，以便于投影到 2D 图像上。因此，本文采用 K-means 聚类算法，该算法满足这两个标准。考虑到 3D 高斯体具有由其协方差定义的大小或影响，簇球体的半径不仅由到簇质心的距离确定，还要考虑高斯体的大小。然后将这些定义的簇球体投影到 2D 图像平面上，以确定它们对 2D 图像颜色的影响。不影响图像颜色的簇可以从渲染过程中排除。在本文的方法中，可以在离线执行聚类和计算簇的半径，并且仅在实时执行将簇投影到 2D 图像平面上，这仅需 6.2% 的计算开销。在 3D-GS 渲染过程中，在当前视图渲染之前应用所提出的方法时，平均可以排除 63% 的 3D 高斯体，从而在不牺牲峰值信噪比 (PSNR) 的情况下将整体渲染计算减少了近 38.3%。所提出的加速器还实现了与 GPU 相比 10.7 倍的加速。</p>
<p>（4）方法在任务和性能上的表现：在 Mip-NeRF360 数据集上，所提出的方法平均排除了 63% 的 3D 高斯体，在不牺牲峰值信噪比 (PSNR) 的情况下将整体渲染计算减少了近 38.3%。所提出的加速器还实现了与 GPU 相比 10.7 倍的加速。这些性能支持了本文的目标，即快速且高质量地渲染 3D 场景。</p>
<p>Some Error for method(比如是不是没有Methods这个章节)</p>
<ol>
<li>结论：
（1）：本文提出了一种基于聚类的方案，通过识别不影响 2D 图像颜色的簇来排除当前视图渲染过程中的不必要 3D 高斯体。该方法平均可以排除 63% 的 3D 高斯体，在不牺牲峰值信噪比 (PSNR) 的情况下将整体渲染计算减少了近 38.3%。所提出的加速器还实现了与 GPU 相比 10.7 倍的加速。
（2）：创新点：</li>
<li>提出了一种基于聚类的方案来识别不必要的 3D 高斯体。</li>
<li>该方法可以离线执行聚类和计算簇的半径，并且仅在实时执行将簇投影到 2D 图像平面上，这仅需 6.2% 的计算开销。</li>
<li>所提出的加速器实现了与 GPU 相比 10.7 倍的加速。
性能：</li>
<li>在 Mip-NeRF360 数据集上，该方法平均排除了 63% 的 3D 高斯体，在不牺牲峰值信噪比 (PSNR) 的情况下将整体渲染计算减少了近 38.3%。
工作量：</li>
<li>该方法可以在离线执行聚类和计算簇的半径，并且仅在实时执行将簇投影到 2D 图像平面上，这仅需 6.2% 的计算开销。</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-eb8532b7f44bd3308c4f19fe6bf7f78c.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-8e5e9d849dcc9fd5228abd36df009311.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-8a43367bbb6924d5ba043f598753b956.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-d13d1af17267a2b843bea8ac607b39a9.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-bca1cf3d857e2d53600b33fc6c9e298c.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-ee494dce0084e0f0c71d55d940b03dc9.jpg" align="middle">
</details>




<h2 id="GaussianObject-Just-Taking-Four-Images-to-Get-A-High-Quality-3D-Object-with-Gaussian-Splatting"><a href="#GaussianObject-Just-Taking-Four-Images-to-Get-A-High-Quality-3D-Object-with-Gaussian-Splatting" class="headerlink" title="GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object   with Gaussian Splatting"></a>GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object   with Gaussian Splatting</h2><p><strong>Authors:Chen Yang, Sikuang Li, Jiemin Fang, Ruofan Liang, Lingxi Xie, Xiaopeng Zhang, Wei Shen, Qi Tian</strong></p>
<p>Reconstructing and rendering 3D objects from highly sparse views is of critical importance for promoting applications of 3D vision techniques and improving user experience. However, images from sparse views only contain very limited 3D information, leading to two significant challenges: 1) Difficulty in building multi-view consistency as images for matching are too few; 2) Partially omitted or highly compressed object information as view coverage is insufficient. To tackle these challenges, we propose GaussianObject, a framework to represent and render the 3D object with Gaussian splatting, that achieves high rendering quality with only 4 input images. We first introduce techniques of visual hull and floater elimination which explicitly inject structure priors into the initial optimization process for helping build multi-view consistency, yielding a coarse 3D Gaussian representation. Then we construct a Gaussian repair model based on diffusion models to supplement the omitted object information, where Gaussians are further refined. We design a self-generating strategy to obtain image pairs for training the repair model. Our GaussianObject is evaluated on several challenging datasets, including MipNeRF360, OmniObject3D, and OpenIllumination, achieving strong reconstruction results from only 4 views and significantly outperforming previous state-of-the-art methods. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.10259v2">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://gaussianobject.github.io/">https://gaussianobject.github.io/</a></p>
<p><strong>摘要</strong><br>利用仅有 4 张输入图像，以高斯散点图表示和渲染三维对象，展现出极佳的渲染质量。</p>
<p><strong>要点</strong></p>
<ul>
<li>重建和渲染高度稀疏视图的 3D 对象对于促进 3D 视觉技术应用和改善用户体验至关重要。</li>
<li>提出 GaussianObject，一种以高斯散点图表示和渲染 3D 对象的框架，仅需 4 张输入图像即可实现高渲染质量。</li>
<li>引入视觉外壳和浮子消除技术，将结构先验明确注入初始优化过程，帮助建立多视图一致性，产生粗糙的 3D 高斯表示。</li>
<li>基于扩散模型构建高斯修复模型，以补充省略的对象信息，其中高斯值进一步细化。</li>
<li>设计了一种自生成策略来获取图像对，以训练修复模型。</li>
<li>在多个具有挑战性的数据集上评估了 GaussianObject，包括 MipNeRF360、OmniObject3D 和 OpenIllumination，仅使用 4 个视图即可实现强大的重建结果，并且明显优于先前的最先进方法。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>题目：高斯对象：只需四张图像即可获取高质量的 3D 对象</li>
<li>作者：陈阳，李思宽，方杰民，梁若凡，谢凌希，张晓鹏，沈巍，田齐</li>
<li>单位：上海交通大学</li>
<li>关键词：神经辐射场、3D 重建、稀疏视图、高斯球面体</li>
<li>论文链接：https://arxiv.org/abs/2402.10259，Github 链接：None</li>
<li>
<p>摘要：
（1）研究背景：重建和渲染 3D 对象是计算机视觉领域的重要课题，但传统方法通常需要大量视图才能获得高质量的结果。这对于用户来说非常繁琐，限制了 3D 技术的广泛应用。
（2）过去的方法：一些研究尝试减少对密集捕获的依赖，但当视图变得极度稀疏时，仍然难以生成高质量的 3D 对象。主要挑战在于难以建立多视图一致性，以及部分缺失或高度压缩的对象信息。
（3）研究方法：本文提出了一种名为高斯对象的新框架，旨在从稀疏视图中重建高质量的 3D 对象。该框架使用 3D 高斯球面体作为基本表示，并设计了几种技术来引入对象结构先验，帮助建立多视图一致性。此外，还提出了一种基于扩散模型的高斯修复模型，以消除由缺失或高度压缩的对象信息引起的伪影。
（4）性能表现：高斯对象方法在几个具有挑战性的真实世界数据集上表现出强大的性能，在定性和定量评估中均优于以前的最先进方法。这表明该方法能够有效地从稀疏视图中重建高质量的 3D 对象。</p>
</li>
<li>
<p>方法：
(1) 高斯球面体表示：将3D对象表示为一个3D高斯球面体，该球面体由一系列3D高斯分布组成。每个高斯分布对应于对象的一个局部区域，其参数（中心位置、尺度和权重）由神经网络学习得到。
(2) 结构先验引入：设计了几种技术来引入对象结构先验，帮助建立多视图一致性。这些技术包括：</p>
<ul>
<li>形状正则化：使用一个预训练的形状生成模型来正则化高斯球面体的形状，使其更加真实和自然。</li>
<li>拓扑正则化：使用一个拓扑生成模型来正则化高斯球面体的拓扑结构，使其更加连通和完整。</li>
<li>语义正则化：使用一个语义分割模型来正则化高斯球面体的语义信息，使其更加准确和一致。
(3) 高斯修复模型：提出了一种基于扩散模型的高斯修复模型，以消除由缺失或高度压缩的对象信息引起的伪影。该模型通过迭代地扩散和恢复高斯球面体的参数，逐步消除伪影并生成高质量的3D对象。</li>
</ul>
</li>
<li>
<p>结论：
（1）：高斯对象是一种新颖的框架，旨在从极度稀疏的 360° 视图中重建高质量的 3D 对象，该框架基于 3D 高斯球面体，并具有实时的渲染能力。我们设计了两种主要方法来实现这一目标：辅助结构先验的优化，以促进多视图一致性的构建，以及高斯修复模型，以去除由遗漏或高度压缩的对象信息引起的伪影。我们希望高斯对象能够推进重建 3D 对象的日常应用。
（2）：创新点：</p>
</li>
<li>提出了一种新的 3D 对象表示形式——高斯球面体，该表示形式能够有效地捕获对象的形状、拓扑结构和语义信息。</li>
<li>设计了几种技术来引入对象结构先验，帮助建立多视图一致性，包括形状正则化、拓扑正则化和语义正则化。</li>
<li>提出了一种基于扩散模型的高斯修复模型，以消除由缺失或高度压缩的对象信息引起的伪影。
性能：</li>
<li>在几个具有挑战性的真实世界数据集上，高斯对象方法在定性和定量评估中均优于以前的最先进方法。</li>
<li>高斯对象方法能够从极度稀疏的 360° 视图中重建高质量的 3D 对象，这对于用户来说非常方便，并且可以广泛应用于各种领域。
工作量：</li>
<li>高斯对象方法需要大量的训练数据，这可能会增加训练时间和成本。</li>
<li>高斯对象方法需要使用神经网络来学习高斯球面体的参数，这可能会增加计算复杂度。</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ec0859f0d4156531b928896ce0f20711.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-a6cf586e290dad38d6317bf5e32650f6.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-fc6b9cc2318a136451091ab1f1c68efb.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-0ee843ee1e2c5a9e509cc05d4936f7f7.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-de6acbb2bc7ce290268eb48c8af2cb6b.jpg" align="middle">
</details>




<h2 id="GES-Generalized-Exponential-Splatting-for-Efficient-Radiance-Field-Rendering"><a href="#GES-Generalized-Exponential-Splatting-for-Efficient-Radiance-Field-Rendering" class="headerlink" title="GES: Generalized Exponential Splatting for Efficient Radiance Field   Rendering"></a>GES: Generalized Exponential Splatting for Efficient Radiance Field   Rendering</h2><p><strong>Authors:Abdullah Hamdi, Luke Melas-Kyriazi, Guocheng Qian, Jinjie Mai, Ruoshi Liu, Carl Vondrick, Bernard Ghanem, Andrea Vedaldi</strong></p>
<p>Advancements in 3D Gaussian Splatting have significantly accelerated 3D reconstruction and generation. However, it may require a large number of Gaussians, which creates a substantial memory footprint. This paper introduces GES (Generalized Exponential Splatting), a novel representation that employs Generalized Exponential Function (GEF) to model 3D scenes, requiring far fewer particles to represent a scene and thus significantly outperforming Gaussian Splatting methods in efficiency with a plug-and-play replacement ability for Gaussian-based utilities. GES is validated theoretically and empirically in both principled 1D setup and realistic 3D scenes.   It is shown to represent signals with sharp edges more accurately, which are typically challenging for Gaussians due to their inherent low-pass characteristics. Our empirical analysis demonstrates that GEF outperforms Gaussians in fitting natural-occurring signals (e.g. squares, triangles, and parabolic signals), thereby reducing the need for extensive splitting operations that increase the memory footprint of Gaussian Splatting. With the aid of a frequency-modulated loss, GES achieves competitive performance in novel-view synthesis benchmarks while requiring less than half the memory storage of Gaussian Splatting and increasing the rendering speed by up to 39%. The code is available on the project website <a target="_blank" rel="noopener" href="https://abdullahamdi.com/ges">https://abdullahamdi.com/ges</a> . </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.10128v1">PDF</a> preprint</p>
<p><strong>摘要</strong><br>广义指数散列法（GES）是一种新颖的 3D 场景表示方法，它使用广义指数函数 (GEF) 对 3D 场景进行建模，从而显著减少了表示场景所需的粒子数量，比高斯散列方法更加高效，并且即插即用，可以替代基于高斯的工具。</p>
<p><strong>要点</strong></p>
<ul>
<li>GES 使用广义指数函数 (GEF) 对 3D 场景进行建模，显著减少了所需粒子数量，提高了效率。</li>
<li>GES 优于高斯散列法，能够将 3D 场景建模为更少的粒子，在效率方面显著优于高斯散列法。</li>
<li>GES 在原理性的一维设置和现实的 3D 场景中经过理论和经验验证。</li>
<li>GES 在表达具有清晰边缘的信号方面更准确，而这些信号通常对高斯函数构成挑战，因其本身具有低通特性。</li>
<li>GES 在拟合自然发生的信号（例如正方形、三角形和抛物线信号）方面优于高斯函数，因而减少了增加高斯散列法的内存占用的大量分裂操作的需要。</li>
<li>使用调制频率损失，GES 可实现在新视图合成基准中具有竞争力的性能，同时所需的存储空间不到高斯散列法的二分之一，并使渲染速度提高多达 39%。</li>
<li>GES 的代码可在项目网站 <a target="_blank" rel="noopener" href="https://abdullahamdi.com/ges">https://abdullahamdi.com/ges</a> 上获取。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>题目：GES：用于高效光场渲染的广义指数散射（中文翻译）</li>
<li>作者：Abdullah Hamdi、Luke Melas-Kyriazi、Guocheng Qian、Jinjie Mai、Ruoshi Liu、Carl Vondrick、Bernard Ghanem、Andrea Vedaldi</li>
<li>第一作者单位：牛津大学视觉几何组（中文翻译）</li>
<li>关键词：3D 重建、3D 生成、3D 表示、光场渲染、广义指数函数</li>
<li>论文链接：https://arxiv.org/abs/2402.10128，Github 代码链接：无</li>
<li>摘要：
（1）研究背景：3D 高斯散射在 3D 重建和生成方面取得了重大进展。然而，它可能需要大量高斯函数，这会造成巨大的内存占用。
（2）过去的方法及其问题：高斯散射方法假设场景信号是低通的，但大多数 3D 场景都包含形状和外观上的突变，因此高斯散射需要使用大量非常小的高斯函数来表示这些 3D 场景，这会对内存利用率产生负面影响。
（3）本文提出的研究方法：本文提出 GES（广义指数散射），它使用广义指数函数（具有额外的可学习形状参数）来建模 3D 场景，从而可以减少表示场景所需的粒子数量，从而在效率上明显优于高斯散射方法，并且可以即插即用地替换基于高斯的实用工具。
（4）方法在什么任务上取得了什么性能，这些性能是否支持其目标：GES 在原理性 1D 设置和逼真的 3D 场景中都得到了理论和经验验证。结果表明，它可以更准确地表示具有锐利边缘的信号，而这对于高斯函数来说通常具有挑战性，因为它们具有固有的低通特性。实证分析表明，GES 在拟合自然出现的信号（例如，正方形、三角形、抛物线信号）方面优于高斯函数，从而减少了增加高斯散射内存占用率的广泛分裂操作的需要。在频率调制损失的帮助下，GES 在新视图合成基准测试中取得了具有竞争力的性能，同时所需的内存存储量不到高斯散射的一半，并且渲染速度提高了 39%。</li>
</ol>
<p><methods>:
(1): GES使用广义指数函数（具有额外的可学习形状参数）来建模3D场景，从而可以减少表示场景所需的粒子数量，从而在效率上明显优于高斯散射方法，并且可以即插即用地替换基于高斯的实用工具。
(2): GES在原理性1D设置和逼真的3D场景中都得到了理论和经验验证。结果表明，它可以更准确地表示具有锐利边缘的信号，而这对于高斯函数来说通常具有挑战性，因为它们具有固有的低通特性。
(3): 实证分析表明，GES在拟合自然出现的信号（例如，正方形、三角形、抛物线信号）方面优于高斯函数，从而减少了增加高斯散射内存占用率的广泛分裂操作的需要。
(4): 在频率调制损失的帮助下，GES在新视图合成基准测试中取得了具有竞争力的性能，同时所需的内存存储量不到高斯散射的一半，并且渲染速度提高了39%。</methods></p>
<ol>
<li>结论：
(1): 本文提出了一种新的光场渲染方法 GES，它使用广义指数函数来建模 3D 场景，从而可以减少表示场景所需的粒子数量，从而在效率上明显优于高斯散射方法，并且可以即插即用地替换基于高斯的实用工具。
(2): 创新点：</li>
<li>GES 使用广义指数函数来建模 3D 场景，从而可以减少表示场景所需的粒子数量，从而在效率上明显优于高斯散射方法。</li>
<li>GES 在原理性 1D 设置和逼真的 3D 场景中都得到了理论和经验验证。结果表明，它可以更准确地表示具有锐利边缘的信号，而这对于高斯函数来说通常具有挑战性，因为它们具有固有的低通特性。</li>
<li>实证分析表明，GES 在拟合自然出现的信号（例如，正方形、三角形、抛物线信号）方面优于高斯函数，从而减少了增加高斯散射内存占用率的广泛分裂操作的需要。</li>
<li>在频率调制损失的帮助下，GES 在新视图合成基准测试中取得了具有竞争力的性能，同时所需的内存存储量不到高斯散射的一半，并且渲染速度提高了 39%。
性能：</li>
<li>GES 在原理性 1D 设置和逼真的 3D 场景中都得到了理论和经验验证。结果表明，它可以更准确地表示具有锐利边缘的信号，而这对于高斯函数来说通常具有挑战性，因为它们具有固有的低通特性。</li>
<li>实证分析表明，GES 在拟合自然出现的信号（例如，正方形、三角形、抛物线信号）方面优于高斯函数，从而减少了增加高斯散射内存占用率的广泛分裂操作的需要。</li>
<li>在频率调制损失的帮助下，GES 在新视图合成基准测试中取得了具有竞争力的性能，同时所需的内存存储量不到高斯散射的一半，并且渲染速度提高了 39%。
工作量：</li>
<li>GES 的实现相对简单，并且可以很容易地集成到现有的光场渲染工具中。</li>
<li>GES 的训练过程相对较快，并且可以在几分钟内完成。</li>
<li>GES 的渲染速度很快，并且可以在几秒钟内生成高质量的图像。</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-06e50cf8fcf2b71cc6d5f5fa60bd416c.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-e0387aa41ca3382d21ca4822a1185a81.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-d98ce6f15593a9709f1a7d0a0c108a7f.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4903d39957be51dd29a4222bcccefaa4.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c50bfcbaec1420bcb70374001db6c443.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-e090b0178d5a97f88600cc386571b770.jpg" align="middle">
</details>




<h2 id="GS-CLIP-Gaussian-Splatting-for-Contrastive-Language-Image-3D-Pretraining-from-Real-World-Data"><a href="#GS-CLIP-Gaussian-Splatting-for-Contrastive-Language-Image-3D-Pretraining-from-Real-World-Data" class="headerlink" title="GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D   Pretraining from Real-World Data"></a>GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D   Pretraining from Real-World Data</h2><p><strong>Authors:Haoyuan Li, Yanpeng Zhou, Yihan Zeng, Hang Xu, Xiaodan Liang</strong></p>
<p>3D Shape represented as point cloud has achieve advancements in multimodal pre-training to align image and language descriptions, which is curial to object identification, classification, and retrieval. However, the discrete representations of point cloud lost the object’s surface shape information and creates a gap between rendering results and 2D correspondences. To address this problem, we propose GS-CLIP for the first attempt to introduce 3DGS (3D Gaussian Splatting) into multimodal pre-training to enhance 3D representation. GS-CLIP leverages a pre-trained vision-language model for a learned common visual and textual space on massive real world image-text pairs and then learns a 3D Encoder for aligning 3DGS optimized per object. Additionally, a novel Gaussian-Aware Fusion is proposed to extract and fuse global explicit feature. As a general framework for language-image-3D pre-training, GS-CLIP is agnostic to 3D backbone networks. Experiments on challenging shows that GS-CLIP significantly improves the state-of-the-art, outperforming the previously best results. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.06198v2">PDF</a> The content of the technical report needs to be updated and retracted   to avoid other impacts</p>
<p><strong>摘要</strong><br>利用3DGS(三维高斯渲染)增强3D表现，以进行多模态预训练，提升图像、语言和三维数据的对齐，改善物体识别、分类和检索任务。</p>
<p><strong>要点</strong></p>
<ul>
<li>利用点云表示的3D形状在图像和语言描述的对齐上取得了多模态预训练的进步，这对于物体识别、分类和检索至关重要。</li>
<li>点云的离散表示丢失了物体的曲面形状信息，并在渲染结果和2D对应关系之间制造差距。</li>
<li>提出GS-CLIP，首次尝试将3DGS（三维高斯渲染）引入多模态预训练，以增强3D表示。</li>
<li>GS-CLIP利用预训练的视觉-语言模型，在大量真实世界图像-文本对上学习一个通用的视觉和文本空间，然后学习一个针对每个物体优化3DGS的3D编码器。</li>
<li>提出了一种新的高斯感知融合来提取和融合全局显式特征。</li>
<li>作为语言-图像-3D预训练的通用框架，GS-CLIP独立于3D骨干网络。</li>
<li>具有挑战性的实验表明，GS-CLIP显著优于最先进的技术，超越了以前最好的成果。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>题目：GS-CLIP：用于对比语言-图像-3D 预训练的高斯喷绘</li>
<li>作者：李昊源、周雁鹏、曾义涵、徐航、梁晓丹</li>
<li>第一作者单位：深圳大学</li>
<li>关键词：3D 表示、对比学习、多模态预训练、高斯喷绘</li>
<li>论文链接：https://arxiv.org/abs/2402.06198，Github 代码链接：无</li>
<li>
<p>摘要：
（1）研究背景：3D 形状表示为点云在多模态预训练中取得了进展，可以对齐图像和语言描述，这对物体识别、分类和检索至关重要。然而，点云的离散表示丢失了物体的表面形状信息，并在渲染结果和 2D 对应关系之间产生了差距。
（2）过去的方法及其问题：现有方法主要集中在对点云进行建模，但这些方法通常会丢失物体的几何信息和形状纹理。此外，现有方法通常需要大量的数据，这使得它们难以应用于现实世界中的场景。
（3）提出的研究方法：为了解决上述问题，本文提出了一种新的框架 GS-CLIP，该框架将 3D 高斯喷绘 (3DGS) 引入多模态预训练中，以增强 3D 表示。GS-CLIP 利用预训练的视觉语言模型在大量真实世界图像-文本对上学习一个共同的视觉和文本空间，然后学习一个 3D 编码器来对齐针对每个对象优化的 3DGS。此外，本文还提出了一种新的高斯感知融合方法，用于提取和融合全局显式特征。
（4）方法在任务和性能上的表现：在 SUN-RGBD 数据集上的实验表明，GS-CLIP 在真实世界环境中的零样本/开放世界学习中取得了最先进的性能。这些结果表明，3DGS 在跨模态学习中具有强大的表示能力。</p>
</li>
<li>
<p>方法：
（1）跨模态预训练：利用预训练的语言-图像模型CLIP，为文本、图像和3DGS建立共同的语言-图像潜在空间，作为3DGS的目标潜在空间。
（2）语言-3DGS对齐和图像-3DGS对齐：分别使用对比损失函数来对齐文本与3DGS、图像与3DGS的特征表示。
（3）高斯感知融合：采用基于Transformer的分支直接对高斯特征进行建模，并将其与残差形式注入到3D主干网络中。</p>
</li>
<li>
<p>结论：
（1）：本工作首次将 3DGS 纳入跨模态学习，作为补充形状和纹理信息的通用 3D 表示。为此，提出了一种高斯感知融合，以便更好地从补充信息中学习信息。我们证明了我们提出的 GS-CLIP 在最先进的方法中取得了优异的性能，并在真实世界环境中实现了零样本/开放世界学习的最新性能。
（2）：创新点：</p>
</li>
<li>将 3DGS 引入跨模态学习，作为补充形状和纹理信息的通用 3D 表示。</li>
<li>提出了一种高斯感知融合，以便更好地从补充信息中学习信息。</li>
<li>在真实世界环境中实现了零样本/开放世界学习的最新性能。
性能：</li>
<li>在 SUN-RGBD 数据集上，GS-CLIP 在真实世界环境中的零样本/开放世界学习中取得了最先进的性能。</li>
<li>这些结果表明，3DGS 在跨模态学习中具有强大的表示能力。
工作量：</li>
<li>该工作涉及到大量的数据预处理和模型训练。</li>
<li>需要对 3DGS 进行优化，以使其能够更好地对齐文本和图像的特征表示。</li>
<li>需要对高斯感知融合进行进一步的研究，以使其能够更好地提取和融合全局显式特征。</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-5ca02e3188a2350914f961c6e31c0616.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4980273838b01e0c94c7593c3becb878.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-b33d684beebaf5252e0357a0e0af9c1d.jpg" align="middle">
</details>




<h2 id="GaMeS-Mesh-Based-Adapting-and-Modification-of-Gaussian-Splatting"><a href="#GaMeS-Mesh-Based-Adapting-and-Modification-of-Gaussian-Splatting" class="headerlink" title="GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting"></a>GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting</h2><p><strong>Authors:Joanna Waczyńska, Piotr Borycki, Sławomir Tadeja, Jacek Tabor, Przemysław Spurek</strong></p>
<p>Recently, a range of neural network-based methods for image rendering have been introduced. One such widely-researched neural radiance field (NeRF) relies on a neural network to represent 3D scenes, allowing for realistic view synthesis from a small number of 2D images. However, most NeRF models are constrained by long training and inference times. In comparison, Gaussian Splatting (GS) is a novel, state-of-the-art technique for rendering points in a 3D scene by approximating their contribution to image pixels through Gaussian distributions, warranting fast training and swift, real-time rendering. A drawback of GS is the absence of a well-defined approach for its conditioning due to the necessity to condition several hundred thousand Gaussian components. To solve this, we introduce the Gaussian Mesh Splatting (GaMeS) model, which allows modification of Gaussian components in a similar way as meshes. We parameterize each Gaussian component by the vertices of the mesh face. Furthermore, our model needs mesh initialization on input or estimated mesh during training. We also define Gaussian splats solely based on their location on the mesh, allowing for automatic adjustments in position, scale, and rotation during animation. As a result, we obtain a real-time rendering of editable GS. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2402.01459v3">PDF</a> </p>
<p><strong>Summary:</strong><br>神经辐射场 (NeRF) 是一种用于图像渲染的神经网络方法，而高斯网格泼溅 (GaMeS) 模型则通过高斯分布来估算 3D 场景中点的贡献，从而实现快速训练和实时渲染。</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>利用神经网络表征 3D 场景的 NeRF，允许从少量 2D 图像中进行逼真的视点合成。</li>
<li>高斯泼溅 (GS) 通过高斯分布来估算 3D 场景中点的贡献，从而实现快速训练和实时渲染。</li>
<li>GaMeS 模型允许以与网格类似的方式修改高斯分量，从而为 GS 的调节提供了一个明确的方法。</li>
<li>将每个高斯分量参数化为网格面的顶点，这使得 GaMeS 模型可以对 GS 进行实时渲染。</li>
<li>GaMeS 模型需要在输入时初始化网格或在训练期间估计网格。</li>
<li>根据其在网格上的位置定义高斯泼溅，从而允许在动画期间自动调整位置、缩放和旋转。</li>
<li>GaMeS 模型可以实现可编辑 GS 的实时渲染。</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>题目：GaMeS：基于网格的自适应和修改高斯喷绘</li>
<li>作者：Joanna Waczyńska、Piotr Borycki、Sławomir Tadeja、Jacek Tabor、Przemysław Spurek</li>
<li>第一作者单位：雅盖隆大学数学与计算机科学学院，波兰克拉科夫</li>
<li>关键词：高斯喷绘、神经辐射场、神经渲染、网格、实时渲染</li>
<li>论文链接：https://arxiv.org/abs/2402.01459，Github 代码链接：无</li>
<li>摘要：
(1)：研究背景：近年来，基于神经网络的图像渲染方法取得了很大进展，其中神经辐射场（NeRF）是一种流行的方法，它使用神经网络来表示 3D 场景，并能够从少量 2D 图像中合成逼真的视图。然而，大多数 NeRF 模型都受到训练和推理时间长的限制。与之相比，高斯喷绘（GS）是一种新颖的、最先进的技术，它通过高斯分布来近似点对图像像素的贡献，从而渲染 3D 场景中的点，具有快速训练和快速实时渲染的能力。
(2)：过去的方法和问题：GS 的一个缺点是缺乏明确的调节方法，因为需要调节数十万个高斯分量。为了解决这个问题，本文介绍了高斯网格喷绘（GaMeS）模型，它允许像修改网格一样修改高斯分量。我们将每个高斯分量参数化为网格面的顶点。此外，我们的模型需要在输入或训练期间估计的网格上进行网格初始化。我们还定义了仅基于其在网格上的位置的高斯喷绘，允许在动画期间自动调整位置、比例和旋转。因此，我们获得了可编辑 GS 的实时渲染。
(3)：研究方法：我们提出了 GaMeS 模型，它允许像修改网格一样修改高斯分量。我们将每个高斯分量参数化为网格面的顶点。此外，我们的模型需要在输入或训练期间估计的网格上进行网格初始化。我们还定义了仅基于其在网格上的位置的高斯喷绘，允许在动画期间自动调整位置、比例和旋转。
(4)：方法的性能：实验结果表明，GaMeS 模型能够在保持高质量渲染的同时，实现实时修改和适应高斯喷绘。这使得 GaMeS 成为交互式应用程序和游戏中的一个有前景的技术。</li>
</ol>
<p>Some Error for method(比如是不是没有Methods这个章节)</p>
<ol>
<li>结论：
（1）GaMeS 允许实时修改，但对于具有大面的网格，在发生重大变化的情况下会出现伪影。在实践中，大面应该被分成更小的面。当网格面分裂时如何在 GaMeS 中更改高斯分量尚不清楚。
（2）创新点：GaMeS 提出了一种新的基于网格的自适应和修改高斯喷绘模型，该模型允许像修改网格一样修改高斯分量，从而实现了实时修改和适应高斯喷绘。
性能：实验结果表明，GaMeS 模型能够在保持高质量渲染的同时，实现实时修改和适应高斯喷绘。这使得 GaMeS 成为交互式应用程序和游戏中的一个有前景的技术。
工作量：GaMeS 模型需要在输入或训练期间估计网格，这可能会增加模型的训练和推理时间。此外，GaMeS 模型需要对网格进行修改，这可能会增加模型的修改时间。</li>
</ol>


<details>
  <summary>点此查看论文截图</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-11676aa94eeb837bc5149bf9038274ae.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3d3c20ac78640d356ea03699146c96e9.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4070017cd795fd8699e30a356efae899.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-0416310a796f7ec70150342ac59ffe37.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-6eb0975a0f5d702a6daef3f78e530869.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-9fb0edd088d9a64e792369a6d6a72979.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-dd54f927f26f28fdcefe778d566087c5.jpg" align="middle">
</details>




</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://kedreamix.github.io/Paper/2024-02-23/3DGS/">https://kedreamix.github.io/Paper/2024-02-23/3DGS/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/3DGS/">3DGS</a></div><div class="post_share"><div class="social-share" data-image="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Paper/2024-02-23/NeRF/" title="NeRF"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-190136188bdfd4cb8f04bafbfb9ef577.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">NeRF</div></div></a></div><div class="next-post pull-right"><a href="/Paper/2024-02-23/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ff425802a32a4519e30b9044a3eed1e8.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Diffusion Models</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/Paper/3DGS%20Survey/" title="3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-25</div><div class="title">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting</div></div></a></div><div><a href="/Paper/Awesome-Talking-Head-Synthesis/" title="超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-01</div><div class="title">超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis</div></div></a></div><div><a href="/Paper/2024-02-02/3DGS/" title="3DGS"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-e4e5570dfa99dfac9b297f7650c717c3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-02</div><div class="title">3DGS</div></div></a></div><div><a href="/Paper/2024-01-30/3DGS/" title="3DGS"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2032721a60695f2d41ac96f75dec65a2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">3DGS</div></div></a></div><div><a href="/Paper/2024-02-09/3DGS/" title="3DGS"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-28074a5f13fdf5a52c0d4de04dfb9406.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-09</div><div class="title">3DGS</div></div></a></div><div><a href="/Paper/2024-01-24/3DGS/" title="3DGS"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-3d3dcd00c27bc3d320b23d4247ae79f3.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-24</div><div class="title">3DGS</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-02-23-%E6%9B%B4%E6%96%B0"><span class="toc-text">2024-02-23 更新</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting"><span class="toc-text">Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GaussianObject-Just-Taking-Four-Images-to-Get-A-High-Quality-3D-Object-with-Gaussian-Splatting"><span class="toc-text">GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object   with Gaussian Splatting</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GES-Generalized-Exponential-Splatting-for-Efficient-Radiance-Field-Rendering"><span class="toc-text">GES: Generalized Exponential Splatting for Efficient Radiance Field   Rendering</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GS-CLIP-Gaussian-Splatting-for-Contrastive-Language-Image-3D-Pretraining-from-Real-World-Data"><span class="toc-text">GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D   Pretraining from Real-World Data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GaMeS-Mesh-Based-Adapting-and-Modification-of-Gaussian-Splatting"><span class="toc-text">GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">簡</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="Paper/3DGS Survey/" alt="">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGS综述以及对3DGS的理解：A Survey on 3D Gaussian Splatting 今天想介绍的是`ZJU`带来的`3DGS`的首篇综述`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="Paper/3DGS Survey/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="CUDA/Pytorch+cppcuda extension 学习/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="CUDA/Pytorch+cppcuda extension 学习/" alt="">CUDA编程学习：自定义Pytorch+cpp/cuda extension</a><div class="blog-slider__text">虽然说PyTorch提供了丰富的与神经网络、张量代数、数据处理等相关的操作，但是有时候你可能需要**更定制化的操作**，比如使用论文中的新型激活函数，或者实现作为研究一部分开发的操作。在PyTorch中，最简单的集成自定义操作的方式是在Python中编写，通过扩展Function和Module来实现，</div><a class="blog-slider__button" href="CUDA/Pytorch+cppcuda extension 学习/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="Project/Linly-Talker/" alt="">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</a><div class="blog-slider__text">Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。</div><a class="blog-slider__button" href="Project/Linly-Talker/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="Project/Linly-Talker - GPT-SoVITS/" alt="">数字人对话系统 - Linly-Talker —— “数字人交互，与虚拟的自己互动”</a><div class="blog-slider__text">Linly-Talker是一个将大型语言模型与视觉模型相结合的智能AI系统,创建了一种全新的人机交互方式。它集成了各种技术,例如Whisper、Linly、微软语音服务和SadTalker会说话的生成系统。该系统部署在Gradio上,允许用户通过提供图像与AI助手进行交谈。用户可以根据自己的喜好进行自由的对话或内容生成。</div><a class="blog-slider__button" href="Project/Linly-Talker - GPT-SoVITS/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="Paper/Awesome-Talking-Head-Synthesis/" alt="">超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">超赞的数字人生成知识库  Awesome-Talking-Head-Synthesis， 这份资源库整理了与生成对抗网络(GAN)和神经辐射场(NeRF)相关的论文、代码和资源,重点关注基于图像和音频的虚拟讲话头合成论文及已发布代码。如果您觉得这个仓库有用,请star⭐支持!</div><a class="blog-slider__button" href="Paper/Awesome-Talking-Head-Synthesis/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="Project/ChatPaperFree/" alt="">ChatPaperFree GeminiPro（一分钟读论文）</a><div class="blog-slider__text">ChatPaperFree是一个基于ChatGPT的自动论文摘要生成器，在ChatPaper的基础上进行的更新，采用了最近由Google开源的Gemini Pro大模型。目前,我们能够对用户输入的论文进行自动总结。未来,我还计划加入对论文图片/表格/公式的识别 extraction,从而生成更全面而易读的总结。</div><a class="blog-slider__button" href="Project/ChatPaperFree/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>