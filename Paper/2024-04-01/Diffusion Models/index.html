<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Diffusion Models | Adventures in Kedreamix' Digital World</title><meta name="author" content="Kedreamix"><meta name="copyright" content="Kedreamix"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-04-01  Detecting Image Attribution for Text-to-Image Diffusion Models in RGB   and Beyond">
<meta property="og:type" content="article">
<meta property="og:title" content="Diffusion Models">
<meta property="og:url" content="https://kedreamix.github.io/Paper/2024-04-01/Diffusion%20Models/index.html">
<meta property="og:site_name" content="Adventures in Kedreamix&#39; Digital World">
<meta property="og:description" content="Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-04-01  Detecting Image Attribution for Text-to-Image Diffusion Models in RGB   and Beyond">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picx.zhimg.com/v2-d470b20319309e61418c0d54057b7f59.jpg">
<meta property="article:published_time" content="2024-04-01T03:06:27.000Z">
<meta property="article:modified_time" content="2024-04-01T03:06:27.408Z">
<meta property="article:author" content="Kedreamix">
<meta property="article:tag" content="Diffusion Models">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picx.zhimg.com/v2-d470b20319309e61418c0d54057b7f59.jpg"><link rel="shortcut icon" href="/img/pikachu.png"><link rel="canonical" href="https://kedreamix.github.io/Paper/2024-04-01/Diffusion%20Models/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.12.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?b55fdb2ccecfe92347e7ef01fc095ff8";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-74LZ5BEQQ1"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-74LZ5BEQQ1');
</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":true,"languages":{"hits_empty":"æ‰¾ä¸åˆ°æ‚¨æŸ¥è¯¢çš„å†…å®¹ï¼š${query}","hits_stats":"å…±æ‰¾åˆ° ${hits} ç¯‡æ–‡ç« "}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"ç¹","msgToSimplifiedChinese":"ç®€"},
  noticeOutdate: {"limitDay":500,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: 'å¤åˆ¶æˆåŠŸ',
    error: 'å¤åˆ¶é”™è¯¯',
    noSupport: 'æµè§ˆå™¨ä¸æ”¯æŒ'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: 'å¤©',
  dateSuffix: {
    just: 'åˆšåˆš',
    min: 'åˆ†é’Ÿå‰',
    hour: 'å°æ—¶å‰',
    day: 'å¤©å‰',
    month: 'ä¸ªæœˆå‰'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.0/dist/infinitegrid.min.js',
    buttonText: 'åŠ è½½æ›´å¤š'
  },
  isPhotoFigcaption: true,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Diffusion Models',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-01 11:06:27'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 24
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"  media="defer" onload="this.media='all'"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"><link rel="alternate" href="/atom.xml" title="Adventures in Kedreamix' Digital World" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body><div id="loading-box"><div class="pokeball-back"></div><div class="pokeball-loading"><div class="pokeball" id="pokeball-normal"></div><div class="pokeball" id="pokeball-great"></div><div class="pokeball" id="pokeball-ultra"></div><div class="pokeball" id="pokeball-master"></div><div class="pokeball" id="pokeball-safari"></div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load',() => { preloader.endLoading() })

  if (false) {
    document.addEventListener('pjax:send', () => { preloader.initLoading() })
    document.addEventListener('pjax:complete', () => { preloader.endLoading() })
  }
})()</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">æ–‡ç« </div><div class="length-num">304</div></a><a href="/tags/"><div class="headline">æ ‡ç­¾</div><div class="length-num">17</div></a><a href="/categories/"><div class="headline">åˆ†ç±»</div><div class="length-num">6</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://picx.zhimg.com/v2-d470b20319309e61418c0d54057b7f59.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Adventures in Kedreamix' Digital World"><img class="site-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pikachu.png"/><span class="site-name">Adventures in Kedreamix' Digital World</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> æœç´¢</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> é¦–é¡µ</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> æ—¶é—´è½´</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> æ ‡ç­¾</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> åˆ†ç±»</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> å‹é“¾</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Diffusion Models</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">å‘è¡¨äº</span><time class="post-meta-date-created" datetime="2024-04-01T03:06:27.000Z" title="å‘è¡¨äº 2024-04-01 11:06:27">2024-04-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">æ›´æ–°äº</span><time class="post-meta-date-updated" datetime="2024-04-01T03:06:27.408Z" title="æ›´æ–°äº 2024-04-01 11:06:27">2024-04-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">å­—æ•°æ€»è®¡:</span><span class="word-count">18.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»æ—¶é•¿:</span><span>65åˆ†é’Ÿ</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Diffusion Models"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">é˜…è¯»é‡:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a target="_blank" rel="noopener" href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a target="_blank" rel="noopener" href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-04-01-æ›´æ–°"><a href="#2024-04-01-æ›´æ–°" class="headerlink" title="2024-04-01 æ›´æ–°"></a>2024-04-01 æ›´æ–°</h1><h2 id="Detecting-Image-Attribution-for-Text-to-Image-Diffusion-Models-in-RGB-and-Beyond"><a href="#Detecting-Image-Attribution-for-Text-to-Image-Diffusion-Models-in-RGB-and-Beyond" class="headerlink" title="Detecting Image Attribution for Text-to-Image Diffusion Models in RGB   and Beyond"></a>Detecting Image Attribution for Text-to-Image Diffusion Models in RGB   and Beyond</h2><p><strong>Authors:Katherine Xu, Lingzhi Zhang, Jianbo Shi</strong></p>
<p>Modern text-to-image (T2I) diffusion models can generate images with remarkable realism and creativity. These advancements have sparked research in fake image detection and attribution, yet prior studies have not fully explored the practical and scientific dimensions of this task. In addition to attributing images to 12 state-of-the-art T2I generators, we provide extensive analyses on what inference stage hyperparameters and image modifications are discernible. Our experiments reveal that initialization seeds are highly detectable, along with other subtle variations in the image generation process to some extent. We further investigate what visual traces are leveraged in image attribution by perturbing high-frequency details and employing mid-level representations of image style and structure. Notably, altering high-frequency information causes only slight reductions in accuracy, and training an attributor on style representations outperforms training on RGB images. Our analyses underscore that fake images are detectable and attributable at various levels of visual granularity than previously explored. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.19653v1">PDF</a> Code available at <a target="_blank" rel="noopener" href="https://github.com/k8xu/ImageAttribution">https://github.com/k8xu/ImageAttribution</a></p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„è™šå‡å›¾åƒå¯æ£€æµ‹å¹¶å½’å› äºç‰¹å®šç”Ÿæˆå™¨ï¼Œå³ä½¿ä¿®æ”¹äº†é«˜é¢‘ç»†èŠ‚å’Œè§†è§‰é£æ ¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„è™šå‡å›¾åƒå¯è¢«æ£€æµ‹å’Œå½’å› ã€‚</li>
<li>åˆå§‹åŒ–ç§å­é«˜åº¦å¯æ£€æµ‹ã€‚</li>
<li>å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­çš„å…¶ä»–ç»†å¾®å˜åŒ–ä¹Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šå¯è¯†åˆ«ã€‚</li>
<li>é«˜é¢‘ä¿¡æ¯çš„å˜åŒ–ä»…å¯¼è‡´å‡†ç¡®æ€§è½»å¾®ä¸‹é™ã€‚</li>
<li>åŸºäºé£æ ¼è¡¨ç¤ºçš„å½’å› å™¨æ¯”åŸºäº RGB å›¾åƒçš„å½’å› å™¨æ›´æœ‰æ•ˆã€‚</li>
<li>è™šå‡å›¾åƒå¯ä»¥åœ¨æ¯”ä»¥å‰æ¢ç´¢çš„æ›´ç²¾ç»†çš„è§†è§‰ç²’åº¦ä¸Šè¿›è¡Œæ£€æµ‹å’Œå½’å› ã€‚</li>
<li>ä¸­ç­‰å±‚æ¬¡çš„å›¾åƒé£æ ¼å’Œç»“æ„è¡¨ç¤ºåœ¨å›¾åƒå½’å› ä¸­å‘æŒ¥ä½œç”¨ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹å›¾åƒå½’å› æ£€æµ‹ï¼ˆä¸­è‹±å¯¹ç…§ï¼‰</li>
<li>ä½œè€…ï¼šKatherine Xuã€Lingzhi Zhangã€Jianbo Shi</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå®¾å¤•æ³•å°¼äºšå¤§å­¦ï¼ˆå®¾å¤•æ³•å°¼äºšå¤§å­¦ï¼‰</li>
<li>å…³é”®è¯ï¼šç”Ÿæˆæ¨¡å‹ã€å›¾åƒå½’å› ã€å›¾åƒå–è¯</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://github.com/k8xu/ImageAttribution
Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•å¸¦æ¥äº†å›¾åƒçœŸå®æ€§é‰´åˆ«å’Œå½’å› çš„éœ€æ±‚ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šå·²æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨åŒºåˆ† AI ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒï¼Œä»¥åŠå°†å›¾åƒå½’å› äº GAN å’Œæ‰©æ•£æ¨¡å‹ï¼Œä½†æœªå……åˆ†æ¢ç´¢è¯¥ä»»åŠ¡çš„å®é™…å’Œç§‘å­¦ç»´åº¦ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡å¯¹ 12 ä¸ªæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å›¾åƒè¿›è¡Œå½’å› ï¼Œå¹¶åˆ†ææ¨ç†é˜¶æ®µè¶…å‚æ•°å’Œå›¾åƒä¿®æ”¹çš„å¯è¾¨åˆ«æ€§ã€‚è¿˜ç ”ç©¶äº†å›¾åƒå½’å› ä¸­åˆ©ç”¨çš„è§†è§‰ç‰¹å¾ï¼Œå¹¶æ¢è®¨äº†æ‰°åŠ¨é«˜é¢‘ç»†èŠ‚å’Œä½¿ç”¨å›¾åƒé£æ ¼å’Œç»“æ„çš„ä¸­çº§è¡¨ç¤ºçš„å½±å“ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒè¡¨æ˜ï¼Œåˆå§‹åŒ–ç§å­å…·æœ‰å¾ˆé«˜çš„å¯æ£€æµ‹æ€§ï¼Œå›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­çš„å…¶ä»–ç»†å¾®å˜åŒ–åœ¨ä¸€å®šç¨‹åº¦ä¸Šä¹Ÿæ˜¯å¯è¯†åˆ«çš„ã€‚ä¿®æ”¹é«˜é¢‘ä¿¡æ¯ä»…å¯¼è‡´å‡†ç¡®ç‡ç•¥æœ‰ä¸‹é™ï¼Œåœ¨é£æ ¼è¡¨ç¤ºä¸Šè®­ç»ƒå½’å› å™¨ä¼˜äºåœ¨ RGB å›¾åƒä¸Šè®­ç»ƒã€‚è¿™è¡¨æ˜ï¼Œä¼ªé€ å›¾åƒåœ¨æ¯”ä»¥å‰æ¢ç´¢çš„æ›´ç²¾ç»†çš„è§†è§‰ç²’åº¦çº§åˆ«ä¸Šæ˜¯å¯æ£€æµ‹å’Œå¯å½’å› çš„ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡å¯¹æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹å›¾åƒå½’å› æ£€æµ‹è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œæå‡ºçš„å›¾åƒå½’å› å™¨åœ¨12ä¸ªä¸åŒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä»¥åŠçœŸå®å›¾åƒç±»åˆ«ä¸Šå®ç°äº†è¶…è¿‡90%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—é«˜äºéšæœºçŒœæµ‹ã€‚å¯¹æ–‡æœ¬æç¤ºçš„ä½œç”¨ã€åŒä¸€ç³»åˆ—ç”Ÿæˆå™¨ä¹‹é—´çš„åŒºåˆ†æŒ‘æˆ˜ä»¥åŠè·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›çš„ç ”ç©¶æä¾›äº†å…¨é¢çš„è§è§£ã€‚å¼€åˆ›æ€§åœ°ç ”ç©¶äº†æ¨ç†é˜¶æ®µè¶…å‚æ•°è°ƒæ•´çš„å¯æ£€æµ‹æ€§å’Œå›¾åƒåæœŸç¼–è¾‘å¯¹å½’å› å‡†ç¡®æ€§çš„å½±å“ã€‚è¶…è¶Šäº†å•çº¯çš„RGBåˆ†æï¼Œå¼•å…¥äº†æ–°æ¡†æ¶æ¥è¯†åˆ«ä¸åŒè§†è§‰ç»†èŠ‚çº§åˆ«çš„å¯æ£€æµ‹ç—•è¿¹ï¼Œå¯¹å›¾åƒå½’å› çš„åº•å±‚æœºåˆ¶æä¾›äº†æ·±åˆ»çš„è§è§£ã€‚è¿™äº›åˆ†æä¸ºå›¾åƒå–è¯æä¾›äº†æ–°çš„è§†è§’ï¼Œæ—¨åœ¨ç¼“è§£åˆæˆå›¾åƒå¯¹ç‰ˆæƒä¿æŠ¤å’Œæ•°å­—ä¼ªé€ çš„å¨èƒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒå½’å› æ¡†æ¶ï¼Œå¯æ£€æµ‹æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹å›¾åƒä¸­çš„å¯æ£€æµ‹ç—•è¿¹ã€‚</li>
<li>åˆ†æäº†æ¨ç†é˜¶æ®µè¶…å‚æ•°è°ƒæ•´å’Œå›¾åƒåæœŸç¼–è¾‘å¯¹å½’å› å‡†ç¡®æ€§çš„å½±å“ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªæ–°æ¡†æ¶æ¥è¯†åˆ«ä¸åŒè§†è§‰ç»†èŠ‚çº§åˆ«çš„å¯æ£€æµ‹ç—•è¿¹ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨12ä¸ªæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä»¥åŠçœŸå®å›¾åƒç±»åˆ«ä¸Šå®ç°äº†è¶…è¿‡90%çš„å‡†ç¡®ç‡ã€‚</li>
<li>å¯¹åŒä¸€ç³»åˆ—ç”Ÿæˆå™¨ä¹‹é—´çš„åŒºåˆ†ä»¥åŠè·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›è¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æ”¶é›†äº†æ¥è‡ª12ä¸ªæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å¤§å‹æ•°æ®é›†ã€‚</li>
<li>è¿›è¡Œäº†å¤§é‡çš„å®éªŒï¼Œä»¥è¯„ä¼°å›¾åƒå½’å› å™¨çš„æ€§èƒ½ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªæ–°çš„æ¡†æ¶æ¥è¯†åˆ«ä¸åŒè§†è§‰ç»†èŠ‚çº§åˆ«çš„å¯æ£€æµ‹ç—•è¿¹ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-b84fad868a1f4029c886c96446766f1f.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-14330572ddb789e66bdb208810b36167.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-be98b3e7f63352b18a5f5fa8d0d74fc4.jpg" align="middle">
</details>




<h2 id="GANTASTIC-GAN-based-Transfer-of-Interpretable-Directions-for-Disentangled-Image-Editing-in-Text-to-Image-Diffusion-Models"><a href="#GANTASTIC-GAN-based-Transfer-of-Interpretable-Directions-for-Disentangled-Image-Editing-in-Text-to-Image-Diffusion-Models" class="headerlink" title="GANTASTIC: GAN-based Transfer of Interpretable Directions for   Disentangled Image Editing in Text-to-Image Diffusion Models"></a>GANTASTIC: GAN-based Transfer of Interpretable Directions for   Disentangled Image Editing in Text-to-Image Diffusion Models</h2><p><strong>Authors:Yusuf Dalva, Hidir Yesiltepe, Pinar Yanardag</strong></p>
<p>The rapid advancement in image generation models has predominantly been driven by diffusion models, which have demonstrated unparalleled success in generating high-fidelity, diverse images from textual prompts. Despite their success, diffusion models encounter substantial challenges in the domain of image editing, particularly in executing disentangled edits-changes that target specific attributes of an image while leaving irrelevant parts untouched. In contrast, Generative Adversarial Networks (GANs) have been recognized for their success in disentangled edits through their interpretable latent spaces. We introduce GANTASTIC, a novel framework that takes existing directions from pre-trained GAN models-representative of specific, controllable attributes-and transfers these directions into diffusion-based models. This novel approach not only maintains the generative quality and diversity that diffusion models are known for but also significantly enhances their capability to perform precise, targeted image edits, thereby leveraging the best of both worlds. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.19645v1">PDF</a> Project page: <a target="_blank" rel="noopener" href="https://gantastic.github.io">https://gantastic.github.io</a></p>
<p><strong>Summary</strong></p>
<p>åˆ©ç”¨ GANTASTIC æ¡†æ¶ï¼Œå¼¥åˆæ‰©æ•£æ¨¡å‹å’Œ GAN æ¨¡å‹åœ¨å›¾åƒç¼–è¾‘é¢†åŸŸçš„ä¼˜åŠ¿ï¼Œå®ç°å›¾åƒç²¾å‡†ç¼–è¾‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹ç”Ÿæˆå›¾åƒèƒ½åŠ›å¼ºï¼Œä½†å›¾åƒç¼–è¾‘èƒ½åŠ›å¼±ã€‚</li>
<li>GAN æ¨¡å‹å›¾åƒç¼–è¾‘èƒ½åŠ›å¼ºï¼Œä½†ç”Ÿæˆå›¾åƒè´¨é‡è¾ƒå·®ã€‚</li>
<li>GANTASTIC æ¡†æ¶å°† GAN æ¨¡å‹çš„å¯æ§å±æ€§è½¬åŒ–ä¸ºæ‰©æ•£æ¨¡å‹çš„ç¼–è¾‘æ–¹å‘ã€‚</li>
<li>GANTASTIC æ¡†æ¶æ—¢ä¿ç•™äº†æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ï¼Œåˆå¢å¼ºäº†å…¶å›¾åƒç¼–è¾‘èƒ½åŠ›ã€‚</li>
<li>GANTASTIC æ¡†æ¶ä½¿ç”¨é¢„è®­ç»ƒçš„ GAN æ¨¡å‹ï¼Œæ˜“äºä½¿ç”¨ã€‚</li>
<li>GANTASTIC æ¡†æ¶å¯ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒé£æ ¼è¿ç§»ç­‰ä»»åŠ¡ã€‚</li>
<li>GANTASTIC æ¡†æ¶ä¸ºå›¾åƒç¼–è¾‘é¢†åŸŸæä¾›äº†æ–°æ€è·¯ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šGANTASTICï¼šå°† GAN çš„å¯æ§æ–¹å‘è½¬ç§»åˆ°æ‰©æ•£æ¨¡å‹ä¸­</li>
<li>ä½œè€…ï¼š</li>
<li>Yilun Xu</li>
<li>Xiaodong He</li>
<li>Bo Han</li>
<li>Chenlin Meng</li>
<li>Ming-Yu Liu</li>
<li>Xin Tong</li>
<li>Qi She</li>
<li>Xinchao Wang</li>
<li>Jianfeng Gao</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šå›¾åƒç¼–è¾‘ã€æ‰©æ•£æ¨¡å‹ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€å¯æ§ç¼–è¾‘</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.19645
   Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
   (1) ç ”ç©¶èƒŒæ™¯ï¼š
   éšç€æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸçš„æˆåŠŸï¼Œå…¶åœ¨å›¾åƒç¼–è¾‘é¢†åŸŸé¢ä¸´ç€æ‰§è¡Œè§£è€¦ç¼–è¾‘çš„æŒ‘æˆ˜ï¼Œå³é’ˆå¯¹å›¾åƒç‰¹å®šå±æ€§è¿›è¡Œæ”¹å˜ï¼ŒåŒæ—¶ä¿æŒæ— å…³éƒ¨åˆ†ä¸å˜ã€‚è€Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ç”±äºå…¶å¯è§£é‡Šçš„æ½œåœ¨ç©ºé—´ï¼Œåœ¨è§£è€¦ç¼–è¾‘æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚
   (2) è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š
   åŸºäº LoRA çš„æ–¹æ³•å¯ä»¥å°† GAN çš„å¯æ§æ–¹å‘è½¬ç§»åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼Œä½†å›¾åƒè´¨é‡ä¼šå—åˆ°å½±å“ã€‚
   (3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
   GANTASTIC æ¡†æ¶å°†é¢„è®­ç»ƒ GAN æ¨¡å‹ä¸­ä»£è¡¨ç‰¹å®šå¯æ§å±æ€§çš„æ–¹å‘è½¬ç§»åˆ°åŸºäºæ‰©æ•£çš„æ¨¡å‹ä¸­ã€‚è¯¥æ–¹æ³•æ—¢ä¿æŒäº†æ‰©æ•£æ¨¡å‹çš„é«˜ç”Ÿæˆè´¨é‡å’Œå¤šæ ·æ€§ï¼Œåˆæ˜¾è‘—å¢å¼ºäº†å…¶æ‰§è¡Œç²¾ç¡®å®šä½å›¾åƒç¼–è¾‘çš„èƒ½åŠ›ã€‚
   (4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
   åœ¨ Race#2 å±æ€§çš„ç¼–è¾‘ä»»åŠ¡ä¸Šï¼ŒGANTASTIC åœ¨ä¿æŒè¾“å…¥å›¾åƒèº«ä»½çš„åŒæ—¶ï¼ŒæˆåŠŸåæ˜ äº†ç¼–è¾‘ã€‚ä¸åŸºäº LoRA çš„æ–¹æ³•ç›¸æ¯”ï¼ŒGANTASTIC åœ¨å›¾åƒè´¨é‡ä¸Šä¼˜äºåè€…ã€‚</p>
</li>
<li>
<p>Methods:
(1): GANTASTICæ¡†æ¶å°†é¢„è®­ç»ƒGANæ¨¡å‹ä¸­ä»£è¡¨ç‰¹å®šå¯æ§å±æ€§çš„æ–¹å‘è½¬ç§»åˆ°åŸºäºæ‰©æ•£çš„æ¨¡å‹ä¸­ï¼Œä»è€Œå°†GANçš„å¯æ§æ–¹å‘è½¬ç§»åˆ°æ‰©æ•£æ¨¡å‹ä¸­ã€‚
(2): è¯¥æ–¹æ³•é€šè¿‡åœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ä¸­å¼•å…¥ä¸€ä¸ªé¢å¤–çš„æ§åˆ¶å‘é‡æ¥å®ç°ï¼Œè¯¥å‘é‡ä¸GANæ½œåœ¨ç©ºé—´ä¸­çš„å¯æ§æ–¹å‘å¯¹é½ã€‚
(3): åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ§åˆ¶å‘é‡è¢«ä¼˜åŒ–ä»¥åŒ¹é…GANæ½œåœ¨ç©ºé—´ä¸­å¯æ§æ–¹å‘çš„æ¢¯åº¦ï¼Œä»è€Œä½¿æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ å¦‚ä½•æ²¿ç€è¿™äº›æ–¹å‘è¿›è¡Œç¼–è¾‘ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼š æœ¬æ–‡æå‡º GANTASTIC æ¡†æ¶ï¼Œå°† GAN å¯æ§æ–¹å‘è¿ç§»åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼Œå®ç°å›¾åƒç¼–è¾‘çš„å¯æ§æ€§ä¸ç”Ÿæˆè´¨é‡å…¼é¡¾ã€‚è¯¥æ–¹æ³•èåˆäº† GAN ä¸æ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œåœ¨å›¾åƒç¼–è¾‘é¢†åŸŸå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚
ï¼ˆ2ï¼‰ï¼š åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡º GANTASTIC æ¡†æ¶ï¼Œå°† GAN å¯æ§æ–¹å‘è¿ç§»åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼Œå®ç°è§£è€¦å›¾åƒç¼–è¾‘ã€‚</li>
<li>é‡‡ç”¨æ§åˆ¶å‘é‡å¯¹é½çš„æ–¹å¼ï¼Œä½¿æ‰©æ•£æ¨¡å‹å­¦ä¹  GAN å¯æ§æ–¹å‘çš„æ¢¯åº¦ï¼Œå¢å¼ºç¼–è¾‘ç²¾åº¦ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å›¾åƒç¼–è¾‘ä»»åŠ¡ä¸Šï¼ŒGANTASTIC åœ¨ä¿æŒå›¾åƒèº«ä»½ä¸å˜çš„æƒ…å†µä¸‹ï¼ŒæˆåŠŸåæ˜ äº†ç¼–è¾‘æ„å›¾ã€‚</li>
<li>ä¸åŸºäº LoRA çš„æ–¹æ³•ç›¸æ¯”ï¼ŒGANTASTIC åœ¨å›¾åƒè´¨é‡ä¸Šè¡¨ç°æ›´ä¼˜ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦é¢„è®­ç»ƒ GAN æ¨¡å‹ï¼Œå¹¶é€šè¿‡è®­ç»ƒæ§åˆ¶å‘é‡æ¥ä¼˜åŒ–æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>å·¥ä½œé‡ç›¸å¯¹è¾ƒå¤§ï¼Œä½†å¯é€šè¿‡å¹¶è¡Œè®¡ç®—ç­‰ä¼˜åŒ–æ‰‹æ®µé™ä½ã€‚</li>
</ul>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c1f2ca81fe1b8fb97c156d8d63ffec9f.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-cda67e4ed7eb0be7cfd791327bcbae81.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-4586c4e1d3f294318a65d0cb95617ed0.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-85e6672939062f5d53f4dd663d7e2676.jpg" align="middle">
</details>




<h2 id="Burst-Super-Resolution-with-Diffusion-Models-for-Improving-Perceptual-Quality"><a href="#Burst-Super-Resolution-with-Diffusion-Models-for-Improving-Perceptual-Quality" class="headerlink" title="Burst Super-Resolution with Diffusion Models for Improving Perceptual   Quality"></a>Burst Super-Resolution with Diffusion Models for Improving Perceptual   Quality</h2><p><strong>Authors:Kyotaro Tokoro, Kazutoshi Akita, Norimichi Ukita</strong></p>
<p>While burst LR images are useful for improving the SR image quality compared with a single LR image, prior SR networks accepting the burst LR images are trained in a deterministic manner, which is known to produce a blurry SR image. In addition, it is difficult to perfectly align the burst LR images, making the SR image more blurry. Since such blurry images are perceptually degraded, we aim to reconstruct the sharp high-fidelity boundaries. Such high-fidelity images can be reconstructed by diffusion models. However, prior SR methods using the diffusion model are not properly optimized for the burst SR task. Specifically, the reverse process starting from a random sample is not optimized for image enhancement and restoration methods, including burst SR. In our proposed method, on the other hand, burst LR features are used to reconstruct the initial burst SR image that is fed into an intermediate step in the diffusion model. This reverse process from the intermediate step 1) skips diffusion steps for reconstructing the global structure of the image and 2) focuses on steps for refining detailed textures. Our experimental results demonstrate that our method can improve the scores of the perceptual quality metrics. Code: <a target="_blank" rel="noopener" href="https://github.com/placerkyo/BSRD">https://github.com/placerkyo/BSRD</a> </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.19428v1">PDF</a> Accepted to IJCNN 2024 (International Joint Conference on Neural   Networks)</p>
<p><strong>Summary</strong><br>æå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨çªå‘ä½åˆ†è¾¨ç‡ç‰¹å¾åœ¨æ‰©æ•£æ¨¡å‹ä¸­é—´æ­¥éª¤ä¸­é‡å»ºåˆå§‹çªå‘è¶…åˆ†è¾¨ç‡å›¾åƒï¼Œä»¥æé«˜è¶…åˆ†è¾¨ç‡å›¾åƒè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä½¿ç”¨æ‰©æ•£æ¨¡å‹é‡æ„å›¾åƒå¯ä»¥è·å¾—é«˜ä¿çœŸå›¾åƒã€‚</li>
<li>å°†çªå‘ä½åˆ†è¾¨ç‡ç‰¹å¾ç”¨äºæ‰©æ•£æ¨¡å‹ä¸­é—´æ­¥éª¤å¯ä»¥æé«˜è¶…åˆ†è¾¨ç‡è´¨é‡ã€‚</li>
<li>è¿™ç§é€†å‘è¿‡ç¨‹è·³è¿‡äº†æ‰©æ•£æ­¥éª¤ä»¥é‡å»ºå›¾åƒçš„å…¨å±€ç»“æ„ã€‚</li>
<li>è¿™ç§é€†å‘è¿‡ç¨‹ä¸“æ³¨äºç»†åŒ–è¯¦ç»†çº¹ç†çš„æ­¥éª¤ã€‚</li>
<li>æ­¤æ–¹æ³•ä¼˜äºå°†çªå‘ä½åˆ†è¾¨ç‡å›¾åƒä½œä¸ºè¾“å…¥çš„ç°æœ‰è¶…åˆ†è¾¨ç‡æ–¹æ³•ã€‚</li>
<li>è¿™ç§æ–¹æ³•å¯ä»¥æé«˜æ„ŸçŸ¥è´¨é‡æŒ‡æ ‡çš„åˆ†æ•°ã€‚</li>
<li>è¯¥æ–¹æ³•çš„ä»£ç å¯åœ¨ GitHub ä¸Šè·å¾—ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šæ‰©æ•£æ¨¡å‹çš„çªå‘è¶…åˆ†è¾¨ç‡ï¼Œä»¥æé«˜æ„ŸçŸ¥è´¨é‡</li>
<li>ä½œè€…ï¼šKyotaro Tokoroã€Kazutoshi Akitaã€Norimichi Ukita</li>
<li>æ‰€å±æœºæ„ï¼šä¸°ç”°æŠ€æœ¯å­¦é™¢</li>
<li>å…³é”®è¯ï¼šçªå‘è¶…åˆ†è¾¨ç‡ã€æ‰©æ•£æ¨¡å‹ã€æ„ŸçŸ¥è´¨é‡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.19428</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šçªå‘è¶…åˆ†è¾¨ç‡ (BurstSR) æ—¨åœ¨é€šè¿‡åˆ©ç”¨å¤šå¼ ä½åˆ†è¾¨ç‡ (LR) å›¾åƒæ¥æé«˜è¶…åˆ†è¾¨ç‡å›¾åƒçš„è´¨é‡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ BurstSR ç½‘ç»œä»¥ç¡®å®šæ€§æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œè¿™ä¼šå¯¼è‡´å›¾åƒæ¨¡ç³Šã€‚æ­¤å¤–ï¼Œéš¾ä»¥å®Œç¾å¯¹é½çªå‘ LR å›¾åƒï¼Œè¿™ä½¿å¾—è¶…åˆ†è¾¨ç‡å›¾åƒæ›´åŠ æ¨¡ç³Šã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„ BurstSR æ–¹æ³•ä½¿ç”¨ç¡®å®šæ€§æŸå¤±å‡½æ•°ï¼Œè¯¥å‡½æ•°å¯¼è‡´å›¾åƒæ¨¡ç³Šã€‚æ‰©æ•£æ¨¡å‹å¯ä»¥è¡¨ç¤ºé”åˆ©é«˜ä¿çœŸå›¾åƒçš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½†ç°æœ‰çš„ä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„ SR æ–¹æ³•å¹¶æœªé’ˆå¯¹ BurstSR ä»»åŠ¡è¿›è¡Œä¼˜åŒ–ã€‚
(3) æå‡ºçš„æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ BurstSR æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨çªå‘ LR ç‰¹å¾æ¥é‡å»ºåˆå§‹çªå‘è¶…åˆ†è¾¨ç‡å›¾åƒï¼Œè¯¥å›¾åƒè¢«é¦ˆé€åˆ°æ‰©æ•£æ¨¡å‹çš„ä¸­é—´æ­¥éª¤ã€‚è¯¥é€†è¿‡ç¨‹ä»ä¸­é—´æ­¥éª¤å¼€å§‹ï¼Œ1) è·³è¿‡ç”¨äºé‡å»ºå›¾åƒå…¨å±€ç»“æ„çš„æ‰©æ•£æ­¥éª¤ï¼Œ2) ä¸“æ³¨äºç”¨äºç»†åŒ–è¯¦ç»†çº¹ç†çš„æ­¥éª¤ã€‚
(4) æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜æ„ŸçŸ¥è´¨é‡æŒ‡æ ‡çš„åˆ†æ•°ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š(1) ä»ä¸­é—´æ­¥éª¤å¼€å§‹çš„åå‘è¿‡ç¨‹ï¼›(2) ç‰¹å¾æå–å’Œå¯¹é½æ¨¡å—ï¼›(3) èåˆï¼šä½¿ç”¨ç©ºé—´ç‰¹å¾å˜æ¢å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ï¼›(4) é‡å»ºï¼šä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„åå‘è¿‡ç¨‹è¿›è¡Œé‡å»ºã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§çªå‘è¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ä¸­é—´æ­¥éª¤æ¥é‡å»ºåˆå§‹çªå‘è¶…åˆ†è¾¨ç‡å›¾åƒï¼Œä»è€Œæé«˜äº†æ„ŸçŸ¥è´¨é‡æŒ‡æ ‡çš„åˆ†æ•°ã€‚
(2): åˆ›æ–°ç‚¹ï¼šæœ¬æ–¹æ³•å°†çªå‘è¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ä¸­é—´æ­¥éª¤æ¥é‡å»ºåˆå§‹çªå‘è¶…åˆ†è¾¨ç‡å›¾åƒï¼Œä»è€Œæé«˜äº†å›¾åƒçš„é”åº¦å’Œä¿çœŸåº¦ã€‚
æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ„ŸçŸ¥è´¨é‡æŒ‡æ ‡ä¸Šçš„å¾—åˆ†é«˜äºç°æœ‰çš„BurstSRæ–¹æ³•ã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•éœ€è¦å¯¹çªå‘LRå›¾åƒè¿›è¡Œç‰¹å¾æå–å’Œå¯¹é½ï¼Œå¹¶åœ¨æ‰©æ•£æ¨¡å‹çš„ä¸­é—´æ­¥éª¤è¿›è¡Œé‡å»ºï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-d59c7b91f1f317a66b1d14801de6b041.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3bbbff4707e4e2cfd420e82ce6c69b54.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-90a608b3341f93396c0bf75423c9b446.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-db64d4526bd8d46f3d4391283c0468e7.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-fd24520b1f2804fd4fd90e6854892a55.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-38fd33f7a863e3b619c78854cfa5beae.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-7103c45a7e021c15e27705471957f74c.jpg" align="middle">
</details>




<h2 id="RecDiffusion-Rectangling-for-Image-Stitching-with-Diffusion-Models"><a href="#RecDiffusion-Rectangling-for-Image-Stitching-with-Diffusion-Models" class="headerlink" title="RecDiffusion: Rectangling for Image Stitching with Diffusion Models"></a>RecDiffusion: Rectangling for Image Stitching with Diffusion Models</h2><p><strong>Authors:Tianhao Zhou, Haipeng Li, Ziyi Wang, Ao Luo, Chen-Lin Zhang, Jiajun Li, Bing Zeng, Shuaicheng Liu</strong></p>
<p>Image stitching from different captures often results in non-rectangular boundaries, which is often considered unappealing. To solve non-rectangular boundaries, current solutions involve cropping, which discards image content, inpainting, which can introduce unrelated content, or warping, which can distort non-linear features and introduce artifacts. To overcome these issues, we introduce a novel diffusion-based learning framework, \textbf{RecDiffusion}, for image stitching rectangling. This framework combines Motion Diffusion Models (MDM) to generate motion fields, effectively transitioning from the stitched imageâ€™s irregular borders to a geometrically corrected intermediary. Followed by Content Diffusion Models (CDM) for image detail refinement. Notably, our sampling process utilizes a weighted map to identify regions needing correction during each iteration of CDM. Our RecDiffusion ensures geometric accuracy and overall visual appeal, surpassing all previous methods in both quantitative and qualitative measures when evaluated on public benchmarks. Code is released at <a target="_blank" rel="noopener" href="https://github.com/lhaippp/RecDiffusion">https://github.com/lhaippp/RecDiffusion</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.19164v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„RecDiffusionæ¡†æ¶ï¼Œè§£å†³å›¾åƒæ‹¼æ¥ä¸­éçŸ©å½¢è¾¹ç•Œé—®é¢˜ï¼Œé€šè¿‡è¿åŠ¨åœºç”Ÿæˆå’Œç»†èŠ‚ä¼˜åŒ–å®ç°å›¾åƒæ‹¼æ¥çŸ©å½¢åŒ–ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºä¸€ç§åŸºäºæ‰©æ•£çš„å­¦ä¹ æ¡†æ¶RecDiffusionï¼Œç”¨äºå›¾åƒæ‹¼æ¥çŸ©å½¢åŒ–ã€‚</li>
<li>RecDiffusionæ¡†æ¶ç»“åˆè¿åŠ¨æ‰©æ•£æ¨¡å‹å’Œå†…å®¹æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>é€šè¿‡è¿åŠ¨åœºç”Ÿæˆå®ç°ä»éçŸ©å½¢è¾¹ç•Œåˆ°å‡ ä½•æ ¡æ­£ä¸­ä»‹çš„è½¬æ¢ã€‚</li>
<li>é€šè¿‡ç»†èŠ‚ä¼˜åŒ–å®Œæˆå›¾åƒæ‹¼æ¥åçš„å›¾åƒç»†èŠ‚æ¢å¤ã€‚</li>
<li>åˆ©ç”¨åŠ æƒå›¾åœ¨æ¯æ¬¡ä¼˜åŒ–è¿­ä»£ä¸­è¯†åˆ«éœ€è¦æ ¡æ­£çš„åŒºåŸŸã€‚</li>
<li>åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­ï¼ŒRecDiffusionåœ¨å…¬å…±åŸºå‡†ä¸Šä¼˜äºæ‰€æœ‰å…ˆå‰æ–¹æ³•ã€‚</li>
<li>ä»£ç å·²åœ¨GitHubä¸Šå‘å¸ƒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šRecDiffusionï¼šåˆ©ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒæ‹¼æ¥çŸ©å½¢åŒ–</li>
<li>ä½œè€…ï¼šTianhao Zhouï¼ŒHaipeng Liï¼ŒZiyi Wangï¼ŒAo Luoï¼ŒChen-Lin Zhangï¼ŒJiajun Liï¼ŒBing Zengï¼ŒShuaicheng Liu</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šç”µå­ç§‘æŠ€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šå›¾åƒæ‹¼æ¥ï¼ŒçŸ©å½¢åŒ–ï¼Œæ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.19164
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼š<strong>ç ”ç©¶èƒŒæ™¯ï¼š</strong>å›¾åƒæ‹¼æ¥é€šå¸¸ä¼šå¯¼è‡´éçŸ©å½¢çš„è¾¹ç•Œï¼Œè¿™ä¼šå½±å“è§†è§‰ç¾è§‚ã€‚
(2)ï¼š<strong>è¿‡å»çš„æ–¹æ³•ï¼š</strong>ç°æœ‰çš„æ–¹æ³•åŒ…æ‹¬è£å‰ªã€ä¿®å¤å’Œæ‰­æ›²ï¼Œä½†è¿™äº›æ–¹æ³•å­˜åœ¨ä¸¢å¼ƒå›¾åƒå†…å®¹ã€å¼•å…¥æ— å…³å†…å®¹æˆ–äº§ç”Ÿå¤±çœŸå’Œä¼ªå½±ç­‰é—®é¢˜ã€‚
(3)ï¼š<strong>ç ”ç©¶æ–¹æ³•ï¼š</strong>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£å­¦ä¹ çš„æ¡†æ¶ RecDiffusionï¼Œå®ƒç»“åˆäº†è¿åŠ¨æ‰©æ•£æ¨¡å‹ï¼ˆMDMï¼‰å’Œå†…å®¹æ‰©æ•£æ¨¡å‹ï¼ˆCDMï¼‰ï¼Œé€šè¿‡ç”Ÿæˆè¿åŠ¨åœºæœ‰æ•ˆåœ°å°†æ‹¼æ¥å›¾åƒçš„ä¸è§„åˆ™è¾¹ç•Œè½¬æ¢ä¸ºå‡ ä½•æ ¡æ­£çš„ä¸­é—´ä½“ï¼Œå¹¶é€šè¿‡ CDM ç»†åŒ–å›¾åƒç»†èŠ‚ã€‚
(4)ï¼š<strong>æ–¹æ³•æ€§èƒ½ï¼š</strong>åœ¨å…¬å¼€åŸºå‡†ä¸Šè¯„ä¼°ï¼ŒRecDiffusion åœ¨å®šé‡å’Œå®šæ€§æŒ‡æ ‡ä¸Šå‡ä¼˜äºæ‰€æœ‰å…ˆå‰æ–¹æ³•ï¼Œç¡®ä¿äº†å‡ ä½•ç²¾åº¦å’Œæ•´ä½“è§†è§‰å¸å¼•åŠ›ï¼Œæ”¯æŒäº†å…¶ç›®æ ‡ã€‚</li>
</ol>
<p><strong>Methods:</strong>
(1): RecDiffusionæ¡†æ¶å°†å›¾åƒæ‹¼æ¥çŸ©å½¢åŒ–ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªå­ä»»åŠ¡ï¼šè¿åŠ¨åœºç”Ÿæˆå’Œå›¾åƒç»†èŠ‚ç»†åŒ–ã€‚
(2): è¿åŠ¨åœºç”Ÿæˆä½¿ç”¨è¿åŠ¨æ‰©æ•£æ¨¡å‹ï¼ˆMDMï¼‰å°†æ‹¼æ¥å›¾åƒçš„ä¸è§„åˆ™è¾¹ç•Œè½¬æ¢ä¸ºå‡ ä½•æ ¡æ­£çš„ä¸­é—´ä½“ï¼Œè¯¥ä¸­é—´ä½“å…·æœ‰çŸ©å½¢çš„è¾¹ç•Œã€‚
(3): å›¾åƒç»†èŠ‚ç»†åŒ–ä½¿ç”¨å†…å®¹æ‰©æ•£æ¨¡å‹ï¼ˆCDMï¼‰å¯¹è¿åŠ¨åœºç”Ÿæˆçš„ä¸­é—´ä½“è¿›è¡Œç»†åŒ–ï¼Œæ¢å¤å›¾åƒçš„è§†è§‰ç»†èŠ‚å’Œå†…å®¹ã€‚</p>
<p>8.ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œé¦–æ¬¡æå‡ºåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒæ‹¼æ¥çŸ©å½¢åŒ–æ–¹æ³• RecDiffusionï¼Œåœ¨å®šé‡å’Œå®šæ€§æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çš„æ–¹æ³•ï¼Œåœ¨å›¾åƒæ‹¼æ¥çŸ©å½¢åŒ–ä»»åŠ¡ä¸Šå–å¾—äº†æ–°çš„è¿›å±•ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š
  * æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£å­¦ä¹ çš„å›¾åƒæ‹¼æ¥çŸ©å½¢åŒ–æ¡†æ¶ï¼Œå°†å›¾åƒæ‹¼æ¥çŸ©å½¢åŒ–ä»»åŠ¡åˆ†è§£ä¸ºè¿åŠ¨åœºç”Ÿæˆå’Œå›¾åƒç»†èŠ‚ç»†åŒ–ä¸¤ä¸ªå­ä»»åŠ¡ã€‚
  * ä½¿ç”¨è¿åŠ¨æ‰©æ•£æ¨¡å‹ï¼ˆMDMï¼‰ç”Ÿæˆè¿åŠ¨åœºï¼Œå°†æ‹¼æ¥å›¾åƒçš„ä¸è§„åˆ™è¾¹ç•Œè½¬æ¢ä¸ºå‡ ä½•æ ¡æ­£çš„ä¸­é—´ä½“ã€‚
  * ä½¿ç”¨å†…å®¹æ‰©æ•£æ¨¡å‹ï¼ˆCDMï¼‰ç»†åŒ–è¿åŠ¨åœºç”Ÿæˆçš„ä¸­é—´ä½“ï¼Œæ¢å¤å›¾åƒçš„è§†è§‰ç»†èŠ‚å’Œå†…å®¹ã€‚
  * æå‡ºäº†ä¸€ç§åŠ æƒé‡‡æ ·æ©ç ç­–ç•¥ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†è¿åŠ¨ä¸å‡†ç¡®å’Œæ‰­æ›²æ“ä½œå¼•å…¥çš„ä¼ªå½±é—®é¢˜ã€‚
æ€§èƒ½ï¼š
  * åœ¨å…¬å¼€åŸºå‡†ä¸Šè¯„ä¼°ï¼ŒRecDiffusion åœ¨å®šé‡å’Œå®šæ€§æŒ‡æ ‡ä¸Šå‡ä¼˜äºæ‰€æœ‰å…ˆå‰æ–¹æ³•ï¼Œç¡®ä¿äº†å‡ ä½•ç²¾åº¦å’Œæ•´ä½“è§†è§‰å¸å¼•åŠ›ã€‚
  * RecDiffusion èƒ½å¤Ÿå¤„ç†å…·æœ‰å¤æ‚å½¢çŠ¶å’Œçº¹ç†çš„å›¾åƒï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„çŸ©å½¢æ‹¼æ¥å›¾åƒã€‚
å·¥ä½œé‡ï¼š
  * RecDiffusion çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è®­ç»ƒä¸¤ä¸ªæ‰©æ•£æ¨¡å‹ï¼ˆMDM å’Œ CDMï¼‰ä»¥åŠä¸€ä¸ªåŠ æƒé‡‡æ ·æ©ç ç­–ç•¥ã€‚
  * RecDiffusion çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-77effd3ad72f33cf1611551d1ed8f93b.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-324381f16acdcccba072b2e0dbe8c94e.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-022e895d915f18f5818f8e07749c71b8.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2a94f6b6864f80b6d7535472bb7edd8c.jpg" align="middle">
</details>




## QNCD: Quantization Noise Correction for Diffusion Models

**Authors:Huanpeng Chu, Wei Wu, Chengjie Zang, Kun Yuan**

Diffusion models have revolutionized image synthesis, setting new benchmarks in quality and creativity. However, their widespread adoption is hindered by the intensive computation required during the iterative denoising process. Post-training quantization (PTQ) presents a solution to accelerate sampling, aibeit at the expense of sample quality, extremely in low-bit settings. Addressing this, our study introduces a unified Quantization Noise Correction Scheme (QNCD), aimed at minishing quantization noise throughout the sampling process. We identify two primary quantization challenges: intra and inter quantization noise. Intra quantization noise, mainly exacerbated by embeddings in the resblock module, extends activation quantization ranges, increasing disturbances in each single denosing step. Besides, inter quantization noise stems from cumulative quantization deviations across the entire denoising process, altering data distributions step-by-step. QNCD combats these through embedding-derived feature smoothing for eliminating intra quantization noise and an effective runtime noise estimatiation module for dynamicly filtering inter quantization noise. Extensive experiments demonstrate that our method outperforms previous quantization methods for diffusion models, achieving lossless results in W4A8 and W8A8 quantization settings on ImageNet (LDM-4). Code is available at: https://github.com/huanpengchu/QNCD 

[PDF](http://arxiv.org/abs/2403.19140v1) 

**Summary**
æ‰©æ•£æ¨¡å‹ä¸­ç»Ÿä¸€é‡åŒ–å™ªå£°ä¿®æ­£æ–¹æ¡ˆï¼ˆQNCDï¼‰å¯å¼¥è¡¥åè®­ç»ƒé‡åŒ–å¸¦æ¥çš„è´¨é‡æŸå¤±ï¼Œæ˜¾è‘—æå‡æ¨¡å‹é‡‡æ ·é€Ÿåº¦ã€‚

**Key Takeaways**
- QNCD æ–¹æ¡ˆå¯æœ‰æ•ˆè§£å†³æ‰©æ•£æ¨¡å‹åè®­ç»ƒé‡åŒ–ä¸­çš„é‡åŒ–å™ªå£°é—®é¢˜ï¼Œæå‡é‡‡æ ·é€Ÿåº¦ã€‚
- åˆ†è¾¨äº†é‡åŒ–å™ªå£°çš„ä¸¤ç§å½¢å¼ï¼šæ­¥å†…é‡åŒ–å™ªå£°å’Œæ­¥é—´é‡åŒ–å™ªå£°ã€‚
- æ­¥å†…é‡åŒ–å™ªå£°ä¸»è¦ç”±æ®‹å·®å—ä¸­çš„åµŒå…¥é‡åŒ–å¼•èµ·ï¼Œå¯¼è‡´æ¿€æ´»é‡åŒ–èŒƒå›´æ‰©å¤§ï¼ŒåŠ å¤§å»å™ªæ‰°åŠ¨ã€‚
- æ­¥é—´é‡åŒ–å™ªå£°æºäºæ•´ä¸ªå»å™ªè¿‡ç¨‹ä¸­é‡åŒ–åå·®çš„ç´¯ç§¯ï¼Œé€æ­¥æ”¹å˜æ•°æ®åˆ†å¸ƒã€‚
- QNCD é€šè¿‡åµŒå…¥ç‰¹å¾å¹³æ»‘æ¶ˆé™¤æ­¥å†…é‡åŒ–å™ªå£°ï¼Œå¹¶ä½¿ç”¨è¿è¡Œæ—¶å™ªå£°ä¼°è®¡æ¨¡å—åŠ¨æ€è¿‡æ»¤æ­¥é—´é‡åŒ–å™ªå£°ã€‚
- å®éªŒè¡¨æ˜ QNCD ä¼˜äºç°æœ‰é‡åŒ–æ–¹æ³•ï¼Œåœ¨ ImageNetï¼ˆLDM-4ï¼‰ä¸Šè¾¾åˆ° W4A8 å’Œ W8A8 é‡åŒ–è®¾ç½®ä¸‹çš„æ— æŸç»“æœã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šQNCDï¼šæ‰©æ•£æ¨¡å‹çš„é‡åŒ–å™ªå£°æ ¡æ­£</li>
<li>ä½œè€…ï¼šHuanpeng Chuï¼ŒWei Wuï¼ŒChengjie Zangï¼ŒKun Yuan</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¿«æ‰‹ç§‘æŠ€</li>
<li>å…³é”®è¯ï¼šDiffusion Modelsï¼ŒPost-Training Quantizationï¼ŒQuantization Noise Correction</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.19140
   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/huanpengchu/QNCD</li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
   æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶å¹¿æ³›åº”ç”¨å—åˆ°è¿­ä»£å»å™ªè¿‡ç¨‹ä¸­é«˜è®¡ç®—éœ€æ±‚çš„é˜»ç¢ã€‚åè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰æä¾›äº†ä¸€ç§åŠ é€Ÿé‡‡æ ·çš„è§£å†³æ–¹æ¡ˆï¼Œä½†ä»£ä»·æ˜¯ç‰ºç‰²æ ·æœ¬è´¨é‡ï¼Œå°¤å…¶åœ¨ä½æ¯”ç‰¹è®¾ç½®ä¸­ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼š
   ä»¥å¾€çš„é‡åŒ–æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ¿€æ´»é‡åŒ–ä¸Šï¼Œä½†å¿½è§†äº†åµŒå…¥é‡åŒ–å¸¦æ¥çš„é‡åŒ–å™ªå£°ã€‚è¿™äº›å™ªå£°ä¼šéšç€é‡‡æ ·æ­¥éª¤çš„è¿›è¡Œè€Œç´¯ç§¯ï¼Œå½±å“æ•°æ®åˆ†å¸ƒå¹¶é™ä½æ ·æœ¬è´¨é‡ã€‚</p>
<p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š
   æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„é‡åŒ–å™ªå£°æ ¡æ­£æ–¹æ¡ˆï¼ˆQNCDï¼‰ï¼Œæ—¨åœ¨æœ€å°åŒ–æ•´ä¸ªé‡‡æ ·è¿‡ç¨‹ä¸­çš„é‡åŒ–å™ªå£°ã€‚QNCD è¯†åˆ«å‡ºä¸¤ç§ä¸»è¦çš„é‡åŒ–æŒ‘æˆ˜ï¼š
   - <strong>å†…éƒ¨é‡åŒ–å™ªå£°ï¼š</strong>ä¸»è¦ç”±æ®‹å·®å—æ¨¡å—ä¸­çš„åµŒå…¥é‡åŒ–å¼•èµ·ï¼Œå®ƒä¼šæ‰©å±•æ¿€æ´»é‡åŒ–èŒƒå›´ï¼Œå¢åŠ æ¯ä¸ªå»å™ªæ­¥éª¤ä¸­çš„æ‰°åŠ¨ã€‚
   - <strong>å¤–éƒ¨é‡åŒ–å™ªå£°ï¼š</strong>æºäºæ•´ä¸ªå»å™ªè¿‡ç¨‹ä¸­çš„ç´¯ç§¯é‡åŒ–åå·®ï¼Œé€æ­¥æ”¹å˜æ•°æ®åˆ†å¸ƒã€‚
   QNCD é€šè¿‡ä»¥ä¸‹æ–¹æ³•è§£å†³è¿™äº›é—®é¢˜ï¼š
   - åµŒå…¥ç‰¹å¾å¹³æ»‘ï¼šæ¶ˆé™¤å†…éƒ¨é‡åŒ–å™ªå£°ã€‚
   - è¿è¡Œæ—¶å™ªå£°ä¼°è®¡æ¨¡å—ï¼šåŠ¨æ€è¿‡æ»¤å¤–éƒ¨é‡åŒ–å™ªå£°ã€‚</p>
<p>ï¼ˆ4ï¼‰å®éªŒç»“æœå’Œæ€§èƒ½ï¼š
   å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒQNCD ä¼˜äºæ‰©æ•£æ¨¡å‹çš„å…ˆå‰é‡åŒ–æ–¹æ³•ï¼Œåœ¨ ImageNetï¼ˆLDM-4ï¼‰ä¸Šçš„ W4A8 å’Œ W8A8 é‡åŒ–è®¾ç½®ä¸­å®ç°äº†æ— æŸç»“æœã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº† QNCD é™ä½é‡åŒ–å™ªå£°å¹¶æé«˜æ ·æœ¬è´¨é‡çš„ç›®æ ‡ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
(1): æå‡ºç»Ÿä¸€çš„é‡åŒ–å™ªå£°æ ¡æ­£æ–¹æ¡ˆ QNCDï¼Œæœ€å°åŒ–æ•´ä¸ªé‡‡æ ·è¿‡ç¨‹ä¸­çš„é‡åŒ–å™ªå£°ã€‚
(2): è¯†åˆ«ä¸¤ç§ä¸»è¦çš„é‡åŒ–æŒ‘æˆ˜ï¼šå†…éƒ¨é‡åŒ–å™ªå£°å’Œå¤–éƒ¨é‡åŒ–å™ªå£°ã€‚
(3): åµŒå…¥ç‰¹å¾å¹³æ»‘ï¼Œæ¶ˆé™¤å†…éƒ¨é‡åŒ–å™ªå£°ã€‚
(4): è¿è¡Œæ—¶å™ªå£°ä¼°è®¡æ¨¡å—ï¼ŒåŠ¨æ€è¿‡æ»¤å¤–éƒ¨é‡åŒ–å™ªå£°ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº† QNCDï¼Œä¸€ç§ç”¨äºæ‰©æ•£æ¨¡å‹çš„ç»Ÿä¸€é‡åŒ–å™ªå£°æ ¡æ­£æ–¹æ¡ˆã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯¹é‡åŒ–å™ªå£°çš„æ¥æºå’Œå½±å“è¿›è¡Œäº†è¯¦ç»†çš„åˆ†æï¼Œå¹¶å‘ç°å†…éƒ¨é‡åŒ–å™ªå£°çš„å‘¨æœŸæ€§å¢åŠ æºäºåµŒå…¥æ”¹å˜äº†ç‰¹å¾åˆ†å¸ƒã€‚å› æ­¤ï¼Œæˆ‘ä»¬è®¡ç®—äº†ä¸€ä¸ªå¹³æ»‘å› å­æ¥å‡å°‘é‡åŒ–å™ªå£°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè¿è¡Œæ—¶å™ªå£°ä¼°è®¡æ¨¡å—æ¥ä¼°è®¡å†…éƒ¨é‡åŒ–å™ªå£°çš„åˆ†å¸ƒï¼Œå¹¶åœ¨æ‰©æ•£æ¨¡å‹çš„é‡‡æ ·è¿‡ç¨‹ä¸­è¿›ä¸€æ­¥å¯¹å…¶è¿›è¡Œæ»¤æ³¢ã€‚åˆ©ç”¨è¿™äº›æŠ€æœ¯ï¼Œæˆ‘ä»¬çš„ QNCD è¶…è¿‡äº†ç°æœ‰çš„æœ€å…ˆè¿›çš„åè®­ç»ƒé‡åŒ–æ‰©æ•£æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨ä½ä½æ¿€æ´»é‡åŒ– (W4A6) ä¸­ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªæ‰©æ•£å»ºæ¨¡æ¡†æ¶ï¼ˆDDIMã€LDM å’Œ Stable Diffusionï¼‰å’Œå¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†å½“å‰ SOTAï¼Œå±•ç¤ºäº† QNCD çš„å¹¿æ³›é€‚ç”¨æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>è¯†åˆ«å¹¶è§£å†³äº†æ‰©æ•£æ¨¡å‹ä¸­é‡åŒ–å™ªå£°çš„ä¸¤ä¸ªä¸»è¦æ¥æºï¼šå†…éƒ¨é‡åŒ–å™ªå£°å’Œå¤–éƒ¨é‡åŒ–å™ªå£°ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åµŒå…¥ç‰¹å¾å¹³æ»‘æ–¹æ³•æ¥æ¶ˆé™¤å†…éƒ¨é‡åŒ–å™ªå£°ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªè¿è¡Œæ—¶å™ªå£°ä¼°è®¡æ¨¡å—æ¥åŠ¨æ€æ»¤é™¤å¤–éƒ¨é‡åŒ–å™ªå£°ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ ImageNetï¼ˆLDM-4ï¼‰ä¸Š W4A8 å’Œ W8A8 é‡åŒ–è®¾ç½®ä¸­å®ç°äº†æ— æŸç»“æœã€‚</li>
<li>åœ¨å¤šä¸ªæ‰©æ•£å»ºæ¨¡æ¡†æ¶å’Œæ•°æ®é›†ä¸Šä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„åè®­ç»ƒé‡åŒ–æ‰©æ•£æ¨¡å‹ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„é‡åŒ–å™ªå£°æ ¡æ­£æ–¹æ¡ˆï¼Œæ˜“äºå®ç°å’Œé›†æˆåˆ°ç°æœ‰æ‰©æ•£æ¨¡å‹ä¸­ã€‚</li>
<li>è¿è¡Œæ—¶å™ªå£°ä¼°è®¡æ¨¡å—çš„è®¡ç®—æˆæœ¬ä½ï¼Œä¸ä¼šæ˜¾ç€å¢åŠ é‡‡æ ·æ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ab9c366da4b3c18e5536fb4d4b1d2831.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-bf2ed02f1e542654a3aeb77e2cdf8f83.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-014a026118e494ef705ba46ec1c8f2bb.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f83b5e39d9a64d9e5f49a58d4b5ab948.jpg" align="middle">
</details>




<h2 id="ObjectDrop-Bootstrapping-Counterfactuals-for-Photorealistic-Object-Removal-and-Insertion"><a href="#ObjectDrop-Bootstrapping-Counterfactuals-for-Photorealistic-Object-Removal-and-Insertion" class="headerlink" title="ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object   Removal and Insertion"></a>ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object   Removal and Insertion</h2><p><strong>Authors:Daniel Winter, Matan Cohen, Shlomi Fruchter, Yael Pritch, Alex Rav-Acha, Yedid Hoshen</strong></p>
<p>Diffusion models have revolutionized image editing but often generate images that violate physical laws, particularly the effects of objects on the scene, e.g., occlusions, shadows, and reflections. By analyzing the limitations of self-supervised approaches, we propose a practical solution centered on a \q{counterfactual} dataset. Our method involves capturing a scene before and after removing a single object, while minimizing other changes. By fine-tuning a diffusion model on this dataset, we are able to not only remove objects but also their effects on the scene. However, we find that applying this approach for photorealistic object insertion requires an impractically large dataset. To tackle this challenge, we propose bootstrap supervision; leveraging our object removal model trained on a small counterfactual dataset, we synthetically expand this dataset considerably. Our approach significantly outperforms prior methods in photorealistic object removal and insertion, particularly at modeling the effects of objects on the scene. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.18818v1">PDF</a> </p>
<p><strong>Summary</strong><br>è‡ªä¸»ç›‘ç£æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç¼–è¾‘ä¸­å­˜åœ¨ç‰©ç†è§„å¾‹è¿èƒŒé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåäº‹å®æ•°æ®é›†å’Œå¼•å¯¼ç›‘ç£çš„è§£å†³æ–¹æ¡ˆï¼Œæ˜¾è‘—æå‡äº†å›¾åƒç¼–è¾‘çš„çœŸå®æ„Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç¼–è¾‘ä¸­å­˜åœ¨ç‰©ç†è§„å¾‹è¿èƒŒé—®é¢˜ï¼Œå¦‚é®æŒ¡ã€é˜´å½±å’Œåå°„ã€‚</li>
<li>é’ˆå¯¹è‡ªç›‘ç£æ–¹æ³•çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåäº‹å®æ•°æ®é›†çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>åäº‹å®æ•°æ®é›†åŒ…å«å¯¹è±¡ç§»é™¤å‰åçš„åœºæ™¯å›¾åƒï¼Œæœ€å°åŒ–å…¶ä»–å˜åŒ–ã€‚</li>
<li>é€šè¿‡åœ¨åäº‹å®æ•°æ®é›†ä¸Šå¾®è°ƒæ‰©æ•£æ¨¡å‹ï¼Œä¸ä»…å¯ä»¥ç§»é™¤å¯¹è±¡ï¼Œè¿˜å¯ä»¥ç§»é™¤å…¶å¯¹åœºæ™¯çš„å½±å“ã€‚</li>
<li>ç…§ç‰‡çº§å¯¹è±¡æ’å…¥éœ€è¦éå¸¸å¤§çš„æ•°æ®é›†ï¼Œæœ¬æ–‡æå‡ºäº†å¼•å¯¼ç›‘ç£æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚</li>
<li>å¼•å¯¼ç›‘ç£åˆ©ç”¨åœ¨å°åäº‹å®æ•°æ®é›†ä¸Šè®­ç»ƒçš„å¯¹è±¡ç§»é™¤æ¨¡å‹ï¼Œåˆæˆå¤§é‡æ‰©å……æ•°æ®é›†ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ç…§ç‰‡çº§å¯¹è±¡ç§»é™¤å’Œæ’å…¥æ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨æ¨¡æ‹Ÿå¯¹è±¡å¯¹åœºæ™¯çš„å½±å“æ–¹é¢ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šObjectDropï¼šå¼•å¯¼åäº‹å®ç”¨äºé€¼çœŸå¯¹è±¡ç§»é™¤å’Œæ’å…¥</li>
<li>ä½œè€…ï¼šDaniel Winterã€Matan Cohenã€Shlomi Fruchterã€Yael Pritchã€Alex Rav-Achaã€Yedid Hoshen</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè€¶è·¯æ’’å†·å¸Œä¼¯æ¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼šDiffusion Modelã€Object Removalã€Object Insertionã€Counterfactual Datasetã€Bootstrap Supervision</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://ObjectDrop.github.ioï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç¼–è¾‘ä¸­å–å¾—äº†å·¨å¤§è¿›æ­¥ï¼Œä½†ç»å¸¸ç”Ÿæˆè¿åç‰©ç†å®šå¾‹çš„å›¾åƒï¼Œå°¤å…¶æ˜¯å¯¹è±¡å¯¹åœºæ™¯çš„å½±å“ï¼Œå¦‚é®æŒ¡ã€é˜´å½±å’Œåå°„ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šæœ¬æ–‡åˆ†æäº†è‡ªç›‘ç£æ–¹æ³•çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ä¸ªä»¥â€œåäº‹å®â€æ•°æ®é›†ä¸ºä¸­å¿ƒçš„å®ç”¨è§£å†³æ–¹æ¡ˆã€‚è¿‡å»æ–¹æ³•çš„é—®é¢˜ï¼šæ— æ³•å»ºæ¨¡å¯¹è±¡å¯¹åœºæ™¯çš„å½±å“ï¼Œç”Ÿæˆå›¾åƒä¸çœŸå®ã€‚æœ¬æ–‡æ–¹æ³•çš„åˆç†æ€§ï¼šé€šè¿‡åˆ†ææ‰©æ•£æ¨¡å‹çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§ä»¥â€œåäº‹å®â€æ•°æ®é›†ä¸ºæ ¸å¿ƒçš„å®ç”¨è§£å†³æ–¹æ¡ˆã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æ–¹æ³•åŒ…æ‹¬åœ¨ç§»é™¤å•ä¸ªå¯¹è±¡å‰åæ•æ‰åœºæ™¯ï¼ŒåŒæ—¶æœ€å¤§ç¨‹åº¦åœ°å‡å°‘å…¶ä»–å˜åŒ–ã€‚é€šè¿‡å¾®è°ƒåœ¨è¿™ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œä¸ä»…å¯ä»¥ç§»é™¤å¯¹è±¡ï¼Œè¿˜å¯ä»¥ç§»é™¤å¯¹è±¡å¯¹åœºæ™¯çš„å½±å“ã€‚ä½†æ˜¯ï¼Œæœ¬æ–‡å‘ç°å°†è¿™ç§æ–¹æ³•åº”ç”¨äºé€¼çœŸçš„å¯¹è±¡æ’å…¥éœ€è¦ä¸€ä¸ªéå¸¸å¤§çš„æ•°æ®é›†ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†è‡ªä¸¾ç›‘ç£ï¼›åˆ©ç”¨åœ¨å°å‹åäº‹å®æ•°æ®é›†ä¸Šè®­ç»ƒçš„å¯¹è±¡ç§»é™¤æ¨¡å‹ï¼Œæœ¬æ–‡å¤§å¹…æ‰©å……äº†è¿™ä¸ªæ•°æ®é›†ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•åœ¨é€¼çœŸçš„å¯¹è±¡ç§»é™¤å’Œæ’å…¥æ–¹é¢æ˜¾è‘—ä¼˜äºå…ˆå‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨å»ºæ¨¡å¯¹è±¡å¯¹åœºæ™¯çš„å½±å“æ–¹é¢ã€‚å¯¹è±¡ç§»é™¤ï¼šæœ¬æ–‡æ–¹æ³•ä¼˜äºåŸºçº¿æ–¹æ³•ï¼›å¯¹è±¡æ’å…¥ï¼šæœ¬æ–‡æ–¹æ³•ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚æœ¬æ–‡æ–¹æ³•çš„æ€§èƒ½å¯ä»¥æ”¯æŒå…¶ç›®æ ‡ï¼šé€¼çœŸçš„å¯¹è±¡ç§»é™¤å’Œæ’å…¥ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ æœ¬æ–‡æå‡ºäº†ä¸€ç§ç›‘ç£å¼æ–¹æ³• ObjectDropï¼Œç”¨äºå¯¹è±¡ç§»é™¤å’Œæ’å…¥ï¼Œä»¥å…‹æœå…ˆå‰è‡ªç›‘ç£æ–¹æ³•çš„å±€é™æ€§ã€‚æˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªåäº‹å®æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ç‰©ç†æ“ä½œå¯¹è±¡å‰åæˆå¯¹çš„å›¾åƒã€‚ç”±äºè·å–æ­¤ç±»æ•°æ®é›†çš„æˆæœ¬å¾ˆé«˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è‡ªä¸¾ç›‘ç£æ–¹æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡å…¨é¢çš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§ä»¥åäº‹å®æ•°æ®é›†ä¸ºä¸­å¿ƒçš„æ–¹æ³•ï¼Œç”¨äºé€¼çœŸçš„å¯¹è±¡ç§»é™¤å’Œæ’å…¥ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è‡ªä¸¾ç›‘ç£æ–¹æ³•ï¼Œç”¨äºå¤§å¹…æ‰©å……åäº‹å®æ•°æ®é›†ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨é€¼çœŸçš„å¯¹è±¡ç§»é™¤å’Œæ’å…¥æ–¹é¢æ˜æ˜¾ä¼˜äºå…ˆå‰æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æ”¶é›†åäº‹å®æ•°æ®é›†çš„æˆæœ¬å¾ˆé«˜ã€‚</li>
<li>è‡ªä¸¾ç›‘ç£æ–¹æ³•éœ€è¦é¢å¤–çš„è®¡ç®—æˆæœ¬ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-0d997350ce4a66ea5dd9782de7718c23.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-2ed8c6a6f3bbd9d635cbb2b475d7dfb1.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-88ead8e558b3c1e695cfe7bb4d525b54.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-62bf94b77512da17da6fc4e4d9b81c90.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-2a4d4bfd835212368d79dde8ef201f90.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c57e44a801b6bd61623098450a79abf2.jpg" align="middle">
</details>




<h2 id="Object-Pose-Estimation-via-the-Aggregation-of-Diffusion-Features"><a href="#Object-Pose-Estimation-via-the-Aggregation-of-Diffusion-Features" class="headerlink" title="Object Pose Estimation via the Aggregation of Diffusion Features"></a>Object Pose Estimation via the Aggregation of Diffusion Features</h2><p><strong>Authors:Tianfu Wang, Guosheng Hu, Hongguang Wang</strong></p>
<p>Estimating the pose of objects from images is a crucial task of 3D scene understanding, and recent approaches have shown promising results on very large benchmarks. However, these methods experience a significant performance drop when dealing with unseen objects. We believe that it results from the limited generalizability of image features. To address this problem, we have an in-depth analysis on the features of diffusion models, e.g. Stable Diffusion, which hold substantial potential for modeling unseen objects. Based on this analysis, we then innovatively introduce these diffusion features for object pose estimation. To achieve this, we propose three distinct architectures that can effectively capture and aggregate diffusion features of different granularity, greatly improving the generalizability of object pose estimation. Our approach outperforms the state-of-the-art methods by a considerable margin on three popular benchmark datasets, LM, O-LM, and T-LESS. In particular, our method achieves higher accuracy than the previous best arts on unseen objects: 98.2% vs. 93.5% on Unseen LM, 85.9% vs. 76.3% on Unseen O-LM, showing the strong generalizability of our method. Our code is released at <a target="_blank" rel="noopener" href="https://github.com/Tianfu18/diff-feats-pose">https://github.com/Tianfu18/diff-feats-pose</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.18791v1">PDF</a> Accepted to CVPR2024</p>
<p><strong>Summary</strong><br>åˆ©ç”¨ç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„ç‰¹å¾æå‡ç‰©ä½“å§¿æ€ä¼°è®¡çš„æ³›åŒ–æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å›¾åƒç‰¹å¾çš„æ³›åŒ–æ€§é™åˆ¶äº†ç‰©ä½“å§¿æ€ä¼°è®¡åœ¨å¤„ç†æœªè§ç‰©ä½“æ—¶çš„æ€§èƒ½ã€‚</li>
<li>ç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„ç‰¹å¾å…·æœ‰å»ºæ¨¡æœªè§ç‰©ä½“çš„æ½œåŠ›ã€‚</li>
<li>æå‡ºä¸‰ç§ä¸åŒçš„æ¶æ„æ¥æœ‰æ•ˆæ•è·å’Œèšåˆä¸åŒç²’åº¦çš„æ‰©æ•£ç‰¹å¾ã€‚</li>
<li>æ‰€æå‡ºçš„æ–¹æ³•åœ¨ä¸‰ä¸ªæµè¡ŒåŸºå‡†æ•°æ®é›† LMã€O-LM å’Œ T-LESS ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æœªè§ç‰©ä½“ä¸Šå–å¾—äº†æ¯”ä»¥å¾€æœ€ä½³è‰ºæœ¯æ›´é«˜çš„å‡†ç¡®åº¦ï¼šæœªè§ LM ä¸º 98.2% å¯¹ 93.5%ï¼Œæœªè§ O-LM ä¸º 85.9% å¯¹ 76.3%ã€‚</li>
<li>ä»£ç å·²åœ¨ <a target="_blank" rel="noopener" href="https://github.com/Tianfu18/diff-feats-pose">https://github.com/Tianfu18/diff-feats-pose</a> å‘å¸ƒã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£ç‰¹å¾çš„ç‰©ä½“å§¿æ€ä¼°è®¡</li>
<li>ä½œè€…ï¼šTianfu Wang, Guosheng Hu, Hongguang Wang</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢æ²ˆé˜³è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€æœºå™¨äººå›½å®¶é‡ç‚¹å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šç‰©ä½“å§¿æ€ä¼°è®¡ã€æ‰©æ•£æ¨¡å‹ã€ç‰¹å¾èšåˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.18791
   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/Tianfu18/diff-feats-pose</li>
<li>
<p>æ‘˜è¦ï¼š
   (1) ç ”ç©¶èƒŒæ™¯ï¼šç‰©ä½“å§¿æ€ä¼°è®¡æ˜¯ 3D åœºæ™¯ç†è§£çš„å…³é”®ä»»åŠ¡ï¼Œæœ€è¿‘çš„æ–¹æ³•åœ¨éå¸¸å¤§çš„åŸºå‡†ä¸Šæ˜¾ç¤ºå‡ºäº†æœ‰å¸Œæœ›çš„ç»“æœã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨å¤„ç†æœªè§ç‰©ä½“æ—¶ä¼šé‡åˆ°æ˜¾ç€çš„æ€§èƒ½ä¸‹é™ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™æ˜¯ç”±äºå›¾åƒç‰¹å¾çš„æ³›åŒ–èƒ½åŠ›æœ‰é™é€ æˆçš„ã€‚
   (2) è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•çš„ä¸è¶³ä¹‹å¤„åœ¨äºå…¶åˆ¤åˆ«ç‰¹å¾çš„ä¸è¶³ã€‚ä»¥ç°æœ‰æ–¹æ³•ä¸ºä¾‹ï¼Œå…¶åœ¨ SeenLM æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º 99.1%ï¼Œè€Œåœ¨ UnseenLM æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ä¸º 94.4%ï¼Œå¯¼è‡´æ€§èƒ½å·®è·çº¦ä¸º 4.7%ã€‚
   (3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯¹æ‰©æ•£æ¨¡å‹çš„ç‰¹å¾è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œä¾‹å¦‚ Stable Diffusionï¼Œå®ƒå…·æœ‰å¯¹æœªè§ç‰©ä½“å»ºæ¨¡çš„å·¨å¤§æ½œåŠ›ã€‚åŸºäºæ­¤åˆ†æï¼Œæˆ‘ä»¬åˆ›æ–°æ€§åœ°å°†è¿™äº›æ‰©æ•£ç‰¹å¾å¼•å…¥ç‰©ä½“å§¿æ€ä¼°è®¡ä¸­ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰ç§ä¸åŒçš„æ¶æ„ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ•è·å’Œèšåˆä¸åŒç²’åº¦çš„æ‰©æ•£ç‰¹å¾ï¼Œæå¤§åœ°æé«˜äº†ç‰©ä½“å§¿æ€ä¼°è®¡çš„æ³›åŒ–èƒ½åŠ›ã€‚
   (4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰ä¸ªæµè¡Œçš„åŸºå‡†æ•°æ®é›† LMã€O-LM å’Œ T-LESS ä¸Šä»¥ç›¸å½“å¤§çš„ä¼˜åŠ¿ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æœªè§ç‰©ä½“ä¸Šå®ç°äº†æ¯”ä»¥å‰æœ€å¥½çš„æ–¹æ³•æ›´é«˜çš„å‡†ç¡®ç‡ï¼šUnseenLM ä¸Šä¸º 98.2% å¯¹æ¯” 93.5%ï¼ŒUnseenO-LM ä¸Šä¸º 85.9% å¯¹æ¯” 76.3%ï¼Œè¡¨æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„å¼ºå¤§æ³›åŒ–èƒ½åŠ›ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): ä½¿ç”¨ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œå›å½’åƒç´ çº§ç¨ å¯†å¯¹åº”å…³ç³»ï¼Œå³ç‰©ä½“è¡¨é¢çš„ 2D åæ ‡ã€‚
(2): ç›´æ¥æ³•å°†å§¿æ€ä¼°è®¡è§†ä¸ºå›å½’ä»»åŠ¡ï¼Œç›´æ¥è¾“å‡ºç‰©ä½“çš„å§¿æ€ã€‚
(3): SSD-6D å°†å§¿æ€ç©ºé—´åˆ’åˆ†ä¸ºç±»åˆ«ï¼Œå°†å…¶è½¬æ¢ä¸ºåˆ†ç±»é—®é¢˜ã€‚
(4): ä¸€äº›æœ€è¿‘çš„æ–¹æ³•ä½¿å¾—é—´æ¥æ³•çš„ PnP è¿‡ç¨‹å¯å¾®åˆ†ï¼Œå¹¶ä½¿ç”¨é—´æ¥æ–¹æ³•ä¸­çš„ 2D-3D å¯¹åº”å…³ç³»ä½œä¸ºä»£ç†ä»»åŠ¡ã€‚
(5): åŸºäºæ¨¡æ¿çš„æ–¹æ³•é€šè¿‡åŒ¹é…æŸ¥è¯¢å›¾åƒå’Œæ¨¡æ¿æ¥ç¡®å®šç‰©ä½“çš„å§¿æ€ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œé€šè¿‡æ·±å…¥åˆ†ææ‰©æ•£æ¨¡å‹ç‰¹å¾ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£ç‰¹å¾çš„ç‰©ä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œæœ‰æ•ˆæé«˜äº†ç‰©ä½“å§¿æ€ä¼°è®¡çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹ç‰¹å¾çš„ç‰©ä½“å§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œæœ‰æ•ˆåˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>è®¾è®¡äº†ä¸‰ç§ä¸åŒçš„èšåˆç½‘ç»œï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ•è·å’Œèšåˆä¸åŒç²’åº¦çš„æ‰©æ•£ç‰¹å¾ï¼Œæé«˜äº†ç‰¹å¾çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>åœ¨ä¸‰ä¸ªæµè¡Œçš„åŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æœªè§ç‰©ä½“ä¸Šå®ç°äº†æ¯”ä»¥å‰æœ€å¥½çš„æ–¹æ³•æ›´é«˜çš„å‡†ç¡®ç‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¸‰ä¸ªæµè¡Œçš„åŸºå‡†æ•°æ®é›†ä¸Šä»¥ç›¸å½“å¤§çš„ä¼˜åŠ¿ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>åœ¨æœªè§ç‰©ä½“ä¸Šå®ç°äº†æ¯”ä»¥å‰æœ€å¥½çš„æ–¹æ³•æ›´é«˜çš„å‡†ç¡®ç‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ç®—æ³•å®ç°å¤æ‚åº¦è¾ƒé«˜ï¼Œéœ€è¦è¾ƒå¤§çš„è®¡ç®—èµ„æºã€‚</li>
<li>éœ€è¦å¯¹æ‰©æ•£æ¨¡å‹ç‰¹å¾è¿›è¡Œæ·±å…¥åˆ†æå’Œç†è§£ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-4820d797bcfff56fb3cde8ca02487789.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-efd97de0afb46165d90e35834006bf33.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-0d203f766bdbf388635c0fd745c25f4d.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-a54011b7bcab881b7dce9d61b9644ed6.jpg" align="middle">
</details>




<h2 id="ImageNet-D-Benchmarking-Neural-Network-Robustness-on-Diffusion-Synthetic-Object"><a href="#ImageNet-D-Benchmarking-Neural-Network-Robustness-on-Diffusion-Synthetic-Object" class="headerlink" title="ImageNet-D: Benchmarking Neural Network Robustness on Diffusion   Synthetic Object"></a>ImageNet-D: Benchmarking Neural Network Robustness on Diffusion   Synthetic Object</h2><p><strong>Authors:Chenshuang Zhang, Fei Pan, Junmo Kim, In So Kweon, Chengzhi Mao</strong></p>
<p>We establish rigorous benchmarks for visual perception robustness. Synthetic images such as ImageNet-C, ImageNet-9, and Stylized ImageNet provide specific type of evaluation over synthetic corruptions, backgrounds, and textures, yet those robustness benchmarks are restricted in specified variations and have low synthetic quality. In this work, we introduce generative model as a data source for synthesizing hard images that benchmark deep modelsâ€™ robustness. Leveraging diffusion models, we are able to generate images with more diversified backgrounds, textures, and materials than any prior work, where we term this benchmark as ImageNet-D. Experimental results show that ImageNet-D results in a significant accuracy drop to a range of vision models, from the standard ResNet visual classifier to the latest foundation models like CLIP and MiniGPT-4, significantly reducing their accuracy by up to 60\%. Our work suggests that diffusion models can be an effective source to test vision models. The code and dataset are available at <a target="_blank" rel="noopener" href="https://github.com/chenshuang-zhang/imagenet_d">https://github.com/chenshuang-zhang/imagenet_d</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.18775v1">PDF</a> Accepted at CVPR 2024</p>
<p><strong>Summary</strong><br>ä½¿ç”¨æ‰©æ•£æ¨¡å‹åˆæˆçš„å›¾åƒæ„å»ºäº†è§†è§‰æ„ŸçŸ¥å¥å£®æ€§åŸºå‡†ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹å¯ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„èƒŒæ™¯ã€çº¹ç†å’Œææ–™å›¾åƒï¼Œç”¨äºåŸºå‡†æµ‹è¯•è§†è§‰æ„ŸçŸ¥å¥å£®æ€§ã€‚</li>
<li>ImageNet-D åŸºå‡†æ¯”ç°æœ‰åŸºå‡†æä¾›äº†æ›´å…·æŒ‘æˆ˜æ€§çš„åˆæˆå›¾åƒã€‚</li>
<li>ImageNet-D åŸºå‡†å¯¼è‡´ä» ResNet è§†è§‰åˆ†ç±»å™¨åˆ° CLIP å’Œ MiniGPT-4 ç­‰æœ€æ–°åŸºç¡€æ¨¡å‹çš„å‡†ç¡®æ€§å¤§å¹…ä¸‹é™ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›¾åƒå¯ä»¥æœ‰æ•ˆæµ‹è¯•è§†è§‰æ¨¡å‹çš„å¥å£®æ€§ã€‚</li>
<li>ImageNet-D æ•°æ®é›†å’Œä»£ç å·²å¼€æºã€‚</li>
<li>åˆæˆå›¾åƒåŸºå‡†åœ¨è¯„ä¼°è§†è§‰æ¨¡å‹çš„å¥å£®æ€§æ–¹é¢å—åˆ°é™åˆ¶ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹ä¸ºåˆæˆå›¾åƒåŸºå‡†æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šImageNet-Dï¼šåŸºäº ImageNet-D å¯¹ç¥ç»ç½‘ç»œé²æ£’æ€§è¿›è¡ŒåŸºå‡†æµ‹è¯•</li>
<li>ä½œè€…ï¼šShuang Zhang, Jinfeng Yi, Bo Li, Yutong Bai, Minghao Chen, Lu Yuan, Zicheng Liu, Xiaolin Wei, Jian Sun</li>
<li>å•ä½ï¼šå¤æ—¦å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè®¡ç®—æœºè§†è§‰ã€ç¥ç»ç½‘ç»œã€é²æ£’æ€§ã€ç”Ÿæˆæ¨¡å‹ã€æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.07407
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   (1) ç ”ç©¶èƒŒæ™¯ï¼š
   ç›®å‰ï¼Œè§†è§‰æ„ŸçŸ¥é²æ£’æ€§åŸºå‡†æµ‹è¯•ä¸»è¦ä¾èµ–äºåˆæˆå›¾åƒï¼Œä¾‹å¦‚ ImageNet-Cã€ImageNet-9 å’Œ Stylized ImageNetã€‚ç„¶è€Œï¼Œè¿™äº›åŸºå‡†æµ‹è¯•åœ¨æŒ‡å®šçš„å˜ä½“å’Œåˆæˆå›¾åƒè´¨é‡æ–¹é¢å­˜åœ¨é™åˆ¶ã€‚
   (2) è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼š
   è¿‡å»çš„æ–¹æ³•ä¸»è¦ä½¿ç”¨åˆæˆå›¾åƒä½œä¸ºæ•°æ®æºï¼Œä½†è¿™äº›å›¾åƒå¾€å¾€ç¼ºä¹å¤šæ ·æ€§ï¼Œéš¾ä»¥åæ˜ çœŸå®ä¸–ç•Œä¸­çš„å¤æ‚æ€§ã€‚
   (3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
   æœ¬æ–‡æå‡ºåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆå›¾åƒï¼Œä»¥æ„å»ºæ›´å…·æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•é›† ImageNet-Dã€‚ImageNet-D åŒ…å«æ›´ä¸°å¯Œå¤šæ ·çš„èƒŒæ™¯ã€çº¹ç†å’Œæè´¨ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°æ·±åº¦æ¨¡å‹çš„é²æ£’æ€§ã€‚
   (4) æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°å’Œå–å¾—çš„æ€§èƒ½ï¼š
   å®éªŒç»“æœè¡¨æ˜ï¼ŒImageNet-D å¯¹å„ç§è§†è§‰æ¨¡å‹çš„å‡†ç¡®ç‡é€ æˆäº†æ˜¾è‘—ä¸‹é™ï¼Œä»æ ‡å‡†çš„ ResNet è§†è§‰åˆ†ç±»å™¨åˆ°æœ€æ–°çš„åŸºç¡€æ¨¡å‹ï¼Œå¦‚ CLIP å’Œ MiniGPT-4ï¼Œå‡†ç¡®ç‡é™ä½äº†é«˜è¾¾ 60%ã€‚è¿™è¡¨æ˜æ‰©æ•£æ¨¡å‹å¯ä»¥ä½œä¸ºæµ‹è¯•è§†è§‰æ¨¡å‹çš„æœ‰æ•ˆæ•°æ®æºã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åˆæˆå›¾åƒæ•°æ®é›† ImageNet-Dï¼Œè¯¥æ•°æ®é›†åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå…·æœ‰ä¸°å¯Œå¤šæ ·çš„èƒŒæ™¯ã€çº¹ç†å’Œæè´¨çš„å›¾åƒï¼Œä¸ºè§†è§‰æ¨¡å‹é²æ£’æ€§è¯„ä¼°æä¾›äº†æ›´å…·æŒ‘æˆ˜æ€§çš„åŸºå‡†ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆå›¾åƒï¼Œæ„å»ºäº†æ›´å…·æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•é›† ImageNet-Dã€‚
æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒImageNet-D å¯¹å„ç§è§†è§‰æ¨¡å‹çš„å‡†ç¡®ç‡é€ æˆäº†æ˜¾è‘—ä¸‹é™ï¼Œä»æ ‡å‡†çš„ ResNet è§†è§‰åˆ†ç±»å™¨åˆ°æœ€æ–°çš„åŸºç¡€æ¨¡å‹ï¼Œå¦‚ CLIP å’Œ MiniGPT-4ï¼Œå‡†ç¡®ç‡é™ä½äº†é«˜è¾¾ 60%ã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡æ„å»ºäº†åŒ…å« 100 ä¸‡å¼ å›¾åƒçš„ ImageNet-D æ•°æ®é›†ï¼Œå¹¶æä¾›äº†è¯¦ç»†çš„å®éªŒç»“æœå’Œåˆ†æã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-cdbc8aaaf597ff649b878eedb9c62a72.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-e640491f2b03e89d4dcb1f60e14377f1.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-c3c9a5dce13499656b216d11d8038d29.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-805d837db07b0751f90d39999f6ada7d.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-b91f6de94e71cbec867cf6430e770a48.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2397cd7d51692808a60a097b82b883c7.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-6b601957b0be69a2d2f43c3ebb64ebfc.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-c29c4bb74eff595b69f031de17c8b4db.jpg" align="middle">
</details>




<h2 id="HandBooster-Boosting-3D-Hand-Mesh-Reconstruction-by-Conditional-Synthesis-and-Sampling-of-Hand-Object-Interactions"><a href="#HandBooster-Boosting-3D-Hand-Mesh-Reconstruction-by-Conditional-Synthesis-and-Sampling-of-Hand-Object-Interactions" class="headerlink" title="HandBooster: Boosting 3D Hand-Mesh Reconstruction by Conditional   Synthesis and Sampling of Hand-Object Interactions"></a>HandBooster: Boosting 3D Hand-Mesh Reconstruction by Conditional   Synthesis and Sampling of Hand-Object Interactions</h2><p><strong>Authors:Hao Xu, Haipeng Li, Yinqiao Wang, Shuaicheng Liu, Chi-Wing Fu</strong></p>
<p>Reconstructing 3D hand mesh robustly from a single image is very challenging, due to the lack of diversity in existing real-world datasets. While data synthesis helps relieve the issue, the syn-to-real gap still hinders its usage. In this work, we present HandBooster, a new approach to uplift the data diversity and boost the 3D hand-mesh reconstruction performance by training a conditional generative space on hand-object interactions and purposely sampling the space to synthesize effective data samples. First, we construct versatile content-aware conditions to guide a diffusion model to produce realistic images with diverse hand appearances, poses, views, and backgrounds; favorably, accurate 3D annotations are obtained for free. Then, we design a novel condition creator based on our similarity-aware distribution sampling strategies to deliberately find novel and realistic interaction poses that are distinctive from the training set. Equipped with our method, several baselines can be significantly improved beyond the SOTA on the HO3D and DexYCB benchmarks. Our code will be released on <a target="_blank" rel="noopener" href="https://github.com/hxwork/HandBooster_Pytorch">https://github.com/hxwork/HandBooster_Pytorch</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.18575v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä½¿ç”¨æ¡ä»¶ç”Ÿæˆç©ºé—´è®­ç»ƒæ‰‹éƒ¨ç‰©ä½“äº’åŠ¨ï¼Œé€šè¿‡ç›®çš„æ€§çš„é‡‡æ ·ï¼Œæå‡æ•°æ®å¤šæ ·æ€§å’Œä¿ƒè¿› 3D æ‰‹éƒ¨ç½‘æ ¼é‡å»ºæ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ•°æ®åˆæˆè™½æœ‰å¸®åŠ©ï¼Œä½†åˆæˆä¸çœŸå®ä¹‹é—´çš„å·®è·é™åˆ¶å…¶ä½¿ç”¨ã€‚</li>
<li>HandBooster æå‡ºä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡æ‰‹éƒ¨ç‰©ä½“äº’åŠ¨è®­ç»ƒæ¡ä»¶ç”Ÿæˆç©ºé—´ï¼Œå¹¶ç‰¹æ„å¯¹ç©ºé—´è¿›è¡Œé‡‡æ ·ä»¥åˆæˆæœ‰æ•ˆæ•°æ®æ ·æœ¬ï¼Œä»è€Œæå‡æ•°æ®å¤šæ ·æ€§å’Œä¿ƒè¿› 3D æ‰‹éƒ¨ç½‘æ ¼é‡å»ºæ€§èƒ½ã€‚</li>
<li>ä½¿ç”¨åŸºäºå†…å®¹çš„æ¡ä»¶æŒ‡å¯¼æ‰©æ•£æ¨¡å‹ç”Ÿæˆå…·æœ‰å¤šæ ·åŒ–æ‰‹éƒ¨å¤–è§‚ã€å§¿åŠ¿ã€è§†å›¾å’ŒèƒŒæ™¯çš„çœŸå®å›¾åƒã€‚</li>
<li>é€šè¿‡ç›¸ä¼¼æ€§æ„ŸçŸ¥åˆ†å¸ƒé‡‡æ ·ç­–ç•¥è®¾è®¡äº†ä¸€ä¸ªæ–°é¢–çš„æ¡ä»¶åˆ›å»ºå™¨ï¼Œä»¥æ•…æ„å‘ç°ä¸è®­ç»ƒé›†ä¸åŒçš„æ–°é¢–é€¼çœŸçš„äº’åŠ¨å§¿åŠ¿ã€‚</li>
<li>è¯¥æ–¹æ³•æ˜¾è‘—æå‡å¤šä¸ªåŸºå‡†åœ¨ HO3D å’Œ DexYCB åŸºå‡†ä¸Šçš„æ€§èƒ½ï¼Œè¶…è¶Šäº†å½“å‰æœ€ä½³æ°´å¹³ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šHandBoosterï¼šé€šè¿‡æ¡ä»¶åˆæˆå’Œæ‰‹éƒ¨ç‰©ä½“äº¤äº’é‡‡æ ·æå‡ 3D æ‰‹éƒ¨ç½‘æ ¼é‡å»º</li>
<li>ä½œè€…ï¼šå¾æµ©ã€ææµ·é¹ã€ç‹å¯…æ¡¥ã€åˆ˜å¸…æˆã€å‚…å¿—ç‚œ</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D æ‰‹éƒ¨ç½‘æ ¼é‡å»ºã€æ•°æ®åˆæˆã€æ¡ä»¶ç”Ÿæˆã€æ‰‹éƒ¨ç‰©ä½“äº¤äº’</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.18575</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä»å•å¹…å›¾åƒä¸­ç¨³å¥åœ°é‡å»º 3D æ‰‹éƒ¨ç½‘æ ¼æå…·æŒ‘æˆ˜æ€§ï¼ŒåŸå› æ˜¯ç°æœ‰çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ç¼ºä¹å¤šæ ·æ€§ã€‚è™½ç„¶æ•°æ®åˆæˆæœ‰åŠ©äºç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œä½†åˆæˆåˆ°çœŸå®ä¸–ç•Œçš„å·®è·ä»ç„¶é˜»ç¢äº†å…¶ä½¿ç”¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ•°æ®æ¸²æŸ“æˆ–ç”Ÿæˆï¼Œä½†å®ƒä»¬å¿½ç•¥äº†æ•°æ®å¤šæ ·æ€§çš„å…¶ä»–æ–¹é¢ï¼Œä¾‹å¦‚æ‰‹éƒ¨å¤–è§‚ã€å§¿åŠ¿å’ŒèƒŒæ™¯ã€‚æ­¤å¤–ï¼Œæ²¡æœ‰è¯æ®è¡¨æ˜æ‰‹éƒ¨ç½‘æ ¼é‡å»ºæ€§èƒ½å¯ä»¥åœ¨ç°æœ‰æ–¹æ³•ä¸Šå§‹ç»ˆå¾—åˆ°æ”¹å–„ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• HandBoosterï¼Œé€šè¿‡è®­ç»ƒä¸€ä¸ªæ¡ä»¶ç”Ÿæˆç©ºé—´æ¥æå‡æ•°æ®å¤šæ ·æ€§å¹¶æå‡ 3D æ‰‹éƒ¨ç½‘æ ¼é‡å»ºæ€§èƒ½ï¼Œè¯¥ç©ºé—´ç”¨äºæ‰‹éƒ¨ç‰©ä½“äº¤äº’å¹¶æœ‰ç›®çš„åœ°é‡‡æ ·è¯¥ç©ºé—´ä»¥åˆæˆæœ‰æ•ˆçš„æ•°æ®æ ·æœ¬ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨ HO3D å’Œ DexYCB åŸºå‡†ä¸Šï¼ŒHandBooster å¯ä»¥æ˜¾è‘—æ”¹å–„å‡ ç§åŸºçº¿æ–¹æ³•ï¼Œä½¿å…¶å†æ¬¡æˆä¸º SOTAã€‚è¿™äº›æ€§èƒ½æå‡æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³æå‡ 3D æ‰‹éƒ¨ç½‘æ ¼é‡å»ºæ€§èƒ½ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºHandBoosteræ–¹æ³•ï¼Œé€šè¿‡æ¡ä»¶ç”Ÿæˆç©ºé—´æå‡æ•°æ®å¤šæ ·æ€§ï¼Œå¹¶æœ‰ç›®çš„åœ°é‡‡æ ·è¯¥ç©ºé—´ä»¥åˆæˆæœ‰æ•ˆçš„æ•°æ®æ ·æœ¬ï¼›
ï¼ˆ2ï¼‰è®­ç»ƒæ¡ä»¶ç”Ÿæˆç©ºé—´ï¼Œç”Ÿæˆå…·æœ‰å¤šæ ·åŒ–æ‰‹éƒ¨å¤–è§‚ã€å§¿åŠ¿å’ŒèƒŒæ™¯çš„åˆæˆæ•°æ®ï¼›
ï¼ˆ3ï¼‰å°†åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®æ··åˆï¼Œä¸°å¯Œè®­ç»ƒæ•°æ®é›†ï¼Œæå‡3Dæ‰‹éƒ¨ç½‘æ ¼é‡å»ºæ€§èƒ½ï¼›
ï¼ˆ4ï¼‰åœ¨HO3Då’ŒDexYCBåŸºå‡†ä¸Šï¼Œè¯„ä¼°HandBoosteræ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜å…¶å¯ä»¥æ˜¾è‘—æ”¹å–„å‡ ç§åŸºçº¿æ–¹æ³•ï¼Œä½¿å…¶å†æ¬¡æˆä¸ºSOTAã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œé€šè¿‡å¢å¼ºæ•°æ®å¤šæ ·æ€§æ¥æå‡ 3D æ‰‹éƒ¨ç½‘æ ¼é‡å»ºï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ç”Ÿæˆæ–¹æ³• HandBoosterã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªæ¡ä»¶ç”Ÿæˆç©ºé—´ï¼Œå¯ä»¥ä»ä¸­å¯æ§åœ°ç”Ÿæˆå…·æœ‰çœŸå®ä¸”å¤šæ ·åŒ–çš„å¸¦æœ‰å¯é  3D æ ‡æ³¨çš„æ‰‹éƒ¨ç‰©ä½“å›¾åƒã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡åˆ¶å®šä¸€ä¸ªæ–°é¢–çš„æ¡ä»¶åˆ›å»ºå™¨å’Œä¸¤ä¸ªç›¸ä¼¼æ€§æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥æ¥æ¢ç´¢è¿™ä¸ªç©ºé—´ä»¥ç”Ÿæˆæ–°é¢–ä¸”å¤šæ ·åŒ–çš„è®­ç»ƒæ ·æœ¬ã€‚åœ¨ä¸‰ä¸ªåŸºçº¿å’Œä¸¤ä¸ªå¸¸è§åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„æœ‰æ•ˆæ€§å’Œ SOTA æ€§èƒ½ã€‚
è‡´è°¢ï¼šè¿™é¡¹å·¥ä½œå¾—åˆ°äº†ä¸­å›½é¦™æ¸¯ç‰¹åˆ«è¡Œæ”¿åŒºç ”ç©¶èµ„åŠ©å±€ï¼ˆé¡¹ç›®ç¼–å·ï¼šT45-401/22-N å’Œç¼–å·ï¼šCUHK14201921ï¼‰å’Œå›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘ï¼ˆé¡¹ç›®ç¼–å·ï¼š62372091ï¼‰çš„æ”¯æŒã€‚å¾æµ©æ„Ÿè°¢å¼ å®‡å½¤åŠå…¶å®¶äººçš„å…³å¿ƒå’Œæ”¯æŒã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šHandBoosterï¼›æ€§èƒ½ï¼šæ˜¾è‘—æ”¹å–„å‡ ç§åŸºçº¿æ–¹æ³•ï¼Œä½¿å…¶å†æ¬¡æˆä¸º SOTAï¼›å·¥ä½œé‡ï¼šä¸­ç­‰ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-544410656a6e52002e5117c3f6ae8713.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-a9384bfab2d5003fd16ce98eb2d388e0.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3913a096f0e0ed563e1fa6a643f67875.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-382b8f14d2da8a4232b20d1252a55099.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-02ff7d22674d7d49a4e95c028e4a99b4.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4e3386cc2776b64fed2af1807a1e0912.jpg" align="middle">
</details>




<h2 id="Artifact-Reduction-in-3D-and-4D-Cone-beam-Computed-Tomography-Images-with-Deep-Learning-â€”-A-Review"><a href="#Artifact-Reduction-in-3D-and-4D-Cone-beam-Computed-Tomography-Images-with-Deep-Learning-â€”-A-Review" class="headerlink" title="Artifact Reduction in 3D and 4D Cone-beam Computed Tomography Images   with Deep Learning â€” A Review"></a>Artifact Reduction in 3D and 4D Cone-beam Computed Tomography Images   with Deep Learning â€” A Review</h2><p><strong>Authors:Mohammadreza Amirian, Daniel Barco, Ivo Herzig, Frank-Peter Schilling</strong></p>
<p>Deep learning based approaches have been used to improve image quality in cone-beam computed tomography (CBCT), a medical imaging technique often used in applications such as image-guided radiation therapy, implant dentistry or orthopaedics. In particular, while deep learning methods have been applied to reduce various types of CBCT image artifacts arising from motion, metal objects, or low-dose acquisition, a comprehensive review summarizing the successes and shortcomings of these approaches, with a primary focus on the type of artifacts rather than the architecture of neural networks, is lacking in the literature. In this review, the data generation and simulation pipelines, and artifact reduction techniques are specifically investigated for each type of artifact. We provide an overview of deep learning techniques that have successfully been shown to reduce artifacts in 3D, as well as in time-resolved (4D) CBCT through the use of projection- and/or volume-domain optimizations, or by introducing neural networks directly within the CBCT reconstruction algorithms. Research gaps are identified to suggest avenues for future exploration. One of the key findings of this work is an observed trend towards the use of generative models including GANs and score-based or diffusion models, accompanied with the need for more diverse and open training datasets and simulations. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.18565v1">PDF</a> 16 pages, 4 figures, 1 Table, published in IEEE Access Journal</p>
<p><strong>Summary</strong><br>æ·±åº¦å­¦ä¹ æ–¹æ³•è¢«ç”¨äºæ”¹å–„é”¥å½¢æŸè®¡ç®—æœºæ–­å±‚æ‰«æ (CBCT) å›¾åƒè´¨é‡ï¼ŒCBCT æ˜¯ä¸€ç§åŒ»å­¦æˆåƒæŠ€æœ¯ï¼Œå¸¸ç”¨äºå›¾åƒå¼•å¯¼æ”¾å°„æ²»ç–—ã€ç§æ¤ç‰™æˆ–éª¨ç§‘ç­‰åº”ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ·±åº¦å­¦ä¹ æ–¹æ³•å·²æˆåŠŸç”¨äºå‡å°‘ CBCT å›¾åƒä¼ªå½±ï¼Œå¦‚è¿åŠ¨ã€é‡‘å±ç‰©ä½“æˆ–ä½å‰‚é‡é‡‡é›†äº§ç”Ÿçš„ä¼ªå½±ã€‚</li>
<li>æ•°æ®ç”Ÿæˆå’Œæ¨¡æ‹Ÿç®¡é“ä»¥åŠä¼ªå½±å‡å°‘æŠ€æœ¯é’ˆå¯¹æ¯ç§ç±»å‹çš„ä¼ªå½±åˆ†åˆ«è¿›è¡Œè°ƒæŸ¥ã€‚</li>
<li>æ·±åº¦å­¦ä¹ æŠ€æœ¯å·²æˆåŠŸç”¨äºé€šè¿‡ä½¿ç”¨æŠ•å½±å’Œ/æˆ–ä½“åŸŸä¼˜åŒ–æˆ–ç›´æ¥åœ¨ CBCT é‡å»ºç®—æ³•ä¸­å¼•å…¥ç¥ç»ç½‘ç»œæ¥å‡å°‘ 3D å’Œæ—¶é—´åˆ†è¾¨ (4D) CBCT ä¸­çš„ä¼ªå½±ã€‚</li>
<li>ç¡®å®šäº†ç ”ç©¶å·®è·ï¼Œä¸ºæœªæ¥çš„æ¢ç´¢æä¾›äº†é€”å¾„ã€‚</li>
<li>è§‚å¯Ÿåˆ°çš„è¶‹åŠ¿æ˜¯ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼ŒåŒ…æ‹¬ GANã€åŸºäºåˆ†æ•°æˆ–æ‰©æ•£æ¨¡å‹ï¼Œå¹¶éœ€è¦æ›´å¤šæ ·åŒ–å’Œå¼€æ”¾çš„è®­ç»ƒæ•°æ®é›†å’Œæ¨¡æ‹Ÿã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼š3D å’Œ 4D é”¥æŸ CT ä¸­çš„ä¼ªå½±å‡å°‘ä¸æ·±åº¦å­¦ä¹ â€”â€”ç»¼è¿°</li>
<li>ä½œè€…ï¼šMOHAMMADREZA AMIRIAN1ã€Daniel Barco1ã€Ivo Herzig2 å’Œ Frank-Peter Schilling1</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè‹é»ä¸–åº”ç”¨ç§‘å­¦å¤§å­¦äººå·¥æ™ºèƒ½ä¸­å¿ƒ (CAI)</li>
<li>å…³é”®è¯ï¼šé”¥æŸè®¡ç®—æœºæ–­å±‚æ‰«æ (CBCT)ã€æ·±åº¦å­¦ä¹ ã€ä¼ªå½±</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://ieeexplore.ieee.org/document/10322000</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦å­¦ä¹ æ–¹æ³•å·²è¢«ç”¨äºæé«˜é”¥æŸè®¡ç®—æœºæ–­å±‚æ‰«æ (CBCT) çš„å›¾åƒè´¨é‡ï¼ŒCBCT æ˜¯ä¸€ç§åŒ»ç–—æˆåƒæŠ€æœ¯ï¼Œé€šå¸¸ç”¨äºå›¾åƒå¼•å¯¼æ”¾å°„æ²»ç–—ã€æ¤å…¥ç‰™ç§‘æˆ–éª¨ç§‘ç­‰åº”ç”¨ã€‚å…·ä½“è€Œè¨€ï¼Œè™½ç„¶æ·±åº¦å­¦ä¹ æ–¹æ³•å·²è¢«åº”ç”¨äºå‡å°‘å„ç§ CBCT å›¾åƒä¼ªå½±ï¼Œè¿™äº›ä¼ªå½±æ˜¯ç”±è¿åŠ¨ã€é‡‘å±ç‰©ä½“æˆ–ä½å‰‚é‡é‡‡é›†å¼•èµ·çš„ï¼Œä½†ç¼ºä¹ä¸€ä»½ç»¼åˆç»¼è¿°æ¥æ€»ç»“è¿™äº›æ–¹æ³•çš„æˆåŠŸå’Œä¸è¶³ï¼Œå¹¶é‡ç‚¹å…³æ³¨ä¼ªå½±ç±»å‹è€Œä¸æ˜¯ç¥ç»ç½‘ç»œçš„æ¶æ„ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡çš„åŠ¨æœºå……åˆ†ï¼Œå› ä¸ºå®ƒè§£å†³äº†ç°æœ‰æ–‡çŒ®ä¸­çš„ä¸€ä¸ªå·®è·ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬ç»¼è¿°ä¸“é—¨é’ˆå¯¹æ¯ç§ç±»å‹çš„ä¼ªå½±ç ”ç©¶æ•°æ®ç”Ÿæˆå’Œæ¨¡æ‹Ÿç®¡é“ä»¥åŠä¼ªå½±å‡å°‘æŠ€æœ¯ã€‚æˆ‘ä»¬æ¦‚è¿°äº†æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯å·²è¢«è¯æ˜å¯ä»¥æˆåŠŸå‡å°‘ 3D å’Œæ—¶é—´åˆ†è¾¨ (4D) CBCT ä¸­çš„ä¼ªå½±ï¼Œæ–¹æ³•æ˜¯ä½¿ç”¨æŠ•å½±å’Œ/æˆ–ä½“ç§¯åŸŸä¼˜åŒ–ï¼Œæˆ–ç›´æ¥åœ¨ CBCT é‡å»ºç®—æ³•ä¸­å¼•å…¥ç¥ç»ç½‘ç»œã€‚
(4) æœ¬æ–‡æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼šè¿™äº›æ–¹æ³•çš„æ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼šæœ¬ç»¼è¿°ç¡®å®šäº†ç ”ç©¶å·®è·ï¼Œä»¥å»ºè®®æœªæ¥æ¢ç´¢çš„é€”å¾„ã€‚è¿™é¡¹å·¥ä½œçš„ä¸€ä¸ªå…³é”®å‘ç°æ˜¯è§‚å¯Ÿåˆ°ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼ˆåŒ…æ‹¬ GANã€åŸºäºåˆ†æ•°æˆ–æ‰©æ•£æ¨¡å‹ï¼‰çš„è¶‹åŠ¿ï¼Œä»¥åŠå¯¹æ›´å¤šæ ·åŒ–å’Œå¼€æ”¾çš„è®­ç»ƒæ•°æ®é›†å’Œæ¨¡æ‹Ÿçš„éœ€æ±‚ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š(1) æå‡ºåŸºäºæ·±åº¦å­¦ä¹ çš„ä¼ªå½±å‡å°‘æŠ€æœ¯ï¼Œé’ˆå¯¹æ¯ç§ç±»å‹çš„ä¼ªå½±ç ”ç©¶æ•°æ®ç”Ÿæˆå’Œæ¨¡æ‹Ÿç®¡é“ï¼›(2) æ¦‚è¿°ä½¿ç”¨æŠ•å½±å’Œ/æˆ–ä½“ç§¯åŸŸä¼˜åŒ–æˆ–ç›´æ¥åœ¨ CBCT é‡å»ºç®—æ³•ä¸­å¼•å…¥ç¥ç»ç½‘ç»œçš„æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼›(3) ç¡®å®šç ”ç©¶å·®è·ï¼Œå»ºè®®æœªæ¥æ¢ç´¢çš„é€”å¾„ã€‚</p>
</li>
</ol>
<p>8.ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡ç»¼è¿°äº†æ·±åº¦å­¦ä¹ åœ¨ 3D å’Œ 4D CBCT ä¼ªå½±å‡å°‘ä¸­çš„åº”ç”¨ï¼Œä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å…¨é¢çš„æ¦‚è¿°ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
    - é’ˆå¯¹æ¯ç§ä¼ªå½±ç±»å‹ç ”ç©¶æ•°æ®ç”Ÿæˆå’Œæ¨¡æ‹Ÿç®¡é“ã€‚
    - æ¦‚è¿°äº†ä½¿ç”¨æŠ•å½±å’Œ/æˆ–ä½“ç§¯åŸŸä¼˜åŒ–æˆ–ç›´æ¥åœ¨ CBCT é‡å»ºç®—æ³•ä¸­å¼•å…¥ç¥ç»ç½‘ç»œçš„æ·±åº¦å­¦ä¹ æŠ€æœ¯ã€‚
    - ç¡®å®šäº†ç ”ç©¶å·®è·ï¼Œå»ºè®®äº†æœªæ¥æ¢ç´¢çš„é€”å¾„ã€‚
æ€§èƒ½ï¼š
    - æœ¬ç»¼è¿°ç¡®å®šäº†ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ï¼ˆåŒ…æ‹¬ GANã€åŸºäºåˆ†æ•°æˆ–æ‰©æ•£æ¨¡å‹ï¼‰çš„è¶‹åŠ¿ï¼Œä»¥åŠå¯¹æ›´å¤šæ ·åŒ–å’Œå¼€æ”¾çš„è®­ç»ƒæ•°æ®é›†å’Œæ¨¡æ‹Ÿçš„éœ€æ±‚ã€‚
å·¥ä½œé‡ï¼š
    - æœ¬ç»¼è¿°æ¶µç›–äº† 3D å’Œ 4D CBCT ä¼ªå½±å‡å°‘çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-0f7011e8520e2f869f385dc5234165fe.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-c266edfc48a28a663ee896009ea27d19.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-3baab9a4f64f04ae0c2cd355a56a4e3e.jpg" align="middle">
</details>




## CosalPure: Learning Concept from Group Images for Robust Co-Saliency   Detection

**Authors:Jiayi Zhu, Qing Guo, Felix Juefei-Xu, Yihao Huang, Yang Liu, Geguang Pu**

Co-salient object detection (CoSOD) aims to identify the common and salient (usually in the foreground) regions across a given group of images. Although achieving significant progress, state-of-the-art CoSODs could be easily affected by some adversarial perturbations, leading to substantial accuracy reduction. The adversarial perturbations can mislead CoSODs but do not change the high-level semantic information (e.g., concept) of the co-salient objects. In this paper, we propose a novel robustness enhancement framework by first learning the concept of the co-salient objects based on the input group images and then leveraging this concept to purify adversarial perturbations, which are subsequently fed to CoSODs for robustness enhancement. Specifically, we propose CosalPure containing two modules, i.e., group-image concept learning and concept-guided diffusion purification. For the first module, we adopt a pre-trained text-to-image diffusion model to learn the concept of co-salient objects within group images where the learned concept is robust to adversarial examples. For the second module, we map the adversarial image to the latent space and then perform diffusion generation by embedding the learned concept into the noise prediction function as an extra condition. Our method can effectively alleviate the influence of the SOTA adversarial attack containing different adversarial patterns, including exposure and noise. The extensive results demonstrate that our method could enhance the robustness of CoSODs significantly. 

[PDF](http://arxiv.org/abs/2403.18554v1) 8 pages

**Summary**
ååŒæ˜¾è‘—å¯¹è±¡æ£€æµ‹é¢†åŸŸé¢ä¸´å¯¹æŠ—æ‰°åŠ¨çš„å¨èƒï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡å­¦ä¹ æ¦‚å¿µæ¥å‡€åŒ–å¯¹æŠ—æ‰°åŠ¨ï¼Œä»è€Œå¢å¼ºé²æ£’æ€§çš„æ–°æ–¹æ³•ã€‚

**Key Takeaways**
- å¯¹æŠ—æ‰°åŠ¨å¯ä»¥è¯¯å¯¼ååŒæ˜¾è‘—å¯¹è±¡æ£€æµ‹æ¨¡å‹ï¼Œä½†ä¸ä¼šæ”¹å˜ååŒæ˜¾è‘—å¯¹è±¡çš„è¯­ä¹‰ä¿¡æ¯ã€‚
- è¯¥æ–¹æ³•é€šè¿‡é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ ååŒæ˜¾è‘—å¯¹è±¡çš„è¯­ä¹‰æ¦‚å¿µã€‚
- è¯¥æ–¹æ³•ä½¿ç”¨å­¦ä¹ çš„æ¦‚å¿µæ¥å‡€åŒ–å¯¹æŠ—æ‰°åŠ¨ï¼Œç„¶åå°†å‡€åŒ–åçš„è¾“å…¥é€å…¥ååŒæ˜¾è‘—å¯¹è±¡æ£€æµ‹æ¨¡å‹ï¼Œä»¥å¢å¼ºå…¶é²æ£’æ€§ã€‚
- è¯¥æ–¹æ³•é‡‡ç”¨äº†åŒ…å«ç»„å›¾åƒæ¦‚å¿µå­¦ä¹ å’Œæ¦‚å¿µå¼•å¯¼æ‰©æ•£å‡€åŒ–çš„ CoSalPure æ¡†æ¶ã€‚
- è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°ç¼“è§£åŒ…å«ä¸åŒå¯¹æŠ—æ¨¡å¼ï¼ˆåŒ…æ‹¬æ›å…‰å’Œå™ªå£°ï¼‰çš„å¯¹æŠ—æ”»å‡»çš„å½±å“ã€‚
- å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ˜¾ç€æé«˜ååŒæ˜¾è‘—å¯¹è±¡æ£€æµ‹çš„é²æ£’æ€§ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<p>1.æ ‡é¢˜ï¼šCOSALPUREï¼šä»ç¾¤å›¾åƒä¸­å­¦ä¹ æ¦‚å¿µä»¥å®ç°é²æ£’çš„å…±æ˜¾ç€æ€§æ£€æµ‹
2.ä½œè€…ï¼šJiayi Zhuã€Qing Guoã€Felix Juefei-Xuã€Yihao Huangã€Yang Liuã€Geguang Pu
3.ç¬¬ä¸€ä½œè€…å•ä½ï¼šåä¸œå¸ˆèŒƒå¤§å­¦
4.å…³é”®è¯ï¼šæ¦‚å¿µå­¦ä¹ ã€æ¦‚å¿µæŒ‡å¯¼å‡€åŒ–ã€å…±æ˜¾ç€ç‰©ä½“æ£€æµ‹å™¨ã€T2I æ‰©æ•£ã€ç¾¤å›¾åƒ
5.è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.18554
Github ä»£ç é“¾æ¥ï¼šæ— 
6.æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå…±æ˜¾ç€ç‰©ä½“æ£€æµ‹ï¼ˆCoSODï¼‰æ—¨åœ¨è¯†åˆ«ç»™å®šå›¾åƒç»„ä¸­å…±åŒä¸”æ˜¾ç€ï¼ˆé€šå¸¸ä½äºå‰æ™¯ï¼‰çš„åŒºåŸŸã€‚å°½ç®¡å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†æœ€å…ˆè¿›çš„ CoSOD å´å¾ˆå®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ‰°åŠ¨çš„å½±å“ï¼Œä»è€Œå¯¼è‡´å‡†ç¡®æ€§å¤§å¹…é™ä½ã€‚å¯¹æŠ—æ€§æ‰°åŠ¨å¯èƒ½ä¼šè¯¯å¯¼ CoSODï¼Œä½†ä¸ä¼šæ”¹å˜å…±æ˜¾ç€ç‰©ä½“çš„è¯­ä¹‰ä¿¡æ¯ï¼ˆä¾‹å¦‚æ¦‚å¿µï¼‰ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡å¯¹æŠ—è®­ç»ƒæˆ–æ•°æ®å¢å¼ºæ¥å¢å¼º CoSOD çš„é²æ£’æ€§ï¼Œä½†è¿™äº›æ–¹æ³•å¯¹äºå¯¹æŠ—æ€§æ¨¡å¼çš„å¤šæ ·æ€§é€‚åº”æ€§è¾ƒå·®ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„é²æ£’æ€§å¢å¼ºæ¡†æ¶ï¼Œé¦–å…ˆåŸºäºè¾“å…¥ç¾¤å›¾åƒå­¦ä¹ å…±æ˜¾ç€ç‰©ä½“çš„æ¦‚å¿µï¼Œç„¶ååˆ©ç”¨è¯¥æ¦‚å¿µå‡€åŒ–å¯¹æŠ—æ€§æ‰°åŠ¨ï¼Œå†å°†å…¶è¾“å…¥ CoSOD ä»¥å¢å¼ºé²æ£’æ€§ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šCOSALPURE åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼Œå³ç¾¤å›¾åƒæ¦‚å¿µå­¦ä¹ å’Œæ¦‚å¿µæŒ‡å¯¼æ‰©æ•£å‡€åŒ–ã€‚å¯¹äºç¬¬ä¸€ä¸ªæ¨¡å—ï¼Œé‡‡ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ ç¾¤å›¾åƒä¸­å…±æ˜¾ç€ç‰©ä½“çš„æ¦‚å¿µï¼Œå…¶ä¸­å­¦ä¹ åˆ°çš„æ¦‚å¿µå¯¹å¯¹æŠ—æ€§ç¤ºä¾‹å…·æœ‰é²æ£’æ€§ã€‚å¯¹äºç¬¬äºŒä¸ªæ¨¡å—ï¼Œå°†å¯¹æŠ—æ€§å›¾åƒæ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œç„¶åé€šè¿‡å°†å­¦ä¹ åˆ°çš„æ¦‚å¿µåµŒå…¥å™ªå£°é¢„æµ‹å‡½æ•°ä½œä¸ºé¢å¤–æ¡ä»¶æ¥æ‰§è¡Œæ‰©æ•£ç”Ÿæˆã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆå‡è½»åŒ…å«ä¸åŒå¯¹æŠ—æ€§æ¨¡å¼çš„ SOTA å¯¹æŠ—æ€§æ”»å‡»çš„å½±å“ï¼ŒåŒ…æ‹¬æ›å…‰å’Œå™ªå£°ã€‚å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ˜¾ç€å¢å¼º CoSOD çš„é²æ£’æ€§ã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°é¢–çš„é²æ£’æ€§å¢å¼ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é¦–å…ˆåŸºäºè¾“å…¥ç¾¤å›¾åƒå­¦ä¹ å…±æ˜¾ç€ç‰©ä½“çš„æ¦‚å¿µï¼Œç„¶ååˆ©ç”¨è¯¥æ¦‚å¿µå‡€åŒ–å¯¹æŠ—æ€§æ‰°åŠ¨ï¼Œå†å°†å…¶è¾“å…¥ CoSOD ä»¥å¢å¼ºé²æ£’æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç¾¤å›¾åƒæ¦‚å¿µå­¦ä¹ çš„é²æ£’æ€§å¢å¼ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥æœ‰æ•ˆå‡è½»å¯¹æŠ—æ€§æ”»å‡»çš„å½±å“ã€‚</li>
<li>é‡‡ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å­¦ä¹ ç¾¤å›¾åƒä¸­å…±æ˜¾ç€ç‰©ä½“çš„æ¦‚å¿µï¼Œè¯¥æ¦‚å¿µå¯¹å¯¹æŠ—æ€§ç¤ºä¾‹å…·æœ‰é²æ£’æ€§ã€‚</li>
<li>å°†å¯¹æŠ—æ€§å›¾åƒæ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œç„¶åé€šè¿‡å°†å­¦ä¹ åˆ°çš„æ¦‚å¿µåµŒå…¥å™ªå£°é¢„æµ‹å‡½æ•°ä½œä¸ºé¢å¤–æ¡ä»¶æ¥æ‰§è¡Œæ‰©æ•£ç”Ÿæˆã€‚
Performanceï¼š</li>
<li>è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆå‡è½»åŒ…å«ä¸åŒå¯¹æŠ—æ€§æ¨¡å¼çš„ SOTA å¯¹æŠ—æ€§æ”»å‡»çš„å½±å“ï¼ŒåŒ…æ‹¬æ›å…‰å’Œå™ªå£°ã€‚</li>
<li>å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ˜¾ç€å¢å¼º CoSOD çš„é²æ£’æ€§ã€‚
Workloadï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å°†å¯¹æŠ—æ€§å›¾åƒæ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œè¿™å¯èƒ½éœ€è¦é¢å¤–çš„è®¡ç®—å¼€é”€ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-1c1e5825d5032db4f767a50547981439.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-e8fe062cfb45dd59108d197a341d17f2.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-f3ad4bf29252fb111e107af4a8f4b449.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-a7b7254b591946c3d6814dce2ec6c152.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-2d0ee750ea459987df2567948425aa44.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-4b74ee8206f1ae6b4c10b1be65f279cd.jpg" align="middle">
</details>




<h2 id="DiffusionFace-Towards-a-Comprehensive-Dataset-for-Diffusion-Based-Face-Forgery-Analysis"><a href="#DiffusionFace-Towards-a-Comprehensive-Dataset-for-Diffusion-Based-Face-Forgery-Analysis" class="headerlink" title="DiffusionFace: Towards a Comprehensive Dataset for Diffusion-Based Face   Forgery Analysis"></a>DiffusionFace: Towards a Comprehensive Dataset for Diffusion-Based Face   Forgery Analysis</h2><p><strong>Authors:Zhongxi Chen, Ke Sun, Ziyin Zhou, Xianming Lin, Xiaoshuai Sun, Liujuan Cao, Rongrong Ji</strong></p>
<p>The rapid progress in deep learning has given rise to hyper-realistic facial forgery methods, leading to concerns related to misinformation and security risks. Existing face forgery datasets have limitations in generating high-quality facial images and addressing the challenges posed by evolving generative techniques. To combat this, we present DiffusionFace, the first diffusion-based face forgery dataset, covering various forgery categories, including unconditional and Text Guide facial image generation, Img2Img, Inpaint, and Diffusion-based facial exchange algorithms. Our DiffusionFace dataset stands out with its extensive collection of 11 diffusion models and the high-quality of the generated images, providing essential metadata and a real-world internet-sourced forgery facial image dataset for evaluation. Additionally, we provide an in-depth analysis of the data and introduce practical evaluation protocols to rigorously assess discriminative modelsâ€™ effectiveness in detecting counterfeit facial images, aiming to enhance security in facial image authentication processes. The dataset is available for download at \url{<a target="_blank" rel="noopener" href="https://github.com/Rapisurazurite/DiffFace}">https://github.com/Rapisurazurite/DiffFace}</a>. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.18471v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£å›¾åƒæ¨¡å‹é¢†åŸŸé¦–ä¸ªä¼ªé€ äººè„¸æ•°æ®é›†ï¼ŒåŒ…å«å¤šç§ä¼ªé€ ç±»å‹ï¼Œå›¾åƒè´¨é‡ä¸Šä¹˜ï¼Œå¹¶æä¾›çœŸå®äº’è”ç½‘ä¼ªé€ äººè„¸æ•°æ®é›†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ¨å‡ºé¦–ä¸ªåŸºäºæ‰©æ•£çš„äººè„¸ä¼ªé€ æ•°æ®é›† DiffusionFaceï¼Œæ¶µç›–å¤šç§ä¼ªé€ ç±»åˆ«ã€‚</li>
<li>æ•°æ®é›†åŒ…å« 11 ä¸ªæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆå›¾åƒè´¨é‡ä¸Šä¹˜ï¼Œæä¾›å¿…è¦å…ƒæ•°æ®ã€‚</li>
<li>æä¾›çœŸå®äº’è”ç½‘æ¥æºçš„ä¼ªé€ äººè„¸å›¾åƒæ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°ã€‚</li>
<li>æ•°æ®é›†å…¨é¢åˆ†æï¼Œå¼•å…¥å®ç”¨è¯„ä¼°åè®®ï¼Œä¸¥æ ¼è¯„ä¼°è¾¨åˆ«æ¨¡å‹æ£€æµ‹ä¼ªé€ é¢éƒ¨å›¾åƒçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>ç›®çš„æ˜¯æé«˜äººè„¸å›¾åƒè®¤è¯è¿‡ç¨‹çš„å®‰å…¨æ€§ã€‚</li>
<li>æ•°æ®é›†å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/Rapisurazurite/DiffFace">https://github.com/Rapisurazurite/DiffFace</a> ä¸‹è½½ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šDiffusionFaceï¼šé¢å‘åŸºäºæ‰©æ•£çš„äººè„¸ç¯¡æ”¹åˆ†æçš„ç»¼åˆæ•°æ®é›†</li>
<li>ä½œè€…ï¼šRapisurazuriteã€Jiahong Chenã€Junjie Huangã€Yuhang Songã€Xiangyu Huã€Yuxuan Zhangã€Xin Li</li>
<li>æ‰€å±å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šäººè„¸ç¯¡æ”¹æ£€æµ‹ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒé‰´åˆ«ã€æ·±åº¦å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2302.07650.pdf
Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„è¶…å†™å®äººè„¸ç¯¡æ”¹æ–¹æ³•å‘å±•è¿…é€Ÿï¼Œå¼•å‘äº†æœ‰å…³é”™è¯¯ä¿¡æ¯å’Œå®‰å…¨é£é™©çš„æ‹…å¿§ã€‚ç°æœ‰çš„äººè„¸ç¯¡æ”¹æ•°æ®é›†åœ¨ç”Ÿæˆé«˜è´¨é‡äººè„¸å›¾åƒå’Œåº”å¯¹ä¸æ–­æ¼”å˜çš„ç”ŸæˆæŠ€æœ¯æ‰€å¸¦æ¥çš„æŒ‘æˆ˜æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šå·²æœ‰æ–¹æ³•ä¸»è¦åŸºäºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œå¯¹æŠ—ç”Ÿæˆç½‘ç»œï¼ˆGANï¼‰ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡äººè„¸å›¾åƒå’Œåº”å¯¹ä¸æ–­æ¼”å˜çš„ç”ŸæˆæŠ€æœ¯æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„äººè„¸ç¯¡æ”¹æ•°æ®é›† DiffusionFaceï¼Œè¯¥æ•°æ®é›†æ¶µç›–äº†å„ç§ç¯¡æ”¹ç±»åˆ«ï¼ŒåŒ…æ‹¬æ— æ¡ä»¶å’Œæ–‡æœ¬æŒ‡å¯¼äººè„¸å›¾åƒç”Ÿæˆã€Img2Imgã€Inpaint å’ŒåŸºäºæ‰©æ•£çš„äººè„¸äº¤æ¢ç®—æ³•ã€‚DiffusionFace æ•°æ®é›†ä»¥å…¶å¹¿æ³›æ”¶é›†çš„ 11 ä¸ªæ‰©æ•£æ¨¡å‹å’Œç”Ÿæˆå›¾åƒçš„é«˜è´¨é‡è€Œè„±é¢–è€Œå‡ºï¼Œå®ƒæä¾›äº†å¿…è¦çš„å…ƒæ•°æ®å’Œä¸€ä¸ªçœŸå®ä¸–ç•Œäº’è”ç½‘æ¥æºçš„ç¯¡æ”¹äººè„¸å›¾åƒæ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¯¹æ•°æ®è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œå¹¶å¼•å…¥äº†å®ç”¨çš„è¯„ä¼°åè®®ï¼Œä»¥ä¸¥æ ¼è¯„ä¼°åˆ¤åˆ«æ¨¡å‹åœ¨æ£€æµ‹ä¼ªé€ äººè„¸å›¾åƒä¸­çš„æœ‰æ•ˆæ€§ï¼Œæ—¨åœ¨å¢å¼ºäººè„¸å›¾åƒè®¤è¯è¿‡ç¨‹ä¸­çš„å®‰å…¨æ€§ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨äººè„¸ç¯¡æ”¹æ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ£€æµ‹å‡ºä¼ªé€ çš„äººè„¸å›¾åƒï¼Œæ”¯æŒå…¶å¢å¼ºäººè„¸å›¾åƒè®¤è¯è¿‡ç¨‹ä¸­çš„å®‰å…¨æ€§çš„ç›®æ ‡ã€‚</li>
</ol>
<p>7.Methodsï¼š
(1) åŸºäºæ‰©æ•£æ¨¡å‹æ„å»ºäººè„¸ç¯¡æ”¹æ•°æ®é›†DiffusionFaceï¼Œæ¶µç›–æ— æ¡ä»¶å’Œæ–‡æœ¬æŒ‡å¯¼äººè„¸å›¾åƒç”Ÿæˆã€Img2Imgã€Inpaintå’ŒåŸºäºæ‰©æ•£çš„äººè„¸äº¤æ¢ç®—æ³•ç­‰å¤šç§ç¯¡æ”¹ç±»åˆ«ï¼›
(2) æ”¶é›†11ä¸ªæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆé«˜è´¨é‡äººè„¸å›¾åƒï¼Œå¹¶æä¾›å¿…è¦çš„å…ƒæ•°æ®å’ŒçœŸå®ä¸–ç•Œäº’è”ç½‘æ¥æºçš„ç¯¡æ”¹äººè„¸å›¾åƒæ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°ï¼›
(3) å¯¹æ•°æ®è¿›è¡Œæ·±å…¥åˆ†æï¼Œå¼•å…¥å®ç”¨çš„è¯„ä¼°åè®®ï¼Œä¸¥æ ¼è¯„ä¼°åˆ¤åˆ«æ¨¡å‹åœ¨æ£€æµ‹ä¼ªé€ äººè„¸å›¾åƒä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¢å¼ºäººè„¸å›¾åƒè®¤è¯è¿‡ç¨‹ä¸­çš„å®‰å…¨æ€§ã€‚</p>
<ol>
<li><strong>ç»“è®º</strong>
(1): æœ¬æ–‡é¦–æ¬¡æå‡ºåŸºäºæ‰©æ•£æ¨¡å‹çš„äººè„¸ç¯¡æ”¹æ•°æ®é›†ï¼Œæ¶µç›–äº†å¤šç§ç¯¡æ”¹ç±»åˆ«ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å’Œè¯„ä¼°åè®®ä¸ºå¢å¼ºäººè„¸å›¾åƒè®¤è¯è¿‡ç¨‹çš„å®‰å…¨æ€§æä¾›äº†åŸºç¡€ã€‚
(2): <strong>åˆ›æ–°ç‚¹ï¼š</strong></li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„äººè„¸ç¯¡æ”¹æ•°æ®é›†ï¼Œæ¶µç›–äº†å¤šç§ç¯¡æ”¹ç±»åˆ«ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§å®ç”¨çš„è¯„ä¼°åè®®ï¼Œä¸¥æ ¼è¯„ä¼°åˆ¤åˆ«æ¨¡å‹åœ¨æ£€æµ‹ä¼ªé€ äººè„¸å›¾åƒä¸­çš„æœ‰æ•ˆæ€§ã€‚
<strong>æ€§èƒ½ï¼š</strong></li>
<li>åœ¨äººè„¸ç¯¡æ”¹æ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ£€æµ‹å‡ºä¼ªé€ çš„äººè„¸å›¾åƒã€‚
<strong>å·¥ä½œé‡ï¼š</strong></li>
<li>æ”¶é›†äº†11ä¸ªæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆé«˜è´¨é‡äººè„¸å›¾åƒï¼Œå¹¶æä¾›äº†å¿…è¦çš„å…ƒæ•°æ®å’ŒçœŸå®ä¸–ç•Œäº’è”ç½‘æ¥æºçš„ç¯¡æ”¹äººè„¸å›¾åƒæ•°æ®é›†ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-9643541d354b0efb8dc15be6f4562ef8.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-aea3a6a1330a4030ba0932e135a67ddf.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-e9d4193151e6946578223a87feedaff6.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-990f1238e6dfd593ddc01ac02dc09a6c.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-28f66023d5dd0210a64ba931c14504e8.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-622526f71df87bdce2448e6388f19205.jpg" align="middle">
</details>




<h2 id="ECNet-Effective-Controllable-Text-to-Image-Diffusion-Models"><a href="#ECNet-Effective-Controllable-Text-to-Image-Diffusion-Models" class="headerlink" title="ECNet: Effective Controllable Text-to-Image Diffusion Models"></a>ECNet: Effective Controllable Text-to-Image Diffusion Models</h2><p><strong>Authors:Sicheng Li, Keqiang Sun, Zhixin Lai, Xiaoshi Wu, Feng Qiu, Haoran Xie, Kazunori Miyata, Hongsheng Li</strong></p>
<p>The conditional text-to-image diffusion models have garnered significant attention in recent years. However, the precision of these models is often compromised mainly for two reasons, ambiguous condition input and inadequate condition guidance over single denoising loss. To address the challenges, we introduce two innovative solutions. Firstly, we propose a Spatial Guidance Injector (SGI) which enhances conditional detail by encoding text inputs with precise annotation information. This method directly tackles the issue of ambiguous control inputs by providing clear, annotated guidance to the model. Secondly, to overcome the issue of limited conditional supervision, we introduce Diffusion Consistency Loss (DCL), which applies supervision on the denoised latent code at any given time step. This encourages consistency between the latent code at each time step and the input signal, thereby enhancing the robustness and accuracy of the output. The combination of SGI and DCL results in our Effective Controllable Network (ECNet), which offers a more accurate controllable end-to-end text-to-image generation framework with a more precise conditioning input and stronger controllable supervision. We validate our approach through extensive experiments on generation under various conditions, such as human body skeletons, facial landmarks, and sketches of general objects. The results consistently demonstrate that our method significantly enhances the controllability and robustness of the generated images, outperforming existing state-of-the-art controllable text-to-image models. </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.18417v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„å¯æ§æ€§å¢å¼ºï¼Œé€šè¿‡ç©ºé—´å¼•å¯¼æ³¨å…¥å™¨å’Œæ‰©æ•£ä¸€è‡´æ€§æŸå¤±å®ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¼•å…¥ç©ºé—´å¼•å¯¼æ³¨å…¥å™¨ï¼Œé€šè¿‡ç²¾ç¡®æ³¨é‡Šä¿¡æ¯å¢å¼ºæ¡ä»¶ç»†èŠ‚ï¼Œè§£å†³æ¡ä»¶è¾“å…¥æ¨¡æ£±ä¸¤å¯çš„é—®é¢˜ã€‚</li>
<li>æå‡ºæ‰©æ•£ä¸€è‡´æ€§æŸå¤±ï¼Œåœ¨æ¯ä¸€ä¸ªå»å™ªæ—¶é—´æ­¥ä¸Šå¯¹å»å™ªéšç æ–½åŠ ç›‘ç£ï¼Œæå‡æ¡ä»¶ç›‘ç£çš„å……åˆ†æ€§ã€‚</li>
<li>å°†ç©ºé—´å¼•å¯¼æ³¨å…¥å™¨å’Œæ‰©æ•£ä¸€è‡´æ€§æŸå¤±ç»“åˆï¼Œæ„å»ºæœ‰æ•ˆå¯æ§ç½‘ç»œï¼Œå®ç°ç²¾åº¦å’Œå¯æ§æ€§æ›´å¼ºçš„ç«¯åˆ°ç«¯æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ã€‚</li>
<li>å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨äººä½“éª¨éª¼ã€é¢éƒ¨ç‰¹å¾å’Œä¸€èˆ¬ç‰©ä½“è‰å›¾ç­‰æ¡ä»¶ä¸‹ç”Ÿæˆå›¾åƒçš„å¯æ§æ€§å’Œç¨³å¥æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•ä¼˜äºç°æœ‰çš„å¯æ§æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆå›¾åƒçš„å¯æ§æ€§å’Œç¨³å¥æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šç§æ¡ä»¶ä¸‹ç”Ÿæˆå›¾åƒæ—¶éƒ½è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼ŒåŒ…æ‹¬äººä½“éª¨éª¼ã€é¢éƒ¨ç‰¹å¾å’Œæ™®é€šç‰©ä½“çš„è‰å›¾ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—å¢å¼ºäº†ç”Ÿæˆå›¾åƒçš„å¯æ§æ€§å’Œé²æ£’æ€§ï¼Œä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„å¯æ§æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šECNetï¼šæœ‰æ•ˆå¯æ§æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹â€”â€”è¡¥å……ææ–™â€”â€”1 æ›´å¤šç»“æœ</li>
<li>ä½œè€…ï¼šLiyuan Liu, Yujie Zhang, Yibing Lu, Yiran Zhong, Xiaogang Wang</li>
<li>éš¶å±å…³ç³»ï¼šæ— </li>
<li>å…³é”®è¯ï¼šå¯æ§æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆï¼Œæ‰©æ•£æ¨¡å‹ï¼Œæ‰©æ•£ä¸€è‡´æ€§æŸå¤±</li>
<li>è®ºæ–‡é“¾æ¥ï¼šarXiv:2403.18417v1[cs.CV]
   Githubï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ¡ä»¶æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¿‘å¹´æ¥å¤‡å—å…³æ³¨ï¼Œä½†å…¶ç²¾åº¦å¾€å¾€å—åˆ°ä¸¤ä¸ªä¸»è¦åŸå› çš„å½±å“ï¼šæ¡ä»¶è¾“å…¥æ¨¡ç³Šå’Œå¯¹å•ä¸€å»å™ªæŸå¤±çš„æ¡ä»¶æŒ‡å¯¼ä¸è¶³ã€‚
   ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸¤ç§åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚é¦–å…ˆï¼Œæå‡ºäº†ä¸€ç§ç©ºé—´å¼•å¯¼æ³¨å…¥å™¨ï¼ˆSGIï¼‰ï¼Œé€šè¿‡å¯¹æ–‡æœ¬è¾“å…¥è¿›è¡Œç²¾ç¡®æ³¨é‡Šä¿¡æ¯ç¼–ç æ¥å¢å¼ºæ¡ä»¶ç»†èŠ‚ã€‚è¿™ç§æ–¹æ³•é€šè¿‡å‘æ¨¡å‹æä¾›æ¸…æ™°ã€å¸¦æ³¨é‡Šçš„æŒ‡å¯¼ï¼Œç›´æ¥è§£å†³äº†æ¡ä»¶è¾“å…¥æ¨¡ç³Šçš„é—®é¢˜ã€‚å…¶æ¬¡ï¼Œä¸ºäº†å…‹æœæ¡ä»¶ç›‘ç£æœ‰é™çš„é—®é¢˜ï¼Œå¼•å…¥äº†æ‰©æ•£ä¸€è‡´æ€§æŸå¤±ï¼ˆDCLï¼‰ï¼Œåœ¨ä»»ä½•ç»™å®šçš„æ—¶é—´æ­¥é•¿å¯¹å»å™ªçš„æ½œåœ¨ä»£ç åº”ç”¨ç›‘ç£ã€‚è¿™é¼“åŠ±äº†æ¯ä¸ªæ—¶é—´æ­¥é•¿çš„æ½œåœ¨ä»£ç ä¸è¾“å…¥ä¿¡å·ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œä»è€Œæé«˜äº†è¾“å‡ºçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚
   ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šSGI å’Œ DCL çš„ç»“åˆäº§ç”Ÿäº†æœ¬æ–‡çš„æœ‰æ•ˆå¯æ§ç½‘ç»œï¼ˆECNetï¼‰ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªæ›´å‡†ç¡®çš„å¯æ§ç«¯åˆ°ç«¯æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ï¼Œå…·æœ‰æ›´ç²¾ç¡®çš„æ¡ä»¶è¾“å…¥å’Œæ›´å¼ºçš„å¯æ§ç›‘ç£ã€‚
   ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šé€šè¿‡åœ¨å„ç§æ¡ä»¶ä¸‹çš„ç”Ÿæˆè¿›è¡Œå¹¿æ³›çš„å®éªŒæ¥éªŒè¯æœ¬æ–‡çš„æ–¹æ³•ï¼Œä¾‹å¦‚äººä½“éª¨æ¶ã€é¢éƒ¨åœ°æ ‡å’Œä¸€èˆ¬ç‰©ä½“çš„è‰å›¾ã€‚ç»“æœå§‹ç»ˆè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•æ˜¾ç€å¢å¼ºäº†ç”Ÿæˆå›¾åƒçš„å¯æ§æ€§å’Œé²æ£’æ€§ï¼Œä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„å¯æ§æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ‰©æ•£ä¸€è‡´æ€§æŸå¤±ï¼ˆDiffusion Consistency Lossï¼ŒDCLï¼‰ï¼šåœ¨æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé™¤äº†ä¼ ç»Ÿçš„å»å™ªæŸå¤±ä¹‹å¤–ï¼Œè¿˜å¼•å…¥äº†é¢å¤–çš„æ½œåœ¨ä»£ç ç›‘ç£ï¼Œä»¥å¢å¼ºç”Ÿæˆç²¾åº¦ã€‚æ€»æŸå¤± L e ç”±åŠ æƒ SD æŸå¤± L h å’Œ DCL ç»„æˆï¼Œå¦‚å…¬å¼ 6 æ‰€ç¤ºã€‚DCL åœ¨æ‰©æ•£è¿‡ç¨‹çš„ä¸åŒé˜¶æ®µé‡‡ç”¨ä¸åŒçš„ç›‘ç£ç­–ç•¥ï¼Œåˆ©ç”¨ä¸åŒæ—¶é—´æ­¥é•¿ä¸‹å™ªå£°å·®åˆ†å›¾åƒå’Œæ´¾ç”Ÿå›¾åƒçš„é«˜ä¿çœŸåº¦ï¼Œä¸ºè®­ç»ƒè¿‡ç¨‹æä¾›ç²¾ç¡®çš„ç›‘ç£ã€‚
ï¼ˆ2ï¼‰ç©ºé—´å¼•å¯¼æ³¨å…¥å™¨ï¼ˆSpatial Guidance Injectorï¼ŒSGIï¼‰ï¼šä¼ ç»Ÿçš„åŸºäº SD çš„å§¿æ€æ§åˆ¶æ¨¡å‹ä½¿ç”¨éª¨æ¶å›¾åƒæ¥èå…¥å§¿æ€æ¡ä»¶ï¼Œåˆ©ç”¨ VAE æ¨¡å—å¤„ç†è¿™äº›éª¨æ¶å›¾åƒä»¥è·å–ä½ç½®ä¿¡æ¯ï¼Œç¡®ä¿å§¿æ€æ¡ä»¶ä¸è¾“å…¥å›¾åƒçš„æ½œåœ¨åµŒå…¥å¯¹é½ã€‚ç„¶è€Œï¼Œæœ¬æ–‡è®¤ä¸ºä»å›¾åƒç‰¹å¾ä¸­æå–å§¿æ€ä¿¡æ¯è¿‡äºé—´æ¥ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œéª¨æ¶å›¾åƒä¸­åµŒå…¥çš„å…³é”®ç‚¹æ³¨é‡Šä¸ºå§¿æ€è¡¨ç¤ºæä¾›äº†æ›´ç›´æ¥çš„ç©ºé—´ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è§‚å¯Ÿåˆ°æ–‡æœ¬æ¡ä»¶é€šå¸¸ä¸åŒ…å«ç‰¹å®šç»†èŠ‚ï¼Œä¾‹å¦‚å¯¹è±¡æ•°é‡æˆ–å…³èŠ‚ä½ç½®ã€‚åŸºäºè¿™äº›è€ƒè™‘ï¼Œæœ¬æ–‡æå‡ºå°†å…³é”®ç‚¹æ³¨é‡Šä½œä¸ºé™„åŠ æ¡ä»¶é›†æˆåˆ°ç°æœ‰çš„å§¿æ€å›¾åƒå’Œæ–‡æœ¬æ¡ä»¶ä¸­ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹æ¯ä¸ªå›¾åƒè¿›è¡Œå¤„ç†ä»¥æå–å…³é”®ç‚¹æ³¨é‡Šï¼Œç„¶åé€šè¿‡å¡«å……ã€æ ‡è®°åŒ–ã€æ©è”½å’ŒåµŒå…¥ç­‰ä¸€ç³»åˆ—æ“ä½œå¯¹è¿™äº›æ³¨é‡Šè¿›è¡Œç²¾ç‚¼ã€‚åŒæ—¶ï¼Œä½¿ç”¨ CLIP ç¼–ç å™¨ç”Ÿæˆæ–‡æœ¬åµŒå…¥ã€‚ä¸ºäº†ç»¼åˆè§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œæœ¬æ–‡åœ¨æ³¨é‡Šä¸Šä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶é€šè¿‡è·¨æ³¨æ„åŠ›æ¨¡å—å°†ç»“æœä¸æ–‡æœ¬åµŒå…¥é›†æˆã€‚è¿™ä¸ªé›†æˆæ¨¡å—ç§°ä¸º SGIï¼Œå¦‚å…¬å¼ 8 æ‰€ç¤ºã€‚SGI ä¿ƒè¿›äº†å¯¹å¤šæ¨¡æ€æ³¨é‡Šæ•°æ®çš„æ›´ç²¾ç»†ç†è§£ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šè¿™ç¯‡å·¥ä½œçš„é‡è¦æ„ä¹‰åœ¨äºï¼šæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ ECNetï¼Œå®ƒå»ºç«‹åœ¨é¢„è®­ç»ƒçš„ Stable Diffusionï¼ˆSDï¼‰æ¨¡å‹ä¹‹ä¸Šã€‚ECNet é€šè¿‡ä¸ºæ‰©æ•£æ¨¡å‹å»å™ªçš„æ½œåœ¨ä»£ç å¼•å…¥ DCL ä»¥å®ç°ä¸€è‡´æ€§ç›‘ç£ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºäº†å¯æ§æ¨¡å‹çš„ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å¼•å…¥ç©ºé—´å¼•å¯¼æ³¨å…¥å™¨å¢å¼ºäº†æ¨¡å‹å¯¹è¾“å…¥æ¡ä»¶æ¨¡ç³Šæ€§çš„æ„ŸçŸ¥ã€‚è¯¥æ¡†æ¶æ—¨åœ¨ä¿æŒé€šç”¨æ€§ï¼Œä¿ç•™é¢„è®­ç»ƒ SD æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼ŒåŒæ—¶å¢å¼ºå„ç§è¾“å…¥æ¡ä»¶å¯¹è¾“å‡ºçš„å½±å“ã€‚åœ¨ä½¿ç”¨å§¿åŠ¿å’Œé¢éƒ¨åœ°æ ‡ç²¾åº¦ã€å›¾åƒè´¨é‡å’Œä¸æ–‡æœ¬ç›¸å…³æ€§ç­‰å¤šç§è¯„ä¼°æŒ‡æ ‡ä¸åŸºçº¿æ¨¡å‹è¿›è¡Œæ¯”è¾ƒåˆ†æä¸­ï¼ŒECNet æ˜æ˜¾è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æ‰©æ•£ä¸€è‡´æ€§æŸå¤±ï¼ˆDCLï¼‰ï¼šåœ¨æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé™¤äº†ä¼ ç»Ÿçš„å»å™ªæŸå¤±ä¹‹å¤–ï¼Œè¿˜å¼•å…¥äº†é¢å¤–çš„æ½œåœ¨ä»£ç ç›‘ç£ï¼Œä»¥å¢å¼ºç”Ÿæˆç²¾åº¦ã€‚</li>
<li>ç©ºé—´å¼•å¯¼æ³¨å…¥å™¨ï¼ˆSGIï¼‰ï¼šé€šè¿‡å°†å…³é”®ç‚¹æ³¨é‡Šä½œä¸ºé™„åŠ æ¡ä»¶é›†æˆåˆ°ç°æœ‰çš„å§¿æ€å›¾åƒå’Œæ–‡æœ¬æ¡ä»¶ä¸­ï¼Œå¢å¼ºäº†æ¨¡å‹å¯¹è¾“å…¥æ¡ä»¶æ¨¡ç³Šæ€§çš„æ„ŸçŸ¥ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å„ç§æ¡ä»¶ä¸‹çš„ç”Ÿæˆä¸­è¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œä¾‹å¦‚äººä½“éª¨æ¶ã€é¢éƒ¨åœ°æ ‡å’Œä¸€èˆ¬ç‰©ä½“çš„è‰å›¾ã€‚</li>
<li>ç»“æœå§‹ç»ˆè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•æ˜¾ç€å¢å¼ºäº†ç”Ÿæˆå›¾åƒçš„å¯æ§æ€§å’Œé²æ£’æ€§ï¼Œä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„å¯æ§æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡æå‡ºçš„æ–¹æ³•éœ€è¦é¢å¤–çš„è®¡ç®—èµ„æºæ¥è®­ç»ƒ DCL å’Œ SGIã€‚</li>
<li>ç„¶è€Œï¼Œç”±äº ECNet å»ºç«‹åœ¨é¢„è®­ç»ƒçš„ SD æ¨¡å‹ä¹‹ä¸Šï¼Œå› æ­¤è®­ç»ƒæ—¶é—´å’Œèµ„æºæ¶ˆè€—ä»ç„¶å¯ä»¥æ¥å—ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-88076af7c138e4902314fb0b0c93fd24.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-715aecf5ab30721345e7c95d919f646f.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-d470b20319309e61418c0d54057b7f59.jpg" align="middle">
</details>




<h2 id="Ship-in-Sight-Diffusion-Models-for-Ship-Image-Super-Resolution"><a href="#Ship-in-Sight-Diffusion-Models-for-Ship-Image-Super-Resolution" class="headerlink" title="Ship in Sight: Diffusion Models for Ship-Image Super Resolution"></a>Ship in Sight: Diffusion Models for Ship-Image Super Resolution</h2><p><strong>Authors:Luigi Sigillo, Riccardo Fosco Gramaccioni, Alessandro Nicolosi, Danilo Comminiello</strong></p>
<p>In recent years, remarkable advancements have been achieved in the field of image generation, primarily driven by the escalating demand for high-quality outcomes across various image generation subtasks, such as inpainting, denoising, and super resolution. A major effort is devoted to exploring the application of super-resolution techniques to enhance the quality of low-resolution images. In this context, our method explores in depth the problem of ship image super resolution, which is crucial for coastal and port surveillance. We investigate the opportunity given by the growing interest in text-to-image diffusion models, taking advantage of the prior knowledge that such foundation models have already learned. In particular, we present a diffusion-model-based architecture that leverages text conditioning during training while being class-aware, to best preserve the crucial details of the ships during the generation of the super-resoluted image. Since the specificity of this task and the scarcity availability of off-the-shelf data, we also introduce a large labeled ship dataset scraped from online ship images, mostly from ShipSpotting\footnote{\url{www.shipspotting.com}} website. Our method achieves more robust results than other deep learning models previously employed for super resolution, as proven by the multiple experiments performed. Moreover, we investigate how this model can benefit downstream tasks, such as classification and object detection, thus emphasizing practical implementation in a real-world scenario. Experimental results show flexibility, reliability, and impressive performance of the proposed framework over state-of-the-art methods for different tasks. The code is available at: <a target="_blank" rel="noopener" href="https://github.com/LuigiSigillo/ShipinSight">https://github.com/LuigiSigillo/ShipinSight</a> . </p>
<p><a target="_blank" rel="noopener" href="http://arxiv.org/abs/2403.18370v1">PDF</a> Accepted at 2024 International Joint Conference on Neural Networks   (IJCNN)</p>
<p><strong>Summary</strong></p>
<p>åˆ©ç”¨æ–‡æœ¬æ¡ä»¶ç”Ÿæˆæ¨¡å‹å’Œè‡ªæœ‰èˆ¹èˆ¶æ•°æ®é›†ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºèˆ¹èˆ¶å›¾åƒè¶…åˆ†è¾¨ç‡çš„ç±»æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹æ¶æ„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§ç”¨äºèˆ¹èˆ¶å›¾åƒè¶…åˆ†è¾¨ç‡çš„ç±»æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹æ¶æ„ã€‚</li>
<li>åˆ©ç”¨äº†æ–‡æœ¬æ¡ä»¶ç”Ÿæˆæ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªä»åœ¨çº¿èˆ¹èˆ¶å›¾åƒä¸­è·å–çš„å¤§å‹æ ‡è®°èˆ¹èˆ¶æ•°æ®é›†ã€‚</li>
<li>è¯¥æ–¹æ³•æ¯”ä»¥å‰ç”¨äºè¶…åˆ†è¾¨ç‡çš„å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹è·å¾—äº†æ›´ç¨³å¥çš„ç»“æœã€‚</li>
<li>æ¢ç´¢äº†è¯¥æ¨¡å‹å¦‚ä½•ä½¿ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚åˆ†ç±»å’Œå¯¹è±¡æ£€æµ‹ï¼‰å—ç›Šã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æ¯”é’ˆå¯¹ä¸åŒä»»åŠ¡çš„æœ€å…ˆè¿›æ–¹æ³•å…·æœ‰çµæ´»æ€§ã€å¯é æ€§å’Œä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ã€‚</li>
<li>ä»£ç å¯åœ¨ <a target="_blank" rel="noopener" href="https://github.com/LuigiSigillo/ShipinSight">https://github.com/LuigiSigillo/ShipinSight</a> è·å–ã€‚</li>
</ul>
<p><strong><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šShipinSightï¼šèˆ¹èˆ¶å›¾åƒè¶…åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šLuigi Sigilloã€Riccardo Fosco Gramaccioniã€Alessandro Nicolosiã€Danilo Comminiello</li>
<li>éš¶å±æœºæ„ï¼šç½—é©¬ç¬¬ä¸€å¤§å­¦ä¿¡æ¯å·¥ç¨‹ã€ç”µå­å’Œç”µä¿¡ç³»</li>
<li>å…³é”®è¯ï¼šç”Ÿæˆæ·±åº¦å­¦ä¹ ã€å›¾åƒè¶…åˆ†è¾¨ç‡ã€æ‰©æ•£æ¨¡å‹ã€èˆ¹èˆ¶åˆ†ç±»</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.18370</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œå›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä¸»è¦å—å„å›¾åƒç”Ÿæˆå­ä»»åŠ¡ï¼ˆå¦‚å›¾åƒä¿®å¤ã€å»å™ªå’Œè¶…åˆ†è¾¨ç‡ï¼‰å¯¹é«˜è´¨é‡ç»“æœéœ€æ±‚ä¸æ–­å¢é•¿çš„æ¨åŠ¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¶…åˆ†è¾¨ç‡æŠ€æœ¯ä¸»è¦é›†ä¸­åœ¨è‡ªç„¶æˆ–äººè„¸å›¾åƒä¸Šã€‚ç„¶è€Œï¼Œè¶…åˆ†è¾¨ç‡åœ¨å…¶ä»–é¢†åŸŸï¼ˆå¦‚æµ·ä¸Šç›‘æµ‹ï¼‰ä¹Ÿè‡³å…³é‡è¦ã€‚ä¼ ç»Ÿæ–¹æ³•éš¾ä»¥è·å–é«˜è´¨é‡çš„èˆ¹èˆ¶å›¾åƒï¼Œè¿™é˜»ç¢äº†å¯¹èˆ¹èˆ¶çš„æ£€æµ‹ã€åˆ†ç±»å’Œè·Ÿè¸ªã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ¶æ„ï¼Œåˆ©ç”¨æ–‡æœ¬æ¡ä»¶å¯¹èˆ¹èˆ¶å›¾åƒè¿›è¡Œè¶…åˆ†è¾¨ç‡ã€‚è¯¥æ¶æ„åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åˆ©ç”¨æ–‡æœ¬æ¡ä»¶ï¼ŒåŒæ—¶å…·æœ‰ç±»åˆ«æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»¥åœ¨ç”Ÿæˆè¶…åˆ†è¾¨ç‡å›¾åƒæ—¶æœ€å¤§ç¨‹åº¦åœ°ä¿ç•™èˆ¹èˆ¶çš„å…³é”®ç»†èŠ‚ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨èˆ¹èˆ¶å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸Šå–å¾—äº†æ¯”å…¶ä»–æ·±åº¦å­¦ä¹ æ¨¡å‹æ›´å¥½çš„ç»“æœã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æé«˜ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚åˆ†ç±»å’Œç›®æ ‡æ£€æµ‹ï¼‰çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒä»»åŠ¡ä¸Šéƒ½å…·æœ‰çµæ´»æ€§ã€å¯é æ€§å’Œä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æœ¬æ–‡åŸºäºé¢„è®­ç»ƒçš„ Stable Diffusion æ¨¡å‹ï¼Œåˆ©ç”¨æ–‡æœ¬æ¡ä»¶å¯¹èˆ¹èˆ¶å›¾åƒè¿›è¡Œè¶…åˆ†è¾¨ç‡ã€‚
(2) åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œåˆ©ç”¨æ–‡æœ¬æ¡ä»¶æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼ŒåŒæ—¶å…·æœ‰ç±»åˆ«æ„ŸçŸ¥èƒ½åŠ›ï¼Œä»¥æœ€å¤§ç¨‹åº¦åœ°ä¿ç•™èˆ¹èˆ¶çš„å…³é”®ç»†èŠ‚ã€‚
(3) æå‡ºäº†ä¸€ç§ç±»åˆ«å’Œæ—¶é—´æ„ŸçŸ¥ç¼–ç å™¨ï¼Œä¸ºæ‰©æ•£æ¨¡å‹æä¾›èˆ¹èˆ¶ç±»åˆ«ä¿¡æ¯ï¼Œè¯¥ä¿¡æ¯é€šè¿‡å¯¹ä½åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œåˆ†ç±»å¾—åˆ°ã€‚
(4) é€šè¿‡ç©ºé—´ç‰¹å¾å˜æ¢ï¼ˆSFTï¼‰å°†ç¼–ç å™¨è¾“å‡ºä¸ U-Net çš„ä¸­é—´ç‰¹å¾å›¾ç›¸ç»“åˆï¼Œä»¥æé«˜å›¾åƒè´¨é‡ã€‚
(5) é›†æˆæ—¶é—´ä¿¡æ¯ï¼Œå¢å¼ºç”Ÿæˆå›¾åƒçš„æ•´ä½“å®šæ€§ç»“æœã€‚
(6) ä¼˜åŒ–ç±»åˆ«å’Œæ—¶é—´æ­¥é•¿åµŒå…¥çš„æ¡ä»¶ç¼–ç å™¨ï¼Œä»¥æä¾›æœ‰ç”¨çš„æŒ‡å¯¼ã€‚
(7) åˆ›å»ºäº†ä¸€ä¸ªç‰¹å®šäºèˆ¹èˆ¶å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡çš„æ•°æ®é›†ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† StableShip-SRï¼Œè¿™æ˜¯ä¸“é—¨é’ˆå¯¹èˆ¹èˆ¶è¶…åˆ†è¾¨ç‡é‡èº«å®šåˆ¶çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚é€šè¿‡å¯¹ä¸åŒæ¨¡å‹çš„å…¨é¢æ¯”è¾ƒï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒå¹¶ç¡®å®šäº†æˆ‘ä»¬çš„æ–¹æ³•æ˜¯æœ€é€‚åˆèˆ¹èˆ¶è¶…åˆ†è¾¨ç‡ä»»åŠ¡çš„æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å§‹ç»ˆå¦‚ä¸€åœ°ç”Ÿæˆä»¥é«˜åº¦çœŸå®æ„Ÿä¸ºç‰¹å¾çš„å›¾åƒï¼Œä¸äººç±»çš„æ„ŸçŸ¥èƒ½åŠ›ç´§å¯†ä¸€è‡´ã€‚è¿™ä»½æ‰‹ç¨¿ä»ç†è®ºè§’åº¦æ·±å…¥æ¢è®¨äº†è¶…åˆ†è¾¨ç‡èŒƒå¼çš„å¤æ‚æ€§ï¼Œåˆ©ç”¨äº†å¼ºå¤§çš„æ¶æ„åŸºç¡€ã€‚æˆ‘ä»¬å¯¹ä¸åŒä»»åŠ¡çš„å®éªŒè¯„ä¼°è¯æ˜äº† StableShip-SR ä¸å…¶å¯¹åº”ä»»åŠ¡ç›¸æ¯”çš„ä¼˜è¶Šæ€§ã€‚åŸºäºæˆ‘ä»¬çš„å…¨é¢æµ‹è¯•ï¼Œæˆ‘ä»¬ä½¿ç”¨æ ‡å‡†å’Œéæ ‡å‡†æŒ‡æ ‡è¾¾æˆäº†ä¸€äº›å…³é”®å‘ç°ï¼Œè¿˜è¯„ä¼°äº†ä¸‹æ¸¸ä»»åŠ¡ä»¥ç¡®ä¿å…¨é¢è¯„ä¼°ã€‚æˆ‘ä»¬å·¥ä½œçš„å…³é”®è´¡çŒ®æ˜¯å¼•å…¥äº†ä¸€ä¸ªç²¾å¿ƒç­–åˆ’çš„èˆ¹èˆ¶æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«åˆ†å¸ƒåœ¨ 20 ä¸ªä¸åŒç±»ä¸­çš„è¶…è¿‡ 500.000 ä¸ªæ ·æœ¬ã€‚ä½œä¸ºä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åº”ç”¨é¢†åŸŸï¼Œæˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œå¯¹ç ”ç©¶ç•Œå’Œå·¥ä¸šç•Œéƒ½æœ‰æ‰€å¸®åŠ©ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™é¡¹å·¥ä½œä¸»è¦ä¿ƒè¿›äº†å›¾åƒè¶…åˆ†è¾¨ç‡é¢†åŸŸçš„ç ”ç©¶ï¼Œé‡ç‚¹å…³æ³¨èˆ¹èˆ¶å›¾åƒçš„å…·ä½“åº”ç”¨æ¡ˆä¾‹ï¼Œå¼•å…¥äº†æ–°æ¨¡å‹å’Œæ–°æ•°æ®é›†ï¼Œå¹¶å¯¹ä¸åŒæ–¹æ³•çš„æ€§èƒ½å’Œæƒè¡¡è¿›è¡Œäº†åˆ†æã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pica.zhimg.com/v2-1b9ae387ee4795bfb003c41f6c86ff2d.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-87f453ff5380369cdedec8cfad032bdf.jpg" align="middle">
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-c85f8b7be4728ecd05414278728302e1.jpg" align="middle">
</details>




</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>æ–‡ç« ä½œè€…: </span><span class="post-copyright-info"><a href="https://kedreamix.github.io">Kedreamix</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>æ–‡ç« é“¾æ¥: </span><span class="post-copyright-info"><a href="https://kedreamix.github.io/Paper/2024-04-01/Diffusion%20Models/">https://kedreamix.github.io/Paper/2024-04-01/Diffusion Models/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>ç‰ˆæƒå£°æ˜: </span><span class="post-copyright-info">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥è‡ª <a href="https://kedreamix.github.io" target="_blank">Adventures in Kedreamix' Digital World</a>ï¼</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Diffusion-Models/">Diffusion Models</a></div><div class="post_share"><div class="social-share" data-image="https://picx.zhimg.com/v2-d470b20319309e61418c0d54057b7f59.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>èµåŠ©</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-9a9b3c8658acbcad50b3234f818a6f6e.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-285d9459d746def9a847dd41da474e4c.png" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/Paper/2024-04-01/Talking%20Head%20Generation/" title="Talking Head Generation"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-9e4d3acaf0612269dbaa41a149d52930.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">ä¸Šä¸€ç¯‡</div><div class="prev_info">Talking Head Generation</div></div></a></div><div class="next-post pull-right"><a href="/Paper/2024-03-28/NeRF/" title="NeRF"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-8a4b46a392670a516f67cab259e4deea.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">ä¸‹ä¸€ç¯‡</div><div class="next_info">NeRF</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>ç›¸å…³æ¨è</span></div><div class="relatedPosts-list"><div><a href="/Paperscape/EMO/" title="EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-6492e24fb03ffa98135dc584535ab7d9.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-03</div><div class="title">EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC</div></div></a></div><div><a href="/Paper/2024-02-02/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-5920453c69c00995f18077b22d4a790e.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-02</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/Paper/2024-01-30/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/v2-e55358c77a9d65f15701e8f33262e2a4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-30</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/Paper/2024-02-09/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-32488f736ee10537497afccc3a1a1d76.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-09</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/Paper/2024-01-24/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-71a37c439c6714e8867560f580599d2f.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-24</div><div class="title">Diffusion Models</div></div></a></div><div><a href="/Paper/2024-02-23/Diffusion%20Models/" title="Diffusion Models"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/v2-ff425802a32a4519e30b9044a3eed1e8.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-02-23</div><div class="title">Diffusion Models</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>ç›®å½•</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#2024-04-01-%E6%9B%B4%E6%96%B0"><span class="toc-text">2024-04-01 æ›´æ–°</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Detecting-Image-Attribution-for-Text-to-Image-Diffusion-Models-in-RGB-and-Beyond"><span class="toc-text">Detecting Image Attribution for Text-to-Image Diffusion Models in RGB   and Beyond</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GANTASTIC-GAN-based-Transfer-of-Interpretable-Directions-for-Disentangled-Image-Editing-in-Text-to-Image-Diffusion-Models"><span class="toc-text">GANTASTIC: GAN-based Transfer of Interpretable Directions for   Disentangled Image Editing in Text-to-Image Diffusion Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Burst-Super-Resolution-with-Diffusion-Models-for-Improving-Perceptual-Quality"><span class="toc-text">Burst Super-Resolution with Diffusion Models for Improving Perceptual   Quality</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#RecDiffusion-Rectangling-for-Image-Stitching-with-Diffusion-Models"><span class="toc-text">RecDiffusion: Rectangling for Image Stitching with Diffusion Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ObjectDrop-Bootstrapping-Counterfactuals-for-Photorealistic-Object-Removal-and-Insertion"><span class="toc-text">ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object   Removal and Insertion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Object-Pose-Estimation-via-the-Aggregation-of-Diffusion-Features"><span class="toc-text">Object Pose Estimation via the Aggregation of Diffusion Features</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ImageNet-D-Benchmarking-Neural-Network-Robustness-on-Diffusion-Synthetic-Object"><span class="toc-text">ImageNet-D: Benchmarking Neural Network Robustness on Diffusion   Synthetic Object</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#HandBooster-Boosting-3D-Hand-Mesh-Reconstruction-by-Conditional-Synthesis-and-Sampling-of-Hand-Object-Interactions"><span class="toc-text">HandBooster: Boosting 3D Hand-Mesh Reconstruction by Conditional   Synthesis and Sampling of Hand-Object Interactions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Artifact-Reduction-in-3D-and-4D-Cone-beam-Computed-Tomography-Images-with-Deep-Learning-%E2%80%94-A-Review"><span class="toc-text">Artifact Reduction in 3D and 4D Cone-beam Computed Tomography Images   with Deep Learning â€” A Review</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DiffusionFace-Towards-a-Comprehensive-Dataset-for-Diffusion-Based-Face-Forgery-Analysis"><span class="toc-text">DiffusionFace: Towards a Comprehensive Dataset for Diffusion-Based Face   Forgery Analysis</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ECNet-Effective-Controllable-Text-to-Image-Diffusion-Models"><span class="toc-text">ECNet: Effective Controllable Text-to-Image Diffusion Models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ship-in-Sight-Diffusion-Models-for-Ship-Image-Super-Resolution"><span class="toc-text">Ship in Sight: Diffusion Models for Ship-Image Super Resolution</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background-image: url('https://picx.zhimg.com/v2-d470b20319309e61418c0d54057b7f59.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Kedreamix</div><div class="framework-info"><span>æ¡†æ¶ </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>ä¸»é¢˜ </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://kedreamix.github.io/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="é˜…è¯»æ¨¡å¼"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="ç®€ç¹è½¬æ¢">ç°¡</button><button id="darkmode" type="button" title="æµ…è‰²å’Œæ·±è‰²æ¨¡å¼è½¬æ¢"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="å•æ å’ŒåŒæ åˆ‡æ¢"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="è®¾ç½®"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="ç›®å½•"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="å›åˆ°é¡¶éƒ¨"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.12.0"></script><script src="/js/main.js?v=4.12.0"></script><script src="/js/tw_cn.js?v=4.12.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.32/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">æœç´¢</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  æ•°æ®åº“åŠ è½½ä¸­</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="æœç´¢æ–‡ç« " type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.12.0"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Paper/3DGS Survey/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-25</span><a class="blog-slider__title" href="Paper/3DGS Survey/" alt="">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting</a><div class="blog-slider__text">3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting ä»Šå¤©æƒ³ä»‹ç»çš„æ˜¯`ZJU`å¸¦æ¥çš„`3DGS`çš„é¦–ç¯‡ç»¼è¿°`A Survey on 3D Gaussian Splatting`</div><a class="blog-slider__button" href="Paper/3DGS Survey/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/80/v2-dd72e374ab099a8115894f5247afb51f_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-12</span><a class="blog-slider__title" href="CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">CUDAç¼–ç¨‹å­¦ä¹ ï¼šè‡ªå®šä¹‰Pytorch+cpp/cuda extension</a><div class="blog-slider__text">è™½ç„¶è¯´PyTorchæä¾›äº†ä¸°å¯Œçš„ä¸ç¥ç»ç½‘ç»œã€å¼ é‡ä»£æ•°ã€æ•°æ®å¤„ç†ç­‰ç›¸å…³çš„æ“ä½œï¼Œä½†æ˜¯æœ‰æ—¶å€™ä½ å¯èƒ½éœ€è¦**æ›´å®šåˆ¶åŒ–çš„æ“ä½œ**ï¼Œæ¯”å¦‚ä½¿ç”¨è®ºæ–‡ä¸­çš„æ–°å‹æ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…å®ç°ä½œä¸ºç ”ç©¶ä¸€éƒ¨åˆ†å¼€å‘çš„æ“ä½œã€‚åœ¨PyTorchä¸­ï¼Œæœ€ç®€å•çš„é›†æˆè‡ªå®šä¹‰æ“ä½œçš„æ–¹å¼æ˜¯åœ¨Pythonä¸­ç¼–å†™ï¼Œé€šè¿‡æ‰©å±•Functionå’ŒModuleæ¥å®ç°ï¼Œ</div><a class="blog-slider__button" href="CUDA/Pytorch+cppcuda extension å­¦ä¹ /" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Project/Linly-Talker/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="Project/Linly-Talker/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="Project/Linly-Talker/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Project/Linly-Talker - GPT-SoVITS/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-2ae8c11c1aae13ac400d5589124377b9_720w.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-20</span><a class="blog-slider__title" href="Project/Linly-Talker - GPT-SoVITS/" alt="">æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</a><div class="blog-slider__text">Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</div><a class="blog-slider__button" href="Project/Linly-Talker - GPT-SoVITS/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Paper/Awesome-Talking-Head-Synthesis/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://picx.zhimg.com/70/v2-de8deb9ec70dc554000936e71b7e907a.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2024-01-01</span><a class="blog-slider__title" href="Paper/Awesome-Talking-Head-Synthesis/" alt="">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesis</a><div class="blog-slider__text">è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesisï¼Œ è¿™ä»½èµ„æºåº“æ•´ç†äº†ä¸ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)å’Œç¥ç»è¾å°„åœº(NeRF)ç›¸å…³çš„è®ºæ–‡ã€ä»£ç å’Œèµ„æº,é‡ç‚¹å…³æ³¨åŸºäºå›¾åƒå’ŒéŸ³é¢‘çš„è™šæ‹Ÿè®²è¯å¤´åˆæˆè®ºæ–‡åŠå·²å‘å¸ƒä»£ç ã€‚å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªä»“åº“æœ‰ç”¨,è¯·starâ­æ”¯æŒ!</div><a class="blog-slider__button" href="Paper/Awesome-Talking-Head-Synthesis/" alt="">è¯¦æƒ…   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Project/ChatPaperFree/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="Project/ChatPaperFree/" alt="">ChatPaperFree GeminiProï¼ˆä¸€åˆ†é’Ÿè¯»è®ºæ–‡ï¼‰</a><div class="blog-slider__text">ChatPaperFreeæ˜¯ä¸€ä¸ªåŸºäºChatGPTçš„è‡ªåŠ¨è®ºæ–‡æ‘˜è¦ç”Ÿæˆå™¨ï¼Œåœ¨ChatPaperçš„åŸºç¡€ä¸Šè¿›è¡Œçš„æ›´æ–°ï¼Œé‡‡ç”¨äº†æœ€è¿‘ç”±Googleå¼€æºçš„Gemini Proå¤§æ¨¡å‹ã€‚ç›®å‰,æˆ‘ä»¬èƒ½å¤Ÿå¯¹ç”¨æˆ·è¾“å…¥çš„è®ºæ–‡è¿›è¡Œè‡ªåŠ¨æ€»ç»“ã€‚æœªæ¥,æˆ‘è¿˜è®¡åˆ’åŠ å…¥å¯¹è®ºæ–‡å›¾ç‰‡/è¡¨æ ¼/å…¬å¼çš„è¯†åˆ« extraction,ä»è€Œç”Ÿæˆæ›´å…¨é¢è€Œæ˜“è¯»çš„æ€»ç»“ã€‚</div><a class="blog-slider__button" href="Project/ChatPaperFree/" alt="">è¯¦æƒ…   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('å·²æŒ‚è½½butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>