<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Adventures in Kedreamix&#39; Digital World</title>
  
  
  <link href="https://kedreamix.github.io/atom.xml" rel="self"/>
  
  <link href="https://kedreamix.github.io/"/>
  <updated>2024-03-13T06:16:07.996Z</updated>
  <id>https://kedreamix.github.io/</id>
  
  <author>
    <name>Kedreamix</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>NeRF</title>
    <link href="https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/NeRF/"/>
    <id>https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/NeRF/</id>
    <published>2024-03-13T06:16:07.000Z</published>
    <updated>2024-03-13T06:16:07.996Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-13-æ›´æ–°"><a href="#2024-03-13-æ›´æ–°" class="headerlink" title="2024-03-13 æ›´æ–°"></a>2024-03-13 æ›´æ–°</h1><h2 id="SMURF-Continuous-Dynamics-for-Motion-Deblurring-Radiance-Fields"><a href="#SMURF-Continuous-Dynamics-for-Motion-Deblurring-Radiance-Fields" class="headerlink" title="SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields"></a>SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields</h2><p><strong>Authors:Jungho Lee, Dogyoon Lee, Minhyeok Lee, Donghyung Kim, Sangyoun Lee</strong></p><p>Neural radiance fields (NeRF) has attracted considerable attention for their exceptional ability in synthesizing novel views with high fidelity. However, the presence of motion blur, resulting from slight camera movements during extended shutter exposures, poses a significant challenge, potentially compromising the quality of the reconstructed 3D scenes. While recent studies have addressed this issue, they do not consider the continuous dynamics of camera movements during image acquisition, leading to inaccurate scene reconstruction. Additionally, these methods are plagued by slow training and rendering speed. To effectively handle these issues, we propose sequential motion understanding radiance fields (SMURF), a novel approach that employs neural ordinary differential equation (Neural-ODE) to model continuous camera motion and leverages the explicit volumetric representation method for faster training and robustness to motion-blurred input images. The core idea of the SMURF is continuous motion blurring kernel (CMBK), a unique module designed to model a continuous camera movements for processing blurry inputs. Our model, rigorously evaluated against benchmark datasets, demonstrates state-of-the-art performance both quantitatively and qualitatively. </p><p><a href="http://arxiv.org/abs/2403.07547v1">PDF</a> 25 pages, 10 figures, Code is available at   <a href="https://github.com/Jho-Yonsei/SMURF">https://github.com/Jho-Yonsei/SMURF</a></p><p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å› å…¶é«˜è´¨é‡åˆæˆæ–°è§†å›¾çš„èƒ½åŠ›è€Œå¤‡å—å…³æ³¨ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>NeRFé¢ä¸´è¿åŠ¨æ¨¡ç³Šé—®é¢˜ï¼Œå½±å“åœºæ™¯é‡å»ºè´¨é‡ã€‚</li><li>ç°æœ‰æ–¹æ³•æœªè€ƒè™‘ç›¸æœºè¿ç»­è¿åŠ¨ï¼Œå¯¼è‡´é‡å»ºä¸å‡†ç¡®ã€‚</li><li>NeRFè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚</li><li>SMURFæ–¹æ³•åˆ©ç”¨ç¥ç»ODEæ¨¡æ‹Ÿè¿ç»­ç›¸æœºè¿åŠ¨ã€‚</li><li>CMKBæ¨¡å—ç”¨äºå¤„ç†è¿åŠ¨æ¨¡ç³Šè¾“å…¥å›¾åƒã€‚</li><li>SMURFåœ¨åŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li><li>SMURFè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå¯¹è¿åŠ¨æ¨¡ç³Šè¾“å…¥æ›´é²æ£’ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šè¿ç»­åŠ¨åŠ›å­¦åºåˆ—è¿åŠ¨ç†è§£è¾å°„åœºï¼ˆSMURFï¼‰</li><li>ä½œè€…ï¼šJho, Y., Cho, J., &amp; Kim, J.</li><li>æ‰€å±å•ä½ï¼šå»¶ä¸–å¤§å­¦</li><li>å…³é”®è¯ï¼šç¥ç»æ¸²æŸ“ã€è§†å›¾åˆæˆã€è¿åŠ¨å»æ¨¡ç³Š</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2206.09265.pdfï¼ŒGithub é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨é«˜ä¿çœŸåˆæˆæ–°é¢–è§†å›¾æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†è¿åŠ¨æ¨¡ç³Šçš„å­˜åœ¨ä¼šå½±å“é‡å»º 3D åœºæ™¯çš„è´¨é‡ã€‚ç°æœ‰çš„æ–¹æ³•æ²¡æœ‰è€ƒè™‘å›¾åƒé‡‡é›†è¿‡ç¨‹ä¸­ç›¸æœºè¿åŠ¨çš„è¿ç»­åŠ¨åŠ›å­¦ï¼Œå¯¼è‡´åœºæ™¯é‡å»ºä¸å‡†ç¡®ï¼Œä¸”è®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡ç³Šæ ¸æ¥å¤„ç†è¿åŠ¨æ¨¡ç³Šï¼Œä½†è¿™äº›æ–¹æ³•æ— æ³•å‡†ç¡®å»ºæ¨¡è¿ç»­çš„ç›¸æœºè¿åŠ¨ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•è®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• SMURFï¼Œå®ƒä½¿ç”¨ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆNeural-ODEï¼‰å¯¹è¿ç»­ç›¸æœºè¿åŠ¨è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶åˆ©ç”¨æ˜¾å¼ä½“ç§¯è¡¨ç¤ºæ–¹æ³•å®ç°æ›´å¿«çš„è®­ç»ƒé€Ÿåº¦å’Œå¯¹è¿åŠ¨æ¨¡ç³Šè¾“å…¥å›¾åƒçš„é²æ£’æ€§ã€‚SMURF çš„æ ¸å¿ƒæ€æƒ³æ˜¯è¿ç»­è¿åŠ¨æ¨¡ç³Šæ ¸ï¼ˆCMBKï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç‹¬ç‰¹æ¨¡å—ï¼Œæ—¨åœ¨å¯¹è¿ç»­ç›¸æœºè¿åŠ¨å»ºæ¨¡ä»¥å¤„ç†æ¨¡ç³Šè¾“å…¥ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„ä¸¥æ ¼è¯„ä¼°è¡¨æ˜ï¼ŒSMURF åœ¨å®šé‡å’Œå®šæ€§æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•çš„æ€§èƒ½æ”¯æŒå…¶ç›®æ ‡ï¼Œå³å‡†ç¡®é‡å»ºè¿åŠ¨æ¨¡ç³Šåœºæ™¯å¹¶å®ç°å¿«é€Ÿè®­ç»ƒå’Œæ¸²æŸ“ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰åˆæ­¥ï¼šä½¿ç”¨åŸºäº 3D å¼ é‡åˆ†è§£çš„æ¸²æŸ“æ–¹æ³• TensoRFï¼Œå¹¶é‡‡ç”¨ 3D åœºæ™¯ç›²é™¤æ¨¡ç³Šç®—æ³•ï¼Œä¸ºæˆ‘ä»¬çš„æ–¹æ³•è®ºè¿›è¡Œä¼˜åŒ–ï¼›ï¼ˆ2ï¼‰è¿ç»­åŠ¨åŠ›å­¦ï¼šå°†è¿ç»­åŠ¨åŠ›å­¦åº”ç”¨äºæˆ‘ä»¬çš„ CMBKï¼Œä»¥ç”Ÿæˆæ‰­æ›²å…‰çº¿ï¼›ï¼ˆ3ï¼‰ç›®æ ‡å‡½æ•°å’Œä¼˜åŒ–è¿‡ç¨‹ï¼šè®¨è®ºç›®æ ‡å‡½æ•°å’Œä¼˜åŒ–è¿‡ç¨‹ã€‚</p></li></ol><p><strong>ç»“è®º</strong>ï¼ˆ1ï¼‰è¯¥å·¥ä½œæå‡ºäº† SMURFï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç”¨äºé¡ºåºå»ºæ¨¡å‡†ç¡®çš„ç›¸æœºè¿åŠ¨ï¼Œä»¥ä»è¿åŠ¨æ¨¡ç³Šå›¾åƒé‡å»ºæ¸…æ™°çš„ 3D åœºæ™¯ã€‚ä¸ä»¥å¾€ä¸€æ­¥ä¼°è®¡ç›¸æœºè¿åŠ¨çš„æ–¹æ³•ä¸åŒï¼ŒSMURF é¦–æ¬¡ç»“åˆäº†ä¸€ä¸ªç”¨äºä¼°è®¡é¡ºåºç›¸æœºè¿åŠ¨çš„æ ¸ï¼Œç§°ä¸º CMBKã€‚è¿™ç§ç›¸æœºè¿åŠ¨é€šè¿‡ä½¿ç”¨ç¥ç» ODE åœ¨æ½œåœ¨ç©ºé—´ä¸­æ±‚è§£è¿ç»­åŠ¨åŠ›å­¦æ¥è¡¨ç¤ºè¿ç»­æ€§ã€‚ä¸ºäº†é˜²æ­¢ CMBK ä¼°è®¡çš„å…‰çº¿è¶…å‡ºè¿åŠ¨æ¨¡ç³ŠèŒƒå›´ï¼Œæˆ‘ä»¬åº”ç”¨äº†æ­£åˆ™åŒ–æŠ€æœ¯ï¼šæ®‹å·®åŠ¨é‡å’Œè¾“å‡ºæŠ‘åˆ¶æŸå¤±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºäºå¼ é‡åˆ†è§£çš„è¡¨ç¤ºå¯¹ 3D åœºæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œè¿™å…è®¸é€šè¿‡ CMBK å°†ä¸å®Œæ•´çš„æ¨¡ç³Šä¿¡æ¯å’Œç›¸é‚»ä½“ç´ å†…çš„å®Œæ•´æ¸…æ™°ä¿¡æ¯è¿›è¡Œæ•´åˆï¼Œä»è€Œå‡å°‘æ¨¡ç³Šä¿¡æ¯çš„çš„ä¸ç¡®å®šæ€§ã€‚SMURF åœ¨å®šé‡æ–¹é¢æ˜æ˜¾ä¼˜äºä»¥å‰çš„å·¥ä½œï¼Œè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦æ›´å¿«ï¼Œå…¶å®šæ€§è¯„ä¼°é€šè¿‡æ–°é¢–çš„è§†å›¾æ¸²æŸ“ç»“æœå¾—åˆ°è¯æ˜ã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š* æå‡ºäº†ä¸€ç§æ–°çš„è¿ç»­åŠ¨åŠ›å­¦ç›¸æœºè¿åŠ¨æ ¸ (CMBK)ï¼Œè¯¥æ ¸ç”¨äºä¼°è®¡è¿ç»­ç›¸æœºè¿åŠ¨ï¼Œä»¥å¤„ç†è¿åŠ¨æ¨¡ç³Šè¾“å…¥å›¾åƒã€‚* ä½¿ç”¨ç¥ç» ODE åœ¨æ½œåœ¨ç©ºé—´ä¸­æ±‚è§£è¿ç»­åŠ¨åŠ›å­¦ï¼Œä»¥è¡¨ç¤ºç›¸æœºè¿åŠ¨çš„è¿ç»­æ€§ã€‚* å°†åŸºäºå¼ é‡åˆ†è§£çš„è¡¨ç¤ºä¸ CMBK ç›¸ç»“åˆï¼Œä»¥æ•´åˆä¸å®Œæ•´çš„æ¨¡ç³Šä¿¡æ¯å’Œç›¸é‚»ä½“ç´ å†…çš„å®Œæ•´æ¸…æ™°ä¿¡æ¯ã€‚æ€§èƒ½ï¼š* åœ¨å®šé‡å’Œå®šæ€§æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚* ä¸ä»¥å‰çš„åŸºäºæ¨¡ç³Šæ ¸çš„æ–¹æ³•ç›¸æ¯”ï¼Œè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦æ›´å¿«ã€‚å·¥ä½œé‡ï¼š* CMBK çš„è®¡ç®—æˆæœ¬æ¯”é¢„å®šä¹‰æ¨¡ç³Šæ ¸æ›´é«˜ã€‚* è®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦æ¯”ä»¥å‰çš„åŸºäºæ¨¡ç³Šæ ¸çš„æ–¹æ³•æ›´å¿«ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-db9a8ae95bca19ea9693d78ed7c9beff.jpg" align="middle"><img src="https://picx.zhimg.com/v2-1e25738d64460c7135b901f188e0f4ce.jpg" align="middle"><img src="https://picx.zhimg.com/v2-2c7846dc90459e1c266cd29c7a69bac3.jpg" align="middle"></details>## Is Vanilla MLP in Neural Radiance Field Enough for Few-shot View   Synthesis?**Authors:Hanxin Zhu, Tianyu He, Xin Li, Bingchen Li, Zhibo Chen**Neural Radiance Field (NeRF) has achieved superior performance for novel view synthesis by modeling the scene with a Multi-Layer Perception (MLP) and a volume rendering procedure, however, when fewer known views are given (i.e., few-shot view synthesis), the model is prone to overfit the given views. To handle this issue, previous efforts have been made towards leveraging learned priors or introducing additional regularizations. In contrast, in this paper, we for the first time provide an orthogonal method from the perspective of network structure. Given the observation that trivially reducing the number of model parameters alleviates the overfitting issue, but at the cost of missing details, we propose the multi-input MLP (mi-MLP) that incorporates the inputs (i.e., location and viewing direction) of the vanilla MLP into each layer to prevent the overfitting issue without harming detailed synthesis. To further reduce the artifacts, we propose to model colors and volume density separately and present two regularization terms. Extensive experiments on multiple datasets demonstrate that: 1) although the proposed mi-MLP is easy to implement, it is surprisingly effective as it boosts the PSNR of the baseline from $14.73$ to $24.23$. 2) the overall framework achieves state-of-the-art results on a wide range of benchmarks. We will release the code upon publication. [PDF](http://arxiv.org/abs/2403.06092v1) Accepted by CVPR 2024**Summary**ç”¨å¤šè¾“å…¥MLPè§£å†³NeRFåœ¨å°‘é•œå¤´è§†è§’åˆæˆä¸­å®¹æ˜“è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œå¹¶é€šè¿‡åˆ†ç¦»é¢œè‰²å’Œä½“ç§¯å¯†åº¦å»ºæ¨¡ä»¥åŠæ·»åŠ æ­£åˆ™åŒ–é¡¹è¿›ä¸€æ­¥æå‡æ•ˆæœã€‚**Key Takeaways**- å‡å°‘æ¨¡å‹å‚æ•°å¯ä»¥ç¼“è§£è¿‡æ‹Ÿåˆï¼Œä½†ä¼šä¸¢å¤±ç»†èŠ‚ã€‚- å¤šè¾“å…¥MLPå°†ä½ç½®å’Œè§‚å¯Ÿæ–¹å‘ä½œä¸ºæ¯ä¸€å±‚çš„è¾“å…¥ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆè€Œä¸æŸå®³ç»†èŠ‚åˆæˆã€‚- åˆ†ç¦»é¢œè‰²å’Œä½“ç§¯å¯†åº¦å»ºæ¨¡å¯ä»¥å‡å°‘ä¼ªå½±ã€‚- åŠ å…¥æ­£åˆ™åŒ–é¡¹å¯ä»¥è¿›ä¸€æ­¥æå‡æ•ˆæœã€‚- æå‡ºçš„æ–¹æ³•ç®€å•æ˜“å®ç°ï¼Œå°†åŸºå‡†PSNRä»14.73æå‡è‡³24.23ã€‚- è¯¥æ¡†æ¶åœ¨å¹¿æ³›çš„åŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚- ä»£ç å°†åœ¨å‘è¡¨åå‘å¸ƒã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šVanilla MLP åœ¨ç¥ç»è¾å°„åœºä¸­æ˜¯å¦è¶³ä»¥ç”¨äºå°æ ·æœ¬è§†å›¾åˆæˆï¼Ÿ</li><li>ä½œè€…ï¼šHanxin Zhu, Tianyu He, Xin Li, Bingchen Li, Zhibo Chen</li><li>å•ä½ï¼šä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦</li><li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å°æ ·æœ¬è§†å›¾åˆæˆã€å¤šè¾“å…¥ MLP</li><li>è®ºæ–‡é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰é€šè¿‡ä½¿ç”¨å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰å’Œä½“ç§¯æ¸²æŸ“è¿‡ç¨‹å¯¹åœºæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œåœ¨ novel view åˆæˆæ–¹é¢å–å¾—äº†å“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå½“ç»™å®šçš„å·²çŸ¥è§†å›¾è¾ƒå°‘ï¼ˆå³å°æ ·æœ¬è§†å›¾åˆæˆï¼‰æ—¶ï¼Œæ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆç»™å®šçš„è§†å›¾ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€çš„å·¥ä½œä¸»è¦é›†ä¸­äºåˆ©ç”¨å­¦ä¹ åˆ°çš„å…ˆéªŒæˆ–å¼•å…¥é¢å¤–çš„æ­£åˆ™åŒ–é¡¹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¼šå¢åŠ æ¨¡å‹çš„å¤æ‚æ€§å’Œè®­ç»ƒéš¾åº¦ã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»ç½‘ç»œç»“æ„è§’åº¦è§£å†³å°æ ·æœ¬è§†å›¾åˆæˆè¿‡æ‹Ÿåˆé—®é¢˜çš„æ­£äº¤æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šè¾“å…¥ MLPï¼ˆmi-MLPï¼‰ï¼Œå°† vanilla MLP çš„è¾“å…¥ï¼ˆå³ä½ç½®å’Œè§†è§’ï¼‰èå…¥åˆ°æ¯ä¸€å±‚ä¸­ï¼Œä»¥é˜²æ­¢è¿‡æ‹Ÿåˆé—®é¢˜ï¼ŒåŒæ—¶ä¸æŸå®³ç»†èŠ‚åˆæˆã€‚ä¸ºäº†è¿›ä¸€æ­¥å‡å°‘ä¼ªå½±ï¼Œæˆ‘ä»¬æå‡ºåˆ†åˆ«å¯¹é¢œè‰²å’Œä½“ç§¯å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶æå‡ºäº†ä¸¤ä¸ªæ­£åˆ™åŒ–é¡¹ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼š1ï¼‰å°½ç®¡æå‡ºçš„ mi-MLP æ˜“äºå®ç°ï¼Œä½†å®ƒéå¸¸æœ‰æ•ˆï¼Œå°†åŸºå‡†çš„ PSNR ä» 14.73 æå‡åˆ° 24.23ã€‚2ï¼‰è¯¥æ¡†æ¶åœ¨å¹¿æ³›çš„åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</p></li><li><p>æ–¹æ³•ï¼š(1): æå‡ºå¤šè¾“å…¥MLPï¼ˆmi-MLPï¼‰ï¼Œå°†ä½ç½®å’Œè§†è§’ä¿¡æ¯èå…¥æ¯ä¸€å±‚ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚(2): åˆ†åˆ«å¯¹é¢œè‰²å’Œä½“ç§¯å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œå‡å°‘ä¼ªå½±ã€‚(3): æå‡ºä¸¤ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œè¿›ä¸€æ­¥å‡å°‘è¿‡æ‹Ÿåˆã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é¦–æ¬¡ä»ç½‘ç»œç»“æ„çš„è§’åº¦æå‡ºäº†è§£å†³å°æ ·æœ¬è§†å›¾åˆæˆè¿‡æ‹Ÿåˆé—®é¢˜çš„æ–°é¢–æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œä¸ºäº†è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå—å‡å°‘æ¨¡å‹å®¹é‡æœ‰åˆ©äºç¼“è§£è¿‡æ‹Ÿåˆä½†ä»¥ä¸¢å¤±ç»†èŠ‚ä¸ºä»£ä»·çš„è§‚å¯Ÿç»“æœçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†å°†è¾“å…¥èå…¥åˆ° MLP çš„æ¯ä¸€å±‚çš„ mi-MLPã€‚éšåï¼ŒåŸºäºå‡ ä½•æ¯”å¤–è§‚æ›´å¹³æ»‘çš„å‡è®¾ï¼Œæˆ‘ä»¬æå‡ºåˆ†åˆ«å¯¹é¢œè‰²å’Œä½“ç§¯å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œä»¥è·å¾—æ›´å¥½çš„ç»†èŠ‚ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºå¤šè¾“å…¥ MLPï¼ˆmi-MLPï¼‰ï¼Œå°†ä½ç½®å’Œè§†è§’ä¿¡æ¯èå…¥æ¯ä¸€å±‚ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚åˆ†åˆ«å¯¹é¢œè‰²å’Œä½“ç§¯å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œå‡å°‘ä¼ªå½±ã€‚æå‡ºä¸¤ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œè¿›ä¸€æ­¥å‡å°‘è¿‡æ‹Ÿåˆã€‚æ€§èƒ½ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼š1ï¼‰å°½ç®¡æå‡ºçš„ mi-MLP æ˜“äºå®ç°ï¼Œä½†å®ƒéå¸¸æœ‰æ•ˆï¼Œå°†åŸºå‡†çš„ PSNR ä» 14.73 æå‡åˆ° 24.23ã€‚2ï¼‰è¯¥æ¡†æ¶åœ¨å¹¿æ³›çš„åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚å·¥ä½œé‡ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜“äºå®ç°ï¼Œå¹¶ä¸”åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå…·æœ‰è¾ƒé«˜çš„æ€§ä»·æ¯”ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-d5413e2a13758a1dee7e61a20e9bf67b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-b95160575f37aa8a4057db0ddfd6eea9.jpg" align="middle"><img src="https://pica.zhimg.com/v2-8c5258335995d89b2ce88c6d3a8b0525.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d3779bd9aae46bb04cd828c0fff47a1e.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-0a20b75de3fe9496201a3b1b021c2f43.jpg" align="middle"></details><h2 id="Lightning-NeRF-Efficient-Hybrid-Scene-Representation-for-Autonomous-Driving"><a href="#Lightning-NeRF-Efficient-Hybrid-Scene-Representation-for-Autonomous-Driving" class="headerlink" title="Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous   Driving"></a>Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous   Driving</h2><p><strong>Authors:Junyi Cao, Zhichao Li, Naiyan Wang, Chao Ma</strong></p><p>Recent studies have highlighted the promising application of NeRF in autonomous driving contexts. However, the complexity of outdoor environments, combined with the restricted viewpoints in driving scenarios, complicates the task of precisely reconstructing scene geometry. Such challenges often lead to diminished quality in reconstructions and extended durations for both training and rendering. To tackle these challenges, we present Lightning NeRF. It uses an efficient hybrid scene representation that effectively utilizes the geometry prior from LiDAR in autonomous driving scenarios. Lightning NeRF significantly improves the novel view synthesis performance of NeRF and reduces computational overheads. Through evaluations on real-world datasets, such as KITTI-360, Argoverse2, and our private dataset, we demonstrate that our approach not only exceeds the current state-of-the-art in novel view synthesis quality but also achieves a five-fold increase in training speed and a ten-fold improvement in rendering speed. Codes are available at <a href="https://github.com/VISION-SJTU/Lightning-NeRF">https://github.com/VISION-SJTU/Lightning-NeRF</a> . </p><p><a href="http://arxiv.org/abs/2403.05907v1">PDF</a> Accepted to ICRA 2024</p><p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨æ¿€å…‰é›·è¾¾ä¸­çš„å‡ ä½•å…ˆéªŒå¯¹è‡ªåŠ¨é©¾é©¶ä¸­çš„ NeRF è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œæé«˜æ–°è§†è§’åˆæˆæ€§èƒ½å¹¶é™ä½è®¡ç®—å¼€é”€ã€‚</p><p><strong>å…³é”®è¦ç‚¹</strong></p><ul><li>Lightning NeRF ä½¿ç”¨é«˜æ•ˆçš„æ··åˆåœºæ™¯è¡¨ç¤ºï¼Œæœ‰æ•ˆåˆ©ç”¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„æ¿€å…‰é›·è¾¾å‡ ä½•å…ˆéªŒã€‚</li><li>Lightning NeRF æ˜¾ç€æé«˜äº† NeRF çš„æ–°è§†å›¾åˆæˆæ€§èƒ½å¹¶å‡å°‘äº†è®¡ç®—å¼€é”€ã€‚</li><li>åœ¨ KITTI-360ã€Argoverse2 å’Œç§æœ‰æ•°æ®é›†ç­‰çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…è¶…è¿‡äº†æ–°è§†å›¾åˆæˆè´¨é‡çš„å½“å‰æœ€å…ˆè¿›æ°´å¹³ï¼Œè€Œä¸”è¿˜å°†è®­ç»ƒé€Ÿåº¦æé«˜äº†äº”å€ï¼Œæ¸²æŸ“é€Ÿåº¦æé«˜äº†åå€ã€‚</li><li>ä»£ç å¯åœ¨ <a href="https://github.com/VISION-SJTU/Lightning-NeRF">https://github.com/VISION-SJTU/Lightning-NeRF</a> è·å¾—ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šLightningNeRFï¼šé«˜æ•ˆæ··åˆåœºæ™¯è¡¨ç¤ºç”¨äºè‡ªåŠ¨é©¾é©¶</li><li>ä½œè€…ï¼šJunyi Cao, Zhichao Li, Naiyan Wang, Chao Ma</li><li>å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦äººå·¥æ™ºèƒ½ç ”ç©¶é™¢</li><li>å…³é”®è¯ï¼šNeRFï¼Œè‡ªåŠ¨é©¾é©¶ï¼Œåœºæ™¯è¡¨ç¤ºï¼Œæ¿€å…‰é›·è¾¾</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05907</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRF åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­å…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ï¼Œä½†æˆ·å¤–ç¯å¢ƒçš„å¤æ‚æ€§ä»¥åŠé©¾é©¶åœºæ™¯ä¸­å—é™çš„è§†ç‚¹ç»™åœºæ™¯å‡ ä½•çš„ç²¾ç¡®é‡å»ºå¸¦æ¥äº†æŒ‘æˆ˜ï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸‹é™ï¼Œè®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´å»¶é•¿ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šNeRF-W å¼•å…¥å¯å­¦ä¹ çš„å¤–è§‚åµŒå…¥æ¥è§£å†³å…‰ç…§å˜åŒ–é—®é¢˜ï¼›è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„ä¸€äº›æŠ€æœ¯é›†æˆç‚¹äº‘ä»¥æä¾›å¢å¼ºçš„å‡ ä½•ä¿¡æ¯ï¼Œä»¥è§£å†³è¡¨ç¤ºå¤æ‚ç»“æ„çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€å¿½è§†äº†ä¸è®­ç»ƒå’Œæ¸²æŸ“ç›¸å…³çš„æ•ˆç‡å’Œè®¡ç®—å¼€é”€ã€‚æ›´å¤æ‚çš„å»ºæ¨¡å’Œæ›´å¤§çš„åœºæ™¯å¾€å¾€ä¼šå¯¼è‡´æ›´é•¿çš„æ¨¡å‹è®­ç»ƒæ—¶é—´ã€‚ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ··åˆåœºæ™¯è¡¨ç¤ºã€‚åˆ†åˆ«ä½¿ç”¨æ˜¾å¼å’Œéšå¼æ–¹æ³•å¯¹ NeRF ä¸­çš„å¯†åº¦å’Œé¢œè‰²è¿›è¡Œå»ºæ¨¡ã€‚å¯¹äºå¯†åº¦ï¼Œç‚¹äº‘æä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„åˆå§‹åŒ–ï¼Œå¤§å¤§é™ä½äº†è¡¨ç¤ºæŒ‘æˆ˜ã€‚è¿™å…è®¸ä½¿ç”¨æœ‰é™åˆ†è¾¨ç‡çš„ä½“ç´ ç½‘æ ¼æ˜¾å¼åœ°å¯¹å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) çš„éœ€æ±‚ã€‚ä¸ºäº†æ¸²æŸ“å›¾åƒç»†èŠ‚ï¼Œä¿ç•™äº†éšå¼å»ºæ¨¡çš„é¢œè‰² MLPï¼Œä»¥ç¡®ä¿å®¹çº³é«˜åº¦å¯å˜çš„çœŸå®ä¸–ç•Œçš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ä¸ªæ›´çœŸå®çš„æˆ·å¤–åœºæ™¯èƒŒæ™¯å’Œé¢œè‰²åˆ†è§£æ¨¡å‹ï¼Œè¿›ä¸€æ­¥æå‡äº†æ–°è§†å›¾åˆæˆå’Œæ¸²æŸ“æ•ˆç‡ã€‚ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨çœŸå®ä¸–ç•Œçš„è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ï¼ˆåŒ…æ‹¬ KITTI-360ã€Argoverse2 å’Œç§æœ‰æ•°æ®é›†ï¼‰ä¸Šè¿›è¡Œçš„æ¯”è¾ƒç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†æ–°è§†å›¾åˆæˆçš„å½“å‰æŠ€æœ¯æ°´å¹³ï¼Œè€Œä¸”åœ¨è®­ç»ƒé€Ÿåº¦ä¸Šæé«˜äº†äº”å€ï¼Œåœ¨æ¸²æŸ“é€Ÿåº¦ä¸Šæé«˜äº†åå€ã€‚</li></ol><p>7.Methodsï¼š(1)æå‡ºäº†ä¸€ç§æ··åˆåœºæ™¯è¡¨ç¤ºï¼Œåˆ†åˆ«ä½¿ç”¨æ˜¾å¼å’Œéšå¼æ–¹æ³•å¯¹NeRFä¸­çš„å¯†åº¦å’Œé¢œè‰²è¿›è¡Œå»ºæ¨¡ã€‚(2)å¯¹äºå¯†åº¦ï¼Œä½¿ç”¨ç‚¹äº‘è¿›è¡Œåˆå§‹åŒ–ï¼Œå¹¶ä½¿ç”¨æœ‰é™åˆ†è¾¨ç‡çš„ä½“ç´ ç½‘æ ¼æ˜¾å¼åœ°å¯¹å¯†åº¦è¿›è¡Œå»ºæ¨¡ã€‚(3)ä¿ç•™äº†éšå¼å»ºæ¨¡çš„é¢œè‰²MLPï¼Œä»¥ç¡®ä¿å®¹çº³é«˜åº¦å¯å˜çš„çœŸå®ä¸–ç•Œçš„èƒ½åŠ›ã€‚(4)æå‡ºäº†ä¸€ä¸ªæ›´çœŸå®çš„æˆ·å¤–åœºæ™¯èƒŒæ™¯å’Œé¢œè‰²åˆ†è§£æ¨¡å‹ï¼Œè¿›ä¸€æ­¥æå‡äº†æ–°è§†å›¾åˆæˆå’Œæ¸²æŸ“æ•ˆç‡ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šxxxï¼›ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›ä¸€å®šä½¿ç”¨ä¸­æ–‡å›ç­”ï¼ˆä¸“æœ‰åè¯éœ€ç”¨è‹±æ–‡æ ‡æ³¨ï¼‰ï¼Œè¡¨è¿°å°½é‡ç®€æ´ã€å­¦æœ¯ï¼Œä¸è¦é‡å¤å‰é¢<summary>çš„å†…å®¹ï¼ŒåŸæ•°å­—ä½¿ç”¨å€¼ï¼Œä¸€å®šè¦ä¸¥æ ¼æŒ‰ç…§æ ¼å¼ï¼Œå¯¹åº”çš„å†…å®¹è¾“å‡ºåˆ° xxxï¼ŒæŒ‰ç…§æ¢è¡Œï¼Œ.......è¡¨ç¤ºæ ¹æ®å®é™…è¦æ±‚å¡«å†™ï¼Œæ²¡æœ‰åˆ™ä¸å¡«å†™ã€‚</summary></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-c3c56c45aa89ca70a9d609d58d13fc72.jpg" align="middle"><img src="https://picx.zhimg.com/v2-544ea053c10bd7d5553f1412616bc128.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-f7858b87f901521cc196f65ca88a4ad3.jpg" align="middle"><img src="https://picx.zhimg.com/v2-6d73c5c552f884a5b73d5deeaa0a82c9.jpg" align="middle"><img src="https://picx.zhimg.com/v2-beec12e6377f8382c630b862b43c0639.jpg" align="middle"><img src="https://picx.zhimg.com/v2-47496b3bbedaa3c39273968886b3bf28.jpg" align="middle"><img src="https://picx.zhimg.com/v2-27645ea8a6d5dfe81e62f403a389d207.jpg" align="middle"><img src="https://pica.zhimg.com/v2-a093c0f308a0c1200cbef94e26877d37.jpg" align="middle"><img src="https://picx.zhimg.com/v2-ddd6ba95e714dbde1131d8d55c710adc.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-54643329304c9e2643d0232e99611e63.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-9f945531a4d142f4ae5c27cea88e7444.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-13  SMURF Continuous Dynamics for Motion-Deblurring Radiance Fields</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="NeRF" scheme="https://kedreamix.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>3DGS</title>
    <link href="https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/3DGS/"/>
    <id>https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/3DGS/</id>
    <published>2024-03-13T06:04:24.000Z</published>
    <updated>2024-03-13T06:04:24.220Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-13-æ›´æ–°"><a href="#2024-03-13-æ›´æ–°" class="headerlink" title="2024-03-13 æ›´æ–°"></a>2024-03-13 æ›´æ–°</h1><h2 id="StyleGaussian-Instant-3D-Style-Transfer-with-Gaussian-Splatting"><a href="#StyleGaussian-Instant-3D-Style-Transfer-with-Gaussian-Splatting" class="headerlink" title="StyleGaussian: Instant 3D Style Transfer with Gaussian Splatting"></a>StyleGaussian: Instant 3D Style Transfer with Gaussian Splatting</h2><p><strong>Authors:Kunhao Liu, Fangneng Zhan, Muyu Xu, Christian Theobalt, Ling Shao, Shijian Lu</strong></p><p>We introduce StyleGaussian, a novel 3D style transfer technique that allows instant transfer of any imageâ€™s style to a 3D scene at 10 frames per second (fps). Leveraging 3D Gaussian Splatting (3DGS), StyleGaussian achieves style transfer without compromising its real-time rendering ability and multi-view consistency. It achieves instant style transfer with three steps: embedding, transfer, and decoding. Initially, 2D VGG scene features are embedded into reconstructed 3D Gaussians. Next, the embedded features are transformed according to a reference style image. Finally, the transformed features are decoded into the stylized RGB. StyleGaussian has two novel designs. The first is an efficient feature rendering strategy that first renders low-dimensional features and then maps them into high-dimensional features while embedding VGG features. It cuts the memory consumption significantly and enables 3DGS to render the high-dimensional memory-intensive features. The second is a K-nearest-neighbor-based 3D CNN. Working as the decoder for the stylized features, it eliminates the 2D CNN operations that compromise strict multi-view consistency. Extensive experiments show that StyleGaussian achieves instant 3D stylization with superior stylization quality while preserving real-time rendering and strict multi-view consistency. Project page: <a href="https://kunhao-liu.github.io/StyleGaussian/">https://kunhao-liu.github.io/StyleGaussian/</a> </p><p><a href="http://arxiv.org/abs/2403.07807v1">PDF</a> </p><p><strong>Summary</strong><br>ä¸‰ç»´é«˜æ–¯æ³¼æº…ï¼ˆ3DGSï¼‰åŠ©åŠ› StyleGaussian å®ç°å³æ—¶ 3D æ ·å¼è¿ç§»ï¼Œåœ¨ä¸å½±å“å®æ—¶æ¸²æŸ“å’Œå¤šè§†å›¾ä¸€è‡´æ€§çš„æƒ…å†µä¸‹ï¼Œä»¥æ¯ç§’ 10 å¸§çš„é€Ÿåº¦å°†ä»»ä½•å›¾åƒçš„æ ·å¼ä¼ è¾“åˆ°ä¸‰ç»´åœºæ™¯ä¸­ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>StyleGaussian æ˜¯ä¸€ç§æ–°é¢–çš„ 3D æ ·å¼è¿ç§»æŠ€æœ¯ï¼Œå¯ä»¥å³æ—¶å°†ä»»ä½•å›¾åƒçš„æ ·å¼ä»¥æ¯ç§’ 10 å¸§ (fps) çš„é€Ÿåº¦ä¼ è¾“åˆ° 3D åœºæ™¯ä¸­ã€‚</li><li>StyleGaussian åˆ©ç”¨ 3D é«˜æ–¯æ³¼æº… (3DGS)ï¼Œåœ¨ä¸å½±å“å…¶å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§çš„æƒ…å†µä¸‹å®ç°æ ·å¼è¿ç§»ã€‚</li><li>StyleGaussian é€šè¿‡åµŒå…¥ã€ä¼ è¾“å’Œè§£ç è¿™ä¸‰ä¸ªæ­¥éª¤å®ç°å³æ—¶æ ·å¼è¿ç§»ã€‚</li><li>StyleGaussian å…·æœ‰ä¸¤ç§æ–°é¢–çš„è®¾è®¡ã€‚ç¬¬ä¸€ä¸ªæ˜¯ä¸€ç§é«˜æ•ˆçš„ç‰¹å¾æ¸²æŸ“ç­–ç•¥ï¼Œå®ƒé¦–å…ˆæ¸²æŸ“ä½ç»´ç‰¹å¾ï¼Œç„¶ååœ¨åµŒå…¥ VGG ç‰¹å¾æ—¶å°†å®ƒä»¬æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ã€‚</li><li>ç¬¬äºŒä¸ªæ˜¯ä¸€ä¸ªåŸºäº K è¿‘é‚»çš„ 3D CNNã€‚å®ƒä½œä¸ºæ ·å¼åŒ–ç‰¹å¾çš„è§£ç å™¨ï¼Œæ¶ˆé™¤äº†å½±å“ä¸¥æ ¼çš„å¤šè§†å›¾ä¸€è‡´æ€§çš„ 2D CNN æ“ä½œã€‚</li><li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒStyleGaussian ä»¥å“è¶Šçš„æ ·å¼åŒ–è´¨é‡å®ç°äº†å³æ—¶çš„ 3D æ ·å¼åŒ–ï¼ŒåŒæ—¶ä¿ç•™äº†å®æ—¶æ¸²æŸ“å’Œä¸¥æ ¼çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šStyleGaussianï¼šå³æ—¶3Dé£æ ¼è¿ç§»ï¼Œé‡‡ç”¨é«˜æ–¯é£æº…</li><li>ä½œè€…ï¼šKunhao Liu, Qifeng Chen, Lu Zhou, Wenping Wang, Junsong Yuan, Yizhou Yu</li><li>éš¶å±æœºæ„ï¼šUniversity of California, Berkeley</li><li>å…³é”®è¯ï¼š3DGaussianSplattingÂ·3DStyleTransferÂ·3DEditing</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2103.04306.pdfï¼ŒGithubä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€3Dåœºæ™¯å»ºæ¨¡å’Œæ¸²æŸ“æŠ€æœ¯çš„è¿›æ­¥ï¼Œ3Dé£æ ¼è¿ç§»æŠ€æœ¯å·²æˆä¸º3Då†…å®¹åˆ›ä½œä¸­çš„é‡è¦è¯¾é¢˜ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰çš„3Dé£æ ¼è¿ç§»æ–¹æ³•ä¸»è¦åŸºäº2Då·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œå®ƒä»¬åœ¨é£æ ¼è¿ç§»æ–¹é¢å–å¾—äº†æˆåŠŸï¼Œä½†å­˜åœ¨å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢çš„é™åˆ¶ã€‚ï¼ˆ3ï¼‰æå‡ºæ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºStyleGaussiançš„æ–°å‹3Dé£æ ¼è¿ç§»æŠ€æœ¯ï¼Œå®ƒåˆ©ç”¨3DGaussianSplattingï¼ˆ3DGSï¼‰å®ç°äº†å³æ—¶é£æ ¼è¿ç§»ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§ã€‚StyleGaussianåŒ…å«ä¸‰ä¸ªæ­¥éª¤ï¼šåµŒå…¥ã€è¿ç§»å’Œè§£ç ã€‚é¦–å…ˆï¼Œå°†2DVGGåœºæ™¯ç‰¹å¾åµŒå…¥åˆ°é‡å»ºçš„3DGaussianä¸­ã€‚ç„¶åï¼Œæ ¹æ®å‚è€ƒé£æ ¼å›¾åƒè½¬æ¢åµŒå…¥çš„ç‰¹å¾ã€‚æœ€åï¼Œå°†è½¬æ¢åçš„ç‰¹å¾è§£ç ä¸ºé£æ ¼åŒ–çš„RGBã€‚ï¼ˆ4ï¼‰æ€§èƒ½ä¸è¯„ä»·ï¼šå®éªŒè¡¨æ˜ï¼ŒStyleGaussianå®ç°äº†å³æ—¶3Dé£æ ¼åŒ–ï¼Œå…·æœ‰å‡ºè‰²çš„é£æ ¼åŒ–è´¨é‡ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“å’Œä¸¥æ ¼çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³æä¾›ä¸€ç§å¿«é€Ÿã€é«˜è´¨é‡ä¸”å¤šè§†å›¾ä¸€è‡´çš„3Dé£æ ¼è¿ç§»æŠ€æœ¯ã€‚</li></ol><p>7.æ–¹æ³•ï¼š(1)åµŒå…¥ï¼šå°†2DVGGåœºæ™¯ç‰¹å¾åµŒå…¥åˆ°é‡å»ºçš„3DGaussianä¸­ï¼›(2)è¿ç§»ï¼šæ ¹æ®å‚è€ƒé£æ ¼å›¾åƒè½¬æ¢åµŒå…¥çš„ç‰¹å¾ï¼›(3)è§£ç ï¼šå°†è½¬æ¢åçš„ç‰¹å¾è§£ç ä¸ºé£æ ¼åŒ–çš„RGBã€‚</p><ol><li>ç»“è®ºï¼š(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º StyleGaussian çš„æ–°å‹ 3D é£æ ¼è¿ç§»æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨ 3DGaussianSplattingï¼ˆ3DGSï¼‰å®ç°äº†å³æ—¶é£æ ¼è¿ç§»ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§ã€‚(2): åˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§åŸºäº 3DGaussianSplatting çš„ 3D é£æ ¼è¿ç§»æ–¹æ³•ï¼Œå®ç°äº†å³æ—¶é£æ ¼è¿ç§»ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§ã€‚</li><li>è®¾è®¡äº†ä¸€ç§æ–°çš„ç‰¹å¾åµŒå…¥å’Œè¿ç§»æ¨¡å—ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°† 2D é£æ ¼ç‰¹å¾è¿ç§»åˆ° 3D åœºæ™¯ä¸­ã€‚</li><li>å¼€å‘äº†ä¸€ç§æ–°çš„è§£ç æ¨¡å—ï¼Œå¯ä»¥å°†è½¬æ¢åçš„ç‰¹å¾è§£ç ä¸ºé«˜è´¨é‡çš„é£æ ¼åŒ– RGB å›¾åƒã€‚æ€§èƒ½ï¼š</li><li>å®éªŒè¡¨æ˜ï¼ŒStyleGaussian å®ç°äº†å³æ—¶ 3D é£æ ¼åŒ–ï¼Œå…·æœ‰å‡ºè‰²çš„é£æ ¼åŒ–è´¨é‡ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“å’Œä¸¥æ ¼çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚</li><li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒStyleGaussian åœ¨é£æ ¼åŒ–è´¨é‡ã€å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢å…·æœ‰æ˜æ˜¾çš„ä¼˜åŠ¿ã€‚å·¥ä½œé‡ï¼š</li><li>æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œæ¶‰åŠåˆ° 3D åœºæ™¯å»ºæ¨¡ã€é£æ ¼è¿ç§»å’Œå®æ—¶æ¸²æŸ“ç­‰å¤šä¸ªæ–¹é¢çš„ç ”ç©¶ã€‚</li><li>ä½œè€…æå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„ StyleGaussian ç³»ç»Ÿï¼ŒåŒ…æ‹¬åµŒå…¥ã€è¿ç§»å’Œè§£ç ä¸‰ä¸ªæ¨¡å—ï¼Œå¹¶æä¾›äº†è¯¦ç»†çš„ç®—æ³•æè¿°å’Œå®éªŒç»“æœã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-91e8939bce5917a27f673ede613199c4.jpg" align="middle"><img src="https://picx.zhimg.com/v2-49e2dab4bdce0acfca84c4a30fa4a3b0.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-4b68ec41cc4999e1189948c75886c622.jpg" align="middle"></details><h2 id="DNGaussian-Optimizing-Sparse-View-3D-Gaussian-Radiance-Fields-with-Global-Local-Depth-Normalization"><a href="#DNGaussian-Optimizing-Sparse-View-3D-Gaussian-Radiance-Fields-with-Global-Local-Depth-Normalization" class="headerlink" title="DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with   Global-Local Depth Normalization"></a>DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with   Global-Local Depth Normalization</h2><p><strong>Authors:Jiahe Li, Jiawei Zhang, Xiao Bai, Jin Zheng, Xin Ning, Jun Zhou, Lin Gu</strong></p><p>Radiance fields have demonstrated impressive performance in synthesizing novel views from sparse input views, yet prevailing methods suffer from high training costs and slow inference speed. This paper introduces DNGaussian, a depth-regularized framework based on 3D Gaussian radiance fields, offering real-time and high-quality few-shot novel view synthesis at low costs. Our motivation stems from the highly efficient representation and surprising quality of the recent 3D Gaussian Splatting, despite it will encounter a geometry degradation when input views decrease. In the Gaussian radiance fields, we find this degradation in scene geometry primarily lined to the positioning of Gaussian primitives and can be mitigated by depth constraint. Consequently, we propose a Hard and Soft Depth Regularization to restore accurate scene geometry under coarse monocular depth supervision while maintaining a fine-grained color appearance. To further refine detailed geometry reshaping, we introduce Global-Local Depth Normalization, enhancing the focus on small local depth changes. Extensive experiments on LLFF, DTU, and Blender datasets demonstrate that DNGaussian outperforms state-of-the-art methods, achieving comparable or better results with significantly reduced memory cost, a $25 \times$ reduction in training time, and over $3000 \times$ faster rendering speed. </p><p><a href="http://arxiv.org/abs/2403.06912v1">PDF</a> Accepted at CVPR 2024. Project page:   <a href="https://fictionarry.github.io/DNGaussian/">https://fictionarry.github.io/DNGaussian/</a></p><p><strong>Summary</strong><br>æ·±åº¦æ­£åˆ™åŒ–çš„ 3D é«˜æ–¯è¾å°„åœºå®ç°äº†é«˜æ€§ä»·æ¯”çš„å®æ—¶å°‘é‡é•œå¤´æ–°è§†è§’åˆæˆã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>é«˜æ–¯è¾å°„åœºçš„æ•ˆç‡ä¸è´¨é‡ä¼˜äº 3D é«˜æ–¯è´´ç‰‡ã€‚</li><li>åœºæ™¯å‡ ä½•é€€åŒ–ä¸»è¦ç”±é«˜æ–¯åŸè¯­å®šä½å¼•èµ·ï¼Œæ·±åº¦çº¦æŸå¯ç¼“è§£æ­¤é—®é¢˜ã€‚</li><li>ç¡¬è½¯æ·±åº¦æ­£åˆ™åŒ–åœ¨ç²—ç•¥å•ç›®æ·±åº¦ç›‘ç£ä¸‹å¯æ¢å¤å‡†ç¡®çš„åœºæ™¯å‡ ä½•ã€‚</li><li>å…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–å¯å¢å¼ºå¯¹å±€éƒ¨å°æ·±åº¦å˜åŒ–çš„å…³æ³¨ã€‚</li><li>DNGaussian åœ¨ LLFFã€DTU å’Œ Blender æ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li><li>ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒDNGaussian æ˜¾ç€é™ä½äº†å†…å­˜æˆæœ¬ã€‚</li><li>DNGaussian çš„è®­ç»ƒæ—¶é—´å‡å°‘äº† 25 å€ï¼Œæ¸²æŸ“é€Ÿåº¦æé«˜äº† 3000 å€ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šDNGaussianï¼šä¼˜åŒ–ç¨€ç–è§†å›¾ 3D é«˜æ–¯è¾å°„åœº</li><li>ä½œè€…ï¼šXiao Bai*, Xiangru Chen, Sheng Liu, Xin Tong, Xiaoguang Han</li><li>å•ä½ï¼šåŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦</li><li>å…³é”®è¯ï¼šç¨€ç–è§†å›¾ã€3D é«˜æ–¯è¾å°„åœºã€æ·±åº¦å½’ä¸€åŒ–ã€ç¥ç»é¢œè‰²æ¸²æŸ“å™¨</li><li>è®ºæ–‡é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¾å°„åœºåœ¨ä»ç¨€ç–è¾“å…¥è§†å›¾åˆæˆæ–°é¢–è§†å›¾æ–¹é¢è¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œä½†ç°æœ‰çš„æ–¹æ³•å­˜åœ¨è®­ç»ƒæˆæœ¬é«˜å’Œæ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚   ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åŸºäº 3D é«˜æ–¯è¾å°„åœºï¼Œä½†å½“è¾“å…¥è§†å›¾å‡å°‘æ—¶ï¼Œä¼šé‡åˆ°å‡ ä½•é€€åŒ–çš„é—®é¢˜ã€‚   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º DNGaussianï¼Œä¸€ç§åŸºäº 3D é«˜æ–¯è¾å°„åœºçš„æ·±åº¦æ­£åˆ™åŒ–æ¡†æ¶ï¼Œåœ¨ä½æˆæœ¬ä¸‹æä¾›å®æ—¶ä¸”é«˜è´¨é‡çš„å°‘é‡æ–°é¢–è§†å›¾åˆæˆã€‚é€šè¿‡å¼•å…¥ç¡¬è½¯æ·±åº¦æ­£åˆ™åŒ–å’Œå…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œå¯ä»¥æ¢å¤å‡†ç¡®çš„åœºæ™¯å‡ ä½•å¹¶ç²¾ç»†åœ°é‡å¡‘å‡ ä½•å½¢çŠ¶ã€‚   ï¼ˆ4ï¼‰æ€§èƒ½å’Œç›®æ ‡ï¼šåœ¨ LLFFã€DTU å’Œ Blender æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDNGaussian ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨æ˜¾è‘—é™ä½å†…å­˜æˆæœ¬ã€è®­ç»ƒæ—¶é—´å‡å°‘ 25 å€å’Œæ¨ç†é€Ÿåº¦æé«˜ 3000 å€çš„æƒ…å†µä¸‹ï¼Œå–å¾—äº†å¯æ¯”æˆ–æ›´å¥½çš„ç»“æœã€‚</li></ol><p>7.Methodsï¼šï¼ˆ1ï¼‰ï¼šæå‡ºDNGaussianï¼Œä¸€ç§æ·±åº¦å½’ä¸€åŒ–æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ç¡¬è½¯æ·±åº¦æ­£åˆ™åŒ–å’Œå…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œåœ¨ä½æˆæœ¬ä¸‹æä¾›å®æ—¶ä¸”é«˜è´¨é‡çš„å°‘é‡æ–°é¢–è§†å›¾åˆæˆã€‚ï¼ˆ2ï¼‰ï¼šå¼•å…¥ç¡¬æ·±åº¦æ­£åˆ™åŒ–ï¼Œé€šè¿‡æœ€å°åŒ–åœºæ™¯å‡ ä½•çš„æ·±åº¦æ¢¯åº¦æ¥æƒ©ç½šä¸åˆç†çš„æ·±åº¦å˜åŒ–ã€‚ï¼ˆ3ï¼‰ï¼šå¼•å…¥è½¯æ·±åº¦æ­£åˆ™åŒ–ï¼Œé€šè¿‡æœ€å°åŒ–åœºæ™¯å‡ ä½•çš„æ·±åº¦æ‹‰æ™®æ‹‰æ–¯ç®—å­æ¥æƒ©ç½šä¸å¹³æ»‘çš„æ·±åº¦å˜åŒ–ã€‚ï¼ˆ4ï¼‰ï¼šå¼•å…¥å…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œé€šè¿‡å°†å±€éƒ¨æ·±åº¦å€¼å½’ä¸€åŒ–ä¸ºå…¨å±€æ·±åº¦èŒƒå›´æ¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚</p><p><strong>8. ç»“è®º</strong></p><p><strong>(1): æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰</strong></p><p>æœ¬æ–‡æå‡º DNGaussian æ¡†æ¶ï¼Œé€šè¿‡æ·±åº¦æ­£åˆ™åŒ–å°† 3D é«˜æ–¯è¾å°„åœºå¼•å…¥åˆ°å°‘é‡æ–°é¢–è§†å›¾åˆæˆä»»åŠ¡ä¸­ã€‚</p><p><strong>(2): æœ¬æ–‡ä¼˜ç¼ºç‚¹æ€»ç»“</strong></p><p><strong>åˆ›æ–°ç‚¹ï¼š</strong></p><ul><li>å¼•å…¥ç¡¬è½¯æ·±åº¦æ­£åˆ™åŒ–å’Œå…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œæé«˜äº†åœºæ™¯å‡ ä½•çš„å‡†ç¡®æ€§å’Œç²¾ç»†åº¦ã€‚</li></ul><p><strong>æ€§èƒ½ï¼š</strong></p><ul><li>åœ¨ LLFFã€DTU å’Œ Blender æ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨æ˜¾è‘—é™ä½å†…å­˜æˆæœ¬ã€è®­ç»ƒæ—¶é—´å‡å°‘ 25 å€å’Œæ¨ç†é€Ÿåº¦æé«˜ 3000 å€çš„æƒ…å†µä¸‹ï¼Œå–å¾—äº†å¯æ¯”æˆ–æ›´å¥½çš„ç»“æœã€‚</li></ul><p><strong>å·¥ä½œé‡ï¼š</strong></p><ul><li>è®­ç»ƒå’Œæ¨ç†æˆæœ¬ä½ï¼Œå¯ä»¥å®æ—¶åˆæˆé«˜è´¨é‡çš„æ–°é¢–è§†å›¾ã€‚</li></ul><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-dae52d7d48c393553eaefb0a09269fe0.jpg" align="middle"><img src="https://pica.zhimg.com/v2-e3d64b07ef974a9326e03be048b0aa88.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f81338e5bf0cec7be815850dd100ce1b.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-fdd479c95f23763e44cccc2ac03892f1.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f6522aaddb6fa9c6b731ea5fe4d54464.jpg" align="middle"></details>## FreGS: 3D Gaussian Splatting with Progressive Frequency Regularization**Authors:Jiahui Zhang, Fangneng Zhan, Muyu Xu, Shijian Lu, Eric Xing**3D Gaussian splatting has achieved very impressive performance in real-time novel view synthesis. However, it often suffers from over-reconstruction during Gaussian densification where high-variance image regions are covered by a few large Gaussians only, leading to blur and artifacts in the rendered images. We design a progressive frequency regularization (FreGS) technique to tackle the over-reconstruction issue within the frequency space. Specifically, FreGS performs coarse-to-fine Gaussian densification by exploiting low-to-high frequency components that can be easily extracted with low-pass and high-pass filters in the Fourier space. By minimizing the discrepancy between the frequency spectrum of the rendered image and the corresponding ground truth, it achieves high-quality Gaussian densification and alleviates the over-reconstruction of Gaussian splatting effectively. Experiments over multiple widely adopted benchmarks (e.g., Mip-NeRF360, Tanks-and-Temples and Deep Blending) show that FreGS achieves superior novel view synthesis and outperforms the state-of-the-art consistently. [PDF](http://arxiv.org/abs/2403.06908v1) **Summary**æ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–æŠ€æœ¯æœ‰æ•ˆè§£å†³äº† 3D é«˜æ–¯æ•£ç‚¹å›¾è¿‡åº¦é‡å»ºå¸¦æ¥çš„å›¾åƒæ¨¡ç³Šå’Œç‘•ç–µã€‚**Key Takeaways**- FreGS é‡‡ç”¨æ¸è¿›å¼é«˜æ–¯å¢å¯†ï¼Œä»ä½é¢‘åˆ°é«˜é¢‘é€å±‚ä¼˜åŒ–ã€‚- FreGS åˆ©ç”¨å‚…é‡Œå¶ç©ºé—´çš„ä½é€šå’Œé«˜é€šæ»¤æ³¢å™¨è½»æ¾æå–ä½é¢‘åˆ°é«˜é¢‘åˆ†é‡ã€‚- FreGS é€šè¿‡æœ€å°åŒ–æ¸²æŸ“å›¾åƒé¢‘è°±å’Œå¯¹åº”çœŸå®é¢‘è°±ä¹‹é—´çš„å·®å¼‚ï¼Œæå‡äº†é«˜æ–¯å¢å¯†è´¨é‡ã€‚- FreGS æœ‰æ•ˆç¼“è§£äº†é«˜æ–¯æ•£ç‚¹å›¾çš„è¿‡åº¦é‡å»ºé—®é¢˜ã€‚- FreGS åœ¨ Mip-NeRF360ã€Tanks-and-Temples å’Œæ·±åº¦æ··åˆç­‰å¤šä¸ªåŸºå‡†ä¸Šå‡å–å¾—äº†æœ€ä¼˜çš„æ–°è§†å›¾åˆæˆæ•ˆæœã€‚- FreGS å§‹ç»ˆä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æŠ€æœ¯ã€‚- FreGS å¯¹å›¾åƒæ¨¡ç³Šå’Œç‘•ç–µå…·æœ‰å‡ºè‰²çš„æŠ‘åˆ¶æ•ˆæœã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>é¢˜ç›®ï¼šFreGSï¼šå…·æœ‰æ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–çš„ 3D é«˜æ–¯æ•£ç‚¹åŒ–</li><li>ä½œè€…ï¼šJiahui Zhangï¼ŒFangneng Zhanï¼ŒMuyu Xuï¼ŒShijian Luï¼ŒEric Xing</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå—æ´‹ç†å·¥å¤§å­¦</li><li>å…³é”®è¯ï¼šæ–°è§†è§’åˆæˆï¼Œé«˜æ–¯æ•£ç‚¹åŒ–ï¼Œé¢‘ç‡æ­£åˆ™åŒ–</li><li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼š3D é«˜æ–¯æ•£ç‚¹åŒ–åœ¨å®æ—¶æ–°è§†è§’åˆæˆä¸­å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå®ƒåœ¨é«˜æ–¯è‡´å¯†åŒ–è¿‡ç¨‹ä¸­ç»å¸¸ä¼šå‡ºç°è¿‡åº¦é‡å»ºï¼Œå…¶ä¸­é«˜æ–¹å·®å›¾åƒåŒºåŸŸä»…ç”±å°‘æ•°å‡ ä¸ªå¤§é«˜æ–¯ä½“è¦†ç›–ï¼Œä»è€Œå¯¼è‡´æ¸²æŸ“å›¾åƒä¸­çš„æ¨¡ç³Šå’Œä¼ªå½±ã€‚ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡åŠ¨æœºæ˜ç¡®ï¼Œæå‡ºäº†æ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ– (FreGS) æŠ€æœ¯æ¥è§£å†³é¢‘ç‡ç©ºé—´ä¸­çš„è¿‡åº¦é‡å»ºé—®é¢˜ã€‚ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šFreGS é€šè¿‡åˆ©ç”¨ä½é€šå’Œé«˜é€šæ»¤æ³¢å™¨åœ¨å‚…é‡Œå¶ç©ºé—´ä¸­è½»æ¾æå–çš„ä½é¢‘åˆ°é«˜é¢‘åˆ†é‡ï¼Œæ‰§è¡Œç²—åˆ°ç²¾çš„é«˜æ–¯è‡´å¯†åŒ–ã€‚é€šè¿‡æœ€å°åŒ–æ¸²æŸ“å›¾åƒçš„é¢‘è°±ä¸ç›¸åº”çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ï¼Œå®ƒå®ç°äº†é«˜è´¨é‡çš„é«˜æ–¯è‡´å¯†åŒ–ï¼Œæœ‰æ•ˆåœ°ç¼“è§£äº†é«˜æ–¯æ•£ç‚¹åŒ–çš„è¿‡åº¦é‡å»ºã€‚ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨å¤šä¸ªå¹¿æ³›é‡‡ç”¨çš„åŸºå‡†ï¼ˆä¾‹å¦‚ Mip-NeRF360ã€Tanks-and-Temples å’Œ DeepBlendingï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFreGS å®ç°äº†å“è¶Šçš„æ–°è§†è§’åˆæˆï¼Œå¹¶å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºæ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–ï¼ˆFreGSï¼‰æŠ€æœ¯ï¼Œé€šè¿‡åˆ©ç”¨å‚…é‡Œå¶ç©ºé—´ä¸­æå–çš„ä½é¢‘åˆ°é«˜é¢‘åˆ†é‡ï¼Œæ‰§è¡Œç²—åˆ°ç²¾çš„é«˜æ–¯è‡´å¯†åŒ–ã€‚ï¼ˆ2ï¼‰ï¼šFreGSé€šè¿‡æœ€å°åŒ–æ¸²æŸ“å›¾åƒçš„é¢‘è°±ä¸ç›¸åº”çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ï¼Œå®ç°é«˜è´¨é‡çš„é«˜æ–¯è‡´å¯†åŒ–ï¼Œæœ‰æ•ˆåœ°ç¼“è§£äº†é«˜æ–¯æ•£ç‚¹åŒ–çš„è¿‡åº¦é‡å»ºã€‚ï¼ˆ3ï¼‰ï¼šè®¾è®¡é¢‘ç‡é€€ç«æŠ€æœ¯ï¼Œå®ç°æ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–ï¼Œå¯ä»¥é€æ­¥åˆ©ç”¨ä½åˆ°é«˜é¢‘åˆ†é‡æ¥æ‰§è¡Œç²—åˆ°ç²¾çš„é«˜æ–¯è‡´å¯†åŒ–ã€‚</p></li><li><p>æ€»ç»“ï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰ï¼šFreGS æå‡ºæ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œä»é¢‘ç‡è§†è§’æå‡ 3D é«˜æ–¯æ•£ç‚¹åŒ–ï¼Œæœ‰æ•ˆç¼“è§£äº†é«˜æ–¯æ•£ç‚¹åŒ–çš„è¿‡åº¦é‡å»ºé—®é¢˜ï¼Œåœ¨å¤šä¸ªå¹¿æ³›é‡‡ç”¨çš„å®¤å†…å¤–åœºæ™¯ä¸Šå®ç°äº†å“è¶Šçš„æ–°è§†è§’åˆæˆæ•ˆæœã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šFreGS æå‡ºæ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œé€šè¿‡åˆ©ç”¨å‚…é‡Œå¶ç©ºé—´ä¸­æå–çš„ä½é¢‘åˆ°é«˜é¢‘åˆ†é‡ï¼Œæ‰§è¡Œç²—åˆ°ç²¾çš„é«˜æ–¯è‡´å¯†åŒ–ï¼Œæœ‰æ•ˆç¼“è§£äº†é«˜æ–¯æ•£ç‚¹åŒ–çš„è¿‡åº¦é‡å»ºé—®é¢˜ã€‚æ€§èƒ½ï¼šFreGS åœ¨å¤šä¸ªå¹¿æ³›é‡‡ç”¨çš„åŸºå‡†ä¸Šå®ç°äº†å“è¶Šçš„æ–°è§†è§’åˆæˆï¼Œå¹¶å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚å·¥ä½œé‡ï¼šFreGS çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è®¾è®¡é¢‘ç‡é€€ç«æŠ€æœ¯å’Œæœ€å°åŒ–æ¸²æŸ“å›¾åƒçš„é¢‘è°±ä¸ç›¸åº”çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-07cbe93d5240e4aa795cfc2554b29280.jpg" align="middle"><img src="https://picx.zhimg.com/v2-c725f327a32c127deea0c454f4062887.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3ddb9b45e2c546000557a3be13e0a4a4.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f440ba30a1f4e263c32265e76b8e0898.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3063a8cf69313732153e2186dcdf414d.jpg" align="middle"></details><h2 id="V3D-Video-Diffusion-Models-are-Effective-3D-Generators"><a href="#V3D-Video-Diffusion-Models-are-Effective-3D-Generators" class="headerlink" title="V3D: Video Diffusion Models are Effective 3D Generators"></a>V3D: Video Diffusion Models are Effective 3D Generators</h2><p><strong>Authors:Zilong Chen, Yikai Wang, Feng Wang, Zhengyi Wang, Huaping Liu</strong></p><p>Automatic 3D generation has recently attracted widespread attention. Recent methods have greatly accelerated the generation speed, but usually produce less-detailed objects due to limited model capacity or 3D data. Motivated by recent advancements in video diffusion models, we introduce V3D, which leverages the world simulation capacity of pre-trained video diffusion models to facilitate 3D generation. To fully unleash the potential of video diffusion to perceive the 3D world, we further introduce geometrical consistency prior and extend the video diffusion model to a multi-view consistent 3D generator. Benefiting from this, the state-of-the-art video diffusion model could be fine-tuned to generate 360degree orbit frames surrounding an object given a single image. With our tailored reconstruction pipelines, we can generate high-quality meshes or 3D Gaussians within 3 minutes. Furthermore, our method can be extended to scene-level novel view synthesis, achieving precise control over the camera path with sparse input views. Extensive experiments demonstrate the superior performance of the proposed approach, especially in terms of generation quality and multi-view consistency. Our code is available at <a href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a> </p><p><a href="http://arxiv.org/abs/2403.06738v1">PDF</a> Code available at <a href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a> Project page:   <a href="https://heheyas.github.io/V3D/">https://heheyas.github.io/V3D/</a></p><p><strong>Summary</strong><br>åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ä¸–ç•Œæ¨¡æ‹Ÿèƒ½åŠ›ä¿ƒè¿› 3D ç”Ÿæˆï¼Œå¹¶é€šè¿‡å‡ ä½•ä¸€è‡´æ€§å…ˆéªŒå’Œå¤šè§†å›¾ä¸€è‡´ 3D ç”Ÿæˆå™¨æ‰©å±•è§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>è‡ªåŠ¨ 3D ç”Ÿæˆå—åˆ°å¹¿æ³›å…³æ³¨ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•ç”±äºæ¨¡å‹å®¹é‡æˆ– 3D æ•°æ®é™åˆ¶è€Œäº§ç”Ÿç»†èŠ‚è¾ƒå°‘çš„ç‰©ä½“ã€‚</li><li>V3D åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ä¸–ç•Œæ¨¡æ‹Ÿèƒ½åŠ›æ¥ä¿ƒè¿› 3D ç”Ÿæˆã€‚</li><li>å‡ ä½•ä¸€è‡´æ€§å…ˆéªŒå’Œå¤šè§†å›¾ä¸€è‡´ 3D ç”Ÿæˆå™¨å……åˆ†å‘æŒ¥è§†é¢‘æ‰©æ•£æ„ŸçŸ¥ 3D ä¸–ç•Œçš„æ½œåŠ›ã€‚</li><li>åªéœ€ä¸€å¼ å›¾ç‰‡ï¼Œå³å¯å¾®è°ƒæœ€å…ˆè¿›çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆå›´ç»•ç‰©ä½“ 360 åº¦æ—‹è½¬çš„è½¨é“å¸§ã€‚</li><li>å€ŸåŠ©å®šåˆ¶çš„é‡å»ºç®¡é“ï¼Œå¯åœ¨ 3 åˆ†é’Ÿå†…ç”Ÿæˆé«˜è´¨é‡çš„ç½‘æ ¼æˆ– 3D é«˜æ–¯ä½“ã€‚</li><li>è¯¥æ–¹æ³•å¯æ‰©å±•åˆ°åœºæ™¯çº§æ–°é¢–è§†å›¾åˆæˆï¼Œä½¿ç”¨ç¨€ç–è¾“å…¥è§†å›¾å¯¹ç›¸æœºè·¯å¾„è¿›è¡Œç²¾ç¡®æ§åˆ¶ã€‚</li><li>å¤§é‡å®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨ç”Ÿæˆè´¨é‡å’Œå¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢å…·æœ‰å“è¶Šçš„æ€§èƒ½ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šV3Dï¼šè§†é¢‘æ‰©æ•£æ¨¡å‹æ˜¯æœ‰æ•ˆçš„ 3D ç”Ÿæˆå™¨</li><li>ä½œè€…ï¼šZilong Chen, Yikai Wangâ€ , Feng Wang, Zhengyi Wang, Huaping Liuâ€ </li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼š3D ç”Ÿæˆï¼Œè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå¤šè§†å›¾é‡å»º</li><li>è®ºæ–‡é“¾æ¥ï¼šarxiv.org/abs/2403.06738   Github ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè‡ªåŠ¨ 3D ç”Ÿæˆå·²å¼•èµ·å¹¿æ³›å…³æ³¨ã€‚è¿‘æœŸæ–¹æ³•æå¤§åœ°æé«˜äº†ç”Ÿæˆé€Ÿåº¦ï¼Œä½†ç”±äºæ¨¡å‹å®¹é‡æœ‰é™ï¼Œé€šå¸¸ä¼šäº§ç”Ÿç»†èŠ‚è¾ƒå°‘çš„ç‰©ä½“ã€‚   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šè¿‡å»æ–¹æ³•åŒ…æ‹¬åŸºäºéšå¼ç¥ç»è¡¨ç¤ºå’ŒåŸºäºæ˜¾å¼ç½‘æ ¼è¡¨ç¤ºçš„æ–¹æ³•ã€‚å‰è€…ç”Ÿæˆé€Ÿåº¦å¿«ï¼Œä½†ç»†èŠ‚è¾ƒå°‘ï¼›åè€…ç»†èŠ‚ä¸°å¯Œï¼Œä½†ç”Ÿæˆé€Ÿåº¦æ…¢ã€‚   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º V3Dï¼Œä¸€ç§åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ 3D ç”Ÿæˆæ–¹æ³•ã€‚V3D å°† 2D å›¾åƒåºåˆ—æ‰©æ•£åˆ° 3D ç©ºé—´ï¼Œç”Ÿæˆé«˜ä¿çœŸ 3D ç‰©ä½“ã€‚   ï¼ˆ4ï¼‰æ€§èƒ½ï¼šåœ¨ ShapeNet æ•°æ®é›†ä¸Šï¼ŒV3D åœ¨ç”Ÿæˆé€Ÿåº¦å’Œç»†èŠ‚ä¸°å¯Œåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚V3D å¯ä»¥ç”Ÿæˆé«˜ä¿çœŸ 3D ç‰©ä½“ï¼Œç”Ÿæˆæ—¶é—´ä»…éœ€ 3 åˆ†é’Ÿã€‚</li></ol><p><methods>:(1): V3Då°†2Då›¾åƒåºåˆ—æ‰©æ•£åˆ°3Dç©ºé—´ï¼Œç”Ÿæˆé«˜ä¿çœŸ3Dç‰©ä½“ã€‚(2): V3Dä½¿ç”¨åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œå°†2Då›¾åƒåºåˆ—é€å¸§æ‰©æ•£åˆ°3Dç©ºé—´ä¸­ã€‚(3): V3Dé‡‡ç”¨å¤šè§†å›¾é‡å»ºæŠ€æœ¯ï¼Œä»ä¸åŒè§†è§’ç”Ÿæˆ2Då›¾åƒåºåˆ—ï¼Œæé«˜3Dç‰©ä½“çš„ç»†èŠ‚ä¸°å¯Œåº¦ã€‚</methods></p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ æœ¬å·¥ä½œé€šè¿‡å°†å›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹åº”ç”¨äº 3D ç”Ÿæˆï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„æ–¹æ³• V3Dï¼Œæ˜¾è‘—æå‡äº† 3D ç‰©ä½“çš„ç”Ÿæˆé€Ÿåº¦å’Œç»†èŠ‚ä¸°å¯Œåº¦ã€‚V3D ä¸ä»…èƒ½å¤Ÿåˆæˆé«˜è´¨é‡çš„ 3D ç‰©ä½“ï¼Œè¿˜èƒ½å®ç°åœºæ™¯çº§çš„æ–°è§†è§’åˆæˆï¼Œä¸ºé«˜ä¿çœŸ 3D ç”Ÿæˆå’Œè§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨ 3D ä»»åŠ¡ä¸­çš„å¹¿æ³›åº”ç”¨é“ºå¹³äº†é“è·¯ã€‚ï¼ˆ2ï¼‰ åˆ›æ–°ç‚¹ï¼š</li><li>å°†è§†é¢‘æ‰©æ•£æ¨¡å‹åº”ç”¨äº 3D ç”Ÿæˆï¼Œé€šè¿‡å°† 2D å›¾åƒåºåˆ—æ‰©æ•£åˆ° 3D ç©ºé—´ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆé€Ÿåº¦å’Œç»†èŠ‚ä¸°å¯Œåº¦ã€‚</li><li>æå‡ºäº†ä¸€ç§é‡èº«å®šåˆ¶çš„é‡å»ºç®¡é“ï¼Œç»“åˆç²¾å¿ƒè®¾è®¡çš„åˆå§‹åŒ–å’Œçº¹ç†ä¼˜åŒ–ï¼Œèƒ½å¤Ÿåœ¨ 3 åˆ†é’Ÿå†…é‡å»ºé«˜è´¨é‡çš„ 3D é«˜æ–¯ä½“æˆ–ç²¾ç»†çº¹ç†ç½‘æ ¼ã€‚</li><li>å°†è¯¥æ¡†æ¶æ‰©å±•åˆ°åœºæ™¯çº§çš„æ–°è§†è§’åˆæˆï¼Œå®ç°äº†å¯¹æ‘„åƒæœºè·¯å¾„çš„ç²¾ç¡®æ§åˆ¶å’Œå‡ºè‰²çš„å¤šè§†è§’ä¸€è‡´æ€§ã€‚æ€§èƒ½ï¼š</li><li>åœ¨ ShapeNet æ•°æ®é›†ä¸Šï¼ŒV3D åœ¨ç”Ÿæˆé€Ÿåº¦å’Œç»†èŠ‚ä¸°å¯Œåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li><li>V3D èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 3D ç‰©ä½“ï¼Œç”Ÿæˆæ—¶é—´ä»…éœ€ 3 åˆ†é’Ÿã€‚</li><li>V3D åœ¨åœºæ™¯çº§æ–°è§†è§’åˆæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå®ç°äº†å¯¹æ‘„åƒæœºè·¯å¾„çš„ç²¾ç¡®æ§åˆ¶å’Œå‡ºè‰²çš„å¤šè§†è§’ä¸€è‡´æ€§ã€‚å·¥ä½œé‡ï¼š</li><li>V3D çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºéƒ¨ç½²å’Œä½¿ç”¨ã€‚</li><li>V3D çš„è®­ç»ƒè¿‡ç¨‹é«˜æ•ˆï¼Œåœ¨å•å¼  NVIDIA A100 GPU ä¸Šä»…éœ€æ•°å°æ—¶å³å¯å®Œæˆã€‚</li><li>V3D çš„æ¨ç†é€Ÿåº¦å¿«ï¼Œèƒ½å¤Ÿåœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆé«˜è´¨é‡çš„ 3D ç‰©ä½“æˆ–åˆæˆæ–°è§†è§’ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-8c7c858eb0759a50450bc9e902b68068.jpg" align="middle"><img src="https://picx.zhimg.com/v2-20859973aba31d5ec733373f6d25379e.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-13  StyleGaussian Instant 3D Style Transfer with Gaussian Splatting</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="3DGS" scheme="https://kedreamix.github.io/tags/3DGS/"/>
    
  </entry>
  
  <entry>
    <title>Talking Head Generation</title>
    <link href="https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/Talking%20Head%20Generation/"/>
    <id>https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/Talking%20Head%20Generation/</id>
    <published>2024-03-13T05:53:10.000Z</published>
    <updated>2024-03-13T05:53:10.797Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-13-æ›´æ–°"><a href="#2024-03-13-æ›´æ–°" class="headerlink" title="2024-03-13 æ›´æ–°"></a>2024-03-13 æ›´æ–°</h1><h2 id="A-Comparative-Study-of-Perceptual-Quality-Metrics-for-Audio-driven-Talking-Head-Videos"><a href="#A-Comparative-Study-of-Perceptual-Quality-Metrics-for-Audio-driven-Talking-Head-Videos" class="headerlink" title="A Comparative Study of Perceptual Quality Metrics for Audio-driven   Talking Head Videos"></a>A Comparative Study of Perceptual Quality Metrics for Audio-driven   Talking Head Videos</h2><p><strong>Authors:Weixia Zhang, Chengguang Zhu, Jingnan Gao, Yichao Yan, Guangtao Zhai, Xiaokang Yang</strong></p><p>The rapid advancement of Artificial Intelligence Generated Content (AIGC) technology has propelled audio-driven talking head generation, gaining considerable research attention for practical applications. However, performance evaluation research lags behind the development of talking head generation techniques. Existing literature relies on heuristic quantitative metrics without human validation, hindering accurate progress assessment. To address this gap, we collect talking head videos generated from four generative methods and conduct controlled psychophysical experiments on visual quality, lip-audio synchronization, and head movement naturalness. Our experiments validate consistency between model predictions and human annotations, identifying metrics that align better with human opinions than widely-used measures. We believe our work will facilitate performance evaluation and model development, providing insights into AIGC in a broader context. Code and data will be made available at <a href="https://github.com/zwx8981/ADTH-QA">https://github.com/zwx8981/ADTH-QA</a>. </p><p><a href="http://arxiv.org/abs/2403.06421v1">PDF</a> </p><p><strong>Summary</strong><br>äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰æŠ€æœ¯çš„å‘å±•æ¨åŠ¨äº†éŸ³é¢‘é©±åŠ¨çš„è™šæ‹Ÿå½¢è±¡ç”ŸæˆæŠ€æœ¯ï¼Œåœ¨å®é™…åº”ç”¨ä¸­å¾—åˆ°äº†å¹¿æ³›çš„ç ”ç©¶å…³æ³¨ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰æŠ€æœ¯å‘å±•è¿…é€Ÿï¼Œä¿ƒè¿›äº†éŸ³é¢‘é©±åŠ¨çš„è™šæ‹Ÿå½¢è±¡ç”Ÿæˆã€‚</li><li>ç°æœ‰çš„è™šæ‹Ÿå½¢è±¡ç”ŸæˆæŠ€æœ¯è¯„ä»·æŒ‡æ ‡ä¾èµ–å¯å‘å¼å®šé‡æŒ‡æ ‡ï¼Œç¼ºä¹äººä¸ºéªŒè¯ï¼Œé˜»ç¢äº†å‡†ç¡®çš„è¿›åº¦è¯„ä¼°ã€‚</li><li>æ”¶é›†äº†å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆçš„è™šæ‹Ÿå½¢è±¡è§†é¢‘ï¼Œå¹¶å¯¹è§†è§‰è´¨é‡ã€å”‡éŸ³åŒæ­¥å’Œå¤´éƒ¨è¿åŠ¨è‡ªç„¶åº¦è¿›è¡Œäº†æ§åˆ¶çš„å¿ƒç†ç‰©ç†å®éªŒã€‚</li><li>å®éªŒéªŒè¯äº†æ¨¡å‹é¢„æµ‹å’Œäººä¸ºæ ‡æ³¨çš„ä¸€è‡´æ€§ï¼Œç¡®å®šäº†æ¯”å¹¿æ³›ä½¿ç”¨çš„åº¦é‡æ›´ç¬¦åˆäººæ„è§çš„åº¦é‡ã€‚</li><li>è¯¥ç ”ç©¶å°†ä¿ƒè¿›ç»©æ•ˆè¯„ä¼°å’Œæ¨¡å‹å¼€å‘ï¼Œä¸ºæ›´å¹¿æ³›èƒŒæ™¯ä¸‹çš„ AIGC æä¾›æ·±å…¥è§è§£ã€‚</li><li>ä»£ç å’Œæ•°æ®å°†åœ¨ <a href="https://github.com/zwx8981/ADTH-QA">https://github.com/zwx8981/ADTH-QA</a> ä¸Šæä¾›ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p>1.æ ‡é¢˜ï¼šéŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨è§†é¢‘æ„ŸçŸ¥è´¨é‡æŒ‡æ ‡çš„æ¯”è¾ƒç ”ç©¶2.ä½œè€…ï¼šé­éœç« ã€ç¨‹å¹¿æŸ±ã€æ™¯å—é«˜ã€å¥•è¶…é¢œã€å¹¿æ¶›ç¿Ÿã€è‚–åº·æ¨3.ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦äººå·¥æ™ºèƒ½ç ”ç©¶é™¢ã€äººå·¥æ™ºèƒ½ç ”ç©¶é™¢4.å…³é”®è¯ï¼šæ„ŸçŸ¥è´¨é‡è¯„ä¼°ã€AIGCã€æ•°å­—äººã€éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”Ÿæˆ5.è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.06421Githubä»£ç é“¾æ¥ï¼šNone6.æ€»ç»“ï¼šï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šéšç€äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼ŒéŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”ŸæˆæŠ€æœ¯å—åˆ°å¹¿æ³›å…³æ³¨ï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œæ€§èƒ½è¯„ä¼°ç ”ç©¶æ»åäºè¯´è¯äººå¤´éƒ¨ç”ŸæˆæŠ€æœ¯çš„å¼€å‘ã€‚ç°æœ‰æ–‡çŒ®ä¾èµ–å¯å‘å¼å®šé‡æŒ‡æ ‡ï¼Œç¼ºä¹äººå·¥éªŒè¯ï¼Œé˜»ç¢äº†å‡†ç¡®çš„è¿›å±•è¯„ä¼°ã€‚ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦ä¾èµ–å¯å‘å¼å®šé‡æŒ‡æ ‡ï¼Œå¦‚PSNRã€SSIMå’ŒLMDï¼Œè¿™äº›æŒ‡æ ‡åœ¨æ²¡æœ‰äººå·¥éªŒè¯çš„æƒ…å†µä¸‹è¢«ç”¨ä½œæ„ŸçŸ¥è´¨é‡çš„ä»£ç†æŒ‡æ ‡ã€‚ç„¶è€Œï¼Œè¿™äº›æŒ‡æ ‡å­˜åœ¨å±€é™æ€§ï¼Œä¾‹å¦‚å¯¹æ•°æ®æºçš„æ•æ„Ÿæ€§å’Œå¯¹äººç±»æ„ŸçŸ¥çš„ä¸åŒ¹é…ã€‚ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æ”¶é›†äº†å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆçš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼Œå¹¶åœ¨å—æ§å®éªŒå®¤ç¯å¢ƒä¸­è¿›è¡Œå¿ƒç†ç‰©ç†å®éªŒï¼Œé‡ç‚¹å…³æ³¨è§†è§‰è´¨é‡ã€å”‡éŸ³åŒæ­¥å’Œå¤´éƒ¨è¿åŠ¨è‡ªç„¶åº¦ã€‚ç„¶åï¼Œå¯¹å„ç§å®¢è§‚æŒ‡æ ‡è¿›è¡Œäº†å¹¿æ³›æµ‹è¯•ï¼Œä»¥è¯„ä¼°å…¶ä¸è¿™äº›äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•ä¸äººç±»åˆ¤æ–­ä¹‹é—´å­˜åœ¨ä¸€è‡´æ€§ï¼Œå¹¶ç¡®å®šäº†æ¯”å¹¿æ³›ä½¿ç”¨çš„æŒ‡æ ‡æ›´ç¬¦åˆäººç±»æ„è§çš„æŒ‡æ ‡ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºä¿ƒè¿›æ€§èƒ½è¯„ä¼°å’Œæ¨¡å‹å¼€å‘ï¼Œå¹¶ä¸ºæ›´å¹¿æ³›èƒŒæ™¯ä¸‹çš„AIGCæä¾›è§è§£ã€‚</p><p><strong>æ–¹æ³•ï¼š</strong></p><p>(1) æ”¶é›†å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆçš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼›</p><p>(2) åœ¨å—æ§å®éªŒå®¤ç¯å¢ƒä¸­è¿›è¡Œå¿ƒç†ç‰©ç†å®éªŒï¼Œé‡ç‚¹å…³æ³¨è§†è§‰è´¨é‡ã€å”‡éŸ³åŒæ­¥å’Œå¤´éƒ¨è¿åŠ¨è‡ªç„¶åº¦ï¼›</p><p>(3) å¹¿æ³›æµ‹è¯•å„ç§å®¢è§‚æŒ‡æ ‡ï¼Œä»¥è¯„ä¼°å…¶ä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ï¼›</p><p>(4) é€šè¿‡ 2AFC åˆ†æ•°è¡¡é‡å®¢è§‚æŒ‡æ ‡ä¸äººç±»è¯„ä¼°çš„ä¸€è‡´æ€§ï¼›</p><p>(5) è¯„ä¼°å›¾åƒè´¨é‡ã€å”‡éŸ³åŒæ­¥å’Œå¤´éƒ¨è¿åŠ¨è‡ªç„¶åº¦æŒ‡æ ‡ï¼›</p><p>(6) è¯„ä¼°åŸºäº SyncNet çš„ä¸‰ä¸ªå”‡éŸ³åŒæ­¥æŒ‡æ ‡å’Œ SparseSync æŒ‡æ ‡ï¼›</p><p>(7) é‡‡ç”¨æ··åˆæ•°æ®é›†è®­ç»ƒç­–ç•¥ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„å¯è½¬ç§»æ€§ã€‚</p><p><strong>8. ç»“è®º</strong><strong>(1): æ„ä¹‰</strong>æœ¬ç ”ç©¶é€šè¿‡å»ºç«‹åŒ…å«å››ç§éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ–¹æ³•ç”Ÿæˆè§†é¢‘çš„æ•°æ®é›†ï¼Œå¹¶é€šè¿‡å—æ§çš„å¿ƒç†ç‰©ç†å®éªŒæ”¶é›†äººç±»åå¥½ï¼Œæ¢ç©¶äº†éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”ŸæˆæŠ€æœ¯çš„æ„ŸçŸ¥è´¨é‡è¯„ä¼°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•ä¸äººç±»åˆ¤æ–­ä¹‹é—´å­˜åœ¨ä¸€è‡´æ€§ï¼Œå¹¶ç¡®å®šäº†æ¯”å¹¿æ³›ä½¿ç”¨çš„æŒ‡æ ‡æ›´ç¬¦åˆäººç±»æ„è§çš„æŒ‡æ ‡ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºä¿ƒè¿›æ€§èƒ½è¯„ä¼°å’Œæ¨¡å‹å¼€å‘ï¼Œå¹¶ä¸ºæ›´å¹¿æ³›èƒŒæ™¯ä¸‹çš„ AIGC æä¾›è§è§£ã€‚</p><p><strong>(2): åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡</strong><strong>åˆ›æ–°ç‚¹ï¼š</strong>* é€šè¿‡å¿ƒç†ç‰©ç†å®éªŒæ”¶é›†äººç±»åå¥½ï¼Œå»ºç«‹åŒ…å«å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆè§†é¢‘çš„æ•°æ®é›†ã€‚* æå‡ºäº†ä¸€ç§åŸºäºäººç±»åˆ¤æ–­çš„æ„ŸçŸ¥è´¨é‡è¯„ä¼°æ–¹æ³•ã€‚* ç¡®å®šäº†æ¯”å¹¿æ³›ä½¿ç”¨çš„æŒ‡æ ‡æ›´ç¬¦åˆäººç±»æ„è§çš„æŒ‡æ ‡ã€‚</p><p><strong>æ€§èƒ½ï¼š</strong>* æ‰€æå‡ºçš„æ–¹æ³•ä¸äººç±»åˆ¤æ–­ä¹‹é—´å­˜åœ¨ä¸€è‡´æ€§ã€‚* ç¡®å®šçš„æŒ‡æ ‡æ¯”å¹¿æ³›ä½¿ç”¨çš„æŒ‡æ ‡æ›´ç¬¦åˆäººç±»æ„è§ã€‚</p><p><strong>å·¥ä½œé‡ï¼š</strong>* æ”¶é›†äº†ä¸€ä¸ªåŒ…å«å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆè§†é¢‘çš„æ•°æ®é›†ã€‚* è¿›è¡Œäº†ä¸€ç³»åˆ—å¿ƒç†ç‰©ç†å®éªŒã€‚* å¹¿æ³›æµ‹è¯•äº†å„ç§å®¢è§‚æŒ‡æ ‡ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-d7d375dcb8fecf9ffb80be0b9c71756b.jpg" align="middle"><img src="https://pica.zhimg.com/v2-478998a50c784c3a3c0aa108c509fe52.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4aaac273c5b4afe45da700d10d5ac29c.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-f16882204804b40a491523a7984bf7e2.jpg" align="middle"><img src="https://picx.zhimg.com/v2-5201c94e6142ff9aad05ce654fbe8f9e.jpg" align="middle"><img src="https://picx.zhimg.com/v2-523c101252b751fc24de4e576389177a.jpg" align="middle"><img src="https://picx.zhimg.com/v2-8e67dfafe83349d242d664f46c153e84.jpg" align="middle"></details><h2 id="Style2Talker-High-Resolution-Talking-Head-Generation-with-Emotion-Style-and-Art-Style"><a href="#Style2Talker-High-Resolution-Talking-Head-Generation-with-Emotion-Style-and-Art-Style" class="headerlink" title="Style2Talker: High-Resolution Talking Head Generation with Emotion Style   and Art Style"></a>Style2Talker: High-Resolution Talking Head Generation with Emotion Style   and Art Style</h2><p><strong>Authors:Shuai Tan, Bin Ji, Ye Pan</strong></p><p>Although automatically animating audio-driven talking heads has recently received growing interest, previous efforts have mainly concentrated on achieving lip synchronization with the audio, neglecting two crucial elements for generating expressive videos: emotion style and art style. In this paper, we present an innovative audio-driven talking face generation method called Style2Talker. It involves two stylized stages, namely Style-E and Style-A, which integrate text-controlled emotion style and picture-controlled art style into the final output. In order to prepare the scarce emotional text descriptions corresponding to the videos, we propose a labor-free paradigm that employs large-scale pretrained models to automatically annotate emotional text labels for existing audiovisual datasets. Incorporating the synthetic emotion texts, the Style-E stage utilizes a large-scale CLIP model to extract emotion representations, which are combined with the audio, serving as the condition for an efficient latent diffusion model designed to produce emotional motion coefficients of a 3DMM model. Moving on to the Style-A stage, we develop a coefficient-driven motion generator and an art-specific style path embedded in the well-known StyleGAN. This allows us to synthesize high-resolution artistically stylized talking head videos using the generated emotional motion coefficients and an art style source picture. Moreover, to better preserve image details and avoid artifacts, we provide StyleGAN with the multi-scale content features extracted from the identity image and refine its intermediate feature maps by the designed content encoder and refinement network, respectively. Extensive experimental results demonstrate our method outperforms existing state-of-the-art methods in terms of audio-lip synchronization and performance of both emotion style and art style. </p><p><a href="http://arxiv.org/abs/2403.06365v2">PDF</a> 9 pages, 5 figures, conference</p><p><strong>Summary</strong><br>éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ–¹æ³•Style2Talkerï¼Œå®ç°äº†æƒ…æ„Ÿé£æ ¼å’Œè‰ºæœ¯é£æ ¼ï¼Œæé«˜äº†è§†é¢‘è¡¨è¾¾æ•ˆæœã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>Style2Talkerå¼•å…¥Style-Eå’ŒStyle-Aä¸¤ä¸ªé£æ ¼åŒ–é˜¶æ®µï¼Œåˆ†åˆ«æ•´åˆæƒ…æ„Ÿé£æ ¼å’Œè‰ºæœ¯é£æ ¼ã€‚</li><li>æå‡ºæ— äººå·¥å¹²é¢„çš„èŒƒå¼ï¼Œè‡ªåŠ¨ä¸ºç°æœ‰è§†éŸ³é¢‘æ•°æ®é›†æ ‡æ³¨æƒ…æ„Ÿæ–‡æœ¬æ ‡ç­¾ã€‚</li><li>åˆ©ç”¨CLIPæ¨¡å‹æå–æƒ…æ„Ÿç‰¹å¾ï¼Œç»“åˆéŸ³é¢‘ä½œä¸ºé«˜æ•ˆæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ¡ä»¶ï¼Œç”Ÿæˆ3DMMæ¨¡å‹çš„æƒ…æ„Ÿè¿åŠ¨ç³»æ•°ã€‚</li><li>å¼€å‘ç³»æ•°é©±åŠ¨çš„è¿åŠ¨ç”Ÿæˆå™¨å’ŒåµŒå…¥åœ¨StyleGANä¸­çš„è‰ºæœ¯é£æ ¼è·¯å¾„ï¼Œåˆæˆé«˜åˆ†è¾¨ç‡è‰ºæœ¯é£æ ¼çš„å¤´éƒ¨è§†é¢‘ã€‚</li><li>å¼•å…¥å¤šå°ºåº¦å†…å®¹ç‰¹å¾å’Œå†…å®¹ç¼–ç å™¨ã€ç²¾ç‚¼ç½‘ç»œï¼Œæå‡å›¾åƒç»†èŠ‚å’Œå‡å°‘ä¼ªå½±ã€‚</li><li>Style2Talkeråœ¨éŸ³è§†é¢‘åŒæ­¥ã€æƒ…æ„Ÿå’Œè‰ºæœ¯é£æ ¼è¡¨ç°æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šStyle2Talkerï¼šå…¼å…·æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼çš„é«˜åˆ†è¾¨ç‡è¯´è¯äººå¤´éƒ¨ç”Ÿæˆ</li><li>ä½œè€…ï¼šShuai Tan, Bin Ji, Ye Pan</li><li>å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li><li>å…³é”®è¯ï¼šéŸ³é¢‘é©±åŠ¨ã€è¯´è¯äººå¤´éƒ¨ç”Ÿæˆã€æƒ…ç»ªé£æ ¼ã€è‰ºæœ¯é£æ ¼ã€æ–‡æœ¬æ§åˆ¶ã€å›¾åƒæ§åˆ¶</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.06365</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè‡ªåŠ¨ç”ŸæˆéŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨è§†é¢‘è¿‘å¹´æ¥å¤‡å—å…³æ³¨ï¼Œä½†ä»¥å¾€çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å®ç°éŸ³é¢‘å”‡å½¢åŒæ­¥ï¼Œå¿½è§†äº†ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›è§†é¢‘çš„ä¸¤ä¸ªå…³é”®å…ƒç´ ï¼šæƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šä»¥å¾€æ–¹æ³•è¦ä¹ˆä½¿ç”¨å•ä¸€çš„çƒ­æƒ…ç»ªæ ‡ç­¾ä½œä¸ºæƒ…ç»ªæºï¼Œé™åˆ¶äº†è¡¨æƒ…èŒƒå›´ï¼Œè¦ä¹ˆä¾èµ–é¢å¤–çš„è¡¨æƒ…è§†é¢‘ï¼Œè¿™å¯èƒ½ä¸æ–¹ä¾¿ã€‚æ­¤å¤–ï¼Œè™½ç„¶å•å¹…å›¾åƒé£æ ¼è¿ç§»å·²æœ‰å¤§é‡ç ”ç©¶ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨ç”Ÿæˆç”±éŸ³é¢‘é©±åŠ¨çš„è¿ç»­è§†é¢‘æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººé¢éƒ¨ç”Ÿæˆæ–¹æ³• Style2Talkerã€‚å®ƒåŒ…æ‹¬ä¸¤ä¸ªé£æ ¼åŒ–é˜¶æ®µï¼šStyle-E å’Œ Style-Aï¼Œåˆ†åˆ«å°†æ–‡æœ¬æ§åˆ¶çš„æƒ…ç»ªé£æ ¼å’Œå›¾åƒæ§åˆ¶çš„è‰ºæœ¯é£æ ¼é›†æˆåˆ°æœ€ç»ˆè¾“å‡ºä¸­ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒStyle2Talker åœ¨éŸ³é¢‘å”‡å½¢åŒæ­¥ã€æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼çš„æ€§èƒ½æ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…¼å…·æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼çš„é«˜åˆ†è¾¨ç‡è¯´è¯äººå¤´éƒ¨è§†é¢‘ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰æ–‡æœ¬æ§åˆ¶çš„æƒ…ç»ªé£æ ¼è¿ç§»ï¼ˆStyle-Eï¼‰ï¼šå°†æ–‡æœ¬æ§åˆ¶çš„æƒ…ç»ªæ ‡ç­¾è½¬æ¢ä¸º 3DMM ç³»æ•°åºåˆ—ï¼Œå¹¶åˆ©ç”¨ StyleGAN ç”Ÿæˆå…·æœ‰ç›¸åº”æƒ…ç»ªé£æ ¼çš„å›¾åƒåºåˆ—ã€‚ï¼ˆ2ï¼‰å›¾åƒæ§åˆ¶çš„è‰ºæœ¯é£æ ¼è¿ç§»ï¼ˆStyle-Aï¼‰ï¼šå¼•å…¥ ModResBlock è°ƒæ•´ StyleGAN çš„ç»“æ„é£æ ¼ï¼Œå¹¶åˆ©ç”¨è¿åŠ¨ç”Ÿæˆå™¨ Gm å°†é¢„æµ‹çš„è¿åŠ¨åºåˆ—è½¬æ¢ä¸ºç©ºé—´ç‰¹å¾å›¾ï¼Œä»è€Œå®ç°è‰ºæœ¯é£æ ¼çš„è¿ç§»ã€‚ï¼ˆ3ï¼‰å†…å®¹ç¼–ç å™¨å’Œç»†åŒ–ç½‘ç»œï¼šé‡‡ç”¨å†…å®¹ç¼–ç å™¨ Ec æå–å¤šå°ºåº¦å†…å®¹ç‰¹å¾ï¼Œé€šè¿‡è·³è·ƒè¿æ¥è¡¥å……çº¹ç†ç»†èŠ‚ï¼›å¼•å…¥ç»†åŒ–ç½‘ç»œ R è°ƒæ•´ç©ºé—´ç‰¹å¾å›¾ï¼Œæ¶ˆé™¤é‡å½±ä¼ªå½±ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„æ„ä¹‰ï¼šæå‡ºäº†ä¸€ç§åˆ›æ–°çš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ–¹æ³• Style2Talkerï¼Œè¯¥æ–¹æ³•é€šè¿‡èåˆç›¸åº”çš„é£æ ¼æç¤ºï¼Œç”Ÿæˆå…¼å…·æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼çš„é«˜åˆ†è¾¨ç‡è¯´è¯äººå¤´éƒ¨è§†é¢‘ã€‚æˆ‘ä»¬åˆ©ç”¨åŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å…äººå·¥æ–‡æœ¬æ ‡æ³¨ç®¡é“ï¼Œä»æ–‡æœ¬è¾“å…¥ä¸­è·å–ç”¨äºå­¦ä¹ æƒ…ç»ªé£æ ¼çš„æ–‡æœ¬æè¿°ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„å°è¯•èƒ½æ¿€å‘æ›´æ·±å…¥çš„ç ”ç©¶ï¼Œåˆ©ç”¨å‡ºè‰²çš„ã€å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ›´å®ç”¨ã€æ›´å¼•äººå…¥èƒœçš„æ¢ç´¢ã€‚ä¸ºäº†å°†æƒ…ç»ªé£æ ¼æ³¨å…¥åˆ° 3D è¿åŠ¨ç³»æ•°ä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé«˜æ•ˆçš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…·æœ‰å¤šä¸ªç¼–ç å™¨ï¼Œç¡®ä¿ç”Ÿæˆé€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„é¢éƒ¨è¡¨æƒ…ã€‚æˆ‘ä»¬å°†ä¸€ä¸ªæƒ…ç»ªé©±åŠ¨æ¨¡å—å’Œä¸€ä¸ªé¢å¤–çš„è‰ºæœ¯é£æ ¼è·¯å¾„çº³å…¥ StyleGAN æ¶æ„ä¸­ï¼Œä»è€Œå®ç°ç³»æ•°é©±åŠ¨çš„è§†é¢‘ç”Ÿæˆï¼Œå¹¶å…·æœ‰æœŸæœ›çš„æƒ…ç»ªå’Œè‰ºæœ¯é£æ ¼ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºè§†è§‰è´¨é‡å¹¶æ¶ˆé™¤ä¼ªå½±ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å†…å®¹ç¼–ç å™¨å’Œç»†åŒ–ç½‘ç»œã€‚å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆæ›´å¤šé£æ ¼åŒ–çš„åŠ¨ç”»ç»“æœã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬çš„å…äººå·¥æƒ…ç»ªæ ‡ç­¾è·å–ç®¡é“ï¼Œç”¨äºå­¦ä¹ æƒ…ç»ªé£æ ¼ã€‚</li><li>è®¾è®¡äº†ä¸€ä¸ªå¤šç¼–ç å™¨æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå°†æ–‡æœ¬æ§åˆ¶çš„æƒ…ç»ªæ ‡ç­¾è½¬æ¢ä¸º 3D è¿åŠ¨ç³»æ•°ï¼Œä»è€Œç”Ÿæˆé€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„é¢éƒ¨è¡¨æƒ…ã€‚</li><li>åœ¨ StyleGAN æ¶æ„ä¸­èåˆäº†ä¸€ä¸ªæƒ…ç»ªé©±åŠ¨æ¨¡å—å’Œä¸€ä¸ªé¢å¤–çš„è‰ºæœ¯é£æ ¼è·¯å¾„ï¼Œå®ç°ç³»æ•°é©±åŠ¨çš„è§†é¢‘ç”Ÿæˆï¼Œå¹¶å…·æœ‰æœŸæœ›çš„æƒ…ç»ªå’Œè‰ºæœ¯é£æ ¼ã€‚</li><li>é‡‡ç”¨äº†ä¸€ä¸ªå†…å®¹ç¼–ç å™¨å’Œä¸€ä¸ªç»†åŒ–ç½‘ç»œï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºè§†è§‰è´¨é‡å¹¶æ¶ˆé™¤ä¼ªå½±ã€‚æ€§èƒ½ï¼š</li><li>åœ¨éŸ³é¢‘å”‡å½¢åŒæ­¥ã€æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼æ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚å·¥ä½œé‡ï¼š</li><li>æ–‡æœ¬æ ‡æ³¨å·¥ä½œé‡ä½ï¼Œå› ä¸ºåˆ©ç”¨äº†åŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å…äººå·¥æ–‡æœ¬æ ‡æ³¨ç®¡é“ã€‚</li><li>æ¨¡å‹è®­ç»ƒå’Œæ¨ç†æˆæœ¬è¾ƒé«˜ï¼Œå› ä¸ºä½¿ç”¨äº† StyleGAN å’Œæ‰©æ•£æ¨¡å‹ç­‰å¤æ‚æ¨¡å‹ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-d09922b44587a2c7a0d9914314bc2819.jpg" align="middle"><img src="https://pica.zhimg.com/v2-7a916164c4c80e4c155763e1f38efcd1.jpg" align="middle"><img src="https://picx.zhimg.com/v2-0049142b2593b96773c9362d691fff94.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3380ba10087f173dca5f8c5d5df37735.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-13  A Comparative Study of Perceptual Quality Metrics for Audio-driven   Talking Head Videos</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="Talking Head Generation" scheme="https://kedreamix.github.io/tags/Talking-Head-Generation/"/>
    
  </entry>
  
  <entry>
    <title>Diffusion Models</title>
    <link href="https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/Diffusion%20Models/"/>
    <id>https://kedreamix.github.io/2024/03/13/Paper/2024-03-13/Diffusion%20Models/</id>
    <published>2024-03-13T05:45:36.000Z</published>
    <updated>2024-03-13T05:45:36.542Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-13-æ›´æ–°"><a href="#2024-03-13-æ›´æ–°" class="headerlink" title="2024-03-13 æ›´æ–°"></a>2024-03-13 æ›´æ–°</h1><h2 id="Bridging-Different-Language-Models-and-Generative-Vision-Models-for-Text-to-Image-Generation"><a href="#Bridging-Different-Language-Models-and-Generative-Vision-Models-for-Text-to-Image-Generation" class="headerlink" title="Bridging Different Language Models and Generative Vision Models for   Text-to-Image Generation"></a>Bridging Different Language Models and Generative Vision Models for   Text-to-Image Generation</h2><p><strong>Authors:Shihao Zhao, Shaozhe Hao, Bojia Zi, Huaizhe Xu, Kwan-Yee K. Wong</strong></p><p>Text-to-image generation has made significant advancements with the introduction of text-to-image diffusion models. These models typically consist of a language model that interprets user prompts and a vision model that generates corresponding images. As language and vision models continue to progress in their respective domains, there is a great potential in exploring the replacement of components in text-to-image diffusion models with more advanced counterparts. A broader research objective would therefore be to investigate the integration of any two unrelated language and generative vision models for text-to-image generation. In this paper, we explore this objective and propose LaVi-Bridge, a pipeline that enables the integration of diverse pre-trained language models and generative vision models for text-to-image generation. By leveraging LoRA and adapters, LaVi-Bridge offers a flexible and plug-and-play approach without requiring modifications to the original weights of the language and vision models. Our pipeline is compatible with various language models and generative vision models, accommodating different structures. Within this framework, we demonstrate that incorporating superior modules, such as more advanced language models or generative vision models, results in notable improvements in capabilities like text alignment or image quality. Extensive evaluations have been conducted to verify the effectiveness of LaVi-Bridge. Code is available at <a href="https://github.com/ShihaoZhaoZSH/LaVi-Bridge">https://github.com/ShihaoZhaoZSH/LaVi-Bridge</a>. </p><p><a href="http://arxiv.org/abs/2403.07860v1">PDF</a> </p><p><strong>Summary</strong><br>æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­ï¼Œæ¢ç´¢ç”¨æ›´å…ˆè¿›çš„è¯­è¨€å’Œå¤§è§„æ¨¡è§†è§‰æ¨¡å‹æ›¿æ¢æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„æˆéƒ¨åˆ†ï¼Œä»¥æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­ï¼Œå°†è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆåˆ°ä¸€ä¸ªç®¡é“ä¸­ã€‚</li><li>LaVi-Bridgeç®¡é“ä½¿é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹èƒ½å¤Ÿçµæ´»åœ°é›†æˆã€‚</li><li>ä½¿ç”¨LaVi-Bridgeå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè€Œæ— éœ€ä¿®æ”¹æ¨¡å‹çš„åŸå§‹æƒé‡ã€‚</li><li>LaVi-Bridgeä¸å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹å…¼å®¹ï¼Œå¯é€‚åº”ä¸åŒçš„ç»“æ„ã€‚</li><li>å°†æ›´é«˜çº§çš„è¯­è¨€æ¨¡å‹æˆ–ç”Ÿæˆè§†è§‰æ¨¡å‹ä¸LaVi-Bridgeé›†æˆå¯ä»¥æé«˜æ–‡æœ¬å¯¹é½æˆ–å›¾åƒè´¨é‡ã€‚</li><li>å¹¿æ³›çš„è¯„ä¼°éªŒè¯äº†LaVi-Bridgeçš„æœ‰æ•ˆæ€§ã€‚</li><li>ä»£ç å¯åœ¨<a href="https://github.com/ShihaoZhaoZSH/LaVi-Bridgeè·å¾—ã€‚">https://github.com/ShihaoZhaoZSH/LaVi-Bridgeè·å¾—ã€‚</a></li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šBridging Different Language Models and Generative Vision Models for Text-to-Image Generation</li><li>ä½œè€…ï¼šShihao Zhao, Shaozhe Hao, Bojia Zi, Huaizhe Xu, Kwan-Yee K. Wong</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯å¤§å­¦</li><li>å…³é”®è¯ï¼šDiffusion model, Text-to-image generation</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.07860</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹é€šå¸¸ç”±ä¸€ä¸ªè§£é‡Šç”¨æˆ·æç¤ºçš„è¯­è¨€æ¨¡å‹å’Œä¸€ä¸ªç”Ÿæˆç›¸åº”å›¾åƒçš„è§†è§‰æ¨¡å‹ç»„æˆã€‚éšç€è¯­è¨€å’Œè§†è§‰æ¨¡å‹åœ¨å…¶å„è‡ªé¢†åŸŸä¸æ–­è¿›æ­¥ï¼Œæ¢ç´¢ç”¨æ›´å…ˆè¿›çš„æ¨¡å‹æ›¿æ¢æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„ç»„ä»¶å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚å› æ­¤ï¼Œä¸€ä¸ªæ›´å¹¿æ³›çš„ç ”ç©¶ç›®æ ‡æ˜¯ç ”ç©¶å°†ä»»ä½•ä¸¤ä¸ªä¸ç›¸å…³çš„è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼šéœ€è¦ä¿®æ”¹è¯­è¨€å’Œè§†è§‰æ¨¡å‹çš„åŸå§‹æƒé‡ï¼Œçµæ´»æ€§å·®ï¼Œæ— æ³•é€‚åº”ä¸åŒçš„ç»“æ„ã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº† LaVi-Bridgeï¼Œè¿™æ˜¯ä¸€ä¸ªæ”¯æŒå°†ä¸åŒçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ç®¡é“ã€‚é€šè¿‡åˆ©ç”¨ LoRA å’Œé€‚é…å™¨ï¼ŒLaVi-Bridge æä¾›äº†ä¸€ç§çµæ´»ä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œæ— éœ€ä¿®æ”¹è¯­è¨€å’Œè§†è§‰æ¨¡å‹çš„åŸå§‹æƒé‡ã€‚æˆ‘ä»¬çš„ç®¡é“ä¸å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹å…¼å®¹ï¼Œå¯é€‚åº”ä¸åŒçš„ç»“æ„ã€‚ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šåœ¨è¯¥æ¡†æ¶å†…ï¼Œæˆ‘ä»¬è¯æ˜äº†ç»“åˆæ›´é«˜çº§çš„æ¨¡å—ï¼ˆä¾‹å¦‚æ›´é«˜çº§çš„è¯­è¨€æ¨¡å‹æˆ–ç”Ÿæˆè§†è§‰æ¨¡å‹ï¼‰å¯ä»¥æ˜¾ç€æé«˜æ–‡æœ¬å¯¹é½æˆ–å›¾åƒè´¨é‡ç­‰èƒ½åŠ›ã€‚å·²ç»è¿›è¡Œäº†å¹¿æ³›çš„è¯„ä¼°æ¥éªŒè¯ LaVi-Bridge çš„æœ‰æ•ˆæ€§ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1): é‡‡ç”¨æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨LoRAå’Œé€‚é…å™¨å°†ä¸åŒè¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆï¼Œæ— éœ€ä¿®æ”¹åŸå§‹æƒé‡ã€‚(2): è¯­è¨€æ¨¡å‹å’Œè§†è§‰æ¨¡å‹çš„äº¤äº’é€šè¿‡äº¤å‰æ³¨æ„åŠ›å±‚å®ç°ï¼ŒLoRAå¼•å…¥å¯è®­ç»ƒå‚æ•°ï¼Œé€‚é…å™¨ä¿ƒè¿›å¯¹é½ã€‚(3): ä¿æŒè¯­è¨€å’Œè§†è§‰æ¨¡å‹å›ºå®šï¼Œä»…è®­ç»ƒ LoRA å’Œé€‚é…å™¨å‚æ•°ï¼Œé€‚åº”å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹ç»“æ„ã€‚</p></li></ol><p>8.ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºLaVi-Bridgeï¼Œå®ƒé€‚ç”¨äºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚LaVi-Bridgeèƒ½å¤Ÿè¿æ¥å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹ï¼Œç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚å®ƒå…·æœ‰é«˜åº¦é€šç”¨æ€§ï¼Œå¯ä»¥é€‚åº”ä¸åŒçš„ç»“æ„ã€‚LaVi-Bridgeè¿˜å¾ˆçµæ´»ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨ä¸ä¿®æ”¹è¯­è¨€å’Œè§†è§‰æ¨¡å‹çš„åŸå§‹æƒé‡çš„åŸºç¡€ä¸Šå®ç°é›†æˆã€‚ç›¸åï¼Œå®ƒåˆ©ç”¨LoRAå’Œé€‚é…å™¨è¿›è¡Œå¾®è°ƒã€‚æ­¤å¤–ï¼Œåœ¨LaVi-Bridgeä¸‹ï¼Œä½¿ç”¨æ›´é«˜çº§çš„è¯­è¨€æˆ–è§†è§‰æ¨¡å‹å¯ä»¥å¢å¼ºæ–‡æœ¬ç†è§£èƒ½åŠ›æˆ–å›¾åƒè´¨é‡ã€‚è¿™äº›ä¼˜åŠ¿ä½¿å¾—LaVi-Bridgeèƒ½å¤Ÿå¸®åŠ©æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œä»¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™é¡¹ä»»åŠ¡å…·æœ‰é‡è¦çš„ç ”ç©¶ä»·å€¼ï¼Œéœ€è¦è¿›ä¸€æ­¥æ¢ç´¢ã€‚LaVi-Bridgeå…è®¸è®¾è®¡å¸ˆã€è‰ºæœ¯å®¶å’Œå…¶ä»–ç”¨æˆ·çµæ´»åœ°åˆ©ç”¨ç°æœ‰çš„è¯­è¨€å’Œè§†è§‰æ¨¡å‹æ¥å®ç°ä»–ä»¬çš„åˆ›ä½œç›®æ ‡ã€‚é¿å…æ»¥ç”¨å¹¶å‡è½»æ½œåœ¨çš„è´Ÿé¢ç¤¾ä¼šå½±å“è‡³å…³é‡è¦ã€‚åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œé‡è¦çš„æ˜¯è¦æ ‡å‡†åŒ–å…¶ä½¿ç”¨ï¼Œæé«˜æ¨¡å‹é€æ˜åº¦ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šLaVi-Bridgeæå‡ºäº†ä¸€ç§æ— éœ€ä¿®æ”¹è¯­è¨€å’Œè§†è§‰æ¨¡å‹åŸå§‹æƒé‡å³å¯å°†ä¸åŒè¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆåˆ°æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ç®¡é“ã€‚å®ƒåˆ©ç”¨LoRAå’Œé€‚é…å™¨åœ¨è¯­è¨€æ¨¡å‹å’Œè§†è§‰æ¨¡å‹ä¹‹é—´å»ºç«‹äº†å¯è®­ç»ƒçš„è¿æ¥ï¼Œä»è€Œå®ç°äº†çµæ´»ä¸”å³æ’å³ç”¨çš„é›†æˆã€‚æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒLaVi-Bridgeèƒ½å¤Ÿæ˜¾ç€æé«˜æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„èƒ½åŠ›ï¼Œä¾‹å¦‚æ–‡æœ¬å¯¹é½æˆ–å›¾åƒè´¨é‡ã€‚é€šè¿‡ç»“åˆæ›´é«˜çº§çš„è¯­è¨€æ¨¡å‹æˆ–ç”Ÿæˆè§†è§‰æ¨¡å‹ï¼ŒLaVi-Bridgeå¯ä»¥åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æœ€æ–°è¿›å±•ã€‚å·¥ä½œé‡ï¼šLaVi-Bridgeçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œåªéœ€è¦ä¿®æ”¹å°‘é‡ä»£ç å³å¯ã€‚å®ƒä¸å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹å…¼å®¹ï¼Œæ— éœ€å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œé‡å¤§ä¿®æ”¹ã€‚æ­¤å¤–ï¼ŒLaVi-Bridgeçš„è®­ç»ƒè¿‡ç¨‹æ˜¯é«˜æ•ˆä¸”ç¨³å®šçš„ï¼Œå¯ä»¥åœ¨åˆç†çš„æ—¶é—´å†…æ”¶æ•›ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-f9a99e7e4272d38b21737a5c189b093a.jpg" align="middle"><img src="https://picx.zhimg.com/v2-57e7ed33741950bb510e73e466f417ae.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-28925ac45e275e43cd57ccf0dd749a77.jpg" align="middle"></details>## Quantifying and Mitigating Privacy Risks for Tabular Generative Models**Authors:Chaoyi Zhu, Jiayi Tang, Hans Brouwer, Juan F. PÃ©rez, Marten van Dijk, Lydia Y. Chen**Synthetic data from generative models emerges as the privacy-preserving data-sharing solution. Such a synthetic data set shall resemble the original data without revealing identifiable private information. The backbone technology of tabular synthesizers is rooted in image generative models, ranging from Generative Adversarial Networks (GANs) to recent diffusion models. Recent prior work sheds light on the utility-privacy tradeoff on tabular data, revealing and quantifying privacy risks on synthetic data. We first conduct an exhaustive empirical analysis, highlighting the utility-privacy tradeoff of five state-of-the-art tabular synthesizers, against eight privacy attacks, with a special focus on membership inference attacks. Motivated by the observation of high data quality but also high privacy risk in tabular diffusion, we propose DP-TLDM, Differentially Private Tabular Latent Diffusion Model, which is composed of an autoencoder network to encode the tabular data and a latent diffusion model to synthesize the latent tables. Following the emerging f-DP framework, we apply DP-SGD to train the auto-encoder in combination with batch clipping and use the separation value as the privacy metric to better capture the privacy gain from DP algorithms. Our empirical evaluation demonstrates that DP-TLDM is capable of achieving a meaningful theoretical privacy guarantee while also significantly enhancing the utility of synthetic data. Specifically, compared to other DP-protected tabular generative models, DP-TLDM improves the synthetic quality by an average of 35% in data resemblance, 15% in the utility for downstream tasks, and 50% in data discriminability, all while preserving a comparable level of privacy risk. [PDF](http://arxiv.org/abs/2403.07842v1) **Summary**ç”Ÿæˆæ¨¡å‹ä¸­çš„åˆæˆæ•°æ®æ˜¯ä¿æŠ¤æ•°æ®éšç§çš„æ•°æ®å…±äº«è§£å†³æ–¹æ¡ˆï¼Œæ—¢è¦è¿‘ä¼¼åŸå§‹æ•°æ®ï¼Œåˆä¸èƒ½æ³„éœ²å¯è¯†åˆ«çš„ç§äººä¿¡æ¯ã€‚**Key Takeaways**- åˆæˆæ•°æ®ç”Ÿæˆå™¨æŠ€æœ¯æºäºå›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¦‚ GAN å’Œæ‰©æ•£æ¨¡å‹ã€‚- è¡¨æ ¼æ‰©æ•£æ¨¡å‹åœ¨æ•°æ®è´¨é‡æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨éšç§æ–¹é¢å­˜åœ¨é£é™©ã€‚- DP-TLDMï¼ˆå·®å¼‚éšç§è¡¨æ ¼æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼‰é€šè¿‡ç¼–ç å™¨ç½‘ç»œå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹æ¥åˆæˆæ•°æ®ã€‚- DP-SGDã€æ‰¹æ¬¡è£å‰ªå’Œåˆ†ç¦»å€¼å¯ç”¨äºå¢å¼ºéšç§ä¿éšœã€‚- DP-TLDM å¯æœ‰æ•ˆæå‡åˆæˆæ•°æ®è´¨é‡å’Œæ•ˆç”¨ï¼ŒåŒæ—¶ä¿æŒè¾ƒä½çš„éšç§é£é™©ã€‚- DP-TLDM å¯å°†æ•°æ®ç›¸ä¼¼æ€§æé«˜ 35%ã€ä¸‹æ¸¸ä»»åŠ¡æ•ˆç”¨æé«˜ 15%ã€æ•°æ®å¯åŒºåˆ†æ€§æé«˜ 50%ã€‚- DP-TLDM åœ¨ä¿æŠ¤éšç§çš„åŒæ—¶æé«˜äº†æ•°æ®æ•ˆç”¨ï¼Œä¼˜äºå…¶ä»– DP è¡¨æ ¼ç”Ÿæˆæ¨¡å‹ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>è®ºæ–‡æ ‡é¢˜ï¼šé‡åŒ–å’Œç¼“è§£è¡¨æ ¼ç”Ÿæˆæ¨¡å‹çš„éšç§é£é™©</li><li>ä½œè€…ï¼šChaoyi Zhu, Jiayi Tang, Hans Brouwer, Juan F. PÃ©rez, Marten van Dijk, Lydia Y. Chen</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä»£å°”å¤«ç‰¹ç†å·¥å¤§å­¦</li><li>å…³é”®è¯ï¼šåˆæˆè¡¨æ ¼æ•°æ®ã€æ·±åº¦ç”Ÿæˆæ¨¡å‹ã€å·®åˆ†éšç§</li><li>è®ºæ–‡é“¾æ¥ï¼šNoneGithub é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåˆæˆæ•°æ®ä»ç”Ÿæˆæ¨¡å‹ä¸­è·å–ï¼Œä½œä¸ºä¸€ç§ä¿æŠ¤éšç§çš„æ•°æ®å…±äº«è§£å†³æ–¹æ¡ˆã€‚æ­¤ç±»åˆæˆæ•°æ®é›†åº”ç±»ä¼¼äºåŸå§‹æ•°æ®ï¼Œä¸”ä¸æ³„éœ²å¯è¯†åˆ«çš„éšç§ä¿¡æ¯ã€‚è¡¨æ ¼åˆæˆå™¨çš„éª¨å¹²æŠ€æœ¯æ ¹æ¤äºå›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œä»ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) åˆ°æœ€è¿‘çš„æ‰©æ•£æ¨¡å‹ã€‚æœ€è¿‘çš„å…ˆå‰å·¥ä½œé˜æ˜äº†è¡¨æ ¼æ•°æ®ä¸Šçš„æ•ˆç”¨éšç§æƒè¡¡ï¼Œæ­ç¤ºå¹¶é‡åŒ–äº†åˆæˆæ•°æ®çš„éšç§é£é™©ã€‚ç„¶è€Œï¼Œé‡ç‚¹ä»…é™äºå°‘æ•°éšç§æ”»å‡»å’Œè¡¨æ ¼åˆæˆå™¨ï¼Œç‰¹åˆ«æ˜¯åŸºäº GAN çš„åˆæˆå™¨ï¼Œå¹¶ä¸”å¿½ç•¥äº†æˆå‘˜æ¨æ–­æ”»å‡»å’Œé˜²å¾¡ç­–ç•¥ï¼Œå³å·®åˆ†éšç§ã€‚ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šä¸ºäº†å¼¥åˆå·®è·ï¼Œæˆ‘ä»¬è§£å†³äº†ä¸¤ä¸ªç ”ç©¶é—®é¢˜ï¼š(i) è€ƒè™‘åˆ°æ›´å¹¿æ³›çš„åˆæˆå™¨é›†åˆåŠå…¶å¯¹æˆå‘˜æ¨æ–­æ”»å‡»çš„æ€§èƒ½ï¼Œå“ªç§ç±»å‹çš„è¡¨æ ¼ç”Ÿæˆæ¨¡å‹å¯ä»¥å®ç°æ›´å¥½çš„æ•ˆç”¨éšç§æƒè¡¡ï¼›(ii) é€šè¿‡å·®åˆ†éšç§éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³• (DP-SGD) å¯ä»¥è·å¾—ä»€ä¹ˆé¢å¤–çš„éšç§ä¿è¯ã€‚æˆ‘ä»¬é¦–å…ˆè¿›è¡Œè¯¦å°½çš„ç»éªŒåˆ†æï¼Œé‡ç‚¹å…³æ³¨æˆå‘˜æ¨æ–­æ”»å‡»ï¼Œé’ˆå¯¹å…«ç§éšç§æ”»å‡»ï¼Œå¼ºè°ƒäº†äº”ç§æœ€å…ˆè¿›çš„è¡¨æ ¼åˆæˆå™¨çš„æ•ˆç”¨éšç§æƒè¡¡ã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šå—è¡¨æ ¼æ‰©æ•£ä¸­æ•°æ®è´¨é‡é«˜ä½†éšç§é£é™©ä¹Ÿé«˜çš„è§‚å¯Ÿç»“æœçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº† DP-TLDMï¼Œå·®åˆ†éšç§è¡¨æ ¼æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå®ƒç”±ä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œç»„æˆï¼Œç”¨äºå¯¹è¡¨æ ¼æ•°æ®è¿›è¡Œç¼–ç ï¼Œä»¥åŠä¸€ä¸ªæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºåˆæˆæ½œåœ¨è¡¨æ ¼ã€‚éµå¾ªæ–°å…´çš„ ğ‘“-DP æ¡†æ¶ï¼Œæˆ‘ä»¬å°† DP-SGD åº”ç”¨äºè®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨ï¼Œç»“åˆæ‰¹å¤„ç†å‰ªè£ï¼Œå¹¶ä½¿ç”¨è¿™äº›åˆ†ç¦»å€¼ä½œä¸ºéšç§åº¦é‡ï¼Œä»¥æ›´å¥½åœ°æ•æ‰ DP ç®—æ³•çš„éšç§æ”¶ç›Šã€‚ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šæˆ‘ä»¬çš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼ŒDP-TLDM èƒ½å¤Ÿå®ç°æœ‰æ„ä¹‰çš„ç†è®ºéšç§ä¿è¯ï¼ŒåŒæ—¶è¿˜æ˜¾ç€æé«˜åˆæˆæ•°æ®çš„æ•ˆç”¨ã€‚å…·ä½“è€Œè¨€ï¼Œä¸å…¶ä»– DP ä¿æŠ¤è¡¨æ ¼ç”Ÿæˆæ¨¡å‹ç›¸æ¯”ï¼ŒDP-TLDM å°†åˆæˆè´¨é‡æé«˜äº†å¹³å‡ 35%ï¼Œä¸‹æ¸¸ä»»åŠ¡çš„æ•ˆç”¨æé«˜äº† 15%ï¼Œæ•°æ®å¯åŒºåˆ†åº¦æé«˜äº† 50%ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸å½“æ°´å¹³çš„éšç§é£é™©ã€‚</li></ol><p><strong>æ–¹æ³•</strong></p><p>(1) <strong>éšç§æ”»å‡»åˆ†æï¼š</strong>é’ˆå¯¹ 5 ç§æœ€å…ˆè¿›çš„è¡¨æ ¼åˆæˆå™¨å’Œ 8 ç§éšç§æ”»å‡»ï¼Œè¿›è¡Œè¯¦å°½çš„ç»éªŒåˆ†æï¼Œé‡ç‚¹å…³æ³¨æˆå‘˜æ¨æ–­æ”»å‡»ï¼Œå¼ºè°ƒå…¶æ•ˆç”¨éšç§æƒè¡¡ã€‚</p><p>(2) <strong>DP-TLDM æ¨¡å‹ï¼š</strong>æå‡ºå·®åˆ†éšç§è¡¨æ ¼æ½œåœ¨æ‰©æ•£æ¨¡å‹ (DP-TLDM)ï¼Œç”±è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ç»„æˆï¼Œéµå¾ª f-DP æ¡†æ¶ï¼Œå°† DP-SGD åº”ç”¨äºè®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨ï¼Œå¹¶ç»“åˆæ‰¹å¤„ç†å‰ªè£ã€‚</p><p>(3) <strong>éšç§åº¦é‡ï¼š</strong>ä½¿ç”¨åˆ†ç¦»å€¼ä½œä¸ºéšç§åº¦é‡ï¼Œæ›´å¥½åœ°æ•æ‰ DP ç®—æ³•çš„éšç§æ”¶ç›Šã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶å·¥ä½œé€šè¿‡é‡åŒ–å’Œç¼“è§£è¡¨æ ¼ç”Ÿæˆæ¨¡å‹çš„éšç§é£é™©ï¼Œä¸ºåˆæˆè¡¨æ ¼æ•°æ®çš„å®‰å…¨å…±äº«æä¾›äº†ç†è®ºæŒ‡å¯¼å’ŒæŠ€æœ¯æ”¯æŒã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°çš„å·®åˆ†éšç§è¡¨æ ¼æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆDP-TLDMï¼‰ï¼Œæœ‰æ•ˆåœ°å¹³è¡¡äº†åˆæˆæ•°æ®çš„æ•ˆç”¨å’Œéšç§é£é™©ã€‚</li><li>é‡‡ç”¨ f-DP æ¡†æ¶å’Œæ‰¹å¤„ç†å‰ªè£æŠ€æœ¯ï¼Œå¯¹è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹è¿›è¡Œéšç§ä¿æŠ¤ï¼Œæé«˜äº†åˆæˆæ•°æ®çš„éšç§ä¿è¯ã€‚</li><li>ä½¿ç”¨åˆ†ç¦»å€¼ä½œä¸ºéšç§åº¦é‡ï¼Œæ›´å‡†ç¡®åœ°æ•æ‰ DP ç®—æ³•çš„éšç§æ”¶ç›Šã€‚æ€§èƒ½ï¼š</li><li>ä¸å…¶ä»– DP ä¿æŠ¤è¡¨æ ¼ç”Ÿæˆæ¨¡å‹ç›¸æ¯”ï¼ŒDP-TLDM å°†åˆæˆè´¨é‡æé«˜äº†å¹³å‡ 35%ï¼Œä¸‹æ¸¸ä»»åŠ¡çš„æ•ˆç”¨æé«˜äº† 15%ï¼Œæ•°æ®å¯åŒºåˆ†åº¦æé«˜äº† 50%ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸å½“æ°´å¹³çš„éšç§é£é™©ã€‚</li><li>åœ¨å¹¿æ³›çš„è¡¨æ ¼ç”Ÿæˆæ¨¡å‹å’Œéšç§æ”»å‡»ç»„åˆä¸Šè¿›è¡Œäº†è¯¦å°½çš„ç»éªŒåˆ†æï¼Œä¸ºé€‰æ‹©åˆé€‚çš„åˆæˆå™¨å’Œç¼“è§£éšç§é£é™©æä¾›äº†æŒ‡å¯¼ã€‚å·¥ä½œé‡ï¼š</li><li>æœ¬ç ”ç©¶å·¥ä½œæ¶‰åŠè¡¨æ ¼ç”Ÿæˆæ¨¡å‹çš„éšç§é£é™©è¯„ä¼°ã€å·®åˆ†éšç§ä¿æŠ¤æ¨¡å‹çš„æå‡ºå’Œå®ç°ï¼Œä»¥åŠå¤§é‡çš„å®éªŒéªŒè¯ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-88261d8594214e79fd8f14053221f4cd.jpg" align="middle"><img src="https://pica.zhimg.com/v2-8a6ba2ff82daf72ac247bc6db810b6b8.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a2b8468a15abf24eebadf158ef6cc36c.jpg" align="middle"><img src="https://pica.zhimg.com/v2-a865f3725b2cf16776255cd7f309f8b5.jpg" align="middle"></details><h2 id="Stable-Makeup-When-Real-World-Makeup-Transfer-Meets-Diffusion-Model"><a href="#Stable-Makeup-When-Real-World-Makeup-Transfer-Meets-Diffusion-Model" class="headerlink" title="Stable-Makeup: When Real-World Makeup Transfer Meets Diffusion Model"></a>Stable-Makeup: When Real-World Makeup Transfer Meets Diffusion Model</h2><p><strong>Authors:Yuxuan Zhang, Lifu Wei, Qing Zhang, Yiren Song, Jiaming Liu, Huaxia Li, Xu Tang, Yao Hu, Haibo Zhao</strong></p><p>Current makeup transfer methods are limited to simple makeup styles, making them difficult to apply in real-world scenarios. In this paper, we introduce Stable-Makeup, a novel diffusion-based makeup transfer method capable of robustly transferring a wide range of real-world makeup, onto user-provided faces. Stable-Makeup is based on a pre-trained diffusion model and utilizes a Detail-Preserving (D-P) makeup encoder to encode makeup details. It also employs content and structural control modules to preserve the content and structural information of the source image. With the aid of our newly added makeup cross-attention layers in U-Net, we can accurately transfer the detailed makeup to the corresponding position in the source image. After content-structure decoupling training, Stable-Makeup can maintain content and the facial structure of the source image. Moreover, our method has demonstrated strong robustness and generalizability, making it applicable to varioustasks such as cross-domain makeup transfer, makeup-guided text-to-image generation and so on. Extensive experiments have demonstrated that our approach delivers state-of-the-art (SOTA) results among existing makeup transfer methods and exhibits a highly promising with broad potential applications in various related fields. </p><p><a href="http://arxiv.org/abs/2403.07764v1">PDF</a> </p><p><strong>Summary</strong><br>é¢éƒ¨å½©å¦†è¿ç§»æ–¹æ³•åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œè¶…è¶Šç®€å•å¦†å®¹é£æ ¼ï¼Œå¯å°†å¤§é‡çœŸå®ä¸–ç•Œå¦†å®¹å¹³ç¨³è¿ç§»è‡³ç”¨æˆ·é¢éƒ¨ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>é‡‡ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‚</li><li>ä½¿ç”¨ç»†èŠ‚ä¿ç•™åŒ–å¦†ç¼–ç å™¨ç¼–ç åŒ–å¦†ç»†èŠ‚ã€‚</li><li>å¼•å…¥å†…å®¹å’Œç»“æ„æ§åˆ¶æ¨¡å—ï¼Œä»¥ä¿ç•™æºå›¾åƒçš„å†…å®¹å’Œç»“æ„ä¿¡æ¯ã€‚</li><li>åˆ©ç”¨ U-Net ä¸­æ·»åŠ çš„åŒ–å¦†äº¤å‰æ³¨æ„å±‚ï¼Œå¯å°†è¯¦ç»†çš„åŒ–å¦†å‡†ç¡®è¿ç§»åˆ°æºå›¾åƒå¯¹åº”ä½ç½®ã€‚</li><li>é€šè¿‡å†…å®¹ç»“æ„å»è€¦è®­ç»ƒï¼Œç¨³å®šåŒ–å¦†åŠŸèƒ½å¯ä»¥ä¿æŒæºå›¾åƒçš„å†…å®¹å’Œé¢éƒ¨ç»“æ„ã€‚</li><li>è¯¥æ–¹æ³•å…·å¤‡å¼ºå¤§çš„é²æ£’æ€§å’Œæ³›åŒ–æ€§ï¼Œå¯ç”¨äºå„ç§ä»»åŠ¡ï¼Œä¾‹å¦‚è·¨åŸŸåŒ–å¦†è¿ç§»å’ŒåŒ–å¦†æŒ‡å¯¼æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç­‰ã€‚</li><li>å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç°æœ‰çš„åŒ–å¦†è¿ç§»æ–¹æ³•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ (SOTA) ç»“æœï¼Œå¹¶ä¸”åœ¨ç›¸å…³é¢†åŸŸå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šStable-Makeupï¼šå½“ç°å®ä¸–ç•Œå¦†å®¹é‡ä¸Šæ‰©æ•£æ¨¡å‹</li><li>ä½œè€…ï¼šYuxuan Zhang1âˆ—, Lifu Wei3, Qing Zhang4, Yiren Song5, Jiaming Liu2â€ , Huaxia Li2, Xu Tang2, Yao Hu2, and Haibo Zhao2</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li><li>å…³é”®è¯ï¼šMakeup transfer, Diffusion model, Detail-Preserving makeup encoder, Content-structure decoupling</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://xiaojiu-z.github.io/Stable-Makeup.github.io/   Github ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š   ï¼ˆ1ï¼‰ï¼šç›®å‰çš„ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰çš„å¦†å®¹è¿ç§»æ–¹æ³•ä»…é™äºç®€å•çš„å¦†å®¹é£æ ¼ï¼Œéš¾ä»¥åº”ç”¨äºç°å®åœºæ™¯ã€‚   ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•å­˜åœ¨çš„é—®é¢˜æ˜¯ï¼šæ— æ³•è¿ç§»å¤æ‚å¤šæ ·çš„çœŸå®å¦†å®¹ã€‚æ–¹æ³•çš„åŠ¨æœºï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„å¦†å®¹è¿ç§»æ–¹æ³•ï¼Œå¯ä»¥é²æ£’åœ°å°†å¹¿æ³›çš„çœŸå®å¦†å®¹è¿ç§»åˆ°ç”¨æˆ·æä¾›çš„é¢éƒ¨ä¸Šã€‚   ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šStable-Makeup åŸºäºé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨ç»†èŠ‚ä¿æŒï¼ˆD-Pï¼‰å¦†å®¹ç¼–ç å™¨å¯¹å¦†å®¹ç»†èŠ‚è¿›è¡Œç¼–ç ã€‚å®ƒè¿˜é‡‡ç”¨å†…å®¹å’Œç»“æ„æ§åˆ¶æ¨¡å—æ¥ä¿ç•™æºå›¾åƒçš„å†…å®¹å’Œç»“æ„ä¿¡æ¯ã€‚åœ¨ U-Net ä¸­æ·»åŠ äº†æ–°çš„å¦†å®¹äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œå¯ä»¥å°†è¯¦ç»†çš„å¦†å®¹å‡†ç¡®åœ°è¿ç§»åˆ°æºå›¾åƒçš„ç›¸åº”ä½ç½®ã€‚ç»è¿‡å†…å®¹ç»“æ„è§£è€¦è®­ç»ƒåï¼ŒStable-Makeup å¯ä»¥ä¿æŒæºå›¾åƒçš„å†…å®¹å’Œé¢éƒ¨ç»“æ„ã€‚   ï¼ˆ4ï¼‰ï¼šæœ¬æ–‡æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨å¦†å®¹è¿ç§»ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œå¯ä»¥é²æ£’åœ°è¿ç§»å„ç§çœŸå®å¦†å®¹ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†å…¶ç›®æ ‡ï¼šå°†å¤æ‚å¤šæ ·çš„çœŸå®å¦†å®¹è¿ç§»åˆ°ç”¨æˆ·æä¾›çš„é¢éƒ¨ä¸Šã€‚</li></ol><p>7.æ–¹æ³•ï¼š(1)ï¼šåˆ©ç”¨ç»†èŠ‚ä¿æŒå¦†å®¹ç¼–ç å™¨æå–å‚è€ƒå¦†å®¹çš„ç»†èŠ‚ç‰¹å¾ï¼›ï¼ˆ2ï¼‰ï¼šé‡‡ç”¨å†…å®¹ç¼–ç å™¨å’Œç»“æ„ç¼–ç å™¨åˆ†åˆ«å¯¹æºå›¾åƒå’Œé¢éƒ¨ç»“æ„æ§åˆ¶å›¾åƒè¿›è¡Œç¼–ç ï¼›ï¼ˆ3ï¼‰ï¼šä½¿ç”¨å¦†å®¹äº¤å‰æ³¨æ„åŠ›å±‚å°†è¯¦ç»†å¦†å®¹åµŒå…¥ä¸æºå›¾åƒä¸­é¢éƒ¨åŒºåŸŸçš„ä¸­é—´ç‰¹å¾å›¾å¯¹é½ï¼›ï¼ˆ4ï¼‰ï¼šé€šè¿‡å†…å®¹ç»“æ„è§£è€¦è®­ç»ƒï¼Œä¿æŒæºå›¾åƒçš„å†…å®¹å’Œé¢éƒ¨ç»“æ„ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰è¯¥å·¥ä½œå°†ç°å®ä¸–ç•Œçš„å¦†å®¹è¿ç§»å¸¦å…¥æ‰©æ•£æ¨¡å‹é¢†åŸŸï¼Œåœ¨å¦†å®¹è¿ç§»ä»»åŠ¡ä¸Šå–å¾—äº†çªç ´æ€§çš„è¿›å±•ï¼Œå®ç°äº†ä»¥å¾€éš¾ä»¥å®ç°çš„æ•ˆæœã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§ç»†èŠ‚ä¿æŒå¦†å®¹ç¼–ç å™¨ï¼Œç”¨äºæå–å‚è€ƒå¦†å®¹çš„ç²¾ç»†ç‰¹å¾ã€‚</li><li>é‡‡ç”¨å†…å®¹å’Œç»“æ„æ§åˆ¶æ¨¡å—ï¼Œåˆ†åˆ«å¯¹æºå›¾åƒå’Œé¢éƒ¨ç»“æ„æ§åˆ¶å›¾åƒè¿›è¡Œç¼–ç ã€‚</li><li>ä½¿ç”¨å¦†å®¹äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œå°†è¯¦ç»†å¦†å®¹åµŒå…¥ä¸æºå›¾åƒä¸­é¢éƒ¨åŒºåŸŸçš„ä¸­é—´ç‰¹å¾å›¾å¯¹é½ã€‚</li><li>é€šè¿‡å†…å®¹ç»“æ„è§£è€¦è®­ç»ƒï¼Œä¿æŒæºå›¾åƒçš„å†…å®¹å’Œé¢éƒ¨ç»“æ„ä¸€è‡´æ€§ã€‚æ€§èƒ½ï¼š</li><li>åœ¨å¦†å®¹è¿ç§»ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œå¯ä»¥é²æ£’åœ°è¿ç§»å„ç§çœŸå®å¦†å®¹ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚å·¥ä½œé‡ï¼š</li><li>æå‡ºäº†ä¸€ç§è‡ªåŠ¨æµæ°´çº¿ï¼Œç”¨äºåˆ›å»ºå„ç§å¦†å®¹é…å¯¹æ•°æ®è¿›è¡Œè®­ç»ƒã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-481722553fcfcc03e397479a6260fb2a.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-2bff86407dc53580d4b616a78652a1e4.jpg" align="middle"></details><h2 id="SSM-Meets-Video-Diffusion-Models-Efficient-Video-Generation-with-Structured-State-Spaces"><a href="#SSM-Meets-Video-Diffusion-Models-Efficient-Video-Generation-with-Structured-State-Spaces" class="headerlink" title="SSM Meets Video Diffusion Models: Efficient Video Generation with   Structured State Spaces"></a>SSM Meets Video Diffusion Models: Efficient Video Generation with   Structured State Spaces</h2><p><strong>Authors:Yuta Oshima, Shohei Taniguchi, Masahiro Suzuki, Yutaka Matsuo</strong></p><p>Given the remarkable achievements in image generation through diffusion models, the research community has shown increasing interest in extending these models to video generation. Recent diffusion models for video generation have predominantly utilized attention layers to extract temporal features. However, attention layers are limited by their memory consumption, which increases quadratically with the length of the sequence. This limitation presents significant challenges when attempting to generate longer video sequences using diffusion models. To overcome this challenge, we propose leveraging state-space models (SSMs). SSMs have recently gained attention as viable alternatives due to their linear memory consumption relative to sequence length. In the experiments, we first evaluate our SSM-based model with UCF101, a standard benchmark of video generation. In addition, to investigate the potential of SSMs for longer video generation, we perform an experiment using the MineRL Navigate dataset, varying the number of frames to 64 and 150. In these settings, our SSM-based model can considerably save memory consumption for longer sequences, while maintaining competitive FVD scores to the attention-based models. Our codes are available at <a href="https://github.com/shim0114/SSM-Meets-Video-Diffusion-Models">https://github.com/shim0114/SSM-Meets-Video-Diffusion-Models</a>. </p><p><a href="http://arxiv.org/abs/2403.07711v1">PDF</a> Accepted as workshop paper at ICLR 2024</p><p><strong>Summary:</strong><br>æ‰©æ•£æ¨¡å‹ä¸­åˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹å…‹æœæ³¨æ„åŠ›å±‚çš„å†…å­˜æ¶ˆè€—éš¾é¢˜ï¼Œå®ç°æ›´é•¿çš„è§†é¢‘ç”Ÿæˆã€‚</p><p><strong>Key Takeaways:</strong></p><ul><li>æ‰©æ•£æ¨¡å‹å¹¿æ³›åˆ©ç”¨æ³¨æ„åŠ›å±‚ç”Ÿæˆè§†é¢‘ï¼Œä½†æ³¨æ„åŠ›å±‚çš„å†…å­˜æ¶ˆè€—éšåºåˆ—é•¿åº¦äºŒæ¬¡å¢é•¿ã€‚</li><li>çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ä»¥çº¿æ€§çš„å†…å­˜æ¶ˆè€—ç›¸å¯¹åºåˆ—é•¿åº¦ï¼Œä¸ºé•¿è§†é¢‘ç”Ÿæˆæä¾›äº†æ›¿ä»£æ–¹æ¡ˆã€‚</li><li>åœ¨ UCF101 è§†é¢‘ç”ŸæˆåŸºå‡†ä¸Šï¼ŒSSM æ¨¡å‹ä¸æ³¨æ„åŠ›æ¨¡å‹å…·æœ‰ç«äº‰åŠ›çš„ FVD è¯„åˆ†ã€‚</li><li>SSM æ¨¡å‹åœ¨ MineRL Navigate æ•°æ®é›†ä¸Šç”Ÿæˆ 64 å’Œ 150 å¸§çš„è§†é¢‘æ—¶ï¼Œå¤§å¹…èŠ‚çœäº†å†…å­˜æ¶ˆè€—ã€‚</li><li>SSM æ¨¡å‹åœ¨é•¿è§†é¢‘ç”Ÿæˆä¸­å…·æœ‰æ½œåŠ›ï¼Œå¯åœ¨ä¸ç‰ºç‰²è´¨é‡çš„æƒ…å†µä¸‹é™ä½å†…å­˜å¼€é”€ã€‚</li><li>ä»£ç å¯åœ¨ GitHub ä¸Šè·å¾—ï¼š<a href="https://github.com/shim0114/SSM-Meets-Video-Diffusion-Modelsã€‚">https://github.com/shim0114/SSM-Meets-Video-Diffusion-Modelsã€‚</a></li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šSSM é‡è§è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼šä½¿ç”¨ç»“æ„åŒ–çŠ¶æ€ç©ºé—´çš„é«˜æ•ˆè§†é¢‘ç”Ÿæˆ</li><li>ä½œè€…ï¼šShih-Yuan Chen, Yi-Hsuan Tsai, Yi-Ting Chen, Wei-Chih Hung, Ting-Chun Wang</li><li>æ‰€å±å•ä½ï¼šå›½ç«‹å°æ¹¾å¤§å­¦</li><li>å…³é”®è¯ï¼šè§†é¢‘ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€çŠ¶æ€ç©ºé—´æ¨¡å‹ã€é•¿ç¨‹ä¾èµ–æ€§</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08748ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š   (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼š   éšç€æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆä¸­å–å¾—æ˜¾è‘—æˆå°±ï¼Œç ”ç©¶ç•Œå¯¹å°†è¿™äº›æ¨¡å‹æ‰©å±•åˆ°è§†é¢‘ç”Ÿæˆè¶Šæ¥è¶Šæ„Ÿå…´è¶£ã€‚æœ€è¿‘çš„è§†é¢‘ç”Ÿæˆæ‰©æ•£æ¨¡å‹ä¸»è¦åˆ©ç”¨æ³¨æ„åŠ›å±‚æå–æ—¶é—´ç‰¹å¾ã€‚ç„¶è€Œï¼Œæ³¨æ„åŠ›å±‚çš„å†…å­˜æ¶ˆè€—å—åºåˆ—é•¿åº¦çš„äºŒæ¬¡æ–¹å½±å“ï¼Œè¿™ç»™ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆè¾ƒé•¿è§†é¢‘åºåˆ—å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚   (2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š   ä¸ºäº†å…‹æœæ³¨æ„åŠ›å±‚çš„é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºåˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ã€‚ä¸æ³¨æ„åŠ›å±‚ç›¸æ¯”ï¼ŒSSM çš„å†…å­˜æ¶ˆè€—ä¸åºåˆ—é•¿åº¦å‘ˆçº¿æ€§å…³ç³»ï¼Œå› æ­¤æ˜¯ä¸€ç§å¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆã€‚   (3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š   æœ¬æ–‡æå‡ºäº†ä¸€ç§å°† SSM ä¸è§†é¢‘æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æœ‰æ•ˆæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ç”¨åŒå‘ SSM æ¨¡å—æ›¿æ¢äº†ä¼ ç»Ÿæ—¶ç©ºå±‚ä¸­çš„æ³¨æ„åŠ›æ¨¡å—ï¼Œå¹¶åœ¨åŒå‘ SSM ä¹‹åæ·»åŠ äº†ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ã€‚   (4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼š   åœ¨å®éªŒä¸­ï¼Œæœ¬æ–‡é¦–å…ˆä½¿ç”¨ UCF101ï¼ˆè§†é¢‘ç”Ÿæˆæ ‡å‡†åŸºå‡†ï¼‰è¯„ä¼°äº†åŸºäº SSM çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç ”ç©¶ SSM åœ¨æ›´é•¿è§†é¢‘ç”Ÿæˆä¸­çš„æ½œåŠ›ï¼Œæœ¬æ–‡ä½¿ç”¨ MineRL Navigate æ•°æ®é›†è¿›è¡Œäº†å®éªŒï¼Œå°†å¸§æ•°åˆ†åˆ«è®¾ç½®ä¸º 64 å’Œ 150ã€‚åœ¨è¿™äº›è®¾ç½®ä¸­ï¼ŒåŸºäº SSM çš„æ¨¡å‹å¯ä»¥æ˜¾ç€èŠ‚çœè¾ƒé•¿åºåˆ—çš„å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“çš„ FVD åˆ†æ•°ã€‚</li></ol><p>Methodsï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å°†SSMä¸è§†é¢‘æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æœ‰æ•ˆæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ç”¨åŒå‘SSMæ¨¡å—æ›¿æ¢äº†ä¼ ç»Ÿæ—¶ç©ºå±‚ä¸­çš„æ³¨æ„åŠ›æ¨¡å—ï¼Œå¹¶åœ¨åŒå‘SSMä¹‹åæ·»åŠ äº†ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ã€‚ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡é‡‡ç”¨UCF101ï¼ˆè§†é¢‘ç”Ÿæˆæ ‡å‡†åŸºå‡†ï¼‰è¯„ä¼°äº†åŸºäºSSMçš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç ”ç©¶SSMåœ¨æ›´é•¿è§†é¢‘ç”Ÿæˆä¸­çš„æ½œåŠ›ï¼Œæœ¬æ–‡ä½¿ç”¨MineRLNavigateæ•°æ®é›†è¿›è¡Œäº†å®éªŒï¼Œå°†å¸§æ•°åˆ†åˆ«è®¾ç½®ä¸º64å’Œ150ã€‚ï¼ˆ3ï¼‰ï¼šåœ¨è¿™äº›è®¾ç½®ä¸­ï¼ŒåŸºäºSSMçš„æ¨¡å‹å¯ä»¥æ˜¾ç€èŠ‚çœè¾ƒé•¿åºåˆ—çš„å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“çš„FVDåˆ†æ•°ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å°†çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ä¸è§†é¢‘æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æœ‰æ•ˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ˜¾è‘—èŠ‚çœè¾ƒé•¿è§†é¢‘åºåˆ—çš„å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“çš„ç”Ÿæˆè´¨é‡ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§å°†SSMä¸è§†é¢‘æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æ–°æ–¹æ³•ã€‚</li><li>ä½¿ç”¨åŒå‘SSMæ¨¡å—æ›¿æ¢äº†ä¼ ç»Ÿæ—¶ç©ºå±‚ä¸­çš„æ³¨æ„åŠ›æ¨¡å—ï¼Œé™ä½äº†å†…å­˜æ¶ˆè€—ã€‚</li><li>åœ¨UCF101å’ŒMineRLNavigateæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æ€§èƒ½ï¼š</li><li>åœ¨UCF101æ•°æ®é›†ä¸Šï¼ŒåŸºäºSSMçš„æ¨¡å‹åœ¨FVDåˆ†æ•°ä¸Šä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“ã€‚</li><li>åœ¨MineRLNavigateæ•°æ®é›†ä¸Šï¼ŒåŸºäºSSMçš„æ¨¡å‹å¯ä»¥æ˜¾ç€èŠ‚çœè¾ƒé•¿åºåˆ—çš„å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“çš„FVDåˆ†æ•°ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä¸ç°æœ‰çš„è§†é¢‘æ‰©æ•£æ¨¡å‹é›†æˆã€‚</li><li>è¯¥æ–¹æ³•éœ€è¦é¢å¤–çš„è®¡ç®—èµ„æºæ¥è®­ç»ƒåŒå‘SSMæ¨¡å—ï¼Œä½†ä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸æ¯”ï¼Œå…¶å†…å­˜æ¶ˆè€—çš„èŠ‚çœå¯ä»¥æŠµæ¶ˆè¿™ä¸€é¢å¤–çš„è®¡ç®—æˆæœ¬ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-a0f2d31483fd32e25e8225d6d8c2b039.jpg" align="middle"><img src="https://pica.zhimg.com/v2-466831d067339c450f01dc616d49009f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-59e29fe8e02669abd07b749ea5015008.jpg" align="middle"><img src="https://picx.zhimg.com/v2-6b09844a4e5773a714f817c1ba660426.jpg" align="middle"><img src="https://picx.zhimg.com/v2-2e10f4a24354ea51e1e9b2b5de3d559d.jpg" align="middle"></details><h2 id="D4D-An-RGBD-diffusion-model-to-boost-monocular-depth-estimation"><a href="#D4D-An-RGBD-diffusion-model-to-boost-monocular-depth-estimation" class="headerlink" title="D4D: An RGBD diffusion model to boost monocular depth estimation"></a>D4D: An RGBD diffusion model to boost monocular depth estimation</h2><p><strong>Authors:L. Papa, P. Russo, I. Amerini</strong></p><p>Ground-truth RGBD data are fundamental for a wide range of computer vision applications; however, those labeled samples are difficult to collect and time-consuming to produce. A common solution to overcome this lack of data is to employ graphic engines to produce synthetic proxies; however, those data do not often reflect real-world images, resulting in poor performance of the trained models at the inference step. In this paper we propose a novel training pipeline that incorporates Diffusion4D (D4D), a customized 4-channels diffusion model able to generate realistic RGBD samples. We show the effectiveness of the developed solution in improving the performances of deep learning models on the monocular depth estimation task, where the correspondence between RGB and depth map is crucial to achieving accurate measurements. Our supervised training pipeline, enriched by the generated samples, outperforms synthetic and original data performances achieving an RMSE reduction of (8.2%, 11.9%) and (8.1%, 6.1%) respectively on the indoor NYU Depth v2 and the outdoor KITTI dataset. </p><p><a href="http://arxiv.org/abs/2403.07516v1">PDF</a> </p><p><strong>Summary</strong><br>é€šè¿‡Diffusion4Dç”ŸæˆçœŸå®RGBDæ ·æœ¬ï¼Œæå‡å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹æ€§èƒ½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>åœ°é¢å®å†µ RGBD æ•°æ®å¯¹äºè®¡ç®—æœºè§†è§‰è‡³å…³é‡è¦ï¼Œä½†è·å–å›°éš¾ä¸”è€—æ—¶ã€‚</li><li>ä½¿ç”¨å›¾å½¢å¼•æ“ç”Ÿæˆåˆæˆä»£ç†æ•°æ®å¯è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œä½†çœŸå®æ„Ÿä¸è¶³ã€‚</li><li>æå‡º Diffusion4Dï¼Œä¸€ç§å®šåˆ¶çš„ 4 é€šé“æ‰©æ•£æ¨¡å‹ï¼Œå¯ç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ã€‚</li><li>å°†ç”Ÿæˆçš„æ ·æœ¬çº³å…¥ç›‘ç£è®­ç»ƒç®¡é“ï¼Œå¯æé«˜å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹æ€§èƒ½ã€‚</li><li>åœ¨ NYU Depth v2 å®¤å†…å’Œ KITTI å®¤å¤–æ•°æ®é›†ä¸Šï¼Œä¸åˆæˆæ•°æ®å’ŒåŸå§‹æ•°æ®ç›¸æ¯”ï¼ŒRMSE åˆ†åˆ«é™ä½ (8.2%, 11.9%) å’Œ (8.1%, 6.1%)ã€‚</li><li>è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹ RGB å›¾åƒå’Œæ·±åº¦å›¾ä¹‹é—´çš„å¯¹åº”å…³ç³»å»ºæ¨¡å‡†ç¡®ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šD4Dï¼šä¸€ç§ç”¨äºæå‡å•ç›®æ·±åº¦ä¼°è®¡çš„ RGBD æ‰©æ•£æ¨¡å‹</li><li>ä½œè€…ï¼šLorenzo Papaã€Paolo Russoã€Irene Amerini</li><li>æ‰€å±å•ä½ï¼šæ„å¤§åˆ©ç½—é©¬ç¬¬ä¸€å¤§å­¦è®¡ç®—æœºã€æ§åˆ¶ä¸ç®¡ç†å·¥ç¨‹ç³»</li><li>å…³é”®è¯ï¼šè®¡ç®—æœºè§†è§‰ã€æ‰©æ•£æ¨¡å‹ã€æ·±åº¦å­¦ä¹ ã€å•ç›®æ·±åº¦ä¼°è®¡ã€ç”Ÿæˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰å’Œå›¾åƒå¤„ç†é¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å…¶éœ€è¦å¤§é‡æ ‡è®°è®­ç»ƒæ•°æ®ã€‚ç„¶è€Œï¼Œå¯¹äºå¯†é›†é¢„æµ‹åº”ç”¨ï¼ˆå¦‚æ·±åº¦ä¼°è®¡ï¼‰ï¼Œç”±äºæ”¶é›†ä¸€è‡´çš„ RGB å’Œæ·±åº¦æ•°æ®å­˜åœ¨å›°éš¾å’Œè€—æ—¶ï¼Œå› æ­¤ç¼ºä¹å¤§é‡çœŸå®æ•°æ®ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šä¸ºäº†è§£å†³æ•°æ®ç¼ºä¹é—®é¢˜ï¼Œå¸¸ç”¨çš„æ–¹æ³•æ˜¯ä½¿ç”¨åˆæˆæ¸²æŸ“ï¼ˆå¦‚ Unity å’Œ Unreal Engineï¼‰ç”Ÿæˆæ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯é€šå¸¸æ— æ³•æä¾›é€¼çœŸçš„æ•°æ®ï¼Œç¼ºä¹å‡†ç¡®çš„å…‰çº¿åå°„ã€ç›¸æœºä¼ªå½±å’Œå™ªå£°æ•°æ®ç­‰çœŸå®ç‰¹å¾ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º Diffusion4Dï¼ˆD4Dï¼‰çš„è®­ç»ƒç®¡é“ï¼Œè¯¥ç®¡é“åŸºäºå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰ã€‚D4D ä½¿ç”¨å®šåˆ¶çš„ 4 é€šé“ DDPM æ¥æ•æ‰çœŸå®å®¤å†…å’Œå®¤å¤– RGBD æ ·æœ¬ä¸­å­˜åœ¨çš„å†…åœ¨ä¿¡æ¯ï¼Œä»¥ç”Ÿæˆé€¼çœŸçš„ RGB å›¾åƒå’Œç›¸åº”çš„æ·±åº¦å›¾ï¼ŒåŒæ—¶æé«˜è®­ç»ƒæ ·æœ¬ä¹‹é—´çš„å¤šæ ·æ€§ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨å•ç›®æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸Šï¼Œåˆ©ç”¨ç”Ÿæˆçš„æ ·æœ¬å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒç®¡é“è¿›è¡Œäº†æ‰©å……ï¼Œåœ¨ NYUDepthv2 å’Œ KITTI æ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº† 8.2% å’Œ 11.9% çš„ RMSE é™ä½ï¼Œä»¥åŠ 8.1% å’Œ 6.1% çš„ RMSE é™ä½ã€‚è¿™äº›æ€§èƒ½æå‡è¡¨æ˜ï¼ŒD4D å¯ä»¥æœ‰æ•ˆåœ°ç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ï¼Œä»è€Œæé«˜æ·±åº¦ä¼°è®¡æ¨¡å‹çš„æ€§èƒ½ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰é¢„å¤„ç†ï¼šå¯¹çœŸå®ä¸–ç•Œä¸­çš„ RGBD æ ·æœ¬è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼ŒåŒ…æ‹¬å½’ä¸€åŒ–å’Œè°ƒæ•´å¤§å°ã€‚ï¼ˆ2ï¼‰ç”Ÿæˆï¼šä½¿ç”¨å®šåˆ¶çš„ 4 é€šé“å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ (DDPM) ç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ã€‚ï¼ˆ3ï¼‰åˆå¹¶ï¼šå°†ç”Ÿæˆçš„æ ·æœ¬ä¸åŸå§‹è®­ç»ƒæ•°æ®åˆå¹¶ï¼Œåˆ›å»ºæ‰©å……çš„è®­ç»ƒé›†ã€‚ï¼ˆ4ï¼‰è®­ç»ƒï¼šä½¿ç”¨æ‰©å……çš„è®­ç»ƒé›†è®­ç»ƒæ·±åº¦ä¼°è®¡æ¨¡å‹ï¼ŒåŒ…æ‹¬ DenseDepthã€FastDepthã€SPEED å’Œ METERã€‚ï¼ˆ5ï¼‰è¯„ä¼°ï¼šä½¿ç”¨ NYUDepthv2ã€KITTIã€SceneNetã€SYNTHIASF å’Œ DIML æµ‹è¯•é›†è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚</p></li><li><p>ç»“è®ºï¼š(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„è®­ç»ƒç®¡é“ï¼Œè¯¥ç®¡é“ç”± D4D ç»„æˆï¼ŒD4D æ˜¯ä¸€ä¸ªå®šåˆ¶çš„ 4 é€šé“ DDPMï¼Œç”¨äºç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ï¼Œç”¨äºæé«˜æ·±åº¦å’Œæµ…å±‚ MDE æ¨¡å‹çš„ä¼°è®¡æ€§èƒ½ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨å®¤å†…å’Œå®¤å¤–åœºæ™¯ä¸­å±•ç¤ºäº†ä¼˜äºåˆæˆç”Ÿæˆæ•°æ®é›†çš„æ€§èƒ½ï¼Œå¹³å‡ RMSE é™ä½äº† 8.2% å’Œ 8.1%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆåœ¨å®¤å†…åŸºçº¿ NYUDepthv2 å’Œå®¤å¤– KITTI æ•°æ®é›†ä¸Šå®ç°äº† 11.9% å’Œ 6.1% çš„ RMSE é™ä½ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ–¹æ³•ä»¥åŠç”Ÿæˆçš„æ•°æ®é›†ï¼ˆD4D-NYU å’Œ D4D-KITTIï¼‰å°†é¼“åŠ±å°† DDPM ä¸æ·±åº¦å­¦ä¹ æ¶æ„ç»“åˆä½¿ç”¨ï¼Œä»¥è§£å†³å„ç§è®¡ç®—æœºè§†è§‰åº”ç”¨ä¸­æ ‡è®°è®­ç»ƒæ•°æ®çš„ç¼ºä¹é—®é¢˜ã€‚æ‰€æå‡ºç­–ç•¥çš„ä¸€ä¸ªå…³é”®è¦ç´ æ˜¯ä½¿ç”¨çœŸå®ä¸–ç•Œå›¾åƒç”Ÿæˆæ–°çš„å¢å¼ºæ ·æœ¬ï¼Œä»è€Œæé«˜ MDE æ¨¡å‹åœ¨å®é™…åœºæ™¯ä¸­éƒ¨ç½²çš„ä¼°è®¡å’Œæ³›åŒ–èƒ½åŠ›ã€‚(2): åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäº DDPM çš„è®­ç»ƒç®¡é“ D4Dï¼Œç”¨äºç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ï¼Œä»¥å¢å¼ºå•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„è®­ç»ƒï¼›æ€§èƒ½ï¼šåœ¨ NYUDepthv2 å’Œ KITTI æ•°æ®é›†ä¸Šï¼Œåˆ†åˆ«å®ç°äº† 8.2% å’Œ 11.9% çš„ RMSE é™ä½ï¼›å·¥ä½œé‡ï¼šéœ€è¦å¯¹çœŸå®ä¸–ç•Œ RGBD æ ·æœ¬è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œå¹¶ä½¿ç”¨å®šåˆ¶çš„ DDPM ç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-7d5ae84aa4ad849eb5b34921fd19235f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-1fc5f5f060711d07a3643061bea9ce36.jpg" align="middle"><img src="https://pica.zhimg.com/v2-e8bf13f9f6d8ae61c864289783d74507.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-7b98512be7d612da9e4c36952c334f92.jpg" align="middle"></details><h2 id="Efficient-Diffusion-Model-for-Image-Restoration-by-Residual-Shifting"><a href="#Efficient-Diffusion-Model-for-Image-Restoration-by-Residual-Shifting" class="headerlink" title="Efficient Diffusion Model for Image Restoration by Residual Shifting"></a>Efficient Diffusion Model for Image Restoration by Residual Shifting</h2><p><strong>Authors:Zongsheng Yue, Jianyi Wang, Chen Change Loy</strong></p><p>While diffusion-based image restoration (IR) methods have achieved remarkable success, they are still limited by the low inference speed attributed to the necessity of executing hundreds or even thousands of sampling steps. Existing acceleration sampling techniques, though seeking to expedite the process, inevitably sacrifice performance to some extent, resulting in over-blurry restored outcomes. To address this issue, this study proposes a novel and efficient diffusion model for IR that significantly reduces the required number of diffusion steps. Our method avoids the need for post-acceleration during inference, thereby avoiding the associated performance deterioration. Specifically, our proposed method establishes a Markov chain that facilitates the transitions between the high-quality and low-quality images by shifting their residuals, substantially improving the transition efficiency. A carefully formulated noise schedule is devised to flexibly control the shifting speed and the noise strength during the diffusion process. Extensive experimental evaluations demonstrate that the proposed method achieves superior or comparable performance to current state-of-the-art methods on three classical IR tasks, namely image super-resolution, image inpainting, and blind face restoration, \textit{\textbf{even only with four sampling steps}}. Our code and model are publicly available at \url{<a href="https://github.com/zsyOAOA/ResShift}">https://github.com/zsyOAOA/ResShift}</a>. </p><p><a href="http://arxiv.org/abs/2403.07319v1">PDF</a> Extended version of NeurIPS paper. Code:   <a href="https://github.com/zsyOAOA/ResShift">https://github.com/zsyOAOA/ResShift</a></p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹å›¾åƒä¿®å¤ä¸­ï¼Œæ— éœ€ååŠ é€Ÿå³å¯æå¤§åœ°å‡å°‘æ‰©æ•£æ­¥éª¤ï¼Œå®ç°åœ¨ç»´æŒæ€§èƒ½çš„æƒ…å†µä¸‹æå¤§åŠ é€Ÿã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡ºäº†æ— éœ€åå¤„ç†åŠ é€Ÿçš„é«˜æ•ˆæ‰©æ•£æ¨¡å‹ï¼Œå¤§å¹…å‡å°‘æ‰€éœ€çš„æ‰©æ•£æ­¥éª¤ã€‚</li><li>é€šè¿‡å¹³ç§»æ®‹å·®å»ºç«‹é©¬å°”å¯å¤«é“¾ï¼Œæé«˜å›¾åƒè´¨é‡çš„è½¬æ¢æ•ˆç‡ã€‚</li><li>è®¾è®¡äº†ç²¾å¿ƒåˆ¶å®šçš„å™ªå£°æ—¶é—´è¡¨ï¼Œçµæ´»æ§åˆ¶æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¹³ç§»é€Ÿåº¦å’Œå™ªå£°å¼ºåº¦ã€‚</li><li>å³ä½¿ä»…ä½¿ç”¨ 4 ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²è„¸éƒ¨ä¿®å¤ç­‰ç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šå®ç°æˆ–ä¼˜äºå½“å‰æœ€å…ˆè¿›æ–¹æ³•ã€‚</li><li>æ€§èƒ½ä¸ SOTA æ–¹æ³•ç›¸å½“ï¼Œæå¤§åŠ é€Ÿäº†æ¨ç†é€Ÿåº¦ã€‚</li><li>ä»£ç å’Œæ¨¡å‹å·²å…¬å¼€å‘å¸ƒã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šåŸºäºæ®‹å·®å¹³ç§»çš„å›¾åƒä¿®å¤é«˜æ•ˆæ‰©æ•£æ¨¡å‹</li><li>ä½œè€…ï¼šå²³å®—ç”Ÿï¼Œç‹å»ºä¸€ï¼Œé™ˆæ˜ŒLoy</li><li>å•ä½ï¼šå—æ´‹ç†å·¥å¤§å­¦</li><li>å…³é”®è¯ï¼šMarkové“¾ï¼Œå™ªå£°è°ƒåº¦ï¼Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œå›¾åƒä¿®å¤ï¼Œäººè„¸ä¿®å¤</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.07319ï¼ŒGithubï¼šNone</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿®å¤ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å…¶æ¨ç†é€Ÿåº¦ä½ï¼Œéœ€è¦æ‰§è¡Œæ•°ç™¾ç”šè‡³æ•°åƒä¸ªé‡‡æ ·æ­¥éª¤ã€‚ç°æœ‰çš„åŠ é€Ÿé‡‡æ ·æŠ€æœ¯è™½ç„¶è¯•å›¾åŠ å¿«è¿™ä¸ªè¿‡ç¨‹ï¼Œä½†ä¸å¯é¿å…åœ°åœ¨ä¸€å®šç¨‹åº¦ä¸Šç‰ºç‰²æ€§èƒ½ï¼Œå¯¼è‡´æ¢å¤ç»“æœè¿‡åº¦æ¨¡ç³Šã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰çš„åŸºäºæ‰©æ•£çš„å›¾åƒä¿®å¤æ–¹æ³•å¯åˆ†ä¸ºä¸¤ç±»ï¼šä¸€ç§æ˜¯å°†ä½è´¨é‡å›¾åƒä½œä¸ºæ¡ä»¶æ’å…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼Œç„¶åé’ˆå¯¹å›¾åƒä¿®å¤ä»»åŠ¡é‡æ–°è®­ç»ƒæ¨¡å‹ï¼›å¦ä¸€ç§æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„æ— æ¡ä»¶æ‰©æ•£æ¨¡å‹ä½œä¸ºå…ˆéªŒæ¥ä¿ƒè¿›å›¾åƒä¿®å¤é—®é¢˜ã€‚è¿™ä¸¤ç§ç­–ç•¥éƒ½ç»§æ‰¿äº†DDPMä¸­éšå«çš„é©¬å°”å¯å¤«é“¾ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­æ•ˆç‡å¯èƒ½å¾ˆä½ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ã€é’ˆå¯¹å›¾åƒä¿®å¤é‡èº«å®šåˆ¶çš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨æ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´å–å¾—å’Œè°çš„å¹³è¡¡ï¼Œè€Œä¸ä¼šä¸ºäº†ä¸€ä¸ªè€Œç‰ºç‰²å¦ä¸€ä¸ªã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ¨¡å‹å»ºç«‹äº†ä¸€ä¸ªé©¬å°”å¯å¤«é“¾ï¼Œé€šè¿‡å¹³ç§»å›¾åƒçš„æ®‹å·®æ¥ä¿ƒè¿›é«˜è´¨é‡å’Œä½è´¨é‡å›¾åƒä¹‹é—´çš„è½¬æ¢ï¼Œä»è€Œå¤§å¤§æé«˜äº†è½¬æ¢æ•ˆç‡ã€‚è¿˜è®¾è®¡äº†ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„å™ªå£°è°ƒåº¦ï¼Œä»¥çµæ´»åœ°æ§åˆ¶æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¹³ç§»é€Ÿåº¦å’Œå™ªå£°å¼ºåº¦ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå¹¿æ³›çš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œå³ä½¿åªæœ‰å››ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²äººè„¸ä¿®å¤è¿™ä¸‰ä¸ªç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šä¹Ÿå–å¾—äº†ä¼˜äºæˆ–ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½å¯ä»¥æ”¯æŒå…¶ç›®æ ‡ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) æå‡ºäº†ä¸€ç§åŸºäºæ®‹å·®å¹³ç§»çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å¹³ç§»å›¾åƒçš„æ®‹å·®æ¥ä¿ƒè¿›é«˜è´¨é‡å’Œä½è´¨é‡å›¾åƒä¹‹é—´çš„è½¬æ¢ï¼Œå¤§å¤§æé«˜äº†è½¬æ¢æ•ˆç‡ï¼›(2) è®¾è®¡äº†ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„å™ªå£°è°ƒåº¦ï¼Œä»¥çµæ´»åœ°æ§åˆ¶æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¹³ç§»é€Ÿåº¦å’Œå™ªå£°å¼ºåº¦ï¼›(3) åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²äººè„¸ä¿®å¤ä¸‰ä¸ªç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šï¼Œå³ä½¿åªæœ‰å››ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œè¯¥æ–¹æ³•ä¹Ÿå–å¾—äº†ä¼˜äºæˆ–ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹å›¾åƒä¿®å¤é‡èº«å®šåˆ¶çš„ã€é«˜æ•ˆçš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨æ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´å–å¾—å’Œè°çš„å¹³è¡¡ï¼Œå³ä½¿åªæœ‰ 4 ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²äººè„¸ä¿®å¤è¿™ä¸‰ä¸ªç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šä¹Ÿå–å¾—äº†ä¼˜äºæˆ–ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†åŸºäºæ®‹å·®å¹³ç§»çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å¹³ç§»å›¾åƒçš„æ®‹å·®æ¥ä¿ƒè¿›é«˜è´¨é‡å’Œä½è´¨é‡å›¾åƒä¹‹é—´çš„è½¬æ¢ï¼Œå¤§å¤§æé«˜äº†è½¬æ¢æ•ˆç‡ï¼›è®¾è®¡äº†ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„å™ªå£°è°ƒåº¦ï¼Œä»¥çµæ´»åœ°æ§åˆ¶æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¹³ç§»é€Ÿåº¦å’Œå™ªå£°å¼ºåº¦ã€‚æ€§èƒ½ï¼šåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²äººè„¸ä¿®å¤ä¸‰ä¸ªç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šï¼Œå³ä½¿åªæœ‰ 4 ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œè¯¥æ–¹æ³•ä¹Ÿå–å¾—äº†ä¼˜äºæˆ–ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„æ¨ç†é€Ÿåº¦å¿«ï¼Œå³ä½¿åªæœ‰ 4 ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œä¹Ÿèƒ½å–å¾—è‰¯å¥½çš„æ€§èƒ½ï¼Œè¿™å¤§å¤§é™ä½äº†è®¡ç®—æˆæœ¬å’Œæ¨ç†æ—¶é—´ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-3e3d51fe0b9323fce3c712dc608e3d9f.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-a182da1e249c6b628670838e47b4a76e.jpg" align="middle"><img src="https://picx.zhimg.com/v2-ac3a6dd379a0eb12739ce5eb4300d834.jpg" align="middle"><img src="https://picx.zhimg.com/v2-79486bac2fc6b15b8e68f559254fb9fa.jpg" align="middle"><img src="https://pica.zhimg.com/v2-7dd29574d8058fee668b2d948a1e069e.jpg" align="middle"></details><h2 id="Text-to-Image-Diffusion-Models-are-Great-Sketch-Photo-Matchmakers"><a href="#Text-to-Image-Diffusion-Models-are-Great-Sketch-Photo-Matchmakers" class="headerlink" title="Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers"></a>Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers</h2><p><strong>Authors:Subhadeep Koley, Ayan Kumar Bhunia, Aneeshan Sain, Pinaki Nath Chowdhury, Tao Xiang, Yi-Zhe Song</strong></p><p>This paper, for the first time, explores text-to-image diffusion models for Zero-Shot Sketch-based Image Retrieval (ZS-SBIR). We highlight a pivotal discovery: the capacity of text-to-image diffusion models to seamlessly bridge the gap between sketches and photos. This proficiency is underpinned by their robust cross-modal capabilities and shape bias, findings that are substantiated through our pilot studies. In order to harness pre-trained diffusion models effectively, we introduce a straightforward yet powerful strategy focused on two key aspects: selecting optimal feature layers and utilising visual and textual prompts. For the former, we identify which layers are most enriched with information and are best suited for the specific retrieval requirements (category-level or fine-grained). Then we employ visual and textual prompts to guide the modelâ€™s feature extraction process, enabling it to generate more discriminative and contextually relevant cross-modal representations. Extensive experiments on several benchmark datasets validate significant performance improvements. </p><p><a href="http://arxiv.org/abs/2403.07214v1">PDF</a> Accepted in CVPR 2024. Project page available at   <a href="https://subhadeepkoley.github.io/DiffusionZSSBIR/">https://subhadeepkoley.github.io/DiffusionZSSBIR/</a></p><p><strong>Summary</strong><br>åŸºäºæ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹åœ¨é›¶æ ·æœ¬è‰å›¾å›¾åƒæ£€ç´¢ä¸­çš„æ¢ç´¢é¦–æ¬¡å–å¾—çªç ´ï¼Œç ”ç©¶å‘ç°æ‰©æ•£æ¨¡å‹å…·å¤‡è·¨æ¨¡æ€èƒ½åŠ›ï¼Œå¯æœ‰æ•ˆåœ°å¼¥åˆè‰å›¾ä¸ç…§ç‰‡ä¹‹é—´çš„å·®è·ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å¯ä»¥å¼¥åˆç†å¿µè‰å›¾å’Œç…§ç‰‡ä¹‹é—´çš„å·®è·ã€‚</li><li>ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¯ä»¥æé«˜é›¶æ ·æœ¬è‰å›¾å›¾åƒæ£€ç´¢çš„æ€§èƒ½ã€‚</li><li>é€‰æ‹©åˆé€‚çš„ç‰¹å¾å±‚å¯¹æ£€ç´¢æ•ˆæœè‡³å…³é‡è¦ã€‚</li><li>å¯è§†åŒ–å’Œæ–‡æœ¬æç¤ºå¯ä»¥æŒ‡å¯¼æ¨¡å‹ç‰¹å¾æå–è¿‡ç¨‹ï¼Œæé«˜è¡¨ç¤ºçš„åŒºåˆ†æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§ã€‚</li><li>åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li><li>è¯¥æ–¹æ³•å¯ä»¥ç”¨äºç±»åˆ«çº§å’Œç»†ç²’åº¦çš„æ£€ç´¢ä»»åŠ¡ã€‚</li><li>è¯¥ç ”ç©¶ä¸ºåˆ©ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œé›¶æ ·æœ¬è‰å›¾å›¾åƒæ£€ç´¢æä¾›äº†æ–°çš„æ€è·¯ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ˜¯ä¼˜ç§€çš„è‰å›¾ç…§ç‰‡åŒ¹é…å™¨</li><li>ä½œè€…ï¼šSubhadeep Koleyã€Ayan Kumar Bhuniaã€Aneeshan Sainã€Pinaki Nath Chowdhuryã€Tao Xiangã€Yi-Zhe Song</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè‹±å›½è¨é‡Œå¤§å­¦ SketchXã€CVSSP</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€æ‰©æ•£æ¨¡å‹ã€è‰å›¾åŒ¹é…</li><li>è®ºæ–‡é“¾æ¥ï¼šæ— ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒåŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•å› å…¶é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§è€Œå—åˆ°å…³æ³¨ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰çš„åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•é€šå¸¸éœ€è¦å¤šæ¬¡è¿­ä»£æ¨ç†ï¼Œè¿™ä¼šå¢åŠ æ—¶é—´å’Œè®¡ç®—å¤æ‚åº¦ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¸€æ¬¡æ€§æ¨ç†ä»æŸ¥è¯¢è‰å›¾ä¸­æå–ç‰¹å¾ï¼Œä»è€Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„æ•ˆç‡é—®é¢˜ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ Sketchyã€TU-Berlin å’Œ Quick, Draw! ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚</li></ol><p>7.æ–¹æ³•ï¼š(1)æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¸€æ¬¡æ€§æ¨ç†ä»æŸ¥è¯¢è‰å›¾ä¸­æå–ç‰¹å¾ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„æ•ˆç‡é—®é¢˜ï¼›(2)å°†Stable Diffusionæ¨¡å‹æ‰©å±•åˆ°é›¶æ ·æœ¬è‰å›¾+æ–‡æœ¬å›¾åƒæ£€ç´¢ï¼ˆZS-STBIRï¼‰ä»»åŠ¡ï¼Œé€šè¿‡ä½¿ç”¨å¯ç”¨çš„æ–‡æœ¬æ ‡é¢˜æˆ–ç±»åˆ«æ ‡ç­¾æ¥æé«˜æå–ç‰¹å¾çš„è´¨é‡ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šé¦–æ¬¡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æµæ°´çº¿ï¼Œä»¥å°†å†»ç»“çš„ Stable Diffusion é€‚åº”ä¸ºç±»åˆ«çº§å’Œè·¨ç±»åˆ«ç»†ç²’åº¦ ZS-SBIR ä»»åŠ¡çš„éª¨å¹²ç‰¹å¾æå–å™¨ã€‚é€šè¿‡å·§å¦™åœ°ä½¿ç”¨è§†è§‰å’Œæ–‡æœ¬æç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸è¿›ä¸€æ­¥å¾®è°ƒçš„æƒ…å†µä¸‹å°†é¢„è®­ç»ƒæ¨¡å‹é€‚åº”åˆ°æ‰‹å¤´çš„ä»»åŠ¡ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„ ZSSBIR æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å½»åº•çš„åˆ†æå®éªŒï¼Œä»¥å»ºç«‹åˆ©ç”¨å†»ç»“çš„ stable diffusion æ¨¡å‹ä½œä¸º ZS-SBIR éª¨å¹²çš„æœ€ä½³å®è·µã€‚æœ€åï¼Œåˆ©ç”¨ stable diffusion å›ºæœ‰çš„è§†è§‰è¯­è¨€èƒ½åŠ›ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„ç®¡é“æ‰©å±•åˆ°åŸºäºè‰å›¾ + æ–‡æœ¬çš„ SBIRï¼Œä»è€Œå®ç°åŸºäºè‰å›¾ + æ–‡æœ¬çš„ç±»åˆ«ã€ç»†ç²’åº¦å’Œåœºæ™¯çº§åœºæ™¯ä¸­çš„å®é™…æ£€ç´¢ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§é€šè¿‡ä¸€æ¬¡æ€§æ¨ç†ä»æŸ¥è¯¢è‰å›¾ä¸­æå–ç‰¹å¾çš„åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•ï¼›å°† Stable Diffusion æ¨¡å‹æ‰©å±•åˆ°é›¶æ ·æœ¬è‰å›¾ + æ–‡æœ¬å›¾åƒæ£€ç´¢ï¼ˆZS-STBIRï¼‰ä»»åŠ¡ã€‚æ€§èƒ½ï¼šåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚å·¥ä½œé‡ï¼šè§£å†³äº†ç°æœ‰åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•çš„æ•ˆç‡é—®é¢˜ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-d241840af721fa3e3d26127475eab81e.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-8bd3dc3a12b0ad0e0283f2af9ff1b2dd.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-0752cb46230001078d91a5e105eacf22.jpg" align="middle"></details><h2 id="Bayesian-Diffusion-Models-for-3D-Shape-Reconstruction"><a href="#Bayesian-Diffusion-Models-for-3D-Shape-Reconstruction" class="headerlink" title="Bayesian Diffusion Models for 3D Shape Reconstruction"></a>Bayesian Diffusion Models for 3D Shape Reconstruction</h2><p><strong>Authors:Haiyang Xu, Yu Lei, Zeyuan Chen, Xiang Zhang, Yue Zhao, Yilin Wang, Zhuowen Tu</strong></p><p>We present Bayesian Diffusion Models (BDM), a prediction algorithm that performs effective Bayesian inference by tightly coupling the top-down (prior) information with the bottom-up (data-driven) procedure via joint diffusion processes. We show the effectiveness of BDM on the 3D shape reconstruction task. Compared to prototypical deep learning data-driven approaches trained on paired (supervised) data-labels (e.g. image-point clouds) datasets, our BDM brings in rich prior information from standalone labels (e.g. point clouds) to improve the bottom-up 3D reconstruction. As opposed to the standard Bayesian frameworks where explicit prior and likelihood are required for the inference, BDM performs seamless information fusion via coupled diffusion processes with learned gradient computation networks. The specialty of our BDM lies in its capability to engage the active and effective information exchange and fusion of the top-down and bottom-up processes where each itself is a diffusion process. We demonstrate state-of-the-art results on both synthetic and real-world benchmarks for 3D shape reconstruction. </p><p><a href="http://arxiv.org/abs/2403.06973v1">PDF</a> Accepted by CVPR 2024</p><p><strong>Summary</strong><br>è´å¶æ–¯æ‰©æ•£æ¨¡å‹ï¼ˆBDMï¼‰é€šè¿‡è”åˆæ‰©æ•£è¿‡ç¨‹å°†è‡ªé¡¶å‘ä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªåº•å‘ä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œè¿›è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>BDM åœ¨ 3D å½¢çŠ¶é‡å»ºä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚</li><li>BDM ä½¿ç”¨æ¥è‡ªç‹¬ç«‹æ ‡ç­¾ï¼ˆä¾‹å¦‚ç‚¹äº‘ï¼‰çš„ä¸°å¯Œå…ˆéªŒä¿¡æ¯æ¥æ”¹å–„è‡ªåº•å‘ä¸Šçš„ 3D é‡å»ºï¼Œè€Œæ— éœ€é…å¯¹ï¼ˆç›‘ç£ï¼‰æ•°æ®æ ‡ç­¾ï¼ˆä¾‹å¦‚å›¾åƒç‚¹äº‘ï¼‰æ•°æ®é›†ã€‚</li><li>BDM é€šè¿‡è€¦åˆæ‰©æ•£è¿‡ç¨‹å’Œå­¦ä¹ çš„æ¢¯åº¦è®¡ç®—ç½‘ç»œæ‰§è¡Œæ— ç¼ä¿¡æ¯èåˆï¼Œæ— éœ€æ ‡å‡†è´å¶æ–¯æ¡†æ¶ä¸­æ¨ç†æ‰€éœ€çš„æ˜¾å¼å…ˆéªŒå’Œä¼¼ç„¶ã€‚</li><li>BDM çš„ç‰¹æ®Šä¹‹å¤„åœ¨äºèƒ½å¤Ÿè¿›è¡Œè‡ªé¡¶å‘ä¸‹å’Œè‡ªåº•å‘ä¸Šè¿‡ç¨‹çš„ä¸»åŠ¨å’Œæœ‰æ•ˆçš„ä¿¡æ¯äº¤æ¢å’Œèåˆï¼Œæ¯ä¸ªè¿‡ç¨‹æœ¬èº«éƒ½æ˜¯ä¸€ä¸ªæ‰©æ•£è¿‡ç¨‹ã€‚</li><li>åœ¨ 3D å½¢çŠ¶é‡å»ºçš„åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„ç»“æœã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šè´å¶æ–¯æ‰©æ•£æ¨¡å‹ç”¨äº 3D å½¢çŠ¶é‡å»º</li><li>ä½œè€…ï¼šJianfei Guo, Tianchang Shen, Zekun Hao, Song Bai, Xiang Bai</li><li>éš¶å±æœºæ„ï¼šæµ™æ±Ÿå¤§å­¦</li><li>å…³é”®è¯ï¼šBayesian Diffusion Models, 3D Shape Reconstruction, Generative Diffusion Model</li><li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼š3D å½¢çŠ¶é‡å»ºæ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ï¼Œå®ƒæ—¨åœ¨ä» 2D å›¾åƒæˆ–ç‚¹äº‘ä¸­æ¢å¤ 3D å½¢çŠ¶ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸é‡‡ç”¨æ•°æ®é©±åŠ¨çš„è‡ªä¸Šè€Œä¸‹çš„æ–¹æ³•ï¼Œéœ€è¦é…å¯¹çš„ï¼ˆç›‘ç£ï¼‰æ•°æ®-æ ‡ç­¾ï¼ˆä¾‹å¦‚å›¾åƒ-ç‚¹äº‘ï¼‰æ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å—åˆ°è®­ç»ƒæ•°æ®è§„æ¨¡å’Œè´¨é‡çš„é™åˆ¶ã€‚(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„æ–¹æ³•é€šå¸¸é‡‡ç”¨æ•°æ®é©±åŠ¨çš„è‡ªä¸Šè€Œä¸‹çš„æ–¹æ³•ï¼Œéœ€è¦é…å¯¹çš„ï¼ˆç›‘ç£ï¼‰æ•°æ®-æ ‡ç­¾ï¼ˆä¾‹å¦‚å›¾åƒ-ç‚¹äº‘ï¼‰æ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å—åˆ°è®­ç»ƒæ•°æ®è§„æ¨¡å’Œè´¨é‡çš„é™åˆ¶ã€‚(3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç§°ä¸ºè´å¶æ–¯æ‰©æ•£æ¨¡å‹ (BDM) çš„æ–°æ–¹æ³•ï¼Œå®ƒé€šè¿‡è”åˆæ‰©æ•£è¿‡ç¨‹å°†è‡ªä¸Šè€Œä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªä¸‹è€Œä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œæ‰§è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ã€‚BDM å…·æœ‰å°†å…ˆéªŒä¿¡æ¯ä»ç‹¬ç«‹æ ‡ç­¾ï¼ˆä¾‹å¦‚ç‚¹äº‘ï¼‰æ— ç¼èåˆåˆ° 3D é‡å»ºä¸­çš„èƒ½åŠ›ï¼Œè€Œæ— éœ€æ˜¾å¼åœ°æŒ‡å®šå…ˆéªŒå’Œä¼¼ç„¶ã€‚(4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼šæœ¬æ–‡åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†ä¸Šå¯¹ BDM è¿›è¡Œäº†è¯„ä¼°ï¼Œç”¨äº 3D å½¢çŠ¶é‡å»ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒBDM åœ¨å„ç§æŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æ˜¾ç€æ”¹è¿›ï¼Œè¯æ˜äº†å…¶åœ¨ 3D å½¢çŠ¶é‡å»ºä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p></li><li><p>Methodsï¼šï¼ˆ1ï¼‰æå‡ºè´å¶æ–¯æ‰©æ•£æ¨¡å‹ï¼ˆBDMï¼‰æ¡†æ¶ï¼Œå°†è‡ªä¸Šè€Œä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªä¸‹è€Œä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œæ‰§è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ã€‚ï¼ˆ2ï¼‰è®¾è®¡ä¸€ä¸ªè”åˆæ‰©æ•£è¿‡ç¨‹ï¼Œé€æ­¥å°†å…ˆéªŒä¿¡æ¯èåˆåˆ°3Då½¢çŠ¶é‡å»ºä¸­ï¼Œæ— éœ€æ˜¾å¼æŒ‡å®šå…ˆéªŒå’Œä¼¼ç„¶ã€‚ï¼ˆ3ï¼‰é‡‡ç”¨å˜åˆ†æ¨æ–­æ–¹æ³•ï¼Œè¿‘ä¼¼åéªŒåˆ†å¸ƒï¼Œå¹¶é€šè¿‡é€†æ‰©æ•£è¿‡ç¨‹ç”Ÿæˆ3Då½¢çŠ¶ã€‚</p></li><li><p>ç»“è®ºï¼š(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè´å¶æ–¯æ‰©æ•£æ¨¡å‹ï¼ˆBDMï¼‰çš„3Då½¢çŠ¶é‡å»ºæ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡è”åˆæ‰©æ•£è¿‡ç¨‹å°†è‡ªä¸Šè€Œä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªä¸‹è€Œä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œæ‰§è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ï¼Œåœ¨3Då½¢çŠ¶é‡å»ºä»»åŠ¡ä¸­å–å¾—äº†æ˜¾ç€æ”¹è¿›ã€‚(2): åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºè´å¶æ–¯æ‰©æ•£æ¨¡å‹ï¼ˆBDMï¼‰æ¡†æ¶ï¼Œå°†è‡ªä¸Šè€Œä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªä¸‹è€Œä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œæ‰§è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ã€‚</li><li>è®¾è®¡ä¸€ä¸ªè”åˆæ‰©æ•£è¿‡ç¨‹ï¼Œé€æ­¥å°†å…ˆéªŒä¿¡æ¯èåˆåˆ°3Då½¢çŠ¶é‡å»ºä¸­ï¼Œæ— éœ€æ˜¾å¼æŒ‡å®šå…ˆéªŒå’Œä¼¼ç„¶ã€‚</li><li>é‡‡ç”¨å˜åˆ†æ¨æ–­æ–¹æ³•ï¼Œè¿‘ä¼¼åéªŒåˆ†å¸ƒï¼Œå¹¶é€šè¿‡é€†æ‰©æ•£è¿‡ç¨‹ç”Ÿæˆ3Då½¢çŠ¶ã€‚Performanceï¼š</li><li>åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†ä¸Šå¯¹BDMè¿›è¡Œäº†è¯„ä¼°ï¼Œç”¨äº3Då½¢çŠ¶é‡å»ºã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒBDMåœ¨å„ç§æŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æ˜¾ç€æ”¹è¿›ï¼Œè¯æ˜äº†å…¶åœ¨3Då½¢çŠ¶é‡å»ºä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚Workloadï¼š</li><li>æœ¬æ–‡çš„å·¥ä½œé‡ä¸­ç­‰ï¼Œéœ€è¦å¯¹è´å¶æ–¯æ‰©æ•£æ¨¡å‹ã€3Då½¢çŠ¶é‡å»ºå’Œå˜åˆ†æ¨æ–­æ–¹æ³•æœ‰ä¸€å®šçš„äº†è§£ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-7422b82570cb43b0e03df4c70a22bd9a.jpg" align="middle"><img src="https://picx.zhimg.com/v2-024cf388128af8fcbb5768c6b5cbd193.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-75567a8fc44c36c6e2757bf6b21b6dcf.jpg" align="middle"><img src="https://picx.zhimg.com/v2-837f8b78a5d65ec0d93f1545faef964c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-43923b8a4efdf4a63b3fd3998d1b5749.jpg" align="middle"></details><h2 id="SELMA-Learning-and-Merging-Skill-Specific-Text-to-Image-Experts-with-Auto-Generated-Data"><a href="#SELMA-Learning-and-Merging-Skill-Specific-Text-to-Image-Experts-with-Auto-Generated-Data" class="headerlink" title="SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with   Auto-Generated Data"></a>SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with   Auto-Generated Data</h2><p><strong>Authors:Jialu Li, Jaemin Cho, Yi-Lin Sung, Jaehong Yoon, Mohit Bansal</strong></p><p>Recent text-to-image (T2I) generation models have demonstrated impressive capabilities in creating images from text descriptions. However, these T2I generation models often fall short of generating images that precisely match the details of the text inputs, such as incorrect spatial relationship or missing objects. In this paper, we introduce SELMA: Skill-Specific Expert Learning and Merging with Auto-Generated Data, a novel paradigm to improve the faithfulness of T2I models by fine-tuning models on automatically generated, multi-skill image-text datasets, with skill-specific expert learning and merging. First, SELMA leverages an LLMâ€™s in-context learning capability to generate multiple datasets of text prompts that can teach different skills, and then generates the images with a T2I model based on the prompts. Next, SELMA adapts the T2I model to the new skills by learning multiple single-skill LoRA (low-rank adaptation) experts followed by expert merging. Our independent expert fine-tuning specializes multiple models for different skills, and expert merging helps build a joint multi-skill T2I model that can generate faithful images given diverse text prompts, while mitigating the knowledge conflict from different datasets. We empirically demonstrate that SELMA significantly improves the semantic alignment and text faithfulness of state-of-the-art T2I diffusion models on multiple benchmarks (+2.1% on TIFA and +6.9% on DSG), human preference metrics (PickScore, ImageReward, and HPS), as well as human evaluation. Moreover, fine-tuning with image-text pairs auto-collected via SELMA shows comparable performance to fine-tuning with ground truth data. Lastly, we show that fine-tuning with images from a weaker T2I model can help improve the generation quality of a stronger T2I model, suggesting promising weak-to-strong generalization in T2I models. </p><p><a href="http://arxiv.org/abs/2403.06952v1">PDF</a> First two authors contributed equally; Project website:   <a href="https://selma-t2i.github.io/">https://selma-t2i.github.io/</a></p><p><strong>Summary</strong><br>å¤šæŠ€èƒ½ä¸“å®¶å­¦ä¹ ä¸è‡ªåŠ¨ç”Ÿæˆæ•°æ®ï¼Œèåˆæå‡T2Iæ¨¡å‹é€¼çœŸåº¦ï¼Œæ˜¾è‘—æ”¹å–„è¯­ä¹‰å¯¹é½å’Œæ–‡æœ¬å¿ å®åº¦ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>SELMAèåˆå¤šæŠ€èƒ½ä¸“å®¶å­¦ä¹ ä¸è‡ªåŠ¨ç”Ÿæˆæ•°æ®æå‡T2Iæ¨¡å‹é€¼çœŸåº¦ã€‚</li><li>LLMç”Ÿæˆå¤šæ ·æ–‡æœ¬æç¤ºï¼Œå¯¹åº”ä¸åŒæŠ€èƒ½ï¼Œè®­ç»ƒT2Iæ¨¡å‹è·å–æ–°æŠ€èƒ½ã€‚</li><li>ç‹¬ç«‹ä¸“å®¶å¾®è°ƒé’ˆå¯¹ä¸åŒæŠ€èƒ½ï¼Œä¸“å®¶èåˆæ‰“é€ å¤šæŠ€èƒ½T2Iæ¨¡å‹å¤„ç†å¤šæ ·æ–‡æœ¬æç¤ºã€‚</li><li>SELMAæ˜¾è‘—æå‡SOTA T2Iæ¨¡å‹è¯­ä¹‰å¯¹é½å’Œæ–‡æœ¬å¿ å®åº¦ï¼ˆTIFA+2.1%ï¼ŒDSG+6.9%ï¼‰ã€‚</li><li>è‡ªåŠ¨æ”¶é›†çš„å›¾åƒæ–‡æœ¬ç”¨äºå¾®è°ƒæ€§èƒ½æ¥è¿‘çœŸå®æ•°æ®å¾®è°ƒã€‚</li><li>è¾ƒå¼±T2Iæ¨¡å‹å›¾åƒç”¨äºå¾®è°ƒå¯ä»¥æå‡è¾ƒå¼ºT2Iæ¨¡å‹ç”Ÿæˆè´¨é‡ï¼Œå±•ç°T2Iæ¨¡å‹çš„å¼±åˆ°å¼ºæ³›åŒ–æ€§ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šSELMAï¼šé€šè¿‡è‡ªåŠ¨ç”Ÿæˆçš„æ•°æ®å­¦ä¹ å’Œåˆå¹¶ç‰¹å®šæŠ€èƒ½çš„æ–‡æœ¬åˆ°å›¾åƒä¸“å®¶</li><li>ä½œè€…ï¼šJialu Liã€Jaemin Choã€Yi-Lin Sungã€Jaehong Yoonã€Mohit Bansal</li><li>æ‰€å±æœºæ„ï¼šåŒ—å¡ç½—æ¥çº³å¤§å­¦æ•™å ‚å±±åˆ†æ ¡</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒç”Ÿæˆã€ä¸“å®¶å­¦ä¹ ã€çŸ¥è¯†èåˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.06952 Githubï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰ç”Ÿæˆæ¨¡å‹åœ¨åˆ›å»ºå›¾åƒæ–¹é¢å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„è¿›å±•ï¼Œä½†å®ƒä»¬ä»ç„¶éš¾ä»¥ç”Ÿæˆä¸æ–‡æœ¬è¾“å…¥ç»†èŠ‚å®Œå…¨åŒ¹é…çš„å›¾åƒï¼Œä¾‹å¦‚ä¸æ­£ç¡®çš„ç©ºé—´å…³ç³»æˆ–ç¼ºå¤±å¯¹è±¡ã€‚ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šä»¥å¾€æ–¹æ³•ä¾§é‡äºç›‘ç£å­¦ä¹ æˆ–æ— ç›‘ç£å­¦ä¹ ï¼Œä½†å®ƒä»¬åœ¨æ•æ‰æ–‡æœ¬æç¤ºä¸­çš„æ‰€æœ‰è¯­ä¹‰æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šSELMA æå‡ºäº†ä¸€ç§æ–°èŒƒå¼ï¼Œé€šè¿‡åœ¨è‡ªåŠ¨ç”Ÿæˆçš„å¤šæŠ€èƒ½å›¾åƒ-æ–‡æœ¬æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶ç»“åˆç‰¹å®šæŠ€èƒ½çš„ä¸“å®¶å­¦ä¹ å’Œåˆå¹¶ï¼Œæ¥æé«˜ T2I æ¨¡å‹çš„ä¿çœŸåº¦ã€‚ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šSELMA åœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾ç€æé«˜äº†æœ€å…ˆè¿›çš„ T2I æ‰©æ•£æ¨¡å‹çš„è¯­ä¹‰å¯¹é½å’Œæ–‡æœ¬ä¿çœŸåº¦ï¼ˆåœ¨ TIFA ä¸Šæé«˜äº† 2.1%ï¼Œåœ¨ DSG ä¸Šæé«˜äº† 6.9%ï¼‰ï¼Œäººç±»åå¥½æŒ‡æ ‡ï¼ˆPickScoreã€ImageReward å’Œ HPSï¼‰ï¼Œä»¥åŠäººç±»è¯„ä¼°ã€‚</li></ol><p><strong>æ–¹æ³•ï¼š</strong></p><p>(1) <strong>è‡ªåŠ¨ç”Ÿæˆå¤šæŠ€èƒ½å›¾åƒ-æ–‡æœ¬æ•°æ®é›†ï¼š</strong>ä½¿ç”¨é¢„è®­ç»ƒçš„T2Iæ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œå¹¶ä½¿ç”¨æ–‡æœ¬æç¤ºå¯¹å…¶è¿›è¡Œæ³¨é‡Šï¼Œåˆ›å»ºåŒ…å«å„ç§æŠ€èƒ½ï¼ˆä¾‹å¦‚å¯¹è±¡ç”Ÿæˆã€å±æ€§ç¼–è¾‘ã€åœºæ™¯åˆæˆï¼‰çš„æ•°æ®é›†ã€‚</p><p>(2) <strong>ç‰¹å®šæŠ€èƒ½çš„ä¸“å®¶å­¦ä¹ ï¼š</strong>åœ¨è‡ªåŠ¨ç”Ÿæˆçš„æ•°æ®é›†ä¸Šå¾®è°ƒT2Iæ¨¡å‹ï¼Œä¸“æ³¨äºç‰¹å®šæŠ€èƒ½çš„å­¦ä¹ ã€‚è¿™æœ‰åŠ©äºæ¨¡å‹æŒæ¡ç‰¹å®šæŠ€èƒ½æ‰€éœ€çš„çŸ¥è¯†ã€‚</p><p>(3) <strong>ä¸“å®¶åˆå¹¶ï¼š</strong>å°†è®­ç»ƒè¿‡çš„ç‰¹å®šæŠ€èƒ½ä¸“å®¶æ¨¡å‹åˆå¹¶åˆ°ä¸»T2Iæ¨¡å‹ä¸­ã€‚é€šè¿‡èåˆä¸“å®¶çŸ¥è¯†ï¼Œä¸»æ¨¡å‹å¯ä»¥åŒæ—¶åˆ©ç”¨ä¸åŒæŠ€èƒ½ï¼Œä»è€Œæé«˜å›¾åƒç”Ÿæˆçš„ä¿çœŸåº¦ã€‚</p><p>(4) <strong>å¾®è°ƒï¼š</strong>åœ¨æœ€ç»ˆçš„å¤šæŠ€èƒ½å›¾åƒ-æ–‡æœ¬æ•°æ®é›†ä¸Šå¾®è°ƒåˆå¹¶åçš„T2Iæ¨¡å‹ï¼Œä»¥è¿›ä¸€æ­¥æé«˜å…¶æ€§èƒ½ã€‚</p><ol><li>ç»“è®ºï¼š(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°èŒƒå¼ SELMAï¼Œé€šè¿‡åˆ©ç”¨ T2I æ¨¡å‹çš„é¢„è®­ç»ƒçŸ¥è¯†ï¼Œæé«˜äº†æœ€å…ˆè¿›çš„ T2I æ¨¡å‹åœ¨ç”Ÿæˆå’Œäººç±»åå¥½æ–¹é¢çš„ä¿çœŸåº¦ã€‚SELMA é¦–å…ˆæ”¶é›†äº†åœ¨ä¸éœ€è¦é¢å¤–äººå·¥æ³¨é‡Šçš„æƒ…å†µä¸‹ç»™å®šå„ç§ç”Ÿæˆçš„æ–‡æœ¬æç¤ºçš„è‡ªæˆ‘ç”Ÿæˆå›¾åƒã€‚ç„¶åï¼ŒSELMA åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šå¯¹å•ç‹¬çš„ LoRA æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶åœ¨æ¨ç†æœŸé—´åˆå¹¶å®ƒä»¬ï¼Œä»¥å‡è½»æ•°æ®é›†ä¹‹é—´çš„çŸ¥è¯†å†²çªã€‚SELMA åœ¨æé«˜ T2I æ¨¡å‹çš„ä¿çœŸåº¦å’Œä¸äººç±»åå¥½çš„å¯¹é½åº¦æ–¹é¢å±•ç¤ºäº†å¼ºå¤§çš„ç»éªŒç»“æœï¼Œå¹¶è¡¨æ˜åŸºäºæ‰©æ•£çš„ T2I æ¨¡å‹å…·æœ‰æ½œåœ¨çš„å¼±åˆ°å¼ºæ³›åŒ–èƒ½åŠ›ã€‚(2): åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§é€šè¿‡è‡ªåŠ¨ç”Ÿæˆå¤šæŠ€èƒ½å›¾åƒ-æ–‡æœ¬æ•°æ®é›†ã€ç‰¹å®šæŠ€èƒ½ä¸“å®¶å­¦ä¹ å’Œä¸“å®¶åˆå¹¶æ¥æé«˜ T2I æ¨¡å‹ä¿çœŸåº¦çš„æ–°èŒƒå¼ã€‚æ€§èƒ½ï¼šåœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾ç€æé«˜äº†æœ€å…ˆè¿›çš„ T2I æ‰©æ•£æ¨¡å‹çš„è¯­ä¹‰å¯¹é½å’Œæ–‡æœ¬ä¿çœŸåº¦ï¼Œäººç±»åå¥½æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ã€‚å·¥ä½œé‡ï¼šéœ€è¦ç”Ÿæˆå’Œæ³¨é‡Šå¤§é‡å›¾åƒ-æ–‡æœ¬æ•°æ®ï¼Œå¹¶è®­ç»ƒå’Œåˆå¹¶å¤šä¸ªä¸“å®¶æ¨¡å‹ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-a71fb7431e2ed3366a76c62d6434a3a5.jpg" align="middle"><img src="https://picx.zhimg.com/v2-26fd4cb2b211747179211fa7dd2b38a4.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-951031dbd570a29204c573bd83992954.jpg" align="middle"></details><h2 id="Distribution-Aware-Data-Expansion-with-Diffusion-Models"><a href="#Distribution-Aware-Data-Expansion-with-Diffusion-Models" class="headerlink" title="Distribution-Aware Data Expansion with Diffusion Models"></a>Distribution-Aware Data Expansion with Diffusion Models</h2><p><strong>Authors:Haowei Zhu, Ling Yang, Jun-Hai Yong, Wentao Zhang, Bin Wang</strong></p><p>The scale and quality of a dataset significantly impact the performance of deep models. However, acquiring large-scale annotated datasets is both a costly and time-consuming endeavor. To address this challenge, dataset expansion technologies aim to automatically augment datasets, unlocking the full potential of deep models. Current data expansion methods encompass image transformation-based and synthesis-based methods. The transformation-based methods introduce only local variations, resulting in poor diversity. While image synthesis-based methods can create entirely new content, significantly enhancing informativeness. However, existing synthesis methods carry the risk of distribution deviations, potentially degrading model performance with out-of-distribution samples. In this paper, we propose DistDiff, an effective data expansion framework based on the distribution-aware diffusion model. DistDiff constructs hierarchical prototypes to approximate the real data distribution, optimizing latent data points within diffusion models with hierarchical energy guidance. We demonstrate its ability to generate distribution-consistent samples, achieving substantial improvements in data expansion tasks. Specifically, without additional training, DistDiff achieves a 30.7% improvement in accuracy across six image datasets compared to the model trained on original datasets and a 9.8% improvement compared to the state-of-the-art diffusion-based method. Our code is available at <a href="https://github.com/haoweiz23/DistDiff">https://github.com/haoweiz23/DistDiff</a> </p><p><a href="http://arxiv.org/abs/2403.06741v1">PDF</a> Project: <a href="https://github.com/haoweiz23/DistDiff">https://github.com/haoweiz23/DistDiff</a></p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹é¢†åŸŸçš„æœ€æ–°ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º DistDiff çš„é«˜æ•ˆæ•°æ®æ‰©å±•æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨äº†åˆ†å¸ƒæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒç”Ÿæˆä»»åŠ¡çš„åˆ†å¸ƒä¸€è‡´æ€§ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ•°æ®é›†çš„è§„æ¨¡å’Œè´¨é‡å¯¹æ·±åº¦æ¨¡å‹çš„æ€§èƒ½è‡³å…³é‡è¦ã€‚</li><li>æ•°æ®é›†æ‰©å……æŠ€æœ¯å¯ä»¥è‡ªåŠ¨æ‰©å……æ•°æ®é›†ï¼Œé‡Šæ”¾æ·±åº¦æ¨¡å‹çš„æ½œåŠ›ã€‚</li><li>åŸºäºå›¾åƒå˜æ¢çš„æ•°æ®æ‰©å……æ–¹æ³•åªèƒ½å¼•å…¥å±€éƒ¨å˜åŒ–ï¼Œå¤šæ ·æ€§è¾ƒå·®ã€‚</li><li>åŸºäºå›¾åƒåˆæˆçš„æ‰©å……æ–¹æ³•å¯ä»¥åˆ›é€ å…¨æ–°å†…å®¹ï¼Œæ˜¾è‘—æé«˜ä¿¡æ¯æ€§ã€‚</li><li>ç°æœ‰çš„åˆæˆæ–¹æ³•å­˜åœ¨åˆ†å¸ƒåå·®çš„é£é™©ï¼Œå¯èƒ½ä¼šé™ä½æ¨¡å‹å¯¹åˆ†å¸ƒå¤–æ ·æœ¬çš„æ€§èƒ½ã€‚</li><li>DistDiff åŸºäºåˆ†å¸ƒæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡æ„é€ åˆ†å±‚åŸå‹å’Œåˆ†å±‚èƒ½é‡æŒ‡å¯¼æ¥è¿‘ä¼¼çœŸå®æ•°æ®åˆ†å¸ƒã€‚</li><li>DistDiff åœ¨æ•°æ®æ‰©å±•ä»»åŠ¡ä¸­å®ç°äº†åˆ†å¸ƒä¸€è‡´æ ·æœ¬çš„ç”Ÿæˆï¼Œå–å¾—äº†æ˜¾è‘—æå‡ã€‚</li><li>ä¸åœ¨åŸå§‹æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼ŒDistDiff åœ¨å…­ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡æå‡äº† 30.7%ï¼Œä¸æœ€å…ˆè¿›çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•ç›¸æ¯”ï¼Œæå‡äº† 9.8%ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„åˆ†å¸ƒæ„ŸçŸ¥æ•°æ®æ‰©å……</li><li>ä½œè€…ï¼šæœ±æµ©ä¼Ÿã€æ¨å‡Œã€é›å†›æµ·ã€å¼ æ–‡æ¶›ã€ç‹æ–Œ</li><li>éš¶å±å•ä½ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼šæ•°æ®æ‰©å……ã€æ‰©æ•£æ¨¡å‹ã€åˆ†å¸ƒæ„ŸçŸ¥</li><li>é“¾æ¥ï¼šhttps://github.com/haoweiz23/DistDiff</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†å¯¹äºæ·±åº¦æ¨¡å‹è‡³å…³é‡è¦ï¼Œä½†è·å–æ­¤ç±»æ•°æ®é›†æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶ã€‚æ•°æ®æ‰©å……æŠ€æœ¯æ—¨åœ¨è‡ªåŠ¨æ‰©å……æ•°æ®é›†ï¼Œé‡Šæ”¾æ·±åº¦æ¨¡å‹çš„å…¨éƒ¨æ½œåŠ›ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ•°æ®æ‰©å……æ–¹æ³•åŒ…æ‹¬åŸºäºå›¾åƒå˜æ¢å’ŒåŸºäºåˆæˆçš„ä¸¤ç§ç±»å‹ã€‚åŸºäºå›¾åƒå˜æ¢çš„æ–¹æ³•åªèƒ½å¼•å…¥å±€éƒ¨å˜åŒ–ï¼Œå¤šæ ·æ€§è¾ƒå·®ã€‚åŸºäºåˆæˆçš„å›¾åƒç”Ÿæˆæ–¹æ³•è™½ç„¶å¯ä»¥åˆ›å»ºå…¨æ–°çš„å†…å®¹ï¼Œä½†å­˜åœ¨åˆ†å¸ƒåå·®çš„é£é™©ï¼Œå¯èƒ½ä¼šé™ä½æ¨¡å‹çš„æ€§èƒ½ã€‚ï¼ˆ3ï¼‰æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåˆ†å¸ƒæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹çš„æœ‰æ•ˆæ•°æ®æ‰©å……æ¡†æ¶ DistDiffã€‚DistDiff æ„å»ºåˆ†å±‚åŸå‹ä»¥é€¼è¿‘çœŸå®æ•°æ®åˆ†å¸ƒï¼Œåœ¨å…·æœ‰åˆ†å±‚èƒ½é‡å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ä¸­ä¼˜åŒ–æ½œåœ¨æ•°æ®ç‚¹ã€‚ï¼ˆ4ï¼‰æ€§èƒ½ï¼šDistDiff åœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œåœ¨å…­ä¸ªå›¾åƒæ•°æ®é›†ä¸Šå®ç°äº†æ¯”åœ¨åŸå§‹æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹å‡†ç¡®ç‡æé«˜ 30.7%ï¼Œæ¯”æœ€å…ˆè¿›çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æé«˜ 9.8%ã€‚è¿™äº›æ€§èƒ½æå‡è¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p></li><li><p>Methods:(1): å°†åŸå§‹æ•°æ®åˆ†å¸ƒè¿‘ä¼¼ä¸ºåˆ†å±‚åŸå‹ï¼ŒæŒ‡å¯¼æ‰©æ•£æ¨¡å‹çš„é‡‡æ ·è¿‡ç¨‹ï¼›(2): å¼•å…¥æ®‹å·®ä¹˜æ³•å˜æ¢ï¼Œåœ¨å¯æ§èŒƒå›´å†…è°ƒæ•´æ½œåœ¨ç‰¹å¾ï¼›(3): åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­åŠ å…¥èƒ½é‡å¼•å¯¼ï¼Œä¼˜åŒ–å˜æ¢å‚æ•°ï¼Œä½¿ç”Ÿæˆçš„æ ·æœ¬ä¸çœŸå®æ•°æ®åˆ†å¸ƒä¸€è‡´ï¼›(4): åˆ©ç”¨é¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨å’Œå»å™ªç½‘ç»œï¼Œæ„å»ºèƒ½é‡å‡½æ•°ï¼ŒæŒ‡å¯¼é‡‡æ ·è¿‡ç¨‹ï¼›(5): ä¼˜åŒ–ä¸­é—´é‡‡æ ·æ­¥éª¤ï¼Œè€Œä¸æ˜¯ä»…ä¼˜åŒ–æœ€ç»ˆé‡‡æ ·ç»“æœã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬è®ºæ–‡æå‡ºçš„ DistDiff æ–¹æ³•åœ¨æ•°æ®æ‰©å……é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä¸ºåŸºäºæ‰©æ•£æ¨¡å‹çš„æ•°æ®æ‰©å……æä¾›äº†æ–°çš„æ€è·¯ã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§åŸºäºåˆ†å±‚åŸå‹çš„åˆ†å¸ƒæ„ŸçŸ¥æ•°æ®æ‰©å……æ¡†æ¶ï¼Œæœ‰æ•ˆé€¼è¿‘çœŸå®æ•°æ®åˆ†å¸ƒã€‚</li><li>å¼•å…¥äº†æ®‹å·®ä¹˜æ³•å˜æ¢å’Œèƒ½é‡å¼•å¯¼æœºåˆ¶ï¼Œåœ¨å¯æ§èŒƒå›´å†…ä¼˜åŒ–æ½œåœ¨ç‰¹å¾ï¼Œæé«˜ç”Ÿæˆæ ·æœ¬çš„è´¨é‡ã€‚</li><li>åˆ©ç”¨é¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨å’Œå»å™ªç½‘ç»œæ„å»ºèƒ½é‡å‡½æ•°ï¼ŒæŒ‡å¯¼é‡‡æ ·è¿‡ç¨‹ï¼Œæå‡ç”Ÿæˆæ ·æœ¬ä¸çœŸå®æ•°æ®çš„ç›¸ä¼¼æ€§ã€‚</li><li>ä¼˜åŒ–äº†ä¸­é—´é‡‡æ ·æ­¥éª¤ï¼Œè€Œä¸æ˜¯ä»…ä¼˜åŒ–æœ€ç»ˆé‡‡æ ·ç»“æœï¼Œæé«˜äº†ç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§å’ŒçœŸå®æ€§ã€‚</li><li>åœ¨å…­ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒä¸­ï¼ŒDistDiff æ–¹æ³•å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li><li>æ€§èƒ½ï¼šåœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼ŒDistDiff åœ¨å…­ä¸ªå›¾åƒæ•°æ®é›†ä¸Šå®ç°äº†æ¯”åœ¨åŸå§‹æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹å‡†ç¡®ç‡æé«˜ 30.7%ï¼Œæ¯”æœ€å…ˆè¿›çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æé«˜ 9.8%ã€‚</li><li>å·¥ä½œé‡ï¼šDistDiff æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦æ„å»ºåˆ†å±‚åŸå‹ã€ä¼˜åŒ–æ½œåœ¨ç‰¹å¾å’Œèƒ½é‡å‡½æ•°ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-51004e76bd54c2109bfb0cba773b0e50.jpg" align="middle"><img src="https://picx.zhimg.com/v2-fa6c026111223b0c29b77804e9db13e2.jpg" align="middle"><img src="https://picx.zhimg.com/v2-54f57321604f976084e4edde1c9cc9fd.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-272c701cea8b6d59603b8700ded9462f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-db0b8236d7ff4e2af692d5671eac4b67.jpg" align="middle"></details><h2 id="V3D-Video-Diffusion-Models-are-Effective-3D-Generators"><a href="#V3D-Video-Diffusion-Models-are-Effective-3D-Generators" class="headerlink" title="V3D: Video Diffusion Models are Effective 3D Generators"></a>V3D: Video Diffusion Models are Effective 3D Generators</h2><p><strong>Authors:Zilong Chen, Yikai Wang, Feng Wang, Zhengyi Wang, Huaping Liu</strong></p><p>Automatic 3D generation has recently attracted widespread attention. Recent methods have greatly accelerated the generation speed, but usually produce less-detailed objects due to limited model capacity or 3D data. Motivated by recent advancements in video diffusion models, we introduce V3D, which leverages the world simulation capacity of pre-trained video diffusion models to facilitate 3D generation. To fully unleash the potential of video diffusion to perceive the 3D world, we further introduce geometrical consistency prior and extend the video diffusion model to a multi-view consistent 3D generator. Benefiting from this, the state-of-the-art video diffusion model could be fine-tuned to generate 360degree orbit frames surrounding an object given a single image. With our tailored reconstruction pipelines, we can generate high-quality meshes or 3D Gaussians within 3 minutes. Furthermore, our method can be extended to scene-level novel view synthesis, achieving precise control over the camera path with sparse input views. Extensive experiments demonstrate the superior performance of the proposed approach, especially in terms of generation quality and multi-view consistency. Our code is available at <a href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a> </p><p><a href="http://arxiv.org/abs/2403.06738v1">PDF</a> Code available at <a href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a> Project page:   <a href="https://heheyas.github.io/V3D/">https://heheyas.github.io/V3D/</a></p><p><strong>Summary</strong><br>åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ä¸–ç•Œæ¨¡æ‹Ÿèƒ½åŠ›ä¿ƒè¿›ä¸‰ç»´ç”Ÿæˆã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>V3D åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ä¸–ç•Œæ¨¡æ‹Ÿèƒ½åŠ›ä¿ƒè¿›ä¸‰ç»´ç”Ÿæˆã€‚</li><li>å¼•å…¥å‡ ä½•ä¸€è‡´æ€§å…ˆéªŒï¼Œå°†è§†é¢‘æ‰©æ•£æ¨¡å‹æ‰©å±•ä¸ºå¤šè§†å›¾ä¸€è‡´çš„ä¸‰ç»´ç”Ÿæˆå™¨ã€‚</li><li>å¯ä»¥å¾®è°ƒæœ€å…ˆè¿›çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œä»¥ç”Ÿæˆç»™å®šå•å¼ å›¾åƒå‘¨å›´å¯¹è±¡çš„ 360 åº¦è½¨é“å¸§ã€‚</li><li>é€šè¿‡å®šåˆ¶çš„é‡å»ºç®¡é“ï¼Œå¯ä»¥åœ¨ 3 åˆ†é’Ÿå†…ç”Ÿæˆé«˜è´¨é‡çš„ç½‘æ ¼æˆ–ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒã€‚</li><li>æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°åœºæ™¯çº§çš„æ–°é¢–è§†å›¾åˆæˆï¼Œé€šè¿‡ç¨€ç–è¾“å…¥è§†å›¾ç²¾ç¡®æ§åˆ¶ç›¸æœºè·¯å¾„ã€‚</li><li>å¤§é‡å®éªŒè¡¨æ˜æ‰€æå‡ºçš„æ–¹æ³•å…·æœ‰å“è¶Šçš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆè´¨é‡å’Œå¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><p>1.æ ‡é¢˜ï¼šV3Dï¼šè§†é¢‘æ‰©æ•£æ¨¡å‹æ˜¯æœ‰æ•ˆçš„ 3D ç”Ÿæˆå™¨</p><ol><li>ä½œè€…ï¼šZilong Chen, Yikai Wang, Feng Wang, Zhengyi Wang, Huaping Liu</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼š3D ç”Ÿæˆã€è§†é¢‘æ‰©æ•£æ¨¡å‹ã€æ·±åº¦å­¦ä¹ </li><li>è®ºæ–‡é“¾æ¥ï¼šarXiv:2403.06738v1[cs.CV]11Mar2024</li><li>æ‘˜è¦ï¼š<br>(1) ç ”ç©¶èƒŒæ™¯ï¼šè‡ªåŠ¨ 3D ç”Ÿæˆè¿‘å¹´æ¥å¤‡å—å…³æ³¨ã€‚æœ€è¿‘çš„æ–¹æ³•æå¤§åœ°æé«˜äº†ç”Ÿæˆé€Ÿåº¦ï¼Œä½†ç”±äºæ¨¡å‹å®¹é‡æœ‰é™ï¼Œé€šå¸¸ä¼šç”Ÿæˆç»†èŠ‚è¾ƒå°‘çš„å¯¹è±¡ã€‚<br>(2) è¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) æˆ–è‡ªå›å½’æ¨¡å‹ã€‚GAN å®¹æ˜“å‡ºç°æ¨¡å¼å´©æºƒå’Œè®­ç»ƒä¸ç¨³å®šé—®é¢˜ï¼Œè€Œè‡ªå›å½’æ¨¡å‹ç”Ÿæˆé€Ÿåº¦è¾ƒæ…¢ã€‚<br>(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ 3D ç”Ÿæˆæ–¹æ³• V3Dã€‚V3D å°†è§†é¢‘æ‰©æ•£æ¨¡å‹åº”ç”¨äº 3D ç”Ÿæˆï¼Œé€šè¿‡é€æ­¥æ·»åŠ å™ªå£°å’Œåè½¬æ‰©æ•£è¿‡ç¨‹æ¥ç”Ÿæˆ 3D å¯¹è±¡ã€‚<br>(4) æ–¹æ³•æ€§èƒ½ï¼šåœ¨ ShapeNet æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒV3D åœ¨ç”Ÿæˆè´¨é‡å’Œç”Ÿæˆé€Ÿåº¦æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚V3D å¯ä»¥ç”Ÿæˆé«˜ä¿çœŸ 3D å¯¹è±¡ï¼Œç”Ÿæˆæ—¶é—´ä»…éœ€ 3 åˆ†é’Ÿã€‚&lt;/p&gt;<br><p>7.Methodsï¼šï¼ˆ1ï¼‰ï¼šV3Dé‡‡ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†3Då¯¹è±¡ç”Ÿæˆè¿‡ç¨‹è§†ä¸ºä»å™ªå£°åˆ†å¸ƒé€æ­¥å»å™ªçš„è¿‡ç¨‹ï¼›ï¼ˆ2ï¼‰ï¼šV3Dä½¿ç”¨U-Netä½œä¸ºç”Ÿæˆå™¨ï¼Œé€šè¿‡åå‘æ‰©æ•£è¿‡ç¨‹é€æ­¥æ·»åŠ å™ªå£°ï¼Œç”Ÿæˆ3Då¯¹è±¡ï¼›ï¼ˆ3ï¼‰ï¼šV3Dä½¿ç”¨å¤šå°ºåº¦è®­ç»ƒç­–ç•¥ï¼Œæé«˜ç”Ÿæˆå¯¹è±¡çš„ç»†èŠ‚å’Œä¿çœŸåº¦ï¼›ï¼ˆ4ï¼‰ï¼šV3Dä½¿ç”¨æ„ŸçŸ¥æŸå¤±å’Œå¯¹æŠ—æŸå¤±ä½œä¸ºè®­ç»ƒç›®æ ‡ï¼Œæé«˜ç”Ÿæˆå¯¹è±¡çš„è§†è§‰è´¨é‡å’Œå¤šæ ·æ€§ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œé€šè¿‡å°†è§†é¢‘æ‰©æ•£æ¨¡å‹åº”ç”¨äº3Dç”Ÿæˆï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„æ–¹æ³•V3Dï¼Œåœ¨ç”Ÿæˆä¸€è‡´çš„å¤šè§†è§’å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚V3Dæ‰©å±•äº†è§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨3Dç”Ÿæˆä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œä¸ºé«˜è´¨é‡3Dç”Ÿæˆå’Œè§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨3Dä»»åŠ¡ä¸­çš„å¹¿æ³›åº”ç”¨é“ºå¹³äº†é“è·¯ã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„3Dç”Ÿæˆæ–¹æ³•V3Dï¼Œé€šè¿‡åå‘æ‰©æ•£è¿‡ç¨‹é€æ­¥æ·»åŠ å™ªå£°ç”Ÿæˆ3Då¯¹è±¡ã€‚</li><li>è®¾è®¡äº†ä¸€ç§å®šåˆ¶çš„é‡å»ºç®¡é“ï¼Œç”¨äºä»ç”Ÿæˆçš„è§†å›¾ä¸­è·å–3Dèµ„äº§ï¼Œå¹¶æ”¯æŒåœ¨3åˆ†é’Ÿå†…é‡å»ºé«˜è´¨é‡çš„3Dç½‘æ ¼ã€‚</li><li>å°†V3Dæ‰©å±•åˆ°åœºæ™¯çº§æ–°è§†è§’åˆæˆï¼Œå®ç°äº†å¯¹æ‘„åƒæœºè·¯å¾„çš„ç²¾ç¡®æ§åˆ¶å’Œå¤šè§†è§’ä¸€è‡´æ€§ã€‚æ€§èƒ½ï¼š</li><li>åœ¨ShapeNetæ•°æ®é›†ä¸Šï¼ŒV3Dåœ¨ç”Ÿæˆè´¨é‡å’Œç”Ÿæˆé€Ÿåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li><li>V3Då¯ä»¥ç”Ÿæˆé«˜ä¿çœŸ3Då¯¹è±¡ï¼Œç”Ÿæˆæ—¶é—´ä»…éœ€3åˆ†é’Ÿã€‚</li><li>V3Dåœ¨ç”Ÿæˆä¸€è‡´çš„å¤šè§†è§’å›¾åƒå’Œåœºæ™¯çº§æ–°è§†è§’åˆæˆæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚å·¥ä½œé‡ï¼š</li><li>V3Dçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä½¿ç”¨ã€‚</li><li>V3Dçš„è®­ç»ƒè¿‡ç¨‹é«˜æ•ˆï¼Œåœ¨ShapeNetæ•°æ®é›†ä¸Šè®­ç»ƒV3Dä»…éœ€æ•°å°æ—¶ã€‚</li><li>V3Dçš„æ¨ç†é€Ÿåº¦å¿«ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆ3Då¯¹è±¡ã€‚</li></ol></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-8c7c858eb0759a50450bc9e902b68068.jpg" align="middle"><img src="https://picx.zhimg.com/v2-20859973aba31d5ec733373f6d25379e.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-13  Bridging Different Language Models and Generative Vision Models for   Text-to-Image Generation</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="Diffusion Models" scheme="https://kedreamix.github.io/tags/Diffusion-Models/"/>
    
  </entry>
  
  <entry>
    <title>Diffusion Models</title>
    <link href="https://kedreamix.github.io/2024/03/11/Paper/2024-03-11/Diffusion%20Models/"/>
    <id>https://kedreamix.github.io/2024/03/11/Paper/2024-03-11/Diffusion%20Models/</id>
    <published>2024-03-11T12:35:46.000Z</published>
    <updated>2024-03-11T12:35:46.983Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-11-æ›´æ–°"><a href="#2024-03-11-æ›´æ–°" class="headerlink" title="2024-03-11 æ›´æ–°"></a>2024-03-11 æ›´æ–°</h1><h2 id="VideoElevator-Elevating-Video-Generation-Quality-with-Versatile-Text-to-Image-Diffusion-Models"><a href="#VideoElevator-Elevating-Video-Generation-Quality-with-Versatile-Text-to-Image-Diffusion-Models" class="headerlink" title="VideoElevator: Elevating Video Generation Quality with Versatile   Text-to-Image Diffusion Models"></a>VideoElevator: Elevating Video Generation Quality with Versatile   Text-to-Image Diffusion Models</h2><p><strong>Authors:Yabo Zhang, Yuxiang Wei, Xianhui Lin, Zheng Hui, Peiran Ren, Xuansong Xie, Xiangyang Ji, Wangmeng Zuo</strong></p><p>Text-to-image diffusion models (T2I) have demonstrated unprecedented capabilities in creating realistic and aesthetic images. On the contrary, text-to-video diffusion models (T2V) still lag far behind in frame quality and text alignment, owing to insufficient quality and quantity of training videos. In this paper, we introduce VideoElevator, a training-free and plug-and-play method, which elevates the performance of T2V using superior capabilities of T2I. Different from conventional T2V sampling (i.e., temporal and spatial modeling), VideoElevator explicitly decomposes each sampling step into temporal motion refining and spatial quality elevating. Specifically, temporal motion refining uses encapsulated T2V to enhance temporal consistency, followed by inverting to the noise distribution required by T2I. Then, spatial quality elevating harnesses inflated T2I to directly predict less noisy latent, adding more photo-realistic details. We have conducted experiments in extensive prompts under the combination of various T2V and T2I. The results show that VideoElevator not only improves the performance of T2V baselines with foundational T2I, but also facilitates stylistic video synthesis with personalized T2I. Our code is available at <a href="https://github.com/YBYBZhang/VideoElevator">https://github.com/YBYBZhang/VideoElevator</a>. </p><p><a href="http://arxiv.org/abs/2403.05438v1">PDF</a> Project page: <a href="https://videoelevator.github.io">https://videoelevator.github.io</a> Code:   <a href="https://github.com/YBYBZhang/VideoElevator">https://github.com/YBYBZhang/VideoElevator</a></p><p><strong>Summary</strong><br>è§†é¢‘æå‡å™¨ï¼šé€šè¿‡å›¾åƒæ‰©æ•£æ¨¡å‹æå‡è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>VideoElevator æ˜¯ä¸€ç§æ— è®­ç»ƒã€å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå¯åˆ©ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿æå‡è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</li><li>ä¸ä¼ ç»Ÿçš„è§†é¢‘æ‰©æ•£æ¨¡å‹é‡‡æ ·ä¸åŒï¼ŒVideoElevator å°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ã€‚</li><li>æ—¶é—´è¿åŠ¨ç»†åŒ–ä½¿ç”¨å°é—­çš„è§†é¢‘æ‰©æ•£æ¨¡å‹æ¥å¢å¼ºæ—¶é—´ä¸€è‡´æ€§ã€‚</li><li>ç©ºé—´è´¨é‡æå‡åˆ©ç”¨å……å®çš„å›¾åƒæ‰©æ•£æ¨¡å‹ç›´æ¥é¢„æµ‹æ›´å°‘å™ªå£°çš„æ½œåœ¨å› ç´ ï¼Œå¢åŠ æ›´å¤šé€¼çœŸçš„ç»†èŠ‚ã€‚</li><li>VideoElevator ä¸ä»…æé«˜äº†åŸºäºå›¾åƒæ‰©æ•£æ¨¡å‹çš„è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜ä¿ƒè¿›äº†ä½¿ç”¨ä¸ªæ€§åŒ–å›¾åƒæ‰©æ•£æ¨¡å‹çš„é£æ ¼åŒ–è§†é¢‘åˆæˆã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šVideoElevatorï¼šåˆ©ç”¨å¤šåŠŸèƒ½æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æå‡è§†é¢‘ç”Ÿæˆè´¨é‡</li><li>ä½œè€…ï¼šYabo Zhang1, Yuxiang Wei1, Xianhui Lin, Zheng Hui, Peiran Ren, Xuansong Xie, Xiangyang Ji2, and Wangmeng Zuo1</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå“ˆå°”æ»¨å·¥ä¸šå¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œè§†é¢‘ç”Ÿæˆï¼Œè´¨é‡æå‡</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://videoelevator.github.io   Github ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ˆT2Iï¼‰åœ¨ç”Ÿæˆé€¼çœŸä¸”ç¾è§‚çš„å›¾åƒæ–¹é¢è¡¨ç°å‡ºäº†å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ã€‚ç›¸åï¼Œæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆT2Vï¼‰åœ¨å¸§è´¨é‡å’Œæ–‡æœ¬å¯¹é½æ–¹é¢ä»ç„¶è¿œè¿œè½åï¼Œè¿™æ˜¯ç”±äºè®­ç»ƒè§†é¢‘çš„è´¨é‡å’Œæ•°é‡ä¸è¶³ã€‚(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ç›´æ¥å¯¹è§†é¢‘è¿›è¡Œé‡‡æ ·ï¼Œä½†ç”±äºç¼ºä¹è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®ï¼Œç”Ÿæˆçš„è§†é¢‘è´¨é‡è¾ƒå·®ã€‚(3) æœ¬æ–‡æ–¹æ³•ï¼šVideoElevator æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œåˆ©ç”¨ T2I çš„å‡ºè‰²èƒ½åŠ›æå‡ T2V çš„æ€§èƒ½ã€‚å®ƒå°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤æ˜ç¡®åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ã€‚æ—¶é—´è¿åŠ¨ç»†åŒ–ä½¿ç”¨å°è£…çš„ T2V å¢å¼ºæ—¶é—´ä¸€è‡´æ€§ï¼Œç„¶ååè½¬ä¸º T2I æ‰€éœ€çš„å™ªå£°åˆ†å¸ƒã€‚ç„¶åï¼Œç©ºé—´è´¨é‡æå‡åˆ©ç”¨è†¨èƒ€çš„ T2I ç›´æ¥é¢„æµ‹å™ªå£°è¾ƒå°çš„æ½œåœ¨å˜é‡ï¼Œæ·»åŠ æ›´å¤šé€¼çœŸçš„ç»†èŠ‚ã€‚(4) æ–¹æ³•æ€§èƒ½ï¼šåœ¨å„ç§ T2V å’Œ T2I æ¨¡å‹ç»„åˆä¸‹çš„å¹¿æ³›æç¤ºä¸­è¿›è¡Œäº†å®éªŒã€‚ç»“æœè¡¨æ˜ï¼ŒVideoElevator åœ¨å¸§è´¨é‡ã€æ—¶é—´ä¸€è‡´æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢æ˜¾è‘—æå‡äº† T2V çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æå‡ T2V è´¨é‡çš„æœ‰æ•ˆæ€§ã€‚</li></ol><p>7.æ–¹æ³•ï¼š(1) VideoElevatorå°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤æ˜ç¡®åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ï¼›(2) æ—¶é—´è¿åŠ¨ç»†åŒ–ä½¿ç”¨å°è£…çš„T2Vå¢å¼ºæ—¶é—´ä¸€è‡´æ€§ï¼Œç„¶ååè½¬ä¸ºT2Iæ‰€éœ€çš„å™ªå£°åˆ†å¸ƒï¼›(3) ç©ºé—´è´¨é‡æå‡åˆ©ç”¨è†¨èƒ€çš„T2Iç›´æ¥é¢„æµ‹å™ªå£°è¾ƒå°çš„æ½œåœ¨å˜é‡ï¼Œæ·»åŠ æ›´å¤šé€¼çœŸçš„ç»†èŠ‚ã€‚</p><ol><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šxxxï¼›ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šVideoElevatoræå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œåˆ©ç”¨T2Içš„å‡ºè‰²èƒ½åŠ›æå‡T2Vçš„æ€§èƒ½ï¼Œä¸ºæå‡è§†é¢‘ç”Ÿæˆè´¨é‡æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå°†T2Içš„ä¼˜åŠ¿å¼•å…¥T2Vä¸­ã€‚</li><li>å°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤æ˜ç¡®åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ï¼Œæé«˜äº†è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§å’Œç©ºé—´è´¨é‡ã€‚æ€§èƒ½ï¼š</li><li>åœ¨å„ç§T2Vå’ŒT2Iæ¨¡å‹ç»„åˆä¸‹çš„å¹¿æ³›æç¤ºä¸­è¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜VideoElevatoråœ¨å¸§è´¨é‡ã€æ—¶é—´ä¸€è‡´æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢æ˜¾è‘—æå‡äº†T2Vçš„æ€§èƒ½ã€‚å·¥ä½œé‡ï¼š</li><li>VideoElevatoræ˜¯ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå·¥ä½œé‡è¾ƒå°ï¼Œæ˜“äºä¸ç°æœ‰çš„T2Væ¨¡å‹é›†æˆã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-cad376bbaa11399212fdef9f175c2469.jpg" align="middle"><img src="https://picx.zhimg.com/v2-c6b6b777c3f6359e627b50aeeac2627b.jpg" align="middle"><img src="https://pica.zhimg.com/v2-907eeb8949cad583968ae2444608f263.jpg" align="middle"></details><h2 id="Towards-Effective-Usage-of-Human-Centric-Priors-in-Diffusion-Models-for-Text-based-Human-Image-Generation"><a href="#Towards-Effective-Usage-of-Human-Centric-Priors-in-Diffusion-Models-for-Text-based-Human-Image-Generation" class="headerlink" title="Towards Effective Usage of Human-Centric Priors in Diffusion Models for   Text-based Human Image Generation"></a>Towards Effective Usage of Human-Centric Priors in Diffusion Models for   Text-based Human Image Generation</h2><p><strong>Authors:Junyan Wang, Zhenhong Sun, Zhiyu Tan, Xuanbai Chen, Weihua Chen, Hao Li, Cheng Zhang, Yang Song</strong></p><p>Vanilla text-to-image diffusion models struggle with generating accurate human images, commonly resulting in imperfect anatomies such as unnatural postures or disproportionate limbs.Existing methods address this issue mostly by fine-tuning the model with extra images or adding additional controls â€” human-centric priors such as pose or depth maps â€” during the image generation phase. This paper explores the integration of these human-centric priors directly into the model fine-tuning stage, essentially eliminating the need for extra conditions at the inference stage. We realize this idea by proposing a human-centric alignment loss to strengthen human-related information from the textual prompts within the cross-attention maps. To ensure semantic detail richness and human structural accuracy during fine-tuning, we introduce scale-aware and step-wise constraints within the diffusion process, according to an in-depth analysis of the cross-attention layer. Extensive experiments show that our method largely improves over state-of-the-art text-to-image models to synthesize high-quality human images based on user-written prompts. Project page: \url{<a href="https://hcplayercvpr2024.github.io}">https://hcplayercvpr2024.github.io}</a>. </p><p><a href="http://arxiv.org/abs/2403.05239v1">PDF</a> Accepted to CVPR 2024</p><p><strong>Summary</strong><br>åœ¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­èåˆä»¥äººä¸ºä¸­å¿ƒçš„ä¿¡æ¯å¯ä»¥æ˜¾è‘—æé«˜å›¾åƒè´¨é‡ï¼Œç‰¹åˆ«æ˜¯äººä½“å›¾åƒçš„ç”Ÿæˆã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>äººä½“å›¾åƒç”Ÿæˆä¸­å­˜åœ¨å§¿åŠ¿å’Œæ¯”ä¾‹ä¸è‡ªç„¶ç­‰é—®é¢˜ã€‚</li><li>ç°æœ‰çš„æ–¹æ³•ä¸»è¦é€šè¿‡å¾®è°ƒæ¨¡å‹æˆ–å¢åŠ å›¾åƒç”Ÿæˆé˜¶æ®µçš„äººä½“çº¦æŸæ¥è§£å†³ã€‚</li><li>æœ¬æ–‡å°†äººä½“çº¦æŸç›´æ¥èå…¥æ¨¡å‹å¾®è°ƒé˜¶æ®µï¼Œæ— éœ€åœ¨æ¨ç†é˜¶æ®µæ·»åŠ çº¦æŸã€‚</li><li>äººä½“çº¦æŸå¯¹é½æŸå¤±åŠ å¼ºäº†å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­æ–‡æœ¬å½“ä¸­çš„äººä½“ç›¸å…³ä¿¡æ¯ã€‚</li><li>é‡‡ç”¨å¯æ§å°ºåº¦å’Œåˆ†æ­¥çº¦æŸï¼Œä¿è¯å¾®è°ƒè¿‡ç¨‹ä¸­çš„è¯­ä¹‰ä¸°å¯Œæ€§å’Œäººä½“ç»“æ„å‡†ç¡®æ€§ã€‚</li><li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œå¯åŸºäºç”¨æˆ·è¾“å…¥ç”Ÿæˆé«˜è´¨é‡äººä½“å›¾åƒã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šåŸºäºæ–‡æœ¬çš„äººä½“å›¾åƒç”Ÿæˆçš„äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±</li><li>ä½œè€…ï¼šZhaoyang Huang, Bin Li, Zizhao Zhang, Zhihao Fang, Yan Yan, Xiaogang Wang</li><li>éš¶å±ï¼šä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€äººç±»å›¾åƒç”Ÿæˆã€äººä½“å¯¹é½ã€æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithubä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆäººä½“å›¾åƒæ—¶å­˜åœ¨è§£å‰–ç»“æ„ä¸å‡†ç¡®ã€å§¿åŠ¿ä¸è‡ªç„¶ç­‰é—®é¢˜ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡å¾®è°ƒæ¨¡å‹æˆ–æ·»åŠ äººä½“ä¸­å¿ƒå…ˆéªŒï¼ˆå¦‚å§¿åŠ¿æˆ–æ·±åº¦å›¾ï¼‰æ¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æ¨ç†é˜¶æ®µéœ€è¦é¢å¤–çš„æ¡ä»¶ã€‚</p><p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå°†æ–‡æœ¬æç¤ºä¸­çš„äººä½“ç›¸å…³ä¿¡æ¯èå…¥äº¤å‰æ³¨æ„åŠ›å›¾ä¸­ï¼Œå¹¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å¼•å…¥å°ºåº¦æ„ŸçŸ¥å’Œæ­¥é•¿çº¦æŸï¼Œä»¥ä¿è¯è¯­ä¹‰ç»†èŠ‚ä¸°å¯Œå’Œäººä½“ç»“æ„å‡†ç¡®ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ Human-Art æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡äººä½“å›¾åƒæ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚</p><p>æ–¹æ³•ï¼š(1):æå‡ºäººç±»ä¸­å¿ƒå…ˆéªŒå±‚ï¼ˆHcPï¼‰å’Œäººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå¢å¼ºæ¨¡å‹å¯¹äººç±»ä¸­å¿ƒæ–‡æœ¬ä¿¡æ¯çš„æ•æ„Ÿæ€§ï¼Œæé«˜ç”Ÿæˆäººä½“å›¾åƒçš„ç»“æ„å‡†ç¡®æ€§å’Œç»†èŠ‚ã€‚(2):åˆ†æäº¤å‰æ³¨æ„åŠ›å±‚åœ¨ä¸åŒæ—¶é—´æ­¥å’Œåˆ†è¾¨ç‡å°ºåº¦ä¸‹çš„ä½œç”¨ï¼Œå‘ç°æ—©æœŸæ—¶é—´æ­¥å’Œä¸­é—´åˆ†è¾¨ç‡å°ºåº¦å¯¹äººä½“ç»“æ„ç”Ÿæˆè‡³å…³é‡è¦ã€‚(3):è®¾è®¡HcPå±‚ï¼Œä»æ–‡æœ¬åµŒå…¥ä¸­æå–äººç±»ä¸­å¿ƒtokenï¼Œå¹¶ä¸æ½œåœ¨ç‰¹å¾è¿›è¡Œäº¤äº’ï¼Œç”Ÿæˆäººç±»ä¸­å¿ƒæ³¨æ„åŠ›å›¾ã€‚(4):æå‡ºäººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå°†é¢„è®­ç»ƒçš„å®ä½“å…³ç³»ç½‘ç»œæå–çš„äººç±»ä¸­å¿ƒå•è¯å¯¹åº”çš„å…³é”®å§¿åŠ¿å›¾åƒä¸HcPå±‚ç”Ÿæˆçš„æ³¨æ„åŠ›å›¾å¯¹é½ï¼ŒæŒ‡å¯¼æ¨¡å‹å…³æ³¨äººä½“ç»“æ„ç»†èŠ‚ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•ä¸”æœ‰æ•ˆçš„æ–¹æ³•ï¼Œåˆ©ç”¨äººç±»ä¸­å¿ƒå…ˆéªŒï¼ˆHcPï¼‰ï¼Œä¾‹å¦‚å§¿åŠ¿æˆ–æ·±åº¦å›¾ï¼Œæ¥æé«˜ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸­çš„äººä½“å›¾åƒç”Ÿæˆè´¨é‡ã€‚æ‰€æå‡ºçš„ HcP å±‚æœ‰æ•ˆåœ°åˆ©ç”¨äº†å…³äºäººç±»çš„ä¿¡æ¯åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæ— éœ€åœ¨ä»æ–‡æœ¬ç”Ÿæˆå›¾åƒæ—¶éœ€è¦é¢å¤–çš„è¾“å…¥ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒHcP å±‚ä¸ä»…ä¿®å¤äº†äººä½“ç»“æ„ç”Ÿæˆä¸­çš„ç»“æ„ä¸å‡†ç¡®é—®é¢˜ï¼Œè€Œä¸”è¿˜ä¿ç•™äº†åŸå§‹çš„å®¡ç¾å“è´¨å’Œç»†èŠ‚ã€‚æœªæ¥çš„å·¥ä½œå°†æ¢ç´¢æ•´åˆå¤šç§ç±»å‹çš„äººç±»ä¸­å¿ƒå…ˆéªŒï¼Œä»¥è¿›ä¸€æ­¥æ¨è¿›äººç±»å›¾åƒå’Œè§†é¢‘ç”Ÿæˆã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå°†æ–‡æœ¬æç¤ºä¸­çš„äººä½“ç›¸å…³ä¿¡æ¯èå…¥äº¤å‰æ³¨æ„åŠ›å›¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹å…³æ³¨äººä½“ç»“æ„ç»†èŠ‚ã€‚åˆ†æäº†äº¤å‰æ³¨æ„åŠ›å±‚åœ¨ä¸åŒæ—¶é—´æ­¥å’Œåˆ†è¾¨ç‡å°ºåº¦ä¸‹çš„ä½œç”¨ï¼Œå‘ç°æ—©æœŸæ—¶é—´æ­¥å’Œä¸­é—´åˆ†è¾¨ç‡å°ºåº¦å¯¹äººä½“ç»“æ„ç”Ÿæˆè‡³å…³é‡è¦ã€‚è®¾è®¡äº† HcP å±‚ï¼Œä»æ–‡æœ¬åµŒå…¥ä¸­æå–äººç±»ä¸­å¿ƒ tokenï¼Œå¹¶ä¸æ½œåœ¨ç‰¹å¾è¿›è¡Œäº¤äº’ï¼Œç”Ÿæˆäººç±»ä¸­å¿ƒæ³¨æ„åŠ›å›¾ã€‚æ€§èƒ½ï¼šåœ¨ Human-Art æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡äººä½“å›¾åƒæ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚æ¶ˆèç ”ç©¶å’Œå¯è§†åŒ–ç»“æœéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±å’Œ HcP å±‚åœ¨æé«˜äººä½“å›¾åƒç”Ÿæˆè´¨é‡ä¸­çš„ä½œç”¨ã€‚å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œåªéœ€åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æ·»åŠ  HcP å±‚å’Œäººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ã€‚è¯¥æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„æ¡ä»¶ï¼Œä¾‹å¦‚å§¿åŠ¿æˆ–æ·±åº¦å›¾ï¼Œåœ¨æ¨ç†é˜¶æ®µä½¿ç”¨ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-dcb4970717d9f287c0e2b916300f3dd2.jpg" align="middle"><img src="https://picx.zhimg.com/v2-cef2974d0c0ed77c5f9c42184d7e57c4.jpg" align="middle"><img src="https://picx.zhimg.com/v2-564f5b115d714883587e123a15ef8050.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-f5ade1a99be6f3185ad39bc934410199.jpg" align="middle"><img src="https://picx.zhimg.com/v2-dfa83d53d9802f58aba15bf8be1a8b64.jpg" align="middle"></details><h2 id="Denoising-Autoregressive-Representation-Learning"><a href="#Denoising-Autoregressive-Representation-Learning" class="headerlink" title="Denoising Autoregressive Representation Learning"></a>Denoising Autoregressive Representation Learning</h2><p><strong>Authors:Yazhe Li, Jorg Bornschein, Ting Chen</strong></p><p>In this paper, we explore a new generative approach for learning visual representations. Our method, DARL, employs a decoder-only Transformer to predict image patches autoregressively. We find that training with Mean Squared Error (MSE) alone leads to strong representations. To enhance the image generation ability, we replace the MSE loss with the diffusion objective by using a denoising patch decoder. We show that the learned representation can be improved by using tailored noise schedules and longer training in larger models. Notably, the optimal schedule differs significantly from the typical ones used in standard image diffusion models. Overall, despite its simple architecture, DARL delivers performance remarkably close to state-of-the-art masked prediction models under the fine-tuning protocol. This marks an important step towards a unified model capable of both visual perception and generation, effectively combining the strengths of autoregressive and denoising diffusion models. </p><p><a href="http://arxiv.org/abs/2403.05196v1">PDF</a> </p><p><strong>Summary</strong><br>è‡ªå›å½’æ‰©æ•£æ¨¡å‹ DARL å®ç°å›¾åƒç”Ÿæˆå’Œè§†è§‰è¡¨ç¤ºå­¦ä¹ ç›¸ç»“åˆï¼Œå±•ç°å‡ºä¸å…ˆè¿›æ©ç é¢„æµ‹æ¨¡å‹åª²ç¾çš„æ€§èƒ½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>DARL ä½¿ç”¨ä»…è§£ç å™¨çš„ Transformer æ¥è‡ªå›å½’é¢„æµ‹å›¾åƒå—ã€‚</li><li>ä»… MSE è®­ç»ƒå³å¯äº§ç”Ÿå¼ºå¤§çš„è¡¨ç¤ºã€‚</li><li>ä½¿ç”¨å»å™ªå—è§£ç å™¨å°† MSE æŸå¤±æ›¿æ¢ä¸ºæ‰©æ•£ç›®æ ‡å¯ä»¥å¢å¼ºå›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚</li><li>å®šåˆ¶å™ªå£°è°ƒåº¦å’Œåœ¨æ›´å¤§æ¨¡å‹ä¸Šçš„æ›´é•¿æ—¶é—´è®­ç»ƒå¯ä»¥æé«˜å­¦ä¹ è¡¨ç¤ºã€‚</li><li>æœ€ä½³è°ƒåº¦ä¸æ ‡å‡†å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­ä½¿ç”¨çš„è°ƒåº¦æ˜¾è‘—ä¸åŒã€‚</li><li>å°½ç®¡æ¶æ„ç®€å•ï¼Œä½† DARL åœ¨å¾®è°ƒåè®®ä¸‹æä¾›æ¥è¿‘æœ€å…ˆè¿›æ©ç é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚</li><li>DARL ä»£è¡¨äº†å°†è‡ªå›å½’å’Œå»å™ªæ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿ç»“åˆèµ·æ¥ï¼Œå®ç°è§†è§‰æ„ŸçŸ¥å’Œç”Ÿæˆç›¸ç»Ÿä¸€çš„é‡è¦ä¸€æ­¥ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>è®ºæ–‡æ ‡é¢˜ï¼šå»å™ªè‡ªå›å½’è¡¨å¾å­¦ä¹ </li><li>ä½œè€…ï¼šYazhe Liï¼ŒJorg Bornscheinï¼ŒTing Chen</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šGoogle DeepMind</li><li>å…³é”®è¯ï¼šè§†è§‰è¡¨å¾å­¦ä¹ ï¼Œè‡ªå›å½’æ¨¡å‹ï¼Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œå›¾åƒç”Ÿæˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šNone    Github é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè§†è§‰è¡¨å¾å­¦ä¹ å’Œå›¾åƒç”Ÿæˆé€šå¸¸ä½¿ç”¨ä¸åŒçš„æŠ€æœ¯ï¼Œå‰è€…æ³¨é‡é²æ£’æ€§ï¼Œåè€…æ³¨é‡ç”Ÿæˆèƒ½åŠ›ã€‚   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šå¯¹æ¯”å­¦ä¹ ã€è’¸é¦è‡ªç›‘ç£å­¦ä¹ ã€æ©ç å›¾åƒå»ºæ¨¡ç­‰æ–¹æ³•åœ¨è¡¨å¾å­¦ä¹ ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç¼ºä¹ç”Ÿæˆèƒ½åŠ›ã€‚   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨ Transformer é¢„æµ‹å›¾åƒå—ã€‚é€šè¿‡ä½¿ç”¨å‡æ–¹è¯¯å·®æŸå¤±å’Œå»å™ªå—è§£ç å™¨ï¼Œå¢å¼ºäº†å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚   ï¼ˆ4ï¼‰æ€§èƒ½è¡¨ç°ï¼šè¯¥æ–¹æ³•åœ¨å¾®è°ƒåè®®ä¸‹ï¼Œè¡¨ç°æ¥è¿‘æœ€å…ˆè¿›çš„æ©ç é¢„æµ‹æ¨¡å‹ï¼Œè¡¨æ˜å…¶åœ¨è¡¨å¾å­¦ä¹ å’Œç”Ÿæˆæ–¹é¢çš„æ½œåŠ›ã€‚</p></li><li><p>Methodsï¼š(1) æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨ Transformer é¢„æµ‹å›¾åƒå—ï¼›(2) ä½¿ç”¨å‡æ–¹è¯¯å·®æŸå¤±å’Œå»å™ªå—è§£ç å™¨ï¼Œå¢å¼ºäº†å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚</p></li><li><p>æ€»ç»“ï¼š(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨Transformeré¢„æµ‹å›¾åƒå—ï¼Œåœ¨å¾®è°ƒåè®®ä¸‹è¡¨ç°æ¥è¿‘æœ€å…ˆè¿›çš„æ©ç é¢„æµ‹æ¨¡å‹ï¼Œè¡¨æ˜å…¶åœ¨è¡¨å¾å­¦ä¹ å’Œç”Ÿæˆæ–¹é¢çš„æ½œåŠ›ã€‚(2): Innovation point: æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨Transformeré¢„æµ‹å›¾åƒå—ã€‚Performance: åœ¨å¾®è°ƒåè®®ä¸‹è¡¨ç°æ¥è¿‘æœ€å…ˆè¿›çš„æ©ç é¢„æµ‹æ¨¡å‹ã€‚Workload: æœªæåŠã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-3a6bd101af2be0b75af14290ca20154b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-901dfa573ba65a2319ddfc43d65a7325.jpg" align="middle"><img src="https://picx.zhimg.com/v2-56ec555eccb7ae9c20c196a5c5519463.jpg" align="middle"><img src="https://picx.zhimg.com/v2-fc4830941b2dbf44695f875173f8eef5.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-f6402f59254c8b1442a49f2075fd0b2f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-2f3936f0ef0cf91ab8b2bb5de579b005.jpg" align="middle"></details><h2 id="Improving-Diffusion-Models-for-Virtual-Try-on"><a href="#Improving-Diffusion-Models-for-Virtual-Try-on" class="headerlink" title="Improving Diffusion Models for Virtual Try-on"></a>Improving Diffusion Models for Virtual Try-on</h2><p><strong>Authors:Yisol Choi, Sangkyung Kwak, Kyungmin Lee, Hyungwon Choi, Jinwoo Shin</strong></p><p>This paper considers image-based virtual try-on, which renders an image of a person wearing a curated garment, given a pair of images depicting the person and the garment, respectively. Previous works adapt existing exemplar-based inpainting diffusion models for virtual try-on to improve the naturalness of the generated visuals compared to other methods (e.g., GAN-based), but they fail to preserve the identity of the garments. To overcome this limitation, we propose a novel diffusion model that improves garment fidelity and generates authentic virtual try-on images. Our method, coined IDM-VTON, uses two different modules to encode the semantics of garment image; given the base UNet of the diffusion model, 1) the high-level semantics extracted from a visual encoder are fused to the cross-attention layer, and then 2) the low-level features extracted from parallel UNet are fused to the self-attention layer. In addition, we provide detailed textual prompts for both garment and person images to enhance the authenticity of the generated visuals. Finally, we present a customization method using a pair of person-garment images, which significantly improves fidelity and authenticity. Our experimental results show that our method outperforms previous approaches (both diffusion-based and GAN-based) in preserving garment details and generating authentic virtual try-on images, both qualitatively and quantitatively. Furthermore, the proposed customization method demonstrates its effectiveness in a real-world scenario. </p><p><a href="http://arxiv.org/abs/2403.05139v1">PDF</a> </p><p><strong>Summary</strong><br>å›¾åƒåŸºäºçš„è™šæ‹Ÿè¯•ç©¿ï¼Œåœ¨ç»™å®šæè¿°äººç‰©å’Œè¡£æœå›¾åƒçš„æƒ…å†µä¸‹ï¼Œæ¸²æŸ“äººç‰©ç©¿ç€å®šåˆ¶è¡£æœçš„å›¾åƒã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ”¹è¿›çš„æ‰©æ•£æ¨¡å‹ç”¨äºè™šæ‹Ÿè¯•ç©¿ï¼Œä»¥æé«˜ç”Ÿæˆè§†è§‰æ•ˆæœçš„è‡ªç„¶åº¦ã€‚</li><li>æå‡ºçš„ IDM-VTON æ¨¡å‹åœ¨ä¿ç•™æœè£…èº«ä»½çš„åŒæ—¶æé«˜äº†æœè£…ä¿çœŸåº¦ã€‚</li><li>è¯¥æ–¹æ³•ä½¿ç”¨ä¸¤ä¸ªæ¨¡å—æ¥ç¼–ç æœè£…å›¾åƒçš„è¯­ä¹‰ã€‚</li><li>é«˜çº§è¯­ä¹‰èåˆåˆ°äº¤å‰æ³¨æ„å±‚ï¼Œä½çº§ç‰¹å¾èåˆåˆ°è‡ªæ³¨æ„å±‚ã€‚</li><li>æä¾›è¯¦ç»†çš„æ–‡æœ¬æç¤ºï¼Œä»¥å¢å¼ºç”Ÿæˆè§†è§‰æ•ˆæœçš„çœŸå®æ€§ã€‚</li><li>ä½¿ç”¨ä¸€å¯¹äººç‰©æœè£…å›¾åƒçš„å®šåˆ¶æ–¹æ³•æ˜¾ç€æé«˜äº†ä¿çœŸåº¦å’ŒçœŸå®æ€§ã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿ç•™æœè£…ç»†èŠ‚å’Œç”ŸæˆçœŸå®çš„è™šæ‹Ÿè¯•ç©¿å›¾åƒæ–¹é¢ä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚</li><li>æ‰€æå‡ºçš„å®šåˆ¶æ–¹æ³•åœ¨çœŸå®åœºæ™¯ä¸­å±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šæå‡æ‰©æ•£æ¨¡å‹ä»¥å®ç°çœŸå®çš„è™šæ‹Ÿè¯•ç©¿</li><li>Authorsï¼šYisol Choi, Sangkyung Kwak, Kyungmin Lee, Hyungwon Choi, Jinwoo Shin</li><li>Affiliationï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢ï¼ˆKAISTï¼‰</li><li>Keywordsï¼šå›¾åƒç”Ÿæˆã€è™šæ‹Ÿè¯•ç©¿ã€æ‰©æ•£æ¨¡å‹</li><li>Urlsï¼šhttps://arxiv.org/abs/2403.05139</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒå¼è™šæ‹Ÿè¯•ç©¿æ—¨åœ¨ç»™å®šæç»˜äººç‰©å’Œæœé¥°çš„ä¸¤å¹…å›¾åƒï¼Œç”Ÿæˆäººç‰©ç©¿ç€ç‰¹å®šæœé¥°çš„å›¾åƒã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰å·¥ä½œå°†åŸºäºç¤ºä¾‹çš„å›¾åƒä¿®å¤æ‰©æ•£æ¨¡å‹åº”ç”¨äºè™šæ‹Ÿè¯•ç©¿ï¼Œä¸å…¶ä»–æ–¹æ³•ï¼ˆå¦‚åŸºäº GAN çš„æ–¹æ³•ï¼‰ç›¸æ¯”ï¼Œå¯ä»¥æé«˜ç”Ÿæˆè§†è§‰æ•ˆæœçš„è‡ªç„¶æ€§ï¼Œä½†æ— æ³•ä¿ç•™æœé¥°çš„ç‰¹å¾ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæå‡ºä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ IDM-VTONï¼Œè¯¥æ¨¡å‹ä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å—å¯¹æœé¥°å›¾åƒçš„è¯­ä¹‰è¿›è¡Œç¼–ç ï¼›åœ¨ç»™å®šæ‰©æ•£æ¨¡å‹çš„åŸºæœ¬ U-Net çš„æƒ…å†µä¸‹ï¼Œ1ï¼‰ä»è§†è§‰ç¼–ç å™¨ä¸­æå–çš„é«˜çº§è¯­ä¹‰è¢«èåˆåˆ°äº¤å‰æ³¨æ„å±‚ï¼Œç„¶å 2ï¼‰ä»å¹¶è¡Œ U-Net ä¸­æå–çš„ä½çº§ç‰¹å¾è¢«èåˆåˆ°è‡ªæ³¨æ„å±‚ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼ŒIDM-VTON åœ¨å›¾åƒè´¨é‡å’Œæœé¥°ä¿çœŸåº¦æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº†è¯¥æ–¹æ³•çš„ç›®æ ‡ï¼Œå³ç”ŸæˆçœŸå®ã€ä¿çœŸä¸”å¯å®šåˆ¶çš„è™šæ‹Ÿè¯•ç©¿å›¾åƒã€‚</p></li><li><p>Methods:(1): IDM-VTONé‡‡ç”¨åŸºäºç¤ºä¾‹çš„å›¾åƒä¿®å¤æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å—å¯¹æœé¥°å›¾åƒçš„è¯­ä¹‰è¿›è¡Œç¼–ç ã€‚(2): è§†è§‰ç¼–ç å™¨æå–æœé¥°å›¾åƒçš„é«˜çº§è¯­ä¹‰ï¼Œå¹¶å°†å…¶èåˆåˆ°äº¤å‰æ³¨æ„å±‚ä¸­ã€‚(3): å¹¶è¡ŒU-Netæå–æœé¥°å›¾åƒçš„ä½çº§ç‰¹å¾ï¼Œå¹¶å°†å…¶èåˆåˆ°è‡ªæ³¨æ„å±‚ä¸­ã€‚(4): åœ¨ç»™å®šæ‰©æ•£æ¨¡å‹çš„åŸºæœ¬U-Netçš„æƒ…å†µä¸‹ï¼Œèåˆåçš„é«˜çº§è¯­ä¹‰å’Œä½çº§ç‰¹å¾è¢«ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆè¿‡ç¨‹ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œæ„ä¹‰ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ IDM-VTONï¼Œç”¨äºçœŸå®è™šæ‹Ÿè¯•ç©¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å®é™…åœºæ™¯ä¸­ã€‚æˆ‘ä»¬ç»“åˆäº†ä¸¤ä¸ªç‹¬ç«‹çš„æ¨¡å—å¯¹æœé¥°å›¾åƒè¿›è¡Œç¼–ç ï¼Œå³è§†è§‰ç¼–ç å™¨å’Œå¹¶è¡Œ U-Netï¼Œå®ƒä»¬åˆ†åˆ«æœ‰æ•ˆåœ°å¯¹åŸºæœ¬ U-Net ç¼–ç é«˜çº§è¯­ä¹‰å’Œä½çº§ç‰¹å¾ã€‚ä¸ºäº†åœ¨å®é™…åœºæ™¯ä¸­æ”¹è¿›è™šæ‹Ÿè¯•ç©¿ï¼Œæˆ‘ä»¬æå‡ºé€šè¿‡å¾®è°ƒç»™å®šä¸€å¯¹æœé¥°-äººç‰©å›¾åƒçš„ U-Net è§£ç å™¨å±‚æ¥å®šåˆ¶æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨äº†æœé¥°çš„è¯¦ç»†è‡ªç„¶è¯­è¨€æè¿°ï¼Œè¿™æœ‰åŠ©äºç”ŸæˆçœŸå®çš„è™šæ‹Ÿè¯•ç©¿å›¾åƒã€‚åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿ç•™æœé¥°ç»†èŠ‚å’Œç”Ÿæˆé«˜ä¿çœŸå›¾åƒæ–¹é¢ä¼˜äºå…ˆå‰çš„ç ”ç©¶ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å®é™…åœºæ™¯ä¸­è¿›è¡Œè™šæ‹Ÿè¯•ç©¿çš„æ½œåŠ›ã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºäº† IDM-VTONï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºçœŸå®è™šæ‹Ÿè¯•ç©¿çš„æ‰©æ•£æ¨¡å‹çš„æ–°è®¾è®¡ï¼Œç‰¹åˆ«æ˜¯åœ¨å®é™…åœºæ™¯ä¸­ã€‚ç»“åˆäº†ä¸¤ä¸ªç‹¬ç«‹çš„æ¨¡å—å¯¹æœé¥°å›¾åƒè¿›è¡Œç¼–ç ï¼Œå³è§†è§‰ç¼–ç å™¨å’Œå¹¶è¡Œ U-Netï¼Œå®ƒä»¬åˆ†åˆ«æœ‰æ•ˆåœ°å¯¹åŸºæœ¬ U-Net ç¼–ç é«˜çº§è¯­ä¹‰å’Œä½çº§ç‰¹å¾ã€‚æ€§èƒ½ï¼šåœ¨å›¾åƒè´¨é‡å’Œæœé¥°ä¿çœŸåº¦æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å·¥ä½œé‡ï¼šä¸åŸºäº GAN çš„æ–¹æ³•ç›¸æ¯”ï¼ŒåŸºäºç¤ºä¾‹çš„å›¾åƒä¿®å¤æ‰©æ•£æ¨¡å‹é€šå¸¸å…·æœ‰æ›´é«˜çš„è®¡ç®—æˆæœ¬ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-d38c4cb395c666b5e4fd3e52269fff3f.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-d67b069f37d9810aa657e9e7dd415a5a.jpg" align="middle"></details><h2 id="ELLA-Equip-Diffusion-Models-with-LLM-for-Enhanced-Semantic-Alignment"><a href="#ELLA-Equip-Diffusion-Models-with-LLM-for-Enhanced-Semantic-Alignment" class="headerlink" title="ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment"></a>ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment</h2><p><strong>Authors:Xiwei Hu, Rui Wang, Yixiao Fang, Bin Fu, Pei Cheng, Gang Yu</strong></p><p>Diffusion models have demonstrated remarkable performance in the domain of text-to-image generation. However, most widely used models still employ CLIP as their text encoder, which constrains their ability to comprehend dense prompts, encompassing multiple objects, detailed attributes, complex relationships, long-text alignment, etc. In this paper, we introduce an Efficient Large Language Model Adapter, termed ELLA, which equips text-to-image diffusion models with powerful Large Language Models (LLM) to enhance text alignment without training of either U-Net or LLM. To seamlessly bridge two pre-trained models, we investigate a range of semantic alignment connector designs and propose a novel module, the Timestep-Aware Semantic Connector (TSC), which dynamically extracts timestep-dependent conditions from LLM. Our approach adapts semantic features at different stages of the denoising process, assisting diffusion models in interpreting lengthy and intricate prompts over sampling timesteps. Additionally, ELLA can be readily incorporated with community models and tools to improve their prompt-following capabilities. To assess text-to-image models in dense prompt following, we introduce Dense Prompt Graph Benchmark (DPG-Bench), a challenging benchmark consisting of 1K dense prompts. Extensive experiments demonstrate the superiority of ELLA in dense prompt following compared to state-of-the-art methods, particularly in multiple object compositions involving diverse attributes and relationships. </p><p><a href="http://arxiv.org/abs/2403.05135v1">PDF</a> Project Page: <a href="https://ella-diffusion.github.io/">https://ella-diffusion.github.io/</a></p><p><strong>Summary</strong><br>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åŠ å…¥è¯­è¨€å¤§æ¨¡å‹å¢å¼ºå™¨ ELLAï¼Œå¤§å¹…æå‡ä¸°å¯Œæç¤ºç†è§£èƒ½åŠ›ï¼Œæ— éœ€è®­ç»ƒ U å½¢ç½‘ç»œæˆ–è¯­è¨€å¤§æ¨¡å‹ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ELLA è¯­è¨€å¤§æ¨¡å‹å¢å¼ºå™¨é€šè¿‡æ— ç¼è¿æ¥ï¼Œæå‡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ–‡æœ¬å¯¹é½èƒ½åŠ›ï¼Œæ— éœ€è®­ç»ƒ U å½¢ç½‘ç»œæˆ–è¯­è¨€å¤§æ¨¡å‹ã€‚</li><li>æå‡ºæ—¶é—´æ„ŸçŸ¥è¯­ä¹‰è¿æ¥å™¨ (TSC)ï¼ŒåŠ¨æ€ä»è¯­è¨€å¤§æ¨¡å‹ä¸­æå–ä¸æ—¶é—´æ­¥é•¿ç›¸å…³çš„æ¡ä»¶ã€‚</li><li>åœ¨å»å™ªè¿‡ç¨‹çš„ä¸åŒé˜¶æ®µï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´è¯­ä¹‰ç‰¹å¾ï¼Œå¸®åŠ©æ‰©æ•£æ¨¡å‹éšç€é‡‡æ ·æ—¶é—´æ­¥é•¿è§£é‡Šå†—é•¿å¤æ‚æç¤ºã€‚</li><li>ELLA å¯ä»¥è½»æ¾ä¸ç¤¾åŒºæ¨¡å‹å’Œå·¥å…·é›†æˆï¼Œæå‡å…¶æç¤ºéµå¾ªèƒ½åŠ›ã€‚</li><li>å¼•å…¥å¯†é›†æç¤ºå›¾åŸºå‡† (DPG-Bench)ï¼Œç”¨äºè¯„ä¼°æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨å¯†é›†æç¤ºéµå¾ªæ–¹é¢çš„è¡¨ç°ã€‚</li><li>å¹¿æ³›å®éªŒéªŒè¯äº† ELLA åœ¨å¯†é›†æç¤ºéµå¾ªæ–¹é¢çš„ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤šç§å±æ€§å’Œå…³ç³»çš„å¤šå¯¹è±¡ç»„åˆä¸­ã€‚</li><li>ELLA åœ¨ä¿æŒç”Ÿæˆå›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œæå‡äº†å®šé‡å’Œå®šæ€§è¯„ä¼°çš„æ–‡æœ¬å¯¹é½åˆ†æ•°ã€‚</li><li>ELLA å°†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸è¯­è¨€å¤§æ¨¡å‹ç›¸ç»“åˆï¼Œæ¢ç´¢äº†æ–‡æœ¬å’Œå›¾åƒç”Ÿæˆä¹‹é—´çš„æ½œåœ¨è”ç³»ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>è®ºæ–‡æ ‡é¢˜ï¼šELLAï¼šä½¿ç”¨ LLM ä¸ºæ‰©æ•£æ¨¡å‹èµ‹èƒ½ä»¥å¢å¼ºè¯­ä¹‰å¯¹é½</li><li>ä½œè€…ï¼šèƒ¡é”¡å¨ã€ç‹ç‘ã€æ–¹ä¸€æ™“ã€ä»˜æ–Œã€ç¨‹åŸ¹ã€äºé’¢</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè…¾è®¯</li><li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€å¤§è¯­è¨€æ¨¡å‹ã€æ–‡æœ¬-å›¾åƒå¯¹é½</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://ella-diffusion.github.ioï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°å¹¿æ³›ä½¿ç”¨çš„æ¨¡å‹ä»ç„¶ä½¿ç”¨ CLIP ä½œä¸ºå…¶æ–‡æœ¬ç¼–ç å™¨ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬ç†è§£åŒ…å«å¤šä¸ªå¯¹è±¡ã€è¯¦ç»†å±æ€§ã€å¤æ‚å…³ç³»ã€é•¿æ–‡æœ¬å¯¹é½ç­‰å†…å®¹çš„å¯†é›†æç¤ºçš„èƒ½åŠ›ã€‚ï¼ˆ2ï¼‰å·²æœ‰æ–¹æ³•åŠé—®é¢˜ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº† ELLAï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹é€‚é…å™¨ï¼Œå®ƒä¸ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹é…å¤‡äº†å¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ (LLM)ï¼Œä»¥å¢å¼ºæ–‡æœ¬å¯¹é½ï¼Œè€Œæ— éœ€è®­ç»ƒ U-Net æˆ– LLMã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†æ— ç¼æ¡¥æ¥ä¸¤ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œæœ¬æ–‡ç ”ç©¶äº†ä¸€ç³»åˆ—è¯­ä¹‰å¯¹é½è¿æ¥å™¨è®¾è®¡ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ¨¡å—ï¼Œå³ TimeStep-Aware è¯­ä¹‰è¿æ¥å™¨ (TSC)ï¼Œå®ƒåŠ¨æ€åœ°ä» LLM ä¸­æå–ä¸æ—¶é—´æ­¥é•¿ç›¸å…³çš„æ¡ä»¶ã€‚ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å¯†é›†æç¤ºè·Ÿéšä»»åŠ¡ä¸­å±•ç¤ºäº†ä¼˜äºæœ€å…ˆè¿›æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠä¸åŒå±æ€§å’Œå…³ç³»çš„å¤šä¸ªå¯¹è±¡ç»„åˆä¸­ã€‚</li></ol><p>7.æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šè®¾è®¡ELLAæ¶æ„ï¼Œåˆ©ç”¨LLMçš„è¯­è¨€ç†è§£èƒ½åŠ›å’Œæ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆæ½œåŠ›ï¼Œé‡‡ç”¨TimeStep-Awareè¯­ä¹‰è¿æ¥å™¨ï¼ˆTSCï¼‰æ— ç¼è¿æ¥ä¸¤ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼›ï¼ˆ2ï¼‰ï¼šæ„å»ºæ•°æ®é›†ï¼Œé‡‡ç”¨CogVLMè‡ªåŠ¨ç”Ÿæˆå›¾åƒæè¿°ï¼Œæé«˜å›¾åƒä¸æ–‡æœ¬çš„ç›¸å…³æ€§å’Œè¯­ä¹‰ä¿¡æ¯çš„å¯†åº¦ï¼›ï¼ˆ3ï¼‰ï¼šæ„å»ºåŸºå‡†æµ‹è¯•ï¼Œæå‡ºå¯†é›†æç¤ºå›¾è°±åŸºå‡†ï¼ˆDPG-Benchï¼‰ï¼Œæä¾›æ›´é•¿ã€æ›´å…·ä¿¡æ¯é‡çš„æç¤ºï¼Œå…¨é¢è¯„ä¼°ç”Ÿæˆæ¨¡å‹éµå¾ªå¯†é›†æç¤ºçš„èƒ½åŠ›ã€‚</p><p>8.ç»“è®ºï¼š(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹é€‚é…å™¨ELLAï¼Œè¯¥é€‚é…å™¨é€šè¿‡TimeStep-Awareè¯­ä¹‰è¿æ¥å™¨å°†å¤§è¯­è¨€æ¨¡å‹ä¸æ‰©æ•£æ¨¡å‹æ— ç¼è¿æ¥ï¼Œå¢å¼ºäº†æ–‡æœ¬å¯¹é½ï¼Œåœ¨å¯†é›†æç¤ºè·Ÿéšä»»åŠ¡ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚(2): åˆ›æ–°ç‚¹ï¼š* æå‡ºäº†ä¸€ç§æ–°çš„è¯­ä¹‰å¯¹é½è¿æ¥å™¨TSCï¼ŒåŠ¨æ€åœ°ä»å¤§è¯­è¨€æ¨¡å‹ä¸­æå–ä¸æ—¶é—´æ­¥é•¿ç›¸å…³çš„æ¡ä»¶ï¼Œå¢å¼ºäº†æ–‡æœ¬å’Œå›¾åƒä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚* æ„å»ºäº†å¯†é›†æç¤ºå›¾è°±åŸºå‡†DPG-Benchï¼Œæä¾›æ›´é•¿ã€æ›´å…·ä¿¡æ¯é‡çš„æç¤ºï¼Œå…¨é¢è¯„ä¼°ç”Ÿæˆæ¨¡å‹éµå¾ªå¯†é›†æç¤ºçš„èƒ½åŠ›ã€‚* é‡‡ç”¨CogVLMè‡ªåŠ¨ç”Ÿæˆå›¾åƒæè¿°ï¼Œæé«˜å›¾åƒä¸æ–‡æœ¬çš„ç›¸å…³æ€§å’Œè¯­ä¹‰ä¿¡æ¯çš„å¯†åº¦ã€‚æ€§èƒ½ï¼š* åœ¨å¯†é›†æç¤ºè·Ÿéšä»»åŠ¡ä¸­ï¼ŒELLAåœ¨ç”Ÿæˆå›¾åƒçš„è¯­ä¹‰å¯¹é½å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚å·¥ä½œé‡ï¼š* ELLAçš„è®­ç»ƒå’Œéƒ¨ç½²ç›¸å¯¹é«˜æ•ˆï¼Œä¸éœ€è¦è®­ç»ƒU-Netæˆ–å¤§è¯­è¨€æ¨¡å‹ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-4cf50b2bd0a34d7b9b26b53c13b5a923.jpg" align="middle"><img src="https://picx.zhimg.com/v2-fc587ddf93c75ebf159a0c6b73925633.jpg" align="middle"><img src="https://pica.zhimg.com/v2-a0b7496441cb8c23d5d6a09243c13c67.jpg" align="middle"></details>## CogView3: Finer and Faster Text-to-Image Generation via Relay Diffusion**Authors:Wendi Zheng, Jiayan Teng, Zhuoyi Yang, Weihan Wang, Jidong Chen, Xiaotao Gu, Yuxiao Dong, Ming Ding, Jie Tang**Recent advancements in text-to-image generative systems have been largely driven by diffusion models. However, single-stage text-to-image diffusion models still face challenges, in terms of computational efficiency and the refinement of image details. To tackle the issue, we propose CogView3, an innovative cascaded framework that enhances the performance of text-to-image diffusion. CogView3 is the first model implementing relay diffusion in the realm of text-to-image generation, executing the task by first creating low-resolution images and subsequently applying relay-based super-resolution. This methodology not only results in competitive text-to-image outputs but also greatly reduces both training and inference costs. Our experimental results demonstrate that CogView3 outperforms SDXL, the current state-of-the-art open-source text-to-image diffusion model, by 77.0\% in human evaluations, all while requiring only about 1/2 of the inference time. The distilled variant of CogView3 achieves comparable performance while only utilizing 1/10 of the inference time by SDXL. [PDF](http://arxiv.org/abs/2403.05121v1) **Summary**CogView3ï¼Œä¸€ä¸ªçº§è”æ¡†æ¶ï¼Œå¼•å…¥æ¥åŠ›æ‰©æ•£ï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­å®ç°ä½åˆ†è¾¨ç‡åˆ°é«˜åˆ†è¾¨ç‡ï¼Œæé«˜æ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚**Key Takeaways**- CogView3æå‡ºçº§è”æ¡†æ¶ï¼Œä½¿ç”¨æ¥åŠ›æ‰©æ•£ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚- æ¥åŠ›æ‰©æ•£åˆ†æ­¥ç”Ÿæˆå›¾åƒï¼Œä»ä½åˆ†è¾¨ç‡åˆ°é«˜åˆ†è¾¨ç‡ï¼Œé™ä½è®­ç»ƒå’Œæ¨ç†æˆæœ¬ã€‚- CogView3è¶…è¶ŠSDXLï¼Œäººç±»è¯„ä¼°å¾—åˆ†é«˜å‡º77.0%ï¼Œæ¨ç†æ—¶é—´å‡å°‘ä¸€åŠã€‚- CogView3çš„ç²¾ç®€ç‰ˆæ€§èƒ½ç›¸å½“ï¼Œæ¨ç†æ—¶é—´ä»…ä¸ºSDXLçš„ååˆ†ä¹‹ä¸€ã€‚- CogView3æé«˜äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡çš„æ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚- CogView3 å¼•å…¥äº†æ¥åŠ›æ‰©æ•£çš„æ¦‚å¿µï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­å®ç°äº†åˆ†è¾¨ç‡çš„æ¸è¿›æå‡ã€‚- çº§è”æ¡†æ¶å’Œæ¥åŠ›æ‰©æ•£çš„ç»“åˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¹³è¡¡å›¾åƒè´¨é‡å’Œè®¡ç®—æˆæœ¬ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šCogView3ï¼šæ›´ç²¾ç»†ã€æ›´å¿«é€Ÿçš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ</li><li>ä½œè€…ï¼šWendi Zheng, Jiayan Teng, Zhuoyi Yang, Weihan Wang, Jidong Chen, Xiaotao Gu, Yuxiao Dong, Ming Ding, Jie Tang</li><li>å•ä½ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”ŸæˆÂ·æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05121</li><li><p>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹å·²æˆä¸ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿçš„ä¸»æµæ¡†æ¶ã€‚ç„¶è€Œï¼Œå•é˜¶æ®µæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨è®¡ç®—æ•ˆç‡å’Œå›¾åƒç»†èŠ‚ç²¾ç»†åŒ–æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚(2) è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å¤§å¤šåœ¨é«˜å›¾åƒåˆ†è¾¨ç‡ä¸‹è¿›è¡Œæ‰©æ•£è¿‡ç¨‹ï¼Œè¿™å¯¼è‡´è®¡ç®—æˆæœ¬é«˜ã€å›¾åƒç»†èŠ‚ä¸å¤Ÿç²¾ç»†ã€‚(3) æå‡ºæ–¹æ³•ï¼šæœ¬æ–‡æå‡º CogView3ï¼Œä¸€ä¸ªåˆ›æ–°çš„çº§è”æ¡†æ¶ï¼Œé€šè¿‡ä¸­ç»§æ‰©æ•£æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£çš„æ€§èƒ½ã€‚CogView3 æ˜¯ç¬¬ä¸€ä¸ªåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå®ç°ä¸­ç»§æ‰©æ•£çš„æ¨¡å‹ï¼Œå®ƒé€šè¿‡é¦–å…ˆåˆ›å»ºä½åˆ†è¾¨ç‡å›¾åƒï¼Œç„¶ååº”ç”¨åŸºäºä¸­ç»§çš„è¶…åˆ†è¾¨ç‡æ¥æ‰§è¡Œä»»åŠ¡ã€‚(4) å®éªŒç»“æœï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒCogView3 åœ¨äººç±»è¯„ä¼°ä¸­æ¯”å½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ SDXL é«˜å‡º 77.0%ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´ä»…ä¸ºå…¶ä¸€åŠå·¦å³ã€‚CogView3 çš„è’¸é¦å˜ä½“åœ¨æ¨ç†æ—¶é—´ä»…ä¸º SDXL çš„ 1/10 çš„æƒ…å†µä¸‹å®ç°äº†å¯æ¯”çš„æ€§èƒ½ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰æ–‡æœ¬é¢„å¤„ç†å›¾åƒé‡è¿°ï¼šåˆ©ç”¨ GPT-4V è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®é›†å›¾åƒçš„é‡è¿°æ–‡æœ¬ï¼Œå¹¶å¾®è°ƒ CogVLM-17B ä»¥è·å¾—é‡è¿°æ¨¡å‹ï¼›ï¼ˆ2ï¼‰æç¤ºæ‰©å±•ï¼šåˆ©ç”¨è¯­è¨€æ¨¡å‹å°†ç”¨æˆ·æç¤ºæ‰©å±•ä¸ºæ›´å…¨é¢çš„æè¿°ï¼Œä»¥å‡å°‘è®­ç»ƒå’Œæ¨ç†ä¹‹é—´çš„ä¸ä¸€è‡´ï¼›ï¼ˆ3ï¼‰æ¨¡å‹æ„å»ºï¼šCogView3 é‡‡ç”¨ 3 çº§ UNet æ¶æ„çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨é¢„è®­ç»ƒçš„ T5-XXL ç¼–ç å™¨ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼›ï¼ˆ4ï¼‰è®­ç»ƒç®¡é“ï¼šä½¿ç”¨ Laion-2B æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå¹¶é‡‡ç”¨æ¸è¿›è®­ç»ƒç­–ç•¥ä»¥é™ä½è®­ç»ƒæˆæœ¬ï¼›ï¼ˆ5ï¼‰ä¸­ç»§è¶…åˆ†è¾¨ç‡ï¼šåœ¨æ½œåœ¨ç©ºé—´ä¸­å®ç°ä¸­ç»§è¶…åˆ†è¾¨ç‡ï¼Œä½¿ç”¨çº¿æ€§å˜æ¢ä»£æ›¿åŸå§‹çš„å±€éƒ¨æ¨¡ç³Šï¼›ï¼ˆ6ï¼‰é‡‡æ ·å™¨æ„å»ºï¼šè®¾è®¡äº†ä¸ä¸­ç»§è¶…åˆ†è¾¨ç‡ç›¸ä¸€è‡´çš„é‡‡æ ·å™¨ï¼Œå¹¶ä½¿ç”¨ DDIM èŒƒå¼è¿›è¡Œé‡‡æ ·ï¼›ï¼ˆ7ï¼‰ä¸­ç»§æ‰©æ•£çš„è’¸é¦ï¼šå°†æ¸è¿›è’¸é¦æ–¹æ³•ä¸ä¸­ç»§æ‰©æ•£æ¡†æ¶ç›¸ç»“åˆï¼Œä»¥è·å¾— CogView3 çš„è’¸é¦ç‰ˆæœ¬ã€‚</p></li><li><p>ç»“è®º(1): æœ¬å·¥ä½œæå‡ºäº† CogView3ï¼Œè¿™æ˜¯ç»§ç”µæ‰©æ•£æ¡†æ¶ä¸­ç¬¬ä¸€ä¸ªæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿã€‚CogView3 ä»¥æå¤§é™ä½çš„æ¨ç†æˆæœ¬å®ç°äº†ä¼˜è‰¯çš„ç”Ÿæˆè´¨é‡ï¼Œè¿™ä¸»è¦å½’åŠŸäºä¸­ç»§ç®¡é“ã€‚é€šè¿‡è¿­ä»£å®ç° CogView3 çš„è¶…åˆ†è¾¨ç‡é˜¶æ®µï¼Œæˆ‘ä»¬èƒ½å¤Ÿå®ç°æé«˜åˆ†è¾¨ç‡ï¼ˆå¦‚ 2048Ã—2048ï¼‰çš„é«˜è´¨é‡å›¾åƒã€‚åŒæ—¶ï¼Œéšç€æ•°æ®é‡æ–°æè¿°å’Œæç¤ºæ‰©å±•è¢«çº³å…¥æ¨¡å‹ç®¡é“ï¼Œä¸å½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼ŒCogView3 åœ¨æç¤ºç†è§£å’ŒæŒ‡ä»¤éµå¾ªæ–¹é¢å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜æ¢ç´¢äº† CogView3 çš„è’¸é¦ï¼Œå¹¶å±•ç¤ºäº†å…¶å½’åŠŸäºç»§ç”µæ‰©æ•£æ¡†æ¶çš„ç®€å•æ€§å’Œèƒ½åŠ›ã€‚åˆ©ç”¨æ¸è¿›è’¸é¦èŒƒä¾‹ï¼ŒCogView3 çš„è’¸é¦å˜ä½“å¤§å¹…å‡å°‘äº†æ¨ç†æ—¶é—´ï¼ŒåŒæ—¶ä»ä¿æŒäº†ç›¸å½“çš„æ€§èƒ½ã€‚(2): åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§æ–°çš„çº§è”æ¡†æ¶ CogView3ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä¸­ç»§æ‰©æ•£å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£çš„æ€§èƒ½ã€‚</li><li>è®¾è®¡äº†ä¸€ç§ä¸­ç»§è¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡Œè¶…åˆ†è¾¨ç‡ï¼Œå¹¶ä½¿ç”¨çº¿æ€§å˜æ¢ä»£æ›¿åŸå§‹çš„å±€éƒ¨æ¨¡ç³Šã€‚</li><li>æ¢ç´¢äº†æ•°æ®é‡æ–°æè¿°å’Œæç¤ºæ‰©å±•ï¼Œä»¥æé«˜æ¨¡å‹å¯¹æç¤ºçš„ç†è§£å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚æ€§èƒ½ï¼š</li><li>åœ¨äººç±»è¯„ä¼°ä¸­ï¼ŒCogView3 æ¯”å½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ SDXL é«˜å‡º 77.0%ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´ä»…ä¸ºå…¶ä¸€åŠå·¦å³ã€‚</li><li>CogView3 çš„è’¸é¦å˜ä½“åœ¨æ¨ç†æ—¶é—´ä»…ä¸º SDXL çš„ 1/10 çš„æƒ…å†µä¸‹å®ç°äº†å¯æ¯”çš„æ€§èƒ½ã€‚</li><li>CogView3 èƒ½å¤Ÿç”Ÿæˆæé«˜åˆ†è¾¨ç‡ï¼ˆå¦‚ 2048Ã—2048ï¼‰çš„é«˜è´¨é‡å›¾åƒã€‚å·¥ä½œé‡ï¼š</li><li>CogView3 çš„è®­ç»ƒç®¡é“ç›¸å¯¹ç®€å•ï¼Œé‡‡ç”¨æ¸è¿›è®­ç»ƒç­–ç•¥ä»¥é™ä½è®­ç»ƒæˆæœ¬ã€‚</li><li>CogView3 çš„è’¸é¦å˜ä½“è¿›ä¸€æ­¥é™ä½äº†æ¨ç†æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒäº†å¯æ¯”çš„æ€§èƒ½ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-39c07129df4e18479bf6f2000e3bd45b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3130242f65670e2f9a99c29710ffccef.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-a4b8e0b9de2b5980d7c1d4c49daded3b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3e7d124475c2a36f974604208e23b856.jpg" align="middle"></details><h2 id="Face2Diffusion-for-Fast-and-Editable-Face-Personalization"><a href="#Face2Diffusion-for-Fast-and-Editable-Face-Personalization" class="headerlink" title="Face2Diffusion for Fast and Editable Face Personalization"></a>Face2Diffusion for Fast and Editable Face Personalization</h2><p><strong>Authors:Kaede Shiohara, Toshihiko Yamasaki</strong></p><p>Face personalization aims to insert specific faces, taken from images, into pretrained text-to-image diffusion models. However, it is still challenging for previous methods to preserve both the identity similarity and editability due to overfitting to training samples. In this paper, we propose Face2Diffusion (F2D) for high-editability face personalization. The core idea behind F2D is that removing identity-irrelevant information from the training pipeline prevents the overfitting problem and improves editability of encoded faces. F2D consists of the following three novel components: 1) Multi-scale identity encoder provides well-disentangled identity features while keeping the benefits of multi-scale information, which improves the diversity of camera poses. 2) Expression guidance disentangles face expressions from identities and improves the controllability of face expressions. 3) Class-guided denoising regularization encourages models to learn how faces should be denoised, which boosts the text-alignment of backgrounds. Extensive experiments on the FaceForensics++ dataset and diverse prompts demonstrate our method greatly improves the trade-off between the identity- and text-fidelity compared to previous state-of-the-art methods. </p><p><a href="http://arxiv.org/abs/2403.05094v1">PDF</a> CVPR2024. Code: <a href="https://github.com/mapooon/Face2Diffusion">https://github.com/mapooon/Face2Diffusion</a>, Webpage:   <a href="https://mapooon.github.io/Face2DiffusionPage/">https://mapooon.github.io/Face2DiffusionPage/</a></p><p><strong>Summary</strong><br>äººè„¸ä¸ªæ€§åŒ–é€šè¿‡æ¤å…¥ä»å›¾ç‰‡è·å–çš„äººè„¸æ¥å®ç°é¢„å…ˆè®­ç»ƒçš„æ–‡è½¬å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ä»è®­ç»ƒç®¡é“ä¸­å»é™¤ä¸äººè„¸æ— å…³çš„ä¿¡æ¯æœ‰åŠ©äºæå‡ç¼–è¾‘èƒ½åŠ›ã€‚</li><li>å¤šå°ºåº¦äººè„¸ç¼–ç å™¨æä¾›äº†æ¸…æ™°åˆ†ç¦»çš„äººè„¸ç‰¹å¾ã€‚</li><li>è¡¨æƒ…æŒ‡å¯¼å°†äººè„¸è¡¨æƒ…ä¸äººè„¸èº«ä»½è¿›è¡Œåˆ†ç¦»ã€‚</li><li>ç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–å¢å¼ºæ¨¡å‹å¯¹äººè„¸å»å™ªçš„å­¦ä¹ ã€‚</li><li>è·¨æ•°æ®é›†å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æå‡äº†èº«ä»½ä¿çœŸåº¦ä¸æ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´çš„å¹³è¡¡ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šFace2Diffusionï¼šå¿«é€Ÿä¸”å¯ç¼–è¾‘çš„äººè„¸ä¸ªæ€§åŒ–</li><li>ä½œè€…ï¼šKaede Shiohara, Toshihiko Yamasaki</li><li>å•ä½ï¼šä¸œäº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šFace personalization, Text-to-image diffusion model, Identity preservation, Editability</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05094</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å°†ç‰¹å®šäººè„¸æ’å…¥é¢„è®­ç»ƒæ¨¡å‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œæ—¢è¦ä¿æŒèº«ä»½ç›¸ä¼¼æ€§ï¼Œåˆè¦ä¿è¯å¯ç¼–è¾‘æ€§ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•å®¹æ˜“è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ ·æœ¬ï¼Œå¯¼è‡´èº«ä»½ç›¸ä¼¼æ€§å’Œå¯ç¼–è¾‘æ€§ä¹‹é—´çš„æƒè¡¡ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šFace2Diffusionï¼ˆF2Dï¼‰é€šè¿‡ä»è®­ç»ƒç®¡é“ä¸­å»é™¤ä¸èº«ä»½æ— å…³çš„ä¿¡æ¯æ¥è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œæé«˜ç¼–ç äººè„¸çš„å¯ç¼–è¾‘æ€§ã€‚F2DåŒ…å«ä¸‰ä¸ªæ–°é¢–çš„ç»„ä»¶ï¼šå¤šå°ºåº¦èº«ä»½ç¼–ç å™¨ã€è¡¨æƒ…å¼•å¯¼å™¨å’Œç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–ã€‚ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šåœ¨ FaceForensics++ æ•°æ®é›†å’Œå„ç§æç¤ºä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒF2D åœ¨èº«ä»½å’Œæ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡æ–¹é¢æ˜æ˜¾ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) å¤šå°ºåº¦èº«ä»½ç¼–ç å™¨ï¼šä»äººè„¸å›¾åƒä¸­æå–å¤šå°ºåº¦ç‰¹å¾ï¼Œä¿ç•™èº«ä»½ä¿¡æ¯ï¼Œé™ä½è¿‡åº¦æ‹Ÿåˆé£é™©ã€‚(2) è¡¨æƒ…å¼•å¯¼å™¨ï¼šæŒ‡å¯¼æ‰©æ•£æ¨¡å‹å…³æ³¨äººè„¸è¡¨æƒ…çš„ç¼–è¾‘ï¼Œæé«˜å¯ç¼–è¾‘æ€§ã€‚(3) ç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–ï¼šå¼•å…¥ç±»åˆ«ä¿¡æ¯ï¼Œé˜²æ­¢æ¨¡å‹ä»æ— å…³å™ªå£°ä¸­å­¦ä¹ ï¼Œæé«˜èº«ä»½ä¿çœŸåº¦ã€‚</p></li></ol><p><strong>8. ç»“è®º</strong></p><p><strong>(1): æ­¤é¡¹å·¥ä½œçš„æ„ä¹‰</strong></p><p>Face2Diffusion æå‡ºäº†ä¸€ç§å¯ç¼–è¾‘çš„äººè„¸ä¸ªæ€§åŒ–æ–¹æ³•ï¼Œé€šè¿‡è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œæé«˜äº†ç”Ÿæˆäººè„¸çš„å¯ç¼–è¾‘æ€§ï¼Œåœ¨èº«ä»½ä¿çœŸåº¦å’Œæ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</p><p><strong>(2): æœ¬æ–‡ä¼˜ç¼ºç‚¹æ€»ç»“ï¼ˆä¸‰ä¸ªç»´åº¦ï¼šåˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡ï¼‰</strong></p><p><strong>åˆ›æ–°ç‚¹ï¼š</strong></p><ul><li>å¤šå°ºåº¦èº«ä»½ç¼–ç å™¨ï¼šæå–å¤šå°ºåº¦ç‰¹å¾ï¼Œé™ä½è¿‡åº¦æ‹Ÿåˆé£é™©ã€‚</li><li>è¡¨æƒ…å¼•å¯¼å™¨ï¼šæŒ‡å¯¼æ‰©æ•£æ¨¡å‹å…³æ³¨äººè„¸è¡¨æƒ…çš„ç¼–è¾‘ã€‚</li><li>ç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–ï¼šé˜²æ­¢æ¨¡å‹ä»æ— å…³å™ªå£°ä¸­å­¦ä¹ ã€‚</li></ul><p><strong>æ€§èƒ½ï¼š</strong></p><ul><li>åœ¨èº«ä»½ä¿çœŸåº¦å’Œæ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</li><li>åœ¨å„ç§æç¤ºå’Œäººè„¸æ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li></ul><p><strong>å·¥ä½œé‡ï¼š</strong></p><ul><li>è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤šå°ºåº¦ç‰¹å¾æå–å’Œæ­£åˆ™åŒ–ç­–ç•¥ã€‚</li><li>ç”Ÿæˆå•ä¸ªå›¾åƒæ‰€éœ€çš„æ—¶é—´ä¸å…¶ä»–æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç±»ä¼¼ã€‚</li></ul><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-a4d3199be75c4ed763ad12e5fd6fd186.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-073fc885846ed7841fbefca59dc75bb8.jpg" align="middle"><img src="https://picx.zhimg.com/v2-c2c9194bd5afd5f761cca65c865fe0fb.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-b6ba7d02ff97010b563089ea86c62c6b.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-8bdf1923916c837b5df8251aa84ce58b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d5d8555605f33ef6be1a8b7ab0be10cc.jpg" align="middle"><img src="https://picx.zhimg.com/v2-302c4a1ee77cbdfd8dba69c7d6a94497.jpg" align="middle"></details>## Spectrum Translation for Refinement of Image Generation (STIG) Based on   Contrastive Learning and Spectral Filter Profile**Authors:Seokjun Lee, Seung-Won Jung, Hyunseok Seo**Currently, image generation and synthesis have remarkably progressed with generative models. Despite photo-realistic results, intrinsic discrepancies are still observed in the frequency domain. The spectral discrepancy appeared not only in generative adversarial networks but in diffusion models. In this study, we propose a framework to effectively mitigate the disparity in frequency domain of the generated images to improve generative performance of both GAN and diffusion models. This is realized by spectrum translation for the refinement of image generation (STIG) based on contrastive learning. We adopt theoretical logic of frequency components in various generative networks. The key idea, here, is to refine the spectrum of the generated image via the concept of image-to-image translation and contrastive learning in terms of digital signal processing. We evaluate our framework across eight fake image datasets and various cutting-edge models to demonstrate the effectiveness of STIG. Our framework outperforms other cutting-edges showing significant decreases in FID and log frequency distance of spectrum. We further emphasize that STIG improves image quality by decreasing the spectral anomaly. Additionally, validation results present that the frequency-based deepfake detector confuses more in the case where fake spectrums are manipulated by STIG. [PDF](http://arxiv.org/abs/2403.05093v1) Accepted to AAAI 2024**Summary**ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹ä¸­é¢‘åŸŸå·®å¼‚é—®é¢˜ï¼Œå¯é€šè¿‡é¢‘è°±å¯¹æ¯”å­¦ä¹ ä¸‹çš„å›¾åƒç”Ÿæˆè°±è½¬æ¢æ¡†æ¶ï¼ˆSTIGï¼‰æœ‰æ•ˆè§£å†³ã€‚**Key Takeaways*** æå‡ºSTIGæ¡†æ¶å‡è½»ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹å›¾åƒé¢‘åŸŸå·®å¼‚ã€‚* STIGåŸºäºå›¾åƒåˆ°å›¾åƒè½¬æ¢å’Œå¯¹ç…§å­¦ä¹ ï¼Œä¼˜åŒ–ç”Ÿæˆå›¾åƒé¢‘è°±ã€‚* STIGåœ¨å…«ä¸ªä¼ªé€ å›¾åƒæ•°æ®é›†ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæ˜¾ç€é™ä½FIDå’Œå…‰è°±çš„å¯¹æ•°é¢‘ç‡è·ç¦»ã€‚* STIGé€šè¿‡å‡å°å…‰è°±å¼‚å¸¸æé«˜å›¾åƒè´¨é‡ã€‚* ç»è¿‡STIGå¤„ç†çš„ä¼ªé€ å›¾åƒä¼šè¿·æƒ‘åŸºäºé¢‘ç‡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨ã€‚* STIGä½¿ç”¨é¢‘è°±è½¬æ¢æœ‰æ•ˆè§£å†³ç”Ÿæˆæ¨¡å‹ä¸­é¢‘åŸŸå·®å¼‚é—®é¢˜ã€‚* STIGæå‡å›¾åƒç”Ÿæˆè´¨é‡ï¼Œå¢å¼ºå¯¹æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨çš„é²æ£’æ€§ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šå›¾åƒç”Ÿæˆç²¾ç‚¼çš„å…‰è°±è½¬æ¢ï¼ˆSTIGï¼‰</li><li>ä½œè€…ï¼šSeokjun Leeã€Seung-Won Jungã€Hyunseok Seo</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯ç ”ç©¶é™¢ç”Ÿç‰©åŒ»å­¦ç ”ç©¶éƒ¨</li><li>å…³é”®è¯ï¼šå›¾åƒç”Ÿæˆã€å…‰è°±è½¬æ¢ã€å¯¹æ¯”å­¦ä¹ ã€é¢‘è°±æ»¤æ³¢å™¨è½®å»“</li><li>è®ºæ–‡é“¾æ¥ï¼šNoneGithub ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç›®å‰ï¼Œå›¾åƒç”Ÿæˆå’Œåˆæˆåœ¨ç”Ÿæˆæ¨¡å‹çš„å¸®åŠ©ä¸‹å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚å°½ç®¡ç”Ÿæˆç»“æœé€¼çœŸï¼Œä½†åœ¨é¢‘åŸŸä¸­ä»ç„¶å­˜åœ¨å›ºæœ‰çš„å·®å¼‚ã€‚è¿™ç§é¢‘è°±å·®å¼‚ä¸ä»…å‡ºç°åœ¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä¸­ï¼Œè¿˜å‡ºç°åœ¨æ‰©æ•£æ¨¡å‹ä¸­ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€çš„ç ”ç©¶æå‡ºäº†é€šè¿‡ä¿®æ”¹ç”Ÿæˆç½‘ç»œæ¶æ„æˆ–ç›®æ ‡å‡½æ•°æ¥å¼¥è¡¥é¢‘åŸŸå·®å¼‚çš„æ–¹æ³•ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´ã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„å…‰è°±è½¬æ¢æ¡†æ¶ï¼ˆSTIGï¼‰ï¼Œç”¨äºæœ‰æ•ˆå‡è½»ç”Ÿæˆå›¾åƒé¢‘åŸŸä¸­çš„å·®å¼‚ï¼Œä»¥æé«˜ GAN å’Œæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ€§èƒ½ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†æ•°å­—ä¿¡å·å¤„ç†ä¸­å›¾åƒåˆ°å›¾åƒè½¬æ¢å’Œå¯¹æ¯”å­¦ä¹ çš„æ¦‚å¿µæ¥ä¼˜åŒ–ç”Ÿæˆå›¾åƒçš„å…‰è°±ã€‚ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨å…«ä¸ªå‡å›¾åƒæ•°æ®é›†å’Œå„ç§å‰æ²¿æ¨¡å‹ä¸Šè¯„ä¼°äº† STIG çš„æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ï¼ŒSTIG ä¼˜äºå…¶ä»–å‰æ²¿æ–¹æ³•ï¼Œåœ¨ FID å’Œå…‰è°±å¯¹æ•°é¢‘ç‡è·ç¦»æ–¹é¢æœ‰æ˜¾è‘—ä¸‹é™ã€‚æ­¤å¤–ï¼ŒSTIG é€šè¿‡å‡å°‘å…‰è°±å¼‚å¸¸æ¥æé«˜å›¾åƒè´¨é‡ã€‚éªŒè¯ç»“æœè¡¨æ˜ï¼Œå½“ STIG å¤„ç†è™šå‡å…‰è°±æ—¶ï¼ŒåŸºäºé¢‘ç‡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨æ›´å®¹æ˜“æ··æ·†ã€‚</li></ol><p>7.Methodsï¼šï¼ˆ1ï¼‰STIGæ¡†æ¶æ¦‚è¿°ï¼šSTIGæ¡†æ¶ç”±ä¸‰ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼šå›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œï¼ˆI2Iï¼‰ã€å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’Œé¢‘è°±æ»¤æ³¢å™¨è½®å»“ï¼ˆSFPï¼‰ã€‚ï¼ˆ2ï¼‰å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œï¼ˆI2Iï¼‰ï¼šI2Iç½‘ç»œé‡‡ç”¨U-Netæ¶æ„ï¼Œç”¨äºå°†ç”Ÿæˆå›¾åƒä»æºé¢‘åŸŸè½¬æ¢åˆ°ç›®æ ‡é¢‘åŸŸã€‚ï¼ˆ3ï¼‰å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼šå¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°åŸºäºå›¾åƒå¯¹çš„ç›¸ä¼¼æ€§å’Œå·®å¼‚æ€§ï¼Œé€šè¿‡æœ€å¤§åŒ–ç›¸ä¼¼å›¾åƒçš„ç‰¹å¾è¡¨ç¤ºä¹‹é—´çš„ç›¸å…³æ€§ï¼ŒåŒæ—¶æœ€å°åŒ–ä¸åŒå›¾åƒçš„ç‰¹å¾è¡¨ç¤ºä¹‹é—´çš„ç›¸å…³æ€§ï¼Œæ¥ä¼˜åŒ–I2Iç½‘ç»œã€‚ï¼ˆ4ï¼‰é¢‘è°±æ»¤æ³¢å™¨è½®å»“ï¼ˆSFPï¼‰ï¼šSFPæ˜¯ä¸€ä¸ªé¢„å…ˆè®­ç»ƒçš„é¢‘è°±æ»¤æ³¢å™¨é›†åˆï¼Œç”¨äºæŒ‡å¯¼I2Iç½‘ç»œå­¦ä¹ ç›®æ ‡é¢‘åŸŸçš„ç‰¹å¾åˆ†å¸ƒã€‚ï¼ˆ5ï¼‰STIGè®­ç»ƒè¿‡ç¨‹ï¼šSTIGæ¡†æ¶çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šé¢„è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼ŒI2Iç½‘ç»œä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’ŒSFPè¿›è¡Œè®­ç»ƒã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼ŒI2Iç½‘ç»œä½¿ç”¨ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å¯¹æŠ—æ€§æŸå¤±å‡½æ•°è¿›è¡Œå¾®è°ƒã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† STIG æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç›´æ¥æ“ä½œç”Ÿæˆå›¾åƒçš„é¢‘ç‡åˆ†é‡ï¼Œåœ¨é¢‘åŸŸä¸­å‡å°‘ç”Ÿæˆå›¾åƒçš„å…‰è°±å·®å¼‚ï¼Œä»è€Œæé«˜ç”Ÿæˆæ€§èƒ½ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šSTIG æ¡†æ¶åœ¨é¢‘åŸŸä¸­ç›´æ¥æ“ä½œç”Ÿæˆå›¾åƒï¼Œä»¥å‡å°‘ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„å…‰è°±å·®å¼‚ã€‚STIG æ¡†æ¶é‡‡ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’Œé¢‘è°±æ»¤æ³¢å™¨è½®å»“ï¼Œä¼˜åŒ–å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹ã€‚STIG æ¡†æ¶å¯ä»¥æœ‰æ•ˆåœ°æé«˜ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ€§èƒ½ã€‚æ€§èƒ½ï¼šSTIG æ¡†æ¶åœ¨å…«ä¸ªå‡å›¾åƒåŸºå‡†ä¸Šå‡ä¼˜äºå…¶ä»–å‰æ²¿æ–¹æ³•ï¼Œåœ¨ FID å’Œå…‰è°±å¯¹æ•°é¢‘ç‡è·ç¦»æ–¹é¢æœ‰æ˜¾è‘—ä¸‹é™ã€‚STIG æ¡†æ¶é€šè¿‡å‡å°‘å…‰è°±å¼‚å¸¸æ¥æé«˜å›¾åƒè´¨é‡ã€‚STIG æ¡†æ¶å¤„ç†è™šå‡å…‰è°±æ—¶ï¼ŒåŸºäºé¢‘ç‡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨æ›´å®¹æ˜“æ··æ·†ã€‚å·¥ä½œé‡ï¼šSTIG æ¡†æ¶çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬é¢„è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µã€‚é¢„è®­ç»ƒé˜¶æ®µéœ€è¦å¯¹å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’Œé¢‘è°±æ»¤æ³¢å™¨è½®å»“è¿›è¡Œè®­ç»ƒã€‚å¾®è°ƒé˜¶æ®µéœ€è¦å¯¹å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œä½¿ç”¨ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å¯¹æŠ—æ€§æŸå¤±å‡½æ•°è¿›è¡Œå¾®è°ƒã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-59b9082b16c536f6e3dc82d3eedb0929.jpg" align="middle"><img src="https://picx.zhimg.com/v2-cc9ad99c3613618bd289ca6d732974f2.jpg" align="middle"><img src="https://picx.zhimg.com/v2-ed21a9f11c14097979acb60a01fc0faa.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-ee45629a830dd20e3e691c354e6c5761.jpg" align="middle"><img src="https://picx.zhimg.com/v2-82896ffced53d8bc120b544471040628.jpg" align="middle"></details><h2 id="Improving-Diffusion-Based-Generative-Models-via-Approximated-Optimal-Transport"><a href="#Improving-Diffusion-Based-Generative-Models-via-Approximated-Optimal-Transport" class="headerlink" title="Improving Diffusion-Based Generative Models via Approximated Optimal   Transport"></a>Improving Diffusion-Based Generative Models via Approximated Optimal   Transport</h2><p><strong>Authors:Daegyu Kim, Jooyoung Choi, Chaehun Shin, Uiwon Hwang, Sungroh Yoon</strong></p><p>We introduce the Approximated Optimal Transport (AOT) technique, a novel training scheme for diffusion-based generative models. Our approach aims to approximate and integrate optimal transport into the training process, significantly enhancing the ability of diffusion models to estimate the denoiser outputs accurately. This improvement leads to ODE trajectories of diffusion models with lower curvature and reduced truncation errors during sampling. We achieve superior image quality and reduced sampling steps by employing AOT in training. Specifically, we achieve FID scores of 1.88 with just 27 NFEs and 1.73 with 29 NFEs in unconditional and conditional generations, respectively. Furthermore, when applying AOT to train the discriminator for guidance, we establish new state-of-the-art FID scores of 1.68 and 1.58 for unconditional and conditional generations, respectively, each with 29 NFEs. This outcome demonstrates the effectiveness of AOT in enhancing the performance of diffusion models. </p><p><a href="http://arxiv.org/abs/2403.05069v1">PDF</a> </p><p><strong>æ‘˜è¦</strong><br>é€šè¿‡è¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯æå‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ•ˆæœï¼Œé™ä½é‡‡æ ·è¯¯å·®ï¼Œæå‡å›¾åƒè´¨é‡ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>æå‡ºè¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯ï¼Œæ”¹è¿›æ‰©æ•£æ¨¡å‹è®­ç»ƒã€‚</li><li>AOT æŠ€æœ¯å°†æœ€ä¼˜ä¼ è¾“æ•´åˆåˆ°æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼Œæå‡å»å™ªè¾“å‡ºå‡†ç¡®æ€§ã€‚</li><li>ä¼˜åŒ–åçš„æ‰©æ•£è½¨è¿¹æ›²ç‡é™ä½ï¼Œé‡‡æ ·æˆªæ–­è¯¯å·®å‡å°ã€‚</li><li>é‡‡ç”¨ AOT è®­ç»ƒï¼Œå›¾åƒè´¨é‡æå‡ï¼Œé‡‡æ ·æ­¥éª¤å‡å°‘ã€‚</li><li>æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œ27 æ¬¡è¯ºç¦å…‹åºåˆ—ï¼ˆNFEï¼‰ï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.88ï¼›29 æ¬¡ NFEï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.73ã€‚</li><li>æ¡ä»¶ç”Ÿæˆä¸­ï¼Œ29 æ¬¡ NFEï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.68ï¼›æŒ‡å¯¼åˆ¤åˆ«å™¨è®­ç»ƒï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.58ã€‚</li><li>AOT æŠ€æœ¯æœ‰æ•ˆæå‡äº†æ‰©æ•£æ¨¡å‹æ€§èƒ½ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šé€šè¿‡è¿‘ä¼¼æœ€ä¼˜ä¼ è¾“æ”¹è¿›åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹</li><li>ä½œè€…ï¼šDaegyu Kimã€Jooyoung Choiã€Chaehun Shinã€Uiwon Hwangã€Sungroh Yoon</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦–å°”å›½ç«‹å¤§å­¦æ•°æ®ç§‘å­¦ä¸äººå·¥æ™ºèƒ½å®éªŒå®¤</li><li>å…³é”®è¯ï¼šç”Ÿæˆæ¨¡å‹ã€æ‰©æ•£æ¨¡å‹ã€æœ€ä¼˜ä¼ è¾“</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05069   Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§é€šè¿‡é€æ¸å»å™ªæ¥åˆæˆå›¾åƒçš„ç”Ÿæˆæ¨¡å‹ã€‚è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ ODE è½¨è¿¹æ›²ç‡é«˜çš„é—®é¢˜ï¼Œè¿™ä¼šå½±å“å›¾åƒè´¨é‡å’Œé‡‡æ ·æ•ˆç‡ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šFlowMatching ç­‰æ–¹æ³•æå‡ºäº†ä½¿ç”¨æœ€ä¼˜ä¼ è¾“æ¥è§£å†³æ›²ç‡é—®é¢˜ï¼Œä½†ç”±äºæ‰©æ•£æ¨¡å‹çš„ç»“æ„ï¼Œç›´æ¥åº”ç”¨è¿™äº›æ–¹æ³•å­˜åœ¨è®¡ç®—æ•ˆç‡ä½çš„é—®é¢˜ã€‚</p><p>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§è¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰è®­ç»ƒæŠ€æœ¯ï¼Œå°†æœ€ä¼˜ä¼ è¾“è¿‘ä¼¼å¹¶æ•´åˆåˆ°æ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»è€Œé™ä½ ODE è½¨è¿¹çš„æ›²ç‡å’Œæˆªæ–­è¯¯å·®ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°åŠæ€§èƒ½ï¼šåœ¨ CIFAR-10 å›¾åƒæ— æ¡ä»¶å’Œæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œä¸åŸºçº¿ç ”ç©¶å’Œ EDM ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å›¾åƒè´¨é‡å’Œ NFEï¼ˆå‡½æ•°è¯„ä¼°æ¬¡æ•°ï¼‰æ–¹é¢å‡å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œæœ¬æ–‡æ–¹æ³•ä»¥ 27 NFE å®ç°äº† 1.88 çš„ FID å¾—åˆ†ï¼Œä»¥ 29 NFE å®ç°äº† 1.73 çš„ FID å¾—åˆ†ï¼›åœ¨æ¡ä»¶ç”Ÿæˆä¸­ï¼Œä»¥ 29 NFE å®ç°äº† 1.68 çš„ FID å¾—åˆ†ï¼Œä»¥ 29 NFE å®ç°äº† 1.58 çš„ FID å¾—åˆ†ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒAOT æŠ€æœ¯å¯ä»¥æœ‰æ•ˆæå‡æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</p><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶å·¥ä½œé€šè¿‡æå‡ºè¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯ï¼Œæœ‰æ•ˆé™ä½äº†æ‰©æ•£æ¨¡å‹ ODE è½¨è¿¹çš„æ›²ç‡å’Œæˆªæ–­è¯¯å·®ï¼Œä»è€Œæå‡äº†å›¾åƒç”Ÿæˆè´¨é‡å’Œé‡‡æ ·æ•ˆç‡ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºè¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯ï¼Œå°†æœ€ä¼˜ä¼ è¾“è¿‘ä¼¼å¹¶æ•´åˆåˆ°æ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé™ä½äº† ODE è½¨è¿¹çš„æ›²ç‡å’Œæˆªæ–­è¯¯å·®ã€‚</li><li>å°† AOT æŠ€æœ¯æˆåŠŸé›†æˆåˆ° Discriminator Guidanceï¼ˆDGï¼‰æ¡†æ¶ä¸­ï¼Œå±•ç¤ºäº†å…¶åœ¨æ›´å¹¿æ³›åº”ç”¨ä¸­çš„å¤šåŠŸèƒ½æ€§å’Œæ½œåŠ›ã€‚æ€§èƒ½ï¼š</li><li>åœ¨ CIFAR-10 å›¾åƒæ— æ¡ä»¶å’Œæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œä¸åŸºçº¿ç ”ç©¶å’Œ EDM ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å›¾åƒè´¨é‡å’Œ NFEï¼ˆå‡½æ•°è¯„ä¼°æ¬¡æ•°ï¼‰æ–¹é¢å‡å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚</li><li>åœ¨æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œæœ¬æ–‡æ–¹æ³•ä»¥ 27NFE å®ç°äº† 1.88 çš„ FID å¾—åˆ†ï¼Œä»¥ 29NFE å®ç°äº† 1.73 çš„ FID å¾—åˆ†ï¼›åœ¨æ¡ä»¶ç”Ÿæˆä¸­ï¼Œä»¥ 29NFE å®ç°äº† 1.68 çš„ FID å¾—åˆ†ï¼Œä»¥ 29NFE å®ç°äº† 1.58 çš„ FID å¾—åˆ†ã€‚å·¥ä½œé‡ï¼š</li><li>ä¸ EDM ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨è®­ç»ƒæˆæœ¬ä¸Šç•¥æœ‰å¢åŠ ï¼ˆ2% åˆ° 15%ï¼‰ã€‚</li><li>æœ¬æ–¹æ³•éœ€è¦ç®—æ³•æ”¹è¿›ï¼Œä»¥æ‰©å±•å…¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ç”Ÿæˆï¼ˆä¾‹å¦‚æ–‡æœ¬æŒ‡å¯¼ç”Ÿæˆï¼‰ä¸­çš„é€‚ç”¨æ€§ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-8b3484bb01610ca257b110266a789659.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a1905f26c3dd85ac5906dbc02f95a1c6.jpg" align="middle"><img src="https://picx.zhimg.com/v2-06436ae944972e738965038412bab51a.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-092c4ba972936da93fe5ca9a1e0c861e.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3004bc0c97615bac6076ff6a3cd11e53.jpg" align="middle"><img src="https://picx.zhimg.com/v2-63b88ad2349cca16dbda28634bc2b6d1.jpg" align="middle"></details><h2 id="XPSR-Cross-modal-Priors-for-Diffusion-based-Image-Super-Resolution"><a href="#XPSR-Cross-modal-Priors-for-Diffusion-based-Image-Super-Resolution" class="headerlink" title="XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution"></a>XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution</h2><p><strong>Authors:Yunpeng Qu, Kun Yuan, Kai Zhao, Qizhi Xie, Jinhua Hao, Ming Sun, Chao Zhou</strong></p><p>Diffusion-based methods, endowed with a formidable generative prior, have received increasing attention in Image Super-Resolution (ISR) recently. However, as low-resolution (LR) images often undergo severe degradation, it is challenging for ISR models to perceive the semantic and degradation information, resulting in restoration images with incorrect content or unrealistic artifacts. To address these issues, we propose a \textit{Cross-modal Priors for Super-Resolution (XPSR)} framework. Within XPSR, to acquire precise and comprehensive semantic conditions for the diffusion model, cutting-edge Multimodal Large Language Models (MLLMs) are utilized. To facilitate better fusion of cross-modal priors, a \textit{Semantic-Fusion Attention} is raised. To distill semantic-preserved information instead of undesired degradations, a \textit{Degradation-Free Constraint} is attached between LR and its high-resolution (HR) counterpart. Quantitative and qualitative results show that XPSR is capable of generating high-fidelity and high-realism images across synthetic and real-world datasets. Codes will be released at \url{<a href="https://github.com/qyp2000/XPSR}">https://github.com/qyp2000/XPSR}</a>. </p><p><a href="http://arxiv.org/abs/2403.05049v1">PDF</a> 19 pages, 7 figures</p><p><strong>Summary</strong><br>åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œç»“åˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’Œè¯­ä¹‰èåˆç­–ç•¥ï¼Œæå‡ºä¸€ç§å›¾åƒè¶…åˆ†è¾¨ç‡æ¡†æ¶XPSRï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸå’Œé€¼çœŸçš„å›¾åƒã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¼å…ˆéªŒæå‡å›¾åƒè¶…åˆ†è¾¨ç‡æ€§èƒ½ã€‚</li><li>å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æä¾›ç²¾ç¡®è¯­ä¹‰ä¿¡æ¯ã€‚</li><li>è¯­ä¹‰èåˆæ³¨æ„åŠ›ä¿ƒè¿›è·¨æ¨¡æ€å…ˆéªŒèåˆã€‚</li><li>æ— é€€åŒ–çº¦æŸæå–è¯­ä¹‰å†…å®¹ï¼Œè€Œéé€€åŒ–ä¿¡æ¯ã€‚</li><li>XPSRåœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šç”Ÿæˆé«˜è´¨é‡è¶…åˆ†è¾¨ç‡å›¾åƒã€‚</li><li>XPSRä»£ç å°†äº<a href="https://github.com/qyp2000/XPSRå‘å¸ƒã€‚">https://github.com/qyp2000/XPSRå‘å¸ƒã€‚</a></li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šXPSRï¼šç”¨äºåŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡çš„è·¨æ¨¡æ€å…ˆéªŒ</li><li>ä½œè€…ï¼šæ›²äº‘é¹ã€è¢å¤ã€èµµå‡¯ã€è°¢å¯ä¹‹ã€éƒé‡‘åã€å­™æ˜ã€å‘¨è¶…</li><li>å•ä½ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤ã€æ‰©æ•£æ¨¡å‹ã€å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05049Githubä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆISRï¼‰æ–¹æ³•å› å…¶å¼ºå¤§çš„ç”Ÿæˆå…ˆéªŒè€Œå—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å›¾åƒé€šå¸¸ä¼šé­å—ä¸¥é‡çš„é€€åŒ–ï¼Œå› æ­¤å¯¹äºISRæ¨¡å‹æ¥è¯´ï¼Œæ„ŸçŸ¥è¯­ä¹‰å’Œé€€åŒ–ä¿¡æ¯å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¯¼è‡´æ¢å¤çš„å›¾åƒå†…å®¹ä¸æ­£ç¡®æˆ–å‡ºç°ä¸çœŸå®çš„ä¼ªå½±ã€‚ï¼ˆ2ï¼‰ä»¥å¾€æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡çš„åŠ¨æœºæ˜¯è§£å†³ä¸Šè¿°é—®é¢˜ã€‚ä»¥å¾€æ–¹æ³•ä¸»è¦ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰è¿›è¡Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œä½†GANåœ¨ç”Ÿæˆé€¼çœŸçº¹ç†æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¹¶ä¸”å­˜åœ¨åˆæˆè®­ç»ƒæ•°æ®å’ŒçœŸå®ä¸–ç•Œæµ‹è¯•æ•°æ®ä¹‹é—´çš„åŸŸå·®è·é—®é¢˜ã€‚ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè·¨æ¨¡æ€å…ˆéªŒè¶…åˆ†è¾¨ç‡ï¼ˆXPSRï¼‰æ¡†æ¶ã€‚åœ¨XPSRä¸­ï¼Œåˆ©ç”¨å…ˆè¿›çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä¸ºæ‰©æ•£æ¨¡å‹è·å–å‡†ç¡®å’Œå…¨é¢çš„è¯­ä¹‰æ¡ä»¶ã€‚ä¸ºäº†ä¿ƒè¿›è·¨æ¨¡æ€å…ˆéªŒçš„æ›´å¥½èåˆï¼Œæå‡ºäº†ä¸€ç§è¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶ã€‚ä¸ºäº†æå–è¯­ä¹‰ä¿ç•™çš„ä¿¡æ¯è€Œä¸æ˜¯ä¸éœ€è¦çš„é€€åŒ–ï¼Œåœ¨LRåŠå…¶é«˜åˆ†è¾¨ç‡ï¼ˆHRï¼‰å¯¹åº”å›¾åƒä¹‹é—´é™„åŠ äº†ä¸€ä¸ªæ— é€€åŒ–çº¦æŸã€‚ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼ŒXPSRèƒ½å¤Ÿè·¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ç”Ÿæˆé«˜ä¿çœŸå’Œé«˜é€¼çœŸçš„å›¾åƒã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆè§£å†³å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­çš„æŒ‘æˆ˜ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) é‡‡ç”¨å¤§è¯­è¨€æ¨¡å‹ LLaVA è·å–å›¾åƒçš„è¯­ä¹‰å…ˆéªŒï¼ŒåŒ…æ‹¬é«˜å±‚è¯­ä¹‰å’Œä½å±‚è¯­ä¹‰ï¼›(2) ä½¿ç”¨è¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†è¯­ä¹‰å…ˆéªŒä¸ T2I æ¨¡å‹ç”Ÿæˆçš„å…ˆéªŒæœ‰æ•ˆèåˆï¼›(3) æ·»åŠ æ— é€€åŒ–çº¦æŸï¼Œä» LR å›¾åƒä¸­æå–è¯­ä¹‰ä¿ç•™ä½†ä¸é€€åŒ–æ— å…³çš„ä¿¡æ¯ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºçš„ XPSR æ¡†æ¶è§£å†³äº†åŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡æ¨¡å‹åœ¨å‡†ç¡®æ¢å¤è¯­ä¹‰ç»†èŠ‚æ–¹é¢çš„éš¾é¢˜ï¼Œä¸ºå›¾åƒè¶…åˆ†è¾¨ç‡é¢†åŸŸæä¾›äº†æ–°çš„æ€è·¯ã€‚ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹æ€»ç»“ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºè·¨æ¨¡æ€å…ˆéªŒæ¦‚å¿µï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸ºæ‰©æ•£æ¨¡å‹æä¾›å‡†ç¡®å…¨é¢çš„è¯­ä¹‰æ¡ä»¶ã€‚</li><li>è®¾è®¡è¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰æ•ˆèåˆè¯­ä¹‰å…ˆéªŒå’Œ T2I æ¨¡å‹ç”Ÿæˆçš„å…ˆéªŒã€‚</li><li>å¼•å…¥æ— é€€åŒ–çº¦æŸï¼Œä»ä½åˆ†è¾¨ç‡å›¾åƒä¸­æå–è¯­ä¹‰ä¿ç•™ä½†ä¸é€€åŒ–æ— å…³çš„ä¿¡æ¯ã€‚æ€§èƒ½ï¼š</li><li>å®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼ŒXPSR èƒ½å¤Ÿè·¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ç”Ÿæˆé«˜ä¿çœŸå’Œé«˜é€¼çœŸçš„å›¾åƒã€‚</li><li>ä¸å…¶ä»–å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼ŒXPSR åœ¨å„ç§è¯„ä¼°æŒ‡æ ‡ä¸Šå–å¾—äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚å·¥ä½œé‡ï¼š</li><li>XPSR æ¡†æ¶çš„å®ç°éœ€è¦ä¸€å®šçš„å·¥ä½œé‡ï¼ŒåŒ…æ‹¬è®­ç»ƒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹ã€‚</li><li>æ­¤å¤–ï¼Œè¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶å’Œæ— é€€åŒ–çº¦æŸçš„å®ç°ä¹Ÿéœ€è¦é¢å¤–çš„å¼€å‘å·¥ä½œã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-7216c617badf932e3f8d18daf0977b1f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4c7194197140a421dc8eb74d3c744901.jpg" align="middle"><img src="https://picx.zhimg.com/v2-ca3923ee7424c689775b0bb281aa1184.jpg" align="middle"></details><h2 id="DiffClass-Diffusion-Based-Class-Incremental-Learning"><a href="#DiffClass-Diffusion-Based-Class-Incremental-Learning" class="headerlink" title="DiffClass: Diffusion-Based Class Incremental Learning"></a>DiffClass: Diffusion-Based Class Incremental Learning</h2><p><strong>Authors:Zichong Meng, Jie Zhang, Changdi Yang, Zheng Zhan, Pu Zhao, Yanzhi WAng</strong></p><p>Class Incremental Learning (CIL) is challenging due to catastrophic forgetting. On top of that, Exemplar-free Class Incremental Learning is even more challenging due to forbidden access to previous task data. Recent exemplar-free CIL methods attempt to mitigate catastrophic forgetting by synthesizing previous task data. However, they fail to overcome the catastrophic forgetting due to the inability to deal with the significant domain gap between real and synthetic data. To overcome these issues, we propose a novel exemplar-free CIL method. Our method adopts multi-distribution matching (MDM) diffusion models to unify quality and bridge domain gaps among all domains of training data. Moreover, our approach integrates selective synthetic image augmentation (SSIA) to expand the distribution of the training data, thereby improving the modelâ€™s plasticity and reinforcing the performance of our methodâ€™s ultimate component, multi-domain adaptation (MDA). With the proposed integrations, our method then reformulates exemplar-free CIL into a multi-domain adaptation problem to implicitly address the domain gap problem to enhance model stability during incremental training. Extensive experiments on benchmark class incremental datasets and settings demonstrate that our method excels previous exemplar-free CIL methods and achieves state-of-the-art performance. </p><p><a href="http://arxiv.org/abs/2403.05016v1">PDF</a> Preprint</p><p><strong>Summary</strong><br>å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹åœ¨æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ ä¸­è§£å†³ç¾éš¾æ€§é—å¿˜å’Œé¢†åŸŸå·®å¼‚é—®é¢˜ï¼Œé€šè¿‡å¤šåŸŸé€‚åº”éšå¼è§£å†³é¢†åŸŸå·®å¼‚é—®é¢˜ï¼Œæé«˜æ¨¡å‹ç¨³å®šæ€§ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ç±»å¢é‡å­¦ä¹ é¢ä¸´ç¾éš¾æ€§é—å¿˜å’Œæ— ä¾‹å¯å¾ªçš„æŒ‘æˆ˜ã€‚</li><li>æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ æ–¹æ³•é€šè¿‡åˆæˆå…ˆå‰ä»»åŠ¡æ•°æ®æ¥å‡è½»ç¾éš¾æ€§é—å¿˜ã€‚</li><li>æ­¤ç±»æ–¹æ³•ç”±äºæ— æ³•å¤„ç†çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®ä¹‹é—´çš„æ˜¾ç€é¢†åŸŸå·®å¼‚è€Œæ— æ³•å…‹æœç¾éš¾æ€§é—å¿˜ã€‚</li><li>æå‡ºä¸€ç§æ–°çš„æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ æ–¹æ³•ï¼Œé‡‡ç”¨å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ç»Ÿä¸€è´¨é‡å’Œå¼¥åˆæ‰€æœ‰è®­ç»ƒæ•°æ®åŸŸä¹‹é—´çš„é¢†åŸŸå·®å¼‚ã€‚</li><li>è¯¥æ–¹æ³•é›†æˆäº†é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºï¼Œä»¥æ‰©å±•è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒã€‚</li><li>è¿™ç§æ–¹æ³•å°†æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸé€‚åº”é—®é¢˜ï¼Œä»¥éšå¼è§£å†³é¢†åŸŸå·®å¼‚é—®é¢˜ï¼Œæé«˜æ¨¡å‹åœ¨å¢é‡è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§ã€‚</li><li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå…ˆå‰çš„æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ æ–¹æ³•ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£çš„ç±»å¢é‡å­¦ä¹ </li><li>ä½œè€…ï¼šå­Ÿå­èªï¼Œå¼ æ°ï¼Œæ¨æ˜Œè¿ªï¼Œè©¹æ”¿ï¼Œèµµæ™®ï¼Œç‹å»¶ä¹‹</li><li>ä¸œåŒ—å¤§å­¦</li><li>ClassIncrementalLearningï¼ŒExemplarFreeï¼ŒDiffusionModel</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05016   Githubä»£ç é“¾æ¥ï¼šæ— </li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç±»å¢é‡å­¦ä¹ ï¼ˆCILï¼‰å› ç¾éš¾æ€§é—å¿˜è€Œæå…·æŒ‘æˆ˜æ€§ã€‚æ­¤å¤–ï¼Œç”±äºæ— æ³•è®¿é—®å…ˆå‰ä»»åŠ¡çš„æ•°æ®ï¼Œæ— ç¤ºä¾‹ CIL æ›´æ˜¯éš¾ä¸ŠåŠ éš¾ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šæœ€è¿‘çš„æ— ç¤ºä¾‹ CIL æ–¹æ³•å°è¯•é€šè¿‡åˆæˆå…ˆå‰ä»»åŠ¡æ•°æ®æ¥ç¼“è§£ç¾éš¾æ€§é—å¿˜ã€‚ç„¶è€Œï¼Œå®ƒä»¬ç”±äºæ— æ³•å¤„ç†çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®ä¹‹é—´çš„å·¨å¤§åŸŸå·®è·è€Œæ— æ³•å…‹æœç¾éš¾æ€§é—å¿˜ã€‚ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— ç¤ºä¾‹ CIL æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¤šåˆ†å¸ƒåŒ¹é… (MDM) æ‰©æ•£æ¨¡å‹æ¥å¯¹é½åˆæˆæ•°æ®çš„è´¨é‡ï¼Œå¹¶å¼¥åˆè®­ç»ƒæ•°æ®æ‰€æœ‰åŸŸä¹‹é—´çš„åŸŸå·®è·ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡çš„æ–¹æ³•é›†æˆäº†é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼º (SSIA) æ¥æ‰©å±•è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œä»è€Œæé«˜æ¨¡å‹çš„å¯å¡‘æ€§å¹¶å¢å¼ºå¤šåŸŸè‡ªé€‚åº” (MDA) æŠ€æœ¯çš„æ€§èƒ½ã€‚é€šè¿‡æå‡ºçš„é›†æˆï¼Œæœ¬æ–‡çš„æ–¹æ³•å°†æ— ç¤ºä¾‹ CIL é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸè‡ªé€‚åº”é—®é¢˜ï¼Œä»¥éšå¼è§£å†³åŸŸå·®è·é—®é¢˜å¹¶å¢å¼ºæ¨¡å‹åœ¨å¢é‡è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨åŸºå‡† CIL æ•°æ®é›†å’Œè®¾ç½®ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•ä¼˜äºä¹‹å‰çš„æ— ç¤ºä¾‹ CIL æ–¹æ³•ï¼Œå…·æœ‰éè¾¹é™…æ”¹è¿›ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ç²¾è°ƒï¼šä½¿ç”¨ LoRA ç²¾è°ƒå¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ï¼Œå¯¹é½åˆæˆæ•°æ®çš„è´¨é‡ï¼Œç¼©å°è®­ç»ƒæ•°æ®æ‰€æœ‰åŸŸä¹‹é—´çš„åŸŸå·®è·ã€‚(2) é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºï¼šé€šè¿‡é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºæ‰©å±•è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œæé«˜æ¨¡å‹çš„å¯å¡‘æ€§ï¼Œå¢å¼ºå¤šåŸŸè‡ªé€‚åº”æŠ€æœ¯çš„æ€§èƒ½ã€‚(3) å¤šåŸŸè‡ªé€‚åº”ï¼šé‡‡ç”¨å¤šåŸŸè‡ªé€‚åº”è®­ç»ƒæ–¹æ³•ï¼Œå°†æ— ç¤ºä¾‹ CIL é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸè‡ªé€‚åº”é—®é¢˜ï¼Œéšå¼è§£å†³åŸŸå·®è·é—®é¢˜ï¼Œå¢å¼ºæ¨¡å‹åœ¨å¢é‡è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§ã€‚</p></li></ol><p>8.ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„æ–°é¢–æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹å’Œé€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºæœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œå¹¶é€šè¿‡å¤šåŸŸè‡ªé€‚åº”æŠ€æœ¯å¢å¼ºäº†æ¨¡å‹çš„ç¨³å®šæ€§å’Œå¯å¡‘æ€§ï¼Œåœ¨æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š* åŸºäºå¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ï¼Œæ˜¾å¼å¼¥åˆåˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®ä¹‹é—´çš„åŸŸå·®è·ã€‚* é‡‡ç”¨é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºï¼Œæ‰©å±•è®­ç»ƒæ•°æ®åˆ†å¸ƒï¼Œæé«˜æ¨¡å‹çš„å¯å¡‘æ€§ã€‚* å°†æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸè‡ªé€‚åº”é—®é¢˜ï¼Œéšå¼è§£å†³åŸŸå·®è·é—®é¢˜ï¼Œå¢å¼ºæ¨¡å‹åœ¨å¢é‡è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§ã€‚æ€§èƒ½ï¼š* åœ¨ CIFAR100 å’Œ ImageNet100 åŸºå‡†æ•°æ®é›†ä¸Šï¼Œåœ¨å„ç§æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ è®¾ç½®ä¸­å‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚* æ¶ˆèç ”ç©¶è¯æ˜äº†æœ¬æ–‡æ–¹æ³•ä¸­æ¯ä¸ªç»„ä»¶åœ¨æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ ä¸­çš„é‡è¦æ€§ã€‚å·¥ä½œé‡ï¼š* æ¯ä¸ªå¢é‡ä»»åŠ¡çš„è®­ç»ƒæ—¶é—´ç›¸å¯¹è¾ƒé•¿ï¼Œå°¤å…¶æ˜¯ä½¿ç”¨ LoRA å¾®è°ƒç”Ÿæˆæ¨¡å‹çš„æ—¶é—´ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-3071368b15837785fc8226279a7a69f4.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-022f350905045d5945b926c68a304727.jpg" align="middle"><img src="https://picx.zhimg.com/v2-191fbfc51055a8bc7b2acc064efa3416.jpg" align="middle"><img src="https://picx.zhimg.com/v2-70ca4a001e09124d997a32d6f30da7f0.jpg" align="middle"></details>## StereoDiffusion: Training-Free Stereo Image Generation Using Latent   Diffusion Models**Authors:Lezhong Wang, Jeppe Revall Frisvad, Mark Bo Jensen, Siavash Arjomand Bigdeli**The demand for stereo images increases as manufacturers launch more XR devices. To meet this demand, we introduce StereoDiffusion, a method that, unlike traditional inpainting pipelines, is trainning free, remarkably straightforward to use, and it seamlessly integrates into the original Stable Diffusion model. Our method modifies the latent variable to provide an end-to-end, lightweight capability for fast generation of stereo image pairs, without the need for fine-tuning model weights or any post-processing of images. Using the original input to generate a left image and estimate a disparity map for it, we generate the latent vector for the right image through Stereo Pixel Shift operations, complemented by Symmetric Pixel Shift Masking Denoise and Self-Attention Layers Modification methods to align the right-side image with the left-side image. Moreover, our proposed method maintains a high standard of image quality throughout the stereo generation process, achieving state-of-the-art scores in various quantitative evaluations. [PDF](http://arxiv.org/abs/2403.04965v1) **Summary**ç«‹ä½“æ‰©æ•£ï¼šæ— è®­ç»ƒã€ç®€å•æ˜“ç”¨ï¼Œæ— ç¼é›†æˆåŸæœ‰ Stable Diffusion æ¨¡å‹ï¼Œç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ã€‚**Key Takeaways**- StereoDiffusion æ— éœ€è®­ç»ƒï¼Œä½¿ç”¨æ–¹ä¾¿ã€‚- ä¸åŸå§‹ Stable Diffusion æ¨¡å‹æ— ç¼é›†æˆã€‚- ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹æ—¶æ— éœ€å¾®è°ƒæ¨¡å‹æƒé‡æˆ–å›¾åƒåå¤„ç†ã€‚- åˆ©ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ã€‚- ä½¿ç”¨ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³å›¾åƒçš„æ½œå˜é‡ã€‚- ä½¿ç”¨å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•ã€‚- ä¿æŒç«‹ä½“ç”Ÿæˆè¿‡ç¨‹ä¸­å›¾åƒè´¨é‡çš„é«˜æ ‡å‡†ã€‚- åœ¨å„ç§å®šé‡è¯„ä¼°ä¸­å–å¾—æœ€å…ˆè¿›çš„åˆ†æ•°ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šç«‹ä½“æ‰©æ•£ï¼šåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ— è®­ç»ƒç«‹ä½“å›¾åƒç”Ÿæˆ</li><li>ä½œè€…ï¼šLezhong Wangã€Jeppe Revall Frisvadã€Mark Bo Jensenã€Siavash Arjomand Bigdeli</li><li>éš¶å±å•ä½ï¼šä¸¹éº¦æŠ€æœ¯å¤§å­¦åº”ç”¨æ•°å­¦ä¸è®¡ç®—æœºç§‘å­¦ç³»</li><li>å…³é”®è¯ï¼šXRã€æ·±åº¦å›¾åƒ/è§†é¢‘åˆæˆã€å›¾åƒç¼–è¾‘ã€äººå·¥æ™ºèƒ½ã€ä¿®å¤ã€Stable Diffusion</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.04965   Github ä»£ç é“¾æ¥ï¼šæ— </li><li><p>æ‘˜è¦ï¼š   (1)ï¼šéšç€åˆ¶é€ å•†æ¨å‡ºæ›´å¤š XR è®¾å¤‡ï¼Œå¯¹ç«‹ä½“å›¾åƒçš„éœ€æ±‚ä¸æ–­å¢åŠ ã€‚ä¸ºäº†æ»¡è¶³è¿™ä¸€éœ€æ±‚ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç«‹ä½“æ‰©æ•£ï¼Œè¿™æ˜¯ä¸€ç§ä¸ä¼ ç»Ÿä¿®å¤ç®¡é“ä¸åŒã€æ— éœ€è®­ç»ƒã€ä½¿ç”¨æå…¶ç®€å•ä¸”å¯ä¸åŸå§‹ Stable Diffusion æ¨¡å‹æ— ç¼é›†æˆçš„æŠ€æœ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¿®æ”¹äº†æ½œåœ¨å˜é‡ï¼Œæä¾›äº†ä¸€ç§ç«¯åˆ°ç«¯çš„è½»é‡çº§åŠŸèƒ½ï¼Œç”¨äºå¿«é€Ÿç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ï¼Œè€Œæ— éœ€å¾®è°ƒæ¨¡å‹æƒé‡æˆ–å¯¹å›¾åƒè¿›è¡Œä»»ä½•åå¤„ç†ã€‚æˆ‘ä»¬ä½¿ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦ä¾§å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ï¼Œé€šè¿‡ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³ä¾§å›¾åƒçš„æ½œåœ¨å‘é‡ï¼Œå¹¶è¾…ä»¥å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•ï¼Œå°†å³ä¾§å›¾åƒä¸å·¦ä¾§å›¾åƒå¯¹é½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨æ•´ä¸ªç«‹ä½“ç”Ÿæˆè¿‡ç¨‹ä¸­ä¿æŒäº†è¾ƒé«˜çš„å›¾åƒè´¨é‡æ ‡å‡†ï¼Œåœ¨å„ç§å®šé‡è¯„ä¼°ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„å¾—åˆ†ã€‚   (2)ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºå›¾åƒä¿®å¤ç®¡é“ï¼Œè¯¥ç®¡é“éœ€è¦é¢å¤–çš„æ¨¡å‹è¿›è¡Œåå¤„ç†ä»¥ç”Ÿæˆç«‹ä½“å›¾åƒã€‚è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¯¹æ¨¡å‹æƒé‡è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä¸”ç”Ÿæˆè¿‡ç¨‹å¤æ‚ä¸”è€—æ—¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä¿®æ”¹ Stable Diffusion æ¨¡å‹çš„æ½œåœ¨å˜é‡æ¥ç›´æ¥ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ï¼Œæ— éœ€é¢å¤–çš„æ¨¡å‹æˆ–åå¤„ç†ã€‚è¿™ç§æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒã€‚   (3)ï¼šæˆ‘ä»¬æå‡ºçš„æ–¹æ³•æ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„ç«‹ä½“å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œå®ƒä¿®æ”¹äº† Stable Diffusion æ¨¡å‹çš„æ½œåœ¨å˜é‡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦ä¾§å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³ä¾§å›¾åƒçš„æ½œåœ¨å‘é‡ã€‚ä¸ºäº†å¯¹é½å³ä¾§å›¾åƒå’Œå·¦ä¾§å›¾åƒï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•ã€‚   (4)ï¼šæˆ‘ä»¬åœ¨ç«‹ä½“å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šè¯„ä¼°äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§å®šé‡è¯„ä¼°ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„å¾—åˆ†ï¼ŒåŒ…æ‹¬ PSNRã€SSIM å’Œ LPIPSã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå¥½åœ°æ”¯æŒæˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³å¿«é€Ÿç”Ÿæˆæ— éœ€è®­ç»ƒçš„ç«‹ä½“å›¾åƒå¯¹ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰ä½¿ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦ä¾§å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ï¼›ï¼ˆ2ï¼‰é€šè¿‡ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³ä¾§å›¾åƒçš„æ½œåœ¨å‘é‡ï¼›ï¼ˆ3ï¼‰ä½¿ç”¨å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•å¯¹é½å³ä¾§å›¾åƒå’Œå·¦ä¾§å›¾åƒã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šç«‹ä½“æ‰©æ•£ï¼šåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ— è®­ç»ƒç«‹ä½“å›¾åƒç”Ÿæˆï¼Œè¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§é€šè¿‡ä¿®æ”¹æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨å˜é‡æ¥ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–çš„æ¨¡å‹æˆ–åå¤„ç†ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æ— éœ€è®­ç»ƒï¼šè¯¥æ–¹æ³•æ— éœ€å¯¹æ¨¡å‹æƒé‡è¿›è¡Œå¾®è°ƒï¼Œç›´æ¥ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ï¼Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹ã€‚</li><li>ç«¯åˆ°ç«¯ï¼šè¯¥æ–¹æ³•ä¿®æ”¹æ½œåœ¨å˜é‡ï¼Œæä¾›äº†ä¸€ç§ç«¯åˆ°ç«¯çš„è½»é‡çº§åŠŸèƒ½ï¼Œç”¨äºå¿«é€Ÿç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ã€‚</li><li>ä¸åŸå§‹StableDiffusionæ¨¡å‹æ— ç¼é›†æˆï¼šè¯¥æ–¹æ³•å¯ä»¥ä¸åŸå§‹StableDiffusionæ¨¡å‹æ— ç¼é›†æˆï¼Œæ— éœ€å¯¹æ¨¡å‹è¿›è¡Œä»»ä½•ä¿®æ”¹ã€‚æ€§èƒ½ï¼š</li><li>å®šé‡è¯„ä¼°ï¼šè¯¥æ–¹æ³•åœ¨KITTIå’ŒMiddleburyæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„å¾—åˆ†ï¼Œè¡¨æ˜å…¶å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒã€‚å·¥ä½œé‡ï¼š</li><li>è®¡ç®—æˆæœ¬ï¼šè¯¥æ–¹æ³•çš„è®¡ç®—æˆæœ¬è¾ƒä½ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ã€‚</li><li>å†…å­˜å ç”¨ï¼šè¯¥æ–¹æ³•çš„å†…å­˜å ç”¨è¾ƒå°ï¼Œå¯ä»¥åœ¨å„ç§è®¾å¤‡ä¸Šè¿è¡Œã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-2042e22706397759569cb6c0ac2c19fc.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-1a050df593611d8551bcd2b7e676c281.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4970b55916ca916d6716d8304932590e.jpg" align="middle"></details><h2 id="AFreeCA-Annotation-Free-Counting-for-All"><a href="#AFreeCA-Annotation-Free-Counting-for-All" class="headerlink" title="AFreeCA: Annotation-Free Counting for All"></a>AFreeCA: Annotation-Free Counting for All</h2><p><strong>Authors:Adriano Dâ€™Alessandro, Ali Mahdavi-Amiri, Ghassan Hamarneh</strong></p><p>Object counting methods typically rely on manually annotated datasets. The cost of creating such datasets has restricted the versatility of these networks to count objects from specific classes (such as humans or penguins), and counting objects from diverse categories remains a challenge. The availability of robust text-to-image latent diffusion models (LDMs) raises the question of whether these models can be utilized to generate counting datasets. However, LDMs struggle to create images with an exact number of objects based solely on text prompts but they can be used to offer a dependable \textit{sorting} signal by adding and removing objects within an image. Leveraging this data, we initially introduce an unsupervised sorting methodology to learn object-related features that are subsequently refined and anchored for counting purposes using counting data generated by LDMs. Further, we present a density classifier-guided method for dividing an image into patches containing objects that can be reliably counted. Consequently, we can generate counting data for any type of object and count them in an unsupervised manner. Our approach outperforms other unsupervised and few-shot alternatives and is not restricted to specific object classes for which counting data is available. Code to be released upon acceptance. </p><p><a href="http://arxiv.org/abs/2403.04943v1">PDF</a> </p><p><strong>Summary</strong><br>ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ (LDM) è‡ªåŠ¨ç”Ÿæˆåˆ†ç±»æ•°æ®ï¼Œç„¶åé€šè¿‡æ— ç›‘ç£å­¦ä¹ å’Œå¯†åº¦åˆ†ç±»æŒ‡å¯¼æ–¹æ³•å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œä»è€Œå®ç°ç±»åˆ«æ— å…³çš„æ— ç›‘ç£å¯¹è±¡è®¡æ•°ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>LDMs èƒ½å¤Ÿæä¾›å›¾åƒæ·»åŠ å’Œåˆ é™¤å¯¹è±¡çš„å¯é åˆ†ç±»ä¿¡å·ã€‚</li><li>åˆ©ç”¨ LDM ç”Ÿæˆçš„åˆ†ç±»æ•°æ®ï¼Œå¯ä»¥æ— ç›‘ç£åœ°å­¦ä¹ ä¸å¯¹è±¡ç›¸å…³çš„ç‰¹å¾ã€‚</li><li>é€šè¿‡è®¡æ•°æ•°æ®å¯¹ç‰¹å¾è¿›è¡Œç²¾ç‚¼å’Œé”šå®šã€‚</li><li>å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼çš„æ–¹æ³•å¯å°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„å¯¹è±¡çš„åŒºåŸŸã€‚</li><li>è¯¥æ–¹æ³•å¯ç”Ÿæˆä»»ä½•ç±»å‹å¯¹è±¡çš„è®¡æ•°æ•°æ®ï¼Œå¹¶èƒ½ä»¥æ— ç›‘ç£çš„æ–¹å¼è¿›è¡Œè®¡æ•°ã€‚</li><li>ç›¸å¯¹äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•å…·æœ‰è¾ƒå¥½çš„æ€§èƒ½ã€‚</li><li>æ— éœ€ç‰¹å®šå¯¹è±¡ç±»åˆ«å³å¯ç”Ÿæˆè®¡æ•°æ•°æ®ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šæ— æ ‡æ³¨è®¡æ•°ï¼šå¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒº</li><li>ä½œè€…ï¼šLu Qi, Minghao Chen, Junwei Han, Yu Liu, Xiang Bai, Xiaogang Wang</li><li>å•ä½ï¼šæ— </li><li>å…³é”®è¯ï¼šObjectCountingÂ·SyntheticDataÂ·Annotation-Free</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.06673   Github é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š   (1) ç ”ç©¶èƒŒæ™¯ï¼šç›®æ ‡è®¡æ•°æ–¹æ³•é€šå¸¸ä¾èµ–äºäººå·¥æ ‡æ³¨æ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†ç½‘ç»œé’ˆå¯¹ç‰¹å®šç±»åˆ«ï¼ˆå¦‚äººæˆ–ä¼é¹…ï¼‰è®¡æ•°ç›®æ ‡çš„é€šç”¨æ€§ï¼Œå¹¶ä¸”å¯¹ä¸åŒç±»åˆ«ç›®æ ‡çš„è®¡æ•°ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚   (2) è¿‡å»æ–¹æ³•ï¼šæ— ç›‘ç£ã€å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬æ–¹æ³•æ—¨åœ¨ä½¿ç”¨åŒ…å«ä¸åŒç±»åˆ«çš„å¤§å‹äººå·¥æ ‡æ³¨æ•°æ®é›†æ¥åˆ›å»ºé€‚ç”¨äºä»»ä½•ç±»åˆ«çš„é€šç”¨è®¡æ•°ç½‘ç»œã€‚å°‘æ ·æœ¬æ–¹æ³•ä¾èµ–äºä»ç›®æ ‡å›¾åƒä¸­é‡‡æ ·çš„æ ·æœ¬ä¾‹æ¥å®šä¹‰ç›®æ ‡ç±»åˆ«ï¼Œè€Œé›¶æ ·æœ¬æ–¹æ³•ä½¿ç”¨æ–‡æœ¬æç¤ºã€‚è¿™äº›æ–¹æ³•ä¾èµ–äºå¹¿æ³›çš„æ ‡æ³¨æ•°æ®é›†ï¼Œä½†   (3) æœ¬æ–‡æ–¹æ³•ï¼šåˆ©ç”¨äº†æ–‡æœ¬åˆ°å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ã€‚LDM éš¾ä»¥ä»…åŸºäºæ–‡æœ¬æç¤ºåˆ›å»ºå…·æœ‰ç²¾ç¡®æ•°é‡ç›®æ ‡çš„å›¾åƒï¼Œä½†å¯ä»¥é€šè¿‡æ·»åŠ å’Œç§»é™¤å›¾åƒä¸­çš„ç›®æ ‡æ¥æä¾›å¯é çš„æ’åºä¿¡å·ã€‚åˆ©ç”¨è¿™äº›æ•°æ®ï¼Œæœ¬æ–‡é¦–å…ˆå¼•å…¥äº†ä¸€ç§æ— ç›‘ç£æ’åºæ–¹æ³•æ¥å­¦ä¹ ç›®æ ‡ç›¸å…³ç‰¹å¾ï¼Œéšåä½¿ç”¨ LDM ç”Ÿæˆçš„è®¡æ•°æ•°æ®å¯¹è¿™äº›ç‰¹å¾è¿›è¡Œç²¾ç‚¼å’Œé”šå®šä»¥ç”¨äºè®¡æ•°ç›®çš„ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼æ–¹æ³•ï¼Œå°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„ç›®æ ‡çš„å—ã€‚å› æ­¤ï¼Œæœ¬æ–‡å¯ä»¥ä¸ºä»»ä½•ç±»å‹çš„ç›®æ ‡ç”Ÿæˆè®¡æ•°æ•°æ®å¹¶ä»¥æ— ç›‘ç£çš„æ–¹å¼å¯¹å…¶è¿›è¡Œè®¡æ•°ã€‚   (4) æ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•ä¼˜äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•ï¼Œå¹¶ä¸”ä¸å—ç‰¹å®šç›®æ ‡ç±»åˆ«çš„é™åˆ¶ï¼Œè¿™äº›ç±»åˆ«æœ‰å¯ç”¨çš„è®¡æ•°æ•°æ®ã€‚</li></ol><p>7.æ–¹æ³•ï¼š(1)ç”Ÿæˆåˆæˆæ’åºæ•°æ®ï¼Œé€šè¿‡æ·»åŠ å’Œç§»é™¤å›¾åƒä¸­çš„ç›®æ ‡ï¼Œä½¿ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰å¯¹å›¾åƒè¿›è¡Œæ’åºï¼›(2)é¢„è®­ç»ƒæ’åºç½‘ç»œï¼Œä½¿ç”¨æ’åºæŸå¤±å’Œå…³ç³»æŸå¤±ï¼Œå¯¹å›¾åƒç‰¹å¾è¿›è¡Œæ’åºï¼›(3)ä»åˆæˆæ•°æ®å­¦ä¹ è®¡æ•°ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ’åºç½‘ç»œï¼Œé€šè¿‡å¾®è°ƒçº¿æ€§å±‚ï¼Œå°†ç‰¹å¾é”šå®šåˆ°å®é™…è®¡æ•°å€¼ï¼›(4)äººç¾¤å¯†åº¦åˆ†ç±»ï¼Œä½¿ç”¨ Stable Diffusion ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå¯¹äººç¾¤å¯†åº¦è¿›è¡Œåˆ†ç±»ï¼›(5)å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒºï¼ˆDCGPï¼‰ï¼Œæ ¹æ®ä¼°è®¡çš„å¯†åº¦å¯¹å›¾åƒè¿›è¡Œåˆ†åŒºï¼Œå°†å›¾åƒå¤„ç†ä¸ºæ›´å°çš„è¡¥ä¸ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„ç›®æ ‡è®¡æ•°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ–‡æœ¬åˆ°å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ç”Ÿæˆçš„åˆæˆæ•°æ®ã€‚è¯¥æ–¹æ³•é€šè¿‡æ’åºå’Œé”šå®šå­¦ä¹ ç›®æ ‡ç›¸å…³ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒºï¼ˆDCGPï¼‰å°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„ç›®æ ‡çš„å—ã€‚è¯¥æ–¹æ³•ä¸å—ç‰¹å®šç›®æ ‡ç±»åˆ«çš„é™åˆ¶ï¼Œå¹¶ä¸”ä¼˜äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>åˆ©ç”¨LDMç”Ÿæˆåˆæˆæ’åºæ•°æ®å’Œè®¡æ•°æ•°æ®ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚</li><li>æå‡ºäº†ä¸€ç§æ— ç›‘ç£æ’åºæ–¹æ³•ï¼Œå­¦ä¹ ç›®æ ‡ç›¸å…³ç‰¹å¾ã€‚</li><li>æå‡ºäº†ä¸€ç§å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒºï¼ˆDCGPï¼‰æ–¹æ³•ï¼Œå°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„ç›®æ ‡çš„å—ã€‚æ€§èƒ½ï¼š</li><li>åœ¨PASCAL VOCã€COCOå’ŒCityscapesæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ä¼˜äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•ã€‚</li><li>è¯¥æ–¹æ³•ä¸å—ç‰¹å®šç›®æ ‡ç±»åˆ«çš„é™åˆ¶ï¼Œå¯ä»¥ä¸ºä»»ä½•ç±»å‹çš„ç›®æ ‡ç”Ÿæˆè®¡æ•°æ•°æ®å¹¶ä»¥æ— ç›‘ç£çš„æ–¹å¼å¯¹å…¶è¿›è¡Œè®¡æ•°ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•éœ€è¦ç”Ÿæˆåˆæˆæ’åºæ•°æ®å’Œè®¡æ•°æ•°æ®ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li><li>è¯¥æ–¹æ³•éœ€è¦é¢„è®­ç»ƒæ’åºç½‘ç»œå’Œå¾®è°ƒçº¿æ€§å±‚ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-0bdfaf4b65221e3f6287dfe2ed850459.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-7e6e2c7b151a6f679f9aa91c763c21aa.jpg" align="middle"><img src="https://pica.zhimg.com/v2-25087217d0ca2a3290d33e79013e2984.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-04536de3c0849a068b94d559fbfb1068.jpg" align="middle"><img src="https://picx.zhimg.com/v2-9e7e2084d668b0f9c9e859eecaa8550c.jpg" align="middle"></details><h2 id="An-Item-is-Worth-a-Prompt-Versatile-Image-Editing-with-Disentangled-Control"><a href="#An-Item-is-Worth-a-Prompt-Versatile-Image-Editing-with-Disentangled-Control" class="headerlink" title="An Item is Worth a Prompt: Versatile Image Editing with Disentangled   Control"></a>An Item is Worth a Prompt: Versatile Image Editing with Disentangled   Control</h2><p><strong>Authors:Aosong Feng, Weikang Qiu, Jinbin Bai, Kaicheng Zhou, Zhen Dong, Xiao Zhang, Rex Ying, Leandros Tassiulas</strong></p><p>Building on the success of text-to-image diffusion models (DPMs), image editing is an important application to enable human interaction with AI-generated content. Among various editing methods, editing within the prompt space gains more attention due to its capacity and simplicity of controlling semantics. However, since diffusion models are commonly pretrained on descriptive text captions, direct editing of words in text prompts usually leads to completely different generated images, violating the requirements for image editing. On the other hand, existing editing methods usually consider introducing spatial masks to preserve the identity of unedited regions, which are usually ignored by DPMs and therefore lead to inharmonic editing results. Targeting these two challenges, in this work, we propose to disentangle the comprehensive image-prompt interaction into several item-prompt interactions, with each item linked to a special learned prompt. The resulting framework, named D-Edit, is based on pretrained diffusion models with cross-attention layers disentangled and adopts a two-step optimization to build item-prompt associations. Versatile image editing can then be applied to specific items by manipulating the corresponding prompts. We demonstrate state-of-the-art results in four types of editing operations including image-based, text-based, mask-based editing, and item removal, covering most types of editing applications, all within a single unified framework. Notably, D-Edit is the first framework that can (1) achieve item editing through mask editing and (2) combine image and text-based editing. We demonstrate the quality and versatility of the editing results for a diverse collection of images through both qualitative and quantitative evaluations. </p><p><a href="http://arxiv.org/abs/2403.04880v1">PDF</a> </p><p><strong>Summary</strong><br>æ–‡æœ¬æç¤ºç¼–è¾‘å®ç°äº†å›¾åƒç¼–è¾‘ï¼Œä½†ç”±äºæ‰©æ•£æ¨¡å‹çš„é¢„è®­ç»ƒæ–¹å¼ï¼Œç›´æ¥ç¼–è¾‘æç¤ºä¸­çš„æ–‡å­—ä¼šå¯¼è‡´ç”Ÿæˆå®Œå…¨ä¸åŒçš„å›¾åƒï¼Œè¿èƒŒäº†å›¾åƒç¼–è¾‘çš„è¦æ±‚ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡ºæ–‡æœ¬æç¤ºç¼–è¾‘æ–¹æ³• D-Editã€‚</li><li>å°†å›¾åƒæç¤ºäº¤äº’åˆ†è§£ä¸ºå¤šä¸ªé¡¹ç›®æç¤ºäº¤äº’ï¼Œæ¯ä¸ªé¡¹ç›®é“¾æ¥åˆ°ä¸€ä¸ªç‰¹æ®Šå­¦ä¹ æç¤ºã€‚</li><li>é‡‡ç”¨ä¸¤æ­¥ä¼˜åŒ–æ„å»ºé¡¹ç›®æç¤ºå…³è”ã€‚</li><li>å¯è¿›è¡Œå¤šç§å›¾åƒç¼–è¾‘ï¼ŒåŒ…æ‹¬åŸºäºå›¾åƒã€åŸºäºæ–‡æœ¬ã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚</li><li>å¯ä»¥åœ¨å•ä¸ªç»Ÿä¸€æ¡†æ¶ä¸­å®ç°æ‰€æœ‰ç±»å‹çš„ç¼–è¾‘åº”ç”¨ç¨‹åºã€‚</li><li>D-Edit æ˜¯ç¬¬ä¸€ä¸ªï¼ˆ1ï¼‰é€šè¿‡æ©ç ç¼–è¾‘å®ç°é¡¹ç›®ç¼–è¾‘ï¼Œï¼ˆ2ï¼‰ç»“åˆå›¾åƒå’ŒåŸºäºæ–‡æœ¬çš„ç¼–è¾‘çš„æ¡†æ¶ã€‚</li><li>é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°ï¼Œå±•ç¤ºäº†å„ç§å›¾åƒç¼–è¾‘ç»“æœçš„è´¨é‡å’Œå¤šåŠŸèƒ½æ€§ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šAn Item is Worth a Promptï¼šå¤šåŠŸèƒ½çš„å¯æ§å›¾åƒç¼–è¾‘</li><li>ä½œè€…ï¼šAosong Feng, Weikang Qiu, Jinbin Bai, Kaicheng Zhou, Zhen Dong, Xiao Zhang, Rex Ying, Leandros Tassiulas</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè€¶é²å¤§å­¦</li><li>å…³é”®è¯ï¼šå›¾åƒç¼–è¾‘ã€æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€å¯æ§æç¤º</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.04880</li><li><p>æ‘˜è¦ï¼š(1)ï¼šåŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆæˆä¸­çš„æˆåŠŸï¼Œå›¾åƒç¼–è¾‘æˆä¸ºä¸€ç§é‡è¦çš„åº”ç”¨ç¨‹åºï¼Œå®ƒè®©äººä»¬èƒ½å¤Ÿä¸ AI ç”Ÿæˆçš„å†…å®¹è¿›è¡Œäº¤äº’ã€‚åœ¨å„ç§ç¼–è¾‘æ–¹æ³•ä¸­ï¼Œæç¤ºç©ºé—´ç¼–è¾‘å› å…¶æ§åˆ¶è¯­ä¹‰çš„èƒ½åŠ›å’Œç®€å•æ€§è€Œå—åˆ°æ›´å¤šå…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºæ‰©æ•£æ¨¡å‹é€šå¸¸åœ¨æè¿°æ€§æ–‡æœ¬æ ‡é¢˜ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå› æ­¤åœ¨æ–‡æœ¬æç¤ºä¸­ç›´æ¥ç¼–è¾‘å•è¯é€šå¸¸ä¼šå¯¼è‡´å®Œå…¨ä¸åŒçš„ç”Ÿæˆå›¾åƒï¼Œè¿åäº†å›¾åƒç¼–è¾‘çš„è¦æ±‚ã€‚å¦ä¸€æ–¹é¢ï¼Œç°æœ‰çš„ç¼–è¾‘æ–¹æ³•é€šå¸¸è€ƒè™‘å¼•å…¥ç©ºé—´æ©ç æ¥ä¿ç•™æœªç¼–è¾‘åŒºåŸŸçš„èº«ä»½ï¼Œè€Œæ‰©æ•£æ¨¡å‹é€šå¸¸ä¼šå¿½ç•¥è¿™äº›åŒºåŸŸï¼Œå› æ­¤å¯¼è‡´ä¸åè°ƒçš„ç¼–è¾‘ç»“æœã€‚(2)ï¼šé’ˆå¯¹è¿™ä¸¤ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºå°†ç»¼åˆå›¾åƒæç¤ºäº¤äº’åˆ†è§£ä¸ºå‡ ä¸ªé¡¹ç›®æç¤ºäº¤äº’ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½é“¾æ¥åˆ°ä¸€ä¸ªç‰¹æ®Šå­¦ä¹ çš„æç¤ºã€‚ç”±æ­¤äº§ç”Ÿçš„æ¡†æ¶åä¸º D-Editï¼Œå®ƒåŸºäºé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨äº¤å‰æ³¨æ„å±‚è¿›è¡Œè§£è€¦ï¼Œå¹¶é‡‡ç”¨ä¸¤æ­¥ä¼˜åŒ–æ¥æ„å»ºé¡¹ç›®æç¤ºå…³è”ã€‚é€šè¿‡æ“ä½œç›¸åº”çš„æç¤ºï¼Œå¯ä»¥å°†å¤šåŠŸèƒ½å›¾åƒç¼–è¾‘åº”ç”¨äºç‰¹å®šé¡¹ç›®ã€‚æœ¬æ–‡å±•ç¤ºäº†å››ç§ç±»å‹çš„ç¼–è¾‘æ“ä½œï¼ˆåŒ…æ‹¬åŸºäºå›¾åƒã€åŸºäºæ–‡æœ¬ã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ï¼‰çš„æœ€æ–°ç»“æœï¼Œæ¶µç›–äº†å¤§å¤šæ•°ç±»å‹çš„ç¼–è¾‘åº”ç”¨ç¨‹åºï¼Œæ‰€æœ‰è¿™äº›éƒ½é‡‡ç”¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒD-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥ (1) é€šè¿‡æ©ç ç¼–è¾‘å®ç°é¡¹ç›®ç¼–è¾‘ï¼Œä»¥åŠ (2) ç»“åˆå›¾åƒå’ŒåŸºäºæ–‡æœ¬çš„ç¼–è¾‘çš„æ¡†æ¶ã€‚é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°ï¼Œæœ¬æ–‡å±•ç¤ºäº†é’ˆå¯¹å„ç§å›¾åƒé›†åˆçš„ç¼–è¾‘ç»“æœçš„è´¨é‡å’Œå¤šåŠŸèƒ½æ€§ã€‚(3)ï¼šæœ¬æ–‡æå‡ºä¸¤ç§å…³é”®æŠ€æœ¯ï¼Œæ—¨åœ¨å¢å¼ºä¸Šè¿°æ ‡å‡†ï¼š(1) è§£è€¦æ§åˆ¶ï¼šä¸ºäº†ä¿ç•™åŸå§‹å›¾åƒçš„ä¿¡æ¯ï¼Œç›®æ ‡é¡¹ç›®çš„ç¼–è¾‘åº”å°½é‡ä¸å½±å“å‘¨å›´é¡¹ç›®ã€‚ä»æç¤ºåˆ°å›¾åƒçš„æ§åˆ¶è¿‡ç¨‹ä¹Ÿåº”è¯¥è§£è€¦ï¼Œç¡®ä¿ä¿®æ”¹é¡¹ç›®æç¤ºä¸ä¼šç ´åå…¶ä½™é¡¹ç›®çš„æ§åˆ¶æµã€‚æ³¨æ„åˆ°æ–‡æœ¬åˆ°å›¾åƒäº¤äº’å‘ç”Ÿåœ¨åŸºäºæ³¨æ„åŠ›çš„æ‰©æ•£æ¨¡å‹çš„äº¤å‰æ³¨æ„å±‚ä¸­ï¼Œæœ¬æ–‡æå‡ºåˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æç¤ºåˆ°é¡¹ç›®çš„æ§åˆ¶æµã€‚(2) å”¯ä¸€é¡¹ç›®æç¤ºï¼šä¸ºäº†æé«˜ä¸æŒ‡å¯¼çš„ä¸€è‡´æ€§ï¼ˆä¾‹å¦‚å‚è€ƒå›¾åƒï¼‰ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½åº”è¯¥ä¸ä¸€ä¸ªæ§åˆ¶å…¶ç”Ÿæˆçš„å”¯ä¸€æç¤ºç›¸å…³è”ã€‚è¿™äº›æç¤ºé€šå¸¸ç”±ç‰¹æ®Šæ ‡è®°æˆ–ç½•è§å•è¯ç»„æˆã€‚åƒ Dreambooth å’Œ Textual Inversion è¿™æ ·çš„å›¾åƒä¸ªæ€§åŒ–ç°æœ‰å·¥ä½œå·²ç»é€šè¿‡ç”¨å”¯ä¸€æç¤ºè¡¨ç¤ºæ–°ä¸»é¢˜æ¥å¹¿æ³›ç ”ç©¶äº†è¿™ä¸ªæ¦‚å¿µï¼Œéšåå°†å…¶ç”¨äºå›¾åƒç”Ÿæˆã€‚ä¸å®ƒä»¬ç›¸æ¯”ï¼Œæœ¬æ–‡ä½¿ç”¨ç‹¬ç«‹æç¤ºæ¥å®šä¹‰ä¸åŒçš„é¡¹ç›®ï¼Œè€Œä¸æ˜¯æ•´ä¸ªå›¾åƒã€‚åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼Œå¦‚æœå›¾åƒä¸­çš„æ¯ä¸ªé¡¹ç›®åŠå…¶æ‰€æœ‰ç»†èŠ‚éƒ½å¯ä»¥ç”¨ä¸€ä¸ªç‹¬ç‰¹çš„è‹±æ–‡å•è¯å‡†ç¡®æè¿°ï¼Œé‚£ä¹ˆç”¨æˆ·å¯ä»¥é€šè¿‡ç®€å•åœ°å°†å½“å‰å•è¯æ›´æ”¹ä¸ºç›®æ ‡å•è¯æ¥å®ç°æ‰€æœ‰ç±»å‹çš„ç¼–è¾‘ã€‚(4)ï¼šæœ¬æ–‡å……åˆ†åˆ©ç”¨æç¤ºå”¯ä¸€æ€§å’Œè§£è€¦æ§åˆ¶çš„æ½œåŠ›ï¼Œä»‹ç»äº†ä¸€ä¸ªå¤šåŠŸèƒ½å›¾åƒç¼–è¾‘æ¡†æ¶ï¼Œç§°ä¸º Disentangled-Edit (D-Edit)ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå¤§å¤šæ•°ç±»å‹çš„å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚å…·ä½“æ¥è¯´ï¼Œå¦‚å›¾ 1 æ‰€ç¤ºï¼Œä»ç›®æ ‡å›¾åƒå¼€å§‹ï¼Œæœ¬æ–‡æœ€åˆå°†å…¶ç»†åˆ†ä¸ºå¤šä¸ªå¯ç¼–è¾‘é¡¹ç›®ï¼ˆåœ¨ä»¥ä¸‹å†…å®¹ä¸­ï¼Œæœ¬æ–‡è¿˜å°†èƒŒæ™¯å’Œæœªåˆ†å‰²åŒºåŸŸç§°ä¸ºé¡¹ç›®ï¼‰ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½ä¸ä¸€ä¸ªåŒ…å«å‡ ä¸ªæ–°æ ‡è®°çš„æç¤ºç›¸å…³è”ã€‚æç¤ºå’Œé¡¹ç›®ä¹‹é—´çš„å…³è”æ˜¯é€šè¿‡ä¸¤æ­¥å¾®è°ƒè¿‡ç¨‹å»ºç«‹çš„ï¼Œå…¶ä¸­åŒ…æ‹¬ä¼˜åŒ–æ–‡æœ¬ç¼–ç å™¨åµŒå…¥çŸ©é˜µå’Œ UNet æ¨¡å‹æƒé‡ã€‚å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æç¤ºåˆ°é¡¹ç›®çš„äº¤äº’ï¼Œé€šè¿‡éš”ç¦»æ³¨æ„è®¡ç®—å’Œå€¼æ›´æ–°ã€‚ç„¶åï¼Œå¯ä»¥é€šè¿‡æ›´æ”¹æç¤ºã€é¡¹ç›®åŠå…¶ä¹‹é—´çš„å…³è”æ¥å®ç°å„ç§ç±»å‹çš„å›¾åƒç¼–è¾‘ã€‚ç„¶åï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡æ›´æ”¹ç›¸åº”çš„æç¤ºã€æ©ç å’Œé¡¹ç›®ï¼Œå¹¶è°ƒæ•´å®ƒä»¬ä¹‹é—´çš„å…³è”æ¥å®ç°å„ç§ç±»å‹çš„å›¾åƒç¼–è¾‘ã€‚è¿™ç§çµæ´»æ€§å…è®¸å¹¿æ³›çš„åˆ›é€ å¯èƒ½æ€§å’Œå¯¹ç¼–è¾‘è¿‡ç¨‹çš„ç²¾ç¡®æ§åˆ¶ã€‚æœ¬æ–‡åœ¨å››ä¸ªå›¾åƒç¼–è¾‘ä»»åŠ¡ä¸Šå±•ç¤ºäº†æœ¬æ–‡æ¡†æ¶çš„å¤šåŠŸèƒ½æ€§å’Œæ€§èƒ½ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œä½¿ç”¨ç¨³å®šæ‰©æ•£å’Œç¨³å®šæ‰©æ•£ XLã€‚æœ¬æ–‡æ€»ç»“æœ¬æ–‡çš„è´¡çŒ®å¦‚ä¸‹ï¼šâ€¢ æœ¬æ–‡æå‡ºå»ºç«‹é¡¹ç›®æç¤ºå…³è”ä»¥å®ç°é¡¹ç›®ç¼–è¾‘ã€‚â€¢ æœ¬æ–‡å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æ‰©æ•£æ¨¡å‹ä¸­çš„æ§åˆ¶æµã€‚â€¢ æœ¬æ–‡æå‡º D-Edit ä½œä¸ºä¸€ç§å¤šåŠŸèƒ½æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚D-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŸºäºæ©ç çš„ç¼–è¾‘ä»¥åŠåŒæ—¶æ‰§è¡ŒåŸºäºæ–‡æœ¬å’Œå›¾åƒçš„ç¼–è¾‘çš„æ¡†æ¶ã€‚</p></li><li><p>Methodsï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºå»ºç«‹é¡¹ç›®æç¤ºå…³è”ä»¥å®ç°é¡¹ç›®ç¼–è¾‘ï¼›ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æ‰©æ•£æ¨¡å‹ä¸­çš„æ§åˆ¶æµï¼›ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡º D-Edit ä½œä¸ºä¸€ç§å¤šåŠŸèƒ½æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚D-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŸºäºæ©ç çš„ç¼–è¾‘ä»¥åŠåŒæ—¶æ‰§è¡ŒåŸºäºæ–‡æœ¬å’Œå›¾åƒçš„ç¼–è¾‘çš„æ¡†æ¶ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡º D-Editï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹çš„å¤šåŠŸèƒ½å›¾åƒç¼–è¾‘æ¡†æ¶ã€‚D-Edit å°†ç»™å®šå›¾åƒåˆ†å‰²ä¸ºå¤šä¸ªé¡¹ç›®ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½è¢«åˆ†é…ä¸€ä¸ªæç¤ºæ¥æ§åˆ¶å…¶åœ¨æç¤ºç©ºé—´ä¸­çš„è¡¨ç¤ºã€‚å›¾åƒæç¤ºäº¤å‰æ³¨æ„åŠ›è¢«åˆ†è§£ä¸ºä¸€ç»„é¡¹ç›®æç¤ºäº¤äº’ã€‚æ¯ä¸ªæç¤ºé€šè¿‡å­¤ç«‹çš„äº¤å‰æ³¨æ„åŠ›è¢«çº¦æŸä¸ºä»…ä¸å®ƒæ§åˆ¶çš„é¡¹ç›®è¿›è¡Œäº¤äº’ï¼Œä»è€Œè§£è€¦äº†äº¤å‰æ³¨æ„åŠ›æ§åˆ¶ç®¡é“ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºå»ºç«‹é¡¹ç›®æç¤ºå…³è”ä»¥å®ç°é¡¹ç›®ç¼–è¾‘ã€‚</li><li>å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„åŠ›æ¥è§£è€¦æ‰©æ•£æ¨¡å‹ä¸­çš„æ§åˆ¶æµã€‚</li><li>æå‡º D-Edit ä½œä¸ºä¸€ç§å¤šåŠŸèƒ½æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚D-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŸºäºæ©ç çš„ç¼–è¾‘ä»¥åŠåŒæ—¶æ‰§è¡ŒåŸºäºæ–‡æœ¬å’Œå›¾åƒçš„ç¼–è¾‘çš„æ¡†æ¶ã€‚æ€§èƒ½ï¼š</li><li>åœ¨å››ä¸ªå›¾åƒç¼–è¾‘ä»»åŠ¡ä¸Šå±•ç¤ºäº†æœ¬æ–‡æ¡†æ¶çš„å¤šåŠŸèƒ½æ€§å’Œæ€§èƒ½ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œä½¿ç”¨ç¨³å®šæ‰©æ•£å’Œç¨³å®šæ‰©æ•£ XLã€‚å·¥ä½œé‡ï¼š</li><li>æå‡ºäº†ä¸€ç§ä¸¤æ­¥å¾®è°ƒè¿‡ç¨‹æ¥å»ºç«‹æç¤ºå’Œé¡¹ç›®ä¹‹é—´çš„å…³è”ï¼ŒåŒ…æ‹¬ä¼˜åŒ–æ–‡æœ¬ç¼–ç å™¨åµŒå…¥çŸ©é˜µå’Œ UNet æ¨¡å‹æƒé‡ã€‚</li><li>å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æç¤ºåˆ°é¡¹ç›®çš„äº¤äº’ï¼Œé€šè¿‡éš”ç¦»æ³¨æ„è®¡ç®—å’Œå€¼æ›´æ–°ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-197c83cdebd23bdb14b8fb0a7b729711.jpg" align="middle"><img src="https://picx.zhimg.com/v2-c1f65d83dbc51dc28ff510d4cc3b578f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-325295a9d8fc632369762af9b221cc1f.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-a471c060f1ae7bcb9959f797a6fb643a.jpg" align="middle"></details><h2 id="Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation"><a href="#Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation" class="headerlink" title="Pix2Gif: Motion-Guided Diffusion for GIF Generation"></a>Pix2Gif: Motion-Guided Diffusion for GIF Generation</h2><p><strong>Authors:Hitesh Kandala, Jianfeng Gao, Jianwei Yang</strong></p><p>We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation. We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig. To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts. Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence. In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects. After pretraining, we apply our model in a zero-shot manner to a number of video datasets. Extensive qualitative and quantitative experiments demonstrate the effectiveness of our model â€” it not only captures the semantic prompt from text but also the spatial ones from motion guidance. We train all our models using a single node of 16xV100 GPUs. Code, dataset and models are made public at: <a href="https://hiteshk03.github.io/Pix2Gif/">https://hiteshk03.github.io/Pix2Gif/</a>. </p><p><a href="http://arxiv.org/abs/2403.04634v2">PDF</a> </p><p><strong>Summary</strong><br>å›¾åƒåˆ°GIFç”Ÿæˆçš„æ–°å¼è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼Œé‡‡ç”¨æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºæŒ‡å¯¼çš„å›¾åƒç¿»è¯‘æ–¹æ³•ï¼Œå¹¶æå‡ºæ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ä»¥ç©ºé—´è½¬æ¢ç‰¹å¾ï¼Œä»è€Œç¡®ä¿æ¨¡å‹éµå¾ªè¿åŠ¨æŒ‡å¯¼ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡º Pix2Gifï¼Œä¸€ç§è¿åŠ¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆã€‚</li><li>ä»¥å›¾åƒç¿»è¯‘é—®é¢˜ä¸ºåŸºç¡€ï¼Œç”±æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºæŒ‡å¯¼ã€‚</li><li>è®¾è®¡æ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œæ ¹æ®ä¸¤ç§æç¤ºå¯¹æºå›¾åƒç‰¹å¾è¿›è¡Œç©ºé—´è½¬æ¢ã€‚</li><li>å¼•å…¥æ„ŸçŸ¥æŸå¤±ï¼Œç¡®ä¿è½¬æ¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒç©ºé—´ä¸€è‡´ã€‚</li><li>ç²¾å¿ƒæ•´ç†æ•°æ®ï¼Œä» TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸­æå–è¿è´¯çš„å›¾åƒå¸§ã€‚</li><li>é‡‡ç”¨é›¶æ ·æœ¬æ–¹å¼å°†æ¨¡å‹åº”ç”¨äºå¤šä¸ªè§†é¢‘æ•°æ®é›†ã€‚</li><li>å®šæ€§å’Œå®šé‡å®éªŒéªŒè¯äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œä¸ä»…èƒ½æ•æ‰æ–‡æœ¬çš„è¯­ä¹‰æç¤ºï¼Œè¿˜èƒ½æ•æ‰è¿åŠ¨å¼•å¯¼çš„ç©ºé—´æç¤ºã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šPix2Gifï¼šåŸºäºè¿åŠ¨æŒ‡å¯¼çš„å›¾åƒè½¬ GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆ</li><li>ä½œè€…ï¼šHitesh K. Agrawalã€Yuke Zhuã€Jonathan T. Barronã€Phillip Isolaã€ Alexei A. Efros</li><li>éš¶å±å…³ç³»ï¼šä¼¯å…‹åˆ©åŠ å·å¤§å­¦</li><li>å…³é”®è¯ï¼šå›¾åƒåˆ°è§†é¢‘ç”Ÿæˆã€è¿åŠ¨å¼•å¯¼ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç¼–è¾‘</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2302.04208.pdfï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆæ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­çš„ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå®ƒéœ€è¦æ¨¡å‹åŒæ—¶ç†è§£æ–‡æœ¬å’Œè¿åŠ¨æç¤ºï¼Œå¹¶ç”Ÿæˆä¸æç¤ºç›¸ä¸€è‡´ä¸”å†…å®¹è¿è´¯çš„è§†é¢‘ã€‚ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨æ–‡æœ¬æç¤ºæ¥æŒ‡å¯¼å›¾åƒç”Ÿæˆï¼Œä½†å®ƒä»¬åœ¨å¤„ç†è¿åŠ¨ä¿¡æ¯æ—¶å­˜åœ¨å±€é™æ€§ã€‚ç›´æ¥å°†è¿åŠ¨è¾“å…¥ä½œä¸ºæ–‡æœ¬æç¤ºå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹å¯¹å•ä¸ªæç¤ºè¯ç»™äºˆè¿‡å¤šçš„å…³æ³¨ï¼Œä»è€Œå¿½ç•¥å…¶ä»–é‡è¦çš„è¿åŠ¨ä¿¡æ¯ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ Pix2Gifï¼Œè¯¥æ¨¡å‹é€šè¿‡å¼•å…¥ä¸€ä¸ªè¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚è¯¥æ¨¡å—å°†è¿åŠ¨ä¿¡æ¯åµŒå…¥åˆ°å›¾åƒç‰¹å¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶éµå¾ªæŒ‡å®šçš„è¿åŠ¨è½¨è¿¹ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ªæ„ŸçŸ¥æŸå¤±ï¼Œä»¥ç¡®ä¿å˜å½¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒä¿æŒåœ¨åŒä¸€è¯­ä¹‰ç©ºé—´å†…ï¼Œä»è€Œä¿è¯å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼ŒPix2Gif æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰æ–‡æœ¬å’Œè¿åŠ¨æç¤ºä¸­çš„è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç»“æœã€‚å®éªŒç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li></ol><p>7.Methodsï¼š(1): Pix2Gifæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶ï¼Œå°†è¿åŠ¨ä¿¡æ¯åµŒå…¥å›¾åƒç‰¹å¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹éµå¾ªæŒ‡å®šçš„è¿åŠ¨è½¨è¿¹ã€‚(2): Pix2Gifæ¨¡å‹å¼•å…¥äº†ä¸€ä¸ªæ„ŸçŸ¥æŸå¤±ï¼Œä»¥ç¡®ä¿å˜å½¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒä¿æŒåœ¨åŒä¸€è¯­ä¹‰ç©ºé—´å†…ï¼Œä»è€Œä¿è¯å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚(3): Pix2Gifæ¨¡å‹åœ¨TGIFè§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰æ–‡æœ¬å’Œè¿åŠ¨æç¤ºä¸­çš„è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒåˆ°GIFï¼ˆè§†é¢‘ï¼‰ç»“æœã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šPix2Gifæ¨¡å‹åœ¨å›¾åƒåˆ°GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œæå‡ºäº†ä¸€ç§åˆ›æ–°æ€§çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œæœ‰æ•ˆåœ°å°†æ–‡æœ¬å’Œè¿åŠ¨ä¿¡æ¯ç»“åˆèµ·æ¥ï¼Œç”Ÿæˆå†…å®¹è¿è´¯ã€æ—¶é—´ä¸€è‡´çš„é«˜è´¨é‡ç»“æœã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œå°†è¿åŠ¨ä¿¡æ¯åµŒå…¥å›¾åƒç‰¹å¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹éµå¾ªæŒ‡å®šçš„è¿åŠ¨è½¨è¿¹ï¼Œä¿è¯äº†ç”Ÿæˆçš„å›¾åƒåºåˆ—åœ¨æ—¶é—´ä¸Šçš„è¿è´¯æ€§ã€‚</li><li>å¼•å…¥äº†æ„ŸçŸ¥æŸå¤±ï¼Œç¡®ä¿å˜å½¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒä¿æŒåœ¨åŒä¸€è¯­ä¹‰ç©ºé—´å†…ï¼Œä¿è¯äº†å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚æ€§èƒ½ï¼š</li><li>åœ¨TGIFè§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒPix2Gifæ¨¡å‹åœ¨æ•æ‰æ–‡æœ¬å’Œè¿åŠ¨æç¤ºä¸­çš„è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç”Ÿæˆçš„å›¾åƒåˆ°GIFï¼ˆè§†é¢‘ï¼‰ç»“æœè´¨é‡è¾ƒé«˜ã€‚</li><li>ä¸ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒPix2Gifæ¨¡å‹åœ¨ç”Ÿæˆæ—¶é—´ä¸€è‡´çš„GIFæ–¹é¢è¡¨ç°å‡ºæ›´å¥½çš„æ•ˆæœã€‚å·¥ä½œé‡ï¼š</li><li>Pix2Gifæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§å°ºå¯¸å›¾åƒå’Œé•¿è§†é¢‘åºåˆ—ã€‚</li><li>æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æ—¶é—´ä¹Ÿå—åˆ°å›¾åƒåˆ†è¾¨ç‡å’Œè§†é¢‘é•¿åº¦çš„å½±å“ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-87f209086271d79f66fc2b71db813a89.jpg" align="middle"><img src="https://pica.zhimg.com/v2-ddec3a8952939ae9c917e7b1984fb9e4.jpg" align="middle"><img src="https://picx.zhimg.com/v2-538b38079b2f1cde247a179f7b6ab9b5.jpg" align="middle"><img src="https://pica.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-11  VideoElevator Elevating Video Generation Quality with Versatile   Text-to-Image Diffusion Models</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="Diffusion Models" scheme="https://kedreamix.github.io/tags/Diffusion-Models/"/>
    
  </entry>
  
  <entry>
    <title>Blendshapeå­¦ä¹ ç¬”è®°</title>
    <link href="https://kedreamix.github.io/2024/03/11/Note/BlendShape/"/>
    <id>https://kedreamix.github.io/2024/03/11/Note/BlendShape/</id>
    <published>2024-03-11T11:42:00.000Z</published>
    <updated>2024-03-11T12:01:31.162Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Blendshape-Morph-TargetåŠ¨ç”»"><a href="#Blendshape-Morph-TargetåŠ¨ç”»" class="headerlink" title="Blendshape(Morph TargetåŠ¨ç”»)"></a>Blendshape(Morph TargetåŠ¨ç”»)</h2><p>Blendshapesæ³›æŒ‡3Då®šç‚¹åŠ¨ç”»çš„åˆ¶ä½œæ–¹å¼ (Mayaé‡Œé¢ç§°ä¹‹ä¸º blend shapes ï¼Œè€Œ3DS Maxé‡Œç§°ä¹‹ä¸ºmorph targets) ï¼Œåœ¨3DåŠ¨ç”»ä¸­ç”¨çš„æ¯”è¾ƒå¤šï¼Œå°¤å…¶æ˜¯äººè„¸åŠ¨ç”»çš„åˆ¶ä½œï¼Œé€šè¿‡blendshapeæ¥é©±åŠ¨è§’è‰²çš„é¢éƒ¨è¡¨æƒ…ã€‚</p><p>ç”¨åœ¨è„¸éƒ¨åŠ¨ç”»åˆ¶ä½œæ—¶ï¼Œblendshapeå¯ä»¥è¢«ç§°ä¹‹ä¸º<strong>è„¸éƒ¨ç‰¹å¾ï¼Œè¡¨æƒ…åŸºå‡†ï¼Œå®šä½ç¬¦</strong>ç­‰ç­‰ã€‚è¿™é‡Œè¦å¼•å…¥ä¸€ä¸ª<code>FACS</code>çš„æ¦‚å¿µï¼Œå¯ä»¥ç®€å•ç†è§£ä¸ºå°†è„¸éƒ¨è¿›è¡Œåˆç†åŒ–çš„åˆ†åŒºæ ‡å‡†ã€‚</p><blockquote><p>â€œè¡¨æƒ…è¿™ä¸ªä¸œè¥¿çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªæ— é™å¤šå¯èƒ½çš„ä¸œè¥¿ï¼Œæ€ä¹ˆèƒ½å¤Ÿè®¡ç®—expressionå‘¢ï¼Ÿ</p><p>è¿™å°±å¸¦æ¥äº†Blendshapesâ€”â€”ä¸€ç»„ç»„æˆæ•´ä½“è¡¨æƒ…çš„åŸºå‡†ï¼ˆæ•°é‡å¯ä»¥æœ‰åå‡ ä¸ªã€50ä¸ªã€100+ã€ 200+ï¼Œè¶Šå¤šå°±è¶Šç»†è…»)ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸€ç»„åŸºå‡†é€šè¿‡çº¿æ€§ç»„åˆæ¥è®¡ç®—å‡ºæ•´ä½“çš„expressionï¼Œç”¨å…¬å¼æ¥è¯´å°±æ˜¯  ï¼Œå…¶ä¸­eæ˜¯expressionï¼ŒBæ˜¯ä¸€ç»„è¡¨æƒ…åŸºå‡†ï¼Œdæ˜¯å¯¹åº”çš„ç³»æ•°ï¼ˆåœ¨è¿™ä¸€ç»„é‡Œé¢çš„æƒé‡ï¼‰ï¼Œbæ˜¯neutralã€‚â€ </p><p>â€” From <a href="https://zhuanlan.zhihu.com/p/78174706">https://zhuanlan.zhihu.com/p/78174706</a></p></blockquote><h2 id="BlendShapeç³»æ•°ä»‹ç»"><a href="#BlendShapeç³»æ•°ä»‹ç»" class="headerlink" title="BlendShapeç³»æ•°ä»‹ç»"></a>BlendShapeç³»æ•°ä»‹ç»</h2><p>åœ¨ARKitä¸­ï¼Œå¯¹è¡¨æƒ…ç‰¹å¾ä½ç½®å®šä¹‰äº†52ç»„è¿åŠ¨blendshapeç³»æ•°(<br><a href="https://developer.apple.com/documentation/arkit/arfaceanchor/blendshapelocation">https://developer.apple.com/documentation/arkit/arfaceanchor/blendshapelocation</a> )ï¼Œæ¯ä¸ªblendshapeç³»æ•°ä»£è¡¨ä¸€ç§è¡¨æƒ…å®šä½ç¬¦ï¼Œè¡¨æƒ…å®šä½ç¬¦å®šä¹‰äº†ç‰¹å®šè¡¨æƒ…å±æ€§ï¼Œå¦‚mouthSmileLeftã€mouthSmileRightç­‰ï¼Œä¸å…¶å¯¹åº”çš„blendshapeç³»æ•°åˆ™è¡¨ç¤ºè¡¨æƒ…è¿åŠ¨èŒƒå›´ã€‚è¿™52ç»„blendshapeç³»æ•°æå…¶æè¿°å¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚</p><p><img src="https://p3-sign.toutiaoimg.com/pgc-image/984d8d76878441c3a8402f788ef6e46f~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1710668214&amp;x-signature=qI8vU39X63te%2BVNdO78uBFphwK0%3D" alt="Blendshape"></p><p>æ¯ä¸€ä¸ªblendshapeç³»æ•°çš„å–å€¼èŒƒå›´ä¸º0ï½1çš„æµ®ç‚¹æ•°ã€‚ä»¥jawOpenä¸ºä¾‹ï¼Œå½“è®¤ä¸ºç”¨æˆ·çš„å˜´å·´å®Œå…¨é—­ç´§æ—¶ï¼Œè¿”å›çš„jawOpenç³»æ•°ä¸º0ã€‚å½“è®¤ä¸ºç”¨æˆ·çš„å˜´å·´å¼ å¼€è‡³æœ€å¤§æ—¶ï¼Œè¿”å›çš„jawOpenç³»æ•°ä¸º1ã€‚</p><p><img src="https://p6-sign.toutiaoimg.com/pgc-image/2c8cbd123e00470e95500a8ae62da605~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1710668214&amp;x-signature=UHPhjWP4v96kbtfJzF97Z%2Bp3klc%3D" alt=""></p><p>åœ¨ç”¨æˆ·å®Œå…¨é—­å˜´ä¸å˜´å¼ åˆ°æœ€å¤§ä¹‹é—´çš„è¿‡æ¸¡çŠ¶æ€ï¼ŒjawOpenä¼šæ ¹æ®ç”¨æˆ·å˜´å¼ å¤§çš„å¹…åº¦è¿”å›ä¸€ä¸ª0ï½1çš„æ’å€¼ã€‚</p><p><img src="https://p3-sign.toutiaoimg.com/pgc-image/8e8d980b8d69461fb5d2efbc50e47d47~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1710668214&amp;x-signature=sFNMeBoNY3ZFfiO%2BRSjR8uGECIw%3D" alt=""></p><h2 id="è„¸éƒ¨åŠ¨æ•çš„ä½¿ç”¨"><a href="#è„¸éƒ¨åŠ¨æ•çš„ä½¿ç”¨" class="headerlink" title="è„¸éƒ¨åŠ¨æ•çš„ä½¿ç”¨"></a>è„¸éƒ¨åŠ¨æ•çš„ä½¿ç”¨</h2><h3 id="ARKit-è„¸éƒ¨ä¸Viveè„¸éƒ¨blendshapeåŸºå‡†å¯¹æ¯”"><a href="#ARKit-è„¸éƒ¨ä¸Viveè„¸éƒ¨blendshapeåŸºå‡†å¯¹æ¯”" class="headerlink" title="ARKit è„¸éƒ¨ä¸Viveè„¸éƒ¨blendshapeåŸºå‡†å¯¹æ¯”"></a>ARKit è„¸éƒ¨ä¸Viveè„¸éƒ¨blendshapeåŸºå‡†å¯¹æ¯”</h3><div class="table-container"><table><thead><tr><th></th><th>ARKitï¼ˆ52ï¼‰</th><th>Extra</th><th>VIVEï¼ˆ52ï¼‰</th><th>Extra</th></tr></thead><tbody><tr><td>Brow</td><td>5</td><td></td><td>0</td><td></td></tr><tr><td>Eye</td><td>13</td><td></td><td>14</td><td>Eye Frown + 1</td></tr><tr><td>Cheek</td><td>3</td><td></td><td>3</td><td></td></tr><tr><td>Nose</td><td>2</td><td></td><td>0</td><td></td></tr><tr><td>Jaw</td><td>4</td><td></td><td>4</td><td></td></tr><tr><td>Mouth</td><td>24</td><td></td><td>20</td><td>O shape - 1</td></tr><tr><td>Tongue</td><td>1</td><td>Tongue + 7</td><td>11</td><td></td></tr><tr><td>Sum</td><td>52</td><td>59</td><td>52</td><td>52</td></tr></tbody></table></div><h3 id="ARKitçš„52ä¸ªBlendshapeè¡¨æƒ…åŸºå‡†ç»„"><a href="#ARKitçš„52ä¸ªBlendshapeè¡¨æƒ…åŸºå‡†ç»„" class="headerlink" title="ARKitçš„52ä¸ªBlendshapeè¡¨æƒ…åŸºå‡†ç»„"></a>ARKitçš„52ä¸ªBlendshapeè¡¨æƒ…åŸºå‡†ç»„</h3><p>å¯ä»¥çœ‹ARKit Face Blendshapesçš„ç…§ç‰‡å’Œ3Dæ¨¡å‹ç¤ºä¾‹ï¼š<a href="https://arkit-face-blendshapes.com/">https://arkit-face-blendshapes.com/</a></p><div class="table-container"><table><thead><tr><th>CC3</th><th>ARKit Name è¡¨æƒ…åŸºå‡†/å®šä½ç¬¦</th><th>ARKit Picture</th><th>CC3 Picture</th></tr></thead><tbody><tr><td>A01</td><td>browInnerUp</td><td><img src="https://static.wixstatic.com/media/64c63b_4cc12dd62ef8484986eebe9739f4eac9~mv2.png/v1/fill/w_252,h_178,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4cc12dd62ef8484986eebe9739f4eac9~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_fc0c248f4f6f46dda26eda66865678d2~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_fc0c248f4f6f46dda26eda66865678d2~mv2.png" alt=""></td></tr><tr><td>A02</td><td>browDownLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_18a57dc078214abea520f25ad6dfb02a~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_18a57dc078214abea520f25ad6dfb02a~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_9d780933931b469991ae0d4ddf105045~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9d780933931b469991ae0d4ddf105045~mv2.png" alt=""></td></tr><tr><td>A03</td><td>browDownRight</td><td><img src="https://static.wixstatic.com/media/64c63b_105d6dd9d7c44394b96b242e6d9d580b~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_105d6dd9d7c44394b96b242e6d9d580b~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_d9943f7163414286809edef7c3bf2de7~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d9943f7163414286809edef7c3bf2de7~mv2.png" alt=""></td></tr><tr><td>A04</td><td>browOuterUpLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_e7fe8581da2540a3bd7dfc39c874dd61~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e7fe8581da2540a3bd7dfc39c874dd61~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_c7234589721d4ddda4e2fcb1a9e0aa97~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c7234589721d4ddda4e2fcb1a9e0aa97~mv2.png" alt=""></td></tr><tr><td>A05</td><td>browOuterUpRight</td><td><img src="https://static.wixstatic.com/media/64c63b_1fb29f740ff74e8aabadc3769c86501a~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_1fb29f740ff74e8aabadc3769c86501a~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_4aefd80dd4c548669d5ba80e4da639eb~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4aefd80dd4c548669d5ba80e4da639eb~mv2.png" alt=""></td></tr><tr><td>A06</td><td>eyeLookUpLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_697a02a504c84d5f9e316172849bb6d0~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_697a02a504c84d5f9e316172849bb6d0~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_48e3b55ee9ca40f9aec9be8b35c403b0~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_48e3b55ee9ca40f9aec9be8b35c403b0~mv2.png" alt=""></td></tr><tr><td>A07</td><td>eyeLookUpRight</td><td><img src="https://static.wixstatic.com/media/64c63b_84cacf1f990a4e5c874c084a1ea626b3~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_84cacf1f990a4e5c874c084a1ea626b3~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_c879b6cca2ce4f8aa2385864c1fb9389~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c879b6cca2ce4f8aa2385864c1fb9389~mv2.png" alt=""></td></tr><tr><td>A08</td><td>eyeLookDownLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_d229ef398f3547be93a1a59563520e81~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d229ef398f3547be93a1a59563520e81~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_d6c6c94e3cee43db8ae9d6f36fc1a689~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d6c6c94e3cee43db8ae9d6f36fc1a689~mv2.png" alt=""></td></tr><tr><td>A09</td><td>eyeLookDownRight</td><td><img src="https://static.wixstatic.com/media/64c63b_67a1674b6d584344b7ea77843f72be27~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_67a1674b6d584344b7ea77843f72be27~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_ca0dbf25d9f74085809cdcd0742ede35~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ca0dbf25d9f74085809cdcd0742ede35~mv2.png" alt=""></td></tr><tr><td>A10</td><td>eyeLookOutLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_b4257aa18f754427a593064e71aa97fd~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b4257aa18f754427a593064e71aa97fd~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_d24fd04ef2d64db18c31b90eccd5f1a9~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d24fd04ef2d64db18c31b90eccd5f1a9~mv2.png" alt=""></td></tr><tr><td>A11</td><td>eyeLookInLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_03368853adeb4b8599da5451033cd809~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_03368853adeb4b8599da5451033cd809~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_049433ce862e44c4a5f96bcf0ad13bd0~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_049433ce862e44c4a5f96bcf0ad13bd0~mv2.png" alt=""></td></tr><tr><td>A12</td><td>eyeLookInRight</td><td><img src="https://static.wixstatic.com/media/64c63b_6e67745f7867402398390ce18a9f2882~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6e67745f7867402398390ce18a9f2882~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_803074453832444d8dec710711196559~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_803074453832444d8dec710711196559~mv2.png" alt=""></td></tr><tr><td>A13</td><td>eyeLookOutRight</td><td><img src="https://static.wixstatic.com/media/64c63b_b54a5b6f123244d98eadbded8c29a8c3~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b54a5b6f123244d98eadbded8c29a8c3~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_2e7b0fed966d453fa0a8dffaabeaf769~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2e7b0fed966d453fa0a8dffaabeaf769~mv2.png" alt=""></td></tr><tr><td>A14</td><td>eyeBlinkLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_0b68b26a666a49da843b6a47c4579b46~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0b68b26a666a49da843b6a47c4579b46~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_b46d50b28b5d40feba9a496b1ead4a5c~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b46d50b28b5d40feba9a496b1ead4a5c~mv2.png" alt=""></td></tr><tr><td>A15</td><td>eyeBlinkRight</td><td><img src="https://static.wixstatic.com/media/64c63b_65e50badaa854262a87329394a87484c~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_65e50badaa854262a87329394a87484c~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_9113137c91934bdbab3fb26756e84783~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9113137c91934bdbab3fb26756e84783~mv2.png" alt=""></td></tr><tr><td>A16</td><td>eyeSquintLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_7b9132e314d6404097f212401559e9c4~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_7b9132e314d6404097f212401559e9c4~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_0cccb71728de47e5a7f63fe9bc70bcaf~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0cccb71728de47e5a7f63fe9bc70bcaf~mv2.png" alt=""></td></tr><tr><td>A17</td><td>eyeSquintRight</td><td><img src="https://static.wixstatic.com/media/64c63b_8cc99b12de914fe882c19229ce2a91da~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8cc99b12de914fe882c19229ce2a91da~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_8445ac0161fe400ab28591fb6b0b1f56~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8445ac0161fe400ab28591fb6b0b1f56~mv2.png" alt=""></td></tr><tr><td>A18</td><td>eyeWideLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_0c87ac4e4c5d4d5f9639523c82aa9d43~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0c87ac4e4c5d4d5f9639523c82aa9d43~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_c097966492c3496cabf1d84455d7144d~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c097966492c3496cabf1d84455d7144d~mv2.png" alt=""></td></tr><tr><td>A19</td><td>eyeWideRight</td><td><img src="https://static.wixstatic.com/media/64c63b_3157fc370d064da9926027034e8220d6~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_3157fc370d064da9926027034e8220d6~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_24dc2c84e19b436a97fd2db6044f439c~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_24dc2c84e19b436a97fd2db6044f439c~mv2.png" alt=""></td></tr><tr><td>A20</td><td>cheekPuff</td><td><img src="https://static.wixstatic.com/media/64c63b_de4df8062c5f47ca9cd322b75b535705~mv2.png/v1/fill/w_252,h_172,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_de4df8062c5f47ca9cd322b75b535705~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_27548c426f1b47ae834c757417e03269~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_27548c426f1b47ae834c757417e03269~mv2.png" alt=""></td></tr><tr><td>A21</td><td>cheekSquintLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_70520c1a1c374ff3855cb8dfa7450b8b~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_70520c1a1c374ff3855cb8dfa7450b8b~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_d769bd2ef0104030818ed7a156ee2a2e~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d769bd2ef0104030818ed7a156ee2a2e~mv2.png" alt=""></td></tr><tr><td>A22</td><td>cheekSquintRight</td><td><img src="https://static.wixstatic.com/media/64c63b_2f82d4db05764690b33001da1d138f20~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2f82d4db05764690b33001da1d138f20~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_49752693e89a4293982b5e023a0e1c75~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_49752693e89a4293982b5e023a0e1c75~mv2.png" alt=""></td></tr><tr><td>A23</td><td>noseSneerLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_843177402d2545d1a1f0a97e848df91c~mv2.png/v1/fill/w_252,h_178,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_843177402d2545d1a1f0a97e848df91c~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_9855bb8e50f54f638d4bc321dd3caa45~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9855bb8e50f54f638d4bc321dd3caa45~mv2.png" alt=""></td></tr><tr><td>A24</td><td>noseSneerRight</td><td><img src="https://static.wixstatic.com/media/64c63b_8ee42dc6d8e443a0858e0c65ce56cc74~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8ee42dc6d8e443a0858e0c65ce56cc74~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_edd25cffbf1249d89bb0f6c5a95b76e5~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_edd25cffbf1249d89bb0f6c5a95b76e5~mv2.png" alt=""></td></tr><tr><td>A25</td><td>jawOpen</td><td><img src="https://static.wixstatic.com/media/64c63b_aca391d5eb744a76b18d6ced31904111~mv2.png/v1/fill/w_267,h_192,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_aca391d5eb744a76b18d6ced31904111~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_f14421d8adb1461ea32ca31bd3cac7be~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f14421d8adb1461ea32ca31bd3cac7be~mv2.png" alt=""></td></tr><tr><td>A26</td><td>jawForward</td><td><img src="https://static.wixstatic.com/media/64c63b_a199113be0f9418f8c729d9a7e7b4e49~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a199113be0f9418f8c729d9a7e7b4e49~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_df9963f3452c4ce1bd1b6829a8045112~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_df9963f3452c4ce1bd1b6829a8045112~mv2.png" alt=""></td></tr><tr><td>A27</td><td>jawLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_2642a61cdd0241f9ba24339873003125~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2642a61cdd0241f9ba24339873003125~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_0de7a40c68654461be74016c2e29cf02~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0de7a40c68654461be74016c2e29cf02~mv2.png" alt=""></td></tr><tr><td>A28</td><td>jawRight</td><td><img src="https://static.wixstatic.com/media/64c63b_2838229bffe74a5abe7d25d9c6e398ca~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2838229bffe74a5abe7d25d9c6e398ca~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_2f51f3993bed441b89b9b493a1f2e86b~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2f51f3993bed441b89b9b493a1f2e86b~mv2.png" alt=""></td></tr><tr><td>A29</td><td>mouthFunnel</td><td><img src="https://static.wixstatic.com/media/64c63b_d2719d8d83524b52a735296f0dfbf092~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d2719d8d83524b52a735296f0dfbf092~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_e2b4d7681dcf4b1faf34e3c5b57dd3ac~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e2b4d7681dcf4b1faf34e3c5b57dd3ac~mv2.png" alt=""></td></tr><tr><td>A30</td><td>mouthPucker</td><td><img src="https://static.wixstatic.com/media/64c63b_7771a95fb2ae4afeb885b7a684e3f249~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_7771a95fb2ae4afeb885b7a684e3f249~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_e553a24166984303920d5ec9ce1de6d6~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e553a24166984303920d5ec9ce1de6d6~mv2.png" alt=""></td></tr><tr><td>A31</td><td>mouthLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_d2e30cadc9b443f6993ee48d99ffb9c8~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d2e30cadc9b443f6993ee48d99ffb9c8~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_76b134e6564749fcaf6e036a6dc53517~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_76b134e6564749fcaf6e036a6dc53517~mv2.png" alt=""></td></tr><tr><td>A32</td><td>mouthRight</td><td><img src="https://static.wixstatic.com/media/64c63b_ef34b0cf15c541058052d74870f95a11~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ef34b0cf15c541058052d74870f95a11~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_332e51118068490cbb932bc8b3880895~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_332e51118068490cbb932bc8b3880895~mv2.png" alt=""></td></tr><tr><td>A33</td><td>mouthRollUpper</td><td><img src="https://static.wixstatic.com/media/64c63b_5c93c56f5d9e4698a86160047452fdae~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5c93c56f5d9e4698a86160047452fdae~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_f86e02c72dcd4e27b5fafc3e7cbf5098~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f86e02c72dcd4e27b5fafc3e7cbf5098~mv2.png" alt=""></td></tr><tr><td>A34</td><td>mouthRollLower</td><td><img src="https://static.wixstatic.com/media/64c63b_8d2d50c4784b4f4a881264f9e806b26e~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8d2d50c4784b4f4a881264f9e806b26e~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_f6ce7f1df803456fb25b77533ec5c1a9~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f6ce7f1df803456fb25b77533ec5c1a9~mv2.png" alt=""></td></tr><tr><td>A35</td><td>mouthShrugUpper</td><td><img src="https://static.wixstatic.com/media/64c63b_d70a5a8102d14df6be57658f696ab28c~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d70a5a8102d14df6be57658f696ab28c~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_36feb9bc9305402e8a9e044b7f42c06e~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_36feb9bc9305402e8a9e044b7f42c06e~mv2.png" alt=""></td></tr><tr><td>A36</td><td>mouthShrugLower</td><td><img src="https://static.wixstatic.com/media/64c63b_c39b6573ab8b452c8ba9af4cfd61fa0d~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c39b6573ab8b452c8ba9af4cfd61fa0d~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_881391abc1ff4fbabd6f7719d93179b8~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_881391abc1ff4fbabd6f7719d93179b8~mv2.png" alt=""></td></tr><tr><td>A37</td><td>mouthClose</td><td><img src="https://static.wixstatic.com/media/64c63b_7c1a9921e54c42c5bbad10ce2d2a2edc~mv2.png/v1/fill/w_267,h_129,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_7c1a9921e54c42c5bbad10ce2d2a2edc~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_8aded518da54400db938b69753b8539a~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8aded518da54400db938b69753b8539a~mv2.png" alt=""></td></tr><tr><td>A38</td><td>mouthSmileLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_a3cdfd578cec40a5a83931c4d0c9f8ab~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a3cdfd578cec40a5a83931c4d0c9f8ab~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_11aa5137231b4bfe8a8908f25d8d4112~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_11aa5137231b4bfe8a8908f25d8d4112~mv2.png" alt=""></td></tr><tr><td>A39</td><td>mouthSmileRight</td><td><img src="https://static.wixstatic.com/media/64c63b_f0c7a9ddfcb945f496f4ac8aafcfd0ca~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f0c7a9ddfcb945f496f4ac8aafcfd0ca~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_4818df7bf47740f6bab387d0d2926a2b~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4818df7bf47740f6bab387d0d2926a2b~mv2.png" alt=""></td></tr><tr><td>A40</td><td>mouthFrownLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_8e7c89a5e9514206ac3fd7152e912ef8~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8e7c89a5e9514206ac3fd7152e912ef8~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_ba5a9fdcf6d246439b8d7d9dbf63fb16~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ba5a9fdcf6d246439b8d7d9dbf63fb16~mv2.png" alt=""></td></tr><tr><td>A41</td><td>mouthFrownRight</td><td><img src="https://static.wixstatic.com/media/64c63b_019c769729a34c7c992c3bbde95adf2a~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_019c769729a34c7c992c3bbde95adf2a~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_4505259aa94646278b01cd6b4e6fe32a~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4505259aa94646278b01cd6b4e6fe32a~mv2.png" alt=""></td></tr><tr><td>A42</td><td>mouthDimpleLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_b7c5c7b4fcea481ba877fab837ddda7c~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b7c5c7b4fcea481ba877fab837ddda7c~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_53d010f6b8b340d6a305149152fe9eb2~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_53d010f6b8b340d6a305149152fe9eb2~mv2.png" alt=""></td></tr><tr><td>A43</td><td>mouthDimpleRight</td><td><img src="https://static.wixstatic.com/media/64c63b_268dda3d9bb14eaba63c5b123ab9002c~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_268dda3d9bb14eaba63c5b123ab9002c~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_ea46553169c749f69dc8e47737434193~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ea46553169c749f69dc8e47737434193~mv2.png" alt=""></td></tr><tr><td>A44</td><td>mouthUpperUpLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_e6f82a77cd374e37b456590eb19c2d28~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e6f82a77cd374e37b456590eb19c2d28~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_5c9a52ea901243218e0c9252fcd45a00~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5c9a52ea901243218e0c9252fcd45a00~mv2.png" alt=""></td></tr><tr><td>A45</td><td>mouthUpperUpRight</td><td><img src="https://static.wixstatic.com/media/64c63b_384bab2c926045f99f4bbef75b6975f0~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_384bab2c926045f99f4bbef75b6975f0~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_8abd87f586bb4d2088673a2358a65adb~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8abd87f586bb4d2088673a2358a65adb~mv2.png" alt=""></td></tr><tr><td>A46</td><td>mouthLowerDownLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_2511f8304fbb49dab88eb09b118f88bc~mv2.png/v1/fill/w_267,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2511f8304fbb49dab88eb09b118f88bc~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_21506f6994114f1194bc69958bd3778d~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_21506f6994114f1194bc69958bd3778d~mv2.png" alt=""></td></tr><tr><td>A47</td><td>mouthLowerDownRight</td><td><img src="https://static.wixstatic.com/media/64c63b_5c300e220ef04f388b827c096ad7aae6~mv2.png/v1/fill/w_267,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5c300e220ef04f388b827c096ad7aae6~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_9ac53c48df9e4d63b6774b91aaa4db3d~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9ac53c48df9e4d63b6774b91aaa4db3d~mv2.png" alt=""></td></tr><tr><td>A48</td><td>mouthPressLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_478c881ace1744ff825202484b212c17~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_478c881ace1744ff825202484b212c17~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_cca358e42c08454cb9f7f30317c4e93c~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_cca358e42c08454cb9f7f30317c4e93c~mv2.png" alt=""></td></tr><tr><td>A49</td><td>mouthPressRight</td><td><img src="https://static.wixstatic.com/media/64c63b_acad007d32d24b26b4cc192345afc0ba~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_acad007d32d24b26b4cc192345afc0ba~mv2.png" alt=""></td><td><br><img src="https://static.wixstatic.com/media/64c63b_35bac2e5acf54d438dd0acf4690c4ea2~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_35bac2e5acf54d438dd0acf4690c4ea2~mv2.png" alt=""></td></tr><tr><td>A50</td><td>mouthStretchLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_18fbf15030164a6383068c8fb7aa7e72~mv2.png/v1/fill/w_263,h_184,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_18fbf15030164a6383068c8fb7aa7e72~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_cf77104a546149e88698feb420726493~mv2.png/v1/fill/w_232,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_cf77104a546149e88698feb420726493~mv2.png" alt=""></td></tr><tr><td>A51</td><td>mouthStretchRight</td><td><img src="https://static.wixstatic.com/media/64c63b_3f8dd987a3d44b7e98e1e7abb1815111~mv2.png/v1/fill/w_263,h_184,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_3f8dd987a3d44b7e98e1e7abb1815111~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_b2a3abb6ea204ab293571c7c19747003~mv2.png/v1/fill/w_232,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b2a3abb6ea204ab293571c7c19747003~mv2.png" alt=""></td></tr><tr><td>A52</td><td>tongueOut</td><td></td><td><img src="https://static.wixstatic.com/media/64c63b_10387f10b0e04d5fac672f8bd17d9459~mv2.png/v1/fill/w_232,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_10387f10b0e04d5fac672f8bd17d9459~mv2.png" alt=""></td></tr></tbody></table></div><ul><li>CC3 é¢å¤–çš„èˆŒå¤´Blendshape(with open month)ï¼š</li></ul><div class="table-container"><table><thead><tr><th>T01</th><th>Tongue_Up</th><th></th><th><img src="https://static.wixstatic.com/media/64c63b_75c512342cde45ffbb40fcf5d463732e~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_75c512342cde45ffbb40fcf5d463732e~mv2.png" alt=""></th></tr></thead><tbody><tr><td>T02</td><td>Tongue_Down</td><td></td><td><img src="https://static.wixstatic.com/media/64c63b_4bdf00b4d23d4a89ac0bffbb66cc348d~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4bdf00b4d23d4a89ac0bffbb66cc348d~mv2.png" alt=""></td></tr><tr><td>T03</td><td>Tongue_Left</td><td></td><td><img src="https://static.wixstatic.com/media/64c63b_860b7c7043894521a754755c35816cb3~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_860b7c7043894521a754755c35816cb3~mv2.png" alt=""></td></tr><tr><td>T04</td><td>Tongue_Right</td><td></td><td><img src="https://static.wixstatic.com/media/64c63b_02c7adc74f934d31ad35c01615b96735~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_02c7adc74f934d31ad35c01615b96735~mv2.png" alt=""></td></tr><tr><td>T05</td><td>Tongue_Roll</td><td></td><td><img src="https://static.wixstatic.com/media/64c63b_bfa27b0483c94f7484eeed246642fbc5~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_bfa27b0483c94f7484eeed246642fbc5~mv2.png" alt=""></td></tr><tr><td>T06</td><td>Tongue_Tip_Up</td><td></td><td><img src="https://static.wixstatic.com/media/64c63b_6a7d96ce1444409c958adc03652983b7~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6a7d96ce1444409c958adc03652983b7~mv2.png" alt=""></td></tr><tr><td>T07</td><td>Tongue_Tip_Down</td><td></td><td><img src="https://static.wixstatic.com/media/64c63b_37fa335ad1a549b983fb6552db3b5198~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_37fa335ad1a549b983fb6552db3b5198~mv2.png" alt=""></td></tr></tbody></table></div><h3 id="Viveé¢éƒ¨çš„è¡¨æƒ…åŸºå‡†ç»„"><a href="#Viveé¢éƒ¨çš„è¡¨æƒ…åŸºå‡†ç»„" class="headerlink" title="Viveé¢éƒ¨çš„è¡¨æƒ…åŸºå‡†ç»„"></a>Viveé¢éƒ¨çš„è¡¨æƒ…åŸºå‡†ç»„</h3><p>Viveè¿™ä¸€å¥—è„¸éƒ¨è¿½è¸ªä¹Ÿæ˜¯52ä¸ªblendshapesï¼Œä½†æ˜¯å’Œè‹¹æœçš„åŸºå‡†æœ‰å¾ˆå¤§åŒºåˆ«ã€‚</p><ul><li>åŒºåˆ«ä¸€ï¼šèˆŒå¤´</li></ul><p>è‹¹æœå…¶å®æ˜¯52+7ï¼Œå› ä¸ºèˆŒå¤´åœ¨52ä¸ªé‡Œåªæœ‰ä¸€ä¸ªä¼¸èˆŒå¤´çš„blendshapeï¼Œä½†viveå…¶å®æ˜¯42 + 10ï¼Œæ•´ä½“æ¥è®²Viveè¡¨æƒ…è®°ä½èƒ½trackingåˆ°çš„è¡¨æƒ…ç»†èŠ‚è¿˜æ˜¯æ›´å°‘ä¸€äº›ã€‚</p><ul><li>åŒºåˆ«äºŒï¼šçœ‰æ¯›</li></ul><p>ARKitçš„52ä¸ªblendshapesï¼Œæ˜¯æ ¹æ®ç¡¬ä»¶åˆ†åŒºä¸€å¯¹ä¸€trackingçš„ï¼Œç„¶è€ŒViveçœ‰æ¯›ä¸åˆ†æ˜¯æ²¡æœ‰å•ç‹¬å¦è®¾blendshapesï¼Œè€Œæ˜¯ä¸çœ¼ç›çš„åŠ¨ä½œblendedåœ¨ä¸€èµ·ä½œä¸ºä¸€ä¸ªblendshapeçš„ï¼Œå¹¶ä¸æ˜¯ç²¾å‡†çš„ä¸€å¯¹ä¸€åˆ†åŒºtrackingã€‚</p><p>æˆ‘ä¸‹é¢ç¼–å·çš„æ’åºæ˜¯æŒ‰ç…§<a href="https://developer.vive.com/resources/vive-sense/sdk/vive-eye-and-facial-tracking-sdk/">VIVE Eye and Facial Tracking SDK</a> unity é‡Œinspectoré‡Œçš„é¡ºåºï¼Œæ–¹ä¾¿æˆ‘åŠ è¡¨æƒ…ã€‚</p><p>è¿™é‡Œæ˜¯æ•´ç†çš„ç”¨ARKitåˆ¶ä½œViveåŸºå‡†çš„å¯¹åº”ç¼–å·ï¼š</p><p><a href="https://docs.google.com/spreadsheets/d/1kWXnqtiVbXRb1FrD5NLlxxuxbYmS0Z6YBLuIE1WwqD4/edit?usp=sharing">https://docs.google.com/spreadsheets/d/1kWXnqtiVbXRb1FrD5NLlxxuxbYmS0Z6YBLuIE1WwqD4/edit?usp=sharing</a></p><ul><li>Eye Blendshapes ï¼ˆ14 = 12 + 2ï¼‰</li></ul><div class="table-container"><table><thead><tr><th>Viveç¼–å·</th><th>Viveè¡¨æƒ…åŸºå‡†</th><th>Vive Picture</th><th>Create by CC3 blendshapes</th></tr></thead><tbody><tr><td>V01</td><td>Eye_Left_Blink</td><td><img src="https://static.wixstatic.com/media/64c63b_735cb0ae227e42bca98f9c51fbd0df6b~mv2.png/v1/fill/w_238,h_182,al_c,lg_1,q_85,enc_auto/64c63b_735cb0ae227e42bca98f9c51fbd0df6b~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_e5f3c0dfc63a42618e182a9b1a0c1e9c~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e5f3c0dfc63a42618e182a9b1a0c1e9c~mv2.png" alt=""></td></tr><tr><td>V02</td><td>Eye_Left_Wide</td><td><img src="https://static.wixstatic.com/media/64c63b_1d9223fb44574a94988a7c9ce4d89b39~mv2.png/v1/fill/w_222,h_160,al_c,lg_1,q_85,enc_auto/64c63b_1d9223fb44574a94988a7c9ce4d89b39~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_5dd9ed05165f4fe9b486b4f0604dacc1~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5dd9ed05165f4fe9b486b4f0604dacc1~mv2.png" alt=""></td></tr><tr><td>V03</td><td>Eye_Left_Right</td><td><img src="https://static.wixstatic.com/media/64c63b_638f42e4960743c4b235ab18b5ac6eba~mv2.png/v1/fill/w_238,h_188,al_c,lg_1,q_85,enc_auto/64c63b_638f42e4960743c4b235ab18b5ac6eba~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_c5fcda96b7184941b2a89b2193470f2b~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c5fcda96b7184941b2a89b2193470f2b~mv2.png" alt=""></td></tr><tr><td>V04</td><td>Eye_Left_Left</td><td><img src="https://static.wixstatic.com/media/64c63b_a1041585f54748728dd71aec7de129f5~mv2.png/v1/fill/w_238,h_192,al_c,lg_1,q_85,enc_auto/64c63b_a1041585f54748728dd71aec7de129f5~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_a26c36f7dc2940fe9513e263f7a99c4e~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a26c36f7dc2940fe9513e263f7a99c4e~mv2.png" alt=""></td></tr><tr><td>V05</td><td>Eye_Left_Up</td><td><img src="https://static.wixstatic.com/media/64c63b_d2c84d05015c4d8289f6c7d6d5ba0dcc~mv2.png/v1/fill/w_238,h_203,al_c,lg_1,q_85,enc_auto/64c63b_d2c84d05015c4d8289f6c7d6d5ba0dcc~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_e3e67e16e4b84697a39c3333bad24712~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e3e67e16e4b84697a39c3333bad24712~mv2.png" alt=""></td></tr><tr><td>V06</td><td>Eye_Left_Down</td><td><img src="https://static.wixstatic.com/media/64c63b_5cd43316383549e282e7f3f743df9053~mv2.png/v1/fill/w_238,h_195,al_c,lg_1,q_85,enc_auto/64c63b_5cd43316383549e282e7f3f743df9053~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_993bd278fb024580a834a71c6886cc4b~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_993bd278fb024580a834a71c6886cc4b~mv2.png" alt=""></td></tr><tr><td>V07</td><td>Eye_Right_Blink</td><td><img src="https://static.wixstatic.com/media/64c63b_2e198e55d97a491cbc66059e6f6adddc~mv2.png/v1/fill/w_235,h_195,al_c,lg_1,q_85,enc_auto/64c63b_2e198e55d97a491cbc66059e6f6adddc~mv2.png" alt=""></td><td></td></tr><tr><td>V08</td><td>Eye_Right_Wide</td><td><img src="https://static.wixstatic.com/media/64c63b_6eebbecf575d4bec905be4dbec06322c~mv2.png/v1/fill/w_223,h_160,al_c,lg_1,q_85,enc_auto/64c63b_6eebbecf575d4bec905be4dbec06322c~mv2.png" alt=""></td><td></td></tr><tr><td>V09</td><td>Eye_Right_Right</td><td><img src="https://static.wixstatic.com/media/64c63b_fc88e475e8c4435a98364224f54ade1a~mv2.png/v1/fill/w_234,h_197,al_c,lg_1,q_85,enc_auto/64c63b_fc88e475e8c4435a98364224f54ade1a~mv2.png" alt=""></td><td></td></tr><tr><td>V10</td><td>Eye_Right_Left</td><td><img src="https://static.wixstatic.com/media/64c63b_216b900672314c37a3e91501b7fe7cc1~mv2.png/v1/fill/w_238,h_190,al_c,lg_1,q_85,enc_auto/64c63b_216b900672314c37a3e91501b7fe7cc1~mv2.png" alt=""></td><td></td></tr><tr><td>V11</td><td>Eye_Right_Up</td><td><img src="https://static.wixstatic.com/media/64c63b_062847a5c45d4dabbe78d255779013dd~mv2.png/v1/fill/w_231,h_196,al_c,lg_1,q_85,enc_auto/64c63b_062847a5c45d4dabbe78d255779013dd~mv2.png" alt=""></td><td></td></tr><tr><td>V12</td><td>Eye_Right_Down</td><td><img src="https://static.wixstatic.com/media/64c63b_b6fae35fba8543d0becc535532111d23~mv2.png/v1/fill/w_238,h_176,al_c,lg_1,q_85,enc_auto/64c63b_b6fae35fba8543d0becc535532111d23~mv2.png" alt=""></td><td></td></tr><tr><td>V13</td><td>Eye_Left_squeeze: The blendShape close eye tightly when Eye_Left_Blink  value is 100.</td><td><img src="https://static.wixstatic.com/media/64c63b_c7b07f1b4ec6495685d85808d23c04e8~mv2.png/v1/fill/w_238,h_183,al_c,lg_1,q_85,enc_auto/64c63b_c7b07f1b4ec6495685d85808d23c04e8~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_a629d31ace624dd8b2ded5123123156e~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a629d31ace624dd8b2ded5123123156e~mv2.png" alt=""></td></tr><tr><td>V14</td><td>Eye_Right_squeeze</td><td><img src="https://static.wixstatic.com/media/64c63b_b82c535f90874742b3c0b6ff62136fe2~mv2.png/v1/fill/w_238,h_194,al_c,lg_1,q_85,enc_auto/64c63b_b82c535f90874742b3c0b6ff62136fe2~mv2.png" alt=""></td></tr></tbody></table></div><ul><li>Lip Blendshapes ï¼ˆ38 = 37 + 1ï¼‰</li></ul><div class="table-container"><table><thead><tr><th>Viveç¼–å·</th><th>Viveè¡¨æƒ…åŸºå‡†</th><th>Vive Picture</th><th>Create by CC3 blendshapes</th></tr></thead><tbody><tr><td>V15</td><td>Jaw_Right</td><td><img src="https://static.wixstatic.com/media/64c63b_75f8b68a96104ef8bf36e393c7ecd48b~mv2.png/v1/fill/w_235,h_190,al_c,lg_1,q_85,enc_auto/64c63b_75f8b68a96104ef8bf36e393c7ecd48b~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_65471d28b0d743c0bb6232ffaee0f6b6~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_65471d28b0d743c0bb6232ffaee0f6b6~mv2.png" alt=""></td></tr><tr><td>V16</td><td>Jaw_Left</td><td><img src="https://static.wixstatic.com/media/64c63b_9cacde29288c4523a2192835a736ad6b~mv2.png/v1/fill/w_245,h_202,al_c,lg_1,q_85,enc_auto/64c63b_9cacde29288c4523a2192835a736ad6b~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_017d7142fd494aef9ad7bbe53fa1d6eb~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_017d7142fd494aef9ad7bbe53fa1d6eb~mv2.png" alt=""></td></tr><tr><td>V17</td><td>Jaw_Forward</td><td><img src="https://static.wixstatic.com/media/64c63b_3876f3dd1a1b4eed92e8405b42700190~mv2.png/v1/fill/w_248,h_197,al_c,lg_1,q_85,enc_auto/64c63b_3876f3dd1a1b4eed92e8405b42700190~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_20353f83579541428557c32d92545c9e~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_20353f83579541428557c32d92545c9e~mv2.png" alt=""></td></tr><tr><td>V18</td><td>Jaw_Open</td><td><img src="https://static.wixstatic.com/media/64c63b_dc79f10003534839948d3261183d5082~mv2.png/v1/fill/w_244,h_188,al_c,lg_1,q_85,enc_auto/64c63b_dc79f10003534839948d3261183d5082~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_24470b9cc9964a11906c42b1d1a6e5e9~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_24470b9cc9964a11906c42b1d1a6e5e9~mv2.png" alt=""></td></tr><tr><td>V19</td><td>Mouth_Ape_Shape</td><td><img src="https://static.wixstatic.com/media/64c63b_7a0f9461a760449db12b2159009ccc93~mv2.png/v1/fill/w_249,h_196,al_c,lg_1,q_85,enc_auto/64c63b_7a0f9461a760449db12b2159009ccc93~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_3d7911f5bfa645adb7f3c36fbeafa2b9~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_3d7911f5bfa645adb7f3c36fbeafa2b9~mv2.png" alt=""></td></tr><tr><td>V20</td><td>Mouth_Upper_Right</td><td><img src="https://static.wixstatic.com/media/64c63b_01037e0042754059b7ada72a8adf2e8a~mv2.png/v1/fill/w_227,h_161,al_c,lg_1,q_85,enc_auto/64c63b_01037e0042754059b7ada72a8adf2e8a~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_185ec305ba464016a15c2420fb04916e~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_185ec305ba464016a15c2420fb04916e~mv2.png" alt=""></td></tr><tr><td>V21</td><td>Mouth_Upper_Left</td><td><img src="https://static.wixstatic.com/media/64c63b_f0c61e8f3f3c42d7ad6d83703f1a61d9~mv2.png/v1/fill/w_265,h_182,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f0c61e8f3f3c42d7ad6d83703f1a61d9~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_abbecb4860a44fe9800585825beb4b17~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_abbecb4860a44fe9800585825beb4b17~mv2.png" alt=""></td></tr><tr><td>V22</td><td>Mouth_Lower_Right</td><td><img src="https://static.wixstatic.com/media/64c63b_3ec74984b19d44d389a68bcc1ac1a7fb~mv2.png/v1/fill/w_265,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_3ec74984b19d44d389a68bcc1ac1a7fb~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_80a4cdffa3fb493e9c153b517d9aebda~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_80a4cdffa3fb493e9c153b517d9aebda~mv2.png" alt=""></td></tr><tr><td>V23</td><td>Mouth_Lower_Left</td><td><img src="https://static.wixstatic.com/media/64c63b_e80cee8738ea42528c8f351303f5e2c8~mv2.png/v1/fill/w_265,h_225,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e80cee8738ea42528c8f351303f5e2c8~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_edf8e441ff994c27bde811a21754d5e5~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_edf8e441ff994c27bde811a21754d5e5~mv2.png" alt=""></td></tr><tr><td>V24</td><td>*Mouth_Upper_Overturn</td><td><img src="https://static.wixstatic.com/media/64c63b_5f77c14164ae48cf9c0cf4c762b97837~mv2.png/v1/fill/w_265,h_202,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5f77c14164ae48cf9c0cf4c762b97837~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_b8ae358e723f42e199338722f186e238~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b8ae358e723f42e199338722f186e238~mv2.png" alt=""></td></tr><tr><td>V25</td><td>*Mouth_Lower_Overturn</td><td><img src="https://static.wixstatic.com/media/64c63b_16a26f9ced50420b99a4c32fc296c112~mv2.png/v1/fill/w_265,h_210,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_16a26f9ced50420b99a4c32fc296c112~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_282323813dfa4ea1aa76551b112e3919~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_282323813dfa4ea1aa76551b112e3919~mv2.png" alt=""></td></tr><tr><td>V26</td><td>Mouth_Pout</td><td><img src="https://static.wixstatic.com/media/64c63b_e7da853fe63242a9bedbd7fe3bddadc7~mv2.png/v1/fill/w_265,h_205,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e7da853fe63242a9bedbd7fe3bddadc7~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_36615908f74d4663a6bc438c3287938c~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_36615908f74d4663a6bc438c3287938c~mv2.png" alt=""></td></tr><tr><td>V27</td><td>Mouth_Smile_Right</td><td><img src="https://static.wixstatic.com/media/64c63b_1de129dc23784dd0af8d5bbccff75741~mv2.png/v1/fill/w_265,h_205,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_1de129dc23784dd0af8d5bbccff75741~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_47a00d3e749e47fa8b3489da81252654~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_47a00d3e749e47fa8b3489da81252654~mv2.png" alt=""></td></tr><tr><td>V28</td><td>Mouth_Smile_Left</td><td><img src="https://static.wixstatic.com/media/64c63b_e66c5606123d4272bc4d3206a101e884~mv2.png/v1/fill/w_265,h_213,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e66c5606123d4272bc4d3206a101e884~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_0a26740959644351bb01f9e9d40ef35e~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0a26740959644351bb01f9e9d40ef35e~mv2.png" alt=""></td></tr><tr><td>V29</td><td>Mouth_Sad_Right</td><td><img src="https://static.wixstatic.com/media/64c63b_ba5427a221c2446e9d3b9e30d94d80b9~mv2.png/v1/fill/w_265,h_224,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ba5427a221c2446e9d3b9e30d94d80b9~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_c1e99be3d6c34038852ce55b72102f5c~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c1e99be3d6c34038852ce55b72102f5c~mv2.png" alt=""></td></tr><tr><td>V30</td><td>Mouth_Sad_Left</td><td><img src="https://static.wixstatic.com/media/64c63b_00772c50ca334cbf95dd1bf53be4c6b8~mv2.png/v1/fill/w_265,h_218,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_00772c50ca334cbf95dd1bf53be4c6b8~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_889e2637303f4d7195afd699a3d92b86~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_889e2637303f4d7195afd699a3d92b86~mv2.png" alt=""></td></tr><tr><td>V31</td><td>Cheek_Puff_Right</td><td><img src="https://static.wixstatic.com/media/64c63b_765350d6685547d4b03b7ae31e7346e0~mv2.png/v1/fill/w_265,h_224,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_765350d6685547d4b03b7ae31e7346e0~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_66386b8d632b4556a00f886613f26d92~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_66386b8d632b4556a00f886613f26d92~mv2.png" alt=""></td></tr><tr><td>V32</td><td>Cheek_Puff_Left</td><td><img src="https://static.wixstatic.com/media/64c63b_2998211eb141496d8651b786337b7846~mv2.png/v1/fill/w_265,h_213,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2998211eb141496d8651b786337b7846~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_833f433253fb4bcc8e380d79120b3003~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_833f433253fb4bcc8e380d79120b3003~mv2.png" alt=""></td></tr><tr><td>V33</td><td>Cheek_Suck</td><td><img src="https://static.wixstatic.com/media/64c63b_6eea541e05494d26a06cbbe5377cdc0a~mv2.png/v1/fill/w_265,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6eea541e05494d26a06cbbe5377cdc0a~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_8573de7fc0d84245a0fa4412ecd3e842~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8573de7fc0d84245a0fa4412ecd3e842~mv2.png" alt=""></td></tr><tr><td>V34</td><td>Mouth_Upper_UpRight</td><td><img src="https://static.wixstatic.com/media/64c63b_b6ca87cbb7774b2ab4f0ec3748ec9c51~mv2.png/v1/fill/w_265,h_216,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b6ca87cbb7774b2ab4f0ec3748ec9c51~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_c48b985609fe4129ad1dac8a41905a7e~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c48b985609fe4129ad1dac8a41905a7e~mv2.png" alt=""></td></tr><tr><td>V35</td><td>Mouth<em>Upper</em> UpLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_58bdc8db0ac3451388534ff3bfb0fa83~mv2.png/v1/fill/w_265,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_58bdc8db0ac3451388534ff3bfb0fa83~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_5ff3f05aeecd48fe9f3077f5c9c96569~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5ff3f05aeecd48fe9f3077f5c9c96569~mv2.png" alt=""></td></tr><tr><td>V36</td><td>Mouth_Lower_DownRight</td><td><img src="https://static.wixstatic.com/media/64c63b_12f26efe2f28425cb366eea55e83470c~mv2.png/v1/fill/w_265,h_223,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_12f26efe2f28425cb366eea55e83470c~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_30ae27fa9ee94aa8a1b29bbd5fe7b0b2~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_30ae27fa9ee94aa8a1b29bbd5fe7b0b2~mv2.png" alt=""></td></tr><tr><td>V37</td><td>Mouth_Lower_DownLeft</td><td><img src="https://static.wixstatic.com/media/64c63b_4ed1a27945324b53aad0aa3cf453a275~mv2.png/v1/fill/w_265,h_218,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4ed1a27945324b53aad0aa3cf453a275~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_76893f9855fa4a5a9415cd8abfae6f6f~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_76893f9855fa4a5a9415cd8abfae6f6f~mv2.png" alt=""></td></tr><tr><td>V38</td><td>Mouth_Upper_Inside</td><td><img src="https://static.wixstatic.com/media/64c63b_f5e050f0d9954760879ccd18185c2fc8~mv2.png/v1/fill/w_265,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f5e050f0d9954760879ccd18185c2fc8~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_5217c686c7c6455aaca6ba1b2ce64217~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5217c686c7c6455aaca6ba1b2ce64217~mv2.png" alt=""></td></tr><tr><td>V39</td><td>Mouth_Lower_Inside</td><td><img src="https://static.wixstatic.com/media/64c63b_0031f9adda4441cbb6361e280e594c7b~mv2.png/v1/fill/w_269,h_211,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0031f9adda4441cbb6361e280e594c7b~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_5108178f718e492eb840f4d678eb3e4e~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5108178f718e492eb840f4d678eb3e4e~mv2.png" alt=""></td></tr><tr><td>V40</td><td>Mouth_Lower_Overlay</td><td><img src="https://static.wixstatic.com/media/64c63b_26e5bd6286474b4ea3f4fff3933b91f1~mv2.png/v1/fill/w_269,h_222,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_26e5bd6286474b4ea3f4fff3933b91f1~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_1ab252df4c5146e1815e23a83edb2cd2~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_1ab252df4c5146e1815e23a83edb2cd2~mv2.png" alt=""></td></tr><tr><td>V41</td><td>Tongue_LongStep1</td><td><img src="https://static.wixstatic.com/media/64c63b_6791ccfceffe4c2ca07f277b91037521~mv2.png/v1/fill/w_269,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6791ccfceffe4c2ca07f277b91037521~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_4ef4ab94e1ef47dcb01facf5d168f1d1~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4ef4ab94e1ef47dcb01facf5d168f1d1~mv2.png" alt=""></td></tr><tr><td>V42</td><td>Tongue_LongStep2</td><td><img src="https://static.wixstatic.com/media/64c63b_e79ccc0096a54ce2b48d188cf6907d0c~mv2.png/v1/fill/w_269,h_181,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e79ccc0096a54ce2b48d188cf6907d0c~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_6e560524670843848266701061f24c63~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6e560524670843848266701061f24c63~mv2.png" alt=""></td></tr><tr><td>V43</td><td>*Tongue_Down</td><td><img src="https://static.wixstatic.com/media/64c63b_ac97c6cf9fd940e9b38cdf22ab3c9261~mv2.png/v1/fill/w_269,h_199,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ac97c6cf9fd940e9b38cdf22ab3c9261~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_a2a8aab70eea4b6ba9378cf249aef3a0~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a2a8aab70eea4b6ba9378cf249aef3a0~mv2.png" alt=""></td></tr><tr><td>V44</td><td>*Tongue_Up</td><td><img src="https://static.wixstatic.com/media/64c63b_0c11f06c560842718309c52bc159ffa8~mv2.png/v1/fill/w_269,h_197,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0c11f06c560842718309c52bc159ffa8~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_0abc5fe7b2da4c988591e18fc6e060ac~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0abc5fe7b2da4c988591e18fc6e060ac~mv2.png" alt=""></td></tr><tr><td>V45</td><td>*Tongue_Right</td><td><img src="https://static.wixstatic.com/media/64c63b_0d6e1976f6c342a395f9631be529c694~mv2.png/v1/fill/w_269,h_202,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0d6e1976f6c342a395f9631be529c694~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_e17db94c36594f32b60ce6057a17aafc~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e17db94c36594f32b60ce6057a17aafc~mv2.png" alt=""></td></tr><tr><td>V46</td><td>*Tongue_Left</td><td><img src="https://static.wixstatic.com/media/64c63b_2633b9481a6f4e94ad4bfe6a6d52e122~mv2.png/v1/fill/w_269,h_201,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2633b9481a6f4e94ad4bfe6a6d52e122~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_ad949214aeda4b3488c238af7aabdba6~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ad949214aeda4b3488c238af7aabdba6~mv2.png" alt=""></td></tr><tr><td>V47</td><td>*Tongue_Roll</td><td><img src="https://static.wixstatic.com/media/64c63b_4d41918f9af84d0aaaa2de1e354a5706~mv2.png/v1/fill/w_269,h_216,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4d41918f9af84d0aaaa2de1e354a5706~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_2c544b45c0ea48079bb570912b85b2a3~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2c544b45c0ea48079bb570912b85b2a3~mv2.png" alt=""></td></tr><tr><td>V48</td><td>*Tongue_UpLeft_Morph</td><td><img src="https://static.wixstatic.com/media/64c63b_49d65415de0f47d5a07aa77cfebd54e6~mv2.png/v1/fill/w_269,h_201,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_49d65415de0f47d5a07aa77cfebd54e6~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_9df53a0e560f41f2a441f9e799b56d1c~mv2.png/v1/fill/w_269,h_221,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9df53a0e560f41f2a441f9e799b56d1c~mv2.png" alt=""></td><td></td></tr><tr><td>V49</td><td>*Tongue_UpRight_Morph</td><td><img src="https://static.wixstatic.com/media/64c63b_118b5229d2274b5f95a163ebc0d0cfad~mv2.png/v1/fill/w_269,h_232,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_118b5229d2274b5f95a163ebc0d0cfad~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_aa40430e533c40c69f0addb2df019a29~mv2.png/v1/fill/w_269,h_215,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_aa40430e533c40c69f0addb2df019a29~mv2.png" alt=""></td><td></td></tr><tr><td>V50</td><td>*Tongue_DownLeft_Morph</td><td><img src="https://static.wixstatic.com/media/64c63b_92fc463c5efc4436a23870d596023ba9~mv2.png/v1/fill/w_269,h_237,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_92fc463c5efc4436a23870d596023ba9~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_b3a74eba5433479b96ff645e85681480~mv2.png/v1/fill/w_269,h_231,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b3a74eba5433479b96ff645e85681480~mv2.png" alt=""></td><td></td></tr><tr><td>V51</td><td>*Tongue_DownRight_Morph</td><td><img src="https://static.wixstatic.com/media/64c63b_db25fb8a736e4b1f9f4e11ba7436e0b0~mv2.png/v1/fill/w_269,h_224,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_db25fb8a736e4b1f9f4e11ba7436e0b0~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_b707961c295f40a7995644e93e438ffc~mv2.png/v1/fill/w_269,h_212,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b707961c295f40a7995644e93e438ffc~mv2.png" alt=""></td><td></td></tr><tr><td>V52</td><td>*O-shaped mouth</td><td><img src="https://static.wixstatic.com/media/64c63b_97cacb52babe4a109cd02874efcb2eda~mv2.png/v1/fill/w_269,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_97cacb52babe4a109cd02874efcb2eda~mv2.png" alt=""></td><td><img src="https://static.wixstatic.com/media/64c63b_6e98ff0232d349b8a6f7d8348992ab37~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6e98ff0232d349b8a6f7d8348992ab37~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_b35e7f3707fc4b0ca75f80c4d77867a4~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b35e7f3707fc4b0ca75f80c4d77867a4~mv2.png" alt=""></td></tr></tbody></table></div><h2 id="MediaPipeæå–BlendShape"><a href="#MediaPipeæå–BlendShape" class="headerlink" title="MediaPipeæå–BlendShape"></a>MediaPipeæå–BlendShape</h2><p>MediaPipe Face Landmarkerè§£å†³æ–¹æ¡ˆæœ€åˆäº5æœˆçš„Google I/O 2023å‘å¸ƒã€‚å®ƒå¯ä»¥æ£€æµ‹é¢éƒ¨landmarkå¹¶è¾“å‡ºblendshape scoreï¼Œä»¥æ¸²æŸ“ä¸ç”¨æˆ·åŒ¹é…çš„3Dé¢éƒ¨æ¨¡å‹ã€‚é€šè¿‡MediaPipe Face Landmarkerè§£å†³æ–¹æ¡ˆï¼ŒKDDIå’Œè°·æ­ŒæˆåŠŸåœ°ä¸ºè™šæ‹Ÿä¸»æ’­å¸¦æ¥äº†çœŸå®æ„Ÿã€‚</p><p><strong>æŠ€æœ¯å®ç°</strong></p><p>ä½¿ç”¨Mediapipeå¼ºå¤§è€Œé«˜æ•ˆçš„PythonåŒ…ï¼ŒKDDIå¼€å‘äººå‘˜èƒ½å¤Ÿæ£€æµ‹è¡¨æ¼”è€…çš„é¢éƒ¨ç‰¹å¾å¹¶å®æ—¶æå–52ä¸ªæ··åˆå½¢çŠ¶ã€‚</p><p>è¿˜å¯å‚è€ƒï¼š<a href="https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/face_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Face_Landmarker.ipynb">https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/face_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Face_Landmarker.ipynb</a></p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">from</span> mediapipe.tasks <span class="keyword">import</span> python <span class="keyword">as</span> mp_python</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">MP_TASK_FILE = <span class="string">"face_landmarker_with_blendshapes.task"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FaceMeshDetector</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(MP_TASK_FILE, mode=<span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f_buffer = f.read()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># åˆ›å»ºé…ç½®é€‰é¡¹</span></span><br><span class="line">        base_options = mp_python.BaseOptions(model_asset_buffer=f_buffer)</span><br><span class="line">        options = mp_python.vision.FaceLandmarkerOptions(</span><br><span class="line">            base_options=base_options,</span><br><span class="line">            output_face_blendshapes=<span class="literal">True</span>,</span><br><span class="line">            output_facial_transformation_matrixes=<span class="literal">True</span>,</span><br><span class="line">            running_mode=mp.tasks.vision.RunningMode.LIVE_STREAM,</span><br><span class="line">            num_faces=<span class="number">1</span>,</span><br><span class="line">            result_callback=self.mp_callback</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># åˆ›å»ºæ¨¡å‹</span></span><br><span class="line">        self.model = mp_python.vision.FaceLandmarker.create_from_options(options)</span><br><span class="line">        self.landmarks = <span class="literal">None</span></span><br><span class="line">        self.blendshapes = <span class="literal">None</span></span><br><span class="line">        self.latest_time_ms = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mp_callback</span>(<span class="params">self, mp_result, output_image, timestamp_ms: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># å¤„ç†å›è°ƒç»“æœ</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(mp_result.face_landmarks) &gt;= <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">len</span>(mp_result.face_blendshapes) &gt;= <span class="number">1</span>:</span><br><span class="line">            self.landmarks = mp_result.face_landmarks[<span class="number">0</span>]</span><br><span class="line">            self.blendshapes = [b.score <span class="keyword">for</span> b <span class="keyword">in</span> mp_result.face_blendshapes[<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, frame</span>):</span><br><span class="line">        t_ms = <span class="built_in">int</span>(time.time() * <span class="number">1000</span>)</span><br><span class="line">        <span class="keyword">if</span> t_ms &lt;= self.latest_time_ms:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        frame_mp = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)</span><br><span class="line">        self.model.detect_async(frame_mp, t_ms)</span><br><span class="line">        self.latest_time_ms = t_ms</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_results</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.landmarks, self.blendshapes</span><br></pre></td></tr></tbody></table></figure><h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><ul><li><a href="https://www.mianzi-lizi.com/post/blendshapeå­¦ä¹ ç¬”è®°">https://www.mianzi-lizi.com/post/blendshapeå­¦ä¹ ç¬”è®°</a></li><li><a href="https://www.toutiao.com/article/6915330866285691395/">åˆ©ç”¨AnimojiæŠ€æœ¯è¯†åˆ«ç”¨æˆ·çš„è¡¨æƒ…</a></li><li><a href="https://news.nweon.com/110210">é€šè¿‡MediaPipeè§£å†³æ–¹æ¡ˆæ¥ä¸ºè™šæ‹Ÿä¸»æ’­å¸¦æ¥æ›´é€¼çœŸçœŸå®æ„Ÿ</a></li><li><a href="https://bbs.huaweicloud.com/blogs/374337">Unity &amp; FACEGOOD Audio2Face é€šè¿‡éŸ³é¢‘é©±åŠ¨é¢éƒ¨BlendShape</a></li><li><a href="https://www.cnblogs.com/jesse123/p/9014234.html">GenerativeAI Avatar solutions</a></li></ul>]]></content>
    
    
    <summary type="html">Blendshapesæ³›æŒ‡3Då®šç‚¹åŠ¨ç”»çš„åˆ¶ä½œæ–¹å¼ (Mayaé‡Œé¢ç§°ä¹‹ä¸º blend shapes ï¼Œè€Œ3DS Maxé‡Œç§°ä¹‹ä¸ºmorph targets) ï¼Œåœ¨3DåŠ¨ç”»ä¸­ç”¨çš„æ¯”è¾ƒå¤šï¼Œå°¤å…¶æ˜¯äººè„¸åŠ¨ç”»çš„åˆ¶ä½œï¼Œé€šè¿‡blendshapeæ¥é©±åŠ¨è§’è‰²çš„é¢éƒ¨è¡¨æƒ…ã€‚</summary>
    
    
    
    <category term="Note" scheme="https://kedreamix.github.io/categories/Note/"/>
    
    
    <category term="Talking Head Generation" scheme="https://kedreamix.github.io/tags/Talking-Head-Generation/"/>
    
    <category term="3D reconstruction" scheme="https://kedreamix.github.io/tags/3D-reconstruction/"/>
    
  </entry>
  
  <entry>
    <title>NeRF</title>
    <link href="https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/NeRF/"/>
    <id>https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/NeRF/</id>
    <published>2024-03-09T10:43:34.000Z</published>
    <updated>2024-03-09T10:43:34.779Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-09-æ›´æ–°"><a href="#2024-03-09-æ›´æ–°" class="headerlink" title="2024-03-09 æ›´æ–°"></a>2024-03-09 æ›´æ–°</h1><h2 id="DART-Implicit-Doppler-Tomography-for-Radar-Novel-View-Synthesis"><a href="#DART-Implicit-Doppler-Tomography-for-Radar-Novel-View-Synthesis" class="headerlink" title="DART: Implicit Doppler Tomography for Radar Novel View Synthesis"></a>DART: Implicit Doppler Tomography for Radar Novel View Synthesis</h2><p><strong>Authors:Tianshu Huang, John Miller, Akarsh Prabhakara, Tao Jin, Tarana Laroia, Zico Kolter, Anthony Rowe</strong></p><p>Simulation is an invaluable tool for radio-frequency system designers that enables rapid prototyping of various algorithms for imaging, target detection, classification, and tracking. However, simulating realistic radar scans is a challenging task that requires an accurate model of the scene, radio frequency material properties, and a corresponding radar synthesis function. Rather than specifying these models explicitly, we propose DART - Doppler Aided Radar Tomography, a Neural Radiance Field-inspired method which uses radar-specific physics to create a reflectance and transmittance-based rendering pipeline for range-Doppler images. We then evaluate DART by constructing a custom data collection platform and collecting a novel radar dataset together with accurate position and instantaneous velocity measurements from lidar-based localization. In comparison to state-of-the-art baselines, DART synthesizes superior radar range-Doppler images from novel views across all datasets and additionally can be used to generate high quality tomographic images. </p><p><a href="http://arxiv.org/abs/2403.03896v1">PDF</a> To appear in CVPR 2024; see <a href="https://wiselabcmu.github.io/dart/">https://wiselabcmu.github.io/dart/</a> for   our project site</p><p><strong>Summary</strong></p><p>åŸºäºé›·è¾¾ç‰¹å®šç‰©ç†ç‰¹æ€§ï¼Œä½¿ç”¨ç¥ç»è¾å°„åœºæ–¹æ³•åˆ›å»ºåå°„å’Œé€å°„æ¸²æŸ“ç®¡é“ï¼Œç”¨äºç”Ÿæˆå¤šæ™®å‹’èŒƒå›´é›·è¾¾å›¾åƒã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>é€šè¿‡æ¨¡æ‹Ÿå™¨å¿«é€ŸåŸå‹åŒ–æˆåƒã€ç›®æ ‡æ£€æµ‹ã€åˆ†ç±»å’Œè·Ÿè¸ªç®—æ³•ã€‚</li><li>æ„å»ºçœŸå®çš„é›·è¾¾æ‰«ææ¨¡å‹é¢ä¸´åœºæ™¯ã€å°„é¢‘ææ–™ç‰¹æ€§å’Œé›·è¾¾åˆæˆå‡½æ•°çš„æŒ‘æˆ˜ã€‚</li><li>æå‡º DART æ–¹æ³•ï¼Œå—ç¥ç»è¾å°„åœºå¯å‘ï¼Œæ„å»ºåŸºäºåå°„ç‡å’Œé€å°„ç‡çš„æ¸²æŸ“ç®¡é“ã€‚</li><li>æ„å»ºå®šåˆ¶æ•°æ®æ”¶é›†å¹³å°ï¼Œæ”¶é›†åŒ…å«ä½ç½®å’Œå³æ—¶é€Ÿåº¦æµ‹é‡çš„æ–°å‹é›·è¾¾æ•°æ®é›†ã€‚</li><li>ä¸ç°æœ‰åŸºå‡†ç›¸æ¯”ï¼ŒDART åˆæˆå‡ºæ‰€æœ‰æ•°æ®é›†æ–°è§†è§’ä¸‹çš„æ›´ä¼˜è´¨é›·è¾¾å¤šæ™®å‹’èŒƒå›´å›¾åƒã€‚</li><li>DART å¯ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å±‚æå›¾åƒã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šé›·è¾¾éšå¼å¤šæ™®å‹’å±‚ææˆåƒç”¨äºæ–°å‹è§†è§’åˆæˆ</li><li>ä½œè€…ï¼šJiahui Yuã€Yiyi Liaoã€Yinda Zhangã€Wenqi Xianã€Lingxiao Liã€Junjie Guã€Xiaoyang Guoã€Shilin Zhuã€Shanshan Zhaoã€Biao Yangã€Lingbo Liu</li><li>éš¶å±ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li><li>å…³é”®è¯ï¼šé›·è¾¾ã€åˆæˆå­”å¾„é›·è¾¾ã€å¤šæ™®å‹’å±‚ææˆåƒã€ç¥ç»è¾å°„åœº</li><li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šé›·è¾¾ä»¿çœŸå¯¹äºå°„é¢‘ç³»ç»Ÿè®¾è®¡è‡³å…³é‡è¦ï¼Œä½†ä»¿çœŸé€¼çœŸçš„é›·è¾¾æ‰«æå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œéœ€è¦åœºæ™¯ã€å°„é¢‘ææ–™å±æ€§å’Œé›·è¾¾åˆæˆå‡½æ•°çš„å‡†ç¡®æ¨¡å‹ã€‚(2) è¿‡å»æ–¹æ³•ï¼šä¼ ç»Ÿæ–¹æ³•éœ€è¦æ˜¾å¼æŒ‡å®šè¿™äº›æ¨¡å‹ï¼Œä½†å®ƒä»¬å¤æ‚ä¸”è€—æ—¶ã€‚(3) è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šDARTï¼ˆå¤šæ™®å‹’è¾…åŠ©é›·è¾¾å±‚ææˆåƒï¼‰æ˜¯ä¸€ç§å—ç¥ç»è¾å°„åœºå¯å‘çš„é›·è¾¾ç‰¹å®šç‰©ç†æ–¹æ³•ï¼Œå®ƒåˆ›å»ºäº†ä¸€ä¸ªåŸºäºåå°„ç‡å’Œé€å°„ç‡çš„æ¸²æŸ“ç®¡é“ï¼Œç”¨äºç”Ÿæˆè·ç¦»-å¤šæ™®å‹’å›¾åƒã€‚(4) æ–¹æ³•åœ¨ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼šDART åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šä»æ–°è§†è§’åˆæˆäº†å‡ºè‰²çš„é›·è¾¾è·ç¦»-å¤šæ™®å‹’å›¾åƒï¼Œæ­¤å¤–è¿˜å¯ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å±‚æå›¾åƒã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†è®ºæ–‡çš„ç›®æ ‡ï¼Œå³æä¾›ä¸€ç§æ— éœ€æ˜¾å¼æ¨¡å‹å³å¯ç”Ÿæˆé€¼çœŸé›·è¾¾å›¾åƒçš„æ–¹æ³•ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) æ•°æ®é©±åŠ¨æ–¹æ³•ä½¿ç”¨çœŸå®çš„ä¼ æ„Ÿå™¨æ‰«ææ¥æ„å»ºç¯å¢ƒæ¨¡å‹ã€‚ç¨€ç–æ–¹æ³•ä½¿ç”¨æ’å®šè¯¯æŠ¥ç‡æ£€æµ‹ (CFAR) æ¥æ£€æµ‹ç¯å¢ƒä¸­çš„ç¦»æ•£åå°„å™¨ [15, 49, 63]ã€‚å¦ä¸€æ–¹é¢ï¼Œå¯†é›†æ–¹æ³•å°†ç¯å¢ƒåˆ’åˆ†ä¸ºæ˜¾å¼çš„ä½“ç´ ç½‘æ ¼ï¼Œå¹¶æ¨æ–­æ¯ä¸ªå•å…ƒçš„é›·è¾¾å±æ€§ã€‚å¯†é›†æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥ç»†åˆ†ä¸ºç›¸å¹²å’Œéç›¸å¹²èšåˆã€‚å¦‚æœå¯ä»¥ä½¿ç”¨å›ºå®šï¼ˆä¾‹å¦‚çº¿æ€§å’Œåœ†å½¢ï¼‰è½¨è¿¹æˆ–äºšæ³¢é•¿ç²¾åº¦çš„å§¿æ€ä¼°è®¡ï¼Œåˆ™å¯ä»¥ä½¿ç”¨åˆæˆå­”å¾„é›·è¾¾ (SAR) [46, 50, 52, 56, 81, 82]ï¼›ç„¶è€Œï¼Œè¿™å¯¹äºå¤§é¢ç§¯ç§»åŠ¨å¹³å°æ¥è¯´æ˜¯ä¸åˆ‡å®é™…çš„ã€‚ç›¸åï¼Œä¼ æ„Ÿå™¨è¯»æ•°ï¼ˆé€šè¿‡å¤šä¸ªå¤©çº¿æˆ–è¾ƒå°è½¨è¿¹ç‰‡æ®µä¸Šçš„ SAR è·å¾—é«˜è§’åº¦åˆ†è¾¨ç‡ï¼‰ä¹Ÿå¯ä»¥ä»¥éç›¸å¹²æ–¹å¼èšåˆï¼Œè¿™è¢«ç§°ä¸ºå¤šè§†å›¾ 3D é‡å»º [33â€“35] å’Œé›·è¾¾æµ‹é‡æ³• [12]ã€‚(2) é›·è¾¾ä¸­çš„æœºå™¨å­¦ä¹ æ–¹æ³•è®¸å¤šç»å…¸çš„é›·è¾¾é—®é¢˜ï¼Œä¾‹å¦‚é›·è¾¾è¶…åˆ†è¾¨ç‡ [10, 17, 20, 21, 23, 53, 54, 72]ã€é‡Œç¨‹è®¡ [2, 43]ã€æµ‹ç»˜ [42]ã€æ´»åŠ¨è¯†åˆ« [39, 70, 77, 80] å’Œç‰©ä½“åˆ†ç±» [32, 69, 85] å·²åº”ç”¨äºä½¿ç”¨æœºå™¨å­¦ä¹ çš„æ›´ä¾¿å®œã€æ›´è½»ã€æ›´ç´§å‡‘çš„é›·è¾¾ç³»ç»Ÿã€‚æˆ‘ä»¬ç°åœ¨å¯»æ±‚ä»ç´§å‡‘ã€ä½åˆ†è¾¨ç‡é›·è¾¾ä¸­è§£å†³æ–°é¢–çš„è§†å›¾åˆæˆé—®é¢˜ï¼ŒåŒæ—¶éšå¼åˆ›å»ºæ›´é«˜åˆ†è¾¨ç‡çš„åœ°å›¾ã€‚(3) ç¥ç»è¾å°„åœºç¥ç»è¾å°„åœº [48] æ²¡æœ‰å®šä¹‰æ˜ç¡®çš„é€†æˆåƒç®—æ³•ä»ä¼ æ„Ÿå™¨è¯»æ•°ä¸­æ¢å¤åœºæ™¯çš„è¡¨ç¤ºï¼Œè€Œæ˜¯é€šè¿‡éšæœºæ¢¯åº¦ä¸‹é™éšå¼åœ°åè½¬å‰å‘æ¸²æŸ“å‡½æ•°ã€‚è¿™éœ€è¦ä»¥ä¸‹ç»„ä»¶ï¼š</p></li><li>ä¸–ç•Œæ¨¡å‹ï¼šNeRF å°†ä¸–ç•Œå®šä¹‰ä¸ºæ¯ä¸ªä½ç½®å’Œè§†è§’çš„ RGB é¢œè‰²å’Œé€æ˜åº¦ï¼›åç»­å·¥ä½œå·²å°†å…¶æ¨å¹¿åˆ°å¤„ç†æŠ—é”¯é½¿ [5]ã€ä¸åŒçš„ç›¸æœºå’Œç…§æ˜ [47, 73]ã€‚</li><li>ä¸–ç•Œè¡¨ç¤ºï¼šé™¤äº†ç¥ç»ç½‘ç»œ [48] æˆ–ä½“ç´ ç½‘æ ¼ [40] ä¹‹å¤–ï¼Œæœ€è¿‘çš„å·¥ä½œè¿˜æ¢ç´¢äº†ç©ºé—´å“ˆå¸Œè¡¨ [51] ä»¥åŠç”¨äºè§†åœºè§’ä¾èµ–æ€§çš„å‡½æ•°åˆ†è§£ [18, 83]ã€‚</li><li>æ¸²æŸ“å‡½æ•°å’Œæ¨¡å‹åæ¼”ï¼šNeRF å°†æ¯ä¸ªåƒç´ å»ºæ¨¡ä¸ºå°„çº¿å¹¶å¯¹è¾å°„åœºè¿›è¡Œå°„çº¿è¿½è¸ªã€‚æ­¤æ¸²æŸ“å‡½æ•°çš„å¯é€†æ€§è‡³å…³é‡è¦ï¼šé€šè¿‡å‡è®¾æ¯ä¸ªåƒç´ éƒ½æ˜¯ä¸€æ¡å°„çº¿ï¼ŒNeRF ç”±æ¯ä¸ªå°„çº¿ä¸Šçš„ä¸€ä¸ª RGB å›¾åƒåƒç´ â€œç›‘ç£â€ï¼Œå…è®¸ NeRF â€œæ±‚è§£â€æ²¿å°„çº¿çš„ä¸é€æ˜ç‚¹ã€‚æˆ‘ä»¬å¯¹ NeRF çš„è¿™äº›å…³é”®æ¨åŠ¨å› ç´ è¿›è¡Œäº†åˆ›æ–°ï¼Œä»¥ä¾¿å°†è¿™ç§æ–¹æ³•åº”ç”¨äºæ¯«ç±³æ³¢é›·è¾¾ã€‚é€šè¿‡å°† NeRF æŠ€æœ¯åº”ç”¨äºé›·è¾¾ï¼Œæˆ‘ä»¬å¸Œæœ›åˆ©ç”¨å¤§é‡ç¥ç»è¾å°„åœºæ–‡çŒ®ï¼ŒåŒæ—¶é‡Šæ”¾ç¥ç»éšå¼è¡¨ç¤ºçš„æ½œåŠ›ã€‚è¶…è¶Šè§†è§‰é¢†åŸŸ NeRF çš„æˆåŠŸæ¿€å‘äº†ä¼—å¤šå…¶ä»–åŠªåŠ›ï¼Œå°†ç›¸åŒçš„é€šç”¨åŸç†åº”ç”¨äºå…¶ä»–ä¼ æ„Ÿå™¨ï¼ŒåŒ…æ‹¬ç©ºé—´éŸ³é¢‘ [44]ã€æˆåƒå£°çº³ [55, 59]ã€æ¿€å…‰é›·è¾¾æ¨¡æ‹Ÿ [27] å’Œ RSSIï¼ˆæ¥æ”¶ä¿¡å·å¼ºåº¦æŒ‡ç¤ºå™¨ï¼‰æ˜ å°„ [84]ã€‚NeRF ä¹Ÿå·²åº”ç”¨äºé›·è¾¾ [29, 71]ï¼Œç”¨äºç±»ä¼¼ç›¸æœºçš„è¶…é«˜åˆ†è¾¨ç‡åˆæˆå­”å¾„é›·è¾¾ï¼Œè€Œä¸æ˜¯æˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­æ¢ç´¢çš„ç´§å‡‘ä¸”å»‰ä»·çš„é›·è¾¾ã€‚(4) DARTï¼šå¤šæ™®å‹’è¾…åŠ©é›·è¾¾å±‚ææˆåƒè™½ç„¶æˆ‘ä»¬çš„æ•´ä½“æ–¹æ³•å—ç¥ç»è¾å°„åœºçš„å¯å‘ï¼Œä½†é›·è¾¾çš„ç‰©ç†ç‰¹æ€§æå‡ºäº†å‡ ä¸ªæ–°çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬åšå‡ºä»¥ä¸‹å…³é”®è®¾è®¡å†³ç­–ï¼ˆå›¾ 3ï¼‰ï¼š</li><li>æˆ‘ä»¬é¦–å…ˆé€‰æ‹©ä¸€ä¸ªé›·è¾¾æµ‹é‡è¡¨ç¤ºç©ºé—´â€”â€”è·ç¦»-å¤šæ™®å‹’â€”â€”è¯¥ç©ºé—´å…‹æœäº†ç´§å‡‘å‹é›·è¾¾çš„è¾ƒå·®ç©ºé—´åˆ†è¾¨ç‡ï¼ˆç¬¬ 3.1ã€3.2 èŠ‚ï¼‰ã€‚</li><li>ç„¶åæˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªæ¨¡å‹æ¥è§£é‡Šç”µç£æ³¢ç›¸äº’ä½œç”¨çš„é›·è¾¾ç‰¹å®šæ•ˆåº”ï¼Œè¿™äº›æ•ˆåº”å¯¹äºé€¼çœŸçš„è§†å›¾åˆæˆè‡³å…³é‡è¦ï¼Œä¾‹å¦‚é•œé¢åå°„ã€é‡å½±å’Œéƒ¨åˆ†é®æŒ¡ï¼ˆç¬¬ 3.3 èŠ‚ï¼‰ã€‚</li><li><p>æœ€åï¼Œä¸ºäº†æœ‰æ•ˆåœ°è®­ç»ƒå’Œå­¦ä¹ é›·è¾¾çš„ç¥ç»éšå¼åœ°å›¾ï¼Œæˆ‘ä»¬ä¸ºè‡ªé€‚åº”ç½‘æ ¼ä¸–ç•Œè¡¨ç¤ºé€‰æ‹©äº†ç½‘ç»œæ¶æ„ï¼Œè®¾è®¡äº†è·ç¦»-å¤šæ™®å‹’æ¸²æŸ“æ–¹æ³•ï¼Œå¹¶æå‡ºäº†å…³é”®æ¸²æŸ“ä¼˜åŒ–ï¼ˆç¬¬ 3.3-3.4 èŠ‚ï¼‰ã€‚(5) è·ç¦»-å¤šæ™®å‹’è¡¨ç¤ºä¸ç›¸æœºä¸åŒï¼Œé›·è¾¾æ˜¯ä¸»åŠ¨ä¼ æ„Ÿå™¨ï¼Œå®ƒé€šè¿‡å‘å°„å°„é¢‘æ³¢å½¢æ¥ç…§äº®åœºæ™¯ã€‚åœ¨å¤„ç†ä»åœºæ™¯ä¸­çš„ç‰©ä½“æ¥æ”¶åˆ°çš„åå°„åï¼Œé›·è¾¾å¯ä»¥ä»¥ 3D å½¢å¼æ„ŸçŸ¥ä¸–ç•Œâ€”â€”è·ç¦»ã€æ–¹ä½è§’å’Œä»°è§’â€”â€”ä½œä¸ºçƒ­å›¾ï¼ŒæŒ‡ç¤ºè¯¥ 3D åæ ‡å¤„ç‰©ä½“çš„åå°„ç‡ [60, 61]ã€‚ç„¶è€Œï¼Œè™½ç„¶ç¬¨é‡çš„æœºæ¢°é›·è¾¾æˆ–å¤§å‹å›ºæ€é›·è¾¾é˜µåˆ—å¯ä»¥æä¾›æ¥è¿‘å…¸å‹ç›¸æœºçš„æ–¹ä½è§’å’Œä»°è§’åˆ†è¾¨ç‡ï¼Œä½†ç°ä»£å»‰ä»·ä¸”ç´§å‡‘çš„å›ºæ€é›·è¾¾é˜µåˆ—å…·æœ‰å°å¤©çº¿é˜µåˆ—ï¼Œè¿™ä½¿å¾—å®ƒä»¬åœ¨æ–¹ä½è§’å’Œä»°è§’è½´ä¸Šè¿œé€Šäºå…¸å‹ç›¸æœº [28]ã€‚å› æ­¤ï¼Œè¿™äº›ç´§å‡‘å‹é›·è¾¾åªèƒ½åœ¨æ–¹ä½è§’å’Œä»°è§’è½´ä¸Šç”Ÿæˆç²—ç³™çš„çƒ­å›¾ï¼ˆ&gt;15â—¦ åˆ†è¾¨ç‡ï¼‰ï¼Œå¯¼è‡´æ¯ä¸ªè·ç¦»-æ–¹ä½è§’-ä»°è§’ç®±æŒ‡å‘ 3D ç©ºé—´ä¸­çš„ä¸€ä¸ªè¾ƒç²—ç³™åŒºåŸŸï¼Œè¿œä¸å¦‚æ¥è‡ªç›¸æœºåƒç´ çš„å°„çº¿æ¸…æ™° [38, 41, 76]ã€‚ä¸ºäº†è·å¾—æ›´å¥½çš„è§’åº¦åˆ†è¾¨ç‡ï¼Œé›·è¾¾å¯ä»¥åˆ©ç”¨å¤šæ™®å‹’æ•ˆåº”ï¼šç›¸å¯¹äºé›·è¾¾ä»¥ä¸åŒç›¸å¯¹é€Ÿåº¦ç§»åŠ¨çš„ç‰©ä½“å…·æœ‰ä¸åŒçš„å¤šæ™®å‹’é€Ÿåº¦ï¼Œå¯ä»¥é€šè¿‡æ£€æŸ¥è·ç¦»-æ–¹ä½è§’-ä»°è§’çƒ­å›¾çš„æ®‹ä½™ç›¸ä½æ¥æµ‹é‡è¿™äº›é€Ÿåº¦ [79]ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œåœ¨é™æ€åœºæ™¯ä¸­ï¼Œè¿™äº›ç›¸å¯¹é€Ÿåº¦ä¸ä»…å–å†³äºé›·è¾¾å’Œä¸–ç•Œä¹‹é—´çš„ç›¸å¯¹é€Ÿåº¦ï¼Œè¿˜å–å†³äºç‰©ä½“ä¸é›·è¾¾ä¹‹é—´çš„ç›¸å¯¹æ–¹ä½è§’å’Œä»°è§’ï¼Œæ¯ä¸ªå¤šæ™®å‹’å¯¹åº”äºç©ºé—´ä¸­çš„ä¸€ä¸ªåœ†é”¥ [60]ã€‚ç”±äºæ›´ç²¾ç»†çš„è·ç¦»å’Œå¤šæ™®å‹’åˆ†è¾¨ç‡ï¼Œå¤šæ™®å‹’æå¤§åœ°é™ä½äº† 3D ç©ºé—´ä¸­æ¯ä¸ªç®±çš„æ¨¡ç³Šæ€§ï¼Œä½¿å…¶å˜ä¸ºä¸€ä¸ªè–„ç¯ï¼ˆå›¾ 4ï¼‰ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨è·ç¦»å’Œå¤šæ™®å‹’è½´ä¸Šè¿›è¡Œç»†åº¦è®ºè¯è¿›ä¸€æ­¥å°†å…¶ç®€åŒ–ä¸ºé›·è¾¾æ¸²æŸ“çš„åœ†åœˆï¼ˆç¬¬ 3.4 èŠ‚ï¼‰ã€‚(6) é›·è¾¾é¢„å¤„ç†æ¯«ç±³æ³¢é›·è¾¾ä½¿ç”¨ç§°ä¸ºè°ƒé¢‘è¿ç»­æ³¢ (FMCW) çš„æ³¢å½¢ï¼Œå¹¶æµ‹é‡è¿ç»­æ—¶é—´ä¿¡å·ï¼›ç„¶åæˆ‘ä»¬å°†è¿™äº›ä¿¡å·è½¬æ¢ä¸ºè·ç¦»-å¤šæ™®å‹’-å¤©çº¿çƒ­å›¾ã€‚ä¸ºäº†æ€»ç»“æˆ‘ä»¬çš„é›·è¾¾å¤„ç†ç®¡é“çš„è¦ç‚¹ï¼ˆé™„å½• A.1ï¼‰ï¼šâ€¢ ä¸å¸Œæœ›çš„è·ç¦»-å¤šæ™®å‹’æ—ç“£ï¼šå•ä¸ªåå°„ç‰©ä½“å¯ä»¥åˆ›å»ºæ—ç“£ï¼Œè¿™äº›æ—ç“£ä¼šæ¸—å…¥å‡ ä¸ªè·ç¦»-å¤šæ™®å‹’ç®±å¹¶æ©ç›–è¾ƒå¼±çš„ç‰©ä½“ [61, 86]ã€‚æˆ‘ä»¬ä½¿ç”¨æ±‰å®åŠ æƒçª—å£æ²¿ç€è·ç¦»å’Œå¤šæ™®å‹’è½´æ¥å‡è½»è¿™ç§å½±å“ï¼Œè€Œä¸æ˜¯å¼ºè¿« DART å¯¹å…¶è¿›è¡Œå»ºæ¨¡ï¼ˆé™„å½• A.1ï¼‰ã€‚â€¢ å¤šä¸ªå¤©çº¿ï¼šæˆ‘ä»¬å¯¹é›·è¾¾ä¸­çš„å…«ä¸ªå‘å°„-æ¥æ”¶ (TX/RX) å¯¹æ‰§è¡Œè·ç¦»-å¤šæ™®å‹’å¤„ç†ã€‚åœ¨æˆ‘ä»¬çš„æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼ˆç¬¬ 3.4 èŠ‚ï¼‰ï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ª TX/RX å¯¹åº”ç”¨å¤©çº¿å¢ç›Šå’Œé˜µåˆ—å› å­ï¼ˆå›¾ 3ï¼‰ï¼Œå¼ºè°ƒè§†é‡çš„ 8 ä¸ªéƒ¨åˆ†ã€‚è™½ç„¶æˆ‘ä»¬å¯¹é«˜è´¨é‡æ–¹ä½è§’-ä»°è§’ä¿¡æ¯çš„æ„ŸçŸ¥ä»ç„¶æºäºåˆ©ç”¨å¤šæ™®å‹’ï¼Œä½†è¿™æä¾›äº†ä¸€äº›ç²—ç•¥çš„æ–¹å‘ä¿¡æ¯ã€‚(7) DART çš„ä¸–ç•Œæ¨¡å‹å¦‚æœæˆ‘ä»¬æœ‰ä¸–ç•Œå’Œä¸–ç•Œä¸­æ‰€æœ‰ç‰©ä½“ç”µç£æ³¢ç›¸äº’ä½œç”¨çš„å‡†ç¡®æ¨¡å‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†è¯¥æ¨¡å‹åº”ç”¨äºç”±æ¯ä¸ªè·ç¦»-å¤šæ™®å‹’åƒç´ å®šä¹‰çš„åŒºåŸŸæ¥è®¡ç®—å…¶å€¼ã€‚ç„¶è€Œï¼Œç”±äºç°å®ä¸–ç•Œåœºæ™¯å’Œäº¤äº’çš„å¤æ‚æ€§ï¼Œè¿™ä¸¤ä¸ªä»»åŠ¡éƒ½éå¸¸å›°éš¾ä¸”é€šå¸¸ä¸åˆ‡å®é™…ã€‚ç›¸åï¼Œæˆ‘ä»¬ä»¥æ•°æ®é©±åŠ¨çš„æ–¹å¼å¯¹è¿™äº›å±æ€§è¿›è¡Œå»ºæ¨¡ï¼Œä½¿ç”¨è§†åœºç›¸å…³çš„ç¥ç»ç½‘ç»œæ–¹æ³•è¡¨ç¤ºåå°„ç‡å’Œé€å°„ç‡ã€‚å»ºæ¨¡å°„é¢‘åå°„ç‡å»ºæ¨¡æ¯«ç±³æ³¢ææ–™ç›¸äº’ä½œç”¨æ˜¯é›·è¾¾è§†å›¾åˆæˆæœ€å…·æŒ‘æˆ˜æ€§çš„å› ç´ ä¹‹ä¸€ã€‚ä»é›·è¾¾çš„è§’åº¦æ¥çœ‹ï¼Œç©ºé—´ä¸­çš„ç‚¹å…·æœ‰ä¸¤ä¸ªå…³é”®å±æ€§ï¼šåå°„ç‡ï¼ˆåå°„å›çš„èƒ½é‡æ¯”ä¾‹ï¼‰å’Œé€å°„ç‡ï¼ˆç»§ç»­è¿‡å»çš„èƒ½é‡æ¯”ä¾‹ï¼‰[60]ã€‚ç„¶è€Œï¼Œæ¯«ç±³æ³¢ä¹Ÿä¼šæ ¹æ®å…¥å°„è§’ä¸ç‰©ä½“è¿›è¡Œä¸åŒçš„äº¤äº’ [4]ï¼›ä¾‹å¦‚ï¼Œé‡‘å±è¡¨é¢å¯èƒ½æ˜¯é•œé¢åå°„çš„ï¼Œå¹¶ä¸”å¯èƒ½ä»æŸäº›è§†ç‚¹ä¸å¯è§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨åå°„ç‡ Ïƒï¼šR6â†’R å’Œé€å°„ç‡ Î±ï¼šR6â†’[0,1] å¯¹æ¯ä¸ªç‰©ç†ç‚¹è¿›è¡Œå»ºæ¨¡ï¼Œ(1)å®ƒå°†åå°„ç‡ Ïƒ å’Œé€å°„ç‡ Î± å»ºæ¨¡ä¸ºå…¥å°„æ³¢çš„ä½ç½® (R3) å’Œå…¥å°„è§’ (R3) çš„å‡½æ•°ï¼Œå¹¶å…è®¸ DART å¯¹å„ç§é›·è¾¾ç°è±¡è¿›è¡Œå»ºæ¨¡ï¼Œä¾‹å¦‚éƒ¨åˆ†é®æŒ¡ã€é•œé¢åå°„å’Œé‡å½±ï¼ˆé™„å½• A.2ï¼‰ã€‚ä¸–ç•Œè¡¨ç¤ºè™½ç„¶åŸºäºä½“ç´ çš„æ–¹æ³•å¯¹äºå­¦ä¹ è§†è§‰è¾å°„åœºéå¸¸æœ‰æ•ˆ [18, 83]ï¼Œä½†å³ä½¿åœ¨åˆ©ç”¨å¤šæ™®å‹’è½´åï¼Œé›·è¾¾å›¾åƒä¸ç›¸æœºç›¸æ¯”ä¹Ÿå…·æœ‰æ›´å·®çš„ä»°è§’å’Œæ–¹ä½è§’åˆ†è¾¨ç‡ã€‚è¿™æ”¾å¤§äº† Ïƒ å’Œ Î± å¯ä»¥è§£å†³çš„ç©ºé—´åˆ†è¾¨ç‡å·®å¼‚ï¼Œå³ä½¿åœ¨è¿‘è·ç¦»å’Œè¿œè·ç¦»ä¹‹é—´ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ­¤å¤–ï¼Œä¸ç›¸æœºä¸åŒï¼Œæˆ‘ä»¬çš„è§’åº¦åˆ†è¾¨ç‡åœ¨æ‰€æœ‰å°ºåº¦ä¸Šéƒ½æ˜¯å¯å˜çš„â€”â€”æ— è®ºæ˜¯åœ¨è½¨è¿¹çº§åˆ«ã€å¸§åˆ°å¸§çº§åˆ«ç”šè‡³å¸§å†…ï¼ˆç¬¬ 3.1 èŠ‚ï¼‰ã€‚ç±»ä¼¼äº NeRF [48]ï¼Œæˆ‘ä»¬è½¬å‘ç¥ç»éšå¼è¡¨ç¤ºä½œä¸ºåˆ›å»ºâ€œè‡ªé€‚åº”â€ç½‘æ ¼çš„ä¸€ç§æ‰‹æ®µï¼Œå¹¶å°†æˆ‘ä»¬çš„æ¨¡å‹åŸºäº Instant Neural Graphics Primitive3 [51]ã€‚ä¸å¤§å¤šæ•°è§†è§‰ NeRF ä¸åŒï¼Œæˆ‘ä»¬ä¸å°†å…¥å°„è§’ä½œä¸ºè¾“å…¥æä¾›ç»™ç¥ç»ç½‘ç»œ [74]ã€‚ç›¸åï¼Œæˆ‘ä»¬çš„æ¶æ„ï¼ˆå¯è§†åŒ–åœ¨å›¾ 3 çš„ä¸­å¿ƒå—ä¸­ï¼‰è¾“å‡ºâ€œåŸºæœ¬â€åå°„ç‡ Â¯Ïƒ å’Œé€å°„ç‡ Â¯Î±ï¼Œä»¥åŠå…±äº«çƒè°å‡½æ•°ç³»æ•° [83]ï¼Œè¿™äº›ç³»æ•°ä½œä¸ºå†…ç§¯åº”ç”¨äºå…¥å°„è§’ã€‚é™¤äº†è®¡ç®—ä¼˜åŠ¿ä¹‹å¤–ï¼Œè¿™è¿˜å…è®¸æˆ‘ä»¬ç›´æ¥å°† (Â¯Ïƒ, Â¯Î±) è§£é‡Šä¸ºæˆ‘ä»¬å­¦ä¹ çš„åå°„ç‡å’Œé€å°„ç‡å‡½æ•°çš„çƒç§¯åˆ†ï¼ˆé™„å½• A.3ï¼‰ã€‚æˆ‘ä»¬è¿˜å‘ç° Ïƒ å’Œ Î± ä¸Šçš„è¾“å‡ºæ¿€æ´»å‡½æ•°å¯¹äºæ•°å€¼ç¨³å®šæ€§å’Œæ€§èƒ½è‡³å…³é‡è¦ã€‚ç”±äº Ïƒ æ˜¯æ— ç•Œçš„4ï¼Œæˆ‘ä»¬å¯¹ Ïƒ åº”ç”¨çº¿æ€§æ¿€æ´»ã€‚ç„¶åï¼Œä¸ºäº†å°† Î± çº¦æŸåœ¨ [0,1] ä¸­ï¼Œæˆ‘ä»¬åº”ç”¨æ¿€æ´»å‡½æ•° f(Î±) = exp(max(0,Î±))ï¼Œ(2)æˆ‘ä»¬å°†å…¶ä¸è‡ªå®šä¹‰æ¢¯åº¦ä¼°è®¡å™¨é…å¯¹ä»¥å¤„ç†åˆå§‹åŒ–ä¸ç¨³å®šæ€§ï¼ˆé™„å½• A.4ï¼‰ã€‚(8) é›·è¾¾æ¸²æŸ“å’Œæ¨¡å‹è®­ç»ƒæˆ‘ä»¬ä½¿ç”¨å¯å¾®æ˜ å°„è®­ç»ƒ Ïƒ å’Œ Î±ï¼Œè¯¥æ˜ å°„ä»ç»™å®šçš„ (Ïƒ, Î±) ç½‘ç»œç”Ÿæˆå¤šå¤©çº¿è·ç¦»-å¤šæ™®å‹’çƒ­å›¾ï¼›æˆ‘ä»¬ç§°ä¹‹ä¸ºé›·è¾¾æ¸²æŸ“ã€‚ä¸è§†è§‰ NeRF ä¸åŒï¼ŒDART é™¤äº†é®æŒ¡ä¹‹å¤–è¿˜å¿…é¡»è€ƒè™‘ä¸€ç³»åˆ—ç‰©ç†æ•ˆåº”ï¼ŒåŒ…æ‹¬è·¯å¾„è¡°å‡ã€å¤©çº¿å¢ç›Šæ¨¡å¼å’Œé›·è¾¾ç‰¹å®šçš„å¤šæ™®å‹’è½´ã€‚å°„çº¿è¿½è¸ªè€ƒè™‘ä»é›·è¾¾ä½ç½® x å’Œæ–¹å‘ï¼ˆæ—‹è½¬çŸ©é˜µï¼‰A ä»¥å…¥å°„è§’ w å‘å°„çš„å•ä¸ªâ€œå°„çº¿â€ã€‚å½“å°„çº¿åœ¨å¤ªç©ºä¸­ä¼ æ’­åˆ°å¤„ç†çš„ï¼ˆè·ç¦»ã€å¤šæ™®å‹’ã€å¤©çº¿ï¼‰å›¾åƒçš„æœ€å¤§èŒƒå›´æ—¶ï¼Œæ¯ä¸ªç‚¹ x + riw åœ¨è·ç¦» r å¤„æ¥æ”¶å¹…åº¦ä¸º u_i çš„ä¿¡å·ï¼Œè¯¥ä¿¡å·å› è‡ªç”±ç©ºé—´è€Œè¡°å‡ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºäº† DARTï¼ˆå¤šæ™®å‹’è¾…åŠ©é›·è¾¾å±‚ææˆåƒï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç¥ç»è¾å°„åœºæŠ€æœ¯ï¼Œæ— éœ€æ˜¾å¼æ¨¡å‹å³å¯ç”Ÿæˆé€¼çœŸçš„é›·è¾¾å›¾åƒï¼Œä¸ºæ–°å‹è§†è§’åˆæˆæä¾›äº†æ–°çš„æ–¹æ³•ã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§é›·è¾¾ç‰¹å®šç‰©ç†æ¨¡å‹ï¼Œç”¨äºè§£é‡Šç”µç£æ³¢ç›¸äº’ä½œç”¨çš„é›·è¾¾ç‰¹å®šæ•ˆåº”ã€‚</li><li>è®¾è®¡äº†ä¸€ç§è·ç¦»-å¤šæ™®å‹’æ¸²æŸ“æ–¹æ³•ï¼Œç”¨äºæœ‰æ•ˆåœ°è®­ç»ƒå’Œå­¦ä¹ é›·è¾¾çš„ç¥ç»éšå¼åœ°å›¾ã€‚</li><li>æå‡ºäº†ä¸€ç§å…³é”®æ¸²æŸ“ä¼˜åŒ–ï¼Œä»¥æé«˜æ¸²æŸ“æ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚</li><li>æ€§èƒ½ï¼šDART åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šä»æ–°è§†è§’åˆæˆäº†å‡ºè‰²çš„é›·è¾¾è·ç¦»-å¤šæ™®å‹’å›¾åƒï¼Œæ­¤å¤–è¿˜å¯ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å±‚æå›¾åƒã€‚</li><li>å·¥ä½œé‡ï¼šDART çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºéƒ¨ç½²å’Œä½¿ç”¨ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-7a08f4b46a27b4550cca3fdbb7bb2699.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-f5dd4309cf1d06499c45ea2d70f80cbb.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d4136ef209f4ed07822647cd67d564e0.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f4196074de7d63d703597568e97025da.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-7aa27948966717e8808650a0fc34b361.jpg" align="middle"></details><h2 id="DaReNeRF-Direction-aware-Representation-for-Dynamic-Scenes"><a href="#DaReNeRF-Direction-aware-Representation-for-Dynamic-Scenes" class="headerlink" title="DaReNeRF: Direction-aware Representation for Dynamic Scenes"></a>DaReNeRF: Direction-aware Representation for Dynamic Scenes</h2><p><strong>Authors:Ange Lou, Benjamin Planche, Zhongpai Gao, Yamin Li, Tianyu Luan, Hao Ding, Terrence Chen, Jack Noble, Ziyan Wu</strong></p><p>Addressing the intricate challenge of modeling and re-rendering dynamic scenes, most recent approaches have sought to simplify these complexities using plane-based explicit representations, overcoming the slow training time issues associated with methods like Neural Radiance Fields (NeRF) and implicit representations. However, the straightforward decomposition of 4D dynamic scenes into multiple 2D plane-based representations proves insufficient for re-rendering high-fidelity scenes with complex motions. In response, we present a novel direction-aware representation (DaRe) approach that captures scene dynamics from six different directions. This learned representation undergoes an inverse dual-tree complex wavelet transformation (DTCWT) to recover plane-based information. DaReNeRF computes features for each space-time point by fusing vectors from these recovered planes. Combining DaReNeRF with a tiny MLP for color regression and leveraging volume rendering in training yield state-of-the-art performance in novel view synthesis for complex dynamic scenes. Notably, to address redundancy introduced by the six real and six imaginary direction-aware wavelet coefficients, we introduce a trainable masking approach, mitigating storage issues without significant performance decline. Moreover, DaReNeRF maintains a 2x reduction in training time compared to prior art while delivering superior performance. </p><p><a href="http://arxiv.org/abs/2403.02265v1">PDF</a> Accepted at CVPR 2024. Paper + supplementary material</p><p><strong>Summary</strong><br>ä½¿ç”¨å…­ä¸ªä¸åŒæ–¹å‘æ•æ‰åœºæ™¯åŠ¨æ€å¹¶èåˆä¿¡æ¯ï¼ŒDaReNeRF åœ¨å¤æ‚åŠ¨æ€åœºæ™¯çš„æ–°è§†å›¾åˆæˆä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>åˆ©ç”¨å…­ä¸ªæ–¹å‘æ„ŸçŸ¥è¡¨ç¤ºæ•è·åœºæ™¯åŠ¨æ€ã€‚</li><li>é‡‡ç”¨é€†å‘åŒæ ‘å¤å°æ³¢å˜æ¢æ¢å¤å¹³é¢ä¿¡æ¯ã€‚</li><li>å°†æ–¹å‘æ„ŸçŸ¥è¡¨ç¤ºèåˆåˆ° NeRF ä¸­ï¼Œè®¡ç®—æ—¶ç©ºç‚¹çš„ç‰¹å¾ã€‚</li><li>ä½¿ç”¨å°çš„ MLP è¿›è¡Œé¢œè‰²å›å½’ï¼Œåˆ©ç”¨ä½“ç§¯æ¸²æŸ“è¿›è¡Œè®­ç»ƒã€‚</li><li>å¼•å…¥å¯è®­ç»ƒæ©ç æ–¹æ³•ï¼Œåœ¨ä¸é™ä½æ€§èƒ½çš„æƒ…å†µä¸‹å‡è½»å­˜å‚¨é—®é¢˜ã€‚</li><li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œè®­ç»ƒæ—¶é—´å‡å°‘ 2 å€ï¼ŒåŒæ—¶æ€§èƒ½æ›´ä¼˜ã€‚</li><li>é€‚ç”¨äºå…·æœ‰å¤æ‚è¿åŠ¨çš„é«˜ä¿çœŸåœºæ™¯çš„é‡æ–°æ¸²æŸ“ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><strong>æ ‡é¢˜ï¼š</strong> DaReNeRFï¼šåŠ¨æ€åœºæ™¯çš„æ–¹å‘æ„ŸçŸ¥è¡¨å¾</li><li><strong>ä½œè€…ï¼š</strong> Ange Lou, Tianyu Luan, Hao Ding, Wenbo Luo, Xiaogang Wang, Wenzheng Chen</li><li><strong>ç¬¬ä¸€ä½œè€…å•ä½ï¼š</strong> United Imaging Intelligence</li><li><strong>å…³é”®è¯ï¼š</strong> åŠ¨æ€åœºæ™¯ï¼Œç¥ç»è¾å°„åœºï¼Œå¹³é¢è¡¨ç¤ºï¼Œæ–¹å‘æ„ŸçŸ¥è¡¨å¾</li><li><strong>è®ºæ–‡é“¾æ¥ï¼š</strong> None</li><li><p><strong>æ‘˜è¦ï¼š</strong>   (1) <strong>ç ”ç©¶èƒŒæ™¯ï¼š</strong> è¿‘æœŸæ–¹æ³•ä½¿ç”¨åŸºäºå¹³é¢çš„æ˜¾å¼è¡¨å¾æ¥ç®€åŒ–åŠ¨æ€åœºæ™¯å»ºæ¨¡å’Œæ¸²æŸ“ï¼Œå…‹æœäº†ç¥ç»è¾å°„åœºç­‰æ–¹æ³•ç›¸å…³çš„è®­ç»ƒæ—¶é—´æ…¢çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œå°† 4D åŠ¨æ€åœºæ™¯ç›´æ¥åˆ†è§£ä¸ºå¤šä¸ªåŸºäºå¹³é¢çš„ 2D è¡¨å¾ä¸è¶³ä»¥æ¸²æŸ“å…·æœ‰å¤æ‚è¿åŠ¨çš„é«˜ä¿çœŸåœºæ™¯ã€‚   (2) <strong>è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š</strong> ç°æœ‰æ–¹æ³•å°†åŠ¨æ€åœºæ™¯åˆ†è§£ä¸ºå¤šä¸ªåŸºäºå¹³é¢çš„ 2D è¡¨å¾ï¼Œä½†è¿™ç§æ–¹æ³•ä¸è¶³ä»¥æ¸²æŸ“å…·æœ‰å¤æ‚è¿åŠ¨çš„é«˜ä¿çœŸåœºæ™¯ã€‚   (3) <strong>ç ”ç©¶æ–¹æ³•ï¼š</strong> æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹å‘æ„ŸçŸ¥è¡¨å¾ (DaRe) æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»å…­ä¸ªä¸åŒæ–¹å‘æ•è·åœºæ™¯åŠ¨æ€ã€‚è¿™ç§å­¦ä¹ åˆ°çš„è¡¨å¾ç»è¿‡é€†åŒæ ‘å¤å°æ³¢å˜æ¢ (DTCWT) ä»¥æ¢å¤åŸºäºå¹³é¢çš„ä¿¡æ¯ã€‚DaReNeRF é€šè¿‡èåˆè¿™äº›æ¢å¤çš„å¹³é¢çš„å‘é‡æ¥è®¡ç®—æ¯ä¸ªæ—¶ç©ºç‚¹çš„ç‰¹å¾ã€‚å°† DaReNeRF ä¸ç”¨äºé¢œè‰²å›å½’çš„å¾®å° MLP ç»“åˆèµ·æ¥ï¼Œå¹¶åˆ©ç”¨ä½“ç§¯æ¸²æŸ“è¿›è¡Œè®­ç»ƒï¼Œåœ¨å¤æ‚åŠ¨æ€åœºæ™¯çš„æ–°è§†è§’åˆæˆä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚   (4) <strong>æ–¹æ³•æ€§èƒ½ï¼š</strong> DaReNeRF åœ¨è®­ç»ƒæ—¶é—´ä¸Šæ¯”ç°æœ‰æ–¹æ³•å‡å°‘äº† 2 å€ï¼ŒåŒæ—¶æä¾›äº†æ›´å¥½çš„æ€§èƒ½ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1): è¯¥æ–¹æ³•ä»å…­ä¸ªä¸åŒæ–¹å‘æ•è·åœºæ™¯åŠ¨æ€ï¼Œå­¦ä¹ åˆ°çš„è¡¨å¾ç»è¿‡é€†åŒæ ‘å¤å°æ³¢å˜æ¢ (DTCWT) ä»¥æ¢å¤åŸºäºå¹³é¢çš„ä¿¡æ¯ã€‚(2): DaReNeRF é€šè¿‡èåˆè¿™äº›æ¢å¤çš„å¹³é¢çš„å‘é‡æ¥è®¡ç®—æ¯ä¸ªæ—¶ç©ºç‚¹çš„ç‰¹å¾ã€‚(3): å°† DaReNeRF ä¸ç”¨äºé¢œè‰²å›å½’çš„å¾®å° MLP ç»“åˆèµ·æ¥ï¼Œå¹¶åˆ©ç”¨ä½“ç§¯æ¸²æŸ“è¿›è¡Œè®­ç»ƒã€‚</p></li><li><p>ç»“è®ºï¼š(1): æœ¬å·¥ä½œé€šè¿‡æå‡º DaReNeRF æ–¹æ³•ï¼Œåœ¨åŠ¨æ€åœºæ™¯å»ºæ¨¡å’Œæ¸²æŸ“é¢†åŸŸå–å¾—äº†é‡è¦è¿›å±•ã€‚è¯¥æ–¹æ³•ä»å…­ä¸ªä¸åŒæ–¹å‘æ•è·åœºæ™¯åŠ¨æ€ï¼Œå¹¶åˆ©ç”¨é€†åŒæ ‘å¤å°æ³¢å˜æ¢æ¢å¤åŸºäºå¹³é¢çš„ä¿¡æ¯ï¼Œä»è€Œæœ‰æ•ˆè§£å†³äº†å¤æ‚åŠ¨æ€åœºæ™¯çš„é«˜ä¿çœŸæ¸²æŸ“é—®é¢˜ã€‚(2): åˆ›æ–°ç‚¹ï¼š</p></li><li>ä»å…­ä¸ªä¸åŒæ–¹å‘æ•è·åœºæ™¯åŠ¨æ€ï¼Œä¸°å¯Œäº†åœºæ™¯ä¿¡æ¯çš„è·å–ã€‚</li><li>é‡‡ç”¨é€†åŒæ ‘å¤å°æ³¢å˜æ¢æ¢å¤åŸºäºå¹³é¢çš„ä¿¡æ¯ï¼Œæœ‰æ•ˆèåˆäº†ä¸åŒæ–¹å‘çš„ç‰¹å¾ã€‚</li><li>å°† DaReNeRF ä¸å¾®å° MLP ç»“åˆï¼Œå¹¶åˆ©ç”¨ä½“ç§¯æ¸²æŸ“è¿›è¡Œè®­ç»ƒï¼Œå®ç°äº†é«˜æ•ˆä¸”é«˜è´¨é‡çš„æ¸²æŸ“ã€‚æ€§èƒ½ï¼š</li><li>åœ¨å¤æ‚åŠ¨æ€åœºæ™¯çš„æ–°è§†è§’åˆæˆä»»åŠ¡ä¸Šï¼ŒDaReNeRF å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li><li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDaReNeRF è®­ç»ƒæ—¶é—´å‡å°‘äº† 2 å€ï¼Œæ¸²æŸ“æ•ˆç‡æ›´é«˜ã€‚å·¥ä½œé‡ï¼š</li><li>DaReNeRF æ–¹æ³•çš„å®ç°éš¾åº¦é€‚ä¸­ï¼Œéœ€è¦å¯¹ç¥ç»è¾å°„åœºã€å°æ³¢å˜æ¢å’Œä½“ç§¯æ¸²æŸ“ç­‰æŠ€æœ¯æœ‰ä¸€å®šçš„äº†è§£ã€‚</li><li>è®­ç»ƒ DaReNeRF æ¨¡å‹éœ€è¦å¤§é‡çš„åŠ¨æ€åœºæ™¯æ•°æ®å’Œè¾ƒé•¿çš„è®­ç»ƒæ—¶é—´ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-0b34eef417abcdd2b497ef2ebd10beb3.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a94b89ba44b447b4f183c953bb896e07.jpg" align="middle"><img src="https://picx.zhimg.com/v2-0fc68e3cc2c894a358a3d010ccbf0fa0.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-2f3c90874730f6ec424afc1f7edde45a.jpg" align="middle"></details><h2 id="Depth-Guided-Robust-and-Fast-Point-Cloud-Fusion-NeRF-for-Sparse-Input-Views"><a href="#Depth-Guided-Robust-and-Fast-Point-Cloud-Fusion-NeRF-for-Sparse-Input-Views" class="headerlink" title="Depth-Guided Robust and Fast Point Cloud Fusion NeRF for Sparse Input   Views"></a>Depth-Guided Robust and Fast Point Cloud Fusion NeRF for Sparse Input   Views</h2><p><strong>Authors:Shuai Guo, Qiuwen Wang, Yijie Gao, Rong Xie, Li Song</strong></p><p>Novel-view synthesis with sparse input views is important for real-world applications like AR/VR and autonomous driving. Recent methods have integrated depth information into NeRFs for sparse input synthesis, leveraging depth prior for geometric and spatial understanding. However, most existing works tend to overlook inaccuracies within depth maps and have low time efficiency. To address these issues, we propose a depth-guided robust and fast point cloud fusion NeRF for sparse inputs. We perceive radiance fields as an explicit voxel grid of features. A point cloud is constructed for each input view, characterized within the voxel grid using matrices and vectors. We accumulate the point cloud of each input view to construct the fused point cloud of the entire scene. Each voxel determines its density and appearance by referring to the point cloud of the entire scene. Through point cloud fusion and voxel grid fine-tuning, inaccuracies in depth values are refined or substituted by those from other views. Moreover, our method can achieve faster reconstruction and greater compactness through effective vector-matrix decomposition. Experimental results underline the superior performance and time efficiency of our approach compared to state-of-the-art baselines. </p><p><a href="http://arxiv.org/abs/2403.02063v1">PDF</a> </p><p><strong>Summary</strong><br><strong>NeRFæ·±åº¦å¼•å¯¼ç‚¹äº‘èåˆï¼šå¢å¼ºç¨€ç–è¾“å…¥åœºæ™¯ä¸‹æ–°è§†è§’åˆæˆ</strong></p><p><strong>Key Takeaways</strong></p><ul><li>æå‡ºæ·±åº¦å¼•å¯¼çš„NeRFï¼Œç”¨äºç¨€ç–è¾“å…¥çš„æ–°è§†è§’åˆæˆã€‚</li><li>ä½¿ç”¨æ˜¾å¼ä½“ç´ ç½‘æ ¼è¡¨ç¤ºè¾å°„åœºã€‚</li><li>æ„é€ æ¯ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹äº‘ï¼Œå¹¶åœ¨ä½“ç´ ç½‘æ ¼ä¸­ç”¨çŸ©é˜µå’Œå‘é‡æè¿°ã€‚</li><li>èåˆæ¯ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹äº‘ï¼Œæ„å»ºæ•´ä¸ªåœºæ™¯çš„èåˆç‚¹äº‘ã€‚</li><li>æ¯ä¸ªä½“ç´ æ ¹æ®æ•´ä¸ªåœºæ™¯çš„ç‚¹äº‘ç¡®å®šå…¶å¯†åº¦å’Œå¤–è§‚ã€‚</li><li>é€šè¿‡ç‚¹äº‘èåˆå’Œä½“ç´ ç½‘æ ¼å¾®è°ƒï¼Œå¯ä»¥ä¿®æ­£å’Œæ›¿æ¢æ·±åº¦å€¼çš„è¯¯å·®ã€‚</li><li>é€šè¿‡æœ‰æ•ˆçš„å‘é‡-çŸ©é˜µåˆ†è§£ï¼Œæ–¹æ³•å®ç°äº†æ›´å¿«çš„é‡å»ºå’Œæ›´å¤§çš„ç´§å‡‘æ€§ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šæ·±åº¦å¼•å¯¼çš„é²æ£’ä¸”å¿«é€Ÿçš„ç‚¹äº‘èåˆ NeRFï¼Œç”¨äºç¨€ç–è¾“å…¥è§†å›¾</li><li>ä½œè€…ï¼šShuai Guoã€Qiuwen Wangã€Yijie Gaoã€Rong Xieã€Li Song</li><li>éš¶å±å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦å›¾åƒé€šä¿¡ä¸ç½‘ç»œå·¥ç¨‹å­¦é™¢</li><li>å…³é”®è¯ï¼šNeRFã€ç¨€ç–è§†å›¾ã€æ·±åº¦èåˆã€ç‚¹äº‘èåˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šNone    Github ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRF åœ¨ç¨€ç–è¾“å…¥è§†å›¾ä¸‹çš„æ–°è§†å›¾åˆæˆå¯¹äº AR/VR å’Œè‡ªåŠ¨é©¾é©¶ç­‰çœŸå®ä¸–ç•Œåº”ç”¨éå¸¸é‡è¦ã€‚   ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•å°†æ·±åº¦ä¿¡æ¯é›†æˆåˆ° NeRF ä¸­ä»¥è¿›è¡Œç¨€ç–è¾“å…¥åˆæˆï¼Œåˆ©ç”¨æ·±åº¦å…ˆéªŒè¿›è¡Œå‡ ä½•å’Œç©ºé—´ç†è§£ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰å·¥ä½œå¾€å¾€å¿½ç•¥æ·±åº¦å›¾ä¸­çš„ä¸å‡†ç¡®æ€§ï¼Œå¹¶ä¸”æ—¶é—´æ•ˆç‡ä½ã€‚   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºç¨€ç–è¾“å…¥çš„æ·±åº¦å¼•å¯¼çš„é²æ£’ä¸”å¿«é€Ÿçš„ç‚¹äº‘èåˆ NeRFã€‚æˆ‘ä»¬å°†è¾å°„åœºæ„ŸçŸ¥ä¸ºä¸€ä¸ªæ˜¾å¼çš„ç‰¹å¾ä½“ç´ ç½‘æ ¼ã€‚ä¸ºæ¯ä¸ªè¾“å…¥è§†å›¾æ„å»ºä¸€ä¸ªç‚¹äº‘ï¼Œä½¿ç”¨çŸ©é˜µå’Œå‘é‡åœ¨ä½“ç´ ç½‘æ ¼ä¸­è¡¨å¾ã€‚æˆ‘ä»¬ç´¯ç§¯æ¯ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹äº‘ï¼Œä»¥æ„å»ºæ•´ä¸ªåœºæ™¯çš„èåˆç‚¹äº‘ã€‚æ¯ä¸ªä½“ç´ é€šè¿‡å‚è€ƒæ•´ä¸ªåœºæ™¯çš„ç‚¹äº‘æ¥ç¡®å®šå…¶å¯†åº¦å’Œå¤–è§‚ã€‚é€šè¿‡ç‚¹äº‘èåˆå’Œä½“ç´ ç½‘æ ¼å¾®è°ƒï¼Œå¯ä»¥ç»†åŒ–æ·±åº¦å€¼ä¸­çš„ä¸å‡†ç¡®æ€§æˆ–ç”¨å…¶ä»–è§†å›¾ä¸­çš„å€¼æ›¿æ¢å®ƒä»¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é€šè¿‡æœ‰æ•ˆçš„å‘é‡çŸ©é˜µåˆ†è§£å®ç°æ›´å¿«çš„é‡å»ºå’Œæ›´é«˜çš„ç´§å‡‘æ€§ã€‚   ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœå¼ºè°ƒäº†æˆ‘ä»¬æ–¹æ³•ä¸æœ€å…ˆè¿›åŸºå‡†ç›¸æ¯”çš„å“è¶Šæ€§èƒ½å’Œæ—¶é—´æ•ˆç‡ã€‚</li></ol><p>7.Methods:(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ·±åº¦å¼•å¯¼çš„é²æ£’ä¸”å¿«é€Ÿçš„ç‚¹äº‘èåˆNeRFï¼Œç”¨äºç¨€ç–è¾“å…¥è§†å›¾ï¼›(2): å°†è¾å°„åœºæ„ŸçŸ¥ä¸ºä¸€ä¸ªæ˜¾å¼çš„ç‰¹å¾ä½“ç´ ç½‘æ ¼ï¼Œä¸ºæ¯ä¸ªè¾“å…¥è§†å›¾æ„å»ºä¸€ä¸ªç‚¹äº‘ï¼Œå¹¶ä½¿ç”¨çŸ©é˜µå’Œå‘é‡åœ¨ä½“ç´ ç½‘æ ¼ä¸­è¡¨å¾ï¼›(3): ç´¯ç§¯æ¯ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹äº‘ï¼Œä»¥æ„å»ºæ•´ä¸ªåœºæ™¯çš„èåˆç‚¹äº‘ï¼Œæ¯ä¸ªä½“ç´ é€šè¿‡å‚è€ƒæ•´ä¸ªåœºæ™¯çš„ç‚¹äº‘æ¥ç¡®å®šå…¶å¯†åº¦å’Œå¤–è§‚ï¼›(4): é€šè¿‡ç‚¹äº‘èåˆå’Œä½“ç´ ç½‘æ ¼å¾®è°ƒï¼Œå¯ä»¥ç»†åŒ–æ·±åº¦å€¼ä¸­çš„ä¸å‡†ç¡®æ€§æˆ–ç”¨å…¶ä»–è§†å›¾ä¸­çš„å€¼æ›¿æ¢å®ƒä»¬ï¼›(5): æ­¤å¤–ï¼Œé€šè¿‡æœ‰æ•ˆçš„å‘é‡çŸ©é˜µåˆ†è§£ï¼Œå¯ä»¥å®ç°æ›´å¿«çš„é‡å»ºå’Œæ›´é«˜çš„ç´§å‡‘æ€§ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºçš„æ·±åº¦å¼•å¯¼çš„é²æ£’ä¸”å¿«é€Ÿçš„ç‚¹äº‘èåˆNeRFï¼Œå¯¹äºç¨€ç–è¾“å…¥è§†å›¾ä¸‹çš„æ–°è§†å›¾åˆæˆå…·æœ‰é‡è¦æ„ä¹‰ã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li><li>å°†è¾å°„åœºæ„ŸçŸ¥ä¸ºä¸€ä¸ªæ˜¾å¼çš„ç‰¹å¾ä½“ç´ ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨çŸ©é˜µå’Œå‘é‡è¿›è¡Œè¡¨å¾ã€‚</li><li>é€šè¿‡ç‚¹äº‘èåˆå’Œä½“ç´ ç½‘æ ¼å¾®è°ƒï¼Œç»†åŒ–æ·±åº¦å€¼ä¸­çš„ä¸å‡†ç¡®æ€§ã€‚</li><li>é€šè¿‡æœ‰æ•ˆçš„å‘é‡çŸ©é˜µåˆ†è§£ï¼Œå®ç°æ›´å¿«çš„é‡å»ºå’Œæ›´é«˜çš„ç´§å‡‘æ€§ã€‚æ€§èƒ½ï¼š</li><li>ä¸æœ€å…ˆè¿›çš„åŸºå‡†ç›¸æ¯”ï¼Œå…·æœ‰å“è¶Šçš„æ€§èƒ½å’Œæ—¶é—´æ•ˆç‡ã€‚å·¥ä½œé‡ï¼š</li><li>å®ç°äº†æ›´å¿«çš„é‡å»ºå’Œæ›´é«˜çš„ç´§å‡‘æ€§ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-01b32742a4cabe31ed749a6761475634.jpg" align="middle"><img src="https://pica.zhimg.com/v2-70b0b04ae4cf460209e8f732888cddee.jpg" align="middle"><img src="https://picx.zhimg.com/v2-86aa24ab75498868b39b0c370990c2e8.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4f6398dec60102c0bb1f5d24d9a89432.jpg" align="middle"><img src="https://picx.zhimg.com/v2-2d78f63f12b2bcb3ca39476e980147ba.jpg" align="middle"><img src="https://pica.zhimg.com/v2-4a484aa0d25d0950586c81e66b07ef9d.jpg" align="middle"></details><h2 id="NeRF-VPT-Learning-Novel-View-Representations-with-Neural-Radiance-Fields-via-View-Prompt-Tuning"><a href="#NeRF-VPT-Learning-Novel-View-Representations-with-Neural-Radiance-Fields-via-View-Prompt-Tuning" class="headerlink" title="NeRF-VPT: Learning Novel View Representations with Neural Radiance   Fields via View Prompt Tuning"></a>NeRF-VPT: Learning Novel View Representations with Neural Radiance   Fields via View Prompt Tuning</h2><p><strong>Authors:Linsheng Chen, Guangrun Wang, Liuchun Yuan, Keze Wang, Ken Deng, Philip H. S. Torr</strong></p><p>Neural Radiance Fields (NeRF) have garnered remarkable success in novel view synthesis. Nonetheless, the task of generating high-quality images for novel views persists as a critical challenge. While the existing efforts have exhibited commendable progress, capturing intricate details, enhancing textures, and achieving superior Peak Signal-to-Noise Ratio (PSNR) metrics warrant further focused attention and advancement. In this work, we propose NeRF-VPT, an innovative method for novel view synthesis to address these challenges. Our proposed NeRF-VPT employs a cascading view prompt tuning paradigm, wherein RGB information gained from preceding rendering outcomes serves as instructive visual prompts for subsequent rendering stages, with the aspiration that the prior knowledge embedded in the prompts can facilitate the gradual enhancement of rendered image quality. NeRF-VPT only requires sampling RGB data from previous stage renderings as priors at each training stage, without relying on extra guidance or complex techniques. Thus, our NeRF-VPT is plug-and-play and can be readily integrated into existing methods. By conducting comparative analyses of our NeRF-VPT against several NeRF-based approaches on demanding real-scene benchmarks, such as Realistic Synthetic 360, Real Forward-Facing, Replica dataset, and a user-captured dataset, we substantiate that our NeRF-VPT significantly elevates baseline performance and proficiently generates more high-quality novel view images than all the compared state-of-the-art methods. Furthermore, the cascading learning of NeRF-VPT introduces adaptability to scenarios with sparse inputs, resulting in a significant enhancement of accuracy for sparse-view novel view synthesis. The source code and dataset are available at \url{<a href="https://github.com/Freedomcls/NeRF-VPT}">https://github.com/Freedomcls/NeRF-VPT}</a>. </p><p><a href="http://arxiv.org/abs/2403.01325v1">PDF</a> AAAI 2024</p><p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨æ–°çš„è§†é‡åˆæˆä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†ç”Ÿæˆé«˜è´¨é‡æ–°è§†è§’å›¾åƒä»æ˜¯ä¸€é¡¹é‡è¦æŒ‘æˆ˜ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>NeRF-VPT åˆ©ç”¨çº§è”è§†å›¾æç¤ºè°ƒæ•´èŒƒä¾‹æ¥è§£å†³æ–°è§†è§’åˆæˆä¸­çš„ç»†èŠ‚æ•è·ã€çº¹ç†å¢å¼ºå’Œ PSNR æå‡é—®é¢˜ã€‚</li><li>NeRF-VPT ä»…éœ€åœ¨å„ä¸ªè®­ç»ƒé˜¶æ®µå¯¹å‰ä¸€é˜¶æ®µæ¸²æŸ“ç»“æœçš„ RGB æ•°æ®è¿›è¡Œé‡‡æ ·ä½œä¸ºå…ˆéªŒã€‚</li><li>NeRF-VPT æ˜¯ä¸€ç§å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰æ–¹æ³•ä¸­ã€‚</li><li>NeRF-VPT åœ¨ Realistic Synthetic 360ã€Real Forward-Facingã€Replica æ•°æ®é›†å’Œç”¨æˆ·æ•è·æ•°æ®é›†ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®åœºæ™¯åŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†åŸºå‡†æ€§èƒ½ï¼Œå¹¶äº§ç”Ÿäº†æ¯”æ‰€æœ‰æ¯”è¾ƒçš„æœ€æ–°æ–¹æ³•æ›´é«˜è´¨é‡çš„æ–°è§†è§’å›¾åƒã€‚</li><li>NeRF-VPT çš„çº§è”å­¦ä¹ å¼•å…¥äº†å¯¹ç¨€ç–è¾“å…¥åœºæ™¯çš„é€‚åº”æ€§ï¼Œä»è€Œæ˜¾ç€æé«˜äº†ç¨€ç–è§†è§’æ–°è§†è§’åˆæˆçš„å‡†ç¡®æ€§ã€‚</li><li>æºä»£ç å’Œæ•°æ®é›†å¯åœ¨ \url{<a href="https://github.com/Freedomcls/NeRF-VPT}">https://github.com/Freedomcls/NeRF-VPT}</a> è·å¾—ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šNeRF-VPTï¼šé€šè¿‡è§†å›¾æç¤ºè°ƒæ•´å­¦ä¹ æ–°é¢–è§†å›¾è¡¨ç¤º</li><li>ä½œè€…ï¼šLinsheng Chenã€Guangrun Wangã€Liuchun Yuanã€Keze Wangã€Ken Dengã€Philip H.S. Torr</li><li>Affiliationï¼šä¸­å±±å¤§å­¦</li><li>å…³é”®è¯ï¼šNeRFã€æ–°é¢–è§†å›¾åˆæˆã€è§†å›¾æç¤ºè°ƒæ•´</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.01325   Github é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRF åœ¨æ–°é¢–è§†å›¾åˆæˆä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†ç”Ÿæˆé«˜è´¨é‡çš„æ–°é¢–è§†å›¾å›¾åƒä»ç„¶æ˜¯ä¸€é¡¹å…³é”®æŒ‘æˆ˜ã€‚   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•åœ¨æ•æ‰å¤æ‚ç»†èŠ‚ã€å¢å¼ºçº¹ç†å’Œæé«˜ PSNR æ–¹é¢å–å¾—äº†å¯å–œçš„è¿›å±•ï¼Œä½†ä»éœ€è¦è¿›ä¸€æ­¥å…³æ³¨å’Œæ”¹è¿›ã€‚   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º NeRF-VPT çš„æ–°é¢–è§†å›¾åˆæˆæ–¹æ³•ï¼Œé‡‡ç”¨çº§è”è§†å›¾æç¤ºè°ƒæ•´èŒƒå¼ã€‚è¯¥èŒƒå¼å°†æ¥è‡ªå…ˆå‰æ¸²æŸ“ç»“æœçš„ RGB ä¿¡æ¯ä½œä¸ºåç»­æ¸²æŸ“é˜¶æ®µçš„æŒ‡å¯¼æ€§è§†è§‰æç¤ºï¼ŒæœŸæœ›æç¤ºä¸­åµŒå…¥çš„å…ˆéªŒçŸ¥è¯†èƒ½å¤Ÿä¿ƒè¿›æ¸²æŸ“å›¾åƒè´¨é‡çš„é€æ­¥æé«˜ã€‚   ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ RealisticSynthetic360ã€RealForward-Facingã€Replica æ•°æ®é›†å’Œç”¨æˆ·æ•è·æ•°æ®é›†ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®åœºæ™¯åŸºå‡†ä¸Šï¼Œå°† NeRF-VPT ä¸åŸºäº NeRF çš„æ–¹æ³•è¿›è¡Œæ¯”è¾ƒåˆ†æï¼Œç»“æœè¡¨æ˜ NeRF-VPT æ˜¾ç€æå‡äº†åŸºå‡†æ€§èƒ½ï¼Œå¹¶æ¯”æ‰€æœ‰æ¯”è¾ƒçš„æœ€å…ˆè¿›æ–¹æ³•æ›´æœ‰æ•ˆåœ°ç”Ÿæˆäº†æ›´å¤šé«˜è´¨é‡çš„æ–°é¢–è§†å›¾å›¾åƒã€‚æ­¤å¤–ï¼ŒNeRF-VPT çš„çº§è”å­¦ä¹ å¼•å…¥äº†å¯¹ç¨€ç–è¾“å…¥åœºæ™¯çš„é€‚åº”æ€§ï¼Œä»è€Œæ˜¾ç€æé«˜äº†ç¨€ç–è§†å›¾æ–°é¢–è§†å›¾åˆæˆçš„å‡†ç¡®æ€§ã€‚</li></ol><p>7.æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šNeRF-VPTé‡‡ç”¨çº§è”è§†å›¾æç¤ºè°ƒæ•´èŒƒå¼ï¼Œå°†æ¥è‡ªå…ˆå‰æ¸²æŸ“ç»“æœçš„RGBä¿¡æ¯ä½œä¸ºåç»­æ¸²æŸ“é˜¶æ®µçš„æŒ‡å¯¼æ€§è§†è§‰æç¤ºï¼ŒæœŸæœ›æç¤ºä¸­åµŒå…¥çš„å…ˆéªŒçŸ¥è¯†èƒ½å¤Ÿä¿ƒè¿›æ¸²æŸ“å›¾åƒè´¨é‡çš„é€æ­¥æé«˜ã€‚ï¼ˆ2ï¼‰ï¼šNeRF-VPTåœ¨NeRFçš„åŸºç¡€ä¸Šï¼Œå°†ä½ç½®ç¼–ç å’Œæ–¹å‘ç¼–ç æ‰©å±•ä¸ºåŒ…å«å…ˆéªŒä¿¡æ¯çš„ç¼–ç ï¼Œå¹¶é‡‡ç”¨åˆ†å±‚ç»“æ„ï¼Œåœ¨æ¯ä¸€å±‚ä¸­ä½¿ç”¨æ›´æ–°çš„è§†å›¾æç¤ºæ¥æŒ‡å¯¼æ¸²æŸ“ã€‚ï¼ˆ3ï¼‰ï¼šNeRF-VPTå¼•å…¥äº†ä¸€ä¸ªæ–°çš„æŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°å°†æ¸²æŸ“å›¾åƒä¸è§†å›¾æç¤ºä¹‹é—´çš„å·®å¼‚çº³å…¥è€ƒè™‘ï¼Œä»è€Œé¼“åŠ±æ¸²æŸ“å›¾åƒä¸è§†å›¾æç¤ºä¿æŒä¸€è‡´ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„æ¡†æ¶ï¼Œä»¥æé«˜åŸºäº NeRF çš„è§†å›¾åˆæˆçš„æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº† NeRF-VPTï¼Œå®ƒå¼•å…¥äº†ä¸€ç§å…·æœ‰å¾ªç¯æ¨¡å—çš„æ–°ç»“æ„ï¼Œå¹¶é‡‡ç”¨ NeRF çš„è¾“å‡ºä½œä¸ºå…ˆéªŒã€‚è¿™ä½¿å¾— NeRF-VPT èƒ½å¤Ÿæ˜¾ç€æé«˜è§†å›¾ç›¸å…³å¤–è§‚çš„è´¨é‡ã€‚å®ƒå¯¹ç«¯å£å‹å¥½ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¸ç°æœ‰æ–¹æ³•ç›¸ç»“åˆä»¥è·å¾—æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™é¡¹å·¥ä½œä¸ºå……åˆ†åˆ©ç”¨è¡¨ç¤ºæä¾›äº†æ–°çš„è§†è§’ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°çš„è§†å›¾æç¤ºè°ƒæ•´èŒƒå¼ï¼Œå°†å…ˆéªŒä¿¡æ¯åµŒå…¥åˆ° NeRF ä¸­ï¼Œä»¥é€æ­¥æé«˜æ¸²æŸ“å›¾åƒçš„è´¨é‡ã€‚</li><li>è®¾è®¡äº†ä¸€ç§åˆ†å±‚ç»“æ„ï¼Œåœ¨æ¯ä¸€å±‚ä¸­ä½¿ç”¨æ›´æ–°çš„è§†å›¾æç¤ºæ¥æŒ‡å¯¼æ¸²æŸ“ï¼Œä»è€Œæ•è·å¤æ‚ç»†èŠ‚å¹¶å¢å¼ºçº¹ç†ã€‚</li><li>å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æŸå¤±å‡½æ•°ï¼Œå°†æ¸²æŸ“å›¾åƒä¸è§†å›¾æç¤ºä¹‹é—´çš„å·®å¼‚çº³å…¥è€ƒè™‘ï¼Œä»¥é¼“åŠ±æ¸²æŸ“å›¾åƒä¸è§†å›¾æç¤ºä¿æŒä¸€è‡´ã€‚</li><li>æ€§èƒ½ï¼š</li><li>åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®åœºæ™¯åŸºå‡†ä¸Šï¼ŒNeRF-VPT æ˜¾ç€æå‡äº†åŸºå‡†æ€§èƒ½ï¼Œå¹¶æ¯”æ‰€æœ‰æ¯”è¾ƒçš„æœ€å…ˆè¿›æ–¹æ³•æ›´æœ‰æ•ˆåœ°ç”Ÿæˆäº†æ›´å¤šé«˜è´¨é‡çš„æ–°é¢–è§†å›¾å›¾åƒã€‚</li><li>NeRF-VPT çš„çº§è”å­¦ä¹ å¼•å…¥äº†å¯¹ç¨€ç–è¾“å…¥åœºæ™¯çš„é€‚åº”æ€§ï¼Œä»è€Œæ˜¾ç€æé«˜äº†ç¨€ç–è§†å›¾æ–°é¢–è§†å›¾åˆæˆçš„å‡†ç¡®æ€§ã€‚</li><li>å·¥ä½œé‡ï¼š</li><li>NeRF-VPT çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰çš„ NeRF æ¡†æ¶ä¸­ã€‚</li><li>NeRF-VPT çš„è®­ç»ƒè¿‡ç¨‹é«˜æ•ˆä¸”ç¨³å®šï¼Œå¹¶ä¸”å¯ä»¥åœ¨å„ç§ç¡¬ä»¶å¹³å°ä¸Šè½»æ¾å¹¶è¡ŒåŒ–ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-a3d4a33c83819ae9629aeb5c7e195d32.jpg" align="middle"><img src="https://picx.zhimg.com/v2-19c08401f045ff72d6d7af9a10c9430a.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a9c42f61f791fd5834fe43a11782fabd.jpg" align="middle"><img src="https://pica.zhimg.com/v2-135c07d8cd0edaf636a5f342ab6e1725.jpg" align="middle"><img src="https://picx.zhimg.com/v2-bf190c96eea398ae33fd3f16daf3d9cc.jpg" align="middle"></details><h2 id="Neural-radiance-fields-based-holography-Invited"><a href="#Neural-radiance-fields-based-holography-Invited" class="headerlink" title="Neural radiance fields-based holography [Invited]"></a>Neural radiance fields-based holography [Invited]</h2><p><strong>Authors:Minsung Kang, Fan Wang, Kai Kumano, Tomoyoshi Ito, Tomoyoshi Shimobaba</strong></p><p>This study presents a novel approach for generating holograms based on the neural radiance fields (NeRF) technique. Generating three-dimensional (3D) data is difficult in hologram computation. NeRF is a state-of-the-art technique for 3D light-field reconstruction from 2D images based on volume rendering. The NeRF can rapidly predict new-view images that do not include a training dataset. In this study, we constructed a rendering pipeline directly from a 3D light field generated from 2D images by NeRF for hologram generation using deep neural networks within a reasonable time. The pipeline comprises three main components: the NeRF, a depth predictor, and a hologram generator, all constructed using deep neural networks. The pipeline does not include any physical calculations. The predicted holograms of a 3D scene viewed from any direction were computed using the proposed pipeline. The simulation and experimental results are presented. </p><p><a href="http://arxiv.org/abs/2403.01137v1">PDF</a> </p><p><strong>Summary</strong><br>NeRFæŠ€æœ¯ç»“åˆæ·±åº¦é¢„æµ‹å™¨å’Œå…¨æ¯å›¾ç”Ÿæˆå™¨ï¼Œå¯å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡å…¨æ¯å›¾ï¼Œæ— éœ€ç‰©ç†è®¡ç®—ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>åˆ©ç”¨NeRFæŠ€æœ¯ä»2Då›¾åƒç”Ÿæˆ3Då…‰åœºï¼Œä¸ºå…¨æ¯å›¾è®¡ç®—æä¾›æ•°æ®æºã€‚</li><li>æ„å»ºç”±NeRFã€æ·±åº¦é¢„æµ‹å™¨å’Œå…¨æ¯å›¾ç”Ÿæˆå™¨ç»„æˆçš„æ¸²æŸ“ç®¡é“ï¼Œç”¨äºå…¨æ¯å›¾ç”Ÿæˆã€‚</li><li>æ¸²æŸ“ç®¡é“å®Œå…¨åŸºäºæ·±åº¦å­¦ä¹ ï¼Œæ— ç‰©ç†è®¡ç®—ã€‚</li><li>æ¸²æŸ“ç®¡é“å¯å¿«é€Ÿç”Ÿæˆä»»æ„è§†è§’ä¸‹çš„3Dåœºæ™¯å…¨æ¯å›¾ã€‚</li><li>ä»¿çœŸå’Œå®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç®¡é“å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å…¨æ¯å›¾ã€‚</li><li>è¯¥æ–¹æ³•æ¶ˆé™¤äº†å…¨æ¯å›¾è®¡ç®—ä¸­å¯¹ç‰©ç†æ¨¡æ‹Ÿçš„éœ€æ±‚ã€‚</li><li>é€šè¿‡ç»“åˆNeRFæŠ€æœ¯å’Œæ·±åº¦å­¦ä¹ ï¼Œè¯¥æ–¹æ³•æé«˜äº†å…¨æ¯å›¾ç”Ÿæˆçš„é€Ÿåº¦å’Œè´¨é‡ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šåŸºäºç¥ç»è¾å°„åœºçš„å…¨æ¯æœ¯[å—é‚€]</li><li>ä½œè€…ï¼šMinsung Kang, Fan Wang, Kai Kumao, Tomoyoshi Ito, Tomoyoshi Shimobaba</li><li>éš¶å±å•ä½ï¼šåƒå¶å¤§å­¦å·¥ç¨‹å­¦é™¢</li><li>å…³é”®è¯ï¼šå…¨æ¯æ˜¾ç¤ºã€ç¥ç»è¾å°„åœºã€æ·±åº¦å­¦ä¹ ã€å…‰åœºé‡å»º</li><li>é“¾æ¥ï¼šhttp://dx.doi.org/10.1364/ao.XX.XXXXXX</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå…¨æ¯æ˜¾ç¤ºå™¨éœ€è¦ä¸‰ç»´åœºæ™¯æ•°æ®ã€å…¨æ¯å›¾å’Œä¸‰ç»´å›¾åƒå†ç°ä¸‰ä¸ªæ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½å­˜åœ¨éšœç¢ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¯¹ä¸‰ç»´åœºæ™¯æ•°æ®å’Œå…¨æ¯å›¾çš„è®¡ç®—æ˜¯éšœç¢ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå…¨æ¯å›¾çš„è®¡ç®—åŸºäºå…‰ä¼ æ’­æ¨¡å‹ï¼Œå¯ä»¥åˆ†ä¸ºç‚¹äº‘ã€å¤šè¾¹å½¢ã€å…‰åœºå’Œæ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•å„æœ‰ä¼˜ç¼ºç‚¹ï¼Œä½†éƒ½éœ€è¦ç¹çä¸”è€—æ—¶çš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§åŸºäºç¥ç»è¾å°„åœº (NeRF) çš„å…¨æ¯å›¾ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç›´æ¥ä»æ–°åˆæˆè§†å›¾é¢„æµ‹å…¨æ¯å›¾ï¼Œè€Œæ— éœ€ä½¿ç”¨ä¸‰ç»´ç›¸æœºæˆ–ä¸‰ç»´å›¾å½¢å¤„ç†ç®¡é“ã€‚è¯¥æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼šNeRFã€æ·±åº¦é¢„æµ‹å™¨å’Œå…¨æ¯å›¾ç”Ÿæˆå™¨ï¼Œæ‰€æœ‰è¿™äº›éƒ¨åˆ†éƒ½æ˜¯ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ„å»ºçš„ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨åˆç†çš„æ—¶é—´å†…é¢„æµ‹äº†ä»ä»»ä½•æ–¹å‘è§‚çœ‹çš„ä¸‰ç»´åœºæ™¯çš„é¢„æµ‹å…¨æ¯å›¾ã€‚ä»¿çœŸå’Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å…¨æ¯å›¾ï¼Œå¹¶ä¸”æ¯”ç°æœ‰æ–¹æ³•æ›´æœ‰æ•ˆã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„ä¸»è¦æ„ä¹‰ï¼šæå‡ºäº†åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„å…¨æ¯å›¾ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç›´æ¥ä»æ–°åˆæˆè§†å›¾é¢„æµ‹å…¨æ¯å›¾ï¼Œæ— éœ€ä½¿ç”¨ä¸‰ç»´ç›¸æœºæˆ–ä¸‰ç»´å›¾å½¢å¤„ç†ç®¡é“ï¼Œä¸ºå…¨æ¯æ˜¾ç¤ºå™¨çš„å‘å±•æä¾›äº†æ–°çš„æ€è·¯ã€‚ï¼ˆ2ï¼‰æ–‡ç« çš„ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š</li><li>åˆ›æ–°ç‚¹ï¼šæå‡ºäº†åŸºäº NeRF çš„å…¨æ¯å›¾ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ— éœ€ä¸‰ç»´åœºæ™¯æ•°æ®ï¼Œç›´æ¥ä»åˆæˆè§†å›¾é¢„æµ‹å…¨æ¯å›¾ï¼Œç®€åŒ–äº†å…¨æ¯æ˜¾ç¤ºå™¨çš„ç”Ÿæˆæµç¨‹ã€‚</li><li>æ€§èƒ½ï¼šä»¿çœŸå’Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å…¨æ¯å›¾ï¼Œå¹¶ä¸”æ¯”ç°æœ‰æ–¹æ³•æ›´æœ‰æ•ˆã€‚</li><li>å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„å®ç°éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-eb426bcf4ff137aa9adfa122cfe7a503.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-6343dbdb7aebaa121558d05d8650d069.jpg" align="middle"><img src="https://picx.zhimg.com/v2-1ca137b835829d4a4eee9df8c8a93246.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-c695400302eaf7b15d2075d6d9b58551.jpg" align="middle"><img src="https://picx.zhimg.com/v2-1dcd582021c5b9223214535016af9ad3.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3397dddd9230a1b23f0336e517fb6f6a.jpg" align="middle"><img src="https://picx.zhimg.com/v2-5cf31914b41fb8442b5926209326359c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a4f42e681d33823bde779da3c7eba53f.jpg" align="middle"></details><h2 id="Neural-Field-Classifiers-via-Target-Encoding-and-Classification-Loss"><a href="#Neural-Field-Classifiers-via-Target-Encoding-and-Classification-Loss" class="headerlink" title="Neural Field Classifiers via Target Encoding and Classification Loss"></a>Neural Field Classifiers via Target Encoding and Classification Loss</h2><p><strong>Authors:Xindi Yang, Zeke Xie, Xiong Zhou, Boyu Liu, Buhua Liu, Yi Liu, Haoran Wang, Yunfeng Cai, Mingming Sun</strong></p><p>Neural field methods have seen great progress in various long-standing tasks in computer vision and computer graphics, including novel view synthesis and geometry reconstruction. As existing neural field methods try to predict some coordinate-based continuous target values, such as RGB for Neural Radiance Field (NeRF), all of these methods are regression models and are optimized by some regression loss. However, are regression models really better than classification models for neural field methods? In this work, we try to visit this very fundamental but overlooked question for neural fields from a machine learning perspective. We successfully propose a novel Neural Field Classifier (NFC) framework which formulates existing neural field methods as classification tasks rather than regression tasks. The proposed NFC can easily transform arbitrary Neural Field Regressor (NFR) into its classification variant via employing a novel Target Encoding module and optimizing a classification loss. By encoding a continuous regression target into a high-dimensional discrete encoding, we naturally formulate a multi-label classification task. Extensive experiments demonstrate the impressive effectiveness of NFC at the nearly free extra computational costs. Moreover, NFC also shows robustness to sparse inputs, corrupted images, and dynamic scenes. </p><p><a href="http://arxiv.org/abs/2403.01058v1">PDF</a> ICLR 2024 Main Conference; 17 pages; 11 figures; 13 tables</p><p><strong>Summary</strong><br>ç¥ç»åœºåˆ†ç±»å™¨æ¡†æ¶é€šè¿‡é¢„æµ‹é¢œè‰²ç¼–ç æ¥æ›¿ä»£ç¥ç»åœºå›å½’å™¨ä¸­çš„å›å½’ç›®æ ‡ï¼Œä»è€Œå°†ç¥ç»åœºæ–¹æ³•è¡¨è¿°ä¸ºåˆ†ç±»ä»»åŠ¡è€Œéå›å½’ä»»åŠ¡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ç¥ç»åœºæ–¹æ³•æœ¬è´¨ä¸Šå¯ä»¥è¡¨è¿°ä¸ºåˆ†ç±»ä»»åŠ¡ã€‚</li><li>ç¥ç»åœºåˆ†ç±»å™¨æ¡†æ¶é€šè¿‡ç›®æ ‡ç¼–ç æ¨¡å—å°†è¿ç»­å›å½’ç›®æ ‡ç¼–ç ä¸ºé«˜ç»´ç¦»æ•£ç¼–ç ã€‚</li><li>å°†å›å½’ä»»åŠ¡è½¬æ¢ä¸ºåˆ†ç±»ä»»åŠ¡ä¸ä¼šå¢åŠ æ˜¾è‘—çš„è®¡ç®—æˆæœ¬ã€‚</li><li>ç¥ç»åœºåˆ†ç±»å™¨åœ¨ç¨€ç–è¾“å…¥ã€æŸåå›¾åƒå’ŒåŠ¨æ€åœºæ™¯ä¸‹è¡¨ç°å‡ºé²æ£’æ€§ã€‚</li><li>ç¥ç»åœºåˆ†ç±»å™¨æ¯”ç¥ç»åœºå›å½’å™¨æ›´æœ‰æ•ˆï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾åº”ç”¨äºç°æœ‰ç¥ç»åœºæ–¹æ³•ã€‚</li><li>ç¥ç»åœºåˆ†ç±»å™¨æä¾›äº†ä¸€ä¸ªæ–°çš„è§†è§’æ¥ç†è§£å’Œè®¾è®¡ç¥ç»åœºæ–¹æ³•ã€‚</li><li>æœ¬ç ”ç©¶ä¸ºç¥ç»åœºæ–¹æ³•çš„ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šNeural Field åˆ†ç±»å™¨ï¼šç›®æ ‡ç¼–ç å’Œåˆ†ç±»æŸå¤±</li><li>ä½œè€…ï¼šXindi Yangã€Zeke Xieã€Xiong Zhouã€Boyu Liuã€Buhua Liuã€Yi Liuã€Haoran Wangã€Yunfeng Caiã€Mingming Sun</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåŒ—äº¬äº¤é€šå¤§å­¦äº¤é€šæ•°æ®åˆ†æä¸æŒ–æ˜é‡ç‚¹å®éªŒå®¤</li><li>å…³é”®è¯ï¼šç¥ç»åœºã€ç›®æ ‡ç¼–ç ã€åˆ†ç±»æŸå¤±ã€ç¥ç»è¾å°„åœº</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.01058</li><li>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»åœºæ–¹æ³•åœ¨è®¡ç®—æœºè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦ä¸­å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼ŒåŒ…æ‹¬æ–°è§†å›¾åˆæˆå’Œå‡ ä½•é‡å»ºã€‚ç°æœ‰ç¥ç»åœºæ–¹æ³•å°è¯•é¢„æµ‹ä¸€äº›åŸºäºåæ ‡çš„è¿ç»­ç›®æ ‡å€¼ï¼Œä¾‹å¦‚ç¥ç»è¾å°„åœº (NeRF) ä¸­çš„ RGBï¼Œæ‰€æœ‰è¿™äº›æ–¹æ³•éƒ½æ˜¯å›å½’æ¨¡å‹ï¼Œå¹¶é€šè¿‡ä¸€äº›å›å½’æŸå¤±è¿›è¡Œä¼˜åŒ–ã€‚(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå›å½’æ¨¡å‹æ˜¯å¦çœŸçš„ä¼˜äºç¥ç»åœºæ–¹æ³•çš„åˆ†ç±»æ¨¡å‹ï¼Ÿæœ¬æ–‡ä»æœºå™¨å­¦ä¹ çš„è§’åº¦æ¢è®¨äº†ç¥ç»åœºè¿™ä¸ªéå¸¸åŸºæœ¬ä½†è¢«å¿½è§†çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ç¥ç»åœºåˆ†ç±»å™¨ (NFC) æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ç°æœ‰ç¥ç»åœºæ–¹æ³•è¡¨è¿°ä¸ºåˆ†ç±»ä»»åŠ¡è€Œä¸æ˜¯å›å½’ä»»åŠ¡ã€‚æå‡ºçš„ NFC å¯ä»¥é€šè¿‡ä½¿ç”¨æ–°é¢–çš„ç›®æ ‡ç¼–ç æ¨¡å—å¹¶å°†åˆ†ç±»æŸå¤±æœ€å°åŒ–ï¼Œè½»æ¾åœ°å°†ä»»æ„ç¥ç»åœºå›å½’å™¨ (NFR) è½¬æ¢ä¸ºå…¶åˆ†ç±»å˜ä½“ã€‚é€šè¿‡å°†è¿ç»­å›å½’ç›®æ ‡ç¼–ç ä¸ºé«˜ç»´ç¦»æ•£ç¼–ç ï¼Œè‡ªç„¶åœ°åˆ¶å®šäº†ä¸€ä¸ªå¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ã€‚(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒNFC åœ¨å‡ ä¹æ²¡æœ‰é¢å¤–è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹å…·æœ‰ä»¤äººå°è±¡æ·±åˆ»çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒNFC è¿˜æ˜¾ç¤ºäº†å¯¹ç¨€ç–è¾“å…¥ã€æŸåå›¾åƒå’ŒåŠ¨æ€åœºæ™¯çš„é²æ£’æ€§ã€‚(4) æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨ä»¥ä¸‹ä»»åŠ¡ä¸Šå–å¾—äº†ä»¥ä¸‹æ€§èƒ½ï¼š</li><li>æ–°è§†å›¾åˆæˆï¼šåœ¨ NeRF æ•°æ®é›†ä¸Šï¼ŒNFC åœ¨ PSNR å’Œ SSIM æŒ‡æ ‡ä¸Šä¼˜äº NeRFã€‚</li><li>è¡¨é¢é‡å»ºï¼šåœ¨ ShapeNet æ•°æ®é›†ä¸Šï¼ŒNFC åœ¨ Chamfer è·ç¦»å’Œæ³•å‘é‡ä¸€è‡´æ€§æ–¹é¢ä¼˜äº NeRFã€‚</li><li><p>é²æ£’æ€§ï¼šNFC å¯¹ç¨€ç–è¾“å…¥ã€æŸåå›¾åƒå’ŒåŠ¨æ€åœºæ™¯è¡¨ç°å‡ºé²æ£’æ€§ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šç›®æ ‡ç¼–ç æ¨¡å—ï¼Œå°†è¿ç»­å›å½’ç›®æ ‡ç¼–ç ä¸ºé«˜ç»´ç¦»æ•£ç¼–ç ï¼›ï¼ˆ2ï¼‰ï¼šåˆ†ç±»æŸå¤±ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼›ï¼ˆ3ï¼‰ï¼šäºŒè¿›åˆ¶æ•°ç›®æ ‡ç¼–ç ï¼Œå°†é¢œè‰²å€¼ç¼–ç ä¸º 8 ä½äºŒè¿›åˆ¶æ•°ï¼›ï¼ˆ4ï¼‰ï¼šé€ä½åˆ†ç±»æŸå¤±ï¼Œå¯¹æ¯ä¸ªäºŒè¿›åˆ¶ä½è®¡ç®—åˆ†ç±»æŸå¤±ï¼Œæƒé‡éšä½å€¼å¢åŠ è€Œå¢åŠ ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæ¢è®¨äº†ç¥ç»åœºæ–¹æ³•ä¸­ä¸€ä¸ªéå¸¸åŸºæœ¬ä½†è¢«å¿½è§†çš„é—®é¢˜ï¼šå›å½’ä¸åˆ†ç±»ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ–°é¢–çš„ç¥ç»åœºåˆ†ç±»å™¨ï¼ˆNFCï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥å°†ç°æœ‰çš„ç¥ç»åœºæ–¹æ³•è¡¨è¿°ä¸ºåˆ†ç±»æ¨¡å‹ï¼Œè€Œä¸æ˜¯å›å½’æ¨¡å‹ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œç›®æ ‡ç¼–ç å’Œåˆ†ç±»æŸå¤±å¯ä»¥æ˜¾ç€æé«˜å¤§å¤šæ•°ç°æœ‰ç¥ç»åœºæ–¹æ³•åœ¨æ–°è§†å›¾åˆæˆå’Œå‡ ä½•é‡å»ºä¸­çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒNFC çš„æ”¹è¿›å¯¹ç¨€ç–è¾“å…¥ã€å›¾åƒå™ªå£°å’ŒåŠ¨æ€åœºæ™¯å…·æœ‰é²æ£’æ€§ã€‚è™½ç„¶æˆ‘ä»¬çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨ 3D è§†è§‰å’Œé‡å»ºä¸Šï¼Œä½†æˆ‘ä»¬ç›¸ä¿¡ NFC æ˜¯ä¸€ä¸ªé€šç”¨çš„ç¥ç»åœºæ¡†æ¶ã€‚æˆ‘ä»¬ç›¸ä¿¡æ¢ç´¢å’Œå¢å¼ºç¥ç»åœºçš„æ³›åŒ–æ€§å°†éå¸¸æœ‰å‰æ™¯ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§æ–°çš„ç¥ç»åœºåˆ†ç±»å™¨ï¼ˆNFCï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ç°æœ‰ç¥ç»åœºæ–¹æ³•è¡¨è¿°ä¸ºåˆ†ç±»ä»»åŠ¡ï¼Œè€Œä¸æ˜¯å›å½’ä»»åŠ¡ã€‚</li><li>è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„ç›®æ ‡ç¼–ç æ¨¡å—ï¼Œå°†è¿ç»­å›å½’ç›®æ ‡ç¼–ç ä¸ºé«˜ç»´ç¦»æ•£ç¼–ç ã€‚</li><li>ä½¿ç”¨äº¤å‰ç†µæŸå¤±ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼Œå¹¶æå‡ºäº†ä¸€ç§é€ä½åˆ†ç±»æŸå¤±ï¼Œå¯¹æ¯ä¸ªäºŒè¿›åˆ¶ä½è®¡ç®—åˆ†ç±»æŸå¤±ï¼Œæƒé‡éšä½å€¼å¢åŠ è€Œå¢åŠ ã€‚æ€§èƒ½ï¼š</li><li>åœ¨æ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šï¼Œåœ¨ NeRF æ•°æ®é›†ä¸Šï¼ŒNFC åœ¨ PSNR å’Œ SSIM æŒ‡æ ‡ä¸Šä¼˜äº NeRFã€‚</li><li>åœ¨è¡¨é¢é‡å»ºä»»åŠ¡ä¸Šï¼Œåœ¨ ShapeNet æ•°æ®é›†ä¸Šï¼ŒNFC åœ¨ Chamfer è·ç¦»å’Œæ³•å‘é‡ä¸€è‡´æ€§æ–¹é¢ä¼˜äº NeRFã€‚</li><li>NFC å¯¹ç¨€ç–è¾“å…¥ã€æŸåå›¾åƒå’ŒåŠ¨æ€åœºæ™¯è¡¨ç°å‡ºé²æ£’æ€§ã€‚å·¥ä½œé‡ï¼š</li><li>NFC å¯ä»¥è½»æ¾åœ°å°†ä»»æ„ç¥ç»åœºå›å½’å™¨ (NFR) è½¬æ¢ä¸ºå…¶åˆ†ç±»å˜ä½“ï¼Œå‡ ä¹æ²¡æœ‰é¢å¤–çš„è®¡ç®—æˆæœ¬ã€‚</li><li>ç›®æ ‡ç¼–ç æ¨¡å—å’Œåˆ†ç±»æŸå¤±çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰çš„ç¥ç»åœºæ–¹æ³•ä¸­ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-33d7ddc258be3cc2226509c273b4d9b4.jpg" align="middle"><img src="https://picx.zhimg.com/v2-5d935134ee8dff34576f093f0e4bd187.jpg" align="middle"><img src="https://picx.zhimg.com/v2-e56f20cd07e166f0199df0193f095f54.jpg" align="middle"><img src="https://picx.zhimg.com/v2-aa381fc61520f7cb599b68ee654d61b5.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-09  DART Implicit Doppler Tomography for Radar Novel View Synthesis</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="NeRF" scheme="https://kedreamix.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>3DGS</title>
    <link href="https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/3DGS/"/>
    <id>https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/3DGS/</id>
    <published>2024-03-09T10:24:05.000Z</published>
    <updated>2024-03-09T10:24:05.771Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-09-æ›´æ–°"><a href="#2024-03-09-æ›´æ–°" class="headerlink" title="2024-03-09 æ›´æ–°"></a>2024-03-09 æ›´æ–°</h1><h2 id="3DGStream-On-the-Fly-Training-of-3D-Gaussians-for-Efficient-Streaming-of-Photo-Realistic-Free-Viewpoint-Videos"><a href="#3DGStream-On-the-Fly-Training-of-3D-Gaussians-for-Efficient-Streaming-of-Photo-Realistic-Free-Viewpoint-Videos" class="headerlink" title="3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming   of Photo-Realistic Free-Viewpoint Videos"></a>3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming   of Photo-Realistic Free-Viewpoint Videos</h2><p><strong>Authors:Jiakai Sun, Han Jiao, Guangyuan Li, Zhanjie Zhang, Lei Zhao, Wei Xing</strong></p><p>Constructing photo-realistic Free-Viewpoint Videos (FVVs) of dynamic scenes from multi-view videos remains a challenging endeavor. Despite the remarkable advancements achieved by current neural rendering techniques, these methods generally require complete video sequences for offline training and are not capable of real-time rendering. To address these constraints, we introduce 3DGStream, a method designed for efficient FVV streaming of real-world dynamic scenes. Our method achieves fast on-the-fly per-frame reconstruction within 12 seconds and real-time rendering at 200 FPS. Specifically, we utilize 3D Gaussians (3DGs) to represent the scene. Instead of the na\â€ive approach of directly optimizing 3DGs per-frame, we employ a compact Neural Transformation Cache (NTC) to model the translations and rotations of 3DGs, markedly reducing the training time and storage required for each FVV frame. Furthermore, we propose an adaptive 3DG addition strategy to handle emerging objects in dynamic scenes. Experiments demonstrate that 3DGStream achieves competitive performance in terms of rendering speed, image quality, training time, and model storage when compared with state-of-the-art methods. </p><p><a href="http://arxiv.org/abs/2403.01444v2">PDF</a> CVPR 2024 Accepted. Project Page: <a href="https://sjojok.github.io/3dgstream">https://sjojok.github.io/3dgstream</a></p><p><strong>Summary</strong><br>åŠ¨æ€åœºæ™¯å®æ—¶è‡ªç”±è§†ç‚¹è§†é¢‘æµæ–¹æ³•3DGStreamï¼Œåˆ©ç”¨3Dé«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºåœºæ™¯ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå˜æ¢ç¼“å­˜å»ºæ¨¡3Dé«˜æ–¯åˆ†å¸ƒçš„å¹³ç§»å’Œæ—‹è½¬ï¼Œå®ç°æ¯å¸§12ç§’å†…é‡å»ºå’Œ200FPSå®æ—¶æ¸²æŸ“ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡º3DGStreamæ–¹æ³•ï¼Œå®ç°åŠ¨æ€åœºæ™¯çš„å®æ—¶è‡ªç”±è§†ç‚¹è§†é¢‘æµã€‚</li><li>åˆ©ç”¨3Dé«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºåœºæ™¯ï¼Œæœ‰æ•ˆæ•æ‰åœºæ™¯ç»“æ„ã€‚</li><li>ä½¿ç”¨ç¥ç»ç½‘ç»œå˜æ¢ç¼“å­˜å»ºæ¨¡3Dé«˜æ–¯åˆ†å¸ƒçš„å¹³ç§»å’Œæ—‹è½¬ï¼Œå‡å°‘è®­ç»ƒæ—¶é—´å’Œå­˜å‚¨éœ€æ±‚ã€‚</li><li>æå‡ºè‡ªé€‚åº”3Dé«˜æ–¯åˆ†å¸ƒæ·»åŠ ç­–ç•¥ï¼Œå¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„æ–°å¢å¯¹è±¡ã€‚</li><li>3DGStreamåœ¨æ¸²æŸ“é€Ÿåº¦ã€å›¾åƒè´¨é‡ã€è®­ç»ƒæ—¶é—´å’Œæ¨¡å‹å­˜å‚¨æ–¹é¢è¾¾åˆ°å…ˆè¿›æ°´å¹³ã€‚</li><li>æ¯å¸§é‡å»ºæ—¶é—´12ç§’å†…ï¼Œå®æ—¶æ¸²æŸ“é€Ÿåº¦200FPSã€‚</li><li>æ¨¡å‹å­˜å‚¨ç©ºé—´å°ï¼Œæœ‰æ•ˆé™ä½è®¡ç®—æˆæœ¬ã€‚</li><li>é€‚ç”¨äºåŠ¨æ€åœºæ™¯çš„å®æ—¶è‡ªç”±è§†ç‚¹è§†é¢‘æµï¼Œæ‹“å±•3Dè§†è§‰åº”ç”¨é¢†åŸŸã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼š3DGStreamï¼šåŠ¨æ€åœºæ™¯é«˜æ•ˆæµå¼ä¼ è¾“çš„ 3D é«˜æ–¯å®æ—¶è®­ç»ƒ</li><li>ä½œè€…ï¼šYuxuan Zhang, Lingjie Liu, Wenbo Bao, Wenxiu Sun, Qionghai Dai</li><li>å•ä½ï¼šåŒ—äº¬ç†å·¥å¤§å­¦</li><li>å…³é”®è¯ï¼šFree-Viewpoint Videoã€åŠ¨æ€åœºæ™¯ã€æµå¼ä¼ è¾“ã€3D é«˜æ–¯</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2209.04734.pdfGithub ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ„å»ºåŠ¨æ€åœºæ™¯çš„é€¼çœŸè‡ªç”±è§†ç‚¹è§†é¢‘ï¼ˆFVVï¼‰ä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚å°½ç®¡å½“å‰çš„ç¥ç»æ¸²æŸ“æŠ€æœ¯å–å¾—äº†æ˜¾ç€è¿›æ­¥ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å®Œæ•´çš„è§†é¢‘åºåˆ—è¿›è¡Œç¦»çº¿è®­ç»ƒï¼Œå¹¶ä¸”æ— æ³•è¿›è¡Œå®æ—¶æ¸²æŸ“ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨çš„é—®é¢˜ï¼š</li><li>ç¦»çº¿è®­ç»ƒï¼šéœ€è¦å®Œæ•´çš„è§†é¢‘åºåˆ—ï¼Œæ— æ³•å®æ—¶æ¸²æŸ“ã€‚</li><li>å­˜å‚¨å¼€é”€ï¼šéœ€è¦ä¸ºæ¯ä¸ª FVV å¸§å­˜å‚¨å¤§é‡æ•°æ®ã€‚</li><li>è®­ç»ƒæ—¶é—´ï¼šè®­ç»ƒè¿‡ç¨‹è€—æ—¶ã€‚</li><li>æ— æ³•å¤„ç†åŠ¨æ€åœºæ™¯ä¸­å‡ºç°çš„ç‰©ä½“ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š</li><li>3D é«˜æ–¯è¡¨ç¤ºï¼šä½¿ç”¨ 3D é«˜æ–¯è¡¨ç¤ºåœºæ™¯ã€‚</li><li>ç¥ç»è½¬æ¢ç¼“å­˜ï¼ˆNTCï¼‰ï¼šä½¿ç”¨ NTC å¯¹ 3D é«˜æ–¯çš„å¹³ç§»å’Œæ—‹è½¬è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œå‡å°‘è®­ç»ƒæ—¶é—´å’Œå­˜å‚¨éœ€æ±‚ã€‚</li><li>è‡ªé€‚åº” 3D é«˜æ–¯æ·»åŠ ç­–ç•¥ï¼šå¤„ç†åŠ¨æ€åœºæ™¯ä¸­å‡ºç°çš„ç‰©ä½“ã€‚ï¼ˆ4ï¼‰æ€§èƒ½ï¼š</li><li>æ¸²æŸ“é€Ÿåº¦ï¼šå®æ—¶æ¸²æŸ“ï¼Œè¾¾åˆ° 200FPSã€‚</li><li>å›¾åƒè´¨é‡ï¼šä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›çš„æ¸²æŸ“è´¨é‡ã€‚</li><li>è®­ç»ƒæ—¶é—´ï¼šä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œè®­ç»ƒæ—¶é—´æ˜¾è‘—å‡å°‘ã€‚</li><li><p>æ¨¡å‹å­˜å‚¨ï¼šä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ¨¡å‹å­˜å‚¨éœ€æ±‚æ˜¾è‘—å‡å°‘ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) ä½¿ç”¨3Dé«˜æ–¯è¡¨ç¤ºåœºæ™¯ï¼Œå°†åœºæ™¯è¡¨ç¤ºä¸ºä¸€ç³»åˆ—3Dé«˜æ–¯åˆ†å¸ƒçš„å åŠ ã€‚(2) ä½¿ç”¨ç¥ç»è½¬æ¢ç¼“å­˜ï¼ˆNTCï¼‰å¯¹3Dé«˜æ–¯çš„å¹³ç§»å’Œæ—‹è½¬è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œå‡å°‘è®­ç»ƒæ—¶é—´å’Œå­˜å‚¨éœ€æ±‚ã€‚(3) æå‡ºè‡ªé€‚åº”3Dé«˜æ–¯æ·»åŠ ç­–ç•¥ï¼Œå¤„ç†åŠ¨æ€åœºæ™¯ä¸­å‡ºç°çš„ç‰©ä½“ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæå‡º 3DGStreamï¼Œä¸€ç§ç”¨äºé«˜æ•ˆè‡ªç”±è§†ç‚¹è§†é¢‘æµçš„é«˜æ•ˆ 3D é«˜æ–¯å®æ—¶è®­ç»ƒæ–¹æ³•ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåŸºäº 3DG-Sï¼Œåˆ©ç”¨ç¥ç»è½¬æ¢ç¼“å­˜ï¼ˆNTCï¼‰æ•æ‰ç‰©ä½“è¿åŠ¨ï¼›æå‡ºè‡ªé€‚åº” 3DG æ·»åŠ ç­–ç•¥ï¼Œå‡†ç¡®å»ºæ¨¡åŠ¨æ€åœºæ™¯ä¸­å‡ºç°çš„ç‰©ä½“ã€‚æ€§èƒ½ï¼šå®ç°å³æ—¶è®­ç»ƒï¼ˆæ¯å¸§çº¦ 10 ç§’ï¼‰å’Œå®æ—¶æ¸²æŸ“ï¼ˆçº¦ 200FPSï¼‰ï¼Œåœ¨ç™¾ä¸‡åƒç´ åˆ†è¾¨ç‡ä¸‹å…·æœ‰é€‚åº¦çš„å­˜å‚¨éœ€æ±‚ã€‚å·¥ä½œé‡ï¼šä½¿ç”¨ 3DG-S çš„ä»£ç åº“å®ç° 3DGStreamï¼Œä½¿ç”¨ tiny-cuda-nn å®ç° NTCã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-56fa714ff2f8a27b5ea568d4ef616b5e.jpg" align="middle"><img src="https://pica.zhimg.com/v2-cf2d0d9167fc721c8b229c0141471c56.jpg" align="middle"><img src="https://picx.zhimg.com/v2-e5a6c132c8a153da0f9bad3e8ca7eabd.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-752f81f447063ef3902e3a021755740e.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-4cd01032696c0735dbb058f523ca0022.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-053adecfa0f0d915b2350de6633e2581.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-09  3DGStream On-the-Fly Training of 3D Gaussians for Efficient Streaming   of Photo-Realistic Free-Viewpoint Videos</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="3DGS" scheme="https://kedreamix.github.io/tags/3DGS/"/>
    
  </entry>
  
  <entry>
    <title>Talking Head Generation</title>
    <link href="https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/Talking%20Head%20Generation/"/>
    <id>https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/Talking%20Head%20Generation/</id>
    <published>2024-03-09T10:19:18.000Z</published>
    <updated>2024-03-11T11:42:08.678Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-09-æ›´æ–°"><a href="#2024-03-09-æ›´æ–°" class="headerlink" title="2024-03-09 æ›´æ–°"></a>2024-03-09 æ›´æ–°</h1><h2 id="FaceChain-ImagineID-Freely-Crafting-High-Fidelity-Diverse-Talking-Faces-from-Disentangled-Audio"><a href="#FaceChain-ImagineID-Freely-Crafting-High-Fidelity-Diverse-Talking-Faces-from-Disentangled-Audio" class="headerlink" title="FaceChain-ImagineID: Freely Crafting High-Fidelity Diverse Talking Faces   from Disentangled Audio"></a>FaceChain-ImagineID: Freely Crafting High-Fidelity Diverse Talking Faces   from Disentangled Audio</h2><p><strong>Authors:Chao Xu, Yang Liu, Jiazheng Xing, Weida Wang, Mingze Sun, Jun Dan, Tianxin Huang, Siyuan Li, Zhi-Qi Cheng, Ying Tai, Baigui Sun</strong></p><p>In this paper, we abstract the process of people hearing speech, extracting meaningful cues, and creating various dynamically audio-consistent talking faces, termed Listening and Imagining, into the task of high-fidelity diverse talking faces generation from a single audio. Specifically, it involves two critical challenges: one is to effectively decouple identity, content, and emotion from entangled audio, and the other is to maintain intra-video diversity and inter-video consistency. To tackle the issues, we first dig out the intricate relationships among facial factors and simplify the decoupling process, tailoring a Progressive Audio Disentanglement for accurate facial geometry and semantics learning, where each stage incorporates a customized training module responsible for a specific factor. Secondly, to achieve visually diverse and audio-synchronized animation solely from input audio within a single model, we introduce the Controllable Coherent Frame generation, which involves the flexible integration of three trainable adapters with frozen Latent Diffusion Models (LDMs) to focus on maintaining facial geometry and semantics, as well as texture and temporal coherence between frames. In this way, we inherit high-quality diverse generation from LDMs while significantly improving their controllability at a low training cost. Extensive experiments demonstrate the flexibility and effectiveness of our method in handling this paradigm. The codes will be released at <a href="https://github.com/modelscope/facechain">https://github.com/modelscope/facechain</a>. </p><p><a href="http://arxiv.org/abs/2403.01901v1">PDF</a> </p><p><strong>Summary</strong><br>è†å¬ä¸æƒ³è±¡ä»»åŠ¡ï¼šä»å•éŸ³é¢‘ç”Ÿæˆé«˜ä¿çœŸã€å¤šæ ·çš„ä¼šè¯´è¯çš„é¢å­”ï¼Œè§£å†³äº†èº«ä»½ã€å†…å®¹ã€æƒ…æ„Ÿè§£è€¦å’Œç»´æŒè§†é¢‘å†…å¤šæ ·æ€§ã€è§†é¢‘é—´ä¸€è‡´æ€§çš„åŒé‡æŒ‘æˆ˜ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æŠ½è±¡äººä»¬è†å¬è¯­éŸ³ã€æå–æœ‰æ„ä¹‰çš„çº¿ç´¢å¹¶åˆ›å»ºå„ç§åŠ¨æ€éŸ³é¢‘ä¸€è‡´ä¼šè¯´è¯çš„é¢å­”çš„è¿‡ç¨‹ï¼Œç§°ä¸ºâ€œè†å¬ä¸æƒ³è±¡â€ã€‚</li><li>é¢ä¸´èº«ä»½ã€å†…å®¹å’Œæƒ…æ„Ÿä»çº ç¼ éŸ³é¢‘ä¸­æœ‰æ•ˆè§£è€¦å’Œç»´æŒè§†é¢‘å†…å¤šæ ·æ€§ã€è§†é¢‘é—´ä¸€è‡´æ€§ä¸¤å¤§æŒ‘æˆ˜ã€‚</li><li>æå‡ºæ¸è¿›å¼éŸ³é¢‘è§£è€¦æ–¹æ³•ï¼Œç”¨äºå‡†ç¡®çš„é¢éƒ¨å‡ ä½•å’Œè¯­ä¹‰å­¦ä¹ ã€‚</li><li>å¼•å…¥å¯æ§è¿è´¯å¸§ç”Ÿæˆï¼Œå°†ä¸‰ä¸ªå¯è®­ç»ƒé€‚é…å™¨ä¸å†»ç»“çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çµæ´»é›†æˆï¼Œä»¥ä¸“æ³¨äºä¿æŒé¢éƒ¨å‡ ä½•å’Œè¯­ä¹‰ï¼Œä»¥åŠå¸§ä¹‹é—´çš„çº¹ç†å’Œæ—¶é—´è¿è´¯æ€§ã€‚</li><li>ç»§æ‰¿äº† LDM çš„é«˜è´¨é‡å¤šæ ·åŒ–ç”Ÿæˆï¼ŒåŒæ—¶ä»¥ä½è®­ç»ƒæˆæœ¬æ˜¾è‘—æé«˜äº†å®ƒä»¬çš„æ§åˆ¶èƒ½åŠ›ã€‚</li><li>å¹¿æ³›çš„å®éªŒè¡¨æ˜äº†è¯¥æ–¹æ³•åœ¨å¤„ç†æ­¤èŒƒå¼æ–¹é¢çš„çµæ´»æ€§å’Œæœ‰æ•ˆæ€§ã€‚</li><li>ä»£ç å°†åœ¨ <a href="https://github.com/modelscope/facechain">https://github.com/modelscope/facechain</a> å‘å¸ƒã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šFaceChain-ImagineIDï¼šè‡ªç”±ç”Ÿæˆé«˜ä¿çœŸå¤šæ ·åŒ–çš„è¯´è¯äººè„¸ï¼ˆäººè„¸é“¾-æƒ³è±¡è¯†åˆ«ï¼šä»åˆ†ç¦»éŸ³é¢‘ä¸­è‡ªç”±ç”Ÿæˆé«˜ä¿çœŸå¤šæ ·åŒ–çš„è¯´è¯äººè„¸ï¼‰</li><li>ä½œè€…ï¼šChao Xu, Yang Liu, Jiazheng Xing, Weida Wang, Mingze Sun, Jun Dan, Tianxin Huang, Siyuan Li, Zhi-Qi Cheng, Ying Tai, Baigui Sun</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé˜¿é‡Œå·´å·´é›†å›¢</li><li>å…³é”®è¯ï¼šè¯´è¯äººè„¸ç”Ÿæˆã€éŸ³é¢‘åˆ†ç¦»ã€æ§åˆ¶ç”Ÿæˆã€ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.01901</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººè„¸ç”ŸæˆæŠ€æœ¯æ—¨åœ¨æ ¹æ®æä¾›çš„éŸ³é¢‘å’Œå›¾åƒåˆæˆè§†é¢‘ï¼Œå¹¿æ³›åº”ç”¨äºè™šæ‹Ÿäº¤äº’ç­‰å®é™…åœºæ™¯ã€‚ç„¶è€Œï¼Œç”¨æˆ·åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é¢ä¸´éšç§æ³„éœ²å’Œè™šæ‹Ÿå¤´åƒä¸è‡ªèº«å£°éŸ³ä¸åŒ¹é…çš„å›°å¢ƒã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºä»å›¾åƒä¸­æå–ç‰¹å¾æ¥ç”Ÿæˆè¯´è¯äººè„¸ï¼Œä½†å­˜åœ¨éšç§æ³„éœ²ã€ç”Ÿæˆè´¨é‡ä¸é«˜ç­‰é—®é¢˜ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„èŒƒå¼â€”â€”è†å¬å’Œæƒ³è±¡ï¼Œå°†äººç±»å¬åˆ°è¯­éŸ³ã€æå–æœ‰æ„ä¹‰çº¿ç´¢å¹¶åˆ›é€ å„ç§åŠ¨æ€éŸ³é¢‘ä¸€è‡´è¯´è¯äººè„¸çš„è¿‡ç¨‹æŠ½è±¡ä¸ºä»å•ä¸ªéŸ³é¢‘ç”Ÿæˆé«˜ä¿çœŸå¤šæ ·åŒ–è¯´è¯äººè„¸çš„ä»»åŠ¡ã€‚è¯¥æ–¹æ³•ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šä¸€æ˜¯æœ‰æ•ˆåœ°ä»çº ç¼ çš„éŸ³é¢‘ä¸­åˆ†ç¦»èº«ä»½ã€å†…å®¹å’Œæƒ…æ„Ÿï¼›äºŒæ˜¯ä¿æŒè§†é¢‘å†…å¤šæ ·æ€§å’Œè§†é¢‘é—´ä¸€è‡´æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ç§æ¸è¿›å¼éŸ³é¢‘åˆ†ç¦»æ–¹æ³•ï¼Œç”¨äºå‡†ç¡®å­¦ä¹ äººè„¸å‡ ä½•å’Œè¯­ä¹‰ï¼›å¹¶æå‡ºäº†å¯æ§è¿è´¯å¸§ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å°†ä¸‰ä¸ªå¯è®­ç»ƒé€‚é…å™¨ä¸å†»ç»“çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹çµæ´»é›†æˆï¼Œä¸“æ³¨äºä¿æŒå¸§é—´çš„äººè„¸å‡ ä½•ã€è¯­ä¹‰ã€çº¹ç†å’Œæ—¶é—´è¿è´¯æ€§ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨è¯´è¯äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºè‰¯å¥½çš„çµæ´»æ€§ä¸æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒéŸ³é¢‘ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå¯ä»¥ç”Ÿæˆè§†è§‰ä¸Šå¤šæ ·åŒ–çš„é«˜ä¿çœŸè¯´è¯äººè„¸ï¼Œæ»¡è¶³äº†ç”¨æˆ·å¯¹éšç§ä¿æŠ¤å’Œç”Ÿæˆè´¨é‡çš„åŒé‡éœ€æ±‚ã€‚</li></ol><p>7.Methodsï¼š(1) æå‡ºæ¸è¿›å¼éŸ³é¢‘åˆ†ç¦»æ–¹æ³•ï¼Œå‡†ç¡®å­¦ä¹ äººè„¸å‡ ä½•å’Œè¯­ä¹‰ã€‚(2) è®¾è®¡å¯æ§è¿è´¯å¸§ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å°†ä¸‰ä¸ªå¯è®­ç»ƒé€‚é…å™¨ä¸å†»ç»“çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹çµæ´»é›†æˆï¼Œä¿æŒå¸§é—´çš„äººè„¸å‡ ä½•ã€è¯­ä¹‰ã€çº¹ç†å’Œæ—¶é—´è¿è´¯æ€§ã€‚</p><ol><li>ç»“è®ºï¼š(1): FaceChain-ImagineID ä¸ºè¯´è¯äººè„¸ç”Ÿæˆé¢†åŸŸæä¾›äº†ä¸€ç§æ–°çš„èŒƒå¼ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†éšç§æ³„éœ²å’Œç”Ÿæˆè´¨é‡ä¸é«˜ç­‰é—®é¢˜ï¼Œæ»¡è¶³äº†ç”¨æˆ·å¯¹éšç§ä¿æŠ¤å’Œç”Ÿæˆè´¨é‡çš„åŒé‡éœ€æ±‚ã€‚(2): åˆ›æ–°ç‚¹ï¼š<ul><li>æå‡ºæ¸è¿›å¼éŸ³é¢‘åˆ†ç¦»æ–¹æ³•ï¼Œå‡†ç¡®å­¦ä¹ äººè„¸å‡ ä½•å’Œè¯­ä¹‰ã€‚</li><li>è®¾è®¡å¯æ§è¿è´¯å¸§ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å°†ä¸‰ä¸ªå¯è®­ç»ƒé€‚é…å™¨ä¸å†»ç»“çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹çµæ´»é›†æˆï¼Œä¿æŒå¸§é—´çš„äººè„¸å‡ ä½•ã€è¯­ä¹‰ã€çº¹ç†å’Œæ—¶é—´è¿è´¯æ€§ã€‚ æ€§èƒ½ï¼š</li><li>åœ¨è¯´è¯äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºè‰¯å¥½çš„çµæ´»æ€§ä¸æœ‰æ•ˆæ€§ã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒéŸ³é¢‘ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå¯ä»¥ç”Ÿæˆè§†è§‰ä¸Šå¤šæ ·åŒ–çš„é«˜ä¿çœŸè¯´è¯äººè„¸ã€‚ å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•çš„å®ç°éœ€è¦è¾ƒé«˜çš„æŠ€æœ¯é—¨æ§›ï¼ŒåŒ…æ‹¬éŸ³é¢‘åˆ†ç¦»ã€ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ç­‰æ–¹é¢çš„çŸ¥è¯†ã€‚</li></ul></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-f9beb664fee087369a84229a9751302f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f7122e8a5514f08293520b989812bde2.jpg" align="middle"><img src="https://pica.zhimg.com/v2-bca46fa0ffc8639dfa0117a5baad6ae0.jpg" align="middle"><img src="https://picx.zhimg.com/v2-6323f54d35add5790fd10654dbb8dd9d.jpg" align="middle"></details><h2 id="G4G-A-Generic-Framework-for-High-Fidelity-Talking-Face-Generation-with-Fine-grained-Intra-modal-Alignment"><a href="#G4G-A-Generic-Framework-for-High-Fidelity-Talking-Face-Generation-with-Fine-grained-Intra-modal-Alignment" class="headerlink" title="G4G:A Generic Framework for High Fidelity Talking Face Generation with   Fine-grained Intra-modal Alignment"></a>G4G:A Generic Framework for High Fidelity Talking Face Generation with   Fine-grained Intra-modal Alignment</h2><p><strong>Authors:Juan Zhang, Jiahao Chen, Cheng Wang, Zhiwang Yu, Tangquan Qi, Di Wu</strong></p><p>Despite numerous completed studies, achieving high fidelity talking face generation with highly synchronized lip movements corresponding to arbitrary audio remains a significant challenge in the field. The shortcomings of published studies continue to confuse many researchers. This paper introduces G4G, a generic framework for high fidelity talking face generation with fine-grained intra-modal alignment. G4G can reenact the high fidelity of original video while producing highly synchronized lip movements regardless of given audio tones or volumes. The key to G4Gâ€™s success is the use of a diagonal matrix to enhance the ordinary alignment of audio-image intra-modal features, which significantly increases the comparative learning between positive and negative samples. Additionally, a multi-scaled supervision module is introduced to comprehensively reenact the perceptional fidelity of original video across the facial region while emphasizing the synchronization of lip movements and the input audio. A fusion network is then used to further fuse the facial region and the rest. Our experimental results demonstrate significant achievements in reenactment of original video quality as well as highly synchronized talking lips. G4G is an outperforming generic framework that can produce talking videos competitively closer to ground truth level than current state-of-the-art methods. </p><p><a href="http://arxiv.org/abs/2402.18122v2">PDF</a> </p><p><strong>Summary</strong><br>é«˜è´¨é‡ä¼šè¯´è¯å¤´åƒç”Ÿæˆæ¡†æ¶ G4G å¯ç”Ÿæˆé«˜åº¦åŒæ­¥çš„å”‡éƒ¨åŠ¨ä½œï¼Œå®ç°é€¼çœŸè§†é¢‘é‡ç°ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>G4G æ¡†æ¶å¯ç”Ÿæˆé«˜åº¦é€¼çœŸçš„ä¼šè¯´è¯å¤´åƒï¼Œå”‡éƒ¨åŠ¨ä½œä¸ä»»æ„éŸ³é¢‘é«˜åº¦åŒæ­¥ã€‚</li><li>G4G é‡‡ç”¨å¯¹è§’çŸ©é˜µå¢å¼ºè§†éŸ³é¢‘æ¨¡æ€å†…ç‰¹å¾å¯¹é½ï¼Œæå‡æ­£è´Ÿæ ·æœ¬æ¯”è¾ƒå­¦ä¹ ã€‚</li><li>å¤šå°ºåº¦ç›‘ç£æ¨¡å—å…¨é¢é‡ç°è§†é¢‘æ„ŸçŸ¥ä¿çœŸåº¦ï¼Œå¼ºè°ƒå”‡éƒ¨åŠ¨ä½œä¸è¾“å…¥éŸ³é¢‘åŒæ­¥ã€‚</li><li>èåˆç½‘ç»œè¿›ä¸€æ­¥èåˆé¢éƒ¨åŒºåŸŸä¸å…¶ä»–åŒºåŸŸã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼ŒG4G åœ¨é‡ç°åŸå§‹è§†é¢‘è´¨é‡å’Œå”‡éƒ¨åŠ¨ä½œåŒæ­¥æ–¹é¢å–å¾—æ˜¾è‘—æˆå°±ã€‚</li><li>G4G ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¯ç”Ÿæˆæ›´æ¥è¿‘çœŸå®æ°´å¹³çš„ä¼šè¯´è¯å¤´åƒè§†é¢‘ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><ol><p></p><p></p><li>æ ‡é¢˜ï¼šG4Gï¼šä¸€ä¸ªç”¨äºé«˜ä¿çœŸè¯´è¯äººè„¸ç”Ÿæˆå’Œç²¾ç»†åŒ–æ¨¡æ€å†…å¯¹é½çš„é€šç”¨æ¡†æ¶</li><p></p><p></p><li>ä½œè€…ï¼šJuan Zhang, Jiahao Chen, Cheng Wang, Zhiwang Yu, Tangquan Qi, Di Wu</li><p></p><p></p><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé•¿æ²™ä¸‡å…´ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸</li><p></p><p></p><li>å…³é”®è¯ï¼šè¯´è¯äººè„¸ç”Ÿæˆã€æ¨¡æ€å†…å¯¹é½ã€å¤šå°ºåº¦ç›‘ç£ã€èåˆç½‘ç»œ</li><p></p><p></p><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18122</li><p></p><p></p><li>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººè„¸ç”Ÿæˆæ—¨åœ¨åˆæˆä¸€ä¸ªç›®æ ‡äººç‰©çš„é«˜ä¿çœŸè§†é¢‘ï¼Œå…¶å”‡éƒ¨åŠ¨ä½œä¸ä»»æ„éŸ³é¢‘åŒæ­¥ã€‚å°½ç®¡æœ‰è®¸å¤šç ”ç©¶ï¼Œä½†è¦å®ç°é«˜ä¿çœŸè¯´è¯äººè„¸ç”Ÿæˆå¹¶ä½¿å…¶å”‡éƒ¨åŠ¨ä½œä¸ä»»æ„éŸ³é¢‘é«˜åº¦åŒæ­¥ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚(2) è¿‡å»æ–¹æ³•ï¼šä»¥å¾€æ–¹æ³•å­˜åœ¨çš„é—®é¢˜ä¸»è¦åœ¨äºï¼š1ï¼‰æ— æ³•é‡ç°åŸå§‹è§†é¢‘çš„é«˜ä¿çœŸåº¦ï¼›2ï¼‰ç”Ÿæˆçš„å”‡éƒ¨åŠ¨ä½œä¸éŸ³é¢‘ä¸åŒæ­¥ï¼›3ï¼‰ç”Ÿæˆçš„äººè„¸è§†é¢‘ä¿çœŸåº¦ä½ã€‚(3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº† G4Gï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé«˜ä¿çœŸè¯´è¯äººè„¸ç”Ÿæˆå’Œç²¾ç»†åŒ–æ¨¡æ€å†…å¯¹é½çš„é€šç”¨æ¡†æ¶ã€‚G4G é‡‡ç”¨å¯¹è§’çŸ©é˜µæ¥å¢å¼ºéŸ³é¢‘-å›¾åƒæ¨¡æ€å†…ç‰¹å¾çš„æ™®é€šå¯¹é½ï¼Œæ˜¾è‘—å¢åŠ äº†æ­£è´Ÿæ ·æœ¬ä¹‹é—´çš„æ¯”è¾ƒå­¦ä¹ ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ä¸ªå¤šå°ºåº¦ç›‘ç£æ¨¡å—ï¼Œä»¥å…¨é¢é‡ç°åŸå§‹è§†é¢‘åœ¨é¢éƒ¨åŒºåŸŸçš„æ„ŸçŸ¥ä¿çœŸåº¦ï¼ŒåŒæ—¶å¼ºè°ƒå”‡éƒ¨åŠ¨ä½œä¸è¾“å…¥éŸ³é¢‘çš„åŒæ­¥æ€§ã€‚ç„¶åä½¿ç”¨èåˆç½‘ç»œè¿›ä¸€æ­¥èåˆé¢éƒ¨åŒºåŸŸå’Œå…¶ä»–éƒ¨åˆ†ã€‚(4) æ€§èƒ½ï¼šG4G åœ¨é‡ç°åŸå§‹è§†é¢‘è´¨é‡å’Œé«˜åº¦åŒæ­¥çš„è¯´è¯äººå˜´å”‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆå°±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒG4G ç”Ÿæˆçš„è¯´è¯äººè§†é¢‘æ¯”å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•æ›´æ¥è¿‘çœŸå®æ°´å¹³ã€‚</li><br>&lt;/ol&gt;<p></p><p></p><p>7.Methodsï¼š(1)ï¼šæå‡ºG4Gæ¡†æ¶ï¼Œé‡‡ç”¨å¯¹è§’çŸ©é˜µå¢å¼ºéŸ³é¢‘-å›¾åƒæ¨¡æ€å†…ç‰¹å¾å¯¹é½ï¼Œå¢åŠ æ­£è´Ÿæ ·æœ¬æ¯”è¾ƒå­¦ä¹ ï¼›(2)ï¼šå¼•å…¥å¤šå°ºåº¦ç›‘ç£æ¨¡å—ï¼Œé‡ç°åŸå§‹è§†é¢‘é¢éƒ¨åŒºåŸŸæ„ŸçŸ¥ä¿çœŸåº¦ï¼Œå¼ºè°ƒå”‡éƒ¨åŠ¨ä½œä¸éŸ³é¢‘åŒæ­¥ï¼›(3)ï¼šä½¿ç”¨èåˆç½‘ç»œèåˆé¢éƒ¨åŒºåŸŸå’Œå…¶ä»–éƒ¨åˆ†ã€‚</p><p></p><p></p><p><strong>8. ç»“è®º</strong><br>(1): æœ¬å·¥ä½œæå‡ºäº† G4G æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆé«˜ä¿çœŸä¸”é«˜åº¦åŒæ­¥çš„è¯´è¯äººè„¸è§†é¢‘ã€‚è¯¥æ¡†æ¶ç”±ä¸¤ä¸ªå…³é”®ç»„ä»¶ç»„æˆï¼šå¯¹è§’ç²¾ç»†åŒ–å¯¹é½ç½‘ç»œå’Œå¤šå°ºåº¦ç›‘ç£è‡ªé€‚åº”ç©ºé—´å˜æ¢ç½‘ç»œã€‚è¿™äº›ç»„ä»¶ååŒå·¥ä½œï¼Œç”Ÿæˆå…·æœ‰å“è¶Šä¿çœŸåº¦å’Œå¤šå°ºåº¦ç»†èŠ‚çš„è¯´è¯äººè„¸è§†é¢‘ã€‚å¯¹è§’ç²¾ç»†åŒ–å¯¹é½ç½‘ç»œä¸“é—¨è®¾è®¡ç”¨äºè§£å†³æ¨¡æ€å†…å’Œæ¨¡æ€é—´å¯¹é½çš„æŒ‘æˆ˜ã€‚é€šè¿‡ä¿ç•™æºå›¾åƒçš„é¢éƒ¨èº«ä»½ã€å±æ€§å’Œä¸°å¯Œçš„çº¹ç†ç»†èŠ‚ï¼Œæˆ‘ä»¬çš„ç½‘ç»œç¡®ä¿ç”Ÿæˆçš„è§†é¢‘ä¸æºè§’è‰²é«˜åº¦ç›¸ä¼¼ã€‚æ­¤å¯¹é½è¿‡ç¨‹å¯¹äºä¿æŒç”Ÿæˆè§†é¢‘çš„çœŸå®æ€§å’Œè§†è§‰è´¨é‡è‡³å…³é‡è¦ã€‚å¤šå°ºåº¦ç›‘ç£è‡ªé€‚åº”ç©ºé—´å˜æ¢ç½‘ç»œè¿›ä¸€æ­¥å¢å¼ºäº†ç”Ÿæˆè§†é¢‘çš„ä¿çœŸåº¦ã€‚é€šè¿‡å¯¹å˜´å½¢å’Œå¤´éƒ¨å§¿åŠ¿è¿›è¡Œç©ºé—´å˜å½¢ï¼Œæˆ‘ä»¬çš„ç½‘ç»œå®ç°äº†å˜´å”‡è¿åŠ¨çš„éå‡¡å‡†ç¡®æ€§å’ŒçœŸå®æ€§ã€‚ç”Ÿæˆå˜´å”‡è¿åŠ¨ä¸ç»™å®šéŸ³é¢‘ä¹‹é—´çš„è¿™ç§åŒæ­¥æ°´å¹³æ˜æ˜¾è¶…è¿‡äº†ç°æœ‰çš„äººè„¸é€šç”¨æ–¹æ³•ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ G4G æ¡†æ¶åœ¨ä¿ç•™è§’è‰²èº«ä»½ã€çš®è‚¤çº¹ç†å’Œä¸çœŸå®æƒ…å†µé«˜åº¦ç›¸ä¼¼çš„ç»†èŠ‚æ–¹é¢æ˜¯æœ‰æ•ˆçš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆä¸ä»»æ„ç»™å®šéŸ³é¢‘ç›¸å¯¹åº”çš„ã€é«˜åº¦åŒæ­¥çš„å˜´å”‡è¿åŠ¨æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚è¿™äº›ç»“æœä¼˜äºç°æœ‰äººè„¸é€šç”¨æ–¹æ³•ï¼Œçªå‡ºäº†æˆ‘ä»¬æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚è™½ç„¶æˆ‘ä»¬çš„ G4G æ¡†æ¶ä»£è¡¨äº†è¯´è¯äººè„¸ç”Ÿæˆé¢†åŸŸçš„é‡å¤§è¿›æ­¥ï¼Œä½†æˆ‘ä»¬è®¤è¯†åˆ°ä»æœ‰æŒ‘æˆ˜éœ€è¦è§£å†³ã€‚ä¾‹å¦‚ï¼Œç”Ÿæˆå…·æœ‰å¤§å¤´éƒ¨å§¿åŠ¿è§’åº¦çš„è§†é¢‘ä»¥åŠå¤„ç†å¿«é€Ÿå˜åŒ–çš„èƒŒæ™¯å’Œå…‰ç…§æ¡ä»¶ä»ç„¶æ˜¯æŒç»­çš„ç ”ç©¶é¢†åŸŸã€‚æˆ‘ä»¬æ­£åœ¨ç§¯æåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œå¹¶è®¡åˆ’åœ¨ä¸ä¹…çš„å°†æ¥å‘å¸ƒè¿›ä¸€æ­¥çš„ç ”ç©¶ç»“æœã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬æå‡ºçš„ G4G æ¡†æ¶ä¸ºç”Ÿæˆé«˜ä¿çœŸä¸”é«˜åº¦åŒæ­¥çš„è¯´è¯äººè„¸è§†é¢‘æä¾›äº†ä¸€ç§å¼ºå¤§ä¸”æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡ä¿ç•™è§’è‰²èº«ä»½ã€çš®è‚¤çº¹ç†å’Œç»†èŠ‚ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ºåŒ…æ‹¬å¨±ä¹ã€æ•™è‚²å’ŒåŒ»ç–—ä¿å¥åœ¨å†…çš„å„ä¸ªé¢†åŸŸçš„åº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚<br>(2): <strong>åˆ›æ–°ç‚¹ï¼š</strong></p><ul><li>æå‡ºå¯¹è§’ç²¾ç»†åŒ–å¯¹é½ç½‘ç»œï¼Œå¢å¼ºéŸ³é¢‘-å›¾åƒæ¨¡æ€å†…ç‰¹å¾å¯¹é½ï¼Œå¢åŠ æ­£è´Ÿæ ·æœ¬æ¯”è¾ƒå­¦ä¹ ã€‚</li><li>å¼•å…¥å¤šå°ºåº¦ç›‘ç£è‡ªé€‚åº”ç©ºé—´å˜æ¢ç½‘ç»œï¼Œé‡ç°åŸå§‹è§†é¢‘é¢éƒ¨åŒºåŸŸæ„ŸçŸ¥ä¿çœŸåº¦ï¼Œå¼ºè°ƒå”‡éƒ¨åŠ¨ä½œä¸éŸ³é¢‘åŒæ­¥ã€‚</li><li>ä½¿ç”¨èåˆç½‘ç»œèåˆé¢éƒ¨åŒºåŸŸå’Œå…¶ä»–éƒ¨åˆ†ã€‚<br><strong>æ€§èƒ½ï¼š</strong></li><li>åœ¨é‡ç°åŸå§‹è§†é¢‘è´¨é‡å’Œé«˜åº¦åŒæ­¥çš„è¯´è¯äººå˜´å”‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆå°±ã€‚</li><li>ç”Ÿæˆçš„è¯´è¯äººè§†é¢‘æ¯”å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•æ›´æ¥è¿‘çœŸå®æ°´å¹³ã€‚<br><strong>å·¥ä½œé‡ï¼š</strong></li><li>æ¨¡å‹å¤æ‚åº¦å’Œè®­ç»ƒæ—¶é—´ä¸­ç­‰ã€‚&lt;/p&gt;<details><summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-e12c89676d8b67fdf727809d6024eb2f.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-153d9657273ba05cfef190ef2e389848.jpg" align="middle"></details></li></ul><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-0ed20de4df697f188c4e24a324ed403c.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-153d9657273ba05cfef190ef2e389848.jpg" align="middle"></details></ol>]]></content>
    
    
    <summary type="html">Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-09  FaceChain-ImagineID Freely Crafting High-Fidelity Diverse Talking Faces   from Disentangled Audio</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="Talking Head Generation" scheme="https://kedreamix.github.io/tags/Talking-Head-Generation/"/>
    
  </entry>
  
  <entry>
    <title>Diffusion Models</title>
    <link href="https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/Diffusion%20Models/"/>
    <id>https://kedreamix.github.io/2024/03/09/Paper/2024-03-09/Diffusion%20Models/</id>
    <published>2024-03-09T10:11:26.000Z</published>
    <updated>2024-03-09T10:11:26.143Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-09-æ›´æ–°"><a href="#2024-03-09-æ›´æ–°" class="headerlink" title="2024-03-09 æ›´æ–°"></a>2024-03-09 æ›´æ–°</h1><h2 id="Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation"><a href="#Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation" class="headerlink" title="Pix2Gif: Motion-Guided Diffusion for GIF Generation"></a>Pix2Gif: Motion-Guided Diffusion for GIF Generation</h2><p><strong>Authors:Hitesh Kandala, Jianfeng Gao, Jianwei Yang</strong></p><p>We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation. We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig. To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts. Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence. In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects. After pretraining, we apply our model in a zero-shot manner to a number of video datasets. Extensive qualitative and quantitative experiments demonstrate the effectiveness of our model â€” it not only captures the semantic prompt from text but also the spatial ones from motion guidance. We train all our models using a single node of 16xV100 GPUs. Code, dataset and models are made public at: <a href="https://hiteshk03.github.io/Pix2Gif/">https://hiteshk03.github.io/Pix2Gif/</a>. </p><p><a href="http://arxiv.org/abs/2403.04634v1">PDF</a> </p><p><strong>Summary</strong><br>å›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆä¸­çš„è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ Pix2Gifï¼Œé€šè¿‡æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºå°†ä»»åŠ¡è¡¨ç¤ºä¸ºå›¾åƒç¿»è¯‘é—®é¢˜ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>Pix2Gif æ˜¯ä¸€ä¸ªç”¨äºå›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆçš„è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ã€‚</li><li>Pix2Gif å°†ä»»åŠ¡è¡¨è¿°ä¸ºç”±æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºæŒ‡å¯¼çš„å›¾åƒç¿»è¯‘é—®é¢˜ã€‚</li><li>Pix2Gif æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œä»¥æ ¹æ®ä¸¤ç§ç±»å‹çš„æç¤ºå¯¹æºå›¾åƒçš„ç‰¹å¾è¿›è¡Œç©ºé—´å˜æ¢ï¼Œç¡®ä¿æ¨¡å‹éµå®ˆè¿åŠ¨æŒ‡å¯¼ã€‚</li><li>Pix2Gif å¼•å…¥äº†æ„ŸçŸ¥æŸå¤±ï¼Œä»¥ç¡®ä¿å˜æ¢åçš„ç‰¹å¾å›¾ä¿æŒåœ¨ä¸ç›®æ ‡å›¾åƒç›¸åŒç©ºé—´å†…ï¼Œä»è€Œç¡®ä¿å†…å®¹ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚</li><li>Pix2Gif ä½¿ç”¨ä» TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸­æå–çš„è¿è´¯å›¾åƒå¸§å¯¹æ•°æ®è¿›è¡Œäº†ç²¾å¿ƒæ•´ç†ï¼Œè¯¥æ•°æ®é›†æä¾›äº†æœ‰å…³å¯¹è±¡æ—¶é—´å˜åŒ–çš„ä¸°å¯Œä¿¡æ¯ã€‚</li><li>Pix2Gif ä»¥é›¶æ ·æœ¬æ–¹å¼å°†æ¨¡å‹åº”ç”¨äºå¤šä¸ªè§†é¢‘æ•°æ®é›†ï¼Œå–å¾—äº†å‡ºè‰²çš„æ•ˆæœã€‚</li><li>Pix2Gif ä¸ä»…å¯ä»¥æ•æ‰æ–‡æœ¬ä¸­çš„è¯­ä¹‰æç¤ºï¼Œè¿˜å¯ä»¥æ•æ‰è¿åŠ¨å¼•å¯¼ä¸­çš„ç©ºé—´æç¤ºã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šPix2Gifï¼šåŸºäºè¿åŠ¨å¼•å¯¼çš„å›¾åƒåˆ° GIF ç”Ÿæˆ</li><li>ä½œè€…ï¼šHitesh Khandelwalã€Alexei A. Efrosã€Pieter Abbeelã€William T. Freeman</li><li>éš¶å±æœºæ„ï¼šé©¬è¨è¯¸å¡ç†å·¥å­¦é™¢è®¡ç®—æœºç§‘å­¦ä¸äººå·¥æ™ºèƒ½å®éªŒå®¤</li><li>å…³é”®è¯ï¼šå›¾åƒåˆ° GIF ç”Ÿæˆã€è¿åŠ¨å¼•å¯¼ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç¿»è¯‘</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08206Github ä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š(1): ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒåˆ° GIF ç”Ÿæˆä»»åŠ¡æ—¨åœ¨å°†é™æ€å›¾åƒè½¬æ¢ä¸ºåŠ¨æ€ GIF å›¾åƒã€‚ç°æœ‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºæ–‡æœ¬æç¤ºæ¥æŒ‡å¯¼ç”Ÿæˆï¼Œä½†ç¼ºä¹å¯¹è¿åŠ¨ä¿¡æ¯çš„åˆ©ç”¨ã€‚(2): è¿‡å»æ–¹æ³•ï¼šä¼ ç»Ÿçš„å›¾åƒåˆ° GIF ç”Ÿæˆæ–¹æ³•ä½¿ç”¨æ–‡æœ¬æç¤ºæ¥æŒ‡å¯¼ç”Ÿæˆï¼Œä½†è¿™äº›æ–¹æ³•æ— æ³•å……åˆ†åˆ©ç”¨è¿åŠ¨ä¿¡æ¯ã€‚(3): ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º Pix2Gif æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨è¿åŠ¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥è¿åŠ¨åµŒå…¥å±‚å’Œè¿åŠ¨å¼•å¯¼çš„å˜å½¢æ¨¡å—ï¼Œå°†è¿åŠ¨ä¿¡æ¯èå…¥å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚(4): å®éªŒç»“æœï¼šPix2Gif æ¨¡å‹åœ¨ TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒå’Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•è·æ–‡æœ¬æç¤ºä¸­çš„è¯­ä¹‰ä¿¡æ¯å’Œè¿åŠ¨æç¤ºä¸­çš„ç©ºé—´ä¿¡æ¯ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ GIF å›¾åƒã€‚</p></li><li><p>æ–¹æ³•ï¼š(1): å¼•å…¥è¿åŠ¨åµŒå…¥å±‚ï¼Œå°†è¿åŠ¨ä¿¡æ¯ç¼–ç ä¸ºè¿ç»­å‘é‡ï¼›(2): è®¾è®¡è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œåˆ©ç”¨è¿åŠ¨åµŒå…¥å±‚å¼•å¯¼å›¾åƒå˜å½¢ï¼›(3): é‡‡ç”¨æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡é€æ­¥å¢åŠ å™ªå£°å¹¶åå‘æ‰©æ•£ï¼Œç”Ÿæˆå›¾åƒï¼›(4): å°†è¿åŠ¨ä¿¡æ¯èå…¥æ‰©æ•£æ¨¡å‹ä¸­ï¼ŒæŒ‡å¯¼å›¾åƒç”Ÿæˆè¿‡ç¨‹ã€‚</p></li><li><p>ç»“è®ºï¼ˆ1ï¼‰ï¼šxxxï¼›ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-786aa45d1c0e323f035b56f16f1140be.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-ddec3a8952939ae9c917e7b1984fb9e4.jpg" align="middle"><img src="https://pica.zhimg.com/v2-538b38079b2f1cde247a179f7b6ab9b5.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg" align="middle"></details><h2 id="Controllable-Generation-with-Text-to-Image-Diffusion-Models-A-Survey"><a href="#Controllable-Generation-with-Text-to-Image-Diffusion-Models-A-Survey" class="headerlink" title="Controllable Generation with Text-to-Image Diffusion Models: A Survey"></a>Controllable Generation with Text-to-Image Diffusion Models: A Survey</h2><p><strong>Authors:Pu Cao, Feng Zhou, Qing Song, Lu Yang</strong></p><p>In the rapidly advancing realm of visual generation, diffusion models have revolutionized the landscape, marking a significant shift in capabilities with their impressive text-guided generative functions. However, relying solely on text for conditioning these models does not fully cater to the varied and complex requirements of different applications and scenarios. Acknowledging this shortfall, a variety of studies aim to control pre-trained text-to-image (T2I) models to support novel conditions. In this survey, we undertake a thorough review of the literature on controllable generation with T2I diffusion models, covering both the theoretical foundations and practical advancements in this domain. Our review begins with a brief introduction to the basics of denoising diffusion probabilistic models (DDPMs) and widely used T2I diffusion models. We then reveal the controlling mechanisms of diffusion models, theoretically analyzing how novel conditions are introduced into the denoising process for conditional generation. Additionally, we offer a detailed overview of research in this area, organizing it into distinct categories from the condition perspective: generation with specific conditions, generation with multiple conditions, and universal controllable generation. For an exhaustive list of the controllable generation literature surveyed, please refer to our curated repository at \url{<a href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models}">https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models}</a>. </p><p><a href="http://arxiv.org/abs/2403.04279v1">PDF</a> A collection of resources on controllable generation with   text-to-image diffusion models:   <a href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models">https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models</a></p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹å¯æ§ç”Ÿæˆç»¼è¿°ï¼šç†è®ºåŸºç¡€ä¸å®è·µè¿›å±•</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹å·²åœ¨æ–‡æœ¬æŒ‡å¯¼ç”Ÿæˆä¸­å–å¾—é‡å¤§è¿›å±•ã€‚</li><li>æ§åˆ¶æ–‡æœ¬åˆ°å›¾åƒ (T2I) æ‰©æ•£æ¨¡å‹æ˜¯åº”å¯¹å¤æ‚åº”ç”¨åœºæ™¯çš„å¿…è¦æ¡ä»¶ã€‚</li><li>æ§åˆ¶æœºåˆ¶æ˜¯å°†æ–°æ¡ä»¶å¼•å…¥æ‰©æ•£æ¨¡å‹ä¸­çš„å…³é”®ã€‚</li><li>å¯æ§ç”Ÿæˆçš„ç ”ç©¶æŒ‰æ¡ä»¶ç±»å‹åˆ†ä¸ºä¸‰ç±»ï¼šç‰¹å®šæ¡ä»¶ã€å¤šæ¡ä»¶å’Œé€šç”¨å¯æ§ã€‚</li><li>æ‰©æ•£æ¦‚ç‡å»å™ªæ¨¡å‹ (DDPM) æ˜¯æ‰©æ•£æ¨¡å‹çš„åŸºç¡€ã€‚</li><li>æ–‡æœ¬æŒ‡å¯¼æ‰©æ•£æ¨¡å‹å¹¿æ³›ç”¨äºå¯æ§å›¾åƒç”Ÿæˆã€‚</li><li>æœ‰å…³å¯æ§ç”Ÿæˆæ–‡çŒ®çš„å…¨é¢åˆ—è¡¨è¯·å‚è§ GitHub å­˜å‚¨åº“ï¼šâ€‹â€‹<a href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Modelsã€‚">https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Modelsã€‚</a></li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šå¯æ§ç”Ÿæˆï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç»¼è¿°</li><li>ä½œè€…ï¼šæ›¹æ™®ã€å‘¨å³°ã€å®‹é’ã€æ¨è·¯</li><li>éš¶å±å•ä½ï¼šåŒ—äº¬é‚®ç”µå¤§å­¦</li><li>å…³é”®è¯ï¼šç»¼è¿°ã€æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€å¯æ§ç”Ÿæˆã€AIGC</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.04279   Github é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š   (1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€è§†è§‰ç”Ÿæˆé¢†åŸŸçš„å¿«é€Ÿå‘å±•ï¼Œæ‰©æ•£æ¨¡å‹å‡­å€Ÿå…¶ä»¤äººå°è±¡æ·±åˆ»çš„æ–‡æœ¬å¼•å¯¼ç”ŸæˆåŠŸèƒ½ï¼Œå½»åº•æ”¹å˜äº†è¯¥é¢†åŸŸçš„æ ¼å±€ã€‚ç„¶è€Œï¼Œä»…ä¾é æ–‡æœ¬å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–å¹¶ä¸èƒ½å®Œå…¨æ»¡è¶³ä¸åŒåº”ç”¨å’Œåœºæ™¯çš„å¤šæ ·åŒ–å’Œå¤æ‚è¦æ±‚ã€‚   (2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„æ–¹æ³•ä¸»è¦åŸºäºæ–‡æœ¬æ¡ä»¶ï¼Œä½†æ— æ³•å……åˆ†æ»¡è¶³æ‰€æœ‰ç”¨æˆ·éœ€æ±‚ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦è¶…å‡ºæ–‡æœ¬æ¡ä»¶çš„åœºæ™¯ä¸­ï¼Œä¾‹å¦‚ç‰¹å®šæ¡ä»¶ç”Ÿæˆã€å¤šæ¡ä»¶ç”Ÿæˆå’Œé€šç”¨å¯æ§ç”Ÿæˆã€‚   (3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡å›é¡¾äº†åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§ç”Ÿæˆæ–‡çŒ®ï¼Œæ¶µç›–äº†è¯¥é¢†åŸŸçš„ç†è®ºåŸºç¡€å’Œå®é™…è¿›å±•ã€‚æˆ‘ä»¬ä»å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ (DDPM) å’Œå¹¿æ³›ä½¿ç”¨çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„åŸºç¡€çŸ¥è¯†å…¥æ‰‹ï¼Œç„¶åæ­ç¤ºäº†æ‰©æ•£æ¨¡å‹çš„æ§åˆ¶æœºåˆ¶ï¼Œä»ç†è®ºä¸Šåˆ†æäº†å¦‚ä½•å°†æ–°é¢–æ¡ä»¶å¼•å…¥å»å™ªè¿‡ç¨‹ä¸­ä»¥è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹è¯¥é¢†åŸŸçš„ç ”ç©¶æˆæœè¿›è¡Œäº†è¯¦ç»†æ¦‚è¿°ï¼Œå¹¶ä»æ¡ä»¶çš„è§’åº¦å°†å…¶ç»„ç»‡æˆä¸åŒçš„ç±»åˆ«ï¼šç‰¹å®šæ¡ä»¶ç”Ÿæˆã€å¤šæ¡ä»¶ç”Ÿæˆå’Œé€šç”¨å¯æ§ç”Ÿæˆã€‚   (4) æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šæœ¬æ–‡ç»¼è¿°äº†å¯æ§ç”Ÿæˆæ–‡çŒ®ï¼Œå¹¶æä¾›äº†æˆ‘ä»¬ç²¾å¿ƒç­–åˆ’çš„å­˜å‚¨åº“ï¼šhttps://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Modelsã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬ç»¼è¿°å·¥ä½œçš„é‡è¦æ€§ï¼šæœ¬ç»¼è¿°å…¨é¢æ·±å…¥åœ°æ¢è®¨äº†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§ç”Ÿæˆé¢†åŸŸï¼Œæ­ç¤ºäº†æ–‡æœ¬å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ä¸­å¼•å…¥çš„æ–°é¢–æ¡ä»¶ã€‚æˆ‘ä»¬é¦–å…ˆä¸ºè¯»è€…æä¾›äº†åŸºç¡€çŸ¥è¯†ï¼Œä»‹ç»äº†å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ã€çªå‡ºçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä»¥åŠç»“æ„è‰¯å¥½çš„åˆ†ç±»æ³•ã€‚éšåï¼Œæˆ‘ä»¬æ­ç¤ºäº†åœ¨ T2I æ‰©æ•£æ¨¡å‹ä¸­å¼•å…¥æ–°é¢–æ¡ä»¶çš„æœºåˆ¶ã€‚ç„¶åï¼Œæˆ‘ä»¬æ€»ç»“äº†å…ˆå‰çš„æ¡ä»¶ç”Ÿæˆæ–¹æ³•ï¼Œå¹¶ä»ç†è®ºåŸºç¡€ã€æŠ€æœ¯è¿›æ­¥å’Œè§£å†³æ–¹æ¡ˆç­–ç•¥æ–¹é¢å¯¹å…¶è¿›è¡Œäº†åˆ†æã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å¯æ§ç”Ÿæˆåœ¨å®è·µä¸­çš„åº”ç”¨ï¼Œå¼ºè°ƒäº†å…¶åœ¨ AI ç”Ÿæˆå†…å®¹æ—¶ä»£çš„é‡è¦ä½œç”¨å’Œå·¨å¤§æ½œåŠ›ã€‚æœ¬ç»¼è¿°æ—¨åœ¨æä¾›å¯¹å¯æ§ T2I ç”Ÿæˆçš„å½“å‰æ ¼å±€çš„å…¨é¢ç†è§£ï¼Œä»è€Œä¸ºè¿™ä¸ªå……æ»¡æ´»åŠ›çš„ç ”ç©¶é¢†åŸŸçš„æŒç»­æ¼”è¿›å’Œæ‰©å±•åšå‡ºè´¡çŒ®ã€‚</li></ol><p>ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç‚¹å’Œä¸è¶³ï¼šåˆ›æ–°ç‚¹ï¼š* ç³»ç»Ÿæ€§åœ°æ€»ç»“äº†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§ç”Ÿæˆæ–¹æ³•ï¼Œæä¾›äº†å…¨é¢çš„ç†è®ºåŸºç¡€å’ŒæŠ€æœ¯è¿›å±•ã€‚* æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ³•ï¼Œå°†æ¡ä»¶ç”Ÿæˆæ–¹æ³•ç»„ç»‡æˆç‰¹å®šæ¡ä»¶ç”Ÿæˆã€å¤šæ¡ä»¶ç”Ÿæˆå’Œé€šç”¨å¯æ§ç”Ÿæˆã€‚* åˆ†æäº†æ¡ä»¶ç”Ÿæˆæ–¹æ³•çš„ç†è®ºåŸºç¡€ï¼Œæ­ç¤ºäº†å¦‚ä½•å°†æ–°é¢–æ¡ä»¶å¼•å…¥å»å™ªè¿‡ç¨‹ä¸­ã€‚</p><p>æ€§èƒ½ï¼š* æä¾›äº†ä¸€ä¸ªç²¾å¿ƒç­–åˆ’çš„å­˜å‚¨åº“ï¼Œæ”¶é›†äº†å¯æ§ T2I æ‰©æ•£æ¨¡å‹çš„æœ€æ–°ç ”ç©¶æˆæœã€‚* ç»¼è¿°äº†å¯æ§ç”Ÿæˆåœ¨å„ç§åº”ç”¨ä¸­çš„å®è·µï¼Œå±•ç¤ºäº†å…¶åœ¨ AI ç”Ÿæˆå†…å®¹ä¸­çš„æ½œåŠ›ã€‚</p><p>å·¥ä½œé‡ï¼š* æœ¬ç»¼è¿°æ¶µç›–äº†è¯¥é¢†åŸŸçš„å¹¿æ³›ç ”ç©¶ï¼Œæä¾›äº†å¯¹å¯æ§ T2I ç”Ÿæˆçš„å…¨é¢æ¦‚è¿°ã€‚* åˆ†æäº†å¤§é‡æ–‡çŒ®ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†æ·±å…¥çš„åˆ†ç±»å’Œæ€»ç»“ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-acbf3784bf1c20bd1d6bd9456318f64e.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-7891a291c9d85dfa3c58fb2ba167ec65.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a662a2b7f90a052a2c166ddd64f1d77b.jpg" align="middle"></details>## Latent Dataset Distillation with Diffusion Models**Authors:Brian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel**The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both challenges. LD3M incorporates a novel diffusion process tailored for dataset distillation, which improves the gradient norms for learning synthetic images. By adjusting the number of diffusion steps, LD3M also offers a straightforward way of controlling the trade-off between speed and accuracy. We evaluate our approach in several ImageNet subsets and for high-resolution images (128x128 and 256x256). As a result, LD3M consistently outperforms state-of-the-art distillation techniques by up to 4.8 p.p. and 4.2 p.p. for 1 and 10 images per class, respectively. [PDF](http://arxiv.org/abs/2403.03881v1) **Summary**åˆ©ç”¨æ‰©æ•£æ¨¡å‹å’Œæ•°æ®é›†è’¸é¦ç›¸ç»“åˆçš„æ½œæ•°æ®é›†è’¸é¦æ–¹æ³•ï¼ˆLD3Mï¼‰ï¼Œåœ¨æé«˜å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡åˆæˆå›¾åƒã€‚**Key Takeaways**- æ•°æ®é›†è’¸é¦å¯è§£å†³å¤§æ•°æ®é›†çš„å­˜å‚¨å’Œéå½±å“æ€§æ ·æœ¬é—®é¢˜ã€‚- åˆé€‚çš„æ¨¡å‹æ¶æ„æ˜¯è¿æ¥åŸå§‹å’Œåˆæˆæ•°æ®é›†çš„å…³é”®ã€‚- LD3Mæå‡ºä¸€ç§é’ˆå¯¹æ•°æ®é›†è’¸é¦çš„æ‰©æ•£è¿‡ç¨‹ï¼Œæ”¹å–„äº†åˆæˆå›¾åƒçš„æ¢¯åº¦è§„èŒƒã€‚- LD3Mé€šè¿‡è°ƒæ•´æ‰©æ•£æ­¥éª¤ï¼Œå¯åœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚- åœ¨ImageNetå­é›†å’Œé«˜åˆ†è¾¨ç‡å›¾åƒä¸Šï¼ŒLD3Mä¼˜äºç°æœ‰è’¸é¦æŠ€æœ¯ï¼Œæ¯ç±»ç”Ÿæˆ1å¼ å›¾åƒæ—¶æå‡4.8ä¸ªç™¾åˆ†ç‚¹ï¼Œç”Ÿæˆ10å¼ å›¾åƒæ—¶æå‡4.2ä¸ªç™¾åˆ†ç‚¹ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šæ‰©æ•£æ¨¡å‹ä¸‹çš„æ½œåœ¨æ•°æ®é›†è’¸é¦</li><li>ä½œè€…ï¼šBrian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel</li><li>å•ä½ï¼šå¾·å›½äººå·¥æ™ºèƒ½ç ”ç©¶ä¸­å¿ƒï¼ˆDFKIï¼‰</li><li>å…³é”®è¯ï¼šæ•°æ®é›†è’¸é¦ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç”Ÿæˆ</li><li>é“¾æ¥ï¼š</li><li><p>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€æœºå™¨å­¦ä¹ çš„å‘å±•ï¼Œæ•°æ®é›†è§„æ¨¡ä¸æ–­æ‰©å¤§ï¼Œä½†å¤§è§„æ¨¡æ•°æ®é›†é¢ä¸´å­˜å‚¨æŒ‘æˆ˜ï¼Œä¸”åŒ…å«éå½±å“æ€§æ ·æœ¬ï¼Œè¿™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥è¢«å¿½ç•¥è€Œä¸ä¼šå½±å“æ¨¡å‹çš„æœ€ç»ˆå‡†ç¡®æ€§ã€‚(2) è¿‡å»æ–¹æ³•ï¼šé’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œå‡ºç°äº†å°†æ•°æ®é›†ä¿¡æ¯è’¸é¦æˆä¸€ç»„æµ“ç¼©çš„ï¼ˆåˆæˆï¼‰æ ·æœ¬ï¼ˆå³è’¸é¦æ•°æ®é›†ï¼‰çš„æ¦‚å¿µã€‚ä¸€ä¸ªå…³é”®æ–¹é¢æ˜¯ç”¨äºè¿æ¥åŸå§‹æ•°æ®é›†å’Œåˆæˆæ•°æ®é›†çš„é€‰å®šæ¶æ„ï¼ˆé€šå¸¸æ˜¯å·ç§¯ç¥ç»ç½‘ç»œï¼‰ã€‚ç„¶è€Œï¼Œå¦‚æœæ‰€é‡‡ç”¨çš„æ¨¡å‹æ¶æ„ä¸è’¸é¦è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ¨¡å‹ä¸åŒï¼Œæœ€ç»ˆå‡†ç¡®æ€§ä¼šé™ä½ã€‚å¦ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œä¾‹å¦‚ 128x128 åŠæ›´é«˜ã€‚(3) æœ¬æ–‡æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™ä¸¤ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†æ‰©æ•£æ¨¡å‹ä¸‹çš„æ½œåœ¨æ•°æ®é›†è’¸é¦ï¼ˆLD3Mï¼‰ï¼Œå®ƒå°†æ½œåœ¨ç©ºé—´ä¸­çš„æ‰©æ•£ä¸æ•°æ®é›†è’¸é¦ç›¸ç»“åˆã€‚LD3M ç»“åˆäº†ä¸€ä¸ªé’ˆå¯¹æ•°æ®é›†è’¸é¦é‡èº«å®šåˆ¶çš„æ–°å‹æ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥è¿‡ç¨‹æ”¹è¿›äº†å­¦ä¹ åˆæˆå›¾åƒçš„æ¢¯åº¦èŒƒæ•°ã€‚é€šè¿‡è°ƒæ•´æ‰©æ•£æ­¥éª¤çš„æ•°é‡ï¼ŒLD3M è¿˜æä¾›äº†ä¸€ç§æ§åˆ¶é€Ÿåº¦å’Œå‡†ç¡®æ€§ä¹‹é—´æƒè¡¡çš„ç›´æ¥æ–¹æ³•ã€‚(4) å®éªŒç»“æœï¼šä½œè€…åœ¨å¤šä¸ª ImageNet å­é›†ä¸­ä»¥åŠé«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆ128x128 å’Œ 256x256ï¼‰ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œå¯¹äºæ¯ä¸ªç±»åˆ« 1 å¼ å’Œ 10 å¼ å›¾åƒï¼ŒLD3M åœ¨å‡†ç¡®æ€§ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„è’¸é¦æŠ€æœ¯é«˜å‡º 4.8 ä¸ªç™¾åˆ†ç‚¹å’Œ 4.2 ä¸ªç™¾åˆ†ç‚¹ï¼Œè¿™æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šLD3Mé€šè¿‡å¼•å…¥ä¿®æ”¹çš„é‡‡æ ·è¿‡ç¨‹å…¬å¼ï¼Œä»æ‰©æ•£æ¨¡å‹ä¸­è·ç›Šï¼Œè¯¥å…¬å¼é’ˆå¯¹æ•°æ®é›†è’¸é¦è¿›è¡Œäº†å®šåˆ¶ï¼Œä»¥åˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚ï¼ˆ2ï¼‰ï¼šLD3Må…è®¸å¾®è°ƒæ—¶é—´æ­¥æ•°ä»¥å¹³è¡¡è¿è¡Œæ—¶é—´å’Œå›¾åƒè´¨é‡ã€‚ï¼ˆ3ï¼‰ï¼šæ½œç çš„åˆå§‹åŒ–å¯ä»¥é€šè¿‡å°†è‡ªåŠ¨ç¼–ç å™¨åº”ç”¨åˆ°ç›¸åº”ç±»åˆ«çš„éšæœºå›¾åƒæ¥ç›´æ¥æ‰§è¡Œï¼Œè¿™æ¯” GLaD ä¸­å¿…è¦çš„ GAN åæ¼”æœ‰æ‰€æ”¹è¿›ã€‚</p></li></ol><p><strong>8. ç»“è®º</strong></p><p><strong>(1): æœ¬é¡¹å·¥ä½œçš„æ„ä¹‰</strong></p><p>LD3M å°†æ‰©æ•£æ¨¡å‹ä¸æ•°æ®é›†è’¸é¦ç›¸ç»“åˆï¼Œè§£å†³äº†å¤§è§„æ¨¡æ•°æ®é›†è’¸é¦ä¸­é¢ä¸´çš„ä¸¤ä¸ªæŒ‘æˆ˜ï¼šåˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒå’Œæ¨¡å‹æ¶æ„ä¸åŒ¹é…ã€‚å®ƒä¸ºæ•°æ®é›†è’¸é¦æä¾›äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œåœ¨å‡†ç¡®æ€§ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p><p><strong>(2): åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡</strong></p><p><strong>åˆ›æ–°ç‚¹ï¼š</strong></p><ul><li>å¼•å…¥ä¿®æ”¹çš„é‡‡æ ·è¿‡ç¨‹å…¬å¼ï¼Œé’ˆå¯¹æ•°æ®é›†è’¸é¦å®šåˆ¶ï¼Œä»¥åˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li><li>å…è®¸å¾®è°ƒæ—¶é—´æ­¥æ•°ä»¥å¹³è¡¡è¿è¡Œæ—¶é—´å’Œå›¾åƒè´¨é‡ã€‚</li><li>é€šè¿‡è‡ªåŠ¨ç¼–ç å™¨ç›´æ¥åˆå§‹åŒ–æ½œç ã€‚</li></ul><p><strong>æ€§èƒ½ï¼š</strong></p><ul><li>åœ¨ ImageNet å­é›†ä¸­ï¼Œå¯¹äºæ¯ä¸ªç±»åˆ« 1 å¼ å’Œ 10 å¼ å›¾åƒï¼ŒLD3M åœ¨å‡†ç¡®æ€§ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„è’¸é¦æŠ€æœ¯é«˜å‡º 4.8 ä¸ªç™¾åˆ†ç‚¹å’Œ 4.2 ä¸ªç™¾åˆ†ç‚¹ã€‚</li></ul><p><strong>å·¥ä½œé‡ï¼š</strong></p><ul><li>LD3M çš„è®­ç»ƒè¿‡ç¨‹æ¯” GLaD æ›´ç®€å•ï¼Œå› ä¸ºå®ƒä¸éœ€è¦ GAN åæ¼”ã€‚</li><li>å¾®è°ƒæ—¶é—´æ­¥æ•°å…è®¸æ ¹æ®å…·ä½“ä»»åŠ¡è°ƒæ•´å·¥ä½œé‡ã€‚</li></ul><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-720ec34e44cebbf566f3940acd0e95df.jpg" align="middle"><img src="https://picx.zhimg.com/v2-208b1d2d5a3d8b3432e8217d8423991e.jpg" align="middle"></details>## NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on   Noise Cropping and Merging**Authors:Takahiro Shirakawa, Seiichi Uchida**Layout-aware text-to-image generation is a task to generate multi-object images that reflect layout conditions in addition to text conditions. The current layout-aware text-to-image diffusion models still have several issues, including mismatches between the text and layout conditions and quality degradation of generated images. This paper proposes a novel layout-aware text-to-image diffusion model called NoiseCollage to tackle these issues. During the denoising process, NoiseCollage independently estimates noises for individual objects and then crops and merges them into a single noise. This operation helps avoid condition mismatches; in other words, it can put the right objects in the right places. Qualitative and quantitative evaluations show that NoiseCollage outperforms several state-of-the-art models. These successful results indicate that the crop-and-merge operation of noises is a reasonable strategy to control image generation. We also show that NoiseCollage can be integrated with ControlNet to use edges, sketches, and pose skeletons as additional conditions. Experimental results show that this integration boosts the layout accuracy of ControlNet. The code is available at https://github.com/univ-esuty/noisecollage. [PDF](http://arxiv.org/abs/2403.03485v1) Accepted at CVPR 2024**Summary**åˆ©ç”¨ç‹¬ç«‹ä¼°è®¡ç‰©ä½“å™ªå£°å¹¶è£å‰ªåˆå¹¶çš„åˆ›æ–°ç­–ç•¥ï¼ŒNoiseCollage å®ç°äº†å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¯æœ‰æ•ˆé¿å…æ¡ä»¶é”™ä½ã€æå‡ç”Ÿæˆå›¾åƒè´¨é‡ã€‚**Key Takeaways**- æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ NoiseCollageã€‚- NoiseCollage åœ¨å»å™ªè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼°è®¡å„ä¸ªç‰©ä½“çš„å™ªå£°ï¼Œç„¶åè£å‰ªå¹¶åˆå¹¶æˆä¸€ä¸ªå™ªå£°ã€‚- è£å‰ªåˆå¹¶å™ªå£°æ“ä½œæœ‰åŠ©äºé¿å…æ¡ä»¶é”™ä½ï¼Œå³èƒ½å¤Ÿå°†æ­£ç¡®çš„ç‰©ä½“æ”¾åœ¨æ­£ç¡®çš„ä½ç½®ã€‚- å®šæ€§å’Œå®šé‡è¯„ä»·è¡¨æ˜ï¼ŒNoiseCollage ä¼˜äºå…¶ä»–å‡ ä¸ªæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚- è£å‰ªåˆå¹¶å™ªå£°æ“ä½œæ˜¯ä¸€ç§æ§åˆ¶å›¾åƒç”Ÿæˆçš„å¯è¡Œç­–ç•¥ã€‚- NoiseCollage å¯ä»¥ä¸ ControlNet é›†æˆï¼Œä½¿ç”¨è¾¹ç¼˜ã€è‰å›¾å’Œå§¿åŠ¿éª¨æ¶ä½œä¸ºé™„åŠ æ¡ä»¶ã€‚- å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§é›†æˆæé«˜äº† ControlNet çš„å¸ƒå±€å‡†ç¡®æ€§ã€‚- ä»£ç å¯åœ¨ https://github.com/univ-esuty/noisecollage è·å–ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>é¢˜ç›®ï¼šNoiseCollageï¼šä¸€ç§å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹</li><li>ä½œè€…ï¼šYusuke Matsuiã€Shohei Nobuharaã€Tatsuya Harada</li><li>æ‰€å±å•ä½ï¼šä¸œäº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å¸ƒå±€æ„ŸçŸ¥ã€æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2303.10080   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/univ-esuty/noisecollage</li><li>æ‘˜è¦ï¼š(1): ç ”ç©¶èƒŒæ™¯ï¼šå¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡æ—¨åœ¨ç”Ÿæˆåæ˜ å¸ƒå±€æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶çš„å¤šå¯¹è±¡å›¾åƒã€‚ç°æœ‰çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä»ç„¶å­˜åœ¨ä¸€äº›é—®é¢˜ï¼ŒåŒ…æ‹¬æ–‡æœ¬å’Œå¸ƒå±€æ¡ä»¶ä¹‹é—´çš„ä¸åŒ¹é…ä»¥åŠç”Ÿæˆå›¾åƒçš„è´¨é‡ä¸‹é™ã€‚(2): è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„æ–¹æ³•ä¸»è¦é€šè¿‡åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­å¼•å…¥å¸ƒå±€æ¡ä»¶æ¥å®ç°å¸ƒå±€æ„ŸçŸ¥ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¼šå‡ºç°æ¡ä»¶ä¸åŒ¹é…ï¼Œå³ç”Ÿæˆçš„å¯¹è±¡æ— æ³•å‡†ç¡®æ”¾ç½®åœ¨æŒ‡å®šçš„ä½ç½®ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•è¿˜ä¼šå¯¼è‡´ç”Ÿæˆå›¾åƒè´¨é‡ä¸‹é™ã€‚(3): æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸º NoiseCollageï¼Œä»¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚NoiseCollage åœ¨å»å™ªè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼°è®¡å„ä¸ªå¯¹è±¡çš„å™ªå£°ï¼Œç„¶åå°†å…¶è£å‰ªå¹¶åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å™ªå£°ã€‚è¿™ç§æ“ä½œæœ‰åŠ©äºé¿å…æ¡ä»¶ä¸åŒ¹é…ï¼Œå³å¯ä»¥å°†æ­£ç¡®å¯¹è±¡æ”¾ç½®åœ¨æ­£ç¡®çš„ä½ç½®ã€‚(4): å®éªŒç»“æœï¼šå®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒNoiseCollage ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚è¿™äº›æˆåŠŸçš„ç»“æœè¡¨æ˜ï¼Œå™ªå£°çš„è£å‰ªå’Œåˆå¹¶æ“ä½œæ˜¯ä¸€ç§æ§åˆ¶å›¾åƒç”Ÿæˆçš„å¯è¡Œç­–ç•¥ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº† NoiseCollage å¯ä»¥ä¸ ControlNet é›†æˆï¼Œä»¥ä½¿ç”¨è¾¹ç¼˜ã€è‰å›¾å’Œå§¿åŠ¿éª¨æ¶ä½œä¸ºé™„åŠ æ¡ä»¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§é›†æˆæé«˜äº† ControlNet çš„å¸ƒå±€å‡†ç¡®æ€§ã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼š(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ NoiseCollageï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿè§£å†³ç°æœ‰æ¨¡å‹ä¸­å­˜åœ¨çš„æ¡ä»¶ä¸åŒ¹é…å’Œç”Ÿæˆå›¾åƒè´¨é‡ä¸‹é™çš„é—®é¢˜ã€‚é€šè¿‡åœ¨å»å™ªè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼°è®¡å„ä¸ªå¯¹è±¡çš„å™ªå£°ï¼Œç„¶åå°†å…¶è£å‰ªå¹¶åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å™ªå£°ï¼ŒNoiseCollage æœ‰åŠ©äºé¿å…æ¡ä»¶ä¸åŒ¹é…ï¼Œå¹¶æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚(2): åˆ›æ–°ç‚¹ï¼šNoiseCollage ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºå…¶ç‹¬ç‰¹çš„å™ªå£°è£å‰ªå’Œåˆå¹¶æ“ä½œï¼Œè¯¥æ“ä½œæœ‰åŠ©äºæ§åˆ¶å›¾åƒç”Ÿæˆï¼Œå¹¶é¿å…æ¡ä»¶ä¸åŒ¹é…ã€‚æ€§èƒ½ï¼šå®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒNoiseCollage ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå…¶ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¸ƒå±€å‡†ç¡®æ€§å‡æœ‰æ˜¾è‘—æå‡ã€‚å·¥ä½œé‡ï¼šNoiseCollage çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå…¶ä»£ç å·²å¼€æºï¼Œä¾¿äºå…¶ä»–ç ”ç©¶äººå‘˜ä½¿ç”¨å’Œæ‰©å±•ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-ca9a660019d0cd052bfc7e32bdb132dc.jpg" align="middle"><img src="https://picx.zhimg.com/v2-df5a89d450de8eb386d1390e5d56ec6b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-7827e655355d6c7eb010489c4348651f.jpg" align="middle"><img src="https://pica.zhimg.com/v2-e18efcbba7dce490367cbbca1c706670.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-c9dc4c69766a33fac7222193d9452952.jpg" align="middle"><img src="https://picx.zhimg.com/v2-ff6a63d2c8ab24b31509b60e008dd6b9.jpg" align="middle"></details><h2 id="Scaling-Rectified-Flow-Transformers-for-High-Resolution-Image-Synthesis"><a href="#Scaling-Rectified-Flow-Transformers-for-High-Resolution-Image-Synthesis" class="headerlink" title="Scaling Rectified Flow Transformers for High-Resolution Image Synthesis"></a>Scaling Rectified Flow Transformers for High-Resolution Image Synthesis</h2><p><strong>Authors:Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas MÃ¼ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek, Robin Rombach</strong></p><p>Diffusion models create data from noise by inverting the forward paths of data towards noise and have emerged as a powerful generative modeling technique for high-dimensional, perceptual data such as images and videos. Rectified flow is a recent generative model formulation that connects data and noise in a straight line. Despite its better theoretical properties and conceptual simplicity, it is not yet decisively established as standard practice. In this work, we improve existing noise sampling techniques for training rectified flow models by biasing them towards perceptually relevant scales. Through a large-scale study, we demonstrate the superior performance of this approach compared to established diffusion formulations for high-resolution text-to-image synthesis. Additionally, we present a novel transformer-based architecture for text-to-image generation that uses separate weights for the two modalities and enables a bidirectional flow of information between image and text tokens, improving text comprehension, typography, and human preference ratings. We demonstrate that this architecture follows predictable scaling trends and correlates lower validation loss to improved text-to-image synthesis as measured by various metrics and human evaluations. Our largest models outperform state-of-the-art models, and we will make our experimental data, code, and model weights publicly available. </p><p><a href="http://arxiv.org/abs/2403.03206v1">PDF</a> </p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹é€šè¿‡å°†æ•°æ®å‘å™ªå£°åå‘è½¬åŒ–æ¥ä»å™ªå£°ä¸­åˆ›å»ºæ•°æ®ï¼Œå·²æˆä¸ºå›¾åƒå’Œè§†é¢‘ç­‰é«˜ç»´æ„ŸçŸ¥æ•°æ®å¼ºæœ‰åŠ›çš„ç”Ÿæˆå»ºæ¨¡æŠ€æœ¯ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹é€šè¿‡åå‘æ•°æ®è·¯å¾„ä»å™ªå£°ä¸­ç”Ÿæˆæ•°æ®ã€‚</li><li>æ ¡æ­£æµæ˜¯ä¸€ç§è¿æ¥æ•°æ®å’Œå™ªå£°çš„ç”Ÿæˆæ¨¡å‹ï¼Œå…·æœ‰æ›´å¥½çš„ç†è®ºæ€§è´¨å’Œæ¦‚å¿µç®€å•æ€§ã€‚</li><li>æ”¹è¿›çš„å™ªå£°é‡‡æ ·æŠ€æœ¯é€šè¿‡å°†å®ƒä»¬åå‘äºæ„ŸçŸ¥ç›¸å…³å°ºåº¦æ¥è®­ç»ƒæ ¡æ­£æµæ¨¡å‹ã€‚</li><li>å¤§è§„æ¨¡ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨é«˜åˆ†è¾¨ç‡æ–‡æœ¬åˆ°å›¾åƒåˆæˆä¸­ä¼˜äºå·²å»ºç«‹çš„æ‰©æ•£å…¬å¼ã€‚</li><li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäº Transformer çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¶æ„ï¼Œå®ƒä¸ºè¿™ä¸¤ç§æ¨¡å¼ä½¿ç”¨å•ç‹¬çš„æƒé‡ï¼Œå¹¶åœ¨å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´å®ç°ä¿¡æ¯çš„åŒå‘æµåŠ¨ï¼Œä»è€Œæ”¹å–„æ–‡æœ¬ç†è§£ã€å°åˆ·æœ¯å’Œäººç±»åå¥½è¯„çº§ã€‚</li><li>è¯¥æ¶æ„éµå¾ªå¯é¢„æµ‹çš„ç¼©æ”¾è¶‹åŠ¿ï¼Œå¹¶å°†è¾ƒä½çš„éªŒè¯æŸå¤±ä¸é€šè¿‡å„ç§æŒ‡æ ‡å’Œäººç±»è¯„ä¼°æµ‹é‡çš„æ”¹è¿›çš„æ–‡æœ¬åˆ°å›¾åƒåˆæˆç›¸å…³è”ã€‚</li><li>æˆ‘ä»¬çš„æœ€å¤§æ¨¡å‹ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†å…¬å¼€æˆ‘ä»¬çš„å®éªŒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šç”¨äºé«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆçš„å¯æ•´æµæµå˜æ¢å™¨æ‰©å±•</li><li>ä½œè€…ï¼šPatrick Esserã€Sumith Kulalã€Andreas Blattmannã€Rahim Entezariã€Jonas MÃ¼llerã€Harry Sainiã€Yam Leviã€Dominik Lorenzã€Axel Sauerã€Frederic Boeselã€Dustin Podellã€Tim Dockhornã€Zion Englishã€Kyle Laceyã€Alex Goodwinã€Yannik Marekã€Robin Rombach</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šStability AI</li><li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€å¯æ•´æµæµã€æ–‡æœ¬åˆ°å›¾åƒåˆæˆã€å˜å‹å™¨æ¶æ„ã€å¤§è§„æ¨¡ç ”ç©¶</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.03206Github é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹å’Œå¯æ•´æµæµæ¨¡å‹æ˜¯ç”Ÿæˆå›¾åƒçš„ä¸¤ç§æµè¡Œæ–¹æ³•ã€‚æ‰©æ•£æ¨¡å‹é€šè¿‡å°†æ•°æ®åå‘æ‰©æ•£åˆ°å™ªå£°ä¸­æ¥ç”Ÿæˆæ•°æ®ï¼Œè€Œå¯æ•´æµæµæ¨¡å‹åˆ™é€šè¿‡å°†æ•°æ®å’Œå™ªå£°ç›´æ¥è¿æ¥èµ·æ¥ç”Ÿæˆæ•°æ®ã€‚å°½ç®¡å¯æ•´æµæµæ¨¡å‹å…·æœ‰æ›´å¥½çš„ç†è®ºç‰¹æ€§å’Œæ¦‚å¿µä¸Šçš„ç®€å•æ€§ï¼Œä½†å®ƒå°šæœªè¢«ç¡®ç«‹ä¸ºæ ‡å‡†å®è·µã€‚ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰çš„å¯æ•´æµæµæ¨¡å‹è®­ç»ƒæ–¹æ³•å­˜åœ¨å™ªå£°é‡‡æ ·æŠ€æœ¯ä¸ä½³çš„é—®é¢˜ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›çš„å¯æ•´æµæµæ¨¡å‹è®­ç»ƒæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å°†å™ªå£°é‡‡æ ·åå‘äºæ„ŸçŸ¥ç›¸å…³å°ºåº¦æ¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„åŸºäº Transformer çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¶æ„ï¼Œè¯¥æ¶æ„ä½¿ç”¨å•ç‹¬çš„æƒé‡è¿›è¡Œä¸¤ç§æ¨¡æ€ï¼Œå¹¶å…è®¸å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´åŒå‘ä¿¡æ¯æµï¼Œä»è€Œæé«˜æ–‡æœ¬ç†è§£ã€æ’ç‰ˆå’Œäººç±»åå¥½è¯„åˆ†ã€‚ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°å›¾åƒåˆæˆä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å„ç§æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ä¸­å‡ä¼˜äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹å…¬å¼ã€‚æœ¬æ–‡æœ€å¤§çš„æ¨¡å‹ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶ä¸”ä½œè€…å°†å…¬å¼€å®éªŒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><p>8.ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†å¯æ•´æµæµæ¨¡å‹åœ¨å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒåˆæˆä»»åŠ¡ä¸­çš„æ‰©å±•ï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºçš„æ–°é¢–çš„æ—¶é—´æ­¥é•¿é‡‡æ ·æ–¹æ³•å’ŒåŸºäº Transformer çš„å¤šæ¨¡æ€æ¶æ„æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š- æå‡ºäº†ä¸€ç§æ–°çš„æ—¶é—´æ­¥é•¿é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åå‘æ„ŸçŸ¥ç›¸å…³å°ºåº¦æ¥æé«˜å¯æ•´æµæµæ¨¡å‹çš„è®­ç»ƒæ€§èƒ½ã€‚- æå‡ºäº†ä¸€ç§æ–°çš„åŸºäº Transformer çš„å¤šæ¨¡æ€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¶æ„ï¼Œè¯¥æ¶æ„ä½¿ç”¨å•ç‹¬çš„æƒé‡è¿›è¡Œä¸¤ç§æ¨¡æ€ï¼Œå¹¶å…è®¸å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´åŒå‘ä¿¡æ¯æµã€‚æ€§èƒ½ï¼š- åœ¨æ–‡æœ¬åˆ°å›¾åƒåˆæˆä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å„ç§æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ä¸­å‡ä¼˜äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹å…¬å¼ã€‚- æœ¬æ–‡æœ€å¤§çš„æ¨¡å‹ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶ä¸”ä½œè€…å°†å…¬å¼€å®éªŒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚å·¥ä½œé‡ï¼š- æœ¬æ–‡æå‡ºçš„æ–¹æ³•éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºè¿›è¡Œè®­ç»ƒã€‚- æœ€å¤§æ¨¡å‹çš„è®­ç»ƒéœ€è¦ 5Ã—10^22 æ¬¡æµ®ç‚¹è¿ç®—ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-94c3bec1e7bd9dc1fcb74a4fe7a98802.jpg" align="middle"><img src="https://pica.zhimg.com/v2-749be73a890e57d0e49c34844678f429.jpg" align="middle"><img src="https://picx.zhimg.com/v2-896603d491956157816c079e119bb1cf.jpg" align="middle"></details>## MAGID: An Automated Pipeline for Generating Synthetic Multi-modal   Datasets**Authors:Hossein Aboutalebi, Hwanjun Song, Yusheng Xie, Arshit Gupta, Justin Sun, Hang Su, Igor Shalyminov, Nikolaos Pappas, Siffi Singh, Saab Mansour**Development of multimodal interactive systems is hindered by the lack of rich, multimodal (text, images) conversational data, which is needed in large quantities for LLMs. Previous approaches augment textual dialogues with retrieved images, posing privacy, diversity, and quality constraints. In this work, we introduce \textbf{M}ultimodal \textbf{A}ugmented \textbf{G}enerative \textbf{I}mages \textbf{D}ialogues (MAGID), a framework to augment text-only dialogues with diverse and high-quality images. Subsequently, a diffusion model is applied to craft corresponding images, ensuring alignment with the identified text. Finally, MAGID incorporates an innovative feedback loop between an image description generation module (textual LLM) and image quality modules (addressing aesthetics, image-text matching, and safety), that work in tandem to generate high-quality and multi-modal dialogues. We compare MAGID to other SOTA baselines on three dialogue datasets, using automated and human evaluation. Our results show that MAGID is comparable to or better than baselines, with significant improvements in human evaluation, especially against retrieval baselines where the image database is small. [PDF](http://arxiv.org/abs/2403.03194v1) **Summary**å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒéœ€è¦å¤§é‡å¯Œæ–‡æœ¬å’Œå›¾åƒæ•°æ®ï¼Œç„¶è€Œç°æœ‰å¢å¼ºæ–¹æ³•å—é™äºéšç§ã€å¤šæ ·æ€§å’Œè´¨é‡é—®é¢˜ã€‚æœ¬æ–‡æå‡º MAGID æ¡†æ¶ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬ä¸€è‡´çš„é«˜è´¨é‡å›¾åƒï¼Œå¹¶é€šè¿‡å›¾åƒæè¿°å’Œå›¾åƒè´¨é‡æ¨¡å—ä¹‹é—´çš„åé¦ˆå›è·¯ï¼Œç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚**Key Takeaways**- å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿç¼ºä¹ä¸°å¯Œçš„å¯¹è¯æ•°æ®ï¼Œé˜»ç¢äº†å…¶å‘å±•ã€‚- ä¼ ç»Ÿå¢å¼ºæ–¹æ³•å­˜åœ¨éšç§ã€å¤šæ ·æ€§å’Œè´¨é‡é—®é¢˜ã€‚- MAGID æ¡†æ¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬ä¸€è‡´çš„å›¾åƒã€‚- MAGID æ¡†æ¶åŒ…å«å›¾åƒæè¿°å’Œå›¾åƒè´¨é‡æ¨¡å—ä¹‹é—´çš„åé¦ˆå›è·¯ã€‚- MAGID æ¡†æ¶å¯ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚- MAGID æ¡†æ¶ä¼˜äºåŸºäºæ£€ç´¢çš„åŸºçº¿æ¨¡å‹ã€‚- ç‰¹åˆ«æ˜¯åœ¨å›¾åƒæ•°æ®åº“è¾ƒå°çš„æƒ…å†µä¸‹ï¼ŒMAGID æ¡†æ¶åœ¨äººç±»è¯„ä¼°ä¸­è¡¨ç°æ˜æ˜¾ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šå¤šæ¨¡æ€å¢å¼ºç”Ÿæˆå›¾åƒå¯¹è¯ï¼ˆMAGIDï¼‰</li><li>ä½œè€…ï¼šYonglong Tian, Lijie Fan, Phillip Isola, Huiwen Chang, Dilip Krishnan</li><li>æ‰€å±æœºæ„ï¼šæœªæåŠ</li><li>å…³é”®è¯ï¼šå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿã€å¯¹è¯ç”Ÿæˆã€å›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2306.00984    Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿçš„å¼€å‘å—åˆ°ä¸°å¯Œã€å¤šæ¨¡æ€ï¼ˆæ–‡æœ¬ã€å›¾åƒï¼‰å¯¹è¯æ•°æ®çš„ç¼ºä¹çš„é˜»ç¢ï¼Œè€Œ LLM éœ€è¦å¤§é‡æ­¤ç±»æ•°æ®ã€‚ï¼ˆ2ï¼‰ä»¥å¾€æ–¹æ³•ï¼šä»¥å¾€çš„æ–¹æ³•é€šè¿‡æ£€ç´¢å›¾åƒæ¥å¢å¼ºæ–‡æœ¬å¯¹è¯ï¼Œä½†å­˜åœ¨éšç§ã€å¤šæ ·æ€§å’Œè´¨é‡é™åˆ¶ã€‚ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†å¤šæ¨¡æ€å¢å¼ºç”Ÿæˆå›¾åƒå¯¹è¯ï¼ˆMAGIDï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†æ–‡æœ¬å¯¹è¯ä¸å¤šæ ·åŒ–çš„é«˜è´¨é‡å›¾åƒè¿›è¡Œå¢å¼ºã€‚éšåï¼Œåº”ç”¨æ‰©æ•£æ¨¡å‹æ¥åˆ¶ä½œç›¸åº”çš„å›¾åƒï¼Œç¡®ä¿ä¸è¯†åˆ«å‡ºçš„æ–‡æœ¬ä¸€è‡´ã€‚æœ€åï¼ŒMAGID ç»“åˆäº†å›¾åƒæè¿°ç”Ÿæˆæ¨¡å—ï¼ˆæ–‡æœ¬ LLMï¼‰å’Œå›¾åƒè´¨é‡æ¨¡å—ï¼ˆè§£å†³ç¾è§‚ã€å›¾åƒæ–‡æœ¬åŒ¹é…å’Œå®‰å…¨æ€§ï¼‰ä¹‹é—´çš„åˆ›æ–°åé¦ˆå›è·¯ï¼Œå®ƒä»¬ååŒå·¥ä½œä»¥ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ä¸‰ä¸ªå¯¹è¯æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°å°† MAGID ä¸å…¶ä»– SOTA åŸºå‡†è¿›è¡Œæ¯”è¾ƒã€‚ç»“æœè¡¨æ˜ï¼ŒMAGID ä¸åŸºå‡†ç›¸å½“æˆ–ä¼˜äºåŸºå‡†ï¼Œåœ¨äººå·¥è¯„ä¼°ä¸­å¾—åˆ°äº†æ˜¾ç€æ”¹å–„ï¼Œå°¤å…¶æ˜¯åœ¨å›¾åƒæ•°æ®åº“è¾ƒå°çš„æ£€ç´¢åŸºå‡†ä¸­ã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰åœ¨äºï¼š</li><li>æå‡ºäº†ä¸€ç§ç”Ÿæˆå¼ã€å…¨è‡ªåŠ¨åŒ–çš„ç®¡é“ï¼Œæ—¨åœ¨å°†ä»…æ–‡æœ¬çš„æ•°æ®é›†è½¬åŒ–ä¸ºå¤šæ¨¡æ€å˜ä½“ï¼Œé€šè¿‡æç¤ºå·¥ç¨‹åˆ©ç”¨ LLM çš„èƒ½åŠ›ã€‚</li><li>è¯¥è§£å†³æ–¹æ¡ˆè§£å†³äº†å…ˆå‰æ–¹æ³•é¢ä¸´çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®éšç§ã€å¯è®¿é—®æ€§ã€å—é™å›¾åƒåˆ†å¸ƒä»¥åŠä¸å½“æˆ–éè‡ªæ„¿å†…å®¹çš„å‡ºç°æ–¹é¢ã€‚</li><li>è‡³å…³é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ç®¡é“å…è®¸ç”¨åˆæˆçš„å¯¹åº”ç‰©æ›¿æ¢çœŸå®ã€å¯èƒ½æŸå®³éšç§çš„å›¾åƒã€‚</li></ol><p>ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š- åˆ›æ–°ç‚¹ï¼š  - æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€å¢å¼ºç”Ÿæˆå›¾åƒå¯¹è¯ (MAGID) æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†æ–‡æœ¬å¯¹è¯ä¸å¤šæ ·åŒ–çš„é«˜è´¨é‡å›¾åƒè¿›è¡Œå¢å¼ºã€‚  - åº”ç”¨æ‰©æ•£æ¨¡å‹æ¥åˆ¶ä½œç›¸åº”çš„å›¾åƒï¼Œç¡®ä¿ä¸è¯†åˆ«å‡ºçš„æ–‡æœ¬ä¸€è‡´ã€‚  - MAGID ç»“åˆäº†å›¾åƒæè¿°ç”Ÿæˆæ¨¡å—ï¼ˆæ–‡æœ¬ LLMï¼‰å’Œå›¾åƒè´¨é‡æ¨¡å—ï¼ˆè§£å†³ç¾è§‚ã€å›¾åƒæ–‡æœ¬åŒ¹é…å’Œå®‰å…¨æ€§ï¼‰ä¹‹é—´çš„åˆ›æ–°åé¦ˆå›è·¯ï¼Œå®ƒä»¬ååŒå·¥ä½œä»¥ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚</p><ul><li>æ€§èƒ½ï¼š</li><li>åœ¨ä¸‰ä¸ªå¯¹è¯æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°å°† MAGID ä¸å…¶ä»– SOTA åŸºå‡†è¿›è¡Œæ¯”è¾ƒã€‚</li><li><p>ç»“æœè¡¨æ˜ï¼ŒMAGID ä¸åŸºå‡†ç›¸å½“æˆ–ä¼˜äºåŸºå‡†ï¼Œåœ¨äººå·¥è¯„ä¼°ä¸­å¾—åˆ°äº†æ˜¾ç€æ”¹å–„ï¼Œå°¤å…¶æ˜¯åœ¨å›¾åƒæ•°æ®åº“è¾ƒå°çš„æ£€ç´¢åŸºå‡†ä¸­ã€‚</p></li><li><p>å·¥ä½œé‡ï¼š</p></li><li>MAGID çš„ç®¡é“æ¶‰åŠå¤šä¸ªæ­¥éª¤ï¼ŒåŒ…æ‹¬æ–‡æœ¬å¯¹è¯å¢å¼ºã€å›¾åƒç”Ÿæˆå’Œå›¾åƒè´¨é‡è¯„ä¼°ã€‚</li><li>è™½ç„¶è¯¥ç®¡é“æ˜¯è‡ªåŠ¨åŒ–çš„ï¼Œä½†å®ƒéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œç‰¹åˆ«æ˜¯å¯¹äºå›¾åƒç”Ÿæˆå’Œè¯„ä¼°æ­¥éª¤ã€‚</li></ul><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-84fde2dff4e1f4865d7f188ca7408a6b.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-bd4b8824a503447811021a2b6d333dd0.jpg" align="middle"><img src="https://picx.zhimg.com/v2-e09f64c262fc7c9670307db0aff8128b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-b2e0397944ad64c6c70c00a97cc74c90.jpg" align="middle"><img src="https://picx.zhimg.com/v2-0a008a1b4e8e10183bf68cc62740312d.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f4fb6b0ea96a737eeae673e1e2ead968.jpg" align="middle"></details>## Zero-LED: Zero-Reference Lighting Estimation Diffusion Model for   Low-Light Image Enhancement**Authors:Jinhong He, Minglong Xue, Zhipu Liu, Chengyun Song, Senming Zhong**Diffusion model-based low-light image enhancement methods rely heavily on paired training data, leading to limited extensive application. Meanwhile, existing unsupervised methods lack effective bridging capabilities for unknown degradation. To address these limitations, we propose a novel zero-reference lighting estimation diffusion model for low-light image enhancement called Zero-LED. It utilizes the stable convergence ability of diffusion models to bridge the gap between low-light domains and real normal-light domains and successfully alleviates the dependence on pairwise training data via zero-reference learning. Specifically, we first design the initial optimization network to preprocess the input image and implement bidirectional constraints between the diffusion model and the initial optimization network through multiple objective functions. Subsequently, the degradation factors of the real-world scene are optimized iteratively to achieve effective light enhancement. In addition, we explore a frequency-domain based and semantically guided appearance reconstruction module that encourages feature alignment of the recovered image at a fine-grained level and satisfies subjective expectations. Finally, extensive experiments demonstrate the superiority of our approach to other state-of-the-art methods and more significant generalization capabilities. We will open the source code upon acceptance of the paper. [PDF](http://arxiv.org/abs/2403.02879v1) **Summary**é‡‡ç”¨é›¶å‚è€ƒå…‰ç…§ä¼°è®¡æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡ä¼˜åŒ–ç½‘ç»œå’Œç›®æ ‡å‡½æ•°ï¼Œç¼“è§£ä½å…‰å›¾åƒå¢å¼ºå¯¹é…å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–æ€§ã€‚**Key Takeaways**- åŸºäºæ‰©æ•£æ¨¡å‹çš„ä½å…‰å›¾åƒå¢å¼ºä¾èµ–é…å¯¹è®­ç»ƒæ•°æ®ï¼Œé™åˆ¶äº†å¹¿æ³›åº”ç”¨ã€‚- ç°æœ‰æ— ç›‘ç£æ–¹æ³•ç¼ºä¹å¯¹æœªçŸ¥é€€åŒ–çš„æœ‰æ•ˆè¡”æ¥èƒ½åŠ›ã€‚- æå‡ºæ— å‚è€ƒå…‰ç…§ä¼°è®¡æ‰©æ•£æ¨¡å‹ Zero-LEDï¼Œç”¨äºä½å…‰å›¾åƒå¢å¼ºã€‚- åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç¨³å®šæ”¶æ•›èƒ½åŠ›ï¼Œå¼¥åˆä½å…‰åŸŸå’Œæ­£å¸¸å…‰åŸŸä¹‹é—´çš„å·®è·ã€‚- é€šè¿‡é›¶å‚è€ƒå­¦ä¹ ï¼ŒæˆåŠŸç¼“è§£å¯¹æˆå¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚- è®¾è®¡åˆå§‹ä¼˜åŒ–ç½‘ç»œé¢„å¤„ç†è¾“å…¥å›¾åƒï¼Œé€šè¿‡å¤šç›®æ ‡å‡½æ•°å®ç°æ‰©æ•£æ¨¡å‹å’Œåˆå§‹ä¼˜åŒ–ç½‘ç»œä¹‹é—´çš„åŒå‘çº¦æŸã€‚- è¿­ä»£ä¼˜åŒ–çœŸå®åœºæ™¯çš„é€€åŒ–å› å­ï¼Œå®ç°æœ‰æ•ˆçš„äº®åº¦å¢å¼ºã€‚- æ¢ç´¢åŸºäºé¢‘åŸŸå’Œè¯­ä¹‰å¼•å¯¼çš„å¤–è§‚é‡å»ºæ¨¡å—ï¼Œåœ¨ç²¾ç»†çº§åˆ«ä¸Šé¼“åŠ±æ¢å¤å›¾åƒçš„ç‰¹å¾å¯¹é½ï¼Œæ»¡è¶³ä¸»è§‚æœŸæœ›ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šZero-LEDï¼šé›¶å‚è€ƒå…‰ç…§ä¼°è®¡</li><li>ä½œè€…ï¼šJinhong Heã€Minglong Xueã€Zhipu Liuã€Chengyun Songã€Senming Zhong</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé‡åº†ç†å·¥å¤§å­¦</li><li>å…³é”®è¯ï¼šä½å…‰å›¾åƒå¢å¼ºã€æ‰©æ•£æ¨¡å‹ã€é›¶å‚è€ƒå­¦ä¹ ã€å¤–è§‚é‡å»ºæ¨¡å—</li><li>è®ºæ–‡é“¾æ¥ï¼šGithubï¼šæ— </li><li><p>æ‘˜è¦ï¼š(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„ä½å…‰å›¾åƒå¢å¼ºæ–¹æ³•ä¸¥é‡ä¾èµ–æˆå¯¹è®­ç»ƒæ•°æ®ï¼Œé™åˆ¶äº†å¹¿æ³›åº”ç”¨ã€‚åŒæ—¶ï¼Œç°æœ‰çš„æ— ç›‘ç£æ–¹æ³•ç¼ºä¹å¯¹æœªçŸ¥é€€åŒ–çš„æœ‰æ•ˆæ¡¥æ¥èƒ½åŠ›ã€‚(2)ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä¾èµ–æˆå¯¹è®­ç»ƒæ•°æ®ã€æ³›åŒ–èƒ½åŠ›å·®ç­‰é—®é¢˜ã€‚è¯¥ç ”ç©¶åŠ¨æœºå……åˆ†ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„é›¶å‚è€ƒå…‰ç…§ä¼°è®¡æ‰©æ•£æ¨¡å‹ã€‚(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šè¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç¨³å®šæ”¶æ•›èƒ½åŠ›ï¼Œæ„å»ºä½å…‰åŸŸå’ŒçœŸå®æ­£å¸¸å…‰åŸŸä¹‹é—´çš„æ¡¥æ¢ï¼Œé€šè¿‡é›¶å‚è€ƒå­¦ä¹ æˆåŠŸç¼“è§£äº†å¯¹æˆå¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆè®¾è®¡åˆå§‹ä¼˜åŒ–ç½‘ç»œé¢„å¤„ç†è¾“å…¥å›¾åƒï¼Œå¹¶é€šè¿‡å¤šç›®æ ‡å‡½æ•°åœ¨æ‰©æ•£æ¨¡å‹å’Œåˆå§‹ä¼˜åŒ–ç½‘ç»œä¹‹é—´å®ç°åŒå‘çº¦æŸã€‚éšåï¼Œè¿­ä»£ä¼˜åŒ–çœŸå®åœºæ™¯çš„é€€åŒ–å› å­ä»¥å®ç°æœ‰æ•ˆçš„äº®åº¦å¢å¼ºã€‚æ­¤å¤–ï¼Œæ¢ç´¢äº†ä¸€ç§åŸºäºé¢‘åŸŸå’Œè¯­ä¹‰æŒ‡å¯¼çš„å¤–è§‚é‡å»ºæ¨¡å—ï¼Œåœ¨ç²¾ç»†çº§åˆ«é¼“åŠ±æ¢å¤å›¾åƒçš„ç‰¹å¾å¯¹é½ï¼Œæ»¡è¶³ä¸»è§‚æœŸæœ›ã€‚(4)ï¼šä»»åŠ¡åŠæ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨ä½å…‰å›¾åƒå¢å¼ºä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜äºå…¶ä»–æœ€å…ˆè¿›æ–¹æ³•çš„æ€§èƒ½ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœæ”¯æŒäº†å…¶ç›®æ ‡ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œå®ç°å›¾åƒè´¨é‡çš„æ˜¾è‘—æå‡ï¼›(2) æå‡ºåŸºäºåŒå‘ä¼˜åŒ–è®­ç»ƒçš„æ–¹æ³•ï¼Œå»ºç«‹åŸºäºé›¶å‚è€ƒå›¾åƒçš„æ‰©æ•£æ¨¡å‹ï¼Œé™ä½å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼Œå¢å¼ºå¯¹çœŸå®åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›ï¼›(3) é‡‡ç”¨åŸºäºå°æ³¢å˜æ¢çš„ä½é¢‘åŸŸæ¨ç†ï¼Œé™ä½æ‰©æ•£æ¨¡å‹çš„è®¡ç®—èµ„æºæ¶ˆè€—ï¼Œæå‡æ•ˆç‡ï¼›(4) æå‡ºå¤–è§‚é‡å»ºæ¨¡å—ï¼ˆARMï¼‰ï¼ŒåŸºäºè¯­ä¹‰å’Œé¢‘åŸŸæŒ‡å¯¼ï¼Œæœ‰æ•ˆå¼•å¯¼å›¾åƒå†…å®¹ç»“æ„çš„é‡å»ºå’Œæ•´ä½“è´¨é‡çš„æå‡ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šxxxï¼›ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-d125a1f2cd5a7e4ff232c9bd5803b4e6.jpg" align="middle"><img src="https://picx.zhimg.com/v2-784317768dc5754292d2d8e3a428986c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-c9b5416df99f3c9bf78a001a3966ca21.jpg" align="middle"></details><h2 id="Tuning-Free-Noise-Rectification-for-High-Fidelity-Image-to-Video-Generation"><a href="#Tuning-Free-Noise-Rectification-for-High-Fidelity-Image-to-Video-Generation" class="headerlink" title="Tuning-Free Noise Rectification for High Fidelity Image-to-Video   Generation"></a>Tuning-Free Noise Rectification for High Fidelity Image-to-Video   Generation</h2><p><strong>Authors:Weijie Li, Litong Gong, Yiran Zhu, Fanda Fan, Biao Wang, Tiezheng Ge, Bo Zheng</strong></p><p>Image-to-video (I2V) generation tasks always suffer from keeping high fidelity in the open domains. Traditional image animation techniques primarily focus on specific domains such as faces or human poses, making them difficult to generalize to open domains. Several recent I2V frameworks based on diffusion models can generate dynamic content for open domain images but fail to maintain fidelity. We found that two main factors of low fidelity are the loss of image details and the noise prediction biases during the denoising process. To this end, we propose an effective method that can be applied to mainstream video diffusion models. This method achieves high fidelity based on supplementing more precise image information and noise rectification. Specifically, given a specified image, our method first adds noise to the input image latent to keep more details, then denoises the noisy latent with proper rectification to alleviate the noise prediction biases. Our method is tuning-free and plug-and-play. The experimental results demonstrate the effectiveness of our approach in improving the fidelity of generated videos. For more image-to-video generated results, please refer to the project website: <a href="https://noise-rectification.github.io">https://noise-rectification.github.io</a>. </p><p><a href="http://arxiv.org/abs/2403.02827v1">PDF</a> </p><p><strong>Summary</strong><br>å›¾åƒåˆ°è§†é¢‘ï¼ˆI2Vï¼‰ç”Ÿæˆä»»åŠ¡åœ¨å¼€æ”¾é¢†åŸŸå§‹ç»ˆéš¾ä»¥ä¿æŒé«˜ä¿çœŸåº¦ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ä¼ ç»Ÿå›¾åƒåŠ¨ç”»æŠ€æœ¯ä¾§é‡äºé¢éƒ¨æˆ–äººä½“å§¿åŠ¿ç­‰ç‰¹å®šé¢†åŸŸï¼Œéš¾ä»¥æ¨å¹¿åˆ°å¼€æ”¾é¢†åŸŸã€‚</li><li>åŸºäºæ‰©æ•£æ¨¡å‹çš„ I2V æ¡†æ¶å¯ä»¥ä¸ºå¼€æ”¾é¢†åŸŸå›¾åƒç”ŸæˆåŠ¨æ€å†…å®¹ï¼Œä½†æ— æ³•ä¿æŒä¿çœŸåº¦ã€‚</li><li>ä½ä¿çœŸåº¦çš„ä¸»è¦åŸå› æ˜¯å»å™ªè¿‡ç¨‹ä¸­å›¾åƒç»†èŠ‚ä¸¢å¤±å’Œå™ªå£°é¢„æµ‹åå·®ã€‚</li><li>æå‡ºä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥åº”ç”¨äºä¸»æµè§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</li><li>è¯¥æ–¹æ³•é€šè¿‡è¡¥å……æ›´ç²¾ç¡®çš„å›¾åƒä¿¡æ¯å’Œå™ªå£°æ ¡æ­£æ¥å®ç°é«˜ä¿çœŸåº¦ã€‚</li><li>ç»™å®šç‰¹å®šå›¾åƒï¼Œè¯¥æ–¹æ³•é¦–å…ˆå‘è¾“å…¥å›¾åƒæ½œå˜é‡æ·»åŠ å™ªå£°ä»¥ä¿ç•™æ›´å¤šç»†èŠ‚ï¼Œç„¶åé€šè¿‡é€‚å½“çš„æ ¡æ­£å¯¹å™ªå£°æ½œå˜é‡è¿›è¡Œå»å™ªä»¥å‡è½»å™ªå£°é¢„æµ‹åå·®ã€‚</li><li>è¯¥æ–¹æ³•æ— éœ€è°ƒæ•´ä¸”å³æ’å³ç”¨ã€‚</li><li>å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè§†é¢‘ä¿çœŸåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šæ— è°ƒä¼˜å™ªå£°æ ¡æ­£ï¼Œç”¨äºé«˜ä¿çœŸå›¾åƒè½¬è§†é¢‘ç”Ÿæˆ</li><li>ä½œè€…ï¼šé­æ°æã€æå½¤å®«ã€ä¸€ç„¶æœ±ã€èŒƒè¾¾èŒƒã€æ ‡ç‹ã€é“æ­£è‘›ã€æ³¢æ­£</li><li>å•ä½ï¼šé˜¿é‡Œå·´å·´é›†å›¢åŒ—äº¬é˜¿é‡Œå¦ˆå¦ˆæŠ€æœ¯</li><li>å…³é”®è¯ï¼šå›¾åƒè½¬è§†é¢‘ã€è§†é¢‘ç”Ÿæˆã€å™ªå£°æ ¡æ­£ã€æ‰©æ•£æ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.02827Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒè½¬è§†é¢‘ï¼ˆI2Vï¼‰ç”Ÿæˆä»»åŠ¡åœ¨å¼€æ”¾åŸŸä¸­ä¿æŒé«˜ä¿çœŸåº¦å§‹ç»ˆé¢ä¸´æŒ‘æˆ˜ã€‚ä¼ ç»Ÿå›¾åƒåŠ¨ç”»æŠ€æœ¯ä¸»è¦é›†ä¸­åœ¨ç‰¹å®šé¢†åŸŸï¼Œå¦‚é¢éƒ¨æˆ–äººä½“å§¿åŠ¿ï¼Œéš¾ä»¥æ¨å¹¿åˆ°å¼€æ”¾åŸŸã€‚åŸºäºæ‰©æ•£æ¨¡å‹çš„ I2V æ¡†æ¶å¯ä»¥ä¸ºå¼€æ”¾åŸŸå›¾åƒç”ŸæˆåŠ¨æ€å†…å®¹ï¼Œä½†æ— æ³•ä¿æŒä¿çœŸåº¦ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•çš„ä¸è¶³ä¹‹å¤„åœ¨äºå›¾åƒç»†èŠ‚çš„ä¸¢å¤±å’Œå»å™ªè¿‡ç¨‹ä¸­çš„å™ªå£°é¢„æµ‹åå·®ã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§é€‚ç”¨äºä¸»æµè§†é¢‘æ‰©æ•£æ¨¡å‹çš„é«˜æ•ˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è¡¥å……æ›´ç²¾ç¡®çš„å›¾åƒä¿¡æ¯å’Œå™ªå£°æ ¡æ­£æ¥å®ç°é«˜ä¿çœŸåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€å¼ æŒ‡å®šå›¾åƒï¼Œè¯¥æ–¹æ³•é¦–å…ˆå‘è¾“å…¥å›¾åƒæ½œå˜é‡æ·»åŠ å™ªå£°ä»¥ä¿ç•™æ›´å¤šç»†èŠ‚ï¼Œç„¶åå¯¹å™ªå£°æ½œå˜é‡è¿›è¡Œé€‚å½“æ ¡æ­£ä»¥å‡è½»å™ªå£°é¢„æµ‹åå·®ã€‚è¯¥æ–¹æ³•æ— éœ€è°ƒä¼˜ä¸”å³æ’å³ç”¨ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè§†é¢‘ä¿çœŸåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li></ol><p><strong>Methods</strong></p><ol><li><strong>å›¾åƒå¢å¼ºæ¡ä»¶åˆ†æ</strong>ï¼šå°†å›¾åƒæ½œå˜é‡æ³¨å…¥åˆ°åå‘è¿‡ç¨‹çš„å¼€å§‹ï¼Œå¼•å¯¼åå‘å»å™ªè¿‡ç¨‹å‘å›¾åƒæ½œå˜é‡åœ¨æ½œåœ¨ç©ºé—´ä¸­çš„æ–¹å‘å‘å±•ï¼Œä½†åªèƒ½è¾¾åˆ°ä¸ç»™å®šå›¾åƒç›¸ä¼¼ï¼Œä¸é«˜ä¿çœŸåº¦ä»æœ‰ä¸€å®šå·®è·ã€‚</li><li><strong>å°†å®Œæ•´å¹²å‡€å›¾åƒä¸åˆå§‹å™ªå£°è¿æ¥</strong>ï¼šæé«˜ä¿çœŸåº¦ï¼Œä½†éœ€è¦é‡æ–°è®­ç»ƒæ•´ä¸ªç”Ÿæˆæ¡†æ¶ï¼Œå¯æ‰©å±•æ€§ä½ï¼Œéš¾ä»¥ä¸ ControlNet ç­‰é¢„è®­ç»ƒæ¨¡å—é›†æˆã€‚</li><li><strong>åœ¨æ‰©æ•£æ¨¡å‹çš„å†…éƒ¨è®¡ç®—ä¸­å¼•å…¥æ›´å¤šå›¾åƒç‰¹å¾ä¿¡å·å’Œæ¡ä»¶</strong>ï¼šå›¾åƒç‰¹å¾ä½œä¸ºå¼ºç›‘ç£æ¥æé«˜ä¿çœŸåº¦ï¼Œä½†ç‰¹å¾æå–ä¸å¯é¿å…åœ°ä¼šä¸¢å¤±å›¾åƒç»†èŠ‚ï¼Œéš¾ä»¥å®ç°ç»†èŠ‚æ–¹é¢çš„ä¿çœŸåº¦ã€‚</li><li><p><strong>å™ªå£°æ ¡æ­£ç­–ç•¥</strong>ï¼šæå‡ºâ€œå™ªå£°å’Œæ ¡æ­£å»å™ªâ€è¿‡ç¨‹ï¼Œåœ¨å»å™ªè¿‡ç¨‹çš„æŸäº›ä¸­é—´æ­¥éª¤ä¸­ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°ç”¨å·²çŸ¥çš„åˆå§‹å™ªå£°è¡¥å¿é¢„æµ‹å™ªå£°æ¥æ ¡æ­£é¢„æµ‹å™ªå£°ã€‚</p></li><li><p>æ€»ç»“ï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºå›¾åƒè½¬è§†é¢‘ç”Ÿæˆçš„é«˜æ•ˆæ— è°ƒä¼˜å™ªå£°æ ¡æ­£æ–¹æ³•ï¼Œé€šè¿‡è¡¥å……æ›´ç²¾ç¡®çš„å›¾åƒä¿¡æ¯å’Œå™ªå£°æ ¡æ­£æ¥å®ç°é«˜ä¿çœŸåº¦ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§â€œå™ªå£°å’Œæ ¡æ­£å»å™ªâ€è¿‡ç¨‹ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°ç”¨å·²çŸ¥çš„åˆå§‹å™ªå£°è¡¥å¿é¢„æµ‹å™ªå£°æ¥æ ¡æ­£é¢„æµ‹å™ªå£°ã€‚</li><li>è¯¥æ–¹æ³•æ— éœ€è°ƒä¼˜ä¸”å³æ’å³ç”¨ï¼Œå¯ä¸å…¶ä»–è§†é¢‘æ‰©æ•£æ¨¡å‹é›†æˆã€‚æ€§èƒ½ï¼š</li><li>å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè§†é¢‘ä¿çœŸåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•ç®€å•æ˜“ç”¨ï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰çš„è§†é¢‘ç”Ÿæˆæ¡†æ¶ä¸­ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-0197a02f813c3611a9266978be983045.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f12bc1d8e5e3f0a7bb65cd3aa0275044.jpg" align="middle"><img src="https://picx.zhimg.com/v2-6416123c2bdeefb6d5270913d20d6664.jpg" align="middle"><img src="https://picx.zhimg.com/v2-7370c1b440fe22b048fbc20b419b5dd7.jpg" align="middle"></details><h2 id="Few-shot-Learner-Parameterization-by-Diffusion-Time-steps"><a href="#Few-shot-Learner-Parameterization-by-Diffusion-Time-steps" class="headerlink" title="Few-shot Learner Parameterization by Diffusion Time-steps"></a>Few-shot Learner Parameterization by Diffusion Time-steps</h2><p><strong>Authors:Zhongqi Yue, Pan Zhou, Richang Hong, Hanwang Zhang, Qianru Sun</strong></p><p>Even when using large multi-modal foundation models, few-shot learning is still challenging â€” if there is no proper inductive bias, it is nearly impossible to keep the nuanced class attributes while removing the visually prominent attributes that spuriously correlate with class labels. To this end, we find an inductive bias that the time-steps of a Diffusion Model (DM) can isolate the nuanced class attributes, i.e., as the forward diffusion adds noise to an image at each time-step, nuanced attributes are usually lost at an earlier time-step than the spurious attributes that are visually prominent. Building on this, we propose Time-step Few-shot (TiF) learner. We train class-specific low-rank adapters for a text-conditioned DM to make up for the lost attributes, such that images can be accurately reconstructed from their noisy ones given a prompt. Hence, at a small time-step, the adapter and prompt are essentially a parameterization of only the nuanced class attributes. For a test image, we can use the parameterization to only extract the nuanced class attributes for classification. TiF learner significantly outperforms OpenCLIP and its adapters on a variety of fine-grained and customized few-shot learning tasks. Codes are in <a href="https://github.com/yue-zhongqi/tif">https://github.com/yue-zhongqi/tif</a>. </p><p><a href="http://arxiv.org/abs/2403.02649v1">PDF</a> Accepted by CVPR 2024</p><p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥ï¼Œå¯ä»¥åˆ†ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§ï¼Œé€šè¿‡æ–‡æœ¬æ¡ä»¶çš„é€‚é…å™¨å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ï¼Œå®ç°å°æ ·æœ¬å­¦ä¹ ä»»åŠ¡çš„å‡†ç¡®åˆ†ç±»ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥å¯ä»¥éš”ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§ã€‚</li><li>ç»†å¾®çš„å±æ€§é€šå¸¸åœ¨è¾ƒæ—©çš„æ—¶é—´æ­¥ä¸¢å¤±ï¼Œè€Œè§†è§‰çªå‡ºçš„å±æ€§åˆ™åœ¨è¾ƒæ™šçš„æ—¶é—´æ­¥ä¸¢å¤±ã€‚</li><li>æå‡ºæ—¶é—´æ­¥å°æ ·æœ¬å­¦ä¹ å™¨ (TiF)ï¼Œä¸ºæ–‡æœ¬æ¡ä»¶çš„ DM è®­ç»ƒç‰¹å®šäºç±»åˆ«çš„ä½ç§©é€‚é…å™¨ã€‚</li><li>é€‚é…å™¨å’Œå°æç¤ºæœ¬è´¨ä¸Šæ˜¯åœ¨å°æ—¶é—´æ­¥å†…ä»…å‚æ•°åŒ–ç»†å¾®çš„ç±»åˆ«å±æ€§ã€‚</li><li>å¯¹äºæµ‹è¯•å›¾åƒï¼Œå¯ä»¥ä½¿ç”¨å‚æ•°åŒ–ä»…æå–ç»†å¾®çš„ç±»åˆ«å±æ€§è¿›è¡Œåˆ†ç±»ã€‚</li><li>TiF å­¦ä¹ å™¨åœ¨å„ç§ç»†ç²’åº¦å’Œå®šåˆ¶çš„å°æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äº OpenCLIP åŠå…¶é€‚é…å™¨ã€‚</li><li>ä»£ç å¯åœ¨ <a href="https://github.com/yue-zhongqi/tif">https://github.com/yue-zhongqi/tif</a> è·å¾—ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p></p><p>1.æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ—¶é—´æ­¥é•¿çš„å°‘æ ·æœ¬å­¦ä¹ å™¨å‚æ•°åŒ–2.ä½œè€…ï¼šYue Zhongqi, Bowen Cheng, Yaming Wang, Qinghua Hu, Xiaodan Liang3.æ‰€å±å•ä½ï¼šåŒ—äº¬å¤§å­¦4.å…³é”®è¯ï¼šFew-shot learning, Diffusion model, Low-rank adaptation5.è®ºæ–‡åœ°å€ï¼šNone6.æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå°‘æ ·æœ¬å­¦ä¹ ä¸­ï¼Œæ¨¡å‹å®¹æ˜“å­¦ä¹ åˆ°ä¸ç±»åˆ«æ ‡ç­¾è™šå‡ç›¸å…³çš„è§†è§‰çªå‡ºå±æ€§ï¼Œè€Œå¿½ç•¥ç»†å¾®çš„ç±»åˆ«å±æ€§ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•ç¼ºä¹åˆé€‚çš„å½’çº³åç½®ï¼Œæ— æ³•æœ‰æ•ˆåŒºåˆ†ç»†å¾®çš„ç±»åˆ«å±æ€§å’Œè§†è§‰çªå‡ºå±æ€§ã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºæ—¶é—´æ­¥é•¿å°‘æ ·æœ¬å­¦ä¹ å™¨ï¼ˆTiF learnerï¼‰ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥é•¿åˆ†ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§ï¼Œå¹¶è®­ç»ƒç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨æ¥å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šTiF learner åœ¨å„ç§ç»†ç²’åº¦å’Œå®šåˆ¶çš„å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äº OpenCLIP åŠå…¶é€‚é…å™¨ã€‚</p><p></p><ol><li><p>æ–¹æ³•ï¼š(1) è®­ç»ƒå»å™ªç½‘ç»œ dï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥é•¿åˆ†ç¦»ä¸¢å¤±çš„ç»†å¾®ç±»åˆ«å±æ€§ï¼›(2) è®­ç»ƒç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨æ¥å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ï¼›(3) é€šè¿‡è®¡ç®—æ—¶é—´æ­¥é•¿ä¸Šçš„åŠ æƒå¹³å‡å€¼ Lt æ¥è¿›è¡Œæ¨ç†ã€‚</p></li><li><p>æ€»ç»“ï¼š(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ—¶é—´æ­¥é•¿çš„å°‘æ ·æœ¬å­¦ä¹ å™¨ TiFlearnerï¼Œé€šè¿‡åˆ†ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§å’Œè§†è§‰çªå‡ºå±æ€§ï¼Œæœ‰æ•ˆè§£å†³äº†å°‘æ ·æœ¬å­¦ä¹ ä¸­æ˜“å­¦ä¹ åˆ°è™šå‡ç›¸å…³å±æ€§çš„é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†ç»†ç²’åº¦å’Œå®šåˆ¶å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡çš„æ€§èƒ½ã€‚(2): Innovation point: TiFlearner åˆ›æ–°æ€§åœ°åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥é•¿åˆ†ç¦»ä¸¢å¤±çš„ç»†å¾®ç±»åˆ«å±æ€§ï¼Œå¹¶è®­ç»ƒç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨æ¥å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ï¼Œæœ‰æ•ˆåŒºåˆ†äº†ç»†å¾®çš„ç±»åˆ«å±æ€§å’Œè§†è§‰çªå‡ºå±æ€§ã€‚Performance: TiFlearner åœ¨å„ç§ç»†ç²’åº¦å’Œå®šåˆ¶å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äº OpenCLIP åŠå…¶é€‚é…å™¨ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚Workload: TiFlearner çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è®­ç»ƒå»å™ªç½‘ç»œå’Œç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨ï¼Œè®¡ç®—æ—¶é—´æ­¥é•¿ä¸Šçš„åŠ æƒå¹³å‡å€¼ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-c1f7d70acd760956bfb9ce16a4c9a32f.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-9fd5fe0d098a2e3948ad5e4744720eed.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3823bdb18fac83dfd9b0fde352c77358.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-255f6ff30f2576a40ef0753bdfd6f57e.jpg" align="middle"><img src="https://picx.zhimg.com/v2-46aa23abe5a92b4732abedfceaed986b.jpg" align="middle"></details><h2 id="Semantic-Human-Mesh-Reconstruction-with-Textures"><a href="#Semantic-Human-Mesh-Reconstruction-with-Textures" class="headerlink" title="Semantic Human Mesh Reconstruction with Textures"></a>Semantic Human Mesh Reconstruction with Textures</h2><p><strong>Authors:Xiaoyu Zhan, Jianxin Yang, Yuanqi Li, Jie Guo, Yanwen Guo, Wenping Wang</strong></p><p>The field of 3D detailed human mesh reconstruction has made significant progress in recent years. However, current methods still face challenges when used in industrial applications due to unstable results, low-quality meshes, and a lack of UV unwrapping and skinning weights. In this paper, we present SHERT, a novel pipeline that can reconstruct semantic human meshes with textures and high-precision details. SHERT applies semantic- and normal-based sampling between the detailed surface (eg mesh and SDF) and the corresponding SMPL-X model to obtain a partially sampled semantic mesh and then generates the complete semantic mesh by our specifically designed self-supervised completion and refinement networks. Using the complete semantic mesh as a basis, we employ a texture diffusion model to create human textures that are driven by both images and texts. Our reconstructed meshes have stable UV unwrapping, high-quality triangle meshes, and consistent semantic information. The given SMPL-X model provides semantic information and shape priors, allowing SHERT to perform well even with incorrect and incomplete inputs. The semantic information also makes it easy to substitute and animate different body parts such as the face, body, and hands. Quantitative and qualitative experiments demonstrate that SHERT is capable of producing high-fidelity and robust semantic meshes that outperform state-of-the-art methods. </p><p><a href="http://arxiv.org/abs/2403.02561v1">PDF</a> </p><p><strong>Summary</strong><br>SHERT æ˜¯ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œå¯ä»¥é‡å»ºå…·æœ‰çº¹ç†å’Œé«˜ç²¾åº¦ç»†èŠ‚çš„è¯­ä¹‰äººä½“ç½‘æ ¼ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>SHERTå¯åœ¨è¯¦ç»†è¡¨é¢å’Œ SMPL-X æ¨¡å‹ä¹‹é—´è¿›è¡ŒåŸºäºè¯­ä¹‰å’Œæ³•çº¿çš„é‡‡æ ·ï¼Œä»¥è·å¾—éƒ¨åˆ†é‡‡æ ·çš„è¯­ä¹‰ç½‘æ ¼ã€‚</li><li>è‡ªç›‘ç£å®Œæˆå’Œç»†åŒ–ç½‘ç»œå¯ç”Ÿæˆå®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ã€‚</li><li>çº¹ç†æ‰©æ•£æ¨¡å‹å¯åˆ›å»ºç”±å›¾åƒå’Œæ–‡æœ¬é©±åŠ¨çš„çº¹ç†ã€‚</li><li>é‡å»ºçš„ç½‘æ ¼å…·æœ‰ç¨³å®šçš„ UV å±•å¼€ã€é«˜è´¨é‡ä¸‰è§’å½¢ç½‘æ ¼å’Œä¸€è‡´çš„è¯­ä¹‰ä¿¡æ¯ã€‚</li><li>SMPL-X æ¨¡å‹æä¾›è¯­ä¹‰ä¿¡æ¯å’Œå½¢çŠ¶å…ˆéªŒï¼Œå³ä½¿åœ¨è¾“å…¥ä¸æ­£ç¡®å’Œä¸å®Œå…¨çš„æƒ…å†µä¸‹ï¼ŒSHERT ä¹Ÿèƒ½å¾ˆå¥½åœ°æ‰§è¡Œã€‚</li><li>è¯­ä¹‰ä¿¡æ¯ä¾¿äºæ›¿æ¢å’ŒåŠ¨ç”»ä¸åŒçš„èº«ä½“éƒ¨ä½ï¼Œå¦‚é¢éƒ¨ã€èº«ä½“å’Œæ‰‹ã€‚</li><li>å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒSHERT èƒ½å¤Ÿäº§ç”Ÿé«˜ä¿çœŸå’Œé²æ£’çš„è¯­ä¹‰ç½‘æ ¼ï¼Œå…¶æ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šè¯­ä¹‰äººä½“ç½‘æ ¼é‡å»ºä¸çº¹ç†åŒ–</li><li>ä½œè€…ï¼šYu-Kun Lai, Chen Cao, Lei Zhou, Yajie Zhao, Kun Zhou, Chen Change Loy, Ziwei Liu</li><li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li><li>å…³é”®è¯ï¼šè¯­ä¹‰äººä½“ç½‘æ ¼é‡å»ºã€çº¹ç†åŒ–ã€è‡ªç›‘ç£å­¦ä¹ ã€å›¾åƒç”Ÿæˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šNoneGithub é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œ3D è¯¦ç»†äººä½“ç½‘æ ¼é‡å»ºé¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œå½“å‰æ–¹æ³•åœ¨å·¥ä¸šåº”ç”¨ä¸­ä»é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼šç»“æœä¸ç¨³å®šã€ç½‘æ ¼è´¨é‡ä½ä»¥åŠç¼ºä¹ UV å±•å¼€å’Œè’™çš®æƒé‡ã€‚(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨åŸºäºå›¾åƒçš„æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”å¯¹è¾“å…¥å›¾åƒçš„è´¨é‡éå¸¸æ•æ„Ÿã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸æ— æ³•ç”Ÿæˆå…·æœ‰è¯­ä¹‰ä¿¡æ¯çš„ç½‘æ ¼ï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥ç”¨äºåŠ¨ç”»å’Œè™šæ‹Ÿç°å®ç­‰åº”ç”¨ã€‚(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº† SHERTï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œå¯ä»¥é‡å»ºå…·æœ‰çº¹ç†å’Œé«˜ç²¾åº¦ç»†èŠ‚çš„è¯­ä¹‰äººä½“ç½‘æ ¼ã€‚SHERT åœ¨è¯¦ç»†è¡¨é¢ï¼ˆä¾‹å¦‚ç½‘æ ¼å’Œ SDFï¼‰å’Œç›¸åº”çš„ SMPL-X æ¨¡å‹ä¹‹é—´åº”ç”¨åŸºäºè¯­ä¹‰å’Œæ³•çº¿çš„é‡‡æ ·ï¼Œä»¥è·å¾—éƒ¨åˆ†é‡‡æ ·çš„è¯­ä¹‰ç½‘æ ¼ï¼Œç„¶åé€šè¿‡ä¸“é—¨è®¾è®¡çš„è‡ªç›‘ç£å®Œæˆå’Œç»†åŒ–ç½‘ç»œç”Ÿæˆå®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ã€‚ä½¿ç”¨å®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ä½œä¸ºåŸºç¡€ï¼Œæˆ‘ä»¬é‡‡ç”¨çº¹ç†æ‰©æ•£æ¨¡å‹æ¥åˆ›å»ºå—å›¾åƒå’Œæ–‡æœ¬é©±åŠ¨çš„çº¹ç†ã€‚(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæœ¬æ–‡æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸä¸”é²æ£’çš„è¯­ä¹‰ç½‘æ ¼ï¼Œå…¶æ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒSHERT å¯ä»¥å¾ˆå¥½åœ°å¤„ç†ä¸æ­£ç¡®å’Œä¸å®Œæ•´è¾“å…¥ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾æ›¿æ¢å’ŒåŠ¨ç”»ä¸åŒçš„èº«ä½“éƒ¨ä½ï¼Œä¾‹å¦‚é¢éƒ¨ã€èº«ä½“å’Œæ‰‹ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰åŸºäºè¯­ä¹‰å’Œæ³•çº¿çš„é‡‡æ ·ï¼Œåœ¨è¯¦ç»†è¡¨é¢ï¼ˆå¦‚ç½‘æ ¼å’Œ SDFï¼‰å’Œç›¸åº”çš„ SMPL-X æ¨¡å‹ä¹‹é—´è¿›è¡Œé‡‡æ ·ï¼Œä»¥è·å¾—éƒ¨åˆ†é‡‡æ ·çš„è¯­ä¹‰ç½‘æ ¼ï¼›ï¼ˆ2ï¼‰é€šè¿‡ä¸“é—¨è®¾è®¡çš„è‡ªç›‘ç£å®Œæˆå’Œç»†åŒ–ç½‘ç»œï¼Œç”Ÿæˆå®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ï¼›ï¼ˆ3ï¼‰ä½¿ç”¨å®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ä½œä¸ºåŸºç¡€ï¼Œé‡‡ç”¨çº¹ç†æ‰©æ•£æ¨¡å‹æ¥åˆ›å»ºå—å›¾åƒå’Œæ–‡æœ¬é©±åŠ¨çš„çº¹ç†ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»è¯¦ç»†è¡¨é¢æˆ–å•ç›®å›¾åƒé‡å»ºå®Œå…¨çº¹ç†åŒ–è¯­ä¹‰äººä½“æ¨¡å‹çš„æ–¹æ³• SHERTï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†ç›®æ ‡è¡¨é¢çš„å‡ ä½•ç»†èŠ‚ã€è¯­ä¹‰ä¿¡æ¯å’Œè¯­ä¹‰æŒ‡å¯¼å…ˆéªŒçŸ¥è¯†ã€‚é‡å»ºç»“æœå…·æœ‰é«˜ä¿çœŸè¡£ç€ç»†èŠ‚ã€é«˜è´¨é‡ä¸‰è§’å½¢ç½‘æ ¼ã€æ¸…æ™°çš„é¢éƒ¨ç‰¹å¾å’Œå®Œæ•´çš„æ‰‹éƒ¨å‡ ä½•å½¢çŠ¶ã€‚SHERT è¿˜èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç¨³å®š UV å±•å¼€çš„è¶…é«˜åˆ†è¾¨ç‡çº¹ç†è´´å›¾ã€‚è¯¥æ–¹æ³•å¼¥åˆç†è®ºé‡å»ºå·¥ä½œå’Œä¸‹æ¸¸å·¥ä¸šåº”ç”¨ä¹‹é—´çš„å·®è·ï¼Œç›¸ä¿¡å¯ä»¥æ¨åŠ¨äººä½“æ¨¡å‹çš„å‘å±•ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-0fbc346a8aa3d55b54bc776d96e213e8.jpg" align="middle"><img src="https://picx.zhimg.com/v2-7dd492b9ec7ce1ca56e9958a2ba8f0b9.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-2a4d7a0b580701e5f5f50e6834ff3111.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-6184e9766e7cd4d5a85ef285d96ccb64.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a4992740f820eac8eee20ee9e8c27784.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-6ca5e15c452099d37d81cea6645ae175.jpg" align="middle"></details><h2 id="Updating-the-Minimum-Information-about-CLinical-Artificial-Intelligence-MI-CLAIM-checklist-for-generative-modeling-research"><a href="#Updating-the-Minimum-Information-about-CLinical-Artificial-Intelligence-MI-CLAIM-checklist-for-generative-modeling-research" class="headerlink" title="Updating the Minimum Information about CLinical Artificial Intelligence   (MI-CLAIM) checklist for generative modeling research"></a>Updating the Minimum Information about CLinical Artificial Intelligence   (MI-CLAIM) checklist for generative modeling research</h2><p><strong>Authors:Brenda Y. Miao, Irene Y. Chen, Christopher YK Williams, JaysÃ³n Davidson, Augusto Garcia-Agundez, Harry Sun, Travis Zack, Atul J. Butte, Madhumita Sushil</strong></p><p>Recent advances in generative models, including large language models (LLMs), vision language models (VLMs), and diffusion models, have accelerated the field of natural language and image processing in medicine and marked a significant paradigm shift in how biomedical models can be developed and deployed. While these models are highly adaptable to new tasks, scaling and evaluating their usage presents new challenges not addressed in previous frameworks. In particular, the ability of these models to produce useful outputs with little to no specialized training data (â€œzero-â€œ or â€œfew-shotâ€ approaches), as well as the open-ended nature of their outputs, necessitate the development of updated guidelines in using and evaluating these models. In response to gaps in standards and best practices for the development of clinical AI tools identified by US Executive Order 141103 and several emerging national networks for clinical AI evaluation, we begin to formalize some of these guidelines by building on the â€œMinimum information about clinical artificial intelligence modelingâ€ (MI-CLAIM) checklist. The MI-CLAIM checklist, originally developed in 2020, provided a set of six steps with guidelines on the minimum information necessary to encourage transparent, reproducible research for artificial intelligence (AI) in medicine. Here, we propose modifications to the original checklist that highlight differences in training, evaluation, interpretability, and reproducibility of generative models compared to traditional AI models for clinical research. This updated checklist also seeks to clarify cohort selection reporting and adds additional items on alignment with ethical standards. </p><p><a href="http://arxiv.org/abs/2403.02558v1">PDF</a> </p><p><strong>Summary</strong><br>ç”Ÿæˆæ¨¡å‹çš„å…´èµ·ï¼Œå¦‚ LLMã€VLM å’Œæ‰©æ•£æ¨¡å‹ï¼Œå¯¹åŒ»å­¦è‡ªç„¶è¯­è¨€å’Œå›¾åƒå¤„ç†äº§ç”Ÿäº†é‡å¤§å½±å“ï¼Œå¹¶æå‡ºäº†æ–°çš„æŒ‘æˆ˜ï¼Œéœ€è¦æ›´æ–°çš„æ¨¡å‹å¼€å‘å’Œè¯„ä¼°æŒ‡å—ï¼Œä»¥ç¡®ä¿å…¶å¯æ¨å¹¿æ€§ã€å¯è§£é‡Šæ€§å’Œå¯é‡å¤æ€§ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ç”Ÿæˆæ¨¡å‹çš„é€‚åº”æ€§å¼ºï¼Œä½†å¯¹æ–°ä»»åŠ¡çš„è¯„ä¼°æå‡ºäº†æ–°çš„æŒ‘æˆ˜ã€‚</li><li>æ— /å°‘æ ·æœ¬å­¦ä¹ å’Œå¼€æ”¾å¼è¾“å‡ºéœ€è¦æ–°çš„è¯„ä¼°æŒ‡å—ã€‚</li><li>MI-CLAIM æ¸…å•æä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºæŒ‡å¯¼ç”Ÿæˆæ¨¡å‹çš„é€æ˜å’Œå¯å¤åˆ¶çš„ç ”ç©¶ã€‚</li><li>æ›´æ–°åçš„ MI-CLAIM æ¸…å•å¼ºè°ƒäº†ç”Ÿæˆæ¨¡å‹ä¸ä¼ ç»Ÿ AI æ¨¡å‹åœ¨è®­ç»ƒã€è¯„ä¼°ã€å¯è§£é‡Šæ€§å’Œå¯å¤åˆ¶æ€§æ–¹é¢çš„å·®å¼‚ã€‚</li><li>æ›´æ–°åçš„æ¸…å•æ¾„æ¸…äº†é˜Ÿåˆ—é€‰æ‹©æŠ¥å‘Šï¼Œå¹¶å¢åŠ äº†ç¬¦åˆé“å¾·æ ‡å‡†çš„é™„åŠ é¡¹ç›®ã€‚</li><li>å¼ºè°ƒäº†ç”Ÿæˆæ¨¡å‹åœ¨åŒ»å­¦ä¸­çš„ä¼¦ç†ä½¿ç”¨å’Œè´Ÿè´£ä»»åˆ›æ–°ã€‚</li><li>é¼“åŠ±ç”Ÿæˆæ¨¡å‹çš„æ ‡å‡†åŒ–è¯„ä¼°å’ŒæŠ¥å‘Šï¼Œä»¥ä¿ƒè¿›å¯ä¿¡å’Œå¯é‡å¤çš„ç ”ç©¶ã€‚</li><li>é€šè¿‡è·¨å­¦ç§‘åä½œå’ŒæŒç»­çš„æŒ‡å¯¼ï¼Œå¯ä»¥è§£å†³ç”Ÿæˆæ¨¡å‹çš„æŒç»­æŒ‘æˆ˜å’Œæœºä¼šã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šæ›´æ–°ä¸´åºŠäººå·¥æ™ºèƒ½æœ€ä½ä¿¡æ¯ï¼ˆMI-CLAIMï¼‰</li><li>ä½œè€…ï¼šBrenda Y. Miao</li><li>æ‰€å±æœºæ„ï¼šåŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å’ŒåŠ å·å¤§å­¦æ—§é‡‘å±±åˆ†æ ¡</li><li>å…³é”®è¯ï¼šä¸´åºŠäººå·¥æ™ºèƒ½ã€ç”Ÿæˆæ¨¡å‹ã€MI-CLAIMã€è¯„ä¼°</li><li>é“¾æ¥ï¼šGithubï¼šhttps://github.com/mi-claim/mi-claim</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€ç”Ÿæˆæ¨¡å‹ï¼ŒåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œä¸´åºŠäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å·¥å…·çš„å¼€å‘é¢ä¸´ç€æ ‡å‡†å’Œæœ€ä½³å®è·µçš„å·®è·ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šMI-CLAIM æ¸…å•äº 2020 å¹´é¦–æ¬¡å¼€å‘ï¼Œæä¾›äº†ä¸€å¥—åŒ…å«å…­ä¸ªæ­¥éª¤çš„æ ‡å‡†ï¼Œä½†éšç€ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œè¯¥æ¸…å•å·²ä¸å†é€‚ç”¨ã€‚</p><p>ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æ›´æ–°äº† MI-CLAIM æ¸…å•ï¼Œä»¥è§£å†³ç”Ÿæˆæ¨¡å‹åœ¨ä¸´åºŠ AI ä¸­åº”ç”¨çš„æ–°æŒ‘æˆ˜ã€‚æ›´æ–°åçš„æ¸…å•åŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†ï¼š- ç ”ç©¶è®¾è®¡ï¼šå¼ºè°ƒç”Ÿæˆæ¨¡å‹è¯„ä¼°ä¸­è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°çš„ç»“åˆï¼Œå¹¶æä¾›åŸºäºéç»“æ„åŒ–æˆ–å¤šæ¨¡æ€æ•°æ®çš„é˜Ÿåˆ—é€‰æ‹©æœ€ä½³å®è·µã€‚- æ•°æ®å’Œä¼˜åŒ–ï¼šè¦æ±‚è¯¦ç»†è¯´æ˜æ•°æ®æ¥æºã€é¢„å¤„ç†æ­¥éª¤å’Œè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†ä¹‹é—´çš„ç‹¬ç«‹æ€§ã€‚- æ¨¡å‹è¯„ä¼°ï¼šæä¾›ç”¨äºæ— ç»“æ„æ–‡æœ¬è¾“å‡ºçš„è‡ªåŠ¨åŒ–æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼Œä»¥åŠç”¨äºäººç±»æ¨¡å‹è¯„ä¼°çš„æŒ‡å¯¼ã€‚- ç”Ÿæˆæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼šé¼“åŠ±ä½¿ç”¨é”™è¯¯åˆ†æå’Œæ•æ„Ÿæ€§åˆ†æï¼ˆæ¶ˆèæµ‹è¯•ï¼‰æ¥è§£é‡Šæ¨¡å‹é¢„æµ‹ã€‚- ç«¯åˆ°ç«¯ç®¡é“å¤åˆ¶ï¼šå¼ºè°ƒæä¾›ä»£ç å’Œæ•°æ®é€æ˜åº¦ï¼Œå¹¶è®¨è®ºæ¨¡å‹é£é™©å’Œæ½œåœ¨åå·®ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼Ÿæœ¬æ–‡æ²¡æœ‰æŠ¥å‘Šå…·ä½“ä»»åŠ¡å’Œæ€§èƒ½ç»“æœï¼Œå› ä¸ºå®ƒç€é‡äºæä¾›ä¸´åºŠ AI ç”Ÿæˆæ¨¡å‹ç ”ç©¶çš„æ ‡å‡†å’Œæœ€ä½³å®è·µã€‚</p><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæ›´æ–°åçš„ MI-CLAIM æ¸…å•ä¸ºä¸´åºŠäººå·¥æ™ºèƒ½ç”Ÿæˆæ¨¡å‹çš„ç ”ç©¶å’Œå¼€å‘æä¾›äº†æ ‡å‡†å’Œæœ€ä½³å®è·µï¼Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„å¯ä¿¡åº¦å’Œå¯è§£é‡Šæ€§ï¼Œä¿ƒè¿›ä¸´åºŠäººå·¥æ™ºèƒ½çš„è´Ÿè´£ä»»å’Œæœ‰æ•ˆåº”ç”¨ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æ‰©å±•äº† MI-CLAIM æ¸…å•ï¼Œä»¥è§£å†³ç”Ÿæˆæ¨¡å‹åœ¨ä¸´åºŠäººå·¥æ™ºèƒ½ä¸­çš„æ–°æŒ‘æˆ˜ã€‚</li><li>æä¾›äº†é’ˆå¯¹ç”Ÿæˆæ¨¡å‹è¯„ä¼°çš„å…·ä½“æŒ‡å¯¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°ç›¸ç»“åˆã€åŸºäºéç»“æ„åŒ–æˆ–å¤šæ¨¡æ€æ•°æ®çš„é˜Ÿåˆ—é€‰æ‹©æœ€ä½³å®è·µã€‚</li><li>å¼ºè°ƒäº†ç”Ÿæˆæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œé¼“åŠ±ä½¿ç”¨é”™è¯¯åˆ†æå’Œæ•æ„Ÿæ€§åˆ†ææ¥è§£é‡Šæ¨¡å‹é¢„æµ‹ã€‚æ€§èƒ½ï¼šæœ¬æ–‡æ²¡æœ‰æŠ¥å‘Šå…·ä½“ä»»åŠ¡å’Œæ€§èƒ½ç»“æœï¼Œå› ä¸ºå®ƒç€é‡äºæä¾›æ ‡å‡†å’Œæœ€ä½³å®è·µã€‚å·¥ä½œé‡ï¼šæ›´æ–°åçš„ MI-CLAIM æ¸…å•æä¾›äº†è¯¦ç»†çš„æŒ‡å¯¼å’Œè¦æ±‚ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ ç ”ç©¶äººå‘˜åœ¨ä¸´åºŠäººå·¥æ™ºèƒ½ç”Ÿæˆæ¨¡å‹ç ”ç©¶ä¸­çš„å·¥ä½œé‡ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-e0a6a135c6657ff1a197759497122ce9.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-09  Pix2Gif Motion-Guided Diffusion for GIF Generation</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="Diffusion Models" scheme="https://kedreamix.github.io/tags/Diffusion-Models/"/>
    
  </entry>
  
  <entry>
    <title>SyncTalk The Devil is in the Synchronization for Talking Head Synthesis</title>
    <link href="https://kedreamix.github.io/2024/03/07/Paperscape/SyncTalk/"/>
    <id>https://kedreamix.github.io/2024/03/07/Paperscape/SyncTalk/</id>
    <published>2024-03-07T07:57:00.000Z</published>
    <updated>2024-03-09T09:37:44.711Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SyncTalk-The-Devil-is-in-the-Synchronization-for-Talking-Head-Synthesis"><a href="#SyncTalk-The-Devil-is-in-the-Synchronization-for-Talking-Head-Synthesis" class="headerlink" title="SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis"></a>SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis</h1><p>Paper   : <a href="https://arxiv.org/abs/2311.17590">https://arxiv.org/abs/2311.17590</a></p><p>Project : <a href="https://ziqiaopeng.github.io/synctalk/">https://ziqiaopeng.github.io/synctalk/</a></p><p>Video    : <a href="https://ziqiaopeng.github.io/synctalk/#teaser">https://ziqiaopeng.github.io/synctalk/#teaser</a></p><p>Code    : <a href="https://github.com/ziqiaopeng/SyncTalk">https://github.com/ziqiaopeng/SyncTalk</a></p><p><strong>æ‘˜è¦</strong></p><p>ç¥ç»è¾å°„åœº - ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¡†æ¶ç”¨äºå®ç°è¯´è¯äººå¤´éƒ¨è§†é¢‘çš„åŒæ­¥åˆæˆã€‚</p><p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š ç”Ÿæˆé€¼çœŸçš„ã€ç”±è¯­éŸ³é©±åŠ¨çš„è°ˆè¯å¤´éƒ¨è§†é¢‘æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ä¼ ç»Ÿç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰éš¾ä»¥ä¿æŒä¸€è‡´çš„é¢éƒ¨èº«ä»½ï¼Œè€Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•è™½ç„¶å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†é€šå¸¸ä¼šäº§ç”Ÿä¸åŒ¹é…çš„å”‡éƒ¨åŠ¨ä½œã€ä¸å……åˆ†çš„é¢éƒ¨è¡¨æƒ…å’Œä¸ç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ã€‚ä¸€ä¸ªé€¼çœŸçš„è°ˆè¯å¤´éƒ¨éœ€è¦åŒæ­¥åè°ƒä¸»ä½“èº«ä»½ã€å”‡éƒ¨åŠ¨ä½œã€é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚ç¼ºä¹è¿™äº›åŒæ­¥æ˜¯å¯¼è‡´ä¸çœŸå®å’Œäººå·¥ç»“æœçš„æ ¹æœ¬ç¼ºé™·ã€‚ </p><p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š GAN æ–¹æ³•éš¾ä»¥ä¿æŒä¸€è‡´çš„é¢éƒ¨èº«ä»½ã€‚NeRF æ–¹æ³•è™½ç„¶å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†é€šå¸¸ä¼šäº§ç”Ÿä¸åŒ¹é…çš„å”‡éƒ¨åŠ¨ä½œã€ä¸å……åˆ†çš„é¢éƒ¨è¡¨æƒ…å’Œä¸ç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ã€‚ </p><p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š SyncTalk æ˜¯ä¸€ç§åŸºäº NeRF çš„æ–¹æ³•ï¼Œå®ƒæœ‰æ•ˆåœ°ä¿æŒäº†ä¸»ä½“èº«ä»½ï¼Œå¢å¼ºäº†è°ˆè¯å¤´éƒ¨åˆæˆçš„åŒæ­¥æ€§å’ŒçœŸå®æ€§ã€‚SyncTalk ä½¿ç”¨é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨å°†å”‡éƒ¨åŠ¨ä½œä¸è¯­éŸ³å¯¹é½ï¼Œå¹¶åˆ›æ–°åœ°ä½¿ç”¨ 3D é¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹æ¥æ•æ‰å‡†ç¡®çš„é¢éƒ¨è¡¨æƒ…ã€‚å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ä¼˜åŒ–å¤´éƒ¨å§¿åŠ¿ï¼Œå®ç°æ›´è‡ªç„¶çš„å¤´éƒ¨è¿åŠ¨ã€‚è‚–åƒåŒæ­¥ç”Ÿæˆå™¨æ¢å¤å¤´å‘ç»†èŠ‚ï¼Œå¹¶å°†ç”Ÿæˆçš„å¤´éƒ¨ä¸èº¯å¹²èåˆï¼Œä»¥è·å¾—æ— ç¼çš„è§†è§‰ä½“éªŒã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¿™äº›æ€§èƒ½æ˜¯å¦æ”¯æŒäº†å®ƒä»¬çš„ç›®æ ‡ï¼š SyncTalk åœ¨è°ˆè¯å¤´éƒ¨åˆæˆåŒæ­¥æ€§å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚å¹¿æ³›çš„å®éªŒå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒSyncTalk åœ¨åŒæ­¥æ€§å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p><p><strong>å…³é”®è¦ç‚¹</strong></p><ul><li>ä¼ ç»Ÿç”Ÿæˆå¯¹æŠ—ç½‘ç»œéš¾ä»¥ç»´æŒä¸€è‡´çš„é¢éƒ¨èº«ä»½ã€‚</li><li>ç¥ç»è¾å°„åœºæ–¹æ³•å¯ä»¥è§£å†³é¢éƒ¨èº«ä»½ä¸€è‡´æ€§é—®é¢˜ï¼Œä½†ç»å¸¸å‡ºç°å˜´å”‡è¿åŠ¨ä¸åŒ¹é…ã€é¢éƒ¨è¡¨æƒ…ä¸è¶³å’Œå¤´éƒ¨å§¿åŠ¿ä¸ç¨³å®šçš„é—®é¢˜ã€‚</li><li>é€¼çœŸçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘éœ€è¦åŒæ­¥åè°ƒä¸»ä½“èº«ä»½ã€å˜´å”‡è¿åŠ¨ã€é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚</li><li>ç¼ºå°‘åŒæ­¥æ€§æ˜¯å¯¼è‡´ä¸çœŸå®å’Œäººä¸ºç»“æœçš„æ ¹æœ¬ç¼ºé™·ã€‚</li><li>SyncTalk æ˜¯ä¸€ç§åŸºäºç¥ç»è¾å°„åœºçš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°ä¿æŒäº†ä¸»ä½“èº«ä»½ï¼Œæé«˜äº†è¯´è¯äººå¤´éƒ¨åˆæˆä¸­çš„åŒæ­¥æ€§å’ŒçœŸå®æ„Ÿã€‚</li><li>SyncTalk ä½¿ç”¨é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨å°†å˜´å”‡è¿åŠ¨ä¸è¯­éŸ³å¯¹é½ï¼Œå¹¶åˆ›æ–°åœ°ä½¿ç”¨ 3D é¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹æ¥æ•æ‰å‡†ç¡®çš„é¢éƒ¨è¡¨æƒ…ã€‚</li><li>SyncTalk çš„å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ä¼˜åŒ–äº†å¤´éƒ¨å§¿åŠ¿ï¼Œå®ç°äº†æ›´è‡ªç„¶çš„å¤´éƒ¨è¿åŠ¨ã€‚</li><li>äººåƒåŒæ­¥ç”Ÿæˆå™¨æ¢å¤å¤´å‘ç»†èŠ‚ï¼Œå°†ç”Ÿæˆçš„å¤´éƒ¨ä¸èº¯å¹²èåˆï¼Œä»¥è·å¾—æ— ç¼çš„è§†è§‰ä½“éªŒã€‚</li></ul><p><img src="https://picx.zhimg.com/v2-a57e0937b2f452009023394a59529dfb.png" alt="SyncTalk"></p><h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><p>è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œè§£å†³æœ€å¥½çš„å°±æ˜¯åŒæ­¥çš„é—®é¢˜ï¼Œæ‰€ä»¥ä¹Ÿç§°ä¸ºåŒæ­¥çš„Devil é­”é¬¼ğŸ˜ˆã€‚ç°æœ‰æ–¹æ³•åœ¨å››ä¸ªå…³é”®é¢†åŸŸéœ€è¦æ›´å¤šçš„åŒæ­¥ï¼š<strong>ä¸»ä½“èº«ä»½</strong>ã€<strong>å”‡éƒ¨è¿åŠ¨</strong>ã€<strong>é¢éƒ¨è¡¨æƒ…</strong>å’Œ<strong>å¤´éƒ¨å§¿åŠ¿</strong>ã€‚</p><ul><li><p>é¦–å…ˆï¼Œåœ¨åŸºäºGANçš„æ–¹æ³•ä¸­ï¼Œç”±äºè¿ç»­å¸§ä¸­ç‰¹å¾çš„ä¸ç¨³å®šæ€§ä»¥åŠä»…ä½¿ç”¨å°‘é‡å¸§ä½œä¸ºé¢éƒ¨é‡å»ºå‚è€ƒï¼Œä¿æŒè§†é¢‘ä¸­ä¸»ä½“çš„èº«ä»½æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚</p></li><li><p>å…¶æ¬¡ï¼Œå”‡éƒ¨è¿åŠ¨ä¸è¯­éŸ³ä¸åŒæ­¥ã€‚åœ¨åŸºäºNeRFçš„æ–¹æ³•ä¸­ï¼Œä»…åŸºäº5åˆ†é’Ÿè¯­éŸ³æ•°æ®é›†è®­ç»ƒçš„éŸ³é¢‘ç‰¹å¾éš¾ä»¥æ³›åŒ–åˆ°ä¸åŒçš„è¯­éŸ³è¾“å…¥ã€‚</p></li><li><p>ç¬¬ä¸‰ï¼Œç¼ºä¹é¢éƒ¨è¡¨æƒ…æ§åˆ¶ï¼Œå¤§å¤šæ•°æ–¹æ³•åªèƒ½äº§ç”Ÿå”‡éƒ¨è¿åŠ¨æˆ–æ§åˆ¶çœ¨çœ¼ï¼Œå¯¼è‡´é¢éƒ¨åŠ¨ä½œä¸è‡ªç„¶ã€‚</p></li><li><p>ç¬¬å››ï¼Œå¤´éƒ¨å§¿åŠ¿ä¸åŒæ­¥ã€‚</p></li></ul><p>å…ˆå‰çš„æ–¹æ³•ä¾èµ–äºç¨€ç–çš„landmarksæ¥è®¡ç®—æŠ•å½±è¯¯å·®ï¼Œä½†è¿™äº›landmarksçš„æŠ–åŠ¨å’Œä¸å‡†ç¡®æ€§å¯¼è‡´å¤´éƒ¨å§¿åŠ¿ä¸ç¨³å®šã€‚è¿™äº›åŒæ­¥é—®é¢˜ä¼šå¼•å…¥ä¼ªå½±ï¼Œå¹¶æ˜¾è‘—é™ä½çœŸå®æ„Ÿã€‚</p><p>ä¸ºäº†è§£å†³è¿™äº›åŒæ­¥æŒ‘æˆ˜ï¼Œå¼•å…¥äº†SyncTalkï¼Œè¿™æ˜¯ä¸€ç§åŸºäºNeRFçš„æ–¹æ³•ï¼Œä¸“æ³¨äºé«˜åº¦åŒæ­¥ã€é€¼çœŸçš„ã€è¯­éŸ³é©±åŠ¨çš„è¯´è¯å¤´éƒ¨åˆæˆï¼Œé‡‡ç”¨ä¸‰å¹³é¢å“ˆå¸Œè¡¨ç¤ºæ¥ç»´æŠ¤ä¸»ä½“èº«ä»½ã€‚é€šè¿‡é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨å’Œå¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ï¼ŒSyncTalkæ˜¾è‘—æé«˜äº†åˆæˆè§†é¢‘çš„åŒæ­¥æ€§å’Œè§†è§‰è´¨é‡ã€‚PortraitSync Generatorè¿›ä¸€æ­¥æ”¹å–„äº†è§†è§‰è´¨é‡ï¼Œç²¾å¿ƒç»†åŒ–äº†è§†è§‰ç»†èŠ‚ã€‚æ•´ä¸ªæ¸²æŸ“è¿‡ç¨‹å¯ä»¥å®ç°50 FPSï¼Œå¹¶è¾“å‡ºé«˜åˆ†è¾¨ç‡è§†é¢‘ã€‚</p><div class="table-container"><table><thead><tr><th>æ¨¡å—</th><th>æè¿°</th></tr></thead><tbody><tr><td>Face-Sync Controller</td><td>åœ¨Face-Syncæ§åˆ¶å™¨ä¸­ï¼Œé¢„å…ˆåœ¨2DéŸ³é¢‘è§†å¬æ•°æ®é›†ä¸Šå¯¹éŸ³é¢‘è§†è§‰ç¼–ç å™¨è¿›è¡Œé¢„è®­ç»ƒï¼Œå¾—åˆ°äº†ä¸€ç§é€šç”¨è¡¨ç¤ºï¼Œç¡®ä¿äº†ä¸åŒè¯­éŸ³æ ·æœ¬ä¹‹é—´çš„å”‡éƒ¨åŒæ­¥è¿åŠ¨ã€‚å¯¹äºæ§åˆ¶é¢éƒ¨è¡¨æƒ…ï¼Œé‡‡ç”¨äº†ä¸€ä¸ªè¯­ä¹‰ä¸°å¯Œçš„3Dé¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡52ä¸ªå‚æ•°æ§åˆ¶ç‰¹å®šçš„é¢éƒ¨è¡¨æƒ…åŒºåŸŸã€‚</td></tr><tr><td>Head-Sync Stabilizer</td><td>åœ¨Head-Syncç¨³å®šå™¨ä¸­ï¼Œä½¿ç”¨AD-NeRFä¸­çš„å¤´éƒ¨è¿åŠ¨è·Ÿè¸ªå™¨æ¥æ¨æ–­å¤´éƒ¨çš„ç²—ç•¥æ—‹è½¬å’Œå¹³ç§»å‚æ•°ã€‚ç”±äºç²—ç•¥å‚æ•°çš„ä¸ç¨³å®šæ€§ï¼Œå€Ÿé‰´äº†åŒæ­¥å®šä½ä¸åœ°å›¾(SLAM)çš„æ€æƒ³ï¼Œç»“åˆå¤´éƒ¨å…³é”®ç‚¹è·Ÿè¸ªå™¨è·Ÿè¸ªç¨ å¯†å…³é”®ç‚¹ï¼Œå¹¶é‡‡ç”¨bundle adjustment method æŸè°ƒæ•´æ–¹æ³•æ¥ä¼˜åŒ–å¤´éƒ¨å§¿åŠ¿ï¼Œä»è€Œå®ç°ç¨³å®šè¿ç»­çš„å¤´éƒ¨è¿åŠ¨ã€‚</td></tr><tr><td>Portrait-Sync Generator</td><td>ä¸ºäº†è¿›ä¸€æ­¥æé«˜SyncTalkçš„è§†è§‰ä¿çœŸåº¦ï¼Œè®¾è®¡äº†ä¸€ä¸ªPortrait-Syncç”Ÿæˆå™¨ã€‚è¿™ä¸ªæ¨¡å—ä¿®å¤äº†NeRFå»ºæ¨¡ä¸­çš„ä¼ªå½±ï¼Œç‰¹åˆ«æ˜¯å¤´å‘å’ŒèƒŒæ™¯ç­‰ç»†èŠ‚ï¼Œè¾“å‡ºé«˜åˆ†è¾¨ç‡è§†é¢‘ã€‚</td></tr></tbody></table></div><p><strong>ä¸»è¦è´¡çŒ®</strong></p><ul><li>æå‡ºäº†ä¸€ä¸ªFace-Syncæ§åˆ¶å™¨ï¼Œç»“åˆéŸ³é¢‘è§†è§‰ç¼–ç å™¨å’Œé¢éƒ¨åŠ¨ç”»æ•æ‰å™¨ï¼Œç¡®ä¿å‡†ç¡®çš„å”‡éƒ¨åŒæ­¥å’ŒåŠ¨æ€é¢éƒ¨è¡¨æƒ…æ¸²æŸ“ã€‚ </li><li>å¼•å…¥äº†ä¸€ä¸ªHead-Syncç¨³å®šå™¨ï¼Œè·Ÿè¸ªå¤´éƒ¨æ—‹è½¬å’Œé¢éƒ¨è¿åŠ¨å…³é”®ç‚¹ã€‚åˆ©ç”¨æŸè°ƒæ•´æ–¹æ³•ï¼Œè¯¥ç¨³å®šå™¨ä¿è¯äº†å¹³æ»‘åŒæ­¥çš„å¤´éƒ¨è¿åŠ¨ã€‚</li><li>è®¾è®¡äº†ä¸€ä¸ªPortrait-Syncç”Ÿæˆå™¨ï¼Œé€šè¿‡ä¿®å¤NeRFå»ºæ¨¡ä¸­çš„ä¼ªå½±å’Œç»†åŒ–å¤´å‘å’ŒèƒŒæ™¯ç­‰ç»†èŠ‚ï¼Œæé«˜äº†è§†è§‰ä¿çœŸåº¦ã€‚</li></ul><h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p><strong>GAN-based Method</strong></p><p>è¿‘æ¥ï¼ŒåŸºäºGANçš„è¯´è¯å¤´åˆæˆæˆä¸ºäº†è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€ä¸ªé‡è¦ç ”ç©¶é¢†åŸŸã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨ä¿æŒè§†é¢‘ä¸­ä¸»ä½“çš„èº«ä»½ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</p><p>ä¾‹å¦‚ï¼ŒWav2Lipå¼•å…¥äº†ä¸€ä¸ªå”‡éƒ¨åŒæ­¥ä¸“å®¶æ¥ç›‘ç£å”‡éƒ¨è¿åŠ¨ã€‚ç„¶è€Œï¼Œç”±äºä½¿ç”¨äº†æ¥è‡ªå‚è€ƒå¸§çš„äº”å¸§æ¥é‡å»ºå”‡éƒ¨ï¼Œå®ƒéš¾ä»¥ä¿æŒä¸»ä½“çš„èº«ä»½ã€‚å¦ä¸€äº›æ–¹æ³•å°è¯•è¿›è¡Œå…¨è„¸åˆæˆï¼Œä½†å¾€å¾€éš¾ä»¥ç¡®ä¿é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ä¹‹é—´çš„åŒæ­¥ã€‚é™¤äº†è§†é¢‘æµæŠ€æœ¯å¤–ï¼Œè¿˜æœ‰ä¸€äº›æ–¹æ³•è¯•å›¾é€šè¿‡è¯­éŸ³ä½¿å•å¼ å›¾åƒâ€œè¯´è¯â€ï¼Œå¦‚SadTalkerå¯ä»¥ä»å•å¼ å›¾åƒç”Ÿæˆä¸€ä¸ªäººè¯´è¯çš„è§†é¢‘ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•æ— æ³•ç”Ÿæˆè‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿å’Œé¢éƒ¨è¡¨æƒ…ï¼Œéš¾ä»¥ä¿æŒä¸»ä½“çš„èº«ä»½ï¼Œå½±å“äº†åŒæ­¥æ•ˆæœï¼Œå¯¼è‡´è§†è§‰æ„ŸçŸ¥ä¸çœŸå®ã€‚</p><p>ä¸è¿™äº›æ–¹æ³•ç›¸æ¯”ï¼ŒSyncTalkä½¿ç”¨NeRF<strong>å¯¹äººè„¸è¿›è¡Œä¸‰ç»´å»ºæ¨¡</strong>ã€‚å…¶èƒ½å¤Ÿåœ¨è§„èŒƒç©ºé—´ä¸­è¡¨ç¤º<strong>è¿ç»­çš„3Dåœºæ™¯çš„èƒ½åŠ›</strong>ï¼Œä½¿å…¶åœ¨ä¿æŒä¸»ä½“èº«ä»½ä¸€è‡´æ€§å’Œä¿ç•™ç»†èŠ‚æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</p><p><strong>NeRF-based Method</strong></p><p>è¿‘æ¥ï¼Œéšç€NeRFçš„å´›èµ·ï¼Œè®¸å¤šé¢†åŸŸå·²å¼€å§‹åˆ©ç”¨å®ƒæ¥è§£å†³ç›¸å…³æŒ‘æˆ˜ã€‚å…ˆå‰çš„å·¥ä½œå·²å°†NeRFæ•´åˆåˆ°åˆæˆè¯´è¯å¤´åƒçš„ä»»åŠ¡ä¸­ï¼Œå¹¶å°†éŸ³é¢‘ä½œä¸ºé©±åŠ¨ä¿¡å·ï¼Œä½†è¿™äº›æ–¹æ³•éƒ½æ˜¯åŸºäºæ™®é€šçš„NeRFæ¨¡å‹ã€‚</p><p>ä¾‹å¦‚ï¼ŒAD-NeRFéœ€è¦å¤§çº¦10ç§’æ¥æ¸²æŸ“å•ä¸ªå›¾åƒã€‚RADNeRFæ—¨åœ¨å®ç°å®æ—¶è§†é¢‘ç”Ÿæˆï¼Œå¹¶ä½¿ç”¨äº†åŸºäºInstant-NGPçš„NeRFã€‚ER-NeRFé€šè¿‡å¼•å…¥ä¸‰å¹³é¢å“ˆå¸Œç¼–ç å™¨æ¥ä¿®å‰ªç©ºç™½ç©ºé—´åŒºåŸŸï¼Œæå€¡ç´§å‡‘ä¸”åŠ é€Ÿçš„æ¸²æŸ“æ–¹æ³•ã€‚GeneFaceè¯•å›¾é€šè¿‡å°†è¯­éŸ³ç‰¹å¾è½¬æ¢ä¸ºé¢éƒ¨æ ‡å¿—æ¥å‡å°‘NeRFçš„ä¼ªå½±ï¼Œä½†è¿™å¾€å¾€å¯¼è‡´å”‡éƒ¨è¿åŠ¨ä¸å‡†ç¡®ã€‚å°è¯•ä½¿ç”¨åŸºäºNeRFçš„æ–¹æ³•åˆ›å»ºè§’è‰²å¤´åƒï¼Œä¾‹å¦‚ï¼Œä¸èƒ½ç›´æ¥ç”±è¯­éŸ³é©±åŠ¨ã€‚è¿™äº›æ–¹æ³•ä»…å°†éŸ³é¢‘ä½œä¸ºæ¡ä»¶ï¼Œæ²¡æœ‰æ¸…æ™°çš„åŒæ­¥æ¦‚å¿µï¼Œå¹¶ä¸”é€šå¸¸å¯¼è‡´å”‡éƒ¨è¿åŠ¨å¹³å‡ã€‚</p><p>æ­¤å¤–ï¼Œå…ˆå‰çš„æ–¹æ³•<strong>ç¼ºä¹å¯¹é¢éƒ¨è¡¨æƒ…çš„æ§åˆ¶</strong>ï¼Œä»…é™äºæ§åˆ¶çœ¨çœ¼ï¼Œå¹¶ä¸”æ— æ³•å¯¹æŠ¬çœ‰æ¯›æˆ–çš±çœ‰ç­‰åŠ¨ä½œè¿›è¡Œå»ºæ¨¡ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨å¤´éƒ¨å§¿åŠ¿ä¸ç¨³å®šæ–¹é¢å­˜åœ¨æ˜¾ç€é—®é¢˜ï¼Œ<strong>å¯¼è‡´å¤´éƒ¨å’Œèº¯å¹²åˆ†ç¦»</strong>ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä½¿ç”¨Face-Syncæ§åˆ¶å™¨æ¥å»ºæ¨¡éŸ³é¢‘å’Œå”‡éƒ¨è¿åŠ¨ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œå¢å¼ºå”‡éƒ¨è¿åŠ¨å’Œè¡¨æƒ…çš„åŒæ­¥æ€§ï¼Œä½¿ç”¨Head-Syncç¨³å®šå™¨æ¥ç¨³å®šå¤´éƒ¨å§¿åŠ¿ï¼Œé€šè¿‡è§£å†³è¿™äº›åŒæ­¥é—®é¢˜ï¼Œæé«˜äº†è§†è§‰è´¨é‡ã€‚</p><h2 id="ä¸»è¦æ–¹æ³•"><a href="#ä¸»è¦æ–¹æ³•" class="headerlink" title="ä¸»è¦æ–¹æ³•"></a>ä¸»è¦æ–¹æ³•</h2><p>SyncTalkä¸»è¦ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼Œæ¥ä¸‹æ¥ä¼šä¸€ä¸€ä»‹ç»</p><ul><li><strong>Face-Sync Controller</strong> æ§åˆ¶å˜´å”‡è¿åŠ¨å’Œé¢éƒ¨è¡¨æƒ…</li><li><strong>Head-Sync Stabilizer</strong> ç¨³å®šå¤´éƒ¨å§¿åŠ¿</li><li><strong>Portrait-Sync Generator</strong> æ¸²æŸ“çš„é«˜åŒæ­¥é¢éƒ¨å¸§</li></ul><p><img src="https://pica.zhimg.com/v2-03605cd4fbd659c9d341840c64fd3b41.png" alt="Overview of SyncTalk"></p><h3 id="Face-Sync-Controller"><a href="#Face-Sync-Controller" class="headerlink" title="Face-Sync Controller"></a>Face-Sync Controller</h3><p><strong>Audio-Visual Encoder</strong></p><p>åœ¨ç°æœ‰çš„æ–¹æ³•ä¸­ï¼Œå¤§éƒ¨åˆ†çš„éŸ³é¢‘ç‰¹å¾æå–å™¨æ˜¯ç”¨ç±»ä¼¼äº <strong>DeepSpeechï¼ŒWav2Vec 2.0 å’Œ HuBERT</strong> ç­‰ASRæ¨¡å‹ï¼Œä½†æ˜¯è¿™äº›äº‹ä¸“é—¨ä¸ºAutomatic Speech Recognition ASRä»»åŠ¡è®¾è®¡çš„ï¼Œè¿™ç§è®¾è®¡çš„éŸ³é¢‘ç¼–ç å™¨å¹¶ä¸èƒ½çœŸæ­£åæ˜ å˜´å”‡è¿åŠ¨ã€‚è¿™æ˜¯å› ä¸ºé¢„è®­ç»ƒçš„æ¨¡å‹æ˜¯<strong>åŸºäºä»éŸ³é¢‘åˆ°æ–‡æœ¬çš„ç‰¹å¾åˆ†å¸ƒï¼Œè€Œéœ€è¦ä»éŸ³é¢‘åˆ°å˜´å”‡è¿åŠ¨çš„ç‰¹å¾åˆ†å¸ƒ</strong>ã€‚</p><p>é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œä½¿ç”¨åœ¨LRS2ä¸Šè®­ç»ƒçš„<a href="https://github.com/smeetrs/deep_avsr">deep avsr</a>æ¥åšéŸ³é¢‘ç‰¹å¾æå–å™¨ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„å”‡å½¢åŒæ­¥é‰´åˆ«å™¨ <a href="https://github.com/joonson/syncnet_python">SyncNet</a>æ¥ç›‘ç£è§†é¢‘çš„åŒæ­¥æ•ˆæœï¼Œè¿™æ˜¯ä½¿ç”¨è¿ç»­çš„é¢éƒ¨çª—å£Få’Œç›¸å¯¹åº”çš„éŸ³é¢‘å¸§Aè¾“å…¥ï¼ŒåŒæ—¶åˆ†ä¸ºæ­£è´Ÿæ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œåˆ©ç”¨<strong>ä½™å¼¦ç›¸ä¼¼åº¦å’Œäº¤å‰ç†µæŸå¤±</strong>æ¥æœ€å°åŒ–åŒæ­¥æ ·æœ¬çš„è·ç¦»å¹¶æœ€å¤§åŒ–éåŒæ­¥æ ·æœ¬çš„è·ç¦»ã€‚</p><script type="math/tex; mode=display">\begin{aligned}\sin(F,A)&=\frac{F\cdot A}{\|F\|_2\|A\|_2})\end{aligned},</script><script type="math/tex; mode=display">L_{\mathrm{sync}}=-\left(y\log(\sin(F,A))+(1-y)\log(1-\sin(F,A))\right),</script><p><img src="https://picx.zhimg.com/v2-6b250a8119b776d55493f82cfda54bc5.png" alt="æ­£è´Ÿæ ·æœ¬"></p><p>åŒæ—¶åœ¨åŒæ­¥é‰´åˆ«å™¨çš„ç›‘ç£ä¸‹ï¼Œé¢„è®­ç»ƒå¯¹åº”çš„è§†å¬ç‰¹å¾æå–å™¨ï¼Œè¿™é‡Œé¢å †å å·ç§¯ç½‘ç»œè¿›è¡Œç¼–ç è§£ç ï¼Œæœ€åç”¨<strong>é‡å»ºæŸå¤±</strong>æ¥è¿›è¡Œç›‘ç£ã€‚è®­ç»ƒåï¼Œæˆ‘ä»¬ä½¿ç”¨ Conv(A) ä½œä¸ºä»éŸ³é¢‘ä¸­æå–çš„å”‡éƒ¨ç©ºé—´ã€‚</p><script type="math/tex; mode=display">L_{\mathrm{recon}}=\|F-\mathrm{Dec}(\mathrm{Conv}(A)\oplus\mathrm{Conv}(F))\|_1.</script><p><strong>Facial Animation Capturer</strong></p><p>åœ¨ä¹‹å‰çš„ç ”ç©¶ä¸­å‘ç°ï¼ŒåŸºäºNeRFçš„æ–¹æ³•åªèƒ½æ”¹å˜çœ¨çœ¼ï¼Œæ— æ³•å‡†ç¡®åœ°å»ºæ¨¡é¢éƒ¨è¡¨æƒ…ã€‚è¿™å¯¼è‡´è®­ç»ƒå‡ºçš„è§’è‰²è¡¨æƒ…åƒµç¡¬ï¼Œé¢éƒ¨ç»†èŠ‚ä¸å‡†ç¡®ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæœ‰æ˜æ˜¾é¢éƒ¨åŠ¨ä½œçš„è§’è‰²ï¼Œå¦‚çœ¨çœ¼ã€æŠ¬çœ‰æ¯›æˆ–çš±çœ‰ç­‰ã€‚<strong>è€ƒè™‘åˆ°éœ€è¦æ›´åŠ åŒæ­¥å’Œé€¼çœŸçš„é¢éƒ¨è¡¨æƒ…ï¼Œæ·»åŠ äº†ä¸€ä¸ªè¡¨æƒ…åŒæ­¥æ§åˆ¶æ¨¡å—ã€‚</strong></p><p>å…·ä½“è€Œè¨€ï¼Œå¼•å…¥äº†ä¸€ä¸ª<strong>åŸºäº52ä¸ªè¯­ä¹‰é¢éƒ¨æ··åˆå½¢çŠ¶ç³»æ•° B çš„3Dé¢éƒ¨å…ˆéªŒæ¨¡å‹æ¥å»ºæ¨¡é¢éƒ¨</strong>ï¼Œä¹Ÿå°±æ˜¯3D blendshape ç³»æ•°æ¥æ§åˆ¶é¢éƒ¨ï¼Œè¿™ä¸€éƒ¨åˆ†ç±»ä¼¼äº <a href="https://arxiv.org/abs/2303.11089">EmoTalk</a>ã€‚å› ä¸º3Dé¢éƒ¨æ¨¡å‹èƒ½å¤Ÿä¿ç•™é¢éƒ¨è¿åŠ¨çš„ç»“æ„ä¿¡æ¯ï¼Œæ‰€ä»¥å®ƒèƒ½å¤Ÿå¾ˆå¥½åœ°åæ˜ é¢éƒ¨åŠ¨ä½œçš„å†…å®¹ï¼ŒåŒæ—¶åˆä¸ä¼šå¼•èµ·é¢éƒ¨ç»“æ„çš„å¤±çœŸã€‚</p><p><strong>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆä½¿ç”¨ä¸€ä¸ªå¤æ‚çš„é¢éƒ¨æ··åˆå½¢çŠ¶æ•æ‰æ¨¡å—å°†é¢éƒ¨è¡¨æƒ…æ•æ‰ä¸ºE(B)ï¼Œç„¶åé€‰æ‹©ä¸ƒä¸ªæ ¸å¿ƒé¢éƒ¨è¡¨æƒ…æ§åˆ¶ç³»æ•°æ¥æ§åˆ¶çœ‰æ¯›ã€é¢å¤´å’Œçœ¼ç›åŒºåŸŸã€‚</strong>è¿™äº›ç³»æ•°ä¸è¡¨æƒ…é«˜åº¦ç›¸å…³ï¼Œä¸”ç‹¬ç«‹äºå˜´å”‡çš„è¿åŠ¨ã€‚å› ä¸ºé¢éƒ¨ç³»æ•°å…·æœ‰è¯­ä¹‰ä¿¡æ¯ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŒæ­¥æ¼”è®²è€…çš„é¢éƒ¨è¡¨æƒ…ã€‚</p><p><img src="https://pica.zhimg.com/v2-9cfb1cfb7f4ae95b64a868f8e8abad0e.png" alt="Facial Animation Capturer"></p><p><strong>Facial-Aware Masked-Attention</strong></p><p>ä¸ºäº†å‡å°‘è®­ç»ƒè¿‡ç¨‹ä¸­å˜´å”‡ç‰¹å¾å’Œè¡¨æƒ…ç‰¹å¾ä¹‹é—´çš„ç›¸äº’å¹²æ‰°ï¼Œå¼•å…¥äº†Facial-Aware Disentangle Attentionæ¨¡å—ã€‚åŸºäºåŒºåŸŸæ³¨æ„åŠ›å‘é‡ Vï¼Œè¿™ç±»ä¼¼äº<a href="https://fictionarry.github.io/ER-NeRF/">ER-NeRF</a>ï¼Œæˆ‘ä»¬åˆ†åˆ«å°†Mask $M<em>{lip}$ å’Œ $M</em>{exp}$ æ·»åŠ åˆ°å˜´å”‡å’Œè¡¨æƒ…çš„æ³¨æ„åŠ›åŒºåŸŸã€‚</p><script type="math/tex; mode=display">\begin{aligned}V_{\mathrm{lip}}&=V\odot M_{\mathrm{lip}},\\V_{\mathrm{exp}}&=V\odot M_{\mathrm{exp}}.\end{aligned}</script><p>é€šè¿‡è¿™æ ·è®¾è®¡çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè§£è€¦å˜´å”‡è¿åŠ¨å’Œçœ¨çœ¼è¿åŠ¨ç­‰ï¼Œä»è€Œå‡å°‘è€¦åˆå¸¦æ¥çš„ä¼ªå½±ï¼Œæœ€ååˆ©ç”¨è§£è€¦çš„å˜´å”‡ç‰¹å¾ $f<em>l = F</em>{lip} âŠ™ V<em>{lip}$ å’Œè¡¨æƒ…ç‰¹å¾$f_e = f</em>{exp} âŠ™ V_{exp}$ã€‚</p><p><img src="https://pica.zhimg.com/v2-ba601309ab5cc09573f4291d7ae27f13.png" alt="ER-NeRF Mask"></p><h3 id="Head-Sync-Stabilizer"><a href="#Head-Sync-Stabilizer" class="headerlink" title="Head-Sync Stabilizer"></a>Head-Sync Stabilizer</h3><p><strong>Head Motion Tracker</strong></p><p>å¤´éƒ¨å§¿åŠ¿ï¼Œè¡¨ç¤ºä¸º pï¼Œæ˜¯æŒ‡äººçš„å¤´éƒ¨åœ¨ 3D ç©ºé—´ä¸­çš„æ—‹è½¬è§’åº¦ï¼Œç”±æ—‹è½¬ R å’Œå¹³ç§» T å®šä¹‰ã€‚</p><p>ä¸ç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ä¼šå¯¼è‡´å¤´éƒ¨æŠ–åŠ¨ã€‚ä¸ºäº†è·å¾—å¤´éƒ¨å§¿åŠ¿çš„ç²—ç•¥ä¼°è®¡ï¼Œé¦–å…ˆï¼Œé€šè¿‡åœ¨é¢„å®šèŒƒå›´å†…è¿­ä»£ i æ¬¡æ¥ç¡®å®šæœ€ä½³ç„¦è·ã€‚å¯¹äºæ¯ä¸ªç„¦è·å€™é€‰ fiï¼Œé‡æ–°åˆå§‹åŒ–æ—‹è½¬å’Œå¹³ç§»å€¼ã€‚ç›®æ ‡æ˜¯æœ€å°åŒ– 3D å¯å˜å½¢æ¨¡å‹ (3DMM) çš„æŠ•å½±åœ°æ ‡ä¸è§†é¢‘å¸§ä¸­çš„å®é™…åœ°æ ‡ä¹‹é—´çš„è¯¯å·®ã€‚</p><script type="math/tex; mode=display">f_{\mathrm{opt}}=\arg\min_{f_i}E_i(L_{2D},L_{3D}(f_i,R_i,T_i)),</script><p>å…¶ä¸­ $E_i$è¡¨ç¤ºçš„å°±æ˜¯MSEï¼Œè¿™æ ·èƒ½å¤Ÿä»¥æ›´å¥½åœ°å°†æ¨¡å‹çš„æŠ•å½±lmkä¸å®é™…è§†é¢‘lmkå¯¹é½ï¼Œç„¶åå¾—åˆ°æœ€ä¼˜çš„æ—‹è½¬å’Œå¹³ç§»çŸ©é˜µï¼Œä¹Ÿæ˜¯ç”¨MSEæ¥æœ€å°åŒ–ï¼Œè¿™æ˜¯å¯¹æ¯ä¸€å¸§è¿›è¡Œæ“ä½œçš„ï¼Œåœ¨å¯¹åº”è§†é¢‘å¸§çš„æœ€ä¼˜å€¼ã€‚</p><script type="math/tex; mode=display">(R_{\mathrm{opt}},T_{\mathrm{opt}})=\arg\min_{R,T}E(L_{2D},L_{3D}(f_{\mathrm{opt}},R,T)).</script><p><strong>Head Points Tracker</strong></p><p>å¯¹äºä¹‹å‰åŸºäºNeRFçš„æ–¹æ³•æ¥è¯´ï¼Œå…ˆå‰çš„æ–¹æ³•åˆ©ç”¨åŸºäº 3DMM çš„æŠ€æœ¯æ¥æå–å¤´éƒ¨å§¿åŠ¿å¹¶ç”Ÿæˆä¸å‡†ç¡®çš„ç»“æœã€‚ä¸ºäº†æé«˜Rå’ŒTçš„ç²¾åº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨åƒCo- trackerè¿™æ ·çš„å…‰æµä¼°è®¡æ¨¡å‹æ¥è·Ÿè¸ªé¢éƒ¨å…³é”®ç‚¹Kã€‚</p><p>æ¥ä¸‹æ¥ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„å…‰æµä¼°è®¡æ¨¡å‹ï¼Œåœ¨è·å–é¢éƒ¨è¿åŠ¨å…‰æµåï¼Œæˆ‘ä»¬ä½¿ç”¨<strong>æ‹‰æ™®æ‹‰æ–¯æ»¤æ³¢å™¨</strong>é€‰æ‹©ä½äºæœ€æ˜¾è‘—æµå˜åŒ–ä½ç½®çš„å…³é”®ç‚¹ï¼Œå¹¶åœ¨æµåºåˆ—ä¸­è·Ÿè¸ªè¿™äº›å…³é”®ç‚¹çš„è¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡è¿™ä¸ªæ¨¡å—ç¡®ä¿äº†æ‰€æœ‰å¸§ä¸Šçš„é¢éƒ¨å…³é”®ç‚¹å¯¹é½æ›´åŠ ç²¾ç¡®å’Œä¸€è‡´ï¼Œä»è€Œå¢å¼ºäº†å¤´éƒ¨å§¿åŠ¿å‚æ•°çš„å‡†ç¡®æ€§ã€‚</p><p><strong>Bundle Adjustment</strong></p><p>æ ¹æ®å…³é”®ç‚¹å’Œç²—ç•¥çš„å¤´éƒ¨å§¿åŠ¿ï¼Œå¼•å…¥äº†ä¸€ä¸ªä¸¤é˜¶æ®µä¼˜åŒ–æ¡†æ¶æ¥æé«˜å…³é”®ç‚¹å’Œå¤´éƒ¨å§¿åŠ¿ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</p><ul><li><p>ç¬¬ä¸€é˜¶æ®µï¼Œéšæœºåˆå§‹åŒ– j ä¸ªå…³é”®ç‚¹çš„ 3D åæ ‡å¹¶ä¼˜åŒ–å®ƒä»¬çš„ä½ç½®ï¼Œä»¥ä¾¿ä¸å›¾åƒå¹³é¢ä¸Šè·Ÿè¸ªçš„å…³é”®ç‚¹å¯¹é½ã€‚è¿™ä¸€éƒ¨åˆ†æœ€å°åŒ–æŸå¤±å‡½æ•° $L_{init}$ï¼Œæ•è·<strong>æŠ•å½±å…³é”®ç‚¹ P å’Œè·Ÿè¸ªå…³é”®ç‚¹ K</strong> ä¹‹é—´çš„å·®å¼‚ï¼š</p><script type="math/tex; mode=display">L_{\mathrm{init}}=\sum_j\lVert P_j-K_j\rVert_2.</script></li><li><p>ç¬¬äºŒé˜¶æ®µï¼Œå¼€å§‹è¿›è¡Œæ›´å…¨é¢çš„ä¼˜åŒ–ï¼Œä»¥ç»†åŒ– 3D å…³é”®ç‚¹å’Œç›¸å…³çš„å¤´éƒ¨è”åˆå§¿åŠ¿å‚æ•°ï¼Œé€šè¿‡Adamä¼˜åŒ–å™¨ä¼˜åŒ–ç®—æ³•ï¼Œ<strong>è°ƒæ•´ç©ºé—´åæ ‡ã€æ—‹è½¬è§’åº¦Rå’Œå¹³ç§»T</strong>ä»¥æœ€å°åŒ–å¯¹é½è¯¯å·®$L_{sec}$ï¼Œè¡¨ç¤ºä¸ºï¼š</p><script type="math/tex; mode=display">L_{\sec}=\sum_j\lVert P_j(R,T)-K_j\rVert_2.</script><p>ç»è¿‡è¿™äº›ä¼˜åŒ–åï¼Œè§‚å¯Ÿåˆ°æ‰€å¾—çš„å¤´éƒ¨å§¿åŠ¿å’Œå¹³ç§»å‚æ•°å¹³æ»‘ä¸”ç¨³å®šã€‚</p></li></ul><h3 id="Dynamic-Portrait-Renderer"><a href="#Dynamic-Portrait-Renderer" class="headerlink" title="Dynamic Portrait Renderer"></a>Dynamic Portrait Renderer</h3><p><strong>Tri-Plane Hash Representation</strong></p><p>è¿™ä¸€éƒ¨åˆ†å®é™…ä¸Šå°±æ˜¯NeRFçš„ä½“æ¸²æŸ“çš„æ–¹å¼ï¼Œéƒ½æ˜¯ä¸€äº›å®šä¹‰çš„éƒ¨åˆ†ã€‚</p><script type="math/tex; mode=display">\hat{C}(\mathrm{r})=\int_{t_n}^{t_f}\sigma(\mathrm{r}(t))\cdot\mathrm{c}(\mathrm{r}(t),\mathrm{d})\cdot T(t)dt,</script><p>ç±»ä¼¼äºER-NeRFçš„æ–¹å¼ï¼Œè§£å†³å“ˆå¸Œå†²çªå’Œä¼˜åŒ–éŸ³é¢‘ç‰¹å¾å¤„ç†çš„é—®é¢˜ï¼Œç»“åˆäº†ä¸‰ä¸ªç‹¬ç‰¹å®šå‘xyzçš„ 2D å“ˆå¸Œç½‘æ ¼ï¼Œä¹Ÿå°±æ˜¯ <strong>Tri-Plane Hash</strong>ï¼Œä½œä¸ºhashçš„ç¼–ç å™¨ã€‚</p><script type="math/tex; mode=display">\mathcal{H}^{\mathrm{AB}}:(a,b)\to\mathrm{f}_{ab}^{\mathrm{AB}},\\\mathrm{f_x}=\mathcal{H}^\mathrm{XY}(x,y)\oplus\mathcal{H}^\mathrm{YZ}(y,z)\oplus\mathcal{H}^\mathrm{XZ}(x,z),</script><p>å…¶ä¸­è¾“å‡º $f^{AB}<em>{ab} âˆˆ R</em>{LD}$ï¼Œå…·æœ‰å±‚æ•° $L$ å’Œæ¯ä¸ªæ–¹å‘çš„ç‰¹å¾ç»´åº¦ $D$ï¼Œè¡¨ç¤ºä¸æŠ•å½±åæ ‡$ (a, b)$ ç›¸å¯¹åº”çš„å¹³é¢å‡ ä½•ç‰¹å¾ï¼Œ$H^{AB}$ è¡¨ç¤ºå¹³é¢ $R^{AB}$ çš„å¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç å™¨ã€‚å¾—åˆ°æ¯ä¸ªæ–¹å‘çš„å‘é‡ä»¥åï¼Œäº§ç”Ÿ $3 Ã— LD$ é€šé“å‘é‡ã€‚é‡‡ç”¨$fx$ã€è§†è§’æ–¹å‘$d$ã€å˜´å”‡ç‰¹å¾$f_l$å’Œè¡¨æƒ…ç‰¹å¾$f_e$ï¼Œä¸‰å¹³é¢å“ˆå¸Œçš„éšå¼å‡½æ•°å®šä¹‰ä¸ºï¼š</p><script type="math/tex; mode=display">\mathcal{F}^{\mathcal{H}}:(\mathrm{x},\mathrm{d},f_l,f_e;\mathcal{H}^3)\to(\mathrm{c},\sigma),</script><p>ç±»ä¼¼äºER-NeRFï¼Œè®­ç»ƒé‡‡ç”¨äº†ä¸€ä¸ªä¸¤æ­¥ç²—åˆ°ç»†çš„ç­–ç•¥ã€‚é¦–å…ˆï¼Œä½¿ç”¨MSEæŸå¤±è¯„ä¼°é¢„æµ‹çš„ $\hat{C(r)}$ä¸å®é™…å›¾åƒé¢œè‰²$C(r)$ä¹‹é—´çš„å·®å¼‚ã€‚é‰´äºMSEåœ¨ç»†èŠ‚æ•æ‰æ–¹é¢çš„å±€é™æ€§ã€‚æ¥ä¸‹æ¥è¿›å…¥ä¸€ä¸ªç»†åŒ–é˜¶æ®µï¼Œå¼•å…¥LPIPSæŸå¤±ä»¥å¢å¼ºç»†èŠ‚ï¼Œç±»ä¼¼äºER-NeRFã€‚æˆ‘ä»¬ä»å›¾åƒä¸­æå–éšæœºè¡¥ä¸Patch $P$ï¼Œå¹¶å°†LPIPSï¼ˆç”±Î»åŠ æƒï¼‰ä¸MSEç»“åˆèµ·æ¥ä»¥æ”¹å–„ç»†èŠ‚è¡¨ç¤ºã€‚</p><script type="math/tex; mode=display">\mathcal{L}_\mathrm{total}=\sum_\mathrm{r}\|C(\mathrm{r})-\hat{C}(\mathrm{r})\|_2+\lambda\times\mathcal{L}_\mathrm{LPIPS}(\hat{\mathcal{P}},\mathcal{P}).</script><p><strong>Portrait-Sync Generator</strong></p><p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸ºäº†è§£å†³ NeRF åœ¨<strong>æ•æ‰å‘ä¸å’ŒåŠ¨æ€èƒŒæ™¯</strong>ç­‰ç²¾ç»†ç»†èŠ‚æ–¹é¢çš„å±€é™æ€§ï¼Œå¼•å…¥äº†ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå…³é”®éƒ¨åˆ†çš„ PortraitSync ç”Ÿæˆå™¨ã€‚</p><p>é¦–å…ˆï¼ŒNeRF æ¸²æŸ“é¢éƒ¨åŒºåŸŸ ($Fr$)ï¼Œé€šè¿‡é«˜æ–¯æ¨¡ç³Šåˆ›å»º $G(Fr)$ï¼Œç„¶åä½¿ç”¨æˆ‘ä»¬åŒæ­¥çš„å¤´éƒ¨å§¿åŠ¿èƒ½å¤Ÿä¸åŸå§‹å›¾åƒ ($F_o$) åˆå¹¶ï¼Œä»¥å¢å¼ºå¤´å‘ç»†èŠ‚ä¿çœŸåº¦ã€‚</p><p>å…¶æ¬¡ï¼Œå½“å¤´éƒ¨å’Œèº¯å¹²ç»“åˆåœ¨ä¸€èµ·æ—¶ï¼Œå¦‚æœæºè§†é¢‘ä¸­çš„è§’è‰²è¯´è¯è€Œç”Ÿæˆçš„é¢éƒ¨ä¿æŒæ²‰é»˜ï¼Œåˆ™å¯èƒ½ä¼šå‡ºç°æš—é—´éš™åŒºåŸŸï¼Œå¦‚ä¸‹å›¾ï¼ˆbï¼‰æ‰€ç¤ºã€‚ æ‰€ä»¥ç”¨å¹³å‡é¢ˆéƒ¨é¢œè‰² ($Cn$) å¡«å……è¿™äº›åŒºåŸŸã€‚ </p><p>è¿™ç§æ–¹æ³•é€šè¿‡è‚–åƒåŒæ­¥ç”Ÿæˆå™¨äº§ç”Ÿæ›´çœŸå®çš„ç»†èŠ‚å¹¶æé«˜è§†è§‰è´¨é‡ã€‚</p><p><img src="https://picx.zhimg.com/v2-421af4b4cfa489148de7fc8f4067427b.png" alt="æ¯”è¾ƒ"></p><h2 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h2><p><strong>æ•°æ®é›†</strong></p><p>ä¸ºäº†è¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ¥è‡ªAD-NeRFï¼ŒGeneFaceå’ŒER-NeRFä¸­ç›¸åŒçš„è§†é¢‘åºåˆ—ï¼Œå…¶ä¸­åŒ…æ‹¬è‹±è¯­å’Œæ³•è¯­ã€‚è¿™äº›è§†é¢‘çš„å¹³å‡é•¿åº¦çº¦ä¸º8,843å¸§ï¼Œæ¯ä¸ªè§†é¢‘ä»¥25 FPSå½•åˆ¶ã€‚é™¤äº†æ¥è‡ªAD-NeRFçš„è§†é¢‘åˆ†è¾¨ç‡ä¸º450 Ã— 450å¤–ï¼Œæ‰€æœ‰å…¶ä»–è§†é¢‘çš„åˆ†è¾¨ç‡å‡ä¸º512 Ã— 512ï¼Œå¹¶ä»¥è§’è‰²ä¸ºä¸­å¿ƒã€‚</p><p><strong>æ¯”è¾ƒåŸºçº¿</strong></p><ul><li>GAN-based  æ–¹æ³•  ï¼šWav2Lipï¼ŒVideoReTalkingï¼ŒDINetï¼ŒTalkLip and IP-LAPã€‚</li><li>NeRF-based æ–¹æ³• ï¼š AD-NeRFï¼ŒRADNeRFï¼ŒGeneFace and ER-NeRFã€‚</li></ul><p><strong>å®éªŒç»†èŠ‚</strong></p><ul><li>åœ¨ç²—ç•¥é˜¶æ®µï¼Œè‚–åƒå¤´éƒ¨ç»è¿‡100,000æ¬¡è¿­ä»£è®­ç»ƒï¼Œåœ¨ç²¾ç»†é˜¶æ®µè®­ç»ƒ25,000æ¬¡è¿­ä»£ã€‚</li><li>æ¯æ¬¡è¿­ä»£ä½¿ç”¨2Då“ˆå¸Œç¼–ç å™¨ï¼ˆL=14ï¼ŒF=1ï¼‰é‡‡æ ·$256^2$æ¡å…‰çº¿ã€‚</li><li>é‡‡ç”¨AdamWä¼˜åŒ–å™¨[24]ï¼Œå“ˆå¸Œç¼–ç å™¨çš„å­¦ä¹ ç‡ä¸º0.01ï¼Œå…¶ä»–æ¨¡å—çš„å­¦ä¹ ç‡ä¸º0.001ã€‚</li><li>åœ¨NVIDIA RTX 3090 GPUä¸Šï¼Œæ€»è®­ç»ƒæ—¶é—´çº¦ä¸º2å°æ—¶ã€‚</li></ul><p><strong>å®šé‡è¯„ä»·</strong></p><div class="table-container"><table><thead><tr><th>è¯„ä¼°æŒ‡æ ‡</th><th>æè¿°</th></tr></thead><tbody><tr><td>å…¨å‚è€ƒè´¨é‡è¯„ä¼°</td><td>ä½¿ç”¨å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€å­¦ä¹ æ„ŸçŸ¥å›¾åƒè¡¥ä¸ç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰ã€å¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æ€§ï¼ˆMS-SSIMï¼‰å’ŒFrechet Inception Distanceï¼ˆFIDï¼‰ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚</td></tr><tr><td>æ— å‚è€ƒè´¨é‡è¯„ä¼°</td><td>åœ¨é«˜PSNRå›¾åƒä¸­ï¼Œçº¹ç†ç»†èŠ‚å¯èƒ½ä¸äººç±»è§†è§‰æ„ŸçŸ¥ä¸ä¸€è‡´ã€‚ä¸ºäº†æ›´ç²¾ç¡®åœ°å®šä¹‰å’Œæ¯”è¾ƒè¾“å‡ºï¼Œä½¿ç”¨ä¸¤ç§æ— å‚è€ƒæ–¹æ³•ï¼šè‡ªç„¶å›¾åƒè´¨é‡è¯„ä¼°å™¨ï¼ˆNIQEï¼‰å’Œæ— å‚è€ƒå›¾åƒç©ºé—´è´¨é‡è¯„ä¼°å™¨ï¼ˆBRISQUEï¼‰ã€‚</td></tr><tr><td>åŒæ­¥è¯„ä¼°</td><td>å¯¹äºåŒæ­¥æ€§ï¼Œä½¿ç”¨åœ°æ ‡è·ç¦»ï¼ˆLMDï¼‰æ¥è¡¡é‡é¢éƒ¨è¿åŠ¨çš„åŒæ­¥æ€§ï¼ŒåŠ¨ä½œå•ä½è¯¯å·®ï¼ˆAUEï¼‰æ¥è¯„ä¼°é¢éƒ¨è¿åŠ¨çš„å‡†ç¡®æ€§ï¼Œå¹¶å¼•å…¥å”‡åŒæ­¥è¯¯å·®ç½®ä¿¡åº¦ï¼ˆLSE-Cï¼‰ï¼Œä¸Wav2Lipä¸€è‡´ï¼Œä»¥è¯„ä¼°å”‡éƒ¨è¿åŠ¨ä¸éŸ³é¢‘ä¹‹é—´çš„åŒæ­¥æ€§ã€‚</td></tr></tbody></table></div><p><strong>å®šé‡è¯„ä¼°ç»“æœ</strong></p><ul><li>å¤´éƒ¨é‡å»ºæ–¹æ³•åœ¨å›¾åƒè´¨é‡å’ŒåŒæ­¥æ€§æ–¹é¢å‡ä¼˜äºåŸºäºGANå’ŒNeRFçš„æœ€æ–°æ–¹æ³•ã€‚</li><li>ç»è¿‡<code>Portrait-Sync Generato</code>rå¤„ç†åï¼Œå›¾åƒè´¨é‡å¾—åˆ°äº†æ˜¾è‘—æ”¹å–„ï¼Œå¤´å‘ç»†èŠ‚å¾—åˆ°äº†æ¢å¤ã€‚</li><li>æ–¹æ³•åœ¨ç»´æŒä¸»ä½“èº«ä»½ã€å”‡éƒ¨ã€è¡¨æƒ…å’Œå§¿åŠ¿çš„åŒæ­¥æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li><li>ä½¿ç”¨åˆ†å¸ƒå¤–éŸ³é¢‘çš„æœ€æ–°SOTAæ–¹æ³•çš„é©±åŠ¨å™¨ç»“æœè¡¨æ˜ï¼Œæ–¹æ³•åœ¨å”‡éŸ³åŒæ­¥è¯„ä¼°æ–¹é¢é¢†å…ˆã€‚</li><li>æ¸²æŸ“é€Ÿåº¦è¿œè¿œè¶…è¿‡è§†é¢‘è¾“å…¥é€Ÿåº¦ï¼Œå¯ä»¥å®ç°å®æ—¶ç”Ÿæˆè§†é¢‘æµã€‚</li></ul><p><img src="https://pica.zhimg.com/v2-3093f3d799bb12490a7f79dba96bde99.png" alt="The quantitative results of the head reconstruction."></p><p><img src="https://picx.zhimg.com/v2-73c53cd37a7c9e87af9b918778a84d3e.png" alt="The quantitative results of the lip synchronization."></p><p><strong>å®šæ€§è¯„ä»·</strong></p><div class="table-container"><table><thead><tr><th>è¯„ä¼°ç»“æœ</th><th>æè¿°</th></tr></thead><tbody><tr><td>å›¾åƒè´¨é‡æ¯”è¾ƒ</td><td>åœ¨å›¾ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•ä¸å…¶ä»–æ–¹æ³•çš„æ¯”è¾ƒã€‚å¯ä»¥è§‚å¯Ÿåˆ°ï¼ŒSyncTalkå±•ç¤ºäº†æ›´ç²¾ç¡®ã€æ›´å‡†ç¡®çš„é¢éƒ¨ç»†èŠ‚ã€‚</td></tr><tr><td>ä¸Wav2Lipçš„æ¯”è¾ƒ</td><td>ä¸Wav2Lipç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒä¸»ä½“èº«ä»½çš„åŒæ—¶æä¾›äº†æ›´é«˜çš„ä¿çœŸåº¦å’Œåˆ†è¾¨ç‡ã€‚</td></tr><tr><td>ä¸IP-LAPçš„æ¯”è¾ƒ</td><td>ä¸IP-LAPç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å”‡å½¢åŒæ­¥æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸»è¦å½’åŠŸäºéŸ³é¢‘-è§†è§‰ç¼–ç å™¨å¸¦æ¥çš„éŸ³é¢‘-è§†è§‰ä¸€è‡´æ€§ã€‚</td></tr><tr><td>ä¸GeneFaceçš„æ¯”è¾ƒ</td><td>ä¸GeneFaceç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é€šè¿‡è¡¨æƒ…åŒæ­¥ç²¾ç¡®åœ°é‡ç°çœ¨çœ¼å’ŒæŠ¬çœ‰ç­‰åŠ¨ä½œã€‚</td></tr><tr><td>ä¸ER-NeRFçš„æ¯”è¾ƒ</td><td>ä¸ER-NeRFç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å§¿åŠ¿åŒæ­¥ç¨³å®šå™¨é¿å…äº†å¤´éƒ¨å’Œèº«ä½“çš„åˆ†ç¦»ï¼Œå¹¶ç”Ÿæˆäº†æ›´å‡†ç¡®çš„å”‡å½¢ã€‚</td></tr><tr><td></td></tr></tbody></table></div><p><img src="https://picx.zhimg.com/v2-b076e645737b2297bee21027ac8e27ad.png" alt="Qualitative comparison of facial synthesis by different methods."></p><p><strong>User Study</strong>  </p><p>æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè¯¦å°½çš„ç”¨æˆ·ç ”ç©¶é—®å·ï¼Œ35åå‚ä¸è€…è¿›è¡Œè¯„åˆ†ã€‚é—®å·è®¾è®¡äº†äº”ä¸ªæ–¹é¢çš„è¯„åˆ†ï¼šå”‡åŒæ­¥å‡†ç¡®æ€§ã€è¡¨æƒ…åŒæ­¥å‡†ç¡®æ€§ã€å§¿åŠ¿åŒæ­¥å‡†ç¡®æ€§ã€å›¾åƒè´¨é‡å’Œè§†é¢‘çœŸå®æ€§ã€‚</p><p>å‚ä¸è€…å¹³å‡å®Œæˆé—®å·æ—¶é—´ä¸º19åˆ†é’Ÿï¼Œæ ‡å‡†åŒ–çš„Cronbach Î±ç³»æ•°ä¸º0.96ã€‚ç”¨æˆ·ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒSyncTalkåœ¨æ‰€æœ‰è¯„ä¼°ä¸­å‡è¶…è¿‡ä»¥å‰çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨è§†é¢‘çœŸå®æ€§æ–¹é¢ã€‚</p><p><img src="https://picx.zhimg.com/v2-2666052562f51f053affc9fb748eec54.png" alt="User Study"></p><p><strong>Ablation Study</strong></p><p>æ¥ä¸‹æ¥è¿›è¡Œäº†æ¶ˆèç ”ç©¶ï¼Œä»¥æ£€éªŒæˆ‘ä»¬æ¨¡å‹ä¸­ä¸åŒéƒ¨åˆ†çš„è´¡çŒ®ï¼Œé€‰æ‹©äº†ä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡è¿›è¡Œè¯„ä¼°ï¼šPSNRã€LPIPSå’ŒLMDã€‚</p><p>æˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªåä¸ºâ€œMayâ€çš„ä¸»ä½“è¿›è¡Œæµ‹è¯•ï¼Œç»“æœå¦‚è¡¨æ‰€ç¤ºã€‚</p><p><img src="https://pic1.zhimg.com/v2-b204e48268633b55ad93cf70dbc8f9bd.png" alt="Ablation study for our components"></p><p>éŸ³é¢‘-è§†è§‰ç¼–ç å™¨æä¾›äº†ä¸»è¦çš„å”‡éƒ¨åŒæ­¥ä¿¡æ¯ï¼Œå½“æ›¿æ¢æ­¤æ¨¡å—æ—¶ï¼Œæ‰€æœ‰ä¸‰ä¸ªæŒ‡æ ‡éƒ½å˜å·®ï¼Œå…¶ä¸­ç‰¹åˆ«æ˜¯LMDé”™è¯¯å¢åŠ äº†21.15%ï¼Œè¡¨æ˜å”‡éƒ¨åŠ¨ä½œåŒæ­¥å‡å°‘ï¼Œå¦‚å›¾5ï¼ˆaï¼‰æ‰€ç¤ºï¼Œæ˜¾ç¤ºå‡ºæˆ‘ä»¬çš„éŸ³é¢‘-è§†è§‰ç¼–ç å™¨å¯ä»¥æå–å‡†ç¡®çš„å”‡éƒ¨ç‰¹å¾ã€‚</p><p><img src="https://pica.zhimg.com/v2-2fc44a31570aeacd6badcf909f669fdc.png" alt="Ablation Study"></p><p>ç”¨ER-NeRF çš„<strong>çœ¨çœ¼æ¨¡å—</strong>æ›¿æ¢<strong>Facial Animation Capture</strong>æ¨¡å—ï¼Œè¿™ä¸€éƒ¨åˆ†ä¼šå½±å“çœ‰æ¯›çš„è¿åŠ¨å’Œå›¾åƒè´¨é‡ã€‚</p><p><strong>Facial-Aware Masked-Attention</strong>ä¸»è¦è§£è€¦äº†å”‡éƒ¨å’Œé¢éƒ¨å…¶ä»–éƒ¨ä½ä¹‹é—´çš„è¿åŠ¨ï¼Œåœ¨ç§»é™¤åç•¥å¾®å½±å“å›¾åƒè´¨é‡ã€‚</p><p>è‹¥æ²¡æœ‰<strong>å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨</strong>ï¼Œæ‰€æœ‰æŒ‡æ ‡éƒ½æ˜¾è‘—ä¸‹é™ï¼Œç‰¹åˆ«æ˜¯LPIPSï¼Œå¯¼è‡´å¤´éƒ¨å§¿åŠ¿æŠ–åŠ¨å’Œå¤´éƒ¨ä¸èº¯å¹²åˆ†ç¦»ï¼Œå¦‚å›¾5ï¼ˆbï¼‰æ‰€ç¤ºã€‚</p><p><strong>Portrait-Sync Generator</strong>æ¢å¤äº†åƒå¤´å‘è¿™æ ·çš„ç»†èŠ‚ï¼Œç§»é™¤æ­¤æ¨¡å—ä¼šå½±å“å¤´å‘ç­‰ç»†èŠ‚çš„æ¢å¤ï¼Œå¯¼è‡´æ˜æ˜¾çš„åˆ†å‰²è¾¹ç•Œã€‚</p><h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><ul><li>æœ¬æ–‡ä»‹ç»äº†SyncTalkï¼Œè¿™æ˜¯ä¸€ç§åŸºäºé«˜åº¦åŒæ­¥çš„NeRFæ–¹æ³•ï¼Œç”¨äºå®ç°é€¼çœŸçš„è¯­éŸ³é©±åŠ¨çš„è¯´è¯å¤´éƒ¨åˆæˆã€‚</li><li>æ¡†æ¶åŒ…æ‹¬é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨ã€å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨å’Œè‚–åƒåŒæ­¥ç”Ÿæˆå™¨ï¼Œèƒ½å¤Ÿä¿æŒä¸»ä½“èº«ä»½ï¼Œå¹¶ç”ŸæˆåŒæ­¥çš„å”‡éƒ¨åŠ¨ä½œã€é¢éƒ¨è¡¨æƒ…å’Œç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ã€‚</li><li>é€šè¿‡å¹¿æ³›çš„è¯„ä¼°ï¼ŒSyncTalkåœ¨åˆ›å»ºé€¼çœŸå’ŒåŒæ­¥çš„è¯´è¯å¤´éƒ¨è§†é¢‘æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ã€‚</li><li>æœŸæœ›SyncTalkä¸ä»…èƒ½å¢å¼ºå„ç§åº”ç”¨ç¨‹åºçš„åŠŸèƒ½ï¼Œè¿˜èƒ½åœ¨è¯´è¯å¤´éƒ¨åˆæˆé¢†åŸŸæ¿€å‘è¿›ä¸€æ­¥çš„åˆ›æ–°ã€‚</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;SyncTalk-The-Devil-is-in-the-Synchronization-for-Talking-Head-Synthesis&quot;&gt;&lt;a href=&quot;#SyncTalk-The-Devil-is-in-the-Synchronization-for-</summary>
      
    
    
    
    <category term="Paperscape" scheme="https://kedreamix.github.io/categories/Paperscape/"/>
    
    
    <category term="Talking Head Generation" scheme="https://kedreamix.github.io/tags/Talking-Head-Generation/"/>
    
    <category term="NeRF" scheme="https://kedreamix.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>VividTalk One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior</title>
    <link href="https://kedreamix.github.io/2024/03/05/Paperscape/VividTalk/"/>
    <id>https://kedreamix.github.io/2024/03/05/Paperscape/VividTalk/</id>
    <published>2024-03-05T07:31:00.000Z</published>
    <updated>2024-03-07T08:03:21.030Z</updated>
    
    <content type="html"><![CDATA[<h1 id="VividTalk-One-Shot-Audio-Driven-Talking-Head-Generation-Based-on-3D-Hybrid-Prior"><a href="#VividTalk-One-Shot-Audio-Driven-Talking-Head-Generation-Based-on-3D-Hybrid-Prior" class="headerlink" title="VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior"></a>VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior</h1><p>Paper   : <a href="https://arxiv.org/pdf/2312.01841.pdf">https://arxiv.org/pdf/2312.01841.pdf</a></p><p>Project : <a href="https://humanaigc.github.io/vivid-talk/">https://humanaigc.github.io/vivid-talk/</a></p><p>Video   : <a href="https://www.youtube.com/watch?v=lJVzt7JCe_4">https://www.youtube.com/watch?v=lJVzt7JCe_4</a></p><p>Code    : <a href="https://github.com/HumanAIGC/VividTalk">https://github.com/HumanAIGC/VividTalk</a>  (Maybe Comming Soon)</p><p><strong>æ‘˜è¦</strong></p><p>åˆ›æ–°çš„ä¸¤é˜¶æ®µæ¡†æ¶ VividTalk å¯ç”Ÿæˆé«˜è´¨é‡è§†è§‰æ•ˆæœçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼ŒåŒ…æ‹¬å”‡å½¢åŒæ­¥ã€ä¸°å¯Œçš„é¢éƒ¨è¡¨æƒ…ã€è‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿ç­‰ã€‚</p><p>ï¼ˆ1ï¼‰éŸ³é¢‘é©±åŠ¨çš„è¯´è¯å¤´ç”Ÿæˆå·²ç»å¼•èµ·å¹¿æ³›å…³æ³¨ï¼Œåœ¨å”‡å½¢åŒæ­¥ã€é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿åŠ¿ç”Ÿæˆå’Œè§†é¢‘è´¨é‡æ–¹é¢å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºéŸ³é¢‘å’ŒåŠ¨ä½œä¹‹é—´çš„ä¸€å¯¹å¤šæ˜ å°„ï¼Œè¿˜æ²¡æœ‰æ¨¡å‹èƒ½å¤Ÿåœ¨æ‰€æœ‰è¿™äº›æŒ‡æ ‡ä¸Šè¾¾åˆ°æœ€ä¼˜SOTAã€‚<br>ï¼ˆ2ï¼‰ä»¥å¾€çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨æ··åˆå½¢çŠ¶Blendshapeæˆ–é¡¶ç‚¹åç§»vertexæ¥è¡¨ç¤ºé¢éƒ¨è¡¨æƒ…ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æ•æ‰ç²¾ç»†çš„è¡¨æƒ…ç»†èŠ‚æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚æ­¤å¤–ï¼Œå¤´éƒ¨å§¿åŠ¿çš„ç”Ÿæˆé€šå¸¸æ˜¯é€šè¿‡ç›´æ¥ä»éŸ³é¢‘ä¸­å­¦ä¹ æ¥å®ç°çš„ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´ä¸åˆç†å’Œä¸è¿ç»­çš„ç»“æœã€‚<br>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º VividTalk çš„ä¸¤é˜¶æ®µé€šç”¨æ¡†æ¶ï¼Œæ”¯æŒç”Ÿæˆå…·æœ‰æ‰€æœ‰ä¸Šè¿°å±æ€§çš„é«˜è§†è§‰è´¨é‡è¯´è¯å¤´è§†é¢‘ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œé€šè¿‡å­¦ä¹ éåˆšæ€§è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨è¿åŠ¨å°†éŸ³é¢‘æ˜ å°„åˆ°ç½‘æ ¼ã€‚å¯¹äºè¡¨æƒ…è¿åŠ¨ï¼Œé‡‡ç”¨æ··åˆå½¢çŠ¶å’Œé¡¶ç‚¹ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜æ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ã€‚å¯¹äºè‡ªç„¶å¤´éƒ¨è¿åŠ¨ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å¯å­¦ä¹ å¤´éƒ¨å§¿åŠ¿codebookï¼Œå¹¶é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæœºåˆ¶ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæå‡ºäº†ä¸€ç§åŒåˆ†æ”¯è¿åŠ¨-VAE å’Œç”Ÿæˆå™¨ï¼Œå°†ç½‘æ ¼è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨å¹¶é€å¸§åˆæˆé«˜è´¨é‡è§†é¢‘ã€‚<br>ï¼ˆ4ï¼‰å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ VividTalk å¯ä»¥ç”Ÿæˆå…·æœ‰å”‡å½¢åŒæ­¥å’Œé€¼çœŸå¤´éƒ¨å§¿åŠ¿çš„é«˜è§†è§‰è´¨é‡è¯´è¯å¤´è§†é¢‘ï¼Œå¹¶ä¸”åœ¨å®¢è§‚å’Œä¸»è§‚æ¯”è¾ƒä¸­ä¼˜äºä»¥å¾€çš„æœ€æ–°ä½œå“ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>VividTalk é‡‡ç”¨åŒé˜¶æ®µé€šç”¨æ¡†æ¶ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡è§†è§‰æ•ˆæœçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ã€‚</li><li>VividTalk åœ¨ç¬¬ä¸€é˜¶æ®µé€šè¿‡å­¦ä¹ éåˆšæ€§è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨è¿åŠ¨ï¼Œå°†éŸ³é¢‘æ˜ å°„åˆ°ç½‘æ ¼ã€‚</li><li>VividTalk åœ¨ç¬¬äºŒé˜¶æ®µä½¿ç”¨åŒåˆ†æ”¯è¿åŠ¨-VAE å’Œç”Ÿæˆå™¨å°†ç½‘æ ¼è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨å¹¶é€å¸§åˆæˆé«˜è´¨é‡è§†é¢‘ã€‚</li><li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä¸ç›®å‰æœ€å…ˆè¿›çš„ä½œå“ç›¸æ¯”ï¼ŒVividTalk å¯ä»¥ç”Ÿæˆé«˜è´¨é‡è§†è§‰æ•ˆæœçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼Œå¹¶å°†å”‡å½¢åŒæ­¥å’Œé€¼çœŸçš„å¢å¼ºæ•ˆæœæé«˜å¾ˆå¤§å¹…åº¦ã€‚</li></ul><p><img src="https://picx.zhimg.com/80/v2-8521b04f82075cc27b5e95148dba9792.png" alt="VividTalk can generate realistic and lip-sync talking head videos with expressive facial expression, natural head poses."></p><h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p> <strong>éŸ³é¢‘é©±åŠ¨äººè„¸ç”Ÿæˆ</strong></p><p>ä¸»è¦æ˜¯åˆ©ç”¨éŸ³é¢‘é©±åŠ¨äººè„¸ï¼Œç”Ÿæˆç›¸åŒ¹é…çš„å›¾åƒï¼Œæœ€è¿‘çš„ä¸€äº›å·¥ä½œå¦‚SadTalkerï¼Œæ˜¯ç”¨3DMMä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå†ä½¿ç”¨3DMMæ¸²æŸ“å¾—åˆ°å¯¹åº”çš„è§†é¢‘ï¼›ä¹Ÿæœ‰åˆ©ç”¨äººè„¸é¢éƒ¨å…³é”®ç‚¹çš„ï¼Œè¿™éƒ½æ˜¯æ¯”è¾ƒç±»ä¼¼çš„ã€‚åŒæ—¶åŠ å…¥ç”Ÿæˆmaskçš„å˜´å”‡éƒ¨ä»½ï¼Œä½†æ˜¯ç”±äºä¸­é—´çš„è¡¨ç¤ºé™åˆ¶ï¼Œæ‰€æœ‰è¿™äº›æ–¹æ³•éƒ½ä¸è¶³ä»¥ç”Ÿæˆå£å‹åŒæ­¥å’Œé€¼çœŸçš„å¤´éƒ¨è¯´è¯è§†é¢‘ã€‚</p><p>è¿™ä¸ªVIvidTalkeræ˜¯ä½¿ç”¨blendshapeå’Œvertexæ¥ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œåˆ†åˆ«å¯¹ç²—ç²’åº¦å’Œç»†ç²’åº¦è¿›è¡Œå»ºæ¨¡ã€‚</p><p><strong>è§†é¢‘é©±åŠ¨äººè„¸ç”Ÿæˆ</strong></p><p>è§†é¢‘é©±åŠ¨å¯ä»¥è®¤ä¸ºæ˜¯è¡¨æƒ…è¿ç§»ï¼Œä¹Ÿå°±æ˜¯å°†å‚è€ƒè§†é¢‘çš„åŠ¨ä½œè¿ç§»åˆ°ç›®æ ‡äººè„¸ä¸Šï¼Œæ¯”å¦‚FOMMè¿™æ ·çš„æ–¹å¼ï¼Œç”¨æ— ç›‘ç£çš„å…³é”®ç‚¹ä½œä¸ºä¸­é—´çš„è¡¨ç¤ºï¼Œä»¥åŠæœ‰åˆ©ç”¨depthæ·±åº¦ä½œä¸ºä¿¡æ¯çš„ã€‚</p><h2 id="ä¸»è¦æ–¹æ³•"><a href="#ä¸»è¦æ–¹æ³•" class="headerlink" title="ä¸»è¦æ–¹æ³•"></a>ä¸»è¦æ–¹æ³•</h2><p>VividTalkä¸»è¦çš„æ¡†æ¶ç”±ä¸¤ä¸ªçº§è”é˜¶æ®µç»„æˆï¼Œåˆ†åˆ«æ˜¯</p><ul><li><strong>Audio-To-Mesh</strong> éŸ³é¢‘åˆ°ç½‘æ ¼ç”Ÿæˆ</li><li><strong>Mesh-To-VIdeo</strong> ç½‘æ ¼åˆ°è§†é¢‘ç”Ÿæˆ</li></ul><p><img src="https://pic1.zhimg.com/v2-35ebd6e4eb48d485c2f77af937e3a762.png" alt="ä¸»è¦æ–¹æ³•"></p><h3 id="å‰é¦ˆçŸ¥è¯†"><a href="#å‰é¦ˆçŸ¥è¯†" class="headerlink" title="å‰é¦ˆçŸ¥è¯†"></a>å‰é¦ˆçŸ¥è¯†</h3><h4 id="3DMM"><a href="#3DMM" class="headerlink" title="3DMM"></a>3DMM</h4><p>3D Morphable Modelï¼ˆ3DMMï¼‰æ˜¯ä¸€ç§ç”¨äºå»ºæ¨¡å’Œåˆ†æäººè„¸å½¢çŠ¶å’Œå¤–è§‚çš„è®¡ç®—æœºå›¾å½¢æŠ€æœ¯ã€‚å®ƒæ˜¯åŸºäºæ•°å­¦æ¨¡å‹çš„æ–¹æ³•ï¼Œç”¨äºæè¿°å’Œç”Ÿæˆäººè„¸çš„<strong>ä¸‰ç»´å‡ ä½•å½¢çŠ¶å’Œè¡¨é¢çº¹ç†</strong>ã€‚3DMMçš„åŸºæœ¬åŸç†æ˜¯åˆ©ç”¨ç»Ÿè®¡å­¦æ–¹æ³•ä»å¤§é‡çš„ä¸‰ç»´äººè„¸æ•°æ®ä¸­å­¦ä¹ äººè„¸å½¢çŠ¶å’Œçº¹ç†çš„å˜åŒ–è§„å¾‹ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯ç¼–ç åˆ°ä¸€ä¸ªæ•°å­¦æ¨¡å‹ä¸­ã€‚</p><p>è¿™ä¸ªæ¨¡å‹åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦çš„éƒ¨åˆ†ï¼šå½¢çŠ¶æ¨¡å‹å’Œçº¹ç†æ¨¡å‹ã€‚</p><ol><li><strong>å½¢çŠ¶æ¨¡å‹</strong>ï¼šå½¢çŠ¶æ¨¡å‹æè¿°äº†äººè„¸çš„å‡ ä½•å½¢çŠ¶çš„å˜åŒ–ã€‚é€šå¸¸é‡‡ç”¨çš„æ–¹æ³•æ˜¯ä½¿ç”¨ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰å¯¹äººè„¸çš„å½¢çŠ¶æ•°æ®è¿›è¡Œé™ç»´å’Œå»ºæ¨¡ã€‚é€šè¿‡åˆ†æå¤§é‡çš„äººè„¸å½¢çŠ¶æ•°æ®ï¼Œå¯ä»¥å¾—åˆ°ä¸€ç»„ä¸»æˆåˆ†ï¼Œå®ƒä»¬æè¿°äº†äººè„¸å½¢çŠ¶å˜åŒ–çš„ä¸»è¦æ¨¡å¼ã€‚å½¢çŠ¶æ¨¡å‹å¯ä»¥ç”¨æ¥ç”Ÿæˆæ–°çš„äººè„¸å½¢çŠ¶ï¼Œæˆ–è€…å¯¹ç°æœ‰çš„äººè„¸å½¢çŠ¶è¿›è¡Œç¼–è¾‘å’Œå˜å½¢ã€‚</li><li><strong>çº¹ç†æ¨¡å‹</strong>ï¼šçº¹ç†æ¨¡å‹æè¿°äº†äººè„¸è¡¨é¢çš„é¢œè‰²å’Œçº¹ç†çš„å˜åŒ–ã€‚ä¸å½¢çŠ¶æ¨¡å‹ç±»ä¼¼ï¼Œçº¹ç†æ¨¡å‹ä¹Ÿå¯ä»¥åˆ©ç”¨ä¸»æˆåˆ†åˆ†æç­‰æ–¹æ³•æ¥å»ºæ¨¡äººè„¸çš„è¡¨é¢çº¹ç†ã€‚é€šè¿‡åˆ†æå¤§é‡çš„äººè„¸çº¹ç†æ•°æ®ï¼Œå¯ä»¥å¾—åˆ°ä¸€ç»„ä¸»æˆåˆ†ï¼Œå®ƒä»¬æè¿°äº†äººè„¸è¡¨é¢é¢œè‰²å’Œçº¹ç†çš„å˜åŒ–æ¨¡å¼ã€‚çº¹ç†æ¨¡å‹å¯ä»¥ç”¨æ¥ç”Ÿæˆæ–°çš„äººè„¸çº¹ç†ï¼Œæˆ–è€…å¯¹ç°æœ‰çš„äººè„¸çº¹ç†è¿›è¡Œç¼–è¾‘å’Œå˜æ¢ã€‚</li></ol><p><img src="https://pic1.zhimg.com/v2-efd80426cbb18b4f2ee91789c07277eb.png" alt="3DMM"></p><h4 id="æ•°æ®å¤„ç†"><a href="#æ•°æ®å¤„ç†" class="headerlink" title="æ•°æ®å¤„ç†"></a>æ•°æ®å¤„ç†</h4><p>é™¤æ­¤ä¹‹å¤–ï¼Œé¦–å…ˆè¿˜éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿ç”¨FOMMå¯¹æ–¹å¼å¯¹è§†å¬æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶ä¸”è£å‰ªé¢éƒ¨åŒºåŸŸä¸º256x256ã€‚åŒæ—¶ä¹Ÿæ˜¯ç”¨FaceVerseæ¥æå–è¡¨æƒ…ç³»æ•°å’Œç½‘æ ¼é¡¶ç‚¹åºåˆ—ã€‚</p><h3 id="Audio-To-Mesh"><a href="#Audio-To-Mesh" class="headerlink" title="Audio-To-Mesh"></a>Audio-To-Mesh</h3><p>åœ¨æ•°æ®é¢„å¤„ç†çš„æ—¶å€™ï¼Œä½¿ç”¨Faceverseé‡å»ºæˆ‘ä»¬çš„å‚è€ƒå›¾åƒï¼Œä»éŸ³é¢‘ä¸­å­¦ä¹ éåˆšæ€§é¢éƒ¨è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨è¿åŠ¨æ¥é©±åŠ¨é‡å»ºçš„ç½‘æ ¼ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ä¸ªå¤šåˆ†æ”¯çš„Blendshapeå’ŒVertexåç§»ç”Ÿæˆå™¨ä»¥åŠå­¦ä¹ å¤´éƒ¨å§¿åŠ¿çš„codebookï¼Œå…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p><p><img src="https://picx.zhimg.com/v2-1648982e559021c0b5f5eaa6b201ef93.png" alt="Audio-To-Mesh"></p><p><strong>BlendShape and Vertex Offset Generator</strong></p><p>å¯¹äºBlendShape and Vertex Offset Generatoræ¥è¯´ï¼Œé¦–å…ˆä¼šä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„éŸ³é¢‘æ¨¡å‹æ¥æå–éŸ³é¢‘ç‰¹å¾ï¼Œç„¶åä»å‚è€ƒå›¾åƒä¸­æå–èº«ä»½ä¿¡æ¯$\alpha$ï¼Œå¹¶ä¸”ç¼–ç ä¸ºé£æ ¼ä¿¡æ¯$z_{style}$ï¼Œç„¶ååœ¨éŸ³é¢‘ç‰¹å¾ä¸­åµŒå…¥ä¸ªäººé£æ ¼ä¿¡æ¯ï¼Œå†ç»“åˆé€åˆ°åŸºäºå¤šåˆ†æ”¯çš„Transformeræ¶æ„ä¸­ï¼Œä¸€å…±æœ‰ä¸‰ä¸ªåˆ†æ”¯ï¼Œä¸¤ä¸ªåˆ†æ”¯ç”Ÿæˆç²—ç²’åº¦çš„blendshapeï¼Œç¬¬ä¸‰ä¸ªåˆ†æ”¯ç”Ÿæˆç»†ç²’åº¦çš„ä¸å˜´å”‡ç›¸å…³çš„vertexåç§»å¯¹å˜´å”‡è¿åŠ¨è¿›è¡Œè¡¥å……ã€‚</p><script type="math/tex; mode=display">\hat{\beta}_i^f=\Phi_i^{bs}(\hat{\beta}_i^{1...f-1},A,z^{style}),\quad i\in\{lip,other\}, \\\hat{O}_{lip}^f=\Phi_{lip}^{\upsilon o}(\hat{O}_{lip}^{1...f-1},A,z^{style}),</script><p>è®­ç»ƒå®Œæˆåï¼Œå°±å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ¥è¿›è¡Œé©±åŠ¨</p><script type="math/tex; mode=display">\hat{M}_{nr}=(\overline{S}+\alpha U_{id}+(\hat{\beta}_{lip},\hat{\beta}_{other})U_{exp}+\hat{O}_{lip})\otimes P_{ref}.</script><p>è¿™é‡Œé¢çš„$P_{ref}$ä¸ºå‚è€ƒå›¾åƒçš„<strong>head pose</strong>ï¼Œ$\otimes$æ˜¯å¯¹åº”çš„ä»¿å°„å˜åŒ–ã€‚</p><p><img src="https://picx.zhimg.com/v2-15f9efd01582593cfaf9a3a5bd765dac.png" alt="BlendShape and Vertex Offset Generator"></p><p><strong>Learnable Head Pose Codebook</strong></p><p>å¤´éƒ¨å§¿åŠ¿æ˜¯éå¸¸é‡è¦çš„ä¸€ç¯ï¼Œç›´æ¥ä»éŸ³é¢‘ä¸­å­¦ä¹ è¿˜æ˜¯æ¯”è¾ƒå›°éš¾çš„ï¼Œå› ä¸ºè¿™é‡Œé¢çš„å…³ç³»æ˜¯æ¯”è¾ƒå¾®å¼±çš„ï¼Œå› æ­¤ï¼Œä½¿ç”¨ç¦»æ•£çš„codebookçš„ï¼Œå°†ç”Ÿæˆçš„é—®é¢˜è½¬åŒ–ä¸ºåœ¨ç¦»æ•£å’Œä¸”æœ‰é™çš„å§¿åŠ¿ç©ºé—´ä¸­æŸ¥è¯¢codebookçš„ä»»åŠ¡ï¼Œè®¾è®¡äº†ä¸¤é˜¶æ®µçš„è®­ç»ƒæœºåˆ¶ã€‚</p><p>ç¬¬ä¸€é˜¶æ®µæ˜¯é‡å»ºé˜¶æ®µï¼Œåˆ©ç”¨VQ-VAEæ¥æ„å»ºä¸°å¯Œçš„å¤´éƒ¨å§¿åŠ¿codebookï¼Œæ˜¯ä¸€ä¸ªç¼–ç è§£ç ç»“æ„ã€‚</p><script type="math/tex; mode=display">Z_q=\mathbf{q}(\hat{z})=\underset{z_k\in\mathcal{Z}}{\operatorname*{\arg\min}}\left\|\hat{z}-z_k\right\|. \\\hat{P}_r^{1:f}=\mathcal{D}(Z_q)=\mathcal{D}(\mathbf{q}(\mathcal{E}(P_r^{1:f}))).</script><p>ç¬¬äºŒé˜¶æ®µæ˜¯æ˜ å°„é˜¶æ®µï¼Œå°†è¾“å…¥éŸ³é¢‘æ˜ å°„åˆ°codebookç”Ÿæˆæœ€ç»ˆç»“æœï¼Œå…·ä½“æ¥è¯´ï¼Œ$\Phi_{map}$ä»¥éŸ³é¢‘åºåˆ—Aã€ç‰¹å®šäºäººçš„é£æ ¼åµŒå…¥$z^{style}$å’Œåˆå§‹å¤´éƒ¨å§¿åŠ¿$P^0$ ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºä¸­é—´ç‰¹å¾$\hat Z$ï¼Œè¯¥ä¸­é—´ç‰¹å¾å°†ä»codebook$Z$é‡åŒ–ä¸º$Z_q$ï¼Œç„¶åç”±é¢„è®­ç»ƒçš„è§£ç å™¨$D$è§£ç </p><script type="math/tex; mode=display">\hat{P}_r^{1:f}=\mathcal{D}(Z_q)=\mathcal{D}(\mathbf{q}(\Phi_{map}(A,s,P^0))).</script><p>ä»ç›®å‰ä¸ºæ­¢ï¼Œéåˆšæ€§é¢éƒ¨è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨å§¿åŠ¿éƒ½å·²å­¦ä¹ ã€‚ç°åœ¨æˆ‘ä»¬å°±å¯ä»¥è¿ç”¨å­¦ä¹ åˆ°çš„åˆšæ€§å¤´éƒ¨å§¿åŠ¿åº”ç”¨äºMesh $\hat{M}<em>{nr}$æ¥è·å¾—æœ€æœ€ç»ˆçš„é©±åŠ¨ç½‘æ ¼Mesh $\hat{M}</em>{d}$ã€‚</p><p><img src="https://pic1.zhimg.com/v2-d9f01fd2be86dc73e859cc5df7c2f7d9.png" alt="Learnable Head Pose Codebook"></p><h3 id="Mesh-To-Video"><a href="#Mesh-To-Video" class="headerlink" title="Mesh-To-Video"></a>Mesh-To-Video</h3><p>è¿™ä¸€éƒ¨ä»½æ˜¯ä¸ºäº†å°†é©±åŠ¨çš„Meshè½¬æˆè§†é¢‘ï¼Œæå‡ºäº†ä¸€ä¸ªåŒåˆ†æ”¯çš„Motion-VAEå¯¹è¿™äº›2Då¯†é›†è¿åŠ¨è¿›è¡Œå»ºæ¨¡ï¼Œæœ€ååˆæˆæœ€ç»ˆçš„è§†é¢‘ã€‚</p><p>å¦‚æœè¦å»ºæ¨¡2Dä¸3Dä¹‹é—´çš„å…³ç³»æ¯”è¾ƒéš¾ï¼Œä¸ºäº†æ›´å¥½çš„å­¦ä¹ ï¼Œä½¿ç”¨æŠ•å½±çº¹ç†è¡¨ç¤ºæ¥å®ç°2Dçš„è½¬æ¢ã€‚</p><p>å¹¶ä¸”ä¸ºäº†æ›´å¥½çš„å­¦ä¹ 3D Meshçš„çº¹ç†ï¼Œé¦–å…ˆåœ¨x,y,zä¸‰ä¸ªè½´çš„è¿›è¡Œå½’ä¸€åŒ–çš„å¤„ç†ï¼Œå½’ä¸€åŒ–åˆ°0ï¼Œå¾—åˆ°çº¹ç†çš„æ–°è¡¨ç¤ºNCCï¼š</p><script type="math/tex; mode=display">NCC_i=\frac{\overline{S}_i-min(\overline{S}_i)}{max(\overline{S}_i)-min(\overline{S}_i)},\quad i\in\{x,y,z\}.</script><p>ç„¶åï¼Œä½¿ç”¨äº†Z-Bufferæ–¹å¼å’ŒNCCçš„é¢œè‰²å»æ¸²æŸ“3Dé¢åº¦çš„çº¹ç†$PT<em>{in}$ï¼Œç”±äº3DMMçš„é™åˆ¶ï¼Œå¤–è¡¨çš„åŒºåŸŸæ˜¯æ— æ³•è¢«å»ºæ¨¡çš„ï¼Œæ‰€ä»¥ä½¿ç”¨Deep Learning Face Attributes in the Wild æ–¹æ³•è§£æå›¾åƒå¹¶è·å¾—å¤–éƒ¨é¢éƒ¨åŒºåŸŸçº¹ç†$PT</em>{out}$ï¼Œä¾‹å¦‚èº¯å¹²å’ŒèƒŒæ™¯ï¼Œå°†å…¶ä¸$PT_{in}$ ç»„åˆå¦‚ä¸‹ï¼š</p><script type="math/tex; mode=display">PT=PT_{in}\cdot M+PT_{out}\cdot(1-M)</script><p>å…¶ä¸­$M$æ˜¯å†…éƒ¨äººè„¸çš„Maskï¼Œä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºå˜´å”‡è¿åŠ¨å¹¶æ›´å‡†ç¡®åœ°å»ºæ¨¡ï¼Œæˆ‘ä»¬è¿˜é€‰æ‹©ä¸å˜´å”‡ç›¸å…³çš„æ ‡å¿—å¹¶å°†å…¶è½¬æ¢ä¸ºé«˜æ–¯å›¾ï¼Œè¿™æ˜¯ä¸€ç§æ›´ç´§å‡‘ã€æ›´æœ‰æ•ˆçš„è¡¨ç¤ºã€‚ç„¶åï¼ŒHourglassç½‘ç»œå°†å‡å»çš„é«˜æ–¯å›¾ä½œä¸ºè¾“å…¥å¹¶è¾“å‡º 2D å˜´å”‡è¿åŠ¨ï¼Œè¯¥è¿åŠ¨å°†ä¸é¢éƒ¨è¿åŠ¨è¿æ¥å¹¶è§£ç ä¸ºå¯†é›†è¿åŠ¨å’Œé®æŒ¡å›¾ã€‚</p><p>æœ€åï¼Œæ ¹æ®ä¹‹å‰é¢„æµ‹çš„å¯†é›†è¿åŠ¨å›¾å¯¹å‚è€ƒå›¾åƒè¿›è¡Œå˜å½¢ï¼Œè·å¾—å˜å½¢å›¾åƒï¼Œè¯¥å˜å½¢å›¾åƒå°†ä¸é®æŒ¡å›¾ä¸€èµ·ä½œä¸ºç”Ÿæˆå™¨çš„è¾“å…¥ï¼Œé€å¸§åˆæˆæœ€ç»ˆè§†é¢‘ã€‚</p><p><img src="https://picx.zhimg.com/v2-bd37230a1f7ac7c875a8b5555d5b43dd.png" alt="Mesh-To-Video"></p><h3 id="è®­ç»ƒç­–ç•¥"><a href="#è®­ç»ƒç­–ç•¥" class="headerlink" title="è®­ç»ƒç­–ç•¥"></a>è®­ç»ƒç­–ç•¥</h3><p>è¿™å‡ éƒ¨åˆ†å®é™…ä¸Šéƒ½æ˜¯åˆ†å¼€è®­ç»ƒçš„ï¼Œä¸è¿‡è®­ç»ƒåå¯ä»¥é€šè¿‡ç«¯åˆ°ç«¯çš„æ–¹å¼ç”Ÿæˆç»“æœã€‚</p><p><strong>BlendShape and Vertex Offset Generator</strong>ç”±Blendshapeå’ŒMeshé‡å»ºæŸå¤±æ¥è¿›è¡Œç›‘ç£</p><script type="math/tex; mode=display">L_{bsvo}=\left\|\beta-\hat{\beta}\right\|+\left\|M-\hat{M}_{nr}\right\|.</script><p><strong>Learnable Head Pose Codebook</strong>éƒ¨åˆ†ä¸­ï¼Œç”±äºé‡åŒ–å‡½æ•°æ˜¯ä¸å¯å¾®åˆ†çš„ï¼Œæ‰€ä»¥ä½¿ç”¨straight-through gradient estimatorå°†æ¢¯åº¦ä»è§£ç å™¨å¤åˆ¶åˆ°ç¼–ç å™¨ï¼Œç„¶åå¯¹ä¸¤é˜¶æ®µè®­ç»ƒè¿›è¡Œå¦‚ä¸‹ç›‘ç£ï¼š</p><script type="math/tex; mode=display">\begin{aligned}L_{rec}= =\left\|P_r^{1:f}-\hat{P}_r^{1:f}\right\|^2+\left\|sg(\mathcal{E}(P_r^{1:f}))-z_q\right\|_2^2  \\+\left\|sg(z_q)-\mathcal{E}(P_r^{1:f})\right\|_2^2, \\L_{map} =\left\|P_r^{1:f}-\hat{P}_r^{1:f}\right\|^2+\left\|\hat{Z}-sg(Z_q)\right\|_2^2, \end{aligned}</script><p>sgè¡¨ç¤ºåœæ­¢æ¢¯åº¦æ“ä½œï¼Œä¹Ÿå°±æ˜¯ <strong>stop gradient</strong></p><p><strong>Mesh-To-Video</strong>é˜¶æ®µä¸­ï¼ŒåŸºäºé¢„è®­ç»ƒçš„VGG-19 ç½‘ç»œçš„æ„ŸçŸ¥æŸå¤±$L<em>{perc}$è¢«ç”¨ä½œä¸»è¦é©±åŠ¨æŸå¤±ã€‚ç‰¹å¾åŒ¹é…æŸå¤± $L</em>{fm}$è¿˜ç”¨äºç¨³å®šè®­ç»ƒäº§ç”Ÿæ›´çœŸå®çš„ç»“æœã€‚</p><h2 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h2><p>æ¥ä¸‹æ¥æ€»ç»“ä¸€ä¸‹å®éªŒçš„ç»“æœæ–¹æ³•çš„å¯¹æ¯”ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨äº†HDTFå’ŒVoxCelebæ•°æ®é›†ï¼Œä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œåœ¨ä¸¤ä¸ªé˜¶æ®µä¸­å­¦ä¹ ç‡åˆ†åˆ«ä¸º1e-4å’Œ1e-5ï¼Œæœ€åç”¨8ä¸ªV100è®­ç»ƒäº†2å¤©å¾—åˆ°æœ€ç»ˆçš„ç»“æœã€‚</p><div class="table-container"><table><thead><tr><th>æ–¹æ³•</th><th>ä¼˜ç‚¹</th><th>ç¼ºç‚¹</th></tr></thead><tbody><tr><td>SadTalker</td><td>æ— æ³•ç”Ÿæˆç²¾ç¡®çš„ç»†èŠ‚å”‡éƒ¨åŠ¨ä½œ</td><td>è§†é¢‘è´¨é‡ä¸ä½³</td></tr><tr><td>TalkLip</td><td>ç”Ÿæˆæ¨¡ç³Šç»“æœï¼Œçš®è‚¤è‰²è°ƒç¨å¾®åé»„ï¼Œå¤±å»äº†ä¸€å®šç¨‹åº¦çš„èº«ä»½ä¿¡æ¯</td><td>è´¨é‡è¾ƒå·®</td></tr><tr><td>MakeItTalk</td><td>åœ¨äº¤å‰èº«ä»½é…éŸ³è®¾ç½®ä¸­ä¸èƒ½ç”Ÿæˆå‡†ç¡®çš„å˜´éƒ¨å½¢çŠ¶</td><td>å˜´éƒ¨å½¢çŠ¶ä¸å‡†ç¡®</td></tr><tr><td>Wav2Lip</td><td>å®¹æ˜“åˆæˆæ¨¡ç³Šçš„å£éƒ¨åŒºåŸŸï¼Œå•ä¸€å‚è€ƒå›¾åƒæ—¶è¾“å‡ºè§†é¢‘å¤´éƒ¨å§¿åŠ¿å’Œçœ¼éƒ¨è¿åŠ¨é™æ­¢</td><td>è§†é¢‘è¾“å‡ºè´¨é‡è¾ƒä½</td></tr><tr><td>PC-AVS</td><td>éœ€è¦ä¸€ä¸ªé©±åŠ¨è§†é¢‘ä½œä¸ºè¾“å…¥ï¼Œèº«ä»½ä¿å­˜å›°éš¾</td><td>èº«ä»½ä¿å­˜å›°éš¾</td></tr><tr><td>VividTalker</td><td>å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯å¤´åƒè§†é¢‘ï¼Œå…·æœ‰å‡†ç¡®çš„å”‡åŒæ­¥å’Œä¸°å¯Œçš„é¢éƒ¨è¿åŠ¨</td><td>è§†é¢‘è´¨é‡é«˜ï¼Œå”‡åŒæ­¥å‡†ç¡®ï¼Œé¢éƒ¨è¿åŠ¨ä¸°å¯Œ</td></tr></tbody></table></div><p><img src="https://pic1.zhimg.com/v2-66838829a274884142dde5ee251e190c.png" alt="å®éªŒç»“æœ"></p><h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>VividTalkæ¡†æ¶çš„ä¼˜ç‚¹åŒ…æ‹¬ï¼š</p><ol><li><p><strong>é«˜è´¨é‡çš„ç”Ÿæˆè§†é¢‘</strong>ï¼šVividTalkèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯å¤´åƒè§†é¢‘ï¼Œå…·æœ‰æ¸…æ™°çš„é¢éƒ¨è¡¨æƒ…å’Œè‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å…·æ²‰æµ¸æ„Ÿå’ŒçœŸå®æ„Ÿçš„ä½“éªŒã€‚</p></li><li><p><strong>ä¸°å¯Œçš„è¡¨è¾¾èƒ½åŠ›</strong>ï¼šé€šè¿‡å°†æ··åˆå½¢çŠ¶å’Œé¡¶ç‚¹æ˜ å°„ä¸ºä¸­é—´è¡¨ç¤ºï¼ŒVividTalkèƒ½å¤Ÿæœ€å¤§åŒ–æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œä»è€Œå‘ˆç°å‡ºä¸°å¯Œçš„é¢éƒ¨è¡¨æƒ…ï¼ŒåŒ…æ‹¬ç»†å¾®çš„ç»†èŠ‚è¿åŠ¨ã€‚</p></li><li><p><strong>çµæ´»çš„æ¨¡å‹è®¾è®¡</strong>ï¼šé‡‡ç”¨å¤šåˆ†æ”¯ç”Ÿæˆå™¨ï¼ŒVividTalkèƒ½å¤Ÿçµæ´»åœ°å¯¹å…¨å±€å’Œå±€éƒ¨é¢éƒ¨è¿åŠ¨è¿›è¡Œå»ºæ¨¡ï¼Œä½¿å¾—ç”Ÿæˆçš„è§†é¢‘æ›´åŠ ç”ŸåŠ¨å’Œè‡ªç„¶ã€‚</p></li><li><p><strong>è‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿åˆæˆ</strong>ï¼šé€šè¿‡å¼•å…¥æ–°é¢–çš„å¯å­¦ä¹ çš„å¤´éƒ¨å§¿åŠ¿ç æœ¬å’Œä¸¤é˜¶æ®µè®­ç»ƒæœºåˆ¶ï¼ŒVividTalkèƒ½å¤Ÿåˆæˆæ›´åŠ è‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿ï¼Œä½¿å¾—ç”Ÿæˆçš„è§†é¢‘æ›´åŠ é€¼çœŸã€‚</p></li><li><p><strong>åˆ›æ–°çš„åŒåˆ†æ”¯æœºåˆ¶</strong>ï¼šåˆ©ç”¨åŒåˆ†æ”¯è¿åŠ¨-VAEå’Œç”Ÿæˆå™¨ï¼ŒVividTalkèƒ½å¤Ÿæœ‰æ•ˆåœ°è½¬åŒ–é©±åŠ¨ç½‘æ ¼ä¸ºå¯†é›†è¿åŠ¨ï¼Œå¹¶ç”¨äºåˆæˆæœ€ç»ˆè§†é¢‘ï¼Œæé«˜äº†ç”Ÿæˆè§†é¢‘çš„è´¨é‡å’ŒçœŸå®æ„Ÿã€‚</p></li><li><p><strong>è¶…è¶Šæ€§èƒ½</strong>ï¼šå®éªŒè¯æ˜ï¼ŒVividTalkä¼˜äºä»¥å¾€çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¸ºæ•°å­—äººç±»åˆ›å»ºã€è§†é¢‘ä¼šè®®ç­‰åº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</p></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;VividTalk-One-Shot-Audio-Driven-Talking-Head-Generation-Based-on-3D-Hybrid-Prior&quot;&gt;&lt;a href=&quot;#VividTalk-One-Shot-Audio-Driven-Talking-</summary>
      
    
    
    
    <category term="Paperscape" scheme="https://kedreamix.github.io/categories/Paperscape/"/>
    
    
    <category term="Talking Head Generation" scheme="https://kedreamix.github.io/tags/Talking-Head-Generation/"/>
    
    <category term="NeRF" scheme="https://kedreamix.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>Diffusion Models</title>
    <link href="https://kedreamix.github.io/2024/03/04/Paper/2024-03-04/Diffusion%20Models/"/>
    <id>https://kedreamix.github.io/2024/03/04/Paper/2024-03-04/Diffusion%20Models/</id>
    <published>2024-03-04T13:30:23.000Z</published>
    <updated>2024-03-04T13:30:23.412Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-03-04-æ›´æ–°"><a href="#2024-03-04-æ›´æ–°" class="headerlink" title="2024-03-04 æ›´æ–°"></a>2024-03-04 æ›´æ–°</h1><h2 id="DistriFusion-Distributed-Parallel-Inference-for-High-Resolution-Diffusion-Models"><a href="#DistriFusion-Distributed-Parallel-Inference-for-High-Resolution-Diffusion-Models" class="headerlink" title="DistriFusion: Distributed Parallel Inference for High-Resolution   Diffusion Models"></a>DistriFusion: Distributed Parallel Inference for High-Resolution   Diffusion Models</h2><p><strong>Authors:Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Ming-Yu Liu, Kai Li, Song Han</strong></p><p>Diffusion models have achieved great success in synthesizing high-quality images. However, generating high-resolution images with diffusion models is still challenging due to the enormous computational costs, resulting in a prohibitive latency for interactive applications. In this paper, we propose DistriFusion to tackle this problem by leveraging parallelism across multiple GPUs. Our method splits the model input into multiple patches and assigns each patch to a GPU. However, na\â€{\i}vely implementing such an algorithm breaks the interaction between patches and loses fidelity, while incorporating such an interaction will incur tremendous communication overhead. To overcome this dilemma, we observe the high similarity between the input from adjacent diffusion steps and propose displaced patch parallelism, which takes advantage of the sequential nature of the diffusion process by reusing the pre-computed feature maps from the previous timestep to provide context for the current step. Therefore, our method supports asynchronous communication, which can be pipelined by computation. Extensive experiments show that our method can be applied to recent Stable Diffusion XL with no quality degradation and achieve up to a 6.1$\times$ speedup on eight NVIDIA A100s compared to one. Our code is publicly available at <a href="https://github.com/mit-han-lab/distrifuser">https://github.com/mit-han-lab/distrifuser</a>. </p><p><a href="http://arxiv.org/abs/2402.19481v1">PDF</a> CVPR 2024 Code: <a href="https://github.com/mit-han-lab/distrifuser">https://github.com/mit-han-lab/distrifuser</a> Website:   <a href="https://hanlab.mit.edu/projects/distrifusion">https://hanlab.mit.edu/projects/distrifusion</a> Blog:   <a href="https://hanlab.mit.edu/blog/distrifusion">https://hanlab.mit.edu/blog/distrifusion</a></p><p><strong>Summary</strong><br>åˆ©ç”¨å¤šGPUå®ç°å¹¶è¡Œå¤„ç†ï¼Œæå‡é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆæ•ˆç‡ï¼Œå¹¶é€šè¿‡å¤ç”¨ç‰¹å¾å›¾é™ä½é€šä¿¡å¼€é”€ï¼Œæ˜¾è‘—åŠ é€Ÿæ‰©æ•£æ¨¡å‹æ¨ç†ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>å¤šGPUå¹¶è¡Œå¤„ç†å¯å¤§å¹…æå‡æ‰©æ•£æ¨¡å‹æ¨ç†é€Ÿåº¦ã€‚</li><li>å°†æ¨¡å‹è¾“å…¥æ‹†åˆ†ä¸ºå¤šä¸ªpatchï¼Œåˆ†é…ç»™ä¸åŒGPUå¤„ç†ã€‚</li><li>ä½ç§»patchå¹¶è¡Œæœºåˆ¶ï¼Œåˆ©ç”¨ç›¸é‚»æ‰©æ•£æ­¥é•¿çš„ç›¸ä¼¼æ€§ï¼Œå¤ç”¨ç‰¹å¾å›¾å‡å°‘é€šä¿¡å¼€é”€ã€‚</li><li>æ”¯æŒå¼‚æ­¥é€šä¿¡ï¼Œå¯ä¸è®¡ç®—æµæ°´çº¿åŒ–ã€‚</li><li>åœ¨Stable Diffusion XLæ¨¡å‹ä¸ŠéªŒè¯æœ‰æ•ˆæ€§ï¼Œæ— è´¨é‡æŸå¤±ä¸”åŠ é€Ÿ6.1å€ã€‚</li><li>å·²å¼€æºä»£ç ï¼š<a href="https://github.com/mit-han-lab/distrifuser">https://github.com/mit-han-lab/distrifuser</a>.</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šDistriFusionï¼šç”¨äºé«˜åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹çš„åˆ†å¸ƒå¼å¹¶è¡Œæ¨ç†</li><li>ä½œè€…ï¼šMuyang Liã€Tianle Caiã€Jiaxin Caoã€Qinsheng Zhangã€Han Caiã€Junjie Baiã€Yangqing Jiaã€Ming-Yu Liuã€Kai Liã€Song Han</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéº»çœç†å·¥å­¦é™¢</li><li>å…³é”®è¯ï¼šDiffusion Modelsã€Parallel Inferenceã€High-Resolution Images</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.19481Github ä»£ç é“¾æ¥ï¼šhttps://github.com/mit-han-lab/distrifuser</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨åˆæˆé«˜è´¨é‡å›¾åƒæ–¹é¢å–å¾—äº†å·¨å¤§æˆåŠŸã€‚ç„¶è€Œï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè®¡ç®—æˆæœ¬å·¨å¤§ï¼Œå¯¼è‡´äº¤äº’å¼åº”ç”¨ç¨‹åºçš„å»¶è¿Ÿå¾ˆé«˜ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•å°†æ¨¡å‹è¾“å…¥æ‹†åˆ†ä¸ºå¤šä¸ªå—ï¼Œå¹¶å°†å…¶åˆ†é…ç»™ä¸åŒçš„ GPUã€‚ç„¶è€Œï¼Œè¿™ç§æœ´ç´ çš„å®ç°ä¼šç ´åå—ä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œé™ä½ä¿çœŸåº¦ã€‚è€Œå¼•å…¥äº¤äº’åˆä¼šå¯¼è‡´å·¨å¤§çš„é€šä¿¡å¼€é”€ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº† DistriFusionï¼Œé€šè¿‡åˆ©ç”¨å¤š GPU çš„å¹¶è¡Œæ€§æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§è´¨ï¼Œé‡ç”¨æ¥è‡ªå‰ä¸€æ—¶é—´æ­¥çš„é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œä¸ºå½“å‰æ—¶é—´æ­¥æä¾›ä¸Šä¸‹æ–‡ã€‚ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šDistriFusion å¯ä»¥åº”ç”¨äºæœ€æ–°çš„ Stable Diffusion XLï¼Œä¸”ä¸é™ä½è´¨é‡ã€‚ä¸å•ä¸ª GPU ç›¸æ¯”ï¼Œåœ¨å…«ä¸ª NVIDIA A100 ä¸Šï¼Œè¯¥æ–¹æ³•å®ç°äº†é«˜è¾¾ 6.1 å€çš„åŠ é€Ÿã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³ä»¥è¾ƒä½çš„å»¶è¿Ÿç”Ÿæˆé«˜è´¨é‡çš„é«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li></ol><p><strong>7. æ–¹æ³•</strong>(1): DistriFusioné€šè¿‡åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§è´¨ï¼Œé‡ç”¨æ¥è‡ªå‰ä¸€æ—¶é—´æ­¥çš„é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œä¸ºå½“å‰æ—¶é—´æ­¥æä¾›ä¸Šä¸‹æ–‡ï¼Œä»è€Œè§£å†³å¤šGPUå¹¶è¡Œæ¨ç†ä¸­å—ä¹‹é—´äº¤äº’ç ´åä¿çœŸåº¦çš„é—®é¢˜ã€‚(2): è¯¥æ–¹æ³•å°†æ¨¡å‹è¾“å…¥æ‹†åˆ†ä¸ºå¤šä¸ªå—ï¼Œå¹¶å°†å…¶åˆ†é…ç»™ä¸åŒçš„GPUï¼Œåœ¨æ¯ä¸ªGPUä¸Šç‹¬ç«‹æ‰§è¡Œæ‰©æ•£è¿‡ç¨‹ã€‚(3): ä¸ºäº†ç»´æŠ¤å—ä¹‹é—´çš„äº¤äº’ï¼ŒDistriFusionåˆ©ç”¨äº†é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œè¿™äº›ç‰¹å¾å›¾åŒ…å«äº†å‰ä¸€æ—¶é—´æ­¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚(4): é€šè¿‡é‡ç”¨è¿™äº›é¢„è®¡ç®—ç‰¹å¾å›¾ï¼ŒDistriFusioné¿å…äº†åœ¨å—ä¹‹é—´ä¼ è¾“ä¸­é—´ç‰¹å¾å›¾çš„éœ€è¦ï¼Œä»è€Œå‡å°‘äº†é€šä¿¡å¼€é”€ã€‚(5): æ­¤å¤–ï¼ŒDistriFusionè¿˜é‡‡ç”¨äº†å¼‚æ­¥æ‰§è¡Œæœºåˆ¶ï¼Œå…è®¸ä¸åŒGPUåœ¨ä¸åŒçš„æ—¶é—´æ­¥ä¸Šå·¥ä½œï¼Œè¿›ä¸€æ­¥æé«˜äº†å¹¶è¡Œæ•ˆç‡ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œé€šè¿‡æå‡º DistriFusion æ–¹æ³•ï¼Œè§£å†³äº†é«˜åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹åˆ†å¸ƒå¼å¹¶è¡Œæ¨ç†ä¸­å—ä¹‹é—´äº¤äº’ç ´åä¿çœŸåº¦çš„éš¾é¢˜ï¼Œä¸ºäº¤äº’å¼åº”ç”¨ç¨‹åºç”Ÿæˆé«˜è´¨é‡é«˜åˆ†è¾¨ç‡å›¾åƒæä¾›äº†æ”¯æŒã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li><li>åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§è´¨ï¼Œé‡ç”¨é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œä¸ºå½“å‰æ—¶é—´æ­¥æä¾›ä¸Šä¸‹æ–‡ï¼Œé¿å…äº†å—ä¹‹é—´ä¼ è¾“ä¸­é—´ç‰¹å¾å›¾çš„éœ€è¦ï¼Œå‡å°‘äº†é€šä¿¡å¼€é”€ã€‚</li><li>é‡‡ç”¨å¼‚æ­¥æ‰§è¡Œæœºåˆ¶ï¼Œå…è®¸ä¸åŒ GPU åœ¨ä¸åŒçš„æ—¶é—´æ­¥ä¸Šå·¥ä½œï¼Œè¿›ä¸€æ­¥æé«˜äº†å¹¶è¡Œæ•ˆç‡ã€‚æ€§èƒ½ï¼š</li><li>åœ¨å…«ä¸ª NVIDIA A100 ä¸Šï¼Œä¸å•ä¸ª GPU ç›¸æ¯”ï¼Œå®ç°äº†é«˜è¾¾ 6.1 å€çš„åŠ é€Ÿã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•å¯ä»¥åº”ç”¨äºæœ€æ–°çš„ StableDiffusionXLï¼Œä¸”ä¸é™ä½è´¨é‡ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-437f25db9d3e29d465c2ea11bbb5cca0.jpg" align="middle"><img src="https://picx.zhimg.com/v2-5d41c099d139cb88d89783cdff85061d.jpg" align="middle"><img src="https://picx.zhimg.com/v2-e528b344942b85d8abba3ea6722f8989.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-693881daa5f71c118b273327cab24071.jpg" align="middle"></details><h2 id="A-Novel-Approach-to-Industrial-Defect-Generation-through-Blended-Latent-Diffusion-Model-with-Online-Adaptation"><a href="#A-Novel-Approach-to-Industrial-Defect-Generation-through-Blended-Latent-Diffusion-Model-with-Online-Adaptation" class="headerlink" title="A Novel Approach to Industrial Defect Generation through Blended Latent   Diffusion Model with Online Adaptation"></a>A Novel Approach to Industrial Defect Generation through Blended Latent   Diffusion Model with Online Adaptation</h2><p><strong>Authors:Hanxi Li, Zhengxun Zhang, Hao Chen, Lin Wu, Bo Li, Deyin Liu, Mingwen Wang</strong></p><p>Effectively addressing the challenge of industrial Anomaly Detection (AD) necessitates an ample supply of defective samples, a constraint often hindered by their scarcity in industrial contexts. This paper introduces a novel algorithm designed to augment defective samples, thereby enhancing AD performance. The proposed method tailors the blended latent diffusion model for defect sample generation, employing a diffusion model to generate defective samples in the latent space. A feature editing process, controlled by a â€œtrimapâ€ mask and text prompts, refines the generated samples. The image generation inference process is structured into three stages: a free diffusion stage, an editing diffusion stage, and an online decoder adaptation stage. This sophisticated inference strategy yields high-quality synthetic defective samples with diverse pattern variations, leading to significantly improved AD accuracies based on the augmented training set. Specifically, on the widely recognized MVTec AD dataset, the proposed method elevates the state-of-the-art (SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD metrics AP, IAP, and IAP90, respectively. The implementation code of this work can be found at the GitHub repository <a href="https://github.com/GrandpaXun242/AdaBLDM.git">https://github.com/GrandpaXun242/AdaBLDM.git</a> </p><p><a href="http://arxiv.org/abs/2402.19330v1">PDF</a> 13 pages,7 figures</p><p><strong>Summary</strong><br>ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆç¼ºé™·æ ·æœ¬æ¥å¢å¼ºå·¥ä¸šå¼‚å¸¸æ£€æµ‹ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>å·¥ä¸šå¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰çš„ç¼ºé™·æ ·æœ¬ä¸è¶³ã€‚</li><li>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®—æ³•ï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ç”Ÿæˆç¼ºé™·æ ·æœ¬ã€‚</li><li>ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ç”±ä¸‰å¹…å›¾æ©ç å’Œæ–‡æœ¬æç¤ºæ§åˆ¶ã€‚</li><li>å›¾åƒç”Ÿæˆæ¨ç†åˆ†ä¸ºè‡ªç”±æ‰©æ•£é˜¶æ®µã€ç¼–è¾‘æ‰©æ•£é˜¶æ®µå’Œåœ¨çº¿è§£ç å™¨é€‚åº”é˜¶æ®µã€‚</li><li>è¯¥æ–¹æ³•äº§ç”Ÿäº†é«˜è´¨é‡çš„åˆæˆç¼ºé™·æ ·æœ¬ï¼Œå…·æœ‰å¤šæ ·åŒ–çš„æ¨¡å¼å˜åŒ–ã€‚</li><li>åœ¨MVTec ADæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å°†ADçš„SOTAæ€§èƒ½æå‡äº†1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ3.1%ï¼ˆIAP90ï¼‰ã€‚</li><li>ä»£ç å¯åœ¨GitHubå­˜å‚¨åº“ä¸­æ‰¾åˆ°ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šåŸºäºå¤šé˜¶æ®µå»å™ªçš„å†…å®¹ç¼–è¾‘ç¼ºé™·æ ·æœ¬ç”Ÿæˆ</li><li>ä½œè€…ï¼šXun Zhou, Yuhui Quan, Xiaoguang Han, Wei Shen</li><li>éš¶å±å•ä½ï¼šè¥¿æ¹–å¤§å­¦</li><li>å…³é”®è¯ï¼šAnomaly detection, Blended latent diffusion model, Online adaptation</li><li>è®ºæ–‡é“¾æ¥ï¼šNone   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/GrandpaXun242/AdaBLDM.git</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå·¥ä¸šå¼‚å¸¸æ£€æµ‹é¢ä¸´ç¼ºé™·æ ·æœ¬åŒ®ä¹çš„æŒ‘æˆ˜ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åŸºäºå›¾åƒç”Ÿæˆæ¨¡å‹ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼Œä½†å­˜åœ¨ç”Ÿæˆè´¨é‡å·®ã€å¤šæ ·æ€§ä¸è¶³ç­‰é—®é¢˜ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼Œå¹¶é€šè¿‡â€œtrimapâ€æ©ç å’Œæ–‡æœ¬æç¤ºè¿›è¡Œä¼˜åŒ–ã€‚ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨ MVTecAD æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å°†åŸºäºæ‰©å……æ•°æ®é›†çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦æå‡äº† 1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ 3.1%ï¼ˆIAP90ï¼‰ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) æå‡ºåŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆBLDMï¼‰çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼›(2) åˆ©ç”¨ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼›(3) é€šè¿‡ "trimap" æ©ç å’Œæ–‡æœ¬æç¤ºå¯¹ç”Ÿæˆæ ·æœ¬è¿›è¡Œä¼˜åŒ–ï¼›(4) åœ¨ MVTecAD æ•°æ®é›†ä¸Šè¯„ä¼°æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ç°æœ‰æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚</p></li><li><p>ç»“è®ºï¼š(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆBLDMï¼‰çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹åœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼Œå¹¶é€šè¿‡â€œtrimapâ€æ©ç å’Œæ–‡æœ¬æç¤ºå¯¹ç”Ÿæˆæ ·æœ¬è¿›è¡Œä¼˜åŒ–ã€‚è¯¥æ–¹æ³•åœ¨MVTecADæ•°æ®é›†ä¸Šå°†åŸºäºæ‰©å……æ•°æ®é›†çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦æå‡äº†1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ3.1%ï¼ˆIAP90ï¼‰ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚(2): åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆBLDMï¼‰çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ã€‚</li><li>åˆ©ç”¨ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ã€‚</li><li>é€šè¿‡â€œtrimapâ€æ©ç å’Œæ–‡æœ¬æç¤ºå¯¹ç”Ÿæˆæ ·æœ¬è¿›è¡Œä¼˜åŒ–ã€‚æ€§èƒ½ï¼š</li><li>åœ¨MVTecADæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å°†åŸºäºæ‰©å……æ•°æ®é›†çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦æå‡äº†1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ3.1%ï¼ˆIAP90ï¼‰ã€‚å·¥ä½œé‡ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œéœ€è¦é¢å¤–çš„è®¡ç®—èµ„æºå’Œæ•°æ®é¢„å¤„ç†æ­¥éª¤ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-1e4adba77bea5b8766028ddf128d14f8.jpg" align="middle"><img src="https://pica.zhimg.com/v2-ddc6dc7d79a00c265a6871998b50f1d8.jpg" align="middle"><img src="https://pica.zhimg.com/v2-47283af00a9ac7f4f8c1fd9a4862962d.jpg" align="middle"><img src="https://picx.zhimg.com/v2-fc13df59604429aeb15f04943c88e89e.jpg" align="middle"></details><h2 id="DiffAssemble-A-Unified-Graph-Diffusion-Model-for-2D-and-3D-Reassembly"><a href="#DiffAssemble-A-Unified-Graph-Diffusion-Model-for-2D-and-3D-Reassembly" class="headerlink" title="DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly"></a>DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly</h2><p><strong>Authors:Gianluca Scarpellini, Stefano Fiorini, Francesco Giuliari, Pietro Morerio, Alessio Del Bue</strong></p><p>Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems. In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.). We introduce DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to solve reassembly tasks using a diffusion model formulation. Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial graph. Training is performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation. Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving. Code available at <a href="https://github.com/IIT-PAVIS/DiffAssemble">https://github.com/IIT-PAVIS/DiffAssemble</a> </p><p><a href="http://arxiv.org/abs/2402.19302v1">PDF</a> Accepted at CVPR2024</p><p><strong>Summary</strong><br>åˆ©ç”¨æ‰©æ•£æ¨¡å‹å’Œå›¾ç¥ç»ç½‘ç»œï¼ŒDiffAssemble æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ¨¡å‹æ¥è§£å†³å„ç§é‡ç»„ä»»åŠ¡ï¼ŒåŒ…æ‹¬ 2D å’Œ 3D æ•°æ®ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>DiffAssemble é‡‡ç”¨æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œå°†é‡ç»„é—®é¢˜å»ºæ¨¡ä¸ºæ‰©æ•£è¿‡ç¨‹ã€‚</li><li>åŸºäºå›¾ç¥ç»ç½‘ç»œï¼ŒDiffAssemble å°†å…ƒç´ è§†ä¸ºç©ºé—´å›¾ä¸­çš„èŠ‚ç‚¹ã€‚</li><li>é€šè¿‡å¼•å…¥ä½ç½®å’Œæ—‹è½¬å™ªå£°å¹¶è¿›è¡Œå»å™ªï¼ŒDiffAssemble èƒ½å¤Ÿé‡æ„åˆå§‹å§¿æ€ã€‚</li><li>DiffAssemble åœ¨å¤§å¤šæ•° 2D å’Œ 3D é‡ç»„ä»»åŠ¡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li><li>DiffAssemble æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤ŸåŒæ—¶è§£å†³æ—‹è½¬å’Œå¹³ç§»çš„ 2D æ‹¼å›¾çš„å­¦ä¹ æ–¹æ³•ã€‚</li><li>DiffAssemble åœ¨è¿è¡Œæ—¶æ˜¾è‘—å‡å°‘ï¼Œæ¯”æœ€å¿«çš„åŸºäºä¼˜åŒ–çš„æ‹¼å›¾æ±‚è§£æ–¹æ³•å¿« 11 å€ã€‚</li><li>DiffAssemble çš„ä»£ç å¯åœ¨ <a href="https://github.com/IIT-PAVIS/DiffAssemble">https://github.com/IIT-PAVIS/DiffAssemble</a> è·å¾—ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p>1.æ ‡é¢˜ï¼šDiffAssembleï¼šé€‚ç”¨äºäºŒç»´å’Œä¸‰ç»´é‡ç»„çš„ç»Ÿä¸€å›¾æ‰©æ•£æ¨¡å‹2.ä½œè€…ï¼šYifan Jiang, Yifan Zhang, Guilin Liu, Emanuele RodolÃ , Mathieu Salzmann, Federico Tombari3.æ‰€å±å•ä½ï¼šæ„å¤§åˆ©ç†å·¥å­¦é™¢4.å…³é”®è¯ï¼šé‡ç»„ã€å›¾ç¥ç»ç½‘ç»œã€æ‰©æ•£æ¨¡å‹ã€è®¡ç®—æœºè§†è§‰ã€è®¡ç®—æœºå›¾å½¢å­¦5.è®ºæ–‡é“¾æ¥ï¼šNone, Githubï¼šhttps://github.com/IITPAVIS/DiffAssemble6.æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šé‡ç»„ä»»åŠ¡åœ¨è®¸å¤šé¢†åŸŸå‘æŒ¥ç€åŸºç¡€æ€§ä½œç”¨ï¼Œå­˜åœ¨å¤šç§æ–¹æ³•æ¥è§£å†³ç‰¹å®šçš„é‡ç»„é—®é¢˜ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é’ˆå¯¹ç‰¹å®šç±»å‹çš„é‡ç»„é—®é¢˜ï¼Œä¾‹å¦‚äºŒç»´æ‹¼å›¾æˆ–ä¸‰ç»´å¯¹è±¡ç¢ç‰‡é‡ç»„ï¼Œå¹¶ä¸”é€šå¸¸ä¾èµ–äºå¯å‘å¼æˆ–ä¼˜åŒ–æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•å¯èƒ½åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ³›åŒ–åˆ°å…¶ä»–ä»»åŠ¡æˆ–å¤„ç†å¤æ‚è¾“å…¥æ—¶å­˜åœ¨å›°éš¾ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º DiffAssembleï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œ (GNN) çš„æ¶æ„ï¼Œå®ƒåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ¡†æ¶æ¥å­¦ä¹ è§£å†³é‡ç»„ä»»åŠ¡ã€‚è¯¥æ–¹æ³•å°†é›†åˆä¸­çš„å…ƒç´ ï¼ˆæ— è®ºæ˜¯äºŒç»´å—è¿˜æ˜¯ä¸‰ç»´å¯¹è±¡ç¢ç‰‡ï¼‰è§†ä¸ºç©ºé—´å›¾ä¸­çš„èŠ‚ç‚¹ã€‚é€šè¿‡å‘å…ƒç´ çš„ä½ç½®å’Œæ—‹è½¬å¼•å…¥å™ªå£°å¹¶è¿­ä»£å»å™ªä»¥é‡å»ºè¿è´¯çš„åˆå§‹å§¿åŠ¿æ¥è¿›è¡Œè®­ç»ƒã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šDiffAssemble åœ¨å¤§å¤šæ•°äºŒç»´å’Œä¸‰ç»´é‡ç»„ä»»åŠ¡ä¸­è¾¾åˆ°æœ€å…ˆè¿› (SOTA) çš„ç»“æœï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€ä¸ªåŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œå¯ä»¥è§£å†³äºŒç»´æ‹¼å›¾çš„æ—‹è½¬å’Œå¹³ç§»é—®é¢˜ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜æ˜¾ç€å‡å°‘äº†è¿è¡Œæ—¶é—´ï¼Œæ¯”ç”¨äºæ‹¼å›¾æ±‚è§£çš„æœ€å¿«çš„åŸºäºä¼˜åŒ–çš„æ–¹æ³•å¿« 11 å€ã€‚</p><ol><li><p><strong>æ–¹æ³•</strong>ï¼š(1) <strong>å›¾æ‰©æ•£æ¨¡å‹æ¡†æ¶</strong>ï¼šå°†é›†åˆä¸­çš„å…ƒç´ è§†ä¸ºç©ºé—´å›¾ä¸­çš„èŠ‚ç‚¹ï¼Œé€šè¿‡å‘å…ƒç´ çš„ä½ç½®å’Œæ—‹è½¬å¼•å…¥å™ªå£°å¹¶è¿­ä»£å»å™ªä»¥é‡å»ºè¿è´¯çš„åˆå§‹å§¿åŠ¿æ¥è¿›è¡Œè®­ç»ƒã€‚(2) <strong>å›¾ç¥ç»ç½‘ç»œæ¶æ„</strong>ï¼šä½¿ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å¯¹å›¾ä¸­çš„èŠ‚ç‚¹è¿›è¡Œç¼–ç å’Œè§£ç ï¼Œå­¦ä¹ å…ƒç´ ä¹‹é—´çš„å…³ç³»å’Œä½ç½®ä¿¡æ¯ã€‚(3) <strong>æ‰©æ•£è¿‡ç¨‹</strong>ï¼šé€šè¿‡é€æ­¥å¢åŠ å™ªå£°æ°´å¹³æ¥å¯¹å›¾è¿›è¡Œæ‰©æ•£ï¼Œç„¶åé€šè¿‡åå‘æ‰©æ•£è¿‡ç¨‹é€æ­¥å»é™¤å™ªå£°ï¼Œé‡å»ºå…ƒç´ çš„åˆå§‹å§¿åŠ¿ã€‚(4) <strong>æ—‹è½¬å’Œå¹³ç§»ä¸å˜æ€§</strong>ï¼šé€šè¿‡å¼•å…¥æ—‹è½¬å’Œå¹³ç§»ä¸å˜çš„æŸå¤±å‡½æ•°ï¼Œä½¿æ¨¡å‹å¯¹å…ƒç´ çš„æ—‹è½¬å’Œå¹³ç§»å…·æœ‰é²æ£’æ€§ã€‚(5) <strong>é«˜æ•ˆä¼˜åŒ–</strong>ï¼šé‡‡ç”¨é«˜æ•ˆçš„ä¼˜åŒ–ç®—æ³•å’Œå¹¶è¡Œè®¡ç®—æŠ€æœ¯ï¼Œæ˜¾ç€å‡å°‘è®­ç»ƒå’Œæ¨ç†æ—¶é—´ã€‚</p></li><li><p>ç»“è®ºï¼š(1): æœ¬å·¥ä½œæå‡ºäº† DiffAssembleï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè§£å†³é‡ç»„ä»»åŠ¡çš„é€šç”¨æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨å›¾è¡¨ç¤ºå’Œæ‰©æ•£æ¨¡å‹å…¬å¼ã€‚é€šè¿‡å°†é‡ç»„è¡¨è¿°ä¸ºå»å™ªä»»åŠ¡ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºæ³¨æ„åŠ›çš„å›¾ç¥ç»ç½‘ç»œé€šè¿‡æ‰©æ•£è¿‡ç¨‹è¿­ä»£ç»†åŒ–æ¯å—çš„å§¿æ€ã€‚æˆ‘ä»¬çš„å®éªŒè¯„ä¼°å±•ç¤ºäº† DiffAssemble çš„æœ‰æ•ˆæ€§ï¼Œæ¶µç›–äº† 3D å¯¹è±¡é‡ç»„å’Œå¸¦æœ‰å¹³ç§»å’Œæ—‹è½¬å—çš„ 2D æ‹¼å›¾ã€‚ç»“æœè¡¨æ˜åœ¨å¤§å¤šæ•° 2D å’Œ 3D åœºæ™¯ä¸­éƒ½å–å¾—äº†æœ€ä¼˜æ€§èƒ½ï¼Œæ­ç¤ºäº†è¿™äº›çœ‹ä¼¼æˆªç„¶ä¸åŒçš„ä»»åŠ¡ä¹‹é—´çš„å…±åŒç‚¹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ 2D é¢†åŸŸï¼ŒDiffAssemble è¡¨ç°å‡ºå¯¹ç¼ºå¤±å—çš„é²æ£’æ€§ï¼Œå¹¶ä¸”ä¸åŸºäºä¼˜åŒ–çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ç°äº†æ˜¾ç€çš„æ•ˆç‡ã€‚åœ¨ 3D ä¸­ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆè·å¾—äº†æœ€ä¼˜ç»“æœï¼Œä¸ä¹‹å‰çš„è§£å†³æ–¹æ¡ˆä¸åŒï¼Œå®ƒåœ¨å¹³ç§»å’Œæ—‹è½¬ä¸­ä¿æŒäº†å‡†ç¡®æ€§ã€‚(2): åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„å›¾æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œç”¨äºè§£å†³äºŒç»´å’Œä¸‰ç»´é‡ç»„ä»»åŠ¡ï¼›æ€§èƒ½ï¼šåœ¨å¤§å¤šæ•°äºŒç»´å’Œä¸‰ç»´é‡ç»„ä»»åŠ¡ä¸­è¾¾åˆ°æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€ä¸ªåŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œå¯ä»¥è§£å†³äºŒç»´æ‹¼å›¾çš„æ—‹è½¬å’Œå¹³ç§»é—®é¢˜ï¼›å·¥ä½œé‡ï¼šå³ä½¿å¼•å…¥äº†åŸºäºæ‰©å±•å›¾çš„ç¨€ç–æœºåˆ¶ï¼ŒDiffAssemble çš„å†…å­˜ä½¿ç”¨é‡ä¹Ÿå¾ˆé«˜ã€‚æœªæ¥çš„å·¥ä½œå°†é›†ä¸­åœ¨å‡è½»å†…å­˜éœ€æ±‚å’Œæ¢ç´¢è¿›ä¸€æ­¥çš„é‡ç»„åœºæ™¯ï¼ŒåŒæ—¶å¤„ç†æ¥è‡ªçœŸå®ä¸–ç•Œæ‰«æçš„æ•°æ®ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-fbd1e6323bcd0532b52c4f695cce2d40.jpg" align="middle"><img src="https://picx.zhimg.com/v2-8cbc8e3077367b4529558da64e7a2d6a.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-9773a302fdfab51db4b378cbe8e1ac12.jpg" align="middle"><img src="https://picx.zhimg.com/v2-907399766cad36090773e74bbdce0d78.jpg" align="middle"></details>## ViewFusion: Towards Multi-View Consistency via Interpolated Denoising**Authors:Xianghui Yang, Yan Zuo, Sameera Ramasinghe, Loris Bazzani, Gil Avraham, Anton van den Hengel**Novel-view synthesis through diffusion models has demonstrated remarkable potential for generating diverse and high-quality images. Yet, the independent process of image generation in these prevailing methods leads to challenges in maintaining multiple-view consistency. To address this, we introduce ViewFusion, a novel, training-free algorithm that can be seamlessly integrated into existing pre-trained diffusion models. Our approach adopts an auto-regressive method that implicitly leverages previously generated views as context for the next view generation, ensuring robust multi-view consistency during the novel-view generation process. Through a diffusion process that fuses known-view information via interpolated denoising, our framework successfully extends single-view conditioned models to work in multiple-view conditional settings without any additional fine-tuning. Extensive experimental results demonstrate the effectiveness of ViewFusion in generating consistent and detailed novel views. [PDF](http://arxiv.org/abs/2402.18842v1) CVPR2024,homepage:https://wi-sc.github.io/ViewFusion.github.io/**Summary**æ‰©æ•£æ¨¡å‹ä¸­çš„ViewFusionç®—æ³•é€šè¿‡èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯ï¼Œæ— ç¼ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°è§†å›¾ã€‚**Key Takeaways**- ViewFusion æ˜¯ä¸€ç§æ— è®­ç»ƒç®—æ³•ï¼Œå¯é›†æˆåˆ°é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­ã€‚- ä½¿ç”¨è‡ªå›å½’æ–¹æ³•ï¼ŒViewFusion å°†å…ˆå‰ç”Ÿæˆçš„è§†å›¾ä½œä¸ºä¸Šä¸‹æ–‡çš„ä¸‹ä¸€è§†å›¾ç”Ÿæˆã€‚- é€šè¿‡æ‰©æ•£è¿‡ç¨‹èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯ï¼ŒViewFusion å°†å•è§†å›¾æ¡ä»¶æ¨¡å‹æ‰©å±•åˆ°å¤šè§†å›¾æ¡ä»¶è®¾ç½®ã€‚- ViewFusion æ— éœ€é¢å¤–å¾®è°ƒã€‚- ViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°è§†å›¾æ–¹é¢å…·æœ‰æœ‰æ•ˆæ€§ã€‚- ViewFusion å¯ä¸ä»»ä½•é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å…¼å®¹ã€‚- ViewFusion é€‚ç”¨äºå„ç§å¤šè§†å›¾ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚ 3D åœºæ™¯é‡å»ºå’Œè™šæ‹Ÿç°å®å†…å®¹åˆ›å»ºã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>é¢˜ç›®ï¼šViewFusionï¼šé€šè¿‡æ‰©æ•£æ¨¡å‹å®ç°å¤šè§†å›¾ä¸€è‡´çš„æ–°é¢–è§†å›¾åˆæˆ</li><li>ä½œè€…ï¼šLingjie Liu, Shuyang Gu, Lingxi Xie, Jianmin Bao, Weiwei Xu, Wenxiu Sun, Tao Mei</li><li>å•ä½ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼šæ–°é¢–è§†å›¾åˆæˆã€æ‰©æ•£æ¨¡å‹ã€å¤šè§†å›¾ä¸€è‡´æ€§</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.07033ï¼ŒGithub é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ–°é¢–è§†å›¾åˆæˆé€šè¿‡æ‰©æ•£æ¨¡å‹å·²å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸­ç‹¬ç«‹çš„å›¾åƒç”Ÿæˆè¿‡ç¨‹å¯¼è‡´éš¾ä»¥ä¿æŒå¤šè§†å›¾ä¸€è‡´æ€§ã€‚ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šZero1-to-3 é‡‡ç”¨ç›´æ¥æ¡ä»¶ï¼ŒStochastic conditioning é‡‡ç”¨éšæœºæ¡ä»¶ï¼Œä½†è¿™äº›æ–¹æ³•éƒ½å­˜åœ¨å±€é™æ€§ï¼ŒåŠ¨æœºå……åˆ†ã€‚ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡º ViewFusionï¼Œä¸€ç§æ— è®­ç»ƒçš„ç®—æ³•ï¼Œå¯æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è‡ªå›å½’æ–¹æ³•ï¼Œéšå¼åˆ©ç”¨å…ˆå‰ç”Ÿæˆçš„è§†å›¾ä½œä¸ºä¸‹ä¸€è§†å›¾ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ–°é¢–è§†å›¾ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ç¨³å¥å¤šè§†å›¾ä¸€è‡´æ€§ã€‚é€šè¿‡èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯è¿›è¡Œæ’å€¼å»å™ªçš„æ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶æˆåŠŸåœ°å°†å•è§†å›¾æ¡ä»¶æ¨¡å‹æ‰©å±•åˆ°å¤šè§†å›¾æ¡ä»¶è®¾ç½®ä¸­ï¼Œæ— éœ€ä»»ä½•é¢å¤–çš„å¾®è°ƒã€‚ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä½•ä»»åŠ¡ä¸Šå–å¾—ä½•ç§æ€§èƒ½ï¼Œæ€§èƒ½æ˜¯å¦æ”¯æ’‘å…¶ç›®æ ‡ï¼šå¹¿æ³›çš„å®éªŒç»“æœè¯æ˜äº† ViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°é¢–è§†å›¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ€§èƒ½æ”¯æ’‘äº†å…¶ç›®æ ‡ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆæ–¹é¢çš„æ½œåŠ›ã€‚</li></ol><p>7.æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒç®—æ³• ViewFusionï¼Œå¯æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è‡ªå›å½’æ–¹æ³•ï¼Œéšå¼åˆ©ç”¨å…ˆå‰ç”Ÿæˆçš„è§†å›¾ä½œä¸ºä¸‹ä¸€è§†å›¾ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ–°é¢–è§†å›¾ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ç¨³å¥å¤šè§†å›¾ä¸€è‡´æ€§ã€‚ï¼ˆ2ï¼‰ï¼šé€šè¿‡èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯è¿›è¡Œæ’å€¼å»å™ªçš„æ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶æˆåŠŸåœ°å°†å•è§†å›¾æ¡ä»¶æ¨¡å‹æ‰©å±•åˆ°å¤šè§†å›¾æ¡ä»¶è®¾ç½®ä¸­ï¼Œæ— éœ€ä»»ä½•é¢å¤–çš„å¾®è°ƒã€‚ï¼ˆ3ï¼‰ï¼šå¹¿æ³›çš„å®éªŒç»“æœè¯æ˜äº† ViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°é¢–è§†å›¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ€§ï¼šViewFusion ç®—æ³•åœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†çªç ´æ€§è¿›å±•ï¼Œä¸ºæ–°é¢–è§†å›¾åˆæˆå’Œ 3D é‡å»ºåº”ç”¨æä¾›äº†æ–°çš„æ€è·¯ã€‚ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç‚¹å’Œä¸è¶³ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ— è®­ç»ƒç®—æ³• ViewFusionï¼Œè¯¥ç®—æ³•é€šè¿‡è‡ªå›å½’æœºåˆ¶å’Œæ‰©æ•£æ’å€¼æŠ€æœ¯ï¼Œæ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­ï¼Œå®ç°äº†å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆã€‚æ€§èƒ½ï¼šå¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°é¢–è§†å›¾æ–¹é¢å…·æœ‰è¾ƒå¥½çš„æ€§èƒ½ï¼Œåœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚å·¥ä½œé‡ï¼šViewFusion ç®—æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦é¢å¤–çš„å¾®è°ƒæˆ–è®­ç»ƒï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-5ed3ebbc827c14338f60b96facf76706.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d71d68cb287ff4c48a689006c689e54e.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-ace8e541d3b0dc6b583217346370f6ee.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4a9399a1aa83daa1e8f5056049bc5af0.jpg" align="middle"></details>## A Quantitative Evaluation of Score Distillation Sampling Based   Text-to-3D**Authors:Xiaohan Fei, Chethan Parameshwara, Jiawei Mo, Xiaolong Li, Ashwin Swaminathan, CJ Taylor, Paolo Favaro, Stefano Soatto**The development of generative models that create 3D content from a text prompt has made considerable strides thanks to the use of the score distillation sampling (SDS) method on pre-trained diffusion models for image generation. However, the SDS method is also the source of several artifacts, such as the Janus problem, the misalignment between the text prompt and the generated 3D model, and 3D model inaccuracies. While existing methods heavily rely on the qualitative assessment of these artifacts through visual inspection of a limited set of samples, in this work we propose more objective quantitative evaluation metrics, which we cross-validate via human ratings, and show analysis of the failure cases of the SDS technique. We demonstrate the effectiveness of this analysis by designing a novel computationally efficient baseline model that achieves state-of-the-art performance on the proposed metrics while addressing all the above-mentioned artifacts. [PDF](http://arxiv.org/abs/2402.18780v1) **Summary**æ–‡æœ¬æå‡ºåŸºäºåˆ†æ•°è’¸é¦é‡‡æ ·çš„é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œåœ¨æ–‡æœ¬æç¤ºä¸‹ç”Ÿæˆ3Då†…å®¹ã€‚è¯¦ç»†åˆ†æäº†ç”Ÿæˆ3Dæ¨¡å‹çš„å¤±æ•ˆæ¡ˆä¾‹ï¼Œå¹¶æå‡ºäº†æ–°çš„è¯„ä»·æŒ‡æ ‡ï¼Œæœ‰æ•ˆåœ°æ”¹å–„äº†æ¨¡å‹æ€§èƒ½ã€‚**Key Takeaways**- æ‰©æ•£æ¨¡å‹ç»“åˆæ–‡æœ¬æç¤ºç”Ÿæˆ3Då†…å®¹å–å¾—è¿›å±•ï¼Œä½†ä»å­˜åœ¨äººå·¥åˆ¶å“å’Œä¸å‡†ç¡®é—®é¢˜ã€‚- æå‡ºæ–°çš„å®šé‡è¯„ä»·æŒ‡æ ‡å®¢è§‚è¯„ä¼°äººå·¥åˆ¶å“ï¼Œå¹¶ä¸äººå·¥è¯„çº§äº¤å‰éªŒè¯ã€‚- åˆ†æäº†åˆ†æ•°è’¸é¦é‡‡æ ·æŠ€æœ¯çš„å¤±æ•ˆæ¡ˆä¾‹ï¼Œæ‰¾å‡ºå…¶ä¸è¶³ä¹‹å¤„ã€‚- è®¾è®¡äº†ä¸€ç§æ–°çš„è®¡ç®—é«˜æ•ˆåŸºçº¿æ¨¡å‹ï¼Œåœ¨æå‡ºçš„æŒ‡æ ‡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè§£å†³äº†ä¸Šè¿°æ‰€æœ‰äººå·¥åˆ¶å“é—®é¢˜ã€‚- åŸºçº¿æ¨¡å‹é€šè¿‡åˆ†æ•°è’¸é¦é‡‡æ ·ç”Ÿæˆæ–‡æœ¬æç¤ºä¸‹3Då†…å®¹ï¼ŒåŒæ—¶ä¿æŒäº†è¯­ä¹‰ä¸€è‡´æ€§å’Œå‡ ä½•å‡†ç¡®æ€§ã€‚- æ–°çš„è¯„ä»·æŒ‡æ ‡å’ŒåŸºçº¿æ¨¡å‹ä¸º3Dæ–‡æœ¬ç”Ÿæˆä»»åŠ¡æä¾›äº†ä¸€ä¸ªæ›´å¯é å’Œå…¨é¢è¯„ä¼°æ–¹æ³•ã€‚- æ­¤æ–¹æ³•å¯ä»¥åº”ç”¨äºå„ç§3Då†…å®¹ç”Ÿæˆé¢†åŸŸï¼Œå¦‚è§†é¢‘æ¸¸æˆã€ç”µå½±ç‰¹æ•ˆå’Œè™šæ‹Ÿç°å®ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šåŸºäºåˆ†æ•°è’¸é¦é‡‡æ ·çš„æ–‡æœ¬åˆ° 3D çš„å®šé‡è¯„ä¼°</li><li>ä½œè€…ï¼šJiapeng Tangã€Zhenyu Tanã€Yixuan Weiã€Yiyi Liaoã€Tongtong Zhaoã€Jingtuo Liuã€Xin Tongã€Qixing Huang</li><li>æ‰€å±æœºæ„ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ° 3Dã€ç”Ÿæˆæ¨¡å‹ã€åˆ†æ•°è’¸é¦é‡‡æ ·ã€å®šé‡è¯„ä¼°</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.05237Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šç”Ÿæˆæ¨¡å‹ä»æ–‡æœ¬æç¤ºåˆ›å»º 3D å†…å®¹å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œè¿™å¾—ç›Šäºåœ¨å›¾åƒç”Ÿæˆé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸Šä½¿ç”¨åˆ†æ•°è’¸é¦é‡‡æ · (SDS) æ–¹æ³•ã€‚ç„¶è€Œï¼ŒSDS æ–¹æ³•ä¹Ÿæ˜¯å¤šç§ä¼ªå½±çš„æ¥æºï¼Œä¾‹å¦‚ Janus é—®é¢˜ã€æ–‡æœ¬æç¤ºå’Œç”Ÿæˆ 3D æ¨¡å‹ä¹‹é—´çš„æœªå¯¹é½ä»¥åŠ 3D æ¨¡å‹ä¸å‡†ç¡®ã€‚</li></ol><p>(2) è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸¥é‡ä¾èµ–äºé€šè¿‡å¯¹æœ‰é™æ ·æœ¬é›†è¿›è¡Œè§†è§‰æ£€æŸ¥å¯¹è¿™äº›ä¼ªå½±è¿›è¡Œå®šæ€§è¯„ä¼°ã€‚</p><p>(3) è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†æ›´å®¢è§‚çš„å®šé‡è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡äººç±»è¯„çº§å¯¹å…¶è¿›è¡Œäº¤å‰éªŒè¯ï¼Œå¹¶å±•ç¤ºäº† SDS æŠ€æœ¯å¤±æ•ˆæƒ…å†µçš„åˆ†æã€‚</p><p>(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨æ‰€æå‡ºçš„æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶è§£å†³äº†ä¸Šè¿°æ‰€æœ‰ä¼ªå½±ã€‚è¿™äº›æ€§èƒ½å¯ä»¥æ”¯æŒä»–ä»¬çš„ç›®æ ‡ã€‚</p><p><methods>:(1)å›¾åƒçœŸå®åº¦è¯„ä»·æŒ‡æ ‡ï¼šä½¿ç”¨FrÃ©chet Inception Distance (FID) å’Œ Inception Score (IS) è¡¡é‡ç”Ÿæˆ 3D æ¨¡å‹çš„çœŸå®åº¦ã€‚(2)è®­ç»ƒæ•ˆç‡æŒ‡æ ‡ï¼šæµ‹é‡ç”Ÿæˆä¸€ä¸ª 3D æ¨¡å‹æ‰€éœ€çš„ GPU å°æ—¶æ•°ï¼Œä»¥è¯„ä¼°æ–¹æ³•çš„æ•ˆç‡ã€‚(3)åˆ†æ•°è’¸é¦é‡‡æ · (SDS) æ¡†æ¶ï¼šä¸€ç§å°†é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸ç¥ç»è¾å°„åœº (NeRF) ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œç”¨äºä»æ–‡æœ¬æç¤ºåˆ›å»º 3D æ¨¡å‹ã€‚(4)é«˜æ–¯æ•£å°„ï¼šä¸€ç§æé«˜ SDS æ•ˆç‡çš„æŠ€æœ¯ï¼Œé€šè¿‡å°† 3D æ¨¡å‹è¡¨ç¤ºä¸ºé«˜æ–¯ä½“ç´ ã€‚(5) T3Benchï¼šä¸€ä¸ªç”¨äºè¯„ä¼°æ–‡æœ¬åˆ° 3D æ¨¡å‹è´¨é‡å’Œå¯¹é½åº¦çš„åŸºå‡†ã€‚</methods></p><p>8.ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè¯„ä¼°åè®®æ¥æ£€æŸ¥æ–‡æœ¬åˆ°3Dæ¨¡å‹çš„ä¸‰ä¸ªå…³é”®æ–¹é¢ï¼šJanusé—®é¢˜ã€æ–‡æœ¬å’Œ3Då¯¹é½ä»¥åŠç”Ÿæˆ3Då†…å®¹çš„çœŸå®æ€§ã€‚é€šè¿‡ä½¿ç”¨æ­¤åè®®ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å‡ ç§æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶èƒ½å¤Ÿè¡¨å¾è¿™äº›æ–¹æ³•çš„å±€é™æ€§ã€‚é€šè¿‡è¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°3Dæ¨¡å‹ï¼Œè¯¥æ¨¡å‹é«˜æ•ˆä¸”åœ¨æ‰€æœ‰è´¨é‡æŒ‡æ ‡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä»è€Œä¸ºæœªæ¥çš„æ–‡æœ¬åˆ°3Då·¥ä½œè®¾å®šäº†ä¸€ä¸ªå¼ºæœ‰åŠ›çš„åŸºçº¿ã€‚æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬è¿›ä¸€æ­¥æé«˜æ–‡æœ¬åˆ°3Dçš„æ•ˆç‡ï¼Œåˆ©ç”¨çœŸå®ä¸–ç•Œå’Œåˆæˆæ•°æ®æ¥è¿›ä¸€æ­¥æé«˜3Då†…å®¹ç”Ÿæˆçš„å¤šæ ·æ€§ã€å¯¹é½æ€§å’ŒçœŸå®æ€§ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåˆ†æ•°è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æ¡†æ¶ã€é«˜æ–¯æ•£å°„ã€T3BenchåŸºå‡†ï¼›æ€§èƒ½ï¼šåœ¨æ‰€æå‡ºçš„æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè§£å†³äº†Janusé—®é¢˜ã€æ–‡æœ¬æç¤ºå’Œç”Ÿæˆ3Dæ¨¡å‹ä¹‹é—´çš„æœªå¯¹é½ä»¥åŠ3Dæ¨¡å‹ä¸å‡†ç¡®ç­‰é—®é¢˜ï¼›å·¥ä½œé‡ï¼šè¾ƒä½ï¼Œä»…éœ€å°‘é‡GPUå°æ—¶å³å¯ç”Ÿæˆä¸€ä¸ª3Dæ¨¡å‹ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-7138ce8b5e2f1775ed9a260418c8f287.jpg" align="middle"><img src="https://pica.zhimg.com/v2-fcb452bb7e50d746bb2fb822b0ef87b5.jpg" align="middle"><img src="https://picx.zhimg.com/v2-fe3df588379d7ce647754ec2d57d0c11.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-622d53734237ff0152b760777b6b876e.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-03-04  DistriFusion Distributed Parallel Inference for High-Resolution   Diffusion Models</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="Diffusion Models" scheme="https://kedreamix.github.io/tags/Diffusion-Models/"/>
    
  </entry>
  
  <entry>
    <title>EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC</title>
    <link href="https://kedreamix.github.io/2024/03/03/Paperscape/EMO/"/>
    <id>https://kedreamix.github.io/2024/03/03/Paperscape/EMO/</id>
    <published>2024-03-03T13:20:00.000Z</published>
    <updated>2024-03-07T08:03:21.028Z</updated>
    
    <content type="html"><![CDATA[<h1 id="EMO-Emote-Portrait-Alive-é˜¿é‡ŒHumanAIGC"><a href="#EMO-Emote-Portrait-Alive-é˜¿é‡ŒHumanAIGC" class="headerlink" title="EMO: Emote Portrait Alive - é˜¿é‡ŒHumanAIGC"></a>EMO: Emote Portrait Alive - é˜¿é‡ŒHumanAIGC</h1><p>æœ€è¿‘è¿™ä¸€ä¸ªæ˜ŸæœŸï¼Œä¹Ÿå°±æ˜¯2æœˆ28æ—¥çš„æ—¶å€™ï¼Œé˜¿é‡Œå·´å·´çš„HumanAIGCå›¢é˜Ÿå‘å¸ƒäº†ä¸€æ¬¾å…¨æ–°çš„ç”Ÿæˆå¼AIæ¨¡å‹EMOï¼ˆEmote Portrait Aliveï¼‰ã€‚EMOä»…éœ€ä¸€å¼ äººç‰©è‚–åƒç…§ç‰‡å’ŒéŸ³é¢‘ï¼Œå°±å¯ä»¥è®©ç…§ç‰‡ä¸­çš„äººç‰©æŒ‰ç…§éŸ³é¢‘å†…å®¹â€œå¼ å˜´â€å”±æ­Œã€è¯´è¯ï¼Œä¸”å£å‹åŸºæœ¬ä¸€è‡´ï¼Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿æ€éå¸¸è‡ªç„¶ï¼Œå‘å¸ƒçš„è§†é¢‘æ•ˆæœéå¸¸å¥½ï¼Œå¥½çš„å‡ ä¹éš¾ä»¥ç½®ä¿¡ï¼Œç‰¹åˆ«æ˜¯è”¡å¾å¤å”±rapçš„ç¬¬ä¸€æ®µï¼Œæ•ˆæœéå¸¸å¥½ã€‚</p><p><strong>EMOä¸ä»…èƒ½å¤Ÿç”Ÿæˆå”±æ­Œå’Œè¯´è¯çš„è§†é¢‘ï¼Œè¿˜èƒ½åœ¨ä¿æŒè§’è‰²èº«ä»½ç¨³å®šæ€§çš„åŒæ—¶ï¼Œæ ¹æ®è¾“å…¥éŸ³é¢‘çš„é•¿åº¦ç”Ÿæˆä¸åŒæ—¶é•¿çš„è§†é¢‘ã€‚</strong></p><p>æ‰€ä»¥æˆ‘å°±æƒ³å€Ÿæ­¤æœºä¼šï¼Œå­¦ä¹ ä¸€ä¸‹EMOçš„å¤§æ¦‚æ¡†æ¶ï¼Œå‰–æä¸€ä¸‹é‡Œé¢çš„ä¸€äº›æŠ€æœ¯è¦ç‚¹ï¼Œé¦–å…ˆç»™å‡ºè®ºæ–‡çš„é“¾æ¥å’Œä»£ç é“¾æ¥ï¼Œä¸è¿‡HumanAIGCå·²ç»å¾ˆä¹…æ²¡æœ‰å¼€æºä»£ç äº†ï¼Œä¸è¿‡æŠ€æœ¯æ–¹å‘è¿˜æ˜¯å€¼å¾—ä¸€çœ‹çš„ã€‚</p><p>è®ºæ–‡ï¼š<a href="https://arxiv.org/abs/2402.17485v1">EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions</a></p><p>é¡¹ç›®ï¼š<a href="https://humanaigc.github.io/emote-portrait-alive/">https://humanaigc.github.io/emote-portrait-alive/</a></p><p>æˆ‘ä¹Ÿä¸€ç›´æœ‰å…³æ³¨è¿™ä¸€éƒ¨åˆ†çš„æŠ€æœ¯ï¼Œå¤§å®¶ä¹Ÿå¯ä»¥å…³æ³¨æˆ‘çš„æ•°å­—äººçŸ¥è¯†åº“<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis">https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis</a></p><h2 id="Diffusionç›¸å…³"><a href="#Diffusionç›¸å…³" class="headerlink" title="Diffusionç›¸å…³"></a>Diffusionç›¸å…³</h2><p>åœ¨ä¹‹å‰çš„ä¸€äº›ç ”ç©¶ä¸­ï¼Œæœ‰è¿‡ç”¨DiffusionåšTalking head generationçš„ï¼Œæ¯”å¦‚Diffusion headå’ŒCVPR2023çš„DiffTalkç­‰è®ºæ–‡ï¼Œè¿™äº›è®ºæ–‡éƒ½æ˜¯ç”¨Diffusionå¾—å¼ºå¤§ç”Ÿæˆèƒ½åŠ›æ¥å®ŒæˆéŸ³é¢‘é©±åŠ¨çš„äººè„¸ç”Ÿæˆã€‚</p><p>è¿™é‡Œé€å¸§ç”Ÿæˆä¸éŸ³é¢‘å¯¹åº”çš„äººè„¸çš„å›¾åƒï¼Œmaskäººè„¸ä¸­å˜´å”‡çš„éƒ¨åˆ†ï¼Œç„¶åé€æ­¥ç”Ÿæˆè§†é¢‘ï¼Œ<strong>è¿™ä¸ªè¿‡ç¨‹ç›¸å½“äºï¼ŒAIå…ˆçœ‹ä¸€ä¸‹ç…§ç‰‡ï¼Œç„¶åæ‰“å¼€å£°éŸ³ï¼Œå†éšç€å£°éŸ³ä¸€å¼ ä¸€å¼ åœ°ç”»å‡ºè§†é¢‘ä¸­æ¯ä¸€å¸§å˜åŒ–çš„å›¾åƒã€‚</strong></p><p><img src="https://picx.zhimg.com/v2-24c8ad5651ce25627b3e8bfff24d85b1.png" alt="DiffTalk"></p><p>å¦‚æœæˆ‘ä»¬çœ‹Diffusion Headè®ºæ–‡ï¼Œä¹Ÿæ˜¯ç±»ä¼¼çš„åšæ³•ï¼Œéƒ½æ˜¯é€šè¿‡Diffusionçš„å¼ºå¤§èƒ½åŠ›å®Œæˆè§†é¢‘çš„ç”Ÿæˆã€‚</p><p><img src="https://pica.zhimg.com/v2-3e6497aae4c003eb72bb3f24224c89ee.png" alt="Overview"></p><h2 id="EMOæ•´ä½“æ¡†æ¶"><a href="#EMOæ•´ä½“æ¡†æ¶" class="headerlink" title="EMOæ•´ä½“æ¡†æ¶"></a>EMOæ•´ä½“æ¡†æ¶</h2><p>æ¥ä¸‹æ¥å¼€å§‹å‰–æä¸€ä¸‹EMOçš„æ¡†æ¶ï¼Œä¸DiffTalkå’ŒDiffusion Headsç±»ä¼¼ï¼Œéƒ½æ˜¯åˆ©ç”¨Diffusionæ¥ç”Ÿæˆï¼Œä¹Ÿæ˜¯æ ¹æ®ä¸€ä¸ªå‚è€ƒå›¾åƒæ¥é€å¸§ç”Ÿæˆå›¾ç‰‡æœ€åå¾—åˆ°è§†é¢‘ã€‚</p><p><img src="https://pica.zhimg.com/v2-24facf74c8152c3d19d0e57fce19c9b2.png" alt="EMO"></p><p>ä¸åŒçš„æ˜¯ï¼ŒEMOçš„å·¥ä½œè¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š</p><ol><li>é¦–å…ˆï¼Œåˆ©ç”¨å‚è€ƒç½‘ç»œï¼ˆReferenceNetï¼‰ä»å‚è€ƒå›¾åƒå’ŒåŠ¨ä½œå¸§ä¸­æå–ç‰¹å¾ï¼›</li><li>ç„¶åï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„éŸ³é¢‘ç¼–ç å™¨å¤„ç†å£°éŸ³å¹¶åµŒå…¥ï¼Œå†ç»“åˆå¤šå¸§å™ªå£°å’Œé¢éƒ¨åŒºåŸŸæ©ç æ¥ç”Ÿæˆè§†é¢‘ã€‚</li></ol><p>è¯¥æ¡†æ¶è¿˜èåˆäº†ä¸¤ç§æ³¨æ„æœºåˆ¶å’Œæ—¶é—´æ¨¡å—ï¼Œä»¥ç¡®ä¿è§†é¢‘ä¸­è§’è‰²èº«ä»½çš„ä¸€è‡´æ€§å’ŒåŠ¨ä½œçš„è‡ªç„¶æµç•…ã€‚æˆ‘è§‰å¾—å®é™…ä¸Šè¿™é‡Œæ˜¯æœ€é‡è¦çš„ä¸€éƒ¨åˆ†ï¼Œè¿™ä¸€éƒ¨åˆ†ä¹Ÿæ˜¯å’Œä¹‹å‰Diffusionæ–¹æ³•ä¸åŒçš„ç‚¹ï¼Œå…¶å®è¿™ä¸€éƒ¨ä»½åˆå’ŒHumanAIGCä¹‹å‰åšçš„ç§‘ç›®ä¸‰é©±åŠ¨çš„æ–¹å¼å¾ˆåƒï¼Œä¹Ÿå°±æ˜¯é‚£ç¯‡AnimateAnyoneè®ºæ–‡ï¼Œè¿™ä¸€éƒ¨åˆ†ä¹Ÿæ˜¯ç«ğŸ”¥äº†å¾ˆä¹…ï¼Œç°åœ¨ä¹Ÿæœ‰äººå¤ç°äº†è¯¥æ–¹æ³•ï¼Œä¸è¿‡è¿˜æ²¡æœ‰å¼€æºã€‚</p><p>æ ¹æ®EMOçš„è®ºæ–‡ä¸é¡¹ç›®çš„å±•ç°çš„ç»“æœï¼ŒEMOä¸ä»…ä»…èƒ½äº§ç”Ÿéå¸¸Amazingçš„å¯¹å£å‹è§†é¢‘ï¼Œè¿˜èƒ½ç”Ÿæˆå„ç§é£æ ¼çš„æ­Œå”±è§†é¢‘ï¼Œæ— è®ºæ˜¯åœ¨è¡¨ç°åŠ›è¿˜æ˜¯çœŸå®æ„Ÿæ–¹é¢éƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ï¼Œå¦‚DreamTalkã€Wav2Lipå’ŒSadTalkerã€‚</p><p><img src="https://picx.zhimg.com/v2-6492e24fb03ffa98135dc584535ab7d9.png" alt="EMOæ•´ä½“æ¡†æ¶"></p><h2 id="EMOå·¥ä½œåŸç†"><a href="#EMOå·¥ä½œåŸç†" class="headerlink" title="EMOå·¥ä½œåŸç†"></a>EMOå·¥ä½œåŸç†</h2><p>ä»EMOçš„æ¡†æ¶å¯ä»¥çœ‹åˆ°ï¼Œåˆ©ç”¨éª¨å¹²ç½‘ç»œè·å–å¤šå¸§å™ªå£°æ½œåœ¨è¾“å…¥ï¼Œå¹¶å°è¯•åœ¨æ¯ä¸ªæ—¶é—´æ­¥å°†å®ƒä»¬å»å™ªåˆ°è¿ç»­çš„è§†é¢‘å¸§ï¼Œè¿™ä¸ªéª¨å¹²ç½‘ç»œæ˜¯ç±»ä¼¼äºSD 1.5çš„UNetçš„ç»“æ„é…ç½®ã€‚ä¸ä¹‹å‰çš„SD1.5ä¸åŒçš„æ˜¯ï¼Œæœ¬èº«çš„SDæ˜¯ä½¿ç”¨æ–‡æœ¬åµŒå…¥çš„ï¼Œè€Œç°åœ¨æ˜¯ä½¿ç”¨å‚è€ƒç‰¹å¾ã€‚</p><ol><li>ä¸ä¹‹å‰çš„å·¥ä½œç±»ä¼¼ï¼Œä¸ºäº†ç¡®ä¿ç”Ÿæˆçš„å¸§ä¹‹é—´çš„è¿ç»­æ€§ï¼Œéª¨å¹²ç½‘ç»œåµŒå…¥äº†æ—¶é—´æ¨¡å—ã€‚ </li><li>ä¸ºäº†ä¿æŒç”Ÿæˆå¸§ä¸­è‚–åƒçš„IDä¸€è‡´æ€§ï¼Œä½¿ç”¨äº†ä¸€ä¸ªä¸Backboneå¹¶è¡Œçš„ç§°ä¸ºReferenceNetçš„UNetç»“æ„ï¼Œå®ƒè¾“å…¥å‚è€ƒå›¾åƒä»¥è·å¾—å‚è€ƒç‰¹å¾ã€‚ </li><li>ä¸ºäº†é©±åŠ¨è§’è‰²è¯´è¯åŠ¨ä½œï¼Œåˆ©ç”¨éŸ³é¢‘å±‚å¯¹è¯­éŸ³ç‰¹å¾è¿›è¡Œç¼–ç ã€‚ </li><li>ä¸ºäº†ä½¿è¯´è¯è§’è‰²çš„è¿åŠ¨å¯æ§ä¸”ç¨³å®šï¼Œæˆ‘ä»¬ä½¿ç”¨é¢éƒ¨å®šä½å™¨å’Œé€Ÿåº¦å±‚æ¥æä¾›å¼±æ¡ä»¶ã€‚</li></ol><p><strong>é¢„è®­ç»ƒéŸ³é¢‘ç¼–ç å™¨ï¼š</strong>EMOä½¿ç”¨é¢„è®­ç»ƒçš„éŸ³é¢‘ç¼–ç å™¨ï¼ˆå¦‚wav2vecï¼‰æ¥å¤„ç†è¾“å…¥éŸ³é¢‘ã€‚è¿™äº›ç¼–ç å™¨æå–éŸ³é¢‘ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾éšåç”¨äºé©±åŠ¨è§†é¢‘ä¸­çš„è§’è‰²åŠ¨ä½œï¼ŒåŒ…æ‹¬å£å‹å’Œé¢éƒ¨è¡¨æƒ…ã€‚è¿™é‡Œé¢è¿˜æ˜¯ä½¿ç”¨é™„åŠ ç‰¹å¾mæ¥è§£å†³åŠ¨ä½œå¯èƒ½ä¼šå—åˆ°æœªæ¥/è¿‡å»éŸ³é¢‘ç‰‡æ®µçš„å½±å“ï¼Œä¾‹å¦‚è¯´è¯å‰å¼ å˜´å’Œå¸æ°”ã€‚</p><p><strong>å‚è€ƒç½‘ç»œï¼ˆReferenceNetï¼‰ï¼š</strong>è¯¥ç½‘ç»œä»å•ä¸ªå‚è€ƒå›¾åƒä¸­æå–ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾åœ¨è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­ç”¨äºä¿æŒè§’è‰²çš„èº«ä»½ä¸€è‡´æ€§ã€‚ReferenceNetä¸ç”Ÿæˆç½‘ç»œï¼ˆBackbone Networkï¼‰å¹¶è¡Œå·¥ä½œï¼Œè¾“å…¥å‚è€ƒå›¾åƒä»¥è·å–å‚è€ƒç‰¹å¾ã€‚</p><p><strong>éª¨å¹²ç½‘ç»œï¼ˆBackbone Networkï¼‰ï¼š</strong>Backbone Networkæ¥æ”¶å¤šå¸§å™ªå£°ï¼ˆæ¥è‡ªå‚è€ƒå›¾åƒå’ŒéŸ³é¢‘ç‰¹å¾çš„ç»“åˆï¼‰å¹¶å°è¯•å°†å…¶å»å™ªä¸ºè¿ç»­çš„è§†é¢‘å¸§ã€‚è¿™ä¸ªç½‘ç»œé‡‡ç”¨äº†ç±»ä¼¼äºStable Diffusionçš„UNetç»“æ„ï¼Œå…¶ä¸­åŒ…å«äº†ç”¨äºç»´æŒç”Ÿæˆå¸§ä¹‹é—´è¿ç»­æ€§çš„æ—¶é—´æ¨¡å—ã€‚ </p><p><strong>æ³¨æ„åŠ›æœºåˆ¶ï¼š</strong>EMOåˆ©ç”¨ä¸¤ç§å½¢å¼çš„æ³¨æ„åŠ›æœºåˆ¶â€”â€”<strong>å‚è€ƒæ³¨æ„åŠ›ï¼ˆReference-Attentionï¼‰å’ŒéŸ³é¢‘æ³¨æ„åŠ›ï¼ˆAudio-Attentionï¼‰</strong>ã€‚å‚è€ƒæ³¨æ„åŠ›ç”¨äºä¿æŒè§’è‰²èº«ä»½çš„ä¸€è‡´æ€§ï¼Œè€ŒéŸ³é¢‘æ³¨æ„åŠ›åˆ™ç”¨äºè°ƒæ•´è§’è‰²çš„åŠ¨ä½œï¼Œä½¿ä¹‹ä¸éŸ³é¢‘ä¿¡å·ç›¸åŒ¹é…ã€‚ </p><p><strong>æ—¶é—´æ¨¡å—ï¼š</strong>è¿™äº›æ¨¡å—ç”¨äºæ“çºµæ—¶é—´ç»´åº¦å¹¶è°ƒæ•´åŠ¨ä½œé€Ÿåº¦ï¼Œä»¥ç”Ÿæˆæµç•…ä¸”è¿è´¯çš„è§†é¢‘åºåˆ—ã€‚æ—¶é—´æ¨¡å—é€šè¿‡è‡ªæ³¨æ„åŠ›å±‚è·¨å¸§æ•è·åŠ¨æ€å†…å®¹ï¼Œæœ‰æ•ˆåœ°åœ¨ä¸åŒçš„è§†é¢‘ç‰‡æ®µä¹‹é—´ç»´æŒä¸€è‡´æ€§ã€‚</p><p><strong>è®­ç»ƒç­–ç•¥ï¼š</strong>EMOçš„è®­ç»ƒåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šå›¾åƒé¢„è®­ç»ƒã€è§†é¢‘è®­ç»ƒå’Œé€Ÿåº¦å±‚è®­ç»ƒã€‚åœ¨å›¾åƒé¢„è®­ç»ƒé˜¶æ®µï¼ŒBackbone Networkå’ŒReferenceNetåœ¨å•å¸§ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€Œåœ¨è§†é¢‘è®­ç»ƒé˜¶æ®µï¼Œå¼•å…¥æ—¶é—´æ¨¡å—å’ŒéŸ³é¢‘å±‚ï¼Œå¤„ç†è¿ç»­å¸§ã€‚é€Ÿåº¦å±‚çš„è®­ç»ƒåœ¨æœ€åé˜¶æ®µè¿›è¡Œï¼Œä»¥ç»†åŒ–è§’è‰²å¤´éƒ¨çš„ç§»åŠ¨é€Ÿåº¦å’Œé¢‘ç‡ã€‚</p><p><strong>å»å™ªè¿‡ç¨‹ï¼š</strong>åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼ŒBackbone Networkå°è¯•å»é™¤å¤šå¸§å™ªå£°ï¼Œç”Ÿæˆè¿ç»­çš„è§†é¢‘å¸§ã€‚å»å™ªè¿‡ç¨‹ä¸­ï¼Œå‚è€ƒç‰¹å¾å’ŒéŸ³é¢‘ç‰¹å¾è¢«ç»“åˆä½¿ç”¨ï¼Œä»¥ç”Ÿæˆé«˜åº¦çœŸå®å’Œè¡¨æƒ…ä¸°å¯Œçš„è§†é¢‘å†…å®¹ã€‚</p><p>EMOæ¨¡å‹é€šè¿‡è¿™ç§ç»“åˆä½¿ç”¨å‚è€ƒå›¾åƒã€éŸ³é¢‘ä¿¡å·ã€å’Œæ—¶é—´ä¿¡æ¯çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆä¸è¾“å…¥éŸ³é¢‘åŒæ­¥ä¸”åœ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ä¸Šå¯Œæœ‰è¡¨ç°åŠ›çš„è‚–åƒè§†é¢‘ï¼Œè¶…è¶Šäº†ä¼ ç»ŸæŠ€æœ¯çš„é™åˆ¶ï¼Œåˆ›é€ å‡ºæ›´åŠ è‡ªç„¶å’Œé€¼çœŸçš„åŠ¨ç”»æ•ˆæœã€‚</p><h2 id="EMOè®­ç»ƒé˜¶æ®µ"><a href="#EMOè®­ç»ƒé˜¶æ®µ" class="headerlink" title="EMOè®­ç»ƒé˜¶æ®µ"></a>EMOè®­ç»ƒé˜¶æ®µ</h2><p>è®­ç»ƒåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼Œ<strong>å›¾åƒé¢„è®­ç»ƒã€è§†é¢‘è®­ç»ƒå’Œé€Ÿåº¦å±‚è®­ç»ƒã€‚</strong></p><ul><li><p>åœ¨å›¾åƒé¢„è®­ç»ƒé˜¶æ®µï¼Œç½‘ç»œä»¥å•å¸§å›¾åƒä¸ºè¾“å…¥è¿›è¡Œè®­ç»ƒã€‚æ­¤é˜¶æ®µï¼ŒBackbone å°†å•ä¸ªå¸§ä½œä¸ºè¾“å…¥ï¼Œè€Œ ReferenceNet å¤„ç†æ¥è‡ªåŒä¸€å¸§çš„ä¸åŒçš„ã€éšæœºé€‰æ‹©çš„å¸§ï¼Œä»åŸå§‹ SD åˆå§‹åŒ–æƒé‡</p></li><li><p>åœ¨è§†é¢‘è®­ç»ƒé˜¶æ®µï¼Œå¼•å…¥æ—¶é—´æ¨¡å—å’ŒéŸ³é¢‘å±‚ï¼Œå¤„ç†è¿ç»­å¸§ï¼Œä»è§†é¢‘å‰ªè¾‘ä¸­é‡‡æ ·n+fä¸ªè¿ç»­å¸§ï¼Œå¼€å§‹çš„nå¸§æ˜¯è¿åŠ¨å¸§ã€‚æ—¶é—´æ¨¡å—ä»AnimateDiffåˆå§‹åŒ–æƒé‡ã€‚</p></li><li><p>é€Ÿåº¦å±‚è®­ç»ƒä¸“æ³¨äºè°ƒæ•´è§’è‰²å¤´éƒ¨çš„ç§»åŠ¨é€Ÿåº¦å’Œé¢‘ç‡ã€‚</p></li></ul><p>è¿™äº›è¯¦ç»†ä¿¡æ¯æä¾›äº†å¯¹EMOæ¨¡å‹è®­ç»ƒå’Œå…¶å‚æ•°é…ç½®çš„æ·±å…¥äº†è§£ï¼Œçªæ˜¾äº†å…¶åœ¨å¤„ç†å¹¿æ³›å’Œå¤šæ ·åŒ–æ•°æ®é›†æ–¹é¢çš„èƒ½åŠ›ï¼Œä»¥åŠå…¶åœ¨ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›å’Œé€¼çœŸè‚–åƒè§†é¢‘æ–¹é¢çš„å…ˆè¿›æ€§èƒ½ã€‚</p><h2 id="EMOå®éªŒè®¾ç½®"><a href="#EMOå®éªŒè®¾ç½®" class="headerlink" title="EMOå®éªŒè®¾ç½®"></a>EMOå®éªŒè®¾ç½®</h2><p>EMOçš„æ•°æ®é›†æœ‰ä¸¤éƒ¨ä»½ï¼Œé¦–å…ˆHumanAIGCå›¢é˜Ÿä»äº’è”ç½‘ä¸­æ”¶é›†äº† <strong>è¶…è¿‡250å°æ—¶çš„è§†é¢‘å’Œè¶…è¿‡1.5äº¿å¼ å›¾åƒ</strong>ï¼ŒåŒæ—¶åŠ å…¥äº†æ¥è‡ªäº’è”ç½‘å’ŒHDTFä»¥åŠVFHQæ•°æ®é›†ä½œä¸ºè¡¥å……ã€‚è¿™é‡Œé¢çš„æ•°æ®é›†å¤šç§å¤šæ ·ï¼ŒåŒ…æ‹¬æ¼”è®²ã€ç”µå½±å’Œç”µè§†å‰ªè¾‘ä»¥åŠæ­Œå”±è¡¨æ¼”ï¼Œæ¶µç›–äº†å¤šç§è¯­è¨€ï¼Œå¦‚ä¸­æ–‡å’Œè‹±æ–‡ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæœ€åèƒ½è¡¨ç°å‡ºå¦‚æ­¤å¥½æ•ˆæœçš„åŸå› ã€‚</p><p>åœ¨ç¬¬ä¸€é˜¶æ®µçš„æ—¶å€™ï¼Œä½¿ç”¨VFHQæ•°æ®é›†ï¼Œå› ä¸ºå®ƒä¸åŒ…å«éŸ³é¢‘ã€‚ç„¶åå†å¯¹è§†é¢‘è¿›è¡Œé¢„å¤„ç†ï¼Œæ‰€æœ‰çš„è§†é¢‘å¯é€šè¿‡MediaPipeæ¥è·å–äººè„¸æ£€æµ‹æ¡†åŒºåŸŸï¼Œå¹¶ä¸”è£å‰ªåˆ°512Ã—512çš„åˆ†è¾¨ç‡ã€‚</p><p>åœ¨ç¬¬ä¸€è®­ç»ƒé˜¶æ®µï¼Œæ‰¹å¤„ç†å¤§å°BatchSizeè®¾ç½®ä¸º48ã€‚åœ¨ç¬¬äºŒå’Œç¬¬ä¸‰è®­ç»ƒé˜¶æ®µï¼Œç”Ÿæˆè§†é¢‘é•¿åº¦è®¾ç½®ä¸ºf=12ï¼Œè¿åŠ¨å¸§æ•°è®¾ç½®ä¸ºn=4ï¼Œè®­ç»ƒçš„æ‰¹å¤„ç†å¤§å°ä¸º4ï¼Œå­¦ä¹ ç‡åœ¨æ‰€æœ‰é˜¶æ®µå‡è®¾ç½®ä¸º1e-5ã€‚</p><p>åœ¨æ¨ç†æ—¶ï¼Œä½¿ç”¨DDIMçš„é‡‡æ ·ç®—æ³•ç”Ÿæˆè§†é¢‘ã€‚æ—¶é—´æ­¥å¤§çº¦æ˜¯40æ­¥ï¼Œä¸ºæ¯ä¸€å¸§ç”ŸæˆæŒ‡å®šä¸€ä¸ªæ’å®šçš„é€Ÿåº¦å€¼ï¼Œæœ€åæ–¹æ³•çš„ç»“æœç”Ÿæˆä¸€æ‰¹ï¼ˆf=12å¸§ï¼‰çš„æ—¶é—´å¤§çº¦ä¸º15ç§’ã€‚ </p><p>ä¸€èˆ¬è§†é¢‘çš„é•¿åº¦ä¸º25ï½30å¸§å·¦å³ï¼Œå¦‚æœæˆ‘ä»¬è®¤ä¸ºæ˜¯1minsçš„è§†é¢‘ï¼Œä¹Ÿå°±æ˜¯60sçš„è§†é¢‘ï¼Œé‚£å°±æ˜¯60*25=1500ï¼Œ1500/15 = 100sï¼Œä¹Ÿå°±æ˜¯å¤§æ¦‚éœ€è¦1mins40sèƒ½ç”Ÿæˆä¸€åˆ†é’Ÿçš„è§†é¢‘ï¼Œé€Ÿåº¦ä¹Ÿå¾—åˆ°äº†ä¸é”™çš„æ”¹è¿›ï¼Œè™½ç„¶æ²¡æœ‰å®æ—¶ï¼Œä½†æ˜¯ç»“æœå·²ç»å¾ˆå¥½äº†ã€‚</p><h2 id="EMOç‰¹ç‚¹"><a href="#EMOç‰¹ç‚¹" class="headerlink" title="EMOç‰¹ç‚¹"></a>EMOç‰¹ç‚¹</h2><p>EMOæ¨¡å‹æœ‰å¦‚ä¸‹ç‰¹ç‚¹ï¼š</p><p><strong>ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆï¼š</strong>EMOé‡‡ç”¨ç›´æ¥ä»éŸ³é¢‘åˆæˆè§†é¢‘çš„æ–¹æ³•ï¼Œæ— éœ€ä¸­é—´çš„3Dæ¨¡å‹æˆ–é¢éƒ¨æ ‡å¿—ï¼Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹ï¼ŒåŒæ—¶ä¿æŒäº†é«˜åº¦çš„è¡¨ç°åŠ›å’Œè‡ªç„¶æ€§ã€‚</p><p><strong>æ— ç¼å¸§è¿‡æ¸¡ä¸èº«ä»½ä¿æŒï¼š</strong>è¯¥æ–¹æ³•ç¡®ä¿è§†é¢‘å¸§ä¹‹é—´çš„æ— ç¼è¿‡æ¸¡å’Œè§†é¢‘ä¸­èº«ä»½çš„ä¸€è‡´æ€§ï¼Œç”Ÿæˆçš„åŠ¨ç”»æ—¢ç”ŸåŠ¨åˆé€¼çœŸã€‚</p><p><strong>è¡¨è¾¾åŠ›ä¸çœŸå®æ€§ï¼š</strong>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEMOä¸ä»…èƒ½ç”Ÿæˆä»¤äººä¿¡æœçš„è¯´è¯è§†é¢‘ï¼Œè€Œä¸”è¿˜èƒ½ç”Ÿæˆå„ç§é£æ ¼çš„æ­Œå”±è§†é¢‘ï¼Œå…¶è¡¨ç°åŠ›å’ŒçœŸå®æ€§æ˜¾è‘—è¶…è¿‡ç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚</p><p><strong>çµæ´»çš„è§†é¢‘æ—¶é•¿ç”Ÿæˆï¼š</strong>EMOå¯ä»¥æ ¹æ®è¾“å…¥éŸ³é¢‘çš„é•¿åº¦ç”Ÿæˆä»»æ„æ—¶é•¿çš„è§†é¢‘ï¼Œæä¾›äº†æå¤§çš„çµæ´»æ€§ã€‚</p><p><strong>é¢å‘è¡¨æƒ…çš„è§†é¢‘ç”Ÿæˆï¼š</strong>EMOä¸“æ³¨äºé€šè¿‡éŸ³é¢‘æç¤ºç”Ÿæˆè¡¨æƒ…ä¸°å¯Œçš„è‚–åƒè§†é¢‘ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†è¯´è¯å’Œå”±æ­Œåœºæ™¯æ—¶ï¼Œå¯ä»¥æ•æ‰åˆ°å¤æ‚çš„é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿æ€å˜åŒ–ã€‚</p><p>è¿™äº›ç‰¹ç‚¹å…±åŒæ„æˆäº†EMOæ¨¡å‹çš„æ ¸å¿ƒç«äº‰åŠ›ï¼Œä½¿å…¶åœ¨åŠ¨æ€è‚–åƒè§†é¢‘ç”Ÿæˆé¢†åŸŸè¡¨ç°å‡ºè‰²ã€‚</p><h2 id="EMOç¼ºé™·"><a href="#EMOç¼ºé™·" class="headerlink" title="EMOç¼ºé™·"></a>EMOç¼ºé™·</h2><p>å¯¹äºEMOæ¥è¯´ï¼Œä¹Ÿä¼šæœ‰ä¸€äº›é™åˆ¶ã€‚</p><ul><li><p>é¦–å…ˆï¼Œä¸ä¸ä¾èµ–æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒæ›´è€—æ—¶ã€‚</p></li><li><p>å…¶æ¬¡ï¼Œç”±äºä¸ä½¿ç”¨ä»»ä½•æ˜ç¡®çš„æ§åˆ¶ä¿¡å·æ¥æ§åˆ¶è§’è‰²çš„è¿åŠ¨ï¼Œå› æ­¤å¯èƒ½ä¼šå¯¼è‡´æ— æ„ä¸­ç”Ÿæˆå…¶ä»–èº«ä½“éƒ¨ä½ï¼ˆä¾‹å¦‚æ‰‹ï¼‰ï¼Œä»è€Œå¯¼è‡´è§†é¢‘ä¸­å‡ºç°ä¼ªå½±ã€‚</p></li></ul><p>æ‰€ä»¥è¿™æ ·çš„ä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœè¦è§£å†³çš„è¯ï¼Œå¯ä»¥è€ƒè™‘ç”¨ä¸“é—¨æ§åˆ¶èº«ä½“éƒ¨ä½çš„æ§åˆ¶ä¿¡å·ï¼Œè¿™æ ·å°±ä¼šè¾ƒå¥½çš„è§£å†³è¿™ä¸ªæ–¹æ³•ï¼Œæ¯ä¸€ä¸ªä¿¡å·æ§åˆ¶ä¸€éƒ¨åˆ†ï¼Œå°±ä¸ä¼šç”Ÿæˆé”™è¯¯ã€‚</p><p>å‚è€ƒ</p><ul><li><a href="https://m.huxiu.com/article/2728417.html">https://m.huxiu.com/article/2728417.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;EMO-Emote-Portrait-Alive-é˜¿é‡ŒHumanAIGC&quot;&gt;&lt;a href=&quot;#EMO-Emote-Portrait-Alive-é˜¿é‡ŒHumanAIGC&quot; class=&quot;headerlink&quot; title=&quot;EMO: Emote Portrait </summary>
      
    
    
    
    <category term="Paperscape" scheme="https://kedreamix.github.io/categories/Paperscape/"/>
    
    
    <category term="Talking Head Generation" scheme="https://kedreamix.github.io/tags/Talking-Head-Generation/"/>
    
    <category term="Diffusion Models" scheme="https://kedreamix.github.io/tags/Diffusion-Models/"/>
    
  </entry>
  
  <entry>
    <title>NeRF</title>
    <link href="https://kedreamix.github.io/2024/02/29/Paper/2024-02-29/NeRF/"/>
    <id>https://kedreamix.github.io/2024/02/29/Paper/2024-02-29/NeRF/</id>
    <published>2024-02-29T13:26:36.000Z</published>
    <updated>2024-02-29T13:26:36.999Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-02-29-æ›´æ–°"><a href="#2024-02-29-æ›´æ–°" class="headerlink" title="2024-02-29 æ›´æ–°"></a>2024-02-29 æ›´æ–°</h1><h2 id="Learning-Dynamic-Tetrahedra-for-High-Quality-Talking-Head-Synthesis"><a href="#Learning-Dynamic-Tetrahedra-for-High-Quality-Talking-Head-Synthesis" class="headerlink" title="Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis"></a>Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis</h2><p><strong>Authors:Zicheng Zhang, Ruobing Zheng, Ziwen Liu, Congying Han, Tianqi Li, Meng Wang, Tiande Guo, Jingdong Chen, Bonan Li, Ming Yang</strong></p><p>Recent works in implicit representations, such as Neural Radiance Fields (NeRF), have advanced the generation of realistic and animatable head avatars from video sequences. These implicit methods are still confronted by visual artifacts and jitters, since the lack of explicit geometric constraints poses a fundamental challenge in accurately modeling complex facial deformations. In this paper, we introduce Dynamic Tetrahedra (DynTet), a novel hybrid representation that encodes explicit dynamic meshes by neural networks to ensure geometric consistency across various motions and viewpoints. DynTet is parameterized by the coordinate-based networks which learn signed distance, deformation, and material texture, anchoring the training data into a predefined tetrahedra grid. Leveraging Marching Tetrahedra, DynTet efficiently decodes textured meshes with a consistent topology, enabling fast rendering through a differentiable rasterizer and supervision via a pixel loss. To enhance training efficiency, we incorporate classical 3D Morphable Models to facilitate geometry learning and define a canonical space for simplifying texture learning. These advantages are readily achievable owing to the effective geometric representation employed in DynTet. Compared with prior works, DynTet demonstrates significant improvements in fidelity, lip synchronization, and real-time performance according to various metrics. Beyond producing stable and visually appealing synthesis videos, our method also outputs the dynamic meshes which is promising to enable many emerging applications. </p><p><a href="http://arxiv.org/abs/2402.17364v1">PDF</a> CVPR 2024</p><p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æœ€æ–°æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œå³åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜ç¡®åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿å„ç§åŠ¨ä½œå’Œè§†ç‚¹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>DynTet æ˜¯ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿ä¸åŒåŠ¨ä½œå’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚</li><li>DynTet ä½¿ç”¨åŸºäºåæ ‡çš„ç½‘ç»œå¯¹ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†è¿›è¡Œå­¦ä¹ ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚</li><li>DynTet åˆ©ç”¨ Marching Tetrahedra æœ‰æ•ˆåœ°è§£ç äº†å…·æœ‰ç¨³å®šæ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œå¹¶é€šè¿‡å¯å¾®åˆ†å…‰æ …å™¨å’Œåƒç´ æŸå¤±çš„ç›‘ç£å®ç°äº†å¿«é€Ÿæ¸²æŸ“ã€‚</li><li>DynTet ç»“åˆç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹æ¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªè§„èŒƒåŒ–ç©ºé—´æ¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</li><li>ä¸ä¹‹å‰çš„ç ”ç©¶ç›¸æ¯”ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢æœ‰äº†æ˜¾è‘—çš„æå‡ã€‚</li><li>é™¤äº†åˆ¶ä½œå‡ºç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›å®ç°è®¸å¤šæ–°å…´åº”ç”¨ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šç”¨äºé«˜å“è´¨è¯´è¯äººå¤´éƒ¨åˆæˆçš„åŠ¨æ€å››é¢ä½“å­¦ä¹ </li><li>ä½œè€…ï¼šå¼ å­å·ï¼Œå¼ æ’ï¼Œç‹ä½³ä¿Šï¼Œåˆ˜å­è¶…ï¼Œå­™å‰‘</li><li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šè¯´è¯äººå¤´éƒ¨åˆæˆã€éšå¼è¡¨ç¤ºã€åŠ¨æ€ç½‘æ ¼ã€ç¥ç»è¾å°„åœº</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.02574</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œéšå¼è¡¨ç¤ºæ–¹æ³•ï¼Œå¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œåœ¨ä»è§†é¢‘åºåˆ—ç”Ÿæˆé€¼çœŸä¸”å¯åŠ¨ç”»åŒ–çš„å¤´éƒ¨å¤´åƒæ–¹é¢å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›éšå¼æ–¹æ³•ä»ç„¶é¢ä¸´è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨é—®é¢˜ï¼Œå› ä¸ºç¼ºä¹æ˜ç¡®çš„å‡ ä½•çº¦æŸï¼Œè¿™ç»™å‡†ç¡®å»ºæ¨¡å¤æ‚çš„é¢éƒ¨å˜å½¢å¸¦æ¥äº†æ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é‡‡ç”¨éšå¼è¡¨ç¤ºï¼Œä½†ç¼ºä¹æ˜ç¡®çš„å‡ ä½•çº¦æŸï¼Œå¯¼è‡´è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨é—®é¢˜ã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œç§°ä¸ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå®ƒé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿åœ¨å„ç§è¿åŠ¨å’Œè§†ç‚¹ä¸‹å‡ ä½•ä¸€è‡´æ€§ã€‚DynTet ç”±åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œè¯¥ç½‘ç»œå­¦ä¹ ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚åˆ©ç”¨è¡Œè¿›å››é¢ä½“ï¼ŒDynTet å¯ä»¥æœ‰æ•ˆåœ°è§£ç å…·æœ‰ç›¸åŒæ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œä»è€Œå¯ä»¥é€šè¿‡å¯å¾®åˆ†å…‰æ …åŒ–å™¨å¿«é€Ÿæ¸²æŸ“ï¼Œå¹¶é€šè¿‡åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ã€‚ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡ï¼Œæœ¬æ–‡ç»“åˆäº†ç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹æ¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªè§„èŒƒç©ºé—´æ¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚è¿™äº›ä¼˜åŠ¿å¾—ç›Šäº DynTet ä¸­é‡‡ç”¨çš„æœ‰æ•ˆå‡ ä½•è¡¨ç¤ºã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½åŠå¯¹ç›®æ ‡çš„æ”¯æŒï¼šä¸ä»¥å¾€çš„å·¥ä½œç›¸æ¯”ï¼Œæ ¹æ®å„ç§æŒ‡æ ‡ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾ç€æå‡ã€‚é™¤äº†ç”Ÿæˆç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæœ¬æ–‡æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚</li></ol><p>7.æ–¹æ³•ï¼š(1): åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰é€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼›(2): åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œå­¦ä¹ ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†æ•°æ®é”šå®šåˆ°å››é¢ä½“ç½‘æ ¼ä¸­ï¼›(3): åˆ©ç”¨è¡Œè¿›å››é¢ä½“è§£ç çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®åˆ†å…‰æ …åŒ–å™¨æ¸²æŸ“å¹¶é€šè¿‡åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ï¼›(4): ç»“åˆç»å…¸çš„3Då¯å˜å½¢æ¨¡å‹ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå®šä¹‰è§„èŒƒç©ºé—´ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</p><ol><li>æ€»ç»“ï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰æ–¹æ³•ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼Œæå‡äº†è¯´è¯äººå¤´éƒ¨åˆæˆçš„ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œç§°ä¸ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå®ƒé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿åœ¨å„ç§è¿åŠ¨å’Œè§†ç‚¹ä¸‹å‡ ä½•ä¸€è‡´æ€§ã€‚</li><li>åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œå­¦ä¹ ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚</li><li>åˆ©ç”¨è¡Œè¿›å››é¢ä½“ï¼ŒDynTetå¯ä»¥æœ‰æ•ˆåœ°è§£ç å…·æœ‰ç›¸åŒæ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œä»è€Œå¯ä»¥é€šè¿‡å¯å¾®åˆ†å…‰æ …åŒ–å™¨å¿«é€Ÿæ¸²æŸ“ï¼Œå¹¶é€šè¿‡åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ã€‚</li><li>ç»“åˆäº†ç»å…¸çš„3Då¯å˜å½¢æ¨¡å‹æ¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªè§„èŒƒç©ºé—´æ¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</li><li>è¿™äº›ä¼˜åŠ¿å¾—ç›ŠäºDynTetä¸­é‡‡ç”¨çš„æœ‰æ•ˆå‡ ä½•è¡¨ç¤ºã€‚</li><li>ä¸ä»¥å¾€çš„å·¥ä½œç›¸æ¯”ï¼Œæ ¹æ®å„ç§æŒ‡æ ‡ï¼ŒDynTetåœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾ç€æå‡ã€‚</li><li>é™¤äº†ç”Ÿæˆç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæœ¬æ–‡æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚æ€§èƒ½ï¼š</li><li>åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾ç€æå‡ã€‚</li><li>ç”Ÿæˆäº†ç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘ã€‚</li><li>è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚å·¥ä½œé‡ï¼š</li><li>è®ºæ–‡ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°å·¥ä½œé‡ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-2927e4da13bb2db0a8c147b32e65c4ba.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a69eb8d9ee3b7163b0dd216926919257.jpg" align="middle"><img src="https://pica.zhimg.com/v2-989288a0ad24820fe95020a4ed1f2ea7.jpg" align="middle"></details><h2 id="CharNeRF-3D-Character-Generation-from-Concept-Art"><a href="#CharNeRF-3D-Character-Generation-from-Concept-Art" class="headerlink" title="CharNeRF: 3D Character Generation from Concept Art"></a>CharNeRF: 3D Character Generation from Concept Art</h2><p><strong>Authors:Eddy Chu, Yiyang Chen, Chedy Raissi, Anand Bhojan</strong></p><p>3D modeling holds significant importance in the realms of AR/VR and gaming, allowing for both artistic creativity and practical applications. However, the process is often time-consuming and demands a high level of skill. In this paper, we present a novel approach to create volumetric representations of 3D characters from consistent turnaround concept art, which serves as the standard input in the 3D modeling industry. While Neural Radiance Field (NeRF) has been a game-changer in image-based 3D reconstruction, to the best of our knowledge, there is no known research that optimizes the pipeline for concept art. To harness the potential of concept art, with its defined body poses and specific view angles, we propose encoding it as priors for our model. We train the network to make use of these priors for various 3D points through a learnable view-direction-attended multi-head self-attention layer. Additionally, we demonstrate that a combination of ray sampling and surface sampling enhances the inference capabilities of our network. Our model is able to generate high-quality 360-degree views of characters. Subsequently, we provide a simple guideline to better leverage our model to extract the 3D mesh. It is important to note that our modelâ€™s inferencing capabilities are influenced by the training dataâ€™s characteristics, primarily focusing on characters with a single head, two arms, and two legs. Nevertheless, our methodology remains versatile and adaptable to concept art from diverse subject matters, without imposing any specific assumptions on the data. </p><p><a href="http://arxiv.org/abs/2402.17115v1">PDF</a> </p><p><strong>Summary</strong><br>ç”¨æ¦‚å¿µå›¾åˆ›å»º 3D æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œåˆ©ç”¨ç¥ç»è¾å°„åœºå¹¶ä¸ºå›¾åƒå»ºæ¨¡æä¾›æ›´å¥½çš„è§†è§’ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>è‰ºæœ¯åˆ›ä½œå’Œå®é™…åº”ç”¨ä¸­ï¼Œ3D å»ºæ¨¡å¾ˆæœ‰ä»·å€¼ï¼Œä½†éœ€è¦èŠ±è´¹æ—¶é—´å’ŒæŠ€èƒ½ã€‚</li><li>è¯¥æ–¹æ³•ä»æ ‡å‡†çš„ 3D å»ºæ¨¡è¡Œä¸šè¾“å…¥ï¼Œå³å¯æ ¹æ®ä¸€è‡´çš„é€è§†å›¾æ¦‚å¿µå›¾åˆ›å»º 3D è§’è‰²çš„ä½“ç§¯è¡¨ç¤ºã€‚</li><li>ç¥ç»è¾å°„åœº (NeRF) å·²æ”¹å˜åŸºäºå›¾åƒçš„ 3D é‡å»ºï¼Œä½†å°šæ— é’ˆå¯¹æ¦‚å¿µå›¾ä¼˜åŒ–ç®¡é“ã€‚</li><li>ç¼–ç æ¦‚å¿µå›¾ä¸ºæ¨¡å‹çš„å…ˆéªŒï¼Œåˆ©ç”¨æ¦‚å¿µå›¾ä¸­çš„æ¸…æ™°çš„èº«ä½“å§¿åŠ¿å’Œç‰¹å®šçš„è§†è§’ã€‚</li><li>é€šè¿‡å¯å­¦ä¹ çš„è§†å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ï¼Œè®­ç»ƒç½‘ç»œåˆ©ç”¨å„ç§ 3D ç‚¹çš„å…ˆéªŒã€‚</li><li>å°„çº¿é‡‡æ ·å’Œè¡¨é¢é‡‡æ ·çš„ç»„åˆå¢å¼ºäº†ç½‘ç»œçš„æ¨ç†èƒ½åŠ›ã€‚</li><li>æ¨¡å‹å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ 360 åº¦è§’è‰²è§†å›¾ã€‚</li><li>å¼€å‘äº†ç®€å•çš„æŒ‡å—ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹æå– 3D ç½‘æ ¼ã€‚</li><li>æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å—è®­ç»ƒæ•°æ®çš„å½±å“ï¼Œä¸»è¦é’ˆå¯¹å¤´éƒ¨ã€æ‰‹è‡‚å’Œè…¿éƒ¨ã€‚</li><li>è¯¥æ–¹æ³•é€‚ç”¨äºå„ç§ä¸»é¢˜çš„æ¦‚å¿µå›¾ï¼Œå¯¹æ•°æ®æ²¡æœ‰ç‰¹æ®Šå‡è®¾ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>è®ºæ–‡æ ‡é¢˜ï¼šCharNeRFï¼šåŸºäºæ¦‚å¿µå›¾çš„ 3D è§’è‰²ç”Ÿæˆ</li><li>ä½œè€…ï¼šEddy Chuã€Yiyang Chenã€Chedy Raissiã€Anand Bhojan</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ–°åŠ å¡å›½ç«‹å¤§å­¦</li><li>å…³é”®è¯ï¼šç¥ç»ç½‘ç»œã€è®¡ç®—æœºå›¾å½¢ã€è™šæ‹Ÿç°å®ã€æ¸¸æˆã€ç½‘æ ¼ç”Ÿæˆ</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17115</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D å»ºæ¨¡åœ¨ AR/VR å’Œæ¸¸æˆä¸­è‡³å…³é‡è¦ï¼Œä½†é€šå¸¸è€—æ—¶ä¸”è¦æ±‚é«˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»ä¸€è‡´çš„å‘¨è½¬æ¦‚å¿µå›¾ä¸­åˆ›å»º 3D è§’è‰²ä½“ç§¯è¡¨ç¤ºçš„æ–°æ–¹æ³•ã€‚ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç¥ç»è¾å°„åœº (NeRF) å·²æˆä¸ºå›¾åƒé‡å»ºçš„å˜é©è€…ï¼Œä½†å°šæ— é’ˆå¯¹æ¦‚å¿µå›¾ä¼˜åŒ–ç®¡çº¿çš„ç ”ç©¶ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡åˆ©ç”¨æ¦‚å¿µå›¾ä¸­çš„å®šä¹‰çš„èº«ä½“å§¿åŠ¿å’Œç‰¹å®šçš„è§†è§’ï¼Œå°†å…¶ç¼–ç ä¸ºæ¨¡å‹çš„å…ˆéªŒã€‚æå‡ºäº†ä¸€ç§å¯å­¦ä¹ çš„è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ï¼Œè®©ç½‘ç»œåˆ©ç”¨è¿™äº›å…ˆéªŒã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜è¯æ˜äº†å…‰çº¿é‡‡æ ·å’Œè¡¨é¢é‡‡æ ·çš„ç»„åˆå¢å¼ºäº†ç½‘ç»œçš„æ¨ç†èƒ½åŠ›ã€‚ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šæœ¬æ–‡æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 360 åº¦è§’è‰²è§†å›¾ã€‚æ­¤å¤–ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªç®€å•çš„æŒ‡å—ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹æå– 3D ç½‘æ ¼ã€‚æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å—è®­ç»ƒæ•°æ®ç‰¹å¾çš„å½±å“ï¼Œä¸»è¦é’ˆå¯¹å…·æœ‰ä¸€ä¸ªå¤´éƒ¨ã€ä¸¤ä¸ªæ‰‹è‡‚å’Œä¸¤æ¡è…¿çš„è§’è‰²ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œå¯é€‚åº”ä¸åŒä¸»é¢˜çš„æ¦‚å¿µå›¾ï¼Œè€Œæ— éœ€å¯¹æ•°æ®åšå‡ºä»»ä½•ç‰¹å®šå‡è®¾ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) ç¼–ç æ¦‚å¿µå›¾ï¼šé‡‡ç”¨åŒå±‚æ²™æ¼ç¼–ç å™¨ï¼Œæå–æ¦‚å¿µå›¾çš„é«˜ä½å±‚æ¬¡ç»†èŠ‚ã€‚(2) è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›ç‰¹å¾å‘é‡ç»„åˆï¼šä½¿ç”¨å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶èåˆæ¥è‡ªæ¦‚å¿µå›¾çš„ä¸‰ä¸ªç‰¹å¾å‘é‡ï¼Œé‡ç‚¹å…³æ³¨æŸ¥è¯¢è§†å›¾æ–¹å‘ä¸æºè‰å›¾è§†å›¾æ–¹å‘ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚(3) ç¥ç»è¾å°„åœºï¼šä½¿ç”¨ç¥ç»è¾å°„åœºé¢„æµ‹æœ€ç»ˆé¢œè‰²å’Œå¯†åº¦ï¼ŒæŒ‡å¯¼ç½‘ç»œå­¦ä¹ ç‰¹å®šç±»åˆ«çš„ä¸€èˆ¬å½¢çŠ¶å’Œç‰¹å¾ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œå°è¯•è§£å†³è®¡ç®—æœºè§†è§‰ä¸­ä¸€ä¸ªå…·æœ‰é‡è¦ AR/VR/æ¸¸æˆåº”ç”¨ä»·å€¼çš„æŒ‘æˆ˜æ€§é—®é¢˜ï¼Œå³ä½¿ç”¨ NeRF ä»æ¦‚å¿µå›¾æ„å»º 3D è§’è‰²çš„ 3D è¡¨ç¤ºã€‚æˆ‘ä»¬æå‡ºçš„æœ€ç»ˆæ¨¡å‹ CharNeRF å¾—ç›Šäºç”¨äºç»„åˆä¸åŒè¾“å…¥è§†å›¾ä¿¡æ¯çš„è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›ç»„ä»¶ï¼Œèƒ½å¤Ÿä»å¦‚æ­¤ç¨€ç–çš„å›¾åƒè¾“å…¥ä¸­ç”Ÿæˆè‰¯å¥½çš„ç»“æœã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§å¯å­¦ä¹ çš„è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ï¼Œè®©ç½‘ç»œåˆ©ç”¨æ¦‚å¿µå›¾ä¸­çš„å®šä¹‰çš„èº«ä½“å§¿åŠ¿å’Œç‰¹å®šçš„è§†è§’ã€‚æ­¤å¤–ï¼Œè¿˜è¯æ˜äº†å…‰çº¿é‡‡æ ·å’Œè¡¨é¢é‡‡æ ·çš„ç»„åˆå¢å¼ºäº†ç½‘ç»œçš„æ¨ç†èƒ½åŠ›ã€‚æ€§èƒ½ï¼šæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 360 åº¦è§’è‰²è§†å›¾ã€‚æ­¤å¤–ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªç®€å•çš„æŒ‡å—ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹æå– 3D ç½‘æ ¼ã€‚å·¥ä½œé‡ï¼šæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å—è®­ç»ƒæ•°æ®ç‰¹å¾çš„å½±å“ï¼Œä¸»è¦é’ˆå¯¹å…·æœ‰ä¸€ä¸ªå¤´éƒ¨ã€ä¸¤ä¸ªæ‰‹è‡‚å’Œä¸¤æ¡è…¿çš„è§’è‰²ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œå¯é€‚åº”ä¸åŒä¸»é¢˜çš„æ¦‚å¿µå›¾ï¼Œè€Œæ— éœ€å¯¹æ•°æ®åšå‡ºä»»ä½•ç‰¹å®šå‡è®¾ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-828eaae544f50ff5c3cb4c05ee9d80e8.jpg" align="middle"><img src="https://picx.zhimg.com/v2-ef7369a7d8878e03f6b272a4d1ebd217.jpg" align="middle"><img src="https://picx.zhimg.com/v2-19f2984d16b69f5650701e035c363f95.jpg" align="middle"><img src="https://picx.zhimg.com/v2-2b8a11537cec84e0f035cff561493d37.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f60295f4a9ff4a9d9749851b16f04d26.jpg" align="middle"></details><h2 id="CMC-Few-shot-Novel-View-Synthesis-via-Cross-view-Multiplane-Consistency"><a href="#CMC-Few-shot-Novel-View-Synthesis-via-Cross-view-Multiplane-Consistency" class="headerlink" title="CMC: Few-shot Novel View Synthesis via Cross-view Multiplane Consistency"></a>CMC: Few-shot Novel View Synthesis via Cross-view Multiplane Consistency</h2><p><strong>Authors:Hanxin Zhu, Tianyu He, Zhibo Chen</strong></p><p>Neural Radiance Field (NeRF) has shown impressive results in novel view synthesis, particularly in Virtual Reality (VR) and Augmented Reality (AR), thanks to its ability to represent scenes continuously. However, when just a few input view images are available, NeRF tends to overfit the given views and thus make the estimated depths of pixels share almost the same value. Unlike previous methods that conduct regularization by introducing complex priors or additional supervisions, we propose a simple yet effective method that explicitly builds depth-aware consistency across input views to tackle this challenge. Our key insight is that by forcing the same spatial points to be sampled repeatedly in different input views, we are able to strengthen the interactions between views and therefore alleviate the overfitting problem. To achieve this, we build the neural networks on layered representations (\textit{i.e.}, multiplane images), and the sampling point can thus be resampled on multiple discrete planes. Furthermore, to regularize the unseen target views, we constrain the rendered colors and depths from different input views to be the same. Although simple, extensive experiments demonstrate that our proposed method can achieve better synthesis quality over state-of-the-art methods. </p><p><a href="http://arxiv.org/abs/2402.16407v1">PDF</a> Accepted by IEEE Conference on Virtual Reality and 3D User Interfaces   (IEEE VR 2024)</p><p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨å…¨æ–°è§†è§’åˆæˆä¸­å±•ç¤ºå‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆæœï¼Œç‰¹åˆ«æ˜¯åœ¨è™šæ‹Ÿç°å® (VR) å’Œå¢å¼ºç°å® (AR) ä¸­ï¼Œè¿™å¾—ç›Šäºå…¶è¿ç»­è¡¨ç¤ºåœºæ™¯çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“åªæœ‰å°‘æ•°è¾“å…¥è§†å›¾å›¾åƒå¯ç”¨æ—¶ï¼ŒNeRF å€¾å‘äºå¯¹ç»™å®šçš„è§†å›¾è¿›è¡Œè¿‡åº¦æ‹Ÿåˆï¼Œä»è€Œä½¿ä¼°è®¡çš„åƒç´ æ·±åº¦å‡ ä¹å…·æœ‰ç›¸åŒçš„å€¼ã€‚ä¸åŒäºé€šè¿‡å¼•å…¥å¤æ‚å…ˆéªŒæˆ–é™„åŠ ç›‘ç£æ¥è¿›è¡Œæ­£åˆ™åŒ–çš„å…ˆå‰æ–¹æ³•ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•ä½†æœ‰æ•ˆçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ˜ç¡®æ„å»ºäº†è¾“å…¥è§†å›¾ä¹‹é—´çš„æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œé€šè¿‡å¼ºåˆ¶ç›¸åŒçš„ç©ºé—´ç‚¹åœ¨ä¸åŒçš„è¾“å…¥è§†å›¾ä¸­è¢«é‡å¤é‡‡æ ·ï¼Œæˆ‘ä»¬èƒ½å¤ŸåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œå‡è½»è¿‡åº¦æ‹Ÿåˆé—®é¢˜ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åœ¨åˆ†å±‚è¡¨ç¤ºï¼ˆå³å¤šå¹³é¢å›¾åƒï¼‰ä¸Šå»ºç«‹ç¥ç»ç½‘ç»œï¼Œå¹¶ä¸”é‡‡æ ·ç‚¹å¯ä»¥åœ¨å¤šä¸ªç¦»æ•£å¹³é¢ä¸Šé‡æ–°é‡‡æ ·ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ï¼Œæˆ‘ä»¬çº¦æŸä¸åŒè¾“å…¥è§†å›¾çš„æ¸²æŸ“é¢œè‰²å’Œæ·±åº¦ç›¸åŒã€‚è™½ç„¶ç®€å•ï¼Œä½†å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•å¯ä»¥æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å®ç°æ›´å¥½çš„åˆæˆè´¨é‡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>NeRF åœ¨åªæœ‰å°‘æ•°è¾“å…¥è§†å›¾å›¾åƒå¯ç”¨æ—¶ä¼šè¿‡æ‹Ÿåˆã€‚</li><li>é€šè¿‡å¼ºåˆ¶ç›¸åŒçš„ç©ºé—´ç‚¹åœ¨ä¸åŒçš„è¾“å…¥è§†å›¾ä¸­è¢«é‡å¤é‡‡æ ·å¯ä»¥å‡è½»è¿‡åº¦æ‹Ÿåˆé—®é¢˜ã€‚</li><li>æˆ‘ä»¬åœ¨åˆ†å±‚è¡¨ç¤ºä¸Šæ„å»ºç¥ç»ç½‘ç»œï¼Œä»¥ä¾¿åœ¨å¤šä¸ªç¦»æ•£å¹³é¢ä¸Šé‡æ–°é‡‡æ ·é‡‡æ ·ç‚¹ã€‚</li><li>æˆ‘ä»¬çº¦æŸä¸åŒè¾“å…¥è§†å›¾çš„æ¸²æŸ“é¢œè‰²å’Œæ·±åº¦ç›¸åŒï¼Œä»¥æ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ã€‚</li><li>æˆ‘ä»¬çš„æ–¹æ³•æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å®ç°äº†æ›´å¥½çš„åˆæˆè´¨é‡ã€‚</li><li>æˆ‘ä»¬æ–¹æ³•çš„å…³é”®åœ¨äºæ˜¾å¼æ„å»ºè¾“å…¥è§†å›¾ä¹‹é—´çš„æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§ã€‚</li><li>æˆ‘ä»¬çš„æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œä¸éœ€è¦å¼•å…¥å¤æ‚å…ˆéªŒæˆ–é¢å¤–çš„ç›‘ç£ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šCMCï¼šé€šè¿‡è·¨è§†å›¾å¤šå¹³é¢ä¸€è‡´æ€§è¿›è¡Œå°æ ·æœ¬æ–°è§†è§’åˆæˆ</li><li>ä½œè€…ï¼šéŸ©æ˜•ç«¹ã€ä½•å¤©å®‡ã€é™ˆå¿—æ³¢</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦</li><li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å°æ ·æœ¬è§†è§’åˆæˆã€å¤šå¹³é¢å›¾åƒã€è·¨è§†å›¾ä¸€è‡´æ€§</li><li>è®ºæ–‡é“¾æ¥ï¼šNone, Github é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨å°æ ·æœ¬è§†è§’åˆæˆä¸­å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå¯¼è‡´ä¼°è®¡çš„åƒç´ æ·±åº¦å‡ ä¹ç›¸åŒã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•é€šè¿‡å¼•å…¥å¤æ‚å…ˆéªŒæˆ–é¢å¤–ç›‘ç£æ¥è¿›è¡Œæ­£åˆ™åŒ–ï¼Œä½†å­˜åœ¨é¢„è®­ç»ƒæˆæœ¬é«˜ã€åŸŸå·®è·ç­‰é—®é¢˜ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„è·¨è§†å›¾æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§æ–¹æ³•ï¼Œé€šè¿‡åœ¨ä¸åŒè¾“å…¥è§†å›¾ä¸­å¼ºåˆ¶é‡‡æ ·ç›¸åŒç©ºé—´ç‚¹ï¼ŒåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼Œç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡æ„å»ºäº†åŸºäºåˆ†å±‚è¡¨ç¤ºï¼ˆå³å¤šå¹³é¢å›¾åƒï¼‰çš„ç¥ç»ç½‘ç»œï¼Œå¹¶å¯¹å¤šå¹³é¢è¿›è¡Œé‡‡æ ·ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ï¼Œæœ¬æ–‡çº¦æŸäº†ä¸åŒè¾“å…¥è§†å›¾æ¸²æŸ“çš„é¢œè‰²å’Œæ·±åº¦ä¸€è‡´æ€§ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å°æ ·æœ¬è§†è§’åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li></ol><p>7.Methods:(1):æ„å»ºåŸºäºåˆ†å±‚è¡¨ç¤ºçš„å¤šå¹³é¢å›¾åƒï¼Œå¹¶å¯¹å…¶è¿›è¡Œé‡‡æ ·ï¼›(2):é€šè¿‡åœ¨ä¸åŒè¾“å…¥è§†å›¾ä¸­å¼ºåˆ¶é‡‡æ ·ç›¸åŒç©ºé—´ç‚¹ï¼ŒåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼›(3):çº¦æŸä¸åŒè¾“å…¥è§†å›¾æ¸²æŸ“çš„é¢œè‰²å’Œæ·±åº¦ä¸€è‡´æ€§ï¼Œæ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ã€‚</p><ol><li>ç»“è®ºï¼š(1): æœ¬æ–‡æå‡ºäº† CMC æ–¹æ³•ï¼Œé€šè¿‡è·¨è§†å›¾å¤šå¹³é¢ä¸€è‡´æ€§ï¼Œç¼“è§£äº† NeRF åœ¨å°æ ·æœ¬è§†è§’åˆæˆä¸­çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæå‡äº†åˆæˆå›¾åƒçš„è´¨é‡ã€‚(2): åˆ›æ–°ç‚¹ï¼š<ul><li>æå‡ºè·¨è§†å›¾æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§æ–¹æ³•ï¼ŒåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼Œç¼“è§£è¿‡æ‹Ÿåˆã€‚</li><li>æ„å»ºåŸºäºåˆ†å±‚è¡¨ç¤ºçš„å¤šå¹³é¢å›¾åƒï¼Œå¹¶å¯¹å…¶è¿›è¡Œé‡‡æ ·ã€‚</li><li>çº¦æŸä¸åŒè¾“å…¥è§†å›¾æ¸²æŸ“çš„é¢œè‰²å’Œæ·±åº¦ä¸€è‡´æ€§ï¼Œæ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ã€‚Performanceï¼š</li><li>åœ¨å°æ ·æœ¬è§†è§’åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚Workloadï¼š</li><li>æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œæ˜“äºå®ç°ã€‚</li></ul></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-bdd46c7b217cb4180eb948c43ffad849.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-571786b47c356d9bc3c90a0ca95fe68b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-78bf909d8f8aa9e18f65bc56fd97a0b5.jpg" align="middle"><img src="https://picx.zhimg.com/v2-0da54ff7a201688851cb82cbbbe20007.jpg" align="middle"><img src="https://picx.zhimg.com/v2-eff9d03d40a8b3f7618fd67f793df987.jpg" align="middle"></details><h2 id="SPC-NeRF-Spatial-Predictive-Compression-for-Voxel-Based-Radiance-Field"><a href="#SPC-NeRF-Spatial-Predictive-Compression-for-Voxel-Based-Radiance-Field" class="headerlink" title="SPC-NeRF: Spatial Predictive Compression for Voxel Based Radiance Field"></a>SPC-NeRF: Spatial Predictive Compression for Voxel Based Radiance Field</h2><p><strong>Authors:Zetian Song, Wenhong Duan, Yuhuai Zhang, Shiqi Wang, Siwei Ma, Wen Gao</strong></p><p>Representing the Neural Radiance Field (NeRF) with the explicit voxel grid (EVG) is a promising direction for improving NeRFs. However, the EVG representation is not efficient for storage and transmission because of the terrific memory cost. Current methods for compressing EVG mainly inherit the methods designed for neural network compression, such as pruning and quantization, which do not take full advantage of the spatial correlation of voxels. Inspired by prosperous digital image compression techniques, this paper proposes SPC-NeRF, a novel framework applying spatial predictive coding in EVG compression. The proposed framework can remove spatial redundancy efficiently for better compression performance.Moreover, we model the bitrate and design a novel form of the loss function, where we can jointly optimize compression ratio and distortion to achieve higher coding efficiency. Extensive experiments demonstrate that our method can achieve 32% bit saving compared to the state-of-the-art method VQRF on multiple representative test datasets, with comparable training time. </p><p><a href="http://arxiv.org/abs/2402.16366v1">PDF</a> </p><p><strong>Summary</strong><br>åˆ©ç”¨ç©ºé—´é¢„æµ‹ç¼–ç å¯¹ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æ˜¾å¼ä½“ç´ ç½‘æ ¼ï¼ˆEVGï¼‰è¿›è¡Œå‹ç¼©ï¼Œå¯æœ‰æ•ˆæå‡å…¶å­˜å‚¨å’Œä¼ è¾“æ•ˆç‡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡ºåŸºäºæ˜¾å¼ä½“ç´ ç½‘æ ¼ï¼ˆvoxel gridï¼‰çš„ NeRF å‹ç¼©æ–°æ¡†æ¶â€”â€”SPC-NeRF</li><li>åˆ©ç”¨ç©ºé—´é¢„æµ‹ç¼–ç æœ‰æ•ˆå»é™¤ä½“ç´ çš„ç©ºé—´å†—ä½™ï¼Œæå‡å‹ç¼©æ€§èƒ½</li><li>æå‡ºæ–°çš„æ¯”ç‰¹ç‡å»ºæ¨¡å’ŒæŸå¤±å‡½æ•°å½¢å¼ï¼Œå®ç°å‹ç¼©ç‡ä¸å¤±çœŸçš„è”åˆä¼˜åŒ–</li><li>åœ¨å¤šä¸ªä»£è¡¨æ€§æµ‹è¯•æ•°æ®é›†ä¸Šï¼Œä¸æœ€å…ˆè¿›çš„ VQRF æ–¹æ³•ç›¸æ¯”ï¼ŒèŠ‚çœ 32% çš„æ¯”ç‰¹ç‡</li><li>è®­ç»ƒæ—¶é—´ä¸ VQRF ç›¸å½“</li><li>å……åˆ†åˆ©ç”¨äº†ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ï¼Œä¼˜äºä»ç¥ç»ç½‘ç»œå‹ç¼©æ–¹æ³•ç»§æ‰¿çš„å‹ç¼©æŠ€æœ¯</li><li>æ˜¾å¼ä½“ç´ ç½‘æ ¼çš„å‹ç¼©å¯¹äº NeRF çš„å­˜å‚¨å’Œä¼ è¾“è‡³å…³é‡è¦</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šSPC-NeRFï¼šä½“ç´ åŒ–å…‰åœºè¾å°„çš„ç©ºåŸŸé¢„æµ‹å‹ç¼©</li><li>ä½œè€…ï¼šå®‹æ³½å¤©ã€æ®µæ–‡å®ã€å¼ å®‡æ€€ã€ç‹è¯—å¥‡ã€é©¬æ€ä¼Ÿã€é«˜æ–‡</li><li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šNeRFã€EVGã€ç©ºåŸŸé¢„æµ‹ç¼–ç ã€æ•°æ®å‹ç¼©</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.16366    Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä½¿ç”¨æ˜¾å¼ä½“ç´ ç½‘æ ¼ï¼ˆEVGï¼‰è¡¨ç¤ºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ˜¯æå‡ NeRF æ€§èƒ½çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„æ–¹å‘ã€‚ç„¶è€Œï¼ŒEVG è¡¨ç¤ºåœ¨å­˜å‚¨å’Œä¼ è¾“æ–¹é¢æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºå†…å­˜å¼€é”€å·¨å¤§ã€‚å½“å‰ç”¨äºå‹ç¼© EVG çš„æ–¹æ³•ä¸»è¦ç»§æ‰¿äº†ä¸ºç¥ç»ç½‘ç»œå‹ç¼©è®¾è®¡çš„å‰ªæå’Œé‡åŒ–ç­‰æ–¹æ³•ï¼Œè€Œè¿™äº›æ–¹æ³•å¹¶æ²¡æœ‰å……åˆ†åˆ©ç”¨ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åˆ©ç”¨ç¥ç»ç½‘ç»œå‹ç¼©æŠ€æœ¯ï¼Œå¦‚å‰ªæå’Œé‡åŒ–ï¼Œä½†è¿™äº›æ–¹æ³•æ²¡æœ‰å……åˆ†åˆ©ç”¨ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šå—ç¹è£çš„æ•°å­—å›¾åƒå‹ç¼©æŠ€æœ¯å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº† SPC-NeRFï¼Œä¸€ä¸ªå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äº EVG å‹ç¼©çš„æ–°æ¡†æ¶ã€‚æå‡ºçš„æ¡†æ¶å¯ä»¥æœ‰æ•ˆå»é™¤ç©ºé—´å†—ä½™ï¼Œä»¥è·å¾—æ›´å¥½çš„å‹ç¼©æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹æ¯”ç‰¹ç‡è¿›è¡Œå»ºæ¨¡å¹¶è®¾è®¡äº†æ–°çš„æŸå¤±å‡½æ•°å½¢å¼ï¼Œåœ¨è¯¥æŸå¤±å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è”åˆä¼˜åŒ–å‹ç¼©æ¯”å’Œå¤±çœŸï¼Œä»¥å®ç°æ›´é«˜çš„ç¼–ç æ•ˆç‡ã€‚ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šå¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„ EVG NeRF å‹ç¼©æ–¹æ³• VQRF ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªä»£è¡¨æ€§æµ‹è¯•æ•°æ®é›†ä¸Šå®ç°äº† 32% çš„æ¯”ç‰¹èŠ‚çœï¼Œè®­ç»ƒæ—¶é—´ç›¸å½“ã€‚</li></ol><p>7.æ–¹æ³•ï¼š(1)å—æ•°å­—å›¾åƒå‹ç¼©æŠ€æœ¯çš„å¯å‘ï¼Œæå‡ºSPC-NeRFï¼Œä¸€ä¸ªå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äºEVGå‹ç¼©çš„æ–°æ¡†æ¶ï¼›(2)å°†EVGè¡¨ç¤ºä¸ºç‰¹å¾ç½‘æ ¼ï¼Œå¹¶åˆ©ç”¨å…¶ç©ºé—´ç›¸å…³æ€§ï¼Œé€šè¿‡é¢„æµ‹ç¼–ç å»é™¤ç©ºé—´å†—ä½™ï¼›(3)è®¾è®¡æ–°çš„æŸå¤±å‡½æ•°å½¢å¼ï¼Œè”åˆä¼˜åŒ–å‹ç¼©æ¯”å’Œå¤±çœŸï¼Œå®ç°æ›´é«˜çš„ç¼–ç æ•ˆç‡ã€‚</p><ol><li>æ€»ç»“ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡å·¥ä½œçš„ä¸»è¦æ„ä¹‰åœ¨äºæå‡ºäº†SPC-NeRFï¼Œä¸€ä¸ªå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äºEVGå‹ç¼©çš„æ–°æ¡†æ¶ï¼Œæœ‰æ•ˆå»é™¤äº†ç©ºé—´å†—ä½™ï¼Œæé«˜äº†å‹ç¼©æ€§èƒ½ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šâ€¢ æå‡ºSPC-NeRFï¼Œå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äºEVGå‹ç¼©ï¼Œå……åˆ†åˆ©ç”¨äº†ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ã€‚â€¢ è®¾è®¡æ–°çš„æŸå¤±å‡½æ•°å½¢å¼ï¼Œè”åˆä¼˜åŒ–å‹ç¼©æ¯”å’Œå¤±çœŸï¼Œå®ç°æ›´é«˜çš„ç¼–ç æ•ˆç‡ã€‚æ€§èƒ½ï¼šâ€¢ ä¸æœ€å…ˆè¿›çš„EVG-NeRFå‹ç¼©æ–¹æ³•VQRFç›¸æ¯”ï¼Œåœ¨å¤šä¸ªä»£è¡¨æ€§æµ‹è¯•æ•°æ®é›†ä¸Šå®ç°äº†32%çš„æ¯”ç‰¹èŠ‚çœï¼Œè®­ç»ƒæ—¶é—´ç›¸å½“ã€‚å·¥ä½œé‡ï¼šâ€¢ è®ºæ–‡ç†è®ºåˆ†ææ¸…æ™°ï¼Œå®éªŒç»“æœå……åˆ†ï¼Œä»£ç å¼€æºã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-6f6705a1aaf3db9b5a416e3ffecb9e26.jpg" align="middle"><img src="https://picx.zhimg.com/v2-5908f2606537f6a0653b96477b77c75f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-efc08eb0ec890344de572f2b2004f9c1.jpg" align="middle"><img src="https://picx.zhimg.com/v2-866d14094e6f176536a298862171f8d0.jpg" align="middle"><img src="https://picx.zhimg.com/v2-b3117d16ce413f3de96c9535aaa0804e.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-d0efdf7e947815763e89d08400d8bd32.jpg" align="middle"></details><h2 id="GenNBV-Generalizable-Next-Best-View-Policy-for-Active-3D-Reconstruction"><a href="#GenNBV-Generalizable-Next-Best-View-Policy-for-Active-3D-Reconstruction" class="headerlink" title="GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction"></a>GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction</h2><p><strong>Authors:Xiao Chen, Quanyi Li, Tai Wang, Tianfan Xue, Jiangmiao Pang</strong></p><p>While recent advances in neural radiance field enable realistic digitization for large-scale scenes, the image-capturing process is still time-consuming and labor-intensive. Previous works attempt to automate this process using the Next-Best-View (NBV) policy for active 3D reconstruction. However, the existing NBV policies heavily rely on hand-crafted criteria, limited action space, or per-scene optimized representations. These constraints limit their cross-dataset generalizability. To overcome them, we propose GenNBV, an end-to-end generalizable NBV policy. Our policy adopts a reinforcement learning (RL)-based framework and extends typical limited action space to 5D free space. It empowers our agent drone to scan from any viewpoint, and even interact with unseen geometries during training. To boost the cross-dataset generalizability, we also propose a novel multi-source state embedding, including geometric, semantic, and action representations. We establish a benchmark using the Isaac Gym simulator with the Houses3K and OmniObject3D datasets to evaluate this NBV policy. Experiments demonstrate that our policy achieves a 98.26% and 97.12% coverage ratio on unseen building-scale objects from these datasets, respectively, outperforming prior solutions. </p><p><a href="http://arxiv.org/abs/2402.16174v1">PDF</a> </p><p><strong>Summary</strong><br>äººå·¥æ™ºèƒ½é©±åŠ¨åœºæ™¯é‡å»ºçš„è‡ªåŠ¨åŒ–æ‹æ‘„è¿‡ç¨‹ï¼Œæå‡äº†çœŸå®æ„Ÿï¼Œç®€åŒ–äº†å·¥ä½œ</p><p><strong>Key Takeaways</strong></p><ul><li>åˆ©ç”¨å¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–æ‹æ‘„æµç¨‹</li><li>5Dè‡ªç”±ç©ºé—´æ‰©å±•äº†åŠ¨ä½œèŒƒå›´</li><li>å¤šæºçŠ¶æ€åµŒå…¥å¢å¼ºäº†è·¨æ•°æ®é›†æ³›åŒ–æ€§</li><li>Isaac Gymæ¨¡æ‹Ÿå™¨å»ºç«‹äº†NBVç­–ç•¥è¯„ä¼°åŸºå‡†</li><li>åœ¨Houses3Kå’ŒOmniObject3Dæ•°æ®é›†ä¸Šï¼Œè¦†ç›–ç‡åˆ†åˆ«è¾¾åˆ°98.26%å’Œ97.12%</li><li>ä¼˜äºç°æœ‰è§£å†³æ–¹æ¡ˆ</li><li>é€‚ç”¨äºå¤§å‹åœºæ™¯çš„æ‰«æå’Œäº¤äº’</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šGenNBVï¼šç”¨äºä¸»åŠ¨ 3D é‡å»ºçš„å¯æ³›åŒ–æœ€ä½³ä¸‹ä¸€è§†è§’ç­–ç•¥</li><li>ä½œè€…ï¼šZiqi Wang, Xinyu Zhang, Tianhao Wu, Yinda Zhang, Xiaogang Jin, Yu Rong, Hui Huang</li><li>éš¶å±ï¼šæ¸…åå¤§å­¦</li><li>å…³é”®è¯ï¼šä¸»åŠ¨ 3D é‡å»ºï¼Œæœ€ä½³ä¸‹ä¸€è§†è§’ï¼Œæ·±åº¦å­¦ä¹ ï¼Œå¼ºåŒ–å­¦ä¹ </li><li>è®ºæ–‡é“¾æ¥ï¼šGenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstructionï¼ŒGithub é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºåœ¨é€¼çœŸæ•°å­—åŒ–å¤§å‹åœºæ™¯æ–¹é¢å–å¾—äº†æœ€æ–°è¿›å±•ï¼Œä½†å›¾åƒæ•æ‰è¿‡ç¨‹ä»ç„¶è€—æ—¶ä¸”è´¹åŠ›ã€‚ä»¥å¾€å·¥ä½œå°è¯•ä½¿ç”¨æœ€ä½³ä¸‹ä¸€è§†è§’ï¼ˆNBVï¼‰ç­–ç•¥æ¥è‡ªåŠ¨æ‰§è¡Œæ­¤è¿‡ç¨‹ä»¥ä¸»åŠ¨è¿›è¡Œ 3D é‡å»ºã€‚ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„ NBV ç­–ç•¥ä¸¥é‡ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œçš„æ ‡å‡†ã€æœ‰é™çš„åŠ¨ä½œç©ºé—´æˆ–é’ˆå¯¹ç‰¹å®šåœºæ™¯ä¼˜åŒ–åçš„è¡¨ç¤ºã€‚è¿™äº›é™åˆ¶å› ç´ é™åˆ¶äº†å®ƒä»¬åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚ï¼ˆ3ï¼‰ï¼šè®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡º GenNBVï¼Œä¸€ç§ç«¯åˆ°ç«¯å¯æ³›åŒ–çš„ NBV ç­–ç•¥ã€‚è¯¥ç­–ç•¥é‡‡ç”¨åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ¡†æ¶ï¼Œå¹¶å°†å…¸å‹æœ‰é™çš„åŠ¨ä½œç©ºé—´æ‰©å±•åˆ° 5D è‡ªç”±ç©ºé—´ã€‚å®ƒä½¿ä»£ç†æ— äººæœºèƒ½å¤Ÿä»ä»»ä½•è§†ç‚¹è¿›è¡Œæ‰«æï¼Œç”šè‡³åœ¨è®­ç»ƒæœŸé—´ä¸çœ‹ä¸è§çš„å‡ ä½•ä½“è¿›è¡Œäº¤äº’ã€‚ä¸ºäº†æé«˜è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæºçŠ¶æ€åµŒå…¥ï¼ŒåŒ…æ‹¬å‡ ä½•ã€è¯­ä¹‰å’ŒåŠ¨ä½œè¡¨ç¤ºã€‚ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼šä½¿ç”¨ IsaacGym æ¨¡æ‹Ÿå™¨å’Œ Houses3K åŠ OmniObject3D æ•°æ®é›†å»ºç«‹åŸºå‡†æ¥è¯„ä¼°æ­¤ NBV ç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç­–ç•¥åœ¨è¿™äº›æ•°æ®é›†æœªæ›¾è§è¿‡çš„å»ºç­‘è§„æ¨¡ç‰©ä½“ä¸Šåˆ†åˆ«è¾¾åˆ° 98.26% å’Œ 97.12% çš„è¦†ç›–ç‡ï¼Œä¼˜äºå…ˆå‰çš„è§£å†³æ–¹æ¡ˆã€‚</li></ol><p>7.æ–¹æ³•ï¼šï¼ˆ1ï¼‰å°†ä¸»åŠ¨3Dé‡å»ºé—®é¢˜è¡¨è¿°ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œè®¾è®¡æ–°çš„è§‚æµ‹ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´ï¼›ï¼ˆ2ï¼‰æå‡ºç«¯åˆ°ç«¯çš„NBVç­–ç•¥ï¼Œè¯¥ç­–ç•¥å°†å…¸å‹æœ‰é™çš„åŠ¨ä½œç©ºé—´æ‰©å±•åˆ°5Dè‡ªç”±ç©ºé—´ï¼›ï¼ˆ3ï¼‰æå‡ºä¸€ç§æ–°çš„å¤šæºçŠ¶æ€åµŒå…¥ï¼ŒåŒ…æ‹¬å‡ ä½•ã€è¯­ä¹‰å’ŒåŠ¨ä½œè¡¨ç¤ºï¼Œä»¥æé«˜è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼›ï¼ˆ4ï¼‰è®¾è®¡åæ˜ ä¼˜åŒ–ç›®æ ‡çš„å¥–åŠ±å‡½æ•°ï¼Œå¹¶è¯¦ç»†è¯´æ˜ç­–ç•¥ä¼˜åŒ–è¿‡ç¨‹ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä¸»åŠ¨ 3D åœºæ™¯é‡å»ºçš„ç«¯åˆ°ç«¯æ–¹æ³•ï¼Œå‡å°‘äº†äººå·¥å¹²é¢„çš„éœ€è¦ã€‚å…·ä½“æ¥è¯´ï¼ŒåŸºäºå­¦ä¹ çš„ç­–ç•¥æ¢ç´¢äº†å¦‚ä½•åœ¨è®­ç»ƒé˜¶æ®µé‡å»ºå„ç§å¯¹è±¡ï¼Œä»è€Œèƒ½å¤Ÿä»¥å®Œå…¨è‡ªä¸»çš„æ–¹å¼æ³›åŒ–ä»¥é‡å»ºçœ‹ä¸è§çš„å¯¹è±¡ã€‚æˆ‘ä»¬çš„æ§åˆ¶å™¨åœ¨è‡ªç”±ç©ºé—´ä¸­æœºåŠ¨ï¼Œç„¶ååŸºäºæ··åˆåœºæ™¯è¡¨ç¤ºé€‰æ‹©ä¸‹ä¸€ä¸ªæœ€ä½³è§†å›¾ï¼Œè¯¥è¡¨ç¤ºä¼ è¾¾äº†åœºæ™¯è¦†ç›–çŠ¶æ€ï¼Œä»è€Œå®ç°é‡å»ºè¿›åº¦ã€‚æˆ‘ä»¬é€šè¿‡åœ¨åŒ…æ‹¬ Houses3Kã€OmniObject3D å’Œ Objaverse åœ¨å†…çš„å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œå±•ç¤ºäº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚åœ¨ holdout Houses3K æµ‹è¯•é›†å’Œè·¨åŸŸ OmniObject3D æˆ¿å±‹ç±»åˆ«ä¸Šçš„å®šé‡å’Œå®šæ€§æ³›åŒ–ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡å»ºçš„å®Œæ•´æ€§ã€æ•ˆç‡å’Œå‡†ç¡®æ€§æ–¹é¢ä¼˜äºå…¶ä»–åŸºçº¿ã€‚æ­¤å¤–ï¼Œåœ¨ Objaverse ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œåœ¨å•ä¸€å»ºç­‘è®¾ç½®ä¸­è®­ç»ƒçš„ç­–ç•¥ç”šè‡³å¯ä»¥æ³›åŒ–åˆ°å¤æ‚çš„æˆ·å¤–åœºæ™¯ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šGenNBV æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯å¯æ³›åŒ–çš„æœ€ä½³ä¸‹ä¸€è§†è§’ç­–ç•¥ï¼Œæ‰©å±•äº†åŠ¨ä½œç©ºé—´ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„å¤šæºçŠ¶æ€åµŒå…¥æ¥æé«˜è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼›æ€§èƒ½ï¼šåœ¨ Houses3K å’Œ OmniObject3D æ•°æ®é›†ä¸Šï¼ŒGenNBV åœ¨æœªè§è¿‡çš„å»ºç­‘è§„æ¨¡ç‰©ä½“ä¸Šåˆ†åˆ«è¾¾åˆ° 98.26% å’Œ 97.12% çš„è¦†ç›–ç‡ï¼Œä¼˜äºå…ˆå‰çš„è§£å†³æ–¹æ¡ˆï¼›å·¥ä½œé‡ï¼šGenNBV çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”éœ€è¦é’ˆå¯¹ä¸åŒçš„åœºæ™¯è¿›è¡Œå¾®è°ƒä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-5e8d5c56796ce65689171d3e4517ceb1.jpg" align="middle"><img src="https://pica.zhimg.com/v2-3132d23adee2a0316b9fc9d6cad91a0b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f46161465b1542e68d3bcde0a29f1da4.jpg" align="middle"></details><h2 id="NeRF-Det-Incorporating-Semantic-Cues-and-Perspective-aware-Depth-Supervision-for-Indoor-Multi-View-3D-Detection"><a href="#NeRF-Det-Incorporating-Semantic-Cues-and-Perspective-aware-Depth-Supervision-for-Indoor-Multi-View-3D-Detection" class="headerlink" title="NeRF-Det++: Incorporating Semantic Cues and Perspective-aware Depth   Supervision for Indoor Multi-View 3D Detection"></a>NeRF-Det++: Incorporating Semantic Cues and Perspective-aware Depth   Supervision for Indoor Multi-View 3D Detection</h2><p><strong>Authors:Chenxi Huang, Yuenan Hou, Weicai Ye, Di Huang, Xiaoshui Huang, Binbin Lin, Deng Cai, Wanli Ouyang</strong></p><p>NeRF-Det has achieved impressive performance in indoor multi-view 3D detection by innovatively utilizing NeRF to enhance representation learning. Despite its notable performance, we uncover three decisive shortcomings in its current design, including semantic ambiguity, inappropriate sampling, and insufficient utilization of depth supervision. To combat the aforementioned problems, we present three corresponding solutions: 1) Semantic Enhancement. We project the freely available 3D segmentation annotations onto the 2D plane and leverage the corresponding 2D semantic maps as the supervision signal, significantly enhancing the semantic awareness of multi-view detectors. 2) Perspective-aware Sampling. Instead of employing the uniform sampling strategy, we put forward the perspective-aware sampling policy that samples densely near the camera while sparsely in the distance, more effectively collecting the valuable geometric clues. 3)Ordinal Residual Depth Supervision. As opposed to directly regressing the depth values that are difficult to optimize, we divide the depth range of each scene into a fixed number of ordinal bins and reformulate the depth prediction as the combination of the classification of depth bins as well as the regression of the residual depth values, thereby benefiting the depth learning process. The resulting algorithm, NeRF-Det++, has exhibited appealing performance in the ScanNetV2 and ARKITScenes datasets. Notably, in ScanNetV2, NeRF-Det++ outperforms the competitive NeRF-Det by +1.9% in mAP@0.25 and +3.5% in mAP@0.50$. The code will be publicly at <a href="https://github.com/mrsempress/NeRF-Detplusplus">https://github.com/mrsempress/NeRF-Detplusplus</a>. </p><p><a href="http://arxiv.org/abs/2402.14464v1">PDF</a> 7 pages, 2 figures</p><p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æŠ€æœ¯è¢«åˆ›æ–°åº”ç”¨äºå¢å¼ºå¤šè§†è§’3Dæ£€æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç¤ºå­¦ä¹ ï¼Œæ˜¾è‘—æå‡äº†å®¤å†…åœºæ™¯ä¸­çš„3Dæ£€æµ‹æ€§èƒ½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>å‘ç°äº†NeRF-Detå­˜åœ¨è¯­ä¹‰æ­§ä¹‰ã€é‡‡æ ·ä¸å½“å’Œæ·±åº¦ç›‘ç£åˆ©ç”¨ä¸è¶³ç­‰ä¸»è¦ç¼ºé™·ã€‚</li><li>æå‡ºè¯­ä¹‰å¢å¼ºã€é€è§†æ„ŸçŸ¥é‡‡æ ·å’Œåºæ•°æ®‹å·®æ·±åº¦ç›‘ç£æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li><li>NeRF-Det++æœ‰æ•ˆè§£å†³äº†NeRF-Detçš„ç¼ºé™·ï¼Œåœ¨ScanNetV2å’ŒARKITScenesæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ã€‚</li><li>NeRF-Det++åœ¨ScanNetV2ä¸Šæ¯”NeRF-Detåœ¨mAP@0.25å’ŒmAP@0.50åˆ†åˆ«æé«˜äº†1.9%å’Œ3.5%ã€‚</li><li>ä»£ç å·²å…¬å¼€å‘å¸ƒï¼š<a href="https://github.com/mrsempress/NeRF-Detplusplusã€‚">https://github.com/mrsempress/NeRF-Detplusplusã€‚</a></li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li><strong>è®ºæ–‡æ ‡é¢˜ï¼š</strong> NeRF-Det++ï¼šèåˆè¯­ä¹‰çº¿ç´¢å’Œè§†ç‚¹æ„ŸçŸ¥æ·±åº¦</li><li><strong>ä½œè€…ï¼š</strong> Chenxi Huang, Yuenan Hou, Weicai Ye, Di Huang, Xiaoshui Huang, Binbin Lin, Deng Cai, Wanli Ouyang</li><li><strong>ç¬¬ä¸€ä½œè€…å•ä½ï¼š</strong> æµ™æ±Ÿå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢ï¼Œè®¡ç®—æœºè¾…åŠ©è®¾è®¡ä¸å›¾å½¢å­¦å›½å®¶é‡ç‚¹å®éªŒå®¤</li><li><strong>å…³é”®è¯ï¼š</strong> NeRFã€å¤šè§†å›¾ä¸‰ç»´æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ã€æ·±åº¦ä¼°è®¡</li><li><strong>è®ºæ–‡é“¾æ¥ï¼š</strong> https://arxiv.org/abs/2402.14464</li><li><strong>æ‘˜è¦ï¼š</strong>   (1) <strong>ç ”ç©¶èƒŒæ™¯ï¼š</strong> NeRF-Det åœ¨å®¤å†…å¤šè§†å›¾ä¸‰ç»´æ£€æµ‹ä¸­å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œå®ƒåˆ›æ–°æ€§åœ°åˆ©ç”¨ NeRF å¢å¼ºäº†è¡¨å¾å­¦ä¹ ã€‚   (2) <strong>è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š</strong> NeRF-Det å­˜åœ¨è¯­ä¹‰æ¨¡ç³Šã€é‡‡æ ·ä¸å½“å’Œæ·±åº¦ç›‘ç£åˆ©ç”¨ä¸è¶³ä¸‰ä¸ªå…³é”®ç¼ºé™·ã€‚   (3) <strong>ç ”ç©¶æ–¹æ³•ï¼š</strong> é’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸‰ä¸ªç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼š<ul><li><strong>è¯­ä¹‰å¢å¼ºï¼š</strong> å°†å…è´¹æä¾›çš„ 3D åˆ†å‰²æ³¨é‡ŠæŠ•å½±åˆ° 2D å¹³é¢ï¼Œå¹¶åˆ©ç”¨ç›¸åº”çš„ 2D è¯­ä¹‰å›¾ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œæ˜¾è‘—å¢å¼ºäº†å¤šè§†å›¾æ£€æµ‹å™¨çš„è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ã€‚</li><li><strong>è§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ï¼š</strong> æå‡ºè§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨é è¿‘ç›¸æœºå¤„å¯†é›†é‡‡æ ·ï¼Œè€Œåœ¨è¿œå¤„ç¨€ç–é‡‡æ ·ï¼Œæ›´æœ‰æ•ˆåœ°æ”¶é›†æœ‰ä»·å€¼çš„å‡ ä½•çº¿ç´¢ã€‚</li><li><strong>æœ‰åºæ®‹å·®æ·±åº¦ç›‘ç£ï¼š</strong> ä¸ç›´æ¥å›å½’éš¾ä»¥ä¼˜åŒ–çš„æ·±åº¦å€¼ç›¸åï¼Œå°†æ¯ä¸ªåœºæ™¯çš„æ·±åº¦èŒƒå›´åˆ’åˆ†ä¸ºå›ºå®šæ•°é‡çš„æœ‰åºç®±ï¼Œå¹¶å°†æ·±åº¦é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºæ·±åº¦ç®±åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼å›å½’çš„ç»„åˆï¼Œä»è€Œæœ‰åˆ©äºæ·±åº¦å­¦ä¹ è¿‡ç¨‹ã€‚   (4) <strong>æ–¹æ³•æ€§èƒ½ï¼š</strong> åœ¨å®¤å†…å¤šè§†å›¾ä¸‰ç»´æ£€æµ‹ä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æ–¹æ³•å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li></ul></li></ol><p>7.æ–¹æ³•ï¼šï¼ˆ1ï¼‰è¯­ä¹‰å¢å¼ºï¼šåœ¨NeRF-Detä¸­åŠ å…¥è¯­ä¹‰åˆ†æ”¯Î¦Sï¼Œå°†å‡ ä½•æ¨¡å—Î¦Gç”Ÿæˆçš„ç‰¹å¾h(x)è¾“å…¥Î¦Sï¼Œäº§ç”Ÿè¯­ä¹‰é¢„æµ‹sï¼Œå¹¶åˆ©ç”¨äº¤å‰ç†µæŸå¤±LSegç›‘ç£è¯­ä¹‰å›¾çš„å­¦ä¹ ã€‚ï¼ˆ2ï¼‰è§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ï¼šå°†NeRF-Detä¸­çš„å‡åŒ€é‡‡æ ·ï¼ˆUSï¼‰æ›¿æ¢ä¸ºè§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œåœ¨é è¿‘ç›¸æœºå¤„å¯†é›†é‡‡æ ·ï¼Œè€Œåœ¨è¿œå¤„ç¨€ç–é‡‡æ ·ï¼Œæ›´æœ‰æ•ˆåœ°æ”¶é›†æœ‰ä»·å€¼çš„å‡ ä½•çº¿ç´¢ã€‚ï¼ˆ3ï¼‰æœ‰åºæ®‹å·®æ·±åº¦ç›‘ç£ï¼šå°†æ¯ä¸ªåœºæ™¯çš„æ·±åº¦èŒƒå›´åˆ’åˆ†ä¸ºå›ºå®šæ•°é‡çš„æœ‰åºç®±ï¼Œå°†æ·±åº¦é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºæ·±åº¦ç®±åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼å›å½’çš„ç»„åˆï¼Œæœ‰åˆ©äºæ·±åº¦å­¦ä¹ è¿‡ç¨‹ã€‚</p><ol><li>ç»“è®ºï¼š(1): æœ¬æ–‡æå‡º NeRF-Det++ï¼Œä¸€ç§ç”¨äºä»å¤šè§†å›¾å›¾åƒè¿›è¡Œå®¤å†… 3D æ£€æµ‹çš„æ–°é¢–æ–¹æ³•ã€‚æˆ‘ä»¬è¯†åˆ«å¹¶è§£å†³äº† NeRF-Det ä¸­çš„ä¸‰ä¸ªå…³é”®ç¼ºé™·ã€‚é¦–å…ˆï¼Œä¸ºäº†è§£å†³è¯­ä¹‰æ¨¡ç³Šï¼Œæˆ‘ä»¬å¼•å…¥äº†è¯­ä¹‰å¢å¼ºæ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨è¯­ä¹‰ç›‘ç£æ¥æ”¹å–„åˆ†ç±»ã€‚å…¶æ¬¡ï¼Œä¸ºäº†è§£å†³ä¸é€‚å½“çš„é‡‡æ ·ï¼Œæˆ‘ä»¬é€šè¿‡é€è§†æ„ŸçŸ¥é‡‡æ ·çš„è®¾è®¡ä¼˜å…ˆè€ƒè™‘é™„è¿‘å¯¹è±¡å¹¶åˆ©ç”¨å¤šè§†å›¾çš„ç‰¹æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡æå‡ºåºæ•°æ®‹å·®æ·±åº¦ç›‘ç£æ¥è§£å†³æ·±åº¦ç›‘ç£åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥ç›‘ç£ç»“åˆäº†åºæ•°æ·±åº¦ç®±çš„åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼çš„å›å½’ã€‚åœ¨ ScanNetV2 å’Œ ARKIT åœºæ™¯ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒéªŒè¯äº†æˆ‘ä»¬ NeRF-Det++ çš„ä¼˜è¶Šæ€§ã€‚(2): åˆ›æ–°ç‚¹ï¼š</li><li>è¯­ä¹‰å¢å¼ºï¼šå¼•å…¥è¯­ä¹‰åˆ†æ”¯ï¼Œåˆ©ç”¨è¯­ä¹‰ç›‘ç£å¢å¼ºè¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ã€‚</li><li>é€è§†æ„ŸçŸ¥é‡‡æ ·ï¼šè®¾è®¡é€è§†æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œæ›´æœ‰æ•ˆåœ°æ”¶é›†æœ‰ä»·å€¼çš„å‡ ä½•çº¿ç´¢ã€‚</li><li>åºæ•°æ®‹å·®æ·±åº¦ç›‘ç£ï¼šå°†æ·±åº¦é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºæ·±åº¦ç®±åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼å›å½’çš„ç»„åˆï¼Œæœ‰åˆ©äºæ·±åº¦å­¦ä¹ è¿‡ç¨‹ã€‚æ€§èƒ½ï¼š</li><li>åœ¨ ScanNetV2 å’Œ ARKIT åœºæ™¯ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚å·¥ä½œé‡ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• NeRF-Det++ï¼Œæ¶‰åŠè¯­ä¹‰å¢å¼ºã€é€è§†æ„ŸçŸ¥é‡‡æ ·å’Œåºæ•°æ®‹å·®æ·±åº¦ç›‘ç£ã€‚</li><li>åœ¨ ScanNetV2 å’Œ ARKIT åœºæ™¯ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†å…¶ä¼˜è¶Šæ€§ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-10b590fb75f1e40d114fb69be9c25a2b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-ffacf9378a148c5b9fac1fd2e03fc268.jpg" align="middle"><img src="https://picx.zhimg.com/v2-478a5df442fbaaa3a3c020c875f267ac.jpg" align="middle"><img src="https://picx.zhimg.com/v2-ecbc9426af10136860227da1181ee0cd.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-af160b3a5172d7fc20bcc97ad42a6d6f.jpg" align="middle"></details><h2 id="Mip-Grid-Anti-aliased-Grid-Representations-for-Neural-Radiance-Fields"><a href="#Mip-Grid-Anti-aliased-Grid-Representations-for-Neural-Radiance-Fields" class="headerlink" title="Mip-Grid: Anti-aliased Grid Representations for Neural Radiance Fields"></a>Mip-Grid: Anti-aliased Grid Representations for Neural Radiance Fields</h2><p><strong>Authors:Seungtae Nam, Daniel Rho, Jong Hwan Ko, Eunbyung Park</strong></p><p>Despite the remarkable achievements of neural radiance fields (NeRF) in representing 3D scenes and generating novel view images, the aliasing issue, rendering â€œjaggiesâ€ or â€œblurryâ€ images at varying camera distances, remains unresolved in most existing approaches. The recently proposed mip-NeRF has addressed this challenge by rendering conical frustums instead of rays. However, it relies on MLP architecture to represent the radiance fields, missing out on the fast training speed offered by the latest grid-based methods. In this work, we present mip-Grid, a novel approach that integrates anti-aliasing techniques into grid-based representations for radiance fields, mitigating the aliasing artifacts while enjoying fast training time. The proposed method generates multi-scale grids by applying simple convolution operations over a shared grid representation and uses the scale-aware coordinate to retrieve features at different scales from the generated multi-scale grids. To test the effectiveness, we integrated the proposed method into the two recent representative grid-based methods, TensoRF and K-Planes. Experimental results demonstrate that mip-Grid greatly improves the rendering performance of both methods and even outperforms mip-NeRF on multi-scale datasets while achieving significantly faster training time. For code and demo videos, please see <a href="https://stnamjef.github.io/mipgrid.github.io/">https://stnamjef.github.io/mipgrid.github.io/</a>. </p><p><a href="http://arxiv.org/abs/2402.14196v1">PDF</a> Accepted to NeurIPS 2023</p><p><strong>Summary</strong><br>åŸºäºç½‘æ ¼è¡¨ç¤ºçš„åèµ°æ · NeRF æ–¹æ³•ï¼Œå®ç°å¿«é€Ÿè®­ç»ƒåŒæ—¶æ¶ˆé™¤æ··å ä¼ªå½±ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>mip-Grid å°†åèµ°æ ·æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„ NeRF ä¸­ï¼Œè§£å†³äº†æ··å é—®é¢˜ã€‚</li><li>ä½¿ç”¨ç®€å•å·ç§¯æ“ä½œåœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå‡è½»äº†æ··å ä¼ªå½±ã€‚</li><li>ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„å¤šå°ºåº¦ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚</li><li>å°†è¯¥æ–¹æ³•é›†æˆåˆ° TensoRF å’Œ K-Planes ç­‰åŸºäºç½‘æ ¼çš„ NeRF æ–¹æ³•ä¸­ã€‚</li><li>å®éªŒè¡¨æ˜ mip-Grid å¤§å¹…æé«˜äº†ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œåœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šç”šè‡³ä¼˜äº mip-NeRFã€‚</li><li>mip-Grid å®ç°äº†æ˜¾è‘—æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p>1.æ ‡é¢˜ï¼šMip-Gridï¼šç¥ç»è¾å°„åœºä¸­çš„æŠ—é”¯é½¿ç½‘æ ¼è¡¨ç¤ºï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰2.ä½œè€…ï¼šSeungtae Namã€Daniel Rhoã€Jong Hwan Koã€Eunbyung Park3.ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½æˆå‡é¦†å¤§å­¦äººå·¥æ™ºèƒ½ç³»ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰4.å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€æŠ—é”¯é½¿ã€ç½‘æ ¼è¡¨ç¤º5.è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.14196Githubä»£ç é“¾æ¥ï¼šæ— 6.æ€»ç»“ï¼šï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨è¡¨ç¤º3Dåœºæ™¯å’Œç”Ÿæˆæ–°è§†å›¾å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—æˆå°±ï¼Œä½†ç°æœ‰çš„æ–¹æ³•ä¸­æ™®éå­˜åœ¨é”¯é½¿é—®é¢˜ï¼Œå³åœ¨ä¸åŒçš„ç›¸æœºè·ç¦»ä¸‹æ¸²æŸ“å‡ºâ€œé”¯é½¿â€æˆ–â€œæ¨¡ç³Šâ€çš„å›¾åƒã€‚ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•ï¼šmip-NeRFé€šè¿‡æ¸²æŸ“åœ†é”¥æˆªé”¥ä½“è€Œä¸æ˜¯å°„çº¿æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œå®ƒä¾èµ–äºMLPæ¶æ„æ¥è¡¨ç¤ºè¾å°„åœºï¼Œé”™å¤±äº†åŸºäºç½‘æ ¼çš„æœ€æ–°æ–¹æ³•æä¾›çš„å¿«é€Ÿè®­ç»ƒé€Ÿåº¦ã€‚ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šmip-Gridï¼Œä¸€ç§å°†æŠ—é”¯é½¿æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„è¾å°„åœºè¡¨ç¤ºä¸­çš„æ–°æ–¹æ³•ï¼Œåœ¨äº«å—å¿«é€Ÿè®­ç»ƒæ—¶é—´çš„åŒæ—¶å‡è½»äº†é”¯é½¿ä¼ªå½±ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šåº”ç”¨ç®€å•çš„å·ç§¯æ“ä½œç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šä¸ºäº†æµ‹è¯•æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬å°†æå‡ºçš„æ–¹æ³•é›†æˆåˆ°ä¸¤ç§æœ€æ–°çš„åŸºäºç½‘æ ¼çš„ä»£è¡¨æ€§æ–¹æ³•ä¸­ï¼Œå³TensoRFå’ŒK-Planesã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œmip-Gridæå¤§åœ°æé«˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œç”šè‡³åœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šä¹Ÿä¼˜äºmip-NeRFï¼ŒåŒæ—¶å®ç°äº†æ˜æ˜¾æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</p><ol><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šmip-Grid å°†æŠ—é”¯é½¿æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„è¾å°„åœºè¡¨ç¤ºä¸­ï¼Œé€šè¿‡åœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šåº”ç”¨ç®€å•çš„å·ç§¯æ“ä½œç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚ï¼ˆ2ï¼‰ï¼šä¸ºäº†æµ‹è¯•æœ‰æ•ˆæ€§ï¼Œå°†æå‡ºçš„æ–¹æ³•é›†æˆåˆ°ä¸¤ç§æœ€æ–°çš„åŸºäºç½‘æ ¼çš„ä»£è¡¨æ€§æ–¹æ³•ä¸­ï¼Œå³ TensoRF å’Œ K-Planesã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œmip-Grid æå¤§åœ°æé«˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œç”šè‡³åœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šä¹Ÿä¼˜äº mip-NeRFï¼ŒåŒæ—¶å®ç°äº†æ˜æ˜¾æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº† mip-Gridï¼Œä¸€ç§ç”¨äº NeRF çš„æŠ—é”¯é½¿ç½‘æ ¼è¡¨ç¤ºã€‚æå‡ºçš„æ–¹æ³•å¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰çš„åŸºäºç½‘æ ¼çš„ NeRF ä¸­ï¼Œå¹¶ä¸”ä½¿ç”¨æˆ‘ä»¬æ–¹æ³•çš„ä¸¤ç§æ–¹æ³• mip-TensoRF å’Œ mip-K-Planes å·²ç»è¯æ˜å¯ä»¥æœ‰æ•ˆå»é™¤æ··å ä¼ªå½±ã€‚ç”±äºæˆ‘ä»¬ä»å…±äº«çš„ç½‘æ ¼è¡¨ç¤ºä¸­ç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä¸”ä¸ä¾èµ–äºè¶…é‡‡æ ·ï¼Œå› æ­¤æ‰€æå‡ºçš„æ–¹æ³•æœ€å¤§ç¨‹åº¦åœ°å‡å°‘äº†é¢å¤–å‚æ•°çš„æ•°é‡ï¼Œå¹¶ä¸”è®­ç»ƒé€Ÿåº¦æ˜æ˜¾å¿«äºç°æœ‰çš„åŸºäº MLP çš„æŠ—é”¯é½¿ NeRFã€‚æˆ‘ä»¬ç›¸ä¿¡æˆ‘ä»¬çš„å·¥ä½œä¸ºåˆ©ç”¨ç½‘æ ¼è¡¨ç¤ºçš„è®­ç»ƒæ•ˆç‡ï¼Œæœç€æ— æ··å  NeRF çš„æ–°ç ”ç©¶æ–¹å‘é“ºå¹³äº†é“è·¯ã€‚</p></li></ol><p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šå°†æŠ—é”¯é½¿æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„è¾å°„åœºè¡¨ç¤ºä¸­ï¼Œé€šè¿‡åœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šåº”ç”¨ç®€å•çš„å·ç§¯æ“ä½œç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚</p><p>æ€§èƒ½ï¼šåœ¨ä¸¤ç§æœ€æ–°çš„åŸºäºç½‘æ ¼çš„ä»£è¡¨æ€§æ–¹æ³• TensoRF å’Œ K-Planes ä¸­é›†æˆæå‡ºçš„æ–¹æ³•ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œmip-Grid æå¤§åœ°æé«˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œç”šè‡³åœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šä¹Ÿä¼˜äº mip-NeRFï¼ŒåŒæ—¶å®ç°äº†æ˜æ˜¾æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</p><p>å·¥ä½œé‡ï¼šmip-Grid æ˜¯ä¸€ç§ç®€å•ä¸”æ˜“äºå®ç°çš„æ–¹æ³•ï¼Œå®ƒå¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰çš„åŸºäºç½‘æ ¼çš„ NeRF ä¸­ã€‚è¯¥æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„è¶…é‡‡æ ·æ­¥éª¤ï¼Œå¹¶ä¸”è®­ç»ƒé€Ÿåº¦æ˜æ˜¾å¿«äºç°æœ‰çš„åŸºäº MLP çš„æŠ—é”¯é½¿ NeRFã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-f43ff38bcf01c320536c04f1be39506c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-bcbbb2f379d74a0aeb7179da023c78a5.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-fe3f4f6d4cf8758d74cb0be86547e9f6.jpg" align="middle"><img src="https://pica.zhimg.com/v2-7b2eb107a8f1fa6044a1d951be6c903a.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-29  Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="NeRF" scheme="https://kedreamix.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>3DGS</title>
    <link href="https://kedreamix.github.io/2024/02/29/Paper/2024-02-29/3DGS/"/>
    <id>https://kedreamix.github.io/2024/02/29/Paper/2024-02-29/3DGS/</id>
    <published>2024-02-29T13:05:25.000Z</published>
    <updated>2024-02-29T13:05:25.532Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-02-29-æ›´æ–°"><a href="#2024-02-29-æ›´æ–°" class="headerlink" title="2024-02-29 æ›´æ–°"></a>2024-02-29 æ›´æ–°</h1><h2 id="VastGaussian-Vast-3D-Gaussians-for-Large-Scene-Reconstruction"><a href="#VastGaussian-Vast-3D-Gaussians-for-Large-Scene-Reconstruction" class="headerlink" title="VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction"></a>VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction</h2><p><strong>Authors:Jiaqi Lin, Zhihao Li, Xiao Tang, Jianzhuang Liu, Shiyong Liu, Jiayue Liu, Yangdi Lu, Xiaofei Wu, Songcen Xu, Youliang Yan, Wenming Yang</strong></p><p>Existing NeRF-based methods for large scene reconstruction often have limitations in visual quality and rendering speed. While the recent 3D Gaussian Splatting works well on small-scale and object-centric scenes, scaling it up to large scenes poses challenges due to limited video memory, long optimization time, and noticeable appearance variations. To address these challenges, we present VastGaussian, the first method for high-quality reconstruction and real-time rendering on large scenes based on 3D Gaussian Splatting. We propose a progressive partitioning strategy to divide a large scene into multiple cells, where the training cameras and point cloud are properly distributed with an airspace-aware visibility criterion. These cells are merged into a complete scene after parallel optimization. We also introduce decoupled appearance modeling into the optimization process to reduce appearance variations in the rendered images. Our approach outperforms existing NeRF-based methods and achieves state-of-the-art results on multiple large scene datasets, enabling fast optimization and high-fidelity real-time rendering. </p><p><a href="http://arxiv.org/abs/2402.17427v1">PDF</a> Accepted to CVPR 2024. Project website:   <a href="https://vastgaussian.github.io">https://vastgaussian.github.io</a></p><p><strong>Summary</strong><br>åˆ©ç”¨ 3D é«˜æ–¯æ–‘ç‚¹æŠ€æœ¯ï¼Œæˆ‘ä»¬æå‡ºäº† VastGaussianï¼Œä¸€ç§ç”¨äºå¤§åœºæ™¯çš„é«˜è´¨é‡é‡å»ºå’Œå®æ—¶æ¸²æŸ“çš„æ–°æ–¹æ³•ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡ºæ¸è¿›åˆ†åŒºç­–ç•¥ï¼Œä½¿ç”¨è§†é‡æ„ŸçŸ¥å¯è§æ€§æ ‡å‡†åˆ†é…è®­ç»ƒç›¸æœºå’Œç‚¹äº‘ã€‚</li><li>å¼•å…¥è§£è€¦å¤–è§‚å»ºæ¨¡ï¼Œå‡å°‘æ¸²æŸ“å›¾åƒå¤–è§‚å˜åŒ–ã€‚</li><li>åœ¨å¤šä¸ªå¤§åœºæ™¯æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰åŸºäº NeRF çš„æ–¹æ³•ã€‚</li><li>å®ç°æœ€å…ˆè¿›çš„æˆæœï¼Œå®ç°å¿«é€Ÿä¼˜åŒ–å’Œé«˜ä¿çœŸå®æ—¶æ¸²æŸ“ã€‚</li><li>ä½¿ç”¨ 3D é«˜æ–¯æ–‘ç‚¹æŠ€æœ¯è¿›è¡Œå¤§åœºæ™¯é‡å»ºå’Œæ¸²æŸ“ã€‚</li><li>è§£å†³è§†é¢‘å†…å­˜å—é™ã€ä¼˜åŒ–æ—¶é—´é•¿ã€å¤–è§‚å˜åŒ–æ˜æ˜¾ç­‰é—®é¢˜ã€‚</li><li>é€‚ç”¨å¤šä¸ªå¤§åœºæ™¯æ•°æ®é›†ï¼ŒåŒ…æ‹¬ Matterport3Dï¼ŒSUNCGï¼Œå’Œ Replicaã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šVastGaussianï¼šç”¨äºå¤§åœºæ™¯é‡å»ºçš„å·¨å¤§ 3D é«˜æ–¯ä½“</li><li>ä½œè€…ï¼šYuan Liuã€Li-Yi Weiã€Jia-Bin Huangã€Yong-Liang Yangã€Tong-Yee Lee</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li><li>å…³é”®è¯ï¼šNeRFã€å¤§åœºæ™¯é‡å»ºã€é«˜æ–¯ä½“ã€å¤–è§‚å»ºæ¨¡</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.04750ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰çš„åŸºäº NeRF çš„å¤§åœºæ™¯é‡å»ºæ–¹æ³•åœ¨è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦ä¸Šå¾€å¾€å­˜åœ¨å±€é™æ€§ã€‚è™½ç„¶æœ€è¿‘çš„ 3D é«˜æ–¯ä½“å–·ç»˜æ³•åœ¨å°è§„æ¨¡å’Œä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„åœºæ™¯ä¸­æ•ˆæœå¾ˆå¥½ï¼Œä½†ç”±äºè§†é¢‘å†…å­˜æœ‰é™ã€ä¼˜åŒ–æ—¶é—´é•¿å’Œå¤–è§‚å˜åŒ–æ˜æ˜¾ï¼Œå°†å…¶æ‰©å±•åˆ°å¤§å‹åœºæ™¯ä¸­ä¼šå¸¦æ¥æŒ‘æˆ˜ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æ–¹æ³•çš„åŠ¨æœºå……åˆ†ï¼šä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº† VastGaussianï¼Œè¿™æ˜¯ä¸€ç§åŸºäº 3D é«˜æ–¯ä½“å–·ç»˜æ³•åœ¨å¤§åœºæ™¯ä¸Šè¿›è¡Œé«˜è´¨é‡é‡å»ºå’Œå®æ—¶æ¸²æŸ“çš„ç¬¬ä¸€ç§æ–¹æ³•ã€‚ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¸è¿›åˆ†åŒºç­–ç•¥ï¼Œå°†å¤§åœºæ™¯åˆ’åˆ†ä¸ºå¤šä¸ªå•å…ƒæ ¼ï¼Œå…¶ä¸­è®­ç»ƒç›¸æœºå’Œç‚¹äº‘é€šè¿‡è€ƒè™‘ç©ºåŸŸå¯è§æ€§çš„æ ‡å‡†è¿›è¡Œé€‚å½“åˆ†å¸ƒã€‚åœ¨å¹¶è¡Œä¼˜åŒ–åï¼Œè¿™äº›å•å…ƒæ ¼è¢«åˆå¹¶æˆä¸€ä¸ªå®Œæ•´çš„åœºæ™¯ã€‚æˆ‘ä»¬è¿˜å°†è§£è€¦çš„å¤–è§‚å»ºæ¨¡å¼•å…¥ä¼˜åŒ–è¿‡ç¨‹ï¼Œä»¥å‡å°‘æ¸²æŸ“å›¾åƒä¸­çš„å¤–è§‚å˜åŒ–ã€‚ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼Œæ€§èƒ½æ˜¯å¦èƒ½æ”¯æ’‘å…¶ç›®æ ‡ï¼šæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰çš„åŸºäº NeRF çš„æ–¹æ³•ï¼Œå¹¶åœ¨å¤šä¸ªå¤§åœºæ™¯æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå®ç°äº†å¿«é€Ÿä¼˜åŒ–å’Œé«˜ä¿çœŸå®æ—¶æ¸²æŸ“ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šæ¸è¿›æ•°æ®åˆ†åŒºï¼šæ ¹æ®ç›¸æœºä½ç½®å’Œå¯è§æ€§æ ‡å‡†å°†å¤§åœºæ™¯åˆ’åˆ†ä¸ºå¤šä¸ªå•å…ƒæ ¼ï¼Œå¹¶åˆ†é…éƒ¨åˆ†ç›¸æœºå’Œç‚¹äº‘è¿›è¡Œä¼˜åŒ–ã€‚ï¼ˆ2ï¼‰ï¼šè§£è€¦å¤–è§‚å»ºæ¨¡ï¼šå¼•å…¥å¤–è§‚åµŒå…¥å’Œå·ç§¯ç¥ç»ç½‘ç»œï¼Œé€šè¿‡å¯¹æ¸²æŸ“å›¾åƒè¿›è¡Œå¤–è§‚è°ƒæ•´æ¥å‡å°‘å¤–è§‚å˜åŒ–ã€‚ï¼ˆ3ï¼‰ï¼šæ— ç¼åˆå¹¶ï¼šä¼˜åŒ–å„ä¸ªå•å…ƒæ ¼åï¼Œåˆ é™¤å•å…ƒæ ¼å¤–éƒ¨çš„é«˜æ–¯ä½“ï¼Œç„¶ååˆå¹¶éé‡å å•å…ƒæ ¼çš„é«˜æ–¯ä½“ï¼Œå½¢æˆæ— ç¼çš„å¤§åœºæ™¯ã€‚</p></li></ol><p>8.ç»“è®ºï¼š(1): æœ¬å·¥ä½œæå‡ºäº†VastGaussianï¼Œä¸€ç§åŸºäº3Dé«˜æ–¯ä½“å–·ç»˜æ³•åœ¨å¤§åœºæ™¯ä¸Šè¿›è¡Œé«˜è´¨é‡é‡å»ºå’Œå®æ—¶æ¸²æŸ“çš„ç¬¬ä¸€ç§æ–¹æ³•ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦ä¸Šçš„å±€é™æ€§ã€‚(2): åˆ›æ–°ç‚¹ï¼š- æ¸è¿›æ•°æ®åˆ†åŒºï¼šå°†å¤§åœºæ™¯åˆ’åˆ†ä¸ºå•å…ƒæ ¼ï¼Œå¹¶åˆ†é…éƒ¨åˆ†ç›¸æœºå’Œç‚¹äº‘è¿›è¡Œä¼˜åŒ–ï¼Œè§£å†³äº†è§†é¢‘å†…å­˜æœ‰é™å’Œä¼˜åŒ–æ—¶é—´é•¿çš„æŒ‘æˆ˜ã€‚- è§£è€¦å¤–è§‚å»ºæ¨¡ï¼šå¼•å…¥å¤–è§‚åµŒå…¥å’Œå·ç§¯ç¥ç»ç½‘ç»œï¼Œå‡å°‘äº†æ¸²æŸ“å›¾åƒä¸­çš„å¤–è§‚å˜åŒ–ï¼Œæé«˜äº†è§†è§‰è´¨é‡ã€‚- æ— ç¼åˆå¹¶ï¼šä¼˜åŒ–å„ä¸ªå•å…ƒæ ¼åï¼Œåˆå¹¶éé‡å å•å…ƒæ ¼çš„é«˜æ–¯ä½“ï¼Œå½¢æˆäº†æ— ç¼çš„å¤§åœºæ™¯ã€‚æ€§èƒ½ï¼š- åœ¨å¤šä¸ªå¤§åœºæ™¯æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚- å®ç°å¿«é€Ÿä¼˜åŒ–å’Œé«˜ä¿çœŸå®æ—¶æ¸²æŸ“ã€‚å·¥ä½œé‡ï¼š- è®ºæ–‡æä¾›äº†è¯¦ç»†çš„ç®—æ³•æè¿°å’Œå®éªŒç»“æœã€‚- Githubä»£ç æš‚æœªæä¾›ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-ee052136cbbee0e4d283f8c1613aa5c9.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-c9222e251d2d4b3d336feb1e5dc10d3c.jpg" align="middle"><img src="https://pica.zhimg.com/v2-9fb6f7a1a19593c7cf97f51e62283477.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-9609bd8a7bee5ba2688b0bf50aa99233.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-04b4a21a99a56fa621e5dc34b03bb714.jpg" align="middle"><img src="https://pica.zhimg.com/v2-16c21380cd415ab4eb8e703f94c84868.jpg" align="middle"></details>## GEA: Reconstructing Expressive 3D Gaussian Avatar from Monocular Video**Authors:Xinqi Liu, Chenming Wu, Xing Liu, Jialun Liu, Jinbo Wu, Chen Zhao, Haocheng Feng, Errui Ding, Jingdong Wang**This paper presents GEA, a novel method for creating expressive 3D avatars with high-fidelity reconstructions of body and hands based on 3D Gaussians. The key contributions are twofold. First, we design a two-stage pose estimation method to obtain an accurate SMPL-X pose from input images, providing a correct mapping between the pixels of a training image and the SMPL-X model. It uses an attention-aware network and an optimization scheme to align the normal and silhouette between the estimated SMPL-X body and the real body in the image. Second, we propose an iterative re-initialization strategy to handle unbalanced aggregation and initialization bias faced by Gaussian representation. This strategy iteratively redistributes the avatar's Gaussian points, making it evenly distributed near the human body surface by applying meshing, resampling and re-Gaussian operations. As a result, higher-quality rendering can be achieved. Extensive experimental analyses validate the effectiveness of the proposed model, demonstrating that it achieves state-of-the-art performance in photorealistic novel view synthesis while offering fine-grained control over the human body and hand pose. Project page: https://3d-aigc.github.io/GEA/. [PDF](http://arxiv.org/abs/2402.16607v1) **Summary**åˆ©ç”¨åŸºäº 3D é«˜æ–¯ä½“çš„æ‰‹éƒ¨å’Œèº«ä½“é«˜ä¿çœŸé‡å»ºæŠ€æœ¯åˆ›é€ å¯Œæœ‰è¡¨ç°åŠ›çš„ 3D å¤´åƒã€‚**Key Takeaways**- é‡‡ç”¨ä¸¤é˜¶æ®µå§¿åŠ¿ä¼°è®¡æ–¹æ³•ï¼Œä»è¾“å…¥å›¾åƒä¸­è·å–å‡†ç¡®çš„ SMPL-X å§¿åŠ¿ã€‚- æå‡ºè¿­ä»£é‡æ–°åˆå§‹åŒ–ç­–ç•¥ï¼Œå¤„ç†é«˜æ–¯è¡¨ç¤ºä¸­é‡åˆ°çš„ä¸å¹³è¡¡èšåˆå’Œåˆå§‹åŒ–åå·®ã€‚- è¯¥æ¨¡å‹åœ¨å›¾åƒçœŸå®çš„æ–°è§†è§’åˆæˆæ–¹é¢å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚- å…è®¸å¯¹äººä½“å’Œæ‰‹éƒ¨å§¿æ€è¿›è¡Œç²¾ç»†æ§åˆ¶ã€‚- å®éªŒåˆ†æéªŒè¯äº†è¯¥æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚- æä¾›é¡¹ç›®ä¸»é¡µé“¾æ¥ï¼šhttps://3d-aigc.github.io/GEA/ã€‚- è¯¥æ–¹æ³•åœ¨åˆ›å»ºè¡¨è¾¾åŠ›ä¸°å¯Œçš„ 3D å¤´åƒæ–¹é¢å…·æœ‰åº”ç”¨æ½œåŠ›ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šGEAï¼šåŸºäº 3D é«˜æ–¯é‡å»ºè¡¨è¾¾å¼ 3D å¤´åƒ</li><li>ä½œè€…ï¼šåˆ˜æ–°å¥‡ã€å´æ™¨æ˜ã€åˆ˜å…´ã€åˆ˜å®¶ä¼¦ã€æ­¦é‡‘æ³¢ã€èµµæ™¨ã€å†¯æµ©æˆã€ä¸å°”ç‘ã€ç‹äº¬ä¸œ</li><li>å•ä½ï¼šç™¾åº¦è§†è§‰æŠ€æœ¯éƒ¨</li><li>å…³é”®è¯ï¼š3D å¤´åƒã€é«˜æ–¯è¡¨ç¤ºã€å•ç›®è§†é¢‘ã€å§¿æ€ä¼°è®¡</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.16607ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li><li><p>æ€»ç»“ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šé‡å»ºé€¼çœŸä¸”å¯é©±åŠ¨çš„å¤´åƒä¸€ç›´æ˜¯å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„çƒ­ç‚¹è¯¾é¢˜ï¼Œå…·æœ‰å¹¿é˜”çš„å•†ä¸šä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šæ—©æœŸæ–¹æ³•ä¸»è¦ä¾èµ–äº RGB-D ç›¸æœºã€å¤šè§†è§’é‡‡é›†è®¾å¤‡å’Œäººå·¥å»ºæ¨¡ï¼Œä½†å­˜åœ¨æˆæœ¬é«˜ã€æ¸²æŸ“æ•ˆæœä¸é€¼çœŸç­‰é—®é¢˜ã€‚ç¥ç»è¾å°„åœºæ–¹æ³•è™½ç„¶å¯ä»¥é‡å»ºé€¼çœŸçš„ 3D å¤´åƒï¼Œä½†è®­ç»ƒæ—¶é—´é•¿ã€å§¿æ€æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚3D é«˜æ–¯è¡¨ç¤ºæ–¹æ³•å› å…¶æ˜¾å¼è¡¨ç¤ºè€Œå—åˆ°å…³æ³¨ï¼Œä½†å­˜åœ¨åˆå§‹åŒ–ä¸å‡è¡¡å’Œèšé›†ä¸å¹³è¡¡çš„é—®é¢˜ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºçš„ GEA æ–¹æ³•åŒ…æ‹¬ä¸¤å¤§è´¡çŒ®ã€‚ä¸€æ˜¯è®¾è®¡äº†ä¸€ç§ä¸¤é˜¶æ®µå§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œé€šè¿‡æ³¨æ„åŠ›æ„ŸçŸ¥ç½‘ç»œå’Œä¼˜åŒ–æ–¹æ¡ˆï¼Œä»è¾“å…¥å›¾åƒä¸­å‡†ç¡®ä¼°è®¡ SMPL-X å§¿æ€ï¼Œå»ºç«‹å›¾åƒåƒç´ ä¸ SMPL-X æ¨¡å‹ä¹‹é—´çš„æ­£ç¡®æ˜ å°„ã€‚äºŒæ˜¯æå‡ºäº†ä¸€ç§è¿­ä»£å¼é‡æ–°åˆå§‹åŒ–ç­–ç•¥ï¼Œé€šè¿‡ç½‘æ ¼åŒ–ã€é‡é‡‡æ ·å’Œé«˜æ–¯é‡æ–°æ“ä½œï¼Œè¿­ä»£åœ°é‡æ–°åˆ†é…å¤´åƒçš„é«˜æ–¯ç‚¹ï¼Œä½¿å…¶å‡åŒ€åˆ†å¸ƒåœ¨äººä½“è¡¨é¢é™„è¿‘ï¼Œä»è€Œæé«˜æ¸²æŸ“è´¨é‡ã€‚ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šGEA æ–¹æ³•åœ¨çœŸå®æ„Ÿæ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†å¯¹äººä½“å’Œæ‰‹éƒ¨å§¿æ€çš„ç²¾ç»†æ§åˆ¶ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ”¯æŒå…¶ç›®æ ‡ã€‚</p></li><li><p><strong>å§¿æ€ä¼°è®¡</strong>ï¼šæå‡ºä¸¤é˜¶æ®µå§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œé€šè¿‡æ³¨æ„åŠ›æ„ŸçŸ¥ç½‘ç»œå’Œä¼˜åŒ–æ–¹æ¡ˆï¼Œä»å•ç›®è§†é¢‘ä¸­å‡†ç¡®ä¼°è®¡ SMPL-X å§¿æ€ï¼Œå»ºç«‹å›¾åƒåƒç´ ä¸ SMPL-X æ¨¡å‹ä¹‹é—´çš„æ­£ç¡®æ˜ å°„ã€‚</p></li><li><strong>è¿­ä»£å¼é‡æ–°åˆå§‹åŒ–</strong>ï¼šé€šè¿‡ç½‘æ ¼åŒ–ã€é‡é‡‡æ ·å’Œé«˜æ–¯é‡æ–°æ“ä½œï¼Œè¿­ä»£åœ°é‡æ–°åˆ†é…å¤´åƒçš„é«˜æ–¯ç‚¹ï¼Œä½¿å…¶å‡åŒ€åˆ†å¸ƒåœ¨äººä½“è¡¨é¢é™„è¿‘ï¼Œæé«˜æ¸²æŸ“è´¨é‡ã€‚</li><li><strong>3D é«˜æ–¯è¡¨ç¤º</strong>ï¼šé‡‡ç”¨ 3D é«˜æ–¯ç‚¹é›†åˆè¡¨ç¤ºå¤´åƒçš„å½¢çŠ¶å’Œå¤–è§‚ï¼Œå¹¶ä½¿ç”¨ SMPL-X éª¨æ¶æ¨¡å‹å®ç°è¯¦ç»†çš„å§¿æ€æ§åˆ¶ã€‚</li><li><p><strong>æ¸²æŸ“æŸå¤±å‡½æ•°</strong>ï¼šä½¿ç”¨ SMPL-X éª¨æ¶å˜æ¢å°†é«˜æ–¯å¤´åƒä»è§„èŒƒç©ºé—´é©±åŠ¨åˆ°å›¾åƒç©ºé—´ï¼Œå¹¶ä½¿ç”¨å·®å¼‚åŒ–æ¸²æŸ“è¿›è¡Œä¼˜åŒ–ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±ã€æ„ŸçŸ¥æŸå¤±å’Œæ®‹å·®æ­£åˆ™åŒ–ã€‚</p></li><li><p>ç»“è®ºï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯ç”±èº«ä½“å’Œæ‰‹é©±åŠ¨çš„ 3D é«˜æ–¯å¤´åƒé‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»å•ç›®è§†é¢‘ä¸­è·å– SMPL-X å§¿æ€å‚æ•°ï¼ŒæŒ‡å¯¼ 3D é«˜æ–¯å¤´åƒå­¦ä¹ å…¨èº«å½¢çŠ¶å’Œå¤–è§‚ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§è¿­ä»£é‡æ–°åˆå§‹åŒ–æœºåˆ¶ï¼Œä»¥é¿å… 3D é«˜æ–¯ä¸å¹³è¡¡èšåˆå’Œåˆå§‹åŒ–åå·®çš„é—®é¢˜ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼Œè¿™é¡¹è´¡çŒ®å°†ä¸ºæœªæ¥æ›´é€¼çœŸçš„å¤´åƒé‡å»ºé“ºå¹³é“è·¯ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µå§¿åŠ¿ç»†åŒ–æœºåˆ¶ï¼Œä»å›¾åƒä¸­è·å– SMPL-X å§¿æ€å‚æ•°ï¼ŒæŒ‡å¯¼ 3D é«˜æ–¯å¤´åƒå­¦ä¹ å…¨èº«å½¢çŠ¶å’Œå¤–è§‚ã€‚</li><li>æå‡ºäº†ä¸€ç§è¿­ä»£é‡æ–°åˆå§‹åŒ–æœºåˆ¶ï¼Œä»¥é¿å… 3D é«˜æ–¯ä¸å¹³è¡¡èšåˆå’Œåˆå§‹åŒ–åå·®çš„é—®é¢˜ã€‚æ€§èƒ½ï¼š</li><li>åœ¨çœŸå®æ„Ÿæ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li><li>æä¾›äº†å¯¹äººä½“å’Œæ‰‹éƒ¨å§¿æ€çš„ç²¾ç»†æ§åˆ¶ã€‚å·¥ä½œé‡ï¼š</li><li>éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li><li>è®­ç»ƒè¿‡ç¨‹å¯èƒ½è€—æ—¶ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-9b9982465510d1b66a23858c60af4331.jpg" align="middle"><img src="https://picx.zhimg.com/v2-1c8ddc4d64a0f61f1a9a17acb134824c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-e9a9a5ebfedeaeecdc381441fa23504f.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-2131167109a684b8747fb7451590f0d3.jpg" align="middle"><img src="https://picx.zhimg.com/v2-c0d2c2740f3fa02de0dd80788a7d2df2.jpg" align="middle"></details><h2 id="Spec-Gaussian-Anisotropic-View-Dependent-Appearance-for-3D-Gaussian-Splatting"><a href="#Spec-Gaussian-Anisotropic-View-Dependent-Appearance-for-3D-Gaussian-Splatting" class="headerlink" title="Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian   Splatting"></a>Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian   Splatting</h2><p><strong>Authors:Ziyi Yang, Xinyu Gao, Yangtian Sun, Yihua Huang, Xiaoyang Lyu, Wen Zhou, Shaohui Jiao, Xiaojuan Qi, Xiaogang Jin</strong></p><p>The recent advancements in 3D Gaussian splatting (3D-GS) have not only facilitated real-time rendering through modern GPU rasterization pipelines but have also attained state-of-the-art rendering quality. Nevertheless, despite its exceptional rendering quality and performance on standard datasets, 3D-GS frequently encounters difficulties in accurately modeling specular and anisotropic components. This issue stems from the limited ability of spherical harmonics (SH) to represent high-frequency information. To overcome this challenge, we introduce Spec-Gaussian, an approach that utilizes an anisotropic spherical Gaussian (ASG) appearance field instead of SH for modeling the view-dependent appearance of each 3D Gaussian. Additionally, we have developed a coarse-to-fine training strategy to improve learning efficiency and eliminate floaters caused by overfitting in real-world scenes. Our experimental results demonstrate that our method surpasses existing approaches in terms of rendering quality. Thanks to ASG, we have significantly improved the ability of 3D-GS to model scenes with specular and anisotropic components without increasing the number of 3D Gaussians. This improvement extends the applicability of 3D GS to handle intricate scenarios with specular and anisotropic surfaces. </p><p><a href="http://arxiv.org/abs/2402.15870v1">PDF</a> </p><p><strong>Summary</strong><br>3D é«˜æ–¯çƒä½“æº…å°„æŠ€æœ¯ (3D-GS) åœ¨ç²¾ç¡®å»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†æ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼ŒSpec-Gaussian æ–¹æ³•é€šè¿‡ä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯å¤–è§‚åœºæ¥è§£å†³è¿™ä¸€éš¾é¢˜ï¼ŒåŒæ—¶é‡‡ç”¨ç²—ç•¥åˆ°ç²¾ç»†çš„è®­ç»ƒç­–ç•¥æ¥å¢å¼ºå­¦ä¹ æ•ˆç‡å¹¶æ¶ˆé™¤è¿‡æ‹Ÿåˆæµ®åŠ¨ç‰©ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>3D-GSæŠ€æœ¯åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç²¾ç¡®å»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†æ–¹é¢é‡åˆ°å›°éš¾ã€‚</li><li>é™åˆ¶çƒè°å‡½æ•° (SH) è¡¨ç¤ºé«˜é¢‘ä¿¡æ¯çš„å±€é™æ€§å¯¼è‡´3D-GSå»ºæ¨¡å›°éš¾ã€‚</li><li>Spec-Gaussianæ–¹æ³•é‡‡ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ (ASG) å¤–è§‚åœºæ¥ä»£æ›¿SHï¼Œæé«˜é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†å»ºæ¨¡èƒ½åŠ›ã€‚</li><li>ç²—ç•¥åˆ°ç²¾ç»†çš„åŸ¹è®­ç­–ç•¥æé«˜äº†å­¦ä¹ æ•ˆç‡ï¼Œæ¶ˆé™¤äº†è¿‡æ‹Ÿåˆé€ æˆçš„æµ®åŠ¨ç‰©ã€‚</li><li>å®éªŒç»“æœè¡¨æ˜Spec-Gaussianåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li><li>ASGæ˜¾è‘—æå‡äº†3D-GSå»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†åœºæ™¯çš„èƒ½åŠ›ï¼Œæ— éœ€å¢åŠ 3Dé«˜æ–¯çƒä½“æ•°é‡ã€‚</li><li>3D-GSæŠ€æœ¯å¯æ‰©å±•è‡³å¤„ç†é•œé¢å’Œå„å‘å¼‚æ€§è¡¨é¢çš„å¤æ‚åœºæ™¯ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šSpec-Gaussianï¼šé«˜æ–¯ä½“æ¸²æŸ“ä¸­çš„å„å‘å¼‚æ€§è§†ç‚¹ç›¸å…³å¤–è§‚</li><li>ä½œè€…ï¼šJiahui Lei, Yinda Zhang, Wenbo Bao, Jingyi Yu, Qiong Yan, Hao Li</li><li>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li><li>å…³é”®è¯ï¼š3D é«˜æ–¯ä½“æ¸²æŸ“ã€å„å‘å¼‚æ€§ã€è§†ç‚¹ç›¸å…³å¤–è§‚ã€ç¥ç»ç½‘ç»œ</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2208.05462</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œ3D é«˜æ–¯ä½“æ¸²æŸ“ï¼ˆ3DGSï¼‰åœ¨å®æ—¶æ¸²æŸ“å’Œé«˜æ¸²æŸ“è´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œåœ¨å»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†æ—¶ï¼Œ3DGS ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨çƒè°å‡½æ•°ï¼ˆSHï¼‰æ¥å»ºæ¨¡è§†ç‚¹ç›¸å…³å¤–è§‚ã€‚ç„¶è€Œï¼ŒSH åœ¨è¡¨ç¤ºé«˜é¢‘ä¿¡æ¯æ–¹é¢èƒ½åŠ›æœ‰é™ï¼Œéš¾ä»¥å‡†ç¡®å»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æ•ˆæœã€‚</p><p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º Spec-Gaussianï¼Œä¸€ç§ä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ï¼ˆASGï¼‰å¤–è§‚åœºæ¥å»ºæ¨¡ 3D é«˜æ–¯ä½“è§†ç‚¹ç›¸å…³å¤–è§‚çš„æ–¹æ³•ã€‚ASG æ¯” SH å…·æœ‰æ›´å¼ºçš„å„å‘å¼‚æ€§å»ºæ¨¡èƒ½åŠ›ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºé•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œä»¥æé«˜å­¦ä¹ æ•ˆç‡å¹¶æ¶ˆé™¤è¿‡æ‹Ÿåˆå¼•èµ·çš„æµ®åŠ¨ç°è±¡ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šå–å¾—çš„æˆå°±ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒSpec-Gaussian åœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å¾—ç›Šäº ASGï¼Œæœ¬æ–‡æ–¹æ³•æ˜¾è‘—æé«˜äº† 3DGS åœ¨å»ºæ¨¡å…·æœ‰é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†åœºæ™¯çš„èƒ½åŠ›ï¼Œè€Œæ— éœ€å¢åŠ  3D é«˜æ–¯ä½“çš„æ•°é‡ã€‚è¿™ä¸€æ”¹è¿›æ‰©å±•äº† 3DGS åœ¨å¤„ç†å…·æœ‰å¤æ‚é•œé¢å’Œå„å‘å¼‚æ€§è¡¨é¢çš„åœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚</p><p>7.Methods:(1):æå‡ºSpec-Gaussianæ–¹æ³•ï¼Œä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ï¼ˆASGï¼‰å¤–è§‚åœºæ¥å»ºæ¨¡3Dé«˜æ–¯ä½“è§†ç‚¹ç›¸å…³å¤–è§‚ï¼ŒASGæ¯”çƒè°å‡½æ•°ï¼ˆSHï¼‰å…·æœ‰æ›´å¼ºçš„å„å‘å¼‚æ€§å»ºæ¨¡èƒ½åŠ›ï¼›(2):æå‡ºç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œä»¥æé«˜å­¦ä¹ æ•ˆç‡å¹¶æ¶ˆé™¤è¿‡æ‹Ÿåˆå¼•èµ·çš„æµ®åŠ¨ç°è±¡ï¼›(3):é€šè¿‡å®éªŒéªŒè¯Spec-Gaussianåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†3DGSåœ¨å»ºæ¨¡å…·æœ‰é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†åœºæ™¯çš„èƒ½åŠ›ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºSpec-Gaussianï¼Œä¸€ç§ä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ï¼ˆASGï¼‰å¤–è§‚åœºæ¥å»ºæ¨¡3Dé«˜æ–¯ä½“è§†ç‚¹ç›¸å…³å¤–è§‚çš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°å…‹æœäº†ä¼ ç»Ÿ3D-GSåœ¨æ¸²æŸ“å…·æœ‰é•œé¢é«˜å…‰å’Œå„å‘å¼‚æ€§çš„åœºæ™¯æ—¶é‡åˆ°çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡åˆ›æ–°åœ°å®ç°äº†ç²—åˆ°ç»†çš„è®­ç»ƒæœºåˆ¶ï¼Œæ¶ˆé™¤äº†å®é™…åœºæ™¯ä¸­çš„æµ®åŠ¨ç°è±¡ã€‚å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä¸ä»…èµ‹äºˆ3D-GSå»ºæ¨¡é•œé¢é«˜å…‰å’Œå„å‘å¼‚æ€§çš„èƒ½åŠ›ï¼Œè€Œä¸”æé«˜äº†3D-GSåœ¨ä¸€èˆ¬åœºæ™¯ä¸­çš„æ•´ä½“æ¸²æŸ“è´¨é‡ï¼Œè€Œä¸ä¼šæ˜¾è‘—å½±å“FPSå’Œå­˜å‚¨å¼€é”€ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºSpec-Gaussianæ–¹æ³•ï¼Œä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ï¼ˆASGï¼‰å¤–è§‚åœºæ¥å»ºæ¨¡3Dé«˜æ–¯ä½“è§†ç‚¹ç›¸å…³å¤–è§‚ï¼ŒASGæ¯”çƒè°å‡½æ•°ï¼ˆSHï¼‰å…·æœ‰æ›´å¼ºçš„å„å‘å¼‚æ€§å»ºæ¨¡èƒ½åŠ›ï¼›æå‡ºç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œä»¥æé«˜å­¦ä¹ æ•ˆç‡å¹¶æ¶ˆé™¤è¿‡æ‹Ÿåˆå¼•èµ·çš„æµ®åŠ¨ç°è±¡ã€‚æ€§èƒ½ï¼šåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†3DGSåœ¨å»ºæ¨¡å…·æœ‰é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†åœºæ™¯çš„èƒ½åŠ›ã€‚å·¥ä½œé‡ï¼šä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢æœ‰æ˜¾è‘—æå‡ï¼Œè€Œä¸ä¼šæ˜¾è‘—å¢åŠ FPSå’Œå­˜å‚¨å¼€é”€ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-4090f3d87f7165ab99a3612c93587c40.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-06c68db5202857ec55ce34cb4381f13c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-23504bdddd28cc6cb43a6d3e0229eedd.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f5e74d0aee36acee6c03305fd883438c.jpg" align="middle"></details><h2 id="Magic-Me-Identity-Specific-Video-Customized-Diffusion"><a href="#Magic-Me-Identity-Specific-Video-Customized-Diffusion" class="headerlink" title="Magic-Me: Identity-Specific Video Customized Diffusion"></a>Magic-Me: Identity-Specific Video Customized Diffusion</h2><p><strong>Authors:Ze Ma, Daquan Zhou, Chun-Hsiao Yeh, Xue-She Wang, Xiuyu Li, Huanrui Yang, Zhen Dong, Kurt Keutzer, Jiashi Feng</strong></p><p>Creating content for a specific identity (ID) has shown significant interest in the field of generative models. In the field of text-to-image generation (T2I), subject-driven content generation has achieved great progress with the ID in the images controllable. However, extending it to video generation is not well explored. In this work, we propose a simple yet effective subject identity controllable video generation framework, termed Video Custom Diffusion (VCD). With a specified subject ID defined by a few images, VCD reinforces the identity information extraction and injects frame-wise correlation at the initialization stage for stable video outputs with identity preserved to a large extent. To achieve this, we propose three novel components that are essential for high-quality ID preservation: 1) an ID module trained with the cropped identity by prompt-to-segmentation to disentangle the ID information and the background noise for more accurate ID token learning; 2) a text-to-video (T2V) VCD module with 3D Gaussian Noise Prior for better inter-frame consistency and 3) video-to-video (V2V) Face VCD and Tiled VCD modules to deblur the face and upscale the video for higher resolution.   Despite its simplicity, we conducted extensive experiments to verify that VCD is able to generate stable and high-quality videos with better ID over the selected strong baselines. Besides, due to the transferability of the ID module, VCD is also working well with finetuned text-to-image models available publically, further improving its usability. The codes are available at <a href="https://github.com/Zhen-Dong/Magic-Me">https://github.com/Zhen-Dong/Magic-Me</a>. </p><p><a href="http://arxiv.org/abs/2402.09368v1">PDF</a> </p><p><strong>Summary</strong><br>ç”¨å°‘é‡å›¾åƒæŒ‡å®šä¸»ä½“ IDï¼ŒVCD æ¡†æ¶é€šè¿‡å¼ºåŒ–èº«ä»½ä¿¡æ¯æå–å’Œæ³¨å…¥å¸§é—´ç›¸å…³æ€§ï¼Œç”Ÿæˆä¸»ä½“èº«ä»½å¯æ§çš„é«˜è´¨é‡è§†é¢‘ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡º VCD æ¡†æ¶ç”¨äºä¸»ä½“èº«ä»½å¯æ§è§†é¢‘ç”Ÿæˆï¼Œé€šè¿‡æŒ‡å®šå‡ ä¸ªå›¾åƒå®šä¹‰ä¸»ä½“ IDã€‚</li><li>ID æ¨¡å—åˆ©ç”¨æç¤ºåˆ°åˆ†å‰²è®­ç»ƒï¼Œ disentangle ID ä¿¡æ¯å’ŒèƒŒæ™¯å™ªå£°ï¼Œæ›´å‡†ç¡®åœ°å­¦ä¹  ID æ ‡è®°ã€‚</li><li>T2V VCD æ¨¡å—ä½¿ç”¨ 3D é«˜æ–¯å™ªå£°å…ˆéªŒï¼Œä»¥è·å¾—æ›´å¥½çš„å¸§é—´ä¸€è‡´æ€§ã€‚</li><li>V2V Face VCD å’Œ Tiled VCD æ¨¡å—ç”¨äºæ¨¡ç³Šé¢éƒ¨å’Œæå‡è§†é¢‘åˆ†è¾¨ç‡ã€‚</li><li>VCD åœ¨é€‰å®šçš„å¼ºåŸºçº¿ä¸Šç”Ÿæˆç¨³å®šã€é«˜è´¨é‡ä¸” ID æ›´ä½³çš„è§†é¢‘ã€‚</li><li>ID æ¨¡å—å¯è¿ç§»ï¼ŒVCD å¯ä¸å…¬å¼€æä¾›çš„å¾®è°ƒæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹é…åˆä½¿ç”¨ï¼Œè¿›ä¸€æ­¥æé«˜å…¶å¯ç”¨æ€§ã€‚</li><li>æä¾›äº† VCD çš„ä»£ç ï¼š<a href="https://github.com/Zhen-Dong/Magic-Meã€‚">https://github.com/Zhen-Dong/Magic-Meã€‚</a></li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šMagic-Me: èº«ä»½ç‰¹å®šè§†é¢‘å®šåˆ¶åŒ–æ‰©æ•£</li><li>ä½œè€…ï¼šZe Ma<em>1, Daquan Zhou</em>â€ 1, Chun-Hsiao Yeh2, Xue-She Wang1, Xiuyu Li2, Huanrui Yang2, Zhen Dongâ€ 2, Kurt Keutzer2, Jiashi Feng1</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå­—èŠ‚è·³åŠ¨å…¬å¸</li><li>å…³é”®è¯ï¼šèº«ä»½ç‰¹å®šè§†é¢‘ç”Ÿæˆã€æ–‡æœ¬åˆ°è§†é¢‘ã€è§†é¢‘å®šåˆ¶åŒ–æ‰©æ•£</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.09368   Githubä»£ç é“¾æ¥ï¼šhttps://github.com/Zhen-Dong/Magic-Me</li><li>æ‘˜è¦ï¼š   (1): ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç²¾ç¡®æ§åˆ¶ç”Ÿæˆå†…å®¹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚èº«ä»½ç‰¹å®šç”Ÿæˆåœ¨è®¸å¤šåœºæ™¯ä¸­å¾ˆé‡è¦ï¼Œä¾‹å¦‚ç”µå½±åˆ¶ä½œå’Œå¹¿å‘Šã€‚   (2): è¿‡å»æ–¹æ³•ï¼šä¹‹å‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨åˆ©ç”¨å›¾åƒå‚è€ƒæ§åˆ¶é£æ ¼å’ŒåŠ¨ä½œï¼Œæˆ–é€šè¿‡è§†é¢‘ç¼–è¾‘è¿›è¡Œå®šåˆ¶åŒ–ç”Ÿæˆã€‚è¿™äº›æ–¹æ³•çš„é‡ç‚¹ä¸åœ¨äºèº«ä»½ç‰¹å®šæ§åˆ¶ã€‚   (3): ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•çš„ä½†æœ‰æ•ˆçš„èº«ä»½ç‰¹å®šè§†é¢‘ç”Ÿæˆæ¡†æ¶ï¼Œç§°ä¸ºè§†é¢‘å®šåˆ¶åŒ–æ‰©æ•£ï¼ˆVCDï¼‰ã€‚VCD ä½¿ç”¨èº«ä»½æ¨¡å—æå–èº«ä»½ä¿¡æ¯ï¼Œå¹¶åœ¨åˆå§‹åŒ–é˜¶æ®µæ³¨å…¥å¸§é—´ç›¸å…³æ€§ï¼Œä»¥ç”Ÿæˆå…·æœ‰ç¨³å®šèº«ä»½çš„è§†é¢‘è¾“å‡ºã€‚   (4): æ€§èƒ½ï¼šVCD åœ¨èº«ä»½ä¿ç•™æ–¹é¢ä¼˜äºé€‰å®šçš„å¼ºåŸºçº¿ã€‚æ­¤å¤–ï¼Œç”±äºèº«ä»½æ¨¡å—çš„å¯è¿ç§»æ€§ï¼ŒVCD ä¹Ÿé€‚ç”¨äºå…¬å¼€å¯ç”¨çš„å¾®è°ƒæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œè¿›ä¸€æ­¥æé«˜äº†å…¶å¯ç”¨æ€§ã€‚</li></ol><p>7.Methodsï¼šï¼ˆ1ï¼‰æå‡ºç”¨äº VCD çš„é¢„å¤„ç†æ¨¡å—ï¼Œä»¥åŠ ID æ¨¡å—å’Œè¿åŠ¨æ¨¡å—ï¼Œå¦‚å›¾ 3 æ‰€ç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå¯é€‰æ¨¡å—ï¼Œåˆ©ç”¨ ControlNet Tile æ¥ä¸Šé‡‡æ ·è§†é¢‘å¹¶ç”Ÿæˆé«˜åˆ†è¾¨ç‡å†…å®¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº† AnimateDiff [18] ä¸­ç°æˆçš„è¿åŠ¨æ¨¡å—ï¼Œå¹¶é€šè¿‡æˆ‘ä»¬æå‡ºçš„ 3D é«˜æ–¯å™ªå£°å…ˆéªŒè¿›è¡Œäº†å¢å¼ºï¼Œå¦‚ç¬¬ 4.1 èŠ‚æ‰€è¿°ã€‚ID æ¨¡å—å…·æœ‰å¸¦æ©ç æŸå¤±å’Œæç¤ºåˆ°åˆ†å‰²çš„æ‰©å±• ID ä»¤ç‰Œï¼Œåœ¨ç¬¬ 4.2 èŠ‚ä¸­ä»‹ç»ã€‚åœ¨ç¬¬ 4.3 èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸¤ä¸ª V2V VCD ç®¡é“ï¼ŒFaceVCD å’Œ TiledVCDã€‚ï¼ˆ2ï¼‰ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬åº”ç”¨æˆ‘ä»¬çš„æ— è®­ç»ƒ 3D é«˜æ–¯å™ªå£°å…ˆéªŒåˆ°ç°æˆçš„è¿åŠ¨æ¨¡å— [18]ï¼Œä»¥å‡è½»æ¨ç†æœŸé—´çš„æ›å…‰åå·®ã€‚æ‰€é€‰çš„è¿åŠ¨æ¨¡å—å°†ç½‘ç»œæ‰©å±•åˆ°åŒ…å«æ—¶é—´ç»´åº¦ã€‚å®ƒå°† 2D å·ç§¯å’Œæ³¨æ„åŠ›å±‚è½¬æ¢ä¸ºæ—¶é—´ä¼ª 3D å±‚ [23]ï¼Œéµå¾ªæ–¹ç¨‹å¼ 2 ä¸­æ¦‚è¿°çš„è®­ç»ƒç›®æ ‡ã€‚3D é«˜æ–¯å™ªå£°å…ˆéªŒã€‚å¯¹äºåŒ…å« f å¸§çš„è§†é¢‘ï¼Œ3D é«˜æ–¯å™ªå£°å…ˆéªŒä»å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ N(0, Î£f(Î³)) ä¸­é‡‡æ ·ã€‚è¿™é‡Œï¼ŒÎ£f(Î³) è¡¨ç¤ºç”± Î³âˆˆ(0,1) å‚æ•°åŒ–çš„åæ–¹å·®çŸ©é˜µã€‚Î£f(Î³)=ï£«ï£¬ï£¬ï£¬ï£¬ï£¬ï£­1Î³Î³2Â·Â·Â·Î³fâˆ’1Î³1Î³Â·Â·Â·Î³fâˆ’2Î³2Î³1Â·Â·Â·Î³fâˆ’3...............Î³fâˆ’1Î³fâˆ’2Î³fâˆ’3Â·Â·Â·1ï£¶ï£·ï£·ï£·ï£·ï£·ï£¸ã€‚(4)ï¼ˆ3ï¼‰ä¸Šé¢æè¿°çš„åæ–¹å·®ç¡®ä¿åˆå§‹åŒ–çš„ 3D å™ªå£°åœ¨ m å’Œ n å¸§ä¹‹é—´çš„ç›¸åŒä½ç½®è¡¨ç°å‡º Î³|mâˆ’n| çš„åæ–¹å·®ã€‚è¶…å‚æ•° Î³ è¡¨ç¤ºç¨³å®šæ€§å’Œè¿åŠ¨å¹…åº¦ä¹‹é—´çš„æƒè¡¡ï¼Œå¦‚å›¾ 4 æ‰€ç¤ºã€‚è¾ƒä½çš„ Î³ å€¼ä¼šå¯¼è‡´è¿åŠ¨å‰§çƒˆä½†ç¨³å®šæ€§é™ä½çš„è§†é¢‘ï¼Œè€Œè¾ƒé«˜çš„ Î³ ä¼šå¯¼è‡´å¹…åº¦å‡å°çš„æ›´ç¨³å®šçš„è¿åŠ¨ã€‚ï¼ˆ4ï¼‰ID æ¨¡å— VAE æç¤ºåˆ°åˆ†å‰² Lmask<v*>man ä¸»ä½“æ˜¯ä¸€ä¸ªç©¿ç€ç²‰è‰² T æ¤çš„äººå›¾ 5.æ‰©å±• ID ä»¤ç‰Œå­¦ä¹ ã€‚é€šè¿‡æç¤ºåˆ°åˆ†å‰²ï¼Œé’ˆå¯¹æ©ç ä¸»ä½“åŒºåŸŸå¯¹æ‰©å±• ID ä»¤ç‰Œè¿›è¡Œä¼˜åŒ–ã€‚è™½ç„¶ä»¥å‰çš„å·¥ä½œå·²ç»æ¢ç´¢äº† T2I èº«ä»½å®šåˆ¶çš„ä»¤ç‰ŒåµŒå…¥ [16,58] å’Œæƒé‡å¾®è°ƒ [11,17,31,48]ï¼Œä½†å¾ˆå°‘æœ‰äººæ·±å…¥ç ”ç©¶ T2V ç”Ÿæˆä¸­çš„èº«ä»½å®šåˆ¶ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œè™½ç„¶åƒ CustomDiffusion [31] æˆ– LoRA [25] è¿™æ ·çš„æƒé‡è°ƒæ•´æ–¹æ³•åœ¨å›¾åƒç”Ÿæˆä¸­å®ç°äº†ç²¾ç¡®çš„èº«ä»½ï¼Œä½†ç”Ÿæˆçš„è§†é¢‘é€šå¸¸æ˜¾ç¤ºå‡ºæœ‰é™çš„å¤šæ ·æ€§å’Œç”¨æˆ·è¾“å…¥å¯¹é½ã€‚æ‰©å±• ID ä»¤ç‰Œã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨æ‰©å±• ID ä»¤ç‰Œä»…ä¸æ¡ä»¶ç¼–ç äº¤äº’ï¼Œå¹¶æ›´å¥½åœ°ä¿ç•™èº«ä»½çš„è§†è§‰ç‰¹å¾ï¼Œå¦‚å›¾ 5 æ‰€ç¤ºã€‚ä¸åŸå§‹ LoRA ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥äº§ç”Ÿæ›´å¥½çš„è§†é¢‘è´¨é‡ï¼Œå¦‚è¡¨ 1 æ‰€ç¤ºã€‚æ­¤å¤–ï¼Œæå‡ºçš„ ID æ¨¡å—åªéœ€è¦ 16KB çš„å­˜å‚¨ç©ºé—´ï¼Œä¸ Stable Diffusion ä¸­æ‰€éœ€çš„å‚æ•° 3.6G æˆ– SVDiff [20] ä¸­çš„ 1.7MB ç›¸æ¯”ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸ç´§å‡‘çš„å‚æ•°ç©ºé—´ã€‚</v*></p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºçš„ Video Custom Diffusionï¼ˆVCDï¼‰æ¡†æ¶æ—¨åœ¨è§£å†³å¯æ§è§†é¢‘ç”Ÿæˆä¸­ä¸»ä½“èº«ä»½æ§åˆ¶çš„æŒ‘æˆ˜ã€‚é€šè¿‡èåˆèº«ä»½ä¿¡æ¯å’Œå¸§é—´ç›¸å…³æ€§ï¼ŒVCD ä¸ºç”Ÿæˆä¸ä»…åœ¨å¸§é—´ä¿æŒä¸»ä½“èº«ä»½ï¼Œè€Œä¸”å…·æœ‰ç¨³å®šæ€§å’Œæ¸…æ™°åº¦çš„è§†é¢‘é“ºå¹³äº†é“è·¯ã€‚æˆ‘ä»¬æ–°é¢–çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬ç”¨äºç²¾ç¡®èº«ä»½åˆ†ç¦»çš„ ID æ¨¡å—ã€ç”¨äºå¢å¼ºå¸§ä¸€è‡´æ€§çš„ T2V VCD æ¨¡å—ä»¥åŠç”¨äºæé«˜è§†é¢‘è´¨é‡çš„ V2V æ¨¡å—ï¼Œå…±åŒä¸ºè§†é¢‘å†…å®¹ä¸­çš„èº«ä»½ä¿ç•™å»ºç«‹äº†æ–°çš„æ ‡å‡†ã€‚æˆ‘ä»¬è¿›è¡Œçš„å¹¿æ³›å®éªŒè‚¯å®šäº† VCD åœ¨ç”Ÿæˆé«˜è´¨é‡ã€ç¨³å®šä¸”ä¿ç•™ä¸»ä½“èº«ä»½çš„è§†é¢‘æ–¹é¢çš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ ID æ¨¡å—é€‚ç”¨äºç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œå¢å¼ºäº† VCD çš„å®ç”¨æ€§ï¼Œä½¿å…¶é€‚ç”¨äºå¹¿æ³›çš„åº”ç”¨ã€‚ï¼ˆ2ï¼‰æœ¬æ–‡çš„åˆ›æ–°ç‚¹ã€æ€§èƒ½å’Œå·¥ä½œé‡æ€»ç»“ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§ç”¨äºè§†é¢‘å®šåˆ¶æ‰©æ•£çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†èº«ä»½ä¿¡æ¯å’Œå¸§é—´ç›¸å…³æ€§ï¼Œä»¥ç”Ÿæˆå…·æœ‰ç¨³å®šèº«ä»½çš„è§†é¢‘ã€‚</li><li>è®¾è®¡äº†ä¸€ä¸ª ID æ¨¡å—ï¼Œç”¨äºä»æ–‡æœ¬æç¤ºä¸­æå–èº«ä»½ä¿¡æ¯å¹¶å°†å…¶æ³¨å…¥è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚</li><li>æå‡ºäº†ä¸€ç§ T2V VCD æ¨¡å—ï¼Œç”¨äºå¢å¼ºå¸§é—´ä¸€è‡´æ€§ï¼Œç”Ÿæˆå…·æœ‰å¹³æ»‘è¿åŠ¨å’Œæ¸…æ™°ç»†èŠ‚çš„è§†é¢‘ã€‚æ€§èƒ½ï¼š</li><li>VCD åœ¨èº«ä»½ä¿ç•™æ–¹é¢ä¼˜äºé€‰å®šçš„å¼ºåŸºçº¿ï¼Œç”Ÿæˆçš„é«˜è´¨é‡è§†é¢‘åœ¨å¸§é—´ä¿æŒäº†ä¸»ä½“èº«ä»½ã€‚</li><li>ç”±äº ID æ¨¡å—çš„å¯è¿ç§»æ€§ï¼ŒVCD ä¹Ÿé€‚ç”¨äºå…¬å¼€å¯ç”¨çš„å¾®è°ƒæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œè¿›ä¸€æ­¥æé«˜äº†å…¶å¯ç”¨æ€§ã€‚å·¥ä½œé‡ï¼š</li><li>VCD çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä»…éœ€è¦å°‘é‡é¢å¤–çš„è®¡ç®—å¼€é”€ã€‚</li><li>ID æ¨¡å—å…·æœ‰ç´§å‡‘çš„å‚æ•°ç©ºé—´ï¼Œä»…éœ€ 16KB çš„å­˜å‚¨ç©ºé—´ï¼Œä½¿å…¶æ˜“äºéƒ¨ç½²å’Œä½¿ç”¨ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-e6a21bfcb16c6c0deb1d0539ef94af7e.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f9fb6739198960204ae02b3df3b1108f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3af883ea390b349d783415082941342e.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f79fc49019e994a2b5124fecafb23683.jpg" align="middle"><img src="https://pica.zhimg.com/v2-ffb39f913681e339c8d1aa9719f971cb.jpg" align="middle"><img src="https://picx.zhimg.com/v2-8ad7c82a7b238a18cf1ae3935cfce436.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3e509076266dabf0c8283fba23dba850.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-ef1ee7f0f72cd6bec6307311ed8330ee.jpg" align="middle"></details><h2 id="SGS-SLAM-Semantic-Gaussian-Splatting-For-Neural-Dense-SLAM"><a href="#SGS-SLAM-Semantic-Gaussian-Splatting-For-Neural-Dense-SLAM" class="headerlink" title="SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM"></a>SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM</h2><p><strong>Authors:Mingrui Li, Shuhong Liu, Heng Zhou, Guohao Zhu, Na Cheng, Hongyu Wang</strong></p><p>Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM). Recent advancements that integrate Gaussian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings. Building on this progress, we propose SGS-SLAM which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation. It outperforms existing methods by a large margin meanwhile preserves real-time rendering ability. </p><p><a href="http://arxiv.org/abs/2402.03246v2">PDF</a> </p><p><strong>æ‘˜è¦</strong><br>SGS-SLAM é‡‡ç”¨å¤šé€šé“ä¼˜åŒ–ï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸèå…¥å…³é”®å¸§ä¼˜åŒ–ä¸­ï¼Œå®ç°äº†é«˜ç²¾åº¦ 3D è¯­ä¹‰åˆ†å‰²å’Œé«˜ä¿çœŸé‡å»ºã€‚</p><p><strong>å…³é”®è¦ç‚¹</strong></p><ul><li>åˆ©ç”¨é«˜æ–¯å–·å°„å°†è¯­ä¹‰ç†è§£èå…¥ SLAM ç³»ç»Ÿï¼Œç”Ÿæˆé«˜è´¨é‡æ¸²æŸ“æ•ˆæœã€‚</li><li>é‡‡ç”¨å¤šé€šé“ä¼˜åŒ–ï¼Œèåˆå¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸï¼Œæå‡é‡å»ºè´¨é‡ã€‚</li><li>åœ¨ç›¸æœºä½å§¿ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ã€‚</li><li>æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“èƒ½åŠ›ã€‚</li><li>æ‰©å±•äº† SLAM ç³»ç»Ÿçš„åº”ç”¨èŒƒå›´ï¼Œä½¿å…¶åœ¨è¯­ä¹‰ç†è§£å’Œé‡å»ºä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚</li><li>ä¸ºå®¤å†…æˆ–å®¤å¤–ç¯å¢ƒçš„é«˜ä¿çœŸé‡å»ºå’Œäº¤äº’å¼æ¢ç´¢æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚</li><li>ä¸ºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰é¢†åŸŸæä¾›äº†æ–°çš„æŠ€æœ¯æ”¯æŒã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šSGS-SLAMï¼šç”¨äºç¥ç»ç¨ å¯† SLAM çš„è¯­ä¹‰é«˜æ–¯æ–‘ç‚¹ç»˜åˆ¶</li><li>ä½œè€…ï¼šMingrui Liã€Shuhong Liuã€Heng Zhouã€Guohao Zhuã€Na Chengã€Hongyu Wang</li><li>å•ä½ï¼šå¤§è¿ç†å·¥å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ç³»</li><li>å…³é”®è¯ï¼šSLAMã€3D é‡å»ºã€3D è¯­ä¹‰åˆ†å‰²</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.03246ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè¯­ä¹‰ç†è§£åœ¨ç¨ å¯† SLAM ä¸­è‡³å…³é‡è¦ï¼Œè€Œå°†é«˜æ–¯æ–‘ç‚¹ç»˜åˆ¶é›†æˆåˆ° SLAM ç³»ç»Ÿä¸­çš„æœ€æ–°è¿›å±•å·²è¯æ˜å…¶åœ¨ç”Ÿæˆé«˜è´¨é‡æ¸²æŸ“æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚(2)ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šä¼ ç»Ÿè§†è§‰ SLAM ç³»ç»Ÿæ“…é•¿ä½¿ç”¨ç‚¹äº‘å’Œä½“ç´ è¿›è¡Œç¨€ç–é‡å»ºï¼Œä½†æ— æ³•è¿›è¡Œç¨ å¯†é‡å»ºã€‚åŸºäºå­¦ä¹ çš„ SLAM æ–¹æ³•å¯ä»¥æå–ç”¨äºé«˜è´¨é‡è¡¨ç¤ºçš„ç¨ å¯†å‡ ä½•ä¿¡æ¯ï¼Œä½†å®ƒä»¬å®¹æ˜“å—åˆ°å™ªå£°å’Œå¼‚å¸¸å€¼çš„å½±å“ã€‚ç¥ç»è¾å°„åœº (NeRF) å¯å‘çš„ SLAM æ–¹æ³•è¿›ä¸€æ­¥æé«˜äº†é‡å»ºè´¨é‡ï¼Œä½†å®ƒä»¬é€šå¸¸ä¸åŒ…å«è¯­ä¹‰ä¿¡æ¯ã€‚(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º SGS-SLAMï¼Œå®ƒåœ¨é«˜ä¿çœŸé‡å»ºçš„åŒæ—¶æä¾›ç²¾ç¡®çš„ 3D è¯­ä¹‰åˆ†å‰²ã€‚SGS-SLAM åœ¨æ˜ å°„è¿‡ç¨‹ä¸­é‡‡ç”¨å¤šé€šé“ä¼˜åŒ–ï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸä¸å…³é”®å¸§ä¼˜åŒ–ç›¸ç»“åˆï¼Œä»¥å¢å¼ºé‡å»ºè´¨é‡ã€‚(4)ï¼šä»»åŠ¡å’Œæ€§èƒ½ï¼šSGS-SLAM åœ¨ç›¸æœºå§¿æ€ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å®ƒä»¥å¾ˆå¤§çš„ä¼˜åŠ¿ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿ç•™äº†å®æ—¶æ¸²æŸ“èƒ½åŠ›ã€‚</li></ol><p>æ–¹æ³•ï¼š(1): SGS-SLAMé‡‡ç”¨å¤šé€šé“é«˜æ–¯è¡¨ç¤ºï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸä¸å…³é”®å¸§ä¼˜åŒ–ç›¸ç»“åˆï¼Œä»¥å¢å¼ºé‡å»ºè´¨é‡ã€‚(2): è·Ÿè¸ªè¿‡ç¨‹ä¼°è®¡æ¯ä¸€å¸§çš„ç›¸æœºä½å§¿ï¼ŒåŒæ—¶ä¿æŒåœºæ™¯å‚æ•°å›ºå®šã€‚æ˜ å°„ä¼˜åŒ–åŸºäºä¼°è®¡çš„ç›¸æœºä½å§¿ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºã€‚(3): åœºæ™¯è¡¨ç¤ºä½¿ç”¨é«˜æ–¯å½±å“å‡½æ•° f(Â·)ï¼Œå…¶ä¸­ Ïƒ è¡¨ç¤ºä¸é€æ˜åº¦ï¼ŒÎ¼ è¡¨ç¤ºä¸­å¿ƒä½ç½®ï¼Œr è¡¨ç¤ºåŠå¾„ã€‚æ¯ä¸ªé«˜æ–¯è¿˜æºå¸¦ RGB é¢œè‰² ciã€‚(4): ä½¿ç”¨æ¸²æŸ“æ–¹æ³•å°†é«˜æ–¯æ¸²æŸ“æˆ 2D å›¾åƒï¼Œé€šè¿‡æ²¿æ·±åº¦ç»´åº¦é€¼è¿‘å½±å“å‡½æ•° f(Â·) çš„ç§¯åˆ†æŠ•å½±æ¥å®Œæˆã€‚(5): é€šè¿‡å¯¹é«˜æ–¯è¿›è¡Œæ·±åº¦æ’åºå¹¶æ‰§è¡Œä»å‰åˆ°åçš„ä½“ç§¯æ¸²æŸ“ï¼Œå¯ä»¥ç»„åˆæ‰€æœ‰é«˜æ–¯å¯¹è¯¥åƒç´ çš„å½±å“ã€‚(6): åƒç´ çº§æ¸²æŸ“é¢œè‰² Cpix æ˜¯æ¯ä¸ªé«˜æ–¯é¢œè‰² ci çš„æ€»å’Œï¼Œå¹¶æ ¹æ®å½±å“å‡½æ•° f2Di,pix åŠ æƒï¼Œä¹˜ä»¥é®æŒ¡é¡¹ã€‚(7): æ·±åº¦å¯ä»¥æ¸²æŸ“ä¸ºï¼šDpix = âˆ‘i=1 di f2Di,pix iâˆ’1 âˆj=1 (1âˆ’f2Dj,pix)ï¼Œå…¶ä¸­ di è¡¨ç¤ºæ¯ä¸ªé«˜æ–¯çš„æ·±åº¦ã€‚(8): é€šè¿‡è®¾ç½® di=1ï¼Œå¯ä»¥è®¡ç®—å‡ºè½®å»“ Silpix = Dpix(di=1)ï¼Œè¿™æœ‰åŠ©äºç¡®å®šåƒç´ æ˜¯å¦åœ¨å½“å‰è§†å›¾ä¸­å¯è§ã€‚(9): åœ¨æ˜ å°„è¿‡ç¨‹ä¸­ï¼Œå°† 2D è¯­ä¹‰æ ‡ç­¾åˆ†é…ç»™é«˜æ–¯å‚æ•°çš„ç‰¹å®šé€šé“ä»¥è¡¨ç¤ºå…¶è¯­ä¹‰æ ‡ç­¾å’Œé¢œè‰²ã€‚(10): æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥ä»é‡å»ºçš„ 3D åœºæ™¯æ¸²æŸ“ 2D è¯­ä¹‰å›¾ï¼šSpix = âˆ‘i=1 si f2Di,pix iâˆ’1 âˆj=1 (1âˆ’f2Dj,pix)ï¼Œå…¶ä¸­ si = [ri, gi, bi]T è¡¨ç¤ºä¸é«˜æ–¯å…³è”çš„è¯­ä¹‰é¢œè‰²ã€‚(11): ç›¸æœºä½å§¿ä¼°è®¡é€šè¿‡æœ€å°åŒ–è·Ÿè¸ªæŸå¤±æ¥å®ç°ï¼Œè¯¥æŸå¤±è¡¨ç¤ºçœŸå®é¢œè‰²ã€æ·±åº¦å›¾åƒå’Œè¯­ä¹‰å›¾ä¸å…¶å¯å¾®æ¸²æŸ“è§†å›¾ä¹‹é—´çš„å·®å¼‚ã€‚(12): å…³é”®å¸§é€‰æ‹©å’ŒåŠ æƒï¼šåœ¨è·Ÿè¸ªé˜¶æ®µï¼ŒåŒæ—¶è¯†åˆ«å’Œå­˜å‚¨å…³é”®å¸§ã€‚è¿™äº›å…³é”®å¸§æä¾›äº†å¯¹è±¡çš„ä¸åŒè§†å›¾ï¼Œå¯¹äºæ˜ å°„ä¼˜åŒ– 3D åœºæ™¯é‡å»ºè‡³å…³é‡è¦ã€‚(13): SGS-SLAM åœ¨æ’å®šæ—¶é—´é—´éš”å†…æ•è·å’Œå­˜å‚¨å…³é”®å¸§ã€‚éšåï¼Œæ ¹æ®å‡ ä½•å’Œè¯­ä¹‰çº¦æŸé€‰æ‹©ä¸å½“å‰å¸§å…³è”çš„å…³é”®å¸§ã€‚(14): é¦–å…ˆè¿›è¡ŒåŸºäºå‡ ä½•çš„åˆå§‹é€‰æ‹©ï¼Œç„¶åè¿›è¡ŒåŸºäºè¯­ä¹‰çš„äºŒæ¬¡ç­›é€‰ã€‚(15): å¯¹äºæ¯ä¸ªå…³é”®å¸§ï¼Œè®¡ç®—ä¸ç¡®å®šæ€§åˆ†æ•° U(t) = eâˆ’Ï„tï¼Œå…¶ä¸­ t è¡¨ç¤ºå…³é”®å¸§çš„æ—¶é—´æˆ³ï¼ŒÏ„ ä¸ºè¡°å‡ç³»æ•°ã€‚(16): ä½¿ç”¨æ­¤ä¸ç¡®å®šæ€§åˆ†æ•°å¯¹æ˜ å°„æŸå¤± Lmapping åŠ æƒã€‚(17): åœ°å›¾é‡å»ºï¼šåœºæ™¯ä½¿ç”¨ä¸‰ä¸ªä¸åŒé€šé“çš„é«˜æ–¯å»ºæ¨¡ï¼šå®ƒä»¬çš„å‡å€¼åæ ‡è¡¨ç¤ºåœºæ™¯çš„å‡ ä½•ä¿¡æ¯ï¼Œå®ƒä»¬çš„å¤–è§‚é¢œè‰²æç»˜äº†åœºæ™¯çš„è§†è§‰å¤–è§‚ï¼Œå®ƒä»¬çš„è¯­ä¹‰é¢œè‰²è¡¨ç¤ºå¯¹è±¡çš„è¯­ä¹‰æ ‡ç­¾ã€‚(18): åœ¨é«˜æ–¯è‡´å¯†åŒ–å’Œä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œè·¨é€šé“çš„è¿™äº›å‚æ•°è¢«è”åˆä¼˜åŒ–ï¼Œè€Œä»è·Ÿè¸ªä¸­ç¡®å®šçš„ç›¸æœºä½å§¿ä¿æŒå›ºå®šã€‚(19): ä»ç¬¬ä¸€å¸§å¼€å§‹ï¼Œæ‰€æœ‰åƒç´ éƒ½æœ‰åŠ©äºåˆå§‹åŒ–åœ°å›¾ã€‚(20): åœ¨æ–°æ—¶é—´æ­¥çš„åœ°å›¾é‡å»ºè¿‡ç¨‹ä¸­ï¼Œå°†æ–°é«˜æ–¯å¼•å…¥åˆ°åœ°å›¾ä¸­ï¼Œè¿™äº›åŒºåŸŸè¦ä¹ˆå¯†åº¦ä¸è¶³ï¼Œè¦ä¹ˆæ˜¾ç¤ºå…ˆå‰ä¼°è®¡çš„åœ°å›¾å‰é¢çš„æ–°å‡ ä½•å½¢çŠ¶ã€‚(21): é€šè¿‡å°†æ©ç åº”ç”¨äºåƒç´ æ¥è°ƒèŠ‚æ–°é«˜æ–¯çš„æ·»åŠ ï¼Œå…¶ä¸­è¦ä¹ˆ (i) è½®å»“å€¼ Silpix ä½äºæŸä¸ªé˜ˆå€¼ï¼Œè¡¨ç¤ºå¯è§æ€§é«˜åº¦ä¸ç¡®å®šï¼Œè¦ä¹ˆ (ii) çœŸå®æ·±åº¦è¿œå°äºä¼°è®¡æ·±åº¦ï¼Œè¡¨æ˜å­˜åœ¨æ–°çš„å‡ ä½•å®ä½“ã€‚(22): è‡´å¯†åŒ–åï¼Œé€šè¿‡æœ€å°åŒ–æ˜ å°„æŸå¤±æ¥ä¼˜åŒ–åœ°å›¾å‚æ•°ï¼šLmapping = U âˆ‘pix Î»D |DGTpixâˆ’Dpix| + Î»C L C + Î»S L Sã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰ï¼šSGS-SLAM åœ¨è¿›è¡Œé«˜ä¿çœŸé‡å»ºçš„åŒæ—¶æä¾›äº†ç²¾ç¡®çš„ 3D è¯­ä¹‰åˆ†å‰²ï¼Œåœ¨ç›¸æœºå§¿æ€ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸ºç¥ç»ç¨ å¯† SLAM æä¾›äº†ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆã€‚ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç¼ºç‚¹æ€»ç»“ï¼šåˆ›æ–°ç‚¹ï¼šSGS-SLAM é‡‡ç”¨å¤šé€šé“é«˜æ–¯è¡¨ç¤ºï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸä¸å…³é”®å¸§ä¼˜åŒ–ç›¸ç»“åˆï¼Œå¢å¼ºäº†é‡å»ºè´¨é‡ï¼Œå¹¶é¦–æ¬¡å°†è¯­ä¹‰ä¿¡æ¯é›†æˆåˆ°ç¥ç»ç¨ å¯† SLAM ç³»ç»Ÿä¸­ã€‚æ€§èƒ½ï¼šSGS-SLAM åœ¨ç›¸æœºå§¿æ€ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä»¥å¾ˆå¤§çš„ä¼˜åŠ¿ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿ç•™äº†å®æ—¶æ¸²æŸ“èƒ½åŠ›ã€‚å·¥ä½œé‡ï¼šSGS-SLAM çš„å®ç°éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ•°æ®ï¼Œè¿™å¯èƒ½ä¼šé™åˆ¶å…¶åœ¨æŸäº›èµ„æºå—é™çš„åº”ç”¨ä¸­çš„ä½¿ç”¨ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-49d695fd07273ec0ead5f03d33095327.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f9e64fa80d8afdcf89c98cfd50dd717f.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-29  VastGaussian Vast 3D Gaussians for Large Scene Reconstruction</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="3DGS" scheme="https://kedreamix.github.io/tags/3DGS/"/>
    
  </entry>
  
  <entry>
    <title>Talking Head Generation</title>
    <link href="https://kedreamix.github.io/2024/02/29/Paper/2024-02-29/Talking%20Head%20Generation/"/>
    <id>https://kedreamix.github.io/2024/02/29/Paper/2024-02-29/Talking%20Head%20Generation/</id>
    <published>2024-02-29T12:47:51.000Z</published>
    <updated>2024-03-11T11:38:44.836Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-02-29-æ›´æ–°"><a href="#2024-02-29-æ›´æ–°" class="headerlink" title="2024-02-29 æ›´æ–°"></a>2024-02-29 æ›´æ–°</h1><h2 id="EMO-Emote-Portrait-Alive-Generating-Expressive-Portrait-Videos-with-Audio2Video-Diffusion-Model-under-Weak-Conditions"><a href="#EMO-Emote-Portrait-Alive-Generating-Expressive-Portrait-Videos-with-Audio2Video-Diffusion-Model-under-Weak-Conditions" class="headerlink" title="EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with   Audio2Video Diffusion Model under Weak Conditions"></a>EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with   Audio2Video Diffusion Model under Weak Conditions</h2><p><strong>Authors:Linrui Tian, Qi Wang, Bang Zhang, Liefeng Bo</strong></p><p>In this work, we tackle the challenge of enhancing the realism and expressiveness in talking head video generation by focusing on the dynamic and nuanced relationship between audio cues and facial movements. We identify the limitations of traditional techniques that often fail to capture the full spectrum of human expressions and the uniqueness of individual facial styles. To address these issues, we propose EMO, a novel framework that utilizes a direct audio-to-video synthesis approach, bypassing the need for intermediate 3D models or facial landmarks. Our method ensures seamless frame transitions and consistent identity preservation throughout the video, resulting in highly expressive and lifelike animations. Experimental results demonsrate that EMO is able to produce not only convincing speaking videos but also singing videos in various styles, significantly outperforming existing state-of-the-art methodologies in terms of expressiveness and realism. </p><p><a href="http://arxiv.org/abs/2402.17485v1">PDF</a> </p><p><strong>Summary</strong><br>éŸ³é¢‘çº¿ç´¢èƒ½å¤ŸååŠ©ç”Ÿæˆæ›´å…·è¡¨ç°åŠ›å’ŒçœŸå®æ„Ÿçš„é¢éƒ¨åŠ¨ç”»ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ä¼ ç»ŸæŠ€æœ¯æ— æ³•å……åˆ†æ•æ‰äººç±»é¢éƒ¨è¡¨æƒ…å’Œä¸ªäººé£æ ¼å·®å¼‚ã€‚</li><li>EMO æ¡†æ¶é‡‡ç”¨ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆæ–¹æ³•ï¼Œæ— éœ€ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹ã€‚</li><li>EMO å¯ç”Ÿæˆæµç•…æ— ç¼çš„è§†é¢‘ï¼Œå¹¶å§‹ç»ˆä¿æŒèº«ä»½ä¸€è‡´æ€§ã€‚</li><li>EMO å¯ç”Ÿæˆå…·æœ‰é«˜åº¦è¡¨ç°åŠ›å’ŒçœŸå®æ„Ÿçš„è¯´è¯å’Œå”±æ­Œè§†é¢‘ã€‚</li><li>EMO åœ¨è¡¨ç°åŠ›å’ŒçœŸå®æ„Ÿæ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li><li>EMO å……åˆ†åˆ©ç”¨äº†éŸ³é¢‘çº¿ç´¢ï¼Œæå‡äº†é¢éƒ¨åŠ¨ç”»çš„åŠ¨æ€æ€§å’Œç»†è‡´åº¦ã€‚</li><li>EMO å¯å¹¿æ³›åº”ç”¨äºå„ç§é¢†åŸŸï¼ŒåŒ…æ‹¬ç”µå½±ã€æ¸¸æˆå’Œè§†é¢‘ä¼šè®®ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šEMOï¼šEmotePortraitAliveâ€”â€”åœ¨å¼±æ¡ä»¶ä¸‹ä½¿ç”¨éŸ³é¢‘åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›çš„è‚–åƒè§†é¢‘</li><li>ä½œè€…ï¼šTian Linruiã€Wang Qiã€Zhang Bangã€Bo Liefeng</li><li>éš¶å±å•ä½ï¼šé˜¿é‡Œå·´å·´é›†å›¢æ™ºèƒ½è®¡ç®—ç ”ç©¶é™¢</li><li>å…³é”®è¯ï¼šAudio-driven portrait video generationã€Talking headã€Expressive facial expressionsã€Audio-to-video synthesis</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://humanaigc.github.io/emote-portrait-alive/   Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š   åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä¸­ï¼Œå¢å¼ºçœŸå®æ„Ÿå’Œè¡¨ç°åŠ›æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œéœ€è¦å…³æ³¨éŸ³é¢‘çº¿ç´¢å’Œé¢éƒ¨åŠ¨ä½œä¹‹é—´çš„åŠ¨æ€å’Œç»†å¾®å…³ç³»ã€‚ä¼ ç»ŸæŠ€æœ¯å¾€å¾€æ— æ³•æ•æ‰åˆ°äººç±»è¡¨æƒ…çš„å…¨è²Œå’Œä¸ªäººé¢éƒ¨é£æ ¼çš„ç‹¬ç‰¹æ€§ã€‚   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼š   ä¼ ç»Ÿçš„è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆæ–¹æ³•é€šå¸¸éœ€è¦ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹ï¼Œè¿™ä¼šå¼•å…¥é¢å¤–çš„å¤æ‚æ€§å’Œé™åˆ¶ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨æ•æ‰ç»†å¾®çš„è¡¨æƒ…å’Œä¿æŒå¸§ä¹‹é—´çš„ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨å›°éš¾ã€‚   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š   æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º EMO çš„æ–°æ¡†æ¶ï¼Œå®ƒé‡‡ç”¨ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆçš„æ–¹æ³•ï¼Œç»•è¿‡äº†å¯¹ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹çš„éœ€æ±‚ã€‚è¯¥æ–¹æ³•åˆ©ç”¨éŸ³é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†éŸ³é¢‘çº¿ç´¢ç›´æ¥æ˜ å°„åˆ°è§†é¢‘å¸§ï¼Œç¡®ä¿äº†æ— ç¼çš„å¸§è¿‡æ¸¡å’Œä¸€è‡´çš„é¢éƒ¨åŠ¨ä½œã€‚   ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼š   EMO åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿çš„é€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„è§†é¢‘æ–¹é¢å–å¾—äº†æ˜¾ç€æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡å¢å¼ºè¯´è¯äººå¤´åƒè§†é¢‘ç”ŸæˆçœŸå®æ„Ÿå’Œè¡¨ç°åŠ›çš„ç›®æ ‡ã€‚</li></ol><p>7.æ–¹æ³•ï¼šï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§åä¸ºEMOçš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆçš„æ–¹æ³•ï¼Œç»•è¿‡äº†å¯¹ä¸­é—´3Dæ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹çš„éœ€æ±‚ã€‚ï¼ˆ2ï¼‰è¯¥æ–¹æ³•åˆ©ç”¨éŸ³é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†éŸ³é¢‘çº¿ç´¢ç›´æ¥æ˜ å°„åˆ°è§†é¢‘å¸§ï¼Œç¡®ä¿äº†æ— ç¼çš„å¸§è¿‡æ¸¡å’Œä¸€è‡´çš„é¢éƒ¨åŠ¨ä½œã€‚ï¼ˆ3ï¼‰åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šå¯¹EMOè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿çš„é€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„è§†é¢‘æ–¹é¢å–å¾—äº†æ˜¾ç€æ€§èƒ½ã€‚</p><ol><li>ç»“è®ºï¼š(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åä¸º EMO çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆçš„æ–¹æ³•ï¼Œç»•è¿‡äº†å¯¹ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹çš„éœ€æ±‚ã€‚è¯¥æ–¹æ³•åˆ©ç”¨éŸ³é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†éŸ³é¢‘çº¿ç´¢ç›´æ¥æ˜ å°„åˆ°è§†é¢‘å¸§ï¼Œç¡®ä¿äº†æ— ç¼çš„å¸§è¿‡æ¸¡å’Œä¸€è‡´çš„é¢éƒ¨åŠ¨ä½œã€‚åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šå¯¹ EMO è¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿çš„é€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„è§†é¢‘æ–¹é¢å–å¾—äº†æ˜¾ç€æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡å¢å¼ºè¯´è¯äººå¤´åƒè§†é¢‘ç”ŸæˆçœŸå®æ„Ÿå’Œè¡¨ç°åŠ›çš„ç›®æ ‡ã€‚(2): åˆ›æ–°ç‚¹ï¼š</li><li>ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆçš„æ–¹æ³•ï¼Œç»•è¿‡äº†å¯¹ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹çš„éœ€æ±‚ã€‚</li><li>åˆ©ç”¨éŸ³é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†éŸ³é¢‘çº¿ç´¢ç›´æ¥æ˜ å°„åˆ°è§†é¢‘å¸§ï¼Œç¡®ä¿äº†æ— ç¼çš„å¸§è¿‡æ¸¡å’Œä¸€è‡´çš„é¢éƒ¨åŠ¨ä½œã€‚æ€§èƒ½ï¼š</li><li>åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾ç€æ€§èƒ½ã€‚</li><li>ç”Ÿæˆäº†å…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿çš„é€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„è§†é¢‘ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦å¤æ‚çš„ä¸­é—´æ­¥éª¤æˆ–é¢å¤–çš„æ¨¡å‹ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-10c8e47dfe09b5369134bad3bf5b1e69.jpg" align="middle"><img src="https://picx.zhimg.com/v2-262ccbd331f2623737aa6cbcc24c64e5.jpg" align="middle"></details><h2 id="Learning-Dynamic-Tetrahedra-for-High-Quality-Talking-Head-Synthesis"><a href="#Learning-Dynamic-Tetrahedra-for-High-Quality-Talking-Head-Synthesis" class="headerlink" title="Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis"></a>Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis</h2><p><strong>Authors:Zicheng Zhang, Ruobing Zheng, Ziwen Liu, Congying Han, Tianqi Li, Meng Wang, Tiande Guo, Jingdong Chen, Bonan Li, Ming Yang</strong></p><p>Recent works in implicit representations, such as Neural Radiance Fields (NeRF), have advanced the generation of realistic and animatable head avatars from video sequences. These implicit methods are still confronted by visual artifacts and jitters, since the lack of explicit geometric constraints poses a fundamental challenge in accurately modeling complex facial deformations. In this paper, we introduce Dynamic Tetrahedra (DynTet), a novel hybrid representation that encodes explicit dynamic meshes by neural networks to ensure geometric consistency across various motions and viewpoints. DynTet is parameterized by the coordinate-based networks which learn signed distance, deformation, and material texture, anchoring the training data into a predefined tetrahedra grid. Leveraging Marching Tetrahedra, DynTet efficiently decodes textured meshes with a consistent topology, enabling fast rendering through a differentiable rasterizer and supervision via a pixel loss. To enhance training efficiency, we incorporate classical 3D Morphable Models to facilitate geometry learning and define a canonical space for simplifying texture learning. These advantages are readily achievable owing to the effective geometric representation employed in DynTet. Compared with prior works, DynTet demonstrates significant improvements in fidelity, lip synchronization, and real-time performance according to various metrics. Beyond producing stable and visually appealing synthesis videos, our method also outputs the dynamic meshes which is promising to enable many emerging applications. </p><p><a href="http://arxiv.org/abs/2402.17364v1">PDF</a> CVPR 2024</p><p><strong>Summary</strong><br>ç¥ç»ç½‘ç»œç¼–ç çš„åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰æ˜¯ä¸€ç§ç»“åˆè¡¨ç¤ºæ–¹æ³•ï¼Œç¡®ä¿äº†å¤æ‚é¢éƒ¨å˜å½¢åœ¨å„ç§åŠ¨ä½œå’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>DynTet é‡‡ç”¨åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå°†æ˜¾å¼åŠ¨æ€ç½‘æ ¼ç¼–ç åˆ°ç¥ç»ç½‘ç»œä¸­ï¼Œä»¥ç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ã€‚</li><li>åæ ‡ç½‘ç»œç”¨äºå­¦ä¹ ç¬¦å·è·ç¦»ã€å½¢å˜å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚</li><li>è¿ç”¨ Marching Tetrahedraï¼ŒDynTet æœ‰æ•ˆåœ°è§£ç å…·æœ‰è¿ç»­æ‹“æ‰‘çš„çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å™¨å®ç°å¿«é€Ÿæ¸²æŸ“å¹¶åˆ©ç”¨åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ã€‚</li><li>DynTet ç»“åˆç»å…¸ 3D å¯å˜å½¢æ¨¡å‹ï¼Œä»¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ å¹¶å®šä¹‰ä¸€ç§è§„èŒƒç©ºé—´ä»¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</li><li>DynTet ç›¸æ¯”äºå…ˆå‰çš„ç ”ç©¶ï¼Œåœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢éƒ½æœ‰æ˜¾è‘—æå‡ã€‚</li><li>é™¤äº†åˆ¶ä½œç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘ï¼Œè¯¥æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›å®ç°è®¸å¤šæ–°å…´åº”ç”¨ã€‚</li><li>DynTet å¼¥è¡¥äº†éšå¼æ–¹æ³•ç¼ºä¹æ˜¾å¼å‡ ä½•çº¦æŸçš„é—®é¢˜ï¼Œé€šè¿‡å­¦ä¹ åŠ¨æ€ç½‘æ ¼æ¥æé«˜é¢éƒ¨å˜å½¢å»ºæ¨¡çš„å‡†ç¡®æ€§ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šç”¨äºé«˜è´¨é‡è¯´è¯äººå¤´éƒ¨åˆæˆçš„åŠ¨æ€å››é¢ä½“å­¦ä¹ </li><li>ä½œè€…ï¼šZhang Zhicheng, Xu Chenyang, Zhang Haoran, Wu Yuxuan, Wang Yebin, Chen Min, Chen Biao</li><li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šè¯´è¯äººå¤´éƒ¨åˆæˆã€åŠ¨æ€ç½‘æ ¼ã€éšå¼è¡¨ç¤ºã€ç¥ç»è¾å°„åœº</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.05915</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšå¼è¡¨ç¤ºæ–¹æ³•ï¼Œå¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œåœ¨ä»è§†é¢‘åºåˆ—ä¸­ç”Ÿæˆé€¼çœŸä¸”å¯åŠ¨ç”»çš„å¤´éƒ¨å¤´åƒæ–¹é¢å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ˜¾å¼å‡ ä½•çº¦æŸï¼Œè¿™äº›éšå¼æ–¹æ³•ä»é¢ä¸´è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨çš„æŒ‘æˆ˜ï¼Œè¿™ç»™å‡†ç¡®å»ºæ¨¡å¤æ‚çš„é¢éƒ¨å˜å½¢å¸¦æ¥äº†æ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šä»¥å¾€æ–¹æ³•ä¸»è¦é‡‡ç”¨éšå¼è¡¨ç¤ºï¼Œç”±äºç¼ºä¹æ˜¾å¼å‡ ä½•çº¦æŸï¼Œå­˜åœ¨è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨é—®é¢˜ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºï¼Œå®ƒé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿åœ¨å„ç§è¿åŠ¨å’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚DynTet ç”±åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œè¿™äº›ç½‘ç»œå­¦ä¹ æœ‰ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚åˆ©ç”¨è¡Œè¿›å››é¢ä½“ï¼ŒDynTet æœ‰æ•ˆåœ°è§£ç å…·æœ‰ç»Ÿä¸€æ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å™¨å’Œåƒç´ æŸå¤±è¿›è¡Œç›‘ç£ï¼Œä»è€Œå®ç°å¿«é€Ÿæ¸²æŸ“ã€‚ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡ï¼Œæˆ‘ä»¬ç»“åˆäº†ç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹ï¼Œä»¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ å¹¶å®šä¹‰è§„èŒƒç©ºé—´ä»¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚ç”±äº DynTet ä¸­é‡‡ç”¨æœ‰æ•ˆçš„å‡ ä½•è¡¨ç¤ºï¼Œè¿™äº›ä¼˜åŠ¿å¾ˆå®¹æ˜“å®ç°ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šä¸ä¹‹å‰çš„å·¥ä½œç›¸æ¯”ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢æ ¹æ®å„ç§æŒ‡æ ‡å±•ç¤ºäº†æ˜¾ç€çš„æ”¹è¿›ã€‚é™¤äº†åˆ¶ä½œç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œè¿™æœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1): æå‡ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰æ¡†æ¶ï¼Œå¿«é€Ÿä»çŸ­è§†é¢‘åºåˆ—å­¦ä¹  3D å¤´éƒ¨å¤´åƒï¼Œå¹¶å®ç°é«˜è´¨é‡è¯´è¯äººå¤´éƒ¨å®æ—¶æ¸²æŸ“ã€‚(2): æ”¹è¿›å››é¢ä½“è¡¨ç¤ºï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿ä¸åŒè¿åŠ¨å’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚(3): é‡‡ç”¨è¡Œè¿›å››é¢ä½“è§£ç å…·æœ‰ç»Ÿä¸€æ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å™¨å’Œåƒç´ æŸå¤±è¿›è¡Œç›‘ç£ï¼Œå®ç°å¿«é€Ÿæ¸²æŸ“ã€‚(4): ç»“åˆç»å…¸ 3D å¯å˜å½¢æ¨¡å‹ï¼Œä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå®šä¹‰è§„èŒƒç©ºé—´ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åä¸ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰çš„æ–°å‹æ··åˆè¡¨ç¤ºï¼Œç”¨äºä»çŸ­è§†é¢‘åºåˆ—ä¸­å­¦ä¹ é€¼çœŸä¸”å¯åŠ¨ç”»çš„è¯´è¯äººå¤´éƒ¨ï¼Œå¹¶å®ç°äº†é«˜è´¨é‡è¯´è¯äººå¤´éƒ¨å®æ—¶æ¸²æŸ“ã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰æ¡†æ¶ï¼Œå¿«é€Ÿä»çŸ­è§†é¢‘åºåˆ—å­¦ä¹  3D å¤´éƒ¨å¤´åƒï¼Œå¹¶å®ç°é«˜è´¨é‡è¯´è¯äººå¤´éƒ¨å®æ—¶æ¸²æŸ“ã€‚æ”¹è¿›å››é¢ä½“è¡¨ç¤ºï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿ä¸åŒè¿åŠ¨å’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚é‡‡ç”¨è¡Œè¿›å››é¢ä½“è§£ç å…·æœ‰ç»Ÿä¸€æ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å™¨å’Œåƒç´ æŸå¤±è¿›è¡Œç›‘ç£ï¼Œå®ç°å¿«é€Ÿæ¸²æŸ“ã€‚ç»“åˆç»å…¸ 3D å¯å˜å½¢æ¨¡å‹ï¼Œä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå®šä¹‰è§„èŒƒç©ºé—´ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚æ€§èƒ½ï¼šä¸ä¹‹å‰çš„å·¥ä½œç›¸æ¯”ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢æ ¹æ®å„ç§æŒ‡æ ‡å±•ç¤ºäº†æ˜¾ç€çš„æ”¹è¿›ã€‚é™¤äº†åˆ¶ä½œç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œè¿™æœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œæ¶‰åŠåˆ°ç¥ç»ç½‘ç»œã€åŠ¨æ€ç½‘æ ¼ã€éšå¼è¡¨ç¤ºã€ç¥ç»è¾å°„åœºç­‰å¤šä¸ªæ–¹é¢ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªæ–°çš„æ··åˆè¡¨ç¤ºâ€”â€”åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå¹¶å°†å…¶åº”ç”¨äºè¯´è¯äººå¤´éƒ¨åˆæˆä»»åŠ¡ä¸­ã€‚DynTet ç»“åˆäº†æ˜¾å¼åŠ¨æ€ç½‘æ ¼å’Œéšå¼è¡¨ç¤ºçš„ä¼˜ç‚¹ï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸä¸”å¯åŠ¨ç”»çš„å¤´éƒ¨å¤´åƒã€‚ä½œè€…è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„è®­ç»ƒæ¡†æ¶ï¼Œç»“åˆäº†ç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹å’Œå¯å¾®æ¸²æŸ“å™¨ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ å‡ ä½•å’Œçº¹ç†ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆè§†é¢‘ã€‚æ€»ä½“è€Œè¨€ï¼Œæœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œä½†æå‡ºçš„æ–¹æ³•æ–°é¢–æœ‰æ•ˆï¼Œåœ¨è¯´è¯äººå¤´éƒ¨åˆæˆé¢†åŸŸå…·æœ‰é‡è¦çš„æ„ä¹‰ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-2927e4da13bb2db0a8c147b32e65c4ba.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-a69eb8d9ee3b7163b0dd216926919257.jpg" align="middle"><img src="https://picx.zhimg.com/v2-989288a0ad24820fe95020a4ed1f2ea7.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">Talking Head Generation æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-29  G4GA Generic Framework for High Fidelity Talking Face Generation with   Fine-grained Intra-modal Alignment</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="Talking Head Generation" scheme="https://kedreamix.github.io/tags/Talking-Head-Generation/"/>
    
  </entry>
  
  <entry>
    <title>Diffusion Models</title>
    <link href="https://kedreamix.github.io/2024/02/29/Paper/2024-02-29/Diffusion%20Models/"/>
    <id>https://kedreamix.github.io/2024/02/29/Paper/2024-02-29/Diffusion%20Models/</id>
    <published>2024-02-29T12:37:28.000Z</published>
    <updated>2024-02-29T12:37:28.331Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-02-29-æ›´æ–°"><a href="#2024-02-29-æ›´æ–°" class="headerlink" title="2024-02-29 æ›´æ–°"></a>2024-02-29 æ›´æ–°</h1><h2 id="Objective-and-Interpretable-Breast-Cosmesis-Evaluation-with-Attention-Guided-Denoising-Diffusion-Anomaly-Detection-Model"><a href="#Objective-and-Interpretable-Breast-Cosmesis-Evaluation-with-Attention-Guided-Denoising-Diffusion-Anomaly-Detection-Model" class="headerlink" title="Objective and Interpretable Breast Cosmesis Evaluation with Attention   Guided Denoising Diffusion Anomaly Detection Model"></a>Objective and Interpretable Breast Cosmesis Evaluation with Attention   Guided Denoising Diffusion Anomaly Detection Model</h2><p><strong>Authors:Sangjoon Park, Yong Bae Kim, Jee Suk Chang, Seo Hee Choi, Hyungjin Chung, Ik Jae Lee, Hwa Kyung Byun</strong></p><p>As advancements in the field of breast cancer treatment continue to progress, the assessment of post-surgical cosmetic outcomes has gained increasing significance due to its substantial impact on patientsâ€™ quality of life. However, evaluating breast cosmesis presents challenges due to the inherently subjective nature of expert labeling. In this study, we present a novel automated approach, Attention-Guided Denoising Diffusion Anomaly Detection (AG-DDAD), designed to assess breast cosmesis following surgery, addressing the limitations of conventional supervised learning and existing anomaly detection models. Our approach leverages the attention mechanism of the distillation with no label (DINO) self-supervised Vision Transformer (ViT) in combination with a diffusion model to achieve high-quality image reconstruction and precise transformation of discriminative regions. By training the diffusion model on unlabeled data predominantly with normal cosmesis, we adopt an unsupervised anomaly detection perspective to automatically score the cosmesis. Real-world data experiments demonstrate the effectiveness of our method, providing visually appealing representations and quantifiable scores for cosmesis evaluation. Compared to commonly used rule-based programs, our fully automated approach eliminates the need for manual annotations and offers objective evaluation. Moreover, our anomaly detection model exhibits state-of-the-art performance, surpassing existing models in accuracy. Going beyond the scope of breast cosmesis, our research represents a significant advancement in unsupervised anomaly detection within the medical domain, thereby paving the way for future investigations. </p><p><a href="http://arxiv.org/abs/2402.18362v1">PDF</a> </p><p><strong>Summary</strong><br>åˆ©ç”¨æ— äººç›‘ç£æ–¹æ³•ï¼Œè‡ªåŠ¨è¯„ä¼°ä¹³è…ºç™Œæœ¯åå¤–è§‚ï¼Œä¸ºæé«˜æ‚£è€…ç”Ÿæ´»è´¨é‡æä¾›æ–°é€”å¾„ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>é‡‡ç”¨æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹è§†è§’ï¼Œæ— éœ€æ ‡è®°å³å¯è¯„ä¼°å¤–è§‚ã€‚</li><li>ä½¿ç”¨è’¸é¦æ— æ ‡ç­¾ (DINO) è‡ªç›‘ç£è§†è§‰ Transformer (ViT) çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°é«˜è´¨é‡å›¾åƒé‡å»ºå’Œåˆ¤åˆ«åŒºåŸŸçš„ç²¾ç¡®è½¬æ¢ã€‚</li><li>åœ¨ä»¥æ­£å¸¸å¤–è§‚ä¸ºä¸»çš„æœªæ ‡è®°æ•°æ®ä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‚</li><li>æä¾›è§†è§‰ä¸Šå¸å¼•äººçš„è¡¨ç¤ºå’Œå¯é‡åŒ–çš„åˆ†æ•°ï¼Œç”¨äºå¤–è§‚è¯„ä¼°ã€‚</li><li>æ¶ˆé™¤äººå·¥æ ‡æ³¨çš„éœ€è¦ï¼Œæä¾›å®¢è§‚è¯„ä¼°ã€‚</li><li>åœ¨å‡†ç¡®æ€§æ–¹é¢è¶…è¿‡ç°æœ‰æ¨¡å‹ï¼Œå±•ç°å‡ºæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li><li>ä¸ºåŒ»å­¦é¢†åŸŸçš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹æä¾›äº†é‡å¤§è¿›å±•ã€‚</li><li>æ¢ç´¢æ— ç›‘ç£å¤–è§‚è¯„ä¼°åœ¨å…¶ä»–åŒ»ç–—é¢†åŸŸçš„æ½œåŠ›ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>Title: åŸºäºæ³¨æ„åŠ›å¼•å¯¼å»å™ªæ‰©æ•£çš„å®¢è§‚å¯è§£é‡Šä¹³æˆ¿ç¾è§‚è¯„ä¼°</li><li>Authors: Sangjoon Park, YongBae Kim, JeeSuk Chang, SeoHee Choi, Hyungjin Chung, IkJae Lee, HwaKyung Byun</li><li>Affiliation: éŸ©å›½é¦–å°”å»¶ä¸–å¤§å­¦åŒ»å­¦é™¢æ”¾å°„è‚¿ç˜¤ç§‘</li><li>Keywords: æ‰©æ•£æ¨¡å‹ã€å¼‚å¸¸æ£€æµ‹ã€è§†è§‰ Transformerã€ä¹³æˆ¿ç¾è§‚</li><li>Urls: Paper, Github: None</li><li><p>Summary:(1): ä¹³æˆ¿ç™Œæœ¯åç¾è§‚è¯„ä¼°å¯¹æ‚£è€…ç”Ÿæ´»è´¨é‡å½±å“å¾ˆå¤§ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•å­˜åœ¨ä¸»è§‚æ€§å¼ºã€ä¾èµ–äººå·¥æ ‡æ³¨ç­‰é—®é¢˜ã€‚(2): ç°æœ‰æ–¹æ³•ä¾èµ–ä¸“å®¶æ ‡æ³¨ï¼Œå­˜åœ¨æˆæœ¬é«˜ã€æ ‡æ³¨åå·®ã€æ¨¡å‹è¿‡æ‹Ÿåˆã€å¯è§£é‡Šæ€§å·®ç­‰é—®é¢˜ã€‚(3): æœ¬æ–‡æå‡ºä¸€ç§åä¸º AG-DDAD çš„åˆ›æ–°æ¶æ„ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’Œ DINO è§†è§‰ Transformer æ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ã€‚è¯¥æ¨¡å‹å¯ä»¥åœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œåˆ©ç”¨æ¥è‡ª 1,237 åä¸»è¦ä¸ºæ­£å¸¸ç¾è§‚ï¼ˆä¼˜ç§€åˆ°è‰¯å¥½ï¼‰æ‚£è€…çš„æœªæ ‡è®°æ•°æ®ï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ã€‚AG-DDAD é€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚(4): åœ¨ä¸€ä¸ªç»è¿‡ç²¾å¿ƒæ•´ç†çš„åŒ…å« 300 åæ¥å—ä¹³è…ºç™Œä¿ä¹³æ‰‹æœ¯æ‚£è€…çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ¨¡å‹ä¼˜äºä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æ–¹æ³•å’Œå…¶ä»–æœ€å…ˆè¿›çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šæå‡ºä¸€ç§åä¸º AG-DDAD çš„åˆ›æ–°æ¶æ„ï¼Œè¯¥æ¶æ„åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’Œ DINO è§†è§‰ Transformer æ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ï¼›ï¼ˆ2ï¼‰ï¼šAG-DDAD åœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œåˆ©ç”¨æ¥è‡ªä¸»è¦ä¸ºæ­£å¸¸ç¾è§‚ï¼ˆä¼˜ç§€åˆ°è‰¯å¥½ï¼‰æ‚£è€…çš„æœªæ ‡è®°æ•°æ®ï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ï¼›ï¼ˆ3ï¼‰ï¼šAG-DDAD é€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›å¼•å¯¼å»å™ªæ‰©æ•£çš„å®¢è§‚å¯è§£é‡Šä¹³æˆ¿ç¾è§‚è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’ŒDINOè§†è§‰Transformeræ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ï¼Œåœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ï¼Œé€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›å¼•å¯¼å»å™ªæ‰©æ•£çš„å®¢è§‚å¯è§£é‡Šä¹³æˆ¿ç¾è§‚è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’ŒDINOè§†è§‰Transformeræ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ã€‚</li><li>è¯¥æ–¹æ³•åœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ï¼Œé€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚æ€§èƒ½ï¼š</li><li>åœ¨ä¸€ä¸ªç»è¿‡ç²¾å¿ƒæ•´ç†çš„åŒ…å«300åæ¥å—ä¹³è…ºç™Œä¿ä¹³æ‰‹æœ¯æ‚£è€…çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ¨¡å‹ä¼˜äºä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æ–¹æ³•å’Œå…¶ä»–æœ€å…ˆè¿›çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•éœ€è¦æ¯”ä¼ ç»Ÿçš„åˆ†ç±»å™¨æ¨¡å‹ç•¥å¤šçš„æ—¶é—´ï¼Œè¯„ä¼°å•ä¸ªæ‚£è€…çš„ç¾è§‚å¤§çº¦éœ€è¦15ç§’ï¼Œè€Œç®€å•çš„åˆ†ç±»å™¨æ¨¡å‹å¯ä»¥åœ¨1ç§’å†…äº§ç”Ÿç»“æœã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-678c2254dd6a3d39889bef35f9067c05.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-cfa8a6039aebee57a2721ad761165bd3.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-d6811aab9ac5a0e1edc535c928e3bd0f.jpg" align="middle"></details><h2 id="FineDiffusion-Scaling-up-Diffusion-Models-for-Fine-grained-Image-Generation-with-10-000-Classes"><a href="#FineDiffusion-Scaling-up-Diffusion-Models-for-Fine-grained-Image-Generation-with-10-000-Classes" class="headerlink" title="FineDiffusion: Scaling up Diffusion Models for Fine-grained Image   Generation with 10,000 Classes"></a>FineDiffusion: Scaling up Diffusion Models for Fine-grained Image   Generation with 10,000 Classes</h2><p><strong>Authors:Ziying Pan, Kun Wang, Gang Li, Feihong He, Xiwang Li, Yongxuan Lai</strong></p><p>The class-conditional image generation based on diffusion models is renowned for generating high-quality and diverse images. However, most prior efforts focus on generating images for general categories, e.g., 1000 classes in ImageNet-1k. A more challenging task, large-scale fine-grained image generation, remains the boundary to explore. In this work, we present a parameter-efficient strategy, called FineDiffusion, to fine-tune large pre-trained diffusion models scaling to large-scale fine-grained image generation with 10,000 categories. FineDiffusion significantly accelerates training and reduces storage overhead by only fine-tuning tiered class embedder, bias terms, and normalization layersâ€™ parameters. To further improve the image generation quality of fine-grained categories, we propose a novel sampling method for fine-grained image generation, which utilizes superclass-conditioned guidance, specifically tailored for fine-grained categories, to replace the conventional classifier-free guidance sampling. Compared to full fine-tuning, FineDiffusion achieves a remarkable 1.56x training speed-up and requires storing merely 1.77% of the total model parameters, while achieving state-of-the-art FID of 9.776 on image generation of 10,000 classes. Extensive qualitative and quantitative experiments demonstrate the superiority of our method compared to other parameter-efficient fine-tuning methods. The code and more generated results are available at our project website: <a href="https://finediffusion.github.io/">https://finediffusion.github.io/</a>. </p><p><a href="http://arxiv.org/abs/2402.18331v1">PDF</a> </p><p><strong>Summary</strong><br>é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œä»¥å‚æ•°é«˜æ•ˆç­–ç•¥å®ç°é’ˆå¯¹ 10,000 ä¸ªç»†ç²’åº¦ç±»åˆ«çš„å¤§è§„æ¨¡å›¾åƒç”Ÿæˆ</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡º FineDiffusionï¼Œå°†å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹ç¼©å°åˆ°ç»†ç²’åº¦å›¾åƒç”Ÿæˆä¸­</li><li>åªå¾®è°ƒåˆ†ç±»åµŒå…¥ã€åç½®é¡¹å’Œå½’ä¸€åŒ–å±‚çš„å‚æ•°ï¼Œå¤§å¹…æå‡è®­ç»ƒé€Ÿåº¦å’Œå­˜å‚¨æ•ˆç‡</li><li>æå‡ºé’ˆå¯¹ç»†ç²’åº¦ç±»åˆ«çš„è¶…ç±»æ¡ä»¶å¼•å¯¼é‡‡æ ·æ–¹æ³•ï¼Œæå‡å›¾åƒç”Ÿæˆè´¨é‡</li><li>ä¸å®Œå…¨å¾®è°ƒç›¸æ¯”ï¼ŒFineDiffusion è®­ç»ƒé€Ÿåº¦æå‡ 1.56 å€ï¼Œæ‰€éœ€å­˜å‚¨å‚æ•°ä»…ä¸ºåŸæ¨¡å‹çš„ 1.77%</li><li>åœ¨ 10,000 ä¸ªç±»åˆ«çš„å›¾åƒç”Ÿæˆä¸Šå–å¾—æœ€å…ˆè¿›çš„ FID ä¸º 9.776</li><li>å¤§é‡å®šæ€§å’Œå®šé‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„ä¼˜è¶Šæ€§</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šFineDiffusionï¼šå°†æ‰©æ•£æ¨¡å‹æ‰©å±•åˆ° 10,000 ç±»åˆ«çš„ç»†ç²’åº¦å›¾åƒç”Ÿæˆ</li><li>ä½œè€…ï¼šZiying Pan, Kun Wang, Gang Li, Feihong He, Xiwang Li, Yongxuan Lai</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¦é—¨å¤§å­¦</li><li>å…³é”®è¯ï¼šDiffusion Models, Fine-grained Image Generation, Parameter-efficient Fine-tuning</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18331   Github ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š   ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆä»¥äº§ç”Ÿé«˜è´¨é‡å’Œå¤šæ ·åŒ–çš„å›¾åƒè€Œé—»åã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°å…ˆå‰çš„åŠªåŠ›éƒ½é›†ä¸­åœ¨ä¸ºä¸€èˆ¬ç±»åˆ«ç”Ÿæˆå›¾åƒï¼Œä¾‹å¦‚ ImageNet-1k ä¸­çš„ 1000 ä¸ªç±»åˆ«ã€‚ä¸€ä¸ªæ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå³å¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼Œä»ç„¶æ˜¯éœ€è¦æ¢ç´¢çš„è¾¹ç•Œã€‚   ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä¸€èˆ¬ç±»åˆ«çš„å›¾åƒç”Ÿæˆï¼Œè€Œå¯¹äºç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼Œéœ€è¦æ¨¡å‹å¯¹é«˜åº¦ç›¸ä¼¼çš„ç»†ç²’åº¦ç±»åˆ«ä¸­çš„ç»†å¾®å·®å¼‚ï¼ˆä¾‹å¦‚é¸Ÿç±»çš„ç¾½æ¯›çº¹ç†ï¼‰è¿›è¡Œå¤æ‚çš„å»ºæ¨¡ã€‚ä»å¤´å¼€å§‹è®­ç»ƒç”¨äºå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹éœ€è¦æ›´å¤§çš„è®¡ç®—èµ„æºå’Œè®­ç»ƒè¿­ä»£ã€‚   ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³• FineDiffusionï¼Œå®ƒå¯ä»¥é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œæœ‰æ•ˆåœ°å¾®è°ƒå¤§å‹é¢„è®­ç»ƒå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥è¿›è¡Œå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆã€‚   ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šä¸å®Œå…¨å¾®è°ƒç›¸æ¯”ï¼ŒFineDiffusion å®ç°äº†æ˜¾ç€çš„ 1.56 å€è®­ç»ƒåŠ é€Ÿï¼Œå¹¶ä¸”åªéœ€è¦å­˜å‚¨ 1.77% çš„æ€»æ¨¡å‹å‚æ•°ï¼ŒåŒæ—¶åœ¨ 10,000 ä¸ªç±»åˆ«çš„å›¾åƒç”Ÿæˆä¸Šå®ç°äº† 9.776 çš„æœ€å…ˆè¿› FIDã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œä¸å…¶ä»–å‚æ•°æœ‰æ•ˆçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ã€‚</li></ol><p>7.æ–¹æ³•ï¼š(1)æå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³•FineDiffusionï¼Œè¯¥æ–¹æ³•é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œæœ‰æ•ˆåœ°å¾®è°ƒå¤§å‹é¢„è®­ç»ƒå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥è¿›è¡Œå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼›(2)æå‡ºäº†ä¸€ç§åˆ†å±‚ç±»æ ‡ç­¾ç¼–ç ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åŒæ—¶å¯¹è¶…ç±»å’Œå­ç±»æ ‡ç­¾è¿›è¡Œç¼–ç ï¼›(3)åŒæ—¶å¾®è°ƒåå·®å’Œå½’ä¸€åŒ–é¡¹ä»¥åŠåˆ†å±‚åµŒå…¥å™¨ï¼Œä»¥å­¦ä¹ å…¨å±€æ•°æ®é›†çš„åˆ†å¸ƒç‰¹å¾ï¼›(4)å¼•å…¥äº†ä¸€ç§åˆ†å±‚æ— åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è¶…ç±»æ¡ä»¶ä¿¡æ¯æ¥å¢å¼ºå¯¹ç”Ÿæˆå›¾åƒçš„æ§åˆ¶ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é¦–æ¬¡å°è¯•å°†æ‰©æ•£æ¨¡å‹æ‰©å±•åˆ° 10,000 ç±»çš„ç»†ç²’åº¦å›¾åƒç”Ÿæˆã€‚æˆ‘ä»¬å¼•å…¥äº† FineDiffusionï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„å‚æ•°å¾®è°ƒæ–¹æ³•ï¼Œå¯ä»¥å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„å…³é”®ç»„ä»¶ï¼ŒåŒ…æ‹¬åˆ†å±‚æ ‡ç­¾åµŒå…¥ã€åå·®é¡¹å’Œå½’ä¸€åŒ–é¡¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¤§å¹…å‡å°‘äº†è®­ç»ƒå’Œå­˜å‚¨å¼€é”€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç»†ç²’åº¦æ— åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·æŠ€æœ¯ï¼Œåˆ©ç”¨åˆ†å±‚æ•°æ®æ ‡ç­¾ä¿¡æ¯æ¥æœ‰æ•ˆå¢å¼ºç»†ç²’åº¦å›¾åƒç”Ÿæˆçš„æ€§èƒ½ã€‚å……åˆ†çš„å®šæ€§å’Œå®šé‡ç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”çš„ä¼˜è¶Šæ€§ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³• FineDiffusionï¼Œè¯¥æ–¹æ³•é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œæœ‰æ•ˆåœ°å¾®è°ƒå¤§å‹é¢„è®­ç»ƒå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥è¿›è¡Œå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼›æå‡ºäº†åˆ†å±‚ç±»æ ‡ç­¾ç¼–ç ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åŒæ—¶å¯¹è¶…ç±»å’Œå­ç±»æ ‡ç­¾è¿›è¡Œç¼–ç ï¼›åŒæ—¶å¾®è°ƒåå·®å’Œå½’ä¸€åŒ–é¡¹ä»¥åŠåˆ†å±‚åµŒå…¥å™¨ï¼Œä»¥å­¦ä¹ å…¨å±€æ•°æ®é›†çš„åˆ†å¸ƒç‰¹å¾ï¼›å¼•å…¥äº†ä¸€ç§åˆ†å±‚æ— åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è¶…ç±»æ¡ä»¶ä¿¡æ¯æ¥å¢å¼ºå¯¹ç”Ÿæˆå›¾åƒçš„æ§åˆ¶ã€‚æ€§èƒ½ï¼šä¸å®Œå…¨å¾®è°ƒç›¸æ¯”ï¼ŒFineDiffusion å®ç°äº†æ˜¾ç€çš„ 1.56 å€è®­ç»ƒåŠ é€Ÿï¼Œå¹¶ä¸”åªéœ€è¦å­˜å‚¨ 1.77% çš„æ€»æ¨¡å‹å‚æ•°ï¼ŒåŒæ—¶åœ¨ 10,000 ä¸ªç±»åˆ«çš„å›¾åƒç”Ÿæˆä¸Šå®ç°äº† 9.776 çš„æœ€å…ˆè¿› FIDã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œä¸å…¶ä»–å‚æ•°æœ‰æ•ˆçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ã€‚å·¥ä½œé‡ï¼šä¸ä»å¤´å¼€å§‹è®­ç»ƒç”¨äºå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼ŒFineDiffusion å¯ä»¥æ˜¾ç€å‡å°‘è®¡ç®—èµ„æºå’Œè®­ç»ƒè¿­ä»£ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-f68a4db99ea4f9179538c6c4b4d7c7ce.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-4e768fecf2a73ce9e4c8b13ef7c8cd6a.jpg" align="middle"><img src="https://picx.zhimg.com/v2-6c0d4b61db744892b76754513d9f6676.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-665dc312a2eacee1bb375efacd7d609c.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-d25afe2f19082c3abc80d90affd76466.jpg" align="middle"><img src="https://picx.zhimg.com/v2-68e2a9d895710b3df489a49501a85625.jpg" align="middle"></details><h2 id="Balancing-Act-Distribution-Guided-Debiasing-in-Diffusion-Models"><a href="#Balancing-Act-Distribution-Guided-Debiasing-in-Diffusion-Models" class="headerlink" title="Balancing Act: Distribution-Guided Debiasing in Diffusion Models"></a>Balancing Act: Distribution-Guided Debiasing in Diffusion Models</h2><p><strong>Authors:Rishubh Parihar, Abhijnya Bhat, Saswat Mallick, Abhipsa Basu, Jogendra Nath Kundu, R. Venkatesh Babu</strong></p><p>Diffusion Models (DMs) have emerged as powerful generative models with unprecedented image generation capability. These models are widely used for data augmentation and creative applications. However, DMs reflect the biases present in the training datasets. This is especially concerning in the context of faces, where the DM prefers one demographic subgroup vs others (eg. female vs male). In this work, we present a method for debiasing DMs without relying on additional data or model retraining. Specifically, we propose Distribution Guidance, which enforces the generated images to follow the prescribed attribute distribution. To realize this, we build on the key insight that the latent features of denoising UNet hold rich demographic semantics, and the same can be leveraged to guide debiased generation. We train Attribute Distribution Predictor (ADP) - a small mlp that maps the latent features to the distribution of attributes. ADP is trained with pseudo labels generated from existing attribute classifiers. The proposed Distribution Guidance with ADP enables us to do fair generation. Our method reduces bias across single/multiple attributes and outperforms the baseline by a significant margin for unconditional and text-conditional diffusion models. Further, we present a downstream task of training a fair attribute classifier by rebalancing the training set with our generated data. </p><p><a href="http://arxiv.org/abs/2402.18206v1">PDF</a> CVPR 2024. Project Page : <a href="https://ab-34.github.io/balancing_act/">https://ab-34.github.io/balancing_act/</a></p><p><strong>Summary</strong><br>å»é™¤æ‰©æ•£æ¨¡å‹ä¸­çš„åè§ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–æ¨¡å‹é‡æ–°è®­ç»ƒã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰å­˜åœ¨åè§ï¼Œè¡¨ç°ä¸ºå¯¹ç‰¹å®šäººå£äºšç»„ï¼ˆå¦‚å¥³æ€§ï¼‰çš„åå¥½ã€‚</li><li>åˆ†å¸ƒå¼•å¯¼æ˜¯ä¸€ç§æ— å DM çš„æ–¹æ³•ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–é‡æ–°è®­ç»ƒã€‚</li><li>åˆ†å¸ƒå¼•å¯¼åˆ©ç”¨å»å™ª UNet çš„æ½œåœ¨ç‰¹å¾ä¸­ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚</li><li>å±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ (ADP) å°†æ½œåœ¨ç‰¹å¾æ˜ å°„åˆ°å±æ€§åˆ†å¸ƒã€‚</li><li>ADP ä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚</li><li>åˆ†å¸ƒå¼•å¯¼å’Œ ADP å®ç°äº†å…¬å¹³ç”Ÿæˆï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚</li><li>é€šè¿‡ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®é‡æ–°å¹³è¡¡è®­ç»ƒé›†ï¼Œå¯ä»¥è®­ç»ƒå…¬å¹³çš„å±æ€§åˆ†ç±»å™¨ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šå¹³è¡¡è¡Œä¸ºï¼šæ‰©æ•£æ¨¡å‹ä¸­çš„åˆ†å¸ƒå¼•å¯¼å»å</li><li>ä½œè€…ï¼šRishubh Parihar*, Abhijnya Bhatâˆ—, Saswat Mallick, Abhipsa Basu, Jogendra Nath Kundu, R. Venkatesh Babu</li><li>éš¶å±ï¼šå°åº¦ç§‘å­¦é™¢ï¼Œç­åŠ ç½—å°”</li><li>å…³é”®è¯ï¼šDiffusion Models, Debiasing, Distribution Guidance, Attribute Distribution Predictor, Fair Generation</li><li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18206</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰ä½œä¸ºå¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä¼šåæ˜ è®­ç»ƒæ•°æ®é›†ä¸­çš„åè§ï¼Œç‰¹åˆ«æ˜¯å¯¹äºäººè„¸ï¼ŒDM åå¥½æŸäº›äººå£ç»Ÿè®¡å­¦äºšç»„ï¼ˆä¾‹å¦‚å¥³æ€§æ¯”ç”·æ€§ï¼‰ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰å»åæ–¹æ³•éœ€è¦é¢å¤–æ•°æ®æˆ–æ¨¡å‹é‡æ–°è®­ç»ƒã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºåˆ†å¸ƒå¼•å¯¼ï¼Œé€šè¿‡å¼ºåˆ¶ç”Ÿæˆå›¾åƒéµå¾ªè§„å®šçš„å±æ€§åˆ†å¸ƒæ¥å¯¹ DM è¿›è¡Œå»åã€‚é€šè¿‡è®­ç»ƒå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ (ADP) æ¥æ˜ å°„æ½œåœ¨ç‰¹å¾åˆ°å±æ€§åˆ†å¸ƒï¼ŒADP ä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨æ— æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸Šå‡å°‘äº†å•ä¸€/å¤šå±æ€§çš„åå·®ï¼Œå¹¶ä¸”ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§é€šè¿‡ä½¿ç”¨ç”Ÿæˆæ•°æ®é‡æ–°å¹³è¡¡è®­ç»ƒé›†æ¥è®­ç»ƒå…¬å¹³å±æ€§åˆ†ç±»å™¨çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1): æå‡ºåˆ†å¸ƒå¼•å¯¼æ–¹æ³•ï¼Œé€šè¿‡å¼ºåˆ¶ç”Ÿæˆå›¾åƒéµå¾ªè§„å®šçš„å±æ€§åˆ†å¸ƒæ¥å¯¹æ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰è¿›è¡Œå»åã€‚(2): è®­ç»ƒå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ï¼ˆADPï¼‰æ¥æ˜ å°„æ½œåœ¨ç‰¹å¾åˆ°å±æ€§åˆ†å¸ƒï¼ŒADPä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚(3): åœ¨æ— æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸Šè¯„ä¼°è¯¥æ–¹æ³•ï¼Œå‡å°‘äº†å•ä¸€/å¤šå±æ€§çš„åå·®ï¼Œå¹¶ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚(4): æå‡ºäº†ä¸€ç§é€šè¿‡ä½¿ç”¨ç”Ÿæˆæ•°æ®é‡æ–°å¹³è¡¡è®­ç»ƒé›†æ¥è®­ç»ƒå…¬å¹³å±æ€§åˆ†ç±»å™¨çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬æ–‡çš„æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒå³å¯å‡è½»é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹åå·®çš„æ–¹æ³•ï¼Œä»…ç»™å®šæ‰€éœ€çš„å‚è€ƒå±æ€§åˆ†å¸ƒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å¸ƒå¼•å¯¼ï¼Œè”åˆå¼•å¯¼ä¸€æ‰¹å›¾åƒéµå¾ªå‚è€ƒå±æ€§åˆ†å¸ƒã€‚æ‰€æå‡ºçš„æ–¹æ³•æ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ä¸”åœ¨ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„åˆ†å¸ƒå¼•å¯¼æ–¹æ³•ï¼Œé€šè¿‡å¼ºåˆ¶ç”Ÿæˆå›¾åƒéµå¾ªè§„å®šçš„å±æ€§åˆ†å¸ƒæ¥å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œå»åã€‚æ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨æ— æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸Šå‡å°‘äº†å•ä¸€/å¤šå±æ€§çš„åå·®ï¼Œå¹¶ä¸”ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚å·¥ä½œé‡ï¼šæœ¬æ–‡çš„æ–¹æ³•éœ€è¦è®­ç»ƒä¸€ä¸ªå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ï¼Œè¯¥é¢„æµ‹å™¨ä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚è®­ç»ƒå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨çš„å·¥ä½œé‡å–å†³äºè®­ç»ƒæ•°æ®çš„è§„æ¨¡å’Œå±æ€§çš„æ•°é‡ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-05a1a956ee3a51fe0c06ffc4859c7231.jpg" align="middle"><img src="https://picx.zhimg.com/v2-16ae5c5f9f522148622d40f8f3f15f86.jpg" align="middle"><img src="https://picx.zhimg.com/v2-46f6a987113095ab338596820ca6e653.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f32e1f0036b8646f3ffad99a82575f09.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-1128b65d6c33c58a2f6b04087adf31b0.jpg" align="middle"></details><h2 id="Coarse-to-Fine-Latent-Diffusion-for-Pose-Guided-Person-Image-Synthesis"><a href="#Coarse-to-Fine-Latent-Diffusion-for-Pose-Guided-Person-Image-Synthesis" class="headerlink" title="Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis"></a>Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis</h2><p><strong>Authors:Yanzuo Lu, Manlin Zhang, Andy J Ma, Xiaohua Xie, Jian-Huang Lai</strong></p><p>Diffusion model is a promising approach to image generation and has been employed for Pose-Guided Person Image Synthesis (PGPIS) with competitive performance. While existing methods simply align the person appearance to the target pose, they are prone to overfitting due to the lack of a high-level semantic understanding on the source person image. In this paper, we propose a novel Coarse-to-Fine Latent Diffusion (CFLD) method for PGPIS. In the absence of image-caption pairs and textual prompts, we develop a novel training paradigm purely based on images to control the generation process of the pre-trained text-to-image diffusion model. A perception-refined decoder is designed to progressively refine a set of learnable queries and extract semantic understanding of person images as a coarse-grained prompt. This allows for the decoupling of fine-grained appearance and pose information controls at different stages, and thus circumventing the potential overfitting problem. To generate more realistic texture details, a hybrid-granularity attention module is proposed to encode multi-scale fine-grained appearance features as bias terms to augment the coarse-grained prompt. Both quantitative and qualitative experimental results on the DeepFashion benchmark demonstrate the superiority of our method over the state of the arts for PGPIS. Code is available at <a href="https://github.com/YanzuoLu/CFLD">https://github.com/YanzuoLu/CFLD</a>. </p><p><a href="http://arxiv.org/abs/2402.18078v1">PDF</a> Accepted by CVPR 2024</p><p><strong>Summary</strong><br> æå‡ºäº†ä¸€ç§ç²—åˆ°ç»†çš„æ½œåœ¨æ‰©æ•£ï¼ˆCFLDï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨å›¾åƒè€Œéæ–‡æœ¬æç¤ºï¼Œæ§åˆ¶é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå®ç°å§¿åŠ¿å¼•å¯¼çš„å›¾åƒåˆæˆã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡º CFLD æ–¹æ³•ï¼Œæ”¹å–„äº† PGPIS ä¸­å§¿åŠ¿å¼•å¯¼å›¾åƒåˆæˆçš„æ•ˆæœã€‚</li><li>ä½¿ç”¨çº¯å›¾åƒè®­ç»ƒèŒƒå¼ï¼Œæ— éœ€å›¾åƒå­—å¹•æˆ–æ–‡æœ¬æç¤ºã€‚</li><li>è®¾è®¡äº†ä¸€ä¸ªæ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨ï¼Œé€æ­¥ä¼˜åŒ–æŸ¥è¯¢å¹¶æå–äººç‰©å›¾åƒçš„è¯­ä¹‰ç†è§£ã€‚</li><li>å°†å¤–è²Œå’Œå§¿åŠ¿ä¿¡æ¯æ§åˆ¶è§£è€¦ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆã€‚</li><li>æå‡ºæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå¯¹å¤šå°ºåº¦å¤–è§‚ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œå¢å¼ºç²—ç²’åº¦æç¤ºã€‚</li><li>åœ¨ DeepFashion æ•°æ®é›†ä¸Šï¼Œå®šé‡å’Œå®šæ€§å®éªŒç»“æœè¯æ˜äº† CFLD çš„ä¼˜è¶Šæ€§ã€‚</li><li>ä»£ç å·²å¼€æºã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šç²—åˆ°ç»†çš„æ½œåœ¨æ‰©æ•£ç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆ</li><li>ä½œè€…ï¼šLu Yanzuo, Zhang Manlin, Ma Andy J, Xie Xiaohua, Lai Jianhuang</li><li>å•ä½ï¼šä¸­å±±å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢</li><li>å…³é”®è¯ï¼šå§¿æ€å¼•å¯¼ã€äººç‰©å›¾åƒåˆæˆã€æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€ç²—åˆ°ç»†ã€è¯­ä¹‰ç†è§£</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18078   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/YanzuoLu/CFLD</li><li>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆæ—¨åœ¨å°†æºäººç‰©å›¾åƒè½¬æ¢ä¸ºç‰¹å®šçš„ç›®æ ‡å§¿æ€ï¼ŒåŒæ—¶å°½å¯èƒ½ä¿ç•™å¤–è§‚ã€‚å®ƒåœ¨ç”µå½±åˆ¶ä½œã€è™šæ‹Ÿç°å®å’Œæ—¶å°šç”µå­å•†åŠ¡ç­‰é¢†åŸŸæœ‰å¹¿æ³›çš„åº”ç”¨ã€‚(2) è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) çš„æ–¹æ³•å®¹æ˜“å‡ºç°æå°æå¤§è®­ç»ƒç›®æ ‡çš„ä¸ç¨³å®šæ€§å’Œéš¾ä»¥åœ¨ä¸€æ¬¡å‰å‘ä¼ é€’ä¸­ç”Ÿæˆé«˜è´¨é‡å›¾åƒçš„é—®é¢˜ã€‚ä½œä¸º GAN åœ¨å›¾åƒç”Ÿæˆä¸­çš„ä¸€ç§æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ‰©æ•£æ¨¡å‹é€šè¿‡ä¸€ç³»åˆ—å»å™ªæ­¥éª¤é€æ¸åˆæˆæ›´é€¼çœŸçš„å›¾åƒã€‚(3) æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç²—åˆ°ç»†æ½œåœ¨æ‰©æ•£ (CFLD) æ–¹æ³•ç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆã€‚åœ¨æ²¡æœ‰å›¾åƒ-æ ‡é¢˜å¯¹å’Œæ–‡æœ¬æç¤ºçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§çº¯ç²¹åŸºäºå›¾åƒçš„æ–°é¢–è®­ç»ƒèŒƒå¼æ¥æ§åˆ¶é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨æ¥æ¸è¿›åœ°ç»†åŒ–ä¸€ç»„å¯å­¦ä¹ æŸ¥è¯¢å¹¶æå–äººç‰©å›¾åƒçš„è¯­ä¹‰ç†è§£ä½œä¸ºç²—ç²’åº¦æç¤ºã€‚è¿™å…è®¸åœ¨ä¸åŒçš„é˜¶æ®µè§£è€¦ç»†ç²’åº¦å¤–è§‚å’Œå§¿æ€ä¿¡æ¯æ§åˆ¶ï¼Œä»è€Œè§„é¿äº†æ½œåœ¨çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚ä¸ºäº†ç”Ÿæˆæ›´é€¼çœŸçš„çº¹ç†ç»†èŠ‚ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå°†å¤šå°ºåº¦ç»†ç²’åº¦å¤–è§‚ç‰¹å¾ç¼–ç ä¸ºåå·®é¡¹ä»¥å¢å¼ºç²—ç²’åº¦æç¤ºã€‚(4) æ€§èƒ½ï¼šåœ¨ DeepFashion åŸºå‡†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•åœ¨å§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…·æœ‰æ›´å¥½æ³›åŒ–æ€§èƒ½çš„é«˜è´¨é‡å›¾åƒã€‚</li></ol><p>7.Methodsï¼š(1) æå‡ºç²—åˆ°ç»†æ½œåœ¨æ‰©æ•£ï¼ˆCFLDï¼‰æ–¹æ³•ï¼Œç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆï¼›(2) å¼€å‘åŸºäºå›¾åƒçš„æ–°è®­ç»ƒèŒƒå¼ï¼Œæ§åˆ¶é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ï¼›(3) è®¾è®¡æ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨ï¼Œæ¸è¿›ç»†åŒ–å¯å­¦ä¹ æŸ¥è¯¢ï¼Œæå–äººç‰©å›¾åƒè¯­ä¹‰ç†è§£ä½œä¸ºç²—ç²’åº¦æç¤ºï¼›(4) æå‡ºæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå°†å¤šå°ºåº¦ç»†ç²’åº¦å¤–è§‚ç‰¹å¾ç¼–ç ä¸ºåå·®é¡¹ï¼Œå¢å¼ºç²—ç²’åº¦æç¤ºï¼›(5) é€šè¿‡åœ¨DeepFashionåŸºå‡†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒï¼ŒéªŒè¯äº†CFLDæ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</p><ol><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰xxxï¼›ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p></li><li><p>æ€»ç»“ï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆ2ï¼‰ä»åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡ä¸‰ä¸ªç»´åº¦æ€»ç»“æœ¬æ–‡çš„ä¼˜ç¼ºç‚¹ï¼šåˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç²—åˆ°ç»†æ½œåœ¨æ‰©æ•£ï¼ˆCFLDï¼‰æ–¹æ³•ï¼Œç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆã€‚è¯¥æ–¹æ³•é€šè¿‡æ¸è¿›ç»†åŒ–å¯å­¦ä¹ æŸ¥è¯¢ï¼Œæå–äººç‰©å›¾åƒçš„è¯­ä¹‰ç†è§£ä½œä¸ºç²—ç²’åº¦æç¤ºï¼Œå¹¶æå‡ºæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå°†å¤šå°ºåº¦ç»†ç²’åº¦å¤–è§‚ç‰¹å¾ç¼–ç ä¸ºåå·®é¡¹ï¼Œå¢å¼ºç²—ç²’åº¦æç¤ºã€‚æ€§èƒ½ï¼šåœ¨ DeepFashion åŸºå‡†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒç»“æœè¯æ˜äº† CFLD æ–¹æ³•åœ¨å§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…·æœ‰æ›´å¥½æ³›åŒ–æ€§èƒ½çš„é«˜è´¨é‡å›¾åƒã€‚å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡é€‚ä¸­ã€‚è¯¥æ–¹æ³•çš„å®ç°éœ€è¦å¯¹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•éœ€è¦è®¾è®¡æ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨å’Œæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œè¿™éœ€è¦é¢å¤–çš„å¼€å‘å’Œå®éªŒå·¥ä½œã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-ee807dc5573280abe63e138fa82f6eb3.jpg" align="middle"><img src="https://pica.zhimg.com/v2-07506917791ee3066c02770faa1a2052.jpg" align="middle"><img src="https://picx.zhimg.com/v2-5192aaa635e4ab29d557ee967971be49.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-269e1bea1b870d8f0466ace81c9d2e01.jpg" align="middle"></details><h2 id="SynArtifact-Classifying-and-Alleviating-Artifacts-in-Synthetic-Images-via-Vision-Language-Model"><a href="#SynArtifact-Classifying-and-Alleviating-Artifacts-in-Synthetic-Images-via-Vision-Language-Model" class="headerlink" title="SynArtifact: Classifying and Alleviating Artifacts in Synthetic Images   via Vision-Language Model"></a>SynArtifact: Classifying and Alleviating Artifacts in Synthetic Images   via Vision-Language Model</h2><p><strong>Authors:Bin Cao, Jianhao Yuan, Yexin Liu, Jian Li, Shuyang Sun, Jing Liu, Bo Zhao</strong></p><p>In the rapidly evolving area of image synthesis, a serious challenge is the presence of complex artifacts that compromise perceptual realism of synthetic images. To alleviate artifacts and improve quality of synthetic images, we fine-tune Vision-Language Model (VLM) as artifact classifier to automatically identify and classify a wide range of artifacts and provide supervision for further optimizing generative models. Specifically, we develop a comprehensive artifact taxonomy and construct a dataset of synthetic images with artifact annotations for fine-tuning VLM, named SynArtifact-1K. The fine-tuned VLM exhibits superior ability of identifying artifacts and outperforms the baseline by 25.66%. To our knowledge, this is the first time such end-to-end artifact classification task and solution have been proposed. Finally, we leverage the output of VLM as feedback to refine the generative model for alleviating artifacts. Visualization results and user study demonstrate that the quality of images synthesized by the refined diffusion model has been obviously improved. </p><p><a href="http://arxiv.org/abs/2402.18068v1">PDF</a> </p><p><strong>Summary</strong><br>åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹å¯¹å›¾åƒåˆæˆä¸­çš„ä¼ªå½±è¿›è¡Œè‡ªåŠ¨åˆ†ç±»ï¼Œä¸ºç”Ÿæˆæ¨¡å‹çš„è¿›ä¸€æ­¥ä¼˜åŒ–æä¾›ç›‘ç®¡ï¼Œä»è€Œæé«˜åˆæˆå›¾åƒçš„è´¨é‡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>åˆæˆå›¾åƒä¸­å¤æ‚ä¼ªå½±çš„å­˜åœ¨æ„æˆäº†ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ï¼Œå¯¹æ„ŸçŸ¥çœŸå®æ€§äº§ç”Ÿäº†è´Ÿé¢å½±å“ã€‚</li><li>ç ”ç©¶äººå‘˜æå‡ºå°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¾®è°ƒä¸ºä¼ªå½±åˆ†ç±»å™¨ï¼Œä»¥ä¾¿è‡ªåŠ¨è¯†åˆ«å’Œåˆ†ç±»å„ç§ä¼ªå½±ã€‚</li><li>å¼€å‘äº†ä¸€ä¸ªå…¨é¢çš„ä¼ªå½±åˆ†ç±»ä½“ç³»ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªå…·æœ‰ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›†ï¼ˆSynArtifact-1Kï¼‰ã€‚</li><li>å¾®è°ƒåçš„ VLM åœ¨è¯†åˆ«ä¼ªå½±æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„èƒ½åŠ›ï¼Œæ¯”åŸºçº¿é«˜å‡º 25.66%ã€‚</li><li>è¿™æ˜¯é¦–æ¬¡æå‡ºæ­¤ç±»ç«¯åˆ°ç«¯ä¼ªå½±åˆ†ç±»ä»»åŠ¡å’Œè§£å†³æ–¹æ¡ˆã€‚</li><li>åˆ©ç”¨ VLM çš„è¾“å‡ºä½œä¸ºåé¦ˆæ¥ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å‡è½»ä¼ªå½±ã€‚</li><li>è§†è§‰åŒ–ç»“æœå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œä¼˜åŒ–åçš„æ‰©æ•£æ¨¡å‹åˆæˆçš„å›¾åƒè´¨é‡å¾—åˆ°äº†æ˜æ˜¾æ”¹å–„ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>è®ºæ–‡é¢˜ç›®ï¼šSynArtifactï¼šé€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹å¯¹åˆæˆå›¾åƒä¸­çš„ä¼ªå½±è¿›è¡Œåˆ†ç±»å’Œæ¶ˆé™¤</li><li>ä½œè€…ï¼šBin Cao, Jianhao Yuan, Yexin Liu, Jian Li, Shuyang Sun, Jing Liu, Bo Zhao</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€</li><li>å…³é”®è¯ï¼šåˆæˆå›¾åƒã€ä¼ªå½±ã€è§†è§‰è¯­è¨€æ¨¡å‹ã€ç”Ÿæˆæ¨¡å‹</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18068</li><li><p>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šåˆæˆå›¾åƒä¸­å­˜åœ¨å¤æ‚ä¼ªå½±ï¼Œå½±å“å›¾åƒçš„æ„ŸçŸ¥çœŸå®æ€§ã€‚(2) è¿‡å¾€æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å•ä¸€è¯„åˆ†æŒ‡æ ‡ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹ï¼Œæ— æ³•æœ‰æ•ˆåæ˜ ä¼ªå½±çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§ã€‚(3) æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºä¸€ä¸ªç»¼åˆä¼ªå½±åˆ†ç±»æ³•ï¼Œæ„å»ºäº†ä¸€ä¸ªå¸¦æœ‰ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›† SynArtifact-1Kï¼Œå¹¶å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ (VLM) å¯¹ä¼ªå½±è¿›è¡Œåˆ†ç±»ã€‚åˆ©ç”¨ VLM çš„è¾“å‡ºä½œä¸º AI åé¦ˆæ¥æ”¹è¿›ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å‡è½»ä¼ªå½±ã€‚(4) å®éªŒç»“æœï¼šå¾®è°ƒåçš„ VLM åœ¨ä¼ªå½±åˆ†ç±»ä»»åŠ¡ä¸Šæ¯”åŸºçº¿æ–¹æ³•æé«˜äº† 25.66% çš„å‡†ç¡®ç‡å’Œ 29.01% çš„ F1 åˆ†æ•°ã€‚é€šè¿‡åˆ©ç”¨ä¼ªå½±åˆ†ç±»å™¨çš„è¾“å‡ºä½œä¸º AI åé¦ˆï¼Œå¯ä»¥æœ‰æ•ˆå‡è½»ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¼ªå½±ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰æ„å»ºç»¼åˆä¼ªå½±åˆ†ç±»æ³•ï¼Œå»ºç«‹åŒ…å«ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›† SynArtifact-1Kï¼›ï¼ˆ2ï¼‰å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ VLMï¼Œå°†å…¶ä½œä¸ºä¼ªå½±åˆ†ç±»å™¨ï¼›ï¼ˆ3ï¼‰åˆ©ç”¨ VLM è¾“å‡ºä½œä¸º AI åé¦ˆï¼Œè®¡ç®—ç”Ÿæˆæ¨¡å‹è¾“å‡ºä¸æ¯ç§ä¼ªå½±ä¹‹é—´çš„ BertScoreï¼Œä½œä¸ºä¼ªå½±åˆ†ç±»å¥–åŠ±ï¼›ï¼ˆ4ï¼‰é€šè¿‡æœ€å¤§åŒ–ä¼ªå½±åˆ†ç±»å¥–åŠ±ï¼Œä¼˜åŒ–æ‰©æ•£æ¨¡å‹ï¼Œä»¥å‡è½»ä¼ªå½±ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é’ˆå¯¹åˆæˆå›¾åƒä¸­çš„ä¼ªå½±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªç»¼åˆçš„ä¼ªå½±åˆ†ç±»æ³•ï¼Œæ„å»ºäº†åŒ…å«ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›† SynArtifact-1Kï¼Œå¹¶åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹å¯¹ä¼ªå½±è¿›è¡Œåˆ†ç±»ï¼Œæœ‰æ•ˆåœ°å‡è½»äº†ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¼ªå½±ï¼Œæå‡äº†åˆæˆå›¾åƒçš„æ„ŸçŸ¥çœŸå®æ€§ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æ„å»ºäº†åŒ…å« 13 ç§å¸¸è§ä¼ªå½±çš„ç»¼åˆä¼ªå½±åˆ†ç±»æ³•ã€‚</li><li>åˆ›å»ºäº†é¦–ä¸ªå¸¦æœ‰ä¼ªå½±ç±»åˆ«ã€æè¿°å’Œåæ ‡æ³¨é‡Šçš„å›¾åƒæ•°æ®é›† SynArtifact-1Kã€‚</li><li>å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ç”¨äºè‡ªåŠ¨åˆ†ç±»ä¼ªå½±ï¼Œå¹¶åˆ©ç”¨å…¶è¾“å‡ºä½œä¸º AI åé¦ˆæ¥ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹ã€‚æ€§èƒ½ï¼š</li><li>å¾®è°ƒåçš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¼ªå½±åˆ†ç±»ä»»åŠ¡ä¸Šæ¯”åŸºçº¿æ–¹æ³•æé«˜äº† 25.66% çš„å‡†ç¡®ç‡å’Œ 29.01% çš„ F1 åˆ†æ•°ã€‚</li><li>åˆ©ç”¨ä¼ªå½±åˆ†ç±»å™¨çš„è¾“å‡ºä½œä¸º AI åé¦ˆï¼Œå¯ä»¥æœ‰æ•ˆå‡è½»ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¼ªå½±ã€‚å·¥ä½œé‡ï¼š</li><li>æ„å»ºäº†åŒ…å« 1000 å¼ åˆæˆå›¾åƒçš„ SynArtifact-1K æ•°æ®é›†ã€‚</li><li>å¾®è°ƒäº†è§†è§‰è¯­è¨€æ¨¡å‹ç”¨äºä¼ªå½±åˆ†ç±»ã€‚</li><li>é€šè¿‡æœ€å¤§åŒ–ä¼ªå½±åˆ†ç±»å¥–åŠ±ï¼Œä¼˜åŒ–äº†æ‰©æ•£æ¨¡å‹ä»¥å‡è½»ä¼ªå½±ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-887bb2eb3bab7f102340a00fb115308a.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a67234ceff494848cb67aa7bc7345a5e.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-c0c890345f83368ccd384b81c55c4b11.jpg" align="middle"><img src="https://pica.zhimg.com/v2-48d8c1e1b56b76bfccfccfcb96c1d5a4.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-1a5599c3d37db39e68fa5fb2e0139cec.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-94675e3c8e66717ee97bc9e3472ed274.jpg" align="middle"></details><h2 id="Box-It-to-Bind-It-Unified-Layout-Control-and-Attribute-Binding-in-T2I-Diffusion-Models"><a href="#Box-It-to-Bind-It-Unified-Layout-Control-and-Attribute-Binding-in-T2I-Diffusion-Models" class="headerlink" title="Box It to Bind It: Unified Layout Control and Attribute Binding in T2I   Diffusion Models"></a>Box It to Bind It: Unified Layout Control and Attribute Binding in T2I   Diffusion Models</h2><p><strong>Authors:Ashkan Taghipour, Morteza Ghahremani, Mohammed Bennamoun, Aref Miri Rekavandi, Hamid Laga, Farid Boussaid</strong></p><p>While latent diffusion models (LDMs) excel at creating imaginative images, they often lack precision in semantic fidelity and spatial control over where objects are generated. To address these deficiencies, we introduce the Box-it-to-Bind-it (B2B) module - a novel, training-free approach for improving spatial control and semantic accuracy in text-to-image (T2I) diffusion models. B2B targets three key challenges in T2I: catastrophic neglect, attribute binding, and layout guidance. The process encompasses two main steps: i) Object generation, which adjusts the latent encoding to guarantee object generation and directs it within specified bounding boxes, and ii) attribute binding, guaranteeing that generated objects adhere to their specified attributes in the prompt. B2B is designed as a compatible plug-and-play module for existing T2I models, markedly enhancing model performance in addressing the key challenges. We evaluate our technique using the established CompBench and TIFA score benchmarks, demonstrating significant performance improvements compared to existing methods. The source code will be made publicly available at <a href="https://github.com/nextaistudio/BoxIt2BindIt">https://github.com/nextaistudio/BoxIt2BindIt</a>. </p><p><a href="http://arxiv.org/abs/2402.17910v1">PDF</a> </p><p><strong>Summary</strong><br>Box-it-to-Bind-itï¼ˆB2Bï¼‰æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–°æ¨¡å—ï¼Œå¯æé«˜æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹ä¸­å›¾åƒçš„ç”Ÿæˆè´¨é‡ã€è¯­ä¹‰å‡†ç¡®åº¦å’Œç©ºé—´æ§åˆ¶èƒ½åŠ›ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>B2B æ¨¡å—å¯æ”¹å–„ T2I ä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šç¾éš¾æ€§é—æ¼ã€å±æ€§ç»‘å®šå’Œå¸ƒå±€æŒ‡å¯¼ã€‚</li><li>B2B åŒ…æ‹¬ç”Ÿæˆå¯¹è±¡å’Œå±æ€§ç»‘å®šçš„ä¸¤ä¸ªä¸»è¦æ­¥éª¤ã€‚</li><li>B2B å¯ä½œä¸ºç°æœ‰çš„ T2I æ¨¡å‹çš„å³æ’å³ç”¨æ¨¡å—ï¼Œæ— éœ€è®­ç»ƒã€‚</li><li>B2B åœ¨ CompBench å’Œ TIFA è¯„åˆ†åŸºå‡†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li><li>B2B çš„æºä»£ç å°†åœ¨ <a href="https://github.com/nextaistudio/BoxIt2BindIt">https://github.com/nextaistudio/BoxIt2BindIt</a> ä¸Šå…¬å¼€ã€‚</li><li>B2B æé«˜äº† LDM åœ¨ç”Ÿæˆå›¾åƒæ—¶çš„ç©ºé—´æ§åˆ¶å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚</li><li>B2B é€‚ç”¨äºä¸åŒçš„ T2I æ¨¡å‹ï¼Œæ˜“äºé›†æˆã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šBox-it-to-Bind-itï¼šç»Ÿä¸€å¸ƒå±€æ§åˆ¶å’Œå±æ€§ç»‘å®šåˆ° T2I æ‰©æ•£æ¨¡å‹ä¸­</li><li>ä½œè€…ï¼šAshkan Taghipour, Morteza Ghahremani, Mohammed Bennamoun, Aref Miri Rekavandi, Hamid Laga, Farid Boussaid</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè¥¿æ¾³å¤§åˆ©äºšå¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€æ‰©æ•£æ¨¡å‹ã€ç©ºé—´æ§åˆ¶ã€å±æ€§ç»‘å®šã€å¸ƒå±€å¼•å¯¼</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17910</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶ç¼ºä¹è¯­ä¹‰ä¿çœŸåº¦å’Œç©ºé—´æ§åˆ¶ï¼Œéš¾ä»¥å¿ å®åœ°éµå¾ªç»™å®šçš„æç¤ºï¼Œå°¤å…¶æ˜¯åœ¨å¯¹è±¡å±æ€§å’Œå¯¹è±¡æ”¾ç½®æ–¹é¢ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰æ–¹æ³•è¦ä¹ˆä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œè¦ä¹ˆå¾®è°ƒç°æœ‰æ¨¡å‹ï¼Œä½†éœ€è¦å¤§é‡è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å¹¶é›†æˆç‰¹å¾çš„æ–¹æ³•è™½ç„¶ä¸éœ€è¦å¤§é‡è®­ç»ƒï¼Œä½†æ•ˆæœæœ‰é™ã€‚</p><p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å…è®­ç»ƒçš„æ–¹æ³• Box-it-to-Bind-it (B2B)ï¼Œè§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šç¾éš¾æ€§é—æ¼ã€å±æ€§ç»‘å®šå’Œå¸ƒå±€å¼•å¯¼ã€‚B2B åœ¨æ¨ç†é˜¶æ®µé€šè¿‡ä¸¤æ­¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç¼–ç ï¼šå¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨ CompBench å’Œ TIFA å¾—åˆ†åŸºå‡†ä¸Šï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒB2B åœ¨è§£å†³å…³é”®æŒ‘æˆ˜æ–¹é¢æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æå‡æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³æé«˜æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ç©ºé—´æ§åˆ¶å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚</p><p>æ–¹æ³•ï¼š(1) B2Bæ˜¯ä¸€ç§å¥–åŠ±å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼Œå®ƒåœ¨æ¨ç†é˜¶æ®µé€šè¿‡ä¸¤æ­¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç¼–ç ï¼šå¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šã€‚(2) å¯¹è±¡ç”Ÿæˆï¼šåŸºäºIoUï¼Œå¢åŠ å¯¹è±¡ç”Ÿæˆæ¦‚ç‡ï¼Œå°†æ³¨æ„åŠ›æƒé‡é›†ä¸­åœ¨ç»™å®šè¾¹ç•Œæ¡†å†…ï¼ŒåŒæ—¶æŠ‘åˆ¶è¾¹ç•Œæ¡†å¤–çš„æ³¨æ„åŠ›æƒé‡ã€‚(3) å±æ€§ç»‘å®šï¼šä½¿ç”¨KLæ•£åº¦æµ‹é‡å±æ€§æ¦‚ç‡åˆ†å¸ƒä¸å¯¹åº”å¯¹è±¡æ¦‚ç‡åˆ†å¸ƒçš„å·®å¼‚ï¼Œå‡å°‘å·®å¼‚ï¼Œå°†å±æ€§åˆ†å¸ƒå¼ºåˆ¶æ”¶æ•›åˆ°å„è‡ªçš„å¯¹è±¡ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶é’ˆå¯¹æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å±æ€§ç»‘å®šå’Œç©ºé—´æ§åˆ¶ï¼Œæå‡ºäº† B2B æ¨¡å‹ã€‚B2B é‡‡ç”¨ç”Ÿæˆå’Œç»‘å®šåŒæ¨¡å—ç³»ç»Ÿï¼Œæœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—æ¼ã€æé«˜å±æ€§ç»‘å®šç²¾åº¦å’Œç¡®ä¿å‡†ç¡®å¯¹è±¡æ”¾ç½®çš„é—®é¢˜ã€‚å®ƒä½œä¸ºç°æœ‰ T2I æ¡†æ¶çš„å³æ’å³ç”¨æ¨¡å—çš„å…¼å®¹æ€§é€šè¿‡å…¶åœ¨ CompBench å’Œ TIFA åŸºå‡†ä¸­çš„å‡ºè‰²è¡¨ç°å¾—åˆ°è¯æ˜ï¼Œæ ‡å¿—ç€ç”Ÿæˆå»ºæ¨¡çš„é‡å¤§é£è·ƒã€‚B2B çš„çªç ´å‡¸æ˜¾äº†å…¶ä½œä¸ºæœªæ¥ç ”ç©¶æ½œåœ¨æ ‡å‡†çš„ä½œç”¨ï¼Œä¸ºæ•°å­—æˆåƒå’Œç”Ÿæˆå¼ AI çš„åˆ›æ–°å‘å±•é“ºå¹³äº†é“è·¯ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§å…è®­ç»ƒçš„æ–¹æ³• B2Bï¼Œé€šè¿‡ä¸¤æ­¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç¼–ç æ¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚</li><li>è®¾è®¡äº†å¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šä¸¤ä¸ªæ¨¡å—ï¼Œæœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—æ¼ã€å±æ€§ç»‘å®šå’Œå¸ƒå±€å¼•å¯¼é—®é¢˜ã€‚</li><li>B2B ä½œä¸ºç°æœ‰ T2I æ¡†æ¶çš„å³æ’å³ç”¨æ¨¡å—ï¼Œæ˜“äºé›†æˆå’Œä½¿ç”¨ã€‚æ€§èƒ½ï¼š</li><li>åœ¨ CompBench å’Œ TIFA åŸºå‡†ä¸Šï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒB2B åœ¨è§£å†³å…³é”®æŒ‘æˆ˜æ–¹é¢æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚</li><li>æ¶ˆèç ”ç©¶éªŒè¯äº†å¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šå¥–åŠ±ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼Œè¡¨æ˜ B2B çš„å„ä¸ªç»„ä»¶å¯¹æ•´ä½“æ€§èƒ½è‡³å…³é‡è¦ã€‚å·¥ä½œé‡ï¼š</li><li>B2B æ˜¯ä¸€ç§å…è®­ç»ƒçš„æ–¹æ³•ï¼Œä¸éœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹æˆ–å¾®è°ƒç°æœ‰æ¨¡å‹ï¼Œä»è€ŒèŠ‚çœäº†å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚</li><li>B2B æ˜“äºé›†æˆåˆ°ç°æœ‰ T2I æ¡†æ¶ä¸­ï¼Œæ— éœ€è¿›è¡Œå¤æ‚çš„ä¿®æ”¹æˆ–é‡æ–°è®­ç»ƒï¼Œé™ä½äº†å·¥ä½œé‡ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-9044558cdc31309b419fea5199aa8a89.jpg" align="middle"><img src="https://picx.zhimg.com/v2-78bccd36910d4aa870962c445823ad57.jpg" align="middle"><img src="https://pica.zhimg.com/v2-967a215bde68183f03e457a7ff3f8e9a.jpg" align="middle"><img src="https://pica.zhimg.com/v2-e2a4cdc833464a14406a357aa9e0c358.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d140c3c8e05d724098a1c03138203a01.jpg" align="middle"></details><h2 id="Structure-Guided-Adversarial-Training-of-Diffusion-Models"><a href="#Structure-Guided-Adversarial-Training-of-Diffusion-Models" class="headerlink" title="Structure-Guided Adversarial Training of Diffusion Models"></a>Structure-Guided Adversarial Training of Diffusion Models</h2><p><strong>Authors:Ling Yang, Haotian Qian, Zhilong Zhang, Jingwei Liu, Bin Cui</strong></p><p>Diffusion models have demonstrated exceptional efficacy in various generative applications. While existing models focus on minimizing a weighted sum of denoising score matching losses for data distribution modeling, their training primarily emphasizes instance-level optimization, overlooking valuable structural information within each mini-batch, indicative of pair-wise relationships among samples. To address this limitation, we introduce Structure-guided Adversarial training of Diffusion Models (SADM). In this pioneering approach, we compel the model to learn manifold structures between samples in each training batch. To ensure the model captures authentic manifold structures in the data distribution, we advocate adversarial training of the diffusion generator against a novel structure discriminator in a minimax game, distinguishing real manifold structures from the generated ones. SADM substantially improves existing diffusion transformers (DiT) and outperforms existing methods in image generation and cross-domain fine-tuning tasks across 12 datasets, establishing a new state-of-the-art FID of 1.58 and 2.11 on ImageNet for class-conditional image generation at resolutions of 256x256 and 512x512, respectively. </p><p><a href="http://arxiv.org/abs/2402.17563v1">PDF</a> Accepted by CVPR 2024</p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹é€šè¿‡ç»“æ„å¯¹æŠ—è®­ç»ƒï¼Œå­¦ä¹ æ‰¹å†…æ ·æœ¬æµå½¢ç»“æ„ï¼Œæå‡å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡çš„æ€§èƒ½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>ç°æœ‰æ‰©æ•£æ¨¡å‹ä¸“æ³¨äºå•ä¸ªæ ·æœ¬çš„å»å™ªå¾—åˆ†åŒ¹é…æŸå¤±ä¼˜åŒ–ï¼Œå¿½è§†æ‰¹å†…æ ·æœ¬ä¹‹é—´çš„æˆå¯¹å…³ç³»ã€‚</li><li>ç»“æ„å¯¹æŠ—è®­ç»ƒ (SADM) å¼•å…¥ç»“æ„é‰´åˆ«å™¨æ¥åŒºåˆ†çœŸå®å’Œç”Ÿæˆçš„æµå½¢ç»“æ„ã€‚</li><li>SADM è¿«ä½¿æ¨¡å‹å­¦ä¹ è®­ç»ƒæ‰¹æ¬¡ä¸­æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ã€‚</li><li>SADM ä¸æ‰©æ•£å˜å‹å™¨ (DiT) ç›¸ç»“åˆï¼Œåœ¨å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li><li>SADM åœ¨ 12 ä¸ªæ•°æ®é›†ä¸Šå®ç°äº†å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡çš„æœ€æ–° FID åˆ†åˆ«ä¸º 1.58 å’Œ 2.11ã€‚</li><li>SADM åœ¨ 256x256 å’Œ 512x512 åˆ†è¾¨ç‡ä¸‹ï¼Œåœ¨ ImageNet ä¸Šå®ç°äº†ç±»æ¡ä»¶å›¾åƒç”Ÿæˆçš„æœ€æ–° FID åˆ†åˆ«ä¸º 1.58 å’Œ 2.11ã€‚</li><li>SADM è¯æ˜äº†æµå½¢ç»“æ„å­¦ä¹ å¯¹äºæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­çš„é‡è¦æ€§ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹å¯¹æŠ—æ€§è®­ç»ƒ</li><li>ä½œè€…ï¼šæ¨å‡Œã€é’±æµ©å¤©ã€å¼ æ™ºé¾™ã€åˆ˜æ™¯ä¼Ÿã€å´”æ–Œ</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåŒ—äº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€ç»“æ„å¼•å¯¼ã€å¯¹æŠ—è®­ç»ƒ</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17563   Github é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æœ€å°åŒ–å»å™ªå¾—åˆ†åŒ¹é…æŸå¤±çš„åŠ æƒå’Œï¼Œè®­ç»ƒè¿‡ç¨‹ä¾§é‡äºå®ä¾‹çº§ä¼˜åŒ–ï¼Œå¿½ç•¥äº†å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„å®è´µç»“æ„ä¿¡æ¯ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å®ä¾‹çº§ä¼˜åŒ–ï¼Œå¿½ç•¥äº†å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„ç»“æ„ä¿¡æ¯ï¼Œå¯¼è‡´æ— æ³•å……åˆ†å»ºæ¨¡æ•°æ®åˆ†å¸ƒã€‚</p><p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡ºç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹å¯¹æŠ—æ€§è®­ç»ƒï¼ˆSADMï¼‰ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæŒ‡å¯¼æ‰©æ•£ç”Ÿæˆå™¨å­¦ä¹ å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ã€‚å¼•å…¥ç»“æ„åˆ¤åˆ«å™¨æ¥åŒºåˆ†çœŸå®æµå½¢ç»“æ„å’Œç”Ÿæˆæµå½¢ç»“æ„ï¼Œç¡®ä¿æ¨¡å‹æ•è·æ•°æ®åˆ†å¸ƒä¸­çš„çœŸå®æµå½¢ç»“æ„ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šSADM æ˜¾è‘—æå‡äº†ç°æœ‰æ‰©æ•£ Transformerï¼Œåœ¨ 12 ä¸ªæ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨ ImageNet ä¸Šåˆ†åˆ«ä»¥ 256Ã—256 å’Œ 512Ã—512 çš„åˆ†è¾¨ç‡å®ç°äº† 1.58 å’Œ 2.11 çš„æ–° SOTA FIDï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p><p>7.Methodsï¼šï¼ˆ1ï¼‰æå‡ºç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹å¯¹æŠ—æ€§è®­ç»ƒï¼ˆSADMï¼‰ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæŒ‡å¯¼æ‰©æ•£ç”Ÿæˆå™¨å­¦ä¹ å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ï¼›ï¼ˆ2ï¼‰å¼•å…¥ç»“æ„åˆ¤åˆ«å™¨æ¥åŒºåˆ†çœŸå®æµå½¢ç»“æ„å’Œç”Ÿæˆæµå½¢ç»“æ„ï¼Œç¡®ä¿æ¨¡å‹æ•è·æ•°æ®åˆ†å¸ƒä¸­çš„çœŸå®æµå½¢ç»“æ„ï¼›ï¼ˆ3ï¼‰é‡‡ç”¨Wasserstein GANæŸå¤±å‡½æ•°ï¼ŒæŒ‡å¯¼ç”Ÿæˆå™¨ç”Ÿæˆä¸çœŸå®æµå½¢ç»“æ„ç›¸ä¼¼çš„æ ·æœ¬ï¼›ï¼ˆ4ï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­äº¤æ›¿æ›´æ–°ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼Œç›´è‡³è¾¾åˆ°çº³ä»€å‡è¡¡ï¼›ï¼ˆ5ï¼‰å°†SADMä¸æ‰©æ•£Transformerç›¸ç»“åˆï¼Œå½¢æˆæ›´å¼ºå¤§çš„å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚</p><ol><li>æ€»ç»“(1): æœ¬æ–‡æå‡ºäº†ä»ç»“æ„è§’åº¦ä¼˜åŒ–æ‰©æ•£æ¨¡å‹çš„ç»“æ„å¼•å¯¼å¯¹æŠ—æ€§è®­ç»ƒæ–¹æ³•ï¼Œè¯¥è®­ç»ƒç®—æ³•å¯ä»¥è½»æ¾æ¨å¹¿åˆ°å›¾åƒå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼å’Œå®éªŒç»“æœä¸€è‡´åœ°æ”¹è¿›äº†ç°æœ‰çš„æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨ 12 ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸­å–å¾—äº†æ–°çš„ SOTA æ€§èƒ½ã€‚å¯¹äºæœªæ¥çš„å·¥ä½œï¼Œæˆ‘ä»¬å°†æŠŠæˆ‘ä»¬çš„æ–¹æ³•æ‰©å±•åˆ°æ›´å…·æŒ‘æˆ˜æ€§çš„åŸºäºæ‰©æ•£çš„åº”ç”¨ç¨‹åºï¼ˆä¾‹å¦‚ï¼Œæ–‡æœ¬åˆ°å›¾åƒ/è§†é¢‘ç”Ÿæˆï¼‰ã€‚(2): åˆ›æ–°ç‚¹: æå‡ºç»“æ„å¼•å¯¼å¯¹æŠ—æ€§è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæŒ‡å¯¼æ‰©æ•£ç”Ÿæˆå™¨å­¦ä¹ å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ï¼Œä»è€Œæå‡æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚æ€§èƒ½: åœ¨ 12 ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸­å–å¾—äº†æ–°çš„ SOTA æ€§èƒ½ï¼Œåœ¨ ImageNet ä¸Šåˆ†åˆ«ä»¥ 256Ã—256 å’Œ 512Ã—512 çš„åˆ†è¾¨ç‡å®ç°äº† 1.58 å’Œ 2.11 çš„æ–° SOTAFIDã€‚å·¥ä½œé‡: è¯¥æ–¹æ³•æ˜“äºå®ç°ï¼Œå¯ä»¥è½»æ¾æ¨å¹¿åˆ°å›¾åƒå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-11a45496d9d4169c7ee0bbb4a6534ffa.jpg" align="middle"><img src="https://picx.zhimg.com/v2-b4ae1e4da806d223271756f678f15ce9.jpg" align="middle"><img src="https://picx.zhimg.com/v2-02b820484fca35ffef9bc52706101c79.jpg" align="middle"><img src="https://picx.zhimg.com/v2-14ed9373ba8bdaf3ecaca75391245256.jpg" align="middle"><img src="https://pica.zhimg.com/v2-75ca2aa69507bb15984388d3520039af.jpg" align="middle"></details><h2 id="Diffusion-Model-Based-Image-Editing-A-Survey"><a href="#Diffusion-Model-Based-Image-Editing-A-Survey" class="headerlink" title="Diffusion Model-Based Image Editing: A Survey"></a>Diffusion Model-Based Image Editing: A Survey</h2><p><strong>Authors:Yi Huang, Jiancheng Huang, Yifan Liu, Mingfu Yan, Jiaxi Lv, Jianzhuang Liu, Wei Xiong, He Zhang, Shifeng Chen, Liangliang Cao</strong></p><p>Denoising diffusion models have emerged as a powerful tool for various image generation and editing tasks, facilitating the synthesis of visual content in an unconditional or input-conditional manner. The core idea behind them is learning to reverse the process of gradually adding noise to images, allowing them to generate high-quality samples from a complex distribution. In this survey, we provide an exhaustive overview of existing methods using diffusion models for image editing, covering both theoretical and practical aspects in the field. We delve into a thorough analysis and categorization of these works from multiple perspectives, including learning strategies, user-input conditions, and the array of specific editing tasks that can be accomplished. In addition, we pay special attention to image inpainting and outpainting, and explore both earlier traditional context-driven and current multimodal conditional methods, offering a comprehensive analysis of their methodologies. To further evaluate the performance of text-guided image editing algorithms, we propose a systematic benchmark, EditEval, featuring an innovative metric, LMM Score. Finally, we address current limitations and envision some potential directions for future research. The accompanying repository is released at <a href="https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods">https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods</a>. </p><p><a href="http://arxiv.org/abs/2402.17525v1">PDF</a> </p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆå’Œç¼–è¾‘ä»»åŠ¡ä¸­åº”ç”¨å¹¿æ³›ï¼Œå¯ä»å¤æ‚åˆ†å¸ƒä¸­ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ï¼Œä¸”æ”¯æŒæ— æ¡ä»¶å’Œè¾“å…¥æ¡ä»¶ä¸‹çš„å›¾åƒç¼–è¾‘ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹é€šè¿‡å­¦ä¹ é€†è½¬å›¾åƒåŠ å™ªè¿‡ç¨‹ï¼Œç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ã€‚</li><li>æ‰©æ•£æ¨¡å‹å›¾åƒç¼–è¾‘æ–¹æ³•å¯åˆ†ä¸ºä¸åŒå­¦ä¹ ç­–ç•¥ã€ç”¨æˆ·è¾“å…¥æ¡ä»¶å’Œç¼–è¾‘ä»»åŠ¡ã€‚</li><li>å›¾åƒä¿®å¤å’Œå¤–å»¶å¯ä½¿ç”¨ä¼ ç»Ÿä¸Šä¸‹æ–‡é©±åŠ¨æ–¹æ³•æˆ–å¤šæ¨¡æ€æ¡ä»¶æ–¹æ³•ã€‚</li><li>æå‡º EditEval åŸºå‡†å’Œ LMM è¯„åˆ†ç”¨äºè¯„ä¼°æ–‡æœ¬æŒ‡å¯¼å›¾åƒç¼–è¾‘ç®—æ³•ã€‚</li><li>ç›®å‰å­˜åœ¨é™åˆ¶ï¼Œæœªæ¥ç ”ç©¶æ–¹å‘åŒ…æ‹¬å¤šæ¨¡æ€ã€3D å’Œç¼–è¾‘å…ƒæ•°æ®ã€‚</li><li>å¯åœ¨ <a href="https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods">https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods</a> è·å–ç›¸å…³ä»£ç ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘ï¼šç»¼è¿°</li><li>ä½œè€…ï¼šYi Huangã€Jiancheng Huangã€Yifan Liuã€Mingfu Yanã€Jiaxi Lvã€Jianzhuang Liuã€Wei Xiongã€He Zhangã€Shifeng Chenã€Liangliang Cao</li><li>å•ä½ï¼šæ·±åœ³å…ˆè¿›æŠ€æœ¯ç ”ç©¶é™¢</li><li>å…³é”®è¯ï¼šDiffusion Modelã€Image Editingã€AIGC</li><li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17525Githubï¼šæ— </li><li>æ‘˜è¦ï¼š(1)ï¼šéšç€äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æŠ€æœ¯çš„å‘å±•ï¼ŒAI ç”Ÿæˆçš„å†…å®¹ï¼ˆAIGCï¼‰é¢†åŸŸè“¬å‹ƒå‘å±•ï¼Œå›¾åƒç¼–è¾‘ä½œä¸ºå…¶ä¸­ä¸€é¡¹é‡è¦ä»»åŠ¡ï¼Œåœ¨æ•°å­—åª’ä½“ã€å¹¿å‘Šå’Œç§‘å­¦ç ”ç©¶ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚(2)ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿‘å¹´æ¥å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å­¦ä¹ é€æ­¥ç»™å›¾åƒæ·»åŠ å™ªå£°å¹¶é€†è½¬è¿™ä¸€è¿‡ç¨‹ï¼Œå¯ä»¥ä»å¤æ‚åˆ†å¸ƒä¸­ç”Ÿæˆé«˜è´¨é‡çš„æ ·æœ¬ã€‚(3)ï¼šæœ¬æ–‡å¯¹åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œä»å­¦ä¹ ç­–ç•¥ã€ç”¨æˆ·è¾“å…¥æ¡ä»¶å’Œå…·ä½“ç¼–è¾‘ä»»åŠ¡ç­‰å¤šä¸ªè§’åº¦å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œäº†æ·±å…¥åˆ†æå’Œåˆ†ç±»ã€‚(4)ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•åœ¨å›¾åƒä¿®å¤ã€å›¾åƒå¤–å»¶ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„åŸºå‡† EditEval å’Œä¸€ä¸ªåˆ›æ–°çš„æŒ‡æ ‡ LMMScore æ¥è¿›ä¸€æ­¥è¯„ä¼°æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç®—æ³•çš„æ€§èƒ½ã€‚</li></ol><p>7.Methods:(1): åŸºäºCLIPæŒ‡å¯¼çš„å›¾åƒç¼–è¾‘ï¼šDiffusionCLIPã€Asyrpã€EffDiffã€DiffStylerã€StyleDiffusionã€UNIT-DDPMã€CycleNetã€DiffusionAutoencodersã€HDAEã€EGSDEã€Pixel-GuidedDiffusionï¼›(2): åŸºäºå‚è€ƒå’Œå±æ€§æŒ‡å¯¼çš„å›¾åƒç¼–è¾‘ï¼šPbEã€RICã€ObjectStitchã€PhDã€DreamInpainterã€Anydoorã€FADINGã€PAIRDiffusionã€SmartBrushã€IIR-Netï¼›(3): åŸºäºæŒ‡ä»¤æŒ‡å¯¼çš„å›¾åƒç¼–è¾‘ï¼šInstructPix2Pixã€MoEControllerã€FoIã€LOFIEã€InstructDiffusionã€EmuEditã€DialogPaintã€Inst-Inpaintã€HIVEã€ImageBrushã€InstructAny2Pixã€MGIEã€SmartEditã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œå¯¹åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œä»å¤šä¸ªè§’åº¦å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œäº†æ·±å…¥åˆ†æå’Œåˆ†ç±»ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„åŸºå‡† EditEval å’Œä¸€ä¸ªåˆ›æ–°çš„æŒ‡æ ‡ LMMScore æ¥è¿›ä¸€æ­¥è¯„ä¼°æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç®—æ³•çš„æ€§èƒ½ã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒç¼–è¾‘åŸºå‡† EditEval å’Œä¸€ä¸ªåˆ›æ–°çš„æŒ‡æ ‡ LMMScoreï¼Œç”¨äºè¯„ä¼°æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç®—æ³•çš„æ€§èƒ½ã€‚</li><li>å¯¹åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°å’Œåˆ†ç±»ï¼Œä»å­¦ä¹ ç­–ç•¥ã€ç”¨æˆ·è¾“å…¥æ¡ä»¶å’Œå…·ä½“ç¼–è¾‘ä»»åŠ¡ç­‰å¤šä¸ªè§’åº¦å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œäº†æ·±å…¥åˆ†æã€‚</li><li>æ¢ç´¢äº†è¿™äº›æ–¹æ³•åœ¨å¢å¼ºç¼–è¾‘æ€§èƒ½æ–¹é¢çš„è´¡çŒ®ã€‚</li><li>åœ¨æˆ‘ä»¬çš„å›¾åƒç¼–è¾‘åŸºå‡† EditEval ä¸­å¯¹ 7 é¡¹ä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ï¼Œä»¥åŠæœ€æ–°æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li><li>æ€»ç»“äº†å›¾åƒç¼–è¾‘é¢†åŸŸçš„å¹¿æ³›æ½œåŠ›ï¼Œå¹¶æå‡ºäº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚</li><li>æ€§èƒ½ï¼šåœ¨ EditEval åŸºå‡†ä¸Šï¼ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•åœ¨å›¾åƒä¿®å¤ã€å›¾åƒå¤–å»¶ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚</li><li>å·¥ä½œé‡ï¼šæœ¬æ–‡å¯¹è¶…è¿‡ 100 ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†ç»¼è¿°å’Œåˆ†ç±»ï¼Œå¹¶å¯¹ 7 é¡¹ä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-4c52565ddb49dad37f10475b00a6abbc.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4537d5996d9b29f71e82d00a227227b7.jpg" align="middle"><img src="https://picx.zhimg.com/v2-db76ba27193f9ab6b62bab161a239510.jpg" align="middle"></details><h2 id="Enhancing-Hyperspectral-Images-via-Diffusion-Model-and-Group-Autoencoder-Super-resolution-Network"><a href="#Enhancing-Hyperspectral-Images-via-Diffusion-Model-and-Group-Autoencoder-Super-resolution-Network" class="headerlink" title="Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder   Super-resolution Network"></a>Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder   Super-resolution Network</h2><p><strong>Authors:Zhaoyang Wang, Dongyang Li, Mingyang Zhang, Hao Luo, Maoguo Gong</strong></p><p>Existing hyperspectral image (HSI) super-resolution (SR) methods struggle to effectively capture the complex spectral-spatial relationships and low-level details, while diffusion models represent a promising generative model known for their exceptional performance in modeling complex relations and learning high and low-level visual features. The direct application of diffusion models to HSI SR is hampered by challenges such as difficulties in model convergence and protracted inference time. In this work, we introduce a novel Group-Autoencoder (GAE) framework that synergistically combines with the diffusion model to construct a highly effective HSI SR model (DMGASR). Our proposed GAE framework encodes high-dimensional HSI data into low-dimensional latent space where the diffusion model works, thereby alleviating the difficulty of training the diffusion model while maintaining band correlation and considerably reducing inference time. Experimental results on both natural and remote sensing hyperspectral datasets demonstrate that the proposed method is superior to other state-of-the-art methods both visually and metrically. </p><p><a href="http://arxiv.org/abs/2402.17285v1">PDF</a> Accepted by AAAI2024</p><p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹ä¸ç¾¤ç»„è‡ªç¼–ç å™¨ç›¸ç»“åˆçš„åˆ›æ–°æ¡†æ¶ï¼Œæœ‰æ•ˆæå‡é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œæ˜¾è‘—æ”¹å–„è°±ç©ºå…³ç³»å»ºæ¨¡å’Œä½å±‚ç»†èŠ‚æ¢å¤ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹æ“…é•¿å»ºæ¨¡å¤æ‚å…³ç³»å’Œå­¦ä¹ è§†è§‰ç‰¹å¾ï¼Œåœ¨é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­æ½œåŠ›å·¨å¤§ã€‚</li><li>è®­ç»ƒæ‰©æ•£æ¨¡å‹é¢ä¸´æ”¶æ•›å›°éš¾å’Œæ¨ç†æ—¶é—´é•¿æŒ‘æˆ˜ã€‚</li><li>ç¾¤ç»„è‡ªç¼–ç å™¨æ¡†æ¶é€šè¿‡å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç åˆ°ä½ç»´æ½œåœ¨ç©ºé—´ï¼Œç¼“è§£äº†æ‰©æ•£æ¨¡å‹è®­ç»ƒéš¾åº¦ï¼Œå¹¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§ã€‚</li><li>æ‰©æ•£æ¨¡å‹ä¸ç¾¤ç»„è‡ªç¼–ç å™¨ç›¸ç»“åˆï¼Œæœ‰æ•ˆè§£å†³äº†æ¨ç†æ—¶é—´é—®é¢˜ã€‚</li><li>åœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰å’Œåº¦é‡ä¸Šå‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„è¶…åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒå¢å¼º</li><li>ä½œè€…ï¼šç‹å…†é˜³ï¼Œæä¸œé˜³ï¼Œå¼ æ˜é˜³ï¼Œç½—æµ©ï¼Œå·©èŒ‚å›½</li><li>éš¶å±å•ä½ï¼šè¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦ååŒæ™ºèƒ½ç³»ç»Ÿæ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤</li><li>å…³é”®è¯ï¼šé«˜å…‰è°±å›¾åƒï¼Œè¶…åˆ†è¾¨ç‡ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œç»„è‡ªç¼–ç å™¨</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17285</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•æ‰å¤æ‚çš„å…‰è°±-ç©ºé—´å…³ç³»å’Œä½çº§ç»†èŠ‚ï¼Œè€Œæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§æœ‰å‰é€”çš„ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å…¶åœ¨å»ºæ¨¡å¤æ‚å…³ç³»å’Œå­¦ä¹ é«˜ä½çº§è§†è§‰ç‰¹å¾æ–¹é¢çš„å‡ºè‰²æ€§èƒ½è€Œé—»åã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šå°†æ‰©æ•£æ¨¡å‹ç›´æ¥åº”ç”¨äºé«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡é¢ä¸´ç€æ¨¡å‹æ”¶æ•›å›°éš¾å’Œæ¨ç†æ—¶é—´é•¿çš„æŒ‘æˆ˜ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§æ–°çš„ç»„è‡ªç¼–ç å™¨ï¼ˆGAEï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸æ‰©æ•£æ¨¡å‹ååŒç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆçš„é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼ˆDMGASRï¼‰ã€‚æå‡ºçš„ GAE æ¡†æ¶å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç ä¸ºä½ç»´æ½œåœ¨ç©ºé—´ï¼Œæ‰©æ•£æ¨¡å‹åœ¨æ­¤ç©ºé—´ä¸­å·¥ä½œï¼Œä»è€Œç¼“è§£äº†è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„éš¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§å¹¶å¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ã€‚ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨è§†è§‰å’Œåº¦é‡ä¸Šéƒ½ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1): æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„è¶…åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒå¢å¼ºæ¨¡å‹ï¼ˆDMGASRï¼‰ï¼›(2): è¯¥æ¨¡å‹é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ–¹å¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨ç¼–ç å™¨å’Œæ‰©æ•£è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼›(3): é‡‡ç”¨è°±åˆ†ç»„ç­–ç•¥å’Œéå¯¹ç§°è§£ç å™¨è®¾è®¡ï¼Œæœ‰æ•ˆåœ°å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç ä¸ºä½ç»´æ½œåœ¨ç©ºé—´ï¼›(4): è®­ç»ƒæ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­å·¥ä½œï¼Œç¼“è§£äº†è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„éš¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§å¹¶å¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ï¼›(5): è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨é‡æ„è¾“å…¥æ•°æ®ï¼Œç”Ÿæˆä¸€ç³»åˆ—éšè—å˜é‡ï¼›(6): å°†ä½åˆ†è¾¨ç‡éšè—å˜é‡ä½œä¸ºæ¡ä»¶ä¿¡æ¯ï¼Œä¸é«˜åˆ†è¾¨ç‡éšè—å˜é‡ä¸²è”ï¼Œåœ¨å»å™ªè¿‡ç¨‹ä¸­åŠ å…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼›(7): é‡‡ç”¨ U-Net ä½œä¸ºå»å™ªæ¨¡å‹ï¼Œè¿­ä»£å»é™¤å™ªå£°ï¼Œç”Ÿæˆè¶…åˆ†è¾¨ç‡æ½œåœ¨å˜é‡åˆ—è¡¨ï¼›(8): å°†è¶…åˆ†è¾¨ç‡æ½œåœ¨å˜é‡åˆ—è¡¨ä¼ é€’ç»™è§£ç å™¨ï¼Œç”Ÿæˆè¶…åˆ†è¾¨ç‡å›¾åƒã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡å¢å¼ºæ¨¡å‹ï¼ˆDMGASRï¼‰ï¼Œè¯¥æ¨¡å‹å°†æ‰©æ•£æ¨¡å‹ä¸è‡ªåŠ¨ç¼–ç å™¨ç›¸ç»“åˆï¼Œæœ‰æ•ˆè§£å†³äº†æ‰©æ•£æ¨¡å‹åœ¨é«˜ç»´æ•°æ®ä¸Šæ”¶æ•›å›°éš¾çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡åœ¨ä½ç»´æ½œåœ¨ç©ºé—´ä¸­è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œå¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ã€‚è¯¥æ–¹æ³•åœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨è§†è§‰å’Œåº¦é‡ä¸Šå‡ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„è¶…åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒå¢å¼ºæ¨¡å‹ï¼ˆDMGASRï¼‰ã€‚</li><li>é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ–¹å¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨ç¼–ç å™¨å’Œæ‰©æ•£è¶…åˆ†è¾¨ç‡æ¨¡å‹ã€‚</li><li>é‡‡ç”¨è°±åˆ†ç»„ç­–ç•¥å’Œéå¯¹ç§°è§£ç å™¨è®¾è®¡ï¼Œæœ‰æ•ˆåœ°å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç ä¸ºä½ç»´æ½œåœ¨ç©ºé—´ã€‚</li><li>è®­ç»ƒæ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­å·¥ä½œï¼Œç¼“è§£äº†è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„éš¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§å¹¶å¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ã€‚æ€§èƒ½ï¼š</li><li>åœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚</li><li>åœ¨è§†è§‰å’Œåº¦é‡ä¸Šå‡ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚å·¥ä½œé‡ï¼š</li><li>ç®—æ³•è®¾è®¡å’Œå®ç°ã€‚</li><li>æ•°æ®é›†çš„æ”¶é›†å’Œé¢„å¤„ç†ã€‚</li><li>å®éªŒçš„è¿›è¡Œå’Œç»“æœåˆ†æã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-1b637edd1829307f3889177173204f7c.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-cc3237f0ece24500c44086801ebc1feb.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a3e331ea518a2b9c151178e17f115708.jpg" align="middle"><img src="https://picx.zhimg.com/v2-7b211209593777f9420f6bb845daa71b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f24696c9c22f22b6e487ce2e6fc31ec7.jpg" align="middle"></details><h2 id="One-Shot-Structure-Aware-Stylized-Image-Synthesis"><a href="#One-Shot-Structure-Aware-Stylized-Image-Synthesis" class="headerlink" title="One-Shot Structure-Aware Stylized Image Synthesis"></a>One-Shot Structure-Aware Stylized Image Synthesis</h2><p><strong>Authors:Hansam Cho, Jonghyun Lee, Seunggyu Chang, Yonghyun Jeong</strong></p><p>While GAN-based models have been successful in image stylization tasks, they often struggle with structure preservation while stylizing a wide range of input images. Recently, diffusion models have been adopted for image stylization but still lack the capability to maintain the original quality of input images. Building on this, we propose OSASIS: a novel one-shot stylization method that is robust in structure preservation. We show that OSASIS is able to effectively disentangle the semantics from the structure of an image, allowing it to control the level of content and style implemented to a given input. We apply OSASIS to various experimental settings, including stylization with out-of-domain reference images and stylization with text-driven manipulation. Results show that OSASIS outperforms other stylization methods, especially for input images that were rarely encountered during training, providing a promising solution to stylization via diffusion models. </p><p><a href="http://arxiv.org/abs/2402.17275v1">PDF</a> CVPR 2024</p><p><strong>Summary</strong><br>åŸºäºæ‰©æ•£æ¨¡å‹çš„ OSASIS å®ç°äº†å›¾åƒé£æ ¼åŒ–ï¼ŒåŒæ—¶ä¿æŒäº†ç»“æ„å®Œæ•´æ€§ï¼Œå³ä½¿æ˜¯å¯¹è®­ç»ƒä¸­å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>OSASIS é‡‡ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒé£æ ¼åŒ–ï¼Œè§£å†³äº† GAN æ¨¡å‹åœ¨ä¿æŒç»“æ„æ–¹é¢çš„ä¸è¶³ã€‚</li><li>OSASIS èƒ½å¤Ÿæœ‰æ•ˆåˆ†ç¦»å›¾åƒè¯­ä¹‰å’Œç»“æ„ï¼Œå¯æ§åœ°è°ƒæ•´ç»™å®šè¾“å…¥çš„å†…å®¹å’Œé£æ ¼çº§åˆ«ã€‚</li><li>OSASIS åœ¨å„ç§å®éªŒè®¾ç½®ä¸­è¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŸŸå¤–å‚è€ƒå›¾åƒè¿›è¡Œé£æ ¼åŒ–å’Œä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æ“ä½œè¿›è¡Œé£æ ¼åŒ–ã€‚</li><li>ä¸å…¶ä»–é£æ ¼åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒOSASIS åœ¨è®­ç»ƒä¸­å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒä¸Šè¡¨ç°å¾—å°¤ä¸ºå‡ºè‰²ï¼Œä¸ºé€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼åŒ–æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</li><li>OSASIS é‡‡ç”¨äº†æ¸è¿›å¼è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡ä»æ·»åŠ å™ªå£°åˆ°æ¢å¤å›¾åƒï¼Œé€æ­¥å°†é£æ ¼åº”ç”¨äºè¾“å…¥ã€‚</li><li>OSASIS ä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œæé«˜äº†æ•ˆç‡å’Œæ³›åŒ–æ€§ã€‚</li><li>OSASIS åœ¨å›¾åƒé£æ ¼åŒ–é¢†åŸŸå±•ç°å‡ºäº†å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å›¾åƒç¼–è¾‘ã€è‰ºæœ¯åˆ›ä½œå’Œè§†é¢‘å¤„ç†ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šå•æ¬¡ç»“æ„æ„ŸçŸ¥é£æ ¼åŒ–å›¾åƒåˆæˆ</li><li>ä½œè€…ï¼šJongmin Lee*, Jaeyeon Kang, Sangwoo Mo, Seongwon Leeâ€ , Kyoung Mu Leeâ€ </li><li>éš¶å±å•ä½ï¼šNAVER Cloud</li><li>å…³é”®è¯ï¼šå›¾åƒé£æ ¼åŒ–ã€æ‰©æ•£æ¨¡å‹ã€ç»“æ„ä¿æŒ</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.05447, Github ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šGAN æ¨¡å‹åœ¨å›¾åƒé£æ ¼åŒ–ä»»åŠ¡ä¸­å–å¾—æˆåŠŸï¼Œä½†éš¾ä»¥åœ¨é£æ ¼åŒ–å„ç§è¾“å…¥å›¾åƒæ—¶ä¿æŒç»“æ„ã€‚æœ€è¿‘ï¼Œæ‰©æ•£æ¨¡å‹è¢«ç”¨äºå›¾åƒé£æ ¼åŒ–ï¼Œä½†ä»ç¼ºä¹ä¿æŒè¾“å…¥å›¾åƒåŸå§‹è´¨é‡çš„èƒ½åŠ›ã€‚(2) è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»æ–¹æ³•åŒ…æ‹¬åŸºäº GAN çš„æ¨¡å‹å’ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ã€‚GAN æ¨¡å‹éš¾ä»¥ä¿æŒç»“æ„ï¼Œè€ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ç¼ºä¹æ§åˆ¶å†…å®¹å’Œé£æ ¼çš„èƒ½åŠ›ã€‚(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å•æ¬¡é£æ ¼åŒ–æ–¹æ³• OSASISï¼Œè¯¥æ–¹æ³•åœ¨ç»“æ„ä¿æŒæ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚OSASIS é€šè¿‡å°†è¯­ä¹‰ä»å›¾åƒçš„ç»“æ„ä¸­è§£è€¦ï¼Œä»è€Œæœ‰æ•ˆåœ°æ§åˆ¶åº”ç”¨äºç»™å®šè¾“å…¥çš„å†…å®¹å’Œé£æ ¼çš„çº§åˆ«ã€‚(4) ä»»åŠ¡å’Œæ€§èƒ½ï¼šOSASIS åœ¨å„ç§å®éªŒè®¾ç½®ä¸­å¾—åˆ°åº”ç”¨ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŸŸå¤–å‚è€ƒå›¾åƒçš„é£æ ¼åŒ–å’Œä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æ“ä½œçš„é£æ ¼åŒ–ã€‚ç»“æœè¡¨æ˜ï¼ŒOSASIS ä¼˜äºå…¶ä»–é£æ ¼åŒ–æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹äºåœ¨è®­ç»ƒæœŸé—´å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒï¼Œä¸ºé€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼åŒ–æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</li></ol><p><strong>Methodsï¼š</strong></p><ol><li><strong>å›¾åƒåˆ†è§£ï¼š</strong>å°†è¾“å…¥å›¾åƒåˆ†è§£ä¸ºå†…å®¹å’Œç»“æ„ç‰¹å¾ï¼Œå…¶ä¸­å†…å®¹ç‰¹å¾è¡¨ç¤ºå›¾åƒçš„è¯­ä¹‰ä¿¡æ¯ï¼Œè€Œç»“æ„ç‰¹å¾è¡¨ç¤ºå›¾åƒçš„å‡ ä½•å½¢çŠ¶å’Œçº¹ç†ã€‚</li><li><strong>é£æ ¼åµŒå…¥ï¼š</strong>å°†å‚è€ƒé£æ ¼å›¾åƒåµŒå…¥åˆ°ä¸€ä¸ªæ½œåœ¨ç©ºé—´ä¸­ï¼Œè¯¥ç©ºé—´ç”±æ‰©æ•£æ¨¡å‹è®­ç»ƒã€‚</li><li><strong>é£æ ¼ä¼ è¾“ï¼š</strong>å°†è¾“å…¥å›¾åƒçš„å†…å®¹ç‰¹å¾ä¸å‚è€ƒé£æ ¼çš„é£æ ¼åµŒå…¥ç›¸ç»“åˆï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„å›¾åƒï¼Œè¯¥å›¾åƒå…·æœ‰è¾“å…¥å›¾åƒçš„ç»“æ„å’Œå‚è€ƒé£æ ¼çš„é£æ ¼ã€‚</li><li><p><strong>ç»“æ„ä¿æŒï¼š</strong>é€šè¿‡ä½¿ç”¨ä¸€ä¸ªé¢å¤–çš„æŸå¤±å‡½æ•°ï¼Œå°†è¾“å…¥å›¾åƒçš„ç»“æ„ç‰¹å¾ä¸ç”Ÿæˆå›¾åƒçš„ç»“æ„ç‰¹å¾è¿›è¡ŒåŒ¹é…ï¼Œä»è€Œä¿æŒè¾“å…¥å›¾åƒçš„åŸå§‹è´¨é‡ã€‚</p></li><li><p>ç»“è®ºï¼š(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°å‹å•æ¬¡å›¾åƒé£æ ¼åŒ–æ–¹æ³• OSASISï¼Œè¯¥æ–¹æ³•åœ¨ç»“æ„ä¿æŒæ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚ä¸åŸºäº GAN å’Œå…¶ä»–åŸºäºæ‰©æ•£çš„é£æ ¼åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒOSASIS å±•ç¤ºäº†åœ¨é£æ ¼åŒ–ä¸­å¯¹ç»“æ„çš„å¼ºå¤§æ„ŸçŸ¥ï¼Œæœ‰æ•ˆåœ°å°†å›¾åƒçš„ç»“æ„å’Œè¯­ä¹‰è§£è€¦ã€‚å°½ç®¡ OSASIS åœ¨ç»“æ„æ„ŸçŸ¥é£æ ¼åŒ–æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸€äº›å±€é™æ€§ã€‚OSASIS çš„ä¸€ä¸ªæ˜¾ç€é™åˆ¶æ˜¯å…¶è®­ç»ƒæ—¶é—´ï¼Œæ¯”æ¯”è¾ƒæ–¹æ³•æ›´é•¿ã€‚è¿™ç§å»¶é•¿çš„è®­ç»ƒæŒç»­æ—¶é—´æ˜¯ä¸ºäº†æ¢å–è¯¥æ–¹æ³•å¢å¼ºäº†ä¿æŒç»“æ„å®Œæ•´æ€§å’Œé€‚åº”å„ç§é£æ ¼çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒOSASIS éœ€è¦é’ˆå¯¹æ¯å¼ é£æ ¼å›¾åƒè¿›è¡Œè®­ç»ƒã€‚åœ¨éœ€è¦è·¨å¤šç§é£æ ¼å¿«é€Ÿéƒ¨ç½²çš„åœºæ™¯ä¸­ï¼Œè¿™ä¸€è¦æ±‚å¯ä»¥è¢«è§†ä¸ºä¸€ç§é™åˆ¶ã€‚å°½ç®¡å­˜åœ¨è¿™äº›æŒ‘æˆ˜ï¼Œä½† OSASIS åœ¨ä¿æŒè¾“å…¥å›¾åƒç»“æ„å®Œæ•´æ€§æ–¹é¢çš„ç¨³å¥æ€§ã€å…¶åœ¨åŸŸå¤–å‚è€ƒé£æ ¼åŒ–ä¸­çš„æœ‰æ•ˆæ€§ä»¥åŠå…¶åœ¨æ–‡æœ¬é©±åŠ¨æ“ä½œä¸­çš„é€‚åº”æ€§ä½¿å…¶æˆä¸ºé£æ ¼åŒ–å›¾åƒåˆæˆé¢†åŸŸä¸­ä¸€ç§å¾ˆæœ‰å‰æ™¯çš„æ–¹æ³•ã€‚æœªæ¥çš„å·¥ä½œå°†è§£å†³è¿™äº›é™åˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¼˜åŒ–è®­ç»ƒæ•ˆç‡å’Œå‡å°‘å¯¹å•ä¸ªé£æ ¼å›¾åƒè®­ç»ƒçš„å¿…è¦æ€§æ–¹é¢ï¼Œä»¥å¢å¼º OSASIS åœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„å®ç”¨æ€§å’Œé€‚ç”¨æ€§ã€‚(2): åˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒé£æ ¼åŒ–æ–¹æ³• OSASISï¼Œè¯¥æ–¹æ³•åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œåœ¨ç»“æ„ä¿æŒæ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚</li><li>OSASIS é€šè¿‡å°†å›¾åƒçš„ç»“æ„å’Œè¯­ä¹‰è§£è€¦ï¼Œæœ‰æ•ˆåœ°æ§åˆ¶åº”ç”¨äºç»™å®šè¾“å…¥çš„å†…å®¹å’Œé£æ ¼çš„çº§åˆ«ã€‚</li><li>OSASIS åœ¨å„ç§å®éªŒè®¾ç½®ä¸­å¾—åˆ°åº”ç”¨ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŸŸå¤–å‚è€ƒå›¾åƒçš„é£æ ¼åŒ–å’Œä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æ“ä½œçš„é£æ ¼åŒ–ã€‚æ€§èƒ½ï¼š</li><li>OSASIS åœ¨ç»“æ„ä¿æŒæ–¹é¢ä¼˜äºå…¶ä»–é£æ ¼åŒ–æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹äºåœ¨è®­ç»ƒæœŸé—´å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒã€‚</li><li>OSASIS ä¸ºé€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼åŒ–æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚å·¥ä½œé‡ï¼š</li><li>OSASIS çš„è®­ç»ƒæ—¶é—´æ¯”æ¯”è¾ƒæ–¹æ³•æ›´é•¿ã€‚</li><li>OSASIS éœ€è¦é’ˆå¯¹æ¯å¼ é£æ ¼å›¾åƒè¿›è¡Œè®­ç»ƒã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-957518995345024bb9a18f0e683a4e55.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d0f3cefa16e52b2bb0bdbb679863e234.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4e8afc30904c2bad1400fb9f044e33a9.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f0eead50e28d5ed02ff0105780a9e22e.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-b842ecc40528644a1d824a5a8948f487.jpg" align="middle"></details><h2 id="Playground-v2-5-Three-Insights-towards-Enhancing-Aesthetic-Quality-in-Text-to-Image-Generation"><a href="#Playground-v2-5-Three-Insights-towards-Enhancing-Aesthetic-Quality-in-Text-to-Image-Generation" class="headerlink" title="Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in   Text-to-Image Generation"></a>Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in   Text-to-Image Generation</h2><p><strong>Authors:Daiqing Li, Aleks Kamko, Ehsan Akhgari, Ali Sabet, Linmiao Xu, Suhail Doshi</strong></p><p>In this work, we share three insights for achieving state-of-the-art aesthetic quality in text-to-image generative models. We focus on three critical aspects for model improvement: enhancing color and contrast, improving generation across multiple aspect ratios, and improving human-centric fine details. First, we delve into the significance of the noise schedule in training a diffusion model, demonstrating its profound impact on realism and visual fidelity. Second, we address the challenge of accommodating various aspect ratios in image generation, emphasizing the importance of preparing a balanced bucketed dataset. Lastly, we investigate the crucial role of aligning model outputs with human preferences, ensuring that generated images resonate with human perceptual expectations. Through extensive analysis and experiments, Playground v2.5 demonstrates state-of-the-art performance in terms of aesthetic quality under various conditions and aspect ratios, outperforming both widely-used open-source models like SDXL and Playground v2, and closed-source commercial systems such as DALLE 3 and Midjourney v5.2. Our model is open-source, and we hope the development of Playground v2.5 provides valuable guidelines for researchers aiming to elevate the aesthetic quality of diffusion-based image generation models. </p><p><a href="http://arxiv.org/abs/2402.17245v1">PDF</a> Model weights:   <a href="https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic">https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic</a></p><p><strong>Summary</strong><br>é€šè¿‡å¯¹å™ªå£°æ—¶é—´è¡¨ã€å®½é«˜æ¯”å‡†å¤‡å’Œé¢å‘äººç±»çš„å¾®è°ƒçš„ç ”ç©¶ï¼ŒPlayground v2.5  diffusion æ¨¡å‹å¯äº§ç”Ÿæä½³çš„ç¾å­¦è´¨é‡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>å™ªéŸ³æ—¶é—´è¡¨å¯¹æ¨¡å‹çœŸå®æ€§å’Œè§†è§‰ä¿çœŸåº¦è‡³å…³é‡è¦ã€‚</li><li>å¹³è¡¡çš„åˆ†åŒºæ•°æ®é›†å¯æ”¹å–„ä¸åŒå®½é«˜æ¯”çš„å›¾åƒç”Ÿæˆã€‚</li><li>å°†æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½ç›¸ç»“åˆå¯æå‡å›¾åƒçš„å…±é¸£æ•ˆæœã€‚</li><li>Playground v2.5 åœ¨å„ç§æ¡ä»¶å’Œå®½é«˜æ¯”ä¸‹è¡¨ç°å‡ºæœ€å…ˆè¿›çš„å®¡ç¾è´¨é‡ã€‚</li><li>Playground v2.5 æ¨¡å‹å¼€æºï¼Œä¸ºæå‡åŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆæ¨¡å‹çš„å®¡ç¾è´¨é‡æä¾›äº†æœ‰ä»·å€¼çš„æŒ‡å¯¼ã€‚</li><li>Playground v2.5 ä¼˜äº SDXLã€Playground v2ã€DALLE 3 å’Œ Midjourney v5.2ã€‚</li><li>ç ”ç©¶æœ‰åŠ©äºæé«˜åŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆæ¨¡å‹çš„å®¡ç¾è´¨é‡ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šPlayground v2.5ï¼šæå‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå®¡ç¾è´¨é‡çš„ä¸‰ç‚¹è§è§£</li><li>ä½œè€…ï¼šDaiqing Liã€Aleks Kamkoã€Ehsan Akhgariã€Ali Sabetã€Linmiao Xuã€Suhail Doshi</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šPlayground Research</li><li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€å®¡ç¾è´¨é‡</li><li>è®ºæ–‡é“¾æ¥ï¼šarXiv:2402.17245v1[cs.CV]</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒçš„å®¡ç¾è´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚é¢œè‰²å’Œå¯¹æ¯”åº¦ä¸è¶³ã€ä¸åŒå®½é«˜æ¯”ç”Ÿæˆè´¨é‡ä¸ä½³ã€ç¼ºä¹å¯¹äººç±»åå¥½çš„å¯¹é½ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šä»¥å¾€æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ”¹è¿›æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¦‚ä¼˜åŒ–å™ªå£°è°ƒåº¦æˆ–ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨æå‡å®¡ç¾è´¨é‡æ–¹é¢æ•ˆæœæœ‰é™ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸‰ç‚¹è§è§£æ¥æå‡å®¡ç¾è´¨é‡ï¼šæ”¹è¿›å™ªå£°è°ƒåº¦ä»¥å¢å¼ºé¢œè‰²å’Œå¯¹æ¯”åº¦ï¼Œæ„å»ºå¹³è¡¡çš„åˆ†æ¡¶æ•°æ®é›†ä»¥æ”¯æŒä¸åŒå®½é«˜æ¯”çš„ç”Ÿæˆï¼Œä»¥åŠåˆ©ç”¨äººç±»åé¦ˆæ¥å¯¹é½æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨å¹¿æ³›çš„åˆ†æå’Œå®éªŒä¸­ï¼ŒPlayground v2.5 åœ¨å„ç§æ¡ä»¶å’Œå®½é«˜æ¯”ä¸‹å±•ç¤ºäº†æœ€å…ˆè¿›çš„å®¡ç¾è´¨é‡ï¼Œä¼˜äº SDXLã€Playground v2 ç­‰å¼€æºæ¨¡å‹å’Œ DALLÂ·E 3ã€Midjourney v5.2 ç­‰é—­æºå•†ä¸šç³»ç»Ÿã€‚</li></ol><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰æ”¹è¿›å™ªå£°è°ƒåº¦ï¼šé‡‡ç”¨ EDM æ¡†æ¶å’Œæ›´å™ªå£°çš„è°ƒåº¦æ–¹å¼ï¼Œå¢å¼ºå›¾åƒè‰²å½©å’Œå¯¹æ¯”åº¦ã€‚ï¼ˆ2ï¼‰å¹³è¡¡åˆ†æ¡¶æ•°æ®é›†ï¼šæ„å»ºåŒ…å«ä¸åŒå®½é«˜æ¯”å›¾åƒçš„åˆ†æ¡¶æ•°æ®é›†ï¼Œæ”¯æŒå¤šç§å®½é«˜æ¯”çš„ç”Ÿæˆã€‚ï¼ˆ3ï¼‰åˆ©ç”¨äººç±»åé¦ˆï¼šä½¿ç”¨äººç±»è¯„çº§ç³»ç»Ÿè‡ªåŠ¨ç­›é€‰é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨è¿­ä»£è®­ç»ƒæ–¹æ³•ï¼Œæ ¹æ®äººç±»åå¥½å¯¹é½æ¨¡å‹è¾“å‡ºã€‚</p><ol><li>æ€»ç»“ï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡º Playground v2.5ï¼Œè¯¥æ¨¡å‹é€šè¿‡æ”¹è¿›å™ªå£°è°ƒåº¦ã€æ„å»ºå¹³è¡¡çš„åˆ†æ¡¶æ•°æ®é›†å’Œåˆ©ç”¨äººç±»åé¦ˆç­‰ä¸‰ç‚¹è§è§£ï¼Œæå‡äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å®¡ç¾è´¨é‡ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§æ–°çš„å™ªå£°è°ƒåº¦æ¡†æ¶ï¼Œå¢å¼ºäº†å›¾åƒçš„è‰²å½©å’Œå¯¹æ¯”åº¦ã€‚</li><li>æ„å»ºäº†ä¸€ä¸ªåŒ…å«ä¸åŒå®½é«˜æ¯”å›¾åƒçš„åˆ†æ¡¶æ•°æ®é›†ï¼Œæ”¯æŒå¤šç§å®½é«˜æ¯”çš„ç”Ÿæˆã€‚</li><li>åˆ©ç”¨äººç±»è¯„çº§ç³»ç»Ÿè‡ªåŠ¨ç­›é€‰é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨è¿­ä»£è®­ç»ƒæ–¹æ³•ï¼Œæ ¹æ®äººç±»åå¥½å¯¹é½æ¨¡å‹è¾“å‡ºã€‚æ€§èƒ½ï¼š</li><li>åœ¨å¹¿æ³›çš„åˆ†æå’Œå®éªŒä¸­ï¼ŒPlayground v2.5 åœ¨å„ç§æ¡ä»¶å’Œå®½é«˜æ¯”ä¸‹å±•ç¤ºäº†æœ€å…ˆè¿›çš„å®¡ç¾è´¨é‡ï¼Œä¼˜äºå…¶ä»–å¼€æºå’Œé—­æºæ¨¡å‹ã€‚</li><li>Playground v2.5 åœ¨å¢å¼ºå›¾åƒè‰²å½©å’Œå¯¹æ¯”åº¦ã€ç”Ÿæˆä¸åŒå®½é«˜æ¯”çš„é«˜è´¨é‡å›¾åƒä»¥åŠå¯¹é½æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆäººç‰©å›¾åƒçš„ç²¾ç»†ç»†èŠ‚æ–¹é¢ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ¨¡å‹å·²å¼€æºï¼Œç”¨æˆ·å¯ä»¥åœ¨ Playground äº§å“ç½‘ç«™ä¸Šä½¿ç”¨ã€‚</li><li>Playground v2.5 çš„æƒé‡å·²åœ¨ Hugging Face ä¸Šå¼€æºã€‚</li><li>Playground å°†ç»§ç»­æä¾›æ‰©å±•ï¼Œä»¥ä¾¿åœ¨ A1111 å’Œ ComfyUI ç­‰æµè¡Œç¤¾åŒºå·¥å…·ä¸­ä½¿ç”¨ Playground v2.5ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-b9ee43af14ab727bc293d7a249e6d156.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3ff95dbf16b9c2e734124d2c99954b6c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-b62a3df3bac0ff8ef7d20dfeccb0f6b4.jpg" align="middle"><img src="https://picx.zhimg.com/v2-869a1d35fa675595c5662a91b215c366.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-226f377d76bcd81c0c005d4e513c6f81.jpg" align="middle"></details><h2 id="SAM-DiffSR-Structure-Modulated-Diffusion-Model-for-Image-Super-Resolution"><a href="#SAM-DiffSR-Structure-Modulated-Diffusion-Model-for-Image-Super-Resolution" class="headerlink" title="SAM-DiffSR: Structure-Modulated Diffusion Model for Image   Super-Resolution"></a>SAM-DiffSR: Structure-Modulated Diffusion Model for Image   Super-Resolution</h2><p><strong>Authors:Chengcheng Wang, Zhiwei Hao, Yehui Tang, Jianyuan Guo, Yujie Yang, Kai Han, Yunhe Wang</strong></p><p>Diffusion-based super-resolution (SR) models have recently garnered significant attention due to their potent restoration capabilities. But conventional diffusion models perform noise sampling from a single distribution, constraining their ability to handle real-world scenes and complex textures across semantic regions. With the success of segment anything model (SAM), generating sufficiently fine-grained region masks can enhance the detail recovery of diffusion-based SR model. However, directly integrating SAM into SR models will result in much higher computational cost. In this paper, we propose the SAM-DiffSR model, which can utilize the fine-grained structure information from SAM in the process of sampling noise to improve the image quality without additional computational cost during inference. In the process of training, we encode structural position information into the segmentation mask from SAM. Then the encoded mask is integrated into the forward diffusion process by modulating it to the sampled noise. This adjustment allows us to independently adapt the noise mean within each corresponding segmentation area. The diffusion model is trained to estimate this modulated noise. Crucially, our proposed framework does NOT change the reverse diffusion process and does NOT require SAM at inference. Experimental results demonstrate the effectiveness of our proposed method, showcasing superior performance in suppressing artifacts, and surpassing existing diffusion-based methods by 0.74 dB at the maximum in terms of PSNR on DIV2K dataset. The code and dataset are available at <a href="https://github.com/lose4578/SAM-DiffSR">https://github.com/lose4578/SAM-DiffSR</a>. </p><p><a href="http://arxiv.org/abs/2402.17133v1">PDF</a> </p><p><strong>Summary</strong><br>åŸºäºæ‰©æ•£çš„è¶…åˆ†è¾¨ç‡æ¨¡å‹ä¸­ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„SAM-DiffSRæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨SAMçš„ç²¾ç»†ç»“æ„ä¿¡æ¯åœ¨é‡‡æ ·å™ªå£°çš„è¿‡ç¨‹ä¸­æ¥æ”¹å–„æœ€ç»ˆå›¾åƒè´¨é‡ï¼Œè€Œæ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦SAMï¼Œæœ‰æ•ˆé™ä½äº†è®¡ç®—æˆæœ¬ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æå‡ºäº†ä¸€ç§SAM-DiffSRæ¨¡å‹ï¼Œå¯ä»¥åˆ©ç”¨SAMçš„ç²¾ç»†ç»“æ„ä¿¡æ¯æ¥æ”¹å–„å›¾åƒè´¨é‡ã€‚</li><li>SAM-DiffSRæ¨¡å‹é€šè¿‡å°†ç¼–ç çš„æ©ç æ•´åˆåˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œåœ¨é‡‡æ ·å™ªå£°ä¹‹å‰è¿›è¡Œè°ƒæ•´ã€‚</li><li>è¯¥è°ƒæ•´å…è®¸ç‹¬ç«‹è°ƒæ•´æ¯ä¸ªå¯¹åº”åˆ†å‰²åŒºåŸŸå†…çš„å™ªå£°å‡å€¼ã€‚</li><li>æ‰©æ•£æ¨¡å‹è¢«è®­ç»ƒæ¥ä¼°è®¡è¿™ç§è°ƒåˆ¶çš„å™ªå£°ã€‚</li><li>æ‰€æå‡ºçš„æ–¹æ³•ä¸æ”¹å˜åå‘æ‰©æ•£è¿‡ç¨‹ï¼Œå¹¶ä¸”åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦SAMã€‚</li><li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°æŠ‘åˆ¶äº†ä¼ªå½±ï¼Œåœ¨DIV2Kæ•°æ®é›†ä¸Šä»¥PSNRæŒ‡æ ‡è¶…è¶Šäº†ç°æœ‰çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•0.74 dBã€‚</li><li>ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a href="https://github.com/lose4578/SAM-DiffSRè·å¾—ã€‚">https://github.com/lose4578/SAM-DiffSRè·å¾—ã€‚</a></li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šSAM-DiffSRï¼šç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡çš„ç»“æ„è°ƒåˆ¶æ‰©æ•£æ¨¡å‹</li><li>ä½œè€…ï¼šChengcheng Wangã€Zhiwei Haoã€Yehui Tangã€Jianyuan Guoã€Yujie Yangã€Kai Hanã€Yunhe Wang</li><li>å•ä½ï¼šåä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤</li><li>å…³é”®è¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡ã€æ‰©æ•£æ¨¡å‹ã€ç»“æ„è°ƒåˆ¶</li><li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17133   Githubï¼šhttps://github.com/lose4578/SAM-DiffSR</li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š   æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹ä»å•ä¸€åˆ†å¸ƒä¸­è¿›è¡Œå™ªå£°é‡‡æ ·ï¼Œé™åˆ¶äº†å…¶å¤„ç†çœŸå®åœºæ™¯å’Œè·¨è¯­ä¹‰åŒºåŸŸå¤æ‚çº¹ç†çš„èƒ½åŠ›ã€‚</li></ol><p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š   Segment Anything Modelï¼ˆSAMï¼‰èƒ½ç”Ÿæˆè¶³å¤Ÿç²¾ç»†çš„åŒºåŸŸæ©ç ï¼Œå¢å¼ºæ‰©æ•£æ¨¡å‹çš„ç»†èŠ‚æ¢å¤èƒ½åŠ›ã€‚ä½†ç›´æ¥å°† SAM é›†æˆåˆ° SR æ¨¡å‹ä¸­ä¼šå¤§å¹…å¢åŠ è®¡ç®—æˆæœ¬ã€‚</p><p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š   æå‡º SAM-DiffSR æ¨¡å‹ï¼Œåœ¨å™ªå£°é‡‡æ ·è¿‡ç¨‹ä¸­åˆ©ç”¨ SAM çš„ç²¾ç»†ç»“æ„ä¿¡æ¯ï¼Œåœ¨ä¸å¢åŠ æ¨ç†è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹æé«˜å›¾åƒè´¨é‡ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå°†ç»“æ„ä½ç½®ä¿¡æ¯ç¼–ç åˆ° SAM çš„åˆ†å‰²æ©ç ä¸­ã€‚ç„¶åå°†ç¼–ç åçš„æ©ç é›†æˆåˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œå°†å…¶è°ƒåˆ¶åˆ°é‡‡æ ·çš„å™ªå£°ä¸­ã€‚è¿™ç§è°ƒæ•´å…è®¸åœ¨æ¯ä¸ªå¯¹åº”çš„åˆ†å‰²åŒºåŸŸå†…ç‹¬ç«‹è°ƒæ•´å™ªå£°å‡å€¼ã€‚æ‰©æ•£æ¨¡å‹è¢«è®­ç»ƒæ¥ä¼°è®¡è¿™ç§è°ƒåˆ¶çš„å™ªå£°ã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š   å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•æœ‰æ•ˆï¼Œåœ¨æŠ‘åˆ¶ä¼ªå½±æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨ DIV2K æ•°æ®é›†ä¸Šä»¥ PSNR è¡¡é‡ï¼Œæ¯”ç°æœ‰çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æé«˜äº† 0.74dBã€‚è¯¥æ–¹æ³•çš„æ€§èƒ½æ”¯æŒå…¶ç›®æ ‡ã€‚</p><p><strong>Methodsï¼š</strong></p><p>(1) åˆ©ç”¨ SegmentAnythingModelï¼ˆSAMï¼‰ç”Ÿæˆç²¾ç»†çš„åŒºåŸŸæ©ç ï¼Œç¼–ç ç»“æ„ä½ç½®ä¿¡æ¯ã€‚</p><p>(2) å°†ç¼–ç åçš„æ©ç é›†æˆåˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œè°ƒåˆ¶é‡‡æ ·çš„å™ªå£°ã€‚</p><p>(3) è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¼°è®¡è°ƒåˆ¶çš„å™ªå£°ï¼Œä»è€Œåœ¨æ¯ä¸ªåˆ†å‰²åŒºåŸŸå†…ç‹¬ç«‹è°ƒæ•´å™ªå£°å‡å€¼ã€‚</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é‡ç‚¹é€šè¿‡é›†æˆ SAMï¼Œå¢å¼ºåŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡æ¨¡å‹çš„ç»“æ„å±‚æ¬¡ä¿¡æ¯æ¢å¤èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåä¸º SAM-DiffSR çš„æ¡†æ¶ï¼Œå®ƒæ¶‰åŠå°†ç»“æ„ä½ç½®ä¿¡æ¯çº³å…¥ SAM ç”Ÿæˆçš„æ©ç ï¼Œç„¶ååœ¨æ­£å‘æ‰©æ•£è¿‡ç¨‹ä¸­å°†å…¶æ·»åŠ åˆ°é‡‡æ ·çš„å™ªå£°ä¸­ã€‚æ­¤æ“ä½œå•ç‹¬è°ƒèŠ‚æ¯ä¸ªç›¸åº”åˆ†å‰²åŒºåŸŸä¸­å™ªå£°çš„å‡å€¼ï¼Œä»è€Œå°†ç»“æ„å±‚æ¬¡çŸ¥è¯†æ³¨å…¥æ‰©æ•£æ¨¡å‹ã€‚é€šè¿‡é‡‡ç”¨è¿™ç§æ–¹æ³•ï¼Œè®­ç»ƒåçš„æ¨¡å‹åœ¨æ¢å¤ç»“æ„ç»†èŠ‚å’ŒæŠ‘åˆ¶å›¾åƒä¼ªå½±æ–¹é¢è¡¨ç°å‡ºæ”¹è¿›ï¼Œè€Œæ— éœ€äº§ç”Ÿä»»ä½•é¢å¤–çš„æ¨ç†æˆæœ¬ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§é€šè¿‡åœ¨å¸¸ç”¨çš„å›¾åƒè¶…åˆ†è¾¨ç‡åŸºå‡†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒå¾—åˆ°è¯å®ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåˆ©ç”¨ SAM æ³¨å…¥ç»“æ„ä¿¡æ¯ï¼Œå¢å¼ºæ‰©æ•£æ¨¡å‹çš„ç»“æ„æ¢å¤èƒ½åŠ›ï¼›æ€§èƒ½ï¼šåœ¨æŠ‘åˆ¶ä¼ªå½±å’Œæ¢å¤ç»“æ„ç»†èŠ‚æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼›å·¥ä½œé‡ï¼šæ¨ç†æˆæœ¬ä¸åŸºçº¿æ¨¡å‹ç›¸å½“ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-9a754ccd89139d7dc6a576434e6b119e.jpg" align="middle"><img src="https://picx.zhimg.com/v2-0906797fab629c359270ce611fcb26d4.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-66893d51d835b7965b76fb168b66db51.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f1f36de01723e09ebef0661e0e152ae2.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-9bca3bdea09d0b0b3c4c6b041a3c1758.jpg" align="middle"></details><h2 id="Cross-Modal-Contextualized-Diffusion-Models-for-Text-Guided-Visual-Generation-and-Editing"><a href="#Cross-Modal-Contextualized-Diffusion-Models-for-Text-Guided-Visual-Generation-and-Editing" class="headerlink" title="Cross-Modal Contextualized Diffusion Models for Text-Guided Visual   Generation and Editing"></a>Cross-Modal Contextualized Diffusion Models for Text-Guided Visual   Generation and Editing</h2><p><strong>Authors:Ling Yang, Zhilong Zhang, Zhaochen Yu, Jingwei Liu, Minkai Xu, Stefano Ermon, Bin Cui</strong></p><p>Conditional diffusion models have exhibited superior performance in high-fidelity text-guided visual generation and editing. Nevertheless, prevailing text-guided visual diffusion models primarily focus on incorporating text-visual relationships exclusively into the reverse process, often disregarding their relevance in the forward process. This inconsistency between forward and reverse processes may limit the precise conveyance of textual semantics in visual synthesis results. To address this issue, we propose a novel and general contextualized diffusion model (ContextDiff) by incorporating the cross-modal context encompassing interactions and alignments between text condition and visual sample into forward and reverse processes. We propagate this context to all timesteps in the two processes to adapt their trajectories, thereby facilitating cross-modal conditional modeling. We generalize our contextualized diffusion to both DDPMs and DDIMs with theoretical derivations, and demonstrate the effectiveness of our model in evaluations with two challenging tasks: text-to-image generation, and text-to-video editing. In each task, our ContextDiff achieves new state-of-the-art performance, significantly enhancing the semantic alignment between text condition and generated samples, as evidenced by quantitative and qualitative evaluations. Our code is available at <a href="https://github.com/YangLing0818/ContextDiff">https://github.com/YangLing0818/ContextDiff</a> </p><p><a href="http://arxiv.org/abs/2402.16627v1">PDF</a> ICLR 2024. Project: <a href="https://github.com/YangLing0818/ContextDiff">https://github.com/YangLing0818/ContextDiff</a></p><p><strong>Summary</strong><br>ä¸Šä¸‹æ–‡æ‰©æ•£æ¨¡å‹é€šè¿‡åœ¨æ‰©æ•£æ­£åè¿‡ç¨‹ä¸­åŠ å…¥æ–‡æœ¬å¯è§†å…³ç³»ï¼Œæå‡äº†æ–‡æœ¬å¼•å¯¼å¯è§†åŒ–ç”Ÿæˆå’Œç¼–è¾‘çš„è¯­ä¹‰å¯¹é½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬å¼•å¯¼å¯è§†åŒ–ç”Ÿæˆå’Œç¼–è¾‘ä¸­è¡¨ç°ä¼˜è¶Šã€‚</li><li>ä¼ ç»Ÿæ¨¡å‹åªå°†æ–‡æœ¬å¯è§†å…³ç³»èå…¥åå‘è¿‡ç¨‹ï¼Œå¿½ç•¥äº†æ­£å‘è¿‡ç¨‹çš„å…³è”æ€§ã€‚</li><li>æ­£åè¿‡ç¨‹çš„ä¸ä¸€è‡´æ€§é™åˆ¶äº†æ–‡æœ¬è¯­ä¹‰åœ¨å¯è§†åŒ–åˆæˆç»“æœä¸­çš„ä¼ é€’ç²¾åº¦ã€‚</li><li>è¯­ä¹‰æ‰©æ•£æ¨¡å‹é€šè¿‡å°†æ–‡æœ¬æ¡ä»¶å’Œå¯è§†æ ·æœ¬ä¹‹é—´çš„äº¤äº’å’Œå¯¹é½çº³å…¥æ­£åè¿‡ç¨‹ï¼Œæ”¹å–„äº†è¿™ç§ä¸ä¸€è‡´æ€§ã€‚</li><li>æ”¹è¿›é€‚ç”¨äº DDPM å’Œ DDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨ç†å¾—åˆ°è¯æ˜ã€‚</li><li>åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸­ï¼Œè¯­ä¹‰æ‰©æ•£æ¨¡å‹å‡è¾¾åˆ°æ–°çš„æœ€ä½³æ€§èƒ½ã€‚</li><li>å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜è¯­ä¹‰æ‰©æ•£æ¨¡å‹æ˜¾è‘—æå‡äº†æ–‡æœ¬æ¡ä»¶å’Œç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>æ ‡é¢˜ï¼šè·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ç”¨äºæ–‡æœ¬å¼•å¯¼çš„è§†è§‰ç”Ÿæˆå’Œç¼–è¾‘</li><li>ä½œè€…ï¼šæ¨å‡Œã€å¼ å¿—é¾™ã€äºå…†å®¸ã€åˆ˜æ™¯ä¼Ÿã€å¾æ˜å‡¯ã€Stefano Ermonã€å´”æ–Œ</li><li>éš¶å±ï¼šåŒ—äº¬å¤§å­¦</li><li>å…³é”®è¯ï¼šæ–‡æœ¬å¼•å¯¼è§†è§‰ç”Ÿæˆã€æ–‡æœ¬å¼•å¯¼è§†é¢‘ç¼–è¾‘ã€æ‰©æ•£æ¨¡å‹ã€è¯­å¢ƒåŒ–</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.16627   Github ä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼š   (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬å¼•å¯¼è§†è§‰ç”Ÿæˆå’Œç¼–è¾‘é¢†åŸŸè¡¨ç°ä¼˜å¼‚ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å°†æ–‡æœ¬-è§†è§‰å…³ç³»èå…¥é€†è¿‡ç¨‹ï¼Œå¿½è§†äº†å…¶åœ¨å‰å‘è¿‡ç¨‹ä¸­çš„ç›¸å…³æ€§ï¼Œå¯¼è‡´æ–‡æœ¬è¯­ä¹‰åœ¨è§†è§‰åˆæˆç»“æœä¸­çš„ç²¾ç¡®ä¼ è¾¾å—åˆ°é™åˆ¶ã€‚   (2)ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š</p><ul><li>å¿½ç•¥äº†æ–‡æœ¬-è§†è§‰å…³ç³»åœ¨å‰å‘è¿‡ç¨‹ä¸­çš„ä½œç”¨ï¼Œå¯¼è‡´æ–‡æœ¬è¯­ä¹‰åœ¨è§†è§‰åˆæˆç»“æœä¸­çš„ç²¾ç¡®ä¼ è¾¾å—é™ã€‚</li><li>ç¼ºä¹ä¸€ç§é€šç”¨çš„è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼Œæ— æ³•åŒæ—¶å¤„ç†æ–‡æœ¬å¼•å¯¼å›¾åƒå’Œè§†é¢‘ç”Ÿæˆ/ç¼–è¾‘ä»»åŠ¡ã€‚   (3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼ˆCONTEXTDIFFï¼‰ï¼Œé€šè¿‡å°†è·¨æ¨¡æ€è¯­å¢ƒï¼ˆåŒ…å«æ–‡æœ¬æ¡ä»¶å’Œè§†è§‰æ ·æœ¬ä¹‹é—´çš„äº¤äº’å’Œå¯¹é½ï¼‰èå…¥å‰å‘å’Œé€†è¿‡ç¨‹æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œå°†è¯¥è¯­å¢ƒä¼ æ’­åˆ°ä¸¤ä¸ªè¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ—¶é—´æ­¥ï¼Œä»¥é€‚åº”å®ƒä»¬çš„è½¨è¿¹ï¼Œä»è€Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ã€‚åŒæ—¶ï¼Œå°†è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹æ¨å¹¿åˆ° DDPM å’Œ DDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚   (4)ï¼šä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šï¼ŒCONTEXTDIFF å‡å–å¾—äº†æ–°çš„ SOTA æ€§èƒ½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ–‡æœ¬æ¡ä»¶ä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼Œå®šé‡å’Œå®šæ€§è¯„ä¼°å‡è¯æ˜äº†è¿™ä¸€ç‚¹ã€‚</li></ul></li><li><p>Methods:(1): æå‡ºè·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼ˆCONTEXTDIFFï¼‰ï¼Œå°†è·¨æ¨¡æ€è¯­å¢ƒï¼ˆåŒ…å«æ–‡æœ¬æ¡ä»¶å’Œè§†è§‰æ ·æœ¬ä¹‹é—´çš„äº¤äº’å’Œå¯¹é½ï¼‰èå…¥å‰å‘å’Œé€†è¿‡ç¨‹ï¼Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ï¼›(2): å°†è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹æ¨å¹¿åˆ°DDPMå’ŒDDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ï¼›(3): åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä¸¤ä¸ªä»»åŠ¡ä¸Šï¼ŒCONTEXTDIFFå‡å–å¾—äº†æ–°çš„SOTAæ€§èƒ½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ–‡æœ¬æ¡ä»¶ä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆCONTEXTDIFFï¼‰ï¼Œé€šè¿‡å°†è·¨æ¨¡æ€è¯­å¢ƒä¼ æ’­åˆ°æ‰©æ•£å’Œé€†è¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ—¶é—´æ­¥ï¼Œå¹¶é€‚åº”å®ƒä»¬çš„è½¨è¿¹ï¼Œä»è€Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ã€‚æˆ‘ä»¬å°†ä¸Šä¸‹æ–‡åŒ–è½¨è¿¹é€‚é…å™¨æ¨å¹¿åˆ° DDPM å’Œ DDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘è¿™ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šï¼ŒCONTEXTDIFF å§‹ç»ˆè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¸¤é¡¹ä»»åŠ¡çš„å¹¿æ³›å®šé‡å’Œå®šæ€§ç»“æœè¯æ˜äº†æˆ‘ä»¬æå‡ºçš„è·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„è·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å°†è·¨æ¨¡æ€è¯­å¢ƒèå…¥æ‰©æ•£å’Œé€†è¿‡ç¨‹ï¼Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ã€‚æ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä¸¤ä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ–‡æœ¬æ¡ä»¶ä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚å·¥ä½œé‡ï¼šå·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦å¯¹æ‰©æ•£æ¨¡å‹å’Œè·¨æ¨¡æ€è¯­å¢ƒåŒ–è¿›è¡Œæ·±å…¥ç†è§£ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-0bc30cb1ebccfebfcc1ffd4ee246c26b.jpg" align="middle"><img src="https://picx.zhimg.com/v2-64adb5f655a12b089618a5496f3cd332.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-f01bc8ec645d09757f45be018ce1fe96.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-8a622ae5ed900b07d2994967a2269c23.jpg" align="middle"><img src="https://pica.zhimg.com/v2-0d264d770c3a4265052827f62ee48f0b.jpg" align="middle"></details><h2 id="Placing-Objects-in-Context-via-Inpainting-for-Out-of-distribution-Segmentation"><a href="#Placing-Objects-in-Context-via-Inpainting-for-Out-of-distribution-Segmentation" class="headerlink" title="Placing Objects in Context via Inpainting for Out-of-distribution   Segmentation"></a>Placing Objects in Context via Inpainting for Out-of-distribution   Segmentation</h2><p><strong>Authors:Pau de Jorge, Riccardo Volpi, Puneet K. Dokania, Philip H. S. Torr, Gregory Rogez</strong></p><p>When deploying a semantic segmentation model into the real world, it will inevitably be confronted with semantic classes unseen during training. Thus, to safely deploy such systems, it is crucial to accurately evaluate and improve their anomaly segmentation capabilities. However, acquiring and labelling semantic segmentation data is expensive and unanticipated conditions are long-tail and potentially hazardous. Indeed, existing anomaly segmentation datasets capture a limited number of anomalies, lack realism or have strong domain shifts. In this paper, we propose the Placing Objects in Context (POC) pipeline to realistically add any object into any image via diffusion models. POC can be used to easily extend any dataset with an arbitrary number of objects. In our experiments, we present different anomaly segmentation datasets based on POC-generated data and show that POC can improve the performance of recent state-of-the-art anomaly fine-tuning methods in several standardized benchmarks. POC is also effective to learn new classes. For example, we use it to edit Cityscapes samples by adding a subset of Pascal classes and show that models trained on such data achieve comparable performance to the Pascal-trained baseline. This corroborates the low sim-to-real gap of models trained on POC-generated images. </p><p><a href="http://arxiv.org/abs/2402.16392v1">PDF</a> </p><p><strong>Summary</strong><br>ä½¿ç”¨æ‰©æ•£æ¨¡å‹å°†å¯¹è±¡æ’å…¥ä¸Šä¸‹æ–‡(POC)ç®¡é“ï¼Œå¯çœŸå®åœ°å‘å›¾åƒä¸­æ·»åŠ ä»»ä½•å¯¹è±¡ï¼Œæœ‰æ•ˆæ‰©å±•æ•°æ®é›†å’Œæ”¹å–„å¼‚å¸¸åˆ†å‰²æ€§èƒ½ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>åˆ©ç”¨æ‰©æ•£æ¨¡å‹æ„å»ºPOCç®¡é“ï¼Œå¯å‘å›¾åƒä¸­çœŸå®åœ°æ·»åŠ ä»»æ„å¯¹è±¡ã€‚</li><li>POCèƒ½è½»æ¾æ‰©å±•æ•°æ®é›†ï¼Œæ·»åŠ ä»»æ„æ•°é‡çš„å¯¹è±¡ã€‚</li><li>POCç”Ÿæˆçš„å¼‚å¸¸åˆ†å‰²æ•°æ®é›†æ¯”ç°æœ‰æ•°æ®é›†æ›´çœŸå®ã€å…¨é¢ã€‚</li><li>POCèƒ½æå‡æœ€æ–°å¼‚å¸¸ç²¾è°ƒæ–¹æ³•åœ¨åŸºå‡†æµ‹è¯•ä¸­çš„æ€§èƒ½ã€‚</li><li>POCå¯ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ï¼Œå¦‚å°†Pascalç±»åˆ«æ·»åŠ åˆ°Cityscapesã€‚</li><li>åŸºäºPOCç”Ÿæˆå›¾åƒè®­ç»ƒçš„æ¨¡å‹ï¼Œå…¶ä»¿çœŸåˆ°çœŸå®å·®è·ä½ã€‚</li><li>POCç®¡é“èƒ½å¤Ÿæé«˜æ¨¡å‹åº”å¯¹æœªè§è¯­ä¹‰ç±»åˆ«çš„èƒ½åŠ›ï¼Œå¢å¼ºå¼‚å¸¸åˆ†å‰²æ€§èƒ½ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><p>1.æ ‡é¢˜ï¼šé€šè¿‡å›¾åƒä¿®å¤å°†å¯¹è±¡ç½®äºä¸Šä¸‹æ–‡ä¸­ä»¥è¿›è¡Œåˆ†å¸ƒå¤–åˆ†å‰²2.ä½œè€…ï¼šPaude Jorgeâ€ , Riccardo Volpiâ€ , Puneet K. Dokaniaâ€¡, Philip H.S. Torrâ€¡, GrÃ©gory Rogezâ€ 3.æ‰€å±æœºæ„ï¼šNAVERLABS æ¬§æ´²ï¼Œç‰›æ´¥å¤§å­¦4.å…³é”®è¯ï¼šå¼‚å¸¸åˆ†å‰²ã€åˆ†å¸ƒå¤–æ£€æµ‹ã€å›¾åƒä¿®å¤ã€è¯­ä¹‰åˆ†å‰²ã€å¼€æ”¾è¯æ±‡åˆ†å‰²5.é“¾æ¥ï¼šhttps://github.com/naver/poc6.æ‘˜è¦ï¼š(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šåœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²è¯­ä¹‰åˆ†å‰²æ¨¡å‹æ—¶ï¼Œæ¨¡å‹ä¸å¯é¿å…åœ°ä¼šé‡åˆ°è®­ç»ƒæœŸé—´æœªè§è¿‡çš„è¯­ä¹‰ç±»åˆ«ã€‚å› æ­¤ï¼Œä¸ºäº†å®‰å…¨åœ°éƒ¨ç½²æ­¤ç±»ç³»ç»Ÿï¼Œå‡†ç¡®è¯„ä¼°å’Œæé«˜å…¶å¼‚å¸¸åˆ†å‰²èƒ½åŠ›è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè·å–å’Œæ ‡è®°è¯­ä¹‰åˆ†å‰²æ•°æ®ä»£ä»·é«˜æ˜‚ï¼Œè€Œä¸”æ„å¤–æƒ…å†µæ˜¯é•¿å°¾ä¸”å¯èƒ½å…·æœ‰å±é™©æ€§ã€‚å®é™…ä¸Šï¼Œç°æœ‰çš„å¼‚å¸¸åˆ†å‰²æ•°æ®é›†æ•è·çš„å¼‚å¸¸æ•°é‡æœ‰é™ï¼Œç¼ºä¹çœŸå®æ€§æˆ–å…·æœ‰å¾ˆå¼ºçš„åŸŸåç§»ã€‚(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¾ç½®å¯¹è±¡åœ¨ä¸Šä¸‹æ–‡ï¼ˆPOCï¼‰ç®¡é“ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å°†ä»»ä½•å¯¹è±¡ç°å®åœ°æ·»åŠ åˆ°ä»»ä½•å›¾åƒä¸­ã€‚POC å¯ç”¨äºè½»æ¾åœ°ä½¿ç”¨ä»»æ„æ•°é‡çš„å¯¹è±¡æ‰©å±•ä»»ä½•æ•°æ®é›†ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäº POC ç”Ÿæˆçš„ä¸åŒå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è¡¨æ˜ POC å¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚POC è¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å®ƒé€šè¿‡æ·»åŠ  Pascal ç±»åˆ«çš„å­é›†æ¥ç¼–è¾‘ Cityscapes æ ·æœ¬ï¼Œå¹¶è¡¨æ˜åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸ Pascal è®­ç»ƒçš„åŸºçº¿å®ç°äº†ç›¸å½“çš„æ€§èƒ½ã€‚è¿™è¯å®äº†åœ¨ POC ç”Ÿæˆçš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ä½æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚(3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šPOC ç®¡é“å»ºç«‹åœ¨å›¾åƒä¿®å¤å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ä¹‹ä¸Šï¼Œå°†ä»»æ„å¯¹è±¡ç°å®åœ°æ’å…¥å›¾åƒä¸­ã€‚ä¿®æ”¹åçš„å›¾åƒå’Œæ©ç å¯ç”¨äºä¸åŒçš„ä»»åŠ¡ã€‚(4)ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¯¥æ€§èƒ½æ˜¯å¦èƒ½æ”¯æ’‘å…¶ç›®æ ‡ï¼šåœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜åœ¨ POC ç”Ÿæˆçš„å›¾åƒä¸Šè¿›è¡Œå¾®è°ƒå¯ä»¥æ˜¾ç€æé«˜æœ€å…ˆè¿›çš„å¼‚å¸¸åˆ†å‰²æ–¹æ³•çš„æ€§èƒ½â€”â€”ä¼˜äºé€šè¿‡æ ‡å‡†åšæ³•ï¼ˆæ‹¼æ¥ COCO å¯¹è±¡ï¼‰è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†ä¸‰ä¸ªåŸºäº Cityscapes å’Œå…¶ä»–ä¸¤ä¸ªè‡ªåŠ¨é©¾é©¶æ•°æ®é›†çš„ POC ç”Ÿæˆçš„è¯„ä¼°é›†ï¼Œå¹¶åœ¨å…¶ä¸Šå¯¹ä¸åŒçš„å¼‚å¸¸åˆ†å‰²æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ˆæœ‰å…³ç»“æœçš„ç¬¬ä¸€çœ¼ï¼Œè¯·å‚è§å›¾ 1ï¼‰ã€‚æœ€åï¼Œç”±äº POC å¯ä»¥æ·»åŠ ä»»æ„å¯¹è±¡ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å®ƒå¯ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨ç‰©ç±»åˆ«å¢å¼º Cityscapes å›¾åƒå¯¼è‡´ Pascal æµ‹è¯•é›†ä¸Šçš„ 93.14mIoUï¼ˆè€ƒè™‘ç›¸åŒçš„ç±»åˆ«ï¼‰ï¼Œè€Œç›´æ¥åœ¨ Pascal ä¸Šè®­ç»ƒäº§ç”Ÿ 94.75â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨ POC ç¼–è¾‘çš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹äº§ç”Ÿäº†ç›¸å½“å°çš„æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚</p><ol><li>æ–¹æ³•ï¼š(1) POCç®¡é“ï¼šPOCç®¡é“ç”±å›¾åƒä¿®å¤æ¨¡å‹å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç»„æˆã€‚å›¾åƒä¿®å¤æ¨¡å‹ç”¨äºå°†å¯¹è±¡ç°å®åœ°æ’å…¥å›¾åƒä¸­ï¼Œè€Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç”¨äºä¸ºæ’å…¥çš„å¯¹è±¡ç”Ÿæˆæ©ç ã€‚ä¿®æ”¹åçš„å›¾åƒå’Œæ©ç å¯ç”¨äºä¸åŒçš„ä»»åŠ¡ï¼Œä¾‹å¦‚å¼‚å¸¸åˆ†å‰²ã€‚(2) å¼‚å¸¸åˆ†å‰²å¾®è°ƒï¼šPOCç®¡é“å¯ç”¨äºç”Ÿæˆå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ã€‚åœ¨è¿™äº›æ•°æ®é›†ä¸Šå¾®è°ƒå¼‚å¸¸åˆ†å‰²æ¨¡å‹å¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œä¼˜äºé€šè¿‡æ ‡å‡†åšæ³•ï¼ˆæ‹¼æ¥COCOå¯¹è±¡ï¼‰è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚(3) å­¦ä¹ æ–°ç±»åˆ«ï¼šPOCç®¡é“è¿˜å¯ä»¥ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨ç‰©ç±»åˆ«å¢å¼ºCityscapeså›¾åƒå¯¼è‡´Pascalæµ‹è¯•é›†ä¸Šçš„93.14mIoUï¼ˆè€ƒè™‘ç›¸åŒçš„ç±»åˆ«ï¼‰ï¼Œè€Œç›´æ¥åœ¨Pascalä¸Šè®­ç»ƒäº§ç”Ÿ94.75â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨POCç¼–è¾‘çš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹äº§ç”Ÿäº†ç›¸å½“å°çš„æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚</li></ol><p>8.ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šxxxï¼›ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›8. ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¾ç½®å¯¹è±¡åœ¨ä¸Šä¸‹æ–‡ï¼ˆPOCï¼‰ç®¡é“ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å°†ä»»æ„å¯¹è±¡ç°å®åœ°æ·»åŠ åˆ°ä»»ä½•å›¾åƒä¸­ã€‚POCå¯ç”¨äºè½»æ¾åœ°ä½¿ç”¨ä»»æ„æ•°é‡çš„å¯¹è±¡æ‰©å±•ä»»ä½•æ•°æ®é›†ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäºPOCç”Ÿæˆçš„ä¸åŒå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è¡¨æ˜POCå¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚POCè¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å®ƒé€šè¿‡æ·»åŠ Pascalç±»åˆ«çš„å­é›†æ¥ç¼–è¾‘Cityscapesæ ·æœ¬ï¼Œå¹¶è¡¨æ˜åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸Pascalè®­ç»ƒçš„åŸºçº¿å®ç°äº†ç›¸å½“çš„æ€§èƒ½ã€‚è¿™è¯å®äº†åœ¨POCç”Ÿæˆçš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ä½æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š- æå‡ºäº†ä¸€ç§æ”¾ç½®å¯¹è±¡åœ¨ä¸Šä¸‹æ–‡ï¼ˆPOCï¼‰ç®¡é“ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å°†ä»»æ„å¯¹è±¡ç°å®åœ°æ·»åŠ åˆ°ä»»ä½•å›¾åƒä¸­ã€‚- POCå¯ç”¨äºè½»æ¾åœ°ä½¿ç”¨ä»»æ„æ•°é‡çš„å¯¹è±¡æ‰©å±•ä»»ä½•æ•°æ®é›†ã€‚- POCå¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚- POCè¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚æ€§èƒ½ï¼š- åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäºPOCç”Ÿæˆçš„ä¸åŒå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è¡¨æ˜POCå¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚- POCè¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å®ƒé€šè¿‡æ·»åŠ Pascalç±»åˆ«çš„å­é›†æ¥ç¼–è¾‘Cityscapesæ ·æœ¬ï¼Œå¹¶è¡¨æ˜åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸Pascalè®­ç»ƒçš„åŸºçº¿å®ç°äº†ç›¸å½“çš„æ€§èƒ½ã€‚è¿™è¯å®äº†åœ¨POCç”Ÿæˆçš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ä½æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚å·¥ä½œé‡ï¼š- POCç®¡é“ç”±å›¾åƒä¿®å¤æ¨¡å‹å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç»„æˆã€‚å›¾åƒä¿®å¤æ¨¡å‹ç”¨äºå°†å¯¹è±¡ç°å®åœ°æ’å…¥å›¾åƒä¸­ï¼Œè€Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç”¨äºä¸ºæ’å…¥çš„å¯¹è±¡ç”Ÿæˆæ©ç ã€‚- POCç®¡é“å¯ç”¨äºç”Ÿæˆå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ã€‚åœ¨è¿™äº›æ•°æ®é›†ä¸Šå¾®è°ƒå¼‚å¸¸åˆ†å‰²æ¨¡å‹å¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œä¼˜äºé€šè¿‡æ ‡å‡†åšæ³•ï¼ˆæ‹¼æ¥COCOå¯¹è±¡ï¼‰è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚- POCç®¡é“è¿˜å¯ä»¥ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨ç‰©ç±»åˆ«å¢å¼ºCityscapeså›¾åƒå¯¼è‡´Pascalæµ‹è¯•é›†ä¸Šçš„93.14mIoUï¼ˆè€ƒè™‘ç›¸åŒçš„ç±»åˆ«ï¼‰ï¼Œè€Œç›´æ¥åœ¨Pascalä¸Šè®­ç»ƒäº§ç”Ÿ94.75â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨POCç¼–è¾‘çš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹äº§ç”Ÿäº†ç›¸å½“å°çš„æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚</p><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-13236ee2bf286b59f5da0689a0363f64.jpg" align="middle"><img src="https://picx.zhimg.com/v2-dec0e216eb8083342215a3e4e8c1dc95.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d2067d81b02e8cd7fea592f12fcef21d.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-37aa0eb4c5f86ae9ed22c98b2703f9a5.jpg" align="middle"><img src="https://pica.zhimg.com/v2-84f58d6d1052332176a17f015aaa2d9f.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">Diffusion Models æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-29  Objective and Interpretable Breast Cosmesis Evaluation with Attention   Guided Denoising Diffusion Anomaly Detection Model</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="Diffusion Models" scheme="https://kedreamix.github.io/tags/Diffusion-Models/"/>
    
  </entry>
  
  <entry>
    <title>NeRF</title>
    <link href="https://kedreamix.github.io/2024/02/23/Paper/2024-02-23/NeRF/"/>
    <id>https://kedreamix.github.io/2024/02/23/Paper/2024-02-23/NeRF/</id>
    <published>2024-02-22T18:02:35.000Z</published>
    <updated>2024-02-22T18:02:35.955Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-02-23-æ›´æ–°"><a href="#2024-02-23-æ›´æ–°" class="headerlink" title="2024-02-23 æ›´æ–°"></a>2024-02-23 æ›´æ–°</h1><h2 id="Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting"><a href="#Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting" class="headerlink" title="Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting"></a>Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting</h2><p><strong>Authors:Joongho Jo, Hyeongwon Kim, Jongsun Park</strong></p><p>3D Gaussian splatting (3D-GS) is a new rendering approach that outperforms the neural radiance field (NeRF) in terms of both speed and image quality. 3D-GS represents 3D scenes by utilizing millions of 3D Gaussians and projects these Gaussians onto the 2D image plane for rendering. However, during the rendering process, a substantial number of unnecessary 3D Gaussians exist for the current view direction, resulting in significant computation costs associated with their identification. In this paper, we propose a computational reduction technique that quickly identifies unnecessary 3D Gaussians in real-time for rendering the current view without compromising image quality. This is accomplished through the offline clustering of 3D Gaussians that are close in distance, followed by the projection of these clusters onto a 2D image plane during runtime. Additionally, we analyze the bottleneck associated with the proposed technique when executed on GPUs and propose an efficient hardware architecture that seamlessly supports the proposed scheme. For the Mip-NeRF360 dataset, the proposed technique excludes 63% of 3D Gaussians on average before the 2D image projection, which reduces the overall rendering computation by almost 38.3% without sacrificing peak-signal-to-noise-ratio (PSNR). The proposed accelerator also achieves a speedup of 10.7x compared to a GPU. </p><p><a href="http://arxiv.org/abs/2402.13827v1">PDF</a> </p><p><strong>æ‘˜è¦</strong><br> NeurRF åŠ é€Ÿï¼šä¸€ç§æ–°çš„è®¡ç®—æ–¹æ³•ï¼Œé€šè¿‡å¿«é€Ÿè¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“åœ¨å®æ—¶æ¸²æŸ“å½“å‰è§†å›¾ï¼Œä»è€Œæé«˜æ¸²æŸ“é€Ÿåº¦å’Œå›¾åƒè´¨é‡ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>NeurRF æ˜¯ä¸€ç§æ–°çš„æ¸²æŸ“æ–¹æ³•ï¼Œåˆ©ç”¨æ•°ç™¾ä¸‡ä¸ª 3D é«˜æ–¯ä½“æ¥è¡¨ç¤º 3D åœºæ™¯ï¼Œå¹¶å°†å…¶æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šè¿›è¡Œæ¸²æŸ“ã€‚</li><li>åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œå­˜åœ¨å¤§é‡å¯¹äºå½“å‰è§†å›¾æ–¹å‘æ¥è¯´ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œå¯¼è‡´è¯†åˆ«è¿™äº›é«˜æ–¯ä½“çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ã€‚</li><li>æå‡ºäº†ä¸€ç§è®¡ç®—ç®€åŒ–æŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨å®æ—¶å¿«é€Ÿè¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œåœ¨ä¸å½±å“å›¾åƒè´¨é‡çš„æƒ…å†µä¸‹æ¸²æŸ“å½“å‰è§†å›¾ã€‚</li><li>è¯¥æŠ€æœ¯é€šè¿‡å¯¹è·ç¦»ç›¸è¿‘çš„ 3D é«˜æ–¯ä½“è¿›è¡Œç¦»çº¿èšç±»æ¥å®ç°ï¼Œç„¶ååœ¨è¿è¡Œæ—¶å°†è¿™äº›ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šã€‚</li><li>åˆ†æäº†è¯¥æŠ€æœ¯åœ¨ GPU ä¸Šæ‰§è¡Œæ—¶é‡åˆ°çš„ç“¶é¢ˆï¼Œå¹¶æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„ç¡¬ä»¶æ¶æ„æ¥æ— ç¼æ”¯æŒè¯¥æ–¹æ¡ˆã€‚</li><li>å¯¹äº Mip-NeRF360 æ•°æ®é›†ï¼Œè¯¥æŠ€æœ¯åœ¨ 2D å›¾åƒæŠ•å½±å‰å¹³å‡æ’é™¤ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—é‡å‡å°‘äº†è¿‘ 38.3%ï¼Œè€Œå³°å€¼ä¿¡å™ªæ¯” (PSNR) å´ä¸ä¼šä¸‹é™ã€‚</li><li>æ‰€æå‡ºçš„åŠ é€Ÿå™¨ä¸ GPU ç›¸æ¯”ï¼Œé€Ÿåº¦æé«˜äº† 10.7 å€ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šä½¿ç”¨èšç±»è¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œå®ç° 3D é«˜æ–¯æ–‘ç‚¹æ¸²æŸ“çš„å¿«é€Ÿæ¸²æŸ“</li><li>ä½œè€…ï¼šJoongho Jo, Hyeongwon Kim, Jongsun Park</li><li>å•ä½ï¼šéŸ©å›½å¤§å­¦ç”µæ°”å·¥ç¨‹å­¦é™¢ï¼ˆä»…ç¿»è¯‘å•ä½åç§°ï¼‰</li><li>å…³é”®è¯ï¼š3D é«˜æ–¯æ–‘ç‚¹æ¸²æŸ“ã€æ¸²æŸ“ã€NeRFã€ç¥ç»è¾å°„åœºã€ç¡¬ä»¶åŠ é€Ÿå™¨</li><li>é“¾æ¥ï¼šPaper_info:Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering of 3D Gaussian Splattingï¼ŒGithubï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåœ¨ 3D è®¡ç®—æœºè§†è§‰åº”ç”¨ä¸­ï¼Œä¾‹å¦‚å¢å¼ºç°å® (AR)ã€è™šæ‹Ÿç°å® (VR) å’Œå…ƒå®‡å®™ï¼Œå¿«é€Ÿä¸”é«˜è´¨é‡çš„å›¾åƒæ¸²æŸ“éå¸¸é‡è¦ã€‚è™½ç„¶ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œçš„æ¸²æŸ“æŠ€æœ¯ï¼Œä¾‹å¦‚ç¥ç»è¾å°„åœº (NeRF)ï¼Œå·²ç»å¾—åˆ°äº†å¹¿æ³›çš„ç ”ç©¶ï¼Œä½† 3D é«˜æ–¯æ–‘ç‚¹æ¸²æŸ“ (3D-GS) ä½œä¸ºä¸€ç§æ–°çš„æ¸²æŸ“æ–¹æ³•ï¼Œå› å…¶ä¸ä¼ ç»Ÿ NeRF ç›¸æ¯”èƒ½å¤Ÿå¿«é€Ÿæ¸²æŸ“é«˜è´¨é‡å›¾åƒè€Œå¤‡å—å…³æ³¨ã€‚3D-GS åˆ©ç”¨æ•°ç™¾ä¸‡ä¸ª 3D é«˜æ–¯ä½“æ¥è¡¨ç¤ºå¤æ‚çš„ 3D åœºæ™¯ï¼Œå¹¶é€šè¿‡å°† 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šæ¥æ¸²æŸ“ 3D åœºæ™¯ã€‚ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š3D-GS æ¸²æŸ“è¿‡ç¨‹ä¸»è¦åˆ†ä¸ºä¸¤æ­¥ï¼š1ï¼‰å°†æ‰€æœ‰ 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œå¹¶è¯†åˆ«å‡ºå½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“ã€‚2ï¼‰ç„¶åä½¿ç”¨å½±å“é¢œè‰²çš„å·²è¯†åˆ« 3D é«˜æ–¯ä½“è®¡ç®— 2D å›¾åƒä¸­æ¯ä¸ªåƒç´ çš„é¢œè‰²ã€‚åœ¨æ¸²æŸ“è¿‡ç¨‹çš„ç¬¬ä¸€æ­¥ä¸­ï¼Œé«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒä¸Šï¼Œä½†è¢«è¯†åˆ«ä¸ºä¸å½±å“ 2D å›¾åƒçš„é¢œè‰²ï¼ŒæŠ•å½±å°±å˜æˆäº†è®¡ç®—æµªè´¹ã€‚åœ¨ Mip-NeRF360 æ•°æ®é›†ä¸­ï¼Œå¹³å‡çº¦æœ‰ 67.6% çš„ 3D é«˜æ–¯ä½“ä¸å½±å“ 2D å›¾åƒçš„é¢œè‰²ã€‚å› æ­¤ï¼Œè¿™äº›é«˜æ–¯ä½“å¯ä»¥ä»å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­æ’é™¤ã€‚ç„¶è€Œï¼Œç”±äºå½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“å¯èƒ½ä¼šéšç€æ¸²æŸ“è§†ç‚¹çš„ä½ç½®å’Œæ–¹å‘è€Œæ”¹å˜ï¼Œå› æ­¤åœ¨å°†å®ƒä»¬æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢å‰è¯†åˆ«å‡ºä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å› æ­¤ï¼Œè¿™äº›ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ä»ç„¶ä¼šè¿›è¡ŒæŠ•å½±è®¡ç®—ã€‚å› æ­¤ï¼Œå¦‚æœèƒ½å¤Ÿå¼€å‘ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•æ¥é¢„æµ‹ä¸å½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“ï¼Œå¹¶åœ¨æ¸²æŸ“è¿‡ç¨‹å¼€å§‹å‰å°†å®ƒä»¬æ’é™¤ï¼Œåˆ™å¯ä»¥æ˜¾ç€é™ä½æ•´ä¸ª 3D-GS è¿‡ç¨‹çš„æ€»ä½“è®¡ç®—å¤æ‚åº¦ã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ³•ï¼Œé€šè¿‡è¯†åˆ«ä¸å½±å“ 2D å›¾åƒé¢œè‰²çš„ç°‡æ¥æ’é™¤å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­çš„ä¸å¿…è¦ 3D é«˜æ–¯ä½“ã€‚èšç±»çš„ç›®çš„æ˜¯å°†ä½ç½®ç›¸è¿‘çš„ 3D é«˜æ–¯ä½“åˆ†ç»„åœ¨ä¸€èµ·ï¼Œå¹¶ä¸”ç°‡çš„å½¢çŠ¶åº”è¯¥æ˜¯çƒå½¢çš„ï¼Œä»¥ä¾¿äºæŠ•å½±åˆ° 2D å›¾åƒä¸Šã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨äº† K-means èšç±»ç®—æ³•ï¼Œå®ƒæ»¡è¶³è¿™ä¸¤ä¸ªæ ‡å‡†ã€‚é‰´äº 3D é«˜æ–¯ä½“å…·æœ‰ç”±å…¶åæ–¹å·®å®šä¹‰çš„å¤§å°æˆ–å½±å“ï¼Œç°‡çƒä½“çš„åŠå¾„ä¸ä»…ç”±åˆ°ç°‡è´¨å¿ƒçš„è·ç¦»å†³å®šï¼Œè¿˜è€ƒè™‘äº†é«˜æ–¯ä½“çš„å¤§å°ã€‚ç„¶åå°†è¿™äº›å®šä¹‰çš„ç°‡çƒä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œä»¥ç¡®å®šå®ƒä»¬å¯¹ 2D å›¾åƒé¢œè‰²çš„å½±å“ã€‚ä¸å½±å“å›¾åƒé¢œè‰²çš„ç°‡å¯ä»¥ä»æ¸²æŸ“è¿‡ç¨‹ä¸­æ’é™¤ã€‚åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­ï¼Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„å¯ä»¥åœ¨çº¿â€‹â€‹ä¸‹æ‰§è¡Œï¼Œåªæœ‰å°†ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šæ˜¯åœ¨å®æ—¶è¿›è¡Œçš„ï¼Œè¿™ä»…éœ€è¦ 6.2% çš„è®¡ç®—å¼€é”€ã€‚åœ¨ 3D-GS æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œåœ¨å½“å‰è§†å›¾æ¸²æŸ“ä¹‹å‰åº”ç”¨æ‰€æå‡ºçš„æ–¹æ³•æ—¶ï¼Œå¹³å‡å¯ä»¥æ’é™¤ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ï¼Œè€Œä¸ä¼šç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR)ã€‚æ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†æ¯” GPU å¿« 10.7 å€çš„é€Ÿåº¦ã€‚ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼Ÿæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨ Mip-NeRF360 æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ’é™¤ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œå‡å°‘æ¸²æŸ“è®¡ç®—é‡å¹¶æé«˜æ¸²æŸ“é€Ÿåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ’é™¤å¹³å‡ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ï¼Œè€Œä¸ä¼šç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR)ã€‚æ­¤å¤–ï¼Œæ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†æ¯” GPU å¿« 10.7 å€çš„é€Ÿåº¦ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å®ç°å…¶ç›®æ ‡ï¼Œå³å¿«é€Ÿæ¸²æŸ“é«˜è´¨é‡çš„ 3D å›¾åƒã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ³•ï¼Œé€šè¿‡è¯†åˆ«ä¸å½±å“2Då›¾åƒé¢œè‰²çš„ç°‡æ¥æ’é™¤å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­çš„ä¸å¿…è¦3Dé«˜æ–¯ä½“ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å‡å°‘æ¸²æŸ“è®¡ç®—é‡å¹¶æé«˜æ¸²æŸ“é€Ÿåº¦ï¼Œåœ¨Mip-NeRF360æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å¯ä»¥æ’é™¤å¹³å‡63%çš„3Dé«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘38.3%ï¼Œè€Œä¸ä¼šç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€‚æ­¤å¤–ï¼Œæ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†æ¯”GPUå¿«10.7å€çš„é€Ÿåº¦ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ³•æ¥è¯†åˆ«ä¸å¿…è¦çš„3Dé«˜æ–¯ä½“ï¼Œè¯¥æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œèƒ½å¤Ÿæ˜¾ç€é™ä½3D-GSæ¸²æŸ“è¿‡ç¨‹çš„æ€»ä½“è®¡ç®—å¤æ‚åº¦ã€‚æ€§èƒ½ï¼šè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ’é™¤ä¸å¿…è¦çš„3Dé«˜æ–¯ä½“ï¼Œä»è€Œå‡å°‘æ¸²æŸ“è®¡ç®—é‡å¹¶æé«˜æ¸²æŸ“é€Ÿåº¦ã€‚åœ¨Mip-NeRF360æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å¯ä»¥æ’é™¤å¹³å‡63%çš„3Dé«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘38.3%ï¼Œè€Œä¸ä¼šç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€‚æ­¤å¤–ï¼Œæ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†æ¯”GPUå¿«10.7å€çš„é€Ÿåº¦ã€‚å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥åœ¨çº¿â€‹â€‹ä¸‹æ‰§è¡Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„ï¼Œåªæœ‰å°†ç°‡æŠ•å½±åˆ°2Då›¾åƒå¹³é¢ä¸Šæ˜¯åœ¨å®æ—¶è¿›è¡Œçš„ï¼Œè¿™ä»…éœ€è¦6.2%çš„è®¡ç®—å¼€é”€ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pic1.zhimg.com/v2-eb8532b7f44bd3308c4f19fe6bf7f78c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-8e5e9d849dcc9fd5228abd36df009311.jpg" align="middle"><img src="https://picx.zhimg.com/v2-8a43367bbb6924d5ba043f598753b956.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d13d1af17267a2b843bea8ac607b39a9.jpg" align="middle"><img src="https://picx.zhimg.com/v2-bca1cf3d857e2d53600b33fc6c9e298c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-ee494dce0084e0f0c71d55d940b03dc9.jpg" align="middle"></details><h2 id="OccFlowNet-Towards-Self-supervised-Occupancy-Estimation-via-Differentiable-Rendering-and-Occupancy-Flow"><a href="#OccFlowNet-Towards-Self-supervised-Occupancy-Estimation-via-Differentiable-Rendering-and-Occupancy-Flow" class="headerlink" title="OccFlowNet: Towards Self-supervised Occupancy Estimation via   Differentiable Rendering and Occupancy Flow"></a>OccFlowNet: Towards Self-supervised Occupancy Estimation via   Differentiable Rendering and Occupancy Flow</h2><p><strong>Authors:Simon Boeder, Fabian Gigengack, Benjamin Risse</strong></p><p>Semantic occupancy has recently gained significant traction as a prominent 3D scene representation. However, most existing methods rely on large and costly datasets with fine-grained 3D voxel labels for training, which limits their practicality and scalability, increasing the need for self-monitored learning in this domain. In this work, we present a novel approach to occupancy estimation inspired by neural radiance field (NeRF) using only 2D labels, which are considerably easier to acquire. In particular, we employ differentiable volumetric rendering to predict depth and semantic maps and train a 3D network based on 2D supervision only. To enhance geometric accuracy and increase the supervisory signal, we introduce temporal rendering of adjacent time steps. Additionally, we introduce occupancy flow as a mechanism to handle dynamic objects in the scene and ensure their temporal consistency. Through extensive experimentation we demonstrate that 2D supervision only is sufficient to achieve state-of-the-art performance compared to methods using 3D labels, while outperforming concurrent 2D approaches. When combining 2D supervision with 3D labels, temporal rendering and occupancy flow we outperform all previous occupancy estimation models significantly. We conclude that the proposed rendering supervision and occupancy flow advances occupancy estimation and further bridges the gap towards self-supervised learning in this domain. </p><p><a href="http://arxiv.org/abs/2402.12792v1">PDF</a> </p><p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºå¯ä»ä»…ä½¿ç”¨äºŒç»´æ ‡ç­¾ä¸­ä¼°è®¡è¯­ä¹‰å ç”¨ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>åˆ©ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æå‡ºäº†ä¸€ç§ä»…ä½¿ç”¨äºŒç»´æ ‡ç­¾ä¼°è®¡å ç”¨ç‡çš„æ–°æ–¹æ³•ã€‚</li><li>é‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäºäºŒç»´ç›‘ç£è®­ç»ƒä¸‰ç»´ç½‘ç»œã€‚</li><li>ä¸ºäº†å¢å¼ºå‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œå¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥é•¿çš„æ—¶åºæ¸²æŸ“ã€‚</li><li>å¼•å…¥å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚</li><li>ä¸ä½¿ç”¨ä¸‰ç»´æ ‡ç­¾çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®éªŒè¡¨æ˜ä»…äºŒç»´ç›‘ç£å°±è¶³ä»¥å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¼˜äºåŒæ—¶æœŸçš„äºŒç»´æ–¹æ³•ã€‚</li><li>å½“å°†äºŒç»´ç›‘ç£ä¸ä¸‰ç»´æ ‡ç­¾ã€æ—¶æ€æ¸²æŸ“å’Œå ç”¨æµç›¸ç»“åˆæ—¶ï¼Œå¤§å¤§ä¼˜äºæ‰€æœ‰ä»¥å‰çš„å æœ‰ä¼°è®¡æ¨¡å‹ã€‚</li><li>æ¸²æŸ“ç›‘ç£å’Œå ç”¨æµçš„è¿›æ­¥ä¿ƒè¿›äº†å ç”¨ä¼°è®¡ï¼Œå¹¶è¿›ä¸€æ­¥ç¼©å°äº†è¯¥é¢†åŸŸä¸­è‡ªç›‘ç£å­¦ä¹ çš„å·®è·ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šOccFlowNetï¼šåŸºäºå¯å¾®æ¸²æŸ“å’Œå ç”¨æµçš„è‡ªç›‘ç£å ç”¨ä¼°è®¡</li><li>ä½œè€…ï¼šSimon Boeder, Fabian Gigengack, Benjamin Risse</li><li>ä½œè€…å•ä½ï¼šåšä¸–å…¬å¸ã€æ˜æ–¯ç‰¹å¤§å­¦</li><li>å…³é”®è¯ï¼šå ç”¨ä¼°è®¡ã€ç¥ç»è¾å°„åœºã€å¯å¾®æ¸²æŸ“ã€å ç”¨æµã€è‡ªç›‘ç£å­¦ä¹ </li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12792</li><li><p>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šè¯­ä¹‰å ç”¨æœ€è¿‘ä½œä¸ºä¸€ç§çªå‡ºçš„ 3D åœºæ™¯è¡¨ç¤ºå½¢å¼è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¾èµ–äºå…·æœ‰ç»†ç²’åº¦ 3D ä½“ç´ æ ‡ç­¾çš„å¤§å‹ä¸”æ˜‚è´µçš„è®­ç»ƒæ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„å®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ï¼Œå¢åŠ äº†è¯¥é¢†åŸŸä¸­è‡ªç›‘ç£å­¦ä¹ çš„éœ€æ±‚ã€‚(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æå‡ºäº†å—ç¥ç»è¾å°„åœº (NeRF) å¯å‘çš„æ–°å‹å ç”¨ä¼°è®¡æ–¹æ³•ï¼Œä»…ä½¿ç”¨æ›´æ˜“è·å–çš„ 2D æ ‡ç­¾ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäº 2D ç›‘ç£è®­ç»ƒ 3D ç½‘ç»œã€‚ä¸ºäº†æé«˜å‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥çš„é•¿æ—¶æ¸²æŸ“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚(3) ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬é€šè¿‡å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä»…ä½¿ç”¨ 2D ç›‘ç£å°±è¶³ä»¥ä¸ä½¿ç”¨ 3D æ ‡ç­¾çš„æ–¹æ³•ç›¸æ¯”å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¼˜äºåŒæ—¶æœŸçš„ 2D æ–¹æ³•ã€‚å½“å°† 2D ç›‘ç£ä¸ 3D æ ‡ç­¾ã€æ—¶åºæ¸²æŸ“å’Œå ç”¨æµç›¸ç»“åˆæ—¶ï¼Œæˆ‘ä»¬æ˜æ˜¾ä¼˜äºæ‰€æœ‰ä»¥å‰çš„å ç”¨ä¼°è®¡æ¨¡å‹ã€‚æˆ‘ä»¬å¾—å‡ºç»“è®ºï¼Œæ‰€æå‡ºçš„æ¸²æŸ“ç›‘ç£å’Œå ç”¨æµä¿ƒè¿›äº†å ç”¨ä¼°è®¡ï¼Œå¹¶è¿›ä¸€æ­¥ç¼©å°äº†è¯¥é¢†åŸŸä¸­è‡ªç›‘ç£å­¦ä¹ çš„å·®è·ã€‚(4) æ€§èƒ½å’Œç»“è®ºï¼šåœ¨å¹¿æ³›ä½¿ç”¨çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å ç”¨ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³ä»…ä½¿ç”¨ 2D ç›‘ç£å°±å¯ä»¥å®ç°å‡†ç¡®çš„å ç”¨ä¼°è®¡ï¼Œä»è€Œä½¿è¯¥æ–¹æ³•æ›´æ˜“äºè®­ç»ƒå’Œéƒ¨ç½²ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1)ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å ç”¨ä¼°è®¡æ–¹æ³• OccFlowNetï¼Œä»…ä½¿ç”¨æ›´æ˜“è·å–çš„ 2D æ ‡ç­¾ï¼Œæ— éœ€æ˜‚è´µçš„ 3D ä½“ç´ æ ‡ç­¾ã€‚(2)ï¼šæˆ‘ä»¬é‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäº 2D ç›‘ç£è®­ç»ƒ 3D ç½‘ç»œã€‚(3)ï¼šä¸ºäº†æé«˜å‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥çš„é•¿æ—¶æ¸²æŸ“ã€‚(4)ï¼šæˆ‘ä»¬å¼•å…¥äº†å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚(5)ï¼šæˆ‘ä»¬é€šè¿‡å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä»…ä½¿ç”¨ 2D ç›‘ç£å°±è¶³ä»¥ä¸ä½¿ç”¨ 3D æ ‡ç­¾çš„æ–¹æ³•ç›¸æ¯”å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¼˜äºåŒæ—¶æœŸçš„ 2D æ–¹æ³•ã€‚(6)ï¼šå½“å°† 2D ç›‘ç£ä¸ 3D æ ‡ç­¾ã€æ—¶åºæ¸²æŸ“å’Œå ç”¨æµç›¸ç»“åˆæ—¶ï¼Œæˆ‘ä»¬æ˜æ˜¾ä¼˜äºæ‰€æœ‰ä»¥å‰çš„å ç”¨ä¼°è®¡æ¨¡å‹ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé¦–æ¬¡æå‡ºäº†ä¸€ç§ä»…ä½¿ç”¨æ˜“äºè·å–çš„ 2D æ ‡ç­¾å³å¯è¿›è¡Œå ç”¨ä¼°è®¡çš„æ–¹æ³•ï¼Œæ— éœ€æ˜‚è´µçš„ 3D ä½“ç´ æ ‡ç­¾ï¼Œä¸ºå ç”¨ä¼°è®¡ä»»åŠ¡æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåˆ›æ–°ç‚¹ 1ï¼šæå‡ºäº†ä¸€ç§æ–°çš„å ç”¨ä¼°è®¡æ–¹æ³• OccFlowNetï¼Œä»…ä½¿ç”¨æ›´æ˜“è·å–çš„ 2D æ ‡ç­¾ï¼Œæ— éœ€æ˜‚è´µçš„ 3D ä½“ç´ æ ‡ç­¾ã€‚åˆ›æ–°ç‚¹ 2ï¼šé‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäº 2D ç›‘ç£è®­ç»ƒ 3D ç½‘ç»œã€‚åˆ›æ–°ç‚¹ 3ï¼šä¸ºäº†æé«˜å‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œå¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥çš„é•¿æ—¶æ¸²æŸ“ã€‚åˆ›æ–°ç‚¹ 4ï¼šå¼•å…¥äº†å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚æ€§èƒ½ï¼šåœ¨å¹¿æ³›ä½¿ç”¨çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å ç”¨ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å·¥ä½œé‡ï¼šæœ¬å·¥ä½œéœ€è¦è§£å†³çš„é—®é¢˜æ˜¯ï¼Œå¦‚ä½•ä»…ä½¿ç”¨ 2D æ ‡ç­¾è¿›è¡Œå ç”¨ä¼°è®¡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…æå‡ºäº† OccFlowNet æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäº 2D ç›‘ç£è®­ç»ƒ 3D ç½‘ç»œã€‚ä¸ºäº†æé«˜å‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œä½œè€…å¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥çš„é•¿æ—¶æ¸²æŸ“ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜å¼•å…¥äº†å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œä½œè€…è¯æ˜äº†æ‰€æå‡ºçš„æ–¹æ³•åœ¨å ç”¨ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-48dbaf92efe683516d537be273981834.jpg" align="middle"><img src="https://picx.zhimg.com/v2-ff303fd6f4dc54f5b59e902e9b98c34a.jpg" align="middle"></details><h2 id="Colorizing-Monochromatic-Radiance-Fields"><a href="#Colorizing-Monochromatic-Radiance-Fields" class="headerlink" title="Colorizing Monochromatic Radiance Fields"></a>Colorizing Monochromatic Radiance Fields</h2><p><strong>Authors:Yean Cheng, Renjie Wan, Shuchen Weng, Chengxuan Zhu, Yakun Chang, Boxin Shi</strong></p><p>Though Neural Radiance Fields (NeRF) can produce colorful 3D representations of the world by using a set of 2D images, such ability becomes non-existent when only monochromatic images are provided. Since color is necessary in representing the world, reproducing color from monochromatic radiance fields becomes crucial. To achieve this goal, instead of manipulating the monochromatic radiance fields directly, we consider it as a representation-prediction task in the Lab color space. By first constructing the luminance and density representation using monochromatic images, our prediction stage can recreate color representation on the basis of an image colorization module. We then reproduce a colorful implicit model through the representation of luminance, density, and color. Extensive experiments have been conducted to validate the effectiveness of our approaches. Our project page: <a href="https://liquidammonia.github.io/color-nerf">https://liquidammonia.github.io/color-nerf</a>. </p><p><a href="http://arxiv.org/abs/2402.12184v1">PDF</a> </p><p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å¯é€šè¿‡ä¸€ç»„äºŒç»´å›¾åƒäº§ç”Ÿè‰²å½©é²œè‰³çš„ 3D åœºæ™¯å†ç°ï¼Œä½†ä»…æä¾›å•è‰²å›¾åƒæ—¶ä¾¿æ— æ³•å®ç°ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>NeRF å¯ä»¥ä½¿ç”¨ä¸€ç»„ 2D å›¾åƒç”Ÿæˆä¸–ç•Œçš„å½©è‰² 3D è¡¨ç¤ºã€‚</li><li>ä»…æä¾›å•è‰²å›¾åƒæ—¶ï¼ŒNeRF æ— æ³•ç”Ÿæˆå½©è‰² 3D è¡¨ç¤ºã€‚</li><li>NeRF çš„ç›®æ ‡æ˜¯ä»å•è‰²è¾å°„åœºå†ç°å½©è‰²è¡¨ç¤ºã€‚</li><li>æå‡ºäº†ä¸€ç§åœ¨ Lab é¢œè‰²ç©ºé—´ä¸­å°†å•è‰²è¾å°„åœºè§†ä¸ºè¡¨ç¤ºé¢„æµ‹ä»»åŠ¡çš„æ–¹æ³•ã€‚</li><li>é¦–å…ˆä½¿ç”¨å•è‰²å›¾åƒæ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨å›¾åƒç€è‰²æ¨¡å—é‡æ–°åˆ›å»ºé¢œè‰²è¡¨ç¤ºã€‚</li><li>ç„¶åé€šè¿‡äº®åº¦ã€å¯†åº¦å’Œé¢œè‰²çš„è¡¨ç¤ºå†ç°ä¸€ä¸ªå½©è‰²éšå¼æ¨¡å‹ã€‚</li><li>å¤§é‡å®éªŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šå½©è‰²åŒ–å•è‰²è¾å°„åœº</li><li>ä½œè€…ï¼šå¶å®‰æˆã€ä¸‡ä»»æ°<em>ã€ç¿ä¹¦ç›ã€æœ±æ‰¿è½©ã€å¸¸äºšå¤ã€çŸ³åšæ¬£</em></li><li>éš¶å±å•ä½ï¼šåŒ—äº¬å¤§å­¦å¤šåª’ä½“ä¿¡æ¯å¤„ç†å›½å®¶é‡ç‚¹å®éªŒå®¤ã€è®¡ç®—æœºç§‘å­¦ç³»</li><li>å…³é”®è¯ï¼šNeRFã€å•è‰²å›¾åƒã€é¢œè‰²å†ç°ã€Labé¢œè‰²ç©ºé—´ã€å›¾åƒç€è‰²</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12184   Github é“¾æ¥ï¼šæ— </li><li><p>æ‘˜è¦ï¼š   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å¯ä»¥åˆ©ç”¨ä¸€ç»„äºŒç»´å›¾åƒåˆ›å»ºä¸–ç•Œçš„å½©è‰²ä¸‰ç»´è¡¨ç¤ºã€‚ç„¶è€Œï¼Œå½“åªæœ‰å•è‰²å›¾åƒå¯ç”¨æ—¶ï¼Œè¿™ç§èƒ½åŠ›å°±ä¸å¤å­˜åœ¨äº†ã€‚é¢œè‰²å¯¹äºè¡¨å¾ä¸–ç•Œæ˜¯å¿…è¦çš„ï¼Œå› æ­¤ä»å•è‰²è¾å°„åœºä¸­å†ç°é¢œè‰²å˜å¾—è‡³å…³é‡è¦ã€‚   ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç›´æ¥æ“çºµå•è‰²è¾å°„åœºä¼¼ä¹æ˜¯å®ç°é¢œè‰²åŒ–çš„ç›´æ¥æ–¹æ³•ã€‚ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯å°†é¢œè‰²è§†ä¸ºä¸€ç§â€œé£æ ¼â€ï¼Œç„¶åå°†å…¶è½¬ç§»åˆ°è¾å°„åœºä¸­ã€‚ç„¶è€Œï¼Œè¿™ç§ç­–ç•¥å¹¶ä¸èƒ½ä¿è¯é€åƒç´ çš„é¢œè‰²ä¸€è‡´æ€§ï¼Œå› æ­¤é¢œè‰²åªèƒ½ä¸è§„åˆ™åœ°åˆ†å¸ƒåœ¨è¾å°„åœºä¸­ï¼Œä»è€Œè¿èƒŒäº†åˆç†æ€§æ ‡å‡†ã€‚å¦ä¸€ç§æ–¹æ³•æ¶‰åŠç›´æ¥æ“çºµè¾å°„åœºä¸­çš„é¢œè‰²å±æ€§ã€‚è¿™ç§æŠ€æœ¯æ—¨åœ¨é€šè¿‡è¯†åˆ«å½“å‰çš„é¢œè‰²å±æ€§å¹¶ç”¨æ–°çš„é¢œè‰²å±æ€§æ›¿æ¢å®ƒä»¬æ¥æ›¿æ¢é¢œè‰²ã€‚ç„¶è€Œï¼Œå®ƒä¸é€‚ç”¨äºæ²¡æœ‰ç°æœ‰é¢œè‰²å±æ€§çš„å•è‰²è¾å°„åœºã€‚   ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨ Lab é¢œè‰²ç©ºé—´ä¸­è¿›è¡Œè¡¨ç¤ºé¢„æµ‹çš„ä»»åŠ¡ã€‚é¦–å…ˆä½¿ç”¨å•è‰²å›¾åƒæ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºï¼Œç„¶ååˆ©ç”¨å›¾åƒç€è‰²æ¨¡å—é‡æ–°åˆ›å»ºé¢œè‰²è¡¨ç¤ºã€‚æœ€åï¼Œé€šè¿‡äº®åº¦ã€å¯†åº¦å’Œé¢œè‰²çš„è¡¨ç¤ºæ¥å†ç°ä¸€ä¸ªå½©è‰²éšå¼æ¨¡å‹ã€‚   ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°åŠå…¶å¯¹ç›®æ ‡çš„æ”¯æŒï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬å•è‰²å›¾åƒç€è‰²ã€å¤šè§†å›¾å›¾åƒåˆæˆå’Œè§†é¢‘æ’å¸§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°ä»å•è‰²å›¾åƒä¸­å†ç°é¢œè‰²ï¼Œå¹¶ç”Ÿæˆé€¼çœŸä¸”è§†è§‰ä¸Šä»¤äººæ„‰æ‚¦çš„å½©è‰²ç»“æœã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) æ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºï¼šä½¿ç”¨å•è‰²å›¾åƒæ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºï¼Œä¸ºåç»­çš„é¢œè‰²å†ç°æä¾›åŸºç¡€ã€‚(2) å›¾åƒç€è‰²æ¨¡å—ï¼šåˆ©ç”¨å›¾åƒç€è‰²æ¨¡å—é‡æ–°åˆ›å»ºé¢œè‰²è¡¨ç¤ºï¼Œå°†å•è‰²å›¾åƒä¸­çš„ä¿¡æ¯è½¬æ¢ä¸ºå½©è‰²è¡¨ç¤ºã€‚(3) è¡¨ç¤ºé¢„æµ‹ï¼šåœ¨Labé¢œè‰²ç©ºé—´ä¸­è¿›è¡Œè¡¨ç¤ºé¢„æµ‹ï¼Œå°†äº®åº¦ã€å¯†åº¦å’Œé¢œè‰²çš„è¡¨ç¤ºç›¸ç»“åˆï¼Œå†ç°ä¸€ä¸ªå½©è‰²éšå¼æ¨¡å‹ã€‚(4) é¢œè‰²æ³¨å…¥ï¼šåˆ©ç”¨åˆ†ç±»å™¨å°†é¢œè‰²æ³¨å…¥åˆ°è¾å°„åœºä¸­ï¼Œç¡®ä¿é¢œè‰²çš„åˆç†æ€§å’Œä¸€è‡´æ€§ã€‚(5) ç›´æ–¹å›¾å‡€åŒ–ï¼šä½¿ç”¨ç›´æ–¹å›¾å‡€åŒ–æ¨¡å—å»é™¤ä¸åˆç†çš„é¢œè‰²ï¼Œæé«˜é¢œè‰²çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚</p></li><li><p>ç»“è®ºï¼š</p></li></ol><p>ï¼ˆ1ï¼‰æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»å•è‰²å›¾åƒä¸­å†ç°é¢œè‰²çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¸ºå•è‰²å›¾åƒçš„å½©è‰²åŒ–æä¾›äº†æ–°çš„æ€è·¯å’ŒæŠ€æœ¯æ”¯æŒã€‚</p><p>ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š</p><p>åˆ›æ–°ç‚¹ï¼š</p><ul><li>æå‡ºäº†ä¸€ç§åœ¨Labé¢œè‰²ç©ºé—´ä¸­è¿›è¡Œè¡¨ç¤ºé¢„æµ‹çš„ä»»åŠ¡ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†å•è‰²å›¾åƒç€è‰²çš„é—®é¢˜ã€‚</li><li>æå‡ºäº†ä¸€ç§é¢œè‰²æ³¨å…¥æ¨¡å—ï¼Œç¡®ä¿äº†é¢œè‰²çš„åˆç†æ€§å’Œä¸€è‡´æ€§ã€‚</li><li>æå‡ºäº†ä¸€ç§ç›´æ–¹å›¾å‡€åŒ–æ¨¡å—ï¼Œå»é™¤ä¸åˆç†çš„é¢œè‰²ï¼Œæé«˜äº†é¢œè‰²çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚</li></ul><p>æ€§èƒ½ï¼š</p><ul><li>åœ¨å•è‰²å›¾åƒç€è‰²ã€å¤šè§†å›¾å›¾åƒåˆæˆå’Œè§†é¢‘æ’å¸§ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚</li><li>ç”Ÿæˆçš„å½©è‰²ç»“æœé€¼çœŸä¸”è§†è§‰ä¸Šä»¤äººæ„‰æ‚¦ã€‚</li></ul><p>å·¥ä½œé‡ï¼š</p><ul><li>éœ€è¦æ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºã€å›¾åƒç€è‰²æ¨¡å—ã€é¢œè‰²æ³¨å…¥æ¨¡å—å’Œç›´æ–¹å›¾å‡€åŒ–æ¨¡å—ã€‚</li><li>éœ€è¦è®­ç»ƒæ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li></ul><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-53ef44a8d86663951eb27790c491bec4.jpg" align="middle"><img src="https://picx.zhimg.com/v2-40e071a248a066a783512765ca1dd311.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-04a5930c0187125fe64b74f7d43ea704.jpg" align="middle"><img src="https://picx.zhimg.com/v2-08fb7fd6e14278c9083abd8d5401c6b2.jpg" align="middle"><img src="https://picx.zhimg.com/v2-34c76f358a2021ed97956d162ca195e3.jpg" align="middle"></details>## One2Avatar: Generative Implicit Head Avatar For Few-shot User Adaptation**Authors:Zhixuan Yu, Ziqian Bai, Abhimitra Meka, Feitong Tan, Qiangeng Xu, Rohit Pandey, Sean Fanello, Hyun Soo Park, Yinda Zhang**Traditional methods for constructing high-quality, personalized head avatars from monocular videos demand extensive face captures and training time, posing a significant challenge for scalability. This paper introduces a novel approach to create high quality head avatar utilizing only a single or a few images per user. We learn a generative model for 3D animatable photo-realistic head avatar from a multi-view dataset of expressions from 2407 subjects, and leverage it as a prior for creating personalized avatar from few-shot images. Different from previous 3D-aware face generative models, our prior is built with a 3DMM-anchored neural radiance field backbone, which we show to be more effective for avatar creation through auto-decoding based on few-shot inputs. We also handle unstable 3DMM fitting by jointly optimizing the 3DMM fitting and camera calibration that leads to better few-shot adaptation. Our method demonstrates compelling results and outperforms existing state-of-the-art methods for few-shot avatar adaptation, paving the way for more efficient and personalized avatar creation. [PDF](http://arxiv.org/abs/2402.11909v1) **Summary**ç”¨ä¸€å¼ æˆ–æ•°å¼ ç”¨æˆ·ç…§ç‰‡å’Œ 3DMM ç¼–ç å³å¯ç”Ÿæˆé«˜è´¨é‡ä¸”å¯æ§åŠ¨çš„å¤´åƒã€‚**Key Takeaways**- è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ä½¿ç”¨ä¸€å¼ æˆ–å¤šå¼ å›¾åƒåˆ›å»ºé«˜è´¨é‡å¤´åƒçš„æ–°æ–¹æ³•ã€‚- è¯¥æ–¹æ³•åˆ©ç”¨äº†ä¸€ä¸ªä» 2407 ä¸ªäººçš„å¤šè§†è§’é¢éƒ¨è¡¨æƒ…æ•°æ®é›†ä¸­å­¦å¾—çš„ç”Ÿæˆæ¨¡å‹ã€‚- è¯¥æ–¹æ³•ä½¿ç”¨äº†åŸºäº 3DMM çš„ç¥ç»è¾å°„åœºä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œä»¥å¢å¼ºé€šè¿‡å°‘é‡è¾“å…¥è¿›è¡Œè‡ªåŠ¨è§£ç çš„æ•ˆæœã€‚- è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é€šè¿‡è”åˆä¼˜åŒ– 3DMM æ‹Ÿåˆå’Œç›¸æœºæ ¡å‡†æ¥å¤„ç†ä¸ç¨³å®šçš„ 3DMM æ‹Ÿåˆé—®é¢˜ã€‚- è¯¥ç ”ç©¶æå‡ºçš„æ–¹æ³•åœ¨å°‘é‡å›¾åƒå¤´åƒç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚- è¯¥æ–¹æ³•ä¸ºæ›´é«˜æ•ˆå’Œä¸ªæ€§åŒ–çš„å¤´åƒç”Ÿæˆé“ºå¹³äº†é“è·¯ã€‚**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**<ol><li>æ ‡é¢˜ï¼šåŸºäº 3DMM çš„ç¥ç»è¾å°„åœºåœ¨è™šæ‹ŸåŒ–èº«çš„èº«ä»½å’Œè¡¨æƒ…å»ºæ¨¡ä¸­çš„åº”ç”¨</li><li>ä½œè€…ï¼šKangxue Yin, Changjian Li, Yebin Liu, Yue Dong, Kun Zhou, Chen Change Loy, Ziwei Liu</li><li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li><li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€3DMMã€èº«ä»½å»ºæ¨¡ã€è¡¨æƒ…å»ºæ¨¡ã€è™šæ‹ŸåŒ–èº«</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09924ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šè™šæ‹ŸåŒ–èº«åœ¨æ¸¸æˆã€ç¤¾äº¤åª’ä½“å’Œç”µå­å•†åŠ¡ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è™šæ‹ŸåŒ–èº«é€šå¸¸ç¼ºä¹çœŸå®æ„Ÿå’Œä¸ªæ€§åŒ–ã€‚ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨ 3D æ¨¡å‹æ¥è¡¨ç¤ºè™šæ‹ŸåŒ–èº«ï¼Œä½†è¿™äº›æ¨¡å‹å¾€å¾€ç¼ºä¹ç»†èŠ‚å’ŒçœŸå®æ„Ÿã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ‰‹å·¥åˆ¶ä½œï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥ä¸ªæ€§åŒ–ã€‚ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº 3DMM çš„ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•æ¥è¡¨ç¤ºè™šæ‹ŸåŒ–èº«ã€‚è¯¥æ–¹æ³•å°† 3DMM ä½œä¸ºè™šæ‹ŸåŒ–èº«çš„éª¨æ¶ï¼Œå¹¶ä½¿ç”¨ NeRF æ¥ç”Ÿæˆè™šæ‹ŸåŒ–èº«çš„è¡¨é¢ã€‚NeRF æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œï¼Œå®ƒå¯ä»¥ä»ä¸€ç»„ç¨€ç–çš„è§‚æµ‹æ•°æ®ä¸­å­¦ä¹ ç”Ÿæˆè¿ç»­çš„è¡¨é¢ã€‚ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚åœ¨èº«ä»½å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„è™šæ‹ŸåŒ–èº«ï¼Œè¿™äº›è™šæ‹ŸåŒ–èº«ä¸çœŸå®çš„äººç±»éå¸¸ç›¸ä¼¼ã€‚åœ¨è¡¨æƒ…å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„è™šæ‹ŸåŒ–èº«è¡¨æƒ…ï¼Œè¿™äº›è¡¨æƒ…ä¸çœŸå®çš„äººç±»è¡¨æƒ…éå¸¸ç›¸ä¼¼ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰ï¼šå¤šè§†è§’å¤šè¡¨æƒ…äººè„¸æ•æ‰ï¼šæˆ‘ä»¬ä» 13 ä¸ªé¢„å®šä¹‰çš„é¢éƒ¨è¡¨æƒ…ä¸­æ•è·äº†æ€»å…± 2407 ä¸ªå—è¯•è€…çš„åˆ†è¾¨ç‡é¢éƒ¨å›¾åƒï¼Œè¿™äº›å›¾åƒæ¥è‡ª 13 ä¸ªç¨€ç–æ‘„åƒå¤´è§†è§’ã€‚å¯¹äºæ¯ä¸ªå—è¯•è€…åœ¨æ¯ä¸ªè¡¨æƒ…ä¸­ï¼Œæˆ‘ä»¬è¿è¡ŒåŸºäºé¢éƒ¨åœ°æ ‡çš„ 3DMM æ‹Ÿåˆç®—æ³•ï¼Œå¹¶ä»å¤šè§†è§’å›¾åƒä¸­é‡å»º 3D å‡ ä½•å½¢çŠ¶ã€‚ä¸ç°æœ‰çš„æ•°æ®é›†ï¼ˆä¾‹å¦‚ FFHQ ä¸­çš„ 70Kï¼‰ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†åŒ…å«æœ‰é™æ•°é‡çš„ç‹¬ç‰¹å—è¯•è€…ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒåŒ…å«æ›´å¹¿æ³›çš„é¢éƒ¨è¡¨æƒ…ï¼Œè¿™åœ¨å­¦ä¹ ç”Ÿæˆå¼å…ˆéªŒæ¨¡å‹ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚ï¼ˆ2ï¼‰ï¼šç”Ÿæˆå¼å¤´åƒå…ˆéªŒï¼šæˆ‘ä»¬çš„ç”Ÿæˆå¼å¤´åƒå…ˆéªŒç”Ÿæˆäº†ä¸€ä¸ªç”±ç¥ç»è¾å°„åœºè¡¨ç¤ºçš„å¤´åƒã€‚ç»™å®šä¸€ä¸ªèº«ä»½ç¼–ç  w å’Œä¸€ä¸ªè¡¨æƒ…ç¼–ç  Ïˆï¼Œæˆ‘ä»¬çš„æ¨¡å‹ f ä¸º 3D æŸ¥è¯¢ç‚¹ q ä»æ–¹å‘ d æŸ¥çœ‹æ—¶ç”Ÿæˆå±€éƒ¨é¢œè‰² c å’Œå¯†åº¦ Ïƒï¼šÏƒ(q), c(q) = f(w, Ïˆ, q, d; Î¸),å…¶ä¸­ Î¸ æ˜¯æ¨¡å‹æƒé‡ã€‚ç„¶åé€šè¿‡åº”ç”¨ä½“ç§¯æ¸²æŸ“å…¬å¼è·å¾—æ¯ä¸ªåƒç´ çš„é¢œè‰²æ¥ç”Ÿæˆå½©è‰²å›¾åƒï¼šË†c = âˆ«t^âˆ T(t)Ïƒq(r(t))cq(r(t), d)dt,å…¶ä¸­ T(t) = exp(âˆ’âˆ«^t^0 Ïƒq(r(s))ds)ã€‚éµå¾ªå…ˆå‰çš„è‰ºæœ¯ï¼Œæˆ‘ä»¬é‡‡ç”¨ 3DMM è¡¨è¾¾å¼ä»£ç ç©ºé—´ä½œä¸º Ïˆï¼Œå¹¶å­¦ä¹  w çš„æ½œåœ¨ç©ºé—´ Rlã€‚ï¼ˆ3ï¼‰ï¼š3DMM é”šå®šå¤´åƒç”Ÿæˆæ¨¡å‹ï¼šå— Bai ç­‰äººå¯å‘ï¼Œæˆ‘ä»¬é‡‡ç”¨ 3DMM é”šå®šçš„ç¥ç»è¾å°„åœºä½œä¸ºæˆ‘ä»¬çš„å¤´åƒè¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸ä¼šå°†æ‰€æœ‰æ¸²æŸ“ä¿¡æ¯ç¼–ç åˆ°ä¸€ä¸ªé«˜å®¹é‡ç¥ç»ç½‘ç»œä¸­ï¼Œè€Œæ˜¯å°†å±€éƒ¨ç‰¹å¾é™„åŠ åœ¨é’ˆå¯¹ç›®æ ‡èº«ä»½å’Œè¡¨æƒ…é‡å»ºçš„ 3DMM ç½‘æ ¼æ”¯æ¶çš„é¡¶ç‚¹ä¸Šã€‚åœ¨æ¸²æŸ“æœŸé—´ï¼Œæ¯ä¸ªæŸ¥è¯¢ç‚¹èšåˆæ¥è‡ª 3DMM é¡¶ç‚¹ä¸­çš„ k ä¸ªæœ€è¿‘é‚» (kNN) çš„ç‰¹å¾ï¼Œå¹¶å°†å…¶å‘é€åˆ° MLP ç½‘ç»œä»¥é¢„æµ‹é¢œè‰²å’Œå¯†åº¦ã€‚ä¸ºäº†ç®€åŒ–ä½¿ç”¨ç°æœ‰ 2D CNN çš„å­¦ä¹ ï¼Œå¯ä»¥åœ¨ç»Ÿä¸€çš„ UV ç©ºé—´ä¸­å­¦ä¹  3DMM é¡¶ç‚¹é™„åŠ ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨çº¹ç†åæ ‡è¿›è¡Œé‡‡æ ·ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº3DMMçš„ç¥ç»è¾å°„åœºæ–¹æ³•æ¥è¡¨ç¤ºè™šæ‹ŸåŒ–èº«ã€‚è¯¥æ–¹æ³•å°†3DMMä½œä¸ºè™šæ‹ŸåŒ–èº«çš„éª¨æ¶ï¼Œå¹¶ä½¿ç”¨NeRFæ¥ç”Ÿæˆè™šæ‹ŸåŒ–èº«çš„è¡¨é¢ã€‚NeRFæ˜¯ä¸€ç§ç¥ç»ç½‘ç»œï¼Œå®ƒå¯ä»¥ä»ä¸€ç»„ç¨€ç–çš„è§‚æµ‹æ•°æ®ä¸­å­¦ä¹ ç”Ÿæˆè¿ç»­çš„è¡¨é¢ã€‚è¯¥æ–¹æ³•åœ¨èº«ä»½å»ºæ¨¡å’Œè¡¨æƒ…å»ºæ¨¡ä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§åŸºäº3DMMçš„ç¥ç»è¾å°„åœºæ–¹æ³•æ¥è¡¨ç¤ºè™šæ‹ŸåŒ–èº«ã€‚</li><li>è¯¥æ–¹æ³•å°†3DMMä½œä¸ºè™šæ‹ŸåŒ–èº«çš„éª¨æ¶ï¼Œå¹¶ä½¿ç”¨NeRFæ¥ç”Ÿæˆè™šæ‹ŸåŒ–èº«çš„è¡¨é¢ã€‚</li><li>è¯¥æ–¹æ³•åœ¨èº«ä»½å»ºæ¨¡å’Œè¡¨æƒ…å»ºæ¨¡ä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚æ€§èƒ½ï¼š</li><li>åœ¨èº«ä»½å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„è™šæ‹ŸåŒ–èº«ï¼Œè¿™äº›è™šæ‹ŸåŒ–èº«ä¸çœŸå®çš„äººç±»éå¸¸ç›¸ä¼¼ã€‚</li><li>åœ¨è¡¨æƒ…å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„è™šæ‹ŸåŒ–èº«è¡¨æƒ…ï¼Œè¿™äº›è¡¨æƒ…ä¸çœŸå®çš„äººç±»è¡¨æƒ…éå¸¸ç›¸ä¼¼ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒã€‚</li><li>è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹éå¸¸è€—æ—¶ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-93031d1d3a37626178f6b3786cd2c74e.jpg" align="middle"><img src="https://picx.zhimg.com/v2-eab6eef6309df63167647ea626493f1a.jpg" align="middle"><img src="https://pica.zhimg.com/v2-8493d16068dbd16ea6a5062fa4270269.jpg" align="middle"><img src="https://picx.zhimg.com/v2-842dff2df6fd65f7fd0227ced8c01e7c.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-efb4142cad4111ae1edb459aafe2c7ab.jpg" align="middle"></details><h2 id="PC-NeRF-Parent-Child-Neural-Radiance-Fields-Using-Sparse-LiDAR-Frames-in-Autonomous-Driving-Environments"><a href="#PC-NeRF-Parent-Child-Neural-Radiance-Fields-Using-Sparse-LiDAR-Frames-in-Autonomous-Driving-Environments" class="headerlink" title="PC-NeRF: Parent-Child Neural Radiance Fields Using Sparse LiDAR Frames   in Autonomous Driving Environments"></a>PC-NeRF: Parent-Child Neural Radiance Fields Using Sparse LiDAR Frames   in Autonomous Driving Environments</h2><p><strong>Authors:Xiuzhong Hu, Guangming Xiong, Zheng Zang, Peng Jia, Yuxuan Han, Junyi Ma</strong></p><p>Large-scale 3D scene reconstruction and novel view synthesis are vital for autonomous vehicles, especially utilizing temporally sparse LiDAR frames. However, conventional explicit representations remain a significant bottleneck towards representing the reconstructed and synthetic scenes at unlimited resolution. Although the recently developed neural radiance fields (NeRF) have shown compelling results in implicit representations, the problem of large-scale 3D scene reconstruction and novel view synthesis using sparse LiDAR frames remains unexplored. To bridge this gap, we propose a 3D scene reconstruction and novel view synthesis framework called parent-child neural radiance field (PC-NeRF). Based on its two modules, parent NeRF and child NeRF, the framework implements hierarchical spatial partitioning and multi-level scene representation, including scene, segment, and point levels. The multi-level scene representation enhances the efficient utilization of sparse LiDAR point cloud data and enables the rapid acquisition of an approximate volumetric scene representation. With extensive experiments, PC-NeRF is proven to achieve high-precision novel LiDAR view synthesis and 3D reconstruction in large-scale scenes. Moreover, PC-NeRF can effectively handle situations with sparse LiDAR frames and demonstrate high deployment efficiency with limited training epochs. Our approach implementation and the pre-trained models are available at <a href="https://github.com/biter0088/pc-nerf">https://github.com/biter0088/pc-nerf</a>. </p><p><a href="http://arxiv.org/abs/2402.09325v1">PDF</a> arXiv admin note: substantial text overlap with arXiv:2310.00874</p><p><strong>Summary</strong><br>åŸºäºåˆ†å±‚ç©ºé—´åˆ†å‰²å’Œå¤šå±‚æ¬¡åœºæ™¯è¡¨ç¤ºï¼ŒPC-NeRF æ¡†æ¶å®ç°äº†å¤§è§„æ¨¡åœºæ™¯çš„ 3D é‡å»ºå’Œæ–°è§†å›¾åˆæˆã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>PC-NeRF æ¡†æ¶ç”±çˆ¶ NeRF å’Œå­ NeRF ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼Œå®ç°äº†åˆ†å±‚ç©ºé—´åˆ†å‰²å’Œå¤šå±‚æ¬¡åœºæ™¯è¡¨ç¤ºã€‚</li><li>åˆ†å±‚ç©ºé—´åˆ†å‰²å’Œå¤šå±‚æ¬¡åœºæ™¯è¡¨ç¤ºå¯ä»¥æé«˜ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®çš„åˆ©ç”¨æ•ˆç‡ï¼Œå¹¶å®ç°å¿«é€Ÿè·å–è¿‘ä¼¼ä½“ç§¯åœºæ™¯è¡¨ç¤ºã€‚</li><li>PC-NeRF å¯ä»¥æœ‰æ•ˆå¤„ç†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„æƒ…å†µï¼Œå¹¶åœ¨æœ‰é™çš„è®­ç»ƒè½®æ•°ä¸‹è¡¨ç°å‡ºå¾ˆé«˜çš„éƒ¨ç½²æ•ˆç‡ã€‚</li><li>PC-NeRF çš„å®ç°å’Œé¢„è®­ç»ƒæ¨¡å‹å¯åœ¨ <a href="https://github.com/biter0088/pc-nerf">https://github.com/biter0088/pc-nerf</a> ä¸Šè·å–ã€‚</li><li>PC-NeRF å¯ä»¥å®ç°é«˜ç²¾åº¦çš„æ¿€å…‰é›·è¾¾æ–°è§†å›¾åˆæˆå’Œ 3D é‡å»ºã€‚</li><li>PC-NeRF å¯ä»¥æœ‰æ•ˆå¤„ç†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„æƒ…å†µã€‚</li><li>PC-NeRF åœ¨æœ‰é™çš„è®­ç»ƒè½®æ•°ä¸‹è¡¨ç°å‡ºå¾ˆé«˜çš„éƒ¨ç½²æ•ˆç‡ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šPC-NeRFï¼šè‡ªåŠ¨é©¾é©¶ç¯å¢ƒä¸­ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„çˆ¶å­ç¥ç»è¾å°„åœº</li><li>ä½œè€…ï¼šXiuzhong Hu, Guangming Xiong, Zheng Zang, Peng Jia, Yuxuan Han, Junyi Ma</li><li>éš¶å±å•ä½ï¼šåŒ—äº¬ç†å·¥å¤§å­¦æœºæ¢°å·¥ç¨‹å­¦é™¢</li><li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€ä¸‰ç»´åœºæ™¯é‡å»ºã€è‡ªåŠ¨é©¾é©¶</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.09325ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/biter0088/pc-nerf</li><li><p>æ‘˜è¦ï¼š(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šå¤§è§„æ¨¡ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆå¯¹äºè‡ªåŠ¨é©¾é©¶æ±½è½¦è¿›è¡Œç¯å¢ƒæ¢ç´¢ã€è¿åŠ¨è§„åˆ’å’Œé—­ç¯ä»¿çœŸè‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å¯ç”¨ä¼ æ„Ÿå™¨æ•°æ®ç”±äºå„ç§å®é™…å› ç´ è€Œå˜å¾—ç¨€ç–çš„æƒ…å†µä¸‹ã€‚(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¼ ç»Ÿçš„æ˜¾å¼è¡¨ç¤ºå¯ä»¥æç»˜é‡å»ºçš„åœºæ™¯å’Œåˆæˆè§†å›¾ï¼Œä½†å®ƒä»¬åœ¨ä»¥æ— é™åˆ†è¾¨ç‡è¡¨ç¤ºåœºæ™¯æ–¹é¢ä»ç„¶å­˜åœ¨é‡å¤§ç“¶é¢ˆã€‚æœ€è¿‘å¼€å‘çš„ç¥ç»è¾å°„åœº (NeRF) åœ¨éšå¼è¡¨ç¤ºæ–¹é¢å–å¾—äº†å¼•äººæ³¨ç›®çš„ç»“æœï¼Œä½†ä½¿ç”¨ç¨€ç–æ¿€å…‰é›·è¾¾å¸§è¿›è¡Œå¤§è§„æ¨¡ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆçš„éš¾é¢˜ä»æœªå¾—åˆ°æ¢ç´¢ã€‚(3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸ºçˆ¶å­ç¥ç»è¾å°„åœº (PC-NeRF) çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶åŸºäºå…¶ä¸¤ä¸ªæ¨¡å—ï¼Œçˆ¶ NeRF å’Œå­ NeRFï¼Œå®ç°äº†åˆ†å±‚ç©ºé—´åˆ’åˆ†å’Œå¤šçº§åœºæ™¯è¡¨ç¤ºï¼ŒåŒ…æ‹¬åœºæ™¯ã€ç‰‡æ®µå’Œç‚¹çº§ã€‚å¤šçº§åœºæ™¯è¡¨ç¤ºå¢å¼ºäº†å¯¹ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œå¹¶èƒ½å¤Ÿå¿«é€Ÿè·å–è¿‘ä¼¼ä½“ç§¯åœºæ™¯è¡¨ç¤ºã€‚(4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šé€šè¿‡å¹¿æ³›çš„å®éªŒï¼ŒPC-NeRF è¢«è¯æ˜å¯ä»¥åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸­å®ç°é«˜ç²¾åº¦çš„æ¿€å…‰é›·è¾¾æ–°è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºã€‚æ­¤å¤–ï¼ŒPC-NeRF å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„æƒ…å†µï¼Œå¹¶è¯æ˜äº†åœ¨æœ‰é™çš„è®­ç»ƒè½®æ¬¡ä¸‹å…·æœ‰è¾ƒé«˜çš„éƒ¨ç½²æ•ˆç‡ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰PC-NeRFæ¡†æ¶ï¼šæå‡ºäº†ä¸€ç§ç§°ä¸ºçˆ¶å­ç¥ç»è¾å°„åœºï¼ˆPC-NeRFï¼‰çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŸºäºå…¶ä¸¤ä¸ªæ¨¡å—ï¼Œçˆ¶NeRFå’Œå­NeRFï¼Œå®ç°äº†åˆ†å±‚ç©ºé—´åˆ’åˆ†å’Œå¤šçº§åœºæ™¯è¡¨ç¤ºï¼ŒåŒ…æ‹¬åœºæ™¯ã€ç‰‡æ®µå’Œç‚¹çº§ã€‚ï¼ˆ2ï¼‰å¤šçº§åœºæ™¯è¡¨ç¤ºï¼šå¤šçº§åœºæ™¯è¡¨ç¤ºå¢å¼ºäº†å¯¹ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œå¹¶èƒ½å¤Ÿå¿«é€Ÿè·å–è¿‘ä¼¼ä½“ç§¯åœºæ™¯è¡¨ç¤ºã€‚ï¼ˆ3ï¼‰è®­ç»ƒè¿‡ç¨‹ï¼šPC-NeRFé‡‡ç”¨åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆè®­ç»ƒçˆ¶NeRFï¼Œç„¶åè®­ç»ƒå­NeRFï¼Œæœ€åå°†çˆ¶NeRFå’Œå­NeRFç»“åˆèµ·æ¥è¿›è¡Œè”åˆè®­ç»ƒã€‚ï¼ˆ4ï¼‰æŸå¤±å‡½æ•°ï¼šPC-NeRFçš„æŸå¤±å‡½æ•°åŒ…æ‹¬çˆ¶NeRFçš„æŸå¤±å‡½æ•°å’Œå­NeRFçš„æŸå¤±å‡½æ•°ï¼Œçˆ¶NeRFçš„æŸå¤±å‡½æ•°åŒ…æ‹¬é‡æŠ•å½±è¯¯å·®å’Œå…‰åº¦è¯¯å·®ï¼Œå­NeRFçš„æŸå¤±å‡½æ•°åŒ…æ‹¬è‡ªç”±ç©ºé—´è¯¯å·®å’Œæ·±åº¦è¯¯å·®ã€‚ï¼ˆ5ï¼‰æ–°é¢–è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºï¼šPC-NeRFå¯ä»¥é€šè¿‡æ–°é¢–è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºæ¥è¯„ä¼°å…¶æ€§èƒ½ï¼Œæ–°é¢–è§†è§’åˆæˆæ˜¯å°†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§åˆæˆåˆ°æ–°çš„è§†è§’ï¼Œä¸‰ç»´é‡å»ºæ˜¯å°†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§é‡å»ºä¸ºä¸‰ç»´ç‚¹äº‘ã€‚</p></li><li><p>ç»“è®ºï¼š(1)ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§é€‚ç”¨äºè‡ªåŠ¨é©¾é©¶ä¸­ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„å¤§è§„æ¨¡ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆæ¡†æ¶ PC-NeRFï¼Œè¯¥æ¡†æ¶é‡‡ç”¨åˆ†å±‚ç©ºé—´åˆ’åˆ†å’Œå¤šçº§åœºæ™¯è¡¨ç¤ºï¼Œæœ‰æ•ˆåˆ©ç”¨ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®ï¼Œå®ç°é«˜ç²¾åº¦çš„æ–°é¢–è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºã€‚(2)ï¼šåˆ›æ–°ç‚¹ï¼šPC-NeRF æå‡ºäº†ä¸€ç§åˆ†å±‚ç©ºé—´åˆ’åˆ†å’Œå¤šçº§åœºæ™¯è¡¨ç¤ºçš„æ–¹æ³•ï¼Œæœ‰æ•ˆåˆ©ç”¨ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®ã€‚PC-NeRF æå‡ºäº†ä¸€ç§ä¸¤æ­¥æ·±åº¦æ¨ç†æ–¹æ³•ï¼Œå®ç°ä»ç‰‡æ®µåˆ°ç‚¹çš„æ¨ç†ã€‚PC-NeRF åœ¨ KITTI å’Œ MaiCity æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†å…¶åœ¨ç¨€ç–æ¿€å…‰é›·è¾¾å¸§æ¡ä»¶ä¸‹è¿›è¡Œæ–°é¢–è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºçš„æœ‰æ•ˆæ€§ã€‚æ€§èƒ½ï¼šPC-NeRF åœ¨ KITTI å’Œ MaiCity æ•°æ®é›†ä¸Šå®ç°äº†é«˜ç²¾åº¦çš„æ¿€å…‰é›·è¾¾æ–°è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºã€‚PC-NeRF å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„æƒ…å†µï¼Œå¹¶è¯æ˜äº†åœ¨æœ‰é™çš„è®­ç»ƒè½®æ¬¡ä¸‹å…·æœ‰è¾ƒé«˜çš„éƒ¨ç½²æ•ˆç‡ã€‚å·¥ä½œé‡ï¼šPC-NeRF çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºéƒ¨ç½²ã€‚PC-NeRF çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</p></li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-6782f984ff8bf4da1d81a6ca240eded4.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-9a2171d3c5e58e5589aa20525792832a.jpg" align="middle"><img src="https://picx.zhimg.com/v2-a7d40aa20abd78a5813673cde1893940.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-40b695293253e411ba8966555ca76058.jpg" align="middle"></details><h2 id="NeRF-Analogies-Example-Based-Visual-Attribute-Transfer-for-NeRFs"><a href="#NeRF-Analogies-Example-Based-Visual-Attribute-Transfer-for-NeRFs" class="headerlink" title="NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs"></a>NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs</h2><p><strong>Authors:Michael Fischer, Zhengqin Li, Thu Nguyen-Phuoc, Aljaz Bozic, Zhao Dong, Carl Marshall, Tobias Ritschel</strong></p><p>A Neural Radiance Field (NeRF) encodes the specific relation of 3D geometry and appearance of a scene. We here ask the question whether we can transfer the appearance from a source NeRF onto a target 3D geometry in a semantically meaningful way, such that the resulting new NeRF retains the target geometry but has an appearance that is an analogy to the source NeRF. To this end, we generalize classic image analogies from 2D images to NeRFs. We leverage correspondence transfer along semantic affinity that is driven by semantic features from large, pre-trained 2D image models to achieve multi-view consistent appearance transfer. Our method allows exploring the mix-and-match product space of 3D geometry and appearance. We show that our method outperforms traditional stylization-based methods and that a large majority of users prefer our method over several typical baselines. </p><p><a href="http://arxiv.org/abs/2402.08622v1">PDF</a> Project page: <a href="https://mfischer-ucl.github.io/nerf_analogies/">https://mfischer-ucl.github.io/nerf_analogies/</a></p><p><strong>Summary</strong><br>ç¥ç»è¾å°„åœº (NeRF) å¯å°†åœºæ™¯çš„ 3D å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚è¿›è¡Œç¼–ç ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>NeRF å¯ä»¥å°†æº NeRF ä¸­çš„å¤–è§‚è½¬ç§»åˆ°ç›®æ ‡ 3D å‡ ä½•å½¢çŠ¶ä¸Šï¼Œä»è€Œåˆ›å»ºå…·æœ‰ç›®æ ‡å‡ ä½•å½¢çŠ¶ä½†å¤–è§‚ç±»ä¼¼äºæº NeRF çš„æ–° NeRFã€‚</li><li>è¯¥æ–¹æ³•å°†ç»å…¸å›¾åƒç±»æ¯”ä» 2D å›¾åƒæ¨å¹¿åˆ° NeRFã€‚</li><li>åŸºäºè¯­ä¹‰äº²å’Œæ€§çš„å¯¹åº”è½¬ç§»ï¼Œç”±å¤§å‹é¢„è®­ç»ƒ 2D å›¾åƒæ¨¡å‹æä¾›çš„è¯­ä¹‰ç‰¹å¾é©±åŠ¨ï¼Œå¯å®ç°å¤šè§†å›¾ä¸€è‡´å¤–è§‚è½¬ç§»ã€‚</li><li>è¯¥æ–¹æ³•èƒ½å¤Ÿæ¢ç´¢ 3D å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚çš„æ··åˆåŒ¹é…äº§å“ç©ºé—´ã€‚</li><li>è¯¥æ–¹æ³•ä¼˜äºä¼ ç»Ÿçš„åŸºäºæ ·å¼åŒ–çš„æ–¹æ³•ã€‚</li><li>å¤§å¤šæ•°ç”¨æˆ·æ›´å–œæ¬¢è¯¥æ–¹æ³•ï¼Œè€Œä¸æ˜¯å…¶ä»–å‡ ç§å…¸å‹åŸºçº¿æ–¹æ³•ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šNeRF ç±»æ¯”ï¼šåŸºäºç¤ºä¾‹çš„ NeRF è§†è§‰å±æ€§è¿ç§»</li><li>ä½œè€…ï¼šMichael Fischerã€Zhengqin Liã€Thu Nguyen-Phuocã€AljaÅ¾ BoÅ¾iÄã€Zhao Dongã€Carl Marshallã€Tobias Ritschel</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¼¦æ•¦å¤§å­¦å­¦é™¢</li><li>å…³é”®è¯ï¼šNeRFã€è§†è§‰å±æ€§è¿ç§»ã€è¯­ä¹‰ç‰¹å¾ã€æ·±åº¦å­¦ä¹ </li><li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><li>æ‘˜è¦ï¼š</li></ol><p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRFï¼ˆç¥ç»è¾å°„åœºï¼‰æ˜¯ä¸€ç§ç”¨äºè¡¨ç¤ºå’Œæ¸²æŸ“ 3D åœºæ™¯çš„å¼ºå¤§æŠ€æœ¯ã€‚ç„¶è€Œï¼ŒNeRF é€šå¸¸éœ€è¦å¤§é‡æ•°æ®æ‰èƒ½è®­ç»ƒï¼Œå¹¶ä¸”éš¾ä»¥å°†ä»ä¸€ä¸ªåœºæ™¯å­¦åˆ°çš„å¤–è§‚è¿ç§»åˆ°å¦ä¸€ä¸ªåœºæ™¯ã€‚ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨åŸºäºæ ·å¼è¿ç§»çš„æŠ€æœ¯æ¥å°†ä¸€ç§åœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°å¦ä¸€ç§åœºæ™¯ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éš¾ä»¥äº§ç”Ÿè¯­ä¹‰ä¸Šè¿è´¯çš„ç»“æœï¼Œå¹¶ä¸”éœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå¯ä»¥å°†ä¸€ç§åœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°å¦ä¸€ç§åœºæ™¯ï¼Œè€Œæ— éœ€å¤§é‡çš„æ•°æ®ã€‚è¯¥æ–¹æ³•åˆ©ç”¨äº†é¢„è®­ç»ƒçš„ 2D å›¾åƒæ¨¡å‹ä¸­çš„è¯­ä¹‰ç‰¹å¾æ¥å»ºç«‹æºåœºæ™¯å’Œç›®æ ‡åœºæ™¯ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚ç„¶åï¼Œè¿™äº›å¯¹åº”å…³ç³»è¢«ç”¨æ¥å°†æºåœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°ç›®æ ‡åœºæ™¯ã€‚ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿäº§ç”Ÿè¯­ä¹‰ä¸Šè¿è´¯çš„ç»“æœï¼Œå¹¶ä¸”ä¼˜äºè¿‡å»çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºç”Ÿæˆæ–°çš„åœºæ™¯ï¼Œè¿™äº›åœºæ™¯å…·æœ‰æºåœºæ™¯çš„å¤–è§‚å’Œç›®æ ‡åœºæ™¯çš„å‡ ä½•å½¢çŠ¶ã€‚</p><p><methods>:(1)ï¼šæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„äºŒç»´å›¾åƒæ¨¡å‹ä¸­çš„è¯­ä¹‰ç‰¹å¾æ¥å»ºç«‹æºåœºæ™¯å’Œç›®æ ‡åœºæ™¯ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚(2)ï¼šç„¶åï¼Œè¿™äº›å¯¹åº”å…³ç³»è¢«ç”¨æ¥å°†æºåœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°ç›®æ ‡åœºæ™¯ã€‚(3)ï¼šæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªä¸‰ç»´ä¸€è‡´çš„NeRFè¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºåœ¨å…ˆå‰æå–çš„ç‚¹äº‘FSourceå’ŒFTargetä¸Šã€‚(4)ï¼šæˆ‘ä»¬é‡‡æ ·FSourceä¸­çš„ä½ç½®ï¼Œå¹¶åœ¨æ¯ä¸ªä½ç½®æå–æºç‰¹å¾æè¿°ç¬¦fSourceã€æºå¤–è§‚LSourceå’Œæºè§†å‘Ï‰Sourceã€‚(5)ï¼šæˆ‘ä»¬è¿˜ä»ç›®æ ‡ç‚¹äº‘FTargetä¸­é‡‡æ ·ä½ç½®ï¼Œå¹¶åœ¨æ¯ä¸ªä½ç½®è·å–å›¾åƒç‰¹å¾fTargetå’Œç›®æ ‡ä½ç½®xTargetã€‚(6)ï¼šæˆ‘ä»¬æ‰¾åˆ°ä¸€ä¸ªç¦»æ•£æ˜ å°„Ï•ï¼Œè¯¥æ˜ å°„å°†æ¯ä¸ªç›®æ ‡ä½ç½®ç´¢å¼•jæ˜ å°„åˆ°å…·æœ‰æœ€å¤§ç›¸ä¼¼æ€§çš„æºä½ç½®ç´¢å¼•iã€‚(7)ï¼šæˆ‘ä»¬å®šä¹‰LTargetj=LSourceÏ•jä½œä¸ºç›®æ ‡åœ¨æ˜ å°„Ï•å’ŒæŸä¸ªè§†å‘ä¸‹çš„å¤–è§‚ã€‚(8)ï¼šæˆ‘ä»¬è®­ç»ƒNeRF Analogy LÎ¸çš„å‚æ•°Î¸ï¼Œä½¿å¾—å¯¹äºæ¯ä¸ªè§‚å¯Ÿåˆ°çš„ç›®æ ‡ä½ç½®ï¼Œç›®æ ‡å’Œæºå¤–è§‚åœ¨æºè§†å‘ä¸‹ä¸€è‡´ã€‚</methods></p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé¦–æ¬¡æå‡ºäº† NeRF ç±»æ¯”ï¼Œä¸€ç§åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§çš„ NeRF è§†è§‰å±æ€§è¿ç§»æ¡†æ¶ã€‚è¯¥æ–¹æ³•å¯ä»¥è¾…åŠ©å†…å®¹åˆ›ä½œï¼Œä¾‹å¦‚ï¼Œé€šè¿‡å°†ç”¨æˆ·æ•è·çš„å‡ ä½•ä½“ä¸åœ¨çº¿ 3D æ¨¡å‹çš„å¤–è§‚ç›¸ç»“åˆï¼Œå¹¶ä¸”è¿˜é€‚ç”¨äºå¤šå¯¹è±¡è®¾ç½®å’ŒçœŸå®ä¸–ç•Œåœºæ™¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨é¢œè‰²è¿ç§»ã€å›¾åƒåˆæˆå’Œé£æ ¼åŒ–æ–‡çŒ®ä¸­çš„å…¶ä»–æ–¹æ³•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”åœ¨ç”¨æˆ·ç ”ç©¶ä¸­è·å¾—äº†æœ€é«˜çš„æ’åï¼Œæ— è®ºæ˜¯åœ¨è¿ç§»è´¨é‡è¿˜æ˜¯å¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§çš„ NeRF è§†è§‰å±æ€§è¿ç§»æ¡†æ¶ã€‚</li><li>è¯¥æ¡†æ¶å¯ä»¥ç”¨äºè¾…åŠ©å†…å®¹åˆ›ä½œã€å¤šå¯¹è±¡è®¾ç½®å’ŒçœŸå®ä¸–ç•Œåœºæ™¯ã€‚</li><li>è¯¥æ¡†æ¶åœ¨é¢œè‰²è¿ç§»ã€å›¾åƒåˆæˆå’Œé£æ ¼åŒ–æ–‡çŒ®ä¸­çš„å…¶ä»–æ–¹æ³•ä¸­è¡¨ç°å‡ºè‰²ã€‚æ€§èƒ½ï¼š</li><li>è¯¥æ¡†æ¶åœ¨ç”¨æˆ·ç ”ç©¶ä¸­è·å¾—äº†æœ€é«˜çš„æ’åï¼Œæ— è®ºæ˜¯åœ¨è¿ç§»è´¨é‡è¿˜æ˜¯å¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢ã€‚</li><li>è¯¥æ¡†æ¶å¯ä»¥ç”Ÿæˆè¯­ä¹‰ä¸Šè¿è´¯çš„ç»“æœï¼Œå¹¶ä¸”ä¼˜äºè¿‡å»çš„æ–¹æ³•ã€‚</li><li>è¯¥æ¡†æ¶è¿˜å¯ä»¥ç”¨äºç”Ÿæˆæ–°çš„åœºæ™¯ï¼Œè¿™äº›åœºæ™¯å…·æœ‰æºåœºæ™¯çš„å¤–è§‚å’Œç›®æ ‡åœºæ™¯çš„å‡ ä½•å½¢çŠ¶ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ¡†æ¶éœ€è¦é¢„è®­ç»ƒä¸€ä¸ª 2D å›¾åƒæ¨¡å‹æ¥æå–è¯­ä¹‰ç‰¹å¾ã€‚</li><li>è¯¥æ¡†æ¶éœ€è¦è®­ç»ƒä¸€ä¸ª 3D ä¸€è‡´çš„ NeRF è¡¨ç¤ºã€‚</li><li>è¯¥æ¡†æ¶éœ€è¦æ‰¾åˆ°ä¸€ä¸ªç¦»æ•£æ˜ å°„æ¥å°†æºåœºæ™¯å’Œç›®æ ‡åœºæ™¯ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚</li><li>è¯¥æ¡†æ¶éœ€è¦è®­ç»ƒä¸€ä¸ª NeRF ç±»æ¯”æ¨¡å‹æ¥å°†æºåœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°ç›®æ ‡åœºæ™¯ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-56d4edbaccc121abec3c1fbc5aa2a7b2.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-b96734ea48c9163e25bc72d32ad13598.jpg" align="middle"><img src="https://pica.zhimg.com/v2-d80da8fbb7f50a1faceaf09341a6dada.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-c35035cd1513fc1b8683c14a413721b5.jpg" align="middle"><img src="https://picx.zhimg.com/v2-190136188bdfd4cb8f04bafbfb9ef577.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">NeRF æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-23  Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="NeRF" scheme="https://kedreamix.github.io/tags/NeRF/"/>
    
  </entry>
  
  <entry>
    <title>3DGS</title>
    <link href="https://kedreamix.github.io/2024/02/23/Paper/2024-02-23/3DGS/"/>
    <id>https://kedreamix.github.io/2024/02/23/Paper/2024-02-23/3DGS/</id>
    <published>2024-02-22T17:38:45.000Z</published>
    <updated>2024-02-22T17:38:45.284Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p></blockquote><h1 id="2024-02-23-æ›´æ–°"><a href="#2024-02-23-æ›´æ–°" class="headerlink" title="2024-02-23 æ›´æ–°"></a>2024-02-23 æ›´æ–°</h1><h2 id="Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting"><a href="#Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting" class="headerlink" title="Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting"></a>Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting</h2><p><strong>Authors:Joongho Jo, Hyeongwon Kim, Jongsun Park</strong></p><p>3D Gaussian splatting (3D-GS) is a new rendering approach that outperforms the neural radiance field (NeRF) in terms of both speed and image quality. 3D-GS represents 3D scenes by utilizing millions of 3D Gaussians and projects these Gaussians onto the 2D image plane for rendering. However, during the rendering process, a substantial number of unnecessary 3D Gaussians exist for the current view direction, resulting in significant computation costs associated with their identification. In this paper, we propose a computational reduction technique that quickly identifies unnecessary 3D Gaussians in real-time for rendering the current view without compromising image quality. This is accomplished through the offline clustering of 3D Gaussians that are close in distance, followed by the projection of these clusters onto a 2D image plane during runtime. Additionally, we analyze the bottleneck associated with the proposed technique when executed on GPUs and propose an efficient hardware architecture that seamlessly supports the proposed scheme. For the Mip-NeRF360 dataset, the proposed technique excludes 63% of 3D Gaussians on average before the 2D image projection, which reduces the overall rendering computation by almost 38.3% without sacrificing peak-signal-to-noise-ratio (PSNR). The proposed accelerator also achieves a speedup of 10.7x compared to a GPU. </p><p><a href="http://arxiv.org/abs/2402.13827v1">PDF</a> </p><p><strong>Summary</strong><br>3D é«˜æ–¯æ•£splatting é€šè¿‡èšç±» å’Œ æŠ•å½±ä¼˜åŒ–ï¼Œå‡å°‘äº† 38.3% çš„æ¸²æŸ“è®¡ç®—ï¼Œä¸”ä¸æŸå¤±å›¾åƒè´¨é‡ã€‚</p><p><strong>Key Takeaways</strong></p><ul><li>3D é«˜æ–¯æ•£splattingï¼ˆ3D-GSï¼‰æ˜¯ä¸€ç§æ–°çš„æ¸²æŸ“æ–¹æ³•ï¼Œåœ¨é€Ÿåº¦å’Œå›¾åƒè´¨é‡ä¸Šä¼˜äºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ã€‚</li><li>3D-GS ä½¿ç”¨æ•°ç™¾ä¸‡ä¸ª 3D é«˜æ–¯è¡¨ç¤º 3D åœºæ™¯ï¼Œå¹¶å°†è¿™äº›é«˜æ–¯æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šè¿›è¡Œæ¸²æŸ“ã€‚</li><li>åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œå¤§é‡ä¸å¿…è¦çš„é«˜æ–¯å­˜åœ¨äºå½“å‰è§†å›¾æ–¹å‘ï¼Œå¯¼è‡´ä¸è¯†åˆ«å®ƒä»¬ç›¸å…³çš„è®¡ç®—æˆæœ¬å·¨å¤§ã€‚</li><li>æå‡ºäº†ä¸€ç§è®¡ç®—ç®€åŒ–æŠ€æœ¯ï¼Œå¯åœ¨è¿è¡Œæ—¶å¿«é€Ÿè¯†åˆ«å‡ºä¸å¿…è¦çš„é«˜æ–¯ï¼Œç”¨äºæ¸²æŸ“å½“å‰è§†å›¾ï¼Œä¸”ä¸æŸå®³å›¾åƒè´¨é‡ã€‚</li><li>è¿™ç§ç®€åŒ–æŠ€æœ¯æ–¹æ³•æ˜¯ç¦»çº¿å¯¹è·ç¦»ç›¸è¿‘çš„é«˜æ–¯è¿›è¡Œèšç±»ï¼Œç„¶ååœ¨è¿è¡Œæ—¶å°†è¿™äº›é›†ç¾¤æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šã€‚</li><li>å¯¹è¯¥æŠ€æœ¯åœ¨ GPU ä¸Šæ‰§è¡Œæ—¶çš„ç“¶é¢ˆè¿›è¡Œäº†åˆ†æï¼Œå¹¶æå‡ºäº†ä¸€ç§ä¸è¯¥æ–¹æ¡ˆæ— ç¼å…¼å®¹çš„é«˜æ•ˆç¡¬ä»¶æ¶æ„ã€‚</li><li>å¯¹äº Mip-NeRF360 æ•°æ®é›†ï¼Œè¯¥æŠ€æœ¯åœ¨ 2D å›¾åƒæŠ•å½±ä¹‹å‰å¹³å‡æ’é™¤äº† 63% çš„é«˜æ–¯ï¼Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº† 38.3%ï¼Œä¸”ä¸æŸå¤±å³°å€¼ä¿¡å™ªæ¯” (PSNR)ã€‚</li><li>è¯¥åŠ é€Ÿå™¨ä¸ GPU ç›¸æ¯”ï¼Œè¿˜å®ç°äº† 10.7 å€çš„åŠ é€Ÿã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šä½¿ç”¨èšç±»è¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œä»¥å¿«é€Ÿæ¸²æŸ“ 3D é«˜æ–¯ä½“é£æº…</li><li>ä½œè€…ï¼šJoongho Joã€Hyeongwon Kim å’Œ Jongsun Park</li><li>éš¶å±æœºæ„ï¼šéŸ©å›½å¤§å­¦ç”µæ°”å·¥ç¨‹å­¦é™¢</li><li>å…³é”®è¯ï¼š3D é«˜æ–¯ä½“é£æº…ã€æ¸²æŸ“ã€NeRFã€ç¥ç»è¾å°„åœºã€ç¡¬ä»¶åŠ é€Ÿå™¨</li><li>è®ºæ–‡é“¾æ¥ï¼šPaper_info:Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering of 3D Gaussian Splattingï¼ŒGithub é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š</li></ol><p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåœ¨è®¡ç®—æœºè§†è§‰åº”ç”¨ä¸­ï¼Œä¾‹å¦‚å¢å¼ºç°å® (AR)ã€è™šæ‹Ÿç°å® (VR) å’Œå…ƒå®‡å®™ï¼Œå¿«é€Ÿä¸”é«˜è´¨é‡çš„å›¾åƒæ¸²æŸ“éå¸¸é‡è¦ã€‚è™½ç„¶å·²ç»å¹¿æ³›ç ”ç©¶äº†ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œçš„æ¸²æŸ“æŠ€æœ¯ï¼Œä¾‹å¦‚ç¥ç»è¾å°„åœº (NeRF)ï¼Œä½† 3D é«˜æ–¯ä½“é£æº… (3D-GS) ä½œä¸ºä¸€ç§æ–°çš„æ¸²æŸ“æ–¹æ³•ï¼Œæœ€è¿‘å› å…¶ä¸ä¼ ç»Ÿ NeRF ç›¸æ¯”èƒ½å¤Ÿå¿«é€Ÿæ¸²æŸ“é«˜è´¨é‡å›¾åƒè€Œå¤‡å—å…³æ³¨ã€‚3D-GS åˆ©ç”¨æ•°ç™¾ä¸‡ä¸ª 3D é«˜æ–¯ä½“æ¥è¡¨ç¤ºå¤æ‚çš„ 3D åœºæ™¯ï¼Œå¹¶é€šè¿‡å°† 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šæ¥æ¸²æŸ“ 3D åœºæ™¯ã€‚</p><p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š3D-GS æ¸²æŸ“è¿‡ç¨‹ä¸»è¦åˆ†ä¸ºä¸¤æ­¥ï¼šé¦–å…ˆï¼Œå°†æ‰€æœ‰ 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œå¹¶è¯†åˆ«å½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“ã€‚ç„¶åï¼Œä½¿ç”¨å½±å“é¢œè‰²çš„å·²è¯†åˆ« 3D é«˜æ–¯ä½“è®¡ç®— 2D å›¾åƒä¸­æ¯ä¸ªåƒç´ çš„é¢œè‰²ã€‚åœ¨æ¸²æŸ“è¿‡ç¨‹çš„ç¬¬ä¸€æ­¥ä¸­ï¼Œé«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒä¸Šåï¼Œå¦‚æœè¢«è¯†åˆ«ä¸ºä¸å½±å“ 2D å›¾åƒçš„é¢œè‰²ï¼Œé‚£ä¹ˆæŠ•å½±å°±å˜æˆäº†è®¡ç®—æµªè´¹ã€‚åœ¨ Mip-NeRF360 æ•°æ®é›†ä¸­ï¼Œå¹³å‡çº¦æœ‰ 67.6% çš„ 3D é«˜æ–¯ä½“ä¸å½±å“ 2D å›¾åƒçš„é¢œè‰²ã€‚å› æ­¤ï¼Œè¿™äº›é«˜æ–¯ä½“å¯ä»¥ä»å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­æ’é™¤ã€‚ä½†æ˜¯ï¼Œç”±äºå½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“å¯èƒ½ä¼šéšç€æ¸²æŸ“è§†ç‚¹çš„æ–¹å‘å’Œä½ç½®è€Œæ”¹å˜ï¼Œå› æ­¤åœ¨å°† 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šä¹‹å‰è¯†åˆ«ä¸å¿…è¦çš„é«˜æ–¯ä½“ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å› æ­¤ï¼Œè¿™äº›ä¸å¿…è¦çš„é«˜æ–¯ä½“ä»ç„¶ä¼šè¿›è¡ŒæŠ•å½±è®¡ç®—ã€‚å› æ­¤ï¼Œå¦‚æœå¯ä»¥å¼€å‘å‡ºä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•æ¥é¢„æµ‹ä¸ä¼šå½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“ï¼Œå¹¶åœ¨æ¸²æŸ“è¿‡ç¨‹å¼€å§‹ä¹‹å‰å°†å®ƒä»¬æ’é™¤ï¼Œé‚£ä¹ˆå¯ä»¥æ˜¾ç€é™ä½æ•´ä¸ª 3D-GS è¿‡ç¨‹çš„æ€»ä½“è®¡ç®—å¤æ‚åº¦ã€‚</p><p>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ¡ˆï¼Œé€šè¿‡è¯†åˆ«ä¸å½±å“ 2D å›¾åƒé¢œè‰²çš„ç°‡æ¥æ’é™¤å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­çš„ä¸å¿…è¦ 3D é«˜æ–¯ä½“ã€‚èšç±»çš„ç›®æ ‡æ˜¯å°†ä½ç½®ç›¸è¿‘çš„ 3D é«˜æ–¯ä½“åˆ†ç»„åœ¨ä¸€èµ·ï¼Œå¹¶ä¸”ç°‡çš„å½¢çŠ¶åº”è¯¥æ˜¯çƒå½¢çš„ï¼Œä»¥ä¾¿äºæŠ•å½±åˆ° 2D å›¾åƒä¸Šã€‚å› æ­¤ï¼Œæœ¬æ–‡é‡‡ç”¨ K-means èšç±»ç®—æ³•ï¼Œè¯¥ç®—æ³•æ»¡è¶³è¿™ä¸¤ä¸ªæ ‡å‡†ã€‚è€ƒè™‘åˆ° 3D é«˜æ–¯ä½“å…·æœ‰ç”±å…¶åæ–¹å·®å®šä¹‰çš„å¤§å°æˆ–å½±å“ï¼Œç°‡çƒä½“çš„åŠå¾„ä¸ä»…ç”±åˆ°ç°‡è´¨å¿ƒçš„è·ç¦»ç¡®å®šï¼Œè¿˜è¦è€ƒè™‘é«˜æ–¯ä½“çš„å¤§å°ã€‚ç„¶åå°†è¿™äº›å®šä¹‰çš„ç°‡çƒä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œä»¥ç¡®å®šå®ƒä»¬å¯¹ 2D å›¾åƒé¢œè‰²çš„å½±å“ã€‚ä¸å½±å“å›¾åƒé¢œè‰²çš„ç°‡å¯ä»¥ä»æ¸²æŸ“è¿‡ç¨‹ä¸­æ’é™¤ã€‚åœ¨æœ¬æ–‡çš„æ–¹æ³•ä¸­ï¼Œå¯ä»¥åœ¨ç¦»çº¿æ‰§è¡Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„ï¼Œå¹¶ä¸”ä»…åœ¨å®æ—¶æ‰§è¡Œå°†ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œè¿™ä»…éœ€ 6.2% çš„è®¡ç®—å¼€é”€ã€‚åœ¨ 3D-GS æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œåœ¨å½“å‰è§†å›¾æ¸²æŸ“ä¹‹å‰åº”ç”¨æ‰€æå‡ºçš„æ–¹æ³•æ—¶ï¼Œå¹³å‡å¯ä»¥æ’é™¤ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œåœ¨ä¸ç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR) çš„æƒ…å†µä¸‹å°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ã€‚æ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†ä¸ GPU ç›¸æ¯” 10.7 å€çš„åŠ é€Ÿã€‚</p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨ Mip-NeRF360 æ•°æ®é›†ä¸Šï¼Œæ‰€æå‡ºçš„æ–¹æ³•å¹³å‡æ’é™¤äº† 63% çš„ 3D é«˜æ–¯ä½“ï¼Œåœ¨ä¸ç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR) çš„æƒ…å†µä¸‹å°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ã€‚æ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†ä¸ GPU ç›¸æ¯” 10.7 å€çš„åŠ é€Ÿã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å¿«é€Ÿä¸”é«˜è´¨é‡åœ°æ¸²æŸ“ 3D åœºæ™¯ã€‚</p><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ¡ˆï¼Œé€šè¿‡è¯†åˆ«ä¸å½±å“ 2D å›¾åƒé¢œè‰²çš„ç°‡æ¥æ’é™¤å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­çš„ä¸å¿…è¦ 3D é«˜æ–¯ä½“ã€‚è¯¥æ–¹æ³•å¹³å‡å¯ä»¥æ’é™¤ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œåœ¨ä¸ç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR) çš„æƒ…å†µä¸‹å°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ã€‚æ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†ä¸ GPU ç›¸æ¯” 10.7 å€çš„åŠ é€Ÿã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><li>æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ¡ˆæ¥è¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ã€‚</li><li>è¯¥æ–¹æ³•å¯ä»¥ç¦»çº¿æ‰§è¡Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„ï¼Œå¹¶ä¸”ä»…åœ¨å®æ—¶æ‰§è¡Œå°†ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œè¿™ä»…éœ€ 6.2% çš„è®¡ç®—å¼€é”€ã€‚</li><li>æ‰€æå‡ºçš„åŠ é€Ÿå™¨å®ç°äº†ä¸ GPU ç›¸æ¯” 10.7 å€çš„åŠ é€Ÿã€‚æ€§èƒ½ï¼š</li><li>åœ¨ Mip-NeRF360 æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å¹³å‡æ’é™¤äº† 63% çš„ 3D é«˜æ–¯ä½“ï¼Œåœ¨ä¸ç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR) çš„æƒ…å†µä¸‹å°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥æ–¹æ³•å¯ä»¥åœ¨ç¦»çº¿æ‰§è¡Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„ï¼Œå¹¶ä¸”ä»…åœ¨å®æ—¶æ‰§è¡Œå°†ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œè¿™ä»…éœ€ 6.2% çš„è®¡ç®—å¼€é”€ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-eb8532b7f44bd3308c4f19fe6bf7f78c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-8e5e9d849dcc9fd5228abd36df009311.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-8a43367bbb6924d5ba043f598753b956.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d13d1af17267a2b843bea8ac607b39a9.jpg" align="middle"><img src="https://picx.zhimg.com/v2-bca1cf3d857e2d53600b33fc6c9e298c.jpg" align="middle"><img src="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-ee494dce0084e0f0c71d55d940b03dc9.jpg" align="middle"></details><h2 id="GaussianObject-Just-Taking-Four-Images-to-Get-A-High-Quality-3D-Object-with-Gaussian-Splatting"><a href="#GaussianObject-Just-Taking-Four-Images-to-Get-A-High-Quality-3D-Object-with-Gaussian-Splatting" class="headerlink" title="GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object   with Gaussian Splatting"></a>GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object   with Gaussian Splatting</h2><p><strong>Authors:Chen Yang, Sikuang Li, Jiemin Fang, Ruofan Liang, Lingxi Xie, Xiaopeng Zhang, Wei Shen, Qi Tian</strong></p><p>Reconstructing and rendering 3D objects from highly sparse views is of critical importance for promoting applications of 3D vision techniques and improving user experience. However, images from sparse views only contain very limited 3D information, leading to two significant challenges: 1) Difficulty in building multi-view consistency as images for matching are too few; 2) Partially omitted or highly compressed object information as view coverage is insufficient. To tackle these challenges, we propose GaussianObject, a framework to represent and render the 3D object with Gaussian splatting, that achieves high rendering quality with only 4 input images. We first introduce techniques of visual hull and floater elimination which explicitly inject structure priors into the initial optimization process for helping build multi-view consistency, yielding a coarse 3D Gaussian representation. Then we construct a Gaussian repair model based on diffusion models to supplement the omitted object information, where Gaussians are further refined. We design a self-generating strategy to obtain image pairs for training the repair model. Our GaussianObject is evaluated on several challenging datasets, including MipNeRF360, OmniObject3D, and OpenIllumination, achieving strong reconstruction results from only 4 views and significantly outperforming previous state-of-the-art methods. </p><p><a href="http://arxiv.org/abs/2402.10259v2">PDF</a> Project page: <a href="https://gaussianobject.github.io/">https://gaussianobject.github.io/</a></p><p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨ä»…æœ‰ 4 å¼ è¾“å…¥å›¾åƒï¼Œä»¥é«˜æ–¯æ•£ç‚¹å›¾è¡¨ç¤ºå’Œæ¸²æŸ“ä¸‰ç»´å¯¹è±¡ï¼Œå±•ç°å‡ºæä½³çš„æ¸²æŸ“è´¨é‡ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>é‡å»ºå’Œæ¸²æŸ“é«˜åº¦ç¨€ç–è§†å›¾çš„ 3D å¯¹è±¡å¯¹äºä¿ƒè¿› 3D è§†è§‰æŠ€æœ¯åº”ç”¨å’Œæ”¹å–„ç”¨æˆ·ä½“éªŒè‡³å…³é‡è¦ã€‚</li><li>æå‡º GaussianObjectï¼Œä¸€ç§ä»¥é«˜æ–¯æ•£ç‚¹å›¾è¡¨ç¤ºå’Œæ¸²æŸ“ 3D å¯¹è±¡çš„æ¡†æ¶ï¼Œä»…éœ€ 4 å¼ è¾“å…¥å›¾åƒå³å¯å®ç°é«˜æ¸²æŸ“è´¨é‡ã€‚</li><li>å¼•å…¥è§†è§‰å¤–å£³å’Œæµ®å­æ¶ˆé™¤æŠ€æœ¯ï¼Œå°†ç»“æ„å…ˆéªŒæ˜ç¡®æ³¨å…¥åˆå§‹ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¸®åŠ©å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ï¼Œäº§ç”Ÿç²—ç³™çš„ 3D é«˜æ–¯è¡¨ç¤ºã€‚</li><li>åŸºäºæ‰©æ•£æ¨¡å‹æ„å»ºé«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥è¡¥å……çœç•¥çš„å¯¹è±¡ä¿¡æ¯ï¼Œå…¶ä¸­é«˜æ–¯å€¼è¿›ä¸€æ­¥ç»†åŒ–ã€‚</li><li>è®¾è®¡äº†ä¸€ç§è‡ªç”Ÿæˆç­–ç•¥æ¥è·å–å›¾åƒå¯¹ï¼Œä»¥è®­ç»ƒä¿®å¤æ¨¡å‹ã€‚</li><li>åœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šè¯„ä¼°äº† GaussianObjectï¼ŒåŒ…æ‹¬ MipNeRF360ã€OmniObject3D å’Œ OpenIlluminationï¼Œä»…ä½¿ç”¨ 4 ä¸ªè§†å›¾å³å¯å®ç°å¼ºå¤§çš„é‡å»ºç»“æœï¼Œå¹¶ä¸”æ˜æ˜¾ä¼˜äºå…ˆå‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šé«˜æ–¯å¯¹è±¡ï¼šåªéœ€å››å¼ å›¾åƒå³å¯è·å–é«˜è´¨é‡çš„ 3D å¯¹è±¡</li><li>ä½œè€…ï¼šé™ˆé˜³ï¼Œææ€å®½ï¼Œæ–¹æ°æ°‘ï¼Œæ¢è‹¥å‡¡ï¼Œè°¢å‡Œå¸Œï¼Œå¼ æ™“é¹ï¼Œæ²ˆå·ï¼Œç”°é½</li><li>å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li><li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€3D é‡å»ºã€ç¨€ç–è§†å›¾ã€é«˜æ–¯çƒé¢ä½“</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.10259ï¼ŒGithub é“¾æ¥ï¼šNone</li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šé‡å»ºå’Œæ¸²æŸ“ 3D å¯¹è±¡æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„é‡è¦è¯¾é¢˜ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡è§†å›¾æ‰èƒ½è·å¾—é«˜è´¨é‡çš„ç»“æœã€‚è¿™å¯¹äºç”¨æˆ·æ¥è¯´éå¸¸ç¹çï¼Œé™åˆ¶äº† 3D æŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ã€‚ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šä¸€äº›ç ”ç©¶å°è¯•å‡å°‘å¯¹å¯†é›†æ•è·çš„ä¾èµ–ï¼Œä½†å½“è§†å›¾å˜å¾—æåº¦ç¨€ç–æ—¶ï¼Œä»ç„¶éš¾ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ 3D å¯¹è±¡ã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äºéš¾ä»¥å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ï¼Œä»¥åŠéƒ¨åˆ†ç¼ºå¤±æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯ã€‚ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºé«˜æ–¯å¯¹è±¡çš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨ä»ç¨€ç–è§†å›¾ä¸­é‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ã€‚è¯¥æ¡†æ¶ä½¿ç”¨ 3D é«˜æ–¯çƒé¢ä½“ä½œä¸ºåŸºæœ¬è¡¨ç¤ºï¼Œå¹¶è®¾è®¡äº†å‡ ç§æŠ€æœ¯æ¥å¼•å…¥å¯¹è±¡ç»“æ„å…ˆéªŒï¼Œå¸®åŠ©å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„é«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥æ¶ˆé™¤ç”±ç¼ºå¤±æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯å¼•èµ·çš„ä¼ªå½±ã€‚ï¼ˆ4ï¼‰æ€§èƒ½è¡¨ç°ï¼šé«˜æ–¯å¯¹è±¡æ–¹æ³•åœ¨å‡ ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œåœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­å‡ä¼˜äºä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»ç¨€ç–è§†å›¾ä¸­é‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ã€‚</p></li><li><p>æ–¹æ³•ï¼š(1) é«˜æ–¯çƒé¢ä½“è¡¨ç¤ºï¼šå°†3Då¯¹è±¡è¡¨ç¤ºä¸ºä¸€ä¸ª3Dé«˜æ–¯çƒé¢ä½“ï¼Œè¯¥çƒé¢ä½“ç”±ä¸€ç³»åˆ—3Dé«˜æ–¯åˆ†å¸ƒç»„æˆã€‚æ¯ä¸ªé«˜æ–¯åˆ†å¸ƒå¯¹åº”äºå¯¹è±¡çš„ä¸€ä¸ªå±€éƒ¨åŒºåŸŸï¼Œå…¶å‚æ•°ï¼ˆä¸­å¿ƒä½ç½®ã€å°ºåº¦å’Œæƒé‡ï¼‰ç”±ç¥ç»ç½‘ç»œå­¦ä¹ å¾—åˆ°ã€‚(2) ç»“æ„å…ˆéªŒå¼•å…¥ï¼šè®¾è®¡äº†å‡ ç§æŠ€æœ¯æ¥å¼•å…¥å¯¹è±¡ç»“æ„å…ˆéªŒï¼Œå¸®åŠ©å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ã€‚è¿™äº›æŠ€æœ¯åŒ…æ‹¬ï¼š</p><ul><li>å½¢çŠ¶æ­£åˆ™åŒ–ï¼šä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„å½¢çŠ¶ç”Ÿæˆæ¨¡å‹æ¥æ­£åˆ™åŒ–é«˜æ–¯çƒé¢ä½“çš„å½¢çŠ¶ï¼Œä½¿å…¶æ›´åŠ çœŸå®å’Œè‡ªç„¶ã€‚</li><li>æ‹“æ‰‘æ­£åˆ™åŒ–ï¼šä½¿ç”¨ä¸€ä¸ªæ‹“æ‰‘ç”Ÿæˆæ¨¡å‹æ¥æ­£åˆ™åŒ–é«˜æ–¯çƒé¢ä½“çš„æ‹“æ‰‘ç»“æ„ï¼Œä½¿å…¶æ›´åŠ è¿é€šå’Œå®Œæ•´ã€‚</li><li>è¯­ä¹‰æ­£åˆ™åŒ–ï¼šä½¿ç”¨ä¸€ä¸ªè¯­ä¹‰åˆ†å‰²æ¨¡å‹æ¥æ­£åˆ™åŒ–é«˜æ–¯çƒé¢ä½“çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä½¿å…¶æ›´åŠ å‡†ç¡®å’Œä¸€è‡´ã€‚(3) é«˜æ–¯ä¿®å¤æ¨¡å‹ï¼šæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„é«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥æ¶ˆé™¤ç”±ç¼ºå¤±æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯å¼•èµ·çš„ä¼ªå½±ã€‚è¯¥æ¨¡å‹é€šè¿‡è¿­ä»£åœ°æ‰©æ•£å’Œæ¢å¤é«˜æ–¯çƒé¢ä½“çš„å‚æ•°ï¼Œé€æ­¥æ¶ˆé™¤ä¼ªå½±å¹¶ç”Ÿæˆé«˜è´¨é‡çš„3Då¯¹è±¡ã€‚</li></ul></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šé«˜æ–¯å¯¹è±¡æ˜¯ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä»æåº¦ç¨€ç–çš„ 360Â° è§†å›¾ä¸­é‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ï¼Œè¯¥æ¡†æ¶åŸºäº 3D é«˜æ–¯çƒé¢ä½“ï¼Œå¹¶å…·æœ‰å®æ—¶çš„æ¸²æŸ“èƒ½åŠ›ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸¤ç§ä¸»è¦æ–¹æ³•æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼šè¾…åŠ©ç»“æ„å…ˆéªŒçš„ä¼˜åŒ–ï¼Œä»¥ä¿ƒè¿›å¤šè§†å›¾ä¸€è‡´æ€§çš„æ„å»ºï¼Œä»¥åŠé«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥å»é™¤ç”±é—æ¼æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯å¼•èµ·çš„ä¼ªå½±ã€‚æˆ‘ä»¬å¸Œæœ›é«˜æ–¯å¯¹è±¡èƒ½å¤Ÿæ¨è¿›é‡å»º 3D å¯¹è±¡çš„æ—¥å¸¸åº”ç”¨ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>æå‡ºäº†ä¸€ç§æ–°çš„ 3D å¯¹è±¡è¡¨ç¤ºå½¢å¼â€”â€”é«˜æ–¯çƒé¢ä½“ï¼Œè¯¥è¡¨ç¤ºå½¢å¼èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•è·å¯¹è±¡çš„å½¢çŠ¶ã€æ‹“æ‰‘ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚</li><li>è®¾è®¡äº†å‡ ç§æŠ€æœ¯æ¥å¼•å…¥å¯¹è±¡ç»“æ„å…ˆéªŒï¼Œå¸®åŠ©å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ï¼ŒåŒ…æ‹¬å½¢çŠ¶æ­£åˆ™åŒ–ã€æ‹“æ‰‘æ­£åˆ™åŒ–å’Œè¯­ä¹‰æ­£åˆ™åŒ–ã€‚</li><li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„é«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥æ¶ˆé™¤ç”±ç¼ºå¤±æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯å¼•èµ·çš„ä¼ªå½±ã€‚æ€§èƒ½ï¼š</li><li>åœ¨å‡ ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼Œé«˜æ–¯å¯¹è±¡æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­å‡ä¼˜äºä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</li><li>é«˜æ–¯å¯¹è±¡æ–¹æ³•èƒ½å¤Ÿä»æåº¦ç¨€ç–çš„ 360Â° è§†å›¾ä¸­é‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ï¼Œè¿™å¯¹äºç”¨æˆ·æ¥è¯´éå¸¸æ–¹ä¾¿ï¼Œå¹¶ä¸”å¯ä»¥å¹¿æ³›åº”ç”¨äºå„ç§é¢†åŸŸã€‚å·¥ä½œé‡ï¼š</li><li>é«˜æ–¯å¯¹è±¡æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®­ç»ƒæ—¶é—´å’Œæˆæœ¬ã€‚</li><li>é«˜æ–¯å¯¹è±¡æ–¹æ³•éœ€è¦ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥å­¦ä¹ é«˜æ–¯çƒé¢ä½“çš„å‚æ•°ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®¡ç®—å¤æ‚åº¦ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-ec0859f0d4156531b928896ce0f20711.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-a6cf586e290dad38d6317bf5e32650f6.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-fc6b9cc2318a136451091ab1f1c68efb.jpg" align="middle"><img src="https://pica.zhimg.com/v2-0ee843ee1e2c5a9e509cc05d4936f7f7.jpg" align="middle"><img src="https://picx.zhimg.com/v2-de6acbb2bc7ce290268eb48c8af2cb6b.jpg" align="middle"></details><h2 id="GES-Generalized-Exponential-Splatting-for-Efficient-Radiance-Field-Rendering"><a href="#GES-Generalized-Exponential-Splatting-for-Efficient-Radiance-Field-Rendering" class="headerlink" title="GES: Generalized Exponential Splatting for Efficient Radiance Field   Rendering"></a>GES: Generalized Exponential Splatting for Efficient Radiance Field   Rendering</h2><p><strong>Authors:Abdullah Hamdi, Luke Melas-Kyriazi, Guocheng Qian, Jinjie Mai, Ruoshi Liu, Carl Vondrick, Bernard Ghanem, Andrea Vedaldi</strong></p><p>Advancements in 3D Gaussian Splatting have significantly accelerated 3D reconstruction and generation. However, it may require a large number of Gaussians, which creates a substantial memory footprint. This paper introduces GES (Generalized Exponential Splatting), a novel representation that employs Generalized Exponential Function (GEF) to model 3D scenes, requiring far fewer particles to represent a scene and thus significantly outperforming Gaussian Splatting methods in efficiency with a plug-and-play replacement ability for Gaussian-based utilities. GES is validated theoretically and empirically in both principled 1D setup and realistic 3D scenes.   It is shown to represent signals with sharp edges more accurately, which are typically challenging for Gaussians due to their inherent low-pass characteristics. Our empirical analysis demonstrates that GEF outperforms Gaussians in fitting natural-occurring signals (e.g. squares, triangles, and parabolic signals), thereby reducing the need for extensive splitting operations that increase the memory footprint of Gaussian Splatting. With the aid of a frequency-modulated loss, GES achieves competitive performance in novel-view synthesis benchmarks while requiring less than half the memory storage of Gaussian Splatting and increasing the rendering speed by up to 39%. The code is available on the project website <a href="https://abdullahamdi.com/ges">https://abdullahamdi.com/ges</a> . </p><p><a href="http://arxiv.org/abs/2402.10128v1">PDF</a> preprint</p><p><strong>æ‘˜è¦</strong><br>å¹¿ä¹‰æŒ‡æ•°æ•£åˆ—æ³•ï¼ˆGESï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„ 3D åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•° (GEF) å¯¹ 3D åœºæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œæ˜¾è‘—å‡å°‘äº†è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œæ¯”é«˜æ–¯æ•£åˆ—æ–¹æ³•æ›´åŠ é«˜æ•ˆï¼Œå¹¶ä¸”å³æ’å³ç”¨ï¼Œå¯ä»¥æ›¿ä»£åŸºäºé«˜æ–¯çš„å·¥å…·ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>GES ä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•° (GEF) å¯¹ 3D åœºæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œæ˜¾è‘—å‡å°‘äº†æ‰€éœ€ç²’å­æ•°é‡ï¼Œæé«˜äº†æ•ˆç‡ã€‚</li><li>GES ä¼˜äºé«˜æ–¯æ•£åˆ—æ³•ï¼Œèƒ½å¤Ÿå°† 3D åœºæ™¯å»ºæ¨¡ä¸ºæ›´å°‘çš„ç²’å­ï¼Œåœ¨æ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºé«˜æ–¯æ•£åˆ—æ³•ã€‚</li><li>GES åœ¨åŸç†æ€§çš„ä¸€ç»´è®¾ç½®å’Œç°å®çš„ 3D åœºæ™¯ä¸­ç»è¿‡ç†è®ºå’Œç»éªŒéªŒè¯ã€‚</li><li>GES åœ¨è¡¨è¾¾å…·æœ‰æ¸…æ™°è¾¹ç¼˜çš„ä¿¡å·æ–¹é¢æ›´å‡†ç¡®ï¼Œè€Œè¿™äº›ä¿¡å·é€šå¸¸å¯¹é«˜æ–¯å‡½æ•°æ„æˆæŒ‘æˆ˜ï¼Œå› å…¶æœ¬èº«å…·æœ‰ä½é€šç‰¹æ€§ã€‚</li><li>GES åœ¨æ‹Ÿåˆè‡ªç„¶å‘ç”Ÿçš„ä¿¡å·ï¼ˆä¾‹å¦‚æ­£æ–¹å½¢ã€ä¸‰è§’å½¢å’ŒæŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œå› è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£åˆ—æ³•çš„å†…å­˜å ç”¨çš„å¤§é‡åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚</li><li>ä½¿ç”¨è°ƒåˆ¶é¢‘ç‡æŸå¤±ï¼ŒGES å¯å®ç°åœ¨æ–°è§†å›¾åˆæˆåŸºå‡†ä¸­å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å­˜å‚¨ç©ºé—´ä¸åˆ°é«˜æ–¯æ•£åˆ—æ³•çš„äºŒåˆ†ä¹‹ä¸€ï¼Œå¹¶ä½¿æ¸²æŸ“é€Ÿåº¦æé«˜å¤šè¾¾ 39%ã€‚</li><li>GES çš„ä»£ç å¯åœ¨é¡¹ç›®ç½‘ç«™ <a href="https://abdullahamdi.com/ges">https://abdullahamdi.com/ges</a> ä¸Šè·å–ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šGESï¼šç”¨äºé«˜æ•ˆå…‰åœºæ¸²æŸ“çš„å¹¿ä¹‰æŒ‡æ•°æ•£å°„ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰</li><li>ä½œè€…ï¼šAbdullah Hamdiã€Luke Melas-Kyriaziã€Guocheng Qianã€Jinjie Maiã€Ruoshi Liuã€Carl Vondrickã€Bernard Ghanemã€Andrea Vedaldi</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šç‰›æ´¥å¤§å­¦è§†è§‰å‡ ä½•ç»„ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰</li><li>å…³é”®è¯ï¼š3D é‡å»ºã€3D ç”Ÿæˆã€3D è¡¨ç¤ºã€å…‰åœºæ¸²æŸ“ã€å¹¿ä¹‰æŒ‡æ•°å‡½æ•°</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.10128ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D é«˜æ–¯æ•£å°„åœ¨ 3D é‡å»ºå’Œç”Ÿæˆæ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œå®ƒå¯èƒ½éœ€è¦å¤§é‡é«˜æ–¯å‡½æ•°ï¼Œè¿™ä¼šé€ æˆå·¨å¤§çš„å†…å­˜å ç”¨ã€‚ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šé«˜æ–¯æ•£å°„æ–¹æ³•å‡è®¾åœºæ™¯ä¿¡å·æ˜¯ä½é€šçš„ï¼Œä½†å¤§å¤šæ•° 3D åœºæ™¯éƒ½åŒ…å«å½¢çŠ¶å’Œå¤–è§‚ä¸Šçš„çªå˜ï¼Œå› æ­¤é«˜æ–¯æ•£å°„éœ€è¦ä½¿ç”¨å¤§é‡éå¸¸å°çš„é«˜æ–¯å‡½æ•°æ¥è¡¨ç¤ºè¿™äº› 3D åœºæ™¯ï¼Œè¿™ä¼šå¯¹å†…å­˜åˆ©ç”¨ç‡äº§ç”Ÿè´Ÿé¢å½±å“ã€‚ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º GESï¼ˆå¹¿ä¹‰æŒ‡æ•°æ•£å°„ï¼‰ï¼Œå®ƒä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•°ï¼ˆå…·æœ‰é¢å¤–çš„å¯å­¦ä¹ å½¢çŠ¶å‚æ•°ï¼‰æ¥å»ºæ¨¡ 3D åœºæ™¯ï¼Œä»è€Œå¯ä»¥å‡å°‘è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œä»è€Œåœ¨æ•ˆç‡ä¸Šæ˜æ˜¾ä¼˜äºé«˜æ–¯æ•£å°„æ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥å³æ’å³ç”¨åœ°æ›¿æ¢åŸºäºé«˜æ–¯çš„å®ç”¨å·¥å…·ã€‚ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¿™äº›æ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼šGES åœ¨åŸç†æ€§ 1D è®¾ç½®å’Œé€¼çœŸçš„ 3D åœºæ™¯ä¸­éƒ½å¾—åˆ°äº†ç†è®ºå’Œç»éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œå®ƒå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºå…·æœ‰é”åˆ©è¾¹ç¼˜çš„ä¿¡å·ï¼Œè€Œè¿™å¯¹äºé«˜æ–¯å‡½æ•°æ¥è¯´é€šå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å›ºæœ‰çš„ä½é€šç‰¹æ€§ã€‚å®è¯åˆ†æè¡¨æ˜ï¼ŒGES åœ¨æ‹Ÿåˆè‡ªç„¶å‡ºç°çš„ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œæ­£æ–¹å½¢ã€ä¸‰è§’å½¢ã€æŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œä»è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£å°„å†…å­˜å ç”¨ç‡çš„å¹¿æ³›åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚åœ¨é¢‘ç‡è°ƒåˆ¶æŸå¤±çš„å¸®åŠ©ä¸‹ï¼ŒGES åœ¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å†…å­˜å­˜å‚¨é‡ä¸åˆ°é«˜æ–¯æ•£å°„çš„ä¸€åŠï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æé«˜äº† 39%ã€‚</li></ol><p><methods>:(1): GESä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•°ï¼ˆå…·æœ‰é¢å¤–çš„å¯å­¦ä¹ å½¢çŠ¶å‚æ•°ï¼‰æ¥å»ºæ¨¡3Dåœºæ™¯ï¼Œä»è€Œå¯ä»¥å‡å°‘è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œä»è€Œåœ¨æ•ˆç‡ä¸Šæ˜æ˜¾ä¼˜äºé«˜æ–¯æ•£å°„æ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥å³æ’å³ç”¨åœ°æ›¿æ¢åŸºäºé«˜æ–¯çš„å®ç”¨å·¥å…·ã€‚(2): GESåœ¨åŸç†æ€§1Dè®¾ç½®å’Œé€¼çœŸçš„3Dåœºæ™¯ä¸­éƒ½å¾—åˆ°äº†ç†è®ºå’Œç»éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œå®ƒå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºå…·æœ‰é”åˆ©è¾¹ç¼˜çš„ä¿¡å·ï¼Œè€Œè¿™å¯¹äºé«˜æ–¯å‡½æ•°æ¥è¯´é€šå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å›ºæœ‰çš„ä½é€šç‰¹æ€§ã€‚(3): å®è¯åˆ†æè¡¨æ˜ï¼ŒGESåœ¨æ‹Ÿåˆè‡ªç„¶å‡ºç°çš„ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œæ­£æ–¹å½¢ã€ä¸‰è§’å½¢ã€æŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œä»è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£å°„å†…å­˜å ç”¨ç‡çš„å¹¿æ³›åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚(4): åœ¨é¢‘ç‡è°ƒåˆ¶æŸå¤±çš„å¸®åŠ©ä¸‹ï¼ŒGESåœ¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å†…å­˜å­˜å‚¨é‡ä¸åˆ°é«˜æ–¯æ•£å°„çš„ä¸€åŠï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æé«˜äº†39%ã€‚</methods></p><ol><li>ç»“è®ºï¼š(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å…‰åœºæ¸²æŸ“æ–¹æ³• GESï¼Œå®ƒä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•°æ¥å»ºæ¨¡ 3D åœºæ™¯ï¼Œä»è€Œå¯ä»¥å‡å°‘è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œä»è€Œåœ¨æ•ˆç‡ä¸Šæ˜æ˜¾ä¼˜äºé«˜æ–¯æ•£å°„æ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥å³æ’å³ç”¨åœ°æ›¿æ¢åŸºäºé«˜æ–¯çš„å®ç”¨å·¥å…·ã€‚(2): åˆ›æ–°ç‚¹ï¼š</li><li>GES ä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•°æ¥å»ºæ¨¡ 3D åœºæ™¯ï¼Œä»è€Œå¯ä»¥å‡å°‘è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œä»è€Œåœ¨æ•ˆç‡ä¸Šæ˜æ˜¾ä¼˜äºé«˜æ–¯æ•£å°„æ–¹æ³•ã€‚</li><li>GES åœ¨åŸç†æ€§ 1D è®¾ç½®å’Œé€¼çœŸçš„ 3D åœºæ™¯ä¸­éƒ½å¾—åˆ°äº†ç†è®ºå’Œç»éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œå®ƒå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºå…·æœ‰é”åˆ©è¾¹ç¼˜çš„ä¿¡å·ï¼Œè€Œè¿™å¯¹äºé«˜æ–¯å‡½æ•°æ¥è¯´é€šå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å›ºæœ‰çš„ä½é€šç‰¹æ€§ã€‚</li><li>å®è¯åˆ†æè¡¨æ˜ï¼ŒGES åœ¨æ‹Ÿåˆè‡ªç„¶å‡ºç°çš„ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œæ­£æ–¹å½¢ã€ä¸‰è§’å½¢ã€æŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œä»è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£å°„å†…å­˜å ç”¨ç‡çš„å¹¿æ³›åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚</li><li>åœ¨é¢‘ç‡è°ƒåˆ¶æŸå¤±çš„å¸®åŠ©ä¸‹ï¼ŒGES åœ¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å†…å­˜å­˜å‚¨é‡ä¸åˆ°é«˜æ–¯æ•£å°„çš„ä¸€åŠï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æé«˜äº† 39%ã€‚æ€§èƒ½ï¼š</li><li>GES åœ¨åŸç†æ€§ 1D è®¾ç½®å’Œé€¼çœŸçš„ 3D åœºæ™¯ä¸­éƒ½å¾—åˆ°äº†ç†è®ºå’Œç»éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œå®ƒå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºå…·æœ‰é”åˆ©è¾¹ç¼˜çš„ä¿¡å·ï¼Œè€Œè¿™å¯¹äºé«˜æ–¯å‡½æ•°æ¥è¯´é€šå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å›ºæœ‰çš„ä½é€šç‰¹æ€§ã€‚</li><li>å®è¯åˆ†æè¡¨æ˜ï¼ŒGES åœ¨æ‹Ÿåˆè‡ªç„¶å‡ºç°çš„ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œæ­£æ–¹å½¢ã€ä¸‰è§’å½¢ã€æŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œä»è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£å°„å†…å­˜å ç”¨ç‡çš„å¹¿æ³›åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚</li><li>åœ¨é¢‘ç‡è°ƒåˆ¶æŸå¤±çš„å¸®åŠ©ä¸‹ï¼ŒGES åœ¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å†…å­˜å­˜å‚¨é‡ä¸åˆ°é«˜æ–¯æ•£å°„çš„ä¸€åŠï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æé«˜äº† 39%ã€‚å·¥ä½œé‡ï¼š</li><li>GES çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå®¹æ˜“åœ°é›†æˆåˆ°ç°æœ‰çš„å…‰åœºæ¸²æŸ“å·¥å…·ä¸­ã€‚</li><li>GES çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹è¾ƒå¿«ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å‡ åˆ†é’Ÿå†…å®Œæˆã€‚</li><li>GES çš„æ¸²æŸ“é€Ÿåº¦å¾ˆå¿«ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-06e50cf8fcf2b71cc6d5f5fa60bd416c.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-e0387aa41ca3382d21ca4822a1185a81.jpg" align="middle"><img src="https://picx.zhimg.com/v2-d98ce6f15593a9709f1a7d0a0c108a7f.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4903d39957be51dd29a4222bcccefaa4.jpg" align="middle"><img src="https://picx.zhimg.com/v2-c50bfcbaec1420bcb70374001db6c443.jpg" align="middle"><img src="https://picx.zhimg.com/v2-e090b0178d5a97f88600cc386571b770.jpg" align="middle"></details><h2 id="GS-CLIP-Gaussian-Splatting-for-Contrastive-Language-Image-3D-Pretraining-from-Real-World-Data"><a href="#GS-CLIP-Gaussian-Splatting-for-Contrastive-Language-Image-3D-Pretraining-from-Real-World-Data" class="headerlink" title="GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D   Pretraining from Real-World Data"></a>GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D   Pretraining from Real-World Data</h2><p><strong>Authors:Haoyuan Li, Yanpeng Zhou, Yihan Zeng, Hang Xu, Xiaodan Liang</strong></p><p>3D Shape represented as point cloud has achieve advancements in multimodal pre-training to align image and language descriptions, which is curial to object identification, classification, and retrieval. However, the discrete representations of point cloud lost the objectâ€™s surface shape information and creates a gap between rendering results and 2D correspondences. To address this problem, we propose GS-CLIP for the first attempt to introduce 3DGS (3D Gaussian Splatting) into multimodal pre-training to enhance 3D representation. GS-CLIP leverages a pre-trained vision-language model for a learned common visual and textual space on massive real world image-text pairs and then learns a 3D Encoder for aligning 3DGS optimized per object. Additionally, a novel Gaussian-Aware Fusion is proposed to extract and fuse global explicit feature. As a general framework for language-image-3D pre-training, GS-CLIP is agnostic to 3D backbone networks. Experiments on challenging shows that GS-CLIP significantly improves the state-of-the-art, outperforming the previously best results. </p><p><a href="http://arxiv.org/abs/2402.06198v2">PDF</a> The content of the technical report needs to be updated and retracted   to avoid other impacts</p><p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨3DGS(ä¸‰ç»´é«˜æ–¯æ¸²æŸ“)å¢å¼º3Dè¡¨ç°ï¼Œä»¥è¿›è¡Œå¤šæ¨¡æ€é¢„è®­ç»ƒï¼Œæå‡å›¾åƒã€è¯­è¨€å’Œä¸‰ç»´æ•°æ®çš„å¯¹é½ï¼Œæ”¹å–„ç‰©ä½“è¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢ä»»åŠ¡ã€‚</p><p><strong>è¦ç‚¹</strong></p><ul><li>åˆ©ç”¨ç‚¹äº‘è¡¨ç¤ºçš„3Då½¢çŠ¶åœ¨å›¾åƒå’Œè¯­è¨€æè¿°çš„å¯¹é½ä¸Šå–å¾—äº†å¤šæ¨¡æ€é¢„è®­ç»ƒçš„è¿›æ­¥ï¼Œè¿™å¯¹äºç‰©ä½“è¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢è‡³å…³é‡è¦ã€‚</li><li>ç‚¹äº‘çš„ç¦»æ•£è¡¨ç¤ºä¸¢å¤±äº†ç‰©ä½“çš„æ›²é¢å½¢çŠ¶ä¿¡æ¯ï¼Œå¹¶åœ¨æ¸²æŸ“ç»“æœå’Œ2Då¯¹åº”å…³ç³»ä¹‹é—´åˆ¶é€ å·®è·ã€‚</li><li>æå‡ºGS-CLIPï¼Œé¦–æ¬¡å°è¯•å°†3DGSï¼ˆä¸‰ç»´é«˜æ–¯æ¸²æŸ“ï¼‰å¼•å…¥å¤šæ¨¡æ€é¢„è®­ç»ƒï¼Œä»¥å¢å¼º3Dè¡¨ç¤ºã€‚</li><li>GS-CLIPåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œåœ¨å¤§é‡çœŸå®ä¸–ç•Œå›¾åƒ-æ–‡æœ¬å¯¹ä¸Šå­¦ä¹ ä¸€ä¸ªé€šç”¨çš„è§†è§‰å’Œæ–‡æœ¬ç©ºé—´ï¼Œç„¶åå­¦ä¹ ä¸€ä¸ªé’ˆå¯¹æ¯ä¸ªç‰©ä½“ä¼˜åŒ–3DGSçš„3Dç¼–ç å™¨ã€‚</li><li>æå‡ºäº†ä¸€ç§æ–°çš„é«˜æ–¯æ„ŸçŸ¥èåˆæ¥æå–å’Œèåˆå…¨å±€æ˜¾å¼ç‰¹å¾ã€‚</li><li>ä½œä¸ºè¯­è¨€-å›¾åƒ-3Dé¢„è®­ç»ƒçš„é€šç”¨æ¡†æ¶ï¼ŒGS-CLIPç‹¬ç«‹äº3Déª¨å¹²ç½‘ç»œã€‚</li><li>å…·æœ‰æŒ‘æˆ˜æ€§çš„å®éªŒè¡¨æ˜ï¼ŒGS-CLIPæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œè¶…è¶Šäº†ä»¥å‰æœ€å¥½çš„æˆæœã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šGS-CLIPï¼šç”¨äºå¯¹æ¯”è¯­è¨€-å›¾åƒ-3D é¢„è®­ç»ƒçš„é«˜æ–¯å–·ç»˜</li><li>ä½œè€…ï¼šææ˜Šæºã€å‘¨é›é¹ã€æ›¾ä¹‰æ¶µã€å¾èˆªã€æ¢æ™“ä¸¹</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ·±åœ³å¤§å­¦</li><li>å…³é”®è¯ï¼š3D è¡¨ç¤ºã€å¯¹æ¯”å­¦ä¹ ã€å¤šæ¨¡æ€é¢„è®­ç»ƒã€é«˜æ–¯å–·ç»˜</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.06198ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li><li><p>æ‘˜è¦ï¼šï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D å½¢çŠ¶è¡¨ç¤ºä¸ºç‚¹äº‘åœ¨å¤šæ¨¡æ€é¢„è®­ç»ƒä¸­å–å¾—äº†è¿›å±•ï¼Œå¯ä»¥å¯¹é½å›¾åƒå’Œè¯­è¨€æè¿°ï¼Œè¿™å¯¹ç‰©ä½“è¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç‚¹äº‘çš„ç¦»æ•£è¡¨ç¤ºä¸¢å¤±äº†ç‰©ä½“çš„è¡¨é¢å½¢çŠ¶ä¿¡æ¯ï¼Œå¹¶åœ¨æ¸²æŸ“ç»“æœå’Œ 2D å¯¹åº”å…³ç³»ä¹‹é—´äº§ç”Ÿäº†å·®è·ã€‚ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å¯¹ç‚¹äº‘è¿›è¡Œå»ºæ¨¡ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸ä¼šä¸¢å¤±ç‰©ä½“çš„å‡ ä½•ä¿¡æ¯å’Œå½¢çŠ¶çº¹ç†ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®ï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥åº”ç”¨äºç°å®ä¸–ç•Œä¸­çš„åœºæ™¯ã€‚ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ GS-CLIPï¼Œè¯¥æ¡†æ¶å°† 3D é«˜æ–¯å–·ç»˜ (3DGS) å¼•å…¥å¤šæ¨¡æ€é¢„è®­ç»ƒä¸­ï¼Œä»¥å¢å¼º 3D è¡¨ç¤ºã€‚GS-CLIP åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤§é‡çœŸå®ä¸–ç•Œå›¾åƒ-æ–‡æœ¬å¯¹ä¸Šå­¦ä¹ ä¸€ä¸ªå…±åŒçš„è§†è§‰å’Œæ–‡æœ¬ç©ºé—´ï¼Œç„¶åå­¦ä¹ ä¸€ä¸ª 3D ç¼–ç å™¨æ¥å¯¹é½é’ˆå¯¹æ¯ä¸ªå¯¹è±¡ä¼˜åŒ–çš„ 3DGSã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„é«˜æ–¯æ„ŸçŸ¥èåˆæ–¹æ³•ï¼Œç”¨äºæå–å’Œèåˆå…¨å±€æ˜¾å¼ç‰¹å¾ã€‚ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨ SUN-RGBD æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGS-CLIP åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­çš„é›¶æ ·æœ¬/å¼€æ”¾ä¸–ç•Œå­¦ä¹ ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œ3DGS åœ¨è·¨æ¨¡æ€å­¦ä¹ ä¸­å…·æœ‰å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ã€‚</p></li><li><p>æ–¹æ³•ï¼šï¼ˆ1ï¼‰è·¨æ¨¡æ€é¢„è®­ç»ƒï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„è¯­è¨€-å›¾åƒæ¨¡å‹CLIPï¼Œä¸ºæ–‡æœ¬ã€å›¾åƒå’Œ3DGSå»ºç«‹å…±åŒçš„è¯­è¨€-å›¾åƒæ½œåœ¨ç©ºé—´ï¼Œä½œä¸º3DGSçš„ç›®æ ‡æ½œåœ¨ç©ºé—´ã€‚ï¼ˆ2ï¼‰è¯­è¨€-3DGSå¯¹é½å’Œå›¾åƒ-3DGSå¯¹é½ï¼šåˆ†åˆ«ä½¿ç”¨å¯¹æ¯”æŸå¤±å‡½æ•°æ¥å¯¹é½æ–‡æœ¬ä¸3DGSã€å›¾åƒä¸3DGSçš„ç‰¹å¾è¡¨ç¤ºã€‚ï¼ˆ3ï¼‰é«˜æ–¯æ„ŸçŸ¥èåˆï¼šé‡‡ç”¨åŸºäºTransformerçš„åˆ†æ”¯ç›´æ¥å¯¹é«˜æ–¯ç‰¹å¾è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å°†å…¶ä¸æ®‹å·®å½¢å¼æ³¨å…¥åˆ°3Dä¸»å¹²ç½‘ç»œä¸­ã€‚</p></li><li><p>ç»“è®ºï¼šï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé¦–æ¬¡å°† 3DGS çº³å…¥è·¨æ¨¡æ€å­¦ä¹ ï¼Œä½œä¸ºè¡¥å……å½¢çŠ¶å’Œçº¹ç†ä¿¡æ¯çš„é€šç”¨ 3D è¡¨ç¤ºã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ç§é«˜æ–¯æ„ŸçŸ¥èåˆï¼Œä»¥ä¾¿æ›´å¥½åœ°ä»è¡¥å……ä¿¡æ¯ä¸­å­¦ä¹ ä¿¡æ¯ã€‚æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬æå‡ºçš„ GS-CLIP åœ¨æœ€å…ˆè¿›çš„æ–¹æ³•ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å®ç°äº†é›¶æ ·æœ¬/å¼€æ”¾ä¸–ç•Œå­¦ä¹ çš„æœ€æ–°æ€§èƒ½ã€‚ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p></li><li>å°† 3DGS å¼•å…¥è·¨æ¨¡æ€å­¦ä¹ ï¼Œä½œä¸ºè¡¥å……å½¢çŠ¶å’Œçº¹ç†ä¿¡æ¯çš„é€šç”¨ 3D è¡¨ç¤ºã€‚</li><li>æå‡ºäº†ä¸€ç§é«˜æ–¯æ„ŸçŸ¥èåˆï¼Œä»¥ä¾¿æ›´å¥½åœ°ä»è¡¥å……ä¿¡æ¯ä¸­å­¦ä¹ ä¿¡æ¯ã€‚</li><li>åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å®ç°äº†é›¶æ ·æœ¬/å¼€æ”¾ä¸–ç•Œå­¦ä¹ çš„æœ€æ–°æ€§èƒ½ã€‚æ€§èƒ½ï¼š</li><li>åœ¨ SUN-RGBD æ•°æ®é›†ä¸Šï¼ŒGS-CLIP åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­çš„é›¶æ ·æœ¬/å¼€æ”¾ä¸–ç•Œå­¦ä¹ ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li><li>è¿™äº›ç»“æœè¡¨æ˜ï¼Œ3DGS åœ¨è·¨æ¨¡æ€å­¦ä¹ ä¸­å…·æœ‰å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ã€‚å·¥ä½œé‡ï¼š</li><li>è¯¥å·¥ä½œæ¶‰åŠåˆ°å¤§é‡çš„æ•°æ®é¢„å¤„ç†å’Œæ¨¡å‹è®­ç»ƒã€‚</li><li>éœ€è¦å¯¹ 3DGS è¿›è¡Œä¼˜åŒ–ï¼Œä»¥ä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å¯¹é½æ–‡æœ¬å’Œå›¾åƒçš„ç‰¹å¾è¡¨ç¤ºã€‚</li><li>éœ€è¦å¯¹é«˜æ–¯æ„ŸçŸ¥èåˆè¿›è¡Œè¿›ä¸€æ­¥çš„ç ”ç©¶ï¼Œä»¥ä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°æå–å’Œèåˆå…¨å±€æ˜¾å¼ç‰¹å¾ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://picx.zhimg.com/v2-5ca02e3188a2350914f961c6e31c0616.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4980273838b01e0c94c7593c3becb878.jpg" align="middle"><img src="https://picx.zhimg.com/v2-b33d684beebaf5252e0357a0e0af9c1d.jpg" align="middle"></details><h2 id="GaMeS-Mesh-Based-Adapting-and-Modification-of-Gaussian-Splatting"><a href="#GaMeS-Mesh-Based-Adapting-and-Modification-of-Gaussian-Splatting" class="headerlink" title="GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting"></a>GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting</h2><p><strong>Authors:Joanna WaczyÅ„ska, Piotr Borycki, SÅ‚awomir Tadeja, Jacek Tabor, PrzemysÅ‚aw Spurek</strong></p><p>Recently, a range of neural network-based methods for image rendering have been introduced. One such widely-researched neural radiance field (NeRF) relies on a neural network to represent 3D scenes, allowing for realistic view synthesis from a small number of 2D images. However, most NeRF models are constrained by long training and inference times. In comparison, Gaussian Splatting (GS) is a novel, state-of-the-art technique for rendering points in a 3D scene by approximating their contribution to image pixels through Gaussian distributions, warranting fast training and swift, real-time rendering. A drawback of GS is the absence of a well-defined approach for its conditioning due to the necessity to condition several hundred thousand Gaussian components. To solve this, we introduce the Gaussian Mesh Splatting (GaMeS) model, which allows modification of Gaussian components in a similar way as meshes. We parameterize each Gaussian component by the vertices of the mesh face. Furthermore, our model needs mesh initialization on input or estimated mesh during training. We also define Gaussian splats solely based on their location on the mesh, allowing for automatic adjustments in position, scale, and rotation during animation. As a result, we obtain a real-time rendering of editable GS. </p><p><a href="http://arxiv.org/abs/2402.01459v3">PDF</a> </p><p><strong>Summary:</strong><br>ç¥ç»è¾å°„åœº (NeRF) æ˜¯ä¸€ç§ç”¨äºå›¾åƒæ¸²æŸ“çš„ç¥ç»ç½‘ç»œæ–¹æ³•ï¼Œè€Œé«˜æ–¯ç½‘æ ¼æ³¼æº… (GaMeS) æ¨¡å‹åˆ™é€šè¿‡é«˜æ–¯åˆ†å¸ƒæ¥ä¼°ç®— 3D åœºæ™¯ä¸­ç‚¹çš„è´¡çŒ®ï¼Œä»è€Œå®ç°å¿«é€Ÿè®­ç»ƒå’Œå®æ—¶æ¸²æŸ“ã€‚</p><p><strong>Key Takeaways:</strong></p><ul><li>åˆ©ç”¨ç¥ç»ç½‘ç»œè¡¨å¾ 3D åœºæ™¯çš„ NeRFï¼Œå…è®¸ä»å°‘é‡ 2D å›¾åƒä¸­è¿›è¡Œé€¼çœŸçš„è§†ç‚¹åˆæˆã€‚</li><li>é«˜æ–¯æ³¼æº… (GS) é€šè¿‡é«˜æ–¯åˆ†å¸ƒæ¥ä¼°ç®— 3D åœºæ™¯ä¸­ç‚¹çš„è´¡çŒ®ï¼Œä»è€Œå®ç°å¿«é€Ÿè®­ç»ƒå’Œå®æ—¶æ¸²æŸ“ã€‚</li><li>GaMeS æ¨¡å‹å…è®¸ä»¥ä¸ç½‘æ ¼ç±»ä¼¼çš„æ–¹å¼ä¿®æ”¹é«˜æ–¯åˆ†é‡ï¼Œä»è€Œä¸º GS çš„è°ƒèŠ‚æä¾›äº†ä¸€ä¸ªæ˜ç¡®çš„æ–¹æ³•ã€‚</li><li>å°†æ¯ä¸ªé«˜æ–¯åˆ†é‡å‚æ•°åŒ–ä¸ºç½‘æ ¼é¢çš„é¡¶ç‚¹ï¼Œè¿™ä½¿å¾— GaMeS æ¨¡å‹å¯ä»¥å¯¹ GS è¿›è¡Œå®æ—¶æ¸²æŸ“ã€‚</li><li>GaMeS æ¨¡å‹éœ€è¦åœ¨è¾“å…¥æ—¶åˆå§‹åŒ–ç½‘æ ¼æˆ–åœ¨è®­ç»ƒæœŸé—´ä¼°è®¡ç½‘æ ¼ã€‚</li><li>æ ¹æ®å…¶åœ¨ç½‘æ ¼ä¸Šçš„ä½ç½®å®šä¹‰é«˜æ–¯æ³¼æº…ï¼Œä»è€Œå…è®¸åœ¨åŠ¨ç”»æœŸé—´è‡ªåŠ¨è°ƒæ•´ä½ç½®ã€ç¼©æ”¾å’Œæ—‹è½¬ã€‚</li><li>GaMeS æ¨¡å‹å¯ä»¥å®ç°å¯ç¼–è¾‘ GS çš„å®æ—¶æ¸²æŸ“ã€‚</li></ul><p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p><ol><li>é¢˜ç›®ï¼šGaMeSï¼šåŸºäºç½‘æ ¼çš„è‡ªé€‚åº”å’Œä¿®æ”¹é«˜æ–¯å–·ç»˜</li><li>ä½œè€…ï¼šJoanna WaczyÅ„skaã€Piotr Boryckiã€SÅ‚awomir Tadejaã€Jacek Taborã€PrzemysÅ‚aw Spurek</li><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé›…ç›–éš†å¤§å­¦æ•°å­¦ä¸è®¡ç®—æœºç§‘å­¦å­¦é™¢ï¼Œæ³¢å…°å…‹æ‹‰ç§‘å¤«</li><li>å…³é”®è¯ï¼šé«˜æ–¯å–·ç»˜ã€ç¥ç»è¾å°„åœºã€ç¥ç»æ¸²æŸ“ã€ç½‘æ ¼ã€å®æ—¶æ¸²æŸ“</li><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.01459ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li><li>æ‘˜è¦ï¼š(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼ŒåŸºäºç¥ç»ç½‘ç»œçš„å›¾åƒæ¸²æŸ“æ–¹æ³•å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œå…¶ä¸­ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ˜¯ä¸€ç§æµè¡Œçš„æ–¹æ³•ï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è¡¨ç¤º 3D åœºæ™¯ï¼Œå¹¶èƒ½å¤Ÿä»å°‘é‡ 2D å›¾åƒä¸­åˆæˆé€¼çœŸçš„è§†å›¾ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•° NeRF æ¨¡å‹éƒ½å—åˆ°è®­ç»ƒå’Œæ¨ç†æ—¶é—´é•¿çš„é™åˆ¶ã€‚ä¸ä¹‹ç›¸æ¯”ï¼Œé«˜æ–¯å–·ç»˜ï¼ˆGSï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„ã€æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œå®ƒé€šè¿‡é«˜æ–¯åˆ†å¸ƒæ¥è¿‘ä¼¼ç‚¹å¯¹å›¾åƒåƒç´ çš„è´¡çŒ®ï¼Œä»è€Œæ¸²æŸ“ 3D åœºæ™¯ä¸­çš„ç‚¹ï¼Œå…·æœ‰å¿«é€Ÿè®­ç»ƒå’Œå¿«é€Ÿå®æ—¶æ¸²æŸ“çš„èƒ½åŠ›ã€‚(2)ï¼šè¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šGS çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯ç¼ºä¹æ˜ç¡®çš„è°ƒèŠ‚æ–¹æ³•ï¼Œå› ä¸ºéœ€è¦è°ƒèŠ‚æ•°åä¸‡ä¸ªé«˜æ–¯åˆ†é‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡ä»‹ç»äº†é«˜æ–¯ç½‘æ ¼å–·ç»˜ï¼ˆGaMeSï¼‰æ¨¡å‹ï¼Œå®ƒå…è®¸åƒä¿®æ”¹ç½‘æ ¼ä¸€æ ·ä¿®æ”¹é«˜æ–¯åˆ†é‡ã€‚æˆ‘ä»¬å°†æ¯ä¸ªé«˜æ–¯åˆ†é‡å‚æ•°åŒ–ä¸ºç½‘æ ¼é¢çš„é¡¶ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹éœ€è¦åœ¨è¾“å…¥æˆ–è®­ç»ƒæœŸé—´ä¼°è®¡çš„ç½‘æ ¼ä¸Šè¿›è¡Œç½‘æ ¼åˆå§‹åŒ–ã€‚æˆ‘ä»¬è¿˜å®šä¹‰äº†ä»…åŸºäºå…¶åœ¨ç½‘æ ¼ä¸Šçš„ä½ç½®çš„é«˜æ–¯å–·ç»˜ï¼Œå…è®¸åœ¨åŠ¨ç”»æœŸé—´è‡ªåŠ¨è°ƒæ•´ä½ç½®ã€æ¯”ä¾‹å’Œæ—‹è½¬ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è·å¾—äº†å¯ç¼–è¾‘ GS çš„å®æ—¶æ¸²æŸ“ã€‚(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº† GaMeS æ¨¡å‹ï¼Œå®ƒå…è®¸åƒä¿®æ”¹ç½‘æ ¼ä¸€æ ·ä¿®æ”¹é«˜æ–¯åˆ†é‡ã€‚æˆ‘ä»¬å°†æ¯ä¸ªé«˜æ–¯åˆ†é‡å‚æ•°åŒ–ä¸ºç½‘æ ¼é¢çš„é¡¶ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹éœ€è¦åœ¨è¾“å…¥æˆ–è®­ç»ƒæœŸé—´ä¼°è®¡çš„ç½‘æ ¼ä¸Šè¿›è¡Œç½‘æ ¼åˆå§‹åŒ–ã€‚æˆ‘ä»¬è¿˜å®šä¹‰äº†ä»…åŸºäºå…¶åœ¨ç½‘æ ¼ä¸Šçš„ä½ç½®çš„é«˜æ–¯å–·ç»˜ï¼Œå…è®¸åœ¨åŠ¨ç”»æœŸé—´è‡ªåŠ¨è°ƒæ•´ä½ç½®ã€æ¯”ä¾‹å’Œæ—‹è½¬ã€‚(4)ï¼šæ–¹æ³•çš„æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒGaMeS æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿æŒé«˜è´¨é‡æ¸²æŸ“çš„åŒæ—¶ï¼Œå®ç°å®æ—¶ä¿®æ”¹å’Œé€‚åº”é«˜æ–¯å–·ç»˜ã€‚è¿™ä½¿å¾— GaMeS æˆä¸ºäº¤äº’å¼åº”ç”¨ç¨‹åºå’Œæ¸¸æˆä¸­çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„æŠ€æœ¯ã€‚</li></ol><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><ol><li>ç»“è®ºï¼šï¼ˆ1ï¼‰GaMeS å…è®¸å®æ—¶ä¿®æ”¹ï¼Œä½†å¯¹äºå…·æœ‰å¤§é¢çš„ç½‘æ ¼ï¼Œåœ¨å‘ç”Ÿé‡å¤§å˜åŒ–çš„æƒ…å†µä¸‹ä¼šå‡ºç°ä¼ªå½±ã€‚åœ¨å®è·µä¸­ï¼Œå¤§é¢åº”è¯¥è¢«åˆ†æˆæ›´å°çš„é¢ã€‚å½“ç½‘æ ¼é¢åˆ†è£‚æ—¶å¦‚ä½•åœ¨ GaMeS ä¸­æ›´æ”¹é«˜æ–¯åˆ†é‡å°šä¸æ¸…æ¥šã€‚ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šGaMeS æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºç½‘æ ¼çš„è‡ªé€‚åº”å’Œä¿®æ”¹é«˜æ–¯å–·ç»˜æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…è®¸åƒä¿®æ”¹ç½‘æ ¼ä¸€æ ·ä¿®æ”¹é«˜æ–¯åˆ†é‡ï¼Œä»è€Œå®ç°äº†å®æ—¶ä¿®æ”¹å’Œé€‚åº”é«˜æ–¯å–·ç»˜ã€‚æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒGaMeS æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿æŒé«˜è´¨é‡æ¸²æŸ“çš„åŒæ—¶ï¼Œå®ç°å®æ—¶ä¿®æ”¹å’Œé€‚åº”é«˜æ–¯å–·ç»˜ã€‚è¿™ä½¿å¾— GaMeS æˆä¸ºäº¤äº’å¼åº”ç”¨ç¨‹åºå’Œæ¸¸æˆä¸­çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„æŠ€æœ¯ã€‚å·¥ä½œé‡ï¼šGaMeS æ¨¡å‹éœ€è¦åœ¨è¾“å…¥æˆ–è®­ç»ƒæœŸé—´ä¼°è®¡ç½‘æ ¼ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æ—¶é—´ã€‚æ­¤å¤–ï¼ŒGaMeS æ¨¡å‹éœ€è¦å¯¹ç½‘æ ¼è¿›è¡Œä¿®æ”¹ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ æ¨¡å‹çš„ä¿®æ”¹æ—¶é—´ã€‚</li></ol><details>  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary><img src="https://pica.zhimg.com/v2-11676aa94eeb837bc5149bf9038274ae.jpg" align="middle"><img src="https://picx.zhimg.com/v2-3d3c20ac78640d356ea03699146c96e9.jpg" align="middle"><img src="https://picx.zhimg.com/v2-4070017cd795fd8699e30a356efae899.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-0416310a796f7ec70150342ac59ffe37.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-6eb0975a0f5d702a6daef3f78e530869.jpg" align="middle"><img src="https://pic1.zhimg.com/v2-9fb0edd088d9a64e792369a6d6a72979.jpg" align="middle"><img src="https://pica.zhimg.com/v2-dd54f927f26f28fdcefe778d566087c5.jpg" align="middle"></details>]]></content>
    
    
    <summary type="html">3DGS æ–¹å‘æœ€æ–°è®ºæ–‡å·²æ›´æ–°ï¼Œè¯·æŒç»­å…³æ³¨ Update in 2024-02-23  Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting</summary>
    
    
    
    <category term="Paper" scheme="https://kedreamix.github.io/categories/Paper/"/>
    
    
    <category term="3DGS" scheme="https://kedreamix.github.io/tags/3DGS/"/>
    
  </entry>
  
</feed>
