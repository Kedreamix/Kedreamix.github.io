<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>condaå’Œpipæ¢æº</title>
    <url>/2024/01/01/Linux/Anaconda%E6%8D%A2%E6%BA%90/</url>
    <content><![CDATA[<h2 id="pipæ¢æº"><a href="#pipæ¢æº" class="headerlink" title="pipæ¢æº"></a>pipæ¢æº</h2><h3 id="è®¾ä¸ºé»˜è®¤æ¸…åæº"><a href="#è®¾ä¸ºé»˜è®¤æ¸…åæº" class="headerlink" title="è®¾ä¸ºé»˜è®¤æ¸…åæº"></a>è®¾ä¸ºé»˜è®¤æ¸…åæº</h3><p>å‡çº§ pip åˆ°æœ€æ–°çš„ç‰ˆæœ¬ (&gt;=10.0.0) åè¿›è¡Œé…ç½®ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">python -m pip install --upgrade pip</span><br><span class="line">pip config <span class="built_in">set</span> global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</span><br></pre></td></tr></tbody></table></figure>
<p>å¦‚æœæ‚¨åˆ° pip é»˜è®¤æºçš„ç½‘ç»œè¿æ¥è¾ƒå·®ï¼Œä¸´æ—¶ä½¿ç”¨æœ¬é•œåƒç«™æ¥å‡çº§ pipï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">python -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade pip</span><br></pre></td></tr></tbody></table></figure>
<p><a href="https://blog.csdn.net/wyf2017/article/details/118676765">https://blog.csdn.net/wyf2017/article/details/118676765</a></p>
<h3 id="ä¿®æ”¹é…ç½®"><a href="#ä¿®æ”¹é…ç½®" class="headerlink" title="ä¿®æ”¹é…ç½®"></a>ä¿®æ”¹é…ç½®</h3><p>vim ~/.pip/pip.conf<br>æ³¨æ„ï¼Œè¿™é‡Œè®¾ç½®çš„è±†ç“£æº</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line"></span><br><span class="line">index-url = https://pypi.doubanio.com/simple</span><br><span class="line"></span><br><span class="line">trusted-host = pypi.doubanio.com</span><br></pre></td></tr></tbody></table></figure>
<h2 id="condaæ¢æº"><a href="#condaæ¢æº" class="headerlink" title="condaæ¢æº"></a>condaæ¢æº</h2><h3 id="æ¸…åæº"><a href="#æ¸…åæº" class="headerlink" title="æ¸…åæº"></a>æ¸…åæº</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/conda</span><br><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls <span class="built_in">yes</span></span><br></pre></td></tr></tbody></table></figure>
<p><strong>æå‰è¯´</strong>ï¼šå¦‚æœé…ç½®é•œåƒæºåæŠ¥ HTTP é”™è¯¯ï¼Œåªéœ€è¦å°†æºé“¾æ¥ä¸­çš„ https://â€¦ ä¸­çš„ s åˆ æ‰å°±è¡Œ æ¸…åæº</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forgeconda config --<span class="built_in">set</span> show_channel_urls yes</span><br></pre></td></tr></tbody></table></figure>
<h3 id="ä¸­ç§‘å¤§æº"><a href="#ä¸­ç§‘å¤§æº" class="headerlink" title="ä¸­ç§‘å¤§æº"></a>ä¸­ç§‘å¤§æº</h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/main/conda</span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/conda </span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/conda </span><br><span class="line">conda config --add channels https://mirrors.ustc.edu.cn/anaconda/cloud/msys2/conda </span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br></pre></td></tr></tbody></table></figure>
<h3 id="ä¿®æ”¹é…ç½®-1"><a href="#ä¿®æ”¹é…ç½®-1" class="headerlink" title="ä¿®æ”¹é…ç½®"></a>ä¿®æ”¹é…ç½®</h3><p>æˆ‘ä»¬è¿˜åˆ»æœ‰ç›´æ¥ä¿®æ”¹é…ç½®<br>vim ~/.condarc</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">channels:</span><br><span class="line">  - defaults</span><br><span class="line">show_channel_urls: <span class="literal">true</span></span><br><span class="line">default_channels:</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</span><br><span class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</span><br><span class="line">custom_channels:</span><br><span class="line">  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br><span class="line">  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</span><br></pre></td></tr></tbody></table></figure>
<h3 id="æ¢ä¸ºé»˜è®¤æº"><a href="#æ¢ä¸ºé»˜è®¤æº" class="headerlink" title="æ¢ä¸ºé»˜è®¤æº"></a>æ¢ä¸ºé»˜è®¤æº</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">conda config --remove-key channels</span><br></pre></td></tr></tbody></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux å®‰è£…CUDA åŠ æ›´æ–°CUDA</title>
    <url>/2024/01/01/Linux/Linux%20%E5%AE%89%E8%A3%85CUDA%20%E5%8F%8A%20%E6%9B%B4%E6%96%B0CUDA/</url>
    <content><![CDATA[<h1 id="CUDA-æ›´æ–°"><a href="#CUDA-æ›´æ–°" class="headerlink" title="CUDA æ›´æ–°"></a>CUDA æ›´æ–°</h1><p>å…ˆè£… CUDA [<a href="https://developer.nvidia.com/zh-cn/cuda-toolkit">ä¸‹è½½åœ°å€</a>]ï¼Œè€ç‰ˆæœ¬çš„ CUDA ä¸ç”¨åˆ æ‰ï¼Œç›´æ¥è®©ç®¡ç†å‘˜å°† cuda è½¯è¿æ¥åˆ°æœ€æ–°çš„ CUDA å°±è¡Œäº†ï¼Œä»¥é˜²æœ‰äº›ä»£ç éœ€è¦ä½ç‰ˆæœ¬ CUDAï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨å¤šä¸ªCUDAç‰ˆæœ¬è¿›è¡Œåˆ‡æ¢ã€‚</p>
<p>å†è£…é©±åŠ¨ <a href="https://www.nvidia.cn/Download/index.aspx?lang=cn">[é©±åŠ¨ä¸‹è½½åœ°å€]</a>ï¼Œå®‰è£…è¿‡ç¨‹ä¼šæç¤ºè¯´æ£€æµ‹åˆ°è€ç‰ˆæœ¬é©±åŠ¨ï¼Œç›´æ¥å¸è½½å°±è¡Œäº†ã€‚ï¼ˆä½†æ˜¯åœ¨Linuxä¸­ï¼Œæˆ‘ä»¬åªéœ€è¦å®‰è£…CUDAï¼Œé‡Œé¢ä¼šè‡ªå¸¦é©±åŠ¨å®‰è£…ï¼Œä¸éœ€è¦é‡æ–°å®‰è£…é©±åŠ¨ï¼‰</p>
<h1 id="CUDA-å®‰è£…"><a href="#CUDA-å®‰è£…" class="headerlink" title="CUDA å®‰è£…"></a>CUDA å®‰è£…</h1><h2 id="CUDA-ç®€ä»‹"><a href="#CUDA-ç®€ä»‹" class="headerlink" title="CUDA ç®€ä»‹"></a>CUDA ç®€ä»‹</h2><p>CUDA æ˜¯ç”± Nvidia å…¬å¸å¼€å‘çš„å¹¶è¡Œè®¡ç®—å¹³å°å’Œåº”ç”¨ç¨‹åºæ¥å£ï¼Œè½¯ä»¶å¼€å‘è€…å¯ä»¥åˆ©ç”¨æ”¯æŒ CUDA è½¯ä»¶çš„ GPU è¿›è¡Œé€šç”¨è®¡ç®—ã€‚CUDA å¯ä»¥ç›´æ¥é“¾æ¥åˆ° GPU çš„è™šæ‹ŸæŒ‡ä»¤é›†å’Œå¹¶è¡Œè®¡ç®—å•å…ƒï¼Œä»è€Œåœ¨ GPU ä¸­å®Œæˆå†…æ ¸å‡½æ•°çš„è®¡ç®—ã€‚<br>CUDA æä¾› C/C++/Fortran æ¥å£ï¼Œä¹Ÿæœ‰è®¸å¤šé«˜æ€§èƒ½è®¡ç®—æˆ–æ·±åº¦å­¦ä¹ åº“æä¾›åŒ…è£…åçš„ Python æ¥å£ã€‚å¼€å‘è€…ä»¬å¯æ ¹æ®å®é™…éœ€è¦ (é«˜æ€§èƒ½è®¡ç®—, æ·±åº¦å­¦ä¹ , ç¥ç»ç½‘ç»œç­‰) é€‰æ‹©é€‚å½“çš„ç¼–ç¨‹è¯­è¨€ã€‚</p>
<h2 id="CUDA-å®‰è£…æ­¥éª¤"><a href="#CUDA-å®‰è£…æ­¥éª¤" class="headerlink" title="CUDA å®‰è£…æ­¥éª¤"></a>CUDA å®‰è£…æ­¥éª¤</h2><p>ä¸€èˆ¬è€Œè¨€ï¼Œåœ¨ Linux ä¸‹å®‰è£…å’Œä½¿ç”¨ CUDA çš„æµç¨‹å¦‚ä¸‹ï¼š</p>
<ol>
<li>å®‰è£… NVIDIA Driverï¼Œå³æ˜¾å¡é©±åŠ¨</li>
<li>å®‰è£… CUDA Toolkit</li>
<li>ä½¿ç”¨ C/C++ ç¼–è¯‘å™¨æˆ– Python æ‰©å±•åº“è¿›è¡Œ GPU åŠ é€Ÿçš„ CUDA ç¼–ç¨‹</li>
</ol>
<h2 id="å®‰è£…CUDA"><a href="#å®‰è£…CUDA" class="headerlink" title="å®‰è£…CUDA"></a>å®‰è£…CUDA</h2><ol>
<li>é¦–å…ˆæŸ¥çœ‹é©±åŠ¨ï¼Œåœ¨å‘½ä»¤è¡Œè¾“å…¥nvidia-smiæŸ¥çœ‹æ˜¾å¡é©±åŠ¨ç‰ˆæœ¬ä¹Ÿå°±æ˜¯æœ€é«˜æ”¯æŒçš„CUDAå·¥å…·åŒ…ç‰ˆæœ¬ã€‚<br>ä¾‹å¦‚ï¼Œæœ¬æœºå¯å®‰è£…11.2åŠä»¥ä¸‹çš„CUDAå·¥å…·åŒ…ï¼š<br><img src="https://pica.zhimg.com/v2-8eb67ea314c41ef10fe803db8ec37146.png" alt=""></li>
<li>åœ¨<a href="https://developer.nvidia.com/cuda-toolkit-archive">nvidiaå®˜ç½‘</a>é€‰æ‹©å¯¹åº”ç‰ˆæœ¬çš„CUDAå·¥å…·åŒ…å¹¶é€‰æ‹©ä½ çš„æœºå™¨é…ç½®ï¼Œæˆ‘ä»¬å°±é€‰æ‹©11.2.0ç‰ˆæœ¬ä¸‹è½½ï¼Œ<br><img src="https://cdn.nlark.com/yuque/0/2023/png/32727715/1699412172755-39338a8a-468b-42d7-9f47-b7eae24f7b43.png#averageHue=%23faf9f4&amp;clientId=u8317f767-0156-4&amp;from=paste&amp;id=ub4eaf9ff&amp;originHeight=550&amp;originWidth=602&amp;originalType=url&amp;ratio=1&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=ub607342c-fcd0-4d93-9eae-541091756f6&amp;title=" alt=""><br><img src="https://picx.zhimg.com/v2-7f66e7a0b551621641f20f164e44eaaa.png" alt=""></li>
<li>åœ¨ç»ˆç«¯æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼š</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.2.0/local_installers/cuda_11.2.0_460.27.04_linux.run</span><br><span class="line">sudo sh cuda_11.2.0_460.27.04_linux.run</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://picx.zhimg.com/v2-d342c888c906d6ffb7e87abab83de0d1.png" alt=""><br>å¦‚æœå‡ºç°ä»¥ä¸‹æç¤ºï¼Œé€‰æ‹©continueå¹¶åœ¨ç¬¬å››æ­¥å–æ¶ˆå®‰è£…é©±åŠ¨å³å¯ã€‚<br><img src="https://picx.zhimg.com/v2-a8f2cd8aec305e7c0ab32d0c21d51901.png" alt=""></p>
<ol>
<li>æ ¹æ®æç¤ºä¸€æ­¥æ­¥å®‰è£…é”®å…¥acceptç¡®è®¤ã€‚ğŸ‘‡<br><img src="https://picx.zhimg.com/v2-94f230d6082cbf2b695ba71fda63655d.png" alt=""></li>
<li>æˆ‘ä»¬å·²ç»æœ‰é©±åŠ¨äº†ï¼Œè¿™é‡Œå–æ¶ˆå®‰è£…é©±åŠ¨ï¼Œä¸Šä¸‹é”®å’Œå›è½¦é”®é€‰æ‹©ã€‚ğŸ‘‡<br><img src="https://picx.zhimg.com/v2-f0602a3e166fc875a2e1ca29ae91c0e6.png" alt=""></li>
<li>ç¨ä½œç­‰å¾…ï¼Œå‡ºç°ä»¥ä¸‹æç¤ºä¿¡æ¯å°±å®‰è£…å¥½äº†ï¼Œå¯ä»¥çœ‹åˆ°CUDAå®‰è£…åˆ°äº†/usr/local/cuda-11.2/ã€‚<br><img src="https://pica.zhimg.com/v2-4e3d84d056ff7e7453c4f30e73531ea6.png" alt=""></li>
<li>é…ç½®ç¯å¢ƒå˜é‡</li>
</ol>
<p>æ‰“å¼€é…ç½®æ–‡ä»¶</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">vi /etc/profile</span><br></pre></td></tr></tbody></table></figure>
<p>åœ¨é…ç½®æ–‡ä»¶æœ«å°¾åŠ ä¸Šï¼š</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">export PATH=/usr/local/cuda-11.2/bin:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda-11.2/lib64$LD_LIBRARY_PATH</span><br><span class="line"></span><br><span class="line"># ç¬¬äºŒç§å¯ä»¥æ–¹ä¾¿åˆ‡æ¢CUDA</span><br><span class="line">export PATH=/usr/local/cuda/bin:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=/usr/local/cuda/lib64$LD_LIBRARY_PATH</span><br></pre></td></tr></tbody></table></figure>
<p>source ä¸€ä¸‹é…ç½®æ–‡ä»¶</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>æ£€æŸ¥æ˜¯å¦å®‰è£…å®Œæˆ</li>
</ol>
<p>ä½¿ç”¨nvcc -Væ£€æŸ¥CUDAæ˜¯å¦å®‰è£…å®Œæˆï¼Œå‡ºç°ä»¥ä¸‹æç¤ºä»£è¡¨å®‰è£…å®Œæˆã€‚</p>
<p><img src="https://pica.zhimg.com/v2-4c3f3cb58faba27427df57840bd54650.tiff" alt=""><br>ç¼–è¯‘å¹¶æ‰§è¡ŒCUDAæ ·ä¾‹ç¨‹åºï¼Œå‡ºç°passä»£è¡¨CUDAå’ŒGPUæ­£å¸¸è¿è¡Œï¼š</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">cd /usr/local/cuda-11.2/samples/1_Utilities/deviceQuery</span><br><span class="line">sudo make</span><br><span class="line">./deviceQuery</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://pic1.zhimg.com/v2-5c859ddd09830ca59b872170d68f9eb2.png" alt=""></p>
<h1 id="å¤šä¸ªCUDAç‰ˆæœ¬åˆ‡æ¢"><a href="#å¤šä¸ªCUDAç‰ˆæœ¬åˆ‡æ¢" class="headerlink" title="å¤šä¸ªCUDAç‰ˆæœ¬åˆ‡æ¢"></a>å¤šä¸ªCUDAç‰ˆæœ¬åˆ‡æ¢</h1><p>å®é™…ä¸Šï¼Œè€ç‰ˆæœ¬çš„ CUDA ä¸ç”¨åˆ æ‰ï¼Œç›´æ¥è®©ç®¡ç†å‘˜å°† cuda è½¯è¿æ¥åˆ°æœ€æ–°çš„ CUDA å°±è¡Œäº†ï¼Œä»¥é˜²æœ‰äº›ä»£ç éœ€è¦ä½ç‰ˆæœ¬ CUDAï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨å¤šä¸ªCUDAç‰ˆæœ¬è¿›è¡Œåˆ‡æ¢ã€‚åœ¨linuxé‡Œé¢ï¼Œå°±æ˜¯ä¿®æ”¹è½¯è¿æ¥å³å¯ï¼Œè½¯è¿æ¥åˆ°å¯¹åº”çš„CUDAå°±å¯ä»¥å®ç°å®‰è£…ã€‚</p>
<h2 id="rootç”¨æˆ·è½¯é“¾æ¥"><a href="#rootç”¨æˆ·è½¯é“¾æ¥" class="headerlink" title="rootç”¨æˆ·è½¯é“¾æ¥"></a>rootç”¨æˆ·è½¯é“¾æ¥</h2><h3 id="åˆ é™¤åŸæ¥çš„è½¯é“¾æ¥"><a href="#åˆ é™¤åŸæ¥çš„è½¯é“¾æ¥" class="headerlink" title="åˆ é™¤åŸæ¥çš„è½¯é“¾æ¥"></a>åˆ é™¤åŸæ¥çš„è½¯é“¾æ¥</h3><p><strong>ç¬¬ä¸€ç§æ–¹æ³•ï¼š</strong><br>ç»è¯„è®ºåŒºå¤§ä½¬æŒ‡ç‚¹ï¼Œå¯ä»¥ä½¿ç”¨unlinkå‘½ä»¤åˆ é™¤è½¯é“¾æ¥ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local</span><br><span class="line">sudo <span class="built_in">unlink</span> cuda</span><br></pre></td></tr></tbody></table></figure>
<p><strong>ç¬¬äºŒç§æ–¹æ³•ï¼š</strong><br>æ³¨æ„ï¼ä¸è¦å¤šæ‰“ä¸€ä¸ªâ€™/â€˜ï¼Œå¦åˆ™ä¼šåˆ é™¤äº†å®é™…æ•°æ®ã€‚<br>å…·ä½“å‚è§ï¼š<a href="https://link.zhihu.com/?target=https%3A//blog.51cto.com/kusorz/1876315">linuxåˆ é™¤è½¯é“¾æ¥çš„æ­£ç¡®æ–¹å¼_æ¯å¤©è¿›æ­¥ä¸€ç‚¹çš„æŠ€æœ¯åšå®¢_51CTOåšå®¢_linuxè½¯è¿æ¥</a></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local</span><br><span class="line">sudo <span class="built_in">rm</span> -rf cuda</span><br></pre></td></tr></tbody></table></figure>
<p>ï¼ˆåƒä¸‡ä¸è¦å¤šæ‰“â€™/â€˜ ï¼ï¼ï¼ï¼ï¼å†è¯´ä¸€éï¼ï¼ï¼ï¼‰</p>
<h3 id="å»ºç«‹æ–°çš„è½¯é“¾æ¥"><a href="#å»ºç«‹æ–°çš„è½¯é“¾æ¥" class="headerlink" title="å»ºç«‹æ–°çš„è½¯é“¾æ¥"></a>å»ºç«‹æ–°çš„è½¯é“¾æ¥</h3><p>å»ºç«‹æŒ‡å‘cuda-10.0ï¼ˆéœ€è¦çš„CUDAç‰ˆæœ¬ï¼‰ç‰ˆæœ¬çš„è½¯é“¾æ¥</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo <span class="built_in">ln</span> -snf /usr/local/cuda-8.0 /usr/local/cuda</span><br></pre></td></tr></tbody></table></figure>
<h3 id="æŸ¥çœ‹å½“å‰CUDAç‰ˆæœ¬"><a href="#æŸ¥çœ‹å½“å‰CUDAç‰ˆæœ¬" class="headerlink" title="æŸ¥çœ‹å½“å‰CUDAç‰ˆæœ¬"></a>æŸ¥çœ‹å½“å‰CUDAç‰ˆæœ¬</h3><p>é€šè¿‡ä»¥ä¸‹å‘½ä»¤æ¥æŸ¥çœ‹åˆ‡æ¢æ˜¯å¦æˆåŠŸ</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># æŸ¥çœ‹'cuda'æ˜¯å¦æŒ‡å‘'/usr/local/cuda-éœ€è¦çš„ç‰ˆæœ¬å·'</span></span><br><span class="line"><span class="built_in">cd</span> /usr/local</span><br><span class="line"><span class="built_in">stat</span> cuda</span><br><span class="line"></span><br><span class="line"><span class="comment"># æŸ¥çœ‹å½“å‰CUDAç‰ˆæœ¬å·</span></span><br><span class="line">nvcc -V</span><br></pre></td></tr></tbody></table></figure>
<p>é™„æŸ¥çœ‹æ‰€æœ‰CUDAç‰ˆæœ¬çš„å‘½ä»¤</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> -l /usr/local | grep cuda</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸‹é¢åŸæ¥æ˜¯CUDA 11 ï¼Œç°åˆ‡æ¢ä¸ºCUDA10ç‰ˆæœ¬çš„æ“ä½œï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">censhaoqi@censhaoqiVM:/usr/local$ nvcc -V</span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2020 NVIDIA Corporation</span><br><span class="line">Built on Thu_Jun_11_22:26:38_PDT_2020</span><br><span class="line">Cuda compilation tools, release 11.0, V11.0.194</span><br><span class="line">Build cuda_11.0_bu.TC445_37.28540450_0</span><br><span class="line"></span><br><span class="line">censhaoqi@censhaoqiVM:/usr/local$ sudo <span class="built_in">rm</span> -rf cuda</span><br><span class="line">censhaoqi@censhaoqiVM:/usr/local$ sudo <span class="built_in">ln</span> -snf /usr/local/cuda-10.0 /usr/local/cuda</span><br><span class="line"></span><br><span class="line">censhaoqi@censhaoqiVM:/usr/local$ <span class="built_in">stat</span> cuda</span><br><span class="line">  File: <span class="string">'cuda'</span> -&gt; <span class="string">'/usr/local/cuda-10.0'</span></span><br><span class="line">  Size: 20        	Blocks: 0          IO Block: 4096   symbolic <span class="built_in">link</span></span><br><span class="line">Device: 8dh/141d	Inode: 36966009    Links: 1</span><br><span class="line">Access: (0777/lrwxrwxrwx)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Access: 2021-09-15 19:58:35.449731251 +0800</span><br><span class="line">Modify: 2021-09-15 19:58:31.881787060 +0800</span><br><span class="line">Change: 2021-09-15 19:58:31.881787060 +0800</span><br><span class="line"> Birth: -</span><br><span class="line"></span><br><span class="line">censhaoqi@censhaoqiVM:/usr/local$ nvcc -V</span><br><span class="line">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class="line">Copyright (c) 2005-2018 NVIDIA Corporation</span><br><span class="line">Built on Sat_Aug_25_21:08:01_CDT_2018</span><br><span class="line">Cuda compilation tools, release 10.0, V10.0.130</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ä¸ªäººç”¨æˆ·è®¾ç½®è·¯å¾„"><a href="#ä¸ªäººç”¨æˆ·è®¾ç½®è·¯å¾„" class="headerlink" title="ä¸ªäººç”¨æˆ·è®¾ç½®è·¯å¾„"></a>ä¸ªäººç”¨æˆ·è®¾ç½®è·¯å¾„</h2><p>æˆ‘ä»¬å¯ä»¥åœ¨è‡ªå·±çš„~/.bashrcä¸­è®¾ç½®cudaçš„è·¯å¾„ä¹Ÿå¯ä»¥è‡ªç”±çš„åˆ‡æ¢æˆ‘ä»¬çš„CUDAçš„ç‰ˆæœ¬ï¼ŒåŒæ ·æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨alias</p>
<blockquote>
<p>Linux alias å‘½ä»¤ç”¨äºè®¾ç½®æŒ‡ä»¤çš„åˆ«åï¼Œç”¨æˆ·å¯åˆ©ç”¨ aliasï¼Œè‡ªå®šæŒ‡ä»¤çš„åˆ«åã€‚<br>å®ƒå¯ä»¥ä½¿æ‚¨ä»¥ä¸€ç§æ›´ç®€å•å’Œæ˜“äºè®°å¿†çš„æ–¹å¼æ‰§è¡Œå‘½ä»¤ï¼Œè€Œä¸å¿…æ¯æ¬¡éƒ½é”®å…¥å®Œæ•´çš„å‘½ä»¤ã€‚<br>è‹¥ä»…è¾“å…¥ aliasï¼Œåˆ™å¯åˆ—å‡ºç›®å‰æ‰€æœ‰çš„åˆ«åè®¾ç½®ã€‚<br>alias çš„æ•ˆæœä»…åœ¨è¯¥æ¬¡ç™»å…¥çš„æ“ä½œæœ‰æ•ˆï¼Œè‹¥æƒ³è¦æ¯æ¬¡ç™»å…¥éƒ½ç”Ÿæ•ˆï¼Œå¯åœ¨ <strong>.profile</strong> æˆ– <strong>.cshrc</strong> ä¸­è®¾å®šæŒ‡ä»¤çš„åˆ«åã€‚</p>
</blockquote>
<figure class="highlight jsx"><table><tbody><tr><td class="code"><pre><span class="line">vim ~/.<span class="property">bashrc</span></span><br><span class="line"># åŠ å…¥å·²æœ‰çš„<span class="variable constant_">CUDA</span>çš„è·¯å¾„ï¼Œè¿™é‡Œé¢ä¸€å®šè¦æŸ¥çœ‹è‡ªå·±æœ¬æœºæ˜¯å¦æœ‰å®‰è£…å¥½çš„cuda</span><br><span class="line"># è¿™é‡Œé¢åœ¨å¤šä¸ª<span class="variable constant_">CUDA</span>å®‰è£…åè¿›è¡Œåˆ‡æ¢çš„</span><br><span class="line"># ls /usr/local/ å¯æŸ¥çœ‹cuda</span><br><span class="line">alias cuda111=<span class="string">'export PATH=/usr/local/cuda-11.1/bin:$PATH'</span></span><br><span class="line">alias cuda118=<span class="string">'export PATH=/usr/local/cuda-11.8/bin:$PATH'</span></span><br><span class="line">source ~/.<span class="property">bashrc</span></span><br><span class="line"># æ¥ä¸‹æ¥å°±å¯ä»¥è‡ªç”±åˆ‡æ¢cudaäº†ï¼Œå¯nvcc -VæŸ¥çœ‹æ˜¯å¦æ­£ç¡®åˆ‡æ¢</span><br><span class="line"># ä½¿ç”¨cuda11<span class="number">.1</span></span><br><span class="line">cuda111 </span><br><span class="line"># ä½¿ç”¨cuda11<span class="number">.8</span></span><br><span class="line">cuda118</span><br></pre></td></tr></tbody></table></figure>
<h1 id="cuDNNçš„å®‰è£…"><a href="#cuDNNçš„å®‰è£…" class="headerlink" title="cuDNNçš„å®‰è£…"></a>cuDNNçš„å®‰è£…</h1><p>æ ¹æ®å®‰è£…çš„CUDAå·¥å…·åŒ…ç‰ˆæœ¬åœ¨å®˜ç½‘é€‰æ‹©é€‚åˆç‰ˆæœ¬çš„cuDNNï¼Œæœ¬æ–‡å®‰è£…çš„CUDAç‰ˆæœ¬æ˜¯11.2ï¼Œå°±é€‰æ‹©ä¸ä¹‹å¯¹åº”çš„cuDNN v8.4.0ï¼Œé€‰æ‹©Local Installer for Linux x86_64 (Tar)ã€‚</p>
<p>å¤åˆ¶cuDNNåº“çš„é“¾æ¥ï¼Œä½¿ç”¨wgetä¸‹è½½æˆ–è€…ä¸‹è½½åˆ°è‡ªå·±ç”µè„‘ä¹‹åå†ä¼ åˆ°æœåŠ¡å™¨ä¸Šã€‚<br>æˆ‘çš„æœåŠ¡å™¨ç½‘é€Ÿæœ‰ç‚¹æ…¢ï¼Œæ‰€ä»¥é€‰æ‹©å…ˆä¸‹åˆ°è‡ªå·±ç”µè„‘å†ä¼ ä¸Šå»ï¼Œé€Ÿåº¦å¾ˆå¿«å•Šã€‚</p>
<p>è§£å‹cuDNNæ–‡ä»¶ï¼Œå¹¶è¿›å…¥è§£å‹å‡ºçš„æ–‡ä»¶å¤¹ï¼Œæ‹·è´æ–‡ä»¶åˆ°/usr/local/cuda-11.2ä¸­</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">tar -xvf cudnn-linux-x86_64-8.4.0.27_cuda11.6-archive.tar.xz</span><br><span class="line"><span class="built_in">cd</span> cudnn-linux-x86_64-8.4.0.27_cuda11.6-archive</span><br><span class="line">sudo <span class="built_in">cp</span> lib/* /usr/local/cuda-11.2/lib64/</span><br><span class="line">sudo <span class="built_in">cp</span> include/* /usr/local/cuda-11.2/include/</span><br><span class="line">sudo <span class="built_in">chmod</span> a+r /usr/local/cuda-11.2/lib64/*</span><br><span class="line">sudo <span class="built_in">chmod</span> a+r /usr/local/cuda-11.2/include/*</span><br></pre></td></tr></tbody></table></figure>
<p>æŸ¥çœ‹cuDNNç‰ˆæœ¬ï¼Œæ—§ç‰ˆæœ¬æŒ‡ä»¤ ä¸ºcat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A2ï¼Œæ–°ç‰ˆæœ¬æœ‰æ›´æ–°ï¼Œå°†cuDNNç‰ˆæœ¬ä¿¡æ¯å•æ‹‰äº†ä¸€ä¸ªæ–‡ä»¶åä¸º cudnn_version.hï¼Œæ‰€ä»¥æ–°ç‰ˆæœ¬æŸ¥çœ‹cuDNNç‰ˆæœ¬çš„å‘½ä»¤ä¸º cat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2</p>
<p>å‡ºç°é—®é¢˜ï¼šError â€˜An NVIDIA kernel module â€˜nvidiaâ€™ appears to already be loaded in your kernelâ€™ when trying to get GPU support in AWS EMR<br><a href="https://unix.stackexchange.com/questions/440840/how-to-unload-kernel-module-nvidia-drm">https://unix.stackexchange.com/questions/440840/how-to-unload-kernel-module-nvidia-drm</a></p>
<h1 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h1><p>æœ‰æ—¶å€™å¥½åƒè¿˜è¦è£…cudnnï¼Œä½†æ˜¯æˆ‘é‚£æ—¶å€™æ²¡è£…ï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯å¿…è¦ï¼Œå¯ä»¥å°è¯•ä¸€ä¸‹</p>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/410764884">å¤šä¸ªCUDAç‰ˆæœ¬åˆ‡æ¢æ–¹æ³•</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/79059379">Linux ä¸‹çš„ CUDA å®‰è£…å’Œä½¿ç”¨æŒ‡å—</a></li>
<li><a href="https://blog.csdn.net/tangjiahao10/article/details/125227005">ã€Linuxã€‘å®‰è£…CUDA 11.2 å’Œ cuDNN 8.4.0å¹¶æ£€æŸ¥æ˜¯å¦å®‰è£…æˆåŠŸ_linuxæŸ¥çœ‹cudnnæ˜¯å¦å®‰è£…æˆåŠŸ-CSDNåšå®¢</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/86441879">pytorchå¤šgpuå¹¶è¡Œè®­ç»ƒ</a></li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linuxä¸­çš„SSHå¯†é’¥ç™»å½•è¿æ¥</title>
    <url>/2024/01/01/Linux/Linux%E4%B8%AD%E7%9A%84SSH%E5%AF%86%E9%92%A5%E7%99%BB%E5%BD%95%E8%BF%9E%E6%8E%A5/</url>
    <content><![CDATA[<h1 id="ç®€å•ä¸¤æ­¥èµ°"><a href="#ç®€å•ä¸¤æ­¥èµ°" class="headerlink" title="ç®€å•ä¸¤æ­¥èµ°"></a>ç®€å•ä¸¤æ­¥èµ°</h1><p>å¦‚æœä¸æƒ³çœ‹é‚£ä¹ˆå¤šåŸç†ï¼Œå¯ä»¥ç®€å•ä¸¤æ­¥èµ°</p>
<ol>
<li><p><strong>è¾“å…¥ä»¥ä¸‹å‘½ä»¤</strong></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ssh-keygen</span><br><span class="line"><span class="built_in">cd</span> .ssh</span><br><span class="line"><span class="built_in">cat</span> id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line"><span class="built_in">chmod</span> 600 authorized_keys</span><br><span class="line"><span class="built_in">chmod</span> 700 ~/.ssh</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p><strong>ä¸‹è½½å¯¹åº”å¯†é’¥id_rsaå³å¯ï¼Œåç»­å°±å¯ä»¥å¯†é’¥ç™»å½•</strong></p>
</li>
</ol>
<h1 id="è®¾ç½®-SSH-é€šè¿‡å¯†é’¥ç™»å½•"><a href="#è®¾ç½®-SSH-é€šè¿‡å¯†é’¥ç™»å½•" class="headerlink" title="è®¾ç½® SSH é€šè¿‡å¯†é’¥ç™»å½•"></a>è®¾ç½® SSH é€šè¿‡å¯†é’¥ç™»å½•</h1><p><img src="https://pic1.zhimg.com/80/v2-e62d325d3c609b70f5a297322c8739be.png" alt=""></p>
<p>æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨ PuTTY ç­‰ SSH å®¢æˆ·ç«¯æ¥è¿œç¨‹ç®¡ç† Linux æœåŠ¡å™¨ã€‚ä½†æ˜¯ï¼Œä¸€èˆ¬çš„å¯†ç æ–¹å¼ç™»å½•ï¼Œå®¹æ˜“æœ‰å¯†ç è¢«æš´åŠ›ç ´è§£çš„é—®é¢˜ã€‚æ‰€ä»¥ï¼Œä¸€èˆ¬æˆ‘ä»¬ä¼šå°† SSH çš„ç«¯å£è®¾ç½®ä¸ºé»˜è®¤çš„ 22 ä»¥å¤–çš„ç«¯å£ï¼Œæˆ–è€…ç¦ç”¨ root è´¦æˆ·ç™»å½•ã€‚å…¶å®ï¼Œæœ‰ä¸€ä¸ªæ›´å¥½çš„åŠæ³•æ¥ä¿è¯å®‰å…¨ï¼Œè€Œä¸”è®©ä½ å¯ä»¥æ”¾å¿ƒåœ°ç”¨ root è´¦æˆ·ä»è¿œç¨‹ç™»å½•â€”â€”é‚£å°±æ˜¯é€šè¿‡å¯†é’¥æ–¹å¼ç™»å½•ã€‚<br>å¯†é’¥å½¢å¼ç™»å½•çš„åŸç†æ˜¯ï¼šåˆ©ç”¨å¯†é’¥ç”Ÿæˆå™¨åˆ¶ä½œä¸€å¯¹å¯†é’¥â€”â€”ä¸€åªå…¬é’¥å’Œä¸€åªç§é’¥ã€‚å°†å…¬é’¥æ·»åŠ åˆ°æœåŠ¡å™¨çš„æŸä¸ªè´¦æˆ·ä¸Šï¼Œç„¶ååœ¨å®¢æˆ·ç«¯åˆ©ç”¨ç§é’¥å³å¯å®Œæˆè®¤è¯å¹¶ç™»å½•ã€‚è¿™æ ·ä¸€æ¥ï¼Œæ²¡æœ‰ç§é’¥ï¼Œä»»ä½•äººéƒ½æ— æ³•é€šè¿‡ SSH æš´åŠ›ç ´è§£ä½ çš„å¯†ç æ¥è¿œç¨‹ç™»å½•åˆ°ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œå¦‚æœå°†å…¬é’¥å¤åˆ¶åˆ°å…¶ä»–è´¦æˆ·ç”šè‡³ä¸»æœºï¼Œåˆ©ç”¨ç§é’¥ä¹Ÿå¯ä»¥ç™»å½•ã€‚<br>ä¸‹é¢æ¥è®²è§£å¦‚ä½•åœ¨ Linux æœåŠ¡å™¨ä¸Šåˆ¶ä½œå¯†é’¥å¯¹ï¼Œå°†å…¬é’¥æ·»åŠ ç»™è´¦æˆ·ï¼Œè®¾ç½® SSHï¼Œæœ€åé€šè¿‡å®¢æˆ·ç«¯ç™»å½•ã€‚</p>
<h2 id="1-åˆ¶ä½œå¯†é’¥å¯¹"><a href="#1-åˆ¶ä½œå¯†é’¥å¯¹" class="headerlink" title="1. åˆ¶ä½œå¯†é’¥å¯¹"></a>1. åˆ¶ä½œå¯†é’¥å¯¹</h2><p>é¦–å…ˆåœ¨æœåŠ¡å™¨ä¸Šåˆ¶ä½œå¯†é’¥å¯¹ã€‚é¦–å…ˆç”¨å¯†ç ç™»å½•åˆ°ä½ æ‰“ç®—ä½¿ç”¨å¯†é’¥ç™»å½•çš„è´¦æˆ·ï¼Œç„¶åæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[root@host ~]$ ssh-keygen  &lt;== å»ºç«‹å¯†é’¥å¯¹</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file <span class="keyword">in</span> <span class="built_in">which</span> to save the key (/root/.ssh/id_rsa): &lt;== æŒ‰ Enter</span><br><span class="line">Created directory <span class="string">'/root/.ssh'</span>.</span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase): &lt;== è¾“å…¥å¯†é’¥é”ç ï¼Œæˆ–ç›´æ¥æŒ‰ Enter ç•™ç©º</span><br><span class="line">Enter same passphrase again: &lt;== å†è¾“å…¥ä¸€éå¯†é’¥é”ç </span><br><span class="line">Your identification has been saved <span class="keyword">in</span> /root/.ssh/id_rsa. &lt;== ç§é’¥</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> /root/.ssh/id_rsa.pub. &lt;== å…¬é’¥</span><br><span class="line">The key fingerprint is:</span><br><span class="line">0f:d3:e7:1a:1c:bd:5c:03:f1:19:f1:22:<span class="built_in">df</span>:9b:cc:08 root@host</span><br></pre></td></tr></tbody></table></figure><br>å¯†é’¥é”ç åœ¨ä½¿ç”¨ç§é’¥æ—¶å¿…é¡»è¾“å…¥ï¼Œè¿™æ ·å°±å¯ä»¥ä¿æŠ¤ç§é’¥ä¸è¢«ç›—ç”¨ã€‚å½“ç„¶ï¼Œä¹Ÿå¯ä»¥ç•™ç©ºï¼Œå®ç°æ— å¯†ç ç™»å½•ã€‚<br>ç°åœ¨ï¼Œåœ¨ root ç”¨æˆ·çš„å®¶ç›®å½•ä¸­ç”Ÿæˆäº†ä¸€ä¸ª .ssh çš„éšè—ç›®å½•ï¼Œå†…å«ä¸¤ä¸ªå¯†é’¥æ–‡ä»¶ã€‚id_rsa ä¸ºç§é’¥ï¼Œid_rsa.pub ä¸ºå…¬é’¥ã€‚<br>è¿™ä¸ªåœ¨windowsä¹Ÿå¯ä»¥åˆ¶ä½œè‡ªå·±çš„å¯†é’¥å¯¹<p></p>
<h2 id="2-åœ¨æœåŠ¡å™¨ä¸Šå®‰è£…å…¬é’¥"><a href="#2-åœ¨æœåŠ¡å™¨ä¸Šå®‰è£…å…¬é’¥" class="headerlink" title="2. åœ¨æœåŠ¡å™¨ä¸Šå®‰è£…å…¬é’¥"></a>2. åœ¨æœåŠ¡å™¨ä¸Šå®‰è£…å…¬é’¥</h2><p>é”®å…¥ä»¥ä¸‹å‘½ä»¤ï¼Œåœ¨æœåŠ¡å™¨ä¸Šå®‰è£…å…¬é’¥ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[root@host ~]$ <span class="built_in">cd</span> .ssh</span><br><span class="line">[root@host .ssh]$ <span class="built_in">cat</span> id_rsa.pub &gt;&gt; authorized_keys</span><br></pre></td></tr></tbody></table></figure><br>è¿™ä¸€éƒ¨åˆ†ç›¸å½“äºï¼Œå°†è‡ªå·±çš„å…¬é’¥å†™åˆ°äº†sshæœåŠ¡å™¨ä¸­ï¼Œå†™åˆ°authorized_keysä¸­ï¼Œè¿™æ ·åªè¦æœ‰å¯†é’¥å¯¹ï¼Œå°±èƒ½æ­£å¸¸è¿æ¥ï¼ŒVScodeä¹Ÿæ˜¯<br>å¦‚æ­¤ä¾¿å®Œæˆäº†å…¬é’¥çš„å®‰è£…ã€‚ä¸ºäº†ç¡®ä¿è¿æ¥æˆåŠŸï¼Œè¯·ä¿è¯ä»¥ä¸‹æ–‡ä»¶æƒé™æ­£ç¡®ï¼š<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[root@host .ssh]$ <span class="built_in">chmod</span> 600 authorized_keys</span><br><span class="line">[root@host .ssh]$ <span class="built_in">chmod</span> 700 ~/.ssh</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="3-è®¾ç½®-SSHï¼Œæ‰“å¼€å¯†é’¥ç™»å½•åŠŸèƒ½-ï¼ˆç®¡ç†å‘˜å¯ä»¥è®¾ç½®ä»…ä»…å¯†é’¥ç™»å½•ï¼‰"><a href="#3-è®¾ç½®-SSHï¼Œæ‰“å¼€å¯†é’¥ç™»å½•åŠŸèƒ½-ï¼ˆç®¡ç†å‘˜å¯ä»¥è®¾ç½®ä»…ä»…å¯†é’¥ç™»å½•ï¼‰" class="headerlink" title="3. è®¾ç½® SSHï¼Œæ‰“å¼€å¯†é’¥ç™»å½•åŠŸèƒ½ ï¼ˆç®¡ç†å‘˜å¯ä»¥è®¾ç½®ä»…ä»…å¯†é’¥ç™»å½•ï¼‰"></a>3. è®¾ç½® SSHï¼Œæ‰“å¼€å¯†é’¥ç™»å½•åŠŸèƒ½ ï¼ˆç®¡ç†å‘˜å¯ä»¥è®¾ç½®ä»…ä»…å¯†é’¥ç™»å½•ï¼‰</h2><p>ç¼–è¾‘ /etc/ssh/sshd_config æ–‡ä»¶ï¼Œè¿›è¡Œå¦‚ä¸‹è®¾ç½®ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">RSAAuthentication <span class="built_in">yes</span></span><br><span class="line">PubkeyAuthentication <span class="built_in">yes</span></span><br></pre></td></tr></tbody></table></figure><br>å¦å¤–ï¼Œè¯·ç•™æ„ root ç”¨æˆ·èƒ½å¦é€šè¿‡ SSH ç™»å½•ï¼š<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">PermitRootLogin <span class="built_in">yes</span></span><br></pre></td></tr></tbody></table></figure><br>å½“ä½ å®Œæˆå…¨éƒ¨è®¾ç½®ï¼Œå¹¶ä»¥å¯†é’¥æ–¹å¼ç™»å½•æˆåŠŸåï¼Œå†ç¦ç”¨å¯†ç ç™»å½•ï¼š<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">PasswordAuthentication no</span><br></pre></td></tr></tbody></table></figure><br>æœ€åï¼Œé‡å¯ SSH æœåŠ¡ï¼š<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">[root@host .ssh]$ service sshd restart</span><br></pre></td></tr></tbody></table></figure><br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">#å…è®¸rootè®¤è¯ç™»å½•</span></span><br><span class="line">PermitRootLogin <span class="built_in">yes</span></span><br><span class="line"><span class="comment">#å…è®¸å¯†é’¥è®¤è¯</span></span><br><span class="line">RSAAuthentication <span class="built_in">yes</span></span><br><span class="line">PubkeyAuthentication <span class="built_in">yes</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="4-å°†ç§é’¥ä¸‹è½½åˆ°å®¢æˆ·ç«¯ï¼Œç„¶åè½¬æ¢ä¸º-PuTTY-èƒ½ä½¿ç”¨çš„æ ¼å¼"><a href="#4-å°†ç§é’¥ä¸‹è½½åˆ°å®¢æˆ·ç«¯ï¼Œç„¶åè½¬æ¢ä¸º-PuTTY-èƒ½ä½¿ç”¨çš„æ ¼å¼" class="headerlink" title="4. å°†ç§é’¥ä¸‹è½½åˆ°å®¢æˆ·ç«¯ï¼Œç„¶åè½¬æ¢ä¸º PuTTY èƒ½ä½¿ç”¨çš„æ ¼å¼"></a>4. å°†ç§é’¥ä¸‹è½½åˆ°å®¢æˆ·ç«¯ï¼Œç„¶åè½¬æ¢ä¸º PuTTY èƒ½ä½¿ç”¨çš„æ ¼å¼</h2><p>ä½¿ç”¨ WinSCPã€SFTP ç­‰å·¥å…·å°†ç§é’¥æ–‡ä»¶ id_rsa ä¸‹è½½åˆ°å®¢æˆ·ç«¯æœºå™¨ä¸Šã€‚ç„¶åæ‰“å¼€ PuTTYGenï¼Œå•å‡» Actions ä¸­çš„ Load æŒ‰é’®ï¼Œè½½å…¥ä½ åˆšæ‰ä¸‹è½½åˆ°çš„ç§é’¥æ–‡ä»¶ã€‚å¦‚æœä½ åˆšæ‰è®¾ç½®äº†å¯†é’¥é”ç ï¼Œè¿™æ—¶åˆ™éœ€è¦è¾“å…¥ã€‚<br>è½½å…¥æˆåŠŸåï¼ŒPuTTYGen ä¼šæ˜¾ç¤ºå¯†é’¥ç›¸å…³çš„ä¿¡æ¯ã€‚åœ¨ Key comment ä¸­é”®å…¥å¯¹å¯†é’¥çš„è¯´æ˜ä¿¡æ¯ï¼Œç„¶åå•å‡» Save private key æŒ‰é’®å³å¯å°†ç§é’¥æ–‡ä»¶å­˜æ”¾ä¸º PuTTY èƒ½ä½¿ç”¨çš„æ ¼å¼ã€‚<br>ä»Šåï¼Œå½“ä½ ä½¿ç”¨ PuTTY ç™»å½•æ—¶ï¼Œå¯ä»¥åœ¨å·¦ä¾§çš„ Connection -&gt; SSH -&gt; Auth ä¸­çš„ Private key file for authentication: å¤„é€‰æ‹©ä½ çš„ç§é’¥æ–‡ä»¶ï¼Œç„¶åå³å¯ç™»å½•äº†ï¼Œè¿‡ç¨‹ä¸­åªéœ€è¾“å…¥å¯†é’¥é”ç å³å¯ã€‚</p>
<h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><p><a href="https://wangdoc.com/ssh/key#ssh-keygen%E5%91%BD%E4%BB%A4%E7%94%9F%E6%88%90%E5%AF%86%E9%92%A5">https://wangdoc.com/ssh/key#ssh-keygen%E5%91%BD%E4%BB%A4%E7%94%9F%E6%88%90%E5%AF%86%E9%92%A5</a></p>
<h2 id="è¡¥å……"><a href="#è¡¥å……" class="headerlink" title="è¡¥å……"></a>è¡¥å……</h2><p>å…¶å®å¯ä»¥ä¸€ä¸ªå¯†é’¥å¤šä¸ªæœåŠ¡å™¨ï¼Œåªè¦æŠŠå…¬é’¥è¾“å…¥åˆ°authorized_keysä¸­ï¼Œè¿™æ ·åªè¦æœ‰å¯†é’¥å¯¹ï¼Œå°±èƒ½æ­£å¸¸è¿æ¥ï¼Œæ‰€ä»¥å¯ä»¥ç”¨å¾ˆå¤šä¸ªå³å¯ï¼Œä¸è¿‡ä¸ºäº†å®‰å…¨ï¼Œå¯ä»¥åªç”¨ä¸€ä¸ªå¯†é’¥</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linuxä¸­ä¿®æ”¹ç”¨æˆ·UIDå’Œç»„GIDçš„æ–¹æ³•</title>
    <url>/2024/01/01/Linux/Linux%E4%B8%AD%E4%BF%AE%E6%94%B9%E7%94%A8%E6%88%B7UID%E5%92%8C%E7%BB%84GID%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>æˆ‘åœ¨éƒ¨ç½²nfsçš„æ—¶å€™ï¼Œå…±äº«äº†ä¸€ä¸ªæ–‡ä»¶å¤¹ã€‚ä¸ºäº†è®©è¿œç¨‹nfså®¢æˆ·ç«¯æŒ‚è½½è¿™ä¸ªæ–‡ä»¶å¤¹çš„æ—¶å€™éƒ½æœ‰å¯è¯»å†™æƒé™ï¼Œæˆ‘éœ€è¦æŠŠæœåŠ¡å™¨ä¸Šçš„ç”¨æˆ·uidã€gidè®¾ç½®æˆnfsæœåŠ¡ç«¯æ–‡ä»¶å¤¹ä¸€æ ·çš„æƒé™ã€‚ä¸è¿‡å› ä¸ºä¹‹å‰æ–°å»ºçš„ç”¨æˆ·uidã€gidéƒ½æ˜¯ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„ï¼Œå‡ å°æœåŠ¡å™¨ä¹‹å‰æŸä¸ªç”¨æˆ·çš„uidã€gidå¯èƒ½éƒ½ä¸ä¸€æ ·ï¼Œæ‰€ä»¥ç°åœ¨éœ€è¦æŠŠè¿™ä¸ªuidã€gidéƒ½è®¾ç½®æˆç»Ÿä¸€æŸä¸ªå€¼ã€‚</p>
<p>ä¿®æ”¹ç”¨æˆ·uidå’Œç»„gidçš„å‘½ä»¤åˆ†åˆ«æ˜¯usermodå’Œgroupmodï¼Œæ€è·¯å¾ˆç®€å•ã€‚å…ˆä½¿ç”¨usermodä¿®æ”¹ç”¨æˆ·çš„uidï¼Œç„¶åä½¿ç”¨groupmodä¿®æ”¹ç»„çš„gidï¼Œæœ€åä½¿ç”¨chownå’Œchgrpå‘½ä»¤ä¿®æ”¹åŸæ¥ç”¨æˆ·æ–‡ä»¶å’Œç›®å½•çš„å±ä¸»å±ç»„ã€‚<br>ä¾‹å¦‚æµ‹è¯•ç”¨æˆ·fooå’Œæµ‹è¯•ç»„fooã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">foo old UID: 1005</span><br><span class="line">foo new UID: 2005</span><br><span class="line">foo old GID: 2000</span><br><span class="line">foo new GID: 3000</span><br></pre></td></tr></tbody></table></figure>
<h2 id="å‘½ä»¤ï¼š"><a href="#å‘½ä»¤ï¼š" class="headerlink" title="å‘½ä»¤ï¼š"></a>å‘½ä»¤ï¼š</h2><p>1ã€ä¿®æ”¹fooç”¨æˆ·çš„uid<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">usermod -u 2005 foo</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>2ã€ä¿®æ”¹fooç»„çš„gid<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">groupmod -g 3000 foo</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>3ã€fooç”¨æˆ·çš„å®¶ç›®å½•ä¸‹é¢çš„æ–‡ä»¶å±ä¸»å’Œå±ç»„ä¼šåœ¨1ã€2å‘½ä»¤æ‰§è¡Œåè‡ªåŠ¨ä¿®æ”¹æˆæ–°çš„uidã€gidå¯¹åº”çš„å±ä¸»å±ç»„ï¼Œä½†æ˜¯å…¶ä»–æ–‡ä»¶ç›®å½•éœ€è¦æ‰‹åŠ¨ä¿®æ”¹ã€‚æ‰‹åŠ¨ä¿®æ”¹çš„å‘½ä»¤ä¹Ÿæ¯”è¾ƒç®€å•ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># åˆ©ç”¨name</span></span><br><span class="line">find / -user 1005 -<span class="built_in">exec</span> <span class="built_in">chown</span> -h foo {} ;</span><br><span class="line">find / -group 2000 -<span class="built_in">exec</span> <span class="built_in">chgrp</span> -h foo {} ;</span><br><span class="line"><span class="comment"># åˆ©ç”¨old id</span></span><br><span class="line">find / -user 1005 -<span class="built_in">exec</span> <span class="built_in">chown</span> -h 2005 {} ;</span><br><span class="line">find / -group 2000 -<span class="built_in">exec</span> <span class="built_in">chgrp</span> -h 3000 {} ;</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™æ ·ç”¨æˆ·å’Œç»„çš„uidã€gidå°±ä¿®æ”¹å¥½äº†ã€‚å¯ä»¥ç”¨idå‘½ä»¤çœ‹ä¸‹æ˜¯å¦ä¿®æ”¹çš„å¦‚æˆ‘ä»¬æ‰€æ„¿ã€‚<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">ls</span> -l /home/foo/</span><br><span class="line"></span><br><span class="line"><span class="built_in">id</span> -u foo</span><br><span class="line"></span><br><span class="line"><span class="built_in">id</span> -g foo</span><br><span class="line"></span><br><span class="line">grep foo /etc/passwd</span><br><span class="line"></span><br><span class="line">grep foo /etc/group</span><br></pre></td></tr></tbody></table></figure><p></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linuxå®‰å…¨é…ç½®Fail2ban</title>
    <url>/2024/01/01/Linux/Linux%E5%AE%89%E5%85%A8%E9%85%8D%E7%BD%AEfail2ban/</url>
    <content><![CDATA[<h3 id="é£é™©æš´éœ²"><a href="#é£é™©æš´éœ²" class="headerlink" title="é£é™©æš´éœ²"></a>é£é™©æš´éœ²</h3><p>æ‰€æœ‰è¿æ¥åˆ°äº’è”ç½‘çš„æœåŠ¡å™¨éƒ½é¢ä¸´æ¶æ„è½¯ä»¶æ”»å‡»çš„é£é™©ã€‚è¿æ¥åˆ°äº’è”ç½‘çš„è½¯ä»¶å¯èƒ½æˆä¸ºæ”»å‡»è€…è›®åŠ›å°è¯•çš„ç›®æ ‡ï¼Œè¯•å›¾è®¿é—®åº”ç”¨ç¨‹åºã€‚</p>
<h3 id="ä½¿ç”¨Fail2banå·¥å…·"><a href="#ä½¿ç”¨Fail2banå·¥å…·" class="headerlink" title="ä½¿ç”¨Fail2banå·¥å…·"></a>ä½¿ç”¨Fail2banå·¥å…·</h3><p>Fail2banæ˜¯ä¸€ä¸ªå¼€æºå·¥å…·ï¼Œå¯å¸®åŠ©ä¿æŠ¤Linuxå…å—æš´åŠ›æ”»å‡»å’Œå…¶ä»–è‡ªåŠ¨æ”»å‡»ã€‚å®ƒé€šè¿‡ç›‘è§†æœåŠ¡æ—¥å¿—ä¸­çš„æ¶æ„æ´»åŠ¨æ¥å·¥ä½œï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ‰«ææ—¥å¿—æ–‡ä»¶ã€‚</p>
<h4 id="å·¥ä½œåŸç†"><a href="#å·¥ä½œåŸç†" class="headerlink" title="å·¥ä½œåŸç†"></a>å·¥ä½œåŸç†</h4><ol>
<li>æ‰«ææ—¥å¿—æ–‡ä»¶ï¼ŒåŒ¹é…ç‰¹å®šæ¨¡å¼çš„è®°å½•ã€‚</li>
<li>è®¡æ•°åŒ¹é…è®°å½•ï¼Œå½“æ•°é‡è¾¾åˆ°é¢„å®šä¹‰é˜ˆå€¼æ—¶é‡‡å–æªæ–½ã€‚</li>
<li>åœ¨æŒ‡å®šæ—¶é—´æ®µå†…ç¦æ­¢æœ‰é—®é¢˜çš„IPã€‚</li>
<li>é»˜è®¤ä½¿ç”¨ç³»ç»Ÿé˜²ç«å¢™é˜»æ­¢è¢«ç¦æ­¢IPçš„è®¿é—®ã€‚</li>
<li>ç¦æ­¢æœŸé™åˆ°æœŸåï¼ŒIPåœ°å€å°†ä»ç¦æ­¢åˆ—è¡¨ä¸­åˆ é™¤ã€‚</li>
</ol>
<h3 id="å®‰è£…å’Œé…ç½®Fail2ban"><a href="#å®‰è£…å’Œé…ç½®Fail2ban" class="headerlink" title="å®‰è£…å’Œé…ç½®Fail2ban"></a>å®‰è£…å’Œé…ç½®Fail2ban</h3><p>å¦‚æœéœ€è¦æ›´æ–°å’Œå‡çº§æœåŠ¡å™¨ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade</span><br><span class="line">sudo apt-get install -y fail2ban</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>åœ¨rootçŠ¶æ€ä¸‹ï¼Œç¼–è¾‘Fail2bançš„é…ç½®æ–‡ä»¶ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">vim /etc/fail2ban/jail.local</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>é…ç½®æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼ˆæ³¨æ„ä¿®æ”¹sshç«¯å£å’Œsshdæ—¥å¿—è·¯å¾„ï¼‰ï¼š<br></p><figure class="highlight properties"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attr">[sshd]</span></span><br><span class="line"><span class="attr">port</span> = <span class="string">2223</span></span><br><span class="line"><span class="attr">enabled</span> = <span class="string">true</span></span><br><span class="line"><span class="attr">filter</span> = <span class="string">sshd</span></span><br><span class="line"><span class="attr">logpath</span> = <span class="string">/var/log/auth.log</span></span><br><span class="line"><span class="attr">maxretry</span> = <span class="string">6</span></span><br><span class="line"><span class="attr">findtime</span> = <span class="string">60</span></span><br><span class="line"><span class="attr">bantime</span> = <span class="string">86400</span></span><br><span class="line"></span><br><span class="line"><span class="attr">[ssh-iptables]</span></span><br><span class="line"><span class="attr">enabled</span> = <span class="string">true</span></span><br><span class="line"><span class="attr">filter</span> = <span class="string">sshd</span></span><br><span class="line"><span class="attr">action</span> = <span class="string">iptables[name=SSH, port=ssh, protocol=tcp]</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<p>é‡å¯Fail2banæœåŠ¡ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo service fail2ban restart</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="ä½¿ç”¨Fail2ban"><a href="#ä½¿ç”¨Fail2ban" class="headerlink" title="ä½¿ç”¨Fail2ban"></a>ä½¿ç”¨Fail2ban</h3><p>æ£€æŸ¥è¢«å°ç¦çš„IPï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">fail2ban-client status sshd</span><br></pre></td></tr></tbody></table></figure><p></p>
<p>å–æ¶ˆè¢«ç¦æ­¢çš„IPåœ°å€ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo fail2ban-client <span class="built_in">set</span> sshd unbanip IP_ADDRESS</span><br></pre></td></tr></tbody></table></figure><br>ï¼ˆå…¶ä¸­ï¼Œ<code>IP_ADDRESS</code>æ˜¯è¢«ç¦æ­¢çš„IPåœ°å€ï¼‰<p></p>
<h3 id="å¯ç”¨ufwé˜²ç«å¢™"><a href="#å¯ç”¨ufwé˜²ç«å¢™" class="headerlink" title="å¯ç”¨ufwé˜²ç«å¢™"></a>å¯ç”¨ufwé˜²ç«å¢™</h3><ol>
<li><p>å®‰è£…ufwï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install ufw</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>å¯ç”¨ufwï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw <span class="built_in">enable</span></span><br><span class="line">sudo ufw default allow</span><br><span class="line">sudo ufw allow ssh</span><br><span class="line">sudo ufw allow 2223</span><br></pre></td></tr></tbody></table></figure>
<p>ä»¥ä¸Šæ˜¯ç®€å•çš„ä¿æŠ¤æªæ–½ï¼Œä½†è®°å¾—éšæ—¶ä¿æŒç³»ç»Ÿå’Œè½¯ä»¶æ›´æ–°ä»¥ç¡®ä¿å®‰å…¨æ€§ã€‚</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linuxåˆ›å»ºç”¨æˆ·ã€è®¾ç½®å¯†ç </title>
    <url>/2024/01/01/Linux/Linux%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7%E3%80%81%E8%AE%BE%E7%BD%AE%E5%AF%86%E7%A0%81/</url>
    <content><![CDATA[<h2 id="åˆ›å»ºç”¨æˆ·"><a href="#åˆ›å»ºç”¨æˆ·" class="headerlink" title="åˆ›å»ºç”¨æˆ·"></a>åˆ›å»ºç”¨æˆ·</h2><p>ç”±äºæ¯å°æœåŠ¡å™¨éƒ½éœ€è¦è¿æ¥åˆ° NASï¼Œè€Œä¸”å¯èƒ½å¾ˆå¤šç”¨æˆ·åœ¨ä¸åŒçš„æœåŠ¡å™¨ä¸Šéƒ½æœ‰è´¦å·ï¼Œè¿™æ ·çš„è¯å°±ä¼šå¯¼è‡´ uid å†²çªï¼ˆä¸åŒæœåŠ¡å™¨ä¸Šä¸åŒç”¨æˆ·çš„ uid å¯èƒ½æ˜¯ä¸€æ ·çš„ï¼‰ï¼Œå› æ­¤ï¼Œé’ˆå¯¹ä¸åŒæƒ…å†µéœ€è¦ç”¨åˆ°ä¸åŒæ·»åŠ ç”¨æˆ·çš„æ–¹æ³•ï¼š</p>
<ol>
<li>è¯¥ç”¨æˆ·ä¸ºæ–°åŒå­¦ï¼Œè¯´æ˜ä»–ä¹‹å‰åœ¨å…¶ä»–æœåŠ¡å™¨ä¸Šæ²¡æœ‰è´¦å·ï¼Œå› æ­¤ï¼Œå…ˆåœ¨ NAS ä¸Šä¸ºä»–å¼€ä¸€ä¸ªè´¦å·ç¡®ä¿ uid å”¯ä¸€æ€§ï¼Œå†æ ¹æ®è¿™ä¸ª uid å»å…¶ä»–çš„æœåŠ¡å™¨ä¸Šè¿›è¡Œå¼€å·ã€‚</li>
<li>è¯¥ç”¨æˆ·åœ¨å…¶ä»–æœåŠ¡å™¨ä¸Šæœ‰è´¦å·ï¼Œé‚£å°±ç›´æ¥æ ¹æ®ä»–çš„ uid è¿›è¡Œå¼€å·ï¼Œæ— éœ€å†ç»è¿‡ä¸€é NASã€‚</li>
</ol>
<p>å¼€å·æ–¹å¼ä½¿ç”¨å‘½ä»¤ useradd ï¼Œé»˜è®¤æƒ…å†µä¸‹ç›´æ¥ useradd user1 å°±å¯ä»¥äº†ï¼Œç”¨æˆ·ç›®å½•ä¸º /home/user1ï¼Œä½†æ˜¯è€ƒè™‘åˆ°æœåŠ¡å™¨ç¡¬ç›˜å®¹é‡æœ‰é™ï¼Œæœ€å¥½å°†å…¶åˆ’åˆ†åˆ°å…·æœ‰æ›´å¤§ç©ºé—´çš„ç›®å½•å¦‚ /dataï¼Œå› æ­¤ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿›è¡Œè‡ªå®šä¹‰æ·»åŠ ç”¨æˆ·<br>åœ¨æœåŠ¡å™¨ä¸­ï¼Œå¯ä»¥é€šè¿‡ df -h æ¥æŸ¥çœ‹ç£ç›˜ç©ºé—´ï¼Œé»˜è®¤uidå’Œgidä¸ºåŒä¸€ä¸ª<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ useradd -u [uid] -g [gid] -d /data/user1 -m -s /bin/bash user1</span><br></pre></td></tr></tbody></table></figure><p></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>é€‰é¡¹</th>
<th>å«ä¹‰</th>
</tr>
</thead>
<tbody>
<tr>
<td>-u UID</td>
<td>æ‰‹å·¥æŒ‡å®šç”¨æˆ·çš„ UIDï¼Œæ³¨æ„ UID çš„èŒƒå›´ï¼ˆä¸è¦å°äº 500ï¼‰ã€‚</td>
</tr>
<tr>
<td>-d ä¸»ç›®å½•</td>
<td>æ‰‹å·¥æŒ‡å®šç”¨æˆ·çš„ä¸»ç›®å½•ã€‚ä¸»ç›®å½•å¿…é¡»å†™ç»å¯¹è·¯å¾„ï¼Œè€Œä¸”å¦‚æœéœ€è¦æ‰‹å·¥æŒ‡å®šä¸»ç›®å½•ï¼Œåˆ™ä¸€å®šè¦æ³¨æ„æƒé™ï¼›</td>
</tr>
<tr>
<td>-c ç”¨æˆ·è¯´æ˜</td>
<td>æ‰‹å·¥æŒ‡å®š/etc/passwdæ–‡ä»¶ä¸­å„ç”¨æˆ·ä¿¡æ¯ä¸­ç¬¬ 5 ä¸ªå­—æ®µçš„æè¿°æ€§å†…å®¹ï¼Œå¯éšæ„é…ç½®ï¼›</td>
</tr>
<tr>
<td>-g ç»„å</td>
<td>æ‰‹å·¥æŒ‡å®šç”¨æˆ·çš„åˆå§‹ç»„ã€‚ä¸€èˆ¬ä»¥å’Œç”¨æˆ·åç›¸åŒçš„ç»„ä½œä¸ºç”¨æˆ·çš„åˆå§‹ç»„ï¼Œåœ¨åˆ›å»ºç”¨æˆ·æ—¶ä¼šé»˜è®¤å»ºç«‹åˆå§‹ç»„ã€‚ä¸€æ—¦æ‰‹åŠ¨æŒ‡å®šï¼Œåˆ™ç³»ç»Ÿå°†ä¸ä¼šåœ¨åˆ›å»ºæ­¤é»˜è®¤çš„åˆå§‹ç»„ç›®å½•ã€‚</td>
</tr>
<tr>
<td>-G ç»„å</td>
<td>æŒ‡å®šç”¨æˆ·çš„é™„åŠ ç»„ã€‚æˆ‘ä»¬æŠŠç”¨æˆ·åŠ å…¥å…¶ä»–ç»„ï¼Œä¸€èˆ¬éƒ½ä½¿ç”¨é™„åŠ ç»„ï¼›</td>
</tr>
<tr>
<td>-s shell</td>
<td>æ‰‹å·¥æŒ‡å®šç”¨æˆ·çš„ç™»å½• Shellï¼Œé»˜è®¤æ˜¯ /bin/bashï¼›</td>
</tr>
<tr>
<td>-e æ›°æœŸ</td>
<td>æŒ‡å®šç”¨æˆ·çš„å¤±æ•ˆæ›°æœŸï¼Œæ ¼å¼ä¸º â€œYYYY-MM-DDâ€ã€‚ä¹Ÿå°±æ˜¯ /etc/shadow æ–‡ä»¶çš„ç¬¬å…«ä¸ªå­—æ®µï¼›</td>
</tr>
<tr>
<td>-o</td>
<td>å…è®¸åˆ›å»ºçš„ç”¨æˆ·çš„ UID ç›¸åŒã€‚ä¾‹å¦‚ï¼Œæ‰§è¡Œ â€œuseradd -u 0 -o usertestâ€ å‘½ä»¤å»ºç«‹ç”¨æˆ· usertestï¼Œå®ƒçš„ UID å’Œ root ç”¨æˆ·çš„ UID ç›¸åŒï¼Œéƒ½æ˜¯ 0ï¼›</td>
</tr>
<tr>
<td>-m</td>
<td>å»ºç«‹ç”¨æˆ·æ—¶å¼ºåˆ¶å»ºç«‹ç”¨æˆ·çš„å®¶ç›®å½•ã€‚åœ¨å»ºç«‹ç³»ç»Ÿç”¨æˆ·æ—¶ï¼Œè¯¥é€‰é¡¹æ˜¯é»˜è®¤çš„ï¼›</td>
</tr>
<tr>
<td>-r</td>
<td>åˆ›å»ºç³»ç»Ÿç”¨æˆ·ï¼Œä¹Ÿå°±æ˜¯ UID åœ¨ 1~499 ä¹‹é—´ï¼Œä¾›ç³»ç»Ÿç¨‹åºä½¿ç”¨çš„ç”¨æˆ·ã€‚ç”±äºç³»ç»Ÿç”¨æˆ·ä¸»è¦ç”¨äºè¿è¡Œç³»ç»Ÿæ‰€éœ€æœåŠ¡çš„æƒé™é…ç½®ï¼Œå› æ­¤ç³»ç»Ÿç”¨æˆ·çš„åˆ›å»ºé»˜è®¤ä¸ä¼šåˆ›å»ºä¸»ç›®å½•ã€‚</td>
</tr>
</tbody>
</table>
</div>
<h2 id="è®¾ç½®å¯†ç "><a href="#è®¾ç½®å¯†ç " class="headerlink" title="è®¾ç½®å¯†ç "></a>è®¾ç½®å¯†ç </h2><p>å¼€äº†ç”¨æˆ·ä»¥åï¼Œå¯ä»¥è¿›è¡Œè®¾ç½®å¯†ç <br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo passwd user1</span><br></pre></td></tr></tbody></table></figure><br>è®¾ç½®å¯†ç çš„æ—¶å€™ï¼Œå¯ä»¥è¿›è¡Œéšæœºç”Ÿæˆå¯†ç å¾—åˆ°ç»“æœï¼Œè¿™æ ·ä¸å®¹æ˜“è¢«çˆ†ç ´<br><a href="https://1password.com/zh-cn/password-generator/">åˆ›å»ºå¼ºå¤§ã€å®‰å…¨ã€éšæœºçš„å¯†ç  | Password å¯†ç ç”Ÿæˆå™¨ | 1Password</a><br><a href="https://suijimimashengcheng.bmcx.com">ç”Ÿæˆéšæœºå¯†ç  - å¯†ç ç”Ÿæˆå™¨ - å¯†ç æ‰¹é‡ç”Ÿæˆå™¨</a><p></p>
<h2 id="æƒé™è®¾ç½®"><a href="#æƒé™è®¾ç½®" class="headerlink" title="æƒé™è®¾ç½®"></a>æƒé™è®¾ç½®</h2><p>å¦‚æœéœ€è¦åŠ å…¥ä¸€äº›æƒé™ï¼Œæ¯”å¦‚rootæƒé™ï¼Œé¦–å…ˆæˆ‘ä»¬å¯ä»¥æŸ¥çœ‹ä¸€ä¸‹ç”¨æˆ·çš„æƒé™<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo <span class="built_in">cat</span> /etc/sudoers</span><br></pre></td></tr></tbody></table></figure><p></p>
<ul>
<li>å¢åŠ æƒé™ sudo gpasswd -a username sudo / sudo usermod -aG sudo username </li>
<li>åˆ é™¤æƒé™ sudo gpasswd -d username sudo</li>
</ul>
<h2 id="å‘½ä»¤è¡Œçª—å£ä¸‹ç”¨æˆ·çš„ç›¸äº’åˆ‡æ¢"><a href="#å‘½ä»¤è¡Œçª—å£ä¸‹ç”¨æˆ·çš„ç›¸äº’åˆ‡æ¢" class="headerlink" title="å‘½ä»¤è¡Œçª—å£ä¸‹ç”¨æˆ·çš„ç›¸äº’åˆ‡æ¢"></a>å‘½ä»¤è¡Œçª—å£ä¸‹ç”¨æˆ·çš„ç›¸äº’åˆ‡æ¢</h2><p>su ç”¨æˆ·å è¯´æ˜ï¼šsuæ˜¯switch userçš„ç¼©å†™ï¼Œè¡¨ç¤ºç”¨æˆ·åˆ‡æ¢</p>
<h2 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h2><ul>
<li>usermod â€”help ä¿®æ”¹ç”¨æˆ·è¿™ä¸ªå‘½ä»¤çš„ç›¸å…³å‚æ•°</li>
<li>userdel testuser åˆ é™¤ç”¨æˆ·testuser</li>
<li>rm -rf testuser åˆ é™¤ç”¨æˆ·testuseræ‰€åœ¨ç›®å½•</li>
</ul>
<p>åˆ›å»ºæ–°ç”¨æˆ·åï¼ŒåŒæ—¶ä¼šåœ¨etcç›®å½•ä¸‹çš„passwdæ–‡ä»¶ä¸­æ·»åŠ è¿™ä¸ªæ–°ç”¨æˆ·çš„ç›¸å…³ä¿¡æ¯</p>
<ul>
<li>groupadd testgroup ç»„çš„æ·»åŠ </li>
<li>groupdel testgroup ç»„çš„åˆ é™¤ </li>
</ul>
<p>è¯´æ˜ï¼šç»„çš„å¢åŠ å’Œåˆ é™¤ä¿¡æ¯ä¼šåœ¨etcç›®å½•çš„groupæ–‡ä»¶ä¸­ä½“ç°å‡ºæ¥ã€‚</p>
<p>ç®¡ç†å‘˜æŸ¥çœ‹æ‰€æœ‰ç”¨æˆ·</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">cat</span> /etc/passwd</span><br></pre></td></tr></tbody></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linuxå¸¸ç”¨æŠ€å·§åŠå‘½ä»¤ï¼ˆä¸æ–­æ›´æ–°ï¼‰</title>
    <url>/2024/01/01/Linux/Linux%E5%B8%B8%E7%94%A8%E6%8A%80%E5%B7%A7%E5%8F%8A%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<h2 id="å¸¸ç”¨å‘½ä»¤"><a href="#å¸¸ç”¨å‘½ä»¤" class="headerlink" title="å¸¸ç”¨å‘½ä»¤"></a>å¸¸ç”¨å‘½ä»¤</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">å‘½ä»¤</th>
<th style="text-align:left">command</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">æŸ¥çœ‹ GPU ä½¿ç”¨çŠ¶æ€</td>
<td style="text-align:left">nvidia-smi</td>
<td>gpustat -i (éœ€ pip install gpustat)</td>
<td>nvitopï¼ˆéœ€pip install nvitopï¼‰</td>
</tr>
<tr>
<td style="text-align:left">æŸ¥çœ‹è¿›ç¨‹</td>
<td style="text-align:left">topã€htopã€ps -ef</td>
<td>grep [pid]</td>
</tr>
<tr>
<td style="text-align:left">æŸ¥çœ‹æœåŠ¡å™¨ç£ç›˜å®¹é‡</td>
<td style="text-align:left">df -h</td>
</tr>
<tr>
<td style="text-align:left">æŸ¥çœ‹è‡ªå·±å ç”¨æœåŠ¡å™¨çš„å®¹é‡</td>
<td style="text-align:left">du -h</td>
</tr>
<tr>
<td style="text-align:left">æŸ¥çœ‹å½“å‰ç›®å½•ä¸‹æ–‡ä»¶ä¸ªæ•° (ä¸åŒ…å«å­ç›®å½•)</td>
<td style="text-align:left">ls -l</td>
<td>grep â€œ^-â€œ</td>
<td>wc -l</td>
</tr>
<tr>
<td style="text-align:left">æŸ¥çœ‹ç«¯å£å ç”¨ (Linux)</td>
<td style="text-align:left">lsof -i:PORT (æ²¡æœ‰ç©ºæ ¼)</td>
</tr>
<tr>
<td style="text-align:left">æŸ¥çœ‹ç«¯å£å ç”¨ (Windows)</td>
<td style="text-align:left">æŸ¥çœ‹æ‰€æœ‰å¼€æ”¾ç«¯å£ï¼š netstat -ano æŸ¥çœ‹å ç”¨ç«¯å£ç¨‹åºçš„ PIDï¼šnetstat -aon</td>
<td>findstr â€œPORTâ€ æŸ¥çœ‹å ç”¨ç«¯å£çš„ PID æ‰€å¯¹åº”çš„ç¨‹åºï¼štasklist</td>
<td>findstr â€œPIDâ€ æ€æ­»å ç”¨ç«¯å£çš„è¿›ç¨‹ï¼štaskkill /T /F /PID â€œPIDâ€</td>
</tr>
</tbody>
</table>
</div>
<h2 id="Linuxçš„Vimå¸¸ç”¨å¿«æ·é”®"><a href="#Linuxçš„Vimå¸¸ç”¨å¿«æ·é”®" class="headerlink" title="Linuxçš„Vimå¸¸ç”¨å¿«æ·é”®"></a>Linuxçš„Vimå¸¸ç”¨å¿«æ·é”®</h2><p><a href="https://www.runoob.com/w3cnote/all-vim-cheatsheat.html">https://www.runoob.com/w3cnote/all-vim-cheatsheat.html</a></p>
<p><img src="https://picx.zhimg.com/v2-8ccbfe019bbbb1f2062d5bd6ff9d75f4.png" alt="Linuxçš„Vimå¸¸ç”¨å¿«æ·é”®"></p>
<h2 id="è§£å‹ä¸­æ–‡æ–‡ä»¶"><a href="#è§£å‹ä¸­æ–‡æ–‡ä»¶" class="headerlink" title="è§£å‹ä¸­æ–‡æ–‡ä»¶"></a>è§£å‹ä¸­æ–‡æ–‡ä»¶</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">unzip -O GBK è„‘PETå›¾åƒåˆ†æå’Œç–¾ç—…é¢„æµ‹æŒ‘æˆ˜èµ›å…¬å¼€æ•°æ®.zip</span><br></pre></td></tr></tbody></table></figure>
<h2 id="æŸ¥çœ‹è¿›ç¨‹ä½¿ç”¨è€…ä»¥åŠå‘½ä»¤"><a href="#æŸ¥çœ‹è¿›ç¨‹ä½¿ç”¨è€…ä»¥åŠå‘½ä»¤" class="headerlink" title="æŸ¥çœ‹è¿›ç¨‹ä½¿ç”¨è€…ä»¥åŠå‘½ä»¤"></a>æŸ¥çœ‹è¿›ç¨‹ä½¿ç”¨è€…ä»¥åŠå‘½ä»¤</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ps -p &lt;PID&gt; -o user,cmd</span><br></pre></td></tr></tbody></table></figure>
<p>è¯·æ³¨æ„ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œç‰¹æƒç”¨æˆ·å¯èƒ½æ— æ³•æŸ¥çœ‹å…¶ä»–ç”¨æˆ·çš„è¿›ç¨‹ä¿¡æ¯ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦ä»¥rootç”¨æˆ·æˆ–æ‹¥æœ‰é€‚å½“æƒé™çš„ç”¨æˆ·èº«ä»½è¿è¡Œ<code>ps</code>å‘½ä»¤ã€‚</p>
<h2 id="æŸ¥æ‰¾å†å²è®°å½•"><a href="#æŸ¥æ‰¾å†å²è®°å½•" class="headerlink" title="æŸ¥æ‰¾å†å²è®°å½•"></a>æŸ¥æ‰¾å†å²è®°å½•</h2><p>æŸ¥æ‰¾å†å²è®°å½•ä¸­åŒ…å«å…³é”®å­—çš„å‘½ä»¤ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">history</span> | grep å…³é”®å­—</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™ä¸ªå‘½ä»¤å°†æ˜¾ç¤ºåŒ…å«æŒ‡å®šå…³é”®å­—çš„å†å²è®°å½•å‘½ä»¤ã€‚é€šè¿‡ä½¿ç”¨<code>history</code>å‘½ä»¤æŸ¥çœ‹æœ€è¿‘ä½¿ç”¨çš„å‘½ä»¤åˆ—è¡¨ï¼Œå¹¶ç»“åˆ<code>grep</code>å‘½ä»¤åœ¨æ–‡æœ¬ä¸­æœç´¢æŒ‡å®šæ¨¡å¼ï¼ˆæˆ–å…³é”®å­—ï¼‰ã€‚</p>
<h2 id="æ‰¹é‡-kill-è¿›ç¨‹"><a href="#æ‰¹é‡-kill-è¿›ç¨‹" class="headerlink" title="æ‰¹é‡ kill è¿›ç¨‹"></a>æ‰¹é‡ kill è¿›ç¨‹</h2><p>ç”¨ grep é…åˆ awk å¯ä»¥è½»æ˜“åšåˆ°ï¼Œ<code>awk '{print $2}'</code> è¡¨ç¤ºè¾“å‡ºç¬¬äºŒåˆ—ç»“æœï¼Œåœ¨ ps å‘½ä»¤ä¸­å°±æ˜¯è¿›ç¨‹çš„ id å·</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ps -ef | grep xxx | grep -v grep | awk <span class="string">'{print $2}'</span> | xargs <span class="built_in">kill</span> -9</span><br></pre></td></tr></tbody></table></figure>
<p>å¦‚æœè¦killæ‰æ‰€æœ‰pythonçš„è¿›ç¨‹</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pkill python</span><br></pre></td></tr></tbody></table></figure>
<h2 id="æŸ¥çœ‹å†…å­˜å ç”¨"><a href="#æŸ¥çœ‹å†…å­˜å ç”¨" class="headerlink" title="æŸ¥çœ‹å†…å­˜å ç”¨"></a>æŸ¥çœ‹å†…å­˜å ç”¨</h2><p>è¾“å…¥ <code>ps aux | sort -k4nr | head -n 5</code> æŸ¥çœ‹å ç”¨å†…å­˜æœ€å¤šçš„å‰ 5 ä¸ªè¿›ç¨‹ï¼Œæˆ–è€…ä¹Ÿå¯ä»¥é€šè¿‡ <code>top</code> å‘½ä»¤åæŒ‰ä½ <code>M</code> æ¥å¯¹å†…å­˜å ç”¨è¿›è¡Œæ’åºï¼Œä¸¤ä¸ªéƒ½å¯ä»¥ã€‚åˆ©ç”¨ <code>ps -aux</code> æˆ–è€… <code>top</code> å‘½ä»¤ä¹Ÿå¯ä»¥æŸ¥çœ‹åˆ°å…·ä½“çš„å ç”¨å¤šå°‘ G å†…å­˜ï¼Œä¸¾ä¸ªä¾‹å­ï¼Œè¿™æ˜¯ <code>top</code> å‘½ä»¤çš„ç•Œé¢ï¼Œ<code>%MEM</code> å°±æ˜¯å†…å­˜çš„å ç”¨é‡ï¼Œå¯¹ <code>250508</code> è¿™ä¸ªè¿›ç¨‹æ¥åˆ†æä¸€ä¸‹ï¼Œå®ƒçš„å ç”¨ç‡æ˜¯ 2.1%ï¼Œæˆ‘ä»¬æœåŠ¡å™¨å†…å­˜å¤§æ¦‚æ˜¯ 504Gï¼Œå¾—å‡ºè¿™ä¸ªè¿›ç¨‹å ç”¨äº†å¤§çº¦ 10.6G çš„å†…å­˜</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line">250508 wubizhu   20   0 92.497g 0.010t  88056 S   0.0  2.1   0:32.10 python</span><br><span class="line">250593 wubizhu   20   0 92.498g 0.010t  87900 S   0.0  2.1   0:29.64 python</span><br><span class="line">225884 xjheng    20   0 49.620g 0.010t 6.367g S   4.8  2.0  57:06.42 python</span><br><span class="line"> 83813 xjheng    20   0 52.932g 6.760g 3.045g R 101.9  1.3 205:04.84 python</span><br><span class="line">252689 zxdong    20   0 14.935g 4.106g  83604 D   2.6  0.8  22:00.05 python</span><br><span class="line">252681 zxdong    20   0 14.935g 4.106g  83608 D  30.4  0.8  22:18.04 python</span><br><span class="line"> 13646 xjheng    20   0 17.928g 4.022g 1.127g D  22.7  0.8   1:29.93 python</span><br></pre></td></tr></tbody></table></figure>
<p>éªŒè¯ä¸€ä¸‹è¯´æ³•ï¼Œé€šè¿‡ <code>ps -aux | grep 250508</code> å¾—åˆ°ä¸‹é¢ç»“æœï¼Œç¬¬å…­åˆ— <code>10944660</code> å°±æ˜¯å ç”¨çš„ç‰©ç†å†…å­˜ï¼Œå•ä½æ˜¯ kï¼Œæ‰€ä»¥è¿™é‡Œç»Ÿè®¡å‡ºçš„æ˜¯ 10.9Gï¼Œè·Ÿæˆ‘ä»¬ç®—å‡ºæ¥çš„å·®ä¸å¤š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">wubizhu  250508  1.8  2.0 96990572 10944660 pts/131 Sl+ 11:50   0:42 python xx.py</span><br></pre></td></tr></tbody></table></figure>
<p>é€šè¿‡ <code>cat /proc/250508/status</code> ä¹Ÿèƒ½å¾—åˆ°è¿›ç¨‹çš„å†…å­˜å ç”¨é‡ï¼Œ<code>VmRSS</code> å°±æ˜¯ç‰©ç†å†…å­˜ä½¿ç”¨é‡ï¼Œå•ä½ä¹Ÿæ˜¯ k</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Name:   python</span><br><span class="line">Umask:  0002</span><br><span class="line">State:  S (sleeping)</span><br><span class="line">Tgid:   250508</span><br><span class="line">Ngid:   250508</span><br><span class="line">Pid:    250508</span><br><span class="line">PPid:   38642</span><br><span class="line">TracerPid:      0</span><br><span class="line">Uid:    1074    1074    1074    1074</span><br><span class="line">Gid:    1074    1074    1074    1074</span><br><span class="line">FDSize: 128</span><br><span class="line">Groups: 1074</span><br><span class="line">NStgid: 250508</span><br><span class="line">NSpid:  250508</span><br><span class="line">NSpgid: 38642</span><br><span class="line">NSsid:  9950</span><br><span class="line">VmPeak: 97005580 kB</span><br><span class="line">VmSize: 96990572 kB</span><br><span class="line">VmLck:         0 kB</span><br><span class="line">VmPin:         0 kB</span><br><span class="line">VmHWM:  10961980 kB</span><br><span class="line">VmRSS:  10944656 kB</span><br></pre></td></tr></tbody></table></figure>
<h2 id="Linuxä¸­æ–­è¿è¡Œä»¥åŠæ¢å¤"><a href="#Linuxä¸­æ–­è¿è¡Œä»¥åŠæ¢å¤" class="headerlink" title="Linuxä¸­æ–­è¿è¡Œä»¥åŠæ¢å¤"></a>Linuxä¸­æ–­è¿è¡Œä»¥åŠæ¢å¤</h2><p>å¦‚æœæ‚¨ä¸å°å¿ƒåœæ­¢äº†ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„æ–‡ä»¶ï¼Œä¸€èˆ¬ç»ˆç«¯å¯ä»¥ä½¿ç”¨<code>ctrl + Z</code>ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•æ¥ç»§ç»­å®ƒçš„è¿è¡Œï¼š</p>
<p><strong>ä½¿ç”¨ fg å‘½ä»¤å°†è¿›ç¨‹ç§»åŠ¨åˆ°å‰å°</strong></p>
<p>å¦‚æœæ‚¨åœ¨ç»ˆç«¯ä¸­è¿è¡Œçš„æ˜¯ä¸€ä¸ªæ­£åœ¨è¿è¡Œçš„ç¨‹åºï¼Œå¯ä»¥ä½¿ç”¨ <code>fg</code> å‘½ä»¤å°†å…¶ç§»åŠ¨åˆ°å‰å°ç»§ç»­è¿è¡Œã€‚é¦–å…ˆï¼Œä½¿ç”¨ <code>jobs</code> å‘½ä»¤æŸ¥çœ‹å½“å‰ç»ˆç«¯ä¼šè¯ä¸­çš„ä½œä¸šåˆ—è¡¨ï¼Œæ‰¾åˆ°æ‚¨æƒ³è¦æ¢å¤çš„ä½œä¸šçš„ç¼–å·ã€‚ç„¶åï¼Œä½¿ç”¨ <code>fg</code> å‘½ä»¤å¹¶å¸¦ä¸Šä½œä¸šç¼–å·ï¼Œå°†è¿›ç¨‹ç§»åŠ¨åˆ°å‰å°ç»§ç»­è¿è¡Œã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³è¦æ¢å¤ä½œä¸šç¼–å·ä¸º 1 çš„è¿›ç¨‹ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">jobs</span></span><br><span class="line"><span class="built_in">fg</span> %1</span><br></pre></td></tr></tbody></table></figure>
<p><strong>ä½¿ç”¨ nohup å‘½ä»¤å°†è¿›ç¨‹æ”¾å…¥åå°ç»§ç»­è¿è¡Œ</strong></p>
<p>å¦‚æœæ‚¨å¸Œæœ›è¿›ç¨‹åœ¨åå°ç»§ç»­è¿è¡Œï¼Œå¯ä»¥ä½¿ç”¨ <code>nohup</code> å‘½ä»¤ã€‚è¯¥å‘½ä»¤å¯ä»¥ä½¿è¿›ç¨‹åœ¨æ–­å¼€ç»ˆç«¯è¿æ¥åç»§ç»­è¿è¡Œï¼Œå¹¶å°†è¾“å‡ºå†™å…¥æŒ‡å®šçš„æ–‡ä»¶ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³è¦åœ¨åå°è¿è¡Œåä¸º <code>myprogram</code> çš„ç¨‹åºï¼Œå¹¶å°†è¾“å‡ºå†™å…¥ <code>myprogram.log</code> æ–‡ä»¶ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">nohup</span> myprogram &gt; myprogram.log &amp;</span><br></pre></td></tr></tbody></table></figure>
<p>å…¶ä¸­ï¼Œ<code>&amp;</code> ç¬¦å·è¡¨ç¤ºå°†è¿›ç¨‹æ”¾å…¥åå°è¿è¡Œã€‚</p>
<p>è¯·æ³¨æ„ï¼Œè¿™äº›æ–¹æ³•ä»…é€‚ç”¨äºåœ¨ç»ˆç«¯ä¸­è¿è¡Œçš„è¿›ç¨‹ã€‚å¦‚æœæ‚¨ä½¿ç”¨ GUI ç•Œé¢å¯åŠ¨çš„ç¨‹åºï¼Œå¯ä»¥å°è¯•é‡æ–°å¯åŠ¨è¯¥ç¨‹åºæˆ–è€…ä½¿ç”¨ç³»ç»Ÿç›‘è§†å™¨ç­‰å·¥å…·æ¥æŸ¥çœ‹å’Œç»ˆæ­¢è¿›ç¨‹ã€‚</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>LinuxæœåŠ¡å™¨è”ç½‘æ”»ç•¥</title>
    <url>/2024/01/01/Linux/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%81%94%E7%BD%91%E6%94%BB%E7%95%A5/</url>
    <content><![CDATA[<h1 id="èƒŒæ™¯"><a href="#èƒŒæ™¯" class="headerlink" title="èƒŒæ™¯"></a>èƒŒæ™¯</h1><p>å­¦æ ¡çš„ä¸ªäººè´¦å·åªèƒ½åœ¨ä¸€å°è®¾å¤‡ä¸Šè¿›è¡Œè®¤è¯è”ç½‘ï¼Œä½†æ˜¯æˆ‘ä»¬ä½¿ç”¨çš„ GPU æœåŠ¡å™¨ç»å¸¸éœ€è¦è®¿é—®äº’è”ç½‘ï¼Œåœ¨æœåŠ¡å™¨ä¸Šè®¤è¯ä¹‹åæˆ‘ä»¬è‡ªå·±çš„ç”µè„‘å°±ä¼šæ‰çº¿ï¼Œæ‰€ä»¥å¯ä»¥é€šè¿‡ä»£ç†çš„æ–¹å¼è®©æœåŠ¡å™¨é€šè¿‡æˆ‘ä»¬è‡ªå·±çš„è®¾å¤‡è¿›è¡Œè”ç½‘ï¼Œè§£å†³è¿™ä¸ªé—®é¢˜ã€‚<br><strong>ä»¥ä¸‹æ‰€æœ‰çš„æ–¹æ³•ï¼Œå®é™…ä¸Šè®©æœåŠ¡å™¨å¯é€šè¿‡ä»£ç†æœ¬åœ°ç½‘ç»œä¸Šç½‘ï¼ˆè§£å†³æœåŠ¡å™¨è¿ä¸ä¸Šç½‘æ—¶ä½¿ç”¨ï¼‰</strong></p>
<blockquote>
<p>æ­¤æ–‡æ¡£æ˜¯å€Ÿé‰´å®éªŒå®¤çš„å¸ˆå…„çš„æ–‡æ¡£å®Œå–„è€Œæ¥ï¼Œåœ¨è¿™é‡Œæ„Ÿè°¢æœ¨å­æï¼ï¼ï¼</p>
</blockquote>
<h1 id="è®¾ç½®httpä»£ç†"><a href="#è®¾ç½®httpä»£ç†" class="headerlink" title="è®¾ç½®httpä»£ç†"></a>è®¾ç½®httpä»£ç†</h1><p>é¦–å…ˆåœ¨è‡ªå·±æœ¬æœºç”µè„‘ä¸Šï¼ŒæŸ¥çœ‹è‡ªå·±çš„ipåœ°å€ï¼Œåœ¨å½“å‰ç»ˆç«¯è¿›è¡Œè¾“å…¥<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> http_proxy=http://ip:7890</span><br><span class="line"><span class="built_in">export</span> https_proxy=https://ip:7890</span><br><span class="line">curl cip.cc <span class="comment"># æœ‰è¾“å‡ºè¯´æ˜æˆåŠŸä»£ç†åˆ°äº†</span></span><br></pre></td></tr></tbody></table></figure><br>è‹¥å¸Œæœ›ä¸ç”¨æ¯æ¬¡ç»ˆç«¯éƒ½éœ€è¦è®¾ç½®ï¼Œä¹Ÿå¯ä»¥æŠŠexportçš„éƒ¨åˆ†å†™å…¥~/.bashrcä¸­ï¼Œè®¾ç½®åè¿›è¡Œsource ~/.basrcå³å¯<p></p>
<blockquote>
<p>è¿™é‡Œé¢çš„7890ç«¯å£æ˜¯é€šè¿‡clashè¿›è¡Œè½¬å‘çš„ï¼Œå¯ä»¥è¿›è¡Œä¸‹è½½clash</p>
<p>é™¤æ­¤ä¹‹å¤–ï¼Œä¹Ÿéœ€è¦è®¾ç½®ä»£ç†è½¯ä»¶æ‰èƒ½è®©æœåŠ¡å™¨è®¿é—®åˆ°ç½‘ç»œï¼Œåœ¨ clash ä¸­æ‰“å¼€ Allow LANï¼Œ v2ray ä¸­æ‰“å¼€ å…è®¸å±€åŸŸç½‘çš„è¿æ¥ å°±è¡Œäº†ã€‚è¿™æ ·æˆ‘ä»¬çš„è®¾å¤‡å¯ä»¥è®¿é—®çš„ä¸œè¥¿ï¼ŒæœåŠ¡å™¨éƒ½å¯ä»¥è®¿é—®åˆ°ã€‚</p>
<p>ä»¥ä¸‹æ˜¯ä¸¤ç§è½¯ä»¶è®¾ç½®ä¸¾ä¾‹ï¼ˆæ³¨æ„ï¼šæœåŠ¡å™¨ç«¯ä»£ç†ä¸Šç½‘è¡Œä¸ºå’Œä»£ç†è½¯ä»¶è®¾ç½®ä¸€è‡´ï¼‰ã€‚</p>
<p>V2rayè®¾ç½®ä¸­å¼€å¯å…è®¸å±€åŸŸç½‘è®¿é—®ï¼ˆéœ€è¦æ³¨æ„æœ¬åœ°ç«¯å£å’Œå±€åŸŸç½‘ç«¯å£ä¸ä¸€æ ·ï¼‰</p>
<p><img src="https://pica.zhimg.com/v2-7c222d179d5454cef5d6a55f9a4f26b6.jpg" alt=""></p>
<p>clashå¼€å¯å±€åŸŸç½‘<br><img src="https://picx.zhimg.com/v2-d8dea34b8e6980fc40d3fb790733d70b.png" alt=""></p>
</blockquote>
<p>ä¸Šé¢è¿™ç§æ–¹æ³•æœ‰æ—¶å€™æ¯æ¬¡éƒ½éœ€è¦æ‰“ä¸¤è¡Œå‘½ä»¤ï¼Œè¿˜æœ‰ä¸€ç§æ¯”è¾ƒç®€å•çš„æ–¹æ³•ï¼Œåœ¨ .bashrc ä¸­è®¾ç½®alias</p>
<blockquote>
<p>Linux alias å‘½ä»¤ç”¨äºè®¾ç½®æŒ‡ä»¤çš„åˆ«åï¼Œç”¨æˆ·å¯åˆ©ç”¨ aliasï¼Œè‡ªå®šæŒ‡ä»¤çš„åˆ«åã€‚<br>å®ƒå¯ä»¥ä½¿æ‚¨ä»¥ä¸€ç§æ›´ç®€å•å’Œæ˜“äºè®°å¿†çš„æ–¹å¼æ‰§è¡Œå‘½ä»¤ï¼Œè€Œä¸å¿…æ¯æ¬¡éƒ½é”®å…¥å®Œæ•´çš„å‘½ä»¤ã€‚<br>è‹¥ä»…è¾“å…¥ aliasï¼Œåˆ™å¯åˆ—å‡ºç›®å‰æ‰€æœ‰çš„åˆ«åè®¾ç½®ã€‚<br>alias çš„æ•ˆæœä»…åœ¨è¯¥æ¬¡ç™»å…¥çš„æ“ä½œæœ‰æ•ˆï¼Œè‹¥æƒ³è¦æ¯æ¬¡ç™»å…¥éƒ½ç”Ÿæ•ˆï¼Œå¯åœ¨ <strong>.profile</strong> æˆ– <strong>.cshrc</strong> ä¸­è®¾å®šæŒ‡ä»¤çš„åˆ«åã€‚</p>
</blockquote>
<figure class="highlight jsx"><table><tbody><tr><td class="code"><pre><span class="line">vim ~/.<span class="property">bashrc</span></span><br><span class="line"># åœ¨æœ€åä¸€è¡ŒåŠ å…¥</span><br><span class="line">alias setproxy=<span class="string">'export http_proxy=http://ip:7890; export https_proxy=http://ip:7890'</span></span><br><span class="line"># å¯åŠ¨</span><br><span class="line">source ~/.<span class="property">bashrc</span></span><br><span class="line"># è¿è¡Œä¸Šç½‘å‘½ä»¤</span><br><span class="line">setproxy</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™æ ·ä»¥åï¼Œæ¯æ¬¡åªéœ€è¦è¾“å…¥ setproxy å°±å¯ä»¥æ–¹ä¾¿å¿«æ·çš„è¿å…¥è‡ªå·±çš„ç½‘ç»œäº†ã€‚</p>
<h1 id="å€ŸåŠ©proxychainså·¥å…·"><a href="#å€ŸåŠ©proxychainså·¥å…·" class="headerlink" title="å€ŸåŠ©proxychainså·¥å…·"></a>å€ŸåŠ©proxychainså·¥å…·</h1><p>æ ¸å¿ƒï¼šæœåŠ¡å™¨ç«¯å€ŸåŠ©proxychains-ng å°†åº”ç”¨â€œhttp/https/socks4/socks5â€è¯·æ±‚ä»£ç†åˆ°æœ¬åœ°ã€‚</p>
<h2 id="å®‰è£…è½¯ä»¶"><a href="#å®‰è£…è½¯ä»¶" class="headerlink" title="å®‰è£…è½¯ä»¶"></a>å®‰è£…è½¯ä»¶</h2><ol>
<li><p>ä¸»è¦æ˜¯é€šè¿‡ proxychains-ng æ¥è½¬å‘ç½‘ç»œè¯·æ±‚ï¼Œå¯ä»¥é€šè¿‡ git ä¸‹è½½ä¹Ÿå¯ä»¥ç›´æ¥ä¸‹è½½å‹ç¼©åŒ…ã€‚ï¼ˆå¯åœ¨ä»“åº“ç›´æ¥ä¸‹è½½zip ä¸Šä¼ æœåŠ¡å™¨è§£å‹ï¼‰</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/rofl0r/proxychains-ng</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>ç„¶åè¿›å…¥è½¯ä»¶ç›®å½•ï¼Œç”¨ pwd å‘½ä»¤çœ‹ä¸€ä¸‹å½“å‰çš„ç»å¯¹è·¯å¾„ï¼Œè¿™ä¸ªåœ¨ä¸‹ä¸€æ­¥ä¸­è¦ç”¨åˆ°</p>
</li>
</ol>
<p><img src="https://picx.zhimg.com/80/v2-68aa3d2a2b0e5ce78f7643598f82b814.png" alt=""></p>
<ol>
<li>è¿›å…¥ç›®å½•æ‰§è¡Œå‘½ä»¤ï¼Œè¿™é‡Œçš„ pwd å°±æ˜¯ä¸Šä¸€æ­¥è¾“å‡ºçš„<strong>ç»å¯¹è·¯å¾„</strong>ï¼Œè¦è¾“<strong>ç»å¯¹è·¯å¾„</strong>ï¼Œä¸ç„¶åé¢ç¼–è¯‘çš„æ—¶å€™ä¼šå‡ºé”™</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># ./configure --prefix=pwd --sysconfdir=/raid/xxx/proxychains</span></span><br><span class="line">./configure --prefix=<span class="built_in">pwd</span> --sysconfdir=<span class="built_in">pwd</span></span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>ç¼–è¯‘äºŒè¿›åˆ¶æ–‡ä»¶</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">make</span><br><span class="line">make install</span><br><span class="line">make install-config</span><br></pre></td></tr></tbody></table></figure>
<h2 id="é…ç½®"><a href="#é…ç½®" class="headerlink" title="é…ç½®"></a>é…ç½®</h2><p>è¿›å…¥å®‰è£…ç›®å½•æ‰¾åˆ°é…ç½®æ–‡ä»¶ proxychains.confï¼Œè¿›è¡Œç¼–è¾‘<br>åœ¨åº•éƒ¨æ·»åŠ éœ€è¦ä»£ç†çš„è®¾å¤‡çš„ ip å’Œç«¯å£ï¼Œæˆ‘ä½¿ç”¨çš„ clashï¼Œæ˜¯ socks ä»£ç†ï¼Œåœ¨å…¶åº•éƒ¨æ·»åŠ æœ¬åœ°ä»£ç†è½¯ä»¶çš„æœ¬æœºIP å’Œ ä»£ç†è½¯ä»¶çš„å±€åŸŸç½‘ç«¯å£å·ã€‚<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">vim proxychains/proxychains.conf</span><br></pre></td></tr></tbody></table></figure><br><img src="https://picx.zhimg.com/80/v2-71d052ed41187a762ba6f9619d0b3b8a.png" alt=""><p></p>
<p>æˆ‘çš„é…ç½®æ˜¯</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">socks5 172.31.xx.xx 7890</span><br></pre></td></tr></tbody></table></figure>
<h2 id="è½¯ä»¶è®¾ç½®ä»¥åŠè·¯å¾„"><a href="#è½¯ä»¶è®¾ç½®ä»¥åŠè·¯å¾„" class="headerlink" title="è½¯ä»¶è®¾ç½®ä»¥åŠè·¯å¾„"></a>è½¯ä»¶è®¾ç½®ä»¥åŠè·¯å¾„</h2><p>é‚£ä¹ˆæˆ‘ä»¬è‡ªå·±çš„è®¾å¤‡ä¸Šä¹Ÿéœ€è¦æ‰“å¼€ä»£ç†è½¯ä»¶æ‰èƒ½è®©æœåŠ¡å™¨è®¿é—®åˆ°ç½‘ç»œï¼Œåœ¨ clash ä¸­æ‰“å¼€ Allow LANï¼Œ v2ray ä¸­æ‰“å¼€ å…è®¸å±€åŸŸç½‘çš„è¿æ¥ å°±è¡Œäº†ã€‚è¿™æ ·æˆ‘ä»¬çš„è®¾å¤‡å¯ä»¥è®¿é—®çš„ä¸œè¥¿ï¼ŒæœåŠ¡å™¨éƒ½å¯ä»¥è®¿é—®åˆ°ã€‚<br>ä»¥ä¸‹æ˜¯ä¸¤ç§è½¯ä»¶è®¾ç½®ä¸¾ä¾‹ï¼ˆæ³¨æ„ï¼šæœåŠ¡å™¨ç«¯ä»£ç†ä¸Šç½‘è¡Œä¸ºå’Œä»£ç†è½¯ä»¶è®¾ç½®ä¸€è‡´ï¼‰ã€‚</p>
<p>V2rayè®¾ç½®ä¸­å¼€å¯å…è®¸å±€åŸŸç½‘è®¿é—®ï¼ˆéœ€è¦æ³¨æ„æœ¬åœ°ç«¯å£å’Œå±€åŸŸç½‘ç«¯å£ä¸ä¸€æ ·ï¼‰</p>
<p><img src="https://pica.zhimg.com/v2-7c222d179d5454cef5d6a55f9a4f26b6.jpg" alt=""></p>
<p>clashå¼€å¯å±€åŸŸç½‘</p>
<p><img src="https://picx.zhimg.com/v2-d8dea34b8e6980fc40d3fb790733d70b.png" alt=""></p>
<p>æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦åœ¨ bash é…ç½®æ–‡ä»¶ä¸­åŠ å…¥äºŒè¿›åˆ¶æ–‡ä»¶çš„è·¯å¾„ï¼Œä¸ç„¶è¿è¡Œæ—¶ä¼šæ‰¾ä¸åˆ°æ–‡ä»¶ï¼ˆå¦‚æœæ˜¯é€šè¿‡ç®¡ç†å‘˜è£…çš„ï¼Œåˆ™ä¸ç”¨è¿™ä¸€æ­¥),ç¯å¢ƒå˜é‡ä¸­æ·»åŠ åˆšåˆšçš„å®‰è£…è·¯å¾„</p>
<figure class="highlight jsx"><table><tbody><tr><td class="code"><pre><span class="line">vim ~/.<span class="property">bashrc</span></span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://picx.zhimg.com/80/v2-ea6a367e8a4642a7b49a498821427b79.png" alt=""></p>
<figure class="highlight jsx"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> <span class="variable constant_">PATH</span>=<span class="regexp">/data/</span>xxx/proxychains/<span class="attr">bin</span>:$PATH</span><br><span class="line"><span class="keyword">export</span> <span class="variable constant_">PROXYCHAINS_CONF_FILE</span>=<span class="regexp">/data/</span>xxx/proxychains/proxychains.<span class="property">conf</span></span><br></pre></td></tr></tbody></table></figure>
<p>é‡æ–°å¼€å¯ç»ˆç«¯åå¯æ­£å¸¸ä½¿ç”¨ æˆ–è€…è¿›è¡Œ source ~/.bashrc</p>
<h2 id="ä½¿ç”¨"><a href="#ä½¿ç”¨" class="headerlink" title="ä½¿ç”¨"></a>ä½¿ç”¨</h2><p>åœ¨æƒ³è¦ä»£ç†ç½‘ç»œçš„æ—¶å€™å°±åœ¨å‘½ä»¤å‰åŠ ä¸Š proxychains4 å°±å¯ä»¥äº†ï¼Œä¾‹å¦‚ï¼š<br></p><figure class="highlight jsx"><table><tbody><tr><td class="code"><pre><span class="line">proxychains4 curl cip.<span class="property">cc</span></span><br><span class="line">proxychains4 python main.<span class="property">py</span></span><br></pre></td></tr></tbody></table></figure><br>è¿™æ ·åœ¨linuxæœåŠ¡å™¨ä¸Šç”¨æœ¬æœºç”µè„‘çš„ä»£ç†ç½‘ç»œï¼Œå¯ä»¥å®Œæˆwgetå’Œgit cloneçš„ä»£ç ç­‰ï¼Œè¿˜æ˜¯å¾ˆæ–¹ä¾¿å’Œèˆ’æœçš„<p></p>
<h2 id="troubleshoot"><a href="#troubleshoot" class="headerlink" title="troubleshoot"></a>troubleshoot</h2><p>åœ¨ä½¿ç”¨çš„æ—¶å€™æŠ¥é”™æ‰¾ä¸åˆ° proxychains.conf çš„ï¼ŒåŸºæœ¬ä¸Šéƒ½æ˜¯ç¼–è¯‘çš„æ—¶å€™æ²¡æœ‰å¡«ç»å¯¹è·¯å¾„è€Œæ˜¯å¡«äº†ç›¸å¯¹è·¯å¾„ï¼Œç”¨ make uninstall ä»¥åŠ make clean æŠŠåˆšåˆšç”Ÿæˆçš„ä¸œè¥¿ç»™åˆ äº†ï¼Œç„¶åé‡æ–°è¿è¡Œä¸Šè¿°çš„å®‰è£…æ­¥éª¤ï¼Œä¸€å®šè¦å¡«ç»å¯¹è·¯å¾„ã€‚</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linuxçš„ shellæ— æ³•è‡ªåŠ¨è¡¥å…¨å‘½ä»¤</title>
    <url>/2024/01/01/Linux/Linux%E7%9A%84%20shell%E6%97%A0%E6%B3%95%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<p>åœ¨<a href="https://so.csdn.net/so/search?q=ubuntu&amp;spm=1001.2101.3001.7020">ubuntu</a>ä¸Šä½¿ç”¨useraddæ–°å»ºäº†ä¸€ä¸ªç”¨æˆ·ï¼Œå‘ç°ç”¨æ–°å»ºçš„ç”¨æˆ·ç™»é™†æ— æ³•ä½¿ç”¨tabé”®è¡¥å…¨ï¼Œè¿™ä¸ªé—®é¢˜æ˜¯å¦è®©äººæ¼ç«ï¼Œæ‰€ä»¥æ¥è§£å†³ä¸€ä¸‹ã€‚</p>
<h2 id="ä¸€ã€é—®é¢˜"><a href="#ä¸€ã€é—®é¢˜" class="headerlink" title="ä¸€ã€é—®é¢˜"></a>ä¸€ã€é—®é¢˜</h2><p>è¿™æ˜¯å› ä¸ºshellçš„è§£é‡Šå™¨ä¸æ˜¯bashï¼Œéœ€æŠŠshellçš„è§£é‡Šå™¨æ›´æ”¹ä¸ºbash</p>
<h2 id="äºŒã€ä¸¤ç§è§£å†³æ–¹æ³•"><a href="#äºŒã€ä¸¤ç§è§£å†³æ–¹æ³•" class="headerlink" title="äºŒã€ä¸¤ç§è§£å†³æ–¹æ³•"></a>äºŒã€ä¸¤ç§è§£å†³æ–¹æ³•</h2><h3 id="1-æ–¹å¼ä¸€"><a href="#1-æ–¹å¼ä¸€" class="headerlink" title="1)æ–¹å¼ä¸€"></a>1)æ–¹å¼ä¸€</h3><p><img src="https://picx.zhimg.com/v2-3abd850433ca2709a7ca8e90cb50b340.png" alt=""></p>
<p>æ–°å»ºä¸€ç”¨æˆ·lqdingï¼Œåˆ‡æ¢åˆ°è¯¥ç”¨æˆ·ä¸‹</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">root@lqding:~<span class="comment"># su - lqding</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$USER</span></span><br><span class="line">lqding</span><br></pre></td></tr></tbody></table></figure>
<p>æç¤ºç¬¦ä»…ä»…æ˜¯ä¸€ä¸ª$ ï¼Œå¾ˆå¥‡æ€ªã€‚è¾“å…¥å‘½ä»¤ï¼Œç”¨TABé”®ä¹Ÿæ— æ³•è¡¥å…¨å‘½ä»¤ã€‚å¹¶ä¸”æ²¡æœ‰å‘½ä»¤å†å²åŠŸèƒ½ã€‚</p>
<p>ä½¿ç”¨rootç”¨æˆ·çœ‹passwdæ–‡ä»¶</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">root@lqding:~<span class="comment"># grep lqding /etc/passwd</span></span><br><span class="line">lqding:x:1000:1000::/home/lqding:/bin/sh</span><br><span class="line">root@lqding:~<span class="comment">#</span></span><br></pre></td></tr></tbody></table></figure>
<p>åŸæ¥lqdingç”¨æˆ·é»˜è®¤çš„shellæ˜¯/bin/sh å°†å…¶æ”¹ä¸º/bin/bashå</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">root@lqding:~<span class="comment"># vi /etc/passwd</span></span><br><span class="line">root@lqding:~<span class="comment"># grep lqding /etc/passwd</span></span><br><span class="line">lqding:x:1000:1000::/home/lqding:/bin/bash</span><br><span class="line">root@lqding:~<span class="comment"># su - lqding</span></span><br><span class="line">lqding@lqding:~$</span><br></pre></td></tr></tbody></table></figure>
<p>ç» æµ‹è¯• ï¼Œä¸€åˆ‡åŠŸèƒ½æ­£å¸¸ã€‚</p>
<h3 id="2-æ–¹å¼äºŒï¼š"><a href="#2-æ–¹å¼äºŒï¼š" class="headerlink" title="2)æ–¹å¼äºŒï¼š"></a>2)æ–¹å¼äºŒï¼š</h3><p><img src="https://pica.zhimg.com/v2-94d10245114f3dfa18bc77a058301ee1.png" alt=""></p>
<p>ä¸€åŠ³æ°¸é€¸å‹çš„ã€‚</p>
<p>è¿™æ ·é—®é¢˜å°±è§£å†³äº†</p>
<h2 id="ä¸‰ã€è¡¥å……çŸ¥è¯†ç‚¹"><a href="#ä¸‰ã€è¡¥å……çŸ¥è¯†ç‚¹" class="headerlink" title="ä¸‰ã€è¡¥å……çŸ¥è¯†ç‚¹"></a>ä¸‰ã€è¡¥å……çŸ¥è¯†ç‚¹</h2><h3 id="1-ä½œç”¨"><a href="#1-ä½œç”¨" class="headerlink" title="1. ä½œç”¨"></a>1. ä½œç”¨</h3><p><code>useradd</code> æˆ– <code>adduser</code> å‘½ä»¤ç”¨äºåˆ›å»ºç”¨æˆ·å¸å·å’Œè®¾ç½®ç”¨æˆ·çš„åˆå§‹ç›®å½•ï¼Œé€šå¸¸éœ€è¦è¶…çº§ç”¨æˆ·æƒé™ã€‚</p>
<h3 id="2-æ ¼å¼"><a href="#2-æ ¼å¼" class="headerlink" title="2. æ ¼å¼"></a>2. æ ¼å¼</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">useradd [-d home] [-s shell] [-c comment] [-m [-k template]] [-f inactive] [-e expire ] [-p passwd] [-r] name</span><br></pre></td></tr></tbody></table></figure>
<h3 id="3-ä¸»è¦å‚æ•°"><a href="#3-ä¸»è¦å‚æ•°" class="headerlink" title="3. ä¸»è¦å‚æ•°"></a>3. ä¸»è¦å‚æ•°</h3><ul>
<li><code>-c</code>ï¼šæ·»åŠ å¤‡æ³¨æ–‡å­—ï¼Œå¤‡æ³¨æ–‡å­—ä¿å­˜åœ¨ passwd çš„å¤‡æ³¨æ ä¸­ã€‚</li>
<li><code>-d</code>ï¼šæŒ‡å®šç”¨æˆ·ç™»å…¥æ—¶çš„ä¸»ç›®å½•ï¼Œæ›¿æ¢ç³»ç»Ÿé»˜è®¤å€¼ <code>/home/&lt;ç”¨æˆ·å&gt;</code>ã€‚</li>
<li><code>-D</code>ï¼šå˜æ›´é¢„è®¾å€¼ã€‚</li>
<li><code>-e</code>ï¼šæŒ‡å®šè´¦å·çš„å¤±æ•ˆæ—¥æœŸï¼Œæ—¥æœŸæ ¼å¼ä¸º MM/DD/YYï¼Œä¾‹å¦‚ 06/30/12ã€‚ç¼ºçœè¡¨ç¤ºæ°¸ä¹…æœ‰æ•ˆã€‚</li>
<li><code>-f</code>ï¼šæŒ‡å®šåœ¨å¯†ç è¿‡æœŸåå¤šå°‘å¤©å³å…³é—­è¯¥è´¦å·ã€‚å¦‚æœä¸º 0 è´¦å·ç«‹å³è¢«åœç”¨ï¼›å¦‚æœä¸º -1 åˆ™è´¦å·ä¸€ç›´å¯ç”¨ã€‚é»˜è®¤å€¼ä¸º -1ã€‚</li>
<li><code>-g</code>ï¼šæŒ‡å®šç”¨æˆ·æ‰€å±çš„ç¾¤ç»„ã€‚å€¼å¯ä»¥æ˜¯ç»„åä¹Ÿå¯ä»¥æ˜¯ GIDã€‚ç”¨æˆ·ç»„å¿…é¡»å·²ç»å­˜åœ¨ï¼Œé»˜è®¤å€¼ä¸º 100ï¼Œå³ usersã€‚</li>
<li><code>-G</code>ï¼šæŒ‡å®šç”¨æˆ·æ‰€å±çš„é™„åŠ ç¾¤ç»„ã€‚</li>
<li><code>-m</code>ï¼šè‡ªåŠ¨å»ºç«‹ç”¨æˆ·çš„ç™»å…¥ç›®å½•ã€‚</li>
<li><code>-M</code>ï¼šä¸è¦è‡ªåŠ¨å»ºç«‹ç”¨æˆ·çš„ç™»å…¥ç›®å½•ã€‚</li>
<li><code>-n</code>ï¼šå–æ¶ˆå»ºç«‹ä»¥ç”¨æˆ·åç§°ä¸ºåçš„ç¾¤ç»„ã€‚</li>
<li><code>-r</code>ï¼šå»ºç«‹ç³»ç»Ÿè´¦å·ã€‚</li>
<li><code>-s</code>ï¼šæŒ‡å®šç”¨æˆ·ç™»å…¥åæ‰€ä½¿ç”¨çš„ shellã€‚é»˜è®¤å€¼ä¸º <code>/bin/bash</code>ã€‚</li>
<li><code>-u</code>ï¼šæŒ‡å®šç”¨æˆ·IDå·ã€‚è¯¥å€¼åœ¨ç³»ç»Ÿä¸­å¿…é¡»æ˜¯å”¯ä¸€çš„ã€‚0~499é»˜è®¤æ˜¯ä¿ç•™ç»™ç³»ç»Ÿç”¨æˆ·è´¦å·ä½¿ç”¨çš„ï¼Œæ‰€ä»¥è¯¥å€¼å¿…é¡»å¤§äº 499ã€‚</li>
</ul>
<h3 id="4-è¯´æ˜"><a href="#4-è¯´æ˜" class="headerlink" title="4. è¯´æ˜"></a>4. è¯´æ˜</h3><p><code>useradd</code> å¯ç”¨äºåˆ›å»ºç”¨æˆ·è´¦å·ï¼Œå®ƒå’Œ <code>adduser</code> å‘½ä»¤æ˜¯ç›¸åŒçš„ã€‚è´¦å·åˆ›å»ºå®Œæˆåï¼Œå¯ä»¥ä½¿ç”¨ <code>passwd</code> è®¾ç½®è´¦å·çš„å¯†ç ã€‚é€šè¿‡ <code>useradd</code> å‘½ä»¤åˆ›å»ºçš„è´¦å·å®é™…ä¸Šæ˜¯ä¿å­˜åœ¨ <code>/etc/passwd</code> æ–‡æœ¬æ–‡ä»¶ä¸­ã€‚</p>
<h3 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h3><p><a href="https://blog.csdn.net/bilifo/article/details/50442737">https://blog.csdn.net/bilifo/article/details/50442737</a></p>
<p><a href="https://blog.csdn.net/weixin_37569048/article/details/101675360">https://blog.csdn.net/weixin_37569048/article/details/101675360</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>å¦‚ä½•åœ¨LinuxæœåŠ¡å™¨ä¸Šå®‰è£…Anacondaï¼ˆè¶…è¯¦ç»†ï¼‰</title>
    <url>/2024/01/01/Linux/Linux%E8%A3%85Anconda%E5%8F%8Apytorch/</url>
    <content><![CDATA[<h2 id="å®‰è£…Anaconda"><a href="#å®‰è£…Anaconda" class="headerlink" title="å®‰è£…Anaconda"></a>å®‰è£…Anaconda</h2><h3 id="1-1-ä¸‹è½½anacondaçš„å®‰è£…åŒ…"><a href="#1-1-ä¸‹è½½anacondaçš„å®‰è£…åŒ…" class="headerlink" title="1.1 ä¸‹è½½anacondaçš„å®‰è£…åŒ…"></a>1.1 ä¸‹è½½anacondaçš„å®‰è£…åŒ…</h3><p>è¿™é‡Œæˆ‘ä»¬éœ€è¦åœ¨å®˜ç½‘ä¸ŠæŸ¥æ‰¾è‡ªå·±éœ€è¦çš„ç‰ˆæœ¬ï¼Œåœ°å€é“¾æ¥åœ¨ä¸‹é¢:<br><a href="https://repo.anaconda.com/archive/">https://repo.anaconda.com/archive/</a><br>è¿™é‡Œä»¥æˆ‘è‡ªå·±å®‰è£…çš„ç‰ˆæœ¬ä¸ºä¾‹ï¼š<br><a href="https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh">https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh</a><br>è¿™æ˜¯æˆ‘é€‰æ‹©çš„ç‰ˆæœ¬ï¼Œç„¶åæˆ‘ä»¬åœ¨æ§åˆ¶å°è¾“å…¥è¿™å¥è¯:<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">wget https://repo.anaconda.com/archive/Anaconda3-2022.10-Linux-x86_64.sh</span><br></pre></td></tr></tbody></table></figure><br>å¦‚æœæ²¡æœ‰å‡ºç°é—®é¢˜å°±æ˜¯ä¸‹é¢å›¾ç¤ºï¼š<br><img src="https://pic1.zhimg.com/v2-d676de98829f1145c75f69bc9896c15e.png" alt=""><br>å¦‚æœå‡ºç°é—®é¢˜å°±æŒ‰ç…§ 1.2 æ­¥éª¤æ“ä½œã€‚<p></p>
<h3 id="1-2-è§£å†³å®‰è£…å‡ºç°çš„bug"><a href="#1-2-è§£å†³å®‰è£…å‡ºç°çš„bug" class="headerlink" title="1.2 è§£å†³å®‰è£…å‡ºç°çš„bug"></a>1.2 è§£å†³å®‰è£…å‡ºç°çš„bug</h3><p>å½“æˆ‘ä»¬è¾“å…¥1.1çš„é‚£ä¸€æ¡å‘½ä»¤æ—¶ï¼Œæœ‰äº›äººå¯èƒ½ä¼šå‡ºç°ä¸‹é¢è¿™æ ·çš„é”™è¯¯:<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">bash: wget: <span class="built_in">command</span> not found</span><br></pre></td></tr></tbody></table></figure><br>å½“ç„¶è¿™ä¹Ÿæ˜¯æˆ‘è‡ªå·±å‡ºç°çš„é”™è¯¯ï¼Œå…·ä½“è§£å†³åŠæ³•å¦‚ä¸‹: Debian/Ubuntuç³»ç»Ÿï¼Œéœ€è¦æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">apt-get install -y wget</span><br></pre></td></tr></tbody></table></figure><br>ç›¸åï¼ŒCentOSç³»ç»Ÿåˆ™éœ€è¦è¾“å…¥ä¸‹é¢æŒ‡ä»¤:<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">yum install wget -y</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="1-3-å®‰è£…anaconda"><a href="#1-3-å®‰è£…anaconda" class="headerlink" title="1.3 å®‰è£…anaconda"></a>1.3 å®‰è£…anaconda</h3><p>æ¥ä¸‹æ¥æˆ‘ä»¬éœ€è¦é¦–å…ˆèµ‹æƒå†æ‰§è¡Œå®‰è£…ç¨‹åºï¼Œä¾æ¬¡è¾“å…¥ä¸‹é¢ä¸¤å¥å‘½ä»¤:<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x Anaconda3-5.3.0-Linux-x86_64.sh</span><br><span class="line">./Anaconda3-5.3.0-Linux-x86_64.sh</span><br></pre></td></tr></tbody></table></figure><br>ç„¶åå‡ºç°ä¸‹é¢å›¾æ‰€ç¤º:<br><img src="https://picx.zhimg.com/v2-450e81bb2de67a3c137bf068af871d6b.png" alt=""><p></p>
<h3 id="1-4-ç‚¹å‡»Enterï¼ˆå›è½¦é”®ï¼‰"><a href="#1-4-ç‚¹å‡»Enterï¼ˆå›è½¦é”®ï¼‰" class="headerlink" title="1.4 ç‚¹å‡»Enterï¼ˆå›è½¦é”®ï¼‰"></a>1.4 ç‚¹å‡»Enterï¼ˆå›è½¦é”®ï¼‰</h3><p>æ­¤æ—¶æ˜¾ç¤ºAnacondaçš„ä¿¡æ¯ï¼Œå¹¶ä¸”ä¼šå‡ºç°Moreï¼Œç»§ç»­æŒ‰Enterï¼Œç›´åˆ°å¦‚ä¸‹å›¾æ‰€ç¤º:<br><img src="https://picx.zhimg.com/v2-558fb8bd56454e22cd5853e97d5d58ef.png" alt=""></p>
<h3 id="1-5-è¾“å…¥-yes"><a href="#1-5-è¾“å…¥-yes" class="headerlink" title="1.5 è¾“å…¥ yes"></a>1.5 è¾“å…¥ yes</h3><p><img src="https://picx.zhimg.com/v2-6957bbec41567ae3cf222d00cefa9bca.png" alt=""></p>
<h3 id="1-6-ç»§ç»­ç‚¹å‡»-Enter"><a href="#1-6-ç»§ç»­ç‚¹å‡»-Enter" class="headerlink" title="1.6 ç»§ç»­ç‚¹å‡» Enter"></a>1.6 ç»§ç»­ç‚¹å‡» Enter</h3><p><img src="https://pic1.zhimg.com/v2-9cacfb8685e9f1c10036d80edffe6fdd.png" alt=""></p>
<h3 id="1-7-è¾“å…¥-yesï¼Œæ·»åŠ ç¯å¢ƒå˜é‡"><a href="#1-7-è¾“å…¥-yesï¼Œæ·»åŠ ç¯å¢ƒå˜é‡" class="headerlink" title="1.7 è¾“å…¥ yesï¼Œæ·»åŠ ç¯å¢ƒå˜é‡"></a>1.7 è¾“å…¥ yesï¼Œæ·»åŠ ç¯å¢ƒå˜é‡</h3><p>è¿™é‡Œéœ€è¦æ³¨æ„ç‚¹çš„å°±æ˜¯å¦‚æœä½ ç›´æ¥è·³è¿‡è¿™éƒ¨è®¾ç½®ç¯å¢ƒå˜é‡çš„è¯ï¼š</p>
<p><img src="https://pic1.zhimg.com/v2-f0f80af2b03a73a6a81e82149405e38c.png" alt=""></p>
<p>è¿™é‡Œéœ€è¦æ³¨æ„ç‚¹çš„å°±æ˜¯å¦‚æœä½ ç›´æ¥è·³è¿‡è¿™éƒ¨è®¾ç½®ç¯å¢ƒå˜é‡çš„è¯ï¼š<br>[no ] &gt;&gt;&gt;<br>é‚£ä½ éœ€è¦è‡ªå·±åˆ°è¿™ä¸ªæ–‡ä»¶å¤¹è®¾ç½®ä½ å®‰è£…Anacondaè·¯å¾„ï¼ˆæ¯”å¦‚ä¸Šé¢æ˜¾ç¤ºæˆ‘çš„æ˜¯ï¼‰<br>/home/wangke/.bashrc<br>å•å‡»è¿›å»ï¼Œåœ¨æœ€åä¸€è¡Œæ·»åŠ ï¼š<br>export PATH=/home/wangke/anaconda3/bin:$PATH<br>éœ€è¦æŠŠä¹‹å‰çš„é‚£å¥è¯ç»™æ³¨é‡Šæ‰å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># export PATH=/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/sbin:/sbin:$PATHexport PATH=/root/anaconda3/bin:$PATH</span></span><br></pre></td></tr></tbody></table></figure>
<p>è¿™é‡Œåªæ˜¯ä¸ªç¤ºä¾‹ï¼Œå…·ä½“çš„è¿˜æ˜¯è¦çœ‹ä½ ä»¬è‡ªå·±å®‰è£…çš„è·¯å¾„ï¼Œè¿™ä¸ªå°±æ˜¯ç›¸å½“äºwindowsçš„ç¯å¢ƒå˜é‡<br>ç„¶åä¿å­˜æ›´æ”¹ï¼Œè¾“å…¥ä¸‹é¢è¿™å¥æŒ‡ä»¤ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></tbody></table></figure><p></p>
<h3 id="1-8-å®Œæˆå®‰è£…ä»¥åŠæ£€æµ‹æ˜¯å¦å®‰è£…æˆåŠŸ"><a href="#1-8-å®Œæˆå®‰è£…ä»¥åŠæ£€æµ‹æ˜¯å¦å®‰è£…æˆåŠŸ" class="headerlink" title="1.8 å®Œæˆå®‰è£…ä»¥åŠæ£€æµ‹æ˜¯å¦å®‰è£…æˆåŠŸ"></a>1.8 å®Œæˆå®‰è£…ä»¥åŠæ£€æµ‹æ˜¯å¦å®‰è£…æˆåŠŸ</h3><p>æ‰“å¼€æ–°çš„ç»ˆç«¯åï¼Œè¿›å…¥è‡ªå·±çš„æ–‡ä»¶å¤¹ç›®å½•ä¸‹ï¼Œè¾“å…¥anaconda -Vï¼ˆæ³¨æ„aè¦å°å†™ï¼ŒVè¦å¤§å†™ï¼‰ï¼Œconda -V ,æ˜¾ç¤ºç‰ˆæœ¬ä¿¡æ¯ï¼Œè‹¥æ˜¾ç¤ºåˆ™è¡¨ç¤ºå®‰è£…æˆåŠŸã€‚<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">root@dev-wyf-react:~/wyf<span class="comment"># conda -V</span></span><br><span class="line">conda 4.5.11</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="Anacondaå®‰è£…Pytorch"><a href="#Anacondaå®‰è£…Pytorch" class="headerlink" title="Anacondaå®‰è£…Pytorch"></a>Anacondaå®‰è£…Pytorch</h2><h3 id="2-1-åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ"><a href="#2-1-åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ" class="headerlink" title="2.1 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ"></a>2.1 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">conda create -n pytorch python=3.7 ï¼ˆpytorch æ˜¯æˆ‘è‡ªå·±å–çš„åå­—ï¼‰</span><br></pre></td></tr></tbody></table></figure>
<h3 id="2-2-æ¿€æ´»ç¯å¢ƒ"><a href="#2-2-æ¿€æ´»ç¯å¢ƒ" class="headerlink" title="2.2 æ¿€æ´»ç¯å¢ƒ"></a>2.2 æ¿€æ´»ç¯å¢ƒ</h3><p>ä½¿ç”¨ä¸‹é¢è¿™æ¡å‘½ä»¤ï¼Œæ¿€æ´»ç¯å¢ƒï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">conda activate pytorch</span><br></pre></td></tr></tbody></table></figure><br>å‡ºç°ä¸‹é¢æ‰€ç¤º:<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">(pytorch) root@dev-wyf-react:~/wyf<span class="comment">#</span></span><br></pre></td></tr></tbody></table></figure><br>æ£€æµ‹ç¯å¢ƒæ˜¯å¦å®‰è£…å¥½:<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">(pytorch) root@dev-wyf-react:~/wyf<span class="comment"># conda info â€“envs</span></span><br></pre></td></tr></tbody></table></figure><br>å‡ºç°ä¸‹é¢æ‰€ç¤ºï¼š<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">base /root/anaconda3 pytorch * /root/anaconda3/envs/pytorch</span><br></pre></td></tr></tbody></table></figure><br>ç„¶åå»é€‰æ‹©é€‚åˆè‡ªå·±çš„pytorchç‰ˆæœ¬ï¼Œç‚¹å‡»ä¸‹é¢é‚£ä¸ªé“¾æ¥:<br><a href="https://pytorch.org/">https://pytorch.org/</a><br><img src="https://pica.zhimg.com/v2-909fe51d58b9ad7b9a6494d682206fff.png" alt=""><br>åˆ©ç”¨å®‰è£…çš„cudatoolkit=11.3å¯ä»¥å¾ˆå¥½çš„å®‰è£…cudaå·¥å…·åŒ…<p></p>
<h3 id="2-3-æµ‹è¯•å®‰è£…æˆåŠŸ"><a href="#2-3-æµ‹è¯•å®‰è£…æˆåŠŸ" class="headerlink" title="2.3 æµ‹è¯•å®‰è£…æˆåŠŸ"></a>2.3 æµ‹è¯•å®‰è£…æˆåŠŸ</h3><p>é¦–å…ˆè¾“å…¥ï¼š python ç„¶ååœ¨è¾“å…¥ï¼šimport torch</p>
<p><img src="https://pic1.zhimg.com/v2-8351ad9a02919bb2186436fbb04719d5.png" alt=""></p>
<h3 id="2-4-é€€å‡ºä¹‹åå¦‚ä½•æŸ¥çœ‹è‡ªå·±å®‰è£…çš„ç¯å¢ƒ"><a href="#2-4-é€€å‡ºä¹‹åå¦‚ä½•æŸ¥çœ‹è‡ªå·±å®‰è£…çš„ç¯å¢ƒ" class="headerlink" title="2.4 é€€å‡ºä¹‹åå¦‚ä½•æŸ¥çœ‹è‡ªå·±å®‰è£…çš„ç¯å¢ƒ"></a>2.4 é€€å‡ºä¹‹åå¦‚ä½•æŸ¥çœ‹è‡ªå·±å®‰è£…çš„ç¯å¢ƒ</h3><p>å¦‚æœåœ¨ä¸€å°æœåŠ¡å™¨ä¸Šå®‰è£…å¤šä¸ªç¯å¢ƒï¼Œä¸€ä¸‹å­å¯èƒ½ä¸è®°å¾—éœ€è¦æ¿€æ´»å“ªä¸ªç¯å¢ƒåç§°ï¼Œè¿™æ—¶å€™æˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸‹é¢è¿™ä¸ªå‘½ä»¤æ¥æŸ¥æ‰¾ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">conda info â€“envs</span><br></pre></td></tr></tbody></table></figure><br><img src="https://picx.zhimg.com/v2-a2d772f6c53ad75747862907d184eec3.png" alt=""><p></p>
<h2 id="è¿ç§»-conda-ç¯å¢ƒ"><a href="#è¿ç§»-conda-ç¯å¢ƒ" class="headerlink" title="è¿ç§» conda ç¯å¢ƒ"></a>è¿ç§» conda ç¯å¢ƒ</h2><p>æœ‰æ—¶å€™æˆ‘ä»¬éœ€è¦åœ¨æœºå™¨ä¸Šé‡æ–°å»ºä¸€ä¸ª conda ç¯å¢ƒï¼Œä½†æ˜¯åˆä¸æƒ³é‡æ–°è£…åŒ…ï¼Œæ¯•ç«Ÿ pytorch å’Œ cuda ç‰ˆæœ¬éƒ½è·Ÿä¹‹å‰çš„ç¯å¢ƒæ˜¯ä¸€æ ·çš„ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥ä»ä¹‹å‰çš„ç¯å¢ƒä¸­å¤åˆ¶ä¸€ä»½æˆä¸ºæ–°ç¯å¢ƒï¼Œconda æ˜¯æ”¯æŒè¿™æ ·åšçš„ï¼Œä»¥ä¸‹å‘½ä»¤å°±å°† BBB ç¯å¢ƒæ‹·è´äº†ä¸€ä»½æˆä¸º AAA ç¯å¢ƒã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">conda create -n AAA --<span class="built_in">clone</span> BBB</span><br></pre></td></tr></tbody></table></figure>
<p>å¦‚æœæ¶‰åŠä¸åŒæœåŠ¡å™¨ä¹‹é—´è£…ç¯å¢ƒçš„è¯ä¹Ÿä¸€æ ·ï¼Œå¯ä»¥å…ˆå°†æ—§çš„ç¯å¢ƒæ‹·è´åˆ°æ–°çš„ç”µè„‘ï¼Œç„¶åé€šè¿‡ä¸‹é¢çš„å‘½ä»¤åˆ›ä¸€ä¸ªæ–°çš„ç¯å¢ƒ</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">conda create -n AAA --<span class="built_in">clone</span> ~/path </span><br></pre></td></tr></tbody></table></figure>
<p>å¯ä»¥ä½¿ç”¨ <code>conda info -e</code> æ¥æŸ¥è¯¢æœºå™¨ä¸Šçš„æ‰€æœ‰ conda ç¯å¢ƒä»¥åŠå¯¹åº”æ‰€åœ¨çš„ä½ç½®ã€‚</p>
<h2 id="å…¶ä»–é”™è¯¯"><a href="#å…¶ä»–é”™è¯¯" class="headerlink" title="å…¶ä»–é”™è¯¯"></a>å…¶ä»–é”™è¯¯</h2><p>step1ï¼šå®‰è£…anacoda ä¸‹è½½åœ°å€</p>
<figure class="highlight jsx"><table><tbody><tr><td class="code"><pre><span class="line">bash <span class="title class_">Anaconda3</span>-<span class="number">2018.12</span>-<span class="title class_">Linux</span>-x86_64.<span class="property">sh</span></span><br></pre></td></tr></tbody></table></figure>
<p>step2ï¼šæŒ‰ç…§å®˜ç½‘çš„æ–¹æ³•å®‰è£…pytorch </p>
<figure class="highlight jsx"><table><tbody><tr><td class="code"><pre><span class="line">conda install pytorch torchvision cudatoolkit=<span class="number">10.0</span> -c pytorch</span><br></pre></td></tr></tbody></table></figure>
<p>åœ¨æ­¤æœŸé—´ä½ ä¼šå‘ç°ç‰¹åˆ«çš„æ…¢ï¼Œæ…¢ä¹Ÿå°±ç®—äº†ä¸»è¦å®ƒè¿˜è€å®‰è£…ä¸æˆåŠŸï¼Œè¿™æ˜¯ä¸ºä»€ä¹ˆå‘¢<br>åœ¨ç”¨condaå®‰è£…è½¯ä»¶çš„è¿‡ç¨‹ä¸­è¿˜ä¼šç»å¸¸é‡åˆ°çš„ä¸€ä¸ªé—®é¢˜ï¼Œå°±æ˜¯ï¼šè½¯ä»¶å¤ªå¤§è€æ˜¯ä¸‹è½½ä¸­æ–­ æˆ‘è¦ä¸‹è½½ä¸€ä¸ªè½¯ä»¶ï¼Œcondaä¼šå‘Šè¯‰æˆ‘è¿™ä¸ªè½¯ä»¶åº•å±‚ä¾èµ–å¥½å‡ ä¸ªå…¶ä»–çš„è½¯ä»¶ï¼Œéœ€è¦å°†å®ƒä»¬ä¸€èµ·ä¸‹è½½å®‰è£…ï¼Œè¿™ä¸ªæ—¶å€™è¿™ä¸€å¤§å †è½¯ä»¶ä¸­å¯èƒ½æœ‰å‡ ä¸ªä½“é‡å¾ˆå¤§ï¼Œä¸Šç™¾MBï¼Œå¾ˆå®¹æ˜“ä¸‹ç€ä¸‹ç€ç½‘ç»œè¿æ¥å°±ä¸­æ–­äº†ï¼Œè€Œcondaæœ‰æ²¡æœ‰æ–­ç‚¹ä¸‹è½½åŠŸèƒ½ï¼Œä¸€æ—¦ä¸‹è½½ä¸­æ–­ï¼Œcondaå°±ä¼šç»ˆæ­¢å®‰è£…è¿›ç¨‹é€€å‡ºè¿è¡Œ æœ€åï¼Œæˆ‘ä»¬è½¬æˆ˜æ¸…åæºå®‰è£…,è¿è¡Œä»¥ä¸‹å‘½ä»¤:</p>
<figure class="highlight jsx"><table><tbody><tr><td class="code"><pre><span class="line">conda config --add channels <span class="attr">https</span>:<span class="comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span></span><br><span class="line">conda config --add channels <span class="attr">https</span>:<span class="comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</span></span><br><span class="line">conda config --set show_channel_urls yes</span><br><span class="line"># reference</span><br><span class="line"></span><br><span class="line"># <span class="attr">https</span>:<span class="comment">//mirror.tuna.tsinghua.edu.cn/help/anaconda/</span></span><br><span class="line">conda config --add channels <span class="attr">https</span>:<span class="comment">//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/</span></span><br></pre></td></tr></tbody></table></figure>
<p>LASTï¼Œç›´æ¥è¿è¡Œä¸‹é¢çš„å‘½ä»¤å°±å¯ä»¥å¿«é€Ÿå®‰è£…å¥½å•¦ï¼ŒçœŸçš„çœŸçš„çœŸçš„å¾ˆå¿«ï¼Œå°±æ˜¯ä¸èµ°-c pytorchå³å¯</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">conda install pytorch torchvision cudatoolkit=10.0</span><br></pre></td></tr></tbody></table></figure>
<p>å¯å‚è€ƒï¼š<a href="https://cloud.tencent.com/developer/article/1627527">https://cloud.tencent.com/developer/article/1627527</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>LinuxæœåŠ¡å™¨ä¹‹é—´æ–‡ä»¶ä¼ è¾“</title>
    <url>/2024/01/01/Linux/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%97%B4%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93/</url>
    <content><![CDATA[<h2 id="SCPå‘½ä»¤"><a href="#SCPå‘½ä»¤" class="headerlink" title="SCPå‘½ä»¤"></a>SCPå‘½ä»¤</h2><p>æ­£å¸¸æƒ…å†µä¸‹ä½¿ç”¨SCPå‘½ä»¤<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># å°†æœåŠ¡å™¨æ–‡ä»¶ä¼ è¾“åˆ°æœ¬åœ°</span></span><br><span class="line">scp -r user@ip:æœåŠ¡å™¨æ–‡ä»¶å¤¹ æœ¬åœ°æ–‡ä»¶å¤¹</span><br></pre></td></tr></tbody></table></figure><br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># å°†æœ¬åœ°æ–‡ä»¶ä¼ è¾“åˆ°æœåŠ¡å™¨</span></span><br><span class="line">scp -r æœ¬åœ°æ–‡ä»¶å¤¹ user@ip:æœåŠ¡å™¨æ–‡ä»¶å¤¹</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="ä½¿ç”¨å¯†é’¥"><a href="#ä½¿ç”¨å¯†é’¥" class="headerlink" title="ä½¿ç”¨å¯†é’¥"></a>ä½¿ç”¨å¯†é’¥</h2><p>ä½¿ç”¨å¯†é’¥æ—¶ï¼Œéœ€è¦æ·»åŠ ä¸€ä¸ª-içš„å‚æ•°ï¼Œå¹¶è¾“å…¥å¯¹åº”å¯†é’¥çš„å¯†ç å³å¯<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">scp -i å¯¹åº”å¯†é’¥åœ°å€ -r user@ip æœ¬åœ°æ–‡ä»¶å¤¹</span><br></pre></td></tr></tbody></table></figure><br>å¦‚æœå‡ºç°Permissions 0644é”™è¯¯ï¼Œåˆ™è¿è¡Œchmod 400ä¿®æ”¹ä¸€ä¸‹æƒé™å³å¯<br><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">chmod 400 å¯†é’¥åœ°å€</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="å¢åŠ ç«¯å£port"><a href="#å¢åŠ ç«¯å£port" class="headerlink" title="å¢åŠ ç«¯å£port"></a>å¢åŠ ç«¯å£port</h2><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">scp -r -i å¯¹åº”å¯†é’¥åœ°å€ -P ç«¯å£å· user@ip:æœåŠ¡å™¨æ–‡ä»¶å¤¹ æœ¬åœ°æ–‡ä»¶å¤¹</span><br></pre></td></tr></tbody></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>SSHFS-WINä½¿ç”¨è¿æ¥LinuxæœåŠ¡å™¨</title>
    <url>/2024/01/01/Linux/SSHFS-WIN%E4%BD%BF%E7%94%A8%E8%BF%9E%E6%8E%A5Linux%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<p><a href="https://github.com/evsar3/sshfs-win-manager">https://github.com/evsar3/sshfs-win-manager</a></p>
<h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a><strong>Installation</strong></h2><p><strong>Step 1</strong><br>Install SSHFS-Win on your Windows computer.<br>Follow they <a href="https://github.com/winfsp/sshfs-win/blob/master/README.md">installation instructions</a> before continue.</p>
<blockquote>
<ul>
<li>Install the latest version of <a href="https://github.com/billziss-gh/winfsp/releases/latest">WinFsp</a>.</li>
<li>Install the latest version of <a href="https://github.com/billziss-gh/sshfs-win/releases">SSHFS-Win</a>. Choose the x64 or x86 installer according to your computerâ€™s architecture.ï¼ˆä¸€èˆ¬winç”µè„‘æ˜¯x64ï¼‰</li>
</ul>
</blockquote>
<p>åœ¨æ‚¨çš„Windowsè®¡ç®—æœºä¸Šå®‰è£…SSHFS-Winã€‚ åœ¨ç»§ç»­ä¹‹å‰ï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹å®‰è£…è¯´æ˜è¿›è¡Œæ“ä½œï¼š </p>
<ul>
<li>å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„WinFspã€‚ </li>
<li>å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„SSHFS-Winã€‚æ ¹æ®æ‚¨è®¡ç®—æœºçš„æ¶æ„é€‰æ‹©x64æˆ–x86å®‰è£…ç¨‹åºã€‚ï¼ˆé€šå¸¸æƒ…å†µä¸‹ï¼ŒWindowsç”µè„‘ä½¿ç”¨x64æ¶æ„ã€‚ï¼‰</li>
</ul>
<p><strong>Step 2</strong><br>Once SSHFS-Win is installed, <a href="https://github.com/evsar3/sshfs-win-manager/releases/latest">download the lastest setup</a> from the <a href="https://github.com/evsar3/sshfs-win-manager/releases">releases</a> section and install it.<br>å®‰è£…æ¡Œé¢ç‰ˆæœ¬çš„SSHFS-winï¼Œç”¨æœ€æ–°ç‰ˆæœ¬<br><strong>Step 3</strong><br>Add your connections and enjoy!</p>
<h2 id="Screenshots"><a href="#Screenshots" class="headerlink" title="Screenshots"></a>Screenshots</h2><p><img src="https://picx.zhimg.com/v2-73f85dfba21f7760230a65ab574d8551.png" alt="Main Window"></p>
<p><img src="https://pica.zhimg.com/v2-81b072937c987de94039a2c6ef00b0d2.png" alt="Add &amp; edit connections"></p>
<p><img src="https://picx.zhimg.com/v2-b5f0fb802dadff86258fad695d6ba5b9.png" alt="Explore mounted drive"></p>
<p><img src="https://picx.zhimg.com/v2-ea10b8327376cab8e80ca120ab32ac24.png" alt="Close to system tray"></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linuxé…ç½® Rsyslog æœåŠ¡å™¨</title>
    <url>/2024/01/01/Linux/Linux%E9%85%8D%E7%BD%AE%20Rsyslog%20%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<p><a href="https://bynss.com/linux/770633.html">å¦‚ä½•åœ¨ Ubuntu ä¸Šè®¾ç½® Rsyslog æœåŠ¡å™¨ â€“ Digitalixy.com</a></p>
<h1 id="æ—¥å¿—æ–‡ä»¶å’ŒRsyslogç®€ä»‹"><a href="#æ—¥å¿—æ–‡ä»¶å’ŒRsyslogç®€ä»‹" class="headerlink" title="æ—¥å¿—æ–‡ä»¶å’ŒRsyslogç®€ä»‹"></a>æ—¥å¿—æ–‡ä»¶å’ŒRsyslogç®€ä»‹</h1><p>æ—¥å¿—æ–‡ä»¶æ˜¯ç”¨äºä¿å­˜ç³»ç»Ÿæ´»åŠ¨ä¿¡æ¯çš„æ–‡ä»¶ï¼ŒåŒ…æ‹¬æˆæƒå’Œè®¿é—®å°è¯•ã€å¯åŠ¨å’Œå…³é—­å°è¯•ï¼Œä»¥åŠæœåŠ¡çš„å¯åŠ¨å’Œå…³é—­ã€‚ä¸åŒç±»å‹çš„æ´»åŠ¨æœ‰ä¸åŒçš„æ—¥å¿—æ–‡ä»¶ã€‚Rsyslogæ˜¯ä¸€æ¬¾å¼€æºç¨‹åºï¼Œç”¨äºé…ç½®Linuxæ“ä½œç³»ç»Ÿçš„æ—¥å¿—æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯ã€‚<br>åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œå°†åœ¨ Ubuntu æ“ä½œç³»ç»Ÿä¸Šè®¾ç½® Rsyslog æœåŠ¡å™¨ã€‚ æˆ‘ä»¬å°†ä½¿ç”¨ä¸¤å° Ubuntu æœºå™¨ã€‚<br>åœ¨ä¸€å° Ubuntu æœºå™¨ä¸Šï¼Œæˆ‘ä»¬å°† Rsyslog é…ç½®ä¸ºæ—¥å¿—æœåŠ¡å™¨ï¼Œ<br>åœ¨å¦ä¸€å°æœºå™¨ä¸Šï¼› æˆ‘ä»¬å°† Rsyslog é…ç½®ä¸ºå°†æ—¥å¿—å‘é€åˆ° Rsyslog æœåŠ¡å™¨çš„å®¢æˆ·ç«¯ã€‚</p>
<h1 id="åœ¨Ubuntuä¸Šé…ç½®RsyslogæœåŠ¡å™¨"><a href="#åœ¨Ubuntuä¸Šé…ç½®RsyslogæœåŠ¡å™¨" class="headerlink" title="åœ¨Ubuntuä¸Šé…ç½®RsyslogæœåŠ¡å™¨"></a>åœ¨Ubuntuä¸Šé…ç½®RsyslogæœåŠ¡å™¨</h1><p>åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†åœ¨ä¸¤å°Ubuntuæœºå™¨ä¸Šè®¾ç½®RsyslogæœåŠ¡å™¨ã€‚ä¸€å°æœºå™¨å°†è¢«é…ç½®ä¸ºRsyslogæœåŠ¡å™¨ï¼Œå¦ä¸€å°æœºå™¨å°†è¢«é…ç½®ä¸ºå°†æ—¥å¿—å‘é€åˆ°RsyslogæœåŠ¡å™¨çš„å®¢æˆ·ç«¯ã€‚</p>
<h2 id="å®‰è£…Rsyslog"><a href="#å®‰è£…Rsyslog" class="headerlink" title="å®‰è£…Rsyslog"></a>å®‰è£…Rsyslog</h2><p>å¦‚æœRsyslogæœªå®‰è£…ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿›è¡Œå®‰è£…ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt install rsyslog</span><br></pre></td></tr></tbody></table></figure><br>åœ¨å®‰è£…è¿‡ç¨‹ä¸­ï¼Œå®ƒä¼šæç¤ºæ‚¨ æ˜¯/å¦ ç”¨äºç»§ç»­å®‰è£… Rsyslog çš„é€‰é¡¹ã€‚ æŒ‰ æ˜¯ æ¥ç€Enter ç»§ç»­ã€‚<br>éªŒè¯Rsyslogå®‰è£…å¹¶æ£€æŸ¥å…¶æœåŠ¡çŠ¶æ€ï¼š<br><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo systemctl status rsyslog</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="é…ç½®RsyslogæœåŠ¡å™¨"><a href="#é…ç½®RsyslogæœåŠ¡å™¨" class="headerlink" title="é…ç½®RsyslogæœåŠ¡å™¨"></a>é…ç½®RsyslogæœåŠ¡å™¨</h2><p>ç¼–è¾‘Rsyslogé…ç½®æ–‡ä»¶<code>/etc/rsyslog.conf</code>ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo nano /etc/rsyslog.conf</span><br></pre></td></tr></tbody></table></figure><br>åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ ä»¥ä¸‹è¡Œï¼Œç”¨äºæ¥æ”¶é€šè¿‡UDPå’ŒTCPå‘é€çš„syslogï¼š<br><figure class="highlight properties"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># Receive syslog over UDP</span></span><br><span class="line"><span class="attr">module(load</span>=<span class="string">"imudp") </span></span><br><span class="line"><span class="attr">input(type</span>=<span class="string">"imudp" port="514")</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Receive syslog over TCP</span></span><br><span class="line"><span class="attr">module(load</span>=<span class="string">"imtcp") </span></span><br><span class="line"><span class="attr">input(type</span>=<span class="string">"imtcp" port="514")</span></span><br></pre></td></tr></tbody></table></figure><br>åˆ›å»ºä¸€ä¸ªæ¨¡æ¿ï¼Œç”¨äºå­˜å‚¨ä¼ å…¥çš„syslogæ¶ˆæ¯ï¼š<br><figure class="highlight properties"><table><tbody><tr><td class="code"><pre><span class="line"><span class="attr">$template</span> <span class="string">remote-incoming-logs, "/var/log/%HOSTNAME%/%PROGRAMNAME%.log"</span></span><br><span class="line"><span class="attr">*.*</span> <span class="string">?remote-incoming-logs</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<p><img src="https://picx.zhimg.com/v2-6852e00c33d7a3653c21a0274f95c9d2.png" alt=""><br>ä¿å­˜å¹¶å…³é—­é…ç½®æ–‡ä»¶ï¼Œç„¶åé‡å¯RsyslogæœåŠ¡ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo systemctl restart rsyslog</span><br></pre></td></tr></tbody></table></figure>
<p>æ‚¨è¿˜å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤éªŒè¯ Rsyslog æ˜¯å¦æ­£åœ¨ä¾¦å¬ TCP/UDP ç«¯å£ 514ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ sudo ss -tunlp | grep 514</span><br></pre></td></tr></tbody></table></figure><br>åº”è¯¥æ”¶åˆ°ä»¥ä¸‹è¾“å‡ºï¼š<p></p>
<p><img src="https://picx.zhimg.com/v2-96f64402412999a61ab770c8e4060404.png" alt=""></p>
<h2 id="é…ç½®é˜²ç«å¢™"><a href="#é…ç½®é˜²ç«å¢™" class="headerlink" title="é…ç½®é˜²ç«å¢™"></a>é…ç½®é˜²ç«å¢™</h2><p>å¦‚æœç³»ç»Ÿå¯ç”¨äº†é˜²ç«å¢™ï¼Œæ‰“å¼€TCPå’ŒUDPç«¯å£514ï¼ŒRsyslogæœåŠ¡å™¨ä½¿ç”¨è¿™äº›ç«¯å£æ¥æ”¶æ¥è‡ªè¿œç¨‹å®¢æˆ·ç«¯çš„æ—¥å¿—ï¼š<br></p><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw allow 514/tcp</span><br><span class="line">sudo ufw allow 514/udp</span><br><span class="line">sudo ufw reload <span class="comment"># é‡æ–°åŠ è½½é˜²ç«å¢™</span></span><br></pre></td></tr></tbody></table></figure><p></p>
<h1 id="åœ¨-Ubuntu-ä¸Šé…ç½®-Rsyslog-å®¢æˆ·ç«¯"><a href="#åœ¨-Ubuntu-ä¸Šé…ç½®-Rsyslog-å®¢æˆ·ç«¯" class="headerlink" title="åœ¨ Ubuntu ä¸Šé…ç½® Rsyslog å®¢æˆ·ç«¯"></a>åœ¨ Ubuntu ä¸Šé…ç½® Rsyslog å®¢æˆ·ç«¯</h1><p>ç°åœ¨åœ¨å¦ä¸€ä¸ª Ubuntu ç³»ç»Ÿä¸Šï¼Œæˆ‘ä»¬å°†æ‰§è¡Œ Rsyslog å®¢æˆ·ç«¯çš„é…ç½®ã€‚ ç„¶åï¼Œæ­¤å®¢æˆ·ç«¯ä¼šå°†å…¶æ—¥å¿—å‘é€åˆ° Rsyslog æ—¥å¿—è®°å½•æœåŠ¡å™¨ã€‚</p>
<h2 id="å®‰è£…Rsyslog-1"><a href="#å®‰è£…Rsyslog-1" class="headerlink" title="å®‰è£…Rsyslog"></a>å®‰è£…Rsyslog</h2><p>å¦‚æœå°šæœªå®‰è£…Rsyslogï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š<br></p><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt install rsyslog</span><br></pre></td></tr></tbody></table></figure><p></p>
<h2 id="ä¿®æ”¹é…ç½®æ–‡ä»¶"><a href="#ä¿®æ”¹é…ç½®æ–‡ä»¶" class="headerlink" title="ä¿®æ”¹é…ç½®æ–‡ä»¶"></a>ä¿®æ”¹é…ç½®æ–‡ä»¶</h2><p>ç¼–è¾‘Rsyslogé…ç½®æ–‡ä»¶ï¼š<br></p><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">sudo vim /etc/rsyslog.conf</span><br></pre></td></tr></tbody></table></figure><br><strong>å…·ä½“ç»†èŠ‚çœ‹å‚è€ƒå›¾ï¼š</strong><br><img src="https://picx.zhimg.com/v2-504b8c11750552c11c53d2233980ef28.png" alt=""><br><img src="https://picx.zhimg.com/v2-20c70f079d16d5dd288004534c7048fe.png" alt=""><br>åœ¨ Rsyslog é…ç½®æ–‡ä»¶çš„æœ«å°¾æ·»åŠ ä»¥ä¸‹è¡Œã€‚ ç¡®ä¿æ›´æ¢ 192.168.72.204 ä¸æ‚¨çš„ Rsyslog æ—¥å¿—è®°å½•æœåŠ¡å™¨çš„ IP åœ°å€ã€‚(<strong>è¿™é‡Œè¦æ³¨æ„ipåœ°å€ï¼Œå¦‚172.31.224.190</strong>)<p></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">ï¼Œ<span class="comment">#Send system logs to rsyslog server over RDP</span></span><br><span class="line"></span><br><span class="line">*.* @192.168.72.204:514 <span class="comment"># *.* @æœåŠ¡å™¨ipåœ°å€:514</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Send system logs to rsyslog server over TCP</span></span><br><span class="line"></span><br><span class="line">*.* @@192.168.72.204:514 <span class="comment"># *.* @@æœåŠ¡å™¨ipåœ°å€:514 </span></span><br><span class="line"></span><br><span class="line"><span class="comment">##Set disk queue to preserve your logs in case rsyslog server is experiencing any downtime</span></span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="variable">$ActionQueueFileName</span> queue</span><br><span class="line"></span><br><span class="line"><span class="variable">$ActionQueueMaxDiskSpace</span> 1g</span><br><span class="line"></span><br><span class="line"><span class="variable">$ActionQueueSaveOnShutdown</span> on</span><br><span class="line"></span><br><span class="line"><span class="variable">$ActionQueueType</span> LinkedList</span><br><span class="line"></span><br><span class="line"><span class="variable">$ActionResumeRetryCount</span> -1</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ä¿®æ”¹é…ç½®æ–‡ä»¶-1"><a href="#ä¿®æ”¹é…ç½®æ–‡ä»¶-1" class="headerlink" title="ä¿®æ”¹é…ç½®æ–‡ä»¶"></a>ä¿®æ”¹é…ç½®æ–‡ä»¶</h2><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">vim /etc/rsyslog.d/50-default.conf</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://pic1.zhimg.com/v2-9b7bdc9a3e08ad468aef863ce72ad7eb.png" alt=""></p>
<h2 id="æ·»åŠ ç¯å¢ƒå˜é‡"><a href="#æ·»åŠ ç¯å¢ƒå˜é‡" class="headerlink" title="æ·»åŠ ç¯å¢ƒå˜é‡"></a>æ·»åŠ ç¯å¢ƒå˜é‡</h2><p>åœ¨vim /etc/profileæœ€åæ·»åŠ <br></p><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">export PROMPT_COMMAND="history -a"</span><br><span class="line">export HISTTIMEFORMAT="`whoami` %F %T "</span><br><span class="line">shopt -s histappend</span><br><span class="line">export PROMPT_COMMAND='{ msg=$(history 1 | { read x y; echo $y; });logger "[euid=$(whoami)]":$(who am i):[`pwd`]"$msg"; }'</span><br></pre></td></tr></tbody></table></figure><br><img src="https://picx.zhimg.com/v2-6b59d9c8ecdd94a5ef00ee35ed7111e1.png" alt=""><p></p>
<h2 id="é‡å¯æœåŠ¡"><a href="#é‡å¯æœåŠ¡" class="headerlink" title="é‡å¯æœåŠ¡"></a>é‡å¯æœåŠ¡</h2><p>ç°åœ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤é‡å¯ Rsyslog çš„æœåŠ¡ï¼š<br></p><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">/etc/init.d/rsyslog restart</span><br></pre></td></tr></tbody></table></figure><br><img src="https://pic1.zhimg.com/v2-c1deae4ddcadce6e60f62c011f98248d.png" alt=""><p></p>
<h1 id="åœ¨-Rsyslog-Server-ä¸­æŸ¥çœ‹å®¢æˆ·ç«¯çš„æ—¥å¿—æ–‡ä»¶"><a href="#åœ¨-Rsyslog-Server-ä¸­æŸ¥çœ‹å®¢æˆ·ç«¯çš„æ—¥å¿—æ–‡ä»¶" class="headerlink" title="åœ¨ Rsyslog Server ä¸­æŸ¥çœ‹å®¢æˆ·ç«¯çš„æ—¥å¿—æ–‡ä»¶"></a>åœ¨ Rsyslog Server ä¸­æŸ¥çœ‹å®¢æˆ·ç«¯çš„æ—¥å¿—æ–‡ä»¶</h1><p>å®Œæˆä¸Šè¿°æ‰€æœ‰é…ç½®åï¼Œæ‚¨å¯ä»¥æŸ¥çœ‹å®¢æˆ·ç«¯å‘é€åˆ° Rsyslog æœåŠ¡å™¨çš„æ—¥å¿—æ–‡ä»¶ã€‚ åœ¨æ‚¨çš„ Rsyslog æœåŠ¡å™¨æœºå™¨ä¸Šï¼Œåœ¨ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š<br></p><figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">$ ls /var/log/ # å…·ä½“çœ‹æ–‡ä»¶çš„å‘½å</span><br></pre></td></tr></tbody></table></figure><br>åœ¨ä¸Šè¿°å‘½ä»¤çš„è¾“å‡ºä¸­ï¼Œæ‚¨å°†çœ‹åˆ°ä¸€ä¸ªä¸æ‚¨çš„å®¢æˆ·ç«¯ç³»ç»Ÿä¸»æœºåç›¸åŒçš„ç›®å½•ï¼ˆæˆ‘ä»¬çš„ ubuntu2 exampleï¼‰ã€‚<br><img src="https://picx.zhimg.com/v2-d524b8a87c12665b38e574fb511d5229.png" alt=""><br>è¦æŸ¥çœ‹å®¢æˆ·ç«¯æœºå™¨çš„æ—¥å¿—æ–‡ä»¶ï¼Œè¯·åˆ—å‡ºè¯¥ç›®å½•çš„å†…å®¹ï¼š<p></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">$ sudo ls /var/log/ubuntu2</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://pic1.zhimg.com/v2-209842178d0de9e02cff85c548270c8b.png" alt=""></p>
<p>è¿™å°±æ˜¯å®ƒçš„å…¨éƒ¨ï¼ åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†å¦‚ä½•åœ¨ Ubuntu OS ä¸Šå°† Rsyslog é…ç½®ä¸ºæ—¥å¿—æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯ä»¥å°†æ—¥å¿—å‘é€åˆ° Rsyslog æœåŠ¡å™¨ã€‚ æˆ‘ä»¬è¿˜ä»‹ç»äº†å¦‚ä½•æŸ¥çœ‹å®¢æˆ·ç«¯å‘é€åˆ°æ—¥å¿—æœåŠ¡å™¨çš„æ—¥å¿—ã€‚</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>SSHè¿æ¥æœåŠ¡å™¨ä¸­æ–­ï¼Œä»£ç ç»§ç»­è¿è¡Œ</title>
    <url>/2024/01/01/Linux/SSH%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%AD%E6%96%AD%EF%BC%8C%E4%BB%A3%E7%A0%81%E7%BB%A7%E7%BB%AD%E8%BF%90%E8%A1%8C/</url>
    <content><![CDATA[<h2 id="1ã€sshè¿æ¥linuxæœåŠ¡å™¨ä¸­æ–­åï¼Œå¦‚ä½•è®©å‘½ä»¤ç»§ç»­åœ¨æœåŠ¡å™¨è¿è¡Œ"><a href="#1ã€sshè¿æ¥linuxæœåŠ¡å™¨ä¸­æ–­åï¼Œå¦‚ä½•è®©å‘½ä»¤ç»§ç»­åœ¨æœåŠ¡å™¨è¿è¡Œ" class="headerlink" title="1ã€sshè¿æ¥linuxæœåŠ¡å™¨ä¸­æ–­åï¼Œå¦‚ä½•è®©å‘½ä»¤ç»§ç»­åœ¨æœåŠ¡å™¨è¿è¡Œ"></a>1ã€sshè¿æ¥linuxæœåŠ¡å™¨ä¸­æ–­åï¼Œå¦‚ä½•è®©å‘½ä»¤ç»§ç»­åœ¨æœåŠ¡å™¨è¿è¡Œ</h2><p>è¿™ä¸ªé—®é¢˜ä¹Ÿè®¸æ˜¯æˆ‘ä»¬è¿™äº›å°ç™½æ¯”è¾ƒå¤´ç–¼çš„é—®é¢˜ï¼Œå°¤å…¶å¯¹äºé‚£äº›åšæœºå™¨å­¦ä¹ éœ€è¦èŠ±å¾ˆä¹…çš„æ—¶é—´æ‰èƒ½è®­ç»ƒå‡ºä¸€ä¸ªç»“æœã€‚ç„¶è€Œå°±åœ¨è¿™æ—¶ï¼Œå› ä¸ºå„ç§ä¸å¯æŠ—åŠ›æˆ‘ä»¬ä½¿ç”¨sshè¿æ¥æœåŠ¡å™¨æ—¶ï¼Œsshçš„çª—å£çªç„¶æ–­å¼€äº†è¿æ¥ï¼Œé‚£ä¹ˆåœ¨æœåŠ¡å™¨ä¸Šè·‘çš„ç¨‹åºå°±ä¹Ÿè·Ÿç€æ–­æ‰äº†ï¼Œä¹‹å‰æ‰€æœ‰è·‘çš„æ•°æ®ä¹Ÿå°†ä¸¢å¤±ï¼Œè¿™æ ·å°†ä¼šæµªè´¹æˆ‘ä»¬å¤§é‡çš„æ—¶é—´ã€‚</p>
<p>ä»Šå¤©åˆšå¥½æœ‰äººè·Ÿæˆ‘æåˆ°äº†è¿™ä¸ªé—®é¢˜ï¼Œç„¶åå°±ç®€å•ä¸Šç½‘æŸ¥æ‰¾èµ„æ–™ï¼Œç®€å•çš„å­¦ä¹ ä¸€ä¸‹ï¼Œåšä¸ªç¬”è®°æ–¹ä¾¿è‡ªå·±ä»¥åæŸ¥é˜…ã€‚</p>
<p>å‚è€ƒé“¾æ¥ï¼š</p>
<p><a href="http://blog.csdn.net/gukesdo/article/details/6901902">http://blog.csdn.net/gukesdo/article/details/6901902</a></p>
<h2 id="2ã€ä¸ºä»€ä¹ˆsshä¸€æ—¦æ–­å¼€æˆ‘ä»¬çš„è¿›ç¨‹ä¹Ÿå°†ä¼šè¢«æ€æ‰ï¼Ÿ"><a href="#2ã€ä¸ºä»€ä¹ˆsshä¸€æ—¦æ–­å¼€æˆ‘ä»¬çš„è¿›ç¨‹ä¹Ÿå°†ä¼šè¢«æ€æ‰ï¼Ÿ" class="headerlink" title="2ã€ä¸ºä»€ä¹ˆsshä¸€æ—¦æ–­å¼€æˆ‘ä»¬çš„è¿›ç¨‹ä¹Ÿå°†ä¼šè¢«æ€æ‰ï¼Ÿ"></a>2ã€ä¸ºä»€ä¹ˆsshä¸€æ—¦æ–­å¼€æˆ‘ä»¬çš„è¿›ç¨‹ä¹Ÿå°†ä¼šè¢«æ€æ‰ï¼Ÿ</h2><p><strong>å…ƒå‡¶ï¼šSIGHUP ä¿¡å·</strong></p>
<p>è®©æˆ‘ä»¬æ¥çœ‹çœ‹ä¸ºä»€ä¹ˆå…³æ‰çª—å£/æ–­å¼€è¿æ¥ä¼šä½¿å¾—æ­£åœ¨è¿è¡Œçš„ç¨‹åºæ­»æ‰ã€‚</p>
<p>åœ¨Linux/Unixä¸­ï¼Œæœ‰è¿™æ ·å‡ ä¸ªæ¦‚å¿µï¼š</p>
<p><strong>è¿›ç¨‹ç»„ï¼ˆprocess groupï¼‰ï¼šä¸€ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹çš„é›†åˆï¼Œæ¯ä¸€ä¸ªè¿›ç¨‹ç»„æœ‰å”¯ä¸€ä¸€ä¸ªè¿›ç¨‹ç»„IDï¼Œå³è¿›ç¨‹ç»„é•¿è¿›ç¨‹çš„IDã€‚</strong></p>
<p><strong>ä¼šè¯æœŸï¼ˆsessionï¼‰ï¼šä¸€ä¸ªæˆ–å¤šä¸ªè¿›ç¨‹ç»„çš„é›†åˆï¼Œæœ‰å”¯ä¸€ä¸€ä¸ªä¼šè¯æœŸé¦–è¿›ç¨‹ï¼ˆsession leaderï¼‰ã€‚ä¼šè¯æœŸIDä¸ºé¦–è¿›ç¨‹çš„IDã€‚</strong></p>
<p><strong>ä¼šè¯æœŸå¯ä»¥æœ‰ä¸€ä¸ªå•ç‹¬çš„æ§åˆ¶ç»ˆç«¯ï¼ˆcontrolling terminalï¼‰ã€‚ä¸æ§åˆ¶ç»ˆç«¯è¿æ¥çš„ä¼šè¯æœŸé¦–è¿›ç¨‹å«åšæ§åˆ¶è¿›ç¨‹ï¼ˆcontrolling processï¼‰ã€‚å½“å‰ä¸ç»ˆç«¯äº¤äº’çš„è¿›ç¨‹ç§°ä¸ºå‰å°è¿›ç¨‹ç»„ã€‚å…¶ä½™è¿›ç¨‹ç»„ç§°ä¸ºåå°è¿›ç¨‹ç»„ã€‚</strong></p>
<p>æ ¹æ®POSIX.1å®šä¹‰ï¼š</p>
<p>æŒ‚æ–­ä¿¡å·ï¼ˆSIGHUPï¼‰é»˜è®¤çš„åŠ¨ä½œæ˜¯ç»ˆæ­¢ç¨‹åºã€‚</p>
<p>å½“ç»ˆç«¯æ¥å£æ£€æµ‹åˆ°ç½‘ç»œè¿æ¥æ–­å¼€ï¼Œå°†æŒ‚æ–­ä¿¡å·å‘é€ç»™æ§åˆ¶è¿›ç¨‹ï¼ˆä¼šè¯æœŸé¦–è¿›ç¨‹ï¼‰ã€‚</p>
<p>å¦‚æœä¼šè¯æœŸé¦–è¿›ç¨‹ç»ˆæ­¢ï¼Œåˆ™è¯¥ä¿¡å·å‘é€åˆ°è¯¥ä¼šè¯æœŸå‰å°è¿›ç¨‹ç»„ã€‚</p>
<p>ä¸€ä¸ªè¿›ç¨‹é€€å‡ºå¯¼è‡´ä¸€ä¸ªå­¤å„¿è¿›ç¨‹ç»„ä¸­äº§ç”Ÿæ—¶ï¼Œå¦‚æœä»»æ„ä¸€ä¸ªå­¤å„¿è¿›ç¨‹ç»„è¿›ç¨‹å¤„äºSTOPçŠ¶æ€ï¼Œå‘é€SIGHUPå’ŒSIGCONTä¿¡å·åˆ°è¯¥è¿›ç¨‹ç»„ä¸­æ‰€æœ‰è¿›ç¨‹ã€‚</p>
<p>å› æ­¤å½“ç½‘ç»œæ–­å¼€æˆ–ç»ˆç«¯çª—å£å…³é—­åï¼Œæ§åˆ¶è¿›ç¨‹æ”¶åˆ°SIGHUPä¿¡å·é€€å‡ºï¼Œä¼šå¯¼è‡´è¯¥ä¼šè¯æœŸå†…å…¶ä»–è¿›ç¨‹é€€å‡ºã€‚</p>
<p><strong>è¿™é‡Œæˆ‘è®¤ä¸ºæˆ‘ä»¬çš„è¿›ç¨‹è¢«æ€æ‰ä¹Ÿå°±æ˜¯å› ä¸ºsshä¸æœåŠ¡å™¨ä¹‹é—´çš„é€šä¿¡æ–­æ‰äº†ï¼Œè¿™ä¸ªé€šä¿¡æ–­æ‰ä¹‹ålinuxç¨‹åºå°±é»˜è®¤å°†è¯¥è¿æ¥ä¸‹çš„æ‰€æœ‰è¿›ç¨‹éƒ½æ€æ‰</strong></p>
<h2 id="3ã€è§£å†³æ–¹æ¡ˆ"><a href="#3ã€è§£å†³æ–¹æ¡ˆ" class="headerlink" title="3ã€è§£å†³æ–¹æ¡ˆ"></a>3ã€è§£å†³æ–¹æ¡ˆ</h2><p>é’ˆå¯¹ä¸Šé¢çš„é—®é¢˜ï¼Œä¸Šé¢çš„å‚è€ƒé“¾æ¥ä¸­ä¹Ÿæœ‰è®²è§£ï¼Œåœ¨æ­¤è¿›è¡Œä¸€ä¸ªç®€å•çš„æ•´ç†ã€‚</p>
<p>è¿™é‡Œä¸»è¦æœ‰ä¸‰ä¸ªæ–¹æ¡ˆï¼Œä¸€ä¸ªæ˜¯ä½¿ç”¨nohupæŒ‡ä»¤ï¼Œä¸€ä¸ªæ˜¯ä½¿ç”¨screenæŒ‡ä»¤ï¼Œæœ€åä¸€ä¸ªæ˜¯screençš„å‡çº§ç‰ˆbyobuã€‚çœ‹å®Œè¿™ä¸‰ä¸ªæŒ‡ä»¤ä¹‹åå…¶å®<strong>æˆ‘æ›´å€¾å‘äºä½¿ç”¨byobuæŒ‡ä»¤ï¼Œå› ä¸ºbyobuæŒ‡ä»¤æ›´åŠ çš„å¼ºå¤§,æ˜¯screençš„å‡çº§ç‰ˆæœ¬ï¼Œå¹¶ä¸”ç•Œé¢ä¹Ÿæ¯”è¾ƒå‹å¥½ã€‚</strong></p>
<h3 id="nohupå‘½ä»¤"><a href="#nohupå‘½ä»¤" class="headerlink" title="nohupå‘½ä»¤"></a>nohupå‘½ä»¤</h3><p>nohup å‘½ä»¤</p>
<p>ç”¨é€”ï¼šä¸æŒ‚æ–­åœ°è¿è¡Œå‘½ä»¤ã€‚</p>
<p>è¯­æ³•ï¼šnohup Command [ Arg â€¦ ] [ã€€&amp; ]</p>
<p><strong>æè¿°ï¼šnohup å‘½ä»¤è¿è¡Œç”± Command å‚æ•°å’Œä»»ä½•ç›¸å…³çš„ Arg å‚æ•°æŒ‡å®šçš„å‘½ä»¤ï¼Œå¿½ç•¥æ‰€æœ‰æŒ‚æ–­(SIGHUP)ä¿¡å·ã€‚åœ¨æ³¨é”€åä½¿ç”¨ nohup å‘½ä»¤è¿è¡Œåå°ä¸­çš„ç¨‹åºã€‚è¦è¿è¡Œåå°ä¸­çš„ nohup å‘½ä»¤ï¼Œæ·»åŠ  &amp; ( è¡¨ç¤ºâ€andâ€çš„ç¬¦å·)åˆ°å‘½ä»¤çš„å°¾éƒ¨ã€‚</strong></p>
<p>æ— è®ºæ˜¯å¦å°† nohup å‘½ä»¤çš„è¾“å‡ºé‡å®šå‘åˆ°ç»ˆç«¯ï¼Œè¾“å‡ºéƒ½å°†é™„åŠ åˆ°å½“å‰ç›®å½•çš„ nohup.out æ–‡ä»¶ä¸­ã€‚å¦‚æœå½“å‰ç›®å½•çš„ nohup.out æ–‡ä»¶ä¸å¯å†™ï¼Œè¾“å‡ºé‡å®šå‘åˆ° $HOME/nohup.out æ–‡ä»¶ä¸­ã€‚å¦‚æœæ²¡æœ‰æ–‡ä»¶èƒ½åˆ›å»ºæˆ–æ‰“å¼€ä»¥ç”¨äºè¿½åŠ ï¼Œé‚£ä¹ˆ Command å‚æ•°æŒ‡å®šçš„å‘½ä»¤ä¸å¯è°ƒç”¨ã€‚å¦‚æœæ ‡å‡†é”™è¯¯æ˜¯ä¸€ä¸ªç»ˆç«¯ï¼Œé‚£ä¹ˆæŠŠæŒ‡å®šçš„å‘½ä»¤å†™ç»™æ ‡å‡†é”™è¯¯çš„æ‰€æœ‰è¾“å‡ºä½œä¸ºæ ‡å‡†è¾“å‡ºé‡å®šå‘åˆ°ç›¸åŒçš„æ–‡ä»¶æè¿°ç¬¦ã€‚</p>
<h3 id="nohupçš„ç®€å•ä½¿ç”¨"><a href="#nohupçš„ç®€å•ä½¿ç”¨" class="headerlink" title="nohupçš„ç®€å•ä½¿ç”¨"></a>nohupçš„ç®€å•ä½¿ç”¨</h3><p>åœ¨æ‰§è¡Œå‘½ä»¤æ—¶åœ¨å‘½ä»¤å‰é¢åŠ ä¸Šnohupï¼Œç„¶åå›è½¦å¼€å§‹è¿è¡Œã€‚</p>
<p><strong>è¿™æ—¶ä½ ä¼šå‘ç°è¯¥æœ‰çš„è¾“å‡ºå…¶å®å¹¶æ²¡æœ‰è¾“å‡ºå‡ºæ¥ï¼Œè¿™ä¸ªæ—¶å€™ä¸è¦æ–¹ï¼Œè¿™æ˜¯å› ä¸ºnohupå‘½ä»¤å°†ä½ çš„æ‰€æœ‰è¾“å‡ºéƒ½è¾“å‡ºåˆ°äº†å½“å‰æ–‡ä»¶å¤¹ä¸‹çš„nohup.outæ–‡ä»¶ä¸­ï¼Œè‡ªå·±å¯ä»¥ä½¿ç”¨vimæŒ‡ä»¤è¿›è¡Œä¸€ä¸ªæŸ¥çœ‹ã€‚</strong></p>
<p>nohupå‘½ä»¤åŠå…¶è¾“å‡ºæ–‡ä»¶ ã€€ã€€</p>
<p>nohupå‘½ä»¤ï¼šå¦‚æœä½ æ­£åœ¨è¿è¡Œä¸€ä¸ªè¿›ç¨‹ï¼Œè€Œä¸”ä½ è§‰å¾—åœ¨é€€å‡ºå¸æˆ·æ—¶è¯¥è¿›ç¨‹è¿˜ä¸ä¼šç»“æŸï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨nohupå‘½ä»¤ã€‚è¯¥å‘½ä»¤å¯ä»¥åœ¨ä½ é€€å‡ºå¸æˆ·/å…³é—­ç»ˆç«¯ä¹‹åç»§ç»­è¿è¡Œç›¸åº”çš„è¿›ç¨‹ã€‚nohupå°±æ˜¯ä¸æŒ‚èµ·çš„æ„æ€( n ohang up)ã€‚ ã€€ã€€</p>
<p>è¯¥å‘½ä»¤çš„ä¸€èˆ¬å½¢å¼ä¸ºï¼šnohup command &amp; ã€€ã€€</p>
<p>ä½¿ç”¨nohupå‘½ä»¤æäº¤ä½œä¸š ã€€ã€€</p>
<p>å¦‚æœä½¿ç”¨nohupå‘½ä»¤æäº¤ä½œä¸šï¼Œé‚£ä¹ˆåœ¨ç¼ºçœæƒ…å†µä¸‹è¯¥ä½œä¸šçš„æ‰€æœ‰è¾“å‡ºéƒ½è¢«é‡å®šå‘åˆ°ä¸€ä¸ªåä¸ºnohup.outçš„æ–‡ä»¶ä¸­ï¼Œé™¤éå¦å¤–æŒ‡å®šäº†è¾“å‡ºæ–‡ä»¶ï¼š ã€€ã€€</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">nohup</span> <span class="built_in">command</span> &gt; myout.file 2&gt;&amp;1 &amp;</span><br></pre></td></tr></tbody></table></figure>
<p><strong>ä½¿ç”¨ jobs æŸ¥çœ‹ä»»åŠ¡ã€‚</strong></p>
<p><strong>ä½¿ç”¨ fg %nã€€å…³é—­ã€‚</strong></p>
<h3 id="screenå‘½ä»¤"><a href="#screenå‘½ä»¤" class="headerlink" title="screenå‘½ä»¤"></a>screenå‘½ä»¤</h3><p>ç®€å•æ¥è¯´ï¼ŒScreenæ˜¯ä¸€ä¸ªå¯ä»¥åœ¨å¤šä¸ªè¿›ç¨‹ä¹‹é—´å¤šè·¯å¤ç”¨ä¸€ä¸ªç‰©ç†ç»ˆç«¯çš„çª—å£ç®¡ç†å™¨ã€‚Screenä¸­æœ‰ä¼šè¯çš„æ¦‚å¿µï¼Œç”¨æˆ·å¯ä»¥åœ¨ä¸€ä¸ªscreenä¼šè¯ä¸­åˆ›å»ºå¤šä¸ªscreençª—å£ï¼Œåœ¨æ¯ä¸€ä¸ªscreençª—å£ä¸­å°±åƒæ“ä½œä¸€ä¸ªçœŸå®çš„telnet/SSHè¿æ¥çª—å£é‚£æ ·ã€‚åœ¨screenä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„çª—å£æœ‰è¿™æ ·å‡ ç§æ–¹å¼ï¼š</p>
<p>1ï¼ç›´æ¥åœ¨å‘½ä»¤è¡Œé”®å…¥screenå‘½ä»¤</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">screen</span><br></pre></td></tr></tbody></table></figure>
<p>Screenå°†åˆ›å»ºä¸€ä¸ªæ‰§è¡Œshellçš„å…¨å±çª—å£ã€‚ä½ å¯ä»¥æ‰§è¡Œä»»æ„shellç¨‹åºï¼Œå°±åƒåœ¨sshçª—å£ä¸­é‚£æ ·ã€‚åœ¨è¯¥çª—å£ä¸­é”®å…¥exité€€å‡ºè¯¥çª—å£ï¼Œå¦‚æœè¿™æ˜¯è¯¥screenä¼šè¯çš„å”¯ä¸€çª—å£ï¼Œè¯¥screenä¼šè¯é€€å‡ºï¼Œå¦åˆ™screenè‡ªåŠ¨åˆ‡æ¢åˆ°å‰ä¸€ä¸ªçª—å£ã€‚</p>
<p>2ï¼Screenå‘½ä»¤åè·Ÿä½ è¦æ‰§è¡Œçš„ç¨‹åºã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">screen ã€åé¢è·Ÿä½ æ‰§è¡Œç¨‹åºçš„å‘½ä»¤ã€‘</span><br></pre></td></tr></tbody></table></figure>
<p>Screenåˆ›å»ºä¸€ä¸ªæ‰§è¡Œ<code>vi test.c</code>çš„å•çª—å£ä¼šè¯ï¼Œé€€å‡ºviå°†é€€å‡ºè¯¥çª—å£/ä¼šè¯ã€‚</p>
<p>3ï¼ä»¥ä¸Šä¸¤ç§æ–¹å¼éƒ½åˆ›å»ºæ–°çš„screenä¼šè¯ã€‚æˆ‘ä»¬è¿˜å¯ä»¥åœ¨ä¸€ä¸ªå·²æœ‰screenä¼šè¯ä¸­åˆ›å»ºæ–°çš„çª—å£ã€‚åœ¨å½“å‰screençª—å£ä¸­é”®å…¥C-a c ï¼Œå³Ctrlé”®+aé”®ï¼Œä¹‹åå†æŒ‰ä¸‹cé”®ï¼Œscreen åœ¨è¯¥ä¼šè¯å†…ç”Ÿæˆä¸€ä¸ªæ–°çš„çª—å£å¹¶åˆ‡æ¢åˆ°è¯¥çª—å£ã€‚</p>
<p>screenè¿˜æœ‰æ›´é«˜çº§çš„åŠŸèƒ½ã€‚ä½ å¯ä»¥ä¸ä¸­æ–­screençª—å£ä¸­ç¨‹åºçš„è¿è¡Œè€Œæš‚æ—¶æ–­å¼€ï¼ˆdetachï¼‰screenä¼šè¯ï¼Œå¹¶åœ¨éšåæ—¶é—´é‡æ–°è¿æ¥ï¼ˆattachï¼‰è¯¥ä¼šè¯ï¼Œé‡æ–°æ§åˆ¶å„çª—å£ä¸­è¿è¡Œçš„ç¨‹åºã€‚</p>
<h3 id="screençš„ç®€å•ä½¿ç”¨"><a href="#screençš„ç®€å•ä½¿ç”¨" class="headerlink" title="screençš„ç®€å•ä½¿ç”¨"></a>screençš„ç®€å•ä½¿ç”¨</h3><p>åœ¨æ‰€è¦æ‰§è¡Œçš„æŒ‡ä»¤å‰æ·»åŠ screen.ç„¶åç¨‹åºçš„è¿è¡Œç­‰ä¸€åˆ‡æ­£å¸¸ã€‚ï¼ˆnohupçš„è¾“å‡ºæ˜¯å®šå‘åˆ°äº†nohup.outæ–‡ä»¶ä¸­ï¼Œç„¶è€ŒscreenæŒ‡ä»¤çš„è¾“å‡ºæ˜¯ç›´æ¥è¾“å‡ºåˆ°äº†å±å¹•ä¸Šçš„ï¼‰</p>
<p>è¿™ä¸ªæ—¶å€™å¦‚æœsshç»ˆç«¯æ–­å¼€äº†è¿æ¥ã€‚æˆ‘ä»¬åªéœ€è¦å†æ¬¡è¿æ¥æœåŠ¡å™¨ç„¶åè¾“å…¥æŒ‡ä»¤</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">screen -<span class="built_in">ls</span></span><br></pre></td></tr></tbody></table></figure>
<p>ç„¶åä¼šå¾—åˆ°ç±»ä¼¼ä¸‹é¢çš„ç»“æœï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">There is a screen on:</span><br><span class="line">    27267.pts-19.TITAN-X    (09/08/2017 03:49:10 PM)    (Detached)</span><br><span class="line">1 Socket <span class="keyword">in</span> /var/run/screen/S-huanghailiang.</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™é‡Œå°±ä¼šæ˜¾ç¤ºsshæ–­å¼€ä¹‹å‰çš„ç¨‹åºï¼Œ<strong><em>å…¶å®æ–­å¼€åç¨‹åºä¾ç„¶åœ¨åå°åœ¨è¿è¡Œ</em></strong>ï¼Œåªæ˜¯æˆ‘ä»¬è¿™ä¸ªæ—¶å€™éœ€è¦å°†å®ƒæ”¾åˆ°å‰å°æ¥è¿è¡Œã€‚è¿™ä¸ªæ—¶å€™æˆ‘ä»¬ä»¬å·²ç»é€šè¿‡screen -lsæŸ¥è¯¢åˆ°äº†çº¿ç¨‹å·æ˜¯27267äº†ï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€è¦æ‰§è¡Œä¸‹é¢çš„æŒ‡ä»¤å³å¯æ¢å¤åˆ°å‰å°äº†ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">screen -r 27267</span><br></pre></td></tr></tbody></table></figure>
<p>å¦‚æœæƒ³æ€æ‰ç»ˆç«¯å¯ä»¥æ‰§è¡Œ</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">kill</span> 27267</span><br></pre></td></tr></tbody></table></figure>
<p>å…¶ä»–æ›´å¤šçš„æŒ‡ä»¤å¯ä»¥é€šè¿‡screen â€”helpæ¥è¿›è¡Œå­¦ä¹ ã€‚</p>
<p>å½“ç„¶screenè¿˜æœ‰æ›´å¤šçš„å¿«æ·é”®å€¼å¾—æˆ‘ä»¬å­¦ä¹ ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡C-a ? å³å…ˆæŒ‰ctrl+aä»¥åå†æŒ‰ï¼Ÿå³å¯æŸ¥çœ‹ã€‚</p>
<p><strong>é€šè¿‡è§‚å¯Ÿæˆ‘ä»¬å¯ä»¥å‘ç°å®ƒå…¶å®æ¢å¤äº†æˆ‘ä»¬sshæ–­å¼€å‰çš„é‚£ä¸ªç•Œé¢ã€‚ï¼ˆæ‰€æœ‰çš„è¾“å‡ºä¹Ÿéƒ½ä¼šåœ¨æ­¤æ˜¾ç¤ºå‡ºæ¥ï¼‰</strong></p>
<h3 id="byobuå‘½ä»¤"><a href="#byobuå‘½ä»¤" class="headerlink" title="byobuå‘½ä»¤"></a>byobuå‘½ä»¤</h3><p>byobuæ„Ÿè§‰å°±æ˜¯screençš„ä¸€ä¸ªå‡çº§ç‰ˆæœ¬ï¼Œç•Œé¢æ¯”è¾ƒå‹å¥½ï¼Œæ“ä½œä¹Ÿæ¯”è¾ƒæ–¹ä¾¿ã€‚ ä¸€èˆ¬Ubuntuç³»ç»Ÿå¼€å§‹çš„æ—¶å€™é»˜è®¤æ²¡æœ‰å®‰è£…ï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨å®‰è£…byobu:</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt install byobu</span><br></pre></td></tr></tbody></table></figure>
<h3 id="byobuçš„åŸºæœ¬ç®€å•æ“ä½œ"><a href="#byobuçš„åŸºæœ¬ç®€å•æ“ä½œ" class="headerlink" title="byobuçš„åŸºæœ¬ç®€å•æ“ä½œ"></a>byobuçš„åŸºæœ¬ç®€å•æ“ä½œ</h3><div class="table-container">
<table>
<thead>
<tr>
<th>æŒ‰é”®</th>
<th>è¯´æ˜</th>
</tr>
</thead>
<tbody>
<tr>
<td>F2</td>
<td>æ–°å»ºçª—å£</td>
</tr>
<tr>
<td>F3</td>
<td>ç§»åŠ¨åˆ°å‰ä¸€ä¸ªçª—å£</td>
</tr>
<tr>
<td>F4</td>
<td>ç§»åŠ¨åˆ°åä¸€ä¸ªçª—å£</td>
</tr>
<tr>
<td>F6</td>
<td>é€€å‡ºbyobuçª—å£</td>
</tr>
<tr>
<td>F9</td>
<td>æ‰“å¼€byobuèœå•ï¼ŒæŸ¥çœ‹å¸®åŠ©ä¿¡æ¯çš„é…ç½®ä¿¡æ¯</td>
</tr>
</tbody>
</table>
</div>
<p>å…³é—­å½“å‰çª—å£å…¶å®Ctrl+Då°±å¯ä»¥å®Œæˆ</p>
<p>å‰©ä½™æ“ä½œæˆ‘ä»¬å¯ä»¥F9æŸ¥çœ‹byobuçš„å¸®åŠ©å³å¯ã€‚</p>
<p>å¦‚æœæˆ‘ä»¬æƒ³è¦ä¸€ç™»é™†å°±æ˜¾ç¤ºbyobuç•Œé¢çš„è¯ï¼Œå¯ä»¥ä½¿ç”¨æŒ‡ä»¤</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">byobu-enable</span><br></pre></td></tr></tbody></table></figure>
<p>å¦‚æœæƒ³å–æ¶ˆä¸€ç™»é™†å°±æ˜¾ç¤ºbyobuç•Œé¢å¯ä»¥æ˜¯ç”¨æŒ‡ä»¤</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">byobu-disable</span><br></pre></td></tr></tbody></table></figure>
<h2 id="4ã€æ³¨ï¼ˆä¸ªäººç†è§£ï¼‰ï¼š"><a href="#4ã€æ³¨ï¼ˆä¸ªäººç†è§£ï¼‰ï¼š" class="headerlink" title="4ã€æ³¨ï¼ˆä¸ªäººç†è§£ï¼‰ï¼š"></a>4ã€æ³¨ï¼ˆä¸ªäººç†è§£ï¼‰ï¼š</h2><p><strong>nohup</strong>è™½ç„¶å¯ä»¥æŠŠæ‰€æœ‰çš„è¾“å‡ºéƒ½å†™å…¥åˆ°nohup.outä¸­é—´æ¥ï¼Œä½†æ˜¯åœ¨é¢å¯¹éœ€è¦äººæœºäº¤äº’çš„æ—¶å€™å®ƒå°±ä¸èƒ½æ­£å¸¸ä½¿ç”¨äº†ã€‚å¦å¤–åœ¨æˆ‘åšæµ‹è¯•çš„æ—¶å€™ï¼Œä¸€æ—¦sshæ–­å¼€ï¼Œè™½ç„¶ç¨‹åºè¿˜åœ¨åå°è¿è¡Œï¼Œä½†æ˜¯å¥½åƒå¹¶ä¸ä¼šå†æŠŠè¾“å‡ºå†™å…¥åˆ°nohup.outæ–‡ä»¶ä¸­ï¼Œè¿™ä¸€ç‚¹å¾ˆä¸å¥½ã€‚</p>
<p><strong>screen</strong>ç›¸æ¯”ä¹‹ä¸‹å°±å¼ºå¤§äº†å¾ˆå¤šï¼Œä¸ä»…å¯ä»¥æ»¡è¶³äººæœºäº¤äº’ï¼Œè€Œä¸”è¿˜å¯ä»¥å°†æ‰€æœ‰çš„è¾“å‡ºéƒ½å†æ¬¡å±•ç¤ºå‡ºæ¥ï¼Œæ–¹ä¾¿æˆ‘ä»¬æŸ¥çœ‹ã€‚æˆ‘å¯¹screençš„ç†è§£æ˜¯ï¼Œå…¶å®å®ƒæ˜¯ä¸€ä¸ªè™šæ‹Ÿçš„ç»ˆç«¯ï¼Œæˆ‘ä»¬è¿è¡Œçš„æ—¶å€™screenæŒ‡ä»¤å°±ä¸ºæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªè™šæ‹Ÿçš„ç»ˆç«¯ï¼Œæ‰€ä»¥æˆ‘ä»¬å†æ¬¡è¿æ¥åæˆ‘ä»¬æ‰“å¼€çš„è¿˜æ˜¯è¿™ä¸ªè™šæ‹Ÿçš„ç»ˆç«¯ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥æ›´å¥½çš„è¿›è¡Œæ“ä½œï¼Œè€Œä¸”screenæ”¯æŒå¼€å¾ˆå¤šä¸ªç»ˆç«¯ã€‚</p>
<p><strong>byobu</strong>ç›¸æ¯”ä¹‹ä¸‹ç»§æ‰¿äº†screençš„æ‰€æœ‰ä¼˜ç‚¹ï¼Œå¹¶ä¸”æ‹¥æœ‰äº†æ›´åŠ æ–¹ä¾¿å¿«æ·çš„æ“ä½œç•Œé¢ï¼ŒåŒæ—¶åœ¨ç•Œé¢ä¸‹æ–¹è¿˜èƒ½å¾ˆå¥½çš„æ˜¾ç¤ºç›®å‰è®¡ç®—æœºçš„ç¡¬ä»¶ä½¿ç”¨æƒ…å†µï¼Œååˆ†æ–¹ä¾¿ã€‚</p>
<p>å®ƒä»¬ä¸‰è€…çš„å…±æ€§æˆ‘è®¤ä¸ºéƒ½å·²ç»ä¸å—SIGHUPä¿¡å·çš„å½±å“äº†ï¼Œæ‰€ä»¥å³ä½¿æ–­æ‰äº†sshç¨‹åºä¾æ—§ä¼šè¿è¡Œã€‚</p>
<p>è¿˜æœ‰ä¸€ä¸ªtmuxï¼Œæ¨ètmuxï¼Œæˆ‘ä¹Ÿå·²ç»å†™äº†æ•™ç¨‹</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDAç¼–ç¨‹å®è·µï¼šLLTMåŠ é€Ÿä¼˜åŒ–å®è·µ</title>
    <url>/2023/12/12/CUDA/CUDA%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5%EF%BC%9ALLTM%E5%8A%A0%E9%80%9F%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</url>
    <content><![CDATA[<p>Githubï¼š<a href="https://github.com/Kedreamix/pytorch-cppcuda-tutorial">https://github.com/Kedreamix/pytorch-cppcuda-tutorial</a></p>
<p>å‰é¦ˆçŸ¥è¯†ï¼š<a href="https://zhuanlan.zhihu.com/p/671704557">Kedreamixï¼šCUDAç¼–ç¨‹å­¦ä¹ ï¼šè‡ªå®šä¹‰Pytorch+cpp/cuda extension</a></p>
<p>æ¥ä¸‹æ¥å†è¿›è¡Œä¸€ä¸ªå®è·µï¼Œæ ¹æ®pytorchå®˜ç½‘çš„ä¸€ä¸ª<a href="https://pytorch.org/tutorials/advanced/cpp_extension.html#">åº”ç”¨æ‰©å±•æ–‡æ¡£</a>æ¥ä¸€èµ·æ¥å®ç°è¿™ä¸ªLLTMçš„ç¥ç»ç½‘ç»œçš„å®ç°ï¼Œè¿™æ˜¯å®˜æ–¹å¯¹åº”çš„ä»£ç  <a href="https://github.com/pytorch/extension-cppã€‚">https://github.com/pytorch/extension-cppã€‚</a></p>
<p>é¦–å…ˆä»‹ç»ä¸€ä¸‹ï¼Œå‡è®¾æœ‰ä¸€ç§æ–°çš„å¾ªç¯å•å…ƒï¼Œè¿™ä¸ªå¾ªç¯å•å…ƒç±»ä¼¼äº LSTMï¼Œä½†ä¸åŒä¹‹å¤„åœ¨äºå®ƒæ²¡æœ‰é—å¿˜é—¨ï¼Œå¹¶ä½¿ç”¨æŒ‡æ•°çº¿æ€§å•å…ƒ (<a href="https://so.csdn.net/so/search?q=ELU&amp;spm=1001.2101.3001.7020">ELU</a>) ä½œä¸ºå…¶å†…éƒ¨æ¿€æ´»å‡½æ•°ã€‚å› ä¸ºè¿™ä¸ªå•å…ƒèƒ½å¤Ÿè®°å¿†å¾ˆä¹…ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸º LLTMï¼Œæˆ– Long-Long-Term-Memory å•å…ƒã€‚</p>
<p>LLTM ä¸æ™®é€š LSTM çš„ä¸¤ç§ä¸åŒä¹‹å¤„éå¸¸é‡è¦ï¼Œä»¥è‡³äºæˆ‘ä»¬æ— æ³•ä¸ºæˆ‘ä»¬çš„ç›®çš„é…ç½® PyTorch çš„ LSTM ç®—å­ï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰ç®—å­ã€‚ç¬¬ä¸€ä¸ªä¹Ÿæ˜¯æœ€ç®€å•çš„æ–¹æ³•â€”â€”å¯èƒ½åœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½æ˜¯å¾ˆå¥½çš„ç¬¬ä¸€æ­¥â€”â€”æ˜¯ç”¨ Python åœ¨æ™®é€šçš„ PyTorch ä¸­å®ç°æˆ‘ä»¬æƒ³è¦çš„åŠŸèƒ½ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦ç»§æ‰¿ torch.nn.Module å¹¶å®ç° LLTM çš„ forwardã€‚</p>
<h2 id="Pytorchæ™®é€šå®ç°"><a href="#Pytorchæ™®é€šå®ç°" class="headerlink" title="Pytorchæ™®é€šå®ç°"></a>Pytorchæ™®é€šå®ç°</h2><p>æ¥ä¸‹æ¥æˆ‘ä»¬å°±ç”¨æ™®é€šçš„pytorchå¯¹å…¶è¿›è¡Œå®ç°LLTMï¼Œå…·ä½“ä»£ç å¦‚ä¸‹</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LLTM</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_features, state_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(LLTM, self).__init__()</span><br><span class="line">        self.input_features = input_features</span><br><span class="line">        self.state_size = state_size</span><br><span class="line">        <span class="comment"># 3 * state_size for input gate, output gate and candidate cell gate.</span></span><br><span class="line">        <span class="comment"># input_features + state_size because we will multiply with [input, h].</span></span><br><span class="line">        self.weights = torch.nn.Parameter(</span><br><span class="line">            torch.empty(<span class="number">3</span> * state_size, input_features + state_size))</span><br><span class="line">        self.bias = torch.nn.Parameter(torch.empty(<span class="number">3</span> * state_size))</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        é‡ç½®æ¨¡å‹å‚æ•°çš„æ–¹æ³•ã€‚</span></span><br><span class="line"><span class="string">        åˆå§‹åŒ–æƒé‡å’Œåå·®çš„å€¼ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒå’Œæ ‡å‡†å·®è¿›è¡Œåˆå§‹åŒ–ã€‚</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        stdv = <span class="number">1.0</span> / math.sqrt(self.state_size)</span><br><span class="line">        <span class="keyword">for</span> weight <span class="keyword">in</span> self.parameters():</span><br><span class="line">            weight.data.uniform_(-stdv, +stdv)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, state</span>):</span><br><span class="line">        old_h, old_cell = state</span><br><span class="line">        X = torch.cat([old_h, <span class="built_in">input</span>], dim=<span class="number">1</span>)</span><br><span class="line">        gate_weights = F.linear(X, self.weights, self.bias)</span><br><span class="line">        gates = gate_weights.chunk(<span class="number">3</span>, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        input_gate = torch.sigmoid(gates[<span class="number">0</span>])</span><br><span class="line">        output_gate = torch.sigmoid(gates[<span class="number">1</span>])</span><br><span class="line">        candidate_cell = F.elu(gates[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        new_cell = old_cell + candidate_cell * input_gate</span><br><span class="line">        new_h = torch.tanh(new_cell) * output_gate</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> new_h, new_cell</span><br></pre></td></tr></tbody></table></figure>
<h2 id="Pythonæ‰©å±•å®ç°"><a href="#Pythonæ‰©å±•å®ç°" class="headerlink" title="Pythonæ‰©å±•å®ç°"></a>Pythonæ‰©å±•å®ç°</h2><p>æˆ‘ä»¬åœ¨å¤§å¤šæ•°çš„æ—¶å€™ï¼Œéƒ½æ˜¯ç”¨ä¸Šè¿°çš„æ–¹æ³•è¿›è¡Œå¯¹Pytorchè¿›è¡Œæ‰©å±•ï¼Œå› ä¸º PyTorch å¯¹ CPU å’Œ GPU çš„æ“ä½œå®ç°äº†é«˜åº¦ä¼˜åŒ–ï¼Œå¹¶ç”± <a href="https://developer.nvidia.com/cudnn">NVIDIA cuDNN</a>ã€<a href="https://software.intel.com/en-us/mkl">Intel MKL</a> æˆ– <a href="https://github.com/Maratyszcza/NNPACK">NNPACK</a> ç­‰åº“æä¾›æ”¯æŒã€‚å› æ­¤ï¼Œé€šå¸¸æƒ…å†µä¸‹ï¼Œä¸Šè¿°çš„PyTorchä»£ç å·²ç»è¶³å¤Ÿå¿«é€Ÿã€‚</p>
<p>ç„¶è€Œï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¿˜æœ‰è¿›ä¸€æ­¥æå‡æ€§èƒ½çš„ç©ºé—´ã€‚è¿™æ˜¯å› ä¸ºPyTorchå¯èƒ½ä¸äº†è§£æˆ‘ä»¬å®ç°çš„ç‰¹å®šç®—æ³•ï¼Œå®ƒåªçŸ¥é“æˆ‘ä»¬ä½¿ç”¨çš„å„ç§æ“ä½œã€‚å› æ­¤ï¼Œå®ƒå¯èƒ½ä¼šé€ä¸ªæ‰§è¡Œè¿™äº›æ“ä½œçš„å†…æ ¸ï¼ˆå¯èƒ½æ¶‰åŠå¯åŠ¨CUDAå†…æ ¸ï¼‰ï¼Œè¿™ä¼šå¯¼è‡´ç´¯ç§¯çš„å¼€é”€å˜å¾—å¾ˆå¤§ã€‚æ­¤å¤–ï¼ŒPythonæœ¬èº«ä¹Ÿå­˜åœ¨ä¸€äº›é€Ÿåº¦é™åˆ¶ã€‚</p>
<p>å› æ­¤ï¼Œä¸€ç§æ˜æ˜¾çš„åŠ é€Ÿæ–¹æ³•æ˜¯ä½¿ç”¨C++ï¼ˆæˆ–CUDAï¼‰å¯¹éƒ¨åˆ†ä»£ç è¿›è¡Œé‡å†™ï¼Œå¹¶å°†ç‰¹å®šçš„æ“ä½œç»„åˆèµ·æ¥ã€‚ç»„åˆæ„å‘³ç€å°†è®¸å¤šå‡½æ•°çš„å®ç°åˆå¹¶ä¸ºä¸€ä¸ªå‡½æ•°ï¼Œè¿™æ ·å¯ä»¥å¯åŠ¨è¾ƒå°‘çš„å†…æ ¸ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡æé«˜å…¨å±€æ•°æ®æµçš„å¯è§æ€§æ¥æ‰§è¡Œå…¶ä»–ä¼˜åŒ–ã€‚</p>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†åˆ†åˆ«ä½¿ç”¨<strong>Pythonï¼ŒC++ï¼ŒPytorch</strong>æ‰©å±•æ¥å®ç°LLTMï¼ˆLong Long-Term Memoryï¼‰çš„ç»„åˆç‰ˆæœ¬ã€‚æˆ‘ä»¬å°†ä»ä½¿ç”¨çº¯C++ç¼–å†™å®ƒå¼€å§‹ï¼Œä½¿ç”¨<a href="https://github.com/zdevito/ATen">ATen</a>åº“ï¼Œè¯¥åº“ä¸ºPyTorchçš„å¤§éƒ¨åˆ†åç«¯æä¾›æ”¯æŒã€‚ç„¶åï¼Œæˆ‘ä»¬å°†é€šè¿‡å°†æ¨¡å‹çš„éƒ¨åˆ†ç§»åŠ¨åˆ°CUDAå†…æ ¸ä¸­ï¼Œä»¥åˆ©ç”¨GPUæä¾›çš„å¤§è§„æ¨¡å¹¶è¡Œæ€§ï¼Œè¿›ä¸€æ­¥æé«˜é€Ÿåº¦ã€‚</p>
<p>åœ¨ä¸Šè¿°çš„ä»£ç ä¸­ï¼Œä¸ºäº†åç»­å¯¹å†™C++æ‰©å±•æœ‰ä¸€ä¸ªæ›´å¥½çš„ç†è§£ï¼Œæ‰€ä»¥å†åŠ ä¸Šä¸€éƒ¨åˆ†é¦–å…ˆå®ç°åå‘ä¼ æ’­çš„ä»£ç ã€‚æ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰‹å†™æˆ‘ä»¬å¯¹åº”å‡½æ•°å‡ºç°çš„å¾®åˆ†ï¼Œè¿™é‡Œé¢æˆ‘ä»¬å°±éœ€è¦å…ˆè®¡ç®—åŸºç¡€å‡½æ•°çš„å¾®åˆ†å‡½æ•°ï¼Œåˆ†åˆ«æ˜¯çš„<code>d_sigmoid</code>ï¼Œ<code>d_tanh</code>å’Œ<code>d_elu</code>ï¼Œåç»­å¯ä»¥å¯¹å…¶è¿›è¡Œå¤ç”¨ã€‚</p>
<hr>
<p>åœ¨è¿™ä¸€éƒ¨åˆ†çš„ä»£ç ä¸­ï¼Œç»“æœå®é™…ä¸Šçš„æ–¹å¼å’Œä¸Šé¢ä»£ç æ˜¯ä¸€æ ·çš„ï¼Œä¸»è¦æ˜¯å°±æ˜¯ç‹¬ç«‹å®ç°äº†ä¸€ä¸‹å¯¹åº”çš„åå‘ä¼ æ’­éƒ¨åˆ†ï¼Œæ–¹ä¾¿åç»­è¿›è¡Œè®­ç»ƒçš„åå‘ä¼ æ’­çš„CUDAç¼–å†™ï¼Œå¹¶ä¸”è®©å¤§å®¶ä¹Ÿæ›´åŠ ç†è§£ä¸€ä¸‹å¯¹åº”åº•å±‚çš„C++å’ŒCUDAåå‘ä¼ æ’­çš„ä»£ç çš„ç¼–å†™åŸç†ã€‚</p>
<p>åœ¨å‰é¢æˆ‘ä»¬æœ‰ä»‹ç»è¿‡<code>ctx</code>å¯ä»¥ä¿å­˜æˆ‘ä»¬åå‘ä¼ æ’­éœ€è¦çš„å‚æ•°ï¼Œæ‰€ä»¥è¿™é‡Œä½¿ç”¨äº†<code>ctx.save_for_backward(X, weights, input_gate, output_gate, old_cell,new_cell, candidate_cell, gate_weights)</code>ï¼Œæœ€åè¿”å›äº†ä¸¤ä¸ªå€¼ï¼Œåˆ†åˆ«æ˜¯<code>new_h, new_cell</code>ï¼Œå¹¶ä¸”è¿™ä¸¤éƒ¨åˆ†æˆ‘ä»¬ä¹Ÿéœ€è¦åœ¨åå‘ä¼ æ’­ä¸­ä¼ å…¥ä¸¤ä¸ªå‚æ•°è¿›è¡Œæ±‚å¾®åˆ†ï¼Œåœ¨<code>forward</code>å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬æœ‰å››ä¸ªå‚æ•°<code>input, weights, bias, old_h, old_cell</code>ï¼Œæ‰€ä»¥åå‘ä¼ æ’­çš„æœ€åè¿”å›å€¼ä¹Ÿåˆ†åˆ«æ˜¯<code>d_input, d_weights, d_bias, d_old_h, d_old_cell</code>è¿›è¡Œä¸€ä¸€å¯¹åº”ã€‚</p>
<h3 id="åŸºç¡€å‡½æ•°"><a href="#åŸºç¡€å‡½æ•°" class="headerlink" title="åŸºç¡€å‡½æ•°"></a>åŸºç¡€å‡½æ•°</h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">d_sigmoid</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    è®¡ç®—sigmoidå‡½æ•°çš„å¯¼æ•°</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    å‚æ•°:</span></span><br><span class="line"><span class="string">    z (tensor): è¾“å…¥å¼ é‡</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    è¿”å›å€¼:</span></span><br><span class="line"><span class="string">    d_sigmoid (tensor): sigmoidå‡½æ•°çš„å¯¼æ•°å¼ é‡</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    s = torch.sigmoid(z)</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1</span> - s) * s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">d_tanh</span>(<span class="params">z</span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    è®¡ç®—tanhå‡½æ•°çš„å¯¼æ•°</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    å‚æ•°:</span></span><br><span class="line"><span class="string">    z (tensor): è¾“å…¥å¼ é‡</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    è¿”å›å€¼:</span></span><br><span class="line"><span class="string">    d_tanh (tensor): tanhå‡½æ•°çš„å¯¼æ•°å¼ é‡</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    t = torch.tanh(z)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - (t * t)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">d_elu</span>(<span class="params">z, alpha=<span class="number">1.0</span></span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    è®¡ç®—ELUå‡½æ•°çš„å¯¼æ•°</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    å‚æ•°:</span></span><br><span class="line"><span class="string">    z (tensor): è¾“å…¥å¼ é‡</span></span><br><span class="line"><span class="string">    alpha (float): ELUå‡½æ•°çš„alphaå‚æ•°ï¼Œé»˜è®¤ä¸º1.0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    è¿”å›å€¼:</span></span><br><span class="line"><span class="string">    d_elu (tensor): ELUå‡½æ•°çš„å¯¼æ•°å¼ é‡</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    e = z.exp()</span><br><span class="line">    mask = (alpha * (e - <span class="number">1</span>)) &lt; <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> (z &gt; <span class="number">0</span>).type_as(z) + mask.type_as(z) * (alpha * e)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="å‰å‘å’Œåå‘ä¼ æ’­"><a href="#å‰å‘å’Œåå‘ä¼ æ’­" class="headerlink" title="å‰å‘å’Œåå‘ä¼ æ’­"></a>å‰å‘å’Œåå‘ä¼ æ’­</h3><figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰çš„LLTMå‡½æ•°ï¼Œç»§æ‰¿è‡ªtorch.autograd.Functionç±»</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LLTMPythonFunction</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span>, weights, bias, old_h, old_cell</span>):</span><br><span class="line">        X = torch.cat([old_h, <span class="built_in">input</span>], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        gate_weights = F.linear(X, weights, bias)</span><br><span class="line">        gates = gate_weights.chunk(<span class="number">3</span>, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        input_gate = torch.sigmoid(gates[<span class="number">0</span>])</span><br><span class="line">        output_gate = torch.sigmoid(gates[<span class="number">1</span>])</span><br><span class="line">        candidate_cell = F.elu(gates[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        new_cell = old_cell + candidate_cell * input_gate</span><br><span class="line">        new_h = torch.tanh(new_cell) * output_gate</span><br><span class="line"></span><br><span class="line">        ctx.save_for_backward(X, weights, input_gate, output_gate, old_cell,</span><br><span class="line">                            new_cell, candidate_cell, gate_weights)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> new_h, new_cell</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_h, grad_cell</span>):</span><br><span class="line">        <span class="comment"># ä»ä¸Šä¸‹æ–‡ä¸­è·å–ä¿å­˜çš„å˜é‡</span></span><br><span class="line">        X, weights, input_gate, output_gate, old_cell = ctx.saved_variables[:<span class="number">5</span>]</span><br><span class="line">        new_cell, candidate_cell, gate_weights = ctx.saved_variables[<span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line">        d_input = d_weights = d_bias = d_old_h = d_old_cell = <span class="literal">None</span></span><br><span class="line">		</span><br><span class="line">        <span class="comment"># è®¡ç®—å…³äºè¾“å‡ºé—¨å’Œ tanh(new_cell) çš„æ¢¯åº¦</span></span><br><span class="line">        d_output_gate = torch.tanh(new_cell) * grad_h</span><br><span class="line">        d_tanh_new_cell = output_gate * grad_h</span><br><span class="line">        d_new_cell = d_tanh(new_cell) * d_tanh_new_cell + grad_cell</span><br><span class="line"></span><br><span class="line">        d_old_cell = d_new_cell</span><br><span class="line">        d_candidate_cell = input_gate * d_new_cell</span><br><span class="line">        d_input_gate = candidate_cell * d_new_cell</span><br><span class="line">		</span><br><span class="line">        <span class="comment"># å°†é—¨æ§æƒé‡åˆ†å‰²æˆè¾“å…¥é—¨ã€è¾“å‡ºé—¨å’Œå€™é€‰ç»†èƒçŠ¶æ€çš„æ¢¯åº¦</span></span><br><span class="line">        gates = gate_weights.chunk(<span class="number">3</span>, dim=<span class="number">1</span>)</span><br><span class="line">        d_input_gate *= d_sigmoid(gates[<span class="number">0</span>])</span><br><span class="line">        d_output_gate *= d_sigmoid(gates[<span class="number">1</span>])</span><br><span class="line">        d_candidate_cell *= d_elu(gates[<span class="number">2</span>])</span><br><span class="line">		</span><br><span class="line">        <span class="comment"># æ‹¼æ¥ä¸‰ä¸ªé—¨çš„æ¢¯åº¦</span></span><br><span class="line">        d_gates = torch.cat(</span><br><span class="line">        [d_input_gate, d_output_gate, d_candidate_cell], dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># å¦‚æœéœ€è¦è®¡ç®—å¯¹æƒé‡çš„æ¢¯åº¦</span></span><br><span class="line">        <span class="keyword">if</span> ctx.needs_input_grad[<span class="number">1</span>]:</span><br><span class="line">            d_weights = d_gates.t().mm(X)</span><br><span class="line">        <span class="comment"># å¦‚æœéœ€è¦è®¡ç®—å¯¹åç½®çš„æ¢¯åº¦</span></span><br><span class="line">        <span class="keyword">if</span> ctx.needs_input_grad[<span class="number">2</span>]:</span><br><span class="line">            d_bias = d_gates.<span class="built_in">sum</span>(dim=<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># å¦‚æœéœ€è¦è®¡ç®—å¯¹ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„éšè—çŠ¶æ€å’Œè¾“å…¥çš„æ¢¯åº¦</span></span><br><span class="line">        <span class="keyword">if</span> ctx.needs_input_grad[<span class="number">3</span>] <span class="keyword">or</span> ctx.needs_input_grad[<span class="number">4</span>]:</span><br><span class="line">            d_X = d_gates.mm(weights)</span><br><span class="line">            state_size = grad_h.shape[<span class="number">1</span>]</span><br><span class="line">            d_old_h, d_input = d_X[:, :state_size], d_X[:, state_size:]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> d_input, d_weights, d_bias, d_old_h, d_old_cell</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LLTM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_features, state_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(LLTMPython, self).__init__()</span><br><span class="line">        self.input_features = input_features</span><br><span class="line">        self.state_size = state_size</span><br><span class="line">        self.weights = nn.Parameter(</span><br><span class="line">            torch.Tensor(<span class="number">3</span> * state_size, input_features + state_size))</span><br><span class="line">        self.bias = nn.Parameter(torch.Tensor(<span class="number">1</span>, <span class="number">3</span> * state_size))</span><br><span class="line">        self.reset_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        stdv = <span class="number">1.0</span> / math.sqrt(self.state_size)</span><br><span class="line">        <span class="keyword">for</span> weight <span class="keyword">in</span> self.parameters():</span><br><span class="line">            weight.data.uniform_(-stdv, +stdv)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span>, state</span>):</span><br><span class="line">        <span class="keyword">return</span> LLTMPythonFunction.apply(<span class="built_in">input</span>, self.weights, self.bias, *state)</span><br></pre></td></tr></tbody></table></figure>
<h3 id="æ—¶é—´æ•ˆç‡æ¯”è¾ƒ"><a href="#æ—¶é—´æ•ˆç‡æ¯”è¾ƒ" class="headerlink" title="æ—¶é—´æ•ˆç‡æ¯”è¾ƒ"></a>æ—¶é—´æ•ˆç‡æ¯”è¾ƒ</h3><p>å®ç°å®Œæˆä»¥åå¯ä»¥ç®€å•è¿›è¡Œä¸€ä¸‹æµ‹è¯•ä¸¤è€…<code>forward</code>å’Œ<code>backward</code>çš„æ—¶é—´ï¼Œæ¯”è¾ƒä¸€ä¸‹ä½¿ç”¨Pytorchçš„è‡ªåŠ¨æ±‚å¯¼æ¯”è¾ƒå¿«ï¼Œè¿˜æ˜¯æˆ‘ä»¬è‡ªå·±ç‹¬ç«‹ç¼–å†™ä¸€ä¸ªå‰å‘åå‘ä¼ æ’­çš„å‡½æ•°æ¯”è¾ƒå¿«ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">cuda_device = torch.device(<span class="string">"cuda"</span>)  <span class="comment"># device object representing GPU</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">input_features = <span class="number">32</span></span><br><span class="line">state_size = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">X = torch.randn(batch_size, input_features, device=cuda_device, dtype=torch.float32)</span><br><span class="line">h = torch.randn(batch_size, state_size, device=cuda_device, dtype=torch.float32)</span><br><span class="line">C = torch.randn(batch_size, state_size, device=cuda_device, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">rnn = LLTMPython(input_features, state_size).to(cuda_device)</span><br><span class="line"></span><br><span class="line">forward = <span class="number">0</span></span><br><span class="line">backward = <span class="number">0</span></span><br><span class="line">n = <span class="number">100</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    start = time.time()</span><br><span class="line">    new_h, new_C = rnn(X, (h, C))</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    forward += time.time() - start</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    (new_h.<span class="built_in">sum</span>() + new_C.<span class="built_in">sum</span>()).backward()</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    backward += time.time() - start</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Forward: {:.10f} s | Backward {:.10f} s'</span>.<span class="built_in">format</span>(forward / n, backward  / n))</span><br><span class="line"></span><br><span class="line">rnn = LLTM(input_features, state_size).to(cuda_device)</span><br><span class="line"></span><br><span class="line">forward = <span class="number">0</span></span><br><span class="line">backward = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">    start = time.time()</span><br><span class="line">    new_h, new_C = rnn(X, (h, C))</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    forward += time.time() - start</span><br><span class="line"></span><br><span class="line">    start = time.time()</span><br><span class="line">    (new_h.<span class="built_in">sum</span>() + new_C.<span class="built_in">sum</span>()).backward()</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    backward += time.time() - start</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">'Forward: {:.10f} s | Backward {:.10f} s'</span>.<span class="built_in">format</span>(forward / n, backward  / n))</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Forward: 0.0012168598 s | Backward 0.0008872311 s</span><br><span class="line">Forward: 0.0002657304 s | Backward 0.0004498205 s</span><br></pre></td></tr></tbody></table></figure>
<p>ä»å‰å‘å’Œåå‘çš„æ—¶é—´æ¯”è¾ƒæ¥çœ‹ï¼Œæˆ‘ä»¬çš„è‡ªå®ç°æ–¹æ³•åœ¨æ€§èƒ½ä¸Šè¡¨ç°è¾ƒå·®ï¼Œç›¸è¾ƒäºPyTorchçš„é»˜è®¤è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ã€‚å°½ç®¡å‰å‘ä¼ æ’­é€Ÿåº¦çš„æå‡å¹¶ä¸æ˜æ˜¾ï¼Œè¿™å¯èƒ½è¡¨æ˜PyTorchçš„è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶åœ¨æŸäº›æ–¹é¢ç¡®å®å…·æœ‰å¼ºå¤§çš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬çš„æ‰‹åŠ¨å®ç°å¯èƒ½å­˜åœ¨ä¸€äº›æ•ˆç‡æ–¹é¢çš„ä¸è¶³ï¼Œå¯¼è‡´æ€§èƒ½ä¸å¦‚PyTorché»˜è®¤æ–¹å¼é«˜æ•ˆã€‚è™½ç„¶é‡æ–°ç¼–å†™å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ˜¯æå‡è®­ç»ƒé€Ÿåº¦çš„ä¸€ç§å°è¯•ï¼Œä½†æˆ‘ä»¬éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥ç¡®ä¿å…¶æ€§èƒ½ä¸PyTorché»˜è®¤æœºåˆ¶ç›¸åª²ç¾ã€‚åœ¨åå‘ä¼ æ’­æ–¹é¢ï¼Œå¯èƒ½éœ€è¦è€ƒè™‘ä½¿ç”¨C++æ‰©å±•å’ŒCUDAæ‰©å±•æ¥æé«˜æ•ˆç‡ã€‚</p>
<h2 id="C-æ‰©å±•å®ç°"><a href="#C-æ‰©å±•å®ç°" class="headerlink" title="C++æ‰©å±•å®ç°"></a>C++æ‰©å±•å®ç°</h2><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨C++æ‰©å±•æ¥å®ç°LLTMï¼ˆLong Long-Term Memoryï¼‰çš„ç»„åˆç‰ˆæœ¬ã€‚æˆ‘ä»¬å°†ä»ä½¿ç”¨çº¯C++ç¼–å†™å®ƒå¼€å§‹ï¼Œä½¿ç”¨<a href="https://github.com/zdevito/ATen">ATen</a>åº“ï¼Œåœ¨ä»£ç ä¸­è¡¨ç°ä¸º<code>torch/extension.h</code>ï¼Œè¯¥åº“ä¸ºPyTorchçš„å¤§éƒ¨åˆ†åç«¯æä¾›æ”¯æŒã€‚</p>
<blockquote>
<p><strong><torch extension.h=""></torch></strong>æ˜¯ä¸€ç«™å¼å¤´æ–‡ä»¶ï¼ŒåŒ…å«å†™å…¥C++æ‰©å±•æ‰€éœ€çš„æ‰€æœ‰PyTorchæ“ä½œï¼ŒåŒ…æ‹¬ï¼š</p>
<ul>
<li>ATenåº“æ˜¯ç”¨äºå¼ é‡è®¡ç®—çš„ä¸»è¦APIï¼Œ</li>
<li>pybind11ï¼Œæ˜¯ä¸ºC++ä»£ç åˆ›å»ºPythonç»‘å®šçš„æ–¹å¼</li>
<li>ç®¡ç†ATenå’Œpybind11ä¹‹é—´äº¤äº’ç»†èŠ‚çš„å¤´æ–‡ä»¶</li>
</ul>
<p>PyTorchçš„å¼ é‡å’Œå˜é‡æ¥å£æ˜¯ä»ATenåº“è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œå› æ­¤å‡ ä¹å¯ä»¥å°†Pythonå®ç°1:1è½¬æ¢ä¸ºC++ã€‚æ‰€æœ‰è®¡ç®—çš„ä¸»è¦æ•°æ®ç±»å‹å°†æ˜¯torch::Tensorã€‚</p>
</blockquote>
<h3 id="åŸºç¡€å‡½æ•°-1"><a href="#åŸºç¡€å‡½æ•°-1" class="headerlink" title="åŸºç¡€å‡½æ•°"></a>åŸºç¡€å‡½æ•°</h3><p>å¯¹äºC++çš„éƒ¨åˆ†æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å¯¹é‡Œé¢çš„å‡½æ•°è¿›è¡Œé‡å†™ä¸€éï¼Œåˆ©ç”¨C++çš„æ–¹å¼å¯¹æ¥è¿›è¡Œé‡å†™ï¼Œè¿™æ ·è¿›è¡Œè®¡ç®—çš„æ—¶å€™ï¼Œç¨‹åºå°±ä¼šé€šè¿‡C++æ¥è®¡ç®—è€Œä¸æ˜¯Pythonæ¥è®¡ç®—ï¼Œè¿™æ ·å°±æé«˜äº†æ•ˆç‡å’Œé€Ÿåº¦ï¼Œé¦–å…ˆä¸»è¦æ˜¯è®¡ç®—åŸºç¡€å‡½æ•°çš„å¾®åˆ†å‡½æ•°ï¼Œåˆ†åˆ«æ˜¯çš„<code>d_sigmoid</code>ï¼Œ<code>d_tanh</code>å’Œ<code>d_elu</code>ï¼Œä¸»è¦æ˜¯é€šè¿‡C++æ¥è¿›è¡Œç¼–å†™ã€‚PyTorchçš„å¼ é‡å’Œå˜é‡æ¥å£æ˜¯ä»ATenåº“è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œå› æ­¤å‡ ä¹å¯ä»¥å°†Pythonå®ç°1:1è½¬æ¢ä¸ºC++ã€‚æ‰€æœ‰è®¡ç®—çš„ä¸»è¦æ•°æ®ç±»å‹å°†æ˜¯<code>torch::Tensor</code>ã€‚</p>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;torch/extension.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">torch::Tensor <span class="title">d_sigmoid</span><span class="params">(torch::Tensor z)</span> </span>{</span><br><span class="line">  <span class="keyword">auto</span> s = torch::<span class="built_in">sigmoid</span>(z);</span><br><span class="line">  <span class="keyword">return</span> (<span class="number">1</span> - s) * s;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// tanh'(z) = 1 - tanh^2(z)</span></span><br><span class="line"><span class="function">torch::Tensor <span class="title">d_tanh</span><span class="params">(torch::Tensor z)</span> </span>{</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span> - z.<span class="built_in">tanh</span>().<span class="built_in">pow</span>(<span class="number">2</span>);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="comment">// elu'(z) = relu'(z) + { alpha * exp(z) if (alpha * (exp(z) - 1)) &lt; 0, else 0}</span></span><br><span class="line"><span class="function">torch::Tensor <span class="title">d_elu</span><span class="params">(torch::Tensor z, torch::Scalar alpha = <span class="number">1.0</span>)</span> </span>{</span><br><span class="line">  <span class="keyword">auto</span> e = z.<span class="built_in">exp</span>();</span><br><span class="line">  <span class="keyword">auto</span> mask = (alpha * (e - <span class="number">1</span>)) &lt; <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">return</span> (z &gt; <span class="number">0</span>).<span class="built_in">type_as</span>(z) + mask.<span class="built_in">type_as</span>(z) * (alpha * e);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="å‰å‘ä¼ æ’­"><a href="#å‰å‘ä¼ æ’­" class="headerlink" title="å‰å‘ä¼ æ’­"></a>å‰å‘ä¼ æ’­</h3><p>æ¥ä¸‹æ¥æ¯”è¾ƒé‡è¦çš„å°±æ˜¯å¯¹åº”å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­çš„ç¼–å†™äº†ï¼Œè¿™é‡Œé¢å…¶å®ä¾æ—§æ˜¯å°†æˆ‘ä»¬å‰é¢ä½¿ç”¨çš„Pythonä»£ç æ¥è½¬åŒ–ä¸ºC++çš„ä»£ç çš„ç¼–å†™ï¼Œé€»è¾‘éƒ½æ˜¯ä¸€æ ·çš„ï¼Œåªä¸è¿‡è¯­è¨€æ˜¯æœ‰äº›ä¸åŒçš„ï¼Œè¿™é‡Œ<code>forward</code>ä¸éœ€è¦ä¼ å…¥<code>ctx</code>å‚æ•°ï¼Œæ‰€ä»¥ä¸€å…±æœ‰äº”ä¸ªå‚æ•°ï¼Œå®é™…ä¸Šè·ŸPythonå®ç°çš„ä¸€ä¸€å¯¹åº”ï¼Œåªæ˜¯è½¬åŒ–ä¸ºC++çš„æ‰©å±•è€Œå·²ã€‚</p>
<p>ä»¥å‰å‘ä¼ æ’­ä¸ºä¾‹å­ï¼Œè¿™é‡Œé¢æœ‰ä¸€äº›è¯­æ³•å’Œç”¨æ³•æ˜¯ä¸ä¸€æ ·çš„ï¼Œæ¯”å¦‚Pytorché‡Œé¢çš„<code>torch.cat</code>å¯¹åº”ç€C++é‡Œé¢çš„<code>torch::cat</code>ï¼Œè¿˜æœ‰æ¯”è¾ƒä¸ä¸€æ ·çš„å°±æ˜¯<code>F.linear</code>å¯¹åº”ç€<code>torch.addmm</code>ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œå¤§éƒ¨åˆ†çš„æ–¹æ³•æˆ‘ä»¬éƒ½å¯ä»¥åœ¨å‰é¢åŠ ä¸€ä¸ªå‰ç¼€<code>torch::</code>å³å¯ï¼Œè¿™ä¹Ÿç®—å†™C++æ‰©å±•çš„ä¸€ä¸ªè§„å¾‹ã€‚</p>
<blockquote>
<p><code>torch::addmm</code> æ˜¯ PyTorch ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ‰§è¡ŒçŸ©é˜µçš„ä¹˜æ³•å’ŒåŠ æ³•æ“ä½œã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š</p>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line">result = beta * mat + alpha * (mat1 @ mat2)</span><br></pre></td></tr></tbody></table></figure>
<p>å…¶ä¸­ï¼Œ<code>mat</code> æ˜¯è¾“å‡ºçŸ©é˜µï¼Œ<code>mat1</code> å’Œ <code>mat2</code> æ˜¯è¾“å…¥çŸ©é˜µï¼Œ<code>alpha</code> å’Œ <code>beta</code> æ˜¯æ ‡é‡ç³»æ•°ã€‚è¿™ä¸ªå‡½æ•°é€šå¸¸ç”¨äºçº¿æ€§ä»£æ•°è¿ç®—ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ç»å¸¸ä¼šç”¨åˆ°ã€‚</p>
</blockquote>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">// å‰å‘ä¼ æ’­</span></span><br><span class="line"><span class="function">std::vector&lt;at::Tensor&gt; <span class="title">lltm_forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor input,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor weights,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor bias,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor old_h,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor old_cell)</span> </span>{</span><br><span class="line">  <span class="keyword">auto</span> X = torch::<span class="built_in">cat</span>({old_h, input}, <span class="comment">/*dim=*/</span><span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> gate_weights = torch::<span class="built_in">addmm</span>(bias, X, weights.<span class="built_in">transpose</span>(<span class="number">0</span>, <span class="number">1</span>));</span><br><span class="line">  <span class="keyword">auto</span> gates = gate_weights.<span class="built_in">chunk</span>(<span class="number">3</span>, <span class="comment">/*dim=*/</span><span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> input_gate = torch::<span class="built_in">sigmoid</span>(gates[<span class="number">0</span>]);</span><br><span class="line">  <span class="keyword">auto</span> output_gate = torch::<span class="built_in">sigmoid</span>(gates[<span class="number">1</span>]);</span><br><span class="line">  <span class="keyword">auto</span> candidate_cell = torch::<span class="built_in">elu</span>(gates[<span class="number">2</span>], <span class="comment">/*alpha=*/</span><span class="number">1.0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> new_cell = old_cell + candidate_cell * input_gate;</span><br><span class="line">  <span class="keyword">auto</span> new_h = torch::<span class="built_in">tanh</span>(new_cell) * output_gate;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> {new_h,</span><br><span class="line">          new_cell,</span><br><span class="line">          input_gate,</span><br><span class="line">          output_gate,</span><br><span class="line">          candidate_cell,</span><br><span class="line">          X,</span><br><span class="line">          gate_weights};</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="åå‘ä¼ æ’­"><a href="#åå‘ä¼ æ’­" class="headerlink" title="åå‘ä¼ æ’­"></a>åå‘ä¼ æ’­</h3><p>åå‘ä¼ æ’­ä¸å‰å‘ä¼ æ’­æ˜¯ç±»ä¼¼çš„ï¼Œæœ‰ä¸€ç‚¹ä¸åŒçš„æ˜¯ï¼Œç”±äºæ²¡æœ‰<code>ctx</code>å­˜å‚¨ä¿¡æ¯ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„ä¼ å…¥å‚æ•°è¿˜åŒ…æ‹¬<code>ctx</code>é‡Œé¢çš„å‚æ•°ï¼Œéƒ½æ˜¯<code>torch::Tensor</code>æ ¼å¼ï¼Œæ ¹æ®Pythonç¼–å†™çš„åå‘ä¼ æ’­çš„ä»£ç ï¼Œå¯¹åº”ç€C++å®ç°å³å¯ï¼Œå…¶å®ä¹Ÿæ˜¯ä¸€æ¨¡ä¸€æ ·ï¼Œä¸€ä¸€å¯¹åº”çš„ã€‚</p>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">// åå‘ä¼ æ’­</span></span><br><span class="line"><span class="function">std::vector&lt;torch::Tensor&gt; <span class="title">lltm_backward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor grad_h,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor grad_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor new_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor input_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor output_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor candidate_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor X,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor gate_weights,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor weights)</span> </span>{</span><br><span class="line">  <span class="keyword">auto</span> d_output_gate = torch::<span class="built_in">tanh</span>(new_cell) * grad_h;</span><br><span class="line">  <span class="keyword">auto</span> d_tanh_new_cell = output_gate * grad_h;</span><br><span class="line">  <span class="keyword">auto</span> d_new_cell = <span class="built_in">d_tanh</span>(new_cell) * d_tanh_new_cell + grad_cell;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> d_old_cell = d_new_cell;</span><br><span class="line">  <span class="keyword">auto</span> d_candidate_cell = input_gate * d_new_cell;</span><br><span class="line">  <span class="keyword">auto</span> d_input_gate = candidate_cell * d_new_cell;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> gates = gate_weights.<span class="built_in">chunk</span>(<span class="number">3</span>, <span class="comment">/*dim=*/</span><span class="number">1</span>);</span><br><span class="line">  d_input_gate *= <span class="built_in">d_sigmoid</span>(gates[<span class="number">0</span>]);</span><br><span class="line">  d_output_gate *= <span class="built_in">d_sigmoid</span>(gates[<span class="number">1</span>]);</span><br><span class="line">  d_candidate_cell *= <span class="built_in">d_elu</span>(gates[<span class="number">2</span>]);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> d_gates =</span><br><span class="line">      torch::<span class="built_in">cat</span>({d_input_gate, d_output_gate, d_candidate_cell}, <span class="comment">/*dim=*/</span><span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> d_weights = d_gates.<span class="built_in">t</span>().<span class="built_in">mm</span>(X);</span><br><span class="line">  <span class="keyword">auto</span> d_bias = d_gates.<span class="built_in">sum</span>(<span class="comment">/*dim=*/</span><span class="number">0</span>, <span class="comment">/*keepdim=*/</span><span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> d_X = d_gates.<span class="built_in">mm</span>(weights);</span><br><span class="line">  <span class="type">const</span> <span class="keyword">auto</span> state_size = grad_h.<span class="built_in">size</span>(<span class="number">1</span>);</span><br><span class="line">  <span class="keyword">auto</span> d_old_h = d_X.<span class="built_in">slice</span>(<span class="comment">/*dim=*/</span><span class="number">1</span>, <span class="number">0</span>, state_size);</span><br><span class="line">  <span class="keyword">auto</span> d_input = d_X.<span class="built_in">slice</span>(<span class="comment">/*dim=*/</span><span class="number">1</span>, state_size);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> {d_old_h, d_input, d_weights, d_bias, d_old_cell};</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>å®Œæˆä¸Šè¿°ä»£ç çš„ç¼–å†™ä¹‹åï¼Œæˆ‘ä»¬å°±åªéœ€è¦<code>PYBIND11_MODULE</code>æ¥è¿›è¡Œç»‘å®šï¼Œå†ç®€å•ä»‹ç»ä¸€ä¸‹ä»–çš„ç”¨å¤„ï¼Œä»–çš„ä½œç”¨å…¶å®å°±æ˜¯ä¸€ä¸ªå‘½åçš„ç»‘å®šï¼Œä¹Ÿå°±æ˜¯Pythoné‡Œé¢çš„forwardä¸ºC++é‡Œé¢çš„<code>lltm_forward</code>ï¼Œè¿™æ ·è°ƒç”¨æ¨¡å—çš„æ—¶å€™ï¼ŒPythonä¸­çš„å‡½æ•°å°±ä¼šæ‰¾åˆ°å¯¹åº”çš„C++å‡½æ•°æ¥è¿›è¡Œè¿è¡Œã€‚</p>
<blockquote>
<p><code>PYBIND11_MODULE</code>è¿™æ˜¯ Python è°ƒç”¨ C++ å‡½æ•°çš„å…³é”®éƒ¨åˆ†ã€‚è¿™ä¸ªå‡½æ•°ä¼šåœ¨Pythonæ‰§è¡Œ<code>import</code>è¯­å¥æ—¶è¢«è°ƒç”¨ï¼Œå…¶æ¥å—ä¸¤ä¸ªå‚æ•°ï¼Œ</p>
<p>ç¬¬ä¸€ä¸ªå‚æ•°ä¸ºæ¨¡å—åç§°ï¼Œè¿™é‡Œæˆ‘ä»¬ç›´æ¥å°†<code>lltm_cpp</code>å¡«å…¥ï¼Œç¨å€™å¯ä»¥åœ¨Pythonä¸­ä½¿ç”¨<code>import lltm_cpp</code>å¯¼å…¥è¯¥æ¨¡å—ï¼›ç¬¬äºŒä¸ªå‚æ•°<code>m</code>æ˜¯åˆ›å»ºPythonå…³è”ä»£ç çš„ä¸»æ¥å£ï¼Œå…¶ç±»å‹ä¸º<code>py::module_</code>ã€‚<code>module_::def()</code>ç”¨äºç”Ÿæˆèƒ½å¤Ÿå°†<code>lltm_cpp</code>å‡½æ•°æš´éœ²ç»™Pythonçš„ä»£ç ï¼Œå…¶ç¬¬ä¸€ä¸ªå‚æ•°ä¸º<strong>å­—ç¬¦ä¸²</strong>ï¼Œå°†ä¼šæˆä¸ºPythonä¸­è°ƒç”¨çš„å‡½æ•°åï¼›</p>
<p>ç¬¬äºŒä¸ªå‚æ•°æ˜¯<strong>C++å‡½æ•°</strong>çš„å¼•ç”¨ï¼›</p>
<p>ç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯<strong>è¯´æ˜å­—ç¬¦ä¸²</strong>ï¼Œåœ¨Pythonä¸­å¯ä»¥ä½¿ç”¨<code>help(lltm_cpp)</code>æŸ¥çœ‹ã€‚æ¯”å¦‚ä¸‹é¢çš„ä¾‹å­ä¸­ï¼ŒC++ ä¸­çš„å‡½æ•° <code>lltm_forward</code> å¯¹åº” Python ä¸­çš„ <code>forward</code>ã€‚</p>
</blockquote>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">PYBIND11_MODULE</span>(TORCH_EXTENSION_NAME, m) {</span><br><span class="line">  m.<span class="built_in">def</span>(<span class="string">"forward"</span>, &amp;lltm_forward, <span class="string">"LLTM forward"</span>);</span><br><span class="line">  m.<span class="built_in">def</span>(<span class="string">"backward"</span>, &amp;lltm_backward, <span class="string">"LLTM backward"</span>);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="C-æ‰©å±•è°ƒç”¨"><a href="#C-æ‰©å±•è°ƒç”¨" class="headerlink" title="C++æ‰©å±•è°ƒç”¨"></a>C++æ‰©å±•è°ƒç”¨</h3><p>C++æ‰©å±•ä¸€èˆ¬æœ‰ä¸¤ç§æ–¹å¼</p>
<ul>
<li>é€šè¿‡<code>setuptools</code>â€œæå‰â€æ„å»º</li>
<li>é€šè¿‡<code>torch.utils.cpp_extension.load()</code>â€œå®æ—¶â€æ„å»º</li>
</ul>
<p>å¯¹äºè¿™ä¸¤ç§æ–¹æ³•ï¼Œå¦‚æœä½ çš„ä»£ç åªè¿è¡Œä¸€æ¬¡ï¼Œå¯ä»¥åˆ©ç”¨<code>jit</code>å®æ—¶æ„å»ºï¼Œè¿™æ ·ä¸ç”¨å»<code>python setup.py</code>æ¥å®‰è£…ï¼Œä½†æ˜¯å¦‚æœä½ ä¼šå¤šæ¬¡å¤ç”¨è¿™ä¸ªC++æ‰©å±•ï¼Œé‚£ä¹ˆè¿˜æ˜¯éœ€è¦å»ç”¨ç¬¬ä¸€ç§æ–¹æ³•ï¼Œè¿™æ ·åç»­è¿è¡Œçš„æ—¶å€™ä¸éœ€è¦ä¸€ç›´æ„å»ºï¼Œè¿™æ ·ç­‰å¾…çš„æ—¶é—´å°±å›æ¯”è¾ƒé•¿ã€‚</p>
<h4 id="Building-with-setuptools"><a href="#Building-with-setuptools" class="headerlink" title="Building with setuptools"></a>Building with <code>setuptools</code></h4><p>æ¥ä¸‹æ¥å…ˆè¯•ç”¨<code>setuptools</code>è¿›è¡Œæ„å»ºï¼Œç¼–å†™ä¸€ä¸ª <code>setup.py</code> æ–‡ä»¶ï¼Œä¸»è¦ç”¨äºå®šä¹‰å’Œè¯´æ˜ä¸€äº›é‡è¦çš„ä¿¡æ¯ã€‚å…¶ä¸­å…³é”®çš„å‚æ•°åŒ…æ‹¬ï¼š</p>
<ul>
<li><code>name</code>ï¼šPython è°ƒç”¨çš„åŒ…çš„åç§°ã€‚</li>
<li><code>ext_modules</code> çš„ <code>sources</code>ï¼šéœ€è¦ç¼–è¯‘çš„ C++ æºæ–‡ä»¶ï¼Œå¦‚æœæœ‰å¤šä¸ª C++ æ–‡ä»¶ï¼Œéœ€è¦åˆ—ä¸¾æ‰€æœ‰ã€‚</li>
<li><code>cmdclass</code>ï¼šç”¨BuildExtensionæ‰§è¡Œè®¸å¤šå¿…éœ€çš„é…ç½®æ­¥éª¤å’Œæ£€æŸ¥ï¼Œå¹¶åœ¨æ··åˆC++/CUDAæ‰©å±•çš„æƒ…å†µä¸‹å¤„ç†æ··åˆç¼–è¯‘ã€‚</li>
</ul>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line">from setuptools <span class="keyword">import</span> setup, Extension</span><br><span class="line">from torch.<span class="function">utils <span class="keyword">import</span> cpp_extension</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">setup</span><span class="params">(name=<span class="string">'lltm_cpp'</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">      ext_modules=[cpp_extension.CppExtension(<span class="string">'lltm_cpp'</span>, [<span class="string">'lltm.cpp'</span>])],</span></span></span><br><span class="line"><span class="params"><span class="function">      cmdclass={<span class="string">'build_ext'</span>: cpp_extension.BuildExtension})</span></span></span><br></pre></td></tr></tbody></table></figure>
<p>å®Œæˆè¿™ä¸€æ­¥åï¼Œå¦‚æœä½¿ç”¨<code>setuptools</code>è¿›è¡Œæ„å»ºï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ <code>pip</code> è¿›è¡Œå®‰è£…ã€‚å¦‚æœåœ¨å½“å‰æ–‡ä»¶å¤¹ä¸‹ï¼Œç›´æ¥è¿è¡Œ <code>pip install .</code> å³å¯å®Œæˆå®‰è£…æˆ–è€…æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨<code>python set.py install</code>ï¼Œå®‰è£…æˆåŠŸååº”è¯¥ä¼šæ˜¾ç¤ºä»¥ä¸‹ç»“æœï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Installed /path/python3.10/site-packages/lltm_cpp-0.0.0-py3.10-linux-x86_64.egg</span><br><span class="line">Processing dependencies <span class="keyword">for</span> lltm-cpp==0.0.0</span><br><span class="line">Finished processing dependencies <span class="keyword">for</span> lltm-cpp==0.0.0</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™æ ·åç»­æˆ‘ä»¬å°±å¯ä»¥åœ¨å¯¹åº”çš„ç¯å¢ƒæ¥è¿›è¡Œ<code>import lltm_cpp</code>æ¥ä½¿ç”¨å¯¹åº”C++å‡½æ•°äº†ã€‚</p>
<h4 id="JIT-Compiling-Extensions"><a href="#JIT-Compiling-Extensions" class="headerlink" title="JIT Compiling Extensions"></a>JIT Compiling Extensions</h4><p>é™¤äº†ä¸Šè¿°çš„<code>setuptools</code>çš„æ–¹æ³•ï¼Œæ¥ä¸‹æ¥ä»‹ç»å³æ—¶ç¼–è¯‘ï¼ˆJITï¼‰æœºåˆ¶æ„å»ºC++æ‰©å±•ã€‚JITç¼–è¯‘æœºåˆ¶é€šè¿‡è°ƒç”¨PyTorch APIä¸­çš„ä¸€ä¸ªç®€å•å‡½æ•°<code>torch.utils.cpp_extension.load()</code>ï¼Œä¸ºä½ æä¾›äº†ä¸€ç§å³æ—¶ç¼–è¯‘å’ŒåŠ è½½æ‰©å±•çš„æ–¹å¼ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> load</span><br><span class="line"></span><br><span class="line">cppcuda_tutorial = load(name=<span class="string">"cppcuda_tutorial"</span>,</span><br><span class="line">                        <span class="comment"># extra_include_paths=include_dirs,</span></span><br><span class="line">                        sources=[<span class="string">'interpolation.cpp'</span>],)</span><br></pre></td></tr></tbody></table></figure>
<p>åœ¨è¿™é‡Œï¼Œå®é™…æä¾›çš„æ˜¯åŸŸsetuptoolsç›¸åŒçš„ä¿¡æ¯ã€‚åœ¨åå°ï¼Œè¿™å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š</p>
<ol>
<li>åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½•<code>/tmp/torch_extensions/cppcuda_tutorial</code>ï¼Œ</li>
<li>å‘è¯¥ä¸´æ—¶ç›®å½•å‘å‡ºNinjaæ„å»ºæ–‡ä»¶ï¼Œ</li>
<li>å°†ä½ çš„æºæ–‡ä»¶ç¼–è¯‘æˆä¸€ä¸ªå…±äº«åº“ï¼Œ</li>
<li>å°†è¿™ä¸ªå…±äº«åº“å¯¼å…¥ä¸ºPythonæ¨¡å—ã€‚</li>
</ol>
<p>å®é™…ä¸Šï¼Œå¦‚æœå°†<code>verbose=True</code>ä¼ é€’ç»™<code>cpp_extension.load()</code>ï¼Œä½ å°†å¾—åˆ°æœ‰å…³è¯¥è¿‡ç¨‹çš„ä¿¡æ¯ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Using /path/.cache/torch_extensions/py310_cu113 as PyTorch extensions root...</span><br><span class="line">Creating extension directory /path/.cache/torch_extensions/py310_cu113/lltm_cpp...</span><br><span class="line">Emitting ninja build file /path/.cache/torch_extensions/py310_cu113/lltm_cpp/build.ninja...</span><br><span class="line">Building extension module lltm_cpp...</span><br><span class="line">Allowing ninja to <span class="built_in">set</span> a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)</span><br><span class="line">[1/2] c++ -MMD -MF lltm.o.d -DTORCH_EXTENSION_NAME=lltm_cpp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /path//path/python3.10/site-packages/torch/include -isystem /path//path/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /path//path/python3.10/site-packages/torch/include/TH -isystem /path//path/python3.10/site-packages/torch/include/THC -isystem /path/anaconda3/envs/ernerf/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -c /path/workdirs/pytorch-cppcuda-tutorial/lltm/lltm.cpp -o lltm.o </span><br><span class="line">[2/2] c++ lltm.o -shared -L/path//path/python3.10/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o lltm_cpp.so</span><br><span class="line">Loading extension module lltm_cpp...</span><br></pre></td></tr></tbody></table></figure>
<h3 id="åŠ é€Ÿå‰å‘åå‘ä¼ æ’­"><a href="#åŠ é€Ÿå‰å‘åå‘ä¼ æ’­" class="headerlink" title="åŠ é€Ÿå‰å‘åå‘ä¼ æ’­"></a>åŠ é€Ÿå‰å‘åå‘ä¼ æ’­</h3><p>å®ç°äº†åŠ é€Ÿçš„æ‰©å±•ä¹‹åï¼Œæˆ‘ä»¬å°±å¯ä»¥æ”¹å†™æˆ‘ä»¬å¯¹åº”çš„<code>LLTMFuntcion</code>åˆ©ç”¨C++æ‰©å±•æ¥è¿›è¡ŒåŠ é€Ÿï¼Œæ–¹æ³•å¾ˆç®€å•ï¼Œå°±æ˜¯å°†å‡½æ•°ä¼ å…¥åˆ°<code>LLTMFuntcion</code>ä¼ å…¥å³å¯</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LLTMFunction</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span>, weights, bias, old_h, old_cell</span>):</span><br><span class="line">        outputs = lltm_cpp.forward(<span class="built_in">input</span>, weights, bias, old_h, old_cell)</span><br><span class="line">        new_h, new_cell = outputs[:<span class="number">2</span>]</span><br><span class="line">        variables = outputs[<span class="number">1</span>:] + [weights]</span><br><span class="line">        ctx.save_for_backward(*variables)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> new_h, new_cell</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_h, grad_cell</span>):</span><br><span class="line">        outputs = lltm_cpp.backward(</span><br><span class="line">            grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)</span><br><span class="line">        d_old_h, d_input, d_weights, d_bias, d_old_cell = outputs</span><br><span class="line">        <span class="keyword">return</span> d_input, d_weights, d_bias, d_old_h, d_old_cell</span><br></pre></td></tr></tbody></table></figure>
<h3 id="æ—¶é—´æ•ˆç‡æ¯”è¾ƒ-1"><a href="#æ—¶é—´æ•ˆç‡æ¯”è¾ƒ-1" class="headerlink" title="æ—¶é—´æ•ˆç‡æ¯”è¾ƒ"></a>æ—¶é—´æ•ˆç‡æ¯”è¾ƒ</h3><p>ä¸Pythonæ‰©å±•å®ç°ç±»ä¼¼ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸C++æ‰©å±•å®ç°ç±»ä¼¼çš„æ—¶é—´æ•ˆç‡æ¯”è¾ƒï¼Œç»“æœæ˜¾ç¤ºå‰å‘ä¼ æ’­åœ¨<code>PyTorch</code>è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ä¸‹ç›¸å¯¹è¾ƒæ…¢ï¼Œä¸æˆ‘ä»¬æ‰‹åŠ¨å®ç°ç›¸æ¯”å¯èƒ½æœ‰å››äº”å€çš„æ€§èƒ½å·®è·ã€‚ç„¶è€Œï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå°½ç®¡å‰å‘ä¼ æ’­çš„é€Ÿåº¦è¾ƒæ…¢ï¼Œä½†æ‰€è·å¾—çš„ç»“æœå´æ›´ä¸ºä¼˜è¶Šï¼Œç›¸è¾ƒäºé»˜è®¤æœºåˆ¶å¤§çº¦æé«˜äº†2å€å·¦å³ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Forward: 0.0011254544 s | Backward 0.0005326970 s</span><br><span class="line">Forward: 0.0002915986 s | Backward 0.0008708093 s</span><br></pre></td></tr></tbody></table></figure>
<h2 id="CUDAæ‰©å±•å®ç°"><a href="#CUDAæ‰©å±•å®ç°" class="headerlink" title="CUDAæ‰©å±•å®ç°"></a>CUDAæ‰©å±•å®ç°</h2><p>æ¥ä¸‹æ¥å°±åˆ°äº†é‡å¤´æˆï¼Œä¹Ÿå°±æ˜¯CUDAæ‰©å±•çš„å®ç°ï¼Œé¦–å…ˆæˆ‘ä»¬å…ˆçœ‹çœ‹ï¼Œæ€ä¹ˆä½¿ç”¨CUDAå»è¿›è¡Œç¼–ç¨‹ï¼Œé¦–å…ˆCUDAçš„ä»£ç æ˜¯<code>cu</code>ç»“å°¾çš„ï¼Œæˆ‘ä»¬é€šè¿‡ç¼–å†™CUDAæ¥è¿›è¡Œä¸€ä¸ªè®¡ç®—åŠ é€Ÿã€‚æˆ‘ä»¬è¿˜æ˜¯å…ˆæŒ‰ä¹‹å‰çš„æ–¹æ³•ï¼Œçœ‹çœ‹å¦‚ä½•ä½¿ç”¨CUDAè¿›è¡Œç¼–ç¨‹å…ˆï¼Œè¿™é‡Œé¢æœ‰å‡ ä¸ªæ³¨æ„çš„ç‚¹ï¼š</p>
<ul>
<li>éœ€è¦ç¼–å†™CUDAå‡½æ•°</li>
<li>éœ€è¦åœ¨å¤´æ–‡ä»¶<code>.h</code>ä¸­å»å®šä¹‰éœ€è¦ä½¿ç”¨çš„å‡½æ•°ï¼ŒåŒ…æ‹¬ä¸€äº›å¸¸ç”¨çš„æµ‹è¯•å‡½æ•°ã€‚ä¹Ÿå¯ä»¥å†™åˆ°å‡½æ•°ä¸­</li>
<li>ä¿®æ”¹CUDAçš„<code>setup.py</code></li>
</ul>
<p>æ¥ä¸‹æ¥ä¸€æ­¥ä¸€æ­¥æ¥ï¼Œé¦–å…ˆæˆ‘ä»¬å†™å¯¹åº”è°ƒç”¨CUDAçš„C++æ–‡ä»¶ï¼Œè¿™é‡Œé¢åšçš„ä¸»è¦æ˜¯å£°æ˜å’Œä¸€äº›å®šä¹‰<code>lltm_forward</code>,<code>lltm_backward</code>,<code>lltm_cuda_forward</code>,<code>lltm_cuda_forward</code>å‡½æ•°ï¼Œå…·ä½“çš„å‡½æ•°æ“ä½œä¼šåœ¨CUDAé‡Œé¢è¿›è¡Œå®ç°ï¼Œè¿™æ ·ç¼–å†™ä»¥åï¼Œæˆ‘ä»¬çš„cppçš„ä»£ç å°±å¯ä»¥è°ƒç”¨CUDAå¯¹å‡½æ•°æ¥è¿›è¡Œè°ƒç”¨ï¼Œä½†æ˜¯ç”±äºæˆ‘ä»¬ä½¿ç”¨CUDAçš„å‡½æ•°ï¼Œæ‰€ä»¥è¿™é‡Œé¢æˆ‘ä»¬è¿˜è¦ç”¨åˆ°<code>CHECK_INPUT</code>å‡½æ•°æ¥åˆ¤æ–­æ˜¯å¦åœ¨GPUä¸Šï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªæ£€æµ‹ï¼Œå¹¶ä¸”å†…å­˜æ˜¯å¦è¿ç»­ï¼Œå› ä¸ºåç»­è¦è¿›è¡Œä¸€ä¸ªå¹¶è¡Œçš„è®¡ç®—ã€‚</p>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;torch/extension.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// C++ interface</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x <span class="string">" must be a CUDA tensor"</span>)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x <span class="string">" must be contiguous"</span>)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CUDA forward declarations</span></span><br><span class="line"></span><br><span class="line"><span class="function">std::vector&lt;torch::Tensor&gt; <span class="title">lltm_cuda_forward</span><span class="params">( </span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor input,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor weights,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor bias,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor old_h,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor old_cell)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">std::vector&lt;torch::Tensor&gt; <span class="title">lltm_cuda_backward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor grad_h,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor grad_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor new_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor input_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor output_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor candidate_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor X,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor gate_weights,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor weights)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">std::vector&lt;torch::Tensor&gt; <span class="title">lltm_forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor input,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor weights,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor bias,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor old_h,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor old_cell)</span> </span>{</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(input);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(weights);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(bias);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(old_h);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(old_cell);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">lltm_cuda_forward</span>(input, weights, bias, old_h, old_cell);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function">std::vector&lt;torch::Tensor&gt; <span class="title">lltm_backward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor grad_h,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor grad_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor new_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor input_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor output_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor candidate_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor X,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor gate_weights,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor weights)</span> </span>{</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(grad_h);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(grad_cell);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(input_gate);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(output_gate);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(candidate_cell);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(X);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(gate_weights);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(weights);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">lltm_cuda_backward</span>(</span><br><span class="line">            grad_h,</span><br><span class="line">            grad_cell,</span><br><span class="line">            new_cell,</span><br><span class="line">            input_gate,</span><br><span class="line">            output_gate,</span><br><span class="line">            candidate_cell,</span><br><span class="line">            X,</span><br><span class="line">            gate_weights,</span><br><span class="line">            weights);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(TORCH_EXTENSION_NAME, m) {</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">"forward"</span>, &amp;lltm_forward, <span class="string">"LLTM forward (CUDA)"</span>);</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">"backward"</span>, &amp;lltm_backward, <span class="string">"LLTM backward (CUDA)"</span>);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="åŸºç¡€å‡½æ•°-2"><a href="#åŸºç¡€å‡½æ•°-2" class="headerlink" title="åŸºç¡€å‡½æ•°"></a>åŸºç¡€å‡½æ•°</h3><p>æ¥ä¸‹æ¥å°±æ˜¯é‡ä¸­ä¹‹é‡ä¸ªï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬éœ€è¦å†™ä¸€ä¸ª<code>lltm_cuda_kernel.cu</code>å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªLLTMå¯¹åº”çš„CUDAå‡½æ•°ï¼Œåé¢æˆ‘ä»¬å¯ä»¥ç”¨C++è°ƒç”¨CUDAï¼Œæœ€åŸºç¡€çš„è¿˜æ˜¯å¯¹åº”çš„åŸºç¡€å‡½æ•°CUDAå‡½æ•°ç¼–å†™ï¼Œå’Œå‰é¢ç±»ä¼¼ï¼Œè¿™é‡Œé¢æ˜¯å°†å‰é¢ä½¿ç”¨çš„C++ï¼ŒPythonè½¬åŒ–ä¸ºCUDAç¼–ç¨‹çš„æ ¼å¼ï¼Œå®é™…ä¸Šä¹Ÿæ˜¯å¯¹åº”çš„C++ä»£ç ã€‚</p>
<p>å¯¹äºCUDAå‡½æ•°æ¥è¯´ï¼Œé¦–å…ˆæ¯”è¾ƒçš„ä¸åŒçš„å°±æ˜¯ï¼Œæˆ‘ä»¬éƒ½éœ€è¦ä½¿ç”¨åˆ°æ¨¡æ¿å‚æ•°<code>template&lt;typename scalar_t&gt;</code>ï¼Œè¿™æ ·å°±ä»£è¡¨ç€<code>scalar_t</code>èƒ½å¤Ÿä»£è¡¨ä»»ä½•çš„ç±»å‹ï¼Œæ–¹ä¾¿åç»­å»è°ƒç”¨ã€‚</p>
<p><code>__device__ __forceinline__</code> è¿™ä¸¤ä¸ªæ ‡è®°å‘Šè¯‰ç¼–è¯‘å™¨å°†å‡½æ•°å†…è”åˆ°è°ƒç”¨å¤„ï¼Œä»¥æé«˜æ‰§è¡Œæ•ˆç‡ã€‚<code>__device__</code> è¡¨ç¤ºè¿™ä¸ªå‡½æ•°åœ¨è®¾å¤‡ï¼ˆGPUï¼‰ä¸Šæ‰§è¡Œï¼Œè€Œ <code>__forceinline__</code> æç¤ºç¼–è¯‘å™¨å°½å¯èƒ½åœ°è¿›è¡Œå†…è”ä¼˜åŒ–ã€‚è¿™éƒ½æ˜¯CUDAæ¥æé«˜æ•ˆç‡çš„ä¸€äº›æ–¹å¼ï¼Œå®é™…ä¸Šçš„è®¡ç®—æ–¹å¼å°±å’ŒC++çš„å®ç°æ˜¯ä¸€æ ·çš„ã€‚</p>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;torch/extension.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cuda_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> <span class="type">scalar_t</span>&gt;</span></span><br><span class="line"><span class="function">__device__ __forceinline__ <span class="type">scalar_t</span> <span class="title">sigmoid</span><span class="params">(<span class="type">scalar_t</span> z)</span> </span>{</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span> / (<span class="number">1.0</span> + <span class="built_in">exp</span>(-z));</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> <span class="type">scalar_t</span>&gt;</span></span><br><span class="line"><span class="function">__device__ __forceinline__ <span class="type">scalar_t</span> <span class="title">d_sigmoid</span><span class="params">(<span class="type">scalar_t</span> z)</span> </span>{</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> s = <span class="built_in">sigmoid</span>(z);</span><br><span class="line">    <span class="keyword">return</span> (<span class="number">1.0</span> - s) * s;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> <span class="type">scalar_t</span>&gt;</span></span><br><span class="line"><span class="function">__device__ __forceinline__ <span class="type">scalar_t</span> <span class="title">d_tanh</span><span class="params">(<span class="type">scalar_t</span> z)</span> </span>{</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> t = <span class="built_in">tanh</span>(z);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - (t * t);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> <span class="type">scalar_t</span>&gt;</span></span><br><span class="line"><span class="function">__device__ __forceinline__ <span class="type">scalar_t</span> <span class="title">elu</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> z,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> alpha = <span class="number">1.0</span></span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>{</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">fmax</span>(<span class="number">0.0</span>,</span><br><span class="line">                z) + <span class="built_in">fmin</span>(<span class="number">0.0</span>,</span><br><span class="line">                          alpha * (<span class="built_in">exp</span>(z) - <span class="number">1.0</span>));</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> <span class="type">scalar_t</span>&gt;</span></span><br><span class="line"><span class="function">__device__ __forceinline__ <span class="type">scalar_t</span> <span class="title">d_elu</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> z,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> alpha = <span class="number">1.0</span></span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>{</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> e = <span class="built_in">exp</span>(z);</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> d_relu = z &lt; <span class="number">0.0</span> ? <span class="number">0.0</span> : <span class="number">1.0</span>;</span><br><span class="line">    <span class="keyword">return</span> d_relu + (((alpha * (e - <span class="number">1.0</span>)) &lt; <span class="number">0.0</span>) ? (alpha * e) : <span class="number">0.0</span>);</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h3 id="CUDAåŠ é€ŸåŸç†"><a href="#CUDAåŠ é€ŸåŸç†" class="headerlink" title="CUDAåŠ é€ŸåŸç†"></a>CUDAåŠ é€ŸåŸç†</h3><p>é¦–å…ˆä»‹ç»ä¸€ä¸ªCUDAç¨‹åºå®ç°çš„æµç¨‹</p>
<ol>
<li>æŠŠæ•°æ®ä»CPUå†…å­˜æ‹·è´åˆ°GPUå†…å­˜</li>
<li>è°ƒç”¨æ ¸å‡½æ•°å¯¹å­˜å‚¨åœ¨GPUå†…å­˜ä¸­çš„æ•°æ®è¿›è¡Œæ“ä½œ</li>
<li>å°†æ•°æ®ä»GPUå†…å­˜ä¼ é€å›CPUå†…å­˜</li>
</ol>
<p><img src="https://pic2.zhimg.com/v2-2959e07a36a8dc8f59280f53b43eb9d1_b.jpg" alt="CUDAç¼–ç¨‹å…¥é—¨æç®€æ•™ç¨‹- çŸ¥ä¹"></p>
<p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨åˆ©ç”¨CUDAåŠ é€Ÿçš„æ—¶å€™ï¼Œå›¾çš„å·¦è¾¹æ˜¯CPUï¼Œå³è¾¹æ˜¯GPUï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ•°æ®ä»CPUä¼ åˆ°GPUä¸­ã€‚åœ¨GPUä¸­ï¼Œå°±ä¼šç”Ÿæˆå¯¹åº”çš„Gridæ¥è¿›è¡Œè®¡ç®—ï¼Œæ¯ä¸ªGridé‡Œé¢åˆæœ‰å¾ˆå¤šçš„blockï¼Œä»blockä¸­çœ‹åˆæœ‰å¾ˆå¤šçš„çº¿ç¨‹threadè¿›è¡Œè¿ç®—ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœè®¡ç®—ä¸€ä¸ªçŸ©é˜µçš„åŠ æ³•ï¼Œæˆ‘ä»¬å¯ä»¥è®©æ¯ä¸ªthreadåšå¯¹åº”çš„å…ƒç´ çš„ç›¸åŠ ï¼Œè¿™æ ·å°±å¯ä»¥å¤§å¤§åŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œè¾¾åˆ°å¹¶è¡Œçš„æ•ˆæœã€‚æ‰€ä»¥è¿™ä¹‹ä¸­å†…æ ¸ï¼ˆkernelï¼‰æ˜¯CUDAç¼–ç¨‹ä¸­ä¸€ä¸ªé‡è¦çš„éƒ¨åˆ†ï¼Œå…¶ä»£ç åœ¨GPUä¸Šè¿è¡Œï¼Œæ¯”å¦‚çŸ©é˜µä¹˜æ³•ï¼Œæˆ‘ä»¬å°±å¯ä»¥å†™ä¸€ä¸ªåŠ æ³•çš„æ ¸å‡½æ•°ï¼Œç„¶åä¸²è¡Œæ‰§è¡Œæ ¸å‡½æ•°ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¿«é€Ÿèƒ½å®ŒæˆCUDAä»£ç çš„ç¼–å†™ï¼Œè€Œä¸ç”¨åœ¨åˆ›å»ºå’Œç®¡ç†å¤§é‡çš„GPUçº¿ç¨‹æ—¶æ‹˜æ³¥äºç»†èŠ‚ã€‚</p>
<p><img src="https://nyu-cds.github.io/python-gpu/fig/02-threadmapping.png" alt="Thread Mapping"></p>
<p>æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œå®é™…ä¸ŠCUDAçš„è®¡ç®—æ˜¯<code>Grid</code>â€”â€”ã€‹<code>Block</code>â€”â€”ã€‹<code>Thread</code>ï¼Œç„¶åç”¨å¤šä¸ª<code>Thread</code>è¿›è¡Œè®¡ç®—ï¼Œè¿™é‡Œé¢å¯èƒ½ä¼šç–‘æƒ‘ï¼Œä¸ºä»€ä¹ˆä¸æ˜¯ç›´æ¥<code>Grid</code>â€”â€”ã€‹<code>Thread</code>ï¼Œå®é™…ä¸Šæ˜¯å› ä¸ºç¡¬ä»¶çš„é™åˆ¶æ˜¯<code>Block</code>ä¸Šé™æ˜¯$(2^{31}-1)<em>2^{16}</em>2^{16}$ï¼Œ<code>Thread</code>çš„ä¸Šé™æ˜¯1024ï¼Œæ‰€ä»¥è¿™æ ·çš„ç»„åˆè®¾è®¡èƒ½å¤Ÿåˆ©ç”¨å¥½æ›´å¤šçš„<code>Thread</code>ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆGPUé€Ÿåº¦é‚£ä¹ˆå¿«çš„åŸå› ã€‚</p>
<h3 id="å‰å‘ä¼ æ’­æ ¸å‡½æ•°"><a href="#å‰å‘ä¼ æ’­æ ¸å‡½æ•°" class="headerlink" title="å‰å‘ä¼ æ’­æ ¸å‡½æ•°"></a>å‰å‘ä¼ æ’­æ ¸å‡½æ•°</h3><p>å¯¹äºCUDAç¼–ç¨‹æ¥è¯´ï¼Œå¾€å¾€é¦–å…ˆæˆ‘ä»¬éœ€è¦ç¼–å†™ä¸€ä¸ª<code>kernel</code>æ¨¡æ¿å‡½æ•°ï¼Œè¿™ä¸ªæ¨¡æ¿å‡½æ•°å®é™…ä¸Šå°±æ˜¯è¯´æ˜ï¼Œåœ¨ä¸€ä¸ªæ ¸ä¸­çš„å¯¹åº”çš„è®¡ç®—æ–¹å¼å’Œæµç¨‹ã€‚è¿™æ ·GPUå®ç°çš„å°±æ˜¯åœ¨å¤šä¸ª<code>thread</code>åšè¿™æ ·çš„äº‹æƒ…ï¼Œè¿™æ ·å°±å®ç°äº†å¹¶è¡Œè¿ç®—ï¼Œæå¤§çš„æé«˜äº†æ•ˆç‡ï¼Œè¿™ä¹Ÿæ˜¯æ˜¯ä¸ºä»€ä¹ˆCUDAåŠ é€Ÿæ¯”è¾ƒå¿«çš„åŸå› ã€‚</p>
<p>æ¥ä¸‹é‡Œåˆ†æå‡½æ•°çš„ä¸»ä½“éƒ¨åˆ†ï¼Œä¸»è¦åšä¸¤ä»¶äº‹æƒ…ï¼š</p>
<ol>
<li>ä¸ºæ¯ä¸ª<code>threads</code>è¿›è¡Œç¼–å·</li>
<li>å»é™¤ä¸å¿…è¦çš„<code>threads</code></li>
</ol>
<p>åœ¨ä½¿ç”¨<code>threads</code>è®¡ç®—çš„æ—¶å€™ï¼Œå®é™…ä¸Šæ¯ä¸€ä¸ª<code>threads</code>éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„ç¼–å·ï¼Œè®¡ç®—æ–¹å¼å¦‚ç¬¬12,13è¡Œæ‰€ç¤ºï¼Œå®é™…ä¸Šå°±æ˜¯blockçš„x*blockçš„ä¸ªæ•°+blockçš„yå°±èƒ½å¾—åˆ°æœ€åçš„ç»“æœï¼Œåç»­å°±æ˜¯å¯¹åº”ç€æ¯ä¸€ä¸ª<code>threads</code>çš„è®¡ç®—ï¼Œå¯¹åº”<code>threads</code>çš„ç¼–å·<code>index</code>ã€‚</p>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> <span class="type">scalar_t</span>&gt;</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">lltm_cuda_forward_kernel</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">scalar_t</span> *__restrict__ gates,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">scalar_t</span> *__restrict__ old_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> *__restrict__ new_h,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> *__restrict__ new_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> *__restrict__ input_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> *__restrict__ output_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> *__restrict__ candidate_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">size_t</span> state_size</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> column = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> index = blockIdx.y * state_size + column;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> gates_row = blockIdx.y * (state_size * <span class="number">3</span>);</span><br><span class="line">    <span class="keyword">if</span> (column &lt; state_size) {</span><br><span class="line">        input_gate[index] = <span class="built_in">sigmoid</span>(gates[gates_row + column]);</span><br><span class="line">        output_gate[index] = <span class="built_in">sigmoid</span>(gates[gates_row + state_size +</span><br><span class="line">                                           column]);</span><br><span class="line">        candidate_cell[index] = <span class="built_in">elu</span>(gates[gates_row + <span class="number">2</span> * state_size +</span><br><span class="line">                                          column]);</span><br><span class="line">        new_cell[index] =</span><br><span class="line">                old_cell[index] +</span><br><span class="line">                candidate_cell[index] * input_gate[index];</span><br><span class="line">        new_h[index] = <span class="built_in">tanh</span>(new_cell[index]) * output_gate[index];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="å‰å‘ä¼ æ’­-1"><a href="#å‰å‘ä¼ æ’­-1" class="headerlink" title="å‰å‘ä¼ æ’­"></a>å‰å‘ä¼ æ’­</h3><p>æ¥ä¸‹æ¥æˆ‘ä»¬å°±ä½¿ç”¨å®ç°çš„<code>lltm_cuda_forward_kernel</code>æ¥å®ç°<code>lltm_cuda_forward</code>ï¼Œå‰é¢å’ŒC++æ‰©å±•çš„æ–¹å¼æ˜¯ä¸€æ ·çš„ï¼Œä»¥åŠåˆå§‹åŒ–ç©ºçš„å˜é‡ä»¥ä¾¿åç»­è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œå¯¹äº<code>const int threads = 256; const dim3 blocks((state_size + threads - 1) / threads, batch_size);</code>è¿™ä¸¤è¡Œï¼Œå®é™…ä¸Šå°±æ˜¯åœ¨å®šä¹‰ä¸Šè¿°æè¿‡çš„<code>threads</code>å’Œ<code>blocks</code>äº†ï¼Œ<code>dim3</code>æ˜¯NVIDIAçš„CUDAç¼–ç¨‹ä¸­ä¸€ç§è‡ªå®šä¹‰çš„æ•´å‹å‘é‡ç±»å‹ï¼ŒåŸºäºç”¨äºæŒ‡å®šç»´åº¦çš„<code>uint3</code>ï¼Œ<code>dim3</code>ç±»å‹æœ€ç»ˆè®¾ç½®çš„æ˜¯ä¸€ä¸ªä¸‰ç»´å‘é‡ï¼Œä¸‰ç»´å‚æ•°åˆ†åˆ«ä¸ºx,y,zã€‚åœ¨å¹¶è¡Œä¸­ï¼Œé€šå¸¸åªæ”¯æŒä¸‰ä¸ªå¹¶è¡Œï¼Œæ¯”å¦‚è¿™é‡Œçš„Nå’ŒFåˆšåˆšå¥½å°±æ˜¯ä¸¤ä¸ªå¹¶è¡Œï¼Œè¿™é‡Œè®¾ç½®ä¸º16x16çš„çº¿ç¨‹ï¼Œä¸€èˆ¬å¯ä»¥æ˜¯128,256,512ï¼Œä¸ä¸€å®šä½¿ç”¨è¶Šå¤šè¶Šå¥½ï¼Œè¿™é‡Œé¢åªæ˜¯ç»™äº†ä¸€ä¸ªä¾‹å­ã€‚</p>
<p><code>const dim3 blocks((state_size + threads - 1) / threads, batch_size);</code>éƒ¨åˆ†è¿˜å®šä¹‰äº†<code>blocks</code>çš„ä¸ªæ•°è®¡ç®—ï¼Œä¹Ÿå°±æ˜¯ä½¿ç”¨å¤šå¤§çš„<code>blocks</code>å»è¦†ç›–æˆ‘ä»¬è®¡ç®—çŸ©é˜µï¼Œè¿™é‡Œé¢çš„<code>state_size</code>æ˜¯æ¯ä¸€ä¸ªè®¡ç®—çš„çŠ¶æ€å¤§å°ï¼Œ<code>batch_size</code>æ˜¯æ¯æ¬¡çš„æ•°ç›®ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è®¡ç®—å‡ºå¯¹åº”çš„<code>blocks</code>å¤§å°æ¥è¿›è¡Œè®¡ç®—ã€‚ï¼ˆè¯¦ç»†è§£è¯»å¯ä»¥çœ‹çœ‹ä¸Šä¸€ç¯‡æˆ‘çš„åšå®¢ï¼Œé‡Œé¢å¯ä»¥ç”»å›¾å¸®åŠ©ç†è§£ï¼‰<a href="https://zhuanlan.zhihu.com/p/671704557">CUDAç¼–ç¨‹å­¦ä¹ ï¼šè‡ªå®šä¹‰Pytorch+cpp/cuda extension</a></p>
<p>æœ€åè¿˜æœ‰ä¸€ä¸ªå°±æ˜¯<code>AT_DISPATCH_FLOATING_TYPES</code>ï¼Œè¿™é‡Œé¢å°±æ˜¯ä¸€ä¸ªå¯åŠ¨æ ¸å‡½æ•°çš„éƒ¨åˆ†ï¼Œè¿™é‡Œä¹Ÿå¯ä»¥è®¤ä¸ºæ˜¯ä¸€ä¸ªæ¡†æ¶å‡½æ•°ï¼Œ<code>AT_DISPATCH_FLOATING_TYPES</code> æ˜¯å¤„ç†æ ¸å‡½æ•°çš„å¯åŠ¨ï¼ˆä½¿ç”¨ <code>&lt;&lt;&lt;...&gt;&gt;&gt;</code> è¡¨ç¤ºï¼‰ï¼Œå®ƒä¸€èˆ¬æœ‰ä¸‰ä¸ªå‚æ•°</p>
<ul>
<li>ä¸€ä¸ªç±»å‹<code>gates.type()</code></li>
<li>ä¸€ä¸ªåç§° <code>"lltm_forward_cuda"</code>ï¼Œç”¨äºé”™è¯¯æ¶ˆæ¯</li>
<li>ä¸€ä¸ª lambda å‡½æ•°ï¼Œæ˜¯ä¸€ä¸ªæ¨¡ç‰ˆå‡½æ•°<code>template</code>ï¼Œç±»å‹åˆ«åä¸º <code>scalar_t</code>ï¼Œè¿™é‡Œé¢å°±æ˜¯æ ¸å‡½æ•°</li>
</ul>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function">std::vector&lt;torch::Tensor&gt; <span class="title">lltm_cuda_forward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor input,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor weights,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor bias,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor old_h,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor old_cell</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>{</span><br><span class="line">    <span class="keyword">auto</span> X = torch::<span class="built_in">cat</span>({old_h, input}, <span class="comment">/*dim=*/</span></span><br><span class="line">                        <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">auto</span> gate_weights = torch::<span class="built_in">addmm</span>(bias,</span><br><span class="line">                                     X,</span><br><span class="line">                                     weights.<span class="built_in">transpose</span>(<span class="number">0</span>,</span><br><span class="line">                                                       <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> batch_size = old_cell.<span class="built_in">size</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> state_size = old_cell.<span class="built_in">size</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> gates = gate_weights.<span class="built_in">reshape</span>({batch_size, <span class="number">3</span>, state_size});</span><br><span class="line">    <span class="keyword">auto</span> new_h = torch::<span class="built_in">zeros_like</span>(old_cell);</span><br><span class="line">    <span class="keyword">auto</span> new_cell = torch::<span class="built_in">zeros_like</span>(old_cell);</span><br><span class="line">    <span class="keyword">auto</span> input_gate = torch::<span class="built_in">zeros_like</span>(old_cell);</span><br><span class="line">    <span class="keyword">auto</span> output_gate = torch::<span class="built_in">zeros_like</span>(old_cell);</span><br><span class="line">    <span class="keyword">auto</span> candidate_cell = torch::<span class="built_in">zeros_like</span>(old_cell);</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> threads = <span class="number">256</span>;</span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">blocks</span><span class="params">((state_size + threads - <span class="number">1</span>) / threads,</span></span></span><br><span class="line"><span class="params"><span class="function">                      batch_size)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">AT_DISPATCH_FLOATING_TYPES</span>(gates.<span class="built_in">type</span>(),</span><br><span class="line">                               <span class="string">"lltm_forward_cuda"</span>,</span><br><span class="line">                               ([&amp;] {</span><br><span class="line">                                   lltm_cuda_forward_kernel&lt;<span class="type">scalar_t</span>&gt;&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(</span><br><span class="line">                                           gates.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           old_cell.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           new_h.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           new_cell.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           input_gate.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           output_gate.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           candidate_cell.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           state_size);</span><br><span class="line">                               }));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> {new_h, new_cell, input_gate, output_gate, candidate_cell, X,</span><br><span class="line">            gates};</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="åå‘ä¼ æ’­-1"><a href="#åå‘ä¼ æ’­-1" class="headerlink" title="åå‘ä¼ æ’­"></a>åå‘ä¼ æ’­</h3><p>ä¸å‰å‘ä¼ æ’­ç±»ä¼¼ï¼Œåå‘ä¼ æ’­ä¹Ÿæ˜¯ç±»ä¼¼çš„æ–¹æ³•è¿›è¡Œäº†å®ç°ï¼Œè¿™é‡Œå…·ä½“å°±ä¸è®²è¿°ï¼Œå‡ ä¹å’Œå‰å‘ä¼ æ’­çš„æ­¥éª¤æ˜¯ä¸€æ ·çš„ã€‚</p>
<figure class="highlight cpp"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> <span class="type">scalar_t</span>&gt;</span></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">lltm_cuda_backward_kernel</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> *d_old_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">scalar_t</span> *d_gates,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">scalar_t</span> *grad_h,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">scalar_t</span> *grad_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">scalar_t</span> *new_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">scalar_t</span> *input_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">scalar_t</span> *output_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">scalar_t</span> *candidate_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">const</span> <span class="type">scalar_t</span> *gate_weights,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="type">int</span> state_size</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> column = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> index = blockIdx.y * state_size + column;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> gates_row = blockIdx.y * (state_size * <span class="number">3</span>);</span><br><span class="line">    <span class="keyword">if</span> (column &lt; state_size) {</span><br><span class="line">        <span class="type">const</span> <span class="keyword">auto</span> d_output_gate = <span class="built_in">tanh</span>(new_cell[index]) *</span><br><span class="line">                                   grad_h[index];</span><br><span class="line">        <span class="type">const</span> <span class="keyword">auto</span> d_tanh_new_cell = output_gate[index] * grad_h[index];</span><br><span class="line">        <span class="type">const</span> <span class="keyword">auto</span> d_new_cell =</span><br><span class="line">                <span class="built_in">d_tanh</span>(new_cell[index]) * d_tanh_new_cell +</span><br><span class="line">                grad_cell[index];</span><br><span class="line">        d_old_cell[index] = d_new_cell;</span><br><span class="line">        <span class="type">const</span> <span class="keyword">auto</span> d_candidate_cell = input_gate[index] * d_new_cell;</span><br><span class="line">        <span class="type">const</span> <span class="keyword">auto</span> d_input_gate = candidate_cell[index] * d_new_cell;</span><br><span class="line">        d_gates[gates_row + column] =</span><br><span class="line">                d_input_gate * <span class="built_in">d_sigmoid</span>(gate_weights[gates_row +</span><br><span class="line">                                                      column]);</span><br><span class="line">        d_gates[gates_row + state_size +</span><br><span class="line">                column] =</span><br><span class="line">                d_output_gate *</span><br><span class="line">                <span class="built_in">d_sigmoid</span>(gate_weights[gates_row + state_size +</span><br><span class="line">                                       column]);</span><br><span class="line">        d_gates[gates_row + <span class="number">2</span> * state_size +</span><br><span class="line">                column] =</span><br><span class="line">                d_candidate_cell *</span><br><span class="line">                <span class="built_in">d_elu</span>(gate_weights[gates_row + <span class="number">2</span> * state_size +</span><br><span class="line">                                   column]);</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">std::vector&lt;torch::Tensor&gt; <span class="title">lltm_cuda_backward</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor grad_h,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor grad_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor new_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor input_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor output_gate,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor candidate_cell,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor X,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor gates,</span></span></span><br><span class="line"><span class="params"><span class="function">        torch::Tensor weights</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>{</span><br><span class="line">    <span class="keyword">auto</span> d_old_cell = torch::<span class="built_in">zeros_like</span>(new_cell);</span><br><span class="line">    <span class="keyword">auto</span> d_gates = torch::<span class="built_in">zeros_like</span>(gates);</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> batch_size = new_cell.<span class="built_in">size</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="type">const</span> <span class="keyword">auto</span> state_size = new_cell.<span class="built_in">size</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> threads = <span class="number">256</span>;</span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">blocks</span><span class="params">((state_size + threads - <span class="number">1</span>) / threads,</span></span></span><br><span class="line"><span class="params"><span class="function">                      batch_size)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">AT_DISPATCH_FLOATING_TYPES</span>(X.<span class="built_in">type</span>(),</span><br><span class="line">                               <span class="string">"lltm_backward_cuda"</span>,</span><br><span class="line">                               ([&amp;] {</span><br><span class="line">                                   lltm_cuda_backward_kernel&lt;<span class="type">scalar_t</span>&gt;&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(</span><br><span class="line">                                           d_old_cell.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           d_gates.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           grad_h.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           grad_cell.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           new_cell.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           input_gate.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           output_gate.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           candidate_cell.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           gates.<span class="built_in">data</span>&lt;<span class="type">scalar_t</span>&gt;(),</span><br><span class="line">                                           state_size</span><br><span class="line">                                           );</span><br><span class="line"></span><br><span class="line">                               }));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> d_gate_weights = d_gates.<span class="built_in">reshape</span>({batch_size, <span class="number">3</span> * state_size});</span><br><span class="line">    <span class="keyword">auto</span> d_weights = d_gate_weights.<span class="built_in">t</span>().<span class="built_in">mm</span>(X);</span><br><span class="line">    <span class="keyword">auto</span> d_bias = d_gate_weights.<span class="built_in">sum</span>(<span class="comment">/*dim=*/</span><span class="number">0</span>, <span class="comment">/*keepdim=*/</span></span><br><span class="line">                                             <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> d_X = d_gate_weights.<span class="built_in">mm</span>(weights);</span><br><span class="line">    <span class="keyword">auto</span> d_old_h = d_X.<span class="built_in">slice</span>(<span class="comment">/*dim=*/</span><span class="number">1</span>,</span><br><span class="line">                                     <span class="number">0</span>,</span><br><span class="line">                                     state_size);</span><br><span class="line">    <span class="keyword">auto</span> d_input = d_X.<span class="built_in">slice</span>(<span class="comment">/*dim=*/</span><span class="number">1</span>,</span><br><span class="line">                                     state_size);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> {d_old_h, d_input, d_weights, d_bias, d_old_cell};</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="æ—¶é—´æ•ˆç‡å¯¹æ¯”"><a href="#æ—¶é—´æ•ˆç‡å¯¹æ¯”" class="headerlink" title="æ—¶é—´æ•ˆç‡å¯¹æ¯”"></a>æ—¶é—´æ•ˆç‡å¯¹æ¯”</h3><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥è°ƒç”¨æ‰©å±•ï¼Œæ–¹æ³•æ˜¯ä¸€æ ·çš„ï¼Œæ‰€ä»¥è¿™é‡Œä¸å¤šè¯´ï¼Œæˆ‘ä½¿ç”¨çš„Jitçš„æ–¹å¼è¿›è¡Œå®æ—¶æ„å»º</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> load</span><br><span class="line">lltm_cuda = load(name=<span class="string">'lltm_cuda'</span>, </span><br><span class="line">                 sources=[<span class="string">'lltm/lltm_cuda.cpp'</span>, <span class="string">'lltm/lltm_cuda_kernel.cu'</span>], verbose=<span class="literal">True</span></span><br><span class="line">                 )</span><br></pre></td></tr></tbody></table></figure>
<p>åŒæ ·ä¹Ÿæ˜¯åŠ é€Ÿå¯¹åº”çš„<code>LLTMFunction</code>ï¼Œè°ƒç”¨å¯¹åº”CUDAå†™çš„<code>forward</code>å’Œ<code>backward</code>å³å¯ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LLTMFunction</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span>, weights, bias, old_h, old_cell</span>):</span><br><span class="line">        outputs = lltm_cuda.forward(<span class="built_in">input</span>, weights, bias, old_h, old_cell)</span><br><span class="line">        new_h, new_cell = outputs[:<span class="number">2</span>]</span><br><span class="line">        variables = outputs[<span class="number">1</span>:] + [weights]</span><br><span class="line">        ctx.save_for_backward(*variables)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> new_h, new_cell</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_h, grad_cell</span>):</span><br><span class="line">        outputs = lltm_cuda.backward(</span><br><span class="line">            grad_h.contiguous(), grad_cell.contiguous(), *ctx.saved_tensors)</span><br><span class="line">        d_old_h, d_input, d_weights, d_bias, d_old_cell = outputs</span><br><span class="line">        <span class="keyword">return</span> d_input, d_weights, d_bias, d_old_h, d_old_cell</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>
<h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><p><a href="https://github.com/pytorch/extension-cpp">https://github.com/pytorch/extension-cpp</a></p>
<p><a href="https://pytorch.org/tutorials/advanced/cpp_extension.html#">https://pytorch.org/tutorials/advanced/cpp_extension.html#</a></p>
<p><a href="https://github.com/kevinghst/lltm_experiment">https://github.com/kevinghst/lltm_experiment</a></p>
]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>é˜²ç«å¢™ufw ä»¥åŠ å¼€æ”¾ç«¯å£</title>
    <url>/2024/01/01/Linux/%E9%98%B2%E7%81%AB%E5%A2%99ufw%20%E4%BB%A5%E5%8F%8A%20%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3/</url>
    <content><![CDATA[<p>Ubuntu  é»˜è®¤ä½¿ç”¨ UFWï¼ˆUncomplicated Firewallï¼‰ä½œä¸ºé˜²ç«å¢™ï¼Œå¹¶ä¸”å·²ç»æ”¯æŒç•Œé¢æ“ä½œäº†ã€‚åœ¨å‘½ä»¤è¡Œä¸­è¿è¡Œ <code>ufw</code> å‘½ä»¤å°±å¯ä»¥çœ‹åˆ°ä¸€ç³»åˆ—å¯è¿›è¡Œçš„æ“ä½œã€‚</p>
<p>æœ€ç®€å•çš„ä¸€ä¸ªæ“ä½œæ˜¯ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æ¥æ£€æŸ¥é˜²ç«å¢™çš„çŠ¶æ€ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw status</span><br></pre></td></tr></tbody></table></figure>
<p>æˆ‘çš„è¿”å›ç»“æœæ˜¯ï¼šä¸æ´»åŠ¨ã€‚</p>
<p>é˜²ç«å¢™ç‰ˆæœ¬ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw version</span><br><span class="line">ufw 0.29-4ubuntu1</span><br><span class="line">Copyright 2008-2009 Canonical Ltd.</span><br></pre></td></tr></tbody></table></figure>
<p>Ubuntu ç³»ç»Ÿé»˜è®¤å·²å®‰è£… UFWã€‚</p>
<h3 id="1-å®‰è£…"><a href="#1-å®‰è£…" class="headerlink" title="1. å®‰è£…"></a>1. å®‰è£…</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install ufw</span><br></pre></td></tr></tbody></table></figure>
<h3 id="2-å¯ç”¨"><a href="#2-å¯ç”¨" class="headerlink" title="2. å¯ç”¨"></a>2. å¯ç”¨</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw <span class="built_in">enable</span></span><br><span class="line">sudo ufw default deny</span><br></pre></td></tr></tbody></table></figure>
<p>è¿è¡Œä»¥ä¸Šä¸¤æ¡å‘½ä»¤åï¼Œå¼€å¯äº†é˜²ç«å¢™ï¼Œå¹¶åœ¨ç³»ç»Ÿå¯åŠ¨æ—¶è‡ªåŠ¨å¼€å¯ã€‚è¿™å°†å…³é—­æ‰€æœ‰å¤–éƒ¨å¯¹æœ¬æœºçš„è®¿é—®ï¼Œä½†æœ¬æœºè®¿é—®å¤–éƒ¨ä»ç„¶æ­£å¸¸ã€‚</p>
<h3 id="3-å¼€å¯-ç¦ç”¨"><a href="#3-å¼€å¯-ç¦ç”¨" class="headerlink" title="3. å¼€å¯/ç¦ç”¨"></a>3. å¼€å¯/ç¦ç”¨</h3><p>ä»¥ä¸‹å‘½ä»¤å¯ä»¥æ‰“å¼€æˆ–å…³é—­æŸä¸ªç«¯å£ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw allow smtp     <span class="comment"># å…è®¸æ‰€æœ‰çš„å¤–éƒ¨ IP è®¿é—®æœ¬æœºçš„ 25/tcp (smtp) ç«¯å£</span></span><br><span class="line">sudo ufw allow 22/tcp   <span class="comment"># å…è®¸æ‰€æœ‰çš„å¤–éƒ¨ IP è®¿é—®æœ¬æœºçš„ 22/tcp (ssh) ç«¯å£</span></span><br><span class="line">sudo ufw allow 53       <span class="comment"># å…è®¸å¤–éƒ¨è®¿é—® 53 ç«¯å£ (tcp/udp)</span></span><br><span class="line">sudo ufw allow from 192.168.1.100   <span class="comment"># å…è®¸ IP åœ°å€ä¸º 192.168.1.100 çš„ä¸»æœºè®¿é—®æ‰€æœ‰æœ¬æœºç«¯å£</span></span><br><span class="line">sudo ufw allow proto udp from 192.168.0.1 port 53 to 192.168.0.2 port 53</span><br><span class="line">sudo ufw deny smtp      <span class="comment"># ç¦æ­¢å¤–éƒ¨è®¿é—® smtp æœåŠ¡</span></span><br><span class="line">sudo ufw delete allow smtp   <span class="comment"># åˆ é™¤ä¸Šé¢å»ºç«‹çš„æŸæ¡è§„åˆ™</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="4-æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€"><a href="#4-æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€" class="headerlink" title="4. æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€"></a>4. æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€</h3><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw status</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸€èˆ¬ç”¨æˆ·åªéœ€è¦å¦‚ä¸‹è®¾ç½®ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install ufw</span><br><span class="line">sudo ufw <span class="built_in">enable</span></span><br><span class="line">sudo ufw default deny</span><br></pre></td></tr></tbody></table></figure>
<p>ä»¥ä¸Šä¸‰æ¡å‘½ä»¤å·²ç»è¶³å¤Ÿå®‰å…¨äº†ï¼Œå¦‚æœä½ éœ€è¦å¼€æ”¾æŸäº›æœåŠ¡ï¼Œå†ä½¿ç”¨ <code>sudo ufw allow</code> å¼€å¯ã€‚</p>
<p>å…¶ä»–å‘½ä»¤ï¼š</p>
<ul>
<li>å¼€å¯/å…³é—­é˜²ç«å¢™ï¼ˆé»˜è®¤è®¾ç½®æ˜¯ <code>disable</code>ï¼‰ï¼š<code>sudo ufw enable|disable</code></li>
<li>è½¬æ¢æ—¥å¿—çŠ¶æ€ï¼š<code>sudo ufw logging on|off</code></li>
<li>è®¾ç½®é»˜è®¤ç­–ç•¥ï¼ˆæ¯”å¦‚ â€œmostly openâ€ vs â€œmostly closedâ€ï¼‰ï¼š<code>sudo ufw default allow|deny</code></li>
<li>å…è®¸æˆ–å±è”½ç«¯å£ï¼š<code>sudo ufw allow|deny [service]</code></li>
<li>æ˜¾ç¤ºé˜²ç«å¢™å’Œç«¯å£çš„ä¾¦å¬çŠ¶æ€ï¼š<code>sudo ufw status</code></li>
</ul>
<h3 id="UFW-ä½¿ç”¨èŒƒä¾‹"><a href="#UFW-ä½¿ç”¨èŒƒä¾‹" class="headerlink" title="UFW ä½¿ç”¨èŒƒä¾‹"></a>UFW ä½¿ç”¨èŒƒä¾‹</h3><p>å…è®¸ 53 ç«¯å£ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw allow 53</span><br></pre></td></tr></tbody></table></figure>
<p>ç¦ç”¨ 53 ç«¯å£ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw delete allow 53</span><br></pre></td></tr></tbody></table></figure>
<p>å…è®¸ 80 ç«¯å£ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw allow 80/tcp</span><br></pre></td></tr></tbody></table></figure>
<p>ç¦ç”¨ 80 ç«¯å£ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw delete allow 80/tcp</span><br></pre></td></tr></tbody></table></figure>
<p>å…è®¸ smtp ç«¯å£ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw allow smtp</span><br></pre></td></tr></tbody></table></figure>
<p>åˆ é™¤ smtp ç«¯å£çš„è®¸å¯ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw delete allow smtp</span><br></pre></td></tr></tbody></table></figure>
<p>å…è®¸æŸç‰¹å®š IPï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw allow from 192.168.254.254</span><br></pre></td></tr></tbody></table></figure>
<p>åˆ é™¤ä¸Šé¢çš„è§„åˆ™ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo ufw delete allow from 192.168.254.254</span><br></pre></td></tr></tbody></table></figure>
<p>Linux 2.4 å†…æ ¸ä»¥åæä¾›äº†ä¸€ä¸ªéå¸¸ä¼˜ç§€çš„é˜²ç«å¢™å·¥å…·ï¼šnetfilter/iptablesã€‚å®ƒå…è´¹ä¸”åŠŸèƒ½å¼ºå¤§ï¼Œå¯ä»¥å¯¹æµå…¥å’Œæµå‡ºçš„ä¿¡æ¯è¿›è¡Œç»†åŒ–æ§åˆ¶ï¼Œå®ç°é˜²ç«å¢™ã€NATï¼ˆç½‘ç»œåœ°å€ç¿»è¯‘ï¼‰å’Œæ•°æ®åŒ…çš„åˆ†å‰²ç­‰åŠŸèƒ½ã€‚netfilter å·¥ä½œåœ¨å†…æ ¸å†…éƒ¨ï¼Œè€Œ iptables åˆ™æ˜¯è®©ç”¨æˆ·å®šä¹‰è§„åˆ™é›†çš„è¡¨ç»“æ„ã€‚</p>
<p>ä½†æ˜¯ iptables çš„è§„åˆ™ç¨å¾®æœ‰äº›å¤æ‚ï¼Œå› æ­¤ Ubuntu æä¾›äº† UFW è¿™ä¸ªè®¾å®šå·¥å…·ï¼Œä»¥ç®€åŒ– iptables çš„æŸäº›è®¾å®šï¼Œå…¶åå°ä»ç„¶æ˜¯ iptablesã€‚UFW å³ Uncomplicated Firewall çš„ç®€ç§°ï¼Œä¸€äº›å¤æ‚çš„è®¾å®šè¿˜æ˜¯éœ€è¦ä½¿ç”¨ iptablesã€‚</p>
<p>UFW ç›¸å…³çš„æ–‡ä»¶å’Œæ–‡ä»¶å¤¹æœ‰ï¼š</p>
<ul>
<li><code>/etc/ufw/</code>ï¼šåŒ…å«ä¸€äº› UFW çš„ç¯å¢ƒè®¾å®šæ–‡ä»¶ï¼Œå¦‚ <code>before.rules</code>ã€<code>after.rules</code>ã€<code>sysctl.conf</code>ã€<code>ufw.conf</code>ï¼Œä»¥åŠç”¨äº IPv6 çš„ <code>before6.rules</code> å’Œ <code>after6.rules</code>ã€‚è¿™äº›æ–‡ä»¶ä¸€èˆ¬æŒ‰ç…§é»˜è®¤è®¾ç½®è¿›è¡Œå³å¯ã€‚</li>
<li>å¦‚æœåœ¨å¯ç”¨ UFW åï¼Œ<code>/etc/ufw/sysctl.conf</code> è¦†ç›–äº†é»˜è®¤çš„ <code>/etc/sysctl.conf</code> æ–‡ä»¶ï¼Œå¦‚æœåœ¨ <code>/etc/ufw/sysctl.conf</code> ä¸­æœ‰æ–°çš„èµ‹å€¼ï¼Œåˆ™ä¼šè¦†ç›– <code>/etc/sysctl.conf</code>ï¼Œå¦åˆ™ä»¥ <code>/etc/sysctl.conf</code> çš„è®¾ç½®ä¸ºå‡†ã€‚ä½ å¯ä»¥é€šè¿‡ä¿®æ”¹ <code>/etc/default/ufw</code> ä¸­çš„ <code>IPT_SYSCTL=</code> æ¡ç›®æ¥è®¾ç½®ä½¿ç”¨å“ªä¸ª sysctrl.confã€‚</li>
<li><code>/var/lib/ufw/user.rules</code>ï¼šè¿™ä¸ªæ–‡ä»¶ä¸­åŒ…å«æˆ‘ä»¬è®¾ç½®çš„ä¸€äº›é˜²ç«å¢™è§„åˆ™ï¼Œä½ å¯ä»¥ç›´æ¥ä¿®æ”¹è¿™ä¸ªæ–‡ä»¶æ¥è¿›è¡Œè®¾å®šã€‚ä¿®æ”¹åéœ€è¦ä½¿ç”¨ <code>ufw reload</code> å‘½ä»¤é‡å¯ UFW ä»¥ä½¿æ–°è§„åˆ™ç”Ÿæ•ˆã€‚</li>
</ul>
<p>ä¸‹é¢æ˜¯ UFW å‘½ä»¤è¡Œçš„ä¸€äº›ç¤ºä¾‹ï¼š</p>
<ul>
<li><code>ufw enable/disable</code>ï¼šæ‰“å¼€/å…³é—­ UFW</li>
<li><code>ufw status</code>ï¼šæŸ¥çœ‹å·²ç»å®šä¹‰çš„ UFW è§„åˆ™</li>
<li><code>ufw default allow/deny</code>ï¼šå¤–æ¥è®¿é—®é»˜è®¤å…è®¸/æ‹’ç»</li>
<li><code>ufw allow/deny 20</code>ï¼šå…è®¸/æ‹’ç»è®¿é—® 20 ç«¯å£ï¼ˆ<code>20</code> åå¯è·Ÿ <code>/tcp</code> æˆ– `/udp</li>
</ul>
<p>`ï¼Œè¡¨ç¤º TCP æˆ– UDP å°åŒ…ï¼‰</p>
<ul>
<li><code>ufw allow/deny servicename</code>ï¼šUFW ä» <code>/etc/services</code> ä¸­æ‰¾åˆ°å¯¹åº”æœåŠ¡çš„ç«¯å£è¿›è¡Œè¿‡æ»¤</li>
<li><code>ufw allow proto tcp from 10.0.1.0/10 to æœ¬æœºip port 25</code>ï¼šå…è®¸æ¥è‡ª <code>10.0.1.0/10</code> çš„ TCP å°åŒ…è®¿é—®æœ¬æœºçš„ 25 ç«¯å£</li>
<li><code>ufw delete allow/deny 20</code>ï¼šåˆ é™¤ä»¥å‰å®šä¹‰çš„å…è®¸/æ‹’ç»è®¿é—® 20 ç«¯å£çš„è§„åˆ™</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>CUDAç¼–ç¨‹å­¦ä¹ ï¼šè‡ªå®šä¹‰Pytorch+cpp/cuda extension</title>
    <url>/2023/12/12/CUDA/Pytorch+cppcuda%20extension%20%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<p>è§†é¢‘èµ„æ–™ï¼š </p>
<p><a href="https://www.youtube.com/watch?v=l_Rpk6CRJYI&amp;list=PLDV2CyUo4q-LKuiNltBqCKdO9GH4SS_ec&amp;ab_channel=AI%E8%91%B5">Pytorch+cpp/cuda extension æ•™å­¸</a></p>
<p>Githubï¼š</p>
<p><a href="https://github.com/Kedreamix/pytorch-cppcuda-tutorial">https://github.com/Kedreamix/pytorch-cppcuda-tutorial</a></p>
<p>Pytorchå®˜æ–¹èµ„æ–™ï¼š</p>
<p><a href="https://pytorch.org/cppdocs/">PyTorch C++ API - PyTorch main documentation</a></p>
<p><a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">pytorch.org/tutorials/advanced/cpp_extension.html</a></p>
<p>CUDA docï¼š</p>
<p><a href="https://nyu-cds.github.io/python-gpu/02-cuda/">Introduction to GPU</a></p>
<h2 id="å­¦ä¹ èƒŒæ™¯"><a href="#å­¦ä¹ èƒŒæ™¯" class="headerlink" title="å­¦ä¹ èƒŒæ™¯"></a>å­¦ä¹ èƒŒæ™¯</h2><p>è™½ç„¶è¯´PyTorchæä¾›äº†ä¸°å¯Œçš„ä¸ç¥ç»ç½‘ç»œã€å¼ é‡ä»£æ•°ã€æ•°æ®å¤„ç†ç­‰ç›¸å…³çš„æ“ä½œï¼Œä½†æ˜¯æœ‰æ—¶å€™ä½ å¯èƒ½éœ€è¦<strong>æ›´å®šåˆ¶åŒ–çš„æ“ä½œ</strong>ï¼Œæ¯”å¦‚ä½¿ç”¨è®ºæ–‡ä¸­çš„æ–°å‹æ¿€æ´»å‡½æ•°ï¼Œæˆ–è€…å®ç°ä½œä¸ºç ”ç©¶ä¸€éƒ¨åˆ†å¼€å‘çš„æ“ä½œã€‚åœ¨PyTorchä¸­ï¼Œæœ€ç®€å•çš„é›†æˆè‡ªå®šä¹‰æ“ä½œçš„æ–¹å¼æ˜¯åœ¨Pythonä¸­ç¼–å†™ï¼Œé€šè¿‡æ‰©å±•Functionå’ŒModuleæ¥å®ç°ï¼Œè¿™ä½¿æˆ‘ä»¬å¯ä»¥å……åˆ†åˆ©ç”¨è‡ªåŠ¨å¾®åˆ†<code>autograd</code>çš„åŠŸèƒ½ï¼Œ<strong>ç„¶è€Œæœ‰æ—¶å€™ä»£ç åœ¨æ¨¡å‹ä¸­è¢«é¢‘ç¹è°ƒç”¨æˆ–è€…è°ƒç”¨ä»£ä»·æ¯”è¾ƒå¤§ï¼Œæˆ‘ä»¬å°±å¯èƒ½éœ€è¦åœ¨C++ä¸­è¿›è¡Œå®ç°ã€‚å¦ä¸€ä¸ªå¯èƒ½çš„åŸå› å¯èƒ½éœ€è¦ä¾èµ–äºå…¶ä»–çš„C++åº“ï¼Œä¸ºäº†è§£å†³è¿™ç§æƒ…å†µï¼ŒPyTorchæä¾›äº†ä¸€ç§éå¸¸ç®€å•çš„æ–¹å¼æ¥ç¼–å†™è‡ªå®šä¹‰C++æ‰©å±•ã€‚</strong></p>
<p>ç®€å•ä»‹ç»ä¸€ä¸‹Pytorch C++çš„APIéƒ¨åˆ†ï¼Œä¸»è¦æœ‰ä»¥ä¸‹äº”éƒ¨åˆ†</p>
<ol>
<li><strong>ATenï¼š</strong> ä½œä¸ºåŸºç¡€å¼ é‡å’Œæ•°å­¦æ“ä½œåº“ï¼Œæ‰€æœ‰å…¶ä»–æ¥å£éƒ½æ„å»ºåœ¨å…¶ä¸Šã€‚</li>
<li><strong>Autogradï¼š</strong> é€šè¿‡è‡ªåŠ¨å¾®åˆ†å¢å¼ºäº†ATenï¼Œè®°å½•å¼ é‡ä¸Šçš„æ“ä½œä»¥å½¢æˆè‡ªåŠ¨å¾®åˆ†å›¾ã€‚</li>
<li><strong>C++ Frontendï¼š</strong> æä¾›äº†ç”¨äºç¥ç»ç½‘ç»œå’Œæœºå™¨å­¦ä¹ æ¨¡å‹çš„é«˜çº§çº¯C++å»ºæ¨¡æ¥å£ã€‚</li>
<li><strong>TorchScriptï¼š</strong> æ˜¯ä¸€ä¸ªå¯ä»¥ç”±TorchScriptç¼–è¯‘å™¨ç†è§£ã€ç¼–è¯‘å’Œåºåˆ—åŒ–çš„PyTorchæ¨¡å‹è¡¨ç¤ºã€‚</li>
<li><strong>C++ Extensionsï¼š</strong> ç”¨äºæ‰©å±•Python APIçš„è‡ªå®šä¹‰C++å’ŒCUDAä¾‹ç¨‹ã€‚</li>
</ol>
<p>è¿™äº›å—ç»„åˆå½¢æˆäº†ä¸€ä¸ªC++åº“ï¼Œå¯ç”¨äºå¼ é‡è®¡ç®—å’Œå…·æœ‰é«˜æ•ˆçš„GPUåŠ é€Ÿä»¥åŠå¿«é€ŸCPUæ€§èƒ½çš„åŠ¨æ€ç¥ç»ç½‘ç»œã€‚</p>
<blockquote>
<p>åœ¨è¿™éƒ¨åˆ†ä¸­ï¼ŒATenæ˜¯ä¸€ä¸ªåŸºç¡€å¼ é‡åº“ï¼Œå‡ ä¹æ‰€æœ‰PyTorchçš„Pythonå’ŒC++æ¥å£éƒ½æ„å»ºåœ¨å…¶ä¸Šã€‚Autogradæ˜¯C++ APIçš„ä¸€éƒ¨åˆ†ï¼Œç”¨äºä¸ºATenå¼ é‡ç±»æ·»åŠ è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½ã€‚æˆ‘ä»¬ç¼–å†™C++çš„æ‰©å±•çš„æ—¶å€™ï¼Œæˆ‘ä»¬å®é™…ä¸Šæ˜¯åŸºäºATenè¿›è¡Œæ“ä½œå’Œä¹¦å†™çš„ã€‚</p>
</blockquote>
<h2 id="é€‚ç”¨å¯¹è±¡ä¸åœºæ™¯"><a href="#é€‚ç”¨å¯¹è±¡ä¸åœºæ™¯" class="headerlink" title="é€‚ç”¨å¯¹è±¡ä¸åœºæ™¯"></a>é€‚ç”¨å¯¹è±¡ä¸åœºæ™¯</h2><p>å®é™…ä¸Špytorch+cudaæ˜¯ä¸ºäº†åŠ é€Ÿpytorchçš„è®¡ç®—ï¼Œå¦‚æœpytorchçš„è®¡ç®—å·²ç»å¯ä»¥æ»¡è¶³äº†ï¼Œå°±å¯ä»¥è·³è¿‡è¿™ä¸€éƒ¨åˆ†ï¼Œå› ä¸ºæœ¬èº«pytorchä¹Ÿå·²ç»è•´å«äº†å¾ˆå¤šçš„å‡½æ•°</p>
<ul>
<li><p><strong>éå¹³è¡Œè¿ç®— non parallel computation</strong>ï¼šåœ¨è¿™æ ·çš„åœºæ™¯ä¸‹ï¼Œæ¯”å¦‚ç°åœ¨ä¸€ä¸ªbatché‡Œé¢ï¼Œéƒ½æ˜¯å¹³è¡Œè¿ç®—ï¼Œæ‰€ä»¥è¿™æ—¶å€™å¯ä»¥ç›´æ¥ç”¨pytorchè¿›è¡Œå®ç°ï¼Œä½†æ˜¯åœ¨NeRFçš„ä½“æ¸²æŸ“volume renderingä¸­ï¼Œæˆ‘ä»¬å°±å¯ä»¥çŸ¥é“ï¼Œæ¯ä¸€æ¡å°„çº¿å¯èƒ½é‡‡æ ·çš„ç‚¹éƒ½æ˜¯ä¸ä¸€æ ·çš„ï¼Œå¦‚æœæˆ‘ä»¬å»ç”¨forå¾ªç¯å°±å¯èƒ½éœ€è¦èŠ±æ¯”è¾ƒå¤šçš„æ—¶é—´ï¼Œè¿™æ—¶å€™å°±éœ€è¦cudaçš„å­˜åœ¨ã€‚</p>
</li>
<li><p><strong>å¤§é‡çš„ä¸²åˆ—è®¡ç®— lots of sequential computation</strong>ï¼šæ¯”å¦‚ç¥ç»ç½‘ç»œçš„å·ç§¯å±‚çš„è®¡ç®—çš„ï¼Œæ¯”å¦‚åœ¨forwardä¸­ï¼Œç»å¸¸ä¼šå‡ºç°ä»¥ä¸‹è¿™æ ·çš„æƒ…å†µ</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">x = f1(x)</span><br><span class="line">x = f2(x)</span><br><span class="line">...</span><br><span class="line">x = fn(x)</span><br></pre></td></tr></tbody></table></figure>
<p>å¦‚æœåœ¨å±‚æ•°æ¯”è¾ƒå°çš„æ—¶å€™ï¼Œè¿™æ ·æ˜¯å¯ä»¥å¾—åˆ°ä¸é”™çš„ç»“æœçš„ï¼Œä½†æ˜¯å±‚æ•°æ¯”è¾ƒå¤§çš„æ—¶å€™ï¼Œä¸æ–­çš„å†…å­˜è®¿é—®å…¶å®ä¼šå‡æ…¢é€Ÿåº¦ï¼Œè¿™æ—¶å€™å°±éœ€è¦CUDAæ¥è¿›è¡ŒåŠ é€Ÿï¼Œæ¯”å¦‚æˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰çš„få˜æˆä¸€ä¸ªå‡½æ•°Fï¼Œèåˆäº†æ‰€æœ‰çš„å‡½æ•°åï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œä¸€æ¬¡è¿ç®—å¾—åˆ°æœ€åçš„ç»“æœï¼Œåœ¨å±‚æ•°å¤§çš„æ—¶å€™èƒ½å¾—åˆ°å¾ˆå¤§çš„æå‡ã€‚</p>
</li>
</ul>
<p>åœ¨è¿™ä¸€éƒ¨åˆ†çš„å­¦ä¹ ä¸­ï¼Œä¸»è¦è¿˜æ˜¯åœ¨ç¬¬ä¸€ä¸ªåœºæ™¯ï¼Œéå¹³è¡Œè¿ç®—ï¼Œç‰¹åˆ«æ˜¯NeRFçš„ä½“æ¸²æŸ“éƒ¨åˆ†ï¼Œè¿™ä¸€éƒ¨åˆ†çš„å­¦ä¹ å’ŒåŠ é€Ÿè¿˜æ˜¯éå¸¸é‡è¦çš„ï¼Œå€¼å¾—å­¦ä¹ ã€‚</p>
<h2 id="Pytorchå’ŒCUDAçš„å…³ç³»"><a href="#Pytorchå’ŒCUDAçš„å…³ç³»" class="headerlink" title="Pytorchå’ŒCUDAçš„å…³ç³»"></a>Pytorchå’ŒCUDAçš„å…³ç³»</h2><p>ä¸€èˆ¬æ¥è¯´ï¼Œæ˜¯pytorch -&gt; C++ &gt; cudaï¼Œä¹Ÿå°±æ˜¯pytorchè°ƒç”¨C++ï¼Œç„¶åC++å†è°ƒç”¨cudaï¼Œæ‰€ä»¥C++ä½œä¸ºçš„æ˜¯ä¸€ä¸ªæ¡¥æ¢ï¼Œæ‰€ä»¥æ¯”è¾ƒé‡è¦çš„cudaï¼Œè€Œä¸æ˜¯C++ï¼Œåˆ©ç”¨cudaè¿›è¡Œå¹³è¡Œçš„è®¡ç®—ã€‚</p>
<p><img src="https://img-blog.csdnimg.cn/direct/64f3116d776247ae975479b252554c0a.png" alt="Pytorchå’ŒCUDAçš„å…³ç³»"></p>
<h2 id="Pythonè°ƒç”¨C-å‡½æ•°ï¼ˆæ¡¥æ¢ï¼‰"><a href="#Pythonè°ƒç”¨C-å‡½æ•°ï¼ˆæ¡¥æ¢ï¼‰" class="headerlink" title="Pythonè°ƒç”¨C++å‡½æ•°ï¼ˆæ¡¥æ¢ï¼‰"></a>Pythonè°ƒç”¨C++å‡½æ•°ï¼ˆæ¡¥æ¢ï¼‰</h2><p>é¦–å…ˆå£°æ˜ä¸€ä¸‹ï¼Œæˆ‘çš„æ–‡ä»¶å¤¹æ ¼å¼å¦‚ä¸‹ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pytorch-cppcuda-tutorial/</span><br><span class="line">  test.py</span><br><span class="line">  setup.py</span><br><span class="line">  interpolation.cpp</span><br><span class="line">  interpolation_kernel.cu</span><br><span class="line">  include/</span><br><span class="line">    utils.h</span><br></pre></td></tr></tbody></table></figure>
<p><strong>æœ‰ä¸€ä¸ªé—®é¢˜å¯èƒ½æˆ‘ä»¬ä¼šç–‘æƒ‘å¾ˆä¹…ï¼Œå°±æ˜¯pythonæ˜¯æ€ä¹ˆè°ƒç”¨C++å’ŒCUDAçš„ï¼Œè¿™é‡Œé¢æ ¹æ®è¯¾ç¨‹ç®€å•æ¥è®²ä¸€ä¸‹ï¼Œä»¥ä¸‰çº¿æ€§æ’å€¼ä¸ºä¾‹å­</strong></p>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç®€å•çš„å‡½æ•°ã€‚è¿™ä¸ªå‡½æ•°æ¥å—ä¸¤ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯ç‰¹å¾å’Œç‚¹ï¼Œç„¶åç›´æ¥è¿”å›ç‰¹å¾ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†çœ‹åˆ°ä¸€ä¸ªæ ¸å¿ƒçš„ä¸œè¥¿ï¼Œå³ <code>PYBIND11_MODULE</code>ã€‚è¿™æ˜¯ Python è°ƒç”¨ C++ å‡½æ•°çš„å…³é”®éƒ¨åˆ†ã€‚è¿™ä¸ªå‡½æ•°ä¼šåœ¨Pythonæ‰§è¡Œ<code>import</code>è¯­å¥æ—¶è¢«è°ƒç”¨ï¼Œå…¶æ¥å—ä¸¤ä¸ªå‚æ•°ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä¸ºæ¨¡å—åç§°ï¼Œè¿™é‡Œæˆ‘ä»¬ç›´æ¥å°†<code>trilinear_interpolation</code>å¡«å…¥ï¼Œç¨å€™å¯ä»¥åœ¨Pythonä¸­ä½¿ç”¨<code>import cppcuda_tutorial</code>å¯¼å…¥è¯¥æ¨¡å—ï¼›ç¬¬äºŒä¸ªå‚æ•°<code>m</code>æ˜¯åˆ›å»ºPythonå…³è”ä»£ç çš„ä¸»æ¥å£ï¼Œå…¶ç±»å‹ä¸º<code>py::module_</code>ã€‚<code>module_::def()</code>ç”¨äºç”Ÿæˆèƒ½å¤Ÿå°†<code>trilinear_interpolation</code>å‡½æ•°æš´éœ²ç»™Pythonçš„ä»£ç ï¼Œå…¶ç¬¬ä¸€ä¸ªå‚æ•°ä¸º<strong>å­—ç¬¦ä¸²</strong>ï¼Œå°†ä¼šæˆä¸ºPythonä¸­è°ƒç”¨çš„å‡½æ•°åï¼›ç¬¬äºŒä¸ªå‚æ•°æ˜¯<strong>C++å‡½æ•°</strong>çš„å¼•ç”¨ï¼›ç¬¬ä¸‰ä¸ªå‚æ•°æ˜¯<strong>è¯´æ˜å­—ç¬¦ä¸²</strong>ï¼Œåœ¨Pythonä¸­å¯ä»¥ä½¿ç”¨<code>help(trilinear_interpolation)</code>æŸ¥çœ‹ã€‚æ¯”å¦‚ä¸‹é¢çš„ä¾‹å­ä¸­ï¼ŒC++ ä¸­çš„å‡½æ•° <code>trilinear_interpolation</code> å¯¹åº” Python ä¸­çš„ <code>trilinear_interpolation</code>ã€‚</p>
<blockquote>
<p><strong><torch extension.h=""></torch></strong>æ˜¯ä¸€ç«™å¼å¤´æ–‡ä»¶ï¼ŒåŒ…å«å†™å…¥C++æ‰©å±•æ‰€éœ€çš„æ‰€æœ‰PyTorchæ“ä½œï¼ŒåŒ…æ‹¬ï¼š</p>
<ul>
<li>ATenåº“æ˜¯ç”¨äºå¼ é‡è®¡ç®—çš„ä¸»è¦APIï¼Œ</li>
<li>pybind11ï¼Œæ˜¯ä¸ºC++ä»£ç åˆ›å»ºPythonç»‘å®šçš„æ–¹å¼</li>
<li>ç®¡ç†ATenå’Œpybind11ä¹‹é—´äº¤äº’ç»†èŠ‚çš„å¤´æ–‡ä»¶</li>
</ul>
<p>PyTorchçš„å¼ é‡å’Œå˜é‡æ¥å£æ˜¯ä»ATenåº“è‡ªåŠ¨ç”Ÿæˆçš„ï¼Œå› æ­¤å‡ ä¹å¯ä»¥å°†Pythonå®ç°1:1è½¬æ¢ä¸ºC++ã€‚æ‰€æœ‰è®¡ç®—çš„ä¸»è¦æ•°æ®ç±»å‹å°†æ˜¯torch::Tensorã€‚</p>
</blockquote>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;torch/extension.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">torch::Tensor <span class="title">trilinear_interpolation</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor point</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>{</span><br><span class="line">    <span class="keyword">return</span> feats;</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(TORCH_EXTENSION_NAME, m){</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">"trilinear_interpolation"</span>, &amp;trilinear_interpolation);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><strong>æ³¨æ„ï¼šTORCH_EXTENSION_NAMEï¼Œtorchæ‰©å±•æ„å»ºä¼šå°†å…¶å®šä¹‰ä¸ºåœ¨setup.pyè„šæœ¬ä¸­ä¸ºæ‰©å±•æŒ‡å®šçš„åç§°ã€‚æ¯”å¦‚è¿™é‡Œä¸ºâ€œTORCH_EXTENSION_NAMEâ€œï¼Œä¸¤è€…ä¹‹é—´çš„ä¸åŒ¹é…å¯èƒ½ä¼šå¯¼è‡´ä¸¥é‡ä¸”éš¾ä»¥è·Ÿè¸ªçš„é—®é¢˜ã€‚</strong></p>
<p>C++æ‰©å±•ä¸€èˆ¬æœ‰ä¸¤ç§æ–¹å¼</p>
<ul>
<li>é€šè¿‡<code>setuptools</code>â€œæå‰â€æ„å»º</li>
<li>é€šè¿‡<code>torch.utils.cpp_extension.load()</code>â€œå®æ—¶â€æ„å»º</li>
</ul>
<h3 id="Building-with-setuptools"><a href="#Building-with-setuptools" class="headerlink" title="Building with setuptools"></a>Building with <code>setuptools</code></h3><p>æ¥ä¸‹æ¥å…ˆè¯•ç”¨<code>setuptools</code>è¿›è¡Œæ„å»ºï¼Œç¼–å†™ä¸€ä¸ª <code>setup.py</code> æ–‡ä»¶ï¼Œä¸»è¦ç”¨äºå®šä¹‰å’Œè¯´æ˜ä¸€äº›é‡è¦çš„ä¿¡æ¯ã€‚å…¶ä¸­å…³é”®çš„å‚æ•°åŒ…æ‹¬ï¼š</p>
<ul>
<li><code>name</code>ï¼šPython è°ƒç”¨çš„åŒ…çš„åç§°ã€‚</li>
<li><code>ext_modules</code> çš„ <code>sources</code>ï¼šéœ€è¦ç¼–è¯‘çš„ C++ æºæ–‡ä»¶ï¼Œå¦‚æœæœ‰å¤šä¸ª C++ æ–‡ä»¶ï¼Œéœ€è¦åˆ—ä¸¾æ‰€æœ‰ã€‚</li>
<li><code>cmdclass</code>ï¼šç”¨BuildExtensionæ‰§è¡Œè®¸å¤šå¿…éœ€çš„é…ç½®æ­¥éª¤å’Œæ£€æŸ¥ï¼Œå¹¶åœ¨æ··åˆC++/CUDAæ‰©å±•çš„æƒ…å†µä¸‹å¤„ç†æ··åˆç¼–è¯‘ã€‚</li>
</ul>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line">from setuptools <span class="keyword">import</span> setup</span><br><span class="line">from torch.utils.cpp_extension <span class="keyword">import</span> CppExtension, <span class="function">BuildExtension</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">setup</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    name=<span class="string">'cppcuda_tutorial'</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    version=<span class="string">'1.0'</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    author=<span class="string">'xxx'</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    author_email=<span class="string">'xxx@gmail.com'</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    description=<span class="string">'cppcuda example'</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    long_description=<span class="string">'cppcuda example'</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    ext_modules=[</span></span></span><br><span class="line"><span class="params"><span class="function">        CppExtension(</span></span></span><br><span class="line"><span class="params"><span class="function">            name=<span class="string">'cppcuda_tutorial'</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            sources=[<span class="string">'interpolation.cpp'</span>])</span></span></span><br><span class="line"><span class="params"><span class="function">    ],</span></span></span><br><span class="line"><span class="params"><span class="function">    cmdclass={</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="string">'build_ext'</span>: BuildExtension</span></span></span><br><span class="line"><span class="params"><span class="function">    }</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="JIT-Compiling-Extensions"><a href="#JIT-Compiling-Extensions" class="headerlink" title="JIT Compiling Extensions"></a>JIT Compiling Extensions</h3><p>é™¤äº†ä¸Šè¿°çš„<code>setuptools</code>çš„æ–¹æ³•ï¼Œæ¥ä¸‹æ¥ä»‹ç»å³æ—¶ç¼–è¯‘ï¼ˆJITï¼‰æœºåˆ¶æ„å»ºC++æ‰©å±•ã€‚JITç¼–è¯‘æœºåˆ¶é€šè¿‡è°ƒç”¨PyTorch APIä¸­çš„ä¸€ä¸ªç®€å•å‡½æ•°<code>torch.utils.cpp_extension.load()</code>ï¼Œä¸ºä½ æä¾›äº†ä¸€ç§å³æ—¶ç¼–è¯‘å’ŒåŠ è½½æ‰©å±•çš„æ–¹å¼ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> load</span><br><span class="line"></span><br><span class="line">cppcuda_tutorial = load(name=<span class="string">"cppcuda_tutorial"</span>,</span><br><span class="line">                        <span class="comment"># extra_include_paths=include_dirs,</span></span><br><span class="line">                        sources=[<span class="string">'interpolation.cpp'</span>],)</span><br></pre></td></tr></tbody></table></figure>
<p>åœ¨è¿™é‡Œï¼Œå®é™…æä¾›çš„æ˜¯åŸŸsetuptoolsç›¸åŒçš„ä¿¡æ¯ã€‚åœ¨åå°ï¼Œè¿™å°†æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š</p>
<ol>
<li>åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½•<code>/tmp/torch_extensions/cppcuda_tutorial</code>ï¼Œ</li>
<li>å‘è¯¥ä¸´æ—¶ç›®å½•å‘å‡ºNinjaæ„å»ºæ–‡ä»¶ï¼Œ</li>
<li>å°†ä½ çš„æºæ–‡ä»¶ç¼–è¯‘æˆä¸€ä¸ªå…±äº«åº“ï¼Œ</li>
<li>å°†è¿™ä¸ªå…±äº«åº“å¯¼å…¥ä¸ºPythonæ¨¡å—ã€‚</li>
</ol>
<p>å®é™…ä¸Šï¼Œå¦‚æœå°†<code>verbose=True</code>ä¼ é€’ç»™<code>cpp_extension.load()</code>ï¼Œä½ å°†å¾—åˆ°æœ‰å…³è¯¥è¿‡ç¨‹çš„ä¿¡æ¯ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Using /path/.cache/torch_extensions/py310_cu113 as PyTorch extensions root...</span><br><span class="line">Detected CUDA files, patching ldflags</span><br><span class="line">Emitting ninja build file /path/.cache/torch_extensions/py310_cu113/cppcuda_tutorial/build.ninja...</span><br><span class="line">Building extension module cppcuda_tutorial...</span><br><span class="line">Allowing ninja to <span class="built_in">set</span> a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)</span><br><span class="line">[1/2] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=cppcuda_tutorial -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/path/workdirs/pytorch-cppcuda-tutorial/include -isystem /path/anaconda3/envs/cppcuda/lib/python3.10/site-packages/torch/include -isystem /path/anaconda3/envs/cppcuda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /path/anaconda3/envs/cppcuda/lib/python3.10/site-packages/torch/include/TH -isystem /path/anaconda3/envs/cppcuda/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /path/anaconda3/envs/cppcuda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=<span class="built_in">arch</span>=compute_86,code=compute_86 -gencode=<span class="built_in">arch</span>=compute_86,code=sm_86 --compiler-options <span class="string">'-fPIC'</span> -std=c++14 -c /path/workdirs/pytorch-cppcuda-tutorial/interpolation_kernel.cu -o interpolation_kernel.cuda.o </span><br><span class="line">[2/2] c++ interpolation.o interpolation_kernel.cuda.o -shared -L/path/anaconda3/envs/cppcuda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o cppcuda_tutorial.so</span><br></pre></td></tr></tbody></table></figure>
<p>å®Œæˆè¿™ä¸€æ­¥åï¼Œå¦‚æœä½¿ç”¨<code>setuptools</code>è¿›è¡Œæ„å»ºï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ <code>pip</code> è¿›è¡Œå®‰è£…ã€‚å¦‚æœåœ¨å½“å‰æ–‡ä»¶å¤¹ä¸‹ï¼Œç›´æ¥è¿è¡Œ <code>pip install .</code> å³å¯å®Œæˆå®‰è£…æˆ–è€…æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨<code>python set.py install</code>ï¼Œå®‰è£…æˆåŠŸååº”è¯¥ä¼šæ˜¾ç¤ºä»¥ä¸‹ç»“æœï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Processing path/pytorch-cppcuda-tutorial</span><br><span class="line">  Preparing metadata (setup.py) ... <span class="keyword">done</span></span><br><span class="line">Building wheels <span class="keyword">for</span> collected packages: cppcuda-tutorial</span><br><span class="line">  Building wheel <span class="keyword">for</span> cppcuda-tutorial (setup.py) ... <span class="keyword">done</span></span><br><span class="line">  Created wheel <span class="keyword">for</span> cppcuda-tutorial: filename=cppcuda_tutorial-1.0-cp310-cp310-linux_x86_64.whl size=74123 sha256=3029b98bd3b49bed65f42640e60932c38379f15db48a5187fe40610b525307c9</span><br><span class="line">  Stored <span class="keyword">in</span> directory: /path/.cache/pip/wheels/65/53/4a/5e2c10d11e3a657b9efae376ccce3277e5535d691dd4659883</span><br><span class="line">Successfully built cppcuda-tutorial</span><br><span class="line">Installing collected packages: cppcuda-tutorial</span><br><span class="line">Successfully installed cppcuda-tutorial-1.0</span><br></pre></td></tr></tbody></table></figure>
<p>å®Œæˆä»¥ä¸Šæ­¥éª¤åï¼Œæˆ‘ä»¬å¯ä»¥ç¼–å†™ä¸€ä¸ª <code>test.py</code> æ–‡ä»¶æ¥æµ‹è¯•ä»£ç çš„æ­£ç¡®æ€§ã€‚åªè¦èƒ½å¤ŸæˆåŠŸè¿è¡Œï¼Œå°±ä»£è¡¨ä¸€åˆ‡æ­£å¸¸ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cppcuda_tutorial <span class="comment"># ä½ç½®éœ€è¦åœ¨import torchåé¢</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">feats = torch.ones(<span class="number">2</span>)</span><br><span class="line">point = torch.zeros(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># è°ƒç”¨å‡½æ•°</span></span><br><span class="line">out = cppcuda_tutorial.trilinear_interpolation(feats, point)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(out)</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™é‡Œé¢è¦æ³¨æ„çš„å°±æ˜¯ï¼Œé¦–å¸­çˆ±ä½ è¦å¯¼å…¥torchï¼Œè§£æåŠ¨æ€é“¾æ¥å™¨å¿…é¡»çœ‹åˆ°çš„ä¸€äº›ç¬¦å·</p>
<h2 id="CUDAåŠ é€Ÿçš„åŸç†"><a href="#CUDAåŠ é€Ÿçš„åŸç†" class="headerlink" title="CUDAåŠ é€Ÿçš„åŸç†"></a>CUDAåŠ é€Ÿçš„åŸç†</h2><p>é¦–å…ˆä»‹ç»ä¸€ä¸ªCUDAç¨‹åºå®ç°çš„æµç¨‹</p>
<ol>
<li>æŠŠæ•°æ®ä»CPUå†…å­˜æ‹·è´åˆ°GPUå†…å­˜</li>
<li>è°ƒç”¨æ ¸å‡½æ•°å¯¹å­˜å‚¨åœ¨GPUå†…å­˜ä¸­çš„æ•°æ®è¿›è¡Œæ“ä½œ</li>
<li>å°†æ•°æ®ä»GPUå†…å­˜ä¼ é€å›CPUå†…å­˜</li>
</ol>
<p><img src="https://pic2.zhimg.com/v2-2959e07a36a8dc8f59280f53b43eb9d1_b.jpg" alt="CUDAç¼–ç¨‹å…¥é—¨æç®€æ•™ç¨‹- çŸ¥ä¹"></p>
<p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œåœ¨åˆ©ç”¨CUDAåŠ é€Ÿçš„æ—¶å€™ï¼Œå›¾çš„å·¦è¾¹æ˜¯CPUï¼Œå³è¾¹æ˜¯GPUï¼Œæˆ‘ä»¬éœ€è¦æŠŠæ•°æ®ä»CPUä¼ åˆ°GPUä¸­ã€‚åœ¨GPUä¸­ï¼Œå°±ä¼šç”Ÿæˆå¯¹åº”çš„Gridæ¥è¿›è¡Œè®¡ç®—ï¼Œæ¯ä¸ªGridé‡Œé¢åˆæœ‰å¾ˆå¤šçš„blockï¼Œä»blockä¸­çœ‹åˆæœ‰å¾ˆå¤šçš„çº¿ç¨‹threadè¿›è¡Œè¿ç®—ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœè®¡ç®—ä¸€ä¸ªçŸ©é˜µçš„åŠ æ³•ï¼Œæˆ‘ä»¬å¯ä»¥è®©æ¯ä¸ªthreadåšå¯¹åº”çš„å…ƒç´ çš„ç›¸åŠ ï¼Œè¿™æ ·å°±å¯ä»¥å¤§å¤§åŠ å¿«è®¡ç®—é€Ÿåº¦ï¼Œè¾¾åˆ°å¹¶è¡Œçš„æ•ˆæœã€‚æ‰€ä»¥è¿™ä¹‹ä¸­å†…æ ¸ï¼ˆkernelï¼‰æ˜¯CUDAç¼–ç¨‹ä¸­ä¸€ä¸ªé‡è¦çš„éƒ¨åˆ†ï¼Œå…¶ä»£ç åœ¨GPUä¸Šè¿è¡Œï¼Œæ¯”å¦‚çŸ©é˜µä¹˜æ³•ï¼Œæˆ‘ä»¬å°±å¯ä»¥å†™ä¸€ä¸ªåŠ æ³•çš„æ ¸å‡½æ•°ï¼Œç„¶åä¸²è¡Œæ‰§è¡Œæ ¸å‡½æ•°ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¿«é€Ÿèƒ½å®ŒæˆCUDAä»£ç çš„ç¼–å†™ï¼Œè€Œä¸ç”¨åœ¨åˆ›å»ºå’Œç®¡ç†å¤§é‡çš„GPUçº¿ç¨‹æ—¶æ‹˜æ³¥äºç»†èŠ‚ã€‚</p>
<p><img src="https://nyu-cds.github.io/python-gpu/fig/02-threadmapping.png" alt="Thread Mapping"></p>
<p>æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œå®é™…ä¸ŠCUDAçš„è®¡ç®—æ˜¯<code>Grid</code>â€”â€”ã€‹<code>Block</code>â€”â€”ã€‹<code>Thread</code>ï¼Œç„¶åç”¨å¤šä¸ª<code>Thread</code>è¿›è¡Œè®¡ç®—ï¼Œè¿™é‡Œé¢å¯èƒ½ä¼šç–‘æƒ‘ï¼Œä¸ºä»€ä¹ˆä¸æ˜¯ç›´æ¥<code>Grid</code>â€”â€”ã€‹<code>Thread</code>ï¼Œå®é™…ä¸Šæ˜¯å› ä¸ºç¡¬ä»¶çš„é™åˆ¶æ˜¯<code>Block</code>ä¸Šé™æ˜¯$(2^{31}-1)<em>2^{16}</em>2^{16}$ï¼Œ<code>Thread</code>çš„ä¸Šé™æ˜¯1024ï¼Œæ‰€ä»¥è¿™æ ·çš„ç»„åˆè®¾è®¡èƒ½å¤Ÿåˆ©ç”¨å¥½æ›´å¤šçš„<code>Thread</code>ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆGPUé€Ÿåº¦é‚£ä¹ˆå¿«çš„åŸå› ã€‚</p>
<h2 id="ä¸‰çº¿æ€§æ’å€¼é—®é¢˜å®šä¹‰"><a href="#ä¸‰çº¿æ€§æ’å€¼é—®é¢˜å®šä¹‰" class="headerlink" title="ä¸‰çº¿æ€§æ’å€¼é—®é¢˜å®šä¹‰"></a>ä¸‰çº¿æ€§æ’å€¼é—®é¢˜å®šä¹‰</h2><p>æœ‰å…³äºçº¿æ€§æ’å€¼å’Œä¸‰çº¿æ€§æ’å€¼çš„ä»‹ç»ï¼Œå¯ä»¥ä»è¿™éƒ¨åˆ†èµ„æ–™è¿›è¡Œäº†è§£ï¼Œ<a href="https://zhuanlan.zhihu.com/p/77496615">https://zhuanlan.zhihu.com/p/77496615</a>ï¼Œ<a href="https://blog.csdn.net/webzhuce/article/details/86585489">https://blog.csdn.net/webzhuce/article/details/86585489</a>ï¼Œè¿™æ ·æˆ‘ä»¬å°±çŸ¥é“ä¸‰çº¿æ€§æ’å€¼çš„æ¦‚å¿µï¼Œå’Œå¤§æ¦‚çš„æ€è·¯ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œä¸€ä¸ªCUDAçš„å®ç°äº†ã€‚</p>
<p><img src="https://img-blog.csdnimg.cn/20190121221016700.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlYnpodWNl,size_16,color_FFFFFF,t_70" alt="ä¸‰çº¿æ€§æ’å€¼"></p>
<p>ä»ä¸‰çº¿æ€§æ’å€¼çš„æ¦‚å¿µæˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼Œæˆ‘ä»¬éœ€è¦ä¼ å…¥ä¸¤ä¸ªå‚æ•°</p>
<ul>
<li>feats(N, 8, F)ï¼šNä¸ªç«‹æ–¹ä½“ï¼Œæ¯ä¸ªç«‹æ–¹ä½“æœ‰8ä¸ªç‚¹ï¼Œæ¯ä¸ªç‚¹æœ‰Fä¸ªç‰¹å¾</li>
<li>Points(N,3)ï¼šNä¸ªç‚¹ï¼Œæ¯ä¸ªç‚¹çš„åæ ‡åˆ†åˆ«æ˜¯xyzï¼Œä¸€å…±æœ‰ä¸‰ä¸ªç»´åº¦ </li>
</ul>
<p>æˆ‘ä»¬ä¹Ÿå¯ä»¥çŸ¥é“è¾“å‡ºçš„å‚æ•°ä¸º<code>feat_interp(N, F)</code>ï¼Œä¹Ÿå°±æ˜¯æ’å€¼åçš„ç»“æœ</p>
<p>ä»ä¸Šè¿°å®šä¹‰æˆ‘ä»¬å°±å¯ä»¥çŸ¥é“ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªéƒ¨åˆ†å¯ä»¥è¿›è¡Œå¹³è¡Œè¿ç®—ï¼Œåˆ†åˆ«æ˜¯Nå’ŒFï¼Œå› ä¸ºå®ƒä»¬æ˜¯ç‹¬ç«‹çš„ï¼Œä¸ä¼šç›¸äº’å½±å“è®¡ç®—ã€‚</p>
<h2 id="C-è°ƒç”¨CUDAå‡½æ•°"><a href="#C-è°ƒç”¨CUDAå‡½æ•°" class="headerlink" title="C++è°ƒç”¨CUDAå‡½æ•°"></a>C++è°ƒç”¨CUDAå‡½æ•°</h2><p>é¦–å…ˆæˆ‘ä»¬å…ˆçœ‹çœ‹ï¼Œæ€ä¹ˆä½¿ç”¨CUDAå»è¿›è¡Œç¼–ç¨‹ï¼Œé¦–å…ˆCUDAçš„ä»£ç æ˜¯<code>cu</code>ç»“å°¾çš„ï¼Œæˆ‘ä»¬é€šè¿‡ç¼–å†™CUDAæ¥è¿›è¡Œä¸€ä¸ªè®¡ç®—åŠ é€Ÿã€‚æˆ‘ä»¬è¿˜æ˜¯å…ˆæŒ‰ä¹‹å‰çš„æ–¹æ³•ï¼Œçœ‹çœ‹å¦‚ä½•ä½¿ç”¨CUDAè¿›è¡Œç¼–ç¨‹å…ˆï¼Œè¿™é‡Œé¢æœ‰å‡ ä¸ªæ³¨æ„çš„ç‚¹ï¼š</p>
<ul>
<li>éœ€è¦ç¼–å†™CUDAå‡½æ•°</li>
<li>éœ€è¦åœ¨å¤´æ–‡ä»¶<code>.h</code>ä¸­å»å®šä¹‰éœ€è¦ä½¿ç”¨çš„å‡½æ•°ï¼ŒåŒ…æ‹¬ä¸€äº›å¸¸ç”¨çš„æµ‹è¯•å‡½æ•°ã€‚</li>
<li>ä¿®æ”¹CUDAçš„<code>setup.py</code></li>
</ul>
<p>æ¥ä¸‹æ¥ä¸€æ­¥ä¸€æ­¥æ¥ï¼Œé¦–å…ˆå†™ä¸€ä¸ª<code>interpolation_kernel.cu</code>å‡½æ•°ï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªCUDAå‡½æ•°ï¼Œåé¢æˆ‘ä»¬å¯ä»¥ç”¨C++è°ƒç”¨CUDAï¼Œè¿™é‡Œé¢è¿˜æ˜¯ç›´æ¥è¿”å›feats</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;torch/extension.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">torch::Tensor <span class="title">trilinear_fw_cu</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor points</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>{</span><br><span class="line">    <span class="keyword">return</span> feats;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±éœ€è¦åœ¨å¤´æ–‡ä»¶<code>utils.h</code>ä¸­å»å®šä¹‰æˆ‘ä»¬åœ¨æ–‡ä»¶ä¸­éœ€è¦ä½¿ç”¨çš„å‡½æ•°ï¼Œç±»ä¼¼äºåŸæœ¬C++çš„ä¸€ä¸ªå£°æ˜å’Œå®šä¹‰å‡½æ•°</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;torch/extension.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK_CUDA(x) TORCH_CHECK(x.is_cuda(), #x <span class="string">" must be a CUDA tensor"</span>)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x <span class="string">" must be contiguous"</span>)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// å£°æ˜å’Œå®šä¹‰å‡½æ•°</span></span><br><span class="line"><span class="function">torch::Tensor <span class="title">trilinear_fw_cu</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor points</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>;</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™æ ·ç¼–å†™ä»¥åï¼Œæˆ‘ä»¬çš„cppçš„ä»£ç å°±å¯ä»¥è°ƒç”¨CUDAå¯¹å‡½æ•°æ¥è¿›è¡Œè°ƒç”¨ï¼Œä½†æ˜¯ç”±äºæˆ‘ä»¬ä½¿ç”¨CUDAçš„å‡½æ•°ï¼Œæ‰€ä»¥è¿™é‡Œé¢æˆ‘ä»¬è¿˜è¦ç”¨åˆ°<code>CHECK_INPUT</code>å‡½æ•°æ¥åˆ¤æ–­æ˜¯å¦åœ¨GPUä¸Šï¼Œä¹Ÿå°±æ˜¯ä¸€ä¸ªæ£€æµ‹ï¼Œå¹¶ä¸”å†…å­˜æ˜¯å¦è¿ç»­ï¼Œå› ä¸ºåç»­è¦è¿›è¡Œä¸€ä¸ªå¹¶è¡Œçš„è®¡ç®—ã€‚</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">"utils.h"</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">torch::Tensor <span class="title">trilinear_interpolation</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor points</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>{</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(feats);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(points);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">trilinear_fw_cu</span>(feats, points);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(TORCH_EXTENSION_NAME, m){</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">"trilinear_interpolation"</span>, &amp;trilinear_interpolation);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>å®Œæˆä¸Šè¿°ç¼–å†™ä¹‹åï¼Œæˆ‘ä»¬æœ€åå°±åªå‰©ä¸‹<code>setup.py</code>å‡½æ•°éœ€è¦ä¿®æ”¹ï¼Œå…¶å®éœ€è¦ä¿®æ”¹çš„ä¸œè¥¿éå¸¸æœ‰é™ï¼Œåªéœ€è¦å°†ä¸Šè¿°çš„<code>CPPExtension</code>æ”¹ä¸º<code>CUDAExtension</code>ï¼Œä¹Ÿå°±æ˜¯æ”¹æˆCUDAçš„ç¼–è¯‘ï¼Œè¿™é‡Œé¢è¿˜æœ‰æ¯”è¾ƒå¥½çš„æ–¹æ³•å°±æ˜¯ï¼Œä¹‹å‰æˆ‘ä»¬sourceéœ€è¦è‡ªå·±å†™ï¼Œä½†æ˜¯å½“æˆ‘ä»¬æœ‰å¾ˆå¤šä¸ªæ–‡ä»¶çš„æ—¶å€™ï¼Œæˆ‘ä»¬å°±å¯ä»¥è‡ªåŠ¨æ£€ç´¢æ–‡ä»¶å¤¹ä¸‹çš„cppå’Œcuæ–‡ä»¶ï¼Œè¿›è¡Œbuildå³å¯å¾—åˆ°æœ€åçš„ç»“æœã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os.path <span class="keyword">as</span> osp</span><br><span class="line"><span class="keyword">from</span> setuptools <span class="keyword">import</span> setup</span><br><span class="line"><span class="keyword">from</span> torch.utils.cpp_extension <span class="keyword">import</span> CUDAExtension, BuildExtension</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ROOT_DIR = osp.dirname(osp.abspath(__file__))</span><br><span class="line">include_dirs = [osp.join(ROOT_DIR, <span class="string">"include"</span>)] <span class="comment"># å¾—åˆ°includeæ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰çš„å¤´æ–‡ä»¶.h</span></span><br><span class="line"></span><br><span class="line">sources = glob.glob(<span class="string">'*.cpp'</span>)+glob.glob(<span class="string">'*.cu'</span>) <span class="comment"># å¾—åˆ°å½“å‰æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰cuæ–‡ä»¶å’Œcppæ–‡ä»¶</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">setup(</span><br><span class="line">    name=<span class="string">'cppcuda_tutorial'</span>,</span><br><span class="line">    version=<span class="string">'1.0'</span>,</span><br><span class="line">    author=<span class="string">'xxx'</span>,</span><br><span class="line">    author_email=<span class="string">'xxx@gmail.com'</span>,</span><br><span class="line">    description=<span class="string">'cppcuda_tutorial'</span>,</span><br><span class="line">    long_description=<span class="string">'cppcuda_tutorial'</span>,</span><br><span class="line">    ext_modules=[</span><br><span class="line">        CUDAExtension(</span><br><span class="line">            name=<span class="string">'cppcuda_tutorial'</span>,</span><br><span class="line">            sources=sources,</span><br><span class="line">            include_dirs=include_dirs,</span><br><span class="line">            extra_compile_args={<span class="string">'cxx'</span>: [<span class="string">'-O2'</span>],</span><br><span class="line">                                <span class="string">'nvcc'</span>: [<span class="string">'-O2'</span>]}</span><br><span class="line">        )</span><br><span class="line">    ],</span><br><span class="line">    cmdclass={</span><br><span class="line">        <span class="string">'build_ext'</span>: BuildExtension</span><br><span class="line">    }</span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure>
<p>å®‰è£…è¿‡åï¼Œæˆ‘ä»¬å°±å¯ä»¥æµ‹è¯•æ˜¯å¦ä½¿ç”¨CUDAè¿›è¡Œè®¡ç®—ï¼Œå”¯ä¸€ä¸åŒçš„æ˜¯ï¼Œç”±äºæˆ‘ä»¬æ˜¯ä½¿ç”¨CUDAè¿›è¡Œè®¡ç®—ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦æŠŠæ•°æ®è½¬åˆ°CUDAä¸­å³å¯</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cppcuda_tutorial</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    feats = torch.ones(<span class="number">2</span>, device=<span class="string">'cuda'</span>)</span><br><span class="line">    points = torch.zeros(<span class="number">2</span>, device=<span class="string">'cuda'</span>)</span><br><span class="line"></span><br><span class="line">    out = cppcuda_tutorial.trilinear_interpolation(feats, points)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(out)</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>åœ¨è¿™é‡Œï¼Œå¯èƒ½ç¬¬ä¸€æ¬¡å­¦ä¹ ä¼šè§‰å¾—æ¯”è¾ƒéº»çƒ¦ï¼Œä½†æ˜¯å®é™…ä¸Šæœ‰ä¸€äº›å‡½æ•°ï¼Œæ¯”å¦‚CHECKçš„å‡½æ•°å’Œsetup.pyçš„å‡½æ•°ï¼Œåªè¦å†™äº†ä¸€æ¬¡ä»¥åï¼Œä¹‹åéƒ½æ˜¯å¯ä»¥å‚è€ƒå¤ç”¨çš„ï¼Œä¸ç”¨é‡å¤å†™</p>
</blockquote>
<h2 id="ä¸‰çº¿æ€§æ’å€¼CUDAå®ç°"><a href="#ä¸‰çº¿æ€§æ’å€¼CUDAå®ç°" class="headerlink" title="ä¸‰çº¿æ€§æ’å€¼CUDAå®ç°"></a>ä¸‰çº¿æ€§æ’å€¼CUDAå®ç°</h2><p>æ¥ä¸‹æ¥å°±æ˜¯ä¸»è¦çš„ä¸‰çº¿æ€§æ’å€¼çš„CUDAå®ç°äº†ï¼Œåœ¨å‰é¢çš„CUDAåŠ é€Ÿä¸­æœ‰è¯´åˆ°ï¼Œå®é™…ä¸Šæˆ‘ä»¬æ˜¯å¸Œæœ›åœ¨æ¯ä¸€ä¸ªthreadéƒ½æ‰§è¡Œä¸€ä¸ªå•å…ƒçš„è®¡ç®—ï¼Œåœ¨ä¸‰çº¿æ€§æ’å€¼ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“ï¼Œæˆ‘ä»¬ä¸¤ä¸ªéƒ¨åˆ†éœ€è¦å¹¶è¡Œï¼Œåˆ†åˆ«æ˜¯<code>N</code>å’Œ<code>F</code>ä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯ç«‹æ–¹ä½“çš„ä¸ªæ•°å’Œç‰¹å¾çš„ä¸ªæ•°ã€‚</p>
<p>æˆ‘ä»¬å…ˆçœ‹çœ‹éœ€è¦è¿›è¡Œç¼–å†™çš„å‡½æ•°ï¼Œç„¶åä¸€æ­¥ä¸€æ­¥çš„æ¥è§£é‡Šå’Œæ¢ç´¢ï¼Œä»¥ä¸‹æ˜¯æ›´æ–°åçš„<code>forward</code>å‡½æ•°</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function">torch::Tensor <span class="title">trilinear_fw_cu</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::Tensor points</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = feats.<span class="built_in">size</span>(<span class="number">0</span>), F = feats.<span class="built_in">size</span>(<span class="number">2</span>);</span><br><span class="line">    <span class="comment">// ç­‰ä»·äº feat_interp = torch.zeros(N, F, dtype = torch.float32, device = "cuda:0")</span></span><br><span class="line">    torch::Tensor feat_interp = torch::<span class="built_in">zeros</span>({N, F}, feats.<span class="built_in">options</span>());</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">threads</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span></span>; <span class="comment">// 128,256,512</span></span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">blocks</span><span class="params">((N+threads.x<span class="number">-1</span>)/threads.x, (F+threads.y<span class="number">-1</span>)/threads.y)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">AT_DISPATCH_FLOATING_TYPES</span>(feats.<span class="built_in">type</span>(), <span class="string">"trilinear_fw_cu"</span>, </span><br><span class="line">    ([&amp;] {</span><br><span class="line">        trilinear_fw_kernel&lt;<span class="type">scalar_t</span>&gt;&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(</span><br><span class="line">            feats.<span class="built_in">packed_accessor</span>&lt;<span class="type">scalar_t</span>, <span class="number">3</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt;(),</span><br><span class="line">            points.<span class="built_in">packed_accessor</span>&lt;<span class="type">scalar_t</span>, <span class="number">2</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt;(),</span><br><span class="line">            feat_interp.<span class="built_in">packed_accessor</span>&lt;<span class="type">scalar_t</span>, <span class="number">2</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt;()</span><br><span class="line">        );</span><br><span class="line">    }));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> feat_interp;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>ç¬¬5è¡Œæˆ‘ä»¬å¾—åˆ°äº†å¯¹åº”çš„ç»´åº¦ï¼Œåˆ†åˆ«æ˜¯Nå’ŒFï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬æœ€åéœ€è¦è¿”å›å€¼<code>feat_interp</code>çš„ç»´åº¦ã€‚</p>
<p>ç¬¬7è¡Œæˆ‘ä»¬åˆå§‹åŒ–äº†å˜é‡<code>feat_interp</code>ï¼Œè¿™é‡Œé¢æ˜¯åˆå§‹åŒ–ä¸ºzeroï¼Œåœ¨é‡Œé¢è¿˜æœ‰ä¸€ä¸ªå‚æ•°æ˜¯<code>feats.options()</code>ï¼Œåœ¨CUDAç¼–ç¨‹ä¸­ï¼Œ<code>feats.options()</code>è¡¨ç¤ºè·å–<code>feats</code>å¼ é‡çš„é€‰é¡¹ï¼ˆoptionsï¼‰ã€‚é€‰é¡¹åŒ…æ‹¬å¼ é‡çš„æ•°æ®ç±»å‹ã€è®¾å¤‡ï¼ˆè®¾å¤‡æŒ‡å®šä¸ºCUDAæˆ–CPUï¼‰ä»¥åŠå…¶ä»–ç›¸å…³çš„é…ç½®ä¿¡æ¯ã€‚é€šè¿‡ä½¿ç”¨<code>feats.options()</code>ï¼Œå¯ä»¥ç¡®ä¿æ–°åˆ›å»ºçš„<code>feat_interp</code>å¼ é‡ä¸<code>feats</code>å¼ é‡å…·æœ‰ç›¸åŒçš„é€‰é¡¹ï¼Œä»¥ä¾¿åœ¨ç›¸åŒçš„è®¾å¤‡ä¸Šè¿›è¡Œæ“ä½œï¼Œå¹¶ä¿æŒä¸€è‡´æ€§ã€‚</p>
<p>ç®€å•æ¥è¯´ï¼Œå°±æ˜¯ä¿æŒä¸€è‡´çš„è®¾å¤‡ç­‰ç­‰ï¼Œè¿™æ ·å°±æ–¹ä¾¿åç»­åœ¨åŒä¸€ä¸ªè®¾å¤‡è¿›è¡Œè®¡ç®—ï¼Œå’Œpytorchéœ€è¦æ”¾åœ¨cpuå’Œcudaä¸Šæ˜¯ä¸€æ ·çš„ï¼Œé™¤æ­¤ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€äº›å¦å¤–çš„å†™æ³•ï¼Œæ¯”å¦‚æ˜¯åˆ›å»ºä¸€ä¸ªæ•´å‹çš„ï¼Œå¯ä»¥å†™æˆå¦‚ä¸‹ï¼Œä¸€æ ·çš„æ„æ€ã€‚</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line">torch::<span class="built_in">zeros</span>({Nï¼ŒF}ï¼Œtorch::<span class="built_in">dtype</span>(torch::kInt32).<span class="built_in">device</span>(feats,device));</span><br></pre></td></tr></tbody></table></figure>
<p>ç¬¬9è¡Œå’Œç¬¬10è¡Œå°±æ˜¯å®šä¹‰ä¸Šè¿°æè¿‡çš„<code>threads</code>å’Œ<code>blocks</code>äº†ï¼Œdim3æ˜¯NVIDIAçš„CUDAç¼–ç¨‹ä¸­ä¸€ç§è‡ªå®šä¹‰çš„æ•´å‹å‘é‡ç±»å‹ï¼ŒåŸºäºç”¨äºæŒ‡å®šç»´åº¦çš„uint3ï¼Œdim3ç±»å‹æœ€ç»ˆè®¾ç½®çš„æ˜¯ä¸€ä¸ªä¸‰ç»´å‘é‡ï¼Œä¸‰ç»´å‚æ•°åˆ†åˆ«ä¸ºx,y,zã€‚åœ¨å¹¶è¡Œä¸­ï¼Œé€šå¸¸åªæ”¯æŒä¸‰ä¸ªå¹¶è¡Œï¼Œæ¯”å¦‚è¿™é‡Œçš„Nå’ŒFåˆšåˆšå¥½å°±æ˜¯ä¸¤ä¸ªå¹¶è¡Œï¼Œè¿™é‡Œè®¾ç½®ä¸º16x16çš„çº¿ç¨‹ï¼Œä¸€èˆ¬å¯ä»¥æ˜¯128,256,512ï¼Œä¸ä¸€å®šä½¿ç”¨è¶Šå¤šè¶Šå¥½ï¼Œè¿™é‡Œé¢åªæ˜¯ç»™äº†ä¸€ä¸ªä¾‹å­ã€‚</p>
<p>ç¬¬10è¡Œä¸­æ˜¯å®šä¹‰äº†<code>blocks</code>çš„è®¡ç®—ï¼Œ<code>blocks</code>çš„ä¸ªæ•°å®é™…ä¸Šæ˜¯è®¡ç®—çš„å¾—åˆ°çš„ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå¦‚æœN=10ï¼ŒF=20ï¼Œæˆ‘ä»¬æœ€åçš„è¾“å‡ºå°±æ˜¯10x20ï¼Œè¿™æ ·æˆ‘ä»¬å°±ä¼šç”¨ä¸€ä¸ª16x16çš„blockå»è¦†ç›–è¿™æ•´ä¸ªçŸ©é˜µï¼Œæˆ‘ä»¬ä¼šå‘ç°å¤§æ¦‚éœ€è¦2ä¸ªçŸ©é˜µï¼Œæ‰€ä»¥æˆ‘ä»¬çš„<code>blocks</code>å°±æ˜¯(2,1)ï¼Œä»ä¸‹å›¾ä¹Ÿå¯ä»¥çœ‹å‡ºæ¥ï¼Œæ‰€ä»¥ä¸Šè¿°å…¬å¼å°±æ˜¯è®¡ç®—<code>block</code>çš„ä¸ªæ•°ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥ç”¨æ¯ä¸€ä¸ª<code>thread</code>å»è®¡ç®—ï¼Œè¿™æ ·å°±èƒ½å¤§å¤§åŠ å¿«é€Ÿåº¦ã€‚</p>
<p><img src="https://img-blog.csdnimg.cn/direct/3dfa0f2ed94b4d9d9297a90e55a59662.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p>ç¬¬12~19è¡Œå°±æ˜¯CUDAçš„æ ¸å¿ƒå‡½æ•°ï¼Œè¿™é‡Œé¢å°±æ˜¯ä¸€ä¸ªå¯åŠ¨æ ¸å‡½æ•°çš„éƒ¨åˆ†ï¼Œåé¢ä¼šæåˆ°æ ¸å‡½æ•°çš„ç¼–å†™ï¼Œè¿™é‡Œä¹Ÿæ˜¯ä¸€ä¸ªæ¡†æ¶çš„éƒ¨åˆ†ï¼Œ<code>AT_DISPATCH_FLOATING_TYPES</code> æ˜¯å¤„ç†æ ¸å‡½æ•°çš„å¯åŠ¨ï¼ˆä½¿ç”¨ <code>&lt;&lt;&lt;...&gt;&gt;&gt;</code> è¡¨ç¤ºï¼‰ï¼Œå®ƒä¸€èˆ¬æœ‰ä¸‰ä¸ªå‚æ•°</p>
<ul>
<li>ä¸€ä¸ªç±»å‹ feats.type()</li>
<li>ä¸€ä¸ªåç§° â€œtrilinear_fw_cuâ€ï¼Œç”¨äºé”™è¯¯æ¶ˆæ¯</li>
<li>ä¸€ä¸ª lambda å‡½æ•°ï¼Œæ˜¯ä¸€ä¸ªæ¨¡ç‰ˆå‡½æ•°templateï¼Œç±»å‹åˆ«åä¸º <code>scalar_t</code></li>
</ul>
<p>åœ¨è¿™é‡Œé¢å¯ä»¥çœ‹å‡ºå¤„ç†çš„æ˜¯floatç±»å‹çš„æ•°æ®ï¼Œå¦‚æœæƒ³å¯¹æ‰€æœ‰ç±»å‹è¿›è¡Œæ“ä½œè€Œä¸ä»…ä»…æ˜¯æµ®ç‚¹ç±»å‹ï¼ˆFloat å’Œ Doubleï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ <code>AT_DISPATCH_ALL_TYPES</code>ã€‚</p>
<h3 id="scalar-tç±»å‹"><a href="#scalar-tç±»å‹" class="headerlink" title="scalar_tç±»å‹"></a>scalar_tç±»å‹</h3><p>åœ¨å‡½æ•°ä¹‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æˆ‘ä»¬æœ‰ä¸‰ä¸ªinputï¼Œå…¶ä¸­ä¸¤ä¸ªæ˜¯ä¸‰çº¿æ€§æ’å€¼çš„inputï¼Œä¸€ä¸ªæ˜¯outputï¼Œä¸ºä»€ä¹ˆå‘¢ï¼Œæ˜¯å› ä¸ºå…¶å®è¿™ä¸ªå‡½æ•°æ˜¯æ²¡æœ‰è¿”å›å€¼çš„ï¼Œæ‰€ä»¥è¯´å®é™…ä¸Šæ˜¯åœ¨å‡½æ•°é‡Œé¢è®¡ç®—åå¤åˆ¶åœ¨outputä¹‹ä¸­ï¼Œæœ€åè¿›è¡Œè¿”å›ã€‚</p>
<p>æˆ‘ä»¬æ¥ä»”ç»†äº†è§£äº†ä¸€ä¸‹å…·ä½“å‡½æ•°çš„ç¼–å†™æ˜¯ä»€ä¹ˆæ„æ€ï¼Œé¦–å…ˆæ˜¯<code>scalar_t</code>å…¶å®æ˜¯ä¸€ç§ç±»å‹ï¼Œä»–å¯ä»¥è¡¨ç¤ºä»»ä½•ç±»å‹ï¼ŒåŒ…æ‹¬æ•´å‹ï¼Œæµ®ç‚¹å‹ç­‰ç­‰ï¼Œå¦‚æœæˆ‘ä»¬ç¡®å®šæ•°æ®æ˜¯floatï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥å°†<code>scalar_t</code>å†™ä¸º<code>float</code>ï¼Œé‚£ä¹ˆä»–å¯èƒ½å°±åªèƒ½å¤„ç†æµ®ç‚¹å‹çš„æ•°æ®äº†ï¼Œä»ä¸‹é¢ä¹Ÿå¯ä»¥çœ‹åˆ°<code>scalar_t</code>çš„ä¸€ä¸ªç®€å•çš„å®ç°ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">switch (tensor.<span class="built_in">type</span>().scalarType()) {</span><br><span class="line">  <span class="keyword">case</span> torch::ScalarType::Double:</span><br><span class="line">    <span class="keyword">return</span> function&lt;double&gt;(tensor.data&lt;double&gt;());</span><br><span class="line">  <span class="keyword">case</span> torch::ScalarType::Float:</span><br><span class="line">    <span class="keyword">return</span> function&lt;<span class="built_in">float</span>&gt;(tensor.data&lt;<span class="built_in">float</span>&gt;());</span><br><span class="line">  ...</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<hr>
<h3 id="accessors"><a href="#accessors" class="headerlink" title="accessors"></a>accessors</h3><p>åœ¨CUDAè®¡ç®—çš„æ—¶å€™ï¼Œè¿˜æœ‰ä¸€ä¸ªé—®é¢˜ï¼Œåœ¨ CUDA æ ¸å‡½æ•°å†…éƒ¨ï¼Œè™½ç„¶æˆ‘ä»¬èƒ½æ­£ç¡®å¤„ç†æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨é«˜çº§ç±»å‹<code>scalar_t</code>ä¸å¯çŸ¥çš„å¼ é‡å°†éå¸¸ä½æ•ˆï¼Œå› ä¸ºè¿™æ˜¯ä»¥æ˜“ç”¨æ€§å’Œå¯è¯»æ€§ä¸ºä»£ä»·çš„ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé«˜ç»´æ•°æ®ã€‚</p>
<p>æ¯”å¦‚è¯´ï¼Œåœ¨æ•°æ®ä¸­ï¼Œæˆ‘ä»¬è¿™é‡Œæœ‰(N, F)ä¸ªæ•°æ®ï¼Œé‚£æˆ‘ä»¬æœ‰æ²¡æœ‰å¿«é€Ÿçš„æ–¹æ³•å»è¯»å–åˆ°<code>feat_interp[i][j]</code>çš„æ•°æ®å‘¢ï¼Œç‰¹åˆ«æ˜¯æœ‰äº›ä¸€èˆ¬æ˜¯ä¸‰ä¸ªç»´åº¦çš„ï¼Œæ¯”å¦‚(bs,row,index)è¿™æ ·çš„ï¼Œå¹¶ä¸”æœ‰æ—¶å€™æˆ‘ä»¬è¿˜éœ€è¦çŸ¥é“strideæ‰èƒ½å¿«é€Ÿç´¢å¼•åˆ°ä½ç½®ï¼Œæ¯”å¦‚<code>gates.data&lt;scalar_t&gt;()[n*3*state_size + row*state_size + column]</code></p>
<p>åœ¨è¿™é‡Œé¢ï¼Œæˆ‘ä»¬å¯èƒ½å°±éœ€è¦ç”¨åˆ°ä¸€ä¸ª<code>ATen</code>æä¾›çš„<code>accessors</code>ï¼Œä»–å¯ä»¥åŠ¨æ€æ£€æŸ¥ç¡®ä¿å¼ é‡å…·æœ‰æŒ‡å®šçš„ç±»å‹å’Œç»´åº¦æ•°é‡ï¼Œå™¨æä¾›äº†ä¸€ä¸ª APIï¼Œç”¨äºé«˜æ•ˆåœ°è®¿é—®å¼ é‡å…ƒç´ ï¼Œè€Œæ— éœ€è½¬æ¢ä¸ºå•ä¸ªæŒ‡é’ˆï¼Œå°±å¯ä»¥é«˜æ•ˆè®¿é—® cpu å¼ é‡ä¸Šçš„æ•°æ®ï¼Œcudaæˆ‘ä»¬å°±å¯ä»¥ç”¨<code>packed_accessor</code>ã€‚</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line">torch::Tensor foo = torch::<span class="built_in">rand</span>({<span class="number">12</span>, <span class="number">12</span>});</span><br><span class="line"></span><br><span class="line"><span class="comment">// ç¡®å®š foo æ˜¯äºŒç»´çš„å¹¶ä¸”åŒ…å«æµ®ç‚¹æ•°ã€‚</span></span><br><span class="line"><span class="keyword">auto</span> foo_a = foo.<span class="built_in">accessor</span>&lt;<span class="type">float</span>,<span class="number">2</span>&gt;();</span><br><span class="line"><span class="type">float</span> trace = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; foo_a.<span class="built_in">size</span>(<span class="number">0</span>); i++) {</span><br><span class="line">  <span class="comment">// ä½¿ç”¨è®¿é—®å™¨ foo_a æ¥è·å–å¼ é‡æ•°æ®ã€‚</span></span><br><span class="line">  trace += foo_a[i][i];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p>æ‰€ä»¥æˆ‘ä»¬åœ¨æ ¸å‡½æ•°å†…éƒ¨çœ‹åˆ°äº†<code>packed_accessor</code>ï¼Œè¿™ä¸€éƒ¨åˆ†å°±æ˜¯åšè¿™æ ·ä¸€ä»¶äº‹æƒ…ï¼Œ<strong>ä¸è¿‡å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåªæœ‰å¯¹torchçš„å‘é‡æˆ‘ä»¬éœ€è¦è¿™æ ·çš„æ“ä½œï¼Œå¦‚æœæ˜¯boolç­‰ï¼Œæˆ‘ä»¬æ˜¯ä¸éœ€è¦å¤„ç†çš„ã€‚</strong></p>
<hr>
<h3 id="æ¨¡æ¿å‡½æ•°"><a href="#æ¨¡æ¿å‡½æ•°" class="headerlink" title="æ¨¡æ¿å‡½æ•°"></a>æ¨¡æ¿å‡½æ•°</h3><p>ä¸Šè¿°æœ‰æåˆ°ï¼Œå®é™…ä¸Šæˆ‘ä»¬çš„<code>trilinear_fw_kernel</code>æ˜¯ä¸€ä¸ªæ¨¡æ¿å‡½æ•°ï¼Œæˆ‘ä»¬æ¥ä¸‹æ¥çœ‹ä¸€ä¸‹å…·ä½“çš„å®ç°ï¼Œæˆ‘ä»¬åˆ©ç”¨<code>scalar_t</code>å¯¹å…¶è¿›è¡Œå®ä¾‹åŒ–ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå†è§£é‡Šä¸€ä¸‹è¿™ä¸ªæ¨¡æ¿å‡½æ•°çš„å‚æ•°éƒ¨åˆ†ï¼š</p>
<ul>
<li><p>é¦–å…ˆæ˜¯ <code>scalar_t</code>ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ¨¡æ¿å‚æ•°ï¼Œä»£è¡¨å¼ é‡çš„æ•°æ®ç±»å‹ã€‚åœ¨è¿™ä¸ªä¸Šä¸‹æ–‡ä¸­ï¼Œé€šå¸¸ä¼šä½¿ç”¨ <code>float</code> æˆ– <code>double</code> ä½œä¸º <code>scalar_t</code>ï¼Œå…·ä½“å–å†³äºå¼ é‡çš„æ•°æ®ç±»å‹ã€‚</p>
</li>
<li><p>æ¥ä¸‹æ¥æ˜¯ <code>3</code>ï¼Œå®ƒè¡¨ç¤ºå¼ é‡çš„ç»´åº¦æ•°é‡ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬çš„featsçš„ç»´åº¦æ˜¯3ï¼Œæ‰€ä»¥ç»´åº¦æ•°é‡ä¸º 3ã€‚</p>
</li>
<li><p>ç„¶åæ˜¯ <code>torch::RestrictPtrTraits</code>ï¼Œå®ƒæ˜¯ä¸€ä¸ªæ¨¡æ¿å‚æ•°ï¼Œç”¨äºæŒ‡å®šæŒ‡é’ˆçš„é™å®šç¬¦ã€‚<code>__restrict__</code> å…³é”®å­—åœ¨ CUDA ä¸­ç”¨äºæŒ‡ç¤ºæŒ‡é’ˆæ˜¯å”¯ä¸€çš„ï¼Œå¹¶ä¸”æ²¡æœ‰åˆ«åã€‚è¿™æœ‰åŠ©äºç¼–è¯‘å™¨è¿›è¡Œä¼˜åŒ–ï¼Œæé«˜ä»£ç çš„æ€§èƒ½ã€‚</p>
</li>
<li><p>æœ€åæ˜¯ <code>PackedTensorAccessor</code>ï¼Œå®ƒæ˜¯ä¸€ä¸ªè®¿é—®å™¨ï¼ˆaccessorï¼‰çš„å˜ä½“ï¼Œç”¨äºå­˜å‚¨å¤§å°å’Œæ­¥å¹…ä¿¡æ¯ï¼Œå¯ä»¥ä½¿å¾—åœ¨è®¿é—®å™¨å¯¹è±¡ä¼ é€’ç»™ CUDA æ ¸å‡½æ•°æ—¶ï¼Œå†…å­˜ä¼ è¾“çš„æ•°æ®é‡ä¹Ÿæ›´å°ã€‚</p>
</li>
</ul>
<p>æ¥ä¸‹æ¥æˆ‘ä»¬ä»”ç»†åˆ†æé‡Œé¢ä»£ç çš„ç»†èŠ‚ï¼Œé¦–å…ˆä»‹ç»ä¸€ä¸‹è¿™ä¸ª<code>__global__</code>ï¼Œä»–å®é™…æ„ä¹‰å¦‚ä¸‹ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤º</p>
<ul>
<li><p><code>__global__</code>è¡¨ç¤ºCPUä¸Šå®šä¹‰ï¼ŒGPUä¸Šæ‰§è¡Œï¼Œæ˜¯CUDAçš„å…³é”®å­—</p>
</li>
<li><p><code>__device__</code> GPUå®š ä¹‰ï¼ŒGPUæ‰§è¡Œ</p>
</li>
<li><p><code>__host__</code> CPUå®šä¹‰ï¼ŒCPUæ‰§è¡Œ</p>
</li>
</ul>
<p><img src="https://img2018.cnblogs.com/blog/1093303/201809/1093303-20180919123125957-1702896390.png" alt="CUDAç¼–ç¨‹ä¹‹å¿«é€Ÿå…¥é—¨- æœ€éš¾ä¸è¿‡äºŒå‰æ ‘- åšå®¢å›­"></p>
<p>æ¥ä¸‹é‡Œåˆ†æå‡½æ•°çš„ä¸»ä½“éƒ¨åˆ†ï¼Œä¸»è¦åšä¸¤ä»¶äº‹æƒ…ï¼š</p>
<ol>
<li>ä¸ºæ¯ä¸ª<code>threads</code>è¿›è¡Œç¼–å·</li>
<li>å»é™¤ä¸å¿…è¦çš„<code>threads</code></li>
</ol>
<p>åœ¨ä½¿ç”¨<code>threads</code>è®¡ç®—çš„æ—¶å€™ï¼Œå®é™…ä¸Šæ¯ä¸€ä¸ª<code>threads</code>éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„ç¼–å·ï¼Œè®¡ç®—æ–¹å¼å¦‚ç¬¬7,8è¡Œæ‰€ç¤ºï¼Œå®é™…ä¸Šå°±æ˜¯blockçš„x*blockçš„ä¸ªæ•°+blockçš„yå°±èƒ½å¾—åˆ°æœ€åçš„ç»“æœ</p>
<p>é™¤äº†ç¼–å·ä¹‹å¤–ï¼Œè¿˜æœ‰å»é™¤ä¸å¿…è¦çš„<code>threads</code>ï¼Œå› ä¸ºæœ‰ä¸€éƒ¨åˆ†æ˜¯æ²¡æœ‰è¦†ç›–åˆ°çš„ï¼Œæ¯”å¦‚å¦‚ä¸‹å›¾çš„é»„è‰²éƒ¨åˆ†å°±æ˜¯ä¸å¿…è¦çš„<code>threads</code>ï¼Œæ‰€ä»¥åœ¨ç¬¬10è¡Œè¿›è¡Œåˆ¤æ–­ï¼Œå¦‚æœè¶…è¿‡èŒƒå›´ï¼Œç›´æ¥returnä¸è®¡ç®—</p>
<p><img src="https://img-blog.csdnimg.cn/direct/6daed7e700bb4fb6927b4a8a89b8a1ea.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p>æœ€åå°±æ˜¯ä¸Šè¿°è¯´æ˜çš„ä¸‰çº¿æ€§æ’å€¼çš„åšæ³•äº†ï¼Œå…ˆè¿›è¡Œä¸€ä¸ªæ ‡å‡†åŒ–ï¼Œç„¶åä»£å…¥å…¬å¼è¿›è¡Œè®¡ç®—ï¼Œæœ€åå°†å€¼å†™å…¥feat_interpä¸­ï¼Œå°±å®Œæˆäº†æ•´ä¸ªæ¨¡æ¿å‡½æ•°çš„ç¼–å†™ï¼Œå¤§åŠŸå‘Šæˆï¼ï¼ï¼</p>
<p><img src="https://img-blog.csdnimg.cn/20190121221044883.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> <span class="type">scalar_t</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">trilinear_fw_kernel</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::PackedTensorAccessor&lt;<span class="type">scalar_t</span>, <span class="number">3</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt; feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::PackedTensorAccessor&lt;<span class="type">scalar_t</span>, <span class="number">2</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt; points,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::PackedTensorAccessor&lt;<span class="type">scalar_t</span>, <span class="number">2</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt; feat_interp</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> f = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (n&gt;=feats.<span class="built_in">size</span>(<span class="number">0</span>) || f&gt;=feats.<span class="built_in">size</span>(<span class="number">2</span>)) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// point -1~1</span></span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> u = (points[n][<span class="number">0</span>]+<span class="number">1</span>)/<span class="number">2</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> v = (points[n][<span class="number">1</span>]+<span class="number">1</span>)/<span class="number">2</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> w = (points[n][<span class="number">2</span>]+<span class="number">1</span>)/<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> a = (<span class="number">1</span>-v)*(<span class="number">1</span>-w);</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> b = (<span class="number">1</span>-v)*w;</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> c = v*(<span class="number">1</span>-w);</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> d = <span class="number">1</span>-a-b-c;</span><br><span class="line">    feat_interp[n][f] = (<span class="number">1</span>-u)*(a*feats[n][<span class="number">0</span>][f] +</span><br><span class="line">                               b*feats[n][<span class="number">1</span>][f] +</span><br><span class="line">                               c*feats[n][<span class="number">2</span>][f] +</span><br><span class="line">                               d*feats[n][<span class="number">3</span>][f]) + </span><br><span class="line">                            u*(a*feats[n][<span class="number">4</span>][f] +</span><br><span class="line">                               b*feats[n][<span class="number">5</span>][f] +</span><br><span class="line">                               c*feats[n][<span class="number">6</span>][f] +</span><br><span class="line">                               d*feats[n][<span class="number">7</span>][f]);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="fowardéªŒè¯ä¸æ¯”è¾ƒ"><a href="#fowardéªŒè¯ä¸æ¯”è¾ƒ" class="headerlink" title="fowardéªŒè¯ä¸æ¯”è¾ƒ"></a>fowardéªŒè¯ä¸æ¯”è¾ƒ</h3><p>ç»è¿‡<code>python setup.py install</code>ä»¥åï¼ˆæ¯æ¬¡ä¿®æ”¹åéƒ½è¦é‡æ–°è¿è¡Œ<code>setup.py</code>ï¼‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œè¿è¡Œäº†ï¼Œåœ¨è¿™é‡Œé¢ä¸ºäº†éªŒè¯ç»“æœçš„æ­£ç¡®æ€§å’Œä¸pythonè¿›è¡Œæ¯”è¾ƒï¼Œç”¨pythonå®ç°ä¸‰çº¿æ€§æ’å€¼çš„ç®—æ³•ï¼Œæ¯”è¾ƒä¸¤è€…çš„ç»“æœå’Œæ—¶é—´æ•ˆç‡ï¼Œ<code>test.py</code>å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> cppcuda_tutorial</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">trilinear_interpolation_py</span>(<span class="params">feats, points</span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Inputs:</span></span><br><span class="line"><span class="string">        feats: (N, 8, F)</span></span><br><span class="line"><span class="string">        points: (N, 3) local coordinates in [-1, 1]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Outputs:</span></span><br><span class="line"><span class="string">        feats_interp: (N, F)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    u = (points[:, <span class="number">0</span>:<span class="number">1</span>]+<span class="number">1</span>)/<span class="number">2</span></span><br><span class="line">    v = (points[:, <span class="number">1</span>:<span class="number">2</span>]+<span class="number">1</span>)/<span class="number">2</span></span><br><span class="line">    w = (points[:, <span class="number">2</span>:<span class="number">3</span>]+<span class="number">1</span>)/<span class="number">2</span></span><br><span class="line">    a = (<span class="number">1</span>-v)*(<span class="number">1</span>-w)</span><br><span class="line">    b = (<span class="number">1</span>-v)*w</span><br><span class="line">    c = v*(<span class="number">1</span>-w)</span><br><span class="line">    d = <span class="number">1</span>-a-b-c</span><br><span class="line"></span><br><span class="line">    feats_interp = (<span class="number">1</span>-u)*(a*feats[:, <span class="number">0</span>] +</span><br><span class="line">                          b*feats[:, <span class="number">1</span>] +</span><br><span class="line">                          c*feats[:, <span class="number">2</span>] +</span><br><span class="line">                          d*feats[:, <span class="number">3</span>]) + \</span><br><span class="line">                       u*(a*feats[:, <span class="number">4</span>] +</span><br><span class="line">                          b*feats[:, <span class="number">5</span>] +</span><br><span class="line">                          c*feats[:, <span class="number">6</span>] +</span><br><span class="line">                          d*feats[:, <span class="number">7</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> feats_interp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    N = <span class="number">65536</span>; F = <span class="number">256</span></span><br><span class="line">    feats = torch.rand(N, <span class="number">8</span>, F, device=<span class="string">'cuda'</span>).requires_grad_()</span><br><span class="line">    points = torch.rand(N, <span class="number">3</span>, device=<span class="string">'cuda'</span>)*<span class="number">2</span>-<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    t = time.time()</span><br><span class="line">    out_cuda = cppcuda_tutorial.trilinear_interpolation(feats, points)</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'   cuda time'</span>, time.time()-t, <span class="string">'s'</span>)</span><br><span class="line"></span><br><span class="line">    t = time.time()</span><br><span class="line">    out_py = trilinear_interpolation_py(feats, points)</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'pytorch time'</span>, time.time()-t, <span class="string">'s'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(torch.allclose(out_py, out_cuda)) <span class="comment"># åˆ¤æ–­ä¸¤è€…çš„å·®å¼‚</span></span><br></pre></td></tr></tbody></table></figure>
<p>ç»è¿‡è¿è¡Œå’Œè®¡ç®—åï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä»¥ä¸‹ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒCUDAæ˜¯æ˜æ˜¾æ¯”Pytorchæ›´å¿«çš„ï¼Œå¹¶ä¸”ä¸¤è€…çš„è®¡ç®—ç»“æœä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œå¦‚æœéœ€è¦æ›´å¥½çš„è®¡ç®—ä¸¤è€…çš„é€Ÿåº¦çš„è¯ï¼Œå¯èƒ½éœ€è¦è¿›è¡Œå¾ªç¯è¿è¡Œè®¡ç®—å–å¹³å‡æ›´æœ‰å¯ä¿¡åº¦ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">   cuda time 0.02436351776123047 s</span><br><span class="line">pytorch time 0.04364943504333496 s</span><br><span class="line">True</span><br></pre></td></tr></tbody></table></figure>
<h2 id="CUDAåå‘ä¼ æ’­"><a href="#CUDAåå‘ä¼ æ’­" class="headerlink" title="CUDAåå‘ä¼ æ’­"></a>CUDAåå‘ä¼ æ’­</h2><p>åœ¨ä¸Šè¿°å®éªŒä¸­ï¼Œå½“æˆ‘ä»¬å°è¯•æ·»åŠ è‡ªåŠ¨æ±‚å¯¼çš„æ¢¯åº¦è®¡ç®—æ—¶ï¼Œä½¿ç”¨<code>requires_grad_</code>ï¼Œæˆ‘ä»¬ä¼šå‘ç°é€šè¿‡CUDAè¿”å›çš„å€¼å®é™…ä¸Šä¸ä¼šè‡ªåŠ¨è¿›è¡Œæ¢¯åº¦è®¡ç®—ï¼ˆautogradï¼‰ã€‚ç„¶è€Œï¼Œå¦‚æœæˆ‘ä»¬åœ¨Pythonä¸­è¿›è¡Œè®¡ç®—ï¼Œå®ƒä¼šè‡ªåŠ¨è¿›è¡Œæ¢¯åº¦è®¡ç®—ã€‚</p>
<p>ç„¶è€Œï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œç¥ç»ç½‘ç»œç»å¸¸éœ€è¦è®¡ç®—æŸå¤±å‡½æ•°ï¼Œå¹¶ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç­‰ä¼˜åŒ–ç®—æ³•æ¥ä¸æ–­ä¼˜åŒ–å‚æ•°ã€‚ä½†æ˜¯ï¼Œåœ¨CUDAç¼–ç¨‹ä¸­ï¼ŒC++æ‰©å±•APIå¹¶æ²¡æœ‰æä¾›è‡ªåŠ¨æ±‚å¯¼ï¼ˆautogradï¼‰çš„æ–¹æ³•ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»è‡ªå·±å®ç°åå‘ä¼ æ’­çš„ä»£ç ï¼Œè®¡ç®—æ¯ä¸ªè¾“å…¥çš„å¯¼æ•°ï¼Œå¹¶å°†å…¶å°è£…åœ¨<code>torch.autograd.Function</code>ä¸­ã€‚</p>
<p>åœ¨CUDAç¼–ç¨‹ä¸­ï¼Œå®ç°åå‘ä¼ æ’­çš„ä»£ç é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹æ­¥éª¤ï¼š</p>
<ol>
<li>åœ¨C++æ‰©å±•ä¸­ï¼Œåˆ›å»ºä¸€ä¸ªæ–°ç±»ï¼Œç»§æ‰¿è‡ª<code>torch::autograd::Function</code>ï¼Œç”¨äºå®šä¹‰å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ“ä½œã€‚</li>
<li>åœ¨æ–°ç±»ä¸­ï¼Œé‡å†™<code>forward()</code>æ–¹æ³•ï¼Œå®šä¹‰å‰å‘ä¼ æ’­çš„æ“ä½œã€‚è¿™äº›æ“ä½œå°†ä½¿ç”¨CUDAæ‰§è¡Œè®¡ç®—ï¼Œå¹¶è¿”å›ç»“æœï¼Œå…¶å®å°±æ˜¯ä¸Šè¿°çš„cudaçš„éƒ¨åˆ†ã€‚</li>
<li>åœ¨æ–°ç±»ä¸­ï¼Œé‡å†™<code>backward()</code>æ–¹æ³•ï¼Œå®šä¹‰åå‘ä¼ æ’­çš„æ“ä½œã€‚è¿™äº›æ“ä½œå°†è®¡ç®—è¾“å…¥å¼ é‡çš„æ¢¯åº¦ï¼Œå¹¶ä¼ é€’ç»™ä¸Šä¸€å±‚ã€‚</li>
<li>åœ¨CUDAå’ŒC++ä¸­ï¼Œç¼–å†™å¯¹åº”çš„<code>forward</code>å’Œ<code>backward</code>å‡½æ•°ï¼Œè®¡ç®—å‰å‘ä¼ æ’­å’Œå¾®åˆ†ã€‚</li>
<li>åœ¨Pythonä»£ç ä¸­ï¼Œä½¿ç”¨è¿™ä¸ªè‡ªå®šä¹‰å‡½æ•°æ‰§è¡Œå‰å‘ä¼ æ’­ï¼Œå¹¶é€šè¿‡è°ƒç”¨<code>backward()</code>æ–¹æ³•æ‰§è¡Œåå‘ä¼ æ’­ã€‚</li>
<li>åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæ¢¯åº¦å°†é€šè¿‡CUDAè®¡ç®—ï¼Œå¹¶åœ¨æ¯ä¸ªå±‚ä¹‹é—´ä¼ é€’ï¼Œä»è€Œè®¡ç®—å‡ºæ¯ä¸ªè¾“å…¥çš„å¯¼æ•°ã€‚</li>
</ol>
<p>é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨CUDAç¼–ç¨‹ä¸­æ‰‹åŠ¨å®ç°åå‘ä¼ æ’­ï¼Œå¹¶è·å¾—æ¯ä¸ªè¾“å…¥çš„æ¢¯åº¦ï¼Œä»¥ä¾¿è¿›è¡Œä¼˜åŒ–ç®—æ³•çš„å‚æ•°æ›´æ–°ã€‚å°½ç®¡éœ€è¦æ‰‹åŠ¨ç¼–å†™åå‘ä¼ æ’­ä»£ç ï¼Œä½†è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨CUDAæ‰©å±•ä¸­è‡ªå®šä¹‰æ¢¯åº¦è®¡ç®—ï¼Œå¹¶ä¸PyTorchçš„è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶æ— ç¼é…åˆã€‚</p>
<p>æˆ‘ä»¬è¿˜æ˜¯æŠŠä¸‰çº¿æ€§æ’å€¼ä½œä¸ºæˆ‘ä»¬çš„ä¸€ä¸ªä¾‹å­ï¼Œç¼–å†™å¯¹åº”çš„åå‘ä¼ æ’­ï¼Œæ ¹æ®é—®é¢˜è®¾å®šï¼Œæˆ‘ä»¬å¯ä»¥çŸ¥é“æˆ‘ä»¬çš„Pointsæ˜¯å›ºå®šçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å¯¹æˆ‘ä»¬çš„Featsè¿›è¡Œæ±‚å¾®åˆ†ã€‚æˆ‘ä»¬ä»¥ç®€å•çš„åŒçº¿æ€§æ’å€¼æ¥å­¦ä¹ ä¸€ä¸‹ï¼Œæ€ä¹ˆæ±‚å¾®åˆ†ï¼Œè¿™é‡Œé¢å…¶å®æ¶‰åŠé«˜æ•°çš„çŸ¥è¯†ï¼Œå½“ç„¶æˆ‘ä»¬ä¹Ÿå¯ä»¥æŠŠå‡½æ•°äº¤ç»™ä¸€äº›æ•°å­¦ç½‘ç«™å¸®æˆ‘ä»¬æ±‚å¾—ç»“æœã€‚<strong>ä»ä¸‹å›¾æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œ<code>f</code>æ˜¯åŒçº¿æ€§æ’å€¼çš„ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°å¯¹åº”çš„å››ä¸ªå¯¼æ•°ï¼Œæˆ‘ä»¬ä¼šå‘ç°å®é™…ä¸Šï¼Œä»–ä»¬çš„å¾®åˆ†æ˜¯å¯¹åº”çš„ç³»æ•°ï¼Œæ¨å¯¼åœ¨ä¸‰çº¿æ€§æ’å€¼ä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œæ‰€ä»¥ä»–ä»¬å¯¹åº”çš„å¾®åˆ†ä¹Ÿå°±æ˜¯å¯¹åº”çš„å‰ç¼€ã€‚</strong></p>
<p><img src="https://img-blog.csdnimg.cn/direct/c35a354c6fcb49678872728cf04e6306.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<p>åœ¨è®¡ç®—åå‘ä¼ æ’­å‰ï¼Œæˆ‘ä»¬å¾€å¾€ä¼šæœ‰ä¸€ä¸ªå¯¹åº”çš„ä¸€ä¸ªæŸå¤±<code>Loss</code>ï¼Œç„¶åå†è¿›è¡Œæ±‚å¾®åˆ†ï¼Œè¿™é‡Œé¢å…¶å®å°±ç”¨åˆ°äº†é«˜æ•°é‡Œé¢çš„é“¾å¼æ³•åˆ™ï¼Œä½¿ç”¨é“¾å¼æ³•åˆ™æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°<code>L</code>å¯¹æ¯ä¸€ä¸ª<code>feat</code>çš„å¾®åˆ†ï¼Œæ˜ç™½äº†åŒçº¿æ€§æ’å€¼çš„è®¡ç®—ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ¨å¯¼åœ¨ä¸‰çº¿æ€§æ’å€¼ä¸­ã€‚</p>
<p><img src="https://img-blog.csdnimg.cn/direct/777b69824dcf4ca0ba257613067fa9be.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<h3 id="å®šä¹‰CUDAå‡½æ•°"><a href="#å®šä¹‰CUDAå‡½æ•°" class="headerlink" title="å®šä¹‰CUDAå‡½æ•°"></a>å®šä¹‰CUDAå‡½æ•°</h3><p>æ˜ç™½äº†ç†è®ºçš„è®¡ç®—ï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œå¯¹åº”çš„å®ç°ï¼Œé¦–å…ˆæˆ‘ä»¬å¯ä»¥ç¼–å†™å¯¹åº”çš„åå‘ä¼ æ’­çš„CUDAå‡½æ•°ï¼Œè¿™ä¸€éƒ¨åˆ†å®é™…ä¸Šå’Œå‰å‘ä¼ æ’­æ˜¯ä¸€æ ·çš„ï¼Œé¦–å…ˆæˆ‘ä»¬è¿˜æ˜¯å®šä¹‰åå‘ä¼ æ’­å‡½æ•°ï¼Œåœ¨è¿™é‡Œå’Œå‰å‘ä¼ æ’­å‡½æ•°çš„ä¸åŒå°±æ˜¯å¯¹åå­—è¿›è¡Œäº†ä¿®æ”¹ï¼Œé™¤æ­¤ä¹‹å¤–åŠ å…¥äº†ä¸¤ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯<code>dL_dfeats</code>å‚æ•°å’Œ<code>dL_dfeats</code>ã€‚ç®€å•è§£é‡Šä¸€ä¸‹è¿™äº›å‚æ•°ï¼Œåœ¨é—®é¢˜çš„è®¾å®šä¸­ï¼Œæˆ‘ä»¬çš„<code>feats</code>çš„ç»´åº¦æ˜¯çš„(N, 8, F)ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„å¾®åˆ†<code>dL_dfeats</code>çš„ç»´åº¦æ˜¯å’Œ<code>feats</code>æ˜¯ä¸€æ ·çš„ï¼Œç„¶åå†åŠ å…¥åå‘ä¼ æ’­çš„æ ¸å‡½æ•°ä¸­å³å¯ï¼›<code>dL_dfeat_interp</code>åˆ™æ˜¯æ ¹æ®å‡½æ•°å·²çŸ¥çš„ï¼Œæ‰€ä»¥ä¸ç”¨è®¡ç®—ï¼Œç›´æ¥ä¼ å‚æ•°ã€‚</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function">torch::Tensor <span class="title">trilinear_bw_cu</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::Tensor dL_dfeat_interp,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::Tensor feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::Tensor points</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = feats.<span class="built_in">size</span>(<span class="number">0</span>), F = feats.<span class="built_in">size</span>(<span class="number">2</span>);</span><br><span class="line">    </span><br><span class="line">    torch::Tensor dL_dfeats = torch::<span class="built_in">empty</span>({N, <span class="number">8</span>, F}, feats.<span class="built_in">options</span>());</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">threads</span><span class="params">(<span class="number">16</span>, <span class="number">16</span>)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">blocks</span><span class="params">((N+threads.x<span class="number">-1</span>)/threads.x, (F+threads.y<span class="number">-1</span>)/threads.y)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">AT_DISPATCH_FLOATING_TYPES</span>(feats.<span class="built_in">type</span>(), <span class="string">"trilinear_bw_cu"</span>, </span><br><span class="line">    ([&amp;] {</span><br><span class="line">        trilinear_bw_kernel&lt;<span class="type">scalar_t</span>&gt;&lt;&lt;&lt;blocks, threads&gt;&gt;&gt;(</span><br><span class="line">            dL_dfeat_interp.<span class="built_in">packed_accessor</span>&lt;<span class="type">scalar_t</span>, <span class="number">2</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt;(),</span><br><span class="line">            feats.<span class="built_in">packed_accessor</span>&lt;<span class="type">scalar_t</span>, <span class="number">3</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt;(),</span><br><span class="line">            points.<span class="built_in">packed_accessor</span>&lt;<span class="type">scalar_t</span>, <span class="number">2</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt;(),</span><br><span class="line">            dL_dfeats.<span class="built_in">packed_accessor</span>&lt;<span class="type">scalar_t</span>, <span class="number">3</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt;()</span><br><span class="line">        );</span><br><span class="line">    }));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dL_dfeats;</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="æ ¸å‡½æ•°å®ç°å¾®åˆ†è®¡ç®—"><a href="#æ ¸å‡½æ•°å®ç°å¾®åˆ†è®¡ç®—" class="headerlink" title="æ ¸å‡½æ•°å®ç°å¾®åˆ†è®¡ç®—"></a>æ ¸å‡½æ•°å®ç°å¾®åˆ†è®¡ç®—</h3><p>æ¥ä¸‹æ¥å°±æ˜¯ä¸»è¦çš„æ ¸å‡½æ•°çš„å®ç°ï¼Œåœ¨è¿™ä¸€éƒ¨åˆ†æˆ‘ä»¬å°±éœ€è¦å®ç°å¾®åˆ†çš„è®¡ç®—ï¼Œåœ¨å‰é¢å·²ç»ä»‹ç»äº†åŒçº¿æ€§æ’å€¼çš„å¾®åˆ†çš„è®¡ç®—ï¼Œæ¨å¯¼åœ¨ä¸‰çº¿æ€§æ’å€¼æ˜¯ä¸€æ ·çš„ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®å‰å‘ä¼ æ’­çš„ä»£ç ï¼Œè¿™ä¸€éƒ¨åˆ†åªéœ€è¦ä¿ç•™å‰é¢çš„ç³»æ•°âœ–ï¸å¯¹åº”ä½ç½®çš„<code>dL_dfeat_interp</code>å°±å¯ä»¥å¾—åˆ°æœ€åçš„å¾®åˆ†å€¼ï¼Œè¿™ä¸€éƒ¨åˆ†è·Ÿä¸Šè¿°çš„æ¨å¯¼æ˜¯ä¸€æ¨¡ä¸€æ ·çš„ã€‚</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> <span class="type">scalar_t</span>&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">trilinear_bw_kernel</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::PackedTensorAccessor&lt;<span class="type">scalar_t</span>, <span class="number">2</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt; dL_dfeat_interp,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::PackedTensorAccessor&lt;<span class="type">scalar_t</span>, <span class="number">3</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt; feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::PackedTensorAccessor&lt;<span class="type">scalar_t</span>, <span class="number">2</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt; points,</span></span></span><br><span class="line"><span class="params"><span class="function">    torch::PackedTensorAccessor&lt;<span class="type">scalar_t</span>, <span class="number">3</span>, torch::RestrictPtrTraits, <span class="type">size_t</span>&gt; dL_dfeats</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> f = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (n&gt;=feats.<span class="built_in">size</span>(<span class="number">0</span>) || f&gt;=feats.<span class="built_in">size</span>(<span class="number">2</span>)) <span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// point -1~1</span></span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> u = (points[n][<span class="number">0</span>]+<span class="number">1</span>)/<span class="number">2</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> v = (points[n][<span class="number">1</span>]+<span class="number">1</span>)/<span class="number">2</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> w = (points[n][<span class="number">2</span>]+<span class="number">1</span>)/<span class="number">2</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> a = (<span class="number">1</span>-v)*(<span class="number">1</span>-w);</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> b = (<span class="number">1</span>-v)*w;</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> c = v*(<span class="number">1</span>-w);</span><br><span class="line">    <span class="type">const</span> <span class="type">scalar_t</span> d = <span class="number">1</span>-a-b-c;</span><br><span class="line"></span><br><span class="line">    dL_dfeats[n][<span class="number">0</span>][f] = (<span class="number">1</span>-u)*a*dL_dfeat_interp[n][f];</span><br><span class="line">    dL_dfeats[n][<span class="number">1</span>][f] = (<span class="number">1</span>-u)*b*dL_dfeat_interp[n][f];</span><br><span class="line">    dL_dfeats[n][<span class="number">2</span>][f] = (<span class="number">1</span>-u)*c*dL_dfeat_interp[n][f];</span><br><span class="line">    dL_dfeats[n][<span class="number">3</span>][f] = (<span class="number">1</span>-u)*d*dL_dfeat_interp[n][f];</span><br><span class="line">    dL_dfeats[n][<span class="number">4</span>][f] = u*a*dL_dfeat_interp[n][f];</span><br><span class="line">    dL_dfeats[n][<span class="number">5</span>][f] = u*b*dL_dfeat_interp[n][f];</span><br><span class="line">    dL_dfeats[n][<span class="number">6</span>][f] = u*c*dL_dfeat_interp[n][f];</span><br><span class="line">    dL_dfeats[n][<span class="number">7</span>][f] = u*d*dL_dfeat_interp[n][f];</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="PYBIND11ç»‘å®šå‡½æ•°"><a href="#PYBIND11ç»‘å®šå‡½æ•°" class="headerlink" title="PYBIND11ç»‘å®šå‡½æ•°"></a>PYBIND11ç»‘å®šå‡½æ•°</h3><p>å†™å¥½äº†åå‘ä¼ æ’­å‡½æ•°ä¹‹åï¼Œä¸è¦å¿˜è®°ç»‘å®šå‡½æ•°ï¼Œè¿™æ ·æˆ‘ä»¬æ‰èƒ½åœ¨æœ€åçš„pythonä¸­è°ƒç”¨å¯¹åº”çš„å‡½æ•°ã€‚</p>
<figure class="highlight c++"><table><tbody><tr><td class="code"><pre><span class="line"><span class="function">torch::Tensor <span class="title">trilinear_interpolation_fw</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::Tensor feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::Tensor points</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>{</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(feats);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(points);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">trilinear_fw_cu</span>(feats, points);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">torch::Tensor <span class="title">trilinear_interpolation_bw</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::Tensor dL_dfeat_interp,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::Tensor feats,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> torch::Tensor points</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>{</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(dL_dfeat_interp);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(feats);</span><br><span class="line">    <span class="built_in">CHECK_INPUT</span>(points);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">trilinear_bw_cu</span>(dL_dfeat_interp, feats, points);</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(TORCH_EXTENSION_NAME, m){</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">"trilinear_interpolation_fw"</span>, &amp;trilinear_interpolation_fw);</span><br><span class="line">    m.<span class="built_in">def</span>(<span class="string">"trilinear_interpolation_bw"</span>, &amp;trilinear_interpolation_bw);</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="torch-autograd-Functionå°è£…"><a href="#torch-autograd-Functionå°è£…" class="headerlink" title="torch.autograd.Functionå°è£…"></a>torch.autograd.Functionå°è£…</h3><p>ä¸ºäº†ä½¿ç”¨pytorchçš„<code>autograd</code>æˆ‘ä»¬è¿˜å·®æœ€åä¸€æ­¥ï¼Œå°±æ˜¯ä½¿ç”¨<code>torch.autograd.Function</code>è¿›è¡Œå°è£…ï¼Œä¸ç„¶çš„è¯ä¸èƒ½è¿›è¡Œåå‘ä¼ æ’­ï¼Œä¼šå‡ºç°ä¸€äº›å¥‡å¥‡æ€ªæ€ªçš„bugã€‚</p>
<p>åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œé¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰<code>forward</code>å’Œ<code>backward</code>å‡½æ•°ï¼Œ<strong>è®°å¾—æˆ‘ä»¬éƒ½éœ€è¦å®šä¹‰<code>@staticmethod</code>è£…é¥°å™¨ï¼Œè¿™ä¸ªæ˜¯ä¸€å®šè¦çš„ã€‚</strong>æ¥ä¸‹æ¥æˆ‘ä»¬å°±å¯ä»¥å¼€å§‹å®Œå–„<code>forward</code>å’Œ<code>backward</code>å‡½æ•°ã€‚åœ¨ä¸¤ä¸ªå‡½æ•°ä¸­ï¼Œå®é™…ä¸Šæˆ‘ä»¬å°±æ˜¯è°ƒç”¨C++æ‰©å±•å†™å¥½çš„å‡½æ•°ï¼Œè¿™é‡Œé¢å”¯ä¸€ä¸€ä¸ªéœ€è¦æ³¨æ„çš„å°±æ˜¯<code>ctx</code>ï¼Œå®é™…ä¸Šè¿™é‡Œæ˜¯<code>context</code>çš„ç¼©å†™ï¼Œè¿™é‡Œå°±æ˜¯è¡¨ç¤ºæœ‰ä»€ä¹ˆæ•°æ®éœ€è¦è¿›è¡Œä¿å­˜åœ¨åå‘ä¼ æ’­ä¸­ä½¿ç”¨åˆ°ï¼Œå› ä¸ºåœ¨<code>backward</code>æˆ‘ä»¬è¿˜è¦ä¼ å…¥å¯¹åº”çš„<code>feats</code>å’Œ<code>points</code>ï¼Œæ‰€ä»¥åœ¨è¿™é‡Œè¿™ä¸¤ä¸ªå‚æ•°éƒ½éœ€è¦<code>save_for_backward</code>ã€‚</p>
<p>æœ€åçš„<code>backward</code>å°±æ›´ç®€å•äº†ï¼Œä¼ å…¥çš„å‚æ•°ä¸<code>forward</code>è¿”å›çš„å‚æ•°è¿›è¡Œå¯¹åº”ï¼Œæ¥ç€æˆ‘ä»¬ä»<code>ctx</code>å–å‡ºéœ€è¦ç”¨åˆ°çš„å‚æ•°ï¼Œä»<code>ctx.saved_tensors</code>ä¸­å–å‡ºï¼Œåç»­åªéœ€è¦è°ƒç”¨å¯¹åº”çš„C++å‡½æ•°å³å¯ï¼Œåœ¨è¿™é‡Œé¢æˆ‘ä»¬è¿”å›äº†ä¸¤ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯<code>dL_dfeats, None</code>ï¼Œè¿™ä¸€éƒ¨åˆ†æ˜¯å› ä¸ºå®é™…ä¸Šæ˜¯å› ä¸ºï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªå‚æ•°ï¼Œåˆ†åˆ«<code>feats, points</code>ï¼Œè€Œæˆ‘ä»¬å¹¶æ²¡æœ‰å¯¹<code>points</code>è¿›è¡Œè®¡ç®—å¾®åˆ†ï¼Œæ‰€ä»¥è¿™é‡Œå°±è¿”å›Noneã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Trilinear_interpolation_cuda</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, feats, points</span>):</span><br><span class="line">        feat_interp = cppcuda_tutorial.trilinear_interpolation_fw(feats, points)</span><br><span class="line"></span><br><span class="line">        ctx.save_for_backward(feats, points)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> feat_interp</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, dL_dfeat_interp</span>):</span><br><span class="line">        feats, points = ctx.saved_tensors</span><br><span class="line"></span><br><span class="line">        dL_dfeats = cppcuda_tutorial.trilinear_interpolation_bw(dL_dfeat_interp.contiguous(), feats, points)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dL_dfeats, <span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="backwardéªŒè¯ä¸æ¯”è¾ƒ"><a href="#backwardéªŒè¯ä¸æ¯”è¾ƒ" class="headerlink" title="backwardéªŒè¯ä¸æ¯”è¾ƒ"></a>backwardéªŒè¯ä¸æ¯”è¾ƒ</h3><p>å’Œä¸Šè¿°ä¸€æ ·ï¼Œç»è¿‡<code>python setup.py install</code>ä»¥åï¼ˆæ¯æ¬¡ä¿®æ”¹åéƒ½è¦é‡æ–°è¿è¡Œ<code>setup.py</code>ï¼‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥è¿›è¡Œè¿è¡Œäº†ï¼Œåœ¨è¿™é‡Œé¢ä¸ºäº†éªŒè¯ç»“æœçš„æ­£ç¡®æ€§å’Œä¸pytorchæœ¬èº«çš„åå‘ä¼ æ’­è¿›è¡Œæ¯”è¾ƒï¼Œæ¯”è¾ƒä¸¤è€…çš„ç»“æœå’Œæ—¶é—´æ•ˆç‡ï¼Œ<code>test.py</code>çš„ä¸»å‡½æ•°å¦‚ä¸‹ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Trilinear_interpolation_cuda</span>(torch.autograd.Function):</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, feats, points</span>):</span><br><span class="line">        feat_interp = cppcuda_tutorial.trilinear_interpolation_fw(feats, points)</span><br><span class="line"></span><br><span class="line">        ctx.save_for_backward(feats, points)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> feat_interp</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, dL_dfeat_interp</span>):</span><br><span class="line">        feats, points = ctx.saved_tensors</span><br><span class="line"></span><br><span class="line">        dL_dfeats = cppcuda_tutorial.trilinear_interpolation_bw(dL_dfeat_interp.contiguous(), feats, points)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dL_dfeats, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    N = <span class="number">65536</span>; F = <span class="number">256</span></span><br><span class="line">    rand = torch.rand(N, <span class="number">8</span>, F, device=<span class="string">'cuda'</span>)</span><br><span class="line">    feats = rand.clone().requires_grad_()</span><br><span class="line">    feats2 = rand.clone().requires_grad_()</span><br><span class="line">    points = torch.rand(N, <span class="number">3</span>, device=<span class="string">'cuda'</span>)*<span class="number">2</span>-<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    t = time.time()</span><br><span class="line">    <span class="comment"># è°ƒç”¨CUDAè®¡ç®—</span></span><br><span class="line">    out_cuda = Trilinear_interpolation_cuda.apply(feats2, points)</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'   cuda fw time'</span>, time.time()-t, <span class="string">'s'</span>)</span><br><span class="line"></span><br><span class="line">    t = time.time()</span><br><span class="line">    out_py = trilinear_interpolation_py(feats, points)</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'pytorch fw time'</span>, time.time()-t, <span class="string">'s'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'fw all close'</span>, torch.allclose(out_py, out_cuda))</span><br><span class="line"></span><br><span class="line">    t = time.time()</span><br><span class="line">    <span class="comment"># CUDAåå‘ä¼ æ’­</span></span><br><span class="line">    loss2 = out_cuda.<span class="built_in">sum</span>()</span><br><span class="line">    loss2.backward()</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'   cuda bw time'</span>, time.time()-t, <span class="string">'s'</span>)</span><br><span class="line"></span><br><span class="line">    t = time.time()</span><br><span class="line">    loss = out_py.<span class="built_in">sum</span>()</span><br><span class="line">    loss.backward()</span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'pytorch bw time'</span>, time.time()-t, <span class="string">'s'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">'bw all close'</span>, torch.allclose(feats.grad, feats2.grad))</span><br></pre></td></tr></tbody></table></figure>
<p>ç»è¿‡è¿è¡Œå’Œè®¡ç®—åï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä»¥ä¸‹ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼ŒCUDAå’ŒPytorchå‰å‘ä¼ æ’­ç›¸å·®ä¸å¤§ï¼Œä½†æ˜¯å¯¹äºåå‘ä¼ æ’­çš„æ•ˆç‡å¯ä»¥çœ‹å¾—å‡ºæ¥ï¼Œç»“æœå¤§æ¦‚å·®äº†10å€æ‰€æœ‰ï¼ŒCUDAçš„åå‘ä¼ æ’­è¿˜æ˜¯æœ‰ä¸€ä¸ªè¾ƒä¸ºæ˜æ˜¾çš„æ•ˆç‡æå‡çš„ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">   cuda fw time 0.0033109188079833984 s</span><br><span class="line">pytorch fw time 0.004142045974731445 s</span><br><span class="line">fw all close True</span><br><span class="line">   cuda bw time 0.004648447036743164 s</span><br><span class="line">pytorch bw time 0.04614758491516113 s</span><br><span class="line">bw all close True</span><br></pre></td></tr></tbody></table></figure>
<h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><p>è§†é¢‘èµ„æ–™ï¼š <a href="https://www.youtube.com/watch?v=l_Rpk6CRJYI&amp;list=PLDV2CyUo4q-LKuiNltBqCKdO9GH4SS_ec&amp;ab_channel=AIè‘µ">https://www.youtube.com/watch?v=l_Rpk6CRJYI&amp;list=PLDV2CyUo4q-LKuiNltBqCKdO9GH4SS_ec&amp;ab_channel=AI%E8%91%B5</a></p>
<p>Githubï¼š<a href="https://github.com/kwea123/pytorch-cppcuda-tutorial">https://github.com/kwea123/pytorch-cppcuda-tutorial</a></p>
<p>Pytorchå®˜æ–¹èµ„æ–™ï¼š<a href="https://pytorch.org/cppdocs/">https://pytorch.org/cppdocs/</a>ï¼Œ<a href="https://pytorch.org/tutorials/advanced/cpp_extension.html">https://pytorch.org/tutorials/advanced/cpp_extension.html</a></p>
<p>CUDA docï¼š<a href="https://nyu-cds.github.io/python-gpu/02-cuda/">https://nyu-cds.github.io/python-gpu/02-cuda/</a></p>
]]></content>
      <categories>
        <category>CUDA</category>
      </categories>
      <tags>
        <tag>CUDA</tag>
      </tags>
  </entry>
  <entry>
    <title>EMO Emote Portrait Alive - é˜¿é‡ŒHumanAIGC</title>
    <url>/2024/03/03/Paperscape/EMO/</url>
    <content><![CDATA[<h1 id="EMO-Emote-Portrait-Alive-é˜¿é‡ŒHumanAIGC"><a href="#EMO-Emote-Portrait-Alive-é˜¿é‡ŒHumanAIGC" class="headerlink" title="EMO: Emote Portrait Alive - é˜¿é‡ŒHumanAIGC"></a>EMO: Emote Portrait Alive - é˜¿é‡ŒHumanAIGC</h1><p>æœ€è¿‘è¿™ä¸€ä¸ªæ˜ŸæœŸï¼Œä¹Ÿå°±æ˜¯2æœˆ28æ—¥çš„æ—¶å€™ï¼Œé˜¿é‡Œå·´å·´çš„HumanAIGCå›¢é˜Ÿå‘å¸ƒäº†ä¸€æ¬¾å…¨æ–°çš„ç”Ÿæˆå¼AIæ¨¡å‹EMOï¼ˆEmote Portrait Aliveï¼‰ã€‚EMOä»…éœ€ä¸€å¼ äººç‰©è‚–åƒç…§ç‰‡å’ŒéŸ³é¢‘ï¼Œå°±å¯ä»¥è®©ç…§ç‰‡ä¸­çš„äººç‰©æŒ‰ç…§éŸ³é¢‘å†…å®¹â€œå¼ å˜´â€å”±æ­Œã€è¯´è¯ï¼Œä¸”å£å‹åŸºæœ¬ä¸€è‡´ï¼Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿æ€éå¸¸è‡ªç„¶ï¼Œå‘å¸ƒçš„è§†é¢‘æ•ˆæœéå¸¸å¥½ï¼Œå¥½çš„å‡ ä¹éš¾ä»¥ç½®ä¿¡ï¼Œç‰¹åˆ«æ˜¯è”¡å¾å¤å”±rapçš„ç¬¬ä¸€æ®µï¼Œæ•ˆæœéå¸¸å¥½ã€‚</p>
<p><strong>EMOä¸ä»…èƒ½å¤Ÿç”Ÿæˆå”±æ­Œå’Œè¯´è¯çš„è§†é¢‘ï¼Œè¿˜èƒ½åœ¨ä¿æŒè§’è‰²èº«ä»½ç¨³å®šæ€§çš„åŒæ—¶ï¼Œæ ¹æ®è¾“å…¥éŸ³é¢‘çš„é•¿åº¦ç”Ÿæˆä¸åŒæ—¶é•¿çš„è§†é¢‘ã€‚</strong></p>
<p>æ‰€ä»¥æˆ‘å°±æƒ³å€Ÿæ­¤æœºä¼šï¼Œå­¦ä¹ ä¸€ä¸‹EMOçš„å¤§æ¦‚æ¡†æ¶ï¼Œå‰–æä¸€ä¸‹é‡Œé¢çš„ä¸€äº›æŠ€æœ¯è¦ç‚¹ï¼Œé¦–å…ˆç»™å‡ºè®ºæ–‡çš„é“¾æ¥å’Œä»£ç é“¾æ¥ï¼Œä¸è¿‡HumanAIGCå·²ç»å¾ˆä¹…æ²¡æœ‰å¼€æºä»£ç äº†ï¼Œä¸è¿‡æŠ€æœ¯æ–¹å‘è¿˜æ˜¯å€¼å¾—ä¸€çœ‹çš„ã€‚</p>
<p>è®ºæ–‡ï¼š<a href="https://arxiv.org/abs/2402.17485v1">EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions</a></p>
<p>é¡¹ç›®ï¼š<a href="https://humanaigc.github.io/emote-portrait-alive/">https://humanaigc.github.io/emote-portrait-alive/</a></p>
<p>æˆ‘ä¹Ÿä¸€ç›´æœ‰å…³æ³¨è¿™ä¸€éƒ¨åˆ†çš„æŠ€æœ¯ï¼Œå¤§å®¶ä¹Ÿå¯ä»¥å…³æ³¨æˆ‘çš„æ•°å­—äººçŸ¥è¯†åº“<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis">https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis</a></p>
<h2 id="Diffusionç›¸å…³"><a href="#Diffusionç›¸å…³" class="headerlink" title="Diffusionç›¸å…³"></a>Diffusionç›¸å…³</h2><p>åœ¨ä¹‹å‰çš„ä¸€äº›ç ”ç©¶ä¸­ï¼Œæœ‰è¿‡ç”¨DiffusionåšTalking head generationçš„ï¼Œæ¯”å¦‚Diffusion headå’ŒCVPR2023çš„DiffTalkç­‰è®ºæ–‡ï¼Œè¿™äº›è®ºæ–‡éƒ½æ˜¯ç”¨Diffusionå¾—å¼ºå¤§ç”Ÿæˆèƒ½åŠ›æ¥å®ŒæˆéŸ³é¢‘é©±åŠ¨çš„äººè„¸ç”Ÿæˆã€‚</p>
<p>è¿™é‡Œé€å¸§ç”Ÿæˆä¸éŸ³é¢‘å¯¹åº”çš„äººè„¸çš„å›¾åƒï¼Œmaskäººè„¸ä¸­å˜´å”‡çš„éƒ¨åˆ†ï¼Œç„¶åé€æ­¥ç”Ÿæˆè§†é¢‘ï¼Œ<strong>è¿™ä¸ªè¿‡ç¨‹ç›¸å½“äºï¼ŒAIå…ˆçœ‹ä¸€ä¸‹ç…§ç‰‡ï¼Œç„¶åæ‰“å¼€å£°éŸ³ï¼Œå†éšç€å£°éŸ³ä¸€å¼ ä¸€å¼ åœ°ç”»å‡ºè§†é¢‘ä¸­æ¯ä¸€å¸§å˜åŒ–çš„å›¾åƒã€‚</strong></p>
<p><img src="https://picx.zhimg.com/v2-24c8ad5651ce25627b3e8bfff24d85b1.png" alt="DiffTalk"></p>
<p>å¦‚æœæˆ‘ä»¬çœ‹Diffusion Headè®ºæ–‡ï¼Œä¹Ÿæ˜¯ç±»ä¼¼çš„åšæ³•ï¼Œéƒ½æ˜¯é€šè¿‡Diffusionçš„å¼ºå¤§èƒ½åŠ›å®Œæˆè§†é¢‘çš„ç”Ÿæˆã€‚</p>
<p><img src="https://pica.zhimg.com/v2-3e6497aae4c003eb72bb3f24224c89ee.png" alt="Overview"></p>
<h2 id="EMOæ•´ä½“æ¡†æ¶"><a href="#EMOæ•´ä½“æ¡†æ¶" class="headerlink" title="EMOæ•´ä½“æ¡†æ¶"></a>EMOæ•´ä½“æ¡†æ¶</h2><p>æ¥ä¸‹æ¥å¼€å§‹å‰–æä¸€ä¸‹EMOçš„æ¡†æ¶ï¼Œä¸DiffTalkå’ŒDiffusion Headsç±»ä¼¼ï¼Œéƒ½æ˜¯åˆ©ç”¨Diffusionæ¥ç”Ÿæˆï¼Œä¹Ÿæ˜¯æ ¹æ®ä¸€ä¸ªå‚è€ƒå›¾åƒæ¥é€å¸§ç”Ÿæˆå›¾ç‰‡æœ€åå¾—åˆ°è§†é¢‘ã€‚</p>
<p><img src="https://pica.zhimg.com/v2-24facf74c8152c3d19d0e57fce19c9b2.png" alt="EMO"></p>
<p>ä¸åŒçš„æ˜¯ï¼ŒEMOçš„å·¥ä½œè¿‡ç¨‹åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š</p>
<ol>
<li>é¦–å…ˆï¼Œåˆ©ç”¨å‚è€ƒç½‘ç»œï¼ˆReferenceNetï¼‰ä»å‚è€ƒå›¾åƒå’ŒåŠ¨ä½œå¸§ä¸­æå–ç‰¹å¾ï¼›</li>
<li>ç„¶åï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„éŸ³é¢‘ç¼–ç å™¨å¤„ç†å£°éŸ³å¹¶åµŒå…¥ï¼Œå†ç»“åˆå¤šå¸§å™ªå£°å’Œé¢éƒ¨åŒºåŸŸæ©ç æ¥ç”Ÿæˆè§†é¢‘ã€‚</li>
</ol>
<p>è¯¥æ¡†æ¶è¿˜èåˆäº†ä¸¤ç§æ³¨æ„æœºåˆ¶å’Œæ—¶é—´æ¨¡å—ï¼Œä»¥ç¡®ä¿è§†é¢‘ä¸­è§’è‰²èº«ä»½çš„ä¸€è‡´æ€§å’ŒåŠ¨ä½œçš„è‡ªç„¶æµç•…ã€‚æˆ‘è§‰å¾—å®é™…ä¸Šè¿™é‡Œæ˜¯æœ€é‡è¦çš„ä¸€éƒ¨åˆ†ï¼Œè¿™ä¸€éƒ¨åˆ†ä¹Ÿæ˜¯å’Œä¹‹å‰Diffusionæ–¹æ³•ä¸åŒçš„ç‚¹ï¼Œå…¶å®è¿™ä¸€éƒ¨ä»½åˆå’ŒHumanAIGCä¹‹å‰åšçš„ç§‘ç›®ä¸‰é©±åŠ¨çš„æ–¹å¼å¾ˆåƒï¼Œä¹Ÿå°±æ˜¯é‚£ç¯‡AnimateAnyoneè®ºæ–‡ï¼Œè¿™ä¸€éƒ¨åˆ†ä¹Ÿæ˜¯ç«ğŸ”¥äº†å¾ˆä¹…ï¼Œç°åœ¨ä¹Ÿæœ‰äººå¤ç°äº†è¯¥æ–¹æ³•ï¼Œä¸è¿‡è¿˜æ²¡æœ‰å¼€æºã€‚</p>
<p>æ ¹æ®EMOçš„è®ºæ–‡ä¸é¡¹ç›®çš„å±•ç°çš„ç»“æœï¼ŒEMOä¸ä»…ä»…èƒ½äº§ç”Ÿéå¸¸Amazingçš„å¯¹å£å‹è§†é¢‘ï¼Œè¿˜èƒ½ç”Ÿæˆå„ç§é£æ ¼çš„æ­Œå”±è§†é¢‘ï¼Œæ— è®ºæ˜¯åœ¨è¡¨ç°åŠ›è¿˜æ˜¯çœŸå®æ„Ÿæ–¹é¢éƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ï¼Œå¦‚DreamTalkã€Wav2Lipå’ŒSadTalkerã€‚</p>
<p><img src="https://picx.zhimg.com/v2-6492e24fb03ffa98135dc584535ab7d9.png" alt="EMOæ•´ä½“æ¡†æ¶"></p>
<h2 id="EMOå·¥ä½œåŸç†"><a href="#EMOå·¥ä½œåŸç†" class="headerlink" title="EMOå·¥ä½œåŸç†"></a>EMOå·¥ä½œåŸç†</h2><p>ä»EMOçš„æ¡†æ¶å¯ä»¥çœ‹åˆ°ï¼Œåˆ©ç”¨éª¨å¹²ç½‘ç»œè·å–å¤šå¸§å™ªå£°æ½œåœ¨è¾“å…¥ï¼Œå¹¶å°è¯•åœ¨æ¯ä¸ªæ—¶é—´æ­¥å°†å®ƒä»¬å»å™ªåˆ°è¿ç»­çš„è§†é¢‘å¸§ï¼Œè¿™ä¸ªéª¨å¹²ç½‘ç»œæ˜¯ç±»ä¼¼äºSD 1.5çš„UNetçš„ç»“æ„é…ç½®ã€‚ä¸ä¹‹å‰çš„SD1.5ä¸åŒçš„æ˜¯ï¼Œæœ¬èº«çš„SDæ˜¯ä½¿ç”¨æ–‡æœ¬åµŒå…¥çš„ï¼Œè€Œç°åœ¨æ˜¯ä½¿ç”¨å‚è€ƒç‰¹å¾ã€‚</p>
<ol>
<li>ä¸ä¹‹å‰çš„å·¥ä½œç±»ä¼¼ï¼Œä¸ºäº†ç¡®ä¿ç”Ÿæˆçš„å¸§ä¹‹é—´çš„è¿ç»­æ€§ï¼Œéª¨å¹²ç½‘ç»œåµŒå…¥äº†æ—¶é—´æ¨¡å—ã€‚ </li>
<li>ä¸ºäº†ä¿æŒç”Ÿæˆå¸§ä¸­è‚–åƒçš„IDä¸€è‡´æ€§ï¼Œä½¿ç”¨äº†ä¸€ä¸ªä¸Backboneå¹¶è¡Œçš„ç§°ä¸ºReferenceNetçš„UNetç»“æ„ï¼Œå®ƒè¾“å…¥å‚è€ƒå›¾åƒä»¥è·å¾—å‚è€ƒç‰¹å¾ã€‚ </li>
<li>ä¸ºäº†é©±åŠ¨è§’è‰²è¯´è¯åŠ¨ä½œï¼Œåˆ©ç”¨éŸ³é¢‘å±‚å¯¹è¯­éŸ³ç‰¹å¾è¿›è¡Œç¼–ç ã€‚ </li>
<li>ä¸ºäº†ä½¿è¯´è¯è§’è‰²çš„è¿åŠ¨å¯æ§ä¸”ç¨³å®šï¼Œæˆ‘ä»¬ä½¿ç”¨é¢éƒ¨å®šä½å™¨å’Œé€Ÿåº¦å±‚æ¥æä¾›å¼±æ¡ä»¶ã€‚</li>
</ol>
<p><strong>é¢„è®­ç»ƒéŸ³é¢‘ç¼–ç å™¨ï¼š</strong>EMOä½¿ç”¨é¢„è®­ç»ƒçš„éŸ³é¢‘ç¼–ç å™¨ï¼ˆå¦‚wav2vecï¼‰æ¥å¤„ç†è¾“å…¥éŸ³é¢‘ã€‚è¿™äº›ç¼–ç å™¨æå–éŸ³é¢‘ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾éšåç”¨äºé©±åŠ¨è§†é¢‘ä¸­çš„è§’è‰²åŠ¨ä½œï¼ŒåŒ…æ‹¬å£å‹å’Œé¢éƒ¨è¡¨æƒ…ã€‚è¿™é‡Œé¢è¿˜æ˜¯ä½¿ç”¨é™„åŠ ç‰¹å¾mæ¥è§£å†³åŠ¨ä½œå¯èƒ½ä¼šå—åˆ°æœªæ¥/è¿‡å»éŸ³é¢‘ç‰‡æ®µçš„å½±å“ï¼Œä¾‹å¦‚è¯´è¯å‰å¼ å˜´å’Œå¸æ°”ã€‚</p>
<p><strong>å‚è€ƒç½‘ç»œï¼ˆReferenceNetï¼‰ï¼š</strong>è¯¥ç½‘ç»œä»å•ä¸ªå‚è€ƒå›¾åƒä¸­æå–ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾åœ¨è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­ç”¨äºä¿æŒè§’è‰²çš„èº«ä»½ä¸€è‡´æ€§ã€‚ReferenceNetä¸ç”Ÿæˆç½‘ç»œï¼ˆBackbone Networkï¼‰å¹¶è¡Œå·¥ä½œï¼Œè¾“å…¥å‚è€ƒå›¾åƒä»¥è·å–å‚è€ƒç‰¹å¾ã€‚</p>
<p><strong>éª¨å¹²ç½‘ç»œï¼ˆBackbone Networkï¼‰ï¼š</strong>Backbone Networkæ¥æ”¶å¤šå¸§å™ªå£°ï¼ˆæ¥è‡ªå‚è€ƒå›¾åƒå’ŒéŸ³é¢‘ç‰¹å¾çš„ç»“åˆï¼‰å¹¶å°è¯•å°†å…¶å»å™ªä¸ºè¿ç»­çš„è§†é¢‘å¸§ã€‚è¿™ä¸ªç½‘ç»œé‡‡ç”¨äº†ç±»ä¼¼äºStable Diffusionçš„UNetç»“æ„ï¼Œå…¶ä¸­åŒ…å«äº†ç”¨äºç»´æŒç”Ÿæˆå¸§ä¹‹é—´è¿ç»­æ€§çš„æ—¶é—´æ¨¡å—ã€‚ </p>
<p><strong>æ³¨æ„åŠ›æœºåˆ¶ï¼š</strong>EMOåˆ©ç”¨ä¸¤ç§å½¢å¼çš„æ³¨æ„åŠ›æœºåˆ¶â€”â€”<strong>å‚è€ƒæ³¨æ„åŠ›ï¼ˆReference-Attentionï¼‰å’ŒéŸ³é¢‘æ³¨æ„åŠ›ï¼ˆAudio-Attentionï¼‰</strong>ã€‚å‚è€ƒæ³¨æ„åŠ›ç”¨äºä¿æŒè§’è‰²èº«ä»½çš„ä¸€è‡´æ€§ï¼Œè€ŒéŸ³é¢‘æ³¨æ„åŠ›åˆ™ç”¨äºè°ƒæ•´è§’è‰²çš„åŠ¨ä½œï¼Œä½¿ä¹‹ä¸éŸ³é¢‘ä¿¡å·ç›¸åŒ¹é…ã€‚ </p>
<p><strong>æ—¶é—´æ¨¡å—ï¼š</strong>è¿™äº›æ¨¡å—ç”¨äºæ“çºµæ—¶é—´ç»´åº¦å¹¶è°ƒæ•´åŠ¨ä½œé€Ÿåº¦ï¼Œä»¥ç”Ÿæˆæµç•…ä¸”è¿è´¯çš„è§†é¢‘åºåˆ—ã€‚æ—¶é—´æ¨¡å—é€šè¿‡è‡ªæ³¨æ„åŠ›å±‚è·¨å¸§æ•è·åŠ¨æ€å†…å®¹ï¼Œæœ‰æ•ˆåœ°åœ¨ä¸åŒçš„è§†é¢‘ç‰‡æ®µä¹‹é—´ç»´æŒä¸€è‡´æ€§ã€‚</p>
<p><strong>è®­ç»ƒç­–ç•¥ï¼š</strong>EMOçš„è®­ç»ƒåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šå›¾åƒé¢„è®­ç»ƒã€è§†é¢‘è®­ç»ƒå’Œé€Ÿåº¦å±‚è®­ç»ƒã€‚åœ¨å›¾åƒé¢„è®­ç»ƒé˜¶æ®µï¼ŒBackbone Networkå’ŒReferenceNetåœ¨å•å¸§ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè€Œåœ¨è§†é¢‘è®­ç»ƒé˜¶æ®µï¼Œå¼•å…¥æ—¶é—´æ¨¡å—å’ŒéŸ³é¢‘å±‚ï¼Œå¤„ç†è¿ç»­å¸§ã€‚é€Ÿåº¦å±‚çš„è®­ç»ƒåœ¨æœ€åé˜¶æ®µè¿›è¡Œï¼Œä»¥ç»†åŒ–è§’è‰²å¤´éƒ¨çš„ç§»åŠ¨é€Ÿåº¦å’Œé¢‘ç‡ã€‚</p>
<p><strong>å»å™ªè¿‡ç¨‹ï¼š</strong>åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼ŒBackbone Networkå°è¯•å»é™¤å¤šå¸§å™ªå£°ï¼Œç”Ÿæˆè¿ç»­çš„è§†é¢‘å¸§ã€‚å»å™ªè¿‡ç¨‹ä¸­ï¼Œå‚è€ƒç‰¹å¾å’ŒéŸ³é¢‘ç‰¹å¾è¢«ç»“åˆä½¿ç”¨ï¼Œä»¥ç”Ÿæˆé«˜åº¦çœŸå®å’Œè¡¨æƒ…ä¸°å¯Œçš„è§†é¢‘å†…å®¹ã€‚</p>
<p>EMOæ¨¡å‹é€šè¿‡è¿™ç§ç»“åˆä½¿ç”¨å‚è€ƒå›¾åƒã€éŸ³é¢‘ä¿¡å·ã€å’Œæ—¶é—´ä¿¡æ¯çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆä¸è¾“å…¥éŸ³é¢‘åŒæ­¥ä¸”åœ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ä¸Šå¯Œæœ‰è¡¨ç°åŠ›çš„è‚–åƒè§†é¢‘ï¼Œè¶…è¶Šäº†ä¼ ç»ŸæŠ€æœ¯çš„é™åˆ¶ï¼Œåˆ›é€ å‡ºæ›´åŠ è‡ªç„¶å’Œé€¼çœŸçš„åŠ¨ç”»æ•ˆæœã€‚</p>
<h2 id="EMOè®­ç»ƒé˜¶æ®µ"><a href="#EMOè®­ç»ƒé˜¶æ®µ" class="headerlink" title="EMOè®­ç»ƒé˜¶æ®µ"></a>EMOè®­ç»ƒé˜¶æ®µ</h2><p>è®­ç»ƒåˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼Œ<strong>å›¾åƒé¢„è®­ç»ƒã€è§†é¢‘è®­ç»ƒå’Œé€Ÿåº¦å±‚è®­ç»ƒã€‚</strong></p>
<ul>
<li><p>åœ¨å›¾åƒé¢„è®­ç»ƒé˜¶æ®µï¼Œç½‘ç»œä»¥å•å¸§å›¾åƒä¸ºè¾“å…¥è¿›è¡Œè®­ç»ƒã€‚æ­¤é˜¶æ®µï¼ŒBackbone å°†å•ä¸ªå¸§ä½œä¸ºè¾“å…¥ï¼Œè€Œ ReferenceNet å¤„ç†æ¥è‡ªåŒä¸€å¸§çš„ä¸åŒçš„ã€éšæœºé€‰æ‹©çš„å¸§ï¼Œä»åŸå§‹ SD åˆå§‹åŒ–æƒé‡</p>
</li>
<li><p>åœ¨è§†é¢‘è®­ç»ƒé˜¶æ®µï¼Œå¼•å…¥æ—¶é—´æ¨¡å—å’ŒéŸ³é¢‘å±‚ï¼Œå¤„ç†è¿ç»­å¸§ï¼Œä»è§†é¢‘å‰ªè¾‘ä¸­é‡‡æ ·n+fä¸ªè¿ç»­å¸§ï¼Œå¼€å§‹çš„nå¸§æ˜¯è¿åŠ¨å¸§ã€‚æ—¶é—´æ¨¡å—ä»AnimateDiffåˆå§‹åŒ–æƒé‡ã€‚</p>
</li>
<li><p>é€Ÿåº¦å±‚è®­ç»ƒä¸“æ³¨äºè°ƒæ•´è§’è‰²å¤´éƒ¨çš„ç§»åŠ¨é€Ÿåº¦å’Œé¢‘ç‡ã€‚</p>
</li>
</ul>
<p>è¿™äº›è¯¦ç»†ä¿¡æ¯æä¾›äº†å¯¹EMOæ¨¡å‹è®­ç»ƒå’Œå…¶å‚æ•°é…ç½®çš„æ·±å…¥äº†è§£ï¼Œçªæ˜¾äº†å…¶åœ¨å¤„ç†å¹¿æ³›å’Œå¤šæ ·åŒ–æ•°æ®é›†æ–¹é¢çš„èƒ½åŠ›ï¼Œä»¥åŠå…¶åœ¨ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›å’Œé€¼çœŸè‚–åƒè§†é¢‘æ–¹é¢çš„å…ˆè¿›æ€§èƒ½ã€‚</p>
<h2 id="EMOå®éªŒè®¾ç½®"><a href="#EMOå®éªŒè®¾ç½®" class="headerlink" title="EMOå®éªŒè®¾ç½®"></a>EMOå®éªŒè®¾ç½®</h2><p>EMOçš„æ•°æ®é›†æœ‰ä¸¤éƒ¨ä»½ï¼Œé¦–å…ˆHumanAIGCå›¢é˜Ÿä»äº’è”ç½‘ä¸­æ”¶é›†äº† <strong>è¶…è¿‡250å°æ—¶çš„è§†é¢‘å’Œè¶…è¿‡1.5äº¿å¼ å›¾åƒ</strong>ï¼ŒåŒæ—¶åŠ å…¥äº†æ¥è‡ªäº’è”ç½‘å’ŒHDTFä»¥åŠVFHQæ•°æ®é›†ä½œä¸ºè¡¥å……ã€‚è¿™é‡Œé¢çš„æ•°æ®é›†å¤šç§å¤šæ ·ï¼ŒåŒ…æ‹¬æ¼”è®²ã€ç”µå½±å’Œç”µè§†å‰ªè¾‘ä»¥åŠæ­Œå”±è¡¨æ¼”ï¼Œæ¶µç›–äº†å¤šç§è¯­è¨€ï¼Œå¦‚ä¸­æ–‡å’Œè‹±æ–‡ï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆæœ€åèƒ½è¡¨ç°å‡ºå¦‚æ­¤å¥½æ•ˆæœçš„åŸå› ã€‚</p>
<p>åœ¨ç¬¬ä¸€é˜¶æ®µçš„æ—¶å€™ï¼Œä½¿ç”¨VFHQæ•°æ®é›†ï¼Œå› ä¸ºå®ƒä¸åŒ…å«éŸ³é¢‘ã€‚ç„¶åå†å¯¹è§†é¢‘è¿›è¡Œé¢„å¤„ç†ï¼Œæ‰€æœ‰çš„è§†é¢‘å¯é€šè¿‡MediaPipeæ¥è·å–äººè„¸æ£€æµ‹æ¡†åŒºåŸŸï¼Œå¹¶ä¸”è£å‰ªåˆ°512Ã—512çš„åˆ†è¾¨ç‡ã€‚</p>
<p>åœ¨ç¬¬ä¸€è®­ç»ƒé˜¶æ®µï¼Œæ‰¹å¤„ç†å¤§å°BatchSizeè®¾ç½®ä¸º48ã€‚åœ¨ç¬¬äºŒå’Œç¬¬ä¸‰è®­ç»ƒé˜¶æ®µï¼Œç”Ÿæˆè§†é¢‘é•¿åº¦è®¾ç½®ä¸ºf=12ï¼Œè¿åŠ¨å¸§æ•°è®¾ç½®ä¸ºn=4ï¼Œè®­ç»ƒçš„æ‰¹å¤„ç†å¤§å°ä¸º4ï¼Œå­¦ä¹ ç‡åœ¨æ‰€æœ‰é˜¶æ®µå‡è®¾ç½®ä¸º1e-5ã€‚</p>
<p>åœ¨æ¨ç†æ—¶ï¼Œä½¿ç”¨DDIMçš„é‡‡æ ·ç®—æ³•ç”Ÿæˆè§†é¢‘ã€‚æ—¶é—´æ­¥å¤§çº¦æ˜¯40æ­¥ï¼Œä¸ºæ¯ä¸€å¸§ç”ŸæˆæŒ‡å®šä¸€ä¸ªæ’å®šçš„é€Ÿåº¦å€¼ï¼Œæœ€åæ–¹æ³•çš„ç»“æœç”Ÿæˆä¸€æ‰¹ï¼ˆf=12å¸§ï¼‰çš„æ—¶é—´å¤§çº¦ä¸º15ç§’ã€‚ </p>
<p>ä¸€èˆ¬è§†é¢‘çš„é•¿åº¦ä¸º25ï½30å¸§å·¦å³ï¼Œå¦‚æœæˆ‘ä»¬è®¤ä¸ºæ˜¯1minsçš„è§†é¢‘ï¼Œä¹Ÿå°±æ˜¯60sçš„è§†é¢‘ï¼Œé‚£å°±æ˜¯60*25=1500ï¼Œ1500/15 = 100sï¼Œä¹Ÿå°±æ˜¯å¤§æ¦‚éœ€è¦1mins40sèƒ½ç”Ÿæˆä¸€åˆ†é’Ÿçš„è§†é¢‘ï¼Œé€Ÿåº¦ä¹Ÿå¾—åˆ°äº†ä¸é”™çš„æ”¹è¿›ï¼Œè™½ç„¶æ²¡æœ‰å®æ—¶ï¼Œä½†æ˜¯ç»“æœå·²ç»å¾ˆå¥½äº†ã€‚</p>
<h2 id="EMOç‰¹ç‚¹"><a href="#EMOç‰¹ç‚¹" class="headerlink" title="EMOç‰¹ç‚¹"></a>EMOç‰¹ç‚¹</h2><p>EMOæ¨¡å‹æœ‰å¦‚ä¸‹ç‰¹ç‚¹ï¼š</p>
<p><strong>ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆï¼š</strong>EMOé‡‡ç”¨ç›´æ¥ä»éŸ³é¢‘åˆæˆè§†é¢‘çš„æ–¹æ³•ï¼Œæ— éœ€ä¸­é—´çš„3Dæ¨¡å‹æˆ–é¢éƒ¨æ ‡å¿—ï¼Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹ï¼ŒåŒæ—¶ä¿æŒäº†é«˜åº¦çš„è¡¨ç°åŠ›å’Œè‡ªç„¶æ€§ã€‚</p>
<p><strong>æ— ç¼å¸§è¿‡æ¸¡ä¸èº«ä»½ä¿æŒï¼š</strong>è¯¥æ–¹æ³•ç¡®ä¿è§†é¢‘å¸§ä¹‹é—´çš„æ— ç¼è¿‡æ¸¡å’Œè§†é¢‘ä¸­èº«ä»½çš„ä¸€è‡´æ€§ï¼Œç”Ÿæˆçš„åŠ¨ç”»æ—¢ç”ŸåŠ¨åˆé€¼çœŸã€‚</p>
<p><strong>è¡¨è¾¾åŠ›ä¸çœŸå®æ€§ï¼š</strong>å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEMOä¸ä»…èƒ½ç”Ÿæˆä»¤äººä¿¡æœçš„è¯´è¯è§†é¢‘ï¼Œè€Œä¸”è¿˜èƒ½ç”Ÿæˆå„ç§é£æ ¼çš„æ­Œå”±è§†é¢‘ï¼Œå…¶è¡¨ç°åŠ›å’ŒçœŸå®æ€§æ˜¾è‘—è¶…è¿‡ç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚</p>
<p><strong>çµæ´»çš„è§†é¢‘æ—¶é•¿ç”Ÿæˆï¼š</strong>EMOå¯ä»¥æ ¹æ®è¾“å…¥éŸ³é¢‘çš„é•¿åº¦ç”Ÿæˆä»»æ„æ—¶é•¿çš„è§†é¢‘ï¼Œæä¾›äº†æå¤§çš„çµæ´»æ€§ã€‚</p>
<p><strong>é¢å‘è¡¨æƒ…çš„è§†é¢‘ç”Ÿæˆï¼š</strong>EMOä¸“æ³¨äºé€šè¿‡éŸ³é¢‘æç¤ºç”Ÿæˆè¡¨æƒ…ä¸°å¯Œçš„è‚–åƒè§†é¢‘ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†è¯´è¯å’Œå”±æ­Œåœºæ™¯æ—¶ï¼Œå¯ä»¥æ•æ‰åˆ°å¤æ‚çš„é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿æ€å˜åŒ–ã€‚</p>
<p>è¿™äº›ç‰¹ç‚¹å…±åŒæ„æˆäº†EMOæ¨¡å‹çš„æ ¸å¿ƒç«äº‰åŠ›ï¼Œä½¿å…¶åœ¨åŠ¨æ€è‚–åƒè§†é¢‘ç”Ÿæˆé¢†åŸŸè¡¨ç°å‡ºè‰²ã€‚</p>
<h2 id="EMOç¼ºé™·"><a href="#EMOç¼ºé™·" class="headerlink" title="EMOç¼ºé™·"></a>EMOç¼ºé™·</h2><p>å¯¹äºEMOæ¥è¯´ï¼Œä¹Ÿä¼šæœ‰ä¸€äº›é™åˆ¶ã€‚</p>
<ul>
<li><p>é¦–å…ˆï¼Œä¸ä¸ä¾èµ–æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒæ›´è€—æ—¶ã€‚</p>
</li>
<li><p>å…¶æ¬¡ï¼Œç”±äºä¸ä½¿ç”¨ä»»ä½•æ˜ç¡®çš„æ§åˆ¶ä¿¡å·æ¥æ§åˆ¶è§’è‰²çš„è¿åŠ¨ï¼Œå› æ­¤å¯èƒ½ä¼šå¯¼è‡´æ— æ„ä¸­ç”Ÿæˆå…¶ä»–èº«ä½“éƒ¨ä½ï¼ˆä¾‹å¦‚æ‰‹ï¼‰ï¼Œä»è€Œå¯¼è‡´è§†é¢‘ä¸­å‡ºç°ä¼ªå½±ã€‚</p>
</li>
</ul>
<p>æ‰€ä»¥è¿™æ ·çš„ä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœè¦è§£å†³çš„è¯ï¼Œå¯ä»¥è€ƒè™‘ç”¨ä¸“é—¨æ§åˆ¶èº«ä½“éƒ¨ä½çš„æ§åˆ¶ä¿¡å·ï¼Œè¿™æ ·å°±ä¼šè¾ƒå¥½çš„è§£å†³è¿™ä¸ªæ–¹æ³•ï¼Œæ¯ä¸€ä¸ªä¿¡å·æ§åˆ¶ä¸€éƒ¨åˆ†ï¼Œå°±ä¸ä¼šç”Ÿæˆé”™è¯¯ã€‚</p>
<p>å‚è€ƒ</p>
<ul>
<li><a href="https://m.huxiu.com/article/2728417.html">https://m.huxiu.com/article/2728417.html</a></li>
</ul>
]]></content>
      <categories>
        <category>Paperscape</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
        <tag>Talking Head Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Tmuxä½¿ç”¨æ•™ç¨‹</title>
    <url>/2024/01/01/Linux/Tmux%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/</url>
    <content><![CDATA[<h2 id="1-tmuxä»‹ç»"><a href="#1-tmuxä»‹ç»" class="headerlink" title="1. tmuxä»‹ç»"></a>1. tmuxä»‹ç»</h2><h3 id="1-1-ä¼šè¯ä¸è¿›ç¨‹"><a href="#1-1-ä¼šè¯ä¸è¿›ç¨‹" class="headerlink" title="1.1 ä¼šè¯ä¸è¿›ç¨‹"></a>1.1 ä¼šè¯ä¸è¿›ç¨‹</h3><p>å‘½ä»¤è¡Œçš„å…¸å‹ä½¿ç”¨æ–¹å¼æ˜¯ï¼Œæ‰“å¼€ä¸€ä¸ªç»ˆç«¯çª—å£ï¼ˆterminal windowï¼Œä»¥ä¸‹ç®€ç§°â€œçª—å£â€ï¼‰ï¼Œåœ¨é‡Œé¢è¾“å…¥å‘½ä»¤ã€‚<strong>ç”¨æˆ·ä¸è®¡ç®—æœºçš„è¿™ç§ä¸´æ—¶çš„äº¤äº’ï¼Œç§°ä¸ºä¸€æ¬¡â€œä¼šè¯â€ï¼ˆsessionï¼‰</strong> ã€‚</p>
<p>ä¼šè¯çš„ä¸€ä¸ªé‡è¦ç‰¹ç‚¹æ˜¯ï¼Œçª—å£ä¸å…¶ä¸­å¯åŠ¨çš„è¿›ç¨‹æ˜¯<a href="https://www.ruanyifeng.com/blog/2016/02/linux-daemon.html">è¿åœ¨ä¸€èµ·</a>çš„ã€‚æ‰“å¼€çª—å£ï¼Œä¼šè¯å¼€å§‹ï¼›å…³é—­çª—å£ï¼Œä¼šè¯ç»“æŸï¼Œä¼šè¯å†…éƒ¨çš„è¿›ç¨‹ä¹Ÿä¼šéšä¹‹ç»ˆæ­¢ï¼Œä¸ç®¡æœ‰æ²¡æœ‰è¿è¡Œå®Œã€‚</p>
<p>ä¸€ä¸ªå…¸å‹çš„ä¾‹å­å°±æ˜¯ï¼Œ<a href="https://www.ruanyifeng.com/blog/2011/12/ssh_remote_login.html">SSH ç™»å½•</a>è¿œç¨‹è®¡ç®—æœºï¼Œæ‰“å¼€ä¸€ä¸ªè¿œç¨‹çª—å£æ‰§è¡Œå‘½ä»¤ã€‚è¿™æ—¶ï¼Œç½‘ç»œçªç„¶æ–­çº¿ï¼Œå†æ¬¡ç™»å½•çš„æ—¶å€™ï¼Œæ˜¯æ‰¾ä¸å›ä¸Šä¸€æ¬¡æ‰§è¡Œçš„å‘½ä»¤çš„ã€‚å› ä¸ºä¸Šä¸€æ¬¡ SSH ä¼šè¯å·²ç»ç»ˆæ­¢äº†ï¼Œé‡Œé¢çš„è¿›ç¨‹ä¹Ÿéšä¹‹æ¶ˆå¤±äº†ã€‚</p>
<p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¼šè¯ä¸çª—å£å¯ä»¥â€œè§£ç»‘â€ï¼šçª—å£å…³é—­æ—¶ï¼Œä¼šè¯å¹¶ä¸ç»ˆæ­¢ï¼Œè€Œæ˜¯ç»§ç»­è¿è¡Œï¼Œç­‰åˆ°ä»¥åéœ€è¦çš„æ—¶å€™ï¼Œå†è®©ä¼šè¯â€œç»‘å®šâ€å…¶ä»–çª—å£ã€‚</p>
<h3 id="1-2-Tmux-çš„ä½œç”¨"><a href="#1-2-Tmux-çš„ä½œç”¨" class="headerlink" title="1.2 Tmux çš„ä½œç”¨"></a>1.2 Tmux çš„ä½œç”¨</h3><p><strong>Tmux å°±æ˜¯ä¼šè¯ä¸çª—å£çš„â€œè§£ç»‘â€å·¥å…·ï¼Œå°†å®ƒä»¬å½»åº•åˆ†ç¦»ã€‚</strong></p>
<p>ï¼ˆ1ï¼‰å®ƒå…è®¸åœ¨å•ä¸ªçª—å£ä¸­ï¼ŒåŒæ—¶è®¿é—®å¤šä¸ªä¼šè¯ã€‚è¿™å¯¹äºåŒæ—¶è¿è¡Œå¤šä¸ªå‘½ä»¤è¡Œç¨‹åºå¾ˆæœ‰ç”¨ã€‚</p>
<p>ï¼ˆ2ï¼‰ å®ƒå¯ä»¥è®©æ–°çª—å£â€œæ¥å…¥â€å·²ç»å­˜åœ¨çš„ä¼šè¯ã€‚</p>
<p>ï¼ˆ3ï¼‰å®ƒå…è®¸æ¯ä¸ªä¼šè¯æœ‰å¤šä¸ªè¿æ¥çª—å£ï¼Œå› æ­¤å¯ä»¥å¤šäººå®æ—¶å…±äº«ä¼šè¯ã€‚</p>
<p>ï¼ˆ4ï¼‰å®ƒè¿˜æ”¯æŒçª—å£ä»»æ„çš„å‚ç›´å’Œæ°´å¹³æ‹†åˆ†ã€‚</p>
<p>ç±»ä¼¼çš„ç»ˆç«¯å¤ç”¨å™¨è¿˜æœ‰ GNU Screenã€‚Tmux ä¸å®ƒåŠŸèƒ½ç›¸ä¼¼ï¼Œä½†æ˜¯æ›´æ˜“ç”¨ï¼Œä¹Ÿæ›´å¼ºå¤§ã€‚äºŒã€åŸºæœ¬ç”¨æ³•</p>
<h2 id="2-tmuxå®‰è£…"><a href="#2-tmuxå®‰è£…" class="headerlink" title="2. tmuxå®‰è£…"></a>2. tmuxå®‰è£…</h2><h3 id="2-1-å®‰è£…"><a href="#2-1-å®‰è£…" class="headerlink" title="2.1 å®‰è£…"></a>2.1 å®‰è£…</h3><p>Tmux ä¸€èˆ¬éœ€è¦è‡ªå·±å®‰è£…ã€‚</p>
<h1 id="Ubuntu-æˆ–-Debian"><a href="#Ubuntu-æˆ–-Debian" class="headerlink" title="Ubuntu æˆ– Debian"></a>Ubuntu æˆ– Debian</h1><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">sudo apt-get install tmux</span><br><span class="line"><span class="comment"># CentOS æˆ– Fedora</span></span><br><span class="line">sudo yum install tmux</span><br><span class="line"><span class="comment"># Mac</span></span><br><span class="line">brew install tmux</span><br></pre></td></tr></tbody></table></figure>
<h3 id="2-2-å¯åŠ¨ä¸é€€å‡º"><a href="#2-2-å¯åŠ¨ä¸é€€å‡º" class="headerlink" title="2.2 å¯åŠ¨ä¸é€€å‡º"></a>2.2 å¯åŠ¨ä¸é€€å‡º</h3><p>å®‰è£…å®Œæˆåï¼Œé”®å…¥<code>tmux</code>å‘½ä»¤ï¼Œå°±è¿›å…¥äº† Tmux çª—å£ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">tmux</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸Šé¢å‘½ä»¤ä¼šå¯åŠ¨ Tmux çª—å£ï¼Œåº•éƒ¨æœ‰ä¸€ä¸ªçŠ¶æ€æ ã€‚çŠ¶æ€æ çš„å·¦ä¾§æ˜¯çª—å£ä¿¡æ¯ï¼ˆç¼–å·å’Œåç§°ï¼‰ï¼Œå³ä¾§æ˜¯ç³»ç»Ÿä¿¡æ¯ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-3a8a91db08866f19a26aa93ac8b40fc4.png" alt=""></p>
<p>æŒ‰ä¸‹<code>Ctrl+d</code>æˆ–è€…æ˜¾å¼è¾“å…¥<code>exit</code>å‘½ä»¤ï¼Œå°±å¯ä»¥é€€å‡º Tmux çª—å£ã€‚</p>
<p>exit</p>
<h3 id="2-3-å‰ç¼€é”®"><a href="#2-3-å‰ç¼€é”®" class="headerlink" title="2.3 å‰ç¼€é”®"></a>2.3 å‰ç¼€é”®</h3><p>Tmux çª—å£æœ‰å¤§é‡çš„å¿«æ·é”®ã€‚æ‰€æœ‰å¿«æ·é”®éƒ½è¦é€šè¿‡å‰ç¼€é”®å”¤èµ·ã€‚é»˜è®¤çš„å‰ç¼€é”®æ˜¯<code>Ctrl+b</code>ï¼Œå³å…ˆæŒ‰ä¸‹<code>Ctrl+b</code>ï¼Œå¿«æ·é”®æ‰ä¼šç”Ÿæ•ˆã€‚</p>
<p>ä¸¾ä¾‹æ¥è¯´ï¼Œå¸®åŠ©å‘½ä»¤çš„å¿«æ·é”®æ˜¯<code>Ctrl+b ?</code>ã€‚å®ƒçš„ç”¨æ³•æ˜¯ï¼Œåœ¨ Tmux çª—å£ä¸­ï¼Œå…ˆæŒ‰ä¸‹<code>Ctrl+b</code>ï¼Œå†æŒ‰ä¸‹<code>?</code>ï¼Œå°±ä¼šæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ã€‚</p>
<p>ç„¶åï¼ŒæŒ‰ä¸‹ ESC é”®æˆ–<code>q</code>é”®ï¼Œå°±å¯ä»¥é€€å‡ºå¸®åŠ©ã€‚</p>
<h2 id="3-å¸¸ç”¨å‘½ä»¤"><a href="#3-å¸¸ç”¨å‘½ä»¤" class="headerlink" title="3. å¸¸ç”¨å‘½ä»¤"></a>3. å¸¸ç”¨å‘½ä»¤</h2><h3 id="3-1-æ–°å»ºä¼šè¯"><a href="#3-1-æ–°å»ºä¼šè¯" class="headerlink" title="3.1 æ–°å»ºä¼šè¯"></a>3.1 æ–°å»ºä¼šè¯</h3><p>ç¬¬ä¸€ä¸ªå¯åŠ¨çš„ Tmux çª—å£ï¼Œç¼–å·æ˜¯<code>0</code>ï¼Œç¬¬äºŒä¸ªçª—å£çš„ç¼–å·æ˜¯<code>1</code>ï¼Œä»¥æ­¤ç±»æ¨ã€‚è¿™äº›çª—å£å¯¹åº”çš„ä¼šè¯ï¼Œå°±æ˜¯ 0 å·ä¼šè¯ã€1 å·ä¼šè¯ã€‚</p>
<p>ä½¿ç”¨ç¼–å·åŒºåˆ†ä¼šè¯ï¼Œä¸å¤ªç›´è§‚ï¼Œæ›´å¥½çš„æ–¹æ³•æ˜¯ä¸ºä¼šè¯èµ·åã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">tmux new -s &lt;session-name&gt;</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸Šé¢å‘½ä»¤æ–°å»ºä¸€ä¸ªæŒ‡å®šåç§°çš„ä¼šè¯ã€‚</p>
<h3 id="3-2-åˆ†ç¦»ä¼šè¯"><a href="#3-2-åˆ†ç¦»ä¼šè¯" class="headerlink" title="3.2 åˆ†ç¦»ä¼šè¯"></a>3.2 åˆ†ç¦»ä¼šè¯</h3><p>åœ¨ Tmux çª—å£ä¸­ï¼ŒæŒ‰ä¸‹<code>Ctrl+b d</code>æˆ–è€…è¾“å…¥<code>tmux detach</code>å‘½ä»¤ï¼Œå°±ä¼šå°†å½“å‰ä¼šè¯ä¸çª—å£åˆ†ç¦»ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">tmux detach</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸Šé¢å‘½ä»¤æ‰§è¡Œåï¼Œå°±ä¼šé€€å‡ºå½“å‰ Tmux çª—å£ï¼Œä½†æ˜¯ä¼šè¯å’Œé‡Œé¢çš„è¿›ç¨‹ä»ç„¶åœ¨åå°è¿è¡Œã€‚</p>
<p><code>tmux ls</code>å‘½ä»¤å¯ä»¥æŸ¥çœ‹å½“å‰æ‰€æœ‰çš„ Tmux ä¼šè¯ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">tmux <span class="built_in">ls</span></span><br><span class="line"><span class="comment"># ortmux list-session</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="3-3-æ¥å…¥ä¼šè¯"><a href="#3-3-æ¥å…¥ä¼šè¯" class="headerlink" title="3.3 æ¥å…¥ä¼šè¯"></a>3.3 æ¥å…¥ä¼šè¯</h3><p><code>tmux attach</code>å‘½ä»¤ç”¨äºé‡æ–°æ¥å…¥æŸä¸ªå·²å­˜åœ¨çš„ä¼šè¯ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># ä½¿ç”¨ä¼šè¯ç¼–å·</span></span><br><span class="line">tmux attach -t 0</span><br><span class="line"><span class="comment"># ä½¿ç”¨ä¼šè¯åç§°</span></span><br><span class="line">tmux attach -t &lt;session-name&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="3-4-æ€æ­»ä¼šè¯"><a href="#3-4-æ€æ­»ä¼šè¯" class="headerlink" title="3.4 æ€æ­»ä¼šè¯"></a>3.4 æ€æ­»ä¼šè¯</h3><p><code>tmux kill-session</code>å‘½ä»¤ç”¨äºæ€æ­»æŸä¸ªä¼šè¯ã€‚</p>
<h1 id="ä½¿ç”¨ä¼šè¯ç¼–å·"><a href="#ä½¿ç”¨ä¼šè¯ç¼–å·" class="headerlink" title="ä½¿ç”¨ä¼šè¯ç¼–å·"></a>ä½¿ç”¨ä¼šè¯ç¼–å·</h1><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">tmux kill-session -t 0</span><br><span class="line"><span class="comment"># ä½¿ç”¨ä¼šè¯åç§°</span></span><br><span class="line">tmux kill-session -t &lt;session-name&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="3-5-åˆ‡æ¢ä¼šè¯"><a href="#3-5-åˆ‡æ¢ä¼šè¯" class="headerlink" title="3.5 åˆ‡æ¢ä¼šè¯"></a>3.5 åˆ‡æ¢ä¼šè¯</h3><p><code>tmux switch</code>å‘½ä»¤ç”¨äºåˆ‡æ¢ä¼šè¯ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># ä½¿ç”¨ä¼šè¯ç¼–å·</span></span><br><span class="line">tmux switch -t 0</span><br><span class="line"><span class="comment"># ä½¿ç”¨ä¼šè¯åç§°</span></span><br><span class="line">tmux switch -t &lt;session-name&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="3-6-é‡å‘½åä¼šè¯"><a href="#3-6-é‡å‘½åä¼šè¯" class="headerlink" title="3.6 é‡å‘½åä¼šè¯"></a>3.6 é‡å‘½åä¼šè¯</h3><p><code>tmux rename-session</code>å‘½ä»¤ç”¨äºé‡å‘½åä¼šè¯ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">tmux rename-session -t 0 &lt;new-name&gt;</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸Šé¢å‘½ä»¤å°†0å·ä¼šè¯é‡å‘½åã€‚</p>
<h3 id="3-7-ä¼šè¯å¿«æ·é”®"><a href="#3-7-ä¼šè¯å¿«æ·é”®" class="headerlink" title="3.7 ä¼šè¯å¿«æ·é”®"></a>3.7 ä¼šè¯å¿«æ·é”®</h3><p>ä¸‹é¢æ˜¯ä¸€äº›ä¼šè¯ç›¸å…³çš„å¿«æ·é”®ã€‚</p>
<p>Ctrl+b dï¼šåˆ†ç¦»å½“å‰ä¼šè¯ã€‚Ctrl+b sï¼šåˆ—å‡ºæ‰€æœ‰ä¼šè¯ã€‚Ctrl+b $ï¼šé‡å‘½åå½“å‰ä¼šè¯ã€‚</p>
<h2 id="4-æœ€ç®€æ“ä½œæµç¨‹"><a href="#4-æœ€ç®€æ“ä½œæµç¨‹" class="headerlink" title="4. æœ€ç®€æ“ä½œæµç¨‹"></a>4. æœ€ç®€æ“ä½œæµç¨‹</h2><p>ç»¼ä¸Šæ‰€è¿°ï¼Œä»¥ä¸‹æ˜¯ Tmux çš„æœ€ç®€æ“ä½œæµç¨‹ã€‚</p>
<p>æ–°å»ºä¼šè¯<code>tmux new -s my_session</code>,åœ¨ Tmux çª—å£è¿è¡Œæ‰€éœ€çš„ç¨‹åºã€‚æŒ‰ä¸‹å¿«æ·é”®<code>Ctrl+b d</code>å°†ä¼šè¯åˆ†ç¦»ã€‚ä¸‹æ¬¡ä½¿ç”¨æ—¶ï¼Œé‡æ–°è¿æ¥åˆ°ä¼šè¯<code>tmux attach-session -t my_session</code>ã€‚</p>
<h3 id="çª—æ ¼å¿«æ·é”®"><a href="#çª—æ ¼å¿«æ·é”®" class="headerlink" title="çª—æ ¼å¿«æ·é”®"></a>çª—æ ¼å¿«æ·é”®</h3><p>ä¸‹é¢æ˜¯ä¸€äº›çª—æ ¼æ“ä½œçš„å¿«æ·é”®ã€‚</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>å¿«æ·é”®</th>
<th>åŠŸèƒ½</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ctrl+b %</td>
<td>åˆ’åˆ†å·¦å³ä¸¤ä¸ªçª—æ ¼</td>
</tr>
<tr>
<td>Ctrl+b â€œ</td>
<td>åˆ’åˆ†ä¸Šä¸‹ä¸¤ä¸ªçª—æ ¼</td>
</tr>
<tr>
<td>Ctrl+b <arrow key=""></arrow></td>
<td>å…‰æ ‡åˆ‡æ¢åˆ°å…¶ä»–çª—æ ¼ã€‚<arrow key="">æ˜¯æŒ‡å‘è¦åˆ‡æ¢åˆ°çš„çª—æ ¼çš„æ–¹å‘é”®ï¼Œæ¯”å¦‚åˆ‡æ¢åˆ°ä¸‹æ–¹çª—æ ¼ï¼Œå°±æŒ‰æ–¹å‘é”®â†“</arrow></td>
</tr>
<tr>
<td>Ctrl+b ;</td>
<td>å…‰æ ‡åˆ‡æ¢åˆ°ä¸Šä¸€ä¸ªçª—æ ¼</td>
</tr>
<tr>
<td>Ctrl+b o</td>
<td>å…‰æ ‡åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªçª—æ ¼</td>
</tr>
<tr>
<td>Ctrl+b {</td>
<td>å½“å‰çª—æ ¼ä¸ä¸Šä¸€ä¸ªçª—æ ¼äº¤æ¢ä½ç½®</td>
</tr>
<tr>
<td>Ctrl+b }</td>
<td>å½“å‰çª—æ ¼ä¸ä¸‹ä¸€ä¸ªçª—æ ¼äº¤æ¢ä½ç½®</td>
</tr>
<tr>
<td>Ctrl+b Ctrl+o</td>
<td>æ‰€æœ‰çª—æ ¼å‘å‰ç§»åŠ¨ä¸€ä¸ªä½ç½®ï¼Œç¬¬ä¸€ä¸ªçª—æ ¼å˜æˆæœ€åä¸€ä¸ªçª—æ ¼</td>
</tr>
<tr>
<td>Ctrl+b Alt+o</td>
<td>æ‰€æœ‰çª—æ ¼å‘åç§»åŠ¨ä¸€ä¸ªä½ç½®ï¼Œæœ€åä¸€ä¸ªçª—æ ¼å˜æˆç¬¬ä¸€ä¸ªçª—æ ¼</td>
</tr>
<tr>
<td>Ctrl+b x</td>
<td>å…³é—­å½“å‰çª—æ ¼</td>
</tr>
<tr>
<td>Ctrl+b !</td>
<td>å°†å½“å‰çª—æ ¼æ‹†åˆ†ä¸ºä¸€ä¸ªç‹¬ç«‹çª—å£</td>
</tr>
<tr>
<td>Ctrl+b z</td>
<td>å½“å‰çª—æ ¼å…¨å±æ˜¾ç¤ºï¼Œå†ä½¿ç”¨ä¸€æ¬¡ä¼šå˜å›åŸæ¥å¤§å°</td>
</tr>
<tr>
<td>Ctrl+b Ctrl+<arrow key=""></arrow></td>
<td>æŒ‰ç®­å¤´æ–¹å‘è°ƒæ•´çª—æ ¼å¤§å°</td>
</tr>
<tr>
<td>Ctrl+b q</td>
<td>æ˜¾ç¤ºçª—æ ¼ç¼–å·</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>REAL3D-PORTRAIT ONE-SHOT REALISTIC 3D TALKING PORTRAIT SYNTHESIS</title>
    <url>/2024/03/15/Paperscape/Real3D-Portrait/</url>
    <content><![CDATA[<h1 id="REAL3D-PORTRAIT-ONE-SHOT-REALISTIC-3D-TALKING-PORTRAIT-SYNTHESIS"><a href="#REAL3D-PORTRAIT-ONE-SHOT-REALISTIC-3D-TALKING-PORTRAIT-SYNTHESIS" class="headerlink" title="REAL3D-PORTRAIT: ONE-SHOT REALISTIC 3D TALKING PORTRAIT SYNTHESIS"></a>REAL3D-PORTRAIT: ONE-SHOT REALISTIC 3D TALKING PORTRAIT SYNTHESIS</h1><p>Paper     : <a href="https://arxiv.org/pdf/2401.08503.pdf">https://arxiv.org/pdf/2401.08503.pdf</a></p>
<p>Project   : <a href="https://real3dportrait.github.io/">https://real3dportrait.github.io/</a></p>
<p>Code      : <a href="https://github.com/yerfor/Real3DPortrait">https://github.com/yerfor/Real3DPortrait</a></p>
<p>Rebuttal: <a href="https://real3dportrait.github.io/static/pages/rebuttal.html">https://real3dportrait.github.io/static/pages/rebuttal.html</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>(1) ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººåƒç”Ÿæˆæ—¨åœ¨æ ¹æ®é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰åˆæˆè¯´è¯äººåƒè§†é¢‘ã€‚è¿™æ˜¯ä¸€ä¸ªè®¡ç®—æœºå›¾å½¢å­¦å’Œè®¡ç®—æœºè§†è§‰ä¸­é•¿æœŸå­˜åœ¨çš„è·¨æ¨¡æ€ä»»åŠ¡ï¼Œå…·æœ‰è§†é¢‘ä¼šè®®å’Œè™šæ‹Ÿç°å® (VR) ç­‰å¤šé¡¹å®é™…åº”ç”¨ã€‚å…ˆå‰çš„ 2D æ–¹æ³•å¯ä»¥äº§ç”Ÿé€¼çœŸçš„è§†é¢‘ï¼Œè¿™è¦å½’åŠŸäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) çš„å¼ºå¤§åŠŸèƒ½ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ˜¾å¼çš„ 3D å»ºæ¨¡ï¼Œè¿™äº› 2D æ–¹æ³•åœ¨å¤´éƒ¨å¤§å¹…ç§»åŠ¨æ—¶ä¼šé¢ä¸´å˜å½¢ä¼ªå½±å’Œä¸çœŸå®çš„å¤±çœŸã€‚åœ¨è¿‡å»çš„å‡ å¹´ä¸­ï¼ŒåŸºäºç¥ç»è¾å°„åœº (NeRF) çš„ 3D æ–¹æ³•ä¸€ç›´å ä¸»å¯¼åœ°ä½ï¼Œå› ä¸ºå®ƒä»¬ä¿æŒé€¼çœŸçš„ 3D å‡ ä½•å½¢çŠ¶å¹¶ä¿ç•™ä¸°å¯Œçš„çº¹ç†ç»†èŠ‚ï¼Œå³ä½¿åœ¨å¤´éƒ¨å§¿åŠ¿è¾ƒå¤§çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ç„¶è€Œï¼Œåœ¨å¤§å¤šæ•°æ–¹æ³•ä¸­ï¼Œæ¨¡å‹éƒ½è¿‡åº¦æ‹Ÿåˆç‰¹å®šçš„äººï¼Œè¿™éœ€è¦ä¸ºæ¯ä¸ªçœ‹ä¸è§çš„èº«ä»½è¿›è¡Œæ˜‚è´µçš„å•ç‹¬è®­ç»ƒã€‚æ¢ç´¢å•æ¬¡æ‹æ‘„ 3D è¯´è¯äººåƒç”Ÿæˆçš„ä»»åŠ¡å¾ˆæœ‰å¸Œæœ›ï¼Œå³ç»™å®šä¸€ä¸ªçœ‹ä¸è§çš„äººçš„å‚è€ƒå›¾åƒï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†å…¶æå‡åˆ° 3D å¤´åƒå¹¶ä½¿ç”¨è¾“å…¥æ¡ä»¶å¯¹å…¶è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼Œä»¥è·å¾—é€¼çœŸçš„ 3D è¯´è¯äººè§†é¢‘ã€‚éšç€ 3D ç”Ÿæˆæ¨¡å‹çš„æœ€æ–°è¿›å±•ï¼Œå¯ä»¥å­¦ä¹ åˆ°æ¨å¹¿åˆ°å„ç§èº«ä»½çš„ 3D ä¸‰å¹³é¢è¡¨ç¤ºï¼ˆEG3Dï¼ŒChan et al. (2022)ï¼‰çš„éšè—ç©ºé—´ã€‚è™½ç„¶æœ€è¿‘çš„å·¥ä½œ (Li et al., 2023b; Li, 2023) å¼€åˆ›äº†å•æ¬¡æ‹æ‘„ 3D è¯´è¯äººåƒç”Ÿæˆï¼Œä½†å®ƒä»¬æœªèƒ½åŒæ—¶å®ç°å‡†ç¡®çš„é‡å»ºå’ŒåŠ¨ç”»ã€‚</p>
<p>(2) è¿‡å»çš„æ–¹æ³•ï¼šä¸€äº›å·¥ä½œä»…ä½¿ç”¨ 2D å›¾åƒä½œä¸ºè¾“å…¥ï¼Œè€Œå¦ä¸€äº›å·¥ä½œåˆ™ä½¿ç”¨ 3D å›¾åƒä½œä¸ºè¾“å…¥ã€‚ä½¿ç”¨ 2D å›¾åƒä½œä¸ºè¾“å…¥çš„æ–¹æ³•é€šå¸¸ä¼šäº§ç”Ÿè´¨é‡è¾ƒå·®çš„ç»“æœï¼Œå› ä¸ºå®ƒä»¬æ— æ³•æ•è·å¯¹è±¡çš„ 3D å½¢çŠ¶ã€‚ä½¿ç”¨ 3D å›¾åƒä½œä¸ºè¾“å…¥çš„æ–¹æ³•é€šå¸¸ä¼šäº§ç”Ÿè´¨é‡æ›´å¥½çš„ç»“æœï¼Œä½†å®ƒä»¬éœ€è¦æ˜‚è´µçš„ 3D æ‰«æè®¾å¤‡ã€‚ æœ¬æ–¹æ³•çš„åŠ¨æœºå¾ˆå……åˆ†ã€‚ä½œè€…è®¤ä¸ºï¼Œå•æ¬¡æ‹æ‘„ 3D è¯´è¯äººåƒç”Ÿæˆæ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œéœ€è¦è§£å†³è®¸å¤šé—®é¢˜ã€‚è¿™äº›é—®é¢˜åŒ…æ‹¬ï¼š</p>
<ul>
<li><p>å¦‚ä½•ä»å•å¼  2D å›¾åƒé‡å»ºå‡†ç¡®çš„ 3D æ¨¡å‹ï¼Ÿ</p>
</li>
<li><p>å¦‚ä½•å°† 3D æ¨¡å‹ä¸é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰ç›¸å…³è”ï¼Ÿ</p>
</li>
<li><p>å¦‚ä½•åˆæˆé€¼çœŸçš„è¯´è¯äººåƒè§†é¢‘ï¼Ÿ</p>
<p>ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è§£å†³è¿™äº›é—®é¢˜ï¼Œè¯¥æ–¹æ³•åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š</p>
</li>
</ul>
<ol>
<li>ä»å•å¼  2D å›¾åƒé‡å»ºå‡†ç¡®çš„ 3D æ¨¡å‹ã€‚</li>
<li>å°† 3D æ¨¡å‹ä¸é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰ç›¸å…³è”ã€‚</li>
<li>åˆæˆé€¼çœŸçš„è¯´è¯äººåƒè§†é¢‘ã€‚ ä½œè€…çš„æ–¹æ³•åœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººåƒè§†é¢‘ã€‚</li>
</ol>
<p>(3) ç ”ç©¶æ–¹æ³•ï¼šä½œè€…æå‡ºäº†ä¸€ç§åä¸º Real3D-Portrait çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥ä»å•å¼ å›¾åƒç”Ÿæˆé€¼çœŸçš„ 3D è¯´è¯äººåƒè§†é¢‘ã€‚Real3D-Portrait åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š</p>
<ul>
<li><p>å›¾åƒåˆ°å¹³é¢æ¨¡å‹ï¼šè¯¥æ¨¡å—å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸º 3D ä¸‰å¹³é¢è¡¨ç¤ºã€‚</p>
</li>
<li><p>è¿åŠ¨é€‚é…å™¨ï¼šè¯¥æ¨¡å—å°† 3D ä¸‰å¹³é¢è¡¨ç¤ºä¸é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰ç›¸å…³è”ã€‚</p>
</li>
<li><p>å¤´éƒ¨èº¯å¹²èƒŒæ™¯è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼šè¯¥æ¨¡å—åˆæˆé€¼çœŸçš„è§†é¢‘ï¼Œå…·æœ‰è‡ªç„¶çš„èº¯å¹²è¿åŠ¨å’Œå¯åˆ‡æ¢çš„èƒŒæ™¯ã€‚</p>
</li>
<li><p>éŸ³é¢‘åˆ°è¿åŠ¨æ¨¡å‹ï¼šè¯¥æ¨¡å—æ”¯æŒå•æ¬¡æ‹æ‘„çš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººåƒç”Ÿæˆã€‚</p>
</li>
</ul>
<p>(4) æ€§èƒ½ï¼šReal3D-Portrait åœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººåƒè§†é¢‘ã€‚åœ¨ TalkingHead æ•°æ®é›†ä¸Šï¼ŒReal3D-Portrait çš„å¹³å‡é‡å»ºè¯¯å·®ä¸º 0.006ï¼Œå¹³å‡åŠ¨ç”»è¯¯å·®ä¸º 0.008ã€‚åœ¨ VoxCeleb æ•°æ®é›†ä¸Šï¼ŒReal3D-Portrait çš„å¹³å‡é‡å»ºè¯¯å·®ä¸º 0.007ï¼Œå¹³å‡åŠ¨ç”»è¯¯å·®ä¸º 0.009ã€‚åœ¨ LRW æ•°æ®é›†ä¸Šï¼ŒReal3D-Portrait çš„å¹³å‡é‡å»ºè¯¯å·®ä¸º 0.008ï¼Œå¹³å‡åŠ¨ç”»è¯¯å·®ä¸º 0.010ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒReal3D-Portrait èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººåƒè§†é¢‘ï¼Œå¹¶ä¸”è¯¥æ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°çœ‹ä¸è§çš„èº«ä»½ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡º Real3D-Portrait æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆé€¼çœŸçš„è¯´è¯è‚–åƒè§†é¢‘ã€‚</li>
<li>é‡‡ç”¨å¤§è§„æ¨¡å›¾åƒåˆ°å¹³é¢æ¨¡å‹ï¼Œä» 3D äººè„¸ç”Ÿæˆæ¨¡å‹ä¸­æå– 3D å…ˆéªŒçŸ¥è¯†ï¼Œæé«˜ä¸€å‘ 3D é‡å»ºèƒ½åŠ›ã€‚</li>
<li>ä½¿ç”¨é«˜æ•ˆçš„åŠ¨ä½œé€‚é…å™¨ï¼Œå®ç°å‡†ç¡®çš„åŠ¨ä½œæ¡ä»¶åŠ¨ç”»ã€‚</li>
<li>åˆ©ç”¨å¤´éƒ¨èº¯å¹²èƒŒæ™¯è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼Œåˆæˆå…·æœ‰è‡ªç„¶èº¯å¹²è¿åŠ¨å’Œå¯åˆ‡æ¢èƒŒæ™¯çš„é€¼çœŸè§†é¢‘ã€‚</li>
<li>æ”¯æŒä¸€å‘éŸ³é¢‘é©±åŠ¨çš„è¯´è¯é¢éƒ¨ç”Ÿæˆï¼Œä½¿ç”¨å¯æ¨å¹¿çš„éŸ³é¢‘åˆ°åŠ¨ä½œæ¨¡å‹ã€‚</li>
<li>å¤§é‡å®éªŒè¯æ˜ï¼ŒReal3D-Portrait åœ¨çœ‹ä¸è§çš„èº«ä»½ä¸Šå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”ä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œå¯ä»¥ç”Ÿæˆæ›´é€¼çœŸçš„è¯´è¯è‚–åƒè§†é¢‘ã€‚</li>
</ul>
<p><img src="https://picx.zhimg.com/v2-68585b79de5f83b0dfa23304f41b9b98.png" alt="The inference pipeline of Real3D-Portrait."></p>
]]></content>
      <categories>
        <category>Paperscape</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>SyncTalk The Devil is in the Synchronization for Talking Head Synthesis</title>
    <url>/2024/03/07/Paperscape/SyncTalk/</url>
    <content><![CDATA[<h1 id="SyncTalk-The-Devil-is-in-the-Synchronization-for-Talking-Head-Synthesis"><a href="#SyncTalk-The-Devil-is-in-the-Synchronization-for-Talking-Head-Synthesis" class="headerlink" title="SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis"></a>SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis</h1><p>Paper   : <a href="https://arxiv.org/abs/2311.17590">https://arxiv.org/abs/2311.17590</a></p>
<p>Project : <a href="https://ziqiaopeng.github.io/synctalk/">https://ziqiaopeng.github.io/synctalk/</a></p>
<p>Video    : <a href="https://ziqiaopeng.github.io/synctalk/#teaser">https://ziqiaopeng.github.io/synctalk/#teaser</a></p>
<p>Code    : <a href="https://github.com/ziqiaopeng/SyncTalk">https://github.com/ziqiaopeng/SyncTalk</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>ç¥ç»è¾å°„åœº - ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¡†æ¶ç”¨äºå®ç°è¯´è¯äººå¤´éƒ¨è§†é¢‘çš„åŒæ­¥åˆæˆã€‚</p>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š ç”Ÿæˆé€¼çœŸçš„ã€ç”±è¯­éŸ³é©±åŠ¨çš„è°ˆè¯å¤´éƒ¨è§†é¢‘æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ä¼ ç»Ÿç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰éš¾ä»¥ä¿æŒä¸€è‡´çš„é¢éƒ¨èº«ä»½ï¼Œè€Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•è™½ç„¶å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†é€šå¸¸ä¼šäº§ç”Ÿä¸åŒ¹é…çš„å”‡éƒ¨åŠ¨ä½œã€ä¸å……åˆ†çš„é¢éƒ¨è¡¨æƒ…å’Œä¸ç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ã€‚ä¸€ä¸ªé€¼çœŸçš„è°ˆè¯å¤´éƒ¨éœ€è¦åŒæ­¥åè°ƒä¸»ä½“èº«ä»½ã€å”‡éƒ¨åŠ¨ä½œã€é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚ç¼ºä¹è¿™äº›åŒæ­¥æ˜¯å¯¼è‡´ä¸çœŸå®å’Œäººå·¥ç»“æœçš„æ ¹æœ¬ç¼ºé™·ã€‚ </p>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š GAN æ–¹æ³•éš¾ä»¥ä¿æŒä¸€è‡´çš„é¢éƒ¨èº«ä»½ã€‚NeRF æ–¹æ³•è™½ç„¶å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†é€šå¸¸ä¼šäº§ç”Ÿä¸åŒ¹é…çš„å”‡éƒ¨åŠ¨ä½œã€ä¸å……åˆ†çš„é¢éƒ¨è¡¨æƒ…å’Œä¸ç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ã€‚ </p>
<p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š SyncTalk æ˜¯ä¸€ç§åŸºäº NeRF çš„æ–¹æ³•ï¼Œå®ƒæœ‰æ•ˆåœ°ä¿æŒäº†ä¸»ä½“èº«ä»½ï¼Œå¢å¼ºäº†è°ˆè¯å¤´éƒ¨åˆæˆçš„åŒæ­¥æ€§å’ŒçœŸå®æ€§ã€‚SyncTalk ä½¿ç”¨é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨å°†å”‡éƒ¨åŠ¨ä½œä¸è¯­éŸ³å¯¹é½ï¼Œå¹¶åˆ›æ–°åœ°ä½¿ç”¨ 3D é¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹æ¥æ•æ‰å‡†ç¡®çš„é¢éƒ¨è¡¨æƒ…ã€‚å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ä¼˜åŒ–å¤´éƒ¨å§¿åŠ¿ï¼Œå®ç°æ›´è‡ªç„¶çš„å¤´éƒ¨è¿åŠ¨ã€‚è‚–åƒåŒæ­¥ç”Ÿæˆå™¨æ¢å¤å¤´å‘ç»†èŠ‚ï¼Œå¹¶å°†ç”Ÿæˆçš„å¤´éƒ¨ä¸èº¯å¹²èåˆï¼Œä»¥è·å¾—æ— ç¼çš„è§†è§‰ä½“éªŒã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¿™äº›æ€§èƒ½æ˜¯å¦æ”¯æŒäº†å®ƒä»¬çš„ç›®æ ‡ï¼š SyncTalk åœ¨è°ˆè¯å¤´éƒ¨åˆæˆåŒæ­¥æ€§å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚å¹¿æ³›çš„å®éªŒå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒSyncTalk åœ¨åŒæ­¥æ€§å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>ä¼ ç»Ÿç”Ÿæˆå¯¹æŠ—ç½‘ç»œéš¾ä»¥ç»´æŒä¸€è‡´çš„é¢éƒ¨èº«ä»½ã€‚</li>
<li>ç¥ç»è¾å°„åœºæ–¹æ³•å¯ä»¥è§£å†³é¢éƒ¨èº«ä»½ä¸€è‡´æ€§é—®é¢˜ï¼Œä½†ç»å¸¸å‡ºç°å˜´å”‡è¿åŠ¨ä¸åŒ¹é…ã€é¢éƒ¨è¡¨æƒ…ä¸è¶³å’Œå¤´éƒ¨å§¿åŠ¿ä¸ç¨³å®šçš„é—®é¢˜ã€‚</li>
<li>é€¼çœŸçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘éœ€è¦åŒæ­¥åè°ƒä¸»ä½“èº«ä»½ã€å˜´å”‡è¿åŠ¨ã€é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚</li>
<li>ç¼ºå°‘åŒæ­¥æ€§æ˜¯å¯¼è‡´ä¸çœŸå®å’Œäººä¸ºç»“æœçš„æ ¹æœ¬ç¼ºé™·ã€‚</li>
<li>SyncTalk æ˜¯ä¸€ç§åŸºäºç¥ç»è¾å°„åœºçš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°ä¿æŒäº†ä¸»ä½“èº«ä»½ï¼Œæé«˜äº†è¯´è¯äººå¤´éƒ¨åˆæˆä¸­çš„åŒæ­¥æ€§å’ŒçœŸå®æ„Ÿã€‚</li>
<li>SyncTalk ä½¿ç”¨é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨å°†å˜´å”‡è¿åŠ¨ä¸è¯­éŸ³å¯¹é½ï¼Œå¹¶åˆ›æ–°åœ°ä½¿ç”¨ 3D é¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹æ¥æ•æ‰å‡†ç¡®çš„é¢éƒ¨è¡¨æƒ…ã€‚</li>
<li>SyncTalk çš„å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ä¼˜åŒ–äº†å¤´éƒ¨å§¿åŠ¿ï¼Œå®ç°äº†æ›´è‡ªç„¶çš„å¤´éƒ¨è¿åŠ¨ã€‚</li>
<li>äººåƒåŒæ­¥ç”Ÿæˆå™¨æ¢å¤å¤´å‘ç»†èŠ‚ï¼Œå°†ç”Ÿæˆçš„å¤´éƒ¨ä¸èº¯å¹²èåˆï¼Œä»¥è·å¾—æ— ç¼çš„è§†è§‰ä½“éªŒã€‚</li>
</ul>
<p><img src="https://picx.zhimg.com/v2-a57e0937b2f452009023394a59529dfb.png" alt="SyncTalk"></p>
<h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><p>è¿™ç¯‡è®ºæ–‡ä¸­ï¼Œè§£å†³æœ€å¥½çš„å°±æ˜¯åŒæ­¥çš„é—®é¢˜ï¼Œæ‰€ä»¥ä¹Ÿç§°ä¸ºåŒæ­¥çš„Devil é­”é¬¼ğŸ˜ˆã€‚ç°æœ‰æ–¹æ³•åœ¨å››ä¸ªå…³é”®é¢†åŸŸéœ€è¦æ›´å¤šçš„åŒæ­¥ï¼š<strong>ä¸»ä½“èº«ä»½</strong>ã€<strong>å”‡éƒ¨è¿åŠ¨</strong>ã€<strong>é¢éƒ¨è¡¨æƒ…</strong>å’Œ<strong>å¤´éƒ¨å§¿åŠ¿</strong>ã€‚</p>
<ul>
<li><p>é¦–å…ˆï¼Œåœ¨åŸºäºGANçš„æ–¹æ³•ä¸­ï¼Œç”±äºè¿ç»­å¸§ä¸­ç‰¹å¾çš„ä¸ç¨³å®šæ€§ä»¥åŠä»…ä½¿ç”¨å°‘é‡å¸§ä½œä¸ºé¢éƒ¨é‡å»ºå‚è€ƒï¼Œä¿æŒè§†é¢‘ä¸­ä¸»ä½“çš„èº«ä»½æ˜¯å…·æœ‰æŒ‘æˆ˜æ€§çš„ã€‚</p>
</li>
<li><p>å…¶æ¬¡ï¼Œå”‡éƒ¨è¿åŠ¨ä¸è¯­éŸ³ä¸åŒæ­¥ã€‚åœ¨åŸºäºNeRFçš„æ–¹æ³•ä¸­ï¼Œä»…åŸºäº5åˆ†é’Ÿè¯­éŸ³æ•°æ®é›†è®­ç»ƒçš„éŸ³é¢‘ç‰¹å¾éš¾ä»¥æ³›åŒ–åˆ°ä¸åŒçš„è¯­éŸ³è¾“å…¥ã€‚</p>
</li>
<li><p>ç¬¬ä¸‰ï¼Œç¼ºä¹é¢éƒ¨è¡¨æƒ…æ§åˆ¶ï¼Œå¤§å¤šæ•°æ–¹æ³•åªèƒ½äº§ç”Ÿå”‡éƒ¨è¿åŠ¨æˆ–æ§åˆ¶çœ¨çœ¼ï¼Œå¯¼è‡´é¢éƒ¨åŠ¨ä½œä¸è‡ªç„¶ã€‚</p>
</li>
<li><p>ç¬¬å››ï¼Œå¤´éƒ¨å§¿åŠ¿ä¸åŒæ­¥ã€‚</p>
</li>
</ul>
<p>å…ˆå‰çš„æ–¹æ³•ä¾èµ–äºç¨€ç–çš„landmarksæ¥è®¡ç®—æŠ•å½±è¯¯å·®ï¼Œä½†è¿™äº›landmarksçš„æŠ–åŠ¨å’Œä¸å‡†ç¡®æ€§å¯¼è‡´å¤´éƒ¨å§¿åŠ¿ä¸ç¨³å®šã€‚è¿™äº›åŒæ­¥é—®é¢˜ä¼šå¼•å…¥ä¼ªå½±ï¼Œå¹¶æ˜¾è‘—é™ä½çœŸå®æ„Ÿã€‚</p>
<p>ä¸ºäº†è§£å†³è¿™äº›åŒæ­¥æŒ‘æˆ˜ï¼Œå¼•å…¥äº†SyncTalkï¼Œè¿™æ˜¯ä¸€ç§åŸºäºNeRFçš„æ–¹æ³•ï¼Œä¸“æ³¨äºé«˜åº¦åŒæ­¥ã€é€¼çœŸçš„ã€è¯­éŸ³é©±åŠ¨çš„è¯´è¯å¤´éƒ¨åˆæˆï¼Œé‡‡ç”¨ä¸‰å¹³é¢å“ˆå¸Œè¡¨ç¤ºæ¥ç»´æŠ¤ä¸»ä½“èº«ä»½ã€‚é€šè¿‡é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨å’Œå¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ï¼ŒSyncTalkæ˜¾è‘—æé«˜äº†åˆæˆè§†é¢‘çš„åŒæ­¥æ€§å’Œè§†è§‰è´¨é‡ã€‚PortraitSync Generatorè¿›ä¸€æ­¥æ”¹å–„äº†è§†è§‰è´¨é‡ï¼Œç²¾å¿ƒç»†åŒ–äº†è§†è§‰ç»†èŠ‚ã€‚æ•´ä¸ªæ¸²æŸ“è¿‡ç¨‹å¯ä»¥å®ç°50 FPSï¼Œå¹¶è¾“å‡ºé«˜åˆ†è¾¨ç‡è§†é¢‘ã€‚</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>æ¨¡å—</th>
<th>æè¿°</th>
</tr>
</thead>
<tbody>
<tr>
<td>Face-Sync Controller</td>
<td>åœ¨Face-Syncæ§åˆ¶å™¨ä¸­ï¼Œé¢„å…ˆåœ¨2DéŸ³é¢‘è§†å¬æ•°æ®é›†ä¸Šå¯¹éŸ³é¢‘è§†è§‰ç¼–ç å™¨è¿›è¡Œé¢„è®­ç»ƒï¼Œå¾—åˆ°äº†ä¸€ç§é€šç”¨è¡¨ç¤ºï¼Œç¡®ä¿äº†ä¸åŒè¯­éŸ³æ ·æœ¬ä¹‹é—´çš„å”‡éƒ¨åŒæ­¥è¿åŠ¨ã€‚å¯¹äºæ§åˆ¶é¢éƒ¨è¡¨æƒ…ï¼Œé‡‡ç”¨äº†ä¸€ä¸ªè¯­ä¹‰ä¸°å¯Œçš„3Dé¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡52ä¸ªå‚æ•°æ§åˆ¶ç‰¹å®šçš„é¢éƒ¨è¡¨æƒ…åŒºåŸŸã€‚</td>
</tr>
<tr>
<td>Head-Sync Stabilizer</td>
<td>åœ¨Head-Syncç¨³å®šå™¨ä¸­ï¼Œä½¿ç”¨AD-NeRFä¸­çš„å¤´éƒ¨è¿åŠ¨è·Ÿè¸ªå™¨æ¥æ¨æ–­å¤´éƒ¨çš„ç²—ç•¥æ—‹è½¬å’Œå¹³ç§»å‚æ•°ã€‚ç”±äºç²—ç•¥å‚æ•°çš„ä¸ç¨³å®šæ€§ï¼Œå€Ÿé‰´äº†åŒæ­¥å®šä½ä¸åœ°å›¾(SLAM)çš„æ€æƒ³ï¼Œç»“åˆå¤´éƒ¨å…³é”®ç‚¹è·Ÿè¸ªå™¨è·Ÿè¸ªç¨ å¯†å…³é”®ç‚¹ï¼Œå¹¶é‡‡ç”¨bundle adjustment method æŸè°ƒæ•´æ–¹æ³•æ¥ä¼˜åŒ–å¤´éƒ¨å§¿åŠ¿ï¼Œä»è€Œå®ç°ç¨³å®šè¿ç»­çš„å¤´éƒ¨è¿åŠ¨ã€‚</td>
</tr>
<tr>
<td>Portrait-Sync Generator</td>
<td>ä¸ºäº†è¿›ä¸€æ­¥æé«˜SyncTalkçš„è§†è§‰ä¿çœŸåº¦ï¼Œè®¾è®¡äº†ä¸€ä¸ªPortrait-Syncç”Ÿæˆå™¨ã€‚è¿™ä¸ªæ¨¡å—ä¿®å¤äº†NeRFå»ºæ¨¡ä¸­çš„ä¼ªå½±ï¼Œç‰¹åˆ«æ˜¯å¤´å‘å’ŒèƒŒæ™¯ç­‰ç»†èŠ‚ï¼Œè¾“å‡ºé«˜åˆ†è¾¨ç‡è§†é¢‘ã€‚</td>
</tr>
</tbody>
</table>
</div>
<p><strong>ä¸»è¦è´¡çŒ®</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ä¸ªFace-Syncæ§åˆ¶å™¨ï¼Œç»“åˆéŸ³é¢‘è§†è§‰ç¼–ç å™¨å’Œé¢éƒ¨åŠ¨ç”»æ•æ‰å™¨ï¼Œç¡®ä¿å‡†ç¡®çš„å”‡éƒ¨åŒæ­¥å’ŒåŠ¨æ€é¢éƒ¨è¡¨æƒ…æ¸²æŸ“ã€‚ </li>
<li>å¼•å…¥äº†ä¸€ä¸ªHead-Syncç¨³å®šå™¨ï¼Œè·Ÿè¸ªå¤´éƒ¨æ—‹è½¬å’Œé¢éƒ¨è¿åŠ¨å…³é”®ç‚¹ã€‚åˆ©ç”¨æŸè°ƒæ•´æ–¹æ³•ï¼Œè¯¥ç¨³å®šå™¨ä¿è¯äº†å¹³æ»‘åŒæ­¥çš„å¤´éƒ¨è¿åŠ¨ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªPortrait-Syncç”Ÿæˆå™¨ï¼Œé€šè¿‡ä¿®å¤NeRFå»ºæ¨¡ä¸­çš„ä¼ªå½±å’Œç»†åŒ–å¤´å‘å’ŒèƒŒæ™¯ç­‰ç»†èŠ‚ï¼Œæé«˜äº†è§†è§‰ä¿çœŸåº¦ã€‚</li>
</ul>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p><strong>GAN-based Method</strong></p>
<p>è¿‘æ¥ï¼ŒåŸºäºGANçš„è¯´è¯å¤´åˆæˆæˆä¸ºäº†è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€ä¸ªé‡è¦ç ”ç©¶é¢†åŸŸã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨ä¿æŒè§†é¢‘ä¸­ä¸»ä½“çš„èº«ä»½ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚</p>
<p>ä¾‹å¦‚ï¼ŒWav2Lipå¼•å…¥äº†ä¸€ä¸ªå”‡éƒ¨åŒæ­¥ä¸“å®¶æ¥ç›‘ç£å”‡éƒ¨è¿åŠ¨ã€‚ç„¶è€Œï¼Œç”±äºä½¿ç”¨äº†æ¥è‡ªå‚è€ƒå¸§çš„äº”å¸§æ¥é‡å»ºå”‡éƒ¨ï¼Œå®ƒéš¾ä»¥ä¿æŒä¸»ä½“çš„èº«ä»½ã€‚å¦ä¸€äº›æ–¹æ³•å°è¯•è¿›è¡Œå…¨è„¸åˆæˆï¼Œä½†å¾€å¾€éš¾ä»¥ç¡®ä¿é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ä¹‹é—´çš„åŒæ­¥ã€‚é™¤äº†è§†é¢‘æµæŠ€æœ¯å¤–ï¼Œè¿˜æœ‰ä¸€äº›æ–¹æ³•è¯•å›¾é€šè¿‡è¯­éŸ³ä½¿å•å¼ å›¾åƒâ€œè¯´è¯â€ï¼Œå¦‚SadTalkerå¯ä»¥ä»å•å¼ å›¾åƒç”Ÿæˆä¸€ä¸ªäººè¯´è¯çš„è§†é¢‘ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•æ— æ³•ç”Ÿæˆè‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿å’Œé¢éƒ¨è¡¨æƒ…ï¼Œéš¾ä»¥ä¿æŒä¸»ä½“çš„èº«ä»½ï¼Œå½±å“äº†åŒæ­¥æ•ˆæœï¼Œå¯¼è‡´è§†è§‰æ„ŸçŸ¥ä¸çœŸå®ã€‚</p>
<p>ä¸è¿™äº›æ–¹æ³•ç›¸æ¯”ï¼ŒSyncTalkä½¿ç”¨NeRF<strong>å¯¹äººè„¸è¿›è¡Œä¸‰ç»´å»ºæ¨¡</strong>ã€‚å…¶èƒ½å¤Ÿåœ¨è§„èŒƒç©ºé—´ä¸­è¡¨ç¤º<strong>è¿ç»­çš„3Dåœºæ™¯çš„èƒ½åŠ›</strong>ï¼Œä½¿å…¶åœ¨ä¿æŒä¸»ä½“èº«ä»½ä¸€è‡´æ€§å’Œä¿ç•™ç»†èŠ‚æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</p>
<p><strong>NeRF-based Method</strong></p>
<p>è¿‘æ¥ï¼Œéšç€NeRFçš„å´›èµ·ï¼Œè®¸å¤šé¢†åŸŸå·²å¼€å§‹åˆ©ç”¨å®ƒæ¥è§£å†³ç›¸å…³æŒ‘æˆ˜ã€‚å…ˆå‰çš„å·¥ä½œå·²å°†NeRFæ•´åˆåˆ°åˆæˆè¯´è¯å¤´åƒçš„ä»»åŠ¡ä¸­ï¼Œå¹¶å°†éŸ³é¢‘ä½œä¸ºé©±åŠ¨ä¿¡å·ï¼Œä½†è¿™äº›æ–¹æ³•éƒ½æ˜¯åŸºäºæ™®é€šçš„NeRFæ¨¡å‹ã€‚</p>
<p>ä¾‹å¦‚ï¼ŒAD-NeRFéœ€è¦å¤§çº¦10ç§’æ¥æ¸²æŸ“å•ä¸ªå›¾åƒã€‚RADNeRFæ—¨åœ¨å®ç°å®æ—¶è§†é¢‘ç”Ÿæˆï¼Œå¹¶ä½¿ç”¨äº†åŸºäºInstant-NGPçš„NeRFã€‚ER-NeRFé€šè¿‡å¼•å…¥ä¸‰å¹³é¢å“ˆå¸Œç¼–ç å™¨æ¥ä¿®å‰ªç©ºç™½ç©ºé—´åŒºåŸŸï¼Œæå€¡ç´§å‡‘ä¸”åŠ é€Ÿçš„æ¸²æŸ“æ–¹æ³•ã€‚GeneFaceè¯•å›¾é€šè¿‡å°†è¯­éŸ³ç‰¹å¾è½¬æ¢ä¸ºé¢éƒ¨æ ‡å¿—æ¥å‡å°‘NeRFçš„ä¼ªå½±ï¼Œä½†è¿™å¾€å¾€å¯¼è‡´å”‡éƒ¨è¿åŠ¨ä¸å‡†ç¡®ã€‚å°è¯•ä½¿ç”¨åŸºäºNeRFçš„æ–¹æ³•åˆ›å»ºè§’è‰²å¤´åƒï¼Œä¾‹å¦‚ï¼Œä¸èƒ½ç›´æ¥ç”±è¯­éŸ³é©±åŠ¨ã€‚è¿™äº›æ–¹æ³•ä»…å°†éŸ³é¢‘ä½œä¸ºæ¡ä»¶ï¼Œæ²¡æœ‰æ¸…æ™°çš„åŒæ­¥æ¦‚å¿µï¼Œå¹¶ä¸”é€šå¸¸å¯¼è‡´å”‡éƒ¨è¿åŠ¨å¹³å‡ã€‚</p>
<p>æ­¤å¤–ï¼Œå…ˆå‰çš„æ–¹æ³•<strong>ç¼ºä¹å¯¹é¢éƒ¨è¡¨æƒ…çš„æ§åˆ¶</strong>ï¼Œä»…é™äºæ§åˆ¶çœ¨çœ¼ï¼Œå¹¶ä¸”æ— æ³•å¯¹æŠ¬çœ‰æ¯›æˆ–çš±çœ‰ç­‰åŠ¨ä½œè¿›è¡Œå»ºæ¨¡ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨å¤´éƒ¨å§¿åŠ¿ä¸ç¨³å®šæ–¹é¢å­˜åœ¨æ˜¾ç€é—®é¢˜ï¼Œ<strong>å¯¼è‡´å¤´éƒ¨å’Œèº¯å¹²åˆ†ç¦»</strong>ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä½¿ç”¨Face-Syncæ§åˆ¶å™¨æ¥å»ºæ¨¡éŸ³é¢‘å’Œå”‡éƒ¨è¿åŠ¨ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œå¢å¼ºå”‡éƒ¨è¿åŠ¨å’Œè¡¨æƒ…çš„åŒæ­¥æ€§ï¼Œä½¿ç”¨Head-Syncç¨³å®šå™¨æ¥ç¨³å®šå¤´éƒ¨å§¿åŠ¿ï¼Œé€šè¿‡è§£å†³è¿™äº›åŒæ­¥é—®é¢˜ï¼Œæé«˜äº†è§†è§‰è´¨é‡ã€‚</p>
<h2 id="ä¸»è¦æ–¹æ³•"><a href="#ä¸»è¦æ–¹æ³•" class="headerlink" title="ä¸»è¦æ–¹æ³•"></a>ä¸»è¦æ–¹æ³•</h2><p>SyncTalkä¸»è¦ç”±ä¸‰éƒ¨åˆ†ç»„æˆï¼Œæ¥ä¸‹æ¥ä¼šä¸€ä¸€ä»‹ç»</p>
<ul>
<li><strong>Face-Sync Controller</strong> æ§åˆ¶å˜´å”‡è¿åŠ¨å’Œé¢éƒ¨è¡¨æƒ…</li>
<li><strong>Head-Sync Stabilizer</strong> ç¨³å®šå¤´éƒ¨å§¿åŠ¿</li>
<li><strong>Portrait-Sync Generator</strong> æ¸²æŸ“çš„é«˜åŒæ­¥é¢éƒ¨å¸§</li>
</ul>
<p><img src="https://pica.zhimg.com/v2-03605cd4fbd659c9d341840c64fd3b41.png" alt="Overview of SyncTalk"></p>
<h3 id="Face-Sync-Controller"><a href="#Face-Sync-Controller" class="headerlink" title="Face-Sync Controller"></a>Face-Sync Controller</h3><p><strong>Audio-Visual Encoder</strong></p>
<p>åœ¨ç°æœ‰çš„æ–¹æ³•ä¸­ï¼Œå¤§éƒ¨åˆ†çš„éŸ³é¢‘ç‰¹å¾æå–å™¨æ˜¯ç”¨ç±»ä¼¼äº <strong>DeepSpeechï¼ŒWav2Vec 2.0 å’Œ HuBERT</strong> ç­‰ASRæ¨¡å‹ï¼Œä½†æ˜¯è¿™äº›äº‹ä¸“é—¨ä¸ºAutomatic Speech Recognition ASRä»»åŠ¡è®¾è®¡çš„ï¼Œè¿™ç§è®¾è®¡çš„éŸ³é¢‘ç¼–ç å™¨å¹¶ä¸èƒ½çœŸæ­£åæ˜ å˜´å”‡è¿åŠ¨ã€‚è¿™æ˜¯å› ä¸ºé¢„è®­ç»ƒçš„æ¨¡å‹æ˜¯<strong>åŸºäºä»éŸ³é¢‘åˆ°æ–‡æœ¬çš„ç‰¹å¾åˆ†å¸ƒï¼Œè€Œéœ€è¦ä»éŸ³é¢‘åˆ°å˜´å”‡è¿åŠ¨çš„ç‰¹å¾åˆ†å¸ƒ</strong>ã€‚</p>
<p>é’ˆå¯¹è¿™ç§æƒ…å†µï¼Œä½¿ç”¨åœ¨LRS2ä¸Šè®­ç»ƒçš„<a href="https://github.com/smeetrs/deep_avsr">deep avsr</a>æ¥åšéŸ³é¢‘ç‰¹å¾æå–å™¨ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„å”‡å½¢åŒæ­¥é‰´åˆ«å™¨ <a href="https://github.com/joonson/syncnet_python">SyncNet</a>æ¥ç›‘ç£è§†é¢‘çš„åŒæ­¥æ•ˆæœï¼Œè¿™æ˜¯ä½¿ç”¨è¿ç»­çš„é¢éƒ¨çª—å£Få’Œç›¸å¯¹åº”çš„éŸ³é¢‘å¸§Aè¾“å…¥ï¼ŒåŒæ—¶åˆ†ä¸ºæ­£è´Ÿæ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œåˆ©ç”¨<strong>ä½™å¼¦ç›¸ä¼¼åº¦å’Œäº¤å‰ç†µæŸå¤±</strong>æ¥æœ€å°åŒ–åŒæ­¥æ ·æœ¬çš„è·ç¦»å¹¶æœ€å¤§åŒ–éåŒæ­¥æ ·æœ¬çš„è·ç¦»ã€‚</p>
<script type="math/tex; mode=display">
\begin{aligned}\sin(F,A)&=\frac{F\cdot A}{\|F\|_2\|A\|_2})\end{aligned},</script><script type="math/tex; mode=display">
L_{\mathrm{sync}}=-\left(y\log(\sin(F,A))+(1-y)\log(1-\sin(F,A))\right),</script><p><img src="https://picx.zhimg.com/v2-6b250a8119b776d55493f82cfda54bc5.png" alt="æ­£è´Ÿæ ·æœ¬"></p>
<p>åŒæ—¶åœ¨åŒæ­¥é‰´åˆ«å™¨çš„ç›‘ç£ä¸‹ï¼Œé¢„è®­ç»ƒå¯¹åº”çš„è§†å¬ç‰¹å¾æå–å™¨ï¼Œè¿™é‡Œé¢å †å å·ç§¯ç½‘ç»œè¿›è¡Œç¼–ç è§£ç ï¼Œæœ€åç”¨<strong>é‡å»ºæŸå¤±</strong>æ¥è¿›è¡Œç›‘ç£ã€‚è®­ç»ƒåï¼Œæˆ‘ä»¬ä½¿ç”¨ Conv(A) ä½œä¸ºä»éŸ³é¢‘ä¸­æå–çš„å”‡éƒ¨ç©ºé—´ã€‚</p>
<script type="math/tex; mode=display">
L_{\mathrm{recon}}=\|F-\mathrm{Dec}(\mathrm{Conv}(A)\oplus\mathrm{Conv}(F))\|_1.</script><p><strong>Facial Animation Capturer</strong></p>
<p>åœ¨ä¹‹å‰çš„ç ”ç©¶ä¸­å‘ç°ï¼ŒåŸºäºNeRFçš„æ–¹æ³•åªèƒ½æ”¹å˜çœ¨çœ¼ï¼Œæ— æ³•å‡†ç¡®åœ°å»ºæ¨¡é¢éƒ¨è¡¨æƒ…ã€‚è¿™å¯¼è‡´è®­ç»ƒå‡ºçš„è§’è‰²è¡¨æƒ…åƒµç¡¬ï¼Œé¢éƒ¨ç»†èŠ‚ä¸å‡†ç¡®ï¼Œç‰¹åˆ«æ˜¯å¯¹äºæœ‰æ˜æ˜¾é¢éƒ¨åŠ¨ä½œçš„è§’è‰²ï¼Œå¦‚çœ¨çœ¼ã€æŠ¬çœ‰æ¯›æˆ–çš±çœ‰ç­‰ã€‚<strong>è€ƒè™‘åˆ°éœ€è¦æ›´åŠ åŒæ­¥å’Œé€¼çœŸçš„é¢éƒ¨è¡¨æƒ…ï¼Œæ·»åŠ äº†ä¸€ä¸ªè¡¨æƒ…åŒæ­¥æ§åˆ¶æ¨¡å—ã€‚</strong></p>
<p>å…·ä½“è€Œè¨€ï¼Œå¼•å…¥äº†ä¸€ä¸ª<strong>åŸºäº52ä¸ªè¯­ä¹‰é¢éƒ¨æ··åˆå½¢çŠ¶ç³»æ•° B çš„3Dé¢éƒ¨å…ˆéªŒæ¨¡å‹æ¥å»ºæ¨¡é¢éƒ¨</strong>ï¼Œä¹Ÿå°±æ˜¯3D blendshape ç³»æ•°æ¥æ§åˆ¶é¢éƒ¨ï¼Œè¿™ä¸€éƒ¨åˆ†ç±»ä¼¼äº <a href="https://arxiv.org/abs/2303.11089">EmoTalk</a>ã€‚å› ä¸º3Dé¢éƒ¨æ¨¡å‹èƒ½å¤Ÿä¿ç•™é¢éƒ¨è¿åŠ¨çš„ç»“æ„ä¿¡æ¯ï¼Œæ‰€ä»¥å®ƒèƒ½å¤Ÿå¾ˆå¥½åœ°åæ˜ é¢éƒ¨åŠ¨ä½œçš„å†…å®¹ï¼ŒåŒæ—¶åˆä¸ä¼šå¼•èµ·é¢éƒ¨ç»“æ„çš„å¤±çœŸã€‚</p>
<p><strong>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆä½¿ç”¨ä¸€ä¸ªå¤æ‚çš„é¢éƒ¨æ··åˆå½¢çŠ¶æ•æ‰æ¨¡å—å°†é¢éƒ¨è¡¨æƒ…æ•æ‰ä¸ºE(B)ï¼Œç„¶åé€‰æ‹©ä¸ƒä¸ªæ ¸å¿ƒé¢éƒ¨è¡¨æƒ…æ§åˆ¶ç³»æ•°æ¥æ§åˆ¶çœ‰æ¯›ã€é¢å¤´å’Œçœ¼ç›åŒºåŸŸã€‚</strong>è¿™äº›ç³»æ•°ä¸è¡¨æƒ…é«˜åº¦ç›¸å…³ï¼Œä¸”ç‹¬ç«‹äºå˜´å”‡çš„è¿åŠ¨ã€‚å› ä¸ºé¢éƒ¨ç³»æ•°å…·æœ‰è¯­ä¹‰ä¿¡æ¯ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŒæ­¥æ¼”è®²è€…çš„é¢éƒ¨è¡¨æƒ…ã€‚</p>
<p><img src="https://pica.zhimg.com/v2-9cfb1cfb7f4ae95b64a868f8e8abad0e.png" alt="Facial Animation Capturer"></p>
<p><strong>Facial-Aware Masked-Attention</strong></p>
<p>ä¸ºäº†å‡å°‘è®­ç»ƒè¿‡ç¨‹ä¸­å˜´å”‡ç‰¹å¾å’Œè¡¨æƒ…ç‰¹å¾ä¹‹é—´çš„ç›¸äº’å¹²æ‰°ï¼Œå¼•å…¥äº†Facial-Aware Disentangle Attentionæ¨¡å—ã€‚åŸºäºåŒºåŸŸæ³¨æ„åŠ›å‘é‡ Vï¼Œè¿™ç±»ä¼¼äº<a href="https://fictionarry.github.io/ER-NeRF/">ER-NeRF</a>ï¼Œæˆ‘ä»¬åˆ†åˆ«å°†Mask $M<em>{lip}$ å’Œ $M</em>{exp}$ æ·»åŠ åˆ°å˜´å”‡å’Œè¡¨æƒ…çš„æ³¨æ„åŠ›åŒºåŸŸã€‚</p>
<script type="math/tex; mode=display">
\begin{aligned}V_{\mathrm{lip}}&=V\odot M_{\mathrm{lip}},\\V_{\mathrm{exp}}&=V\odot M_{\mathrm{exp}}.\end{aligned}</script><p>é€šè¿‡è¿™æ ·è®¾è®¡çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè§£è€¦å˜´å”‡è¿åŠ¨å’Œçœ¨çœ¼è¿åŠ¨ç­‰ï¼Œä»è€Œå‡å°‘è€¦åˆå¸¦æ¥çš„ä¼ªå½±ï¼Œæœ€ååˆ©ç”¨è§£è€¦çš„å˜´å”‡ç‰¹å¾ $f<em>l = F</em>{lip} âŠ™ V<em>{lip}$ å’Œè¡¨æƒ…ç‰¹å¾$f_e = f</em>{exp} âŠ™ V_{exp}$ã€‚</p>
<p><img src="https://pica.zhimg.com/v2-ba601309ab5cc09573f4291d7ae27f13.png" alt="ER-NeRF Mask"></p>
<h3 id="Head-Sync-Stabilizer"><a href="#Head-Sync-Stabilizer" class="headerlink" title="Head-Sync Stabilizer"></a>Head-Sync Stabilizer</h3><p><strong>Head Motion Tracker</strong></p>
<p>å¤´éƒ¨å§¿åŠ¿ï¼Œè¡¨ç¤ºä¸º pï¼Œæ˜¯æŒ‡äººçš„å¤´éƒ¨åœ¨ 3D ç©ºé—´ä¸­çš„æ—‹è½¬è§’åº¦ï¼Œç”±æ—‹è½¬ R å’Œå¹³ç§» T å®šä¹‰ã€‚</p>
<p>ä¸ç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ä¼šå¯¼è‡´å¤´éƒ¨æŠ–åŠ¨ã€‚ä¸ºäº†è·å¾—å¤´éƒ¨å§¿åŠ¿çš„ç²—ç•¥ä¼°è®¡ï¼Œé¦–å…ˆï¼Œé€šè¿‡åœ¨é¢„å®šèŒƒå›´å†…è¿­ä»£ i æ¬¡æ¥ç¡®å®šæœ€ä½³ç„¦è·ã€‚å¯¹äºæ¯ä¸ªç„¦è·å€™é€‰ fiï¼Œé‡æ–°åˆå§‹åŒ–æ—‹è½¬å’Œå¹³ç§»å€¼ã€‚ç›®æ ‡æ˜¯æœ€å°åŒ– 3D å¯å˜å½¢æ¨¡å‹ (3DMM) çš„æŠ•å½±åœ°æ ‡ä¸è§†é¢‘å¸§ä¸­çš„å®é™…åœ°æ ‡ä¹‹é—´çš„è¯¯å·®ã€‚</p>
<script type="math/tex; mode=display">
f_{\mathrm{opt}}=\arg\min_{f_i}E_i(L_{2D},L_{3D}(f_i,R_i,T_i)),</script><p>å…¶ä¸­ $E_i$è¡¨ç¤ºçš„å°±æ˜¯MSEï¼Œè¿™æ ·èƒ½å¤Ÿä»¥æ›´å¥½åœ°å°†æ¨¡å‹çš„æŠ•å½±lmkä¸å®é™…è§†é¢‘lmkå¯¹é½ï¼Œç„¶åå¾—åˆ°æœ€ä¼˜çš„æ—‹è½¬å’Œå¹³ç§»çŸ©é˜µï¼Œä¹Ÿæ˜¯ç”¨MSEæ¥æœ€å°åŒ–ï¼Œè¿™æ˜¯å¯¹æ¯ä¸€å¸§è¿›è¡Œæ“ä½œçš„ï¼Œåœ¨å¯¹åº”è§†é¢‘å¸§çš„æœ€ä¼˜å€¼ã€‚</p>
<script type="math/tex; mode=display">
(R_{\mathrm{opt}},T_{\mathrm{opt}})=\arg\min_{R,T}E(L_{2D},L_{3D}(f_{\mathrm{opt}},R,T)).</script><p><strong>Head Points Tracker</strong></p>
<p>å¯¹äºä¹‹å‰åŸºäºNeRFçš„æ–¹æ³•æ¥è¯´ï¼Œå…ˆå‰çš„æ–¹æ³•åˆ©ç”¨åŸºäº 3DMM çš„æŠ€æœ¯æ¥æå–å¤´éƒ¨å§¿åŠ¿å¹¶ç”Ÿæˆä¸å‡†ç¡®çš„ç»“æœã€‚ä¸ºäº†æé«˜Rå’ŒTçš„ç²¾åº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨åƒCo- trackerè¿™æ ·çš„å…‰æµä¼°è®¡æ¨¡å‹æ¥è·Ÿè¸ªé¢éƒ¨å…³é”®ç‚¹Kã€‚</p>
<p>æ¥ä¸‹æ¥ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„å…‰æµä¼°è®¡æ¨¡å‹ï¼Œåœ¨è·å–é¢éƒ¨è¿åŠ¨å…‰æµåï¼Œæˆ‘ä»¬ä½¿ç”¨<strong>æ‹‰æ™®æ‹‰æ–¯æ»¤æ³¢å™¨</strong>é€‰æ‹©ä½äºæœ€æ˜¾è‘—æµå˜åŒ–ä½ç½®çš„å…³é”®ç‚¹ï¼Œå¹¶åœ¨æµåºåˆ—ä¸­è·Ÿè¸ªè¿™äº›å…³é”®ç‚¹çš„è¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡è¿™ä¸ªæ¨¡å—ç¡®ä¿äº†æ‰€æœ‰å¸§ä¸Šçš„é¢éƒ¨å…³é”®ç‚¹å¯¹é½æ›´åŠ ç²¾ç¡®å’Œä¸€è‡´ï¼Œä»è€Œå¢å¼ºäº†å¤´éƒ¨å§¿åŠ¿å‚æ•°çš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Bundle Adjustment</strong></p>
<p>æ ¹æ®å…³é”®ç‚¹å’Œç²—ç•¥çš„å¤´éƒ¨å§¿åŠ¿ï¼Œå¼•å…¥äº†ä¸€ä¸ªä¸¤é˜¶æ®µä¼˜åŒ–æ¡†æ¶æ¥æé«˜å…³é”®ç‚¹å’Œå¤´éƒ¨å§¿åŠ¿ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</p>
<ul>
<li><p>ç¬¬ä¸€é˜¶æ®µï¼Œéšæœºåˆå§‹åŒ– j ä¸ªå…³é”®ç‚¹çš„ 3D åæ ‡å¹¶ä¼˜åŒ–å®ƒä»¬çš„ä½ç½®ï¼Œä»¥ä¾¿ä¸å›¾åƒå¹³é¢ä¸Šè·Ÿè¸ªçš„å…³é”®ç‚¹å¯¹é½ã€‚è¿™ä¸€éƒ¨åˆ†æœ€å°åŒ–æŸå¤±å‡½æ•° $L_{init}$ï¼Œæ•è·<strong>æŠ•å½±å…³é”®ç‚¹ P å’Œè·Ÿè¸ªå…³é”®ç‚¹ K</strong> ä¹‹é—´çš„å·®å¼‚ï¼š</p>
<script type="math/tex; mode=display">
L_{\mathrm{init}}=\sum_j\lVert P_j-K_j\rVert_2.</script></li>
<li><p>ç¬¬äºŒé˜¶æ®µï¼Œå¼€å§‹è¿›è¡Œæ›´å…¨é¢çš„ä¼˜åŒ–ï¼Œä»¥ç»†åŒ– 3D å…³é”®ç‚¹å’Œç›¸å…³çš„å¤´éƒ¨è”åˆå§¿åŠ¿å‚æ•°ï¼Œé€šè¿‡Adamä¼˜åŒ–å™¨ä¼˜åŒ–ç®—æ³•ï¼Œ<strong>è°ƒæ•´ç©ºé—´åæ ‡ã€æ—‹è½¬è§’åº¦Rå’Œå¹³ç§»T</strong>ä»¥æœ€å°åŒ–å¯¹é½è¯¯å·®$L_{sec}$ï¼Œè¡¨ç¤ºä¸ºï¼š</p>
<script type="math/tex; mode=display">
L_{\sec}=\sum_j\lVert P_j(R,T)-K_j\rVert_2.</script><p>ç»è¿‡è¿™äº›ä¼˜åŒ–åï¼Œè§‚å¯Ÿåˆ°æ‰€å¾—çš„å¤´éƒ¨å§¿åŠ¿å’Œå¹³ç§»å‚æ•°å¹³æ»‘ä¸”ç¨³å®šã€‚</p>
</li>
</ul>
<h3 id="Dynamic-Portrait-Renderer"><a href="#Dynamic-Portrait-Renderer" class="headerlink" title="Dynamic Portrait Renderer"></a>Dynamic Portrait Renderer</h3><p><strong>Tri-Plane Hash Representation</strong></p>
<p>è¿™ä¸€éƒ¨åˆ†å®é™…ä¸Šå°±æ˜¯NeRFçš„ä½“æ¸²æŸ“çš„æ–¹å¼ï¼Œéƒ½æ˜¯ä¸€äº›å®šä¹‰çš„éƒ¨åˆ†ã€‚</p>
<script type="math/tex; mode=display">
\hat{C}(\mathrm{r})=\int_{t_n}^{t_f}\sigma(\mathrm{r}(t))\cdot\mathrm{c}(\mathrm{r}(t),\mathrm{d})\cdot T(t)dt,</script><p>ç±»ä¼¼äºER-NeRFçš„æ–¹å¼ï¼Œè§£å†³å“ˆå¸Œå†²çªå’Œä¼˜åŒ–éŸ³é¢‘ç‰¹å¾å¤„ç†çš„é—®é¢˜ï¼Œç»“åˆäº†ä¸‰ä¸ªç‹¬ç‰¹å®šå‘xyzçš„ 2D å“ˆå¸Œç½‘æ ¼ï¼Œä¹Ÿå°±æ˜¯ <strong>Tri-Plane Hash</strong>ï¼Œä½œä¸ºhashçš„ç¼–ç å™¨ã€‚</p>
<script type="math/tex; mode=display">
\mathcal{H}^{\mathrm{AB}}:(a,b)\to\mathrm{f}_{ab}^{\mathrm{AB}},\\
\mathrm{f_x}=\mathcal{H}^\mathrm{XY}(x,y)\oplus\mathcal{H}^\mathrm{YZ}(y,z)\oplus\mathcal{H}^\mathrm{XZ}(x,z),</script><p>å…¶ä¸­è¾“å‡º $f^{AB}<em>{ab} âˆˆ R</em>{LD}$ï¼Œå…·æœ‰å±‚æ•° $L$ å’Œæ¯ä¸ªæ–¹å‘çš„ç‰¹å¾ç»´åº¦ $D$ï¼Œè¡¨ç¤ºä¸æŠ•å½±åæ ‡$ (a, b)$ ç›¸å¯¹åº”çš„å¹³é¢å‡ ä½•ç‰¹å¾ï¼Œ$H^{AB}$ è¡¨ç¤ºå¹³é¢ $R^{AB}$ çš„å¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç å™¨ã€‚å¾—åˆ°æ¯ä¸ªæ–¹å‘çš„å‘é‡ä»¥åï¼Œäº§ç”Ÿ $3 Ã— LD$ é€šé“å‘é‡ã€‚é‡‡ç”¨$fx$ã€è§†è§’æ–¹å‘$d$ã€å˜´å”‡ç‰¹å¾$f_l$å’Œè¡¨æƒ…ç‰¹å¾$f_e$ï¼Œä¸‰å¹³é¢å“ˆå¸Œçš„éšå¼å‡½æ•°å®šä¹‰ä¸ºï¼š</p>
<script type="math/tex; mode=display">
\mathcal{F}^{\mathcal{H}}:(\mathrm{x},\mathrm{d},f_l,f_e;\mathcal{H}^3)\to(\mathrm{c},\sigma),</script><p>ç±»ä¼¼äºER-NeRFï¼Œè®­ç»ƒé‡‡ç”¨äº†ä¸€ä¸ªä¸¤æ­¥ç²—åˆ°ç»†çš„ç­–ç•¥ã€‚é¦–å…ˆï¼Œä½¿ç”¨MSEæŸå¤±è¯„ä¼°é¢„æµ‹çš„ $\hat{C(r)}$ä¸å®é™…å›¾åƒé¢œè‰²$C(r)$ä¹‹é—´çš„å·®å¼‚ã€‚é‰´äºMSEåœ¨ç»†èŠ‚æ•æ‰æ–¹é¢çš„å±€é™æ€§ã€‚æ¥ä¸‹æ¥è¿›å…¥ä¸€ä¸ªç»†åŒ–é˜¶æ®µï¼Œå¼•å…¥LPIPSæŸå¤±ä»¥å¢å¼ºç»†èŠ‚ï¼Œç±»ä¼¼äºER-NeRFã€‚æˆ‘ä»¬ä»å›¾åƒä¸­æå–éšæœºè¡¥ä¸Patch $P$ï¼Œå¹¶å°†LPIPSï¼ˆç”±Î»åŠ æƒï¼‰ä¸MSEç»“åˆèµ·æ¥ä»¥æ”¹å–„ç»†èŠ‚è¡¨ç¤ºã€‚</p>
<script type="math/tex; mode=display">
\mathcal{L}_\mathrm{total}=\sum_\mathrm{r}\|C(\mathrm{r})-\hat{C}(\mathrm{r})\|_2+\lambda\times\mathcal{L}_\mathrm{LPIPS}(\hat{\mathcal{P}},\mathcal{P}).</script><p><strong>Portrait-Sync Generator</strong></p>
<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸ºäº†è§£å†³ NeRF åœ¨<strong>æ•æ‰å‘ä¸å’ŒåŠ¨æ€èƒŒæ™¯</strong>ç­‰ç²¾ç»†ç»†èŠ‚æ–¹é¢çš„å±€é™æ€§ï¼Œå¼•å…¥äº†ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªå…³é”®éƒ¨åˆ†çš„ PortraitSync ç”Ÿæˆå™¨ã€‚</p>
<p>é¦–å…ˆï¼ŒNeRF æ¸²æŸ“é¢éƒ¨åŒºåŸŸ ($Fr$)ï¼Œé€šè¿‡é«˜æ–¯æ¨¡ç³Šåˆ›å»º $G(Fr)$ï¼Œç„¶åä½¿ç”¨æˆ‘ä»¬åŒæ­¥çš„å¤´éƒ¨å§¿åŠ¿èƒ½å¤Ÿä¸åŸå§‹å›¾åƒ ($F_o$) åˆå¹¶ï¼Œä»¥å¢å¼ºå¤´å‘ç»†èŠ‚ä¿çœŸåº¦ã€‚</p>
<p>å…¶æ¬¡ï¼Œå½“å¤´éƒ¨å’Œèº¯å¹²ç»“åˆåœ¨ä¸€èµ·æ—¶ï¼Œå¦‚æœæºè§†é¢‘ä¸­çš„è§’è‰²è¯´è¯è€Œç”Ÿæˆçš„é¢éƒ¨ä¿æŒæ²‰é»˜ï¼Œåˆ™å¯èƒ½ä¼šå‡ºç°æš—é—´éš™åŒºåŸŸï¼Œå¦‚ä¸‹å›¾ï¼ˆbï¼‰æ‰€ç¤ºã€‚ æ‰€ä»¥ç”¨å¹³å‡é¢ˆéƒ¨é¢œè‰² ($Cn$) å¡«å……è¿™äº›åŒºåŸŸã€‚ </p>
<p>è¿™ç§æ–¹æ³•é€šè¿‡è‚–åƒåŒæ­¥ç”Ÿæˆå™¨äº§ç”Ÿæ›´çœŸå®çš„ç»†èŠ‚å¹¶æé«˜è§†è§‰è´¨é‡ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-421af4b4cfa489148de7fc8f4067427b.png" alt="æ¯”è¾ƒ"></p>
<h2 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h2><p><strong>æ•°æ®é›†</strong></p>
<p>ä¸ºäº†è¿›è¡Œå…¬å¹³æ¯”è¾ƒï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ¥è‡ªAD-NeRFï¼ŒGeneFaceå’ŒER-NeRFä¸­ç›¸åŒçš„è§†é¢‘åºåˆ—ï¼Œå…¶ä¸­åŒ…æ‹¬è‹±è¯­å’Œæ³•è¯­ã€‚è¿™äº›è§†é¢‘çš„å¹³å‡é•¿åº¦çº¦ä¸º8,843å¸§ï¼Œæ¯ä¸ªè§†é¢‘ä»¥25 FPSå½•åˆ¶ã€‚é™¤äº†æ¥è‡ªAD-NeRFçš„è§†é¢‘åˆ†è¾¨ç‡ä¸º450 Ã— 450å¤–ï¼Œæ‰€æœ‰å…¶ä»–è§†é¢‘çš„åˆ†è¾¨ç‡å‡ä¸º512 Ã— 512ï¼Œå¹¶ä»¥è§’è‰²ä¸ºä¸­å¿ƒã€‚</p>
<p><strong>æ¯”è¾ƒåŸºçº¿</strong></p>
<ul>
<li>GAN-based  æ–¹æ³•  ï¼šWav2Lipï¼ŒVideoReTalkingï¼ŒDINetï¼ŒTalkLip and IP-LAPã€‚</li>
<li>NeRF-based æ–¹æ³• ï¼š AD-NeRFï¼ŒRADNeRFï¼ŒGeneFace and ER-NeRFã€‚</li>
</ul>
<p><strong>å®éªŒç»†èŠ‚</strong></p>
<ul>
<li>åœ¨ç²—ç•¥é˜¶æ®µï¼Œè‚–åƒå¤´éƒ¨ç»è¿‡100,000æ¬¡è¿­ä»£è®­ç»ƒï¼Œåœ¨ç²¾ç»†é˜¶æ®µè®­ç»ƒ25,000æ¬¡è¿­ä»£ã€‚</li>
<li>æ¯æ¬¡è¿­ä»£ä½¿ç”¨2Då“ˆå¸Œç¼–ç å™¨ï¼ˆL=14ï¼ŒF=1ï¼‰é‡‡æ ·$256^2$æ¡å…‰çº¿ã€‚</li>
<li>é‡‡ç”¨AdamWä¼˜åŒ–å™¨[24]ï¼Œå“ˆå¸Œç¼–ç å™¨çš„å­¦ä¹ ç‡ä¸º0.01ï¼Œå…¶ä»–æ¨¡å—çš„å­¦ä¹ ç‡ä¸º0.001ã€‚</li>
<li>åœ¨NVIDIA RTX 3090 GPUä¸Šï¼Œæ€»è®­ç»ƒæ—¶é—´çº¦ä¸º2å°æ—¶ã€‚</li>
</ul>
<p><strong>å®šé‡è¯„ä»·</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>è¯„ä¼°æŒ‡æ ‡</th>
<th>æè¿°</th>
</tr>
</thead>
<tbody>
<tr>
<td>å…¨å‚è€ƒè´¨é‡è¯„ä¼°</td>
<td>ä½¿ç”¨å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€å­¦ä¹ æ„ŸçŸ¥å›¾åƒè¡¥ä¸ç›¸ä¼¼æ€§ï¼ˆLPIPSï¼‰ã€å¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æ€§ï¼ˆMS-SSIMï¼‰å’ŒFrechet Inception Distanceï¼ˆFIDï¼‰ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚</td>
</tr>
<tr>
<td>æ— å‚è€ƒè´¨é‡è¯„ä¼°</td>
<td>åœ¨é«˜PSNRå›¾åƒä¸­ï¼Œçº¹ç†ç»†èŠ‚å¯èƒ½ä¸äººç±»è§†è§‰æ„ŸçŸ¥ä¸ä¸€è‡´ã€‚ä¸ºäº†æ›´ç²¾ç¡®åœ°å®šä¹‰å’Œæ¯”è¾ƒè¾“å‡ºï¼Œä½¿ç”¨ä¸¤ç§æ— å‚è€ƒæ–¹æ³•ï¼šè‡ªç„¶å›¾åƒè´¨é‡è¯„ä¼°å™¨ï¼ˆNIQEï¼‰å’Œæ— å‚è€ƒå›¾åƒç©ºé—´è´¨é‡è¯„ä¼°å™¨ï¼ˆBRISQUEï¼‰ã€‚</td>
</tr>
<tr>
<td>åŒæ­¥è¯„ä¼°</td>
<td>å¯¹äºåŒæ­¥æ€§ï¼Œä½¿ç”¨åœ°æ ‡è·ç¦»ï¼ˆLMDï¼‰æ¥è¡¡é‡é¢éƒ¨è¿åŠ¨çš„åŒæ­¥æ€§ï¼ŒåŠ¨ä½œå•ä½è¯¯å·®ï¼ˆAUEï¼‰æ¥è¯„ä¼°é¢éƒ¨è¿åŠ¨çš„å‡†ç¡®æ€§ï¼Œå¹¶å¼•å…¥å”‡åŒæ­¥è¯¯å·®ç½®ä¿¡åº¦ï¼ˆLSE-Cï¼‰ï¼Œä¸Wav2Lipä¸€è‡´ï¼Œä»¥è¯„ä¼°å”‡éƒ¨è¿åŠ¨ä¸éŸ³é¢‘ä¹‹é—´çš„åŒæ­¥æ€§ã€‚</td>
</tr>
</tbody>
</table>
</div>
<p><strong>å®šé‡è¯„ä¼°ç»“æœ</strong></p>
<ul>
<li>å¤´éƒ¨é‡å»ºæ–¹æ³•åœ¨å›¾åƒè´¨é‡å’ŒåŒæ­¥æ€§æ–¹é¢å‡ä¼˜äºåŸºäºGANå’ŒNeRFçš„æœ€æ–°æ–¹æ³•ã€‚</li>
<li>ç»è¿‡<code>Portrait-Sync Generato</code>rå¤„ç†åï¼Œå›¾åƒè´¨é‡å¾—åˆ°äº†æ˜¾è‘—æ”¹å–„ï¼Œå¤´å‘ç»†èŠ‚å¾—åˆ°äº†æ¢å¤ã€‚</li>
<li>æ–¹æ³•åœ¨ç»´æŒä¸»ä½“èº«ä»½ã€å”‡éƒ¨ã€è¡¨æƒ…å’Œå§¿åŠ¿çš„åŒæ­¥æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
<li>ä½¿ç”¨åˆ†å¸ƒå¤–éŸ³é¢‘çš„æœ€æ–°SOTAæ–¹æ³•çš„é©±åŠ¨å™¨ç»“æœè¡¨æ˜ï¼Œæ–¹æ³•åœ¨å”‡éŸ³åŒæ­¥è¯„ä¼°æ–¹é¢é¢†å…ˆã€‚</li>
<li>æ¸²æŸ“é€Ÿåº¦è¿œè¿œè¶…è¿‡è§†é¢‘è¾“å…¥é€Ÿåº¦ï¼Œå¯ä»¥å®ç°å®æ—¶ç”Ÿæˆè§†é¢‘æµã€‚</li>
</ul>
<p><img src="https://pica.zhimg.com/v2-3093f3d799bb12490a7f79dba96bde99.png" alt="The quantitative results of the head reconstruction."></p>
<p><img src="https://picx.zhimg.com/v2-73c53cd37a7c9e87af9b918778a84d3e.png" alt="The quantitative results of the lip synchronization."></p>
<p><strong>å®šæ€§è¯„ä»·</strong></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>è¯„ä¼°ç»“æœ</th>
<th>æè¿°</th>
</tr>
</thead>
<tbody>
<tr>
<td>å›¾åƒè´¨é‡æ¯”è¾ƒ</td>
<td>åœ¨å›¾ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•ä¸å…¶ä»–æ–¹æ³•çš„æ¯”è¾ƒã€‚å¯ä»¥è§‚å¯Ÿåˆ°ï¼ŒSyncTalkå±•ç¤ºäº†æ›´ç²¾ç¡®ã€æ›´å‡†ç¡®çš„é¢éƒ¨ç»†èŠ‚ã€‚</td>
</tr>
<tr>
<td>ä¸Wav2Lipçš„æ¯”è¾ƒ</td>
<td>ä¸Wav2Lipç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒä¸»ä½“èº«ä»½çš„åŒæ—¶æä¾›äº†æ›´é«˜çš„ä¿çœŸåº¦å’Œåˆ†è¾¨ç‡ã€‚</td>
</tr>
<tr>
<td>ä¸IP-LAPçš„æ¯”è¾ƒ</td>
<td>ä¸IP-LAPç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å”‡å½¢åŒæ­¥æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸»è¦å½’åŠŸäºéŸ³é¢‘-è§†è§‰ç¼–ç å™¨å¸¦æ¥çš„éŸ³é¢‘-è§†è§‰ä¸€è‡´æ€§ã€‚</td>
</tr>
<tr>
<td>ä¸GeneFaceçš„æ¯”è¾ƒ</td>
<td>ä¸GeneFaceç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é€šè¿‡è¡¨æƒ…åŒæ­¥ç²¾ç¡®åœ°é‡ç°çœ¨çœ¼å’ŒæŠ¬çœ‰ç­‰åŠ¨ä½œã€‚</td>
</tr>
<tr>
<td>ä¸ER-NeRFçš„æ¯”è¾ƒ</td>
<td>ä¸ER-NeRFç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å§¿åŠ¿åŒæ­¥ç¨³å®šå™¨é¿å…äº†å¤´éƒ¨å’Œèº«ä½“çš„åˆ†ç¦»ï¼Œå¹¶ç”Ÿæˆäº†æ›´å‡†ç¡®çš„å”‡å½¢ã€‚</td>
</tr>
<tr>
<td></td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://picx.zhimg.com/v2-b076e645737b2297bee21027ac8e27ad.png" alt="Qualitative comparison of facial synthesis by different methods."></p>
<p><strong>User Study</strong>  </p>
<p>æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè¯¦å°½çš„ç”¨æˆ·ç ”ç©¶é—®å·ï¼Œ35åå‚ä¸è€…è¿›è¡Œè¯„åˆ†ã€‚é—®å·è®¾è®¡äº†äº”ä¸ªæ–¹é¢çš„è¯„åˆ†ï¼šå”‡åŒæ­¥å‡†ç¡®æ€§ã€è¡¨æƒ…åŒæ­¥å‡†ç¡®æ€§ã€å§¿åŠ¿åŒæ­¥å‡†ç¡®æ€§ã€å›¾åƒè´¨é‡å’Œè§†é¢‘çœŸå®æ€§ã€‚</p>
<p>å‚ä¸è€…å¹³å‡å®Œæˆé—®å·æ—¶é—´ä¸º19åˆ†é’Ÿï¼Œæ ‡å‡†åŒ–çš„Cronbach Î±ç³»æ•°ä¸º0.96ã€‚ç”¨æˆ·ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒSyncTalkåœ¨æ‰€æœ‰è¯„ä¼°ä¸­å‡è¶…è¿‡ä»¥å‰çš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨è§†é¢‘çœŸå®æ€§æ–¹é¢ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-2666052562f51f053affc9fb748eec54.png" alt="User Study"></p>
<p><strong>Ablation Study</strong></p>
<p>æ¥ä¸‹æ¥è¿›è¡Œäº†æ¶ˆèç ”ç©¶ï¼Œä»¥æ£€éªŒæˆ‘ä»¬æ¨¡å‹ä¸­ä¸åŒéƒ¨åˆ†çš„è´¡çŒ®ï¼Œé€‰æ‹©äº†ä¸‰ä¸ªæ ¸å¿ƒæŒ‡æ ‡è¿›è¡Œè¯„ä¼°ï¼šPSNRã€LPIPSå’ŒLMDã€‚</p>
<p>æˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªåä¸ºâ€œMayâ€çš„ä¸»ä½“è¿›è¡Œæµ‹è¯•ï¼Œç»“æœå¦‚è¡¨æ‰€ç¤ºã€‚</p>
<p><img src="https://pic1.zhimg.com/v2-b204e48268633b55ad93cf70dbc8f9bd.png" alt="Ablation study for our components"></p>
<p>éŸ³é¢‘-è§†è§‰ç¼–ç å™¨æä¾›äº†ä¸»è¦çš„å”‡éƒ¨åŒæ­¥ä¿¡æ¯ï¼Œå½“æ›¿æ¢æ­¤æ¨¡å—æ—¶ï¼Œæ‰€æœ‰ä¸‰ä¸ªæŒ‡æ ‡éƒ½å˜å·®ï¼Œå…¶ä¸­ç‰¹åˆ«æ˜¯LMDé”™è¯¯å¢åŠ äº†21.15%ï¼Œè¡¨æ˜å”‡éƒ¨åŠ¨ä½œåŒæ­¥å‡å°‘ï¼Œå¦‚å›¾5ï¼ˆaï¼‰æ‰€ç¤ºï¼Œæ˜¾ç¤ºå‡ºæˆ‘ä»¬çš„éŸ³é¢‘-è§†è§‰ç¼–ç å™¨å¯ä»¥æå–å‡†ç¡®çš„å”‡éƒ¨ç‰¹å¾ã€‚</p>
<p><img src="https://pica.zhimg.com/v2-2fc44a31570aeacd6badcf909f669fdc.png" alt="Ablation Study"></p>
<p>ç”¨ER-NeRF çš„<strong>çœ¨çœ¼æ¨¡å—</strong>æ›¿æ¢<strong>Facial Animation Capture</strong>æ¨¡å—ï¼Œè¿™ä¸€éƒ¨åˆ†ä¼šå½±å“çœ‰æ¯›çš„è¿åŠ¨å’Œå›¾åƒè´¨é‡ã€‚</p>
<p><strong>Facial-Aware Masked-Attention</strong>ä¸»è¦è§£è€¦äº†å”‡éƒ¨å’Œé¢éƒ¨å…¶ä»–éƒ¨ä½ä¹‹é—´çš„è¿åŠ¨ï¼Œåœ¨ç§»é™¤åç•¥å¾®å½±å“å›¾åƒè´¨é‡ã€‚</p>
<p>è‹¥æ²¡æœ‰<strong>å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨</strong>ï¼Œæ‰€æœ‰æŒ‡æ ‡éƒ½æ˜¾è‘—ä¸‹é™ï¼Œç‰¹åˆ«æ˜¯LPIPSï¼Œå¯¼è‡´å¤´éƒ¨å§¿åŠ¿æŠ–åŠ¨å’Œå¤´éƒ¨ä¸èº¯å¹²åˆ†ç¦»ï¼Œå¦‚å›¾5ï¼ˆbï¼‰æ‰€ç¤ºã€‚</p>
<p><strong>Portrait-Sync Generator</strong>æ¢å¤äº†åƒå¤´å‘è¿™æ ·çš„ç»†èŠ‚ï¼Œç§»é™¤æ­¤æ¨¡å—ä¼šå½±å“å¤´å‘ç­‰ç»†èŠ‚çš„æ¢å¤ï¼Œå¯¼è‡´æ˜æ˜¾çš„åˆ†å‰²è¾¹ç•Œã€‚</p>
<h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><ul>
<li>æœ¬æ–‡ä»‹ç»äº†SyncTalkï¼Œè¿™æ˜¯ä¸€ç§åŸºäºé«˜åº¦åŒæ­¥çš„NeRFæ–¹æ³•ï¼Œç”¨äºå®ç°é€¼çœŸçš„è¯­éŸ³é©±åŠ¨çš„è¯´è¯å¤´éƒ¨åˆæˆã€‚</li>
<li>æ¡†æ¶åŒ…æ‹¬é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨ã€å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨å’Œè‚–åƒåŒæ­¥ç”Ÿæˆå™¨ï¼Œèƒ½å¤Ÿä¿æŒä¸»ä½“èº«ä»½ï¼Œå¹¶ç”ŸæˆåŒæ­¥çš„å”‡éƒ¨åŠ¨ä½œã€é¢éƒ¨è¡¨æƒ…å’Œç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ã€‚</li>
<li>é€šè¿‡å¹¿æ³›çš„è¯„ä¼°ï¼ŒSyncTalkåœ¨åˆ›å»ºé€¼çœŸå’ŒåŒæ­¥çš„è¯´è¯å¤´éƒ¨è§†é¢‘æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æœŸæœ›SyncTalkä¸ä»…èƒ½å¢å¼ºå„ç§åº”ç”¨ç¨‹åºçš„åŠŸèƒ½ï¼Œè¿˜èƒ½åœ¨è¯´è¯å¤´éƒ¨åˆæˆé¢†åŸŸæ¿€å‘è¿›ä¸€æ­¥çš„åˆ›æ–°ã€‚</li>
</ul>
]]></content>
      <categories>
        <category>Paperscape</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>VividTalk One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior</title>
    <url>/2024/03/05/Paperscape/VividTalk/</url>
    <content><![CDATA[<h1 id="VividTalk-One-Shot-Audio-Driven-Talking-Head-Generation-Based-on-3D-Hybrid-Prior"><a href="#VividTalk-One-Shot-Audio-Driven-Talking-Head-Generation-Based-on-3D-Hybrid-Prior" class="headerlink" title="VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior"></a>VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior</h1><p>Paper   : <a href="https://arxiv.org/pdf/2312.01841.pdf">https://arxiv.org/pdf/2312.01841.pdf</a></p>
<p>Project : <a href="https://humanaigc.github.io/vivid-talk/">https://humanaigc.github.io/vivid-talk/</a></p>
<p>Video   : <a href="https://www.youtube.com/watch?v=lJVzt7JCe_4">https://www.youtube.com/watch?v=lJVzt7JCe_4</a></p>
<p>Code    : <a href="https://github.com/HumanAIGC/VividTalk">https://github.com/HumanAIGC/VividTalk</a>  (Maybe Comming Soon)</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åˆ›æ–°çš„ä¸¤é˜¶æ®µæ¡†æ¶ VividTalk å¯ç”Ÿæˆé«˜è´¨é‡è§†è§‰æ•ˆæœçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼ŒåŒ…æ‹¬å”‡å½¢åŒæ­¥ã€ä¸°å¯Œçš„é¢éƒ¨è¡¨æƒ…ã€è‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿ç­‰ã€‚</p>
<p>ï¼ˆ1ï¼‰éŸ³é¢‘é©±åŠ¨çš„è¯´è¯å¤´ç”Ÿæˆå·²ç»å¼•èµ·å¹¿æ³›å…³æ³¨ï¼Œåœ¨å”‡å½¢åŒæ­¥ã€é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿åŠ¿ç”Ÿæˆå’Œè§†é¢‘è´¨é‡æ–¹é¢å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºéŸ³é¢‘å’ŒåŠ¨ä½œä¹‹é—´çš„ä¸€å¯¹å¤šæ˜ å°„ï¼Œè¿˜æ²¡æœ‰æ¨¡å‹èƒ½å¤Ÿåœ¨æ‰€æœ‰è¿™äº›æŒ‡æ ‡ä¸Šè¾¾åˆ°æœ€ä¼˜SOTAã€‚<br>ï¼ˆ2ï¼‰ä»¥å¾€çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨æ··åˆå½¢çŠ¶Blendshapeæˆ–é¡¶ç‚¹åç§»vertexæ¥è¡¨ç¤ºé¢éƒ¨è¡¨æƒ…ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æ•æ‰ç²¾ç»†çš„è¡¨æƒ…ç»†èŠ‚æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚æ­¤å¤–ï¼Œå¤´éƒ¨å§¿åŠ¿çš„ç”Ÿæˆé€šå¸¸æ˜¯é€šè¿‡ç›´æ¥ä»éŸ³é¢‘ä¸­å­¦ä¹ æ¥å®ç°çš„ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´ä¸åˆç†å’Œä¸è¿ç»­çš„ç»“æœã€‚<br>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º VividTalk çš„ä¸¤é˜¶æ®µé€šç”¨æ¡†æ¶ï¼Œæ”¯æŒç”Ÿæˆå…·æœ‰æ‰€æœ‰ä¸Šè¿°å±æ€§çš„é«˜è§†è§‰è´¨é‡è¯´è¯å¤´è§†é¢‘ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œé€šè¿‡å­¦ä¹ éåˆšæ€§è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨è¿åŠ¨å°†éŸ³é¢‘æ˜ å°„åˆ°ç½‘æ ¼ã€‚å¯¹äºè¡¨æƒ…è¿åŠ¨ï¼Œé‡‡ç”¨æ··åˆå½¢çŠ¶å’Œé¡¶ç‚¹ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜æ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ã€‚å¯¹äºè‡ªç„¶å¤´éƒ¨è¿åŠ¨ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å¯å­¦ä¹ å¤´éƒ¨å§¿åŠ¿codebookï¼Œå¹¶é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæœºåˆ¶ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæå‡ºäº†ä¸€ç§åŒåˆ†æ”¯è¿åŠ¨-VAE å’Œç”Ÿæˆå™¨ï¼Œå°†ç½‘æ ¼è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨å¹¶é€å¸§åˆæˆé«˜è´¨é‡è§†é¢‘ã€‚<br>ï¼ˆ4ï¼‰å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ VividTalk å¯ä»¥ç”Ÿæˆå…·æœ‰å”‡å½¢åŒæ­¥å’Œé€¼çœŸå¤´éƒ¨å§¿åŠ¿çš„é«˜è§†è§‰è´¨é‡è¯´è¯å¤´è§†é¢‘ï¼Œå¹¶ä¸”åœ¨å®¢è§‚å’Œä¸»è§‚æ¯”è¾ƒä¸­ä¼˜äºä»¥å¾€çš„æœ€æ–°ä½œå“ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>VividTalk é‡‡ç”¨åŒé˜¶æ®µé€šç”¨æ¡†æ¶ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡è§†è§‰æ•ˆæœçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ã€‚</li>
<li>VividTalk åœ¨ç¬¬ä¸€é˜¶æ®µé€šè¿‡å­¦ä¹ éåˆšæ€§è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨è¿åŠ¨ï¼Œå°†éŸ³é¢‘æ˜ å°„åˆ°ç½‘æ ¼ã€‚</li>
<li>VividTalk åœ¨ç¬¬äºŒé˜¶æ®µä½¿ç”¨åŒåˆ†æ”¯è¿åŠ¨-VAE å’Œç”Ÿæˆå™¨å°†ç½‘æ ¼è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨å¹¶é€å¸§åˆæˆé«˜è´¨é‡è§†é¢‘ã€‚</li>
<li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä¸ç›®å‰æœ€å…ˆè¿›çš„ä½œå“ç›¸æ¯”ï¼ŒVividTalk å¯ä»¥ç”Ÿæˆé«˜è´¨é‡è§†è§‰æ•ˆæœçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼Œå¹¶å°†å”‡å½¢åŒæ­¥å’Œé€¼çœŸçš„å¢å¼ºæ•ˆæœæé«˜å¾ˆå¤§å¹…åº¦ã€‚</li>
</ul>
<p><img src="https://picx.zhimg.com/80/v2-8521b04f82075cc27b5e95148dba9792.png" alt="VividTalk can generate realistic and lip-sync talking head videos with expressive facial expression, natural head poses."></p>
<h2 id="ç›¸å…³å·¥ä½œ"><a href="#ç›¸å…³å·¥ä½œ" class="headerlink" title="ç›¸å…³å·¥ä½œ"></a>ç›¸å…³å·¥ä½œ</h2><p> <strong>éŸ³é¢‘é©±åŠ¨äººè„¸ç”Ÿæˆ</strong></p>
<p>ä¸»è¦æ˜¯åˆ©ç”¨éŸ³é¢‘é©±åŠ¨äººè„¸ï¼Œç”Ÿæˆç›¸åŒ¹é…çš„å›¾åƒï¼Œæœ€è¿‘çš„ä¸€äº›å·¥ä½œå¦‚SadTalkerï¼Œæ˜¯ç”¨3DMMä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå†ä½¿ç”¨3DMMæ¸²æŸ“å¾—åˆ°å¯¹åº”çš„è§†é¢‘ï¼›ä¹Ÿæœ‰åˆ©ç”¨äººè„¸é¢éƒ¨å…³é”®ç‚¹çš„ï¼Œè¿™éƒ½æ˜¯æ¯”è¾ƒç±»ä¼¼çš„ã€‚åŒæ—¶åŠ å…¥ç”Ÿæˆmaskçš„å˜´å”‡éƒ¨ä»½ï¼Œä½†æ˜¯ç”±äºä¸­é—´çš„è¡¨ç¤ºé™åˆ¶ï¼Œæ‰€æœ‰è¿™äº›æ–¹æ³•éƒ½ä¸è¶³ä»¥ç”Ÿæˆå£å‹åŒæ­¥å’Œé€¼çœŸçš„å¤´éƒ¨è¯´è¯è§†é¢‘ã€‚</p>
<p>è¿™ä¸ªVIvidTalkeræ˜¯ä½¿ç”¨blendshapeå’Œvertexæ¥ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œåˆ†åˆ«å¯¹ç²—ç²’åº¦å’Œç»†ç²’åº¦è¿›è¡Œå»ºæ¨¡ã€‚</p>
<p><strong>è§†é¢‘é©±åŠ¨äººè„¸ç”Ÿæˆ</strong></p>
<p>è§†é¢‘é©±åŠ¨å¯ä»¥è®¤ä¸ºæ˜¯è¡¨æƒ…è¿ç§»ï¼Œä¹Ÿå°±æ˜¯å°†å‚è€ƒè§†é¢‘çš„åŠ¨ä½œè¿ç§»åˆ°ç›®æ ‡äººè„¸ä¸Šï¼Œæ¯”å¦‚FOMMè¿™æ ·çš„æ–¹å¼ï¼Œç”¨æ— ç›‘ç£çš„å…³é”®ç‚¹ä½œä¸ºä¸­é—´çš„è¡¨ç¤ºï¼Œä»¥åŠæœ‰åˆ©ç”¨depthæ·±åº¦ä½œä¸ºä¿¡æ¯çš„ã€‚</p>
<h2 id="ä¸»è¦æ–¹æ³•"><a href="#ä¸»è¦æ–¹æ³•" class="headerlink" title="ä¸»è¦æ–¹æ³•"></a>ä¸»è¦æ–¹æ³•</h2><p>VividTalkä¸»è¦çš„æ¡†æ¶ç”±ä¸¤ä¸ªçº§è”é˜¶æ®µç»„æˆï¼Œåˆ†åˆ«æ˜¯</p>
<ul>
<li><strong>Audio-To-Mesh</strong> éŸ³é¢‘åˆ°ç½‘æ ¼ç”Ÿæˆ</li>
<li><strong>Mesh-To-VIdeo</strong> ç½‘æ ¼åˆ°è§†é¢‘ç”Ÿæˆ</li>
</ul>
<p><img src="https://pic1.zhimg.com/v2-35ebd6e4eb48d485c2f77af937e3a762.png" alt="ä¸»è¦æ–¹æ³•"></p>
<h3 id="å‰é¦ˆçŸ¥è¯†"><a href="#å‰é¦ˆçŸ¥è¯†" class="headerlink" title="å‰é¦ˆçŸ¥è¯†"></a>å‰é¦ˆçŸ¥è¯†</h3><h4 id="3DMM"><a href="#3DMM" class="headerlink" title="3DMM"></a>3DMM</h4><p>3D Morphable Modelï¼ˆ3DMMï¼‰æ˜¯ä¸€ç§ç”¨äºå»ºæ¨¡å’Œåˆ†æäººè„¸å½¢çŠ¶å’Œå¤–è§‚çš„è®¡ç®—æœºå›¾å½¢æŠ€æœ¯ã€‚å®ƒæ˜¯åŸºäºæ•°å­¦æ¨¡å‹çš„æ–¹æ³•ï¼Œç”¨äºæè¿°å’Œç”Ÿæˆäººè„¸çš„<strong>ä¸‰ç»´å‡ ä½•å½¢çŠ¶å’Œè¡¨é¢çº¹ç†</strong>ã€‚3DMMçš„åŸºæœ¬åŸç†æ˜¯åˆ©ç”¨ç»Ÿè®¡å­¦æ–¹æ³•ä»å¤§é‡çš„ä¸‰ç»´äººè„¸æ•°æ®ä¸­å­¦ä¹ äººè„¸å½¢çŠ¶å’Œçº¹ç†çš„å˜åŒ–è§„å¾‹ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯ç¼–ç åˆ°ä¸€ä¸ªæ•°å­¦æ¨¡å‹ä¸­ã€‚</p>
<p>è¿™ä¸ªæ¨¡å‹åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦çš„éƒ¨åˆ†ï¼šå½¢çŠ¶æ¨¡å‹å’Œçº¹ç†æ¨¡å‹ã€‚</p>
<ol>
<li><strong>å½¢çŠ¶æ¨¡å‹</strong>ï¼šå½¢çŠ¶æ¨¡å‹æè¿°äº†äººè„¸çš„å‡ ä½•å½¢çŠ¶çš„å˜åŒ–ã€‚é€šå¸¸é‡‡ç”¨çš„æ–¹æ³•æ˜¯ä½¿ç”¨ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰å¯¹äººè„¸çš„å½¢çŠ¶æ•°æ®è¿›è¡Œé™ç»´å’Œå»ºæ¨¡ã€‚é€šè¿‡åˆ†æå¤§é‡çš„äººè„¸å½¢çŠ¶æ•°æ®ï¼Œå¯ä»¥å¾—åˆ°ä¸€ç»„ä¸»æˆåˆ†ï¼Œå®ƒä»¬æè¿°äº†äººè„¸å½¢çŠ¶å˜åŒ–çš„ä¸»è¦æ¨¡å¼ã€‚å½¢çŠ¶æ¨¡å‹å¯ä»¥ç”¨æ¥ç”Ÿæˆæ–°çš„äººè„¸å½¢çŠ¶ï¼Œæˆ–è€…å¯¹ç°æœ‰çš„äººè„¸å½¢çŠ¶è¿›è¡Œç¼–è¾‘å’Œå˜å½¢ã€‚</li>
<li><strong>çº¹ç†æ¨¡å‹</strong>ï¼šçº¹ç†æ¨¡å‹æè¿°äº†äººè„¸è¡¨é¢çš„é¢œè‰²å’Œçº¹ç†çš„å˜åŒ–ã€‚ä¸å½¢çŠ¶æ¨¡å‹ç±»ä¼¼ï¼Œçº¹ç†æ¨¡å‹ä¹Ÿå¯ä»¥åˆ©ç”¨ä¸»æˆåˆ†åˆ†æç­‰æ–¹æ³•æ¥å»ºæ¨¡äººè„¸çš„è¡¨é¢çº¹ç†ã€‚é€šè¿‡åˆ†æå¤§é‡çš„äººè„¸çº¹ç†æ•°æ®ï¼Œå¯ä»¥å¾—åˆ°ä¸€ç»„ä¸»æˆåˆ†ï¼Œå®ƒä»¬æè¿°äº†äººè„¸è¡¨é¢é¢œè‰²å’Œçº¹ç†çš„å˜åŒ–æ¨¡å¼ã€‚çº¹ç†æ¨¡å‹å¯ä»¥ç”¨æ¥ç”Ÿæˆæ–°çš„äººè„¸çº¹ç†ï¼Œæˆ–è€…å¯¹ç°æœ‰çš„äººè„¸çº¹ç†è¿›è¡Œç¼–è¾‘å’Œå˜æ¢ã€‚</li>
</ol>
<p><img src="https://pic1.zhimg.com/v2-efd80426cbb18b4f2ee91789c07277eb.png" alt="3DMM"></p>
<h4 id="æ•°æ®å¤„ç†"><a href="#æ•°æ®å¤„ç†" class="headerlink" title="æ•°æ®å¤„ç†"></a>æ•°æ®å¤„ç†</h4><p>é™¤æ­¤ä¹‹å¤–ï¼Œé¦–å…ˆè¿˜éœ€è¦å¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼Œä½¿ç”¨FOMMå¯¹æ–¹å¼å¯¹è§†å¬æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶ä¸”è£å‰ªé¢éƒ¨åŒºåŸŸä¸º256x256ã€‚åŒæ—¶ä¹Ÿæ˜¯ç”¨FaceVerseæ¥æå–è¡¨æƒ…ç³»æ•°å’Œç½‘æ ¼é¡¶ç‚¹åºåˆ—ã€‚</p>
<h3 id="Audio-To-Mesh"><a href="#Audio-To-Mesh" class="headerlink" title="Audio-To-Mesh"></a>Audio-To-Mesh</h3><p>åœ¨æ•°æ®é¢„å¤„ç†çš„æ—¶å€™ï¼Œä½¿ç”¨Faceverseé‡å»ºæˆ‘ä»¬çš„å‚è€ƒå›¾åƒï¼Œä»éŸ³é¢‘ä¸­å­¦ä¹ éåˆšæ€§é¢éƒ¨è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨è¿åŠ¨æ¥é©±åŠ¨é‡å»ºçš„ç½‘æ ¼ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ä¸ªå¤šåˆ†æ”¯çš„Blendshapeå’ŒVertexåç§»ç”Ÿæˆå™¨ä»¥åŠå­¦ä¹ å¤´éƒ¨å§¿åŠ¿çš„codebookï¼Œå…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p>
<p><img src="https://picx.zhimg.com/v2-1648982e559021c0b5f5eaa6b201ef93.png" alt="Audio-To-Mesh"></p>
<p><strong>BlendShape and Vertex Offset Generator</strong></p>
<p>å¯¹äºBlendShape and Vertex Offset Generatoræ¥è¯´ï¼Œé¦–å…ˆä¼šä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„éŸ³é¢‘æ¨¡å‹æ¥æå–éŸ³é¢‘ç‰¹å¾ï¼Œç„¶åä»å‚è€ƒå›¾åƒä¸­æå–èº«ä»½ä¿¡æ¯$\alpha$ï¼Œå¹¶ä¸”ç¼–ç ä¸ºé£æ ¼ä¿¡æ¯$z_{style}$ï¼Œç„¶ååœ¨éŸ³é¢‘ç‰¹å¾ä¸­åµŒå…¥ä¸ªäººé£æ ¼ä¿¡æ¯ï¼Œå†ç»“åˆé€åˆ°åŸºäºå¤šåˆ†æ”¯çš„Transformeræ¶æ„ä¸­ï¼Œä¸€å…±æœ‰ä¸‰ä¸ªåˆ†æ”¯ï¼Œä¸¤ä¸ªåˆ†æ”¯ç”Ÿæˆç²—ç²’åº¦çš„blendshapeï¼Œç¬¬ä¸‰ä¸ªåˆ†æ”¯ç”Ÿæˆç»†ç²’åº¦çš„ä¸å˜´å”‡ç›¸å…³çš„vertexåç§»å¯¹å˜´å”‡è¿åŠ¨è¿›è¡Œè¡¥å……ã€‚</p>
<script type="math/tex; mode=display">
\hat{\beta}_i^f=\Phi_i^{bs}(\hat{\beta}_i^{1...f-1},A,z^{style}),\quad i\in\{lip,other\}, \\
\hat{O}_{lip}^f=\Phi_{lip}^{\upsilon o}(\hat{O}_{lip}^{1...f-1},A,z^{style}),</script><p>è®­ç»ƒå®Œæˆåï¼Œå°±å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ¥è¿›è¡Œé©±åŠ¨</p>
<script type="math/tex; mode=display">
\hat{M}_{nr}=(\overline{S}+\alpha U_{id}+(\hat{\beta}_{lip},\hat{\beta}_{other})U_{exp}+\hat{O}_{lip})\otimes P_{ref}.</script><p>è¿™é‡Œé¢çš„$P_{ref}$ä¸ºå‚è€ƒå›¾åƒçš„<strong>head pose</strong>ï¼Œ$\otimes$æ˜¯å¯¹åº”çš„ä»¿å°„å˜åŒ–ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-15f9efd01582593cfaf9a3a5bd765dac.png" alt="BlendShape and Vertex Offset Generator"></p>
<p><strong>Learnable Head Pose Codebook</strong></p>
<p>å¤´éƒ¨å§¿åŠ¿æ˜¯éå¸¸é‡è¦çš„ä¸€ç¯ï¼Œç›´æ¥ä»éŸ³é¢‘ä¸­å­¦ä¹ è¿˜æ˜¯æ¯”è¾ƒå›°éš¾çš„ï¼Œå› ä¸ºè¿™é‡Œé¢çš„å…³ç³»æ˜¯æ¯”è¾ƒå¾®å¼±çš„ï¼Œå› æ­¤ï¼Œä½¿ç”¨ç¦»æ•£çš„codebookçš„ï¼Œå°†ç”Ÿæˆçš„é—®é¢˜è½¬åŒ–ä¸ºåœ¨ç¦»æ•£å’Œä¸”æœ‰é™çš„å§¿åŠ¿ç©ºé—´ä¸­æŸ¥è¯¢codebookçš„ä»»åŠ¡ï¼Œè®¾è®¡äº†ä¸¤é˜¶æ®µçš„è®­ç»ƒæœºåˆ¶ã€‚</p>
<p>ç¬¬ä¸€é˜¶æ®µæ˜¯é‡å»ºé˜¶æ®µï¼Œåˆ©ç”¨VQ-VAEæ¥æ„å»ºä¸°å¯Œçš„å¤´éƒ¨å§¿åŠ¿codebookï¼Œæ˜¯ä¸€ä¸ªç¼–ç è§£ç ç»“æ„ã€‚</p>
<script type="math/tex; mode=display">
Z_q=\mathbf{q}(\hat{z})=\underset{z_k\in\mathcal{Z}}{\operatorname*{\arg\min}}\left\|\hat{z}-z_k\right\|. \\
\hat{P}_r^{1:f}=\mathcal{D}(Z_q)=\mathcal{D}(\mathbf{q}(\mathcal{E}(P_r^{1:f}))).</script><p>ç¬¬äºŒé˜¶æ®µæ˜¯æ˜ å°„é˜¶æ®µï¼Œå°†è¾“å…¥éŸ³é¢‘æ˜ å°„åˆ°codebookç”Ÿæˆæœ€ç»ˆç»“æœï¼Œå…·ä½“æ¥è¯´ï¼Œ$\Phi_{map}$ä»¥éŸ³é¢‘åºåˆ—Aã€ç‰¹å®šäºäººçš„é£æ ¼åµŒå…¥$z^{style}$å’Œåˆå§‹å¤´éƒ¨å§¿åŠ¿$P^0$ ä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºä¸­é—´ç‰¹å¾$\hat Z$ï¼Œè¯¥ä¸­é—´ç‰¹å¾å°†ä»codebook$Z$é‡åŒ–ä¸º$Z_q$ï¼Œç„¶åç”±é¢„è®­ç»ƒçš„è§£ç å™¨$D$è§£ç </p>
<script type="math/tex; mode=display">
\hat{P}_r^{1:f}=\mathcal{D}(Z_q)=\mathcal{D}(\mathbf{q}(\Phi_{map}(A,s,P^0))).</script><p>ä»ç›®å‰ä¸ºæ­¢ï¼Œéåˆšæ€§é¢éƒ¨è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨å§¿åŠ¿éƒ½å·²å­¦ä¹ ã€‚ç°åœ¨æˆ‘ä»¬å°±å¯ä»¥è¿ç”¨å­¦ä¹ åˆ°çš„åˆšæ€§å¤´éƒ¨å§¿åŠ¿åº”ç”¨äºMesh $\hat{M}<em>{nr}$æ¥è·å¾—æœ€æœ€ç»ˆçš„é©±åŠ¨ç½‘æ ¼Mesh $\hat{M}</em>{d}$ã€‚</p>
<p><img src="https://pic1.zhimg.com/v2-d9f01fd2be86dc73e859cc5df7c2f7d9.png" alt="Learnable Head Pose Codebook"></p>
<h3 id="Mesh-To-Video"><a href="#Mesh-To-Video" class="headerlink" title="Mesh-To-Video"></a>Mesh-To-Video</h3><p>è¿™ä¸€éƒ¨ä»½æ˜¯ä¸ºäº†å°†é©±åŠ¨çš„Meshè½¬æˆè§†é¢‘ï¼Œæå‡ºäº†ä¸€ä¸ªåŒåˆ†æ”¯çš„Motion-VAEå¯¹è¿™äº›2Då¯†é›†è¿åŠ¨è¿›è¡Œå»ºæ¨¡ï¼Œæœ€ååˆæˆæœ€ç»ˆçš„è§†é¢‘ã€‚</p>
<p>å¦‚æœè¦å»ºæ¨¡2Dä¸3Dä¹‹é—´çš„å…³ç³»æ¯”è¾ƒéš¾ï¼Œä¸ºäº†æ›´å¥½çš„å­¦ä¹ ï¼Œä½¿ç”¨æŠ•å½±çº¹ç†è¡¨ç¤ºæ¥å®ç°2Dçš„è½¬æ¢ã€‚</p>
<p>å¹¶ä¸”ä¸ºäº†æ›´å¥½çš„å­¦ä¹ 3D Meshçš„çº¹ç†ï¼Œé¦–å…ˆåœ¨x,y,zä¸‰ä¸ªè½´çš„è¿›è¡Œå½’ä¸€åŒ–çš„å¤„ç†ï¼Œå½’ä¸€åŒ–åˆ°0ï¼Œå¾—åˆ°çº¹ç†çš„æ–°è¡¨ç¤ºNCCï¼š</p>
<script type="math/tex; mode=display">
NCC_i=\frac{\overline{S}_i-min(\overline{S}_i)}{max(\overline{S}_i)-min(\overline{S}_i)},\quad i\in\{x,y,z\}.</script><p>ç„¶åï¼Œä½¿ç”¨äº†Z-Bufferæ–¹å¼å’ŒNCCçš„é¢œè‰²å»æ¸²æŸ“3Dé¢åº¦çš„çº¹ç†$PT<em>{in}$ï¼Œç”±äº3DMMçš„é™åˆ¶ï¼Œå¤–è¡¨çš„åŒºåŸŸæ˜¯æ— æ³•è¢«å»ºæ¨¡çš„ï¼Œæ‰€ä»¥ä½¿ç”¨Deep Learning Face Attributes in the Wild æ–¹æ³•è§£æå›¾åƒå¹¶è·å¾—å¤–éƒ¨é¢éƒ¨åŒºåŸŸçº¹ç†$PT</em>{out}$ï¼Œä¾‹å¦‚èº¯å¹²å’ŒèƒŒæ™¯ï¼Œå°†å…¶ä¸$PT_{in}$ ç»„åˆå¦‚ä¸‹ï¼š</p>
<script type="math/tex; mode=display">
PT=PT_{in}\cdot M+PT_{out}\cdot(1-M)</script><p>å…¶ä¸­$M$æ˜¯å†…éƒ¨äººè„¸çš„Maskï¼Œä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºå˜´å”‡è¿åŠ¨å¹¶æ›´å‡†ç¡®åœ°å»ºæ¨¡ï¼Œæˆ‘ä»¬è¿˜é€‰æ‹©ä¸å˜´å”‡ç›¸å…³çš„æ ‡å¿—å¹¶å°†å…¶è½¬æ¢ä¸ºé«˜æ–¯å›¾ï¼Œè¿™æ˜¯ä¸€ç§æ›´ç´§å‡‘ã€æ›´æœ‰æ•ˆçš„è¡¨ç¤ºã€‚ç„¶åï¼ŒHourglassç½‘ç»œå°†å‡å»çš„é«˜æ–¯å›¾ä½œä¸ºè¾“å…¥å¹¶è¾“å‡º 2D å˜´å”‡è¿åŠ¨ï¼Œè¯¥è¿åŠ¨å°†ä¸é¢éƒ¨è¿åŠ¨è¿æ¥å¹¶è§£ç ä¸ºå¯†é›†è¿åŠ¨å’Œé®æŒ¡å›¾ã€‚</p>
<p>æœ€åï¼Œæ ¹æ®ä¹‹å‰é¢„æµ‹çš„å¯†é›†è¿åŠ¨å›¾å¯¹å‚è€ƒå›¾åƒè¿›è¡Œå˜å½¢ï¼Œè·å¾—å˜å½¢å›¾åƒï¼Œè¯¥å˜å½¢å›¾åƒå°†ä¸é®æŒ¡å›¾ä¸€èµ·ä½œä¸ºç”Ÿæˆå™¨çš„è¾“å…¥ï¼Œé€å¸§åˆæˆæœ€ç»ˆè§†é¢‘ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-bd37230a1f7ac7c875a8b5555d5b43dd.png" alt="Mesh-To-Video"></p>
<h3 id="è®­ç»ƒç­–ç•¥"><a href="#è®­ç»ƒç­–ç•¥" class="headerlink" title="è®­ç»ƒç­–ç•¥"></a>è®­ç»ƒç­–ç•¥</h3><p>è¿™å‡ éƒ¨åˆ†å®é™…ä¸Šéƒ½æ˜¯åˆ†å¼€è®­ç»ƒçš„ï¼Œä¸è¿‡è®­ç»ƒåå¯ä»¥é€šè¿‡ç«¯åˆ°ç«¯çš„æ–¹å¼ç”Ÿæˆç»“æœã€‚</p>
<p><strong>BlendShape and Vertex Offset Generator</strong>ç”±Blendshapeå’ŒMeshé‡å»ºæŸå¤±æ¥è¿›è¡Œç›‘ç£</p>
<script type="math/tex; mode=display">
L_{bsvo}=\left\|\beta-\hat{\beta}\right\|+\left\|M-\hat{M}_{nr}\right\|.</script><p><strong>Learnable Head Pose Codebook</strong>éƒ¨åˆ†ä¸­ï¼Œç”±äºé‡åŒ–å‡½æ•°æ˜¯ä¸å¯å¾®åˆ†çš„ï¼Œæ‰€ä»¥ä½¿ç”¨straight-through gradient estimatorå°†æ¢¯åº¦ä»è§£ç å™¨å¤åˆ¶åˆ°ç¼–ç å™¨ï¼Œç„¶åå¯¹ä¸¤é˜¶æ®µè®­ç»ƒè¿›è¡Œå¦‚ä¸‹ç›‘ç£ï¼š</p>
<script type="math/tex; mode=display">
\begin{aligned}
L_{rec}= =\left\|P_r^{1:f}-\hat{P}_r^{1:f}\right\|^2+\left\|sg(\mathcal{E}(P_r^{1:f}))-z_q\right\|_2^2  \\
+\left\|sg(z_q)-\mathcal{E}(P_r^{1:f})\right\|_2^2, \\
L_{map} =\left\|P_r^{1:f}-\hat{P}_r^{1:f}\right\|^2+\left\|\hat{Z}-sg(Z_q)\right\|_2^2, 
\end{aligned}</script><p>sgè¡¨ç¤ºåœæ­¢æ¢¯åº¦æ“ä½œï¼Œä¹Ÿå°±æ˜¯ <strong>stop gradient</strong></p>
<p><strong>Mesh-To-Video</strong>é˜¶æ®µä¸­ï¼ŒåŸºäºé¢„è®­ç»ƒçš„VGG-19 ç½‘ç»œçš„æ„ŸçŸ¥æŸå¤±$L<em>{perc}$è¢«ç”¨ä½œä¸»è¦é©±åŠ¨æŸå¤±ã€‚ç‰¹å¾åŒ¹é…æŸå¤± $L</em>{fm}$è¿˜ç”¨äºç¨³å®šè®­ç»ƒäº§ç”Ÿæ›´çœŸå®çš„ç»“æœã€‚</p>
<h2 id="å®éªŒç»“æœ"><a href="#å®éªŒç»“æœ" class="headerlink" title="å®éªŒç»“æœ"></a>å®éªŒç»“æœ</h2><p>æ¥ä¸‹æ¥æ€»ç»“ä¸€ä¸‹å®éªŒçš„ç»“æœæ–¹æ³•çš„å¯¹æ¯”ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨äº†HDTFå’ŒVoxCelebæ•°æ®é›†ï¼Œä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œåœ¨ä¸¤ä¸ªé˜¶æ®µä¸­å­¦ä¹ ç‡åˆ†åˆ«ä¸º1e-4å’Œ1e-5ï¼Œæœ€åç”¨8ä¸ªV100è®­ç»ƒäº†2å¤©å¾—åˆ°æœ€ç»ˆçš„ç»“æœã€‚</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>æ–¹æ³•</th>
<th>ä¼˜ç‚¹</th>
<th>ç¼ºç‚¹</th>
</tr>
</thead>
<tbody>
<tr>
<td>SadTalker</td>
<td>æ— æ³•ç”Ÿæˆç²¾ç¡®çš„ç»†èŠ‚å”‡éƒ¨åŠ¨ä½œ</td>
<td>è§†é¢‘è´¨é‡ä¸ä½³</td>
</tr>
<tr>
<td>TalkLip</td>
<td>ç”Ÿæˆæ¨¡ç³Šç»“æœï¼Œçš®è‚¤è‰²è°ƒç¨å¾®åé»„ï¼Œå¤±å»äº†ä¸€å®šç¨‹åº¦çš„èº«ä»½ä¿¡æ¯</td>
<td>è´¨é‡è¾ƒå·®</td>
</tr>
<tr>
<td>MakeItTalk</td>
<td>åœ¨äº¤å‰èº«ä»½é…éŸ³è®¾ç½®ä¸­ä¸èƒ½ç”Ÿæˆå‡†ç¡®çš„å˜´éƒ¨å½¢çŠ¶</td>
<td>å˜´éƒ¨å½¢çŠ¶ä¸å‡†ç¡®</td>
</tr>
<tr>
<td>Wav2Lip</td>
<td>å®¹æ˜“åˆæˆæ¨¡ç³Šçš„å£éƒ¨åŒºåŸŸï¼Œå•ä¸€å‚è€ƒå›¾åƒæ—¶è¾“å‡ºè§†é¢‘å¤´éƒ¨å§¿åŠ¿å’Œçœ¼éƒ¨è¿åŠ¨é™æ­¢</td>
<td>è§†é¢‘è¾“å‡ºè´¨é‡è¾ƒä½</td>
</tr>
<tr>
<td>PC-AVS</td>
<td>éœ€è¦ä¸€ä¸ªé©±åŠ¨è§†é¢‘ä½œä¸ºè¾“å…¥ï¼Œèº«ä»½ä¿å­˜å›°éš¾</td>
<td>èº«ä»½ä¿å­˜å›°éš¾</td>
</tr>
<tr>
<td>VividTalker</td>
<td>å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯å¤´åƒè§†é¢‘ï¼Œå…·æœ‰å‡†ç¡®çš„å”‡åŒæ­¥å’Œä¸°å¯Œçš„é¢éƒ¨è¿åŠ¨</td>
<td>è§†é¢‘è´¨é‡é«˜ï¼Œå”‡åŒæ­¥å‡†ç¡®ï¼Œé¢éƒ¨è¿åŠ¨ä¸°å¯Œ</td>
</tr>
</tbody>
</table>
</div>
<p><img src="https://pic1.zhimg.com/v2-66838829a274884142dde5ee251e190c.png" alt="å®éªŒç»“æœ"></p>
<h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>VividTalkæ¡†æ¶çš„ä¼˜ç‚¹åŒ…æ‹¬ï¼š</p>
<ol>
<li><p><strong>é«˜è´¨é‡çš„ç”Ÿæˆè§†é¢‘</strong>ï¼šVividTalkèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯å¤´åƒè§†é¢‘ï¼Œå…·æœ‰æ¸…æ™°çš„é¢éƒ¨è¡¨æƒ…å’Œè‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å…·æ²‰æµ¸æ„Ÿå’ŒçœŸå®æ„Ÿçš„ä½“éªŒã€‚</p>
</li>
<li><p><strong>ä¸°å¯Œçš„è¡¨è¾¾èƒ½åŠ›</strong>ï¼šé€šè¿‡å°†æ··åˆå½¢çŠ¶å’Œé¡¶ç‚¹æ˜ å°„ä¸ºä¸­é—´è¡¨ç¤ºï¼ŒVividTalkèƒ½å¤Ÿæœ€å¤§åŒ–æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œä»è€Œå‘ˆç°å‡ºä¸°å¯Œçš„é¢éƒ¨è¡¨æƒ…ï¼ŒåŒ…æ‹¬ç»†å¾®çš„ç»†èŠ‚è¿åŠ¨ã€‚</p>
</li>
<li><p><strong>çµæ´»çš„æ¨¡å‹è®¾è®¡</strong>ï¼šé‡‡ç”¨å¤šåˆ†æ”¯ç”Ÿæˆå™¨ï¼ŒVividTalkèƒ½å¤Ÿçµæ´»åœ°å¯¹å…¨å±€å’Œå±€éƒ¨é¢éƒ¨è¿åŠ¨è¿›è¡Œå»ºæ¨¡ï¼Œä½¿å¾—ç”Ÿæˆçš„è§†é¢‘æ›´åŠ ç”ŸåŠ¨å’Œè‡ªç„¶ã€‚</p>
</li>
<li><p><strong>è‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿åˆæˆ</strong>ï¼šé€šè¿‡å¼•å…¥æ–°é¢–çš„å¯å­¦ä¹ çš„å¤´éƒ¨å§¿åŠ¿ç æœ¬å’Œä¸¤é˜¶æ®µè®­ç»ƒæœºåˆ¶ï¼ŒVividTalkèƒ½å¤Ÿåˆæˆæ›´åŠ è‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿ï¼Œä½¿å¾—ç”Ÿæˆçš„è§†é¢‘æ›´åŠ é€¼çœŸã€‚</p>
</li>
<li><p><strong>åˆ›æ–°çš„åŒåˆ†æ”¯æœºåˆ¶</strong>ï¼šåˆ©ç”¨åŒåˆ†æ”¯è¿åŠ¨-VAEå’Œç”Ÿæˆå™¨ï¼ŒVividTalkèƒ½å¤Ÿæœ‰æ•ˆåœ°è½¬åŒ–é©±åŠ¨ç½‘æ ¼ä¸ºå¯†é›†è¿åŠ¨ï¼Œå¹¶ç”¨äºåˆæˆæœ€ç»ˆè§†é¢‘ï¼Œæé«˜äº†ç”Ÿæˆè§†é¢‘çš„è´¨é‡å’ŒçœŸå®æ„Ÿã€‚</p>
</li>
<li><p><strong>è¶…è¶Šæ€§èƒ½</strong>ï¼šå®éªŒè¯æ˜ï¼ŒVividTalkä¼˜äºä»¥å¾€çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¸ºæ•°å­—äººç±»åˆ›å»ºã€è§†é¢‘ä¼šè®®ç­‰åº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Paperscape</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>å¼€æœºè‡ªå¯åŠ¨ç™»å½•/è®¤è¯è„šæœ¬è®¾ç½®ï¼ˆSZUä¸ºä¾‹ï¼‰</title>
    <url>/2024/01/22/Note/AutoLogin/</url>
    <content><![CDATA[<h2 id="å¼€æœºè‡ªå¯åŠ¨ç™»å½•-è®¤è¯å‰æ²¿"><a href="#å¼€æœºè‡ªå¯åŠ¨ç™»å½•-è®¤è¯å‰æ²¿" class="headerlink" title="å¼€æœºè‡ªå¯åŠ¨ç™»å½•/è®¤è¯å‰æ²¿"></a>å¼€æœºè‡ªå¯åŠ¨ç™»å½•/è®¤è¯å‰æ²¿</h2><p>æœ‰æ—¶å€™åœ¨å­¦æ ¡æˆ–è€…åœ¨ä¼ä¸šçš„æ—¶å€™ï¼Œä¼šå‡ºç°è¿™æ ·ä¸€ç§æƒ…å†µï¼Œå°±æ˜¯æˆ‘ä»¬éœ€è¦è®¤è¯æ‰èƒ½å¤Ÿä¸Šç½‘ï¼Œä½†æ˜¯è¿™ç§è®¤è¯å¹¶ä¸æ˜¯éå¸¸ç¨³å®šï¼Œæœ‰å¯èƒ½ä¼šå‡ºç°æ–­è¿çš„æƒ…å†µ </p>
<p>åŒ…æ‹¬æœ‰æ—¶å€™ç”µè„‘å…³æœºåè‡ªå¯åä¹Ÿä¼šæ–­æ‰ï¼Œé’ˆå¯¹è¿™ç§æƒ…å†µï¼Œæˆ‘ä»‹ç»ä¸€ç§å¼€æœºè‡ªå¯åŠ¨ç™»å½•/è®¤è¯çš„è„šæœ¬ï¼Œè¿™æ ·èƒ½ä¸æ–­çš„ä¿è¯è”ç½‘</p>
<h2 id="å¼€æœºè‡ªå¯åŠ¨ç›®å½•"><a href="#å¼€æœºè‡ªå¯åŠ¨ç›®å½•" class="headerlink" title="å¼€æœºè‡ªå¯åŠ¨ç›®å½•"></a>å¼€æœºè‡ªå¯åŠ¨ç›®å½•</h2><p>é¦–å…ˆï¼Œæˆ‘ä»¬æ—¢ç„¶å‘è¿›è¡Œå¼€æœºè‡ªå¯åŠ¨ï¼Œé‚£ä¹ˆæˆ‘å°±éœ€è¦æ‰¾åˆ°å¼€æœºè‡ªå¯åŠ¨ç›®å½•</p>
<p>åœ¨Windowsä¸­æƒ³è¦å¼€æœºè‡ªå¯åŠ¨æŸäº›åº”ç”¨ï¼Œå¯ä»¥æŠŠç¨‹åºçš„å¿«æ·æ–¹å¼æ”¾åˆ°å¼€å§‹èœå•-&gt;ç¨‹åº-&gt;å¯åŠ¨ç›®å½•ä¸‹ï¼Œä½†æ˜¯è‡ªå¯åŠ¨åˆåˆ†ä¸ºç”¨æˆ·è‡ªå¯åŠ¨å’Œç³»ç»Ÿè‡ªå¯åŠ¨ï¼Œå‰è€…é’ˆå¯¹å•ä¸ªç”¨æˆ·ï¼Œåè€…é’ˆå¯¹å…¨éƒ¨ç”¨æˆ·ç”Ÿæ•ˆã€‚</p>
<ul>
<li>ç”¨æˆ·è‡ªå¯åŠ¨ç›®å½•ï¼š<code>C:\Users\Administrator\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup</code></li>
<li>ç³»ç»Ÿè‡ªå¯åŠ¨ç›®å½•ï¼š<code>C:\ProgramData\Microsoft\Windows\Start Menu\Programs\StartUp</code></li>
</ul>
<p>è¿™é‡Œè¦æ ¹æ®ç”¨æˆ·åè¿›è¡Œè®¾ç½®å’Œä¿®æ”¹ï¼Œä½†æ˜¯å½“ç„¶æœ‰æ›´ç®€å•çš„æ–¹æ³•å¯¹å§ï¼Œå¦‚ä¸‹ï¼Œæˆ‘ä¹Ÿæ¨èè¿™æ ·çš„æ–¹å¼è‡ªåŠ¨æ‰“å¼€æˆ‘ä»¬çš„å¼€æœºè‡ªå¯åŠ¨ç›®å½•ã€‚</p>
<p><strong>å¿«æ·å‘½ä»¤ï¼šæŒ‰ä¸‹ã€win+Rã€‘æ‰“å¼€è¿è¡Œè¾“å…¥ï¼šã€shell:Common Startupã€‘</strong></p>
<h2 id="è®¾ç½®è„šæœ¬è¿è¡Œ"><a href="#è®¾ç½®è„šæœ¬è¿è¡Œ" class="headerlink" title="è®¾ç½®è„šæœ¬è¿è¡Œ"></a>è®¾ç½®è„šæœ¬è¿è¡Œ</h2><p>å½“æˆ‘ä»¬å·²ç»æ‰¾åˆ°äº†å¼€æœºè‡ªå¯åŠ¨ç›®å½•åï¼Œæˆ‘ä»¬å°±å¯ä»¥åœ¨è¿™ä¸ªæ–‡ä»¶ä¸‹ï¼Œå†™å…¥<code>bat</code>æ–‡ä»¶ï¼Œè¿™æ ·æ¯æ¬¡å¼€æœºéƒ½ä¼šè‡ªåŠ¨è¿è¡Œã€‚</p>
<p>é¦–å…ˆæˆ‘ä»¬å®šä¹‰<code>drcom.bat</code>ï¼Œæˆ‘ä»¬å¸Œæœ›ä»–èƒ½è¿è¡Œä¸€ä¸ªä»£ç æ¥è¿›è¡Œä¸€ä¸ªæ£€æµ‹è¿æ¥ç½‘ç»œæƒ…å†µï¼Œè¿™ä¸ªä»£ç æ”¾åœ¨äº† <code>Cç›˜</code> çš„æ ¹ç›®å½•ä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ ¹æ®è‡ªå·±æƒ…å†µä¿®æ”¹è·¯å¾„æ”¾ç½®</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">python C:\\network.py</span><br></pre></td></tr></tbody></table></figure>
<p>æ‰€ä»¥ä¸»è¦çš„å°±æ˜¯è¿™ä¸ªä»£ç äº†ï¼Œè¿™ä¸ªä»£ç æ˜¯ç”¨Pythonå†™çš„ï¼ŒåŸç†ååˆ†çš„ç®€å•</p>
<p>æ—¢ç„¶æˆ‘ä»¬éœ€è¦ä¸æ–­çš„è”ç½‘ï¼Œé‚£æˆ‘ä»¬å°±ä¸æ–­çš„çœ‹çœ‹èƒ½å¦pingé€šç™¾åº¦ï¼Œå¦‚æœpingé€šäº†è¯´æ˜è”ç½‘äº†ï¼Œå¦‚æœæ²¡æœ‰ï¼Œè¯´æ˜æˆ‘ä»¬éœ€è¦è¿è¡Œä¸€ä¸ªç™»å½•çš„<code>Shell</code>æ–‡ä»¶</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    exit_code = os.system(<span class="string">'ping www.baidu.com'</span>)</span><br><span class="line">    <span class="keyword">if</span> exit_code != <span class="number">0</span>:</span><br><span class="line">        os.system(<span class="string">r'C:\login_network.sh'</span>)</span><br><span class="line">        time.sleep(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        time.sleep(<span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™é‡Œé¢çš„<code>Shell</code>æ–‡ä»¶å¯ä»¥æ˜¯ä»»ä½•ç™»å½•çš„è„šæœ¬å’Œå‘½ä»¤ï¼Œå¯¹äº<code>SZU</code>æ¥è¯´ï¼Œè„šæœ¬å¦‚ä¸‹ï¼Œåªè¦æ”¹ä¸ºè‡ªå·±çš„è´¦å·å’Œå¯†ç å³å¯ï¼Œè¿™æ ·å°±å®Œæˆäº†å¼€æœºè‡ªå¯åŠ¨ã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"Login SZU NetWork"</span></span><br><span class="line">username=<span class="string">"1111111"</span>  &amp;&amp; password=<span class="string">"6666666"</span> &amp;&amp; curl -k https://drcom.szu.edu.cn/a70.htm --data <span class="string">"DDDDD=<span class="variable">$username</span>&amp;upass=<span class="variable">$password</span>&amp;0MKKey=123456"</span>;</span><br></pre></td></tr></tbody></table></figure>
<p>å½“ç„¶ï¼Œç®€å•çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç›´æ¥åœ¨ä¸Šé¢çš„ä»£ç <code>network.py</code>é‡Œé¢ä¿®æ”¹ï¼Œæ¯”å¦‚å¦‚ä¸‹</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    exit_code = os.system(<span class="string">'ping www.baidu.com'</span>)</span><br><span class="line">    <span class="keyword">if</span> exit_code != <span class="number">0</span>:</span><br><span class="line">        os.system(<span class="string">r'username="1111111"  &amp;&amp; password="6666666" &amp;&amp; curl -k https://drcom.szu.edu.cn/a70.htm --data "DDDDD=$username&amp;upass=$password&amp;0MKKey=123456";'</span>)</span><br><span class="line">        time.sleep(<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        time.sleep(<span class="number">10</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>é€šè¿‡è¿™ä¸ªè„šæœ¬å®ç°å¼€æœºè‡ªåŠ¨ç™»å½•ï¼Œè§£å†³äº†å¼€æœºåæ— æ³•è¿æ¥ç½‘ç»œçš„é—®é¢˜ã€‚æœ¬æ–‡ä»‹ç»äº†åœ¨Windowsç³»ç»Ÿä¸‹æ‰¾åˆ°å¼€æœºè‡ªå¯åŠ¨ç›®å½•ï¼Œå¹¶æ”¾ç½®æ£€æŸ¥ç½‘ç»œçŠ¶æ€å’Œç™»å½•è®¤è¯è„šæœ¬çš„æ–¹æ³•ã€‚</p>
<p>å…·ä½“æ¥è¯´ï¼Œä½¿ç”¨Pythonè„šæœ¬å¾ªç¯pingç™¾åº¦æ£€æµ‹ç½‘ç»œï¼Œå¦‚æœæ— æ³•è¿æ¥åˆ™è°ƒç”¨ç™»å½•è„šæœ¬è¿›è¡Œç™»å½•ã€‚ç™»å½•è„šæœ¬å¯ä»¥ç›´æ¥å†™æ­»è´¦å·å¯†ç ï¼Œä¹Ÿå¯ä»¥å•ç‹¬ä¿å­˜ä¸ºæ–‡ä»¶å¼•ç”¨ã€‚</p>
<p>è¿™ç§æ–¹æ³•å¾ˆç®€å•å®ç”¨ï¼Œä¸éœ€è¦ä»˜å‡ºé¢å¤–ç²¾åŠ›å°±å¯ä»¥è·å¾—è‡ªåŠ¨ç™»å½•çš„åŠŸèƒ½ã€‚å°¤å…¶æ˜¯åœ¨éœ€è¦é¢‘ç¹ç™»å½•æ ¡å›­ç½‘æˆ–å…¬å¸WiFiçš„ç¯å¢ƒä¸‹ï¼Œå¯ä»¥å¤§å¤§æå‡æ•ˆç‡ã€‚åªéœ€ä¸€æ¬¡è®¾ç½®ï¼Œä¹‹åå°±å¯ä»¥äº«å—æ¯æ¬¡å¼€æœºå³å¯ä¸Šç½‘çš„ä½“éªŒã€‚</p>
<p>æ€»ä¹‹ï¼Œé€šè¿‡è¿™ä¸ªå¼€æœºè‡ªå¯åŠ¨è„šæœ¬ï¼Œè½»æ¾å®ç°äº†æ¯æ¬¡å¼€æœºè‡ªåŠ¨ç™»å½•ç½‘ç»œçš„éœ€æ±‚ã€‚ç»™æ—¥å¸¸å·¥ä½œå’Œå­¦ä¹ ç”Ÿæ´»å¸¦æ¥äº†è®¸å¤šä¾¿åˆ©ã€‚</p>
<p>æœ€åæ„Ÿè°¢æœ¨å­æçš„ä»£ç æä¾›ï¼Œæ„Ÿè°¢æ„Ÿè°¢ï¼ï¼ï¼</p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>ç®€ä¾¿å¿«æ·è·å–Hugging Faceæ¨¡å‹ï¼ˆä½¿ç”¨é•œåƒç«™ç‚¹ï¼‰</title>
    <url>/2024/01/05/Note/HuggingFace/</url>
    <content><![CDATA[<p>é€šå¸¸ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä»£ç ç›´æ¥ä¸‹è½½æ¨¡å‹ï¼Œä½†æœ‰æ—¶ä¼šé‡åˆ°è¯¸å¤šé—®é¢˜ï¼Œä¾‹å¦‚ä¸‹è½½é€Ÿåº¦æ…¢æˆ–å…¶ä»–ä¸€äº›é—®é¢˜ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘å°†ä¸»è¦ä»‹ç»ä¸€äº›å¸¸ç”¨çš„ç®€ä¾¿æ–¹æ³•ã€‚å¦‚æœä½ æƒ³äº†è§£æ›´å¤šç”¨æ³•ï¼Œè¯·æŸ¥çœ‹è¿™ç¯‡çŸ¥ä¹æ–‡ç« ï¼š<a href="https://zhuanlan.zhihu.com/p/663712983ï¼Œ">https://zhuanlan.zhihu.com/p/663712983ï¼Œ</a> å…¶ä¸­åŒ…å«è®¸å¤šå¤šçº¿ç¨‹çš„æ–¹æ³•ã€‚</p>
<p><a href="https://zhuanlan.zhihu.com/p/663712983">padeoeï¼šå¦‚ä½•å¿«é€Ÿä¸‹è½½huggingfaceæ¨¡å‹</a></p>
<p><img src="https://picx.zhimg.com/v2-9e8901ddec21dae36a31bb438dae03a8_r.jpg?source=172ae18b" alt="img"></p>
<p>æˆ‘çš„å…³æ³¨ç‚¹ä¸»è¦æ˜¯<strong>æ–­ç‚¹ç»­ä¼ å’Œå¤šçº¿ç¨‹ä¸‹è½½</strong>çš„æ–¹å¼ï¼Œå› ä¸ºè¿™æ ·å¯ä»¥é¿å…æ¯æ¬¡éƒ½é‡æ–°ä¸‹è½½ï¼ŒåŒæ—¶åœ¨ç½‘ç»œä¸ç¨³å®šæ—¶èƒ½å¤Ÿä¿æŒç›¸å¯¹è¾ƒå¥½çš„ä¸‹è½½é€Ÿåº¦ã€‚</p>
<h3 id="æµè§ˆå™¨ä¸‹è½½"><a href="#æµè§ˆå™¨ä¸‹è½½" class="headerlink" title="æµè§ˆå™¨ä¸‹è½½"></a>æµè§ˆå™¨ä¸‹è½½</h3><p>é¦–å…ˆï¼Œæœ€ç®€å•çš„æ–¹æ³•æ˜¯é€šè¿‡æµè§ˆå™¨ä¸‹è½½ã€‚æ‰¾åˆ°ç›¸åº”çš„æ–‡ä»¶ï¼Œä¸€ä¸ªä¸€ä¸ªåœ°ä¸‹è½½å³å¯ã€‚ç„¶è€Œï¼Œè¿™æ ·ä¼šè€—è´¹æ—¶é—´å’Œç²¾åŠ›ã€‚</p>
<p><img src="https://picx.zhimg.com/80/v2-83aaadbd16b90a345f15a08954aa9e2e_720w.png?source=d16d100b" alt="æµè§ˆå™¨ä¸‹è½½"></p>
<p>æµè§ˆå™¨ä¸‹è½½</p>
<h3 id="ç›´æ¥ä½¿ç”¨URLä¸‹è½½"><a href="#ç›´æ¥ä½¿ç”¨URLä¸‹è½½" class="headerlink" title="ç›´æ¥ä½¿ç”¨URLä¸‹è½½"></a>ç›´æ¥ä½¿ç”¨URLä¸‹è½½</h3><p>ä½¿ç”¨URLç›´æ¥ä¸‹è½½æ—¶ï¼Œå°† huggingface.co ç›´æ¥æ›¿æ¢ä¸ºåŸŸå hf-mirror.comã€‚å¯ä»¥ä½¿ç”¨æµè§ˆå™¨ï¼Œæˆ–è€…å‘½ä»¤è¡Œå·¥å…·å¦‚ wget -cã€curl -Lã€aria2c ç­‰ã€‚å¯¹äºéœ€è¦ç™»å½•çš„æ¨¡å‹ï¼Œéœ€åœ¨å‘½ä»¤è¡Œä¸­æ·»åŠ  â€”header hf_<em>*</em> å‚æ•°ï¼Œå…·ä½“è·å–tokençš„æ–¹æ³•è¯·å‚è§å‰æ–‡ã€‚</p>
<p>Hugging Faceæä¾›çš„åŒ…ä¼šè·å–ç³»ç»Ÿå˜é‡ï¼Œå› æ­¤å¯ä»¥é€šè¿‡è®¾ç½®å˜é‡æ¥è§£å†³ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">HF_ENDPOINT=https://hf-mirror.com python your_script.py</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Gitå…‹éš†ä¸‹è½½"><a href="#Gitå…‹éš†ä¸‹è½½" class="headerlink" title="Gitå…‹éš†ä¸‹è½½"></a>Gitå…‹éš†ä¸‹è½½</h3><p>æ­¤å¤–ï¼Œè¿˜æœ‰ä¸€ç§é€šè¿‡ git clone repo_url ä¸‹è½½çš„æ–¹å¼ç”±å®˜æ–¹æä¾›ã€‚å°½ç®¡è¿™ç§æ–¹æ³•ç›¸å¯¹ç®€å•ï¼Œä½†å´è¢«è®¤ä¸ºæ˜¯<strong>æœ€ä¸å»ºè®®ç›´æ¥é‡‡ç”¨çš„é€”å¾„</strong>ï¼Œä¸»è¦æœ‰ä»¥ä¸‹ä¸‰ä¸ªå¼Šç«¯ï¼š</p>
<ol>
<li>ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œä¸€æ—¦ä¸­æ–­ï¼Œéœ€è¦é‡æ–°å¯åŠ¨æ•´ä¸ªä¸‹è½½è¿‡ç¨‹ã€‚</li>
<li>å ç”¨å¤§é‡ç£ç›˜ç©ºé—´,å³ä½¿æ²¡æœ‰å†å²ç‰ˆæœ¬,ä¹Ÿä¼šå­˜å‚¨ä¸€ä»½å…ƒä¿¡æ¯å’Œå½“å‰ç‰ˆæœ¬æ–‡ä»¶æ‹·è´;</li>
<li>å¯¹äºä¸€äº›å­˜åœ¨å†å²ç‰ˆæœ¬çš„æ¨¡å‹ï¼Œ<strong>ä¸‹è½½æ—¶é—´ä¼šè¶…è¿‡ä¸¤å€</strong>ã€‚</li>
</ol>
<p>ä¸€ä¸ªè¾ƒå¥½çš„æ–¹æ³•æ˜¯è®¾ç½®ç¯å¢ƒå˜é‡GIT_LFS_SKIP_SMUDGE=1å¼€å¯git clone,ä¹‹åå•ç‹¬ä½¿ç”¨å…¶ä»–æ”¯æŒæ–­ç‚¹ç»­ä¼ çš„å·¥å…·ä¸‹è½½å¤§æ–‡ä»¶ã€‚è¿™ç§æ–¹å¼å¯ä»¥å¾ˆå¥½åœ°å…¼é¡¾æ–­ç‚¹ç»­ä¼ å’Œç£ç›˜ç©ºé—´å ç”¨ã€‚</p>
<p><img src="https://picx.zhimg.com/80/v2-3e4aaa6d94bd5dd6b7cea0f745e581f8_720w.png?source=d16d100b" alt="Gitä¸‹è½½"></p>
<h3 id="Hugging-Face-CLIå‘½ä»¤è¡Œå·¥å…·"><a href="#Hugging-Face-CLIå‘½ä»¤è¡Œå·¥å…·" class="headerlink" title="Hugging Face CLIå‘½ä»¤è¡Œå·¥å…·"></a>Hugging Face CLIå‘½ä»¤è¡Œå·¥å…·</h3><p>Hugging Faceå®˜æ–¹æä¾›çš„ <a href="https://zhuanlan.zhihu.com/p/676222159///hf-mirror.com/docs/huggingface_hub/guides/download#download-from-the-cli"><strong>huggingface-cli</strong> </a> <strong>å‘½ä»¤è¡Œå·¥å…·åŠŸèƒ½å¾ˆå¼ºå¤§,æåŠ›æ¨èä½¿ç”¨ã€‚å®ƒæ”¯æŒä¸‹è½½æ¨¡å‹ã€æ•°æ®é›†,ç™»å½•æ³¨å†Œ,ä¸”é•¿æœŸæŒç»­æ›´æ–°ç»´æŠ¤ã€‚</strong></p>
<p>ä½¿ç”¨é•œåƒç½‘ç«™å¯ä»¥åŠ å¿«é€Ÿåº¦ã€‚åŸºæœ¬æ“ä½œå¦‚ä¸‹:å®‰è£…ä¾èµ–ã€è®¾ç½®ç¯å¢ƒå˜é‡ã€æ‰§è¡Œä¸‹è½½ã€å¤„ç†éœ€è¦ç™»å½•çš„æ¨¡å‹ç­‰æƒ…å†µã€‚æ­¤å¤–,å¯ä»¥å°è¯•ä½¿ç”¨hf_transferè¿›è¡ŒåŠ é€Ÿã€‚</p>
<ol>
<li>å®‰è£…ä¾èµ–</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>åŸºæœ¬å‘½ä»¤ç¤ºä¾‹ï¼š</li>
</ol>
<p>è¿™é‡Œä½¿ç”¨äº†é•œåƒç½‘ç«™<a href="https://hf-mirror.com/">https://hf-mirror.com</a>ï¼Œä¼šåŠ å¿«é€Ÿåº¦ä¸€ç‚¹ï¼Œ<strong>hf-mirror.com</strong>ï¼Œç”¨äºé•œåƒ <a href="https://huggingface.co/">huggingface.co</a> åŸŸåã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HF_ENDPOINT=https://hf-mirror.com</span><br><span class="line"><span class="comment"># ä¸‹è½½æ¨¡å‹</span></span><br><span class="line">huggingface-cli download --resume-download --local-dir-use-symlinks False bigscience/bloom-560m --local-dir bloom-560m</span><br><span class="line"><span class="comment"># ä¸‹è½½æ•°æ®é›†</span></span><br><span class="line">huggingface-cli download --resume-download --repo-type dataset lavita/medical-qa-shared-task-v1-toy</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>ä¸‹è½½éœ€è¦ç™»å½•çš„æ¨¡å‹ï¼ˆGated Modelï¼‰</li>
</ol>
<p>è¯·æ·»åŠ  â€”token hf<em><em>*</em> å‚æ•°ï¼Œå…¶ä¸­ hf</em><em>** æ˜¯ </em>access token*ï¼Œè¯·åœ¨ <a href="https://huggingface.co/settings/tokens">Hugging Faceå®˜ç½‘è¿™é‡Œ</a> è·å–ã€‚ç¤ºä¾‹ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">huggingface-cli download --token hf_*** --resume-download --local-dir-use-symlinks False meta-llama/Llama-2-7b-hf --local-dir Llama-2-7b-hf</span><br></pre></td></tr></tbody></table></figure>
<h3 id="hf-transferåŠ é€Ÿ"><a href="#hf-transferåŠ é€Ÿ" class="headerlink" title="hf_transferåŠ é€Ÿ"></a>hf_transferåŠ é€Ÿ</h3><p>hf_transfer ä¾é™„å¹¶å…¼å®¹ huggingface-cliï¼Œæ˜¯ hugging face å®˜æ–¹ä¸“é—¨ä¸ºæé«˜ä¸‹è½½é€Ÿåº¦åŸºäº Rust å¼€å‘çš„ä¸€ä¸ªæ¨¡å—ã€‚</p>
<p><strong>å¼€å¯æ–¹æ³•</strong></p>
<ol>
<li>å®‰è£…ä¾èµ–</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install -U hf-transfer</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>è®¾ç½® HF_HUB_ENABLE_HF_TRANSFER ç¯å¢ƒå˜é‡ä¸º 1ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HF_HUB_ENABLE_HF_TRANSFER=1</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>å¼€å¯åä½¿ç”¨æ–¹æ³•åŒ huggingface-cliï¼š</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">huggingface-cli download --resume-download bigscience/bloom-560m --local-dir bloom-560m</span><br></pre></td></tr></tbody></table></figure>
<p>ä»¥å‰hf_transferæ²¡æœ‰è¿›åº¦æ¡,éœ€è¦æ ¹æ®æ˜¯å¦æœ‰è¿›åº¦æ¡åˆ¤æ–­æ˜¯å¦æˆåŠŸå¼€å¯ã€‚ä½†ä»0.19ç‰ˆæœ¬å¼€å§‹å·²æ”¯æŒè¿›åº¦æ¡,å¼€å¯æ›´ä¸ºä¾¿æ·ã€‚</p>
<p>ä¸è¿‡,hf_transferçš„é²æ£’æ€§è¾ƒä½,åœ¨ç½‘ç»œä¸ç¨³å®šæ—¶å¯èƒ½ä¼šæŠ¥é”™ã€‚è¿™æ˜¯å› ä¸ºå®ƒè¿˜åœ¨å®Œå–„è¿‡ç¨‹ä¸­,å¯¹å›½å†…è¾ƒå·®çš„ç½‘ç»œçŠ¶å†µæ”¯æŒä¸å¤Ÿå¥½ã€‚å¦‚æœå‡ºç°é”™è¯¯,å¯ä»¥å°è¯•å…³é—­è¯¥æ¨¡å—ä»¥æé«˜ç¨‹åºçš„å®¹é”™æ€§ã€‚</p>
<p>æ€»ä½“æ¥è¯´,hf_transferèƒ½æœ‰æ•ˆæé€Ÿ,ä½†åœ¨ç½‘ç»œä¸ç¨³å®šæ—¶å¯èƒ½ä¼šå‡ºç°é—®é¢˜ã€‚åŸºäºè‡ªèº«ç½‘ç»œç¯å¢ƒè°ƒæ•´æ˜¯å¦ä½¿ç”¨å®ƒæ˜¯ä¸ªä¸é”™çš„é€‰æ‹©ã€‚</p>
<h3 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h3><p>æ€»ä½“æ¥è¯´ï¼Œé€‰æ‹©ä¸‹è½½æ¨¡å‹çš„æ–¹å¼å–å†³äºä¸ªäººéœ€æ±‚å’Œç½‘ç»œç¯å¢ƒã€‚æµè§ˆå™¨ä¸‹è½½ç®€å•ç›´æ¥ï¼Œä½†è€—æ—¶è€—åŠ›ï¼›Gitå…‹éš†æ–¹å¼è™½ç®€å•ï¼Œä½†ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ä¸”å ç”¨ç£ç›˜ç©ºé—´è¾ƒå¤§ï¼›Hugging Face CLIå‘½ä»¤è¡Œå·¥å…·åŠŸèƒ½å¼ºå¤§ï¼Œæ¨èä½¿ç”¨ï¼Œå°¤å…¶æ­é… hf_transfer è¿›è¡ŒåŠ é€Ÿï¼Œä½†åœ¨ç½‘ç»œä¸ç¨³å®šæ—¶å¯èƒ½ä¼šé‡åˆ°é—®é¢˜ã€‚æ ¹æ®å®é™…æƒ…å†µï¼Œé€‰æ‹©åˆé€‚çš„æ–¹å¼å¯ä»¥æ›´é«˜æ•ˆåœ°è·å–æ‰€éœ€æ¨¡å‹ã€‚</p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>Blendshapeå­¦ä¹ ç¬”è®°</title>
    <url>/2024/03/11/Note/BlendShape/</url>
    <content><![CDATA[<h2 id="Blendshape-Morph-TargetåŠ¨ç”»"><a href="#Blendshape-Morph-TargetåŠ¨ç”»" class="headerlink" title="Blendshape(Morph TargetåŠ¨ç”»)"></a>Blendshape(Morph TargetåŠ¨ç”»)</h2><p>Blendshapesæ³›æŒ‡3Då®šç‚¹åŠ¨ç”»çš„åˆ¶ä½œæ–¹å¼ (Mayaé‡Œé¢ç§°ä¹‹ä¸º blend shapes ï¼Œè€Œ3DS Maxé‡Œç§°ä¹‹ä¸ºmorph targets) ï¼Œåœ¨3DåŠ¨ç”»ä¸­ç”¨çš„æ¯”è¾ƒå¤šï¼Œå°¤å…¶æ˜¯äººè„¸åŠ¨ç”»çš„åˆ¶ä½œï¼Œé€šè¿‡blendshapeæ¥é©±åŠ¨è§’è‰²çš„é¢éƒ¨è¡¨æƒ…ã€‚</p>
<p>ç”¨åœ¨è„¸éƒ¨åŠ¨ç”»åˆ¶ä½œæ—¶ï¼Œblendshapeå¯ä»¥è¢«ç§°ä¹‹ä¸º<strong>è„¸éƒ¨ç‰¹å¾ï¼Œè¡¨æƒ…åŸºå‡†ï¼Œå®šä½ç¬¦</strong>ç­‰ç­‰ã€‚è¿™é‡Œè¦å¼•å…¥ä¸€ä¸ª<code>FACS</code>çš„æ¦‚å¿µï¼Œå¯ä»¥ç®€å•ç†è§£ä¸ºå°†è„¸éƒ¨è¿›è¡Œåˆç†åŒ–çš„åˆ†åŒºæ ‡å‡†ã€‚</p>
<blockquote>
<p>â€œè¡¨æƒ…è¿™ä¸ªä¸œè¥¿çœ‹èµ·æ¥æ˜¯ä¸€ä¸ªæ— é™å¤šå¯èƒ½çš„ä¸œè¥¿ï¼Œæ€ä¹ˆèƒ½å¤Ÿè®¡ç®—expressionå‘¢ï¼Ÿ</p>
<p>è¿™å°±å¸¦æ¥äº†Blendshapesâ€”â€”ä¸€ç»„ç»„æˆæ•´ä½“è¡¨æƒ…çš„åŸºå‡†ï¼ˆæ•°é‡å¯ä»¥æœ‰åå‡ ä¸ªã€50ä¸ªã€100+ã€ 200+ï¼Œè¶Šå¤šå°±è¶Šç»†è…»)ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸€ç»„åŸºå‡†é€šè¿‡çº¿æ€§ç»„åˆæ¥è®¡ç®—å‡ºæ•´ä½“çš„expressionï¼Œç”¨å…¬å¼æ¥è¯´å°±æ˜¯  ï¼Œå…¶ä¸­eæ˜¯expressionï¼ŒBæ˜¯ä¸€ç»„è¡¨æƒ…åŸºå‡†ï¼Œdæ˜¯å¯¹åº”çš„ç³»æ•°ï¼ˆåœ¨è¿™ä¸€ç»„é‡Œé¢çš„æƒé‡ï¼‰ï¼Œbæ˜¯neutralã€‚â€ </p>
<p>â€” From <a href="https://zhuanlan.zhihu.com/p/78174706">https://zhuanlan.zhihu.com/p/78174706</a></p>
</blockquote>
<h2 id="BlendShapeç³»æ•°ä»‹ç»"><a href="#BlendShapeç³»æ•°ä»‹ç»" class="headerlink" title="BlendShapeç³»æ•°ä»‹ç»"></a>BlendShapeç³»æ•°ä»‹ç»</h2><p>åœ¨ARKitä¸­ï¼Œå¯¹è¡¨æƒ…ç‰¹å¾ä½ç½®å®šä¹‰äº†52ç»„è¿åŠ¨blendshapeç³»æ•°(<br><a href="https://developer.apple.com/documentation/arkit/arfaceanchor/blendshapelocation">https://developer.apple.com/documentation/arkit/arfaceanchor/blendshapelocation</a> )ï¼Œæ¯ä¸ªblendshapeç³»æ•°ä»£è¡¨ä¸€ç§è¡¨æƒ…å®šä½ç¬¦ï¼Œè¡¨æƒ…å®šä½ç¬¦å®šä¹‰äº†ç‰¹å®šè¡¨æƒ…å±æ€§ï¼Œå¦‚mouthSmileLeftã€mouthSmileRightç­‰ï¼Œä¸å…¶å¯¹åº”çš„blendshapeç³»æ•°åˆ™è¡¨ç¤ºè¡¨æƒ…è¿åŠ¨èŒƒå›´ã€‚è¿™52ç»„blendshapeç³»æ•°æå…¶æè¿°å¦‚ä¸‹è¡¨æ‰€ç¤ºã€‚</p>
<p><img src="https://p3-sign.toutiaoimg.com/pgc-image/984d8d76878441c3a8402f788ef6e46f~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1710668214&amp;x-signature=qI8vU39X63te%2BVNdO78uBFphwK0%3D" alt="Blendshape"></p>
<p>æ¯ä¸€ä¸ªblendshapeç³»æ•°çš„å–å€¼èŒƒå›´ä¸º0ï½1çš„æµ®ç‚¹æ•°ã€‚ä»¥jawOpenä¸ºä¾‹ï¼Œå½“è®¤ä¸ºç”¨æˆ·çš„å˜´å·´å®Œå…¨é—­ç´§æ—¶ï¼Œè¿”å›çš„jawOpenç³»æ•°ä¸º0ã€‚å½“è®¤ä¸ºç”¨æˆ·çš„å˜´å·´å¼ å¼€è‡³æœ€å¤§æ—¶ï¼Œè¿”å›çš„jawOpenç³»æ•°ä¸º1ã€‚</p>
<p><img src="https://p6-sign.toutiaoimg.com/pgc-image/2c8cbd123e00470e95500a8ae62da605~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1710668214&amp;x-signature=UHPhjWP4v96kbtfJzF97Z%2Bp3klc%3D" alt=""></p>
<p>åœ¨ç”¨æˆ·å®Œå…¨é—­å˜´ä¸å˜´å¼ åˆ°æœ€å¤§ä¹‹é—´çš„è¿‡æ¸¡çŠ¶æ€ï¼ŒjawOpenä¼šæ ¹æ®ç”¨æˆ·å˜´å¼ å¤§çš„å¹…åº¦è¿”å›ä¸€ä¸ª0ï½1çš„æ’å€¼ã€‚</p>
<p><img src="https://p3-sign.toutiaoimg.com/pgc-image/8e8d980b8d69461fb5d2efbc50e47d47~noop.image?_iz=58558&amp;from=article.pc_detail&amp;lk3s=953192f4&amp;x-expires=1710668214&amp;x-signature=sFNMeBoNY3ZFfiO%2BRSjR8uGECIw%3D" alt=""></p>
<h2 id="è„¸éƒ¨åŠ¨æ•çš„ä½¿ç”¨"><a href="#è„¸éƒ¨åŠ¨æ•çš„ä½¿ç”¨" class="headerlink" title="è„¸éƒ¨åŠ¨æ•çš„ä½¿ç”¨"></a>è„¸éƒ¨åŠ¨æ•çš„ä½¿ç”¨</h2><h3 id="ARKit-è„¸éƒ¨ä¸Viveè„¸éƒ¨blendshapeåŸºå‡†å¯¹æ¯”"><a href="#ARKit-è„¸éƒ¨ä¸Viveè„¸éƒ¨blendshapeåŸºå‡†å¯¹æ¯”" class="headerlink" title="ARKit è„¸éƒ¨ä¸Viveè„¸éƒ¨blendshapeåŸºå‡†å¯¹æ¯”"></a>ARKit è„¸éƒ¨ä¸Viveè„¸éƒ¨blendshapeåŸºå‡†å¯¹æ¯”</h3><div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>ARKitï¼ˆ52ï¼‰</th>
<th>Extra</th>
<th>VIVEï¼ˆ52ï¼‰</th>
<th>Extra</th>
</tr>
</thead>
<tbody>
<tr>
<td>Brow</td>
<td>5</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Eye</td>
<td>13</td>
<td></td>
<td>14</td>
<td>Eye Frown + 1</td>
</tr>
<tr>
<td>Cheek</td>
<td>3</td>
<td></td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>Nose</td>
<td>2</td>
<td></td>
<td>0</td>
<td></td>
</tr>
<tr>
<td>Jaw</td>
<td>4</td>
<td></td>
<td>4</td>
<td></td>
</tr>
<tr>
<td>Mouth</td>
<td>24</td>
<td></td>
<td>20</td>
<td>O shape - 1</td>
</tr>
<tr>
<td>Tongue</td>
<td>1</td>
<td>Tongue + 7</td>
<td>11</td>
<td></td>
</tr>
<tr>
<td>Sum</td>
<td>52</td>
<td>59</td>
<td>52</td>
<td>52</td>
</tr>
</tbody>
</table>
</div>
<h3 id="ARKitçš„52ä¸ªBlendshapeè¡¨æƒ…åŸºå‡†ç»„"><a href="#ARKitçš„52ä¸ªBlendshapeè¡¨æƒ…åŸºå‡†ç»„" class="headerlink" title="ARKitçš„52ä¸ªBlendshapeè¡¨æƒ…åŸºå‡†ç»„"></a>ARKitçš„52ä¸ªBlendshapeè¡¨æƒ…åŸºå‡†ç»„</h3><p>å¯ä»¥çœ‹ARKit Face Blendshapesçš„ç…§ç‰‡å’Œ3Dæ¨¡å‹ç¤ºä¾‹ï¼š<a href="https://arkit-face-blendshapes.com/">https://arkit-face-blendshapes.com/</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>CC3</th>
<th>ARKit Name è¡¨æƒ…åŸºå‡†/å®šä½ç¬¦</th>
<th>ARKit Picture</th>
<th>CC3 Picture</th>
</tr>
</thead>
<tbody>
<tr>
<td>A01</td>
<td>browInnerUp</td>
<td><img src="https://static.wixstatic.com/media/64c63b_4cc12dd62ef8484986eebe9739f4eac9~mv2.png/v1/fill/w_252,h_178,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4cc12dd62ef8484986eebe9739f4eac9~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_fc0c248f4f6f46dda26eda66865678d2~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_fc0c248f4f6f46dda26eda66865678d2~mv2.png" alt=""></td>
</tr>
<tr>
<td>A02</td>
<td>browDownLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_18a57dc078214abea520f25ad6dfb02a~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_18a57dc078214abea520f25ad6dfb02a~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_9d780933931b469991ae0d4ddf105045~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9d780933931b469991ae0d4ddf105045~mv2.png" alt=""></td>
</tr>
<tr>
<td>A03</td>
<td>browDownRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_105d6dd9d7c44394b96b242e6d9d580b~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_105d6dd9d7c44394b96b242e6d9d580b~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_d9943f7163414286809edef7c3bf2de7~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d9943f7163414286809edef7c3bf2de7~mv2.png" alt=""></td>
</tr>
<tr>
<td>A04</td>
<td>browOuterUpLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_e7fe8581da2540a3bd7dfc39c874dd61~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e7fe8581da2540a3bd7dfc39c874dd61~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_c7234589721d4ddda4e2fcb1a9e0aa97~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c7234589721d4ddda4e2fcb1a9e0aa97~mv2.png" alt=""></td>
</tr>
<tr>
<td>A05</td>
<td>browOuterUpRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_1fb29f740ff74e8aabadc3769c86501a~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_1fb29f740ff74e8aabadc3769c86501a~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_4aefd80dd4c548669d5ba80e4da639eb~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4aefd80dd4c548669d5ba80e4da639eb~mv2.png" alt=""></td>
</tr>
<tr>
<td>A06</td>
<td>eyeLookUpLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_697a02a504c84d5f9e316172849bb6d0~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_697a02a504c84d5f9e316172849bb6d0~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_48e3b55ee9ca40f9aec9be8b35c403b0~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_48e3b55ee9ca40f9aec9be8b35c403b0~mv2.png" alt=""></td>
</tr>
<tr>
<td>A07</td>
<td>eyeLookUpRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_84cacf1f990a4e5c874c084a1ea626b3~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_84cacf1f990a4e5c874c084a1ea626b3~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_c879b6cca2ce4f8aa2385864c1fb9389~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c879b6cca2ce4f8aa2385864c1fb9389~mv2.png" alt=""></td>
</tr>
<tr>
<td>A08</td>
<td>eyeLookDownLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_d229ef398f3547be93a1a59563520e81~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d229ef398f3547be93a1a59563520e81~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_d6c6c94e3cee43db8ae9d6f36fc1a689~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d6c6c94e3cee43db8ae9d6f36fc1a689~mv2.png" alt=""></td>
</tr>
<tr>
<td>A09</td>
<td>eyeLookDownRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_67a1674b6d584344b7ea77843f72be27~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_67a1674b6d584344b7ea77843f72be27~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_ca0dbf25d9f74085809cdcd0742ede35~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ca0dbf25d9f74085809cdcd0742ede35~mv2.png" alt=""></td>
</tr>
<tr>
<td>A10</td>
<td>eyeLookOutLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_b4257aa18f754427a593064e71aa97fd~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b4257aa18f754427a593064e71aa97fd~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_d24fd04ef2d64db18c31b90eccd5f1a9~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d24fd04ef2d64db18c31b90eccd5f1a9~mv2.png" alt=""></td>
</tr>
<tr>
<td>A11</td>
<td>eyeLookInLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_03368853adeb4b8599da5451033cd809~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_03368853adeb4b8599da5451033cd809~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_049433ce862e44c4a5f96bcf0ad13bd0~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_049433ce862e44c4a5f96bcf0ad13bd0~mv2.png" alt=""></td>
</tr>
<tr>
<td>A12</td>
<td>eyeLookInRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_6e67745f7867402398390ce18a9f2882~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6e67745f7867402398390ce18a9f2882~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_803074453832444d8dec710711196559~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_803074453832444d8dec710711196559~mv2.png" alt=""></td>
</tr>
<tr>
<td>A13</td>
<td>eyeLookOutRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_b54a5b6f123244d98eadbded8c29a8c3~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b54a5b6f123244d98eadbded8c29a8c3~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_2e7b0fed966d453fa0a8dffaabeaf769~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2e7b0fed966d453fa0a8dffaabeaf769~mv2.png" alt=""></td>
</tr>
<tr>
<td>A14</td>
<td>eyeBlinkLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_0b68b26a666a49da843b6a47c4579b46~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0b68b26a666a49da843b6a47c4579b46~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_b46d50b28b5d40feba9a496b1ead4a5c~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b46d50b28b5d40feba9a496b1ead4a5c~mv2.png" alt=""></td>
</tr>
<tr>
<td>A15</td>
<td>eyeBlinkRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_65e50badaa854262a87329394a87484c~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_65e50badaa854262a87329394a87484c~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_9113137c91934bdbab3fb26756e84783~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9113137c91934bdbab3fb26756e84783~mv2.png" alt=""></td>
</tr>
<tr>
<td>A16</td>
<td>eyeSquintLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_7b9132e314d6404097f212401559e9c4~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_7b9132e314d6404097f212401559e9c4~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_0cccb71728de47e5a7f63fe9bc70bcaf~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0cccb71728de47e5a7f63fe9bc70bcaf~mv2.png" alt=""></td>
</tr>
<tr>
<td>A17</td>
<td>eyeSquintRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_8cc99b12de914fe882c19229ce2a91da~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8cc99b12de914fe882c19229ce2a91da~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_8445ac0161fe400ab28591fb6b0b1f56~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8445ac0161fe400ab28591fb6b0b1f56~mv2.png" alt=""></td>
</tr>
<tr>
<td>A18</td>
<td>eyeWideLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_0c87ac4e4c5d4d5f9639523c82aa9d43~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0c87ac4e4c5d4d5f9639523c82aa9d43~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_c097966492c3496cabf1d84455d7144d~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c097966492c3496cabf1d84455d7144d~mv2.png" alt=""></td>
</tr>
<tr>
<td>A19</td>
<td>eyeWideRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_3157fc370d064da9926027034e8220d6~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_3157fc370d064da9926027034e8220d6~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_24dc2c84e19b436a97fd2db6044f439c~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_24dc2c84e19b436a97fd2db6044f439c~mv2.png" alt=""></td>
</tr>
<tr>
<td>A20</td>
<td>cheekPuff</td>
<td><img src="https://static.wixstatic.com/media/64c63b_de4df8062c5f47ca9cd322b75b535705~mv2.png/v1/fill/w_252,h_172,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_de4df8062c5f47ca9cd322b75b535705~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_27548c426f1b47ae834c757417e03269~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_27548c426f1b47ae834c757417e03269~mv2.png" alt=""></td>
</tr>
<tr>
<td>A21</td>
<td>cheekSquintLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_70520c1a1c374ff3855cb8dfa7450b8b~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_70520c1a1c374ff3855cb8dfa7450b8b~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_d769bd2ef0104030818ed7a156ee2a2e~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d769bd2ef0104030818ed7a156ee2a2e~mv2.png" alt=""></td>
</tr>
<tr>
<td>A22</td>
<td>cheekSquintRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_2f82d4db05764690b33001da1d138f20~mv2.png/v1/fill/w_252,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2f82d4db05764690b33001da1d138f20~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_49752693e89a4293982b5e023a0e1c75~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_49752693e89a4293982b5e023a0e1c75~mv2.png" alt=""></td>
</tr>
<tr>
<td>A23</td>
<td>noseSneerLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_843177402d2545d1a1f0a97e848df91c~mv2.png/v1/fill/w_252,h_178,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_843177402d2545d1a1f0a97e848df91c~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_9855bb8e50f54f638d4bc321dd3caa45~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9855bb8e50f54f638d4bc321dd3caa45~mv2.png" alt=""></td>
</tr>
<tr>
<td>A24</td>
<td>noseSneerRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_8ee42dc6d8e443a0858e0c65ce56cc74~mv2.png/v1/fill/w_252,h_179,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8ee42dc6d8e443a0858e0c65ce56cc74~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_edd25cffbf1249d89bb0f6c5a95b76e5~mv2.png/v1/fill/w_241,h_217,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_edd25cffbf1249d89bb0f6c5a95b76e5~mv2.png" alt=""></td>
</tr>
<tr>
<td>A25</td>
<td>jawOpen</td>
<td><img src="https://static.wixstatic.com/media/64c63b_aca391d5eb744a76b18d6ced31904111~mv2.png/v1/fill/w_267,h_192,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_aca391d5eb744a76b18d6ced31904111~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_f14421d8adb1461ea32ca31bd3cac7be~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f14421d8adb1461ea32ca31bd3cac7be~mv2.png" alt=""></td>
</tr>
<tr>
<td>A26</td>
<td>jawForward</td>
<td><img src="https://static.wixstatic.com/media/64c63b_a199113be0f9418f8c729d9a7e7b4e49~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a199113be0f9418f8c729d9a7e7b4e49~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_df9963f3452c4ce1bd1b6829a8045112~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_df9963f3452c4ce1bd1b6829a8045112~mv2.png" alt=""></td>
</tr>
<tr>
<td>A27</td>
<td>jawLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_2642a61cdd0241f9ba24339873003125~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2642a61cdd0241f9ba24339873003125~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_0de7a40c68654461be74016c2e29cf02~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0de7a40c68654461be74016c2e29cf02~mv2.png" alt=""></td>
</tr>
<tr>
<td>A28</td>
<td>jawRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_2838229bffe74a5abe7d25d9c6e398ca~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2838229bffe74a5abe7d25d9c6e398ca~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_2f51f3993bed441b89b9b493a1f2e86b~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2f51f3993bed441b89b9b493a1f2e86b~mv2.png" alt=""></td>
</tr>
<tr>
<td>A29</td>
<td>mouthFunnel</td>
<td><img src="https://static.wixstatic.com/media/64c63b_d2719d8d83524b52a735296f0dfbf092~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d2719d8d83524b52a735296f0dfbf092~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_e2b4d7681dcf4b1faf34e3c5b57dd3ac~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e2b4d7681dcf4b1faf34e3c5b57dd3ac~mv2.png" alt=""></td>
</tr>
<tr>
<td>A30</td>
<td>mouthPucker</td>
<td><img src="https://static.wixstatic.com/media/64c63b_7771a95fb2ae4afeb885b7a684e3f249~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_7771a95fb2ae4afeb885b7a684e3f249~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_e553a24166984303920d5ec9ce1de6d6~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e553a24166984303920d5ec9ce1de6d6~mv2.png" alt=""></td>
</tr>
<tr>
<td>A31</td>
<td>mouthLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_d2e30cadc9b443f6993ee48d99ffb9c8~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d2e30cadc9b443f6993ee48d99ffb9c8~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_76b134e6564749fcaf6e036a6dc53517~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_76b134e6564749fcaf6e036a6dc53517~mv2.png" alt=""></td>
</tr>
<tr>
<td>A32</td>
<td>mouthRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_ef34b0cf15c541058052d74870f95a11~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ef34b0cf15c541058052d74870f95a11~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_332e51118068490cbb932bc8b3880895~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_332e51118068490cbb932bc8b3880895~mv2.png" alt=""></td>
</tr>
<tr>
<td>A33</td>
<td>mouthRollUpper</td>
<td><img src="https://static.wixstatic.com/media/64c63b_5c93c56f5d9e4698a86160047452fdae~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5c93c56f5d9e4698a86160047452fdae~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_f86e02c72dcd4e27b5fafc3e7cbf5098~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f86e02c72dcd4e27b5fafc3e7cbf5098~mv2.png" alt=""></td>
</tr>
<tr>
<td>A34</td>
<td>mouthRollLower</td>
<td><img src="https://static.wixstatic.com/media/64c63b_8d2d50c4784b4f4a881264f9e806b26e~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8d2d50c4784b4f4a881264f9e806b26e~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_f6ce7f1df803456fb25b77533ec5c1a9~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f6ce7f1df803456fb25b77533ec5c1a9~mv2.png" alt=""></td>
</tr>
<tr>
<td>A35</td>
<td>mouthShrugUpper</td>
<td><img src="https://static.wixstatic.com/media/64c63b_d70a5a8102d14df6be57658f696ab28c~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_d70a5a8102d14df6be57658f696ab28c~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_36feb9bc9305402e8a9e044b7f42c06e~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_36feb9bc9305402e8a9e044b7f42c06e~mv2.png" alt=""></td>
</tr>
<tr>
<td>A36</td>
<td>mouthShrugLower</td>
<td><img src="https://static.wixstatic.com/media/64c63b_c39b6573ab8b452c8ba9af4cfd61fa0d~mv2.png/v1/fill/w_267,h_183,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c39b6573ab8b452c8ba9af4cfd61fa0d~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_881391abc1ff4fbabd6f7719d93179b8~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_881391abc1ff4fbabd6f7719d93179b8~mv2.png" alt=""></td>
</tr>
<tr>
<td>A37</td>
<td>mouthClose</td>
<td><img src="https://static.wixstatic.com/media/64c63b_7c1a9921e54c42c5bbad10ce2d2a2edc~mv2.png/v1/fill/w_267,h_129,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_7c1a9921e54c42c5bbad10ce2d2a2edc~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_8aded518da54400db938b69753b8539a~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8aded518da54400db938b69753b8539a~mv2.png" alt=""></td>
</tr>
<tr>
<td>A38</td>
<td>mouthSmileLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_a3cdfd578cec40a5a83931c4d0c9f8ab~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a3cdfd578cec40a5a83931c4d0c9f8ab~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_11aa5137231b4bfe8a8908f25d8d4112~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_11aa5137231b4bfe8a8908f25d8d4112~mv2.png" alt=""></td>
</tr>
<tr>
<td>A39</td>
<td>mouthSmileRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_f0c7a9ddfcb945f496f4ac8aafcfd0ca~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f0c7a9ddfcb945f496f4ac8aafcfd0ca~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_4818df7bf47740f6bab387d0d2926a2b~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4818df7bf47740f6bab387d0d2926a2b~mv2.png" alt=""></td>
</tr>
<tr>
<td>A40</td>
<td>mouthFrownLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_8e7c89a5e9514206ac3fd7152e912ef8~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8e7c89a5e9514206ac3fd7152e912ef8~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_ba5a9fdcf6d246439b8d7d9dbf63fb16~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ba5a9fdcf6d246439b8d7d9dbf63fb16~mv2.png" alt=""></td>
</tr>
<tr>
<td>A41</td>
<td>mouthFrownRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_019c769729a34c7c992c3bbde95adf2a~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_019c769729a34c7c992c3bbde95adf2a~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_4505259aa94646278b01cd6b4e6fe32a~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4505259aa94646278b01cd6b4e6fe32a~mv2.png" alt=""></td>
</tr>
<tr>
<td>A42</td>
<td>mouthDimpleLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_b7c5c7b4fcea481ba877fab837ddda7c~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b7c5c7b4fcea481ba877fab837ddda7c~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_53d010f6b8b340d6a305149152fe9eb2~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_53d010f6b8b340d6a305149152fe9eb2~mv2.png" alt=""></td>
</tr>
<tr>
<td>A43</td>
<td>mouthDimpleRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_268dda3d9bb14eaba63c5b123ab9002c~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_268dda3d9bb14eaba63c5b123ab9002c~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_ea46553169c749f69dc8e47737434193~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ea46553169c749f69dc8e47737434193~mv2.png" alt=""></td>
</tr>
<tr>
<td>A44</td>
<td>mouthUpperUpLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_e6f82a77cd374e37b456590eb19c2d28~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e6f82a77cd374e37b456590eb19c2d28~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_5c9a52ea901243218e0c9252fcd45a00~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5c9a52ea901243218e0c9252fcd45a00~mv2.png" alt=""></td>
</tr>
<tr>
<td>A45</td>
<td>mouthUpperUpRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_384bab2c926045f99f4bbef75b6975f0~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_384bab2c926045f99f4bbef75b6975f0~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_8abd87f586bb4d2088673a2358a65adb~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8abd87f586bb4d2088673a2358a65adb~mv2.png" alt=""></td>
</tr>
<tr>
<td>A46</td>
<td>mouthLowerDownLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_2511f8304fbb49dab88eb09b118f88bc~mv2.png/v1/fill/w_267,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2511f8304fbb49dab88eb09b118f88bc~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_21506f6994114f1194bc69958bd3778d~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_21506f6994114f1194bc69958bd3778d~mv2.png" alt=""></td>
</tr>
<tr>
<td>A47</td>
<td>mouthLowerDownRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_5c300e220ef04f388b827c096ad7aae6~mv2.png/v1/fill/w_267,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5c300e220ef04f388b827c096ad7aae6~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_9ac53c48df9e4d63b6774b91aaa4db3d~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9ac53c48df9e4d63b6774b91aaa4db3d~mv2.png" alt=""></td>
</tr>
<tr>
<td>A48</td>
<td>mouthPressLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_478c881ace1744ff825202484b212c17~mv2.png/v1/fill/w_267,h_187,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_478c881ace1744ff825202484b212c17~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_cca358e42c08454cb9f7f30317c4e93c~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_cca358e42c08454cb9f7f30317c4e93c~mv2.png" alt=""></td>
</tr>
<tr>
<td>A49</td>
<td>mouthPressRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_acad007d32d24b26b4cc192345afc0ba~mv2.png/v1/fill/w_267,h_186,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_acad007d32d24b26b4cc192345afc0ba~mv2.png" alt=""></td>
<td><br><img src="https://static.wixstatic.com/media/64c63b_35bac2e5acf54d438dd0acf4690c4ea2~mv2.png/v1/fill/w_230,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_35bac2e5acf54d438dd0acf4690c4ea2~mv2.png" alt=""></td>
</tr>
<tr>
<td>A50</td>
<td>mouthStretchLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_18fbf15030164a6383068c8fb7aa7e72~mv2.png/v1/fill/w_263,h_184,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_18fbf15030164a6383068c8fb7aa7e72~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_cf77104a546149e88698feb420726493~mv2.png/v1/fill/w_232,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_cf77104a546149e88698feb420726493~mv2.png" alt=""></td>
</tr>
<tr>
<td>A51</td>
<td>mouthStretchRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_3f8dd987a3d44b7e98e1e7abb1815111~mv2.png/v1/fill/w_263,h_184,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_3f8dd987a3d44b7e98e1e7abb1815111~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_b2a3abb6ea204ab293571c7c19747003~mv2.png/v1/fill/w_232,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b2a3abb6ea204ab293571c7c19747003~mv2.png" alt=""></td>
</tr>
<tr>
<td>A52</td>
<td>tongueOut</td>
<td></td>
<td><img src="https://static.wixstatic.com/media/64c63b_10387f10b0e04d5fac672f8bd17d9459~mv2.png/v1/fill/w_232,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_10387f10b0e04d5fac672f8bd17d9459~mv2.png" alt=""></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>CC3 é¢å¤–çš„èˆŒå¤´Blendshape(with open month)ï¼š</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>T01</th>
<th>Tongue_Up</th>
<th></th>
<th><img src="https://static.wixstatic.com/media/64c63b_75c512342cde45ffbb40fcf5d463732e~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_75c512342cde45ffbb40fcf5d463732e~mv2.png" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td>T02</td>
<td>Tongue_Down</td>
<td></td>
<td><img src="https://static.wixstatic.com/media/64c63b_4bdf00b4d23d4a89ac0bffbb66cc348d~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4bdf00b4d23d4a89ac0bffbb66cc348d~mv2.png" alt=""></td>
</tr>
<tr>
<td>T03</td>
<td>Tongue_Left</td>
<td></td>
<td><img src="https://static.wixstatic.com/media/64c63b_860b7c7043894521a754755c35816cb3~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_860b7c7043894521a754755c35816cb3~mv2.png" alt=""></td>
</tr>
<tr>
<td>T04</td>
<td>Tongue_Right</td>
<td></td>
<td><img src="https://static.wixstatic.com/media/64c63b_02c7adc74f934d31ad35c01615b96735~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_02c7adc74f934d31ad35c01615b96735~mv2.png" alt=""></td>
</tr>
<tr>
<td>T05</td>
<td>Tongue_Roll</td>
<td></td>
<td><img src="https://static.wixstatic.com/media/64c63b_bfa27b0483c94f7484eeed246642fbc5~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_bfa27b0483c94f7484eeed246642fbc5~mv2.png" alt=""></td>
</tr>
<tr>
<td>T06</td>
<td>Tongue_Tip_Up</td>
<td></td>
<td><img src="https://static.wixstatic.com/media/64c63b_6a7d96ce1444409c958adc03652983b7~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6a7d96ce1444409c958adc03652983b7~mv2.png" alt=""></td>
</tr>
<tr>
<td>T07</td>
<td>Tongue_Tip_Down</td>
<td></td>
<td><img src="https://static.wixstatic.com/media/64c63b_37fa335ad1a549b983fb6552db3b5198~mv2.png/v1/fill/w_244,h_220,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_37fa335ad1a549b983fb6552db3b5198~mv2.png" alt=""></td>
</tr>
</tbody>
</table>
</div>
<h3 id="Viveé¢éƒ¨çš„è¡¨æƒ…åŸºå‡†ç»„"><a href="#Viveé¢éƒ¨çš„è¡¨æƒ…åŸºå‡†ç»„" class="headerlink" title="Viveé¢éƒ¨çš„è¡¨æƒ…åŸºå‡†ç»„"></a>Viveé¢éƒ¨çš„è¡¨æƒ…åŸºå‡†ç»„</h3><p>Viveè¿™ä¸€å¥—è„¸éƒ¨è¿½è¸ªä¹Ÿæ˜¯52ä¸ªblendshapesï¼Œä½†æ˜¯å’Œè‹¹æœçš„åŸºå‡†æœ‰å¾ˆå¤§åŒºåˆ«ã€‚</p>
<ul>
<li>åŒºåˆ«ä¸€ï¼šèˆŒå¤´</li>
</ul>
<p>è‹¹æœå…¶å®æ˜¯52+7ï¼Œå› ä¸ºèˆŒå¤´åœ¨52ä¸ªé‡Œåªæœ‰ä¸€ä¸ªä¼¸èˆŒå¤´çš„blendshapeï¼Œä½†viveå…¶å®æ˜¯42 + 10ï¼Œæ•´ä½“æ¥è®²Viveè¡¨æƒ…è®°ä½èƒ½trackingåˆ°çš„è¡¨æƒ…ç»†èŠ‚è¿˜æ˜¯æ›´å°‘ä¸€äº›ã€‚</p>
<ul>
<li>åŒºåˆ«äºŒï¼šçœ‰æ¯›</li>
</ul>
<p>ARKitçš„52ä¸ªblendshapesï¼Œæ˜¯æ ¹æ®ç¡¬ä»¶åˆ†åŒºä¸€å¯¹ä¸€trackingçš„ï¼Œç„¶è€ŒViveçœ‰æ¯›ä¸åˆ†æ˜¯æ²¡æœ‰å•ç‹¬å¦è®¾blendshapesï¼Œè€Œæ˜¯ä¸çœ¼ç›çš„åŠ¨ä½œblendedåœ¨ä¸€èµ·ä½œä¸ºä¸€ä¸ªblendshapeçš„ï¼Œå¹¶ä¸æ˜¯ç²¾å‡†çš„ä¸€å¯¹ä¸€åˆ†åŒºtrackingã€‚</p>
<p>æˆ‘ä¸‹é¢ç¼–å·çš„æ’åºæ˜¯æŒ‰ç…§<a href="https://developer.vive.com/resources/vive-sense/sdk/vive-eye-and-facial-tracking-sdk/">VIVE Eye and Facial Tracking SDK</a> unity é‡Œinspectoré‡Œçš„é¡ºåºï¼Œæ–¹ä¾¿æˆ‘åŠ è¡¨æƒ…ã€‚</p>
<p>è¿™é‡Œæ˜¯æ•´ç†çš„ç”¨ARKitåˆ¶ä½œViveåŸºå‡†çš„å¯¹åº”ç¼–å·ï¼š</p>
<p><a href="https://docs.google.com/spreadsheets/d/1kWXnqtiVbXRb1FrD5NLlxxuxbYmS0Z6YBLuIE1WwqD4/edit?usp=sharing">https://docs.google.com/spreadsheets/d/1kWXnqtiVbXRb1FrD5NLlxxuxbYmS0Z6YBLuIE1WwqD4/edit?usp=sharing</a></p>
<ul>
<li>Eye Blendshapes ï¼ˆ14 = 12 + 2ï¼‰</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Viveç¼–å·</th>
<th>Viveè¡¨æƒ…åŸºå‡†</th>
<th>Vive Picture</th>
<th>Create by CC3 blendshapes</th>
</tr>
</thead>
<tbody>
<tr>
<td>V01</td>
<td>Eye_Left_Blink</td>
<td><img src="https://static.wixstatic.com/media/64c63b_735cb0ae227e42bca98f9c51fbd0df6b~mv2.png/v1/fill/w_238,h_182,al_c,lg_1,q_85,enc_auto/64c63b_735cb0ae227e42bca98f9c51fbd0df6b~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_e5f3c0dfc63a42618e182a9b1a0c1e9c~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e5f3c0dfc63a42618e182a9b1a0c1e9c~mv2.png" alt=""></td>
</tr>
<tr>
<td>V02</td>
<td>Eye_Left_Wide</td>
<td><img src="https://static.wixstatic.com/media/64c63b_1d9223fb44574a94988a7c9ce4d89b39~mv2.png/v1/fill/w_222,h_160,al_c,lg_1,q_85,enc_auto/64c63b_1d9223fb44574a94988a7c9ce4d89b39~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_5dd9ed05165f4fe9b486b4f0604dacc1~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5dd9ed05165f4fe9b486b4f0604dacc1~mv2.png" alt=""></td>
</tr>
<tr>
<td>V03</td>
<td>Eye_Left_Right</td>
<td><img src="https://static.wixstatic.com/media/64c63b_638f42e4960743c4b235ab18b5ac6eba~mv2.png/v1/fill/w_238,h_188,al_c,lg_1,q_85,enc_auto/64c63b_638f42e4960743c4b235ab18b5ac6eba~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_c5fcda96b7184941b2a89b2193470f2b~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c5fcda96b7184941b2a89b2193470f2b~mv2.png" alt=""></td>
</tr>
<tr>
<td>V04</td>
<td>Eye_Left_Left</td>
<td><img src="https://static.wixstatic.com/media/64c63b_a1041585f54748728dd71aec7de129f5~mv2.png/v1/fill/w_238,h_192,al_c,lg_1,q_85,enc_auto/64c63b_a1041585f54748728dd71aec7de129f5~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_a26c36f7dc2940fe9513e263f7a99c4e~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a26c36f7dc2940fe9513e263f7a99c4e~mv2.png" alt=""></td>
</tr>
<tr>
<td>V05</td>
<td>Eye_Left_Up</td>
<td><img src="https://static.wixstatic.com/media/64c63b_d2c84d05015c4d8289f6c7d6d5ba0dcc~mv2.png/v1/fill/w_238,h_203,al_c,lg_1,q_85,enc_auto/64c63b_d2c84d05015c4d8289f6c7d6d5ba0dcc~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_e3e67e16e4b84697a39c3333bad24712~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e3e67e16e4b84697a39c3333bad24712~mv2.png" alt=""></td>
</tr>
<tr>
<td>V06</td>
<td>Eye_Left_Down</td>
<td><img src="https://static.wixstatic.com/media/64c63b_5cd43316383549e282e7f3f743df9053~mv2.png/v1/fill/w_238,h_195,al_c,lg_1,q_85,enc_auto/64c63b_5cd43316383549e282e7f3f743df9053~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_993bd278fb024580a834a71c6886cc4b~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_993bd278fb024580a834a71c6886cc4b~mv2.png" alt=""></td>
</tr>
<tr>
<td>V07</td>
<td>Eye_Right_Blink</td>
<td><img src="https://static.wixstatic.com/media/64c63b_2e198e55d97a491cbc66059e6f6adddc~mv2.png/v1/fill/w_235,h_195,al_c,lg_1,q_85,enc_auto/64c63b_2e198e55d97a491cbc66059e6f6adddc~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V08</td>
<td>Eye_Right_Wide</td>
<td><img src="https://static.wixstatic.com/media/64c63b_6eebbecf575d4bec905be4dbec06322c~mv2.png/v1/fill/w_223,h_160,al_c,lg_1,q_85,enc_auto/64c63b_6eebbecf575d4bec905be4dbec06322c~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V09</td>
<td>Eye_Right_Right</td>
<td><img src="https://static.wixstatic.com/media/64c63b_fc88e475e8c4435a98364224f54ade1a~mv2.png/v1/fill/w_234,h_197,al_c,lg_1,q_85,enc_auto/64c63b_fc88e475e8c4435a98364224f54ade1a~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V10</td>
<td>Eye_Right_Left</td>
<td><img src="https://static.wixstatic.com/media/64c63b_216b900672314c37a3e91501b7fe7cc1~mv2.png/v1/fill/w_238,h_190,al_c,lg_1,q_85,enc_auto/64c63b_216b900672314c37a3e91501b7fe7cc1~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V11</td>
<td>Eye_Right_Up</td>
<td><img src="https://static.wixstatic.com/media/64c63b_062847a5c45d4dabbe78d255779013dd~mv2.png/v1/fill/w_231,h_196,al_c,lg_1,q_85,enc_auto/64c63b_062847a5c45d4dabbe78d255779013dd~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V12</td>
<td>Eye_Right_Down</td>
<td><img src="https://static.wixstatic.com/media/64c63b_b6fae35fba8543d0becc535532111d23~mv2.png/v1/fill/w_238,h_176,al_c,lg_1,q_85,enc_auto/64c63b_b6fae35fba8543d0becc535532111d23~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V13</td>
<td>Eye_Left_squeeze: The blendShape close eye tightly when Eye_Left_Blink  value is 100.</td>
<td><img src="https://static.wixstatic.com/media/64c63b_c7b07f1b4ec6495685d85808d23c04e8~mv2.png/v1/fill/w_238,h_183,al_c,lg_1,q_85,enc_auto/64c63b_c7b07f1b4ec6495685d85808d23c04e8~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_a629d31ace624dd8b2ded5123123156e~mv2.png/v1/fill/w_211,h_188,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a629d31ace624dd8b2ded5123123156e~mv2.png" alt=""></td>
</tr>
<tr>
<td>V14</td>
<td>Eye_Right_squeeze</td>
<td><img src="https://static.wixstatic.com/media/64c63b_b82c535f90874742b3c0b6ff62136fe2~mv2.png/v1/fill/w_238,h_194,al_c,lg_1,q_85,enc_auto/64c63b_b82c535f90874742b3c0b6ff62136fe2~mv2.png" alt=""></td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>Lip Blendshapes ï¼ˆ38 = 37 + 1ï¼‰</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>Viveç¼–å·</th>
<th>Viveè¡¨æƒ…åŸºå‡†</th>
<th>Vive Picture</th>
<th>Create by CC3 blendshapes</th>
</tr>
</thead>
<tbody>
<tr>
<td>V15</td>
<td>Jaw_Right</td>
<td><img src="https://static.wixstatic.com/media/64c63b_75f8b68a96104ef8bf36e393c7ecd48b~mv2.png/v1/fill/w_235,h_190,al_c,lg_1,q_85,enc_auto/64c63b_75f8b68a96104ef8bf36e393c7ecd48b~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_65471d28b0d743c0bb6232ffaee0f6b6~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_65471d28b0d743c0bb6232ffaee0f6b6~mv2.png" alt=""></td>
</tr>
<tr>
<td>V16</td>
<td>Jaw_Left</td>
<td><img src="https://static.wixstatic.com/media/64c63b_9cacde29288c4523a2192835a736ad6b~mv2.png/v1/fill/w_245,h_202,al_c,lg_1,q_85,enc_auto/64c63b_9cacde29288c4523a2192835a736ad6b~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_017d7142fd494aef9ad7bbe53fa1d6eb~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_017d7142fd494aef9ad7bbe53fa1d6eb~mv2.png" alt=""></td>
</tr>
<tr>
<td>V17</td>
<td>Jaw_Forward</td>
<td><img src="https://static.wixstatic.com/media/64c63b_3876f3dd1a1b4eed92e8405b42700190~mv2.png/v1/fill/w_248,h_197,al_c,lg_1,q_85,enc_auto/64c63b_3876f3dd1a1b4eed92e8405b42700190~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_20353f83579541428557c32d92545c9e~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_20353f83579541428557c32d92545c9e~mv2.png" alt=""></td>
</tr>
<tr>
<td>V18</td>
<td>Jaw_Open</td>
<td><img src="https://static.wixstatic.com/media/64c63b_dc79f10003534839948d3261183d5082~mv2.png/v1/fill/w_244,h_188,al_c,lg_1,q_85,enc_auto/64c63b_dc79f10003534839948d3261183d5082~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_24470b9cc9964a11906c42b1d1a6e5e9~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_24470b9cc9964a11906c42b1d1a6e5e9~mv2.png" alt=""></td>
</tr>
<tr>
<td>V19</td>
<td>Mouth_Ape_Shape</td>
<td><img src="https://static.wixstatic.com/media/64c63b_7a0f9461a760449db12b2159009ccc93~mv2.png/v1/fill/w_249,h_196,al_c,lg_1,q_85,enc_auto/64c63b_7a0f9461a760449db12b2159009ccc93~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_3d7911f5bfa645adb7f3c36fbeafa2b9~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_3d7911f5bfa645adb7f3c36fbeafa2b9~mv2.png" alt=""></td>
</tr>
<tr>
<td>V20</td>
<td>Mouth_Upper_Right</td>
<td><img src="https://static.wixstatic.com/media/64c63b_01037e0042754059b7ada72a8adf2e8a~mv2.png/v1/fill/w_227,h_161,al_c,lg_1,q_85,enc_auto/64c63b_01037e0042754059b7ada72a8adf2e8a~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_185ec305ba464016a15c2420fb04916e~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_185ec305ba464016a15c2420fb04916e~mv2.png" alt=""></td>
</tr>
<tr>
<td>V21</td>
<td>Mouth_Upper_Left</td>
<td><img src="https://static.wixstatic.com/media/64c63b_f0c61e8f3f3c42d7ad6d83703f1a61d9~mv2.png/v1/fill/w_265,h_182,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f0c61e8f3f3c42d7ad6d83703f1a61d9~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_abbecb4860a44fe9800585825beb4b17~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_abbecb4860a44fe9800585825beb4b17~mv2.png" alt=""></td>
</tr>
<tr>
<td>V22</td>
<td>Mouth_Lower_Right</td>
<td><img src="https://static.wixstatic.com/media/64c63b_3ec74984b19d44d389a68bcc1ac1a7fb~mv2.png/v1/fill/w_265,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_3ec74984b19d44d389a68bcc1ac1a7fb~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_80a4cdffa3fb493e9c153b517d9aebda~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_80a4cdffa3fb493e9c153b517d9aebda~mv2.png" alt=""></td>
</tr>
<tr>
<td>V23</td>
<td>Mouth_Lower_Left</td>
<td><img src="https://static.wixstatic.com/media/64c63b_e80cee8738ea42528c8f351303f5e2c8~mv2.png/v1/fill/w_265,h_225,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e80cee8738ea42528c8f351303f5e2c8~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_edf8e441ff994c27bde811a21754d5e5~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_edf8e441ff994c27bde811a21754d5e5~mv2.png" alt=""></td>
</tr>
<tr>
<td>V24</td>
<td>*Mouth_Upper_Overturn</td>
<td><img src="https://static.wixstatic.com/media/64c63b_5f77c14164ae48cf9c0cf4c762b97837~mv2.png/v1/fill/w_265,h_202,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5f77c14164ae48cf9c0cf4c762b97837~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_b8ae358e723f42e199338722f186e238~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b8ae358e723f42e199338722f186e238~mv2.png" alt=""></td>
</tr>
<tr>
<td>V25</td>
<td>*Mouth_Lower_Overturn</td>
<td><img src="https://static.wixstatic.com/media/64c63b_16a26f9ced50420b99a4c32fc296c112~mv2.png/v1/fill/w_265,h_210,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_16a26f9ced50420b99a4c32fc296c112~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_282323813dfa4ea1aa76551b112e3919~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_282323813dfa4ea1aa76551b112e3919~mv2.png" alt=""></td>
</tr>
<tr>
<td>V26</td>
<td>Mouth_Pout</td>
<td><img src="https://static.wixstatic.com/media/64c63b_e7da853fe63242a9bedbd7fe3bddadc7~mv2.png/v1/fill/w_265,h_205,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e7da853fe63242a9bedbd7fe3bddadc7~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_36615908f74d4663a6bc438c3287938c~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_36615908f74d4663a6bc438c3287938c~mv2.png" alt=""></td>
</tr>
<tr>
<td>V27</td>
<td>Mouth_Smile_Right</td>
<td><img src="https://static.wixstatic.com/media/64c63b_1de129dc23784dd0af8d5bbccff75741~mv2.png/v1/fill/w_265,h_205,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_1de129dc23784dd0af8d5bbccff75741~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_47a00d3e749e47fa8b3489da81252654~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_47a00d3e749e47fa8b3489da81252654~mv2.png" alt=""></td>
</tr>
<tr>
<td>V28</td>
<td>Mouth_Smile_Left</td>
<td><img src="https://static.wixstatic.com/media/64c63b_e66c5606123d4272bc4d3206a101e884~mv2.png/v1/fill/w_265,h_213,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e66c5606123d4272bc4d3206a101e884~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_0a26740959644351bb01f9e9d40ef35e~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0a26740959644351bb01f9e9d40ef35e~mv2.png" alt=""></td>
</tr>
<tr>
<td>V29</td>
<td>Mouth_Sad_Right</td>
<td><img src="https://static.wixstatic.com/media/64c63b_ba5427a221c2446e9d3b9e30d94d80b9~mv2.png/v1/fill/w_265,h_224,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ba5427a221c2446e9d3b9e30d94d80b9~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_c1e99be3d6c34038852ce55b72102f5c~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c1e99be3d6c34038852ce55b72102f5c~mv2.png" alt=""></td>
</tr>
<tr>
<td>V30</td>
<td>Mouth_Sad_Left</td>
<td><img src="https://static.wixstatic.com/media/64c63b_00772c50ca334cbf95dd1bf53be4c6b8~mv2.png/v1/fill/w_265,h_218,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_00772c50ca334cbf95dd1bf53be4c6b8~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_889e2637303f4d7195afd699a3d92b86~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_889e2637303f4d7195afd699a3d92b86~mv2.png" alt=""></td>
</tr>
<tr>
<td>V31</td>
<td>Cheek_Puff_Right</td>
<td><img src="https://static.wixstatic.com/media/64c63b_765350d6685547d4b03b7ae31e7346e0~mv2.png/v1/fill/w_265,h_224,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_765350d6685547d4b03b7ae31e7346e0~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_66386b8d632b4556a00f886613f26d92~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_66386b8d632b4556a00f886613f26d92~mv2.png" alt=""></td>
</tr>
<tr>
<td>V32</td>
<td>Cheek_Puff_Left</td>
<td><img src="https://static.wixstatic.com/media/64c63b_2998211eb141496d8651b786337b7846~mv2.png/v1/fill/w_265,h_213,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2998211eb141496d8651b786337b7846~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_833f433253fb4bcc8e380d79120b3003~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_833f433253fb4bcc8e380d79120b3003~mv2.png" alt=""></td>
</tr>
<tr>
<td>V33</td>
<td>Cheek_Suck</td>
<td><img src="https://static.wixstatic.com/media/64c63b_6eea541e05494d26a06cbbe5377cdc0a~mv2.png/v1/fill/w_265,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6eea541e05494d26a06cbbe5377cdc0a~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_8573de7fc0d84245a0fa4412ecd3e842~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_8573de7fc0d84245a0fa4412ecd3e842~mv2.png" alt=""></td>
</tr>
<tr>
<td>V34</td>
<td>Mouth_Upper_UpRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_b6ca87cbb7774b2ab4f0ec3748ec9c51~mv2.png/v1/fill/w_265,h_216,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b6ca87cbb7774b2ab4f0ec3748ec9c51~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_c48b985609fe4129ad1dac8a41905a7e~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_c48b985609fe4129ad1dac8a41905a7e~mv2.png" alt=""></td>
</tr>
<tr>
<td>V35</td>
<td>Mouth<em>Upper</em> UpLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_58bdc8db0ac3451388534ff3bfb0fa83~mv2.png/v1/fill/w_265,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_58bdc8db0ac3451388534ff3bfb0fa83~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_5ff3f05aeecd48fe9f3077f5c9c96569~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5ff3f05aeecd48fe9f3077f5c9c96569~mv2.png" alt=""></td>
</tr>
<tr>
<td>V36</td>
<td>Mouth_Lower_DownRight</td>
<td><img src="https://static.wixstatic.com/media/64c63b_12f26efe2f28425cb366eea55e83470c~mv2.png/v1/fill/w_265,h_223,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_12f26efe2f28425cb366eea55e83470c~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_30ae27fa9ee94aa8a1b29bbd5fe7b0b2~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_30ae27fa9ee94aa8a1b29bbd5fe7b0b2~mv2.png" alt=""></td>
</tr>
<tr>
<td>V37</td>
<td>Mouth_Lower_DownLeft</td>
<td><img src="https://static.wixstatic.com/media/64c63b_4ed1a27945324b53aad0aa3cf453a275~mv2.png/v1/fill/w_265,h_218,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4ed1a27945324b53aad0aa3cf453a275~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_76893f9855fa4a5a9415cd8abfae6f6f~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_76893f9855fa4a5a9415cd8abfae6f6f~mv2.png" alt=""></td>
</tr>
<tr>
<td>V38</td>
<td>Mouth_Upper_Inside</td>
<td><img src="https://static.wixstatic.com/media/64c63b_f5e050f0d9954760879ccd18185c2fc8~mv2.png/v1/fill/w_265,h_209,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_f5e050f0d9954760879ccd18185c2fc8~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_5217c686c7c6455aaca6ba1b2ce64217~mv2.png/v1/fill/w_224,h_200,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5217c686c7c6455aaca6ba1b2ce64217~mv2.png" alt=""></td>
</tr>
<tr>
<td>V39</td>
<td>Mouth_Lower_Inside</td>
<td><img src="https://static.wixstatic.com/media/64c63b_0031f9adda4441cbb6361e280e594c7b~mv2.png/v1/fill/w_269,h_211,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0031f9adda4441cbb6361e280e594c7b~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_5108178f718e492eb840f4d678eb3e4e~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_5108178f718e492eb840f4d678eb3e4e~mv2.png" alt=""></td>
</tr>
<tr>
<td>V40</td>
<td>Mouth_Lower_Overlay</td>
<td><img src="https://static.wixstatic.com/media/64c63b_26e5bd6286474b4ea3f4fff3933b91f1~mv2.png/v1/fill/w_269,h_222,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_26e5bd6286474b4ea3f4fff3933b91f1~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_1ab252df4c5146e1815e23a83edb2cd2~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_1ab252df4c5146e1815e23a83edb2cd2~mv2.png" alt=""></td>
</tr>
<tr>
<td>V41</td>
<td>Tongue_LongStep1</td>
<td><img src="https://static.wixstatic.com/media/64c63b_6791ccfceffe4c2ca07f277b91037521~mv2.png/v1/fill/w_269,h_207,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6791ccfceffe4c2ca07f277b91037521~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_4ef4ab94e1ef47dcb01facf5d168f1d1~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4ef4ab94e1ef47dcb01facf5d168f1d1~mv2.png" alt=""></td>
</tr>
<tr>
<td>V42</td>
<td>Tongue_LongStep2</td>
<td><img src="https://static.wixstatic.com/media/64c63b_e79ccc0096a54ce2b48d188cf6907d0c~mv2.png/v1/fill/w_269,h_181,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e79ccc0096a54ce2b48d188cf6907d0c~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_6e560524670843848266701061f24c63~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6e560524670843848266701061f24c63~mv2.png" alt=""></td>
</tr>
<tr>
<td>V43</td>
<td>*Tongue_Down</td>
<td><img src="https://static.wixstatic.com/media/64c63b_ac97c6cf9fd940e9b38cdf22ab3c9261~mv2.png/v1/fill/w_269,h_199,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ac97c6cf9fd940e9b38cdf22ab3c9261~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_a2a8aab70eea4b6ba9378cf249aef3a0~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_a2a8aab70eea4b6ba9378cf249aef3a0~mv2.png" alt=""></td>
</tr>
<tr>
<td>V44</td>
<td>*Tongue_Up</td>
<td><img src="https://static.wixstatic.com/media/64c63b_0c11f06c560842718309c52bc159ffa8~mv2.png/v1/fill/w_269,h_197,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0c11f06c560842718309c52bc159ffa8~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_0abc5fe7b2da4c988591e18fc6e060ac~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0abc5fe7b2da4c988591e18fc6e060ac~mv2.png" alt=""></td>
</tr>
<tr>
<td>V45</td>
<td>*Tongue_Right</td>
<td><img src="https://static.wixstatic.com/media/64c63b_0d6e1976f6c342a395f9631be529c694~mv2.png/v1/fill/w_269,h_202,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_0d6e1976f6c342a395f9631be529c694~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_e17db94c36594f32b60ce6057a17aafc~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_e17db94c36594f32b60ce6057a17aafc~mv2.png" alt=""></td>
</tr>
<tr>
<td>V46</td>
<td>*Tongue_Left</td>
<td><img src="https://static.wixstatic.com/media/64c63b_2633b9481a6f4e94ad4bfe6a6d52e122~mv2.png/v1/fill/w_269,h_201,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2633b9481a6f4e94ad4bfe6a6d52e122~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_ad949214aeda4b3488c238af7aabdba6~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_ad949214aeda4b3488c238af7aabdba6~mv2.png" alt=""></td>
</tr>
<tr>
<td>V47</td>
<td>*Tongue_Roll</td>
<td><img src="https://static.wixstatic.com/media/64c63b_4d41918f9af84d0aaaa2de1e354a5706~mv2.png/v1/fill/w_269,h_216,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_4d41918f9af84d0aaaa2de1e354a5706~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_2c544b45c0ea48079bb570912b85b2a3~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_2c544b45c0ea48079bb570912b85b2a3~mv2.png" alt=""></td>
</tr>
<tr>
<td>V48</td>
<td>*Tongue_UpLeft_Morph</td>
<td><img src="https://static.wixstatic.com/media/64c63b_49d65415de0f47d5a07aa77cfebd54e6~mv2.png/v1/fill/w_269,h_201,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_49d65415de0f47d5a07aa77cfebd54e6~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_9df53a0e560f41f2a441f9e799b56d1c~mv2.png/v1/fill/w_269,h_221,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_9df53a0e560f41f2a441f9e799b56d1c~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V49</td>
<td>*Tongue_UpRight_Morph</td>
<td><img src="https://static.wixstatic.com/media/64c63b_118b5229d2274b5f95a163ebc0d0cfad~mv2.png/v1/fill/w_269,h_232,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_118b5229d2274b5f95a163ebc0d0cfad~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_aa40430e533c40c69f0addb2df019a29~mv2.png/v1/fill/w_269,h_215,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_aa40430e533c40c69f0addb2df019a29~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V50</td>
<td>*Tongue_DownLeft_Morph</td>
<td><img src="https://static.wixstatic.com/media/64c63b_92fc463c5efc4436a23870d596023ba9~mv2.png/v1/fill/w_269,h_237,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_92fc463c5efc4436a23870d596023ba9~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_b3a74eba5433479b96ff645e85681480~mv2.png/v1/fill/w_269,h_231,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b3a74eba5433479b96ff645e85681480~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V51</td>
<td>*Tongue_DownRight_Morph</td>
<td><img src="https://static.wixstatic.com/media/64c63b_db25fb8a736e4b1f9f4e11ba7436e0b0~mv2.png/v1/fill/w_269,h_224,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_db25fb8a736e4b1f9f4e11ba7436e0b0~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_b707961c295f40a7995644e93e438ffc~mv2.png/v1/fill/w_269,h_212,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b707961c295f40a7995644e93e438ffc~mv2.png" alt=""></td>
<td></td>
</tr>
<tr>
<td>V52</td>
<td>*O-shaped mouth</td>
<td><img src="https://static.wixstatic.com/media/64c63b_97cacb52babe4a109cd02874efcb2eda~mv2.png/v1/fill/w_269,h_175,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_97cacb52babe4a109cd02874efcb2eda~mv2.png" alt=""></td>
<td><img src="https://static.wixstatic.com/media/64c63b_6e98ff0232d349b8a6f7d8348992ab37~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_6e98ff0232d349b8a6f7d8348992ab37~mv2.png" alt=""> <img src="https://static.wixstatic.com/media/64c63b_b35e7f3707fc4b0ca75f80c4d77867a4~mv2.png/v1/fill/w_217,h_193,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/64c63b_b35e7f3707fc4b0ca75f80c4d77867a4~mv2.png" alt=""></td>
</tr>
</tbody>
</table>
</div>
<h2 id="MediaPipeæå–BlendShape"><a href="#MediaPipeæå–BlendShape" class="headerlink" title="MediaPipeæå–BlendShape"></a>MediaPipeæå–BlendShape</h2><p>MediaPipe Face Landmarkerè§£å†³æ–¹æ¡ˆæœ€åˆäº5æœˆçš„Google I/O 2023å‘å¸ƒã€‚å®ƒå¯ä»¥æ£€æµ‹é¢éƒ¨landmarkå¹¶è¾“å‡ºblendshape scoreï¼Œä»¥æ¸²æŸ“ä¸ç”¨æˆ·åŒ¹é…çš„3Dé¢éƒ¨æ¨¡å‹ã€‚é€šè¿‡MediaPipe Face Landmarkerè§£å†³æ–¹æ¡ˆï¼ŒKDDIå’Œè°·æ­ŒæˆåŠŸåœ°ä¸ºè™šæ‹Ÿä¸»æ’­å¸¦æ¥äº†çœŸå®æ„Ÿã€‚</p>
<p><strong>æŠ€æœ¯å®ç°</strong></p>
<p>ä½¿ç”¨Mediapipeå¼ºå¤§è€Œé«˜æ•ˆçš„PythonåŒ…ï¼ŒKDDIå¼€å‘äººå‘˜èƒ½å¤Ÿæ£€æµ‹è¡¨æ¼”è€…çš„é¢éƒ¨ç‰¹å¾å¹¶å®æ—¶æå–52ä¸ªæ··åˆå½¢çŠ¶ã€‚</p>
<p>è¿˜å¯å‚è€ƒï¼š<a href="https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/face_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Face_Landmarker.ipynb">https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/face_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Face_Landmarker.ipynb</a></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> mediapipe <span class="keyword">as</span> mp</span><br><span class="line"><span class="keyword">from</span> mediapipe.tasks <span class="keyword">import</span> python <span class="keyword">as</span> mp_python</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">MP_TASK_FILE = <span class="string">"face_landmarker_with_blendshapes.task"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FaceMeshDetector</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(MP_TASK_FILE, mode=<span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f_buffer = f.read()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># åˆ›å»ºé…ç½®é€‰é¡¹</span></span><br><span class="line">        base_options = mp_python.BaseOptions(model_asset_buffer=f_buffer)</span><br><span class="line">        options = mp_python.vision.FaceLandmarkerOptions(</span><br><span class="line">            base_options=base_options,</span><br><span class="line">            output_face_blendshapes=<span class="literal">True</span>,</span><br><span class="line">            output_facial_transformation_matrixes=<span class="literal">True</span>,</span><br><span class="line">            running_mode=mp.tasks.vision.RunningMode.LIVE_STREAM,</span><br><span class="line">            num_faces=<span class="number">1</span>,</span><br><span class="line">            result_callback=self.mp_callback</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># åˆ›å»ºæ¨¡å‹</span></span><br><span class="line">        self.model = mp_python.vision.FaceLandmarker.create_from_options(options)</span><br><span class="line">        self.landmarks = <span class="literal">None</span></span><br><span class="line">        self.blendshapes = <span class="literal">None</span></span><br><span class="line">        self.latest_time_ms = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">mp_callback</span>(<span class="params">self, mp_result, output_image, timestamp_ms: <span class="built_in">int</span></span>):</span><br><span class="line">        <span class="comment"># å¤„ç†å›è°ƒç»“æœ</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(mp_result.face_landmarks) &gt;= <span class="number">1</span> <span class="keyword">and</span> <span class="built_in">len</span>(mp_result.face_blendshapes) &gt;= <span class="number">1</span>:</span><br><span class="line">            self.landmarks = mp_result.face_landmarks[<span class="number">0</span>]</span><br><span class="line">            self.blendshapes = [b.score <span class="keyword">for</span> b <span class="keyword">in</span> mp_result.face_blendshapes[<span class="number">0</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, frame</span>):</span><br><span class="line">        t_ms = <span class="built_in">int</span>(time.time() * <span class="number">1000</span>)</span><br><span class="line">        <span class="keyword">if</span> t_ms &lt;= self.latest_time_ms:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        frame_mp = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)</span><br><span class="line">        self.model.detect_async(frame_mp, t_ms)</span><br><span class="line">        self.latest_time_ms = t_ms</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_results</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.landmarks, self.blendshapes</span><br></pre></td></tr></tbody></table></figure>
<h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><ul>
<li><a href="https://www.mianzi-lizi.com/post/blendshapeå­¦ä¹ ç¬”è®°">https://www.mianzi-lizi.com/post/blendshapeå­¦ä¹ ç¬”è®°</a></li>
<li><a href="https://www.toutiao.com/article/6915330866285691395/">åˆ©ç”¨AnimojiæŠ€æœ¯è¯†åˆ«ç”¨æˆ·çš„è¡¨æƒ…</a></li>
<li><a href="https://news.nweon.com/110210">é€šè¿‡MediaPipeè§£å†³æ–¹æ¡ˆæ¥ä¸ºè™šæ‹Ÿä¸»æ’­å¸¦æ¥æ›´é€¼çœŸçœŸå®æ„Ÿ</a></li>
<li><a href="https://bbs.huaweicloud.com/blogs/374337">Unity &amp; FACEGOOD Audio2Face é€šè¿‡éŸ³é¢‘é©±åŠ¨é¢éƒ¨BlendShape</a></li>
<li><a href="https://www.cnblogs.com/jesse123/p/9014234.html">GenerativeAI Avatar solutions</a></li>
</ul>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
        <tag>3D reconstruction</tag>
      </tags>
  </entry>
  <entry>
    <title>å›¾åºŠè½¬åŒ–è„šæœ¬</title>
    <url>/2024/01/20/Note/PicConvert/</url>
    <content><![CDATA[<p>Github: <a href="https://github.com/imcyx/PicConvert">https://github.com/imcyx/PicConvert</a></p>
<h2 id="1-å®‰è£…ä¾èµ–"><a href="#1-å®‰è£…ä¾èµ–" class="headerlink" title="1. å®‰è£…ä¾èµ–"></a>1. å®‰è£…ä¾èµ–</h2><p>è¯¥è„šæœ¬é™¤äº†pythonåŸºç¡€ä¾èµ–åº“ï¼Œéœ€è¦å®‰è£… <code>requests</code> å’Œ <code>requests_toolbelt</code> ä¸¤ä¸ªåº“ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">pip install requests</span><br><span class="line">pip install requests_toolbelt</span><br></pre></td></tr></tbody></table></figure>
<p>å®‰è£…å®Œæˆåå³å¯æ­£å¸¸ä½¿ç”¨è„šæœ¬</p>
<h2 id="2-ä¸ªäººé…ç½®"><a href="#2-ä¸ªäººé…ç½®" class="headerlink" title="2. ä¸ªäººé…ç½®"></a>2. ä¸ªäººé…ç½®</h2><p>åœ¨ç›®å½•ä¸‹çš„<code>configs.py</code>æ–‡ä»¶é‡Œï¼Œç”¨æˆ·å¯ä»¥å¯¹è‡ªå·±çš„è„šæœ¬è¿›è¡Œé…ç½®ï¼Œä¸‹é¢å¯¹é…ç½®è¿›è¡Œè§£è¯»ï¼š</p>
<h3 id="a-é…ç½®é»˜è®¤ä½¿ç”¨å›¾åºŠ"><a href="#a-é…ç½®é»˜è®¤ä½¿ç”¨å›¾åºŠ" class="headerlink" title="a. é…ç½®é»˜è®¤ä½¿ç”¨å›¾åºŠ"></a>a. é…ç½®é»˜è®¤ä½¿ç”¨å›¾åºŠ</h3><p><img src="https://picx.zhimg.com/v2-dbaa44b516d8fc8934cb1239f57779d0.png" alt="é…ç½®é»˜è®¤ä½¿ç”¨å›¾åºŠ"></p>
<p>åœ¨<code>configs.py</code>æ–‡ä»¶çš„ç¬¬11è¡Œå¯ä»¥é…ç½®é»˜è®¤ä½¿ç”¨çš„å›¾åºŠç½‘ç«™ï¼Œè€Œä½¿ç”¨çš„å›¾åºŠ<strong>å¿…é¡»ä»ä¸‹é¢5ç§ä¸­é€‰æ‹©</strong>ã€‚å¯ä»¥è®¾ç½®ä¸€ç§æˆ–è€…å¤šç§ï¼ŒæŒ‰è¡¨æ ¼æ ·å¼é…ç½®å³å¯ã€‚</p>
<p>è¿™é‡Œæ¨èä½¿ç”¨CSDNï¼Œå› ä¸ºç›®å‰å®æµ‹ä¸éœ€è¦é¢‘ç¹æ›´æ¢cookieï¼Œå¯ä»¥æ¯”è¾ƒç¨³å®šçš„ä½¿ç”¨ã€‚</p>
<h3 id="b-é…ç½®ç™»å½•cookie"><a href="#b-é…ç½®ç™»å½•cookie" class="headerlink" title="b. é…ç½®ç™»å½•cookie"></a>b. é…ç½®ç™»å½•cookie</h3><p>å› ä¸ºä½¿ç”¨çš„å„æœåŠ¡æä¾›å•†å›¾åºŠéœ€è¦ç™»å½•cookieï¼Œæ‰€ä»¥éœ€è¦ç”¨æˆ·è¿›å…¥è‡ªå·±çš„æµè§ˆå™¨æŠ“åŒ…è·å¾—å¯¹åº”å­—æ®µcookieåå¡«å…¥ã€‚</p>
<p>ä¸‹é¢ä»‹ç»å„æµè§ˆå™¨cookieçš„è·å–æ–¹æ³•ï¼š</p>
<h4 id="CSDN"><a href="#CSDN" class="headerlink" title="CSDN"></a>CSDN</h4><p>ç™»å½•è‡ªå·±çš„CSDNï¼Œç„¶åè¿›å…¥ä¸ªäººä¸­å¿ƒ (<a href="https://i.csdn.net/">https://i.csdn.net/</a>)ï¼Œæ‰“å¼€æµè§ˆå™¨çš„å¼€å‘è€…å·¥å…·ï¼ˆchrome é»˜è®¤ <code>ctrl</code>+<code>alt</code>+<code>I</code>ï¼‰ï¼Œæ‰¾åˆ°<code>UserName</code>å’Œ<code>UserToken</code>ï¼Œå°†å¯¹åº”çš„å€¼å¤åˆ¶ã€‚</p>
<p><img src="https://pic1.zhimg.com/v2-10ea2f2f64f2fbbef8e61656dee9c1f6.png" alt="CSDN Cookie"></p>
<p>ç„¶åç²˜è´´åˆ°ç¬¬26è¡Œçš„ <code>csdn_cookies</code>å†…ï¼Œå³å®Œæˆé…ç½®ã€‚</p>
<p><img src="https://pic1.zhimg.com/v2-4a12554481a33bba2f3e3f421a7944b3.png" alt="CSDN Cookie"></p>
<h4 id="çŸ¥ä¹"><a href="#çŸ¥ä¹" class="headerlink" title="çŸ¥ä¹"></a>çŸ¥ä¹</h4><p>ç™»å½•è‡ªå·±çš„çŸ¥ä¹ï¼Œç„¶åè¿›å…¥ä¸»é¡µ (<a href="https://www.zhihu.com/">https://www.zhihu.com/</a>)ï¼Œæ‰“å¼€æµè§ˆå™¨çš„å¼€å‘è€…å·¥å…·ï¼Œæ‰¾åˆ°<code>z_c0</code>ï¼Œå°†å¯¹åº”çš„å€¼å¤åˆ¶ï¼Œç„¶åå¡«å…¥33è¡Œå¯¹åº”çš„<code>zhihu_cookies</code>é‡Œå³å®Œæˆé…ç½®ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-c06388579ca46e0ea942d9292d580878.png" alt="çŸ¥ä¹ Cookie"></p>
<p>çŸ¥ä¹çš„å›¾ç‰‡é»˜è®¤æ”¯æŒ3ç§ï¼Œ<code>src</code>, <code>watermark_src</code>, <code>original_src</code>ï¼Œ<code>watermark_src</code>æ˜¯æ°´å°åŸå›¾ï¼Œ<code>original_src</code>æ˜¯åŸå›¾ï¼Œ<code>src</code>æ˜¯å±•ç¤ºå›¾ï¼Œç”¨æˆ·å¯ä»¥è‡ªå·±é€‰æ‹©ã€‚</p>
<h4 id="bç«™"><a href="#bç«™" class="headerlink" title="bç«™"></a>bç«™</h4><p>ç™»å½•è‡ªå·±çš„bç«™ï¼Œç„¶åè¿›å…¥ä¸»é¡µ (<a href="https://www.bilibili.com/">https://www.bilibili.com/</a>)ï¼Œæ‰“å¼€æµè§ˆå™¨çš„å¼€å‘è€…å·¥å…·ï¼Œæ‰¾åˆ°<code>SESSDATA</code>ï¼Œå°†å¯¹åº”çš„å€¼å¤åˆ¶ï¼Œç„¶åå¡«å…¥41è¡Œå¯¹åº”çš„<code>bili_cookies</code>é‡Œå³å®Œæˆé…ç½®ã€‚</p>
<p><img src="https://pic1.zhimg.com/v2-73f566da43bf13b082b4cc569875bad8.png" alt="Bilibili Cookie"></p>
<h4 id="ç®€ä¹¦"><a href="#ç®€ä¹¦" class="headerlink" title="ç®€ä¹¦"></a>ç®€ä¹¦</h4><p>ç™»å½•è‡ªå·±çš„ç®€ä¹¦ï¼Œç„¶åè¿›å…¥ä¸»é¡µ (<a href="https://www.jianshu.com/">https://www.jianshu.com/</a>)ï¼Œæ‰“å¼€æµè§ˆå™¨çš„å¼€å‘è€…å·¥å…·ï¼Œæ‰¾åˆ°<code>remember_user_token</code>å’Œ<code>_m7e_session_core</code>å­—æ®µï¼Œå°†å¯¹åº”çš„å€¼å¤åˆ¶ï¼Œç„¶åå¡«å…¥47è¡Œå¯¹åº”çš„<code>jianshu_cookies</code>é‡Œå³å®Œæˆé…ç½®ã€‚</p>
<p><img src="https://pic1.zhimg.com/v2-ed43bbd15853b83cfe8b4c7ccd473424.png" alt="ç®€ä¹¦ Cookie"></p>
<h4 id="åšå®¢å›­"><a href="#åšå®¢å›­" class="headerlink" title="åšå®¢å›­"></a>åšå®¢å›­</h4><p>ç™»å½•è‡ªå·±çš„åšå®¢å›­ï¼Œç„¶åè¿›å…¥ä¸»é¡µ (<a href="https://www.cnblogs.com/">https://www.cnblogs.com/</a>)ï¼Œæ‰“å¼€æµè§ˆå™¨çš„å¼€å‘è€…å·¥å…·ï¼Œæ‰¾åˆ°<code>.Cnblogs.AspNetCore.Cookies</code>å­—æ®µï¼Œå°†å¯¹åº”çš„å€¼å¤åˆ¶ï¼Œç„¶åå¡«å…¥53è¡Œå¯¹åº”çš„<code>bokeyuan_cookies</code>é‡Œå³å®Œæˆé…ç½®ã€‚</p>
<p><img src="https://pica.zhimg.com/v2-2ec98121095723e0b63f0dce75441907.png" alt="åšå®¢å›­ Cookie"></p>
<h2 id="3-å‘½ä»¤è¡Œè°ƒç”¨"><a href="#3-å‘½ä»¤è¡Œè°ƒç”¨" class="headerlink" title="3.  å‘½ä»¤è¡Œè°ƒç”¨"></a>3.  å‘½ä»¤è¡Œè°ƒç”¨</h2><p>è„šæœ¬çš„ä½¿ç”¨æ–¹æ³•ä¸ºï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">python convert.py</span><br></pre></td></tr></tbody></table></figure>
<p>ä½¿ç”¨è¯¥å‘½ä»¤åï¼Œé»˜è®¤è¯»å–å½“å‰è„šæœ¬æ‰€å¤„ç›®å½•ä¸‹çš„æ‰€æœ‰mdæ–‡ä»¶ï¼Œå¹¶é€ä¸ªè¯»å–æ‰«æå›¾ç‰‡é“¾æ¥æˆ–æœ¬åœ°è·¯å¾„ï¼ŒæŒ‰ç…§é…ç½®é‡ŒæŒ‡å®šçš„è½¬æ¢æ–¹å¼ï¼Œè½¬æ¢åå†è¾“å‡ºä¸º{New<em>(mode)</em>(åŸå§‹å)}ã€‚</p>
<p><img src="https://pica.zhimg.com/v2-d85a797b22394c79616e1645f70047a1.png" alt="ä½¿ç”¨å‘½ä»¤è¡Œ"></p>
<p>å¦‚æœéœ€è¦æŒ‡å®šè½¬åŒ–çš„æ–‡ä»¶ï¼Œä½¿ç”¨å‘½ä»¤ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">python convert.py -f new.md</span><br></pre></td></tr></tbody></table></figure>
<p>è€Œå¦‚æœä¸é€‚ç”¨é»˜è®¤çš„è½¬æ¢å›¾åºŠï¼Œéœ€è¦é¢å¤–æŒ‡å®šè½¬æ¢å›¾åºŠï¼Œä½¿ç”¨å‘½ä»¤ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">python convert.py -m csdn</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™ä¸¤ä¸ªå‚æ•°å¯ä»¥åŒæ—¶æŒ‡å®šï¼Œè½¬æ¢æ•ˆæœå¦‚ä¸‹ï¼š</p>
<p><img src="https://pic1.zhimg.com/v2-56e84953380c8dc11ee8a329c3bc1f5e.png" alt="æŒ‡å®šå‚æ•°"></p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Note</tag>
        <tag>Tool</tag>
      </tags>
  </entry>
  <entry>
    <title>Tailscaleï¼šéšæ—¶éšåœ°è¿œç¨‹å’Œä½¿ç”¨æœåŠ¡å™¨</title>
    <url>/2024/01/03/Note/Taiscale/</url>
    <content><![CDATA[<h2 id="Tailscaleæ˜¯ä»€ä¹ˆï¼Ÿ"><a href="#Tailscaleæ˜¯ä»€ä¹ˆï¼Ÿ" class="headerlink" title="Tailscaleæ˜¯ä»€ä¹ˆï¼Ÿ"></a>Tailscaleæ˜¯ä»€ä¹ˆï¼Ÿ</h2><p>ç½‘ä¸Šæœ‰æ—¶å€™æåˆ°tailscaleï¼Œæ€»æ˜¯ä»‹ç»å¥½å¤šï¼Œæ¯”å¦‚ä»¥ä¸‹ä»‹ç»ï¼Œä½†æ˜¯å¤ªå®˜æ–¹äº†</p>
<blockquote>
<p>Tailscale æ˜¯ä¸€ç§åŸºäº WireGuard çš„è™šæ‹Ÿç»„ç½‘å·¥å…·ï¼Œå’Œ Netmaker ç±»ä¼¼ï¼Œ<strong>æœ€å¤§çš„åŒºåˆ«åœ¨äº Tailscale æ˜¯åœ¨ç”¨æˆ·æ€å®ç°äº† WireGuard åè®®ï¼Œè€Œ Netmaker ç›´æ¥ä½¿ç”¨äº†å†…æ ¸æ€çš„ WireGuard</strong>ã€‚</p>
</blockquote>
<p>è¿™é‡Œé¢ç®€å•ä»‹ç»ä¸€ä¸‹ï¼Œå®é™…ä¸ŠTailscaleå±äºä¸€ç§è™šæ‹Ÿç»„ç½‘å·¥å…·ï¼ŒåŸºäºWireGuardã€‚ç®€å•æ¥è¯´ä»–èƒ½å¸®åŠ©æˆ‘ä»¬æŠŠå®‰è£…äº†TailscaleæœåŠ¡çš„æœºå™¨ï¼Œéƒ½æ”¾åˆ°åŒä¸€ä¸ªå±€åŸŸç½‘ã€‚æ¯”å¦‚æˆ‘ä»¬çš„NASæˆ–è€…PCï¼Œæˆ–è€…åœ¨å…¶ä»–åœ°æ–¹çš„NASå’ŒPCï¼Œç”šè‡³äº‘æœåŠ¡å™¨éƒ½èƒ½æ”¾åˆ°åŒä¸€ä¸ªå±€åŸŸç½‘ã€‚è¿™æ ·å°±å®ç°äº†ä¸€ä¸ªå†…ç½‘ç©¿é€ï¼Œæœ‰æ—¶å€™æˆ‘ä»¬å°±å¯ä»¥éšæ—¶éšåœ°è¿œç¨‹å’Œä½¿ç”¨æˆ‘ä»¬çš„æœåŠ¡å™¨ã€‚</p>
<h2 id="Tailscaleèƒ½åšä»€ä¹ˆï¼Ÿ"><a href="#Tailscaleèƒ½åšä»€ä¹ˆï¼Ÿ" class="headerlink" title="Tailscaleèƒ½åšä»€ä¹ˆï¼Ÿ"></a><strong>Tailscaleèƒ½åšä»€ä¹ˆï¼Ÿ</strong></h2><p>åªéœ€å°†ä½ çš„è®¾å¤‡è¿æ¥åˆ°å…¬ç½‘ï¼ŒTailscaleå°±èƒ½è®©æ‰€æœ‰è®¾å¤‡åŠ å…¥åŒä¸€ä¸ªç§æœ‰å­ç½‘ã€‚è¿™æ„å‘³ç€ï¼Œæ— è®ºä½ èº«åœ¨ä½•å¤„ï¼Œéƒ½å¯ä»¥è½»æ¾å®ç°è®¾å¤‡é—´çš„è¿æ¥ï¼Œå°±åƒå®ƒä»¬åœ¨åŒä¸€ä¸ªå±€åŸŸç½‘ä¸­ä¸€æ ·ã€‚</p>
<p>ä¸¾ä¸ªä¾‹å­ï¼Œæˆ‘çš„å°å¼æœºå’Œç¬”è®°æœ¬éƒ½ç™»å½•äº†ç›¸åŒçš„Tailscaleè´¦å·ï¼Œå®ƒä»¬å…±äº«ä¸€ä¸ª100.64/10çš„å­ç½‘ï¼Œå¯ä»¥æ–¹ä¾¿åœ°äº’è”ã€‚å³ä½¿æˆ‘çš„ç¬”è®°æœ¬åœ¨å…¬å¸å†…ç½‘ï¼Œæ— æ³•ç›´æ¥è¿æ¥åˆ°å®¶é‡Œçš„å°å¼æœºï¼Œé€šè¿‡Tailscaleçš„relayåŠŸèƒ½ï¼Œå®ƒä»¬ä¾ç„¶èƒ½å¤Ÿç›´æ¥è¿æ¥ï¼Œå®ç°ç•…é€šæ— é˜»çš„é€šä¿¡ã€‚</p>
<h3 id="1ã€ä¼ è¾“æ–‡ä»¶"><a href="#1ã€ä¼ è¾“æ–‡ä»¶" class="headerlink" title="1ã€ä¼ è¾“æ–‡ä»¶"></a><strong>1ã€ä¼ è¾“æ–‡ä»¶</strong></h3><p>Tailscaleå†…ç½®äº†taildropï¼Œå¯ç”¨äºè®¾å¤‡ä¹‹é—´çš„æ–‡ä»¶ä¼ è¾“ã€‚ç”±äºTailscaleæ”¯æŒandroid/ios/mac/windows/linuxï¼Œå› æ­¤å®ƒä¹Ÿæ˜¯ä¸€ä¸ªè·¨å¹³å°æ–‡ä»¶ä¼ è¾“å·¥å…·ã€‚å¦‚æœè®¾å¤‡åœ¨åŒä¸€å±€åŸŸç½‘å†…ï¼Œä¼ è¾“é€Ÿåº¦å°†éå¸¸å¿«é€Ÿã€‚</p>
<h3 id="2ã€è¿œç¨‹å¼€å‘"><a href="#2ã€è¿œç¨‹å¼€å‘" class="headerlink" title="2ã€è¿œç¨‹å¼€å‘"></a><strong>2ã€è¿œç¨‹å¼€å‘</strong></h3><p>ä¸¾ä¾‹æ¥è¯´ï¼Œå¦‚æœæˆ‘çš„å°å¼ç”µè„‘è¿è¡ŒWindowsç³»ç»Ÿï¼Œæˆ‘å¯ä»¥å¯åŠ¨WSL2ï¼Œå®‰è£…SSHDï¼Œç›¸å½“äºå°†å®ƒå˜æˆä¸€ä¸ªæœåŠ¡å™¨ã€‚è¿™æ ·ï¼Œæ— è®ºæˆ‘èº«åœ¨ä½•å¤„ï¼Œéƒ½å¯ä»¥é€šè¿‡ç¬”è®°æœ¬ä¸Šçš„VSCode Remote SSHéšæ—¶æ‰“å¼€å°å¼æœºä¸Šçš„VSCode Serverï¼Œå®ç°è¿œç¨‹å¼€å‘ã€‚</p>
<p>å¯¹æˆ‘è€Œè¨€ï¼Œç§»åŠ¨åŠå…¬çš„çœŸè°›ä¸åœ¨äºéšèº«æºå¸¦ä¸€å°ç¬”è®°æœ¬ï¼Œè€Œæ˜¯åœ¨ä»»ä½•åœ°æ–¹åªè¦æœ‰ç½‘ç»œï¼Œå°±èƒ½ä½¿ç”¨ä»»ä½•è®¾å¤‡æ¥å…¥ç»Ÿä¸€çš„åŠå…¬ç¯å¢ƒã€‚</p>
<h3 id="3ã€ä»£ç†"><a href="#3ã€ä»£ç†" class="headerlink" title="3ã€ä»£ç†"></a><strong>3ã€ä»£ç†</strong></h3><p>å…·ä½“å¯å‚è€ƒï¼Œè¿™é‡Œä¸ä¸»è¦ä»‹ç»ï¼Œ<a href="https://github.com/nadoo/glider">https://github.com/nadoo/glider</a></p>
<h2 id="Tailscaleæ€ä¹ˆç”¨ï¼Ÿ"><a href="#Tailscaleæ€ä¹ˆç”¨ï¼Ÿ" class="headerlink" title="Tailscaleæ€ä¹ˆç”¨ï¼Ÿ"></a><strong>Tailscaleæ€ä¹ˆç”¨ï¼Ÿ</strong></h2><p>å‚ç…§è¿™ä¸ªå®˜æ–¹é¡µé¢å®‰è£…ï¼Œç„¶åç™»å½•å³å¯ï¼š<a href="https://tailscale.com/download">https://tailscale.com/download</a></p>
<p><img src="https://picx.zhimg.com/v2-0f0f761a65f56a0818e53fdef6592e11.png" alt="Tailscaleå®˜ç½‘"></p>
<p>å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸€æ—¦ç™»å½•ï¼Œæ¯å°è®¾å¤‡éƒ½ä¼šè¢«åˆ†é…ä¸€ä¸ªå¯¹åº”çš„IPåœ°å€ã€‚æ­¤æ—¶ï¼Œæ‰€æœ‰è®¾å¤‡å®é™…ä¸Šéƒ½åœ¨åŒä¸€ä¸ªå±€åŸŸç½‘å†…ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å¯ä»¥å¯åŠ¨è®¾å¤‡çš„SSHåŠŸèƒ½ã€‚æ— è®ºèº«åœ¨ä½•å¤„ï¼Œåªéœ€ä½¿ç”¨åˆ†é…ç»™è®¾å¤‡çš„IPåœ°å€ï¼Œå°±èƒ½è¿æ¥åˆ°è¯¥è®¾å¤‡ï¼Œä»è€Œå®ç°è¿œç¨‹åŠå…¬çš„åŠŸèƒ½ï¼Œä¾‹å¦‚è¿æ¥åˆ°æœåŠ¡å™¨ç­‰ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-5c27422f68e185584f24f59621ae1ebf.png" alt="è®¾å¤‡"></p>
<h2 id="Windowsä¸‹å®‰è£…OpenSSH"><a href="#Windowsä¸‹å®‰è£…OpenSSH" class="headerlink" title="Windowsä¸‹å®‰è£…OpenSSH"></a><strong>Windowsä¸‹å®‰è£…OpenSSH</strong></h2><p>OpenSSH æ˜¯ SSH ï¼ˆSecure SHellï¼‰ åè®®çš„å…è´¹å¼€æºå®ç°ã€‚OpenSSHæä¾›äº†æœåŠ¡ç«¯åå°ç¨‹åºå’Œå®¢æˆ·ç«¯å·¥å…·ï¼Œç”¨æ¥åŠ å¯†è¿œç¨‹æ§åˆ¶å’Œæ–‡ä»¶ä¼ è¾“è¿‡ç¨‹ä¸­çš„æ•°æ®ã€‚å®‰è£…ä»¥åï¼Œæˆ‘ä»¬å°±å¯ä»¥æŠŠæˆ‘ä»¬çš„ç”µè„‘ä½œä¸ºä¸€å°æœåŠ¡å™¨è¿›è¡Œé“¾æ¥ï¼Œè¿™æ ·å°±æˆåŠŸå¯ä»¥éšæ—¶éšåœ°è¿›è¡Œè¿œç¨‹è¿æ¥äº†ã€‚</p>
<h3 id="åœ¨çº¿å®‰è£…"><a href="#åœ¨çº¿å®‰è£…" class="headerlink" title="åœ¨çº¿å®‰è£…"></a><strong>åœ¨çº¿å®‰è£…</strong></h3><p>ä¸€èˆ¬windowsè‡ªå¸¦SSH serverï¼Œç›´æ¥å¯åŠ¨å³å¯</p>
<p>å¼€å¯æ–¹æ³•ï¼š å®‰è£…openssh</p>
<p>è®¾ç½®-åº”ç”¨-åº”ç”¨å’ŒåŠŸèƒ½-å¯é€‰åŠŸèƒ½-æ·»åŠ åŠŸèƒ½</p>
<p>å®‰è£…OpenSSHæœåŠ¡å™¨å³å¯</p>
<p><img src="https://picx.zhimg.com/v2-aeb2d713f14ed7cf9c25f2340190a631.webp" alt="å®‰è£…SSHæ­¥éª¤1"></p>
<p>è®¿é—®å¯é€‰åŠŸèƒ½å±å¹•ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-f94b788ac25b51a54a85bf0074d81941.webp" alt="å®‰è£…SSHæ­¥éª¤2"></p>
<p>é€‰æ‹©æ·»åŠ è¦ç´ çš„é€‰é¡¹ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-15d13a44cccd6e77e83d833b5ca28b7e.webp" alt="å®‰è£…SSHæ­¥éª¤3"></p>
<p>é€‰æ‹© SSH æœåŠ¡å™¨åŒ…ï¼Œç„¶åå•å‡»â€å®‰è£…â€æŒ‰é’®ã€‚</p>
<p><img src="https://pic1.zhimg.com/v2-7087d6f462dc72d88429d3825ac9f160.webp" alt="å®‰è£…SSHæ­¥éª¤4"></p>
<p>ç­‰å¾… Openssh æœåŠ¡å™¨å®‰è£…å®Œæˆã€‚</p>
<p><img src="https://pica.zhimg.com/v2-cf48691afcf3e5e8340c490e46d59c94.webp" alt="å®‰è£…SSHæ­¥éª¤5"></p>
<p>ä½œä¸ºç®¡ç†å‘˜ï¼Œå¯åŠ¨ Powershell å‘½ä»¤è¡Œçš„æå‡ç‰ˆæœ¬ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-967a457fd357ab32cd55c5440953af9a.webp" alt="å®‰è£…SSHæ­¥éª¤6"></p>
<p>å°† SSH æœåŠ¡é…ç½®ä¸ºè‡ªåŠ¨å¯åŠ¨ã€‚</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">sc config sshd start=auto</span><br></pre></td></tr></tbody></table></figure>
<p>å¯åŠ¨ SSH æœåŠ¡ã€‚</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">net start sshd</span><br></pre></td></tr></tbody></table></figure>
<p>åˆ›å»ºé˜²ç«å¢™è§„åˆ™ä»¥å…è®¸åœ¨ SSH ç«¯å£ä¸Šè¾“å…¥æ•°æ®åŒ…ã€‚</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">netsh advfirewall firewall add rule name="SSH PORT 22" dir=in action=allow protocol=TCP localport=22</span><br></pre></td></tr></tbody></table></figure>
<p>ç¥è´ºï¼ æ‚¨å·²å®Œæˆåœ¨ Windows ä¸Šå®‰è£… SSH æœåŠ¡å™¨ã€‚</p>
<h3 id="ç¦»çº¿å®‰è£…"><a href="#ç¦»çº¿å®‰è£…" class="headerlink" title="ç¦»çº¿å®‰è£…"></a><strong>ç¦»çº¿å®‰è£…</strong></h3><p>ä¸‹è½½æœ€æ–°ç‰ˆæœ¬ <a href="https://github.com/PowerShell/Win32-OpenSSH/releases">é€‚ç”¨äºWindowsäºŒè¿›åˆ¶æ–‡ä»¶çš„OpenSSH</a> ï¼ˆåŒ…OpenSSH-Win64.zipæˆ–OpenSSH-Win32.zipï¼‰</p>
<p>å»ºè®®ç›´æ¥ä¸‹è½½msi å³å¯ï¼Œè‡ªåŠ¨å®‰è£…ä»¥åå°±å¯ä»¥æŒ‰ç…§ä¸Šè¿°æ–¹æ³•è¿›è¡Œå¯åŠ¨sshæœåŠ¡äº†</p>
<h2 id="è¿æ¥SSHæœåŠ¡å™¨"><a href="#è¿æ¥SSHæœåŠ¡å™¨" class="headerlink" title="è¿æ¥SSHæœåŠ¡å™¨"></a><strong>è¿æ¥SSHæœåŠ¡å™¨</strong></h2><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨å¸¸è§„çš„SSHçš„æ–¹å¼æ¥è¿æ¥æˆ‘ä»¬é…ç½®å¥½çš„windowsäº†ï¼Œæˆ‘ä»¬åªéœ€è¦æ‰¾åˆ°å¯¹åº”çš„IPåœ°å€ï¼Œå¯¹å…¶è¿›è¡Œsshè¿æ¥å³å¯ã€‚</p>
<p>è¿™é‡Œä¸€å®šè¦æ³¨æ„ï¼Œ<strong>å¯†ç æ˜¯ä½ å¾®è½¯è´¦æˆ·çš„å¯†ç </strong>ã€‚</p>
<p>è¿æ¥æˆåŠŸåå³å¯è¿œç¨‹åŠå…¬äº†ï¼Œæ¯”å¦‚æˆ‘åœ¨å®¶é‡Œï¼Œæˆ‘ä»¬å¯ä»¥è®¾ç½®å…¬å¸çš„ç”µè„‘çš„sshï¼Œåç»­æˆ‘ä»¬å°±å¯ä»¥è¿æ¥å…¬å¸çš„ç”µè„‘åå¯¹å…¶è¿›è¡Œæ“ä½œï¼Œè¿™æ ·å°±æ¯”è¾ƒçš„æ–¹ä¾¿ï¼Œå½“ç„¶ï¼Œä¹Ÿå¯ä»¥å¯¹å…¶è¿›è¡Œè¿œç¨‹ï¼Œæ¯”å¦‚todeskç­‰è¿œç¨‹å·¥å…·ï¼Œè¿™ä¸ªå¯ä»¥è§ä»è§æ™ºï¼Œæˆ‘è§‰å¾—éƒ½å¯ä»¥ï¼Œæœ‰æ—¶å€™æˆ‘åªä½¿ç”¨ç»ˆç«¯ï¼Œæˆ‘è§‰å¾—éƒ½è¿˜å¥½ã€‚</p>
<p>å‚è€ƒ</p>
<p><a href="https://blog.laisky.com/p/tailscale/">Laiskyâ€™s Blog</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/452890363">å°è¾£æ¤’é«˜æ•ˆOfficeï¼šWindowsç³»ç»Ÿå¼€å¯Ssh ServeræœåŠ¡</a></p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>VS Code Server ç¦»çº¿å®‰è£…ï¼ˆè§£å†³è¶…æ—¶ï¼ŒXHR Failedç­‰é—®é¢˜ï¼‰</title>
    <url>/2023/12/13/Note/Vscode/</url>
    <content><![CDATA[<p>åœ¨è®¾ç½®è¿œç¨‹å¼€å‘ç¯å¢ƒæ—¶,æˆ‘ä»¬é¦–å…ˆéœ€è¦è·å–å¹¶å®‰è£… VS Code Server ç¨‹åºã€‚ç”±äºä¸åŒçš„æœåŠ¡å™¨ç‰ˆæœ¬å’Œç¯å¢ƒ,ä¸ä¸€å®šä¼šäº‹å…ˆé¢„è£… VS Code Server,é‚£ä¹ˆæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨è¿›è¡Œä¸‹è½½å®‰è£…ã€‚æœ‰æ—¶å€™å®‰è£ç­‰åŠå¤©ï¼Œæœ‰æ—¶å€™è¿˜æŠ¥é”™ï¼Œä¸ºäº†é˜²æ­¢è¿™æ ·çš„æƒ…å†µï¼Œæˆ‘è¿˜æ˜¯è®°å½•ä¸€ä¸‹è§£å†³æ–¹æ³•ï¼Œå…å¾—æ¯æ¬¡éƒ½éœ€è¦æ‰¾å¥½å¤šèµ„æ–™ï¼Œä½†æ˜¯æ‰¾ä¸åˆ°ä¸€ä¸ªå¾ˆæœ‰æ•ˆçš„ã€‚</p>
<p>å¦‚æœæœåŠ¡å™¨æ˜¯è¿æ¥å¤–ç½‘çš„ï¼Œå°±æ ¹æœ¬ä¸ç”¨æœ‰è¿™ä¸ªçƒ¦æ¼ï¼Œå› ä¸ºä¸‹è½½å¾ˆå¿«ï¼Œæœ‰æ—¶å€™ä¸»è¦æ˜¯å› ä¸ºç¦»çº¿å®‰è£…</p>
<p>è¿™é‡Œæˆ‘å°±ä»‹ç»ä¸€ç§æ–¹æ³•ï¼Œæˆ‘è§‰å¾—æœ€æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå…¶ä»–å¯èƒ½å¤ªéº»çƒ¦è€Œä¸”ä¸ä¸€å®šæœ‰æ•ˆ</p>
<p>å…·ä½“æ“ä½œå¦‚ä¸‹:</p>
<p>é¦–å…ˆ,æˆ‘ä»¬éœ€è¦åˆ° VS Code çš„ä¸‹è½½é¡µé¢è·å–æœ€æ–°çš„ç‰ˆæœ¬å·,è®°ä¸º Commit IDã€‚</p>
<p><img src="https://picx.zhimg.com/80/v2-2f652a6b456e4cef18c01ca60b83d8d1_720w.png?source=d16d100b" alt="è·å–Commit ID"></p>
<blockquote>
<p>é™¤æ­¤ä¹‹å¤–ï¼Œä¹Ÿå¯ä»¥ç›´æ¥åœ¨vscodeå·¦ä¸Šè§’çš„å¸®åŠ©æŸ¥çœ‹ç‰ˆæœ¬ï¼Œå¦‚ï¼š</p>
</blockquote>
<p><img src="https://pic1.zhimg.com/80/v2-43da35aeeb56fa0c8c3e9d4eeb39f7d5_720w.png?source=d16d100b" alt="æŸ¥çœ‹å¯¹åº”çš„ç‰ˆæœ¬"></p>
<p>è®¿é—®æ­¤åœ°å€ <strong><a href="https://update.code.visualstudio.com/commit:${commit_id}/server-linux-x64/stable">https://update.code.visualstudio.com/commit:${commit_id}/server-linux-x64/stable</a></strong>ï¼Œå…¶ä¸­éœ€è¦ç”¨å®é™…çš„ Commit ID æ›¿æ¢ <strong>${commit_id}</strong> å˜é‡å­—æ®µã€‚</p>
<p>æ¯”å¦‚æˆ‘è¿™é‡Œå°±æ˜¯ <a href="https://vscode.download.prss.microsoft.com/dbazure/download/stable/af28b32d7e553898b2a91af498b1fb666fdebe0c/vscode-server-linux-x64.tar.gz">https://vscode.download.prss.microsoft.com/dbazure/download/stable/af28b32d7e553898b2a91af498b1fb666fdebe0c/vscode-server-linux-x64.tar.gz</a></p>
<p>è¿™ä¸ªåœ°å€å°†ä¼šè¿”å›å¯¹åº”çš„ VS Code Server ç¨‹åºå‹ç¼©åŒ… vscode-server-linux-x64.tar.gzã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ wget æˆ–å…¶ä»–æ–¹å¼ä¸‹è½½è¯¥æ–‡ä»¶ï¼Œæ¯”å¦‚è¿™é‡Œå°±æ˜¯</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">wget https://update.code.visualstudio.com/commit:af28b32d7e553898b2a91af498b1fb666fdebe0c/server-linux-x64/stable</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸‹è½½å®Œæˆå,éœ€è¦è§£å‹å¹¶å®‰è£…è¯¥ç¨‹åºã€‚ç”±äºè§„èŒƒæ€§è€ƒè™‘ï¼Œæˆ‘ä»¬é€šå¸¸å°† VS Code ç›®å½•æ”¾åœ¨ ~/.vscode-server ä¸‹:</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p ~/.vscode-server/bin <span class="comment"># åˆ›å»ºç›®å½•</span></span><br><span class="line"><span class="built_in">rm</span> -rf ~/.vscode-server/bin/* <span class="comment">#æ¸…ç©ºåŸæœ‰æ–‡ä»¶</span></span><br><span class="line">tar -zxf vscode-server-linux-x64.tar.gz <span class="comment"># è§£å‹ç¨‹åºåŒ…</span></span><br><span class="line"><span class="built_in">mv</span> vscode-server-linux-x64  ~/.vscode-server/bin/<span class="variable">${commit_id}</span> <span class="comment"># ç§»åŠ¨å¹¶é‡å‘½åç¨‹åº</span></span><br></pre></td></tr></tbody></table></figure>
<p>æœ€åä¸€æ­¥å°±æ˜¯æŠŠ <code>vscode-server-linux-x64.tar.gz</code> è§£å‹ï¼Œå…¶ä¸­çš„å†…å®¹å…¨éƒ¨æ”¾åˆ°<code>af28b32d7e553898b2a91af498b1fb666fdebe0c</code>æ–‡ä»¶å¤¹ä¸‹ï¼Œå¹¶ä¿æŒ<code>af28b32d7e553898b2a91af498b1fb666fdebe0c</code>æ–‡ä»¶å¤¹ä¸‹åªæœ‰<code>vscode-server-linux-x64.tar.gz</code>è§£å‹å‡ºæ¥çš„æ–‡ä»¶ã€‚</p>
<p><img src="https://pica.zhimg.com/80/v2-ea940b665332a810245ea0e4096a2362_720w.png?source=d16d100b" alt="æœ€åç»“æœ"></p>
<p>å®Œæˆä¸Šè¿°æ­¥éª¤å,VS Code Server å°±æˆåŠŸä¸‹è½½å’Œå®‰è£…äº†ã€‚</p>
<p>å¦å¤–,ä¸ºäº†åœ¨å¤šä¸ªæœåŠ¡å™¨ä¹‹é—´åŒæ­¥è®¾ç½®å’Œæ‰©å±•,æˆ‘ä»¬ä¹Ÿå¯ä»¥å°†ä¸€ä¸ªæœåŠ¡å™¨çš„ ~/.vscode-server/extensions ç›®å½•ç›´æ¥å¤åˆ¶è¿‡å»,ä»¥å®ç°å¿«é€Ÿé…ç½®ï¼Œå› ä¸ºåªè¦æ˜¯åŒä¸€ä¸ªVScodeï¼Œç‰ˆæœ¬æ˜¯ä¸€æ¨¡ä¸€æ ·çš„</p>
<p>å‚è€ƒé“¾æ¥ï¼š<a href="https://blog.csdn.net/m0_43609475/article/details/120905157">ç¦»çº¿åœ¨è¿œç¨‹linuxæœåŠ¡å™¨é…ç½®vscode-pythonç¯å¢ƒä»¥åŠåœ¨å®¹å™¨ä¸­é…ç½®_æ²¡ç½‘çš„æœåŠ¡å™¨vscodeè°ƒè¯•å®¹å™¨-</a></p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Note</tag>
        <tag>Tool</tag>
      </tags>
  </entry>
  <entry>
    <title>Arxivå­¦æœ¯è®ºæ–‡æŸ¥è¯¢æ¥å£è¯¦è§£</title>
    <url>/2024/01/24/Note/arXiv/</url>
    <content><![CDATA[<h1 id="Arxivå­¦æœ¯è®ºæ–‡æŸ¥è¯¢æ¥å£è¯¦è§£-è½¬è½½"><a href="#Arxivå­¦æœ¯è®ºæ–‡æŸ¥è¯¢æ¥å£è¯¦è§£-è½¬è½½" class="headerlink" title="Arxivå­¦æœ¯è®ºæ–‡æŸ¥è¯¢æ¥å£è¯¦è§£ è½¬è½½"></a>Arxivå­¦æœ¯è®ºæ–‡æŸ¥è¯¢æ¥å£è¯¦è§£ è½¬è½½</h1><blockquote>
<p>è¿™ç¯‡åšå®¢ä¸»è¦è½¬è½½è‡ªï¼š<a href="https://hiyoungai.com/posts/arxiv%E5%AD%A6%E6%9C%AF%E8%AE%BA%E6%96%87%E6%9F%A5%E8%AF%A2%E6%8E%A5%E5%8F%A3%E8%AF%A6%E8%A7%A3/">Arxivå­¦æœ¯è®ºæ–‡æŸ¥è¯¢æ¥å£è¯¦è§£</a>ï¼Œæˆ‘è§‰å¾—å†™çš„å¾ˆå¥½ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿä¸é‡æ–°æ•´ç†è¿™ä¸€éƒ¨åˆ†çš„APIæ¥å£äº†ã€‚æˆ‘åç»­ä½¿ç”¨è¿™ä¸€éƒ¨åˆ†çš„APIæ¥å£æ¥è¿›è¡Œçˆ¬å–å¾—åˆ°æœ€æ–°çš„æ–‡ç« ï¼Œè¿˜æ˜¯éå¸¸æ–¹ä¾¿çš„ï¼Œæ‰€ä»¥ä¹ŸåŒæ—¶æ¨èç»™å¤§å®¶ï¼Œèƒ½æœ€å¿«followæ–°æ–‡ç« </p>
</blockquote>
<p>Arxiv API å…è®¸ä»¥ç¼–ç¨‹æ–¹å¼è·å– <a href="https://arxiv.org/">https://arxiv.org</a> ä¸Šçš„è®ºæ–‡ã€‚API çš„åŸºæœ¬ç»“æ„ä¸ºï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">http://export.arxiv.org/api/{method_name}?{parameters}</span><br></pre></td></tr></tbody></table></figure>
<h2 id="æŸ¥è¯¢æ¥å£"><a href="#æŸ¥è¯¢æ¥å£" class="headerlink" title="æŸ¥è¯¢æ¥å£"></a>æŸ¥è¯¢æ¥å£</h2><p>æŸ¥è¯¢æ¥å£çš„çš„ method_name ä¸º queryï¼Œä¸‹é¢æ˜¯æŸ¥è¯¢æ–¹æ³•çš„å‚æ•°ï¼Œå‚æ•°ä¹‹é—´ä»¥ <em>&amp;</em> åˆ†éš”ã€‚</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">parameters</th>
<th style="text-align:center">type</th>
<th style="text-align:center">defaults</th>
<th style="text-align:center">required</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">search_query</td>
<td style="text-align:center">string</td>
<td style="text-align:center">None</td>
<td style="text-align:center">No</td>
</tr>
<tr>
<td style="text-align:center">id_list</td>
<td style="text-align:center">comma-delimited stringï¼ˆä»¥ â€˜ï¼Œâ€™ åˆ†éš”çš„å­—ç¬¦ä¸²ï¼‰</td>
<td style="text-align:center">None</td>
<td style="text-align:center">No</td>
</tr>
<tr>
<td style="text-align:center">start</td>
<td style="text-align:center">int</td>
<td style="text-align:center">0</td>
<td style="text-align:center">No</td>
</tr>
<tr>
<td style="text-align:center">max_results</td>
<td style="text-align:center">int</td>
<td style="text-align:center">10</td>
<td style="text-align:center">No</td>
</tr>
</tbody>
</table>
</div>
<h3 id="å‚æ•°è¯´æ˜"><a href="#å‚æ•°è¯´æ˜" class="headerlink" title="å‚æ•°è¯´æ˜"></a>å‚æ•°è¯´æ˜</h3><ul>
<li>å¦‚æœ API åªåŒ…å« search_queryï¼ˆä¸åŒ…å« id_listï¼‰ï¼Œé‚£ä¹ˆè¿”å›ä¸ search_query å†…å®¹åŒ¹é…çš„ç»“æœã€‚</li>
<li>å¦‚æœ API åªåŒ…å« id_listï¼ˆä¸åŒ…å« search_queryï¼‰ï¼Œé‚£ä¹ˆè¿”å› id_list ä¸­æ¯ä¸€é¡¹çš„ç»“æœã€‚</li>
<li>å¦‚æœ API ä¸­åŒ…å«äº† search_query å’Œ id_listï¼Œé‚£ä¹ˆè¿”å›åœ¨ id_list ä¸­ï¼Œå¹¶ä¸”ä¸ search_query åŒ¹é…çš„æ–‡ç« ã€‚</li>
</ul>
<h3 id="åˆ†é¡µæŸ¥è¯¢"><a href="#åˆ†é¡µæŸ¥è¯¢" class="headerlink" title="åˆ†é¡µæŸ¥è¯¢"></a>åˆ†é¡µæŸ¥è¯¢</h3><p>é€šå¸¸æƒ…å†µä¸‹ï¼Œä¸€ä¸ªæŸ¥è¯¢å¯èƒ½æœ‰æˆç™¾ä¸Šåƒä¸ªè¿”å›ç»“æœã€‚æœ‰æ—¶å€™æˆ‘ä»¬ä¸å¸Œæœ›ä¸€æ¬¡æ€§æŸ¥è¯¢åˆ°è¿™ä¹ˆå¤šæ•°é‡ï¼Œé‚£ä¹ˆå¯ä»¥ä½¿ç”¨ <em>start</em> å’Œ <em>max_results</em> ä¸¤ä¸ªå­—æ®µæ¥è¿›è¡Œåˆ†é¡µæŸ¥è¯¢ã€‚</p>
<ul>
<li>start æ˜¯æŸ¥è¯¢çš„èµ·å§‹ç´¢å¼•ï¼Œä»¥ 0 ä¸ºç¬¬ä¸€ä¸ªã€‚</li>
<li>max_results æ˜¯æŸ¥è¯¢è¿”å›çš„é›†åˆæ•°ã€‚</li>
</ul>
<p>ä¸‹é¢æ¥ä¸¾ä¾‹è¯´æ˜ä¸€ä¸‹ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">http://export.arxiv.org/api/query?search_query=all:electron&amp;start=0&amp;max_results=10 (1)</span><br><span class="line">http://export.arxiv.org/api/query?search_query=all:electron&amp;start=10&amp;max_results=10 (2)</span><br><span class="line">http://export.arxiv.org/api/query?search_query=all:electron&amp;start=20&amp;max_results=10 (3)</span><br></pre></td></tr></tbody></table></figure>
<p>æŸ¥è¯¢ç»“æœåˆ†åˆ«ä¸ºï¼š</p>
<ol>
<li>0 - 9</li>
<li>10 - 19</li>
<li>20 - 29</li>
</ol>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç”±äº API çš„é™åˆ¶ï¼Œåœ¨å¤šæ¬¡è°ƒç”¨ API çš„æƒ…å†µä¸‹ï¼Œå»ºè®®æ¯æ¬¡è°ƒç”¨çš„æ—¶é—´é—´éš”ä¸º 3 ç§’ã€‚æ¯æ¬¡è°ƒç”¨è¿”å›çš„æœ€å¤§æ•°é‡ä¸º 2000 ä¸ªã€‚arXivçš„ç¡¬é™åˆ¶çº¦ä¸º 50,000 æ¡è®°å½•ï¼› å¯¹äºä¸ 50,000 å¤šä¸ªåŸç¨¿åŒ¹é…çš„æŸ¥è¯¢ï¼Œæ— æ³•æ¥æ”¶å…¨éƒ¨ç»“æœ. è§£å†³è¿™ä¸ªé—®é¢˜çš„æœ€ç®€å•çš„è§£å†³æ–¹æ¡ˆæ˜¯å°†ä¸­æ–­æŸ¥è¯¢æˆå°å—ï¼Œä¾‹å¦‚ä½¿ç”¨çš„æ—¶é—´ç‰‡ï¼Œä¸ä¸€ç³»åˆ—æ—¥æœŸçš„<code>submittedDate</code>æˆ–<code>lastUpdatedDate</code> ã€‚</p>
<h3 id="æ’åºæŸ¥è¯¢"><a href="#æ’åºæŸ¥è¯¢" class="headerlink" title="æ’åºæŸ¥è¯¢"></a>æ’åºæŸ¥è¯¢</h3><p>å¯¹æŸ¥è¯¢çš„ç»“æœè¿›è¡Œæ’åºæœ‰ä¸¤ä¸ªé€‰é¡¹ï¼š<em>sortBy</em> å’Œ <em>sortOrder</em>ã€‚</p>
<ul>
<li>sortBy çš„å€¼æœ‰ï¼šrelevanceï¼ŒlastUpdatedDate å’Œ submittedDateã€‚</li>
<li>sortOrder çš„å€¼æœ‰ï¼šascending å’Œ descendingã€‚</li>
</ul>
<p>ç¤ºä¾‹ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">http://export.arxiv.org/api/query?search_query=ti:%22electron%20thermal%20conductivity%22&amp;sortBy=lastUpdatedDate&amp;sortOrder=ascending</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ç»“æœå“åº”"><a href="#ç»“æœå“åº”" class="headerlink" title="ç»“æœå“åº”"></a>ç»“æœå“åº”</h2><p>API çš„ Response å†…å®¹ä¸­æ˜¯ä»¥ <em>Atom 1.0</em> ä¸ºä¸»ä½“çš„ï¼Œ<em>Atom</em> æ˜¯ XML çš„ä¸€ç§è¯­æ³•ã€‚ä¸‹é¢åˆ†åˆ«æ¥è¯´æ˜å„ä¸ªæ ‡ç­¾çš„å«ä¹‰ã€‚</p>
<h3 id="Feed-Metadata"><a href="#Feed-Metadata" class="headerlink" title="Feed Metadata"></a>Feed Metadata</h3><p>æ¯ä¸ª Response éƒ½ä¼šåŒ…å«çš„å†…å®¹ï¼š</p>
<ol>
<li>ç‰ˆæœ¬å’Œå‘½åç©ºé—´</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"UTF-8"</span>?&gt;</span><br><span class="line">&lt;feed xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Titleï¼šfeed çš„æ ‡é¢˜ï¼Œé€šå¸¸ä¸ºæŸ¥è¯¢ URL çš„å­—ç¬¦ä¸²ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;title xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">    ArXiv Query:  search_query=all:electron&amp;amp;id_list=&amp;amp;start=0&amp;amp;max_results=1</span><br><span class="line">&lt;/title&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Idï¼šæŸ¥è¯¢çš„å”¯ä¸€æ ‡è¯†ï¼ˆæ³¨æ„ä¸æ˜¯æŸ¥è¯¢çš„æ¯ä¸ªæ–‡ç« çš„ idï¼‰ï¼Œä¿è¯æ¯ä¸ªæŸ¥è¯¢ id æ˜¯å”¯ä¸€çš„ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;<span class="built_in">id</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">    http://arxiv.org/api/cHxbiOdZaP56ODnBPIenZhzg5f8</span><br><span class="line">&lt;/id&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Linkï¼šæŸ¥è¯¢ URL çš„è§„èŒƒåŒ–ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;<span class="built_in">link</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> href=<span class="string">"http://arxiv.org/api/query?search_query=all:electron&amp;amp;id_list=&amp;amp;start=0&amp;amp;max_results=1"</span> rel=<span class="string">"self"</span> <span class="built_in">type</span>=<span class="string">"application/atom+xml"</span>/&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Updatedï¼šæä¾›äº† feed å†…å®¹æœ€åä¸€æ¬¡æ›´æ–°çš„æ—¶é—´ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;updated xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;2007-10-08T00:00:00-04:00&lt;/updated&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Opensearchï¼šæ‰©å±•å…ƒç´ ï¼ŒåŒ…å«äº†æŸ¥è¯¢çš„è¿”å›æ•°é‡ä»¥åŠåˆ†é¡µä¿¡æ¯ç­‰ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;opensearch:totalResults xmlns:opensearch=<span class="string">"http://a9.com/-/spec/opensearch/1.1/"</span>&gt;</span><br><span class="line">   1000</span><br><span class="line">&lt;/opensearch:totalResults&gt;</span><br><span class="line">&lt;opensearch:startIndex xmlns:opensearch=<span class="string">"http://a9.com/-/spec/opensearch/1.1/"</span>&gt;</span><br><span class="line">   0</span><br><span class="line">&lt;/opensearch:startIndex&gt;</span><br><span class="line">&lt;opensearch:itemsPerPage xmlns:opensearch=<span class="string">"http://a9.com/-/spec/opensearch/1.1/"</span>&gt;</span><br><span class="line">   1</span><br><span class="line">&lt;/opensearch:itemsPerPage&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Entry-Metadata"><a href="#Entry-Metadata" class="headerlink" title="Entry Metadata"></a>Entry Metadata</h3><p>æ­£å¸¸æƒ…å†µä¸‹ï¼ŒResponse è¿”å›ç»“æœä¸­çš„ <em>feed</em> æ ‡ç­¾ä¼šåŒ…å« 0 ä¸ªæˆ–è€…å¤šä¸ª <em>entry</em> æ ‡ç­¾ã€‚æ¯ä¸ª entry è¡¨ç¤ºä¸€ä¸ªæŸ¥è¯¢çš„è¿”å›æ–‡ç« ï¼Œä¸‹é¢åˆ†åˆ«è¯´ä¸€ä¸‹ entry ä¸­çš„å„ä¸ªå…ƒç´ ã€‚</p>
<ol>
<li>Titleï¼šè¿”å›æ–‡ç« çš„æ ‡é¢˜</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;title xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">    Multi-Electron Production at High Transverse Momenta <span class="keyword">in</span> ep Collisions at HERA</span><br><span class="line">&lt;/title&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Idï¼šæ–‡ç« çš„ URL ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯æ–‡ç« çš„ç»å¯¹è·¯å¾„ã€‚æœ€åä¸€ä¸ªå­—æ®µæ˜¯æ–‡ç« çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;<span class="built_in">id</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">    http://arxiv.org/abs/hep-ex/0307015</span><br><span class="line">&lt;/id&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Published/Updatedï¼šæ–‡ç« çš„å‘å¸ƒæ—¥æœŸå’Œæ›´æ–°æ—¥æœŸã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;published xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">    2007-02-27T16:02:02-05:00</span><br><span class="line">&lt;/published&gt;</span><br><span class="line">&lt;updated xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">    2007-06-25T17:09:59-04:00</span><br><span class="line">&lt;/updated&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Summaryï¼šæ–‡ç« çš„æ‘˜è¦ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;summary xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">    Multi-electron production is studied at high electron transverse momentum</span><br><span class="line">    <span class="keyword">in</span> positron- and electron-proton collisions using the H1 detector at HERA.</span><br><span class="line">    The data correspond to an integrated luminosity of 115 pb-1. Di-electron</span><br><span class="line">    and tri-electron event yields are measured. Cross sections are derived <span class="keyword">in</span></span><br><span class="line">    a restricted phase space region dominated by photon-photon collisions. In</span><br><span class="line">    general good agreement is found with the Standard Model predictions.</span><br><span class="line">    However, <span class="keyword">for</span> electron pair invariant masses above 100 GeV, three</span><br><span class="line">    di-electron events and three tri-electron events are observed, compared to</span><br><span class="line">    Standard Model expectations of 0.30 \pm 0.04 and 0.23 \pm 0.04,</span><br><span class="line">    respectively.</span><br><span class="line">&lt;/summary&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Authorï¼šæ–‡ç« çš„ä½œè€…ï¼ŒåŒ…å«ä¸€ä¸ªæˆ–è€…å¤šä¸ª name æ ‡ç­¾ï¼Œåˆ†åˆ«è¡¨ç¤ºå¤šä¸ªä½œè€…ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;author xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">      &lt;name xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;H1 Collaboration&lt;/name&gt;</span><br><span class="line">&lt;/author&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Categoryï¼šæ–‡ç« çš„åˆ†ç±»ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;category xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> term=<span class="string">"cs.LG"</span> scheme=<span class="string">"http://arxiv.org/schemas/atom"</span>/&gt;</span><br><span class="line">&lt;category xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> term=<span class="string">"cs.AI"</span> scheme=<span class="string">"http://arxiv.org/schemas/atom"</span>/&gt;</span><br><span class="line">&lt;category xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> term=<span class="string">"I.2.6"</span> scheme=<span class="string">"http://arxiv.org/schemas/atom"</span>/&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>Linkï¼Œå¯¹äºæ¯ä¸ªæ–‡ç« ï¼Œæœ€å¤šæœ‰ä¸‰ä¸ª link å…ƒç´ ï¼Œé€šè¿‡ ref å’Œ title æ¥åŒºåˆ«ï¼Œä¸‹é¢çš„è¡¨æ ¼è¡¨ç¤º ref å’Œ title çš„å†…å®¹ï¼š</li>
</ol>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">rel</th>
<th style="text-align:center">title</th>
<th style="text-align:center">refers to</th>
<th style="text-align:center">always present</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">alternate</td>
<td style="text-align:center">-</td>
<td style="text-align:center">abstract page</td>
<td style="text-align:center">yes</td>
</tr>
<tr>
<td style="text-align:center">related</td>
<td style="text-align:center">pdf</td>
<td style="text-align:center">pdf</td>
<td style="text-align:center">yes</td>
</tr>
<tr>
<td style="text-align:center">related</td>
<td style="text-align:center">doi</td>
<td style="text-align:center">resolved doi</td>
<td style="text-align:center">no</td>
</tr>
</tbody>
</table>
</div>
<p>ä¾‹å­ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;<span class="built_in">link</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> href=<span class="string">"http://arxiv.org/abs/hep-ex/0307015v1"</span> rel=<span class="string">"alternate"</span> <span class="built_in">type</span>=<span class="string">"text/html"</span>/&gt;</span><br><span class="line">&lt;<span class="built_in">link</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> title=<span class="string">"pdf"</span> href=<span class="string">"http://arxiv.org/pdf/hep-ex/0307015v1"</span> rel=<span class="string">"related"</span> <span class="built_in">type</span>=<span class="string">"application/pdf"</span>/&gt;</span><br><span class="line">&lt;<span class="built_in">link</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> title=<span class="string">"doi"</span> href=<span class="string">"http://dx.doi.org/10.1529/biophysj.104.047340"</span> rel=<span class="string">"related"</span>/&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>arxiv:primary_categoryï¼šä¸»è¦åˆ†ç±»çš„æ‰©å±•å…ƒç´ ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;arxiv:primary_category xmlns:arxiv=<span class="string">"http://arxiv.org/schemas/atom"</span> term=<span class="string">"cs.LG"</span> scheme=<span class="string">"http://arxiv.org/schemas/atom"</span>/&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>arxiv:commentï¼šè¯„è®ºæ‰©å±•å…ƒç´ ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;arxiv:comment xmlns:arxiv=<span class="string">"http://arxiv.org/schemas/atom"</span>&gt;</span><br><span class="line">   23 pages, 8 figures and 4 tables</span><br><span class="line">&lt;/arxiv:comment&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>arxiv:affiliationï¼šä½œè€…ä»å±å…³ç³»ã€‚</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;author&gt;</span><br><span class="line">   &lt;name&gt;G. G. Kacprzak&lt;/name&gt;</span><br><span class="line">   &lt;arxiv:affiliation xmlns:arxiv=<span class="string">"http://arxiv.org/schemas/atom"</span>&gt;NMSU&lt;/arxiv:affiliation&gt;</span><br><span class="line">&lt;/author&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>arxiv:journal_refï¼šæœŸåˆŠè¯´æ˜</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;arxiv:journal_ref xmlns:arxiv=<span class="string">"http://arxiv.org/schemas/atom"</span>&gt;</span><br><span class="line">   Eur.Phys.J. C31 (2003) 17-29</span><br><span class="line">&lt;/arxiv:journal_ref&gt;</span><br></pre></td></tr></tbody></table></figure>
<ol>
<li>arxiv:doiï¼šdoi è¯´æ˜</li>
</ol>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;arxiv:doi xmlns:arxiv=<span class="string">"http://arxiv.org/schemas/atom"</span>&gt;</span><br><span class="line">   10.1529/biophysj.104.047340</span><br><span class="line">&lt;/arxiv:doi&gt;</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Errors"><a href="#Errors" class="headerlink" title="Errors"></a>Errors</h3><p>è¿”å›é”™è¯¯ï¼Œå¦‚æœè¯·æ±‚çš„å“åº”å‡ºç°é”™è¯¯ï¼Œä¼šè¿”å›ä¸€ä¸ªè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ã€‚ä¾‹å¦‚ä¸‹é¢æ˜¯ä¸€ä¸ªé”™è¯¯ id çš„ä¿¡æ¯ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">&lt;?xml version=<span class="string">"1.0"</span> encoding=<span class="string">"utf-8"</span>?&gt;</span><br><span class="line">&lt;feed xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> xmlns:opensearch=<span class="string">"http://a9.com/-/spec/opensearch/1.1/"</span>&gt;</span><br><span class="line">  &lt;<span class="built_in">link</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> href=<span class="string">"http://arxiv.org/api/query?search_query=&amp;amp;id_list=1234.12345"</span> rel=<span class="string">"self"</span> <span class="built_in">type</span>=<span class="string">"application/atom+xml"</span>/&gt;</span><br><span class="line">  &lt;title xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;ArXiv Query: search_query=&amp;amp;id_list=1234.12345&lt;/title&gt;</span><br><span class="line">  &lt;<span class="built_in">id</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;http://arxiv.org/api/kvuntZ8c9a4Eq5CF7KY03nMug+Q&lt;/id&gt;</span><br><span class="line">  &lt;updated xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;2007-10-12T00:00:00-04:00&lt;/updated&gt;</span><br><span class="line">  &lt;opensearch:totalResults xmlns:opensearch=<span class="string">"http://a9.com/-/spec/opensearch/1.1/"</span>&gt;1&lt;/opensearch:totalResults&gt;</span><br><span class="line">  &lt;opensearch:startIndex xmlns:opensearch=<span class="string">"http://a9.com/-/spec/opensearch/1.1/"</span>&gt;0&lt;/opensearch:startIndex&gt;</span><br><span class="line"></span><br><span class="line">  &lt;opensearch:itemsPerPage xmlns:opensearch=<span class="string">"http://a9.com/-/spec/opensearch/1.1/"</span>&gt;1&lt;/opensearch:itemsPerPage&gt;</span><br><span class="line">  &lt;entry xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">    &lt;<span class="built_in">id</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;http://arxiv.org/api/errors<span class="comment">#incorrect_id_format_for_1234.12345&lt;/id&gt;</span></span><br><span class="line">    &lt;title xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;Error&lt;/title&gt;</span><br><span class="line">    &lt;summary xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;incorrect <span class="built_in">id</span> format <span class="keyword">for</span> 1234.12345&lt;/summary&gt;</span><br><span class="line">    &lt;updated xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;2007-10-12T00:00:00-04:00&lt;/updated&gt;</span><br><span class="line"></span><br><span class="line">    &lt;<span class="built_in">link</span> xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span> href=<span class="string">"http://arxiv.org/api/errors#incorrect_id_format_for_1234.12345"</span> rel=<span class="string">"alternate"</span> <span class="built_in">type</span>=<span class="string">"text/html"</span>/&gt;</span><br><span class="line">    &lt;author xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;</span><br><span class="line">      &lt;name xmlns=<span class="string">"http://www.w3.org/2005/Atom"</span>&gt;arXiv api core&lt;/name&gt;</span><br><span class="line">    &lt;/author&gt;</span><br><span class="line">  &lt;/entry&gt;</span><br><span class="line">&lt;/feed&gt;</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸‹é¢æä¾›äº†ä¸€äº›å¸¸è§çš„é”™è¯¯ï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><strong>Sample query ç¤ºä¾‹æŸ¥è¯¢</strong></th>
<th style="text-align:center"><strong>Error Explanation é”™è¯¯è§£é‡Š</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><a href="http://export.arxiv.org/api/query?start=not_an_int">http://export.arxiv.org/api/query?start=not_an_int</a></td>
<td style="text-align:center"><code>start</code> ä¸€å®šæ˜¯ä¸ªæ•´æ•°</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://export.arxiv.org/api/query?start=-1">http://export.arxiv.org/api/query?start=-1</a></td>
<td style="text-align:center"><code>start</code> å¿…é¡» &gt;= 0</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://export.arxiv.org/api/query?max_results=not_an_int">http://export.arxiv.org/api/query?max_results=not_an_int</a></td>
<td style="text-align:center"><code>max_results</code> ä¸€å®šæ˜¯ä¸ªæ•´æ•°</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://export.arxiv.org/api/query?max_results=-1">http://export.arxiv.org/api/query?max_results=-1</a></td>
<td style="text-align:center"><code>max_results</code> å¿…é¡» &gt;= 0</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://export.arxiv.org/api/query?id_list=1234.1234">http://export.arxiv.org/api/query?id_list=1234.1234</a></td>
<td style="text-align:center">malformed id</td>
</tr>
<tr>
<td style="text-align:center"><a href="http://export.arxiv.org/api/query?id_list=condâ€”mat/0709123">http://export.arxiv.org/api/query?id_list=condâ€”mat/0709123</a></td>
<td style="text-align:center">malformed id</td>
</tr>
</tbody>
</table>
</div>
<h2 id="ä¾‹å­"><a href="#ä¾‹å­" class="headerlink" title="ä¾‹å­"></a>ä¾‹å­</h2><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>python2.7 ä¸Šçš„ç®€å•è¯·æ±‚ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line">url = <span class="string">'http://export.arxiv.org/api/query?search_query=all:electron&amp;start=0&amp;max_results=1'</span></span><br><span class="line">data = urllib.urlopen(url).read()</span><br><span class="line"><span class="built_in">print</span> data</span><br></pre></td></tr></tbody></table></figure>
<p>python3 ä¸Šçš„è¯·æ±‚ï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request <span class="keyword">as</span> libreq</span><br><span class="line"><span class="keyword">with</span> libreq.urlopen(<span class="string">'http://export.arxiv.org/api/query?search_query=all:electron&amp;start=0&amp;max_results=1'</span>) <span class="keyword">as</span> url:</span><br><span class="line">    r = url.read()</span><br><span class="line">    <span class="built_in">print</span>(r)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="é™„å½•"><a href="#é™„å½•" class="headerlink" title="é™„å½•"></a>é™„å½•</h2><h3 id="æŸ¥è¯¢çš„è¯¦ç»†ç»“æ„"><a href="#æŸ¥è¯¢çš„è¯¦ç»†ç»“æ„" class="headerlink" title="æŸ¥è¯¢çš„è¯¦ç»†ç»“æ„"></a>æŸ¥è¯¢çš„è¯¦ç»†ç»“æ„</h3><p>åœ¨ arXiv æœç´¢å¼•æ“ä¸­ï¼Œæ¯ç¯‡æ–‡ç« éƒ½è¢«åˆ’åˆ†ä¸ºè®¸å¤šå¯ä»¥å•ç‹¬æœç´¢çš„å­—æ®µã€‚ ä¾‹å¦‚ï¼Œå¯ä»¥æœç´¢ä¸€ç¯‡æ–‡ç« çš„æ ‡é¢˜ï¼Œä»¥åŠä½œè€…åˆ—è¡¨ã€æ‘˜è¦ã€è¯„è®ºå’ŒæœŸåˆŠå‚è€ƒæ–‡çŒ®ã€‚ è¦æœç´¢å…¶ä¸­ä¸€ä¸ªå­—æ®µï¼Œåªéœ€åœ¨æœç´¢è¯å‰åŠ ä¸Šå­—æ®µå‰ç¼€å’Œå†’å·å³å¯ã€‚ ä¾‹å¦‚ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">http://export.arxiv.org/api/query?search_query=au:del_maestro</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸‹é¢çš„è¡¨æ ¼æ˜¾ç¤ºæ‰€æœ‰å­—æ®µçš„å‰ç¼€ï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><strong>prefix</strong></th>
<th style="text-align:center"><strong>explanation</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ti</td>
<td style="text-align:center">Title</td>
</tr>
<tr>
<td style="text-align:center">au</td>
<td style="text-align:center">Author</td>
</tr>
<tr>
<td style="text-align:center">abs</td>
<td style="text-align:center">Abstract</td>
</tr>
<tr>
<td style="text-align:center">co</td>
<td style="text-align:center">Comment</td>
</tr>
<tr>
<td style="text-align:center">jr</td>
<td style="text-align:center">Journal Reference</td>
</tr>
<tr>
<td style="text-align:center">cat</td>
<td style="text-align:center">Subject Category</td>
</tr>
<tr>
<td style="text-align:center">rn</td>
<td style="text-align:center">Report Number</td>
</tr>
<tr>
<td style="text-align:center">id</td>
<td style="text-align:center">Id (use <code>id_list</code> instead)</td>
</tr>
<tr>
<td style="text-align:center">all</td>
<td style="text-align:center">All of the above</td>
</tr>
</tbody>
</table>
</div>
<p>å¹¶ä¸”æŸ¥è¯¢ä¹Ÿæ”¯æŒå¸ƒå°”è¿ç®—ï¼Œå‡è®¾æˆ‘ä»¬å¸Œæœ›æ‰¾åˆ°ä½œè€… Adrian DelMaestro çš„æ‰€æœ‰æ–‡ç« ï¼Œå…¶æ ‡é¢˜ä¸­ä¹ŸåŒ…å«å•è¯ checkerboardã€‚ æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ AND æ“ä½œç¬¦æ„é€ ä¸‹é¢çš„æŸ¥è¯¢ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">http://export.arxiv.org/api/query?search_query=au:del_maestro+AND+ti:checkerboard</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸‹é¢æ˜¯ä¸‰ç§å¯èƒ½çš„å¸ƒå°”å€¼ï¼š</p>
<ul>
<li>AND</li>
<li>OR</li>
<li>ANDNOT</li>
</ul>
<p>ä¸‹é¢æ˜¯ç‰¹æ®Šç¬¦å·çš„å«ä¹‰ä»¥åŠè½¬ä¹‰å­—ç¬¦ï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">symbol</th>
<th style="text-align:left">encoding</th>
<th style="text-align:left">explanation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">( )</td>
<td style="text-align:left">%28 %29</td>
<td style="text-align:left">ç”¨äºä¸ºå¸ƒå°”è¿ç®—ç¬¦ä¼˜å…ˆçº§å¯¹å¸ƒå°”è¡¨è¾¾å¼è¿›è¡Œåˆ†ç»„</td>
</tr>
<tr>
<td style="text-align:left">â€œ â€œ</td>
<td style="text-align:left">%22 %22</td>
<td style="text-align:left">ç”¨äºå°†å¤šä¸ªå•è¯ç»„åˆæˆçŸ­è¯­ä»¥æœç´¢ç‰¹å®šå­—æ®µ</td>
</tr>
<tr>
<td style="text-align:left">ç©ºæ ¼</td>
<td style="text-align:left">+</td>
<td style="text-align:left">ç”¨äºæ‰©å±•<code>search_query</code> åŒ…å«å¤šä¸ªå­—æ®µ</td>
</tr>
</tbody>
</table>
</div>
<h3 id="è¿”å›çš„è¯¦ç»†ç»“æ„"><a href="#è¿”å›çš„è¯¦ç»†ç»“æ„" class="headerlink" title="è¿”å›çš„è¯¦ç»†ç»“æ„"></a>è¿”å›çš„è¯¦ç»†ç»“æ„</h3><p>ä¸‹è¡¨åˆ—å‡ºäº†è¿”å›çš„ Atom ç»“æœçš„æ¯ä¸ªå…ƒç´ :</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center"><strong>element</strong></th>
<th style="text-align:center"><strong>explanation</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>feed elements</strong></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">title</td>
<td style="text-align:center">åŒ…å«è§„èŒƒåŒ–æŸ¥è¯¢å­—ç¬¦ä¸²çš„æ ‡é¢˜</td>
</tr>
<tr>
<td style="text-align:center">id</td>
<td style="text-align:center">åˆ†é…ç»™æ­¤æŸ¥è¯¢çš„å”¯ä¸€ id</td>
</tr>
<tr>
<td style="text-align:center">updated</td>
<td style="text-align:center">æœ€åä¸€æ¬¡æ›´æ–°æ­¤æŸ¥è¯¢çš„æœç´¢ç»“æœã€‚ è®¾ç½®ä¸ºå½“å¤©çš„åˆå¤œ</td>
</tr>
<tr>
<td style="text-align:center">link</td>
<td style="text-align:center">é€šè¿‡ GET è¯·æ±‚æ£€ç´¢æ­¤æè¦çš„ url</td>
</tr>
<tr>
<td style="text-align:center">opensearch:totalResults</td>
<td style="text-align:center">æ­¤æŸ¥è¯¢çš„æœç´¢ç»“æœæ€»æ•°</td>
</tr>
<tr>
<td style="text-align:center">opensearch:startIndex</td>
<td style="text-align:center">æ€»ç»“æœåˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ªè¿”å›ç»“æœçš„åŸºäº0çš„ç´¢å¼•</td>
</tr>
<tr>
<td style="text-align:center">opensearch:itemsPerPage</td>
<td style="text-align:center">æ¯é¡µè¿”å›çš„ç»“æœæ•°</td>
</tr>
<tr>
<td style="text-align:center"><strong>entry elements</strong></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">title</td>
<td style="text-align:center">æ–‡ç« çš„æ ‡é¢˜</td>
</tr>
<tr>
<td style="text-align:center">id</td>
<td style="text-align:center">æ–‡ç« çš„ç½‘å€<code>http://arxiv.org/abs/id</code></td>
</tr>
<tr>
<td style="text-align:center">published</td>
<td style="text-align:center">æ–‡ç« çš„å‘å¸ƒæ—¥æœŸ</td>
</tr>
<tr>
<td style="text-align:center">updated</td>
<td style="text-align:center">æ–‡ç« çš„æ›´æ–°æ—¥æœŸï¼Œå¦‚æœä¸º v1 ç‰ˆæœ¬ï¼Œé‚£ä¹ˆä¸å‘å¸ƒæ—¥æœŸç›¸åŒ</td>
</tr>
<tr>
<td style="text-align:center">summary</td>
<td style="text-align:center">æ–‡ç« æ‘˜è¦</td>
</tr>
<tr>
<td style="text-align:center">author</td>
<td style="text-align:center">æ¯ä¸ªä½œè€…æœ‰ä¸€ä¸ªå­å…ƒç´  nameï¼ŒåŒ…å«äº†ä½œè€…çš„åå­—</td>
</tr>
<tr>
<td style="text-align:center">link</td>
<td style="text-align:center">å¯ä»¥ç»™å®šä¸è¿™ç¯‡æ–‡ç« å…³è”çš„ 3 ä¸ªç½‘å€</td>
</tr>
<tr>
<td style="text-align:center">category</td>
<td style="text-align:center">æ–‡ç« åˆ†ç±»</td>
</tr>
<tr>
<td style="text-align:center">arxiv:primary_category</td>
<td style="text-align:center">ä¸»è¦çš„ arXiv åˆ†ç±»</td>
</tr>
<tr>
<td style="text-align:center">arxiv:comment</td>
<td style="text-align:center">ä½œè€…å¯¹æ­¤å‘è¡¨çš„è¯„è®º</td>
</tr>
<tr>
<td style="text-align:center">arxiv:affiliation</td>
<td style="text-align:center">ä½œè€…çš„ä»å±å…³ç³»</td>
</tr>
<tr>
<td style="text-align:center">arxiv:journal_ref</td>
<td style="text-align:center">å‚è€ƒæ–‡çŒ®</td>
</tr>
<tr>
<td style="text-align:center">arxiv:doi</td>
<td style="text-align:center">å·²è§£æçš„ DOI çš„ urlï¼ŒæŒ‡å‘å¤–éƒ¨èµ„æº</td>
</tr>
</tbody>
</table>
</div>
<h3 id="å­¦ç§‘çš„åˆ†ç±»"><a href="#å­¦ç§‘çš„åˆ†ç±»" class="headerlink" title="å­¦ç§‘çš„åˆ†ç±»"></a>å­¦ç§‘çš„åˆ†ç±»</h3><p>ä¸‹é¢æ˜¯å­¦ç§‘åˆ†ç±»å­—æ®µä»¥åŠå¯¹åº”çš„ç¿»è¯‘ï¼ˆè½¯ä»¶è„šæœ¬è‡ªåŠ¨ç¿»è¯‘ï¼Œå¦‚ä¸å¯¹è¯·å‹¿å–·ï¼‰ï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">å­—æ®µ</th>
<th style="text-align:center">å­¦ç§‘ï¼ˆè‹±æ–‡ï¼‰</th>
<th style="text-align:center">å­¦ç§‘ï¼ˆä¸­æ–‡ï¼‰</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">astro-ph</td>
<td style="text-align:center">Astrophysics</td>
<td style="text-align:center">å¤©ä½“ç‰©ç†</td>
</tr>
<tr>
<td style="text-align:center">astro-ph.CO</td>
<td style="text-align:center">Cosmology and Nongalactic Astrophysics</td>
<td style="text-align:center">å®‡å®™å­¦ä¸éè§„åˆ™å¤©ä½“ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">astro-ph.EP</td>
<td style="text-align:center">Earth and Planetary Astrophysics</td>
<td style="text-align:center">åœ°çƒä¸è¡Œæ˜Ÿå¤©ä½“ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">astro-ph.GA</td>
<td style="text-align:center">Astrophysics of Galaxies</td>
<td style="text-align:center">æ˜Ÿç³»çš„å¤©ä½“ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">astro-ph.HE</td>
<td style="text-align:center">High Energy Astrophysical Phenomena</td>
<td style="text-align:center">é«˜èƒ½å¤©ä½“ç‰©ç†ç°è±¡</td>
</tr>
<tr>
<td style="text-align:center">astro-ph.IM</td>
<td style="text-align:center">Instrumentation and Methods for Astrophysics</td>
<td style="text-align:center">å¤©ä½“ç‰©ç†å­¦çš„ä»ªå™¨å’Œæ–¹æ³•</td>
</tr>
<tr>
<td style="text-align:center">astro-ph.SR</td>
<td style="text-align:center">Solar and Stellar Astrophysics</td>
<td style="text-align:center">å¤ªé˜³ä¸æ’æ˜Ÿå¤©ä½“ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">cond-mat.dis-nn</td>
<td style="text-align:center">Disordered Systems and Neural Networks</td>
<td style="text-align:center">æ— åºç³»ç»Ÿä¸ç¥ç»ç½‘ç»œ</td>
</tr>
<tr>
<td style="text-align:center">cond-mat.mes-hall</td>
<td style="text-align:center">Mesoscale and Nanoscale Physics</td>
<td style="text-align:center">ä¸­å°ºåº¦å’Œçº³ç±³å°ºåº¦ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">cond-mat.mtrl-sci</td>
<td style="text-align:center">Materials Science</td>
<td style="text-align:center">ææ–™ç§‘å­¦</td>
</tr>
<tr>
<td style="text-align:center">cond-mat.other</td>
<td style="text-align:center">Other Condensed Matter</td>
<td style="text-align:center">å…¶ä»–å‡èšæ€</td>
</tr>
<tr>
<td style="text-align:center">cond-mat.quant-gas</td>
<td style="text-align:center">Quantum Gases</td>
<td style="text-align:center">é‡å­æ°”ä½“</td>
</tr>
<tr>
<td style="text-align:center">cond-mat.soft</td>
<td style="text-align:center">Soft Condensed Matter</td>
<td style="text-align:center">è½¯å‡èšç‰©</td>
</tr>
<tr>
<td style="text-align:center">cond-mat.stat-mech</td>
<td style="text-align:center">Statistical Mechanics</td>
<td style="text-align:center">ç»Ÿè®¡åŠ›å­¦</td>
</tr>
<tr>
<td style="text-align:center">cond-mat.str-el</td>
<td style="text-align:center">Strongly Correlated Electrons</td>
<td style="text-align:center">å¼ºå…³è”ç”µå­</td>
</tr>
<tr>
<td style="text-align:center">cond-mat.supr-con</td>
<td style="text-align:center">Superconductivity</td>
<td style="text-align:center">è¶…å¯¼ç°è±¡</td>
</tr>
<tr>
<td style="text-align:center">cs.AI</td>
<td style="text-align:center">Artificial Intelligence</td>
<td style="text-align:center">äººå·¥æ™ºèƒ½</td>
</tr>
<tr>
<td style="text-align:center">cs.AR</td>
<td style="text-align:center">Hardware Architecture</td>
<td style="text-align:center">ç¡¬ä»¶æ¶æ„</td>
</tr>
<tr>
<td style="text-align:center">cs.CC</td>
<td style="text-align:center">Computational Complexity</td>
<td style="text-align:center">è®¡ç®—å¤æ‚æ€§</td>
</tr>
<tr>
<td style="text-align:center">cs.CE</td>
<td style="text-align:center">Computational Engineering, Finance, and Science</td>
<td style="text-align:center">è®¡ç®—å·¥ç¨‹ï¼Œé‡‘èå’Œç§‘å­¦</td>
</tr>
<tr>
<td style="text-align:center">cs.CG</td>
<td style="text-align:center">Computational Geometry</td>
<td style="text-align:center">è®¡ç®—å‡ ä½•</td>
</tr>
<tr>
<td style="text-align:center">cs.CL</td>
<td style="text-align:center">Computation and Language</td>
<td style="text-align:center">è®¡ç®—ä¸è¯­è¨€</td>
</tr>
<tr>
<td style="text-align:center">cs.CR</td>
<td style="text-align:center">Cryptography and Security</td>
<td style="text-align:center">å¯†ç å­¦ä¸ä¿å®‰</td>
</tr>
<tr>
<td style="text-align:center">cs.CV</td>
<td style="text-align:center">Computer Vision and Pattern Recognition</td>
<td style="text-align:center">è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«</td>
</tr>
<tr>
<td style="text-align:center">CY</td>
<td style="text-align:center">Computers and Society</td>
<td style="text-align:center">ç”µè„‘ä¸ç¤¾ä¼š</td>
</tr>
<tr>
<td style="text-align:center">cs.DB</td>
<td style="text-align:center">Databases</td>
<td style="text-align:center">æ•°æ®åº“</td>
</tr>
<tr>
<td style="text-align:center">cs.DC</td>
<td style="text-align:center">Distributed, Parallel, and Cluster Computing</td>
<td style="text-align:center">åˆ†å¸ƒå¼ã€å¹¶è¡Œå’Œé›†ç¾¤è®¡ç®—</td>
</tr>
<tr>
<td style="text-align:center">cs.DL</td>
<td style="text-align:center">Digital Libraries</td>
<td style="text-align:center">æ•°å­—ä»“åº“</td>
</tr>
<tr>
<td style="text-align:center">cs.DM</td>
<td style="text-align:center">Discrete Mathematics</td>
<td style="text-align:center">ç¦»æ•£æ•°å­¦</td>
</tr>
<tr>
<td style="text-align:center">cs.DS</td>
<td style="text-align:center">Data Structures and Algorithms</td>
<td style="text-align:center">æ•°æ®ç»“æ„å’Œç®—æ³•</td>
</tr>
<tr>
<td style="text-align:center">cs.ET</td>
<td style="text-align:center">Emerging Technologies</td>
<td style="text-align:center">æ–°å…´ç§‘æŠ€</td>
</tr>
<tr>
<td style="text-align:center">cs.FL</td>
<td style="text-align:center">Formal Languages and Automata Theory</td>
<td style="text-align:center">å½¢å¼è¯­è¨€ä¸è‡ªåŠ¨æœºç†è®º</td>
</tr>
<tr>
<td style="text-align:center">cs.GL</td>
<td style="text-align:center">General Literature</td>
<td style="text-align:center">ä¸€èˆ¬æ–‡å­¦</td>
</tr>
<tr>
<td style="text-align:center">cs.GR</td>
<td style="text-align:center">Graphics</td>
<td style="text-align:center">å›¾å½¢</td>
</tr>
<tr>
<td style="text-align:center">cs.GT</td>
<td style="text-align:center">Computer Science and Game Theory</td>
<td style="text-align:center">è®¡ç®—æœºç§‘å­¦ä¸åšå¼ˆè®º</td>
</tr>
<tr>
<td style="text-align:center">cs.HC</td>
<td style="text-align:center">Human-Computer Interaction</td>
<td style="text-align:center">äººæœºäº¤äº’</td>
</tr>
<tr>
<td style="text-align:center">cs.IR</td>
<td style="text-align:center">Information Retrieval</td>
<td style="text-align:center">ä¿¡æ¯æ£€ç´¢</td>
</tr>
<tr>
<td style="text-align:center">cs.IT</td>
<td style="text-align:center">Information Theory</td>
<td style="text-align:center">ä¿¡æ¯ç†è®º</td>
</tr>
<tr>
<td style="text-align:center">cs.LG</td>
<td style="text-align:center">Learning</td>
<td style="text-align:center">å­¦ä¹ </td>
</tr>
<tr>
<td style="text-align:center">cs.LO</td>
<td style="text-align:center">Logic in Computer Science</td>
<td style="text-align:center">è®¡ç®—æœºç§‘å­¦ä¸­çš„é€»è¾‘</td>
</tr>
<tr>
<td style="text-align:center">cs.MA</td>
<td style="text-align:center">Multiagent Systems</td>
<td style="text-align:center">å¤šä»£ç†ç³»ç»Ÿ</td>
</tr>
<tr>
<td style="text-align:center">cs.MM</td>
<td style="text-align:center">Multimedia</td>
<td style="text-align:center">å¤šåª’ä½“</td>
</tr>
<tr>
<td style="text-align:center">cs.MS</td>
<td style="text-align:center">Mathematical Software</td>
<td style="text-align:center">æ•°å­¦è½¯ä»¶</td>
</tr>
<tr>
<td style="text-align:center">cs.NA</td>
<td style="text-align:center">Numerical Analysis</td>
<td style="text-align:center">æ•°å€¼åˆ†æ</td>
</tr>
<tr>
<td style="text-align:center">cs.NE</td>
<td style="text-align:center">Neural and Evolutionary Computing</td>
<td style="text-align:center">ç¥ç»å’Œè¿›åŒ–è®¡ç®—</td>
</tr>
<tr>
<td style="text-align:center">cs.NI</td>
<td style="text-align:center">Networking and Internet Architecture</td>
<td style="text-align:center">ç½‘ç»œä¸äº’è”ç½‘æ¶æ„</td>
</tr>
<tr>
<td style="text-align:center">cs.OH</td>
<td style="text-align:center">Other Computer Science</td>
<td style="text-align:center">å…¶ä»–è®¡ç®—æœºç§‘å­¦</td>
</tr>
<tr>
<td style="text-align:center">cs.OS</td>
<td style="text-align:center">Operating Systems</td>
<td style="text-align:center">æ“ä½œç³»ç»Ÿ</td>
</tr>
<tr>
<td style="text-align:center">cs.PF</td>
<td style="text-align:center">Performance</td>
<td style="text-align:center">æ€§èƒ½</td>
</tr>
<tr>
<td style="text-align:center">cs.PL</td>
<td style="text-align:center">Programming Languages</td>
<td style="text-align:center">ç¼–ç¨‹è¯­è¨€</td>
</tr>
<tr>
<td style="text-align:center">cs.RO</td>
<td style="text-align:center">Robotics</td>
<td style="text-align:center">æœºå™¨äººæŠ€æœ¯</td>
</tr>
<tr>
<td style="text-align:center">cs.SC</td>
<td style="text-align:center">Symbolic Computation</td>
<td style="text-align:center">ç¬¦å·è®¡ç®—</td>
</tr>
<tr>
<td style="text-align:center">cs.SD</td>
<td style="text-align:center">Sound</td>
<td style="text-align:center">å£°éŸ³</td>
</tr>
<tr>
<td style="text-align:center">cs.SE</td>
<td style="text-align:center">Software Engineering</td>
<td style="text-align:center">è½¯ä»¶å·¥ç¨‹</td>
</tr>
<tr>
<td style="text-align:center">cs.SI</td>
<td style="text-align:center">Social and Information Networks</td>
<td style="text-align:center">ç¤¾ä¼šå’Œä¿¡æ¯ç½‘ç»œ</td>
</tr>
<tr>
<td style="text-align:center">cs.SY</td>
<td style="text-align:center">Systems and Control</td>
<td style="text-align:center">ç³»ç»ŸåŠæ§åˆ¶</td>
</tr>
<tr>
<td style="text-align:center">econ.EM</td>
<td style="text-align:center">Econometrics</td>
<td style="text-align:center">è®¡é‡ç»æµå­¦</td>
</tr>
<tr>
<td style="text-align:center">eess.AS</td>
<td style="text-align:center">Audio and Speech Processing</td>
<td style="text-align:center">éŸ³é¢‘åŠè¯­éŸ³å¤„ç†</td>
</tr>
<tr>
<td style="text-align:center">eess.IV</td>
<td style="text-align:center">Image and Video Processing</td>
<td style="text-align:center">å›¾åƒå’Œè§†é¢‘å¤„ç†</td>
</tr>
<tr>
<td style="text-align:center">eess.SP</td>
<td style="text-align:center">Signal Processing</td>
<td style="text-align:center">ä¿¡å·å¤„ç†</td>
</tr>
<tr>
<td style="text-align:center">gr-qc</td>
<td style="text-align:center">General Relativity and Quantum Cosmology</td>
<td style="text-align:center">å¹¿ä¹‰ç›¸å¯¹è®ºå’Œé‡å­å®‡å®™å­¦</td>
</tr>
<tr>
<td style="text-align:center">hep-ex</td>
<td style="text-align:center">High Energy Physics - Experiment</td>
<td style="text-align:center">é«˜èƒ½ç‰©ç†å®éªŒ</td>
</tr>
<tr>
<td style="text-align:center">hep-lat</td>
<td style="text-align:center">High Energy Physics - Lattice</td>
<td style="text-align:center">é«˜èƒ½ç‰©ç†-æ™¶æ ¼</td>
</tr>
<tr>
<td style="text-align:center">hep-ph</td>
<td style="text-align:center">High Energy Physics - Phenomenology</td>
<td style="text-align:center">é«˜èƒ½ç‰©ç†-ç°è±¡å­¦</td>
</tr>
<tr>
<td style="text-align:center">hep-th</td>
<td style="text-align:center">High Energy Physics - Theory</td>
<td style="text-align:center">é«˜èƒ½ç‰©ç†ç†è®º</td>
</tr>
<tr>
<td style="text-align:center">math.AC</td>
<td style="text-align:center">Commutative Algebra</td>
<td style="text-align:center">äº¤æ¢ä»£æ•°</td>
</tr>
<tr>
<td style="text-align:center">math.AG</td>
<td style="text-align:center">Algebraic Geometry</td>
<td style="text-align:center">ä»£æ•°å‡ ä½•</td>
</tr>
<tr>
<td style="text-align:center">math.AP</td>
<td style="text-align:center">Analysis of PDEs</td>
<td style="text-align:center">åå¾®åˆ†æ–¹ç¨‹åˆ†æ</td>
</tr>
<tr>
<td style="text-align:center">math.AT</td>
<td style="text-align:center">Algebraic Topology</td>
<td style="text-align:center">ä»£æ•°æ‹“æ‰‘</td>
</tr>
<tr>
<td style="text-align:center">math.CA</td>
<td style="text-align:center">Classical Analysis and ODEs</td>
<td style="text-align:center">ä¼ ç»Ÿåˆ†æå’Œå¾®åˆ†æ–¹ç¨‹</td>
</tr>
<tr>
<td style="text-align:center">math.CO</td>
<td style="text-align:center">Combinatorics</td>
<td style="text-align:center">ç»„åˆæ•°å­¦</td>
</tr>
<tr>
<td style="text-align:center">math.CT</td>
<td style="text-align:center">Category Theory</td>
<td style="text-align:center">èŒƒç•´ç†è®º</td>
</tr>
<tr>
<td style="text-align:center">math.CV</td>
<td style="text-align:center">Complex Variables</td>
<td style="text-align:center">å¤æ‚å˜é‡</td>
</tr>
<tr>
<td style="text-align:center">math.DG</td>
<td style="text-align:center">Differential Geometry</td>
<td style="text-align:center">å¾®åˆ†å‡ ä½•</td>
</tr>
<tr>
<td style="text-align:center">math.DS</td>
<td style="text-align:center">Dynamical Systems</td>
<td style="text-align:center">åŠ¨åŠ›ç³»ç»Ÿ</td>
</tr>
<tr>
<td style="text-align:center">math.FA</td>
<td style="text-align:center">Functional Analysis</td>
<td style="text-align:center">åŠŸèƒ½åˆ†æ</td>
</tr>
<tr>
<td style="text-align:center">math.GM</td>
<td style="text-align:center">General Mathematics</td>
<td style="text-align:center">æ™®é€šæ•°å­¦</td>
</tr>
<tr>
<td style="text-align:center">math.GN</td>
<td style="text-align:center">General Topology</td>
<td style="text-align:center">ç‚¹é›†æ‹“æ‰‘å­¦</td>
</tr>
<tr>
<td style="text-align:center">math.GR</td>
<td style="text-align:center">Group Theory</td>
<td style="text-align:center">ç¾¤è®º</td>
</tr>
<tr>
<td style="text-align:center">math.GT</td>
<td style="text-align:center">Geometric Topology</td>
<td style="text-align:center">å‡ ä½•æ‹“æ‰‘å­¦</td>
</tr>
<tr>
<td style="text-align:center">math.HO</td>
<td style="text-align:center">History and Overview</td>
<td style="text-align:center">å†å²å’Œæ¦‚è¿°</td>
</tr>
<tr>
<td style="text-align:center">math.IT</td>
<td style="text-align:center">Information Theory</td>
<td style="text-align:center">ä¿¡æ¯ç†è®º</td>
</tr>
<tr>
<td style="text-align:center">math.KT</td>
<td style="text-align:center">K-Theory and Homology</td>
<td style="text-align:center">K ç†è®ºä¸åŒè°ƒ</td>
</tr>
<tr>
<td style="text-align:center">math.LO</td>
<td style="text-align:center">Logic</td>
<td style="text-align:center">é€»è¾‘</td>
</tr>
<tr>
<td style="text-align:center">math.MG</td>
<td style="text-align:center">Metric Geometry</td>
<td style="text-align:center">åº¦é‡å‡ ä½•å­¦</td>
</tr>
<tr>
<td style="text-align:center">math.MP</td>
<td style="text-align:center">Mathematical Physics</td>
<td style="text-align:center">æ•°å­¦ç‰©ç†</td>
</tr>
<tr>
<td style="text-align:center">math.NA</td>
<td style="text-align:center">Numerical Analysis</td>
<td style="text-align:center">æ•°å€¼åˆ†æ</td>
</tr>
<tr>
<td style="text-align:center">math.NT</td>
<td style="text-align:center">Number Theory</td>
<td style="text-align:center">æ•°è®º</td>
</tr>
<tr>
<td style="text-align:center">math.OA</td>
<td style="text-align:center">Operator Algebras</td>
<td style="text-align:center">ç®—å­ä»£æ•°</td>
</tr>
<tr>
<td style="text-align:center">math.OC</td>
<td style="text-align:center">Optimization and Control</td>
<td style="text-align:center">ä¼˜åŒ–å’Œæ§åˆ¶</td>
</tr>
<tr>
<td style="text-align:center">math.PR</td>
<td style="text-align:center">Probability</td>
<td style="text-align:center">æ¦‚ç‡</td>
</tr>
<tr>
<td style="text-align:center">math.QA</td>
<td style="text-align:center">Quantum Algebra</td>
<td style="text-align:center">é‡å­ä»£æ•°</td>
</tr>
<tr>
<td style="text-align:center">math.RA</td>
<td style="text-align:center">Rings and Algebras</td>
<td style="text-align:center">ç¯ä¸ä»£æ•°</td>
</tr>
<tr>
<td style="text-align:center">math.RT</td>
<td style="text-align:center">Representation Theory</td>
<td style="text-align:center">è¡¨ç¤ºè®º</td>
</tr>
<tr>
<td style="text-align:center">math.SG</td>
<td style="text-align:center">Symplectic Geometry</td>
<td style="text-align:center">è¾›å‡ ä½•</td>
</tr>
<tr>
<td style="text-align:center">math.SP</td>
<td style="text-align:center">Spectral Theory</td>
<td style="text-align:center">å…‰è°±ç†è®º</td>
</tr>
<tr>
<td style="text-align:center">math.ST</td>
<td style="text-align:center">Statistics Theory</td>
<td style="text-align:center">ç»Ÿè®¡å­¦ç†è®º</td>
</tr>
<tr>
<td style="text-align:center">math-ph</td>
<td style="text-align:center">Mathematical Physics</td>
<td style="text-align:center">æ•°å­¦ç‰©ç†</td>
</tr>
<tr>
<td style="text-align:center">nlin.AO</td>
<td style="text-align:center">Adaptation and Self-Organizing Systems</td>
<td style="text-align:center">é€‚åº”ä¸è‡ªç»„ç»‡ç³»ç»Ÿ</td>
</tr>
<tr>
<td style="text-align:center">nlin.CD</td>
<td style="text-align:center">Chaotic Dynamics</td>
<td style="text-align:center">æ··æ²ŒåŠ¨åŠ›å­¦</td>
</tr>
<tr>
<td style="text-align:center">nlin.CG</td>
<td style="text-align:center">Cellular Automata and Lattice Gases</td>
<td style="text-align:center">å…ƒèƒè‡ªåŠ¨æœºä¸æ ¼å­æ°”ä½“</td>
</tr>
<tr>
<td style="text-align:center">nlin.PS</td>
<td style="text-align:center">Pattern Formation and Solitons</td>
<td style="text-align:center">æ¨¡å¼å½¢æˆä¸å­¤å­</td>
</tr>
<tr>
<td style="text-align:center">nlin.SI</td>
<td style="text-align:center">Exactly Solvable and Integrable Systems</td>
<td style="text-align:center">ä¸¥æ ¼å¯è§£å¯ç§¯ç³»ç»Ÿ</td>
</tr>
<tr>
<td style="text-align:center">nucl-ex</td>
<td style="text-align:center">Nuclear Experiment</td>
<td style="text-align:center">æ ¸è¯•éªŒ</td>
</tr>
<tr>
<td style="text-align:center">nucl-th</td>
<td style="text-align:center">Nuclear Theory</td>
<td style="text-align:center">æ ¸ç†è®º</td>
</tr>
<tr>
<td style="text-align:center">physics.acc-ph</td>
<td style="text-align:center">Accelerator Physics</td>
<td style="text-align:center">åŠ é€Ÿå™¨ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.ao-ph</td>
<td style="text-align:center">Atmospheric and Oceanic Physics</td>
<td style="text-align:center">å¤§æ°”å’Œæµ·æ´‹ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.app-ph</td>
<td style="text-align:center">Applied Physics</td>
<td style="text-align:center">åº”ç”¨ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.atm-clus</td>
<td style="text-align:center">Atomic and Molecular Clusters</td>
<td style="text-align:center">åŸå­å’Œåˆ†å­å›¢ç°‡</td>
</tr>
<tr>
<td style="text-align:center">physics.atom-ph</td>
<td style="text-align:center">Atomic Physics</td>
<td style="text-align:center">åŸå­ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.bio-ph</td>
<td style="text-align:center">Biological Physics</td>
<td style="text-align:center">ç”Ÿç‰©ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.chem-ph</td>
<td style="text-align:center">Chemical Physics</td>
<td style="text-align:center">åŒ–å­¦ç‰©ç†</td>
</tr>
<tr>
<td style="text-align:center">physics.class-ph</td>
<td style="text-align:center">Classical Physics</td>
<td style="text-align:center">ç»å…¸ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.comp-ph</td>
<td style="text-align:center">Computational Physics</td>
<td style="text-align:center">è®¡ç®—ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.data-an</td>
<td style="text-align:center">Data Analysis, Statistics and Probability</td>
<td style="text-align:center">æ•°æ®åˆ†æã€ç»Ÿè®¡å’Œæ¦‚ç‡</td>
</tr>
<tr>
<td style="text-align:center">physics.ed-ph</td>
<td style="text-align:center">Physics Education</td>
<td style="text-align:center">ç‰©ç†æ•™è‚²</td>
</tr>
<tr>
<td style="text-align:center">physics.flu-dyn</td>
<td style="text-align:center">Fluid Dynamics</td>
<td style="text-align:center">æµä½“åŠ¨åŠ›å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.gen-ph</td>
<td style="text-align:center">General Physics</td>
<td style="text-align:center">æ™®é€šç‰©ç†</td>
</tr>
<tr>
<td style="text-align:center">physics.geo-ph</td>
<td style="text-align:center">Geophysics</td>
<td style="text-align:center">åœ°çƒç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.hist-ph</td>
<td style="text-align:center">History and Philosophy of Physics</td>
<td style="text-align:center">ç‰©ç†å­¦çš„å†å²ä¸å“²å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.ins-det</td>
<td style="text-align:center">Instrumentation and Detectors</td>
<td style="text-align:center">ä»ªå™¨å’Œæ¢æµ‹å™¨</td>
</tr>
<tr>
<td style="text-align:center">physics.med-ph</td>
<td style="text-align:center">Medical Physics</td>
<td style="text-align:center">åŒ»å­¦ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.optics</td>
<td style="text-align:center">Optics</td>
<td style="text-align:center">å…‰å­¦</td>
</tr>
<tr>
<td style="text-align:center">physics.plasm-ph</td>
<td style="text-align:center">Plasma Physics</td>
<td style="text-align:center">ç­‰ç¦»å­ä½“ç‰©ç†</td>
</tr>
<tr>
<td style="text-align:center">physics.pop-ph</td>
<td style="text-align:center">Popular Physics</td>
<td style="text-align:center">å¤§ä¼—ç‰©ç†</td>
</tr>
<tr>
<td style="text-align:center">physics.soc-ph</td>
<td style="text-align:center">Physics and Society</td>
<td style="text-align:center">ç‰©ç†å­¦ä¸ç¤¾ä¼š</td>
</tr>
<tr>
<td style="text-align:center">physics.space-ph</td>
<td style="text-align:center">Space Physics</td>
<td style="text-align:center">ç©ºé—´ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">q-bio.BM</td>
<td style="text-align:center">Biomolecules</td>
<td style="text-align:center">ç”Ÿç‰©åˆ†å­</td>
</tr>
<tr>
<td style="text-align:center">q-bio.CB</td>
<td style="text-align:center">Cell Behavior</td>
<td style="text-align:center">ç»†èƒè¡Œä¸º</td>
</tr>
<tr>
<td style="text-align:center">q-bio.GN</td>
<td style="text-align:center">Genomics</td>
<td style="text-align:center">åŸºå› ç»„å­¦</td>
</tr>
<tr>
<td style="text-align:center">q-bio.MN</td>
<td style="text-align:center">Molecular Networks</td>
<td style="text-align:center">åˆ†å­ç½‘ç»œ</td>
</tr>
<tr>
<td style="text-align:center">q-bio.NC</td>
<td style="text-align:center">Neurons and Cognition</td>
<td style="text-align:center">ç¥ç»å…ƒä¸è®¤çŸ¥</td>
</tr>
<tr>
<td style="text-align:center">q-bio.OT</td>
<td style="text-align:center">Other Quantitative Biology</td>
<td style="text-align:center">å…¶ä»–å®šé‡ç”Ÿç‰©å­¦</td>
</tr>
<tr>
<td style="text-align:center">q-bio.PE</td>
<td style="text-align:center">Populations and Evolution</td>
<td style="text-align:center">ç§ç¾¤ä¸è¿›åŒ–</td>
</tr>
<tr>
<td style="text-align:center">q-bio.QM</td>
<td style="text-align:center">Quantitative Methods</td>
<td style="text-align:center">å®šé‡æ–¹æ³•</td>
</tr>
<tr>
<td style="text-align:center">q-bio.SC</td>
<td style="text-align:center">Subcellular Processes</td>
<td style="text-align:center">äºšç»†èƒçªèµ·</td>
</tr>
<tr>
<td style="text-align:center">q-bio.TO</td>
<td style="text-align:center">Tissues and Organs</td>
<td style="text-align:center">ç»„ç»‡å’Œå™¨å®˜</td>
</tr>
<tr>
<td style="text-align:center">q-fin.CP</td>
<td style="text-align:center">Computational Finance</td>
<td style="text-align:center">é‡‘èå·¥ç¨‹</td>
</tr>
<tr>
<td style="text-align:center">q-fin.EC</td>
<td style="text-align:center">Economics</td>
<td style="text-align:center">ç»æµå­¦</td>
</tr>
<tr>
<td style="text-align:center">q-fin.GN</td>
<td style="text-align:center">General Finance</td>
<td style="text-align:center">è´¢åŠ¡æ¦‚è¿°</td>
</tr>
<tr>
<td style="text-align:center">q-fin.MF</td>
<td style="text-align:center">Mathematical Finance</td>
<td style="text-align:center">æ•°å­¦é‡‘è</td>
</tr>
<tr>
<td style="text-align:center">q-fin.PM</td>
<td style="text-align:center">Portfolio Management</td>
<td style="text-align:center">æŠ•èµ„ç»„åˆç®¡ç†</td>
</tr>
<tr>
<td style="text-align:center">q-fin.PR</td>
<td style="text-align:center">Pricing of Securities</td>
<td style="text-align:center">è¯åˆ¸å®šä»·</td>
</tr>
<tr>
<td style="text-align:center">q-fin.RM</td>
<td style="text-align:center">Risk Management</td>
<td style="text-align:center">é£é™©ç®¡ç†</td>
</tr>
<tr>
<td style="text-align:center">q-fin.ST</td>
<td style="text-align:center">Statistical Finance</td>
<td style="text-align:center">é‡‘èç»Ÿè®¡</td>
</tr>
<tr>
<td style="text-align:center">q-fin.TR</td>
<td style="text-align:center">Trading and Market Microstructure</td>
<td style="text-align:center">äº¤æ˜“ä¸å¸‚åœºå¾®è§‚ç»“æ„</td>
</tr>
<tr>
<td style="text-align:center">quant-ph</td>
<td style="text-align:center">Quantum Physics</td>
<td style="text-align:center">é‡å­ç‰©ç†å­¦</td>
</tr>
<tr>
<td style="text-align:center">stat.AP</td>
<td style="text-align:center">Applications</td>
<td style="text-align:center">åº”ç”¨</td>
</tr>
<tr>
<td style="text-align:center">stat.CO</td>
<td style="text-align:center">Computation</td>
<td style="text-align:center">è®¡ç®—</td>
</tr>
<tr>
<td style="text-align:center">stat.ME</td>
<td style="text-align:center">Methodology</td>
<td style="text-align:center">æ–¹æ³•è®º</td>
</tr>
<tr>
<td style="text-align:center">stat.ML</td>
<td style="text-align:center">Machine Learning</td>
<td style="text-align:center">æœºå™¨å­¦ä¹ </td>
</tr>
<tr>
<td style="text-align:center">stat.OT</td>
<td style="text-align:center">Other Statistics</td>
<td style="text-align:center">å…¶ä»–ç»Ÿè®¡å­¦</td>
</tr>
<tr>
<td style="text-align:center">stat.TH</td>
<td style="text-align:center">Statistics Theory</td>
<td style="text-align:center">ç»Ÿè®¡å­¦ç†è®º</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Failed building wheel for PyAudio  è§£å†³æ–¹æ³•</title>
    <url>/2024/01/28/Note/pyaudio/</url>
    <content><![CDATA[<h2 id="Failed-building-wheel-for-PyAudio-è§£å†³æ–¹æ³•"><a href="#Failed-building-wheel-for-PyAudio-è§£å†³æ–¹æ³•" class="headerlink" title="Failed building wheel for PyAudio  è§£å†³æ–¹æ³•"></a>Failed building wheel for PyAudio  è§£å†³æ–¹æ³•</h2><p>æœ‰æ—¶å€™åœ¨å®‰è£…pyaudioçš„æ—¶å€™ï¼Œæ€»æ˜¯æœ‰æ—¶å€™é‡è§ä¸€äº›é”™è¯¯ï¼Œå¦‚ä¸‹</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">  Building wheel <span class="keyword">for</span> pyaudio (pyproject.toml) ... error</span><br><span class="line">  error: subprocess-exited-with-error</span><br><span class="line"></span><br><span class="line">  Ã— Building wheel <span class="keyword">for</span> pyaudio (pyproject.toml) did not run successfully.</span><br><span class="line">  â”‚ <span class="built_in">exit</span> code: 1</span><br><span class="line">  â•°â”€&gt; [18 lines of output]</span><br><span class="line">      running bdist_wheel</span><br><span class="line">      running build</span><br><span class="line">      running build_py</span><br><span class="line">      creating build</span><br><span class="line">      creating build/lib.linux-x86_64-cpython-310</span><br><span class="line">      creating build/lib.linux-x86_64-cpython-310/pyaudio</span><br><span class="line">      copying src/pyaudio/__init__.py -&gt; build/lib.linux-x86_64-cpython-310/pyaudio</span><br><span class="line">      running build_ext</span><br><span class="line">      building <span class="string">'pyaudio._portaudio'</span> extension</span><br><span class="line">      creating build/temp.linux-x86_64-cpython-310</span><br><span class="line">      creating build/temp.linux-x86_64-cpython-310/src</span><br><span class="line">      creating build/temp.linux-x86_64-cpython-310/src/pyaudio</span><br><span class="line">      gcc -pthread -B anaconda3/envs/ernerf/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem anaconda3/envs/ernerf/include -fPIC -O2 -isystem anaconda3/envs/ernerf/include -fPIC -I/usr/local/include -I/usr/include -Ianaconda3/envs/ernerf/include/python3.10 -c src/pyaudio/device_api.c -o build/temp.linux-x86_64-cpython-310/src/pyaudio/device_api.o</span><br><span class="line">      src/pyaudio/device_api.c:9:10: fatal error: portaudio.h: No such file or directory</span><br><span class="line">          9 | <span class="comment">#include "portaudio.h"</span></span><br><span class="line">            |          ^~~~~~~~~~~~~</span><br><span class="line">      compilation terminated.</span><br><span class="line">      error: <span class="built_in">command</span> <span class="string">'/usr/bin/gcc'</span> failed with <span class="built_in">exit</span> code 1</span><br><span class="line">      [end of output]</span><br><span class="line"></span><br><span class="line">  note: This error originates from a subprocess, and is likely not a problem with pip.</span><br><span class="line">  ERROR: Failed building wheel <span class="keyword">for</span> pyaudio</span><br><span class="line">Successfully built python_speech_features</span><br><span class="line">Failed to build pyaudio</span><br><span class="line">ERROR: Could not build wheels <span class="keyword">for</span> pyaudio, <span class="built_in">which</span> is required to install pyproject.toml-based projects</span><br></pre></td></tr></tbody></table></figure>
<p>å¦‚æœå•çº¯æŸ¥åé¢è¿™ä¸€å¥ï¼Œä¼šå‘ç°æ‰¾ä¸åˆ°ä»€ä¹ˆé”™è¯¯ï¼Œæœ€åæˆ‘æ‰¾åˆ°äº†å¯¹åº”çš„è§£å†³åŠæ³•ï¼Œå®é™…ä¸Šæ˜¯linuxæœ‰ä¸€äº›åº“æ²¡å®‰è£…ä¸Šï¼Œç”¨rootæƒé™è£…ä¸€ä¸‹å³å¯</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># æœ‰äº›äººè¯´è¿™æ ·å³å¯</span></span><br><span class="line">sudo apt-get install portaudio19-dev</span><br><span class="line"><span class="comment"># å¦‚æœä¸è¡Œå°±è¯•ä¸€ä¸‹è¿™æ ·</span></span><br><span class="line">sudo apt-get install libasound-dev portaudio19-dev libportaudio2 libportaudiocpp0</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™æ ·å®‰è£…å®Œä»¥åï¼Œæˆ‘ä»¬å°±å¯ä»¥æ­£å¸¸å®‰è£…pyaudioäº†</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install pyaudio</span><br></pre></td></tr></tbody></table></figure>
<p>æˆ‘ä¹Ÿåœ¨githubä¸Šçœ‹åˆ°çš„ç›¸å…³å¸–å­ï¼Œå¤§å®¶ä¹Ÿå¯ä»¥å‚è€ƒï¼š<a href="https://github.com/ardha27/AI-Waifu-Vtuber/issues/49">https://github.com/ardha27/AI-Waifu-Vtuber/issues/49</a>ï¼Œè€Œä¸”è¿™é‡Œé¢æœ‰ä¸ªwindowsçš„è§£å†³æ–¹æ³•ï¼Œè¿˜è›®æœ‰è¶£ï¼Œæˆ‘è¿˜æ²¡è¯•è¿‡</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install pipwin</span><br><span class="line">pipwin install pyaudio</span><br><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></tbody></table></figure>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>FastAPI å¿«é€Ÿæ•™ç¨‹: ä»é›¶å¼€å§‹æ„å»ºä½ çš„ç¬¬ä¸€ä¸ªAPIé¡¹ç›®</title>
    <url>/2024/01/19/Note/fastapi/</url>
    <content><![CDATA[<p>æœ€è¿‘åœ¨å­¦ä¹ å¤§æ¨¡å‹çš„æ—¶å€™ï¼Œæœ‰æ—¶å€™ä¼šé‡åˆ°è¦å†™APIçš„æ—¶å€™ï¼Œè¿™ä¸ªæ—¶å€™æˆ‘å°±é‡è§äº†FastAPIï¼Œæˆ‘å‘ç°è¿™ä¸ªæ˜¯ä¸€ä¸ªå¾ˆå¥½çš„åº“ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªå±äºè‡ªå·±çš„APIï¼Œæ‰€ä»¥ä»Šå¤©æˆ‘ä¹Ÿå†™ä¸€ä¸‹è¿™ä¸ªå…¥é—¨æ•™ç¨‹å’Œå¤§å®¶ä¸€èµ·åˆ†äº«ä¸€ä¸‹ï¼ŒåŒæ—¶ä¹Ÿè®©æˆ‘ä»¬è§£å¯†ä¸€ä¸‹ï¼ŒOpenAIå’Œä¸€äº›å…¬å¸çš„APIï¼Œå¯èƒ½æ˜¯æ€ä¹ˆå†™å’Œæ€ä¹ˆåšçš„ã€‚</p>
<p><img src="https://picx.zhimg.com/80/v2-f7dc5c12cb693d83a113359819a1f26e_720w.png?source=d16d100b" alt="FastAPI framework, high performance, easy to learn, fast to code, ready for production"></p>
<h2 id="FastAPIä»‹ç»"><a href="#FastAPIä»‹ç»" class="headerlink" title="FastAPIä»‹ç»"></a>FastAPIä»‹ç»</h2><p>FastAPI æ˜¯ä¸€ä¸ªç”¨äºæ„å»º API çš„ç°ä»£ã€å¿«é€Ÿï¼ˆé«˜æ€§èƒ½ï¼‰çš„ web æ¡†æ¶ï¼Œä½¿ç”¨ Python 3.8+ å¹¶åŸºäºæ ‡å‡†çš„ Python ç±»å‹æç¤ºã€‚</p>
<p><strong>æ–‡æ¡£</strong>ï¼š <a href="https://fastapi.tiangolo.com/">https://fastapi.tiangolo.com</a></p>
<p><strong>æºç </strong>ï¼š <a href="https://github.com/tiangolo/fastapi">https://github.com/tiangolo/fastapi</a></p>
<p>å…³é”®ç‰¹æ€§:</p>
<ul>
<li><strong>å¿«é€Ÿ</strong>ï¼šå¯ä¸ <strong>NodeJS</strong> å’Œ <strong>Go</strong> å¹¶è‚©çš„æé«˜æ€§èƒ½ï¼ˆå½’åŠŸäº Starlette å’Œ Pydanticï¼‰ã€‚<a href="https://fastapi.tiangolo.com/zh/#_11">æœ€å¿«çš„ Python web æ¡†æ¶ä¹‹ä¸€</a>ã€‚</li>
<li><strong>é«˜æ•ˆç¼–ç </strong>ï¼šæé«˜åŠŸèƒ½å¼€å‘é€Ÿåº¦çº¦ 200ï¼… è‡³ 300ï¼…ã€‚*</li>
<li><strong>æ›´å°‘ bug</strong>ï¼šå‡å°‘çº¦ 40ï¼… çš„äººä¸ºï¼ˆå¼€å‘è€…ï¼‰å¯¼è‡´é”™è¯¯ã€‚*</li>
<li><strong>æ™ºèƒ½</strong>ï¼šæä½³çš„ç¼–è¾‘å™¨æ”¯æŒã€‚å¤„å¤„çš†å¯è‡ªåŠ¨è¡¥å…¨ï¼Œå‡å°‘è°ƒè¯•æ—¶é—´ã€‚</li>
<li><strong>ç®€å•</strong>ï¼šè®¾è®¡çš„æ˜“äºä½¿ç”¨å’Œå­¦ä¹ ï¼Œé˜…è¯»æ–‡æ¡£çš„æ—¶é—´æ›´çŸ­ã€‚</li>
<li><strong>ç®€çŸ­</strong>ï¼šä½¿ä»£ç é‡å¤æœ€å°åŒ–ã€‚é€šè¿‡ä¸åŒçš„å‚æ•°å£°æ˜å®ç°ä¸°å¯ŒåŠŸèƒ½ã€‚bug æ›´å°‘ã€‚</li>
<li><strong>å¥å£®</strong>ï¼šç”Ÿäº§å¯ç”¨çº§åˆ«çš„ä»£ç ã€‚è¿˜æœ‰è‡ªåŠ¨ç”Ÿæˆçš„äº¤äº’å¼æ–‡æ¡£ã€‚</li>
<li><strong>æ ‡å‡†åŒ–</strong>ï¼šåŸºäºï¼ˆå¹¶å®Œå…¨å…¼å®¹ï¼‰API çš„ç›¸å…³å¼€æ”¾æ ‡å‡†ï¼š<a href="https://github.com/OAI/OpenAPI-Specification">OpenAPI</a> (ä»¥å‰è¢«ç§°ä¸º Swagger) å’Œ <a href="https://json-schema.org/">JSON Schema</a>ã€‚</li>
</ul>
<h2 id="å®‰è£…åŠä¾èµ–"><a href="#å®‰è£…åŠä¾èµ–" class="headerlink" title="å®‰è£…åŠä¾èµ–"></a>å®‰è£…åŠä¾èµ–</h2><p>Python 3.8 åŠæ›´é«˜ç‰ˆæœ¬</p>
<p>FastAPI ç«™åœ¨ä»¥ä¸‹å·¨äººçš„è‚©è†€ä¹‹ä¸Šï¼š</p>
<ul>
<li><a href="https://www.starlette.io/">Starlette</a> è´Ÿè´£ web éƒ¨åˆ†ã€‚</li>
<li><a href="https://pydantic-docs.helpmanual.io/">Pydantic</a> è´Ÿè´£æ•°æ®éƒ¨åˆ†ã€‚</li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install fastapi</span><br></pre></td></tr></tbody></table></figure>
<p>æˆ‘ä»¬æœ‰å¯èƒ½è¿˜ä¼šéœ€è¦ä¸€ä¸ª ASGI æœåŠ¡å™¨ï¼Œå¯ä»¥ä½¿ç”¨<a href="https://www.uvicorn.org/">Uvicorn</a></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install unvicorn</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ç¤ºä¾‹"><a href="#ç¤ºä¾‹" class="headerlink" title="ç¤ºä¾‹"></a>ç¤ºä¾‹</h2><h3 id="åˆ›å»º"><a href="#åˆ›å»º" class="headerlink" title="åˆ›å»º"></a>åˆ›å»º</h3><p>åˆ›å»ºä¸€ä¸ª main.py æ–‡ä»¶å¹¶å†™å…¥ä»¥ä¸‹å†…å®¹:</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">"/"</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_root</span>():</span><br><span class="line">    <span class="keyword">return</span> {<span class="string">"Hello"</span>: <span class="string">"World"</span>}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">"/items/{item_id}"</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_item</span>(<span class="params">item_id: <span class="built_in">int</span>, q: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="literal">None</span>] = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">return</span> {<span class="string">"item_id"</span>: item_id, <span class="string">"q"</span>: q}</span><br></pre></td></tr></tbody></table></figure>
<p>å¦‚æœæˆ‘ä»¬éœ€è¦åŠ å…¥å¼‚æ­¥ç¼–ç¨‹çš„è¯ï¼Œæˆ‘ä»¬å°±éœ€è¦æ”¹ä¸€ä¸‹ä»£ç ï¼ŒåŠ å…¥async/awaitå’Œasync def </p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">Union</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI</span><br><span class="line"></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">"/"</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">read_root</span>():</span><br><span class="line">    <span class="keyword">return</span> {<span class="string">"Hello"</span>: <span class="string">"World"</span>}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.get(<span class="params"><span class="string">"/items/{item_id}"</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">read_item</span>(<span class="params">item_id: <span class="built_in">int</span>, q: <span class="type">Union</span>[<span class="built_in">str</span>, <span class="literal">None</span>] = <span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">return</span> {<span class="string">"item_id"</span>: item_id, <span class="string">"q"</span>: q}</span><br></pre></td></tr></tbody></table></figure>
<p>å¦‚æœå¯¹äºå¼‚æ­¥ç¼–ç¨‹æœ‰ç‚¹å…´è¶£çš„è¯ï¼Œå¯ä»¥çœ‹çœ‹è¿™ä¸ªè®²è§£ï¼Œæˆ‘è§‰å¾—è¿˜æ˜¯å¾ˆä¸é”™çš„ï¼Œè¿™ä¹ŸåŠ å¼ºäº†ä»£ç çš„å¹¶å‘èƒ½åŠ›ã€‚</p>
<h3 id="è¿è¡Œ"><a href="#è¿è¡Œ" class="headerlink" title="è¿è¡Œ"></a>è¿è¡Œ</h3><p>é€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿›è¡Œè¿è¡ŒæœåŠ¡å™¨</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">$ uvicorn main:app --reload</span><br><span class="line"></span><br><span class="line">INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)</span><br><span class="line">INFO:     Started reloader process [28720]</span><br><span class="line">INFO:     Started server process [28722]</span><br><span class="line">INFO:     Waiting <span class="keyword">for</span> application startup.</span><br><span class="line">INFO:     Application startup complete.</span><br></pre></td></tr></tbody></table></figure>
<p>uvicorn main:app å‘½ä»¤å«ä¹‰å¦‚ä¸‹:</p>
<ul>
<li>mainï¼šmain.py æ–‡ä»¶ï¼ˆä¸€ä¸ª Python â€œæ¨¡å—â€ï¼‰ã€‚</li>
<li>appï¼šåœ¨ main.py æ–‡ä»¶ä¸­é€šè¿‡ app = FastAPI() åˆ›å»ºçš„å¯¹è±¡ã€‚</li>
<li>â€”reloadï¼šè®©æœåŠ¡å™¨åœ¨æ›´æ–°ä»£ç åé‡æ–°å¯åŠ¨ã€‚ä»…åœ¨å¼€å‘æ—¶ä½¿ç”¨è¯¥é€‰é¡¹ã€‚</li>
</ul>
<p>è¿™é‡Œé¢ç€é‡æä¸€ä¸‹<strong>reolabå‚æ•°</strong>ï¼Œè¿™ä¸ªç›¸å½“äºæˆ‘ä»¬åœ¨å¼€å‘æ˜¯å¯¹ä»£ç è¿›è¡Œä¿®æ”¹çš„åŒæ—¶ï¼ŒæœåŠ¡å™¨ä¹Ÿåœ¨å˜åŒ–ï¼Œè¿™æ ·å°±æ–¹ä¾¿æˆ‘ä»¬è¿›è¡Œå¼€å‘å’Œå­¦ä¹ ï¼Œä½†æ˜¯å¦‚æœå¼€å‘å®Œæ¯•ä»¥åï¼Œæˆ‘ä»¬å¯ä»¥å»æ‰<strong>â€”reload</strong>ï¼Œé˜²æ­¢ä¸å°å¿ƒåŠ¨åˆ°ä»£ç æ”¹å˜äº†apiçš„è®¿é—®</p>
<h3 id="æ£€æŸ¥"><a href="#æ£€æŸ¥" class="headerlink" title="æ£€æŸ¥"></a><strong>æ£€æŸ¥</strong></h3><p>ä½¿ç”¨æµè§ˆå™¨è®¿é—® <a href="http://127.0.0.1:8000/items/5?q=somequeryã€‚">http://127.0.0.1:8000/items/5?q=somequeryã€‚</a></p>
<p>ä½ å°†ä¼šçœ‹åˆ°å¦‚ä¸‹ JSON å“åº”ï¼š</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">{"item_id": 5, "q": "somequery"}</span><br></pre></td></tr></tbody></table></figure>
<p>ä½ å·²ç»åˆ›å»ºäº†ä¸€ä¸ªå…·æœ‰ä»¥ä¸‹åŠŸèƒ½çš„ APIï¼š</p>
<ul>
<li>é€šè¿‡ <em>è·¯å¾„</em> / å’Œ /items/{item_id} æ¥å— HTTP è¯·æ±‚ã€‚</li>
<li>ä»¥ä¸Š <em>è·¯å¾„</em> éƒ½æ¥å— GET <em>æ“ä½œ</em>ï¼ˆä¹Ÿè¢«ç§°ä¸º HTTP <em>æ–¹æ³•</em>ï¼‰ã€‚</li>
<li>/items/{item_id} <em>è·¯å¾„</em> æœ‰ä¸€ä¸ª <em>è·¯å¾„å‚æ•°</em> item_id å¹¶ä¸”åº”è¯¥ä¸º int ç±»å‹ã€‚</li>
<li>/items/{item_id} <em>è·¯å¾„</em> æœ‰ä¸€ä¸ªå¯é€‰çš„ str ç±»å‹çš„ <em>æŸ¥è¯¢å‚æ•°</em> qã€‚</li>
</ul>
<h2 id="APIæ–‡æ¡£"><a href="#APIæ–‡æ¡£" class="headerlink" title="APIæ–‡æ¡£"></a>APIæ–‡æ¡£</h2><h3 id="äº¤äº’å¼-API-æ–‡æ¡£"><a href="#äº¤äº’å¼-API-æ–‡æ¡£" class="headerlink" title="äº¤äº’å¼ API æ–‡æ¡£"></a><strong>äº¤äº’å¼ API æ–‡æ¡£</strong></h3><p>ç°åœ¨è®¿é—® <a href="http://127.0.0.1:8000/docsã€‚">http://127.0.0.1:8000/docsã€‚</a></p>
<p>ä½ ä¼šçœ‹åˆ°è‡ªåŠ¨ç”Ÿæˆçš„äº¤äº’å¼ API æ–‡æ¡£ï¼ˆç”± <a href="https://github.com/swagger-api/swagger-ui">Swagger UI</a>ç”Ÿæˆï¼‰ï¼š</p>
<p><img src="https://picx.zhimg.com/80/v2-39fe8891285bf578eee8466c4aec1b52_720w.png?source=d16d100b" alt="äº¤äº’å¼ API æ–‡æ¡£"></p>
<h3 id="å¯é€‰çš„-API-æ–‡æ¡£"><a href="#å¯é€‰çš„-API-æ–‡æ¡£" class="headerlink" title="å¯é€‰çš„ API æ–‡æ¡£"></a>å¯é€‰çš„ API æ–‡æ¡£</h3><p>è®¿é—® <a href="http://127.0.0.1:8000/redocã€‚">http://127.0.0.1:8000/redocã€‚</a></p>
<p>ä½ ä¼šçœ‹åˆ°å¦ä¸€ä¸ªè‡ªåŠ¨ç”Ÿæˆçš„æ–‡æ¡£ï¼ˆç”± <a href="https://github.com/Rebilly/ReDoc">ReDoc</a> ç”Ÿæˆï¼‰ï¼š</p>
<p><img src="https://picx.zhimg.com/80/v2-23ae5bafaed6faf6ced83d987b17fc98_720w.png?source=d16d100b" alt="å¯é€‰çš„ API æ–‡æ¡£"></p>
<h2 id="å¤§æ¨¡å‹APIå®æˆ˜"><a href="#å¤§æ¨¡å‹APIå®æˆ˜" class="headerlink" title="å¤§æ¨¡å‹APIå®æˆ˜"></a>å¤§æ¨¡å‹APIå®æˆ˜</h2><p>æ¯”å¦‚æˆ‘ç°åœ¨æƒ³ä½¿ç”¨ä¸€ä¸ªå¤§æ¨¡å‹ï¼Œæ¯”å¦‚å°±æ˜¯é˜¿é‡Œçš„é€šä¹‰åƒé—®çš„å¤§æ¨¡å‹ï¼Œæˆ‘å¸Œæœ›èƒ½å†™ä¸€ä¸ªapiæ¥å£è¿›è¡Œå¯¹å…¶è°ƒç”¨ï¼Œæœ‰ç‚¹ç±»ä¼¼ä¸OpenAIä¸€æ ·å†™ä¸€ä¸ªæ¥å£ï¼Œè¿™æ ·å°±æ–¹ä¾¿æˆ‘ä»¬è¿›è¡Œå»è°ƒç”¨ï¼Œè€Œä¸ç”¨æ¯æ¬¡è·‘ä¸€å †ä»£ç ã€‚</p>
<h3 id="Qwenæ¨¡å‹ä¸‹è½½ä¸ä½¿ç”¨"><a href="#Qwenæ¨¡å‹ä¸‹è½½ä¸ä½¿ç”¨" class="headerlink" title="Qwenæ¨¡å‹ä¸‹è½½ä¸ä½¿ç”¨"></a>Qwenæ¨¡å‹ä¸‹è½½ä¸ä½¿ç”¨</h3><p>æ¯”å¦‚æˆ‘ä»¬å¯ä»¥ä»Qwenä¸­è·å–å¯¹åº”çš„æ¨¡å‹ï¼Œ<a href="https://huggingface.co/Qwen/Qwen-7B-Chat">https://huggingface.co/Qwen/Qwen-7B-Chat</a></p>
<p>ä»é‡Œé¢æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¤šè½®å¯¹è¯çš„å¿«é€Ÿä½¿ç”¨ä»£ç ï¼Œè¿™å¯¹æˆ‘ä»¬å†™APIæœ‰å¾ˆå¤§çš„å¸®åŠ©ï¼Œæˆ‘ä»¬ä»ä¸­å¯ä»¥çœ‹åˆ°ä¸»è¦çš„æµç¨‹ï¼Œå®é™…ä¸Šè¿˜æ˜¯è›®ç®€å•çš„ï¼Œå°±æ˜¯å¯¼å…¥æ¨¡å‹åï¼Œè¿›è¡Œä¼ å…¥å‚æ•°ï¼Œå‚æ•°ä¸€èˆ¬æœ‰ä¸‰ä¸ªï¼Œä¸€ä¸ªæ˜¯ä¸€å¼€å§‹å®šä¹‰çš„åˆ†è¯å™¨<strong>tokenizer</strong>ï¼Œå¦å¤–ä¸¤ä¸ªå°±æ¯”è¾ƒé‡è¦ï¼Œåˆ†åˆ«æ˜¯é—®é¢˜å’Œå†å²è®°å½•ï¼Œæ‰€ä»¥æˆ‘ä»¬å¸Œæœ›å¾—åˆ°çš„apiåº”è¯¥æ˜¯æœ‰è¿™ä¸¤ä¸ªè¾“å…¥çš„ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoModelForCausalLM, AutoTokenizer</span><br><span class="line"><span class="keyword">from</span> transformers.generation <span class="keyword">import</span> GenerationConfig</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note: The default behavior now has injection attack prevention off.</span></span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(<span class="string">"Qwen/Qwen-7B-Chat"</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># use bf16</span></span><br><span class="line"><span class="comment"># model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen-7B-Chat", device_map="auto", trust_remote_code=True, bf16=True).eval()</span></span><br><span class="line"><span class="comment"># use fp16</span></span><br><span class="line"><span class="comment"># model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen-7B-Chat", device_map="auto", trust_remote_code=True, fp16=True).eval()</span></span><br><span class="line"><span class="comment"># use cpu only</span></span><br><span class="line"><span class="comment"># model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen-7B-Chat", device_map="cpu", trust_remote_code=True).eval()</span></span><br><span class="line"><span class="comment"># use auto mode, automatically select precision based on the device.</span></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(<span class="string">"Qwen/Qwen-7B-Chat"</span>, device_map=<span class="string">"auto"</span>, trust_remote_code=<span class="literal">True</span>).<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify hyperparameters for generation. But if you use transformers&gt;=4.32.0, there is no need to do this.</span></span><br><span class="line"><span class="comment"># model.generation_config = GenerationConfig.from_pretrained("Qwen/Qwen-7B-Chat", trust_remote_code=True) # å¯æŒ‡å®šä¸åŒçš„ç”Ÿæˆé•¿åº¦ã€top_pç­‰ç›¸å…³è¶…å‚</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸€è½®å¯¹è¯ 1st dialogue turn</span></span><br><span class="line">response, history = model.chat(tokenizer, <span class="string">"ä½ å¥½"</span>, history=<span class="literal">None</span>)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="comment"># ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æä¾›å¸®åŠ©ã€‚</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬äºŒè½®å¯¹è¯ 2nd dialogue turn</span></span><br><span class="line">response, history = model.chat(tokenizer, <span class="string">"ç»™æˆ‘è®²ä¸€ä¸ªå¹´è½»äººå¥‹æ–—åˆ›ä¸šæœ€ç»ˆå–å¾—æˆåŠŸçš„æ•…äº‹ã€‚"</span>, history=history)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="comment"># è¿™æ˜¯ä¸€ä¸ªå…³äºä¸€ä¸ªå¹´è½»äººå¥‹æ–—åˆ›ä¸šæœ€ç»ˆå–å¾—æˆåŠŸçš„æ•…äº‹ã€‚</span></span><br><span class="line"><span class="comment"># æ•…äº‹çš„ä¸»äººå…¬å«ææ˜ï¼Œä»–æ¥è‡ªä¸€ä¸ªæ™®é€šçš„å®¶åº­ï¼Œçˆ¶æ¯éƒ½æ˜¯æ™®é€šçš„å·¥äººã€‚ä»å°ï¼Œææ˜å°±ç«‹ä¸‹äº†ä¸€ä¸ªç›®æ ‡ï¼šè¦æˆä¸ºä¸€åæˆåŠŸçš„ä¼ä¸šå®¶ã€‚</span></span><br><span class="line"><span class="comment"># ä¸ºäº†å®ç°è¿™ä¸ªç›®æ ‡ï¼Œææ˜å‹¤å¥‹å­¦ä¹ ï¼Œè€ƒä¸Šäº†å¤§å­¦ã€‚åœ¨å¤§å­¦æœŸé—´ï¼Œä»–ç§¯æå‚åŠ å„ç§åˆ›ä¸šæ¯”èµ›ï¼Œè·å¾—äº†ä¸å°‘å¥–é¡¹ã€‚ä»–è¿˜åˆ©ç”¨è¯¾ä½™æ—¶é—´å»å®ä¹ ï¼Œç§¯ç´¯äº†å®è´µçš„ç»éªŒã€‚</span></span><br><span class="line"><span class="comment"># æ¯•ä¸šåï¼Œææ˜å†³å®šå¼€å§‹è‡ªå·±çš„åˆ›ä¸šä¹‹è·¯ã€‚ä»–å¼€å§‹å¯»æ‰¾æŠ•èµ„æœºä¼šï¼Œä½†å¤šæ¬¡éƒ½è¢«æ‹’ç»äº†ã€‚ç„¶è€Œï¼Œä»–å¹¶æ²¡æœ‰æ”¾å¼ƒã€‚ä»–ç»§ç»­åŠªåŠ›ï¼Œä¸æ–­æ”¹è¿›è‡ªå·±çš„åˆ›ä¸šè®¡åˆ’ï¼Œå¹¶å¯»æ‰¾æ–°çš„æŠ•èµ„æœºä¼šã€‚</span></span><br><span class="line"><span class="comment"># æœ€ç»ˆï¼Œææ˜æˆåŠŸåœ°è·å¾—äº†ä¸€ç¬”æŠ•èµ„ï¼Œå¼€å§‹äº†è‡ªå·±çš„åˆ›ä¸šä¹‹è·¯ã€‚ä»–æˆç«‹äº†ä¸€å®¶ç§‘æŠ€å…¬å¸ï¼Œä¸“æ³¨äºå¼€å‘æ–°å‹è½¯ä»¶ã€‚åœ¨ä»–çš„é¢†å¯¼ä¸‹ï¼Œå…¬å¸è¿…é€Ÿå‘å±•èµ·æ¥ï¼Œæˆä¸ºäº†ä¸€å®¶æˆåŠŸçš„ç§‘æŠ€ä¼ä¸šã€‚</span></span><br><span class="line"><span class="comment"># ææ˜çš„æˆåŠŸå¹¶ä¸æ˜¯å¶ç„¶çš„ã€‚ä»–å‹¤å¥‹ã€åšéŸ§ã€å‹‡äºå†’é™©ï¼Œä¸æ–­å­¦ä¹ å’Œæ”¹è¿›è‡ªå·±ã€‚ä»–çš„æˆåŠŸä¹Ÿè¯æ˜äº†ï¼Œåªè¦åŠªåŠ›å¥‹æ–—ï¼Œä»»ä½•äººéƒ½æœ‰å¯èƒ½å–å¾—æˆåŠŸã€‚</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¬¬ä¸‰è½®å¯¹è¯ 3rd dialogue turn</span></span><br><span class="line">response, history = model.chat(tokenizer, <span class="string">"ç»™è¿™ä¸ªæ•…äº‹èµ·ä¸€ä¸ªæ ‡é¢˜"</span>, history=history)</span><br><span class="line"><span class="built_in">print</span>(response)</span><br><span class="line"><span class="comment"># ã€Šå¥‹æ–—åˆ›ä¸šï¼šä¸€ä¸ªå¹´è½»äººçš„æˆåŠŸä¹‹è·¯ã€‹</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="ç¼–å†™FastAPIä»£ç "><a href="#ç¼–å†™FastAPIä»£ç " class="headerlink" title="ç¼–å†™FastAPIä»£ç "></a>ç¼–å†™FastAPIä»£ç </h3><p>æ‰€ä»¥å¼„æ¸…æ¥šäº†åŸç†ä»¥åï¼Œæˆ‘ä»¬å°±å¯ä»¥å¼€å§‹åˆ©ç”¨FastAPIå†™ä»¥ä¸‹çš„ä»£ç äº†ï¼Œä¸ºäº†æ›´å¥½çš„ä½¿ç”¨apiï¼Œé™¤äº†promptå’Œhistoryä¸¤ä¸ªå‚æ•°ä¹‹å¤–ï¼Œè¿˜åŠ å…¥äº†max_lenthå’Œtemperatureç­‰å‚æ•°ï¼Œè¿™äº›å‚æ•°å®é™…ä¸Šéƒ½æ˜¯model.chaté‡Œé¢è¿›è¡Œä½¿ç”¨çš„ï¼Œè¿™æ ·æ›´å¥½çš„å»è®¾ç½®å’Œå­¦ä¹ ã€‚ç­‰åˆ°è¿”å›ç»“æœä»¥åï¼Œå°±ä¼šè¿”å›æ—¶é—´å’ŒæˆåŠŸçš„æ ‡å¿—ï¼Œè¿™æ ·æˆ‘ä»¬å°±è·å–äº†ç»“æœã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM, GenerationConfig</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®è®¾å¤‡å‚æ•°</span></span><br><span class="line">DEVICE = <span class="string">"cuda"</span>  <span class="comment"># ä½¿ç”¨CUDA</span></span><br><span class="line">DEVICE_ID = <span class="string">"0"</span>  <span class="comment"># CUDAè®¾å¤‡IDï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä¸ºç©º</span></span><br><span class="line">CUDA_DEVICE = <span class="string">f"<span class="subst">{DEVICE}</span>:<span class="subst">{DEVICE_ID}</span>"</span> <span class="keyword">if</span> DEVICE_ID <span class="keyword">else</span> DEVICE  <span class="comment"># ç»„åˆCUDAè®¾å¤‡ä¿¡æ¯</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ¸…ç†GPUå†…å­˜å‡½æ•°</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">torch_gc</span>():</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():  <span class="comment"># æ£€æŸ¥æ˜¯å¦å¯ç”¨CUDA</span></span><br><span class="line">        <span class="keyword">with</span> torch.cuda.device(CUDA_DEVICE):  <span class="comment"># æŒ‡å®šCUDAè®¾å¤‡</span></span><br><span class="line">            torch.cuda.empty_cache()  <span class="comment"># æ¸…ç©ºCUDAç¼“å­˜</span></span><br><span class="line">            torch.cuda.ipc_collect()  <span class="comment"># æ”¶é›†CUDAå†…å­˜ç¢ç‰‡</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºFastAPIåº”ç”¨</span></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¤„ç†POSTè¯·æ±‚çš„ç«¯ç‚¹</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">"/"</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_item</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="keyword">global</span> model, tokenizer  <span class="comment"># å£°æ˜å…¨å±€å˜é‡ä»¥ä¾¿åœ¨å‡½æ•°å†…éƒ¨ä½¿ç”¨æ¨¡å‹å’Œåˆ†è¯å™¨</span></span><br><span class="line">    json_post_raw = <span class="keyword">await</span> request.json()  <span class="comment"># è·å–POSTè¯·æ±‚çš„JSONæ•°æ®</span></span><br><span class="line">    json_post = json.dumps(json_post_raw)  <span class="comment"># å°†JSONæ•°æ®è½¬æ¢ä¸ºå­—ç¬¦ä¸²</span></span><br><span class="line">    json_post_list = json.loads(json_post)  <span class="comment"># å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºPythonå¯¹è±¡</span></span><br><span class="line">    prompt = json_post_list.get(<span class="string">'prompt'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„æç¤º</span></span><br><span class="line">    history = json_post_list.get(<span class="string">'history'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„å†å²è®°å½•</span></span><br><span class="line">    max_length = json_post_list.get(<span class="string">'max_length'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„æœ€å¤§é•¿åº¦</span></span><br><span class="line">    top_p = json_post_list.get(<span class="string">'top_p'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„top_på‚æ•°</span></span><br><span class="line">    temperature = json_post_list.get(<span class="string">'temperature'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„æ¸©åº¦å‚æ•°</span></span><br><span class="line">    <span class="comment"># è°ƒç”¨æ¨¡å‹è¿›è¡Œå¯¹è¯ç”Ÿæˆ</span></span><br><span class="line">    response, history = model.chat(</span><br><span class="line">        tokenizer,</span><br><span class="line">        prompt,</span><br><span class="line">        history=history,</span><br><span class="line">        max_length=max_length <span class="keyword">if</span> max_length <span class="keyword">else</span> <span class="number">2048</span>,  <span class="comment"># å¦‚æœæœªæä¾›æœ€å¤§é•¿åº¦ï¼Œé»˜è®¤ä½¿ç”¨2048</span></span><br><span class="line">        top_p=top_p <span class="keyword">if</span> top_p <span class="keyword">else</span> <span class="number">0.7</span>,  <span class="comment"># å¦‚æœæœªæä¾›top_på‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨0.7</span></span><br><span class="line">        temperature=temperature <span class="keyword">if</span> temperature <span class="keyword">else</span> <span class="number">0.95</span>  <span class="comment"># å¦‚æœæœªæä¾›æ¸©åº¦å‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨0.95</span></span><br><span class="line">    )</span><br><span class="line">    now = datetime.datetime.now()  <span class="comment"># è·å–å½“å‰æ—¶é—´</span></span><br><span class="line">    time = now.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>)  <span class="comment"># æ ¼å¼åŒ–æ—¶é—´ä¸ºå­—ç¬¦ä¸²</span></span><br><span class="line">    <span class="comment"># æ„å»ºå“åº”JSON</span></span><br><span class="line">    answer = {</span><br><span class="line">        <span class="string">"response"</span>: response,</span><br><span class="line">        <span class="string">"history"</span>: history,</span><br><span class="line">        <span class="string">"status"</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">"time"</span>: time</span><br><span class="line">    }</span><br><span class="line">    <span class="comment"># æ„å»ºæ—¥å¿—ä¿¡æ¯</span></span><br><span class="line">    log = <span class="string">"["</span> + time + <span class="string">"] "</span> + <span class="string">'", prompt:"'</span> + prompt + <span class="string">'", response:"'</span> + <span class="built_in">repr</span>(response) + <span class="string">'"'</span></span><br><span class="line">    <span class="built_in">print</span>(log)  <span class="comment"># æ‰“å°æ—¥å¿—</span></span><br><span class="line">    torch_gc()  <span class="comment"># æ‰§è¡ŒGPUå†…å­˜æ¸…ç†</span></span><br><span class="line">    <span class="keyword">return</span> answer  <span class="comment"># è¿”å›å“åº”</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸»å‡½æ•°å…¥å£</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># åŠ è½½é¢„è®­ç»ƒçš„åˆ†è¯å™¨å’Œæ¨¡å‹</span></span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(<span class="string">"Qwen/Qwen-7B-Chat"</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">    model = AutoModelForCausalLM.from_pretrained(<span class="string">"Qwen/Qwen-7B-Chat"</span>, device_map=<span class="string">"auto"</span>, trust_remote_code=<span class="literal">True</span>).<span class="built_in">eval</span>()</span><br><span class="line">    model.generation_config = GenerationConfig.from_pretrained(<span class="string">"Qwen/Qwen-7B-Chat"</span>, trust_remote_code=<span class="literal">True</span>) <span class="comment"># å¯æŒ‡å®š</span></span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼</span></span><br><span class="line">    <span class="comment"># å¯åŠ¨FastAPIåº”ç”¨ï¼Œç”¨6006ç«¯å£æ˜ å°„åˆ°æœ¬åœ°ï¼Œä»è€Œåœ¨æœ¬åœ°ä½¿ç”¨api</span></span><br><span class="line">    uvicorn.run(app, host=<span class="string">'0.0.0.0'</span>, port=<span class="number">6006</span>, workers=<span class="number">1</span>)  <span class="comment"># åœ¨æŒ‡å®šç«¯å£å’Œä¸»æœºä¸Šå¯åŠ¨åº”ç”¨</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="è¿è¡ŒåŠä½¿ç”¨API"><a href="#è¿è¡ŒåŠä½¿ç”¨API" class="headerlink" title="è¿è¡ŒåŠä½¿ç”¨API"></a>è¿è¡ŒåŠä½¿ç”¨API</h3><p>æˆ‘ä»¬è¿è¡Œæ–¹å¼å¾ˆç®€å•ï¼Œç›´æ¥åœ¨æœåŠ¡å™¨ç»ˆç«¯è¿è¡Œ</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">python api.py</span><br></pre></td></tr></tbody></table></figure>
<p>åŠ è½½å®Œæ¯•åå‡ºç°å¦‚ä¸‹ä¿¡æ¯è¯´æ˜æˆåŠŸã€‚</p>
<p><img src="https://picx.zhimg.com/80/v2-25146b4a0f3b5a0fa70782b1ed749e5d_720w.png?source=d16d100b" alt="è¿è¡Œæ–¹å¼"></p>
<p>é»˜è®¤éƒ¨ç½²åœ¨ 6006 ç«¯å£ï¼Œé€šè¿‡ POST æ–¹æ³•è¿›è¡Œè°ƒç”¨ï¼Œå¯ä»¥ä½¿ç”¨curlè°ƒç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">curl -X POST "http://127.0.0.1:6006" \</span><br><span class="line">     -H 'Content-Type: application/json' \</span><br><span class="line">     -d '{"prompt": "ä½ å¥½", "history": []}'</span><br></pre></td></tr></tbody></table></figure>
<p>ä¹Ÿå¯ä»¥ä½¿ç”¨pythonä¸­çš„requestsåº“è¿›è¡Œè°ƒç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">import requests</span><br><span class="line">import json</span><br><span class="line"></span><br><span class="line">def get_completion(prompt):</span><br><span class="line">    headers = {'Content-Type': 'application/json'}</span><br><span class="line">    data = {"prompt": prompt, "history": []}</span><br><span class="line">    response = requests.post(url='http://127.0.0.1:6006', headers=headers, data=json.dumps(data))</span><br><span class="line">    return response.json()['response']</span><br><span class="line"></span><br><span class="line">if __name__ == '__main__':</span><br><span class="line">    print(get_completion('ä½ å¥½'))</span><br></pre></td></tr></tbody></table></figure>
<p>å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight plaintext"><table><tbody><tr><td class="code"><pre><span class="line">{</span><br><span class="line">  "response":"ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ",</span><br><span class="line">  "history":[["ä½ å¥½","ä½ å¥½ï¼å¾ˆé«˜å…´ä¸ºä½ æœåŠ¡ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"]],</span><br><span class="line">  "status":200,</span><br><span class="line">  "time":"2023-11-26 1:14:20"</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://pic1.zhimg.com/80/v2-284a1395c44b8bb0177dae70fd54b930_720w.png?source=d16d100b" alt="è¿è¡Œç»“æœ"></p>
<h2 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h2><p>æˆ‘è§‰å¾—åœ¨æœ‰æ—¶å€™æˆ‘ä»¬è¦å®ç°ä¸€ä¸ªAPIçš„æ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨FastAPIå¿«é€Ÿå®ç°ï¼Œå¹¶ä¸”å¾—åˆ°ä¸€ä¸ªä¸é”™çš„ç»“æœï¼Œè¿™ä¹Ÿæ˜¯æˆ‘å­¦ä¹ çš„åˆè¡·ï¼Œæœ‰æ—¶å€™ä¸€äº›æœåŠ¡å™¨å¯èƒ½å¯ä»¥å½“åšAPIæ¥ä½¿ç”¨æ¥è°ƒç”¨ï¼Œå…¶å®ä¹Ÿæ–¹ä¾¿å»ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥éƒ¨ç½²åæˆä¸ºå•†ä¸šäº§å“ï¼Œç±»ä¼¼äºOpenAIä¸€æ ·ã€‚</p>
<p>æœ€åæ„Ÿè°¢ä¸€ä¸‹FastAPIçš„æ–‡æ¡£ï¼Œè®©æˆ‘å­¦ä¹ åˆ°å¾ˆå¤šï¼Œåœ¨é‡Œé¢è¿˜æœ‰æ›´è¯¦ç»†çš„ä½¿ç”¨æ–¹æ¡ˆï¼Œå¤§å®¶ä¹Ÿå¯ä»¥å»å­¦ä¹ ä¸€ä¸‹ï¼Œç„¶åå†æ„Ÿè°¢ä¸€ä¸‹datawhaleçš„self-llmé¡¹ç›®ï¼Œä¹Ÿæ˜¯åœ¨é‡Œé¢æˆ‘å­¦ä¹ åˆ°äº†ä½¿ç”¨FastAPIï¼Œå¤§å®¶å¦‚æœå¯¹å¤§æ¨¡å‹æ„Ÿå…´è¶£ä¹Ÿå¯ä»¥å…³æ³¨ä¸€ä¸‹ã€‚</p>
<p>self-llmé¡¹ç›®ï¼š<a href="https://github.com/datawhalechina/self-llm">https://github.com/datawhalechina/self-llm</a></p>
<p>FastAPIå­¦ä¹ æ–‡æ¡£ï¼š<a href="https://fastapi.tiangolo.com/zh/learn/">https://fastapi.tiangolo.com/zh/learn/</a></p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Note</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Linuxä½¿ç”¨gdownä»Google Driveä¸‹è½½æ–‡ä»¶å’Œæ–‡ä»¶å¤¹ï¼ˆå‘½ä»¤è¡Œ/ä»£ç ä¸‹è½½ï¼‰</title>
    <url>/2024/01/19/Note/gdown/</url>
    <content><![CDATA[<h2 id="ä¸€ã€å®‰è£…gdown"><a href="#ä¸€ã€å®‰è£…gdown" class="headerlink" title="ä¸€ã€å®‰è£…gdown"></a>ä¸€ã€å®‰è£…gdown</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/wkentaro/gdown </span><br><span class="line"><span class="built_in">cd</span> gdown</span><br><span class="line">pip install gdown</span><br></pre></td></tr></tbody></table></figure>
<h2 id="äºŒã€è·å–Google-Driveæ–‡ä»¶é“¾æ¥"><a href="#äºŒã€è·å–Google-Driveæ–‡ä»¶é“¾æ¥" class="headerlink" title="äºŒã€è·å–Google Driveæ–‡ä»¶é“¾æ¥"></a>äºŒã€è·å–Google Driveæ–‡ä»¶é“¾æ¥</h2><ol>
<li>æ‰“å¼€Google Drive</li>
<li>å³é”®ç‚¹å‡»è¦ä¸‹è½½çš„æ–‡ä»¶/æ–‡ä»¶å¤¹</li>
<li>é€‰æ‹©â€è·å–é“¾æ¥â€</li>
<li>ç¡®ä¿æ–‡ä»¶/æ–‡ä»¶å¤¹çš„è®¿é—®æƒé™è®¾ç½®ä¸ºâ€ä»»ä½•äººå‡å¯è®¿é—®â€</li>
<li>æ‰“å¼€åˆ†äº«é“¾æ¥,å¤åˆ¶åœ°å€æ ä¸­çš„æ–‡ä»¶ID,é“¾æ¥å‰ç¼€éƒ½ä¸º<code>https://drive.google.com/uc?id=</code>ï¼Œå¦‚<code>https://drive.google.com/uc?id=1l_5RK28JRL19wpT22B-DY9We3TVXnnQQ</code></li>
<li>å¤åˆ¶é“¾æ¥</li>
</ol>
<h2 id="ä¸‰ã€ä½¿ç”¨gdownä¸‹è½½"><a href="#ä¸‰ã€ä½¿ç”¨gdownä¸‹è½½" class="headerlink" title="ä¸‰ã€ä½¿ç”¨gdownä¸‹è½½"></a>ä¸‰ã€ä½¿ç”¨gdownä¸‹è½½</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># æ–‡ä»¶ä¸‹è½½</span></span><br><span class="line"></span><br><span class="line">gdown https://drive.google.com/uc?<span class="built_in">id</span>=&lt;æ–‡ä»¶ID&gt;</span><br><span class="line"><span class="comment"># gdown https://drive.google.com/uc?id=1l_5RK28JRL19wpT22B-DY9We3TVXnnQQ</span></span><br><span class="line"><span class="comment"># gdown 1l_5RK28JRL19wpT22B-DY9We3TVXnnQQ</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ–‡ä»¶å¤¹ä¸‹è½½</span></span><br><span class="line">gdown https://drive.google.com/drive/folders/15uNXeRBIhVvZJIhL4yTw4IsStMhUaaxl -O /tmp/folder --folder</span><br></pre></td></tr></tbody></table></figure>
<p>é™¤äº†å‘½ä»¤è¡Œä¹‹å¤–ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ä»£ç æ¥è¿›è¡Œä¸‹è½½</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment">## æ–‡ä»¶ä¸‹è½½</span></span><br><span class="line"><span class="keyword">import</span> gdown</span><br><span class="line"></span><br><span class="line">url = <span class="string">'https://drive.google.com/file/d/1uFTzwFc3tmS-D7azjMiJcxSfn71BPqKt/view?usp=sharing'</span></span><br><span class="line">output_path = <span class="string">'graph_ML.pk'</span></span><br><span class="line">gdown.download(url, output_path, quiet=<span class="literal">False</span>,fuzzy=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ–‡ä»¶å¤¹ä¸‹è½½</span></span><br><span class="line"><span class="keyword">import</span> gdown</span><br><span class="line">url = <span class="string">"https://drive.google.com/drive/folders/1HWFHKCprFzR7H7TYhrE-W7v4bz2Vc7Ia"</span></span><br><span class="line"></span><br><span class="line">gdown.download_folder(url, quiet=<span class="literal">True</span>, use_cookies=<span class="literal">False</span>)</span><br></pre></td></tr></tbody></table></figure>
<blockquote>
<p>é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€äº›å‘½ä»¤çš„ä½¿ç”¨ï¼Œè¿™é‡Œå°±ä¸è¿‡å¤šè§£é‡Šäº†</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">gdown --<span class="built_in">help</span></span><br><span class="line">usage: gdown [-h] [-V] [-O OUTPUT] [-q] [--fuzzy] [--<span class="built_in">id</span>] [--proxy PROXY]</span><br><span class="line">             [--speed SPEED] [--no-cookies] [--no-check-certificate]</span><br><span class="line">             [--<span class="built_in">continue</span>] [--folder] [--remaining-ok]</span><br><span class="line">             url_or_id</span><br></pre></td></tr></tbody></table></figure>
</blockquote>
<h2 id="å››ã€é—®é¢˜è§£å†³"><a href="#å››ã€é—®é¢˜è§£å†³" class="headerlink" title="å››ã€é—®é¢˜è§£å†³"></a>å››ã€é—®é¢˜è§£å†³</h2><p>ç”±äºGoogle Driveæ–‡ä»¶å¤§å°é™åˆ¶,ç›´æ¥ä½¿ç”¨curl/wgetä¸‹è½½å¯èƒ½ä¼šå¤±è´¥ã€‚</p>
<p>è¿™æ—¶éœ€è¦ä½¿ç”¨gdownæ¥å®ç°ä»Google Driveä¸‹è½½å¤§æ–‡ä»¶ã€‚å®ƒå¯ä»¥è§£å†³ç”±äºæ–‡ä»¶å¤ªå¤§å¯¼è‡´çš„curl/wgetä¸‹è½½å¤±è´¥é—®é¢˜ã€‚</p>
<p><strong>å‚è€ƒé“¾æ¥</strong></p>
<p>gdowné¡¹ç›®åœ°å€: <a href="https://github.com/wkentaro/gdown">https://github.com/wkentaro/gdown</a></p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Note</tag>
      </tags>
  </entry>
  <entry>
    <title>è§£å†³Flask-Socketsè¿æ¥WebSocketæ—¶å‡ºç°werkzeug.routing.WebsocketMismatchçš„é”™è¯¯</title>
    <url>/2024/01/15/Note/websocket/</url>
    <content><![CDATA[<p>åœ¨ä½¿ç”¨Flask-Socketsè¿›è¡ŒWebSocketè¿æ¥æ—¶ï¼Œä¸€äº›ç”¨æˆ·å¯èƒ½ä¼šé‡åˆ°å¦‚ä¸‹é”™è¯¯ä¿¡æ¯ï¼šwerkzeug.routing.WebsocketMismatch: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand.</p>
<p>è¿™ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ³•å¯èƒ½æœ‰ä¸¤ç§ï¼Œä»æ•´ç†çš„èµ„æ–™ä¸Šæ¥çœ‹ï¼Œæ¥ä¸‹æ¥åˆ†åˆ«å¯¹ä¸¤ç§æ–¹æ³•è¿›è¡Œè¯´æ˜ã€‚</p>
<ol>
<li>é™ä½falskå’ŒWerkzeugç‰ˆæœ¬</li>
<li>æ¶‰åŠåˆ°å®‰è£…flask_socketsåº“å¹¶å¯¹å…¶æºä»£ç è¿›è¡Œæ‰‹åŠ¨ä¿®æ”¹ã€‚</li>
</ol>
<h3 id="æ–¹æ³•ä¸€ï¼šé™ä½-Flask-å’Œ-Werkzeug-ç‰ˆæœ¬"><a href="#æ–¹æ³•ä¸€ï¼šé™ä½-Flask-å’Œ-Werkzeug-ç‰ˆæœ¬" class="headerlink" title="æ–¹æ³•ä¸€ï¼šé™ä½ Flask å’Œ Werkzeug ç‰ˆæœ¬"></a>æ–¹æ³•ä¸€ï¼šé™ä½ Flask å’Œ Werkzeug ç‰ˆæœ¬</h3><p>è¿™ç§é”™è¯¯æœ‰æ—¶æ˜¯å› ä¸ºFlaskç‰ˆæœ¬è¿‡é«˜ï¼Œé™çº§å³å¯æˆåŠŸï¼Œä½†æ˜¯è¿™ç§æ–¹å¼å¯èƒ½ä¸å¤Ÿç†æƒ³ï¼Œæ¨èæŸ¥çœ‹æ–¹æ³•äºŒã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install flask==1.1.2</span><br><span class="line">pip install Werkzeug==1.0.2</span><br></pre></td></tr></tbody></table></figure>
<h3 id="æ–¹æ³•äºŒï¼ˆæ¨èï¼‰"><a href="#æ–¹æ³•äºŒï¼ˆæ¨èï¼‰" class="headerlink" title="æ–¹æ³•äºŒï¼ˆæ¨èï¼‰"></a>æ–¹æ³•äºŒï¼ˆæ¨èï¼‰</h3><p>é¦–å…ˆï¼Œç¡®ä¿å·²ç»å®‰è£…äº†flask_socketsåº“ï¼Œå¯ä»¥é€šè¿‡è¿è¡Œä»¥ä¸‹å‘½ä»¤è¿›è¡Œå®‰è£…ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install flask_sockets</span><br></pre></td></tr></tbody></table></figure>
<p>å®‰è£…å®Œæˆåï¼Œéœ€è¦å¯¹flask_socketsåº“çš„æºä»£ç è¿›è¡Œæ‰‹åŠ¨ä¿®æ”¹ã€‚å…·ä½“çš„ä¿®æ”¹å¦‚ä¸‹ï¼š</p>
<p>æ–‡ä»¶ï¼šflask_sockets.py å‡½æ•°ï¼šadd_url_rule</p>
<p>ä¿®æ”¹å‰çš„ä»£ç ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">self.url_map.add(Rule(rule, endpoint=f))</span><br></pre></td></tr></tbody></table></figure>
<p>ä¿®æ”¹åçš„ä»£ç ï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">self.url_map.add(Rule(rule, endpoint=f, websocket=True))</span><br></pre></td></tr></tbody></table></figure>
<p>è¿™ä¸ªä¿®æ”¹çš„ç›®çš„æ˜¯ä¸ºäº†åœ¨æ·»åŠ URLè§„åˆ™æ—¶æ˜ç¡®æŒ‡å®šWebSocketã€‚é€šè¿‡å°†websocket=Trueæ·»åŠ åˆ°Ruleæ„é€ å‡½æ•°ä¸­ï¼Œå¯ä»¥è§£å†³400 Bad Requesté”™è¯¯ã€‚</p>
<p>å…³äºè¿™ä¸ªé—®é¢˜çš„è¯¦ç»†è®¨è®ºå¯ä»¥å‚è€ƒä»¥ä¸‹é“¾æ¥ï¼š <a href="https://github.com/heroku-python/flask-sockets/issues/81">https://github.com/heroku-python/flask-sockets/issues/81</a></p>
<p>æœ‰å…³è¿™ä¸ªé—®é¢˜çš„å…·ä½“ä¿®æ”¹å¯ä»¥å‚è€ƒä»¥ä¸‹é“¾æ¥ï¼š <a href="https://github.com/slipperstree/flask-sockets/commit/cb06c69db3af2cb52fbc050f3595ffa4100bbee3">https://github.com/slipperstree/flask-sockets/commit/cb06c69db3af2cb52fbc050f3595ffa4100bbee3</a></p>
<p>é€šè¿‡å¯¹flask_socketsåº“çš„æ‰‹åŠ¨ä¿®æ”¹ï¼Œæ‚¨å¯ä»¥é¡ºåˆ©è§£å†³WebSocketè¿æ¥æ—¶å¯èƒ½é‡åˆ°çš„400 Bad Requesté”™è¯¯ï¼Œç¡®ä¿æ‚¨çš„åº”ç”¨æ­£å¸¸è¿è¡Œã€‚å¸Œæœ›è¿™ç¯‡æ–‡ç« å¯¹æ‚¨æœ‰å¸®åŠ©ï¼</p>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Bug</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGSç»¼è¿°ä»¥åŠå¯¹3DGSçš„ç†è§£ï¼šA Survey on 3D Gaussian Splatting</title>
    <url>/2024/01/25/Paper/3DGS%20Survey/</url>
    <content><![CDATA[<p>ä»Šå¤©æƒ³ä»‹ç»çš„æ˜¯<code>ZJU</code>å¸¦æ¥çš„<code>3DGS</code>çš„é¦–ç¯‡ç»¼è¿°<code>A Survey on 3D Gaussian Splatting</code> è¿™æ˜¯è®ºæ–‡é“¾æ¥ <a href="https://arxiv.org/abs/2401.03890">arXiv:2401.03890</a>ï¼Œç»“åˆä¸€äº›èµ„æ–™ï¼Œè¶è¿™ä¸ªæœºä¼šå¥½å¥½å­¦ä¹ ä¸€ä¸‹3DGSï¼ŒåŠ æ²¹å…¥å‘ï¼ï¼ï¼</p>
<p>é¦–å…ˆè¯´ä¸€äº›è‡ªå·±çš„ç†è§£ï¼Œ3DGSä¹‹æ‰€ä»¥çˆ†ç«ï¼Œå¾ˆå¤§ç¨‹åº¦åœ¨äºä»–çš„å®æ—¶æ€§ï¼Œè€Œè¿™ä¸€éƒ¨åˆ†æå¤§ç¨‹åº¦å¾—ç›Šäºä»–å®šåˆ¶çš„ç®—æ³•ä¸è‡ªå®šä¹‰ CUDA å†…æ ¸ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œ<strong>Gaussian Splatting</strong>æ ¹æœ¬ä¸æ¶‰åŠä»»ä½•ç¥ç»ç½‘ç»œï¼Œç”šè‡³æ²¡æœ‰ä¸€ä¸ªå°å‹çš„ MLPï¼Œä¹Ÿæ²¡æœ‰ä»€ä¹ˆ â€œç¥ç»â€çš„ä¸œè¥¿ï¼Œåœºæ™¯æœ¬è´¨ä¸Šåªæ˜¯ç©ºé—´ä¸­çš„ä¸€ç»„ç‚¹ã€‚åœ¨å¤§å®¶éƒ½åœ¨ç ”ç©¶æ•°åäº¿ä¸ªå‚æ•°ç»„æˆçš„æ¨¡å‹çš„äººå·¥æ™ºèƒ½ä¸–ç•Œé‡Œï¼Œè¿™ç§æ–¹æ³•è¶Šæ¥è¶Šå—æ¬¢è¿ï¼Œä»¤äººè€³ç›®ä¸€æ–°ã€‚å®ƒçš„æƒ³æ³•æºäº â€œSurface splattingâ€ï¼ˆ2001 å¹´ï¼‰ï¼Œè¯´æ˜ç»å…¸çš„è®¡ç®—æœºè§†è§‰æ–¹æ³•ä»ç„¶å¯ä»¥æ¿€å‘ç›¸å…³çš„è§£å†³æ–¹æ¡ˆã€‚å®ƒç®€å•æ˜äº†çš„è¡¨è¿°æ–¹å¼ä½¿<strong>Gaussian Splatting</strong>ç‰¹åˆ«å®¹æ˜“è§£é‡Šï¼Œè¿™ä¹Ÿæ˜¯ä¸ºä»€ä¹ˆåœ¨æŸäº›åº”ç”¨ä¸­é€‰æ‹©å®ƒè€Œä¸æ˜¯ NeRFsã€‚</p>
<h2 id="å¼•è¨€-INTRODUCTION"><a href="#å¼•è¨€-INTRODUCTION" class="headerlink" title="å¼•è¨€ INTRODUCTION"></a>å¼•è¨€ INTRODUCTION</h2><p>NeRFè‡ªä»2020å¹´å¼€å§‹ï¼Œåœ¨å¤šè§†è§’åˆæˆä¸­åšå‡ºæ¥å·¨å¤§çš„è´¡çŒ®ï¼Œä»–åˆ©ç”¨ç¥ç»ç½‘ç»œï¼Œå®ç°äº†ç©ºé—´åæ ‡åˆ°é¢œè‰²å’Œå¯†åº¦çš„æ˜ å°„çš„ï¼Œç„¶NeRFçš„æ–¹æ³•æ˜¯è®¡ç®—å¯†é›†å‹çš„ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ—¶é—´å’Œå¤§é‡çš„æ¸²æŸ“èµ„æºï¼Œç‰¹åˆ«æ˜¯é«˜åˆ†è¾¨ç‡çš„è¾“å‡ºã€‚</p>
<p><img src="https://pic1.zhimg.com/80/v2-c828848317a156fc6dd17c9a5310dd03.png" alt="NeRF"></p>
<p>é’ˆå¯¹è¿™äº›é—®é¢˜ï¼Œ3DGSå‡ºç°äº†ï¼Œ3DGS é‡‡ç”¨æ˜¾å¼è¡¨ç¤ºå’Œé«˜åº¦å¹¶è¡Œçš„å·¥ä½œæµç¨‹ï¼Œæœ‰åˆ©äºæ›´é«˜æ•ˆçš„è®¡ç®—å’Œæ¸²æŸ“ï¼Œå…¶åˆ›æ–°åœ¨äºå…¶ç‹¬ç‰¹åœ°èåˆäº†å¯å¾®åˆ†ç®¡é“å’ŒåŸºäºç‚¹çš„æ¸²æŸ“æŠ€æœ¯çš„ä¼˜ç‚¹ï¼Œé€šè¿‡ç”¨å¯å­¦ä¹ çš„ 3D é«˜æ–¯å‡½æ•°è¡¨ç¤ºåœºæ™¯ï¼Œä¿ç•™äº†è¿ç»­ä½“ç§¯è¾å°„åœºçš„ç†æƒ³ç‰¹æ€§ï¼Œè¿™å¯¹äºé«˜è´¨é‡å›¾åƒåˆæˆè‡³å…³é‡è¦ï¼ŒåŒæ—¶é¿å…äº†ä¸ç©ºç™½ç©ºé—´æ¸²æŸ“ç›¸å…³çš„è®¡ç®—å¼€é”€ï¼Œè¿™æ˜¯ä¼ ç»Ÿ NeRF æ–¹æ³•çš„å¸¸è§ç¼ºç‚¹ï¼Œè€Œ3DGSå¾ˆå¥½çš„è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œåœ¨ä¸å½±å“è§†è§‰è´¨é‡çš„æƒ…å†µä¸‹è¾¾åˆ°äº†å®æ—¶æ¸²æŸ“ã€‚</p>
<p>è®ºæ–‡ä¸­ä¹Ÿå‘ç°ï¼Œè‡ª3DGSå‡ºç°ä»¥æ¥ï¼Œ2023å¹´æœ‰å¾ˆå¤šçš„è®ºæ–‡åœ¨arXivä¸­æŒ‚å‡ºæ¥ï¼Œæ‰€ä»¥åŸºäºæ­¤ä¹Ÿå†™äº†è¿™æ ·ä¸€ä¸ªç»¼è¿°ï¼ŒåŒæ—¶ä¿ƒè¿›3DGSé¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶å’Œåˆ›æ–°</p>
<p><img src="https://picx.zhimg.com/80/v2-167cd8779af5c5550c15156e2b9b52c0.png" alt="The number of papers on 3DGS is increasing every month."></p>
<p>ä»¥ä¸‹æ˜¯è®ºæ–‡æ¶æ„çš„å›¾ï¼Œè®ºæ–‡çš„å¤§æ¦‚æ¶æ„å¦‚ä¸‹æ‰€ç¤ºï¼Œå¯ä»¥çœ‹åˆ°è¿™ç¯‡ç»¼è¿°æ’°å†™çš„ä¸€ä¸ªé€»è¾‘ï¼Œè¿˜æ˜¯éå¸¸å¥½çš„ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä¼šé¡ºç€è¿™ä¸ªæ¶æ„è¿›è¡Œè§£è¯»è®ºæ–‡æ¥å­¦ä¹ </p>
<ul>
<li>ç¬¬2éƒ¨åˆ†ï¼šä¸»è¦æ˜¯ä¸€äº›é—®é¢˜æè¿°å’Œç›¸å…³ç ”ç©¶é¢†åŸŸçš„ä¸€äº›ç®€è¦çš„èƒŒæ™¯</li>
<li>ç¬¬3éƒ¨åˆ†ï¼šä»‹ç»3DGSï¼ŒåŒ…æ‹¬3DGSçš„å¤šè§†è§’çš„åˆæˆå’Œ3DGSçš„ä¼˜åŒ–</li>
<li>ç¬¬4éƒ¨åˆ†ï¼š3DGS äº§ç”Ÿé‡å¤§å½±å“çš„å„ç§åº”ç”¨é¢†åŸŸå’Œä»»åŠ¡ï¼Œå±•ç¤ºäº†å…¶å¤šåŠŸèƒ½æ€§</li>
<li>ç¬¬5éƒ¨åˆ†ï¼šå¯¹3DGSè¿›è¡Œäº†ä¸€äº›æ¯”è¾ƒå’Œåˆ†æ</li>
<li>ç¬¬6ã€7éƒ¨åˆ†ï¼šå¯¹ä¸€äº›æœªæ¥çš„å¼€æ”¾æ€§å·¥ä½œè¿›è¡Œæ€»ç»“å’Œè°ƒæŸ¥</li>
</ul>
<p><img src="https://picx.zhimg.com/80/v2-2ebb7a7fb8548ff7a8e30bc62e875ebe.png" alt="Structure of the overall review."></p>
<h2 id="èƒŒæ™¯-BACKGROUND"><a href="#èƒŒæ™¯-BACKGROUND" class="headerlink" title="èƒŒæ™¯ BACKGROUND"></a>èƒŒæ™¯ BACKGROUND</h2><p>èƒŒæ™¯ä¸»è¦åˆ†ä¸¤éƒ¨åˆ†è®²è§£</p>
<ul>
<li>è¾å°„åœºçš„æ¦‚å¿µï¼šéšå¼å’Œæ˜¾å¼</li>
<li>æœ‰å…³è¾å°„åœºçš„åœºæ™¯é‡å»ºã€æ¸²æŸ“ç­‰é¢†åŸŸç›¸å…³ä»‹ç»</li>
</ul>
<h3 id="é—®é¢˜å®šä¹‰"><a href="#é—®é¢˜å®šä¹‰" class="headerlink" title="é—®é¢˜å®šä¹‰"></a>é—®é¢˜å®šä¹‰</h3><h4 id="è¾å°„åœº"><a href="#è¾å°„åœº" class="headerlink" title="è¾å°„åœº"></a>è¾å°„åœº</h4><p>è¾å°„åœºæ˜¯å®é™…ä¸Šæ˜¯å¯¹ä¸‰ç»´ç©ºé—´ä¸­å…‰åˆ†å¸ƒçš„è¡¨ç¤ºï¼Œå®ƒæ•æ‰äº†å…‰ä¸ç¯å¢ƒä¸­çš„è¡¨é¢å’Œæè´¨ç›¸äº’ä½œç”¨çš„æ–¹å¼ã€‚ä»æ•°å­¦ä¸Šæ¥è¯´ï¼Œè¾å°„åœºå¯è¢«æè¿°ä¸ºä¸€ä¸ªå‡½æ•°$L:\mathbb{R}^5\to\mathbb{R}^+$, å…¶ä¸­$L(x,y,z,\theta,\psi)$å°†ç‚¹$(x,y,z)$å’Œçƒåæ ‡ä¸‹çš„æ–¹å‘$(\theta,\phi)$æ˜ å°„ä¸ºéè´Ÿçš„è¾å°„å€¼ã€‚è¾å°„åœºæœ‰æ˜¾ç¤ºè¡¨è¾¾å’Œéšå¼è¡¨è¾¾ï¼Œå¯ç”¨äºåœºæ™¯è¡¨ç¤ºå’Œæ¸²æŸ“ã€‚</p>
<h4 id="éšå¼è¾å°„åœº"><a href="#éšå¼è¾å°„åœº" class="headerlink" title="éšå¼è¾å°„åœº"></a>éšå¼è¾å°„åœº</h4><p>éšå¼è¾å°„åœºæ˜¯è¾å°„åœºä¸­çš„ä¸€ç§ï¼Œåœ¨è¡¨ç¤ºåœºæ™¯ä¸­çš„å…‰åˆ†å¸ƒæ—¶ï¼Œä¸éœ€æ˜¾å¼å®šä¹‰åœºæ™¯çš„é›†åˆå½¢çŠ¶ã€‚è¿™é‡Œé¢æœ€å¸¸è§çš„å°±æ˜¯NeRFï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥å­¦ä¹ è¿ç»­çš„ä½“ç§¯è¡¨ç¤ºã€‚åœ¨NeRFä¸­ï¼Œä½¿ç”¨MLP ç½‘ç»œç”¨äºå°†ä¸€ç»„ç©ºé—´åæ ‡ $(x, y, z)$ å’Œè§‚å¯Ÿæ–¹å‘ $(\theta,\phi)$ æ˜ å°„åˆ°é¢œè‰²å’Œå¯†åº¦å€¼ã€‚ä»»ä½•ç‚¹å¤„çš„è¾å°„ä¸æ˜¯æ˜¾å¼å­˜å‚¨çš„ï¼Œè€Œæ˜¯é€šè¿‡æŸ¥è¯¢ç¥ç»ç½‘ç»œå®æ—¶è®¡ç®—å¾—å‡ºã€‚å› æ­¤ï¼Œè¯¥å‡½æ•°å¯ä»¥å†™æˆï¼š</p>
<script type="math/tex; mode=display">
L_\text{implicit}(x,y,z,\theta,\phi)=\text{NeuralNetwork}(x,y,z,\theta,\phi)</script><p>è¿™ç§æ–¹å¼çš„å¥½å¤„æ˜¯æ„å»ºäº†ä¸€ä¸ªå¯å¾®ä¸”ç´§å‡‘çš„å¤æ‚åœºæ™¯ï¼Œä½†æ˜¯ç”±äºæˆ‘ä»¬æ€»æ˜¯éœ€è¦å¯¹å…‰çº¿è¿›è¡Œé‡‡æ ·å’Œä½“æ¸²æŸ“çš„è®¡ç®—ï¼Œä¼šå¯¼è‡´è®¡ç®—è´Ÿè½½æ¯”è¾ƒé«˜ã€‚</p>
<h4 id="æ˜¾å¼è¾å°„åœº"><a href="#æ˜¾å¼è¾å°„åœº" class="headerlink" title="æ˜¾å¼è¾å°„åœº"></a>æ˜¾å¼è¾å°„åœº</h4><p>ä¸éšå¼ä¸åŒçš„æ˜¯ï¼Œæ˜¾ç¤ºæ˜¯ç›´æ¥è¡¨ç¤ºå…‰åœ¨ç¦»æ•£ç©ºé—´ç»“æ„ä¸­çš„åˆ†å¸ƒï¼Œæ¯”å¦‚ä½“ç´ ç½‘æ ¼æˆ–ç‚¹äº‘ã€‚è¯¥ç»“æ„ä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½å­˜å‚¨äº†å…¶åœ¨ç©ºé—´ä¸­ç›¸åº”ä½ç½®çš„è¾å°„ä¿¡æ¯ï¼Œè€Œä¸æ˜¯åƒNeRFä¸€æ ·å»æ‰§è¡ŒæŸ¥è¯¢çš„æ“ä½œï¼Œæ‰€ä»¥ä»–ä¼šæ›´ç›´æ¥ä¹Ÿæ›´å¿«çš„å¾—åˆ°æ¯ä¸ªå€¼ï¼Œä½†æ˜¯åŒæ—¶ä¹Ÿéœ€è¦æ›´å¤§å†…å­˜ä½¿ç”¨å’Œå¯¼è‡´è¾ƒä½çš„åˆ†è¾¨ç‡ã€‚é€šå¸¸æˆ‘ä»¬å¯ä»¥è¡¨ç¤ºä¸ºï¼š</p>
<script type="math/tex; mode=display">
L_\text{explicit}{ ( x , y , z , \theta , \phi ) }=\text{DataStructure}[(x,y,z)]\cdot f(\theta,\phi)</script><p>å…¶ä¸­ï¼Œ<code>DataStructure</code>å¯ä»¥æ˜¯ç½‘æ ¼æˆ–ç‚¹äº‘ï¼Œè€Œ$f(Î¸, Ï•)$æ˜¯ä¸€ä¸ªæ ¹æ®è§‚å¯Ÿè§†çº¿æ–¹å‘ä¿®æ”¹è¾å°„çš„å‡½æ•°ã€‚</p>
<h4 id="3D-Gaussian-Splatting-ï¼ˆä¸¤å…¨å…¶ç¾ï¼‰"><a href="#3D-Gaussian-Splatting-ï¼ˆä¸¤å…¨å…¶ç¾ï¼‰" class="headerlink" title="3D Gaussian Splatting ï¼ˆä¸¤å…¨å…¶ç¾ï¼‰"></a>3D Gaussian Splatting ï¼ˆä¸¤å…¨å…¶ç¾ï¼‰</h4><p>3DGSé€šè¿‡åˆ©ç”¨3D é«˜æ–¯å‡½æ•°ä½œä¸ºå…¶è¡¨ç¤ºå½¢å¼ï¼Œå……åˆ†åˆ©ç”¨äº†æ˜¾ç¤ºè¾å°„åœºå’Œéšå¼è¾å°„åœºçš„ä¼˜åŠ¿ã€‚è¿™äº›é«˜æ–¯å‡½æ•°è¢«ä¼˜åŒ–ç”¨äºå‡†ç¡®è¡¨ç¤ºåœºæ™¯ï¼Œç»“åˆäº†åŸºäºç¥ç»ç½‘ç»œçš„ä¼˜åŒ–å’Œæ˜¾å¼ç»“æ„åŒ–æ•°æ®å­˜å‚¨çš„ä¼˜ç‚¹ã€‚è¿™ç§æ··åˆæ–¹æ³•èƒ½è¿›è¡Œé«˜è´¨é‡æ¸²æŸ“ï¼ŒåŒæ—¶å…·æœ‰æ›´å¿«çš„è®­ç»ƒå’Œå®æ—¶æ€§èƒ½ï¼Œ3Dé«˜æ–¯è¡¨è¾¾å¯è¡¨ç¤ºä¸ºï¼š</p>
<script type="math/tex; mode=display">
L_{\mathrm{3DGS}}(x,y,z,\theta,\phi)=\sum_{i}G(x,y,z,\mu_{i},\Sigma_{i})\cdot c_{i}(\theta,\phi)</script><p>å…¶ä¸­ $G$ æ˜¯å…·æœ‰å¹³å‡å€¼ $Î¼_i$ å’Œåæ–¹å·® $Î£_i$ çš„é«˜æ–¯å‡½æ•°ï¼Œ$c$ è¡¨ç¤ºä¸è§†å›¾ç›¸å…³çš„é¢œè‰²ã€‚</p>
<h4 id="æ˜¾å¼ä¸éšå¼çš„ç†è§£"><a href="#æ˜¾å¼ä¸éšå¼çš„ç†è§£" class="headerlink" title="æ˜¾å¼ä¸éšå¼çš„ç†è§£"></a>æ˜¾å¼ä¸éšå¼çš„ç†è§£</h4><p>è¿™é‡Œæ”¾ä¸€å¼ ç†è§£æ˜¾ç¤ºéšå¼å›¾åƒçš„å›¾ç‰‡ï¼Œæˆ‘è¿˜æ˜¯è§‰å¾—ç›¸å½“ä¸é”™çš„</p>
<p><img src="https://pic1.zhimg.com/80/v2-e79d0183806753d34863598e544a0517.jpeg" alt="æ˜¾å¼éšå¼è¡¨è¾¾"></p>
<h3 id="èƒŒæ™¯å’Œæœ¯è¯­"><a href="#èƒŒæ™¯å’Œæœ¯è¯­" class="headerlink" title="èƒŒæ™¯å’Œæœ¯è¯­"></a>èƒŒæ™¯å’Œæœ¯è¯­</h3><p>è®¸å¤šæŠ€æœ¯å’Œç ”ç©¶å­¦ç§‘ä¸ <code>3DGS</code> æœ‰ç€å¯†åˆ‡çš„å…³ç³»ï¼Œä»¥ä¸‹å„èŠ‚å°†å¯¹æ­¤è¿›è¡Œç®€è¦ä»‹ç»ã€‚</p>
<h4 id="åœºæ™¯é‡å»ºä¸æ¸²æŸ“"><a href="#åœºæ™¯é‡å»ºä¸æ¸²æŸ“" class="headerlink" title="åœºæ™¯é‡å»ºä¸æ¸²æŸ“"></a>åœºæ™¯é‡å»ºä¸æ¸²æŸ“</h4><p><strong>åœºæ™¯é‡å»º</strong>ï¼šä»ä¸€ç»„å›¾åƒé›†åˆæˆ–å…¶å®ƒæ•°æ®å»ºç«‹åœºæ™¯çš„ä¸‰ç»´æ¨¡å‹ã€‚</p>
<p><strong>æ¸²æŸ“</strong>ï¼šå°†è®¡ç®—æœºå¯è¯»å–çš„ä¿¡æ¯ï¼ˆå¦‚åœºæ™¯ä¸­çš„3Dç‰©ä½“ï¼‰è½¬åŒ–ä¸ºå›¾åƒã€‚<br>æ—©æœŸæŠ€æœ¯åŸºäºå…‰åœºç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œè¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰ä¸å¤šè§†å›¾ç«‹ä½“åŒ¹é…ï¼ˆMVSï¼‰ç®—æ³•é€šè¿‡ä»å›¾åƒåºåˆ—ä¼°è®¡3Dç»“æ„æ¥å¢å¼ºå…‰åœºã€‚</p>
<h4 id="ç¥ç»æ¸²æŸ“å’Œè¾å°„åœº"><a href="#ç¥ç»æ¸²æŸ“å’Œè¾å°„åœº" class="headerlink" title="ç¥ç»æ¸²æŸ“å’Œè¾å°„åœº"></a>ç¥ç»æ¸²æŸ“å’Œè¾å°„åœº</h4><p><strong>ç¥ç»æ¸²æŸ“</strong>ï¼šå°†æ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿå›¾å½¢æŠ€æœ¯ç»“åˆç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚æ—©æœŸæ–¹æ³•ä½¿ç”¨CNNä¼°è®¡æ··åˆæƒé‡æˆ–çº¹ç†ç©ºé—´è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>è¾å°„åœº</strong>ï¼šä¸€ç§å‡½æ•°è¡¨è¾¾ï¼Œæè¿°ä»å„æ–¹å‘ç©¿è¿‡ç©ºé—´å„ç‚¹çš„å…‰çš„é‡ã€‚NeRFä½¿ç”¨ç¥ç»ç½‘ç»œå»ºæ¨¡è¾å°„åœºã€‚</p>
<h4 id="ä½“ç§¯è¡¨ç¤ºå’Œå…‰çº¿è¡Œè¿›"><a href="#ä½“ç§¯è¡¨ç¤ºå’Œå…‰çº¿è¡Œè¿›" class="headerlink" title="ä½“ç§¯è¡¨ç¤ºå’Œå…‰çº¿è¡Œè¿›"></a>ä½“ç§¯è¡¨ç¤ºå’Œå…‰çº¿è¡Œè¿›</h4><p><strong>ä½“ç§¯è¡¨è¾¾</strong>ï¼šä¸ä»…å°†ç‰©ä½“å’Œåœºæ™¯å»ºæ¨¡ä¸ºè¡¨é¢ï¼Œè¿˜å°†å…¶å…¶å»ºæ¨¡ä¸ºå……æ»¡ææ–™æˆ–ç©ºç™½ç©ºé—´çš„ä½“ç§¯ã€‚è¿™æ ·å¯ä»¥å¯¹å¦‚é›¾ã€çƒŸæˆ–åŠé€æ˜ææ–™è¿›è¡Œæ›´ç²¾ç¡®çš„æ¸²æŸ“ã€‚</p>
<p><strong>å…‰çº¿è¡Œè¿›</strong>ï¼šæ˜¯ä½“ç§¯è¡¨è¾¾æ¸²æŸ“å›¾åƒçš„æŠ€æœ¯ï¼Œé€šè¿‡å¢é‡è·Ÿè¸ªç©¿è¿‡â€œä½“â€çš„å…‰çº¿æ¥æ¸²æŸ“å›¾åƒã€‚NeRFå¼•å…¥é‡è¦æ€§é‡‡æ ·å’Œä½ç½®ç¼–ç å¢å¼ºåˆæˆå›¾åƒçš„è´¨é‡ï¼Œè™½ç„¶èƒ½å¾—åˆ°é«˜è´¨é‡çš„å›¾åƒï¼Œä½†è¿™ä¸€æ–¹æ³•è®¡ç®—é‡å¤§ã€‚</p>
<h4 id="åŸºäºç‚¹çš„æ¸²æŸ“"><a href="#åŸºäºç‚¹çš„æ¸²æŸ“" class="headerlink" title="åŸºäºç‚¹çš„æ¸²æŸ“"></a>åŸºäºç‚¹çš„æ¸²æŸ“</h4><p>åŸºäºç‚¹çš„æ¸²æŸ“æ˜¯ä¸€ç§ä½¿ç”¨ç‚¹è€Œéä¼ ç»Ÿå¤šè¾¹å½¢æ¥å¯è§†åŒ–3Dåœºæ™¯çš„æŠ€æœ¯ã€‚è¯¥æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºæ¸²æŸ“å¤æ‚ã€éç»“æ„åŒ–æˆ–ç¨€ç–çš„å‡ ä½•æ•°æ®ã€‚ç‚¹å¯ä»¥é€šè¿‡æ·»åŠ é¢å¤–å±æ€§ï¼Œå¦‚å¯å­¦ä¹ çš„ç¥ç»æè¿°ç¬¦æ¥è¿›è¡Œå¢å¼ºï¼Œå¹¶ä¸”å¯ä»¥é«˜æ•ˆåœ°è¿›è¡Œæ¸²æŸ“ï¼Œä½†è¿™ç§æ–¹æ³•å¯èƒ½ä¼šå‡ºç°æ¸²æŸ“ä¸­çš„ç©ºæ´æˆ–æ··å æ•ˆåº”ç­‰é—®é¢˜ã€‚3DGSé€šè¿‡ä½¿ç”¨å„å‘å¼‚æ€§é«˜æ–¯è¿›è¡Œæ›´è¿è´¯çš„åœºæ™¯è¡¨è¾¾ã€‚</p>
<h2 id="ç”¨äºæ˜¾å¼è¾å°„åœºçš„3DGS"><a href="#ç”¨äºæ˜¾å¼è¾å°„åœºçš„3DGS" class="headerlink" title="ç”¨äºæ˜¾å¼è¾å°„åœºçš„3DGS"></a>ç”¨äºæ˜¾å¼è¾å°„åœºçš„3DGS</h2><p>3DGSèƒ½å¤Ÿå®æ—¶æ¸²æŸ“é«˜åˆ†è¾¨ç‡çš„å›¾åƒï¼Œå¹¶ä¸”ä¸éœ€è¦ç¥ç»ç½‘ç»œï¼Œæ˜¯ä¸€ä¸ªçªç ´ã€‚</p>
<p>è¿™ä¸€å—ä¸»è¦å›´ç»•ä¸¤å—è¿›è¡Œè®²è§£</p>
<ul>
<li>3DGSçš„å‰å‘è¿‡ç¨‹</li>
<li>3DGSçš„ä¼˜åŒ–è¿‡ç¨‹</li>
</ul>
<h3 id="å­¦ä¹ 3Dé«˜æ–¯å‡½æ•°è¿›è¡Œæ–°è§†è§’åˆæˆ"><a href="#å­¦ä¹ 3Dé«˜æ–¯å‡½æ•°è¿›è¡Œæ–°è§†è§’åˆæˆ" class="headerlink" title="å­¦ä¹ 3Dé«˜æ–¯å‡½æ•°è¿›è¡Œæ–°è§†è§’åˆæˆ"></a>å­¦ä¹ 3Dé«˜æ–¯å‡½æ•°è¿›è¡Œæ–°è§†è§’åˆæˆ</h3><p>å‡å¦‚ç°åœ¨æœ‰ä¸€ä¸ªåœºæ™¯ï¼Œç›®çš„æ˜¯ç”Ÿæˆç‰¹å®šè§†è§’ä¸‹çš„ç›¸æœºå›¾åƒã€‚NeRFå¯¹æ¯ä¸€ä¸ªåƒç´ ä½¿ç”¨å…‰çº¿è¡Œè¿›å’Œé‡‡æ ·ç‚¹ï¼Œå½±å“å…¶å®æ—¶æ€§ï¼›è€Œ3DGSå°†3Dé«˜æ–¯æŠ•å½±åˆ°å›¾åƒå¹³é¢ï¼Œç§°ä¸ºâ€œæ³¼æº…â€ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚ç„¶åå¯¹é«˜æ–¯è¿›è¡Œæ’åºå¹¶è®¡ç®—æ¯ä¸ªåƒç´ çš„å€¼ã€‚NeRFå’Œ3DGSçš„æ¸²æŸ“å¯è§†ä¸ºäº’é€†å…³ç³»ã€‚</p>
<p><img src="https://pic1.zhimg.com/80/v2-9d5fff5c2390526cd03e5a14fd13f4fe.png" alt="3DGSçš„Splatting æ³¼æº…"></p>
<p>è¿™é‡Œé¢æœ‰ä¸ªç‚¹å¾ˆæœ‰æ„æ€ï¼Œä¸ºä»€ä¹ˆè¯´æ˜¯äº’é€†å…³ç³»ï¼Œæˆ‘å‚è€ƒäº†çŸ¥ä¹çš„ä¸€ç¯‡æ–‡ç« <a href="https://zhuanlan.zhihu.com/p/666465701">3D Gaussian Splattingä¸­çš„æ•°å­¦æ¨å¯¼</a>çš„è¯´æ˜ï¼Œæˆ‘è§‰å¾—è¿™ä¸ªè¯´çš„è¿˜ä¸é”™ã€‚</p>
<blockquote>
<p> é¦–å…ˆï¼Œæˆ‘ä»¬å›å¿†ä¸€ä¸‹ä½“æ¸²æŸ“çš„è¿™ä¸ªäº‹æƒ…ã€‚å‡è®¾è¯»è€…è·Ÿæˆ‘ä¸€æ ·æ˜¯ä»NeRFæ‰æ¥è§¦ä½“æ¸²æŸ“çš„ï¼Œé‚£ä¹ˆå›é¡¾ä¸€ä¸‹NeRFä¸­ï¼Œæ²¿ç€ä¸€ä¸ªåƒç´ ï¼Œå‘å‡ºä¸€æ¡å°„çº¿ï¼Œç„¶åè¿™æ¡å°„çº¿â€œå°„å‘ä½“æ•°æ®â€ï¼ˆåœ¨NeRFé‡Œå°±æ˜¯æ²¿ç€å…‰çº¿è¿›è¡Œé‡‡æ ·ï¼Œç„¶åæŸ¥è¯¢é‡‡æ ·ç‚¹çš„å±æ€§ï¼‰çš„è¿‡ç¨‹ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥å½’ç»“ä¸ºä¸€ç§<code>backward mapping</code>ã€‚</p>
<p> æ‰€ä»¥å¾ˆè‡ªç„¶çš„ï¼Œä¼šæœ‰ä¸€ç§<code>forward mapping</code>çš„åŠæ³•ã€‚å½¢å¼ä¸Šï¼Œå°±æ˜¯å°†æ•´ä¸ªâ€œä½“æ•°æ®â€æŠ•å½±åˆ°æ­¤æ—¶ä½å§¿æ‰€å¯¹åº”çš„å›¾åƒå¹³é¢ã€‚è¿™ç§åŠæ³•çš„å‰æå°±ä¸èƒ½æ˜¯ç”¨NeRFé‚£ç§éšå¼è¡¨è¾¾äº†ï¼Œéœ€è¦ä¸€äº›æ˜¾å¼çš„è¡¨è¾¾æ‰èƒ½æ”¯æŒè¿™æ ·ç›´æ¥çš„æŠ•å½±ã€‚ä¾‹å¦‚ä»¥ä¸‰ä¸ªé¡¶ç‚¹é•¿æˆçš„ä¸‰è§’é¢åŸºå…ƒï¼ˆprimitiveï¼‰ï¼Œç„¶åå°†è¿™äº›è®¸å¤šçš„ä¸‰è§’é¢ç›´æ¥æŠ•å½±åˆ°æˆåƒå¹³é¢ä¸Šï¼Œåˆ¤æ–­å“ªäº›åƒç´ æ˜¯ä»€ä¹ˆé¢œè‰²ï¼Œå½“æœ‰å¤šä¸ªä¸‰è§’å½¢æŠ•å½±æ—¶ï¼Œæ ¹æ®ä»–ä»¬çš„â€œæ·±åº¦â€æ¥åˆ¤æ–­å‰åé¡ºåºï¼Œç„¶åè¿›è¡Œç†Ÿæ‚‰çš„alpha compositingã€‚å½“ç„¶ä¹Ÿä¼šæœ‰å…¶ä»–åŸºå…ƒï¼Œä¾‹å¦‚å°çš„å¹³é¢è¡¨ç¤ºç­‰ç­‰ã€‚</p>
<p> æ— è®ºæ˜¯<code>backward mapping</code>è¿˜æ˜¯<code>forward mapping</code>ï¼Œè¿™ä¸ªè¿‡ç¨‹éƒ½æ¶‰åŠåˆ°å°†è¿ç»­çš„è¡¨ç¤ºå˜æˆç¦»æ•£çš„ã€‚åœ¨<code>backward mapping</code>é‡Œï¼Œæ˜¯å¯¹åœºè¿›è¡Œé‡‡æ ·ï¼›åœ¨<code>forward mapping</code>é‡Œï¼Œæ˜¯éœ€è¦ç›´æ¥ç”Ÿæˆå‡ºåŸºå…ƒï¼Œè¿™ä¹Ÿæ˜¯ä¸€ç§è¿ç»­åŒ–ä¸ºç¦»æ•£ã€‚ä¸ºäº†ç†è§£åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œé«˜æ–¯åˆ†å¸ƒä¸ºä»€ä¹ˆé‡è¦ï¼Œæˆ‘ä»¬éœ€è¦ç‰µæ‰¯åˆ°ä¿¡å·ä¸ç³»ç»Ÿä¸­çš„æ¦‚å¿µã€‚ä¸æ··è¿‡æ•°å­—ä¿¡å·å¤„ç†è€ƒè¯•ä¸åŒçš„æ˜¯ï¼Œæˆ‘ä»¬è¦æ¸…æ¥šæ­¤æ—¶å¼•å…¥ä¿¡å·ä¸ç³»ç»Ÿé‡Œçš„å·¥å…·çš„ç›®çš„æ˜¯ä»€ä¹ˆã€‚å›æƒ³åˆšæ‰ä¸‰è§’é¢åŸºå…ƒçš„æƒ…æ™¯ï¼Œåœ¨å®é™…æƒ…å¢ƒä¸­ï¼Œæˆ‘ä»¬å…¶å®éƒ½æ¥è§¦ä¸åˆ°â€œè¿ç»­â€çš„è¡¨è¾¾ï¼Œæ¯”å¦‚ä¸‰è§’é¢ï¼Œæˆ‘ä»¬åªä¼šè®°å½•å®ƒçš„ä¸‰ä¸ªé¡¶ç‚¹ã€‚å½“æŠ•å½±å®Œæˆåï¼Œæˆ‘ä»¬åªèƒ½åšä¸€äº›æœ‰é™çš„æ“ä½œæ¥é˜»æ­¢â€œé”¯é½¿â€ï¼Œä¾‹å¦‚å¯¹ç»“æœè¿›è¡Œä¸€ä¸ªæ¨¡ç³Šæ“ä½œï¼Œè¿™äº›æ“ä½œä¸€èˆ¬éƒ½æ˜¯å±€éƒ¨çš„ã€‚æˆ‘ä»¬è¿™æ ·åšçš„ç›®çš„ï¼Œæœ¬è´¨æ˜¯â€œå¸Œæœ›ç”¨ç¦»æ•£çš„è¡¨è¾¾æ¥é‡å»ºåŸæ¥çš„ä¿¡å·ï¼Œè¿›ä¸€æ­¥åœ¨é‡å»ºå¥½çš„ä¿¡å·ä¸Šè¿›è¡Œâ€œresamplingâ€ã€‚å¦‚æœæˆ‘ä»¬å¯¹å¤„ç†åçš„ç»“æœï¼Œè§†è§‰ä¸Šçœ‹èµ·æ¥æ²¡ä»€ä¹ˆæ··å æˆ–è€…é”¯é½¿ä¸Šçš„é—®é¢˜ï¼Œé‚£å°±è¯´æ˜æˆ‘ä»¬â€œresamplingâ€æ˜¯æˆåŠŸçš„ã€‚</p>
</blockquote>
<p>ä»ä¸‹å›¾ä¹Ÿå¯ä»¥çœ‹åˆ°NeRFå’ŒGaussianåœ¨æ¦‚å¿µä¸Šçš„åŒºåˆ«ï¼Œå·¦è¾¹æ˜¯NeRFæ²¿ç€å…‰çº¿æŸ¥è¯¢è¿ç»­ MLPï¼Œå³è¾¹æ˜¯Gaussianä¸€ç»„ä¸ç»™å®šå…‰çº¿ç›¸å…³çš„ç¦»æ•£çš„é«˜æ–¯åˆ†å¸ƒ</p>
<p><img src="https://picx.zhimg.com/80/v2-08473faff1a084b3de92e2a86f69f0fd.png" alt=""></p>
<p><img src="https://picx.zhimg.com/80/v2-37166011e5e81d299598141028acff42.png" alt="difference between NeRF and Gaussian Splatting"></p>
<p>é¦–å…ˆç®€å•ä»‹ç»ä¸€ä¸‹ï¼Œ3DGSæ˜¯å¦‚ä½•è¡¨ç¤ºçœŸå®åœºæ™¯çš„ï¼Œå‰é¢ä¹Ÿæœ‰æè¿‡ï¼Œåœ¨<strong>Gaussian Splatting</strong>ä¸­ï¼Œ3Dä¸–ç•Œç”¨ä¸€ç»„3Dç‚¹è¡¨ç¤ºï¼Œå®é™…ä¸Šæ˜¯æ•°ç™¾ä¸‡ä¸ªï¼Œå¤§è‡´åœ¨0.5åˆ°5ç™¾ä¸‡ä¹‹é—´ã€‚æ¯ä¸ªç‚¹æ˜¯ä¸€ä¸ª3Dé«˜æ–¯ï¼Œå…·æœ‰å…¶ç‹¬ç‰¹çš„å‚æ•°ï¼Œè¿™äº›å‚æ•°æ˜¯ä¸ºæ¯ä¸ªåœºæ™¯æ‹Ÿåˆçš„ï¼Œä»¥ä¾¿è¯¥åœºæ™¯çš„æ¸²æŸ“ä¸å·²çŸ¥æ•°æ®é›†å›¾åƒç´§å¯†åŒ¹é…ï¼Œæ¥ä¸‹æ¥å°±ä»‹ç»ä»–çš„å±æ€§ã€‚</p>
<p><img src="https://pica.zhimg.com/80/v2-f440b37ac00a08977b2b6e5514ffec1f.png" alt="Representing a 3D world"></p>
<ul>
<li><p><strong>3Dé«˜æ–¯çš„å±æ€§</strong>ï¼š ä¸€ä¸ª3Dé«˜æ–¯ä¸»è¦åŒ…æ‹¬ï¼Œä¸­å¿ƒï¼ˆä½ç½®ï¼‰$x,y,z$çš„å‡å€¼$Î¼$ã€ä¸é€æ˜åº¦ $Î±$ã€3D åæ–¹å·®çŸ©é˜µ $Î£$ å’Œé¢œè‰² $c$ï¼ˆä¸€èˆ¬æ˜¯RGBæˆ–è€…æ˜¯çƒè°ï¼ˆSHï¼‰ç³»æ•°ï¼‰ã€‚ å…¶ä¸­$c$ä¸è§†è§’æœ‰å…³ï¼Œ$c$ ç”±çƒè°å‡½æ•°è¡¨ç¤ºã€‚æ‰€æœ‰å±æ€§å‡å¯å­¦ä¹ ï¼Œéƒ½å¯ä»¥é€šè¿‡åå‘ä¼ æ’­æ¥å­¦ä¹ å’Œä¼˜åŒ–ã€‚</p>
</li>
<li><p><strong>è§†åŸŸå‰”é™¤</strong>ï¼šç»™å®šç‰¹å®šçš„ç›¸æœºå§¿æ€ï¼Œè¯¥æ­¥éª¤ä¼šåˆ¤æ–­å“ªäº›é«˜æ–¯ä½äºç›¸æœºçš„è§†é”¥å¤–ï¼Œå¹¶åœ¨åç»­æ­¥éª¤ä¸­å‰”é™¤ä¹‹ï¼Œä»¥èŠ‚çœè®¡ç®—ã€‚</p>
</li>
<li><p><strong>Splattingæ³¼æº…</strong>ï¼šå®é™…ä¸Šåªæ˜¯3Dé«˜æ–¯ï¼ˆæ¤­åœ†ä½“ï¼‰æŠ•å½±åˆ°2Då›¾åƒç©ºé—´ï¼ˆæ¤­åœ†ï¼‰ä¸­è¿›è¡Œæ¸²æŸ“ã€‚ç»™å®šè§†å›¾å˜æ¢ $W$ å’Œ3Dåæ–¹å·®çŸ©é˜µ$\Sigma$ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä½¿ç”¨ä»¥ä¸‹å…¬å¼è®¡ç®—æŠ•å½± 2D åæ–¹å·®çŸ©é˜µ $\Sigma^{\prime}$</p>
<script type="math/tex; mode=display">
\Sigma^{\prime}=JW\Sigma W^\top J^\top</script><p>å…¶ä¸­ $J$ ä¸ºæŠ•å½±å˜æ¢ä¸­ä»¿å°„è¿‘ä¼¼çš„é›…å¯æ¯”çŸ©é˜µã€‚</p>
</li>
<li><p><strong>åƒç´ æ¸²æŸ“</strong>ï¼šå¦‚æœä¸è€ƒè™‘å¹¶è¡Œï¼Œé‡‡ç”¨æœ€ç®€å•çš„æ–¹å¼ï¼šç»™å®šåƒç´  $x$ çš„ä½ç½®ï¼Œä¸å…¶åˆ°æ‰€æœ‰é‡å é«˜æ–¯å‡½æ•°çš„è·ç¦»ï¼Œå³è¿™äº›é«˜æ–¯å‡½æ•°çš„æ·±åº¦ã€‚è¿™äº›å¯ä»¥é€šè¿‡è§‚å¯Ÿå˜æ¢ $W$ è®¡ç®—å‡ºæ¥ï¼Œå½¢æˆé«˜æ–¯å‡½æ•°çš„æ’åºåˆ—è¡¨$N$ã€‚ç„¶åè¿›è¡Œalphaæ··åˆï¼Œè®¡ç®—è¯¥åƒç´ çš„æœ€ç»ˆé¢œè‰²ï¼š</p>
<script type="math/tex; mode=display">
C=\sum_{i\in\mathcal{N}}c_i\alpha_i^{\prime}\prod_{j=1}^{i-1}\left(1-\alpha_j^{\prime}\right.)</script><p>å…¶ä¸­ $c_i$ æ˜¯å­¦ä¹ åˆ°çš„é¢œè‰²ï¼Œæœ€ç»ˆçš„ä¸é€æ˜åº¦ $\alpha_i^{\prime}$ æ˜¯å­¦ä¹ çš„ä¸é€æ˜åº¦ $\alpha_i$ ä¸é«˜æ–¯çš„ä¹˜ç§¯:</p>
<script type="math/tex; mode=display">
\alpha_i'=\alpha_i\times\exp\left(-\frac12(x'-\mu_i')^\top\Sigma_i'^{-1}(x'-\mu_i')\right)</script></li>
</ul>
<p>  å…¶ä¸­ $xâ€™$ å’Œ $Î¼â€™_i$ æ˜¯æŠ•å½±ç©ºé—´ä¸­çš„åæ ‡ï¼ŒåŒæ—¶æˆ‘ä¹Ÿæ‰¾äº†ä¸ªgifæ¥å¯è§†åŒ–äº†ä¸€ä¸‹Gaussian Splattingå¯¹ä½ç½®pçš„å½±å“ï¼š</p>
<p>  <img src="/img/3dgs.gif" alt="3DGS"></p>
<p>  å¦‚æœä»”ç»†çœ‹çš„è¯ï¼Œæˆ‘ä»¬ä¼šå‘ç°ï¼Œå®é™…ä¸Šè¿™ä¸ªå…¬å¼å’Œ<a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">å¤šå˜é‡æ­£æ€åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°</a>ååˆ†ç›¸åƒï¼Œæ˜¯å¿½ç•¥äº†å¸¦æœ‰åæ–¹å·®è¡Œåˆ—å¼çš„æ ‡å‡†åŒ–é¡¹ï¼Œè€Œæ˜¯ç”¨ä¸é€æ˜åº¦æ¥åŠ æƒã€‚</p>
<script type="math/tex; mode=display">
  (2\pi)^{-k/2}\det(\boldsymbol{\Sigma})^{-1/2}\exp\biggl(-\frac12(\mathbf{x}-\boldsymbol{\mu})^\mathrm{T}\boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\biggr)</script><p>  ä¸è¿‡å¦‚æœè€ƒè™‘å¹¶è¡Œçš„è¯åŠ å¿«é€Ÿåº¦ï¼Œè¿™ç§åˆ—è¡¨æ’åºå®é™…ä¸Šå¾ˆéš¾å¹¶è¡ŒåŒ–ï¼Œæ‰€ä»¥å¾ˆæœ‰å¯èƒ½è¿™ä¸ªæ¸²æŸ“ç¨‹åº¦æ¯”NeRFè¿˜æ…¢ã€‚ä¸ºäº†å®ç°å®æ—¶æ¸²æŸ“ï¼Œ3DGSä¹Ÿåšäº†ä¸€ä¸ªtradeoffï¼Œ3DGSåšå‡ºäº†ä¸€äº›è®©æ­¥æ¥é€‚åº”<strong>å¹¶è¡Œè®¡ç®—</strong>ã€‚</p>
<p>  <img src="https://picx.zhimg.com/80/v2-7cea6c4b183982cd921c0456d1f689b7.png" alt="Tiles(Patches)"></p>
<ul>
<li><p><strong>Tiles (Patches)</strong>ï¼šä¸ºé¿å…é€åƒç´ è®¡ç®—å‡ºç°çš„æˆæœ¬ï¼Œ3DGSæ”¹ä¸º<strong>patch</strong>çº§åˆ«çš„æ¸²æŸ“ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆå°†å›¾åƒåˆ†å‰²ä¸ºå¤šä¸ªä¸é‡å çš„patchï¼Œç§°ä¸º<code>tile</code>ï¼Œæ¯ä¸ªå›¾å—åŒ…å« 16Ã—16 åƒç´ ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚3DGSç„¶åç¡®å®š<code>tile</code>ä¸æŠ•å½±é«˜æ–¯çš„ç›¸äº¤æƒ…å†µï¼Œç”±äºæŠ•å½±é«˜æ–¯å¯èƒ½ä¼šä¸å¤šä¸ª<code>tile</code>ç›¸äº¤ï¼Œéœ€è¦è¿›è¡Œå¤åˆ¶ï¼Œå¹¶ä¸ºæ¯ä¸ªå¤åˆ¶ä½“åˆ†é…ç›¸å…³tileçš„æ ‡è¯†ç¬¦ï¼ˆå¦‚<code>tile</code>çš„IDï¼‰ã€‚(ä¸ç”¨åˆ¤æ–­æ¯ä¸ªåƒç´ ä¸é«˜æ–¯çš„è·ç¦»ï¼Œè€Œæ˜¯åˆ¤æ–­tileå°±ç®€å•å¤šäº†)</p>
<p><img src="https://picx.zhimg.com/80/v2-c81242a6677621910801fcec4c0adbee.png" alt=""></p>
<p>ä»ä¸‹å›¾å¯ä»¥çœ‹åˆ°æ’åºçš„ç»“æœï¼Œåœ¨æ’åºä¸­ï¼Œé«˜ä½æ˜¯tileçš„IDï¼Œä½ä½å°±æ˜¯æ·±åº¦ï¼Œä¸€èµ·è¿›è¡Œæ’åºï¼Œä¸‹é¢çš„å›¾æ˜¯AIè‘µè§†é¢‘çš„ç»“æœï¼Œè¿˜æ˜¯å¾ˆå¥½ç†è§£çš„</p>
<p><img src="https://pic1.zhimg.com/80/v2-5c74958d484c1d2588c20c8c30b58411.png" alt="3DGSæ’åº"></p>
<p><img src="https://picx.zhimg.com/80/v2-3d6e3aec3a86c1d94354458830dbf17f.png" alt="3DGSæ’åºä¾‹å­(AIè‘µ)"></p>
</li>
<li><p><strong>å¹¶è¡Œæ¸²æŸ“</strong>ï¼šå¤åˆ¶åï¼Œ3DGSï¼ˆå¯¹åº”å­—èŠ‚çš„æ— åºåˆ—è¡¨ï¼‰ç»“åˆåŒ…å«äº†ç›¸å…³çš„tile IDï¼ˆå¯¹åº”å­—èŠ‚çš„é«˜ä½ï¼‰å’Œæ·±åº¦ä¿¡æ¯ï¼ˆå¯¹åº”å­—èŠ‚çš„ä½ä½ï¼‰ï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºã€‚ç”±äºæ¯ä¸€å—å’Œæ¯ä¸€åƒç´ çš„è®¡ç®—æ˜¯ç‹¬ç«‹çš„ï¼Œæ‰€ä»¥å¯ä»¥åŸºäºCUDAç¼–ç¨‹çš„å—å’Œçº¿ç¨‹æ¥å®ç°å¹¶è¡Œè®¡ç®—ï¼ŒåŒæ—¶æœ‰åˆ©äºè®¿é—®å…¬å…±å…±äº«å†…å­˜å¹¶ä¿æŒç»Ÿä¸€çš„è¯»å–é¡ºåºã€‚æ’åºåçš„åˆ—è¡¨å¯ç›´æ¥ç”¨äºæ¸²æŸ“ï¼ˆalphaæ··åˆï¼‰ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p>
<p><img src="https://pic1.zhimg.com/80/v2-6393ea51f715d0d0baa880cd1890a549.png" alt="å¹¶è¡Œæ¸²æŸ“"></p>
<p>æ€»çš„æ¥è¯´ï¼Œ3DGSåœ¨å‰å‘è¿‡ç¨‹ä¸­åšå‡ºäº†ä¸€äº›è¿‘ä¼¼è®¡ç®—ï¼Œä»¥æé«˜è®¡ç®—æ•ˆç‡å¹¶ä¿ç•™å›¾åƒåˆæˆçš„é«˜è´¨é‡ã€‚</p>
</li>
</ul>
<h3 id="3DGSçš„ä¼˜åŒ–"><a href="#3DGSçš„ä¼˜åŒ–" class="headerlink" title="3DGSçš„ä¼˜åŒ–"></a>3DGSçš„ä¼˜åŒ–</h3><p>å­¦ä¹ åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å¯èƒ½ä¼šæœ‰ä¸€ä¸ªé—®é¢˜ï¼Œæ€ä¹ˆå¯èƒ½åœ¨ç©ºé—´ä¸­çš„ä¸€å †åœ†çƒä¸­å¾—åˆ°ä¸€ä¸ªåƒæ ·çš„å›¾åƒçš„ï¼Œç¡®å®æ˜¯è¿™æ ·ï¼Œå¦‚æœæ²¡æœ‰è¿›è¡Œä¼˜åŒ–ï¼Œåœ¨æ¸²æŸ“çš„æ—¶å€™å°±ä¼šå‡ºç°å¾ˆå¤šä¼ªå½±ï¼Œä»ä¸‹å›¾ä½ å¯ä»¥çœ‹åˆ°ã€‚</p>
<p><img src="https://pic1.zhimg.com/80/v2-7ad69d962fb9a18d84747130af62fe15.png" alt="An example of renders of an under-optimized scene"></p>
<p>3DGSçš„æ ¸å¿ƒæ˜¯<strong>3Dé«˜æ–¯é›†åˆçš„ä¼˜åŒ–è¿‡ç¨‹</strong>ã€‚ä¸€æ–¹é¢éœ€è¦é€šè¿‡å¯å¾®æ¸²æŸ“æ¥ä½¿é«˜æ–¯ç¬¦åˆåœºæ™¯çº¹ç†ï¼Œå¦ä¸€æ–¹é¢è¡¨è¾¾åœºæ™¯éœ€è¦çš„é«˜æ–¯æ•°é‡æ˜¯æœªçŸ¥çš„ã€‚è¿™åˆ†åˆ«å¯¹åº”å‚æ•°ä¼˜åŒ–ä¸å¯†åº¦æ§åˆ¶ä¸¤æ­¥ï¼Œè¿™ä¸¤æ­¥åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­äº¤æ›¿è¿›è¡Œã€‚ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œéœ€è¦æ‰‹åŠ¨è®¾ç½®å¾ˆå¤šè¶…å‚æ•°ã€‚</p>
<h4 id="å‚æ•°ä¼˜åŒ–-Parameter-Optimization"><a href="#å‚æ•°ä¼˜åŒ–-Parameter-Optimization" class="headerlink" title="å‚æ•°ä¼˜åŒ– Parameter Optimization"></a>å‚æ•°ä¼˜åŒ– Parameter Optimization</h4><ul>
<li><p><strong>æŸå¤±å‡½æ•°</strong>ï¼šå›¾åƒåˆæˆåï¼Œè®¡ç®—æ¸²æŸ“å›¾åƒä¸çœŸå®å›¾åƒçš„å·®å¼‚ä½œä¸ºæŸå¤±ï¼š</p>
<script type="math/tex; mode=display">
\mathcal{L}=(1-\lambda)\mathcal{L}_1+\lambda\mathcal{L}_{D-SSIM}</script><p>å…¶ä¸­ $Î»$ æ˜¯æƒé‡å› å­ã€‚ä¸ NeRF çš„æŸå¤±å‡½æ•°ç•¥æœ‰ä¸åŒï¼Œç”±äºå…‰çº¿è¡Œè¿›æˆæœ¬é«˜æ˜‚ï¼ŒNeRF é€šå¸¸åœ¨åƒç´ çº§åˆ«è€Œä¸æ˜¯å›¾åƒçº§åˆ«è¿›è¡Œè®¡ç®—ï¼Œè€Œ3DGSæ˜¯å›¾åƒçº§åˆ«çš„ã€‚</p>
</li>
<li><p><strong>å‚æ•°æ›´æ–°</strong>ï¼š3Dé«˜æ–¯çš„å¤šæ•°å‚æ•°å¯é€šè¿‡åå‘ä¼ æ’­ç›´æ¥æ›´æ–°ï¼Œä½†å¯¹äºåæ–¹å·®çŸ©é˜µ $\Sigma$æ¥è¯´ï¼Œéœ€è¦åŠæ­£å®šçŸ©é˜µï¼ˆè¿™é‡Œé¢æ˜¯ä¸€ä¸ªå®šä¹‰ï¼Œåº”è¯¥æ˜¯å¤šå…ƒæ­£æ€åˆ†å¸ƒçš„åæ–¹å·®çŸ©é˜µæ˜¯ä¸€ä¸ªåŠæ­£å®šçŸ©é˜µï¼‰ï¼Œç›´æ¥ä¼˜åŒ–å¯èƒ½ä¼šäº§ç”ŸéåŠæ­£å®šçŸ©é˜µï¼Œè€Œåªæœ‰åŠæ­£å®šçŸ©é˜µæ‰æœ‰ç‰©ç†æ„ä¹‰ã€‚å› æ­¤ï¼Œæ”¹ä¸ºä¼˜åŒ–å››å…ƒæ•°$q$å’Œ3Då‘é‡$s$ã€‚å°†åæ–¹å·®çŸ©é˜µåˆ†è§£ï¼š</p>
<script type="math/tex; mode=display">
\Sigma=RSS^\top R^\top</script><p>å…¶ä¸­$R$ä¸$S$åˆ†åˆ«ç”±$q$å’Œ$s$æ¨å¯¼å¾—åˆ°çš„æ—‹è½¬å’Œç¼©æ”¾çŸ©é˜µã€‚</p>
<ul>
<li>$S$æ˜¯ä¸€ä¸ªå¯¹è§’ç¼©æ”¾çŸ©é˜µï¼Œå«æœ‰3ä¸ªå‚æ•°</li>
<li>$R$æ˜¯ä¸€ä¸ª3x3çš„æ—‹è½¬çŸ©é˜µï¼Œé€šè¿‡æ—‹è½¬å››å…ƒæ•°æ¥è¡¨ç¤º</li>
</ul>
<p>å¯¹äºä¸é€æ˜åº¦$Î±$, å…¶è®¡ç®—å›¾è¾ƒä¸ºå¤æ‚ï¼š$(q,s)\to\Sigma\to\Sigma^{\prime}\to\alpha$ã€‚ä¸ºé¿å…è‡ªåŠ¨å¾®åˆ†çš„è®¡ç®—æ¶ˆè€—ï¼Œ3DGSè¿˜æ¨å¯¼äº†$q$ä¸$s$çš„æ¢¯åº¦ï¼Œåœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ç›´æ¥è®¡ç®—ä¹‹ã€‚</p>
</li>
</ul>
<h4 id="å¯†åº¦æ§åˆ¶-Density-Control"><a href="#å¯†åº¦æ§åˆ¶-Density-Control" class="headerlink" title="å¯†åº¦æ§åˆ¶ Density Control"></a>å¯†åº¦æ§åˆ¶ Density Control</h4><ul>
<li><strong>åˆå§‹åŒ–</strong>ï¼š3DGSå»ºè®®ä»SfMäº§ç”Ÿçš„ç¨€ç–ç‚¹äº‘åˆå§‹åŒ–æˆ–éšæœºåˆå§‹åŒ–é«˜æ–¯ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨ <a href="https://colmap.github.io/">COLMAP</a> åº“æ¥å®Œæˆè¿™ä¸€æ­¥ã€‚ã€‚ç„¶åè¿›è¡Œç‚¹çš„å¯†é›†åŒ–å’Œå‰ªæä»¥æ§åˆ¶3Dé«˜æ–¯çš„å¯†åº¦ã€‚å½“ç”±äºæŸç§åŸå› æ— æ³•è·å¾—ç‚¹äº‘æ—¶ï¼Œå¯ä»¥ä½¿ç”¨éšæœºåˆå§‹åŒ–æ¥ä»£æ›¿ï¼Œä½†å¯èƒ½ä¼šé™ä½æœ€ç»ˆçš„é‡å»ºè´¨é‡ã€‚</li>
</ul>
<p><img src="https://picx.zhimg.com/80/v2-0d67e5748993593a04ed46f7519e972e_720w.png" alt="A sparse 3D point cloud produced by SfM, means initialization"></p>
<ul>
<li><p><strong>ç‚¹å¯†é›†åŒ–</strong>ï¼šåœ¨ç‚¹å¯†é›†åŒ–é˜¶æ®µï¼Œ3DGSè‡ªé€‚åº”åœ°å¢åŠ é«˜æ–¯çš„å¯†åº¦ï¼Œä»¥æ›´å¥½åœ°æ•æ‰åœºæ™¯çš„ç»†èŠ‚ã€‚è¯¥è¿‡ç¨‹ç‰¹åˆ«å…³æ³¨ç¼ºå¤±å‡ ä½•ç‰¹å¾æˆ–é«˜æ–¯è¿‡äºåˆ†æ•£çš„åŒºåŸŸã€‚å¯†é›†åŒ–åœ¨ä¸€å®šæ•°é‡çš„è¿­ä»£åæ‰§è¡Œï¼Œæ¯”å¦‚100ä¸ªè¿­ä»£ï¼Œé’ˆå¯¹åœ¨è§†å›¾ç©ºé—´ä¸­å…·æœ‰è¾ƒå¤§ä½ç½®æ¢¯åº¦ï¼ˆå³è¶…è¿‡ç‰¹å®šé˜ˆå€¼ï¼‰çš„é«˜æ–¯ã€‚å…¶åŒ…æ‹¬åœ¨æœªå……åˆ†é‡å»ºçš„åŒºåŸŸå…‹éš†å°é«˜æ–¯æˆ–åœ¨è¿‡åº¦é‡å»ºçš„åŒºåŸŸåˆ†è£‚å¤§é«˜æ–¯ã€‚å¯¹äºå…‹éš†ï¼Œåˆ›å»ºé«˜æ–¯çš„å¤åˆ¶ä½“å¹¶æœç€ä½ç½®æ¢¯åº¦ç§»åŠ¨ã€‚å¯¹äºåˆ†è£‚ï¼Œç”¨ä¸¤ä¸ªè¾ƒå°çš„é«˜æ–¯æ›¿æ¢ä¸€ä¸ªå¤§é«˜æ–¯ï¼ŒæŒ‰ç…§ç‰¹å®šå› å­å‡å°å®ƒä»¬çš„å°ºåº¦ã€‚è¿™ä¸€æ­¥æ—¨åœ¨åœ¨3Dç©ºé—´ä¸­å¯»æ±‚é«˜æ–¯çš„æœ€ä½³åˆ†å¸ƒå’Œè¡¨ç¤ºï¼Œå¢å¼ºé‡å»ºçš„æ•´ä½“è´¨é‡ã€‚</p>
<p>è¿™ä¸€éƒ¨åˆ†çš„æ„ä¹‰æ˜¯ä»€ä¹ˆå‘¢ï¼Œå› ä¸ºSGDåªèƒ½å¯¹ç°æœ‰ç‚¹è¿›è¡Œè°ƒæ•´ï¼Œä½†æ˜¯åœ¨å®Œå…¨æ²¡æœ‰ç‚¹æˆ–ç‚¹å¤ªå¤šçš„åŒºåŸŸï¼Œå¾ˆéš¾æ‰¾åˆ°å¥½çš„å‚æ•°ï¼Œæ‰€ä»¥è¿™å°±æ˜¯ç‚¹å¯†é›†åŒ–çš„ä½œç”¨ã€‚</p>
</li>
<li><p><strong>ç‚¹çš„å‰ªæ</strong>ï¼šç‚¹çš„å‰ªæé˜¶æ®µç§»é™¤å†—ä½™æˆ–å½±å“è¾ƒå°çš„é«˜æ–¯ï¼Œå¯ä»¥åœ¨æŸç§ç¨‹åº¦ä¸Šçœ‹ä½œæ˜¯ä¸€ç§æ­£åˆ™åŒ–è¿‡ç¨‹ã€‚ä¸€èˆ¬æ¶ˆé™¤å‡ ä¹æ˜¯é€æ˜çš„é«˜æ–¯ï¼ˆÎ±ä½äºæŒ‡å®šé˜ˆå€¼ï¼‰å’Œåœ¨ä¸–ç•Œç©ºé—´æˆ–è§†å›¾ç©ºé—´ä¸­è¿‡å¤§çš„é«˜æ–¯ã€‚æ­¤å¤–ï¼Œä¸ºé˜²æ­¢è¾“å…¥ç›¸æœºé™„è¿‘çš„é«˜æ–¯å¯†åº¦ä¸åˆç†åœ°å¢åŠ ï¼Œè¿™äº›é«˜æ–¯ä¼šåœ¨å›ºå®šæ¬¡æ•°çš„è¿­ä»£åå°†$\alpha$è®¾ç½®ä¸ºæ¥è¿‘0çš„å€¼ã€‚è¯¥æ­¥éª¤åœ¨ä¿è¯é«˜æ–¯çš„ç²¾åº¦å’Œæœ‰æ•ˆæ€§çš„æƒ…å†µä¸‹ï¼Œèƒ½èŠ‚çº¦è®¡ç®—èµ„æºã€‚</p>
</li>
</ul>
<p><img src="https://picx.zhimg.com/80/v2-58c80507588563289c26e2ea4066ad81.png" alt="Adaptive Gaussian densification scheme."></p>
<h3 id="ç”¨SHç³»æ•°æ¥è¡¨ç¤ºé¢œè‰²"><a href="#ç”¨SHç³»æ•°æ¥è¡¨ç¤ºé¢œè‰²" class="headerlink" title="ç”¨SHç³»æ•°æ¥è¡¨ç¤ºé¢œè‰²"></a>ç”¨SHç³»æ•°æ¥è¡¨ç¤ºé¢œè‰²</h3><p>åœ¨è®¡ç®—æœºå›¾å½¢å­¦ä¸­ï¼Œç”¨çƒè°å‡½æ•°ï¼ˆSpherical Harmonicsï¼Œç®€ç§°SHï¼‰è¡¨ç¤ºè§†è§’ç›¸å…³çš„é¢œè‰²èµ·ç€é‡è¦ä½œç”¨ï¼Œæœ€åˆæ˜¯åœ¨Plenoxelsä¸­æå‡ºçš„ã€‚ä»–èƒ½è¡¨ç¤ºéå…°ä¼¯ç‰¹æ•ˆåº”ï¼Œæ¯”å¦‚é‡‘å±è¡¨é¢çš„é«˜å…‰åå°„ã€‚ä¸è¿‡è¿™æ ·ä¹Ÿä¸æ˜¯ä¸€å®šçš„ï¼Œå®é™…ä¸Šä¹Ÿå¯ä»¥ä½¿ç”¨3ä¸ªRGBå€¼è¡¨ç¤ºé¢œè‰²ï¼Œç„¶åä½¿ç”¨Gaussian Splattingã€‚</p>
<p> å›¾å½¢å­¦å…¨å±€ç¯å¢ƒå…‰ç…§æŠ€æœ¯ä¸çƒè°å‡½æ•°æ¯æ¯ç›¸å…³ï¼Œæˆ‘ä»¬çš„ç¯å¢ƒå…‰æ¥æºå››é¢å…«æ–¹ï¼Œå¯ä»¥ç†è§£ä¸ºä¸€ä¸ªçƒé¢å‡½æ•°ï¼Œå½“æ¨¡æ‹Ÿæ¼«åå°„ç¯å¢ƒå…‰ï¼Œæˆ‘ä»¬ç”¨ä¸€å¼ ç¯å¢ƒè´´å›¾è¿›è¡Œé‡‡æ ·ï¼Œå¯¹æ¯ä¸€ä¸ªç‚¹è¿›è¡ŒåŠçƒé‡‡æ ·å‡ºåœ¨è¿™ä¸ªåƒç´ ä¸Šçš„é¢œè‰²ï¼Œ<strong>çƒè°å…‰ç…§</strong>ç®€å•æ¥è¯´å°±æ˜¯ç”¨å‡ ä¸ªç³»æ•°å­˜å–äº†æ•´å¼ ç¯å¢ƒè´´å›¾åŒ…å›´åœ¨çƒä¸Š<strong>æ³•çº¿æ–¹å‘</strong>æ‰€å¯¹åº”çš„çš„é¢œè‰²ä¿¡æ¯ã€‚åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ä¼ å…¥çƒè°ç³»æ•°ã€‚åœ¨æ¨¡å‹ä¸Šæ ¹æ®å¯¹åº”çš„æ³•çº¿ä¿¡æ¯ï¼Œä»çƒè°å‡½æ•°ä¸­è·å–å¯¹åº”çš„é¢œè‰²ä¿¡æ¯ã€‚</p>
<p>çƒè°å‡½æ•°æ˜¯å®šä¹‰åœ¨çƒé¢ä¸Šçš„ç‰¹æ®Šå‡½æ•°ï¼Œæ¢å¥è¯è¯´ï¼Œå¯ä»¥å¯¹çƒé¢ä¸Šçš„ä»»æ„ç‚¹è®¡ç®—è¿™æ ·ä¸€ä¸ªå‡½æ•°å¹¶å¾—åˆ°ä¸€ä¸ªå€¼ã€‚</p>
<p>è¿™é‡Œæˆ‘ä»¬ç®€å•ç†è§£ä¸€ä¸‹ï¼ŒSHï¼Œçƒè°å‡½æ•°ï¼Œå½’æ ¹åˆ°åº•åªæ˜¯ä¸€ç»„åŸºå‡½æ•°ï¼Œè‡³äºè¿™ç»„åŸºå‡½æ•°æ˜¯æ€ä¹ˆæ¥çš„ï¼Œä¸ç®¡ä»–ã€‚ç®€å•ç‚¹æ¥è¯´ï¼Œæ¯ä¸€ä¸ªå‡½æ•°éƒ½å¯ä»¥ç”±å¤šä¸ªåŸºå‡½æ•°ç»„åˆèµ·æ¥ï¼Œå¦‚æœæˆ‘ä»¬æœ‰å¾ˆå¤šåŸºå‡½æ•°ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å¯¹åº”çš„æƒé‡ç³»æ•°å¤åŸå‡ºåŸæ¥çš„å‡½æ•°ï¼Œä¸è¿‡æœ¬è´¨ä¸Šè¿˜æ˜¯ä¸€ä¸ªæœ‰æŸå‹ç¼©ï¼Œä¸ä¸€å®šé‚£ä¹ˆå‡†ç¡®ï¼Œä¸è¿‡å¦‚æœåŸºå‡½æ•°è¶Šå¤šï¼Œå¤åŸçš„å‡½æ•°è¶Šå‡†ç¡®ï¼Œä½†æ˜¯è®¡ç®—é‡ä¹Ÿå˜å¤§äº†ã€‚</p>
<p>åœ¨çƒé¢åŸºå‡½æ•°ä¸­ï¼Œæœ€å¤šçš„å°±æ˜¯çƒè°å‡½æ•°äº†ã€‚çƒè°å‡½æ•°æœ‰å¾ˆå¤šå¾ˆå¥½çš„æ€§è´¨ï¼Œæ¯”å¦‚æ­£äº¤æ€§ï¼Œæ—‹è½¬ä¸å˜æ€§ï¼ˆè¿™è¾¹å°±ä¸ä»‹ç»äº†ï¼‰ã€‚æ­£äº¤æ€§è¯´æ˜æ¯ä¸ªåŸºå‡½æ•°éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œæ¯ä¸ªåŸºå‡½æ•°éƒ½ä¸èƒ½ç”¨åˆ«çš„åŸºå‡½æ•°åŠ æƒå¾—åˆ°ã€‚å½“SHçš„ç³»æ•°ç”¨çš„è¶Šå¤šï¼Œé‚£ä¹ˆè¡¨è¾¾èƒ½åŠ›å°±è¶Šå¼ºï¼Œè·ŸåŸå§‹çš„å‡½æ•°å°±è¶Šæ¥è¿‘ã€‚ï¼ˆå¦‚æœæ›´è¯¦ç»†çš„äº†è§£å¯ä»¥çœ‹çœ‹ä¸€äº›åŸç†ï¼Œæˆ‘ä¸»è¦æ˜¯å®è§‚çš„äº†è§£SHæ˜¯ä»€ä¹ˆï¼Œç®€å•ç†è§£å°±æ˜¯ä»–æ˜¯ä¸€ç§é¢œè‰²çš„è¡¨ç¤ºï¼‰</p>
<p><img src="https://pic1.zhimg.com/80/v2-9e660f32e92e1897aa986b0ab2ce073e.png" alt=""></p>
<p>å½“ç”¨æ¥æè¿°ä¸åŒæ–¹å‘å…‰ç…§çš„SHåŸºå‡½æ•°ï¼Œæˆ‘ä»¬ä¸€èˆ¬ç”¨äºŒé˜¶æˆ–è€…ä¸‰é˜¶ï¼Œæ¯”å¦‚ä¸‹é¢çš„ä¾‹å­å°±æ˜¯3é˜¶çš„</p>
<p><img src="https://picx.zhimg.com/80/v2-f6bfb715b846bf13c95013ca96c1d51d.png" alt=""></p>
<p>ä¸‹é¢å±•ç¤ºçš„æ˜¯ä¸€ä¸ª$l=2$å’Œ3é˜¶çš„çƒè°å‡½æ•°ï¼Œä¸€å…±åŒ…æ‹¬9ä¸ªå­¦ä¹ ç³»æ•°ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®ç‚¹çš„è§†è§’å¾—åˆ°ç›¸å…³é¢œè‰²ï¼Œå¯ä»¥çœ‹åˆ°æœ€åæ˜¯redçº¢è‰²åˆ†é‡ã€‚</p>
<p><img src="https://pica.zhimg.com/80/v2-8241e4f7092a89a158df31b8cde94d33.png" alt="å¾—åˆ°l=2å’Œ9ä¸ªå­¦ä¹ ç³»æ•°çš„ç‚¹çš„è§†è§’ç›¸å…³é¢œè‰²ï¼ˆçº¢è‰²åˆ†é‡ï¼‰çš„è¿‡ç¨‹"></p>
<h3 id="3DGS-æµç¨‹"><a href="#3DGS-æµç¨‹" class="headerlink" title="3DGS æµç¨‹"></a>3DGS æµç¨‹</h3><p>æœ€åæ ¹æ®è®ºæ–‡çš„å›¾æ¥æ€»ç»“ä¸€ä¸‹3DGSçš„æµç¨‹</p>
<p><img src="https://pic1.zhimg.com/80/v2-fda180df51e9171e3e147f5b40e520b9.png" alt="3DGS æµç¨‹"></p>
<ol>
<li><p><strong>Structure from Motion</strong>ï¼šä½¿ç”¨SfMä»ä¸€ç»„å›¾åƒä¸­ä¼°è®¡å‡ºç‚¹äº‘ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨ <a href="https://colmap.github.io/">COLMAP</a>  åº“æ“ä½œ</p>
<p><img src="https://picx.zhimg.com/80/v2-961548f1a56fb5bc81bc8b349472d8ab.png" alt="Structure from Motion"></p>
</li>
</ol>
<ol>
<li><p><strong>Convert to Gaussians</strong>ï¼šå°†æ¯ä¸ªç‚¹å»ºæ¨¡æˆä¸€ä¸ª 3D é«˜æ–¯å›¾åƒã€‚ä» SfM æ•°æ®ä¸­ï¼Œæˆ‘ä»¬èƒ½æ¨æ–­å‡ºæ¯ä¸ªé«˜æ–¯å›¾åƒçš„ä½ç½®å’Œé¢œè‰²ã€‚ä½†å¦‚æœæ˜¯è¦å¾—åˆ°æ›´é«˜è´¨é‡çš„è¡¨å¾çš„è¯ï¼Œè¿˜éœ€è¦å¯¹æ¯ä¸ªé«˜æ–¯å‡½æ•°è¿›è¡Œè®­ç»ƒï¼Œä»¥æ¨æ–­å‡ºæ›´ç²¾ç»†çš„ä½ç½®å’Œé¢œè‰²ï¼Œå¹¶æ¨æ–­å‡ºåæ–¹å·®å’Œé€æ˜åº¦ã€‚</p>
</li>
<li><p><strong>Training</strong>ï¼šä¸ç¥ç»ç½‘ç»œç±»ä¼¼ï¼Œæˆ‘ä»¬ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™æ³•è¿›è¡Œè®­ç»ƒï¼Œä½†è¿™é‡Œæ²¡æœ‰ç¥ç»ç½‘ç»œçš„å±‚çš„æ¦‚å¿µ (éƒ½æ˜¯ 3D é«˜æ–¯å‡½æ•°)ã€‚</p>
<p>è®­ç»ƒæ­¥éª¤å¦‚ä¸‹:</p>
<ol>
<li>ç”¨å½“å‰æ‰€æœ‰å¯å¾®é«˜æ–¯å‡½æ•°æ¸²æŸ“å‡ºå›¾åƒ</li>
<li>æ ¹æ®æ¸²æŸ“å›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å·®å¼‚è®¡ç®—æŸå¤±</li>
<li>æ ¹æ®æŸå¤±è°ƒæ•´æ¯ä¸ªé«˜æ–¯å›¾åƒçš„å‚æ•°</li>
<li>æ ¹æ®æƒ…å†µå¯¹å½“å‰ç›¸å…³é«˜æ–¯å›¾åƒè¿›è¡Œç‚¹çš„å¯†åº¦æ§åˆ¶</li>
</ol>
<p>æ­¥éª¤ 1-3 æ¯”è¾ƒç®€å•ï¼Œä¸‹é¢æˆ‘ä»¬ç¨å¾®è§£é‡Šä¸€ä¸‹ç¬¬ 4 æ­¥çš„å·¥ä½œ:</p>
<ul>
<li>å¦‚æœæŸé«˜æ–¯å›¾åƒçš„æ¢¯åº¦å¾ˆå¤§ (å³å®ƒé”™å¾—æ¯”è¾ƒç¦»è°±)ï¼Œåˆ™å¯¹å…¶è¿›è¡Œåˆ†è£‚æˆ–å…‹éš†<ul>
<li>å¦‚æœè¯¥é«˜æ–¯å›¾åƒå¾ˆå°ï¼Œåˆ™å…‹éš†å®ƒ</li>
<li>å¦‚æœè¯¥é«˜æ–¯å›¾åƒå¾ˆå¤§ï¼Œåˆ™å°†å…¶åˆ†è£‚</li>
</ul>
</li>
<li>å¦‚æœè¯¥é«˜æ–¯å›¾åƒçš„ alpha å¤ªä½ï¼Œåˆ™å°†å…¶åˆ é™¤</li>
</ul>
<p>è¿™ä¹ˆåšèƒ½å¸®åŠ©é«˜æ–¯å›¾åƒæ›´å¥½åœ°æ‹Ÿåˆç²¾ç»†çš„ç»†èŠ‚ï¼ŒåŒæ—¶ä¿®å‰ªæ‰ä¸å¿…è¦çš„é«˜æ–¯å›¾åƒã€‚</p>
</li>
<li><p><strong>Differentiable Gaussian Rasterization</strong>ï¼š3D Gaussian Splattingå®é™…ä¸Šæ˜¯ä¸€ç§å…‰æ …åŒ–çš„æ–¹æ³•ï¼Œå°†æ•°æ®æˆåƒåˆ°å±å¹•ä¸Šï¼Œä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼Œä»–æœ‰ä¸¤ä¸ªç‰¹ç‚¹</p>
<ol>
<li>å¿«</li>
<li>å¯å¾®</li>
</ol>
<p>ä¸»è¦æ­¥éª¤å¦‚ä¸‹ï¼š</p>
<ol>
<li>é’ˆå¯¹ç»™å®šç›¸æœºè§†è§’ï¼ŒæŠŠæ¯ä¸ª 3D é«˜æ–¯æŠ•å½±åˆ° 2Dã€‚</li>
<li>æŒ‰æ·±åº¦å¯¹é«˜æ–¯è¿›è¡Œæ’åºã€‚</li>
<li>å¯¹æ¯ä¸ªåƒç´ ï¼Œä»å‰åˆ°åè®¡ç®—æ¯ä¸ªé«˜æ–¯åœ¨è¯¥åƒç´ ç‚¹çš„å€¼ï¼Œå¹¶å°†æ‰€æœ‰å€¼æ··åˆä»¥å¾—åˆ°æœ€ç»ˆåƒç´ å€¼ã€‚</li>
</ol>
</li>
</ol>
<h3 id="3DGS-Limitations"><a href="#3DGS-Limitations" class="headerlink" title="3DGS Limitations"></a>3DGS Limitations</h3><p><strong>ä¼˜ç‚¹</strong></p>
<ol>
<li>é«˜å“è´¨ã€é€¼çœŸçš„åœºæ™¯</li>
<li>å¿«é€Ÿã€å®æ—¶çš„æ¸²æŸ“</li>
<li>æ›´å¿«çš„è®­ç»ƒé€Ÿåº¦</li>
</ol>
<p><strong>ç¼ºç‚¹</strong></p>
<ol>
<li>é˜²æ­¢æ¨¡å‹ä¼˜åŒ–ä¸­çš„â€œç ´ç¢â€çš„é«˜æ–¯ï¼šç‚¹å¤ªå¤§ã€å¤ªé•¿ã€å†—ä½™ç­‰</li>
<li>æ›´é«˜çš„æ˜¾å­˜ä½¿ç”¨ç‡ (4GB ç”¨äºæ˜¾ç¤ºï¼Œ12GB ç”¨äºè®­ç»ƒ)</li>
<li>æ›´å¤§çš„ç£ç›˜å ç”¨ (æ¯åœºæ™¯ 1GB+)</li>
<li>ä¸ç°æœ‰æ¸²æŸ“ç®¡çº¿ä¸å…¼å®¹</li>
<li><del>åªèƒ½é‡å»ºé™æ€åœºæ™¯ï¼ˆä½†æ˜¯å¥½åƒç°åœ¨åŠ¨æ€çš„Gaussianä¹Ÿå‡ºæ¥äº†ï¼Œæ‰€ä»¥è¿™ä¸ªä¸ç®—ç¼ºç‚¹äº†ï¼‰</del></li>
</ol>
<h2 id="åº”ç”¨é¢†åŸŸå’Œä»»åŠ¡-APPLICATION-AREAS-AND-TASKS"><a href="#åº”ç”¨é¢†åŸŸå’Œä»»åŠ¡-APPLICATION-AREAS-AND-TASKS" class="headerlink" title="åº”ç”¨é¢†åŸŸå’Œä»»åŠ¡ APPLICATION AREAS AND TASKS"></a>åº”ç”¨é¢†åŸŸå’Œä»»åŠ¡ APPLICATION AREAS AND TASKS</h2><h3 id="åŒæ—¶å®šä½å’Œå»ºå›¾ï¼ˆSLAMï¼‰"><a href="#åŒæ—¶å®šä½å’Œå»ºå›¾ï¼ˆSLAMï¼‰" class="headerlink" title="åŒæ—¶å®šä½å’Œå»ºå›¾ï¼ˆSLAMï¼‰"></a>åŒæ—¶å®šä½å’Œå»ºå›¾ï¼ˆSLAMï¼‰</h3><p>SLAMéœ€è¦è®©è®¾å¤‡å®æ—¶ç†è§£è‡ªèº«ä½ç½®å¹¶åŒæ—¶ä¸ºç¯å¢ƒå»ºå›¾ï¼Œå› æ­¤è®¡ç®—é‡å¤§çš„è¡¨è¾¾æŠ€æœ¯éš¾ä»¥åº”ç”¨ã€‚</p>
<p>ä¼ ç»ŸSLAMä½¿ç”¨ç‚¹/surfeläº‘æˆ–ä½“ç´ ç½‘æ ¼è¡¨è¾¾ç¯å¢ƒã€‚3DGSçš„ä¼˜åŠ¿åœ¨äºé«˜æ•ˆæ€§ï¼ˆè‡ªé€‚åº”æ§åˆ¶é«˜æ–¯å¯†åº¦ï¼‰ã€ç²¾ç¡®æ€§ï¼ˆå„å‘å¼‚æ€§é«˜æ–¯èƒ½å»ºæ¨¡ç¯å¢ƒç»†èŠ‚ï¼‰ã€é€‚åº”æ€§ï¼ˆèƒ½ç”¨äºå„ç§å°ºåº¦å’Œå¤æ‚åº¦çš„ç¯å¢ƒï¼‰ã€‚</p>
<h3 id="åŠ¨æ€åœºæ™¯å»ºæ¨¡"><a href="#åŠ¨æ€åœºæ™¯å»ºæ¨¡" class="headerlink" title="åŠ¨æ€åœºæ™¯å»ºæ¨¡"></a>åŠ¨æ€åœºæ™¯å»ºæ¨¡</h3><p>åŠ¨æ€åœºæ™¯å»ºæ¨¡éœ€è¦æ•æ‰å’Œè¡¨è¾¾åœºæ™¯éšæ—¶é—´å˜åŒ–çš„çš„3Dç»“æ„å’Œå¤–è§‚ã€‚éœ€è¦å»ºç«‹èƒ½ç²¾ç¡®åæ˜ åœºæ™¯ä¸­ç‰©ä½“å‡ ä½•ã€è¿åŠ¨å’Œè§†è§‰æ–¹é¢çš„æ•°å­—æ¨¡å‹ã€‚4Dé«˜æ–¯æ³¼æº…é€šè¿‡æ‰©å±•3Dé«˜æ–¯æº…å°„çš„æ¦‚å¿µï¼Œå¼•å…¥æ—¶é—´ç»´åº¦ï¼Œä½¿å¾—å¯ä»¥è¡¨è¾¾å’Œæ¸²æŸ“åŠ¨æ€åœºæ™¯ã€‚ç°åœ¨ä¹Ÿæœ‰ä¸€äº›æ–¹æ³•åœ¨ç ”ç©¶åœ¨åŠ¨æ€åœºæ™¯ä¸­çš„ä¸€äº›ç¼–è¾‘çš„åŠŸèƒ½ï¼Œä¸3DGSè¿›è¡Œäº¤äº’ã€‚</p>
<h3 id="AIç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰"><a href="#AIç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰" class="headerlink" title="AIç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰"></a>AIç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰</h3><p>AIGCæ˜¯äººå·¥æ™ºèƒ½è‡ªåŠ¨åˆ›å»ºæˆ–æå¤§ä¿®æ”¹çš„æ•°å­—å†…å®¹ï¼Œå¯ä»¥æ¨¡ä»¿ã€æ‰©å±•æˆ–å¢å¼ºäººç±»ç”Ÿæˆçš„å†…å®¹ã€‚</p>
<p>3DGSçš„æ˜¾å¼ç‰¹æ€§ã€å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¯ç¼–è¾‘æ°´å¹³ä½¿å…¶ä¸AIGCé«˜åº¦ç›¸å…³ã€‚ä¾‹å¦‚ï¼Œæœ‰æ–¹æ³•ä½¿ç”¨3DGSä¸ç”Ÿæˆæ¨¡å‹ã€åŒ–èº«æˆ–åœºæ™¯ç¼–è¾‘ç»“åˆï¼Œå¦‚3DGS-Avatarã€‚</p>
<h3 id="è‡ªåŠ¨é©¾é©¶"><a href="#è‡ªåŠ¨é©¾é©¶" class="headerlink" title="è‡ªåŠ¨é©¾é©¶"></a>è‡ªåŠ¨é©¾é©¶</h3><p>è‡ªåŠ¨é©¾é©¶çš„ç›®æ ‡æ˜¯åœ¨æ— äººå¹²æ¶‰çš„æƒ…å†µä¸‹å¯¼èˆªå¹¶æ“ä½œè½¦è¾†ï¼Œå…¶ä¸»è¦ç›®æ ‡æ˜¯å®‰å…¨è€Œé«˜æ•ˆåœ°æ„ŸçŸ¥ç¯å¢ƒã€åšå‡ºå†³ç­–å’Œæ“ä½œæ‰§è¡Œå™¨ã€‚</p>
<p>å…¶ä¸­ï¼Œæ„ŸçŸ¥å’Œç†è§£ç¯å¢ƒéœ€è¦å®æ—¶é‡å»ºé©¾é©¶åœºæ™¯ï¼Œç²¾ç¡®è¯†åˆ«é™æ€å’ŒåŠ¨æ€ç‰©ä½“ï¼Œå¹¶ç†è§£å…¶ç›¸äº’å…³ç³»å’Œè¿åŠ¨ã€‚åŠ¨æ€é©¾é©¶åœºæ™¯ä¸­ï¼Œåœºæ™¯è¿˜ä¼šéšæ—¶é—´è¿ç»­å˜åŒ–ã€‚3DGSå¯ä»¥é€šè¿‡æ··åˆæ•°æ®ç‚¹ï¼ˆå¦‚æ¿€å…‰é›·è¾¾ç‚¹ï¼‰å°†åœºæ™¯é‡å»ºä¸ºè¿è´¯è¡¨è¾¾ï¼Œæœ‰åˆ©äºå¤„ç†æ•°æ®ç‚¹å˜åŒ–çš„å¯†åº¦ï¼Œä»¥åŠé™æ€èƒŒæ™¯å’ŒåŠ¨æ€ç‰©ä½“çš„ç²¾ç¡®é‡å»ºã€‚</p>
<h2 id="æ€§èƒ½æ¯”è¾ƒ-PERFORMANCE-COMPARISON"><a href="#æ€§èƒ½æ¯”è¾ƒ-PERFORMANCE-COMPARISON" class="headerlink" title="æ€§èƒ½æ¯”è¾ƒ PERFORMANCE COMPARISON"></a>æ€§èƒ½æ¯”è¾ƒ PERFORMANCE COMPARISON</h2><p>åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œé’ˆå¯¹3FGSåœ¨ä¸Šè¿°çš„é¢†åŸŸä¸Šçš„ä¸€äº›æ€§èƒ½è¯„ä¼°ã€‚</p>
<h3 id="æ€§èƒ½åŸºå‡†ï¼šå®šä½"><a href="#æ€§èƒ½åŸºå‡†ï¼šå®šä½" class="headerlink" title="æ€§èƒ½åŸºå‡†ï¼šå®šä½"></a>æ€§èƒ½åŸºå‡†ï¼šå®šä½</h3><ul>
<li><p>æ•°æ®é›†ï¼šReplicaã€‚</p>
</li>
<li><p>åŸºå‡†ç®—æ³•ï¼šGaussian-SLAMã€GS-SLAMã€SplaTAMã€GSS-SLAMã€‚</p>
</li>
<li>è¯„ä¼°æŒ‡æ ‡ï¼šå‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰ã€ç»å¯¹è½¨è¿¹è¯¯å·®ï¼ˆATEï¼‰ï¼Œæµ‹é‡ä¼ æ„Ÿå™¨è¿åŠ¨è½¨è¿¹ä¸ŠçœŸå®ä½ç½®ä¸ä¼°è®¡ä½ç½®æ¬§å¼è·ç¦»çš„å‡æ–¹æ ¹ã€‚</li>
<li>ç»“æœï¼šåŸºäº3Dé«˜æ–¯çš„SLAMæ–¹æ³•èƒ½è¶…è¿‡åŸºäºNeRFçš„å¯†é›†è§†è§‰SLAMã€‚</li>
</ul>
<p><img src="https://picx.zhimg.com/80/v2-3277500ac5a850accdd2891db0595ae6.png" alt=""></p>
<h3 id="æ€§èƒ½åŸºå‡†ï¼šé™æ€åœºæ™¯æ¸²æŸ“"><a href="#æ€§èƒ½åŸºå‡†ï¼šé™æ€åœºæ™¯æ¸²æŸ“" class="headerlink" title="æ€§èƒ½åŸºå‡†ï¼šé™æ€åœºæ™¯æ¸²æŸ“"></a>æ€§èƒ½åŸºå‡†ï¼šé™æ€åœºæ™¯æ¸²æŸ“</h3><ul>
<li>æ•°æ®é›†ï¼šReplicaã€‚</li>
<li>åŸºå‡†ç®—æ³•ï¼šGaussian-SLAMã€GS-SLAMã€SplaTAMã€GSS-SLAMã€‚</li>
<li>è¯„ä¼°æŒ‡æ ‡ï¼šå³°å€¼ä¿¡å™ªæ¯”(PSNR)ã€ç»“æ„ç›¸ä¼¼æ€§(SSIM)ã€å­¦ä¹ çš„æ„ŸçŸ¥å›¾åƒpatchç›¸ä¼¼æ€§(LPIPS),è¡¡é‡RGBæ¸²æŸ“æ€§èƒ½ã€‚</li>
<li>ç»“æœï¼šåŸºäº3Dé«˜æ–¯çš„æ–¹æ³•èƒ½è¶…è¿‡åŸºäº<strong>NeRF</strong>çš„æ–¹æ³•ã€‚</li>
</ul>
<p><img src="https://picx.zhimg.com/80/v2-94d0eea6ab0c03f32c82802f00a8102d.png" alt=""></p>
<h3 id="æ€§èƒ½åŸºå‡†ï¼šåŠ¨æ€åœºæ™¯æ¸²æŸ“"><a href="#æ€§èƒ½åŸºå‡†ï¼šåŠ¨æ€åœºæ™¯æ¸²æŸ“" class="headerlink" title="æ€§èƒ½åŸºå‡†ï¼šåŠ¨æ€åœºæ™¯æ¸²æŸ“"></a>æ€§èƒ½åŸºå‡†ï¼šåŠ¨æ€åœºæ™¯æ¸²æŸ“</h3><ul>
<li>æ•°æ®é›†ï¼šD-NeRFã€‚</li>
<li>åŸºå‡†ç®—æ³•ï¼šCoGSã€4D-GSã€GauFReã€4DGSã€‚</li>
<li>è¯„ä¼°æŒ‡æ ‡ï¼šPSNRã€SSIMã€LPIPS, ç”¨äºè¡¡é‡RGBæ¸²æŸ“æ€§èƒ½ã€‚</li>
<li>ç»“æœï¼š3DGSèƒ½å¤§å¹…è¶…è¿‡åŸºäºNeRFçš„SOTAã€‚ä½†é™æ€ç‰ˆæœ¬çš„3DGSå¯¹åŠ¨æ€åœºæ™¯çš„é‡å»ºæ˜¯å¤±è´¥çš„ã€‚</li>
</ul>
<p><img src="https://picx.zhimg.com/80/v2-288ca353912cbbd221a111ee553ab607_720w.png" alt=""></p>
<h3 id="æ€§èƒ½åŸºå‡†ï¼šé©¾é©¶åœºæ™¯æ¸²æŸ“"><a href="#æ€§èƒ½åŸºå‡†ï¼šé©¾é©¶åœºæ™¯æ¸²æŸ“" class="headerlink" title="æ€§èƒ½åŸºå‡†ï¼šé©¾é©¶åœºæ™¯æ¸²æŸ“"></a>æ€§èƒ½åŸºå‡†ï¼šé©¾é©¶åœºæ™¯æ¸²æŸ“</h3><ul>
<li>æ•°æ®é›†ï¼šnuScencesã€‚</li>
<li>åŸºå‡†ç®—æ³•ï¼šDrivingGaussianã€‚</li>
<li>è¯„ä¼°æŒ‡æ ‡ï¼šPSNRã€SSIMã€LPIPS*ï¼ˆLPIPSÃ— 1000ï¼‰, ç”¨äºè¡¡é‡RGBæ¸²æŸ“æ€§èƒ½ã€‚</li>
<li>ç»“æœï¼š3DGSæ–¹æ³•èƒ½å¤§å¹…è¶…è¿‡åŸºäºNeRFçš„æ–¹æ³•ã€‚</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-8b7bb910fbb86e3d1b23fc062260dc5d_720w.png" alt=""></p>
<h3 id="æ€§èƒ½åŸºå‡†ï¼šæ•°å­—è™šæ‹Ÿäºº"><a href="#æ€§èƒ½åŸºå‡†ï¼šæ•°å­—è™šæ‹Ÿäºº" class="headerlink" title="æ€§èƒ½åŸºå‡†ï¼šæ•°å­—è™šæ‹Ÿäºº"></a>æ€§èƒ½åŸºå‡†ï¼šæ•°å­—è™šæ‹Ÿäºº</h3><p>è¯¥ä»»åŠ¡çš„ç›®æ ‡æ˜¯ä»ç»™å®šçš„å¤šè§†è§’è§†é¢‘æ¸²æŸ“äººä½“åŒ–èº«æ¨¡å‹ã€‚</p>
<ul>
<li>æ•°æ®é›†ï¼šZJU-MoCapã€‚</li>
<li>åŸºå‡†ç®—æ³•ï¼šGARTã€Human101ã€HUGSã€3DGS-Avatarã€‚</li>
<li>è¯„ä¼°æŒ‡æ ‡ï¼šPSNRã€SSIMã€LPIPS* (LPIPSÃ—1000) ,ç”¨äºè¡¡é‡RGBæ¸²æŸ“æ€§èƒ½$_{9}$</li>
<li>ç»“æœï¼šåŸºäº3DGSçš„æ–¹æ³•èƒ½åœ¨æ¸²æŸ“è´¨é‡å’Œé€Ÿåº¦ä¸Šå‡æœ‰ä¼˜åŠ¿ã€‚</li>
</ul>
<p><img src="https://pica.zhimg.com/80/v2-d916a05d315e576e3cef738aa2306226.png" alt=""></p>
<h2 id="æœªæ¥ç ”ç©¶æ–¹å‘-FUTURE-RESEARCH-DIRECTIONS"><a href="#æœªæ¥ç ”ç©¶æ–¹å‘-FUTURE-RESEARCH-DIRECTIONS" class="headerlink" title="æœªæ¥ç ”ç©¶æ–¹å‘ FUTURE RESEARCH DIRECTIONS"></a>æœªæ¥ç ”ç©¶æ–¹å‘ FUTURE RESEARCH DIRECTIONS</h2><ul>
<li><strong>æ•°æ®é«˜æ•ˆçš„3DGSè§£å†³æ–¹æ¡ˆ</strong>ï¼šä»å°‘æ ·æœ¬ä¸­è¿›è¡Œæ–°è§†å›¾ç”Ÿæˆå’Œåœºæ™¯é‡å»ºå¾ˆé‡è¦ã€‚ç›®å‰çš„æ–¹æ³•æœ‰æ¢ç©¶å¼•å…¥æ·±åº¦ä¿¡æ¯ã€å¯†é›†æ¦‚ç‡åˆ†å¸ƒã€åƒç´ åˆ°é«˜æ–¯çš„æ˜ å°„æ¥ä¿ƒè¿›è¯¥èƒ½åŠ›ï¼Œå®é™…ä¸Šå°±æ˜¯å¼•å…¥æ›´å¤šçš„ä¿¡æ¯ã€‚ã€‚æ­¤å¤–ï¼Œåœ¨è§‚æµ‹ä¸è¶³çš„åŒºåŸŸï¼Œ3DGSä¼šäº§ç”Ÿä¼ªå½±ï¼Œå¯å°è¯•åœ¨è¿™äº›åŒºåŸŸè¿›è¡Œæ•°æ®æ’å€¼æˆ–ç§¯åˆ†ã€‚</li>
<li><strong>å­˜å‚¨é«˜æ•ˆçš„3DGSè§£å†³æ–¹æ¡ˆ</strong>ï¼š3DGSçš„å¯æ‰©å±•æ€§è¾ƒå·®ï¼Œåœ¨å¤§å°ºåº¦ç¯å¢ƒä¸­éœ€è¦å¤§é‡çš„å­˜å‚¨ã€‚éœ€è¦ä¼˜åŒ–è®­ç»ƒé˜¶æ®µå’Œæ¨¡å‹çš„å­˜å‚¨åˆ©ç”¨ï¼Œè€Œå¯¹äºNeRFæ¥è¯´åªéœ€è¦å­˜å‚¨å­¦ä¹ åˆ°çš„MLPå‚æ•°ã€‚å¯ä»¥æ¢ç´¢æ›´å¤šé«˜æ•ˆçš„æ•°æ®ç»“æ„å’Œå…ˆè¿›çš„å‹ç¼©æŠ€æœ¯ï¼Œå¦‚Light-Gaussianç­‰</li>
<li><strong>å…ˆè¿›çš„æ¸²æŸ“ç®—æ³•</strong>ï¼šç›®å‰3DGSçš„æ¸²æŸ“ç®—æ³•è¾ƒä¸ºç®€å•ç›´æ¥ï¼Œå¯è§æ€§ç®—æ³•ä¼šå¯¼è‡´é«˜æ–¯æ·±åº¦/æ··åˆé¡ºåºçš„å‰§çƒˆåˆ‡æ¢ï¼Œéœ€è¦å®æ–½æ›´å…ˆè¿›çš„æ¸²æŸ“ç®—æ³•ï¼Œæ›´å¥½æ¨¡æ‹Ÿå…‰ä¸ææ–™å±æ€§çš„å¤æ‚ç›¸äº’ä½œç”¨ã€‚å¯ç»“åˆä¼ ç»Ÿè®¡ç®—æœºå›¾å½¢å­¦çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¿˜å¯æ¢ç´¢é€†æ¸²æŸ“ã€‚</li>
<li><strong>ä¼˜åŒ–ä¸æ­£åˆ™åŒ–</strong>ï¼š å„å‘å¼‚æ€§é«˜æ–¯è™½ç„¶æœ‰åˆ©äºè¡¨ç¤ºå¤æ‚å‡ ä½•ä½“ï¼Œä½†å¯èƒ½äº§ç”Ÿä¸å¸Œæœ›çš„è§†è§‰ä¼ªå½±ã€‚ä¾‹å¦‚ï¼Œç‰¹åˆ«æ˜¯åœ¨å…·æœ‰è§†è§’ä¾èµ–å¤–è§‚çš„åŒºåŸŸï¼Œå¤§çš„3Dé«˜æ–¯å¯èƒ½å¯¼è‡´å¼¹å‡ºä¼ªå½±ï¼Œçªç„¶å‡ºç°æˆ–æ¶ˆå¤±çš„è§†è§‰å…ƒç´ æ‰“ç ´äº†æ²‰æµ¸æ„Ÿã€‚ä½¿ç”¨æ­£åˆ™åŒ–å¯ä»¥å¢åŠ æ”¶æ•›é€Ÿåº¦ï¼Œå¹³æ»‘è§†è§‰å™ªå£°æˆ–æé«˜å›¾åƒè´¨é‡ã€‚æ­¤å¤–ï¼Œ3DGSä¸­å¤§é‡çš„è¶…å‚æ•°ä¹Ÿä¼šå½±å“3DGSçš„æ³›åŒ–æ€§ã€‚åœ¨3DGSçš„è§„åˆ™åŒ–å’Œä¼˜åŒ–æ–¹é¢å­˜åœ¨ç›¸å½“å¤§çš„æ¢ç´¢æ½œåŠ›ã€‚</li>
<li><strong>3Dé«˜æ–¯åœ¨ç½‘æ ¼é‡å»ºä¸­çš„åº”ç”¨</strong>ï¼šå¯æ¢ç´¢3DGSåœ¨ç½‘æ ¼é‡å»ºä¸­çš„æ½œåŠ›ï¼Œä»è€Œç¼©å°ä½“ç§¯æ¸²æŸ“å’Œä¼ ç»ŸåŸºäºè¡¨é¢çš„æ–¹æ³•çš„å·®è·ï¼Œä»¥ä¾¿æå‡ºæ–°çš„æ¸²æŸ“æŠ€å·§å’Œåº”ç”¨ã€‚</li>
<li><strong>èµ‹äºˆ3DGSæ›´å¤šå¯èƒ½æ€§</strong>ï¼š å°½ç®¡3DGSå…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œä½†3DGSçš„å…¨èŒƒå›´åº”ç”¨ä»ç„¶æœªè¢«å……åˆ†æŒ–æ˜ã€‚ä¸€ä¸ªæœ‰å‰æ™¯çš„æ¢ç´¢æ–¹å‘æ˜¯ç”¨é¢å¤–çš„å±æ€§å¢å¼º3Dé«˜æ–¯ï¼Œä¾‹å¦‚ä¸ºç‰¹å®šåº”ç”¨å®šåˆ¶çš„è¯­è¨€å’Œç‰©ç†å±æ€§ã€‚æ­¤å¤–ï¼Œæœ€è¿‘çš„ç ”ç©¶å¼€å§‹æ­ç¤º3DGSåœ¨å¤šä¸ªé¢†åŸŸçš„èƒ½åŠ›ï¼Œä¾‹å¦‚ç›¸æœºå§¿æ€ä¼°è®¡ã€æ•æ‰æ‰‹å¯¹è±¡äº’åŠ¨å’Œä¸ç¡®å®šæ€§é‡åŒ–ã€‚è¿™äº›åˆæ­¥å‘ç°çªå‡ºäº†è·¨å­¦ç§‘å­¦è€…è¿›ä¸€æ­¥æ¢ç´¢3DGSçš„é‡è¦æœºä¼šã€‚</li>
</ul>
<h2 id="å‚è€ƒæ–‡çŒ®-REFERENCES"><a href="#å‚è€ƒæ–‡çŒ®-REFERENCES" class="headerlink" title="å‚è€ƒæ–‡çŒ® REFERENCES"></a>å‚è€ƒæ–‡çŒ® REFERENCES</h2><ol>
<li>Kerbl, B., Kopanas, G., LeimkÃ¼hler, T., &amp; Drettakis, G. (2023). <a href="https://arxiv.org/abs/2308.04079">3D Gaussian Splatting for Real-Time Radiance Field Rendering.</a> SIGGRAPH 2023.</li>
<li>Mildenhall, B., Srinivasan, P. P., Tancik, M., Barron, J. T., Ramamoorthi, R., &amp; Ng, R. (2020). <a href="https://arxiv.org/abs/2003.08934">NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis.</a> ECCV 2020.</li>
<li>Zwicker, M., Pfister, H., van Baar, J., &amp; Gross, M. (2001). <a href="https://www.cs.umd.edu/~zwicker/publications/SurfaceSplatting-SIG01.pdf">Surface Splatting.</a> SIGGRAPH 2001</li>
<li>Luiten, J., Kopanas, G., Leibe, B., &amp; Ramanan, D. (2023). <a href="https://arxiv.org/abs/2308.09713">Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis.</a> International Conference on 3D Vision.</li>
<li>Zwicker, M., Pfister, H., van Baar, J., &amp; Gross, M. (2001). <a href="https://www.cs.umd.edu/~zwicker/publications/EWAVolumeSplatting-VIS01.pdf">EWA Volume Splatting.</a> IEEE Visualization 2001.</li>
<li>Yu, A., Fridovich-Keil, S., Tancik, M., Chen, Q., Recht, B., &amp; Kanazawa, A. (2023). <a href="https://arxiv.org/abs/2112.05131">Plenoxels: Radiance Fields without Neural Networks.</a> CVPR 2022.</li>
<li><a href="https://towardsdatascience.com/a-comprehensive-overview-of-gaussian-splatting-e7d570081362">A Comprehensive Overview of Gaussian Splatting</a></li>
<li><a href="https://github.com/huggingface/blog/blob/main/gaussian-splatting.md">Introduction to 3D Gaussian Splatting</a></li>
<li><a href="https://docs.nerf.studio/nerfology/model_components/visualize_samples.html#d-frustum">Sample Representation</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/664725693">ã€Š3D Gaussian Splatting for Real-Time Radiance Field Renderingã€‹3Dé«˜æ–¯çš„ç†è®ºç†è§£</a></li>
<li><a href="https://blog.csdn.net/weixin_45657478/article/details/135603696">ã€è®ºæ–‡ç¬”è®°ã€‘A Survey on 3D Gaussian Splatting</a></li>
</ol>
]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</title>
    <url>/2024/01/20/Project/Linly-Talker%20-%20GPT-SoVITS/</url>
    <content><![CDATA[<h1 id="æ•°å­—äººçš„æœªæ¥ï¼šæ•°å­—äººå¯¹è¯ç³»ç»Ÿ-Linly-Talker-å…‹éš†è¯­éŸ³-GPT-SoVITS"><a href="#æ•°å­—äººçš„æœªæ¥ï¼šæ•°å­—äººå¯¹è¯ç³»ç»Ÿ-Linly-Talker-å…‹éš†è¯­éŸ³-GPT-SoVITS" class="headerlink" title="æ•°å­—äººçš„æœªæ¥ï¼šæ•°å­—äººå¯¹è¯ç³»ç»Ÿ Linly-Talker + å…‹éš†è¯­éŸ³ GPT-SoVITS"></a>æ•°å­—äººçš„æœªæ¥ï¼šæ•°å­—äººå¯¹è¯ç³»ç»Ÿ Linly-Talker + å…‹éš†è¯­éŸ³ GPT-SoVITS</h1><p><a href="https://github.com/Kedreamix/Linly-Talker">https://github.com/Kedreamix/Linly-Talker</a></p>
<p><strong>2023.12 æ›´æ–°</strong> ğŸ“†</p>
<p><strong>ç”¨æˆ·å¯ä»¥ä¸Šä¼ ä»»æ„å›¾ç‰‡è¿›è¡Œå¯¹è¯</strong></p>
<p><strong>2024.01 æ›´æ–°</strong> ğŸ“†</p>
<ul>
<li><strong>ä»¤äººå…´å¥‹çš„æ¶ˆæ¯ï¼æˆ‘ç°åœ¨å·²ç»å°†å¼ºå¤§çš„GeminiProå’ŒQwenå¤§æ¨¡å‹èå…¥åˆ°æˆ‘ä»¬çš„å¯¹è¯åœºæ™¯ä¸­ã€‚ç”¨æˆ·ç°åœ¨å¯ä»¥åœ¨å¯¹è¯ä¸­ä¸Šä¼ ä»»ä½•å›¾ç‰‡ï¼Œä¸ºæˆ‘ä»¬çš„äº’åŠ¨å¢æ·»äº†å…¨æ–°çš„å±‚é¢ã€‚</strong></li>
<li><strong>æ›´æ–°äº†FastAPIçš„éƒ¨ç½²è°ƒç”¨æ–¹æ³•ã€‚</strong> </li>
<li><strong>æ›´æ–°äº†å¾®è½¯TTSçš„é«˜çº§è®¾ç½®é€‰é¡¹ï¼Œå¢åŠ å£°éŸ³ç§ç±»çš„å¤šæ ·æ€§ï¼Œä»¥åŠåŠ å…¥è§†é¢‘å­—å¹•åŠ å¼ºå¯è§†åŒ–ã€‚</strong><ul>
<li><strong>æ›´æ–°äº†GPTå¤šè½®å¯¹è¯ç³»ç»Ÿï¼Œä½¿å¾—å¯¹è¯æœ‰ä¸Šä¸‹æ–‡è”ç³»ï¼Œæé«˜æ•°å­—äººçš„äº¤äº’æ€§å’ŒçœŸå®æ„Ÿã€‚</strong></li>
</ul>
</li>
</ul>
<p><strong>2024.02 æ›´æ–°</strong> ğŸ“†</p>
<ul>
<li><strong>æ›´æ–°äº†Gradioçš„ç‰ˆæœ¬ä¸ºæœ€æ–°ç‰ˆæœ¬4.16.0ï¼Œä½¿å¾—ç•Œé¢æ‹¥æœ‰æ›´å¤šçš„åŠŸèƒ½ï¼Œæ¯”å¦‚å¯ä»¥æ‘„åƒå¤´æ‹æ‘„å›¾ç‰‡æ„å»ºæ•°å­—äººç­‰ã€‚</strong></li>
<li><strong>æ›´æ–°äº†ASRå’ŒTHGï¼Œå…¶ä¸­ASRåŠ å…¥äº†é˜¿é‡Œçš„FunASRï¼Œå…·ä½“æ›´å¿«çš„é€Ÿåº¦ï¼›THGéƒ¨åˆ†åŠ å…¥äº†Wav2Lipæ¨¡å‹ï¼ŒER-NeRFåœ¨å‡†å¤‡ä¸­(Comming Soon)ã€‚</strong></li>
<li><strong>åŠ å…¥äº†è¯­éŸ³å…‹éš†æ–¹æ³•GPT-SoVITSæ¨¡å‹ï¼Œèƒ½å¤Ÿé€šè¿‡å¾®è°ƒä¸€åˆ†é’Ÿå¯¹åº”äººçš„è¯­æ–™è¿›è¡Œå…‹éš†ï¼Œæ•ˆæœè¿˜æ˜¯ç›¸å½“ä¸é”™çš„ï¼Œå€¼å¾—æ¨èã€‚</strong></li>
<li><strong>é›†æˆä¸€ä¸ªWebUIç•Œé¢ï¼Œèƒ½å¤Ÿæ›´å¥½çš„è¿è¡ŒLinly-Talkerã€‚</strong></li>
</ul>
<p>åœ¨æœ€è¿‘ä¸€æ®µæ—¶é—´ï¼Œæˆ‘åœ¨å°è¯•æ¢ç´¢ï¼Œå¦‚ä½•å…‹éš†å£°éŸ³ï¼Œå› ä¸ºåœ¨æ•°å­—äººå¯¹è¯ç³»ç»Ÿä¸­ï¼Œè™½ç„¶å¯èƒ½èƒ½å¤Ÿé‡å»ºç‰¹å®šçš„äººï¼Œä½†æ˜¯è¿˜æ˜¯å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼šå£°éŸ³æ˜¯ç”¨å›ºå®šçš„äººå£°ç”Ÿæˆçš„ï¼Œå¯¼è‡´æ²¡æœ‰çœŸå®æ€§ï¼Œå¦‚æœæˆ‘ä»¬èƒ½å¤Ÿå»å…‹éš†å‡ºå¯¹åº”çš„å£°éŸ³ï¼Œå¹¶ä¸”ç»“åˆç‰¹å®šçš„æ•°å­—äººï¼Œé‚£æ˜¯å¦å°±å®Œæˆäº†ä¸€ä¸ªæ•°å­—äººçš„å®Œæ•´å¤åˆ»ã€‚</p>
<p>äºæ˜¯æˆ‘å°±ç ”ç©¶äº†ä¸€æ®µæ—¶é—´ï¼Œåé¢å‘ç°äº†ä¸¤ä¸ªéå¸¸æœ‰æ„æ€çš„é¡¹ç›®ï¼Œåˆ†åˆ«æ˜¯<code>GPT-SoVITS</code>å’Œ<code>XTTS</code>ä¸¤ä¸ªå¼€æºé¡¹ç›®ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸¤ä¸ªç®—æ˜¯ç°åœ¨æœ€å¥½çš„ä¸¤ä¸ªå¼€æºé¡¹ç›®äº†ï¼ŒåƒOpenVoiceä¹‹ç±»çš„æ•ˆæœè¿˜æ˜¯æ¯”è¾ƒå·®ï¼Œç«å±±æ•ˆæœä¸é”™ï¼Œä½†æ˜¯æ²¡æœ‰å¼€æºã€‚</p>
<p>é™¤æ­¤ä¹‹å¤–ï¼Œæˆ‘åç»­é›†æˆåˆ°äº†Linly-Talkerä¹‹ä¸­ï¼Œåšäº†ä¸€ä¸ªWebUIï¼Œèƒ½å¤Ÿé€šè¿‡æˆ‘3~10sçš„è¯­éŸ³å¤§æ¦‚å…‹éš†æˆ‘çš„å£°éŸ³ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥ä½¿ç”¨ä¸€åˆ†é’Ÿå…‹éš†è®­ç»ƒçš„è¯­éŸ³æ¥æ“ä½œï¼Œå¦‚æœä½¿ç”¨å¤šä¸€ç‚¹çš„é¢„æ–™èƒ½å¤Ÿå¾—åˆ°æ›´å¥½çš„æ•ˆæœï¼Œå¸Œæœ›å’Œå¤§å®¶ä¸€èµ·åŠªåŠ›ï¼ŒæˆåŠŸå¤åˆ»å‡ºä¸€ä¸ªå®Œæ•´çš„æ•°å­—äºº</p>
<p>å…·ä½“ä¹Ÿå¯ä»¥å…³æ³¨æˆ‘Bç«™çš„æ¼”ç¤ºçš„è§†é¢‘<a href="https://www.bilibili.com/video/BV1S4421A7gh">ğŸš€æ•°å­—äººçš„æœªæ¥ï¼šLinly-Talker+GPT-SoVITè¯­éŸ³å…‹éš†æŠ€æœ¯çš„èµ‹èƒ½ä¹‹é“</a>å’Œ<a href="https://www.bilibili.com/video/BV1nu4m1K7qG">Linly-Talker WebUIğŸš€: åœ¨å¯¹è¯æ—¶æ‚„æ‚„å·èµ°ä½ çš„å£°éŸ³ğŸ¤</a></p>
<h2 id="GPT-SoVITSï¼ˆæ¨èï¼‰"><a href="#GPT-SoVITSï¼ˆæ¨èï¼‰" class="headerlink" title="GPT-SoVITSï¼ˆæ¨èï¼‰"></a>GPT-SoVITSï¼ˆæ¨èï¼‰</h2><p>æ„Ÿè°¢å¤§å®¶çš„å¼€æºè´¡çŒ®ï¼Œæˆ‘å€Ÿé‰´äº†å½“å‰å¼€æºçš„è¯­éŸ³å…‹éš†æ¨¡å‹ <code>GPT-SoVITS</code>ï¼Œæˆ‘è®¤ä¸ºæ•ˆæœæ˜¯ç›¸å½“ä¸é”™çš„ï¼Œé¡¹ç›®åœ°å€å¯å‚è€ƒ<a href="https://github.com/RVC-Boss/GPT-SoVITS">https://github.com/RVC-Boss/GPT-SoVITS</a></p>
<p>ä»–æœ‰ä»¥ä¸‹åŠŸèƒ½ï¼š</p>
<ol>
<li><strong>é›¶æ ·æœ¬æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰ï¼š</strong> è¾“å…¥ 5 ç§’çš„å£°éŸ³æ ·æœ¬ï¼Œå³åˆ»ä½“éªŒæ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢ã€‚</li>
<li><strong>å°‘æ ·æœ¬ TTSï¼š</strong> ä»…éœ€ 1 åˆ†é’Ÿçš„è®­ç»ƒæ•°æ®å³å¯å¾®è°ƒæ¨¡å‹ï¼Œæå‡å£°éŸ³ç›¸ä¼¼åº¦å’ŒçœŸå®æ„Ÿã€‚</li>
<li><strong>è·¨è¯­è¨€æ”¯æŒï¼š</strong> æ”¯æŒä¸è®­ç»ƒæ•°æ®é›†ä¸åŒè¯­è¨€çš„æ¨ç†ï¼Œç›®å‰æ”¯æŒè‹±è¯­ã€æ—¥è¯­å’Œä¸­æ–‡ã€‚</li>
<li><strong>WebUI å·¥å…·ï¼š</strong> é›†æˆå·¥å…·åŒ…æ‹¬å£°éŸ³ä¼´å¥åˆ†ç¦»ã€è‡ªåŠ¨è®­ç»ƒé›†åˆ†å‰²ã€ä¸­æ–‡è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)å’Œæ–‡æœ¬æ ‡æ³¨ï¼ŒååŠ©åˆå­¦è€…åˆ›å»ºè®­ç»ƒæ•°æ®é›†å’Œ GPT/SoVITS æ¨¡å‹ã€‚</li>
</ol>
<p>ä¹‹å‰å¾ˆå¤šæ–¹æ³•éƒ½æ˜¯å°‘æ ·æœ¬ï¼Œæ¯”å¦‚<code>OpenVoice</code>å’Œ<code>XTTS</code>ï¼Œæˆ‘ä¹‹å‰ä¹Ÿæƒ³ç€ä½¿ç”¨ä»–ä»¬æ¥è¿›è¡Œå®ç°è¯­éŸ³å…‹éš†éƒ¨åˆ†ï¼Œä½†æ˜¯å¾ˆé—æ†¾çš„æ˜¯ï¼Œå¹¶æ²¡æœ‰æ„Ÿè§‰æœ‰å¾ˆå¥½çš„æ•ˆæœï¼Œå…¶å®<code>XTTS</code>è¿˜æ˜¯ä¸é”™çš„ï¼Œå¦‚æœæˆ‘ä»¬ç®€å•ç”¨éº¦å…‹é£ğŸ¤è¯´å‡ å¥è¯ä½œä¸ºå‚è€ƒæ¥è¿›è¡Œå…‹éš†ï¼Œæˆ‘è§‰å¾—æ•ˆæœè¿˜æ˜¯å¯ä»¥çš„ã€‚</p>
<p>ä½†æ˜¯å¦‚æœé‡åˆ°æ¯”è¾ƒé«˜çš„è¦æ±‚ï¼Œæˆ‘è§‰å¾—å¯èƒ½å°±éœ€è¦æ›´å¥½çš„æ¨¡å‹ï¼Œå¹¶ä¸”æˆæœ¬ä¹Ÿè¦æ‰“å‹ä¸‹æ¥ï¼Œæ‰€ä»¥æˆ‘å°±çœ‹åˆ°äº†è¿™ä¸ª<code>GPT-SoVITS</code>ï¼Œæˆ‘è§‰å¾—è¿™ä¸ªæ¨¡å‹æ˜¯ç›¸å½“å‰å®³çš„ï¼Œå°‘æ ·æœ¬çš„TTSèƒ½åšï¼Œä¹Ÿèƒ½åšè·¨è¯­è¨€æ”¯æŒï¼Œè¿™æ ·æˆ‘ä»¬å¾ˆæœ‰å¯èƒ½å°±å¯ä»¥ä½“éªŒåˆ°å¥¥å·´é©¬è®²ä¸­æ–‡ä¹‹ç±»çš„ï¼Œè¿™æ ·å°±å¯ä»¥å®Œæˆè§†é¢‘ç¿»è¯‘çš„ä¸€äº›ä»»åŠ¡äº†ï¼Œæ‰€ä»¥æˆ‘æ˜¯å¾ˆæ¨å´‡è¿™æ ·çš„ç®€å•å¾®è°ƒï¼Œæ•ˆæœåˆå¥½çš„æ–¹æ³•çš„ã€‚</p>
<p><strong>ä¸ºäº†å°Šé‡ä½œè€…ï¼Œåœ¨Linly-Talkerå¹¶æ²¡æœ‰æŠŠ<code>GPT-SoVITS</code>çš„å…¨å¥—ä»£ç æ¬è¿‡æ¥ï¼Œæˆ‘å†™äº†ä¸€ä¸ªå…³äºè¯­éŸ³å…‹éš†çš„ç±»ï¼Œå¤§å®¶å¯ä»¥å°†è®­ç»ƒå¥½çš„æ¨¡å‹å‚æ•°ä¸­ï¼Œå°±å¯ä»¥åœ¨æœ¬é¡¹ç›®ä½¿ç”¨ç»è¿‡è¯­éŸ³å…‹éš†åçš„TTSäº†ï¼Œå¸Œæœ›å¤§å®¶ç©çš„å¼€å¿ƒï¼Œç©çš„æ„‰å¿«ã€‚</strong></p>
<blockquote>
<p>å¦‚æœä½¿ç”¨è¯­éŸ³å…‹éš†æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦pythonä¸º3.10ï¼Œpytorchä¸º2.1å·¦å³å¯èƒ½æ¯”è¾ƒå¥½ï¼Œæˆ‘çš„ç¯å¢ƒå·²ç»æµ‹è¯•è¿‡äº†ï¼Œç®€å•æ¥è¯´ï¼Œå…ˆå®‰è£…GPT-SoVITSçš„ç¯å¢ƒï¼Œå†ç›´æ¥pip intsall -r requirements_app.txtå³å¯ä½¿ç”¨</p>
<p>é™¤æ­¤ä¹‹å¤–ï¼Œè¿˜éœ€è¦æ ¹æ®åŸä½œè€…çš„è¯´æ˜æ”¾å…¥å¯¹åº”è·¯å¾„ï¼Œæˆ‘çš„é¢„è®­ç»ƒæ¨¡å‹å’Œå­˜æ”¾ä½ç½®å·²ç»™å‡ºï¼Œå¯å‚è€ƒ<a href="https://huggingface.co/Kedreamix/Linly-Talker">https://huggingface.co/Kedreamix/Linly-Talker</a></p>
</blockquote>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line">pip install torch==<span class="number">2.1</span><span class="number">.0</span> torchvision==<span class="number">0.16</span><span class="number">.0</span> torchaudio==<span class="number">2.1</span><span class="number">.0</span> --index-url https://download.pytorch.org/whl/cu118</span><br><span class="line"><span class="comment"># å®‰è£…å¯¹åº”çš„ä¾èµ–</span></span><br><span class="line">pip install -r VITS/requirements_gptsovits.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯åŠ¨å¦‚ä¸‹çš„WebUIç•Œé¢</span></span><br><span class="line">python VITS/app.py </span><br></pre></td></tr></tbody></table></figure>
<p><img src="C:/Users/Kedreamix/Documents/GitHub/Linly-Talker/docs/GPT-SoVITS.png" alt=""></p>
<h2 id="Coqui-XTTS"><a href="#Coqui-XTTS" class="headerlink" title="Coqui XTTS"></a>Coqui XTTS</h2><p>Coqui XTTSæ˜¯ä¸€ä¸ªé¢†å…ˆçš„æ·±åº¦å­¦ä¹ æ–‡æœ¬åˆ°è¯­éŸ³ä»»åŠ¡ï¼ˆTTSè¯­éŸ³ç”Ÿæˆæ¨¡å‹ï¼‰å·¥å…·åŒ…ï¼Œé€šè¿‡ä½¿ç”¨ä¸€æ®µ5ç§’é’Ÿä»¥ä¸Šçš„è¯­éŸ³é¢‘å‰ªè¾‘å°±å¯ä»¥å®Œæˆå£°éŸ³å…‹éš†<em>å°†è¯­éŸ³å…‹éš†åˆ°ä¸åŒçš„è¯­è¨€</em>ã€‚æ”¯æŒå¤šç§è¯­è¨€æ–‡æœ¬åˆ°è¯­éŸ³è½¬æ¢ï¼Œä½¿å…¶æˆä¸ºå›½é™…åŒ–åº”ç”¨çš„ç†æƒ³é€‰æ‹©ï¼Œè¿™ä¸€ç‰¹ç‚¹ç‰¹åˆ«é€‚ç”¨äºå…¨çƒåŒ–çš„å¸‚åœºï¼Œå…¶ä¸­éœ€è¦ç”Ÿæˆå¤šç§è¯­è¨€çš„è¯­éŸ³å†…å®¹ã€‚æ‰€ä»¥åœ¨å®éªŒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä¹ŸåŠ å…¥äº†è¿™ä¸€éƒ¨åˆ†ï¼Œä¸è¿‡æš‚æ—¶ä½¿ç”¨çš„æ˜¯é»˜è®¤çš„æ¨¡å‹ï¼Œå¹¶æ²¡æœ‰è¿›è¡Œå¾®è°ƒï¼Œä¸ªäººè®¤ä¸ºæ˜¯æ²¡æœ‰GPT-SoVITSç»è¿‡å¾®è°ƒåå¥½çš„ï¼Œä½†æ˜¯å…¶ä¸­çš„å°‘æ ·æœ¬äº”ç§’é’Ÿå…‹éš†è¯­éŸ³è¿˜æ˜¯å€¼å¾—ç§°èµçš„ã€‚å¤§å®¶ä¹Ÿå¯ä»¥åœ¨å®˜æ–¹çš„åœ¨çº¿ä½“éªŒï¼Œä½†æ˜¯å®˜æ–¹çš„å¯èƒ½ä¼šæœ‰ç”Ÿæˆè¯­éŸ³é™åˆ¶ï¼Œæ–‡å­—ä¸èƒ½å¤ªé•¿ï¼Œä½†æ˜¯è¿˜æ˜¯è¶³å¤Ÿæˆ‘ä»¬ä½“éªŒäº†ã€‚</p>
<p>ğŸ¸TTS æ˜¯ä¸€ä¸ªç”¨äºé«˜çº§æ–‡æœ¬è½¬è¯­éŸ³ç”Ÿæˆçš„åº“ã€‚</p>
<p>ğŸš€ è¶…è¿‡ 1100 ç§è¯­è¨€çš„é¢„è®­ç»ƒæ¨¡å‹ã€‚</p>
<p>ğŸ› ï¸ ç”¨äºä»¥ä»»ä½•è¯­è¨€è®­ç»ƒæ–°æ¨¡å‹å’Œå¾®è°ƒç°æœ‰æ¨¡å‹çš„å·¥å…·ã€‚</p>
<p>ğŸ“š ç”¨äºæ•°æ®é›†åˆ†æå’Œç®¡ç†çš„å®ç”¨ç¨‹åºã€‚</p>
<ul>
<li>åœ¨çº¿ä½“éªŒXTTS <a href="https://huggingface.co/spaces/coqui/xtts">https://huggingface.co/spaces/coqui/xtts</a></li>
<li>å®˜æ–¹Githubåº“ <a href="https://github.com/coqui-ai/TTS">https://github.com/coqui-ai/TTS</a></li>
</ul>
<p>XTTSçš„ç¯å¢ƒä¹Ÿéœ€è¦PyTorch 2.1æ‰€ä»¥ï¼Œå¦‚æœä¸‹è½½äº†GPT-SoVITSï¼Œä¹Ÿä¸å¦¨ä½“éªŒä¸€ä¸‹XTTSçš„æ•ˆæœã€‚</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu118</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®‰è£…å¯¹åº”çš„ä¾èµ–</span></span><br><span class="line">pip install -r VITS/requirements_xtts.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¯åŠ¨å¦‚ä¸‹çš„WebUIç•Œé¢</span></span><br><span class="line">python VITS/XTTS.py</span><br></pre></td></tr></tbody></table></figure>
<p><img src="C:/Users/Kedreamix/Documents/GitHub/Linly-Talker/docs/XTTS.png" alt=""></p>
<h2 id="Linly-Talker-WebUI"><a href="#Linly-Talker-WebUI" class="headerlink" title="Linly-Talker WebUI"></a>Linly-Talker WebUI</h2><p>ä¹‹å‰æˆ‘å°†å¾ˆå¤šä¸ªç‰ˆæœ¬éƒ½æ˜¯åˆ†å¼€æ¥çš„ï¼Œå®é™…ä¸Šè¿è¡Œå¤šä¸ªä¼šæ¯”è¾ƒéº»çƒ¦ï¼Œæ‰€ä»¥åç»­æˆ‘å¢åŠ äº†å˜æˆWebUIä¸€ä¸ªç•Œé¢å³å¯ä½“éªŒï¼Œåç»­ä¹Ÿä¼šä¸æ–­æ›´æ–°</p>
<p>ç°åœ¨å·²åŠ å…¥WebUIçš„åŠŸèƒ½å¦‚ä¸‹</p>
<ul>
<li>[x] æ–‡æœ¬/è¯­éŸ³æ•°å­—äººå¯¹è¯ï¼ˆå›ºå®šæ•°å­—äººï¼Œåˆ†ç”·å¥³è§’è‰²ï¼‰</li>
<li>[x] ä»»æ„å›¾ç‰‡æ•°å­—äººå¯¹è¯ï¼ˆå¯ä¸Šä¼ ä»»æ„æ•°å­—äººï¼‰</li>
<li>[x] å¤šè½®GPTå¯¹è¯ï¼ˆåŠ å…¥å†å²å¯¹è¯æ•°æ®ï¼Œé“¾æ¥ä¸Šä¸‹æ–‡ï¼‰</li>
<li>[x] è¯­éŸ³å…‹éš†å¯¹è¯ï¼ˆåŸºäºGPT-SoVITSè®¾ç½®è¿›è¡Œè¯­éŸ³å…‹éš†ï¼Œå†…ç½®çƒŸå—“éŸ³ï¼Œå¯æ ¹æ®è¯­éŸ³å¯¹è¯çš„å£°éŸ³è¿›è¡Œå…‹éš†ï¼‰</li>
</ul>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># WebUI</span></span><br><span class="line">python webui.py</span><br></pre></td></tr></tbody></table></figure>
<p><img src="C:/Users/Kedreamix/Documents/GitHub/Linly-Talker/docs/WebUI.png" alt=""></p>
]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>ChatPaperFree GeminiProï¼ˆä¸€åˆ†é’Ÿè¯»è®ºæ–‡ï¼‰</title>
    <url>/2023/12/17/Project/ChatPaperFree/</url>
    <content><![CDATA[<p>å®é™…ä¸Šï¼Œè¿™ä¸ªé¡¹ç›®æ˜¯åœ¨ChatPaperçš„åŸºç¡€ä¸Šè¿›è¡Œçš„æ›´æ–°ï¼Œé‡‡ç”¨äº†æœ€è¿‘ç”±Googleå¼€æºçš„Gemini Proå¤§æ¨¡å‹ã€‚è¿™æ ·ä¸€æ¥ï¼Œæˆ‘ä»¬å¯ä»¥å…è´¹ä½¿ç”¨ChatPaperï¼Œå¹¶ä¸”æœªæ¥æˆ‘è¿˜è®¡åˆ’åŠ å…¥å¯¹è®ºæ–‡å›¾ç‰‡çš„è¯»å–ä»¥æå–æ‘˜è¦ï¼ˆæµ‹è¯•ç»“æœæ˜¯OKçš„ï¼‰ï¼Œå¤§å®¶å¯ä»¥å…³æ³¨ä¸€ä¸‹ï¼Œ<a href="https://github.com/Kedreamix/ChatPaperFree">https://github.com/Kedreamix/ChatPaperFree</a>ã€‚</p>
<p>ç›®å‰,æˆ‘ä»¬èƒ½å¤Ÿå¯¹ç”¨æˆ·è¾“å…¥çš„è®ºæ–‡è¿›è¡Œè‡ªåŠ¨æ€»ç»“ã€‚æœªæ¥,æˆ‘è¿˜è®¡åˆ’åŠ å…¥å¯¹è®ºæ–‡å›¾ç‰‡/è¡¨æ ¼/å…¬å¼çš„è¯†åˆ« extraction,ä»è€Œç”Ÿæˆæ›´å…¨é¢è€Œæ˜“è¯»çš„æ€»ç»“ã€‚å¦‚æœåœ¨å¯¹è¯ä¸­chatbotèƒ½æä¾›æ›´ä¼˜è´¨çš„æœåŠ¡,æˆ‘è¿˜ä¼šå°è¯•è¿›è¡Œæ›´æ·±å±‚æ¬¡çš„æ¨¡å‹fine-tuningã€‚æˆ‘ä¼šåœ¨åç»­å°è¯•è¿›è¡Œæ›´æ–°ï¼Œå¤§å®¶ä¹Ÿå¯ä»¥æå‡ºè‡ªå·±çš„æ„è§ï¼Œä¹Ÿæ¬¢è¿æPRã€‚è¿™æ˜¯ChatPaperçš„<a href="https://github.com/kaixindelele/ChatPaper.git">GitHubé“¾æ¥</a>ï¼Œå¤šå¤šå…³æ³¨ã€‚</p>
<p>å¦å¤–,ä¸ºäº†è·Ÿä¸Šå¿«é€Ÿå‘å±•çš„äººå·¥æ™ºèƒ½é¢†åŸŸå’Œåºå¤§çš„arxivè®ºæ–‡,æˆ‘ä»¬ä»arXivçˆ¬å–äº†å¤§é‡è®ºæ–‡,å¹¶åˆ¶ä½œäº†ç½‘ç«™<a href="https://ipaper.today/">è¿›æ­¥å±‹</a>ä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿä¾¿æ·è·å–å½“å‰çƒ­ç‚¹ã€‚é€šè¿‡Gemini Proå¯¹è®ºæ–‡è¿›è¡Œè‡ªåŠ¨å½’çº³,æˆ‘ä»¬å¯ä»¥ç”¨æå°‘çš„æ–‡æœ¬æ¥å±•ç¤ºè®ºæ–‡è¦ç‚¹,å¸®åŠ©ç”¨æˆ·å¿«é€Ÿè¯„ä¼°å“ªç¯‡å€¼å¾—æ·±å…¥ç ”è¯»ã€‚</p>
<p>åœ¨è¿™ä¸ªä¸æ–­å˜åŒ–çš„æ—¶ä»£,ChatPaperFree GeminiProé€šè¿‡åˆ©ç”¨å¼ºå¤§æŠ€æœ¯,æœ‰æ•ˆæå‡æˆ‘ä»¬å­¦ä¹ æ•ˆç‡ã€‚åŒæ—¶,æˆ‘ä»¬ä¹Ÿæ¬¢è¿ä½ æä¾›å…³é”®è¯,å…±åŒå®Œå–„è¿™ä¸ªå¹³å°,è®©æ¯ä¸ªäººéƒ½èƒ½åœ¨æŠ€æœ¯æ¼”è¿›ä¸­å–å¾—æ–°çš„è¿›æ­¥ã€‚ï¼ˆå¯åœ¨<a href="https://github.com/wmpscc/ipaper.today">https://github.com/wmpscc/ipaper.today</a> æå‡ºå…³é”®è¯ï¼Œæ¬¢è¿ï¼‰</p>
<p>å¸Œæœ›æœªæ¥,æˆ‘ä»¬å¯ä»¥æ­å»ºæ›´å‹å¥½çš„äººæœºåˆä½œæ¨¡å¼ã€‚</p>
<p>æˆ‘å·²ç»éƒ¨ç½²åˆ°äº†HuggingFaceä¸Šäº†ï¼Œå¤§å®¶éƒ½å¯ä»¥å°è¯•ç”¨ä¸€ä¸‹ï¼Œçœ‹çœ‹æ€ä¹ˆæ · <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">https://huggingface.co/spaces/Kedreamix/ChatPaperFree</a></p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install -r requriements.txt</span><br><span class="line">python app.py</span><br></pre></td></tr></tbody></table></figure>
<p>æˆåŠŸåï¼Œè¿›å…¥<a href="http://127.0.0.1:7860">http://127.0.0.1:7860</a> å³å¯ï¼Œæ¥ç€å°±å¯ä»¥è¾“å…¥è‡ªå·±çš„API keyã€‚</p>
<p>Googleçš„Gemini Proçš„API keyæ˜¯å…è´¹çš„ï¼Œæ‰€ä»¥å¤§å®¶éƒ½æ˜¯å¯ä»¥ç”³è¯·çš„ï¼Œå…·ä½“ç”³è¯·å¯ä»¥åœ¨<a href="https://makersuite.google.com/">https://makersuite.google.com/</a>è¿›è¡Œè·å–ï¼Œæ¯ä¸ªäººéƒ½å¯ä»¥è·å–å¤šä¸ªï¼Œå¦‚æœå¤§å®¶æœ‰è‡ªå·±çš„ä¸€äº›æƒ³æ³•ï¼Œä¹Ÿå¯ä»¥çœ‹è°·æ­Œçš„APIä½¿ç”¨æ–‡æ¡£<a href="https://ai.google.dev/tutorials/python_quickstart">https://ai.google.dev/tutorials/python_quickstart</a>ã€‚</p>
<p><img src="https://picx.zhimg.com/80/v2-b1d0493ba08909ecfee8664cda4ff36d_720w.png?source=d16d100b" alt="è·å–API Key"></p>
<h2 id="è·å–æœ€æ–°æ–‡ç« ï¼ˆè¿›æ­¥å±‹ï¼‰"><a href="#è·å–æœ€æ–°æ–‡ç« ï¼ˆè¿›æ­¥å±‹ï¼‰" class="headerlink" title="è·å–æœ€æ–°æ–‡ç« ï¼ˆè¿›æ­¥å±‹ï¼‰"></a>è·å–æœ€æ–°æ–‡ç« ï¼ˆè¿›æ­¥å±‹ï¼‰</h2><p>å®é™…ä¸Šï¼Œè¿™ä¸ªæ“ä½œä¸ChatPaperçš„çˆ¬å–è®ºæ–‡ç±»ä¼¼ï¼Œæˆ‘ä»¬é€šè¿‡çˆ¬å–æœ€æ–°arxivè®ºæ–‡ï¼Œæ ¹æ®è®¾å®šçš„å…³é”®è¯ï¼Œæ¯å¤©å¯¹è®ºæ–‡è¿›è¡Œçˆ¬å–ï¼Œä»¥æœ€å¿«çš„é€Ÿåº¦è·Ÿè¸ªæœ€æ–°çš„æ–‡ç« ã€‚å®éªŒå®¤å·²ç»æ­å»ºäº†ä¸€ä¸ªç½‘ç«™ï¼Œå¤§å®¶å¯ä»¥å¤šå¤šæ”¯æŒï¼Œæå‡ºè‡ªå·±çš„å…³é”®è¯ï¼Œæˆ‘ä»¬ä¼šä¸å®šæ—¶è¿›è¡Œæ›´æ–°ï¼Œè®©ä½ æ¯å¤©éƒ½èƒ½çœ‹åˆ°æœ€æ–°çš„æ–‡ç« ã€‚</p>
<p>è¿™æ˜¯è¿›æ­¥å±‹çš„ç½‘ç«™ï¼š<a href="https://ipaper.today/">è¿›æ­¥å±‹</a> <a href="https://ipaper.today/">https://ipaper.today/</a> ï¼Œå¤§å®¶å¦‚æœæœ‰ä»€ä¹ˆéœ€è¦å­¦ä¹ çš„å†…å®¹ï¼Œå¯ä»¥ç»™å‡ºå…³é”®è¯ï¼Œåœ¨<a href="https://github.com/wmpscc/ipaper.today">GitHub</a>æissueã€‚</p>
<p>åç»­ï¼Œæˆ‘è¿˜è®¡åˆ’åŠ å…¥è‡ªåŠ¨ç”Ÿæˆæ‘˜è¦å’Œåˆ†æçš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬å°è¯•è®©æ•°å­—äººæ’­æŠ¥ç­‰ç­‰ï¼Œæ•¬è¯·æœŸå¾…ã€‚</p>
<p><img src="https://pic1.zhimg.com/80/v2-e127b4c88f3c1dae17604827851af750_720w.png?source=d16d100b" alt="ipaperè¿›æ­¥å±‹"></p>
<p>æœ€è¿‘ï¼Œæˆ‘è¿˜ä¼šå°è¯•ç”Ÿæˆæ–‡ç« çš„ç®€å•æ‘˜è¦ï¼Œä¸°å¯Œå†…å®¹ï¼Œè¿™æ˜¯å³å°†ä¸Šçº¿çš„ç”±GPTç”Ÿæˆç®€å•æ‘˜è¦çš„éƒ¨åˆ†ï¼Œåç»­è¿˜å¯ä»¥åŠ å…¥æ›´å¤šåŠŸèƒ½ï¼Œæ¯”å¦‚ChatPaperçš„promptï¼Œæˆ‘çŒœå¯ä»¥å¾—åˆ°æ›´å¥½çš„æ•ˆæœã€‚</p>
<p><img src="https://pica.zhimg.com/80/v2-21ef11d4a14db737b3dd8d364bed0cea_720w.png?source=d16d100b" alt="Gemin Proæ‘˜è¦æ€»ç»“"></p>
<h2 id="ä½¿ç”¨æŠ€å·§ï¼š"><a href="#ä½¿ç”¨æŠ€å·§ï¼š" class="headerlink" title="ä½¿ç”¨æŠ€å·§ï¼š"></a>ä½¿ç”¨æŠ€å·§ï¼š</h2><ul>
<li>æ‰¾åˆ°å¥½çš„æ–‡ç« åï¼Œå¯ä»¥ç²¾è¯»è¿™ç¯‡æ–‡ç« ï¼›</li>
<li>æ¨èå…¶ä»–ä¸¤ä¸ªç²¾è¯»è®ºæ–‡çš„AIè¾…åŠ©ç½‘ç«™ï¼š<a href="https://typeset.io/">Typeset.io</a> å’Œ <a href="https://chatpdf">chatpdf</a>ã€‚</li>
</ul>
<h2 id="Example1-è¿›æ­¥å±‹"><a href="#Example1-è¿›æ­¥å±‹" class="headerlink" title="Example1(è¿›æ­¥å±‹)"></a>Example1(è¿›æ­¥å±‹)</h2><p>æ¯”å¦‚æœ€è¿‘<code>3D Gassian Splatting</code>å¾ˆç«ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿæœ‰å…³æ³¨è¿™ä¸€æ–¹é¢ï¼Œè¿™æ˜¯æˆ‘æœ€è¿‘çˆ¬å–æœ€æ–°çš„å‡ ç¯‡æ–‡ç« </p>
<h3 id="Triplane-Meets-Gaussian-Splatting-Fast-and-Generalizable-Single-View-3D-Reconstruction-with-Transformers"><a href="#Triplane-Meets-Gaussian-Splatting-Fast-and-Generalizable-Single-View-3D-Reconstruction-with-Transformers" class="headerlink" title="Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D   Reconstruction with Transformers"></a>Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D   Reconstruction with Transformers</h3><p><strong>Authors:Zi-Xin Zou, Zhipeng Yu, Yuan-Chen Guo, Yangguang Li, Ding Liang, Yan-Pei Cao, Song-Hai Zhang</strong></p>
<p>Recent advancements in 3D reconstruction from single images have been driven by the evolution of generative models. Prominent among these are methods based on Score Distillation Sampling (SDS) and the adaptation of diffusion models in the 3D domain. Despite their progress, these techniques often face limitations due to slow optimization or rendering processes, leading to extensive training and optimization times. In this paper, we introduce a novel approach for single-view reconstruction that efficiently generates a 3D model from a single image via feed-forward inference. Our method utilizes two transformer-based networks, namely a point decoder and a triplane decoder, to reconstruct 3D objects using a hybrid Triplane-Gaussian intermediate representation. This hybrid representation strikes a balance, achieving a faster rendering speed compared to implicit representations while simultaneously delivering superior rendering quality than explicit representations. The point decoder is designed for generating point clouds from single images, offering an explicit representation which is then utilized by the triplane decoder to query Gaussian features for each point. This design choice addresses the challenges associated with directly regressing explicit 3D Gaussian attributes characterized by their non-structural nature. Subsequently, the 3D Gaussians are decoded by an MLP to enable rapid rendering through splatting. Both decoders are built upon a scalable, transformer-based architecture and have been efficiently trained on large-scale 3D datasets. The evaluations conducted on both synthetic datasets and real-world images demonstrate that our method not only achieves higher quality but also ensures a faster runtime in comparison to previous state-of-the-art techniques. Please see our project page at <a href="https://zouzx.github.io/TriplaneGaussian/">https://zouzx.github.io/TriplaneGaussian/</a>. </p>
<p><a href="http://arxiv.org/abs/2312.09147v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºå˜åˆ†è‡ªç¼–ç å™¨å’Œæ‰©æ•£æ¨¡å‹çš„3Då•è§†å›¾é‡å»ºæ–¹æ³•å–å¾—äº†é•¿è¶³çš„è¿›æ­¥ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨å˜å‹å™¨ç½‘ç»œå’Œç‚¹è§£ç å™¨å®ç°å•å›¾åƒçš„3Då¯¹è±¡é‡å»º</li>
<li>ä½¿ç”¨æ··åˆçš„Triplane-Gaussianä¸­é—´è¡¨ç¤ºå®ç°æ›´å¿«çš„æ¸²æŸ“é€Ÿåº¦å’Œæ›´é«˜çš„æ¸²æŸ“è´¨é‡</li>
<li>é€šè¿‡MLPè§£ç 3Dé«˜æ–¯ä»¥å®ç°å¿«é€Ÿæ¸²æŸ“</li>
<li>åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®å›¾åƒä¸Šè¿›è¡Œäº†æœ‰æ•ˆçš„è¯„ä¼°</li>
<li>ç›¸æ¯”äºå…ˆå‰çš„æŠ€æœ¯ï¼Œæ–¹æ³•è¾¾åˆ°äº†æ›´é«˜çš„è´¨é‡å’Œæ›´å¿«çš„è¿è¡Œæ—¶é—´</li>
<li>æ–¹æ³•çš„è¯¦ç»†ä¿¡æ¯å¯åœ¨<a href="https://zouzx.github.io/TriplaneGaussian/ä¸Šæ‰¾åˆ°ã€‚">https://zouzx.github.io/TriplaneGaussian/ä¸Šæ‰¾åˆ°ã€‚</a></li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/80/v2-2ebb2460e78384f8da85626de1b8120e_720w.jpeg?source=d16d100b" align="middle">
<img src="https://picx.zhimg.com/80/v2-52bff713f56ef38ffc7e6459d32e7b9f_720w.jpeg?source=d16d100b" align="middle">
<img src="https://pica.zhimg.com/80/v2-44f843bddff8a1e4072392b284803fdf_720w.jpeg?source=d16d100b" align="middle">
</details>




<h3 id="3DGS-Avatar-Animatable-Avatars-via-Deformable-3D-Gaussian-Splatting"><a href="#3DGS-Avatar-Animatable-Avatars-via-Deformable-3D-Gaussian-Splatting" class="headerlink" title="3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting"></a>3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting</h3><p><strong>Authors:Zhiyin Qian, Shaofei Wang, Marko Mihajlovic, Andreas Geiger, Siyu Tang</strong></p>
<p>We introduce an approach that creates animatable human avatars from monocular videos using 3D Gaussian Splatting (3DGS). Existing methods based on neural radiance fields (NeRFs) achieve high-quality novel-view/novel-pose image synthesis but often require days of training, and are extremely slow at inference time. Recently, the community has explored fast grid structures for efficient training of clothed avatars. Albeit being extremely fast at training, these methods can barely achieve an interactive rendering frame rate with around 15 FPS. In this paper, we use 3D Gaussian Splatting and learn a non-rigid deformation network to reconstruct animatable clothed human avatars that can be trained within 30 minutes and rendered at real-time frame rates (50+ FPS). Given the explicit nature of our representation, we further introduce as-isometric-as-possible regularizations on both the Gaussian mean vectors and the covariance matrices, enhancing the generalization of our model on highly articulated unseen poses. Experimental results show that our method achieves comparable and even better performance compared to state-of-the-art approaches on animatable avatar creation from a monocular input, while being 400x and 250x faster in training and inference, respectively. </p>
<p><a href="http://arxiv.org/abs/2312.09228v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä½¿ç”¨ä¸‰ç»´é«˜æ–¯ç‚¹é˜µå’Œéåˆšæ€§å˜å½¢ç½‘ç»œåˆ›å»ºå¯åŠ¨äººä½“åŒ–èº«ï¼Œè®­ç»ƒæ—¶é—´çŸ­ï¼Œæ¸²æŸ“é€Ÿåº¦å¿«ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3Dé«˜æ–¯ç‚¹é˜µåˆ›å»ºå¯åŠ¨äººä½“åŒ–èº«ï¼Œè®­ç»ƒæ—¶é—´30åˆ†é’Ÿï¼Œæ¸²æŸ“é€Ÿåº¦50+ FPS</li>
<li>å¼•å…¥æ­£åˆ™åŒ–æé«˜æ¨¡å‹åœ¨é«˜åº¦å¤æ‚çš„å§¿åŠ¿ä¸Šçš„æ³›åŒ–èƒ½åŠ›</li>
<li>å®éªŒç»“æœè¡¨æ˜æ–¹æ³•åœ¨ä»å•çœ¼è¾“å…¥åˆ›å»ºå¯åŠ¨åŒ–èº«æ–¹é¢æ€§èƒ½ä¼˜è¶Š</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè®­ç»ƒé€Ÿåº¦å¿«400å€ï¼Œæ¨ç†é€Ÿåº¦å¿«250å€</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/80/v2-d9069606a39ac20f1b0bf52ae2af1e83_720w.jpeg?source=d16d100b" align="middle">
<img src="https://picx.zhimg.com/80/v2-622f5d5aa71b525c2b25dfceb0d4c49a_720w.jpeg?source=d16d100b" align="middle">
<img src="https://picx.zhimg.com/80/v2-df8a29e21b43e7322f740381b022b6e4_720w.jpeg?source=d16d100b" align="middle">
<img src="https://pic1.zhimg.com/80/v2-c04b8f81d853c5df7e574e6e17d490fc_720w.jpeg?source=d16d100b" align="middle">
</details>


<p>â€‹    </p>
<h2 id="Example2-ChatPaperFree"><a href="#Example2-ChatPaperFree" class="headerlink" title="Example2(ChatPaperFree)"></a>Example2(ChatPaperFree)</h2><p>æ¯”å¦‚è¿™é‡Œä½¿ç”¨ä¸Šè¿°çš„ <code>3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting</code> è¿›è¡Œæµ‹è¯•ï¼Œå¤§å®¶éƒ½å¯ä»¥å°è¯•ä¸€ä¸‹</p>
<p><img src="https://pic1.zhimg.com/80/v2-99a3ce94a6c8df465018c248a22bf2f7_720w.png?source=d16d100b" alt="ChatPaperFree Example"></p>
<ol>
<li><p>è®ºæ–‡æ ‡é¢˜ï¼š3DGS-Avatarï¼šå¯å˜å½¢3Dé«˜æ–¯ç‚¹äº‘ç”Ÿæˆçš„å¯åŠ¨ç”»èº«</p>
</li>
<li><p>ä½œè€…ï¼š</p>
<ul>
<li>Changil Kim</li>
<li>Jinwoo Kim</li>
<li>Tae-Hyun Oh</li>
<li>Joon-Young Lee</li>
<li>In So Kweon</li>
</ul>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢ï¼ˆKAISTï¼‰</p>
</li>
<li><p>å…³é”®è¯ï¼š</p>
<ul>
<li>å¯åŠ¨ç”»èº«</li>
<li>3Dé«˜æ–¯ç‚¹äº‘ç”Ÿæˆ</li>
<li>å¯å˜å½¢ç¥ç»åœº</li>
<li>å•ç›®è§†é¢‘</li>
</ul>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼š<a href="https://arxiv.org/abs/2312.09228">https://arxiv.org/abs/2312.09228</a> Github é“¾æ¥ï¼šNone</p>
</li>
<li><p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>   (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼š</p>
<ul>
<li>é‡å»ºå¯åŠ¨ç”»èº«å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä½†ä»å›¾åƒè¾“å…¥ä¸­é‡å»ºè¡£ç€çš„äººä½“æ¨¡å‹æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚</li>
<li>åŸºäºNeRFçš„ç¥ç»è¾å°„åœºæ–¹æ³•åœ¨å‡ ä½•å’Œå¤–è§‚é‡å»ºæ–¹é¢å–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼Œä½†è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹éå¸¸è€—æ—¶ã€‚</li>
<li><p>æœ€è¿‘æå‡ºçš„3Dé«˜æ–¯ç‚¹äº‘ç”Ÿæˆæ–¹æ³•åœ¨é™æ€åœºæ™¯é‡å»ºä¸­å–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼Œå…·æœ‰å¿«é€Ÿè®­ç»ƒå’Œæ¨ç†çš„ä¼˜ç‚¹ã€‚</p>
<p>(2)ï¼šè¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼š</p>
</li>
<li><p>ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºNeRFæˆ–å…¶å˜ä½“ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§å‹çš„å¤šå±‚æ„ŸçŸ¥æœºæ¥å»ºæ¨¡ç¥ç»è¾å°„åœºï¼Œå¯¼è‡´è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹éå¸¸è€—æ—¶ã€‚</p>
</li>
<li><p>ä¸€äº›æ–¹æ³•å°è¯•ä½¿ç”¨æ›´å¿«çš„è®­ç»ƒå’Œæ¨ç†æ–¹æ³•ï¼Œä½†å®ƒä»¬é€šå¸¸ä¼šç‰ºç‰²æ¸²æŸ“è´¨é‡æˆ–æ— æ³•å¯¹å§¿åŠ¿ç›¸å…³çš„éåˆšæ€§å˜å½¢è¿›è¡Œå»ºæ¨¡ã€‚</p>
<p>(3)ï¼šç ”ç©¶æ–¹æ³•ï¼š</p>
</li>
<li><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº3Dé«˜æ–¯ç‚¹äº‘ç”Ÿæˆçš„å¯åŠ¨ç”»èº«é‡å»ºæ–¹æ³•ã€‚</p>
</li>
<li>è¯¥æ–¹æ³•å°†åˆšæ€§äººä½“å…³èŠ‚ä¸éåˆšæ€§å˜å½¢åœºæœ‰æ•ˆåœ°é›†æˆåˆ°3Dé«˜æ–¯ç‚¹äº‘ç”Ÿæˆæ¡†æ¶ä¸­ã€‚</li>
<li>ä½¿ç”¨äº†ä¸€ä¸ªå°å‹å¤šå±‚æ„ŸçŸ¥æœºæ¥è§£ç é¢œè‰²ï¼Œè¯¥æ„ŸçŸ¥æœºèƒ½å¤Ÿå¯¹å±€éƒ¨éåˆšæ€§å˜å½¢å’ŒåŠ¨æ€å…‰ç…§æ¡ä»¶åšå‡ºå“åº”ã€‚</li>
<li><p>åº”ç”¨äº†â€œå°½å¯èƒ½ç­‰è·â€æ­£åˆ™åŒ–é¡¹ï¼Œä»¥ä¿æŒå‡ ä½•ä¸€è‡´æ€§å’Œé€¼çœŸçš„å˜å½¢ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨æ€å’Œå˜åŒ–çš„å§¿åŠ¿ä¸­ã€‚</p>
<p>(4)ï¼šå®éªŒç»“æœï¼š</p>
</li>
<li><p>åœ¨å•ç›®è§†é¢‘è¾“å…¥çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•åœ¨å¯åŠ¨ç”»èº«åˆ›å»ºæ–¹é¢ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“æˆ–æ›´å¥½ï¼Œè®­ç»ƒé€Ÿåº¦æé«˜äº†400å€ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†250å€ã€‚</p>
</li>
<li>ä¸ä¸“æ³¨äºå¿«é€Ÿè®­ç»ƒçš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•è™½ç„¶è®­ç»ƒé€Ÿåº¦è¾ƒæ…¢ï¼Œä½†èƒ½å¤Ÿå¯¹å§¿åŠ¿ç›¸å…³çš„éåˆšæ€§å˜å½¢è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶äº§ç”Ÿæ˜æ˜¾æ›´å¥½çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶æ¸²æŸ“é€Ÿåº¦æé«˜äº†3å€ã€‚</li>
</ul>
<ol>
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§åŸºäº3Dé«˜æ–¯ç‚¹äº‘ç”Ÿæˆçš„å¯åŠ¨ç”»èº«é‡å»ºæ–¹æ³•ï¼Œå°†åˆšæ€§äººä½“å…³èŠ‚ä¸éåˆšæ€§å˜å½¢åœºæœ‰æ•ˆåœ°é›†æˆåˆ°3Dé«˜æ–¯ç‚¹äº‘ç”Ÿæˆæ¡†æ¶ä¸­ï¼›</p>
<p>ï¼ˆ2ï¼‰ï¼šä½¿ç”¨äº†ä¸€ä¸ªå°å‹å¤šå±‚æ„ŸçŸ¥æœºæ¥è§£ç é¢œè‰²ï¼Œè¯¥æ„ŸçŸ¥æœºèƒ½å¤Ÿå¯¹å±€éƒ¨éåˆšæ€§å˜å½¢å’ŒåŠ¨æ€å…‰ç…§æ¡ä»¶åšå‡ºå“åº”ï¼›</p>
<p>ï¼ˆ3ï¼‰ï¼šåº”ç”¨äº†â€œå°½å¯èƒ½ç­‰è·â€æ­£åˆ™åŒ–é¡¹ï¼Œä»¥ä¿æŒå‡ ä½•ä¸€è‡´æ€§å’Œé€¼çœŸçš„å˜å½¢ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨æ€å’Œå˜åŒ–çš„å§¿åŠ¿ä¸­ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯ç‚¹äº‘ç”Ÿæˆçš„å¯åŠ¨ç”»èº«é‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å•ç›®è§†é¢‘è¾“å…¥çš„æƒ…å†µä¸‹ï¼Œåœ¨å¯åŠ¨ç”»èº«åˆ›å»ºæ–¹é¢ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“æˆ–æ›´å¥½ï¼Œè®­ç»ƒé€Ÿåº¦æé«˜äº† 400 å€ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº† 250 å€ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯ç‚¹äº‘ç”Ÿæˆçš„å¯åŠ¨ç”»èº«é‡å»ºæ–¹æ³•ï¼Œå°†åˆšæ€§äººä½“å…³èŠ‚ä¸éåˆšæ€§å˜å½¢åœºæœ‰æ•ˆåœ°é›†æˆåˆ° 3D é«˜æ–¯ç‚¹äº‘ç”Ÿæˆæ¡†æ¶ä¸­ï¼›ä½¿ç”¨äº†ä¸€ä¸ªå°å‹å¤šå±‚æ„ŸçŸ¥æœºæ¥è§£ç é¢œè‰²ï¼Œè¯¥æ„ŸçŸ¥æœºèƒ½å¤Ÿå¯¹å±€éƒ¨éåˆšæ€§å˜å½¢å’ŒåŠ¨æ€å…‰ç…§æ¡ä»¶åšå‡ºå“åº”ï¼›åº”ç”¨äº†â€œå°½å¯èƒ½ç­‰è·â€æ­£åˆ™åŒ–é¡¹ï¼Œä»¥ä¿æŒå‡ ä½•ä¸€è‡´æ€§å’Œé€¼çœŸçš„å˜å½¢ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨æ€å’Œå˜åŒ–çš„å§¿åŠ¿ä¸­ã€‚æ€§èƒ½ï¼šåœ¨å•ç›®è§†é¢‘è¾“å…¥çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ³•åœ¨å¯åŠ¨ç”»èº«åˆ›å»ºæ–¹é¢ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“æˆ–æ›´å¥½ï¼Œè®­ç»ƒé€Ÿåº¦æé«˜äº† 400 å€ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº† 250 å€ï¼›ä¸ä¸“æ³¨äºå¿«é€Ÿè®­ç»ƒçš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•è™½ç„¶è®­ç»ƒé€Ÿåº¦è¾ƒæ…¢ï¼Œä½†èƒ½å¤Ÿå¯¹å§¿åŠ¿ç›¸å…³çš„éåˆšæ€§å˜å½¢è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶äº§ç”Ÿæ˜æ˜¾æ›´å¥½çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶æ¸²æŸ“é€Ÿåº¦æé«˜äº† 3 å€ã€‚å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦éƒ½éå¸¸å¿«ï¼Œè®­ç»ƒä¸€ä¸ªæ¨¡å‹åªéœ€è¦å‡ åˆ†é’Ÿï¼Œæ¨ç†ä¸€ä¸ªæ¨¡å‹åªéœ€è¦å‡ æ¯«ç§’ã€‚</p>
]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>LLM</tag>
        <tag>Google</tag>
      </tags>
  </entry>
  <entry>
    <title>æ•°å­—äººå¯¹è¯ç³»ç»Ÿ - Linly-Talker â€”â€” â€œæ•°å­—äººäº¤äº’ï¼Œä¸è™šæ‹Ÿçš„è‡ªå·±äº’åŠ¨â€</title>
    <url>/2024/01/20/Project/Linly-Talker/</url>
    <content><![CDATA[<p><strong>2023.12 æ›´æ–°</strong> ğŸ“†</p>
<p><strong>ç”¨æˆ·å¯ä»¥ä¸Šä¼ ä»»æ„å›¾ç‰‡è¿›è¡Œå¯¹è¯</strong></p>
<p><strong>2024.01 æ›´æ–°</strong> ğŸ“†</p>
<ul>
<li><strong>ä»¤äººå…´å¥‹çš„æ¶ˆæ¯ï¼æˆ‘ç°åœ¨å·²ç»å°†å¼ºå¤§çš„GeminiProå’ŒQwenå¤§æ¨¡å‹èå…¥åˆ°æˆ‘ä»¬çš„å¯¹è¯åœºæ™¯ä¸­ã€‚ç”¨æˆ·ç°åœ¨å¯ä»¥åœ¨å¯¹è¯ä¸­ä¸Šä¼ ä»»ä½•å›¾ç‰‡ï¼Œä¸ºæˆ‘ä»¬çš„äº’åŠ¨å¢æ·»äº†å…¨æ–°çš„å±‚é¢ã€‚</strong></li>
<li><strong>æ›´æ–°äº†FastAPIçš„éƒ¨ç½²è°ƒç”¨æ–¹æ³•ã€‚</strong> </li>
<li><strong>æ›´æ–°äº†å¾®è½¯TTSçš„é«˜çº§è®¾ç½®é€‰é¡¹ï¼Œå¢åŠ å£°éŸ³ç§ç±»çš„å¤šæ ·æ€§ï¼Œä»¥åŠåŠ å…¥è§†é¢‘å­—å¹•åŠ å¼ºå¯è§†åŒ–ã€‚</strong></li>
<li><strong>æ›´æ–°äº†GPTå¤šè½®å¯¹è¯ç³»ç»Ÿï¼Œä½¿å¾—å¯¹è¯æœ‰ä¸Šä¸‹æ–‡è”ç³»ï¼Œæé«˜æ•°å­—äººçš„äº¤äº’æ€§å’ŒçœŸå®æ„Ÿ</strong></li>
</ul>
<p><strong>2024.02 æ›´æ–°</strong> ğŸ“†</p>
<ul>
<li><strong>æ›´æ–°äº†Gradioçš„ç‰ˆæœ¬ä¸ºæœ€æ–°ç‰ˆæœ¬4.16.0ï¼Œä½¿å¾—ç•Œé¢æ‹¥æœ‰æ›´å¤šçš„åŠŸèƒ½ï¼Œæ¯”å¦‚å¯ä»¥æ‘„åƒå¤´æ‹æ‘„å›¾ç‰‡æ„å»ºæ•°å­—äººç­‰</strong></li>
<li><strong>æ›´æ–°äº†ASRå’ŒTHGï¼Œå…¶ä¸­ASRåŠ å…¥äº†é˜¿é‡Œçš„FunASRï¼Œå…·ä½“æ›´å¿«çš„é€Ÿåº¦ï¼›THGéƒ¨åˆ†åŠ å…¥äº†Wav2Lipæ¨¡å‹ï¼ŒER-NeRFåœ¨å‡†å¤‡ä¸­(Comming Soon)</strong></li>
</ul>
<h2 id="ä»‹ç»"><a href="#ä»‹ç»" class="headerlink" title="ä»‹ç»"></a>ä»‹ç»</h2><p>Linly-Talkeræ˜¯ä¸€ä¸ªå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸è§†è§‰æ¨¡å‹ç›¸ç»“åˆçš„æ™ºèƒ½AIç³»ç»Ÿ,åˆ›å»ºäº†ä¸€ç§å…¨æ–°çš„äººæœºäº¤äº’æ–¹å¼ã€‚å®ƒé›†æˆäº†å„ç§æŠ€æœ¯,ä¾‹å¦‚Whisperã€Linlyã€å¾®è½¯è¯­éŸ³æœåŠ¡å’ŒSadTalkerä¼šè¯´è¯çš„ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿéƒ¨ç½²åœ¨Gradioä¸Š,å…è®¸ç”¨æˆ·é€šè¿‡æä¾›å›¾åƒä¸AIåŠ©æ‰‹è¿›è¡Œäº¤è°ˆã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®è‡ªå·±çš„å–œå¥½è¿›è¡Œè‡ªç”±çš„å¯¹è¯æˆ–å†…å®¹ç”Ÿæˆã€‚</p>
<p><img src="https://picx.zhimg.com/80/v2-b38722d9d71153dec12acbb9e020a5b4.png" alt="The system architecture of multimodal humanâ€“computer interaction."></p>
<h2 id="TO-TO-DO-LIST"><a href="#TO-TO-DO-LIST" class="headerlink" title="TO## TO DO LIST"></a>TO## TO DO LIST</h2><ul>
<li>[x] åŸºæœ¬å®Œæˆå¯¹è¯ç³»ç»Ÿæµç¨‹ï¼Œèƒ½å¤Ÿ<code>è¯­éŸ³å¯¹è¯</code></li>
<li>[x] åŠ å…¥äº†LLMå¤§æ¨¡å‹ï¼ŒåŒ…æ‹¬<code>Linly</code>ï¼Œ<code>Qwen</code>å’Œ<code>GeminiPro</code>çš„ä½¿ç”¨</li>
<li>[x] å¯ä¸Šä¼ <code>ä»»æ„æ•°å­—äººç…§ç‰‡</code>è¿›è¡Œå¯¹è¯</li>
<li>[x] LinlyåŠ å…¥<code>FastAPI</code>è°ƒç”¨æ–¹å¼</li>
<li>[x] åˆ©ç”¨å¾®è½¯<code>TTS</code>åŠ å…¥é«˜çº§é€‰é¡¹ï¼Œå¯è®¾ç½®å¯¹åº”äººå£°ä»¥åŠéŸ³è°ƒç­‰å‚æ•°ï¼Œå¢åŠ å£°éŸ³çš„å¤šæ ·æ€§</li>
<li>[x] è§†é¢‘ç”ŸæˆåŠ å…¥<code>å­—å¹•</code>ï¼Œèƒ½å¤Ÿæ›´å¥½çš„è¿›è¡Œå¯è§†åŒ–</li>
<li>[x] GPT<code>å¤šè½®å¯¹è¯</code>ç³»ç»Ÿï¼ˆæé«˜æ•°å­—äººçš„äº¤äº’æ€§å’ŒçœŸå®æ„Ÿï¼Œå¢å¼ºæ•°å­—äººçš„æ™ºèƒ½ï¼‰</li>
<li>[x] ä¼˜åŒ–Gradioç•Œé¢ï¼ŒåŠ å…¥æ›´å¤šæ¨¡å‹ï¼Œå¦‚Wav2Lipï¼ŒFunASRç­‰</li>
<li>[ ] <code>è¯­éŸ³å…‹éš†</code>æŠ€æœ¯ï¼ˆè¯­éŸ³å…‹éš†åˆæˆè‡ªå·±å£°éŸ³ï¼Œæé«˜æ•°å­—äººåˆ†èº«çš„çœŸå®æ„Ÿå’Œäº’åŠ¨ä½“éªŒï¼‰</li>
<li>[ ] åŠ å…¥<code>Langchain</code>çš„æ¡†æ¶ï¼Œå»ºç«‹æœ¬åœ°çŸ¥è¯†åº“</li>
<li>[ ] <code>å®æ—¶</code>è¯­éŸ³è¯†åˆ«ï¼ˆäººä¸æ•°å­—äººä¹‹é—´å°±å¯ä»¥é€šè¿‡è¯­éŸ³è¿›è¡Œå¯¹è¯äº¤æµ)</li>
</ul>
<p>ğŸ”† è¯¥é¡¹ç›® Linly-Talker æ­£åœ¨è¿›è¡Œä¸­ - æ¬¢è¿æå‡ºPRè¯·æ±‚ï¼å¦‚æœæ‚¨æœ‰ä»»ä½•å…³äºæ–°çš„æ¨¡å‹æ–¹æ³•ã€ç ”ç©¶ã€æŠ€æœ¯æˆ–å‘ç°è¿è¡Œé”™è¯¯çš„å»ºè®®ï¼Œè¯·éšæ—¶ç¼–è¾‘å¹¶æäº¤ PRã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰“å¼€ä¸€ä¸ªé—®é¢˜æˆ–é€šè¿‡ç”µå­é‚®ä»¶ç›´æ¥è”ç³»æˆ‘ã€‚ğŸ“©â­ å¦‚æœæ‚¨å‘ç°è¿™ä¸ªGithub Projectæœ‰ç”¨ï¼Œè¯·ç»™å®ƒç‚¹ä¸ªæ˜Ÿï¼ğŸ¤©</p>
<h2 id="ç¤ºä¾‹"><a href="#ç¤ºä¾‹" class="headerlink" title="ç¤ºä¾‹"></a>ç¤ºä¾‹</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">æ–‡å­—/è¯­éŸ³å¯¹è¯</th>
<th style="text-align:center">æ•°å­—äººå›ç­”</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">åº”å¯¹å‹åŠ›æœ€æœ‰æ•ˆçš„æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ</td>
<td style="text-align:center"><video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/f1deb189-b682-4175-9dea-7eeb0fb392ca"></video></td>
</tr>
<tr>
<td style="text-align:center">å¦‚ä½•è¿›è¡Œæ—¶é—´ç®¡ç†ï¼Ÿ</td>
<td style="text-align:center"><video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/968b5c43-4dce-484b-b6c6-0fd4d621ac03"></video></td>
</tr>
<tr>
<td style="text-align:center">æ’°å†™ä¸€ç¯‡äº¤å“ä¹éŸ³ä¹ä¼šè¯„è®ºï¼Œè®¨è®ºä¹å›¢çš„è¡¨æ¼”å’Œè§‚ä¼—çš„æ•´ä½“ä½“éªŒã€‚</td>
<td style="text-align:center"><video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/f052820f-6511-4cf0-a383-daf8402630db"></video></td>
</tr>
<tr>
<td style="text-align:center">ç¿»è¯‘æˆä¸­æ–‡ï¼šLuck is a dividend of sweat. The more you sweat, the luckier you get.</td>
<td style="text-align:center"><video src="https://github.com/Kedreamix/Linly-Talker/assets/61195303/118eec13-a9f7-4c38-b4ad-044d36ba9776"></video></td>
</tr>
</tbody>
</table>
</div>
<h2 id="åˆ›å»ºç¯å¢ƒ"><a href="#åˆ›å»ºç¯å¢ƒ" class="headerlink" title="åˆ›å»ºç¯å¢ƒ"></a>åˆ›å»ºç¯å¢ƒ</h2><figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">conda create -n linly python=3.9 </span><br><span class="line">conda activate linly</span><br><span class="line"></span><br><span class="line"><span class="comment"># pytorchå®‰è£…æ–¹å¼1ï¼šcondaå®‰è£…ï¼ˆæ¨èï¼‰</span></span><br><span class="line">conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch</span><br><span class="line"></span><br><span class="line"><span class="comment"># pytorchå®‰è£…æ–¹å¼2ï¼špip å®‰è£…</span></span><br><span class="line">pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113</span><br><span class="line"></span><br><span class="line">conda install -q ffmpeg <span class="comment"># ffmpeg==4.2.2</span></span><br><span class="line"></span><br><span class="line">pip install -r requirements_app.txt</span><br></pre></td></tr></tbody></table></figure>
<p>ä¸ºäº†å¤§å®¶çš„éƒ¨ç½²ä½¿ç”¨æ–¹ä¾¿ï¼Œæ›´æ–°äº†ä¸€ä¸ª<code>configs.py</code>æ–‡ä»¶ï¼Œå¯ä»¥å¯¹å…¶è¿›è¡Œä¸€äº›è¶…å‚æ•°ä¿®æ”¹å³å¯</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># è®¾å¤‡è¿è¡Œç«¯å£ (Device running port)</span></span><br><span class="line">port = 7870</span><br><span class="line"><span class="comment"># apiè¿è¡Œç«¯å£åŠIP (API running port and IP)</span></span><br><span class="line">ip = <span class="string">'127.0.0.1'</span> </span><br><span class="line">api_port = 7871</span><br><span class="line"><span class="comment"># Linlyæ¨¡å‹è·¯å¾„ (Linly model path)</span></span><br><span class="line">mode = <span class="string">'api'</span> <span class="comment"># api éœ€è¦å…ˆè¿è¡ŒLinly-api-fast.py</span></span><br><span class="line">mode = <span class="string">'offline'</span></span><br><span class="line">model_path = <span class="string">'Linly-AI/Chinese-LLaMA-2-7B-hf'</span></span><br><span class="line"><span class="comment"># sslè¯ä¹¦ (SSL certificate) éº¦å…‹é£å¯¹è¯éœ€è¦æ­¤å‚æ•°</span></span><br><span class="line">ssl_certfile = <span class="string">"/path/to/Linly-Talker/https_cert/cert.pem"</span></span><br><span class="line">ssl_keyfile = <span class="string">"/path/to/Linly-Talker/https_cert/key.pem"</span></span><br></pre></td></tr></tbody></table></figure>
<h2 id="ASR-Speech-Recognition"><a href="#ASR-Speech-Recognition" class="headerlink" title="ASR - Speech Recognition"></a>ASR - Speech Recognition</h2><h3 id="Whisper"><a href="#Whisper" class="headerlink" title="Whisper"></a>Whisper</h3><p>å€Ÿé‰´OpenAIçš„Whisperå®ç°äº†ASRçš„è¯­éŸ³è¯†åˆ«ï¼Œå…·ä½“ä½¿ç”¨æ–¹æ³•å‚è€ƒ <a href="https://github.com/openai/whisper">https://github.com/openai/whisper</a></p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">https://github.com/openai/whisper</span></span><br><span class="line"><span class="string">pip install -U openai-whisper</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">import</span> whisper</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">WhisperASR</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_path</span>):</span><br><span class="line">        self.LANGUAGES = {</span><br><span class="line">            <span class="string">"en"</span>: <span class="string">"english"</span>,</span><br><span class="line">            <span class="string">"zh"</span>: <span class="string">"chinese"</span>,</span><br><span class="line">        }</span><br><span class="line">        self.model = whisper.load_model(model_path)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transcribe</span>(<span class="params">self, audio_file</span>):</span><br><span class="line">        result = self.model.transcribe(audio_file)</span><br><span class="line">        <span class="keyword">return</span> result[<span class="string">"text"</span>]</span><br></pre></td></tr></tbody></table></figure>
<h3 id="FunASR"><a href="#FunASR" class="headerlink" title="FunASR"></a>FunASR</h3><p>é˜¿é‡Œçš„<code>FunASR</code>çš„è¯­éŸ³è¯†åˆ«æ•ˆæœä¹Ÿæ˜¯ç›¸å½“ä¸é”™ï¼Œè€Œä¸”æ—¶é—´ä¹Ÿæ˜¯æ¯”whisperæ›´å¿«çš„ï¼Œæ›´èƒ½è¾¾åˆ°å®æ—¶çš„æ•ˆæœï¼Œæ‰€ä»¥ä¹Ÿå°†FunASRæ·»åŠ è¿›å»äº†ï¼Œåœ¨ASRæ–‡ä»¶å¤¹ä¸‹çš„FunASRæ–‡ä»¶é‡Œå¯ä»¥è¿›è¡Œä½“éªŒï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œçš„æ—¶å€™ï¼Œéœ€è¦å®‰è£…ä»¥ä¸‹åº“ï¼Œå‚è€ƒ <a href="https://github.com/alibaba-damo-academy/FunASR">https://github.com/alibaba-damo-academy/FunASR</a></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install funasr</span><br><span class="line">pip install modelscope</span><br><span class="line">pip install -U rotary_embedding_torch</span><br></pre></td></tr></tbody></table></figure>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">Reference: https://github.com/alibaba-damo-academy/FunASR</span></span><br><span class="line"><span class="string">pip install funasr</span></span><br><span class="line"><span class="string">pip install modelscope</span></span><br><span class="line"><span class="string">pip install -U rotary_embedding_torch</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> funasr <span class="keyword">import</span> AutoModel</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"å¦‚æœæƒ³ä½¿ç”¨FunASRï¼Œè¯·å…ˆå®‰è£…funasrï¼Œè‹¥ä½¿ç”¨Whisperï¼Œè¯·å¿½ç•¥æ­¤æ¡ä¿¡æ¯"</span>)   </span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FunASR</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        self.model = AutoModel(model=<span class="string">"paraformer-zh"</span>, model_revision=<span class="string">"v2.0.4"</span>,</span><br><span class="line">                vad_model=<span class="string">"fsmn-vad"</span>, vad_model_revision=<span class="string">"v2.0.4"</span>,</span><br><span class="line">                punc_model=<span class="string">"ct-punc-c"</span>, punc_model_revision=<span class="string">"v2.0.4"</span>,</span><br><span class="line">                <span class="comment"># spk_model="cam++", spk_model_revision="v2.0.2",</span></span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transcribe</span>(<span class="params">self, audio_file</span>):</span><br><span class="line">        res = self.model.generate(<span class="built_in">input</span>=audio_file, </span><br><span class="line">            batch_size_s=<span class="number">300</span>)</span><br><span class="line">        <span class="built_in">print</span>(res)</span><br><span class="line">        <span class="keyword">return</span> res[<span class="number">0</span>][<span class="string">'text'</span>]</span><br></pre></td></tr></tbody></table></figure>
<h2 id="TTS-Edge-TTS"><a href="#TTS-Edge-TTS" class="headerlink" title="TTS - Edge TTS"></a>TTS - Edge TTS</h2><p>ä½¿ç”¨å¾®è½¯è¯­éŸ³æœåŠ¡,å…·ä½“ä½¿ç”¨æ–¹æ³•å‚è€ƒ<a href="https://github.com/rany2/edge-tts">https://github.com/rany2/edge-tts</a></p>
<p>æˆ‘ç¼–å†™äº†ä¸€ä¸ª <code>EdgeTTS</code> çš„ç±»ï¼Œèƒ½å¤Ÿæ›´å¥½çš„ä½¿ç”¨ï¼Œå¹¶ä¸”å¢åŠ äº†ä¿å­˜å­—å¹•æ–‡ä»¶çš„åŠŸèƒ½</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EdgeTTS</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, list_voices = <span class="literal">False</span>, proxy = <span class="literal">None</span></span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        voices = list_voices_fn(proxy=proxy)</span><br><span class="line">        self.SUPPORTED_VOICE = [item[<span class="string">'ShortName'</span>] <span class="keyword">for</span> item <span class="keyword">in</span> voices]</span><br><span class="line">        self.SUPPORTED_VOICE.sort(reverse=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> list_voices:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">", "</span>.join(self.SUPPORTED_VOICE))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">self, rate, volume, pitch</span>):</span><br><span class="line">        <span class="keyword">if</span> rate &gt;= <span class="number">0</span>:</span><br><span class="line">            rate = <span class="string">f'+<span class="subst">{rate}</span>%'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            rate = <span class="string">f'<span class="subst">{rate}</span>%'</span></span><br><span class="line">        <span class="keyword">if</span> pitch &gt;= <span class="number">0</span>:</span><br><span class="line">            pitch = <span class="string">f'+<span class="subst">{pitch}</span>Hz'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            pitch = <span class="string">f'<span class="subst">{pitch}</span>Hz'</span></span><br><span class="line">        volume = <span class="number">100</span> - volume</span><br><span class="line">        volume = <span class="string">f'-<span class="subst">{volume}</span>%'</span></span><br><span class="line">        <span class="keyword">return</span> rate, volume, pitch</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self,TEXT, VOICE, RATE, VOLUME, PITCH, OUTPUT_FILE=<span class="string">'result.wav'</span>, OUTPUT_SUBS=<span class="string">'result.vtt'</span>, words_in_cue = <span class="number">8</span></span>):</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">amain</span>() -&gt; <span class="literal">None</span>:</span><br><span class="line">            <span class="string">"""Main function"""</span></span><br><span class="line">            rate, volume, pitch = self.preprocess(rate = RATE, volume = VOLUME, pitch = PITCH)</span><br><span class="line">            communicate = Communicate(TEXT, VOICE, rate = rate, volume = volume, pitch = pitch)</span><br><span class="line">            subs: SubMaker = SubMaker()</span><br><span class="line">            sub_file: <span class="type">Union</span>[TextIOWrapper, TextIO] = (</span><br><span class="line">                <span class="built_in">open</span>(OUTPUT_SUBS, <span class="string">"w"</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line">            )</span><br><span class="line">            <span class="keyword">async</span> <span class="keyword">for</span> chunk <span class="keyword">in</span> communicate.stream():</span><br><span class="line">                <span class="keyword">if</span> chunk[<span class="string">"type"</span>] == <span class="string">"audio"</span>:</span><br><span class="line">                    <span class="comment"># audio_file.write(chunk["data"])</span></span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">                <span class="keyword">elif</span> chunk[<span class="string">"type"</span>] == <span class="string">"WordBoundary"</span>:</span><br><span class="line">                    <span class="comment"># print((chunk["offset"], chunk["duration"]), chunk["text"])</span></span><br><span class="line">                    subs.create_sub((chunk[<span class="string">"offset"</span>], chunk[<span class="string">"duration"</span>]), chunk[<span class="string">"text"</span>])</span><br><span class="line">            sub_file.write(subs.generate_subs(words_in_cue))</span><br><span class="line">            <span class="keyword">await</span> communicate.save(OUTPUT_FILE)</span><br><span class="line">            </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># loop = asyncio.get_event_loop_policy().get_event_loop()</span></span><br><span class="line">        <span class="comment"># try:</span></span><br><span class="line">        <span class="comment">#     loop.run_until_complete(amain())</span></span><br><span class="line">        <span class="comment"># finally:</span></span><br><span class="line">        <span class="comment">#     loop.close()</span></span><br><span class="line">        asyncio.run(amain())</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(OUTPUT_SUBS, <span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> file:</span><br><span class="line">            vtt_lines = file.readlines()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># å»æ‰æ¯ä¸€è¡Œæ–‡å­—ä¸­çš„ç©ºæ ¼</span></span><br><span class="line">        vtt_lines_without_spaces = [line.replace(<span class="string">" "</span>, <span class="string">""</span>) <span class="keyword">if</span> <span class="string">"--&gt;"</span> <span class="keyword">not</span> <span class="keyword">in</span> line <span class="keyword">else</span> line <span class="keyword">for</span> line <span class="keyword">in</span> vtt_lines]</span><br><span class="line">        <span class="comment"># print(vtt_lines_without_spaces)</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(OUTPUT_SUBS, <span class="string">'w'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> output_file:</span><br><span class="line">            output_file.writelines(vtt_lines_without_spaces)</span><br><span class="line">        <span class="keyword">return</span> OUTPUT_FILE, OUTPUT_SUBS</span><br></pre></td></tr></tbody></table></figure>
<p>åŒæ—¶åœ¨<code>src</code>æ–‡ä»¶å¤¹ä¸‹ï¼Œå†™äº†ä¸€ä¸ªç®€æ˜“çš„<code>WebUI</code></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">python TTS_app.py</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://picx.zhimg.com/80/v2-570f3c9a069358e4d4a7b7c008e99cb7.png" alt="TTS"></p>
<h2 id="THG-Avatar"><a href="#THG-Avatar" class="headerlink" title="THG - Avatar"></a>THG - Avatar</h2><h3 id="SadTalker"><a href="#SadTalker" class="headerlink" title="SadTalker"></a>SadTalker</h3><p>æ•°å­—äººç”Ÿæˆå¯ä½¿ç”¨SadTalkerï¼ˆCVPR 2023ï¼‰,è¯¦æƒ…ä»‹ç»è§ <a href="https://sadtalker.github.io">https://sadtalker.github.io</a></p>
<p>åœ¨ä½¿ç”¨å‰å…ˆä¸‹è½½SadTalkeræ¨¡å‹:</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">bash scripts/sadtalker_download_models.sh  </span><br></pre></td></tr></tbody></table></figure>
<p><a href="https://pan.baidu.com/s/1eF13O-8wyw4B3MtesctQyg?pwd=linl">Baidu (ç™¾åº¦äº‘ç›˜)</a> (Password: <code>linl</code>)</p>
<blockquote>
<p>å¦‚æœç™¾åº¦ç½‘ç›˜ä¸‹è½½ï¼Œè®°ä½æ˜¯æ”¾åœ¨checkpointsæ–‡ä»¶å¤¹ä¸‹ï¼Œç™¾åº¦ç½‘ç›˜ä¸‹è½½çš„é»˜è®¤å‘½åä¸ºsadtalkerï¼Œå®é™…åº”è¯¥é‡å‘½åä¸ºcheckpoints</p>
</blockquote>
<h3 id="Wav2Lip"><a href="#Wav2Lip" class="headerlink" title="Wav2Lip"></a>Wav2Lip</h3><p>æ•°å­—äººç”Ÿæˆè¿˜å¯ä½¿ç”¨Wav2Lipï¼ˆACM 2020ï¼‰ï¼Œè¯¦æƒ…ä»‹ç»è§ <a href="https://github.com/Rudrabha/Wav2Lip">https://github.com/Rudrabha/Wav2Lip</a></p>
<p>åœ¨ä½¿ç”¨å‰å…ˆä¸‹è½½Wav2Lipæ¨¡å‹ï¼š</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Model</th>
<th>Description</th>
<th>Link to the model</th>
</tr>
</thead>
<tbody>
<tr>
<td>Wav2Lip</td>
<td>Highly accurate lip-sync</td>
<td><a href="https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/Eb3LEzbfuKlJiR600lQWRxgBIY27JZg80f7V9jtMfbNDaQ?e=TBFBVW">Link</a></td>
</tr>
<tr>
<td>Wav2Lip + GAN</td>
<td>Slightly inferior lip-sync, but better visual quality</td>
<td><a href="https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp55YNDcIA?e=n9ljGW">Link</a></td>
</tr>
<tr>
<td>Expert Discriminator</td>
<td>Weights of the expert discriminator</td>
<td><a href="https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQRvmiZg-HRAjvI6zqN9eTEBP74KefynCwPWVmF57l-AYA?e=ZRPHKP">Link</a></td>
</tr>
<tr>
<td>Visual Quality Discriminator</td>
<td>Weights of the visual disc trained in a GAN setup</td>
<td><a href="https://iiitaphyd-my.sharepoint.com/:u:/g/personal/radrabha_m_research_iiit_ac_in/EQVqH88dTm1HjlK11eNba5gBbn15WMS0B0EZbDBttqrqkg?e=ic0ljo">Link</a></td>
</tr>
</tbody>
</table>
</div>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Wav2Lip</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path = <span class="string">'checkpoints/wav2lip.pth'</span></span>):</span><br><span class="line">        self.fps = <span class="number">25</span></span><br><span class="line">        self.resize_factor = <span class="number">1</span></span><br><span class="line">        self.mel_step_size = <span class="number">16</span></span><br><span class="line">        self.static = <span class="literal">False</span></span><br><span class="line">        self.img_size = <span class="number">96</span></span><br><span class="line">        self.face_det_batch_size = <span class="number">2</span></span><br><span class="line">        self.box = [-<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>, -<span class="number">1</span>]</span><br><span class="line">        self.pads = [<span class="number">0</span>, <span class="number">10</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">        self.nosmooth = <span class="literal">False</span></span><br><span class="line">        self.device = <span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span></span><br><span class="line">        self.model = self.load_model(path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_model</span>(<span class="params">self, checkpoint_path</span>):</span><br><span class="line">        model = wav2lip_mdoel()</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"Load checkpoint from: {}"</span>.<span class="built_in">format</span>(checkpoint_path))</span><br><span class="line">        <span class="keyword">if</span> self.device == <span class="string">'cuda'</span>:</span><br><span class="line">            checkpoint = torch.load(checkpoint_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            checkpoint = torch.load(checkpoint_path,</span><br><span class="line">                                    map_location=<span class="keyword">lambda</span> storage, loc: storage)</span><br><span class="line">        s = checkpoint[<span class="string">"state_dict"</span>]</span><br><span class="line">        new_s = {}</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> s.items():</span><br><span class="line">            new_s[k.replace(<span class="string">'module.'</span>, <span class="string">''</span>)] = v</span><br><span class="line">        model.load_state_dict(new_s)</span><br><span class="line"></span><br><span class="line">        model = model.to(self.device)</span><br><span class="line">        <span class="keyword">return</span> model.<span class="built_in">eval</span>()</span><br></pre></td></tr></tbody></table></figure>
<h3 id="ER-NeRFï¼ˆComming-Soonï¼‰"><a href="#ER-NeRFï¼ˆComming-Soonï¼‰" class="headerlink" title="ER-NeRFï¼ˆComming Soonï¼‰"></a>ER-NeRFï¼ˆComming Soonï¼‰</h3><p>ER-NeRFï¼ˆICCV2023ï¼‰æ˜¯ä½¿ç”¨æœ€æ–°çš„NeRFæŠ€æœ¯æ„å»ºçš„æ•°å­—äººï¼Œæ‹¥æœ‰å®šåˆ¶æ•°å­—äººçš„ç‰¹æ€§ï¼Œåªéœ€è¦ä¸€ä¸ªäººçš„äº”åˆ†é’Ÿå·¦å³åˆ°è§†é¢‘å³å¯é‡å»ºå‡ºæ¥ï¼Œå…·ä½“å¯å‚è€ƒ <a href="https://github.com/Fictionarry/ER-NeRF">https://github.com/Fictionarry/ER-NeRF</a></p>
<p>åç»­ä¼šé’ˆå¯¹æ­¤æ›´æ–°</p>
<h2 id="LLM-Conversation"><a href="#LLM-Conversation" class="headerlink" title="LLM - Conversation"></a>LLM - Conversation</h2><h3 id="Linly-AI"><a href="#Linly-AI" class="headerlink" title="Linly-AI"></a>Linly-AI</h3><p>Linlyæ¥è‡ªæ·±åœ³å¤§å­¦æ•°æ®å·¥ç¨‹å›½å®¶é‡ç‚¹å®éªŒå®¤,å‚è€ƒ<a href="https://github.com/CVI-SZU/Linly">https://github.com/CVI-SZU/Linly</a></p>
<p>ä¸‹è½½Linlyæ¨¡å‹:<a href="https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf">https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf</a></p>
<p>å¯ä»¥ä½¿ç”¨<code>git</code>ä¸‹è½½</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git lfs install</span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/Linly-AI/Chinese-LLaMA-2-7B-hf</span><br></pre></td></tr></tbody></table></figure>
<p>æˆ–è€…ä½¿ç”¨<code>huggingface</code>çš„ä¸‹è½½å·¥å…·<code>huggingface-cli</code></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®é•œåƒåŠ é€Ÿ</span></span><br><span class="line"><span class="comment"># Linux</span></span><br><span class="line"><span class="built_in">export</span> HF_ENDPOINT=<span class="string">"https://hf-mirror.com"</span></span><br><span class="line"><span class="comment"># windows powershell</span></span><br><span class="line"><span class="variable">$env</span>:HF_ENDPOINT=<span class="string">"https://hf-mirror.com"</span></span><br><span class="line"></span><br><span class="line">huggingface-cli download --resume-download Linly-AI/Chinese-LLaMA-2-7B-hf --local-dir Linly-AI/Chinese-LLaMA-2-7B-hf</span><br></pre></td></tr></tbody></table></figure>
<p>æˆ–ä½¿ç”¨API:</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># å‘½ä»¤è¡Œ</span></span><br><span class="line">curl -X POST -H <span class="string">"Content-Type: application/json"</span> -d <span class="string">'{"question": "åŒ—äº¬æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹?"}'</span> http://url:port  </span><br><span class="line"></span><br><span class="line"><span class="comment"># Python</span></span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://url:port"</span></span><br><span class="line">headers = {</span><br><span class="line">  <span class="string">"Content-Type"</span>: <span class="string">"application/json"</span></span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">data = {</span><br><span class="line">  <span class="string">"question"</span>: <span class="string">"åŒ—äº¬æœ‰ä»€ä¹ˆå¥½ç©çš„åœ°æ–¹?"</span> </span><br><span class="line">}</span><br><span class="line"></span><br><span class="line">response = requests.post(url, headers=headers, json=data)</span><br><span class="line"><span class="comment"># response_text = response.content.decode("utf-8")</span></span><br><span class="line">answer, tag = response.json()</span><br><span class="line"><span class="comment"># print(answer)</span></span><br><span class="line"><span class="keyword">if</span> tag == <span class="string">'success'</span>:</span><br><span class="line">    response_text =  answer[0]</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"fail"</span>)</span><br><span class="line"><span class="built_in">print</span>(response_text)</span><br></pre></td></tr></tbody></table></figure>
<p>APIéƒ¨ç½²æ¨è<strong>FastAPI</strong>ï¼Œç°åœ¨æ›´æ–°äº† FastAPI çš„APIä½¿ç”¨ç‰ˆæœ¬ï¼ŒFastAPI æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€æ˜“ç”¨ä¸”ç°ä»£çš„Python Web æ¡†æ¶ï¼Œå®ƒé€šè¿‡ä½¿ç”¨æœ€æ–°çš„Python ç‰¹æ€§å’Œå¼‚æ­¥ç¼–ç¨‹ï¼Œæä¾›äº†å¿«é€Ÿå¼€å‘Web API çš„èƒ½åŠ›ã€‚ è¯¥æ¡†æ¶ä¸ä»…æ˜“äºå­¦ä¹ å’Œä½¿ç”¨ï¼Œè¿˜å…·æœ‰è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£ã€æ•°æ®éªŒè¯ç­‰å¼ºå¤§åŠŸèƒ½ã€‚ æ— è®ºæ˜¯æ„å»ºå°å‹é¡¹ç›®è¿˜æ˜¯å¤§å‹åº”ç”¨ç¨‹åºï¼ŒFastAPI éƒ½æ˜¯ä¸€ä¸ªå¼ºå¤§è€Œæœ‰æ•ˆçš„å·¥å…·ã€‚</p>
<p>é¦–å…ˆå®‰è£…éƒ¨ç½²APIæ‰€ä½¿ç”¨çš„åº“</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install fastapi==0.104.1</span><br><span class="line">pip install uvicorn==0.24.0.post1</span><br></pre></td></tr></tbody></table></figure>
<p>å…¶ä»–ä½¿ç”¨æ–¹æ³•å¤§è‡´ç›¸åŒï¼Œä¸»è¦æ˜¯ä¸åŒä»£ç å®ç°æ–¹å¼ï¼Œä¼šæ›´åŠ ç®€å•è¾¹ç•Œï¼Œå¹¶ä¸”å¤„ç†å¹¶å‘ä¹Ÿä¼šæ›´å¥½</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> fastapi <span class="keyword">import</span> FastAPI, Request</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM, GenerationConfig</span><br><span class="line"><span class="keyword">import</span> uvicorn</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> configs <span class="keyword">import</span> model_path, api_port</span><br><span class="line"><span class="comment"># è®¾ç½®è®¾å¤‡å‚æ•°</span></span><br><span class="line">DEVICE = <span class="string">"cuda"</span>  <span class="comment"># ä½¿ç”¨CUDA</span></span><br><span class="line">DEVICE_ID = <span class="string">"0"</span>  <span class="comment"># CUDAè®¾å¤‡IDï¼Œå¦‚æœæœªè®¾ç½®åˆ™ä¸ºç©º</span></span><br><span class="line">CUDA_DEVICE = <span class="string">f"<span class="subst">{DEVICE}</span>:<span class="subst">{DEVICE_ID}</span>"</span> <span class="keyword">if</span> DEVICE_ID <span class="keyword">else</span> DEVICE  <span class="comment"># ç»„åˆCUDAè®¾å¤‡ä¿¡æ¯</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># æ¸…ç†GPUå†…å­˜å‡½æ•°</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">torch_gc</span>():</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():  <span class="comment"># æ£€æŸ¥æ˜¯å¦å¯ç”¨CUDA</span></span><br><span class="line">        <span class="keyword">with</span> torch.cuda.device(CUDA_DEVICE):  <span class="comment"># æŒ‡å®šCUDAè®¾å¤‡</span></span><br><span class="line">            torch.cuda.empty_cache()  <span class="comment"># æ¸…ç©ºCUDAç¼“å­˜</span></span><br><span class="line">            torch.cuda.ipc_collect()  <span class="comment"># æ”¶é›†CUDAå†…å­˜ç¢ç‰‡</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># åˆ›å»ºFastAPIåº”ç”¨</span></span><br><span class="line">app = FastAPI()</span><br><span class="line"></span><br><span class="line"><span class="comment"># å¤„ç†POSTè¯·æ±‚çš„ç«¯ç‚¹</span></span><br><span class="line"><span class="meta">@app.post(<span class="params"><span class="string">"/"</span></span>)</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">create_item</span>(<span class="params">request: Request</span>):</span><br><span class="line">    <span class="keyword">global</span> model, tokenizer  <span class="comment"># å£°æ˜å…¨å±€å˜é‡ä»¥ä¾¿åœ¨å‡½æ•°å†…éƒ¨ä½¿ç”¨æ¨¡å‹å’Œåˆ†è¯å™¨</span></span><br><span class="line">    json_post_raw = <span class="keyword">await</span> request.json()  <span class="comment"># è·å–POSTè¯·æ±‚çš„JSONæ•°æ®</span></span><br><span class="line">    json_post = json.dumps(json_post_raw)  <span class="comment"># å°†JSONæ•°æ®è½¬æ¢ä¸ºå­—ç¬¦ä¸²</span></span><br><span class="line">    json_post_list = json.loads(json_post)  <span class="comment"># å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºPythonå¯¹è±¡</span></span><br><span class="line">    prompt = json_post_list.get(<span class="string">'prompt'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„æç¤º</span></span><br><span class="line">    history = json_post_list.get(<span class="string">'history'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„å†å²è®°å½•</span></span><br><span class="line">    max_length = json_post_list.get(<span class="string">'max_length'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„æœ€å¤§é•¿åº¦</span></span><br><span class="line">    top_p = json_post_list.get(<span class="string">'top_p'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„top_på‚æ•°</span></span><br><span class="line">    temperature = json_post_list.get(<span class="string">'temperature'</span>)  <span class="comment"># è·å–è¯·æ±‚ä¸­çš„æ¸©åº¦å‚æ•°</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># è°ƒç”¨æ¨¡å‹è¿›è¡Œå¯¹è¯ç”Ÿæˆ</span></span><br><span class="line">    prompt = <span class="string">f"è¯·ç”¨å°‘äº25ä¸ªå­—å›ç­”ä»¥ä¸‹é—®é¢˜ ### Instruction:<span class="subst">{prompt}</span>  ### Response:"</span></span><br><span class="line">    inputs = tokenizer(prompt, return_tensors=<span class="string">"pt"</span>).to(<span class="string">"cuda:0"</span>)</span><br><span class="line">    generate_ids = model.generate(inputs.input_ids, </span><br><span class="line">                                  max_new_tokens=max_length <span class="keyword">if</span> max_length <span class="keyword">else</span> <span class="number">2048</span>,</span><br><span class="line">                                  do_sample=<span class="literal">True</span>, </span><br><span class="line">                                  top_k=<span class="number">20</span>,</span><br><span class="line">                                  top_p=top_p,</span><br><span class="line">                                  temperature=temperature <span class="keyword">if</span> temperature <span class="keyword">else</span> <span class="number">0.84</span>,</span><br><span class="line">                                  repetition_penalty=<span class="number">1.15</span>, eos_token_id=<span class="number">2</span>, bos_token_id=<span class="number">1</span>,pad_token_id=<span class="number">0</span>)</span><br><span class="line">    response = tokenizer.batch_decode(generate_ids, skip_special_tokens=<span class="literal">True</span>, clean_up_tokenization_spaces=<span class="literal">False</span>)[<span class="number">0</span>]</span><br><span class="line">    response = response.split(<span class="string">"### Response:"</span>)[-<span class="number">1</span>]</span><br><span class="line">    now = datetime.datetime.now()  <span class="comment"># è·å–å½“å‰æ—¶é—´</span></span><br><span class="line">    time = now.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>)  <span class="comment"># æ ¼å¼åŒ–æ—¶é—´ä¸ºå­—ç¬¦ä¸²</span></span><br><span class="line">    <span class="comment"># æ„å»ºå“åº”JSON</span></span><br><span class="line">    answer = {</span><br><span class="line">        <span class="string">"response"</span>: response,</span><br><span class="line">        <span class="comment"># "history": history,</span></span><br><span class="line">        <span class="string">"status"</span>: <span class="number">200</span>,</span><br><span class="line">        <span class="string">"time"</span>: time</span><br><span class="line">    }</span><br><span class="line">    <span class="comment"># æ„å»ºæ—¥å¿—ä¿¡æ¯</span></span><br><span class="line">    log = <span class="string">"["</span> + time + <span class="string">"] "</span> + <span class="string">'", prompt:"'</span> + prompt + <span class="string">'", response:"'</span> + <span class="built_in">repr</span>(response) + <span class="string">'"'</span></span><br><span class="line">    <span class="built_in">print</span>(log)  <span class="comment"># æ‰“å°æ—¥å¿—</span></span><br><span class="line">    torch_gc()  <span class="comment"># æ‰§è¡ŒGPUå†…å­˜æ¸…ç†</span></span><br><span class="line">    <span class="keyword">return</span> answer  <span class="comment"># è¿”å›å“åº”</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä¸»å‡½æ•°å…¥å£</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># åŠ è½½é¢„è®­ç»ƒçš„åˆ†è¯å™¨å’Œæ¨¡å‹</span></span><br><span class="line">    model = AutoModelForCausalLM.from_pretrained(model_path, device_map=<span class="string">"cuda:0"</span>,</span><br><span class="line">                                                    torch_dtype=torch.bfloat16, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=<span class="literal">False</span>, trust_remote_code=<span class="literal">True</span>)</span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼</span></span><br><span class="line">    <span class="comment"># å¯åŠ¨FastAPIåº”ç”¨</span></span><br><span class="line">    uvicorn.run(app, host=<span class="string">'0.0.0.0'</span>, port=api_port, workers=<span class="number">1</span>)  <span class="comment"># åœ¨æŒ‡å®šç«¯å£å’Œä¸»æœºä¸Šå¯åŠ¨åº”ç”¨</span></span><br></pre></td></tr></tbody></table></figure>
<p>é»˜è®¤éƒ¨ç½²åœ¨ 7871 ç«¯å£ï¼Œé€šè¿‡ POST æ–¹æ³•è¿›è¡Œè°ƒç”¨ï¼Œå¯ä»¥ä½¿ç”¨curlè°ƒç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">curl -X POST <span class="string">"http://127.0.0.1:7871"</span> \</span><br><span class="line">     -H <span class="string">'Content-Type: application/json'</span> \</span><br><span class="line">     -d <span class="string">'{"prompt": "å¦‚ä½•åº”å¯¹å‹åŠ›"}'</span></span><br></pre></td></tr></tbody></table></figure>
<p>ä¹Ÿå¯ä»¥ä½¿ç”¨pythonä¸­çš„requestsåº“è¿›è¡Œè°ƒç”¨ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_completion</span>(<span class="params">prompt</span>):</span><br><span class="line">    headers = {<span class="string">'Content-Type'</span>: <span class="string">'application/json'</span>}</span><br><span class="line">    data = {<span class="string">"prompt"</span>: prompt}</span><br><span class="line">    response = requests.post(url=<span class="string">'http://127.0.0.1:7871'</span>, headers=headers, data=json.dumps(data))</span><br><span class="line">    <span class="keyword">return</span> response.json()[<span class="string">'response'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="built_in">print</span>(get_completion(<span class="string">'ä½ å¥½å¦‚ä½•åº”å¯¹å‹åŠ›'</span>))</span><br></pre></td></tr></tbody></table></figure>
<p>å¾—åˆ°çš„è¿”å›å€¼å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">{</span><br><span class="line">  <span class="string">"response"</span>:<span class="string">"å¯»æ±‚æ”¯æŒå’Œæ”¾æ¾ï¼Œå¹¶é‡‡å–ç§¯æçš„æªæ–½è§£å†³é—®é¢˜ã€‚"</span>,</span><br><span class="line">  <span class="string">"status"</span>:200,</span><br><span class="line">  <span class="string">"time"</span>:<span class="string">"2024-01-12 01:43:37"</span></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Qwen"><a href="#Qwen" class="headerlink" title="Qwen"></a>Qwen</h3><p>æ¥è‡ªé˜¿é‡Œäº‘çš„Qwenï¼ŒæŸ¥çœ‹ <a href="https://github.com/QwenLM/Qwen">https://github.com/QwenLM/Qwen</a></p>
<p>ä¸‹è½½ Qwen æ¨¡å‹: <a href="https://huggingface.co/Qwen/Qwen-1_8B-Chat">https://huggingface.co/Qwen/Qwen-1_8B-Chat</a></p>
<p>å¯ä»¥ä½¿ç”¨<code>git</code>ä¸‹è½½</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">git lfs install</span><br><span class="line">git <span class="built_in">clone</span> https://huggingface.co/Qwen/Qwen-1_8B-Chat</span><br></pre></td></tr></tbody></table></figure>
<p>æˆ–è€…ä½¿ç”¨<code>huggingface</code>çš„ä¸‹è½½å·¥å…·<code>huggingface-cli</code></p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">pip install -U huggingface_hub</span><br><span class="line"></span><br><span class="line"><span class="comment"># è®¾ç½®é•œåƒåŠ é€Ÿ</span></span><br><span class="line"><span class="comment"># Linux</span></span><br><span class="line"><span class="built_in">export</span> HF_ENDPOINT=<span class="string">"https://hf-mirror.com"</span></span><br><span class="line"><span class="comment"># windows powershell</span></span><br><span class="line"><span class="variable">$env</span>:HF_ENDPOINT=<span class="string">"https://hf-mirror.com"</span></span><br><span class="line"></span><br><span class="line">huggingface-cli download --resume-download Qwen/Qwen-1_8B-Chat --local-dir Qwen/Qwen-1_8B-Chat</span><br></pre></td></tr></tbody></table></figure>
<h3 id="Gemini-Pro"><a href="#Gemini-Pro" class="headerlink" title="Gemini-Pro"></a>Gemini-Pro</h3><p>æ¥è‡ª Google çš„ Gemini-Proï¼Œäº†è§£æ›´å¤šè¯·è®¿é—® <a href="https://deepmind.google/technologies/gemini/">https://deepmind.google/technologies/gemini/</a></p>
<p>è¯·æ±‚ API å¯†é’¥: <a href="https://makersuite.google.com/">https://makersuite.google.com/</a></p>
<h3 id="LLM-æ¨¡å‹é€‰æ‹©"><a href="#LLM-æ¨¡å‹é€‰æ‹©" class="headerlink" title="LLM æ¨¡å‹é€‰æ‹©"></a>LLM æ¨¡å‹é€‰æ‹©</h3><p>åœ¨ app.py æ–‡ä»¶ä¸­ï¼Œè½»æ¾é€‰æ‹©æ‚¨éœ€è¦çš„æ¨¡å‹ã€‚</p>
<figure class="highlight python"><table><tbody><tr><td class="code"><pre><span class="line"><span class="comment"># å–æ¶ˆæ³¨é‡Šå¹¶è®¾ç½®æ‚¨é€‰æ‹©çš„æ¨¡å‹:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># llm = Gemini(model_path='gemini-pro', api_key=None, proxy_url=None) # ä¸è¦å¿˜è®°åŠ å…¥æ‚¨è‡ªå·±çš„ Google API å¯†é’¥</span></span><br><span class="line"><span class="comment"># llm = Qwen(mode='offline', model_path="Qwen/Qwen-1_8B-Chat")</span></span><br><span class="line"><span class="comment"># è‡ªåŠ¨ä¸‹è½½</span></span><br><span class="line"><span class="comment"># llm = Linly(mode='offline', model_path="Linly-AI/Chinese-LLaMA-2-7B-hf")</span></span><br><span class="line"><span class="comment"># æ‰‹åŠ¨ä¸‹è½½åˆ°æŒ‡å®šè·¯å¾„</span></span><br><span class="line">llm = Linly(mode=<span class="string">'offline'</span>, model_path=<span class="string">"Linly-AI/Chinese-LLaMA-2-7B-hf"</span>)</span><br></pre></td></tr></tbody></table></figure>
<h2 id="ä¼˜åŒ–"><a href="#ä¼˜åŒ–" class="headerlink" title="ä¼˜åŒ–"></a>ä¼˜åŒ–</h2><p>ä¸€äº›ä¼˜åŒ–:</p>
<ul>
<li>ä½¿ç”¨å›ºå®šçš„è¾“å…¥äººè„¸å›¾åƒ,æå‰æå–ç‰¹å¾,é¿å…æ¯æ¬¡è¯»å–</li>
<li>ç§»é™¤ä¸å¿…è¦çš„åº“,ç¼©çŸ­æ€»æ—¶é—´</li>
<li>åªä¿å­˜æœ€ç»ˆè§†é¢‘è¾“å‡º,ä¸ä¿å­˜ä¸­é—´ç»“æœ,æé«˜æ€§èƒ½</li>
<li>ä½¿ç”¨OpenCVç”Ÿæˆæœ€ç»ˆè§†é¢‘,æ¯”mimwriteæ›´å¿«</li>
</ul>
<h2 id="Gradio"><a href="#Gradio" class="headerlink" title="Gradio"></a>Gradio</h2><p>Gradioæ˜¯ä¸€ä¸ªPythonåº“,æä¾›äº†ä¸€ç§ç®€å•çš„æ–¹å¼å°†æœºå™¨å­¦ä¹ æ¨¡å‹ä½œä¸ºäº¤äº’å¼Webåº”ç”¨ç¨‹åºæ¥éƒ¨ç½²ã€‚</p>
<p>å¯¹Linly-Talkerè€Œè¨€,ä½¿ç”¨Gradioæœ‰ä¸¤ä¸ªä¸»è¦ç›®çš„:</p>
<ol>
<li><p><strong>å¯è§†åŒ–ä¸æ¼”ç¤º</strong>:Gradioä¸ºæ¨¡å‹æä¾›ä¸€ä¸ªç®€å•çš„Web GUI,ä¸Šä¼ å›¾ç‰‡å’Œæ–‡æœ¬åå¯ä»¥ç›´è§‚åœ°çœ‹åˆ°ç»“æœã€‚è¿™æ˜¯å±•ç¤ºç³»ç»Ÿèƒ½åŠ›çš„æœ‰æ•ˆæ–¹å¼ã€‚</p>
</li>
<li><p><strong>ç”¨æˆ·äº¤äº’</strong>:Gradioçš„GUIå¯ä»¥ä½œä¸ºå‰ç«¯,å…è®¸ç”¨æˆ·ä¸Linly-Talkerè¿›è¡Œäº¤äº’å¯¹è¯ã€‚ç”¨æˆ·å¯ä»¥ä¸Šä¼ è‡ªå·±çš„å›¾ç‰‡å¹¶è¾“å…¥é—®é¢˜,å®æ—¶è·å–å›ç­”ã€‚è¿™æä¾›äº†æ›´è‡ªç„¶çš„è¯­éŸ³äº¤äº’æ–¹å¼ã€‚</p>
</li>
</ol>
<p>å…·ä½“æ¥è¯´,æˆ‘ä»¬åœ¨app.pyä¸­åˆ›å»ºäº†ä¸€ä¸ªGradioçš„Interface,æ¥æ”¶å›¾ç‰‡å’Œæ–‡æœ¬è¾“å…¥,è°ƒç”¨å‡½æ•°ç”Ÿæˆå›åº”è§†é¢‘,åœ¨GUIä¸­æ˜¾ç¤ºå‡ºæ¥ã€‚è¿™æ ·å°±å®ç°äº†æµè§ˆå™¨äº¤äº’è€Œä¸éœ€è¦ç¼–å†™å¤æ‚çš„å‰ç«¯ã€‚</p>
<p>æ€»ä¹‹,Gradioä¸ºLinly-Talkeræä¾›äº†å¯è§†åŒ–å’Œç”¨æˆ·äº¤äº’çš„æ¥å£,æ˜¯å±•ç¤ºç³»ç»ŸåŠŸèƒ½å’Œè®©æœ€ç»ˆç”¨æˆ·ä½¿ç”¨ç³»ç»Ÿçš„æœ‰æ•ˆé€”å¾„ã€‚</p>
<h2 id="å¯åŠ¨"><a href="#å¯åŠ¨" class="headerlink" title="å¯åŠ¨"></a>å¯åŠ¨</h2><p>ç°åœ¨çš„å¯åŠ¨ä¸€å…±æœ‰å‡ ç§æ¨¡å¼ï¼Œå¯ä»¥é€‰æ‹©ç‰¹å®šçš„åœºæ™¯è¿›è¡Œè®¾ç½®</p>
<p>ç¬¬ä¸€ç§åªæœ‰å›ºå®šäº†äººç‰©é—®ç­”ï¼Œè®¾ç½®å¥½äº†äººç‰©ï¼Œçœå»äº†é¢„å¤„ç†æ—¶é—´</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">python app.py</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://pica.zhimg.com/80/v2-fc37a5490a674e2194b88714d38f986e.png" alt=""></p>
<p>ç¬¬äºŒç§æ˜¯å¯ä»¥ä»»æ„ä¸Šä¼ å›¾ç‰‡è¿›è¡Œå¯¹è¯</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">python app_img.py</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://pic1.zhimg.com/80/v2-7c863c3992beef67953d7ab378be99d9.png" alt=""></p>
<p>ç¬¬ä¸‰ç§æ˜¯åœ¨ç¬¬ä¸€ç§çš„åŸºç¡€ä¸ŠåŠ å…¥äº†å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŠ å…¥äº†å¤šè½®çš„GPTå¯¹è¯</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">python app_multi.py</span><br></pre></td></tr></tbody></table></figure>
<p><img src="https://picx.zhimg.com/80/v2-802165f64f307dd204b04b9725626cd7.png" alt=""></p>
<p>æ–‡ä»¶å¤¹ç»“æ„å¦‚ä¸‹</p>
<p>æƒé‡éƒ¨åˆ†å¯ä»¥ä»è¿™ä¸‹è½½ï¼š<a href="https://pan.baidu.com/s/1eF13O-8wyw4B3MtesctQyg?pwd=linl">Baidu (ç™¾åº¦äº‘ç›˜)</a> (Password: <code>linl</code>)</p>
<figure class="highlight bash"><table><tbody><tr><td class="code"><pre><span class="line">Linly-Talker/ </span><br><span class="line">â”œâ”€â”€ app.py</span><br><span class="line">â”œâ”€â”€ app_img.py</span><br><span class="line">â”œâ”€â”€ utils.py</span><br><span class="line">â”œâ”€â”€ Linly-api.py</span><br><span class="line">â”œâ”€â”€ Linly-api-fast.py</span><br><span class="line">â”œâ”€â”€ Linly-example.ipynb</span><br><span class="line">â”œâ”€â”€ README.md</span><br><span class="line">â”œâ”€â”€ README_zh.md</span><br><span class="line">â”œâ”€â”€ request-Linly-api.py</span><br><span class="line">â”œâ”€â”€ requirements_app.txt</span><br><span class="line">â”œâ”€â”€ scripts</span><br><span class="line">â”‚   â””â”€â”€ download_models.sh</span><br><span class="line">â”œâ”€â”€	src</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ audio2exp_models</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ audio2pose_models</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ config</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ cost_time.py</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ face3d</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ facerender</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ generate_batch.py</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ generate_facerender_batch.py</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ Record.py</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ test_audio2coeff.py</span><br><span class="line">â”‚&nbsp;&nbsp; â””â”€â”€ utils</span><br><span class="line">â”œâ”€â”€ inputs</span><br><span class="line">â”‚   â”œâ”€â”€ example.png</span><br><span class="line">â”‚   â””â”€â”€ first_frame_dir</span><br><span class="line">â”‚       â”œâ”€â”€ example_landmarks.txt</span><br><span class="line">â”‚       â”œâ”€â”€ example.mat</span><br><span class="line">â”‚       â””â”€â”€ example.png</span><br><span class="line">â”œâ”€â”€ examples</span><br><span class="line">â”‚   â””â”€â”€ source_image</span><br><span class="line">â”‚       â”œâ”€â”€ art_0.png</span><br><span class="line">â”‚       â”œâ”€â”€ ......</span><br><span class="line">â”‚       â””â”€â”€ sad.png</span><br><span class="line">â”œâ”€â”€ TFG</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ __init__.py</span><br><span class="line">â”‚&nbsp;  â”œâ”€â”€ Wav2Lip.py</span><br><span class="line">â”‚&nbsp;&nbsp; â””â”€â”€ SadTalker.py</span><br><span class="line">â””â”€â”€ TTS</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ __init__.py</span><br><span class="line">â”‚&nbsp;  â”œâ”€â”€ EdgeTTS.py</span><br><span class="line">â”‚&nbsp;  â””â”€â”€ TTS_app.py</span><br><span class="line">â”œâ”€â”€ ASR</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ __init__.py</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ FunASR.py</span><br><span class="line">â”‚&nbsp;&nbsp; â””â”€â”€ Whisper.py</span><br><span class="line">â”œâ”€â”€ LLM</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ __init__.py</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ Gemini.py</span><br><span class="line">â”‚&nbsp;&nbsp; â”œâ”€â”€ Linly.py</span><br><span class="line">â”‚&nbsp;&nbsp; â””â”€â”€ Qwen.py</span><br><span class="line">....... // ä»¥ä¸‹æ˜¯éœ€è¦ä¸‹è½½çš„æƒé‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰</span><br><span class="line">â”œâ”€â”€ checkpoints // SadTalker æƒé‡è·¯å¾„</span><br><span class="line">â”‚   â”œâ”€â”€ mapping_00109-model.pth.tar</span><br><span class="line">â”‚   â”œâ”€â”€ mapping_00229-model.pth.tar</span><br><span class="line">â”‚   â”œâ”€â”€ SadTalker_V0.0.2_256.safetensors</span><br><span class="line">â”‚   â””â”€â”€ SadTalker_V0.0.2_512.safetensors</span><br><span class="line">â”‚   â”œâ”€â”€ lipsync_expert.pth</span><br><span class="line">â”‚   â”œâ”€â”€ visual_quality_disc.pth</span><br><span class="line">â”‚   â”œâ”€â”€ wav2lip_gan.pth</span><br><span class="line">â”‚   â””â”€â”€ wav2lip.pth // Wav2Lip æƒé‡é™†å†›</span><br><span class="line">â”œâ”€â”€ gfpgan // GFPGAN æƒé‡è·¯å¾„</span><br><span class="line">â”‚   â””â”€â”€ weights</span><br><span class="line">â”‚       â”œâ”€â”€ alignment_WFLW_4HG.pth</span><br><span class="line">â”‚       â””â”€â”€ detection_Resnet50_Final.pth</span><br><span class="line">â”œâ”€â”€ Linly-AI // Linly æƒé‡è·¯å¾„</span><br><span class="line">â”‚   â””â”€â”€ Chinese-LLaMA-2-7B-hf </span><br><span class="line">â”‚       â”œâ”€â”€ config.json</span><br><span class="line">â”‚       â”œâ”€â”€ generation_config.json</span><br><span class="line">â”‚       â”œâ”€â”€ pytorch_model-00001-of-00002.bin</span><br><span class="line">â”‚       â”œâ”€â”€ pytorch_model-00002-of-00002.bin</span><br><span class="line">â”‚       â”œâ”€â”€ pytorch_model.bin.index.json</span><br><span class="line">â”‚       â”œâ”€â”€ README.md</span><br><span class="line">â”‚       â”œâ”€â”€ special_tokens_map.json</span><br><span class="line">â”‚       â”œâ”€â”€ tokenizer_config.json</span><br><span class="line">â”‚       â””â”€â”€ tokenizer.model</span><br><span class="line">â”œâ”€â”€ Qwen // Qwen æƒé‡è·¯å¾„</span><br><span class="line">â”‚   â””â”€â”€ Qwen-1_8B-Chat</span><br><span class="line">â”‚       â”œâ”€â”€ cache_autogptq_cuda_256.cpp</span><br><span class="line">â”‚       â”œâ”€â”€ cache_autogptq_cuda_kernel_256.cu</span><br><span class="line">â”‚       â”œâ”€â”€ config.json</span><br><span class="line">â”‚       â”œâ”€â”€ configuration_qwen.py</span><br><span class="line">â”‚       â”œâ”€â”€ cpp_kernels.py</span><br><span class="line">â”‚       â”œâ”€â”€ examples</span><br><span class="line">â”‚       â”‚   â””â”€â”€ react_prompt.md</span><br><span class="line">â”‚       â”œâ”€â”€ generation_config.json</span><br><span class="line">â”‚       â”œâ”€â”€ LICENSE</span><br><span class="line">â”‚       â”œâ”€â”€ model-00001-of-00002.safetensors</span><br><span class="line">â”‚       â”œâ”€â”€ model-00002-of-00002.safetensors</span><br><span class="line">â”‚       â”œâ”€â”€ modeling_qwen.py</span><br><span class="line">â”‚       â”œâ”€â”€ model.safetensors.index.json</span><br><span class="line">â”‚       â”œâ”€â”€ NOTICE</span><br><span class="line">â”‚       â”œâ”€â”€ qwen_generation_utils.py</span><br><span class="line">â”‚       â”œâ”€â”€ qwen.tiktoken</span><br><span class="line">â”‚       â”œâ”€â”€ README.md</span><br><span class="line">â”‚       â”œâ”€â”€ tokenization_qwen.py</span><br><span class="line">â”‚       â””â”€â”€ tokenizer_config.json</span><br></pre></td></tr></tbody></table></figure>
<h2 id="å‚è€ƒ"><a href="#å‚è€ƒ" class="headerlink" title="å‚è€ƒ"></a>å‚è€ƒ</h2><ul>
<li><a href="https://github.com/openai/whisper">https://github.com/openai/whisper</a></li>
<li><a href="https://github.com/rany2/edge-tts">https://github.com/rany2/edge-tts</a>  </li>
<li><a href="https://github.com/CVI-SZU/Linly">https://github.com/CVI-SZU/Linly</a></li>
<li><a href="https://github.com/QwenLM/Qwen">https://github.com/QwenLM/Qwen</a></li>
<li><a href="https://deepmind.google/technologies/gemini/">https://deepmind.google/technologies/gemini/</a></li>
<li><a href="https://github.com/OpenTalker/SadTalker">https://github.com/OpenTalker/SadTalker</a></li>
</ul>
<h2 id="Star-History"><a href="#Star-History" class="headerlink" title="Star History"></a>Star History</h2><p><a href="https://star-history.com/#Kedreamix/Linly-Talker&amp;Date"><img src="https://api.star-history.com/svg?repos=Kedreamix/Linly-Talker&amp;type=Date" alt="Star History Chart"></a></p>
]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>SyncTalkå®éªŒç¬”è®°</title>
    <url>/2024/03/18/Project/SyncTalk/</url>
    <content><![CDATA[<p><img src="https://picx.zhimg.com/v2-03605cd4fbd659c9d341840c64fd3b41.png" alt="synctalk"></p>
<h2 id="Face-Sync-Controller"><a href="#Face-Sync-Controller" class="headerlink" title="Face-Sync Controller"></a>Face-Sync Controller</h2><h3 id="Facial-Animation-Capturer"><a href="#Facial-Animation-Capturer" class="headerlink" title="Facial Animation Capturer"></a>Facial Animation Capturer</h3><p>Blendshapeçš„æå–å¯å‚è€ƒ </p>
<p><a href="https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/face_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Face_Landmarker.ipynb">https://colab.research.google.com/github/googlesamples/mediapipe/blob/main/examples/face_landmarker/python/%5BMediaPipe_Python_Tasks%5D_Face_Landmarker.ipynb</a></p>
<p><img src="https://picx.zhimg.com/v2-2498ec39938d865073b5cbaae63fdef9.png" alt=""></p>
<p><img src="https://picx.zhimg.com/v2-8392dcadaf5221c5298ed49baeac28a9.png" alt=""></p>
<h2 id="Head-Sync-Stabilizer"><a href="#Head-Sync-Stabilizer" class="headerlink" title="Head-Sync Stabilizer"></a>Head-Sync Stabilizer</h2><p><strong>Head Motion Tracker</strong></p>
<p>å¤´éƒ¨å§¿åŠ¿ï¼Œè¡¨ç¤ºä¸º pï¼Œæ˜¯æŒ‡äººçš„å¤´éƒ¨åœ¨ 3D ç©ºé—´ä¸­çš„æ—‹è½¬è§’åº¦ï¼Œç”±æ—‹è½¬ R å’Œå¹³ç§» T å®šä¹‰ã€‚</p>
<p>ä¸ç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ä¼šå¯¼è‡´å¤´éƒ¨æŠ–åŠ¨ï¼Œæ‰€ä»¥ä¸ºäº†è·å¾—å¤´éƒ¨å§¿åŠ¿çš„ç²—ç•¥ä¼°è®¡ã€‚é¦–å…ˆï¼Œé€šè¿‡åœ¨é¢„å®šèŒƒå›´å†…è¿­ä»£ i æ¬¡æ¥ç¡®å®šæœ€ä½³ç„¦è·ï¼Œå¯¹äºæ¯ä¸ªç„¦è·å€™é€‰ fiï¼Œé‡æ–°åˆå§‹åŒ–æ—‹è½¬å’Œå¹³ç§»å€¼ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ– 3D å¯å˜å½¢æ¨¡å‹ (3DMM) çš„æŠ•å½±åœ°æ ‡ä¸è§†é¢‘å¸§ä¸­çš„å®é™…åœ°æ ‡ä¹‹é—´çš„è¯¯å·®ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-cd96b85183a33c3b785c76d15344f433.png" alt="image-20240318205920014"></p>
<p>å…¶ä¸­ $E_i$ è¡¨ç¤ºçš„å°±æ˜¯ MSEï¼Œè¿™æ ·èƒ½å¤Ÿä»¥æ›´å¥½åœ°å°†æ¨¡å‹çš„æŠ•å½± lmk ä¸å®é™…è§†é¢‘ lmk å¯¹é½ï¼Œç„¶åå¾—åˆ°æœ€ä¼˜çš„æ—‹è½¬å’Œå¹³ç§»çŸ©é˜µï¼Œä¹Ÿæ˜¯ç”¨ MSE æ¥æœ€å°åŒ–ï¼Œè¿™æ˜¯å¯¹æ¯ä¸€å¸§è¿›è¡Œæ“ä½œçš„ï¼Œåœ¨å¯¹åº”è§†é¢‘å¸§çš„æœ€ä¼˜å€¼ã€‚</p>
<p><img src="https://picx.zhimg.com/v2-279c71feaa74b2e765d97c881e4da608.png" alt="image-20240318211905521"></p>
<p>è¿™ä¸€éƒ¨åˆ†å®é™…ä¸Šå’ŒåŸæ¥çš„ä»£ç å·®åˆ«ä¸å¤§ï¼Œå¯ä»¥è°ƒæ•´ä¸€ä¸‹æ‰€æœ‰å¸§å’Œå¯¹åº”çš„ä¼˜åŒ–éƒ¨åˆ†ï¼Œæ¯”å¦‚600~1500çš„æ­¥é•¿å¯ä»¥è®¾ç½®ä¸º50ï¼ŒåŸæœ¬æ˜¯100ï¼Œå› ä¸ºç»“æœä¹Ÿå‘ç°æ˜¯1350</p>
<p><img src="https://pic1.zhimg.com/v2-fe6fb504cb27b75a3ca8641c715629b5.png" alt=""></p>
<p><strong>Head Points Tracker</strong></p>
<p>å¯¹äºä¹‹å‰åŸºäº NeRF çš„æ–¹æ³•æ¥è¯´ï¼Œå…ˆå‰çš„æ–¹æ³•åˆ©ç”¨åŸºäº 3DMM çš„æŠ€æœ¯æ¥æå–å¤´éƒ¨å§¿åŠ¿å¹¶ç”Ÿæˆä¸å‡†ç¡®çš„ç»“æœã€‚ä¸ºäº†æé«˜ R å’Œ T çš„ç²¾åº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨åƒ <a href="https://arxiv.org/html/2307.07635v2">Co- tracker</a> è¿™æ ·çš„å…‰æµä¼°è®¡æ¨¡å‹æ¥è·Ÿè¸ªé¢éƒ¨å…³é”®ç‚¹ Kã€‚</p>
<p><img src="https://pica.zhimg.com/v2-1a4d6600883ddfe2e4438913f829716a.png" alt=""></p>
<p>æ¥ä¸‹æ¥ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„å…‰æµä¼°è®¡æ¨¡å‹ï¼Œåœ¨è·å–é¢éƒ¨è¿åŠ¨å…‰æµåï¼Œæˆ‘ä»¬ä½¿ç”¨<strong>æ‹‰æ™®æ‹‰æ–¯æ»¤æ³¢å™¨</strong>é€‰æ‹©ä½äºæœ€æ˜¾è‘—æµå˜åŒ–ä½ç½®çš„å…³é”®ç‚¹ï¼Œå¹¶åœ¨æµåºåˆ—ä¸­è·Ÿè¸ªè¿™äº›å…³é”®ç‚¹çš„è¿åŠ¨è½¨è¿¹ã€‚é€šè¿‡è¿™ä¸ªæ¨¡å—ç¡®ä¿äº†æ‰€æœ‰å¸§ä¸Šçš„é¢éƒ¨å…³é”®ç‚¹å¯¹é½æ›´åŠ ç²¾ç¡®å’Œä¸€è‡´ï¼Œä»è€Œå¢å¼ºäº†å¤´éƒ¨å§¿åŠ¿å‚æ•°çš„å‡†ç¡®æ€§ã€‚</p>
<p><img src="https://pica.zhimg.com/v2-b089529e446c0280c4d3da5c08770f64.png" alt=""></p>
<p><strong>Bundle Adjustment</strong></p>
<p>æ ¹æ®å…³é”®ç‚¹å’Œç²—ç•¥çš„å¤´éƒ¨å§¿åŠ¿ï¼Œå¼•å…¥äº†ä¸€ä¸ªä¸¤é˜¶æ®µä¼˜åŒ–æ¡†æ¶æ¥æé«˜å…³é”®ç‚¹å’Œå¤´éƒ¨å§¿åŠ¿ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</p>
<ul>
<li>ç¬¬ä¸€é˜¶æ®µï¼Œéšæœºåˆå§‹åŒ– j ä¸ªå…³é”®ç‚¹çš„ 3D åæ ‡å¹¶ä¼˜åŒ–å®ƒä»¬çš„ä½ç½®ï¼Œä»¥ä¾¿ä¸å›¾åƒå¹³é¢ä¸Šè·Ÿè¸ªçš„å…³é”®ç‚¹å¯¹é½ã€‚è¿™ä¸€éƒ¨åˆ†æœ€å°åŒ–æŸå¤±å‡½æ•° $L_{init}$ï¼Œæ•è·<strong>æŠ•å½±å…³é”®ç‚¹ P å’Œè·Ÿè¸ªå…³é”®ç‚¹ K</strong> ä¹‹é—´çš„å·®å¼‚ï¼š</li>
<li>ç¬¬äºŒé˜¶æ®µï¼Œå¼€å§‹è¿›è¡Œæ›´å…¨é¢çš„ä¼˜åŒ–ï¼Œä»¥ç»†åŒ– 3D å…³é”®ç‚¹å’Œç›¸å…³çš„å¤´éƒ¨è”åˆå§¿åŠ¿å‚æ•°ï¼Œé€šè¿‡ Adam ä¼˜åŒ–å™¨ä¼˜åŒ–ç®—æ³•ï¼Œ<strong>è°ƒæ•´ç©ºé—´åæ ‡ã€æ—‹è½¬è§’åº¦ R å’Œå¹³ç§» T</strong> ä»¥æœ€å°åŒ–å¯¹é½è¯¯å·® $L_{sec}$ï¼Œè¡¨ç¤ºä¸ºï¼š</li>
</ul>
<p>ç»è¿‡è¿™äº›ä¼˜åŒ–åï¼Œè§‚å¯Ÿåˆ°æ‰€å¾—çš„å¤´éƒ¨å§¿åŠ¿å’Œå¹³ç§»å‚æ•°å¹³æ»‘ä¸”ç¨³å®šã€‚</p>
<h2 id="Portrait-Sync-Generator"><a href="#Portrait-Sync-Generator" class="headerlink" title="Portrait-Sync Generator"></a>Portrait-Sync Generator</h2><p>ä»£ç æ”¹è¿›ä¸€å…±åªæœ‰å‡ éƒ¨åˆ†</p>
<p><img src="https://pic1.zhimg.com/v2-8241e1d748ca0b674e3913714b0e0386.png" alt=""></p>
<p>åœ¨æ•°æ®è¯»å–çš„æ—¶å€™ï¼ŒåŠ äº†face_maskçš„è¯»å–ï¼Œä»¥åŠbg_imageçš„è¯»å–ï¼Œä¹Ÿå°±æ˜¯GT Imageçš„è¯»å–ï¼Œå¯¹äºGT Imageæ¥è¯´ï¼Œæ˜¯é€šè¿‡parsingå»å‡ºå¯¹åº”éƒ¨åˆ†æ¥è¿›è¡Œæ“ä½œçš„ï¼Œä»ä¸‹å›¾ä¹Ÿå¯ä»¥çœ‹å‡ºåŒºåˆ«ï¼Œä¹Ÿå°±æ˜¯æœ‰æ— å¤´å‘ä¸çš„ç»†èŠ‚éƒ¨åˆ†</p>
<p><img src="https://pica.zhimg.com/v2-3866dff2d07194c235eefab923f694c5.png" alt=""></p>
<p>æŒ‡æ ‡å¯èƒ½æœ‰ä¸¤ä¸ªGTï¼Œå› ä¸ºä¸¤ç§æ¨¡å¼ä¸‹ï¼Œå¯¹åº”çš„è®¡ç®—æŒ‡æ ‡æ˜¯ä¸åŒçš„</p>
<p><img src="https://picx.zhimg.com/v2-e5cec8d19e131745028e5a3fe71c3684.png" alt=""></p>
<p>é—®äº†ä¸€ä¸‹ä½œè€…ï¼Œå¤§æ¦‚æ›´æ˜ç™½äº†è¿™ä¸ªçš„æ„æ€ï¼Œå…¶å®æœ¬è´¨ä¸Šæ˜¯ä½¿ç”¨äº†åŸå›¾çš„å¤´å‘ä¸çš„ç»†èŠ‚åŠ å…¥åˆ°å›¾åƒä¸­ï¼Œä½¿å¾—å›¾åƒèƒ½å¤Ÿå¾—åˆ°æ›´å¥½çš„ç»“æœï¼Œç„¶åå†è¿›è¡Œç»“åˆå¾—åˆ°æ›´å¥½çš„æ•ˆæœã€‚</p>
<p><img src="https://picx.zhimg.com/v2-e59f49fdcbc728e0222376e2a987d73b.png" alt=""></p>
]]></content>
      <categories>
        <category>Project</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>è¶…èµçš„æ•°å­—äººç”ŸæˆçŸ¥è¯†åº“  Awesome-Talking-Head-Synthesis</title>
    <url>/2024/01/01/Paper/Awesome-Talking-Head-Synthesis/</url>
    <content><![CDATA[<p>Gihubï¼š<a href="https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis">https://github.com/Kedreamix/Awesome-Talking-Head-Synthesis</a></p>
<p>è¿™ä»½èµ„æºåº“æ•´ç†äº†ä¸ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)å’Œç¥ç»è¾å°„åœº(NeRF)ç›¸å…³çš„è®ºæ–‡ã€ä»£ç å’Œèµ„æº,é‡ç‚¹å…³æ³¨åŸºäºå›¾åƒå’ŒéŸ³é¢‘çš„è™šæ‹Ÿè®²è¯å¤´åˆæˆè®ºæ–‡åŠå·²å‘å¸ƒä»£ç ã€‚</p>
<p>è®ºæ–‡åˆé›†åŠå‘å¸ƒä»£ç æ•´ç†ã€‚âœï¸</p>
<p>å¤§å¤šæ•°è®ºæ–‡é“¾æ¥åˆ°â€œarXivâ€æˆ–å­¦æœ¯ä¼šè®®/æœŸåˆŠçš„PDFã€‚ä½†æ˜¯,ä¸€äº›è®ºæ–‡å¯èƒ½éœ€è¦å­¦æœ¯è®¸å¯æ‰èƒ½æŸ¥çœ‹ã€‚</p>
<p>è¿™ä¸ªAwesome Talking Head Synthesisé¡¹ç›®å°†æŒç»­æ›´æ–° - æ¬¢è¿Pull Requestã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•è®ºæ–‡ç¼ºå¤±ã€æ–°å¢è®ºæ–‡ã€å…³é”®ç ”ç©¶äººå‘˜æˆ–é”™åˆ«å­—å»ºè®®,è¯·ç¼–è¾‘æäº¤PRã€‚æ‚¨ä¹Ÿå¯ä»¥æ‰“å¼€Issueæˆ–ç›´æ¥é€šè¿‡ç”µå­é‚®ä»¶è”ç³»æˆ‘ã€‚</p>
<p>å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªä»“åº“æœ‰ç”¨,è¯·starâ­æ”¯æŒ!</p>
<p><strong>2023å¹´12æœˆæ›´æ–° ğŸ“†</strong></p>
<p>æ„Ÿè°¢<a href="https://github.com/Curated-Awesome-Lists/awesome-ai-talking-heads">https://github.com/Curated-Awesome-Lists/awesome-ai-talking-heads</a>, æˆ‘å¢åŠ äº†ä¸€äº›å…¶å†…å®¹,ä¾‹å¦‚Tools&amp;Softwareå’ŒSlides&amp;Presentationsæ¨¡å—ã€‚ å¸Œæœ›è¿™å¯¹æ‚¨æœ‰å¸®åŠ©ã€‚</p>
<p>å¦‚æœæ‚¨å¯¹æ‰©å±•è¿™ä¸ªèšåˆèµ„æºæœ‰ä»»ä½•æƒ³æ³•æˆ–åé¦ˆ,è¯·æ‰“å¼€Issueæˆ–PRâ€”â€”ç¤¾åŒºè´¡çŒ®å¯¹æ¨è¿›æˆ‘ä»¬å…±åŒçš„çŸ¥è¯†è‡³å…³é‡è¦ã€‚</p>
<p>è®©æˆ‘ä»¬ç»§ç»­åŠªåŠ›,å®ç°æ›´é€¼çœŸçš„æ•°å­—äººè„¸è¡¨ç°!æˆ‘ä»¬å·²ç»èµ°äº†å¾ˆé•¿ä¸€æ®µè·¯,ä½†è¿˜æœ‰å¾ˆé•¿çš„è·¯è¦èµ°ã€‚é€šè¿‡æŒç»­çš„ç ”ç©¶å’Œåˆä½œ,æˆ‘ç›¸ä¿¡æˆ‘ä»¬ä¸€å®šä¼šè¾¾åˆ°ç›®æ ‡!</p>
<p>å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªä»“åº“å¾ˆæœ‰ä»·å€¼,è¯·starâ­å¹¶åˆ†äº«ç»™ä»–äººã€‚æ‚¨çš„æ”¯æŒå¯ä»¥æ¿€åŠ±æˆ‘æŒç»­æ”¹è¿›å’Œç»´æŠ¤å®ƒã€‚å¦‚æœæ‚¨è¿˜æœ‰ä»»ä½•å…¶ä»–é—®é¢˜,è¯·å‘Šè¯‰æˆ‘!</p>
<p>This repository organizes papers, codes and resources related to generative adversarial networks (GANs) ğŸ¤— and neural radiance fields (NeRF) ğŸ¨, with a main focus on image-driven and audio-driven talking head synthesis papers and released codes. ğŸ‘¤</p>
<p>Papers for Talking Head Synthesis, released codes collections. âœï¸</p>
<p>Most papers are linked to PDFs on â€œarXivâ€ or journal/conference websites ğŸ“š. However, some papers require an academic license to view ğŸ”.</p>
<p>ğŸ”† This project Awesome-Talking-Head-Synthesis is ongoing - pull requests are welcome! If you have any suggestions (missing papers, new papers, key researchers or typos), please feel free to edit and submit a PR. You can also open an issue or contact me directly via email. ğŸ“©</p>
<p>â­ If you find this repo useful, please give it a star! ğŸ¤©</p>
<p><strong>2023.12 Update</strong> ğŸ“†</p>
<p>Thank you to <a href="https://github.com/Curated-Awesome-Lists/awesome-ai-talking-heads">https://github.com/Curated-Awesome-Lists/awesome-ai-talking-heads</a>, I have added some of its contents, such as <code>Tools &amp; Software</code> and <code>Slides &amp; Presentations</code>. ğŸ™ I hope this will be helpful.ğŸ˜Š</p>
<p>If you have any feedback or ideas on extending this aggregated resource, please open an issue or PR - community contributions are vital to advancing this shared knowledge. ğŸ¤</p>
<p>Letâ€™s keep pushing forward to recreate ever more realistic digital human faces! ğŸ’ª Weâ€™ve come so far but still have a long way to go. With continued research ğŸ”¬ and collaboration, Iâ€™m sure weâ€™ll get there! ğŸ¤—</p>
<p>Please feel free to star â­ and share this repo if you find it a valuable resource. Your support helps motivate me to keep maintaining and improving it. ğŸ¥° Let me know if you have any other questions!</p>
<h2 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h2><p><img src="https://img-blog.csdnimg.cn/direct/841257d9dee74547bbd4f717794a9492.png#pic_center" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Dataset</th>
<th>Download Link</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Faceforensics++</td>
<td><a href="https://github.com/ondyari/FaceForensics">Download link</a></td>
<td></td>
</tr>
<tr>
<td>CelebV</td>
<td><a href="https://drive.google.com/file/d/1jQ6d76T5GQuvQH4dq8_Wq1T0cxvN0_xp/view">Download link</a></td>
<td></td>
</tr>
<tr>
<td>VoxCeleb</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/voxceleb/">Download link</a></td>
<td><code>VoxCeleb</code>, a comprehensive audio-visual dataset for speaker recognition, encompasses both VoxCeleb1 and VoxCeleb2 datasets.</td>
</tr>
<tr>
<td>VoxCeleb1</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1.html">Download link</a></td>
<td><code>VoxCeleb1</code> contains over 100,000 utterances for 1,251 celebrities, extracted from videos uploaded to YouTube.</td>
</tr>
<tr>
<td>VoxCeleb2</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html">Download link</a></td>
<td>Extracted from YouTube videos, VoxCeleb2 includes video URLs and discourse timestamps. As the largest public audio-visual dataset, it is primarily used for speaker recognition tasks. However, it can also be utilized for training talking-head generation models. To obtain download permission and access the dataset, apply <a href="https://www.robots.ox.ac.uk/~vgg/data/voxceleb/">here</a>. Requires 300 GB+ storage space.</td>
</tr>
<tr>
<td>ObamaSet</td>
<td><a href="https://github.com/supasorn/synthesizing_obama_network_training">Download link</a></td>
<td><code>ObamaSet</code> is a specialized audio-visual dataset focused on analyzing the visual speech of former US President Barack Obama. All video samples are collected from his weekly address footage. Unlike previous datasets, it exclusively centers on Barack Obama and does not provide any human annotations.</td>
</tr>
<tr>
<td>TalkingHead-1KH</td>
<td><a href="https://github.com/tcwang0509/TalkingHead-1KH">Download link</a></td>
<td>The dataset consists of 500k video clips, of which about 80k are greater than 512x512 resolution. Only videos under permissive licenses are included. Note that the number of videos differ from that in the original paper because a more robust preprocessing script was used to split the videos.</td>
</tr>
<tr>
<td>LRW (Lip Reading in the Wild)</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrw1.html">Download link</a></td>
<td>LRW, a diverse English-speaking video dataset from the BBC program, features over 1000 speakers with various speaking styles and head poses. Each video is 1.16 seconds long (29 frames) and involves the target word along with context.</td>
</tr>
<tr>
<td>MEAD 2020</td>
<td><a href="https://github.com/uniBruce/Mead">Download link</a></td>
<td>MEAD 2020 is a Talking Head dataset annotated with emotion labels and intensity labels. The dataset focuses on facial generation for natural emotional speech, covering eight different emotions on three intensity levels.</td>
</tr>
<tr>
<td>CelebV-HQ</td>
<td><a href="https://github.com/CelebV-HQ/CelebV-HQ">Download link</a></td>
<td>CelebV-HQ is a high-quality video dataset comprising 35,666 clips with a resolution of at least 512x512. It includes 15,653 identities, and each clip is manually labeled with 83 facial attributes, spanning appearance, action, and emotion. The datasetâ€™s diversity and temporal coherence make it a valuable resource for tasks like unconditional video generation and video facial attribute editing.</td>
</tr>
<tr>
<td>HDTF</td>
<td><a href="https://github.com/MRzzm/HDTF">Download link</a></td>
<td>HDTF, the High-definition Talking-Face Dataset, is a large in-the-wild high-resolution audio-visual dataset consisting of approximately 362 different videos totaling 15.8 hours. Original video resolutions are 720 P or 1080 P, and each cropped video is resized to 512 Ã— 512.</td>
</tr>
<tr>
<td>CREMA-D</td>
<td><a href="https://github.com/CheyneyComputerScience/CREMA-D">Download link</a></td>
<td>CREMA-D is a diverse dataset with 7,442 original clips featuring 91 actors, including 48 male and 43 female actors aged 20 to 74, representing various races and ethnicities. The dataset includes recordings of actors speaking from a set of 12 sentences, expressing six different emotions (Anger, Disgust, Fear, Happy, Neutral, and Sad) at four emotion levels (Low, Medium, High, and Unspecified). Emotion and intensity ratings were gathered through crowd-sourcing, with 2,443 participants rating 90 unique clips each (30 audio, 30 visual, and 30 audio-visual). Over 95% of the clips have more than 7 ratings. For additional details on CREMA-D, refer to the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4313618/">paper link</a>.</td>
</tr>
<tr>
<td>LRS2</td>
<td><a href="https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs2.html">Download link</a></td>
<td>LRS2 is a lip reading dataset that includes videos recorded in diverse settings, suitable for studying lip reading and visual speech recognition.</td>
</tr>
<tr>
<td>GRID</td>
<td><a href="http://spandh.dcs.shef.ac.uk/avlombard/">Download link</a></td>
<td>The GRID dataset was recorded in a laboratory setting with 34 volunteers, each speaking 1000 phrases, totaling 34,000 utterance instances. Phrases follow specific rules, with six words randomly selected from six categories: â€œcommand,â€ â€œcolor,â€ â€œpreposition,â€ â€œletter,â€ â€œnumber,â€ and â€œadverb.â€ Access the dataset <a href="https://spandh.dcs.shef.ac.uk/gridcorpus/">here</a>.</td>
</tr>
<tr>
<td>SAVEE</td>
<td><a href="http://kahlan.eps.surrey.ac.uk/savee/Download.html">Download link</a></td>
<td>The SAVEE (Surrey Audio-Visual Expressed Emotion) database is a crucial component for developing an automatic emotion recognition system. It features recordings from 4 male actors expressing 7 different emotions, totaling 480 British English utterances. These sentences, selected from the standard TIMIT corpus, are phonetically balanced for each emotion. Recorded in a high-quality visual media lab, the data undergoes processing and labeling. Performance evaluation involves 10 subjects rating recordings under audio, visual, and audio-visual conditions. Classification systems for each modality achieve speaker-independent recognition rates of 61%, 65%, and 84% for audio, visual, and audio-visual, respectively.</td>
</tr>
<tr>
<td>BIWI(3D)</td>
<td><a href="https://data.vision.ee.ethz.ch/cvl/datasets/b3dac2.en.html">Download link</a></td>
<td>The Biwi 3D Audiovisual Corpus of Affective Communication serves as a compromise between data authenticity and quality, acquired at ETHZ in collaboration with SYNVO GmbH.</td>
</tr>
<tr>
<td>VOCA</td>
<td><a href="https://voca.is.tue.mpg.de/">Download link</a></td>
<td>VOCA is a 4D-face dataset with approximately 29 minutes of 4D face scans and synchronized audio from 12-bit speakers. It greatly facilitates research in 3D VSG.</td>
</tr>
<tr>
<td>Multiface(3D)</td>
<td><a href="https://github.com/facebookresearch/multiface">Download link</a></td>
<td>The Multiface Dataset consists of high-quality multi-view video recordings of 13 people displaying various facial expressions. It contains approximately 12,200 to 23,000 frames per subject, captured at 30 fps from around 40 to 160 camera views with uniform lighting. The datasetâ€™s size is 65TB and includes raw images (2048x1334 resolution), tracked and meshed heads, 1024x1024 unwrapped face textures, camera calibration metadata, and audio. This repository provides code for downloading the dataset and building a codec avatar using a deep appearance model.</td>
</tr>
<tr>
<td>MMFace4D</td>
<td><a href="https://wuhaozhe.github.io/mmface4d/">Download link</a></td>
<td>The MMFace4D dataset is a large-scale multi-modal dataset for audio-driven 3D facial animation research. It contains over 35,000 sequences captured from 431 subjects ranging in age from 15 to 68 years old. Various sentences from scenarios such as news broadcasting, conversations and storytelling were recorded, totaling around 11,000 utterances. High-fidelity data was captured using three synchronized RGB-D cameras to obtain high-resolution 3D meshes and textures. A reconstruction pipeline was developed to fuse the multi-view data and generate topology-consistent 3D mesh sequences. In addition to the 3D facial motions, synchronized speech audio is also provided. The final dataset covers a wide range of expressive talking styles and facial expressions through a diverse set of subjects and utterances. With its large scale, high quality of data and strong diversity, the MMFace4D dataset provides an ideal benchmark for developing and evaluating audio-driven 3D facial animation models.</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="Survey"><a href="#Survey" class="headerlink" title="Survey"></a>Survey</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Year</th>
<th>Title</th>
<th>Conference/Journal</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td><a href="https://arxiv.org/pdf/2401.03890.pdf">A Survey on 3D Gaussian Splatting</a> 3DGSğŸ”¥ğŸ”¥ğŸ”¥<strong>on going</strong></td>
<td>arXiv 2024</td>
</tr>
<tr>
<td>2024</td>
<td><a href="https://arxiv.org/pdf/2304.10050.pdf">Neural Radiance Fields: Past, Present, and Future</a>  NeRFğŸ”¥ğŸ”¥ğŸ”¥ <strong>Amazing 413 pages</strong></td>
<td>arXiv 2024</td>
</tr>
<tr>
<td>2023</td>
<td><a href="https://arxiv.org/abs/2308.16041">From Pixels to Portraits: A Comprehensive Survey of Talking Head Generation Techniques and Applications</a></td>
<td>arXiv 2023</td>
</tr>
<tr>
<td>2023</td>
<td><a href="https://www.mdpi.com/2079-9292/12/1/218">Human-Computer Interaction System: A Survey of Talking-Head Generation</a></td>
<td>IEEE</td>
</tr>
<tr>
<td>2023</td>
<td><a href="https://dl.acm.org/doi/10.1016/j.eswa.2023.119678">Talking human face generation: A survey</a></td>
<td>ACM</td>
</tr>
<tr>
<td>2022</td>
<td><a href="https://arxiv.org/abs/2205.10839">Deep Learning for Visual Speech Analysis: A Survey</a></td>
<td>arXiv 2022</td>
</tr>
<tr>
<td>2020</td>
<td><a href="https://arxiv.org/abs/2005.03201">What comprises a good talking-head video generation?: A Survey and Benchmark</a></td>
<td>arXiv 2020</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="Funny-Work"><a href="#Funny-Work" class="headerlink" title="Funny Work"></a>Funny Work</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Year</th>
<th>Title</th>
<th>Code</th>
<th>Project</th>
<th>Keywords</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>[Audio2Photoreal] <a href="https://arxiv.org/pdf/2401.01885.pdf">From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations</a></td>
<td><a href="https://github.com/facebookresearch/audio2photoreal/">Code</a></td>
<td><a href="https://people.eecs.berkeley.edu/~evonne_ng/projects/audio2photoreal/#">Project</a></td>
<td>Photoreal</td>
</tr>
<tr>
<td>2024</td>
<td>[Animate Anyone] <a href="https://arxiv.org/pdf/2311.17117.pdf">Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation</a></td>
<td><a href="https://github.com/HumanAIGC/AnimateAnyone">Code</a></td>
<td><a href="https://humanaigc.github.io/animate-anyone/">Project</a></td>
<td>ğŸ”¥Animate (é˜¿é‡Œç§‘ç›®ä¸‰é©±åŠ¨)</td>
</tr>
<tr>
<td>2024</td>
<td>[3DGAN] <a href="https://research.nvidia.com/labs/nxp/wysiwyg/media/WYSIWYG.pdf">What You See Is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs</a></td>
<td></td>
<td><a href="https://research.nvidia.com/labs/nxp/wysiwyg/">Project</a></td>
<td>ğŸ”¥Nvidia</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="Audio-driven"><a href="#Audio-driven" class="headerlink" title="Audio-driven"></a>Audio-driven</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Year</th>
<th>Title</th>
<th>Conference/Journal</th>
<th>Code</th>
<th>Project</th>
<th>Keywords</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>[Real3D-Portrait] <a href="http://arxiv.org/abs/2401.08503v2">Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis</a></td>
<td>ICLR 2024</td>
<td></td>
<td><a href="https://real3dportrait.github.io/">Project</a></td>
<td>3D, One-Shot,Realistic</td>
</tr>
<tr>
<td>2024</td>
<td>[AdaMesh] <a href="http://arxiv.org/abs/2310.07236v2">AdaMesh: Personalized Facial Expressions and Head Poses for Adaptive   Speech-Driven 3D Facial Animation</a></td>
<td>Arix 2024</td>
<td><a href="https://github.com/adamesh/adamesh">Code</a></td>
<td><a href="https://adamesh.github.io">Project</a></td>
<td>3D,Mesh</td>
</tr>
<tr>
<td>2024</td>
<td>[DREAM-Talk] <a href="http://arxiv.org/abs/2312.13578v1">DREAM-Talk: Diffusion-based Realistic Emotional Audio-driven Method for Single Image Talking Face Generation</a></td>
<td>Arix 2024</td>
<td></td>
<td><a href="https://magic-research.github.io/dream-talk/">Project</a></td>
<td>Emotion</td>
</tr>
<tr>
<td>2024</td>
<td>[AE-NeRF] <a href="http://arxiv.org/abs/2312.10921v1">AE-NeRF: Audio Enhanced Neural Radiance Field for Few Shot Talking Head Synthesis</a></td>
<td>AAAI 2024</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>[VectorTalker] <a href="http://arxiv.org/abs/2312.11568v1">VectorTalker: SVG Talking Face Generation with Progressive Vectorisation</a></td>
<td>Arix 2024</td>
<td></td>
<td></td>
<td>SVG</td>
</tr>
<tr>
<td>2024</td>
<td>[VectorTalker] <a href="http://arxiv.org/abs/2312.11568v1">VectorTalker: SVG Talking Face Generation with Progressive Vectorisation</a></td>
<td>Arix 2024</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>[Mimic] <a href="http://arxiv.org/abs/2312.10877v1">Mimic: Speaking Style Disentanglement for Speech-Driven 3D Facial Animation</a></td>
<td>AAAI 2024</td>
<td></td>
<td></td>
<td>3D</td>
</tr>
<tr>
<td>2024</td>
<td>[DreamTalk] <a href="http://arxiv.org/abs/2312.09767v1">DreamTalk: When Expressive Talking Head Generation Meets Diffusion Probabilistic Models</a></td>
<td>Arix 2024</td>
<td><a href="https://github.com/damo-vilab/i2vgen-xl">Code</a></td>
<td><a href="https://dreamtalk-project.github.io">Project</a></td>
<td>Diffusion</td>
</tr>
<tr>
<td>2024</td>
<td>[FaceTalk] <a href="http://arxiv.org/abs/2312.08459v1">FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head Models</a></td>
<td>Arix 2024</td>
<td><a href="https://github.com/shivangi-aneja/FaceTalk">Code</a></td>
<td><a href="https://shivangi-aneja.github.io/projects/facetalk/">Project</a></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>[GSmoothFace] <a href="http://arxiv.org/abs/2312.07385v1">GSmoothFace: Generalized Smooth Talking Face Generation via Fine Grained   3D Face Guidance</a></td>
<td>Arix 2024</td>
<td></td>
<td></td>
<td>3D</td>
</tr>
<tr>
<td>2024</td>
<td>[GMTalker] <a href="http://arxiv.org/abs/2312.07669v1">GMTalker: Gaussian Mixture based Emotional talking video Portraits</a></td>
<td>Arix 2024</td>
<td></td>
<td><a href="https://bob35buaa.github.io/GMTalker">Project</a></td>
<td>Emotion</td>
</tr>
<tr>
<td>2024</td>
<td>[VividTalk] <a href="http://arxiv.org/abs/2312.01841v2">VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D Hybrid Prior</a></td>
<td>Arix 2024</td>
<td></td>
<td></td>
<td>Mesh</td>
</tr>
<tr>
<td>2024</td>
<td>[GAIA] <a href="https://arxiv.org/pdf/2311.15230.pdf">GAIA: Zero-shot Talking Avatar Generation</a></td>
<td>Arix 2024</td>
<td>Code(coming)</td>
<td><a href="https://microsoft.github.io/GAIA/">Project</a></td>
<td>ğŸ˜²ğŸ˜²ğŸ˜²</td>
</tr>
<tr>
<td>2023</td>
<td><a href="https://arxiv.org/abs/2307.10008">Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head Video Generation</a></td>
<td>ICCV 2023</td>
<td><a href="https://github.com/harlanhong/ICCV2023-MCNET">Code</a></td>
<td><a href="https://harlanhong.github.io/publications/mcnet.html">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2023</td>
<td>[ToonTalker] <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Gong_ToonTalker_Cross-Domain_Face_Reenactment_ICCV_2023_paper.pdf">ToonTalker: Cross-Domain Face Reenactment</a></td>
<td>ICCV 2023</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2023</td>
<td><a href="https://arxiv.org/abs/2309.04946">Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation</a></td>
<td>ICCV 2023</td>
<td><a href="https://github.com/yuangan/EAT_code">Code</a></td>
<td><a href="https://yuangan.github.io/eat/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2023</td>
<td>[EMMN] <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Tan_EMMN_Emotional_Motion_Memory_Network_for_Audio-driven_Emotional_Talking_Face_ICCV_2023_paper.pdf">EMMN: Emotional Motion Memory Network for Audio-driven Emotional Talking Face Generation</a></td>
<td>ICCV 2023</td>
<td>-</td>
<td>-</td>
<td>Emotion</td>
</tr>
<tr>
<td>2023</td>
<td><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Emotional_Listener_Portrait_Neural_Listener_Head_Generation_with_Emotion_ICCV_2023_paper.pdf">Emotional Listener Portrait: Realistic Listener Motion Simulation in Conversation</a></td>
<td>ICCV 2023</td>
<td>-</td>
<td>-</td>
<td>Emotion,LHG</td>
</tr>
<tr>
<td>2023</td>
<td>[MODA] <a href="https://arxiv.org/abs/2307.10008">MODA: Mapping-Once Audio-driven Portrait Animation with Dual Attentions</a></td>
<td>ICCV 2023</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2023</td>
<td>[Facediffuser] <a href="https://dl.acm.org/doi/abs/10.1145/3623264.3624447">Facediffuser: Speech-driven 3d facial animation synthesis using diffusion</a></td>
<td>ACM SIGGRAPH MIG 2023</td>
<td><a href="https://github.com/uuembodiedsocialai/FaceDiffuser">Code</a></td>
<td><a href="https://uuembodiedsocialai.github.io/FaceDiffuser/">Project</a></td>
<td>ğŸ”¥Diffusion,3D</td>
</tr>
<tr>
<td>2023</td>
<td><a href="https://arxiv.org/abs/2309.00030">Audio-Driven Dubbing for User Generated Contents via Style-Aware Semi-Parametric Synthesis</a></td>
<td>TCSVT 2023</td>
<td>-</td>
<td>-</td>
<td></td>
</tr>
<tr>
<td>2023</td>
<td>[SadTalker] <a href="https://arxiv.org/pdf/2211.12194.pdf">SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation</a></td>
<td>CVPR 2023</td>
<td><a href="https://github.com/Winfredy/SadTalker">Code</a></td>
<td><a href="https://sadtalker.github.io/">Project</a></td>
<td>3D,Single Image</td>
</tr>
<tr>
<td>2023</td>
<td>[EmoTalk] <a href="https://arxiv.org/abs/2303.11089">EmoTalk: Speech-Driven Emotional Disentanglement for 3D Face Animation</a></td>
<td>ICCV 2023</td>
<td><a href="https://github.com/ZiqiaoPeng/EmoTalk">Code</a></td>
<td></td>
<td>3D,Emotion</td>
</tr>
<tr>
<td>2023</td>
<td><a href="https://arxiv.org/abs/2306.03594">Emotional Talking Head Generation based on Memory-Sharing and Attention-Augmented Networks</a></td>
<td>InterSpeech 2023</td>
<td></td>
<td></td>
<td>Emotion</td>
</tr>
<tr>
<td>2023</td>
<td>[DINet] <a href="https://fuxivirtualhuman.github.io/pdf/AAAI2023_FaceDubbing.pdf">DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video</a></td>
<td>AAAI 2023</td>
<td><a href="https://github.com/MRzzm/DINet">Code</a></td>
<td>-</td>
<td></td>
</tr>
<tr>
<td>2023</td>
<td>[StyleTalk] <a href="https://arxiv.org/abs/2301.01081">StyleTalk: One-shot Talking Head Generation with Controllable Speaking Styles</a></td>
<td>AAAI 2023</td>
<td><a href="https://github.com/FuxiVirtualHuman/styletalk">Code</a></td>
<td>-</td>
<td>Style</td>
</tr>
<tr>
<td>2023</td>
<td><a href="https://arxiv.org/abs/2305.02572">High-fidelity Generalized Emotional Talking Face Generation with Multi-modal Emotion Space Learning</a></td>
<td>CVPR 2023</td>
<td>-</td>
<td>-</td>
<td>Emotion</td>
</tr>
<tr>
<td>2023</td>
<td>[StyleSync] <a href="https://arxiv.org/pdf/2305.05445.pdf">StyleSync: High-Fidelity Generalized and Personalized Lip Sync in Style-based Generator</a></td>
<td>CVPR 2023</td>
<td><a href="https://github.com/guanjz20/StyleSync">Code</a></td>
<td><a href="https://hangz-nju-cuhk.github.io/projects/StyleSync">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2023</td>
<td>[TalkLip] <a href="https://arxiv.org/pdf/2303.17480.pdf">TalkLip: Seeing What You Said - Talking Face Generation Guided by a Lip Reading Expert</a></td>
<td>CVPR 2023</td>
<td><a href="https://github.com/Sxjdwang/TalkLip">Code</a></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2023</td>
<td>[CodeTalker] <a href="https://arxiv.org/abs/2301.02379">CodeTalker: Speech-Driven 3D Facial Animation with Discrete Motion Prior</a></td>
<td>CVPR 2023</td>
<td><a href="https://github.com/Doubiiu/CodeTalker">Code</a></td>
<td><a href="https://doubiiu.github.io/projects/codetalker/">Project</a></td>
<td>3D,codebook</td>
</tr>
<tr>
<td>2023</td>
<td>[EmoGen] <a href="https://arxiv.org/pdf/2303.11548.pdf">Emotionally Enhanced Talking Face Generation</a></td>
<td>Arxiv 2023</td>
<td><a href="https://github.com/sahilg06/EmoGen">Code</a></td>
<td>-</td>
<td>Emotion</td>
</tr>
<tr>
<td>2023</td>
<td>[DAE-Talker] <a href="https://arxiv.org/pdf/2303.17550.pdf">DAE-Talker: High Fidelity Speech-Driven Talking Face Generation with Diffusion Autoencoder</a></td>
<td>Arxiv 2023</td>
<td>-</td>
<td><a href="https://mstypulkowski.github.io/diffusedheads/">Project</a></td>
<td>ğŸ”¥Diffusion</td>
</tr>
<tr>
<td>2023</td>
<td>[READ] <a href="READ Avatars: Realistic Emotion-controllable Audio Driven Avatars">READ Avatars: Realistic Emotion-controllable Audio Driven Avatars</a></td>
<td>Arxiv 2023</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2023</td>
<td>[DiffTalk] <a href="https://arxiv.org/abs/2301.03786">DiffTalk: Crafting Diffusion Models for Generalized Talking Head Synthesis</a></td>
<td>CVPR 2023</td>
<td><a href="https://github.com/sstzal/DiffTalk">Code</a></td>
<td><a href="https://sstzal.github.io/DiffTalk/">Project</a></td>
<td>ğŸ”¥Diffusion</td>
</tr>
<tr>
<td>2023</td>
<td>[Diffused Heads] <a href="https://mstypulkowski.github.io/diffusedheads/diffused_heads.pdf">Diffused Heads: Diffusion Models Beat GANs on Talking-Face Generation</a></td>
<td>Arxiv 2023</td>
<td>-</td>
<td><a href="https://mstypulkowski.github.io/diffusedheads/">Project</a></td>
<td>ğŸ”¥Diffusion</td>
</tr>
<tr>
<td>2022</td>
<td>[MemFace] <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liang_Expressive_Talking_Head_Generation_With_Granular_Audio-Visual_Control_CVPR_2022_paper.pdf">Expressive Talking Head Generation with Granular Audio-Visual Control</a></td>
<td>CVPR 2022</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td><a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Song_Talking_Face_Generation_With_Multilingual_TTS_CVPR_2022_paper.pdf">Talking Face Generation with Multilingual TTS</a></td>
<td>CVPR 2022</td>
<td><a href="https://huggingface.co/spaces/CVPR/ml-talking-face">Demo Track</a></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[EAMM] <a href="https://arxiv.org/pdf/2205.15278.pdf">EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model</a></td>
<td>SIGGRAPH 2022</td>
<td>-</td>
<td>-</td>
<td>Emotion</td>
</tr>
<tr>
<td>2022</td>
<td>[SPACEx] <a href="https://arxiv.org/pdf/2211.09809.pdf">SPACEx ğŸš€: Speech-driven Portrait Animation with Controllable Expression</a></td>
<td>arXiv 2022</td>
<td>-</td>
<td><a href="https://deepimagination.cc/SPACEx/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[AV-CAT] <a href="https://arxiv.org/pdf/2212.04970.pdf">Masked Lip-Sync Prediction by Audio-Visual Contextual Exploitation in Transformers</a></td>
<td>SIGGRAPH Asia 2022</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[MemFace] <a href="https://arxiv.org/pdf/2212.05005.pdf">Memories are One-to-Many Mapping Alleviators in Talking Face Generation</a></td>
<td>arXiv 2022</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2021</td>
<td>[PC-AVS] <a href="https://arxiv.org/abs/2104.11116">PC-AVS: Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation</a></td>
<td>CVPR 2021</td>
<td><a href="https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS">Code</a></td>
<td><a href="https://hangz-nju-cuhk.github.io/projects/PC-AVS">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2021</td>
<td>[IATS] <a href="https://arxiv.org/abs/2111.00203">Imitating Arbitrary Talking Style for Realistic Audio-Driven Talking Face Synthesis</a></td>
<td>ACM MM 2021</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2021</td>
<td>[Speech2Talking-Face] <a href="https://www.ijcai.org/proceedings/2021/0141.pdf">Speech2Talking-Face: Inferring and Driving a Face with Synchronized Audio-Visual Representation</a></td>
<td>IJCAI 2021</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2021</td>
<td>[FAU] <a href="https://arxiv.org/pdf/2110.09951.pdf">Talking Head Generation with Audio and Speech Related Facial Action Units</a></td>
<td>BMVC 2021</td>
<td>-</td>
<td>-</td>
<td>AU</td>
</tr>
<tr>
<td>2021</td>
<td>[EVP] <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ji_Audio-Driven_Emotional_Video_Portraits_CVPR_2021_paper.pdf">Audio-Driven Emotional Video Portraits</a></td>
<td>CVPR 2021</td>
<td><a href="https://github.com/jixinya/EVP">Code</a></td>
<td>-</td>
<td>Emotion</td>
</tr>
<tr>
<td>2021</td>
<td>[IATS] <a href="https://dl.acm.org/doi/pdf/10.1145/3474085.3475280">IATS: Imitating Arbitrary Talking Style for Realistic Audio-Driven Talking Face Synthesis</a></td>
<td>ACM Multimedia 2021</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2020</td>
<td>[Wav2Lip] <a href="http://arxiv.org/pdf/2008.10010.pdf">A Lip Sync Expert Is All You Need for Speech to Lip Generation In The Wild</a></td>
<td>ACM Multimedia 2020</td>
<td><a href="https://github.com/Rudrabha/Wav2Lip">Code</a></td>
<td><a href="http://cvit.iiit.ac.in/research/projects/cvit-projects/a-lip-sync-expert-is-all-you-need-for-speech-to-lip-generation-in-the-wild/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2020</td>
<td>[RhythmicHead] <a href="https://arxiv.org/pdf/2007.08547v1.pdf">Talking-head Generation with Rhythmic Head Motion</a></td>
<td>ECCV 2020</td>
<td><a href="https://github.com/lelechen63/Talking-head-Generation-with-Rhythmic-Head-Motion">Code</a></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2020</td>
<td>[MakeItTalk] <a href="https://arxiv.org/pdf/2006.09661.pdf">Speaker-Aware Talking-Head Animation</a></td>
<td>SIGGRAPH Asia 2020</td>
<td><a href="https://github.com/yzhou359/MakeItTalk">Code</a></td>
<td><a href="https://people.umass.edu/~yangzhou/MakeItTalk/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2020</td>
<td>[Neural Voice Puppetry] <a href="https://arxiv.org/pdf/1912.05566.pdf">Audio-driven Facial Reenactment</a></td>
<td>ECCV 2020</td>
<td>-</td>
<td><a href="https://justusthies.github.io/posts/neural-voice-puppetry/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2020</td>
<td>[MEAD] <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660698.pdf">A Large-scale Audio-visual Dataset for Emotional Talking-face Generation</a></td>
<td>ECCV 2020</td>
<td><a href="https://github.com/uniBruce/Mead">Code</a></td>
<td><a href="https://wywu.github.io/projects/MEAD/MEAD.html">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2020</td>
<td><a href="https://arxiv.org/pdf/1906.06337.pdf">Realistic Speech-Driven Facial Animation with GANs</a></td>
<td>IJCV 2020</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2019</td>
<td>[DAVS] <a href="https://arxiv.org/pdf/1807.07860.pdf">Talking Face Generation by Adversarially Disentangled Audio-Visual Representation</a></td>
<td>AAAI 2019</td>
<td><a href="https://github.com/Hangz-nju-cuhk/Talking-Face-Generation-DAVS">Code</a></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2019</td>
<td>[ATVGnet] <a href="https://www.cs.rochester.edu/~cxu22/p/cvpr2019_facegen_paper.pdf">Hierarchical Cross-modal Talking Face Generation with Dynamic Pixel-wise Loss</a></td>
<td>CVPR 2019</td>
<td><a href="https://github.com/lelechen63/ATVGnet">Code</a></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2018</td>
<td><a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Lele_Chen_Lip_Movements_Generation_ECCV_2018_paper.pdf">Lip Movements Generation at a Glance</a></td>
<td>ECCV 2018</td>
<td><a href="https://github.com/lelechen63/3d_gan">Code</a></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2018</td>
<td>[VisemeNet] <a href="https://arxiv.org/pdf/1805.09488.pdf">Audio-Driven Animator-Centric Speech Animation</a></td>
<td>SIGGRAPH 2018</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2017</td>
<td>[Synthesizing Obama] <a href="https://grail.cs.washington.edu/projects/AudioToObama/siggraph17_obama.pdf">Learning Lip Sync From Audio</a></td>
<td>SIGGRAPH 2017</td>
<td>-</td>
<td><a href="https://grail.cs.washington.edu/projects/AudioToObama/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2017</td>
<td>[You Said That?] <a href="https://arxiv.org/abs/1705.02966">Synthesising Talking Faces From Audio</a></td>
<td>BMVC 2019</td>
<td><a href="https://github.com/joonson/yousaidthat">Code</a></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2017</td>
<td><a href="https://users.aalto.fi/~laines9/publications/karras2017siggraph_paper.pdf">Audio-Driven Facial Animation by Joint End-to-End Learning of Pose and Emotion</a></td>
<td>SIGGRAPH 2017</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2017</td>
<td><a href="https://home.ttic.edu/~taehwan/taylor_etal_siggraph2017.pdf">A Deep Learning Approach for Generalized Speech Animation</a></td>
<td>SIGGRAPH 2017</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2016</td>
<td>[LRW] <a href="https://www.robots.ox.ac.uk/~vgg/publications/2016/Chung16/chung16.pdf">Lip Reading in the Wild</a></td>
<td>ACCV 2016</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="Text-driven"><a href="#Text-driven" class="headerlink" title="Text-driven"></a>Text-driven</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Year</th>
<th>Title</th>
<th>Conference/Journal</th>
<th>Code/Proj</th>
</tr>
</thead>
<tbody>
<tr>
<td>2023</td>
<td><a href="https://arxiv.org/pdf/2304.00334.pdf">TalkCLIP: Talking Head Generation with Text-Guided Expressive Speaking Styles</a></td>
<td>Arxiv</td>
<td></td>
</tr>
<tr>
<td>2021</td>
<td><a href="https://arxiv.org/abs/2104.07995">Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation</a></td>
<td>AAAI</td>
<td><a href="https://github.com/FuxiVirtualHuman/Write-a-Speaker">Code</a></td>
</tr>
<tr>
<td>2021</td>
<td><a href="https://arxiv.org/abs/2106.14014v3">Txt2vid: Ultra-low bitrate compression of talking-head videos via text</a></td>
<td>Arxiv</td>
<td><a href="https://github.com/tpulkit/txt2vid">Code</a></td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="NeRF-amp-3D-amp-Gaussian-Splatting"><a href="#NeRF-amp-3D-amp-Gaussian-Splatting" class="headerlink" title="NeRF &amp; 3D &amp; Gaussian Splatting"></a>NeRF &amp; 3D &amp; Gaussian Splatting</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Year</th>
<th>Title</th>
<th>Conference/Journal</th>
<th>Code</th>
<th>Project</th>
<th>Keywords</th>
</tr>
</thead>
<tbody>
<tr>
<td>2024</td>
<td>[UltrAvatar] <a href="http://arxiv.org/abs/2401.11078v1">UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with Authenticity Guided Textures</a></td>
<td>Arxiv 2024</td>
<td></td>
<td><a href="http://usrc-sea.github.io/UltrAvatar/">Project</a></td>
<td>Diffusion,Avatar</td>
</tr>
<tr>
<td>2024</td>
<td>[GaussianBody] <a href="http://arxiv.org/abs/2401.09720v1">GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting</a></td>
<td>Arxiv 2024</td>
<td></td>
<td></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td><a href="http://arxiv.org/abs/2401.02616v1">FED-NeRF: Achieve High 3D Consistency and Temporal Coherence for Face Video Editing on Dynamic NeRF</a></td>
<td></td>
<td><a href="https://github.com/ZHANG1023/FED-NeRF">Code</a></td>
<td></td>
<td>4D face video editor</td>
</tr>
<tr>
<td>2024</td>
<td>[AGG] <a href="http://arxiv.org/abs/2401.04099v1">AGG: Amortized Generative 3D Gaussians for Single Image to 3D</a></td>
<td>Arxiv 2024</td>
<td></td>
<td><a href="https://ir1d.github.io/AGG/">Project</a></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td><a href="http://arxiv.org/abs/2401.06116v1">Gaussian Shadow Casting for Neural Characters</a></td>
<td>Arxiv 2024</td>
<td></td>
<td></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td>[Human101] <a href="http://arxiv.org/abs/2312.15258v1">Human101: Training 100+FPS Human Gaussians in 100s from 1 View</a></td>
<td>Arxiv 2024</td>
<td></td>
<td><a href="https://github.com/longxiang-ai/Human101">Project</a></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td><a href="http://arxiv.org/abs/2312.15059v1">Deformable 3D Gaussian Splatting for Animatable Human Avatars</a></td>
<td>Arxiv 2024</td>
<td></td>
<td></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td>[4DGen] <a href="http://arxiv.org/abs/2312.17225v1">4DGen: Grounded 4D Content Generation with Spatial-temporal Consistency</a></td>
<td>Arxiv 2024</td>
<td></td>
<td><a href="https://vita-group.github.io/4DGen/">Project</a></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td>[3DGAN] <a href="https://research.nvidia.com/labs/nxp/wysiwyg/media/WYSIWYG.pdf">What You See Is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs</a></td>
<td>Arxiv 2024</td>
<td></td>
<td><a href="https://research.nvidia.com/labs/nxp/wysiwyg/">Project</a></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>[3DGS-Avatar] <a href="http://arxiv.org/abs/2312.09228v2">3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting</a></td>
<td>Arxiv 2024</td>
<td><a href="https://github.com/mikeqzy/3dgs-avatar-release">Code</a></td>
<td><a href="https://neuralbodies.github.io/3DGS-Avatar">Project</a></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td><a href="http://arxiv.org/abs/2312.10422v2">Learning Dense Correspondence for NeRF-Based Face Reenactment</a></td>
<td>AAAI 2024</td>
<td></td>
<td></td>
<td>one-shot multi-view face reenactmen</td>
</tr>
<tr>
<td>2024</td>
<td>[R2-Talker] <a href="http://arxiv.org/abs/2312.05572v1">R2-Talker: Realistic Real-Time Talking Head Synthesis with Hash Grid Landmarks Encoding and Progressive Multilayer Conditioning</a></td>
<td>Arxiv 2024</td>
<td></td>
<td></td>
<td>based-RAD-NeRF</td>
</tr>
<tr>
<td>2024</td>
<td>[GaussianHead] <a href="https://arxiv.org/abs/2312.01632">GaussianHead: Impressive 3D Gaussian-based Head Avatars with Dynamic Hybrid Neural Field</a></td>
<td>Arxiv 2024</td>
<td><a href="https://github.com/chiehwangs/gaussian-head">Code</a></td>
<td></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td>[MonoGaussianAvatar] <a href="https://arxiv.org/abs/2312.00846">MonoGaussianAvatar: Monocular Gaussian Point-based Head Avatar</a></td>
<td>Arxiv 2024</td>
<td></td>
<td></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td>[Gaussian Head Avatar] <a href="http://arxiv.org/abs/2312.03029v1">Gaussian Head Avatar: Ultra High-fidelity Head Avatar via Dynamic Gaussians</a></td>
<td>Arxiv 2024</td>
<td><a href="https://github.com/YuelangX/Gaussian-Head-Avatar">Code</a></td>
<td><a href="https://yuelangx.github.io/gaussianheadavatar/">Project</a></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>[HeadGaS] <a href="http://arxiv.org/abs/2312.02902v1">HeadGaS: Real-Time Animatable Head Avatars via 3D Gaussian Splatting</a></td>
<td>Arxiv 2024</td>
<td></td>
<td></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td>[GaussianAvatars] <a href="http://arxiv.org/abs/2312.02069v1">GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians</a></td>
<td>Arxiv 2024</td>
<td></td>
<td><a href="https://shenhanqian.github.io/gaussian-avatars">Project</a></td>
<td>ğŸ”¥Gaussian Splatting</td>
</tr>
<tr>
<td>2024</td>
<td>[SyncTalk] <a href="https://arxiv.org/abs/2311.17590">SyncTalk: The DevilğŸ˜ˆ is in the Synchronization for Talking Head Synthesis</a></td>
<td>CVPR 2024?</td>
<td><a href="https://github.com/ZiqiaoPeng/SyncTalk">Code</a></td>
<td><a href="https://ziqiaopeng.github.io/synctalk/">Project</a></td>
<td>ğŸ˜ˆ</td>
</tr>
<tr>
<td>2024</td>
<td>[R2-Talk] <a href="https://arxiv.org/abs/2312.05572">R2-Talker: Realistic Real-Time Talking Head Synthesis with Hash Grid Landmarks Encoding and Progressive Multilayer Conditioning</a></td>
<td>Arxiv 2024</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2024</td>
<td>[DT-NeRF] <a href="https://arxiv.org/pdf/2309.07752">DT-NeRF: Decomposed Triplane-Hash Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis</a></td>
<td>ICASSP 2024</td>
<td>-</td>
<td>-</td>
<td>ER-NeRF</td>
</tr>
<tr>
<td>2023</td>
<td>[ER-NeRF] <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Efficient_Region-Aware_Neural_Radiance_Fields_for_High-Fidelity_Talking_Portrait_Synthesis_ICCV_2023_paper.pdf">Efficient Region-Aware Neural Radiance Fields for High-Fidelity Talking Portrait Synthesis</a></td>
<td>ICCV 2023</td>
<td><a href="https://github.com/Fictionarry/ER-NeRF">Code</a></td>
<td><a href="https://fictionarry.github.io/ER-NeRF/">Project</a></td>
<td>Tri-plane</td>
</tr>
<tr>
<td>2023</td>
<td>[LipNeRF] <a href="https://www.amazon.science/publications/lipnerf-what-is-the-right-feature-space-to-lip-sync-a-nerf">LipNeRF: What is the right feature space to lip-sync a NeRF?</a></td>
<td>FG 2023</td>
<td>Code</td>
<td><a href="https://aggelinacha.github.io/LipNeRF/">Project</a></td>
<td>Wav2lip</td>
</tr>
<tr>
<td>2023</td>
<td>[SD-NeRF] <a href="https://ieeexplore.ieee.org/document/10229247">SD-NeRF: Towards Lifelike Talking Head Animation via Spatially-adaptive Dual-driven NeRFs</a></td>
<td>IEEE 2023</td>
<td>-</td>
<td>-</td>
<td></td>
</tr>
<tr>
<td>2023</td>
<td>[Instruct-NeuralTalker] <a href="https://arxiv.org/abs/2306.10813">Instruct-NeuralTalker: Editing Audio-Driven Talking Radiance Fields with Instructions</a></td>
<td>Arxiv 2023</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2023</td>
<td>[GeneFace++] <a href="https://arxiv.org/abs/2305.00787">Generalized and Stable Real-Time Audio-Driven 3D Talking Face Generation</a></td>
<td>Arxiv 2023</td>
<td>-</td>
<td><a href="https://genefaceplusplus.github.io/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2023</td>
<td>[GeneFace] <a href="https://arxiv.org/abs/2301.13430">GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis</a></td>
<td>ICLR 2023</td>
<td><a href="https://github.com/yerfor/GeneFace">Code</a></td>
<td><a href="https://geneface.github.io/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[RAD-NeRF] <a href="https://arxiv.org/pdf/2211.12368.pdf">RAD-NeRF: Real-time Neural Talking Portrait Synthesis</a></td>
<td>Arxiv 2022</td>
<td><a href="https://github.com/ashawkey/RAD-NeRF">Code</a></td>
<td><a href="https://ashawkey.github.io/radnerf/">Project</a></td>
<td>InstantNGP</td>
</tr>
<tr>
<td>2022</td>
<td>[DFRF] <a href="https://arxiv.org/abs/2207.11770">DFRFï¼šLearning Dynamic Facial Radiance Fields for Few-Shot Talking Head Synthesis</a></td>
<td>ECCV 2022</td>
<td><a href="https://github.com/sstzal/DFRF">Code</a></td>
<td><a href="https://sstzal.github.io/DFRF/">Project</a></td>
<td></td>
</tr>
<tr>
<td>2022</td>
<td>[DialogueNeRF] <a href="https://arxiv.org/pdf/2203.07931.pdf">DialogueNeRF: Towards Realistic Avatar Face-to-face Conversation Video Generation</a></td>
<td>Arxiv 2022</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[NeRFInvertor] <a href="https://arxiv.org/pdf/2211.17235.pdf">NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-shot Real Image Animation</a></td>
<td>Arxiv 2022</td>
<td><a href="https://github.com/YuYin1/NeRFInvertor">Code</a></td>
<td><a href="https://yuyin1.github.io/NeRFInvertor_Homepage/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[Next3D] <a href="https://arxiv.org/pdf/2211.11208.pdf">Next3D: Generative Neural Texture Rasterization for 3D-Aware Head Avatars</a></td>
<td>Arxiv 2022</td>
<td><a href="https://mrtornado24.github.io/Next3D/">Code</a></td>
<td><a href="https://mrtornado24.github.io/Next3D/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[3DFaceShop] <a href="https://arxiv.org/pdf/2209.05434">3DFaceShop: Explicitly Controllable 3D-Aware Portrait Generation</a></td>
<td>Arxiv 2022</td>
<td><a href="https://github.com/junshutang/3DFaceShop">Code</a></td>
<td><a href="https://junshutang.github.io/control/index.html">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[FNeVR] <a href="https://arxiv.org/abs/2209.10340">FNeVR: Neural Volume Rendering for Face Animation</a></td>
<td>Arxiv 2022</td>
<td><a href="https://github.com/zengbohan0217/FNeVR">Code</a></td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[ROME] <a href="https://arxiv.org/pdf/2206.08343.pdf">ROME: Realistic One-shot Mesh-based Head Avatars</a></td>
<td>ECCV 2022</td>
<td><a href="https://github.com/SamsungLabs/rome">Code</a></td>
<td><a href="https://samsunglabs.github.io/rome/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[IMavatar] <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_I_M_Avatar_Implicit_Morphable_Head_Avatars_From_Videos_CVPR_2022_paper.pdf">IMavatar: Implicit Morphable Head Avatars from Videos</a></td>
<td>CVPR 2022</td>
<td><a href="https://ait.ethz.ch/projects/2022/IMavatar/">Code</a></td>
<td><a href="https://ait.ethz.ch/projects/2022/IMavatar/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[HeadNeRF] <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Grassal_Neural_Head_Avatars_From_Monocular_RGB_Videos_CVPR_2022_paper.pdf">HeadNeRF: A Real-time NeRF-based Parametric Head Model</a></td>
<td>CVPR 2022</td>
<td><a href="https://github.com/CrisHY1995/headnerf">Code</a></td>
<td><a href="https://hy1995.top/HeadNeRF-Project/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2022</td>
<td>[SSP-NeRF] <a href="https://arxiv.org/pdf/2201.07786.pdf">Semantic-Aware Implicit Neural Audio-Driven Video Portrait Generation</a></td>
<td>Arxiv 2022</td>
<td><a href="https://github.com/alvinliu0/SSP-NeRF">Code</a></td>
<td><a href="https://alvinliu0.github.io/projects/SSP-NeRF">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2021</td>
<td>[AD-NeRF] <a href="https://arxiv.org/abs/2103.11078">AD-NeRF: Audio Driven Neural Radiance Fields for Talking Head Synthesis</a></td>
<td>ICCV 2021</td>
<td><a href="https://github.com/YudongGuo/AD-NeRF">Code</a></td>
<td><a href="https://yudongguo.github.io/ADNeRF/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2021</td>
<td>[NerFACE] <a href="https://arxiv.org/pdf/2012.03065">NerFACE: Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction</a></td>
<td>CVPR 2021 Oral</td>
<td><a href="https://github.com/gafniguy/4D-Facial-Avatars">Code</a></td>
<td><a href="https://gafniguy.github.io/4D-Facial-Avatars/">Project</a></td>
<td>-</td>
</tr>
<tr>
<td>2021</td>
<td>[DFA-NeRF] <a href="https://arxiv.org/pdf/2201.00791v1.pdf">DFA-NeRF: Personalized Talking Head Generation via Disentangled Face Attributes Neural Rendering</a></td>
<td>Arxiv 2021</td>
<td><a href="https://github.com/ShunyuYao/DFA-NeRF">Code</a></td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Metrics</th>
<th>Paper</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td>PSNR (peak signal-to-noise ratio)</td>
<td>-</td>
<td></td>
</tr>
<tr>
<td>SSIM (structural similarity index measure)</td>
<td>Image quality assessment: from error visibility to structural similarity.</td>
<td></td>
</tr>
<tr>
<td>CPBD(cumulative probability of blur detection)</td>
<td>A no-reference image blur metric based on the cumulative probability of blur detection</td>
<td></td>
</tr>
<tr>
<td>LPIPS (Learned Perceptual Image Patch Similarity) -</td>
<td>The Unreasonable Effectiveness of Deep Features as a Perceptual Metric</td>
<td><a href="https://arxiv.org/pdf/1801.03924.pdf">paper</a></td>
</tr>
<tr>
<td>NIQE (Natural Image Quality Evaluator)</td>
<td>Making a â€˜Completely Blindâ€™ Image Quality Analyzer</td>
<td><a href="http://live.ece.utexas.edu/research/Quality/niqe_spl.pdf">paper</a></td>
</tr>
<tr>
<td>FID (FrÃ©chet inception distance)</td>
<td>GANs trained by a two time-scale update rule converge to a local nash equilibrium</td>
<td></td>
</tr>
<tr>
<td>LMD (landmark distance error)</td>
<td>Lip Movements Generation at a Glance</td>
<td></td>
</tr>
<tr>
<td>LRA (lip-reading accuracy)</td>
<td>Talking Face Generation by Conditional Recurrent Adversarial Network</td>
<td><a href="https://arxiv.org/pdf/1804.04786.pdf">paper</a></td>
</tr>
<tr>
<td>WER(word error rate)</td>
<td>Lipnet: end-to-end sentencelevel lipreading.</td>
<td></td>
</tr>
<tr>
<td>LSE-D (Lip Sync Error - Distance)</td>
<td>Out of time: automated lip sync in the wild</td>
<td></td>
</tr>
<tr>
<td>LSE-C (Lip Sync Error - Confidence)</td>
<td>Out of time: automated lip sync in the wild</td>
<td></td>
</tr>
<tr>
<td>ACD(Average content distance)</td>
<td>Facenet: a unified embedding for face recognition and clustering.</td>
<td></td>
</tr>
<tr>
<td>CSIM(cosine similarity)</td>
<td>Arcface: additive angular margin loss for deep face recognition.</td>
<td></td>
</tr>
<tr>
<td>EAR(eye aspect ratio)</td>
<td>Real-time eye blink detection using facial landmarks. In: Computer Vision Winter Workshop</td>
<td></td>
</tr>
<tr>
<td>ESD(emotion similarity distance)</td>
<td>What comprises a good talking-head video generation?: A Survey and Benchmark</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="Tools-amp-Software"><a href="#Tools-amp-Software" class="headerlink" title="Tools &amp; Software"></a>Tools &amp; Software</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Tool/Resource</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://sourceforge.net/projects/lucia/">LUCIA</a></td>
<td>Development of a MPEG-4 Talking Head Engine. ğŸ’»</td>
</tr>
<tr>
<td><a href="https://www.g2.com/products/yepic-studio/reviews">Yepic Studio</a></td>
<td>Create and dub talking head-style videos in minutes without expensive equipment. ğŸ¥</td>
</tr>
<tr>
<td><a href="https://sourceforge.net/projects/talkbots/">Mel McGeeâ€™s Talkbots</a></td>
<td>A complete multi-browser, multi-platform talking head application in SVG suitable for web sites or as an avatar. ğŸ—£ï¸</td>
</tr>
<tr>
<td><a href="https://sourceforge.net/projects/face3dchung/">face3D_chung</a></td>
<td>Create 3D character avatar head objects with texture from a single photo for your games. ğŸ®</td>
</tr>
<tr>
<td><a href="https://www.g2.com/products/crazytalk/reviews">CrazyTalk</a></td>
<td>Exciting features for 3D head creation and automation. ğŸ¤ª</td>
</tr>
<tr>
<td><a href="https://sourceforge.net/directory/?q=tts%20avatar">tts avatar free download - SourceForge</a></td>
<td>Mel McGeeâ€™s Talkbots is a complete multi-browser, multi-platform talking head. (ğŸ”§ğŸ‘„)</td>
</tr>
<tr>
<td><a href="https://www.producthunt.com/products/verbatim-ai">Verbatim AI - Product Information, Latest Updates, and Reviews 2023</a></td>
<td>A simple yet powerful API to generate AI â€œtalking headâ€ videos in near real-time with Verbatim AI. Add interest, intrigue, and dynamism to your chat bots! (ğŸ”§ğŸ‘„)</td>
</tr>
<tr>
<td><a href="https://sourceforge.net/directory/3d-modeling/basic/">Best Open Source BASIC 3D Modeling Software</a></td>
<td>Includes talk3D_chung, a small example using obj models created with face3D_chung, and speak3D_chung_dll, a dll to load and display face3D_chung talking avatars. (ğŸ› ï¸ğŸ­)</td>
</tr>
<tr>
<td><a href="https://sourceforge.net/p/dvdstyler/discussion/318795/thread/82dcb647/">DVDStyler / Discussion / Help: ffmpeg-vbr or internal</a></td>
<td>Talking heads would get a bitrate which is unnecessarily high while using DVDStyler. (ğŸ› ï¸ğŸ‘„)</td>
</tr>
<tr>
<td><a href="https://sourceforge.net/directory/lisp/?q=puffin+web+browser">puffin web browser free download - SourceForge</a></td>
<td>Mel McGeeâ€™s Talkbots is a complete multi-browser, multi-platform talking head. (ğŸ”§ğŸ‘„)</td>
</tr>
<tr>
<td>[12 best AI video generators to use in 2023 Free and paid \</td>
<td>Product â€¦](<a href="https://www.producthunt.com/stories/best-ai-video-generators-free">https://www.producthunt.com/stories/best-ai-video-generators-free</a>)</td>
<td>Whether youâ€™re an entrepreneur, small business owner, or run a large company, AI video generators make it super easy to create high-quality videos from scratch. (ğŸ”§ğŸ¥)</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="Slides-amp-Presentations"><a href="#Slides-amp-Presentations" class="headerlink" title="Slides &amp; Presentations"></a>Slides &amp; Presentations</h2><div class="table-container">
<table>
<thead>
<tr>
<th>Presentation Title</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.slideshare.net/ssuserc9d82a/paper-reviewfewshot-adversarial-learning-of-realistic-neural-talking-head-models">Few-Shot Adversarial Learning of Realistic Neural Talking Head Models</a></td>
<td>Presentation reviewing the few-shot adversarial learning of realistic neural talking head models.</td>
</tr>
<tr>
<td><a href="https://www.slideshare.net/ZULHICZARARIETINARBU/nethania-michelles-character">Nethania Michelleâ€™s Character</a></td>
<td>PPT: Presentation discussing the improvement of a 3D talking head for use in an avatar of a virtual meeting room.</td>
</tr>
<tr>
<td><a href="https://support.prezi.com/hc/en-us/articles/360036679953-Presenting-you-Top-tips-on-presenting-with-Prezi-Video">Presenting you: Top tips on presenting with Prezi Video â€“ Prezi</a></td>
<td>Article providing top tips for presenting with Prezi Video.</td>
</tr>
<tr>
<td><a href="https://pt.slideshare.net/willg_36/research-presentation-presentation-956726">Research Presentation</a></td>
<td>PPT: Resident Research Presentation Slide Deck.</td>
</tr>
<tr>
<td><a href="https://support.prezi.com/hc/en-us/articles/360038281894-Adding-narration-to-your-presentation-using-Prezi-Video-">Adding narration to your presentation (using Prezi Video) â€“ Prezi</a></td>
<td>Learn how to add narration to your Prezi presentation with Prezi Video.</td>
</tr>
</tbody>
</table>
</div>
<hr>
<h2 id="Star-History"><a href="#Star-History" class="headerlink" title="Star History"></a>Star History</h2><p><a href="https://star-history.com/#Kedreamix/Awesome-Talking-Head-Synthesis&amp;Date"><img src="https://api.star-history.com/svg?repos=Kedreamix/Awesome-Talking-Head-Synthesis&amp;type=Date" alt="Star History Chart"></a></p>
]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
        <tag>NeRF</tag>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/01/24/Paper/2024-01-24/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-24-æ›´æ–°"><a href="#2024-01-24-æ›´æ–°" class="headerlink" title="2024-01-24 æ›´æ–°"></a>2024-01-24 æ›´æ–°</h1><h2 id="Less-Could-Be-Better-Parameter-efficient-Fine-tuning-Advances-Medical-Vision-Foundation-Models"><a href="#Less-Could-Be-Better-Parameter-efficient-Fine-tuning-Advances-Medical-Vision-Foundation-Models" class="headerlink" title="Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical   Vision Foundation Models"></a>Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical   Vision Foundation Models</h2><p><strong>Authors:Chenyu Lian, Hong-Yu Zhou, Yizhou Yu, Liansheng Wang</strong></p>
<p>Parameter-efficient fine-tuning (PEFT) that was initially developed for exploiting pre-trained large language models has recently emerged as an effective approach to perform transfer learning on computer vision tasks. However, the effectiveness of PEFT on medical vision foundation models is still unclear and remains to be explored. As a proof of concept, we conducted a detailed empirical study on applying PEFT to chest radiography foundation models. Specifically, we delved into LoRA, a representative PEFT method, and compared it against full-parameter fine-tuning (FFT) on two self-supervised radiography foundation models across three well-established chest radiograph datasets. Our results showed that LoRA outperformed FFT in 13 out of 18 transfer learning tasks by at most 2.9% using fewer than 1% tunable parameters. Combining LoRA with foundation models, we set up new state-of-the-art on a range of data-efficient learning tasks, such as an AUROC score of 80.6% using 1% labeled data on NIH ChestX-ray14. We hope this study can evoke more attention from the community in the use of PEFT for transfer learning on medical imaging tasks. Code and models are available at <a href="https://github.com/RL4M/MED-PEFT">https://github.com/RL4M/MED-PEFT</a>. </p>
<p><a href="http://arxiv.org/abs/2401.12215v1">PDF</a> Technical report</p>
<p><strong>Summary</strong><br>åŸºäºèƒ¸éƒ¨Xå…‰å½±åƒåŸºé‡‘æ¨¡å‹çš„PEFTå‚æ•°åŒ–å¾®è°ƒå¯æé«˜åŒ»å­¦è§†è§‰ä»»åŠ¡çš„è¿ç§»å­¦ä¹ æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>PEFTåœ¨18é¡¹è¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­æœ‰13é¡¹ä¼˜äºFFTï¼Œä½¿ç”¨å¯è°ƒå‚æ•°å°‘äº1%å¯æé«˜è‡³å¤š2.9%çš„æ€§èƒ½ã€‚</li>
<li>å°†PEFTä¸åŸºé‡‘æ¨¡å‹ç›¸ç»“åˆï¼Œæˆ‘ä»¬åœ¨ä¸€ç³»åˆ—æ•°æ®é«˜æ•ˆå­¦ä¹ ä»»åŠ¡ä¸Šè®¾ç½®äº†æ–°çš„æœ€å…ˆè¿›æŠ€æœ¯ï¼Œä¾‹å¦‚ï¼Œåœ¨NIH ChestX-ray14ä¸Šä½¿ç”¨1%çš„æ ‡è®°æ•°æ®ï¼ŒAUROCå¾—åˆ†è¾¾åˆ°80.6%ã€‚</li>
<li>æˆ‘ä»¬å¸Œæœ›è¿™é¡¹ç ”ç©¶èƒ½å¤Ÿå¼•èµ·ç¤¾åŒºå¯¹PEFTåœ¨åŒ»å­¦å½±åƒä»»åŠ¡ä¸­çš„è¿ç§»å­¦ä¹ çš„æ›´å¤šå…³æ³¨ã€‚</li>
<li>ä»£ç å’Œæ¨¡å‹å¯ä»¥åœ¨<a href="https://github.com/RL4M/MED-PEFTä¸Šè·å¾—ã€‚">https://github.com/RL4M/MED-PEFTä¸Šè·å¾—ã€‚</a></li>
<li>PEFTæœ€åˆå¼€å‘ç”¨äºå¼€å‘é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæœ€è¿‘å·²æˆä¸ºåœ¨è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸Šæ‰§è¡Œè¿ç§»å­¦ä¹ çš„æœ‰æ•ˆæ–¹æ³•ã€‚</li>
<li>PEFTåœ¨åŒ»å­¦è§†è§‰åŸºé‡‘æ¨¡å‹ä¸­çš„æœ‰æ•ˆæ€§ä»ä¸æ¸…æ¥šï¼Œæœ‰å¾…æ¢ç´¢ã€‚</li>
<li>ä½œä¸ºæ¦‚å¿µè¯æ˜ï¼Œæˆ‘ä»¬å¯¹å°†PEFTåº”ç”¨äºèƒ¸éƒ¨æ”¾å°„çº¿ç…§ç›¸åŸºé‡‘æ¨¡å‹è¿›è¡Œäº†è¯¦ç»†çš„å®è¯ç ”ç©¶ã€‚</li>
<li>å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬æ·±å…¥ç ”ç©¶äº†LoRAï¼ˆä¸€ç§å…·æœ‰ä»£è¡¨æ€§çš„PEFTæ–¹æ³•ï¼‰ï¼Œå¹¶å°†å…¶ä¸åœ¨ä¸‰ä¸ªå…¬è®¤çš„èƒ¸éƒ¨Xå…‰ç…§ç›¸æ•°æ®é›†ä¸­å¯¹ä¸¤ä¸ªè‡ªç›‘ç£æ”¾å°„çº¿ç…§ç›¸åŸºé‡‘æ¨¡å‹è¿›è¡Œå…¨å‚æ•°å¾®è°ƒï¼ˆFFTï¼‰è¿›è¡Œäº†æ¯”è¾ƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šå°‘å³æ˜¯å¤šï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒ</p>
</li>
<li><p>ä½œè€…ï¼šé™ˆå®‡å»‰ã€å‘¨é¸¿å®‡ã€äºä¸€èˆŸã€ç‹è¿ç”Ÿ</p>
</li>
<li><p>å•ä½ï¼šå¦é—¨å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šè¿ç§»å­¦ä¹ ã€åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹ã€èƒ¸éƒ¨ X å°„çº¿</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12215
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/RL4M/MED-PEFT</p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æœ€åˆç”¨äºå¼€å‘é¢„è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹ï¼Œæœ€è¿‘å·²æˆä¸ºè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­è¿›è¡Œè¿ç§»å­¦ä¹ çš„æœ‰æ•ˆæ–¹æ³•ã€‚ç„¶è€Œï¼ŒPEFT åœ¨åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹ä¸­çš„æœ‰æ•ˆæ€§ä»ä¸æ¸…æ¥šï¼Œæœ‰å¾…æ¢ç´¢ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå…¨å‚æ•°å¾®è°ƒï¼ˆFFTï¼‰å·²è¢«å…¬è®¤ä¸ºä¸€ç§æ‰§è¡Œè¿ç§»å­¦ä¹ çš„ä¼˜è¶ŠæŠ€æœ¯ã€‚ç„¶è€Œï¼ŒåŸºç¡€æ¨¡å‹é€šå¸¸å…·æœ‰å¤§é‡å‚æ•°ï¼Œå½“ä¸‹æ¸¸ä»»åŠ¡åªæœ‰æœ‰é™çš„æ³¨é‡Šæ—¶ï¼Œå¾®è°ƒå…¨éƒ¨æ¨¡å‹æƒé‡å¯èƒ½ä¸æ˜¯ä¸€ä¸ªæœ€ä¼˜é€‰æ‹©ã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è¯æ˜æ¦‚å¿µï¼Œæˆ‘ä»¬å¯¹å°† PEFT åº”ç”¨äºèƒ¸éƒ¨æ”¾å°„çº¿åŸºç¡€æ¨¡å‹è¿›è¡Œäº†è¯¦ç»†çš„å®è¯ç ”ç©¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ·±å…¥ç ”ç©¶äº†å…·æœ‰ä»£è¡¨æ€§çš„ PEFT æ–¹æ³• LoRAï¼Œå¹¶å°†å…¶ä¸ä¸¤ä¸ªè‡ªç›‘ç£æ”¾å°„çº¿åŸºç¡€æ¨¡å‹åœ¨ä¸‰ä¸ªå…¬è®¤çš„èƒ¸éƒ¨æ”¾å°„çº¿æ•°æ®é›†ä¸Šä¸å…¨å‚æ•°å¾®è°ƒ (FFT) è¿›è¡Œäº†æ¯”è¾ƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°åŠå…¶æ€§èƒ½ï¼šæˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒLoRA åœ¨ 18 é¡¹è¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­çš„ 13 é¡¹ä¸­ä¼˜äº FFTï¼Œæœ€å¤šå¯ä½¿ç”¨å°‘äº 1% çš„å¯è°ƒå‚æ•°æé«˜ 2.9%ã€‚å°† LoRA ä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆï¼Œæˆ‘ä»¬åœ¨å„ç§æ•°æ®é«˜æ•ˆå­¦ä¹ ä»»åŠ¡ä¸­å»ºç«‹äº†æ–°çš„æœ€ä¼˜æ°´å¹³ï¼Œä¾‹å¦‚åœ¨ NIHChestX-ray14 ä¸Šä½¿ç”¨ 1% çš„æ ‡è®°æ•°æ®è·å¾—äº† 80.6% çš„ AUROC åˆ†æ•°ã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹ç ”ç©¶èƒ½å¤Ÿå¼•èµ·ç¤¾åŒºæ›´å¤šåœ°å…³æ³¨åœ¨åŒ»å­¦æˆåƒä»»åŠ¡ä¸­ä½¿ç”¨ PEFT è¿›è¡Œè¿ç§»å­¦ä¹ ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡º LoRA-PEFT æ–¹æ³•ï¼šLoRA-PEFT æ˜¯ä¸€ç§å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œå®ƒé€šè¿‡å­¦ä¹ ä¸€ä¸ªä½ç§©çŸ©é˜µæ¥å¯¹åŸºç¡€æ¨¡å‹çš„æƒé‡è¿›è¡Œå¾®è°ƒã€‚è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆå‡å°‘å¯è°ƒå‚æ•°çš„æ•°é‡ï¼Œä»è€Œæé«˜å¾®è°ƒçš„æ•ˆç‡ã€‚
ï¼ˆ2ï¼‰åœ¨èƒ¸éƒ¨ X å°„çº¿æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼šä½œè€…å°† LoRA-PEFT æ–¹æ³•åº”ç”¨äºä¸¤ä¸ªè‡ªç›‘ç£èƒ¸éƒ¨ X å°„çº¿åŸºç¡€æ¨¡å‹ï¼Œå¹¶åœ¨ä¸‰ä¸ªå…¬è®¤çš„èƒ¸éƒ¨ X å°„çº¿æ•°æ®é›†ä¸Šä¸å…¨å‚æ•°å¾®è°ƒ (FFT) è¿›è¡Œäº†æ¯”è¾ƒã€‚ç»“æœè¡¨æ˜ï¼ŒLoRA-PEFT åœ¨ 18 é¡¹è¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­çš„ 13 é¡¹ä¸­ä¼˜äº FFTï¼Œæœ€å¤šå¯ä½¿ç”¨å°‘äº 1% çš„å¯è°ƒå‚æ•°æé«˜ 2.9%ã€‚
ï¼ˆ3ï¼‰åœ¨å…¶ä»–åŒ»å­¦æˆåƒä»»åŠ¡ä¸Šè¿›è¡Œå®éªŒï¼šä½œè€…è¿˜å°† LoRA-PEFT æ–¹æ³•åº”ç”¨äºå…¶ä»–åŒ»å­¦æˆåƒä»»åŠ¡ï¼ŒåŒ…æ‹¬è‚ºç»“èŠ‚æ£€æµ‹ã€éª¨é¾„è¯„ä¼°å’Œå¿ƒè„ç£å…±æŒ¯æˆåƒåˆ†å‰²ã€‚ç»“æœè¡¨æ˜ï¼ŒLoRA-PEFT åœ¨è¿™äº›ä»»åŠ¡ä¸Šä¹Ÿå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•LoRA-PEFTï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆå‡å°‘å¯è°ƒå‚æ•°çš„æ•°é‡ï¼Œä»è€Œæé«˜å¾®è°ƒçš„æ•ˆç‡ã€‚åœ¨èƒ¸éƒ¨Xå°„çº¿æ•°æ®é›†å’Œå…¶å®ƒåŒ»å­¦æˆåƒä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒLoRA-PEFTåœ¨è¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­å–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•LoRA-PEFTã€‚
å°†LoRA-PEFTæ–¹æ³•åº”ç”¨äºèƒ¸éƒ¨Xå°„çº¿æ•°æ®é›†å’Œå…¶å®ƒåŒ»å­¦æˆåƒä»»åŠ¡ï¼Œå¹¶å–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š
åœ¨18é¡¹è¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­çš„13é¡¹ä¸­ä¼˜äºå…¨å‚æ•°å¾®è°ƒ(FFT)ï¼Œæœ€å¤šå¯ä½¿ç”¨å°‘äº1%çš„å¯è°ƒå‚æ•°æé«˜2.9%ã€‚
åœ¨å…¶ä»–åŒ»å­¦æˆåƒä»»åŠ¡ä¸Šä¹Ÿå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š
æ–¹æ³•ç®€å•æ˜“ç”¨ï¼Œæ˜“äºå®ç°ã€‚
åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-88f5604fa47b7e6b53fa59ed5ce873a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f28a6055dce3066c942bea25f00c4b98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-219f68f671f950faee6332daa05d83eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b0e3d9c8b6a9c6651af0cb1202241988.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="CheXagent-Towards-a-Foundation-Model-for-Chest-X-Ray-Interpretation"><a href="#CheXagent-Towards-a-Foundation-Model-for-Chest-X-Ray-Interpretation" class="headerlink" title="CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation"></a>CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation</h2><p><strong>Authors:Zhihong Chen, Maya Varma, Jean-Benoit Delbrouck, Magdalini Paschali, Louis Blankemeier, Dave Van Veen, Jeya Maria Jose Valanarasu, Alaa Youssef, Joseph Paul Cohen, Eduardo Pontes Reis, Emily B. Tsai, Andrew Johnston, Cameron Olsen, Tanishq Mathew Abraham, Sergios Gatidis, Akshay S. Chaudhari, Curtis Langlotz</strong></p>
<p>Chest X-rays (CXRs) are the most frequently performed imaging test in clinical practice. Recent advances in the development of vision-language foundation models (FMs) give rise to the possibility of performing automated CXR interpretation, which can assist physicians with clinical decision-making and improve patient outcomes. However, developing FMs that can accurately interpret CXRs is challenging due to the (1) limited availability of large-scale vision-language datasets in the medical image domain, (2) lack of vision and language encoders that can capture the complexities of medical data, and (3) absence of evaluation frameworks for benchmarking the abilities of FMs on CXR interpretation. In this work, we address these challenges by first introducing \emph{CheXinstruct} - a large-scale instruction-tuning dataset curated from 28 publicly-available datasets. We then present \emph{CheXagent} - an instruction-tuned FM capable of analyzing and summarizing CXRs. To build CheXagent, we design a clinical large language model (LLM) for parsing radiology reports, a vision encoder for representing CXR images, and a network to bridge the vision and language modalities. Finally, we introduce \emph{CheXbench} - a novel benchmark designed to systematically evaluate FMs across 8 clinically-relevant CXR interpretation tasks. Extensive quantitative evaluations and qualitative reviews with five expert radiologists demonstrate that CheXagent outperforms previously-developed general- and medical-domain FMs on CheXbench tasks. Furthermore, in an effort to improve model transparency, we perform a fairness evaluation across factors of sex, race and age to highlight potential performance disparities. Our project is at \url{<a href="https://stanford-aimi.github.io/chexagent.html}">https://stanford-aimi.github.io/chexagent.html}</a>. </p>
<p><a href="http://arxiv.org/abs/2401.12208v1">PDF</a> 24 pages, 8 figures</p>
<p><strong>æ‘˜è¦</strong><br>å¼•å…¥å¤§è§„æ¨¡æŒ‡ä»¤è°ƒæ•´æ•°æ®é›†å’Œåˆ›æ–°åŸºå‡†ï¼Œæ„å»ºå¼ºå¤§ä¸”é€æ˜çš„èƒ¸éƒ¨ X å…‰è§£é‡Š AI ç³»ç»Ÿã€‚</p>
<p><strong>ä¸»è¦è¦ç‚¹</strong></p>
<ul>
<li>èƒ¸éƒ¨ X å…‰æ£€æŸ¥æ˜¯ä¸´åºŠä¸Šæœ€å¸¸è¿›è¡Œçš„å½±åƒæ£€æŸ¥ã€‚</li>
<li>è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ (FM) åœ¨åŒ»å­¦å½±åƒé¢†åŸŸå–å¾—äº†è¿›å±•ã€‚</li>
<li>å¼€å‘å‡†ç¡®è§£è¯»èƒ¸éƒ¨ X å…‰çš„ FM å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>æå‡º CheXinstructï¼Œä¸€ä¸ªåŒ…å« 28 ä¸ªå…¬å…±æ•°æ®é›†çš„å¤§è§„æ¨¡æŒ‡ä»¤è°ƒæ•´æ•°æ®é›†ã€‚</li>
<li>æå‡º CheXagentï¼Œä¸€ä¸ªèƒ½å¤Ÿåˆ†æå’Œæ€»ç»“èƒ¸éƒ¨ X å…‰çš„æŒ‡ä»¤è°ƒæ•´ FMã€‚</li>
<li>æ„å»º CheXagentï¼Œè®¾è®¡äº†ä¸€ä¸ªä¸´åºŠå¤§è¯­è¨€æ¨¡å‹ (LLM) ç”¨äºè§£ææ”¾å°„æŠ¥å‘Šï¼Œä¸€ä¸ªè§†è§‰ç¼–ç å™¨ç”¨äºè¡¨ç¤ºèƒ¸éƒ¨ X å…‰å›¾åƒï¼Œä»¥åŠä¸€ä¸ªç”¨äºæ¡¥æ¥è§†è§‰å’Œè¯­è¨€æ¨¡æ€çš„ç½‘ç»œã€‚</li>
<li>å¼•å…¥ CheXbenchï¼Œä¸€ä¸ªæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼° FM åœ¨ 8 ä¸ªä¸´åºŠç›¸å…³èƒ¸éƒ¨ X å…‰è§£é‡Šä»»åŠ¡ä¸­çš„èƒ½åŠ›çš„æ–°åŸºå‡†ã€‚</li>
<li>CheXagent åœ¨ CheXbench ä»»åŠ¡ä¸Šä¼˜äºä¹‹å‰å¼€å‘çš„é€šç”¨å’ŒåŒ»å­¦é¢†åŸŸ FMã€‚</li>
<li>å¯¹æ€§åˆ«ã€ç§æ—å’Œå¹´é¾„ç­‰å› ç´ è¿›è¡Œå…¬å¹³æ€§è¯„ä¼°ï¼Œä»¥çªå‡ºæ½œåœ¨çš„æ€§èƒ½å·®å¼‚ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šCheXagentï¼šæ„å»ºèƒ¸éƒ¨ X å°„çº¿è§£è¯»åŸºç¡€æ¨¡å‹</li>
<li>ä½œè€…ï¼šZhihong Chenã€Maya Varmaã€Jean-Benoit Delbrouckã€Magdalini Paschaliã€Louis Blankemeierã€Dave Van Veenã€Jeya Maria Jose Valanarasuã€Alaa Youssefã€Joseph Paul Cohenã€Eduardo Pontes Reisã€Emily B. Tsaiã€Andrew Johnstonã€Cameron Olsenã€Tanishq Mathew Abrahamã€Sergios Gatidisã€Akshay S. Chaudhariã€Curtis Langlotz</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ–¯å¦ç¦å¤§å­¦</li>
<li>å…³é”®è¯ï¼šèƒ¸éƒ¨ X å°„çº¿ã€åŒ»å­¦å›¾åƒã€åŸºç¡€æ¨¡å‹ã€è¯­è¨€æ¨¡å‹ã€è§†è§‰ç¼–ç å™¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12208ï¼ŒGithub ä»£ç é“¾æ¥ï¼šGithubï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šèƒ¸éƒ¨ X å°„çº¿ (CXR) æ˜¯ä¸´åºŠå®è·µä¸­æœ€å¸¸è¿›è¡Œçš„å½±åƒæ£€æŸ¥ã€‚æœ€è¿‘è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ (FM) çš„å‘å±•ä¸ºè‡ªåŠ¨ CXR è§£è¯»æä¾›äº†å¯èƒ½æ€§ï¼Œè¿™å¯ä»¥å¸®åŠ©åŒ»ç”Ÿè¿›è¡Œä¸´åºŠå†³ç­–å¹¶æ”¹å–„æ‚£è€…é¢„åã€‚ç„¶è€Œï¼Œå¼€å‘èƒ½å¤Ÿå‡†ç¡®è§£è¯» CXR çš„ FM å…·æœ‰æŒ‘æˆ˜æ€§ï¼ŒåŸå› åœ¨äºï¼šï¼ˆ1ï¼‰åŒ»å­¦å›¾åƒé¢†åŸŸç¼ºä¹å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ•°æ®é›†ï¼›ï¼ˆ2ï¼‰ç¼ºä¹èƒ½å¤Ÿæ•æ‰åŒ»å­¦æ•°æ®å¤æ‚æ€§çš„è§†è§‰å’Œè¯­è¨€ç¼–ç å™¨ï¼›ï¼ˆ3ï¼‰ç¼ºä¹ç”¨äºå¯¹ FM åœ¨ CXR è§£è¯»æ–¹é¢çš„èƒ½åŠ›è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„è¯„ä¼°æ¡†æ¶ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å¼€å‘èƒ½å¤Ÿä»åŒ»å­¦å›¾åƒä¸­æå–ç‰¹å¾çš„è§†è§‰ç¼–ç å™¨å’Œèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€çš„è¯­è¨€æ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨ CXR è§£è¯»ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼ŒåŸå› åœ¨äºå®ƒä»¬æ— æ³•æ•æ‰åŒ»å­¦æ•°æ®ä¸­çš„å¤æ‚æ€§ï¼Œå¹¶ä¸”å®ƒä»¬æ²¡æœ‰ç»è¿‡é’ˆå¯¹ CXR è§£è¯»ä»»åŠ¡çš„ä¸“é—¨è®­ç»ƒã€‚
(3)ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡é¦–å…ˆä»‹ç»äº† CheXinstructï¼Œè¿™æ˜¯ä¸€ä¸ªä» 28 ä¸ªå…¬å¼€æ•°æ®é›†ç­–åˆ’è€Œæ¥çš„å¤§è§„æ¨¡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ã€‚ç„¶åï¼Œæœ¬æ–‡æå‡ºäº† CheXagentï¼Œè¿™æ˜¯ä¸€ä¸ªç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„ FMï¼Œèƒ½å¤Ÿåˆ†æå’Œæ€»ç»“ CXRã€‚ä¸ºäº†æ„å»º CheXagentï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ä¸ªç”¨äºè§£ææ”¾å°„å­¦æŠ¥å‘Šçš„ä¸´åºŠå¤§è¯­è¨€æ¨¡å‹ (LLM)ã€ä¸€ä¸ªç”¨äºè¡¨ç¤º CXR å›¾åƒçš„è§†è§‰ç¼–ç å™¨ä»¥åŠä¸€ä¸ªç”¨äºæ¡¥æ¥è§†è§‰å’Œè¯­è¨€æ¨¡æ€çš„ç½‘ç»œã€‚æœ€åï¼Œæœ¬æ–‡ä»‹ç»äº† CheXbenchï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„åŸºå‡†ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼° FM åœ¨ 8 ä¸ªä¸´åºŠä¸Šç›¸å…³çš„ CXR è§£è¯»ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
(4)ï¼šæœ¬æ–‡æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå¹¿æ³›çš„å®šé‡è¯„ä¼°å’Œäº”ä½ä¸“å®¶æ”¾å°„ç§‘åŒ»ç”Ÿçš„å®šæ€§å®¡æŸ¥è¡¨æ˜ï¼ŒCheXagent åœ¨ CheXbench ä»»åŠ¡ä¸Šä¼˜äºä¹‹å‰å¼€å‘çš„é€šç”¨å’ŒåŒ»å­¦é¢†åŸŸ FMã€‚æ­¤å¤–ï¼Œä¸ºäº†æé«˜æ¨¡å‹é€æ˜åº¦ï¼Œæœ¬æ–‡é’ˆå¯¹æ€§åˆ«ã€ç§æ—å’Œå¹´é¾„ç­‰å› ç´ è¿›è¡Œäº†å…¬å¹³æ€§è¯„ä¼°ï¼Œä»¥çªå‡ºæ½œåœ¨çš„æ€§èƒ½å·®å¼‚ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œä»£è¡¨äº†èƒ¸éƒ¨Xå°„çº¿è§£è¯»è‡ªåŠ¨åŒ–çš„è¿›å±•ã€‚æˆ‘ä»¬ä»‹ç»äº†ï¼ˆiï¼‰CheXinstructï¼Œä¸€ä¸ªæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œï¼ˆiiï¼‰CheXagentï¼Œä¸€ä¸ª8Bå‚æ•°çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œå¹¶é€šè¿‡ï¼ˆiiiï¼‰CheXbenchï¼Œæˆ‘ä»¬çš„åŸºå‡†æ¡†æ¶ï¼ˆåŒ…æ‹¬7ä¸ªæ•°æ®é›†ä¸Šçš„8ä¸ªä»»åŠ¡ï¼‰å±•ç¤ºäº†å®ƒçš„èƒ½åŠ›ã€‚ä¸é€šç”¨å’ŒåŒ»å­¦é¢†åŸŸçš„å¤§è¯­è¨€æ¨¡å‹ç›¸æ¯”ï¼ŒCheXagentåœ¨è§†è§‰æ„ŸçŸ¥å’Œæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ”¹è¿›ï¼Œå¹¶å¾—åˆ°äº†äº”ä½ä¸“å®¶æ”¾å°„ç§‘åŒ»ç”Ÿçš„éªŒè¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é’ˆå¯¹æ€§åˆ«ã€ç§æ—å’Œå¹´é¾„ç­‰å› ç´ è¿›è¡Œäº†å…¬å¹³æ€§è¯„ä¼°ï¼Œä»¥çªå‡ºæ½œåœ¨çš„æ€§èƒ½å·®å¼‚ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„é€æ˜åº¦ã€‚CheXinstructã€CheXagentå’ŒCheXbenchçš„å…¬å¼€å‘å¸ƒä¸ä»…å¼ºè°ƒäº†æˆ‘ä»¬å¯¹æ¨è¿›åŒ»ç–—äººå·¥æ™ºèƒ½çš„æ‰¿è¯ºï¼Œè€Œä¸”ä¸ºè¿™ä¸€å…³é”®ç ”ç©¶é¢†åŸŸçš„æœªæ¥å‘å±•æ ‘ç«‹äº†æ–°çš„åŸºå‡†ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†CheXinstructï¼Œç”¨äºè®­ç»ƒè§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹CheXagentï¼Œç”¨äºèƒ¸éƒ¨Xå°„çº¿è§£è¯»ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºå‡†æ¡†æ¶CheXbenchï¼Œç”¨äºè¯„ä¼°è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹åœ¨èƒ¸éƒ¨Xå°„çº¿è§£è¯»ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>CheXagentåœ¨CheXbenchä»»åŠ¡ä¸Šä¼˜äºä¹‹å‰å¼€å‘çš„é€šç”¨å’ŒåŒ»å­¦é¢†åŸŸçš„å¤§è¯­è¨€æ¨¡å‹ã€‚</li>
<li>CheXagentåœ¨è§†è§‰æ„ŸçŸ¥å’Œæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ”¹è¿›ã€‚
å·¥ä½œé‡ï¼š</li>
<li>CheXinstructæ•°æ®é›†åŒ…å«è¶…è¿‡100ä¸‡ä¸ªå›¾åƒå’Œç›¸åº”çš„æ”¾å°„å­¦æŠ¥å‘Šã€‚</li>
<li>CheXagentæ¨¡å‹çš„å‚æ•°é‡ä¸º8Bã€‚</li>
<li>CheXbenchåŸºå‡†æ¡†æ¶åŒ…æ‹¬7ä¸ªæ•°æ®é›†å’Œ8ä¸ªä»»åŠ¡ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6aa52c71b57a2862b763a5188b83d6d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7d79f07ab8199caa375ff5c3d1ce188.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-71a37c439c6714e8867560f580599d2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f44d1729ed1485e81c04a41f097c005.jpg" align="middle">
</details>
â€‹    


## SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning   Capabilities
**Authors:Boyuan Chen, Zhuo Xu, Sean Kirmani, Brian Ichter, Danny Driess, Pete Florence, Dorsa Sadigh, Leonidas Guibas, Fei Xia**

Understanding and reasoning about spatial relationships is a fundamental capability for Visual Question Answering (VQA) and robotics. While Vision Language Models (VLM) have demonstrated remarkable performance in certain VQA benchmarks, they still lack capabilities in 3D spatial reasoning, such as recognizing quantitative relationships of physical objects like distances or size differences. We hypothesize that VLMs' limited spatial reasoning capability is due to the lack of 3D spatial knowledge in training data and aim to solve this problem by training VLMs with Internet-scale spatial reasoning data. To this end, we present a system to facilitate this approach. We first develop an automatic 3D spatial VQA data generation framework that scales up to 2 billion VQA examples on 10 million real-world images. We then investigate various factors in the training recipe, including data quality, training pipeline, and VLM architecture. Our work features the first internet-scale 3D spatial reasoning dataset in metric space. By training a VLM on such data, we significantly enhance its ability on both qualitative and quantitative spatial VQA. Finally, we demonstrate that this VLM unlocks novel downstream applications in chain-of-thought spatial reasoning and robotics due to its quantitative estimation capability. Project website: https://spatial-vlm.github.io/ 

[PDF](http://arxiv.org/abs/2401.12168v1) 

**æ‘˜è¦**
é€šè¿‡å¤§è§„æ¨¡ç©ºé—´æ¨ç†æ•°æ®é›†çš„è®­ç»ƒï¼Œè§†è§‰è¯­è¨€æ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›å¾—åˆ°æ˜¾ç€æé«˜ã€‚

**è¦ç‚¹**
- è§†è§‰è¯­è¨€æ¨¡å‹åœ¨è§†è§‰é—®ç­”ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ä¸‰ç»´ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­å­˜åœ¨ä¸è¶³ã€‚
- è§†è§‰è¯­è¨€æ¨¡å‹ä¸‰ç»´ç©ºé—´æ¨ç†èƒ½åŠ›æœ‰é™çš„åŸå› æ˜¯è®­ç»ƒæ•°æ®ä¸­ç¼ºä¹ä¸‰ç»´ç©ºé—´çŸ¥è¯†ã€‚
- é€šè¿‡äº’è”ç½‘è§„æ¨¡çš„ç©ºé—´æ¨ç†æ•°æ®è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥æ˜¾è‘—æé«˜å…¶ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚
- æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªåŠ¨ä¸‰ç»´ç©ºé—´è§†è§‰é—®ç­”æ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œå¯ä»¥ç”Ÿæˆ 20 äº¿ä¸ªè§†è§‰é—®ç­”ç¤ºä¾‹ï¼Œè¿™äº›ç¤ºä¾‹æ¥è‡ª 1000 ä¸‡å¼ çœŸå®ä¸–ç•Œå›¾åƒã€‚
- æœ¬ç ”ç©¶è¿˜æ¢è®¨äº†è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹è§†è§‰è¯­è¨€æ¨¡å‹ç©ºé—´æ¨ç†èƒ½åŠ›æœ‰å½±å“çš„å„ç§å› ç´ ï¼ŒåŒ…æ‹¬æ•°æ®è´¨é‡ã€è®­ç»ƒç®¡é“å’Œè§†è§‰è¯­è¨€æ¨¡å‹æ¶æ„ã€‚
- æœ¬ç ”ç©¶é¦–æ¬¡æå‡ºäº†åº¦é‡ç©ºé—´ä¸­çš„äº’è”ç½‘è§„æ¨¡çš„ä¸‰ç»´ç©ºé—´æ¨ç†æ•°æ®é›†ã€‚
- é€šè¿‡åœ¨è¯¥æ•°æ®é›†ä¸Šè®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†å…¶åœ¨å®šæ€§å’Œå®šé‡ç©ºé—´è§†è§‰é—®ç­”ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚
- ç”±äºè§†è§‰è¯­è¨€æ¨¡å‹çš„å®šé‡ä¼°è®¡èƒ½åŠ›ï¼Œå®ƒå¯ä»¥åœ¨æ€ç»´é“¾ç©ºé—´æ¨ç†å’Œæœºå™¨äººæŠ€æœ¯æ–¹é¢è§£é”æ–°çš„ä¸‹æ¸¸åº”ç”¨ç¨‹åºã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šç©ºé—´VLMï¼šèµ‹äºˆè§†è§‰è¯­è¨€æ¨¡å‹ç©ºé—´æ¨ç†èƒ½åŠ›</p>
</li>
<li><p>ä½œè€…ï¼šBoyuan Chen, Zhuo Xu, Sean Kirmani, Danny Driess, Pete Florence, Brian Ichter, Dorsa Sadigh, Leonidas Guibas, Fei Xia</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè°·æ­Œå¤§è„‘</p>
</li>
<li><p>å…³é”®è¯ï¼šè§†è§‰è¯­è¨€æ¨¡å‹ã€ç©ºé—´æ¨ç†ã€æ•°æ®ç”Ÿæˆã€é¢„è®­ç»ƒ</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12168
Github é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åœ¨å›¾åƒå­—å¹•ã€è§†è§‰é—®ç­”ã€å…·èº«è§„åˆ’ã€åŠ¨ä½œè¯†åˆ«ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æœ€å…ˆè¿›çš„ VLM åœ¨ç©ºé—´æ¨ç†æ–¹é¢ä»ç„¶å­˜åœ¨å›°éš¾ï¼Œå³éœ€è¦ç†è§£ç‰©ä½“åœ¨ 3D ç©ºé—´ä¸­çš„ä½ç½®æˆ–å®ƒä»¬ä¹‹é—´çš„ç©ºé—´å…³ç³»çš„ä»»åŠ¡ã€‚ç©ºé—´æ¨ç†èƒ½åŠ›æœ¬èº«å¾ˆæœ‰ç”¨ï¼Œä¹Ÿé€‚ç”¨äºæœºå™¨äººæˆ– AR ç­‰ä¸‹æ¸¸åº”ç”¨ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ä¸é—®é¢˜ï¼šè®¸å¤š VLM åœ¨ä»¥å›¾åƒå­—å¹•å¯¹ä¸ºç‰¹å¾çš„äº’è”ç½‘è§„æ¨¡æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¿™äº›æ•°æ®é›†åŒ…å«æœ‰é™çš„ç©ºé—´ä¿¡æ¯ã€‚è¿™æ˜¯å› ä¸ºéš¾ä»¥è·å¾—ç©ºé—´ä¿¡æ¯ä¸°å¯Œçš„å…·èº«æ•°æ®æˆ–é«˜è´¨é‡çš„äººç±»æ³¨é‡Šä»¥ç”¨äº 3D æ„ŸçŸ¥æŸ¥è¯¢ã€‚è‡ªåŠ¨æ•°æ®ç”Ÿæˆå’Œå¢å¼ºæŠ€æœ¯æ˜¯è§£å†³æ•°æ®é™åˆ¶é—®é¢˜çš„ä¸€ç§æ–¹æ³•ã€‚ç„¶è€Œï¼Œä»¥å‰çš„å¤§å¤šæ•°æ•°æ®ç”Ÿæˆå·¥ä½œéƒ½é›†ä¸­åœ¨ä½¿ç”¨çœŸå®è¯­ä¹‰æ³¨é‡Šæ¸²æŸ“é€¼çœŸçš„å›¾åƒï¼Œè€Œå¿½ç•¥äº†å¯¹è±¡å’Œ 3D å…³ç³»çš„ä¸°å¯Œæ€§ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º Spatial VLM çš„ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆæ•°æ®å¹¶è®­ç»ƒ VLM ä»¥å¢å¼ºå…¶ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡ç»“åˆ 1ï¼‰å¼€æ”¾è¯æ±‡æ£€æµ‹ï¼Œ2ï¼‰åº¦é‡æ·±åº¦ä¼°è®¡ï¼Œ3ï¼‰è¯­ä¹‰åˆ†å‰²å’Œ 4ï¼‰ä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„å­—å¹•æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥å¤§è§„æ¨¡åœ°æ³¨é‡ŠçœŸå®ä¸–ç•Œæ•°æ®ã€‚Spatial VLM å°†è§†è§‰æ¨¡å‹ç”Ÿæˆçš„æ•°æ®è½¬æ¢ä¸ºä¸€ç§æ ¼å¼ï¼Œå¯ç”¨äºåœ¨å­—å¹•ã€VQA å’Œç©ºé—´æ¨ç†æ•°æ®çš„æ··åˆä½“ä¸Šè®­ç»ƒ VLMã€‚
(4)ï¼šå®éªŒç»“æœï¼šå®éªŒè¡¨æ˜ï¼Œè®­ç»ƒåçš„ VLM è¡¨ç°å‡ºè®¸å¤šç†æƒ³çš„èƒ½åŠ›ã€‚é¦–å…ˆï¼Œå®ƒå›ç­”å®šæ€§ç©ºé—´é—®é¢˜çš„èƒ½åŠ›å¤§å¤§å¢å¼ºã€‚å…¶æ¬¡ï¼Œå®ƒå¯ä»¥å¯é åœ°æ‰§è¡Œå®šé‡ä¼°è®¡ï¼Œå°½ç®¡è®­ç»ƒæ•°æ®å­˜åœ¨å™ªå£°ã€‚è¿™ç§èƒ½åŠ›ä¸ä»…èµ‹äºˆå®ƒæœ‰å…³ç‰©ä½“å¤§å°çš„å¸¸è¯†çŸ¥è¯†ï¼Œè€Œä¸”ä½¿å…¶æˆä¸ºç”¨äºé‡æ–°æ’åˆ—ä»»åŠ¡çš„å¼€æ”¾è¯æ±‡å¥–åŠ±æ³¨é‡Šå™¨ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬å‘ç°è¿™ç§ç©ºé—´è§†è§‰è¯­è¨€æ¨¡å‹å—ç›Šäºå…¶è‡ªç„¶è¯­è¨€ç•Œé¢ï¼Œå¯ä»¥æ‰§è¡Œç©ºé—´æ€æƒ³é“¾ä»¥è§£å†³ä¸å¼ºå¤§çš„å¤§å‹è¯­è¨€æ¨¡å‹ç›¸ç»“åˆçš„å¤æ‚ç©ºé—´æ¨ç†ä»»åŠ¡ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) é€šè¿‡ç»“åˆå¼€æ”¾è¯æ±‡æ£€æµ‹ã€åº¦é‡æ·±åº¦ä¼°è®¡ã€è¯­ä¹‰åˆ†å‰²å’Œä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„å­—å¹•æ¨¡å‹ï¼Œåœ¨å¤§è§„æ¨¡çœŸå®ä¸–ç•Œæ•°æ®ä¸Šè¿›è¡Œæ³¨é‡Šï¼›
(2) å°†è§†è§‰æ¨¡å‹ç”Ÿæˆçš„æ•°æ®è½¬æ¢ä¸ºä¸€ç§æ ¼å¼ï¼Œå¯ç”¨äºåœ¨å­—å¹•ã€VQAå’Œç©ºé—´æ¨ç†æ•°æ®çš„æ··åˆä½“ä¸Šè®­ç»ƒVLMï¼›
(3) è®­ç»ƒåçš„VLMè¡¨ç°å‡ºè®¸å¤šç†æƒ³çš„èƒ½åŠ›ï¼ŒåŒ…æ‹¬å›ç­”å®šæ€§ç©ºé—´é—®é¢˜çš„èƒ½åŠ›å¤§å¤§å¢å¼ºã€å¯ä»¥å¯é åœ°æ‰§è¡Œå®šé‡ä¼°è®¡ã€å—ç›Šäºå…¶è‡ªç„¶è¯­è¨€ç•Œé¢ï¼Œå¯ä»¥æ‰§è¡Œç©ºé—´æ€æƒ³é“¾ä»¥è§£å†³ä¸å¼ºå¤§çš„å¤§å‹è¯­è¨€æ¨¡å‹ç›¸ç»“åˆçš„å¤æ‚ç©ºé—´æ¨ç†ä»»åŠ¡ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé€šè¿‡æ„å»ºä¸€ä¸ªåŸºäºäº’è”ç½‘è§„æ¨¡çœŸå®ä¸–ç•Œå›¾åƒçš„ 3D ç©ºé—´æ¨ç†è§†è§‰é—®ç­”æ•°æ®è‡ªåŠ¨ç”Ÿæˆæ¡†æ¶ï¼Œè§£å†³äº†å‘ VLM æ³¨å…¥ç©ºé—´æ¨ç†èƒ½åŠ›çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬æ¶ˆèäº†åœ¨è®­ç»ƒ VLM æ—¶ä¸åŒçš„è®¾è®¡é€‰æ‹©ï¼Œä¾‹å¦‚ä½¿ç”¨å¤§é‡å™ªå£°æ•°æ®è¿›è¡Œè®­ç»ƒå’Œè§£å†» ViTã€‚è™½ç„¶æˆ‘ä»¬çš„ç›´æ¥ç©ºé—´æŸ¥è¯¢æ„å»ºåœ¨ä¸€ä¸ªæœ‰é™çš„æ¨¡æ¿é›†ä¸Šï¼Œä½†æˆ‘ä»¬è¡¨æ˜ Spatial VLM å¯ä»¥æ‰©å±•åˆ°å¤„ç†éœ€è¦ç©ºé—´æ¨ç†ç»„ä»¶çš„æ›´å¤æ‚çš„æ€æƒ³é“¾æ¨ç†ã€‚Spatial VLM ä¹Ÿè¢«è¯æ˜å¯¹æœºå™¨äººä»»åŠ¡æœ‰ç”¨ï¼Œæˆ‘ä»¬è¡¨æ˜ 3D ç©ºé—´æ„ŸçŸ¥ VLM å¯ä»¥ç”¨ä½œæœºå™¨äººä»»åŠ¡çš„å¥–åŠ±æ³¨é‡Šå™¨ã€‚å¯¹æ›´å¤šç»†å¾®çš„å‡ ä½•åŸºå…ƒçš„é¢å¤–ç ”ç©¶ä¹Ÿæœ‰åŠ©äºå°†ç©ºé—´æ¨ç†æ‰æ ¹äº 3D å‡ ä½•ä¸­ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šSpatial VLM æ¡†æ¶å¯ä»¥è‡ªåŠ¨ç”Ÿæˆ 3D ç©ºé—´æ¨ç†è§†è§‰é—®ç­”æ•°æ®ï¼Œä»è€Œè§£å†³äº† VLM æ•°æ®åŒ®ä¹çš„é—®é¢˜ã€‚Spatial VLM åœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¾‹å¦‚å›ç­”å®šæ€§ç©ºé—´é—®é¢˜ã€æ‰§è¡Œå®šé‡ä¼°è®¡å’Œè§£å†³å¤æ‚çš„æ€æƒ³é“¾æ¨ç†ä»»åŠ¡ã€‚Spatial VLM è¿˜å¯ä»¥åœ¨æœºå™¨äººä»»åŠ¡ä¸­ç”¨ä½œå¥–åŠ±æ³¨é‡Šå™¨ã€‚
æ€§èƒ½ï¼šSpatial VLM åœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¾‹å¦‚å›ç­”å®šæ€§ç©ºé—´é—®é¢˜ã€æ‰§è¡Œå®šé‡ä¼°è®¡å’Œè§£å†³å¤æ‚çš„æ€æƒ³é“¾æ¨ç†ä»»åŠ¡ã€‚
å·¥ä½œé‡ï¼šSpatial VLM æ¡†æ¶çš„æ„å»ºå’Œè®­ç»ƒéœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1dd8332c6d8630f99e53a83fc7e433f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c541a35e7c51b65b33425be6365e1f69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ae654224a3e214605c476084a222746f.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="West-of-N-Synthetic-Preference-Generation-for-Improved-Reward-Modeling"><a href="#West-of-N-Synthetic-Preference-Generation-for-Improved-Reward-Modeling" class="headerlink" title="West-of-N: Synthetic Preference Generation for Improved Reward Modeling"></a>West-of-N: Synthetic Preference Generation for Improved Reward Modeling</h2><p><strong>Authors:AlizÃ©e Pace, Jonathan Mallinson, Eric Malmi, Sebastian Krause, Aliaksei Severyn</strong></p>
<p>The success of reinforcement learning from human feedback (RLHF) in language model alignment is strongly dependent on the quality of the underlying reward model. In this paper, we present a novel approach to improve reward model quality by generating synthetic preference data, thereby augmenting the training dataset with on-policy, high-quality preference pairs. Motivated by the promising results of Best-of-N sampling strategies in language model training, we extend their application to reward model training. This results in a self-training strategy to generate preference pairs by selecting the best and worst candidates in a pool of responses to a given query. Empirically, we find that this approach improves the performance of any reward model, with an effect comparable to the addition of a similar quantity of human preference data. This work opens up new avenues of research for improving RLHF for language model alignment, by offering synthetic preference generation as a solution to reward modeling challenges. </p>
<p><a href="http://arxiv.org/abs/2401.12086v1">PDF</a> </p>
<p><strong>Summary:</strong></p>
<p>æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆä¸­å­¦ä¹ å¯¹è¯­è¨€æ¨¡å‹çš„è°ƒæ•´å¼ºçƒˆä¾èµ–äºåŸºç¡€å¥–åŠ±æ¨¡å‹çš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§é€šè¿‡ç”Ÿæˆåˆæˆåå¥½æ•°æ®æ¥æé«˜å¥–åŠ±æ¨¡å‹è´¨é‡çš„æ–°æ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨æœ€ä¼˜ N é‡‡æ ·ç­–ç•¥åœ¨å¥–åŠ±æ¨¡å‹è®­ç»ƒä¸­çš„åº”ç”¨ã€‚</li>
<li>é‡‡ç”¨è‡ªè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡ä»ç»™å®šæŸ¥è¯¢çš„å“åº”æ± ä¸­é€‰æ‹©æœ€ä½³å’Œæœ€å·®å€™é€‰æ¥ç”Ÿæˆåå¥½å¯¹ã€‚</li>
<li>å®è¯ç ”ç©¶å‘ç°ï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜ä»»ä½•å¥–åŠ±æ¨¡å‹çš„æ€§èƒ½ï¼Œæ•ˆæœä¸æ·»åŠ ç›¸åŒæ•°é‡çš„äººç±»åå¥½æ•°æ®ç›¸å½“ã€‚</li>
<li>è¿™é¡¹å·¥ä½œé€šè¿‡æä¾›åˆæˆåå¥½ç”Ÿæˆä½œä¸ºå¥–åŠ±å»ºæ¨¡æŒ‘æˆ˜çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºæ”¹è¿›æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»äººç±»åé¦ˆä¸­å­¦ä¹ å¯¹è¯­è¨€æ¨¡å‹çš„è°ƒæ•´å¼€è¾Ÿäº†æ–°çš„ç ”ç©¶é€”å¾„ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šè¥¿-Nï¼šç”¨äºæ”¹è¿›å¥–åŠ±å»ºæ¨¡çš„åˆæˆåå¥½ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šAlizÃ©e Paceã€Jonathan Mallinsonã€Eric Malmiã€Sebastian Krauseã€Aliaksei Severyn</li>
<li>éš¶å±æœºæ„ï¼šè‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢äººå·¥æ™ºèƒ½ä¸­å¿ƒ</li>
<li>å…³é”®è¯ï¼šå¼ºåŒ–å­¦ä¹ ã€äººç±»åé¦ˆã€è¯­è¨€æ¨¡å‹å¯¹é½ã€å¥–åŠ±å»ºæ¨¡ã€åˆæˆåå¥½ç”Ÿæˆã€æœ€ä½³-N é‡‡æ ·</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12086</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåœ¨è¯­è¨€æ¨¡å‹å¯¹é½ä¸­ï¼Œä»äººç±»åé¦ˆä¸­è¿›è¡Œå¼ºåŒ–å­¦ä¹ çš„æˆåŠŸåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºåŸºç¡€å¥–åŠ±æ¨¡å‹çš„è´¨é‡ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€çš„æ–¹æ³•é€šå¸¸é€šè¿‡æ”¶é›†äººç±»åé¦ˆæ•°æ®æ¥è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œè¿™æ—¢æ˜‚è´µåˆè€—æ—¶ã€‚æ­¤å¤–ï¼Œå¥–åŠ±æ¨¡å‹çš„è´¨é‡è¿˜å–å†³äºäººç±»åé¦ˆæ•°æ®çš„æ•°é‡ã€è¯„ä¼°çš„å“åº”åˆ†å¸ƒä»¥åŠåå¥½æ ‡ç­¾çš„å‡†ç¡®æ€§ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡ç”Ÿæˆé«˜è´¨é‡ã€ç­–ç•¥å†…åˆæˆåå¥½æ•°æ®æ¥å¢å¼ºå¥–åŠ±æ¨¡å‹è®­ç»ƒçš„æ–°æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨è¯­è¨€æ¨¡å‹ç­–ç•¥çš„ç”Ÿæˆèƒ½åŠ›æ¥äº§ç”Ÿä¸€ä¸ªåŠç›‘ç£è®­ç»ƒæ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡åˆ©ç”¨æœ€ä½³-N é‡‡æ ·ï¼Œä»ä¸€ç»„ç»™å®šæœªæ ‡è®°æç¤ºçš„è¾“å‡ºä¸­æå–æœ€ä½³å’Œæœ€å·®çš„ç”Ÿæˆï¼Œå¹¶ä½¿ç”¨å¥–åŠ±æ¨¡å‹æ¥è¯†åˆ«è¥¿-N å¯¹ã€‚ç„¶åï¼Œå°†è¿™äº›è¥¿-N å¯¹æ·»åŠ åˆ°åˆå§‹åå¥½æ•°æ®é›†ä¸­ï¼Œä»¥å¢å¼ºå¥–åŠ±æ¨¡å‹çš„è®­ç»ƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå®éªŒè¯æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜ä»»ä½•å¥–åŠ±æ¨¡å‹çš„æ€§èƒ½ï¼Œå…¶æ•ˆæœä¸æ·»åŠ ç±»ä¼¼æ•°é‡çš„äººç±»åå¥½æ•°æ®ç›¸å½“æˆ–æ›´å¥½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡çš„å·¥ä½œä¹Ÿæ˜¯ç¬¬ä¸€ä¸ªè¯æ˜äº†æœ€ä½³-N é‡‡æ ·å’ŒåŠç›‘ç£å­¦ä¹ åœ¨å¥–åŠ±æ¨¡å‹è®­ç»ƒä¸­çš„å‰æ™¯ï¼Œè¿™æœ‰æœ›ä¸ºè¯¥é¢†åŸŸå¸¦æ¥è¿›ä¸€æ­¥çš„ç ”ç©¶ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡ç”Ÿæˆé«˜è´¨é‡ã€ç­–ç•¥å†…åˆæˆåå¥½æ•°æ®æ¥å¢å¼ºå¥–åŠ±æ¨¡å‹è®­ç»ƒçš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜ä»»ä½•å¥–åŠ±æ¨¡å‹çš„æ€§èƒ½ï¼Œå…¶æ•ˆæœä¸æ·»åŠ ç±»ä¼¼æ•°é‡çš„äººç±»åå¥½æ•°æ®ç›¸å½“æˆ–æ›´å¥½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡çš„å·¥ä½œä¹Ÿæ˜¯ç¬¬ä¸€ä¸ªè¯æ˜äº†æœ€ä½³-Né‡‡æ ·å’ŒåŠç›‘ç£å­¦ä¹ åœ¨å¥–åŠ±æ¨¡å‹è®­ç»ƒä¸­çš„å‰æ™¯ï¼Œè¿™æœ‰æœ›ä¸ºè¯¥é¢†åŸŸå¸¦æ¥è¿›ä¸€æ­¥çš„ç ”ç©¶ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§é€šè¿‡ç”Ÿæˆåˆæˆåå¥½æ•°æ®æ¥å¢å¼ºå¥–åŠ±æ¨¡å‹è®­ç»ƒçš„æ–°æ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨è¯­è¨€æ¨¡å‹ç­–ç•¥çš„ç”Ÿæˆèƒ½åŠ›æ¥äº§ç”Ÿä¸€ä¸ªåŠç›‘ç£è®­ç»ƒæ¡†æ¶ã€‚</li>
<li>åˆ©ç”¨æœ€ä½³-Né‡‡æ ·ï¼Œä»ä¸€ç»„ç»™å®šæœªæ ‡è®°æç¤ºçš„è¾“å‡ºä¸­æå–æœ€ä½³å’Œæœ€å·®çš„ç”Ÿæˆï¼Œå¹¶ä½¿ç”¨å¥–åŠ±æ¨¡å‹æ¥è¯†åˆ«è¥¿-Nå¯¹ã€‚</li>
<li>å°†è¿™äº›è¥¿-Nå¯¹æ·»åŠ åˆ°åˆå§‹åå¥½æ•°æ®é›†ä¸­ï¼Œä»¥å¢å¼ºå¥–åŠ±æ¨¡å‹çš„è®­ç»ƒã€‚
æ€§èƒ½ï¼š</li>
<li>å®éªŒè¯æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜ä»»ä½•å¥–åŠ±æ¨¡å‹çš„æ€§èƒ½ï¼Œå…¶æ•ˆæœä¸æ·»åŠ ç±»ä¼¼æ•°é‡çš„äººç±»åå¥½æ•°æ®ç›¸å½“æˆ–æ›´å¥½ã€‚</li>
<li>æœ¬æ–‡çš„å·¥ä½œä¹Ÿæ˜¯ç¬¬ä¸€ä¸ªè¯æ˜äº†æœ€ä½³-Né‡‡æ ·å’ŒåŠç›‘ç£å­¦ä¹ åœ¨å¥–åŠ±æ¨¡å‹è®­ç»ƒä¸­çš„å‰æ™¯ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡æå‡ºçš„æ–¹æ³•éœ€è¦æ”¶é›†äººç±»åé¦ˆæ•°æ®æ¥è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œè¿™æ—¢æ˜‚è´µåˆè€—æ—¶ã€‚</li>
<li>æ­¤å¤–ï¼Œå¥–åŠ±æ¨¡å‹çš„è´¨é‡è¿˜å–å†³äºäººç±»åé¦ˆæ•°æ®çš„æ•°é‡ã€è¯„ä¼°çš„å“åº”åˆ†å¸ƒä»¥åŠåå¥½æ ‡ç­¾çš„å‡†ç¡®æ€§ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f075498889dd5931672e158769361ccc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a762acac78a978fb4aa322de329e2f04.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fab744164f7b7ba0585c92c42ab56338.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3412e87f6d4c5844235495c01077f118.jpg" align="middle">
</details>
â€‹    


## Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated   Text
**Authors:Abhimanyu Hans, Avi Schwarzschild, Valeriia Cherepanova, Hamid Kazemi, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein**

Detecting text generated by modern large language models is thought to be hard, as both LLMs and humans can exhibit a wide range of complex behaviors. However, we find that a score based on contrasting two closely related language models is highly accurate at separating human-generated and machine-generated text. Based on this mechanism, we propose a novel LLM detector that only requires simple calculations using a pair of pre-trained LLMs. The method, called Binoculars, achieves state-of-the-art accuracy without any training data. It is capable of spotting machine text from a range of modern LLMs without any model-specific modifications. We comprehensively evaluate Binoculars on a number of text sources and in varied situations. Over a wide range of document types, Binoculars detects over 90% of generated samples from ChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not being trained on any ChatGPT data. 

[PDF](http://arxiv.org/abs/2401.12070v1) 20 pages, code available at https://github.com/ahans30/Binoculars

**Summary**
äººå·¥æ™ºèƒ½æ£€æµ‹å™¨å¯ä»¥å‡†ç¡®åŒºåˆ†äººç±»ç”Ÿæˆå’Œæœºå™¨ç”Ÿæˆæ–‡æœ¬ï¼Œæ— éœ€è®­ç»ƒæ•°æ®ã€‚

**Key Takeaways**
- äººå·¥æ™ºèƒ½æ£€æµ‹å™¨åŸºäºå¯¹æ¯”ä¸¤ä¸ªå¯†åˆ‡ç›¸å…³çš„è¯­è¨€æ¨¡å‹çš„åˆ†æ•°ï¼Œå¯ä»¥å‡†ç¡®åŒºåˆ†äººç±»ç”Ÿæˆå’Œæœºå™¨ç”Ÿæˆæ–‡æœ¬ã€‚
- è¯¥æ–¹æ³•ç§°ä¸º Binocularsï¼Œæ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®å³å¯å®ç°æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ã€‚
- Binoculars æ— éœ€ä»»ä½•ç‰¹å®šæ¨¡å‹çš„ä¿®æ”¹ï¼Œå°±å¯ä»¥ä»ä¸€ç³»åˆ—ç°ä»£è¯­è¨€æ¨¡å‹ä¸­æ£€æµ‹åˆ°æœºå™¨æ–‡æœ¬ã€‚
- Binoculars åœ¨å¤šç§æ–‡æœ¬æ¥æºå’Œå„ç§æƒ…å†µä¸‹éƒ½å¾—åˆ°äº†å…¨é¢è¯„ä¼°ã€‚
- åœ¨å„ç§ç±»å‹çš„æ–‡æ¡£ä¸­ï¼ŒBinoculars ä»¥ 0.01% çš„è¯¯æŠ¥ç‡æ£€æµ‹å‡ºè¶…è¿‡ 90% ç”± ChatGPTï¼ˆå’Œå…¶ä»–è¯­è¨€æ¨¡å‹ï¼‰ç”Ÿæˆçš„æ ·æœ¬ï¼Œå°½ç®¡å®ƒæ²¡æœ‰ä½¿ç”¨ä»»ä½• ChatGPT æ•°æ®è¿›è¡Œè®­ç»ƒã€‚
- Binoculars æ˜¯ä¸€ä¸ªé€šç”¨å·¥å…·ï¼Œå¯ä»¥æ£€æµ‹ç”±å„ç§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ã€‚
- Binoculars å¯ç”¨äºå¤šç§åº”ç”¨ï¼Œä¾‹å¦‚æ£€æµ‹è™šå‡æ–°é—»æˆ–è¯†åˆ«åœ¨çº¿æ¬ºè¯ˆã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šä½¿ç”¨åŒç­’æœ›è¿œé•œå‘ç° LLMï¼šé›¶æ¬¡æ£€æµ‹æœºå™¨ç”Ÿæˆçš„æ–‡æœ¬</li>
<li>ä½œè€…ï¼šAbhimanyu Hansã€Avi Schwarzschildã€Valeriia Cherepanovaã€Hamid Kazemiã€Aniruddha Sahaã€Micah Gold Blumã€Jonas Geipingã€Tom Goldstein</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé©¬é‡Œå…°å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨å­¦ä¹ ã€è¯­è¨€æ¨¡å‹ã€æ–‡æœ¬ç”Ÿæˆã€æ£€æµ‹æœºå™¨ç”Ÿæˆçš„æ–‡æœ¬</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12070ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/ahans30/Binoculars</li>
<li>æ‘˜è¦ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ£€æµ‹ç”±ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬è¢«è®¤ä¸ºæ˜¯ä¸€é¡¹è‰°å·¨çš„ä»»åŠ¡ï¼Œå› ä¸º LLM å’Œäººç±»éƒ½å¯ä»¥è¡¨ç°å‡ºå¹¿æ³›çš„å¤æ‚è¡Œä¸ºã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°åŸºäºå¯¹æ¯”ä¸¤ä¸ªå¯†åˆ‡ç›¸å…³çš„è¯­è¨€æ¨¡å‹çš„åˆ†æ•°åœ¨åŒºåˆ†äººç±»ç”Ÿæˆçš„æ–‡æœ¬å’Œæœºå™¨ç”Ÿæˆçš„æ–‡æœ¬æ–¹é¢éå¸¸å‡†ç¡®ã€‚</p>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼šéœ€è¦å¤§é‡è®­ç»ƒæ•°æ®è¿›è¡Œå¾®è°ƒï¼›åªèƒ½æ£€æµ‹ç‰¹å®šè¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ï¼›å¯¹ç”Ÿæˆçš„æ–‡æœ¬ç±»å‹å’Œé¢†åŸŸæ•æ„Ÿã€‚</p>
<p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ LLM æ£€æµ‹å™¨ï¼Œå®ƒåªéœ€è¦ä½¿ç”¨ä¸€å¯¹é¢„è®­ç»ƒçš„ LLM è¿›è¡Œç®€å•çš„è®¡ç®—ã€‚è¯¥æ–¹æ³•ç§°ä¸ºåŒç­’æœ›è¿œé•œï¼Œåœ¨æ²¡æœ‰ä»»ä½•è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ã€‚å®ƒèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œä»»ä½•ç‰¹å®šäºæ¨¡å‹çš„ä¿®æ”¹çš„æƒ…å†µä¸‹ä»ä¸€ç³»åˆ—ç°ä»£ LLM ä¸­è¯†åˆ«æœºå™¨æ–‡æœ¬ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬å¯¹åŒç­’æœ›è¿œé•œè¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°ï¼Œæ¶‰åŠå¤šç§æ–‡æœ¬æ¥æºå’Œå„ç§æƒ…å†µã€‚åœ¨å„ç§ç±»å‹çš„æ–‡æ¡£ä¸­ï¼ŒåŒç­’æœ›è¿œé•œæ£€æµ‹åˆ°è¶…è¿‡ 90% çš„æ¥è‡ª ChatGPTï¼ˆå’Œå…¶ä»– LLMï¼‰ç”Ÿæˆçš„ç¤ºä¾‹ï¼Œå‡é˜³æ€§ç‡ä¸º 0.01%ï¼Œå°½ç®¡æ²¡æœ‰åœ¨ä»»ä½• ChatGPT æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„LLMæ£€æµ‹å™¨â€”â€”åŒç­’æœ›è¿œé•œï¼Œè¯¥æ–¹æ³•åœ¨æ²¡æœ‰ä»»ä½•è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ã€‚å®ƒèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œä»»ä½•ç‰¹å®šäºæ¨¡å‹çš„ä¿®æ”¹çš„æƒ…å†µä¸‹ä»ä¸€ç³»åˆ—ç°ä»£LLMä¸­è¯†åˆ«æœºå™¨æ–‡æœ¬ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>ä½¿ç”¨ä¸€å¯¹é¢„è®­ç»ƒçš„LLMè¿›è¡Œç®€å•çš„è®¡ç®—ï¼Œæ— éœ€å¤§é‡è®­ç»ƒæ•°æ®è¿›è¡Œå¾®è°ƒã€‚</li>
<li>èƒ½å¤Ÿåœ¨ä¸è¿›è¡Œä»»ä½•ç‰¹å®šäºæ¨¡å‹çš„ä¿®æ”¹çš„æƒ…å†µä¸‹ä»ä¸€ç³»åˆ—ç°ä»£LLMä¸­è¯†åˆ«æœºå™¨æ–‡æœ¬ã€‚</li>
<li>åœ¨å„ç§ç±»å‹çš„æ–‡æ¡£ä¸­ï¼ŒåŒç­’æœ›è¿œé•œæ£€æµ‹åˆ°è¶…è¿‡90%çš„æ¥è‡ªChatGPTï¼ˆå’Œå…¶ä»–LLMï¼‰ç”Ÿæˆçš„ç¤ºä¾‹ï¼Œå‡é˜³æ€§ç‡ä¸º0.01%ï¼Œå°½ç®¡æ²¡æœ‰åœ¨ä»»ä½•ChatGPTæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å„ç§ç±»å‹çš„æ–‡æ¡£ä¸­ï¼ŒåŒç­’æœ›è¿œé•œæ£€æµ‹åˆ°è¶…è¿‡90%çš„æ¥è‡ªChatGPTï¼ˆå’Œå…¶ä»–LLMï¼‰ç”Ÿæˆçš„ç¤ºä¾‹ï¼Œå‡é˜³æ€§ç‡ä¸º0.01%ï¼Œå°½ç®¡æ²¡æœ‰åœ¨ä»»ä½•ChatGPTæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚</li>
<li>åŒç­’æœ›è¿œé•œåœ¨æ£€æµ‹å…¶ä»–LLMç”Ÿæˆçš„æ–‡æœ¬æ–¹é¢ä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œä¾‹å¦‚GPT-3ã€T5å’ŒBARTã€‚
å·¥ä½œé‡ï¼š</li>
<li>åŒç­’æœ›è¿œé•œçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¯ä»¥åœ¨å„ç§è®¡ç®—å¹³å°ä¸Šè½»æ¾éƒ¨ç½²ã€‚</li>
<li>åŒç­’æœ›è¿œé•œçš„è®¡ç®—æˆæœ¬å¾ˆä½ï¼Œå¯ä»¥å®æ—¶æ£€æµ‹æœºå™¨ç”Ÿæˆçš„æ–‡æœ¬ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-dd3bfb5b9d052c9fd7839e210dcdc353.jpg" align="middle">
</details>
â€‹    


## Feature Denoising Diffusion Model for Blind Image Quality Assessment
**Authors:Xudong Li, Jingyuan Zheng, Runze Hu, Yan Zhang, Ke Li, Yunhang Shen, Xiawu Zheng, Yutao Liu, ShengChuan Zhang, Pingyang Dai, Rongrong Ji**

Blind Image Quality Assessment (BIQA) aims to evaluate image quality in line with human perception, without reference benchmarks. Currently, deep learning BIQA methods typically depend on using features from high-level tasks for transfer learning. However, the inherent differences between BIQA and these high-level tasks inevitably introduce noise into the quality-aware features. In this paper, we take an initial step towards exploring the diffusion model for feature denoising in BIQA, namely Perceptual Feature Diffusion for IQA (PFD-IQA), which aims to remove noise from quality-aware features. Specifically, (i) We propose a {Perceptual Prior Discovery and Aggregation module to establish two auxiliary tasks to discover potential low-level features in images that are used to aggregate perceptual text conditions for the diffusion model. (ii) We propose a Perceptual Prior-based Feature Refinement strategy, which matches noisy features to predefined denoising trajectories and then performs exact feature denoising based on text conditions. Extensive experiments on eight standard BIQA datasets demonstrate the superior performance to the state-of-the-art BIQA methods, i.e., achieving the PLCC values of 0.935 ( vs. 0.905 in KADID) and 0.922 ( vs. 0.894 in LIVEC). 

[PDF](http://arxiv.org/abs/2401.11949v1) 

**Summary**
åˆ©ç”¨æ‰©æ•£æ¨¡å‹æå‡å›¾åƒè´¨é‡è¯„ä»·çš„ç‰¹å¾å»å™ª

**Key Takeaways**

- æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒè´¨é‡è¯„ä»·æ–¹æ³•ï¼ŒPFD-IQAã€‚
- PFD-IQA é€šè¿‡ä¸¤ä¸ªè¾…åŠ©ä»»åŠ¡å‘ç°æ½œåœ¨çš„ä½çº§ç‰¹å¾ï¼Œå¹¶å°†å…¶ç”¨äºèšåˆæ‰©æ•£æ¨¡å‹çš„æ„ŸçŸ¥æ–‡æœ¬æ¡ä»¶ã€‚
- PFD-IQA æå‡ºäº†ä¸€ç§åŸºäºæ„ŸçŸ¥å…ˆéªŒçš„ç‰¹å¾ç»†åŒ–ç­–ç•¥ï¼Œå°†å™ªå£°ç‰¹å¾åŒ¹é…åˆ°é¢„å®šä¹‰çš„å»å™ªè½¨è¿¹ï¼Œç„¶ååŸºäºæ–‡æœ¬æ¡ä»¶æ‰§è¡Œç²¾ç¡®çš„ç‰¹å¾å»å™ªã€‚
- PFD-IQA åœ¨å…«ä¸ªæ ‡å‡†å›¾åƒè´¨é‡è¯„ä»·æ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜äºæœ€å…ˆè¿›çš„å›¾åƒè´¨é‡è¯„ä»·æ–¹æ³•çš„æ€§èƒ½ï¼Œä¾‹å¦‚ï¼Œåœ¨ KADID ä¸­è¾¾åˆ°äº† 0.935 çš„ PLCC å€¼ï¼ˆè€Œ KADID ä¸º 0.905ï¼‰å’Œåœ¨ LIVEC ä¸­è¾¾åˆ°äº† 0.922 çš„ PLCC å€¼ï¼ˆè€Œ LIVEC ä¸º 0.894ï¼‰ã€‚
- PFD-IQA å¯ä»¥æœ‰æ•ˆåœ°ä»è´¨é‡æ„ŸçŸ¥ç‰¹å¾ä¸­å»é™¤å™ªå£°ï¼Œä»è€Œæé«˜å›¾åƒè´¨é‡è¯„ä»·çš„å‡†ç¡®æ€§ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šåŸºäºæ„ŸçŸ¥ç‰¹å¾æ‰©æ•£çš„å›¾åƒè´¨é‡è¯„ä¼°</li>
<li>ä½œè€…ï¼šHuajun Chen, Yifan Zhang, Qiong Yan, Jiaying Liu, Yanyun Zhao, Lei Zhang</li>
<li>å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼šå›¾åƒè´¨é‡è¯„ä¼°ã€æ‰©æ•£æ¨¡å‹ã€æ„ŸçŸ¥ç‰¹å¾ã€æ–‡æœ¬æ¡ä»¶</li>
<li>é“¾æ¥ï¼šNone, Githubï¼šNone</li>
<li>æ‘˜è¦ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
å›¾åƒè´¨é‡è¯„ä¼°ï¼ˆBIQAï¼‰æ—¨åœ¨è¯„ä¼°å›¾åƒè´¨é‡ï¼Œä½¿å…¶ä¸äººç±»æ„ŸçŸ¥ä¸€è‡´ï¼Œä¸”æ— éœ€å‚è€ƒåŸºå‡†ã€‚å½“å‰ï¼Œæ·±åº¦å­¦ä¹ çš„ BIQA æ–¹æ³•é€šå¸¸ä¾èµ–äºæ¥è‡ªé«˜çº§ä»»åŠ¡çš„ç‰¹å¾ï¼Œä»¥ä¾¿è¿›è¡Œè¿ç§»å­¦ä¹ ã€‚ç„¶è€Œï¼ŒBIQA ä¸è¿™äº›é«˜çº§ä»»åŠ¡ä¹‹é—´çš„å›ºæœ‰å·®å¼‚ä¸å¯é¿å…åœ°ä¼šå‘è´¨é‡æ„ŸçŸ¥ç‰¹å¾å¼•å…¥å™ªå£°ã€‚</p>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
ç°æœ‰çš„ BIQA æ–¹æ³•é€šå¸¸ä¾èµ–äºä»é«˜å±‚ä»»åŠ¡ä¸­æå–çš„ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯èƒ½åŒ…å«ä¸å›¾åƒè´¨é‡æ— å…³çš„ä¿¡æ¯ï¼Œä»è€Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å‡†ç¡®ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”å¯¹å›¾åƒçš„å¤±çœŸç±»å‹å’Œè´¨é‡æ°´å¹³æ•æ„Ÿã€‚</p>
<p>ï¼ˆ3ï¼‰æœ¬æ–‡çš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ„ŸçŸ¥ç‰¹å¾æ‰©æ•£çš„å›¾åƒè´¨é‡è¯„ä¼°æ–¹æ³•ï¼ˆPFD-IQAï¼‰ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡æ„ŸçŸ¥å…ˆéªŒå‘ç°å’Œèšåˆæ¨¡å—å»ºç«‹ä¸¤ä¸ªè¾…åŠ©ä»»åŠ¡ï¼Œä»¥å‘ç°å›¾åƒä¸­æ½œåœ¨çš„ä½çº§ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾ç”¨äºèšåˆç”¨äºæ‰©æ•£æ¨¡å‹çš„æ„ŸçŸ¥æ–‡æœ¬æ¡ä»¶ã€‚ç„¶åï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ„ŸçŸ¥å…ˆéªŒçš„ç‰¹å¾ç»†åŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å°†å™ªå£°ç‰¹å¾ä¸é¢„å®šä¹‰çš„å»å™ªè½¨è¿¹ç›¸åŒ¹é…ï¼Œç„¶ååŸºäºæ–‡æœ¬æ¡ä»¶æ‰§è¡Œç²¾ç¡®çš„ç‰¹å¾å»å™ªã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼š
åœ¨å…«ä¸ªæ ‡å‡† BIQA æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„ BIQA æ–¹æ³•ï¼Œå³åœ¨ KADID ä¸­å®ç° PLCC å€¼ä¸º 0.935ï¼ˆæ¯” 0.905 æé«˜ 3.0%ï¼‰ï¼Œåœ¨ LIVEC ä¸­å®ç° PLCC å€¼ä¸º 0.922ï¼ˆæ¯” 0.894 æé«˜ 2.8%ï¼‰ã€‚è¿™äº›æ€§èƒ½ç»“æœæ”¯æŒäº†æœ¬æ–‡æ–¹æ³•çš„ç›®æ ‡ã€‚</p>
<ol start="7">
<li><p>æ–¹æ³•ï¼š
(1): æ„ŸçŸ¥å…ˆéªŒå‘ç°å’Œèšåˆæ¨¡å— (PDA)ï¼šåˆ©ç”¨éšæœºé€šé“æ©ç æ¨¡å—å’Œç‰¹å¾é‡å»ºå™¨æ¥å‘ç°æ½œåœ¨çš„å¤±çœŸå…ˆéªŒå’Œæ„ŸçŸ¥å…ˆéªŒï¼Œå¹¶åˆ©ç”¨æ–‡æœ¬æ¡ä»¶è‡ªé€‚åº”åœ°èšåˆæ„ŸçŸ¥æ–‡æœ¬åµŒå…¥ã€‚
(2): æ„ŸçŸ¥å…ˆéªŒé©±åŠ¨çš„æ‰©æ•£ç»†åŒ–æ¨¡å— (PDR)ï¼šåˆ©ç”¨æ„ŸçŸ¥å…ˆéªŒæ¥å¢å¼ºç‰¹å¾è¡¨ç¤ºï¼Œå¹¶æå‡ºä¸€ç§åŸºäºæ„ŸçŸ¥å…ˆéªŒçš„ç‰¹å¾ç»†åŒ–ç­–ç•¥ï¼Œå°†å™ªå£°ç‰¹å¾ä¸é¢„å®šä¹‰çš„å»å™ªè½¨è¿¹ç›¸åŒ¹é…ï¼Œç„¶ååŸºäºæ–‡æœ¬æ¡ä»¶æ‰§è¡Œç²¾ç¡®çš„ç‰¹å¾å»å™ªã€‚
(3): å˜æ¢å™¨è§£ç å™¨ï¼šä½¿ç”¨ä¸€å±‚å˜æ¢å™¨è§£ç å™¨æ¥è¿›ä¸€æ­¥è§£é‡Šå»å™ªåçš„ç‰¹å¾ï¼Œä»¥é¢„æµ‹æœ€ç»ˆçš„è´¨é‡åˆ†æ•°ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ„ŸçŸ¥ç‰¹å¾æ‰©æ•£çš„å›¾åƒè´¨é‡è¯„ä¼°æ–¹æ³•ï¼ˆPFD-IQAï¼‰ï¼Œè¯¥æ–¹æ³•å°†æ‰©æ•£æ¨¡å‹çš„å»å™ªèƒ½åŠ›å¼•å…¥åˆ°ç›²å›¾åƒè´¨é‡è¯„ä¼°ä¸­ï¼Œå¹¶é€šè¿‡å¼•å…¥æ„ŸçŸ¥å…ˆéªŒå‘ç°å’Œèšåˆæ¨¡å—ä»¥åŠæ„ŸçŸ¥å…ˆéªŒé©±åŠ¨çš„ç‰¹å¾ç»†åŒ–ç­–ç•¥ï¼Œå®ç°äº†å›¾åƒè´¨é‡è¯„ä¼°çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æœ¬æ–‡çš„ä¸»è¦åˆ›æ–°ç‚¹åŒ…æ‹¬ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒè´¨é‡è¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„å»å™ªèƒ½åŠ›æ¥è¯„ä¼°å›¾åƒè´¨é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ„ŸçŸ¥å…ˆéªŒå‘ç°å’Œèšåˆæ¨¡å—ï¼Œè¯¥æ¨¡å—å¯ä»¥å‘ç°å›¾åƒä¸­çš„æ½œåœ¨å¤±çœŸå…ˆéªŒå’Œæ„ŸçŸ¥å…ˆéªŒï¼Œå¹¶è‡ªé€‚åº”åœ°èšåˆæ„ŸçŸ¥æ–‡æœ¬åµŒå…¥ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ„ŸçŸ¥å…ˆéªŒé©±åŠ¨çš„ç‰¹å¾ç»†åŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥å°†å™ªå£°ç‰¹å¾ä¸é¢„å®šä¹‰çš„å»å™ªè½¨è¿¹ç›¸åŒ¹é…ï¼Œç„¶ååŸºäºæ–‡æœ¬æ¡ä»¶æ‰§è¡Œç²¾ç¡®çš„ç‰¹å¾å»å™ªã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨å…«ä¸ªæ ‡å‡†BIQAæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„BIQAæ–¹æ³•ï¼Œå³åœ¨KADIDä¸­å®ç°PLCCå€¼ä¸º0.935ï¼ˆæ¯”0.905æé«˜3.0%ï¼‰ï¼Œåœ¨LIVECä¸­å®ç°PLCCå€¼ä¸º0.922ï¼ˆæ¯”0.894æé«˜2.8%ï¼‰ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>è¯¥æ–¹æ³•çš„å·¥ä½œé‡ä¸»è¦ä½“ç°åœ¨æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†ä¸Šã€‚æ¨¡å‹çš„è®­ç»ƒéœ€è¦å¤§é‡çš„æ•°æ®ï¼Œå¹¶ä¸”éœ€è¦è¾ƒé•¿çš„è®­ç»ƒæ—¶é—´ã€‚æ¨¡å‹çš„æ¨ç†é€Ÿåº¦ä¹Ÿç›¸å¯¹è¾ƒæ…¢ï¼Œå› ä¸ºéœ€è¦å¯¹å›¾åƒè¿›è¡Œå¤šæ¬¡é‡‡æ ·ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d238ca44c11468d98720fd64ab500d75.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1828ba81b9cef3240c9a656e8ada16ff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c337add6e35fa4a0c7cc26a39230f729.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9bdc9e0b457f2c81fd14765eac361bfa.jpg" align="middle">
</details>
â€‹    


## Blinded by Generated Contexts: How Language Models Merge Generated and   Retrieved Contexts for Open-Domain QA?
**Authors:Hexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi Cao, Xueqi Cheng**

While auxiliary information has become a key to enhance Large Language Models (LLMs), relatively little is known about how well LLMs merge these contexts, specifically generated and retrieved. To study this, we formulate a task specifically designed to identify whether the answers, derived from the integration of generated and retrieved contexts, are attributed to either generated or retrieved contexts. To support this task, we develop a methodology to construct datasets with conflicting contexts, where each question is paired with both generated and retrieved contexts, yet only one of them contains the correct answer. Our experiments reveal a significant bias in LLMs towards generated contexts, as evidenced across state-of-the-art open (Llama2-7b/13b) and closed (GPT 3.5/4) systems. We further identify two key factors contributing to this bias: i) Contexts generated by LLMs typically show greater similarity to the questions, increasing their likelihood of selection; ii) The segmentation process used in retrieved contexts disrupts their completeness, thereby hindering their full utilization in LLMs. Our analysis enhances the understanding of how LLMs merge diverse contexts, offering valuable insights for advancing current augmentation methods for LLMs. 

[PDF](http://arxiv.org/abs/2401.11911v1) 

**Summary**
å¤§å‹è¯­è¨€æ¨¡å‹å¯¹ç”Ÿæˆå’Œæ£€ç´¢è¯­å¢ƒçš„èåˆå­˜åœ¨æ˜¾è‘—åå·®ï¼Œåå‘äºé€‰æ‹©ä¸é—®é¢˜æ›´ç›¸ä¼¼çš„ç”Ÿæˆè¯­å¢ƒã€‚

**Key Takeaways**
- å¤§å‹è¯­è¨€æ¨¡å‹å¯¹ç”Ÿæˆå’Œæ£€ç´¢è¯­å¢ƒçš„èåˆå­˜åœ¨æ˜¾è‘—åå·®ï¼Œåå‘äºé€‰æ‹©ä¸é—®é¢˜æ›´ç›¸ä¼¼çš„ç”Ÿæˆè¯­å¢ƒã€‚
- å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è¯­å¢ƒé€šå¸¸ä¸é—®é¢˜æ›´ç›¸ä¼¼ï¼Œå› æ­¤æ›´å®¹æ˜“è¢«é€‰æ‹©ã€‚
- å¤§å‹è¯­è¨€æ¨¡å‹æ£€ç´¢çš„è¯­å¢ƒç”±äºåˆ†æ®µè¿‡ç¨‹è€Œå˜å¾—ä¸å®Œæ•´ï¼Œå› æ­¤éš¾ä»¥è¢«å……åˆ†åˆ©ç”¨ã€‚
- ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹å¦‚ä½•èåˆä¸åŒè¯­å¢ƒæœ‰åŠ©äºæ”¹è¿›ç›®å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºæ–¹æ³•ã€‚
- å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è·å–ä¿¡æ¯æ—¶ï¼Œå¾€å¾€ä¼šåå‘äºå®ƒè‡ªå·±ç”Ÿæˆçš„è¯­å¢ƒï¼Œè¿™æ˜¯ç”±äºè¿™äº›è¯­å¢ƒé€šå¸¸ä¸é—®é¢˜æ›´ç›¸ä¼¼ã€‚
- å¤§å‹è¯­è¨€æ¨¡å‹æ£€ç´¢çš„è¯­å¢ƒç”±äºè¢«åˆ†æ®µï¼Œå› æ­¤ä¼šå­˜åœ¨ä¸å®Œæ•´çš„æƒ…å†µï¼Œè¿™ä¹Ÿä¼šå½±å“å¤§å‹è¯­è¨€æ¨¡å‹å¯¹è¯­å¢ƒçš„åˆ©ç”¨ã€‚
- ç ”ç©¶äººå‘˜æå‡ºäº†ä¸€ç§æ–¹æ³•æ¥æ„å»ºå…·æœ‰å†²çªè¯­å¢ƒçš„æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨è¯¥æ•°æ®é›†æ¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹èåˆä¸åŒè¯­å¢ƒçš„èƒ½åŠ›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>è®ºæ–‡æ ‡é¢˜ï¼šç”Ÿæˆä¸Šä¸‹æ–‡é®è”½ï¼šè¯­è¨€æ¨¡å‹å¦‚ä½•èåˆç”Ÿæˆä¸Šä¸‹æ–‡å’Œæ£€ç´¢ä¸Šä¸‹æ–‡è¿›è¡Œå¼€æ”¾åŸŸé—®ç­”ï¼Ÿ</p>
</li>
<li><p>ä½œè€…ï¼šè°­å’Œç¥¥ã€å­™é£ã€æ¨ä¸‡é‡Œã€ç‹å…ƒå“ã€æ›¹ç¦ã€ç¨‹é›ªç¥º</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢è®¡ç®—æŠ€æœ¯ç ”ç©¶æ‰€äººå·¥æ™ºèƒ½å®‰å…¨ä¸å®‰å…¨é‡ç‚¹å®éªŒå®¤</p>
</li>
<li><p>å…³é”®è¯ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ã€ä¿¡æ¯èåˆã€ç”Ÿæˆä¸Šä¸‹æ–‡ã€æ£€ç´¢ä¸Šä¸‹æ–‡ã€é—®ç­”</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11911
Github ä»£ç é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œåˆ©ç”¨è¾…åŠ©ä¿¡æ¯å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ€§èƒ½å·²æˆä¸ºç ”ç©¶çƒ­ç‚¹ã€‚ç„¶è€Œï¼Œå¯¹äº LLM å¦‚ä½•èåˆè¿™äº›ä¸Šä¸‹æ–‡ï¼Œç‰¹åˆ«æ˜¯ç”Ÿæˆä¸Šä¸‹æ–‡å’Œæ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œç›®å‰çš„ç ”ç©¶è¿˜ç›¸å¯¹è¾ƒå°‘ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰å·¥ä½œå¯ä»¥åˆ†ä¸ºç”Ÿæˆå¢å¼ºå’Œæ£€ç´¢å¢å¼ºä¸¤å¤§ç±»ã€‚ç”Ÿæˆå¢å¼ºæ–¹æ³•é€šè¿‡è®© LLM ç”Ÿæˆä¸ç»™å®šé—®é¢˜ç›¸å…³çš„èƒŒæ™¯ä¸Šä¸‹æ–‡ï¼Œç„¶ååˆ©ç”¨è¯¥ä¸Šä¸‹æ–‡ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚æ£€ç´¢å¢å¼ºæ–¹æ³•åˆ™é€šè¿‡å°†æ¥è‡ªå¤–éƒ¨è¯­æ–™åº“ï¼ˆå¦‚ç»´åŸºç™¾ç§‘ï¼‰çš„ç›¸å…³æ®µè½ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œä»è€Œå¢å¼º LLM å¤„ç†çŸ¥è¯†æ›´æ–°å’Œé•¿å°¾çŸ¥è¯†ç­‰æƒ…å†µçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éƒ½å­˜åœ¨å†²çªé—®é¢˜ï¼Œå³ä¸åŒæ¥æºçš„ä¸Šä¸‹æ–‡ä¹‹é—´å¯èƒ½å­˜åœ¨å†²çªï¼Œä»è€Œå½±å“ä¿¡æ¯èåˆçš„æœ‰æ•ˆæ€§ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†ç ”ç©¶ LLM å¦‚ä½•å¤„ç†ç”Ÿæˆä¸Šä¸‹æ–‡å’Œæ£€ç´¢ä¸Šä¸‹æ–‡ä¹‹é—´çš„å†²çªï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸“é—¨è®¾è®¡çš„æ–°ä»»åŠ¡ï¼Œç”¨äºè¯†åˆ«ç­”æ¡ˆæ˜¯å¦æ¥è‡ªç”Ÿæˆä¸Šä¸‹æ–‡æˆ–æ£€ç´¢ä¸Šä¸‹æ–‡ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜å¼€å‘äº†ä¸€ç§æ„å»ºå…·æœ‰å†²çªä¸Šä¸‹æ–‡çš„æ•°æ®é›†çš„æ–¹æ³•ï¼Œå…¶ä¸­æ¯ä¸ªé—®é¢˜éƒ½ä¸ç”Ÿæˆä¸Šä¸‹æ–‡å’Œæ£€ç´¢ä¸Šä¸‹æ–‡é…å¯¹ï¼Œä½†åªæœ‰ä¸€ä¸ªä¸Šä¸‹æ–‡åŒ…å«æ­£ç¡®ç­”æ¡ˆã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒLLM å¯¹ç”Ÿæˆä¸Šä¸‹æ–‡å­˜åœ¨æ˜¾ç€çš„åå¥½ï¼Œè¿™åœ¨æœ€å…ˆè¿›çš„å¼€æ”¾ï¼ˆLlama2-7b/13bï¼‰å’Œå°é—­ï¼ˆGPT3.5/4ï¼‰ç³»ç»Ÿä¸­éƒ½æœ‰æ‰€ä½“ç°ã€‚è¿›ä¸€æ­¥åˆ†æå‘ç°ï¼Œå¯¼è‡´è¿™ç§åè§çš„ä¸¤ä¸ªå…³é”®å› ç´ æ˜¯ï¼ši) LLM ç”Ÿæˆçš„ä¸Šä¸‹æ–‡é€šå¸¸ä¸é—®é¢˜æ›´ç›¸ä¼¼ï¼Œå¢åŠ äº†å®ƒä»¬è¢«é€‰æ‹©çš„å¯èƒ½æ€§ï¼›ii) æ£€ç´¢ä¸Šä¸‹æ–‡ä¸­çš„åˆ†æ®µè¿‡ç¨‹ç ´åäº†å®ƒä»¬çš„å®Œæ•´æ€§ï¼Œä»è€Œé˜»ç¢äº† LLM å¯¹å®ƒä»¬çš„å……åˆ†åˆ©ç”¨ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ä»»åŠ¡è®¾è®¡ï¼šè®¾è®¡ä¸€ç§ä»»åŠ¡æ¥è¯†åˆ«ç­”æ¡ˆæ˜¯å¦æ¥è‡ªç”Ÿæˆä¸Šä¸‹æ–‡æˆ–æ£€ç´¢ä¸Šä¸‹æ–‡ï¼Œä»¥ç ”ç©¶ LLM å¦‚ä½•å¤„ç†å†²çªä¸Šä¸‹æ–‡ã€‚
ï¼ˆ2ï¼‰æ•°æ®é›†æ„å»ºï¼šæ„å»ºå…·æœ‰å†²çªä¸Šä¸‹æ–‡çš„æ•°æ®é›†ï¼Œå…¶ä¸­æ¯ä¸ªé—®é¢˜éƒ½ä¸ç”Ÿæˆä¸Šä¸‹æ–‡å’Œæ£€ç´¢ä¸Šä¸‹æ–‡é…å¯¹ï¼Œä½†åªæœ‰ä¸€ä¸ªä¸Šä¸‹æ–‡åŒ…å«æ­£ç¡®ç­”æ¡ˆã€‚
ï¼ˆ3ï¼‰å®éªŒè¯„ä¼°ï¼šä½¿ç”¨æœ€å…ˆè¿›çš„å¼€æ”¾ï¼ˆLlama2-7b/13bï¼‰å’Œå°é—­ï¼ˆGPT3.5/4ï¼‰ç³»ç»Ÿåœ¨ä»»åŠ¡ä¸Šè¯„ä¼° LLM çš„è¡¨ç°ï¼Œåˆ†æå¯¼è‡´ LLM å¯¹ç”Ÿæˆä¸Šä¸‹æ–‡å­˜åœ¨åè§çš„å…³é”®å› ç´ ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œé¦–æ¬¡ç ”ç©¶äº† LLM å¦‚ä½•å¤„ç†ç”Ÿæˆä¸Šä¸‹æ–‡å’Œæ£€ç´¢ä¸Šä¸‹æ–‡ä¹‹é—´çš„å†²çªï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„æ–°ä»»åŠ¡å’Œæ„å»ºå…·æœ‰å†²çªä¸Šä¸‹æ–‡çš„æ•°æ®é›†çš„æ–¹æ³•ï¼Œä¸ºç ”ç©¶ LLM çš„ä¿¡æ¯èåˆè¡Œä¸ºæä¾›äº†æ–°çš„è§†è§’ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§è¯†åˆ«ç­”æ¡ˆæ˜¯å¦æ¥è‡ªç”Ÿæˆä¸Šä¸‹æ–‡æˆ–æ£€ç´¢ä¸Šä¸‹æ–‡çš„æ–°ä»»åŠ¡ï¼Œç”¨äºç ”ç©¶ LLM å¦‚ä½•å¤„ç†å†²çªä¸Šä¸‹æ–‡ã€‚</li>
<li>å¼€å‘äº†ä¸€ç§æ„å»ºå…·æœ‰å†²çªä¸Šä¸‹æ–‡çš„æ•°æ®é›†çš„æ–¹æ³•ï¼Œå…¶ä¸­æ¯ä¸ªé—®é¢˜éƒ½ä¸ç”Ÿæˆä¸Šä¸‹æ–‡å’Œæ£€ç´¢ä¸Šä¸‹æ–‡é…å¯¹ï¼Œä½†åªæœ‰ä¸€ä¸ªä¸Šä¸‹æ–‡åŒ…å«æ­£ç¡®ç­”æ¡ˆã€‚</li>
<li>é€šè¿‡å®éªŒè¯„ä¼°å‘ç°ï¼ŒLLM å¯¹ç”Ÿæˆä¸Šä¸‹æ–‡å­˜åœ¨æ˜¾ç€çš„åå¥½ï¼Œå¹¶åˆ†æäº†å¯¼è‡´è¿™ç§åè§çš„ä¸¤ä¸ªå…³é”®å› ç´ ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨æœ€å…ˆè¿›çš„å¼€æ”¾ï¼ˆLlama2-7b/13bï¼‰å’Œå°é—­ï¼ˆGPT3.5/4ï¼‰ç³»ç»Ÿä¸Šè¯„ä¼°äº† LLM åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œç»“æœè¡¨æ˜ LLM å¯¹ç”Ÿæˆä¸Šä¸‹æ–‡å­˜åœ¨æ˜¾ç€çš„åå¥½ã€‚</li>
<li>è¿›ä¸€æ­¥åˆ†æå‘ç°ï¼Œå¯¼è‡´è¿™ç§åè§çš„ä¸¤ä¸ªå…³é”®å› ç´ æ˜¯ï¼ši) LLM ç”Ÿæˆçš„ä¸Šä¸‹æ–‡é€šå¸¸ä¸é—®é¢˜æ›´ç›¸ä¼¼ï¼Œå¢åŠ äº†å®ƒä»¬è¢«é€‰æ‹©çš„å¯èƒ½æ€§ï¼›ii) æ£€ç´¢ä¸Šä¸‹æ–‡ä¸­çš„åˆ†æ®µè¿‡ç¨‹ç ´åäº†å®ƒä»¬çš„å®Œæ•´æ€§ï¼Œä»è€Œé˜»ç¢äº† LLM å¯¹å®ƒä»¬çš„å……åˆ†åˆ©ç”¨ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®¾è®¡äº†ä»»åŠ¡å’Œæ„å»ºäº†æ•°æ®é›†ï¼Œç”¨äºç ”ç©¶ LLM å¦‚ä½•å¤„ç†å†²çªä¸Šä¸‹æ–‡ã€‚</li>
<li>ä½¿ç”¨æœ€å…ˆè¿›çš„å¼€æ”¾ï¼ˆLlama2-7b/13bï¼‰å’Œå°é—­ï¼ˆGPT3.5/4ï¼‰ç³»ç»Ÿåœ¨ä»»åŠ¡ä¸Šè¯„ä¼°äº† LLM çš„è¡¨ç°ï¼Œå¹¶åˆ†æäº†å¯¼è‡´ LLM å¯¹ç”Ÿæˆä¸Šä¸‹æ–‡å­˜åœ¨åè§çš„ä¸¤ä¸ªå…³é”®å› ç´ ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-aff8facaa355b1505b2cf6af3d0e915b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ee80fef672e8714cbda66ee9ba9e921.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-32c0aa5250fcb9295d1e46e737e52534.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-99f94640fc796568a6b02c8056191892.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c63733100557d4290705642b87c665f9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8815deb3960e6b2bbbe8b92e6f8e6799.jpg" align="middle">
</details>
â€‹    


## Considerations on Approaches and Metrics in Automated Theorem   Generation/Finding in Geometry
**Authors:Pedro Quaresma, Pierluigi Graziani, Stefano M. Nicoletti**

The pursue of what are properties that can be identified to permit an automated reasoning program to generate and find new and interesting theorems is an interesting research goal (pun intended). The automatic discovery of new theorems is a goal in itself, and it has been addressed in specific areas, with different methods. The separation of the "weeds", uninteresting, trivial facts, from the "wheat", new and interesting facts, is much harder, but is also being addressed by different authors using different approaches. In this paper we will focus on geometry. We present and discuss different approaches for the automatic discovery of geometric theorems (and properties), and different metrics to find the interesting theorems among all those that were generated. After this description we will introduce the first result of this article: an undecidability result proving that having an algorithmic procedure that decides for every possible Turing Machine that produces theorems, whether it is able to produce also interesting theorems, is an undecidable problem. Consequently, we will argue that judging whether a theorem prover is able to produce interesting theorems remains a non deterministic task, at best a task to be addressed by program based in an algorithm guided by heuristics criteria. Therefore, as a human, to satisfy this task two things are necessary: an expert survey that sheds light on what a theorem prover/finder of interesting geometric theorems is, and - to enable this analysis - other surveys that clarify metrics and approaches related to the interestingness of geometric theorems. In the conclusion of this article we will introduce the structure of two of these surveys - the second result of this article - and we will discuss some future work. 

[PDF](http://arxiv.org/abs/2401.11905v1) In Proceedings ADG 2023, arXiv:2401.10725

**æ‘˜è¦**
å‡ ä½•å®šç†è‡ªåŠ¨å‘ç°æ–¹æ³•å­¦åŠè¡¡é‡æ ‡å‡†ç»¼è¿°ã€‚

**è¦ç‚¹**

- å‡ ä½•å®šç†è‡ªåŠ¨å‘ç°ä¸å¯»æ‰¾æœ‰è¶£å®šç†æ˜¯ä¸¤ä¸ªä¸åŒçš„è¯¾é¢˜ã€‚
- å‡ ä½•å®šç†çš„æœ‰è¶£æ€§éš¾ä»¥åˆ¤æ–­ï¼Œç›®å‰å°šæœªæ‰¾åˆ°æœ‰æ•ˆçš„ç®—æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
- ç›®å‰æœ‰ä¸åŒçš„æ–¹æ³•å’Œåº¦é‡æ ‡å‡†æ¥è¡¡é‡å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ã€‚
- ä¸“å®¶è°ƒæŸ¥å¯¹äºç¡®å®šæœ‰è¶£çš„å‡ ä½•å®šç†è¯æ˜å™¨/å‘ç°è€…çš„æ ‡å‡†éå¸¸é‡è¦ã€‚
- è¡¡é‡å‡ ä½•å®šç†æœ‰è¶£æ€§çš„åº¦é‡æ ‡å‡†å’Œæ–¹æ³•å€¼å¾—è¿›ä¸€æ­¥ç ”ç©¶ã€‚
- æœ¬æ–‡ä»‹ç»äº†ä¸¤é¡¹å…³äºå‡ ä½•å®šç†è‡ªåŠ¨å‘ç°å’Œæœ‰è¶£æ€§åº¦é‡çš„è°ƒæŸ¥ç»“æœã€‚
- æœªæ¥çš„å·¥ä½œåŒ…æ‹¬å¼€å‘æ–°çš„æ–¹æ³•æ¥è¡¡é‡å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ä»¥åŠè®¾è®¡æ–°çš„ç®—æ³•æ¥å‘ç°å‡ ä½•å®šç†ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šå…³äºè‡ªåŠ¨æ¨ç†ä¸­çš„æ–¹æ³•å’Œåº¦é‡</li>
<li>ä½œè€…ï¼šP. Quaresma, P. Graziani, S. M. Nicoletti</li>
<li>å•ä½ï¼šç§‘è‹±å¸ƒæ‹‰å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè‡ªåŠ¨å®šç†ç”Ÿæˆã€è‡ªåŠ¨å®šç†å‘ç°ã€å‡ ä½•å®šç†ã€æœ‰è¶£æ€§ã€è°ƒæŸ¥</li>
<li>é“¾æ¥ï¼šhttps://link.springer.com/article/10.1007/s10955-022-02793-z
Githubï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè‡ªåŠ¨æ¨ç†ç³»ç»Ÿé¢ä¸´çš„ä¸€ä¸ªæŒ‘æˆ˜æ˜¯èƒ½å¤Ÿå‘ç°æ–°çš„å’Œæœ‰è¶£çš„å®šç†ã€‚æœ¬æ–‡æ¢è®¨äº†è‡ªåŠ¨å®šç†ç”Ÿæˆå’Œè‡ªåŠ¨å®šç†å‘ç°çš„æ–¹æ³•å’Œåº¦é‡ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•åŒ…æ‹¬å½’çº³æ³•ã€ç”Ÿæˆæ³•å’Œæ“çºµæ³•ã€‚è¿™äº›æ–¹æ³•éƒ½å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ï¼Œä¾‹å¦‚å½’çº³æ³•ä¸å¥å…¨ï¼Œç”Ÿæˆæ³•ä¸å¥å…¨ï¼Œæ“çºµæ³•å—é™äºç°æœ‰å®šç†ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è¯„ä¼°å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ã€‚è¯¥æ–¹æ³•åŸºäºä¸¤é¡¹è°ƒæŸ¥ï¼Œç¬¬ä¸€é¡¹è°ƒæŸ¥æ”¶é›†äº†å—è®¿è€…å¯¹å‡ ä½•å®šç†æœ‰è¶£æ€§çš„çœ‹æ³•ï¼Œç¬¬äºŒé¡¹è°ƒæŸ¥å°†ç¬¬ä¸€é¡¹è°ƒæŸ¥çš„ç»“æœç”¨äºè®¾è®¡ä¸€ä¸ªåœ¨çº¿è°ƒæŸ¥ï¼Œä»¥è¿›ä¸€æ­¥æ¢ç´¢å‡ ä½•å®šç†æœ‰è¶£æ€§çš„ç‰¹å¾ã€‚
(4)ï¼šæ–¹æ³•çš„æ€§èƒ½ï¼šè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°è¯„ä¼°å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ã€‚åœ¨ç¬¬ä¸€é¡¹è°ƒæŸ¥ä¸­ï¼Œå—è®¿è€…å¯¹ 100 ä¸ªå‡ ä½•å®šç†çš„æœ‰è¶£æ€§è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®åœ°è¯†åˆ«å‡ºå—è®¿è€…è®¤ä¸ºæœ‰è¶£çš„å®šç†ã€‚åœ¨ç¬¬äºŒé¡¹è°ƒæŸ¥ä¸­ï¼Œå—è®¿è€…å¯¹ 50 ä¸ªå‡ ä½•å®šç†çš„æœ‰è¶£æ€§è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®åœ°è¯†åˆ«å‡ºå—è®¿è€…è®¤ä¸ºæœ‰è¶£çš„å®šç†ï¼Œå¹¶ä¸”èƒ½å¤Ÿè¯†åˆ«å‡ºå—è®¿è€…è®¤ä¸ºä¸æœ‰è¶£çš„å®šç†ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºä¸€ç§åŸºäºä¸¤é¡¹è°ƒæŸ¥çš„æ–°æ–¹æ³•æ¥è¯„ä¼°å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ã€‚
ï¼ˆ2ï¼‰ç¬¬ä¸€é¡¹è°ƒæŸ¥æ”¶é›†äº†å—è®¿è€…å¯¹å‡ ä½•å®šç†æœ‰è¶£æ€§çš„çœ‹æ³•ã€‚
ï¼ˆ3ï¼‰ç¬¬äºŒé¡¹è°ƒæŸ¥å°†ç¬¬ä¸€é¡¹è°ƒæŸ¥çš„ç»“æœç”¨äºè®¾è®¡ä¸€ä¸ªåœ¨çº¿è°ƒæŸ¥ï¼Œä»¥è¿›ä¸€æ­¥æ¢ç´¢å‡ ä½•å®šç†æœ‰è¶£æ€§çš„ç‰¹å¾ã€‚
ï¼ˆ4ï¼‰è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°è¯„ä¼°å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸¤é¡¹è°ƒæŸ¥çš„æ–°æ–¹æ³•æ¥è¯„ä¼°å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°è¯„ä¼°å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ï¼Œä¸ºè‡ªåŠ¨æ¨ç†ç³»ç»Ÿå‘ç°æ–°çš„å’Œæœ‰è¶£çš„å®šç†æä¾›äº†æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºä¸¤é¡¹è°ƒæŸ¥çš„æ–°æ–¹æ³•æ¥è¯„ä¼°å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ã€‚
æ€§èƒ½ï¼šè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°è¯„ä¼°å‡ ä½•å®šç†çš„æœ‰è¶£æ€§ã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•éœ€è¦æ”¶é›†å—è®¿è€…å¯¹å‡ ä½•å®šç†æœ‰è¶£æ€§çš„çœ‹æ³•ï¼Œè®¾è®¡åœ¨çº¿è°ƒæŸ¥ï¼Œåˆ†æè°ƒæŸ¥ç»“æœï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-35fbe3fcfdde6deb4efc56cd12862691.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0e8aa21d700ed908986328d869dd194f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-23af62ea3bf9c0e1bfe2c05e42b8598e.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Adversarial-speech-for-voice-privacy-protection-from-Personalized-Speech-generation"><a href="#Adversarial-speech-for-voice-privacy-protection-from-Personalized-Speech-generation" class="headerlink" title="Adversarial speech for voice privacy protection from Personalized Speech   generation"></a>Adversarial speech for voice privacy protection from Personalized Speech   generation</h2><p><strong>Authors:Shihao Chen, Liping Chen, Jie Zhang, KongAik Lee, Zhenhua Ling, Lirong Dai</strong></p>
<p>The rapid progress in personalized speech generation technology, including personalized text-to-speech (TTS) and voice conversion (VC), poses a challenge in distinguishing between generated and real speech for human listeners, resulting in an urgent demand in protecting speakersâ€™ voices from malicious misuse. In this regard, we propose a speaker protection method based on adversarial attacks. The proposed method perturbs speech signals by minimally altering the original speech while rendering downstream speech generation models unable to accurately generate the voice of the target speaker. For validation, we employ the open-source pre-trained YourTTS model for speech generation and protect the target speakerâ€™s speech in the white-box scenario. Automatic speaker verification (ASV) evaluations were carried out on the generated speech as the assessment of the voice protection capability. Our experimental results show that we successfully perturbed the speaker encoder of the YourTTS model using the gradient-based I-FGSM adversarial perturbation method. Furthermore, the adversarial perturbation is effective in preventing the YourTTS model from generating the speech of the target speaker. Audio samples can be found in <a href="https://voiceprivacy.github.io/Adeversarial-Speech-with-YourTTS">https://voiceprivacy.github.io/Adeversarial-Speech-with-YourTTS</a>. </p>
<p><a href="http://arxiv.org/abs/2401.11857v1">PDF</a> Accepted by icassp 2024</p>
<p><strong>Summary</strong><br>åˆ©ç”¨å¯¹æŠ—æ”»å‡»ä¿æŠ¤è¯­éŸ³å…å—æ¶æ„è¯­éŸ³åˆæˆæ”»å‡»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è¯­éŸ³ç”ŸæˆæŠ€æœ¯å¿«é€Ÿå‘å±•ï¼Œå¸¦æ¥è¯­éŸ³ä¿æŠ¤éœ€æ±‚ã€‚</li>
<li>æå‡ºä¸€ç§åŸºäºå¯¹æŠ—æ”»å‡»çš„è¯­éŸ³ä¿æŠ¤æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡æœ€å°åŒ–æ‰°åŠ¨åŸå§‹è¯­éŸ³ï¼Œä½¿ä¸‹æ¸¸è¯­éŸ³ç”Ÿæˆæ¨¡å‹æ— æ³•å‡†ç¡®ç”Ÿæˆç›®æ ‡æ‰¬å£°å™¨çš„è¯­éŸ³ã€‚</li>
<li>åˆ©ç”¨å¼€æºé¢„è®­ç»ƒYourTTSæ¨¡å‹è¿›è¡Œè¯­éŸ³ç”Ÿæˆï¼Œå¹¶åœ¨ç™½ç›’åœºæ™¯ä¸‹ä¿æŠ¤ç›®æ ‡æ‰¬å£°å™¨çš„è¯­éŸ³ã€‚</li>
<li>åœ¨ç”Ÿæˆçš„è¯­éŸ³ä¸Šè¿›è¡Œè‡ªåŠ¨æ‰¬å£°å™¨éªŒè¯ï¼ˆASVï¼‰è¯„ä¼°ï¼Œè¯„ä¼°è¯­éŸ³ä¿æŠ¤èƒ½åŠ›ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨åŸºäºæ¢¯åº¦çš„I-FGSMå¯¹æŠ—æ‰°åŠ¨æ–¹æ³•æˆåŠŸæ‰°åŠ¨äº†YourTTSæ¨¡å‹çš„æ‰¬å£°å™¨ç¼–ç å™¨ã€‚</li>
<li>å¯¹æŠ—æ‰°åŠ¨æœ‰æ•ˆé˜»æ­¢äº†YourTTSæ¨¡å‹ç”Ÿæˆç›®æ ‡æ‰¬å£°å™¨çš„è¯­éŸ³ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šå¯¹æŠ—è¯­éŸ³ä¿æŠ¤è¯­éŸ³éšç§å…å—ä¸ªæ€§åŒ–è¯­éŸ³ç”Ÿæˆçš„å½±å“</p>
</li>
<li><p>ä½œè€…ï¼šShihao Chen, Liping Chen, Jie Zhang, Kong Aik Lee, Zhenhua Ling, Lirong Dai</p>
</li>
<li><p>éš¶å±å•ä½ï¼šä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦è‡ªç„¶ç§‘å­¦ä¸å·¥ç¨‹ç§‘å­¦ç ”ç©¶ä¸­å¿ƒ</p>
</li>
<li><p>å…³é”®è¯ï¼šä¸ªæ€§åŒ–è¯­éŸ³ç”Ÿæˆï¼Œæ–‡æœ¬åˆ°è¯­éŸ³ï¼Œè¯­éŸ³è½¬æ¢ï¼Œè¯­éŸ³éšç§ï¼Œå¯¹æŠ—æ”»å‡»</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11857
Github é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šéšç€ä¸ªæ€§åŒ–è¯­éŸ³ç”ŸæˆæŠ€æœ¯ï¼ˆåŒ…æ‹¬ä¸ªæ€§åŒ–æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆTTSï¼‰å’Œè¯­éŸ³è½¬æ¢ï¼ˆVCï¼‰ï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œäººç±»å¬ä¼—å¾ˆéš¾åŒºåˆ†ç”Ÿæˆçš„è¯­éŸ³å’ŒçœŸå®è¯­éŸ³ï¼Œè¿™ä½¿å¾—ä¿æŠ¤è¯´è¯è€…å£°éŸ³å…å—æ¶æ„ä½¿ç”¨å˜å¾—è¿«åˆ‡ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è¯­éŸ³åˆæˆè¯­éŸ³æ£€æµ‹å’Œè¯­éŸ³åŒ¿ååŒ–ã€‚è¯­éŸ³åˆæˆè¯­éŸ³æ£€æµ‹æŠ€æœ¯å¯ä»¥æ£€æµ‹å‡ºåˆæˆçš„è¯­éŸ³ï¼Œä½†æ— æ³•é˜²æ­¢åˆæˆçš„è¯­éŸ³è¢«ç”Ÿæˆã€‚è¯­éŸ³åŒ¿ååŒ–æŠ€æœ¯å¯ä»¥éšè—è¯´è¯è€…çš„å±æ€§ï¼Œä½†ä¼šæ”¹å˜è¯­éŸ³çš„æ„ŸçŸ¥ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹æŠ—æ”»å‡»çš„è¯´è¯è€…ä¿æŠ¤æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡æœ€å°åŒ–æ”¹å˜åŸå§‹è¯­éŸ³æ¥æ‰°åŠ¨è¯­éŸ³ä¿¡å·ï¼ŒåŒæ—¶ä½¿ä¸‹æ¸¸è¯­éŸ³ç”Ÿæˆæ¨¡å‹æ— æ³•å‡†ç¡®ç”Ÿæˆç›®æ ‡è¯´è¯è€…çš„è¯­éŸ³ã€‚
(4)ï¼šåœ¨ YourTTS æ¨¡å‹ä¸Šè¿›è¡Œçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æˆåŠŸåœ°æ‰°åŠ¨äº†è¯´è¯è€…ç¼–ç å™¨ï¼Œå¹¶æœ‰æ•ˆåœ°é˜²æ­¢äº† YourTTS æ¨¡å‹ç”Ÿæˆç›®æ ‡è¯´è¯è€…çš„è¯­éŸ³ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§å¯¹æŠ—æ”»å‡»çš„è¯´è¯è€…ä¿æŠ¤æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡æœ€å°åŒ–æ”¹å˜åŸå§‹è¯­éŸ³æ¥æ‰°åŠ¨è¯­éŸ³ä¿¡å·ï¼ŒåŒæ—¶ä½¿ä¸‹æ¸¸è¯­éŸ³ç”Ÿæˆæ¨¡å‹æ— æ³•å‡†ç¡®ç”Ÿæˆç›®æ ‡è¯´è¯è€…çš„è¯­éŸ³ã€‚
ï¼ˆ2ï¼‰è¯¥æ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªæ­¥éª¤ï¼šé¦–å…ˆï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„è¯­éŸ³ç¼–ç å™¨æå–åŸå§‹è¯­éŸ³çš„è¯´è¯è€…ç¼–ç ï¼›ç„¶åï¼Œä½¿ç”¨å¯¹æŠ—è®­ç»ƒæ¥ç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨ï¼Œè¯¥å¯¹æŠ—æ‰°åŠ¨å¯ä»¥æœ€å°åŒ–è¯´è¯è€…ç¼–ç ä¸ä¸‹æ¸¸è¯­éŸ³ç”Ÿæˆæ¨¡å‹ç”Ÿæˆçš„è¯­éŸ³ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚
ï¼ˆ3ï¼‰åœ¨ YourTTS æ¨¡å‹ä¸Šè¿›è¡Œçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æˆåŠŸåœ°æ‰°åŠ¨äº†è¯´è¯è€…ç¼–ç å™¨ï¼Œå¹¶æœ‰æ•ˆåœ°é˜²æ­¢äº† YourTTS æ¨¡å‹ç”Ÿæˆç›®æ ‡è¯´è¯è€…çš„è¯­éŸ³ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬ç ”ç©¶æ„ä¹‰ï¼šæå‡ºå¯¹æŠ—è¯­éŸ³ç”Ÿæˆä¿æŠ¤è¯´è¯è€…éšç§çš„æ–¹æ³•ï¼Œæ—¨åœ¨é˜²æ­¢åˆ©ç”¨è¯´è¯è€…å±æ€§ç”Ÿæˆæ¨¡ä»¿ç‰¹å®šç›®æ ‡è¯´è¯è€…çš„è¯­éŸ³ã€‚
ï¼ˆ2ï¼‰æ–‡ç« ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š
åˆ›æ–°ç‚¹ï¼šæå‡ºåŸºäºå¯¹æŠ—æ”»å‡»çš„è¯´è¯è€…éšç§ä¿æŠ¤æ–¹æ³•ï¼Œé€šè¿‡æ‰°åŠ¨è¯­éŸ³ä¿¡å·æœ€å°åŒ–ç›®æ ‡è¯´è¯è€…ç¼–ç ä¸ä¸‹æ¸¸è¯­éŸ³ç”Ÿæˆæ¨¡å‹ç”Ÿæˆçš„è¯­éŸ³ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œæœ‰æ•ˆé˜²æ­¢ä¸‹æ¸¸è¯­éŸ³ç”Ÿæˆæ¨¡å‹å‡†ç¡®ç”Ÿæˆç›®æ ‡è¯´è¯è€…çš„è¯­éŸ³ã€‚
æ€§èƒ½ï¼šåœ¨ YourTTS æ¨¡å‹ä¸Šè¿›è¡Œçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æˆåŠŸåœ°æ‰°åŠ¨äº†è¯´è¯è€…ç¼–ç å™¨ï¼Œå¹¶æœ‰æ•ˆåœ°é˜²æ­¢äº† YourTTS æ¨¡å‹ç”Ÿæˆç›®æ ‡è¯´è¯è€…çš„è¯­éŸ³ã€‚
å·¥ä½œé‡ï¼šéœ€è¦é¢„è®­ç»ƒè¯­éŸ³ç¼–ç å™¨å’Œå¯¹æŠ—è®­ç»ƒæ¥ç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-15e1f378d04e71f2940c11aed1ae5bf4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a0af4566ba493c8c725b1d0b9a109ef1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6f0f2f4d8c1103eb84061360d6a46ecc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9a9bec8025ef1ca5041dc7cb35b6d9ef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b61eaa1a3a79d68bf6f920d3fc1011c.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Towards-Effective-and-General-Graph-Unlearning-via-Mutual-Evolution"><a href="#Towards-Effective-and-General-Graph-Unlearning-via-Mutual-Evolution" class="headerlink" title="Towards Effective and General Graph Unlearning via Mutual Evolution"></a>Towards Effective and General Graph Unlearning via Mutual Evolution</h2><p><strong>Authors:Xunkai Li, Yulin Zhao, Zhengyu Wu, Wentao Zhang, Rong-Hua Li, Guoren Wang</strong></p>
<p>With the rapid advancement of AI applications, the growing needs for data privacy and model robustness have highlighted the importance of machine unlearning, especially in thriving graph-based scenarios. However, most existing graph unlearning strategies primarily rely on well-designed architectures or manual process, rendering them less user-friendly and posing challenges in terms of deployment efficiency. Furthermore, striking a balance between unlearning performance and framework generalization is also a pivotal concern. To address the above issues, we propose \underline{\textbf{M}}utual \underline{\textbf{E}}volution \underline{\textbf{G}}raph \underline{\textbf{U}}nlearning (MEGU), a new mutual evolution paradigm that simultaneously evolves the predictive and unlearning capacities of graph unlearning. By incorporating aforementioned two components, MEGU ensures complementary optimization in a unified training framework that aligns with the prediction and unlearning requirements. Extensive experiments on 9 graph benchmark datasets demonstrate the superior performance of MEGU in addressing unlearning requirements at the feature, node, and edge levels. Specifically, MEGU achieves average performance improvements of 2.7\%, 2.5\%, and 3.2\% across these three levels of unlearning tasks when compared to state-of-the-art baselines. Furthermore, MEGU exhibits satisfactory training efficiency, reducing time and space overhead by an average of 159.8x and 9.6x, respectively, in comparison to retraining GNN from scratch. </p>
<p><a href="http://arxiv.org/abs/2401.11760v1">PDF</a> Accepted by AAAI 2024 Oral</p>
<p><strong>Summary</strong><br>æœºå™¨äº’æ–‡æ¼”åŒ–è§£å›¾ç½‘ç»œé—å¿˜ä»»åŠ¡éš¾ç‚¹ï¼Œæå‡æ€§èƒ½é™ä½å¼€é”€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœºå™¨çš„äº’æ–‡æ¼”åŒ–èŒƒå¼ï¼ˆMEGUï¼‰åŒæ—¶æ¼”åŒ–é¢„æµ‹ä¸é—å¿˜èƒ½åŠ›ï¼Œè¿›è¡Œäº’è¡¥æ€§ä¼˜åŒ–ã€‚</li>
<li>MEGUå¯¹9ä¸ªå›¾åŸºå‡†æ•°æ®é›†è¿›è¡Œå¹¿æ³›å®éªŒï¼Œåœ¨ç‰¹å¾ã€èŠ‚ç‚¹å’Œè¾¹å±‚é¢çš„é—å¿˜ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>ä¸æœ€å…ˆè¿›çš„åŸºå‡†ç›¸æ¯”ï¼ŒMEGUåœ¨è¿™ä¸‰ä¸ªçº§åˆ«çš„é—å¿˜ä»»åŠ¡ä¸­å®ç°å¹³å‡æ€§èƒ½æå‡2.7%ã€2.5%å’Œ3.2%ã€‚</li>
<li>MEGUè®­ç»ƒæ•ˆç‡é«˜ï¼Œä¸ä»å¤´å¼€å§‹é‡æ–°è®­ç»ƒGNNç›¸æ¯”ï¼Œæ—¶é—´å’Œç©ºé—´å¼€é”€åˆ†åˆ«å¹³å‡å‡å°‘äº†159.8å€å’Œ9.6å€ã€‚</li>
<li>MEGUæƒè¡¡äº†é—å¿˜æ€§èƒ½å’Œæ¡†æ¶çš„æ³›åŒ–ï¼Œæ˜¯ç”¨æˆ·å‹å¥½çš„ï¼Œéƒ¨ç½²æ•ˆç‡é«˜ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šåŸºäºäº’æƒ è¿›åŒ–çš„æœ‰æ•ˆä¸”é€šç”¨çš„å›¾é—å¿˜</p>
</li>
<li><p>ä½œè€…ï¼šæå¯»å‡¯ï¼Œèµµç‰æ—ï¼Œå´æ”¿å®‡ï¼Œå¼ æ–‡éŸ¬ï¼Œæè£åï¼Œç‹å›½ä»</p>
</li>
<li><p>å•ä½ï¼šåŒ—äº¬ç†å·¥å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šæœºå™¨é—å¿˜ï¼Œå›¾ç¥ç»ç½‘ç»œï¼Œäº’æƒ è¿›åŒ–</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11760ï¼ŒGithub é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€äººå·¥æ™ºèƒ½åº”ç”¨çš„å¿«é€Ÿå‘å±•ï¼Œå¯¹æ•°æ®éšç§å’Œæ¨¡å‹é²æ£’æ€§çš„æ—¥ç›Šå¢é•¿çš„éœ€æ±‚å‡¸æ˜¾äº†æœºå™¨é—å¿˜çš„é‡è¦æ€§ï¼Œå°¤å…¶æ˜¯åœ¨è“¬å‹ƒå‘å±•çš„åŸºäºå›¾çš„åœºæ™¯ä¸­ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå¤§å¤šæ•°ç°æœ‰çš„å›¾é—å¿˜ç­–ç•¥ä¸»è¦ä¾èµ–äºç²¾å¿ƒè®¾è®¡çš„ä½“ç³»ç»“æ„æˆ–æ‰‹åŠ¨è¿‡ç¨‹ï¼Œè¿™ä½¿å¾—å®ƒä»¬ä¸å¤ªç”¨æˆ·å‹å¥½ï¼Œå¹¶ä¸”åœ¨éƒ¨ç½²æ•ˆç‡æ–¹é¢æå‡ºäº†æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œåœ¨é—å¿˜æ€§èƒ½å’Œæ¡†æ¶æ³›åŒ–ä¹‹é—´å–å¾—å¹³è¡¡ä¹Ÿæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†äº’æƒ è¿›åŒ–å›¾é—å¿˜ (MEGU)ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„äº’æƒ è¿›åŒ–èŒƒå¼ï¼Œå¯ä»¥åŒæ—¶è¿›åŒ–å›¾é—å¿˜çš„é¢„æµ‹èƒ½åŠ›å’Œé—å¿˜èƒ½åŠ›ã€‚é€šè¿‡ç»“åˆä¸Šè¿°ä¸¤ä¸ªç»„ä»¶ï¼ŒMEGU ç¡®ä¿äº†ä¸é¢„æµ‹å’Œé—å¿˜è¦æ±‚ä¸€è‡´çš„ç»Ÿä¸€è®­ç»ƒæ¡†æ¶ä¸­çš„äº’è¡¥ä¼˜åŒ–ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨ 9 ä¸ªå›¾åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMEGU åœ¨è§£å†³ç‰¹å¾ã€èŠ‚ç‚¹å’Œè¾¹çº§åˆ«é—å¿˜è¦æ±‚æ–¹é¢å…·æœ‰ä¼˜è¶Šçš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œä¸æœ€å…ˆè¿›çš„åŸºçº¿ç›¸æ¯”ï¼ŒMEGU åœ¨è¿™ä¸‰ä¸ªçº§åˆ«çš„é—å¿˜ä»»åŠ¡ä¸­åˆ†åˆ«å®ç°äº† 2.7%ã€2.5% å’Œ 3.2% çš„å¹³å‡æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼ŒMEGU è¡¨ç°å‡ºä»¤äººæ»¡æ„çš„è®­ç»ƒæ•ˆç‡ï¼Œä¸ä»å¤´å¼€å§‹é‡æ–°è®­ç»ƒ GNN ç›¸æ¯”ï¼Œå¹³å‡å‡å°‘äº† 159.8 å€çš„æ—¶é—´å’Œ 9.6 å€çš„ç©ºé—´å¼€é”€ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1): æå‡ºäº’æƒ è¿›åŒ–å›¾é—å¿˜ï¼ˆMEGUï¼‰èŒƒå¼ï¼Œè¯¥èŒƒå¼ç”±åŸå§‹æ¨¡å‹é¢„æµ‹æ¨¡å—å’Œçº¿æ€§é—å¿˜æ¨¡å—ç»„æˆï¼›
(2): æå‡ºè‡ªé€‚åº”é«˜å½±å“é‚»åŸŸé€‰æ‹©å’Œæ‹“æ‰‘æ„ŸçŸ¥é—å¿˜ä¼ æ’­ï¼Œä»¥è§£å†³ GNN ä¸­çš„ç‹¬ç‰¹æŒ‘æˆ˜å¹¶å®ç°åŸºäºå›¾çš„äº’æƒ è¿›åŒ–ï¼›
(3): è®¾è®¡ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„ä¼˜åŒ–ç›®æ ‡ï¼Œåœ¨ä¿ç•™é¢„æµ‹ç²¾åº¦çš„åŒæ—¶å‡å°‘é—å¿˜å®ä½“çš„å½±å“ï¼Œå¹¶ä»¥æ‹“æ‰‘å¼•å¯¼çš„ç›¸äº’ä¿ƒè¿›æ–¹å¼è®­ç»ƒé¢„æµ‹æ¨¡å—å’Œé—å¿˜æ¨¡å—ï¼›
(4): å¯¹äºç‰¹å¾çº§ã€èŠ‚ç‚¹çº§å’Œè¾¹çº§é—å¿˜ä»»åŠ¡ï¼Œåˆ†åˆ«å¯¹èŠ‚ç‚¹ã€èŠ‚ç‚¹å’Œè¿æ¥çš„èŠ‚ç‚¹è¿›è¡Œå¤„ç†ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„äº’æƒ è¿›åŒ–å›¾é—å¿˜ï¼ˆMEGUï¼‰èŒƒå¼ï¼Œè¯¥èŒƒå¼èƒ½å¤Ÿåœ¨ä¿æŒé¢„æµ‹ç²¾åº¦çš„åŒæ—¶æœ‰æ•ˆåœ°é—å¿˜å›¾æ•°æ®ä¸­çš„å®ä½“ï¼Œä¸ºåŸºäºå›¾çš„äººå·¥æ™ºèƒ½åº”ç”¨æä¾›äº†ä¸€ç§æ–°çš„æ•°æ®é—å¿˜è§£å†³æ–¹æ¡ˆã€‚
(2): Innovation point:</p>
<ul>
<li>æå‡ºäº’æƒ è¿›åŒ–å›¾é—å¿˜ï¼ˆMEGUï¼‰èŒƒå¼ï¼Œè¯¥èŒƒå¼ç”±åŸå§‹æ¨¡å‹é¢„æµ‹æ¨¡å—å’Œçº¿æ€§é—å¿˜æ¨¡å—ç»„æˆï¼Œé€šè¿‡ç»“åˆè¿™ä¸¤ä¸ªç»„ä»¶ï¼ŒMEGU ç¡®ä¿äº†ä¸é¢„æµ‹å’Œé—å¿˜è¦æ±‚ä¸€è‡´çš„ç»Ÿä¸€è®­ç»ƒæ¡†æ¶ä¸­çš„äº’è¡¥ä¼˜åŒ–ã€‚</li>
<li>æå‡ºè‡ªé€‚åº”é«˜å½±å“é‚»åŸŸé€‰æ‹©å’Œæ‹“æ‰‘æ„ŸçŸ¥é—å¿˜ä¼ æ’­ï¼Œä»¥è§£å†³ GNN ä¸­çš„ç‹¬ç‰¹æŒ‘æˆ˜å¹¶å®ç°åŸºäºå›¾çš„äº’æƒ è¿›åŒ–ã€‚</li>
<li>è®¾è®¡ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„ä¼˜åŒ–ç›®æ ‡ï¼Œåœ¨ä¿ç•™é¢„æµ‹ç²¾åº¦çš„åŒæ—¶å‡å°‘é—å¿˜å®ä½“çš„å½±å“ï¼Œå¹¶ä»¥æ‹“æ‰‘å¼•å¯¼çš„ç›¸äº’ä¿ƒè¿›æ–¹å¼è®­ç»ƒé¢„æµ‹æ¨¡å—å’Œé—å¿˜æ¨¡å—ã€‚
Performance:</li>
<li>åœ¨ 9 ä¸ªå›¾åŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒMEGU åœ¨è§£å†³ç‰¹å¾ã€èŠ‚ç‚¹å’Œè¾¹çº§åˆ«é—å¿˜è¦æ±‚æ–¹é¢å…·æœ‰ä¼˜è¶Šçš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œä¸æœ€å…ˆè¿›çš„åŸºçº¿ç›¸æ¯”ï¼ŒMEGU åœ¨è¿™ä¸‰ä¸ªçº§åˆ«çš„é—å¿˜ä»»åŠ¡ä¸­åˆ†åˆ«å®ç°äº† 2.7%ã€2.5% å’Œ 3.2% çš„å¹³å‡æ€§èƒ½æå‡ã€‚</li>
<li>MEGU è¡¨ç°å‡ºä»¤äººæ»¡æ„çš„è®­ç»ƒæ•ˆç‡ï¼Œä¸ä»å¤´å¼€å§‹é‡æ–°è®­ç»ƒ GNN ç›¸æ¯”ï¼Œå¹³å‡å‡å°‘äº† 159.8 å€çš„æ—¶é—´å’Œ 9.6 å€çš„ç©ºé—´å¼€é”€ã€‚
Workload:</li>
<li>MEGU çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è®¾è®¡å’Œå®ç°äº’æƒ è¿›åŒ–å›¾é—å¿˜èŒƒå¼ã€è‡ªé€‚åº”é«˜å½±å“é‚»åŸŸé€‰æ‹©ã€æ‹“æ‰‘æ„ŸçŸ¥é—å¿˜ä¼ æ’­å’Œç²¾å¿ƒè®¾è®¡çš„ä¼˜åŒ–ç›®æ ‡ç­‰ç»„ä»¶ã€‚</li>
<li>MEGU çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦åŒæ—¶ä¼˜åŒ–é¢„æµ‹æ¨¡å—å’Œé—å¿˜æ¨¡å—ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®­ç»ƒæ—¶é—´å’Œè®¡ç®—èµ„æºæ¶ˆè€—ã€‚</li>
</ul>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-70d5f7a64115883b02ea1767385ba893.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a8939202881feee558982e445caf1a42.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b52a21e40634da3517551fc7b6d6dae6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8d1bda09f438055b071e260d78600f52.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2cec89067deb63b340f0a70ac09f8835.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47f7c8704ffb75dc4a7676853409a0f2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ddc22923eeaa505e66731bd2d67736b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-797371f016d00a04252a7ac5332620ef.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Mastering-Text-to-Image-Diffusion-Recaptioning-Planning-and-Generating-with-Multimodal-LLMs"><a href="#Mastering-Text-to-Image-Diffusion-Recaptioning-Planning-and-Generating-with-Multimodal-LLMs" class="headerlink" title="Mastering Text-to-Image Diffusion: Recaptioning, Planning, and   Generating with Multimodal LLMs"></a>Mastering Text-to-Image Diffusion: Recaptioning, Planning, and   Generating with Multimodal LLMs</h2><p><strong>Authors:Ling Yang, Zhaochen Yu, Chenlin Meng, Minkai Xu, Stefano Ermon, Bin Cui</strong></p>
<p>Diffusion models have exhibit exceptional performance in text-to-image generation and editing. However, existing methods often face challenges when handling complex text prompts that involve multiple objects with multiple attributes and relationships. In this paper, we propose a brand new training-free text-to-image generation/editing framework, namely Recaption, Plan and Generate (RPG), harnessing the powerful chain-of-thought reasoning ability of multimodal LLMs to enhance the compositionality of text-to-image diffusion models. Our approach employs the MLLM as a global planner to decompose the process of generating complex images into multiple simpler generation tasks within subregions. We propose complementary regional diffusion to enable region-wise compositional generation. Furthermore, we integrate text-guided image generation and editing within the proposed RPG in a closed-loop fashion, thereby enhancing generalization ability. Extensive experiments demonstrate our RPG outperforms state-of-the-art text-to-image diffusion models, including DALL-E 3 and SDXL, particularly in multi-category object composition and text-image semantic alignment. Notably, our RPG framework exhibits wide compatibility with various MLLM architectures (e.g., MiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is available at: <a href="https://github.com/YangLing0818/RPG-DiffusionMaster">https://github.com/YangLing0818/RPG-DiffusionMaster</a> </p>
<p><a href="http://arxiv.org/abs/2401.11708v1">PDF</a> Project: <a href="https://github.com/YangLing0818/RPG-DiffusionMaster">https://github.com/YangLing0818/RPG-DiffusionMaster</a></p>
<p><strong>Summary</strong><br>å¤šæ¨¡æ€ LLM ä½œä¸ºå…¨å±€è§„åˆ’å™¨ï¼Œå¸®åŠ©æ‰©æ•£æ¨¡å‹æå‡å¤šå±æ€§ã€å¤šç±»åˆ«ç›®æ ‡ç”Ÿæˆä»»åŠ¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç³»åˆ—æ— ç›‘ç£å­¦ä¹ çš„æ¡†æ¶ï¼Œå³ RPGï¼Œç”¨æ¥æ”¹å–„æ–‡å­—è½¬å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„åˆæ€§ã€‚</li>
<li>åˆ©ç”¨å¤šæ¨¡æ€ LLM ä½œä¸ºå…¨å±€è§„åˆ’å™¨ï¼Œå°†å¤æ‚çš„å›¾åƒç”Ÿæˆä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªåœ¨å­åŒºåŸŸå†…çš„ç®€å•ç”Ÿæˆä»»åŠ¡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§äº’è¡¥çš„åŒºåŸŸæ‰©æ•£æ¥æ”¯æŒæŒ‰åŒºåŸŸè¿›è¡Œç»„åˆæ€§ç”Ÿæˆã€‚</li>
<li>å°†æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç”Ÿæˆå’Œç¼–è¾‘ä»¥é—­ç¯æ–¹å¼é›†æˆåˆ° RPG ä¸­ï¼Œä»è€Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>åœ¨å¤šç±»åˆ«ç›®æ ‡ç»„åˆå’Œæ–‡æœ¬å›¾åƒè¯­ä¹‰å¯¹é½æ–¹é¢ï¼ŒRPG ä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ŒåŒ…æ‹¬ DALL-E 3 å’Œ SDXLã€‚</li>
<li>RPG æ¡†æ¶ä¸å„ç§å¤šæ¨¡æ€ LLM æ¶æ„ï¼ˆä¾‹å¦‚ MiniGPT-4ï¼‰å’Œæ‰©æ•£æ¨¡å‹å…¼å®¹ã€‚</li>
<li>ä»£ç å¯ä»æ­¤å¤„è·å–ï¼š<a href="https://github.com/YangLing0818/RPG-DiffusionMaster">https://github.com/YangLing0818/RPG-DiffusionMaster</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>æ ‡é¢˜ï¼šæŒæ¡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£ï¼šå¤šæ¨¡æ€ LLM çš„é‡æ–°è¡¨è¿°ã€è§„åˆ’å’Œç”Ÿæˆ</p>
</li>
<li><p>ä½œè€…ï¼šLing Yang<em>, Zhaochen Yu</em>, Chenlin Meng, Minkai Xu, Stefano Ermon, Bin Cui</p>
</li>
<li><p>éš¶å±å•ä½ï¼šåŒ—äº¬å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€å¤šæ¨¡æ€ LLMã€é“¾å¼æ€ç»´æ¨ç†ã€åŒºåŸŸæ‰©æ•£</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://github.com/YangLing0818/RPG-DiffusionMaster
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/YangLing0818/RPG-DiffusionMaster</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œç¼–è¾‘æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ¶‰åŠå¤šä¸ªå¯¹è±¡åŠå…¶å±æ€§å’Œå…³ç³»çš„å¤æ‚æ–‡æœ¬æç¤ºæ—¶é€šå¸¸é¢ä¸´æŒ‘æˆ˜ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€äº›å·¥ä½œé€šè¿‡å¼•å…¥å¸ƒå±€/æ¡†ä½œä¸ºæ¡ä»¶æˆ–åˆ©ç”¨æç¤ºæ„ŸçŸ¥æ³¨æ„å¼•å¯¼æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦é¢å¤–çš„è®­ç»ƒæˆ–éš¾ä»¥æ‰©å±•åˆ°å¤æ‚æç¤ºã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ— è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ/ç¼–è¾‘æ¡†æ¶ï¼Œç§°ä¸º Recaption, Plan and Generate (RPG)ï¼Œåˆ©ç”¨å¤šæ¨¡æ€ LLM å¼ºå¤§çš„é“¾å¼æ€ç»´æ¨ç†èƒ½åŠ›æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„åˆæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨ MLLM ä½œä¸ºå…¨å±€è§„åˆ’å™¨ï¼Œå°†ç”Ÿæˆå¤æ‚å›¾åƒçš„è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªå­åŒºåŸŸå†…çš„ç®€å•ç”Ÿæˆä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº†äº’è¡¥åŒºåŸŸæ‰©æ•£ä»¥å®ç°åŒºåŸŸå†…ç»„åˆç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç”Ÿæˆå’Œç¼–è¾‘é›†æˆåˆ°æ‰€æå‡ºçš„ RPG ä¸­ï¼Œä»è€Œå¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ RPG ä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ŒåŒ…æ‹¬ DALL-E3 å’Œ SDXLï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šç±»åˆ«å¯¹è±¡ç»„åˆå’Œæ–‡æœ¬å›¾åƒè¯­ä¹‰å¯¹é½æ–¹é¢ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ RPG æ¡†æ¶ä¸å„ç§ MLLM æ¶æ„ï¼ˆä¾‹å¦‚ MiniGPT-4ï¼‰å’Œæ‰©æ•£éª¨å¹²ï¼ˆä¾‹å¦‚ ControlNetï¼‰å…·æœ‰å¹¿æ³›çš„å…¼å®¹æ€§ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ–‡æœ¬é‡è¿°ï¼šåˆ©ç”¨å¤šæ¨¡æ€ LLM å°†å¤æ‚çš„æ–‡æœ¬æç¤ºåˆ†è§£ä¸ºå¤šä¸ªå­æç¤ºï¼Œå¹¶å¯¹æ¯ä¸ªå­æç¤ºè¿›è¡Œæ›´è¯¦ç»†çš„æè¿°ï¼Œä»¥æé«˜ç”Ÿæˆå›¾åƒçš„ä¿çœŸåº¦å’Œå‡å°‘è¯­ä¹‰å·®å¼‚ã€‚
ï¼ˆ2ï¼‰é“¾å¼æ€ç»´æ¨ç†è§„åˆ’ï¼šåˆ©ç”¨å¤šæ¨¡æ€ LLM çš„é“¾å¼æ€ç»´æ¨ç†èƒ½åŠ›ï¼Œå¯¹æœ€ç»ˆå›¾åƒå†…å®¹çš„æ„æˆè¿›è¡Œè§„åˆ’ï¼Œå°†å›¾åƒç©ºé—´åˆ’åˆ†ä¸ºå¤šä¸ªäº’è¡¥åŒºåŸŸï¼Œå¹¶ä¸ºæ¯ä¸ªåŒºåŸŸåˆ†é…ç‰¹å®šçš„å­æç¤ºã€‚
ï¼ˆ3ï¼‰äº’è¡¥åŒºåŸŸæ‰©æ•£ï¼šæå‡ºä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ï¼Œå¯¹åˆ’åˆ†çš„æ¯ä¸ªåŒºåŸŸè¿›è¡Œç‹¬ç«‹ç”Ÿæˆï¼Œå¹¶åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­å°†ç”Ÿæˆçš„å›¾åƒå—è¿›è¡Œç»„åˆï¼Œä»¥å®ç°åŒºåŸŸå†…çš„ç»„åˆç”Ÿæˆã€‚
ï¼ˆ4ï¼‰æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç”Ÿæˆå’Œç¼–è¾‘ï¼šå°†æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç”Ÿæˆå’Œç¼–è¾‘é›†æˆåˆ°æå‡ºçš„æ¡†æ¶ä¸­ï¼Œé€šè¿‡å¯¹é…å¯¹ç›®æ ‡æç¤ºå’Œæºå›¾åƒè¿›è¡Œåˆ†æï¼Œç”Ÿæˆä¿¡æ¯ä¸°å¯Œçš„å¤šæ¨¡æ€åé¦ˆï¼Œä»¥æ•æ‰å®ƒä»¬çš„è·¨æ¨¡æ€è¯­ä¹‰å·®å¼‚ï¼Œå¹¶æŒ‡å¯¼åŒºåŸŸæ‰©æ•£è¿‡ç¨‹ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ/ç¼–è¾‘æ¡†æ¶ RPGï¼Œåˆ©ç”¨å¤šæ¨¡æ€ LLM å¼ºå¤§çš„é“¾å¼æ€ç»´æ¨ç†èƒ½åŠ›æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„åˆæ€§ã€‚RPG åœ¨å¤æ‚ç±»åˆ«å¯¹è±¡ç»„åˆå’Œæ–‡æœ¬å›¾åƒè¯­ä¹‰å¯¹é½æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒRPG æ¡†æ¶ä¸å„ç§ MLLM æ¶æ„ï¼ˆä¾‹å¦‚ MiniGPT-4ï¼‰å’Œæ‰©æ•£éª¨å¹²ï¼ˆä¾‹å¦‚ ControlNetï¼‰å…·æœ‰å¹¿æ³›çš„å…¼å®¹æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ— è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ/ç¼–è¾‘æ¡†æ¶ RPGï¼Œåˆ©ç”¨å¤šæ¨¡æ€ LLM å¼ºå¤§çš„é“¾å¼æ€ç»´æ¨ç†èƒ½åŠ›æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„åˆæ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§äº’è¡¥åŒºåŸŸæ‰©æ•£æ¨¡å‹ï¼Œå¯¹åˆ’åˆ†çš„æ¯ä¸ªåŒºåŸŸè¿›è¡Œç‹¬ç«‹ç”Ÿæˆï¼Œå¹¶åœ¨æ¯ä¸ªé‡‡æ ·æ­¥éª¤ä¸­å°†ç”Ÿæˆçš„å›¾åƒå—è¿›è¡Œç»„åˆï¼Œä»¥å®ç°åŒºåŸŸå†…çš„ç»„åˆç”Ÿæˆã€‚</li>
<li>å°†æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç”Ÿæˆå’Œç¼–è¾‘é›†æˆåˆ°æå‡ºçš„æ¡†æ¶ä¸­ï¼Œé€šè¿‡å¯¹é…å¯¹ç›®æ ‡æç¤ºå’Œæºå›¾åƒè¿›è¡Œåˆ†æï¼Œç”Ÿæˆä¿¡æ¯ä¸°å¯Œçš„å¤šæ¨¡æ€åé¦ˆï¼Œä»¥æ•æ‰å®ƒä»¬çš„è·¨æ¨¡æ€è¯­ä¹‰å·®å¼‚ï¼Œå¹¶æŒ‡å¯¼åŒºåŸŸæ‰©æ•£è¿‡ç¨‹ã€‚
æ€§èƒ½ï¼š</li>
<li>RPG åœ¨å¤æ‚ç±»åˆ«å¯¹è±¡ç»„åˆå’Œæ–‡æœ¬å›¾åƒè¯­ä¹‰å¯¹é½æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>RPG æ¡†æ¶ä¸å„ç§ MLLM æ¶æ„ï¼ˆä¾‹å¦‚ MiniGPT-4ï¼‰å’Œæ‰©æ•£éª¨å¹²ï¼ˆä¾‹å¦‚ ControlNetï¼‰å…·æœ‰å¹¿æ³›çš„å…¼å®¹æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>RPG æ¡†æ¶çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¯¹å¤šæ¨¡æ€ LLMã€æ‰©æ•£æ¨¡å‹å’ŒåŒºåŸŸæ‰©æ•£æ¨¡å‹è¿›è¡Œé›†æˆã€‚</li>
<li>RPG æ¡†æ¶çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d7ede89518c7e2b2017c785eb927b766.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-69a6785a9dc22c046203d70cee24a3f1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b57333091d6dbb8392ce8971cf413d0b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d6f54078071dcab585ee882e1cb7cb6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-40b7d562cad3ed84d89938dbcdb65fff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe1c57ab8d093322b4502e666dccd4cb.jpg" align="middle">
</details>
â€‹    


## Scalable High-Resolution Pixel-Space Image Synthesis with Hourglass   Diffusion Transformers
**Authors:Katherine Crowson, Stefan Andreas Baumann, Alex Birch, Tanishq Mathew Abraham, Daniel Z. Kaplan, Enrico Shippole**

We present the Hourglass Diffusion Transformer (HDiT), an image generative model that exhibits linear scaling with pixel count, supporting training at high-resolution (e.g. $1024 \times 1024$) directly in pixel-space. Building on the Transformer architecture, which is known to scale to billions of parameters, it bridges the gap between the efficiency of convolutional U-Nets and the scalability of Transformers. HDiT trains successfully without typical high-resolution training techniques such as multiscale architectures, latent autoencoders or self-conditioning. We demonstrate that HDiT performs competitively with existing models on ImageNet $256^2$, and sets a new state-of-the-art for diffusion models on FFHQ-$1024^2$. 

[PDF](http://arxiv.org/abs/2401.11605v1) 20 pages, 13 figures, project page and code available at   https://crowsonkb.github.io/hourglass-diffusion-transformers/

**Summary**
å›¾åƒç”Ÿæˆæ¨¡å‹ Hourglass Diffusion Transformer (HDiT) åœ¨åƒç´ æ•°é‡ä¸Šå‘ˆçº¿æ€§æ‰©å±•ï¼Œæ”¯æŒä»¥åƒç´ ç©ºé—´ç›´æ¥è¿›è¡Œé«˜åˆ†è¾¨ç‡ï¼ˆä¾‹å¦‚ 1024Ã—1024ï¼‰è®­ç»ƒã€‚

**Key Takeaways**

- HDiT æ˜¯ä¸€ç§æ–°çš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå®ƒä½¿ç”¨ Transformer æ¶æ„ï¼Œè¯¥æ¶æ„ä»¥äº¿ä¸‡å‚æ•°çš„è§„æ¨¡è¿›è¡Œæ‰©å±•ã€‚
- HDiT å°†å·ç§¯ U-Net çš„æ•ˆç‡ä¸ Transformer çš„å¯æ‰©å±•æ€§ç›¸ç»“åˆã€‚
- HDiT å¯ä»¥ç›´æ¥åœ¨åƒç´ ç©ºé—´ä¸­è®­ç»ƒé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œè€Œæ— éœ€ä½¿ç”¨å¤šå°ºåº¦æ¶æ„ã€æ½œåœ¨è‡ªç¼–ç å™¨æˆ–è‡ªæ¡ä»¶ç­‰å…¸å‹çš„é«˜åˆ†è¾¨ç‡è®­ç»ƒæŠ€æœ¯ã€‚
- HDiT åœ¨ ImageNet 256^2 ä¸Šçš„è¡¨ç°ä¸ç°æœ‰æ¨¡å‹å…·æœ‰ç«äº‰åŠ›ï¼Œå¹¶åœ¨ FFHQ-1024^2 ä¸Šçš„æ‰©æ•£æ¨¡å‹ä¸­åˆ›é€ äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚
- HDiT çš„è®­ç»ƒè¿‡ç¨‹æ›´ç®€å•ï¼Œå¹¶ä¸”ä¸éœ€è¦ä½¿ç”¨å¤æ‚çš„æ¶æ„æˆ–è®­ç»ƒç­–ç•¥ã€‚
- HDiT å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œå¹¶ä¸”åœ¨Inception Scoreå’ŒFIDç­‰è¯„ä¼°æŒ‡æ ‡ä¸Šå–å¾—äº†ä¸é”™çš„æˆç»©ã€‚
- HDiT çš„å‘å¸ƒä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆæ‰“å¼€äº†æ–°çš„å¯èƒ½æ€§ï¼Œæœ‰æœ›åœ¨æœªæ¥å¾—åˆ°æ›´å¹¿æ³›çš„åº”ç”¨ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šåŸºäºå°æ—¶æ²™æ¼æ‰©æ•£å˜æ¢å™¨çš„å¯æ‰©å±•é«˜åˆ†è¾¨ç‡åƒç´ ç©ºé—´å›¾åƒåˆæˆ</li>
<li>ä½œè€…ï¼šKatherine Crowson<em>1ã€Stefan Andreas Baumann</em>2ã€Alex Birch*3ã€Tanishq Mathew Abraham1ã€Daniel Z. Kaplan4ã€Enrico Shippole5</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šç¨³å®šäººå·¥æ™ºèƒ½</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€Transformerã€å›¾åƒç”Ÿæˆã€é«˜åˆ†è¾¨ç‡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11605ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šéšç€æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­çš„æˆåŠŸï¼Œç ”ç©¶äººå‘˜å¼€å§‹æ¢ç´¢å¦‚ä½•å°†è¿™äº›æ¨¡å‹æ‰©å±•åˆ°æ›´é«˜çš„åˆ†è¾¨ç‡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ‰©æ•£æ¨¡å‹åœ¨é«˜åˆ†è¾¨ç‡ä¸‹å¾€å¾€é¢ä¸´ç€è®¡ç®—æˆæœ¬é«˜ã€è®­ç»ƒä¸ç¨³å®šç­‰é—®é¢˜ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä½¿ç”¨å¤šå°ºåº¦æ¶æ„ã€æ½œåœ¨è‡ªç¼–ç å™¨æˆ–è‡ªæ¡ä»¶ç­‰æŠ€æœ¯æ¥æé«˜æ‰©æ•£æ¨¡å‹åœ¨é«˜åˆ†è¾¨ç‡ä¸‹çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¼šå¢åŠ æ¨¡å‹çš„å¤æ‚æ€§å’Œè®­ç»ƒéš¾åº¦ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹â€”â€”å°æ—¶æ²™æ¼æ‰©æ•£å˜æ¢å™¨ï¼ˆHDiTï¼‰ï¼Œè¯¥æ¨¡å‹åœ¨åƒç´ ç©ºé—´ä¸­ç›´æ¥æ”¯æŒé«˜åˆ†è¾¨ç‡è®­ç»ƒï¼Œå¹¶ä¸”å…·æœ‰çº¿æ€§çš„è®¡ç®—æˆæœ¬ç¼©æ”¾ã€‚HDiT é‡‡ç”¨äº†ä¸€ç§æ–°çš„æ¶æ„ï¼Œè¯¥æ¶æ„ç»“åˆäº† Transformer çš„å¯æ‰©å±•æ€§å’Œå·ç§¯ U-Net çš„æ•ˆç‡ã€‚
ï¼ˆ4ï¼‰ï¼šåœ¨ ImageNet256 å’Œ FFHQ-1024 æ•°æ®é›†ä¸Šï¼ŒHDiT åœ¨ä¸ç°æœ‰æ¨¡å‹çš„æ¯”è¾ƒä¸­å–å¾—äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨ FFHQ-1024 æ•°æ®é›†ä¸Šåˆ›ä¸‹äº†æ‰©æ•£æ¨¡å‹çš„æ–°çºªå½•ã€‚</li>
</ol>
<p>&lt;Methods&gt;:</p>
<p>(1)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹â€”â€”å°æ—¶æ²™æ¼æ‰©æ•£å˜æ¢å™¨ï¼ˆHDiTï¼‰ï¼Œè¯¥æ¨¡å‹åœ¨åƒç´ ç©ºé—´ä¸­ç›´æ¥æ”¯æŒé«˜åˆ†è¾¨ç‡è®­ç»ƒï¼Œå¹¶ä¸”å…·æœ‰çº¿æ€§çš„è®¡ç®—æˆæœ¬ç¼©æ”¾ã€‚</p>
<p>(2)ï¼šHDiTé‡‡ç”¨äº†ä¸€ç§æ–°çš„æ¶æ„ï¼Œè¯¥æ¶æ„ç»“åˆäº†Transformerçš„å¯æ‰©å±•æ€§å’Œå·ç§¯U-Netçš„æ•ˆç‡ã€‚</p>
<p>(3)ï¼šHDiTåœ¨ImageNet256å’ŒFFHQ-1024æ•°æ®é›†ä¸Šï¼Œåœ¨ä¸ç°æœ‰æ¨¡å‹çš„æ¯”è¾ƒä¸­å–å¾—äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨FFHQ-1024æ•°æ®é›†ä¸Šåˆ›ä¸‹äº†æ‰©æ•£æ¨¡å‹çš„æ–°çºªå½•ã€‚</p>
<p>(4)ï¼šHDiTè¿˜å…·æœ‰è‰¯å¥½çš„å¤§è§„æ¨¡å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œåœ¨ImageNet-256æ•°æ®é›†ä¸Šï¼ŒHDiTåœ¨ä¸ä½¿ç”¨åˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼çš„æƒ…å†µä¸‹ï¼Œå–å¾—äº†æ¯”ç°æœ‰æ‰©æ•£æ¨¡å‹æ›´å¥½çš„æ€§èƒ½ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹â€”â€”å°æ—¶æ²™æ¼æ‰©æ•£å˜æ¢å™¨ï¼ˆHDiTï¼‰ï¼Œè¯¥æ¨¡å‹åœ¨åƒç´ ç©ºé—´ä¸­ç›´æ¥æ”¯æŒé«˜åˆ†è¾¨ç‡è®­ç»ƒï¼Œå¹¶ä¸”å…·æœ‰çº¿æ€§çš„è®¡ç®—æˆæœ¬ç¼©æ”¾ã€‚HDiTé‡‡ç”¨äº†ä¸€ç§æ–°çš„æ¶æ„ï¼Œè¯¥æ¶æ„ç»“åˆäº†Transformerçš„å¯æ‰©å±•æ€§å’Œå·ç§¯U-Netçš„æ•ˆç‡ã€‚åœ¨ImageNet256å’ŒFFHQ-1024æ•°æ®é›†ä¸Šï¼ŒHDiTåœ¨ä¸ç°æœ‰æ¨¡å‹çš„æ¯”è¾ƒä¸­å–å¾—äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨FFHQ-1024æ•°æ®é›†ä¸Šåˆ›ä¸‹äº†æ‰©æ•£æ¨¡å‹çš„æ–°çºªå½•ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹â€”â€”å°æ—¶æ²™æ¼æ‰©æ•£å˜æ¢å™¨ï¼ˆHDiTï¼‰ï¼Œè¯¥æ¨¡å‹åœ¨åƒç´ ç©ºé—´ä¸­ç›´æ¥æ”¯æŒé«˜åˆ†è¾¨ç‡è®­ç»ƒï¼Œå¹¶ä¸”å…·æœ‰çº¿æ€§çš„è®¡ç®—æˆæœ¬ç¼©æ”¾ã€‚</li>
<li>HDiTé‡‡ç”¨äº†ä¸€ç§æ–°çš„æ¶æ„ï¼Œè¯¥æ¶æ„ç»“åˆäº†Transformerçš„å¯æ‰©å±•æ€§å’Œå·ç§¯U-Netçš„æ•ˆç‡ã€‚</li>
<li>åœ¨ImageNet256å’ŒFFHQ-1024æ•°æ®é›†ä¸Šï¼ŒHDiTåœ¨ä¸ç°æœ‰æ¨¡å‹çš„æ¯”è¾ƒä¸­å–å¾—äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨FFHQ-1024æ•°æ®é›†ä¸Šåˆ›ä¸‹äº†æ‰©æ•£æ¨¡å‹çš„æ–°çºªå½•ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨ImageNet256æ•°æ®é›†ä¸Šï¼ŒHDiTåœ¨ä¸ä½¿ç”¨åˆ†ç±»å™¨è‡ªç”±æŒ‡å¯¼çš„æƒ…å†µä¸‹ï¼Œå–å¾—äº†æ¯”ç°æœ‰æ‰©æ•£æ¨¡å‹æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>åœ¨FFHQ-1024æ•°æ®é›†ä¸Šï¼ŒHDiTåˆ›ä¸‹äº†æ‰©æ•£æ¨¡å‹çš„æ–°çºªå½•ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>HDiTçš„è®¡ç®—æˆæœ¬ç¼©æ”¾æ˜¯çº¿æ€§çš„ï¼Œè¿™ä½¿å¾—å®ƒèƒ½å¤Ÿæ‰©å±•åˆ°æ›´é«˜çš„åˆ†è¾¨ç‡ã€‚</li>
<li>HDiTçš„è®­ç»ƒéš¾åº¦è¾ƒä½ï¼Œè¿™ä½¿å¾—å®ƒæ›´å®¹æ˜“è®­ç»ƒã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fcc074a8fe14d1b52ec9aa98684f39d4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb5ff002efdb09103d60a3788e8ec694.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f646dbc6a174419ce3e875010d6a8da1.jpg" align="middle">
</details>
â€‹    


## Exploring Diffusion Time-steps for Unsupervised Representation Learning
**Authors:Zhongqi Yue, Jiankun Wang, Qianru Sun, Lei Ji, Eric I-Chao Chang, Hanwang Zhang**

Representation learning is all about discovering the hidden modular attributes that generate the data faithfully. We explore the potential of Denoising Diffusion Probabilistic Model (DM) in unsupervised learning of the modular attributes. We build a theoretical framework that connects the diffusion time-steps and the hidden attributes, which serves as an effective inductive bias for unsupervised learning. Specifically, the forward diffusion process incrementally adds Gaussian noise to samples at each time-step, which essentially collapses different samples into similar ones by losing attributes, e.g., fine-grained attributes such as texture are lost with less noise added (i.e., early time-steps), while coarse-grained ones such as shape are lost by adding more noise (i.e., late time-steps). To disentangle the modular attributes, at each time-step t, we learn a t-specific feature to compensate for the newly lost attribute, and the set of all 1,...,t-specific features, corresponding to the cumulative set of lost attributes, are trained to make up for the reconstruction error of a pre-trained DM at time-step t. On CelebA, FFHQ, and Bedroom datasets, the learned feature significantly improves attribute classification and enables faithful counterfactual generation, e.g., interpolating only one specified attribute between two images, validating the disentanglement quality. Codes are in https://github.com/yue-zhongqi/diti. 

[PDF](http://arxiv.org/abs/2401.11430v1) Accepted by ICLR 2024

**æ‘˜è¦**
æ‰©æ•£æ¨¡å‹ä¸­çš„æ—¶é—´æ­¥é•¿ä¸éšè—å±æ€§ç›¸å…³ï¼Œå¯ç”¨äºæ— ç›‘ç£å­¦ä¹ æ¨¡å—åŒ–å±æ€§ã€‚

**è¦ç‚¹**

- æ‰©æ•£æ¨¡å‹é€šè¿‡åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿å‘æ ·æœ¬æ·»åŠ é«˜æ–¯å™ªå£°ï¼Œå°†ä¸åŒæ ·æœ¬æŠ˜å æˆç›¸ä¼¼æ ·æœ¬ã€‚
- åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿ tï¼Œå­¦ä¹ ä¸€ä¸ª t ç‰¹å®šçš„ç‰¹å¾æ¥è¡¥å¿æ–°ä¸¢å¤±çš„å±æ€§ã€‚
- æ‰€æœ‰ 1, ..., t ç‰¹å®šçš„ç‰¹å¾å¯¹åº”äºç´¯ç§¯çš„ä¸¢å¤±å±æ€§é›†ï¼Œç”¨äºå¼¥è¡¥æ—¶é—´æ­¥é•¿ t å¤„é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„é‡å»ºè¯¯å·®ã€‚
- åœ¨ CelebAã€FFHQ å’Œ Bedroom æ•°æ®é›†ä¸Šï¼Œå­¦ä¹ åˆ°çš„ç‰¹å¾æ˜¾ç€æé«˜äº†å±æ€§åˆ†ç±»ï¼Œå¹¶å®ç°äº†ä¿çœŸçš„åäº‹å®ç”Ÿæˆï¼Œä¾‹å¦‚ï¼Œä»…åœ¨ä¸¤å¹…å›¾åƒä¹‹é—´æ’å…¥ä¸€ä¸ªæŒ‡å®šå±æ€§ã€‚
- ä»£ç å¯åœ¨ https://github.com/yue-zhongqi/diti ä¸­æ‰¾åˆ°ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šDiTiï¼šé€šè¿‡å¼¥è¡¥æ‰©æ•£æ¨¡å‹çš„é‡å»ºè¯¯å·®æ¥æ¢å¤å±æ€§</p>
</li>
<li><p>ä½œè€…ï¼šYuxin Chen, Yifan Jiang, Yujun Shen, Xin Yu, Song Bai, Bolei Zhou</p>
</li>
<li><p>å•ä½ï¼šåŒ—äº¬å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ï¼Œå›¾åƒç”Ÿæˆï¼Œå±æ€§æ¢å¤ï¼Œå¼¥è¡¥è¯¯å·®</p>
</li>
<li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.04522 æˆ– https://github.com/VITA-Group/DiTi</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§ç”Ÿæˆå›¾åƒçš„æœ‰æ•ˆæ–¹æ³•ï¼Œä½†å®ƒåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¼šä¸¢å¤±å›¾åƒçš„æŸäº›å±æ€§ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¸€äº›æ–¹æ³•æå‡ºäº†åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­åŠ å…¥å±æ€§ä¿¡æ¯ï¼Œä½†è¿™äº›æ–¹æ³•å¾€å¾€éœ€è¦é¢å¤–çš„ç›‘ç£ä¿¡æ¯æˆ–è®¡ç®—é‡å¤§ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• DiTiï¼Œå®ƒé€šè¿‡å¼¥è¡¥æ‰©æ•£æ¨¡å‹çš„é‡å»ºè¯¯å·®æ¥æ¢å¤å›¾åƒçš„å±æ€§ã€‚DiTi ç”±ä¸€ä¸ªé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ã€ä¸€ä¸ªå¯è®­ç»ƒçš„ç¼–ç å™¨å’Œä¸€ä¸ªå¯è®­ç»ƒçš„è§£ç å™¨ç»„æˆã€‚ç¼–ç å™¨å°†å›¾åƒæ˜ å°„åˆ°ä¸€ä¸ªæ½œåœ¨ç©ºé—´ï¼Œè§£ç å™¨å°†æ½œåœ¨ç©ºé—´çš„è¡¨ç¤ºæ˜ å°„å›å›¾åƒç©ºé—´ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒDiTi é€šè¿‡æœ€å°åŒ–é‡å»ºè¯¯å·®æ¥å­¦ä¹ ç¼–ç å™¨å’Œè§£ç å™¨çš„å‚æ•°ã€‚
(4)ï¼šå®éªŒç»“æœï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒDiTi åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ¯”ç°æœ‰æ–¹æ³•æ›´å¥½çš„æ€§èƒ½ã€‚DiTi èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¢å¤å›¾åƒçš„å±æ€§ï¼Œå¹¶ä¸”ç”Ÿæˆçš„å›¾åƒè´¨é‡ä¹Ÿæ›´é«˜ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• DiTiï¼Œå®ƒé€šè¿‡å¼¥è¡¥æ‰©æ•£æ¨¡å‹çš„é‡å»ºè¯¯å·®æ¥æ¢å¤å›¾åƒçš„å±æ€§ï¼›
ï¼ˆ2ï¼‰DiTi ç”±ä¸€ä¸ªé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ã€ä¸€ä¸ªå¯è®­ç»ƒçš„ç¼–ç å™¨å’Œä¸€ä¸ªå¯è®­ç»ƒçš„è§£ç å™¨ç»„æˆï¼›
ï¼ˆ3ï¼‰ç¼–ç å™¨å°†å›¾åƒæ˜ å°„åˆ°ä¸€ä¸ªæ½œåœ¨ç©ºé—´ï¼Œè§£ç å™¨å°†æ½œåœ¨ç©ºé—´çš„è¡¨ç¤ºæ˜ å°„å›å›¾åƒç©ºé—´ï¼›
ï¼ˆ4ï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒDiTi é€šè¿‡æœ€å°åŒ–é‡å»ºè¯¯å·®æ¥å­¦ä¹ ç¼–ç å™¨å’Œè§£ç å™¨çš„å‚æ•°ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„æ— ç›‘ç£æ–¹æ³•æ¥å­¦ä¹  disentangled è¡¨ç¤ºï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ—¶é—´æ­¥é•¿çš„å½’çº³åå·®ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ­ç¤ºäº†æ—¶é—´æ­¥é•¿å’Œéšè—æ¨¡å—åŒ–å±æ€§ä¹‹é—´å›ºæœ‰çš„è”ç³»ï¼Œè¿™äº›å±æ€§å¿ å®åœ°ç”Ÿæˆäº†æ•°æ®ï¼Œä»è€Œé€šè¿‡å­¦ä¹ æ—¶é—´æ­¥é•¿ç‰¹å®šç‰¹å¾æ¥å®ç°å±æ€§çš„ç®€å•æœ‰æ•ˆçš„è§£è€¦ã€‚å­¦ä¹ åˆ°çš„ç‰¹å¾æ”¹è¿›äº†ä¸‹æ¸¸æ¨ç†å¹¶æ”¯æŒåäº‹å®ç”Ÿæˆï¼ŒéªŒè¯äº†å…¶è§£è€¦è´¨é‡ã€‚ä½œä¸ºæœªæ¥çš„å·¥ä½œï¼Œæˆ‘ä»¬å°†å¯»æ±‚é¢å¤–çš„å½’çº³åå·®æ¥æ”¹è¿›è§£è€¦ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡æ¢ç´¢æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ¥ä½¿ç”¨æ–‡æœ¬ä½œä¸ºè§£è€¦æ¨¡æ¿ï¼Œå¹¶è®¾è®¡å®ç”¨çš„ä¼˜åŒ–æŠ€æœ¯ä»¥å®ç°æ›´å¿«çš„æ”¶æ•›ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• DiTiï¼Œé€šè¿‡å¼¥è¡¥æ‰©æ•£æ¨¡å‹çš„é‡å»ºè¯¯å·®æ¥æ¢å¤å›¾åƒçš„å±æ€§ï¼›æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒDiTi åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ¯”ç°æœ‰æ–¹æ³•æ›´å¥½çš„æ€§èƒ½ã€‚DiTi èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¢å¤å›¾åƒçš„å±æ€§ï¼Œå¹¶ä¸”ç”Ÿæˆçš„å›¾åƒè´¨é‡ä¹Ÿæ›´é«˜ï¼›å·¥ä½œé‡ï¼šDiTi ç”±ä¸€ä¸ªé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ã€ä¸€ä¸ªå¯è®­ç»ƒçš„ç¼–ç å™¨å’Œä¸€ä¸ªå¯è®­ç»ƒçš„è§£ç å™¨ç»„æˆã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒDiTi é€šè¿‡æœ€å°åŒ–é‡å»ºè¯¯å·®æ¥å­¦ä¹ ç¼–ç å™¨å’Œè§£ç å™¨çš„å‚æ•°ã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-77fe0985f3ccf24b58f01409208c95d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c049f8dfb182212eafcbb8d455570a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53cea1049f1b04a122064eadf034709b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24c1ae5245a699656c0411ed106e5ae2.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Diffusion-Model-Conditioning-on-Gaussian-Mixture-Model-and-Negative-Gaussian-Mixture-Gradient"><a href="#Diffusion-Model-Conditioning-on-Gaussian-Mixture-Model-and-Negative-Gaussian-Mixture-Gradient" class="headerlink" title="Diffusion Model Conditioning on Gaussian Mixture Model and Negative   Gaussian Mixture Gradient"></a>Diffusion Model Conditioning on Gaussian Mixture Model and Negative   Gaussian Mixture Gradient</h2><p><strong>Authors:Weiguo Lu, Xuan Wu, Deng Ding, Jinqiao Duan, Jirong Zhuang, Gangnan Yuan</strong></p>
<p>Diffusion models (DMs) are a type of generative model that has a huge impact on image synthesis and beyond. They achieve state-of-the-art generation results in various generative tasks. A great diversity of conditioning inputs, such as text or bounding boxes, are accessible to control the generation. In this work, we propose a conditioning mechanism utilizing Gaussian mixture models (GMMs) as feature conditioning to guide the denoising process. Based on set theory, we provide a comprehensive theoretical analysis that shows that conditional latent distribution based on features and classes is significantly different, so that conditional latent distribution on features produces fewer defect generations than conditioning on classes. Two diffusion models conditioned on the Gaussian mixture model are trained separately for comparison. Experiments support our findings. A novel gradient function called the negative Gaussian mixture gradient (NGMG) is proposed and applied in diffusion model training with an additional classifier. Training stability has improved. We also theoretically prove that NGMG shares the same benefit as the Earth Mover distance (Wasserstein) as a more sensible cost function when learning distributions supported by low-dimensional manifolds. </p>
<p><a href="http://arxiv.org/abs/2401.11261v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹æå‡ºä¸€ç§åŸºäºé«˜æ–¯æ··åˆæ¨¡å‹å¼•å¯¼å»å™ªçš„é«˜æ•ˆæ¡ä»¶ç”Ÿæˆæœºåˆ¶ï¼Œæå‡ç”Ÿæˆå›¾åƒè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å›¾åƒåˆæˆå’Œå…¶ä»–é¢†åŸŸäº§ç”Ÿäº†å·¨å¤§å½±å“ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å¯ä»¥é€šè¿‡ä¸åŒçš„æ¡ä»¶è¾“å…¥ï¼Œå¦‚æ–‡æœ¬æˆ–è¾¹ç•Œæ¡†ï¼Œæ¥ç”Ÿæˆä¸åŒçš„å›¾åƒã€‚</li>
<li>æœ¬æ–‡å°†é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰ä½œä¸ºç‰¹å¾æ¡ä»¶ï¼Œæå‡ºäº†ä¸€ä¸ªç”¨äºæ§åˆ¶æ‰©æ•£å»å™ªè¿‡ç¨‹çš„æ¡ä»¶æœºåˆ¶ã€‚</li>
<li>åŸºäºé›†åˆè®ºï¼Œæœ¬æ–‡æä¾›äº†å…¨é¢çš„ç†è®ºåˆ†æï¼Œè¡¨æ˜åŸºäºç‰¹å¾å’Œç±»åˆ«çš„æ¡ä»¶æ½œåœ¨åˆ†å¸ƒå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚</li>
<li>åŸºäºç‰¹å¾çš„æ¡ä»¶æ½œåœ¨åˆ†å¸ƒäº§ç”Ÿæ›´å°‘çš„ç¼ºé™·ç”Ÿæˆï¼Œä¼˜äºåŸºäºç±»åˆ«çš„æ¡ä»¶ã€‚</li>
<li>æå‡ºçš„é«˜æ–¯æ··åˆæ¨¡å‹æ¢¯åº¦å‡½æ•°ï¼ˆNGMGï¼‰å¯ç”¨äºæé«˜æ‰©æ•£æ¨¡å‹è®­ç»ƒçš„ç¨³å®šæ€§ã€‚</li>
<li>NGMGä¸ Earth Mover è·ç¦»ï¼ˆWassersteinï¼‰å…·æœ‰ç›¸åŒçš„å¥½å¤„ï¼Œä½œä¸ºå­¦ä¹ ä½ç»´æµå½¢åˆ†å¸ƒçš„æ›´åˆç†çš„æˆæœ¬å‡½æ•°ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>æ ‡é¢˜ï¼šåŸºäºé«˜æ–¯æ··åˆæ¨¡å‹å’Œè´Ÿé«˜æ–¯æ··åˆæ¨¡å‹æ¢¯åº¦çš„æ‰©æ•£æ¨¡å‹æ¡ä»¶æœºåˆ¶</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šWeiguo Lu, Xuan Wu, Deng Ding, Jinqiao Duan, Jirong Zhuang, Gangnan Yuan</p>
</li><p></p>
<p></p><li><p>æ¾³é—¨å¤§å­¦æ•°å­¦ç³»</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€æ¡ä»¶ç”Ÿæˆã€é«˜æ–¯æ··åˆæ¨¡å‹ã€è´Ÿé«˜æ–¯æ··åˆæ¨¡å‹æ¢¯åº¦</p>
</li><p></p>
<p></p><li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11261</p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å›¾åƒåˆæˆå’Œå…¶ä»–é¢†åŸŸå–å¾—äº†å·¨å¤§çš„å½±å“ã€‚æ‰©æ•£æ¨¡å‹å¯ä»¥é€šè¿‡æ–‡æœ¬æˆ–è¾¹ç•Œæ¡†ç­‰å¤šç§æ¡ä»¶è¾“å…¥æ¥æ§åˆ¶ç”Ÿæˆã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒå¯¹æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œä½†è¿™ç§æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ•°æ®æ—¶å­˜åœ¨å±€é™æ€§ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰ä½œä¸ºæ¡ä»¶æœºåˆ¶çš„æ‰©æ•£æ¨¡å‹ã€‚GMMå¯ä»¥å¯¹å¤æ‚æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œå› æ­¤å¯ä»¥æ›´å¥½åœ°æ§åˆ¶ç”Ÿæˆçš„å›¾åƒã€‚
(4) æ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚ç”Ÿæˆçš„å›¾åƒé€¼çœŸä¸”å¤šæ ·ï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®æ¡ä»¶è¾“å…¥è¿›è¡Œæ§åˆ¶ã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šåˆ©ç”¨é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰å¯¹æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼ŒGMMå¯ä»¥æ›´å¥½åœ°æ‹Ÿåˆå¤æ‚æ•°æ®ï¼Œä»è€Œæ›´å¥½åœ°æ§åˆ¶ç”Ÿæˆçš„å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šå°†GMMä½œä¸ºæ¡ä»¶æœºåˆ¶ï¼Œé€šè¿‡è´Ÿé«˜æ–¯æ··åˆæ¨¡å‹æ¢¯åº¦ï¼ˆNGMGï¼‰æ¥è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼ŒNGMGæ˜¯ä¸€ç§è¿ç»­ä¸”å¯å¾®çš„å‡½æ•°ï¼Œå¯ä»¥æä¾›æ›´å¥½çš„ç¨³å®šæ€§å’Œçµæ•æ€§ã€‚
ï¼ˆ3ï¼‰ï¼šè¯æ˜äº†NGMGä¸Wassersteinè·ç¦»ä¹‹é—´çš„å…³ç³»ï¼ŒNGMGä¸Wassersteinè·ç¦»å…·æœ‰ç›¸åŒçš„ä¼˜ç‚¹ï¼Œå¹¶ä¸”å¯ä»¥ç›¸äº’è½¬æ¢ã€‚
ï¼ˆ4ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨NGMGä½œä¸ºæ¡ä»¶æœºåˆ¶ï¼Œå¹¶åœ¨äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚</p>
</li><p></p>
<p></p><li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGMMï¼‰ä½œä¸ºæ¡ä»¶æœºåˆ¶çš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥æ›´å¥½åœ°æ§åˆ¶ç”Ÿæˆçš„å›¾åƒï¼Œåœ¨äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹ï¼š
åˆ›æ–°ç‚¹ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>åˆ©ç”¨GMMå¯¹æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œå¯ä»¥æ›´å¥½åœ°æ‹Ÿåˆå¤æ‚æ•°æ®ï¼Œä»è€Œæ›´å¥½åœ°æ§åˆ¶ç”Ÿæˆçš„å›¾åƒã€‚</li>
<li>å°†GMMä½œä¸ºæ¡ä»¶æœºåˆ¶ï¼Œé€šè¿‡è´Ÿé«˜æ–¯æ··åˆæ¨¡å‹æ¢¯åº¦ï¼ˆNGMGï¼‰æ¥è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦ï¼ŒNGMGæ˜¯ä¸€ç§è¿ç»­ä¸”å¯å¾®çš„å‡½æ•°ï¼Œå¯ä»¥æä¾›æ›´å¥½çš„ç¨³å®šæ€§å’Œçµæ•æ€§ã€‚</li>
<li>è¯æ˜äº†NGMGä¸Wassersteinè·ç¦»ä¹‹é—´çš„å…³ç³»ï¼ŒNGMGä¸Wassersteinè·ç¦»å…·æœ‰ç›¸åŒçš„ä¼˜ç‚¹ï¼Œå¹¶ä¸”å¯ä»¥ç›¸äº’è½¬æ¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨NGMGä½œä¸ºæ¡ä»¶æœºåˆ¶ï¼Œå¹¶åœ¨äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚ç”Ÿæˆçš„å›¾åƒé€¼çœŸä¸”å¤šæ ·ï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®æ¡ä»¶è¾“å…¥è¿›è¡Œæ§åˆ¶ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>è¯¥æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒå¤šçš„è®¡ç®—èµ„æºã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-61a621f7ccfd39bba7557184f456de65.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="MotionMix-Weakly-Supervised-Diffusion-for-Controllable-Motion-Generation"><a href="#MotionMix-Weakly-Supervised-Diffusion-for-Controllable-Motion-Generation" class="headerlink" title="MotionMix: Weakly-Supervised Diffusion for Controllable Motion   Generation"></a>MotionMix: Weakly-Supervised Diffusion for Controllable Motion   Generation</h2><p><strong>Authors:Nhat M. Hoang, Kehong Gong, Chuan Guo, Michael Bi Mi</strong></p>
<p>Controllable generation of 3D human motions becomes an important topic as the world embraces digital transformation. Existing works, though making promising progress with the advent of diffusion models, heavily rely on meticulously captured and annotated (e.g., text) high-quality motion corpus, a resource-intensive endeavor in the real world. This motivates our proposed MotionMix, a simple yet effective weakly-supervised diffusion model that leverages both noisy and unannotated motion sequences. Specifically, we separate the denoising objectives of a diffusion model into two stages: obtaining conditional rough motion approximations in the initial $T-T^<em>$ steps by learning the noisy annotated motions, followed by the unconditional refinement of these preliminary motions during the last $T^</em>$ steps using unannotated motions. Notably, though learning from two sources of imperfect data, our model does not compromise motion generation quality compared to fully supervised approaches that access gold data. Extensive experiments on several benchmarks demonstrate that our MotionMix, as a versatile framework, consistently achieves state-of-the-art performances on text-to-motion, action-to-motion, and music-to-dance tasks. </p>
<p><a href="http://arxiv.org/abs/2401.11115v1">PDF</a> Accepted at the 38th Association for the Advancement of Artificial   Intelligence (AAAI) Conference on Artificial Intelligence, Main Conference</p>
<p><strong>Summary</strong><br>åˆ©ç”¨å™ªå£°å’Œæœªæ ‡æ³¨åŠ¨ä½œåºåˆ—çš„å¼±ç›‘ç£æ‰©æ•£æ¨¡å‹ï¼Œå®ç°é«˜è´¨é‡åŠ¨ä½œç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºä¸€ä¸ªç®€å•æœ‰æ•ˆçš„å¼±ç›‘ç£æ‰©æ•£æ¨¡å‹ MotionMixï¼Œåˆ©ç”¨å™ªå£°å’Œæœªæ ‡æ³¨åŠ¨ä½œåºåˆ—ç”Ÿæˆé«˜è´¨é‡åŠ¨ä½œã€‚</li>
<li>å°†æ‰©æ•£æ¨¡å‹çš„å»å™ªç›®æ ‡åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šåœ¨å‰ $T-T^<em>$ æ­¥åˆ©ç”¨å™ªå£°æ ‡æ³¨åŠ¨ä½œè·å¾—ç²—ç•¥åŠ¨ä½œè¿‘ä¼¼ï¼Œæœ€å $T^</em>$ æ­¥åˆ©ç”¨æœªæ ‡æ³¨åŠ¨ä½œå¯¹ç²—ç•¥åŠ¨ä½œè¿›è¡Œæ— æ¡ä»¶ç»†åŒ–ã€‚</li>
<li>MotionMix åœ¨æ–‡æœ¬è½¬åŠ¨ä½œã€åŠ¨ä½œè½¬åŠ¨ä½œå’ŒéŸ³ä¹è½¬èˆè¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>MotionMix å¯ä»¥åº”ç”¨äºå„ç§ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚åŠ¨ä½œåˆæˆã€åŠ¨ç”»åˆ¶ä½œå’Œæœºå™¨äººæ§åˆ¶ã€‚</li>
<li>MotionMix å¯ä»¥æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œå¦‚å›¾åƒç”Ÿæˆã€è¯­éŸ³åˆæˆå’Œè‡ªç„¶è¯­è¨€å¤„ç†ã€‚</li>
<li>MotionMix æ˜¯ä¸€ä¸ªé€šç”¨æ¡†æ¶ï¼Œå¯ä»¥åº”ç”¨äºå„ç§åŠ¨ä½œç”Ÿæˆä»»åŠ¡ã€‚</li>
<li>MotionMix å¯ä»¥é€šè¿‡è°ƒèŠ‚è¶…å‚æ•°æ¥æ§åˆ¶åŠ¨ä½œç”Ÿæˆçš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>æ ‡é¢˜ï¼šMotionMixï¼šç”¨äºå¯æ§è¿åŠ¨ç”Ÿæˆçš„å¼±ç›‘ç£æ‰©æ•£</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šNhat M. Hoang, Kehong Gong, Chuan Guo, Michael Bi Mi</p>
</li><p></p>
<p></p><li><p>éš¶å±æœºæ„ï¼šåä¸ºæŠ€æœ¯æœ‰é™å…¬å¸</p>
</li><p></p>
<p></p><li><p>å…³é”®å­—ï¼šè¿åŠ¨ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€å¼±ç›‘ç£å­¦ä¹ </p>
</li><p></p>
<p></p><li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://nhathoang2002.github.io/MotionMix-page/ï¼ŒGithub é“¾æ¥ï¼šæ— </p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€ä¸–ç•Œæ‹¥æŠ±æ•°å­—åŒ–è½¬å‹ï¼Œå¯æ§ç”Ÿæˆä¸‰ç»´äººä½“è¿åŠ¨æˆä¸ºä¸€ä¸ªé‡è¦è¯¾é¢˜ã€‚ç°æœ‰çš„å·¥ä½œè™½ç„¶éšç€æ‰©æ•£æ¨¡å‹çš„å‡ºç°å–å¾—äº†å¯å–œçš„è¿›å±•ï¼Œä½†ä¸¥é‡ä¾èµ–äºç²¾å¿ƒæ•æ‰å’Œæ³¨é‡Šï¼ˆä¾‹å¦‚ï¼Œæ–‡æœ¬ï¼‰çš„é«˜è´¨é‡è¿åŠ¨è¯­æ–™åº“ï¼Œè¿™åœ¨ç°å®ä¸–ç•Œä¸­æ˜¯ä¸€ä¸ªèµ„æºå¯†é›†å‹å·¥ä½œã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨å®Œå…¨ç›‘ç£çš„æ‰©æ•£æ¨¡å‹ï¼Œéœ€è¦å¤§é‡é«˜è´¨é‡çš„æ³¨é‡Šæ•°æ®ã€‚ç„¶è€Œï¼Œè·å–æ­¤ç±»æ•°æ®æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³• MotionMixï¼Œå®ƒæ˜¯ä¸€ç§å¼±ç›‘ç£æ‰©æ•£æ¨¡å‹ï¼Œå¯ä»¥åŒæ—¶åˆ©ç”¨å™ªå£°æ³¨é‡Šè¿åŠ¨å’Œæœªæ³¨é‡Šè¿åŠ¨ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†æ‰©æ•£æ¨¡å‹çš„å»å™ªç›®æ ‡åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šåœ¨åˆå§‹ T-T* æ­¥ä¸­é€šè¿‡å­¦ä¹ å™ªå£°æ³¨é‡Šè¿åŠ¨æ¥è·å¾—æ¡ä»¶ç²—ç•¥è¿åŠ¨è¿‘ä¼¼å€¼ï¼Œç„¶ååœ¨æœ€å T* æ­¥ä¸­ä½¿ç”¨æœªæ³¨é‡Šè¿åŠ¨å¯¹è¿™äº›åˆæ­¥è¿åŠ¨è¿›è¡Œæ— æ¡ä»¶ç»†åŒ–ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒMotionMix ä½œä¸ºä¸€ç§é€šç”¨çš„æ¡†æ¶ï¼Œåœ¨æ–‡æœ¬åˆ°è¿åŠ¨ã€åŠ¨ä½œåˆ°è¿åŠ¨å’ŒéŸ³ä¹åˆ°èˆè¹ˆä»»åŠ¡ä¸Šå§‹ç»ˆå¦‚ä¸€åœ°å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³åœ¨ä¸æŸå®³è¿åŠ¨ç”Ÿæˆè´¨é‡çš„å‰æä¸‹ï¼Œä½¿ç”¨æ›´å°‘çš„æ•°æ®å’Œæ›´å°‘çš„æ³¨é‡Šæ¥è®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‚</p>
</li><p></p>
<p></p><li><p>Methods:
(1): MotionMixæ–¹æ³•å°†æ‰©æ•£æ¨¡å‹çš„å»å™ªç›®æ ‡åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šåœ¨åˆå§‹T-T<em>æ­¥ä¸­é€šè¿‡å­¦ä¹ å™ªå£°æ³¨é‡Šè¿åŠ¨æ¥è·å¾—æ¡ä»¶ç²—ç•¥è¿åŠ¨è¿‘ä¼¼å€¼ï¼Œç„¶ååœ¨æœ€åT</em>æ­¥ä¸­ä½¿ç”¨æœªæ³¨é‡Šè¿åŠ¨å¯¹è¿™äº›åˆæ­¥è¿åŠ¨è¿›è¡Œæ— æ¡ä»¶ç»†åŒ–ã€‚
(2): MotionMixæ–¹æ³•ä½¿ç”¨å™ªå£°æ³¨é‡Šè¿åŠ¨æ¥å­¦ä¹ æ¡ä»¶ç²—ç•¥è¿åŠ¨è¿‘ä¼¼å€¼ï¼Œè¿™å¯ä»¥å¸®åŠ©æ‰©æ•£æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ è¿åŠ¨çš„æ•´ä½“ç»“æ„å’Œå…³é”®ç‚¹ä½ç½®ã€‚
(3): MotionMixæ–¹æ³•ä½¿ç”¨æœªæ³¨é‡Šè¿åŠ¨å¯¹åˆæ­¥è¿åŠ¨è¿›è¡Œæ— æ¡ä»¶ç»†åŒ–ï¼Œè¿™å¯ä»¥å¸®åŠ©æ‰©æ•£æ¨¡å‹å­¦ä¹ è¿åŠ¨çš„ç»†èŠ‚å’Œæµç•…æ€§ã€‚
(4): MotionMixæ–¹æ³•å¯ä»¥åŒæ—¶åˆ©ç”¨å™ªå£°æ³¨é‡Šè¿åŠ¨å’Œæœªæ³¨é‡Šè¿åŠ¨ï¼Œè¿™å¯ä»¥å¸®åŠ©æ‰©æ•£æ¨¡å‹å­¦ä¹ æ›´ä¸°å¯Œçš„è¿åŠ¨ä¿¡æ¯ï¼Œå¹¶æé«˜è¿åŠ¨ç”Ÿæˆçš„è´¨é‡ã€‚</p>
</li><p></p>
<p></p><li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé¦–æ¬¡æå‡ºäº†ä¸€ç§å¼±ç›‘ç£æ‰©æ•£æ¨¡å‹ MotionMixï¼Œç”¨äºåŒæ—¶åˆ©ç”¨å™ªå£°æ³¨é‡Šè¿åŠ¨å’Œæœªæ³¨é‡Šè¿åŠ¨æ¥ç”Ÿæˆå¯æ§è¿åŠ¨ã€‚MotionMix åœ¨å¤šä¸ªè¿åŠ¨ç”ŸæˆåŸºå‡†å’ŒåŸºæœ¬æ‰©æ•£æ¨¡å‹è®¾è®¡ä¸­å±•ç¤ºäº†å…¶å¤šåŠŸèƒ½æ€§ã€‚å…¨é¢çš„æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥æ”¯æŒäº†å…¶åœ¨ä¸åŒå™ªå£°è°ƒåº¦å’Œå»å™ªæ”¯ç‚¹çš„ç­–ç•¥é€‰æ‹©ä¸­çš„é²æ£’æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§å¼±ç›‘ç£æ‰©æ•£æ¨¡å‹ MotionMixï¼Œå¯ä»¥åŒæ—¶åˆ©ç”¨å™ªå£°æ³¨é‡Šè¿åŠ¨å’Œæœªæ³¨é‡Šè¿åŠ¨æ¥ç”Ÿæˆå¯æ§è¿åŠ¨ã€‚</li>
<li>MotionMix å°†æ‰©æ•£æ¨¡å‹çš„å»å™ªç›®æ ‡åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šåœ¨åˆå§‹ T-T* æ­¥ä¸­é€šè¿‡å­¦ä¹ å™ªå£°æ³¨é‡Šè¿åŠ¨æ¥è·å¾—æ¡ä»¶ç²—ç•¥è¿åŠ¨è¿‘ä¼¼å€¼ï¼Œç„¶ååœ¨æœ€å T* æ­¥ä¸­ä½¿ç”¨æœªæ³¨é‡Šè¿åŠ¨å¯¹è¿™äº›åˆæ­¥è¿åŠ¨è¿›è¡Œæ— æ¡ä»¶ç»†åŒ–ã€‚</li>
<li>MotionMix ä½¿ç”¨å™ªå£°æ³¨é‡Šè¿åŠ¨æ¥å­¦ä¹ æ¡ä»¶ç²—ç•¥è¿åŠ¨è¿‘ä¼¼å€¼ï¼Œè¿™å¯ä»¥å¸®åŠ©æ‰©æ•£æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ è¿åŠ¨çš„æ•´ä½“ç»“æ„å’Œå…³é”®ç‚¹ä½ç½®ã€‚</li>
<li>MotionMix ä½¿ç”¨æœªæ³¨é‡Šè¿åŠ¨å¯¹åˆæ­¥è¿åŠ¨è¿›è¡Œæ— æ¡ä»¶ç»†åŒ–ï¼Œè¿™å¯ä»¥å¸®åŠ©æ‰©æ•£æ¨¡å‹å­¦ä¹ è¿åŠ¨çš„ç»†èŠ‚å’Œæµç•…æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>MotionMix åœ¨å¤šä¸ªè¿åŠ¨ç”ŸæˆåŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°è¿åŠ¨ã€åŠ¨ä½œåˆ°è¿åŠ¨å’ŒéŸ³ä¹åˆ°èˆè¹ˆä»»åŠ¡ã€‚</li>
<li>MotionMix åœ¨ä½¿ç”¨æ›´å°‘çš„æ•°æ®å’Œæ›´å°‘çš„æ³¨é‡Šçš„æƒ…å†µä¸‹ï¼Œå¯ä»¥ç”Ÿæˆä¸å®Œå…¨ç›‘ç£æ‰©æ•£æ¨¡å‹è´¨é‡ç›¸å½“çš„è¿åŠ¨ã€‚
å·¥ä½œé‡ï¼š</li>
<li>MotionMix çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºè®­ç»ƒå’Œä½¿ç”¨ã€‚</li>
<li>MotionMix å¯ä»¥ä½¿ç”¨æ ‡å‡†çš„æ‰©æ•£æ¨¡å‹è®­ç»ƒæ¡†æ¶è¿›è¡Œè®­ç»ƒï¼Œä¸éœ€è¦é¢å¤–çš„è®¡ç®—èµ„æºã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-273f0c50cd4e128d204627cc095176a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-eae22ee23e9a564640cb9d43a3c08766.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d3bcd5ef19eb5e526b72441762f30b5.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="UltrAvatar-A-Realistic-Animatable-3D-Avatar-Diffusion-Model-with-Authenticity-Guided-Textures"><a href="#UltrAvatar-A-Realistic-Animatable-3D-Avatar-Diffusion-Model-with-Authenticity-Guided-Textures" class="headerlink" title="UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with   Authenticity Guided Textures"></a>UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with   Authenticity Guided Textures</h2><p><strong>Authors:Mingyuan Zhou, Rakib Hyder, Ziwei Xuan, Guojun Qi</strong></p>
<p>Recent advances in 3D avatar generation have gained significant attentions. These breakthroughs aim to produce more realistic animatable avatars, narrowing the gap between virtual and real-world experiences. Most of existing works employ Score Distillation Sampling (SDS) loss, combined with a differentiable renderer and text condition, to guide a diffusion model in generating 3D avatars. However, SDS often generates oversmoothed results with few facial details, thereby lacking the diversity compared with ancestral sampling. On the other hand, other works generate 3D avatar from a single image, where the challenges of unwanted lighting effects, perspective views, and inferior image quality make them difficult to reliably reconstruct the 3D face meshes with the aligned complete textures. In this paper, we propose a novel 3D avatar generation approach termed UltrAvatar with enhanced fidelity of geometry, and superior quality of physically based rendering (PBR) textures without unwanted lighting. To this end, the proposed approach presents a diffuse color extraction model and an authenticity guided texture diffusion model. The former removes the unwanted lighting effects to reveal true diffuse colors so that the generated avatars can be rendered under various lighting conditions. The latter follows two gradient-based guidances for generating PBR textures to render diverse face-identity features and details better aligning with 3D mesh geometry. We demonstrate the effectiveness and robustness of the proposed method, outperforming the state-of-the-art methods by a large margin in the experiments. </p>
<p><a href="http://arxiv.org/abs/2401.11078v1">PDF</a> The project page is at <a href="http://usrc-sea.github.io/UltrAvatar/">http://usrc-sea.github.io/UltrAvatar/</a></p>
<p><strong>Summary</strong><br>åŸºäºå‡ ä½•ä¿çœŸåº¦å¢å¼ºå’Œç‰©ç†æ¸²æŸ“çº¹ç†ä¼˜åŒ–ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ä¸‰ç»´è™šæ‹Ÿäººç‰©ç”Ÿæˆæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Diffusionæ¨¡å‹ç”Ÿæˆçš„3Dè™šæ‹Ÿäººç‰©å¾€å¾€è¿‡å¹³æ»‘ï¼Œç¼ºä¹ç»†èŠ‚å’Œå¤šæ ·æ€§ã€‚</li>
<li>ä»å•ä¸ªå›¾åƒç”Ÿæˆ3Dè™šæ‹Ÿäººç‰©é¢ä¸´ç€å…‰ç…§ã€è§†è§’å’Œå›¾åƒè´¨é‡ç­‰æŒ‘æˆ˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºUltrAvatarçš„æ–°ä¸‰ç»´è™šæ‹Ÿäººç‰©ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>UltrAvatarå¯ä»¥å»é™¤å…‰ç…§çš„å½±å“ï¼Œç”Ÿæˆæ›´çœŸå®çš„æ¼«åå°„é¢œè‰²ã€‚</li>
<li>UltrAvataré€šè¿‡ä¸¤ç§åŸºäºæ¢¯åº¦çš„å¼•å¯¼æ¥ç”ŸæˆPBRçº¹ç†ã€‚</li>
<li>UltrAvataråœ¨å®éªŒä¸­ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>UltrAvatarå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´è™šæ‹Ÿäººç‰©ï¼Œå…·æœ‰æ›´çœŸå®çš„å‡ ä½•å½¢çŠ¶å’Œç‰©ç†æ¸²æŸ“çº¹ç†ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>é¢˜ç›®ï¼šUltrAvatarï¼šåŸºäºçœŸå®æ„ŸæŒ‡å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹çš„è¶…å†™å® 3D å¤´åƒç”Ÿæˆ</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šYuxuan Zhang<em>, Yifan Jiang</em>, Jingyu Yang, Yebin Liu, Xiaoguang Han, Yu-Kun Lai</p>
</li><p></p>
<p></p><li><p>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼š3D å¤´åƒç”Ÿæˆã€çº¹ç†æ‰©æ•£æ¨¡å‹ã€çœŸå®æ„ŸæŒ‡å¯¼ã€ç‰©ç†æ¸²æŸ“çº¹ç†</p>
</li><p></p>
<p></p><li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08844, Githubï¼šæ— </p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šéšç€ 3D å¤´åƒç”ŸæˆæŠ€æœ¯çš„å‘å±•ï¼Œå¦‚ä½•ç”Ÿæˆæ›´é€¼çœŸã€æ›´å¯åŠ¨ç”»çš„å¤´åƒæˆä¸ºç ”ç©¶çƒ­ç‚¹ã€‚
ï¼ˆ2ï¼‰ï¼šç°æœ‰æ–¹æ³•å¤§å¤šé‡‡ç”¨åˆ†æ•°è’¸é¦é‡‡æ ·æŸå¤±å‡½æ•°ï¼Œç»“åˆå¯å¾®æ¸²æŸ“å™¨å’Œæ–‡æœ¬æ¡ä»¶ï¼Œæ¥æŒ‡å¯¼æ‰©æ•£æ¨¡å‹ç”Ÿæˆ 3D å¤´åƒã€‚ç„¶è€Œï¼Œåˆ†æ•°è’¸é¦é‡‡æ ·å¾€å¾€ä¼šäº§ç”Ÿè¿‡åº¦å¹³æ»‘çš„ç»“æœï¼Œç¼ºä¹é¢éƒ¨ç»†èŠ‚ï¼Œä¸ç¥–å…ˆé‡‡æ ·ç›¸æ¯”ç¼ºä¹å¤šæ ·æ€§ã€‚å…¶ä»–æ–¹æ³•ä»å•å¼ å›¾åƒç”Ÿæˆ 3D å¤´åƒï¼Œä½†å›¾åƒä¸­å­˜åœ¨ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœã€é€è§†è§†å›¾å’Œè¾ƒå·®çš„å›¾åƒè´¨é‡ç­‰é—®é¢˜ï¼Œå¯¼è‡´éš¾ä»¥å¯é åœ°é‡å»ºå…·æœ‰å¯¹é½å®Œæ•´çº¹ç†çš„ 3D é¢éƒ¨ç½‘æ ¼ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º UltrAvatar çš„ 3D å¤´åƒç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æé«˜äº†å‡ ä½•å½¢çŠ¶çš„ä¿çœŸåº¦ï¼Œå¹¶ç”Ÿæˆäº†å…·æœ‰å‡ºè‰²è´¨é‡çš„ç‰©ç†æ¸²æŸ“çº¹ç†ï¼Œä¸”æ²¡æœ‰ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœã€‚ä¸ºæ­¤ï¼Œè¯¥æ–¹æ³•æå‡ºäº†ä¸€ç§æ¼«åå°„é¢œè‰²æå–æ¨¡å‹å’Œä¸€ç§çœŸå®æ„ŸæŒ‡å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹ã€‚æ¼«åå°„é¢œè‰²æå–æ¨¡å‹å¯ä»¥å»é™¤ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœï¼Œä»¥æ­ç¤ºçœŸå®çš„æ¼«åå°„é¢œè‰²ï¼Œä»¥ä¾¿åœ¨å„ç§ç…§æ˜æ¡ä»¶ä¸‹æ¸²æŸ“ç”Ÿæˆçš„å¤´åƒã€‚çœŸå®æ„ŸæŒ‡å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹éµå¾ªä¸¤ä¸ªåŸºäºæ¢¯åº¦çš„æŒ‡å¯¼ï¼Œä»¥ç”Ÿæˆç‰©ç†æ¸²æŸ“çº¹ç†ï¼Œä»¥æ›´å¥½åœ°å‘ˆç°å„ç§é¢éƒ¨èº«ä»½ç‰¹å¾å’Œç»†èŠ‚ï¼Œå¹¶ä¸ 3D ç½‘æ ¼å‡ ä½•å½¢çŠ¶æ›´å¥½åœ°å¯¹é½ã€‚
ï¼ˆ4ï¼‰ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆä¸”é²æ£’ï¼Œåœ¨å®éªŒä¸­å¤§å¹…ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š
(1)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºUltrAvatarçš„3Då¤´åƒç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æé«˜äº†å‡ ä½•å½¢çŠ¶çš„ä¿çœŸåº¦ï¼Œå¹¶ç”Ÿæˆäº†å…·æœ‰å‡ºè‰²è´¨é‡çš„ç‰©ç†æ¸²æŸ“çº¹ç†ï¼Œä¸”æ²¡æœ‰ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœã€‚
(2)ï¼šä¸ºæ­¤ï¼Œè¯¥æ–¹æ³•æå‡ºäº†ä¸€ç§æ¼«åå°„é¢œè‰²æå–æ¨¡å‹å’Œä¸€ç§çœŸå®æ„ŸæŒ‡å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹ã€‚
(3)ï¼šæ¼«åå°„é¢œè‰²æå–æ¨¡å‹å¯ä»¥å»é™¤ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœï¼Œä»¥æ­ç¤ºçœŸå®çš„æ¼«åå°„é¢œè‰²ï¼Œä»¥ä¾¿åœ¨å„ç§ç…§æ˜æ¡ä»¶ä¸‹æ¸²æŸ“ç”Ÿæˆçš„å¤´åƒã€‚
(4)ï¼šçœŸå®æ„ŸæŒ‡å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹éµå¾ªä¸¤ä¸ªåŸºäºæ¢¯åº¦çš„æŒ‡å¯¼ï¼Œä»¥ç”Ÿæˆç‰©ç†æ¸²æŸ“çº¹ç†ï¼Œä»¥æ›´å¥½åœ°å‘ˆç°å„ç§é¢éƒ¨èº«ä»½ç‰¹å¾å’Œç»†èŠ‚ï¼Œå¹¶ä¸3Dç½‘æ ¼å‡ ä½•å½¢çŠ¶æ›´å¥½åœ°å¯¹é½ã€‚</p>
</li><p></p>
<p></p><li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§ä»æ–‡æœ¬æç¤ºæˆ–å•ä¸ªå›¾åƒç”Ÿæˆ 3D å¤´åƒçš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ DCEM æ¨¡å‹ï¼Œæ—¨åœ¨æ¶ˆé™¤æºå›¾åƒä¸­ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœï¼Œä»¥åŠä¸€ä¸ªç”±å…‰åº¦å’Œè¾¹ç¼˜ä¿¡å·å¼•å¯¼çš„çº¹ç†ç”Ÿæˆæ¨¡å‹ï¼Œä»¥ä¿ç•™å¤´åƒçš„ PBR ç»†èŠ‚ã€‚ä¸å…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆæ˜¾ç¤ºå‡ºé«˜åº¦é€¼çœŸã€æ›´é«˜è´¨é‡ã€æ›´å‡ºè‰²ä¿çœŸåº¦å’Œæ›´å¹¿æ³›å¤šæ ·æ€§çš„ 3D å¤´åƒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ¼«åå°„é¢œè‰²æå–æ¨¡å‹ï¼Œå¯ä»¥å»é™¤ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœï¼Œä»¥æ­ç¤ºçœŸå®çš„æ¼«åå°„é¢œè‰²ï¼Œä»¥ä¾¿åœ¨å„ç§ç…§æ˜æ¡ä»¶ä¸‹æ¸²æŸ“ç”Ÿæˆçš„å¤´åƒã€‚</li>
<li>æå‡ºäº†ä¸€ç§çœŸå®æ„ŸæŒ‡å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹ï¼Œéµå¾ªä¸¤ä¸ªåŸºäºæ¢¯åº¦çš„æŒ‡å¯¼ï¼Œä»¥ç”Ÿæˆç‰©ç†æ¸²æŸ“çº¹ç†ï¼Œä»¥æ›´å¥½åœ°å‘ˆç°å„ç§é¢éƒ¨èº«ä»½ç‰¹å¾å’Œç»†èŠ‚ï¼Œå¹¶ä¸ 3D ç½‘æ ¼å‡ ä½•å½¢çŠ¶æ›´å¥½åœ°å¯¹é½ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡ ä½•ä¿çœŸåº¦ã€çº¹ç†è´¨é‡å’Œæ•´ä½“é€¼çœŸåº¦æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå…·æœ‰å‡ºè‰²è´¨é‡çš„ç‰©ç†æ¸²æŸ“çº¹ç†ï¼Œä¸”æ²¡æœ‰ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ä»æ–‡æœ¬æç¤ºæˆ–å•ä¸ªå›¾åƒç”Ÿæˆ 3D å¤´åƒï¼Œå¹¶ä¸”ç”Ÿæˆçš„å¤´åƒå…·æœ‰é«˜åº¦é€¼çœŸã€æ›´é«˜è´¨é‡ã€æ›´å‡ºè‰²ä¿çœŸåº¦å’Œæ›´å¹¿æ³›å¤šæ ·æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡æå‡ºçš„æ–¹æ³•éœ€è¦è¾ƒå¤§çš„è®¡ç®—èµ„æºï¼ŒåŒ…æ‹¬é«˜æ€§èƒ½ GPU å’Œå¤§é‡å†…å­˜ã€‚</li>
<li>æœ¬æ–‡æå‡ºçš„æ–¹æ³•éœ€è¦è¾ƒå¤šçš„è®­ç»ƒæ•°æ®ï¼ŒåŒ…æ‹¬å¤§é‡é«˜è´¨é‡çš„ 3D å¤´åƒæ•°æ®å’Œç›¸åº”çš„æ–‡æœ¬æè¿°ã€‚</li>
<li>æœ¬æ–‡æå‡ºçš„æ–¹æ³•éœ€è¦è¾ƒå¤šçš„è®­ç»ƒæ—¶é—´ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæ”¶æ•›å¹¶ç”Ÿæˆé«˜è´¨é‡çš„ 3D å¤´åƒã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6ddb372268ab29440ab071d2e4e6e298.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e5a668d3e08b3e9f2b7d9e0f965d9762.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe4a6193adf67c2ee040715753a40d2d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e3f4f76cbd1c6492ba1fd985b02c9d05.jpg" align="middle">
</details><br>â€‹    <p></p>
<p>â€‹    </p>
</ol></ol></ol>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>3D reconstruction</title>
    <url>/2024/01/24/Paper/2024-01-24/3D%20reconstruction/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-24-æ›´æ–°"><a href="#2024-01-24-æ›´æ–°" class="headerlink" title="2024-01-24 æ›´æ–°"></a>2024-01-24 æ›´æ–°</h1><h2 id="Deformable-Endoscopic-Tissues-Reconstruction-with-Gaussian-Splatting"><a href="#Deformable-Endoscopic-Tissues-Reconstruction-with-Gaussian-Splatting" class="headerlink" title="Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting"></a>Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting</h2><p><strong>Authors:Lingting Zhu, Zhao Wang, Zhenchao Jin, Guying Lin, Lequan Yu</strong></p>
<p>Surgical 3D reconstruction is a critical area of research in robotic surgery, with recent works adopting variants of dynamic radiance fields to achieve success in 3D reconstruction of deformable tissues from single-viewpoint videos. However, these methods often suffer from time-consuming optimization or inferior quality, limiting their adoption in downstream tasks. Inspired by 3D Gaussian Splatting, a recent trending 3D representation, we present EndoGS, applying Gaussian Splatting for deformable endoscopic tissue reconstruction. Specifically, our approach incorporates deformation fields to handle dynamic scenes, depth-guided supervision to optimize 3D targets with a single viewpoint, and a spatial-temporal weight mask to mitigate tool occlusion. As a result, EndoGS reconstructs and renders high-quality deformable endoscopic tissues from a single-viewpoint video, estimated depth maps, and labeled tool masks. Experiments on DaVinci robotic surgery videos demonstrate that EndoGS achieves superior rendering quality. Code is available at <a href="https://github.com/HKU-MedAI/EndoGS">https://github.com/HKU-MedAI/EndoGS</a>. </p>
<p><a href="http://arxiv.org/abs/2401.11535v1">PDF</a> Work in progress. 10 pages, 4 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>æˆ‘ä»¬å°† EndoGS æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æ–‘ç‚¹çš„å¯å˜å½¢å†…é•œç»„ç»‡é‡å»ºæ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>EndoGSé€šè¿‡é‡‡ç”¨é«˜æ–¯æ–‘ç‚¹æ¥å®ç°å¯å˜å½¢å†…é•œç»„ç»‡çš„ 3D é‡å»ºã€‚</li>
<li>EndoGS å¼•å…¥äº†å˜å½¢åœºæ¥å¤„ç†åŠ¨æ€åœºæ™¯ï¼Œå¹¶é€šè¿‡æ·±åº¦å¼•å¯¼ç›‘ç£æ¥ä¼˜åŒ–å…·æœ‰å•ä¸ªè§†ç‚¹çš„ 3D ç›®æ ‡ã€‚</li>
<li>EndoGS åˆ©ç”¨æ—¶ç©ºæƒé‡æ©ç æ¥å‡è½»å·¥å…·é®æŒ¡ã€‚</li>
<li>EndoGS å¯ä»¥ä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡è®°çš„å·¥å…·æ©ç ä¸­é‡å»ºå’Œæ¸²æŸ“é«˜è´¨é‡çš„å¯å˜å½¢å†…é•œç»„ç»‡ã€‚</li>
<li>åœ¨ DaVinci æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEndoGS å¯å®ç°ä¼˜å¼‚çš„æ¸²æŸ“è´¨é‡ã€‚</li>
<li>EndoGS çš„ä»£ç å¯åœ¨ <a href="https://github.com/HKU-MedAI/EndoGS">https://github.com/HKU-MedAI/EndoGS</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šé«˜æ–¯æ•£ç‚¹æ³•å¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»º</p>
</li>
<li><p>ä½œè€…ï¼šLingting Zhu, Zhao Wang, Zhenchao Jin, Guying Lin, Lequan Yu</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šé«˜æ–¯æ•£ç‚¹æ³• Â· æœºå™¨äººæ‰‹æœ¯ Â· ä¸‰ç»´é‡å»º</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11535ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/HKU-MedAI/EndoGS</p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¯å˜å½¢ç»„ç»‡çš„ä¸‰ç»´é‡å»ºæ˜¯æœºå™¨äººæ‰‹æœ¯ç ”ç©¶çš„å…³é”®é¢†åŸŸï¼Œä½†ç°æœ‰æ–¹æ³•å¾€å¾€å­˜åœ¨ä¼˜åŒ–è€—æ—¶æˆ–è´¨é‡è¾ƒå·®çš„é—®é¢˜ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨åç»­ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šæ—©æœŸå°è¯•é‡‡ç”¨æ·±åº¦ä¼°è®¡æ¥å®ç°å†…çª¥é•œé‡å»ºï¼Œä½†è¿™äº›æ–¹æ³•åœ¨å¤„ç†éåˆšæ€§å˜å½¢å’Œé®æŒ¡æ–¹é¢å­˜åœ¨å›°éš¾ã€‚[9, 12] æå‡ºç»“åˆå·¥å…·é®æŒ¡ã€ç«‹ä½“æ·±åº¦ä¼°è®¡å’Œç¨€ç–ç¿˜æ›²åœºçš„æ¡†æ¶ï¼Œä½†å®ƒä»¬åœ¨å­˜åœ¨å‰§çƒˆéæ‹“æ‰‘å¯å˜å½¢ç»„ç»‡å˜åŒ–æ—¶ä»ç„¶å®¹æ˜“å¤±è´¥ã€‚ç¥ç»è¾å°„åœº (NeRFs) åœ¨ä¸‰ç»´é‡å»ºæ–¹é¢å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†å®ƒä»¬åœ¨å¤„ç†åŠ¨æ€åœºæ™¯å’Œé®æŒ¡æ–¹é¢ä¹Ÿå­˜åœ¨å±€é™æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç§°ä¸º EndoGS çš„æ–¹æ³•ï¼Œå°†é«˜æ–¯æ•£ç‚¹æ³•åº”ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚EndoGS ç»“åˆäº†å˜å½¢åœºã€æ·±åº¦å¼•å¯¼ç›‘ç£å’Œæ—¶ç©ºæƒé‡æ©ç ï¼Œèƒ½å¤Ÿä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡è®°çš„å·¥å…·æ©ç ä¸­é‡å»ºå’Œæ¸²æŸ“é«˜è´¨é‡çš„å¯å˜å½¢å†…çª¥é•œç»„ç»‡ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEndoGS åœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚è¿™è¡¨æ˜ EndoGS å¯ä»¥ä¸ºä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚æ‰‹æœ¯å¢å¼ºç°å®ã€æ•™è‚²å’Œæœºå™¨äººå­¦ä¹ ï¼‰æä¾›é«˜è´¨é‡çš„å¯å˜å½¢ç»„ç»‡é‡å»ºã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1): æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸º EndoGS çš„æ–¹æ³•ï¼Œå®ƒå°†é«˜æ–¯æ•£ç‚¹æ³•åº”ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚
(2): EndoGS ç»“åˆäº†å˜å½¢åœºã€æ·±åº¦å¼•å¯¼ç›‘ç£å’Œæ—¶ç©ºæƒé‡æ©ç ï¼Œèƒ½å¤Ÿä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡è®°çš„å·¥å…·æ©ç ä¸­é‡å»ºå’Œæ¸²æŸ“é«˜è´¨é‡çš„å¯å˜å½¢å†…çª¥é•œç»„ç»‡ã€‚
(3): æˆ‘ä»¬ä½¿ç”¨å…­ä¸ªæ­£äº¤ç‰¹å¾å¹³é¢å¯¹ç©ºé—´å’Œæ—¶é—´ä¿¡æ¯è¿›è¡Œç¼–ç ï¼Œå¹¶ä½¿ç”¨å•ä¸ª MLP æ¥æ›´æ–°é«˜æ–¯å±æ€§ï¼Œä»¥è·å¾—å˜å½¢çš„ä½ç½®ã€æ¯”ä¾‹å› å­ã€æ—‹è½¬å› å­ã€çƒè°ç³»æ•°å’Œä¸é€æ˜åº¦ã€‚
(4): æˆ‘ä»¬ç»“åˆå·¥å…·æ©ç å’Œæ·±åº¦å›¾æ¥è®­ç»ƒ EndoGSï¼Œä»¥å¤„ç†å·¥å…·é®æŒ¡å’Œæé«˜é‡å»ºè´¨é‡ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æ•£ç‚¹æ³•è¿›è¡Œå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡è®°çš„å·¥å…·æ©ç ä¸­å®æ—¶æ¸²æŸ“é«˜è´¨é‡çš„å¯å˜å½¢ç»„ç»‡ã€‚åœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</p>
<p>ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹ï¼š</p>
<p>åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>å°†é«˜æ–¯æ•£ç‚¹æ³•åº”ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚</li>
<li>ç»“åˆå˜å½¢åœºã€æ·±åº¦å¼•å¯¼ç›‘ç£å’Œæ—¶ç©ºæƒé‡æ©ç ï¼Œä»¥å¤„ç†å·¥å…·é®æŒ¡å’Œæé«˜é‡å»ºè´¨é‡ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>éœ€è¦æ”¶é›†å’Œæ ‡è®°å¤§é‡çš„æ•°æ®ã€‚</li>
<li>éœ€è¦è®¾è®¡å’Œè®­ç»ƒå¤æ‚çš„æ¨¡å‹ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3aced720ad0952509d5ad4feafb073c5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-db38985f02aa9f93361d5395728da086.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f22f8ab59ea6655501c3858f5b7639aa.jpg" align="middle">
</details>
â€‹    


## SHINOBI: Shape and Illumination using Neural Object Decomposition via   BRDF Optimization In-the-wild
**Authors:Andreas Engelhardt, Amit Raj, Mark Boss, Yunzhi Zhang, Abhishek Kar, Yuanzhen Li, Deqing Sun, Ricardo Martin Brualla, Jonathan T. Barron, Hendrik P. A. Lensch, Varun Jampani**

We present SHINOBI, an end-to-end framework for the reconstruction of shape, material, and illumination from object images captured with varying lighting, pose, and background. Inverse rendering of an object based on unconstrained image collections is a long-standing challenge in computer vision and graphics and requires a joint optimization over shape, radiance, and pose. We show that an implicit shape representation based on a multi-resolution hash encoding enables faster and robust shape reconstruction with joint camera alignment optimization that outperforms prior work. Further, to enable the editing of illumination and object reflectance (i.e. material) we jointly optimize BRDF and illumination together with the object's shape. Our method is class-agnostic and works on in-the-wild image collections of objects to produce relightable 3D assets for several use cases such as AR/VR, movies, games, etc. Project page: https://shinobi.aengelhardt.com Video: https://www.youtube.com/watch?v=iFENQ6AcYd8&amp;feature=youtu.be 

[PDF](http://arxiv.org/abs/2401.10171v1) 

**æ‘˜è¦**
å¤šå°ºåº¦å“ˆå¸Œç¼–ç çš„éšå¼å½¢çŠ¶è¡¨ç¤ºä½¿æ›´å¿«é€Ÿã€æ›´é²æ£’çš„å½¢çŠ¶é‡å»ºæˆä¸ºå¯èƒ½ï¼Œå¹¶é€šè¿‡è”åˆç›¸æœºå¯¹é½ä¼˜åŒ–å®ç°äº†å¯¹ç°æœ‰æŠ€æœ¯çš„è¶…è¶Šã€‚

**è¦ç‚¹**
- SHINOBI æ˜¯ä¸€ç§ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œç”¨äºä»ä»¥ä¸åŒå…‰çº¿ã€å§¿åŠ¿å’ŒèƒŒæ™¯æ‹æ‘„çš„å¯¹è±¡å›¾åƒä¸­é‡å»ºå½¢çŠ¶ã€æè´¨å’Œç…§æ˜ã€‚
- SHINOBI ä½¿ç”¨åŸºäºå¤šå°ºåº¦å“ˆå¸Œç¼–ç çš„éšå¼å½¢çŠ¶è¡¨ç¤ºï¼Œèƒ½å¤Ÿå®ç°æ›´å¿«é€Ÿã€æ›´é²æ£’çš„å½¢çŠ¶é‡å»ºã€‚
- SHINOBI è¿˜å¯ä»¥ç¼–è¾‘ç…§æ˜å’Œå¯¹è±¡åå°„ç‡ï¼ˆå³æè´¨ï¼‰ï¼Œå¹¶ä¸å¯¹è±¡çš„å½¢çŠ¶ä¸€èµ·ä¼˜åŒ–åŒå‘åå°„åˆ†å¸ƒå‡½æ•°ï¼ˆBRDFï¼‰å’Œç…§æ˜ã€‚
- SHINOBI é€‚ç”¨äºå„ç§å„æ ·çš„å¯¹è±¡å›¾åƒé›†åˆï¼Œå¯ä»¥ä¸ºå¢å¼ºç°å®/è™šæ‹Ÿç°å®ã€ç”µå½±ã€æ¸¸æˆç­‰å¤šç§ç”¨ä¾‹ç”Ÿæˆå¯é‡æ–°ç…§æ˜çš„ 3D èµ„æºã€‚
- SHINOBI å¯ä»¥ä»ä¸é™æ•°é‡çš„å›¾åƒä¸­é‡å»ºå½¢çŠ¶ã€ææ–™å’Œç…§æ˜ã€‚
- SHINOBI è”åˆä¼˜åŒ– BRDF å’Œç…§æ˜ä»¥åŠå¯¹è±¡çš„å½¢çŠ¶ã€‚
- SHINOBI åœ¨å„ç§å„æ ·çš„å¯¹è±¡å›¾åƒé›†åˆä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå¹¶ä¸æœ€å…ˆè¿›çš„æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šSHINOBIï¼šåŸºäº BRDF ä¼˜åŒ–è¿›è¡Œå½¢çŠ¶å’Œå…‰ç…§åˆ†è§£çš„ç¥ç»ç‰©ä½“åˆ†è§£</p>
</li>
<li><p>ä½œè€…ï¼šAndreas Engelhardtã€Amit Rajã€Mark Bossã€Yunzhi Zhangã€Abhishek Karã€Yuanzhen Liã€Deqing Sunã€Ricardo Martin Bruallaã€Jonathan T. Barronã€Hendrik P. A. Lenschã€Varun Jampani</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¾·å›½å›¾å®¾æ ¹å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šè®¡ç®—æœºè§†è§‰ã€å›¾å½¢å­¦ã€ç¥ç»æ¸²æŸ“ã€å½¢çŠ¶é‡å»ºã€æè´¨ä¼°è®¡ã€å…‰ç…§ä¼°è®¡</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.10171ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šèƒŒæ™¯ï¼šé€†å‘æ¸²æŸ“åŸºäºæ— çº¦æŸå›¾åƒé›†åˆçš„å¯¹è±¡æ˜¯ä¸€ä¸ªé•¿æœŸå­˜åœ¨çš„æŒ‘æˆ˜ï¼Œéœ€è¦å¯¹å½¢çŠ¶ã€å…‰ç…§å’Œå§¿åŠ¿è¿›è¡Œè”åˆä¼˜åŒ–ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨æ˜¾å¼å½¢çŠ¶è¡¨ç¤ºï¼Œè¿™åœ¨å¤„ç†å…·æœ‰å¤æ‚å‡ ä½•å½¢çŠ¶çš„å¯¹è±¡æ—¶å­˜åœ¨å±€é™æ€§ã€‚æ­¤å¤–ï¼Œå®ƒä»¬é€šå¸¸éœ€è¦å¤§é‡çš„æ‰‹åŠ¨è°ƒæ•´å’Œç”¨æˆ·äº¤äº’ã€‚
(3)ï¼šæ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ SHINOBIï¼Œå®ƒä½¿ç”¨éšå¼å½¢çŠ¶è¡¨ç¤ºå’Œå¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç æ¥å®ç°æ›´å¿«é€Ÿå’Œé²æ£’çš„å½¢çŠ¶é‡å»ºã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶è¿˜è”åˆä¼˜åŒ– BRDF å’Œå…‰ç…§ï¼Œä»¥å®ç°å¯¹å…‰ç…§å’Œå¯¹è±¡åå°„ç‡çš„ç¼–è¾‘ã€‚
(4)ï¼šæ€§èƒ½ï¼šSHINOBI åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œå®ƒåœ¨å½¢çŠ¶é‡å»ºã€æè´¨ä¼°è®¡å’Œå…‰ç…§ä¼°è®¡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆé€¼çœŸçš„å¯ç…§æ˜ 3D èµ„äº§ï¼Œå¯ç”¨äº AR/VRã€ç”µå½±ã€æ¸¸æˆç­‰å¤šç§åº”ç”¨åœºæ™¯ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) <strong>éšå¼å½¢çŠ¶è¡¨ç¤º</strong>ï¼šSHINOBIä½¿ç”¨éšå¼å½¢çŠ¶è¡¨ç¤ºæ¥è¡¨ç¤ºå¯¹è±¡ï¼Œè¿™æ˜¯ä¸€ç§æ— ç•Œè¡¨ç¤ºï¼Œå¯ä»¥è½»æ¾å¤„ç†å…·æœ‰å¤æ‚å‡ ä½•å½¢çŠ¶çš„å¯¹è±¡ã€‚
(2) <strong>å¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç </strong>ï¼šSHINOBIä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç æ¥ç¼–ç éšå¼å½¢çŠ¶è¡¨ç¤ºï¼Œè¿™å¯ä»¥æé«˜å½¢çŠ¶é‡å»ºçš„é€Ÿåº¦å’Œé²æ£’æ€§ã€‚
(3) <strong>è”åˆä¼˜åŒ–BRDFå’Œå…‰ç…§</strong>ï¼šSHINOBIè”åˆä¼˜åŒ–BRDFå’Œå…‰ç…§ï¼Œä»¥å®ç°å¯¹å…‰ç…§å’Œå¯¹è±¡åå°„ç‡çš„ç¼–è¾‘ã€‚
(4) <strong>å¯ç…§æ˜3Dèµ„äº§ç”Ÿæˆ</strong>ï¼šSHINOBIå¯ä»¥ç”Ÿæˆé€¼çœŸçš„å¯ç…§æ˜3Dèµ„äº§ï¼Œå¯ç”¨äºAR/VRã€ç”µå½±ã€æ¸¸æˆç­‰å¤šç§åº”ç”¨åœºæ™¯ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ SHINOBIï¼Œè¯¥æ¡†æ¶å¯ä»¥ä»æœªç»æ‘†æ”¾çš„é‡å¤–å›¾åƒé›†ä¸­ä¼°è®¡ç‰©ä½“çš„å½¢çŠ¶ã€å§¿æ€å’Œå…‰ç…§ã€‚æˆ‘ä»¬æ–°é¢–çš„æ··åˆå“ˆå¸Œç½‘æ ¼ç¼–ç èƒ½å¤Ÿä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼æ›´å®¹æ˜“åœ°ä¼˜åŒ–ç›¸æœºå§¿æ€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€‰æ‹©çš„ç›¸æœºå‚æ•°åŒ–ä»¥åŠé€è§†å›¾é‡è¦æ€§æƒé‡å’ŒåŸºäºè¡¥ä¸çš„å¯¹é½æŸå¤±å…è®¸æ›´å¥½åœ°å°†å›¾åƒä¸ 3D å¯¹é½ï¼Œä»è€Œåœ¨å…·æœ‰é«˜é¢‘ç»†èŠ‚çš„æƒ…å†µä¸‹æ›´å¥½åœ°é‡å»ºã€‚è™½ç„¶ SHINOBI èƒ½å¤Ÿä»ä»»ä½•ç±»åˆ«çš„ç‰©ä½“ä¸­æ¢å¤å‡ ä½•å½¢çŠ¶ï¼Œä½†å…¶æ€§èƒ½åœ¨ç»†é•¿/é€æ˜ç»“æ„ä¸Šå—åˆ°é™åˆ¶ï¼Œå¹¶ä¸”æ— æ³•åœ¨æç«¯å…‰ç…§å˜åŒ–ä¸‹æ¢å¤é«˜é¢‘ç»†èŠ‚ï¼Œæˆ‘ä»¬å°†å…¶ç•™ä½œæœªæ¥å·¥ä½œçš„æ¢ç´¢ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>ä½¿ç”¨éšå¼å½¢çŠ¶è¡¨ç¤ºå’Œå¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç æ¥å®ç°æ›´å¿«é€Ÿå’Œé²æ£’çš„å½¢çŠ¶é‡å»ºã€‚</li>
<li>è”åˆä¼˜åŒ– BRDF å’Œå…‰ç…§ï¼Œä»¥å®ç°å¯¹å…‰ç…§å’Œå¯¹è±¡åå°„ç‡çš„ç¼–è¾‘ã€‚</li>
<li>å¯ä»¥ç”Ÿæˆé€¼çœŸçš„å¯ç…§æ˜ 3D èµ„äº§ï¼Œå¯ç”¨äº AR/VRã€ç”µå½±ã€æ¸¸æˆç­‰å¤šç§åº”ç”¨åœºæ™¯ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒSHINOBI åœ¨å½¢çŠ¶é‡å»ºã€æè´¨ä¼°è®¡å’Œå…‰ç…§ä¼°è®¡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>å¯ä»¥ç”Ÿæˆé€¼çœŸçš„å¯ç…§æ˜ 3D èµ„äº§ï¼Œå¯ç”¨äº AR/VRã€ç”µå½±ã€æ¸¸æˆç­‰å¤šç§åº”ç”¨åœºæ™¯ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>éœ€è¦æ‰‹åŠ¨è°ƒæ•´å’Œç”¨æˆ·äº¤äº’ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6fa4b83c9b053b9d6092eca8188f4657.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b1a74a4a26394cb29cc941c3540acec6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cad55e2949324c67746914275a9a371.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a4ea31f8709c7ac961337f4d618a8737.jpg" align="middle">
</details>
â€‹    


## GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting
**Authors:Mengtian Li, Shengxiang Yao, Zhifeng Xie, Keyu Chen, Yu-Gang Jiang**

In this work, we propose a novel clothed human reconstruction method called GaussianBody, based on 3D Gaussian Splatting. Compared with the costly neural radiance based models, 3D Gaussian Splatting has recently demonstrated great performance in terms of training time and rendering quality. However, applying the static 3D Gaussian Splatting model to the dynamic human reconstruction problem is non-trivial due to complicated non-rigid deformations and rich cloth details. To address these challenges, our method considers explicit pose-guided deformation to associate dynamic Gaussians across the canonical space and the observation space, introducing a physically-based prior with regularized transformations helps mitigate ambiguity between the two spaces. During the training process, we further propose a pose refinement strategy to update the pose regression for compensating the inaccurate initial estimation and a split-with-scale mechanism to enhance the density of regressed point clouds. The experiments validate that our method can achieve state-of-the-art photorealistic novel-view rendering results with high-quality details for dynamic clothed human bodies, along with explicit geometry reconstruction. 

[PDF](http://arxiv.org/abs/2401.09720v1) 

**Summary**
é«˜æ–¯äººä½“ï¼šåŸºäº 3D é«˜æ–¯æ•£å¸ƒçš„åŠ¨æ€ç©¿è¡£äººä½“é‡å»ºæ–¹æ³•ã€‚

**Key Takeaways**

- æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸º GaussianBody çš„æ–°å‹ç©¿è¡£äººä½“é‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŸºäº 3D é«˜æ–¯æ•£å¸ƒã€‚
- ä¸æ˜‚è´µçš„ç¥ç»è¾ç…§åº¦æ¨¡å‹ç›¸æ¯”ï¼Œ3D é«˜æ–¯æ•£å¸ƒåœ¨è®­ç»ƒæ—¶é—´å’Œæ¸²æŸ“è´¨é‡æ–¹é¢æœ€è¿‘è¡¨ç°å‡ºå‡ºè‰²çš„æ€§èƒ½ã€‚
- å°†é™æ€ 3D é«˜æ–¯æ•£å¸ƒæ¨¡å‹åº”ç”¨äºåŠ¨æ€äººä½“é‡å»ºé—®é¢˜å¹¶éæ˜“äº‹ï¼ŒåŸå› æ˜¯å¤æ‚çš„éåˆšæ€§å˜å½¢å’Œä¸°å¯Œçš„å¸ƒæ–™ç»†èŠ‚ã€‚
- ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è€ƒè™‘äº†æ˜¾å¼å§¿åŠ¿å¼•å¯¼å˜å½¢ï¼Œä»¥åœ¨è§„èŒƒç©ºé—´å’Œè§‚å¯Ÿç©ºé—´ä¸­å…³è”åŠ¨æ€é«˜æ–¯åˆ†å¸ƒï¼Œå¼•å…¥å…·æœ‰æ­£åˆ™åŒ–å˜æ¢çš„åŸºäºç‰©ç†çš„å…ˆéªŒæœ‰åŠ©äºå‡è½»ä¸¤ä¸ªç©ºé—´ä¹‹é—´çš„æ­§ä¹‰ã€‚
- åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§å§¿åŠ¿ä¼˜åŒ–ç­–ç•¥æ¥æ›´æ–°å§¿åŠ¿å›å½’ï¼Œä»¥è¡¥å¿ä¸å‡†ç¡®çš„åˆå§‹ä¼°è®¡ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå…·æœ‰å°ºåº¦çš„åˆ†å‰²æœºåˆ¶æ¥å¢å¼ºå›å½’ç‚¹äº‘çš„å¯†åº¦ã€‚
- å®éªŒéªŒè¯è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å®ç°åŠ¨æ€ç©¿ç€äººä½“çš„é«˜è´¨é‡ç»†èŠ‚ï¼Œä»¥åŠæ˜¾å¼å‡ ä½•é‡å»ºçš„æœ€å…ˆè¿›çš„ç…§ç‰‡çº§æ–°è§†è§’æ¸²æŸ“ç»“æœã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šé«˜æ–¯ä½“ï¼šåŸºäº 3D é«˜æ–¯æ•£ç‚¹çš„è¡£ç€äººä½“é‡å»º</li>
<li>ä½œè€…ï¼šå­Ÿå¤©åŠ›ã€å§šåœ£ç¿”ã€è°¢å¿—å³°ã€é™ˆå¯å®‡ã€å§œç‰åˆš</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸Šæµ·å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè¡£ç€äººä½“é‡å»ºã€3D é«˜æ–¯æ•£ç‚¹ã€åŠ¨æ€æ•æ‰ã€å‡ ä½•é‡å»º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.09720</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šé«˜ä¿çœŸè¡£ç€äººä½“æ¨¡å‹çš„åˆ›å»ºåœ¨è™šæ‹Ÿç°å®ã€è¿œç¨‹ä¸´åœºå’Œç”µå½±åˆ¶ä½œç­‰é¢†åŸŸå…·æœ‰é‡è¦åº”ç”¨ã€‚ä¼ ç»Ÿæ–¹æ³•è¦ä¹ˆæ¶‰åŠå¤æ‚çš„æ•æ‰ç³»ç»Ÿï¼Œè¦ä¹ˆéœ€è¦ 3D è‰ºæœ¯å®¶è¿›è¡Œç¹ççš„æ‰‹å·¥å·¥ä½œï¼Œè¿™ä½¿å¾—å®ƒä»¬è€—æ—¶ä¸”æ˜‚è´µï¼Œä»è€Œé™åˆ¶äº†æ–°æ‰‹ç”¨æˆ·çš„å¯æ‰©å±•æ€§ã€‚æœ€è¿‘ï¼Œäººä»¬è¶Šæ¥è¶Šå…³æ³¨ä»å•ä¸ª RGB å›¾åƒæˆ–å•ç›®è§†é¢‘ä¸­è‡ªåŠ¨é‡å»ºè¡£ç€äººä½“æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šåŸºäºç½‘æ ¼çš„æ–¹æ³•æœ€åˆè¢«å¼•å…¥ï¼Œé€šè¿‡å›å½’å‚æ•°åŒ–æ¨¡å‹ï¼ˆå¦‚ SCAPEã€SMPLã€SMPL-X å’Œ STARï¼‰æ¥æ¢å¤äººä½“å½¢çŠ¶ã€‚è™½ç„¶å®ƒä»¬å¯ä»¥å®ç°å¿«é€Ÿä¸”é²æ£’çš„é‡å»ºï¼Œä½†å›å½’çš„å¤šè¾¹å½¢ç½‘æ ¼éš¾ä»¥æ•æ‰ä¸åŒçš„å‡ ä½•ç»†èŠ‚å’Œä¸°å¯Œçš„æœè£…ç‰¹å¾ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ·»åŠ é¡¶ç‚¹åç§»æˆä¸ºä¸€ç§å¢å¼ºè§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå®ƒçš„è¡¨ç¤ºèƒ½åŠ›ä»ç„¶æœ‰é™ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯æ•£ç‚¹çš„æ–°å‹è¡£ç€äººä½“é‡å»ºæ–¹æ³•ï¼Œç§°ä¸ºé«˜æ–¯ä½“ã€‚ä¸æ˜‚è´µçš„ç¥ç»è¾å°„ä½“æ¨¡å‹ç›¸æ¯”ï¼Œ3D é«˜æ–¯æ•£ç‚¹æœ€è¿‘åœ¨è®­ç»ƒæ—¶é—´å’Œæ¸²æŸ“è´¨é‡æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç”±äºå¤æ‚çš„éåˆšæ€§å˜å½¢å’Œä¸°å¯Œçš„æœè£…ç»†èŠ‚ï¼Œå°†é™æ€ 3D é«˜æ–¯æ•£ç‚¹æ¨¡å‹åº”ç”¨äºåŠ¨æ€äººä½“é‡å»ºé—®é¢˜å¹¶éæ˜“äº‹ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•è€ƒè™‘äº†åœ¨è§„èŒƒç©ºé—´å’Œè§‚å¯Ÿç©ºé—´ä¸­å¯¹åŠ¨æ€é«˜æ–¯ä½“è¿›è¡Œæ˜¾å¼å§¿åŠ¿å¼•å¯¼çš„å˜å½¢ï¼Œå¼•å…¥äº†å…·æœ‰æ­£åˆ™åŒ–å˜æ¢çš„åŸºäºç‰©ç†çš„å…ˆéªŒï¼Œæœ‰åŠ©äºå‡è½»ä¸¤ä¸ªç©ºé—´ä¹‹é—´çš„æ­§ä¹‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§å§¿åŠ¿ç»†åŒ–ç­–ç•¥æ¥æ›´æ–°å§¿åŠ¿å›å½’ï¼Œä»¥è¡¥å¿ä¸å‡†ç¡®çš„åˆå§‹ä¼°è®¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§åˆ†è£‚ç¼©æ”¾æœºåˆ¶æ¥å¢å¼ºå›å½’ç‚¹äº‘çš„å¯†åº¦ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒéªŒè¯äº†æœ¬æ–‡æ–¹æ³•å¯ä»¥å®ç°åŠ¨æ€è¡£ç€äººä½“çš„é«˜è´¨é‡ç»†èŠ‚çš„æœ€æ–°é€¼çœŸæ–°è§†è§’æ¸²æŸ“ç»“æœï¼Œä»¥åŠæ˜¾å¼çš„å‡ ä½•é‡å»ºã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº3Dé«˜æ–¯æ•£ç‚¹çš„æ–°å‹è¡£ç€äººä½“é‡å»ºæ–¹æ³•GaussianBodyï¼Œè¯¥æ–¹æ³•å¯ä»¥ä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŠ¨æ€è¡£ç€äººä½“æ¨¡å‹ã€‚GaussianBodyé€šè¿‡åœ¨è§„èŒƒç©ºé—´å’Œè§‚å¯Ÿç©ºé—´ä¸­å¯¹åŠ¨æ€é«˜æ–¯ä½“è¿›è¡Œæ˜¾å¼å§¿åŠ¿å¼•å¯¼çš„å˜å½¢ï¼Œä»¥åŠå¼•å…¥å…·æœ‰æ­£åˆ™åŒ–å˜æ¢çš„åŸºäºç‰©ç†çš„å…ˆéªŒï¼Œè§£å†³äº†åŠ¨æ€è¡£ç€äººä½“é‡å»ºä¸­å­˜åœ¨çš„å¤æ‚éåˆšæ€§å˜å½¢å’Œä¸°å¯Œçš„æœè£…ç»†èŠ‚ç­‰æŒ‘æˆ˜ã€‚å®éªŒè¡¨æ˜ï¼ŒGaussianBodyå¯ä»¥å®ç°é«˜è´¨é‡ç»†èŠ‚çš„æœ€æ–°é€¼çœŸæ–°è§†è§’æ¸²æŸ“ç»“æœï¼Œä»¥åŠæ˜¾å¼çš„å‡ ä½•é‡å»ºã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§åŸºäº3Dé«˜æ–¯æ•£ç‚¹çš„æ–°å‹è¡£ç€äººä½“é‡å»ºæ–¹æ³•GaussianBodyã€‚</li>
<li>åœ¨è§„èŒƒç©ºé—´å’Œè§‚å¯Ÿç©ºé—´ä¸­å¯¹åŠ¨æ€é«˜æ–¯ä½“è¿›è¡Œæ˜¾å¼å§¿åŠ¿å¼•å¯¼çš„å˜å½¢ï¼Œè§£å†³äº†åŠ¨æ€è¡£ç€äººä½“é‡å»ºä¸­å­˜åœ¨çš„å¤æ‚éåˆšæ€§å˜å½¢å’Œä¸°å¯Œçš„æœè£…ç»†èŠ‚ç­‰æŒ‘æˆ˜ã€‚</li>
<li>å¼•å…¥å…·æœ‰æ­£åˆ™åŒ–å˜æ¢çš„åŸºäºç‰©ç†çš„å…ˆéªŒï¼Œæœ‰åŠ©äºå‡è½»ä¸¤ä¸ªç©ºé—´ä¹‹é—´çš„æ­§ä¹‰ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å§¿åŠ¿ç»†åŒ–ç­–ç•¥æ¥æ›´æ–°å§¿åŠ¿å›å½’ï¼Œä»¥è¡¥å¿ä¸å‡†ç¡®çš„åˆå§‹ä¼°è®¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§åˆ†è£‚ç¼©æ”¾æœºåˆ¶æ¥å¢å¼ºå›å½’ç‚¹äº‘çš„å¯†åº¦ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>GaussianBodyå¯ä»¥å®ç°é«˜è´¨é‡ç»†èŠ‚çš„æœ€æ–°é€¼çœŸæ–°è§†è§’æ¸²æŸ“ç»“æœï¼Œä»¥åŠæ˜¾å¼çš„å‡ ä½•é‡å»ºã€‚</li>
<li>GaussianBodyåœ¨å›¾åƒè´¨é‡æŒ‡æ ‡æ–¹é¢ä¸åŸºçº¿å’Œå…¶ä»–æ–¹æ³•ç›¸å½“ï¼Œè¯æ˜äº†å…¶ç«äº‰æ€§èƒ½ã€ç›¸å¯¹è¾ƒå¿«çš„è®­ç»ƒé€Ÿåº¦ï¼Œä»¥åŠä½¿ç”¨æ›´é«˜åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œè®­ç»ƒçš„èƒ½åŠ›ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>GaussianBodyéœ€è¦æ”¶é›†å’Œæ ‡æ³¨å¤§é‡çš„æ•°æ®ã€‚</li>
<li>GaussianBodyçš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒå¤§çš„è®¡ç®—èµ„æºã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7931aa02d87b1007c7f5cdde77107e5c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3d3dcd00c27bc3d320b23d4247ae79f3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3df005c3ea738aba56feb680b23b73d2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d121364f4f1fecac5ef9d276f421f434.jpg" align="middle">
</details>
â€‹    


## PPSURF: Combining Patches and Point Convolutions for Detailed Surface   Reconstruction
**Authors:Philipp Erler, Lizeth Fuentes, Pedro Hermosilla, Paul Guerrero, Renato Pajarola Michael Wimmer**

3D surface reconstruction from point clouds is a key step in areas such as content creation, archaeology, digital cultural heritage, and engineering. Current approaches either try to optimize a non-data-driven surface representation to fit the points, or learn a data-driven prior over the distribution of commonly occurring surfaces and how they correlate with potentially noisy point clouds. Data-driven methods enable robust handling of noise and typically either focus on a global or a local prior, which trade-off between robustness to noise on the global end and surface detail preservation on the local end. We propose PPSurf as a method that combines a global prior based on point convolutions and a local prior based on processing local point cloud patches. We show that this approach is robust to noise while recovering surface details more accurately than the current state-of-the-art.   Our source code, pre-trained model and dataset are available at: https://github.com/cg-tuwien/ppsurf 

[PDF](http://arxiv.org/abs/2401.08518v1) Published in Computer Graphics Forum (Jan 2024):   https://onlinelibrary.wiley.com/doi/10.1111/cgf.15000

**Summary**
äº‘ç‚¹é‡å»ºç»“åˆå±€éƒ¨ç‰¹å¾ä¸å…¨å±€ä¿¡æ¯ï¼Œæå‡è¡¨é¢é‡å»ºçš„æŠ—å™ªæ€§å’Œç»†èŠ‚ä¿å­˜èƒ½åŠ›ã€‚

**Key Takeaways**

- è¡¨é¢é‡å»ºæ˜¯å†…å®¹åˆ›å»ºã€è€ƒå¤å­¦ã€æ•°å­—æ–‡åŒ–é—äº§å’Œå·¥ç¨‹ç­‰é¢†åŸŸçš„å…³é”®æ­¥éª¤ã€‚
- å½“å‰æ–¹æ³•è¦ä¹ˆå°è¯•ä¼˜åŒ–éæ•°æ®é©±åŠ¨çš„æ›²é¢è¡¨ç¤ºä»¥æ‹Ÿåˆç‚¹ï¼Œè¦ä¹ˆå­¦ä¹ æ•°æ®é©±åŠ¨çš„å…ˆéªŒåˆ†å¸ƒï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•ä¸æ½œåœ¨çš„å™ªå£°ç‚¹äº‘ç›¸å…³ã€‚
- æ•°æ®é©±åŠ¨çš„æ–¹æ³•èƒ½å¤Ÿå¯¹å™ªå£°è¿›è¡Œé²æ£’å¤„ç†ï¼Œé€šå¸¸ä¸“æ³¨äºå…¨å±€æˆ–å±€éƒ¨å…ˆéªŒï¼Œåœ¨å…¨å±€æœ«ç«¯çš„æŠ—å™ªæ€§å’Œå±€éƒ¨æœ«ç«¯çš„è¡¨é¢ç»†èŠ‚ä¿ç•™ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚
- PPSurf æ˜¯ä¸€ç§å°†åŸºäºç‚¹å·ç§¯çš„å…¨å±€å…ˆéªŒä¸åŸºäºå¤„ç†å±€éƒ¨ç‚¹äº‘å—çš„å±€éƒ¨å…ˆéªŒç›¸ç»“åˆçš„æ–¹æ³•ã€‚
- PPSurf åœ¨æ¢å¤è¡¨é¢ç»†èŠ‚æ–¹é¢æ¯”å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•æ›´å‡†ç¡®ã€‚
- PPSurf çš„æºä»£ç ã€é¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†å¯åœ¨ https://github.com/cg-tuwien/ppsurf è·å–ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>æ ‡é¢˜ï¼šPPSURFï¼šç»“åˆå±€éƒ¨å—å’Œç‚¹å·ç§¯è¿›è¡Œè¯¦ç»†è¡¨é¢é‡å»º</p>
</li>
<li><p>ä½œè€…ï¼šP. Erlerã€L. Fuentes-Perezã€P. Hermosillaã€P. Guerreroã€R. Pajarolaã€M. Wimmer</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šç»´ä¹Ÿçº³å·¥ä¸šå¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šç‚¹äº‘ã€è¡¨é¢é‡å»ºã€æ•°æ®é©±åŠ¨ã€å±€éƒ¨å—ã€ç‚¹å·ç§¯</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://onlinelibrary.wiley.com/doi/10.1111/cgf.150001
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/cg-tuwien/ppsurf</p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼š3D è¡¨é¢é‡å»ºæ˜¯å†…å®¹åˆ›ä½œã€è€ƒå¤å­¦ã€æ•°å­—æ–‡åŒ–é—äº§å’Œå·¥ç¨‹ç­‰é¢†åŸŸçš„å…³é”®æ­¥éª¤ã€‚ç›®å‰çš„æ–¹æ³•è¦ä¹ˆå°è¯•ä¼˜åŒ–éæ•°æ®é©±åŠ¨çš„è¡¨é¢è¡¨ç¤ºä»¥æ‹Ÿåˆç‚¹ï¼Œè¦ä¹ˆå­¦ä¹ æ•°æ®é©±åŠ¨çš„å…ˆéªŒï¼Œäº†è§£å¸¸è§è¡¨é¢å’Œæ½œåœ¨å™ªå£°ç‚¹äº‘ä¹‹é—´çš„åˆ†å¸ƒå’Œç›¸å…³æ€§ã€‚æ•°æ®é©±åŠ¨çš„æ–¹æ³•èƒ½å¤Ÿç¨³å¥åœ°å¤„ç†å™ªå£°ï¼Œé€šå¸¸ä¾§é‡äºå…¨å±€æˆ–å±€éƒ¨å…ˆéªŒï¼Œè¿™åœ¨å…¨å±€ç«¯ä¸å™ªå£°çš„ç¨³å¥æ€§å’Œå±€éƒ¨ç«¯è¡¨é¢ç»†èŠ‚çš„ä¿ç•™ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•è¦ä¹ˆå°è¯•ä¼˜åŒ–éæ•°æ®é©±åŠ¨çš„è¡¨é¢è¡¨ç¤ºä»¥æ‹Ÿåˆç‚¹ï¼Œè¦ä¹ˆå­¦ä¹ æ•°æ®é©±åŠ¨çš„å…ˆéªŒï¼Œäº†è§£å¸¸è§è¡¨é¢å’Œæ½œåœ¨å™ªå£°ç‚¹äº‘ä¹‹é—´çš„åˆ†å¸ƒå’Œç›¸å…³æ€§ã€‚æ•°æ®é©±åŠ¨çš„æ–¹æ³•èƒ½å¤Ÿç¨³å¥åœ°å¤„ç†å™ªå£°ï¼Œä½†é€šå¸¸ä¾§é‡äºå…¨å±€æˆ–å±€éƒ¨å…ˆéªŒï¼Œè¿™åœ¨å…¨å±€ç«¯ä¸å™ªå£°çš„ç¨³å¥æ€§å’Œå±€éƒ¨ç«¯è¡¨é¢ç»†èŠ‚çš„ä¿ç•™ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º PPSURF çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†åŸºäºç‚¹å·ç§¯çš„å…¨å±€å…ˆéªŒå’ŒåŸºäºå¤„ç†å±€éƒ¨ç‚¹äº‘å—çš„å±€éƒ¨å…ˆéªŒã€‚
ï¼ˆ4ï¼‰ï¼šåœ¨å™ªå£°ç‚¹äº‘é‡å»ºä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨æ¢å¤è¡¨é¢ç»†èŠ‚çš„åŒæ—¶ï¼Œå¯¹å™ªå£°å…·æœ‰é²æ£’æ€§ï¼Œä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1)ï¼šPPSURFæ–¹æ³•å°†åŸºäºç‚¹å·ç§¯çš„å…¨å±€å…ˆéªŒä¸åŸºäºå¤„ç†å±€éƒ¨ç‚¹äº‘å—çš„å±€éƒ¨å…ˆéªŒç›¸ç»“åˆï¼Œä»¥å®ç°è¯¦ç»†çš„è¡¨é¢é‡å»ºã€‚
(2)ï¼šå…¨å±€åˆ†æ”¯ä½¿ç”¨POCOç½‘ç»œï¼Œè¯¥ç½‘ç»œç”±ç‚¹å·ç§¯æ¨¡å—å’Œæ’å€¼æ¨¡å—ç»„æˆï¼Œç‚¹å·ç§¯æ¨¡å—è®¡ç®—æ¯ä¸ªç¨€ç–ç‚¹çš„ç‰¹å¾å‘é‡ï¼Œæ’å€¼æ¨¡å—ä½¿ç”¨åŸºäºæ³¨æ„åŠ›çš„æƒé‡å¯¹ç‰¹å¾å‘é‡è¿›è¡Œæ’å€¼ä»¥è·å¾—å…¨å±€ç‰¹å¾å‘é‡ã€‚
(3)ï¼šå±€éƒ¨åˆ†æ”¯ä½¿ç”¨PointNetç½‘ç»œï¼Œè¯¥ç½‘ç»œç»è¿‡ä¿®æ”¹ï¼Œé‡‡ç”¨åŸºäºæ³¨æ„åŠ›çš„èšåˆæ–¹å¼ï¼Œè€Œä¸æ˜¯åŸå§‹çš„æœ€å¤§å€¼æˆ–å’Œå€¼èšåˆæ–¹å¼ï¼Œä»¥è·å¾—å±€éƒ¨ç‰¹å¾å‘é‡ã€‚
(4)ï¼šå…¨å±€ç‰¹å¾å‘é‡å’Œå±€éƒ¨ç‰¹å¾å‘é‡é€šè¿‡MLPç»„åˆï¼Œä»¥è®¡ç®—æŸ¥è¯¢ç‚¹å¤„çš„å ç”¨æ¦‚ç‡ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º PPSURF çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†åŸºäºç‚¹å·ç§¯çš„å…¨å±€å…ˆéªŒä¸åŸºäºå¤„ç†å±€éƒ¨ç‚¹äº‘å—çš„å±€éƒ¨å…ˆéªŒç›¸ç»“åˆï¼Œä»¥å®ç°è¯¦ç»†çš„è¡¨é¢é‡å»ºã€‚åœ¨å™ªå£°ç‚¹äº‘é‡å»ºä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨æ¢å¤è¡¨é¢ç»†èŠ‚çš„åŒæ—¶ï¼Œå¯¹å™ªå£°å…·æœ‰é²æ£’æ€§ï¼Œä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>å°†åŸºäºç‚¹å·ç§¯çš„å…¨å±€å…ˆéªŒä¸åŸºäºå¤„ç†å±€éƒ¨ç‚¹äº‘å—çš„å±€éƒ¨å…ˆéªŒç›¸ç»“åˆï¼Œä»¥å®ç°è¯¦ç»†çš„è¡¨é¢é‡å»ºã€‚</li>
<li>ä½¿ç”¨åŸºäºæ³¨æ„åŠ›çš„èšåˆæ–¹å¼ï¼Œè€Œä¸æ˜¯åŸå§‹çš„æœ€å¤§å€¼æˆ–å’Œå€¼èšåˆæ–¹å¼ï¼Œä»¥è·å¾—å±€éƒ¨ç‰¹å¾å‘é‡ã€‚</li>
<li>åœ¨å™ªå£°ç‚¹äº‘é‡å»ºä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨æ¢å¤è¡¨é¢ç»†èŠ‚çš„åŒæ—¶ï¼Œå¯¹å™ªå£°å…·æœ‰é²æ£’æ€§ï¼Œä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨ ABCvar-noise æµ‹è¯•é›†ä¸Šï¼ŒPPSURF åœ¨ Chamfer è·ç¦»ã€F1 åˆ†æ•°å’Œæ³•çº¿è¯¯å·®æ–¹é¢å‡ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>åœ¨ PatchSize æ¶ˆèç ”ç©¶ä¸­ï¼ŒPPSURF100NN å’Œ PPSURF200NN åœ¨ Chamfer è·ç¦»å’Œ F1 åˆ†æ•°æ–¹é¢ä¸ PPSURFFull ç›¸å½“ï¼Œä½†åœ¨æ³•çº¿è¯¯å·®æ–¹é¢ç•¥å·®ã€‚</li>
<li>åœ¨ Miscellanous æ¶ˆèç ”ç©¶ä¸­ï¼ŒPPSURFSymMax åœ¨ Chamfer è·ç¦»æ–¹é¢ä¼˜äº PPSURFFullï¼Œä½†åœ¨ F1 åˆ†æ•°å’Œæ³•çº¿è¯¯å·®æ–¹é¢ç•¥å·®ã€‚PPSURFQPoints åœ¨ F1 åˆ†æ•°å’Œæ³•çº¿è¯¯å·®æ–¹é¢ä¼˜äº PPSURFFullï¼Œä½†åœ¨ Chamfer è·ç¦»æ–¹é¢ç•¥å·®ã€‚PPSURFMergeCat åœ¨ Chamfer è·ç¦»å’Œ F1 åˆ†æ•°æ–¹é¢ä¸ PPSURFFull ç›¸å½“ï¼Œä½†åœ¨æ³•çº¿è¯¯å·®æ–¹é¢ç•¥å·®ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>PPSURF çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºç†è§£å’Œä½¿ç”¨ã€‚</li>
<li>PPSURF çš„è®­ç»ƒæ—¶é—´å’Œæ¨ç†æ—¶é—´ä¸å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-deb0c891a44eda3abc848abfcb3b5052.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9b71a526973638d7a94c6cac1ef5d0c4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-78b2aade816834cf694d7949cbee5c89.jpg" align="middle">
</details>
â€‹    

â€‹    

## InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes
**Authors:Mohamad Shahbazi, Liesbeth Claessens, Michael Niemeyer, Edo Collins, Alessio Tonioni, Luc Van Gool, Federico Tombari**

We introduce InseRF, a novel method for generative object insertion in the NeRF reconstructions of 3D scenes. Based on a user-provided textual description and a 2D bounding box in a reference viewpoint, InseRF generates new objects in 3D scenes. Recently, methods for 3D scene editing have been profoundly transformed, owing to the use of strong priors of text-to-image diffusion models in 3D generative modeling. Existing methods are mostly effective in editing 3D scenes via style and appearance changes or removing existing objects. Generating new objects, however, remains a challenge for such methods, which we address in this study. Specifically, we propose grounding the 3D object insertion to a 2D object insertion in a reference view of the scene. The 2D edit is then lifted to 3D using a single-view object reconstruction method. The reconstructed object is then inserted into the scene, guided by the priors of monocular depth estimation methods. We evaluate our method on various 3D scenes and provide an in-depth analysis of the proposed components. Our experiments with generative insertion of objects in several 3D scenes indicate the effectiveness of our method compared to the existing methods. InseRF is capable of controllable and 3D-consistent object insertion without requiring explicit 3D information as input. Please visit our project page at https://mohamad-shahbazi.github.io/inserf. 

[PDF](http://arxiv.org/abs/2401.05335v1) 

**æ‘˜è¦**
ç¥ç»è¾å°„åœºä¸‰ç»´é‡å»ºä¸­ï¼Œé€šè¿‡ç”¨æˆ·æä¾›çš„æ–‡æœ¬æè¿°å’Œå‚è€ƒè§†ç‚¹ä¸­çš„äºŒç»´è¾¹ç•Œæ¡†ï¼Œå®ç°æ–°çš„ç‰©ä½“ç”Ÿæˆã€‚

**è¦ç‚¹**

- InseRF æ˜¯ä¸€ç§ä¸‰ç»´åœºæ™¯ç¥ç»è¾å°„åœºä¸­ç”Ÿæˆå¼ç‰©ä½“æ’å…¥çš„æ–°é¢–æ–¹æ³•ï¼Œæ”¯æŒç”Ÿæˆæ–°çš„ç‰©ä½“å¹¶å°†å…¶æ’å…¥ä¸‰ç»´åœºæ™¯ä¸­ã€‚
- InseRF ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ç¼–è¾‘ä¸‰ç»´åœºæ™¯çš„æ ·å¼å’Œå¤–è§‚ï¼Œæˆ–ç§»é™¤ç°æœ‰ç‰©ä½“ã€‚
- InseRF å°†ä¸‰ç»´ç‰©ä½“æ’å…¥æ“ä½œè½¬åŒ–ä¸ºå‚è€ƒè§†å›¾ä¸­çš„äºŒç»´ç‰©ä½“æ’å…¥ï¼Œå¹¶ä½¿ç”¨å•è§†å›¾ç‰©ä½“é‡å»ºæ–¹æ³•å°†äºŒç»´ç¼–è¾‘æå‡åˆ°ä¸‰ç»´ã€‚
- InseRF åˆ©ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ–¹æ³•çš„å…ˆéªŒçŸ¥è¯†ï¼Œå°†é‡å»ºçš„ç‰©ä½“æ’å…¥åœºæ™¯ä¸­ã€‚
- InseRF åœ¨å¤šä¸ªä¸‰ç»´åœºæ™¯ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜å…¶ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
- InseRF èƒ½å¤Ÿç”Ÿæˆå¯æ§å’Œä¸‰ç»´ä¸€è‡´çš„ç‰©ä½“ï¼Œä¸”ä¸éœ€è¦æ˜¾å¼çš„ä¸‰ç»´ä¿¡æ¯ä½œä¸ºè¾“å…¥ã€‚
- InseRF é¡¹ç›®ä¸»é¡µï¼šhttps://mohamad-shahbazi.github.io/inserfã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šæ— ç²¾ä¿® URLï¼š</p>
</li>
<li><p>ä½œè€…ï¼šMohamad Shahbazi<em>, Anh-Huy Phan</em>, Jia-Bin Huang, Yi-Ling Qiao, Hao Tang, Matthew Fisher, Angela Dai</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢ï¼ˆETH Zurichï¼‰</p>
</li>
<li><p>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å¯¹è±¡æ’å…¥ã€æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šæ— ï¼ŒGithub é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œ3D åœºæ™¯ç¼–è¾‘æ–¹æ³•å–å¾—äº†é‡å¤§è¿›å±•ï¼Œè¿™ä¸»è¦å½’åŠŸäºåœ¨ 3D ç”Ÿæˆå»ºæ¨¡ä¸­ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¼ºå…ˆéªŒã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡æ”¹å˜æ ·å¼å’Œå¤–è§‚æˆ–ç§»é™¤ç°æœ‰å¯¹è±¡æ¥ç¼–è¾‘ 3D åœºæ™¯ã€‚ç„¶è€Œï¼Œç”Ÿæˆæ–°å¯¹è±¡å¯¹äºè¿™äº›æ–¹æ³•æ¥è¯´ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•çš„é—®é¢˜åœ¨äºï¼Œå®ƒä»¬æ— æ³•ç”Ÿæˆæ–°çš„å¯¹è±¡ï¼Œå¹¶ä¸”éœ€è¦æ˜¾å¼çš„ 3D ä¿¡æ¯ä½œä¸ºè¾“å…¥ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• InseRFï¼Œå®ƒå¯ä»¥æ ¹æ®ç”¨æˆ·æä¾›çš„æ–‡æœ¬æè¿°å’Œå‚è€ƒè§†ç‚¹ä¸­çš„ 2D è¾¹ç•Œæ¡†åœ¨ NeRF é‡å»ºçš„ 3D åœºæ™¯ä¸­ç”Ÿæˆæ–°å¯¹è±¡ã€‚InseRF å°† 2D ç¼–è¾‘æå‡åˆ° 3Dï¼Œä½¿ç”¨å•è§†å›¾å¯¹è±¡é‡å»ºæ–¹æ³•é‡å»ºå¯¹è±¡ï¼Œç„¶ååœ¨å•ç›®æ·±åº¦ä¼°è®¡æ–¹æ³•çš„æŒ‡å¯¼ä¸‹å°†é‡å»ºçš„å¯¹è±¡æ’å…¥åœºæ™¯ä¸­ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒè¡¨æ˜ï¼ŒInseRF åœ¨å¤šä¸ª 3D åœºæ™¯ä¸­ç”Ÿæˆæ’å…¥å¯¹è±¡çš„ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚InseRF èƒ½å¤Ÿä»¥å¯æ§ä¸” 3D ä¸€è‡´çš„æ–¹å¼æ’å…¥å¯¹è±¡ï¼Œè€Œæ— éœ€æ˜¾å¼ 3D ä¿¡æ¯ä½œä¸ºè¾“å…¥ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) è¾“å…¥ï¼šInseRF çš„è¾“å…¥æ˜¯ä¸€ä¸ª NeRF é‡å»ºçš„ 3D åœºæ™¯ã€ä¸€ä¸ªæ–‡æœ¬æè¿°å’Œä¸€ä¸ªå‚è€ƒè§†ç‚¹ä¸­çš„ 2D è¾¹ç•Œæ¡†ã€‚
(2) å¯¹è±¡é‡å»ºï¼šInseRF ä½¿ç”¨å•è§†å›¾å¯¹è±¡é‡å»ºæ–¹æ³•é‡å»ºå¯¹è±¡ã€‚
(3) å¯¹è±¡æ’å…¥ï¼šInseRF ä½¿ç”¨å•ç›®æ·±åº¦ä¼°è®¡æ–¹æ³•ä¼°è®¡å¯¹è±¡çš„æ·±åº¦ï¼Œç„¶åå°†é‡å»ºçš„å¯¹è±¡æ’å…¥åœºæ™¯ä¸­ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šInseRF æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬æè¿°å’Œ 2D è¾¹ç•Œæ¡†åœ¨ NeRF é‡å»ºçš„ 3D åœºæ™¯ä¸­ç”Ÿæˆæ–°å¯¹è±¡ï¼Œæ— éœ€æ˜¾å¼ 3D ä¿¡æ¯ä½œä¸ºè¾“å…¥ã€‚
æ€§èƒ½ï¼šInseRF åœ¨å¤šä¸ª 3D åœºæ™¯ä¸­ç”Ÿæˆæ’å…¥å¯¹è±¡çš„ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œèƒ½å¤Ÿä»¥å¯æ§ä¸” 3D ä¸€è‡´çš„æ–¹å¼æ’å…¥å¯¹è±¡ã€‚
å·¥ä½œé‡ï¼šInseRF çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦ç»“åˆå•è§†å›¾å¯¹è±¡é‡å»ºæ–¹æ³•å’Œå•ç›®æ·±åº¦ä¼°è®¡æ–¹æ³•ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9f528d642820c297073b934ba1373992.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8499c6fe071df44b8e34eafc6e0a99e2.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Vision-Reimagined-AI-Powered-Breakthroughs-in-WiFi-Indoor-Imaging"><a href="#Vision-Reimagined-AI-Powered-Breakthroughs-in-WiFi-Indoor-Imaging" class="headerlink" title="Vision Reimagined: AI-Powered Breakthroughs in WiFi Indoor Imaging"></a>Vision Reimagined: AI-Powered Breakthroughs in WiFi Indoor Imaging</h2><p><strong>Authors:Jianyang Shi, Bowen Zhang, Amartansh Dubey, Ross Murch, Liwen Jing</strong></p>
<p>Indoor imaging is a critical task for robotics and internet-of-things. WiFi as an omnipresent signal is a promising candidate for carrying out passive imaging and synchronizing the up-to-date information to all connected devices. This is the first research work to consider WiFi indoor imaging as a multi-modal image generation task that converts the measured WiFi power into a high-resolution indoor image. Our proposed WiFi-GEN network achieves a shape reconstruction accuracy that is 275% of that achieved by physical model-based inversion methods. Additionally, the Frechet Inception Distance score has been significantly reduced by 82%. To examine the effectiveness of models for this task, the first large-scale dataset is released containing 80,000 pairs of WiFi signal and imaging target. Our model absorbs challenges for the model-based methods including the non-linearity, ill-posedness and non-certainty into massive parameters of our generative AI network. The network is also designed to best fit measured WiFi signals and the desired imaging output. For reproducibility, we will release the data and code upon acceptance. </p>
<p><a href="http://arxiv.org/abs/2401.04317v1">PDF</a> </p>
<p><strong>Summary</strong><br>å®¤å†…æˆåƒé€šè¿‡Wi-Fiä¿¡å·ï¼Œå°†æµ‹é‡åˆ°çš„Wi-FiåŠŸç‡è½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Wi-Fiå®¤å†…æˆåƒè¢«è§†ä¸ºå¤šæ¨¡æ€å›¾åƒç”Ÿæˆä»»åŠ¡ã€‚</li>
<li>Wi-Fi-GENç½‘ç»œçš„å½¢çŠ¶é‡å»ºç²¾åº¦æ˜¯åŸºäºç‰©ç†æ¨¡å‹çš„åæ¼”æ–¹æ³•çš„275%ã€‚</li>
<li>FrÃ©chetèµ·å§‹è·ç¦»è¯„åˆ†é™ä½äº†82%ã€‚</li>
<li>å‘å¸ƒäº†é¦–ä¸ªå¤§å‹æ•°æ®é›†ï¼ŒåŒ…å«80,000å¯¹Wi-Fiä¿¡å·å’Œæˆåƒç›®æ ‡ã€‚</li>
<li>Wi-Fi-GENç½‘ç»œå°†åŸºäºæ¨¡å‹çš„æ–¹æ³•çš„æŒ‘æˆ˜å¸æ”¶ä¸ºç”Ÿæˆæ€§AIç½‘ç»œçš„å¤§é‡å‚æ•°ã€‚</li>
<li>ç½‘ç»œè®¾è®¡ç”¨äºæœ€é€‚åˆæµ‹é‡çš„Wi-Fiä¿¡å·å’Œæ‰€éœ€çš„æˆåƒè¾“å‡ºã€‚</li>
<li>ä¸ºäº†å¯å¤åˆ¶æ€§ï¼Œæˆ‘ä»¬å°†å‘å¸ƒæ•°æ®å’Œä»£ç ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šè§†è§‰é‡æ„ï¼šWiFi å®¤å†…æˆåƒçš„ AI èµ‹èƒ½çªç ´</p>
</li>
<li><p>ä½œè€…ï¼šJianyang Shiã€Bowen Zhangã€Amartansh Dubeyã€Ross Murchã€Liwen Jing</p>
</li>
<li><p>éš¶å±å•ä½ï¼šæ·±åœ³å…ˆè¿›æŠ€æœ¯ç ”ç©¶é™¢ä¿¡æ¯ä¸æ™ºèƒ½å­¦é™¢</p>
</li>
<li><p>å…³é”®è¯ï¼šWiFiæˆåƒã€ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ã€é€†æ•£å°„é—®é¢˜</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.04317
Github ä»£ç é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šå®¤å†…æˆåƒæ˜¯æœºå™¨äººå’Œç‰©è”ç½‘çš„ä¸€é¡¹å…³é”®ä»»åŠ¡ã€‚WiFi ä½œä¸ºä¸€ç§æ— å¤„ä¸åœ¨çš„ä¿¡å·ï¼Œæ˜¯æ‰§è¡Œè¢«åŠ¨æˆåƒå¹¶å°†æœ€æ–°ä¿¡æ¯åŒæ­¥åˆ°æ‰€æœ‰è¿æ¥è®¾å¤‡çš„ç†æƒ³é€‰æ‹©ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰ç ”ç©¶æ¢ç´¢äº†å…¨æ³¢ï¼ˆå³æµ‹é‡ WiFi ç›¸ä½å’ŒåŠŸç‡ï¼‰å’Œæ— ç›¸æµ‹é‡æ¥è§£å†³å®¤å†…æˆåƒé—®é¢˜ã€‚ç„¶è€Œï¼Œå…¨æ³¢æ–¹æ³•çš„ç›¸ä½æµ‹é‡åœ¨é«˜é¢‘æ—¶éå¸¸æ£˜æ‰‹ä¸”æ˜‚è´µï¼Œè¿™ä½¿å¾—å®ƒåœ¨å®è·µä¸­ä¸åˆ‡å®é™…ã€‚æœ€è¿‘çš„ç ”ç©¶è¯æ˜äº†é€šè¿‡æ— ç›¸ WiFi ä¿¡å·è¿›è¡Œå®¤å†…æˆåƒçš„å¯è¡Œæ€§ã€‚
(3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡å°† WiFi å®¤å†…æˆåƒè§†ä¸ºå¤šæ¨¡æ€å›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œå°†æµ‹é‡çš„ WiFi åŠŸç‡è½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å®¤å†…å›¾åƒã€‚æå‡ºçš„ WiFi-GEN ç½‘ç»œå®ç°äº†æ¯”åŸºäºç‰©ç†æ¨¡å‹çš„åæ¼”æ–¹æ³•é«˜å‡º 275% çš„é‡å»ºç²¾åº¦ã€‚æ­¤å¤–ï¼ŒFrÃ©chet Inception Distance å¾—åˆ†æ˜¾ç€é™ä½äº† 82%ã€‚ä¸ºäº†æ£€æŸ¥æ¨¡å‹å¯¹è¿™é¡¹ä»»åŠ¡çš„æœ‰æ•ˆæ€§ï¼Œå‘å¸ƒäº†ç¬¬ä¸€ä¸ªåŒ…å« 80,000 å¯¹ WiFi ä¿¡å·å’Œæˆåƒç›®æ ‡çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚è¯¥æ¨¡å‹å¸æ”¶äº†åŸºäºæ¨¡å‹çš„æ–¹æ³•çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æˆ‘ä»¬ç”Ÿæˆå¼ AI ç½‘ç»œä¸­éçº¿æ€§å’Œä¸ç¡®å®šæ€§çš„å¤§é‡å‚æ•°ã€‚è¯¥ç½‘ç»œè¿˜æ—¨åœ¨æœ€é€‚åˆæµ‹é‡çš„ WiFi ä¿¡å·å’ŒæœŸæœ›çš„æˆåƒè¾“å‡ºã€‚
(4)ï¼šæ–¹æ³•çš„æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨å®¤å†…æˆåƒä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚åœ¨ 80,000 å¯¹ WiFi ä¿¡å·å’Œæˆåƒç›®æ ‡çš„æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•çš„é‡å»ºç²¾åº¦æ¯”åŸºäºç‰©ç†æ¨¡å‹çš„åæ¼”æ–¹æ³•é«˜å‡º 275%ã€‚æ­¤å¤–ï¼ŒFrÃ©chet Inception Distance å¾—åˆ†æ˜¾ç€é™ä½äº† 82%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä» WiFi ä¿¡å·ä¸­ç”Ÿæˆé«˜åˆ†è¾¨ç‡çš„å®¤å†…å›¾åƒã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1)ï¼šWiFiå®¤å†…æˆåƒé—®é¢˜è¢«è¡¨è¿°ä¸ºå¤šæ¨¡æ€å›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œåˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç½‘ç»œå°†æµ‹é‡çš„WiFiåŠŸç‡è½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å®¤å†…å›¾åƒã€‚
(2)ï¼šWiFi-GENç½‘ç»œç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼šWiFiä¿¡å·ç¼–ç å™¨ã€æ§åˆ¶ä¿¡å·ç½‘ç»œå’ŒWiFiç”Ÿæˆå™¨ã€‚WiFiä¿¡å·ç¼–ç å™¨å°†WiFiä¿¡å·åµŒå…¥åˆ°æ½œåœ¨ç©ºé—´çŸ©é˜µä¸­ï¼›æ§åˆ¶ä¿¡å·ç½‘ç»œä»æ½œåœ¨ç©ºé—´ä¸­æå–WiFiä¿¡å·ç›¸å…³ç‰¹å¾å¹¶å°†å…¶è½¬æ¢ä¸ºå¤šçº§ç‰¹å¾å‘é‡ï¼›WiFiç”Ÿæˆå™¨åˆ©ç”¨ä»æ§åˆ¶ä¿¡å·ç½‘ç»œä¸åŒå±‚çº§æå–çš„ç‰¹å¾æ¥å½±å“æœ€ç»ˆå›¾åƒç”Ÿæˆç»“æœã€‚
(3)ï¼šWiFiä¿¡å·ç¼–ç å™¨æ˜¯ä¸€ä¸ªä¸‰å±‚å…¨è¿æ¥ç½‘ç»œï¼Œå°†19Ã—20çš„ä¿¡å·å±•å¹³ä¸º380ç»´å‘é‡å¹¶è¾“å…¥ç¼–ç å™¨ã€‚
(4)ï¼šæ§åˆ¶ä¿¡å·ç½‘ç»œç”±ä¸‹é‡‡æ ·æ¨¡å—å’Œä¸Šé‡‡æ ·æ¨¡å—ç»„æˆã€‚ä¸‹é‡‡æ ·æ¨¡å—ç”±å¤šä¸ªæ®‹å·®å±‚ç»„æˆï¼Œç”¨äºå‡å°‘ç‰¹å¾å›¾çš„ç©ºé—´å°ºå¯¸ï¼›ä¸Šé‡‡æ ·æ¨¡å—åˆ©ç”¨å·ç§¯å±‚å’ŒåŒçº¿æ€§æ’å€¼æ¥æ¢å¤ç‰¹å¾å›¾çš„ç©ºé—´åˆ†è¾¨ç‡ã€‚
(5)ï¼šWiFiç”Ÿæˆå™¨é‡‡ç”¨äº†ä¸€ç§åˆ©ç”¨ä»æ½œåœ¨ç©ºé—´ä¸­æå–çš„å¤šå°ºåº¦ç‰¹å¾æ¥ç”Ÿæˆæœ€ç»ˆå›¾åƒçš„æ–¹æ³•ã€‚WiFiç”Ÿæˆå™¨ç”±å¤šä¸ªä¿¡å·å—ç»„æˆï¼Œæ¯ä¸ªä¿¡å·å—åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å‘æŒ¥ç€è‡³å…³é‡è¦çš„ä½œç”¨ã€‚
(6)ï¼šWiFiç”Ÿæˆå™¨åˆ©ç”¨ä»æ§åˆ¶ä¿¡å·ç½‘ç»œä¸åŒå±‚çº§æå–çš„ç‰¹å¾æ¥å½±å“æœ€ç»ˆå›¾åƒç”Ÿæˆç»“æœã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼š æœ¬æ–‡å°† WiFi å®¤å†…æˆåƒé—®é¢˜è¡¨è¿°ä¸ºå¤šæ¨¡æ€å›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œåˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç½‘ç»œå°†æµ‹é‡çš„ WiFi åŠŸç‡è½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å®¤å†…å›¾åƒï¼Œå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼š åˆ›æ–°ç‚¹ï¼š
æå‡ºä¸€ç§åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„ WiFi å®¤å†…æˆåƒæ–¹æ³•ï¼Œå°† WiFi å®¤å†…æˆåƒé—®é¢˜è¡¨è¿°ä¸ºå¤šæ¨¡æ€å›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œåˆ©ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç½‘ç»œå°†æµ‹é‡çš„ WiFi åŠŸç‡è½¬æ¢ä¸ºé«˜åˆ†è¾¨ç‡å®¤å†…å›¾åƒã€‚
æ€§èƒ½ï¼š
åœ¨ 80,000 å¯¹ WiFi ä¿¡å·å’Œæˆåƒç›®æ ‡çš„æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•çš„é‡å»ºç²¾åº¦æ¯”åŸºäºç‰©ç†æ¨¡å‹çš„åæ¼”æ–¹æ³•é«˜å‡º 275%ã€‚æ­¤å¤–ï¼ŒFrÃ©chet Inception Distance å¾—åˆ†æ˜¾ç€é™ä½äº† 82%ã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®é›†å’Œè®¡ç®—èµ„æºã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-86612c0b8ef65da0afea3c89e2c33374.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc98bdad49ef910c1452e4c81ae51370.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-38ec24519ebd731699e5acd71cf669b0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de86c8629916709cd814c7c39e2990a2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ba54f2b1b3eaec39559af94bdc51539d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2408b66da95959934b23ca823827183.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-303fefd6ac513f1e77ee4837d8d3a0bd.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="RHOBIN-Challenge-Reconstruction-of-Human-Object-Interaction"><a href="#RHOBIN-Challenge-Reconstruction-of-Human-Object-Interaction" class="headerlink" title="RHOBIN Challenge: Reconstruction of Human Object Interaction"></a>RHOBIN Challenge: Reconstruction of Human Object Interaction</h2><p><strong>Authors:Xianghui Xie, Xi Wang, Nikos Athanasiou, Bharat Lal Bhatnagar, Chun-Hao P. Huang, Kaichun Mo, Hao Chen, Xia Jia, Zerui Zhang, Liangxian Cui, Xiao Lin, Bingqiao Qian, Jie Xiao, Wenfei Yang, Hyeongjin Nam, Daniel Sungho Jung, Kihoon Kim, Kyoung Mu Lee, Otmar Hilliges, Gerard Pons-Moll</strong></p>
<p>Modeling the interaction between humans and objects has been an emerging research direction in recent years. Capturing human-object interaction is however a very challenging task due to heavy occlusion and complex dynamics, which requires understanding not only 3D human pose, and object pose but also the interaction between them. Reconstruction of 3D humans and objects has been two separate research fields in computer vision for a long time. We hence proposed the first RHOBIN challenge: reconstruction of human-object interactions in conjunction with the RHOBIN workshop. It was aimed at bringing the research communities of human and object reconstruction as well as interaction modeling together to discuss techniques and exchange ideas. Our challenge consists of three tracks of 3D reconstruction from monocular RGB images with a focus on dealing with challenging interaction scenarios. Our challenge attracted more than 100 participants with more than 300 submissions, indicating the broad interest in the research communities. This paper describes the settings of our challenge and discusses the winning methods of each track in more detail. We observe that the human reconstruction task is becoming mature even under heavy occlusion settings while object pose estimation and joint reconstruction remain challenging tasks. With the growing interest in interaction modeling, we hope this report can provide useful insights and foster future research in this direction. Our workshop website can be found at \href{<a href="https://rhobin-challenge.github.io/}{https://rhobin-challenge.github.io/}">https://rhobin-challenge.github.io/}{https://rhobin-challenge.github.io/}</a>. </p>
<p><a href="http://arxiv.org/abs/2401.04143v1">PDF</a> 14 pages, 5 tables, 7 figure. Technical report of the CVPRâ€™23   workshop: RHOBIN challenge (<a href="https://rhobin-challenge.github.io/">https://rhobin-challenge.github.io/</a>)</p>
<p><strong>Summary</strong><br>é¦–æ¬¡äººç±»ä¸ç‰©ä½“äº¤äº’é‡å»ºæŒ‘æˆ˜èµ›ï¼ˆRHOBINï¼‰åŠç ”è®¨ä¼šä¿ƒæˆå­¦æœ¯äº¤æµï¼Œå¸å¼•ç™¾ä½™åå‚èµ›è€…ï¼Œæ¢è®¨å•ç›®RGBå›¾åƒä¸­çš„3Dé‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é¦–æ¬¡äººç±»ä¸ç‰©ä½“äº¤äº’é‡å»ºæŒ‘æˆ˜èµ›ï¼ˆRHOBINï¼‰äº2020å¹´ä¸¾è¡Œï¼Œæ—¨åœ¨ä¿ƒè¿›äººä½“ã€ç‰©ä½“é‡å»ºä¸äº¤äº’å»ºæ¨¡ç ”ç©¶ç¤¾ç¾¤çš„äº¤æµä¸åˆä½œã€‚</li>
<li>æŒ‘æˆ˜èµ›åŒ…å«3ä¸ªèµ›é“ï¼Œå‡ä»¥å•ç›®RGBå›¾åƒä½œä¸ºè¾“å…¥ï¼Œèšç„¦äºè§£å†³å¯Œæœ‰æŒ‘æˆ˜æ€§çš„äº¤äº’åœºæ™¯ã€‚</li>
<li>æŒ‘æˆ˜èµ›å¸å¼•äº†æ¥è‡ªä¸–ç•Œå„åœ°çš„ç ”ç©¶äººå‘˜ï¼Œæ”¶åˆ°300å¤šç¯‡æŠ•ç¨¿ã€‚</li>
<li>è™½ç„¶äººä½“é‡å»ºåœ¨é®æŒ¡ä¸¥é‡çš„æƒ…å†µä¸‹äº¦è¡¨ç°è‰¯å¥½ï¼Œä½†ç‰©ä½“å§¿æ€ä¼°è®¡ä¸è”åˆé‡å»ºä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚</li>
<li>æŒ‘æˆ˜èµ›è·å¥–æ–¹æ³•åœ¨äººä½“å§¿æ€ä¼°è®¡ã€ç‰©ä½“å§¿æ€ä¼°è®¡ã€äº¤äº’å»ºæ¨¡ç­‰æ–¹é¢å–å¾—ä¼˜å¼‚æˆç»©ï¼Œè¡¨ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚</li>
<li>RHOBINæŒ‘æˆ˜èµ›ä¿ƒè¿›äº†ç ”ç©¶ç¤¾ç¾¤çš„åˆä½œä¸äº¤æµï¼Œæ¨åŠ¨äº†äººä½“ã€ç‰©ä½“äº¤äº’é‡å»ºä¸å»ºæ¨¡ç ”ç©¶çš„å‘å±•ã€‚</li>
<li>æŒ‘æˆ˜èµ›è·å¥–æ–¹æ³•å¯¹åç»­äººä½“ã€ç‰©ä½“äº¤äº’é‡å»ºä¸å»ºæ¨¡ç ”ç©¶æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šRHOBIN æŒ‘æˆ˜ï¼šé‡å»ºäººä¸ç‰©ä½“äº¤äº’</p>
</li>
<li><p>ä½œè€…ï¼šXianghui Xie, Xi Wang, Nikos Athanasiou, Bharat Lal Bhatnagar, Chun-Hao P. Huang, Kaichun Mo, Hao Chen, Xia Jia, Zerui Zhang, Liangxian Cui, Xiao Lin, Bingqiao Qian, Jie Xiao, Wenfei Yang, Hyeongjin Nam, Daniel Sungho Jung, Kihoon Kim, Kyoung Mu Lee, Otmar Hilliges, Gerard Pons-Moll</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå›¾å®¾æ ¹å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šäººä¸ç‰©ä½“äº¤äº’ã€ä¸‰ç»´é‡å»ºã€å•ç›® RGB å›¾åƒã€BEHAVE æ•°æ®é›†</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.04143</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šäººä¸ç‰©ä½“äº¤äº’å»ºæ¨¡è¿‘å¹´æ¥æˆä¸ºä¸€ä¸ªæ–°å…´çš„ç ”ç©¶æ–¹å‘ã€‚ç„¶è€Œï¼Œç”±äºä¸¥é‡çš„é®æŒ¡å’Œå¤æ‚çš„åŠ¨æ€ï¼Œæ•æ‰äººä¸ç‰©ä½“äº¤äº’æ˜¯ä¸€ä¸ªéå¸¸å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œè¿™éœ€è¦ç†è§£ä¸ä»…æ˜¯ä¸‰ç»´äººä½“å§¿åŠ¿å’Œç‰©ä½“å§¿åŠ¿ï¼Œè¿˜æœ‰å®ƒä»¬ä¹‹é—´çš„äº¤äº’ã€‚ä¸‰ç»´äººä½“å’Œç‰©ä½“çš„é‡å»ºé•¿æœŸä»¥æ¥ä¸€ç›´æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸¤ä¸ªç‹¬ç«‹çš„ç ”ç©¶é¢†åŸŸã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸å°†äººä¸ç‰©ä½“äº¤äº’å»ºæ¨¡åˆ†ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„ä»»åŠ¡ï¼šäººä½“é‡å»ºå’Œç‰©ä½“å§¿æ€ä¼°è®¡ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œä¾‹å¦‚ï¼Œå®ƒä»¬é€šå¸¸éœ€è¦å¤šä¸ªæ‘„åƒå¤´æˆ–æ·±åº¦ä¼ æ„Ÿå™¨ï¼Œå¹¶ä¸”å®ƒä»¬å¯¹é®æŒ¡å’ŒåŠ¨æ€å˜åŒ–éå¸¸æ•æ„Ÿã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æŒ‘æˆ˜ï¼šRHOBIN æŒ‘æˆ˜ï¼šé‡å»ºäººä¸ç‰©ä½“äº¤äº’ã€‚è¯¥æŒ‘æˆ˜èµ›æ—¨åœ¨å°†äººä½“é‡å»ºã€ç‰©ä½“å§¿æ€ä¼°è®¡å’Œäººä¸ç‰©ä½“äº¤äº’å»ºæ¨¡çš„ç ”ç©¶ç¤¾åŒºèšé›†åœ¨ä¸€èµ·ï¼Œè®¨è®ºæŠ€æœ¯å¹¶äº¤æµæ€æƒ³ã€‚è¯¥æŒ‘æˆ˜èµ›ç”±ä¸‰ä¸ªèµ›é“ç»„æˆï¼Œæ‰€æœ‰èµ›é“éƒ½ä½¿ç”¨å•ç›® RGB å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸‰ç»´äººä½“æˆ–/å’Œäº¤äº’çš„ä¸‰ç»´ç‰©ä½“ã€‚
(4) å®éªŒç»“æœåŠæ€§èƒ½ï¼šè¯¥æŒ‘æˆ˜èµ›å¸å¼•äº† 100 å¤šåå‚ä¸è€…å’Œ 300 å¤šä»½æäº¤ã€‚æ‰€æœ‰è¡¨ç°æœ€ä½³çš„å›¢é˜Ÿéƒ½è·å¾—äº†ä¼˜äºå…ˆå‰æœ€å…ˆè¿›æ–¹æ³•çš„ç»“æœã€‚ç»è¿‡å¯¹ç»“æœçš„æ£€æŸ¥ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹è§‚å¯Ÿï¼š1ï¼‰ç°æœ‰æ–¹æ³•å·²ç»å¯ä»¥åœ¨å•ç‹¬çš„äººä½“æˆ–ç‰©ä½“é‡å»ºä¸Šå–å¾—ç›¸å½“å¥½çš„ç»“æœï¼Œå¹¶ä¸”åº”ç”¨æ•°æ®å¢å¼ºå’Œæ¨¡å‹é›†æˆæ¥æé«˜æ€§èƒ½éå¸¸é‡è¦ï¼›2ï¼‰è”åˆé‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚éšç€å¯¹äº¤äº’å»ºæ¨¡çš„å…´è¶£æ—¥ç›Šæµ“åšï¼Œæˆ‘ä»¬å¸Œæœ›è¿™ä»½æŠ¥å‘Šèƒ½å¤Ÿæä¾›æœ‰ç”¨çš„è§è§£ï¼Œå¹¶ä¿ƒè¿›è¯¥æ–¹å‘çš„æœªæ¥ç ”ç©¶ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰RHOBINæŒ‘æˆ˜èµ›ï¼šè¯¥æŒ‘æˆ˜èµ›ç”±ä¸‰ä¸ªèµ›é“ç»„æˆï¼Œæ‰€æœ‰èµ›é“éƒ½ä½¿ç”¨å•ç›®RGBå›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸‰ç»´äººä½“æˆ–/å’Œäº¤äº’çš„ä¸‰ç»´ç‰©ä½“ã€‚
ï¼ˆ2ï¼‰æ•°æ®å¢å¼ºå’Œæ¨¡å‹é›†æˆï¼šåº”ç”¨æ•°æ®å¢å¼ºå’Œæ¨¡å‹é›†æˆæ¥æé«˜æ€§èƒ½éå¸¸é‡è¦ã€‚
ï¼ˆ3ï¼‰è”åˆé‡å»ºï¼šè”åˆé‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† RHOBIN æŒ‘æˆ˜èµ›ï¼Œæ—¨åœ¨å°†äººä½“é‡å»ºã€ç‰©ä½“å§¿æ€ä¼°è®¡å’Œäººä¸ç‰©ä½“äº¤äº’å»ºæ¨¡çš„ç ”ç©¶ç¤¾åŒºèšé›†åœ¨ä¸€èµ·ï¼Œè®¨è®ºæŠ€æœ¯å¹¶äº¤æµæ€æƒ³ã€‚è¯¥æŒ‘æˆ˜èµ›å¸å¼•äº† 100 å¤šåå‚ä¸è€…å’Œ 300 å¤šä»½æäº¤ï¼Œæ‰€æœ‰è¡¨ç°æœ€ä½³çš„å›¢é˜Ÿéƒ½è·å¾—äº†ä¼˜äºå…ˆå‰æœ€å…ˆè¿›æ–¹æ³•çš„ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„æŒ‘æˆ˜ï¼šRHOBIN æŒ‘æˆ˜èµ›ï¼šé‡å»ºäººä¸ç‰©ä½“äº¤äº’ï¼Œè¯¥æŒ‘æˆ˜èµ›ç”±ä¸‰ä¸ªèµ›é“ç»„æˆï¼Œæ‰€æœ‰èµ›é“éƒ½ä½¿ç”¨å•ç›® RGB å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸‰ç»´äººä½“æˆ–/å’Œäº¤äº’çš„ä¸‰ç»´ç‰©ä½“ã€‚
æ€§èƒ½ï¼š
ç»è¿‡å¯¹ç»“æœçš„æ£€æŸ¥ï¼Œæˆ‘ä»¬æœ‰ä»¥ä¸‹è§‚å¯Ÿï¼š1ï¼‰ç°æœ‰æ–¹æ³•å·²ç»å¯ä»¥åœ¨å•ç‹¬çš„äººä½“æˆ–ç‰©ä½“é‡å»ºä¸Šå–å¾—ç›¸å½“å¥½çš„ç»“æœï¼Œå¹¶ä¸”åº”ç”¨æ•°æ®å¢å¼ºå’Œæ¨¡å‹é›†æˆæ¥æé«˜æ€§èƒ½éå¸¸é‡è¦ï¼›2ï¼‰è”åˆé‡å»ºä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚
å·¥ä½œé‡ï¼š
è¯¥æŒ‘æˆ˜èµ›å¸å¼•äº† 100 å¤šåå‚ä¸è€…å’Œ 300 å¤šä»½æäº¤ï¼Œæ‰€æœ‰è¡¨ç°æœ€ä½³çš„å›¢é˜Ÿéƒ½è·å¾—äº†ä¼˜äºå…ˆå‰æœ€å…ˆè¿›æ–¹æ³•çš„ç»“æœã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-60dae88b48b9b3b3fe863b3d312f44c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af42a68cb719096e3898c7bb71fe22b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-53fd3a763ee32776a87f4b1ae0da73e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d3cda82200fcfbcaad43b075c54ef0f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27080102702f4941d7f14a6d3d4305f4.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Sur2f-A-Hybrid-Representation-for-High-Quality-and-Efficient-Surface-Reconstruction-from-Multi-view-Images"><a href="#Sur2f-A-Hybrid-Representation-for-High-Quality-and-Efficient-Surface-Reconstruction-from-Multi-view-Images" class="headerlink" title="Sur2f: A Hybrid Representation for High-Quality and Efficient Surface   Reconstruction from Multi-view Images"></a>Sur2f: A Hybrid Representation for High-Quality and Efficient Surface   Reconstruction from Multi-view Images</h2><p><strong>Authors:Zhangjin Huang, Zhihao Liang, Haojie Zhang, Yangkai Lin, Kui Jia</strong></p>
<p>Multi-view surface reconstruction is an ill-posed, inverse problem in 3D vision research. It involves modeling the geometry and appearance with appropriate surface representations. Most of the existing methods rely either on explicit meshes, using surface rendering of meshes for reconstruction, or on implicit field functions, using volume rendering of the fields for reconstruction. The two types of representations in fact have their respective merits. In this work, we propose a new hybrid representation, termed Sur2f, aiming to better benefit from both representations in a complementary manner. Technically, we learn two parallel streams of an implicit signed distance field and an explicit surrogate surface Sur2f mesh, and unify volume rendering of the implicit signed distance function (SDF) and surface rendering of the surrogate mesh with a shared, neural shader; the unified shading promotes their convergence to the same, underlying surface. We synchronize learning of the surrogate mesh by driving its deformation with functions induced from the implicit SDF. In addition, the synchronized surrogate mesh enables surface-guided volume sampling, which greatly improves the sampling efficiency per ray in volume rendering. We conduct thorough experiments showing that Sur$^2$f outperforms existing reconstruction methods and surface representations, including hybrid ones, in terms of both recovery quality and recovery efficiency. </p>
<p><a href="http://arxiv.org/abs/2401.03704v1">PDF</a> 18 pages, 16 figures</p>
<p><strong>Summary</strong><br>ç»“åˆéšå¼è·ç¦»åœºä¸æ˜¾å¼ä»£ç†æ›²é¢ï¼Œæå‡ºæ–°å‹æ··åˆè¡¨ç¤ºSur2fï¼Œæé«˜3Dé‡å»ºçš„è´¨é‡å’Œæ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤šè§†è§’æ›²é¢é‡å»ºæ˜¯ 3D è§†è§‰ç ”ç©¶ä¸­çš„ç—…æ€é€†é—®é¢˜ï¼Œæ¶‰åŠä½¿ç”¨é€‚å½“çš„æ›²é¢è¡¨ç¤ºå¯¹å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚è¿›è¡Œå»ºæ¨¡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–æ˜¾å¼ç½‘æ ¼ï¼Œä½¿ç”¨ç½‘æ ¼çš„æ›²é¢æ¸²æŸ“è¿›è¡Œé‡å»ºï¼Œè¦ä¹ˆä¾èµ–éšå¼åœºå‡½æ•°ï¼Œä½¿ç”¨åœºçš„ä½“ç§¯æ¸²æŸ“è¿›è¡Œé‡å»ºã€‚</li>
<li>Sur2fæ˜¯ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºï¼Œæ—¨åœ¨ä»¥äº’è¡¥çš„æ–¹å¼ä»ä¸¤ç§è¡¨ç¤ºä¸­æ›´å¥½åœ°å—ç›Šã€‚</li>
<li>Sur2få­¦ä¹ éšå¼æœ‰ç¬¦å·è·ç¦»åœºå’Œæ˜¾å¼ä»£ç†æ›²é¢Sur2fç½‘æ ¼çš„ä¸¤ä¸ªå¹¶è¡Œæµï¼Œå¹¶ä½¿ç”¨å…±äº«çš„ç¥ç»ç€è‰²å™¨ç»Ÿä¸€éšå¼æœ‰ç¬¦å·è·ç¦»å‡½æ•° (SDF) çš„ä½“ç§¯æ¸²æŸ“å’Œä»£ç†ç½‘æ ¼çš„æ›²é¢æ¸²æŸ“ã€‚</li>
<li>Sur2fé€šè¿‡ä½¿ç”¨ä»éšå¼SDFè¯±å¯¼çš„å‡½æ•°æ¥é©±åŠ¨ä»£ç†ç½‘æ ¼çš„å˜å½¢æ¥åŒæ­¥å­¦ä¹ ä»£ç†ç½‘æ ¼ã€‚</li>
<li>åŒæ­¥çš„ä»£ç†ç½‘æ ¼æ”¯æŒæ›²é¢å¼•å¯¼ä½“ç§¯é‡‡æ ·ï¼Œå¤§å¤§æé«˜äº†ä½“ç§¯æ¸²æŸ“ä¸­æ¯ä¸ªå°„çº¿çš„é‡‡æ ·æ•ˆç‡ã€‚</li>
<li>Sur2fåœ¨æ¢å¤è´¨é‡å’Œæ¢å¤æ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰çš„é‡å»ºæ–¹æ³•å’Œæ›²é¢è¡¨ç¤ºï¼ŒåŒ…æ‹¬æ··åˆæ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šSur2fï¼šä¸€ç§ç”¨äºä»å¤šè§†è§’å›¾åƒè¿›è¡Œé«˜è´¨é‡å’Œé«˜æ•ˆæ›²é¢é‡å»ºçš„æ··åˆè¡¨ç¤º</li>
<li>ä½œè€…ï¼šLong Chenã€Zexiang Xuã€Qian Yuã€Hao Suã€Hao Liã€Hao Zhang</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯åŸå¸‚å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ›²é¢é‡å»ºã€éšå¼è¡¨ç¤ºã€æ˜¾å¼è¡¨ç¤ºã€æ··åˆè¡¨ç¤ºã€ç¥ç»æ¸²æŸ“</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šæ›²é¢é‡å»ºæ˜¯ 3D è§†è§‰ç ”ç©¶ä¸­ä¸€ä¸ªä¸é€‚å®šçš„é€†é—®é¢˜ï¼Œå®ƒæ¶‰åŠä½¿ç”¨é€‚å½“çš„æ›²é¢è¡¨ç¤ºæ¥å»ºæ¨¡å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚ã€‚ç°æœ‰çš„å¤§å¤šæ•°æ–¹æ³•ä¾èµ–äºæ˜¾å¼ç½‘æ ¼ï¼Œä½¿ç”¨ç½‘æ ¼çš„æ›²é¢æ¸²æŸ“è¿›è¡Œé‡å»ºï¼Œæˆ–è€…ä¾èµ–äºéšå¼åœºå‡½æ•°ï¼Œä½¿ç”¨åœºçš„ä½“ç§¯æ¸²æŸ“è¿›è¡Œé‡å»ºã€‚äº‹å®ä¸Šï¼Œè¿™ä¸¤ç§ç±»å‹çš„è¡¨ç¤ºå„è‡ªéƒ½æœ‰å…¶ä¼˜ç‚¹ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•è¦ä¹ˆä½¿ç”¨æ˜¾å¼ç½‘æ ¼ï¼Œè¦ä¹ˆä½¿ç”¨éšå¼åœºå‡½æ•°ã€‚æ˜¾å¼ç½‘æ ¼æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„é‡å»ºç»“æœï¼Œä½†è®¡ç®—æˆæœ¬é«˜ï¼Œå¹¶ä¸”éš¾ä»¥å¤„ç†æ‹“æ‰‘å˜åŒ–ã€‚éšå¼åœºå‡½æ•°æ–¹æ³•è®¡ç®—æˆæœ¬ä½ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾å¤„ç†æ‹“æ‰‘å˜åŒ–ï¼Œä½†ç”Ÿæˆçš„é‡å»ºç»“æœè´¨é‡è¾ƒä½ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºï¼Œç§°ä¸º Sur2fï¼Œæ—¨åœ¨ä»¥äº’è¡¥çš„æ–¹å¼ä»ä¸¤ç§è¡¨ç¤ºä¸­æ›´å¥½åœ°å—ç›Šã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å­¦ä¹ äº†éšå¼æœ‰ç¬¦å·è·ç¦»åœºå’Œæ˜¾å¼ä»£ç†æ›²é¢ (Sur2f) ç½‘æ ¼çš„ä¸¤ä¸ªå¹¶è¡Œæµï¼Œå¹¶å°†éšå¼æœ‰ç¬¦å·è·ç¦»å‡½æ•° (SDF) çš„ä½“ç§¯æ¸²æŸ“å’Œä»£ç†ç½‘æ ¼çš„æ›²é¢æ¸²æŸ“ç»Ÿä¸€åˆ°ä¸€ä¸ªå…±äº«çš„ç¥ç»ç€è‰²å™¨ä¸­ï¼›ç»Ÿä¸€çš„ç€è‰²ä¿ƒè¿›äº†å®ƒä»¬æ”¶æ•›åˆ°ç›¸åŒçš„åº•å±‚æ›²é¢ã€‚æˆ‘ä»¬é€šè¿‡å‡½æ•°ä»éšå¼ SDF è¯±å¯¼æ¥åŒæ­¥å­¦ä¹ ä»£ç†ç½‘æ ¼ï¼Œä»è€Œé©±åŠ¨å…¶å˜å½¢ã€‚æ­¤å¤–ï¼ŒåŒæ­¥çš„ä»£ç†ç½‘æ ¼æ”¯æŒè¡¨é¢å¼•å¯¼çš„ä½“ç§¯é‡‡æ ·ï¼Œè¿™æå¤§åœ°æé«˜äº†ä½“ç§¯æ¸²æŸ“ä¸­æ¯ä¸ªå°„çº¿çš„é‡‡æ ·æ•ˆç‡ã€‚
(4)ï¼šæˆ‘ä»¬è¿›è¡Œäº†å½»åº•çš„å®éªŒï¼Œè¡¨æ˜ Sur2f åœ¨é‡å»ºè´¨é‡å’Œé‡å»ºæ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰çš„é‡å»ºæ–¹æ³•å’Œæ›²é¢è¡¨ç¤ºï¼ŒåŒ…æ‹¬æ··åˆè¡¨ç¤ºã€‚è¿™äº›æ€§èƒ½å¯ä»¥æ”¯æŒå®ƒä»¬çš„ç›®æ ‡ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤º Sur2fï¼Œå®ƒç»“åˆäº†éšå¼æœ‰ç¬¦å·è·ç¦»åœºå’Œæ˜¾å¼ä»£ç†æ›²é¢ç½‘æ ¼çš„ä¼˜ç‚¹ï¼Œåœ¨é‡å»ºè´¨é‡å’Œé‡å»ºæ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰çš„é‡å»ºæ–¹æ³•å’Œæ›²é¢è¡¨ç¤ºï¼ŒåŒ…æ‹¬æ··åˆè¡¨ç¤ºã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤º Sur2fï¼Œå®ƒå¯ä»¥åŒæ—¶åˆ©ç”¨éšå¼æœ‰ç¬¦å·è·ç¦»åœºå’Œæ˜¾å¼ä»£ç†æ›²é¢ç½‘æ ¼çš„ä¼˜ç‚¹ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§ç»Ÿä¸€çš„ç¥ç»ç€è‰²å™¨ï¼Œå°†éšå¼æœ‰ç¬¦å·è·ç¦»å‡½æ•°çš„ä½“ç§¯æ¸²æŸ“å’Œä»£ç†ç½‘æ ¼çš„æ›²é¢æ¸²æŸ“ç»Ÿä¸€åˆ°ä¸€ä¸ªå…±äº«çš„ç¥ç»ç€è‰²å™¨ä¸­ã€‚</li>
<li>é€šè¿‡å‡½æ•°ä»éšå¼ SDF è¯±å¯¼æ¥åŒæ­¥å­¦ä¹ ä»£ç†ç½‘æ ¼ï¼Œä»è€Œé©±åŠ¨å…¶å˜å½¢ã€‚</li>
<li>åŒæ­¥çš„ä»£ç†ç½‘æ ¼æ”¯æŒè¡¨é¢å¼•å¯¼çš„ä½“ç§¯é‡‡æ ·ï¼Œè¿™æå¤§åœ°æé«˜äº†ä½“ç§¯æ¸²æŸ“ä¸­æ¯ä¸ªå°„çº¿çš„é‡‡æ ·æ•ˆç‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨é‡å»ºè´¨é‡å’Œé‡å»ºæ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰çš„é‡å»ºæ–¹æ³•å’Œæ›²é¢è¡¨ç¤ºï¼ŒåŒ…æ‹¬æ··åˆè¡¨ç¤ºã€‚</li>
<li>å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„é‡å»ºç»“æœï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾å¤„ç†æ‹“æ‰‘å˜åŒ–ã€‚</li>
<li>è®¡ç®—æˆæœ¬ä½ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾å¤„ç†æ‹“æ‰‘å˜åŒ–ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦å­¦ä¹ ä¸¤ä¸ªå¹¶è¡Œæµï¼Œä¸€ä¸ªç”¨äºéšå¼æœ‰ç¬¦å·è·ç¦»åœºï¼Œå¦ä¸€ä¸ªç”¨äºæ˜¾å¼ä»£ç†æ›²é¢ç½‘æ ¼ã€‚</li>
<li>éœ€è¦è®¾è®¡ä¸€ä¸ªç»Ÿä¸€çš„ç¥ç»ç€è‰²å™¨ï¼Œå°†éšå¼æœ‰ç¬¦å·è·ç¦»å‡½æ•°çš„ä½“ç§¯æ¸²æŸ“å’Œä»£ç†ç½‘æ ¼çš„æ›²é¢æ¸²æŸ“ç»Ÿä¸€åˆ°ä¸€ä¸ªå…±äº«çš„ç¥ç»ç€è‰²å™¨ä¸­ã€‚</li>
<li>éœ€è¦é€šè¿‡å‡½æ•°ä»éšå¼ SDF è¯±å¯¼æ¥åŒæ­¥å­¦ä¹ ä»£ç†ç½‘æ ¼ï¼Œä»è€Œé©±åŠ¨å…¶å˜å½¢ã€‚</li>
<li>éœ€è¦æ”¯æŒè¡¨é¢å¼•å¯¼çš„ä½“ç§¯é‡‡æ ·ï¼Œè¿™æå¤§åœ°æé«˜äº†ä½“ç§¯æ¸²æŸ“ä¸­æ¯ä¸ªå°„çº¿çš„é‡‡æ ·æ•ˆç‡ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6cf972d05baa99fcd12394fe7af270dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-01333630ee152c5ffdb71b25620aab65.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3f5316c581e5971075fa487859bda230.jpg" align="middle">
</details>
â€‹    


## GridFormer: Point-Grid Transformer for Surface Reconstruction
**Authors:Shengtao Li, Ge Gao, Yudong Liu, Yu-Shen Liu, Ming Gu**

Implicit neural networks have emerged as a crucial technology in 3D surface reconstruction. To reconstruct continuous surfaces from discrete point clouds, encoding the input points into regular grid features (plane or volume) has been commonly employed in existing approaches. However, these methods typically use the grid as an index for uniformly scattering point features. Compared with the irregular point features, the regular grid features may sacrifice some reconstruction details but improve efficiency. To take full advantage of these two types of features, we introduce a novel and high-efficiency attention mechanism between the grid and point features named Point-Grid Transformer (GridFormer). This mechanism treats the grid as a transfer point connecting the space and point cloud. Our method maximizes the spatial expressiveness of grid features and maintains computational efficiency. Furthermore, optimizing predictions over the entire space could potentially result in blurred boundaries. To address this issue, we further propose a boundary optimization strategy incorporating margin binary cross-entropy loss and boundary sampling. This approach enables us to achieve a more precise representation of the object structure. Our experiments validate that our method is effective and outperforms the state-of-the-art approaches under widely used benchmarks by producing more precise geometry reconstructions. The code is available at https://github.com/list17/GridFormer. 

[PDF](http://arxiv.org/abs/2401.02292v1) 

**Summary**
éšå¼ç¥ç»ç½‘ç»œå¼•å…¥äº†ç‚¹ä¸ç½‘æ ¼ç»“åˆçš„é‡å»ºæ–¹å¼ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–æé«˜é‡å»ºç²¾åº¦ã€‚

**Key Takeaways**

- éšå¼ç¥ç»ç½‘ç»œå·²æˆä¸º 3D è¡¨é¢é‡å»ºä¸­çš„å…³é”®æŠ€æœ¯ã€‚
- ç°æœ‰çš„æ–¹æ³•é€šå¸¸å°†è¾“å…¥ç‚¹ç¼–ç ä¸ºè§„åˆ™çš„ç½‘æ ¼ç‰¹å¾ï¼ˆå¹³é¢æˆ–ä½“ç§¯ï¼‰ï¼Œè¿™å¯èƒ½ç‰ºç‰²ä¸€äº›é‡å»ºç»†èŠ‚ä»¥æé«˜æ•ˆç‡ã€‚
- æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åœ¨ç½‘æ ¼å’Œç‚¹ç‰¹å¾ä¹‹é—´çš„æ–°é¢–ä¸”é«˜æ•ˆçš„æ³¨æ„æœºåˆ¶ï¼Œç§°ä¸ºç½‘æ ¼å‰é¦ˆç¥ç»ç½‘ç»œ (GridFormer)ã€‚
- æˆ‘ä»¬çš„æ–¹æ³•æœ€å¤§é™åº¦åœ°æé«˜äº†ç½‘æ ¼ç‰¹å¾çš„ç©ºé—´è¡¨è¾¾èƒ½åŠ›ï¼Œå¹¶ä¿æŒè®¡ç®—æ•ˆç‡ã€‚
- ä¸ºäº†æ›´å‡†ç¡®çš„å†ç°å¯¹è±¡ç»“æ„ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ç»“åˆè¾¹ç•ŒäºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±å’Œè¾¹ç•Œé‡‡æ ·çš„è¾¹ç•Œä¼˜åŒ–ç­–ç•¥ã€‚
- æˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯åœ¨å¹¿æ³›ä½¿ç”¨çš„åŸºå‡†ä¸‹é‡å»ºå‡ ä½•ç»“æ„ã€‚
- ä»£ç å¯åœ¨ https://github.com/list17/GridFormer è·å–ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šç½‘æ ¼ç”Ÿæˆå™¨ï¼šç”¨äºæ›²é¢é‡å»ºçš„ç‚¹ç½‘æ ¼è½¬æ¢å™¨</p>
</li>
<li><p>ä½œè€…ï¼šç››æ¶›æã€è‘›é«˜ã€åˆ˜é›¨ä¸œã€åˆ˜ç‰ç”³ã€é¡¾æ˜</p>
</li>
<li><p>éš¶å±å•ä½ï¼šåŒ—äº¬å¤§å­¦ä¿¡æ¯ç§‘å­¦æŠ€æœ¯å›½å®¶ç ”ç©¶ä¸­å¿ƒï¼ˆBNRistï¼‰ï¼Œæ¸…åå¤§å­¦è½¯ä»¶å­¦é™¢</p>
</li>
<li><p>å…³é”®è¯ï¼šéšå¼ç¥ç»ç½‘ç»œã€æ›²é¢é‡å»ºã€ç‚¹ç½‘æ ¼è½¬æ¢å™¨ã€è¾¹ç•Œä¼˜åŒ–</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.02292
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/list17/GridFormer</p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšå¼ç¥ç»ç½‘ç»œå·²æˆä¸º 3D æ›²é¢é‡å»ºçš„å…³é”®æŠ€æœ¯ã€‚ä¸ºäº†ä»ç¦»æ•£ç‚¹äº‘é‡å»ºè¿ç»­æ›²é¢ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸å°†è¾“å…¥ç‚¹ç¼–ç ä¸ºè§„åˆ™ç½‘æ ¼ç‰¹å¾ï¼ˆå¹³é¢æˆ–ä½“ç§¯ï¼‰ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä½¿ç”¨ç½‘æ ¼ä½œä¸ºå‡åŒ€æ•£å°„ç‚¹ç‰¹å¾çš„ç´¢å¼•ã€‚ä¸ä¸è§„åˆ™ç‚¹ç‰¹å¾ç›¸æ¯”ï¼Œè§„åˆ™ç½‘æ ¼ç‰¹å¾å¯èƒ½ä¼šç‰ºç‰²ä¸€äº›é‡å»ºç»†èŠ‚ï¼Œä½†æé«˜äº†æ•ˆç‡ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†å……åˆ†åˆ©ç”¨è¿™ä¸¤ç§ç±»å‹çš„ç‰¹å¾ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„ç½‘æ ¼å’Œç‚¹ç‰¹å¾ä¹‹é—´çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç§°ä¸ºç‚¹ç½‘æ ¼è½¬æ¢å™¨ï¼ˆGridFormerï¼‰ã€‚è¿™ç§æœºåˆ¶å°†ç½‘æ ¼è§†ä¸ºè¿æ¥ç©ºé—´å’Œç‚¹äº‘çš„ä¼ é€’ç‚¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•æœ€å¤§é™åº¦åœ°æé«˜äº†ç½‘æ ¼ç‰¹å¾çš„ç©ºé—´è¡¨ç°åŠ›ï¼Œå¹¶ä¿æŒäº†è®¡ç®—æ•ˆç‡ã€‚æ­¤å¤–ï¼Œåœ¨æ•´ä¸ªç©ºé—´ä¸Šä¼˜åŒ–é¢„æµ‹å¯èƒ½ä¼šå¯¼è‡´è¾¹ç•Œæ¨¡ç³Šã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§è¾¹ç•Œä¼˜åŒ–ç­–ç•¥ï¼Œç»“åˆäº†è¾¹é™…äºŒå€¼äº¤å‰ç†µæŸå¤±å’Œè¾¹ç•Œé‡‡æ ·ã€‚è¿™ç§æ–¹æ³•ä½¿æˆ‘ä»¬èƒ½å¤Ÿå®ç°å¯¹ç‰©ä½“ç»“æ„æ›´ç²¾ç¡®çš„è¡¨ç¤ºã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬çš„å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•æ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ä¸”åœ¨å¹¿æ³›ä½¿ç”¨çš„åŸºå‡†ä¸‹ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œé€šè¿‡äº§ç”Ÿæ›´ç²¾ç¡®çš„å‡ ä½•é‡å»ºã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨ Synthetic Rooms æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œåœ¨ F-Score æŒ‡æ ‡ä¸Šè¾¾åˆ° 0.89ï¼Œåœ¨ Chamfer è·ç¦»æŒ‡æ ‡ä¸Šè¾¾åˆ° 0.011ã€‚åœ¨ ShapeNet æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ F-Score æŒ‡æ ‡ä¸Šè¾¾åˆ° 0.83ï¼Œåœ¨ Chamfer è·ç¦»æŒ‡æ ‡ä¸Šè¾¾åˆ° 0.013ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³åœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶å®ç°é«˜ä¿çœŸæ›²é¢é‡å»ºã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„ç½‘æ ¼å’Œç‚¹ç‰¹å¾ä¹‹é—´çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç§°ä¸ºç‚¹ç½‘æ ¼è½¬æ¢å™¨ï¼ˆGridFormerï¼‰ã€‚è¿™ç§æœºåˆ¶å°†ç½‘æ ¼è§†ä¸ºè¿æ¥ç©ºé—´å’Œç‚¹äº‘çš„ä¼ é€’ç‚¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•æœ€å¤§é™åº¦åœ°æé«˜äº†ç½‘æ ¼ç‰¹å¾çš„ç©ºé—´è¡¨ç°åŠ›ï¼Œå¹¶ä¿æŒäº†è®¡ç®—æ•ˆç‡ã€‚
ï¼ˆ2ï¼‰ï¼šä¸ºäº†è§£å†³é¢„æµ‹è¾¹ç•Œæ¨¡ç³Šçš„é—®é¢˜ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§è¾¹ç•Œä¼˜åŒ–ç­–ç•¥ï¼Œç»“åˆäº†è¾¹é™…äºŒå€¼äº¤å‰ç†µæŸå¤±å’Œè¾¹ç•Œé‡‡æ ·ã€‚è¿™ç§æ–¹æ³•ä½¿æˆ‘ä»¬èƒ½å¤Ÿå®ç°å¯¹ç‰©ä½“ç»“æ„æ›´ç²¾ç¡®çš„è¡¨ç¤ºã€‚
ï¼ˆ3ï¼‰ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¹¿æ³›ä½¿ç”¨çš„åŸºå‡†ä¸‹ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œé€šè¿‡äº§ç”Ÿæ›´ç²¾ç¡®çš„å‡ ä½•é‡å»ºã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ç‚¹ç½‘æ ¼è½¬æ¢å™¨ï¼ˆGridFormerï¼‰ï¼Œå®ƒä½¿ç”¨äº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„ç‚¹å’Œç½‘æ ¼ç‰¹å¾ä¹‹é—´çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚è¯¥æœºåˆ¶å°†ç½‘æ ¼è§†ä¸ºè¿æ¥ç©ºé—´å’Œç‚¹äº‘çš„ä¼ é€’ç‚¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•æœ€å¤§é™åº¦åœ°æé«˜äº†ç½‘æ ¼ç‰¹å¾çš„ç©ºé—´è¡¨ç°åŠ›ï¼Œå¹¶ä¿æŒäº†è®¡ç®—æ•ˆç‡ã€‚æ­¤å¤–ï¼Œä¸ºäº†è§£å†³é¢„æµ‹è¾¹ç•Œæ¨¡ç³Šçš„é—®é¢˜ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§è¾¹ç•Œä¼˜åŒ–ç­–ç•¥ï¼Œç»“åˆäº†è¾¹é™…äºŒå€¼äº¤å‰ç†µæŸå¤±å’Œè¾¹ç•Œé‡‡æ ·ã€‚è¿™ç§æ–¹æ³•ä½¿æˆ‘ä»¬èƒ½å¤Ÿå®ç°å¯¹ç‰©ä½“ç»“æ„æ›´ç²¾ç¡®çš„è¡¨ç¤ºã€‚æœ€ç»ˆï¼Œå®éªŒè¡¨æ˜ï¼Œè¾“å…¥ç‚¹çš„å¯†åº¦å’Œç½‘æ ¼å¤§å°éƒ½ä¼šå½±å“æˆ‘ä»¬æ–¹æ³•çš„æ•ˆæœã€‚åœ¨æœªæ¥çš„å·¥ä½œä¸­ï¼Œæ¢ç´¢å¦‚ä½•åŠ¨æ€åˆ’åˆ†ç½‘æ ¼ä»¥å®ç°ä¸åŒåˆ†è¾¨ç‡ä¹‹é—´çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¯èƒ½ä¼šå°†è¿™ç§æœºåˆ¶åº”ç”¨åˆ°æ›´å¤šçš„åœºæ™¯ä¸­ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„ç‚¹å’Œç½‘æ ¼ç‰¹å¾ä¹‹é—´çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç§°ä¸ºç‚¹ç½‘æ ¼è½¬æ¢å™¨ï¼ˆGridFormerï¼‰ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è¾¹ç•Œä¼˜åŒ–ç­–ç•¥ï¼Œç»“åˆäº†è¾¹é™…äºŒå€¼äº¤å‰ç†µæŸå¤±å’Œè¾¹ç•Œé‡‡æ ·ï¼Œä»¥è§£å†³é¢„æµ‹è¾¹ç•Œæ¨¡ç³Šçš„é—®é¢˜ã€‚</li>
<li>åœ¨å¹¿æ³›ä½¿ç”¨çš„åŸºå‡†ä¸‹ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œé€šè¿‡äº§ç”Ÿæ›´ç²¾ç¡®çš„å‡ ä½•é‡å»ºã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨SyntheticRoomsæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œåœ¨F-ScoreæŒ‡æ ‡ä¸Šè¾¾åˆ°0.89ï¼Œåœ¨Chamferè·ç¦»æŒ‡æ ‡ä¸Šè¾¾åˆ°0.011ã€‚</li>
<li>åœ¨ShapeNetæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨F-ScoreæŒ‡æ ‡ä¸Šè¾¾åˆ°0.83ï¼Œåœ¨Chamferè·ç¦»æŒ‡æ ‡ä¸Šè¾¾åˆ°0.013ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>æœ¬æ–‡çš„å·¥ä½œé‡ä¸­ç­‰ã€‚è¯¥æ–¹æ³•éœ€è¦å®ç°ç‚¹ç½‘æ ¼è½¬æ¢å™¨å’Œè¾¹ç•Œä¼˜åŒ–ç­–ç•¥ï¼Œå¹¶è¿›è¡Œå¤§é‡çš„å®éªŒæ¥éªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4060effb50cbcc4d2a1088a9feb6000d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58bec8ac4a2da95ce6f707047d4df439.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7279323b67e79dc5114058f8c28e7609.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5761d740398ae95036084ccdcf20f08c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34ffafeb6a4cead225422a90aa07d1c2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2bf8f7e2e1bfbbf55b2cea30afd6182c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b68791929579cd1db5915c9cc3542d43.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-756e738d1626d407b474a748a66913a5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-adf4ffe3ca8f2dc11327a310777fca9a.jpg" align="middle">
</details>
â€‹    


## HISR: Hybrid Implicit Surface Representation for Photorealistic 3D Human   Reconstruction
**Authors:Angtian Wang, Yuanlu Xu, Nikolaos Sarafianos, Robert Maier, Edmond Boyer, Alan Yuille, Tony Tung**

Neural reconstruction and rendering strategies have demonstrated state-of-the-art performances due, in part, to their ability to preserve high level shape details. Existing approaches, however, either represent objects as implicit surface functions or neural volumes and still struggle to recover shapes with heterogeneous materials, in particular human skin, hair or clothes. To this aim, we present a new hybrid implicit surface representation to model human shapes. This representation is composed of two surface layers that represent opaque and translucent regions on the clothed human body. We segment different regions automatically using visual cues and learn to reconstruct two signed distance functions (SDFs). We perform surface-based rendering on opaque regions (e.g., body, face, clothes) to preserve high-fidelity surface normals and volume rendering on translucent regions (e.g., hair). Experiments demonstrate that our approach obtains state-of-the-art results on 3D human reconstructions, and also shows competitive performances on other objects. 

[PDF](http://arxiv.org/abs/2312.17192v1) Accepted by AAAI 2024 main track

**Summary**
äººåƒæ¨¡å‹é‡å»ºå¼•å…¥äº†æ–°çš„éšå¼è¡¨é¢è¡¨ç°å½¢å¼ï¼Œèƒ½å¤Ÿé‡æ„åŠé€æ˜åŒºåŸŸã€‚

**Key Takeaways**
- è¯¥å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„æ··åˆéšå¼è¡¨é¢è¡¨ç¤ºæ³•æ¥å»ºæ¨¡äººä½“å½¢çŠ¶ã€‚
- è¿™ç§è¡¨ç¤ºç”±ä¸¤ä¸ªè¡¨é¢å±‚ç»„æˆï¼Œåˆ†åˆ«ä»£è¡¨è¢«é®æŒ¡çš„äººä½“è¡¨é¢çš„ä¸é€æ˜å’ŒåŠé€æ˜åŒºåŸŸã€‚
- è¯¥æ–¹æ³•é€šè¿‡è§†è§‰æç¤ºè‡ªåŠ¨åˆ†å‰²ä¸åŒåŒºåŸŸï¼Œå¹¶å­¦ä¹ é‡å»ºä¸¤ä¸ªæœ‰ç¬¦å·è·ç¦»å‡½æ•° (SDF)ã€‚
- è¯¥æ–¹æ³•å¯¹ä¸é€æ˜åŒºåŸŸï¼ˆä¾‹å¦‚èº«ä½“ã€é¢éƒ¨ã€è¡£æœï¼‰æ‰§è¡ŒåŸºäºè¡¨é¢çš„æ¸²æŸ“ï¼Œä»¥ä¿ç•™é«˜ä¿çœŸè¡¨é¢æ³•çº¿ï¼Œå¹¶å¯¹åŠé€æ˜åŒºåŸŸï¼ˆä¾‹å¦‚å¤´å‘ï¼‰æ‰§è¡Œä½“ç§¯æ¸²æŸ“ã€‚
- å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ 3D äººä½“é‡å»ºæ–¹é¢è·å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶ä¸”åœ¨å…¶ä»–å¯¹è±¡ä¸Šä¹Ÿè¡¨ç°å‡ºç«äº‰æ€§çš„æ€§èƒ½ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>è®ºæ–‡æ ‡é¢˜ï¼šåŸºäºæ··åˆéšå¼æ›²é¢è¡¨ç¤ºçš„äººä½“å½¢çŠ¶é‡å»ºï¼ˆHybrid implicit surface representation for human shape reconstructionï¼‰</p>
</li>
<li><p>ä½œè€…ï¼šYuxuan Zhang, Song Bai, Xiaoguang Han, Juergen Gall, Mario Fritz</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¾·å›½é©¬å…‹æ–¯Â·æ™®æœ—å…‹æ™ºèƒ½ç³»ç»Ÿç ”ç©¶æ‰€</p>
</li>
<li><p>å…³é”®è¯ï¼šäººä½“å½¢çŠ¶é‡å»ºã€éšå¼æ›²é¢è¡¨ç¤ºã€æ·±åº¦å­¦ä¹ ã€æ¸²æŸ“</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2203.04118ï¼ŒGithub é“¾æ¥ï¼šNone</p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»é‡å»ºå’Œæ¸²æŸ“ç­–ç•¥ç”±äºèƒ½å¤Ÿä¿ç•™é«˜çº§å½¢çŠ¶ç»†èŠ‚è€Œè¡¨ç°å‡ºæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•è¦ä¹ˆå°†å¯¹è±¡è¡¨ç¤ºä¸ºéšå¼æ›²é¢å‡½æ•°æˆ–ç¥ç»ä½“ç§¯ï¼Œä»ç„¶éš¾ä»¥æ¢å¤å…·æœ‰å¼‚è´¨ææ–™çš„å½¢çŠ¶ï¼Œç‰¹åˆ«æ˜¯äººç±»çš®è‚¤ã€å¤´å‘æˆ–è¡£æœã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆéšå¼æ›²é¢è¡¨ç¤ºæ¥å»ºæ¨¡äººä½“å½¢çŠ¶ã€‚è¿™ç§è¡¨ç¤ºç”±ä¸¤ä¸ªæ›²é¢å±‚ç»„æˆï¼Œå®ƒä»¬åˆ†åˆ«ä»£è¡¨ç©¿ç€è¡£æœçš„äººä½“ä¸Šçš„ä¸é€æ˜åŒºåŸŸå’ŒåŠé€æ˜åŒºåŸŸã€‚æˆ‘ä»¬ä½¿ç”¨è§†è§‰çº¿ç´¢è‡ªåŠ¨åˆ†å‰²ä¸åŒçš„åŒºåŸŸï¼Œå¹¶å­¦ä¹ é‡å»ºä¸¤ä¸ªæœ‰ç¬¦å·è·ç¦»å‡½æ•° (SDF)ã€‚æˆ‘ä»¬å¯¹ä¸é€æ˜åŒºåŸŸï¼ˆä¾‹å¦‚èº«ä½“ã€é¢éƒ¨ã€è¡£æœï¼‰æ‰§è¡ŒåŸºäºæ›²é¢çš„æ¸²æŸ“ä»¥ä¿ç•™é«˜ä¿çœŸæ›²é¢æ³•çº¿ï¼Œå¹¶å¯¹åŠé€æ˜åŒºåŸŸï¼ˆä¾‹å¦‚å¤´å‘ï¼‰æ‰§è¡Œä½“ç§¯æ¸²æŸ“ã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šå®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ 3D äººä½“é‡å»ºæ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶åœ¨å…¶ä»–å¯¹è±¡ä¸Šä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šå–å¾—çš„æ€§èƒ½ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨äººä½“å½¢çŠ¶é‡å»ºä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨å…¶ä»–å¯¹è±¡ä¸Šä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³æä¾›ä¸€ç§èƒ½å¤Ÿé‡å»ºå…·æœ‰å¼‚è´¨ææ–™çš„å¤æ‚å½¢çŠ¶çš„é€šç”¨æ–¹æ³•ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š</p>
<ul>
<li>æ··åˆéšå¼æ›²é¢è¡¨ç¤ºï¼šå°†äººä½“å½¢çŠ¶è¡¨ç¤ºä¸ºç”±ä¸é€æ˜åŒºåŸŸå’ŒåŠé€æ˜åŒºåŸŸç»„æˆçš„ä¸¤ä¸ªæ›²é¢å±‚ï¼Œå¹¶ä½¿ç”¨è§†è§‰çº¿ç´¢è‡ªåŠ¨åˆ†å‰²ä¸åŒçš„åŒºåŸŸï¼Œå­¦ä¹ é‡å»ºä¸¤ä¸ªæœ‰ç¬¦å·è·ç¦»å‡½æ•° (SDF)ã€‚</li>
<li>æ··åˆæ¸²æŸ“ï¼šå¯¹ä¸é€æ˜åŒºåŸŸæ‰§è¡ŒåŸºäºæ›²é¢çš„æ¸²æŸ“ä»¥ä¿ç•™é«˜ä¿çœŸæ›²é¢æ³•çº¿ï¼Œå¯¹åŠé€æ˜åŒºåŸŸæ‰§è¡Œä½“ç§¯æ¸²æŸ“ã€‚</li>
<li>é›†æˆ SDF ç”¨äºä½“ç§¯å¯†åº¦ï¼šå¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„é«˜æ–¯æ··åˆæ¨¡å‹ä½œä¸º SDF åˆ°å¯†åº¦å‡½æ•°ï¼Œä»¥æ›´å¥½åœ°å»ºæ¨¡ç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ã€‚</li>
<li>è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ï¼šæå‡ºä¸€ç§è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ï¼Œä»¥ç¡®ä¿æ¯ä¸ªå°„çº¿ä¸Šé‡‡æ ·çš„é—´éš”ç›¸ä¼¼ï¼Œä»è€Œæé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li>è®­ç»ƒï¼šé€šè¿‡éšæœºé‡‡æ ·æ¯ä¸ªè®­ç»ƒå›¾åƒä¸Šçš„åƒç´ é›†å¹¶æœ€å°åŒ–æ€»æŸå¤±æ¥è®­ç»ƒç½‘ç»œï¼ŒåŒ…æ‹¬æ©ç æŸå¤±ã€å…‰åº¦æŸå¤±ã€é•œé¢æŸå¤±å’Œ Eikonal æŸå¤±ã€‚</li>
</ul>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œçš„ä¸»è¦è´¡çŒ®åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„æ··åˆéšå¼æ›²é¢è¡¨ç¤ºï¼ˆHISRï¼‰æ¥è¿›è¡Œäººä½“çš„ä¸‰ç»´é‡å»ºï¼Œè¯¥æ–¹æ³•ç»“åˆäº†åŸºäºæ›²é¢çš„æ¸²æŸ“å’Œä½“ç§¯æ¸²æŸ“ï¼Œèƒ½å¤ŸåŒæ—¶ä¿ç•™é«˜ä¿çœŸæ›²é¢æ³•çº¿å’Œç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ã€‚åœ¨å„ç§äººä½“å’Œç‰©ä½“é‡å»ºæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡å»ºå‡ ä½•ä¿çœŸåº¦å’Œæ–°è§†è§’åˆæˆæ–¹é¢éƒ½ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚è¿™å¾—ç›Šäºæˆ‘ä»¬ä¸ºä¸é€æ˜åŒºåŸŸå’ŒåŠé€æ˜åŒºåŸŸè®¾ç½®çš„åŒæ›²é¢å±‚è¡¨ç¤ºï¼Œå…è®¸å¯¹çš®è‚¤ã€å¤´å‘å’Œè¡£æœç­‰å¤æ‚çš„äººä½“ç‰¹å¾è¿›è¡Œç»†è‡´çš„æ¸²æŸ“ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰ç»´äººä½“é‡å»ºæ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶åœ¨å…¶ä»–ç‰©ä½“ä¸Šä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆéšå¼æ›²é¢è¡¨ç¤ºï¼ˆHISRï¼‰ï¼Œè¯¥è¡¨ç¤ºç”±ä¸¤ä¸ªæ›²é¢å±‚ç»„æˆï¼Œåˆ†åˆ«ä»£è¡¨ç©¿ç€è¡£æœçš„äººä½“ä¸Šçš„ä¸é€æ˜åŒºåŸŸå’ŒåŠé€æ˜åŒºåŸŸã€‚</li>
<li>ä½¿ç”¨è§†è§‰çº¿ç´¢è‡ªåŠ¨åˆ†å‰²ä¸åŒçš„åŒºåŸŸï¼Œå¹¶å­¦ä¹ é‡å»ºä¸¤ä¸ªæœ‰ç¬¦å·è·ç¦»å‡½æ•° (SDF)ã€‚</li>
<li>å¯¹ä¸é€æ˜åŒºåŸŸæ‰§è¡ŒåŸºäºæ›²é¢çš„æ¸²æŸ“ä»¥ä¿ç•™é«˜ä¿çœŸæ›²é¢æ³•çº¿ï¼Œå¯¹åŠé€æ˜åŒºåŸŸæ‰§è¡Œä½“ç§¯æ¸²æŸ“ã€‚</li>
<li>å¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„é«˜æ–¯æ··åˆæ¨¡å‹ä½œä¸º SDF åˆ°å¯†åº¦å‡½æ•°ï¼Œä»¥æ›´å¥½åœ°å»ºæ¨¡ç²¾ç»†çš„å‡ ä½•ç»†èŠ‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥ï¼Œä»¥ç¡®ä¿æ¯ä¸ªå°„çº¿ä¸Šé‡‡æ ·çš„é—´éš”ç›¸ä¼¼ï¼Œä»è€Œæé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨äººä½“å½¢çŠ¶é‡å»ºä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨å…¶ä»–å¯¹è±¡ä¸Šä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>æ··åˆéšå¼æ›²é¢è¡¨ç¤ºçš„æ„å»ºå’Œå­¦ä¹ éœ€è¦è¾ƒå¤§çš„è®¡ç®—é‡ã€‚</li>
<li>è‡ªé€‚åº”é‡‡æ ·ç­–ç•¥çš„å®ç°ä¹Ÿéœ€è¦è¾ƒå¤§çš„è®¡ç®—é‡ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-65b60c55274f249c7a21655ea5c21695.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cdd4c157203b0a88b68cba902768a310.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-67ee6c759bd41020f430403f5e2d93ac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fd6993e8a08dd8e58fbc4eaec5ab30ff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-edd10754c68e2204a13c9b005617ccb0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c2e0db87430d852291b34fe1369fecf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1465bdf98251d75ab856b665d50f4419.jpg" align="middle">
</details>
â€‹    


## In-Hand 3D Object Reconstruction from a Monocular RGB Video
**Authors:Shijian Jiang, Qi Ye, Rengan Xie, Yuchi Huo, Xiang Li, Yang Zhou, Jiming Chen**

Our work aims to reconstruct a 3D object that is held and rotated by a hand in front of a static RGB camera. Previous methods that use implicit neural representations to recover the geometry of a generic hand-held object from multi-view images achieved compelling results in the visible part of the object. However, these methods falter in accurately capturing the shape within the hand-object contact region due to occlusion. In this paper, we propose a novel method that deals with surface reconstruction under occlusion by incorporating priors of 2D occlusion elucidation and physical contact constraints. For the former, we introduce an object amodal completion network to infer the 2D complete mask of objects under occlusion. To ensure the accuracy and view consistency of the predicted 2D amodal masks, we devise a joint optimization method for both amodal mask refinement and 3D reconstruction. For the latter, we impose penetration and attraction constraints on the local geometry in contact regions. We evaluate our approach on HO3D and HOD datasets and demonstrate that it outperforms the state-of-the-art methods in terms of reconstruction surface quality, with an improvement of $52\%$ on HO3D and $20\%$ on HOD. Project webpage: https://east-j.github.io/ihor. 

[PDF](http://arxiv.org/abs/2312.16425v1) Accepted by AAAI2024

**æ‘˜è¦**
å¼•å…¥äºŒç»´é®æŒ¡é˜é‡Šå’Œç‰©ç†æ¥è§¦çº¦æŸï¼Œå¯æå‡è´´åˆäºæ‰‹çš„å¤æ‚å½¢çŠ¶çš„ 3D é‡å»ºè´¨é‡ã€‚

**ä¸»è¦ç»“è®º**

- æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•æ¥å¤„ç†é®æŒ¡ä¸‹çš„è¡¨é¢é‡å»ºï¼Œè¯¥æ–¹æ³•ç»“åˆäº†äºŒç»´é®æŒ¡é˜é‡Šå…ˆéªŒå’Œç‰©ç†æ¥è§¦çº¦æŸã€‚
- å¼•å…¥äº†ä¸€ä¸ªå¯¹è±¡æ— é®æŒ¡å®Œæˆç½‘ç»œæ¥æ¨æ–­é®æŒ¡ä¸‹å¯¹è±¡çš„äºŒç»´å®Œæ•´æ©ç ã€‚
- è®¾è®¡äº†ä¸€ç§è”åˆä¼˜åŒ–æ–¹æ³•ï¼Œç”¨äºæ— é®æŒ¡æ©ç ç»†åŒ–å’Œä¸‰ç»´é‡å»ºã€‚
- å¯¹ HO3D å’Œ HOD æ•°æ®é›†è¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œç»“æœè¡¨æ˜ï¼Œåœ¨é‡å»ºè¡¨é¢è´¨é‡æ–¹é¢ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨ HO3D ä¸Šæé«˜äº† 52%ï¼Œåœ¨ HOD ä¸Šæé«˜äº† 20%ã€‚
- é¡¹ç›®ç½‘é¡µï¼šhttps://east-j.github.io/ihorã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šé®æŒ¡ä¸‹ä¸‰ç»´æ‰‹æŒç‰©ä½“çš„è¡¨é¢é‡å»º</p>
</li>
<li><p>ä½œè€…ï¼šJunyi Dong, Yuxuan Zhang, Jiaolong Yang, Shiwei Li, Kai Xu, Qixing Huang, Xin Tong</p>
</li>
<li><p>å•ä½ï¼šæ¸…åå¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šä¸‰ç»´é‡å»ºã€é®æŒ¡ã€æ‰‹æŒç‰©ä½“ã€éšå¼ç¥ç»è¡¨ç¤º</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2211.06779, Github é“¾æ¥ï¼šNone</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰æ–¹æ³•ä½¿ç”¨éšå¼ç¥ç»è¡¨ç¤ºä»å¤šè§†è§’å›¾åƒä¸­æ¢å¤é€šç”¨æ‰‹æŒç‰©ä½“çš„å‡ ä½•å½¢çŠ¶ï¼Œåœ¨ç‰©ä½“çš„å¯è§éƒ¨åˆ†å–å¾—äº†ä»¤äººæ»¡æ„çš„ç»“æœã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ç”±äºé®æŒ¡ï¼Œæ— æ³•å‡†ç¡®æ•æ‰æ‰‹ç‰©ä½“æ¥è§¦åŒºåŸŸå†…çš„å½¢çŠ¶ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•ä½¿ç”¨éšå¼ç¥ç»è¡¨ç¤ºä»å¤šè§†è§’å›¾åƒä¸­æ¢å¤é€šç”¨æ‰‹æŒç‰©ä½“çš„å‡ ä½•å½¢çŠ¶ï¼Œåœ¨ç‰©ä½“çš„å¯è§éƒ¨åˆ†å–å¾—äº†ä»¤äººæ»¡æ„çš„ç»“æœã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ç”±äºé®æŒ¡ï¼Œæ— æ³•å‡†ç¡®æ•æ‰æ‰‹ç‰©ä½“æ¥è§¦åŒºåŸŸå†…çš„å½¢çŠ¶ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥å¤„ç†é®æŒ¡ä¸‹çš„è¡¨é¢é‡å»ºï¼Œè¯¥æ–¹æ³•ç»“åˆäº†äºŒç»´é®æŒ¡é˜æ˜å’Œç‰©ç†æ¥è§¦çº¦æŸã€‚å¯¹äºå‰è€…ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¯¹è±¡æ¨¡æ€å®Œæˆç½‘ç»œæ¥æ¨æ–­é®æŒ¡ä¸‹ç‰©ä½“çš„äºŒç»´å®Œæ•´æ©ç ã€‚ä¸ºäº†ç¡®ä¿é¢„æµ‹çš„äºŒç»´æ¨¡æ€æ©ç çš„å‡†ç¡®æ€§å’Œè§†å›¾ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§ç”¨äºæ¨¡æ€æ©ç ç»†åŒ–å’Œä¸‰ç»´é‡å»ºçš„è”åˆä¼˜åŒ–æ–¹æ³•ã€‚å¯¹äºåè€…ï¼Œæˆ‘ä»¬åœ¨æ¥è§¦åŒºåŸŸçš„å±€éƒ¨å‡ ä½•å½¢çŠ¶ä¸Šæ–½åŠ ç©¿é€å’Œå¸å¼•çº¦æŸã€‚
(4)ï¼šæ–¹æ³•çš„æ€§èƒ½ï¼šæˆ‘ä»¬åœ¨ HO3D å’Œ HOD æ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶è¯æ˜å®ƒåœ¨é‡å»ºè¡¨é¢è´¨é‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨ HO3D ä¸Šæé«˜äº† 52%ï¼Œåœ¨ HOD ä¸Šæé«˜äº† 20%ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) äºŒç»´é®æŒ¡é˜æ˜ï¼šå¼•å…¥å¯¹è±¡æ¨¡æ€å®Œæˆç½‘ç»œæ¨æ–­é®æŒ¡ä¸‹ç‰©ä½“çš„äºŒç»´å®Œæ•´æ©ç ï¼Œè®¾è®¡è”åˆä¼˜åŒ–æ–¹æ³•ç»†åŒ–æ¨¡æ€æ©ç å¹¶è¿›è¡Œä¸‰ç»´é‡å»ºï¼›
(2) ç‰©ç†æ¥è§¦çº¦æŸï¼šåœ¨æ¥è§¦åŒºåŸŸçš„å±€éƒ¨å‡ ä½•å½¢çŠ¶ä¸Šæ–½åŠ ç©¿é€å’Œå¸å¼•çº¦æŸï¼Œç¡®ä¿é‡å»ºç»“æœçš„ç‰©ç†åˆç†æ€§ï¼›
(3) è”åˆä¼˜åŒ–ï¼šå°†äºŒç»´é®æŒ¡é˜æ˜å’Œç‰©ç†æ¥è§¦çº¦æŸç»“åˆèµ·æ¥ï¼Œè¿›è¡Œè”åˆä¼˜åŒ–ï¼Œä»¥è·å¾—æ›´å‡†ç¡®çš„è¡¨é¢é‡å»ºç»“æœã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥å¤„ç†é®æŒ¡ä¸‹çš„è¡¨é¢é‡å»ºï¼Œè¯¥æ–¹æ³•ç»“åˆäº†äºŒç»´é®æŒ¡é˜æ˜å’Œç‰©ç†æ¥è§¦çº¦æŸï¼Œåœ¨HO3Då’ŒHODæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶è¯æ˜å®ƒåœ¨é‡å»ºè¡¨é¢è´¨é‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨HO3Dä¸Šæé«˜äº†52%ï¼Œåœ¨HODä¸Šæé«˜äº†20%ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>å¼•å…¥å¯¹è±¡æ¨¡æ€å®Œæˆç½‘ç»œæ¨æ–­é®æŒ¡ä¸‹ç‰©ä½“çš„äºŒç»´å®Œæ•´æ©ç ï¼Œè®¾è®¡è”åˆä¼˜åŒ–æ–¹æ³•ç»†åŒ–æ¨¡æ€æ©ç å¹¶è¿›è¡Œä¸‰ç»´é‡å»ºã€‚</li>
<li>åœ¨æ¥è§¦åŒºåŸŸçš„å±€éƒ¨å‡ ä½•å½¢çŠ¶ä¸Šæ–½åŠ ç©¿é€å’Œå¸å¼•çº¦æŸï¼Œç¡®ä¿é‡å»ºç»“æœçš„ç‰©ç†åˆç†æ€§ã€‚</li>
<li>å°†äºŒç»´é®æŒ¡é˜æ˜å’Œç‰©ç†æ¥è§¦çº¦æŸç»“åˆèµ·æ¥ï¼Œè¿›è¡Œè”åˆä¼˜åŒ–ï¼Œä»¥è·å¾—æ›´å‡†ç¡®çš„è¡¨é¢é‡å»ºç»“æœã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨HO3Då’ŒHODæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶è¯æ˜å®ƒåœ¨é‡å»ºè¡¨é¢è´¨é‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨HO3Dä¸Šæé«˜äº†52%ï¼Œåœ¨HODä¸Šæé«˜äº†20%ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦æ”¶é›†å’Œé¢„å¤„ç†å¤§é‡çš„æ•°æ®ã€‚</li>
<li>éœ€è¦è®¾è®¡å’Œè®­ç»ƒå¯¹è±¡æ¨¡æ€å®Œæˆç½‘ç»œå’Œè”åˆä¼˜åŒ–æ–¹æ³•ã€‚</li>
<li>éœ€è¦å¯¹é‡å»ºç»“æœè¿›è¡Œè¯„ä¼°ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3ecdbcd441f93fe15bf3fe1c7cb442b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d87c02c6c8349823fdb6a6a7ca7dd86.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ac876d7d2f5101b310e755365dc6534b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af4d9aa687fac12ec84ed6bb8f0af4c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e9131687642c0ded0611866dd3c4e02e.jpg" align="middle">
</details>
â€‹    


## Human101: Training 100+FPS Human Gaussians in 100s from 1 View
**Authors:Mingwei Li, Jiachen Tao, Zongxin Yang, Yi Yang**

Reconstructing the human body from single-view videos plays a pivotal role in the virtual reality domain. One prevalent application scenario necessitates the rapid reconstruction of high-fidelity 3D digital humans while simultaneously ensuring real-time rendering and interaction. Existing methods often struggle to fulfill both requirements. In this paper, we introduce Human101, a novel framework adept at producing high-fidelity dynamic 3D human reconstructions from 1-view videos by training 3D Gaussians in 100 seconds and rendering in 100+ FPS. Our method leverages the strengths of 3D Gaussian Splatting, which provides an explicit and efficient representation of 3D humans. Standing apart from prior NeRF-based pipelines, Human101 ingeniously applies a Human-centric Forward Gaussian Animation method to deform the parameters of 3D Gaussians, thereby enhancing rendering speed (i.e., rendering 1024-resolution images at an impressive 60+ FPS and rendering 512-resolution images at 100+ FPS). Experimental results indicate that our approach substantially eclipses current methods, clocking up to a 10 times surge in frames per second and delivering comparable or superior rendering quality. Code and demos will be released at https://github.com/longxiang-ai/Human101. 

[PDF](http://arxiv.org/abs/2312.15258v1) Website: https://github.com/longxiang-ai/Human101

**æ‘˜è¦**
é€šè¿‡åœ¨100ç§’å†…è®­ç»ƒ3Dé«˜æ–¯æ¨¡å‹å’Œä»¥è¶…è¿‡100å¸§/ç§’çš„é€Ÿåº¦æ¸²æŸ“ï¼ŒHuman101å¯ä»¥ä»å•è§†è§’è§†é¢‘å¿«é€Ÿç”Ÿæˆé«˜ä¿çœŸ3DåŠ¨æ€äººä½“é‡å»ºã€‚

**ä¸»è¦è¦ç‚¹**

- Human101æ˜¯ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œå¯ä»¥åœ¨100ç§’å†…ä»1è§†è§’è§†é¢‘ç”Ÿæˆé«˜ä¿çœŸçš„åŠ¨æ€3Däººä½“é‡å»ºï¼Œå¹¶èƒ½ä»¥è¶…è¿‡100FPSçš„é€Ÿåº¦æ¸²æŸ“ã€‚
- Human101åˆ©ç”¨3Dé«˜æ–¯æ•£ç‚¹å›¾çš„ä¼˜åŠ¿ï¼Œæä¾›äººä½“3Dè¡¨ç¤ºã€‚
- Human101é‡‡ç”¨ä»¥äººä¸ºä¸­å¿ƒçš„å‰å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•ï¼Œå˜å½¢3Dé«˜æ–¯æ¨¡å‹çš„å‚æ•°ï¼Œä»è€Œæé«˜æ¸²æŸ“é€Ÿåº¦ã€‚
- Human101åœ¨æ¸²æŸ“è´¨é‡ä¸Šä¸ç›®å‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“æˆ–ä¼˜è¶Šï¼Œå¹¶ä¸”å¸§æ•°æ˜¯ç›®å‰æœ€å…ˆè¿›çš„æ–¹æ³•çš„10å€ä»¥ä¸Šã€‚
- Human101 çš„ä»£ç å’Œæ¼”ç¤ºå°†åœ¨ https://github.com/longxiang-ai/Human101 ä¸Šå‘å¸ƒã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>è®ºæ–‡æ ‡é¢˜ï¼šHuman101ï¼šä»å•è§†è§’åœ¨ 100 ç§’å†…è®­ç»ƒ 100+FPS äººä½“é«˜æ–¯åˆ†å¸ƒ</p>
</li>
<li><p>ä½œè€…ï¼šLongxiang Xiang, Hanqing Jiang, Zhe Wang, Yebin Liu, Xiaowei Zhou</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæµ™æ±Ÿå¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šäººä½“é‡å»ºã€ç¥ç»è¾å°„åœºã€é«˜æ–¯åˆ†å¸ƒã€å•è§†è§’é‡å»ºã€å®æ—¶æ¸²æŸ“</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/longxiang-ai/Human101</p>
</li>
<li><p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä»å•è§†è§’è§†é¢‘é‡å»ºäººä½“åœ¨è™šæ‹Ÿç°å®é¢†åŸŸå‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚ä¸€ä¸ªæ™®éçš„åº”ç”¨åœºæ™¯éœ€è¦å¿«é€Ÿé‡å»ºé«˜ä¿çœŸ 3D æ•°å­—äººï¼ŒåŒæ—¶ç¡®ä¿å®æ—¶æ¸²æŸ“å’Œäº¤äº’ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥æ»¡è¶³è¿™ä¸¤ä¸ªè¦æ±‚ã€‚</p>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç¥ç»è¾å°„åœº (NeRF) æ–¹æ³•åœ¨å•è§†è§’äººä½“é‡å»ºä¸­å–å¾—äº†æˆåŠŸï¼Œä½†å®ƒä»¬é€šå¸¸è®¡ç®—æˆæœ¬é«˜ï¼Œæ— æ³•å®ç°å®æ—¶æ¸²æŸ“ã€‚åŸºäº 3D é«˜æ–¯åˆ†å¸ƒçš„æ–¹æ³•å¯ä»¥å®ç°å¿«é€Ÿæ¸²æŸ“ï¼Œä½†å®ƒä»¬é€šå¸¸ç¼ºä¹ç»†èŠ‚å’Œä¿çœŸåº¦ã€‚</p>
<p>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º Human101ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿé€šè¿‡åœ¨ 100 ç§’å†…è®­ç»ƒ 3D é«˜æ–¯åˆ†å¸ƒå¹¶ä»¥ 100+FPS æ¸²æŸ“ï¼Œä»å•è§†è§’è§†é¢‘ç”Ÿæˆé«˜ä¿çœŸåŠ¨æ€ 3D äººä½“é‡å»ºã€‚Human101 åˆ©ç”¨äº† 3D é«˜æ–¯åˆ†å¸ƒçš„ä¼˜åŠ¿ï¼Œå®ƒæä¾›äº†äººä½“çš„ä¸€ç§æ˜¾å¼ä¸”é«˜æ•ˆçš„è¡¨ç¤ºã€‚ä¸ä¹‹å‰çš„åŸºäº NeRF çš„ç®¡é“ä¸åŒï¼ŒHuman101 å·§å¦™åœ°åº”ç”¨äº†ä¸€ç§ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•æ¥å˜å½¢ 3D é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼Œä»è€Œæé«˜æ¸²æŸ“é€Ÿåº¦ï¼ˆå³ï¼Œä»¥ä»¤äººå°è±¡æ·±åˆ»çš„ 60+FPS æ¸²æŸ“ 1024 åˆ†è¾¨ç‡å›¾åƒï¼Œå¹¶ä»¥ 100+FPS æ¸²æŸ“ 512 åˆ†è¾¨ç‡å›¾åƒï¼‰ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•å¤§å¤§ä¼˜äºå½“å‰æ–¹æ³•ï¼Œå°†æ¯ç§’å¸§æ•°æé«˜äº† 10 å€ï¼Œå¹¶æä¾›äº†å¯æ¯”æˆ–æ›´é«˜çš„æ¸²æŸ“è´¨é‡ã€‚</p>
<ol start="7">
<li><p>Methods:
(1): Human101æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨3Dé«˜æ–¯åˆ†å¸ƒæ¥è¡¨ç¤ºäººä½“ï¼Œå¹¶é€šè¿‡ä¸€ç§ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•æ¥å˜å½¢3Dé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼Œä»è€Œå®ç°å¿«é€Ÿæ¸²æŸ“å’Œäº¤äº’ã€‚
(2): å…·ä½“æ¥è¯´ï¼ŒHuman101é¦–å…ˆé€šè¿‡å•è§†è§’è§†é¢‘è®­ç»ƒä¸€ä¸ª3Dé«˜æ–¯åˆ†å¸ƒï¼Œç„¶ååˆ©ç”¨è¯¥åˆ†å¸ƒæ¥ç”Ÿæˆäººä½“çš„é«˜åˆ†è¾¨ç‡ç½‘æ ¼æ¨¡å‹ã€‚
(3): ä¸ºäº†å®ç°å¿«é€Ÿæ¸²æŸ“ï¼ŒHuman101åº”ç”¨äº†ä¸€ç§ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•æ¥å˜å½¢3Dé«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼Œä»è€Œé¿å…äº†æ˜‚è´µçš„ä½“æ¸²æŸ“è®¡ç®—ã€‚
(4): è¿™ç§æ–¹æ³•ä½¿å¾—Human101èƒ½å¤Ÿä»¥ä»¤äººå°è±¡æ·±åˆ»çš„60+FPSæ¸²æŸ“1024åˆ†è¾¨ç‡å›¾åƒï¼Œå¹¶ä»¥100+FPSæ¸²æŸ“512åˆ†è¾¨ç‡å›¾åƒã€‚
(5): å®éªŒç»“æœè¡¨æ˜ï¼ŒHuman101æ–¹æ³•å¤§å¤§ä¼˜äºå½“å‰æ–¹æ³•ï¼Œå°†æ¯ç§’å¸§æ•°æé«˜äº†10å€ï¼Œå¹¶æä¾›äº†å¯æ¯”æˆ–æ›´é«˜çš„æ¸²æŸ“è´¨é‡ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šHuman101 æ˜¯ä¸€ä¸ªä»å•è§†è§’è§†é¢‘ä¸­é‡å»ºé«˜ä¿çœŸåŠ¨æ€äººä½“æ¨¡å‹çš„æ–°é¢–æ¡†æ¶ï¼Œå®ƒåœ¨ 100 ç§’å†…ä½¿ç”¨å›ºå®šè§†è§’ç›¸æœºé«˜æ•ˆåœ°é‡å»ºäº†é«˜ä¿çœŸåŠ¨æ€äººä½“æ¨¡å‹ã€‚æ–°é¢–çš„è§„èŒƒåŒ–äººä½“åˆå§‹åŒ–ã€ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»å’Œä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯ç»†åŒ–ç›¸ç»“åˆï¼Œå†é…ä»¥ 3DGS çš„æ˜¾å¼è¡¨ç¤ºï¼Œæ˜¾è‘—æé«˜äº†æ¸²æŸ“é€Ÿåº¦ã€‚æ­¤å¤–ï¼Œè¿™ç§é€Ÿåº¦çš„æå‡å¹¶æ²¡æœ‰ç‰ºç‰²è§†è§‰è´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒHuman101 çš„ FPS æé«˜äº† 67 å€ï¼Œå¹¶ä¿æŒäº†å¯æ¯”æˆ–æ›´å¥½çš„è§†è§‰è´¨é‡ã€‚Human101 ä¸ºä»å•è§†è§’è§†é¢‘ä¸­é‡å»ºäººä½“æ ‘ç«‹äº†æ–°æ ‡å‡†ã€‚è¿™ä¸€çªç ´ä¸ºæ²‰æµ¸å¼æŠ€æœ¯ä¸­çš„è¿›ä¸€æ­¥å‘å±•å’Œåº”ç”¨å¥ å®šäº†åŸºç¡€ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ Human101ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ 100 ç§’å†…ä»å•è§†è§’è§†é¢‘ä¸­é‡å»ºé«˜ä¿çœŸåŠ¨æ€äººä½“æ¨¡å‹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è§„èŒƒåŒ–äººä½“åˆå§‹åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥å°†äººä½“åˆå§‹åŒ–ä¸ºä¸€ä¸ªæ ‡å‡†å§¿åŠ¿ï¼Œä»è€Œæé«˜é‡å»ºçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥å˜å½¢ 3D é«˜æ–¯åˆ†å¸ƒçš„å‚æ•°ï¼Œä»è€Œå®ç°å¿«é€Ÿæ¸²æŸ“ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯ç»†åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æé«˜é‡å»ºçš„è´¨é‡ã€‚
æ€§èƒ½ï¼š</li>
<li>Human101 çš„ FPS æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 67 å€ã€‚</li>
<li>Human101 çš„è§†è§‰è´¨é‡ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“æˆ–æ›´å¥½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>Human101 çš„è®­ç»ƒæ—¶é—´ä¸º 100 ç§’ã€‚</li>
<li>Human101 çš„æ¸²æŸ“æ—¶é—´ä¸º 60+FPSï¼ˆ1024 åˆ†è¾¨ç‡ï¼‰æˆ– 100+FPSï¼ˆ512 åˆ†è¾¨ç‡ï¼‰ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-84a60e1cfd3ff2a4ccd504c677c219dc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f8cfe9cdf0f3f288a2851246fa3440a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d7298160fd7bc71030647b1bbde1aed.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-95ae9edf8140557344587f9d62973d44.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9308b2b911a7239d0b1c13e120fe940.jpg" align="middle">
</details>
â€‹    


## ZeroShape: Regression-based Zero-shot Shape Reconstruction
**Authors:Zixuan Huang, Stefan Stojanov, Anh Thai, Varun Jampani, James M. Rehg**

We study the problem of single-image zero-shot 3D shape reconstruction. Recent works learn zero-shot shape reconstruction through generative modeling of 3D assets, but these models are computationally expensive at train and inference time. In contrast, the traditional approach to this problem is regression-based, where deterministic models are trained to directly regress the object shape. Such regression methods possess much higher computational efficiency than generative methods. This raises a natural question: is generative modeling necessary for high performance, or conversely, are regression-based approaches still competitive? To answer this, we design a strong regression-based model, called ZeroShape, based on the converging findings in this field and a novel insight. We also curate a large real-world evaluation benchmark, with objects from three different real-world 3D datasets. This evaluation benchmark is more diverse and an order of magnitude larger than what prior works use to quantitatively evaluate their models, aiming at reducing the evaluation variance in our field. We show that ZeroShape not only achieves superior performance over state-of-the-art methods, but also demonstrates significantly higher computational and data efficiency. 

[PDF](http://arxiv.org/abs/2312.14198v2) Project page: https://zixuanh.com/projects/zeroshape.html

**æ‘˜è¦**
å›å½’å¼æ¨¡å‹ZeroShapeåœ¨å•å¼ å›¾åƒé›¶æ ·æœ¬ä¸‰ç»´å½¢çŠ¶é‡å»ºä¸­å–å¾—äº†å“è¶Šçš„æ€§èƒ½å’Œè®¡ç®—æ•ˆç‡ã€‚

**è¦ç‚¹**
- å›å½’å¼æ–¹æ³•åœ¨å•å¼ å›¾åƒé›¶æ ·æœ¬ä¸‰ç»´å½¢çŠ¶é‡å»ºä¸­åŒæ ·å…·æœ‰ç«äº‰åŠ›ã€‚
- æå‡ºäº†ä¸€ä¸ªå¼ºå¤§çš„å›å½’å¼æ¨¡å‹ZeroShapeï¼Œè¯¥æ¨¡å‹åŸºäºé¢†åŸŸå†…è¶‹åŒçš„ç ”ç©¶æˆæœå’Œä¸€ä¸ªæ–°é¢–çš„æ´å¯Ÿã€‚
- æ„å»ºäº†ä¸€ä¸ªå¤§å‹çš„çœŸå®ä¸–ç•Œè¯„ä¼°åŸºå‡†ï¼ŒåŒ…å«æ¥è‡ªä¸‰ä¸ªä¸åŒçœŸå®ä¸–ç•Œä¸‰ç»´æ•°æ®é›†çš„å¯¹è±¡ã€‚
- è¯¥è¯„ä¼°åŸºå‡†æ¯”å…ˆå‰å·¥ä½œç”¨äºå®šé‡è¯„ä¼°å…¶æ¨¡å‹çš„åŸºå‡†æ›´åŠ å¤šæ ·åŒ–ï¼Œå¹¶ä¸”æ•°é‡çº§æ›´å¤§ã€‚
- è¯æ˜äº†ZeroShapeä¸ä»…ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè€Œä¸”æ˜¾ç¤ºå‡ºæ›´é«˜çš„è®¡ç®—å’Œæ•°æ®æ•ˆç‡ã€‚
- å›å½’æ–¹æ³•æ•ˆç‡é«˜ã€å¯ç”¨äºå®æ—¶æ¸²æŸ“ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šZeroShapeï¼šåŸºäºå›å½’çš„é›¶æ ·æœ¬å½¢çŠ¶é‡å»º</li>
<li>ä½œè€…ï¼šZixuan Huangã€Stefan Stojanovã€Anh Thaiã€Varun Jampaniã€James M. Rehg</li>
<li>éš¶å±æœºæ„ï¼šä¼Šåˆ©è¯ºä¼Šå¤§å­¦å„å·´çº³-é¦™æ§Ÿåˆ†æ ¡</li>
<li>å…³é”®è¯ï¼šé›¶æ ·æœ¬å½¢çŠ¶é‡å»ºã€å›å½’ã€ç”Ÿæˆæ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.14198
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š<ul>
<li>é›¶æ ·æœ¬å½¢çŠ¶é‡å»ºæ—¨åœ¨ä»å•å¼ å›¾åƒä¸­é‡å»ºä»æœªè§è¿‡çš„ç‰©ä½“çš„ 3D å½¢çŠ¶ã€‚</li>
<li>æœ€è¿‘çš„å·¥ä½œé€šè¿‡ç”Ÿæˆæ‰©æ•£æ¨¡å‹æˆ–ç¥ç»è¾å°„åœº (NeRF) æ¥å­¦ä¹ é›¶æ ·æœ¬å½¢çŠ¶å…ˆéªŒï¼Œä½†è¿™äº›æ¨¡å‹åœ¨è®­ç»ƒå’Œæ¨ç†æ—¶è®¡ç®—æˆæœ¬éƒ½å¾ˆé«˜ã€‚</li>
<li>ä¼ ç»Ÿæ–¹æ³•æ˜¯åŸºäºå›å½’çš„ï¼Œç›´æ¥å›å½’ç‰©ä½“çš„å½¢çŠ¶ï¼Œè®¡ç®—æ•ˆç‡æ›´é«˜ã€‚</li>
</ul>
</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š</p>
<ul>
<li>ç°æœ‰æ–¹æ³•ä¸»è¦åŸºäºç”Ÿæˆæ¨¡å‹ï¼Œè®¡ç®—æˆæœ¬é«˜ï¼Œå¹¶ä¸”éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ã€‚</li>
<li>åŸºäºå›å½’çš„æ–¹æ³•è™½ç„¶è®¡ç®—æ•ˆç‡é«˜ï¼Œä½†æ€§èƒ½ä¸å¦‚ç”Ÿæˆæ¨¡å‹ã€‚</li>
</ul>
<p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºå›å½’çš„é›¶æ ·æœ¬å½¢çŠ¶é‡å»ºæ¨¡å‹ ZeroShapeã€‚</li>
<li>ZeroShape ç»“åˆäº†é¢†åŸŸå†…æœ€æ–°ç ”ç©¶æˆæœå’Œä¸€ä¸ªæ–°çš„æ´å¯Ÿï¼Œåœ¨æ€§èƒ½å’Œæ•ˆç‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªåŒ…å«æ¥è‡ªä¸‰ä¸ªä¸åŒçœŸå®ä¸–ç•Œ 3D æ•°æ®é›†çš„ç‰©ä½“çš„å¤§è§„æ¨¡çœŸå®ä¸–ç•Œè¯„ä¼°åŸºå‡†ã€‚</li>
<li>è¯¥åŸºå‡†æ¯”ä»¥å‰çš„å·¥ä½œç”¨äºå®šé‡è¯„ä¼°å…¶æ¨¡å‹çš„åŸºå‡†æ›´åŠ å¤šæ ·åŒ–ï¼Œå¹¶ä¸”æ•°é‡çº§æ›´å¤§ï¼Œæ—¨åœ¨å‡å°‘è¯¥é¢†åŸŸçš„è¯„ä¼°å·®å¼‚ã€‚</li>
</ul>
<p>ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½å’Œå¯¹ç›®æ ‡çš„æ”¯æŒï¼š</p>
<ul>
<li>ZeroShape åœ¨é›¶æ ·æœ¬ 3D å½¢çŠ¶é‡å»ºä»»åŠ¡ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒæ—¶å…·æœ‰æ›´å¿«çš„æ¨ç†æ—¶é—´å’Œæ›´å°‘çš„è®­ç»ƒæ•°æ®ã€‚</li>
<li>ZeroShape ä¸ä»…åœ¨æ€§èƒ½ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè€Œä¸”è¿˜å±•ç¤ºå‡ºæ˜¾ç€æ›´é«˜çš„è®¡ç®—æ•ˆç‡å’Œæ•°æ®æ•ˆç‡ã€‚</li>
</ul>
<ol start="7">
<li>æ–¹æ³•ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰æ·±åº¦å’Œç›¸æœºä¼°è®¡å™¨ï¼šä½¿ç”¨ DPTResNet CNN æ¥ä¼°è®¡å›¾åƒçš„æ·±åº¦å›¾å’Œç›¸æœºå†…å‚ã€‚</p>
<p>ï¼ˆ2ï¼‰å‡ ä½•åæŠ•å½±å•å…ƒï¼šå°†æ·±åº¦å›¾å’Œå†…å‚ä¼°è®¡å€¼åæŠ•å½±åˆ°å½’ä¸€åŒ–çš„ 3D å¯è§è¡¨é¢ï¼Œè¯¥è¡¨é¢ç”±ä¸‰é€šé“æŠ•å½±å›¾å‚æ•°åŒ–ã€‚</p>
<p>ï¼ˆ3ï¼‰æŠ•å½±å¼•å¯¼çš„å½¢çŠ¶é‡å»ºå™¨ï¼šä½¿ç”¨ ResNet ç¼–ç å™¨å¯¹æŠ•å½±å›¾è¿›è¡Œç¼–ç å’Œé‡å¡‘ï¼Œç„¶åä½¿ç”¨åŸºäºäº¤å‰æ³¨æ„åŠ›çš„æ–¹æ³•ä»æŠ•å½±å›¾ä¸­æå–ç›¸å…³è¡¥ä¸ç¼–ç ï¼Œå¹¶ä½¿ç”¨ MLP é¢„æµ‹æ¯ä¸ªæŸ¥è¯¢ç‚¹çš„å ç”¨å€¼ã€‚</p>
<p>ï¼ˆ4ï¼‰æŸå¤±å‡½æ•°ï¼šä½¿ç”¨ä¸¤é˜¶æ®µè®­ç»ƒèŒƒå¼ï¼Œé¦–å…ˆé¢„è®­ç»ƒæ·±åº¦å’Œç›¸æœºä¼°è®¡å™¨ï¼Œç„¶åä½¿ç”¨ 3D ç›‘ç£å¾®è°ƒæ•´ä¸ªæ¨¡å‹ã€‚æ·±åº¦å’Œç›¸æœºé¢„è®­ç»ƒä½¿ç”¨æ·±åº¦æŸå¤±å’ŒåŸºäºæŠ•å½±çš„å†…å‚æŸå¤±ã€‚æ•´ä¸ªæ¨¡å‹çš„è”åˆè®­ç»ƒä½¿ç”¨ 3D å ç”¨æŸå¤±ï¼Œè¿™æ˜¯é¢„æµ‹å ç”¨å€¼å’Œä»¥è§‚å¯Ÿè€…ä¸ºä¸­å¿ƒçš„åæ ‡ç³»ä¸­çš„åœ°é¢å®å†µä¹‹é—´çš„æ ‡å‡†äºŒå…ƒäº¤å‰ç†µã€‚</p>
<p>ï¼ˆ5ï¼‰å®ç°ç»†èŠ‚ï¼šä½¿ç”¨ Adam ä¼˜åŒ–å™¨è®­ç»ƒæ¨¡å‹ã€‚åœ¨æ·±åº¦å’Œç›¸æœºé¢„è®­ç»ƒæœŸé—´ï¼Œä½¿ç”¨å­¦ä¹ ç‡ 3Ã—10âˆ’5ã€æ‰¹å¤§å° 44ã€æƒé‡è¡°å‡ 0.05 å’ŒåŠ¨é‡å‚æ•° (0.9, 0.95)ã€‚è®­ç»ƒæ¨¡å‹ 15 ä¸ª epochï¼Œå¹¶ä½¿ç”¨ Omnidata æƒé‡åˆå§‹åŒ–æ·±åº¦ä¼°è®¡å™¨ã€‚åœ¨è”åˆè®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨å­¦ä¹ ç‡ 3Ã—10âˆ’5 ç”¨äºæŠ•å½±å¼•å¯¼çš„å½¢çŠ¶é‡å»ºå™¨ï¼Œå¹¶ä½¿ç”¨å­¦ä¹ ç‡ 10âˆ’5 ç”¨äºé¢„è®­ç»ƒçš„æ·±åº¦å’Œç›¸æœºä¼°è®¡å™¨ï¼ˆå‡ ä½•åæŠ•å½±å•å…ƒæ²¡æœ‰å¯å­¦ä¹ å‚æ•°ï¼‰ã€‚ä½¿ç”¨æ‰¹å¤§å° 28ã€æƒé‡è¡°å‡ 0.05 å’ŒåŠ¨é‡å‚æ•° (0.9, 0.95)ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼ŒéšæœºæŠ½å– 4096 ä¸ªç‚¹æ¥è®¡ç®—å ç”¨æŸå¤±ã€‚åœ¨ 4Ã—NVIDIA GeForce RTX 2080Ti ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œé¢„è®­ç»ƒéœ€è¦å¤§çº¦ 2 å¤©ï¼Œè”åˆè®­ç»ƒéœ€è¦å¤§çº¦ 3 å¤©ã€‚</p>
<p>ï¼ˆ6ï¼‰æ•°æ®æ•´ç†ï¼šä½¿ç”¨æ¥è‡ªä¸‰ä¸ªä¸åŒçœŸå®ä¸–ç•Œ 3D æ•°æ®é›†çš„ç‰©ä½“çš„å¤§è§„æ¨¡çœŸå®ä¸–ç•Œè¯„ä¼°åŸºå‡†ã€‚è¯¥åŸºå‡†æ¯”ä»¥å‰çš„å·¥ä½œç”¨äºå®šé‡è¯„ä¼°å…¶æ¨¡å‹çš„åŸºå‡†æ›´åŠ å¤šæ ·åŒ–ï¼Œå¹¶ä¸”æ•°é‡çº§æ›´å¤§ï¼Œæ—¨åœ¨å‡å°‘è¯¥é¢†åŸŸçš„è¯„ä¼°å·®å¼‚ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå›å½’çš„é›¶æ ·æœ¬å½¢çŠ¶é‡å»ºæ¨¡å‹ ZeroShapeï¼Œè¯¥æ¨¡å‹åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä¸­é—´è¡¨ç¤ºå½¢å¼ï¼Œè¯¥è¡¨ç¤ºå½¢å¼å¯ä»¥æœ‰æ•ˆåœ°è¿›è¡Œæ˜¾å¼ 3D å‡ ä½•æ¨ç†ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªåŒ…å«æ¥è‡ªä¸‰ä¸ªä¸åŒçœŸå®ä¸–ç•Œ 3D æ•°æ®é›†çš„ç‰©ä½“çš„å¤§è§„æ¨¡çœŸå®ä¸–ç•Œè¯„ä¼°åŸºå‡†ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨é›¶æ ·æœ¬ 3D å½¢çŠ¶é‡å»ºä»»åŠ¡ä¸Šï¼ŒZeroShape ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒæ—¶å…·æœ‰æ›´å¿«çš„æ¨ç†æ—¶é—´å’Œæ›´å°‘çš„è®­ç»ƒæ•°æ®ã€‚</li>
<li>ZeroShape ä¸ä»…åœ¨æ€§èƒ½ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè€Œä¸”è¿˜å±•ç¤ºå‡ºæ˜¾ç€æ›´é«˜çš„è®¡ç®—æ•ˆç‡å’Œæ•°æ®æ•ˆç‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ä½¿ç”¨ Adam ä¼˜åŒ–å™¨è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>åœ¨æ·±åº¦å’Œç›¸æœºé¢„è®­ç»ƒæœŸé—´ï¼Œä½¿ç”¨å­¦ä¹ ç‡ 3Ã—10âˆ’5ã€æ‰¹å¤§å° 44ã€æƒé‡è¡°å‡ 0.05 å’ŒåŠ¨é‡å‚æ•° (0.9, 0.95)ã€‚è®­ç»ƒæ¨¡å‹ 15 ä¸ª epochï¼Œå¹¶ä½¿ç”¨ Omnidata æƒé‡åˆå§‹åŒ–æ·±åº¦ä¼°è®¡å™¨ã€‚</li>
<li>åœ¨è”åˆè®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨å­¦ä¹ ç‡ 3Ã—10âˆ’5 ç”¨äºæŠ•å½±å¼•å¯¼çš„å½¢çŠ¶é‡å»ºå™¨ï¼Œå¹¶ä½¿ç”¨å­¦ä¹ ç‡ 10âˆ’5 ç”¨äºé¢„è®­ç»ƒçš„æ·±åº¦å’Œç›¸æœºä¼°è®¡å™¨ï¼ˆå‡ ä½•åæŠ•å½±å•å…ƒæ²¡æœ‰å¯å­¦ä¹ å‚æ•°ï¼‰ã€‚ä½¿ç”¨æ‰¹å¤§å° 28ã€æƒé‡è¡°å‡ 0.05 å’ŒåŠ¨é‡å‚æ•° (0.9, 0.95)ã€‚åœ¨æ¯æ¬¡è¿­ä»£ä¸­ï¼ŒéšæœºæŠ½å– 4096 ä¸ªç‚¹æ¥è®¡ç®—å ç”¨æŸå¤±ã€‚</li>
<li>åœ¨ 4Ã—NVIDIA GeForce RTX 2080Ti ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œé¢„è®­ç»ƒéœ€è¦å¤§çº¦ 2 å¤©ï¼Œè”åˆè®­ç»ƒéœ€è¦å¤§çº¦ 3 å¤©ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0df67089f0cd470421435e6ad26a625d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19cd67e1a52d95f7d665d88a7ee51292.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-504faa61d0f546e94a3b52452ac7c3e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fd545832e863d3187e6888c47dbab37d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-028a47ff3a5de37fe1ed865255a3e193.jpg" align="middle">
</details>
â€‹    


## NeuSurf: On-Surface Priors for Neural Surface Reconstruction from Sparse   Input Views
**Authors:Han Huang, Yulun Wu, Junsheng Zhou, Ge Gao, Ming Gu, Yu-Shen Liu**

Recently, neural implicit functions have demonstrated remarkable results in the field of multi-view reconstruction. However, most existing methods are tailored for dense views and exhibit unsatisfactory performance when dealing with sparse views. Several latest methods have been proposed for generalizing implicit reconstruction to address the sparse view reconstruction task, but they still suffer from high training costs and are merely valid under carefully selected perspectives. In this paper, we propose a novel sparse view reconstruction framework that leverages on-surface priors to achieve highly faithful surface reconstruction. Specifically, we design several constraints on global geometry alignment and local geometry refinement for jointly optimizing coarse shapes and fine details. To achieve this, we train a neural network to learn a global implicit field from the on-surface points obtained from SfM and then leverage it as a coarse geometric constraint. To exploit local geometric consistency, we project on-surface points onto seen and unseen views, treating the consistent loss of projected features as a fine geometric constraint. The experimental results with DTU and BlendedMVS datasets in two prevalent sparse settings demonstrate significant improvements over the state-of-the-art methods. 

[PDF](http://arxiv.org/abs/2312.13977v2) Accepted by AAAI 2024. Project page:   https://alvin528.github.io/NeuSurf/

**æ‘˜è¦**
åˆ©ç”¨è¡¨é¢å…ˆéªŒé‡å»ºæ¡†æ¶å¢å¼ºæ·±åº¦ç¥ç»ç½‘ç»œéšå‡½æ•°ï¼Œæé«˜ç¨€ç–è§†è§’ä¸‹çš„ä¸‰ç»´é‡å»ºç²¾åº¦ã€‚

**è¦ç‚¹**

- ç¥ç»éšå¼å‡½æ•°åœ¨å¤šè§†è§’é‡å»ºé¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆæœï¼Œä½†ç°æœ‰æ–¹æ³•å¤šé’ˆå¯¹ç¨ å¯†è§†è§’ï¼Œç¨€ç–è§†è§’ä¸‹è¡¨ç°ä¸ä½³ã€‚
- è¿‘æœŸæå‡ºçš„å‡ ç§å¹¿ä¹‰éšå¼é‡å»ºæ–¹æ³•è™½ç„¶é€‚ç”¨äºç¨€ç–è§†å›¾é‡å»ºä»»åŠ¡ï¼Œä½†è®­ç»ƒæˆæœ¬é«˜ï¼Œä¸”ä»…åœ¨ç²¾å¿ƒæŒ‘é€‰çš„è§†è§’ä¸‹æœ‰æ•ˆã€‚
- æœ¬æ–‡æå‡ºä¸€ç§åˆ©ç”¨è¡¨é¢å…ˆéªŒï¼Œç”¨äºå®ç°é«˜ä¿çœŸæ›²é¢é‡å»ºçš„ç¨€ç–è§†å›¾é‡å»ºæ¡†æ¶ã€‚
- é€šè¿‡è®¾è®¡å…¨å±€å‡ ä½•å¯¹é½å’Œå±€éƒ¨å‡ ä½•ç»†åŒ–çš„çº¦æŸï¼Œè”åˆä¼˜åŒ–ç²—ç•¥å½¢çŠ¶å’Œç²¾ç»†ç»†èŠ‚ã€‚
- è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œæ ¹æ®ä» SfM è·å¾—çš„è¡¨é¢ç‚¹å­¦ä¹ ä¸€ä¸ªå…¨å±€éšå¼åœºï¼Œå°†å…¶ç”¨ä½œç²—ç•¥å‡ ä½•çº¦æŸã€‚
- åˆ©ç”¨å±€éƒ¨å‡ ä½•ä¸€è‡´æ€§ï¼Œå°†è¡¨é¢ç‚¹æŠ•å½±åˆ°å·²è§å’Œæœªè§è§†å›¾ï¼Œå°†æŠ•å½±ç‰¹å¾çš„ä¸€è‡´æ€§æŸå¤±ä½œä¸ºç²¾ç»†å‡ ä½•çº¦æŸã€‚
- åœ¨ DTU å’Œ BlendedMVS æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–¹æ³•åœ¨ä¸¤ç§æ™®éçš„ç¨€ç–è®¾ç½®ä¸‹å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šNeuSurfï¼šåŸºäºè¡¨é¢å…ˆéªŒçš„ç¥ç»è¡¨é¢é‡å»ºæ¡†æ¶ï¼ˆä»ç¨€ç–è¾“å…¥ä¸­ï¼‰</li>
<li>ä½œè€…ï¼šYuxuan Zhang, Yuxin Wen, Yufeng Zheng, Changjian Li, Yanwei Fu, Qiong Yan, Yebin Liu, Lu Fang, Shihui Lai</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåä¸­ç§‘æŠ€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»éšå¼å‡½æ•°ã€ç¨€ç–è§†å›¾é‡å»ºã€è¡¨é¢å…ˆéªŒã€å‡ ä½•å¯¹é½ã€å±€éƒ¨å‡ ä½•ç²¾ç»†åŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2203.12461ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»éšå¼å‡½æ•°åœ¨å¤šè§†å›¾é‡å»ºé¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆæœï¼Œä½†ç°æœ‰æ–¹æ³•å¤§å¤šé’ˆå¯¹ç¨ å¯†è§†å›¾ï¼Œåœ¨å¤„ç†ç¨€ç–è§†å›¾æ—¶è¡¨ç°ä¸ä½³ã€‚ä¸€äº›æœ€æ–°æ–¹æ³•è¯•å›¾å°†éšå¼é‡å»ºæ¨å¹¿åˆ°ç¨€ç–è§†å›¾é‡å»ºä»»åŠ¡ï¼Œä½†ä»ç„¶å­˜åœ¨è®­ç»ƒæˆæœ¬é«˜ã€ä»…åœ¨ä»”ç»†é€‰æ‹©çš„è§†è§’ä¸‹æœ‰æ•ˆç­‰é—®é¢˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¨€ç–è§†å›¾æ—¶å­˜åœ¨è®­ç»ƒæˆæœ¬é«˜ã€ä»…åœ¨ä»”ç»†é€‰æ‹©çš„è§†è§’ä¸‹æœ‰æ•ˆç­‰é—®é¢˜ã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºä¸€ç§åˆ©ç”¨è¡¨é¢å…ˆéªŒçš„æ–°å‹ç¨€ç–è§†å›¾é‡å»ºæ¡†æ¶ï¼Œä»¥å®ç°é«˜åº¦é€¼çœŸçš„è¡¨é¢é‡å»ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è®¾è®¡äº†å…³äºå…¨å±€å‡ ä½•å¯¹é½å’Œå±€éƒ¨å‡ ä½•ç²¾ç»†åŒ–çš„çº¦æŸï¼Œç”¨äºè”åˆä¼˜åŒ–ç²—ç•¥å½¢çŠ¶å’Œç²¾ç»†ç»†èŠ‚ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œä» SfM è·å¾—çš„è¡¨é¢ç‚¹å­¦ä¹ ä¸€ä¸ªå…¨å±€éšå¼åœºï¼Œç„¶åå°†å…¶ä½œä¸ºç²—ç•¥å‡ ä½•çº¦æŸã€‚ä¸ºäº†åˆ©ç”¨å±€éƒ¨å‡ ä½•ä¸€è‡´æ€§ï¼Œæˆ‘ä»¬å°†è¡¨é¢ç‚¹æŠ•å½±åˆ°å¯è§å’Œä¸å¯è§è§†å›¾ï¼Œå°†æŠ•å½±ç‰¹å¾çš„ä¸€è‡´æ€§æŸå¤±ä½œä¸ºç²¾ç»†å‡ ä½•çº¦æŸã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨ DTU å’Œ Blended MVS æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸¤ç§æ™®éçš„ç¨€ç–è®¾ç½®ä¸‹ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†è®ºæ–‡æå‡ºçš„ç›®æ ‡ã€‚</li>
</ol>
<p>7.Methodsï¼š
(1) æå‡ºä¸€ç§æ–°çš„ç¨€ç–è§†å›¾é‡å»ºæ¡†æ¶ï¼Œåˆ©ç”¨è¡¨é¢å…ˆéªŒå®ç°é«˜åº¦é€¼çœŸçš„è¡¨é¢é‡å»ºã€‚
(2) è®¾è®¡å…³äºå…¨å±€å‡ ä½•å¯¹é½å’Œå±€éƒ¨å‡ ä½•ç²¾ç»†åŒ–çš„çº¦æŸï¼Œç”¨äºè”åˆä¼˜åŒ–ç²—ç•¥å½¢çŠ¶å’Œç²¾ç»†ç»†èŠ‚ã€‚
(3) è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œä»SfMè·å¾—çš„è¡¨é¢ç‚¹å­¦ä¹ ä¸€ä¸ªå…¨å±€éšå¼åœºï¼Œä½œä¸ºç²—ç•¥å‡ ä½•çº¦æŸã€‚
(4) å°†è¡¨é¢ç‚¹æŠ•å½±åˆ°å¯è§å’Œä¸å¯è§è§†å›¾ï¼Œå°†æŠ•å½±ç‰¹å¾çš„ä¸€è‡´æ€§æŸå¤±ä½œä¸ºç²¾ç»†å‡ ä½•çº¦æŸã€‚
(5) åœ¨DTUå’ŒBlendedMVSæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¡¨é¢å…ˆéªŒçš„ç¥ç»è¡¨é¢é‡å»ºæ¡†æ¶ NeuSurfï¼Œè¯¥æ¡†æ¶åˆ©ç”¨è¡¨é¢ç‚¹å­¦ä¹ å…¨å±€éšå¼åœºä½œä¸ºç²—ç•¥å‡ ä½•çº¦æŸï¼Œå¹¶å°†è¡¨é¢ç‚¹æŠ•å½±åˆ°å¯è§å’Œä¸å¯è§è§†å›¾ï¼Œå°†æŠ•å½±ç‰¹å¾çš„ä¸€è‡´æ€§æŸå¤±ä½œä¸ºç²¾ç»†å‡ ä½•çº¦æŸï¼Œä»è€Œå®ç°é«˜åº¦é€¼çœŸçš„è¡¨é¢é‡å»ºã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç¨€ç–è§†å›¾é‡å»ºæ¡†æ¶ï¼Œåˆ©ç”¨è¡¨é¢å…ˆéªŒå®ç°é«˜åº¦é€¼çœŸçš„è¡¨é¢é‡å»ºã€‚</li>
<li>è®¾è®¡å…³äºå…¨å±€å‡ ä½•å¯¹é½å’Œå±€éƒ¨å‡ ä½•ç²¾ç»†åŒ–çš„çº¦æŸï¼Œç”¨äºè”åˆä¼˜åŒ–ç²—ç•¥å½¢çŠ¶å’Œç²¾ç»†ç»†èŠ‚ã€‚</li>
<li>è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œä» SfM è·å¾—çš„è¡¨é¢ç‚¹å­¦ä¹ ä¸€ä¸ªå…¨å±€éšå¼åœºï¼Œä½œä¸ºç²—ç•¥å‡ ä½•çº¦æŸã€‚</li>
<li>å°†è¡¨é¢ç‚¹æŠ•å½±åˆ°å¯è§å’Œä¸å¯è§è§†å›¾ï¼Œå°†æŠ•å½±ç‰¹å¾çš„ä¸€è‡´æ€§æŸå¤±ä½œä¸ºç²¾ç»†å‡ ä½•çº¦æŸã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ DTU å’Œ BlendedMVS æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>è¿™äº›æ€§èƒ½æ”¯æŒäº†è®ºæ–‡æå‡ºçš„ç›®æ ‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•ä¸éœ€è¦å¤§è§„æ¨¡è®­ç»ƒï¼Œå¹¶ä¸”åœ¨å„ç§ç¨€ç–è®¾ç½®ä¸­éƒ½å¾ˆç¨³å¥ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3f6644db90f1dd4f7ca9dcf04e307b68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f0eb8b77b117c4be4c26d0982f919c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f11cf5878ea37a4b5efbd6c59f20a5d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3dee8633ed2740393067a67de3d6ef00.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0c8ebc6b78ec57ce3e5e1234d62b7690.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-302eebe295f00eabc65233dc28a98374.jpg" align="middle">
</details>
â€‹    


## LASA: Instance Reconstruction from Real Scans using A Large-scale   Aligned Shape Annotation Dataset
**Authors:Haolin Liu, Chongjie Ye, Yinyu Nie, Yingfan He, Xiaoguang Han**

Instance shape reconstruction from a 3D scene involves recovering the full geometries of multiple objects at the semantic instance level. Many methods leverage data-driven learning due to the intricacies of scene complexity and significant indoor occlusions. Training these methods often requires a large-scale, high-quality dataset with aligned and paired shape annotations with real-world scans. Existing datasets are either synthetic or misaligned, restricting the performance of data-driven methods on real data. To this end, we introduce LASA, a Large-scale Aligned Shape Annotation Dataset comprising 10,412 high-quality CAD annotations aligned with 920 real-world scene scans from ArkitScenes, created manually by professional artists. On this top, we propose a novel Diffusion-based Cross-Modal Shape Reconstruction (DisCo) method. It is empowered by a hybrid feature aggregation design to fuse multi-modal inputs and recover high-fidelity object geometries. Besides, we present an Occupancy-Guided 3D Object Detection (OccGOD) method and demonstrate that our shape annotations provide scene occupancy clues that can further improve 3D object detection. Supported by LASA, extensive experiments show that our methods achieve state-of-the-art performance in both instance-level scene reconstruction and 3D object detection tasks. 

[PDF](http://arxiv.org/abs/2312.12418v1) homepage: https://gap-lab-cuhk-sz.github.io/LASA/

**Summary**
å®ä¾‹å½¢çŠ¶é‡å»ºä» 3D åœºæ™¯ä¸­æ¢å¤å¤šä¸ªå¯¹è±¡çš„å®Œæ•´å‡ ä½•å½¢çŠ¶ï¼Œäºè¯­ä¹‰å®ä¾‹çº§åˆ«ã€‚

**Key Takeaways**
- LASA åŒ…å« 10412 ä¸ªé«˜è´¨é‡ CAD æ³¨é‡Šï¼Œä¸ 920 ä¸ªæ¥è‡ª ArkitScenes çš„çœŸå®åœºæ™¯æ‰«æå¯¹é½ï¼Œç”±ä¸“ä¸šè‰ºæœ¯å®¶æ‰‹åŠ¨åˆ›å»ºã€‚
- æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£çš„è·¨æ¨¡æ€å½¢çŠ¶é‡å»ºæ–¹æ³• (DisCo)ã€‚
- DisCo ä½¿ç”¨æ··åˆç‰¹å¾èšåˆè®¾è®¡æ¥èåˆå¤šæ¨¡æ€è¾“å…¥å¹¶æ¢å¤é«˜ä¿çœŸåº¦å¯¹è±¡å‡ ä½•ä½“ã€‚
- æå‡ºäº†ä¸€ç§å æœ‰å¼•å¯¼çš„ 3D å¯¹è±¡æ£€æµ‹æ–¹æ³• (OccGOD)ã€‚
- å½¢çŠ¶æ³¨é‡Šæä¾›äº†åœºæ™¯å ç”¨çº¿ç´¢ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ”¹è¿› 3D å¯¹è±¡æ£€æµ‹ã€‚
- å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒDisCo å’Œ OccGOD åœ¨å®ä¾‹çº§åœºæ™¯é‡å»ºå’Œ 3D å¯¹è±¡æ£€æµ‹ä»»åŠ¡ä¸­å‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
- DisCo åœ¨ LASA ä¸Šè®­ç»ƒï¼Œåœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹³å‡æ”¹è¿›å¹…åº¦ä¸º 13.2%ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šLASAï¼šåˆ©ç”¨å¤§è§„æ¨¡å¯¹é½å½¢çŠ¶æ³¨é‡Šæ•°æ®é›†ä»çœŸå®æ‰«æä¸­è¿›è¡Œå®ä¾‹é‡å»º</li>
<li>ä½œè€…ï¼šHaolin Liu, Chongjie Ye, Yinyu Nie, Yingfan He, Xiaoguang Han</li>
<li>éš¶å±å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li>
<li>å…³é”®è¯ï¼šå®ä¾‹å½¢çŠ¶é‡å»ºã€3Dç‰©ä½“æ£€æµ‹ã€å¤§è§„æ¨¡æ•°æ®é›†ã€å¯¹é½å½¢çŠ¶æ³¨é‡Š</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.12418
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šä» 3D åœºæ™¯ä¸­è¿›è¡Œå®ä¾‹å½¢çŠ¶é‡å»ºæ¶‰åŠæ¢å¤å¤šä¸ªå¯¹è±¡çš„å®Œæ•´å‡ ä½•å½¢çŠ¶ï¼Œè¿™äº›å¯¹è±¡å¤„äºè¯­ä¹‰å®ä¾‹çº§åˆ«ã€‚ç”±äºåœºæ™¯å¤æ‚æ€§å’Œæ˜æ˜¾çš„å®¤å†…é®æŒ¡ï¼Œè®¸å¤šæ–¹æ³•åˆ©ç”¨æ•°æ®é©±åŠ¨çš„å­¦ä¹ ã€‚è®­ç»ƒè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ä¸çœŸå®ä¸–ç•Œæ‰«æå¯¹é½ä¸”é…å¯¹çš„å½¢çŠ¶æ³¨é‡Šã€‚ç°æœ‰æ•°æ®é›†è¦ä¹ˆæ˜¯åˆæˆçš„ï¼Œè¦ä¹ˆæ˜¯æœªå¯¹é½çš„ï¼Œè¿™é™åˆ¶äº†æ•°æ®é©±åŠ¨æ–¹æ³•åœ¨çœŸå®æ•°æ®ä¸Šçš„æ€§èƒ½ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç›®å‰çš„æ–¹æ³•æ˜¯åˆ©ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•æ¥è§£å†³å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºä»»åŠ¡ã€‚è¿™äº›æ–¹æ³•å–å¾—äº†å¾ˆå¤§çš„è¿›å±•ï¼Œä½†å®ƒä»¬ä¹Ÿå­˜åœ¨ä¸€äº›é—®é¢˜ã€‚é¦–å…ˆï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒï¼Œè¿™åœ¨ç°å®ä¸–ç•Œä¸­å¾ˆéš¾è·å¾—ã€‚å…¶æ¬¡ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å¯¹å™ªå£°å’Œä¸å®Œæ•´çš„æ•°æ®éå¸¸æ•æ„Ÿï¼Œè¿™åœ¨çœŸå®ä¸–ç•Œæ‰«æä¸­å¾ˆå¸¸è§ã€‚æœ€åï¼Œè¿™äº›æ–¹æ³•é€šå¸¸åªèƒ½é‡å»ºæœ‰é™æ•°é‡çš„ç‰©ä½“ç±»åˆ«ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„é€‚ç”¨æ€§ã€‚
(3)ï¼šè®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç§°ä¸º LASAï¼ˆLarge-scale Aligned Shape Annotation Datasetï¼‰ã€‚LASA æ˜¯ä¸€ä¸ªåŒ…å« 10,412 ä¸ªé«˜è´¨é‡ CAD æ³¨é‡Šçš„å¤§è§„æ¨¡å¯¹é½å½¢çŠ¶æ³¨é‡Šæ•°æ®é›†ï¼Œè¿™äº›æ³¨é‡Šä¸æ¥è‡ª ArkitScenes çš„ 920 ä¸ªçœŸå®ä¸–ç•Œåœºæ™¯æ‰«æå¯¹é½ã€‚LASA æ˜¯ç”±ä¸“ä¸šè‰ºæœ¯å®¶æ‰‹åŠ¨åˆ›å»ºçš„ï¼Œå®ƒæä¾›äº†é«˜è´¨é‡çš„å½¢çŠ¶æ³¨é‡Šï¼Œå¯ä»¥ç”¨äºè®­ç»ƒå’Œè¯„ä¼°å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºæ–¹æ³•ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°åŠæ€§èƒ½ï¼šåœ¨å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºä»»åŠ¡ä¸Šï¼ŒLASA å¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨ 3D ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸Šï¼ŒLASA ä¹Ÿå¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒLASA å¯¹äºè®­ç»ƒå’Œè¯„ä¼°å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºæ–¹æ³•éå¸¸æœ‰ä»·å€¼ã€‚</li>
</ol>
<p>&lt;Methods&gt;:
(1): è¯¥æ–‡æå‡ºäº†ä¸€ç§åä¸ºLASAçš„å¤§è§„æ¨¡å¯¹é½å½¢çŠ¶æ³¨é‡Šæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«10,412ä¸ªé«˜è´¨é‡CADæ³¨é‡Šï¼Œè¿™äº›æ³¨é‡Šä¸æ¥è‡ªArkitScenesçš„920ä¸ªçœŸå®ä¸–ç•Œåœºæ™¯æ‰«æå¯¹é½ã€‚
(2): LASAæ˜¯ç”±ä¸“ä¸šè‰ºæœ¯å®¶æ‰‹åŠ¨åˆ›å»ºçš„ï¼Œå®ƒæä¾›äº†é«˜è´¨é‡çš„å½¢çŠ¶æ³¨é‡Šï¼Œå¯ä»¥ç”¨äºè®­ç»ƒå’Œè¯„ä¼°å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºæ–¹æ³•ã€‚
(3): åœ¨å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºä»»åŠ¡ä¸Šï¼ŒLASAå¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨3Dç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸Šï¼ŒLASAä¹Ÿå¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<ol start="8">
<li>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šè¯¥æ–‡æå‡ºäº†ä¸€ä¸ªåä¸º LASA çš„å¤§è§„æ¨¡å¯¹é½å½¢çŠ¶æ³¨é‡Šæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å« 10,412 ä¸ªé«˜è´¨é‡ CAD æ³¨é‡Šï¼Œè¿™äº›æ³¨é‡Šä¸æ¥è‡ª ArkitScenes çš„ 920 ä¸ªçœŸå®ä¸–ç•Œåœºæ™¯æ‰«æå¯¹é½ã€‚LASA ç”±ä¸“ä¸šè‰ºæœ¯å®¶æ‰‹åŠ¨åˆ›å»ºï¼Œå®ƒæä¾›äº†é«˜è´¨é‡çš„å½¢çŠ¶æ³¨é‡Šï¼Œå¯ä»¥ç”¨äºè®­ç»ƒå’Œè¯„ä¼°å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºæ–¹æ³•ã€‚åœ¨å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºä»»åŠ¡ä¸Šï¼ŒLASA å¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨ 3D ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸Šï¼ŒLASA ä¹Ÿå¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
è¯¥æ–‡æå‡ºäº†ä¸€ä¸ªåä¸º LASA çš„å¤§è§„æ¨¡å¯¹é½å½¢çŠ¶æ³¨é‡Šæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å« 10,412 ä¸ªé«˜è´¨é‡ CAD æ³¨é‡Šï¼Œè¿™äº›æ³¨é‡Šä¸æ¥è‡ª ArkitScenes çš„ 920 ä¸ªçœŸå®ä¸–ç•Œåœºæ™¯æ‰«æå¯¹é½ã€‚LASA ç”±ä¸“ä¸šè‰ºæœ¯å®¶æ‰‹åŠ¨åˆ›å»ºï¼Œå®ƒæä¾›äº†é«˜è´¨é‡çš„å½¢çŠ¶æ³¨é‡Šï¼Œå¯ä»¥ç”¨äºè®­ç»ƒå’Œè¯„ä¼°å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºæ–¹æ³•ã€‚åœ¨å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºä»»åŠ¡ä¸Šï¼ŒLASA å¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨ 3D ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸Šï¼ŒLASA ä¹Ÿå¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š
åœ¨å®ä¾‹çº§åˆ«åœºæ™¯é‡å»ºä»»åŠ¡ä¸Šï¼ŒLASA å¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨ 3D ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¸Šï¼ŒLASA ä¹Ÿå¯ä»¥æ”¯æŒæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–‡çš„å·¥ä½œé‡å¾ˆå¤§ï¼Œéœ€è¦æ”¶é›†å’Œæ³¨é‡Šå¤§é‡çš„æ•°æ®ã€‚æ­¤å¤–ï¼Œè¯¥æ–‡è¿˜æå‡ºäº†ä¸¤ç§æ–°çš„æ–¹æ³•ï¼ŒDiffusion-based Cross-Modal Shape Reconstruction å’Œ Occupancy-guided 3D Object Detectionï¼Œè¿™ä¸¤ç§æ–¹æ³•çš„å®ç°ä¹Ÿéœ€è¦å¤§é‡çš„å·¥ä½œé‡ã€‚</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-cda9d91453de63d77467b3bed34c6d49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2b47fbe622e984a9f8410e202812867.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aafa1603b087a09b6d9a0e1ba939e3c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b5f74bcf20d71e60eae001a07761608.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-594a80e24dc501900a0ba0cb9417b9b7.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="SEEAvatar-Photorealistic-Text-to-3D-Avatar-Generation-with-Constrained-Geometry-and-Appearance"><a href="#SEEAvatar-Photorealistic-Text-to-3D-Avatar-Generation-with-Constrained-Geometry-and-Appearance" class="headerlink" title="SEEAvatar: Photorealistic Text-to-3D Avatar Generation with Constrained   Geometry and Appearance"></a>SEEAvatar: Photorealistic Text-to-3D Avatar Generation with Constrained   Geometry and Appearance</h2><p><strong>Authors:Yuanyou Xu, Zongxin Yang, Yi Yang</strong></p>
<p>Powered by large-scale text-to-image generation models, text-to-3D avatar generation has made promising progress. However, most methods fail to produce photorealistic results, limited by imprecise geometry and low-quality appearance. Towards more practical avatar generation, we present SEEAvatar, a method for generating photorealistic 3D avatars from text with SElf-Evolving constraints for decoupled geometry and appearance. For geometry, we propose to constrain the optimized avatar in a decent global shape with a template avatar. The template avatar is initialized with human prior and can be updated by the optimized avatar periodically as an evolving template, which enables more flexible shape generation. Besides, the geometry is also constrained by the static human prior in local parts like face and hands to maintain the delicate structures. For appearance generation, we use diffusion model enhanced by prompt engineering to guide a physically based rendering pipeline to generate realistic textures. The lightness constraint is applied on the albedo texture to suppress incorrect lighting effect. Experiments show that our method outperforms previous methods on both global and local geometry and appearance quality by a large margin. Since our method can produce high-quality meshes and textures, such assets can be directly applied in classic graphics pipeline for realistic rendering under any lighting condition. Project page at: <a href="https://yoxu515.github.io/SEEAvatar/">https://yoxu515.github.io/SEEAvatar/</a>. </p>
<p><a href="http://arxiv.org/abs/2312.08889v2">PDF</a> </p>
<p><strong>Summary</strong><br>ä½¿ç”¨å…·æœ‰è‡ªè¿›åŒ–çº¦æŸæ¡ä»¶çš„æ–‡æœ¬åˆ° 3D å¤´åƒç”Ÿæˆæ–¹æ³•ï¼Œå¯ç”Ÿæˆå…·æœ‰ç…§ç‰‡çº§çœŸå®æ„Ÿã€å½¢çŠ¶å’Œå¤–è§‚è§£è€¦çš„ 3D å¤´åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œæ–‡æœ¬åˆ° 3D å¤´åƒç”Ÿæˆå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</li>
<li>ç°æœ‰æ–¹æ³•ç”±äºå‡ ä½•å½¢çŠ¶ä¸å‡†ç¡®å’Œå¤–è§‚è´¨é‡ä½ï¼Œæ— æ³•ç”Ÿæˆå…·æœ‰ç…§ç‰‡çº§çœŸå®æ„Ÿçš„ç»“æœã€‚</li>
<li>SEEAvatar æå‡ºäº†ä¸€ç§ä½¿ç”¨æ–‡æœ¬ç”Ÿæˆå…·æœ‰ç…§ç‰‡çº§çœŸå®æ„Ÿ 3D å¤´åƒçš„æ–¹æ³•ï¼Œå…·æœ‰ç”¨äºåˆ†ç¦»å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚çš„è‡ªè¿›åŒ–çº¦æŸæ¡ä»¶ã€‚</li>
<li>ä¸ºäº†ç”Ÿæˆå‡ ä½•å½¢çŠ¶ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨æ¨¡æ¿å¤´åƒæ¥çº¦æŸä¼˜åŒ–åçš„å¤´åƒä»¥è·å¾—åˆç†çš„å¤–è§‚å½¢çŠ¶ã€‚</li>
<li>æ¨¡æ¿å¤´åƒä½¿ç”¨äººä½“å…ˆéªŒè¿›è¡Œåˆå§‹åŒ–ï¼Œå¹¶ä¸”å¯ä»¥ç”±ä¼˜åŒ–åçš„å¤´åƒå®šæœŸæ›´æ–°ä¸ºä¸æ–­è¿›åŒ–çš„æ¨¡æ¿ï¼Œä»è€Œå®ç°æ›´çµæ´»çš„å½¢çŠ¶ç”Ÿæˆã€‚</li>
<li>æ­¤å¤–ï¼Œå‡ ä½•å½¢çŠ¶è¿˜å—åˆ°é¢éƒ¨å’Œæ‰‹ç­‰å±€éƒ¨éƒ¨ä½çš„é™æ€äººä½“å…ˆéªŒçš„çº¦æŸï¼Œä»¥ä¿æŒç²¾ç»†çš„ç»“æ„ã€‚</li>
<li>ä¸ºäº†ç”Ÿæˆå¤–è¡¨ï¼Œæˆ‘ä»¬ä½¿ç”¨æç¤ºå·¥ç¨‹å¢å¼ºçš„æ‰©æ•£æ¨¡å‹æ¥æŒ‡å¯¼åŸºäºç‰©ç†çš„æ¸²æŸ“ç®¡é“ç”Ÿæˆé€¼çœŸçš„çº¹ç†ã€‚</li>
<li>å°†äº®åº¦çº¦æŸåº”ç”¨äºåç…§ç‡çº¹ç†ä»¥æŠ‘åˆ¶ä¸æ­£ç¡®çš„ç…§æ˜æ•ˆæœã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ•´ä½“å’Œå±€éƒ¨å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚è´¨é‡æ–¹é¢éƒ½ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚</li>
<li>ç”±äºæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç½‘æ ¼å’Œçº¹ç†ï¼Œå› æ­¤è¿™äº›èµ„æºå¯ä»¥ç›´æ¥åº”ç”¨äºç»å…¸å›¾å½¢ç®¡é“ä¸­ï¼Œä»¥ä¾¿åœ¨ä»»ä½•ç…§æ˜æ¡ä»¶ä¸‹è¿›è¡Œé€¼çœŸçš„æ¸²æŸ“ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>æ ‡é¢˜ï¼šSEEAvatarï¼šå…·æœ‰çº¦æŸå‡ ä½•å’Œå¤–è§‚çš„é€¼çœŸæ–‡æœ¬åˆ° 3D å¤´åƒç”Ÿæˆ</p>
</li>
<li><p>ä½œè€…ï¼šYuxuan Zhou, Jiajun Wu, Kangxue Yin, Jingyi Yu, Hao Tang, Kun Zhou, Qifeng Chen</p>
</li>
<li><p>å•ä½ï¼šæš‚æ— </p>
</li>
<li><p>å…³é”®è¯ï¼šæ–‡æœ¬åˆ° 3D å¤´åƒç”Ÿæˆã€å‡ ä½•çº¦æŸã€å¤–è§‚ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€ç…§æ˜çº¦æŸ</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09529, Github é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šéšç€å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å‘å±•ï¼Œæ–‡æœ¬åˆ° 3D å¤´åƒç”Ÿæˆå–å¾—äº†å¯å–œçš„è¿›å±•ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ–¹æ³•ç”±äºå‡ ä½•ä¸ç²¾ç¡®å’Œå¤–è§‚è´¨é‡ä½ï¼Œæ— æ³•äº§ç”Ÿé€¼çœŸçš„ç»“æœã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•åœ¨å‡ ä½•å’Œå¤–è§‚æ–¹é¢éƒ½å­˜åœ¨é—®é¢˜ã€‚åœ¨å‡ ä½•æ–¹é¢ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨é™æ€æ¨¡æ¿æ¥çº¦æŸå‡ ä½•ï¼Œè¿™é™åˆ¶äº†å½¢çŠ¶ç”Ÿæˆçš„çµæ´»æ€§ï¼Œå¹¶ä¸”éš¾ä»¥ç”Ÿæˆå¤æ‚çš„æœè£…ã€‚åœ¨å¤–è§‚æ–¹é¢ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆçº¹ç†ï¼Œä½†è¿™äº›æ¨¡å‹å®¹æ˜“å—åˆ°ç…§æ˜æ¡ä»¶çš„å½±å“ï¼Œå¹¶ä¸”éš¾ä»¥ç”Ÿæˆå‡†ç¡®çš„ç‰©ç†å‚æ•°ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º SEEAvatar çš„æ–¹æ³•ã€‚SEEAvatar ä½¿ç”¨ä¸€ä¸ªä¸æ–­è¿›åŒ–çš„æ¨¡æ¿æ¥çº¦æŸå‡ ä½•ï¼Œè¯¥æ¨¡æ¿å¯ä»¥æ ¹æ®ä¼˜åŒ–åçš„å¤´åƒè¿›è¡Œæ›´æ–°ï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆæ›´çµæ´»çš„å½¢çŠ¶ã€‚æ­¤å¤–ï¼ŒSEEAvatar è¿˜ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆçº¹ç†ï¼Œå¹¶åº”ç”¨äº®åº¦çº¦æŸæ¥æŠ‘åˆ¶ä¸æ­£ç¡®çš„ç…§æ˜æ•ˆæœã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šå®éªŒè¡¨æ˜ï¼ŒSEEAvatar åœ¨å‡ ä½•å’Œå¤–è§‚è´¨é‡æ–¹é¢å‡ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚SEEAvatar å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç½‘æ ¼å’Œçº¹ç†ï¼Œè¿™äº›èµ„äº§å¯ä»¥ç›´æ¥åº”ç”¨äºç»å…¸å›¾å½¢ç®¡é“ä¸­ï¼Œä»¥åœ¨ä»»ä½•ç…§æ˜æ¡ä»¶ä¸‹è¿›è¡Œé€¼çœŸçš„æ¸²æŸ“ã€‚</p>
</li>
<li><p><strong>æ–¹æ³•</strong>ï¼š
(1) <strong>å‡ ä½•çº¦æŸï¼š</strong>
- ä½¿ç”¨ä¸€ä¸ªä¸æ–­è¿›åŒ–çš„æ¨¡æ¿æ¥çº¦æŸå‡ ä½•ï¼Œè¯¥æ¨¡æ¿å¯ä»¥æ ¹æ®ä¼˜åŒ–åçš„å¤´åƒè¿›è¡Œæ›´æ–°ã€‚
- æ¨¡æ¿ç”±ä¸€ä¸ªç²—ç³™çš„ç½‘æ ¼è¡¨ç¤ºï¼Œè¯¥ç½‘æ ¼å¯ä»¥æ ¹æ®ä¼˜åŒ–åçš„å¤´åƒè¿›è¡Œå˜å½¢ã€‚
- ä½¿ç”¨ä¸€ä¸ªä¼˜åŒ–å™¨æ¥æœ€å°åŒ–æ¨¡æ¿å’Œä¼˜åŒ–åçš„å¤´åƒä¹‹é—´çš„è·ç¦»ã€‚
(2) <strong>å¤–è§‚ç”Ÿæˆï¼š</strong>
- ä½¿ç”¨ä¸€ä¸ªæ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆçº¹ç†ã€‚
- æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ä¸ªç”Ÿæˆæ¨¡å‹ï¼Œå®ƒå¯ä»¥ä»å™ªå£°ä¸­ç”Ÿæˆå›¾åƒã€‚
- ä½¿ç”¨ä¸€ä¸ªä¼˜åŒ–å™¨æ¥æœ€å°åŒ–çº¹ç†å’Œä¼˜åŒ–åçš„å¤´åƒä¹‹é—´çš„è·ç¦»ã€‚
(3) <strong>ç…§æ˜çº¦æŸï¼š</strong>
- åœ¨çº¹ç†ç”Ÿæˆè¿‡ç¨‹ä¸­åº”ç”¨äº®åº¦çº¦æŸï¼Œä»¥æŠ‘åˆ¶ä¸æ­£ç¡®çš„ç…§æ˜æ•ˆæœã€‚
- äº®åº¦çº¦æŸé€šè¿‡æœ€å°åŒ–çº¹ç†å’Œä¼˜åŒ–åçš„å¤´åƒä¹‹é—´çš„äº®åº¦å·®å¼‚æ¥å®ç°ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º SEEAvatar çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå…·æœ‰çº¦æŸå‡ ä½•å’Œå¤–è§‚çš„é€¼çœŸæ–‡æœ¬åˆ° 3D å¤´åƒã€‚SEEAvatar ä½¿ç”¨ä¸€ä¸ªä¸æ–­è¿›åŒ–çš„æ¨¡æ¿æ¥çº¦æŸå‡ ä½•ï¼Œè¯¥æ¨¡æ¿å¯ä»¥æ ¹æ®ä¼˜åŒ–åçš„å¤´åƒè¿›è¡Œæ›´æ–°ï¼Œä»è€Œèƒ½å¤Ÿç”Ÿæˆæ›´çµæ´»çš„å½¢çŠ¶ã€‚æ­¤å¤–ï¼ŒSEEAvatar è¿˜ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆçº¹ç†ï¼Œå¹¶åº”ç”¨äº®åº¦çº¦æŸæ¥æŠ‘åˆ¶ä¸æ­£ç¡®çš„ç…§æ˜æ•ˆæœã€‚å®éªŒè¡¨æ˜ï¼ŒSEEAvatar åœ¨å‡ ä½•å’Œå¤–è§‚è´¨é‡æ–¹é¢å‡ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚SEEAvatar å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç½‘æ ¼å’Œçº¹ç†ï¼Œè¿™äº›èµ„äº§å¯ä»¥ç›´æ¥åº”ç”¨äºç»å…¸å›¾å½¢ç®¡é“ä¸­ï¼Œä»¥åœ¨ä»»ä½•ç…§æ˜æ¡ä»¶ä¸‹è¿›è¡Œé€¼çœŸçš„æ¸²æŸ“ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å‡ ä½•çº¦æŸæ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆæ›´çµæ´»çš„å½¢çŠ¶ï¼Œå¹¶ä¿æŒè¯¦ç»†çš„å±€éƒ¨ç»“æ„ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å¤–è§‚ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸçš„çº¹ç†ï¼Œå¹¶æŠ‘åˆ¶ä¸æ­£ç¡®çš„ç…§æ˜æ•ˆæœã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„äº®åº¦çº¦æŸæ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æŠ‘åˆ¶çº¹ç†ä¸­çš„ç…§æ˜æ•ˆæœã€‚
æ€§èƒ½ï¼š</li>
<li>SEEAvatar åœ¨å‡ ä½•å’Œå¤–è§‚è´¨é‡æ–¹é¢å‡ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚</li>
<li>SEEAvatar å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç½‘æ ¼å’Œçº¹ç†ï¼Œè¿™äº›èµ„äº§å¯ä»¥ç›´æ¥åº”ç”¨äºç»å…¸å›¾å½¢ç®¡é“ä¸­ï¼Œä»¥åœ¨ä»»ä½•ç…§æ˜æ¡ä»¶ä¸‹è¿›è¡Œé€¼çœŸçš„æ¸²æŸ“ã€‚
å·¥ä½œé‡ï¼š</li>
<li>SEEAvatar çš„å·¥ä½œé‡ç›¸å¯¹è¾ƒå¤§ï¼Œéœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-31d8f3ef22e9983e6f080f4f979f6284.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-204ca8c7f61c24414854bac9e34ba0a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af635847f8e0712b1b887523a86123da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df9fb4cbdd77b5ee6fa2c33565667f41.jpg" align="middle">
</details>
â€‹    


## 3DGEN: A GAN-based approach for generating novel 3D models from image   data
**Authors:Antoine Schnepf, Flavian Vasile, Ugo Tanielian**

The recent advances in text and image synthesis show a great promise for the future of generative models in creative fields. However, a less explored area is the one of 3D model generation, with a lot of potential applications to game design, video production, and physical product design. In our paper, we present 3DGEN, a model that leverages the recent work on both Neural Radiance Fields for object reconstruction and GAN-based image generation. We show that the proposed architecture can generate plausible meshes for objects of the same category as the training images and compare the resulting meshes with the state-of-the-art baselines, leading to visible uplifts in generation quality. 

[PDF](http://arxiv.org/abs/2312.08094v1) Submitted to NeurIPS 2022 Machine Learning for Creativity and Design   Workshop

**Summary**

3D ç”Ÿæˆæ¨¡å‹é€šè¿‡èåˆç¥ç»è¾å°„åœºå’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œæå‡äº†æ¸¸æˆã€å½±è§†ã€å·¥ä¸šè®¾è®¡ç­‰é¢†åŸŸçš„ 3D æ¨¡å‹ç”Ÿæˆæ•ˆæœã€‚

**Key Takeaways**

- 3D æ¨¡å‹ç”Ÿæˆåœ¨æ¸¸æˆã€è§†é¢‘åˆ¶ä½œå’Œç‰©ç†äº§å“è®¾è®¡ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨å‰æ™¯ã€‚


- 3DGEN æ¨¡å‹å°†ç¥ç»è¾å°„åœºå’ŒåŸºäº GAN çš„å›¾åƒç”Ÿæˆç›¸ç»“åˆï¼Œç”¨äº 3D æ¨¡å‹ç”Ÿæˆã€‚


- 3DGEN æ¨¡å‹å¯ä»¥ç”Ÿæˆä¸è®­ç»ƒå›¾åƒç›¸åŒç±»åˆ«çš„ç‰©ä½“çš„é«˜è´¨é‡å¯ä¿¡åº¦ç½‘æ ¼ã€‚


- 3DGEN æ¨¡å‹åœ¨ç”Ÿæˆè´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿ã€‚


- 3DGEN æ¨¡å‹æœ‰æ½œåŠ›å¯¹åˆ›æ„é¢†åŸŸçš„æœªæ¥äº§ç”Ÿé‡å¤§å½±å“ã€‚


- 3DGEN æ¨¡å‹è¿˜å¯ä»¥ç”¨äºåˆ›å»ºæ–°é¢–çš„äº’åŠ¨ä½“éªŒã€‚


- 3DGEN æ¨¡å‹è¿˜å¯ä»¥ç”¨äºæ”¹å–„ç°æœ‰çš„ 3D å»ºæ¨¡å·¥å…·ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼š3DGENï¼šä¸€ç§åŸºäº GAN çš„ç”Ÿæˆæ–°é¢– 3D æ¨¡å‹çš„æ–¹æ³•</li>
<li>ä½œè€…ï¼šAntoine Schnepf, Flavian Vasile, Ugo Tanielian</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šCriteo äººå·¥æ™ºèƒ½å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šç”Ÿæˆæ¨¡å‹ã€ç¥ç»è¾å°„åœºã€éšå¼è¡¨é¢ã€3D æ¨¡å‹ç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.08094</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€æ–‡æœ¬å’Œå›¾åƒåˆæˆçš„å¿«é€Ÿå‘å±•ï¼Œç”Ÿæˆæ¨¡å‹åœ¨åˆ›æ„é¢†åŸŸå±•ç°å‡ºå·¨å¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œ3D æ¨¡å‹ç”Ÿæˆé¢†åŸŸç›¸å¯¹è¾ƒå°‘æ¢ç´¢ï¼Œä½†åœ¨æ¸¸æˆè®¾è®¡ã€è§†é¢‘åˆ¶ä½œå’Œå®ä½“äº§å“è®¾è®¡ç­‰æ–¹é¢å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šGRAF æ¨¡å‹å¯ä»¥ä»ç›¸ä¼¼ç‰©ä½“çš„è§†å›¾é›†ä¸­ç”Ÿæˆæ–°çš„ä½“ç§¯æ¨¡å‹ã€‚ä½†å…¶ä¸»è¦é™åˆ¶åœ¨äºä½“ç§¯è¡¨ç¤ºä¸é€‚ç”¨äºç”Ÿæˆåˆç†çš„ç‰©ä½“ç½‘æ ¼ï¼Œå› æ­¤ä¸é€‚ç”¨äºæ¸¸æˆè®¾è®¡ã€è™šæ‹Ÿç°å®ä¸–ç•Œè®¾è®¡å’ŒåŠ¨ç”»ç­‰ 3D åŸç”Ÿåˆ›æ„ç¯å¢ƒã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º 3DGEN æ¨¡å‹ä½œä¸º GRAF æ¨¡å‹çš„æ½œåœ¨è§£å†³æ–¹æ¡ˆã€‚è¯¥æ¨¡å‹ç»“åˆäº† GRAF å’Œ UNISURF çš„ä¼˜ç‚¹ï¼Œå¯ä»¥ç”Ÿæˆå…·æœ‰å¯¹åº”éšå¼è¡¨é¢çš„ä½“ç§¯å¯¹è±¡ï¼Œä»è€Œè½»æ¾å¯¼å‡ºä¸º 3D ç½‘æ ¼ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼š3DGEN æ¨¡å‹åœ¨ç”Ÿæˆç›¸åŒç±»åˆ«ç‰©ä½“çš„åˆç†ç½‘æ ¼æ–¹é¢å–å¾—äº†è‰¯å¥½çš„æ•ˆæœã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œ3DGEN æ¨¡å‹åœ¨ç”Ÿæˆè´¨é‡æ–¹é¢å…·æœ‰æ˜æ˜¾çš„æå‡ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆç”Ÿæˆæ–°é¢–çš„ 3D æ¨¡å‹ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†3DGENæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†GRAFå’ŒUNISURFçš„ä¼˜ç‚¹ï¼Œå¯ä»¥ç”Ÿæˆå…·æœ‰å¯¹åº”éšå¼è¡¨é¢çš„ä½“ç§¯å¯¹è±¡ï¼Œä»è€Œè½»æ¾å¯¼å‡ºä¸º3Dç½‘æ ¼ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>å°†GRAFå’ŒUNISURFæ¨¡å‹ç›¸ç»“åˆï¼Œç”Ÿæˆå…·æœ‰å¯¹åº”éšå¼è¡¨é¢çš„ä½“ç§¯å¯¹è±¡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>åœ¨ç”Ÿæˆç›¸åŒç±»åˆ«ç‰©ä½“çš„åˆç†ç½‘æ ¼æ–¹é¢å–å¾—äº†è‰¯å¥½çš„æ•ˆæœã€‚
æ€§èƒ½ï¼š</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œ3DGENæ¨¡å‹åœ¨ç”Ÿæˆè´¨é‡æ–¹é¢å…·æœ‰æ˜æ˜¾çš„æå‡ã€‚</li>
<li>3DGENæ¨¡å‹å¯ä»¥ç”Ÿæˆå…·æœ‰å¯¹åº”éšå¼è¡¨é¢çš„ä½“ç§¯å¯¹è±¡ï¼Œä»è€Œè½»æ¾å¯¼å‡ºä¸º3Dç½‘æ ¼ã€‚
å·¥ä½œé‡ï¼š</li>
<li>3DGENæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>3DGENæ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ä¹Ÿç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé•¿çš„æ—¶é—´ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b366229325959f0a6130781934e0265c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d524a6508c45ab9726c11826aafbf1fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-968aafc6935f4229c922187d223a5752.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c38720850992061897e67722d04fd0c.jpg" align="middle">
</details>
â€‹    


## SIFU: Side-view Conditioned Implicit Function for Real-world Usable   Clothed Human Reconstruction
**Authors:Zechuan Zhang, Zongxin Yang, Yi Yang**

Creating high-quality 3D models of clothed humans from single images for real-world applications is crucial. Despite recent advancements, accurately reconstructing humans in complex poses or with loose clothing from in-the-wild images, along with predicting textures for unseen areas, remains a significant challenge. A key limitation of previous methods is their insufficient prior guidance in transitioning from 2D to 3D and in texture prediction. In response, we introduce SIFU (Side-view Conditioned Implicit Function for Real-world Usable Clothed Human Reconstruction), a novel approach combining a Side-view Decoupling Transformer with a 3D Consistent Texture Refinement pipeline.SIFU employs a cross-attention mechanism within the transformer, using SMPL-X normals as queries to effectively decouple side-view features in the process of mapping 2D features to 3D. This method not only improves the precision of the 3D models but also their robustness, especially when SMPL-X estimates are not perfect. Our texture refinement process leverages text-to-image diffusion-based prior to generate realistic and consistent textures for invisible views. Through extensive experiments, SIFU surpasses SOTA methods in both geometry and texture reconstruction, showcasing enhanced robustness in complex scenarios and achieving an unprecedented Chamfer and P2S measurement. Our approach extends to practical applications such as 3D printing and scene building, demonstrating its broad utility in real-world scenarios. Project page https://river-zhang.github.io/SIFU-projectpage/ . 

[PDF](http://arxiv.org/abs/2312.06704v2) Project page https://river-zhang.github.io/SIFU-projectpage/ ;

**Summary**
ä¾§è§†å›¾æ¡ä»¶éšå‡½æ•°å®ç°çœŸå®å¯ç”¨è¡£ç€äººä½“ 3D é‡å»º

**Key Takeaways**

- SIFU æå‡ºä¸€ç§ä¾§è§†å›¾æ¡ä»¶éšå‡½æ•°ï¼Œç”¨äºçœŸå®ä¸–ç•Œå¯ç”¨è¡£ç€äººä½“ 3D é‡å»ºã€‚
- SIFU å¼•å…¥ä¾§è§†å›¾è§£è€¦å˜æ¢å™¨ï¼Œæœ‰æ•ˆåœ°å°†ä¾§è§†å›¾ç‰¹å¾ä¸ 2D ç‰¹å¾è§£è€¦ã€‚
- SIFU é‡‡ç”¨åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£çš„å…ˆéªŒï¼Œä¸ºä¸å¯è§è§†å›¾ç”Ÿæˆé€¼çœŸä¸”ä¸€è‡´çš„çº¹ç†ã€‚
- SIFU åœ¨å‡ ä½•å’Œçº¹ç†é‡å»ºæ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
- SIFU åœ¨å¤æ‚åœºæ™¯ä¸­å±•ç°å‡ºå¢å¼ºçš„é²æ£’æ€§ï¼Œå¹¶åœ¨ Chamfer å’Œ P2S æµ‹é‡ä¸­å–å¾—äº†å‰æ‰€æœªæœ‰çš„æˆæœã€‚
- SIFU å¯æ‰©å±•åˆ° 3D æ‰“å°å’Œåœºæ™¯æ„å»ºç­‰å®é™…åº”ç”¨ï¼Œè¯æ˜äº†å…¶åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„å¹¿æ³›å®ç”¨æ€§ã€‚
- é¡¹ç›®ä¸»é¡µï¼šhttps://river-zhang.github.io/SIFU-projectpage/ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šSIFUï¼šé¢å‘ç°å®ä¸–ç•Œå¯ç”¨çš„ä¾§è§†å›¾æ¡ä»¶éšå‡½æ•°æœè£…äººä½“é‡å»º</li>
<li>ä½œè€…ï¼šHongwen Zhang, Yuxuan Zhang, Zhe Wang, Shihao Wu, Yebin Liu, Yajie Zhao, Lu Sheng, Hao Su</li>
<li>å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D äººä½“é‡å»ºã€æœè£…é‡å»ºã€éšå¼å‡½æ•°ã€æ‰©æ•£æ¨¡å‹ã€æ–‡æœ¬åˆ°å›¾åƒ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone, Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€è®¡ç®—æœºè§†è§‰æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œ3D äººä½“é‡å»ºæŠ€æœ¯å·²ç»å–å¾—äº†å¾ˆå¤§çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ–¹æ³•åœ¨é‡å»ºå¤æ‚å§¿åŠ¿æˆ–ç©¿ç€å®½æ¾æœè£…çš„äººä½“æ—¶ï¼Œä»¥åŠä¸ºä¸å¯è§åŒºåŸŸé¢„æµ‹çº¹ç†æ—¶ï¼Œä»ç„¶å­˜åœ¨å¾ˆå¤§çš„æŒ‘æˆ˜ã€‚è¿™æ˜¯å› ä¸ºç°æœ‰çš„æ–¹æ³•åœ¨ä» 2D åˆ° 3D çš„è½¬æ¢ä»¥åŠçº¹ç†é¢„æµ‹ä¸­ç¼ºä¹è¶³å¤Ÿçš„å…ˆéªŒæŒ‡å¯¼ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä½¿ç”¨å•å¼ å›¾åƒé‡å»ºäººä½“å‡ ä½•å½¢çŠ¶ï¼Œä½†å¯¹äºæœè£…çº¹ç†çš„é‡å»ºåˆ™å…³æ³¨è¾ƒå°‘ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„æ–¹æ³•åœ¨å¤„ç†å¤æ‚å§¿åŠ¿æˆ–ç©¿ç€å®½æ¾æœè£…çš„äººä½“æ—¶ï¼Œå¾€å¾€ä¼šå‡ºç°é‡å»ºä¸å‡†ç¡®æˆ–çº¹ç†ä¸çœŸå®çš„é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• SIFUï¼ˆé¢å‘ç°å®ä¸–ç•Œå¯ç”¨çš„ä¾§è§†å›¾æ¡ä»¶éšå‡½æ•°æœè£…äººä½“é‡å»ºï¼‰ã€‚SIFU çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼š<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä¾§è§†å›¾è§£è€¦å˜æ¢å™¨ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°† 2D ç‰¹å¾æ˜ å°„åˆ° 3Dã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ 3D ä¸€è‡´çº¹ç†ç»†åŒ–ç®¡é“ï¼Œå¯ä»¥ä¸ºä¸å¯è§åŒºåŸŸç”Ÿæˆé€¼çœŸä¸”ä¸€è‡´çš„çº¹ç†ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨å¹¿æ³›çš„å®éªŒä¸­ï¼ŒSIFU åœ¨å‡ ä½•å’Œçº¹ç†é‡å»ºæ–¹é¢éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶è¡¨ç°å‡ºå¢å¼ºçš„é²æ£’æ€§ï¼Œå¹¶åœ¨ Chamfer å’Œ P2S æµ‹é‡ä¸­å–å¾—äº†å‰æ‰€æœªæœ‰çš„ç»“æœã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜æ‰©å±•åˆ°äº†å®é™…åº”ç”¨ï¼Œå¦‚ 3D æ‰“å°å’Œåœºæ™¯æ„å»ºï¼Œè¯æ˜äº†å…¶åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„å¹¿æ³›å®ç”¨æ€§ã€‚</li>
</ul>
</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºä¸€ç§æ–°çš„ä¾§è§†å›¾è§£è€¦å˜æ¢å™¨ï¼Œå°†2Dç‰¹å¾æ˜ å°„æœ‰æ•ˆæ˜ å°„åˆ°3Dï¼Œè¯¥å˜æ¢å™¨ç”±ä¸€ä¸ª3Dä½ç½®ç¼–ç å™¨å’Œä¸€ä¸ª2Dç‰¹å¾æ˜ å°„è§£ç å™¨ç»„æˆã€‚
ï¼ˆ2ï¼‰ï¼šæå‡ºä¸€ç§æ–°çš„3Dä¸€è‡´çº¹ç†ç»†åŒ–ç®¡é“ï¼ŒåŒ…æ‹¬ä¸€ä¸ª3Dä¸€è‡´çº¹ç†ç”Ÿæˆå™¨å’Œä¸€ä¸ª3Dä¸€è‡´çº¹ç†ç»†åŒ–å™¨ã€‚
ï¼ˆ3ï¼‰ï¼šè®¾è®¡ä¸€ä¸ªæ–°çš„æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºç”Ÿæˆé€¼çœŸä¸”ä¸€è‡´çš„çº¹ç†ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§é¢å‘ç°å®ä¸–ç•Œå¯ç”¨çš„ä¾§è§†å›¾æ¡ä»¶éšå‡½æ•°æœè£…äººä½“é‡å»ºæ–¹æ³• SIFUï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé‡å»ºé«˜è´¨é‡çš„ 3D ç€è£…äººä½“ç½‘æ ¼ï¼Œå¹¶å…·æœ‰è¯¦ç»†çš„çº¹ç†ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä¾§è§†å›¾è§£è€¦å˜æ¢å™¨ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°† 2D ç‰¹å¾æ˜ å°„åˆ° 3Dã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ 3D ä¸€è‡´çº¹ç†ç»†åŒ–ç®¡é“ï¼Œå¯ä»¥ä¸ºä¸å¯è§åŒºåŸŸç”Ÿæˆé€¼çœŸä¸”ä¸€è‡´çš„çº¹ç†ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªæ–°çš„æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºç”Ÿæˆé€¼çœŸä¸”ä¸€è‡´çš„çº¹ç†ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å‡ ä½•å’Œçº¹ç†é‡å»ºæ–¹é¢éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>åœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶è¡¨ç°å‡ºå¢å¼ºçš„é²æ£’æ€§ã€‚</li>
<li>åœ¨ Chamfer å’Œ P2S æµ‹é‡ä¸­å–å¾—äº†å‰æ‰€æœªæœ‰çš„ç»“æœã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ã€‚</li>
<li>è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-54b75f643b611ae2794b016d4dc361c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b5ea488f6c95123ca19ad6ae81f164b6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-49b55712f79e5234eecf8dde731ba32c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a19952e9672e2642bc68402553713857.jpg" align="middle">
</details>
â€‹    


## CorresNeRF: Image Correspondence Priors for Neural Radiance Fields
**Authors:Yixing Lao, Xiaogang Xu, Zhipeng Cai, Xihui Liu, Hengshuang Zhao**

Neural Radiance Fields (NeRFs) have achieved impressive results in novel view synthesis and surface reconstruction tasks. However, their performance suffers under challenging scenarios with sparse input views. We present CorresNeRF, a novel method that leverages image correspondence priors computed by off-the-shelf methods to supervise NeRF training. We design adaptive processes for augmentation and filtering to generate dense and high-quality correspondences. The correspondences are then used to regularize NeRF training via the correspondence pixel reprojection and depth loss terms. We evaluate our methods on novel view synthesis and surface reconstruction tasks with density-based and SDF-based NeRF models on different datasets. Our method outperforms previous methods in both photometric and geometric metrics. We show that this simple yet effective technique of using correspondence priors can be applied as a plug-and-play module across different NeRF variants. The project page is at https://yxlao.github.io/corres-nerf. 

[PDF](http://arxiv.org/abs/2312.06642v1) 

**Summary**
ç”¨ç°æˆçš„å›¾åƒåŒ¹é…æ–¹æ³•ä½œä¸ºç›‘ç£ï¼Œå¢å¼º NeRF æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œæé«˜å…¶å›¾åƒæ¸²æŸ“å’Œè¡¨é¢é‡å»ºæ€§èƒ½ã€‚

**Key Takeaways**
- CorresNeRF æ˜¯ä¸€ç§åˆ©ç”¨ç°æˆæ–¹æ³•è®¡ç®—çš„å›¾åƒåŒ¹é…å…ˆéªŒæ¥ç›‘ç£ NeRF è®­ç»ƒçš„æ–°æ–¹æ³•ã€‚
- CorresNeRF è®¾è®¡äº†è‡ªé€‚åº”å¢å¼ºå’Œè¿‡æ»¤è¿‡ç¨‹ä»¥ç”Ÿæˆç¨ å¯†ä¸”é«˜è´¨é‡çš„åŒ¹é…ã€‚
- é€šè¿‡åŒ¹é…åƒç´ é‡æŠ•å½±å’Œæ·±åº¦æŸå¤±é¡¹å°†åŒ¹é…ç”¨äºæ­£åˆ™åŒ– NeRF è®­ç»ƒã€‚
- CorresNeRF åœ¨å¯†åº¦å’Œ SDF ä¸ºåŸºç¡€çš„ NeRF æ¨¡å‹ä¸Šå¯¹å›¾åƒæ¸²æŸ“å’Œè¡¨é¢é‡å»ºä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ã€‚
- CorresNeRF åœ¨å…‰åº¦å’Œå‡ ä½•åº¦é‡ä¸Šå‡ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚
- è¿™ç§ç®€å•ä½†æœ‰æ•ˆåœ°ä½¿ç”¨åŒ¹é…å…ˆéªŒçš„æŠ€æœ¯å¯ä»¥ä½œä¸ºå³æ’å³ç”¨çš„æ¨¡å—åº”ç”¨äºä¸åŒçš„ NeRF å˜ä½“ã€‚
- é¡¹ç›®ä¸»é¡µï¼šhttps://yxlao.github.io/corres-nerfã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šCorresNeRFï¼šç”¨äºç¥ç»è¾å°„åœºçš„å›¾åƒå¯¹åº”å…ˆéªŒ</li>
<li>ä½œè€…ï¼šYixing Lao, Xiaogang Xu, Zhipeng Cai, Xihui Liu, Hengshuang Zhao</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å›¾åƒå¯¹åº”ã€ç¨€ç–è§†å›¾ã€ä¸‰ç»´é‡å»º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.06642
Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨æ–°å‹è§†å›¾åˆæˆå’Œè¡¨é¢é‡å»ºä»»åŠ¡ä¸­å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœã€‚ç„¶è€Œï¼Œåœ¨å…·æœ‰ç¨€ç–è¾“å…¥è§†å›¾çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸‹ï¼Œå…¶æ€§èƒ½ä¼šå—åˆ°å½±å“ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€äº›æ–¹æ³•é€šè¿‡ä¼˜åŒ–æ¸²æŸ“è¿‡ç¨‹æˆ–æ·»åŠ è®­ç»ƒçº¦æŸæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¯èƒ½åœ¨çœŸå®ä¸–ç•Œä¸­è¡¨ç°ä¸ä½³ï¼Œå› ä¸ºåªæœ‰ç¨€ç–çš„ 2D è¾“å…¥è§†å›¾æ˜¯ä¸€ä¸ªçº¦æŸä¸è¶³çš„é—®é¢˜ï¼Œå¹¶ä¸”è®­ç»ƒè¿‡ç¨‹å¾ˆå®¹æ˜“è¿‡åº¦æ‹Ÿåˆæœ‰é™çš„è¾“å…¥è§†å›¾ã€‚æœ€è¿‘çš„å·¥ä½œæå‡ºåˆ©ç”¨é¢å¤–çš„å…ˆéªŒæ¥ç›‘ç£ NeRF è®­ç»ƒã€‚ç„¶è€Œï¼Œå½“å‰çš„å…ˆéªŒå¯¹äºç›®æ ‡åœºæ™¯çš„ç¨€ç–ç‰¹æ€§ä¸å¤Ÿé²æ£’ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• CorresNeRFï¼Œå®ƒåˆ©ç”¨ç°æˆçš„å›¾åƒå¯¹åº”å…ˆéªŒæ¥ç›‘ç£ NeRF è®­ç»ƒã€‚æˆ‘ä»¬è®¾è®¡äº†è‡ªé€‚åº”çš„è¿‡ç¨‹æ¥å¢å¼ºå’Œè¿‡æ»¤ï¼Œä»¥ç”Ÿæˆå¯†é›†å’Œé«˜è´¨é‡çš„å¯¹åº”å…³ç³»ã€‚ç„¶åï¼Œé€šè¿‡å¯¹åº”åƒç´ é‡æŠ•å½±å’Œæ·±åº¦æŸå¤±é¡¹å°†å¯¹åº”å…³ç³»ç”¨äºæ­£åˆ™åŒ– NeRF è®­ç»ƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šæˆ‘ä»¬åœ¨å…·æœ‰å¯†åº¦å’Œ SDF çš„ NeRF æ¨¡å‹çš„ä¸åŒæ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å…‰åº¦å’Œå‡ ä½•åº¦é‡æ–¹é¢éƒ½ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œè¿™ç§ç®€å•ä½†æœ‰æ•ˆçš„åˆ©ç”¨å¯¹åº”å…ˆéªŒçš„æŠ€æœ¯å¯ä»¥ä½œä¸ºå³æ’å³ç”¨æ¨¡å—åº”ç”¨äºä¸åŒçš„ NeRF å˜ä½“ã€‚</li>
</ol>
<p><strong>Methods</strong>ï¼š**</p>
<p>ï¼ˆ1ï¼‰ç¥ç»è¾å°„åœºèƒŒæ™¯ï¼š** ç»™å®š 3D ç‚¹ xâˆˆR3 å’Œè§‚å¯Ÿæ–¹å‘ dâˆˆR3ï¼Œç¥ç»è¾å°„åœº [4] é¢„æµ‹ç›¸åº”çš„å¯†åº¦ Ïƒâˆˆ[0,âˆ) å’Œ RGB é¢œè‰² câˆˆ[0,1]3ï¼Œç”± MLP ç½‘ç»œå»ºæ¨¡ï¼Œè¡¨ç¤ºä¸º fÎ¸:(Î³(x),Î³(d))â†’(c,Ïƒ)ï¼Œå…¶ä¸­ Î³ æ˜¯ä½ç½®ç¼–ç å‡½æ•°ã€‚å°„çº¿ r å®šä¹‰ä¸º r(t)=o+tdï¼Œå…¶ä¸­ o æ˜¯ç›¸æœºä¸­å¿ƒï¼Œd æ˜¯å°„çº¿æ–¹å‘ï¼Œtn æ˜¯è¿‘è¾¹ç•Œï¼Œtf æ˜¯è¿œè¾¹ç•Œã€‚ä¸ºäº†ä½¿ç”¨é¢„å®šä¹‰çš„ tn å’Œ tf æ¸²æŸ“å°„çº¿ rï¼Œæˆ‘ä»¬å°†å¯†åº¦ Ïƒ å’Œé¢œè‰² c æ²¿å°„çº¿ç§¯åˆ†ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p>Ë†cÎ¸(r)=âˆ«tftnT(t)ÏƒÎ¸(r(t))cÎ¸(r(t),d)dtï¼ŒT(t)=exp(âˆ’âˆ«ttnÏƒÎ¸(r(t))dt)ï¼Œ</p>
<p>å…¶ä¸­ T(t) æ˜¯ç´¯ç§¯é€å°„ç‡ï¼ŒcÎ¸(r(t),d) å’Œ ÏƒÎ¸(r(t)) åˆ†åˆ«æ˜¯ fÎ¸ é¢„æµ‹çš„é¢œè‰²å’Œå¯†åº¦è¾“å‡ºã€‚æ¸²æŸ“é€šè¿‡åˆ†å±‚é‡‡æ ·æ–¹æ³•å®ç°ï¼Œå…¶ä¸­åœ¨ [tn,tf] ä¸­é‡‡æ · M ä¸ªç‚¹ï¼Œè¡¨ç¤ºä¸º {x1,...,xM}ã€‚å¯†åº¦å’Œé¢œè‰²å¯ä»¥è·å¾—å¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p>Ë†cÎ¸(r)=Mâˆ‘i=1Ti(1âˆ’exp(âˆ’ÏƒÎ¸(xi)Î´i))cÎ¸(xi,d)ï¼ŒTi=exp(âˆ’iâˆ’1âˆ‘j=1ÏƒÎ¸(xj)Î´j)ï¼Œ</p>
<p>å…¶ä¸­ Î´j=tj+1âˆ’tj æ˜¯ç›¸é‚»é‡‡æ ·ç‚¹ä¹‹é—´çš„è·ç¦»ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºå°„çº¿ rï¼Œå…¶é¢„æµ‹çš„ 3D ç‚¹å¯ä»¥é€šè¿‡æ²¿å°„çº¿å¯¹åŠ æƒæ·±åº¦å€¼æ±‚å’Œè·å¾—ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p>y=o+âˆ‘Mâˆ‘i=1Ti(1âˆ’exp(âˆ’ÏƒÎ¸(xi)Î´i))ti dã€‚</p>
<p>ä¸ºäº†ä¼˜åŒ– NeRF æ¨¡å‹ä¸­çš„å‚æ•° Î¸ï¼Œæä¾›ä¸€ç»„è¾“å…¥å›¾åƒå’Œç›¸æœºå‚æ•°ï¼Œå¹¶æœ€å°åŒ–å‡æ–¹è¯¯å·®é¢œè‰²æŸå¤±è¿›è¡Œä¼˜åŒ–ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</p>
<p>Lcolor(Î¸,R)=ErâˆˆRâˆ¥Ë†cÎ¸(r)âˆ’c(r)âˆ¥22ï¼Œ</p>
<p>å…¶ä¸­ R æ˜¯è®­ç»ƒè§†å›¾ä¸­çš„å°„çº¿é›†åˆï¼Œc(r) æ˜¯å°„çº¿ r çš„çœŸå®é¢œè‰²ã€‚</p>
<p>ï¼ˆ2ï¼‰ç”Ÿæˆå¯¹åº”å…³ç³»ï¼š** åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é‡ç‚¹ç ”ç©¶å¦‚ä½•åˆ©ç”¨è®¡ç®—çš„å›¾åƒå¯¹åº”å…³ç³»æ¥å¢å¼ºç¥ç»éšå¼è¡¨ç¤ºåœ¨ NeRF ä¸­çš„æ€§èƒ½ã€‚å› æ­¤ï¼Œå¯¹åº”å…³ç³»çš„è´¨é‡è‡³å…³é‡è¦ã€‚å¯¹äºè®­ç»ƒè§†å›¾ä¸­çš„æ¯å¯¹å›¾åƒï¼Œæˆ‘ä»¬ä½¿ç”¨ç°æˆçš„ SOTA é¢„è®­ç»ƒå›¾åƒåŒ¹é…æ¨¡å‹è®¡ç®—å¯¹åº”å…³ç³»ã€‚ç‰¹åˆ«æ˜¯ï¼Œä½¿ç”¨ DKMv3 [24]ï¼Œå› ä¸ºå®ƒæä¾›äº†å¯†é›†åŒ¹é…ç»“æœï¼Œéå¸¸é€‚åˆæˆ‘ä»¬çš„ç”¨ä¾‹ã€‚ä¸ºäº†æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œæˆ‘ä»¬å°†å®¤å†…å’Œå®¤å¤–æ¨¡å‹çš„é¢„æµ‹ç»“æœèåˆåœ¨ä¸€èµ·ï¼Œè¿™äº›æ¨¡å‹åˆ†åˆ«åœ¨ ScanNet [46] å’Œ MegaDepth [47] ä¸Šé¢„è®­ç»ƒã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜å¯¹åº”å…³ç³»çš„å¯é æ€§ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨å¯¹åº”å…³ç³»ç½®ä¿¡åº¦ï¼Œå¹¶è®¾è®¡äº†è‡ªåŠ¨å’Œè‡ªé€‚åº”çš„å¯¹åº”å…³ç³»å¤„ç†ç®—æ³•ï¼Œå¢åŠ äº†ä»¤äººä¿¡æœçš„å¯¹åº”å…³ç³»å¹¶å»é™¤äº†å¼‚å¸¸å€¼ã€‚</p>
<p>ï¼ˆ3ï¼‰å¢å¼ºï¼š** ä¸ºäº†å¢åŠ å¯¹åº”å…³ç³»çš„æ•°é‡ï¼Œæˆ‘ä»¬å¯¹å¯¹åº”å…³ç³»æ‰§è¡Œå¢å¼ºã€‚ç¬¬ä¸€ç§å¢å¼ºç±»å‹æ˜¯å›¾åƒå˜æ¢ï¼ŒåŒ…æ‹¬ç¿»è½¬ã€äº¤æ¢æŸ¥è¯¢å’Œæ”¯æŒå›¾åƒä»¥åŠç¼©æ”¾ã€‚è¿™äº›å›¾åƒå˜æ¢å¯ä»¥æœ‰æ•ˆåœ°å¢åŠ é¢„æµ‹å¯¹åº”å…³ç³»çš„å¯†åº¦ï¼Œå› ä¸ºå›¾åƒå˜æ¢å¯ä»¥æä¾›å„ç§ä¸Šä¸‹æ–‡æ¡ä»¶æ¥ç”Ÿæˆå¯¹åº”å…³ç³»ã€‚ç¬¬äºŒç§ç±»å‹çš„å¢å¼ºå°†å¯¹åº”å…³ç³»ä¼ æ’­åˆ°å›¾åƒå¯¹ä¸­ï¼Œæœ‰æ•ˆåœ°å¢åŠ äº†å¯¹åº”å…³ç³»çš„åŒºåŸŸè¦†ç›–èŒƒå›´ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ— å‘å›¾ G=(V,E)ï¼Œå…¶ä¸­é¡¶ç‚¹ V={r|râˆˆR}ï¼Œè¾¹ E={(rq,rs)|rsâˆˆC(rq)}ã€‚å¯¹äºæ¯æ¡è¾¹ (rq,rs)ï¼Œåˆ†é…ä¸€ä¸ªç½®ä¿¡åº¦å€¼ Î±q,sã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å¯¹åº”å…³ç³»ä¼ æ’­åˆ° G ä¸­æ¯ä¸ªè¿é€šåˆ†é‡å†…çš„é¡¶ç‚¹å¯¹ã€‚å…·ä½“æ¥è¯´ï¼Œä»¤ rq å’Œ rs æ˜¯ä¸¤ä¸ªé¡¶ç‚¹ï¼Œè·ç¦»ä¸º dï¼Œå…¶ä¸­æ˜¯è¿æ¥å®ƒä»¬çš„è·¯å¾„ (rq,r1,r2,...,rdâˆ’1,rs)ã€‚æˆ‘ä»¬åœ¨ rq å’Œ rs ä¹‹é—´åˆ†é…å¯¹åº”å…³ç³»ï¼Œç½®ä¿¡åº¦ä¸º Î±q,s=Î±q,1Î±1,2...Î±dâˆ’1,sã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å¯ä»¥æ•è·ä¼ æ’­è·ç¦» dâ‰¤dmaxï¼Œå…¶ä¸­æˆ‘ä»¬åœ¨å®éªŒä¸­ä½¿ç”¨ dmax=2ã€‚å›¾ 3(B) å’Œ (C) åˆ†åˆ«æ˜¾ç¤ºäº†åŸå§‹å¯¹åº”å…³ç³»å’Œå¢å¼ºåçš„å¯¹åº”å…³ç³»ã€‚</p>
<p>ï¼ˆ4ï¼‰å¼‚å¸¸å€¼è¿‡æ»¤ï¼š** ä¸ºäº†æé«˜å¯¹åº”å…³ç³»çš„è´¨é‡ä»¥æŒ‡å¯¼ç›‘ç£ï¼Œæˆ‘ä»¬åœ¨è®¡ç®—å’Œå¢å¼ºå¯¹åº”å…³ç³»ååˆ é™¤å¼‚å¸¸å€¼ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æ ¹æ®å¯¹åº”ç‚¹ä¹‹é—´çš„æŠ•å½±å°„çº¿è·ç¦»å»é™¤å¼‚å¸¸å€¼ã€‚å‡è®¾ pq å’Œ ps æ˜¯ Iq åˆ° Is ä¸­çš„ä¸€å¯¹ 2D å¯¹åº”å…³ç³»ï¼ŒÏ€q å’Œ Ï€s åˆ†åˆ«æ˜¯ Iq å’Œ Is çš„ä¸–ç•Œåˆ°åƒç´ æŠ•å½±ã€‚ç»™å®šä¸€å¯¹å¯¹åº”å…³ç³»å’Œç›¸æœºå‚æ•°ï¼Œæˆ‘ä»¬è®¡ç®—æ²¿ä»ç›¸æœºä¸­å¿ƒå°„å‡ºçš„ä¸¤æ¡å°„çº¿çš„æœ€è¿‘ 3D ç‚¹ xq å’Œ xsã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™ä¸¤ä¸ª 3D ç‚¹æŠ•å½±åˆ°å¯¹åº”å…³ç³»çš„å›¾åƒå¹³é¢ã€‚æŠ•å½±å°„çº¿è·ç¦» [48] å®šä¹‰ä¸ºæŠ•å½±ç‚¹å’Œå¯¹åº”å…³ç³»ä¹‹é—´çš„å¹³å‡æ¬§å‡ é‡Œå¾—è·ç¦»ï¼š</p>
<p>dproj=âˆ¥Ï€q(xs)âˆ’pqâˆ¥2+âˆ¥Ï€s(xq)âˆ’psâˆ¥22ã€‚</p>
<p>æˆ‘ä»¬åˆ é™¤æŠ•å½±å°„çº¿è·ç¦» dproj å¤§äºé˜ˆå€¼çš„å¯¹åº”å…³ç³»ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬é€šè¿‡æ£€æŸ¥ä¸€ä¸ªç‚¹æ˜¯å¦åœ¨ç»Ÿè®¡ä¸Šè¿œç¦»å…¶é‚»å±…æ¥å»é™¤å¼‚å¸¸å€¼ã€‚å¯¹äºæ¯ä¸€å¯¹å¯¹åº”å…³ç³»ï¼Œå¯ä»¥è·å¾—ä¸¤ä¸ª 3D ç‚¹ xq å’Œ xsï¼Œè¿™å·²ç»åœ¨ä¸Šä¸€æ®µä¸­æŒ‡å‡ºäº†ã€‚ç„¶åï¼Œæˆ‘ä»¬è€ƒè™‘ 12(xq+xs) æ˜¯å¯¹åº”å…³ç³»çš„ 3D ç‚¹ã€‚æˆ‘ä»¬å¯¹æ‰€æœ‰å¯¹åº”å…³ç³»å¯¹æ‰§è¡Œæ­¤æ“ä½œä»¥è·å¾— 3D ç‚¹é›† Pã€‚å¯¹äº P ä¸­çš„æ¯ä¸ª 3D ç‚¹ï¼Œæˆ‘ä»¬è®¡ç®—åˆ°å…¶ k ä¸ªæœ€è¿‘é‚»å±…çš„å¹³å‡è·ç¦»ï¼Œå¦‚æœè·ç¦»å¤§äºé˜ˆå€¼ï¼Œåˆ™åˆ é™¤è¯¥ç‚¹ï¼ˆä»¥åŠå…¶åŒ¹é…çš„å¯¹åº”å…³ç³»å¯¹ï¼‰ã€‚æ­¤é˜ˆå€¼ç”± P ä¸­æ‰€æœ‰ç‚¹çš„å¹³å‡è·ç¦»çš„æ ‡å‡†å·®ç¡®å®šã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å›¾åƒå¯¹åº”å…ˆéªŒæ¥è®­ç»ƒå…·æœ‰ç¨€ç–è§†å›¾è¾“å…¥çš„ç¥ç»è¾å°„åœºçš„æ–°æ–¹æ³•ã€‚æˆ‘ä»¬è®¾è®¡äº†è‡ªåŠ¨å¢å¼ºå’Œè¿‡æ»¤æ–¹æ³•ï¼Œä»¥ä»ç¨€ç–è§†å›¾è¾“å…¥ä¸­ç”Ÿæˆå¯†é›†ä¸”é«˜è´¨é‡çš„å›¾åƒå¯¹åº”å…³ç³»ã€‚æˆ‘ä»¬è®¾è®¡äº†åŸºäºå¯¹åº”å…ˆéªŒçš„é‡æŠ•å½±å’Œæ·±åº¦æŸå¤±é¡¹æ¥æ­£åˆ™åŒ–ç¥ç»è¾å°„åœºè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»…ä½¿ç”¨å°‘é‡è¾“å…¥å›¾åƒå³å¯æ˜¾ç€æé«˜å…‰åº¦å’Œå‡ ä½•åº¦é‡ä¸­è¡¡é‡çš„é‡å»ºè´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>åˆ©ç”¨å›¾åƒå¯¹åº”å…ˆéªŒæ¥ç›‘ç£ç¥ç»è¾å°„åœºè®­ç»ƒï¼Œæé«˜äº†é‡å»ºè´¨é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è‡ªåŠ¨å¢å¼ºå’Œè¿‡æ»¤æ–¹æ³•æ¥ç”Ÿæˆå¯†é›†ä¸”é«˜è´¨é‡çš„å›¾åƒå¯¹åº”å…³ç³»ã€‚</li>
<li>è®¾è®¡äº†åŸºäºå¯¹åº”å…ˆéªŒçš„é‡æŠ•å½±å’Œæ·±åº¦æŸå¤±é¡¹æ¥æ­£åˆ™åŒ–ç¥ç»è¾å°„åœºè®­ç»ƒã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å…·æœ‰å¯†åº¦å’ŒSDFçš„NeRFæ¨¡å‹çš„ä¸åŒæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…‰åº¦å’Œå‡ ä½•åº¦é‡æ–¹é¢éƒ½ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ä½œä¸ºå³æ’å³ç”¨æ¨¡å—åº”ç”¨äºä¸åŒçš„NeRFå˜ä½“ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡ä¸­ç­‰ã€‚éœ€è¦æ”¶é›†å’Œé¢„å¤„ç†æ•°æ®ï¼Œè®­ç»ƒç¥ç»è¾å°„åœºæ¨¡å‹ï¼Œå¹¶è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>æœ¬æ–‡çš„ä»£ç å’Œæ•°æ®å·²å¼€æºï¼Œä¾¿äºå…¶ä»–ç ”ç©¶äººå‘˜ä½¿ç”¨å’Œæ‰©å±•ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bb81a1d85c4890b96c58352034ef526e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0bfbadb767d53f08ad37ade7dcd5b8f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fb67d265cc7f332cd181f46f3137ec9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51f7196d6c0e34d80890742433bf1ba7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-09c23c9b810e3846280b6f7fbd407f08.jpg" align="middle">
</details>
â€‹    


## MVDD: Multi-View Depth Diffusion Models
**Authors:Zhen Wang, Qiangeng Xu, Feitong Tan, Menglei Chai, Shichen Liu, Rohit Pandey, Sean Fanello, Achuta Kadambi, Yinda Zhang**

Denoising diffusion models have demonstrated outstanding results in 2D image generation, yet it remains a challenge to replicate its success in 3D shape generation. In this paper, we propose leveraging multi-view depth, which represents complex 3D shapes in a 2D data format that is easy to denoise. We pair this representation with a diffusion model, MVDD, that is capable of generating high-quality dense point clouds with 20K+ points with fine-grained details. To enforce 3D consistency in multi-view depth, we introduce an epipolar line segment attention that conditions the denoising step for a view on its neighboring views. Additionally, a depth fusion module is incorporated into diffusion steps to further ensure the alignment of depth maps. When augmented with surface reconstruction, MVDD can also produce high-quality 3D meshes. Furthermore, MVDD stands out in other tasks such as depth completion, and can serve as a 3D prior, significantly boosting many downstream tasks, such as GAN inversion. State-of-the-art results from extensive experiments demonstrate MVDD's excellent ability in 3D shape generation, depth completion, and its potential as a 3D prior for downstream tasks. 

[PDF](http://arxiv.org/abs/2312.04875v3) 

**Summary**
å¤šè§†è§’æ·±åº¦è¡¨å¾ä¸æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆï¼Œç”¨äºé«˜æ•ˆä¸”é«˜è´¨é‡çš„ä¸‰ç»´å½¢çŠ¶ç”Ÿæˆã€‚

**Key Takeaways**
- å¤šè§†è§’æ·±åº¦èƒ½å¤Ÿå°†å¤æ‚çš„ä¸‰ç»´å½¢çŠ¶è¡¨ç¤ºä¸ºæ˜“äºå»å™ªçš„äºŒç»´æ•°æ®æ ¼å¼ã€‚
- æå‡ºäº†å¤šè§†è§’æ·±åº¦æ‰©æ•£æ¨¡å‹ MVDDï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰ 20,000 å¤šä¸ªç‚¹çš„åŒ…å«ç²¾ç»†ç»†èŠ‚çš„é«˜è´¨é‡å¯†é›†ç‚¹äº‘ã€‚
- ä»‹ç»äº†ä¸€ç§æçº¿çº¿æ®µæ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥æœºåˆ¶å¯¹è§†å›¾çš„å»å™ªæ­¥éª¤è¿›è¡Œæ¡ä»¶å¤„ç†ï¼Œä»¥ç¡®ä¿å¤šè§†è§’æ·±åº¦ä¸­çš„ä¸‰ç»´ä¸€è‡´æ€§ã€‚
- åŠ å…¥äº†ä¸€ä¸ªæ·±åº¦èåˆæ¨¡å—ï¼Œä»¥è¿›ä¸€æ­¥ç¡®ä¿æ·±åº¦å›¾çš„å¯¹é½ã€‚
- å½“ä½¿ç”¨è¡¨é¢é‡å»ºå¢å¼ºæ—¶ï¼ŒMVDD è¿˜å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´ç½‘æ ¼ã€‚
- MVDD åœ¨æ·±åº¦è¡¥å…¨ç­‰å…¶ä»–ä»»åŠ¡ä¸­è„±é¢–è€Œå‡ºï¼Œå¹¶ä¸”å¯ä»¥ç”¨ä½œä¸‰ç»´å…ˆéªŒï¼Œæå¤§åœ°æé«˜äº†è®¸å¤šä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ï¼Œä¾‹å¦‚ GAN åæ¼”ã€‚
- å¤§é‡å®éªŒçš„æœ€æ–°ç»“æœè¯æ˜äº† MVDD åœ¨ä¸‰ç»´å½¢çŠ¶ç”Ÿæˆã€æ·±åº¦è¡¥å…¨ä»¥åŠä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„ä¸‰ç»´å…ˆéªŒæ–¹é¢çš„å‡ºè‰²èƒ½åŠ›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>æ ‡é¢˜ï¼šMVDDï¼šå¤šè§†å›¾æ·±åº¦æ‰©æ•£æ¨¡å‹</p>
</li>
<li><p>ä½œè€…ï¼šZhen Wang, Qiangeng Xu, Feitong Tan, Menglei Chai, Shichen Liu, Rohit Pandey, Sean Fanello, Achuta Kadambi, Yinda Zhang</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåŠ å·å¤§å­¦æ´›æ‰çŸ¶åˆ†æ ¡</p>
</li>
<li><p>å…³é”®è¯ï¼šæ·±åº¦æ‰©æ•£æ¨¡å‹ã€å¤šè§†å›¾æ·±åº¦ã€3Då½¢çŠ¶ç”Ÿæˆã€å½¢çŠ¶è¡¥å…¨ã€3D GANåæ¼”</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.04875
Github é“¾æ¥ï¼šhttps://github.com/mvdepth/mvdd</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨ 2D å›¾åƒç”Ÿæˆä¸­å–å¾—äº†å‡ºè‰²çš„ç»“æœï¼Œä½†åœ¨ 3D å½¢çŠ¶ç”Ÿæˆä¸­å¤åˆ¶å…¶æˆåŠŸä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨ç‚¹äº‘æˆ–ä½“ç´ è¡¨ç¤ºæ¥ç”Ÿæˆ 3D å½¢çŠ¶ï¼Œä½†è¿™äº›è¡¨ç¤ºéš¾ä»¥å»ºæ¨¡å¤æ‚çš„å½¢çŠ¶ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šè§†å›¾æ·±åº¦æ‰©æ•£æ¨¡å‹ (MVDD)ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨å¤šè§†å›¾æ·±åº¦æ¥è¡¨ç¤ºå¤æ‚çš„ 3D å½¢çŠ¶ã€‚MVDD èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å¯†é›†ç‚¹äº‘ï¼Œå…·æœ‰ 20K+ ä¸ªç‚¹å’Œç²¾ç»†çš„ç»†èŠ‚ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼šMVDD åœ¨ 3D å½¢çŠ¶ç”Ÿæˆã€æ·±åº¦è¡¥å…¨å’Œä½œä¸º 3D GAN åæ¼”çš„å…ˆéªŒç­‰ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚è¿™äº›ç»“æœè¯æ˜äº† MVDD åœ¨ 3D å½¢çŠ¶ç”Ÿæˆå’Œç›¸å…³ä»»åŠ¡ä¸­çš„å‡ºè‰²æ€§èƒ½ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) å¤šè§†å›¾æ·±åº¦æ‰©æ•£æ¨¡å‹ (MVDD)ï¼šMVDD é‡‡ç”¨å¤šè§†å›¾æ·±åº¦æ¥è¡¨ç¤ºå¤æ‚çš„ 3D å½¢çŠ¶ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å¯†é›†ç‚¹äº‘ï¼Œå…·æœ‰ 20K+ ä¸ªç‚¹å’Œç²¾ç»†çš„ç»†èŠ‚ã€‚
(2) è¡¨è§‚çº¿æ®µæ³¨æ„åŠ› (Epipole â€œLine Segmentâ€ Attention)ï¼šMVDD å¼•å…¥äº†ä¸€ç§æœ‰æ•ˆçš„è¡¨è§‚â€œçº¿æ®µâ€æ³¨æ„åŠ›ï¼Œä»¥ä¿ƒè¿›æ‰€æœ‰æ·±åº¦å›¾çš„ä¸€è‡´æ€§ã€‚è¯¥æ³¨æ„åŠ›ä»…å…³æ³¨å…¶ä»–è§†å›¾ä¸Šå¯è§ä½ç½®çš„ç‰¹å¾ï¼Œä»è€Œæé«˜äº†æ•ˆç‡å’Œæœ‰æ•ˆæ€§ã€‚
(3) å»å™ªæ·±åº¦èåˆ (Denoising Depth Fusion)ï¼šä¸ºäº†è¿›ä¸€æ­¥åŠ å¼ºå¤šè§†å›¾æ·±åº¦å›¾çš„æ’åˆ—ï¼ŒMVDD åœ¨æ‰©æ•£æ­¥éª¤ä¸­ç»“åˆäº†æ·±åº¦èåˆã€‚è¯¥èåˆè¿‡ç¨‹å°†æ·±åº¦å›¾æŠ•å½±åˆ°å…¶ä»–è§†å›¾å¹¶è¿›è¡Œæ¯”è¾ƒï¼Œä»¥ç¡®ä¿æ·±åº¦å€¼çš„ä¸€è‡´æ€§ã€‚
(4) è®­ç»ƒç›®æ ‡ï¼šMVDD é‡‡ç”¨ DDPM çš„ç›®æ ‡å‡½æ•°ï¼Œæ—¨åœ¨æœ€å¤§åŒ–å¯¹æ•°ä¼¼ç„¶å‡½æ•°ã€‚è¯¥ç›®æ ‡å‡½æ•°é€šè¿‡æœ€å°åŒ–å™ªå£°ä¼°è®¡è¯¯å·®æ¥å®ç°ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿä»çº¯å™ªå£°ç”Ÿæˆé€¼çœŸçš„æ·±åº¦å›¾ã€‚
(5) åº”ç”¨ï¼šMVDD åœ¨ 3D å½¢çŠ¶ç”Ÿæˆã€æ·±åº¦è¡¥å…¨å’Œä½œä¸º 3DGAN åæ¼”çš„å…ˆéªŒç­‰ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚è¿™äº›ç»“æœè¯æ˜äº† MVDD åœ¨ 3D å½¢çŠ¶ç”Ÿæˆå’Œç›¸å…³ä»»åŠ¡ä¸­çš„å‡ºè‰²æ€§èƒ½ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šMVDD æå‡ºäº†ä¸€ç§å¤šè§†å›¾æ·±åº¦æ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å¯†é›†ç‚¹äº‘ï¼Œå¹¶å…·æœ‰ç²¾ç»†çš„ç»†èŠ‚ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§å¤šè§†å›¾æ·±åº¦æ‰©æ•£æ¨¡å‹ï¼ˆMVDDï¼‰ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨å¤šè§†å›¾æ·±åº¦æ¥è¡¨ç¤ºå¤æ‚çš„ 3D å½¢çŠ¶ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§æœ‰æ•ˆçš„è¡¨è§‚â€œçº¿æ®µâ€æ³¨æ„åŠ›ï¼Œä»¥ä¿ƒè¿›æ‰€æœ‰æ·±åº¦å›¾çš„ä¸€è‡´æ€§ã€‚</li>
<li>ç»“åˆäº†æ·±åº¦èåˆï¼Œä»¥è¿›ä¸€æ­¥åŠ å¼ºå¤šè§†å›¾æ·±åº¦å›¾çš„æ’åˆ—ã€‚
æ€§èƒ½ï¼š</li>
<li>MVDD åœ¨ 3D å½¢çŠ¶ç”Ÿæˆã€æ·±åº¦è¡¥å…¨å’Œä½œä¸º 3DGAN åæ¼”çš„å…ˆéªŒç­‰ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
å·¥ä½œé‡ï¼š</li>
<li>MVDD çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0cd9c4d80e12157224ee5b88f9d1ffc4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-681bf6921d2a2ffb41e0728da51d27c7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f8e93402d2ce303a0694caeced8bf21f.jpg" align="middle">
</details>
â€‹    


## DreamComposer: Controllable 3D Object Generation via Multi-View   Conditions
**Authors:Yunhan Yang, Yukun Huang, Xiaoyang Wu, Yuan-Chen Guo, Song-Hai Zhang, Hengshuang Zhao, Tong He, Xihui Liu**

Utilizing pre-trained 2D large-scale generative models, recent works are capable of generating high-quality novel views from a single in-the-wild image. However, due to the lack of information from multiple views, these works encounter difficulties in generating controllable novel views. In this paper, we present DreamComposer, a flexible and scalable framework that can enhance existing view-aware diffusion models by injecting multi-view conditions. Specifically, DreamComposer first uses a view-aware 3D lifting module to obtain 3D representations of an object from multiple views. Then, it renders the latent features of the target view from 3D representations with the multi-view feature fusion module. Finally the target view features extracted from multi-view inputs are injected into a pre-trained diffusion model. Experiments show that DreamComposer is compatible with state-of-the-art diffusion models for zero-shot novel view synthesis, further enhancing them to generate high-fidelity novel view images with multi-view conditions, ready for controllable 3D object reconstruction and various other applications. 

[PDF](http://arxiv.org/abs/2312.03611v1) Project Page: https://yhyang-myron.github.io/DreamComposer/

**Summary**
å¤šè§†å›¾æ¡ä»¶åŠ©åŠ›åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°è§†è§’ç”Ÿæˆï¼Œå®ç°å¯æ§çš„ä¸‰ç»´é‡å»ºã€‚

**Key Takeaways**

- DreamComposer å¯ä»¥å°†å¤šè§†å›¾æ¡ä»¶æ³¨å…¥åˆ°ç°æœ‰åŸºäºæ‰©æ•£æ¨¡å‹ä¸­ï¼Œä»¥å¢å¼ºå®ƒä»¬ç”Ÿæˆæ–°çš„å¯æ§è§†è§’çš„èƒ½åŠ›ã€‚
- DreamComposer ä½¿ç”¨è§†å›¾æ„ŸçŸ¥ 3D æå‡æ¨¡å—ä»å¤šä¸ªè§†è§’è·å–å¯¹è±¡çš„ 3D è¡¨å¾ï¼Œç„¶åé€šè¿‡å¤šè§†å›¾ç‰¹å¾èåˆæ¨¡å—ä» 3D è¡¨å¾ä¸­æ¸²æŸ“ç›®æ ‡è§†è§’çš„æ½œåœ¨ç‰¹å¾ã€‚
- æå–è‡ªå¤šè§†å›¾è¾“å…¥çš„ç›®æ ‡è§†è§’ç‰¹å¾è¢«æ³¨å…¥åˆ°é¢„å…ˆè®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­ã€‚
- DreamComposer èƒ½ä¸æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹å…¼å®¹ï¼Œç”¨äºé›¶æ ·æœ¬æ–°è§†è§’åˆæˆï¼Œè¿›ä¸€æ­¥å¢å¼ºå®ƒä»¬ç”Ÿæˆé«˜ä¿çœŸæ–°è§†è§’å›¾åƒçš„èƒ½åŠ›ï¼Œæ»¡è¶³å¯æ§ 3D å¯¹è±¡é‡å»ºå’Œå„ç§å…¶ä»–åº”ç”¨çš„éœ€æ±‚ã€‚
- DreamComposer èƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜æœ€ç»ˆåˆæˆå›¾åƒçš„è´¨é‡ï¼Œå°¤å…¶æ˜¯åœ¨ç»†èŠ‚å’Œå‡ ä½•ç»“æ„æ–¹é¢ã€‚
- DreamComposer å¯ä»¥å¤„ç†å„ç§ä¸åŒçš„å¯¹è±¡å’Œåœºæ™¯ï¼Œé²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›å¼ºã€‚
- DreamComposer ä½¿ç”¨é¢„è®­ç»ƒçš„ 2D æ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œæ— éœ€é¢å¤–çš„æ•°æ®æˆ–è®­ç»ƒï¼Œæ˜“äºéƒ¨ç½²å’Œä½¿ç”¨ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šDreamComposerï¼šé€šè¿‡å¤šè§†å›¾æ¡ä»¶ç”Ÿæˆå¯æ§çš„ 3D å¯¹è±¡</p>
</li>
<li><p>ä½œè€…ï¼šYunhan Yangã€Yukun Huangã€Xiaoyang Wuã€Yuan-Chen Guoã€Song-Hai Zhangã€Hengshuang Zhaoã€Tong Heã€Xihui Liu</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šå¯æ§ 3D å¯¹è±¡ç”Ÿæˆã€å¤šè§†å›¾æ¡ä»¶ã€æ‰©æ•£æ¨¡å‹ã€é›¶æ ·æœ¬æ–°è§†è§’åˆæˆ</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.03611ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„ 2D å¤§è§„æ¨¡ç”Ÿæˆæ¨¡å‹ï¼Œæœ€è¿‘çš„å·¥ä½œèƒ½å¤Ÿä»ä¸€å¼ è‡ªç„¶ç•Œå›¾åƒä¸­ç”Ÿæˆé«˜è´¨é‡çš„æ–°è§†è§’ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ¥è‡ªå¤šè§†è§’çš„ä¿¡æ¯ï¼Œè¿™äº›å·¥ä½œåœ¨ç”Ÿæˆå¯æ§çš„æ–°è§†è§’æ—¶é‡åˆ°äº†å›°éš¾ã€‚
(2) è¿‡å»æ–¹æ³•ä¸ä¸è¶³ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨å•ä¸€çš„é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆæ–°è§†è§’ï¼Œä½†è¿™äº›æ¨¡å‹ç¼ºä¹å¯¹å¤šè§†è§’æ¡ä»¶çš„æ§åˆ¶èƒ½åŠ›ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º DreamComposerï¼Œè¿™æ˜¯ä¸€ä¸ªçµæ´»ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼Œå¯ä»¥é€šè¿‡æ³¨å…¥å¤šè§†å›¾æ¡ä»¶æ¥å¢å¼ºç°æœ‰çš„è§†å›¾æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ã€‚å…·ä½“æ¥è¯´ï¼ŒDreamComposer é¦–å…ˆä½¿ç”¨è§†å›¾æ„ŸçŸ¥ 3D æå‡æ¨¡å—ä»å¤šä¸ªè§†å›¾ä¸­è·å¾—å¯¹è±¡çš„ 3D è¡¨ç¤ºã€‚ç„¶åï¼Œå®ƒä½¿ç”¨å¤šè§†å›¾ç‰¹å¾èåˆæ¨¡å—ä» 3D è¡¨ç¤ºä¸­æ¸²æŸ“ç›®æ ‡è§†å›¾çš„æ½œåœ¨ç‰¹å¾ã€‚æœ€åï¼Œå°†ä»å¤šè§†å›¾è¾“å…¥ä¸­æå–çš„ç›®æ ‡è§†å›¾ç‰¹å¾æ³¨å…¥é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ã€‚
(4) å®éªŒç»“æœï¼šå®éªŒè¡¨æ˜ï¼ŒDreamComposer ä¸æœ€å…ˆè¿›çš„ç”¨äºé›¶æ ·æœ¬æ–°è§†è§’åˆæˆçš„æ‰©æ•£æ¨¡å‹å…¼å®¹ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†è¿™äº›æ¨¡å‹ç”Ÿæˆå…·æœ‰å¤šè§†å›¾æ¡ä»¶çš„é«˜ä¿çœŸæ–°è§†è§’å›¾åƒçš„èƒ½åŠ›ï¼Œå¯ç”¨äºå¯æ§ 3D å¯¹è±¡é‡å»ºå’Œå„ç§å…¶ä»–åº”ç”¨ã€‚</p>
</li>
<li><p>Methodsï¼š
(1) è§†å›¾æ„ŸçŸ¥3Dæå‡æ¨¡å—ï¼šè¯¥æ¨¡å—ä»å¤šä¸ªè§†å›¾ä¸­è·å¾—å¯¹è±¡çš„3Dè¡¨ç¤ºã€‚å®ƒé¦–å…ˆä½¿ç”¨é¢„è®­ç»ƒçš„2Dæ‰©æ•£æ¨¡å‹ä»æ¯ä¸ªè§†å›¾ä¸­ç”Ÿæˆå¯¹è±¡çš„2Dè¡¨ç¤ºï¼Œç„¶åå°†è¿™äº›2Dè¡¨ç¤ºæŠ•å½±åˆ°3Dç©ºé—´ä¸­ï¼Œå¹¶ä½¿ç”¨3Då·ç§¯ç½‘ç»œèåˆè¿™äº›æŠ•å½±ï¼Œä»¥è·å¾—å¯¹è±¡çš„3Dè¡¨ç¤ºã€‚
(2) å¤šè§†å›¾ç‰¹å¾èåˆæ¨¡å—ï¼šè¯¥æ¨¡å—ä»3Dè¡¨ç¤ºä¸­æ¸²æŸ“ç›®æ ‡è§†å›¾çš„æ½œåœ¨ç‰¹å¾ã€‚å®ƒé¦–å…ˆä½¿ç”¨3Dæ¸²æŸ“å™¨å°†3Dè¡¨ç¤ºæ¸²æŸ“æˆç›®æ ‡è§†å›¾çš„2Då›¾åƒï¼Œç„¶åä½¿ç”¨é¢„è®­ç»ƒçš„2Dæ‰©æ•£æ¨¡å‹ä»2Då›¾åƒä¸­æå–æ½œåœ¨ç‰¹å¾ã€‚
(3) å¤šè§†å›¾æ¡ä»¶æ³¨å…¥æ¨¡å—ï¼šè¯¥æ¨¡å—å°†ä»å¤šè§†å›¾è¾“å…¥ä¸­æå–çš„ç›®æ ‡è§†å›¾ç‰¹å¾æ³¨å…¥é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ã€‚å®ƒé¦–å…ˆå°†ç›®æ ‡è§†å›¾çš„æ½œåœ¨ç‰¹å¾ä¸é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç‰¹å¾è¿›è¡Œæ‹¼æ¥ï¼Œç„¶åä½¿ç”¨ä¸€ä¸ªçº¿æ€§å±‚å°†æ‹¼æ¥åçš„ç‰¹å¾æŠ•å½±åˆ°é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ä¸­ã€‚
(4) æ‰©æ•£æ¨¡å‹ç”Ÿæˆï¼šå°†æ³¨å…¥å¤šè§†å›¾æ¡ä»¶çš„æ½œåœ¨ç‰¹å¾è¾“å…¥é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆç›®æ ‡è§†å›¾çš„æ–°è§†è§’å›¾åƒã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šDreamComposer æ¡†æ¶æå‡ºäº†ä¸€ä¸ªçµæ´»ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼Œå¯ä»¥é€šè¿‡æ³¨å…¥å¤šè§†å›¾æ¡ä»¶æ¥å¢å¼ºç°æœ‰çš„è§†å›¾æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œä»è€Œç”Ÿæˆå…·æœ‰å¤šè§†å›¾æ¡ä»¶çš„é«˜ä¿çœŸæ–°è§†è§’å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è§†å›¾æ„ŸçŸ¥ 3D æå‡æ¨¡å—ï¼Œå¯ä»¥ä»å¤šä¸ªè§†å›¾ä¸­è·å¾—å¯¹è±¡çš„ 3D è¡¨ç¤ºã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å¤šè§†å›¾ç‰¹å¾èåˆæ¨¡å—ï¼Œå¯ä»¥ä» 3D è¡¨ç¤ºä¸­æ¸²æŸ“ç›®æ ‡è§†å›¾çš„æ½œåœ¨ç‰¹å¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å¤šè§†å›¾æ¡ä»¶æ³¨å…¥æ¨¡å—ï¼Œå¯ä»¥å°†ä»å¤šè§†å›¾è¾“å…¥ä¸­æå–çš„ç›®æ ‡è§†å›¾ç‰¹å¾æ³¨å…¥é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ã€‚
æ€§èƒ½ï¼š</li>
<li>DreamComposer ä¸æœ€å…ˆè¿›çš„ç”¨äºé›¶æ ·æœ¬æ–°è§†è§’åˆæˆçš„æ‰©æ•£æ¨¡å‹å…¼å®¹ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†è¿™äº›æ¨¡å‹ç”Ÿæˆå…·æœ‰å¤šè§†å›¾æ¡ä»¶çš„é«˜ä¿çœŸæ–°è§†è§’å›¾åƒçš„èƒ½åŠ›ã€‚
å·¥ä½œé‡ï¼š</li>
<li>DreamComposer æ¡†æ¶çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä½¿ç”¨ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-168607583ef1e4f58b3bdcd4803e43c5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33dcfafc8394f58e1dbd724842a101fb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-93b23a2d6c08c410dd4391267ba17622.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29ce8934dd91a9c823f4314c0c68127d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0e0119c153d54525b574ef2a92843a1d.jpg" align="middle">
</details>
â€‹    


## HOLD: Category-agnostic 3D Reconstruction of Interacting Hands and   Objects from Video
**Authors:Zicong Fan, Maria Parelli, Maria Eleni Kadoglou, Muhammed Kocabas, Xu Chen, Michael J. Black, Otmar Hilliges**

Since humans interact with diverse objects every day, the holistic 3D capture of these interactions is important to understand and model human behaviour. However, most existing methods for hand-object reconstruction from RGB either assume pre-scanned object templates or heavily rely on limited 3D hand-object data, restricting their ability to scale and generalize to more unconstrained interaction settings. To this end, we introduce HOLD -- the first category-agnostic method that reconstructs an articulated hand and object jointly from a monocular interaction video. We develop a compositional articulated implicit model that can reconstruct disentangled 3D hand and object from 2D images. We also further incorporate hand-object constraints to improve hand-object poses and consequently the reconstruction quality. Our method does not rely on 3D hand-object annotations while outperforming fully-supervised baselines in both in-the-lab and challenging in-the-wild settings. Moreover, we qualitatively show its robustness in reconstructing from in-the-wild videos. Code: https://github.com/zc-alexfan/hold 

[PDF](http://arxiv.org/abs/2311.18448v1) 

**Summary**
æ— é¡»å…ˆéªŒçŸ¥è¯†ï¼Œä»…ä»å•ç›®äº¤äº’è§†é¢‘ä¸­ï¼Œå°±èƒ½å¯¹é“°æ¥æ‰‹å’Œç‰©ä½“è¿›è¡Œè”åˆé‡å»ºã€‚

**Key Takeaways**

- HOLD æ˜¯ä¸€ç§æ— éœ€ç±»åˆ«ä¿¡æ¯çš„é€šç”¨æ–¹æ³•ï¼Œå¯ä»¥ä»…ä»å•ç›®äº¤äº’è§†é¢‘ä¸­é‡å»ºé“°æ¥æ‰‹å’Œç‰©ä½“ã€‚
- HOLD ä½¿ç”¨å¤åˆé“°æ¥éšå¼æ¨¡å‹æ¥é‡å»ºä» 2D å›¾åƒä¸­åˆ†ç¦»å‡ºçš„ 3D æ‰‹å’Œç‰©ä½“ã€‚
- HOLD è¿˜è¿›ä¸€æ­¥åŠ å…¥äº†æ‰‹ç‰©ä½“çº¦æŸï¼Œä»¥æ”¹è¿›æ‰‹ç‰©ä½“å§¿åŠ¿ï¼Œä»è€Œæå‡é‡å»ºè´¨é‡ã€‚
- HOLD æ— éœ€ 3D æ‰‹ç‰©ä½“æ³¨é‡Šï¼Œå³ä¾¿åœ¨å®éªŒå®¤å’Œæå…·æŒ‘æˆ˜æ€§çš„é‡å¤–ç¯å¢ƒä¸­ï¼Œä¹Ÿèƒ½ä¼˜äºå®Œå…¨ç›‘ç£çš„åŸºçº¿æ–¹æ³•ã€‚
- HOLD åœ¨é‡å»ºé‡å¤–è§†é¢‘æ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚
- HOLD é€‚ç”¨äºå¹¿æ³›çš„äº’åŠ¨åœºæ™¯ï¼ŒåŒ…æ‹¬æŠ“å–ã€æ“ä½œå’Œæ“çºµã€‚
- HOLD å¯ä»¥ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚åŠ¨ä½œè¯†åˆ«å’Œæ‰‹åŠ¿è¯†åˆ«ï¼‰çš„è¾…åŠ©å·¥å…·ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šHOLDï¼šä»è§†é¢‘ä¸­è¿›è¡Œç±»åˆ«æ— å…³çš„äº¤äº’æ‰‹å’Œç‰©ä½“çš„ 3D é‡å»º</li>
<li>ä½œè€…ï¼šZicong Fan, Maria Parelli, Maria Eleni Kadoglou, Muhammed Kocabas, Xu Chen, Michael J. Black, Otmar Hilliges</li>
<li>éš¶å±å•ä½ï¼šè‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢ï¼Œå¾·å›½å›¾å®¾æ ¹é©¬å…‹æ–¯æ™®æœ—å…‹æ™ºèƒ½ç³»ç»Ÿç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼š3D é‡å»ºã€æ‰‹éƒ¨å¯¹è±¡äº¤äº’ã€éšå¼ç¥ç»è¡¨ç¤ºã€çº¦æŸä¼˜åŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.18448ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/zc-alexfan/hold</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šäººç±»æ¯å¤©éƒ½ä¼šä¸å„ç§ç‰©ä½“äº’åŠ¨ï¼Œå› æ­¤å…¨é¢æ•æ‰è¿™äº›äº’åŠ¨å¯¹äºç†è§£å’Œå»ºæ¨¡äººç±»è¡Œä¸ºéå¸¸é‡è¦ã€‚ç„¶è€Œï¼Œç›®å‰å¤§å¤šæ•°ç”¨äºä» RGB å›¾åƒè¿›è¡Œæ‰‹éƒ¨ç‰©ä½“é‡å»ºçš„æ–¹æ³•è¦ä¹ˆå‡è®¾é¢„å…ˆæ‰«æçš„å¯¹è±¡æ¨¡æ¿ï¼Œè¦ä¹ˆä¸¥é‡ä¾èµ–æœ‰é™çš„ 3D æ‰‹éƒ¨ç‰©ä½“æ•°æ®ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨æ›´ä¸å—çº¦æŸçš„äº¤äº’åœºæ™¯ä¸­çš„æ‰©å±•å’Œæ³›åŒ–èƒ½åŠ›ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æ–¹æ³•çš„åŠ¨æœºï¼šç°æœ‰æ–¹æ³•è¦ä¹ˆå‡è®¾é¢„å…ˆæ‰«æçš„å¯¹è±¡æ¨¡æ¿ï¼Œè¦ä¹ˆä¸¥é‡ä¾èµ–æœ‰é™çš„ 3D æ‰‹éƒ¨ç‰©ä½“æ•°æ®ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨æ›´ä¸å—çº¦æŸçš„äº¤äº’åœºæ™¯ä¸­çš„æ‰©å±•å’Œæ³›åŒ–èƒ½åŠ›ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º HOLD çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä»å•ç›®äº¤äº’è§†é¢‘ä¸­é‡å»ºé“°æ¥æ‰‹å’Œç‰©ä½“ã€‚HOLD ä½¿ç”¨äº†ä¸€ç§ç»„åˆå…³èŠ‚éšå¼æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä» 2D å›¾åƒé‡å»ºåˆ†ç¦»çš„ 3D æ‰‹éƒ¨å’Œç‰©ä½“ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜è¿›ä¸€æ­¥ç»“åˆäº†æ‰‹éƒ¨ç‰©ä½“çº¦æŸæ¥æ”¹è¿›æ‰‹éƒ¨ç‰©ä½“å§¿åŠ¿ï¼Œä»è€Œæé«˜é‡å»ºè´¨é‡ã€‚
(4)ï¼šæ–¹æ³•çš„æ€§èƒ½ï¼šHOLD æ–¹æ³•åœ¨å®éªŒå®¤å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„é‡å¤–åœºæ™¯ä¸­å‡ä¼˜äºå®Œå…¨ç›‘ç£çš„åŸºçº¿ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å®šæ€§åœ°å±•ç¤ºäº†å…¶ä»é‡å¤–è§†é¢‘ä¸­é‡å»ºçš„é²æ£’æ€§ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶çš„æ„ä¹‰ï¼š
æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º HOLD çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä»å•ç›®äº¤äº’è§†é¢‘ä¸­é‡å»ºé“°æ¥æ‰‹å’Œç‰©ä½“ã€‚HOLD ä½¿ç”¨äº†ä¸€ç§ç»„åˆå…³èŠ‚éšå¼æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä» 2D å›¾åƒé‡å»ºåˆ†ç¦»çš„ 3D æ‰‹éƒ¨å’Œç‰©ä½“ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜è¿›ä¸€æ­¥ç»“åˆäº†æ‰‹éƒ¨ç‰©ä½“çº¦æŸæ¥æ”¹è¿›æ‰‹éƒ¨ç‰©ä½“å§¿åŠ¿ï¼Œä»è€Œæé«˜é‡å»ºè´¨é‡ã€‚HOLD æ–¹æ³•åœ¨å®éªŒå®¤å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„é‡å¤–åœºæ™¯ä¸­å‡ä¼˜äºå®Œå…¨ç›‘ç£çš„åŸºçº¿ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å®šæ€§åœ°å±•ç¤ºäº†å…¶ä»é‡å¤–è§†é¢‘ä¸­é‡å»ºçš„é²æ£’æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡çš„ä¼˜ç¼ºç‚¹ï¼š
åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åä¸º HOLD çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä»å•ç›®äº¤äº’è§†é¢‘ä¸­é‡å»ºé“°æ¥æ‰‹å’Œç‰©ä½“ã€‚</li>
<li>ä½¿ç”¨äº†ä¸€ç§ç»„åˆå…³èŠ‚éšå¼æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä» 2D å›¾åƒé‡å»ºåˆ†ç¦»çš„ 3D æ‰‹éƒ¨å’Œç‰©ä½“ã€‚</li>
<li>è¿›ä¸€æ­¥ç»“åˆäº†æ‰‹éƒ¨ç‰©ä½“çº¦æŸæ¥æ”¹è¿›æ‰‹éƒ¨ç‰©ä½“å§¿åŠ¿ï¼Œä»è€Œæé«˜é‡å»ºè´¨é‡ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š</p>
<ol>
<li>HOLD æ–¹æ³•åœ¨å®éªŒå®¤å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„é‡å¤–åœºæ™¯ä¸­å‡ä¼˜äºå®Œå…¨ç›‘ç£çš„åŸºçº¿ã€‚</li>
<li>HOLD æ–¹æ³•ä»é‡å¤–è§†é¢‘ä¸­é‡å»ºçš„é²æ£’æ€§å¼ºã€‚</li>
</ol>
<p>å·¥ä½œé‡ï¼š</p>
<ol>
<li>HOLD æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>HOLD æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹æ¯”è¾ƒå¤æ‚ã€‚</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-415ee1a9b6ee2ab5c473c2f0dda0e51e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c2ea9ec163c36ce8e5caba3457d81b7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ac62d03408862e6758b781f5f9d3f4f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ad526669e8557416b88d13528a10f59.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="HumanRecon-Neural-Reconstruction-of-Dynamic-Human-Using-Geometric-Cues-and-Physical-Priors"><a href="#HumanRecon-Neural-Reconstruction-of-Dynamic-Human-Using-Geometric-Cues-and-Physical-Priors" class="headerlink" title="HumanRecon: Neural Reconstruction of Dynamic Human Using Geometric Cues   and Physical Priors"></a>HumanRecon: Neural Reconstruction of Dynamic Human Using Geometric Cues   and Physical Priors</h2><p><strong>Authors:Junhui Yin, Wei Yin, Hao Chen, Xuqian Ren, Zhanyu Ma, Jun Guo, Yifan Liu</strong></p>
<p>Recent methods for dynamic human reconstruction have attained promising reconstruction results. Most of these methods rely only on RGB color supervision without considering explicit geometric constraints. This leads to existing human reconstruction techniques being more prone to overfitting to color and causes geometrically inherent ambiguities, especially in the sparse multi-view setup.   Motivated by recent advances in the field of monocular geometry prediction, we consider the geometric constraints of estimated depth and normals in the learning of neural implicit representation for dynamic human reconstruction. As a geometric regularization, this provides reliable yet explicit supervision information, and improves reconstruction quality. We also exploit several beneficial physical priors, such as adding noise into view direction and maximizing the density on the human surface. These priors ensure the color rendered along rays to be robust to view direction and reduce the inherent ambiguities of density estimated along rays. Experimental results demonstrate that depth and normal cues, predicted by human-specific monocular estimators, can provide effective supervision signals and render more accurate images. Finally, we also show that the proposed physical priors significantly reduce overfitting and improve the overall quality of novel view synthesis. Our code is available at:~\href{<a href="https://github.com/PRIS-CV/HumanRecon}{https://github.com/PRIS-CV/HumanRecon}">https://github.com/PRIS-CV/HumanRecon}{https://github.com/PRIS-CV/HumanRecon}</a>. </p>
<p><a href="http://arxiv.org/abs/2311.15171v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨æ·±åº¦å’Œæ³•å‘é‡ä½œä¸ºå‡ ä½•æ­£åˆ™åŒ–ï¼Œæé«˜ç¥ç»éšå¼è¡¨ç¤ºåŠ¨æ€äººä½“é‡å»ºçš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ·±åº¦å’Œæ³•å‘é‡æ˜¯äººä½“é‡å»ºçš„å…³é”®å‡ ä½•çº¦æŸã€‚</li>
<li>ä½¿ç”¨æ·±åº¦å’Œæ³•å‘é‡ä½œä¸ºç›‘ç£ä¿¡æ¯å¯ä»¥æé«˜é‡å»ºè´¨é‡ã€‚</li>
<li>åŠ å…¥å™ªå£°åˆ°è§†è§’ä¸­å¯ä»¥ä½¿é¢œè‰²æ¸²æŸ“æ›´é²æ£’ã€‚</li>
<li>æœ€å¤§åŒ–äººä½“è¡¨é¢çš„å¯†åº¦å¯ä»¥å‡å°‘å¯†åº¦ä¼°è®¡çš„å›ºæœ‰äºŒä¹‰æ€§ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæ·±åº¦å’Œæ³•å‘é‡çº¿ç´¢å¯ä»¥æä¾›æœ‰æ•ˆçš„ç›‘ç£ä¿¡å·å¹¶å‘ˆç°æ›´å‡†ç¡®çš„å›¾åƒã€‚</li>
<li>æå‡ºç‰©ç†å…ˆéªŒæ˜¾è‘—å‡å°‘äº†è¿‡æ‹Ÿåˆå¹¶æé«˜äº†æ–°è§†è§’åˆæˆçš„æ€»ä½“è´¨é‡ã€‚</li>
<li>ä»£ç å¯åœ¨ GitHub ä¸Šè·å–ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šHumanReconï¼šåˆ©ç”¨å‡ ä½•çº¿ç´¢å’Œç‰©ç†å…ˆéªŒçš„ç¥ç»é‡å»ºåŠ¨æ€äººä½“</li>
<li>ä½œè€…ï¼šJunhui Yinã€Wei Yinã€Hao Chenã€Xuqian Renã€Zhanyu Maã€Jun Guo å’Œ Yifan Liu</li>
<li>å•ä½ï¼šåŒ—äº¬é‚®ç”µå¤§å­¦</li>
<li>å…³é”®è¯ï¼šåŠ¨æ€äººä½“é‡å»ºã€ç¥ç»éšå¼è¡¨ç¤ºã€å‡ ä½•çº¦æŸã€ç‰©ç†å…ˆéªŒ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.15171
Github é“¾æ¥ï¼šhttps://github.com/PRIS-CV/HumanRecon</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šåŠ¨æ€äººä½“é‡å»ºæ˜¯è®¡ç®—æœºè§†è§‰ç ”ç©¶ä¸­çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜ï¼Œåœ¨æœºå™¨äººæŠ€æœ¯ã€å›¾å½¢å­¦ã€å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®å’Œäººä½“æ•°å­—åŒ–ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚ç„¶è€Œï¼Œä» RGB å›¾åƒå’Œè§†é¢‘ä¸­é‡å»ºåŠ¨æ€äººä½“æå…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè¿™äº›æ•°æ®ç¼ºä¹è¶³å¤Ÿçš„ç›‘ç£ä¿¡æ¯ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•ï¼šä¼ ç»Ÿçš„äººä½“å»ºæ¨¡å·¥ä½œä½¿ç”¨æ˜¾å¼ç½‘æ ¼æ¥è¡¨ç¤ºäººä½“å‡ ä½•å½¢çŠ¶ï¼Œå¹¶å°†å¤–è§‚å­˜å‚¨åœ¨ 2D çº¹ç†è´´å›¾ä¸­ã€‚ä½†æ˜¯ï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¯†é›†çš„æ‘„åƒå¤´é˜µåˆ—å’Œå—æ§çš„ç…§æ˜æ¡ä»¶ã€‚è¿‘å¹´æ¥ï¼ŒPIFuã€StereoPIFu å’Œ PIFuHD ç­‰æ–¹æ³•æå‡ºä½¿ç”¨åƒç´ çº§å›¾åƒç‰¹å¾å›å½’ç¥ç»éšå¼å‡½æ•°ï¼Œèƒ½å¤Ÿé‡å»ºé«˜åˆ†è¾¨ç‡çš„è¡£ç€äººä½“ç»“æœã€‚ARCH æ–¹æ³•å°†ä¸€ç³»åˆ— PIFu æ–¹æ³•æ‰©å±•åˆ°ä»å•ç›®å›¾åƒä¸­å›å½’å¯åŠ¨ç”»çš„è¡£ç€äººä½“åŒ–èº«ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•æ— æ³•ä»ç¨€ç–çš„å¤šè§†è§’è§†é¢‘ä¸­é‡å»ºåŠ¨æ€çš„è¡£ç€äººä½“ã€‚
ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€äººä½“é‡å»ºæ–¹æ³• HumanReconï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å‡ ä½•çº¿ç´¢å’Œç‰©ç†å…ˆéªŒæ¥å­¦ä¹ ç¥ç»éšå¼è¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼ŒHumanRecon ä½¿ç”¨å•ç›®å‡ ä½•ä¼°è®¡å™¨é¢„æµ‹æ·±åº¦å’Œæ³•çº¿çº¿ç´¢ï¼Œå¹¶å°†å…¶ä½œä¸ºå‡ ä½•æ­£åˆ™åŒ–é¡¹æ·»åŠ åˆ°ç¥ç»éšå¼è¡¨ç¤ºçš„å­¦ä¹ ä¸­ã€‚æ­¤å¤–ï¼ŒHumanRecon è¿˜åˆ©ç”¨äº†å‡ ç§æœ‰ç›Šçš„ç‰©ç†å…ˆéªŒï¼Œä¾‹å¦‚åœ¨è§†å‘ä¸­æ·»åŠ å™ªå£°å’Œæœ€å¤§åŒ–äººä½“è¡¨é¢çš„å¯†åº¦ã€‚è¿™äº›å…ˆéªŒç¡®ä¿äº†æ²¿å°„çº¿æ¸²æŸ“çš„é¢œè‰²å¯¹è§†å‘å…·æœ‰é²æ£’æ€§ï¼Œå¹¶å‡å°‘äº†æ²¿å°„çº¿ä¼°è®¡çš„å¯†åº¦çš„å›ºæœ‰æ­§ä¹‰æ€§ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œç”±ç‰¹å®šäºäººç±»çš„å•ç›®ä¼°è®¡å™¨é¢„æµ‹çš„æ·±åº¦å’Œæ³•çº¿çº¿ç´¢å¯ä»¥æä¾›æœ‰æ•ˆçš„ç›‘ç£ä¿¡å·å¹¶æ¸²æŸ“æ›´å‡†ç¡®çš„å›¾åƒã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æå‡ºçš„ç‰©ç†å…ˆéªŒå¯ä»¥æ˜¾ç€å‡å°‘è¿‡æ‹Ÿåˆå¹¶æé«˜æ–°è§†è§’åˆæˆçš„æ•´ä½“è´¨é‡ã€‚</li>
</ol>
<p><strong>æ–¹æ³•</strong>ï¼š</p>
<p>(1)ï¼šHumanReconåˆ©ç”¨å•ç›®å‡ ä½•ä¼°è®¡å™¨é¢„æµ‹æ·±åº¦å’Œæ³•çº¿çº¿ç´¢ï¼Œå¹¶å°†å…¶ä½œä¸ºå‡ ä½•æ­£åˆ™åŒ–é¡¹æ·»åŠ åˆ°ç¥ç»éšå¼è¡¨ç¤ºçš„å­¦ä¹ ä¸­ã€‚</p>
<p>(2)ï¼šHumanReconåˆ©ç”¨äº†å‡ ç§æœ‰ç›Šçš„ç‰©ç†å…ˆéªŒï¼Œä¾‹å¦‚åœ¨è§†å‘ä¸­æ·»åŠ å™ªå£°å’Œæœ€å¤§åŒ–äººä½“è¡¨é¢çš„å¯†åº¦ã€‚</p>
<p>(3)ï¼šHumanReconä½¿ç”¨ç¥ç»éšå¼è¡¨ç¤ºæ¥å­¦ä¹ åŠ¨æ€äººä½“çš„å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚ï¼Œå¹¶åˆ©ç”¨å‡ ä½•çº¿ç´¢å’Œç‰©ç†å…ˆéªŒæ¥æé«˜é‡å»ºçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€äººä½“é‡å»ºæ–¹æ³• HumanReconï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å‡ ä½•çº¿ç´¢å’Œç‰©ç†å…ˆéªŒæ¥å­¦ä¹ ç¥ç»éšå¼è¡¨ç¤ºï¼Œèƒ½å¤Ÿä»ç¨€ç–çš„å¤šè§†è§’è§†é¢‘ä¸­é‡å»ºåŠ¨æ€çš„è¡£ç€äººä½“ï¼Œåœ¨å…¬å…±æ•°æ®é›†ä¸Šå–å¾—äº†æœ€ä¼˜çš„é‡å»ºæ•ˆæœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
HumanRecon æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€äººä½“é‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å‡ ä½•çº¿ç´¢å’Œç‰©ç†å…ˆéªŒæ¥å­¦ä¹ ç¥ç»éšå¼è¡¨ç¤ºï¼Œèƒ½å¤Ÿä»ç¨€ç–çš„å¤šè§†è§’è§†é¢‘ä¸­é‡å»ºåŠ¨æ€çš„è¡£ç€äººä½“ã€‚
æ€§èƒ½ï¼š
HumanRecon åœ¨å…¬å…±æ•°æ®é›†ä¸Šå–å¾—äº†æœ€ä¼˜çš„é‡å»ºæ•ˆæœã€‚
å·¥ä½œé‡ï¼š
HumanRecon çš„å·¥ä½œé‡ä¸­ç­‰ï¼Œéœ€è¦æ”¶é›†ç¨€ç–çš„å¤šè§†è§’è§†é¢‘æ•°æ®ï¼Œå¹¶ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œè®­ç»ƒã€‚</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-53aa17faea82b5e0fdbbccd7e38ab3f0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-efb4eebe5bbbb5efc58baa3b2148c347.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3423434440b10282e759bb59440bd5e3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bb5324e9f58f0fec825b0268ffd59901.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cc59c128bbcbd6e5e97f759649f953d4.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Unsupervised-Graph-Attention-Autoencoder-for-Attributed-Networks-using-K-means-Loss"><a href="#Unsupervised-Graph-Attention-Autoencoder-for-Attributed-Networks-using-K-means-Loss" class="headerlink" title="Unsupervised Graph Attention Autoencoder for Attributed Networks using   K-means Loss"></a>Unsupervised Graph Attention Autoencoder for Attributed Networks using   K-means Loss</h2><p><strong>Authors:Abdelfateh Bekkair, Slimane Bellaouar, Slimane Oulad-Naoui</strong></p>
<p>Several natural phenomena and complex systems are often represented as networks. Discovering their community structure is a fundamental task for understanding these networks. Many algorithms have been proposed, but recently, Graph Neural Networks (GNN) have emerged as a compelling approach for enhancing this task.In this paper, we introduce a simple, efficient, and clustering-oriented model based on unsupervised \textbf{G}raph Attention \textbf{A}uto\textbf{E}ncoder for community detection in attributed networks (GAECO). The proposed model adeptly learns representations from both the networkâ€™s topology and attribute information, simultaneously addressing dual objectives: reconstruction and community discovery. It places a particular emphasis on discovering compact communities by robustly minimizing clustering errors. The model employs k-means as an objective function and utilizes a multi-head Graph Attention Auto-Encoder for decoding the representations. Experiments conducted on three datasets of attributed networks show that our method surpasses state-of-the-art algorithms in terms of NMI and ARI. Additionally, our approach scales effectively with the size of the network, making it suitable for large-scale applications. The implications of our findings extend beyond biological network interpretation and social network analysis, where knowledge of the fundamental community structure is essential. </p>
<p><a href="http://arxiv.org/abs/2311.12986v2">PDF</a> 7 pages, 5 Figures</p>
<p><strong>æ‘˜è¦</strong><br>æ— ç›‘ç£å›¾æ³¨æ„åŠ›è‡ªåŠ¨ç¼–ç å™¨æ–¹æ³•æœ‰æ•ˆåœ°æå–äº†ç”Ÿç‰©å’Œç¤¾äº¤å…³ç³»ç½‘ç»œä¸­çš„ç¤¾åŒºç»“æ„ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§ç®€å•ã€é«˜æ•ˆã€é¢å‘èšç±»çš„æ— ç›‘ç£å›¾æ³¨æ„åŠ›è‡ªåŠ¨ç¼–ç å™¨æ–¹æ³•ï¼Œç”¨äºå‘ç°å±æ€§ç½‘ç»œä¸­çš„ç¤¾åŒºç»“æ„ã€‚</li>
<li>è¯¥æ¨¡å‹èƒ½å¤ŸåŒæ—¶å­¦ä¹ ç½‘ç»œæ‹“æ‰‘å’Œå±æ€§ä¿¡æ¯ï¼Œå¹¶ä»¥é‡å»ºå’Œç¤¾åŒºå‘ç°ä¸ºåŒé‡ç›®æ ‡ã€‚</li>
<li>è¯¥æ¨¡å‹é€šè¿‡ç¨³å¥åœ°æœ€å°åŒ–èšç±»è¯¯å·®ï¼Œç‰¹åˆ«å¼ºè°ƒå‘ç°ç´§å‡‘çš„ç¤¾åŒºã€‚</li>
<li>è¯¥æ¨¡å‹é‡‡ç”¨kå‡å€¼ä½œä¸ºç›®æ ‡å‡½æ•°ï¼Œå¹¶ä½¿ç”¨å¤šå¤´å›¾æ³¨æ„è‡ªåŠ¨ç¼–ç å™¨å¯¹è¡¨ç¤ºè¿›è¡Œè§£ç ã€‚</li>
<li>åœ¨ä¸‰ä¸ªå±æ€§ç½‘ç»œæ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨NMIå’ŒARIæ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„ç®—æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•è¿˜å¯ä»¥æœ‰æ•ˆåœ°æ‰©å±•åˆ°ç½‘ç»œè§„æ¨¡ï¼Œä½¿å…¶é€‚ç”¨äºå¤§è§„æ¨¡åº”ç”¨ã€‚</li>
<li>è¯¥æ–¹æ³•çš„åº”ç”¨èŒƒå›´ä¸ä»…é™äºç”Ÿç‰©ç½‘ç»œè§£é‡Šå’Œç¤¾äº¤ç½‘ç»œåˆ†æï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œäº†è§£åŸºæœ¬çš„ç¤¾åŒºç»“æ„è‡³å…³é‡è¦ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li>è®ºæ–‡æ ‡é¢˜ï¼šæ— ç›‘ç£å›¾æ³¨æ„åŠ›è‡ªç¼–ç å™¨ç”¨äºå±æ€§ç½‘ç»œ</li><p></p>
<p></p><li>ä½œè€…ï¼šAbdelfateh Bekkaira, Slimane Bellaouara, Slimane Oulad-Naouia</li><p></p>
<p></p><li>æ‰€å±å•ä½ï¼šé˜¿å°”åŠåˆ©äºšæ ¼å“ˆè¾¾äºšå¤§å­¦æ•°å­¦ä¸è®¡ç®—æœºç§‘å­¦ç³»</li><p></p>
<p></p><li>å…³é”®è¯ï¼šå›¾æ³¨æ„åŠ›ç½‘ç»œã€è‡ªç¼–ç å™¨ã€æ— ç›‘ç£å­¦ä¹ ã€ç¤¾åŒºæ£€æµ‹</li><p></p>
<p></p><li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.12986</li><p></p>
<p></p><li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¤¾åŒºæ£€æµ‹æ˜¯å›¾åˆ†æä¸­çš„ä¸€é¡¹é‡è¦ä»»åŠ¡ï¼Œæ—¨åœ¨å°†å›¾ä¸­çš„èŠ‚ç‚¹åˆ’åˆ†ä¸ºä¸åŒçš„ç¤¾åŒºï¼Œä½¿ç¤¾åŒºå†…çš„èŠ‚ç‚¹è¿æ¥ç´§å¯†ï¼Œç¤¾åŒºä¹‹é—´çš„èŠ‚ç‚¹è¿æ¥ç¨€ç–ã€‚ä¼ ç»Ÿç¤¾åŒºæ£€æµ‹æ–¹æ³•ä¸»è¦åŸºäºå›¾çš„ç»“æ„ä¿¡æ¯ï¼Œè€Œè¿‘å¹´æ¥æå‡ºçš„å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰å¯ä»¥åŒæ—¶è€ƒè™‘å›¾çš„ç»“æ„ä¿¡æ¯å’ŒèŠ‚ç‚¹çš„å±æ€§ä¿¡æ¯ï¼Œåœ¨ç¤¾åŒºæ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ•ˆæœã€‚ç„¶è€Œï¼Œç°æœ‰çš„GATæ¨¡å‹å¤§å¤šæ˜¯ç›‘ç£å­¦ä¹ æ¨¡å‹ï¼Œéœ€è¦å¤§é‡çš„æ ‡è®°æ•°æ®è¿›è¡Œè®­ç»ƒã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>éœ€è¦å¤§é‡çš„æ ‡è®°æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­å¾€å¾€éš¾ä»¥è·å¾—ã€‚</li>
<li>éš¾ä»¥å¤„ç†å¤§è§„æ¨¡å›¾æ•°æ®ã€‚</li>
<li>å¯¹å›¾çš„ç»“æ„å’Œå±æ€§ä¿¡æ¯åˆ©ç”¨ä¸è¶³ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£å›¾æ³¨æ„åŠ›è‡ªç¼–ç å™¨ï¼ˆGAECOï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åŒæ—¶åˆ©ç”¨å›¾çš„ç»“æ„ä¿¡æ¯å’ŒèŠ‚ç‚¹çš„å±æ€§ä¿¡æ¯è¿›è¡Œç¤¾åŒºæ£€æµ‹ã€‚GAECOæ¨¡å‹çš„ç»“æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</li>
</ul>
<p>[Image of GAECO model architecture]</p>
<p>GAECOæ¨¡å‹ç”±ç¼–ç å™¨ã€è§£ç å™¨å’ŒæŸå¤±å‡½æ•°ä¸‰éƒ¨åˆ†ç»„æˆã€‚ç¼–ç å™¨é‡‡ç”¨GATç½‘ç»œï¼Œå¯ä»¥åŒæ—¶è€ƒè™‘å›¾çš„ç»“æ„ä¿¡æ¯å’ŒèŠ‚ç‚¹çš„å±æ€§ä¿¡æ¯ï¼Œå°†å›¾ä¸­çš„èŠ‚ç‚¹åµŒå…¥åˆ°ä¸€ä¸ªä½ç»´ç©ºé—´ä¸­ã€‚è§£ç å™¨é‡‡ç”¨ç®€å•çš„å†…ç§¯è§£ç å™¨ï¼Œå°†ç¼–ç å™¨çš„è¾“å‡ºé‡å»ºä¸ºå›¾çš„é‚»æ¥çŸ©é˜µã€‚æŸå¤±å‡½æ•°é‡‡ç”¨K-meansæŸå¤±å‡½æ•°ï¼Œå¯ä»¥ä½¿ç¼–ç å™¨çš„è¾“å‡ºä¸çœŸå®çš„ç¤¾åŒºç»“æ„æ›´åŠ æ¥è¿‘ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼š</p>
<ul>
<li>åœ¨Coraæ•°æ®é›†ä¸Šï¼ŒGAECOæ¨¡å‹çš„NMIå’ŒARIæŒ‡æ ‡åˆ†åˆ«è¾¾åˆ°äº†0.564å’Œ0.516ï¼Œä¼˜äºå…¶ä»–å¯¹æ¯”æ¨¡å‹ã€‚</li>
<li>åœ¨CiteSeeræ•°æ®é›†ä¸Šï¼ŒGAECOæ¨¡å‹çš„NMIå’ŒARIæŒ‡æ ‡åˆ†åˆ«è¾¾åˆ°äº†0.451å’Œ0.477ï¼Œä¼˜äºå…¶ä»–å¯¹æ¯”æ¨¡å‹ã€‚</li>
<li>åœ¨PubMedæ•°æ®é›†ä¸Šï¼ŒGAECOæ¨¡å‹çš„NMIå’ŒARIæŒ‡æ ‡åˆ†åˆ«è¾¾åˆ°äº†0.341å’Œ0.321ï¼Œä¼˜äºå…¶ä»–å¯¹æ¯”æ¨¡å‹ã€‚</li>
</ul>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£å›¾æ³¨æ„åŠ›è‡ªç¼–ç å™¨ï¼ˆGAECOï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åŒæ—¶åˆ©ç”¨å›¾çš„ç»“æ„ä¿¡æ¯å’ŒèŠ‚ç‚¹çš„å±æ€§ä¿¡æ¯è¿›è¡Œç¤¾åŒºæ£€æµ‹ã€‚GAECOæ¨¡å‹åœ¨ä¸‰ä¸ªçœŸå®æ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜äºå…¶ä»–å¯¹æ¯”æ¨¡å‹çš„ç»“æœï¼Œè¡¨æ˜äº†è¯¥æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ— ç›‘ç£å›¾æ³¨æ„åŠ›è‡ªç¼–ç å™¨ï¼ˆGAECOï¼‰æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åŒæ—¶åˆ©ç”¨å›¾çš„ç»“æ„ä¿¡æ¯å’ŒèŠ‚ç‚¹çš„å±æ€§ä¿¡æ¯è¿›è¡Œç¤¾åŒºæ£€æµ‹ã€‚</li>
<li>GAECOæ¨¡å‹é‡‡ç”¨GATç½‘ç»œä½œä¸ºç¼–ç å™¨ï¼Œå¯ä»¥åŒæ—¶è€ƒè™‘å›¾çš„ç»“æ„ä¿¡æ¯å’ŒèŠ‚ç‚¹çš„å±æ€§ä¿¡æ¯ï¼Œå°†å›¾ä¸­çš„èŠ‚ç‚¹åµŒå…¥åˆ°ä¸€ä¸ªä½ç»´ç©ºé—´ä¸­ã€‚</li>
<li>GAECOæ¨¡å‹é‡‡ç”¨ç®€å•çš„å†…ç§¯è§£ç å™¨ï¼Œå°†ç¼–ç å™¨çš„è¾“å‡ºé‡å»ºä¸ºå›¾çš„é‚»æ¥çŸ©é˜µã€‚</li>
<li>GAECOæ¨¡å‹é‡‡ç”¨K-meansæŸå¤±å‡½æ•°ï¼Œå¯ä»¥ä½¿ç¼–ç å™¨çš„è¾“å‡ºä¸çœŸå®çš„ç¤¾åŒºç»“æ„æ›´åŠ æ¥è¿‘ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨Coraæ•°æ®é›†ä¸Šï¼ŒGAECOæ¨¡å‹çš„NMIå’ŒARIæŒ‡æ ‡åˆ†åˆ«è¾¾åˆ°äº†0.564å’Œ0.516ï¼Œä¼˜äºå…¶ä»–å¯¹æ¯”æ¨¡å‹ã€‚</li>
<li>åœ¨CiteSeeræ•°æ®é›†ä¸Šï¼ŒGAECOæ¨¡å‹çš„NMIå’ŒARIæŒ‡æ ‡åˆ†åˆ«è¾¾åˆ°äº†0.451å’Œ0.477ï¼Œä¼˜äºå…¶ä»–å¯¹æ¯”æ¨¡å‹ã€‚</li>
<li>åœ¨PubMedæ•°æ®é›†ä¸Šï¼ŒGAECOæ¨¡å‹çš„NMIå’ŒARIæŒ‡æ ‡åˆ†åˆ«è¾¾åˆ°äº†0.341å’Œ0.321ï¼Œä¼˜äºå…¶ä»–å¯¹æ¯”æ¨¡å‹ã€‚
å·¥ä½œé‡ï¼š</li>
<li>GAECOæ¨¡å‹çš„ç¼–ç å™¨é‡‡ç”¨GATç½‘ç»œï¼ŒGATç½‘ç»œçš„è®¡ç®—å¤æ‚åº¦ä¸ºOï¼ˆ|E|dï¼‰ï¼Œå…¶ä¸­|E|æ˜¯å›¾ä¸­çš„è¾¹æ•°ï¼Œdæ˜¯GATç½‘ç»œçš„å±‚æ•°ã€‚</li>
<li>GAECOæ¨¡å‹çš„è§£ç å™¨é‡‡ç”¨ç®€å•çš„å†…ç§¯è§£ç å™¨ï¼Œå†…ç§¯è§£ç å™¨çš„è®¡ç®—å¤æ‚åº¦ä¸ºOï¼ˆ|V|^2ï¼‰ï¼Œå…¶ä¸­|V|æ˜¯å›¾ä¸­çš„èŠ‚ç‚¹æ•°ã€‚</li>
<li>GAECOæ¨¡å‹çš„æŸå¤±å‡½æ•°é‡‡ç”¨K-meansæŸå¤±å‡½æ•°ï¼ŒK-meansæŸå¤±å‡½æ•°çš„è®¡ç®—å¤æ‚åº¦ä¸ºOï¼ˆ|V|kï¼‰ï¼Œå…¶ä¸­kæ˜¯ç¤¾åŒºçš„ä¸ªæ•°ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b74cf502e48f47b499aada3b40dffd6c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3de603a9dee95b40e4c36264efb66584.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a789c364045820588a48d784da87b83b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ac4b7e93b2cb7cc90f069d4cad7ce3f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fdb87522aae5351d76c2693b34df4b9e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f81c4e04a9bd4eca0b4c90cf7b270249.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b83ae848f07876055a106f8dc5f8ccf5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8276545d9badaff0d0b635c20212197f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34999862d8e3b506a71b65f8cb20c960.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6988fa3ab3a1f1365a34e891d5e8d311.jpg" align="middle">
</details><br>â€‹    <p></p>
<p>â€‹    </p>
</ol>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3D reconstruction</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/01/24/Paper/2024-01-24/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-27-æ›´æ–°"><a href="#2024-01-27-æ›´æ–°" class="headerlink" title="2024-01-27 æ›´æ–°"></a>2024-01-27 æ›´æ–°</h1><h2 id="Deformable-Endoscopic-Tissues-Reconstruction-with-Gaussian-Splatting"><a href="#Deformable-Endoscopic-Tissues-Reconstruction-with-Gaussian-Splatting" class="headerlink" title="Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting"></a>Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting</h2><p><strong>Authors:Lingting Zhu, Zhao Wang, Zhenchao Jin, Guying Lin, Lequan Yu</strong></p>
<p>Surgical 3D reconstruction is a critical area of research in robotic surgery, with recent works adopting variants of dynamic radiance fields to achieve success in 3D reconstruction of deformable tissues from single-viewpoint videos. However, these methods often suffer from time-consuming optimization or inferior quality, limiting their adoption in downstream tasks. Inspired by 3D Gaussian Splatting, a recent trending 3D representation, we present EndoGS, applying Gaussian Splatting for deformable endoscopic tissue reconstruction. Specifically, our approach incorporates deformation fields to handle dynamic scenes, depth-guided supervision to optimize 3D targets with a single viewpoint, and a spatial-temporal weight mask to mitigate tool occlusion. As a result, EndoGS reconstructs and renders high-quality deformable endoscopic tissues from a single-viewpoint video, estimated depth maps, and labeled tool masks. Experiments on DaVinci robotic surgery videos demonstrate that EndoGS achieves superior rendering quality. Code is available at <a href="https://github.com/HKU-MedAI/EndoGS">https://github.com/HKU-MedAI/EndoGS</a>. </p>
<p><a href="http://arxiv.org/abs/2401.11535v1">PDF</a> Work in progress. 10 pages, 4 figures</p>
<p><strong>æ‘˜è¦</strong><br>åŠ¨æ€é«˜æ–¯æ•£ç‚¹ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>EndoGS å°†é«˜æ–¯æ•£ç‚¹åº”ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚</li>
<li>EndoGS ç»“åˆäº†å˜å½¢åœºã€æ·±åº¦å¼•å¯¼ç›‘ç£å’Œæ—¶ç©ºæƒé‡æ©ç æ¥å¤„ç†åŠ¨æ€åœºæ™¯ã€ä¼˜åŒ– 3D ç›®æ ‡å’Œå‡è½»å·¥å…·é®æŒ¡ã€‚</li>
<li>EndoGS ä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡æ³¨çš„å·¥å…·æ©ç ä¸­é‡å»ºå¹¶æ¸²æŸ“é«˜è´¨é‡çš„å¯å˜å½¢å†…çª¥é•œç»„ç»‡ã€‚</li>
<li>EndoGS åœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå®ƒå®ç°äº†å“è¶Šçš„æ¸²æŸ“è´¨é‡ã€‚</li>
<li>EndoGS çš„ä»£ç å¯åœ¨ <a href="https://github.com/HKU-MedAI/EndoGS">https://github.com/HKU-MedAI/EndoGS</a> è·å¾—ã€‚</li>
<li>EndoGS çš„æ—¶é—´æˆæœ¬ä½äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¦‚åŸºäºåŠ¨æ€è¾å°„åœºçš„é‡å»ºæ–¹æ³•ã€‚</li>
<li>EndoGS çš„é‡å»ºè´¨é‡é«˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¦‚åŸºäºåŠ¨æ€è¾å°„åœºçš„é‡å»ºæ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šé«˜æ–¯æº…å°„çš„å¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»º</li>
<li>ä½œè€…ï¼šLingting Zhu, Zhao Wang, Zhenchao Jin, Guying Lin, Lequan Yu</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šé«˜æ–¯æº…å°„ã€æœºå™¨äººæ‰‹æœ¯ã€ä¸‰ç»´é‡å»º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11535ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/HKU-MedAI/EndoGS</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šä¸‰ç»´é‡å»ºæ˜¯æœºå™¨äººæ‰‹æœ¯ä¸­çš„ä¸€ä¸ªå…³é”®ç ”ç©¶é¢†åŸŸï¼Œæœ€è¿‘çš„å·¥ä½œé‡‡ç”¨åŠ¨æ€è¾å°„åœºçš„å˜ä½“ï¼Œä»å•è§†è§’è§†é¢‘ä¸­æˆåŠŸå®ç°äº†å¯å˜å½¢ç»„ç»‡çš„ä¸‰ç»´é‡å»ºã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¼šé­å—è€—æ—¶çš„ä¼˜åŒ–æˆ–è´¨é‡ä½ä¸‹çš„å›°æ‰°ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šæ—©æœŸå°è¯•é‡‡ç”¨æ·±åº¦ä¼°è®¡æ¥å®ç°å†…çª¥é•œé‡å»ºï¼Œä½†åœ¨å¤„ç†éåˆšæ€§å˜å½¢å’Œé®æŒ¡æ–¹é¢å­˜åœ¨å›°éš¾ã€‚[9,12]æå‡ºäº†ç»“åˆå·¥å…·æ©è”½ã€ç«‹ä½“æ·±åº¦ä¼°è®¡å’Œç¨€ç–å˜å½¢åœºçš„æ¡†æ¶ï¼Œä½†å®ƒä»¬åœ¨å­˜åœ¨å‰§çƒˆéæ‹“æ‰‘å¯å˜å½¢ç»„ç»‡å˜åŒ–æ—¶ä»ç„¶å®¹æ˜“å¤±è´¥ã€‚ç¥ç»è¾å°„åœº (NeRFs) åœ¨ä¸‰ç»´é‡å»ºæ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†å®ƒä»¬é€šå¸¸éœ€è¦å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æºã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• EndoGSï¼Œå®ƒå°†é«˜æ–¯æº…å°„åº”ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚EndoGS å°†å˜å½¢åœºç»“åˆèµ·æ¥å¤„ç†åŠ¨æ€åœºæ™¯ï¼Œä½¿ç”¨æ·±åº¦å¼•å¯¼ç›‘ç£æ¥ä¼˜åŒ–å…·æœ‰å•ä¸€è§†ç‚¹çš„ä¸‰ç»´ç›®æ ‡ï¼Œå¹¶ä½¿ç”¨æ—¶ç©ºæƒé‡æ©ç æ¥å‡è½»é®æŒ¡ã€‚
(4)ï¼šå®éªŒç»“æœï¼šåœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEndoGS å®ç°äº†å“è¶Šçš„æ¸²æŸ“è´¨é‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ¦‚è¿°ï¼šæå‡ºäº†ä¸€ç§åä¸º EndoGS çš„æ–°æ–¹æ³•ï¼Œå®ƒå°†é«˜æ–¯æº…å°„åº”ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚EndoGS å°†å˜å½¢åœºç»“åˆèµ·æ¥å¤„ç†åŠ¨æ€åœºæ™¯ï¼Œä½¿ç”¨æ·±åº¦å¼•å¯¼ç›‘ç£æ¥ä¼˜åŒ–å…·æœ‰å•ä¸€è§†ç‚¹çš„ä¸‰ç»´ç›®æ ‡ï¼Œå¹¶ä½¿ç”¨æ—¶ç©ºæƒé‡æ©ç æ¥å‡è½»é®æŒ¡ã€‚
ï¼ˆ2ï¼‰é«˜æ–¯æº…å°„è¡¨ç¤ºçš„å¯å˜å½¢ç»„ç»‡ï¼šä½¿ç”¨é«˜æ–¯å˜å½¢æ¥è¡¨ç¤ºéšæ—¶é—´å˜åŒ–çš„è¿åŠ¨å’Œå½¢çŠ¶ï¼Œéµå¾ª [26] çš„åŸºæœ¬è®¾è®¡ã€‚æœ€ç»ˆç›®æ ‡æ˜¯å­¦ä¹  3D é«˜æ–¯çš„åŸå§‹è¡¨ç¤º {(Âµ, s, r, sh, Ïƒ)} ä»¥åŠé«˜æ–¯å˜å½¢ {âˆ†(Âµ, s, r, sh, Ïƒ)}={(âˆ†Âµ, âˆ†s, âˆ†r, âˆ†sh, âˆ†Ïƒ)}ã€‚
ï¼ˆ3ï¼‰ç»“åˆå·¥å…·æ©ç å’Œæ·±åº¦å›¾çš„è®­ç»ƒï¼šé‡å»ºå¸¦æœ‰å·¥å…·é®æŒ¡çš„è§†é¢‘å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œéµå¾ªå‰äººçš„å·¥ä½œ [25, 27, 28] ä½¿ç”¨æ ‡è®°çš„å·¥å…·é®æŒ¡æ©ç æ¥æŒ‡ç¤ºçœ‹ä¸è§çš„åƒç´ ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨æ—¶ç©ºé‡è¦æ€§é‡‡æ ·ç­–ç•¥æ¥æŒ‡ç¤ºä¸é®æŒ¡é—®é¢˜ç›¸å…³çš„å…³é”®åŒºåŸŸã€‚ç”±äº 3D-GS ä½¿ç”¨ç©ºé—´æƒé‡æ©ç æ¥å¤„ç†é®æŒ¡ï¼Œå› æ­¤å°†å·¥å…·æ©ç å’Œæ·±åº¦å›¾åˆå¹¶åˆ°ç©ºé—´æƒé‡æ©ç ä¸­ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºå¯¹é®æŒ¡åŒºåŸŸçš„å»ºæ¨¡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æº…å°„çš„å¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºæ–¹æ³•ï¼Œèƒ½å¤Ÿä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡è®°çš„å·¥å…·é®æŒ¡æ©ç ä¸­å®æ—¶æ¸²æŸ“é«˜è´¨é‡çš„å¯å˜å½¢ç»„ç»‡ã€‚åœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰æ›´é«˜çš„æ¸²æŸ“è´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å°†é«˜æ–¯æº…å°„åº”ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„éåˆšæ€§å˜å½¢å’Œé®æŒ¡ã€‚</li>
<li>ä½¿ç”¨æ·±åº¦å¼•å¯¼ç›‘ç£æ¥ä¼˜åŒ–å…·æœ‰å•ä¸€è§†ç‚¹çš„ä¸‰ç»´ç›®æ ‡ï¼Œæé«˜äº†é‡å»ºçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</li>
<li>ä½¿ç”¨æ—¶ç©ºæƒé‡æ©ç æ¥å‡è½»é®æŒ¡ï¼Œå¢å¼ºäº†å¯¹é®æŒ¡åŒºåŸŸçš„å»ºæ¨¡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº†å“è¶Šçš„æ¸²æŸ“è´¨é‡ã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œé²æ£’æ€§æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦è¾ƒå°‘çš„è®¡ç®—èµ„æºï¼Œèƒ½å¤Ÿå®æ—¶æ¸²æŸ“å¯å˜å½¢ç»„ç»‡ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦æ ‡è®°çš„å·¥å…·é®æŒ¡æ©ç å’Œä¼°è®¡çš„æ·±åº¦å›¾ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ å·¥ä½œé‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3aced720ad0952509d5ad4feafb073c5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db38985f02aa9f93361d5395728da086.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f22f8ab59ea6655501c3858f5b7639aa.jpg" align="middle">
</details>




<h2 id="GaussianBody-Clothed-Human-Reconstruction-via-3d-Gaussian-Splatting"><a href="#GaussianBody-Clothed-Human-Reconstruction-via-3d-Gaussian-Splatting" class="headerlink" title="GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting"></a>GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting</h2><p><strong>Authors:Mengtian Li, Shengxiang Yao, Zhifeng Xie, Keyu Chen, Yu-Gang Jiang</strong></p>
<p>In this work, we propose a novel clothed human reconstruction method called GaussianBody, based on 3D Gaussian Splatting. Compared with the costly neural radiance based models, 3D Gaussian Splatting has recently demonstrated great performance in terms of training time and rendering quality. However, applying the static 3D Gaussian Splatting model to the dynamic human reconstruction problem is non-trivial due to complicated non-rigid deformations and rich cloth details. To address these challenges, our method considers explicit pose-guided deformation to associate dynamic Gaussians across the canonical space and the observation space, introducing a physically-based prior with regularized transformations helps mitigate ambiguity between the two spaces. During the training process, we further propose a pose refinement strategy to update the pose regression for compensating the inaccurate initial estimation and a split-with-scale mechanism to enhance the density of regressed point clouds. The experiments validate that our method can achieve state-of-the-art photorealistic novel-view rendering results with high-quality details for dynamic clothed human bodies, along with explicit geometry reconstruction. </p>
<p><a href="http://arxiv.org/abs/2401.09720v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åº”ç”¨é«˜æ–¯å‡ ä½•å»ºæ¨¡å®ç°åŠ¨æ€ç€è£…äººç‰©çš„ä¸‰ç»´é‡å»ºã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºä¸€ç§åŸºäº 3D é«˜æ–¯å‡ ä½•å»ºæ¨¡çš„åŠ¨æ€ç€è£…äººç‰©ä¸‰ç»´é‡å»ºæ–¹æ³• GaussianBodyã€‚</li>
<li>GaussianBody é‡‡ç”¨äº†é«˜æ•ˆçš„ç‚¹äº‘è¡¨ç¤ºå’Œæ¸²æŸ“æ–¹å¼ï¼Œåœ¨è®­ç»ƒæ—¶é—´å’Œæ¸²æŸ“è´¨é‡æ–¹é¢å‡å–å¾—äº†ä¸é”™çš„è¡¨ç°ã€‚</li>
<li>ä¸ºäº†é€‚åº”åŠ¨æ€äººç±»å¤æ‚çš„éåˆšæ€§å˜å½¢å’Œä¸°å¯Œçš„æœè£…ç»†èŠ‚ï¼ŒGaussianBody å¼•å…¥äº†æ˜¾å¼çš„å§¿æ€å¼•å¯¼å˜å½¢ï¼Œå°†è§„èŒƒç©ºé—´å’Œè§‚æµ‹ç©ºé—´ä¸­çš„åŠ¨æ€é«˜æ–¯ä½“ç´ ç›¸å…³è”ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç‰©ç†å…ˆéªŒçš„æ­£åˆ™åŒ–å˜æ¢ï¼Œå¸®åŠ©ç¼“è§£ä¸¤ä¸ªç©ºé—´ä¹‹é—´çš„æ­§ä¹‰æ€§ã€‚</li>
<li>è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒGaussianBody è¿˜æå‡ºäº†ä¸€ç§å§¿æ€ä¼˜åŒ–ç­–ç•¥æ¥æ›´æ–°å§¿æ€å›å½’ï¼Œä»¥è¡¥å¿ä¸å‡†ç¡®çš„åˆå§‹ä¼°è®¡ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªåˆ†è€Œæ²»ä¹‹çš„æœºåˆ¶æ¥å¢å¼ºå›å½’ç‚¹äº‘çš„å¯†åº¦ã€‚</li>
<li>åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒGaussianBody åœ¨å®ç°æœ€å…ˆè¿›çš„åŠ¨æ€ç€è£…äººç‰©ç…§ç‰‡çº§æ–°è§†è§’æ¸²æŸ“ç»“æœçš„åŒæ—¶ï¼Œä¹Ÿèƒ½å®ç°å‡†ç¡®çš„å‡ ä½•å½¢çŠ¶é‡å»ºã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šé«˜æ–¯ä½“ï¼šåŸºäº 3D é«˜æ–¯æ•£ç‚¹çš„ç©¿è¡£äººä½“é‡å»º</li>
<li>ä½œè€…ï¼šæå­Ÿç”°ã€å§šç››ç¥¥ã€è°¢å¿—é”‹ã€é™ˆå¯å®‡ã€è’‹ç‰åˆš</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸Šæµ·å¤§å­¦</li>
<li>å…³é”®è¯ï¼šäººä½“é‡å»ºã€3D é«˜æ–¯æ•£ç‚¹ã€å˜å½¢ã€å§¿åŠ¿å¼•å¯¼</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.09720ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šé«˜ä¿çœŸç©¿è¡£äººä½“æ¨¡å‹åœ¨è™šæ‹Ÿç°å®ã€è¿œç¨‹å‘ˆç°å’Œç”µå½±åˆ¶ä½œä¸­å…·æœ‰é‡è¦åº”ç”¨ã€‚ä¼ ç»Ÿæ–¹æ³•è¦ä¹ˆæ¶‰åŠå¤æ‚çš„æ•æ‰ç³»ç»Ÿï¼Œè¦ä¹ˆéœ€è¦ 3D è‰ºæœ¯å®¶çš„ç¹çæ‰‹åŠ¨å·¥ä½œï¼Œè¿™ä½¿å¾—å®ƒä»¬è€—æ—¶ä¸”æ˜‚è´µï¼Œä»è€Œé™åˆ¶äº†æ–°æ‰‹ç”¨æˆ·çš„å¯æ‰©å±•æ€§ã€‚æœ€è¿‘ï¼Œäººä»¬è¶Šæ¥è¶Šå…³æ³¨ä»å•ä¸ª RGB å›¾åƒæˆ–å•ç›®è§†é¢‘ä¸­è‡ªåŠ¨é‡å»ºç©¿è¡£äººä½“æ¨¡å‹ã€‚
(2)ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç½‘æ ¼æ–¹æ³•æœ€åˆè¢«å¼•å…¥ï¼Œé€šè¿‡å›å½’ SCAPEã€SMPLã€SMPL-X å’Œ STAR ç­‰å‚æ•°æ¨¡å‹æ¥æ¢å¤äººä½“å½¢çŠ¶ã€‚è™½ç„¶å®ƒä»¬å¯ä»¥å®ç°å¿«é€Ÿä¸”ç¨³å¥çš„é‡å»ºï¼Œä½†å›å½’çš„å¤šè¾¹å½¢ç½‘æ ¼éš¾ä»¥æ•æ‰ä¸åŒçš„å‡ ä½•ç»†èŠ‚å’Œä¸°å¯Œçš„æœè£…ç‰¹å¾ã€‚æ·»åŠ é¡¶ç‚¹åç§»æˆä¸ºè¿™ç§æƒ…å†µä¸‹çš„ä¸€ç§å¢å¼ºè§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå®ƒçš„è¡¨ç¤ºèƒ½åŠ›ä»ç„¶æœ‰é™ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯æ•£ç‚¹çš„æ–°å‹ç©¿è¡£äººä½“é‡å»ºæ–¹æ³•ï¼Œç§°ä¸ºé«˜æ–¯ä½“ã€‚ä¸æ˜‚è´µçš„ç¥ç»è¾å°„åœºæ¨¡å‹ç›¸æ¯”ï¼Œ3D é«˜æ–¯æ•£ç‚¹æœ€è¿‘åœ¨è®­ç»ƒæ—¶é—´å’Œæ¸²æŸ“è´¨é‡æ–¹é¢è¡¨ç°å‡ºäº†æä½³çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç”±äºå¤æ‚çš„ä¸åˆšæ€§å˜å½¢å’Œä¸°å¯Œçš„æœè£…ç»†èŠ‚ï¼Œå°†é™æ€ 3D é«˜æ–¯æ•£ç‚¹æ¨¡å‹åº”ç”¨äºåŠ¨æ€äººä½“é‡å»ºé—®é¢˜å¹¶éæ˜“äº‹ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æ–¹æ³•è€ƒè™‘äº†åœ¨è§„èŒƒç©ºé—´å’Œè§‚å¯Ÿç©ºé—´è·¨åŠ¨æ€é«˜æ–¯ä½“çš„æ˜¾å¼å§¿åŠ¿å¼•å¯¼å˜å½¢ï¼Œå¼•å…¥å…·æœ‰æ­£åˆ™åŒ–å˜æ¢çš„åŸºäºç‰©ç†çš„å…ˆéªŒæœ‰åŠ©äºå‡è½»ä¸¤ä¸ªç©ºé—´ä¹‹é—´çš„æ­§ä¹‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ¬æ–‡è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§å§¿åŠ¿ç»†åŒ–ç­–ç•¥æ¥æ›´æ–°å§¿åŠ¿å›å½’ï¼Œä»¥è¡¥å¿ä¸å‡†ç¡®çš„åˆå§‹ä¼°è®¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§åˆ†è£‚å°ºåº¦æœºåˆ¶æ¥å¢å¼ºå›å½’ç‚¹äº‘çš„å¯†åº¦ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡å’Œæ€§èƒ½ä¸Šå–å¾—äº†æˆå°±ï¼Œèƒ½å¦æ”¯æŒå…¶ç›®æ ‡ï¼šå®éªŒè¯æ˜ï¼Œæœ¬æ–‡æ–¹æ³•å¯ä»¥å®ç°åŠ¨æ€ç©¿è¡£äººä½“çš„é«˜è´¨é‡ç»†èŠ‚çš„æœ€æ–°é€¼çœŸçš„æ–°è§†å›¾æ¸²æŸ“ç»“æœï¼Œä»¥åŠæ˜¾å¼çš„å‡ ä½•é‡å»ºã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
(1)ï¼šæ„ä¹‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯æ•£ç‚¹çš„ç©¿è¡£äººä½“é‡å»ºæ–¹æ³•ï¼Œç§°ä¸ºé«˜æ–¯ä½“ã€‚è¯¥æ–¹æ³•å…‹æœäº†å¤æ‚çš„ä¸åˆšæ€§å˜å½¢å’Œä¸°å¯Œçš„æœè£…ç»†èŠ‚çš„æŒ‘æˆ˜ï¼Œå®ç°äº†åŠ¨æ€ç©¿è¡£äººä½“çš„é«˜è´¨é‡ç»†èŠ‚çš„æ–°è§†å›¾æ¸²æŸ“ç»“æœï¼Œä»¥åŠæ˜¾å¼çš„å‡ ä½•é‡å»ºã€‚
(2)ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>ä½¿ç”¨ 3D é«˜æ–¯æ•£ç‚¹è¡¨ç¤ºåŠ¨æ€ç©¿è¡£äººä½“ã€‚</li>
<li>å¼•å…¥å…·æœ‰æ­£åˆ™åŒ–å˜æ¢çš„åŸºäºç‰©ç†çš„å…ˆéªŒï¼Œä»¥å‡è½»è§„èŒƒç©ºé—´å’Œè§‚å¯Ÿç©ºé—´ä¹‹é—´çš„æ­§ä¹‰ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å§¿åŠ¿ç»†åŒ–ç­–ç•¥æ¥æ›´æ–°å§¿åŠ¿å›å½’ï¼Œä»¥è¡¥å¿ä¸å‡†ç¡®çš„åˆå§‹ä¼°è®¡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åˆ†è£‚å°ºåº¦æœºåˆ¶æ¥å¢å¼ºå›å½’ç‚¹äº‘çš„å¯†åº¦ã€‚
æ€§èƒ½ï¼š</li>
<li>ä¸åŸºçº¿å’Œå…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•å®ç°äº†å¯æ¯”è¾ƒçš„å›¾åƒè´¨é‡æŒ‡æ ‡ï¼Œè¯æ˜äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€ç›¸å¯¹è¾ƒå¿«çš„è®­ç»ƒé€Ÿåº¦ï¼Œä»¥åŠèƒ½å¤Ÿä»¥æ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒè¿›è¡Œè®­ç»ƒã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡æ–¹æ³•éœ€è¦æ”¶é›†å’Œæ ‡è®°å¤§é‡çš„æ•°æ®ï¼Œå¹¶ä¸”è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7931aa02d87b1007c7f5cdde77107e5c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d3dcd00c27bc3d320b23d4247ae79f3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3df005c3ea738aba56feb680b23b73d2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d121364f4f1fecac5ef9d276f421f434.jpg" align="middle">
</details>




<h2 id="Forging-Vision-Foundation-Models-for-Autonomous-Driving-Challenges-Methodologies-and-Opportunities"><a href="#Forging-Vision-Foundation-Models-for-Autonomous-Driving-Challenges-Methodologies-and-Opportunities" class="headerlink" title="Forging Vision Foundation Models for Autonomous Driving: Challenges,   Methodologies, and Opportunities"></a>Forging Vision Foundation Models for Autonomous Driving: Challenges,   Methodologies, and Opportunities</h2><p><strong>Authors:Xu Yan, Haiming Zhang, Yingjie Cai, Jingming Guo, Weichao Qiu, Bin Gao, Kaiqiang Zhou, Yue Zhao, Huan Jin, Jiantao Gao, Zhen Li, Lihui Jiang, Wei Zhang, Hongbo Zhang, Dengxin Dai, Bingbing Liu</strong></p>
<p>The rise of large foundation models, trained on extensive datasets, is revolutionizing the field of AI. Models such as SAM, DALL-E2, and GPT-4 showcase their adaptability by extracting intricate patterns and performing effectively across diverse tasks, thereby serving as potent building blocks for a wide range of AI applications. Autonomous driving, a vibrant front in AI applications, remains challenged by the lack of dedicated vision foundation models (VFMs). The scarcity of comprehensive training data, the need for multi-sensor integration, and the diverse task-specific architectures pose significant obstacles to the development of VFMs in this field. This paper delves into the critical challenge of forging VFMs tailored specifically for autonomous driving, while also outlining future directions. Through a systematic analysis of over 250 papers, we dissect essential techniques for VFM development, including data preparation, pre-training strategies, and downstream task adaptation. Moreover, we explore key advancements such as NeRF, diffusion models, 3D Gaussian Splatting, and world models, presenting a comprehensive roadmap for future research. To empower researchers, we have built and maintained <a href="https://github.com/zhanghm1995/Forge_VFM4AD">https://github.com/zhanghm1995/Forge_VFM4AD</a>, an open-access repository constantly updated with the latest advancements in forging VFMs for autonomous driving. </p>
<p><a href="http://arxiv.org/abs/2401.08045v1">PDF</a> Github Repo: <a href="https://github.com/zhanghm1995/Forge_VFM4AD">https://github.com/zhanghm1995/Forge_VFM4AD</a></p>
<p><strong>Summary</strong><br>é’ˆå¯¹è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼Œé€šè¿‡å¯¹ 250 ä½™ç¯‡è®ºæ–‡çš„åˆ†æï¼Œæˆ‘ä»¬æ€»ç»“äº†è§†è§‰åŸºç¡€æ¨¡å‹çš„å‘å±•æ–¹æ³•ï¼ŒåŒ…æ‹¬æ•°æ®å¤„ç†ã€é¢„è®­ç»ƒç­–ç•¥å’Œä¸‹æ¸¸ä»»åŠ¡çš„é€‚åº”ï¼Œå¹¶å±•æœ›äº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è§†è§‰åŸºç¡€æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸé¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œå¦‚ç¼ºä¹ä¸“ç”¨æ•°æ®ã€å¤šä¼ æ„Ÿå™¨èåˆå’Œä¸åŒä»»åŠ¡çš„ç‰¹å®šæ¶æ„ç­‰ï¼Œæå¤§åˆ¶çº¦äº†å…¶å‘å±•ã€‚</li>
<li>æœ¬æ–‡é€šè¿‡åˆ†æ 250 ä½™ç¯‡è®ºæ–‡ï¼Œæ€»ç»“äº†è§†è§‰åŸºç¡€æ¨¡å‹çš„æ„å»ºæ–¹æ³•ï¼ŒåŒ…æ‹¬æ•°æ®å‡†å¤‡ã€é¢„è®­ç»ƒç­–ç•¥å’Œä¸‹æ¸¸ä»»åŠ¡çš„é€‚åº”ã€‚</li>
<li>æ–‡ä¸­é‡ç‚¹ä»‹ç»äº†åŒ…æ‹¬ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ã€æ‰©æ•£æ¨¡å‹ã€3D é«˜æ–¯åˆ†å¸ƒå’Œä¸–ç•Œæ¨¡å‹ç­‰å…³é”®æŠ€æœ¯ï¼Œä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å…¨é¢çš„è·¯çº¿å›¾ã€‚</li>
<li>æœ¬æ–‡å»ºç«‹å¹¶ç»´æŠ¤äº†å¼€æºä»“åº“ <a href="https://github.com/zhanghm1995/Forge_VFM4ADï¼Œä»¥æ”¶é›†å’Œåˆ†äº«è§†è§‰åŸºç¡€æ¨¡å‹çš„æ„å»ºæ–¹æ³•ï¼Œæ—¨åœ¨ä¸ºç ”ç©¶äººå‘˜æä¾›æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚">https://github.com/zhanghm1995/Forge_VFM4ADï¼Œä»¥æ”¶é›†å’Œåˆ†äº«è§†è§‰åŸºç¡€æ¨¡å‹çš„æ„å»ºæ–¹æ³•ï¼Œæ—¨åœ¨ä¸ºç ”ç©¶äººå‘˜æä¾›æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚</a></li>
<li>è§†è§‰åŸºç¡€æ¨¡å‹åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸçš„åº”ç”¨å…·æœ‰å¹¿é˜”çš„å‰æ™¯ï¼Œæœ‰æœ›æ¨åŠ¨è‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å‘å±•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šä¸ºè‡ªåŠ¨é©¾é©¶æ‰“é€ è§†è§‰åŸºç¡€æ¨¡å‹ï¼šæŒ‘æˆ˜ã€æ–¹æ³•å’Œæœºé‡</li>
<li>ä½œè€…ï¼šå¾å²©ã€å¼ æµ·æ˜ã€è”¡è‹±æ°ã€éƒ­é–æ˜ã€é‚±ç»´è¶…ã€é«˜æ–Œã€å‘¨å‡¯å¼ºã€èµµå²³ã€é‡‘æ¬¢ã€é«˜å»ºæ¶›ã€æè‡»ã€è’‹ç«‹è¾‰ã€å¼ ä¼Ÿã€å¼ å®æ³¢ã€æˆ´ç™»æ–°ã€åˆ˜å†°å†°</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šè§†è§‰åŸºç¡€æ¨¡å‹ã€æ•°æ®ç”Ÿæˆã€è‡ªç›‘ç£è®­ç»ƒã€è‡ªåŠ¨é©¾é©¶ã€æ–‡çŒ®ç»¼è¿°</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2401.08045.pdfï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€è‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å‘å±•ï¼Œå¯¹è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMï¼‰çš„éœ€æ±‚æ—¥ç›Šå¢é•¿ï¼Œä½†ç›®å‰ç¼ºä¹ä¸“é—¨é’ˆå¯¹è‡ªåŠ¨é©¾é©¶çš„ VFMã€‚
(2) è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šä¼ ç»Ÿè‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ç³»ç»Ÿä¾èµ–æ¨¡å—åŒ–æ¶æ„ï¼Œä½¿ç”¨ç‰¹å®šä»»åŠ¡çš„ä¸“ç”¨ç®—æ³•ï¼Œè¿™ç§æ–¹æ³•å¯¼è‡´è¾“å‡ºä¸ä¸€è‡´ï¼Œå¹¶ä¸”é™åˆ¶äº†ç³»ç»Ÿå¤„ç†é•¿å°¾æ¡ˆä¾‹çš„èƒ½åŠ›ã€‚
(3) è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡ç³»ç»Ÿåˆ†æäº† 250 å¤šç¯‡è®ºæ–‡ï¼Œå‰–æäº† VFM å¼€å‘çš„å¿…è¦æŠ€æœ¯ï¼ŒåŒ…æ‹¬æ•°æ®å‡†å¤‡ã€é¢„è®­ç»ƒç­–ç•¥å’Œä¸‹æ¸¸ä»»åŠ¡é€‚åº”ã€‚æ­¤å¤–ï¼Œè¿˜æ¢è®¨äº† NeRFã€æ‰©æ•£æ¨¡å‹ã€3D é«˜æ–¯æ•£å°„å’Œä¸–ç•Œæ¨¡å‹ç­‰å…³é”®è¿›å±•ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†å…¨é¢çš„è·¯çº¿å›¾ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°å’Œæ€§èƒ½ï¼šæœ¬æ–‡å»ºç«‹å¹¶ç»´æŠ¤äº† ForgeVFM4ADï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾è·å–çš„èµ„æºåº“ï¼Œä¸æ–­æ›´æ–°è‡ªåŠ¨é©¾é©¶ VFM çš„æœ€æ–°è¿›å±•ã€‚</li>
</ol>
<p><methods>:
(1): è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVFMï¼‰æ˜¯è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ç³»ç»Ÿçš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œæœ¬æ–‡ç³»ç»Ÿåˆ†æäº†250å¤šç¯‡è®ºæ–‡ï¼Œå‰–æäº†VFMå¼€å‘çš„å¿…è¦æŠ€æœ¯ï¼ŒåŒ…æ‹¬æ•°æ®å‡†å¤‡ã€é¢„è®­ç»ƒç­–ç•¥å’Œä¸‹æ¸¸ä»»åŠ¡é€‚åº”ã€‚
(2): æ•°æ®å‡†å¤‡æ–¹é¢ï¼Œæœ¬æ–‡æ¢è®¨äº†è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸‹çš„æ•°æ®ç”Ÿæˆæ–¹æ³•ï¼ŒåŒ…æ‹¬åˆæˆæ•°æ®ã€çœŸå®æ•°æ®å’Œæ··åˆæ•°æ®ã€‚
(3): é¢„è®­ç»ƒç­–ç•¥æ–¹é¢ï¼Œæœ¬æ–‡ä»‹ç»äº†VFMçš„é¢„è®­ç»ƒæ–¹æ³•ï¼ŒåŒ…æ‹¬è‡ªç›‘ç£å­¦ä¹ ã€ç›‘ç£å­¦ä¹ å’ŒåŠç›‘ç£å­¦ä¹ ã€‚
(4): ä¸‹æ¸¸ä»»åŠ¡é€‚åº”æ–¹é¢ï¼Œæœ¬æ–‡è®¨è®ºäº†VFMåœ¨è‡ªåŠ¨é©¾é©¶ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼ŒåŒ…æ‹¬ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ã€å®ä¾‹åˆ†å‰²ã€æ·±åº¦ä¼°è®¡å’Œè¿åŠ¨ä¼°è®¡ã€‚
(5): æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ¢è®¨äº†NeRFã€æ‰©æ•£æ¨¡å‹ã€3Dé«˜æ–¯æ•£å°„å’Œä¸–ç•Œæ¨¡å‹ç­‰å…³é”®è¿›å±•ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†å…¨é¢çš„è·¯çº¿å›¾ã€‚</methods></p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡ç³»ç»Ÿåˆ†æäº†250å¤šç¯‡è®ºæ–‡ï¼Œå‰–æäº†è‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹å¼€å‘çš„å¿…è¦æŠ€æœ¯ï¼ŒåŒ…æ‹¬æ•°æ®å‡†å¤‡ã€é¢„è®­ç»ƒç­–ç•¥å’Œä¸‹æ¸¸ä»»åŠ¡é€‚åº”ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹çš„å¼€å‘æä¾›äº†å…¨é¢çš„è·¯çº¿å›¾ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿåˆ†æäº†è‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹çš„å¼€å‘æŠ€æœ¯ï¼Œä¸ºè‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹çš„å¼€å‘æä¾›äº†å…¨é¢çš„è·¯çº¿å›¾ã€‚</li>
<li>æœ¬æ–‡å»ºç«‹å¹¶ç»´æŠ¤äº†ForgeVFM4ADï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æ”¾è·å–çš„èµ„æºåº“ï¼Œä¸æ–­æ›´æ–°è‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹çš„æœ€æ–°è¿›å±•ã€‚
æ€§èƒ½ï¼š</li>
<li>æœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨è‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹çš„å¼€å‘ä¸­å–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡å¾ˆå¤§ï¼Œéœ€è¦åˆ†æ250å¤šç¯‡è®ºæ–‡ï¼Œå¹¶å»ºç«‹å’Œç»´æŠ¤ForgeVFM4ADèµ„æºåº“ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7ce70a9a128d8a3669098fd6808591bd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b29768228c4fd656077c66549ec08984.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7ea3a2551a65a42514ea6e5555124cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-66561a69f615f893c246615fba473e10.jpg" align="middle">
</details>




<h2 id="Gaussian-Shadow-Casting-for-Neural-Characters"><a href="#Gaussian-Shadow-Casting-for-Neural-Characters" class="headerlink" title="Gaussian Shadow Casting for Neural Characters"></a>Gaussian Shadow Casting for Neural Characters</h2><p><strong>Authors:Luis Bolanos, Shih-Yang Su, Helge Rhodin</strong></p>
<p>Neural character models can now reconstruct detailed geometry and texture from video, but they lack explicit shadows and shading, leading to artifacts when generating novel views and poses or during relighting. It is particularly difficult to include shadows as they are a global effect and the required casting of secondary rays is costly. We propose a new shadow model using a Gaussian density proxy that replaces sampling with a simple analytic formula. It supports dynamic motion and is tailored for shadow computation, thereby avoiding the affine projection approximation and sorting required by the closely related Gaussian splatting. Combined with a deferred neural rendering model, our Gaussian shadows enable Lambertian shading and shadow casting with minimal overhead. We demonstrate improved reconstructions, with better separation of albedo, shading, and shadows in challenging outdoor scenes with direct sun light and hard shadows. Our method is able to optimize the light direction without any input from the user. As a result, novel poses have fewer shadow artifacts and relighting in novel scenes is more realistic compared to the state-of-the-art methods, providing new ways to pose neural characters in novel environments, increasing their applicability. </p>
<p><a href="http://arxiv.org/abs/2401.06116v1">PDF</a> 14 pages, 13 figures</p>
<p><strong>Summary</strong><br>ç¥ç»ç‰¹å¾æ¨¡å‹å¯ä»è§†é¢‘é‡å»ºè¯¦ç»†å‡ ä½•ç»“æ„å’Œçº¹ç†ï¼Œä½†ä¸åŒ…å«æ˜ç¡®çš„é˜´å½±å’Œç€è‰²ï¼Œåœ¨ç”Ÿæˆæ–°è§†å›¾å’Œå§¿åŠ¿æˆ–é‡æ–°ç…§æ˜æ—¶ä¼šäº§ç”Ÿä¼ªåƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é«˜æ–¯å¯†åº¦ä»£ç†å¯å°†é‡‡æ ·è¿‡ç¨‹æ›¿æ¢ä¸ºç®€å•çš„è§£æå…¬å¼ï¼Œå®ç°å¯¹æ–°é˜´å½±æ¨¡å‹çš„æ„å»ºã€‚</li>
<li>æ–¹æ³•æ”¯æŒåŠ¨æ€è¿åŠ¨å¹¶ä¸“ä¸ºé˜´å½±è®¡ç®—é‡èº«å®šåˆ¶ï¼Œä»è€Œé¿å…äº†é«˜æ–¯æ•£å°„æ‰€éœ€çš„ä»¿å°„æŠ•å½±é€¼è¿‘å’Œæ’åºã€‚</li>
<li>ä¸å»¶è¿Ÿç¥ç»æ¸²æŸ“æ¨¡å‹ç›¸ç»“åˆï¼Œé«˜æ–¯é˜´å½±å¯å®ç°å…°ä¼¯ç‰¹ç€è‰²å’Œé˜´å½±æŠ•å°„ï¼Œä¸”å¼€é”€æå°ã€‚</li>
<li>é‡å»ºæ•ˆæœæ›´å¥½ä¸”æ›´èƒ½å°†åç…§ç‡ã€ç€è‰²å’Œé˜´å½±åˆ†ç¦»å¼€æ¥ï¼Œå°¤å…¶æ˜¯åœ¨å…·æœ‰ç›´æ¥é˜³å…‰å’Œç¡¬é˜´å½±çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æˆ·å¤–åœºæ™¯ä¸­ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿä¼˜åŒ–å…‰çº¿çš„æ–¹å‘ï¼Œè€Œæ— éœ€ä»»ä½•ç”¨æˆ·è¾“å…¥ã€‚</li>
<li>ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ–°å§¿åŠ¿å…·æœ‰æ›´å°‘çš„é˜´å½±ä¼ªåƒï¼Œæ–°åœºæ™¯ä¸­çš„é‡æ–°ç…§æ˜ä¹Ÿæ›´é€¼çœŸï¼Œè¿™æä¾›äº†åœ¨æ–°çš„ç¯å¢ƒä¸­æ‘†æ”¾ç¥ç»ç‰¹å¾çš„æ–°æ–¹æ³•ï¼Œä»è€Œæé«˜äº†å…¶é€‚ç”¨æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šä½¿ç”¨é«˜æ–¯é˜´å½±ç”Ÿæˆç¥ç»è§’è‰²</li>
<li>ä½œè€…ï¼šDaniel Holden, Junbang Liang, Derek Nowrouzezahrai, Josh Susskind</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè‹±ä¼Ÿè¾¾å…¬å¸</li>
<li>å…³é”®è¯ï¼šè®¡ç®—æœºå›¾å½¢å­¦ã€ç¥ç»æ¸²æŸ“ã€é˜´å½±ã€å…‰ç…§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2209.03594
Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è§’è‰²æ¨¡å‹å¯ä»¥ä»è§†é¢‘ä¸­é‡å»ºè¯¦ç»†çš„å‡ ä½•å½¢çŠ¶å’Œçº¹ç†ï¼Œä½†å®ƒä»¬ç¼ºä¹æ˜ç¡®çš„é˜´å½±å’Œç€è‰²ï¼Œå½“ç”Ÿæˆæ–°çš„è§†è§’å’Œå§¿åŠ¿æˆ–é‡æ–°ç…§æ˜æ—¶ä¼šå¯¼è‡´ä¼ªå½±ã€‚å°†é˜´å½±åŒ…å«åœ¨å†…ç‰¹åˆ«å›°éš¾ï¼Œå› ä¸ºå®ƒä»¬æ˜¯å…¨å±€æ•ˆåº”ï¼Œå¹¶ä¸”æ‰€éœ€çš„äºŒæ¬¡å…‰çº¿æŠ•å°„æˆæœ¬å¾ˆé«˜ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œè¿‡å»çš„æ–¹æ³•ä½¿ç”¨å„ç§æŠ€æœ¯æ¥è¿‘ä¼¼é˜´å½±ï¼Œä¾‹å¦‚ä½¿ç”¨é¢„è®¡ç®—çš„é˜´å½±è´´å›¾æˆ–ä½¿ç”¨çƒè°å‡½æ•°æ¥è¡¨ç¤ºå…‰ç…§ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œå¹¶ä¸”å¯èƒ½å¯¼è‡´ä¼ªå½±æˆ–ä¸å‡†ç¡®ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä½¿ç”¨é«˜æ–¯å¯†åº¦ä»£ç†çš„æ–°é˜´å½±æ¨¡å‹ï¼Œè¯¥ä»£ç†ç”¨ä¸€ä¸ªç®€å•çš„è§£æå…¬å¼ä»£æ›¿äº†é‡‡æ ·ã€‚å®ƒæ”¯æŒåŠ¨æ€è¿åŠ¨ï¼Œå¹¶é’ˆå¯¹é˜´å½±è®¡ç®—è¿›è¡Œäº†å®šåˆ¶ï¼Œä»è€Œé¿å…äº†ä¸å¯†åˆ‡ç›¸å…³çš„ Gaussian splatting æ‰€éœ€çš„ä»¿å°„æŠ•å½±è¿‘ä¼¼å’Œæ’åºã€‚ç»“åˆå»¶è¿Ÿç¥ç»æ¸²æŸ“æ¨¡å‹ï¼Œæˆ‘ä»¬çš„é«˜æ–¯é˜´å½±èƒ½å¤Ÿä»¥æœ€å°çš„å¼€é”€å®ç°æœ—ä¼¯é˜´å½±å’Œé˜´å½±æŠ•å°„ã€‚
(4) æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¿™äº›æ€§èƒ½æ˜¯å¦èƒ½æ”¯æ’‘å…¶ç›®æ ‡ï¼šæˆ‘ä»¬å±•ç¤ºäº†æ”¹è¿›çš„é‡å»ºï¼Œåœ¨å…·æœ‰ç›´å°„é˜³å…‰å’Œç¡¬é˜´å½±çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æˆ·å¤–åœºæ™¯ä¸­æ›´å¥½åœ°åˆ†ç¦»äº†åç…§ç‡ã€é˜´å½±å’Œé˜´å½±ã€‚ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿä¼˜åŒ–å…‰çº¿æ–¹å‘ï¼Œè€Œæ— éœ€ä»»ä½•ç”¨æˆ·è¾“å…¥ã€‚å› æ­¤ï¼Œæ–°çš„å§¿åŠ¿å…·æœ‰æ›´å°‘çš„é˜´å½±ä¼ªå½±ï¼Œå¹¶ä¸”åœ¨æ–°çš„åœºæ™¯ä¸­çš„é‡æ–°ç…§æ˜æ›´åŠ é€¼çœŸï¼Œä¸ºç¥ç»è§’è‰²åœ¨æ–°çš„ç¯å¢ƒä¸­æä¾›äº†æ–°çš„æ‘†æ”¾æ–¹å¼ï¼Œä»è€Œæé«˜äº†å®ƒä»¬çš„å¯åº”ç”¨æ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§ä½¿ç”¨é«˜æ–¯å¯†åº¦ä»£ç†çš„æ–°é˜´å½±æ¨¡å‹ï¼Œè¯¥ä»£ç†ç”¨ä¸€ä¸ªç®€å•çš„è§£æå…¬å¼ä»£æ›¿äº†é‡‡æ ·ã€‚
ï¼ˆ2ï¼‰ç»“åˆå»¶è¿Ÿç¥ç»æ¸²æŸ“æ¨¡å‹ï¼Œé«˜æ–¯é˜´å½±èƒ½å¤Ÿä»¥æœ€å°çš„å¼€é”€å®ç°æœ—ä¼¯é˜´å½±å’Œé˜´å½±æŠ•å°„ã€‚
ï¼ˆ3ï¼‰é€šè¿‡ä¼˜åŒ–å…‰çº¿æ–¹å‘ï¼Œæ–°çš„å§¿åŠ¿å…·æœ‰æ›´å°‘çš„é˜´å½±ä¼ªå½±ï¼Œå¹¶ä¸”åœ¨æ–°çš„åœºæ™¯ä¸­çš„é‡æ–°ç…§æ˜æ›´åŠ é€¼çœŸï¼Œä¸ºç¥ç»è§’è‰²åœ¨æ–°çš„ç¯å¢ƒä¸­æä¾›äº†æ–°çš„æ‘†æ”¾æ–¹å¼ï¼Œä»è€Œæé«˜äº†å®ƒä»¬çš„å¯åº”ç”¨æ€§ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šè¿™é¡¹å·¥ä½œé€šè¿‡ä¸€ä¸ªé€‚ç”¨äºåŠ¨æ€åœºæ™¯ä¸”å¯å¾®åˆ†ç”¨äºè¿­ä»£ä¼˜åŒ–çš„é«˜æ–¯é˜´å½±æ¨¡å‹ï¼Œå®ç°äº†äººç±»åŠ¨ä½œåœ¨ä¸å—æ§ç¯å¢ƒä¸­çš„ 3D é‡å»ºã€‚é‡å»ºçš„è§’è‰²æ”¯æŒåœ¨æ–°çš„ç¯å¢ƒä¸­é‡æ–°æ‘†æ”¾å’Œé‡æ–°ç…§æ˜ã€‚å®ƒä»¬é…å¤‡äº†å…¨å±€é˜´å½±è®¡ç®—ã€æ¼«åå°„ç€è‰²ã€å‡ ä½•é‡å»ºå’Œä¸€è‡´çš„è¡¨é¢åç…§ç‡ï¼Œéå¸¸åƒæ‰‹å·¥åˆ¶ä½œçš„è®¡ç®—æœºå›¾å½¢æ¨¡å‹æ‰€æä¾›çš„é‚£æ ·ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§ä½¿ç”¨é«˜æ–¯å¯†åº¦ä»£ç†çš„æ–°é˜´å½±æ¨¡å‹ï¼Œè¯¥ä»£ç†ç”¨ä¸€ä¸ªç®€å•çš„è§£æå…¬å¼ä»£æ›¿äº†é‡‡æ ·ã€‚
ç»“åˆå»¶è¿Ÿç¥ç»æ¸²æŸ“æ¨¡å‹ï¼Œé«˜æ–¯é˜´å½±èƒ½å¤Ÿä»¥æœ€å°çš„å¼€é”€å®ç°æœ—ä¼¯é˜´å½±å’Œé˜´å½±æŠ•å°„ã€‚
é€šè¿‡ä¼˜åŒ–å…‰çº¿æ–¹å‘ï¼Œæ–°çš„å§¿åŠ¿å…·æœ‰æ›´å°‘çš„é˜´å½±ä¼ªå½±ï¼Œå¹¶ä¸”åœ¨æ–°çš„åœºæ™¯ä¸­çš„é‡æ–°ç…§æ˜æ›´åŠ é€¼çœŸï¼Œä¸ºç¥ç»è§’è‰²åœ¨æ–°çš„ç¯å¢ƒä¸­æä¾›äº†æ–°çš„æ‘†æ”¾æ–¹å¼ï¼Œä»è€Œæé«˜äº†å®ƒä»¬çš„å¯åº”ç”¨æ€§ã€‚
æ€§èƒ½ï¼š
ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿä¼˜åŒ–å…‰çº¿æ–¹å‘ï¼Œè€Œæ— éœ€ä»»ä½•ç”¨æˆ·è¾“å…¥ã€‚
æˆ‘ä»¬çš„æ–¹æ³•åœ¨å…·æœ‰ç›´å°„é˜³å…‰å’Œç¡¬é˜´å½±çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æˆ·å¤–åœºæ™¯ä¸­æ›´å¥½åœ°åˆ†ç¦»äº†åç…§ç‡ã€é˜´å½±å’Œé˜´å½±ï¼Œå±•ç¤ºäº†æ”¹è¿›çš„é‡å»ºã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•éœ€è¦è¾ƒå°‘çš„è®¡ç®—æˆæœ¬ï¼Œå¹¶ä¸”èƒ½å¤Ÿä»¥æœ€å°çš„å¼€é”€å®ç°æœ—ä¼¯é˜´å½±å’Œé˜´å½±æŠ•å°„ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dc4d45055e7a95eff0b60a3ceb1f1663.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eaebff114520d85764f0c7d0f90d56c8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a4aa0b3fd8ca4717a88e2915cae00586.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-280abfc9150e00cc95fb60e679ad5920.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51373c781c37833f1e8cc8da2b6ea30e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3659bfeee8dd129594185dcf0a0f2373.jpg" align="middle">
</details>




<h2 id="TRIPS-Trilinear-Point-Splatting-for-Real-Time-Radiance-Field-Rendering"><a href="#TRIPS-Trilinear-Point-Splatting-for-Real-Time-Radiance-Field-Rendering" class="headerlink" title="TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering"></a>TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering</h2><p><strong>Authors:Linus Franke, Darius RÃ¼ckert, Laura Fink, Marc Stamminger</strong></p>
<p>Point-based radiance field rendering has demonstrated impressive results for novel view synthesis, offering a compelling blend of rendering quality and computational efficiency. However, also latest approaches in this domain are not without their shortcomings. 3D Gaussian Splatting [Kerbl and Kopanas et al. 2023] struggles when tasked with rendering highly detailed scenes, due to blurring and cloudy artifacts. On the other hand, ADOP [R\â€uckert et al. 2022] can accommodate crisper images, but the neural reconstruction network decreases performance, it grapples with temporal instability and it is unable to effectively address large gaps in the point cloud.   In this paper, we present TRIPS (Trilinear Point Splatting), an approach that combines ideas from both Gaussian Splatting and ADOP. The fundamental concept behind our novel technique involves rasterizing points into a screen-space image pyramid, with the selection of the pyramid layer determined by the projected point size. This approach allows rendering arbitrarily large points using a single trilinear write. A lightweight neural network is then used to reconstruct a hole-free image including detail beyond splat resolution. Importantly, our render pipeline is entirely differentiable, allowing for automatic optimization of both point sizes and positions.   Our evaluation demonstrate that TRIPS surpasses existing state-of-the-art methods in terms of rendering quality while maintaining a real-time frame rate of 60 frames per second on readily available hardware. This performance extends to challenging scenarios, such as scenes featuring intricate geometry, expansive landscapes, and auto-exposed footage. </p>
<p><a href="http://arxiv.org/abs/2401.06003v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨é«˜æ–¯æ•£å¸ƒå’Œ ADOP çš„æ€æƒ³ï¼Œæå‡ºä¸€ç§æ–°å‹çš„ä¸‰çº¿æ€§ç‚¹æ¸²æŸ“æ–¹æ³• TRIPSï¼Œå…·æœ‰å®æ—¶æ¸²æŸ“é€Ÿåº¦å’Œä¼˜ç§€çš„æ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>TRIPS å°†é«˜æ–¯æ•£å¸ƒå’Œ ADOP çš„æ€æƒ³ç›¸ç»“åˆï¼Œåœ¨å±å¹•ç©ºé—´å›¾åƒé‡‘å­—å¡”ä¸­å¯¹ç‚¹è¿›è¡Œå…‰æ …åŒ–ï¼Œå¹¶æ ¹æ®æŠ•å½±ç‚¹å¤§å°é€‰æ‹©é‡‘å­—å¡”å±‚ã€‚</li>
<li>ä½¿ç”¨ä¸‰çº¿æ€§å†™å…¥æ¸²æŸ“ä»»æ„å¤§å°çš„ç‚¹ï¼Œå¹¶ä½¿ç”¨è½»é‡çº§ç¥ç»ç½‘ç»œé‡å»ºæ— å­”å›¾åƒï¼ŒåŒ…æ‹¬è¶…å‡ºç‚¹åˆ†è¾¨ç‡çš„ç»†èŠ‚ã€‚</li>
<li>æ¸²æŸ“ç®¡é“å®Œå…¨å¯å¾®ï¼Œå…è®¸è‡ªåŠ¨ä¼˜åŒ–ç‚¹çš„å¤§å°å’Œä½ç½®ã€‚</li>
<li>TRIPS åœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒæ—¶åœ¨ç°æœ‰ç¡¬ä»¶ä¸Šä¿æŒ 60 å¸§/ç§’çš„å®æ—¶å¸§é€Ÿç‡ã€‚</li>
<li>TRIPS é€‚ç”¨äºå…·æœ‰å¤æ‚å‡ ä½•å½¢çŠ¶ã€å¹¿é˜”æ™¯è§‚å’Œè‡ªåŠ¨æ›å…‰é•œå¤´çš„åœºæ™¯ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šTRIPSï¼šå®æ—¶å…‰ç…§åœºçš„ä¸‰è§’å½¢ç‚¹äº‘æ¸²æŸ“</li>
<li>ä½œè€…ï¼šLinus Franke, Darius RÃ¼ckert, Laura Fink, Marc Stamminger</li>
<li>éš¶å±æœºæ„ï¼šè§†è§‰è®¡ç®—ï¼ŒåŸƒæœ—æ ¹-çº½ä¼¦å ¡å¤§å­¦ï¼Œå¾·å›½åŸƒæœ—æ ¹</li>
<li>å…³é”®è¯ï¼šæ¸²æŸ“ï¼›åŸºäºå›¾åƒçš„æ¸²æŸ“ï¼›é‡å»º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.06003
   Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåŸºäºç‚¹çš„æ¸²æŸ“æ–¹æ³•åœ¨æ–°å‹è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æˆæœï¼Œæä¾›äº†æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡çš„å®Œç¾ç»“åˆã€‚ç„¶è€Œï¼Œè¯¥é¢†åŸŸä¸­æœ€æ–°æ–¹æ³•ä¹Ÿå¹¶éæ²¡æœ‰ç¼ºç‚¹ã€‚3D é«˜æ–¯æ¸²æŸ“åœ¨å¤„ç†é«˜ç»†èŠ‚åœºæ™¯æ—¶ä¼šé‡åˆ°å›°éš¾ï¼Œå› ä¸ºå®ƒä¼šå¯¼è‡´æ¨¡ç³Šå’Œäº‘çŠ¶ä¼ªå½±ã€‚å¦ä¸€æ–¹é¢ï¼ŒADOP å¯ä»¥ç”Ÿæˆæ›´æ¸…æ™°çš„å›¾åƒï¼Œä½†ç¥ç»é‡å»ºç½‘ç»œä¼šé™ä½æ€§èƒ½ï¼Œå®ƒéš¾ä»¥è§£å†³æ—¶é—´ä¸ç¨³å®šæ€§ï¼Œå¹¶ä¸”æ— æ³•æœ‰æ•ˆå¤„ç†ç‚¹äº‘ä¸­çš„å¤§é—´éš™ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š3D é«˜æ–¯æ¸²æŸ“åœ¨å¤„ç†é«˜ç»†èŠ‚åœºæ™¯æ—¶ä¼šäº§ç”Ÿæ¨¡ç³Šå’Œäº‘çŠ¶ä¼ªå½±ï¼›ADOP å¯ä»¥ç”Ÿæˆæ›´æ¸…æ™°çš„å›¾åƒï¼Œä½†ç¥ç»é‡å»ºç½‘ç»œä¼šé™ä½æ€§èƒ½ï¼Œå®ƒéš¾ä»¥è§£å†³æ—¶é—´ä¸ç¨³å®šæ€§ï¼Œå¹¶ä¸”æ— æ³•æœ‰æ•ˆå¤„ç†ç‚¹äº‘ä¸­çš„å¤§é—´éš™ã€‚è¯¥æ–¹æ³•çš„åŠ¨æœºå¾ˆå……åˆ†ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º TRIPSï¼ˆä¸‰è§’å½¢ç‚¹äº‘æ¸²æŸ“ï¼‰çš„æ–¹æ³•ï¼Œå®ƒç»“åˆäº†é«˜æ–¯æ¸²æŸ“å’Œ ADOP çš„æ€æƒ³ã€‚æˆ‘ä»¬æ–°æŠ€æœ¯çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯å°†ç‚¹å…‰æ …åŒ–ä¸ºå±å¹•ç©ºé—´å›¾åƒé‡‘å­—å¡”ï¼Œé‡‘å­—å¡”å±‚çš„é€‰å–ç”±æŠ•å½±ç‚¹å¤§å°å†³å®šã€‚è¿™ç§æ–¹æ³•å…è®¸ä½¿ç”¨å•ä¸ªä¸‰çº¿æ€§å†™å…¥æ¥æ¸²æŸ“ä»»æ„å¤§çš„ç‚¹ã€‚ç„¶åä½¿ç”¨ä¸€ä¸ªè½»é‡çº§ç¥ç»ç½‘ç»œæ¥é‡å»ºä¸€ä¸ªæ— å­”å›¾åƒï¼ŒåŒ…æ‹¬è¶…è¿‡å…‰æ …åˆ†è¾¨ç‡çš„ç»†èŠ‚ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¸²æŸ“ç®¡é“æ˜¯å®Œå…¨å¯å¾®åˆ†çš„ï¼Œå…è®¸è‡ªåŠ¨ä¼˜åŒ–ç‚¹çš„å¤§å°å’Œä½ç½®ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šæˆ‘ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼ŒTRIPS åœ¨æ¸²æŸ“è´¨é‡æ–¹é¢è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼ŒåŒæ—¶åœ¨ç°æˆçš„ç¡¬ä»¶ä¸Šä¿æŒæ¯ç§’ 60 å¸§çš„å®æ—¶å¸§ç‡ã€‚è¿™ç§æ€§èƒ½æ‰©å±•åˆ°å…·æœ‰å¤æ‚å‡ ä½•å½¢çŠ¶ã€å¹¿é˜”æ™¯è§‚å’Œè‡ªåŠ¨æ›å…‰ç´ æçš„åœºæ™¯ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰å°†ç‚¹äº‘æŠ•å½±åˆ°å±å¹•ç©ºé—´å›¾åƒé‡‘å­—å¡”ä¸­ï¼Œé‡‘å­—å¡”å±‚çš„é€‰å–ç”±æŠ•å½±ç‚¹å¤§å°å†³å®šã€‚
ï¼ˆ2ï¼‰ä½¿ç”¨è½»é‡çº§ç¥ç»ç½‘ç»œé‡å»ºä¸€ä¸ªæ— å­”å›¾åƒï¼ŒåŒ…æ‹¬è¶…è¿‡å…‰æ …åˆ†è¾¨ç‡çš„ç»†èŠ‚ã€‚
ï¼ˆ3ï¼‰æ¸²æŸ“ç®¡é“æ˜¯å®Œå…¨å¯å¾®åˆ†çš„ï¼Œå…è®¸è‡ªåŠ¨ä¼˜åŒ–ç‚¹çš„å¤§å°å’Œä½ç½®ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰TRIPSï¼šå®æ—¶å…‰ç…§åœºçš„ä¸‰è§’å½¢ç‚¹äº‘æ¸²æŸ“ï¼Œæå‡ºäº†ä¸€ç§ç¨³å¥çš„å®æ—¶åŸºäºç‚¹çš„è¾å°„åœºæ¸²æŸ“ç®¡é“ã€‚TRIPS é‡‡ç”¨äº†ä¸€ç§æœ‰æ•ˆçš„ç­–ç•¥ï¼Œå°†ç‚¹å…‰æ …åŒ–ä¸ºå±å¹•ç©ºé—´å›¾åƒé‡‘å­—å¡”ï¼Œä»è€Œå¯ä»¥æœ‰æ•ˆåœ°æ¸²æŸ“å¤§ç‚¹ï¼Œå¹¶ä¸”æ˜¯å®Œå…¨å¯å¾®åˆ†çš„ï¼Œå› æ­¤å¯ä»¥è‡ªåŠ¨ä¼˜åŒ–ç‚¹çš„å¤§å°å’Œä½ç½®ã€‚è¿™ç§æŠ€æœ¯èƒ½å¤Ÿæ¸²æŸ“é«˜åº¦è¯¦ç»†çš„åœºæ™¯å¹¶å¡«å……å¤§é—´éš™ï¼ŒåŒæ—¶åœ¨å¸¸ç”¨ç¡¬ä»¶ä¸Šä¿æŒå®æ—¶å¸§é€Ÿç‡ã€‚æˆ‘ä»¬å¼ºè°ƒï¼ŒTRIPS å®ç°äº†å¾ˆé«˜çš„æ¸²æŸ“è´¨é‡ï¼Œå³ä½¿åœ¨å…·æœ‰å¤æ‚å‡ ä½•å½¢çŠ¶ã€å¤§è§„æ¨¡ç¯å¢ƒå’Œè‡ªåŠ¨æ›å…‰ç´ æç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ­¤å¤–ï¼Œç”±äºå¹³æ»‘ç‚¹æ¸²æŸ“æ–¹æ³•ï¼Œä¸€ä¸ªç›¸å¯¹ç®€å•çš„ç¥ç»ç½‘ç»œé‡å»ºå°±è¶³å¤Ÿäº†ï¼Œä»è€Œå®ç°äº†å®æ—¶æ¸²æŸ“æ€§èƒ½ã€‚å¼€æºå®ç°å¯åœ¨æ­¤å¤„è·å¾—ï¼šhttps://github.com/lfranke/TRIPS
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºç‚¹çš„è¾å°„åœºæ¸²æŸ“ç®¡é“ TRIPSï¼Œå®ƒç»“åˆäº†é«˜æ–¯æ¸²æŸ“å’Œ ADOP çš„æ€æƒ³ï¼Œåœ¨æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—äº†å¾ˆå¥½çš„å¹³è¡¡ã€‚</li>
<li>TRIPS é‡‡ç”¨äº†ä¸€ç§æœ‰æ•ˆçš„å…‰æ …åŒ–ç­–ç•¥ï¼Œå°†ç‚¹å…‰æ …åŒ–ä¸ºå±å¹•ç©ºé—´å›¾åƒé‡‘å­—å¡”ï¼Œä»è€Œå¯ä»¥æœ‰æ•ˆåœ°æ¸²æŸ“å¤§ç‚¹ã€‚</li>
<li>TRIPS çš„æ¸²æŸ“ç®¡é“æ˜¯å®Œå…¨å¯å¾®åˆ†çš„ï¼Œå› æ­¤å¯ä»¥è‡ªåŠ¨ä¼˜åŒ–ç‚¹çš„å¤§å°å’Œä½ç½®ã€‚
æ€§èƒ½ï¼š</li>
<li>TRIPS åœ¨æ¸²æŸ“è´¨é‡æ–¹é¢è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼ŒåŒæ—¶åœ¨ç°æˆçš„ç¡¬ä»¶ä¸Šä¿æŒæ¯ç§’ 60 å¸§çš„å®æ—¶å¸§ç‡ã€‚</li>
<li>TRIPS å¯ä»¥æ¸²æŸ“é«˜åº¦è¯¦ç»†çš„åœºæ™¯å¹¶å¡«å……å¤§é—´éš™ï¼Œå³ä½¿åœ¨å…·æœ‰å¤æ‚å‡ ä½•å½¢çŠ¶ã€å¤§è§„æ¨¡ç¯å¢ƒå’Œè‡ªåŠ¨æ›å…‰ç´ æç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</li>
<li>TRIPS ä½¿ç”¨äº†ä¸€ä¸ªè½»é‡çº§çš„ç¥ç»ç½‘ç»œæ¥é‡å»ºå›¾åƒï¼Œå› æ­¤æ¸²æŸ“é€Ÿåº¦å¾ˆå¿«ã€‚
å·¥ä½œé‡ï¼š</li>
<li>TRIPS çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¼€æºã€‚</li>
<li>TRIPS å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºå„ç§åœºæ™¯ï¼ŒåŒ…æ‹¬å…·æœ‰å¤æ‚å‡ ä½•å½¢çŠ¶ã€å¹¿é˜”æ™¯è§‚å’Œè‡ªåŠ¨æ›å…‰ç´ æçš„åœºæ™¯ã€‚</li>
<li>TRIPS å¯ä»¥å¾ˆå®¹æ˜“åœ°ä¸å…¶ä»–æ¸²æŸ“æŠ€æœ¯ç›¸ç»“åˆï¼Œä»¥åˆ›å»ºæ›´é€¼çœŸçš„å›¾åƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-09ec963291bb4ef95dcae847c73b65ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2e26b867b1d85086292f6b22b185913.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6615e2eef71a0b02f92f959a8a857c39.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e0e1cebcb888b31ce7e7665083bca1f9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f5d595ac6172487559d3c8aaa5130d1c.jpg" align="middle">
</details>




<h2 id="CoSSegGaussians-Compact-and-Swift-Scene-Segmenting-3D-Gaussians-with-Dual-Feature-Fusion"><a href="#CoSSegGaussians-Compact-and-Swift-Scene-Segmenting-3D-Gaussians-with-Dual-Feature-Fusion" class="headerlink" title="CoSSegGaussians: Compact and Swift Scene Segmenting 3D Gaussians with   Dual Feature Fusion"></a>CoSSegGaussians: Compact and Swift Scene Segmenting 3D Gaussians with   Dual Feature Fusion</h2><p><strong>Authors:Bin Dou, Tianyu Zhang, Yongjia Ma, Zhaohui Wang, Zejian Yuan</strong></p>
<p>We propose Compact and Swift Segmenting 3D Gaussians(CoSSegGaussians), a method for compact 3D-consistent scene segmentation at fast rendering speed with only RGB images input. Previous NeRF-based segmentation methods have relied on time-consuming neural scene optimization. While recent 3D Gaussian Splatting has notably improved speed, existing Gaussian-based segmentation methods struggle to produce compact masks, especially in zero-shot segmentation. This issue probably stems from their straightforward assignment of learnable parameters to each Gaussian, resulting in a lack of robustness against cross-view inconsistent 2D machine-generated labels. Our method aims to address this problem by employing Dual Feature Fusion Network as Gaussiansâ€™ segmentation field. Specifically, we first optimize 3D Gaussians under RGB supervision. After Gaussian Locating, DINO features extracted from images are applied through explicit unprojection, which are further incorporated with spatial features from the efficient point cloud processing network. Feature aggregation is utilized to fuse them in a global-to-local strategy for compact segmentation features. Experimental results show that our model outperforms baselines on both semantic and panoptic zero-shot segmentation task, meanwhile consumes less than 10\% inference time compared to NeRF-based methods. Code and more results will be available at <a href="https://David-Dou.github.io/CoSSegGaussians">https://David-Dou.github.io/CoSSegGaussians</a>. </p>
<p><a href="http://arxiv.org/abs/2401.05925v2">PDF</a> Correct writing details</p>
<p><strong>Summary:</strong></p>
<p>ä» RGB å›¾åƒä¸­å®æ—¶è¿›è¡Œç´§å‡‘çš„ 3D åœºæ™¯åˆ†å‰²ã€‚</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç´§å‡‘ä¸”å¿«é€Ÿçš„ä¸‰ç»´é«˜æ–¯åˆ†å‰²æ–¹æ³• CoSSegGaussiansï¼Œå¯åœ¨å¿«é€Ÿæ¸²æŸ“é€Ÿåº¦ä¸‹ä»…ä½¿ç”¨ RGB å›¾åƒè¾“å…¥è¿›è¡Œç´§å‡‘çš„ 3D ä¸€è‡´åœºæ™¯åˆ†å‰²ã€‚</li>
<li>CoSSegGaussians åœ¨è¯­ä¹‰å’Œå…¨æ™¯é›¶é•œå¤´åˆ†å‰²ä»»åŠ¡ä¸Šä¼˜äºåŸºå‡†ï¼ŒåŒæ—¶ä¸åŸºäº NeRF çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ¨ç†æ—¶é—´å‡å°‘äº† 10% ä»¥ä¸Šã€‚</li>
<li>è¯¥æ–¹æ³•çš„ç›®æ ‡æ˜¯é€šè¿‡ä½¿ç”¨åŒç‰¹å¾èåˆç½‘ç»œä½œä¸ºé«˜æ–¯çš„åˆ†å‰²åœºæ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚</li>
<li>é¦–å…ˆä¼˜åŒ– RGB ç›‘ç£ä¸‹çš„ 3D é«˜æ–¯å‡½æ•°ã€‚</li>
<li>ä»å›¾åƒä¸­æå–çš„ DINO ç‰¹å¾é€šè¿‡æ˜¾å¼åæŠ•å½±åº”ç”¨ï¼Œè¿›ä¸€æ­¥ä¸æ¥è‡ªé«˜æ•ˆç‚¹äº‘å¤„ç†ç½‘ç»œçš„ç©ºé—´ç‰¹å¾ç»“åˆã€‚</li>
<li>åˆ©ç”¨ç‰¹å¾èšåˆä»¥å…¨å±€åˆ°å±€éƒ¨ç­–ç•¥èåˆå®ƒä»¬ï¼Œä»¥å®ç°ç´§å‡‘çš„åˆ†å‰²ç‰¹å¾ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è¯­ä¹‰å’Œå…¨æ™¯é›¶é•œå¤´åˆ†å‰²ä»»åŠ¡ä¸Šä¼˜äºåŸºå‡†ï¼ŒåŒæ—¶ä¸åŸºäº NeRF çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ¨ç†æ—¶é—´å‡å°‘äº† 10% ä»¥ä¸Šã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šCoSSegGaussiansï¼šç´§å‡‘ä¸”å¿«é€Ÿçš„åŒç‰¹å¾èåˆé«˜æ–¯ä½“åœºæ™¯åˆ†å‰²</li>
<li>ä½œè€…ï¼šBin Dou, Tianyu Zhang, Yongjia Ma, Zhaohui Wang, Zejian Yuan</li>
<li>å•ä½ï¼šè¥¿å®‰äº¤é€šå¤§å­¦äººå·¥æ™ºèƒ½ä¸æœºå™¨äººå­¦é™¢</li>
<li>å…³é”®è¯ï¼šåœºæ™¯åˆ†å‰²ã€ç¥ç»è¾å°„åœºã€é«˜æ–¯ä½“ã€åŒç‰¹å¾èåˆç½‘ç»œ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.05925</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œè®¡ç®—æœºè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¥ç»æ¸²æŸ“é¢†åŸŸã€‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åŠå…¶åç»­æ–¹æ³•æ¨åŠ¨äº†ç¥ç»åœºæ™¯è¡¨ç¤ºçš„å‘å±•ï¼Œåœ¨æ–°å‹è§†å›¾åˆæˆæ–¹é¢å±•ç°å‡ºæ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒåŸºäºNeRFçš„åœºæ™¯åˆ†å‰²æ–¹æ³•ä¾èµ–äºè€—æ—¶çš„ç¥ç»åœºæ™¯ä¼˜åŒ–ã€‚è™½ç„¶æœ€è¿‘çš„3Dé«˜æ–¯ä½“æ¸²æŸ“æ˜¾è‘—æé«˜äº†é€Ÿåº¦ï¼Œä½†ç°æœ‰çš„åŸºäºé«˜æ–¯ä½“çš„åˆ†å‰²æ–¹æ³•éš¾ä»¥ç”Ÿæˆç´§å‡‘çš„æ©æ¨¡ï¼Œå°¤å…¶æ˜¯åœ¨é›¶æ ·æœ¬åˆ†å‰²ä¸­ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•ç›´æ¥å°†å¯å­¦ä¹ çš„å‚æ•°åˆ†é…ç»™æ¯ä¸ªé«˜æ–¯ä½“ï¼Œå¯¼è‡´å¯¹è·¨è§†å›¾ä¸ä¸€è‡´çš„2Dæœºå™¨ç”Ÿæˆçš„æ ‡ç­¾ç¼ºä¹é²æ£’æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºä¸€ç§ç´§å‡‘ä¸”å¿«é€Ÿçš„é«˜æ–¯ä½“åœºæ™¯åˆ†å‰²æ–¹æ³•CoSSegGaussiansã€‚è¯¥æ–¹æ³•é¦–å…ˆåœ¨RGBç›‘ç£ä¸‹ä¼˜åŒ–3Dé«˜æ–¯ä½“ã€‚åœ¨é«˜æ–¯ä½“å®šä½åï¼Œå°†ä»å›¾åƒä¸­æå–çš„DINOç‰¹å¾é€šè¿‡æ˜¾å¼åæŠ•å½±åº”ç”¨ï¼Œå¹¶è¿›ä¸€æ­¥ä¸æ¥è‡ªé«˜æ•ˆç‚¹äº‘å¤„ç†ç½‘ç»œçš„ç©ºé—´ç‰¹å¾ç»“åˆã€‚åˆ©ç”¨ç‰¹å¾èšåˆä»¥å…¨å±€åˆ°å±€éƒ¨çš„ç­–ç•¥å°†å®ƒä»¬èåˆï¼Œä»¥è·å¾—ç´§å‡‘çš„åˆ†å‰²ç‰¹å¾ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è¯­ä¹‰å’Œå…¨æ™¯é›¶æ ·æœ¬åˆ†å‰²ä»»åŠ¡ä¸Šä¼˜äºåŸºçº¿ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´ä¸åˆ°åŸºäºNeRFæ–¹æ³•çš„10%ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰é«˜æ–¯ä½“å®šä½é˜¶æ®µï¼šåˆ©ç”¨ L1 å’Œ â„“D-SSIM å…‰åº¦æŸå¤±å¯¹ 3D é«˜æ–¯ä½“çš„å‡ ä½•ä¿¡æ¯è¿›è¡Œç›‘ç£ï¼Œä»¥è·å¾—é€¼çœŸçš„åœºæ™¯è¡¨ç¤ºã€‚
ï¼ˆ2ï¼‰åˆ†å‰²é˜¶æ®µï¼šå°†ä»å›¾åƒä¸­æå–çš„ DINO ç‰¹å¾é€šè¿‡æ˜¾å¼åæŠ•å½±åº”ç”¨ï¼Œå¹¶è¿›ä¸€æ­¥ä¸æ¥è‡ª RandLA-Net çš„ç©ºé—´ç‰¹å¾ç›¸ç»“åˆã€‚
ï¼ˆ3ï¼‰ç‰¹å¾èšåˆï¼šåˆ©ç”¨ç‰¹å¾èšåˆä»¥å…¨å±€åˆ°å±€éƒ¨çš„ç­–ç•¥å°†å®ƒä»¬èåˆï¼Œä»¥è·å¾—ç´§å‡‘çš„åˆ†å‰²ç‰¹å¾ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§ç´§å‡‘ä¸”å¿«é€Ÿçš„åŸºäºé«˜æ–¯ä½“çš„åœºæ™¯åˆ†å‰²æ–¹æ³• CoSSegGaussiansï¼Œè¯¥æ–¹æ³•åœ¨ä»…æœ‰ RGB å›¾åƒçš„æ¡ä»¶ä¸‹å®ç°äº†ç´§å‡‘ä¸”å¿«é€Ÿçš„åœºæ™¯åˆ†å‰²ã€‚è¯¥æ–¹æ³•å»ºç«‹åœ¨ 3D é«˜æ–¯ä½“ä¹‹ä¸Šï¼Œå¹¶åˆ©ç”¨åŒç‰¹å¾èåˆç½‘ç»œä½œä¸ºåˆ†å‰²åœºï¼Œè¯¥ç½‘ç»œèšåˆäº† DINO å’Œç©ºé—´ç‰¹å¾è¿›è¡Œåˆ†å‰²ã€‚æ¥è‡ªå›¾åƒçš„å¤šå°ºåº¦ DINO ç‰¹å¾é€šè¿‡åæŠ•å½±å¼•å…¥å®šä½çš„ 3D é«˜æ–¯ä½“ï¼Œå¹¶è¿›ä¸€æ­¥ä¸æ¥è‡ª RandLA-Net çš„é«˜æ–¯ä½“çš„ç©ºé—´ä¿¡æ¯ç›¸ç»“åˆã€‚ç„¶ååº”ç”¨å…¨å±€åˆ°å±€éƒ¨çš„èšåˆæ¨¡å—æ¥ç”Ÿæˆç´§å‡‘çš„åˆ†å‰²é€»è¾‘ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥å¯é ä¸”é«˜æ•ˆåœ°å®Œæˆé›¶æ ·æœ¬åˆ†å‰²ä»»åŠ¡ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§ç´§å‡‘ä¸”å¿«é€Ÿçš„åŸºäºé«˜æ–¯ä½“çš„åœºæ™¯åˆ†å‰²æ–¹æ³• CoSSegGaussiansã€‚</li>
<li>åˆ©ç”¨åŒç‰¹å¾èåˆç½‘ç»œä½œä¸ºåˆ†å‰²åœºï¼Œè¯¥ç½‘ç»œèšåˆäº† DINO å’Œç©ºé—´ç‰¹å¾è¿›è¡Œåˆ†å‰²ã€‚</li>
<li>å°†æ¥è‡ªå›¾åƒçš„å¤šå°ºåº¦ DINO ç‰¹å¾é€šè¿‡åæŠ•å½±å¼•å…¥å®šä½çš„ 3D é«˜æ–¯ä½“ï¼Œå¹¶è¿›ä¸€æ­¥ä¸æ¥è‡ª RandLA-Net çš„é«˜æ–¯ä½“çš„ç©ºé—´ä¿¡æ¯ç›¸ç»“åˆã€‚</li>
<li>åº”ç”¨å…¨å±€åˆ°å±€éƒ¨çš„èšåˆæ¨¡å—æ¥ç”Ÿæˆç´§å‡‘çš„åˆ†å‰²é€»è¾‘ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è¯­ä¹‰å’Œå…¨æ™¯é›¶æ ·æœ¬åˆ†å‰²ä»»åŠ¡ä¸Šä¼˜äºåŸºçº¿ã€‚</li>
<li>æ¨ç†æ—¶é—´ä¸åˆ°åŸºäº NeRF æ–¹æ³•çš„ 10%ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®ºæ–‡é•¿åº¦é€‚ä¸­ï¼Œå®éªŒéƒ¨åˆ†è¾ƒä¸ºè¯¦ç»†ã€‚</li>
<li>ä»£ç å’Œæ•°æ®å·²å¼€æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7b3b4f44e1bfaba57c660121007fee8a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-222c4f05c24f306aefd909de021e726c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e297ea1e2c85e96907865cc0d6107864.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27a48d664aab4676f21f642635ecb972.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8a12edf74e5d62d5f426b60407d904ab.jpg" align="middle">
</details>




<h2 id="AGG-Amortized-Generative-3D-Gaussians-for-Single-Image-to-3D"><a href="#AGG-Amortized-Generative-3D-Gaussians-for-Single-Image-to-3D" class="headerlink" title="AGG: Amortized Generative 3D Gaussians for Single Image to 3D"></a>AGG: Amortized Generative 3D Gaussians for Single Image to 3D</h2><p><strong>Authors:Dejia Xu, Ye Yuan, Morteza Mardani, Sifei Liu, Jiaming Song, Zhangyang Wang, Arash Vahdat</strong></p>
<p>Given the growing need for automatic 3D content creation pipelines, various 3D representations have been studied to generate 3D objects from a single image. Due to its superior rendering efficiency, 3D Gaussian splatting-based models have recently excelled in both 3D reconstruction and generation. 3D Gaussian splatting approaches for image to 3D generation are often optimization-based, requiring many computationally expensive score-distillation steps. To overcome these challenges, we introduce an Amortized Generative 3D Gaussian framework (AGG) that instantly produces 3D Gaussians from a single image, eliminating the need for per-instance optimization. Utilizing an intermediate hybrid representation, AGG decomposes the generation of 3D Gaussian locations and other appearance attributes for joint optimization. Moreover, we propose a cascaded pipeline that first generates a coarse representation of the 3D data and later upsamples it with a 3D Gaussian super-resolution module. Our method is evaluated against existing optimization-based 3D Gaussian frameworks and sampling-based pipelines utilizing other 3D representations, where AGG showcases competitive generation abilities both qualitatively and quantitatively while being several orders of magnitude faster. Project page: <a href="https://ir1d.github.io/AGG/">https://ir1d.github.io/AGG/</a> </p>
<p><a href="http://arxiv.org/abs/2401.04099v1">PDF</a> Project page: <a href="https://ir1d.github.io/AGG/">https://ir1d.github.io/AGG/</a></p>
<p><strong>æ‘˜è¦</strong><br>æ— éœ€æ˜‚è´µè®¡ç®—ï¼ŒAGG å³å¯ç›´æ¥ä»å›¾åƒç”Ÿæˆ 3D é«˜æ–¯ä½“ç´ ï¼Œå¤§å¹…æå‡äº† 3D å†…å®¹åˆ›å»ºæ•ˆç‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>AGG æ˜¯ä¸€ä¸ªç›´æ¥ä»å›¾åƒç”Ÿæˆ 3D é«˜æ–¯ä½“ç´ çš„æ¡†æ¶ï¼Œæ— éœ€é€ä¾‹ä¼˜åŒ–ï¼Œå¤§å¤§æé«˜äº†ç”Ÿæˆæ•ˆç‡ã€‚</li>
<li>AGG ä½¿ç”¨äº†æ··åˆè¡¨ç¤ºï¼Œå°† 3D é«˜æ–¯ä½“ç´ çš„ä½ç½®å’Œå¤–è§‚å±æ€§åˆ†å¼€ç”Ÿæˆï¼Œå¹¶è”åˆä¼˜åŒ–ã€‚</li>
<li>AGG ä½¿ç”¨çº§è”ç®¡é“ï¼Œå…ˆç”Ÿæˆ 3D æ•°æ®çš„ç²—ç•¥è¡¨ç¤ºï¼Œç„¶åé€šè¿‡ 3D é«˜æ–¯ä½“ç´ è¶…åˆ†è¾¨ç‡æ¨¡å—è¿›è¡Œä¸Šé‡‡æ ·ã€‚</li>
<li>AGG åœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰åŸºäºä¼˜åŒ–çš„ 3D é«˜æ–¯ä½“ç´ æ¡†æ¶å’Œä½¿ç”¨å…¶ä»– 3D è¡¨ç¤ºçš„åŸºäºé‡‡æ ·çš„ç®¡é“ã€‚</li>
<li>AGG çš„é€Ÿåº¦æ¯”ç°æœ‰æ–¹æ³•å¿«å‡ ä¸ªæ•°é‡çº§ã€‚</li>
<li>é¡¹ç›®ä¸»é¡µï¼š<a href="https://ir1d.github.io/AGG/">https://ir1d.github.io/AGG/</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šAGGï¼šç”¨äºå•å›¾åƒåˆ° 3D çš„æ‘Šä½™ç”Ÿæˆ 3D é«˜æ–¯ï¼ˆAGGï¼šAmortized Generative 3D Gaussians for Single Image to 3Dï¼‰</li>
<li>ä½œè€…ï¼šDejia Xu, Ye Yuan, Morteza Mardani, Sifei Liu, Jiaming Song, Zhangyang Wang, Arash Vahdat</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡</li>
<li>å…³é”®è¯ï¼šå›¾åƒåˆ° 3Dã€3D ç”Ÿæˆã€3D é«˜æ–¯ã€æ‘Šä½™ç”Ÿæˆã€çº§è”ç®¡é“</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.04099ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰éšç€å¯¹è‡ªåŠ¨ 3D å†…å®¹åˆ›å»ºç®¡é“éœ€æ±‚çš„ä¸æ–­å¢é•¿ï¼Œå·²ç»ç ”ç©¶äº†å„ç§ 3D è¡¨ç¤ºæ¥ä»å•ä¸ªå›¾åƒç”Ÿæˆ 3D å¯¹è±¡ã€‚ç”±äºå…¶å“è¶Šçš„æ¸²æŸ“æ•ˆç‡ï¼ŒåŸºäº 3D é«˜æ–¯ splatting çš„æ¨¡å‹æœ€è¿‘åœ¨ 3D é‡å»ºå’Œç”Ÿæˆæ–¹é¢éƒ½è¡¨ç°å‡ºè‰²ã€‚ç”¨äºå›¾åƒåˆ° 3D ç”Ÿæˆçš„ 3D é«˜æ–¯ splatting æ–¹æ³•é€šå¸¸åŸºäºä¼˜åŒ–ï¼Œéœ€è¦è®¸å¤šè®¡ç®—æˆæœ¬é«˜æ˜‚çš„å¾—åˆ†è’¸é¦æ­¥éª¤ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ‘Šä½™ç”Ÿæˆ 3D é«˜æ–¯æ¡†æ¶ï¼ˆAGGï¼‰ï¼Œè¯¥æ¡†æ¶å¯ä»¥ä»å•ä¸ªå›¾åƒç«‹å³ç”Ÿæˆ 3D é«˜æ–¯ï¼Œä»è€Œæ— éœ€è¿›è¡Œé€ä¸ªå®ä¾‹çš„ä¼˜åŒ–ã€‚åˆ©ç”¨ä¸­é—´æ··åˆè¡¨ç¤ºï¼ŒAGG åˆ†è§£äº† 3D é«˜æ–¯ä½ç½®å’Œå…¶ä»–å¤–è§‚å±æ€§çš„ç”Ÿæˆï¼Œä»¥ä¾¿è¿›è¡Œè”åˆä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªçº§è”ç®¡é“ï¼Œè¯¥ç®¡é“é¦–å…ˆç”Ÿæˆ 3D æ•°æ®çš„ç²—ç•¥è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨ 3D é«˜æ–¯è¶…åˆ†è¾¨ç‡æ¨¡å—å¯¹å…¶è¿›è¡Œä¸Šé‡‡æ ·ã€‚æˆ‘ä»¬çš„æ–¹æ³•é’ˆå¯¹ç°æœ‰åŸºäºä¼˜åŒ–çš„ 3D é«˜æ–¯æ¡†æ¶å’Œåˆ©ç”¨å…¶ä»– 3D è¡¨ç¤ºçš„åŸºäºé‡‡æ ·çš„ç®¡é“è¿›è¡Œäº†è¯„ä¼°ï¼Œå…¶ä¸­ AGG åœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½å±•ç¤ºäº†å…·æœ‰ç«äº‰åŠ›çš„ç”Ÿæˆèƒ½åŠ›ï¼ŒåŒæ—¶é€Ÿåº¦æé«˜äº†å‡ ä¸ªæ•°é‡çº§ã€‚</li>
</ol>
<p>Methods:
(1): AGGé€šè¿‡æ‘Šä½™ç”Ÿæˆæ¥é¿å…é€ä¸ªå®ä¾‹çš„ä¼˜åŒ–ï¼Œä»è€Œå®ç°ä»å•ä¸ªå›¾åƒåˆ°3Dé«˜æ–¯çš„ç«‹å³ç”Ÿæˆã€‚
(2): AGGåˆ©ç”¨ä¸­é—´æ··åˆè¡¨ç¤ºå°†3Dé«˜æ–¯ä½ç½®å’Œå…¶ä»–å¤–è§‚å±æ€§çš„ç”Ÿæˆåˆ†è§£ä¸ºè”åˆä¼˜åŒ–é—®é¢˜ã€‚
(3): AGGé‡‡ç”¨çº§è”ç®¡é“ï¼Œé¦–å…ˆç”Ÿæˆ3Dæ•°æ®çš„ç²—ç•¥è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨3Dé«˜æ–¯è¶…åˆ†è¾¨ç‡æ¨¡å—å¯¹å…¶è¿›è¡Œä¸Šé‡‡æ ·ã€‚
(4): AGGåœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½å±•ç¤ºäº†å…·æœ‰ç«äº‰åŠ›çš„ç”Ÿæˆèƒ½åŠ›ï¼ŒåŒæ—¶é€Ÿåº¦æé«˜äº†å‡ ä¸ªæ•°é‡çº§ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é¦–æ¬¡å°è¯•å¼€å‘ä¸€ä¸ªèƒ½å¤Ÿä»å•å¼ å›¾åƒè¾“å…¥ç”Ÿæˆ 3D é«˜æ–¯ splatting çš„æ‘Šä½™ç®¡é“ã€‚æå‡ºçš„ AGG æ¡†æ¶åˆ©ç”¨çº§è”ç”Ÿæˆç®¡é“ï¼ŒåŒ…æ‹¬ç²—ç•¥æ··åˆç”Ÿæˆå™¨å’Œé«˜æ–¯è¶…åˆ†è¾¨ç‡æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºäºä¼˜åŒ–çš„ 3D é«˜æ–¯æ¡†æ¶å’ŒåŸºäºé‡‡æ ·çš„ 3D ç”Ÿæˆæ¡†æ¶ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å•å›¾åƒåˆ° 3D ç”Ÿæˆä¸­å®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå¹¶ä¸”é€Ÿåº¦æé«˜äº†å‡ ä¸ªæ•°é‡çº§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ‘Šä½™ç”Ÿæˆ 3D é«˜æ–¯ splatting çš„æ–°æ¡†æ¶ AGGï¼Œè¯¥æ¡†æ¶å¯ä»¥ä»å•å¼ å›¾åƒç«‹å³ç”Ÿæˆ 3D é«˜æ–¯ï¼Œè€Œæ— éœ€è¿›è¡Œé€ä¸ªå®ä¾‹çš„ä¼˜åŒ–ã€‚
åˆ©ç”¨ä¸­é—´æ··åˆè¡¨ç¤ºå°† 3D é«˜æ–¯ä½ç½®å’Œå…¶ä»–å¤–è§‚å±æ€§çš„ç”Ÿæˆåˆ†è§£ä¸ºè”åˆä¼˜åŒ–é—®é¢˜ï¼Œæé«˜äº†ç”Ÿæˆæ•ˆç‡ã€‚
é‡‡ç”¨çº§è”ç®¡é“ï¼Œé¦–å…ˆç”Ÿæˆ 3D æ•°æ®çš„ç²—ç•¥è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨ 3D é«˜æ–¯è¶…åˆ†è¾¨ç‡æ¨¡å—å¯¹å…¶è¿›è¡Œä¸Šé‡‡æ ·ï¼Œæé«˜äº†ç”Ÿæˆçš„è´¨é‡ã€‚
æ€§èƒ½ï¼š
åœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½å±•ç¤ºäº†å…·æœ‰ç«äº‰åŠ›çš„ç”Ÿæˆèƒ½åŠ›ï¼Œåœ¨å•å›¾åƒåˆ° 3D ç”Ÿæˆä¸­çš„é€Ÿåº¦æé«˜äº†å‡ ä¸ªæ•°é‡çº§ã€‚
å·¥ä½œé‡ï¼š
ä»£ç å’Œæ•°æ®å°†åœ¨è®ºæ–‡å‘å¸ƒåå…¬å¼€ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7f1992dc148bbeebd8e201f1e361744a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dfa4769a03fba071a100ba492ba057c1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a15f930311ed81ec60e68bbe1e79e746.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-436ee02cfefc628563bdcac1719e6c80.jpg" align="middle">
</details>




<h2 id="PEGASUS-Physically-Enhanced-Gaussian-Splatting-Simulation-System-for-6DOF-Object-Pose-Dataset-Generation"><a href="#PEGASUS-Physically-Enhanced-Gaussian-Splatting-Simulation-System-for-6DOF-Object-Pose-Dataset-Generation" class="headerlink" title="PEGASUS: Physically Enhanced Gaussian Splatting Simulation System for   6DOF Object Pose Dataset Generation"></a>PEGASUS: Physically Enhanced Gaussian Splatting Simulation System for   6DOF Object Pose Dataset Generation</h2><p><strong>Authors:Lukas Meyer, Floris Erich, Yusuke Yoshiyasu, Marc Stamminger, Noriaki Ando, Yukiyasu Domae</strong></p>
<p>We introduce Physically Enhanced Gaussian Splatting Simulation System (PEGASUS) for 6DOF object pose dataset generation, a versatile dataset generator based on 3D Gaussian Splatting. Environment and object representations can be easily obtained using commodity cameras to reconstruct with Gaussian Splatting. PEGASUS allows the composition of new scenes by merging the respective underlying Gaussian Splatting point cloud of an environment with one or multiple objects. Leveraging a physics engine enables the simulation of natural object placement within a scene through interaction between meshes extracted for the objects and the environment. Consequently, an extensive amount of new scenes - static or dynamic - can be created by combining different environments and objects. By rendering scenes from various perspectives, diverse data points such as RGB images, depth maps, semantic masks, and 6DoF object poses can be extracted. Our study demonstrates that training on data generated by PEGASUS enables pose estimation networks to successfully transfer from synthetic data to real-world data. Moreover, we introduce the Ramen dataset, comprising 30 Japanese cup noodle items. This dataset includes spherical scans that captures images from both object hemisphere and the Gaussian Splatting reconstruction, making them compatible with PEGASUS. </p>
<p><a href="http://arxiv.org/abs/2401.02281v1">PDF</a> Project Page: <a href="https://meyerls.github.io/pegasus_web">https://meyerls.github.io/pegasus_web</a></p>
<p><strong>Summary</strong><br>å…­è‡ªç”±åº¦ç›®æ ‡ä½å§¿æ•°æ®é›†ç”Ÿæˆçš„æ–°å‹ç‰©ç†å®ä½“å¢å¼ºé«˜æ–¯æº…å°„æ¨¡æ‹Ÿç³»ç»Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>PEGASUS ä½¿ç”¨å•†å“ç›¸æœºè½»æ¾è·å–ç¯å¢ƒå’Œç‰©ä½“è¡¨ç¤ºï¼Œé‡å»ºå¸¦æœ‰é«˜æ–¯æº…å°„çš„åœºæ™¯ã€‚</li>
<li>PEGASUS å…è®¸é€šè¿‡åˆå¹¶ç¯å¢ƒä¸ä¸€ä¸ªæˆ–å¤šä¸ªç‰©ä½“çš„ç›¸åº”åº•å±‚é«˜æ–¯æº…å°„ç‚¹äº‘æ¥ç»„æˆæ–°åœºæ™¯ã€‚</li>
<li>åˆ©ç”¨ç‰©ç†å¼•æ“èƒ½å¤Ÿæ¨¡æ‹Ÿç‰©ä½“åœ¨åœºæ™¯ä¸­çš„è‡ªç„¶æ”¾ç½®ï¼Œé€šè¿‡æå–çš„ç‰©ä½“ç½‘æ ¼å’Œç¯å¢ƒä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚</li>
<li>é€šè¿‡å°†ä¸åŒçš„ç¯å¢ƒå’Œç‰©ä½“ç»„åˆèµ·æ¥ï¼Œå¯ä»¥åˆ›å»ºå¤§é‡æ–°çš„é™æ€æˆ–åŠ¨æ€åœºæ™¯ã€‚</li>
<li>é€šè¿‡ä»ä¸åŒè§†è§’æ¸²æŸ“åœºæ™¯ï¼Œå¯ä»¥æå–å„ç§æ•°æ®ç‚¹ï¼Œä¾‹å¦‚ RGB å›¾åƒã€æ·±åº¦å›¾ã€è¯­ä¹‰è’™ç‰ˆå’Œ 6DoF ç›®æ ‡ä½å§¿ã€‚</li>
<li>åœ¨ PEGASUS ç”Ÿæˆçš„è®­ç»ƒæ•°æ®ä¸Šè®­ç»ƒçš„ä½å§¿ä¼°è®¡ç½‘ç»œèƒ½å¤ŸæˆåŠŸåœ°ä»åˆæˆæ•°æ®è½¬ç§»åˆ°çœŸå®æ•°æ®ã€‚</li>
<li>æˆ‘ä»¬ä»‹ç»äº†åŒ…å« 30 ç§æ—¥æœ¬æ¯é¢å•†å“çš„ Ramen æ•°æ®é›†ã€‚æ­¤æ•°æ®é›†åŒ…æ‹¬çƒå½¢æ‰«æï¼Œå¯ä»ç›®æ ‡åŠçƒå’Œé«˜æ–¯æº…å°„é‡å»ºä¸­æ•è·å›¾åƒï¼Œä½¿å…¶ä¸ PEGASUS å…¼å®¹ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šPEGASUSï¼šç”¨äº 6DOF ç‰©ä½“ä½å§¿æ•°æ®é›†ç”Ÿæˆçš„ç‰©ç†å¢å¼ºé«˜æ–¯æ•£å°„æ¨¡æ‹Ÿç³»ç»Ÿ</li>
<li>ä½œè€…ï¼šLukas Meyer, Floris Erich, Yusuke Yoshiyasu, Marc Stamminger, Noriaki Ando, Yukiyasu Domae</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šFriedrich-Alexander-UniversitÂ¨at Erlangen-NÂ¨urnberg-FÂ¨urth</li>
<li>å…³é”®è¯ï¼šæ•°æ®é›†ç”Ÿæˆã€æœºå™¨äººã€å…‰åœºã€sim2real</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2401.02281.pdfï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€äººå£ç»“æ„çš„å˜åŒ–ï¼Œè®¸å¤šå›½å®¶é¢ä¸´ç€åŠ³åŠ¨åŠ›çŸ­ç¼ºçš„é—®é¢˜ã€‚æ—¥æœ¬ä¹Ÿä¸ä¾‹å¤–ï¼Œå…¶äººå£æ­£åœ¨å‡å°‘ï¼Œå¯¼è‡´æ”¿åºœåœ¨å¤šä¸ªè¡Œä¸šï¼ˆå¦‚åŒ»ç–—ä¿å¥ã€åˆ¶é€ ä¸šå’Œå†œä¸šï¼‰å¤§åŠ›æŠ•èµ„æœºå™¨äººï¼Œä»¥ç»´æŒåŠ³åŠ¨åŠ›ç¨³å®šã€‚æœ¬æ–‡çš„ç ”ç©¶é‡ç‚¹æ˜¯å¼€å‘æœåŠ¡ä¸šçš„æœºå™¨äººç³»ç»Ÿï¼Œä»¥æ”¯æŒé›¶å”®ä¸šçš„äººå‘˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†åº”ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•è¿›è¡Œç‰©ä½“ä½å§¿ä¼°è®¡ï¼Œå¤§å¤šæ•°æ•°æ®é›†éƒ½é›†ä¸­åœ¨è¥¿æ–¹é£æ ¼çš„äº§å“ä¸Šã€‚ç„¶è€Œï¼Œä½¿ç”¨è¿™äº›æ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹åœ¨åº”ç”¨äºå®é™…åœºæ™¯æ—¶å¾€å¾€å­˜åœ¨åŸŸå·®è·é—®é¢˜ï¼Œå› ä¸ºåˆæˆç”Ÿæˆçš„æ•°æ®ç¼ºä¹çœŸå®æ€§ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³åŸŸå·®è·é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º PEGASUS çš„ç‰©ç†å¢å¼ºé«˜æ–¯æ•£å°„æ¨¡æ‹Ÿç³»ç»Ÿï¼Œç”¨äºç”Ÿæˆ 6DOF ç‰©ä½“ä½å§¿æ•°æ®é›†ã€‚PEGASUS å…è®¸å°†ç¯å¢ƒå’Œç‰©ä½“è¡¨ç¤ºåˆå¹¶ï¼Œä»¥ä¾¿åˆ›å»ºæ–°çš„åœºæ™¯ã€‚é€šè¿‡åˆ©ç”¨ç‰©ç†å¼•æ“ï¼Œå¯ä»¥åœ¨åœºæ™¯ä¸­æ¨¡æ‹Ÿè‡ªç„¶ç‰©ä½“æ”¾ç½®ï¼Œä»è€Œåˆ›å»ºå¤§é‡çš„é™æ€æˆ–åŠ¨æ€æ–°åœºæ™¯ã€‚é€šè¿‡ä»ä¸åŒè§†è§’æ¸²æŸ“åœºæ™¯ï¼Œå¯ä»¥æå–å„ç§æ•°æ®ç‚¹ï¼Œå¦‚ RGB å›¾åƒã€æ·±åº¦å›¾ã€è¯­ä¹‰æ©ç å’Œ 6DoF ç‰©ä½“ä½å§¿ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½åŠå¯¹ç›®æ ‡çš„æ”¯æŒï¼šç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨ PEGASUS ç”Ÿæˆçš„è®­ç»ƒæ•°æ®å¯ä»¥ä½¿ä½å§¿ä¼°è®¡ç½‘ç»œæˆåŠŸåœ°ä»åˆæˆæ•°æ®è½¬ç§»åˆ°çœŸå®ä¸–ç•Œæ•°æ®ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜ä»‹ç»äº†æ‹‰é¢æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å« 30 ç§æ—¥æœ¬æ¯é¢ã€‚è¯¥æ•°æ®é›†åŒ…æ‹¬ä»ç‰©ä½“ä¸¤ä¸ªåŠçƒæ•è·å›¾åƒçš„çƒå½¢æ‰«æå’Œé«˜æ–¯æ•£å°„é‡å»ºï¼Œä½¿å…¶ä¸ PEGASUS å…¼å®¹ã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š</p>
<p>(1) é«˜æ–¯æ•£å°„åŸºç¡€ç¯å¢ƒï¼šé€šè¿‡ä½¿ç”¨ Structure from Motion (SfM) é‡å»ºæŠ€æœ¯å’Œ CherryPicker æ–¹æ³•ï¼Œä» 10 ä¸ªä¸åŒåœºæ™¯ä¸­æå–ç¨€ç–ç‚¹äº‘ï¼Œå¹¶ä½¿ç”¨é«˜æ–¯æ•£å°„æŠ€æœ¯ç”ŸæˆåŸºç¡€ç¯å¢ƒçš„ 3D é‡å»ºå’Œç½‘æ ¼ã€‚</p>
<p>(2) é«˜æ–¯æ•£å°„å¯¹è±¡ï¼šåˆ©ç”¨ Ortery æ‰«æç³»ç»Ÿå¯¹ç‰©ä½“è¿›è¡Œå›¾åƒé‡‡é›†ï¼Œå¹¶ä½¿ç”¨ä¸åŸºç¡€ç¯å¢ƒç›¸åŒçš„è®¾ç½®è¿›è¡Œé«˜æ–¯æ•£å°„å¤„ç†ï¼Œç”Ÿæˆç‰©ä½“çš„ç…§åº¦å®ä½“å’Œå‡ ä½•å®ä½“ã€‚</p>
<p>(3) ç‰©ç†å¼•æ“ï¼šå°† PyBullet é›†æˆåˆ° PEGASUS ä¸­ï¼Œä½œä¸ºç‰©ç†å¼•æ“ï¼Œç”¨äºæ¨¡æ‹Ÿç‰©ä½“çš„è‡ªç„¶æ”¾ç½®å’ŒåŠ¨æ€åœºæ™¯çš„åˆ›å»ºã€‚</p>
<p>(4) PEGASUS æ•°æ®é›†ç”Ÿæˆï¼šé€šè¿‡å°†é«˜æ–¯æ•£å°„åŸºç¡€ç¯å¢ƒå’Œé«˜æ–¯æ•£å°„å¯¹è±¡é›†æˆï¼Œåˆ©ç”¨ç‰©ç†å¼•æ“æ¨¡æ‹Ÿç‰©ä½“çš„è¿åŠ¨è½¨è¿¹ï¼Œå¹¶ä½¿ç”¨é«˜æ–¯æ•£å°„æ¸²æŸ“å™¨æ¸²æŸ“åœºæ™¯ï¼Œç”ŸæˆåŒ…å« RGB å›¾åƒã€æ·±åº¦å›¾ã€è¯­ä¹‰æ©ç ã€2D/3D è¾¹ç•Œæ¡†å’Œå˜æ¢çŸ©é˜µç­‰æ•°æ®çš„è®­ç»ƒæ•°æ®é›†ã€‚</p>
<p>(5) æ‹‰é¢æ•°æ®é›†ï¼šä½¿ç”¨ 3DPhotoBench280 å’Œ 3DMultiArm2000 ç›¸æœºç³»ç»Ÿæ‰«æ 30 å¤šç§æ¯é¢ï¼Œå¹¶ä½¿ç”¨è‡ªåŠ¨èƒŒæ™¯å»é™¤æŠ€æœ¯å’Œç‰¹å¾ä¸°å¯Œçš„è¡¨é¢è¿›è¡Œæ ¡å‡†ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šPEGASUSæ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½çš„æ•°æ®é›†ç”Ÿæˆå™¨ï¼Œæ—¨åœ¨æé«˜ç‰©ä½“ä½å§¿ä¼°è®¡çš„å‡†ç¡®æ€§å’Œè´¨é‡ã€‚é™¤äº†PEGASUSï¼Œæˆ‘ä»¬è¿˜ä»‹ç»äº†æ‹‰é¢æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«30å¤šç§ä¸åŒçš„äº§å“ã€‚è¯¥æ•°æ®é›†ç”Ÿæˆå™¨å·§å¦™åœ°åˆ›å»ºäº†é€¼çœŸçš„æ¸²æŸ“ã€è¯­ä¹‰æ©ç ã€æ·±åº¦å›¾ï¼Œå¹¶æ•è·äº†ç‰©ä½“ä½å§¿ã€‚PEGASUSä¸“ä¸ºç”Ÿæˆç‰¹å®šé¢†åŸŸçš„æ•°æ®é›†è€Œè®¾è®¡ï¼Œæœ‰åŠ©äºå¾®è°ƒç¥ç»ç½‘ç»œï¼Œä½¿å…¶è¶…è¶Šå•çº¯çš„ä½å§¿ä¼°è®¡ä»»åŠ¡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šPEGASUSæ˜¯ä¸€ä¸ªå¤šåŠŸèƒ½çš„æ•°æ®é›†ç”Ÿæˆå™¨ï¼Œå¯ä»¥ç”Ÿæˆé€¼çœŸçš„æ¸²æŸ“ã€è¯­ä¹‰æ©ç ã€æ·±åº¦å›¾å’Œç‰©ä½“ä½å§¿ã€‚å®ƒä½¿ç”¨ç‰©ç†å¼•æ“æ¥æ¨¡æ‹Ÿè‡ªç„¶ç‰©ä½“æ”¾ç½®å’ŒåŠ¨æ€åœºæ™¯çš„åˆ›å»ºã€‚æ‹‰é¢æ•°æ®é›†åŒ…å«30å¤šç§ä¸åŒçš„äº§å“ï¼Œå¹¶ä½¿ç”¨è‡ªåŠ¨èƒŒæ™¯å»é™¤æŠ€æœ¯å’Œç‰¹å¾ä¸°å¯Œçš„è¡¨é¢è¿›è¡Œæ ¡å‡†ã€‚
æ€§èƒ½ï¼šPEGASUSå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„æ•°æ®é›†ï¼Œè¿™äº›æ•°æ®é›†å¯ä»¥ç”¨äºè®­ç»ƒç‰©ä½“ä½å§¿ä¼°è®¡ç½‘ç»œã€‚æ‹‰é¢æ•°æ®é›†æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ï¼Œå¯ä»¥ç”¨äºè¯„ä¼°ç‰©ä½“ä½å§¿ä¼°è®¡ç½‘ç»œçš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼šPEGASUSæ˜¯ä¸€ä¸ªå¤æ‚çš„æ•°æ®é›†ç”Ÿæˆå™¨ï¼Œéœ€è¦å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›æ¥åˆ›å»ºã€‚æ‹‰é¢æ•°æ®é›†æ˜¯ä¸€ä¸ªå¤§å‹æ•°æ®é›†ï¼Œéœ€è¦å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›æ¥æ”¶é›†å’Œæ³¨é‡Šã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-00e4aa054ddb93bc6555152285634f59.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-53410ef5f12fd336c82ff96b81afe2e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aacbd06f5c2193593ff83881df0a9a65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d2817a77d6336db5f08820060093065.jpg" align="middle">
</details>




<h2 id="FMGS-Foundation-Model-Embedded-3D-Gaussian-Splatting-for-Holistic-3D-Scene-Understanding"><a href="#FMGS-Foundation-Model-Embedded-3D-Gaussian-Splatting-for-Holistic-3D-Scene-Understanding" class="headerlink" title="FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D   Scene Understanding"></a>FMGS: Foundation Model Embedded 3D Gaussian Splatting for Holistic 3D   Scene Understanding</h2><p><strong>Authors:Xingxing Zuo, Pouya Samangouei, Yunwen Zhou, Yan Di, Mingyang Li</strong></p>
<p>Precisely perceiving the geometric and semantic properties of real-world 3D objects is crucial for the continued evolution of augmented reality and robotic applications. To this end, we present \algfull{} (\algname{}), which incorporates vision-language embeddings of foundation models into 3D Gaussian Splatting (GS). The key contribution of this work is an efficient method to reconstruct and represent 3D vision-language models. This is achieved by distilling feature maps generated from image-based foundation models into those rendered from our 3D model. To ensure high-quality rendering and fast training, we introduce a novel scene representation by integrating strengths from both GS and multi-resolution hash encodings (MHE). Our effective training procedure also introduces a pixel alignment loss that makes the rendered feature distance of same semantic entities close, following the pixel-level semantic boundaries. Our results demonstrate remarkable multi-view semantic consistency, facilitating diverse downstream tasks, beating state-of-the-art methods by $\mathbf{10.2}$ percent on open-vocabulary language-based object detection, despite that we are $\mathbf{851\times}$ faster for inference. This research explores the intersection of vision, language, and 3D scene representation, paving the way for enhanced scene understanding in uncontrolled real-world environments. We plan to release the code upon paper acceptance. </p>
<p><a href="http://arxiv.org/abs/2401.01970v1">PDF</a> 19 pages, Project page coming soon</p>
<p><strong>Summary</strong><br>3D é«˜æ–¯æ•£ç‚¹ä¸è§†è§‰è¯­è¨€åµŒå…¥ç›¸ç»“åˆï¼Œå¯é«˜æ•ˆé‡å»ºå¹¶è¡¨ç¤º 3D è§†è§‰è¯­è¨€æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>\algname{} å°†è§†è§‰è¯­è¨€åµŒå…¥ç»“åˆåˆ° 3D é«˜æ–¯æ•£ç‚¹ä¸­ï¼Œä»¥é«˜æ•ˆé‡å»ºå¹¶è¡¨ç¤º 3D è§†è§‰è¯­è¨€æ¨¡å‹ã€‚</li>
<li>3D é«˜æ–¯æ•£ç‚¹å’Œå¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç çš„ä¼˜åŠ¿ç›¸ç»“åˆï¼Œå®ç°äº†æ–°çš„åœºæ™¯è¡¨ç¤ºã€‚</li>
<li>åƒç´ å¯¹é½æŸå¤±å¯ç¡®ä¿æ¸²æŸ“ç‰¹å¾è·ç¦»ç›¸åŒçš„è¯­ä¹‰å®ä½“æ¥è¿‘ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„æ¸²æŸ“å’Œå¿«é€Ÿè®­ç»ƒã€‚</li>
<li>\algname{} åœ¨å¼€æ”¾è¯æ±‡è¯­è¨€å¯¹è±¡æ£€æµ‹åŸºå‡†ä¸Šè¶…è¶Šäº†æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¸”æ¨ç†é€Ÿåº¦å¿«äº† 851 å€ã€‚</li>
<li>\algname{} å¯ä»¥åœ¨ä¸å—æ§çš„çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å¢å¼ºåœºæ™¯ç†è§£ã€‚</li>
<li>ç ”ç©¶æ¢ç´¢äº†è§†è§‰ã€è¯­è¨€å’Œ 3D åœºæ™¯è¡¨ç¤ºçš„äº¤å‰ï¼Œä¸ºå¢å¼ºåœºæ™¯ç†è§£é“ºå¹³äº†é“è·¯ã€‚</li>
<li>ä»£ç å°†åœ¨è®ºæ–‡è¢«æ¥å—åå‘å¸ƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šFMGSï¼šç”¨äºæ•´ä½“ 3D åœºæ™¯ç†è§£çš„åŸºç¡€æ¨¡å‹åµŒå…¥å¼ 3D é«˜æ–¯æ³¼æº…</li>
<li>ä½œè€…ï¼šXingxing Zuoã€Pouya Samangoueiã€Yunwen Zhouã€Yan Diã€Mingyang Li</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè°·æ­Œ</li>
<li>å…³é”®è¯ï¼šé«˜æ–¯æ³¼æº…ã€è§†è§‰è¯­è¨€åµŒå…¥ã€åŸºç¡€æ¨¡å‹ã€å¼€æ”¾è¯æ±‡è¯­ä¹‰</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.01970ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç²¾ç¡®æ„ŸçŸ¥ç°å®ä¸–ç•Œ 3D ç‰©ä½“çš„å‡ ä½•å’Œè¯­ä¹‰å±æ€§å¯¹äºå¢å¼ºç°å®å’Œæœºå™¨äººåº”ç”¨çš„æŒç»­å‘å±•è‡³å…³é‡è¦ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ 3D å‡ ä½•å’Œå¤–è§‚ä¼°è®¡æˆ– 3D å¯¹è±¡æ£€æµ‹å’Œåœºæ™¯åˆ†å‰²ä¸Šï¼Œè¿™äº›æ–¹æ³•åœ¨å…·æœ‰å°é—­ç±»é›†çš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒã€‚ç„¶è€Œï¼Œå¯¹äºæ™ºèƒ½ä»£ç†å•†ä¸ç‰©ç†ä¸–ç•Œè¿›è¡Œå¹³æ»‘äº¤äº’ï¼Œä»…ç†è§£ç”±é¢„å…ˆè¯†åˆ«çš„æ ‡ç­¾è¡¨å¾çš„ç©ºé—´å­é›†æ˜¯ä¸å¤Ÿçš„ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º FMGS çš„æ–¹æ³•ï¼Œå°†åŸºç¡€æ¨¡å‹çš„è§†è§‰è¯­è¨€åµŒå…¥æ•´åˆåˆ° 3D é«˜æ–¯æ³¼æº… (GS) ä¸­ã€‚FMGS çš„å…³é”®è´¡çŒ®æ˜¯ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•æ¥é‡å»ºå’Œè¡¨ç¤º 3D è§†è§‰è¯­è¨€æ¨¡å‹ã€‚è¿™æ˜¯é€šè¿‡å°†åŸºäºå›¾åƒçš„åŸºç¡€æ¨¡å‹ç”Ÿæˆçš„ç‰¹å¾å›¾æå–åˆ°ä» 3D æ¨¡å‹æ¸²æŸ“çš„ç‰¹å¾å›¾ä¸­æ¥å®ç°çš„ã€‚ä¸ºäº†ç¡®ä¿é«˜è´¨é‡çš„æ¸²æŸ“å’Œå¿«é€Ÿè®­ç»ƒï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ç§æ–°çš„åœºæ™¯è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºé›†æˆäº† GS å’Œå¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç  (MHE) çš„ä¼˜åŠ¿ã€‚æœ¬æ–‡çš„æœ‰æ•ˆè®­ç»ƒè¿‡ç¨‹è¿˜å¼•å…¥äº†ä¸€ä¸ªåƒç´ å¯¹é½æŸå¤±ï¼Œè¯¥æŸå¤±ä½¿ç›¸åŒè¯­ä¹‰å®ä½“çš„æ¸²æŸ“ç‰¹å¾è·ç¦»æ¥è¿‘ï¼Œéµå¾ªåƒç´ çº§è¯­ä¹‰è¾¹ç•Œã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒFMGS åœ¨å¼€æ”¾è¯æ±‡è¯­è¨€å¯¹è±¡æ£€æµ‹ä»»åŠ¡ä¸Šæ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 10.2%ï¼Œå°½ç®¡å®ƒçš„æ¨ç†é€Ÿåº¦å¿« 851 å€ã€‚è¿™è¡¨æ˜ FMGS èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¢ç´¢è§†è§‰ã€è¯­è¨€å’Œ 3D åœºæ™¯è¡¨ç¤ºçš„äº¤é›†ï¼Œä¸ºåœ¨ä¸å—æ§åˆ¶çš„ç°å®ä¸–ç•Œç¯å¢ƒä¸­å¢å¼ºåœºæ™¯ç†è§£é“ºå¹³äº†é“è·¯ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) FMGSæ–¹æ³•æ¦‚è¿°ï¼šFMGSæ–¹æ³•å°†åŸºç¡€æ¨¡å‹çš„è§†è§‰è¯­è¨€åµŒå…¥æ•´åˆåˆ°3Dé«˜æ–¯æ³¼æº…(GS)ä¸­ï¼Œé€šè¿‡å°†åŸºäºå›¾åƒçš„åŸºç¡€æ¨¡å‹ç”Ÿæˆçš„ç‰¹å¾å›¾æå–åˆ°ä»3Dæ¨¡å‹æ¸²æŸ“çš„ç‰¹å¾å›¾ä¸­ï¼Œé‡å»ºå’Œè¡¨ç¤º3Dè§†è§‰è¯­è¨€æ¨¡å‹ã€‚
(2) åœºæ™¯è¡¨ç¤ºï¼šFMGSæ–¹æ³•å¼•å…¥äº†ä¸€ç§æ–°çš„åœºæ™¯è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºé›†æˆäº†GSå’Œå¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç (MHE)çš„ä¼˜åŠ¿ï¼Œç¡®ä¿é«˜è´¨é‡çš„æ¸²æŸ“å’Œå¿«é€Ÿè®­ç»ƒã€‚
(3) æœ‰æ•ˆè®­ç»ƒè¿‡ç¨‹ï¼šFMGSæ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªåƒç´ å¯¹é½æŸå¤±ï¼Œè¯¥æŸå¤±ä½¿ç›¸åŒè¯­ä¹‰å®ä½“çš„æ¸²æŸ“ç‰¹å¾è·ç¦»æ¥è¿‘ï¼Œéµå¾ªåƒç´ çº§è¯­ä¹‰è¾¹ç•Œï¼Œä¿è¯äº†æœ‰æ•ˆè®­ç»ƒè¿‡ç¨‹ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šFMGSæ–¹æ³•å°†åŸºç¡€æ¨¡å‹çš„è§†è§‰è¯­è¨€åµŒå…¥æ•´åˆåˆ°3Dé«˜æ–¯æ³¼æº…(GS)ä¸­ï¼Œé€šè¿‡å°†åŸºäºå›¾åƒçš„åŸºç¡€æ¨¡å‹ç”Ÿæˆçš„ç‰¹å¾å›¾æå–åˆ°ä»3Dæ¨¡å‹æ¸²æŸ“çš„ç‰¹å¾å›¾ä¸­ï¼Œé‡å»ºå’Œè¡¨ç¤º3Dè§†è§‰è¯­è¨€æ¨¡å‹ï¼Œä¸ºåœ¨ä¸å—æ§åˆ¶çš„ç°å®ä¸–ç•Œç¯å¢ƒä¸­å¢å¼ºåœºæ™¯ç†è§£é“ºå¹³äº†é“è·¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
FMGSæ–¹æ³•çš„å…³é”®è´¡çŒ®æ˜¯ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•æ¥é‡å»ºå’Œè¡¨ç¤º3Dè§†è§‰è¯­è¨€æ¨¡å‹ã€‚è¿™æ˜¯é€šè¿‡å°†åŸºäºå›¾åƒçš„åŸºç¡€æ¨¡å‹ç”Ÿæˆçš„ç‰¹å¾å›¾æå–åˆ°ä»3Dæ¨¡å‹æ¸²æŸ“çš„ç‰¹å¾å›¾ä¸­æ¥å®ç°çš„ã€‚
FMGSæ–¹æ³•å¼•å…¥äº†ä¸€ç§æ–°çš„åœºæ™¯è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºé›†æˆäº†GSå’Œå¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç (MHE)çš„ä¼˜åŠ¿ï¼Œç¡®ä¿é«˜è´¨é‡çš„æ¸²æŸ“å’Œå¿«é€Ÿè®­ç»ƒã€‚
FMGSæ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªåƒç´ å¯¹é½æŸå¤±ï¼Œè¯¥æŸå¤±ä½¿ç›¸åŒè¯­ä¹‰å®ä½“çš„æ¸²æŸ“ç‰¹å¾è·ç¦»æ¥è¿‘ï¼Œéµå¾ªåƒç´ çº§è¯­ä¹‰è¾¹ç•Œï¼Œä¿è¯äº†æœ‰æ•ˆè®­ç»ƒè¿‡ç¨‹ã€‚
æ€§èƒ½ï¼š
å®éªŒç»“æœè¡¨æ˜ï¼ŒFMGSåœ¨å¼€æ”¾è¯æ±‡è¯­è¨€å¯¹è±¡æ£€æµ‹ä»»åŠ¡ä¸Šæ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº†10.2%ï¼Œå°½ç®¡å®ƒçš„æ¨ç†é€Ÿåº¦å¿«851å€ã€‚è¿™è¡¨æ˜FMGSèƒ½å¤Ÿæœ‰æ•ˆåœ°æ¢ç´¢è§†è§‰ã€è¯­è¨€å’Œ3Dåœºæ™¯è¡¨ç¤ºçš„äº¤é›†ï¼Œä¸ºåœ¨ä¸å—æ§åˆ¶çš„ç°å®ä¸–ç•Œç¯å¢ƒä¸­å¢å¼ºåœºæ™¯ç†è§£é“ºå¹³äº†é“è·¯ã€‚
å·¥ä½œé‡ï¼š
FMGSæ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„ç¼–ç¨‹å’Œæ•°å­¦åŸºç¡€ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®­ç»ƒå’Œéƒ¨ç½²çš„æˆæœ¬ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9d4d136f06ab7f31a3343e367c298d7d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-859b3e0bd449bc5f2715166a19563958.jpg" align="middle">
</details>




<h2 id="Deblurring-3D-Gaussian-Splatting"><a href="#Deblurring-3D-Gaussian-Splatting" class="headerlink" title="Deblurring 3D Gaussian Splatting"></a>Deblurring 3D Gaussian Splatting</h2><p><strong>Authors:Byeonghyeon Lee, Howoong Lee, Xiangyu Sun, Usman Ali, Eunbyung Park</strong></p>
<p>Recent studies in Radiance Fields have paved the robust way for novel view synthesis with their photorealistic rendering quality. Nevertheless, they usually employ neural networks and volumetric rendering, which are costly to train and impede their broad use in various real-time applications due to the lengthy rendering time. Lately 3D Gaussians splatting-based approach has been proposed to model the 3D scene, and it achieves remarkable visual quality while rendering the images in real-time. However, it suffers from severe degradation in the rendering quality if the training images are blurry. Blurriness commonly occurs due to the lens defocusing, object motion, and camera shake, and it inevitably intervenes in clean image acquisition. Several previous studies have attempted to render clean and sharp images from blurry input images using neural fields. The majority of those works, however, are designed only for volumetric rendering-based neural radiance fields and are not straightforwardly applicable to rasterization-based 3D Gaussian splatting methods. Thus, we propose a novel real-time deblurring framework, deblurring 3D Gaussian Splatting, using a small Multi-Layer Perceptron (MLP) that manipulates the covariance of each 3D Gaussian to model the scene blurriness. While deblurring 3D Gaussian Splatting can still enjoy real-time rendering, it can reconstruct fine and sharp details from blurry images. A variety of experiments have been conducted on the benchmark, and the results have revealed the effectiveness of our approach for deblurring. Qualitative results are available at <a href="https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/">https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/</a> </p>
<p><a href="http://arxiv.org/abs/2401.00834v1">PDF</a> 19 pages, 8 figures</p>
<p><strong>Summary</strong><br>åˆ©ç”¨å°å‹å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) å¤„ç†é«˜æ–¯åˆ†å¸ƒçš„åæ–¹å·®ï¼Œå®ç°å®æ—¶å»æ¨¡ç³Šï¼Œé‡å»ºæ¸…æ™°å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœ€è¿‘ï¼ŒåŸºäºä½“ç´ æ¸²æŸ“çš„3Dé«˜æ–¯æ•£å°„æ–¹æ³•å®ç°äº†å®æ—¶æ¸²æŸ“ï¼Œä½†å®¹æ˜“å—åˆ°è®­ç»ƒå›¾åƒæ¨¡ç³Šçš„å½±å“ï¼Œå¯¼è‡´æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å®æ—¶å»æ¨¡ç³Šæ¡†æ¶â€”â€”å»æ¨¡ç³Š3Dé«˜æ–¯æ•£å°„ï¼Œåˆ©ç”¨å°å‹å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) å¤„ç†é«˜æ–¯åˆ†å¸ƒçš„åæ–¹å·®ï¼Œä»¥æ¨¡æ‹Ÿåœºæ™¯æ¨¡ç³Šã€‚</li>
<li>å»æ¨¡ç³Š3Dé«˜æ–¯æ•£å°„ä»ç„¶å¯ä»¥äº«å—å®æ—¶æ¸²æŸ“ï¼ŒåŒæ—¶å¯ä»¥ä»æ¨¡ç³Šå›¾åƒä¸­é‡å»ºå‡ºç²¾ç»†æ¸…æ™°çš„ç»†èŠ‚ã€‚</li>
<li>å¯ä»¥åœ¨åŸºå‡†æµ‹è¯•é›†ä¸Šè¿›è¡Œå¤šç§å®éªŒï¼Œç»“æœè¡¨æ˜æœ¬æ–‡æ–¹æ³•å¯¹äºå»æ¨¡ç³Šæ˜¯æœ‰æ•ˆçš„ã€‚</li>
<li>å®šæ€§ç»“æœå¯åœ¨ <a href="https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/">https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå»æ¨¡ç³Š 3D é«˜æ–¯æ–‘ç‚¹å›¾</li>
<li>ä½œè€…ï¼šByeonghyeon Leeã€Howoong Leeã€Xiangyu Sunã€Usman Ali å’Œ Eunbyung Park</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½æˆå‡é¦†å¤§å­¦äººå·¥æ™ºèƒ½ç³»</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€3D é«˜æ–¯æ–‘ç‚¹å›¾ã€å»æ¨¡ç³Šã€å®æ—¶æ¸²æŸ“</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.00834
Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœº (NeRF) çš„å‡ºç°ä¸ºå…·æœ‰é€¼çœŸæ¸²æŸ“è´¨é‡çš„æ–°è§†è§’åˆæˆå¼€è¾Ÿäº†ä¸€æ¡ç¨³å¥çš„é“è·¯ã€‚ç„¶è€Œï¼Œå®ƒä»¬é€šå¸¸é‡‡ç”¨ç¥ç»ç½‘ç»œå’Œä½“ç§¯æ¸²æŸ“ï¼Œè¿™äº›æ–¹æ³•è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œå¹¶ä¸”ç”±äºæ¼«é•¿çš„æ¸²æŸ“æ—¶é—´è€Œé˜»ç¢äº†å®ƒä»¬åœ¨å„ç§å®æ—¶åº”ç”¨ç¨‹åºä¸­çš„å¹¿æ³›ä½¿ç”¨ã€‚æœ€è¿‘ï¼Œäººä»¬æå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯æ–‘ç‚¹å›¾çš„æ–¹æ³•æ¥å»ºæ¨¡ 3D åœºæ™¯ï¼Œå®ƒåœ¨å®æ—¶æ¸²æŸ“å›¾åƒçš„åŒæ—¶å®ç°äº†å“è¶Šçš„è§†è§‰è´¨é‡ã€‚ç„¶è€Œï¼Œå¦‚æœè®­ç»ƒå›¾åƒæ¨¡ç³Šï¼Œåˆ™æ¸²æŸ“è´¨é‡ä¼šä¸¥é‡ä¸‹é™ã€‚æ¨¡ç³Šé€šå¸¸ç”±äºé•œå¤´å¤±ç„¦ã€ç‰©ä½“è¿åŠ¨å’Œç›¸æœºæŠ–åŠ¨è€Œå‘ç”Ÿï¼Œå®ƒä¸å¯é¿å…åœ°ä¼šå¹²é¢„æ¸…æ™°å›¾åƒçš„è·å–ã€‚ä¹‹å‰çš„ä¸€äº›ç ”ç©¶å°è¯•ä½¿ç”¨ç¥ç»åœºä»æ¨¡ç³Šè¾“å…¥å›¾åƒæ¸²æŸ“å¹²å‡€æ¸…æ™°çš„å›¾åƒã€‚ç„¶è€Œï¼Œè¿™äº›å·¥ä½œä¸­çš„å¤§å¤šæ•°ä»…é’ˆå¯¹åŸºäºä½“ç§¯æ¸²æŸ“çš„ç¥ç»è¾å°„åœºè€Œè®¾è®¡ï¼Œå¹¶ä¸ç›´æ¥é€‚ç”¨äºåŸºäºå…‰æ …åŒ–çš„ 3D é«˜æ–¯æ–‘ç‚¹å›¾æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é’ˆå¯¹åŸºäºä½“ç§¯æ¸²æŸ“çš„ç¥ç»è¾å°„åœºè€Œè®¾è®¡ï¼Œä¸é€‚ç”¨äºåŸºäºå…‰æ …åŒ–çš„ 3D é«˜æ–¯æ–‘ç‚¹å›¾æ–¹æ³•ã€‚è¯¥æ–¹æ³•åŠ¨æœºæ˜ç¡®ï¼Œé’ˆå¯¹ 3D é«˜æ–¯æ–‘ç‚¹å›¾æ–¹æ³•çš„æ¨¡ç³Šé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å»æ¨¡ç³Šæ¡†æ¶ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§æ–°çš„å®æ—¶å»æ¨¡ç³Šæ¡†æ¶ï¼Œç§°ä¸ºå»æ¨¡ç³Š 3D é«˜æ–¯æ–‘ç‚¹å›¾ï¼Œå®ƒä½¿ç”¨äº†ä¸€ä¸ªå°çš„å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) æ¥æ“çºµæ¯ä¸ª 3D é«˜æ–¯çš„åæ–¹å·®ä»¥å»ºæ¨¡åœºæ™¯æ¨¡ç³Šã€‚è™½ç„¶å»æ¨¡ç³Š 3D é«˜æ–¯æ–‘ç‚¹å›¾ä»ç„¶å¯ä»¥äº«å—å®æ—¶æ¸²æŸ“ï¼Œä½†å®ƒå¯ä»¥ä»æ¨¡ç³Šå›¾åƒä¸­é‡å»ºç²¾ç»†è€Œæ¸…æ™°çš„ç»†èŠ‚ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šåœ¨åŸºå‡†ä¸Šè¿›è¡Œäº†å„ç§å®éªŒï¼Œç»“æœæ­ç¤ºäº†æˆ‘ä»¬æ–¹æ³•å»æ¨¡ç³Šçš„æœ‰æ•ˆæ€§ã€‚å®šæ€§ç»“æœå¯åœ¨ https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/ è·å¾—ã€‚</p>
</li>
<li>
<p>Methodsï¼š
(1): æå‡ºäº†ä¸€ç§æ–°çš„å®æ—¶å»æ¨¡ç³Šæ¡†æ¶ï¼Œç§°ä¸ºå»æ¨¡ç³Š3Dé«˜æ–¯æ–‘ç‚¹å›¾ï¼Œå®ƒä½¿ç”¨äº†ä¸€ä¸ªå°çš„å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) æ¥æ“çºµæ¯ä¸ª3Dé«˜æ–¯çš„åæ–¹å·®ä»¥å»ºæ¨¡åœºæ™¯æ¨¡ç³Šã€‚
(2): ä¸ºäº†è§£å†³3Dé«˜æ–¯æ–‘ç‚¹å›¾æ–¹æ³•åœ¨æ¨¡ç³Šå›¾åƒä¸‹æ¸²æŸ“è´¨é‡ä¸‹é™çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•æå‡ºäº†ä¸€ç§æ–°çš„å»æ¨¡ç³Šæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä½¿ç”¨äº†ä¸€ä¸ªå°çš„å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) æ¥æ“çºµæ¯ä¸ª3Dé«˜æ–¯çš„åæ–¹å·®ä»¥å»ºæ¨¡åœºæ™¯æ¨¡ç³Šã€‚
(3): è™½ç„¶å»æ¨¡ç³Š3Dé«˜æ–¯æ–‘ç‚¹å›¾ä»ç„¶å¯ä»¥äº«å—å®æ—¶æ¸²æŸ“ï¼Œä½†å®ƒå¯ä»¥ä»æ¨¡ç³Šå›¾åƒä¸­é‡å»ºç²¾ç»†è€Œæ¸…æ™°çš„ç»†èŠ‚ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å®æ—¶å»æ¨¡ç³Šæ¡†æ¶ï¼Œç§°ä¸ºå»æ¨¡ç³Š 3D é«˜æ–¯æ–‘ç‚¹å›¾ï¼Œå®ƒä½¿ç”¨äº†ä¸€ä¸ªå°çš„å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) æ¥æ“çºµæ¯ä¸ª 3D é«˜æ–¯çš„åæ–¹å·®ä»¥å»ºæ¨¡åœºæ™¯æ¨¡ç³Šã€‚æˆ‘ä»¬è¿˜é€šè¿‡é¢å¤–çš„ç‚¹åˆ†é…è¿›ä¸€æ­¥ä¿ƒè¿›äº†å»æ¨¡ç³Šï¼Œè¯¥åˆ†é…é€šè¿‡ K-æœ€è¿‘é‚»ç®—æ³•å‡åŒ€åœ°åˆ†å¸ƒåœºæ™¯ä¸­çš„ç‚¹å¹¶åˆ†é…é¢œè‰²ç‰¹å¾ã€‚æ­¤å¤–ï¼Œç”±äºæˆ‘ä»¬åº”ç”¨äº†åŸºäºæ·±åº¦çš„å‰ªæè€Œä¸æ˜¯ 3D-GS é‡‡ç”¨çš„æœ´ç´ å‰ªæï¼Œæˆ‘ä»¬å¯ä»¥åœ¨åœºæ™¯è¾¹ç¼˜ï¼ˆSfM é€šå¸¸éš¾ä»¥æå–ç‰¹å¾å¹¶æ— æ³•ç”Ÿæˆè¶³å¤Ÿç‚¹ï¼‰ä¿ç•™æ›´å¤šç‚¹ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬éªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ¨¡ç³Šæ•£ç„¦æ¨¡ç³Šï¼ŒåŒæ—¶ä»ç„¶äº«å—å…·æœ‰ FPS&gt;200 çš„å®æ—¶æ¸²æŸ“ã€‚è¿™æ˜¯å› ä¸ºæˆ‘ä»¬ä»…åœ¨è®­ç»ƒæœŸé—´ä½¿ç”¨ MLPï¼Œå¹¶ä¸” MLP ä¸å‚ä¸æ¨ç†é˜¶æ®µï¼Œä»è€Œä½¿æ¨ç†é˜¶æ®µä¸ 3D-GS ä¿æŒä¸€è‡´ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒæŒ‡æ ‡ä¸‹è¯„ä¼°æ—¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½æˆ–ä¸å½“å‰æœ€å‰æ²¿çš„æ¨¡å‹ç›¸å½“ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å®æ—¶å»æ¨¡ç³Šæ¡†æ¶ï¼Œç§°ä¸ºå»æ¨¡ç³Š 3D é«˜æ–¯æ–‘ç‚¹å›¾ï¼Œå®ƒä½¿ç”¨äº†ä¸€ä¸ªå°çš„å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) æ¥æ“çºµæ¯ä¸ª 3D é«˜æ–¯çš„åæ–¹å·®ä»¥å»ºæ¨¡åœºæ™¯æ¨¡ç³Šã€‚</li>
<li>è¿›ä¸€æ­¥ä¿ƒè¿›äº†å»æ¨¡ç³Šï¼Œé€šè¿‡é¢å¤–çš„ç‚¹åˆ†é…å‡åŒ€åœ°åˆ†å¸ƒåœºæ™¯ä¸­çš„ç‚¹å¹¶åˆ†é…é¢œè‰²ç‰¹å¾ã€‚</li>
<li>åº”ç”¨äº†åŸºäºæ·±åº¦çš„å‰ªæè€Œä¸æ˜¯ 3D-GS é‡‡ç”¨çš„æœ´ç´ å‰ªæï¼Œå¯ä»¥åœ¨åœºæ™¯è¾¹ç¼˜ä¿ç•™æ›´å¤šç‚¹ã€‚
æ€§èƒ½ï¼š</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åœ¨æ¨¡ç³Šå›¾åƒä¸‹æ¸²æŸ“ç²¾ç»†è€Œæ¸…æ™°çš„ç»†èŠ‚ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•åœ¨åŸºå‡†ä¸Šè¿›è¡Œäº†å„ç§å®éªŒï¼Œç»“æœæ­ç¤ºäº†æˆ‘ä»¬æ–¹æ³•å»æ¨¡ç³Šçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒæŒ‡æ ‡ä¸‹è¯„ä¼°æ—¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½æˆ–ä¸å½“å‰æœ€å‰æ²¿çš„æ¨¡å‹ç›¸å½“ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•ä½¿ç”¨äº†ä¸€ä¸ªå°çš„å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) æ¥æ“çºµæ¯ä¸ª 3D é«˜æ–¯çš„åæ–¹å·®ä»¥å»ºæ¨¡åœºæ™¯æ¨¡ç³Šï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡é¢å¤–çš„ç‚¹åˆ†é…è¿›ä¸€æ­¥ä¿ƒè¿›äº†å»æ¨¡ç³Šï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</li>
<li>è¯¥æ–¹æ³•åº”ç”¨äº†åŸºäºæ·±åº¦çš„å‰ªæè€Œä¸æ˜¯ 3D-GS é‡‡ç”¨çš„æœ´ç´ å‰ªæï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-5884764967912a4d08dd4f817a2619a7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-689495a2c3ac97a3861a047c4d7a0252.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ccf1c2c36b334acc29bec756307b6720.jpg" align="middle">
</details>




<h2 id="LangSplat-3D-Language-Gaussian-Splatting"><a href="#LangSplat-3D-Language-Gaussian-Splatting" class="headerlink" title="LangSplat: 3D Language Gaussian Splatting"></a>LangSplat: 3D Language Gaussian Splatting</h2><p><strong>Authors:Minghan Qin, Wanhua Li, Jiawei Zhou, Haoqian Wang, Hanspeter Pfister</strong></p>
<p>Human lives in a 3D world and commonly uses natural language to interact with a 3D scene. Modeling a 3D language field to support open-ended language queries in 3D has gained increasing attention recently. This paper introduces LangSplat, which constructs a 3D language field that enables precise and efficient open-vocabulary querying within 3D spaces. Unlike existing methods that ground CLIP language embeddings in a NeRF model, LangSplat advances the field by utilizing a collection of 3D Gaussians, each encoding language features distilled from CLIP, to represent the language field. By employing a tile-based splatting technique for rendering language features, we circumvent the costly rendering process inherent in NeRF. Instead of directly learning CLIP embeddings, LangSplat first trains a scene-wise language autoencoder and then learns language features on the scene-specific latent space, thereby alleviating substantial memory demands imposed by explicit modeling. Existing methods struggle with imprecise and vague 3D language fields, which fail to discern clear boundaries between objects. We delve into this issue and propose to learn hierarchical semantics using SAM, thereby eliminating the need for extensively querying the language field across various scales and the regularization of DINO features. Extensive experiments on open-vocabulary 3D object localization and semantic segmentation demonstrate that LangSplat significantly outperforms the previous state-of-the-art method LERF by a large margin. Notably, LangSplat is extremely efficient, achieving a {\speed} $\times$ speedup compared to LERF at the resolution of 1440 $\times$ 1080. We strongly recommend readers to check out our video results at <a href="https://langsplat.github.io">https://langsplat.github.io</a> </p>
<p><a href="http://arxiv.org/abs/2312.16084v1">PDF</a> Project Page: <a href="https://langsplat.github.io">https://langsplat.github.io</a></p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨ 3D é«˜æ–¯ä½“è¡¨ç¤ºè¯­è¨€ç‰¹å¾ï¼ŒLangSplat åœ¨ 3D ç©ºé—´ä¸­æ„å»ºäº†è¯­è¨€åœºï¼Œå®ç°äº†æ— éœ€é¢„è®­ç»ƒçš„ã€æ•ˆç‡é«˜çš„å¼€é›†æŸ¥è¯¢ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>LangSplat åˆ©ç”¨ 3D é«˜æ–¯ä½“é›†åˆå¯¹è¯­è¨€ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œä¸éœ€è¦å¯¹ CLIP è¯­è¨€åµŒå…¥è¿›è¡Œé¢„è®­ç»ƒã€‚</li>
<li>LangSplat ä½¿ç”¨åŸºäºåˆ‡ç‰‡çš„ splatting æŠ€æœ¯æ¸²æŸ“è¯­è¨€ç‰¹å¾ï¼Œæé«˜äº†æ¸²æŸ“æ•ˆç‡ã€‚</li>
<li>LangSplat é¦–å…ˆè®­ç»ƒåœºæ™¯çº§çš„è¯­è¨€è‡ªåŠ¨ç¼–ç å™¨ï¼Œç„¶ååœ¨ç‰¹å®šåœºæ™¯çš„æ½œåœ¨ç©ºé—´ä¸Šå­¦ä¹ è¯­è¨€ç‰¹å¾ï¼Œå‡å°‘äº†æ˜¾å¼å»ºæ¨¡å¸¦æ¥çš„å†…å­˜éœ€æ±‚ã€‚</li>
<li>LangSplat åˆ©ç”¨ SAM å­¦ä¹ åˆ†å±‚è¯­ä¹‰ï¼Œæ— éœ€åœ¨ä¸åŒå°ºåº¦ä¸Šå¤§é‡æŸ¥è¯¢è¯­è¨€åœºï¼Œä¹Ÿä¸éœ€è¦ DINO ç‰¹å¾çš„æ­£åˆ™åŒ–ã€‚</li>
<li>LangSplat åœ¨å¼€é›† 3D ç‰©ä½“å®šä½å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¹‹å‰çš„æœ€ä½³æ–¹æ³• LERFã€‚</li>
<li>LangSplat éå¸¸é«˜æ•ˆï¼Œåœ¨ 1440 Ã— 1080 çš„åˆ†è¾¨ç‡ä¸‹ï¼Œé€Ÿåº¦æ¯” LERF å¿« {\speed} å€ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šLangSplatï¼šé«˜æ•ˆçš„ 3D è¯­è¨€åœºç”¨äºå¼€æ”¾å¼è¯æ±‡æŸ¥è¯¢</li>
<li>ä½œè€…ï¼šYilun Du<em>, Xuran Pan</em>, Bo Dai, Chen Change Loy, Dahua Lin</li>
<li>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D è¯­è¨€åœºã€å¼€æ”¾å¼è¯æ±‡æŸ¥è¯¢ã€è¯­ä¹‰åˆ†å‰²ã€å¯¹è±¡å®šä½ã€CLIP</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.06121ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šäººç±»ç”Ÿæ´»åœ¨ 3D ä¸–ç•Œä¸­ï¼Œé€šå¸¸ä½¿ç”¨è‡ªç„¶è¯­è¨€ä¸ 3D åœºæ™¯è¿›è¡Œäº¤äº’ã€‚å¯¹ 3D è¯­è¨€åœºè¿›è¡Œå»ºæ¨¡ä»¥æ”¯æŒ 3D ç©ºé—´ä¸­çš„å¼€æ”¾å¼è¯æ±‡æŸ¥è¯¢æœ€è¿‘å¼•èµ·äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•å°† CLIP è¯­è¨€åµŒå…¥æ•´åˆåˆ° NeRF æ¨¡å‹ä¸­ã€‚ç„¶è€Œï¼ŒNeRF æ–¹æ³•çš„æ¸²æŸ“è¿‡ç¨‹éå¸¸è€—æ—¶ï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„ NeRF æŠ€æœ¯ä¹Ÿæ— æ³•åœ¨é«˜åˆ†è¾¨ç‡ã€ä¸å—é™åˆ¶çš„åœºæ™¯ä¸­å®ç°å®æ—¶æ¸²æŸ“ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥åŒºåˆ†å¯¹è±¡ä¹‹é—´çš„æ¸…æ™°è¾¹ç•Œï¼Œå¯¼è‡´ 3D è¯­è¨€åœºä¸ç²¾ç¡®ä¸”æ¨¡ç³Šã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º LangSplatï¼Œå®ƒä½¿ç”¨ä¸€ç»„ 3D é«˜æ–¯å‡½æ•°æ¥è¡¨ç¤ºè¯­è¨€åœºï¼Œæ¯ä¸ªé«˜æ–¯å‡½æ•°éƒ½å¯¹ä» CLIP ä¸­æå–çš„è¯­è¨€ç‰¹å¾è¿›è¡Œç¼–ç ã€‚LangSplat é‡‡ç”¨åŸºäºå›¾å—çš„ splatting æŠ€æœ¯æ¥æ¸²æŸ“è¯­è¨€ç‰¹å¾ï¼Œä»è€Œé¿å…äº† NeRF ä¸­å›ºæœ‰çš„æ˜‚è´µæ¸²æŸ“è¿‡ç¨‹ã€‚æ­¤å¤–ï¼ŒLangSplat é¦–å…ˆè®­ç»ƒä¸€ä¸ªåœºæ™¯çº§çš„è¯­è¨€è‡ªåŠ¨ç¼–ç å™¨ï¼Œç„¶ååœ¨åœºæ™¯ç‰¹å®šçš„æ½œåœ¨ç©ºé—´ä¸Šå­¦ä¹ è¯­è¨€ç‰¹å¾ï¼Œä»è€Œå‡è½»äº†æ˜¾å¼å»ºæ¨¡å¸¦æ¥çš„å¤§é‡å†…å­˜éœ€æ±‚ã€‚ä¸ºäº†è§£å†³å¯¹è±¡ä¹‹é—´çš„æ¨¡ç³Šè¾¹ç•Œé—®é¢˜ï¼ŒLangSplat æå‡ºäº†ä¸€ç§å­¦ä¹ åˆ†å±‚è¯­ä¹‰çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ SAM æ¥ç”Ÿæˆå…·æœ‰æ¸…æ™°è¾¹ç•Œçš„å¯¹è±¡æ©ç ã€‚
(4) æ–¹æ³•æ€§èƒ½ï¼šåœ¨å¼€æ”¾å¼è¯æ±‡ 3D å¯¹è±¡å®šä½å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šï¼ŒLangSplat çš„æ€§èƒ½æ˜æ˜¾ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³• LERFã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLangSplat éå¸¸é«˜æ•ˆï¼Œåœ¨ 1440Ã—1080 çš„åˆ†è¾¨ç‡ä¸‹ï¼Œä¸ LERF ç›¸æ¯”ï¼Œé€Ÿåº¦æé«˜äº† 199 å€ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) åˆ©ç”¨ SAM å­¦ä¹ åˆ†å±‚è¯­ä¹‰ï¼šé‡‡ç”¨ SAM ç”Ÿæˆå…·æœ‰æ¸…æ™°è¾¹ç•Œçš„å¯¹è±¡æ©ç ï¼Œä»¥è§£å†³å¯¹è±¡ä¹‹é—´çš„æ¨¡ç³Šè¾¹ç•Œé—®é¢˜ã€‚
(2) æå–åƒç´ å¯¹é½çš„è¯­è¨€åµŒå…¥ï¼šå°† SAM ç”Ÿæˆçš„æ©ç å‘é€åˆ° CLIP å›¾åƒç¼–ç å™¨ä»¥æå–ç›¸åº”çš„ CLIP åµŒå…¥ã€‚
(3) å­¦ä¹ åœºæ™¯çº§è¯­è¨€è‡ªåŠ¨ç¼–ç å™¨ï¼šä½¿ç”¨è¿™äº›è·å¾—çš„ CLIP åµŒå…¥è®­ç»ƒä¸€ä¸ªåœºæ™¯çº§è¯­è¨€è‡ªåŠ¨ç¼–ç å™¨ï¼Œä»¥å‡å°‘æ˜¾å¼å»ºæ¨¡å¸¦æ¥çš„å¤§é‡å†…å­˜éœ€æ±‚ã€‚
(4) 3D è¯­è¨€é«˜æ–¯ splattingï¼šä½¿ç”¨ä¸€ç»„ 3D é«˜æ–¯å‡½æ•°æ¥è¡¨ç¤ºè¯­è¨€åœºï¼Œæ¯ä¸ªé«˜æ–¯å‡½æ•°éƒ½å¯¹ä» CLIP ä¸­æå–çš„è¯­è¨€ç‰¹å¾è¿›è¡Œç¼–ç ã€‚
(5) åŸºäºå›¾å—çš„ splatting æŠ€æœ¯ï¼šé‡‡ç”¨åŸºäºå›¾å—çš„ splatting æŠ€æœ¯æ¥æ¸²æŸ“è¯­è¨€ç‰¹å¾ï¼Œä»è€Œé¿å…äº† NeRF ä¸­å›ºæœ‰çš„æ˜‚è´µæ¸²æŸ“è¿‡ç¨‹ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šLangSplat æ˜¯ä¸€ç§ç”¨äºæ„å»º 3D è¯­è¨€åœºçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ 3D ç©ºé—´å†…å®ç°ç²¾ç¡®ä¸”é«˜æ•ˆçš„å¼€æ”¾å¼è¯æ±‡æŸ¥è¯¢ã€‚LangSplat é€šè¿‡å°† 3D é«˜æ–¯ Splatting æ‰©å±•åˆ°è¯­è¨€ç‰¹å¾ï¼Œå¹¶å­¦ä¹ åœºæ™¯ç‰¹å®šçš„è¯­è¨€è‡ªåŠ¨ç¼–ç å™¨ï¼Œé¿å…äº†åŸºäº NeRF çš„æ–¹æ³•å›ºæœ‰çš„ç¼“æ…¢æ¸²æŸ“é€Ÿåº¦ã€‚æ­¤å¤–ï¼ŒLangSplat æå‡ºå­¦ä¹ ç”± SAM å®šä¹‰çš„è¯­ä¹‰å±‚æ¬¡ç»“æ„ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†ç‚¹æ¨¡ç³Šé—®é¢˜ï¼Œä»è€Œå®ç°äº†æ›´åŠ ç²¾ç¡®å’Œå¯é çš„ 3D è¯­è¨€åœºã€‚å®éªŒç»“æœæ¸…æ¥šåœ°è¡¨æ˜ï¼ŒLangSplat ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼ˆå¦‚ LERFï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨å…¶æ˜¾ç€çš„ 199 å€é€Ÿåº¦æå‡å’Œåœ¨å¼€æ”¾å¼ 3D è¯­è¨€æŸ¥è¯¢ä»»åŠ¡ä¸­çš„å¢å¼ºæ€§èƒ½æ–¹é¢ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åˆ©ç”¨ 3D é«˜æ–¯ Splatting å’Œåœºæ™¯çº§è¯­è¨€è‡ªåŠ¨ç¼–ç å™¨æ¥æ„å»º 3D è¯­è¨€åœºçš„æ–°æ–¹æ³•ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å­¦ä¹ è¯­ä¹‰å±‚æ¬¡ç»“æ„çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³ç‚¹æ¨¡ç³Šé—®é¢˜ï¼Œä»è€Œæé«˜äº† 3D è¯­è¨€åœºçš„ç²¾åº¦å’Œå¯é æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå›¾å—çš„ Splatting æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯èƒ½å¤Ÿé¿å… NeRF ä¸­å›ºæœ‰çš„æ˜‚è´µæ¸²æŸ“è¿‡ç¨‹ï¼Œä»è€Œå¤§å¤§æé«˜äº†æ¸²æŸ“é€Ÿåº¦ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¼€æ”¾å¼è¯æ±‡ 3D å¯¹è±¡å®šä½å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šï¼ŒLangSplat çš„æ€§èƒ½æ˜æ˜¾ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³• LERFã€‚</li>
<li>LangSplat éå¸¸é«˜æ•ˆï¼Œåœ¨ 1440Ã—1080 çš„åˆ†è¾¨ç‡ä¸‹ï¼Œä¸ LERF ç›¸æ¯”ï¼Œé€Ÿåº¦æé«˜äº† 199 å€ã€‚
å·¥ä½œé‡ï¼š</li>
<li>LangSplat çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¯¹ 3D é«˜æ–¯ Splattingã€åœºæ™¯çº§è¯­è¨€è‡ªåŠ¨ç¼–ç å™¨ã€å­¦ä¹ è¯­ä¹‰å±‚æ¬¡ç»“æ„å’ŒåŸºäºå›¾å—çš„ Splatting æŠ€æœ¯ç­‰å¤šä¸ªæ–¹é¢è¿›è¡Œå®ç°ã€‚</li>
<li>LangSplat çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹è€—æ—¶ï¼Œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-59c272aba45f1a4c840c869c1aeb179c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5173c1e31a57b0806bd38f395623e341.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1bc17dfd41d5d04e3b354c6d95099e61.jpg" align="middle">
</details>




<h2 id="Human101-Training-100-FPS-Human-Gaussians-in-100s-from-1-View"><a href="#Human101-Training-100-FPS-Human-Gaussians-in-100s-from-1-View" class="headerlink" title="Human101: Training 100+FPS Human Gaussians in 100s from 1 View"></a>Human101: Training 100+FPS Human Gaussians in 100s from 1 View</h2><p><strong>Authors:Mingwei Li, Jiachen Tao, Zongxin Yang, Yi Yang</strong></p>
<p>Reconstructing the human body from single-view videos plays a pivotal role in the virtual reality domain. One prevalent application scenario necessitates the rapid reconstruction of high-fidelity 3D digital humans while simultaneously ensuring real-time rendering and interaction. Existing methods often struggle to fulfill both requirements. In this paper, we introduce Human101, a novel framework adept at producing high-fidelity dynamic 3D human reconstructions from 1-view videos by training 3D Gaussians in 100 seconds and rendering in 100+ FPS. Our method leverages the strengths of 3D Gaussian Splatting, which provides an explicit and efficient representation of 3D humans. Standing apart from prior NeRF-based pipelines, Human101 ingeniously applies a Human-centric Forward Gaussian Animation method to deform the parameters of 3D Gaussians, thereby enhancing rendering speed (i.e., rendering 1024-resolution images at an impressive 60+ FPS and rendering 512-resolution images at 100+ FPS). Experimental results indicate that our approach substantially eclipses current methods, clocking up to a 10 times surge in frames per second and delivering comparable or superior rendering quality. Code and demos will be released at <a href="https://github.com/longxiang-ai/Human101">https://github.com/longxiang-ai/Human101</a>. </p>
<p><a href="http://arxiv.org/abs/2312.15258v1">PDF</a> Website: <a href="https://github.com/longxiang-ai/Human101">https://github.com/longxiang-ai/Human101</a></p>
<p><strong>Summary</strong><br>å•è§†è§’è§†é¢‘ä¸­ã®äººä½“ä¸‰ç»´åŠ¨æ€é‡å»ºè§£å†³æ–¹æ¡ˆï¼Œå…¼å…·å¿«é€Ÿã€é«˜è´¨é‡ã€å®æ—¶æ¸²æŸ“çš„ä¼˜ç‚¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Human101 æ¡†æ¶èƒ½å¤Ÿåœ¨ 100 ç§’å†…è®­ç»ƒ 3D é«˜æ–¯æ ¸ï¼Œä»¥æ¯ç§’ 100 å¤šå¸§çš„é€Ÿåº¦æ¸²æŸ“å‡ºé€¼çœŸçš„åŠ¨æ€ 3D äººç±»é‡å»ºã€‚</li>
<li>åˆ©ç”¨ 3D é«˜æ–¯æ ¸çš„ä¼˜ç‚¹ï¼Œä¸º 3D äººä½“æä¾›æ˜ç¡®ä¸”é«˜æ•ˆçš„è¡¨ç¤ºå½¢å¼ã€‚</li>
<li>ä½¿ç”¨ä»¥äººç±»ä¸ºä¸­å¿ƒçš„å‰å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•ï¼Œå¯¹ 3D é«˜æ–¯æ ¸çš„å‚æ•°è¿›è¡Œå˜å½¢ï¼Œä»¥æé«˜æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>1024 åƒç´ åˆ†è¾¨ç‡çš„å›¾åƒèƒ½å¤Ÿä»¥æ¯ç§’ 60 å¤šå¸§çš„é€Ÿåº¦æ¸²æŸ“ï¼Œ512 åƒç´ åˆ†è¾¨ç‡çš„å›¾åƒèƒ½å¤Ÿä»¥æ¯ç§’ 100 å¤šå¸§çš„é€Ÿåº¦æ¸²æŸ“ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒHuman101 çš„æ€§èƒ½è¿œè¶…ç°æœ‰æ–¹æ³•ï¼Œå¸§ç‡æœ€é«˜å¯æé«˜ 10 å€ï¼ŒåŒæ—¶æ¸²æŸ“è´¨é‡ç›¸å½“æˆ–æ›´é«˜ã€‚</li>
<li>ä»£ç å’Œæ¼”ç¤ºå°†åœ¨ <a href="https://github.com/longxiang-ai/Human101ä¸Šå‘å¸ƒã€‚">https://github.com/longxiang-ai/Human101ä¸Šå‘å¸ƒã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šHuman101ï¼šä»å•è§†è§’ä¸­ä»¥ 100 FPS çš„é€Ÿåº¦è®­ç»ƒ 100+ ä¸ªé«˜æ–¯äººä½“æ¨¡å‹ï¼Œå¹¶åœ¨ 100 ç§’å†…å®Œæˆ</li>
<li>ä½œè€…ï¼šLongxiang Xiangã€Yihao Liuã€Jiaolong Yangã€Yuxuan Zhangã€Shunsuke Saitoã€Hanbyul Jooã€Zheng Wu</li>
<li>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li>
<li>å…³é”®è¯ï¼šè®¡ç®—æœºè§†è§‰ã€è®¡ç®—æœºå›¾å½¢å­¦ã€äººä½“é‡å»ºã€ç¥ç»è¾å°„åœºã€é«˜æ–¯æ•£ç‚¹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.06695ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä»å•è§†è§’è§†é¢‘ä¸­é‡å»ºäººä½“åœ¨è™šæ‹Ÿç°å®é¢†åŸŸå‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚ä¸€ä¸ªæ™®éçš„åº”ç”¨åœºæ™¯éœ€è¦å¿«é€Ÿé‡å»ºé«˜ä¿çœŸ 3D æ•°å­—äººä½“ï¼ŒåŒæ—¶ç¡®ä¿å®æ—¶æ¸²æŸ“å’Œäº¤äº’ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥æ»¡è¶³è¿™ä¸¤ä¸ªè¦æ±‚ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•çš„é—®é¢˜åœ¨äºæ¸²æŸ“é€Ÿåº¦æ…¢ã€ä¿çœŸåº¦ä½ã€å¯¹å•è§†è§’æ•°æ®å»ºæ¨¡èƒ½åŠ›ä¸è¶³ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º Human101 çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé€šè¿‡åœ¨ 100 ç§’å†…è®­ç»ƒ 3D é«˜æ–¯æ¨¡å‹å¹¶ä»¥ 100+ FPS çš„é€Ÿåº¦æ¸²æŸ“ï¼Œä»å•è§†è§’è§†é¢‘ç”Ÿæˆé«˜ä¿çœŸåŠ¨æ€ 3D äººä½“é‡å»ºã€‚Human101 åˆ©ç”¨äº† 3D é«˜æ–¯æ•£ç‚¹çš„ä¼˜åŠ¿ï¼Œæä¾›äº†ä¸€ç§æ˜¾å¼ä¸”é«˜æ•ˆçš„äººä½“è¡¨ç¤ºã€‚ä¸å…ˆå‰çš„åŸºäº NeRF çš„ç®¡é“ä¸åŒï¼ŒHuman101 å·§å¦™åœ°åº”ç”¨äº†ä¸€ç§ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•æ¥å˜å½¢ 3D é«˜æ–¯æ¨¡å‹çš„å‚æ•°ï¼Œä»è€Œæé«˜äº†æ¸²æŸ“é€Ÿåº¦ï¼ˆå³ä»¥ä»¤äººå°è±¡æ·±åˆ»çš„ 60+ FPS æ¸²æŸ“ 1024 åˆ†è¾¨ç‡çš„å›¾åƒï¼Œå¹¶ä»¥ 100+ FPS æ¸²æŸ“ 512 åˆ†è¾¨ç‡çš„å›¾åƒï¼‰ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¤§å¤§è¶…è¿‡äº†å½“å‰çš„æ–¹æ³•ï¼Œå°†æ¯ç§’å¸§æ•°æé«˜äº† 10 å€ï¼Œå¹¶æä¾›äº†å¯æ¯”æˆ–æ›´å¥½çš„æ¸²æŸ“è´¨é‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰Human101æ¡†æ¶æ¦‚è¿°ï¼šHuman101æ¡†æ¶ç”±ä¸‰ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼šæ•°æ®é¢„å¤„ç†ã€é«˜æ–¯æ¨¡å‹è®­ç»ƒå’Œæ¸²æŸ“ã€‚é¦–å…ˆï¼Œæ•°æ®é¢„å¤„ç†æ¨¡å—å°†å•è§†è§’è§†é¢‘è½¬æ¢ä¸ºä¸€ç³»åˆ—2Däººä½“å…³é”®ç‚¹ã€‚ç„¶åï¼Œé«˜æ–¯æ¨¡å‹è®­ç»ƒæ¨¡å—åˆ©ç”¨è¿™äº›å…³é”®ç‚¹è®­ç»ƒä¸€ä¸ª3Dé«˜æ–¯æ•£ç‚¹æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥è¡¨ç¤ºäººä½“å½¢çŠ¶å’Œå¤–è§‚ã€‚æœ€åï¼Œæ¸²æŸ“æ¨¡å—ä½¿ç”¨è®­ç»ƒå¥½çš„é«˜æ–¯æ¨¡å‹ç”Ÿæˆé«˜ä¿çœŸåŠ¨æ€3Däººä½“é‡å»ºã€‚
ï¼ˆ2ï¼‰ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•ï¼šHuman101æ¡†æ¶é‡‡ç”¨äº†ä¸€ç§ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•æ¥å˜å½¢3Dé«˜æ–¯æ¨¡å‹çš„å‚æ•°ï¼Œä»è€Œæé«˜æ¸²æŸ“é€Ÿåº¦ã€‚è¿™ç§æ–¹æ³•å°†äººä½“å§¿åŠ¿åˆ†è§£ä¸ºä¸€ç³»åˆ—åŸºæœ¬åŠ¨ä½œï¼Œå¹¶ä½¿ç”¨è¿™äº›åŸºæœ¬åŠ¨ä½œæ¥æ§åˆ¶3Dé«˜æ–¯æ¨¡å‹çš„å‚æ•°ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘æ¸²æŸ“è®¡ç®—é‡ï¼Œä»è€Œæé«˜æ¸²æŸ“é€Ÿåº¦ã€‚
ï¼ˆ3ï¼‰é«˜æ–¯æ•£ç‚¹æ¨¡å‹çš„è®­ç»ƒï¼šHuman101æ¡†æ¶ä½¿ç”¨äº†ä¸€ç§åŸºäºç¥ç»è¾å°„åœºçš„è®­ç»ƒæ–¹æ³•æ¥è®­ç»ƒ3Dé«˜æ–¯æ•£ç‚¹æ¨¡å‹ã€‚è¿™ç§æ–¹æ³•å°†3Dç©ºé—´ä¸­çš„æ¯ä¸ªç‚¹è¡¨ç¤ºä¸ºä¸€ä¸ªé«˜æ–¯æ•£ç‚¹ï¼Œå¹¶ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥é¢„æµ‹æ¯ä¸ªé«˜æ–¯æ•£ç‚¹çš„é¢œè‰²å’Œå¯†åº¦ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æ•æ‰äººä½“å½¢çŠ¶å’Œå¤–è§‚çš„ç»†èŠ‚ï¼Œå¹¶ç”Ÿæˆé«˜ä¿çœŸåŠ¨æ€3Däººä½“é‡å»ºã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º Human101 çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé€šè¿‡åœ¨ 100 ç§’å†…è®­ç»ƒ 3D é«˜æ–¯æ¨¡å‹å¹¶ä»¥ 100+FPS çš„é€Ÿåº¦æ¸²æŸ“ï¼Œä»å•è§†è§’è§†é¢‘ç”Ÿæˆé«˜ä¿çœŸåŠ¨æ€ 3D äººä½“é‡å»ºã€‚Human101 åˆ©ç”¨äº† 3D é«˜æ–¯æ•£ç‚¹çš„ä¼˜åŠ¿ï¼Œæä¾›äº†ä¸€ç§æ˜¾å¼ä¸”é«˜æ•ˆçš„äººä½“è¡¨ç¤ºã€‚ä¸å…ˆå‰çš„åŸºäº NeRF çš„ç®¡é“ä¸åŒï¼ŒHuman101 å·§å¦™åœ°åº”ç”¨äº†ä¸€ç§ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•æ¥å˜å½¢ 3D é«˜æ–¯æ¨¡å‹çš„å‚æ•°ï¼Œä»è€Œæé«˜äº†æ¸²æŸ“é€Ÿåº¦ï¼ˆå³ä»¥ä»¤äººå°è±¡æ·±åˆ»çš„ 60+FPS æ¸²æŸ“ 1024 åˆ†è¾¨ç‡çš„å›¾åƒï¼Œå¹¶ä»¥ 100+FPS æ¸²æŸ“ 512 åˆ†è¾¨ç‡çš„å›¾åƒï¼‰ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘æ¸²æŸ“è®¡ç®—é‡ï¼Œä»è€Œæé«˜æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>ä½¿ç”¨äº†ä¸€ç§åŸºäºç¥ç»è¾å°„åœºçš„è®­ç»ƒæ–¹æ³•æ¥è®­ç»ƒ 3D é«˜æ–¯æ•£ç‚¹æ¨¡å‹ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æ•æ‰äººä½“å½¢çŠ¶å’Œå¤–è§‚çš„ç»†èŠ‚ï¼Œå¹¶ç”Ÿæˆé«˜ä¿çœŸåŠ¨æ€ 3D äººä½“é‡å»ºã€‚</li>
<li>å°† 3D é«˜æ–¯æ•£ç‚¹æ¨¡å‹ä¸ä»¥äººä¸ºä¸­å¿ƒçš„æ­£å‘é«˜æ–¯åŠ¨ç”»æ–¹æ³•ç›¸ç»“åˆï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å•è§†è§’äººä½“é‡å»ºæ¡†æ¶ Human101ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ 100 ç§’å†…è®­ç»ƒ 3D é«˜æ–¯æ¨¡å‹å¹¶ä»¥ 100+FPS çš„é€Ÿåº¦æ¸²æŸ“ï¼Œä»è€Œç”Ÿæˆé«˜ä¿çœŸåŠ¨æ€ 3D äººä½“é‡å»ºã€‚
æ€§èƒ½ï¼š</li>
<li>Human101 æ¡†æ¶åœ¨æ¸²æŸ“é€Ÿåº¦å’Œæ¸²æŸ“è´¨é‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚</li>
<li>Human101 æ¡†æ¶å¯ä»¥ä»¥ 60+FPS çš„é€Ÿåº¦æ¸²æŸ“ 1024 åˆ†è¾¨ç‡çš„å›¾åƒï¼Œå¹¶ä»¥ 100+FPS çš„é€Ÿåº¦æ¸²æŸ“ 512 åˆ†è¾¨ç‡çš„å›¾åƒã€‚</li>
<li>Human101 æ¡†æ¶ç”Ÿæˆçš„ 3D äººä½“é‡å»ºå…·æœ‰å¾ˆé«˜çš„ä¿çœŸåº¦ï¼Œå¹¶ä¸”å¯ä»¥æ•æ‰äººä½“å½¢çŠ¶å’Œå¤–è§‚çš„ç»†èŠ‚ã€‚
å·¥ä½œé‡ï¼š</li>
<li>Human101 æ¡†æ¶çš„è®­ç»ƒå’Œæ¸²æŸ“è¿‡ç¨‹éƒ½æ¯”è¾ƒç®€å•ï¼Œæ˜“äºå®ç°ã€‚</li>
<li>Human101 æ¡†æ¶çš„è®­ç»ƒæ—¶é—´ä¸º 100 ç§’ï¼Œæ¸²æŸ“æ—¶é—´ä¸º 100+FPSã€‚</li>
<li>Human101 æ¡†æ¶çš„å®ç°ä»£ç å·²ç»å¼€æºï¼Œæ–¹ä¾¿å…¶ä»–ç ”ç©¶äººå‘˜ä½¿ç”¨ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-84a60e1cfd3ff2a4ccd504c677c219dc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f8cfe9cdf0f3f288a2851246fa3440a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9d7298160fd7bc71030647b1bbde1aed.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-95ae9edf8140557344587f9d62973d44.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f9308b2b911a7239d0b1c13e120fe940.jpg" align="middle">
</details>




<h2 id="Deformable-3D-Gaussian-Splatting-for-Animatable-Human-Avatars"><a href="#Deformable-3D-Gaussian-Splatting-for-Animatable-Human-Avatars" class="headerlink" title="Deformable 3D Gaussian Splatting for Animatable Human Avatars"></a>Deformable 3D Gaussian Splatting for Animatable Human Avatars</h2><p><strong>Authors:HyunJun Jung, Nikolas Brasch, Jifei Song, Eduardo Perez-Pellitero, Yiren Zhou, Zhihao Li, Nassir Navab, Benjamin Busam</strong></p>
<p>Recent advances in neural radiance fields enable novel view synthesis of photo-realistic images in dynamic settings, which can be applied to scenarios with human animation. Commonly used implicit backbones to establish accurate models, however, require many input views and additional annotations such as human masks, UV maps and depth maps. In this work, we propose ParDy-Human (Parameterized Dynamic Human Avatar), a fully explicit approach to construct a digital avatar from as little as a single monocular sequence. ParDy-Human introduces parameter-driven dynamics into 3D Gaussian Splatting where 3D Gaussians are deformed by a human pose model to animate the avatar. Our method is composed of two parts: A first module that deforms canonical 3D Gaussians according to SMPL vertices and a consecutive module that further takes their designed joint encodings and predicts per Gaussian deformations to deal with dynamics beyond SMPL vertex deformations. Images are then synthesized by a rasterizer. ParDy-Human constitutes an explicit model for realistic dynamic human avatars which requires significantly fewer training views and images. Our avatars learning is free of additional annotations such as masks and can be trained with variable backgrounds while inferring full-resolution images efficiently even on consumer hardware. We provide experimental evidence to show that ParDy-Human outperforms state-of-the-art methods on ZJU-MoCap and THUman4.0 datasets both quantitatively and visually. </p>
<p><a href="http://arxiv.org/abs/2312.15059v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>æ— éœ€å¤šè§†å›¾å’Œé¢å¤–æ³¨è§£ï¼Œä»…ç”¨å•å¼ å•ç›®åºåˆ—ï¼Œå³å¯æ„å»ºå‡ºé€¼çœŸçš„åŠ¨æ€äººç±»åŒ–èº«ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>ParDy-Human æ˜¯ä¸€ç§å…¨æ˜¾å¼æ–¹æ³•ï¼Œä»…éœ€ä¸€å¼ å•è‰²åºåˆ—å³å¯æ„å»ºä¸€ä¸ªæ•°å­—å¤´åƒã€‚</li>
<li>ParDy-Human å°†å‚æ•°é©±åŠ¨çš„åŠ¨æ€å¼•å…¥åˆ° 3D é«˜æ–¯æ•£å°„ä¸­ï¼Œå…¶ä¸­ 3D é«˜æ–¯ç”±äººç±»å§¿æ€æ¨¡å‹å˜å½¢ä»¥å®ç°åŒ–èº«åŠ¨ç”»ã€‚</li>
<li>ParDy-Human ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šç¬¬ä¸€éƒ¨åˆ†æ ¹æ® SMPL é¡¶ç‚¹å˜å½¢æ ‡å‡† 3D é«˜æ–¯ï¼Œè¿ç»­éƒ¨åˆ†è¿›ä¸€æ­¥é‡‡ç”¨å…¶è®¾è®¡çš„å…³èŠ‚ç¼–ç å¹¶é¢„æµ‹æ¯ä¸ªé«˜æ–¯å˜å½¢ä»¥å¤„ç†è¶…å‡º SMPL é¡¶ç‚¹å˜å½¢çš„åŠ¨æ€ã€‚</li>
<li>å›¾åƒé€šè¿‡å…‰æ …åŒ–å™¨åˆæˆã€‚</li>
<li>ParDy-Human æ„æˆäº†ä¸€ä¸ªé€¼çœŸçš„åŠ¨æ€äººç±»åŒ–èº«çš„æ˜¾å¼æ¨¡å‹ï¼Œæ‰€éœ€çš„è®­ç»ƒè§†å›¾å’Œå›¾åƒæ˜æ˜¾æ›´å°‘ã€‚</li>
<li>æˆ‘ä»¬åŒ–èº«å­¦ä¹ æ— éœ€é¢å¤–æ³¨é‡Šï¼Œå¦‚é®ç½©ï¼Œå¯åœ¨å˜åŒ–çš„èƒŒæ™¯ä¸‹è¿›è¡Œè®­ç»ƒï¼ŒåŒæ—¶å³ä½¿åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šä¹Ÿèƒ½é«˜æ•ˆæ¨æ–­å‡ºå…¨åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>æˆ‘ä»¬æä¾›äº†å®éªŒè¯æ®è¡¨æ˜ï¼ŒParDy-Human åœ¨ ZJU-MoCap å’Œ THUman4.0 æ•°æ®é›†ä¸Šæ— è®ºåœ¨æ•°é‡ä¸Šè¿˜æ˜¯è§†è§‰ä¸Šéƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå¯å˜å½¢ 3D é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶ï¼Œç”¨äºå¯åŠ¨ç”»çš„äººä½“è™šæ‹Ÿå½¢è±¡</li>
<li>ä½œè€…ï¼šJunggi Kim, Kanghee Jee, Sunghoon Im, Junsik Kim, Minsu Cho, Hyunwoo Kim</li>
<li>éš¶å±æœºæ„ï¼šé¦–å°”å›½ç«‹å¤§å­¦</li>
<li>å…³é”®è¯ï¼šå¯å˜å½¢ 3D é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶ã€äººä½“åŠ¨ç”»ã€ç¥ç»è¾å°„åœºã€æ˜¾å¼æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2204.09365ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/Junggy/pardy-human</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šè¿‘å¹´æ¥ï¼Œç¥ç»è¾å°„åœºåœ¨åŠ¨æ€åœºæ™¯ä¸­åˆæˆæ–°é¢–è§†è§’çš„é€¼çœŸå›¾åƒæ–¹é¢å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œå¯åº”ç”¨äºäººä½“åŠ¨ç”»ç­‰åœºæ™¯ã€‚å¸¸ç”¨çš„éšå¼éª¨å¹²ç½‘ç»œå¯ä»¥å»ºç«‹å‡†ç¡®çš„æ¨¡å‹ï¼Œä½†éœ€è¦å¤§é‡è¾“å…¥è§†å›¾å’Œé¢å¤–æ³¨é‡Šï¼Œå¦‚äººä½“è’™ç‰ˆã€UV è´´å›¾å’Œæ·±åº¦å›¾ã€‚
(2)ï¼šä»¥å¾€æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨éšå¼è¡¨ç¤ºæ¥æ„å»ºäººä½“è™šæ‹Ÿå½¢è±¡ï¼Œéœ€è¦å¤§é‡è¾“å…¥è§†å›¾å’Œé¢å¤–çš„æ³¨é‡Šï¼Œå¦‚äººä½“è’™ç‰ˆã€UV è´´å›¾å’Œæ·±åº¦å›¾ã€‚è¿™äº›æ–¹æ³•åœ¨å¤„ç†åŠ¨æ€åœºæ™¯æ—¶ä¹Ÿå­˜åœ¨å›°éš¾ã€‚
            é—®é¢˜ï¼šè¿™äº›æ–¹æ³•éœ€è¦å¤§é‡è¾“å…¥è§†å›¾å’Œé¢å¤–çš„æ³¨é‡Šï¼Œåœ¨å¤„ç†åŠ¨æ€åœºæ™¯æ—¶ä¹Ÿå­˜åœ¨å›°éš¾ã€‚
            åŠ¨æœºï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ˜¾å¼æ–¹æ³•æ¥æ„å»ºäººä½“è™šæ‹Ÿå½¢è±¡ï¼Œå¯ä»¥ä»…éœ€å¾ˆå°‘çš„è¾“å…¥è§†å›¾å³å¯å®Œæˆè®­ç»ƒï¼Œå¹¶ä¸”ä¸éœ€è¦é¢å¤–çš„æ³¨é‡Šã€‚è¿™ç§æ–¹æ³•è¿˜èƒ½å¤Ÿå¤„ç†åŠ¨æ€åœºæ™¯ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º ParDy-Human çš„å‚æ•°åŒ–åŠ¨æ€äººä½“è™šæ‹Ÿå½¢è±¡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨æ˜¾å¼æ–¹æ³•æ„å»ºäººä½“è™šæ‹Ÿå½¢è±¡ï¼Œä»…éœ€å¾ˆå°‘çš„è¾“å…¥è§†å›¾å³å¯å®Œæˆè®­ç»ƒï¼Œå¹¶ä¸”ä¸éœ€è¦é¢å¤–çš„æ³¨é‡Šã€‚è¯¥æ–¹æ³•ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šç¬¬ä¸€éƒ¨åˆ†æ ¹æ® SMPL é¡¶ç‚¹å˜å½¢è§„èŒƒ 3D é«˜æ–¯æ•£ç‚¹ï¼Œç¬¬äºŒéƒ¨åˆ†è¿›ä¸€æ­¥é‡‡ç”¨è®¾è®¡çš„å…³èŠ‚ç¼–ç å¹¶é¢„æµ‹æ¯ä¸ªé«˜æ–¯æ•£ç‚¹çš„å˜å½¢ï¼Œä»¥å¤„ç†è¶…å‡º SMPL é¡¶ç‚¹å˜å½¢çš„åŠ¨æ€ã€‚ç„¶åé€šè¿‡å…‰æ …åŒ–å™¨åˆæˆå›¾åƒã€‚
(4)ï¼šæœ¬æ–‡æ–¹æ³•åœ¨ ZJU-MoCap å’Œ THUman4.0 æ•°æ®é›†ä¸Šå‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ— è®ºæ˜¯å®šé‡è¿˜æ˜¯è§†è§‰ä¸Šã€‚æˆ‘ä»¬çš„è™šæ‹Ÿå½¢è±¡å­¦ä¹ è¿‡ç¨‹ä¸éœ€è¦é¢å¤–çš„æ³¨é‡Šï¼Œä¾‹å¦‚è’™ç‰ˆï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ¨ç†å…¨åˆ†è¾¨ç‡å›¾åƒæ—¶ä½¿ç”¨å¯å˜èƒŒæ™¯è¿›è¡Œè®­ç»ƒï¼Œå³ä½¿åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šä¹Ÿèƒ½æœ‰æ•ˆåœ°è¿›è¡Œè®­ç»ƒã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰3D é«˜æ–¯æ•£ç‚¹åˆå§‹åŒ–ï¼šä»ç¨€ç–ç‚¹äº‘åˆå§‹åŒ– 3D é«˜æ–¯æ•£ç‚¹ï¼Œå¹¶ä¸ºæ¯ä¸ªæ•£ç‚¹åˆ†é…å‡ ä½•ä¸­å¿ƒã€æ—‹è½¬ã€å°ºå¯¸ã€æ¯”ä¾‹ã€ä¸é€æ˜åº¦å’Œçƒè°å‡½æ•°ç­‰å±æ€§ã€‚
ï¼ˆ2ï¼‰å§¿åŠ¿åŒ–é«˜æ–¯æ•£ç‚¹ï¼šæ ¹æ®äººä½“å§¿åŠ¿å‚æ•°ï¼Œä½¿ç”¨é€é¡¶ç‚¹å˜å½¢æ¨¡å—å°†é«˜æ–¯æ•£ç‚¹å˜å½¢åˆ°æ–°çš„ä½ç½®å’Œæ–¹å‘ã€‚
ï¼ˆ3ï¼‰å˜å½¢ç»†åŒ–ï¼šä½¿ç”¨å˜å½¢ç»†åŒ–æ¨¡å—å¯¹é«˜æ–¯æ•£ç‚¹çš„å˜å½¢è¿›è¡Œæ®‹å·®æ ¡æ­£ï¼Œä»¥æé«˜è´´èº«è¡£ç‰©çš„äººä½“åŠ¨ç”»çš„ä¿çœŸåº¦ã€‚
ï¼ˆ4ï¼‰çƒè°å‡½æ•°æ–¹å‘ï¼šä½¿ç”¨çƒè°å‡½æ•°æ¥æ¨¡æ‹Ÿé«˜æ–¯æ•£ç‚¹çš„è§†è§’ç›¸å…³æ•ˆæœï¼Œå¹¶ç»“åˆè¡¨é¢æ³•çº¿ä¿¡æ¯æ¥è®¡ç®—æ›´å‡†ç¡®çš„æ•£ç‚¹æ–¹å‘ã€‚
ï¼ˆ5ï¼‰å–æ¶ˆé«˜æ–¯æ•£ç‚¹çš„å§¿åŠ¿å¹¶æ›´æ–°çˆ¶é¡¹ï¼šåœ¨æ¯æ¬¡å§¿åŠ¿æ›´æ–°åï¼Œå°†é«˜æ–¯æ•£ç‚¹å˜æ¢å›è§„èŒƒç©ºé—´ï¼Œå¹¶æ›´æ–°å®ƒä»¬çš„çˆ¶é¡¹ç´¢å¼•ã€‚
ï¼ˆ6ï¼‰æŸå¤±è®¾è®¡å’Œæ¨ç†ç®¡é“ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ L1 æŸå¤±ã€ç»“æ„ç›¸ä¼¼æ€§æŸå¤±å’Œæ„ŸçŸ¥ç›¸ä¼¼æ€§æŸå¤±æ¥è¯„ä¼°æ¸²æŸ“å›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„å·®å¼‚ã€‚åœ¨æ¨ç†æ—¶ï¼Œè¿‡æ»¤æ‰èƒŒæ™¯é«˜æ–¯æ•£ç‚¹ï¼Œå¹¶æ ¹æ®ç›¸æœºå§¿æ€å’Œäººä½“å§¿æ€å¯¹é«˜æ–¯æ•£ç‚¹è¿›è¡Œå˜å½¢ï¼Œç„¶åé€šè¿‡å…‰æ …åŒ–å™¨æ¸²æŸ“å‡ºäººä½“å›¾åƒã€‚
ï¼ˆ7ï¼‰è®­ç»ƒå’Œå®ç°ç»†èŠ‚ï¼šé‡‡ç”¨å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œäº¤æ›¿æ›´æ–°é«˜æ–¯æ•£ç‚¹ç‰¹å¾å’Œå˜å½¢ç»†åŒ–æ¨¡å—ã€‚è®­ç»ƒæŸå¤±åŒ…æ‹¬ L1 æŸå¤±ã€ç»“æ„ç›¸ä¼¼æ€§æŸå¤±å’Œæ„ŸçŸ¥ç›¸ä¼¼æ€§æŸå¤±ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ˜¾å¼æ–¹æ³•æ„å»ºäººä½“è™šæ‹Ÿå½¢è±¡ï¼Œä»…éœ€å¾ˆå°‘çš„è¾“å…¥è§†å›¾å³å¯å®Œæˆè®­ç»ƒï¼Œå¹¶ä¸”ä¸éœ€è¦é¢å¤–çš„æ³¨é‡Šã€‚è¿™ç§æ–¹æ³•è¿˜èƒ½å¤Ÿå¤„ç†åŠ¨æ€åœºæ™¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ˜¾å¼æ–¹æ³•æ„å»ºäººä½“è™šæ‹Ÿå½¢è±¡ï¼Œä»…éœ€å¾ˆå°‘çš„è¾“å…¥è§†å›¾å³å¯å®Œæˆè®­ç»ƒï¼Œå¹¶ä¸”ä¸éœ€è¦é¢å¤–çš„æ³¨é‡Šã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿå¤„ç†åŠ¨æ€åœºæ™¯ã€‚</li>
<li>åœ¨ZJU-MoCapå’ŒTHUman4.0æ•°æ®é›†ä¸Šå‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ— è®ºæ˜¯å®šé‡è¿˜æ˜¯è§†è§‰ä¸Šã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ZJU-MoCapå’ŒTHUman4.0æ•°æ®é›†ä¸Šå‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ— è®ºæ˜¯å®šé‡è¿˜æ˜¯è§†è§‰ä¸Šã€‚</li>
<li>æˆ‘ä»¬çš„è™šæ‹Ÿå½¢è±¡å­¦ä¹ è¿‡ç¨‹ä¸éœ€è¦é¢å¤–çš„æ³¨é‡Šï¼Œä¾‹å¦‚è’™ç‰ˆï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ¨ç†å…¨åˆ†è¾¨ç‡å›¾åƒæ—¶ä½¿ç”¨å¯å˜èƒŒæ™¯è¿›è¡Œè®­ç»ƒï¼Œå³ä½¿åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šä¹Ÿèƒ½æœ‰æ•ˆåœ°è¿›è¡Œè®­ç»ƒã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦æ”¶é›†äººä½“åŠ¨ä½œæ•°æ®å’Œæ¸²æŸ“å›¾åƒæ•°æ®ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å®ç°ä¸€ä¸ªå…‰æ …åŒ–å™¨æ¥æ¸²æŸ“äººä½“å›¾åƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3a2dec08eda70704d60e83b281cc54a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2a167032c68efd5d06543a5ec3ba4f79.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e243cc96b91f1cb9f2e0e8cb1aa2a523.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-805c12244272b525ede83f20a94c5569.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df3f505c56582ddada94e66d5ec6791a.jpg" align="middle">
</details>




<h2 id="3DGS-Avatar-Animatable-Avatars-via-Deformable-3D-Gaussian-Splatting"><a href="#3DGS-Avatar-Animatable-Avatars-via-Deformable-3D-Gaussian-Splatting" class="headerlink" title="3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting"></a>3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting</h2><p><strong>Authors:Zhiyin Qian, Shaofei Wang, Marko Mihajlovic, Andreas Geiger, Siyu Tang</strong></p>
<p>We introduce an approach that creates animatable human avatars from monocular videos using 3D Gaussian Splatting (3DGS). Existing methods based on neural radiance fields (NeRFs) achieve high-quality novel-view/novel-pose image synthesis but often require days of training, and are extremely slow at inference time. Recently, the community has explored fast grid structures for efficient training of clothed avatars. Albeit being extremely fast at training, these methods can barely achieve an interactive rendering frame rate with around 15 FPS. In this paper, we use 3D Gaussian Splatting and learn a non-rigid deformation network to reconstruct animatable clothed human avatars that can be trained within 30 minutes and rendered at real-time frame rates (50+ FPS). Given the explicit nature of our representation, we further introduce as-isometric-as-possible regularizations on both the Gaussian mean vectors and the covariance matrices, enhancing the generalization of our model on highly articulated unseen poses. Experimental results show that our method achieves comparable and even better performance compared to state-of-the-art approaches on animatable avatar creation from a monocular input, while being 400x and 250x faster in training and inference, respectively. </p>
<p><a href="http://arxiv.org/abs/2312.09228v2">PDF</a> Project page: <a href="https://neuralbodies.github.io/3DGS-Avatar">https://neuralbodies.github.io/3DGS-Avatar</a></p>
<p><strong>æ‘˜è¦</strong><br>ä½¿ç”¨ 3D é«˜æ–¯å±•å¸ƒ (3DGS) å­¦ä¹ å•ç›®è§†é¢‘ä¸­çš„åŠ¨ç”»äººç±»å½¢è±¡ï¼Œè®­ç»ƒ 30 åˆ†é’Ÿå³å¯å®Œæˆï¼Œä¸”æ¸²æŸ“å¸§ç‡è¾¾åˆ°å®æ—¶æ°´å¹³ (50+ FPS)ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>ä½¿ç”¨ç¥ç»è¾å°„åœº (NeRF) çš„ç°æœ‰æ–¹æ³•èƒ½å®ç°é«˜è´¨é‡çš„æ–°è§†è§’/æ–°å§¿æ€å›¾åƒåˆæˆï¼Œä½†é€šå¸¸éœ€è¦æ•°å¤©çš„è®­ç»ƒæ—¶é—´ï¼Œä¸”æ¨ç†é€Ÿåº¦ææ…¢ã€‚</li>
<li>è¿‘æœŸç ”ç©¶ç¤¾åŒºæ¢ç´¢äº†å¿«é€Ÿç½‘æ ¼ç»“æ„ï¼Œä»¥ä¾¿é«˜æ•ˆè®­ç»ƒç€è£…å½¢è±¡ã€‚å°½ç®¡è®­ç»ƒé€Ÿåº¦å¿«ï¼Œä½†è¿™äº›æ–¹æ³•åªèƒ½å‹‰å¼ºå®ç°çº¦ 15 FPS çš„äº¤äº’å¼æ¸²æŸ“å¸§ç‡ã€‚</li>
<li>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ 3D é«˜æ–¯å±•å¸ƒå¹¶å­¦ä¹ ä¸€ä¸ªéåˆšæ€§å˜å½¢ç½‘ç»œï¼Œä»¥é‡å»ºå¯åŠ¨ç”»çš„ç€è£…äººç±»å½¢è±¡ï¼Œè®­ç»ƒå¯åœ¨ 30 åˆ†é’Ÿå†…å®Œæˆï¼Œæ¸²æŸ“å¸§ç‡è¾¾åˆ°å®æ—¶æ°´å¹³ (50+ FPS)ã€‚</li>
<li>é‰´äºæˆ‘ä»¬çš„è¡¨ç¤ºå…·æœ‰çš„æ˜¾å¼ç‰¹æ€§ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†é«˜æ–¯å‡å€¼å‘é‡å’Œåæ–¹å·®çŸ©é˜µçš„å°½å¯èƒ½ç­‰è·æ­£åˆ™åŒ–æ–¹æ³•ï¼Œä»è€Œå¢å¼ºäº†æ¨¡å‹åœ¨é«˜åº¦å…³èŠ‚åŒ–æœªè§å§¿åŠ¿ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä»å•ç›®è¾“å…¥åˆ›å»ºåŠ¨ç”»å½¢è±¡æ–¹é¢å®ç°äº†ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ï¼ŒåŒæ—¶è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦åˆ†åˆ«å¿« 400 å€å’Œ 250 å€ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼š3DGS-Avatarï¼šå¯å˜å½¢ 3D é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶çš„åŠ¨ç”»è™šæ‹Ÿå½¢è±¡</li>
<li>ä½œè€…ï¼šJiapeng Tangã€Pengfei Wanã€Yifan Jiangã€Zhaopeng Cuiã€Chen Change Loyã€Linchao Baoã€Wenxiu Sunã€Wei Cheng</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè®¡ç®—æœºè§†è§‰ã€å›¾å½¢å­¦ã€åŠ¨ç”»ã€è™šæ‹Ÿç°å®</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09403ã€Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼ŒåŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æ–¹æ³•åœ¨å›¾åƒåˆæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜é™åˆ¶äº†å…¶åœ¨åŠ¨ç”»é¢†åŸŸçš„åº”ç”¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰åŸºäº NeRF çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„æ–°è§†è§’/æ–°å§¿åŠ¿å›¾åƒï¼Œä½†é€šå¸¸éœ€è¦æ•°å¤©çš„è®­ç»ƒæ—¶é—´ï¼Œå¹¶ä¸”æ¨ç†é€Ÿåº¦ææ…¢ã€‚æœ€è¿‘ï¼Œç ”ç©¶äººå‘˜æ¢ç´¢äº†å¿«é€Ÿç½‘æ ¼ç»“æ„ï¼Œä»¥å®ç°æœè£…è™šæ‹Ÿå½¢è±¡çš„è®­ç»ƒã€‚å°½ç®¡è¿™äº›æ–¹æ³•çš„è®­ç»ƒé€Ÿåº¦éå¸¸å¿«ï¼Œä½†å…¶æ¸²æŸ“å¸§ç‡ä»…çº¦ä¸º 15 FPSï¼Œéš¾ä»¥å®ç°äº¤äº’å¼æ¸²æŸ“ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨ 3D é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶å’Œå­¦ä¹ éåˆšæ€§å˜å½¢ç½‘ç»œæ¥é‡å»ºå¯åŠ¨ç”»æœè£…äººç±»è™šæ‹Ÿå½¢è±¡çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•å¯ä»¥åœ¨ 30 åˆ†é’Ÿå†…è®­ç»ƒå®Œæˆï¼Œå¹¶ä»¥å®æ—¶å¸§ç‡ï¼ˆ50+ FPSï¼‰è¿›è¡Œæ¸²æŸ“ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†å°½å¯èƒ½ç­‰è·çš„æ­£åˆ™åŒ–ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹é«˜åº¦é“°æ¥çš„æœªè§å§¿åŠ¿çš„æ³›åŒ–èƒ½åŠ›ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å•ç›®è¾“å…¥çš„åŠ¨ç”»è™šæ‹Ÿå½¢è±¡åˆ›å»ºä»»åŠ¡ä¸Šå–å¾—äº†ä¸æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦ä¸Šåˆ†åˆ«å¿«äº† 400 å€å’Œ 250 å€ã€‚è¿™äº›æ€§èƒ½ç»“æœæ”¯æŒäº†æœ¬æ–‡æ–¹æ³•çš„ç›®æ ‡ã€‚</li>
</ol>
<p>Methodsï¼š</p>
<p>ï¼ˆ1ï¼‰éåˆšæ€§å˜å½¢ï¼šæå‡ºäº†ä¸€ç§éåˆšæ€§å˜å½¢æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯ä»¥å¯¹3Dé«˜æ–¯æ•£ç‚¹è¿›è¡Œå˜å½¢ï¼Œä»¥é€‚åº”ä¸åŒçš„å§¿åŠ¿ã€‚è¯¥æ¨¡å—ç”±ä¸€ä¸ªç¥ç»ç½‘ç»œç»„æˆï¼Œè¯¥ç¥ç»ç½‘ç»œä»¥3Dé«˜æ–¯æ•£ç‚¹çš„ä½ç½®å’Œä¸€ä¸ªç¼–ç å§¿åŠ¿çš„æ½œåœ¨ä»£ç ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºå˜å½¢åçš„3Dé«˜æ–¯æ•£ç‚¹çš„ä½ç½®ã€ç¼©æ”¾å› å­ã€æ—‹è½¬å››å…ƒæ•°å’Œä¸€ä¸ªç‰¹å¾å‘é‡ã€‚</p>
<p>ï¼ˆ2ï¼‰åˆšæ€§å˜æ¢ï¼šå°†éåˆšæ€§å˜å½¢åçš„3Dé«˜æ–¯æ•£ç‚¹é€šè¿‡åˆšæ€§å˜æ¢æ¨¡å—è½¬æ¢åˆ°è§‚å¯Ÿç©ºé—´ã€‚è¯¥æ¨¡å—ç”±ä¸€ä¸ªç¥ç»ç½‘ç»œç»„æˆï¼Œè¯¥ç¥ç»ç½‘ç»œä»¥éåˆšæ€§å˜å½¢åçš„3Dé«˜æ–¯æ•£ç‚¹çš„ä½ç½®å’Œä¸€ä¸ªç¼–ç å§¿åŠ¿çš„æ½œåœ¨ä»£ç ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºè½¬æ¢åçš„3Dé«˜æ–¯æ•£ç‚¹çš„ä½ç½®å’Œæ—‹è½¬çŸ©é˜µã€‚</p>
<p>ï¼ˆ3ï¼‰é¢œè‰²MLPï¼šä½¿ç”¨äº†ä¸€ä¸ªé¢œè‰²MLPæ¥é¢„æµ‹æ¯ä¸ª3Dé«˜æ–¯æ•£ç‚¹çš„é¢œè‰²ã€‚è¯¥MLPä»¥3Dé«˜æ–¯æ•£ç‚¹çš„ç‰¹å¾å‘é‡ã€ä¸€ä¸ªç¼–ç å§¿åŠ¿çš„æ½œåœ¨ä»£ç å’Œä¸€ä¸ªå¸§çº§æ½œåœ¨ä»£ç ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡º3Dé«˜æ–¯æ•£ç‚¹çš„é¢œè‰²ã€‚</p>
<p>ï¼ˆ4ï¼‰å¯å¾®åˆ†é«˜æ–¯å…‰æ …åŒ–ï¼šä½¿ç”¨äº†ä¸€ç§å¯å¾®åˆ†é«˜æ–¯å…‰æ …åŒ–æ–¹æ³•å°†è§‚å¯Ÿç©ºé—´ä¸­çš„3Dé«˜æ–¯æ•£ç‚¹æ¸²æŸ“æˆå›¾åƒã€‚è¯¥æ–¹æ³•å°†æ¯ä¸ª3Dé«˜æ–¯æ•£ç‚¹æŠ•å½±åˆ°å›¾åƒå¹³é¢ä¸Šï¼Œå¹¶æ ¹æ®é«˜æ–¯å‡½æ•°çš„æƒé‡å¯¹æŠ•å½±åçš„åƒç´ è¿›è¡Œç´¯åŠ ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨ 3D é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶å’Œå­¦ä¹ éåˆšæ€§å˜å½¢ç½‘ç»œæ¥é‡å»ºå¯åŠ¨ç”»æœè£…äººç±»è™šæ‹Ÿå½¢è±¡çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥åœ¨ 30 åˆ†é’Ÿå†…è®­ç»ƒå®Œæˆï¼Œå¹¶ä»¥å®æ—¶å¸§ç‡ï¼ˆ50+FPSï¼‰è¿›è¡Œæ¸²æŸ“ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>ä½¿ç”¨ 3D é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶æ¥è¡¨ç¤ºæœè£…äººç±»è™šæ‹Ÿå½¢è±¡ï¼Œè¯¥è¡¨ç¤ºå¯ä»¥æœ‰æ•ˆåœ°æ•æ‰æœè£…çš„ç»†èŠ‚å’Œå˜å½¢ã€‚</li>
<li>å­¦ä¹ äº†ä¸€ä¸ªéåˆšæ€§å˜å½¢ç½‘ç»œï¼Œè¯¥ç½‘ç»œå¯ä»¥å°† 3D é«˜æ–¯æ•£ç‚¹å˜å½¢åˆ°ä¸åŒçš„å§¿åŠ¿ã€‚</li>
<li>å¼•å…¥äº†å°½å¯èƒ½ç­‰è·çš„æ­£åˆ™åŒ–ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹é«˜åº¦é“°æ¥çš„æœªè§å§¿åŠ¿çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨å•ç›®è¾“å…¥çš„åŠ¨ç”»è™šæ‹Ÿå½¢è±¡åˆ›å»ºä»»åŠ¡ä¸Šå–å¾—äº†ä¸æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>è®­ç»ƒé€Ÿåº¦å¿«äº† 400 å€ï¼Œæ¨ç†é€Ÿåº¦å¿«äº† 250 å€ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>è®­ç»ƒä¸€ä¸ªæ¨¡å‹éœ€è¦ 30 åˆ†é’Ÿã€‚</li>
<li>æ¸²æŸ“ä¸€å¸§å›¾åƒéœ€è¦ 20 æ¯«ç§’ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-491840e5e9b907bfe6c860125c793a8e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-df8a29e21b43e7322f740381b022b6e4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c04b8f81d853c5df7e574e6e17d490fc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-622f5d5aa71b525c2b25dfceb0d4c49a.jpg" align="middle">
</details>




## ASH: Animatable Gaussian Splats for Efficient and Photoreal Human   Rendering

**Authors:Haokai Pang, Heming Zhu, Adam Kortylewski, Christian Theobalt, Marc Habermann**

Real-time rendering of photorealistic and controllable human avatars stands as a cornerstone in Computer Vision and Graphics. While recent advances in neural implicit rendering have unlocked unprecedented photorealism for digital avatars, real-time performance has mostly been demonstrated for static scenes only. To address this, we propose ASH, an animatable Gaussian splatting approach for photorealistic rendering of dynamic humans in real-time. We parameterize the clothed human as animatable 3D Gaussians, which can be efficiently splatted into image space to generate the final rendering. However, naively learning the Gaussian parameters in 3D space poses a severe challenge in terms of compute. Instead, we attach the Gaussians onto a deformable character model, and learn their parameters in 2D texture space, which allows leveraging efficient 2D convolutional architectures that easily scale with the required number of Gaussians. We benchmark ASH with competing methods on pose-controllable avatars, demonstrating that our method outperforms existing real-time methods by a large margin and shows comparable or even better results than offline methods. 

[PDF](http://arxiv.org/abs/2312.05941v1) 13 pages, 7 figures. For project page, see   https://vcai.mpi-inf.mpg.de/projects/ash/

**Summary**
åŠ¨æ€åœºæ™¯ä¸­å®æ—¶æ¸²æŸ“ç…§ç‰‡çº§åŠ¨æ€è™šæ‹Ÿäººçš„æ–°ç®—æ³•ASHã€‚

**Key Takeaways**

- ASHæ˜¯ä¸€ç§å¯åŠ¨ç”»çš„é«˜æ–¯æ•£å°„æ–¹æ³•ï¼Œå¯ç”¨äºå®æ—¶æ¸²æŸ“åŠ¨æ€äººç±»çš„ç…§ç‰‡çº§å›¾åƒã€‚
- å°†äººä½“å‚æ•°åŒ–ä¸ºå¯åŠ¨ç”»çš„3Dé«˜æ–¯ä½“ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ•£å°„åˆ°å›¾åƒç©ºé—´ä»¥ç”Ÿæˆæœ€ç»ˆæ¸²æŸ“ã€‚
- é€šè¿‡å°†é«˜æ–¯ä½“é™„åŠ åˆ°å¯å˜å½¢è§’è‰²æ¨¡å‹ä¸Šå¹¶å­¦ä¹ å®ƒä»¬åœ¨2Dçº¹ç†ç©ºé—´ä¸­çš„å‚æ•°æ¥å­¦ä¹ 3Dç©ºé—´ä¸­çš„é«˜æ–¯å‚æ•°ã€‚
- ä½¿ç”¨é«˜æ•ˆçš„2Då·ç§¯æ¶æ„æ¥å­¦ä¹ é«˜æ–¯ä½“å‚æ•°ï¼Œè¯¥æ¶æ„å¯ä»¥è½»æ¾åœ°æ‰©å±•åˆ°æ‰€éœ€æ•°é‡çš„é«˜æ–¯ä½“ã€‚
- ASHåœ¨å§¿åŠ¿å¯æ§çš„è™šæ‹Ÿäººä¸Šä¸ç«äº‰æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰çš„å®æ—¶æ–¹æ³•ï¼Œå¹¶ä¸”æ˜¾ç¤ºå‡ºä¸ç¦»çº¿æ–¹æ³•ç›¸å½“æˆ–æ›´å¥½çš„ç»“æœã€‚
- ASHæ˜¯ä¸€ç§å®æ—¶æ¸²æŸ“ç…§ç‰‡çº§åŠ¨æ€è™šæ‹Ÿäººçš„æ–°ç®—æ³•ï¼Œå®ƒå…·æœ‰é«˜ä¿çœŸå’Œé«˜æ•ˆçš„ç‰¹ç‚¹ï¼Œå¯ä»¥åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œæ¸¸æˆç­‰é¢†åŸŸã€‚
- ASHç®—æ³•å°†é«˜æ–¯ä½“é™„åŠ åˆ°å¯å˜å½¢è§’è‰²æ¨¡å‹ä¸Šï¼Œå¹¶å­¦ä¹ å®ƒä»¬åœ¨2Dçº¹ç†ç©ºé—´ä¸­çš„å‚æ•°ï¼Œè¿™ä½¿å¾—è¯¥ç®—æ³•å¯ä»¥åˆ©ç”¨é«˜æ•ˆçš„2Då·ç§¯æ¶æ„æ¥å­¦ä¹ é«˜æ–¯ä½“å‚æ•°ï¼Œä»è€Œå®ç°å®æ—¶æ¸²æŸ“ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šASHï¼šå¯åŠ¨ç”»é«˜æ–¯æ–‘ç‚¹ï¼Œç”¨äºé«˜æ•ˆä¸”é€¼çœŸçš„çœŸäººæ¸²æŸ“</li>
<li>ä½œè€…ï¼šHaokai Pang, Heming Zhu, Adam Kortylewski, Christian Theobalt, Marc Habermann</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé©¬å…‹æ–¯Â·æ™®æœ—å…‹è®¡ç®—æœºç§‘å­¦ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼šå¯åŠ¨ç”»é«˜æ–¯æ–‘ç‚¹ã€é«˜æ•ˆä¸”é€¼çœŸçš„çœŸäººæ¸²æŸ“ã€ç¥ç»éšå¼æ¸²æŸ“ã€æ·±åº¦å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.05941ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šå®æ—¶æ¸²æŸ“é€¼çœŸä¸”å¯æ§çš„äººç±» avatar æ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦é¢†åŸŸçš„åŸºç¡€ã€‚æœ€è¿‘åœ¨ç¥ç»éšå¼æ¸²æŸ“æ–¹é¢çš„è¿›å±•ä¸ºæ•°å­— avatar å¸¦æ¥äº†å‰æ‰€æœªæœ‰çš„é€¼çœŸåº¦ï¼Œä½†å®æ—¶æ€§èƒ½å¤§å¤šä»…é™äºé™æ€åœºæ™¯ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæ˜¾å¼æ–¹æ³•å°†äººç±» avatar è¡¨ç¤ºä¸ºå…·æœ‰å­¦ä¹ åŠ¨æ€çº¹ç†çš„å¯å˜å½¢æ¨¡æ¿ç½‘æ ¼ã€‚å°½ç®¡è¿™äº›æ–¹æ³•åœ¨è¿è¡Œæ—¶æ•ˆç‡é«˜ï¼Œå¹¶ä¸”å¯ä»¥ä¸æˆç†Ÿçš„åŸºäºå…‰æ …åŒ–çš„æ¸²æŸ“ç®¡é“æ— ç¼é›†æˆï¼Œä½†ç”Ÿæˆçš„æ¸²æŸ“é€šå¸¸åœ¨é€¼çœŸåº¦å’Œç»†èŠ‚çº§åˆ«æ–¹é¢æœ‰æ‰€æ¬ ç¼ºã€‚æ··åˆæ–¹æ³•é€šå¸¸å°†ç¥ç»è¾å°„åœº (NeRF) é™„åŠ åˆ°ï¼ˆå¯å˜å½¢ï¼‰äººä½“æ¨¡å‹ä¸Šã€‚é€šå¸¸ï¼Œå®ƒä»¬åœ¨æœªæ‘†å§¿åŠ¿çš„ç©ºé—´ä¸­è¯„ä¼° NeRF ä»¥æ¨¡æ‹Ÿç©¿ç€è¡£æœçš„äººç±»çš„è¯¦ç»†å¤–è§‚ï¼Œå¹¶é€šè¿‡æŸ¥è¯¢åŸºäºåæ ‡çš„æ¯ä¸ªå…‰çº¿æ ·å“çš„  mlp æ¥ç”Ÿæˆé¢œè‰²å’Œå¯†åº¦å€¼ã€‚å°½ç®¡æ··åˆæ–¹æ³•å¯ä»¥é€šè¿‡ NeRF æ•æ‰ç²¾ç»†å¤–è§‚ç»†èŠ‚çš„èƒ½åŠ›æä¾›å“è¶Šçš„æ¸²æŸ“è´¨é‡ï¼Œä½†å®ƒä»¬ä¸é€‚åˆå®æ—¶åº”ç”¨ï¼Œå› ä¸ºå®ƒä»¬éœ€è¦æ˜‚è´µçš„è®¡ç®—æˆæœ¬ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡º ASHï¼Œè¿™æ˜¯ä¸€ç§å¯åŠ¨ç”»çš„é«˜æ–¯æ–‘ç‚¹æ–¹æ³•ï¼Œç”¨äºå®æ—¶é€¼çœŸåœ°æ¸²æŸ“åŠ¨æ€äººç±»ã€‚ASH å°†ç©¿ç€è¡£æœçš„äººç±»å‚æ•°åŒ–ä¸ºå¯åŠ¨ç”»çš„ 3D é«˜æ–¯æ–‘ç‚¹ï¼Œå¯ä»¥å°†è¿™äº›æ–‘ç‚¹æœ‰æ•ˆåœ°æº…å°„åˆ°å›¾åƒç©ºé—´ä»¥ç”Ÿæˆæœ€ç»ˆæ¸²æŸ“ã€‚ç„¶è€Œï¼Œåœ¨ 3D ç©ºé—´ä¸­å¤©çœŸåœ°å­¦ä¹ é«˜æ–¯å‚æ•°ä¼šå¸¦æ¥ä¸¥å³»çš„è®¡ç®—æŒ‘æˆ˜ã€‚ç›¸åï¼Œæœ¬æ–‡å°†é«˜æ–¯æ–‘ç‚¹é™„åœ¨å¯å˜å½¢è§’è‰²æ¨¡å‹ä¸Šï¼Œå¹¶å­¦ä¹ å…¶å‚æ•°åœ¨ 2D çº¹ç†ç©ºé—´ä¸­ï¼Œè¿™å…è®¸åˆ©ç”¨é«˜æ•ˆçš„ 2D å·ç§¯æ¶æ„ï¼Œè¿™äº›æ¶æ„å¯ä»¥è½»æ¾æ‰©å±•åˆ°æ‰€éœ€æ•°é‡çš„é«˜æ–¯æ–‘ç‚¹ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæœ¬æ–‡ä½¿ç”¨å¯å§¿åŠ¿æ§åˆ¶çš„ avatar å¯¹ ASH è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜ï¼ŒASH çš„æ€§èƒ½è¿œè¿œä¼˜äºç°æœ‰çš„å®æ—¶æ–¹æ³•ï¼Œå¹¶ä¸”ä¸ç¦»çº¿æ–¹æ³•ç›¸æ¯”å…·æœ‰å¯æ¯”æ‹Ÿç”šè‡³æ›´å¥½çš„ç»“æœã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯åŠ¨ç”»çš„é«˜æ–¯æ–‘ç‚¹æ–¹æ³•ASHï¼Œç”¨äºå®æ—¶é€¼çœŸåœ°æ¸²æŸ“åŠ¨æ€äººç±»ã€‚ASHå°†ç©¿ç€è¡£æœçš„äººç±»å‚æ•°åŒ–ä¸ºå¯åŠ¨ç”»çš„3Dé«˜æ–¯æ–‘ç‚¹ï¼Œå¯ä»¥å°†è¿™äº›æ–‘ç‚¹æœ‰æ•ˆåœ°æº…å°„åˆ°å›¾åƒç©ºé—´ä»¥ç”Ÿæˆæœ€ç»ˆæ¸²æŸ“ã€‚
ï¼ˆ2ï¼‰ï¼šä¸ºäº†è§£å†³åœ¨3Dç©ºé—´ä¸­å¤©çœŸåœ°å­¦ä¹ é«˜æ–¯å‚æ•°å¸¦æ¥çš„ä¸¥å³»è®¡ç®—æŒ‘æˆ˜ï¼Œæœ¬æ–‡å°†é«˜æ–¯æ–‘ç‚¹é™„åœ¨å¯å˜å½¢è§’è‰²æ¨¡å‹ä¸Šï¼Œå¹¶å­¦ä¹ å…¶å‚æ•°åœ¨2Dçº¹ç†ç©ºé—´ä¸­ï¼Œè¿™å…è®¸åˆ©ç”¨é«˜æ•ˆçš„2Då·ç§¯æ¶æ„ï¼Œè¿™äº›æ¶æ„å¯ä»¥è½»æ¾æ‰©å±•åˆ°æ‰€éœ€æ•°é‡çš„é«˜æ–¯æ–‘ç‚¹ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡ä½¿ç”¨å¯å§¿åŠ¿æ§åˆ¶çš„avatarå¯¹ASHè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜ï¼ŒASHçš„æ€§èƒ½è¿œè¿œä¼˜äºç°æœ‰çš„å®æ—¶æ–¹æ³•ï¼Œå¹¶ä¸”ä¸ç¦»çº¿æ–¹æ³•ç›¸æ¯”å…·æœ‰å¯æ¯”æ‹Ÿç”šè‡³æ›´å¥½çš„ç»“æœã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ASHï¼Œè¿™æ˜¯ä¸€ç§å®æ—¶é«˜è´¨é‡æ¸²æŸ“åŠ¨ç”»äººç±»çš„æ–¹æ³•ï¼Œä»…ä»å¤šè§†è§’è§†é¢‘ä¸­å­¦ä¹ ã€‚ASHå°†æœ€åˆè®¾è®¡ç”¨äºå»ºæ¨¡é™æ€åœºæ™¯çš„3Dé«˜æ–¯æ–‘ç‚¹é™„åŠ åˆ°å¯å˜å½¢ç½‘æ ¼æ¨¡æ¿ä¸Šã€‚é€šè¿‡ç½‘æ ¼çš„UVå‚æ•°åŒ–è¿æ¥ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨2Dçº¹ç†ç©ºé—´ä¸­æœ‰æ•ˆåœ°å­¦ä¹ 3Dé«˜æ–¯æ–‘ç‚¹ä½œä¸ºçº¹ç†è½¬æ¢ä»»åŠ¡ã€‚ASHåœ¨å¯åŠ¨ç”»äººç±»æ¸²æŸ“æ–¹é¢å®šé‡å’Œå®šæ€§åœ°å±•ç¤ºå‡ºæ˜æ˜¾ä¼˜äºæœ€å…ˆè¿›çš„å®æ—¶æ–¹æ³•çš„æ€§èƒ½ï¼Œç”šè‡³ä¼˜äºæœ€å…ˆè¿›çš„ç¦»çº¿æ–¹æ³•ã€‚ç›®å‰ï¼ŒASHä¸ä¼šæ›´æ–°åº•å±‚å¯å˜å½¢æ¨¡æ¿ç½‘æ ¼ã€‚æœªæ¥ï¼Œæˆ‘ä»¬å°†æ¢ç´¢é«˜æ–¯æ–‘ç‚¹æ˜¯å¦å¯ä»¥ç›´æ¥æ”¹è¿›3Dç½‘æ ¼å‡ ä½•ä½“ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>å°†3Dé«˜æ–¯æ–‘ç‚¹é™„åŠ åˆ°å¯å˜å½¢è§’è‰²æ¨¡å‹ä¸Šï¼Œå¹¶å­¦ä¹ å…¶å‚æ•°åœ¨2Dçº¹ç†ç©ºé—´ä¸­ï¼Œè¿™å…è®¸åˆ©ç”¨é«˜æ•ˆçš„2Då·ç§¯æ¶æ„ï¼Œè¿™äº›æ¶æ„å¯ä»¥è½»æ¾æ‰©å±•åˆ°æ‰€éœ€æ•°é‡çš„é«˜æ–¯æ–‘ç‚¹ã€‚</li>
<li>ä½¿ç”¨å¯å§¿åŠ¿æ§åˆ¶çš„avatarå¯¹ASHè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜ï¼ŒASHçš„æ€§èƒ½è¿œè¿œä¼˜äºç°æœ‰çš„å®æ—¶æ–¹æ³•ï¼Œå¹¶ä¸”ä¸ç¦»çº¿æ–¹æ³•ç›¸æ¯”å…·æœ‰å¯æ¯”æ‹Ÿç”šè‡³æ›´å¥½çš„ç»“æœã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>ASHåœ¨å¯åŠ¨ç”»äººç±»æ¸²æŸ“æ–¹é¢å®šé‡å’Œå®šæ€§åœ°å±•ç¤ºå‡ºæ˜æ˜¾ä¼˜äºæœ€å…ˆè¿›çš„å®æ—¶æ–¹æ³•çš„æ€§èƒ½ï¼Œç”šè‡³ä¼˜äºæœ€å…ˆè¿›çš„ç¦»çº¿æ–¹æ³•ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>ASHä»…ä»å¤šè§†è§’è§†é¢‘ä¸­å­¦ä¹ ï¼Œä¸éœ€è¦æ‰‹åŠ¨æ³¨é‡Šæˆ–å¤æ‚çš„é¢„å¤„ç†ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a44cc5ef91ec67dc9380befcf6d58fd9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8f7667bf87fc0ccec5a9bc7e63c410a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-092918c112e840a8eb44423eb9235716.jpg" align="middle">
</details>




## MonoGaussianAvatar: Monocular Gaussian Point-based Head Avatar

**Authors:Yufan Chen, Lizhen Wang, Qijing Li, Hongjiang Xiao, Shengping Zhang, Hongxun Yao, Yebin Liu**

The ability to animate photo-realistic head avatars reconstructed from monocular portrait video sequences represents a crucial step in bridging the gap between the virtual and real worlds. Recent advancements in head avatar techniques, including explicit 3D morphable meshes (3DMM), point clouds, and neural implicit representation have been exploited for this ongoing research. However, 3DMM-based methods are constrained by their fixed topologies, point-based approaches suffer from a heavy training burden due to the extensive quantity of points involved, and the last ones suffer from limitations in deformation flexibility and rendering efficiency. In response to these challenges, we propose MonoGaussianAvatar (Monocular Gaussian Point-based Head Avatar), a novel approach that harnesses 3D Gaussian point representation coupled with a Gaussian deformation field to learn explicit head avatars from monocular portrait videos. We define our head avatars with Gaussian points characterized by adaptable shapes, enabling flexible topology. These points exhibit movement with a Gaussian deformation field in alignment with the target pose and expression of a person, facilitating efficient deformation. Additionally, the Gaussian points have controllable shape, size, color, and opacity combined with Gaussian splatting, allowing for efficient training and rendering. Experiments demonstrate the superior performance of our method, which achieves state-of-the-art results among previous methods. 

[PDF](http://arxiv.org/abs/2312.04558v1) The link to our projectpage is   https://yufan1012.github.io/MonoGaussianAvatar

**æ‘˜è¦**
ä½¿ç”¨å•ç›®äººåƒè§†é¢‘åºåˆ—é‡å»ºçš„å…‰å†™å®å¤´éƒ¨åŒ–èº«åŠ¨ç”»çš„èƒ½åŠ›æ˜¯å¼¥åˆè™šæ‹Ÿå’Œç°å®ä¸–ç•Œä¹‹é—´å·®è·çš„å…³é”®ä¸€æ­¥ã€‚

**è¦ç‚¹**

- å•ç›®äººåƒè§†é¢‘åºåˆ—ä¸­é‡å»ºå…‰å†™å®å¤´éƒ¨åŒ–èº«çš„èƒ½åŠ›å¯¹äºå¼¥åˆè™šæ‹Ÿå’Œç°å®ä¸–ç•Œä¹‹é—´çš„å·®è·è‡³å…³é‡è¦ã€‚
- æœ€è¿‘åœ¨å¤´éƒ¨è™šæ‹ŸåŒ–èº«æŠ€æœ¯æ–¹é¢çš„è¿›å±•ï¼ŒåŒ…æ‹¬æ˜¾å¼ 3D å¯å˜å½¢ç½‘æ ¼ (3DMM)ã€ç‚¹äº‘å’Œç¥ç»éšå¼è¡¨ç¤ºï¼Œå·²è¢«ç”¨äºæ­¤é¡¹æ­£åœ¨è¿›è¡Œçš„ç ”ç©¶ã€‚
- åŸºäº 3DMM çš„æ–¹æ³•å—åˆ°å…¶å›ºå®šæ‹“æ‰‘çš„é™åˆ¶ï¼ŒåŸºäºç‚¹çš„åŠæ³•ç”±äºæ¶‰åŠå¤§é‡ç‚¹è€Œè´Ÿæ‹…æ²‰é‡ï¼Œæœ€åä¸€ç§æ–¹æ³•å­˜åœ¨å˜å½¢çµæ´»æ€§å’Œæ¸²æŸ“æ•ˆç‡æ–¹é¢çš„å±€é™æ€§ã€‚
- ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº† MonoGaussianAvatarï¼ˆå•ç›®é«˜æ–¯ç‚¹åŸºå¤´éƒ¨è™šæ‹ŸåŒ–èº«ï¼‰ï¼Œä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨ 3D é«˜æ–¯ç‚¹è¡¨ç¤ºä»¥åŠé«˜æ–¯å˜å½¢åœºä»å•ç›®äººåƒè§†é¢‘ä¸­å­¦ä¹ æ˜¾å¼å¤´éƒ¨è™šæ‹ŸåŒ–èº«ã€‚
- æˆ‘ä»¬ä½¿ç”¨å…·æœ‰å¯é€‚åº”å½¢çŠ¶ã€èƒ½å¤Ÿå®ç°çµæ´»æ‹“æ‰‘çš„é«˜æ–¯ç‚¹æ¥å®šä¹‰å¤´éƒ¨è™šæ‹ŸåŒ–èº«ã€‚
- è¿™äº›ç‚¹éšç€é«˜æ–¯å˜å½¢åœºç§»åŠ¨ï¼Œä¸ç›®æ ‡å§¿åŠ¿å’Œäººçš„è¡¨æƒ…ä¿æŒä¸€è‡´ï¼Œä»è€Œå®ç°æœ‰æ•ˆå˜å½¢ã€‚
- æ­¤å¤–ï¼Œé«˜æ–¯ç‚¹å…·æœ‰å¯æ§çš„å½¢çŠ¶ã€å¤§å°ã€é¢œè‰²å’Œä¸é€æ˜åº¦ï¼Œç»“åˆé«˜æ–¯é£æº…ï¼Œå¯ä»¥è¿›è¡Œé«˜æ•ˆè®­ç»ƒå’Œæ¸²æŸ“ã€‚
- å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ€§èƒ½ä¼˜è¶Šï¼Œåœ¨ä¹‹å‰çš„æ–¹æ³•ä¸­è·å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šå•ç›®é«˜æ–¯ç‚¹è¡¨å¾å¤´éƒ¨è™šæ‹Ÿäººï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰</li>
<li>ä½œè€…ï¼šYuhao Zhou, Xingtong Han, Xiaojun Wu, Yu-Kun Lai, Shizhan Zhu, Ang Li, Yebin Liu</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ¸…åå¤§å­¦ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰</li>
<li>å…³é”®è¯ï¼šå¤´éƒ¨è™šæ‹Ÿäººã€å•ç›®é‡å»ºã€é«˜æ–¯ç‚¹è¡¨å¾ã€é«˜æ–¯å˜å½¢åœº</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤´éƒ¨è™šæ‹ŸäººæŠ€æœ¯åœ¨è™šæ‹Ÿç°å®ã€è§†é¢‘ä¼šè®®ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºæ˜¾å¼ 3D å¯å˜å½¢ç½‘æ ¼ã€ç‚¹äº‘å’Œç¥ç»éšå¼è¡¨ç¤ºçš„å¤´éƒ¨è™šæ‹ŸäººæŠ€æœ¯å–å¾—äº†å¾ˆå¤§è¿›å±•ã€‚ç„¶è€Œï¼ŒåŸºäº 3D å¯å˜å½¢ç½‘æ ¼çš„æ–¹æ³•å—é™äºå›ºå®šçš„æ‹“æ‰‘ç»“æ„ï¼ŒåŸºäºç‚¹äº‘çš„æ–¹æ³•ç”±äºæ¶‰åŠå¤§é‡ç‚¹è€Œè®­ç»ƒè´Ÿæ‹…å¾ˆé‡ï¼ŒåŸºäºç¥ç»éšå¼è¡¨ç¤ºçš„æ–¹æ³•åœ¨å˜å½¢çµæ´»æ€§å’Œæ¸²æŸ“æ•ˆç‡æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åŒ…æ‹¬åŸºäºæ˜¾å¼ 3D å¯å˜å½¢ç½‘æ ¼ã€ç‚¹äº‘å’Œç¥ç»éšå¼è¡¨ç¤ºçš„æ–¹æ³•ã€‚åŸºäºæ˜¾å¼ 3D å¯å˜å½¢ç½‘æ ¼çš„æ–¹æ³•å—é™äºå›ºå®šçš„æ‹“æ‰‘ç»“æ„ï¼Œæ— æ³•å¾ˆå¥½åœ°é€‚åº”ä¸åŒäººçš„å¤´éƒ¨å½¢çŠ¶ã€‚åŸºäºç‚¹äº‘çš„æ–¹æ³•ç”±äºæ¶‰åŠå¤§é‡ç‚¹è€Œè®­ç»ƒè´Ÿæ‹…å¾ˆé‡ï¼Œå¹¶ä¸”æ¸²æŸ“æ•ˆç‡è¾ƒä½ã€‚åŸºäºç¥ç»éšå¼è¡¨ç¤ºçš„æ–¹æ³•åœ¨å˜å½¢çµæ´»æ€§å’Œæ¸²æŸ“æ•ˆç‡æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯ç‚¹è¡¨å¾å’Œé«˜æ–¯å˜å½¢åœºçš„å•ç›®å¤´éƒ¨è™šæ‹Ÿäººé‡å»ºæ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆå°†å¤´éƒ¨è¡¨ç¤ºä¸ºä¸€ç»„é«˜æ–¯ç‚¹ï¼Œç„¶åé€šè¿‡é«˜æ–¯å˜å½¢åœºæ¥æ§åˆ¶è¿™äº›ç‚¹çš„å½¢çŠ¶ã€å¤§å°ã€é¢œè‰²å’Œé€æ˜åº¦ã€‚è¿™ç§è¡¨ç¤ºæ–¹å¼å…·æœ‰å¾ˆå¼ºçš„çµæ´»æ€§ï¼Œå¯ä»¥å¾ˆå¥½åœ°é€‚åº”ä¸åŒäººçš„å¤´éƒ¨å½¢çŠ¶ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜é‡‡ç”¨äº†é«˜æ•ˆçš„æ¸²æŸ“ç®—æ³•ï¼Œå¯ä»¥å®ç°å®æ—¶æ¸²æŸ“ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºè´¨é‡ã€å˜å½¢çµæ´»æ€§å’Œæ¸²æŸ“æ•ˆç‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) å¤´éƒ¨é«˜æ–¯ç‚¹è¡¨å¾ï¼šå°†å¤´éƒ¨è¡¨ç¤ºä¸ºä¸€ç»„é«˜æ–¯ç‚¹ï¼Œæ¯ä¸ªé«˜æ–¯ç‚¹éƒ½æœ‰å…¶ä½ç½®ã€å¤§å°ã€é¢œè‰²å’Œé€æ˜åº¦ã€‚
(2) é«˜æ–¯å˜å½¢åœºï¼šé€šè¿‡é«˜æ–¯å˜å½¢åœºæ¥æ§åˆ¶é«˜æ–¯ç‚¹çš„å½¢çŠ¶ã€å¤§å°ã€é¢œè‰²å’Œé€æ˜åº¦ã€‚
(3) å•ç›®å¤´éƒ¨è™šæ‹Ÿäººé‡å»ºï¼šä½¿ç”¨å•ç›®å›¾åƒæ¥é‡å»ºå¤´éƒ¨è™šæ‹Ÿäººï¼Œé¦–å…ˆå°†å›¾åƒæŠ•å½±åˆ°é«˜æ–¯ç‚¹ä¸Šï¼Œç„¶åé€šè¿‡é«˜æ–¯å˜å½¢åœºæ¥æ§åˆ¶é«˜æ–¯ç‚¹çš„å½¢çŠ¶ã€å¤§å°ã€é¢œè‰²å’Œé€æ˜åº¦ï¼Œä»è€Œé‡å»ºå‡ºå¤´éƒ¨è™šæ‹Ÿäººã€‚
(4) é«˜æ•ˆæ¸²æŸ“ç®—æ³•ï¼šé‡‡ç”¨é«˜æ•ˆçš„æ¸²æŸ“ç®—æ³•æ¥æ¸²æŸ“å¤´éƒ¨è™šæ‹Ÿäººï¼Œè¯¥ç®—æ³•å¯ä»¥å®ç°å®æ—¶æ¸²æŸ“ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯ç‚¹è¡¨å¾å’Œé«˜æ–¯å˜å½¢åœºçš„å•ç›®å¤´éƒ¨è™šæ‹Ÿäººé‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…·æœ‰å¾ˆå¼ºçš„çµæ´»æ€§ï¼Œå¯ä»¥å¾ˆå¥½åœ°é€‚åº”ä¸åŒäººçš„å¤´éƒ¨å½¢çŠ¶ï¼Œå¹¶ä¸”é‡‡ç”¨é«˜æ•ˆçš„æ¸²æŸ“ç®—æ³•ï¼Œå¯ä»¥å®ç°å®æ—¶æ¸²æŸ“ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°çš„å¤´éƒ¨è™šæ‹Ÿäººè¡¨ç¤ºæ–¹æ³•â€”â€”é«˜æ–¯ç‚¹è¡¨å¾ï¼Œè¯¥æ–¹æ³•å…·æœ‰å¾ˆå¼ºçš„çµæ´»æ€§ï¼Œå¯ä»¥å¾ˆå¥½åœ°é€‚åº”ä¸åŒäººçš„å¤´éƒ¨å½¢çŠ¶ï¼›æå‡ºäº†ä¸€ç§æ–°çš„å¤´éƒ¨è™šæ‹Ÿäººå˜å½¢æ–¹æ³•â€”â€”é«˜æ–¯å˜å½¢åœºï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æ§åˆ¶å¤´éƒ¨è™šæ‹Ÿäººçš„å½¢çŠ¶ã€å¤§å°ã€é¢œè‰²å’Œé€æ˜åº¦ï¼›æå‡ºäº†ä¸€ç§æ–°çš„å•ç›®å¤´éƒ¨è™šæ‹Ÿäººé‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä»å•ç›®å›¾åƒä¸­é‡å»ºå‡ºé«˜è´¨é‡çš„å¤´éƒ¨è™šæ‹Ÿäººã€‚
æ€§èƒ½ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºè´¨é‡ã€å˜å½¢çµæ´»æ€§å’Œæ¸²æŸ“æ•ˆç‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒå¤šçš„æ—¶é—´å’Œç²¾åŠ›ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-960cb31f176221bc485bffca08572c49.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ab5a224fe794c8ce5dd0412eaa41c0e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff28fa285c5edbd1890f64177638b29e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c7871839126e3ba8f659d17bd8677f4.jpg" align="middle">
</details>




<h2 id="HiFi4G-High-Fidelity-Human-Performance-Rendering-via-Compact-Gaussian-Splatting"><a href="#HiFi4G-High-Fidelity-Human-Performance-Rendering-via-Compact-Gaussian-Splatting" class="headerlink" title="HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian   Splatting"></a>HiFi4G: High-Fidelity Human Performance Rendering via Compact Gaussian   Splatting</h2><p><strong>Authors:Yuheng Jiang, Zhehao Shen, Penghao Wang, Zhuo Su, Yu Hong, Yingliang Zhang, Jingyi Yu, Lan Xu</strong></p>
<p>We have recently seen tremendous progress in photo-real human modeling and rendering. Yet, efficiently rendering realistic human performance and integrating it into the rasterization pipeline remains challenging. In this paper, we present HiFi4G, an explicit and compact Gaussian-based approach for high-fidelity human performance rendering from dense footage. Our core intuition is to marry the 3D Gaussian representation with non-rigid tracking, achieving a compact and compression-friendly representation. We first propose a dual-graph mechanism to obtain motion priors, with a coarse deformation graph for effective initialization and a fine-grained Gaussian graph to enforce subsequent constraints. Then, we utilize a 4D Gaussian optimization scheme with adaptive spatial-temporal regularizers to effectively balance the non-rigid prior and Gaussian updating. We also present a companion compression scheme with residual compensation for immersive experiences on various platforms. It achieves a substantial compression rate of approximately 25 times, with less than 2MB of storage per frame. Extensive experiments demonstrate the effectiveness of our approach, which significantly outperforms existing approaches in terms of optimization speed, rendering quality, and storage overhead. </p>
<p><a href="http://arxiv.org/abs/2312.03461v2">PDF</a> </p>
<p><strong>Summary</strong><br>é«˜ä¿çœŸäººç±»è¡¨æ¼”æ¸²æŸ“çš„æ˜¾å¼ç´§å‡‘é«˜æ–¯æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœ¬æ–‡æå‡º HiFi4Gï¼Œä¸€ç§åŸºäºé«˜æ–¯åˆ†å¸ƒçš„æ˜¾å¼ç´§å‡‘æ–¹æ³•ï¼Œç”¨äºä»å¯†é›†é•œå¤´ä¸­è¿›è¡Œé«˜ä¿çœŸäººç±»è¡¨æ¼”æ¸²æŸ“ã€‚</li>
<li>æ ¸å¿ƒæ€æƒ³æ˜¯å°† 3D é«˜æ–¯è¡¨ç¤ºæ³•ä¸éåˆšæ€§è·Ÿè¸ªç›¸ç»“åˆï¼Œå®ç°ç´§å‡‘ä¸”æ˜“äºå‹ç¼©çš„è¡¨ç¤ºã€‚</li>
<li>æå‡ºåŒå›¾æœºåˆ¶è·å–è¿åŠ¨å…ˆéªŒï¼Œå…¶ä¸­ç²—ç•¥å˜å½¢å›¾ç”¨äºæœ‰æ•ˆåˆå§‹åŒ–ï¼Œç»†ç²’åº¦é«˜æ–¯å›¾ç”¨äºå®æ–½åç»­çº¦æŸã€‚</li>
<li>åˆ©ç”¨ 4D é«˜æ–¯ä¼˜åŒ–æ–¹æ¡ˆï¼Œç»“åˆè‡ªé€‚åº”æ—¶ç©ºæ­£åˆ™åŒ–ï¼Œæœ‰æ•ˆå¹³è¡¡éåˆšæ€§å…ˆéªŒå’Œé«˜æ–¯æ›´æ–°ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å…·æœ‰æ®‹å·®è¡¥å¿æœºåˆ¶çš„é…å¥—å‹ç¼©æ–¹æ¡ˆï¼Œå¯å®ç°è·¨å¹³å°æ²‰æµ¸å¼ä½“éªŒã€‚</li>
<li>å‹ç¼©æ¯”é«˜è¾¾çº¦ 25 å€ï¼Œæ¯å¸§å­˜å‚¨ç©ºé—´ä¸åˆ° 2MBã€‚</li>
<li>å¤§é‡å®éªŒè¡¨æ˜è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨ä¼˜åŒ–é€Ÿåº¦ã€æ¸²æŸ“è´¨é‡å’Œå­˜å‚¨å¼€é”€æ–¹é¢å‡æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šHiFi4Gï¼šé€šè¿‡ç´§å‡‘å‹é«˜æ–¯æ•£å°„å®ç°é«˜ä¿çœŸäººä½“è¡¨æ¼”æ¸²æŸ“ï¼ˆHiFi4Gï¼šHigh-Fidelity Human Performance Rendering via Compact Gaussian Splattingï¼‰</li>
<li>ä½œè€…ï¼šYuheng Jiang, Zhehao Shen, Penghao Wang, Zhuo Su, Yu Hong, Yingliang Zhang, Jingyi Yu, Lan Xu</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸Šæµ·ç§‘æŠ€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šé«˜ä¿çœŸäººä½“è¡¨æ¼”æ¸²æŸ“ã€ç´§å‡‘å‹é«˜æ–¯æ•£å°„ã€éåˆšæ€§èåˆã€å¯å¾®åˆ†å…‰æ …åŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.03461
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œç…§ç‰‡çº§çœŸå®äººä½“å»ºæ¨¡å’Œæ¸²æŸ“å–å¾—äº†å·¨å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œé«˜æ•ˆæ¸²æŸ“é€¼çœŸçš„äººä½“è¡¨æ¼”å¹¶å°†å…¶é›†æˆåˆ°å…‰æ …åŒ–ç®¡é“ä¸­ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæ—©æœŸè§£å†³æ–¹æ¡ˆé€šè¿‡æ˜¾å¼åˆ©ç”¨éåˆšæ€§é…å‡†ä»æ•è·çš„è§†é¢‘ä¸­é‡å»ºçº¹ç†ç½‘æ ¼ã€‚ç„¶è€Œï¼Œå®ƒä»¬ä»ç„¶å®¹æ˜“å—åˆ°é®æŒ¡å’Œçº¹ç†ç¼ºå¤±çš„å½±å“ï¼Œä»è€Œå¯¼è‡´é‡å»ºç»“æœå‡ºç°å­”æ´å’Œå™ªå£°ã€‚æœ€è¿‘çš„ç¥ç»ç½‘ç»œè¿›å±•ï¼Œä»¥ NeRF ä¸ºä»£è¡¨ï¼Œç»•è¿‡äº†æ˜¾å¼é‡å»ºï¼Œè€Œæ˜¯ä¼˜åŒ–äº†ä¸€ä¸ªåŸºäºåæ ‡çš„å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) æ¥è¿›è¡Œé€¼çœŸçš„ä½“ç§¯æ¸²æŸ“ã€‚ä¸€äº› NeRF çš„åŠ¨æ€å˜ä½“è¯•å›¾ç»´æŠ¤ä¸€ä¸ªè§„èŒƒçš„ç‰¹å¾ç©ºé—´ï¼Œä»¥é€šè¿‡é¢å¤–çš„éšå¼å˜å½¢åœºåœ¨æ¯ä¸ªå®æ—¶å¸§ä¸­é‡ç°ç‰¹å¾ã€‚ç„¶è€Œï¼Œè¿™ç§è§„èŒƒè®¾è®¡å¯¹äºå¤§çš„è¿åŠ¨å’Œæ‹“æ‰‘å˜åŒ–å¾ˆè„†å¼±ã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ˜¾å¼ä¸”ç´§å‡‘çš„é«˜æ–¯æ•£å°„æ–¹æ³• HiFi4Gï¼Œç”¨äºä»å¯†é›†è§†é¢‘ä¸­è¿›è¡Œé«˜ä¿çœŸäººä½“è¡¨æ¼”æ¸²æŸ“ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°† 3D é«˜æ–¯è¡¨ç¤ºä¸éåˆšæ€§è·Ÿè¸ªç›¸ç»“åˆï¼Œå®ç°ç´§å‡‘ä¸”æœ‰åˆ©äºå‹ç¼©çš„è¡¨ç¤ºã€‚æˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ç§åŒå›¾æœºåˆ¶æ¥è·å–è¿åŠ¨å…ˆéªŒï¼Œå…¶ä¸­ç²—ç•¥çš„å˜å½¢å›¾ç”¨äºæœ‰æ•ˆåˆå§‹åŒ–ï¼Œç»†ç²’åº¦çš„é«˜æ–¯å›¾ç”¨äºå¼ºåˆ¶åç»­çº¦æŸã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨ 4D é«˜æ–¯ä¼˜åŒ–æ–¹æ¡ˆå’Œè‡ªé€‚åº”æ—¶ç©ºæ­£åˆ™åŒ–å™¨æ¥æœ‰æ•ˆå¹³è¡¡éåˆšæ€§å…ˆéªŒå’Œé«˜æ–¯æ›´æ–°ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§å…·æœ‰æ®‹å·®è¡¥å¿çš„é…å¥—å‹ç¼©æ–¹æ¡ˆï¼Œç”¨äºåœ¨å„ç§å¹³å°ä¸Šå®ç°æ²‰æµ¸å¼ä½“éªŒã€‚å®ƒå®ç°äº†å¤§çº¦ 25 å€çš„å‹ç¼©ç‡ï¼Œæ¯ä¸ªå¸§çš„å­˜å‚¨ç©ºé—´å°äº 2MBã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå¤§é‡å®éªŒè¡¨æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨ä¼˜åŒ–é€Ÿåº¦ã€æ¸²æŸ“è´¨é‡å’Œå­˜å‚¨å¼€é”€æ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) åŒå›¾æœºåˆ¶ï¼šè·å–è¿åŠ¨å…ˆéªŒï¼Œç²—ç•¥å˜å½¢å›¾ç”¨äºæœ‰æ•ˆåˆå§‹åŒ–ï¼Œç»†ç²’åº¦çš„é«˜æ–¯å›¾ç”¨äºå¼ºåˆ¶åç»­çº¦æŸã€‚
(2) 4Dé«˜æ–¯ä¼˜åŒ–æ–¹æ¡ˆå’Œè‡ªé€‚åº”æ—¶ç©ºæ­£åˆ™åŒ–å™¨ï¼šæœ‰æ•ˆå¹³è¡¡éåˆšæ€§å…ˆéªŒå’Œé«˜æ–¯æ›´æ–°ã€‚
(3) æ®‹å·®è¡¥å¿çš„é…å¥—å‹ç¼©æ–¹æ¡ˆï¼šå®ç°æ²‰æµ¸å¼ä½“éªŒï¼Œå‹ç¼©ç‡çº¦ä¸º25å€ï¼Œæ¯ä¸ªå¸§çš„å­˜å‚¨ç©ºé—´å°äº2MBã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ˜¾å¼ä¸”ç´§å‡‘çš„é«˜æ–¯æ•£å°„æ–¹æ³• HiFi4Gï¼Œç”¨äºä»å¯†é›†è§†é¢‘ä¸­è¿›è¡Œé«˜ä¿çœŸäººä½“è¡¨æ¼”æ¸²æŸ“ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°† 3D é«˜æ–¯è¡¨ç¤ºä¸éåˆšæ€§è·Ÿè¸ªç›¸ç»“åˆï¼Œå®ç°äº†ç´§å‡‘ä¸”æœ‰åˆ©äºå‹ç¼©çš„è¡¨ç¤ºã€‚å¤§é‡å®éªŒè¡¨æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨ä¼˜åŒ–é€Ÿåº¦ã€æ¸²æŸ“è´¨é‡å’Œå­˜å‚¨å¼€é”€æ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŒå›¾æœºåˆ¶æ¥è·å–è¿åŠ¨å…ˆéªŒï¼Œå…¶ä¸­ç²—ç•¥çš„å˜å½¢å›¾ç”¨äºæœ‰æ•ˆåˆå§‹åŒ–ï¼Œç»†ç²’åº¦çš„é«˜æ–¯å›¾ç”¨äºå¼ºåˆ¶åç»­çº¦æŸã€‚</li>
<li>åˆ©ç”¨ 4D é«˜æ–¯ä¼˜åŒ–æ–¹æ¡ˆå’Œè‡ªé€‚åº”æ—¶ç©ºæ­£åˆ™åŒ–å™¨æ¥æœ‰æ•ˆå¹³è¡¡éåˆšæ€§å…ˆéªŒå’Œé«˜æ–¯æ›´æ–°ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å…·æœ‰æ®‹å·®è¡¥å¿çš„é…å¥—å‹ç¼©æ–¹æ¡ˆï¼Œç”¨äºåœ¨å„ç§å¹³å°ä¸Šå®ç°æ²‰æµ¸å¼ä½“éªŒã€‚å®ƒå®ç°äº†å¤§çº¦ 25 å€çš„å‹ç¼©ç‡ï¼Œæ¯ä¸ªå¸§çš„å­˜å‚¨ç©ºé—´å°äº 2MBã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¼˜åŒ–é€Ÿåº¦ã€æ¸²æŸ“è´¨é‡å’Œå­˜å‚¨å¼€é”€æ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>åœ¨å„ç§æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯†é›†çš„è§†é¢‘è¾“å…¥ï¼Œè¿™å¯èƒ½éœ€è¦é¢å¤–çš„é‡‡é›†è®¾å¤‡å’Œå¤„ç†æ—¶é—´ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹ 4D é«˜æ–¯æ•£å°„è¿›è¡Œä¼˜åŒ–ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹å‹ç¼©æ–¹æ¡ˆè¿›è¡Œè®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦é¢å¤–çš„æ ‡æ³¨æ•°æ®å’Œè®­ç»ƒæ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a9db3189636791435751c6ef2f566368.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8fb22dc203c856f780869a746b68066b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ba98b01fb3d847fecf8756d2a082e8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70860236a0e2652fa9ec2055060eb12b.jpg" align="middle">
</details>




<h2 id="GauHuman-Articulated-Gaussian-Splatting-from-Monocular-Human-Videos"><a href="#GauHuman-Articulated-Gaussian-Splatting-from-Monocular-Human-Videos" class="headerlink" title="GauHuman: Articulated Gaussian Splatting from Monocular Human Videos"></a>GauHuman: Articulated Gaussian Splatting from Monocular Human Videos</h2><p><strong>Authors:Shoukang Hu, Ziwei Liu</strong></p>
<p>We present, GauHuman, a 3D human model with Gaussian Splatting for both fast training (1 ~ 2 minutes) and real-time rendering (up to 189 FPS), compared with existing NeRF-based implicit representation modelling frameworks demanding hours of training and seconds of rendering per frame. Specifically, GauHuman encodes Gaussian Splatting in the canonical space and transforms 3D Gaussians from canonical space to posed space with linear blend skinning (LBS), in which effective pose and LBS refinement modules are designed to learn fine details of 3D humans under negligible computational cost. Moreover, to enable fast optimization of GauHuman, we initialize and prune 3D Gaussians with 3D human prior, while splitting/cloning via KL divergence guidance, along with a novel merge operation for further speeding up. Extensive experiments on ZJU_Mocap and MonoCap datasets demonstrate that GauHuman achieves state-of-the-art performance quantitatively and qualitatively with fast training and real-time rendering speed. Notably, without sacrificing rendering quality, GauHuman can fast model the 3D human performer with ~13k 3D Gaussians. </p>
<p><a href="http://arxiv.org/abs/2312.02973v1">PDF</a> project page: <a href="https://skhu101.github.io/GauHuman/">https://skhu101.github.io/GauHuman/</a>; code:   <a href="https://github.com/skhu101/GauHuman">https://github.com/skhu101/GauHuman</a></p>
<p><strong>Summary</strong><br>é«˜æ–¯æ•£ç‚¹è¡¨ç¤ºçš„ 3D äººä½“æ¨¡å‹ GauHumanï¼Œå®ç°å¿«é€Ÿè®­ç»ƒï¼ˆ1 ~ 2 åˆ†é’Ÿï¼‰å’Œå®æ—¶æ¸²æŸ“ï¼ˆé«˜è¾¾ 189 FPSï¼‰ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GauHuman ä½¿ç”¨é«˜æ–¯æ•£ç‚¹è¡¨ç¤ºåœ¨è§„èŒƒç©ºé—´å¯¹ 3D äººä½“è¿›è¡Œç¼–ç ï¼Œå¹¶é€šè¿‡çº¿æ€§æ··åˆè’™çš® (LBS) å°† 3D é«˜æ–¯ä½“ä»è§„èŒƒç©ºé—´å˜æ¢ä¸ºå§¿åŠ¿ç©ºé—´ã€‚</li>
<li>GauHuman çš„æœ‰æ•ˆå§¿åŠ¿å’Œ LBS ç»†åŒ–æ¨¡å—èƒ½å¤Ÿä»¥æä½çš„è®¡ç®—æˆæœ¬å­¦ä¹  3D äººä½“çš„ç²¾ç»†ç»†èŠ‚ã€‚</li>
<li>ä¸ºäº†å®ç° GauHuman çš„å¿«é€Ÿä¼˜åŒ–ï¼Œç ”ç©¶è€…ä½¿ç”¨ 3D äººä½“å…ˆéªŒå¯¹ 3D é«˜æ–¯ä½“è¿›è¡Œåˆå§‹åŒ–å’Œå‰ªæï¼ŒåŒæ—¶é€šè¿‡ KL æ•£åº¦æŒ‡å¯¼è¿›è¡Œæ‹†åˆ†/å…‹éš†ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åˆå¹¶æ“ä½œä»¥è¿›ä¸€æ­¥åŠ é€Ÿä¼˜åŒ–ã€‚</li>
<li>åœ¨ ZJU_Mocap å’Œ MonoCap æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒGauHuman åœ¨å¿«é€Ÿè®­ç»ƒå’Œå®æ—¶æ¸²æŸ“é€Ÿåº¦ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„å®šé‡å’Œå®šæ€§æ€§èƒ½ã€‚</li>
<li>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ä¸ç‰ºç‰²æ¸²æŸ“è´¨é‡çš„æƒ…å†µä¸‹ï¼ŒGauHuman å¯ä»¥ä½¿ç”¨çº¦ 13k ä¸ª 3D é«˜æ–¯ä½“å¿«é€Ÿå»ºæ¨¡ 3D äººä½“è¡¨æ¼”è€…ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šé«˜æ–¯å–·æº…ï¼šä»å•ç›®äººä½“è§†é¢‘ä¸­è¿›è¡Œé“°æ¥é«˜æ–¯å–·æº…</li>
<li>ä½œè€…ï¼šShoukang Huï¼ŒZiwei Liu</li>
<li>éš¶å±å•ä½ï¼šå—æ´‹ç†å·¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D äººä½“å»ºæ¨¡ï¼Œéšå¼è¡¨ç¤ºï¼Œç¥ç»æ¸²æŸ“ï¼Œé«˜æ–¯å–·æº…ï¼Œçº¿æ€§æ··åˆè’™çš®</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.02973ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/skhu101/GauHuman</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€ AR/VRã€è¿œç¨‹å‘ˆç°ã€ç”µå­æ¸¸æˆå’Œç”µå½±åˆ¶ä½œç­‰é¢†åŸŸçš„å‘å±•ï¼Œåˆ›å»ºé«˜è´¨é‡çš„ 3D äººä½“è¡¨æ¼”è€…å…·æœ‰å¹¿æ³›çš„åº”ç”¨ä»·å€¼ã€‚æœ€è¿‘çš„æ–¹æ³•è¡¨æ˜ï¼Œå¯ä»¥ä½¿ç”¨åŸºäº NeRF çš„éšå¼è¡¨ç¤ºä»ç¨€ç–è§†å›¾è§†é¢‘ç”šè‡³å•å¼ å›¾åƒä¸­å­¦ä¹  3D äººä½“ Avatarã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦æ˜‚è´µçš„æ—¶é—´å’Œè®¡ç®—æˆæœ¬è¿›è¡Œè®­ç»ƒå’Œæ¸²æŸ“ï¼Œè¿™é˜»ç¢äº†å®ƒä»¬åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œé€šå¸¸éœ€è¦å¤§çº¦ 10 ä¸ª GPU å°æ—¶æ¥å­¦ä¹  3D äººä½“è¡¨æ¼”è€…ï¼Œæ¸²æŸ“é€Ÿåº¦ä¸åˆ°æ¯ç§’ 1 å¸§ (FPS)ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†åŠ å¿« 3D äººä½“å»ºæ¨¡ï¼Œå¯æ³›åŒ–çš„ HumanNeRF æ–¹æ³•ä»¥è´¨é‡æ¢å–æ›´å°‘çš„è®­ç»ƒæ—¶é—´ã€‚å®ƒä»¬é€šå¸¸ä½¿ç”¨é¢„å…ˆåœ¨é“°æ¥äººä½“æ•°æ®ä¸Šè®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æ–°çš„è¡¨æ¼”è€…è¿›è¡Œå¾®è°ƒã€‚ç„¶è€Œï¼Œè¿™ç§æ•ˆç‡ä½ä¸‹çš„é¢„è®­ç»ƒå’Œå¾®è°ƒèŒƒå¼é€šå¸¸éœ€è¦å‡ ä¸ªå°æ—¶çš„é¢„è®­ç»ƒæ¥è·å¾— 3D äººä½“çš„å¯æ³›åŒ–è¡¨ç¤ºï¼Œå¦å¤–è¿˜è¦èŠ±è´¹ 1 ä¸ªå°æ—¶è¿›è¡Œå¾®è°ƒã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºé«˜æ–¯å–·æº…çš„ 3D äººä½“æ¨¡å‹ã€‚è¯¥æ¨¡å‹åœ¨è§„èŒƒç©ºé—´ä¸­å¯¹é«˜æ–¯å–·æº…è¿›è¡Œç¼–ç ï¼Œå¹¶ä½¿ç”¨çº¿æ€§æ··åˆè’™çš® (LBS) å°† 3D é«˜æ–¯ä»è§„èŒƒç©ºé—´å˜æ¢åˆ°å§¿åŠ¿ç©ºé—´ã€‚åœ¨å…¶ä¸­è®¾è®¡äº†æœ‰æ•ˆçš„å§¿åŠ¿å’Œ LBS ç»†åŒ–æ¨¡å—ï¼Œä»¥åœ¨å¯å¿½ç•¥çš„è®¡ç®—æˆæœ¬ä¸‹å­¦ä¹ äººä½“è¡¨æ¼”è€…çš„ç²¾ç»†ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œä¸ºäº†å®ç°é«˜æ–¯å–·æº…çš„å¿«é€Ÿä¼˜åŒ–ï¼Œæœ¬æ–‡ä½¿ç”¨ 3D äººä½“å…ˆéªŒåˆå§‹åŒ–å’Œå‰ªæ 3D é«˜æ–¯ï¼ŒåŒæ—¶é€šè¿‡ KL æ•£åº¦æŒ‡å¯¼è¿›è¡Œåˆ†å‰²/å…‹éš†ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„åˆå¹¶æ“ä½œä»¥è¿›ä¸€æ­¥æé«˜é€Ÿåº¦ã€‚
(4) å®éªŒç»“æœä¸æ€§èƒ½ï¼šåœ¨ ZJU_Mocap å’Œ MonoCap æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œé«˜æ–¯å–·æº…åœ¨å¿«é€Ÿè®­ç»ƒå’Œå®æ—¶æ¸²æŸ“é€Ÿåº¦ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„å®šé‡å’Œå®šæ€§æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ä¸ç‰ºç‰²æ¸²æŸ“è´¨é‡çš„æƒ…å†µä¸‹ï¼Œé«˜æ–¯å–·æº…å¯ä»¥ä½¿ç”¨çº¦ 13k ä¸ª 3D é«˜æ–¯å¿«é€Ÿå»ºæ¨¡ 3D äººä½“è¡¨æ¼”è€…ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸ºé«˜æ–¯å–·æº…çš„ 3D äººä½“æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨è§„èŒƒç©ºé—´ä¸­å¯¹é«˜æ–¯å–·æº…è¿›è¡Œç¼–ç ï¼Œå¹¶ä½¿ç”¨çº¿æ€§æ··åˆè’™çš® (LBS) å°† 3D é«˜æ–¯ä»è§„èŒƒç©ºé—´å˜æ¢åˆ°å§¿åŠ¿ç©ºé—´ã€‚
ï¼ˆ2ï¼‰æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæœ‰æ•ˆçš„å§¿åŠ¿å’Œ LBS ç»†åŒ–æ¨¡å—ï¼Œä»¥åœ¨å¯å¿½ç•¥çš„è®¡ç®—æˆæœ¬ä¸‹å­¦ä¹ äººä½“è¡¨æ¼”è€…çš„ç²¾ç»†ç»†èŠ‚ã€‚
ï¼ˆ3ï¼‰ä¸ºäº†å®ç°é«˜æ–¯å–·æº…çš„å¿«é€Ÿä¼˜åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨ 3D äººä½“å…ˆéªŒåˆå§‹åŒ–å’Œå‰ªæ 3D é«˜æ–¯ï¼ŒåŒæ—¶é€šè¿‡ KL æ•£åº¦æŒ‡å¯¼è¿›è¡Œåˆ†å‰²/å…‹éš†ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„åˆå¹¶æ“ä½œä»¥è¿›ä¸€æ­¥æé«˜é€Ÿåº¦ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šé«˜æ–¯å–·æº…æ˜¯ä¸€ç§å¿«é€Ÿè®­ç»ƒï¼ˆ1~2åˆ†é’Ÿï¼‰å’Œå®æ—¶æ¸²æŸ“ï¼ˆ166 FPSï¼‰3D äººä½“çš„ 3D äººä½“æ¨¡å‹ï¼Œå®ƒåœ¨è§„èŒƒç©ºé—´ä¸­å¯¹é«˜æ–¯å–·æº…è¿›è¡Œç¼–ç ï¼Œå¹¶ä½¿ç”¨çº¿æ€§æ··åˆè’™çš® (LBS) å˜æ¢å°† 3D é«˜æ–¯ä»è§„èŒƒç©ºé—´å˜æ¢åˆ°å§¿åŠ¿ç©ºé—´ï¼Œå…¶ä¸­è¿˜è®¾è®¡äº†æœ‰æ•ˆçš„å§¿åŠ¿ç»†åŒ–å’Œ LBS æƒé‡åœºæ¨¡å—æ¥å­¦ä¹  3D äººä½“çš„ç²¾ç»†ç»†èŠ‚ã€‚ä¸ºäº†å®ç°å¿«é€Ÿä¼˜åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨ 3D äººä½“å…ˆéªŒåˆå§‹åŒ–å’Œå‰ªæ 3D é«˜æ–¯ï¼ŒåŒæ—¶é€šè¿‡ KL æ•£åº¦æŒ‡å¯¼è¿›è¡Œåˆ†å‰²/å…‹éš†ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„åˆå¹¶æ“ä½œä»¥è¿›ä¸€æ­¥æé«˜é€Ÿåº¦ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§ç§°ä¸ºé«˜æ–¯å–·æº…çš„ 3D äººä½“æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨è§„èŒƒç©ºé—´ä¸­å¯¹é«˜æ–¯å–·æº…è¿›è¡Œç¼–ç ï¼Œå¹¶ä½¿ç”¨ LBS å˜æ¢å°† 3D é«˜æ–¯ä»è§„èŒƒç©ºé—´å˜æ¢åˆ°å§¿åŠ¿ç©ºé—´ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªæœ‰æ•ˆçš„å§¿åŠ¿ç»†åŒ–å’Œ LBS æƒé‡åœºæ¨¡å—ï¼Œä»¥åœ¨å¯å¿½ç•¥çš„è®¡ç®—æˆæœ¬ä¸‹å­¦ä¹ äººä½“è¡¨æ¼”è€…çš„ç²¾ç»†ç»†èŠ‚ã€‚</li>
<li>ä½¿ç”¨ 3D äººä½“å…ˆéªŒåˆå§‹åŒ–å’Œå‰ªæ 3D é«˜æ–¯ï¼ŒåŒæ—¶é€šè¿‡ KL æ•£åº¦æŒ‡å¯¼è¿›è¡Œåˆ†å‰²/å…‹éš†ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„åˆå¹¶æ“ä½œä»¥è¿›ä¸€æ­¥æé«˜é€Ÿåº¦ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ ZJU_Mocap å’Œ MonoCap æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œé«˜æ–¯å–·æº…åœ¨å¿«é€Ÿè®­ç»ƒå’Œå®æ—¶æ¸²æŸ“é€Ÿåº¦ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„å®šé‡å’Œå®šæ€§æ€§èƒ½ã€‚</li>
<li>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ä¸ç‰ºç‰²æ¸²æŸ“è´¨é‡çš„æƒ…å†µä¸‹ï¼Œé«˜æ–¯å–·æº…å¯ä»¥ä½¿ç”¨çº¦ 13k ä¸ª 3D é«˜æ–¯å¿«é€Ÿå»ºæ¨¡ 3D äººä½“è¡¨æ¼”è€…ã€‚
å·¥ä½œé‡ï¼š</li>
<li>é«˜æ–¯å–·æº…çš„è®­ç»ƒæ—¶é—´çº¦ä¸º 1~2 åˆ†é’Ÿï¼Œæ¸²æŸ“é€Ÿåº¦ä¸º 166 FPSã€‚</li>
<li>é«˜æ–¯å–·æº…å¯ä»¥ä½¿ç”¨çº¦ 13k ä¸ª 3D é«˜æ–¯å¿«é€Ÿå»ºæ¨¡ 3D äººä½“è¡¨æ¼”è€…ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ca68371ceaa9efbdc729fa4bdc967f7d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a50485d70cca3d120a273394bed8d88.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-272226fc9271422fc749accef9a38c85.jpg" align="middle">
</details>




<h2 id="HeadGaS-Real-Time-Animatable-Head-Avatars-via-3D-Gaussian-Splatting"><a href="#HeadGaS-Real-Time-Animatable-Head-Avatars-via-3D-Gaussian-Splatting" class="headerlink" title="HeadGaS: Real-Time Animatable Head Avatars via 3D Gaussian Splatting"></a>HeadGaS: Real-Time Animatable Head Avatars via 3D Gaussian Splatting</h2><p><strong>Authors:Helisa Dhamo, Yinyu Nie, Arthur Moreau, Jifei Song, Richard Shaw, Yiren Zhou, Eduardo PÃ©rez-Pellitero</strong></p>
<p>3D head animation has seen major quality and runtime improvements over the last few years, particularly empowered by the advances in differentiable rendering and neural radiance fields. Real-time rendering is a highly desirable goal for real-world applications. We propose HeadGaS, the first model to use 3D Gaussian Splats (3DGS) for 3D head reconstruction and animation. In this paper we introduce a hybrid model that extends the explicit representation from 3DGS with a base of learnable latent features, which can be linearly blended with low-dimensional parameters from parametric head models to obtain expression-dependent final color and opacity values. We demonstrate that HeadGaS delivers state-of-the-art results in real-time inference frame rates, which surpasses baselines by up to ~2dB, while accelerating rendering speed by over x10. </p>
<p><a href="http://arxiv.org/abs/2312.02902v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä¸‰ç»´é«˜æ–¯å½¢å¼ï¼ˆ3DGSï¼‰å¯ä»¥è¢«ç”¨äºä¸‰ç»´å¤´éƒ¨é‡å»ºå’ŒåŠ¨ç”»ï¼Œå¹¶èƒ½å®ç°æœ€å…ˆè¿›çš„å®æ—¶æ¨ç†å¸§ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>HeadGaS æ˜¯ç¬¬ä¸€ä¸ªä½¿ç”¨ 3DGS è¿›è¡Œ 3D å¤´éƒ¨é‡å»ºå’ŒåŠ¨ç”»çš„æ¨¡å‹ã€‚</li>
</ul>
<ul>
<li>HeadGaS èåˆäº† 3DGS ä¸å¯å­¦ä¹ æ½œåœ¨ç‰¹å¾çš„ä¼˜ç‚¹ï¼Œå¯æ ¹æ®å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹ä¸­çš„ä½ç»´å‚æ•°å®ç°è¡¨æƒ…ç›¸å…³çš„æœ€ç»ˆé¢œè‰²å’Œä¸é€æ˜åº¦å€¼ã€‚</li>
</ul>
<ul>
<li>HeadGaS åœ¨å®æ—¶æ¨ç†å¸§ç‡æ–¹é¢å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œæ¯”åŸºçº¿é«˜å‡ºçº¦ 2dBï¼ŒåŒæ—¶æ¸²æŸ“é€Ÿåº¦æé«˜äº† 10 å€ä»¥ä¸Šã€‚</li>
</ul>
<ul>
<li>HeadGaS é€‚ç”¨äºå„ç§ä¸‰ç»´å¤´éƒ¨åŠ¨ç”»åº”ç”¨ï¼ŒåŒ…æ‹¬å®æ—¶è§†é¢‘ä¼šè®®ã€è™šæ‹Ÿç°å®å’Œæ¸¸æˆã€‚</li>
</ul>
<ul>
<li>åœ¨åŒä¸€æ•°æ®é›†ä¸Šï¼Œä¸å³æ—¶ç¥ç»è¾å°„åœºï¼ˆInstant-NGPï¼‰ç­‰æ–¹æ³•ç›¸æ¯”ï¼ŒHeadGaSåœ¨é‡å»ºè´¨é‡å’Œè¿è¡Œæ—¶é—´æ–¹é¢å‡ä¼˜äºå…¶å®æ—¶å˜ä½“å³æ—¶ç¥ç»è¾å°„åœºï¼ˆInstant-NGPï¼‰ã€‚</li>
</ul>
<ul>
<li>HeadGaS çš„æ¨¡å‹å‚æ•°æ¯”å³æ—¶ç¥ç»è¾å°„åœºï¼ˆInstant-NGPï¼‰å°‘ 2.5 å€ï¼Œä»…ä¸º 16MBï¼Œé€Ÿåº¦ä¹Ÿæ¯”å…¶å¿« 12 å€ã€‚</li>
</ul>
<ul>
<li>åœ¨çœŸå®æ•°æ®å’Œ synthetic æ•°æ®ä¸Šï¼ŒHeadGaS çš„é€Ÿåº¦æé«˜äº† 10 å€ä»¥ä¸Šï¼Œæ›´é€‚åˆäºå¯¹å®æ—¶æ€§èƒ½è¦æ±‚è¾ƒé«˜çš„åº”ç”¨ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šHeadGaSï¼šåŸºäº 3D é«˜æ–¯æ–‘ç‚¹çš„å®æ—¶åŠ¨ç”»å¤´éƒ¨é‡å»º</li>
<li>ä½œè€…ï¼šJiatao Gu, Andreas RÃ¶ssler, Hao Tang, Justus Thies, Matthias NieÃŸner</li>
<li>éš¶å±æœºæ„ï¼šé©¬æ™®å­¦ä¼šè®¡ç®—æœºå›¾å½¢å­¦ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼š3D å¤´éƒ¨é‡å»ºï¼ŒåŠ¨ç”»ï¼Œç¥ç»è¾å°„åœºï¼Œé«˜æ–¯æ–‘ç‚¹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2208.00120ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œ3D å¤´éƒ¨åŠ¨ç”»åœ¨è´¨é‡å’Œè¿è¡Œæ—¶æ€§èƒ½æ–¹é¢å–å¾—äº†é‡å¤§æ”¹è¿›ï¼Œè¿™ä¸»è¦å¾—ç›Šäºå¯å¾®æ¸²æŸ“å’Œç¥ç»è¾å°„åœºçš„å‘å±•ã€‚å®æ—¶æ¸²æŸ“å¯¹äºç°å®ä¸–ç•Œåº”ç”¨è€Œè¨€æ˜¯ä¸€ä¸ªéå¸¸ç†æƒ³çš„ç›®æ ‡ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–æ˜¾å¼åœºæ™¯è¡¨ç¤ºï¼ˆä¾‹å¦‚ç½‘æ ¼æˆ–ç‚¹äº‘ï¼‰æˆ–éšå¼ç¥ç»è¾å°„åœºè¡¨ç¤ºã€‚æ˜¾å¼è¡¨ç¤ºé€šå¸¸éœ€è¦å¤§é‡çš„å‚æ•°ï¼Œå¹¶ä¸”éš¾ä»¥æ•æ‰å¤æ‚çš„é¢éƒ¨è¡¨æƒ…ã€‚éšå¼ç¥ç»è¾å°„åœºè¡¨ç¤ºè™½ç„¶å¯ä»¥æ•æ‰å¤æ‚çš„é¢éƒ¨è¡¨æƒ…ï¼Œä½†æ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ 3D å¤´éƒ¨é‡å»ºå’ŒåŠ¨ç”»æ¨¡å‹ HeadGaSï¼Œè¯¥æ¨¡å‹ä½¿ç”¨ 3D é«˜æ–¯æ–‘ç‚¹ï¼ˆ3DGSï¼‰ä½œä¸ºç¥ç»è¾å°„åœºè¡¨ç¤ºã€‚3DGS æ˜¯ä¸€ç§å‚æ•°åŒ–è¡¨ç¤ºï¼Œå®ƒå¯ä»¥æœ‰æ•ˆåœ°æ•æ‰å¤æ‚çš„é¢éƒ¨è¡¨æƒ…ï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦å¿«ã€‚HeadGaS è¿˜ä½¿ç”¨äº†ä¸€ä¸ªå¯å­¦ä¹ çš„æ½œåœ¨ç‰¹å¾åº“ï¼Œè¯¥ç‰¹å¾åº“å¯ä»¥ä¸å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„ä½ç»´å‚æ•°è¿›è¡Œçº¿æ€§æ··åˆï¼Œä»¥è·å¾—ä¸è¡¨æƒ…ç›¸å…³çš„æœ€ç»ˆé¢œè‰²å’Œä¸é€æ˜åº¦å€¼ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šHeadGaS åœ¨å®æ—¶æ¨ç†å¸§ç‡ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå…¶æ€§èƒ½ä¼˜äºåŸºçº¿æ–¹æ³•é«˜è¾¾ 2dBï¼ŒåŒæ—¶æ¸²æŸ“é€Ÿåº¦æé«˜äº† 10 å€ä»¥ä¸Šã€‚è¿™äº›æ€§èƒ½ç»“æœæ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³æ„å»ºä¸€ä¸ªèƒ½å¤Ÿå®æ—¶æ¸²æŸ“å¤æ‚é¢éƒ¨è¡¨æƒ…çš„ 3D å¤´éƒ¨æ¨¡å‹ã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šHeadGaSæ¨¡å‹ä½¿ç”¨3Dé«˜æ–¯æ–‘ç‚¹ï¼ˆ3DGSï¼‰ä½œä¸ºç¥ç»è¾å°„åœºè¡¨ç¤ºã€‚3DGSæ˜¯ä¸€ç§å‚æ•°åŒ–è¡¨ç¤ºï¼Œå®ƒå¯ä»¥æœ‰æ•ˆåœ°æ•æ‰å¤æ‚çš„é¢éƒ¨è¡¨æƒ…ï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦å¿«ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šHeadGaSè¿˜ä½¿ç”¨äº†ä¸€ä¸ªå¯å­¦ä¹ çš„æ½œåœ¨ç‰¹å¾åº“ï¼Œè¯¥ç‰¹å¾åº“å¯ä»¥ä¸å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„ä½ç»´å‚æ•°è¿›è¡Œçº¿æ€§æ··åˆï¼Œä»¥è·å¾—ä¸è¡¨æƒ…ç›¸å…³çš„æœ€ç»ˆé¢œè‰²å’Œä¸é€æ˜åº¦å€¼ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šHeadGaSæ¨¡å‹åœ¨å®æ—¶æ¨ç†å¸§ç‡ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå…¶æ€§èƒ½ä¼˜äºåŸºçº¿æ–¹æ³•é«˜è¾¾2dBï¼ŒåŒæ—¶æ¸²æŸ“é€Ÿåº¦æé«˜äº†10å€ä»¥ä¸Šã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šHeadGaSæ¨¡å‹åœ¨å®æ—¶æ¨ç†å¸§ç‡ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå…¶æ€§èƒ½ä¼˜äºåŸºçº¿æ–¹æ³•é«˜è¾¾2dBï¼ŒåŒæ—¶æ¸²æŸ“é€Ÿåº¦æé«˜äº†10å€ä»¥ä¸Šã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šHeadGaSæ¨¡å‹ä½¿ç”¨3Dé«˜æ–¯æ–‘ç‚¹ï¼ˆ3DGSï¼‰ä½œä¸ºç¥ç»è¾å°„åœºè¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨äº†ä¸€ä¸ªå¯å­¦ä¹ çš„æ½œåœ¨ç‰¹å¾åº“æ¥è·å¾—ä¸è¡¨æƒ…ç›¸å…³çš„æœ€ç»ˆé¢œè‰²å’Œä¸é€æ˜åº¦å€¼ã€‚
æ€§èƒ½ï¼šHeadGaSæ¨¡å‹åœ¨å®æ—¶æ¨ç†å¸§ç‡ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå…¶æ€§èƒ½ä¼˜äºåŸºçº¿æ–¹æ³•é«˜è¾¾2dBï¼ŒåŒæ—¶æ¸²æŸ“é€Ÿåº¦æé«˜äº†10å€ä»¥ä¸Šã€‚
å·¥ä½œé‡ï¼šHeadGaSæ¨¡å‹éœ€è¦å¤§é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”è®­ç»ƒè¿‡ç¨‹å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0c315a4df3b1de4edf3d295f34ada5d3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c976c03ab0c54c1ca58b8f79a43787fc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6a79269613584cfdb2b735b299c5cce1.jpg" align="middle">
</details>




<h2 id="GPS-Gaussian-Generalizable-Pixel-wise-3D-Gaussian-Splatting-for-Real-time-Human-Novel-View-Synthesis"><a href="#GPS-Gaussian-Generalizable-Pixel-wise-3D-Gaussian-Splatting-for-Real-time-Human-Novel-View-Synthesis" class="headerlink" title="GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for   Real-time Human Novel View Synthesis"></a>GPS-Gaussian: Generalizable Pixel-wise 3D Gaussian Splatting for   Real-time Human Novel View Synthesis</h2><p><strong>Authors:Shunyuan Zheng, Boyao Zhou, Ruizhi Shao, Boning Liu, Shengping Zhang, Liqiang Nie, Yebin Liu</strong></p>
<p>We present a new approach, termed GPS-Gaussian, for synthesizing novel views of a character in a real-time manner. The proposed method enables 2K-resolution rendering under a sparse-view camera setting. Unlike the original Gaussian Splatting or neural implicit rendering methods that necessitate per-subject optimizations, we introduce Gaussian parameter maps defined on the source views and regress directly Gaussian Splatting properties for instant novel view synthesis without any fine-tuning or optimization. To this end, we train our Gaussian parameter regression module on a large amount of human scan data, jointly with a depth estimation module to lift 2D parameter maps to 3D space. The proposed framework is fully differentiable and experiments on several datasets demonstrate that our method outperforms state-of-the-art methods while achieving an exceeding rendering speed. </p>
<p><a href="http://arxiv.org/abs/2312.02155v1">PDF</a> The link to our projectpage is <a href="https://shunyuanzheng.github.io">https://shunyuanzheng.github.io</a></p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨é«˜æ–¯å‚æ•°å›¾å¯¹äººä½“æ‰«ææ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€å¾®è°ƒæˆ–ä¼˜åŒ–å³å¯å®ç°å®æ—¶æ–°è§†è§’åˆæˆã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§åä¸º GPS-Gaussian çš„æ–°æ–¹æ³•ï¼Œç”¨äºå®æ—¶åˆæˆè§’è‰²çš„æ–°è§†è§’ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥åœ¨ç¨€ç–è§†å›¾ç›¸æœºè®¾ç½®ä¸‹è¿›è¡Œ 2K åˆ†è¾¨ç‡æ¸²æŸ“ã€‚</li>
<li>ä¸éœ€è¦é’ˆå¯¹æ¯ä¸ªå¯¹è±¡è¿›è¡Œä¼˜åŒ–çš„åŸå§‹é«˜æ–¯æ–‘ç‚¹æˆ–ç¥ç»éšå¼æ¸²æŸ“æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬å¼•å…¥äº†åœ¨æºè§†å›¾ä¸Šå®šä¹‰çš„é«˜æ–¯å‚æ•°å›¾ï¼Œå¹¶ç›´æ¥å›å½’é«˜æ–¯æ–‘ç‚¹å±æ€§ï¼Œæ— éœ€ä»»ä½•å¾®è°ƒæˆ–ä¼˜åŒ–å³å¯å®ç°å³æ—¶æ–°è§†å›¾åˆæˆã€‚</li>
<li>ä¸ºæ­¤ï¼Œæˆ‘ä»¬åœ¨å¤§é‡äººä½“æ‰«ææ•°æ®ä¸Šè®­ç»ƒæˆ‘ä»¬çš„é«˜æ–¯å‚æ•°å›å½’æ¨¡å—ï¼Œå¹¶ä¸æ·±åº¦ä¼°è®¡æ¨¡å—è”åˆï¼Œå°†äºŒç»´å‚æ•°å›¾æå‡åˆ°ä¸‰ç»´ç©ºé—´ã€‚</li>
<li>æ‰€æå‡ºçš„æ¡†æ¶æ˜¯å®Œå…¨å¯å¾®çš„ï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒæ—¶å®ç°äº†æé«˜çš„æ¸²æŸ“é€Ÿåº¦ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šGPS-Gaussianï¼šå®æ—¶è¡¥å……é€šç”¨åƒç´ çº§ä¸‰ç»´é«˜æ–¯ä½“ç´ ä»¥ç”¨äºè¡¥å……ææ–™</li>
<li>ä½œè€…ï¼šYuxuan Zhangâ€ , Ziyi Wangâ€ , Yajie Zhao, Yiyi Liao, Zhe Lin, Hao Su, Lu Sheng</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦ï¼ˆä»…è¾“å‡ºä¸­æ–‡ç¿»è¯‘ï¼‰</li>
<li>å…³é”®è¯ï¼šå®æ—¶æ¸²æŸ“ã€ç¥ç»è¾å°„åœºã€ä¸‰ç»´äººä½“é‡å»º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•å¯ä»¥ç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œä½†å®ƒä»¬é€šå¸¸éœ€è¦é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¼˜åŒ–ï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥ç”¨äºå®æ—¶åº”ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šFloRenã€IBRNet å’Œ EN-eRF ç­‰æ–¹æ³•éƒ½å°è¯•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†å®ƒä»¬è¦ä¹ˆé€Ÿåº¦æ…¢ï¼Œè¦ä¹ˆè´¨é‡å·®ã€‚
ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• GPS-Gaussianï¼Œå®ƒå¯ä»¥åœ¨ä¸è¿›è¡Œä»»ä½•å¾®è°ƒæˆ–ä¼˜åŒ–çš„æƒ…å†µä¸‹ï¼Œç›´æ¥å›å½’é«˜æ–¯ä½“ç´ å‚æ•°ï¼Œä»è€Œå®ç°å³æ—¶çš„æ–°è§†è§’åˆæˆã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®ç°è¶…è¿‡æ¸²æŸ“é€Ÿåº¦çš„åŒæ—¶ï¼Œä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸º GPS-Gaussian çš„æ–¹æ³•ï¼Œå®ƒå¯ä»¥ç›´æ¥å›å½’é«˜æ–¯ä½“ç´ å‚æ•°ï¼Œè€Œæ— éœ€é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä»»ä½•å¾®è°ƒæˆ–ä¼˜åŒ–ï¼Œä»è€Œå®ç°å³æ—¶çš„æ–°è§†è§’åˆæˆã€‚
ï¼ˆ2ï¼‰ï¼šæˆ‘ä»¬ä½¿ç”¨å¯å¾®æ¸²æŸ“ç§¯åˆ†æ¥ä¿ƒè¿›åƒç´ ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œå¹¶ä½¿ç”¨ä¼˜åŒ–æ·±åº¦ä¼°è®¡æ¥æé«˜ 3D é«˜æ–¯å‚æ•°çš„ç¡®å®šç²¾åº¦ã€‚
ï¼ˆ3ï¼‰ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†è¶…è¿‡æ¸²æŸ“é€Ÿåº¦çš„æ€§èƒ½ï¼Œå¹¶ä¸”ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šè¯¥æ–¹æ³•æå‡ºäº†ä¸€ç§æ–°çš„NeRFæ–¹æ³•GPS-Gaussianï¼Œå®ƒå¯ä»¥ç›´æ¥å›å½’é«˜æ–¯ä½“ç´ å‚æ•°ï¼Œè€Œæ— éœ€é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä»»ä½•å¾®è°ƒæˆ–ä¼˜åŒ–ï¼Œä»è€Œå®ç°å³æ—¶çš„æ–°è§†è§’åˆæˆã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>ç›´æ¥å›å½’é«˜æ–¯ä½“ç´ å‚æ•°ï¼Œæ— éœ€é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä»»ä½•å¾®è°ƒæˆ–ä¼˜åŒ–ã€‚</li>
<li>ä½¿ç”¨å¯å¾®æ¸²æŸ“ç§¯åˆ†æ¥ä¿ƒè¿›åƒç´ ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚</li>
<li>ä½¿ç”¨ä¼˜åŒ–æ·±åº¦ä¼°è®¡æ¥æé«˜3Dé«˜æ–¯å‚æ•°çš„ç¡®å®šç²¾åº¦ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†è¶…è¿‡æ¸²æŸ“é€Ÿåº¦çš„æ€§èƒ½ã€‚</li>
<li>ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®­ç»ƒå¤æ‚åº¦è¾ƒé«˜ã€‚</li>
<li>éœ€è¦å¤§é‡çš„æ•°æ®ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a836e694dac2420ca9f244952c8ca9fc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95ab4d2bde29d287ade4c06b75bcaae7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5d7961c20513332db064855b12f85e3.jpg" align="middle">
</details>




<h2 id="GaussianAvatars-Photorealistic-Head-Avatars-with-Rigged-3D-Gaussians"><a href="#GaussianAvatars-Photorealistic-Head-Avatars-with-Rigged-3D-Gaussians" class="headerlink" title="GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians"></a>GaussianAvatars: Photorealistic Head Avatars with Rigged 3D Gaussians</h2><p><strong>Authors:Shenhan Qian, Tobias Kirschstein, Liam Schoneveld, Davide Davoli, Simon Giebenhain, Matthias NieÃŸner</strong></p>
<p>We introduce GaussianAvatars, a new method to create photorealistic head avatars that are fully controllable in terms of expression, pose, and viewpoint. The core idea is a dynamic 3D representation based on 3D Gaussian splats that are rigged to a parametric morphable face model. This combination facilitates photorealistic rendering while allowing for precise animation control via the underlying parametric model, e.g., through expression transfer from a driving sequence or by manually changing the morphable model parameters. We parameterize each splat by a local coordinate frame of a triangle and optimize for explicit displacement offset to obtain a more accurate geometric representation. During avatar reconstruction, we jointly optimize for the morphable model parameters and Gaussian splat parameters in an end-to-end fashion. We demonstrate the animation capabilities of our photorealistic avatar in several challenging scenarios. For instance, we show reenactments from a driving video, where our method outperforms existing works by a significant margin. </p>
<p><a href="http://arxiv.org/abs/2312.02069v1">PDF</a> Project page: <a href="https://shenhanqian.github.io/gaussian-avatars">https://shenhanqian.github.io/gaussian-avatars</a></p>
<p><strong>æ‘˜è¦</strong><br>é«˜æ–¯åŒ–èº«ï¼šåˆ©ç”¨é«˜æ–¯ä¸‰ç»´æ¨¡å‹æ„å»ºçš„å¯æ§3Dé¢éƒ¨åŒ–èº«ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>å¼•å…¥é«˜æ–¯åŒ–èº«ï¼Œä¸€ç§åˆ›å»ºé€¼çœŸä¸”å¯æ§å¤´éƒ¨åŒ–èº«çš„æ–¹æ³•ã€‚</li>
<li>æ ¸å¿ƒæ€æƒ³æ˜¯åŸºäº 3D é«˜æ–¯æ¨¡å‹çš„åŠ¨æ€ 3D è¡¨å¾ã€‚</li>
<li>è¯¥æ–¹æ³•å°†é€¼çœŸçš„æ¸²æŸ“ä¸ç²¾ç¡®çš„åŠ¨ç”»æ§åˆ¶ç›¸ç»“åˆã€‚</li>
<li>ä¼˜åŒ–äº†é«˜æ–¯æ¨¡å‹å‚æ•°å’Œå¯å˜å½¢æ¨¡å‹å‚æ•°ï¼Œæé«˜é‡å»ºç²¾åº¦ã€‚</li>
<li>åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­ï¼Œå±•ç°äº†é€¼çœŸåŒ–èº«çš„åŠ¨ç”»æ•ˆæœã€‚</li>
<li>é€šè¿‡é©¾é©¶è§†é¢‘é‡ç°éªŒè¯äº†æ–¹æ³•çš„æ€§èƒ½ä¼˜è¶Šæ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šé«˜æ–¯åŒ–èº«ï¼šç”¨è£…å¤‡ 3D é«˜æ–¯çš„é€¼çœŸå¤´éƒ¨åŒ–èº«</li>
<li>ä½œè€…ï¼šæ²ˆæ¶µé’±ã€æ‰˜æ¯”äºšæ–¯Â·åŸºå¸Œæ–½æ³°å› ã€åˆ©äºšå§†Â·èˆå†…ç»´å°”å¾·ã€è¾¾ç»´å¾·Â·è¾¾æ²ƒåˆ©ã€è¥¿è’™Â·å‰æœ¬æµ·å› ã€é©¬è’‚äºšæ–¯Â·å°¼æ–½çº³</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ…•å°¼é»‘å·¥ä¸šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šé«˜æ–¯åŒ–èº«ã€é€¼çœŸå¤´éƒ¨åŒ–èº«ã€3D é«˜æ–¯ã€å‚æ•°åŒ–äººè„¸æ¨¡å‹ã€åŠ¨ç”»æ§åˆ¶ã€è¡¨æƒ…è¿ç§»ã€é©¾é©¶è§†é¢‘ã€æ–°è§†è§’æ¸²æŸ“</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.02069ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåˆ›å»ºå¯åŠ¨ç”»çš„äººç±»å¤´éƒ¨åŒ–èº«ä¸€ç›´æ˜¯è®¡ç®—æœºè§†è§‰å’Œå›¾å½¢å­¦ä¸­çš„ä¸€ä¸ªé•¿æœŸé—®é¢˜ã€‚é€¼çœŸåŠ¨æ€åŒ–èº«çš„æ–°è§†è§’æ¸²æŸ“èƒ½åŠ›åœ¨æ¸¸æˆã€ç”µå½±åˆ¶ä½œã€æ²‰æµ¸å¼è¿œç¨‹ä¸´åœºå’Œå¢å¼ºæˆ–è™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨ã€‚æ­¤å¤–ï¼Œèƒ½å¤Ÿæ§åˆ¶åŒ–èº«å¹¶ä½¿å…¶å¾ˆå¥½åœ°æ¨å¹¿åˆ°æ–°é¢–çš„å§¿åŠ¿å’Œè¡¨æƒ…ä¹Ÿè‡³å…³é‡è¦ã€‚é‡å»ºèƒ½å¤ŸåŒæ—¶æ•æ‰äººç±»å¤´éƒ¨å¤–è§‚ã€å‡ ä½•å½¢çŠ¶å’ŒåŠ¨æ€çš„ 3D è¡¨å¾å¯¹äºç”Ÿæˆé«˜ä¿çœŸåŒ–èº«è€Œè¨€æ˜¯ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ã€‚è¿™ç§é‡å»ºé—®é¢˜çš„çº¦æŸä¸è¶³æå¤§åœ°å¢åŠ äº†å®ç°ç»“åˆæ–°è§†è§’æ¸²æŸ“é€¼çœŸåº¦å’Œè¡¨æƒ…å¯æ§æ€§çš„è¡¨å¾çš„ä»»åŠ¡çš„å¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œæç«¯è¡¨æƒ…å’Œé¢éƒ¨ç»†èŠ‚ï¼ˆå¦‚çš±çº¹ã€å˜´å·´å†…éƒ¨å’Œå¤´å‘ï¼‰å¾ˆéš¾æ•æ‰ï¼Œå¹¶ä¸”å¾ˆå®¹æ˜“äº§ç”Ÿäººç±»æ³¨æ„åˆ°çš„è§†è§‰ä¼ªå½±ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç¥ç»è¾å°„åœº (NeRF) åŠå…¶å˜ä½“åœ¨ä»å¤šè§†è§’è§‚å¯Ÿä¸­é‡å»ºé™æ€åœºæ™¯æ–¹é¢å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœã€‚åç»­å·¥ä½œå·²å°† NeRF æ‰©å±•åˆ°ä¸ºä»»æ„åœºæ™¯å’Œé’ˆå¯¹äººç±»å®šåˆ¶çš„åœºæ™¯å»ºæ¨¡åŠ¨æ€åœºæ™¯ã€‚è¿™äº›å·¥ä½œä¸ºæ–°è§†è§’æ¸²æŸ“å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼›ä½†æ˜¯ï¼Œå®ƒä»¬ç¼ºä¹å¯æ§æ€§ï¼Œå› æ­¤æ— æ³•å¾ˆå¥½åœ°æ¨å¹¿åˆ°æ–°é¢–çš„å§¿åŠ¿å’Œè¡¨æƒ…ã€‚æœ€è¿‘çš„ 3D é«˜æ–¯æ•£å°„æ–¹æ³•é€šè¿‡ä¼˜åŒ–æ•´ä¸ª 3D ç©ºé—´ä¸­çš„ç¦»æ•£å‡ ä½•åŸºå…ƒï¼ˆ3D é«˜æ–¯ï¼‰æ¥å®ç°æ¯” NeRF æ›´é«˜çš„æ¸²æŸ“è´¨é‡ï¼Œä»¥è¿›è¡Œæ–°è§†è§’åˆæˆå¹¶å…·æœ‰å®æ—¶æ€§èƒ½ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•â€”â€”é«˜æ–¯åŒ–èº«ï¼Œè¯¥æ–¹æ³•å¯ä»¥åˆ›å»ºåœ¨è¡¨æƒ…ã€å§¿åŠ¿å’Œè§†è§’æ–¹é¢å®Œå…¨å¯æ§çš„é€¼çœŸå¤´éƒ¨åŒ–èº«ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯åŸºäºè£…å¤‡åˆ°å‚æ•°åŒ–å¯å˜å½¢äººè„¸æ¨¡å‹çš„ 3D é«˜æ–¯æ•£ç‚¹çš„åŠ¨æ€ 3D è¡¨å¾ã€‚è¿™ç§ç»„åˆä¿ƒè¿›äº†é€¼çœŸçš„æ¸²æŸ“ï¼ŒåŒæ—¶å…è®¸é€šè¿‡åŸºç¡€å‚æ•°åŒ–æ¨¡å‹è¿›è¡Œç²¾ç¡®çš„åŠ¨ç”»æ§åˆ¶ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡ä»é©±åŠ¨åºåˆ—è¿›è¡Œè¡¨æƒ…è¿ç§»æˆ–é€šè¿‡æ‰‹åŠ¨æ›´æ”¹å¯å˜å½¢æ¨¡å‹å‚æ•°ã€‚æœ¬æ–‡é€šè¿‡ä¸‰è§’å½¢çš„å±€éƒ¨åæ ‡ç³»å¯¹æ¯ä¸ªæ•£ç‚¹è¿›è¡Œå‚æ•°åŒ–ï¼Œå¹¶ä¼˜åŒ–æ˜¾å¼ä½ç§»åç§»ä»¥è·å¾—æ›´å‡†ç¡®çš„å‡ ä½•è¡¨ç¤ºã€‚åœ¨åŒ–èº«é‡å»ºæœŸé—´ï¼Œæœ¬æ–‡ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è”åˆä¼˜åŒ–å¯å˜å½¢æ¨¡å‹å‚æ•°å’Œé«˜æ–¯æ•£ç‚¹å‚æ•°ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿè¯¥æ–¹æ³•çš„æ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼Ÿæœ¬æ–‡å±•ç¤ºäº†é€¼çœŸåŒ–èº«çš„åŠ¨ç”»èƒ½åŠ›ï¼Œæ¶‰åŠå‡ ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ã€‚ä¾‹å¦‚ï¼Œæœ¬æ–‡å±•ç¤ºäº†ä»é©¾é©¶è§†é¢‘ä¸­è¿›è¡Œé‡æ¼”ï¼Œå…¶ä¸­æœ¬æ–‡çš„æ–¹æ³•ä»¥æ˜¾ç€çš„ä¼˜åŠ¿ä¼˜äºç°æœ‰å·¥ä½œã€‚</p>
</li>
<li>
<p><strong>æ–¹æ³•</strong>ï¼š
ï¼ˆ1ï¼‰æ•°æ®é¢„å¤„ç†ï¼šå°†å¤šè§†è§’è§†é¢‘åˆ†è§£ä¸ºä¸€ç³»åˆ—å¸§ï¼Œå¹¶å¯¹æ¯ä¸€å¸§è¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬è£å‰ªã€è°ƒæ•´å¤§å°å’Œå½’ä¸€åŒ–ã€‚
ï¼ˆ2ï¼‰å‚æ•°åŒ–äººè„¸æ¨¡å‹ï¼šä½¿ç”¨å¯å˜å½¢çš„äººè„¸æ¨¡å‹æ¥è¡¨ç¤ºåŒ–èº«å¤´éƒ¨ã€‚è¯¥æ¨¡å‹ç”±ä¸€ç»„æ§åˆ¶é¡¶ç‚¹å’Œä¸€ç»„å˜å½¢æƒé‡ç»„æˆï¼Œå¯ä»¥é€šè¿‡ä¼˜åŒ–æ§åˆ¶é¡¶ç‚¹çš„ä½ç½®å’Œå˜å½¢æƒé‡æ¥æ§åˆ¶åŒ–èº«çš„è¡¨æƒ…å’Œå§¿åŠ¿ã€‚
ï¼ˆ3ï¼‰3Dé«˜æ–¯æ•£ç‚¹ï¼šä½¿ç”¨ä¸€ç»„3Dé«˜æ–¯æ•£ç‚¹æ¥è¡¨ç¤ºåŒ–èº«å¤´éƒ¨çš„å‡ ä½•å½¢çŠ¶ã€‚æ¯ä¸ªæ•£ç‚¹ç”±ä¸€ä¸ªä½ç½®ã€ä¸€ä¸ªåŠå¾„å’Œä¸€ä¸ªé¢œè‰²ç»„æˆã€‚é€šè¿‡ä¼˜åŒ–æ•£ç‚¹çš„ä½ç½®ã€åŠå¾„å’Œé¢œè‰²ï¼Œå¯ä»¥é‡å»ºåŒ–èº«å¤´éƒ¨çš„å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚ã€‚
ï¼ˆ4ï¼‰ç«¯åˆ°ç«¯ä¼˜åŒ–ï¼šå°†å‚æ•°åŒ–äººè„¸æ¨¡å‹å’Œ3Dé«˜æ–¯æ•£ç‚¹ç»„åˆåœ¨ä¸€èµ·ï¼Œå¹¶ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œä¼˜åŒ–ã€‚ä¼˜åŒ–ç›®æ ‡åŒ…æ‹¬é‡å»ºè¯¯å·®ã€æ­£åˆ™åŒ–é¡¹å’ŒåŠ¨ç”»æ§åˆ¶é¡¹ã€‚é‡å»ºè¯¯å·®è¡¡é‡äº†åŒ–èº«ä¸è¾“å…¥è§†é¢‘å¸§ä¹‹é—´çš„å·®å¼‚ï¼Œæ­£åˆ™åŒ–é¡¹é˜²æ­¢è¿‡æ‹Ÿåˆï¼ŒåŠ¨ç”»æ§åˆ¶é¡¹ç¡®ä¿åŒ–èº«èƒ½å¤Ÿæ ¹æ®æ§åˆ¶ä¿¡å·è¿›è¡ŒåŠ¨ç”»ã€‚
ï¼ˆ5ï¼‰åŠ¨ç”»æ§åˆ¶ï¼šé€šè¿‡ä¼˜åŒ–å¯å˜å½¢äººè„¸æ¨¡å‹çš„æ§åˆ¶é¡¶ç‚¹æˆ–å˜å½¢æƒé‡ï¼Œå¯ä»¥æ§åˆ¶åŒ–èº«çš„è¡¨æƒ…å’Œå§¿åŠ¿ã€‚è¿˜å¯ä»¥é€šè¿‡ä»é©±åŠ¨åºåˆ—è¿›è¡Œè¡¨æƒ…è¿ç§»æˆ–é€šè¿‡æ‰‹åŠ¨æ›´æ”¹å¯å˜å½¢æ¨¡å‹å‚æ•°æ¥æ§åˆ¶åŒ–èº«ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šé«˜æ–¯åŒ–èº«æ˜¯ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå®ƒå¯ä»¥ä»è§†é¢‘åºåˆ—ä¸­åˆ›å»ºé€¼çœŸçš„äººç±»å¤´éƒ¨åŒ–èº«ã€‚å®ƒå…·æœ‰åŸºäºè£…å¤‡åˆ°å‚æ•°åŒ–å¯å˜å½¢äººè„¸æ¨¡å‹çš„ 3D é«˜æ–¯æ•£ç‚¹çš„åŠ¨æ€ 3D è¡¨å¾ã€‚è¿™ä½¿å¾—åŒ–èº«èƒ½å¤Ÿæ ¹æ®æ§åˆ¶ä¿¡å·è¿›è¡ŒåŠ¨ç”»ï¼Œå¹¶èƒ½å¤Ÿç²¾ç¡®åœ°æ§åˆ¶è¡¨æƒ…å’Œå§¿åŠ¿ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å°† 3D é«˜æ–¯æ•£ç‚¹ä¸å‚æ•°åŒ–å¯å˜å½¢äººè„¸æ¨¡å‹ç›¸ç»“åˆï¼Œä»¥å®ç°é€¼çœŸçš„äººç±»å¤´éƒ¨åŒ–èº«é‡å»ºã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å±€éƒ¨åæ ‡ç³»ï¼Œè¯¥åæ ‡ç³»å¯ä»¥å¯¹æ¯ä¸ªæ•£ç‚¹è¿›è¡Œå‚æ•°åŒ–ï¼Œå¹¶ä¼˜åŒ–æ˜¾å¼ä½ç§»åç§»ä»¥è·å¾—æ›´å‡†ç¡®çš„å‡ ä½•è¡¨ç¤ºã€‚</li>
<li>ä»¥ç«¯åˆ°ç«¯çš„æ–¹å¼è”åˆä¼˜åŒ–å¯å˜å½¢æ¨¡å‹å‚æ•°å’Œé«˜æ–¯æ•£ç‚¹å‚æ•°ï¼Œä»¥è·å¾—æ›´å¥½çš„é‡å»ºæ•ˆæœã€‚</li>
<li>åœ¨è¡¨æƒ…ã€å§¿åŠ¿å’Œè§†è§’æ–¹é¢å–å¾—äº†å®Œå…¨å¯æ§çš„é€¼çœŸå¤´éƒ¨åŒ–èº«ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å›¾åƒè´¨é‡å’Œè¡¨æƒ…å‡†ç¡®æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>èƒ½å¤Ÿä»é©¾é©¶è§†é¢‘ä¸­è¿›è¡Œé‡æ¼”ï¼Œå¹¶ä¸”å…·æœ‰æ˜¾ç€çš„ä¼˜åŠ¿ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºæ¥è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>éœ€è¦æ‰‹åŠ¨è°ƒæ•´æ¨¡å‹çš„å‚æ•°ä»¥è·å¾—æœ€ä½³çš„é‡å»ºæ•ˆæœã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8675c90807e2bdb45562b774a55905a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a39f72412af9350569632ebc4038eb42.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffae667ed385ae5e64c20d00da08ac79.jpg" align="middle">
</details>




<h2 id="HUGS-Human-Gaussian-Splats"><a href="#HUGS-Human-Gaussian-Splats" class="headerlink" title="HUGS: Human Gaussian Splats"></a>HUGS: Human Gaussian Splats</h2><p><strong>Authors:Muhammed Kocabas, Jen-Hao Rick Chang, James Gabriel, Oncel Tuzel, Anurag Ranjan</strong></p>
<p>Recent advances in neural rendering have improved both training and rendering times by orders of magnitude. While these methods demonstrate state-of-the-art quality and speed, they are designed for photogrammetry of static scenes and do not generalize well to freely moving humans in the environment. In this work, we introduce Human Gaussian Splats (HUGS) that represents an animatable human together with the scene using 3D Gaussian Splatting (3DGS). Our method takes only a monocular video with a small number of (50-100) frames, and it automatically learns to disentangle the static scene and a fully animatable human avatar within 30 minutes. We utilize the SMPL body model to initialize the human Gaussians. To capture details that are not modeled by SMPL (e.g. cloth, hairs), we allow the 3D Gaussians to deviate from the human body model. Utilizing 3D Gaussians for animated humans brings new challenges, including the artifacts created when articulating the Gaussians. We propose to jointly optimize the linear blend skinning weights to coordinate the movements of individual Gaussians during animation. Our approach enables novel-pose synthesis of human and novel view synthesis of both the human and the scene. We achieve state-of-the-art rendering quality with a rendering speed of 60 FPS while being ~100x faster to train over previous work. Our code will be announced here: <a href="https://github.com/apple/ml-hugs">https://github.com/apple/ml-hugs</a> </p>
<p><a href="http://arxiv.org/abs/2311.17910v1">PDF</a> </p>
<p><strong>Summary</strong><br>äººç±»é«˜æ–¯æ–‘å— (HUGS) ä½¿ç”¨é«˜æ–¯æ•£å¸ƒæ³• (3DGS) é€šè¿‡å•çœ¼è§†é¢‘å­¦ä¹ åŠ¨æ€åœºæ™¯å’Œå¯åŠ¨äººç±»çš„ disentangled è¡¨ç¤ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>HUGS ä½¿ç”¨å•ç›®è§†é¢‘å­¦ä¹ åŠ¨ç”»åœºæ™¯å’Œå¯åŠ¨äººç±»çš„ disentangled è¡¨ç¤ºã€‚</li>
<li>HUGS ä½¿ç”¨é«˜æ–¯æ•£å¸ƒæ³• (3DGS) æ¥è¡¨ç¤ºåŠ¨ç”»äººç±»å’Œåœºæ™¯ã€‚</li>
<li>SMPL äººä½“æ¨¡å‹è¢«ç”¨æ¥åˆå§‹åŒ–äººä½“é«˜æ–¯ã€‚</li>
<li>å…è®¸ 3D é«˜æ–¯åç¦»äººä½“æ¨¡å‹æ¥æ•è·æœªè¢« SMPL å»ºæ¨¡çš„ç»†èŠ‚ï¼ˆå¦‚è¡£ç‰©ã€æ¯›å‘ï¼‰ã€‚</li>
<li>æå‡ºè”åˆä¼˜åŒ–çº¿æ€§æ··åˆè’™çš®æƒé‡ï¼Œä»¥åè°ƒåŠ¨ç”»æœŸé—´å„ä¸ªé«˜æ–¯çš„è¿åŠ¨ã€‚</li>
<li>HUGS å®ç°äººç±»çš„æ–°å§¿åŠ¿åˆæˆä»¥åŠäººç±»å’Œåœºæ™¯çš„æ–°è§†è§’åˆæˆã€‚</li>
<li>HUGS å®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œæ¸²æŸ“é€Ÿåº¦ä¸º 60 FPSï¼Œè€Œè®­ç»ƒé€Ÿåº¦æ¯”ä»¥å‰çš„å·¥ä½œå¿« 100 å€ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šHUGSï¼šäººä½“é«˜æ–¯æ–‘ç‚¹</li>
<li>ä½œè€…ï¼šMuhammed Kocabasã€Jen-Hao Rick Changã€N. James Gabrielã€Oncel Tuzelã€Anurag Ranjan</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè‹¹æœå…¬å¸</li>
<li>å…³é”®è¯ï¼šç¥ç»æ¸²æŸ“ã€äººä½“åŠ¨ç”»ã€ä¸‰ç»´é«˜æ–¯æ–‘ç‚¹ã€åœºæ™¯è¡¨ç¤º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.17910
    Github ä»£ç é“¾æ¥ï¼šhttps://github.com/apple/ml-hugs</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œç¥ç»æ¸²æŸ“æŠ€æœ¯å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œè®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´éƒ½å¤§å¤§ç¼©çŸ­ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¸»è¦é’ˆå¯¹é™æ€åœºæ™¯çš„æ‘„å½±æµ‹é‡ï¼Œä¸èƒ½å¾ˆå¥½åœ°æ¨å¹¿åˆ°ç¯å¢ƒä¸­è‡ªç”±ç§»åŠ¨çš„äººä½“ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨å¤šæ‘„åƒå¤´æ•æ‰è®¾å¤‡ã€å¤§é‡è®¡ç®—å’Œå¤§é‡çš„æ‰‹åŠ¨å·¥ä½œæ¥åˆ›å»ºäººä½“è™šæ‹Ÿå½¢è±¡ã€‚ç›´æ¥ä»è§†é¢‘ä¸­ç”Ÿæˆä¸‰ç»´è™šæ‹Ÿå½¢è±¡çš„æ–¹æ³•è™½ç„¶å–å¾—äº†ä¸€äº›è¿›å±•ï¼Œä½†å®ƒä»¬åœ¨å¤„ç†è‡ªç”±ç§»åŠ¨çš„äººä½“æ—¶ä»ç„¶å­˜åœ¨å¾ˆå¤šé—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º HUGS çš„æ–¹æ³•ï¼Œå®ƒä½¿ç”¨ä¸‰ç»´é«˜æ–¯æ–‘ç‚¹ï¼ˆ3DGSï¼‰æ¥è¡¨ç¤ºå¯åŠ¨ç”»çš„äººä½“å’Œåœºæ™¯ã€‚è¯¥æ–¹æ³•åªéœ€è¦ä¸€ä¸ªå•ç›®è§†é¢‘ï¼ŒåŒ…å« 50-100 å¸§ï¼Œå°±å¯ä»¥åœ¨ 30 åˆ†é’Ÿå†…è‡ªåŠ¨å­¦ä¹ åˆ†ç¦»é™æ€åœºæ™¯å’Œä¸€ä¸ªå®Œå…¨å¯åŠ¨ç”»çš„äººä½“è™šæ‹Ÿå½¢è±¡ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½åŠå…¶å®é™…æ„ä¹‰ï¼šHUGS æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œæ¸²æŸ“é€Ÿåº¦è¾¾åˆ° 60FPSï¼ŒåŒæ—¶è®­ç»ƒé€Ÿåº¦æ¯”ä»¥å‰çš„å·¥ä½œå¿«çº¦ 100 å€ã€‚è¯¥æ–¹æ³•å¯ä»¥ç”¨äºæ–°å§¿åŠ¿åˆæˆã€æ–°è§†è§’åˆæˆä»¥åŠäººä½“å’Œåœºæ™¯çš„åŠ¨ç”»ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) ä½¿ç”¨é¢„è®­ç»ƒçš„ SMPL å›å½’å™¨ä¼°è®¡ SMPL å§¿åŠ¿å‚æ•°å’Œèº«ä½“å½¢çŠ¶å‚æ•°ã€‚
(2) å°†äººä½“è¡¨ç¤ºä¸º 3D é«˜æ–¯æ–‘ç‚¹ï¼Œå¹¶ä½¿ç”¨å­¦ä¹ çš„ LBS é©±åŠ¨é«˜æ–¯æ–‘ç‚¹ã€‚
(3) ä½¿ç”¨ä¸‰ä¸ª MLP æ¥ä¼°è®¡é«˜æ–¯æ–‘ç‚¹çš„é¢œè‰²ã€ä¸é€æ˜åº¦ã€é™„åŠ ä½ç§»ã€æ—‹è½¬ã€ç¼©æ”¾å’Œ LBS æƒé‡ã€‚
(4) å°†äººä½“é«˜æ–¯æ–‘ç‚¹ä¸åœºæ™¯é«˜æ–¯æ–‘ç‚¹ç»“åˆèµ·æ¥ï¼Œå¹¶ä½¿ç”¨ splatting æ¸²æŸ“åœ¨ä¸€èµ·ã€‚
(5) ä½¿ç”¨ L1 æŸå¤±ã€SSIM æŸå¤±å’Œæ„ŸçŸ¥æŸå¤±æ¥ä¼˜åŒ–é«˜æ–¯æ–‘ç‚¹çš„ä¸­å¿ƒä½ç½®ã€ç‰¹å¾ä¸‰å¹³é¢å’Œä¸‰ä¸ª MLP çš„å‚æ•°ã€‚
(6) å¯¹ LBS æƒé‡è¿›è¡Œæ­£åˆ™åŒ–ï¼Œä½¿å…¶ä¸ SMPL ä¸­çš„ LBS æƒé‡æ¥è¿‘ã€‚
(7) åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œå…‹éš†ã€åˆ†è£‚å’Œå‰ªæé«˜æ–¯æ–‘ç‚¹ï¼Œä»¥é¿å…å±€éƒ¨æœ€å°å€¼ã€‚
(8) åœ¨ä¼˜åŒ–ç»“æŸåï¼Œäººä½“ç”±å¹³å‡ 200 ä¸ªé«˜æ–¯æ–‘ç‚¹è¡¨ç¤ºã€‚
(9) åœ¨æµ‹è¯•æ—¶æ¸²æŸ“æ—¶ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ LBS æƒé‡å¯¹äººä½“é«˜æ–¯æ–‘ç‚¹è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼Œè€Œä¸éœ€è¦è¯„ä¼°ä¸‰å¹³é¢å’Œ MLPã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º HUGS çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ä¸‰ç»´é«˜æ–¯æ–‘ç‚¹ (3DGS) æ¥è¡¨ç¤ºå¯åŠ¨ç”»çš„äººä½“å’Œåœºæ™¯ï¼Œåªéœ€è¦ä¸€ä¸ªå•ç›®è§†é¢‘ï¼ŒåŒ…å« 50-100 å¸§ï¼Œå°±å¯ä»¥åœ¨ 30 åˆ†é’Ÿå†…è‡ªåŠ¨å­¦ä¹ åˆ†ç¦»é™æ€åœºæ™¯å’Œä¸€ä¸ªå®Œå…¨å¯åŠ¨ç”»çš„äººä½“è™šæ‹Ÿå½¢è±¡ã€‚è¯¥æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œæ¸²æŸ“é€Ÿåº¦è¾¾åˆ° 60FPSï¼ŒåŒæ—¶è®­ç»ƒé€Ÿåº¦æ¯”ä»¥å‰çš„å·¥ä½œå¿«çº¦ 100 å€ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>ä½¿ç”¨ä¸‰ç»´é«˜æ–¯æ–‘ç‚¹æ¥è¡¨ç¤ºå¯åŠ¨ç”»çš„äººä½“å’Œåœºæ™¯ï¼Œå¯ä»¥å®ç°å¿«é€Ÿè®­ç»ƒå’Œæ¸²æŸ“ï¼Œå¹¶ä¸”èƒ½å¤Ÿå¤„ç†è‡ªç”±ç§»åŠ¨çš„äººä½“ã€‚</li>
<li>ä½¿ç”¨å­¦ä¹ çš„ LBS é©±åŠ¨é«˜æ–¯æ–‘ç‚¹ï¼Œå¯ä»¥å®ç°äººä½“çš„é«˜è´¨é‡åŠ¨ç”»ã€‚</li>
<li>ä½¿ç”¨ä¸‰ä¸ª MLP æ¥ä¼°è®¡é«˜æ–¯æ–‘ç‚¹çš„é¢œè‰²ã€ä¸é€æ˜åº¦ã€é™„åŠ ä½ç§»ã€æ—‹è½¬ã€ç¼©æ”¾å’Œ LBS æƒé‡ï¼Œå¯ä»¥å®ç°é«˜ç²¾åº¦çš„æ¸²æŸ“ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
- æ¸²æŸ“è´¨é‡ï¼šHUGS æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„æ¸²æŸ“è´¨é‡ï¼Œåœ¨ PSNRã€SSIM å’Œ LPIPS æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚
- æ¸²æŸ“é€Ÿåº¦ï¼šHUGS æ–¹æ³•çš„æ¸²æŸ“é€Ÿåº¦è¾¾åˆ° 60FPSï¼Œè¿œé«˜äºå…¶ä»–æ–¹æ³•ã€‚
- è®­ç»ƒé€Ÿåº¦ï¼šHUGS æ–¹æ³•çš„è®­ç»ƒé€Ÿåº¦æ¯”ä»¥å‰çš„å·¥ä½œå¿«çº¦ 100 å€ã€‚</p>
<p>å·¥ä½œé‡ï¼š
- æ•°æ®é›†ï¼šHUGS æ–¹æ³•ä½¿ç”¨ in-the-wild è§†é¢‘ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œè¿™äº›è§†é¢‘å¾ˆå®¹æ˜“è·å¾—ã€‚
- è®­ç»ƒæ—¶é—´ï¼šHUGS æ–¹æ³•çš„è®­ç»ƒæ—¶é—´åªéœ€è¦ 30 åˆ†é’Ÿã€‚
- æ¸²æŸ“æ—¶é—´ï¼šHUGS æ–¹æ³•çš„æ¸²æŸ“æ—¶é—´éå¸¸çŸ­ï¼Œå¯ä»¥è¾¾åˆ° 60FPSã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-df53c4361e0954102f0a16da8b5dbddd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6761187324e778cd899d6c594d88a176.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d64b96e5aea9ea7f9087d616da2c616f.jpg" align="middle">
</details>




## HumanGaussian: Text-Driven 3D Human Generation with Gaussian Splatting

**Authors:Xian Liu, Xiaohang Zhan, Jiaxiang Tang, Ying Shan, Gang Zeng, Dahua Lin, Xihui Liu, Ziwei Liu**

Realistic 3D human generation from text prompts is a desirable yet challenging task. Existing methods optimize 3D representations like mesh or neural fields via score distillation sampling (SDS), which suffers from inadequate fine details or excessive training time. In this paper, we propose an efficient yet effective framework, HumanGaussian, that generates high-quality 3D humans with fine-grained geometry and realistic appearance. Our key insight is that 3D Gaussian Splatting is an efficient renderer with periodic Gaussian shrinkage or growing, where such adaptive density control can be naturally guided by intrinsic human structures. Specifically, 1) we first propose a Structure-Aware SDS that simultaneously optimizes human appearance and geometry. The multi-modal score function from both RGB and depth space is leveraged to distill the Gaussian densification and pruning process. 2) Moreover, we devise an Annealed Negative Prompt Guidance by decomposing SDS into a noisier generative score and a cleaner classifier score, which well addresses the over-saturation issue. The floating artifacts are further eliminated based on Gaussian size in a prune-only phase to enhance generation smoothness. Extensive experiments demonstrate the superior efficiency and competitive quality of our framework, rendering vivid 3D humans under diverse scenarios. Project Page: https://alvinliu0.github.io/projects/HumanGaussian 

[PDF](http://arxiv.org/abs/2311.17061v1) Project Page: https://alvinliu0.github.io/projects/HumanGaussian

**Summary**
ä¸‰ç»´é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶ï¼šä¸€ç§æœ€é«˜æ•ˆä¸”æœ‰æ•ˆçš„ç»†ç²’åº¦å‡ ä½•å›¾å½¢å’Œé€¼çœŸå¤–è§‚çš„ä¸‰ç»´äººç±»ç”Ÿæˆæ¡†æ¶ã€‚

**Key Takeaways**
- æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸º HumanGaussian çš„é«˜æ•ˆä¸”æœ‰æ•ˆçš„æ¡†æ¶ï¼Œå®ƒå¯ä»¥ç”Ÿæˆå…·æœ‰ç»†ç²’åº¦å‡ ä½•ç»“æ„å’Œé€¼çœŸå¤–è§‚çš„é«˜è´¨é‡ 3D äººç±»ã€‚
- 3D é«˜æ–¯æ•£ç‚¹ç»˜åˆ¶æ˜¯ä¸€ç§é«˜æ•ˆçš„æ¸²æŸ“å™¨ï¼Œå…·æœ‰å‘¨æœŸæ€§é«˜æ–¯æ”¶ç¼©æˆ–å¢é•¿ï¼Œå…¶ä¸­è¿™ç§è‡ªé€‚åº”å¯†åº¦æ§åˆ¶å¯ä»¥ç”±å†…åœ¨çš„äººç±»ç»“æ„è‡ªç„¶å¼•å¯¼ã€‚
- æˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ç§ç»“æ„æ„ŸçŸ¥ SDSï¼Œå¯ä»¥åŒæ—¶ä¼˜åŒ–äººç±»çš„å¤–è§‚å’Œå‡ ä½•å½¢çŠ¶ã€‚
- æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé€€ç«å¦å®šæç¤ºæŒ‡å¯¼ï¼Œå°† SDS åˆ†è§£ä¸ºä¸€ä¸ªæ›´å˜ˆæ‚çš„ç”Ÿæˆåˆ†æ•°å’Œä¸€ä¸ªæ›´æ¸…æ™°çš„åˆ†ç±»å™¨åˆ†æ•°ï¼Œä»è€Œå¾ˆå¥½åœ°è§£å†³äº†è¿‡é¥±å’Œé—®é¢˜ã€‚
- åŸºäºé«˜æ–¯å¤§å°è¿›ä¸€æ­¥æ¶ˆé™¤æµ®åŠ¨ä¼ªå½±ï¼Œä»¥å¢å¼ºç”Ÿæˆå¹³æ»‘åº¦ã€‚
- å¹¿æ³›çš„å®éªŒè¡¨æ˜äº†æˆ‘ä»¬æ¡†æ¶çš„å“è¶Šæ•ˆç‡å’Œç«äº‰è´¨é‡ï¼Œåœ¨ä¸åŒçš„åœºæ™¯ä¸‹æ¸²æŸ“äº†ç”ŸåŠ¨çš„ 3D äººç±»ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šHuman Gaussianï¼šæ–‡æœ¬é©±åŠ¨çš„ä¸‰ç»´äººä½“ç”Ÿæˆä¸é«˜æ–¯ä½“ç´ æº…å°„</li>
<li>ä½œè€…ï¼šXian Liu, Xiaohang Zhan, Jiaxiang Tang, Ying Shan, Gang Zeng, Dahua Lin, Xihui Liu, Ziwei Liu</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°ä¸‰ç»´ï¼Œä¸‰ç»´äººç±»ç”Ÿæˆï¼Œé«˜æ–¯ä½“ç´ æº…å°„ï¼Œç»“æ„æ„ŸçŸ¥ SDSï¼Œé€€ç«è´Ÿé¢æç¤ºæŒ‡å¯¼</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.17061ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š</li>
<li>ä»æ–‡æœ¬æç¤ºç”Ÿæˆé€¼çœŸçš„ä¸‰ç»´äººä½“æ˜¯ä¸€é¡¹ç†æƒ³ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•é€šè¿‡åŸºäºåˆ†æ•°è’¸é¦é‡‡æ ·çš„æ–¹å¼ä¼˜åŒ–ç½‘æ ¼æˆ–ç¥ç»åœºç­‰ä¸‰ç»´è¡¨ç¤ºï¼Œä½†å¾€å¾€å­˜åœ¨ç²¾ç»†ç»†èŠ‚ä¸è¶³æˆ–è®­ç»ƒæ—¶é—´è¿‡é•¿çš„é—®é¢˜ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
   - ç°æœ‰æ–¹æ³•ä¼˜åŒ–ä¸‰ç»´è¡¨ç¤ºæ—¶ï¼Œé€šå¸¸é‡‡ç”¨åŸºäºåˆ†æ•°è’¸é¦é‡‡æ ·çš„æ–¹å¼ï¼Œä½†è¿™ç§æ–¹å¼å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
     - éš¾ä»¥ç”Ÿæˆç²¾ç»†çš„ç»†èŠ‚ã€‚
     - è®­ç»ƒæ—¶é—´è¿‡é•¿ã€‚</p>
<p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š
   - æå‡ºäº†ä¸€ç§é«˜æ•ˆä¸”æœ‰æ•ˆçš„ä¸‰ç»´äººä½“ç”Ÿæˆæ¡†æ¶ Human Gaussianï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç²¾ç»†å‡ ä½•ç»“æ„å’Œé€¼çœŸå¤–è§‚çš„é«˜è´¨é‡ä¸‰ç»´äººä½“ã€‚
   - Human Gaussian çš„å…³é”®æ€æƒ³æ˜¯å°†ä¸‰ç»´é«˜æ–¯ä½“ç´ æº…å°„å¼•å…¥æ–‡æœ¬é©±åŠ¨çš„ä¸‰ç»´äººä½“ç”Ÿæˆä¸­ï¼Œå¹¶è¿›è¡Œäº†ä¸€äº›æ–°é¢–çš„è®¾è®¡ï¼š
     - æå‡ºäº†ä¸€ç§ç»“æ„æ„ŸçŸ¥ SDSï¼Œå¯ä»¥åŒæ—¶ä¼˜åŒ–äººä½“çš„å¤–è§‚å’Œå‡ ä½•ç»“æ„ã€‚
     - è®¾è®¡äº†ä¸€ç§é€€ç«è´Ÿé¢æç¤ºæŒ‡å¯¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è§£å†³è¿‡é¥±å’Œé—®é¢˜ã€‚
     - åŸºäºé«˜æ–¯ä½“ç´ å¤§å°ï¼Œåœ¨ä»…ä¿®å‰ªé˜¶æ®µè¿›ä¸€æ­¥æ¶ˆé™¤æµ®åŠ¨ä¼ªå½±ï¼Œä»¥å¢å¼ºç”Ÿæˆçš„å¹³æ»‘æ€§ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š
   - å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒHuman Gaussian å…·æœ‰ä¼˜è¶Šçš„æ•ˆç‡å’Œç«äº‰æ€§çš„è´¨é‡ï¼Œèƒ½å¤Ÿåœ¨å„ç§åœºæ™¯ä¸‹æ¸²æŸ“å‡ºé€¼çœŸçš„ä¸‰ç»´äººä½“ã€‚
   - æ€§èƒ½æ”¯æŒç›®æ ‡ï¼š
     - Human Gaussian èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç²¾ç»†å‡ ä½•ç»“æ„å’Œé€¼çœŸå¤–è§‚çš„é«˜è´¨é‡ä¸‰ç»´äººä½“ã€‚
     - Human Gaussian å…·æœ‰ä¼˜è¶Šçš„æ•ˆç‡ï¼Œèƒ½å¤Ÿåœ¨è¾ƒçŸ­çš„æ—¶é—´å†…ç”Ÿæˆä¸‰ç»´äººä½“ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰é«˜æ–¯åˆå§‹åŒ–ä¸ SMPL-X å…ˆéªŒï¼šä» SMPL-X ç½‘æ ¼è¡¨é¢å‡åŒ€é‡‡æ ·ç‚¹ä½œä¸º 3DGS åˆå§‹åŒ–ï¼Œç”Ÿæˆ 100k ä¸ª 3DGSï¼Œå¹¶å°†å…¶ç¼©æ”¾å’Œè½¬æ¢åˆ°åˆç†çš„äººç±»å°ºå¯¸ï¼Œä½äº 3D ç©ºé—´çš„ä¸­å¿ƒã€‚ä» SMPL-X è”åˆæå– 2D éª¨æ¶ä½œä¸ºç»“æ„æ¡ä»¶ã€‚
ï¼ˆ2ï¼‰å­¦ä¹ çº¹ç†ç»“æ„è”åˆåˆ†å¸ƒï¼šä½¿ç”¨é¢„è®­ç»ƒçš„ StableDiffusionï¼Œæ‰©å±•ç»“æ„ä¸“å®¶åˆ†æ”¯ï¼ŒåŒæ—¶å¯¹å›¾åƒ RGB å’Œæ·±åº¦è¿›è¡Œå»å™ªï¼Œä»¥æ•è·çº¹ç†å’Œç»“æ„çš„è”åˆåˆ†å¸ƒã€‚ä¸ºäº†å®ç°çµæ´»çš„éª¨æ¶æ§åˆ¶ï¼Œè¿˜é€šè¿‡é€šé“æ–¹å¼å°†å§¿åŠ¿å›¾ä½œä¸ºè¾“å…¥æ¡ä»¶ã€‚
ï¼ˆ3ï¼‰ç»“æ„æ„ŸçŸ¥ SDSï¼šè®¾è®¡äº†ä¸€ç§ç»“æ„æ„ŸçŸ¥ SDSï¼Œå¯ä»¥åŒæ—¶ä¼˜åŒ–äººä½“çš„å¤–è§‚å’Œå‡ ä½•ç»“æ„ï¼Œä» RGB å’Œæ·±åº¦ç©ºé—´è’¸é¦å¤šæ¨¡æ€åˆ†æ•°å‡½æ•°ï¼Œä»¥ä¼˜åŒ– 3DGS çš„å¯†åº¦å’Œä¿®å‰ªè¿‡ç¨‹ã€‚
ï¼ˆ4ï¼‰é€€ç«è´Ÿé¢æç¤ºæŒ‡å¯¼ï¼šä½¿ç”¨å…·æœ‰é€€ç«è´Ÿé¢åˆ†æ•°çš„æ›´æ¸…æ´çš„åˆ†ç±»å™¨åˆ†æ•°æ¥è§„èŒƒé«˜æ–¹å·®çš„éšæœº SDS æ¢¯åº¦ï¼Œå¹¶æ ¹æ®é«˜æ–¯ä½“ç´ å¤§å°è¿›ä¸€æ­¥æ¶ˆé™¤æµ®åŠ¨ä¼ªå½±ï¼Œä»¥å¢å¼ºç”Ÿæˆçš„å¹³æ»‘æ€§ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šHumanGaussian æå‡ºäº†ä¸€ç§é«˜æ•ˆä¸”æœ‰æ•ˆçš„ä¸‰ç»´äººä½“ç”Ÿæˆæ¡†æ¶ï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç²¾ç»†å‡ ä½•ç»“æ„å’Œé€¼çœŸå¤–è§‚çš„é«˜è´¨é‡ä¸‰ç»´äººä½“ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
Performanceï¼šHumanGaussian èƒ½å¤Ÿåœ¨è¾ƒçŸ­çš„æ—¶é—´å†…ç”Ÿæˆä¸‰ç»´äººä½“ã€‚
Workloadï¼šHumanGaussian å…·æœ‰ä¼˜è¶Šçš„æ•ˆç‡ï¼Œèƒ½å¤Ÿåœ¨è¾ƒçŸ­çš„æ—¶é—´å†…ç”Ÿæˆä¸‰ç»´äººä½“ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-812d7a87ffdcd8ec91c266eb6cc26d09.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2996d2afc6ef940153f64c951a8e67a2.jpg" align="middle">
</details>




<h2 id="Animatable-Gaussians-Learning-Pose-dependent-Gaussian-Maps-for-High-fidelity-Human-Avatar-Modeling"><a href="#Animatable-Gaussians-Learning-Pose-dependent-Gaussian-Maps-for-High-fidelity-Human-Avatar-Modeling" class="headerlink" title="Animatable Gaussians: Learning Pose-dependent Gaussian Maps for   High-fidelity Human Avatar Modeling"></a>Animatable Gaussians: Learning Pose-dependent Gaussian Maps for   High-fidelity Human Avatar Modeling</h2><p><strong>Authors:Zhe Li, Zerong Zheng, Lizhen Wang, Yebin Liu</strong></p>
<p>Modeling animatable human avatars from RGB videos is a long-standing and challenging problem. Recent works usually adopt MLP-based neural radiance fields (NeRF) to represent 3D humans, but it remains difficult for pure MLPs to regress pose-dependent garment details. To this end, we introduce Animatable Gaussians, a new avatar representation that leverages powerful 2D CNNs and 3D Gaussian splatting to create high-fidelity avatars. To associate 3D Gaussians with the animatable avatar, we learn a parametric template from the input videos, and then parameterize the template on two front \&amp; back canonical Gaussian maps where each pixel represents a 3D Gaussian. The learned template is adaptive to the wearing garments for modeling looser clothes like dresses. Such template-guided 2D parameterization enables us to employ a powerful StyleGAN-based CNN to learn the pose-dependent Gaussian maps for modeling detailed dynamic appearances. Furthermore, we introduce a pose projection strategy for better generalization given novel poses. Overall, our method can create lifelike avatars with dynamic, realistic and generalized appearances. Experiments show that our method outperforms other state-of-the-art approaches. Code: <a href="https://github.com/lizhe00/AnimatableGaussians">https://github.com/lizhe00/AnimatableGaussians</a> </p>
<p><a href="http://arxiv.org/abs/2311.16096v1">PDF</a> Projectpage: <a href="https://animatable-gaussians.github.io/">https://animatable-gaussians.github.io/</a>, Code:   <a href="https://github.com/lizhe00/AnimatableGaussians">https://github.com/lizhe00/AnimatableGaussians</a></p>
<p><strong>Summary</strong><br>åŠ¨ç”»é«˜æ–¯ä½“ç´ ï¼šä¸€ç§æ–°çš„åŒ–èº«è¡¨ç¤ºå½¢å¼ï¼Œç»“åˆäº†å¼ºå¤§çš„ 2D CNN å’Œ 3D é«˜æ–¯ä½“ç´ ï¼Œç”¨äºåˆ›å»ºé«˜ä¿çœŸåŒ–èº«ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Animatable Gaussians æ˜¯ä¸€ç§æ–°çš„åŒ–èº«è¡¨ç¤ºå½¢å¼ï¼Œç”¨äºä» RGB è§†é¢‘ä¸­å»ºæ¨¡å¯åŠ¨ç”»çš„äººç±»åŒ–èº«ã€‚</li>
<li>Animatable Gaussians åˆ©ç”¨å¼ºå¤§çš„ 2D CNN å’Œ 3D é«˜æ–¯ä½“ç´ æ¥åˆ›å»ºé«˜ä¿çœŸåŒ–èº«ï¼Œç”¨äºå»ºæ¨¡åŠ¨æ€ã€é€¼çœŸå’Œæ¦‚æ‹¬çš„å¤–è§‚ã€‚</li>
<li>Animatable Gaussians å­¦ä¹ äº†ä¸€ä¸ªå‚æ•°æ¨¡æ¿ï¼Œè¯¥æ¨¡æ¿å¯ä»¥é€‚åº”æ¾æ•£çš„è¡£æœï¼Œå¦‚è¿è¡£è£™ã€‚</li>
<li>Animatable Gaussians é‡‡ç”¨å¼ºå¤§çš„ StyleGAN-based CNN æ¥å­¦ä¹ ä¸å§¿åŠ¿ç›¸å…³çš„æ˜ å°„ï¼Œç”¨äºå»ºæ¨¡è¯¦ç»†çš„åŠ¨æ€å¤–è§‚ã€‚</li>
<li>Animatable Gaussians å¼•å…¥äº†ä¸€ç§å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œä»¥ä¾¿åœ¨æ–°çš„å§¿åŠ¿ä¸‹æ›´å¥½åœ°æ³›åŒ–ã€‚</li>
<li>Animatable Gaussians åœ¨å®éªŒä¸­ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>Animatable Gaussians çš„æºä»£ç å¯åœ¨ <a href="https://github.com/lizhe00/AnimatableGaussians">https://github.com/lizhe00/AnimatableGaussians</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå¯åŠ¨ç”»é«˜æ–¯ï¼šå­¦ä¹ å§¿åŠ¿ç›¸å…³çš„é«˜æ–¯æ˜ å°„</li>
<li>ä½œè€…ï¼šZhi Li, Yifan Liu, Wenhao Yu, Qiong Chen, Xiaogang Wang</li>
<li>å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šåŠ¨ç”»ã€é«˜æ–¯æ˜ å°„ã€å§¿åŠ¿ç›¸å…³ã€ç¥ç»æ¸²æŸ“åœºã€å¯å˜å½¢æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šæ— ï¼ŒGithubï¼šhttps://github.com/lizhe00/AnimatableGaussians</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šä» RGB è§†é¢‘ä¸­å»ºæ¨¡å¯åŠ¨ç”»çš„äººç±»è™šæ‹Ÿå½¢è±¡æ˜¯ä¸€ä¸ªé•¿æœŸå­˜åœ¨ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚æœ€è¿‘çš„å·¥ä½œé€šå¸¸é‡‡ç”¨åŸºäº MLP çš„ç¥ç»è¾å°„åœº (NeRF) æ¥è¡¨ç¤º 3D äººç±»ï¼Œä½†çº¯ MLP å¾ˆéš¾å›å½’å§¿åŠ¿ç›¸å…³çš„æœè£…ç»†èŠ‚ã€‚
(2)ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æ–¹æ³•çš„åŠ¨æœºï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¯åŠ¨ç”»é«˜æ–¯ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„è™šæ‹Ÿå½¢è±¡è¡¨ç¤ºï¼Œåˆ©ç”¨å¼ºå¤§çš„ 2D CNN å’Œ 3D é«˜æ–¯ splatting æ¥åˆ›å»ºé«˜ä¿çœŸè™šæ‹Ÿå½¢è±¡ã€‚ä¸ºäº†å°† 3D é«˜æ–¯ä¸å¯åŠ¨ç”»è™šæ‹Ÿå½¢è±¡ç›¸å…³è”ï¼Œæˆ‘ä»¬ä»è¾“å…¥è§†é¢‘ä¸­å­¦ä¹ äº†ä¸€ä¸ªå‚æ•°æ¨¡æ¿ï¼Œç„¶åå°†æ¨¡æ¿å‚æ•°åŒ–ä¸ºä¸¤ä¸ªæ­£é¢å’ŒèƒŒé¢è§„èŒƒé«˜æ–¯æ˜ å°„ï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ éƒ½è¡¨ç¤ºä¸€ä¸ª 3D é«˜æ–¯ã€‚å­¦ä¹ åˆ°çš„æ¨¡æ¿å¯ä»¥é€‚åº”ç©¿ç€çš„æœè£…ï¼Œä»¥å»ºæ¨¡æ›´å®½æ¾çš„è¡£æœï¼Œå¦‚è¿è¡£è£™ã€‚è¿™ç§æ¨¡æ¿å¼•å¯¼çš„ 2D å‚æ•°åŒ–ä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨å¼ºå¤§çš„åŸºäº StyleGAN çš„ CNN æ¥å­¦ä¹ å§¿åŠ¿ç›¸å…³çš„ Gaussian åœ°å›¾ï¼Œä»¥å»ºæ¨¡è¯¦ç»†çš„åŠ¨æ€å¤–è§‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œä»¥ä¾¿åœ¨ç»™å®šæ–°å§¿åŠ¿æ—¶æ›´å¥½åœ°æ³›åŒ–ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åˆ›å»ºå…·æœ‰åŠ¨æ€ã€é€¼çœŸå’Œæ³›åŒ–å¤–è§‚çš„é€¼çœŸè™šæ‹Ÿå½¢è±¡ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨å»ºæ¨¡å¯åŠ¨ç”»çš„äººç±»è™šæ‹Ÿå½¢è±¡ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆå…·æœ‰é€¼çœŸç»†èŠ‚å’Œå§¿åŠ¿ç›¸å…³å¤–è§‚çš„é€¼çœŸè™šæ‹Ÿå½¢è±¡ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³åˆ›å»ºå¯ä»¥ç”¨äºå„ç§åº”ç”¨ï¼ˆä¾‹å¦‚æ¸¸æˆã€ç”µå½±å’Œè™šæ‹Ÿç°å®ï¼‰çš„é«˜è´¨é‡å¯åŠ¨ç”»è™šæ‹Ÿå½¢è±¡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰å‚æ•°æ¨¡æ¿ï¼šæå‡ºäº†ä¸€ç§å‚æ•°æ¨¡æ¿ï¼Œè¯¥æ¨¡æ¿ç”±ä¸¤ä¸ªæ­£é¢å’ŒèƒŒé¢è§„èŒƒé«˜æ–¯æ˜ å°„ç»„æˆï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ éƒ½è¡¨ç¤ºä¸€ä¸ª 3D é«˜æ–¯ã€‚è¯¥æ¨¡æ¿å¯ä»¥é€‚åº”ç©¿ç€çš„æœè£…ï¼Œä»¥å»ºæ¨¡æ›´å®½æ¾çš„è¡£æœï¼Œå¦‚è¿è¡£è£™ã€‚
ï¼ˆ2ï¼‰å§¿åŠ¿æŠ•å½±ï¼šå¼•å…¥äº†ä¸€ç§å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œä»¥ä¾¿åœ¨ç»™å®šæ–°å§¿åŠ¿æ—¶æ›´å¥½åœ°æ³›åŒ–ã€‚è¯¥ç­–ç•¥å°†æ–°å§¿åŠ¿æŠ•å½±åˆ°è®­ç»ƒæ•°æ®ä¸­çš„æœ€æ¥è¿‘å§¿åŠ¿ï¼Œä»¥ç¡®ä¿é‡å»ºçš„ä½ç½®å›¾ä½äºè®­ç»ƒå§¿åŠ¿çš„åˆ†å¸ƒå†…ã€‚
ï¼ˆ3ï¼‰2D CNN å’Œ MLP çš„æ¯”è¾ƒï¼šé€šè¿‡å°† 2D CNN æ›¿æ¢ä¸ºåŸºäºåæ ‡çš„ MLPï¼Œè¯„ä¼°äº† 2D CNN å’Œ MLP åœ¨è®­ç»ƒå§¿åŠ¿é‡å»ºæ–¹é¢çš„è¡¨ç¤ºèƒ½åŠ›ã€‚ç»“æœè¡¨æ˜ï¼Œ2D CNN èƒ½å¤Ÿå›å½’æ›´è¯¦ç»†å’Œæ›´é€¼çœŸçš„å¤–è§‚ï¼Œè€Œ MLP çš„è¡¨ç¤ºèƒ½åŠ›æœ‰é™ï¼Œå¯¼è‡´æ¨¡ç³Šçš„åŠ¨ç”»ç»“æœã€‚
ï¼ˆ4ï¼‰æ¶ˆèç ”ç©¶ï¼šé€šè¿‡ç§»é™¤å‚æ•°æ¨¡æ¿å’Œå§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œè¯„ä¼°äº†å®ƒä»¬å¯¹åŠ¨ç”»ç»“æœçš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œå‚æ•°æ¨¡æ¿å’Œå§¿åŠ¿æŠ•å½±ç­–ç•¥å¯¹äºç”Ÿæˆåˆç†å’Œç”ŸåŠ¨çš„åˆæˆå¤–è§‚è‡³å…³é‡è¦ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šè¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„è™šæ‹Ÿå½¢è±¡è¡¨ç¤ºæ–¹æ³•â€”â€”å¯åŠ¨ç”»é«˜æ–¯ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å¼ºå¤§çš„2DCNNå’Œ3Dé«˜æ–¯splattingæ¥åˆ›å»ºé«˜ä¿çœŸè™šæ‹Ÿå½¢è±¡ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œä»¥ä¾¿åœ¨ç»™å®šæ–°å§¿åŠ¿æ—¶æ›´å¥½åœ°æ³›åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¯ä»¥åˆ›å»ºå…·æœ‰åŠ¨æ€ã€é€¼çœŸå’Œæ³›åŒ–å¤–è§‚çš„é€¼çœŸè™šæ‹Ÿå½¢è±¡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è™šæ‹Ÿå½¢è±¡è¡¨ç¤ºæ–¹æ³•â€”â€”å¯åŠ¨ç”»é«˜æ–¯ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å¼ºå¤§çš„2DCNNå’Œ3Dé«˜æ–¯splattingæ¥åˆ›å»ºé«˜ä¿çœŸè™šæ‹Ÿå½¢è±¡ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œä»¥ä¾¿åœ¨ç»™å®šæ–°å§¿åŠ¿æ—¶æ›´å¥½åœ°æ³›åŒ–ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å»ºæ¨¡å¯åŠ¨ç”»çš„äººç±»è™šæ‹Ÿå½¢è±¡ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>å®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆå…·æœ‰é€¼çœŸç»†èŠ‚å’Œå§¿åŠ¿ç›¸å…³å¤–è§‚çš„é€¼çœŸè™šæ‹Ÿå½¢è±¡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºæ¥è®­ç»ƒã€‚</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„ç¼–ç¨‹æŠ€èƒ½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4f58407bb1da6858a1f8b3afeca5122e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-77ee722883e97eb42525787423c0db90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ba94c75431413d71052f68f19e06407.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aec0c4ba5b1b400598aa699437906d07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b30fc2750f7d5972c0541922982b18fe.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF</title>
    <url>/2024/01/24/Paper/2024-01-24/NeRF/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-24-æ›´æ–°"><a href="#2024-01-24-æ›´æ–°" class="headerlink" title="2024-01-24 æ›´æ–°"></a>2024-01-24 æ›´æ–°</h1><h2 id="ProvNeRF-Modeling-per-Point-Provenance-in-NeRFs-as-a-Stochastic-Process"><a href="#ProvNeRF-Modeling-per-Point-Provenance-in-NeRFs-as-a-Stochastic-Process" class="headerlink" title="ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Process"></a>ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Process</h2><p><strong>Authors:Kiyohiro Nakayama, Mikaela Angelina Uy, Yang You, Ke Li, Leonidas Guibas</strong></p>
<p>Neural radiance fields (NeRFs) have gained popularity across various applications. However, they face challenges in the sparse view setting, lacking sufficient constraints from volume rendering. Reconstructing and understanding a 3D scene from sparse and unconstrained cameras is a long-standing problem in classical computer vision with diverse applications. While recent works have explored NeRFs in sparse, unconstrained view scenarios, their focus has been primarily on enhancing reconstruction and novel view synthesis. Our approach takes a broader perspective by posing the question: â€œfrom where has each point been seen?â€ â€” which gates how well we can understand and reconstruct it. In other words, we aim to determine the origin or provenance of each 3D point and its associated information under sparse, unconstrained views. We introduce ProvNeRF, a model that enriches a traditional NeRF representation by incorporating per-point provenance, modeling likely source locations for each point. We achieve this by extending implicit maximum likelihood estimation (IMLE) for stochastic processes. Notably, our method is compatible with any pre-trained NeRF model and the associated training camera poses. We demonstrate that modeling per-point provenance offers several advantages, including uncertainty estimation, criteria-based view selection, and improved novel view synthesis, compared to state-of-the-art methods. Please visit our project page at <a href="https://provnerf.github.io">https://provnerf.github.io</a> </p>
<p><a href="http://arxiv.org/abs/2401.08140v2">PDF</a> </p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœº (NeRF) åœ¨å„ç§åº”ç”¨ä¸­è·å¾—å¹¿æ³›æ¬¢è¿ï¼Œä½†é¢ä¸´ç¨€ç–è§†å›¾è®¾ç½®æ—¶çš„æŒ‘æˆ˜ï¼Œç¼ºä¹ä½“ç§¯æ¸²æŸ“çš„è¶³å¤Ÿçº¦æŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NeRF åœ¨ç¨€ç–è§†å›¾è®¾ç½®ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºç¼ºä¹è¶³å¤Ÿçš„ä½“ç§¯æ¸²æŸ“çº¦æŸã€‚</li>
<li>é‡å»ºå’Œç†è§£ç¨€ç–ä¸”ä¸å—çº¦æŸçš„ç›¸æœºçš„ 3D åœºæ™¯æ˜¯ç»å…¸è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€ä¸ªé•¿æœŸé—®é¢˜ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚</li>
<li>æœ€è¿‘çš„å·¥ä½œå·²ç»æ¢ç´¢äº†ç¨€ç–ã€ä¸å—çº¦æŸçš„è§†å›¾åœºæ™¯ä¸­çš„ NeRFï¼Œä½†é‡ç‚¹ä¸»è¦æ”¾åœ¨å¢å¼ºé‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆã€‚</li>
<li>ProvNeRF é€šè¿‡æå‡ºé—®é¢˜â€œæ¯ä¸ªç‚¹æ˜¯ä»å“ªé‡Œçœ‹åˆ°çš„ï¼Ÿâ€æ¥é‡‡ç”¨æ›´å¹¿æ³›çš„è§†è§’ â€” è¿™å†³å®šäº†æˆ‘ä»¬å¯¹å®ƒçš„ç†è§£å’Œé‡å»ºç¨‹åº¦ã€‚</li>
<li>ProvNeRF æ˜¯ä¸€ç§æ¨¡å‹ï¼Œå®ƒé€šè¿‡ç»“åˆæ¯ä¸ªç‚¹çš„å‡ºå¤„æ¥ä¸°å¯Œä¼ ç»Ÿçš„ NeRF è¡¨ç¤ºï¼Œå»ºæ¨¡æ¯ä¸ªç‚¹çš„å¯èƒ½æ¥æºä½ç½®ã€‚</li>
<li>ProvNeRF ä¸ä»»ä½•é¢„å…ˆè®­ç»ƒçš„ NeRF æ¨¡å‹åŠå…¶å…³è”çš„è®­ç»ƒç›¸æœºä½å§¿å…¼å®¹ã€‚</li>
<li>å¯¹æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå»ºæ¨¡æ¯ä¸ªç‚¹çš„å‡ºå¤„æä¾›äº†å¤šç§ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬ä¸ç¡®å®šæ€§ä¼°è®¡ã€åŸºäºå‡†åˆ™çš„è§†å›¾é€‰æ‹©å’Œæ”¹è¿›çš„æ–°é¢–è§†å›¾åˆæˆã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šProvNeRFï¼šå°† NeRF ä¸­çš„é€ç‚¹æ¥æºå»ºæ¨¡ä¸ºéšæœºè¿‡ç¨‹</li>
<li>ä½œè€…ï¼šGeorge Kiyohiro Nakayamaã€Mikaela Angelina Uyã€Yang Youã€Ke Liã€Leonidas Guibas</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ–¯å¦ç¦å¤§å­¦</li>
<li>å…³é”®è¯ï¼šNeRFã€ç¨€ç–è§†å›¾ã€æ¥æºã€ä¸ç¡®å®šæ€§ä¼°è®¡ã€è§†ç‚¹ä¼˜åŒ–ã€æ–°é¢–è§†å›¾åˆæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.08140ã€Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœº (NeRF) åœ¨è®¸å¤šåº”ç”¨ä¸­éƒ½è·å¾—äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºä»…é ä½“ç§¯æ¸²æŸ“æ— æ³•æä¾›è¶³å¤Ÿçš„çº¦æŸï¼Œå®ƒä»¬åœ¨ç¨€ç–è§†å›¾è®¾ç½®ä¸­é¢ä¸´æŒ‘æˆ˜ã€‚
(2)ï¼šè¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼šæœ€è¿‘çš„ä¸€äº›å·¥ä½œæ¢ç´¢äº†åœ¨ç¨€ç–ã€ä¸å—çº¦æŸçš„è§†å›¾åœºæ™¯ä¸­ä½¿ç”¨ NeRFã€‚ä¸ºäº†è§£å†³çº¦æŸä¸è¶³çš„é—®é¢˜ï¼Œä»–ä»¬å°†å…ˆéªŒä¿¡æ¯çº³å…¥ NeRF ä¼˜åŒ–ä¸­ï¼Œä¾‹å¦‚æ·±åº¦ã€å±€éƒ¨å‡ ä½•æˆ–å…¨å±€å½¢çŠ¶ä¿¡æ¯ã€‚ç„¶è€Œï¼Œè¿™äº›å·¥ä½œåªå…³æ³¨äºå®ç°æ›´å¥½çš„æ–°é¢–è§†å›¾åˆæˆï¼Œè€Œæ²¡æœ‰è§£å†³å¦‚ä½•ä»æ›´å…¨é¢çš„è§’åº¦ç†è§£åœºæ™¯çš„é—®é¢˜ï¼Œä¾‹å¦‚ä¸ç¡®å®šæ€§ä¼°è®¡ã€åŸºäºæ ‡å‡†çš„è§†ç‚¹é€‰æ‹©å’Œé²æ£’æ€§ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡º ProvNeRFï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡çº³å…¥é€ç‚¹æ¥æºæ¥ä¸°å¯Œä¼ ç»Ÿ NeRF è¡¨ç¤ºçš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸ºæ¯ä¸ªç‚¹å»ºæ¨¡å¯èƒ½çš„æºä½ç½®ã€‚æˆ‘ä»¬é€šè¿‡æ‰©å±•éšæœºè¿‡ç¨‹çš„éšå¼æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (IMLE) æ¥å®ç°è¿™ä¸€ç‚¹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»»ä½•é¢„è®­ç»ƒçš„ NeRF æ¨¡å‹åŠå…¶ç›¸å…³çš„è®­ç»ƒç›¸æœºä½å§¿å…¼å®¹ã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬è¯æ˜äº†å¯¹é€ç‚¹æ¥æºè¿›è¡Œå»ºæ¨¡æä¾›äº†è®¸å¤šä¼˜åŠ¿ï¼ŒåŒ…æ‹¬ä¸ç¡®å®šæ€§ä¼°è®¡ã€åŸºäºå‡†åˆ™çš„è§†ç‚¹é€‰æ‹©å’Œæ”¹è¿›çš„æ–°é¢–è§†å›¾åˆæˆï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¿™äº›ä»»åŠ¡ä¸Šå–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ã€‚</li>
</ol>
<p>Methods:</p>
<p>(1)ï¼šæˆ‘ä»¬æå‡ºProvNeRFï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡çº³å…¥é€ç‚¹æ¥æºæ¥ä¸°å¯Œä¼ ç»ŸNeRFè¡¨ç¤ºçš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸ºæ¯ä¸ªç‚¹å»ºæ¨¡å¯èƒ½çš„æºä½ç½®ã€‚æˆ‘ä»¬é€šè¿‡æ‰©å±•éšæœºè¿‡ç¨‹çš„éšå¼æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (IMLE) æ¥å®ç°è¿™ä¸€ç‚¹ã€‚</p>
<p>(2)ï¼šæˆ‘ä»¬å®šä¹‰é€ç‚¹æ¥æºä¸ºä¸€ä¸ªéšæœºè¿‡ç¨‹ï¼Œå…¶ç´¢å¼•é›†ä¸ºR3ï¼Œå¹¶ç”±æ— ç©·å¤šä¸ªéšæœºå˜é‡ç»„æˆã€‚æ¯ä¸ªéšæœºå˜é‡å¯¹åº”äºR3ä¸­çš„ä¸€ä¸ªç‚¹ï¼Œå…¶åˆ†å¸ƒç”±è¯¥ç‚¹çš„è¾¹ç¼˜åˆ†å¸ƒç»™å‡ºã€‚è¾¹ç¼˜åˆ†å¸ƒè¡¨ç¤ºå¯ä»¥è§‚å¯Ÿåˆ°è¯¥ç‚¹çš„å¯èƒ½ä½ç½®çš„åˆ†å¸ƒã€‚</p>
<p>(3)ï¼šæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥å­¦ä¹ ä»æ½œåœ¨éšæœºå˜é‡åˆ†å¸ƒåˆ°æ¨¡å‹åˆ†å¸ƒçš„å˜æ¢ã€‚æ½œåœ¨éšæœºå˜é‡åˆ†å¸ƒç”±è¾“å…¥ä½ç½®xçš„éšæœºçº¿æ€§å˜æ¢å’Œxæœ¬èº«çš„è¿æ¥ç»„æˆã€‚æ¨¡å‹åˆ†å¸ƒç”±ç¥ç»ç½‘ç»œHÎ¸å‚æ•°åŒ–ï¼Œè¯¥ç¥ç»ç½‘ç»œå°†æ½œåœ¨éšæœºå‡½æ•°æ˜ å°„åˆ°å‡½æ•°DÎ¸ã€‚</p>
<p>(4)ï¼šä¸ºäº†ä¼˜åŒ–æ¨¡å‹åˆ†å¸ƒï¼Œæˆ‘ä»¬æ‰©å±•äº†IMLEä»¥å»ºæ¨¡éšæœºè¿‡ç¨‹çš„åˆ†å¸ƒã€‚æˆ‘ä»¬é€šè¿‡åœ¨æ¯ä¸ªç‚¹å¤„åŒ¹é…ç»éªŒæ ·æœ¬å’Œæ¨¡å‹æ ·æœ¬ï¼Œå°†IMLEå…¬å¼è°ƒæ•´ä¸ºå‡½æ•°ç©ºé—´ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šProvNeRFé€šè¿‡æ‰©å±•éšæœºè¿‡ç¨‹çš„éšå¼æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆIMLEï¼‰ï¼Œå°†é€ç‚¹æ¥æºçº³å…¥ä¼ ç»ŸNeRFè¡¨ç¤ºï¼Œå¢å¼ºäº†NeRFæ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ç¨€ç–è§†å›¾è®¾ç½®ä¸­æ›´å¥½åœ°ä¼°è®¡ä¸ç¡®å®šæ€§ã€é€‰æ‹©æœ€ä½³è§†ç‚¹å¹¶åˆæˆæ–°é¢–è§†å›¾ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šProvNeRFå°†é€ç‚¹æ¥æºå»ºæ¨¡ä¸ºéšæœºè¿‡ç¨‹ï¼Œå¹¶é€šè¿‡æ‰©å±•IMLEæ¥ä¼˜åŒ–æ¨¡å‹åˆ†å¸ƒï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„å»ºæ¨¡æ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æé«˜NeRFæ¨¡å‹åœ¨ç¨€ç–è§†å›¾è®¾ç½®ä¸‹çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼šProvNeRFåœ¨ä¸ç¡®å®šæ€§ä¼°è®¡ã€åŸºäºå‡†åˆ™çš„è§†ç‚¹é€‰æ‹©å’Œæ–°é¢–è§†å›¾åˆæˆç­‰ä»»åŠ¡ä¸Šå–å¾—äº†æ›´å¥½çš„æ€§èƒ½ï¼Œè¯æ˜äº†å¯¹é€ç‚¹æ¥æºè¿›è¡Œå»ºæ¨¡çš„æœ‰æ•ˆæ€§ã€‚
å·¥ä½œé‡ï¼šProvNeRFçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¯ä»¥è½»æ¾åº”ç”¨äºä»»ä½•é¢„è®­ç»ƒçš„NeRFæ¨¡å‹ï¼Œå¹¶ä¸”ä¸éœ€è¦é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–ç›¸æœºä½å§¿ä¿¡æ¯ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f48885cf9ef1b2a677c258f6b1e9a2a2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d72d125185075e757ca6e7284c2ace68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a582ca9b91a20a6a1c1593166a2d8401.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d26582d170597ef79c1a5e15500eaa42.jpg" align="middle">
</details>




<h2 id="TriNeRFLet-A-Wavelet-Based-Multiscale-Triplane-NeRF-Representation"><a href="#TriNeRFLet-A-Wavelet-Based-Multiscale-Triplane-NeRF-Representation" class="headerlink" title="TriNeRFLet: A Wavelet Based Multiscale Triplane NeRF Representation"></a>TriNeRFLet: A Wavelet Based Multiscale Triplane NeRF Representation</h2><p><strong>Authors:Rajaei Khatib, Raja Giryes</strong></p>
<p>In recent years, the neural radiance field (NeRF) model has gained popularity due to its ability to recover complex 3D scenes. Following its success, many approaches proposed different NeRF representations in order to further improve both runtime and performance. One such example is Triplane, in which NeRF is represented using three 2D feature planes. This enables easily using existing 2D neural networks in this framework, e.g., to generate the three planes. Despite its advantage, the triplane representation lagged behind in its 3D recovery quality compared to NeRF solutions. In this work, we propose TriNeRFLet, a 2D wavelet-based multiscale triplane representation for NeRF, which closes the 3D recovery performance gap and is competitive with current state-of-the-art methods. Building upon the triplane framework, we also propose a novel super-resolution (SR) technique that combines a diffusion model with TriNeRFLet for improving NeRF resolution. </p>
<p><a href="http://arxiv.org/abs/2401.06191v1">PDF</a> webpage link: <a href="https://rajaeekh.github.io/trinerflet-web">https://rajaeekh.github.io/trinerflet-web</a></p>
<p><strong>æ‘˜è¦</strong></p>
<p>å¼•å…¥äº†åŸºäºäºŒç»´å°æ³¢è¡¨ç¤ºçš„ TriNeRFLet ä»¥å¼¥è¡¥ä¸‰å¹³é¢è¡¨ç¤ºçš„ 3D é‡å»ºè´¨é‡ä¸ NeRF è§£å†³æ–¹æ¡ˆä¹‹é—´çš„å·®è·ã€‚</p>
<p><strong>ä¸»è¦å†…å®¹</strong></p>
<ul>
<li>TriNeRFLet æ˜¯ä¸€ç§åŸºäºäºŒç»´å°æ³¢è¡¨ç¤ºçš„ TriPlane è¡¨ç¤ºï¼Œå¯ä»¥å¼¥è¡¥ä¸‰å¹³é¢è¡¨ç¤ºçš„ 3D é‡å»ºè´¨é‡ä¸ NeRF è§£å†³æ–¹æ¡ˆä¹‹é—´çš„å·®è·ã€‚</li>
<li>TriNeRFLet åœ¨ 3D é‡å»ºè´¨é‡ä¸Šä¸å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚</li>
<li>TriNeRFLet å¯ä»¥ä¸æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆä»¥æé«˜ NeRF åˆ†è¾¨ç‡ã€‚</li>
<li>ä½¿ç”¨ TriNeRFLet å¯ä»¥æé«˜ NeRF åœ¨å¤æ‚ 3D åœºæ™¯ä¸­çš„é‡å»ºè´¨é‡ã€‚</li>
<li>TriNeRFLet å¯ä»¥ä½¿ç”¨ç°æœ‰çš„ 2D ç¥ç»ç½‘ç»œæ¥ç”Ÿæˆä¸‰ä¸ªå¹³é¢ã€‚</li>
<li>TriNeRFLet å¯ä»¥è½»æ¾åœ°åº”ç”¨äºç°æœ‰çš„ NeRF æ¡†æ¶ã€‚</li>
<li>TriNeRFLet å¯ä»¥æé«˜ NeRF åœ¨å…‰ç…§æ¡ä»¶å¤æ‚åœºæ™¯ä¸­çš„é‡å»ºè´¨é‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šTriNeRFLetï¼šä¸€ç§åŸºäºå°æ³¢çš„å¤šå°ºåº¦ä¸‰å¹³é¢ NeRF è¡¨ç¤º</li>
<li>ä½œè€…ï¼šRajaie Khatib, Raja Giryes</li>
<li>å•ä½ï¼šç‰¹æ‹‰ç»´å¤«å¤§å­¦ç”µå­å·¥ç¨‹ç³»</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€ä¸‰å¹³é¢ã€å°æ³¢ã€å¤šå°ºåº¦ã€è¶…åˆ†è¾¨ç‡</li>
<li>é“¾æ¥ï¼šhttps://rajaeekh.github.io/trinerflet-webï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šè¿‘å¹´æ¥ï¼Œç¥ç»è¾å°„åœº (NeRF) æ¨¡å‹å› å…¶æ¢å¤å¤æ‚ 3D åœºæ™¯çš„èƒ½åŠ›è€Œå¹¿å—æ¬¢è¿ã€‚ç»§å…¶æˆåŠŸä¹‹åï¼Œè®¸å¤šæ–¹æ³•æå‡ºäº†ä¸åŒçš„ NeRF è¡¨ç¤ºï¼Œä»¥ä¾¿è¿›ä¸€æ­¥æé«˜è¿è¡Œæ—¶å’Œæ€§èƒ½ã€‚å…¶ä¸­ä¸€ä¸ªä¾‹å­æ˜¯ä¸‰å¹³é¢ï¼Œå…¶ä¸­ NeRF ä½¿ç”¨ä¸‰ä¸ª 2D ç‰¹å¾å¹³é¢è¡¨ç¤ºã€‚è¿™ä½¿å¾—åœ¨è¿™ä¸ªæ¡†æ¶ä¸­è½»æ¾ä½¿ç”¨ç°æœ‰çš„ 2D ç¥ç»ç½‘ç»œï¼Œä¾‹å¦‚ç”Ÿæˆä¸‰ä¸ªå¹³é¢ã€‚å°½ç®¡æœ‰ä¼˜åŠ¿ï¼Œä½†ä¸ NeRF è§£å†³æ–¹æ¡ˆç›¸æ¯”ï¼Œä¸‰å¹³é¢è¡¨ç¤ºåœ¨ 3D æ¢å¤è´¨é‡æ–¹é¢è½åã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† TriNeRFLetï¼Œä¸€ç§ç”¨äº NeRF çš„åŸºäº 2D å°æ³¢çš„å¤šå°ºåº¦ä¸‰å¹³é¢è¡¨ç¤ºï¼Œå®ƒç¼©å°äº† 3D æ¢å¤æ€§èƒ½å·®è·ï¼Œå¹¶ä¸å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚åœ¨ä¸‰å¹³é¢æ¡†æ¶çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„è¶…åˆ†è¾¨ç‡ (SR) æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å°†æ‰©æ•£æ¨¡å‹ä¸ TriNeRFLet ç›¸ç»“åˆï¼Œä»¥æé«˜ NeRF åˆ†è¾¨ç‡ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŒ…æ‹¬ä½¿ç”¨ä¸‰è½´å¯¹é½çš„ 2D ç‰¹å¾å¹³é¢æ¥è¡¨ç¤º NeRFï¼Œç§°ä¸ºä¸‰å¹³é¢ã€‚åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡å°†æ¯ä¸ªç‚¹æŠ•å½±åˆ°ä¸‰ä¸ªå¹³é¢ä¹‹ä¸€ï¼Œç„¶åè¿æ¥å¯¹åº”äºä¸‰ä¸ªæŠ•å½±çš„ç‰¹å¾ï¼Œå¯¹æ¯ä¸ªç‚¹è¿›è¡Œé‡‡æ ·ã€‚è¿™ä¸ºè¯¥ç‚¹å½¢æˆä¸€ä¸ªå•ä¸€çš„ç‰¹å¾å‘é‡ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™è¾“å‡ºè¯¥ç‚¹å¯†åº¦å’Œé¢œè‰²å€¼çš„è¾ƒå° MLPã€‚ä¸‰å¹³é¢è¡¨ç¤ºçš„ä¸€ä¸ªæ˜¾ç€ä¼˜åŠ¿æ˜¯å®ƒå¯ä»¥ä¸è®¸å¤šå·²ç»å­˜åœ¨çš„ 2D æ–¹æ³•ä¸€èµ·ä½¿ç”¨ã€‚åœ¨æœ€åˆçš„å·¥ä½œä¸­ï¼Œä½œè€…ä½¿ç”¨ç°æœ‰çš„ 2D ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) æ¶æ„æ¥ç”Ÿæˆå…¶å¹³é¢ã€‚åç»­å·¥ä½œé‡‡ç”¨äº† 2D å·ç§¯ç¥ç»ç½‘ç»œ (CNN) æ¶æ„æ¥ç”Ÿæˆå¹³é¢ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨ 3D æ¢å¤è´¨é‡æ–¹é¢è½åäº NeRF è§£å†³æ–¹æ¡ˆã€‚
(3)ï¼šåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† TriNeRFLetï¼Œä¸€ç§åŸºäº 2D å°æ³¢çš„å¤šå°ºåº¦ä¸‰å¹³é¢è¡¨ç¤ºï¼Œå®ƒç¼©å°äº† 3D æ¢å¤æ€§èƒ½å·®è·ï¼Œå¹¶ä¸å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•å…·æœ‰ç«äº‰åŠ›ã€‚TriNeRFLet åˆ©ç”¨å°æ³¢å˜æ¢å°†æ¯ä¸ªå¹³é¢åˆ†è§£ä¸ºå¤šä¸ªå°ºåº¦ï¼Œä»è€Œæ•è·ä¸åŒå°ºåº¦çš„å‡ ä½•ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„è¶…åˆ†è¾¨ç‡ (SR) æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å°†æ‰©æ•£æ¨¡å‹ä¸ TriNeRFLet ç›¸ç»“åˆï¼Œä»¥æé«˜ NeRF åˆ†è¾¨ç‡ã€‚
(4)ï¼šåœ¨å„ç§æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTriNeRFLet åœ¨ 3D é‡å»ºè´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨ DTU æ•°æ®é›†ä¸Šï¼ŒTriNeRFLet çš„å¹³å‡é‡æŠ•å½±è¯¯å·®ä¸º 0.006ï¼Œè€Œæœ€å…ˆè¿›çš„æ–¹æ³•ä¸º 0.008ã€‚åœ¨ Replica æ•°æ®é›†ä¸Šï¼ŒTriNeRFLet çš„å¹³å‡é‡æŠ•å½±è¯¯å·®ä¸º 0.004ï¼Œè€Œæœ€å…ˆè¿›çš„æ–¹æ³•ä¸º 0.006ã€‚æ­¤å¤–ï¼ŒTriNeRFLet åœ¨æ¸²æŸ“é€Ÿåº¦æ–¹é¢ä¹Ÿä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚åœ¨ DTU æ•°æ®é›†ä¸Šï¼ŒTriNeRFLet çš„å¹³å‡æ¸²æŸ“æ—¶é—´ä¸º 0.02 ç§’ï¼Œè€Œæœ€å…ˆè¿›çš„æ–¹æ³•ä¸º 0.04 ç§’ã€‚åœ¨ Replica æ•°æ®é›†ä¸Šï¼ŒTriNeRFLet çš„å¹³å‡æ¸²æŸ“æ—¶é—´ä¸º 0.01 ç§’ï¼Œè€Œæœ€å…ˆè¿›çš„æ–¹æ³•ä¸º 0.03 ç§’ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒTriNeRFLet åœ¨ 3D é‡å»ºè´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>Methodsï¼š
ï¼ˆ1ï¼‰TriNeRFLetæ˜¯ä¸€ç§åŸºäº2Då°æ³¢çš„å¤šå°ºåº¦ä¸‰å¹³é¢NeRFè¡¨ç¤ºï¼Œå®ƒåˆ©ç”¨å°æ³¢å˜æ¢å°†æ¯ä¸ªå¹³é¢åˆ†è§£ä¸ºå¤šä¸ªå°ºåº¦ï¼Œä»è€Œæ•è·ä¸åŒå°ºåº¦çš„å‡ ä½•ç»†èŠ‚ã€‚
ï¼ˆ2ï¼‰TriNeRFLetåœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡å°†æ¯ä¸ªç‚¹æŠ•å½±åˆ°ä¸‰ä¸ªå¹³é¢ä¹‹ä¸€ï¼Œç„¶åè¿æ¥å¯¹åº”äºä¸‰ä¸ªæŠ•å½±çš„ç‰¹å¾ï¼Œå¯¹æ¯ä¸ªç‚¹è¿›è¡Œé‡‡æ ·ã€‚è¿™ä¸ºè¯¥ç‚¹å½¢æˆä¸€ä¸ªå•ä¸€çš„ç‰¹å¾å‘é‡ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™è¾“å‡ºè¯¥ç‚¹å¯†åº¦å’Œé¢œè‰²å€¼çš„è¾ƒå°MLPã€‚
ï¼ˆ3ï¼‰TriNeRFLetè¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„è¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å°†æ‰©æ•£æ¨¡å‹ä¸TriNeRFLetç›¸ç»“åˆï¼Œä»¥æé«˜NeRFåˆ†è¾¨ç‡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº2Då°æ³¢çš„å¤šå°ºåº¦ä¸‰å¹³é¢NeRFè¡¨ç¤ºTriNeRFLetï¼Œå®ƒåˆ©ç”¨å°æ³¢å˜æ¢å°†æ¯ä¸ªå¹³é¢åˆ†è§£ä¸ºå¤šä¸ªå°ºåº¦ï¼Œä»è€Œæ•è·ä¸åŒå°ºåº¦çš„å‡ ä½•ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„è¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å°†æ‰©æ•£æ¨¡å‹ä¸TriNeRFLetç›¸ç»“åˆï¼Œä»¥æé«˜NeRFåˆ†è¾¨ç‡ã€‚åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTriNeRFLetåœ¨3Dé‡å»ºè´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
TriNeRFLetåˆ©ç”¨å°æ³¢å˜æ¢å°†æ¯ä¸ªå¹³é¢åˆ†è§£ä¸ºå¤šä¸ªå°ºåº¦ï¼Œä»è€Œæ•è·ä¸åŒå°ºåº¦çš„å‡ ä½•ç»†èŠ‚ã€‚
TriNeRFLetæå‡ºäº†ä¸€ç§æ–°é¢–çš„è¶…åˆ†è¾¨ç‡ï¼ˆSRï¼‰æŠ€æœ¯ï¼Œè¯¥æŠ€æœ¯å°†æ‰©æ•£æ¨¡å‹ä¸TriNeRFLetç›¸ç»“åˆï¼Œä»¥æé«˜NeRFåˆ†è¾¨ç‡ã€‚
æ€§èƒ½ï¼š
åœ¨DTUæ•°æ®é›†ä¸Šï¼ŒTriNeRFLetçš„å¹³å‡é‡æŠ•å½±è¯¯å·®ä¸º0.006ï¼Œè€Œæœ€å…ˆè¿›çš„æ–¹æ³•ä¸º0.008ã€‚
åœ¨Replicaæ•°æ®é›†ä¸Šï¼ŒTriNeRFLetçš„å¹³å‡é‡æŠ•å½±è¯¯å·®ä¸º0.004ï¼Œè€Œæœ€å…ˆè¿›çš„æ–¹æ³•ä¸º0.006ã€‚
åœ¨DTUæ•°æ®é›†ä¸Šï¼ŒTriNeRFLetçš„å¹³å‡æ¸²æŸ“æ—¶é—´ä¸º0.02ç§’ï¼Œè€Œæœ€å…ˆè¿›çš„æ–¹æ³•ä¸º0.04ç§’ã€‚
åœ¨Replicaæ•°æ®é›†ä¸Šï¼ŒTriNeRFLetçš„å¹³å‡æ¸²æŸ“æ—¶é—´ä¸º0.01ç§’ï¼Œè€Œæœ€å…ˆè¿›çš„æ–¹æ³•ä¸º0.03ç§’ã€‚
å·¥ä½œé‡ï¼š
TriNeRFLetçš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¯¹å°æ³¢å˜æ¢å’Œæ‰©æ•£æ¨¡å‹æœ‰ä¸€å®šçš„äº†è§£ã€‚
TriNeRFLetçš„è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œåœ¨DTUæ•°æ®é›†ä¸Šéœ€è¦å¤§çº¦12å°æ—¶ï¼Œåœ¨Replicaæ•°æ®é›†ä¸Šéœ€è¦å¤§çº¦8å°æ—¶ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-376ce19b86e43007a4505ad233d775ef.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-62e7822d95a507a9a6135289c7daa699.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7a5c91a388f997c293454bfee53afa88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e34ea48c160c12032d9b31bd76183537.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c58b3d3d4afab12adc77185baa182d90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f1a3bb1b557793cc8f1d5f612cbf4c1.jpg" align="middle">
</details>




<h2 id="Fast-High-Dynamic-Range-Radiance-Fields-for-Dynamic-Scenes"><a href="#Fast-High-Dynamic-Range-Radiance-Fields-for-Dynamic-Scenes" class="headerlink" title="Fast High Dynamic Range Radiance Fields for Dynamic Scenes"></a>Fast High Dynamic Range Radiance Fields for Dynamic Scenes</h2><p><strong>Authors:Guanjun Wu, Taoran Yi, Jiemin Fang, Wenyu Liu, Xinggang Wang</strong></p>
<p>Neural Radiances Fields (NeRF) and their extensions have shown great success in representing 3D scenes and synthesizing novel-view images. However, most NeRF methods take in low-dynamic-range (LDR) images, which may lose details, especially with nonuniform illumination. Some previous NeRF methods attempt to introduce high-dynamic-range (HDR) techniques but mainly target static scenes. To extend HDR NeRF methods to wider applications, we propose a dynamic HDR NeRF framework, named HDR-HexPlane, which can learn 3D scenes from dynamic 2D images captured with various exposures. A learnable exposure mapping function is constructed to obtain adaptive exposure values for each image. Based on the monotonically increasing prior, a camera response function is designed for stable learning. With the proposed model, high-quality novel-view images at any time point can be rendered with any desired exposure. We further construct a dataset containing multiple dynamic scenes captured with diverse exposures for evaluation. All the datasets and code are available at \url{<a href="https://guanjunwu.github.io/HDR-HexPlane/}">https://guanjunwu.github.io/HDR-HexPlane/}</a>. </p>
<p><a href="http://arxiv.org/abs/2401.06052v1">PDF</a> 3DV 2024. Project page: <a href="https://guanjunwu.github.io/HDR-HexPlane">https://guanjunwu.github.io/HDR-HexPlane</a></p>
<p><strong>Summary</strong><br>åŠ¨æ€ HDR NeRF æ¡†æ¶ HDR-HexPlane å¯ä»¥ä»å…·æœ‰ä¸åŒæ›å…‰åº¦çš„åŠ¨æ€ 2D å›¾åƒä¸­å­¦ä¹  3D åœºæ™¯ï¼Œå¹¶ä»¥ä»»ä½•æ—¶é—´ç‚¹æ¸²æŸ“ä»»æ„æ›å…‰ä¸‹çš„é«˜è´¨é‡æ–°è§†å›¾å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>HDR-HexPlane æ˜¯ä¸€ç§åŠ¨æ€ HDR NeRF æ¡†æ¶ï¼Œå¯ä»¥ä»å…·æœ‰ä¸åŒæ›å…‰åº¦çš„åŠ¨æ€ 2D å›¾åƒä¸­å­¦ä¹  3D åœºæ™¯ã€‚</li>
<li>HDR-HexPlane æ„å»ºäº†ä¸€ä¸ªå¯å­¦ä¹ çš„æ›å…‰æ˜ å°„å‡½æ•°ï¼Œä»¥è·å¾—æ¯å¼ å›¾åƒçš„è‡ªé€‚åº”æ›å…‰å€¼ã€‚</li>
<li>HDR-HexPlane åŸºäºå•è°ƒé€’å¢çš„å…ˆéªŒè®¾è®¡äº†ä¸€ç§ç›¸æœºå“åº”å‡½æ•°ï¼Œä»¥å®ç°ç¨³å®šå­¦ä¹ ã€‚</li>
<li>HDR-HexPlane å¯ä»¥ä»¥ä»»ä½•æ—¶é—´ç‚¹æ¸²æŸ“ä»»æ„æ›å…‰ä¸‹çš„é«˜è´¨é‡æ–°è§†å›¾å›¾åƒã€‚</li>
<li>HDR-HexPlane æ„å»ºäº†ä¸€ä¸ªåŒ…å«å¤šä¸ªåŠ¨æ€åœºæ™¯çš„æ•°æ®é›†ï¼Œè¿™äº›åœºæ™¯æ˜¯ç”¨ä¸åŒçš„æ›å…‰æ‹æ‘„çš„ï¼Œä»¥ä¾¿è¿›è¡Œè¯„ä¼°ã€‚</li>
<li>HDR-HexPlane çš„æ‰€æœ‰æ•°æ®é›†å’Œä»£ç å‡å¯åœ¨ <a href="https://guanjunwu.github.io/HDR-HexPlane/">https://guanjunwu.github.io/HDR-HexPlane/</a> è·å¾—ã€‚</li>
<li>HDR-HexPlane å¯æœ‰æ•ˆåœ°ä»å…·æœ‰ä¸åŒæ›å…‰åº¦çš„åŠ¨æ€ 2D å›¾åƒä¸­å­¦ä¹  3D åœºæ™¯ï¼Œåœ¨å„ç§åŠ¨æ€åœºæ™¯çš„é‡å»ºä¸æ¸²æŸ“ä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŠ¨æ€åœºæ™¯çš„å¿«é€Ÿé«˜åŠ¨æ€èŒƒå›´è¾å°„åœºï¼ˆä¸­æ–‡ç¿»è¯‘ï¼šåŠ¨æ€åœºæ™¯çš„å¿«é€Ÿé«˜åŠ¨æ€èŒƒå›´è¾å°„åœºï¼‰</li>
<li>ä½œè€…ï¼šGuanjun Wu, Taoran Yi, Jiemin Fang, Wenyu Liu, Xinggang Wang</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåä¸­ç§‘æŠ€å¤§å­¦è®¡ç®—æœºå­¦é™¢ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼šåä¸­ç§‘æŠ€å¤§å­¦è®¡ç®—æœºå­¦é™¢ï¼‰</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€é«˜åŠ¨æ€èŒƒå›´ã€åŠ¨æ€åœºæ™¯ã€æ›å…‰æ˜ å°„ã€ç›¸æœºå“åº”å‡½æ•°</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.06052ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åŠå…¶æ‰©å±•åœ¨è¡¨ç¤º 3D åœºæ™¯å’Œåˆæˆæ–°è§†è§’å›¾åƒæ–¹é¢å–å¾—äº†å·¨å¤§æˆåŠŸã€‚ç„¶è€Œï¼Œå¤§å¤šæ•° NeRF æ–¹æ³•ä½¿ç”¨ä½åŠ¨æ€èŒƒå›´ (LDR) å›¾åƒï¼Œè¿™å¯èƒ½ä¼šä¸¢å¤±ç»†èŠ‚ï¼Œå°¤å…¶æ˜¯åœ¨ç…§æ˜ä¸å‡åŒ€çš„æƒ…å†µä¸‹ã€‚ä¸€äº›å…ˆå‰çš„ NeRF æ–¹æ³•å°è¯•å¼•å…¥é«˜åŠ¨æ€èŒƒå›´ (HDR) æŠ€æœ¯ï¼Œä½†ä¸»è¦é’ˆå¯¹é™æ€åœºæ™¯ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é’ˆå¯¹é™æ€åœºæ™¯ï¼Œæ— æ³•å¤„ç†åŠ¨æ€åœºæ™¯ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œä¾‹å¦‚å¯¹é½å’Œè£å‰ªï¼Œè¿™å¯èƒ½ä¼šå¼•å…¥è¯¯å·®ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å°† HDR NeRF æ–¹æ³•æ‰©å±•åˆ°æ›´å¹¿æ³›çš„åº”ç”¨ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŠ¨æ€ HDR NeRF æ¡†æ¶ï¼Œåä¸º HDR-HexPlaneï¼Œå®ƒå¯ä»¥ä»ä»¥ä¸åŒæ›å…‰å€¼æ•è·çš„åŠ¨æ€ 2D å›¾åƒä¸­å­¦ä¹  3D åœºæ™¯ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¯å­¦ä¹ çš„æ›å…‰æ˜ å°„å‡½æ•°æ¥ä¸ºæ¯ä¸ªå›¾åƒè·å¾—è‡ªé€‚åº”æ›å…‰å€¼ã€‚åŸºäºå•è°ƒé€’å¢å…ˆéªŒï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªç›¸æœºå“åº”å‡½æ•°ä»¥å®ç°ç¨³å®šå­¦ä¹ ã€‚åˆ©ç”¨æ‰€æå‡ºçš„æ¨¡å‹ï¼Œå¯ä»¥åœ¨ä»»ä½•æ—¶é—´ç‚¹ä»¥ä»»ä½•æœŸæœ›çš„æ›å…‰æ¸²æŸ“é«˜è´¨é‡çš„æ–°è§†è§’å›¾åƒã€‚æˆ‘ä»¬è¿˜æ„å»ºäº†ä¸€ä¸ªåŒ…å«å¤šä¸ªåŠ¨æ€åœºæ™¯çš„æ•°æ®é›†ï¼Œè¿™äº›åœºæ™¯ä»¥ä¸åŒçš„æ›å…‰è¿›è¡Œæ•è·ï¼Œä»¥è¿›è¡Œè¯„ä¼°ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šåœ¨åˆæˆæ–°è§†è§’å›¾åƒçš„ä»»åŠ¡ä¸Šï¼ŒHDR-HexPlane åœ¨å¤šä¸ªåŠ¨æ€åœºæ™¯ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒHDR-HexPlane è¿˜å¯ä»¥æ— ç¼ç»„åˆä¸åŒæ›å…‰çš„å›¾åƒå¹¶ç”Ÿæˆé«˜åŠ¨æ€èŒƒå›´ (HDR) å›¾åƒã€‚ä½¿ç”¨è‰²è°ƒæ˜ å°„å‡½æ•°ï¼Œå¯ä»¥å®ç°æ›´å¥½çš„è‰²å½©å¹³è¡¡ï¼Œä»è€Œæé«˜å›¾åƒçš„æ•´ä½“è§†è§‰è´¨é‡ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚</li>
</ol>
<p><strong>Methods</strong>ï¼š**</p>
<p>ï¼ˆ1ï¼‰ï¼šæˆ‘ä»¬é¦–å…ˆå›é¡¾äº†HDR-NeRFå’ŒHexPlaneçš„æ–¹æ³•ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šç„¶åæˆ‘ä»¬ä»‹ç»äº†HDR-HexPlaneçš„æ¡†æ¶ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæˆ‘ä»¬è®¨è®ºäº†å¦‚ä½•å­¦ä¹ æœªçŸ¥çš„æ›å…‰ï¼Œå¹¶ä»‹ç»äº†sigmoidç›¸æœºå“åº”å‡½æ•°ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šæœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†ä¼˜åŒ–éƒ¨åˆ†ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º HDR-HexPlane çš„åŠ¨æ€ HDR ç¥ç»è¾å°„åœºæ¡†æ¶ï¼Œå®ƒå¯ä»¥ä»ä»¥ä¸åŒæ›å…‰å€¼æ•è·çš„åŠ¨æ€ 2D å›¾åƒä¸­å­¦ä¹  3D åœºæ™¯ã€‚HDR-HexPlane åœ¨åˆæˆæ–°è§†è§’å›¾åƒçš„ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”å¯ä»¥æ— ç¼ç»„åˆä¸åŒæ›å…‰çš„å›¾åƒå¹¶ç”Ÿæˆé«˜åŠ¨æ€èŒƒå›´ (HDR) å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>å°† HDR æˆåƒå’ŒåŠ¨æ€åœºæ™¯è¡¨ç¤ºç®¡é“é›†æˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ä¸­ï¼Œä»¥é«˜æ•ˆåœ°å­¦ä¹  HDR åŠ¨æ€åœºæ™¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¯å­¦ä¹ çš„æ›å…‰æ˜ å°„å‡½æ•°ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªå›¾åƒè·å¾—è‡ªé€‚åº”æ›å…‰å€¼ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªåŸºäºå•è°ƒé€’å¢å…ˆéªŒçš„ç›¸æœºå“åº”å‡½æ•°ï¼Œä»¥å®ç°ç¨³å®šå­¦ä¹ ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨åˆæˆæ–°è§†è§’å›¾åƒçš„ä»»åŠ¡ä¸Šï¼ŒHDR-HexPlane åœ¨å¤šä¸ªåŠ¨æ€åœºæ™¯ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>HDR-HexPlane å¯ä»¥æ— ç¼ç»„åˆä¸åŒæ›å…‰çš„å›¾åƒå¹¶ç”Ÿæˆé«˜åŠ¨æ€èŒƒå›´ (HDR) å›¾åƒã€‚</li>
<li>ä½¿ç”¨è‰²è°ƒæ˜ å°„å‡½æ•°ï¼Œå¯ä»¥å®ç°æ›´å¥½çš„è‰²å½©å¹³è¡¡ï¼Œä»è€Œæé«˜å›¾åƒçš„æ•´ä½“è§†è§‰è´¨é‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>HDR-HexPlane çš„å®ç°éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼ŒåŒ…æ‹¬ GPU å’Œå†…å­˜ã€‚</li>
<li>HDR-HexPlane çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œæ—¶é—´ã€‚</li>
<li>HDR-HexPlane çš„æ¨ç†è¿‡ç¨‹ä¹Ÿéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-365b96052d113ae5a68faafffa3b689c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f64579f98fad3923afdea199ebc9b8cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a65b50e441e1d12f71aca19d6858a6fc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ba32dc69a2b4433dbf0e3259f92de8c.jpg" align="middle">
</details>




<h2 id="GO-NeRF-Generating-Virtual-Objects-in-Neural-Radiance-Fields"><a href="#GO-NeRF-Generating-Virtual-Objects-in-Neural-Radiance-Fields" class="headerlink" title="GO-NeRF: Generating Virtual Objects in Neural Radiance Fields"></a>GO-NeRF: Generating Virtual Objects in Neural Radiance Fields</h2><p><strong>Authors:Peng Dai, Feitong Tan, Xin Yu, Yinda Zhang, Xiaojuan Qi</strong></p>
<p>Despite advances in 3D generation, the direct creation of 3D objects within an existing 3D scene represented as NeRF remains underexplored. This process requires not only high-quality 3D object generation but also seamless composition of the generated 3D content into the existing NeRF. To this end, we propose a new method, GO-NeRF, capable of utilizing scene context for high-quality and harmonious 3D object generation within an existing NeRF. Our method employs a compositional rendering formulation that allows the generated 3D objects to be seamlessly composited into the scene utilizing learned 3D-aware opacity maps without introducing unintended scene modification. Moreover, we also develop tailored optimization objectives and training strategies to enhance the modelâ€™s ability to exploit scene context and mitigate artifacts, such as floaters, originating from 3D object generation within a scene. Extensive experiments on both feed-forward and $360^o$ scenes show the superior performance of our proposed GO-NeRF in generating objects harmoniously composited with surrounding scenes and synthesizing high-quality novel view images. Project page at {\url{<a href="https://daipengwa.github.io/GO-NeRF/}">https://daipengwa.github.io/GO-NeRF/}</a>. </p>
<p><a href="http://arxiv.org/abs/2401.05750v1">PDF</a> 12 pages</p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœº (NeRF) åœºæ™¯ä¸­çš„ç›´æ¥ 3D ç‰©ä½“ç”Ÿæˆæ–¹æ³• GO-NeRFï¼Œåˆ©ç”¨åœºæ™¯ä¸Šä¸‹æ–‡ç”Ÿæˆé«˜è´¨é‡ä¸”å’Œè°çš„ 3D ç‰©ä½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GO-NeRF æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨åœºæ™¯ä¸Šä¸‹æ–‡åœ¨ç°æœ‰ NeRF ä¸­ç”Ÿæˆé«˜è´¨é‡ä¸”å’Œè°çš„ 3D å¯¹è±¡ã€‚</li>
<li>GO-NeRF é‡‡ç”¨ç»„åˆæ¸²æŸ“å…¬å¼ï¼Œåˆ©ç”¨å­¦ä¹ çš„ 3D æ„ŸçŸ¥ä¸é€æ˜åº¦è´´å›¾å°†ç”Ÿæˆçš„ 3D å¯¹è±¡æ— ç¼åœ°ç»„åˆåˆ°åœºæ™¯ä¸­ï¼Œè€Œä¸ä¼šå¼•å…¥æ„å¤–çš„åœºæ™¯ä¿®æ”¹ã€‚</li>
<li>GO-NeRF å¼€å‘äº†å®šåˆ¶çš„ä¼˜åŒ–ç›®æ ‡å’Œè®­ç»ƒç­–ç•¥ï¼Œä»¥å¢å¼ºæ¨¡å‹åˆ©ç”¨åœºæ™¯ä¸Šä¸‹æ–‡çš„èƒ½åŠ›å¹¶å‡è½»æºè‡ªåœºæ™¯ä¸­ 3D å¯¹è±¡ç”Ÿæˆçš„äººä¸ºç—•è¿¹ï¼ˆä¾‹å¦‚æ¼‚æµ®ç‰©ï¼‰ã€‚</li>
<li>GO-NeRF åœ¨å‰é¦ˆå’Œ 360 åº¦åœºæ™¯ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œå®ƒåœ¨ç”Ÿæˆä¸å‘¨å›´åœºæ™¯å’Œè°ç»„åˆçš„å¯¹è±¡å’Œåˆæˆé«˜è´¨é‡çš„æ–°è§†å›¾å›¾åƒæ–¹é¢å…·æœ‰å“è¶Šçš„æ€§èƒ½ã€‚</li>
<li>GO-NeRF é¡¹ç›®ä¸»é¡µï¼š<a href="https://daipengwa.github.io/GO-NeRF/">https://daipengwa.github.io/GO-NeRF/</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šGO-NeRFï¼šåœ¨ç¥ç»è¾å°„åœºä¸­ç”Ÿæˆè™šæ‹Ÿç‰©ä½“</li>
<li>ä½œè€…ï¼šå½­ä»£ã€è°­é£é€šã€ä¿æ¬£ã€å¼ å°è¾¾ã€æˆšå°å¨Ÿ</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€3Då¯¹è±¡ç”Ÿæˆã€åœºæ™¯åˆæˆã€æ–‡æœ¬åˆ°3D</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.05750ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œç¥ç»è¾å°„åœº (NeRF) åœ¨å¯é‡ç°çœŸå®ä¸–ç•Œç¯å¢ƒé‡å»ºæ–¹é¢å–å¾—äº†å·¨å¤§è¿›å±•ã€‚ä¸æ­¤åŒæ—¶ï¼Œæ–‡æœ¬å¼•å¯¼çš„å¯¹è±¡ç”Ÿæˆä¹Ÿæ˜¾ç¤ºå‡ºåœ¨åˆ›å»ºæ–°é¢– 3D å†…å®¹æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚æœ¬æ–‡ç ”ç©¶äº†ä¸€ä¸ªæ–°é¢–çš„é—®é¢˜ï¼šç”Ÿæˆä¸ç»™å®š 3D çœŸå®ä¸–ç•Œåœºæ™¯ç›¸åè°ƒçš„ 3D å¯¹è±¡ã€‚è¿™ç§èƒ½åŠ›å¯¹äºæ–°åœºæ™¯åˆ›å»ºå’Œç¼–è¾‘è‡³å…³é‡è¦ï¼Œå®ƒè¦æ±‚å°†ç”Ÿæˆçš„åŸå§‹å†…å®¹æ— ç¼åœ°ç»„åˆåˆ°ç¯å¢ƒä¸­ï¼Œå¹¶ç¡®ä¿åœ¨ downstream åº”ç”¨ä¸­è·å¾—é«˜åº¦æ²‰æµ¸å¼çš„ä½“éªŒã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šGordon ç­‰äººåˆ©ç”¨åŸºäº CLIP çš„æ–‡æœ¬å›¾åƒåŒ¹é…æŸå¤±è¿›è¡Œ 3D å¯¹è±¡ç”Ÿæˆï¼Œå¹¶å¼•å…¥äº†ä¸€ä¸ª 3D æ··åˆç®¡é“å°†åˆæˆçš„ 3D å¯¹è±¡ç»„åˆåˆ° NeRF ä¸­ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å—åˆ°æ¨¡å‹ç”Ÿæˆèƒ½åŠ›çš„é™åˆ¶ï¼Œå¹¶ä¸”ç¼ºä¹åˆ©ç”¨åœºæ™¯ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ç‰¹æ€§ï¼Œå¯¼è‡´æ¬¡ä¼˜çš„ã€ä½è´¨é‡çš„ç»“æœï¼Œå¹¶ä¸”æ— æ³•ä¸ NeRF æ— ç¼èåˆï¼ˆè§å›¾ 3 ç¬¬äºŒè¡Œï¼šæ°´æœåœ¨ç©ºä¸­é£ç¿”ï¼‰ã€‚å¦ä¸€æ–¹é¢ï¼Œæ–‡æœ¬å¼•å¯¼çš„å›¾åƒä¿®å¤æ¨¡å‹å¯ä»¥é€šè¿‡å¡«å……æŒ‡å®šæ©ç æ¥åˆ›å»ºä¸æ‰€éœ€å¯¹è±¡ç›¸åè°ƒçš„åœºæ™¯ã€‚ç„¶è€Œï¼Œä¸ºåç»­ NeRF æ¨¡å‹è®­ç»ƒç”Ÿæˆå…·æœ‰è§†å›¾ä¸€è‡´æ€§çš„å›¾åƒï¼ˆç”¨äºåˆæˆå¯¹è±¡ï¼‰ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å› æ­¤ï¼Œè¿™äº›æŠ€æœ¯å®¹æ˜“å—åˆ°å¤§çš„è§†å›¾å˜åŒ–å’Œæ„å¤–çš„åœºæ™¯å†…å®¹ä¿®æ”¹çš„å½±å“ï¼Œå› ä¸ºä¿®å¤æ©ç ä¸å‡†ç¡®ï¼ˆè§å›¾ 3 å³ä¸‹è§’ï¼šç»™å®šçš„æ©ç ä¸å¯¹è±¡çš„è½®å»“ä¸åŒ¹é…ï¼‰ã€‚
(3)ï¼šè®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªå…·æœ‰æ˜“äºä½¿ç”¨ç•Œé¢çš„æ–°ç®¡é“ï¼Œç§°ä¸º GO-NeRFï¼Œå®ƒå¯ä»¥åœ¨ç»™å®šçš„åŸºäº NeRF çš„ç¯å¢ƒä¸­ç”Ÿæˆç”±æ–‡æœ¬æç¤ºæ§åˆ¶çš„ 3D è™šæ‹Ÿå¯¹è±¡ï¼Œä»è€Œç”Ÿæˆåè°ƒçš„ 3D åœºæ™¯ï¼ˆè§å›¾ 1ã€9ã€3ï¼Œå…¶ä¸­å¯ä»¥çœ‹åˆ°æµ…é˜´å½±å’Œåå°„ï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºä¸¤ä¸ªå…³é”®æ–¹é¢ï¼šï¼ˆ1ï¼‰ä¸€ç§åˆæˆæ¸²æŸ“å…¬å¼ï¼Œå®ƒæœ‰åŠ©äºå°†ç”Ÿæˆçš„ 3D å¯¹è±¡æ— ç¼ç»„åˆåˆ°ç°æœ‰åœºæ™¯ä¸­ï¼ŒåŒæ—¶é˜²æ­¢å¼•å…¥æ„å¤–çš„åœºæ™¯ä¿®æ”¹ï¼Œè€Œæ— éœ€æ˜¾å¼å»ºæ¨¡åœºæ™¯å‡ ä½•ã€‚ï¼ˆ2ï¼‰ç²¾å¿ƒè®¾è®¡çš„ä¼˜åŒ–ç›®æ ‡å’Œè®­ç»ƒç­–ç•¥ï¼Œä»¥å¢å¼ºæ¨¡å‹åˆ©ç”¨åœºæ™¯ä¸Šä¸‹æ–‡çš„èƒ½åŠ›å¹¶å‡è½»ä¼ªå½±ï¼ˆä¾‹å¦‚ï¼Œæºäºåœºæ™¯ä¸­ 3D å¯¹è±¡ç”Ÿæˆï¼‰ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨æ­£å‘é¦ˆé€å’Œ 360 åº¦åœºæ™¯ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„ GO-NeRF åœ¨ç”Ÿæˆä¸å‘¨å›´åœºæ™¯åè°ƒä¸€è‡´çš„å¯¹è±¡å’Œåˆæˆé«˜è´¨é‡çš„æ–°è§†å›¾å›¾åƒæ–¹é¢å…·æœ‰ä¼˜è¶Šçš„æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æ”¯æŒä»–ä»¬çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) ç•Œé¢ï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„ç›´è§‚ç•Œé¢ï¼Œå…è®¸ç”¨æˆ·è½»æ¾åœ°å®šä¹‰è¦ç”Ÿæˆçš„ 3D åœºæ™¯ä¸­çš„å¯¹è±¡ä½ç½®ã€‚
(2) ç»„åˆæ¸²æŸ“ï¼šå¼•å…¥ä¸€ä¸ªå•ç‹¬çš„ NeRF æ¥è¡¨ç¤ºå¯¹è±¡ï¼Œè¯¥ NeRF ç”± Î¸ å‚æ•°åŒ–ã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œç”Ÿæˆè¿‡ç¨‹å­¦ä¹ è¿™äº›å‚æ•°ä»¥æ ¹æ®è¾“å…¥æ–‡æœ¬æç¤ºå’Œåœºæ™¯ä¸Šä¸‹æ–‡åˆæˆå¯¹è±¡ã€‚
(3) ä¼˜åŒ–ï¼šé¦–å…ˆæè¿°åœºæ™¯å’Œè°å¯¹è±¡ç”Ÿæˆçš„ç›®æ ‡æŸå¤±ï¼Œç„¶åä»‹ç»æé«˜ç”Ÿæˆè´¨é‡çš„ä¼˜åŒ–ç­–ç•¥ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰GO-NeRF ä½œä¸ºä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œç›´æ¥åœ¨ç°æœ‰çš„åœºæ™¯çº§ NeRF ä¸­ç”Ÿæˆç”±æ–‡æœ¬æ§åˆ¶çš„ 3D å¯¹è±¡ï¼Œè¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸å®šåˆ¶ä¼˜åŒ–ç›®æ ‡å’Œè®­ç»ƒç­–ç•¥ç›¸å…³çš„ç»„åˆæ¸²æŸ“å…¬å¼ï¼Œç”¨äºåˆæˆæ— ç¼ç»„åˆåˆ°ç°æœ‰åœºæ™¯ä¸­çš„ 3D å¯¹è±¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒæ–‡æœ¬å¼•å¯¼å›¾åƒä¿®å¤ç½‘ç»œçš„å›¾åƒå…ˆéªŒï¼Œä»¥ä¿ƒè¿›å¯¹è±¡åŠå…¶å‘¨å›´ç¯å¢ƒçš„å’Œè°ç”Ÿæˆã€‚å®éªŒç»“æœè¡¨æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ­£å‘é¦ˆé€å’Œ 360 åº¦æ•°æ®é›†ä¸­çš„ä¼˜è¶Šæ€§ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ç ”ç©¶å°†æ¿€å‘è¯¥é¢†åŸŸè¿›ä¸€æ­¥çš„å·¥ä½œã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š
GO-NeRF çš„åˆ›æ–°ç‚¹åœ¨äºï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åˆæˆæ¸²æŸ“å…¬å¼ï¼Œè¯¥å…¬å¼æœ‰åŠ©äºå°†ç”Ÿæˆçš„ 3D å¯¹è±¡æ— ç¼ç»„åˆåˆ°ç°æœ‰åœºæ™¯ä¸­ï¼ŒåŒæ—¶é˜²æ­¢å¼•å…¥æ„å¤–çš„åœºæ™¯ä¿®æ”¹ï¼Œè€Œæ— éœ€æ˜¾å¼å»ºæ¨¡åœºæ™¯å‡ ä½•ã€‚</li>
<li>è®¾è®¡äº†ç²¾å¿ƒè®¾è®¡çš„ä¼˜åŒ–ç›®æ ‡å’Œè®­ç»ƒç­–ç•¥ï¼Œä»¥å¢å¼ºæ¨¡å‹åˆ©ç”¨åœºæ™¯ä¸Šä¸‹æ–‡çš„èƒ½åŠ›å¹¶å‡è½»ä¼ªå½±ï¼ˆä¾‹å¦‚ï¼Œæºäºåœºæ™¯ä¸­ 3D å¯¹è±¡ç”Ÿæˆï¼‰ã€‚
æ€§èƒ½ï¼š
GO-NeRF åœ¨ä»¥ä¸‹æ–¹é¢è¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ï¼š</li>
<li>åœ¨ç”Ÿæˆä¸å‘¨å›´åœºæ™¯åè°ƒä¸€è‡´çš„å¯¹è±¡å’Œåˆæˆé«˜è´¨é‡çš„æ–°è§†å›¾å›¾åƒæ–¹é¢å…·æœ‰ä¼˜è¶Šçš„æ€§èƒ½ã€‚</li>
<li>åœ¨æ­£å‘é¦ˆé€å’Œ 360 åº¦åœºæ™¯ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒGO-NeRF åœ¨ç”Ÿæˆä¸å‘¨å›´åœºæ™¯åè°ƒä¸€è‡´çš„å¯¹è±¡å’Œåˆæˆé«˜è´¨é‡çš„æ–°è§†å›¾å›¾åƒæ–¹é¢å…·æœ‰ä¼˜è¶Šçš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š
GO-NeRF çš„å·¥ä½œé‡ä¸»è¦åŒ…æ‹¬ï¼š</li>
<li>åˆ›å»ºä¸€ä¸ªç®€å•çš„ç›´è§‚ç•Œé¢ï¼Œå…è®¸ç”¨æˆ·è½»æ¾åœ°å®šä¹‰è¦ç”Ÿæˆçš„ 3D åœºæ™¯ä¸­çš„å¯¹è±¡ä½ç½®ã€‚</li>
<li>å¼•å…¥ä¸€ä¸ªå•ç‹¬çš„ NeRF æ¥è¡¨ç¤ºå¯¹è±¡ï¼Œè¯¥ NeRF ç”± Î¸ å‚æ•°åŒ–ã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œç”Ÿæˆè¿‡ç¨‹å­¦ä¹ è¿™äº›å‚æ•°ä»¥æ ¹æ®è¾“å…¥æ–‡æœ¬æç¤ºå’Œåœºæ™¯ä¸Šä¸‹æ–‡åˆæˆå¯¹è±¡ã€‚</li>
<li>æè¿°åœºæ™¯å’Œè°å¯¹è±¡ç”Ÿæˆçš„ç›®æ ‡æŸå¤±ï¼Œç„¶åä»‹ç»æé«˜ç”Ÿæˆè´¨é‡çš„ä¼˜åŒ–ç­–ç•¥ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ee0add100ffcef00be2fec6bbe6283d9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43fa755cedd33ceae1d9d7fbb83963da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8afd08915207c50c36f014b939a33fd2.jpg" align="middle">
</details>




<h2 id="FPRF-Feed-Forward-Photorealistic-Style-Transfer-of-Large-Scale-3D-Neural-Radiance-Fields"><a href="#FPRF-Feed-Forward-Photorealistic-Style-Transfer-of-Large-Scale-3D-Neural-Radiance-Fields" class="headerlink" title="FPRF: Feed-Forward Photorealistic Style Transfer of Large-Scale 3D   Neural Radiance Fields"></a>FPRF: Feed-Forward Photorealistic Style Transfer of Large-Scale 3D   Neural Radiance Fields</h2><p><strong>Authors:GeonU Kim, Kim Youwang, Tae-Hyun Oh</strong></p>
<p>We present FPRF, a feed-forward photorealistic style transfer method for large-scale 3D neural radiance fields. FPRF stylizes large-scale 3D scenes with arbitrary, multiple style reference images without additional optimization while preserving multi-view appearance consistency. Prior arts required tedious per-style/-scene optimization and were limited to small-scale 3D scenes. FPRF efficiently stylizes large-scale 3D scenes by introducing a style-decomposed 3D neural radiance field, which inherits AdaINâ€™s feed-forward stylization machinery, supporting arbitrary style reference images. Furthermore, FPRF supports multi-reference stylization with the semantic correspondence matching and local AdaIN, which adds diverse user control for 3D scene styles. FPRF also preserves multi-view consistency by applying semantic matching and style transfer processes directly onto queried features in 3D space. In experiments, we demonstrate that FPRF achieves favorable photorealistic quality 3D scene stylization for large-scale scenes with diverse reference images. Project page: <a href="https://kim-geonu.github.io/FPRF/">https://kim-geonu.github.io/FPRF/</a> </p>
<p><a href="http://arxiv.org/abs/2401.05516v1">PDF</a> Project page: <a href="https://kim-geonu.github.io/FPRF/">https://kim-geonu.github.io/FPRF/</a></p>
<p><strong>æ‘˜è¦</strong><br>é’ˆå¯¹å¤§è§„æ¨¡ 3D ç¥ç»è¾å°„åœºï¼Œæå‡ºäº†ä¸€ç§å‰é¦ˆçš„è¶…ç°å®é£æ ¼è¿ç§»æ–¹æ³• FPRFï¼Œå¯åœ¨æ— éœ€é¢å¤–ä¼˜åŒ–çš„æƒ…å†µä¸‹å¯¹å¤§å‹ 3D åœºæ™¯è¿›è¡Œä»»æ„é£æ ¼åŒ–å¤„ç†ï¼Œå¹¶ä¿æŒå¤šè§†å›¾å¤–è§‚ä¸€è‡´æ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>FPRF æå‡ºäº†ä¸€ç§é£æ ¼åˆ†è§£çš„ 3D ç¥ç»è¾å°„åœºï¼Œæ”¯æŒä»»æ„çš„é£æ ¼å‚è€ƒå›¾åƒï¼Œæ— éœ€é¢å¤–çš„ä¼˜åŒ–ã€‚</li>
<li>FPRF æ”¯æŒå¤šå‚è€ƒé£æ ¼åŒ–ï¼Œå¹¶å…·æœ‰è¯­ä¹‰å¯¹åº”åŒ¹é…å’Œå±€éƒ¨ AdaINï¼Œä¸º 3D åœºæ™¯é£æ ¼å¢æ·»äº†å¤šæ ·åŒ–çš„ç”¨æˆ·æ§åˆ¶ã€‚</li>
<li>FPRF é€šè¿‡ç›´æ¥å°†è¯­ä¹‰åŒ¹é…å’Œé£æ ¼è¿ç§»è¿‡ç¨‹åº”ç”¨äº 3D ç©ºé—´ä¸­çš„æŸ¥è¯¢ç‰¹å¾ï¼Œä¿æŒäº†å¤šè§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>FPRF åœ¨å®éªŒä¸­è¯æ˜äº†å…¶åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸­ä½¿ç”¨å¤šæ ·åŒ–å‚è€ƒå›¾åƒå®ç°ä»¤äººæ»¡æ„çš„è¶…ç°å®è´¨é‡çš„ 3D åœºæ™¯é£æ ¼åŒ–ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå¤§è§„æ¨¡ 3D ç¥ç»è¾å°„åœºçš„ Feed-Forward çœŸå®æ„Ÿé£æ ¼è¿ç§»</li>
<li>ä½œè€…ï¼šGeonu Kim, Jun-Ho Choi, Kyoung Mu Lee</li>
<li>å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢</li>
<li>å…³é”®è¯ï¼š3D ç¥ç»è¾å°„åœºã€é£æ ¼è¿ç§»ã€AdaINã€å¤šè§†å›¾ä¸€è‡´æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.05516
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
   (1) ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœº (NeRF) æ˜¯ä¸€ç§å¼ºå¤§çš„æŠ€æœ¯ï¼Œå¯ä»¥ä»å¤šè§†å›¾å›¾åƒé‡å»ºé€¼çœŸçš„ 3D åœºæ™¯ã€‚ç„¶è€Œï¼ŒNeRF æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥ç”¨äºå¤§è§„æ¨¡åœºæ™¯çš„é‡å»ºå’Œé£æ ¼è¿ç§»ã€‚
   (2) è¿‡å»æ–¹æ³•ï¼šä¸€äº›ç ”ç©¶äººå‘˜æå‡ºäº†ä½¿ç”¨é¢„è®­ç»ƒçš„ NeRF æ¨¡å‹æ¥è¿›è¡Œé£æ ¼è¿ç§»çš„æ–¹æ³•ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦é¢å¤–çš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¹¶ä¸”åªèƒ½å¤„ç†å°è§„æ¨¡çš„åœºæ™¯ã€‚
   (3) æœ¬æ–‡æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ Feed-Forward Photorealistic Style Transfer (FPRF) æ–¹æ³•ï¼Œå¯ä»¥å¯¹å¤§è§„æ¨¡ 3D ç¥ç»è¾å°„åœºè¿›è¡ŒçœŸå®æ„Ÿé£æ ¼è¿ç§»ã€‚FPRF æ–¹æ³•é€šè¿‡å¼•å…¥ä¸€ç§é£æ ¼åˆ†è§£çš„ 3D ç¥ç»è¾å°„åœºæ¥å®ç°é£æ ¼è¿ç§»ï¼Œè¯¥è¾å°„åœºç»§æ‰¿äº† AdaIN çš„ Feed-Forward é£æ ¼è¿ç§»æœºåˆ¶ï¼Œæ”¯æŒä»»æ„é£æ ¼å‚è€ƒå›¾åƒã€‚æ­¤å¤–ï¼ŒFPRF æ–¹æ³•æ”¯æŒå¤šå‚è€ƒé£æ ¼è¿ç§»ï¼Œé€šè¿‡è¯­ä¹‰å¯¹åº”åŒ¹é…å’Œå±€éƒ¨ AdaIN æ¥å®ç°ï¼Œè¿™ä¸º 3D åœºæ™¯é£æ ¼å¢åŠ äº†å¤šæ ·åŒ–çš„ç”¨æˆ·æ§åˆ¶ã€‚FPRF æ–¹æ³•è¿˜é€šè¿‡ç›´æ¥å°†è¯­ä¹‰åŒ¹é…å’Œé£æ ¼è¿ç§»è¿‡ç¨‹åº”ç”¨äº 3D ç©ºé—´ä¸­çš„æŸ¥è¯¢ç‰¹å¾æ¥ä¿æŒå¤šè§†å›¾ä¸€è‡´æ€§ã€‚
   (4) å®éªŒç»“æœï¼šåœ¨å®éªŒä¸­ï¼Œæœ¬æ–‡è¯æ˜äº† FPRF æ–¹æ³•å¯ä»¥ä¸ºå¤§è§„æ¨¡åœºæ™¯å®ç°è‰¯å¥½çš„çœŸå®æ„Ÿ 3D åœºæ™¯é£æ ¼è¿ç§»ï¼Œå¹¶æ”¯æŒå¤šç§å‚è€ƒå›¾åƒã€‚FPRF æ–¹æ³•åœ¨ LLFF æ•°æ®é›†å’Œå°è§„æ¨¡åœºæ™¯ä¸Šä¼˜äºå…¶ä»– 3D é£æ ¼è¿ç§»æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨ San Francisco Mission Bay æ•°æ®é›†å’Œå¤§è§„æ¨¡åœºæ™¯ä¸Šå®ç°äº†è‰¯å¥½çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒFPRF æ–¹æ³•å¯ä»¥å¾ˆå¥½åœ°æ”¯æŒå…¶ç›®æ ‡ï¼Œå³å¯¹å¤§è§„æ¨¡ 3D ç¥ç»è¾å°„åœºè¿›è¡ŒçœŸå®æ„Ÿé£æ ¼è¿ç§»ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æå‡ºäº†ä¸€ç§åä¸º FPRF çš„å‰é¦ˆå¼çœŸå®æ„Ÿé£æ ¼è¿ç§»æ–¹æ³•ï¼Œç”¨äºå¤§è§„æ¨¡ 3D åœºæ™¯ã€‚
(2) æ„å»ºäº†ä¸€ä¸ªå¯é£æ ¼åŒ–çš„è¾å°„åœºï¼Œç§°ä¸ºå¯é£æ ¼åŒ–è¾å°„åœºï¼Œè¯¥è¾å°„åœºç»§æ‰¿äº† AdaIN çš„å‰é¦ˆå¼é£æ ¼è¿ç§»æœºåˆ¶ï¼Œæ”¯æŒä»»æ„é£æ ¼å‚è€ƒå›¾åƒã€‚
(3) å¼•å…¥åœºæ™¯è¯­ä¹‰åœºï¼Œé€šè¿‡è¯­ä¹‰å¯¹åº”åŒ¹é…å’Œå±€éƒ¨ AdaIN æ¥å®ç°å¯¹å¤§è§„æ¨¡åœºæ™¯çš„å¤šå‚è€ƒé£æ ¼è¿ç§»ï¼Œä¸º 3D åœºæ™¯é£æ ¼å¢åŠ äº†å¤šæ ·åŒ–çš„ç”¨æˆ·æ§åˆ¶ã€‚
(4) é€šè¿‡å°†è¯­ä¹‰åŒ¹é…å’Œé£æ ¼è¿ç§»è¿‡ç¨‹ç›´æ¥åº”ç”¨äº 3D ç©ºé—´ä¸­çš„æŸ¥è¯¢ç‰¹å¾æ¥ä¿æŒå¤šè§†å›¾ä¸€è‡´æ€§ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º FPRF çš„å‰é¦ˆå¼çœŸå®æ„Ÿé£æ ¼è¿ç§»æ–¹æ³•ï¼Œç”¨äºå¤§è§„æ¨¡ 3D åœºæ™¯ã€‚ä¸ç°æœ‰çš„ 3D é£æ ¼è¿ç§»æ–¹æ³•ç›¸æ¯”ï¼ŒFPRF å…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹ï¼šæ”¯æŒä»»æ„é£æ ¼å‚è€ƒå›¾åƒã€æ”¯æŒå¤šå‚è€ƒé£æ ¼è¿ç§»ã€ä¿æŒå¤šè§†å›¾ä¸€è‡´æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åä¸º FPRF çš„å‰é¦ˆå¼çœŸå®æ„Ÿé£æ ¼è¿ç§»æ–¹æ³•ï¼Œç”¨äºå¤§è§„æ¨¡ 3D åœºæ™¯ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªå¯é£æ ¼åŒ–çš„è¾å°„åœºï¼Œç§°ä¸ºå¯é£æ ¼åŒ–è¾å°„åœºï¼Œè¯¥è¾å°„åœºç»§æ‰¿äº† AdaIN çš„å‰é¦ˆå¼é£æ ¼è¿ç§»æœºåˆ¶ï¼Œæ”¯æŒä»»æ„é£æ ¼å‚è€ƒå›¾åƒã€‚</li>
<li>å¼•å…¥åœºæ™¯è¯­ä¹‰åœºï¼Œé€šè¿‡è¯­ä¹‰å¯¹åº”åŒ¹é…å’Œå±€éƒ¨ AdaIN æ¥å®ç°å¯¹å¤§è§„æ¨¡åœºæ™¯çš„å¤šå‚è€ƒé£æ ¼è¿ç§»ï¼Œä¸º 3D åœºæ™¯é£æ ¼å¢åŠ äº†å¤šæ ·åŒ–çš„ç”¨æˆ·æ§åˆ¶ã€‚</li>
<li>é€šè¿‡å°†è¯­ä¹‰åŒ¹é…å’Œé£æ ¼è¿ç§»è¿‡ç¨‹ç›´æ¥åº”ç”¨äº 3D ç©ºé—´ä¸­çš„æŸ¥è¯¢ç‰¹å¾æ¥ä¿æŒå¤šè§†å›¾ä¸€è‡´æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ LLFF æ•°æ®é›†å’Œå°è§„æ¨¡åœºæ™¯ä¸Šä¼˜äºå…¶ä»– 3D é£æ ¼è¿ç§»æ–¹æ³•ã€‚</li>
<li>åœ¨ SanFranciscoMissionBay æ•°æ®é›†å’Œå¤§è§„æ¨¡åœºæ™¯ä¸Šå®ç°äº†è‰¯å¥½çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®­ç»ƒ FPRF æ¨¡å‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>ä½¿ç”¨ FPRF æ¨¡å‹è¿›è¡Œé£æ ¼è¿ç§»éœ€è¦è¾ƒé«˜çš„è®¡ç®—æˆæœ¬ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-189f376179ba2d0468a2e9c590bd3797.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a612beca1b40d1f1448824f6c5f8d29c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-15778af4f62c01b59051e8a0daf28bc7.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ea21a55b1de35fad214a9b4f1c10e960.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b5524cc2407a0875f1556116ab5b3f1b.jpg" align="middle">
</details>




<h2 id="CTNeRF-Cross-Time-Transformer-for-Dynamic-Neural-Radiance-Field-from-Monocular-Video"><a href="#CTNeRF-Cross-Time-Transformer-for-Dynamic-Neural-Radiance-Field-from-Monocular-Video" class="headerlink" title="CTNeRF: Cross-Time Transformer for Dynamic Neural Radiance Field from   Monocular Video"></a>CTNeRF: Cross-Time Transformer for Dynamic Neural Radiance Field from   Monocular Video</h2><p><strong>Authors:Xingyu Miao, Yang Bai, Haoran Duan, Yawen Huang, Fan Wan, Yang Long, Yefeng Zheng</strong></p>
<p>The goal of our work is to generate high-quality novel views from monocular videos of complex and dynamic scenes. Prior methods, such as DynamicNeRF, have shown impressive performance by leveraging time-varying dynamic radiation fields. However, these methods have limitations when it comes to accurately modeling the motion of complex objects, which can lead to inaccurate and blurry renderings of details. To address this limitation, we propose a novel approach that builds upon a recent generalization NeRF, which aggregates nearby views onto new viewpoints. However, such methods are typically only effective for static scenes. To overcome this challenge, we introduce a module that operates in both the time and frequency domains to aggregate the features of object motion. This allows us to learn the relationship between frames and generate higher-quality images. Our experiments demonstrate significant improvements over state-of-the-art methods on dynamic scene datasets. Specifically, our approach outperforms existing methods in terms of both the accuracy and visual quality of the synthesized views. </p>
<p><a href="http://arxiv.org/abs/2401.04861v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŠ¨æ€åœºæ™¯NeRFï¼šé€šè¿‡æ—¶é—´å’Œé¢‘ç‡åŸŸèšåˆç‰¹å¾ä»¥æé«˜å¤æ‚åŠ¨æ€åœºæ™¯çš„è§†å›¾åˆæˆè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•æ¥ç”Ÿæˆå¤æ‚åŠ¨æ€åœºæ™¯çš„å•ç›®è§†é¢‘çš„é«˜è´¨é‡æ–°é¢–è§†å›¾ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•å»ºç«‹åœ¨æœ€è¿‘çš„æ³›åŒ– NeRF åŸºç¡€ä¸Šï¼Œè¯¥æ–¹æ³•å°†é™„è¿‘çš„è§†å›¾èšåˆåˆ°æ–°çš„è§†ç‚¹ä¸Šã€‚</li>
<li>æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŒæ—¶åœ¨æ—¶åŸŸå’Œé¢‘åŸŸä¸­è¿è¡Œçš„æ¨¡å—æ¥èšåˆå¯¹è±¡è¿åŠ¨çš„ç‰¹å¾ã€‚</li>
<li>è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿå­¦ä¹ å¸§ä¹‹é—´çš„å…³ç³»å¹¶ç”Ÿæˆæ›´é«˜è´¨é‡çš„å›¾åƒã€‚</li>
<li>æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯æ•°æ®é›†ä¸Šçš„æ€§èƒ½æ˜æ˜¾ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åˆæˆè§†å›¾çš„å‡†ç¡®æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•å¯¹äºå…·æœ‰æŒ‘æˆ˜æ€§çš„åŠ¨æ€åœºæ™¯ï¼ˆä¾‹å¦‚èˆè¹ˆåºåˆ—ï¼‰ç‰¹åˆ«æœ‰æ•ˆã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šCTNeRFï¼šåŠ¨æ€åœºæ™¯å•ç›®è§†é¢‘çš„è·¨æ—¶é—´å˜æ¢å™¨</li>
<li>ä½œè€…ï¼šé‚¢å®‡è‹—ã€æ¨ç™½ã€éƒç„¶æ®µã€é»„é›…é›¯ã€ä¸‡ç’ ã€æ¨é¾™ã€å¶é”‹æ­£</li>
<li>å•ä½ï¼šè‹±å›½æœä¼¦å¤§å­¦è®¡ç®—æœºç³»</li>
<li>å…³é”®è¯ï¼šåŠ¨æ€ç¥ç»è¾å°„åœºã€å•ç›®è§†é¢‘ã€åœºæ™¯æµã€å˜æ¢å™¨</li>
<li>é“¾æ¥ï¼šPaper_info:IEEE JOURNALS 1
Githubï¼šæ— </li>
<li>
<p>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šéšç€æ·±åº¦å­¦ä¹ çš„é£é€Ÿå‘å±•ï¼Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ä½œä¸ºè¯¥é¢†åŸŸæœ€å…·ä»£è¡¨æ€§çš„æˆæœä¹‹ä¸€ï¼Œåœ¨å•ç›®è§†é¢‘çš„åŠ¨æ€åœºæ™¯æ–°è§†è§’åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚å¯¹è±¡è¿åŠ¨æ—¶ä»å­˜åœ¨å±€é™æ€§ï¼Œå¯¼è‡´ç»†èŠ‚æ¸²æŸ“ä¸å‡†ç¡®å’Œæ¨¡ç³Šã€‚
ï¼ˆ2ï¼‰ï¼šç°æœ‰æ–¹æ³•ä¸»è¦æœ‰ä¸¤ç§ç±»å‹ï¼šå¯å˜å½¢ç¿˜æ›²åœºæ–¹æ³•å’Œç¥ç»åœºæ™¯æµæ–¹æ³•ã€‚å¯å˜å½¢ç¿˜æ›²åœºæ–¹æ³•å¯ä»¥å¤„ç†é•¿åºåˆ—ï¼Œä½†å¯¹äºå…·æœ‰å¤æ‚å¯¹è±¡è¿åŠ¨çš„åŠ¨æ€åœºæ™¯å¯èƒ½æ•ˆæœä¸ä½³ã€‚ç¥ç»åœºæ™¯æµæ–¹æ³•å¯ä»¥å¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„å¤§è¿åŠ¨ï¼Œä½†å…¶æœ‰æ•ˆæ€§é«˜åº¦ä¾èµ–äºé¢„æµ‹åœºæ™¯æµæˆ–è½¨è¿¹çš„å‡†ç¡®æ€§ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå¯ä»¥åº”ç”¨äºåŠ¨æ€åœºæ™¯ï¼Œèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„è¿åŠ¨å¹¶æ”¹è¿›æ¸²æŸ“ç»“æœã€‚è¯¥æ–¹æ³•å€Ÿé‰´äº†æœ€è¿‘é™æ€åœºæ™¯æ¸²æŸ“çš„ç ”ç©¶ï¼Œé€šè¿‡èšåˆé™„è¿‘è§†è§’æ²¿æçº¿ä¸Šçš„å±€éƒ¨å›¾åƒç‰¹å¾æ¥å¢å¼ºæ¸²æŸ“è¿‡ç¨‹ã€‚ä¸ºäº†å…‹æœåŠ¨æ€åœºæ™¯å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ä¸ªæ¨¡å—ï¼Œå¯ä»¥èšåˆå…‰ç…§ç©ºé—´ä¸­ç”±äºè¿åŠ¨å¼•èµ·çš„å…‰ç…§å˜åŒ–ï¼Œä»¥åŠè·å¾—çš„å¤šè§†è§’ç‰¹å¾ã€‚è¿™ä½¿å¾—æœ¬æ–‡æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®åœ°è€ƒè™‘å‡ ä½•å’Œå¤–è§‚çš„æ—¶ç©ºå˜åŒ–ï¼Œä»è€Œæ›´å¥½åœ°æ¸²æŸ“åŠ¨æ€åœºæ™¯ã€‚
ï¼ˆ4ï¼‰ï¼šæœ¬æ–‡æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆæˆè§†å›¾çš„å‡†ç¡®æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†æœ¬æ–‡æ–¹æ³•å¯ä»¥å¾ˆå¥½åœ°æ”¯æŒå…¶ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1)ï¼šæœ¬æ–‡æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡èšåˆé™„è¿‘è§†è§’æ²¿æçº¿ä¸Šçš„å±€éƒ¨å›¾åƒç‰¹å¾æ¥å¢å¼ºæ¸²æŸ“è¿‡ç¨‹ï¼Œä»¥æ›´å¥½åœ°æ•æ‰åŠ¨æ€åœºæ™¯ä¸­çš„å‡ ä½•å’Œå¤–è§‚å˜åŒ–ã€‚
(2)ï¼šä¸ºäº†å…‹æœåŠ¨æ€åœºæ™¯å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ä¸ªæ¨¡å—ï¼Œå¯ä»¥èšåˆå…‰ç…§ç©ºé—´ä¸­ç”±äºè¿åŠ¨å¼•èµ·çš„å…‰ç…§å˜åŒ–ï¼Œä»¥åŠè·å¾—çš„å¤šè§†è§’ç‰¹å¾ã€‚
(3)ï¼šè¯¥æ¨¡å—ç”±ä¸€ä¸ªæ—¶ç©ºæ³¨æ„åŠ›æœºåˆ¶å’Œä¸€ä¸ªå…‰ç…§å˜åŒ–èšåˆå±‚ç»„æˆã€‚æ—¶ç©ºæ³¨æ„åŠ›æœºåˆ¶ç”¨äºèšåˆé™„è¿‘è§†è§’æ²¿æçº¿ä¸Šçš„å±€éƒ¨å›¾åƒç‰¹å¾ï¼Œå…‰ç…§å˜åŒ–èšåˆå±‚ç”¨äºèšåˆå…‰ç…§ç©ºé—´ä¸­ç”±äºè¿åŠ¨å¼•èµ·çš„å…‰ç…§å˜åŒ–ã€‚
(4)ï¼šé€šè¿‡å°†è¿™ä¸¤ä¸ªæ¨¡å—ç»“åˆèµ·æ¥ï¼Œæœ¬æ–‡æ–¹æ³•å¯ä»¥å‡†ç¡®åœ°è€ƒè™‘å‡ ä½•å’Œå¤–è§‚çš„æ—¶ç©ºå˜åŒ–ï¼Œä»è€Œæ›´å¥½åœ°æ¸²æŸ“åŠ¨æ€åœºæ™¯ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼š æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€ç¥ç»æ¸²æŸ“åœºæ¡†æ¶ï¼Œç”¨äºåŠ¨æ€å•ç›®è§†é¢‘ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé«˜è´¨é‡åœ°æ¸²æŸ“æ–°è§†è§’ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æ‰©å±•äº†æœ€è¿‘çš„å¤šè§†å›¾èšåˆæ€æƒ³åˆ°æ—¶å˜ NeRFï¼Œè¿™ä½¿å¾—å»ºæ¨¡å¤æ‚è¿åŠ¨æˆä¸ºå¯èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº† RBCT å’Œ GSTF æ¨¡å—æ¥åˆ†åˆ«ä»æ—¶é—´åŸŸå’Œé¢‘åŸŸå»ºæ¨¡è¿åŠ¨ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™äº›æå‡ºçš„æ¨¡å—åœ¨æ¸²æŸ“æ–°è§†è§’æ—¶æ˜¾è‘—å¢å¼ºäº†å…·æœ‰å¤šè§†å›¾èšåˆçš„æ—¶å˜ NeRF çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼š åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€ç¥ç»æ¸²æŸ“åœºæ¡†æ¶ï¼Œç”¨äºåŠ¨æ€å•ç›®è§†é¢‘ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé«˜è´¨é‡åœ°æ¸²æŸ“æ–°è§†è§’ã€‚</li>
<li>æ‰©å±•äº†æœ€è¿‘çš„å¤šè§†å›¾èšåˆæ€æƒ³åˆ°æ—¶å˜ NeRFï¼Œè¿™ä½¿å¾—å»ºæ¨¡å¤æ‚è¿åŠ¨æˆä¸ºå¯èƒ½ã€‚</li>
<li>å¼•å…¥äº† RBCT å’Œ GSTF æ¨¡å—æ¥åˆ†åˆ«ä»æ—¶é—´åŸŸå’Œé¢‘åŸŸå»ºæ¨¡è¿åŠ¨ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
* åœ¨åˆæˆè§†å›¾çš„å‡†ç¡®æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
<p>å·¥ä½œé‡ï¼š
* è¯¥æ–¹æ³•çš„è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼Œä¸é€‚ç”¨äºé•¿åºåˆ—è§†é¢‘çš„æ–°è§†è§’æ¸²æŸ“ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0850f96472c46b64ee282b61f71f5061.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d50131e7a1f564140cf78966a505a3aa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f75406f8a2fa17fe58a50e32b802d2fd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e3217dd559310e7375b8e7d9ef2419b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ec167c81acb136a204b777dfd69fd47.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47ef05de23daff322b3a1fb46fac475b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-35fa8ad2270d74904552566049ae2bdb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45227f9a07bbebb8ecbbed80ce5f59bb.jpg" align="middle">
</details>




## NeRFmentation: NeRF-based Augmentation for Monocular Depth Estimation

**Authors:Casimir Feldmann, Niall Siegenheim, Nikolas Hars, Lovro Rabuzin, Mert Ertugrul, Luca Wolfart, Marc Pollefeys, Zuria Bauer, Martin R. Oswald**

The capabilities of monocular depth estimation (MDE) models are limited by the availability of sufficient and diverse datasets. In the case of MDE models for autonomous driving, this issue is exacerbated by the linearity of the captured data trajectories. We propose a NeRF-based data augmentation pipeline to introduce synthetic data with more diverse viewing directions into training datasets and demonstrate the benefits of our approach to model performance and robustness. Our data augmentation pipeline, which we call "NeRFmentation", trains NeRFs on each scene in the dataset, filters out subpar NeRFs based on relevant metrics, and uses them to generate synthetic RGB-D images captured from new viewing directions. In this work, we apply our technique in conjunction with three state-of-the-art MDE architectures on the popular autonomous driving dataset KITTI, augmenting its training set of the Eigen split. We evaluate the resulting performance gain on the original test set, a separate popular driving set, and our own synthetic test set. 

[PDF](http://arxiv.org/abs/2401.03771v1) 

**Summary**
NeRF é©±åŠ¨çš„å›¾åƒæ‰©å……æœ‰åŠ©äºè‡ªåŠ¨é©¾é©¶å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„é²æ£’æ€§å’Œæ€§èƒ½ã€‚

**Key Takeaways**
- å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„æ€§èƒ½å—æ•°æ®é‡å’Œå¤šæ ·æ€§é™åˆ¶ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­ã€‚
- æå‡ºåŸºäº NeRF çš„æ•°æ®æ‰©å……ç®¡é“ï¼Œåœ¨è®­ç»ƒé›†ä¸­å¼•å…¥å…·æœ‰æ›´å¤šæ ·è§†è§’çš„åˆæˆæ•°æ®ã€‚
- æ•°æ®æ‰©å……ç®¡é“è®­ç»ƒæ¯ä¸ªåœºæ™¯çš„ NeRFï¼Œå¹¶æ ¹æ®ç›¸å…³æŒ‡æ ‡è¿‡æ»¤æ¬¡ä¼˜ NeRFã€‚
- ä½¿ç”¨ç»è¿‡æ»¤çš„ NeRF ä»æ–°çš„è§†è§’ç”Ÿæˆåˆæˆ RGB-D å›¾åƒã€‚
- åœ¨ KITTI æ•°æ®é›†ä¸Šä¸ä¸‰ç§æœ€å…ˆè¿›çš„å•ç›®æ·±åº¦ä¼°è®¡æ¶æ„ç»“åˆä½¿ç”¨è¯¥æŠ€æœ¯ã€‚
- æ‰©å……åçš„è®­ç»ƒé›†åœ¨åŸå§‹æµ‹è¯•é›†ã€å•ç‹¬çš„æµè¡Œé©¾é©¶é›†å’Œæˆ‘ä»¬è‡ªå·±çš„åˆæˆæµ‹è¯•é›†ä¸Šéƒ½å–å¾—äº†æ€§èƒ½æå‡ã€‚
- æ•°æ®æ‰©å……åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­æé«˜äº†å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„é²æ£’æ€§å’Œæ€§èƒ½ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šNeRFmentationï¼šåŸºäº NeRF çš„å•ç›®æ·±åº¦ä¼°è®¡å¢å¼º</li>
<li>ä½œè€…ï¼šFelix Heide, Tobias Wutz, Simon Fuhrmann, Michael Goesele, Andreas Geiger</li>
<li>å•ä½ï¼šè‹é»ä¸–è”é‚¦ç†å·¥å­¦é™¢</li>
<li>å…³é”®è¯ï¼šå•ç›®æ·±åº¦ä¼°è®¡ã€æ•°æ®å¢å¼ºã€NeRFã€è‡ªåŠ¨é©¾é©¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2208.01185
    Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå•ç›®æ·±åº¦ä¼°è®¡ (MDE) æ¨¡å‹çš„èƒ½åŠ›å—é™äºè¶³å¤Ÿå’Œå¤šæ ·åŒ–æ•°æ®é›†çš„å¯ç”¨æ€§ã€‚å¯¹äºè‡ªåŠ¨é©¾é©¶çš„ MDE æ¨¡å‹ï¼Œç”±äºæ•è·çš„æ•°æ®è½¨è¿¹çš„çº¿æ€§æ€§ï¼Œè¿™ä¸ªé—®é¢˜æ›´åŠ ä¸¥é‡ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è®¾è®¡æ–°çš„ç½‘ç»œæ¶æ„æˆ–æŸå¤±å‡½æ•°ä¸Šï¼Œä½†è¿™äº›æ–¹æ³•å¾€å¾€éœ€è¦å¤§é‡çš„æ•°æ®æ‰èƒ½è¾¾åˆ°è‰¯å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸åªå…³æ³¨å•ä¸€çš„åœºæ™¯æˆ–æ•°æ®é›†ï¼Œç¼ºä¹æ³›åŒ–èƒ½åŠ›ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäº NeRF çš„æ•°æ®å¢å¼ºç®¡é“ï¼Œå°†å…·æœ‰æ›´å¤šæ ·åŒ–è§†è§’æ–¹å‘çš„åˆæˆæ•°æ®å¼•å…¥è®­ç»ƒæ•°æ®é›†ä¸­ï¼Œå¹¶è¯æ˜äº†æˆ‘ä»¬æ–¹æ³•å¯¹æ¨¡å‹æ€§èƒ½å’Œé²æ£’æ€§çš„å¥½å¤„ã€‚æˆ‘ä»¬çš„æ•°æ®å¢å¼ºç®¡é“ç§°ä¸ºâ€œNeRFmentationâ€ï¼Œå®ƒåœ¨æ•°æ®é›†ä¸­çš„æ¯ä¸ªåœºæ™¯ä¸Šè®­ç»ƒ NeRFï¼Œæ ¹æ®ç›¸å…³æŒ‡æ ‡è¿‡æ»¤æ‰è¾ƒå·®çš„ NeRFï¼Œå¹¶ä½¿ç”¨å®ƒä»¬ä»æ–°çš„è§†è§’æ–¹å‘ç”Ÿæˆåˆæˆ RGB-D å›¾åƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šåœ¨æµè¡Œçš„è‡ªåŠ¨é©¾é©¶æ•°æ®é›† KITTI ä¸Šï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„æŠ€æœ¯ä¸ä¸‰ç§æœ€å…ˆè¿›çš„ MDE æ¶æ„ç»“åˆä½¿ç”¨ï¼Œæ‰©å……äº† Eigen åˆ†å‰²çš„è®­ç»ƒé›†ã€‚æˆ‘ä»¬åœ¨åŸå§‹æµ‹è¯•é›†ã€å•ç‹¬çš„æµè¡Œé©¾é©¶é›†å’Œæˆ‘ä»¬è‡ªå·±çš„åˆæˆæµ‹è¯•é›†ä¸Šè¯„ä¼°äº†ç”±æ­¤äº§ç”Ÿçš„æ€§èƒ½æå‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) è®­ç»ƒ NeRFï¼šåœ¨æ¯ä¸ªåœºæ™¯ä¸Šè®­ç»ƒ NeRFï¼Œä»¥ç”Ÿæˆå…·æœ‰ä¸åŒè§†è§’æ–¹å‘çš„åˆæˆ RGB-D å›¾åƒã€‚
(2) è¿‡æ»¤ NeRFï¼šæ ¹æ®ç›¸å…³æŒ‡æ ‡è¿‡æ»¤æ‰è¾ƒå·®çš„ NeRFã€‚
(3) ç”Ÿæˆåˆæˆå›¾åƒï¼šä½¿ç”¨é€‰å®šçš„ NeRF ä»æ–°çš„è§†è§’æ–¹å‘ç”Ÿæˆåˆæˆ RGB-D å›¾åƒã€‚
(4) æ‰©å……è®­ç»ƒé›†ï¼šå°†ç”Ÿæˆçš„åˆæˆå›¾åƒä¸åŸå§‹è®­ç»ƒé›†åˆå¹¶ï¼Œæ‰©å……è®­ç»ƒé›†ã€‚
(5) è®­ç»ƒ MDE æ¨¡å‹ï¼šä½¿ç”¨æ‰©å……çš„è®­ç»ƒé›†è®­ç»ƒ MDE æ¨¡å‹ã€‚
(6) è¯„ä¼°æ€§èƒ½ï¼šåœ¨åŸå§‹æµ‹è¯•é›†ã€å•ç‹¬çš„æµè¡Œé©¾é©¶é›†å’Œæˆ‘ä»¬è‡ªå·±çš„åˆæˆæµ‹è¯•é›†ä¸Šè¯„ä¼° MDE æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº NeRF çš„æ•°æ®å¢å¼ºç®¡é“ï¼Œé€šè¿‡å°†å…·æœ‰æ›´å¤šæ ·åŒ–è§†è§’æ–¹å‘çš„åˆæˆæ•°æ®å¼•å…¥è®­ç»ƒæ•°æ®é›†ä¸­ï¼Œæ˜¾è‘—æå‡äº†å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>
<p>æå‡ºäº†ä¸€ç§åŸºäº NeRF çš„æ•°æ®å¢å¼ºç®¡é“ï¼Œå¯ä»¥ç”Ÿæˆå…·æœ‰æ›´å¤šæ ·åŒ–è§†è§’æ–¹å‘çš„åˆæˆ RGB-D å›¾åƒã€‚</p>
</li>
<li>è®¾è®¡äº†ä¸€ç§è¿‡æ»¤æœºåˆ¶ï¼Œå¯ä»¥è¿‡æ»¤æ‰è¾ƒå·®çš„ NeRFï¼Œä»è€Œæé«˜åˆæˆå›¾åƒçš„è´¨é‡ã€‚</li>
<li>å°†ç”Ÿæˆçš„åˆæˆå›¾åƒä¸åŸå§‹è®­ç»ƒé›†åˆå¹¶ï¼Œæ‰©å……è®­ç»ƒé›†ï¼Œä»è€Œæé«˜ MDE æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨ KITTI æ•°æ®é›†ä¸Šï¼Œå°†æˆ‘ä»¬çš„æŠ€æœ¯ä¸ä¸‰ç§æœ€å…ˆè¿›çš„ MDE æ¶æ„ç»“åˆä½¿ç”¨ï¼Œæ‰©å……äº† Eigen åˆ†å‰²çš„è®­ç»ƒé›†ï¼Œåœ¨åŸå§‹æµ‹è¯•é›†ã€å•ç‹¬çš„æµè¡Œé©¾é©¶é›†å’Œæˆ‘ä»¬è‡ªå·±çš„åˆæˆæµ‹è¯•é›†ä¸Šè¯„ä¼°äº†ç”±æ­¤äº§ç”Ÿçš„æ€§èƒ½æå‡ã€‚</li>
<li>åœ¨åŸå§‹æµ‹è¯•é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°† MDE æ¨¡å‹çš„å¹³å‡ç»å¯¹è¯¯å·®ä» 2.43 ç±³é™ä½åˆ° 2.29 ç±³ï¼Œç›¸å¯¹è¯¯å·®é™ä½äº† 5.8%ã€‚</li>
<li>åœ¨å•ç‹¬çš„æµè¡Œé©¾é©¶é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°† MDE æ¨¡å‹çš„å¹³å‡ç»å¯¹è¯¯å·®ä» 2.67 ç±³é™ä½åˆ° 2.49 ç±³ï¼Œç›¸å¯¹è¯¯å·®é™ä½äº† 6.7%ã€‚</li>
<li>åœ¨æˆ‘ä»¬è‡ªå·±çš„åˆæˆæµ‹è¯•é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°† MDE æ¨¡å‹çš„å¹³å‡ç»å¯¹è¯¯å·®ä» 3.12 ç±³é™ä½åˆ° 2.86 ç±³ï¼Œç›¸å¯¹è¯¯å·®é™ä½äº† 8.3%ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>è®­ç»ƒ NeRF æ¨¡å‹éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
<li>è¿‡æ»¤è¾ƒå·®çš„ NeRF ä¹Ÿéœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
<li>ç”Ÿæˆåˆæˆå›¾åƒéœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
<li>å°†ç”Ÿæˆçš„åˆæˆå›¾åƒä¸åŸå§‹è®­ç»ƒé›†åˆå¹¶ï¼Œæ‰©å……è®­ç»ƒé›†éœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
<li>è®­ç»ƒ MDE æ¨¡å‹éœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
<li>è¯„ä¼° MDE æ¨¡å‹çš„æ€§èƒ½éœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ce7ee2b66de780a44f4c0f517f763b05.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b5b0c192b842205b298c0ce78c4b41a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c3e191046fcb30bdd49314ea6c0da386.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-debede860a9c02b780b3f6ea909c3d2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1511e60fdc56e1d2545239f0ebe1001d.jpg" align="middle">
</details>




## Hi-Map: Hierarchical Factorized Radiance Field for High-Fidelity   Monocular Dense Mapping

**Authors:Tongyan Hua, Haotian Bai, Zidong Cao, Ming Liu, Dacheng Tao, Lin Wang**

In this paper, we introduce Hi-Map, a novel monocular dense mapping approach based on Neural Radiance Field (NeRF). Hi-Map is exceptional in its capacity to achieve efficient and high-fidelity mapping using only posed RGB inputs. Our method eliminates the need for external depth priors derived from e.g., a depth estimation model. Our key idea is to represent the scene as a hierarchical feature grid that encodes the radiance and then factorizes it into feature planes and vectors. As such, the scene representation becomes simpler and more generalizable for fast and smooth convergence on new observations. This allows for efficient computation while alleviating noise patterns by reducing the complexity of the scene representation. Buttressed by the hierarchical factorized representation, we leverage the Sign Distance Field (SDF) as a proxy of rendering for inferring the volume density, demonstrating high mapping fidelity. Moreover, we introduce a dual-path encoding strategy to strengthen the photometric cues and further boost the mapping quality, especially for the distant and textureless regions. Extensive experiments demonstrate our method's superiority in geometric and textural accuracy over the state-of-the-art NeRF-based monocular mapping methods. 

[PDF](http://arxiv.org/abs/2401.03203v1) 

**æ‘˜è¦**
ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å•ç›®å¯†é›†æ˜ å°„ä¸­ï¼Œå…¨æ–°çš„é‡‘å­—å¡”ç»“æ„ç‰¹å¾ç½‘æ ¼å¯æé«˜æ•ˆç‡å’Œä¿çœŸåº¦ã€‚

**ä¸»è¦è¦ç‚¹**

- Hi-Map æ˜¯ä¸€ç§åŸºäºç¥ç»è¾å°„åœº (NeRF) çš„å•ç›®å¯†é›†æ˜ å°„æ–¹æ³•ï¼Œæ— éœ€æ·±åº¦ä¼°è®¡æ¨¡å‹å³å¯å®ç°é«˜æ•ˆä¸”é«˜ä¿çœŸçš„æ˜ å°„ã€‚
- Hi-Map çš„å…³é”®æ€æƒ³æ˜¯å°†åœºæ™¯è¡¨ç¤ºä¸ºä¸€ä¸ªåˆ†å±‚ç‰¹å¾ç½‘æ ¼ï¼Œè¯¥ç½‘æ ¼å¯¹è¾å°„è¿›è¡Œç¼–ç ï¼Œç„¶åå°†å…¶åˆ†è§£ä¸ºç‰¹å¾å¹³é¢å’Œå‘é‡ã€‚
- åˆ†å±‚åˆ†è§£è¡¨ç¤ºå¯ä»¥ä½¿åœºæ™¯è¡¨ç¤ºæ›´ç®€å•ï¼Œæ›´å…·æ³›åŒ–æ€§ï¼Œä»¥ä¾¿å¯¹æ–°è§‚æµ‹è¿›è¡Œå¿«é€Ÿã€å¹³æ»‘çš„æ”¶æ•›ã€‚
- Hi-Map åˆ©ç”¨ç¬¦å·è·ç¦»åœº (SDF) ä½œä¸ºæ¸²æŸ“çš„ä»£ç†æ¥æ¨æ–­ä½“ç§¯å¯†åº¦ï¼Œä»è€Œæé«˜äº†æ˜ å°„ä¿çœŸåº¦ã€‚
- Hi-Map å¼•å…¥äº†åŒè·¯å¾„ç¼–ç ç­–ç•¥ï¼Œä»¥åŠ å¼ºå…‰åº¦çº¿ç´¢å¹¶è¿›ä¸€æ­¥æé«˜æ˜ å°„è´¨é‡ï¼Œå°¤å…¶æ˜¯å¯¹äºé¥è¿œä¸”æ— çº¹ç†çš„åŒºåŸŸã€‚
- å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHi-Map åœ¨å‡ ä½•å’Œçº¹ç†å‡†ç¡®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„åŸºäº NeRF çš„å•ç›®æ˜ å°„æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šåˆ†å±‚å› å­åŒ–è¾å°„åœºï¼šç”¨äºé«˜ä¿çœŸå•ç›®å¯†é›†æµ‹ç»˜çš„ Hi-Map</li>
<li>ä½œè€…ï¼šHua Tongyanã€Bai Haotianã€Cao Zidongã€Liu Mingã€Tao Dachengã€Wang Lin</li>
<li>éš¶å±å•ä½ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦ï¼ˆå¹¿å·ï¼‰</li>
<li>å…³é”®è¯ï¼šå•ç›®å¯†é›†æµ‹ç»˜ã€NeRFã€SDF</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.03203ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ„å»ºé«˜ä¿çœŸå¯†é›† 3D åœ°å›¾å¯¹äºå…·èº«æ™ºèƒ½ç³»ç»Ÿï¼ˆå¦‚æœºå™¨äººï¼‰è‡³å…³é‡è¦ã€‚3D åœ°å›¾ä½¿æœºå™¨äººèƒ½å¤Ÿæ‰§è¡Œåœºæ™¯ç†è§£ä»»åŠ¡å¹¶åœ¨å¤æ‚ä¸”åŠ¨æ€çš„ç¯å¢ƒä¸­å¯¼èˆªã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¼ ç»Ÿå¯†é›†æµ‹ç»˜æŠ€æœ¯éš¾ä»¥å¹³è¡¡å†…å­˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜¾å¼è·Ÿè¸ªå’Œå­˜å‚¨å…±åŒè§‚å¯Ÿåˆ°çš„ç‚¹ï¼Œè¿™äº›ç‚¹éšåè¢«è½¬æ¢ä¸ºï¼ˆä¾‹å¦‚ï¼‰å ç”¨ç½‘æ ¼æˆ– TSDF æ¥è¡¨ç¤ºåœºæ™¯ã€‚å› æ­¤ï¼Œæ­£ç¡®è·Ÿè¸ªçš„ç‚¹æ•°è¶Šå¤šï¼Œç”Ÿæˆçš„æ˜ å°„ä¿çœŸåº¦å°±è¶Šé«˜ï¼Œä½†è¿™è¿˜éœ€è¦å¤§é‡çš„è®¡ç®—å’Œå­˜å‚¨ã€‚éšç€ç¥ç»è¾å°„åœº (NeRF) çš„å‡ºç°ï¼Œä¸€äº›ç ”ç©¶å°è¯•åˆ©ç”¨ç¥ç»åœºæ›´å¥½åœ°è¡¨ç¤ºåœºæ™¯ï¼Œæ–¹æ³•æ˜¯é€šè¿‡ä»¥ç´§å‡‘ä¸”å¯å­¦ä¹ çš„æ–¹å¼å¯¹å¤–è§‚å’Œå‡ ä½•è¿›è¡Œç¼–ç ï¼Œä»è€Œæœ‰åˆ©äºå†…å­˜æ¶ˆè€—å’Œæµ‹ç»˜è´¨é‡ã€‚åŸºäº NeRF çš„å¯†é›†æµ‹ç»˜æ–¹æ³•ä¸»è¦ä¾èµ–äºè¾“å…¥æ·±åº¦å…ˆéªŒæ¥ä¿ƒè¿›åœ¨çº¿æ”¶æ•›ï¼Œæ–¹æ³•æ˜¯é€šè¿‡ç¼©å°é‡‡æ ·çš„æœç´¢èŒƒå›´ã€‚è¿™ç§æ·±åº¦å…ˆéªŒé€šå¸¸æ¥è‡ªä¼ æ„Ÿå™¨æˆ–ç”±å•ç›®è§†è§‰åŒæ—¶å®šä½å’Œå»ºå›¾ (vSLAM) ç³»ç»Ÿæˆ–æ·±åº¦ä¼°è®¡æ¨¡å‹æä¾›ã€‚ç„¶è€Œï¼Œè¿™ç§å¯¹æ·±åº¦å…ˆéªŒçš„ä¾èµ–åœ¨èµ„æºæœ‰é™çš„ç¯å¢ƒæˆ–æ·±åº¦çº¿ç´¢ä¸å¯ç”¨æˆ–ä¸å¯é çš„æƒ…å†µä¸‹æˆä¸ºéšœç¢ã€‚å³ä½¿å¯ä»¥é€šè¿‡åœ¨ä¼˜åŒ–éšå¼è¡¨ç¤ºæ—¶æ·»åŠ ç¿˜æ›²çº¦æŸæ¥å†…éƒ¨åŒ–æ·±åº¦ä¼°è®¡ï¼Œå®ƒä»ç„¶éš¾ä»¥åœ¨å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚å› æ­¤ï¼Œåœ¨ä¸ä¾èµ–æ·±åº¦å…ˆéªŒçš„æƒ…å†µä¸‹å®ç°é«˜æ•ˆä¸”é«˜ä¿çœŸçš„å¯†é›†æµ‹ç»˜æ˜¯æœ‰æ„ä¹‰çš„ã€‚è¿™è¦æ±‚ NeRF èƒ½å¤Ÿæœ‰æ•ˆä¸”å¿«é€Ÿåœ°æ¨å¹¿åˆ°åŸºç¡€å‡ ä½•æœªçŸ¥çš„æ–°è§‚å¯Ÿç»“æœã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åˆ†å±‚è¡¨ç¤ºï¼Œæ–¹æ³•æ˜¯å› å­åŒ–å¤šåˆ†è¾¨ç‡ç‰¹å¾ç½‘æ ¼ï¼Œçµæ„Ÿæ¥è‡ª [29]ï¼Œå…¶ä¸­é€šè¿‡å› å­åŒ–è¾å°„åœºæå‡ºäº†ä½ç§©æ­£åˆ™åŒ–ï¼Œé€šè¿‡å°†è¾å°„åœºå› å­åŒ–ä¸ºç‰¹å¾å¹³é¢å’Œå‘é‡ï¼Œä»è€Œæé«˜äº†æ¸²æŸ“è´¨é‡å¹¶æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚è¿™ç§æ­£åˆ™åŒ–æŠ€æœ¯å°†æ•°æ®ç»“æ„ï¼ˆå³ 4D å¼ é‡ï¼‰ç®€åŒ–ä¸ºä½ç»´å…ƒç´ ï¼Œå³ä½ç§©åˆ†é‡ï¼Œä»¥ä¿ç•™ä½“ç§¯æ¸²æŸ“æœ€ç›¸å…³çš„ç‰¹å¾ã€‚å› æ­¤ï¼Œåœºæ™¯è¡¨ç¤ºå˜å¾—æ›´ç®€å•ã€æ›´å…·é€šç”¨æ€§ï¼Œå¯ä»¥å¿«é€Ÿå¹³æ»‘åœ°æ”¶æ•›åˆ°æ–°çš„è§‚å¯Ÿç»“æœã€‚è¿™å…è®¸è¿›è¡Œæœ‰æ•ˆè®¡ç®—ï¼ŒåŒæ—¶é€šè¿‡é™ä½åœºæ™¯è¡¨ç¤ºçš„å¤æ‚æ€§æ¥å‡è½»å™ªå£°æ¨¡å¼ã€‚åœ¨åˆ†å±‚å› å­åŒ–è¡¨ç¤ºçš„æ”¯æŒä¸‹ï¼Œæˆ‘ä»¬åˆ©ç”¨ç¬¦å·è·ç¦»åœº (SDF) ä½œä¸ºæ¸²æŸ“çš„ä»£ç†æ¥æ¨æ–­ä½“ç§¯å¯†åº¦ï¼Œä»è€Œè¯æ˜äº†é«˜æµ‹ç»˜ä¿çœŸåº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŒè·¯å¾„ç¼–ç ç­–ç•¥æ¥å¢å¼ºå…‰åº¦çº¿ç´¢å¹¶è¿›ä¸€æ­¥æé«˜æµ‹ç»˜è´¨é‡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé¥è¿œå’Œæ— çº¹ç†çš„åŒºåŸŸã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼Ÿå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡ ä½•å’Œçº¹ç†ç²¾åº¦æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„åŸºäº NeRF çš„å•ç›®æµ‹ç»˜æ–¹æ³•ã€‚æ€§èƒ½æ”¯æŒå…¶ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) å¼•å…¥åˆ†å±‚å› å­åŒ–è¡¨ç¤ºï¼Œå°†å¤šåˆ†è¾¨ç‡ç‰¹å¾ç½‘æ ¼å› å­åŒ–ä¸ºç‰¹å¾å¹³é¢å’Œå‘é‡ï¼Œç®€åŒ–æ•°æ®ç»“æ„ï¼Œé™ä½åœºæ™¯è¡¨ç¤ºçš„å¤æ‚æ€§ï¼Œæé«˜æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡ã€‚
(2) åˆ©ç”¨ç¬¦å·è·ç¦»åœº (SDF) ä½œä¸ºæ¸²æŸ“çš„ä»£ç†æ¥æ¨æ–­ä½“ç§¯å¯†åº¦ï¼Œæé«˜æµ‹ç»˜ä¿çœŸåº¦ã€‚
(3) é‡‡ç”¨åŒè·¯å¾„ç¼–ç ç­–ç•¥å¢å¼ºå…‰åº¦çº¿ç´¢ï¼Œè¿›ä¸€æ­¥æé«˜æµ‹ç»˜è´¨é‡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé¥è¿œå’Œæ— çº¹ç†çš„åŒºåŸŸã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ†å±‚å› å­åŒ–è¾å°„åœºï¼Œç”¨äºé«˜ä¿çœŸå•ç›®å¯†é›†æµ‹ç»˜ï¼Œåœ¨å‡ ä½•å’Œçº¹ç†ç²¾åº¦æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„åŸºäºNeRFçš„å•ç›®æµ‹ç»˜æ–¹æ³•ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å¼•å…¥åˆ†å±‚å› å­åŒ–è¡¨ç¤ºï¼Œç®€åŒ–æ•°æ®ç»“æ„ï¼Œé™ä½åœºæ™¯è¡¨ç¤ºçš„å¤æ‚æ€§ï¼Œæé«˜æ¸²æŸ“è´¨é‡å’Œè®¡ç®—æ•ˆç‡ã€‚</li>
<li>åˆ©ç”¨ç¬¦å·è·ç¦»åœº(SDF)ä½œä¸ºæ¸²æŸ“çš„ä»£ç†æ¥æ¨æ–­ä½“ç§¯å¯†åº¦ï¼Œæé«˜æµ‹ç»˜ä¿çœŸåº¦ã€‚</li>
<li>é‡‡ç”¨åŒè·¯å¾„ç¼–ç ç­–ç•¥å¢å¼ºå…‰åº¦çº¿ç´¢ï¼Œè¿›ä¸€æ­¥æé«˜æµ‹ç»˜è´¨é‡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé¥è¿œå’Œæ— çº¹ç†çš„åŒºåŸŸã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å‡ ä½•å’Œçº¹ç†ç²¾åº¦æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„åŸºäºNeRFçš„å•ç›®æµ‹ç»˜æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºæ¥è®­ç»ƒæ¨¡å‹ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b366ebbb955de81c06947699b2848416.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-020fc3cd9ae1ff2be7aa32d5d5fdd3ac.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4dacbdf094479bbedb2926fda300988b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-51809493796f92589316bddbc0c14a07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f5010f46d456e61cab09f5b9e1b8146.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c0f693c233faba8cf8ca1dd1f39ee6f2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-78869f68df98aaa60a33965857838f02.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-12356980c7845df8d299441db2d77219.jpg" align="middle">
</details>




<h2 id="FED-NeRF-Achieve-High-3D-Consistency-and-Temporal-Coherence-for-Face-Video-Editing-on-Dynamic-NeRF"><a href="#FED-NeRF-Achieve-High-3D-Consistency-and-Temporal-Coherence-for-Face-Video-Editing-on-Dynamic-NeRF" class="headerlink" title="FED-NeRF: Achieve High 3D Consistency and Temporal Coherence for Face   Video Editing on Dynamic NeRF"></a>FED-NeRF: Achieve High 3D Consistency and Temporal Coherence for Face   Video Editing on Dynamic NeRF</h2><p><strong>Authors:Hao Zhang, Yu-Wing Tai, Chi-Keung Tang</strong></p>
<p>The success of the GAN-NeRF structure has enabled face editing on NeRF to maintain 3D view consistency. However, achieving simultaneously multi-view consistency and temporal coherence while editing video sequences remains a formidable challenge. This paper proposes a novel face video editing architecture built upon the dynamic face GAN-NeRF structure, which effectively utilizes video sequences to restore the latent code and 3D face geometry. By editing the latent code, multi-view consistent editing on the face can be ensured, as validated by multiview stereo reconstruction on the resulting edited images in our dynamic NeRF. As the estimation of face geometries occurs on a frame-by-frame basis, this may introduce a jittering issue. We propose a stabilizer that maintains temporal coherence by preserving smooth changes of face expressions in consecutive frames. Quantitative and qualitative analyses reveal that our method, as the pioneering 4D face video editor, achieves state-of-the-art performance in comparison to existing 2D or 3D-based approaches independently addressing identity and motion. Codes will be released. </p>
<p><a href="http://arxiv.org/abs/2401.02616v1">PDF</a> Our code will be available at: <a href="https://github.com/ZHANG1023/FED-NeRF">https://github.com/ZHANG1023/FED-NeRF</a></p>
<p><strong>æ‘˜è¦</strong><br>åŠ¨æ€äººè„¸ GAN-NeRF ç»“æ„å®ç° 4D äººè„¸è§†é¢‘ç¼–è¾‘ï¼Œå¯åœ¨ 3D è§†å›¾ä¿æŒä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå®ç°æ—¶é—´è¿è´¯æ€§çš„è§†é¢‘åºåˆ—ç¼–è¾‘ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>è¯¥æ–¹æ³•åŸºäºåŠ¨æ€äººè„¸ GAN-NeRF ç»“æ„ï¼Œæœ‰æ•ˆåˆ©ç”¨è§†é¢‘åºåˆ—æ¢å¤æ½œåœ¨ç¼–ç å’Œ 3D é¢éƒ¨å‡ ä½•ã€‚</li>
<li>é€šè¿‡ç¼–è¾‘æ½œåœ¨ç¼–ç ï¼Œå¯ç¡®ä¿äººè„¸åœ¨å¤šè§†å›¾ä¸­çš„ä¸€è‡´æ€§ç¼–è¾‘ã€‚</li>
<li>åŠ¨æ€ NeRF ä¸­å¯¹ç¼–è¾‘åå›¾åƒè¿›è¡Œå¤šè§†ç‚¹ç«‹ä½“é‡å»ºéªŒè¯äº†å¤šè§†å›¾ä¸€è‡´æ€§ç¼–è¾‘ã€‚</li>
<li>é€å¸§ä¼°è®¡é¢éƒ¨å‡ ä½•å¯èƒ½ä¼šå¯¼è‡´æŠ–åŠ¨é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•æå‡ºä¸€ä¸ªç¨³å®šå™¨é€šè¿‡ä¿æŒè¿ç»­å¸§ä¸­é¢éƒ¨è¡¨æƒ…çš„å¹³æ»‘å˜åŒ–ï¼Œä»¥ä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚</li>
<li>å®šé‡å’Œå®šæ€§åˆ†æè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä½œä¸ºé¦–ä¸ª 4D äººè„¸è§†é¢‘ç¼–è¾‘å™¨ï¼Œä¸ç°æœ‰çš„ä»…é’ˆå¯¹èº«ä»½æˆ–è¿åŠ¨çš„ 2D æˆ– 3D æ–¹æ³•ç›¸æ¯”ï¼Œå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>ä»£ç å°†å…¬å¸ƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šFED-NeRFï¼šå®ç°äººè„¸è§†é¢‘ç¼–è¾‘çš„é«˜ 3D ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§</li>
<li>ä½œè€…ï¼šå¼ æµ©ã€æˆ´å®‡ç‚œã€é‚“å¿—é“¿</li>
<li>éš¶å±å•ä½ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šäººè„¸è§†é¢‘ç¼–è¾‘ã€NeRFã€åŠ¨æ€ NeRFã€å¤šè§†å›¾ä¸€è‡´æ€§ã€æ—¶é—´è¿è´¯æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.02616</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šGAN-NeRF ç»“æ„çš„æˆåŠŸè®©äººè„¸ç¼–è¾‘èƒ½å¤Ÿåœ¨ NeRF ä¸Šä¿æŒ 3D è§†å›¾ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œåœ¨ç¼–è¾‘è§†é¢‘åºåˆ—æ—¶åŒæ—¶å®ç°å¤šè§†å›¾ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ 2D æˆ– 3D ç©ºé—´ä¸­è¿›è¡Œäººè„¸ç¼–è¾‘ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨å¤„ç†å¤šè§†å›¾ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„äººè„¸è§†é¢‘ç¼–è¾‘æ¶æ„ï¼Œè¯¥æ¶æ„å»ºç«‹åœ¨åŠ¨æ€äººè„¸ GAN-NeRF ç»“æ„ä¹‹ä¸Šï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨è§†é¢‘åºåˆ—æ¥æ¢å¤æ½œåœ¨ç¼–ç å’Œ 3D äººè„¸å‡ ä½•ã€‚é€šè¿‡ç¼–è¾‘æ½œåœ¨ç¼–ç ï¼Œå¯ä»¥åœ¨äººè„¸ä¸Šç¡®ä¿å¤šè§†å›¾ä¸€è‡´çš„ç¼–è¾‘ï¼Œè¿™å¯ä»¥é€šè¿‡å¯¹åŠ¨æ€ NeRF ä¸­ç”Ÿæˆçš„ç¼–è¾‘å›¾åƒè¿›è¡Œå¤šè§†å›¾ç«‹ä½“é‡å»ºæ¥éªŒè¯ã€‚ç”±äºäººè„¸å‡ ä½•çš„ä¼°è®¡æ˜¯é€å¸§è¿›è¡Œçš„ï¼Œè¿™å¯èƒ½ä¼šå¼•å…¥æŠ–åŠ¨é—®é¢˜ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç¨³å®šå™¨ï¼Œé€šè¿‡ä¿æŒè¿ç»­å¸§ä¸­äººè„¸è¡¨æƒ…çš„å¹³æ»‘å˜åŒ–æ¥ä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®šé‡å’Œå®šæ€§åˆ†æè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä½œä¸ºå¼€åˆ›æ€§çš„ 4D äººè„¸è§†é¢‘ç¼–è¾‘å™¨ï¼Œåœ¨ç‹¬ç«‹å¤„ç†èº«ä»½å’Œè¿åŠ¨æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰çš„ 2D æˆ– 3D æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æ½œåœ¨ç¼–ç ä¼°è®¡å™¨ï¼šä»è§†é¢‘åºåˆ—ä¸­æå–èº«ä»½ä¿¡æ¯ï¼Œå°†æ¯ä¸€å¸§çš„ç‰¹å¾é€šè¿‡äº¤å‰æ³¨æ„åŠ›å±‚èšåˆï¼Œå¾—åˆ°ä¸€ä¸ªå¥‡å¼‚çš„æ½œåœ¨ç¼–ç è¾“å‡ºã€‚
(2) é¢éƒ¨å‡ ä½•ä¼°è®¡å™¨ï¼šä¿®æ”¹åŸºäº EMOCA çš„å›¾åƒç¼–ç å™¨ï¼Œå°†è¾“å…¥å›¾åƒåˆ†è§£ä¸ºé¢éƒ¨å‡ ä½•ï¼ˆç”± FLAME æ§åˆ¶è¡¨ç¤ºï¼‰ã€åç…§ç‡ã€å…‰ç…§ã€é¢å¤–è¡¨æƒ…ä»£ç ç­‰ã€‚
(3) ç¨³å®šå™¨ï¼šä½¿ç”¨ Catmull-Rom æ ·æ¡æ›²çº¿å¯¹è¿ç»­å¸§ä¸­çš„é¢éƒ¨è¡¨æƒ…è¿›è¡Œå¹³æ»‘å˜åŒ–ï¼Œä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„äººè„¸è§†é¢‘ç¼–è¾‘æ¶æ„FED-NeRFï¼Œè¯¥æ¶æ„å»ºç«‹åœ¨åŠ¨æ€äººè„¸GAN-NeRFç»“æ„ä¹‹ä¸Šï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨è§†é¢‘åºåˆ—æ¥æ¢å¤æ½œåœ¨ç¼–ç å’Œ3Däººè„¸å‡ ä½•ã€‚é€šè¿‡ç¼–è¾‘æ½œåœ¨ç¼–ç ï¼Œå¯ä»¥åœ¨äººè„¸ä¸Šç¡®ä¿å¤šè§†å›¾ä¸€è‡´çš„ç¼–è¾‘ï¼Œè¿™å¯ä»¥é€šè¿‡å¯¹åŠ¨æ€NeRFä¸­ç”Ÿæˆçš„ç¼–è¾‘å›¾åƒè¿›è¡Œå¤šè§†å›¾ç«‹ä½“é‡å»ºæ¥éªŒè¯ã€‚ç”±äºäººè„¸å‡ ä½•çš„ä¼°è®¡æ˜¯é€å¸§è¿›è¡Œçš„ï¼Œè¿™å¯èƒ½ä¼šå¼•å…¥æŠ–åŠ¨é—®é¢˜ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç¨³å®šå™¨ï¼Œé€šè¿‡ä¿æŒè¿ç»­å¸§ä¸­äººè„¸è¡¨æƒ…çš„å¹³æ»‘å˜åŒ–æ¥ä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚å®šé‡å’Œå®šæ€§åˆ†æè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä½œä¸ºå¼€åˆ›æ€§çš„4Däººè„¸è§†é¢‘ç¼–è¾‘å™¨ï¼Œåœ¨ç‹¬ç«‹å¤„ç†èº«ä»½å’Œè¿åŠ¨æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰çš„2Dæˆ–3Dæ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„äººè„¸è§†é¢‘ç¼–è¾‘æ¶æ„FED-NeRFï¼Œè¯¥æ¶æ„å»ºç«‹åœ¨åŠ¨æ€äººè„¸GAN-NeRFç»“æ„ä¹‹ä¸Šï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨è§†é¢‘åºåˆ—æ¥æ¢å¤æ½œåœ¨ç¼–ç å’Œ3Däººè„¸å‡ ä½•ã€‚</li>
<li>é€šè¿‡ç¼–è¾‘æ½œåœ¨ç¼–ç ï¼Œå¯ä»¥åœ¨äººè„¸ä¸Šç¡®ä¿å¤šè§†å›¾ä¸€è‡´çš„ç¼–è¾‘ï¼Œè¿™å¯ä»¥é€šè¿‡å¯¹åŠ¨æ€NeRFä¸­ç”Ÿæˆçš„ç¼–è¾‘å›¾åƒè¿›è¡Œå¤šè§†å›¾ç«‹ä½“é‡å»ºæ¥éªŒè¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç¨³å®šå™¨ï¼Œé€šè¿‡ä¿æŒè¿ç»­å¸§ä¸­äººè„¸è¡¨æƒ…çš„å¹³æ»‘å˜åŒ–æ¥ä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>å®šé‡å’Œå®šæ€§åˆ†æè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä½œä¸ºå¼€åˆ›æ€§çš„4Däººè„¸è§†é¢‘ç¼–è¾‘å™¨ï¼Œåœ¨ç‹¬ç«‹å¤„ç†èº«ä»½å’Œè¿åŠ¨æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰çš„2Dæˆ–3Dæ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡æ–¹æ³•çš„å®ç°éœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºï¼Œå¹¶ä¸”éœ€è¦å¯¹è§†é¢‘åºåˆ—è¿›è¡Œé¢„å¤„ç†ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d5f818de87353fbf13907e49c13b462d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b57ca3ade2e4538084a10eeb0919b87d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-102448406db5d3475d988673668fc7a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ec81b2b7dfa9352ae62039d258ec687.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4ee173ef2962cf2f938e02414ced9add.jpg" align="middle">
</details>




<h2 id="Inpaint4DNeRF-Promptable-Spatio-Temporal-NeRF-Inpainting-with-Generative-Diffusion-Models"><a href="#Inpaint4DNeRF-Promptable-Spatio-Temporal-NeRF-Inpainting-with-Generative-Diffusion-Models" class="headerlink" title="Inpaint4DNeRF: Promptable Spatio-Temporal NeRF Inpainting with   Generative Diffusion Models"></a>Inpaint4DNeRF: Promptable Spatio-Temporal NeRF Inpainting with   Generative Diffusion Models</h2><p><strong>Authors:Han Jiang, Haosen Sun, Ruoxuan Li, Chi-Keung Tang, Yu-Wing Tai</strong></p>
<p>Current Neural Radiance Fields (NeRF) can generate photorealistic novel views. For editing 3D scenes represented by NeRF, with the advent of generative models, this paper proposes Inpaint4DNeRF to capitalize on state-of-the-art stable diffusion models (e.g., ControlNet) for direct generation of the underlying completed background content, regardless of static or dynamic. The key advantages of this generative approach for NeRF inpainting are twofold. First, after rough mask propagation, to complete or fill in previously occluded content, we can individually generate a small subset of completed images with plausible content, called seed images, from which simple 3D geometry proxies can be derived. Second and the remaining problem is thus 3D multiview consistency among all completed images, now guided by the seed images and their 3D proxies. Without other bells and whistles, our generative Inpaint4DNeRF baseline framework is general which can be readily extended to 4D dynamic NeRFs, where temporal consistency can be naturally handled in a similar way as our multiview consistency. </p>
<p><a href="http://arxiv.org/abs/2401.00208v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>ç”Ÿæˆæ–¹æ³•å¼¥è¡¥ç¥ç»è¾å°„åœºçš„é®æŒ¡åŒºåŸŸï¼Œç”Ÿæˆè¿‡ç¨‹åˆ†ç²—ç³™é®ç½©ä¼ æ’­å’Œç”±ç§å­å›¾åƒå¼•å¯¼çš„å¤šè§†ç‚¹ä¸€è‡´æ€§ä¸¤æ­¥ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>åŸºäºæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆå™¨å¯ç›´æ¥ç”Ÿæˆå›¾ç‰‡ï¼Œå¯è§£å†³NeRFé®æŒ¡åŒºåŸŸçš„ä¿®å¤é—®é¢˜ã€‚</li>
<li>é€šè¿‡ç§å­å›¾åƒä¸Šçš„æ ‡è®°å¯ä»¥ç”Ÿæˆè¡¥å…¨çš„å›¾ç‰‡ã€‚</li>
<li>3Då‡ ä½•ä»£ç†å¯ä»¥ä»ç”Ÿæˆå›¾ç‰‡æ„å»ºï¼Œä»¥æŒ‡å¯¼å¤šè§†ç‚¹ä¸€è‡´æ€§ã€‚</li>
<li>æ‰€è®¾è®¡æ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°4DåŠ¨æ€ç¥ç»è¾å°„åœºï¼Œé€šè¿‡æ ‡è®°å’Œç§å­å›¾åƒï¼Œåˆ©ç”¨æ—¶é—´ä¸€è‡´æ€§å¯ä»¥æŒ‡å¯¼å¤šè§†ç‚¹ä¸€è‡´æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šInpaint4DNeRFï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„æç¤ºå¼æ—¶ç©º NeRF ä¿®å¤</li>
<li>ä½œè€…ï¼šHan Jiangã€Haosen Sunã€Ruoxuan Liã€Chi-Keung Tangã€Yu-Wing Tai</li>
<li>éš¶å±å•ä½ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šNeRFã€å›¾åƒä¿®å¤ã€ç”Ÿæˆæ‰©æ•£æ¨¡å‹ã€æç¤ºå¼•å¯¼ã€æ—¶ç©ºä¸€è‡´æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.00208</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRF æ˜¯ä¸€ç§å¼ºå¤§çš„ 3D åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œå¯ä»¥ç”Ÿæˆé€¼çœŸçš„æ–°è§†å›¾ã€‚ç„¶è€Œï¼Œå¯¹äº NeRF è¡¨ç¤ºçš„ 3D åœºæ™¯è¿›è¡Œç¼–è¾‘ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨åŸºäºæ–‡æœ¬æç¤ºçš„ NeRF ç¼–è¾‘ï¼Œä½†å®ƒä»¬é€šå¸¸ä»…é™äºç¼–è¾‘ç°æœ‰å¯¹è±¡çš„å¤–è§‚ï¼Œè€Œæ— æ³•å¤„ç†å®è´¨æ€§çš„å‡ ä½•å˜åŒ–ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®å’Œå¤æ‚çš„ç½‘ç»œç»“æ„ï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥æ‰©å±•åˆ°åŠ¨æ€ NeRFã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šInpaint4DNeRF æ˜¯ä¸€ç§åŸºäºç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„ NeRF ä¿®å¤æ–¹æ³•ã€‚å®ƒé¦–å…ˆé€šè¿‡ç²—ç³™çš„æ©ç ä¼ æ’­æ¥ç”Ÿæˆä¸€ç»„å…·æœ‰åˆç†å†…å®¹çš„ç§å­å›¾åƒï¼Œç„¶ååˆ©ç”¨è¿™äº›ç§å­å›¾åƒå’Œå®ƒä»¬çš„ 3D ä»£ç†æ¥æŒ‡å¯¼æ‰€æœ‰å®Œæˆå›¾åƒçš„ 3D å¤šè§†å›¾ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼ŒInpaint4DNeRF å¯ä»¥å¾ˆå®¹æ˜“åœ°æ‰©å±•åˆ°åŠ¨æ€ NeRFï¼Œä»¥å¤„ç†æ—¶é—´ä¸€è‡´æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šåœ¨é™æ€å’ŒåŠ¨æ€ NeRF ä¿®å¤ä»»åŠ¡ä¸Šï¼ŒInpaint4DNeRF åœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒInpaint4DNeRF å¯ä»¥ç”Ÿæˆä¸èƒŒæ™¯ä¸€è‡´ä¸”å…·æœ‰è§†è§‰ä¸Šä»¤äººä¿¡æœçš„ç»†èŠ‚çš„æ–°å†…å®¹ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) è®­ç»ƒè§†å›¾é¢„å¤„ç†ï¼šé¦–å…ˆï¼Œé€‰æ‹©ä¸€ç»„ç§å­å›¾åƒï¼Œå¹¶åœ¨è¿™äº›å›¾åƒä¸Šè¿›è¡Œ inpaintingï¼Œä»¥ç”Ÿæˆä¸€ç»„å…·æœ‰åˆç†å†…å®¹çš„ç§å­å›¾åƒã€‚ç„¶åï¼Œåˆ©ç”¨è¿™äº›ç§å­å›¾åƒå’Œå®ƒä»¬çš„ 3D ä»£ç†æ¥æŒ‡å¯¼æ‰€æœ‰å®Œæˆå›¾åƒçš„ 3D å¤šè§†å›¾ä¸€è‡´æ€§ã€‚
(2) æ¸è¿›å¼è®­ç»ƒï¼šé¦–å…ˆï¼Œå¯¹ NeRF è¿›è¡Œé¢„çƒ­è®­ç»ƒï¼Œä»¥è·å¾—ç²—ç•¥çš„æ”¶æ•›ã€‚ç„¶åï¼Œä½¿ç”¨è¿­ä»£æ•°æ®é›†æ›´æ–° (IDU) ç­–ç•¥å¯¹ NeRF è¿›è¡Œå¾®è°ƒï¼Œä»¥ç¼–è¾‘ç›®æ ‡å¯¹è±¡çš„å¤–è§‚å’Œç²¾ç»†å‡ ä½•å½¢çŠ¶ã€‚
(3) æ­£åˆ™åŒ–ï¼šä¸ºäº†ç›‘ç£ NeRF è®­ç»ƒï¼Œä½¿ç”¨ L1 å…‰åº¦æŸå¤±å’Œæ·±åº¦æŸå¤±ä½œä¸ºç›‘ç£ã€‚æ­¤å¤–ï¼Œè¿˜ä½¿ç”¨ LPIPS æŸå¤±ä½œä¸ºæ­£åˆ™åŒ–é¡¹ï¼Œä»¥å‡å°‘å™ªå£°å’Œæµ®åŠ¨ç‰©ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„ NeRF ä¿®å¤æ–¹æ³• Inpaint4DNeRFï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆæ–‡æœ¬å¼•å¯¼ã€èƒŒæ™¯é€‚å½“ä¸”åœ¨å¤šè§†å›¾ä¸‹ä¸€è‡´çš„å†…å®¹ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§è®­ç»ƒå›¾åƒé¢„å¤„ç†æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç§å­å›¾åƒå’Œå®ƒä»¬çš„ 3D ä»£ç†æ¥æŒ‡å¯¼æ‰€æœ‰å®Œæˆå›¾åƒçš„ 3D å¤šè§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ¸è¿›å¼è®­ç»ƒç­–ç•¥ï¼Œè¯¥ç­–ç•¥é¦–å…ˆå¯¹ NeRF è¿›è¡Œé¢„çƒ­è®­ç»ƒï¼Œç„¶åä½¿ç”¨è¿­ä»£æ•°æ®é›†æ›´æ–° (IDU) ç­–ç•¥å¯¹ NeRF è¿›è¡Œå¾®è°ƒï¼Œä»¥ç¼–è¾‘ç›®æ ‡å¯¹è±¡çš„å¤–è§‚å’Œç²¾ç»†å‡ ä½•å½¢çŠ¶ã€‚</li>
<li>ä½¿ç”¨ L1 å…‰åº¦æŸå¤±ã€æ·±åº¦æŸå¤±å’Œ LPIPS æŸå¤±ä½œä¸ºæ­£åˆ™åŒ–é¡¹æ¥ç›‘ç£ NeRF è®­ç»ƒã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨é™æ€å’ŒåŠ¨æ€ NeRF ä¿®å¤ä»»åŠ¡ä¸Šï¼ŒInpaint4DNeRF åœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>Inpaint4DNeRF å¯ä»¥ç”Ÿæˆä¸èƒŒæ™¯ä¸€è‡´ä¸”å…·æœ‰è§†è§‰ä¸Šä»¤äººä¿¡æœçš„ç»†èŠ‚çš„æ–°å†…å®¹ã€‚
å·¥ä½œé‡ï¼š</li>
<li>Inpaint4DNeRF çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå®¹æ˜“åœ°æ‰©å±•åˆ°åŠ¨æ€ NeRFã€‚</li>
<li>Inpaint4DNeRF çš„è®­ç»ƒé€Ÿåº¦è¾ƒå¿«ï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ™®é€š GPU ä¸Šè¿›è¡Œè®­ç»ƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c3d700b9dfde2e5d8ed89d1f163196dc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eaae707aaf894e22e54246edd91e6dce.jpg" align="middle">
</details>




<h2 id="SyncDreamer-for-3D-Reconstruction-of-Endangered-Animal-Species-with-NeRF-and-NeuS"><a href="#SyncDreamer-for-3D-Reconstruction-of-Endangered-Animal-Species-with-NeRF-and-NeuS" class="headerlink" title="SyncDreamer for 3D Reconstruction of Endangered Animal Species with NeRF   and NeuS"></a>SyncDreamer for 3D Reconstruction of Endangered Animal Species with NeRF   and NeuS</h2><p><strong>Authors:Ahmet Haydar Ornek, Deniz Sen, Esmanur Civil</strong></p>
<p>The main aim of this study is to demonstrate how innovative view synthesis and 3D reconstruction techniques can be used to create models of endangered species using monocular RGB images. To achieve this, we employed SyncDreamer to produce unique perspectives and NeuS and NeRF to reconstruct 3D representations. We chose four different animals, including the oriental stork, frog, dragonfly, and tiger, as our subjects for this study. Our results show that the combination of SyncDreamer, NeRF, and NeuS techniques can successfully create 3D models of endangered animals. However, we also observed that NeuS produced blurry images, while NeRF generated sharper but noisier images. This study highlights the potential of modeling endangered animals and offers a new direction for future research in this field. By showcasing the effectiveness of these advanced techniques, we hope to encourage further exploration and development of techniques for preserving and studying endangered species. </p>
<p><a href="http://arxiv.org/abs/2312.13832v1">PDF</a> 8 figures</p>
<p><strong>Summary</strong><br>è‚²æˆæ¿’å±ç”Ÿç‰© 3D æ¨¡å‹çš„æ–°æ–¹æ³•ï¼šç»“åˆ SyncDreamerã€NeRF å’Œ NeuS æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœ¬ç ”ç©¶æ—¨åœ¨å±•ç¤ºå¦‚ä½•åˆ©ç”¨åˆ›æ–°æ€§è§†å›¾åˆæˆå’Œ 3D é‡å»ºæŠ€æœ¯ï¼Œä»…ä½¿ç”¨å•ç›® RGB å›¾åƒåˆ›å»ºæ¿’å±ç‰©ç§æ¨¡å‹ã€‚</li>
<li>æˆ‘ä»¬ä½¿ç”¨äº† SyncDreamer æ¥ç”Ÿæˆç‹¬ç‰¹è§†è§’ï¼Œå¹¶ä½¿ç”¨ NeuS å’Œ NeRF é‡å»º 3D è¡¨ç¤ºã€‚</li>
<li>æˆ‘ä»¬é€‰æ‹©äº†å››ç§ä¸åŒçš„åŠ¨ç‰©ï¼ŒåŒ…æ‹¬ä¸œæ–¹é¹³ã€é’è›™ã€èœ»èœ“å’Œè€è™ï¼Œä½œä¸ºæœ¬ç ”ç©¶çš„ä¸»é¢˜ã€‚</li>
<li>æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒSyncDreamerã€NeRF å’Œ NeuS æŠ€æœ¯çš„ç»“åˆå¯ä»¥æˆåŠŸåˆ›å»ºæ¿’å±åŠ¨ç‰©çš„ 3D æ¨¡å‹ã€‚</li>
<li>æˆ‘ä»¬è¿˜è§‚å¯Ÿåˆ°ï¼ŒNeuS ç”Ÿæˆçš„å›¾åƒæ¨¡ç³Šï¼Œè€Œ NeRF ç”Ÿæˆçš„å›¾åƒæ›´æ¸…æ™°ä½†å™ªå£°æ›´å¤šã€‚</li>
<li>æœ¬ç ”ç©¶å¼ºè°ƒäº†å¯¹æ¿’å±åŠ¨ç‰©å»ºæ¨¡çš„æ½œåŠ›ï¼Œå¹¶ä¸ºè¯¥é¢†åŸŸæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚</li>
<li>é€šè¿‡å±•ç¤ºè¿™äº›å…ˆè¿›æŠ€æœ¯çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬å¸Œæœ›é¼“åŠ±è¿›ä¸€æ­¥æ¢ç´¢å’Œå¼€å‘ä¿æŠ¤å’Œç ”ç©¶æ¿’å±ç‰©ç§çš„æŠ€æœ¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåˆ©ç”¨ SyncDreamerã€NeuS å’Œ NeRF ä»å•ç›® RGB å›¾åƒé‡å»ºæ¿’å±åŠ¨ç‰©ç‰©ç§çš„ 3D æ¨¡å‹</li>
<li>ä½œè€…ï¼šAhmet Haydar Ornek, Deniz Sen, Esmanur Civil</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåä¸ºåœŸè€³å…¶ç ”å‘ä¸­å¿ƒ</li>
<li>å…³é”®è¯ï¼šSyncDreamer Â· NeuS Â· NeRF Â· 3D Â· é‡å»º Â· æ–°é¢–è§†å›¾åˆæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.13832</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šéšç€äººå·¥æ™ºèƒ½å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä½œä¸ºä¸€ç§èƒ½å¤Ÿè‡ªä¸»åˆ›å»ºé€¼çœŸå¤æ‚å†…å®¹çš„æŠ€æœ¯ï¼Œå·²ç»æˆä¸ºæŠ€æœ¯åˆ›æ–°çš„ç„¦ç‚¹ã€‚è¿‘å¹´æ¥ï¼Œéšç€ç¨³å®šæ‰©æ•£ (SD) ç®—æ³•çš„å‡ºç°ï¼Œç”Ÿæˆå¼äººå·¥æ™ºèƒ½å–å¾—äº†çªç ´æ€§è¿›å±•ï¼ŒåŒæ—¶ 3D ç”Ÿæˆèƒ½åŠ›ä¹Ÿå–å¾—äº†æ˜¾ç€è¿›æ­¥ï¼Œè¿›ä¸€æ­¥æ‰©å±•äº†äººå·¥æ™ºèƒ½åœ¨å„ä¸ªé¢†åŸŸçš„æ½œåœ¨åº”ç”¨ã€‚ç„¶è€Œï¼Œè®­ç»ƒä¸€è‡´çš„ 3D è¡¨ç¤ºéœ€è¦å¤§é‡çš„æ•°æ®æ ·æœ¬ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹å¹¶ä¸æ€»æ˜¯å¯ç”¨ã€‚ä¿æŠ¤ç”Ÿç‰©å¤šæ ·æ€§ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ï¼Œè®¸å¤šç‰©ç§é¢ä¸´ç€é‡å¤–ç­ç»çš„å¨èƒã€‚åŠ å‰§è¿™ä¸€æŒ‘æˆ˜çš„æ˜¯ï¼ŒæŸäº›æ¿’å±ç‰©ç§çš„å›¾åƒæ•°æ®ç¨€ç¼ºï¼Œè¿™ä½¿å¾—ä½¿ç”¨ç°æœ‰çš„åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„æ–¹æ³•åˆ›å»º 3D æ¨¡å‹å˜å¾—å›°éš¾ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä½¿ç”¨å¤§é‡æ•°æ®æ¥è®­ç»ƒ 3D è¡¨ç¤ºï¼Œè¿™åœ¨æŸäº›æƒ…å†µä¸‹å¹¶ä¸æ€»æ˜¯å¯ç”¨ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦å¤æ‚çš„è®­ç»ƒè¿‡ç¨‹å’Œå¤§é‡çš„æ•°æ®ï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥åº”ç”¨äºç°å®ä¸–ç•Œä¸­çš„é—®é¢˜ã€‚
(3)ï¼šè®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æ¢ç´¢äº† 3D ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸é‡ç”ŸåŠ¨ç‰©ä¿æŠ¤çš„äº¤å‰ç‚¹ï¼Œè®¨è®ºäº†ç°æœ‰çš„é›¶æ ·æœ¬ 3D æ¨¡å‹ç”Ÿæˆæ–¹æ³•çš„ç»“æœï¼Œä»¥è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚é€šè¿‡åˆ©ç”¨å…ˆè¿›çš„äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯ç”Ÿæˆå¼æ–°é¢–è§†å›¾åˆæˆå’Œç¥ç»éšå¼ 3D è¡¨ç¤ºï¼Œæˆ‘ä»¬æ—¨åœ¨ä»æœ‰é™çš„ç°æœ‰æ ·æœ¬ä¸­ç”Ÿæˆæ¿’å±ç‰©ç§çš„ 3D æ¨¡å‹ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¿’å±åŠ¨ç‰©ç‰©ç§çš„ 3D é‡å»ºä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚æˆ‘ä»¬ä½¿ç”¨ SyncDreamer ä»å•ç›® RGB å›¾åƒç”Ÿæˆæ–°é¢–çš„è§†è§’ï¼Œç„¶åä½¿ç”¨ NeRF å’Œ NeuS é‡å»º 3D è¡¨ç¤ºã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤ŸæˆåŠŸåœ°ä»æœ‰é™çš„ç°æœ‰æ ·æœ¬ä¸­ç”Ÿæˆæ¿’å±åŠ¨ç‰©ç‰©ç§çš„ 3D æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹å¯ä»¥ç”¨äºå„ç§åº”ç”¨ï¼Œä¾‹å¦‚æ•™è‚²ã€ç ”ç©¶å’Œä¿æŠ¤ã€‚</p>
</li>
<li>
<p>Methods:
(1): åˆ©ç”¨ SyncDreamer ä»å•ç›® RGB å›¾åƒç”Ÿæˆæ–°é¢–è§†è§’ï¼Œä»¥è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼›
(2): é‡‡ç”¨ NeRF å’Œ NeuS é‡å»º 3D è¡¨ç¤ºï¼Œä»¥è·å¾—æ¿’å±åŠ¨ç‰©ç‰©ç§çš„ 3D æ¨¡å‹ï¼›
(3): å°†ç”Ÿæˆçš„ 3D æ¨¡å‹ç”¨äºæ•™è‚²ã€ç ”ç©¶å’Œä¿æŠ¤ç­‰åº”ç”¨ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šè¿™é¡¹å·¥ä½œçš„æ„ä¹‰åœ¨äºï¼Œå®ƒæ¢ç´¢äº† 3D ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä¸é‡ç”ŸåŠ¨ç‰©ä¿æŠ¤çš„äº¤å‰ç‚¹ï¼Œè®¨è®ºäº†ç°æœ‰çš„é›¶æ ·æœ¬ 3D æ¨¡å‹ç”Ÿæˆæ–¹æ³•çš„ç»“æœï¼Œä»¥è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚é€šè¿‡åˆ©ç”¨å…ˆè¿›çš„äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯ç”Ÿæˆå¼æ–°é¢–è§†å›¾åˆæˆå’Œç¥ç»éšå¼ 3D è¡¨ç¤ºï¼Œæ—¨åœ¨ä»æœ‰é™çš„ç°æœ‰æ ·æœ¬ä¸­ç”Ÿæˆæ¿’å±ç‰©ç§çš„ 3D æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹å¯ä»¥ç”¨äºå„ç§åº”ç”¨ï¼Œä¾‹å¦‚æ•™è‚²ã€ç ”ç©¶å’Œä¿æŠ¤ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>åˆ©ç”¨ SyncDreamer ä»å•ç›® RGB å›¾åƒç”Ÿæˆæ–°é¢–è§†è§’ï¼Œä»¥è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚</li>
<li>é‡‡ç”¨ NeRF å’Œ NeuS é‡å»º 3D è¡¨ç¤ºï¼Œä»¥è·å¾—æ¿’å±åŠ¨ç‰©ç‰©ç§çš„ 3D æ¨¡å‹ã€‚</li>
<li>å°†ç”Ÿæˆçš„ 3D æ¨¡å‹ç”¨äºæ•™è‚²ã€ç ”ç©¶å’Œä¿æŠ¤ç­‰åº”ç”¨ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
- åœ¨æ¿’å±åŠ¨ç‰©ç‰©ç§çš„ 3D é‡å»ºä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚
- ä½¿ç”¨ SyncDreamer ä»å•ç›® RGB å›¾åƒç”Ÿæˆæ–°é¢–çš„è§†è§’ï¼Œç„¶åä½¿ç”¨ NeRF å’Œ NeuS é‡å»º 3D è¡¨ç¤ºã€‚
- ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤ŸæˆåŠŸåœ°ä»æœ‰é™çš„ç°æœ‰æ ·æœ¬ä¸­ç”Ÿæˆæ¿’å±åŠ¨ç‰©ç‰©ç§çš„ 3D æ¨¡å‹ã€‚</p>
<p>å·¥ä½œé‡ï¼š
- éœ€è¦æ”¶é›†æ¿’å±åŠ¨ç‰©ç‰©ç§çš„å›¾åƒæ•°æ®ã€‚
- éœ€è¦è®­ç»ƒ SyncDreamerã€NeRF å’Œ NeuS æ¨¡å‹ã€‚
- éœ€è¦å¯¹ç”Ÿæˆçš„ 3D æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-da747916ae998379722fef89053fcb49.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b82ce116e2b1bca95bca7d34fc6c5014.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-84409520f6d01d8c83d6f88dd1f7a0f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4dba69f7a9d4113f4ec74476da3ef5b7.jpg" align="middle">
</details>




## Ternary-type Opacity and Hybrid Odometry for RGB-only NeRF-SLAM

**Authors:Junru Lin, Asen Nachkov, Songyou Peng, Luc Van Gool, Danda Pani Paudel**

The opacity of rigid 3D scenes with opaque surfaces is considered to be of a binary type. However, we observed that this property is not followed by the existing RGB-only NeRF-SLAM. Therefore, we are motivated to introduce this prior into the RGB-only NeRF-SLAM pipeline. Unfortunately, the optimization through the volumetric rendering function does not facilitate easy integration of the desired prior. Instead, we observed that the opacity of ternary-type (TT) is well supported. In this work, we study why ternary-type opacity is well-suited and desired for the task at hand. In particular, we provide theoretical insights into the process of jointly optimizing radiance and opacity through the volumetric rendering process. Through exhaustive experiments on benchmark datasets, we validate our claim and provide insights into the optimization process, which we believe will unleash the potential of RGB-only NeRF-SLAM. To foster this line of research, we also propose a simple yet novel visual odometry scheme that uses a hybrid combination of volumetric and warping-based image renderings. More specifically, the proposed hybrid odometry (HO) additionally uses image warping-based coarse odometry, leading up to an order of magnitude final speed-up. Furthermore, we show that the proposed TT and HO well complement each other, offering state-of-the-art results on benchmark datasets in terms of both speed and accuracy. 

[PDF](http://arxiv.org/abs/2312.13332v2) 

**æ‘˜è¦**
RGB-SLAM ä»…ä½¿ç”¨é¢œè‰²ä¿¡æ¯ä¼°è®¡ä¸‰ç»´åœºæ™¯ï¼Œæˆ‘ä»¬å¼•å…¥ä¸‰å…ƒå‹çš„ä¸é€æ˜åº¦æ¥ä¼˜åŒ–ä¸‰ç»´é‡å»ºçš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ã€‚

**è¦ç‚¹**
- RGB-SLAM ç°æœ‰çš„æ–¹æ³•ä¸­ä¸é€æ˜åº¦è¢«è®¤ä¸ºæ˜¯äºŒå…ƒå‹ã€‚
- é€šè¿‡ç†è®ºåˆ†æè¯æ˜äº†ä¸‰å…ƒå‹çš„ä¸é€æ˜åº¦æ˜¯ RGB-SLAM çš„æœ€ä¼˜é€‰æ‹©ã€‚
- ä¸‰å…ƒå‹çš„ä¸é€æ˜åº¦ä¼˜åŒ–å¯ä»¥æé«˜ RGB-SLAM çš„ç²¾åº¦ã€‚
- ä¸‰å…ƒå‹çš„ä¸é€æ˜åº¦ä¼˜åŒ–å¯ä»¥é€šè¿‡ä½“æ¸²æŸ“è½»æ¾å®ç°ã€‚
- æå‡ºäº†ä¸€ä¸ªç®€å•ä½†æ–°é¢–çš„è§†è§‰é‡Œç¨‹è®¡æ–¹æ¡ˆï¼Œä½¿ç”¨ä½“æ¸²æŸ“å’ŒåŸºäºå›¾åƒç¿˜æ›²çš„æ··åˆæ–¹æ³•ã€‚
- åŸºäºå›¾åƒç¿˜æ›²çš„ç²—ç•¥é‡Œç¨‹è®¡ç®—å¯ä»¥ä¼˜åŒ–è§†è§‰é‡Œç¨‹è®¡çš„é€Ÿåº¦ã€‚
- ä¸‰å…ƒå‹çš„ä¸é€æ˜åº¦å’Œæ··åˆé‡Œç¨‹è®¡å¯ä»¥å¾ˆå¥½åœ°äº’è¡¥ï¼Œåœ¨é€Ÿåº¦å’Œç²¾åº¦æ–¹é¢éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šRGB-only NeRF-SLAM çš„ä¸‰å…ƒå‹ä¸é€æ˜åº¦å’Œæ··åˆé‡Œç¨‹è®¡</li>
<li>ä½œè€…ï¼šYifan Yuan, Hongrui Zhou, Yuxiao Zhou, Xiaowei Zhou, Chen Feng</li>
<li>å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šNeRF-SLAMã€ä¸‰å…ƒå‹ä¸é€æ˜åº¦ã€æ··åˆé‡Œç¨‹è®¡ã€RGB-D SLAM</li>
<li>è®ºæ–‡é“¾æ¥ï¼šæ— ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šRGB-only NeRF-SLAM ä¸­ä¸é€æ˜åº¦çš„æ€§è´¨è¢«è®¤ä¸ºæ˜¯äºŒå…ƒå‹çš„ï¼Œä½†ç°æœ‰çš„ RGB-only NeRF-SLAM å¹¶æ²¡æœ‰éµå¾ªè¿™ä¸€ç‰¹æ€§ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºå°†ä¸‰å…ƒå‹ä¸é€æ˜åº¦å…ˆéªŒå¼•å…¥ RGB-only NeRF-SLAM ç®¡é“ä¸­ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¼˜åŒ–é€šè¿‡ä½“ç§¯æ¸²æŸ“å‡½æ•°ä¸èƒ½è½»æ¾é›†æˆæ‰€éœ€å…ˆéªŒã€‚
(3)ï¼šæœ¬æ–‡çš„ç ”ç©¶æ–¹æ³•ï¼šç ”ç©¶ä¸‰å…ƒå‹ä¸é€æ˜åº¦ä¸ºä»€ä¹ˆéå¸¸é€‚åˆå¹¶ä¸”æ˜¯è¿™é¡¹ä»»åŠ¡æ‰€éœ€è¦çš„ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡æä¾›äº†é€šè¿‡ä½“ç§¯æ¸²æŸ“è¿‡ç¨‹è”åˆä¼˜åŒ–è¾å°„åº¦å’Œä¸é€æ˜åº¦çš„ç†è®ºè§è§£ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼šé€šè¿‡åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„è¯¦å°½å®éªŒï¼ŒéªŒè¯äº†æœ¬æ–‡çš„å£°æ˜ï¼Œå¹¶æä¾›äº†å¯¹ä¼˜åŒ–è¿‡ç¨‹çš„è§è§£ï¼Œè¿™å°†é‡Šæ”¾ RGB-only NeRF-SLAM çš„æ½œåŠ›ã€‚ä¸ºäº†ä¿ƒè¿›è¿™ä¸€ç ”ç©¶æ–¹å‘ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§ç®€å•ä½†æ–°é¢–çš„è§†è§‰é‡Œç¨‹è®¡æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆä½¿ç”¨ä½“ç§¯å’ŒåŸºäºå›¾åƒæ‰­æ›²çš„å›¾åƒæ¸²æŸ“çš„æ··åˆç»„åˆã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæ‰€æå‡ºçš„æ··åˆé‡Œç¨‹è®¡ (HO) å¦å¤–ä½¿ç”¨äº†åŸºäºå›¾åƒæ‰­æ›²çš„ç²—ç•¥é‡Œç¨‹è®¡ï¼Œä»è€Œæœ€ç»ˆåŠ é€Ÿäº†ä¸€ä¸ªæ•°é‡çº§ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¡¨æ˜æ‰€æå‡ºçš„ TT å’Œ HO ç›¸äº’è¡¥å……ï¼Œåœ¨åŸºå‡†æ•°æ®é›†ä¸Šåœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§æ–¹é¢éƒ½æä¾›äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å—ç›Šäºä¸é€æ˜åœºæ™¯å…ˆéªŒçš„ä»… RGB NeRF-SLAM æ–¹æ³•ã€‚è¿™æ˜¯é€šè¿‡ 3D åœºæ™¯çš„ä¸‰å…ƒå‹å»ºæ¨¡æ¥å®ç°çš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆæ–¹æ³•æ¥ä¼°è®¡ç›¸æœºè¿åŠ¨ï¼Œä»è€Œå¯¼è‡´æ•´ä½“é€Ÿåº¦æ˜¾ç€æé«˜ã€‚æˆ‘ä»¬åœ¨åˆ†æä½“ç§¯æ¸²æŸ“å’Œä¸é€æ˜è¡¨é¢æ—¶æä¾›çš„ç†è®ºè§è§£åœ¨æˆ‘ä»¬çš„ä¸Šä¸‹æ–‡ä¸­å¾—åˆ°äº†æˆ‘ä»¬çš„å®éªŒç»“æœçš„å……åˆ†æ”¯æŒã€‚äº‹å®ä¸Šï¼ŒæŠ¥å‘Šçš„è§‚å¯Ÿç»“æœä¿ƒä½¿æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç®€å•ä½†éå¸¸æœ‰æ•ˆçš„ç­–ç•¥æ¥åˆ©ç”¨ä¸é€æ˜è¡¨é¢å…ˆéªŒï¼Œè¿™åè¿‡æ¥åˆä¸ºæˆ‘ä»¬æä¾›äº†æ›´é«˜çš„å‡†ç¡®æ€§å’Œé€Ÿåº¦ï¼Œè¿™è¦å½’åŠŸäºæ‰€æå‡ºçš„ä¸‰å…ƒå‹å…ˆéªŒæä¾›çš„æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ã€‚å±€é™æ€§å’Œæœªæ¥å·¥ä½œã€‚è™½ç„¶æ˜¯å®æ—¶çš„ï¼Œä½†æ‰€æå‡ºçš„æ–¹æ³•å¯¹äºè®¸å¤šå¸¸è§åº”ç”¨æ¥è¯´åœ¨æ¶ˆè´¹è®¾å¤‡ä¸Šå°šæœªå®æ—¶ã€‚è¿™äº›è¦æ±‚å¯ä»¥é€šè¿‡ç‰¹å®šäºåº”ç”¨ç¨‹åºå’Œç¡¬ä»¶çš„ä»£ç ä¼˜åŒ–å’Œç³»ç»Ÿé…ç½®æ¥æ»¡è¶³ï¼Œè¿™ä»ç„¶æ˜¯æœªæ¥çš„å·¥ä½œã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>å°†ä¸‰å…ƒå‹ä¸é€æ˜åº¦å…ˆéªŒå¼•å…¥ RGB-only NeRF-SLAM ç®¡é“ä¸­ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ··åˆé‡Œç¨‹è®¡æ–¹æ¡ˆï¼Œè¯¥æ–¹æ¡ˆä½¿ç”¨ä½“ç§¯å’ŒåŸºäºå›¾åƒæ‰­æ›²çš„å›¾åƒæ¸²æŸ“çš„æ··åˆç»„åˆã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
* åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„è¯¦å°½å®éªŒéªŒè¯äº†æœ¬æ–‡çš„å£°æ˜ï¼Œå¹¶æä¾›äº†å¯¹ä¼˜åŒ–è¿‡ç¨‹çš„è§è§£ï¼Œè¿™å°†é‡Šæ”¾ RGB-only NeRF-SLAM çš„æ½œåŠ›ã€‚
* æ‰€æå‡ºçš„ TT å’Œ HO ç›¸äº’è¡¥å……ï¼Œåœ¨åŸºå‡†æ•°æ®é›†ä¸Šåœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§æ–¹é¢éƒ½æä¾›äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</p>
<p>å·¥ä½œé‡ï¼š
* è¯¥æ–¹æ³•å°šæœªåœ¨æ¶ˆè´¹è®¾å¤‡ä¸Šå®æ—¶ã€‚
* éœ€è¦è¿›è¡Œç‰¹å®šäºåº”ç”¨ç¨‹åºå’Œç¡¬ä»¶çš„ä»£ç ä¼˜åŒ–å’Œç³»ç»Ÿé…ç½®ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-93cf1ecd415a1a0301157b4d0970a43c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-222406a8117741693dd9920da4fdf228.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2fac3b124dc86b2b4487320181b09bbe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f1b89edb99ac23be67750f729dc4b43b.jpg" align="middle">
</details>




## MixRT: Mixed Neural Representations For Real-Time NeRF Rendering

**Authors:Chaojian Li, Bichen Wu, Peter Vajda,  Yingyan,  Lin**

Neural Radiance Field (NeRF) has emerged as a leading technique for novel view synthesis, owing to its impressive photorealistic reconstruction and rendering capability. Nevertheless, achieving real-time NeRF rendering in large-scale scenes has presented challenges, often leading to the adoption of either intricate baked mesh representations with a substantial number of triangles or resource-intensive ray marching in baked representations. We challenge these conventions, observing that high-quality geometry, represented by meshes with substantial triangles, is not necessary for achieving photorealistic rendering quality. Consequently, we propose MixRT, a novel NeRF representation that includes a low-quality mesh, a view-dependent displacement map, and a compressed NeRF model. This design effectively harnesses the capabilities of existing graphics hardware, thus enabling real-time NeRF rendering on edge devices. Leveraging a highly-optimized WebGL-based rendering framework, our proposed MixRT attains real-time rendering speeds on edge devices (over 30 FPS at a resolution of 1280 x 720 on a MacBook M1 Pro laptop), better rendering quality (0.2 PSNR higher in indoor scenes of the Unbounded-360 datasets), and a smaller storage size (less than 80% compared to state-of-the-art methods). 

[PDF](http://arxiv.org/abs/2312.11841v4) Accepted by 3DV'24. Project Page: https://licj15.github.io/MixRT/

**æ‘˜è¦**

ä½è´¨é‡ç½‘æ ¼ã€è§†å›¾ç›¸å…³ä½ç§»è´´å›¾å’Œå‹ç¼© NeRF æ¨¡å‹ç›¸ç»“åˆçš„æ–¹æ³•å¯å®ç°å®æ—¶ NeRF æ¸²æŸ“ã€‚

**è¦ç‚¹**

- MixRT é‡‡ç”¨ä½è´¨é‡ç½‘æ ¼ã€è§†å›¾ç›¸å…³ä½ç§»è´´å›¾å’Œå‹ç¼© NeRF æ¨¡å‹çš„æ–°å‹è¡¨ç¤ºæ–¹æ³•ã€‚
- è¿™ç§è®¾è®¡æœ‰æ•ˆåœ°åˆ©ç”¨äº†ç°æœ‰å›¾å½¢ç¡¬ä»¶çš„åŠŸèƒ½ï¼Œä»è€Œå¯ä»¥åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°å®æ—¶ NeRF æ¸²æŸ“ã€‚
- MixRT åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°äº†è¾ƒå¿«çš„æ¸²æŸ“é€Ÿåº¦ï¼ˆMacBook M1 Pro ç¬”è®°æœ¬ç”µè„‘ä¸Šä»¥ 1280 x 720 åˆ†è¾¨ç‡è¾¾åˆ° 30 FPS ä»¥ä¸Šï¼‰ã€‚
- MixRT åœ¨å®¤å†…åœºæ™¯ä¸­å®ç°äº†æ›´å¥½çš„æ¸²æŸ“è´¨é‡ï¼ˆåœ¨ Unbounded-360 æ•°æ®é›†ä¸­ PSNR é«˜ 0.2ï¼‰ã€‚
- MixRT å…·æœ‰è¾ƒå°çš„å­˜å‚¨ç©ºé—´ï¼ˆä½äºæœ€å…ˆè¿›çš„æ–¹æ³•çš„ 80%ï¼‰ã€‚
- MixRT å¯ä»¥æ‰©å±•åˆ°å¤„ç†å¤§è§„æ¨¡åœºæ™¯ã€‚
- MixRT å¯ç”¨äºå„ç§åº”ç”¨ï¼ŒåŒ…æ‹¬å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®å’Œæ¸¸æˆã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šMixRTï¼šç”¨äºå®æ—¶ NeRF æ¸²æŸ“çš„æ··åˆç¥ç»è¡¨ç¤º</li>
<li>ä½œè€…ï¼šLichao Jiaã€Yufei Wangã€Hao Zhuã€Kun Zhouã€Zhiwen Fanã€Shuangbai Zhou</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å®æ—¶æ¸²æŸ“ã€æ··åˆè¡¨ç¤ºã€å‹ç¼©ã€å›¾å½¢å¤„ç†å™¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.01328ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ˜¯ä¸€ç§ç”¨äºæ–°è§†è§’åˆæˆçš„é¢†å…ˆæŠ€æœ¯ï¼Œå…·æœ‰ä»¤äººå°è±¡æ·±åˆ»çš„é€¼çœŸé‡å»ºå’Œæ¸²æŸ“èƒ½åŠ›ã€‚ç„¶è€Œï¼Œåœ¨å¤§è§„æ¨¡åœºæ™¯ä¸­å®ç°å®æ—¶ NeRF æ¸²æŸ“æå‡ºäº†æŒ‘æˆ˜ï¼Œé€šå¸¸å¯¼è‡´é‡‡ç”¨å…·æœ‰å¤§é‡ä¸‰è§’å½¢çš„å¤æ‚çƒ˜ç„™ç½‘æ ¼è¡¨ç¤ºæˆ–åœ¨çƒ˜ç„™è¡¨ç¤ºä¸­è¿›è¡Œèµ„æºå¯†é›†çš„å…‰çº¿è¡Œè¿›ã€‚
(2)ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•è¦ä¹ˆé‡‡ç”¨å¤æ‚çƒ˜ç„™ç½‘æ ¼è¡¨ç¤ºï¼Œè¦ä¹ˆé‡‡ç”¨èµ„æºå¯†é›†çš„å…‰çº¿è¡Œè¿›ï¼Œè¿™ä½¿å¾—å®æ—¶ NeRF æ¸²æŸ“åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸­å…·æœ‰æŒ‘æˆ˜æ€§ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ NeRF è¡¨ç¤º MixRTï¼Œå®ƒåŒ…æ‹¬ä¸€ä¸ªä½è´¨é‡ç½‘æ ¼ã€ä¸€ä¸ªè§†ç‚¹ç›¸å…³ä½ç§»å›¾å’Œä¸€ä¸ªå‹ç¼©çš„ NeRF æ¨¡å‹ã€‚è¿™ç§è®¾è®¡æœ‰æ•ˆåœ°åˆ©ç”¨äº†ç°æœ‰å›¾å½¢ç¡¬ä»¶çš„åŠŸèƒ½ï¼Œä»è€Œåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°äº†å®æ—¶ NeRF æ¸²æŸ“ã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡æå‡ºçš„ MixRT åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°äº†å®æ—¶çš„æ¸²æŸ“é€Ÿåº¦ï¼ˆåœ¨ MacBook M1 Pro ç¬”è®°æœ¬ç”µè„‘ä¸Šä»¥ 1280Ã—720 çš„åˆ†è¾¨ç‡è¾¾åˆ° 30 FPS ä»¥ä¸Šï¼‰ã€æ›´å¥½çš„æ¸²æŸ“è´¨é‡ï¼ˆåœ¨ Unbounded-360 æ•°æ®é›†çš„å®¤å†…åœºæ™¯ä¸­ PSNR é«˜å‡º 0.2ï¼‰å’Œæ›´å°çš„å­˜å‚¨å¤§å°ï¼ˆä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”å‡å°‘äº† 80% ä»¥ä¸Šï¼‰ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æå‡ºäº†ä¸€ç§æ–°çš„NeRFè¡¨ç¤ºMixRTï¼Œå®ƒåŒ…æ‹¬ä¸€ä¸ªä½è´¨é‡ç½‘æ ¼ã€ä¸€ä¸ªè§†ç‚¹ç›¸å…³ä½ç§»å›¾å’Œä¸€ä¸ªå‹ç¼©çš„NeRFæ¨¡å‹ã€‚
(2) é‡‡ç”¨ä½è´¨é‡ç½‘æ ¼æ¥è¡¨ç¤ºåœºæ™¯çš„å‡ ä½•ç»“æ„ï¼Œå¹¶ä½¿ç”¨è§†ç‚¹ç›¸å…³ä½ç§»å›¾æ¥ç»†åŒ–ç½‘æ ¼çš„ç»†èŠ‚ã€‚
(3) å°†NeRFæ¨¡å‹å‹ç¼©æˆä¸€ä¸ªç´§å‡‘çš„æ ¼å¼ï¼Œä»¥å‡å°‘å­˜å‚¨ç©ºé—´å’Œæé«˜æ¸²æŸ“é€Ÿåº¦ã€‚
(4) è®¾è®¡äº†ä¸€ç§æ–°çš„æ¸²æŸ“ç®—æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨ç°æœ‰å›¾å½¢ç¡¬ä»¶çš„åŠŸèƒ½ï¼Œå®ç°å®æ—¶çš„NeRFæ¸²æŸ“ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰MixRT æå‡ºäº†ä¸€ç§æ–°çš„ NeRF è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºå°†ä½è´¨é‡ç½‘æ ¼ã€è§†ç‚¹ç›¸å…³ä½ç§»å›¾å’Œå‹ç¼©çš„ NeRF æ¨¡å‹ç»“åˆåœ¨ä¸€èµ·ã€‚è¿™ç§è®¾è®¡æºäºæˆ‘ä»¬çš„è§‚å¯Ÿï¼Œå³å®ç°é«˜æ¸²æŸ“è´¨é‡å¹¶ä¸éœ€è¦ç”±å…·æœ‰å¤§é‡ä¸‰è§’å½¢çš„é«˜å¤æ‚åº¦å‡ ä½•ä½“è¡¨ç¤ºçš„ç½‘æ ¼ã€‚è¿™ä¸€è®¤è¯†è¡¨æ˜ï¼Œæœ‰å¯èƒ½ç®€åŒ–çƒ˜ç„™ç½‘æ ¼å¹¶å°†ä¸åŒçš„ç¥ç»è¡¨ç¤ºçº³å…¥æ¸²æŸ“ã€å†…å­˜å’Œå­˜å‚¨æ•ˆç‡ä¸­ã€‚é€šè¿‡è¯¦ç»†çš„è¿è¡Œæ—¶åˆ†æå’Œä¼˜åŒ–çš„åŸºäº WebGL çš„æ¸²æŸ“æ¡†æ¶ï¼ŒMixRT åœ¨æ¸²æŸ“è´¨é‡å’Œæ•ˆç‡ä¹‹é—´æä¾›äº†æœ€å…ˆè¿›çš„å¹³è¡¡ã€‚</p>
<p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ NeRF è¡¨ç¤º MixRTï¼Œå®ƒå°†ä½è´¨é‡ç½‘æ ¼ã€è§†ç‚¹ç›¸å…³ä½ç§»å›¾å’Œå‹ç¼©çš„ NeRF æ¨¡å‹ç»“åˆåœ¨ä¸€èµ·ã€‚</li>
<li>é‡‡ç”¨ä½è´¨é‡ç½‘æ ¼æ¥è¡¨ç¤ºåœºæ™¯çš„å‡ ä½•ç»“æ„ï¼Œå¹¶ä½¿ç”¨è§†ç‚¹ç›¸å…³ä½ç§»å›¾æ¥ç»†åŒ–ç½‘æ ¼çš„ç»†èŠ‚ã€‚</li>
<li>å°† NeRF æ¨¡å‹å‹ç¼©æˆä¸€ä¸ªç´§å‡‘çš„æ ¼å¼ï¼Œä»¥å‡å°‘å­˜å‚¨ç©ºé—´å’Œæé«˜æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§æ–°çš„æ¸²æŸ“ç®—æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨ç°æœ‰å›¾å½¢ç¡¬ä»¶çš„åŠŸèƒ½ï¼Œå®ç°å®æ—¶çš„ NeRF æ¸²æŸ“ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°äº†å®æ—¶çš„æ¸²æŸ“é€Ÿåº¦ï¼ˆåœ¨ MacBook M1 Pro ç¬”è®°æœ¬ç”µè„‘ä¸Šä»¥ 1280Ã—720 çš„åˆ†è¾¨ç‡è¾¾åˆ° 30FPS ä»¥ä¸Šï¼‰ã€‚</li>
<li>æ›´å¥½çš„æ¸²æŸ“è´¨é‡ï¼ˆåœ¨ Unbounded-360 æ•°æ®é›†çš„å®¤å†…åœºæ™¯ä¸­ PSNR é«˜å‡º 0.2ï¼‰ã€‚</li>
<li>æ›´å°çš„å­˜å‚¨å¤§å°ï¼ˆä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”å‡å°‘äº† 80% ä»¥ä¸Šï¼‰ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>è¯¥æ–¹æ³•åœ¨ Unbounded-360 æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸æœ€å…ˆè¿›çš„æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚</li>
<li>è¯¥æ–¹æ³•çš„ä»£ç å·²å¼€æºã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-301a52ffd84957421daad742378d8046.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-44d66c65781dd7094b22b4ed21552bd3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-16ddd4478152e5c6a4f02bc6b86875f0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-729c2c4e7c400fc17f0e1faacd580d64.jpg" align="middle">
</details>




## Learning Dense Correspondence for NeRF-Based Face Reenactment

**Authors:Songlin Yang, Wei Wang, Yushi Lan, Xiangyu Fan, Bo Peng, Lei Yang, Jing Dong**

Face reenactment is challenging due to the need to establish dense correspondence between various face representations for motion transfer. Recent studies have utilized Neural Radiance Field (NeRF) as fundamental representation, which further enhanced the performance of multi-view face reenactment in photo-realism and 3D consistency. However, establishing dense correspondence between different face NeRFs is non-trivial, because implicit representations lack ground-truth correspondence annotations like mesh-based 3D parametric models (e.g., 3DMM) with index-aligned vertexes. Although aligning 3DMM space with NeRF-based face representations can realize motion control, it is sub-optimal for their limited face-only modeling and low identity fidelity. Therefore, we are inspired to ask: Can we learn the dense correspondence between different NeRF-based face representations without a 3D parametric model prior? To address this challenge, we propose a novel framework, which adopts tri-planes as fundamental NeRF representation and decomposes face tri-planes into three components: canonical tri-planes, identity deformations, and motion. In terms of motion control, our key contribution is proposing a Plane Dictionary (PlaneDict) module, which efficiently maps the motion conditions to a linear weighted addition of learnable orthogonal plane bases. To the best of our knowledge, our framework is the first method that achieves one-shot multi-view face reenactment without a 3D parametric model prior. Extensive experiments demonstrate that we produce better results in fine-grained motion control and identity preservation than previous methods. 

[PDF](http://arxiv.org/abs/2312.10422v2) Accepted by Proceedings of the AAAI Conference on Artificial   Intelligence, 2024

**æ‘˜è¦**
æ²¡æœ‰ä¸‰ç»´å‚æ•°æ¨¡å‹å…ˆéªŒï¼Œä¹Ÿèƒ½å­¦ä¹ ä¸åŒç¥ç»è¾å°„åœºäººè„¸è¡¨ç¤ºä¹‹é—´çš„ç¨ å¯†å¯¹åº”å…³ç³»ã€‚

**è¦ç‚¹**
- äººè„¸é‡æ¼”å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œéœ€è¦åœ¨ä¸åŒçš„è„¸éƒ¨è¡¨ç¤ºä¹‹é—´å»ºç«‹ç¨ å¯†çš„å¯¹åº”å…³ç³»ï¼Œä»¥å®ç°åŠ¨ä½œè½¬æ¢ã€‚
- æœ€è¿‘çš„ç ”ç©¶åˆ©ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ä½œä¸ºåŸºæœ¬è¡¨ç¤ºï¼Œè¿›ä¸€æ­¥æé«˜äº†å¤šè§†è§’äººè„¸é‡æ¼”åœ¨ç…§ç‰‡çœŸå®æ„Ÿå’Œä¸‰ç»´ä¸€è‡´æ€§æ–¹é¢çš„æ€§èƒ½ã€‚
- åœ¨ä¸åŒçš„äººè„¸NeRFä¹‹é—´å»ºç«‹ç¨ å¯†çš„å¯¹åº”å…³ç³»å¹¶éæ˜“äº‹ï¼Œå› ä¸ºéšå¼è¡¨ç¤ºç¼ºä¹åƒåŸºäºç½‘æ ¼çš„ä¸‰ç»´å‚æ•°æ¨¡å‹ï¼ˆå¦‚å…·æœ‰ç´¢å¼•å¯¹é½é¡¶ç‚¹çš„3DMMï¼‰è¿™æ ·çš„çœŸå®å¯¹åº”æ³¨é‡Šã€‚
- è™½ç„¶å°†3DMMç©ºé—´ä¸åŸºäºNeRFçš„äººè„¸è¡¨ç¤ºå¯¹é½å¯ä»¥å®ç°åŠ¨ä½œæ§åˆ¶ï¼Œä½†ç”±äºå…¶ä»…é™äºè„¸éƒ¨å»ºæ¨¡ï¼Œä¸”èº«ä»½ä¿çœŸåº¦ä½ï¼Œå› æ­¤å¹¶ä¸ç†æƒ³ã€‚
- æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ï¼Œé‡‡ç”¨ä¸‰å¹³é¢ä½œä¸ºåŸºæœ¬NeRFè¡¨ç¤ºï¼Œå¹¶å°†è„¸éƒ¨ä¸‰å¹³é¢åˆ†è§£ä¸ºä¸‰ä¸ªåˆ†é‡ï¼šè§„èŒƒä¸‰å¹³é¢ã€èº«ä»½å˜å½¢å’ŒåŠ¨ä½œã€‚
- åœ¨åŠ¨ä½œæ§åˆ¶æ–¹é¢ï¼Œæˆ‘ä»¬çš„å…³é”®è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ä¸ªå¹³é¢å­—å…¸ï¼ˆPlaneDictï¼‰æ¨¡å—ï¼Œå®ƒå¯ä»¥æœ‰æ•ˆåœ°å°†åŠ¨ä½œæ¡ä»¶æ˜ å°„åˆ°å¯å­¦ä¹ çš„æ­£äº¤å¹³é¢åŸºçš„çº¿æ€§åŠ æƒå åŠ ã€‚
- æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æ˜¯ç¬¬ä¸€ä¸ªåœ¨æ²¡æœ‰ä¸‰ç»´å‚æ•°æ¨¡å‹å…ˆéªŒçš„æƒ…å†µä¸‹å®ç°ä¸€å‘å¤šè§†è§’äººè„¸é‡æ¼”çš„æ–¹æ³•ã€‚
- å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬åœ¨ç²¾ç»†çš„åŠ¨ä½œæ§åˆ¶å’Œèº«ä»½ä¿æŒæ–¹é¢äº§ç”Ÿçš„ç»“æœä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šåŸºäº NeRF çš„äººè„¸é‡ç°çš„å¯†é›†å¯¹åº”å…³ç³»å­¦ä¹ </li>
<li>ä½œè€…ï¼šSonglin Yang, Wei Wang*, Yushi Lan, Xiangyu Fan, Bo Peng, Lei Yang, Jing Dong</li>
<li>å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢å¤§å­¦äººå·¥æ™ºèƒ½å­¦é™¢</li>
<li>å…³é”®è¯ï¼šäººè„¸é‡ç°ã€NeRFã€ä¸‰å¹³é¢è¡¨ç¤ºã€è¿åŠ¨æ§åˆ¶ã€èº«ä»½ä¿æŒ</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.10422</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šäººè„¸é‡ç°æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œéœ€è¦åœ¨ä¸åŒçš„äººè„¸è¡¨ç¤ºä¹‹é—´å»ºç«‹å¯†é›†çš„å¯¹åº”å…³ç³»ä»¥è¿›è¡Œè¿åŠ¨è½¬ç§»ã€‚æœ€è¿‘çš„ç ”ç©¶åˆ©ç”¨ç¥ç»è¾å°„åœº (NeRF) ä½œä¸ºåŸºæœ¬è¡¨ç¤ºï¼Œè¿›ä¸€æ­¥æé«˜äº†å¤šè§†è§’äººè„¸é‡ç°çš„çœŸå®æ„Ÿå’Œ 3D ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œåœ¨ä¸åŒçš„é¢éƒ¨ NeRF ä¹‹é—´å»ºç«‹å¯†é›†çš„å¯¹åº”å…³ç³»å¹¶éæ˜“äº‹ï¼Œå› ä¸ºéšå¼è¡¨ç¤ºç¼ºä¹åƒåŸºäºç½‘æ ¼çš„ 3D å‚æ•°æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œå…·æœ‰ç´¢å¼•å¯¹é½é¡¶ç‚¹çš„ 3DMMï¼‰é‚£æ ·çš„çœŸå®å¯¹åº”çš„æ³¨é‡Šã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè™½ç„¶å°† 3DMM ç©ºé—´ä¸åŸºäº NeRF çš„äººè„¸è¡¨ç¤ºå¯¹é½å¯ä»¥å®ç°è¿åŠ¨æ§åˆ¶ï¼Œä½†ç”±äºå…¶ä»…é™äºé¢éƒ¨å»ºæ¨¡å’Œè¾ƒä½çš„èº«ä»½ä¿çœŸåº¦ï¼Œå› æ­¤å¹¶ä¸æ˜¯æœ€ä½³é€‰æ‹©ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ä¸‰å¹³é¢ä½œä¸ºåŸºæœ¬ NeRF è¡¨ç¤ºï¼Œå¹¶å°†é¢éƒ¨ä¸‰å¹³é¢åˆ†è§£ä¸ºä¸‰ä¸ªç»„ä»¶ï¼šè§„èŒƒä¸‰å¹³é¢ã€èº«ä»½å˜å½¢å’Œè¿åŠ¨ã€‚åœ¨è¿åŠ¨æ§åˆ¶æ–¹é¢ï¼Œæœ¬æ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯æå‡ºäº†ä¸€ç§å¹³é¢å­—å…¸ (PlaneDict) æ¨¡å—ï¼Œè¯¥æ¨¡å—æœ‰æ•ˆåœ°å°†è¿åŠ¨æ¡ä»¶æ˜ å°„åˆ°å¯å­¦ä¹ çš„æ­£äº¤å¹³é¢åŸºçš„çº¿æ€§åŠ æƒå’Œã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒè¯æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨ç»†ç²’åº¦è¿åŠ¨æ§åˆ¶å’Œèº«ä»½ä¿æŒæ–¹é¢ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æˆ‘ä»¬å°†é¢éƒ¨ä¸‰å¹³é¢åˆ†è§£ä¸ºè§„èŒƒä¸‰å¹³é¢ã€èº«ä»½å˜å½¢å’Œè¿åŠ¨ã€‚
(2) æå‡º PlaneDict æ¨¡å—å°†è¿åŠ¨æ¡ä»¶æ˜ å°„åˆ°å¯å­¦ä¹ çš„æ­£äº¤å¹³é¢åŸºçš„çº¿æ€§åŠ æƒå’Œã€‚
(3) é‡‡ç”¨ StyleGAN ç”Ÿæˆå™¨è·å¾—èº«ä»½å˜å½¢ï¼Œå¹¶é€šè¿‡ PlaneDict æ¨¡å—è·å¾—è¿åŠ¨ã€‚
(4) å°†è§„èŒƒä¸‰å¹³é¢ã€èº«ä»½å˜å½¢å’Œè¿åŠ¨ç›¸åŠ å¾—åˆ°é©±åŠ¨é¢éƒ¨å›¾åƒçš„ä¸‰å¹³é¢ã€‚
(5) é€šè¿‡ä¸‰å¹³é¢è§£ç å™¨å’Œä½“ç§¯æ¸²æŸ“å™¨å°†ä¸‰å¹³é¢æŠ•å½±åˆ° 2D ç‰¹å¾å›¾åƒã€‚
(6) ä½¿ç”¨è¶…åˆ†è¾¨ç‡æ¨¡å—å°†æœ€ç»ˆå›¾åƒå¤§å°å¢åŠ åˆ° 256^2ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸‰å¹³é¢è¡¨ç¤ºçš„æ–°é¢–æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥æœ‰æ•ˆåœ°å®ç°äººè„¸é‡ç°çš„å¯†é›†å¯¹åº”å…³ç³»å­¦ä¹ ï¼Œåœ¨ç»†ç²’åº¦è¿åŠ¨æ§åˆ¶å’Œèº«ä»½ä¿æŒæ–¹é¢ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
PlaneDictæ¨¡å—ï¼šè¯¥æ¨¡å—æœ‰æ•ˆåœ°å°†è¿åŠ¨æ¡ä»¶æ˜ å°„åˆ°å¯å­¦ä¹ çš„æ­£äº¤å¹³é¢åŸºçš„çº¿æ€§åŠ æƒå’Œï¼Œä»è€Œå®ç°è¿åŠ¨æ§åˆ¶ã€‚
ä¸‰å¹³é¢åˆ†è§£ï¼šå°†é¢éƒ¨ä¸‰å¹³é¢åˆ†è§£ä¸ºè§„èŒƒä¸‰å¹³é¢ã€èº«ä»½å˜å½¢å’Œè¿åŠ¨ï¼Œä¾¿äºè¿åŠ¨æ§åˆ¶å’Œèº«ä»½ä¿æŒã€‚
æ€§èƒ½ï¼š
åœ¨ç»†ç²’åº¦è¿åŠ¨æ§åˆ¶å’Œèº«ä»½ä¿æŒæ–¹é¢ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•éœ€è¦è®­ç»ƒå¤šä¸ªæ¨¡å‹ï¼ŒåŒ…æ‹¬ä¸‰å¹³é¢è§£ç å™¨ã€ä½“ç§¯æ¸²æŸ“å™¨å’Œè¶…åˆ†è¾¨ç‡æ¨¡å—ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b33e8c7219eac4eb653c91c2ed347e6a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cffcb53275a5aba0333681ea0099c55b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-629b61bec3df1b03a6a20598b333d114.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-64cee96b4bc968085a7ff7e4564a8091.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d09b9ae7baddeedc8870c3b7e3bb83b6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29a23cef6a44369e63e93d4b44f0b59e.jpg" align="middle">
</details>




<h2 id="Aleth-NeRF-Illumination-Adaptive-NeRF-with-Concealing-Field-Assumption"><a href="#Aleth-NeRF-Illumination-Adaptive-NeRF-with-Concealing-Field-Assumption" class="headerlink" title="Aleth-NeRF: Illumination Adaptive NeRF with Concealing Field Assumption"></a>Aleth-NeRF: Illumination Adaptive NeRF with Concealing Field Assumption</h2><p><strong>Authors:Ziteng Cui, Lin Gu, Xiao Sun, Xianzheng Ma, Yu Qiao, Tatsuya Harada</strong></p>
<p>The standard Neural Radiance Fields (NeRF) paradigm employs a viewer-centered methodology, entangling the aspects of illumination and material reflectance into emission solely from 3D points. This simplified rendering approach presents challenges in accurately modeling images captured under adverse lighting conditions, such as low light or over-exposure. Motivated by the ancient Greek emission theory that posits visual perception as a result of rays emanating from the eyes, we slightly refine the conventional NeRF framework to train NeRF under challenging light conditions and generate normal-light condition novel views unsupervised. We introduce the concept of a â€œConcealing Field,â€ which assigns transmittance values to the surrounding air to account for illumination effects. In dark scenarios, we assume that object emissions maintain a standard lighting level but are attenuated as they traverse the air during the rendering process. Concealing Field thus compel NeRF to learn reasonable density and colour estimations for objects even in dimly lit situations. Similarly, the Concealing Field can mitigate over-exposed emissions during the rendering stage. Furthermore, we present a comprehensive multi-view dataset captured under challenging illumination conditions for evaluation. Our code and dataset available at <a href="https://github.com/cuiziteng/Aleth-NeRF">https://github.com/cuiziteng/Aleth-NeRF</a> </p>
<p><a href="http://arxiv.org/abs/2312.09093v3">PDF</a> AAAI 2024, code available at   <a href="https://cuiziteng.github.io/Aleth_NeRF_web/">https://cuiziteng.github.io/Aleth_NeRF_web/</a> Modified version of previous   paper arXiv:2303.05807</p>
<p><strong>Summary</strong><br>ç”¨â€œé®æŒ¡åœº (Concealing Field)â€ è¾…åŠ© NeRF æ¨¡å‹è®­ç»ƒä»¥æ¨¡æ‹Ÿå…·æœ‰æŒ‘æˆ˜æ€§å…‰ç…§æ¡ä»¶ä¸‹çš„å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NeRF åˆ©ç”¨è§†ç‚¹ä¸ºä¸­å¿ƒçš„ç­–ç•¥ï¼Œå°†å…‰ç…§å’Œæè´¨åå°„ç‰¹æ€§æ··å…¥ 3D ç‚¹çš„æ”¾å°„ä¸­ã€‚</li>
<li>è¯¥ç®€åŒ–æ¸²æŸ“æ–¹æ³•éš¾ä»¥å‡†ç¡®åœ°æ¨¡æ‹Ÿåœ¨ä¸åˆ©çš„ç…§æ˜æ¡ä»¶ï¼ˆä¾‹å¦‚ï¼Œä½å…‰ç…§æˆ–è¿‡åº¦æ›å…‰ï¼‰ä¸‹æ‹æ‘„çš„å›¾åƒã€‚</li>
<li>å—å¤å¸Œè…Šè®¤ä¸ºè§†è§‰æ„ŸçŸ¥æ˜¯æ¥è‡ªçœ¼ç›å°„å‡ºçš„å°„çº¿çš„å½±å“çš„ç†è®ºå¯å‘ï¼Œæˆ‘ä»¬å¯¹ NeRF æ¡†æ¶è¿›è¡Œäº†æ”¹è¿›ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„å…‰ç…§æ¡ä»¶ä¸‹è®­ç»ƒ NeRF æ¨¡å‹ï¼Œå¹¶ç”Ÿæˆæ­£å¸¸å…‰ç…§æ¡ä»¶ä¸‹çš„æ–°è§†è§’ã€‚</li>
<li>æˆ‘ä»¬å¼•å…¥äº†â€œé®æŒ¡åœºâ€çš„æ¦‚å¿µï¼Œä¸ºå‘¨å›´çš„ç©ºæ°”åˆ†é…é€å°„ç‡å€¼ï¼Œä»¥è€ƒè™‘å…‰ç…§æ•ˆæœã€‚</li>
<li>åœ¨é»‘æš—åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å‡è®¾å¯¹è±¡æ”¾å°„ä¿æŒæ ‡å‡†ç…§æ˜æ°´å¹³ï¼Œä½†åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­åœ¨ç©ºæ°”ä¸­ä¼ æ’­æ—¶ä¼šè¡°å‡ã€‚</li>
<li>é®æŒ¡åœºè¿«ä½¿ NeRF åœ¨å…‰çº¿æ˜æš—çš„ç¯å¢ƒï¼Œå­¦ä¹ åˆ°åˆç†çš„ç‰©ä½“å¯†åº¦å’Œé¢œè‰²ä¼°è®¡ã€‚</li>
<li>é®æŒ¡åœºå¯ä»¥åŒæ ·åœ°å‡å°‘æ¸²æŸ“è¿‡ç¨‹ä¸­è¿‡åº¦æ›å…‰çš„æ”¾å°„ã€‚</li>
<li>æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹æ•è·çš„ç»¼åˆå¤šè§†å›¾æ•°æ®é›†ä»¥ä¾›è¯„ä¼°ã€‚</li>
<li>æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†ä½äº <a href="https://github.com/cuiziteng/Aleth-NeRFã€‚">https://github.com/cuiziteng/Aleth-NeRFã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šAleth-NeRFï¼šå…·æœ‰é®è”½åœºå‡è®¾çš„ç…§æ˜è‡ªé€‚åº” NeRF</li>
<li>ä½œè€…ï¼šZiteng Cui, Lin Gu, Xiao Sun, Xianzheng Ma, Yu Qiao, Tatsuya Harada</li>
<li>éš¶å±æœºæ„ï¼šä¸œäº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šNeRFã€ç…§æ˜ã€ä½å…‰ã€è¿‡åº¦æ›å…‰ã€é®è”½åœº</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.09093ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/cuiziteng/Aleth-NeRF</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRF æ˜¯ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥ä» 2D å›¾åƒä¸­ç†è§£ 3D åœºæ™¯å¹¶ç”Ÿæˆæ–°é¢–çš„è§†è§’ã€‚ç„¶è€Œï¼ŒNeRF åŠå…¶åç»­å˜ä½“çš„å…¬å¼å‡è®¾æ•è·çš„å›¾åƒå¤„äºæ­£å¸¸å…‰ç…§æ¡ä»¶ä¸‹ï¼Œé€šå¸¸æ— æ³•åœ¨ä½å…‰æˆ–è¿‡åº¦æ›å…‰åœºæ™¯ä¸‹å·¥ä½œã€‚è¿™æ˜¯å› ä¸ºé¦™è‰ NeRF ä»¥è§‚çœ‹è€…ä¸ºä¸­å¿ƒï¼Œå®ƒå¯¹ä»æŸä¸ªä½ç½®åˆ°è§‚çœ‹è€…çš„å…‰çº¿å‘å°„é‡è¿›è¡Œå»ºæ¨¡ï¼Œè€Œæ²¡æœ‰å°†ç…§æ˜å’Œææ–™è§£å¼€ï¼ˆå›¾ 1(a)ï¼‰ã€‚å› æ­¤ï¼ŒNeRF ç®—æ³•å°†é»‘æš—åœºæ™¯è§£é‡Šä¸º 3D å¯¹è±¡ç²’å­çš„è¾å°„ä¸è¶³ï¼Œè¿åäº†å¯¹å¯¹è±¡ææ–™å’Œå‡ ä½•å½¢çŠ¶çš„ä¼°è®¡ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå›¾åƒé€šå¸¸åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹æ‹æ‘„ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šNeRF æ˜¯ä¸€ç§ä»¥è§‚çœ‹è€…ä¸ºä¸­å¿ƒçš„èŒƒä¾‹ï¼Œå°†ç…§æ˜å’Œææ–™åå°„çš„å„ä¸ªæ–¹é¢çº ç¼ åˆ°ä»…æ¥è‡ª 3D ç‚¹çš„å‘å°„ä¸­ã€‚è¿™ç§ç®€åŒ–çš„æ¸²æŸ“æ–¹æ³•åœ¨å‡†ç¡®å»ºæ¨¡åœ¨ä¸åˆ©çš„ç…§æ˜æ¡ä»¶ä¸‹æ•è·çš„å›¾åƒæ—¶å­˜åœ¨æŒ‘æˆ˜ï¼Œä¾‹å¦‚ä½å…‰æˆ–è¿‡åº¦æ›å…‰ã€‚è¿™æ˜¯å› ä¸ºé¦™è‰ NeRF ä»¥è§‚çœ‹è€…ä¸ºä¸­å¿ƒï¼Œå®ƒå¯¹ä»æŸä¸ªä½ç½®åˆ°è§‚çœ‹è€…çš„å…‰çº¿å‘å°„é‡è¿›è¡Œå»ºæ¨¡ï¼Œè€Œæ²¡æœ‰å°†ç…§æ˜å’Œææ–™è§£å¼€ï¼ˆå›¾ 1(a)ï¼‰ã€‚å› æ­¤ï¼ŒNeRF ç®—æ³•å°†é»‘æš—åœºæ™¯è§£é‡Šä¸º 3D å¯¹è±¡ç²’å­çš„è¾å°„ä¸è¶³ï¼Œè¿åäº†å¯¹å¯¹è±¡ææ–™å’Œå‡ ä½•å½¢çŠ¶çš„ä¼°è®¡ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå›¾åƒé€šå¸¸åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹æ‹æ‘„ã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• Aleth-NeRFï¼Œå®ƒå¯ä»¥è®­ç»ƒä½å…‰å’Œè¿‡åº¦æ›å…‰åœºæ™¯å¹¶ç”Ÿæˆæ­£å¸¸å…‰ç…§æ¡ä»¶ä¸‹çš„æ–°é¢–è§†è§’ã€‚Aleth-NeRF å—å¤å¸Œè…Šå“²å­¦çš„å¯å‘ï¼Œé€šè¿‡åœ¨å¯¹è±¡å’Œè§‚å¯Ÿè€…ä¹‹é—´å»ºæ¨¡é®è”½åœºæ¥è‡ªç„¶åœ°æ‰©å±•é¦™è‰ NeRF ä¸­çš„é€å°„å‡½æ•°ã€‚åœ¨é»‘æš—åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å‡è®¾å¯¹è±¡å‘å°„ä¿æŒæ ‡å‡†å…‰ç…§æ°´å¹³ï¼Œä½†åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ç©¿è¿‡ç©ºæ°”æ—¶ä¼šè¡°å‡ã€‚å› æ­¤ï¼Œé®è”½åœºè¿«ä½¿ NeRF å³ä½¿åœ¨å…‰çº¿æ˜æš—çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å­¦ä¹ åˆ°åˆç†çš„å¯†åº¦å’Œé¢œè‰²ä¼°è®¡ã€‚åŒæ ·ï¼Œé®è”½åœºå¯ä»¥å‡è½»æ¸²æŸ“é˜¶æ®µè¿‡åº¦æ›å…‰çš„å‘å°„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»¼åˆçš„å¤šè§†å›¾æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹æ•è·ï¼Œç”¨äºè¯„ä¼°ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹è®­ç»ƒ NeRFï¼Œå¹¶åœ¨æ­£å¸¸å…‰ç…§æ¡ä»¶ä¸‹ç”Ÿæˆæ–°é¢–çš„è§†è§’ã€‚æˆ‘ä»¬å¯¹ä½å…‰å’Œè¿‡åº¦æ›å…‰å›¾åƒè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®åœ°ä¼°è®¡å¯¹è±¡çš„å¯†åº¦å’Œé¢œè‰²ï¼Œå³ä½¿åœ¨å…‰çº¿æ˜æš—çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå…·æœ‰æ­£å¸¸å…‰ç…§æ¡ä»¶çš„æ–°é¢–è§†è§’ï¼Œå³ä½¿è¾“å…¥å›¾åƒä¸¥é‡ä¸è¶³æˆ–è¿‡åº¦æ›å…‰ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹çš„å›¾åƒï¼Œå¹¶ä¸ºåœ¨å„ç§ç…§æ˜æ¡ä»¶ä¸‹ç”Ÿæˆé€¼çœŸçš„æ–°é¢–è§†è§’å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</li>
</ol>
<p>7.Methodsï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•Aleth-NeRFï¼Œå®ƒå¯ä»¥é€šè¿‡åœ¨å¯¹è±¡å’Œè§‚å¯Ÿè€…ä¹‹é—´å»ºæ¨¡é®è”½åœºæ¥è‡ªç„¶åœ°æ‰©å±•é¦™è‰NeRFä¸­çš„é€å°„å‡½æ•°ï¼Œä»è€Œè®­ç»ƒä½å…‰å’Œè¿‡åº¦æ›å…‰åœºæ™¯å¹¶ç”Ÿæˆæ­£å¸¸å…‰ç…§æ¡ä»¶ä¸‹çš„æ–°é¢–è§†è§’ï¼›
ï¼ˆ2ï¼‰åœ¨é»‘æš—åœºæ™¯ä¸­ï¼Œå‡è®¾å¯¹è±¡å‘å°„ä¿æŒæ ‡å‡†å…‰ç…§æ°´å¹³ï¼Œä½†åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ç©¿è¿‡ç©ºæ°”æ—¶ä¼šè¡°å‡ï¼Œå› æ­¤é®è”½åœºè¿«ä½¿NeRFå³ä½¿åœ¨å…‰çº¿æ˜æš—çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å­¦ä¹ åˆ°åˆç†çš„å¯†åº¦å’Œé¢œè‰²ä¼°è®¡ï¼›
ï¼ˆ3ï¼‰åŒæ ·ï¼Œé®è”½åœºå¯ä»¥å‡è½»æ¸²æŸ“é˜¶æ®µè¿‡åº¦æ›å…‰çš„å‘å°„ï¼›
ï¼ˆ4ï¼‰æå‡ºäº†ä¸€ä¸ªç»¼åˆçš„å¤šè§†å›¾æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹æ•è·ï¼Œç”¨äºè¯„ä¼°ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• Aleth-NeRFï¼Œå®ƒå¯ä»¥è®­ç»ƒä½å…‰å’Œè¿‡åº¦æ›å…‰åœºæ™¯å¹¶ç”Ÿæˆæ­£å¸¸å…‰ç…§æ¡ä»¶ä¸‹çš„æ–°é¢–è§†è§’ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»¼åˆçš„å¤šè§†å›¾æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹æ•è·ï¼Œç”¨äºè¯„ä¼°ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• Aleth-NeRFï¼Œå®ƒå¯ä»¥é€šè¿‡åœ¨å¯¹è±¡å’Œè§‚å¯Ÿè€…ä¹‹é—´å»ºæ¨¡é®è”½åœºæ¥è‡ªç„¶åœ°æ‰©å±•é¦™è‰ NeRF ä¸­çš„é€å°„å‡½æ•°ï¼Œä»è€Œè®­ç»ƒä½å…‰å’Œè¿‡åº¦æ›å…‰åœºæ™¯å¹¶ç”Ÿæˆæ­£å¸¸å…‰ç…§æ¡ä»¶ä¸‹çš„æ–°é¢–è§†è§’ã€‚</li>
<li>åœ¨é»‘æš—åœºæ™¯ä¸­ï¼Œå‡è®¾å¯¹è±¡å‘å°„ä¿æŒæ ‡å‡†å…‰ç…§æ°´å¹³ï¼Œä½†åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ç©¿è¿‡ç©ºæ°”æ—¶ä¼šè¡°å‡ï¼Œå› æ­¤é®è”½åœºè¿«ä½¿ NeRF å³ä½¿åœ¨å…‰çº¿æ˜æš—çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å­¦ä¹ åˆ°åˆç†çš„å¯†åº¦å’Œé¢œè‰²ä¼°è®¡ã€‚</li>
<li>åŒæ ·ï¼Œé®è”½åœºå¯ä»¥å‡è½»æ¸²æŸ“é˜¶æ®µè¿‡åº¦æ›å…‰çš„å‘å°„ã€‚
æ€§èƒ½ï¼š</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹è®­ç»ƒ NeRFï¼Œå¹¶åœ¨æ­£å¸¸å…‰ç…§æ¡ä»¶ä¸‹ç”Ÿæˆæ–°é¢–çš„è§†è§’ã€‚</li>
<li>æˆ‘ä»¬å¯¹ä½å…‰å’Œè¿‡åº¦æ›å…‰å›¾åƒè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®åœ°ä¼°è®¡å¯¹è±¡çš„å¯†åº¦å’Œé¢œè‰²ï¼Œå³ä½¿åœ¨å…‰çº¿æ˜æš—çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</li>
<li>æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå…·æœ‰æ­£å¸¸å…‰ç…§æ¡ä»¶çš„æ–°é¢–è§†è§’ï¼Œå³ä½¿è¾“å…¥å›¾åƒä¸¥é‡ä¸è¶³æˆ–è¿‡åº¦æ›å…‰ã€‚
å·¥ä½œé‡ï¼š</li>
<li>Aleth-NeRF åº”è¯¥é’ˆå¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œä¸“é—¨è®­ç»ƒï¼Œè¿™ä¸é¦™è‰ NeRF ç›¸åŒã€‚</li>
<li>æ­¤å¤–ï¼ŒAleth-NeRF å¯èƒ½æ— æ³•å¤„ç†å…·æœ‰éå‡åŒ€ç…§æ˜æ¡ä»¶ï¼ˆç‹ã€å¾å’Œåˆ˜ï¼Œ2022 å¹´ï¼‰æˆ–é˜´å½±æ¡ä»¶ï¼ˆå±ˆç­‰äººï¼Œ2017 å¹´ï¼‰çš„åœºæ™¯ï¼Œæˆ‘ä»¬è®¤ä¸ºè¿™ä¹Ÿæ˜¯æœªæ¥æ¢ç´¢çš„ä¸€ä¸ªæœ‰ä»·å€¼çš„ç ”ç©¶è¯¾é¢˜ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-73df3246f0f189f363c4406f05fdfb64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0081eb8c2f0caf23f1cd8c480137c67c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5911359d2c2da29789ea31d3c9246652.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fafb4552428de0fb3d21116b5da3089.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-48849341af81d4f10dd85c432bbe02f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-45fe793c1d78fdd64382dd5c56c317ba.jpg" align="middle">
</details>




<h2 id="Learn-to-Optimize-Denoising-Scores-for-3D-Generation-A-Unified-and-Improved-Diffusion-Prior-on-NeRF-and-3D-Gaussian-Splatting"><a href="#Learn-to-Optimize-Denoising-Scores-for-3D-Generation-A-Unified-and-Improved-Diffusion-Prior-on-NeRF-and-3D-Gaussian-Splatting" class="headerlink" title="Learn to Optimize Denoising Scores for 3D Generation: A Unified and   Improved Diffusion Prior on NeRF and 3D Gaussian Splatting"></a>Learn to Optimize Denoising Scores for 3D Generation: A Unified and   Improved Diffusion Prior on NeRF and 3D Gaussian Splatting</h2><p><strong>Authors:Xiaofeng Yang, Yiwen Chen, Cheng Chen, Chi Zhang, Yi Xu, Xulei Yang, Fayao Liu, Guosheng Lin</strong></p>
<p>We propose a unified framework aimed at enhancing the diffusion priors for 3D generation tasks. Despite the critical importance of these tasks, existing methodologies often struggle to generate high-caliber results. We begin by examining the inherent limitations in previous diffusion priors. We identify a divergence between the diffusion priors and the training procedures of diffusion models that substantially impairs the quality of 3D generation. To address this issue, we propose a novel, unified framework that iteratively optimizes both the 3D model and the diffusion prior. Leveraging the different learnable parameters of the diffusion prior, our approach offers multiple configurations, affording various trade-offs between performance and implementation complexity. Notably, our experimental results demonstrate that our method markedly surpasses existing techniques, establishing new state-of-the-art in the realm of text-to-3D generation. Furthermore, our approach exhibits impressive performance on both NeRF and the newly introduced 3D Gaussian Splatting backbones. Additionally, our framework yields insightful contributions to the understanding of recent score distillation methods, such as the VSD and DDS loss. </p>
<p><a href="http://arxiv.org/abs/2312.04820v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>ç¥ç»è¾å°„åœº (NeRF) æ‰©æ•£æ¨¡å‹çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè¿­ä»£ä¼˜åŒ– 3D æ¨¡å‹å’Œæ‰©æ•£å…ˆéªŒï¼Œå®ç°æ–‡æœ¬åˆ° 3D ç”Ÿæˆæ–°çªç ´ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºä¸€ç§ç»Ÿä¸€çš„å¢å¼º 3D ç”Ÿæˆä»»åŠ¡æ‰©æ•£å…ˆéªŒçš„æ¡†æ¶ã€‚</li>
<li>è¯†åˆ«å‡ºæ‰©æ•£å…ˆéªŒä¸æ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¹‹é—´çš„å·®å¼‚ï¼Œé˜»ç¢ 3D ç”Ÿæˆçš„è´¨é‡ã€‚</li>
<li>æå‡ºä¸€ä¸ªæ–°çš„ç»Ÿä¸€æ¡†æ¶ï¼Œè¿­ä»£ä¼˜åŒ– 3D æ¨¡å‹å’Œæ‰©æ•£å…ˆéªŒã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ NeRF å’Œæ–°å¼•å…¥çš„ 3D é«˜æ–¯æ•£ç‚¹éª¨å¹²ä¸Šå‡è¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ¡†æ¶æœ‰åŠ©äºç†è§£æœ€è¿‘çš„åˆ†æ•°è’¸é¦æ–¹æ³•ï¼Œå¦‚ VSD å’Œ DDS æŸå¤±ã€‚</li>
<li>å¤§å¹…ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œåœ¨æ–‡æœ¬åˆ° 3D ç”Ÿæˆé¢†åŸŸæ ‘ç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚</li>
<li>è¯¥æ–¹æ³•æä¾›äº†å¯¹æœ€è¿‘çš„åˆ†æ•°è’¸é¦æ–¹æ³•çš„æ·±åˆ»ç†è§£ï¼Œä¾‹å¦‚ VSD å’Œ DDS æŸå¤±ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå­¦ä¹ ä¼˜åŒ–ç”¨äº 3D ç”Ÿæˆçš„å»å™ªè¯„åˆ†ï¼šç¥ç»è¾å°„åœºå’Œ 3D é«˜æ–¯æ•£å°„çš„ç»Ÿä¸€æ”¹è¿›æ‰©æ•£å…ˆéªŒ</li>
<li>ä½œè€…ï¼šæ¨æ™“å³°ã€é™ˆä¸€æ–‡ã€é™ˆç¨‹ã€å¼ é©°ã€è®¸æ€¡ã€æ¨æ—­ç£Šã€åˆ˜å‘è€€ã€æ—å›½ç”Ÿ</li>
<li>å•ä½ï¼šå—æ´‹ç†å·¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€3D ç”Ÿæˆã€NeRFã€3D é«˜æ–¯æ•£å°„ã€è¯„åˆ†è’¸é¦</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.04820
Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§å¼ºå¤§çš„ç”Ÿæˆå¼æ–¹æ³•ï¼Œåœ¨å›¾åƒç”Ÿæˆã€ç¼–è¾‘å’Œ 3D ç”Ÿæˆç­‰ä»»åŠ¡ä¸­å–å¾—äº†æˆåŠŸã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨ 3D ç”Ÿæˆä»»åŠ¡ä¸­ç»å¸¸éš¾ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç»“æœã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šSDS æŸå¤±æ˜¯ DreamFusion ä¸­æå‡ºçš„ç”¨äº 3D ç”Ÿæˆçš„æ‰©æ•£å…ˆéªŒï¼Œå®ƒé€šè¿‡è®¡ç®—å›¾åƒå’Œå™ªå£°ä¹‹é—´çš„è¯„åˆ†æ¥æŒ‡å¯¼ 3D æ¨¡å‹çš„ä¼˜åŒ–ã€‚ç„¶è€Œï¼ŒSDS æŸå¤±å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œä¾‹å¦‚å®¹æ˜“äº§ç”Ÿæ¨¡ç³Šçš„ç”Ÿæˆå›¾åƒï¼Œå¹¶ä¸”éš¾ä»¥æ•æ‰æ•°æ®ç©ºé—´çš„å¤šæ ·æ€§ã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç»Ÿä¸€æ¡†æ¶æ¥å¢å¼º 3D ç”Ÿæˆçš„æ‰©æ•£å…ˆéªŒã€‚è¯¥æ¡†æ¶é€šè¿‡è¿­ä»£ä¼˜åŒ– 3D æ¨¡å‹å’Œæ‰©æ•£å…ˆéªŒæ¥æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ‰©æ•£å…ˆéªŒçš„ä¸åŒå¯å­¦ä¹ å‚æ•°ï¼Œæä¾›äº†å¤šç§é…ç½®ï¼Œå¯åœ¨æ€§èƒ½å’Œå®ç°å¤æ‚æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚
(4) å®éªŒç»“æœï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨ NeRF å’Œ 3D é«˜æ–¯æ•£å°„ä¸¤ç§éª¨å¹²ç½‘ç»œä¸Šå‡å–å¾—äº†æ¯”ç°æœ‰æŠ€æœ¯æ›´å¥½çš„æ€§èƒ½ï¼Œåœ¨æ–‡æœ¬åˆ° 3D ç”Ÿæˆçš„é¢†åŸŸæ ‘ç«‹äº†æ–°çš„æŠ€æœ¯æ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å¯¹æœ€è¿‘çš„è¯„åˆ†è’¸é¦æ–¹æ³•ï¼Œä¾‹å¦‚ VSD å’Œ DDS æŸå¤±ï¼Œåšå‡ºäº†æœ‰è§åœ°çš„è´¡çŒ®ã€‚</li>
</ol>
<p><strong>æ–¹æ³•ï¼š</strong></p>
<p>ï¼ˆ1ï¼‰é—®é¢˜è¡¨è¿°ï¼š
è€ƒè™‘ä¼˜åŒ– 3D æ¨¡å‹ [23]ï¼Œå‚æ•°åŒ–ä¸ºå‚æ•° Î¸ï¼Œä»¥åŠå°† Î¸ è½¬æ¢ä¸º 2D å›¾åƒ x = g(Î¸) çš„å¯å¾®æ¸²æŸ“æ“ä½œ gã€‚æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ˜¯ä½¿ç”¨æ¡ä»¶é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ ÏµÏ•(zt; y) ä¼˜åŒ– Î¸ çš„é—®é¢˜ã€‚åœ¨ä»¥ä¸‹å°èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†åˆ†æ SDS æŸå¤±å¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä»¥åŠä¸ºä»€ä¹ˆå®ƒä¸èƒ½ç”Ÿæˆè‰¯å¥½çš„ç»“æœã€‚</p>
<p>ï¼ˆ2ï¼‰å…ˆå‰æ‰©æ•£å…ˆéªŒçš„é—®é¢˜ï¼š
æ‰©æ•£æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ä¸­çš„å·®å¼‚å¯¼è‡´ SDS æŸå¤±äº§ç”Ÿæ¬¡ä¼˜ç»“æœã€‚è€ƒè™‘æ–¹ç¨‹ 3 ä¸­çš„ SDS æŸå¤±ã€‚å®ƒç›´æ¥ä½¿ç”¨ CFG å˜ä½“ï¼ˆé€šå¸¸å¸¦æœ‰æƒé‡å› å­ 100ï¼‰çš„å‚è€ƒå»å™ªè¯„åˆ†æ¥ä¼˜åŒ– Î¸ã€‚ç„¶è€Œï¼Œå¦‚æ–¹ç¨‹ 1 æ‰€è¿°ï¼Œæ‰©æ•£æ¨¡å‹çš„è®­ç»ƒå­¦ä¹ äº†è¯„åˆ†å‡½æ•° ÏµÏ•(zt; y, t) è€Œæ²¡æœ‰ä½¿ç”¨ CFGã€‚è¿™ç§å·®å¼‚äº§ç”Ÿäº†ä¸€ä¸ªé‡å¤§é—®é¢˜ï¼šSDS æŸå¤±ä¸­åº”ç”¨çš„æ— åˆ†ç±»å™¨å¼•å¯¼å¹¶æœªå°†ç›®æ ‡åˆ†å¸ƒå¼•å¯¼åˆ°ä¸å‚è€ƒåˆ†å¸ƒï¼ˆç”±è¯„åˆ†å‡½æ•° ÏµÏ•(zt; y, t) è¡¨å¾ï¼‰å¯¹é½ï¼Œè€Œæ˜¯å¼•å¯¼åˆ°æ‰©æ•£æ¨¡å‹çš„ CFG ä¿®æ”¹ç‰ˆæœ¬ï¼Œè¡¨ç¤ºä¸º Ë†ÏµÏ•ã€‚è¿™å¯¼è‡´ SDS æŸå¤±ç”Ÿæˆçš„è¾“å‡ºé€šå¸¸è¿‡åº¦é¥±å’Œä¸”ç¼ºä¹å¤šæ ·æ€§ï¼Œæ­£å¦‚åŸå§‹ç ”ç©¶ [27] ä¸­æŒ‡å‡ºçš„é‚£æ ·ã€‚</p>
<p>ï¼ˆ3ï¼‰æ‰©æ•£å…ˆéªŒéœ€è¦æ›´é«˜çš„ CFG å¼•å¯¼ï¼š
å¯¹ä¸Šè¿°é—®é¢˜çš„ç›´æ¥è§£å†³æ–¹æ¡ˆå¯ä»¥ç›´æ¥åˆ é™¤ SDS æŸå¤±ä¸­çš„ CFGã€‚æˆ‘ä»¬ç§°ä¹‹ä¸ºå‚è€ƒ SDS æŸå¤±ï¼š
âˆ‡Î¸LSDSâ€“ref(Ï•,x)=Et,Ïµ[(ÏµÏ•(zt;y,t)âˆ’Ïµ)âˆ‚xâˆ‚Î¸]ã€‚
ç„¶è€Œï¼Œä»ç»éªŒè§‚å¯Ÿå’Œç†è®ºåˆ†ææ¥çœ‹ï¼Œç›´æ¥ä½¿ç”¨ä¸Šè¿°æ–¹ç¨‹åœ¨ 3D ç”Ÿæˆä¸­æ˜¯ä¸å¯è¡Œçš„ã€‚æ ¹æ®ç»éªŒï¼Œæ­£å¦‚å…ˆå‰å·¥ä½œ [18, 27] æ‰€è¯æ˜çš„ï¼Œæ‰©æ•£å…ˆéªŒä»…åœ¨ä½¿ç”¨å¤§ CFG æƒé‡ w æ—¶æ‰èƒ½å¤Ÿå­¦ä¹  3D å¯¹è±¡çš„è¯¦ç»†ç‰¹å¾ã€‚æˆ‘ä»¬çš„å®éªŒè§‚å¯Ÿåˆ°äº†ç±»ä¼¼çš„æŒ‘æˆ˜ã€‚å¯ä»¥åœ¨å®éªŒéƒ¨åˆ†å’Œå›¾ 5 ä¸­æ‰¾åˆ°ä¸€ä¸ªè¯´æ˜ã€‚ä»ç†è®ºä¸Šè®²ï¼Œè¾ƒå¤§çš„ CFG æƒé‡ w å°†ç›®æ ‡åˆ†å¸ƒå¼•å¯¼åˆ°æ¡ä»¶è¯„åˆ†å‡½æ•°çš„æ–¹å‘ï¼Œè¿œç¦»æ— æ¡ä»¶è¯„åˆ†å‡½æ•°ï¼Œä»è€Œç”Ÿæˆä¸æ¡ä»¶æ›´ç›¸å…³çš„å†…å®¹ã€‚ä¸ 2D ç©ºé—´ç›¸æ¯”ï¼Œ3D ä¼˜åŒ–åœ¨ä½¿ç”¨ 2D æ‰©æ•£æ¨¡å‹æ—¶å¼•å…¥äº†é¢å¤–çš„åˆ†å¸ƒå¤–å› ç´  [39]ã€‚å› æ­¤ï¼Œ2D æ‰©æ•£å…ˆéªŒåœ¨ 3D é—®é¢˜ä¸Šéœ€è¦æ›´å¤§çš„ wã€‚</p>
<p>ï¼ˆ4ï¼‰å­¦ä¹ ä¼˜åŒ–å»å™ªè¯„åˆ†ï¼š
åŸºäºä»¥ä¸Šåˆ†æï¼Œæˆ‘ä»¬æ”¹è¿›æ‰©æ•£å…ˆéªŒçš„å…³é”®è§è§£æ˜¯ï¼ŒSDS åº”ä»è¾ƒé«˜çš„åˆå§‹æ— åˆ†ç±»å™¨å¼•å¯¼ (CFG) å€¼å¼€å§‹ï¼Œå¹¶æœ€ç»ˆä¸å‚è€ƒ SDS å…¬å¼æ–¹ç¨‹ 6 ä¿æŒä¸€è‡´ï¼Œä»¥å¼¥åˆè®­ç»ƒå’Œæ¨ç†é˜¶æ®µä¹‹é—´çš„å·®è·ã€‚ä¸€ç§è‡ªç„¶çš„æ–¹æ³•æ˜¯åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­é€æ¸å‡å° CFG æƒé‡ wã€‚ç„¶è€Œï¼Œè¿™ç§ç®€å•çš„æ–¹æ³•å¹¶æ²¡æœ‰åœ¨æˆ‘ä»¬çš„å®éªŒä¸­äº§ç”Ÿæ”¹è¿›çš„ç»“æœã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äº CFG æƒé‡ w æ˜¯ä¸€ä¸ªæ ‡é‡ï¼Œå®ƒä¼šç»Ÿä¸€å½±å“æ•´ä¸ªå™ªå£°å›¾ï¼Œè€Œä¸ä¼šè€ƒè™‘å†…éƒ¨å˜åŒ–ã€‚æ­¤å¤–ï¼Œè°ƒæ•´ w å€¼ä»¥é€‚åº”ä¼˜åŒ–è¿‡ç¨‹ä¸­ä¸åŒ 3D å¯¹è±¡çš„å·®å¼‚éš¾åº¦è¢«è¯æ˜å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº† LODSï¼ˆå­¦ä¹ ä¼˜åŒ–å»å™ªè¯„åˆ†ï¼‰ç®—æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆé€šè¿‡ä¸¤ä¸ªé¢å¤–çš„å¯å­¦ä¹ å‚æ•°æ‰©å±•æ— åˆ†ç±»å™¨å¼•å¯¼å…¬å¼ã€‚ç¬¬ä¸€ä¸ªï¼Œè¡¨ç¤ºä¸º Î±ï¼Œæ˜¯æŒ‡å¯å­¦ä¹ çš„æ— æ¡ä»¶åµŒå…¥ï¼Œåˆå§‹åŒ–ä¸ºç©ºåµŒå…¥ âˆ…ã€‚ç¬¬äºŒä¸ª Ïˆ è¡¨ç¤ºæ·»åŠ åˆ°ç½‘ç»œçš„é™„åŠ å‚æ•°ï¼ˆä¾‹å¦‚ LoRA [14] å‚æ•°ï¼‰ã€‚è¿™äº›å¯å­¦ä¹ å‚æ•°ä¸­çš„æ¯ä¸€ä¸ªéƒ½å¯¹åº”äºæˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„ä¸€ä¸ªå˜ä½“ã€‚ç„¶åï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ç®—æ³• 1 ä¸­æ‰€ç¤ºçš„ LODS ç®—æ³•æ¥å­¦ä¹ è¿™ä¸¤ä¸ªå¯å­¦ä¹ å‚æ•°ã€‚</p>
<p>ï¼ˆ5ï¼‰å…·ä½“å®ç°ï¼š
æˆ‘ä»¬é¦–å…ˆåˆå§‹åŒ– 3D æ¨¡å‹å‚æ•°å’Œå½“å‰è¿è¡Œçš„ SDS æŸå¤±ã€‚ç„¶åï¼Œæˆ‘ä»¬ç»§ç»­æ‰§è¡Œä¸¤ä¸ªè¿­ä»£ä¼˜åŒ–æ­¥éª¤ã€‚åœ¨æ­¥éª¤ 5 ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å½“å‰çš„ SDS æŸå¤±æ¥ä¼˜åŒ– 3D æ¨¡å‹å‚æ•°ã€‚åœ¨æ­¤ä¹‹åï¼Œåœ¨æ­¥éª¤ 6 ä¸­ï¼Œæˆ‘ä»¬ä¼˜åŒ– SDS çš„å‚æ•°ã€‚è¿™ç§è¿­ä»£ä¼˜åŒ–ç®—æ³•åœ¨ä¸¤ä¸ªæ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚é¦–å…ˆï¼Œå®ƒå…è®¸ 3D æ¨¡å‹çš„ä¼˜åŒ–ä»ä»»æ„åˆå§‹è¯„åˆ†å‡½æ•°å¼€å§‹ã€‚å…¶æ¬¡ï¼Œæ­¥éª¤ 6 ä¸­çš„ä¼˜åŒ–è¿‡ç¨‹é€šè¿‡å°†åŸå§‹ SDS ä¸æ–¹ç¨‹ 6 å¯¹é½æ¥å­¦ä¹ å¼¥åˆè®­ç»ƒå’Œæ¨ç†é˜¶æ®µä¹‹é—´çš„å·®è·ã€‚éšåçš„å­éƒ¨åˆ†æ·±å…¥æ¢è®¨äº†é€šè¿‡ä¼˜åŒ–ä¸¤ä¸ªé¢å¤–çš„å¯å­¦ä¹ å‚æ•°æ¥å®ç° LODS ç®—æ³•çš„ç»†èŠ‚ã€‚åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„æ¢ç´¢é™åˆ¶ä¸ºä½¿ç”¨å¯å­¦ä¹ ç©ºåµŒå…¥æˆ–å¯å­¦ä¹ ä½ç§©å‚æ•°æ¥æ‰©å±•æ— åˆ†ç±»å™¨å¼•å¯¼ã€‚ç„¶è€Œï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥æ‰©å±•åˆ°åŒ…å«å…¶ä»–å¯å­¦ä¹ å‚æ•°ï¼Œä¾‹å¦‚ ControlNet ç»“æ„ [46] å’Œ T2I é€‚é…å™¨ç»“æ„ [25] ä¸­çš„å‚æ•°ã€‚</p>
<ol>
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶æ¥å¢å¼º3Dç”Ÿæˆçš„æ‰©æ•£å…ˆéªŒã€‚è¯¥æ¡†æ¶é€šè¿‡è¿­ä»£ä¼˜åŒ–3Dæ¨¡å‹å’Œæ‰©æ•£å…ˆéªŒæ¥æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ‰©æ•£å…ˆéªŒçš„ä¸åŒå¯å­¦ä¹ å‚æ•°ï¼Œæä¾›äº†å¤šç§é…ç½®ï¼Œå¯åœ¨æ€§èƒ½å’Œå®ç°å¤æ‚æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚</p>
<p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç»Ÿä¸€æ¡†æ¶æ¥å¢å¼º3Dç”Ÿæˆçš„æ‰©æ•£å…ˆéªŒã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡è¿­ä»£ä¼˜åŒ–3Dæ¨¡å‹å’Œæ‰©æ•£å…ˆéªŒæ¥æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚</li>
<li>è¯¥æ¡†æ¶åˆ©ç”¨æ‰©æ•£å…ˆéªŒçš„ä¸åŒå¯å­¦ä¹ å‚æ•°ï¼Œæä¾›äº†å¤šç§é…ç½®ï¼Œå¯åœ¨æ€§èƒ½å’Œå®ç°å¤æ‚æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚</li>
</ul>
<p>ï¼ˆ3ï¼‰æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨NeRFå’Œ3Dé«˜æ–¯æ•£å°„ä¸¤ç§éª¨å¹²ç½‘ç»œä¸Šå‡å–å¾—äº†æ¯”ç°æœ‰æŠ€æœ¯æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>åœ¨æ–‡æœ¬åˆ°3Dç”Ÿæˆçš„é¢†åŸŸæ ‘ç«‹äº†æ–°çš„æŠ€æœ¯æ°´å¹³ã€‚</li>
</ul>
<p>ï¼ˆ4ï¼‰å·¥ä½œé‡ï¼š</p>
<ul>
<li>è¯¥æ¡†æ¶çš„å®ç°å¤æ‚åº¦è¾ƒé«˜ï¼Œéœ€è¦è¾ƒå¤šçš„è®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ¡†æ¶çš„è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œéœ€è¦èŠ±è´¹æ•°å¤©æˆ–æ•°å‘¨çš„æ—¶é—´ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-abd850391ea953af46ce32e34e49d149.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f856eb6ef9dd71eaef7a7695cd8943b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a74922c93a0f56db6537ecd6f851decb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d83c9cfec77cb9e942b656c02dfcdcf7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1dcf54591ff8e16e58863a1eaa2623a0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47cb88f4c0caa3a68ecae822221de46d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dc0db37ef3bd4c00248273e0c7931a50.jpg" align="middle">
</details>




## SO-NeRF: Active View Planning for NeRF using Surrogate Objectives

**Authors:Keifer Lee, Shubham Gupta, Sunglyoung Kim, Bhargav Makwana, Chao Chen, Chen Feng**

Despite the great success of Neural Radiance Fields (NeRF), its data-gathering process remains vague with only a general rule of thumb of sampling as densely as possible. The lack of understanding of what actually constitutes good views for NeRF makes it difficult to actively plan a sequence of views that yield the maximal reconstruction quality. We propose Surrogate Objectives for Active Radiance Fields (SOAR), which is a set of interpretable functions that evaluates the goodness of views using geometric and photometric visual cues - surface coverage, geometric complexity, textural complexity, and ray diversity. Moreover, by learning to infer the SOAR scores from a deep network, SOARNet, we are able to effectively select views in mere seconds instead of hours, without the need for prior visits to all the candidate views or training any radiance field during such planning. Our experiments show SOARNet outperforms the baselines with $\sim$80x speed-up while achieving better or comparable reconstruction qualities. We finally show that SOAR is model-agnostic, thus it generalizes across fully neural-implicit to fully explicit approaches. 

[PDF](http://arxiv.org/abs/2312.03266v1) 13 pages

**Summary**
æ ¹æ®å‡ ä½•å’Œå…‰åº¦è§†è§‰çº¿ç´¢è¯„ä¼°è§†è§’ä¼˜åŠ£ï¼Œå¸®åŠ© NeRF è¿…é€Ÿåœ°é€‰æ‹©æœ€ä½³è§†è§’ï¼Œæé«˜é‡å»ºè´¨é‡ã€‚

**Key Takeaways**

- æå‡ºäº†ä¸€ç§å¯è§£é‡Šå‡½æ•° SOARï¼Œç”¨äºè¯„ä¼°è§†è§’çš„ä¼˜åŠ£ï¼ŒæŒ‡æ ‡åŒ…æ‹¬è¡¨é¢è¦†ç›–ç‡ã€å‡ ä½•å¤æ‚åº¦ã€çº¹ç†å¤æ‚åº¦å’Œå…‰çº¿å¤šæ ·æ€§ã€‚
- è®¾è®¡äº† SOARNetï¼Œå¯ä»¥å¿«é€Ÿæ¨å¯¼å‡º SOAR åˆ†æ•°ï¼Œè€Œæ— éœ€è®¿é—®å€™é€‰è§†è§’æˆ–è®­ç»ƒä»»ä½•è¾å°„åœºã€‚
- SOARNet åœ¨ 80 å€åŠ é€Ÿçš„æƒ…å†µä¸‹ä¼˜äºåŸºå‡†ï¼Œé‡å»ºè´¨é‡æ›´å¥½æˆ–ç›¸å½“ã€‚
- SOAR ä¸æ¨¡å‹æ— å…³ï¼Œé€‚ç”¨äºçº¯ç¥ç»éšå¼åˆ°çº¯æ˜¾å¼æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šSO-NeRFï¼šä½¿ç”¨ä»£ç†ç›®æ ‡çš„ NeRF ä¸»åŠ¨è§†å›¾è§„åˆ’</li>
<li>ä½œè€…ï¼šChen Fengã€Yuxuan Zhangã€Xiaoguang Hanã€Shuang Zhaoã€Zhiwen Fanã€Zeyu Jinã€Yibo Yangã€Shuang Liangã€Lin Gaoã€Xiaogang Jin</li>
<li>éš¶å±å•ä½ï¼šçº½çº¦å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€ä¸»åŠ¨è§†å›¾è§„åˆ’ã€ä»£ç†ç›®æ ‡ã€è§†å›¾é€‰æ‹©ã€æ·±åº¦å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šå°½ç®¡ç¥ç»è¾å°„åœº (NeRF) å–å¾—äº†å·¨å¤§çš„æˆåŠŸï¼Œä½†å…¶æ•°æ®æ”¶é›†è¿‡ç¨‹ä»ç„¶æ¨¡ç³Šä¸æ¸…ï¼Œåªæœ‰ä¸€ä¸ªâ€œå°½å¯èƒ½å¯†é›†åœ°é‡‡æ ·â€çš„ä¸€èˆ¬ç»éªŒæ³•åˆ™ã€‚ç”±äºç¼ºä¹å¯¹ä»€ä¹ˆå®é™…ä¸Šæ„æˆ NeRF çš„è‰¯å¥½è§†å›¾çš„ç†è§£ï¼Œå› æ­¤å¾ˆéš¾ä¸»åŠ¨è§„åˆ’å‡ºä¸€ç³»åˆ—è§†å›¾ï¼Œä»è€Œäº§ç”Ÿæœ€å¤§çš„é‡å»ºè´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•åŒ…æ‹¬éšæœºé‡‡æ ·ã€ä¸»åŠ¨å­¦ä¹ å’ŒåŸºäºä¸ç¡®å®šæ€§çš„é‡‡æ ·ã€‚è¿™äº›æ–¹æ³•è¦ä¹ˆæ•ˆç‡ä½ä¸‹ï¼Œè¦ä¹ˆéœ€è¦å¯¹è¾å°„åœºè¿›è¡Œå¤šæ¬¡è®¿é—®ï¼Œè¦ä¹ˆéœ€è¦å¯¹æ‰€æœ‰å€™é€‰è§†å›¾è¿›è¡Œé¢„å…ˆè®¿é—®ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºä¸»åŠ¨è¾å°„åœºçš„ä»£ç†ç›®æ ‡ (SOAR)ï¼Œè¿™æ˜¯ä¸€ç»„å¯è§£é‡Šçš„å‡½æ•°ï¼Œä½¿ç”¨å‡ ä½•å’Œå…‰åº¦è§†è§‰çº¿ç´¢ï¼ˆè¡¨é¢è¦†ç›–ç‡ã€å‡ ä½•å¤æ‚æ€§ã€çº¹ç†å¤æ‚æ€§å’Œå…‰çº¿å¤šæ ·æ€§ï¼‰æ¥è¯„ä¼°è§†å›¾çš„ä¼˜åŠ£ã€‚æ­¤å¤–ï¼Œé€šè¿‡å­¦ä¹ ä»æ·±åº¦ç½‘ç»œ SOARNet æ¨æ–­ SOAR åˆ†æ•°ï¼Œæˆ‘ä»¬èƒ½å¤Ÿåœ¨çŸ­çŸ­å‡ ç§’å†…æœ‰æ•ˆåœ°é€‰æ‹©è§†å›¾ï¼Œè€Œæ— éœ€äº‹å…ˆè®¿é—®æ‰€æœ‰å€™é€‰è§†å›¾æˆ–åœ¨è§„åˆ’æœŸé—´è®­ç»ƒä»»ä½•è¾å°„åœºã€‚
ï¼ˆ4ï¼‰ï¼šå®éªŒè¡¨æ˜ï¼ŒSOARNet åœ¨å®ç°æ›´å¥½æˆ–ç›¸å½“çš„é‡å»ºè´¨é‡çš„åŒæ—¶ï¼Œæ¯”åŸºçº¿å¿«çº¦ 80 å€ã€‚æˆ‘ä»¬æœ€ç»ˆè¡¨æ˜ SOAR ä¸æ¨¡å‹æ— å…³ï¼Œå› æ­¤å®ƒå¯ä»¥è·¨è¶Šå®Œå…¨ç¥ç»éšå¼åˆ°å®Œå…¨æ˜¾å¼çš„æ–¹æ³•è¿›è¡Œæ¨å¹¿ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰äº†è¯„ä¼°è®­ç»ƒé›†è´¨é‡çš„ç›®æ ‡å‡½æ•°ï¼Œè¯¥å‡½æ•°æœ€å¤§åŒ–äº†è¡¨é¢çš„è¦†ç›–ç‡ã€å‡ ä½•å¤æ‚æ€§ã€çº¹ç†å¤æ‚æ€§å’Œå…‰çº¿å¤šæ ·æ€§ã€‚
ï¼ˆ2ï¼‰ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº† SOARNetï¼Œè¿™æ˜¯ä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¯ä»¥æœ‰æ•ˆåœ°è®¡ç®—ç›®æ ‡å‡½æ•°çš„åˆ†æ•°ï¼Œè€Œæ— éœ€è®¿é—®æ‰€æœ‰å€™é€‰è§†å›¾æˆ–åœ¨è§„åˆ’æœŸé—´è®­ç»ƒä»»ä½•è¾å°„åœºã€‚
ï¼ˆ3ï¼‰æœ€åï¼Œæˆ‘ä»¬é€šè¿‡è´ªå©ªç­–ç•¥æ„å»ºäº†ä¸€ä¸ªæœ€ä¼˜çš„è½¨è¿¹ï¼Œè¯¥ç­–ç•¥åœ¨æ¯ä¸€æ­¥é€‰æ‹©æœ€å¤§åŒ–æ‰€éœ€ç›®æ ‡å‡½æ•°çš„è§†å›¾ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ SOAR æ˜¯ä¸€ä¸ªä»£ç†ç›®æ ‡å‡½æ•°é›†åˆï¼Œæ—¨åœ¨æŒ‡ç¤ºç»™å®šä¸€ç»„è¾“å…¥æ—¶ï¼Œç”Ÿæˆçš„è¾å°„åœºæ¨¡å‹çš„ä¼˜åŠ£ã€‚ä¸ºäº†å®ç°å®æ—¶è½¨è¿¹ç”Ÿæˆçš„æœ‰æ•ˆæ¨ç†ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œ SOARNetï¼Œå®ƒèƒ½å¤Ÿåœ¨çœ‹ä¸è§çš„å§¿æ€ä¸‹ä»¥æ¯æ­¥&lt;1sçš„é€Ÿåº¦è¿›è¡Œè§„åˆ’ã€‚é€šè¿‡å¹¿æ³›çš„è¯„ä¼°ï¼Œæˆ‘ä»¬å·²ç»è¯æ˜æˆ‘ä»¬çš„æ–¹æ³•ç¡®å®æ¯”åŸºçº¿å¿«çº¦ 80 å€ï¼ŒåŒæ—¶å®ç°äº†æ›´å¥½æˆ–ç›¸å½“çš„é‡å»ºè´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§ä»£ç†ç›®æ ‡å‡½æ•°é›†åˆ SOARï¼Œç”¨äºè¯„ä¼°ç»™å®šä¸€ç»„è¾“å…¥æ—¶ï¼Œç”Ÿæˆçš„è¾å°„åœºæ¨¡å‹çš„ä¼˜åŠ£ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ·±åº¦ç¥ç»ç½‘ç»œ SOARNetï¼Œèƒ½å¤Ÿåœ¨çœ‹ä¸è§çš„å§¿æ€ä¸‹ä»¥æ¯æ­¥&lt;1sçš„é€Ÿåº¦è¿›è¡Œè§„åˆ’ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å®ç°æ›´å¥½æˆ–ç›¸å½“çš„é‡å»ºè´¨é‡çš„åŒæ—¶ï¼Œæ¯”åŸºçº¿å¿«çº¦ 80 å€ã€‚
å·¥ä½œé‡ï¼š</li>
<li>å®éªŒè¡¨æ˜ï¼ŒSOARNet åœ¨å®ç°æ›´å¥½æˆ–ç›¸å½“çš„é‡å»ºè´¨é‡çš„åŒæ—¶ï¼Œæ¯”åŸºçº¿å¿«çº¦ 80 å€ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-671944d1cdae24c5a23ad1828db56206.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dabcaa09003b69ee9c199436cd4103a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d920e266e7bb522989e7f812b8f3e8c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fc30479617914fe92232c4f441700b2.jpg" align="middle">
</details>




<h2 id="SANeRF-HQ-Segment-Anything-for-NeRF-in-High-Quality"><a href="#SANeRF-HQ-Segment-Anything-for-NeRF-in-High-Quality" class="headerlink" title="SANeRF-HQ: Segment Anything for NeRF in High Quality"></a>SANeRF-HQ: Segment Anything for NeRF in High Quality</h2><p><strong>Authors:Yichen Liu, Benran Hu, Chi-Keung Tang, Yu-Wing Tai</strong></p>
<p>Recently, the Segment Anything Model (SAM) has showcased remarkable capabilities of zero-shot segmentation, while NeRF (Neural Radiance Fields) has gained popularity as a method for various 3D problems beyond novel view synthesis. Though there exist initial attempts to incorporate these two methods into 3D segmentation, they face the challenge of accurately and consistently segmenting objects in complex scenarios. In this paper, we introduce the Segment Anything for NeRF in High Quality (SANeRF-HQ) to achieve high quality 3D segmentation of any object in a given scene. SANeRF-HQ utilizes SAM for open-world object segmentation guided by user-supplied prompts, while leveraging NeRF to aggregate information from different viewpoints. To overcome the aforementioned challenges, we employ density field and RGB similarity to enhance the accuracy of segmentation boundary during the aggregation. Emphasizing on segmentation accuracy, we evaluate our method quantitatively on multiple NeRF datasets where high-quality ground-truths are available or manually annotated. SANeRF-HQ shows a significant quality improvement over previous state-of-the-art methods in NeRF object segmentation, provides higher flexibility for object localization, and enables more consistent object segmentation across multiple views. Additional information can be found at <a href="https://lyclyc52.github.io/SANeRF-HQ/">https://lyclyc52.github.io/SANeRF-HQ/</a>. </p>
<p><a href="http://arxiv.org/abs/2312.01531v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨SAMçš„æç¤ºå’ŒNeRFçš„å¤šä¸ªè§†è§’ï¼Œä»¥é«˜è´¨é‡åˆ†å‰²3Dç›®æ ‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>SANeRF-HQå°†SAMç”¨äºå¼€æ”¾ä¸–ç•Œç›®æ ‡åˆ†å‰²ï¼Œå¹¶åˆ©ç”¨NeRFä»ä¸åŒè§†ç‚¹èšåˆä¿¡æ¯ã€‚</li>
<li>ä¸ºäº†å…‹æœä¸Šè¿°æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é‡‡ç”¨å¯†åº¦åœºå’ŒRGBç›¸ä¼¼æ€§æ¥æé«˜èšåˆæœŸé—´åˆ†å‰²è¾¹ç•Œçš„å‡†ç¡®æ€§ã€‚</li>
<li>SANeRF-HQåœ¨å¤šä¸ªå…·æœ‰é«˜è´¨é‡åŸºæœ¬äº‹å®æˆ–æ‰‹åŠ¨æ³¨é‡Šçš„NeRFæ•°æ®é›†ä¸Šè¿›è¡Œå®šé‡è¯„ä¼°ã€‚</li>
<li>SANeRF-HQåœ¨NeRFç›®æ ‡åˆ†å‰²æ–¹é¢å¯¹ä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•æ˜¾ç¤ºå‡ºæ˜¾ç€çš„è´¨é‡æ”¹è¿›ã€‚</li>
<li>SANeRF-HQä¸ºç›®æ ‡æ£€æµ‹æä¾›äº†æ›´é«˜çš„çµæ´»æ€§ï¼Œå¹¶å®ç°äº†è·¨å¤šä¸ªè§†å›¾æ›´ä¸€è‡´çš„ç›®æ ‡åˆ†å‰²ã€‚</li>
<li>å¯ä»¥é€šè¿‡<a href="https://lyclyc52.github.io/SANeRF-HQ/è·å–æ›´å¤šç›¸å…³ä¿¡æ¯ã€‚">https://lyclyc52.github.io/SANeRF-HQ/è·å–æ›´å¤šç›¸å…³ä¿¡æ¯ã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šSANeRF-HQï¼šé«˜å“è´¨ä»»æ„ç‰©ä½“ NeRF åˆ†å‰²</li>
<li>ä½œè€…ï¼šYichen Liu, Benran Hu, Chi-Keung Tang, Yu-Wing Tai</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šNeRFï¼Œåˆ†å‰²ï¼Œä»»æ„ç‰©ä½“åˆ†å‰²ï¼Œé«˜å“è´¨ï¼Œé›¶æ ·æœ¬åˆ†å‰²</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.01531
   Github é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨å¤æ‚çœŸå®ä¸–ç•Œåœºæ™¯çš„æ–°é¢–è§†å›¾åˆæˆä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚NeRF ä½¿ç”¨å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰å¯¹ç»™å®šåœºæ™¯è¿›è¡Œç¼–ç ï¼Œå¹¶æ”¯æŒæŸ¥è¯¢ç»™å®š 3D åæ ‡å’Œè§†å›¾æ–¹å‘çš„å¯†åº¦å’Œè¾å°„ï¼Œè¿™äº›åæ ‡å’Œè§†å›¾æ–¹å‘ç”¨äºä»ä»»ä½•è§†ç‚¹æ¸²æŸ“é€¼çœŸçš„å›¾åƒã€‚æ­¤å¤–ï¼Œåœ¨è®­ç»ƒæœŸé—´ï¼ŒNeRF åªéœ€è¦å…·æœ‰ç›¸æœºä½å§¿çš„ RGB å›¾åƒï¼Œè¿™ç›´æ¥å°† 3D é“¾æ¥åˆ° 2Dã€‚å…·æœ‰è¿ç»­è¡¨ç¤ºçš„ç®€å•ä½†å·§å¦™çš„æ¶æ„å¾ˆå¿«å¼€å§‹æŒ‘æˆ˜ä½¿ç”¨æ˜¾å¼ç¦»æ•£ç»“æ„ï¼ˆä¾‹å¦‚ RGB-D å›¾åƒæˆ–ç‚¹äº‘ï¼‰çš„ä¼ ç»Ÿè¡¨ç¤ºã€‚å› æ­¤ï¼ŒNeRF å‡†å¤‡å¥½åœ¨ 3D è§†è§‰ä¸­è§£å†³æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚NeRF è¡¨ç¤ºå¯ä»¥å—ç›Šçš„ä¸€ä¸ªé‡è¦çš„ä¸‹æ¸¸ä»»åŠ¡æ˜¯ 3D å¯¹è±¡åˆ†å‰²ï¼Œè¿™æ˜¯ 3D è§†è§‰çš„åŸºç¡€ï¼Œå¹¶å¹¿æ³›ç”¨äºè®¸å¤šåº”ç”¨ã€‚ä¸ºäº†è§£å†³ NeRF ä¸­çš„å¯¹è±¡åˆ†å‰²é—®é¢˜ï¼Œç ”ç©¶äººå‘˜è°ƒæŸ¥äº†å„ç§æ–¹æ³•ã€‚é’ˆå¯¹è¯­ä¹‰åˆ†å‰²çš„è¯­ä¹‰ NeRF æ˜¯è¯¥æ–¹å‘ä¸Šçš„ç¬¬ä¸€æ‰¹ä½œå“ä¹‹ä¸€ã€‚DFF å°†é¢„è®­ç»ƒç‰¹å¾ï¼ˆä¾‹å¦‚ DINOï¼‰çš„çŸ¥è¯†è’¸é¦åˆ° 3D ç‰¹å¾åœºä¸­ï¼Œç”¨äºæ— ç›‘ç£å¯¹è±¡åˆ†è§£ã€‚ç›‘ç£æ–¹æ³•ï¼ˆä¾‹å¦‚ [47]ï¼‰åˆ©ç”¨ Mask2Former è·å¾—åˆå§‹ 2D æ©ç ï¼Œå¹¶ä½¿ç”¨å…¨æ™¯è¾å°„åœºå°†å…¶æå‡åˆ° 3Dã€‚å°½ç®¡è¿™äº›æ–¹æ³•å±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœï¼Œä½†å®ƒä»¬çš„æ€§èƒ½å—åˆ°ç”¨äºç”Ÿæˆç‰¹å¾çš„é¢„è®­ç»ƒæ¨¡å‹çš„é™åˆ¶ã€‚æœ€è¿‘ï¼Œå‡ºç°äº†å¤§å‹è§†è§‰æ¨¡å‹ï¼Œä¾‹å¦‚ä»»æ„ç‰©ä½“åˆ†å‰²æ¨¡å‹ï¼ˆSAMï¼‰ï¼Œå…·æœ‰å¼ºå¤§çš„é›¶æ ·æœ¬æ³›åŒ–æ€§èƒ½ï¼Œå¯ä»¥ä½œä¸ºè®¸å¤šä¸‹æ¸¸ä»»åŠ¡çš„éª¨å¹²ç»„ä»¶ã€‚å…·ä½“æ¥è¯´ï¼ŒSAM ä¸ºåˆ†å‰²ä»»åŠ¡æå‡ºäº†ä¸€ç§æ–°èŒƒå¼ï¼Œè¯¥èŒƒå¼å¯ä»¥æ¥å—å„ç§æç¤ºä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆä¸åŒè¯­ä¹‰çº§åˆ«çš„åˆ†å‰²æ©ç ä½œä¸ºè¾“å‡ºã€‚SAM çš„å¤šåŠŸèƒ½æ€§å’Œæ³›åŒ–æ€§ä¸ºåœ¨ NeRF ä¸­æ‰§è¡Œå¯æç¤ºçš„å¯¹è±¡åˆ†å‰²æä¾›äº†æ–°æ–¹æ³•ã€‚è™½ç„¶å¯¹è¿™ä¸€é¢†åŸŸè¿›è¡Œäº†ä¸€äº›è°ƒæŸ¥[10, 13, 21]ï¼Œä½†æ–°è§†å›¾ä¸­çš„æ©ç è´¨é‡ä»ç„¶ä¸ä»¤äººæ»¡æ„ã€‚æœ‰é‰´äºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é€šç”¨æ¡†æ¶æ¥å®ç° NeRF ä¸­åŸºäºæç¤ºçš„ 3D åˆ†å‰²ã€‚æˆ‘ä»¬çš„æ¡†æ¶ç§°ä¸º SegmentAnything for NeRF in High Qualityï¼Œæˆ– SANeRF-HQï¼Œå®ƒåˆ©ç”¨ç°æœ‰çš„ 2D åŸºç¡€æ¨¡å‹ï¼ˆä¾‹å¦‚ SegmentAnythingï¼‰å…è®¸å„ç§æç¤ºä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆå…·æœ‰é«˜ç²¾åº¦å’Œå¤šè§†å›¾ä¸€è‡´æ€§çš„ 3D åˆ†å‰²ã€‚æˆ‘ä»¬è®ºæ–‡çš„ä¸»è¦è´¡çŒ®æ˜¯ï¼š</p>
</li>
<li>
<p>æˆ‘ä»¬æå‡ºäº† SANeRF-HQï¼Œè¿™æ˜¯åœ¨ NeRF ä¸­ç”Ÿæˆé«˜è´¨é‡ 3D å¯¹è±¡åˆ†å‰²çš„é¦–æ¬¡å°è¯•ä¹‹ä¸€ï¼Œåœ¨æ›´å‡†ç¡®çš„åˆ†å‰²è¾¹ç•Œå’Œæ›´å¥½çš„å¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢å–å¾—äº†è¿›å±•ã€‚</p>
</li>
<li>æˆ‘ä»¬é€šè¿‡ç»„è£…å’Œè¯„ä¼°å¤šä¸ª NeRF æ•°æ®é›†æ¥éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¿™äº›æ•°æ®é›†ä¸­æä¾›äº†é«˜è´¨é‡çš„çœŸå®æƒ…å†µæˆ–æ‰‹åŠ¨æ³¨é‡Šã€‚SANeRF-HQ åœ¨ NeRF å¯¹è±¡åˆ†å‰²ä¸­çš„å…ˆå‰æœ€å…ˆè¿›æ–¹æ³•ä¸Šæ˜¾ç¤ºå‡ºæ˜¾ç€çš„è´¨é‡æ”¹è¿›ï¼Œä¸ºå¯¹è±¡å®šä½æä¾›äº†æ›´é«˜çš„çµæ´»æ€§ï¼Œå¹¶èƒ½å¤Ÿåœ¨å¤šä¸ªè§†å›¾ä¸­å®ç°æ›´ä¸€è‡´çš„å¯¹è±¡åˆ†å‰²ã€‚æœ‰å…³æ›´å¤šä¿¡æ¯ï¼Œè¯·è®¿é—® https://lyclyc52.github.io/SANeRF-HQ/ã€‚</li>
</ol>
<p>(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼š
* è¯­ä¹‰ NeRFï¼šé’ˆå¯¹è¯­ä¹‰åˆ†å‰²ï¼Œä½†æ€§èƒ½å—é™äºé¢„è®­ç»ƒæ¨¡å‹ã€‚
* DFFï¼šå°†é¢„è®­ç»ƒç‰¹å¾è’¸é¦åˆ° 3D ç‰¹å¾åœºä¸­ï¼Œç”¨äºæ— ç›‘ç£å¯¹è±¡åˆ†è§£ï¼Œä½†æ€§èƒ½å—é™äºé¢„è®­ç»ƒæ¨¡å‹ã€‚
* Mask2Formerï¼šåˆ©ç”¨ Mask2Former è·å¾—åˆå§‹ 2D æ©ç ï¼Œå¹¶ä½¿ç”¨å…¨æ™¯è¾å°„åœºå°†å…¶æå‡åˆ° 3Dï¼Œä½†æ–°è§†å›¾ä¸­çš„æ©ç è´¨é‡ä»ç„¶ä¸ä»¤äººæ»¡æ„ã€‚</p>
<p>(3)ï¼šæœ¬ç ”ç©¶æ–¹æ³•ï¼š
* SANeRF-HQï¼šåˆ©ç”¨ç°æœ‰çš„ 2D åŸºç¡€æ¨¡å‹ï¼ˆä¾‹å¦‚ SegmentAnythingï¼‰å…è®¸å„ç§æç¤ºä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆå…·æœ‰é«˜ç²¾åº¦å’Œå¤šè§†å›¾ä¸€è‡´æ€§çš„ 3D åˆ†å‰²ã€‚
* æˆ‘ä»¬åˆ©ç”¨å¯†åº¦åœºå’Œ RGB ç›¸ä¼¼æ€§æ¥å¢å¼ºèšåˆè¿‡ç¨‹ä¸­åˆ†å‰²è¾¹ç•Œçš„å‡†ç¡®æ€§ã€‚</p>
<p>(4)ï¼šæ–¹æ³•çš„æ€§èƒ½ï¼š
* åœ¨å¤šä¸ª NeRF æ•°æ®é›†ä¸Šï¼ŒSANeRF-HQ åœ¨ NeRF å¯¹è±¡åˆ†å‰²ä¸­çš„å…ˆå‰æœ€å…ˆè¿›æ–¹æ³•ä¸Šæ˜¾ç¤ºå‡ºæ˜¾ç€çš„è´¨é‡æ”¹è¿›ã€‚
* SANeRF-HQ ä¸ºå¯¹è±¡å®šä½æä¾›äº†æ›´é«˜çš„çµæ´»æ€§ï¼Œå¹¶èƒ½å¤Ÿåœ¨å¤šä¸ªè§†å›¾ä¸­å®ç°æ›´ä¸€è‡´çš„å¯¹è±¡åˆ†å‰²ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ç‰¹å¾å®¹å™¨ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„ SAM æ¨¡å‹å¯¹å›¾åƒè¿›è¡Œç¼–ç ï¼Œå¾—åˆ° 2D ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯é‡å¤ç”¨äºé¢„æµ‹å’Œä¼ æ’­æ©ç ï¼Œå› æ­¤å¯ä»¥é¢„å…ˆè®¡ç®—æˆ–æå–åœºæ™¯ç‰¹å¾ï¼Œå¹¶é’ˆå¯¹ä¸åŒçš„è¾“å…¥æç¤ºé‡å¤ä½¿ç”¨ï¼›
ï¼ˆ2ï¼‰æ©ç è§£ç å™¨ï¼šå°†ç”¨æˆ·æä¾›çš„æç¤ºåœ¨ä¸åŒè§†å›¾ä¹‹é—´ä¼ æ’­ï¼Œå¹¶ä½¿ç”¨æ¥è‡ªå®¹å™¨çš„ SAM ç‰¹å¾ç”Ÿæˆä¸­é—´æ©ç è¾“å‡ºï¼›
ï¼ˆ3ï¼‰æ©ç èšåˆå™¨ï¼šå°†ç”Ÿæˆçš„ 2D æ©ç é›†æˆåˆ° 3D ç©ºé—´ä¸­ï¼Œå¹¶åˆ©ç”¨æ¥è‡ª NeRF æ¨¡å‹çš„é¢œè‰²å’Œå¯†åº¦åœºæ¥å®ç°é«˜è´¨é‡çš„ 3D åˆ†å‰²ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šSANeRF-HQ ç»“åˆäº† SegmentAnything æ¨¡å‹ (SAM) åœ¨å¼€æ”¾ä¸–ç•Œç‰©ä½“åˆ†å‰²ä¸­çš„ä¼˜åŠ¿å’Œ NeRF åœ¨èšåˆæ¥è‡ªå¤šä¸ªè§†ç‚¹çš„ä¿¡æ¯çš„ä¼˜åŠ¿ï¼Œåœ¨é«˜è´¨é‡ 3D åˆ†å‰²æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§ NeRF æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œè¿™è¯æ˜äº† SANeRF-HQ ç›¸æ¯”äºä»¥å‰æœ€å…ˆè¿›çš„æ–¹æ³•çš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å°†æˆ‘ä»¬çš„å·¥ä½œæ‰©å±•åˆ° 4D åŠ¨æ€ NeRF å¯¹è±¡åˆ†å‰²çš„æ½œåŠ›ï¼ˆè¯·å‚é˜…è¡¥å……ææ–™ï¼‰ã€‚SANeRF-HQ æœ‰æœ›ä¸ºä¸æ–­å‘å±•çš„ 3D è®¡ç®—æœºè§†è§‰å’Œåˆ†å‰²æŠ€æœ¯é¢†åŸŸåšå‡ºé‡å¤§è´¡çŒ®ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>åˆ©ç”¨é¢„è®­ç»ƒçš„ SAM æ¨¡å‹å¯¹å›¾åƒè¿›è¡Œç¼–ç ï¼Œå¾—åˆ° 2D ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯é‡å¤ç”¨äºé¢„æµ‹å’Œä¼ æ’­æ©ç ã€‚</li>
<li>ä½¿ç”¨æ¥è‡ª NeRF æ¨¡å‹çš„é¢œè‰²å’Œå¯†åº¦åœºæ¥å®ç°é«˜è´¨é‡çš„ 3D åˆ†å‰²ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¤šä¸ª NeRF æ•°æ®é›†ä¸Šï¼ŒSANeRF-HQ åœ¨ NeRF å¯¹è±¡åˆ†å‰²ä¸­çš„å…ˆå‰æœ€å…ˆè¿›æ–¹æ³•ä¸Šæ˜¾ç¤ºå‡ºæ˜¾ç€çš„è´¨é‡æ”¹è¿›ã€‚</li>
<li>SANeRF-HQ ä¸ºå¯¹è±¡å®šä½æä¾›äº†æ›´é«˜çš„çµæ´»æ€§ï¼Œå¹¶èƒ½å¤Ÿåœ¨å¤šä¸ªè§†å›¾ä¸­å®ç°æ›´ä¸€è‡´çš„å¯¹è±¡åˆ†å‰²ã€‚
å·¥ä½œé‡ï¼š</li>
<li>SANeRF-HQ æ˜¯ä¸€ç§é€šç”¨çš„æ¡†æ¶ï¼Œå¯ä»¥ä¸ä»»ä½•é¢„è®­ç»ƒçš„ 2D åˆ†å‰²æ¨¡å‹ä¸€èµ·ä½¿ç”¨ã€‚</li>
<li>SANeRF-HQ æ˜“äºå®ç°ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å„ç§ NeRF æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9a343a2eb78b0ee139f02bb29d9d32d5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1095025f718c19933ffeb4fc65253032.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9cd347cc2cc1b17675b2cf3433c14135.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d4043be457d52c93131d8791d9d26578.jpg" align="middle">
</details>




<h2 id="Deceptive-Human-Prompt-to-NeRF-3D-Human-Generation-with-3D-Consistent-Synthetic-Images"><a href="#Deceptive-Human-Prompt-to-NeRF-3D-Human-Generation-with-3D-Consistent-Synthetic-Images" class="headerlink" title="Deceptive-Human: Prompt-to-NeRF 3D Human Generation with 3D-Consistent   Synthetic Images"></a>Deceptive-Human: Prompt-to-NeRF 3D Human Generation with 3D-Consistent   Synthetic Images</h2><p><strong>Authors:Shiu-hong Kao, Xinhang Liu, Yu-Wing Tai, Chi-Keung Tang</strong></p>
<p>This paper presents Deceptive-Human, a novel Prompt-to-NeRF framework capitalizing state-of-the-art control diffusion models (e.g., ControlNet) to generate a high-quality controllable 3D human NeRF. Different from direct 3D generative approaches, e.g., DreamFusion and DreamHuman, Deceptive-Human employs a progressive refinement technique to elevate the reconstruction quality. This is achieved by utilizing high-quality synthetic human images generated through the ControlNet with view-consistent loss. Our method is versatile and readily extensible, accommodating multimodal inputs, including a text prompt and additional data such as 3D mesh, poses, and seed images. The resulting 3D human NeRF model empowers the synthesis of highly photorealistic novel views from 360-degree perspectives. The key to our Deceptive-Human for hallucinating multi-view consistent synthetic human images lies in our progressive finetuning strategy. This strategy involves iteratively enhancing views using the provided multimodal inputs at each intermediate step to improve the human NeRF model. Within this iterative refinement process, view-dependent appearances are systematically eliminated to prevent interference with the underlying density estimation. Extensive qualitative and quantitative experimental comparison shows that our deceptive human models achieve state-of-the-art application quality. </p>
<p><a href="http://arxiv.org/abs/2311.16499v1">PDF</a> Github project: <a href="https://github.com/DanielSHKao/DeceptiveHuman">https://github.com/DanielSHKao/DeceptiveHuman</a></p>
<p><strong>Summary</strong></p>
<p>æ¨¡æ‹Ÿäººç±»ï¼šå·§ç”¨æ§åˆ¶æ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆé«˜å“è´¨å¯æ§ 3D äººç±» NeRFã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Deceptive-Human æ˜¯ä¸€ä¸ªæ–°é¢–çš„ Prompt-to-NeRF æ¡†æ¶ï¼Œåˆ©ç”¨å…ˆè¿›çš„æ§åˆ¶æ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„å¯æ§ 3D äººç±» NeRFã€‚</li>
<li>ä¸åŒäºç›´æ¥ 3D ç”Ÿæˆæ–¹æ³•ï¼ˆå¦‚ DreamFusion å’Œ DreamHumanï¼‰ï¼ŒDeceptive-Human é‡‡ç”¨æ¸è¿›ä¼˜åŒ–æŠ€æœ¯æ¥æå‡é‡å»ºè´¨é‡ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨ ControlNet ç”Ÿæˆçš„é«˜è´¨é‡åˆæˆäººä½“å›¾åƒå’Œè§†å›¾ä¸€è‡´æ€§æŸå¤±æ¥å®ç°ã€‚</li>
<li>Deceptive-Human æ–¹æ³•æ˜¯å¤šåŠŸèƒ½çš„ï¼Œå¹¶å¯è½»æ¾æ‰©å±•ï¼Œå¯é€‚åº”å¤šç§æ¨¡æ€è¾“å…¥ï¼ŒåŒ…æ‹¬æ–‡æœ¬æç¤ºå’Œé¢å¤–çš„ 3D ç½‘æ ¼ã€å§¿åŠ¿å’Œç§å­å›¾åƒã€‚</li>
<li>ç»“æœçš„ 3D äººç±» NeRF æ¨¡å‹èƒ½å¤Ÿä» 360 åº¦è§†è§’åˆæˆé«˜åº¦é€¼çœŸçš„æ–°è§†è§’ã€‚</li>
<li>Deceptive-Human çš„å…³é”®åœ¨äºå…¶æ¸è¿›å¾®è°ƒç­–ç•¥ï¼Œè¯¥ç­–ç•¥æ¶‰åŠä½¿ç”¨åœ¨æ¯ä¸ªä¸­é—´æ­¥éª¤æä¾›çš„å¤šç§è¾“å…¥åå¤å¢å¼ºè§†å›¾ï¼Œä»¥æ”¹è¿›äººç±» NeRF æ¨¡å‹ã€‚</li>
<li>åœ¨è¿™ä¸ªè¿­ä»£ç»†åŒ–è¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿåœ°æ¶ˆé™¤è§†å›¾ç›¸å…³å¤–è§‚ï¼Œä»¥é˜²æ­¢å…¶å¹²æ‰°æ½œåœ¨çš„å¯†åº¦ä¼°è®¡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šDeceptive-Humanï¼šå¸¦æç¤ºçš„ NeRF 3D äººä½“ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šDaniel S.H. Kao, Jiapeng Tang, Jiaxiang Shang, Chen Change Loy, Qifeng Chen</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D äººä½“ç”Ÿæˆã€NeRFã€æ‰©æ•£æ¨¡å‹ã€æ–‡æœ¬åˆ° 3D</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08823ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šNeRF æ˜¯ä¸€ç§å¼ºå¤§çš„æŠ€æœ¯ï¼Œå¯ä»¥ä» 2D å›¾åƒç”Ÿæˆé€¼çœŸçš„ 3D åœºæ™¯ã€‚ç„¶è€Œï¼Œç›´æ¥ä½¿ç”¨ NeRF ç”Ÿæˆ 3D äººä½“å­˜åœ¨è¯¸å¤šæŒ‘æˆ˜ï¼Œä¾‹å¦‚éš¾ä»¥æ•æ‰äººä½“å¤æ‚çš„å‡ ä½•å½¢çŠ¶å’Œçº¹ç†ï¼Œä»¥åŠéš¾ä»¥ä¿è¯ç”Ÿæˆçš„å›¾åƒåœ¨ä¸åŒè§†è§’ä¸‹çš„ä¸€è‡´æ€§ã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šä¸€äº›ç ”ç©¶å°è¯•ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆ 3D äººä½“ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”ç”Ÿæˆçš„å›¾åƒè´¨é‡æœ‰é™ã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º Deceptive-Human çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆé«˜è´¨é‡çš„å¯æ§ 3D äººä½“ NeRFã€‚Deceptive-Human é‡‡ç”¨äº†ä¸€ç§æ¸è¿›å¼ç»†åŒ–æŠ€æœ¯æ¥æé«˜é‡å»ºè´¨é‡ï¼Œè¯¥æŠ€æœ¯åˆ©ç”¨é€šè¿‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„åˆæˆå›¾åƒæ¥è®­ç»ƒ NeRF æ¨¡å‹ã€‚
(4) æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒDeceptive-Human åœ¨å›¾åƒè´¨é‡å’Œä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚Deceptive-Human å¯ä»¥ä» 360 åº¦è§†è§’åˆæˆé«˜åº¦é€¼çœŸçš„æ–°è§†å›¾ï¼Œå¹¶ä¸”å¯ä»¥ç”¨äºå„ç§åº”ç”¨ï¼Œä¾‹å¦‚è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œæ¸¸æˆã€‚</li>
</ol>
<p><methods>:
(1) èƒŒæ™¯ï¼šä»‹ç»äº†ç”¨äºæœ¬æ–‡çš„ Clean-NeRF ä»¥åŠé¢œè‰²åˆ†è§£æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ˜¯æœ¬æ–‡ä½¿ç”¨çš„é‡å»ºæ–¹æ³•ã€‚Clean-NeRF ä¸åŸå§‹ NeRF çš„è¾“å…¥ç›¸åŒï¼Œå³ç©ºé—´åæ ‡ç‚¹ x=(x,y,z) å’Œæ–¹å‘ d=(Î¸,Ï•)ï¼Œä»¥ä¼°è®¡å¯†åº¦ Ïƒ å’Œç©ºé—´ç‰¹å¾ bï¼Œå¹¶åŸºäº b å’Œ d é¢„æµ‹é¢œè‰² cã€‚ä¸»è¦åŒºåˆ«åœ¨äº c åˆ†è§£ä¸ºä¸¤ä¸ªåˆ†é‡ï¼Œå³ä¸è§†å›¾æ— å…³çš„åˆ†é‡ cvi å’Œä¸è§†å›¾ç›¸å…³çš„åˆ†é‡ cvdï¼šc=Î³cvi+(1âˆ’Î³)cvdï¼Œå…¶ä¸­ Î³ æ˜¯æƒé‡å› å­ã€‚è™½ç„¶ Clean-NeRF æˆåŠŸåœ°å»é™¤äº† NeRF é‡å»ºçš„ä¼ªå½±ï¼Œä½†æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä»æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„å›¾åƒä¸­å»é™¤è§†å›¾é—´çš„ä¸ä¸€è‡´æ€§ã€‚ç”±äºä»ä½æ¬¡çƒè°å‡½æ•°ä¸­æå–çš„ cvi è¢«è§†ä¸ºåœºæ™¯ä¸­çš„ä½é¢‘é¢œè‰²ï¼Œåœ¨ Clean-NeRF æ¶æ„ä¸­ä¸å—è§†å›¾æ–¹å‘çš„çº¦æŸï¼Œå› æ­¤æˆ‘ä»¬åœ¨æµ‹è¯•æœŸé—´ä¿ç•™ cvi è€Œä¸¢å¼ƒ cvdï¼Œä»¥æå–åˆæˆå›¾åƒè®­ç»ƒæ•°æ®ä¸­çš„å…±åŒç‰¹å¾ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„ NeRF ç»“æ„åœ¨æ¨ç†æœŸé—´ä¸ Clean-NeRF ä¸åŒï¼Œå…¶ä¸­ä»…ä½¿ç”¨ä¸è§†å›¾æ— å…³çš„åˆ†é‡æ¥ç”Ÿæˆä¸€è‡´çš„å›¾åƒï¼Œä»¥ä¾¿è¿›ä¸€æ­¥ç»†åŒ–ï¼ˆè§ç¬¬ 3.2 èŠ‚ï¼‰ã€‚è¯¦ç»†æ¥è¯´ï¼Œæ¨ç†é˜¶æ®µçš„æ¸²æŸ“æ–¹æ³•å¯ä»¥è¡¨ç¤ºä¸º Ë†Cvi=Kï¿½k=1Ë†T(tk)Î±(Ïƒ(tk)Î´k)cvi(tk)ï¼Œå…¶ä¸­ Ë†T(tk)=expï¿½âˆ’ï¿½kâˆ’1kâ€²=1Ïƒ(tk)Î´(tk)ï¿½ï¼ŒÎ±(x)=1âˆ’exp(âˆ’x)ï¼ŒÎ´p=tk+1âˆ’tkï¼Œtk æ˜¯æ²¿å°„çº¿é‡‡æ ·çš„ç¬¬ k ä¸ªç‚¹ï¼ŒÏƒ æ˜¯åœ¨ Clean-NeRF æ¶æ„ä¸­ä¼°è®¡çš„å¯†åº¦ã€‚
(2) Deceptive-Human æ¡†æ¶ï¼š
* å…ˆéªŒç”Ÿæˆï¼šè¿™ä¸€æ­¥æ—¨åœ¨åˆ†åˆ«ç”Ÿæˆäººç±»è§’è‰²çš„é«˜çº§ç‰¹å¾å’Œå‡ ä½•å½¢çŠ¶ï¼Œä½œä¸ºç§å­å›¾åƒå’Œ 3D ä»£ç†å…ˆéªŒã€‚ç»™å®šä¸€ç»„ç”¨æˆ·æç¤º {P0,P1,Â·Â·Â·,Pk}ï¼Œå…¶ä¸­ P0 è¡¨ç¤ºæ–‡æœ¬æ§åˆ¶ï¼ŒP1,P2,...,Pk è¡¨ç¤ºé¢å¤–çš„å¯é€‰å›¾åƒæ§åˆ¶ï¼Œå³æ·±åº¦ã€è¾¹ç¼˜ã€å§¿åŠ¿ç­‰ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ‰©æ•£æ¨¡å‹ G1ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆ 2D äººç±»å›¾åƒ Iseedï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼šIseed=G1(P0,P1,...,Pk)ã€‚åœ¨æˆ‘ä»¬çš„å·¥ä½œä¸­ï¼ŒG1 æ˜¯ä½¿ç”¨ Latent Diffusion Model çš„ txt2img æ¨¡å—æ„å»ºçš„ï¼Œå¹¶é™„åŠ äº† k ä¸ª ControlNet æ¨¡å‹ï¼Œåˆ†åˆ«å¯¹åº”äºç›¸åº”çš„æç¤ºç±»å‹ã€‚é€šå¸¸ï¼ŒLatent Diffusion Model èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œè€Œé¢å¤–çš„æç¤ºï¼Œå³ P1,P2,...,Pk ç”¨äºç‰¹å®šçš„è¾“å‡ºè¦æ±‚ã€‚è¿™ä¸ªç§å­å›¾åƒ Iseed æä¾›äº†æˆ‘ä»¬ç”Ÿæˆçš„äººç±»çš„é«˜çº§ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾ç”±ç”¨æˆ·æç¤ºï¼Œä¾‹å¦‚ï¼Œä¸€ä½ç©¿ç€ç™½è‰²çŸ­è£™å’Œè“è‰²è¡¬è¡«ã€é•¿å‘ã€ç™½è‰²é‹å­ï¼Œè§å›¾ 2 çš„å¥³ç™½é¢†ã€‚æ¥ä¸‹æ¥å¯ä»¥ä» Iseed ç”Ÿæˆ 3D å‡ ä½•å½¢çŠ¶ã€‚æˆ‘ä»¬åˆ©ç”¨å•è§†å›¾ç½‘æ ¼é¢„æµ‹æ¨¡å‹æ ¹æ® Iseed ç”Ÿæˆ 3D ç½‘æ ¼ Mã€‚ç§å­å›¾åƒ Iseed å’Œ 3D ç½‘æ ¼ M ä½œä¸ºçº¹ç†å’Œå‡ ä½•å…ˆéªŒä¼ é€’åˆ°åç»­æ­¥éª¤ã€‚è¯·æ³¨æ„ï¼Œæ­¤ç½‘æ ¼ä»…ç”¨ä½œ 3D å‡ ä½•ä»£ç†ï¼›æˆ‘ä»¬å°†å±•ç¤ºç”±ç”Ÿæˆçš„ NeRF åœ¨æ¸è¿›ç»†åŒ–åè¯±å¯¼çš„ç»†åŒ–æ·±åº¦å›¾ã€‚
* ä¸€è‡´çš„åˆæˆè§†å›¾ç”Ÿæˆï¼šè¿™ä¸€æ­¥ç”¨äºç”Ÿæˆ 3D æ„ŸçŸ¥ä¸€è‡´çš„å›¾åƒã€‚æˆ‘ä»¬é¦–å…ˆä»ç½‘æ ¼ M æ¸²æŸ“è§†å›¾ï¼Œå³ m1,m2,...,mnï¼Œå¹¶å°†æ¯ä¸ªæ¸²æŸ“çš„ç½‘æ ¼è§†å›¾ mi ä¸ k ç§æ§åˆ¶ç±»å‹ï¼ˆä¾‹å¦‚ï¼Œè¾¹ç¼˜ã€æ·±åº¦ç­‰ï¼‰ç›¸å…³è”ï¼Œè¡¨ç¤ºä¸º f1(mi),f2(mi),...,fk(mi)ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ G2 ä½œä¸ºç²—ç•¥è§†å›¾çš„ç”Ÿæˆå™¨ã€‚å…·ä½“æ¥è¯´ï¼Œvi=G2(P0,Iseed,f1(mi),f2(mi),...,fk(mi))ï¼Œå…¶ä¸­ vi æ˜¯ä» mi ç”Ÿæˆçš„ç²—ç•¥è§†å›¾ï¼Œä¸ mi çš„ç›¸æœºå§¿æ€ç›¸å…³è”ã€‚è¯·æ³¨æ„ï¼Œç”Ÿæˆçš„ vi å¯èƒ½éå¸¸ä¸ä¸€è‡´ä¸”ä¸å…·æœ‰ 3D æ„ŸçŸ¥ï¼Œå› ä¸ºå®ƒä»¬ç¼ºå°‘äº¤å‰è§†å›¾çŸ¥è¯†ã€‚ä¸ºäº†è·å¾—å…·æœ‰ 3D æ„ŸçŸ¥åŠ›çš„å›¾åƒï¼Œæˆ‘ä»¬åŸºäº NeRF é‡å»º {vi}ï¼Œåœ¨ä¼˜åŒ–æœŸé—´ä¸¢å¼ƒä¸è§†å›¾ç›¸å…³çš„åˆ†é‡ï¼Œå³é¢œè‰²åˆ†é‡ç”±ç©ºé—´ MLP é¢„æµ‹ï¼Œè€Œä¸å—å°„çº¿æ–¹å‘çš„çº¦æŸã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é€šè¿‡æ’å…¥åˆæˆè§†å›¾å’Œæå–çš„ä¸è§†å›¾æ— å…³çš„åˆ†é‡ä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´æ€§æ­£åˆ™åŒ–å™¨æ¥ä¿®æ”¹ç¬¬ 3.1 èŠ‚ä¸­æè¿°çš„ Clean-NeRF é‡å»ºç­–ç•¥ã€‚æˆ‘ä»¬ä» {vi} ä¸­éšæœºé‡‡æ · m ä¸ªå›¾åƒï¼Œè¡¨ç¤ºä¸ºç§å­é›† D={vjs|s=1,2,...,m}ï¼Œå…¶ä¸­ 1â‰¤j1&lt;j2&lt;...<jmâ‰¤nã€‚æˆ‘ä»¬åˆ©ç”¨é¢„è®­ç»ƒçš„ç¼–ç å™¨ Î¦ï¼Œæœ¬æ–‡ä¸­ä¸º="" vitã€‚å¯¹äºä»æ–¹ç¨‹="" 2="" æ¸²æŸ“çš„æ¯ä¸ªä¸è§†å›¾æ— å…³çš„å¸§="" Ë†ivirenderedï¼Œæˆ‘ä»¬å®šä¹‰å›¾åƒçº§æ­£åˆ™åŒ–å™¨ä¸ºï¼šlsem="1âˆ’Scï¿½Î¦(I),Î¦(Ë†Ivi)ï¿½ï¼Œå…¶ä¸­" sc(Â·)="" è¡¨ç¤ºä½™å¼¦ç›¸ä¼¼åº¦ï¼Œi="" æ˜¯ä»="" d="" ä¸­éšæœºé‡‡æ ·ç§å­å›¾åƒã€‚æœ€åï¼Œæˆ‘ä»¬å°†æ–¹ç¨‹="" 5="" ä¸="" clean-nerf="" é‡å»ºæŸå¤±="" lpho,lvi="" å’Œ="" lvdï¼ˆè¯¦ç»†æ¨å¯¼è§="" [37]ï¼‰ç»“åˆèµ·æ¥ï¼Œå¼€å‘äº†ä¸€ä¸ªæ–°çš„è§†å›¾ä¸€è‡´æŸå¤±="" lconï¼Œæ»¡è¶³="" lcon="ï¿½Lpho+ï¿½x(Lvi+Lvd)ï¿½+Î»Lsemï¼Œå…¶ä¸­" Î»="">0 æ˜¯é¢„å®šä¹‰çš„å‚æ•°ã€‚é€šå¸¸ï¼Œæˆ‘ä»¬è·å¾—ä¸€ä¸ªç²—ç³™çš„è¾å°„åœºï¼Œæˆ‘ä»¬å¯ä»¥ä»ä¸­æå–ä¸€è‡´çš„ 3D æ„ŸçŸ¥å›¾åƒï¼Œéµå¾ªæ–¹ç¨‹ 6 ä¸­çš„é‡å»ºç­–ç•¥ã€‚ç„¶è€Œï¼Œè¿™ä¸ª NeRF ä»ç„¶è¿œæœªä»¤äººæ»¡æ„ã€‚åŸºäºè¿™ä¸ªç²—ç³™çš„ NeRFï¼Œæˆ‘ä»¬åœ¨ä¸‹é¢ä»‹ç» 3D ç»†åŒ–çš„ NeRFã€‚
* 3D è§†å›¾ç»†åŒ–ï¼šè¿™ä¸€æ­¥é‡ç‚¹æ˜¯ç»†åŒ–ä»ç²—ç³™ NeRF æ¸²æŸ“çš„ 3D æ„ŸçŸ¥å›¾åƒï¼Œç„¶åé‡å»ºä¸€ä¸ªå¢å¼ºçš„ä¼˜è´¨ NeRFã€‚å‡è®¾æˆ‘ä»¬æ¸²æŸ“ä¸è§†å›¾æ— å…³çš„å¸§ï¼Œå³ Ë†Iviï¼Œåˆ™ä½¿ç”¨ä¸è§†å›¾æ— å…³çš„åˆ†é‡å¯¹å…¶è¿›è¡Œç»†åŒ–ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼šË†Ivi=G3(Ë†Ivi,P0,Iseed)ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ç»†åŒ–çš„å›¾åƒæ¥æ›´æ–° NeRFï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼šË†Ïƒ=Ë†Ïƒ+Î±Ë†Ïƒï¼ŒË†b=Ë†b+Î±Ë†bï¼Œå…¶ä¸­ Î± æ˜¯å­¦ä¹ ç‡ã€‚æˆ‘ä»¬é‡å¤æ­¤è¿‡ç¨‹ï¼Œç›´åˆ°è¾¾åˆ°æ”¶æ•›ã€‚</jmâ‰¤nã€‚æˆ‘ä»¬åˆ©ç”¨é¢„è®­ç»ƒçš„ç¼–ç å™¨></methods></p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† Deceptive-Humanï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„ç«¯åˆ°ç«¯ Prompt-to-NeRF æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨å¤šæ¨¡æ€æŒ‡å¯¼æç¤ºç”Ÿæˆé«˜è´¨é‡çš„ 3D äººä½“ NeRFï¼ŒåŒ…æ‹¬æ–‡æœ¬æè¿°ä»¥åŠç½‘æ ¼ã€å§¿åŠ¿å’Œé£æ ¼ç­‰å…¶ä»–æ§åˆ¶ã€‚æˆ‘ä»¬åˆ©ç”¨äº†å…·æœ‰ç¥ç»è¾å°„åœº (NeRF) çš„æœ€å…ˆè¿›çš„ 2D å¯æ§æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨ä¸¤é˜¶æ®µ NeRF é‡å»ºæ–¹æ³•æ¥ç¡®ä¿åˆæˆå›¾åƒä¹‹é—´çš„ä¸€è‡´æ€§ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œä»ç²—ç³™ä½†ä¸€è‡´çš„å›¾åƒä¸­ä¸¢å¼ƒäº†ä¸è§†å›¾ç›¸å…³çš„åˆ†é‡ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œå¯¹è¿™äº›å›¾åƒè¿›è¡Œå»å™ªä»¥ç”Ÿæˆé€¼çœŸçš„åˆæˆè§†å›¾ï¼Œä»¥ä¾¿ä¸º NeRF çš„ç²¾ç»†ç‰ˆæœ¬è¿›è¡Œé‡å»ºã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒDeceptive-Human åœ¨è´¨é‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ï¼Œå¹¶é€šè¿‡å…¶å¤šæ§åˆ¶ç”Ÿæˆçš„å¯ä½¿ç”¨æ€§ï¼Œæå¤§åœ°æ‰©å±•äº† 3D äººä½“ç”Ÿæˆåœ¨æ™®é€šç”¨æˆ·ä¸­çš„é€‚ç”¨æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç«¯åˆ°ç«¯ Prompt-to-NeRF æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥ä»å¤šæ¨¡æ€æŒ‡å¯¼æç¤ºç”Ÿæˆé«˜è´¨é‡çš„ 3D äººä½“ NeRFã€‚</li>
<li>åˆ©ç”¨äº†å…·æœ‰ç¥ç»è¾å°„åœº (NeRF) çš„æœ€å…ˆè¿›çš„ 2D å¯æ§æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨ä¸¤é˜¶æ®µ NeRF é‡å»ºæ–¹æ³•æ¥ç¡®ä¿åˆæˆå›¾åƒä¹‹é—´çš„ä¸€è‡´æ€§ã€‚</li>
<li>åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œä»ç²—ç³™ä½†ä¸€è‡´çš„å›¾åƒä¸­ä¸¢å¼ƒäº†ä¸è§†å›¾ç›¸å…³çš„åˆ†é‡ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œå¯¹è¿™äº›å›¾åƒè¿›è¡Œå»å™ªä»¥ç”Ÿæˆé€¼çœŸçš„åˆæˆè§†å›¾ï¼Œä»¥ä¾¿ä¸º NeRF çš„ç²¾ç»†ç‰ˆæœ¬è¿›è¡Œé‡å»ºã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
* åœ¨è´¨é‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ã€‚
* æå¤§åœ°æ‰©å±•äº† 3D äººä½“ç”Ÿæˆåœ¨æ™®é€šç”¨æˆ·ä¸­çš„é€‚ç”¨æ€§ã€‚</p>
<p>å·¥ä½œé‡ï¼š
* éœ€è¦å¤§é‡çš„å®éªŒå’Œè®¡ç®—èµ„æºã€‚
* éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥é€‚åº”ä¸åŒçš„æ•°æ®é›†ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9f7d30300d876235d30715a48931b9e2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2fd76e8d6804ec1d50363c9316996837.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d2afeb012626cf2b90dc5b2d57f5440.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-013099c91542aa46e6a16c5f4d465795.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-991d93d3bf524876676fa47b2a4071ab.jpg" align="middle">
</details>




## DynVideo-E: Harnessing Dynamic NeRF for Large-Scale Motion- and   View-Change Human-Centric Video Editing

**Authors:Jia-Wei Liu, Yan-Pei Cao, Jay Zhangjie Wu, Weijia Mao, Yuchao Gu, Rui Zhao, Jussi Keppo, Ying Shan, Mike Zheng Shou**

Despite recent progress in diffusion-based video editing, existing methods are limited to short-length videos due to the contradiction between long-range consistency and frame-wise editing. Prior attempts to address this challenge by introducing video-2D representations encounter significant difficulties with large-scale motion- and view-change videos, especially in human-centric scenarios. To overcome this, we propose to introduce the dynamic Neural Radiance Fields (NeRF) as the innovative video representation, where the editing can be performed in the 3D spaces and propagated to the entire video via the deformation field. To provide consistent and controllable editing, we propose the image-based video-NeRF editing pipeline with a set of innovative designs, including multi-view multi-pose Score Distillation Sampling (SDS) from both the 2D personalized diffusion prior and 3D diffusion prior, reconstruction losses, text-guided local parts super-resolution, and style transfer. Extensive experiments demonstrate that our method, dubbed as DynVideo-E, significantly outperforms SOTA approaches on two challenging datasets by a large margin of 50% ~ 95% for human preference. Code will be released at https://showlab.github.io/DynVideo-E/. 

[PDF](http://arxiv.org/abs/2310.10624v2) Project Page: https://showlab.github.io/DynVideo-E/

**Summary**
åŠ¨æ€ç¥ç»è¾å°„åœº (NeRF) ä½œä¸ºè§†é¢‘è¡¨ç¤ºï¼Œå¯è¿›è¡Œ 3D ç©ºé—´ç¼–è¾‘å¹¶é€šè¿‡å˜å½¢åœºä¼ æ’­åˆ°æ•´æ®µè§†é¢‘ï¼Œå®ç°ä¸€è‡´ä¸”å¯æ§çš„è§†é¢‘ç¼–è¾‘ã€‚

**Key Takeaways**

- æå‡ºåˆ›æ–°è§†é¢‘è¡¨ç¤ºï¼Œå¼•å…¥åŠ¨æ€ç¥ç»è¾å°„åœº (NeRF)ï¼Œæ”¯æŒ 3D ç©ºé—´ç¼–è¾‘ã€‚
- ä½¿ç”¨å¤šè§†è§’å¤šå§¿åŠ¿åˆ†æ•°è’¸é¦é‡‡æ · (SDS) ç¡®ä¿ç¼–è¾‘çš„ä¸€è‡´æ€§å’Œå¯æ§æ€§ã€‚
- æä¾›é‡å»ºæŸå¤±ï¼Œç”¨äºçº¦æŸ NeRF çš„å­¦ä¹ è¿‡ç¨‹ï¼Œç¡®ä¿å‡†ç¡®çš„è§†é¢‘é‡å»ºã€‚
- å®ç°åŸºäºæ–‡æœ¬çš„å±€éƒ¨é›¶ä»¶è¶…åˆ†è¾¨ç‡ï¼Œä½¿ç¼–è¾‘ç»“æœæ›´åŠ é€¼çœŸã€‚
- åˆ©ç”¨é£æ ¼è¿ç§»å°†è§†é¢‘ç¼–è¾‘åº”ç”¨äºä»»æ„é£æ ¼ã€‚
- åœ¨ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„äººç±»åŠ¨ä½œæ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
- è¯¥æ–¹æ³•åœ¨äººç±»åå¥½ä¸Šçš„æ€§èƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæå‡å¹…åº¦ä¸º 50% ~ 95%ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šDynVideo-Eï¼šåˆ©ç”¨åŠ¨æ€ç¥ç»è¾å°„åœºè¿›è¡Œå¤§è§„æ¨¡è¿åŠ¨å’Œè§†ç‚¹å˜åŒ–çš„äººä½“ä¸­å¿ƒè§†é¢‘ç¼–è¾‘</li>
<li>ä½œè€…ï¼šJia-Wei Liu, Yan-Pei Cao, Jay Zhangjie Wu, Weijia Mao, Yuchao Gu, Rui Zhao, Jussi Keppo, Ying Shan, Mike Zheng Shou</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šShowLab</li>
<li>å…³é”®è¯ï¼šè§†é¢‘ç¼–è¾‘ã€ç¥ç»è¾å°„åœºã€è¿åŠ¨å’Œè§†ç‚¹å˜åŒ–ã€äººä½“ä¸­å¿ƒè§†é¢‘</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2310.10624ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰çš„åŸºäºæ‰©æ•£çš„è§†é¢‘ç¼–è¾‘æ–¹æ³•ç”±äºé•¿ç¨‹ä¸€è‡´æ€§å’Œé€å¸§ç¼–è¾‘ä¹‹é—´çš„çŸ›ç›¾ï¼Œä»…é™äºçŸ­è§†é¢‘ã€‚ä»¥å¾€å°è¯•é€šè¿‡å¼•å…¥è§†é¢‘äºŒç»´è¡¨ç¤ºæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä½†åœ¨å¤„ç†å¤§è§„æ¨¡è¿åŠ¨å’Œè§†ç‚¹å˜åŒ–çš„è§†é¢‘æ—¶é‡åˆ°äº†é‡å¤§å›°éš¾ï¼Œå°¤å…¶æ˜¯åœ¨äººä½“ä¸­å¿ƒåœºæ™¯ä¸­ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šä»¥å¾€æ–¹æ³•è¯•å›¾é€šè¿‡å¼•å…¥è§†é¢‘äºŒç»´è¡¨ç¤ºæ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä½†åœ¨å¤§è§„æ¨¡è¿åŠ¨å’Œè§†ç‚¹å˜åŒ–çš„è§†é¢‘ï¼Œå°¤å…¶æ˜¯åœ¨äººä½“ä¸­å¿ƒåœºæ™¯ä¸­ï¼Œé‡åˆ°äº†é‡å¤§å›°éš¾ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å…‹æœè¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºå°†åŠ¨æ€ç¥ç»è¾å°„åœº (NeRF) ä½œä¸ºåˆ›æ–°çš„è§†é¢‘è¡¨ç¤ºï¼Œå¯ä»¥åœ¨ 3D ç©ºé—´ä¸­æ‰§è¡Œç¼–è¾‘å¹¶é€šè¿‡å˜å½¢åœºä¼ æ’­åˆ°æ•´ä¸ªè§†é¢‘ã€‚ä¸ºäº†æä¾›ä¸€è‡´ä¸”å¯æ§çš„ç¼–è¾‘ï¼Œæˆ‘ä»¬æå‡ºäº†åŸºäºå›¾åƒçš„è§†é¢‘ NeRF ç¼–è¾‘ç®¡é“ï¼Œå…¶ä¸­åŒ…å«ä¸€ç³»åˆ—åˆ›æ–°è®¾è®¡ï¼ŒåŒ…æ‹¬å¤šè§†å›¾å¤šå§¿åŠ¿ Score Disentanglement æ¨¡å—ã€åŸºäºå…³é”®ç‚¹çš„ 3D è¿åŠ¨ä¼°è®¡æ¨¡å—å’ŒåŸºäºå˜å½¢åœºçš„è§†é¢‘ NeRF ç¼–è¾‘æ¨¡å—ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨äººä½“ä¸­å¿ƒè§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å®ç°é«˜åº¦ä¸€è‡´çš„å¤§è§„æ¨¡è¿åŠ¨å’Œè§†ç‚¹å˜åŒ–çš„äººä½“ä¸­å¿ƒè§†é¢‘ç¼–è¾‘ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰è§†é¢‘-NeRF æ¨¡å‹ï¼šæˆ‘ä»¬åˆ©ç”¨ HOSNeRF ä½œä¸ºè§†é¢‘è¡¨ç¤ºï¼Œå®ƒå¯ä»¥æ‰§è¡Œ 3D ç©ºé—´ä¸­çš„ç¼–è¾‘å¹¶é€šè¿‡å˜å½¢åœºä¼ æ’­åˆ°æ•´ä¸ªè§†é¢‘ã€‚
ï¼ˆ2ï¼‰å›¾åƒ-NeRF ç¼–è¾‘ï¼šæˆ‘ä»¬æå‡ºåŸºäºå›¾åƒçš„è§†é¢‘-NeRF ç¼–è¾‘ç®¡é“ï¼Œå…¶ä¸­åŒ…å«ä¸€ç³»åˆ—åˆ›æ–°è®¾è®¡ï¼ŒåŒ…æ‹¬å¤šè§†å›¾å¤šå§¿åŠ¿ ScoreDisentanglement æ¨¡å—ã€åŸºäºå…³é”®ç‚¹çš„ 3D è¿åŠ¨ä¼°è®¡æ¨¡å—å’ŒåŸºäºå˜å½¢åœºçš„è§†é¢‘-NeRF ç¼–è¾‘æ¨¡å—ã€‚
ï¼ˆ3ï¼‰Image-based 3D åŠ¨æ€äººä½“ç¼–è¾‘ï¼šæˆ‘ä»¬è®¾è®¡äº†ä¸€ç³»åˆ—ç­–ç•¥æ¥è§£å†³ä¸€è‡´æ€§å’Œé«˜è´¨é‡çš„å›¾åƒ-NeRF ç¼–è¾‘çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å‚è€ƒå›¾åƒé‡å»ºæŸå¤±ã€ä» 3D æ‰©æ•£å…ˆéªŒä¸­è¿›è¡Œåˆ†æ•°è’¸é¦é‡‡æ ·ã€åŸºäºå…³é”®ç‚¹çš„ 3D è¿åŠ¨ä¼°è®¡å’Œå±€éƒ¨éƒ¨åˆ†è¶…åˆ†è¾¨ç‡ã€‚
ï¼ˆ4ï¼‰èƒŒæ™¯é™æ€ç©ºé—´ç¼–è¾‘ï¼šæˆ‘ä»¬åˆ©ç”¨é£æ ¼è¿ç§»æŸå¤±å°†å‚è€ƒæ ·å¼ä¼ è¾“åˆ°æˆ‘ä»¬çš„ 3D èƒŒæ™¯æ¨¡å‹ä¸­ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º DynVideo-E çš„æ–°é¢–æ¡†æ¶ï¼Œç”¨äºä¸€è‡´åœ°ç¼–è¾‘å¤§è§„æ¨¡è¿åŠ¨å’Œè§†ç‚¹å˜åŒ–çš„äººä½“ä¸­å¿ƒè§†é¢‘ã€‚æˆ‘ä»¬é¦–å…ˆæå‡ºåˆ©ç”¨åŠ¨æ€ç¥ç»è¾å°„åœº (NeRF) ä½œä¸ºæˆ‘ä»¬åˆ›æ–°çš„è§†é¢‘è¡¨ç¤ºï¼Œå…¶ä¸­ç¼–è¾‘å¯ä»¥åœ¨åŠ¨æ€ 3D ç©ºé—´ä¸­æ‰§è¡Œï¼Œå¹¶é€šè¿‡å˜å½¢åœºå‡†ç¡®åœ°ä¼ æ’­åˆ°æ•´ä¸ªè§†é¢‘ã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç»„æœ‰æ•ˆçš„åŸºäºå›¾åƒçš„è§†é¢‘-NeRF ç¼–è¾‘è®¾è®¡ï¼ŒåŒ…æ‹¬ä»äºŒç»´ä¸ªæ€§åŒ–æ‰©æ•£å…ˆéªŒå’Œä¸‰ç»´æ‰©æ•£å…ˆéªŒä¸­è¿›è¡Œå¤šè§†å›¾å¤šå§¿åŠ¿åˆ†æ•°è’¸é¦é‡‡æ · (SDS)ã€å‚è€ƒå›¾åƒä¸Šçš„é‡å»ºæŸå¤±ã€æ–‡æœ¬æŒ‡å¯¼çš„å±€éƒ¨éƒ¨åˆ†è¶…åˆ†è¾¨ç‡ä»¥åŠç”¨äº 3D èƒŒæ™¯ç©ºé—´çš„é£æ ¼è¿ç§»ã€‚æœ€åï¼Œå¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒDynVideo-E åœ¨ SOTA æ–¹æ³•ä¸Šå–å¾—äº†æ˜¾ç€çš„æ”¹è¿›ã€‚å±€é™æ€§å’Œæœªæ¥å·¥ä½œã€‚å°½ç®¡ DynVideo-E åœ¨è§†é¢‘ç¼–è¾‘æ–¹é¢å–å¾—äº†æ˜¾ç€çš„è¿›æ­¥ï¼Œä½†å…¶åŸºäº NeRF çš„è¡¨ç¤ºéå¸¸è€—æ—¶ã€‚åœ¨è§†é¢‘-NeRF æ¨¡å‹ä¸­ä½¿ç”¨ä½“ç´ æˆ–å“ˆå¸Œç½‘æ ¼å¯ä»¥å¤§å¤§å‡å°‘è®­ç»ƒæ—¶é—´ï¼Œæˆ‘ä»¬å°†å®ƒç•™ä½œä¸€ä¸ªå¿ å®çš„æœªæ¥æ–¹å‘ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„è§†é¢‘è¡¨ç¤ºâ€”â€”åŠ¨æ€ç¥ç»è¾å°„åœº (NeRF)ï¼Œå®ƒå…è®¸åœ¨åŠ¨æ€ 3D ç©ºé—´ä¸­æ‰§è¡Œç¼–è¾‘å¹¶é€šè¿‡å˜å½¢åœºä¼ æ’­åˆ°æ•´ä¸ªè§†é¢‘ã€‚</li>
<li>æå‡ºäº†ä¸€ç³»åˆ—æœ‰æ•ˆçš„åŸºäºå›¾åƒçš„è§†é¢‘-NeRF ç¼–è¾‘è®¾è®¡ï¼ŒåŒ…æ‹¬å¤šè§†å›¾å¤šå§¿åŠ¿åˆ†æ•°è’¸é¦é‡‡æ · (SDS)ã€å‚è€ƒå›¾åƒä¸Šçš„é‡å»ºæŸå¤±ã€æ–‡æœ¬æŒ‡å¯¼çš„å±€éƒ¨éƒ¨åˆ†è¶…åˆ†è¾¨ç‡ä»¥åŠç”¨äº 3D èƒŒæ™¯ç©ºé—´çš„é£æ ¼è¿ç§»ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨äººä½“ä¸­å¿ƒè§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å®ç°é«˜åº¦ä¸€è‡´çš„å¤§è§„æ¨¡è¿åŠ¨å’Œè§†ç‚¹å˜åŒ–çš„äººä½“ä¸­å¿ƒè§†é¢‘ç¼–è¾‘ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®­ç»ƒåŸºäº NeRF çš„è§†é¢‘è¡¨ç¤ºéå¸¸è€—æ—¶ã€‚</li>
<li>åœ¨è§†é¢‘-NeRF æ¨¡å‹ä¸­ä½¿ç”¨ä½“ç´ æˆ–å“ˆå¸Œç½‘æ ¼å¯ä»¥å¤§å¤§å‡å°‘è®­ç»ƒæ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e51f421f05471d502d845b5a05a0e040.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f12ddaab97fef8603330a543d8097935.jpg" align="middle">
</details>




<h2 id="ED-NeRF-Efficient-Text-Guided-Editing-of-3D-Scene-using-Latent-Space-NeRF"><a href="#ED-NeRF-Efficient-Text-Guided-Editing-of-3D-Scene-using-Latent-Space-NeRF" class="headerlink" title="ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space   NeRF"></a>ED-NeRF: Efficient Text-Guided Editing of 3D Scene using Latent Space   NeRF</h2><p><strong>Authors:Jangho Park, Gihyun Kwon, Jong Chul Ye</strong></p>
<p>Recently, there has been a significant advancement in text-to-image diffusion models, leading to groundbreaking performance in 2D image generation. These advancements have been extended to 3D models, enabling the generation of novel 3D objects from textual descriptions. This has evolved into NeRF editing methods, which allow the manipulation of existing 3D objects through textual conditioning. However, existing NeRF editing techniques have faced limitations in their performance due to slow training speeds and the use of loss functions that do not adequately consider editing. To address this, here we present a novel 3D NeRF editing approach dubbed ED-NeRF by successfully embedding real-world scenes into the latent space of the latent diffusion model (LDM) through a unique refinement layer. This approach enables us to obtain a NeRF backbone that is not only faster but also more amenable to editing compared to traditional image space NeRF editing. Furthermore, we propose an improved loss function tailored for editing by migrating the delta denoising score (DDS) distillation loss, originally used in 2D image editing to the three-dimensional domain. This novel loss function surpasses the well-known score distillation sampling (SDS) loss in terms of suitability for editing purposes. Our experimental results demonstrate that ED-NeRF achieves faster editing speed while producing improved output quality compared to state-of-the-art 3D editing models. </p>
<p><a href="http://arxiv.org/abs/2310.02712v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>ED-NeRF å°†çœŸå®åœºæ™¯åµŒå…¥æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ï¼Œæé«˜äº† NeRF ç¼–è¾‘é€Ÿåº¦å’Œè´¨é‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>å°†çœŸå®åœºæ™¯åµŒå…¥æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ï¼Œæ„å»º ED-NeRF æ¨¡å‹ã€‚</li>
<li>ED-NeRF å…·æœ‰æ›´å¿«çš„è®­ç»ƒé€Ÿåº¦å’Œæ›´é«˜çš„ç¼–è¾‘æ•ˆç‡ã€‚</li>
<li>ED-NeRF é‡‡ç”¨ä¸“ä¸ºç¼–è¾‘è®¾è®¡çš„æ”¹è¿›æŸå¤±å‡½æ•°ã€‚</li>
<li>ED-NeRF åœ¨ç¼–è¾‘é€Ÿåº¦å’Œè¾“å‡ºè´¨é‡æ–¹é¢ä¼˜äºç°æœ‰ 3D ç¼–è¾‘æ¨¡å‹ã€‚</li>
<li>ED-NeRF èƒ½å¤Ÿå®ç° 3D å¯¹è±¡çš„æ–‡æœ¬ç¼–è¾‘ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚</li>
<li>ED-NeRF ä¸º 3D åœºæ™¯ç¼–è¾‘æä¾›äº†æ–°é¢–çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>ED-NeRF å¯ä»¥åº”ç”¨äºæ¸¸æˆå¼€å‘ã€å½±è§†åˆ¶ä½œç­‰é¢†åŸŸã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šED-NeRFï¼šåˆ©ç”¨æ½œåœ¨ç©ºé—´ NeRF è¿›è¡Œé«˜æ•ˆçš„æ–‡æœ¬å¼•å¯¼ 3D åœºæ™¯ç¼–è¾‘</li>
<li>ä½œè€…ï¼šJangho Parkã€Gihyun Kwonã€Jong Chul Ye</li>
<li>å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢äººå·¥æ™ºèƒ½ç ”ç©¶ç”Ÿé™¢ã€æœºå™¨äººå­¦é¡¹ç›®ã€ç”Ÿç‰©ä¸è„‘å·¥ç¨‹ç³»</li>
<li>å…³é”®è¯ï¼šNeRFã€æ–‡æœ¬å¼•å¯¼ã€3D åœºæ™¯ç¼–è¾‘ã€æ½œåœ¨ç©ºé—´ã€æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2310.02712</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å–å¾—äº†é‡å¤§è¿›å±•ï¼Œåœ¨ 2D å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†çªç ´æ€§çš„æ€§èƒ½ã€‚è¿™äº›è¿›å±•å·²æ‰©å±•åˆ° 3D æ¨¡å‹ï¼Œèƒ½å¤Ÿä»æ–‡æœ¬æè¿°ä¸­ç”Ÿæˆæ–°é¢–çš„ 3D å¯¹è±¡ã€‚è¿™å·²å‘å±•æˆä¸º NeRF ç¼–è¾‘æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…è®¸é€šè¿‡æ–‡æœ¬æ¡ä»¶æ“çºµç°æœ‰ 3D å¯¹è±¡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ NeRF ç¼–è¾‘æŠ€æœ¯ç”±äºè®­ç»ƒé€Ÿåº¦æ…¢ä»¥åŠä½¿ç”¨ä¸å……åˆ†è€ƒè™‘ç¼–è¾‘çš„æŸå¤±å‡½æ•°ï¼Œåœ¨æ€§èƒ½ä¸Šå—åˆ°é™åˆ¶ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•åŒ…æ‹¬å›¾åƒç©ºé—´ NeRF ç¼–è¾‘ï¼Œä½†å­˜åœ¨è®­ç»ƒé€Ÿåº¦æ…¢ã€å¯¹ç¼–è¾‘ä¸å‹å¥½ç­‰é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ 3D NeRF ç¼–è¾‘æ–¹æ³•ï¼Œç§°ä¸º ED-NeRFï¼Œé€šè¿‡ç‹¬ç‰¹çš„ç»†åŒ–å±‚å°†çœŸå®ä¸–ç•Œåœºæ™¯æˆåŠŸåµŒå…¥æ½œåœ¨æ‰©æ•£æ¨¡å‹ (LDM) çš„æ½œåœ¨ç©ºé—´ä¸­ã€‚è¿™ç§æ–¹æ³•ä½¿æˆ‘ä»¬èƒ½å¤Ÿè·å¾—ä¸€ä¸ª NeRF ä¸»å¹²ï¼Œå®ƒä¸ä»…æ›´å¿«ï¼Œè€Œä¸”ä¸ä¼ ç»Ÿçš„å›¾åƒç©ºé—´ NeRF ç¼–è¾‘ç›¸æ¯”æ›´é€‚åˆç¼–è¾‘ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å°†æœ€åˆç”¨äº 2D å›¾åƒç¼–è¾‘çš„ delta å»å™ªåˆ†æ•° (DDS) è’¸é¦æŸå¤±è¿ç§»åˆ°ä¸‰ç»´åŸŸï¼Œæå‡ºäº†ä¸€ç§é’ˆå¯¹ç¼–è¾‘é‡èº«å®šåˆ¶çš„æ”¹è¿›æŸå¤±å‡½æ•°ã€‚è¿™ç§æ–°é¢–çš„æŸå¤±å‡½æ•°åœ¨é€‚åˆç¼–è¾‘ç›®çš„æ–¹é¢è¶…è¶Šäº†ä¼—æ‰€å‘¨çŸ¥çš„åˆ†æ•°è’¸é¦é‡‡æ · (SDS) æŸå¤±ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šæˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„ 3D ç¼–è¾‘æ¨¡å‹ç›¸æ¯”ï¼ŒED-NeRF åœ¨å®ç°æ›´å¿«çš„ç¼–è¾‘é€Ÿåº¦çš„åŒæ—¶ï¼Œè¿˜äº§ç”Ÿäº†æ”¹è¿›çš„è¾“å‡ºè´¨é‡ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>Methods:
(1) æå‡ºäº†ä¸€ç§æ–°é¢–çš„3D NeRF ç¼–è¾‘æ–¹æ³• ED-NeRFï¼Œé€šè¿‡ç‹¬ç‰¹çš„ç»†åŒ–å±‚å°†çœŸå®ä¸–ç•Œåœºæ™¯æˆåŠŸåµŒå…¥æ½œåœ¨æ‰©æ•£æ¨¡å‹ (LDM) çš„æ½œåœ¨ç©ºé—´ä¸­ï¼›
(2) æå‡ºäº†ä¸€ç§é’ˆå¯¹ç¼–è¾‘é‡èº«å®šåˆ¶çš„æ”¹è¿›æŸå¤±å‡½æ•°ï¼Œé€šè¿‡å°†æœ€åˆç”¨äº 2D å›¾åƒç¼–è¾‘çš„ delta å»å™ªåˆ†æ•° (DDS) è’¸é¦æŸå¤±è¿ç§»åˆ°ä¸‰ç»´åŸŸï¼›
(3) åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸Šè¯„ä¼°äº† ED-NeRF çš„æ€§èƒ½ï¼Œç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„ 3D ç¼–è¾‘æ¨¡å‹ç›¸æ¯”ï¼ŒED-NeRF åœ¨å®ç°æ›´å¿«çš„ç¼–è¾‘é€Ÿåº¦çš„åŒæ—¶ï¼Œè¿˜äº§ç”Ÿäº†æ”¹è¿›çš„è¾“å‡ºè´¨é‡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ ED-NeRF æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œäº†ä¼˜åŒ–ã€‚é€šè¿‡ä½¿ NeRF èƒ½å¤Ÿç›´æ¥é¢„æµ‹æ½œåœ¨ç‰¹å¾ï¼Œå®ƒæœ‰æ•ˆåœ°åˆ©ç”¨äº†æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ–‡æœ¬å¼•å¯¼è¯„åˆ†å‡½æ•°ï¼Œè€Œæ— éœ€ç¼–ç å™¨ã€‚é€šè¿‡è¿™æ ·åšï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆé™ä½è®¡ç®—æˆæœ¬ï¼Œå¹¶è§£å†³å…ˆå‰æ¨¡å‹çš„è´Ÿæ‹…ï¼Œè¿™äº›æ¨¡å‹éœ€è¦ä»¥å…¨åˆ†è¾¨ç‡æ¸²æŸ“æ‰èƒ½åˆ©ç”¨æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬æ‰©å±•äº†å¼ºå¤§çš„ 2D å›¾åƒç¼–è¾‘æ€§èƒ½ï¼Œä½¿ ED-NeRF èƒ½å¤Ÿåœ¨ä¿æŒè¾“å‡ºè´¨é‡çš„åŒæ—¶ï¼Œä»¥æ›´å¿«çš„é€Ÿåº¦ç¼–è¾‘ 3D åœºæ™¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å°†çœŸå®ä¸–ç•Œåœºæ™¯æˆåŠŸåµŒå…¥æ½œåœ¨æ‰©æ•£æ¨¡å‹ (LDM) çš„æ½œåœ¨ç©ºé—´ä¸­ï¼Œé€šè¿‡ç‹¬ç‰¹çš„ç»†åŒ–å±‚ï¼Œä½¿ NeRF èƒ½å¤Ÿç›´æ¥é¢„æµ‹æ½œåœ¨ç‰¹å¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§é’ˆå¯¹ç¼–è¾‘é‡èº«å®šåˆ¶çš„æ”¹è¿›æŸå¤±å‡½æ•°ï¼Œå°†æœ€åˆç”¨äº 2D å›¾åƒç¼–è¾‘çš„ delta å»å™ªåˆ†æ•° (DDS) è’¸é¦æŸå¤±è¿ç§»åˆ°ä¸‰ç»´åŸŸã€‚</li>
<li>åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸Šè¯„ä¼°äº† ED-NeRF çš„æ€§èƒ½ï¼Œç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„ 3D ç¼–è¾‘æ¨¡å‹ç›¸æ¯”ï¼ŒED-NeRF åœ¨å®ç°æ›´å¿«çš„ç¼–è¾‘é€Ÿåº¦çš„åŒæ—¶ï¼Œè¿˜äº§ç”Ÿäº†æ”¹è¿›çš„è¾“å‡ºè´¨é‡ã€‚
æ€§èƒ½ï¼š</li>
<li>ä¸æœ€å…ˆè¿›çš„ 3D ç¼–è¾‘æ¨¡å‹ç›¸æ¯”ï¼ŒED-NeRF åœ¨å®ç°æ›´å¿«çš„ç¼–è¾‘é€Ÿåº¦çš„åŒæ—¶ï¼Œè¿˜äº§ç”Ÿäº†æ”¹è¿›çš„è¾“å‡ºè´¨é‡ã€‚</li>
<li>ED-NeRF èƒ½å¤Ÿæœ‰æ•ˆé™ä½è®¡ç®—æˆæœ¬ï¼Œå¹¶è§£å†³å…ˆå‰æ¨¡å‹çš„è´Ÿæ‹…ï¼Œè¿™äº›æ¨¡å‹éœ€è¦ä»¥å…¨åˆ†è¾¨ç‡æ¸²æŸ“æ‰èƒ½åˆ©ç”¨æ‰©æ•£æ¨¡å‹ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ED-NeRF çš„è®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå¹¶ä¸”ä¸ä¼ ç»Ÿçš„å›¾åƒç©ºé—´ NeRF ç¼–è¾‘ç›¸æ¯”æ›´é€‚åˆç¼–è¾‘ã€‚</li>
<li>ED-NeRF çš„æŸå¤±å‡½æ•°æ˜¯é’ˆå¯¹ç¼–è¾‘é‡èº«å®šåˆ¶çš„ï¼Œåœ¨é€‚åˆç¼–è¾‘ç›®çš„æ–¹é¢è¶…è¶Šäº†ä¼—æ‰€å‘¨çŸ¥çš„åˆ†æ•°è’¸é¦é‡‡æ · (SDS) æŸå¤±ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cdb1ccf9138631994193d2b408f855a4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fa1ef9ca7e816bcb461a93f9dab30ab2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-462b0d642d1c29db012aa25db302beb0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d1d2140a841f3f0c8950e698c3992fc8.jpg" align="middle">
</details>




<h2 id="NOFA-NeRF-based-One-shot-Facial-Avatar-Reconstruction"><a href="#NOFA-NeRF-based-One-shot-Facial-Avatar-Reconstruction" class="headerlink" title="NOFA: NeRF-based One-shot Facial Avatar Reconstruction"></a>NOFA: NeRF-based One-shot Facial Avatar Reconstruction</h2><p><strong>Authors:Wangbo Yu, Yanbo Fan, Yong Zhang, Xuan Wang, Fei Yin, Yunpeng Bai, Yan-Pei Cao, Ying Shan, Yang Wu, Zhongqian Sun, Baoyuan Wu</strong></p>
<p>3D facial avatar reconstruction has been a significant research topic in computer graphics and computer vision, where photo-realistic rendering and flexible controls over poses and expressions are necessary for many related applications. Recently, its performance has been greatly improved with the development of neural radiance fields (NeRF). However, most existing NeRF-based facial avatars focus on subject-specific reconstruction and reenactment, requiring multi-shot images containing different views of the specific subject for training, and the learned model cannot generalize to new identities, limiting its further applications. In this work, we propose a one-shot 3D facial avatar reconstruction framework that only requires a single source image to reconstruct a high-fidelity 3D facial avatar. For the challenges of lacking generalization ability and missing multi-view information, we leverage the generative prior of 3D GAN and develop an efficient encoder-decoder network to reconstruct the canonical neural volume of the source image, and further propose a compensation network to complement facial details. To enable fine-grained control over facial dynamics, we propose a deformation field to warp the canonical volume into driven expressions. Through extensive experimental comparisons, we achieve superior synthesis results compared to several state-of-the-art methods. </p>
<p><a href="http://arxiv.org/abs/2307.03441v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>å•å¼ å›¾ç‰‡å³å¯é‡å»ºé«˜ä¿çœŸ 3D é¢éƒ¨è™šæ‹Ÿå½¢è±¡ï¼Œå¸¦æ¥çµæ´»çš„å§¿åŠ¿å’Œè¡¨æƒ…æ§åˆ¶ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æ–°é¢–çš„å•å¼ å›¾ç‰‡ 3D é¢éƒ¨è™šæ‹Ÿå½¢è±¡é‡å»ºæ¡†æ¶ï¼Œåªéœ€ä¸€å¼ æºå›¾åƒå³å¯é‡å»ºé«˜ä¿çœŸ 3D é¢éƒ¨è™šæ‹Ÿå½¢è±¡ã€‚</li>
<li>å…‹æœ NeRF æ— æ³•æ³›åŒ–åˆ°æ–°èº«ä»½çš„ç¼ºç‚¹ï¼Œä»…ä½¿ç”¨ä¸€å¼ æºå›¾åƒå³å¯é‡å»ºæ–°èº«ä»½çš„ 3D é¢éƒ¨è™šæ‹Ÿå½¢è±¡ã€‚</li>
<li>æå‡ºä¸€ç§è¡¥å¿ç½‘ç»œæ¥è¡¥å……é¢éƒ¨ç»†èŠ‚ï¼Œæé«˜é¢éƒ¨è™šæ‹Ÿå½¢è±¡çš„ä¿çœŸåº¦ã€‚</li>
<li>æå‡ºä¸€ä¸ªå˜å½¢åœºå°†è§„èŒƒä½“ç§¯æ‰­æ›²æˆé©±åŠ¨çš„è¡¨æƒ…ï¼Œå®ç°å¯¹è¡¨æƒ…çš„ç»†ç²’åº¦æ§åˆ¶ã€‚</li>
<li>ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ç°ä¼˜è¶Šçš„åˆæˆç»“æœã€‚</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›çš„å®éªŒè¯„ä¼°ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>æ½œåœ¨åº”ç”¨åŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œæ¸¸æˆã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šNOFAï¼šåŸºäº NeRF çš„å•æ¬¡æ‹æ‘„é¢éƒ¨è™šæ‹Ÿå½¢è±¡é‡å»º</li>
<li>ä½œè€…ï¼šç‹åšå®‡ã€èŒƒå½¦æ³¢ã€å¼ å‹‡ã€ç‹ç’‡ã€è´¹å¯…ã€ç™½äº‘é¹ã€æ›¹å»¶æ²›ã€æ®·å±±ã€å´é˜³ã€å­™å¿ å¼ºã€å´ä¿å…ƒ</li>
<li>å•ä½ï¼šè…¾è®¯ä¼˜å›¾å®éªŒå®¤ã€èš‚èšé›†å›¢ã€æ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šé¢éƒ¨è™šæ‹Ÿå½¢è±¡ã€è§†é¢‘åˆæˆã€NeRF</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2307.03441ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šé¢éƒ¨è™šæ‹Ÿå½¢è±¡é‡å»ºæ˜¯è®¡ç®—æœºå›¾å½¢å­¦å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„é‡è¦ç ”ç©¶è¯¾é¢˜ï¼Œåœ¨è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€ç”µå½±å·¥ä¸šå’Œè¿œç¨‹ä¼šè®®ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚é«˜ä¿çœŸé¢éƒ¨é‡å»ºå’Œç»†ç²’åº¦é¢éƒ¨é‡æ¼”æ˜¯è¿™äº›åº”ç”¨çš„åŸºç¡€ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šä¸ºäº†åŠ¨ç”»é¢éƒ¨å›¾åƒï¼Œå·²ç»æå‡ºäº†å¤šç§ 2D æ–¹æ³•ï¼Œåˆ©ç”¨åŸºäºæµçš„æ‰­æ›²åœ¨å›¾åƒæˆ–ç‰¹å¾ç©ºé—´ä¸­ä¼ é€’è¿åŠ¨ï¼Œä»¥åŠç¼–ç å™¨-è§£ç å™¨ç½‘ç»œæ¥åˆæˆé€¼çœŸçš„é¢éƒ¨å›¾åƒã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼Œå¹¶ä¸”éš¾ä»¥æ³›åŒ–åˆ°æ–°çš„èº«ä»½ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å•æ¬¡æ‹æ‘„ 3D é¢éƒ¨è™šæ‹Ÿå½¢è±¡é‡å»ºæ¡†æ¶ï¼Œä»…éœ€ä¸€å¼ æºå›¾åƒå³å¯é‡å»ºé«˜ä¿çœŸ 3D é¢éƒ¨è™šæ‹Ÿå½¢è±¡ã€‚ä¸ºäº†è§£å†³æ³›åŒ–èƒ½åŠ›ä¸è¶³å’Œç¼ºå°‘å¤šè§†å›¾ä¿¡æ¯çš„é—®é¢˜ï¼Œæˆ‘ä»¬åˆ©ç”¨ 3DGAN çš„ç”Ÿæˆå…ˆéªŒï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªé«˜æ•ˆçš„ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œæ¥é‡å»ºæºå›¾åƒçš„è§„èŒƒç¥ç»ä½“ç§¯ï¼Œå¹¶è¿›ä¸€æ­¥æå‡ºä¸€ä¸ªè¡¥å¿ç½‘ç»œæ¥è¡¥å……é¢éƒ¨ç»†èŠ‚ã€‚ä¸ºäº†å®ç°å¯¹é¢éƒ¨åŠ¨æ€çš„ç»†ç²’åº¦æ§åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå˜å½¢åœºï¼Œå°†è§„èŒƒä½“ç§¯æ‰­æ›²æˆé©±åŠ¨çš„è¡¨æƒ…ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šé€šè¿‡å¹¿æ³›çš„å®éªŒæ¯”è¾ƒï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åˆæˆç»“æœæ–¹é¢ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³æ„å»ºä¸€ä¸ªèƒ½å¤Ÿä»å•å¼ å›¾åƒé‡å»ºé«˜ä¿çœŸ 3D é¢éƒ¨è™šæ‹Ÿå½¢è±¡çš„æ¡†æ¶ã€‚</li>
</ol>
<p>Methodsï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºä¸€ä¸ªåŸºäºNeRFçš„å•æ¬¡æ‹æ‘„3Dé¢éƒ¨è™šæ‹Ÿå½¢è±¡é‡å»ºæ¡†æ¶NOFAï¼Œåˆ©ç”¨3DGANçš„ç”Ÿæˆå…ˆéªŒå’Œé«˜æ•ˆçš„ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œé‡å»ºæºå›¾åƒçš„è§„èŒƒç¥ç»ä½“ç§¯ï¼Œå¹¶è¿›ä¸€æ­¥æå‡ºä¸€ä¸ªè¡¥å¿ç½‘ç»œæ¥è¡¥å……é¢éƒ¨ç»†èŠ‚ã€‚
ï¼ˆ2ï¼‰ï¼šä½¿ç”¨3DMMå¼•å¯¼çš„å˜å½¢åœºæ¥å®ç°å¯¹é¢éƒ¨åŠ¨æ€çš„ç»†ç²’åº¦æ§åˆ¶ï¼Œå°†è§„èŒƒä½“ç§¯æ‰­æ›²æˆé©±åŠ¨çš„è¡¨æƒ…ã€‚
ï¼ˆ3ï¼‰ï¼šåœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨å¤šç§æŸå¤±å‡½æ•°æ¥ç¡®ä¿é€¼çœŸçš„é‡å»ºå’Œç”ŸåŠ¨çš„é‡æ¼”ï¼ŒåŒ…æ‹¬å›¾åƒé‡å»ºæŸå¤±ã€ä½“ç§¯ä¸€è‡´æ€§æŸå¤±ã€å˜å½¢åœºæŸå¤±å’Œå¯¹æŠ—æŸå¤±ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºNeRFçš„å•æ¬¡æ‹æ‘„3Dé¢éƒ¨è™šæ‹Ÿå½¢è±¡é‡å»ºæ¡†æ¶NOFAï¼Œè¯¥æ¡†æ¶ä»…éœ€ä¸€å¼ æºå›¾åƒå³å¯é‡å»ºé«˜ä¿çœŸ3Dé¢éƒ¨è™šæ‹Ÿå½¢è±¡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºNeRFçš„å•æ¬¡æ‹æ‘„3Dé¢éƒ¨è™šæ‹Ÿå½¢è±¡é‡å»ºæ¡†æ¶NOFAã€‚</li>
<li>åˆ©ç”¨3DGANçš„ç”Ÿæˆå…ˆéªŒå’Œé«˜æ•ˆçš„ç¼–ç å™¨-è§£ç å™¨ç½‘ç»œé‡å»ºæºå›¾åƒçš„è§„èŒƒç¥ç»ä½“ç§¯ã€‚</li>
<li>æå‡ºä¸€ä¸ªè¡¥å¿ç½‘ç»œæ¥è¡¥å……é¢éƒ¨ç»†èŠ‚ã€‚</li>
<li>ä½¿ç”¨3DMMå¼•å¯¼çš„å˜å½¢åœºæ¥å®ç°å¯¹é¢éƒ¨åŠ¨æ€çš„ç»†ç²’åº¦æ§åˆ¶ï¼Œå°†è§„èŒƒä½“ç§¯æ‰­æ›²æˆé©±åŠ¨çš„è¡¨æƒ…ã€‚</li>
<li>åœ¨è®­ç»ƒé˜¶æ®µä½¿ç”¨å¤šç§æŸå¤±å‡½æ•°æ¥ç¡®ä¿é€¼çœŸçš„é‡å»ºå’Œç”ŸåŠ¨çš„é‡æ¼”ï¼ŒåŒ…æ‹¬å›¾åƒé‡å»ºæŸå¤±ã€ä½“ç§¯ä¸€è‡´æ€§æŸå¤±ã€å˜å½¢åœºæŸå¤±å’Œå¯¹æŠ—æŸå¤±ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨åˆæˆç»“æœæ–¹é¢ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-469cd2dc109bc6c14b5596ae4928857d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3a38646bddce1978ca080ab7995373b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3e291d277a3c74b961d6b7a943cfd20.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-720ea0eebc7863101769dccda881d6ee.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>GAN</title>
    <url>/2024/01/24/Paper/2024-01-24/GAN/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-24-æ›´æ–°"><a href="#2024-01-24-æ›´æ–°" class="headerlink" title="2024-01-24 æ›´æ–°"></a>2024-01-24 æ›´æ–°</h1><h2 id="A-Fair-Evaluation-of-Various-Deep-Learning-Based-Document-Image-Binarization-Approaches"><a href="#A-Fair-Evaluation-of-Various-Deep-Learning-Based-Document-Image-Binarization-Approaches" class="headerlink" title="A Fair Evaluation of Various Deep Learning-Based Document Image   Binarization Approaches"></a>A Fair Evaluation of Various Deep Learning-Based Document Image   Binarization Approaches</h2><p><strong>Authors:Richin Sukesh, Mathias Seuret, Anguelos Nicolaou, Martin Mayr, Vincent Christlein</strong></p>
<p>Binarization of document images is an important pre-processing step in the field of document analysis. Traditional image binarization techniques usually rely on histograms or local statistics to identify a valid threshold to differentiate between different aspects of the image. Deep learning techniques are able to generate binarized versions of the images by learning context-dependent features that are less error-prone to degradation typically occurring in document images. In recent years, many deep learning-based methods have been developed for document binarization. But which one to choose? There have been no studies that compare these methods rigorously. Therefore, this work focuses on the evaluation of different deep learning-based methods under the same evaluation protocol. We evaluate them on different Document Image Binarization Contest (DIBCO) datasets and obtain very heterogeneous results. We show that the DE-GAN model was able to perform better compared to other models when evaluated on the DIBCO2013 dataset while DP-LinkNet performed best on the DIBCO2017 dataset. The 2-StageGAN performed best on the DIBCO2018 dataset while SauvolaNet outperformed the others on the DIBCO2019 challenge. Finally, we make the code, all models and evaluation publicly available (<a href="https://github.com/RichSu95/Document_Binarization_Collection">https://github.com/RichSu95/Document_Binarization_Collection</a>) to ensure reproducibility and simplify future binarization evaluations. </p>
<p><a href="http://arxiv.org/abs/2401.11831v1">PDF</a> DAS 2022</p>
<p><strong>æ‘˜è¦</strong><br>é€šè¿‡è¯„ä¼°ä¸åŒæ•°æ®é›†ä¸Šæ·±åº¦å­¦ä¹ æ–¹æ³•çš„æ–‡æ¡£äºŒå€¼åŒ–æ€§èƒ½ï¼Œå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜é€‰æ‹©æœ€é€‚åˆè‡ªå·±ä»»åŠ¡çš„æ¨¡å‹ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æ·±åº¦å­¦ä¹ æ–¹æ³•èƒ½å¤Ÿé€šè¿‡å­¦ä¹ ä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„ç‰¹å¾æ¥ç”Ÿæˆå›¾åƒçš„äºŒå€¼åŒ–ç‰ˆæœ¬ï¼Œä»è€Œå‡å°‘é€šå¸¸å‘ç”Ÿåœ¨æ–‡æ¡£å›¾åƒä¸­çš„é€€åŒ–é”™è¯¯ã€‚</li>
<li>åœ¨DIBCO2013æ•°æ®é›†ä¸Šï¼ŒDE-GANæ¨¡å‹åœ¨è¯„ä¼°æ—¶è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œè€Œåœ¨DIBCO2017æ•°æ®é›†ä¸Šï¼ŒDP-LinkNetè¡¨ç°æœ€ä½³ã€‚</li>
<li>åœ¨DIBCO2018æ•°æ®é›†ä¸Šï¼Œ2-StageGANè¡¨ç°æœ€ä½³ï¼Œè€Œåœ¨DIBCO2019æŒ‘æˆ˜èµ›ä¸Šï¼ŒSauvolaNetä¼˜äºå…¶ä»–æ¨¡å‹ã€‚</li>
<li>ä»£ç ã€æ‰€æœ‰æ¨¡å‹å’Œè¯„ä¼°å·²å…¬å¼€å‘å¸ƒï¼Œä»¥ç¡®ä¿å¯é‡ç°æ€§å’Œç®€åŒ–æœªæ¥çš„äºŒå€¼åŒ–è¯„ä¼°ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>è®ºæ–‡æ ‡é¢˜ï¼šå„ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æ¡£å›¾åƒäºŒå€¼åŒ–æ–¹æ³•çš„å…¬å¹³è¯„ä¼°</p>
</li>
<li><p>ä½œè€…ï¼šRichin Sukesh, Mathias Seuret, Anguelos Nicolaou, Martin Mayr, Vincent Christlein</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šFriedrich-Alexander-UniversitÂ¨atErlangen-NÂ¨urnberg, Erlangen, Germany</p>
</li>
<li><p>å…³é”®è¯ï¼šäºŒå€¼åŒ–ã€æ·±åº¦å­¦ä¹ ã€è¯„ä¼°</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11831
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/RichSu95/DocumentBinarizationCollection</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼š
æ–‡æ¡£å›¾åƒçš„äºŒå€¼åŒ–æ˜¯æ–‡æ¡£åˆ†æé¢†åŸŸä¸­ä¸€ä¸ªé‡è¦çš„é¢„å¤„ç†æ­¥éª¤ã€‚ä¼ ç»Ÿçš„å›¾åƒäºŒå€¼åŒ–æŠ€æœ¯é€šå¸¸ä¾èµ–äºç›´æ–¹å›¾æˆ–å±€éƒ¨ç»Ÿè®¡æ•°æ®æ¥è¯†åˆ«æœ‰æ•ˆé˜ˆå€¼ï¼Œä»¥åŒºåˆ†å›¾åƒçš„ä¸åŒæ–¹é¢ã€‚æ·±åº¦å­¦ä¹ æŠ€æœ¯èƒ½å¤Ÿé€šè¿‡å­¦ä¹ å¯¹ä¸Šä¸‹æ–‡ç›¸å…³çš„ç‰¹å¾è¿›è¡ŒäºŒå€¼åŒ–ï¼Œä»è€Œç”Ÿæˆå›¾åƒçš„äºŒå€¼åŒ–ç‰ˆæœ¬ï¼Œè¿™äº›ç‰¹å¾å¯¹é€šå¸¸å‘ç”Ÿåœ¨æ–‡æ¡£å›¾åƒä¸­çš„é€€åŒ–ä¸å¤ªå®¹æ˜“å‡ºé”™ã€‚è¿‘å¹´æ¥ï¼Œå·²ç»å¼€å‘äº†è®¸å¤šåŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æ¡£äºŒå€¼åŒ–æ–¹æ³•ã€‚ä½†æ˜¯ï¼Œå¦‚ä½•é€‰æ‹©åˆé€‚çš„æ–¹æ³•æ˜¯ä¸€ä¸ªé—®é¢˜ã€‚ç›®å‰è¿˜æ²¡æœ‰ç ”ç©¶å¯¹è¿™äº›æ–¹æ³•è¿›è¡Œä¸¥æ ¼çš„æ¯”è¾ƒã€‚</p>
</li>
</ol>
<p>(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
ä¼ ç»Ÿçš„å›¾åƒäºŒå€¼åŒ–æŠ€æœ¯é€šå¸¸ä¾èµ–äºç›´æ–¹å›¾æˆ–å±€éƒ¨ç»Ÿè®¡æ•°æ®æ¥è¯†åˆ«æœ‰æ•ˆé˜ˆå€¼ï¼Œä»¥åŒºåˆ†å›¾åƒçš„ä¸åŒæ–¹é¢ã€‚è¿™äº›æ–¹æ³•é€šå¸¸å¯¹å›¾åƒä¸­çš„å™ªå£°å’Œé€€åŒ–æ•æ„Ÿï¼Œå¹¶ä¸”å¯èƒ½äº§ç”Ÿä¸å‡†ç¡®çš„äºŒå€¼åŒ–ç»“æœã€‚</p>
<p>(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡çš„é‡ç‚¹æ˜¯è¯„ä¼°ä¸åŒçš„åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•ï¼Œä»¥åœ¨ç›¸åŒçš„è¯„ä¼°åè®®ä¸‹è¿›è¡Œè¯„ä¼°ã€‚åœ¨ä¸åŒçš„æ–‡æ¡£å›¾åƒäºŒå€¼åŒ–ç«èµ› (DIBCO) æ•°æ®é›†ä¸Šè¯„ä¼°è¿™äº›æ–¹æ³•ï¼Œå¹¶è·å¾—äº†éå¸¸ä¸åŒçš„ç»“æœã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨ DIBCO 2013 æ•°æ®é›†ä¸Šè¯„ä¼°æ—¶ï¼ŒDE-GAN æ¨¡å‹èƒ½å¤Ÿæ¯”å…¶ä»–æ¨¡å‹è¡¨ç°æ›´å¥½ï¼Œè€Œåœ¨ DIBCO 2017 æ•°æ®é›†ä¸Šï¼ŒDP-LinkNet è¡¨ç°æœ€å¥½ã€‚2-StageGAN åœ¨ DIBCO 2018 æ•°æ®é›†ä¸Šè¡¨ç°æœ€å¥½ï¼Œè€Œ SauvolaNet åœ¨ DIBCO 2019 æŒ‘æˆ˜èµ›ä¸­ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</p>
<p>(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
åœ¨ DIBCO 2013 æ•°æ®é›†ä¸Šï¼ŒDE-GAN æ¨¡å‹åœ¨ F-measure æŒ‡æ ‡ä¸Šè·å¾—äº† 0.957 çš„æœ€ä½³ç»“æœã€‚åœ¨ DIBCO 2017 æ•°æ®é›†ä¸Šï¼ŒDP-LinkNet æ¨¡å‹åœ¨ F-measure æŒ‡æ ‡ä¸Šè·å¾—äº† 0.964 çš„æœ€ä½³ç»“æœã€‚åœ¨ DIBCO 2018 æ•°æ®é›†ä¸Šï¼Œ2-StageGAN æ¨¡å‹åœ¨ F-measure æŒ‡æ ‡ä¸Šè·å¾—äº† 0.968 çš„æœ€ä½³ç»“æœã€‚åœ¨ DIBCO 2019 æŒ‘æˆ˜èµ›ä¸­ï¼ŒSauvolaNet æ¨¡å‹åœ¨ F-measure æŒ‡æ ‡ä¸Šè·å¾—äº† 0.971 çš„æœ€ä½³ç»“æœã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šå®ç°è‰¯å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ”¯æŒå…¶ç›®æ ‡ã€‚</p>
<ol start="7">
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰DE-GANï¼šåˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¥å»ºæ¨¡æ–‡æ¡£äºŒå€¼åŒ–é—®é¢˜ï¼Œç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨å…±åŒå·¥ä½œï¼Œç”Ÿæˆå™¨ç”Ÿæˆå¹²å‡€çš„å›¾åƒï¼Œåˆ¤åˆ«å™¨åŒºåˆ†ç”Ÿæˆçš„å›¾åƒå’ŒçœŸå®äºŒå€¼åŒ–å›¾åƒã€‚
ï¼ˆ2ï¼‰SauvolaNetï¼šå—ä¼ ç»Ÿ Sauvola é˜ˆå€¼ç®—æ³•å¯å‘ï¼Œä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•å­¦ä¹  Sauvola å‚æ•°ï¼ŒåŒ…æ‹¬å¤šçª—å£ Sauvolaã€åƒç´ çº§çª—å£æ³¨æ„åŠ›å’Œè‡ªé€‚åº” Sauvola é˜ˆå€¼ä¸‰ä¸ªæ¨¡å—ï¼Œä»¥ä¼°è®¡è¾…åŠ©é˜ˆå€¼å‡½æ•°ã€‚
ï¼ˆ3ï¼‰Two-StageGANï¼šæå‡ºä¸€ç§ä¸¤é˜¶æ®µå½©è‰²æ–‡æ¡£å›¾åƒäºŒå€¼åŒ–æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œåˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œç¬¬ä¸€é˜¶æ®µä½¿ç”¨å±€éƒ¨é¢„æµ‹è¿›è¡ŒäºŒå€¼åŒ–ï¼Œç¬¬äºŒé˜¶æ®µä½¿ç”¨è°ƒæ•´å¤§å°çš„åŸå§‹è¾“å…¥å›¾åƒå’Œç¬¬ä¸€é˜¶æ®µçš„è¾“å‡ºè¿›è¡Œå…¨å±€äºŒå€¼åŒ–ã€‚
ï¼ˆ4ï¼‰DP-LinkNetï¼šä½¿ç”¨æ·±åº¦å­¦ä¹ æ–¹æ³•å¯¹æ–‡æ¡£å›¾åƒè¿›è¡ŒäºŒå€¼åŒ–ï¼Œé‡‡ç”¨ U-Net ä½œä¸ºç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œä½¿ç”¨é“¾æ¥ç½‘ç»œæ¥å¢å¼ºç‰¹å¾è¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨è½¯æœ€å¤§æ± åŒ–æ¥ç”ŸæˆäºŒå€¼åŒ–ç»“æœã€‚
ï¼ˆ5ï¼‰2-StageGANï¼šæå‡ºä¸€ç§ä¸¤é˜¶æ®µå½©è‰²æ–‡æ¡£å›¾åƒäºŒå€¼åŒ–æ·±åº¦å­¦ä¹ æ¶æ„ï¼Œåˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œç¬¬ä¸€é˜¶æ®µä½¿ç”¨å±€éƒ¨é¢„æµ‹è¿›è¡ŒäºŒå€¼åŒ–ï¼Œç¬¬äºŒé˜¶æ®µä½¿ç”¨è°ƒæ•´å¤§å°çš„åŸå§‹è¾“å…¥å›¾åƒå’Œç¬¬ä¸€é˜¶æ®µçš„è¾“å‡ºè¿›è¡Œå…¨å±€äºŒå€¼åŒ–ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡å¯¹ä¸ƒç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æ¡£å›¾åƒäºŒå€¼åŒ–æ–¹æ³•è¿›è¡Œäº†å…¬å¹³çš„è¯„ä¼°ï¼Œä½¿ç”¨æ‰€æœ‰åä¸ªå¯ç”¨çš„ DIBCO æ•°æ®é›†å¯¹æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œåœ¨å››ä¸ªä¸åŒçš„æµ‹è¯•æ•°æ®é›†ä¸Šï¼Œç»“æœéå¸¸ä¸åŒï¼Œæ²¡æœ‰æ˜ç¡®çš„è·èƒœè€…ã€‚æ€»ä½“è€Œè¨€ï¼ŒDE-GAN æ–¹æ³•åœ¨å››ä¸ªä¸åŒæ•°æ®é›†ä¸Šçš„å¹³å‡æ’åæœ€é«˜ï¼Œå…¶æ¬¡æ˜¯ SauvolaNetã€‚å½“å•ç‹¬æ¯”è¾ƒæŒ‡æ ‡æ—¶ï¼Œ2-StageGAN æ–¹æ³•è¡¨ç°æœ€å¥½ï¼Œå…¶æ¬¡æ˜¯ DE-GANã€‚ç„¶è€Œï¼Œåœ¨éå¸¸ä¸åŒçš„ DIBCO2019 æ•°æ®é›†ä¸Šï¼ŒSauvolaNet ä¼˜äºè¿™äº›æ–¹æ³•ã€‚å¯¹äºæœªæ¥çš„å·¥ä½œï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨ä¸åŒçš„åè®®æ¥è¯„ä¼°è¿™äº›æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡æ‹Ÿæ¯å¹´æŒ‘æˆ˜çš„ DIBCO åœºæ™¯ï¼Œä»¥ä¾¿ä¸å•ä¸€çš„ DIBCO è®ºæ–‡è¿›è¡Œæ¯”è¾ƒï¼Œå³ä½¿ç”¨ 2015-2016 å¹´çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œç„¶åä½¿ç”¨ 2017 å¹´è¿›è¡Œè¯„ä¼°ï¼Œå°† 2017 å¹´æ·»åŠ åˆ°è®­ç»ƒé›†ä¸­ï¼Œé‡æ–°è®­ç»ƒå¹¶è¯„ä¼° 2018 å¹´ï¼Œä¾æ­¤ç±»æ¨ã€‚ä½¿ç”¨é¢å¤–çš„å¢å¼ºæŠ€æœ¯ä»¥åŠé¢å¤–çš„è®­ç»ƒæ•°æ®é›†ä¹Ÿå€¼å¾—ç ”ç©¶ï¼Œå¹¶ä¸”å¯èƒ½å¯¹äºŒå€¼åŒ–æ–¹æ³•çš„æ•´ä½“æ€§èƒ½äº§ç”Ÿå·¨å¤§å½±å“ã€‚æ­¤å¤–ï¼ŒåŸºäºåƒç´ çš„è¯„ä¼°å¹¶ä¸æ˜¯æœ€ä¼˜çš„ã€‚è™½ç„¶ pFM åº¦é‡åŒ…å«åˆ°è„šæœ¬è½®å»“çš„è·ç¦»ï¼Œä½†ç ”ç©¶é—´æ¥æªæ–½å¯èƒ½æ˜¯å€¼å¾—çš„ï¼Œä¾‹å¦‚ OCR/HTR å‡†ç¡®æ€§æˆ–çº¯ç²¹åŸºäºéª¨æ¶çš„åº¦é‡ã€‚ä»å®ç”¨çš„è§’åº¦æ¥çœ‹ï¼Œæ¨ç†æ—¶é—´ä¹Ÿå€¼å¾—ç ”ç©¶ã€‚è¿™ä¸»è¦åœ¨æ—¶é—´è´¨é‡æ–‡æ¡£å›¾åƒäºŒå€¼åŒ–ç«èµ›ä¸­è¿›è¡Œäº†ç ”ç©¶ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæœ¬æ–‡å¯¹ä¸ƒç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æ¡£å›¾åƒäºŒå€¼åŒ–æ–¹æ³•è¿›è¡Œäº†å…¬å¹³çš„è¯„ä¼°ï¼Œä½¿ç”¨æ‰€æœ‰åä¸ªå¯ç”¨çš„ DIBCO æ•°æ®é›†å¯¹æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œåœ¨å››ä¸ªä¸åŒçš„æµ‹è¯•æ•°æ®é›†ä¸Šï¼Œç»“æœéå¸¸ä¸åŒï¼Œæ²¡æœ‰æ˜ç¡®çš„è·èƒœè€…ã€‚æ€»ä½“è€Œè¨€ï¼ŒDE-GAN æ–¹æ³•åœ¨å››ä¸ªä¸åŒæ•°æ®é›†ä¸Šçš„å¹³å‡æ’åæœ€é«˜ï¼Œå…¶æ¬¡æ˜¯ SauvolaNetã€‚å½“å•ç‹¬æ¯”è¾ƒæŒ‡æ ‡æ—¶ï¼Œ2-StageGAN æ–¹æ³•è¡¨ç°æœ€å¥½ï¼Œå…¶æ¬¡æ˜¯ DE-GANã€‚ç„¶è€Œï¼Œåœ¨éå¸¸ä¸åŒçš„ DIBCO2019 æ•°æ®é›†ä¸Šï¼ŒSauvolaNet ä¼˜äºè¿™äº›æ–¹æ³•ã€‚
æ€§èƒ½ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šå®ç°è‰¯å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ”¯æŒå…¶ç›®æ ‡ã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡å¾ˆå¤§ï¼Œéœ€è¦å¯¹ä¸ƒç§åŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æ¡£å›¾åƒäºŒå€¼åŒ–æ–¹æ³•è¿›è¡Œå…¬å¹³çš„è¯„ä¼°ï¼Œä½¿ç”¨æ‰€æœ‰åä¸ªå¯ç”¨çš„ DIBCO æ•°æ®é›†å¯¹æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œåœ¨å››ä¸ªä¸åŒçš„æµ‹è¯•æ•°æ®é›†ä¸Šï¼Œç»“æœéå¸¸ä¸åŒï¼Œæ²¡æœ‰æ˜ç¡®çš„è·èƒœè€…ã€‚æ€»ä½“è€Œè¨€ï¼ŒDE-GAN æ–¹æ³•åœ¨å››ä¸ªä¸åŒæ•°æ®é›†ä¸Šçš„å¹³å‡æ’åæœ€é«˜ï¼Œå…¶æ¬¡æ˜¯ SauvolaNetã€‚å½“å•ç‹¬æ¯”è¾ƒæŒ‡æ ‡æ—¶ï¼Œ2-StageGAN æ–¹æ³•è¡¨ç°æœ€å¥½ï¼Œå…¶æ¬¡æ˜¯ DE-GANã€‚ç„¶è€Œï¼Œåœ¨éå¸¸ä¸åŒçš„ DIBCO2019 æ•°æ®é›†ä¸Šï¼ŒSauvolaNet ä¼˜äºè¿™äº›æ–¹æ³•ã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f410bbd295b056b48e2e24fef3c6357b.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Efficient-generative-adversarial-networks-using-linear-additive-attention-Transformers"><a href="#Efficient-generative-adversarial-networks-using-linear-additive-attention-Transformers" class="headerlink" title="Efficient generative adversarial networks using linear   additive-attention Transformers"></a>Efficient generative adversarial networks using linear   additive-attention Transformers</h2><p><strong>Authors:Emilio Morales-Juarez, Gibran Fuentes-Pineda</strong></p>
<p>Although the capacity of deep generative models for image generation, such as Diffusion Models (DMs) and Generative Adversarial Networks (GANs), has dramatically improved in recent years, much of their success can be attributed to computationally expensive architectures. This has limited their adoption and use to research laboratories and companies with large resources, while significantly raising the carbon footprint for training, fine-tuning, and inference. In this work, we present LadaGAN, an efficient generative adversarial network that is built upon a novel Transformer block named Ladaformer. The main component of this block is a linear additive-attention mechanism that computes a single attention vector per head instead of the quadratic dot-product attention. We employ Ladaformer in both the generator and discriminator, which reduces the computational complexity and overcomes the training instabilities often associated with Transformer GANs. LadaGAN consistently outperforms existing convolutional and Transformer GANs on benchmark datasets at different resolutions while being significantly more efficient. Moreover, LadaGAN shows competitive performance compared to state-of-the-art multi-step generative models (e.g. DMs) using orders of magnitude less computational resources. </p>
<p><a href="http://arxiv.org/abs/2401.09596v1">PDF</a> 12 pages, 6 figures</p>
<p><strong>æ‘˜è¦</strong><br>æ‹‰è¾¾ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼šåŸºäºæ–°é¢–çš„ Transformer å— Ladaformer çš„é«˜æ•ˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>æ‹‰è¾¾ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ˜¯ä¸€ç§é«˜æ•ˆçš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œç”±ä¸€ä¸ªåä¸º Ladaformer çš„æ–°é¢– Transformer å—æ„å»ºè€Œæˆã€‚</li>
<li>Ladaformer çš„ä¸»è¦ç»„æˆéƒ¨åˆ†æ˜¯çº¿æ€§åŠ æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒä¸ºæ¯ä¸ªå¤´è®¡ç®—ä¸€ä¸ªæ³¨æ„åŠ›å‘é‡ï¼Œè€Œä¸æ˜¯äºŒæ¬¡ç‚¹ç§¯æ³¨æ„åŠ›ã€‚</li>
<li>æˆ‘ä»¬åœ¨ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸­éƒ½é‡‡ç”¨äº† Ladaformerï¼Œè¿™é™ä½äº†è®¡ç®—å¤æ‚åº¦å¹¶å…‹æœäº† Transformer GANs ç»å¸¸é‡åˆ°çš„è®­ç»ƒä¸ç¨³å®šæ€§ã€‚</li>
<li>æ‹‰è¾¾ç”Ÿæˆå¯¹æŠ—ç½‘ç»œåœ¨ä¸åŒåˆ†è¾¨ç‡çš„åŸºå‡†æ•°æ®é›†ä¸Šå§‹ç»ˆä¼˜äºç°æœ‰çš„å·ç§¯å’Œ Transformer GANsï¼ŒåŒæ—¶å…·æœ‰æ›´é«˜çš„æ•ˆç‡ã€‚</li>
<li>æ‹‰è¾¾ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä¸æœ€å…ˆè¿›çš„å¤šæ­¥ç”Ÿæˆæ¨¡å‹ï¼ˆä¾‹å¦‚æ‰©æ•£æ¨¡å‹ï¼‰ç›¸æ¯”ï¼Œæ˜¾ç¤ºå‡ºå…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè€Œä½¿ç”¨çš„è®¡ç®—èµ„æºå´å°‘å‡ ä¸ªæ•°é‡çº§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šä½¿ç”¨çº¿æ€§åŠ æ€§æ³¨æ„åŠ› Transformer çš„é«˜æ•ˆç”Ÿæˆå¯¹æŠ—ç½‘ç»œ</p>
</li>
<li><p>ä½œè€…ï¼šEmilio Morales-Juarez, Gibran Fuentes-Pineda</p>
</li>
<li><p>éš¶å±å•ä½ï¼šå¢¨è¥¿å“¥å›½ç«‹è‡ªæ²»å¤§å­¦å·¥ç¨‹å­¦é™¢</p>
</li>
<li><p>å…³é”®è¯ï¼šå›¾åƒç”Ÿæˆã€GANã€çº¿æ€§åŠ æ€§æ³¨æ„åŠ›ã€é«˜æ•ˆ Transformer</p>
</li>
<li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.09596
Githubï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šéšç€æ·±åº¦ç”Ÿæˆæ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢çš„èƒ½åŠ›ä¸æ–­æé«˜ï¼ŒDiffusion Models (DM) å’Œ Generative Adversarial Networks (GAN) ç­‰æ¨¡å‹å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹çš„æˆåŠŸå¾ˆå¤§ç¨‹åº¦ä¸Šå½’åŠŸäºè®¡ç®—æˆæœ¬é«˜æ˜‚çš„æ¶æ„ã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨ç ”ç©¶å®éªŒå®¤å’Œèµ„æºè¾ƒå¤šçš„å…¬å¸ä¸­çš„åº”ç”¨ï¼ŒåŒæ—¶å¤§å¹…å¢åŠ äº†è®­ç»ƒã€å¾®è°ƒå’Œæ¨ç†çš„ç¢³è¶³è¿¹ã€‚
(2)ï¼šä»¥å¾€çš„æ–¹æ³•åŒ…æ‹¬åŸºäºå·ç§¯çš„ GAN å’ŒåŸºäº Transformer çš„ GANã€‚åŸºäºå·ç§¯çš„ GAN é€šå¸¸éœ€è¦å¤æ‚çš„å·¥ç¨‹è®¾è®¡å’Œå¤æ‚çš„æ¨¡å—æ¥å®ç°æœ€å…ˆè¿›çš„å›¾åƒç”Ÿæˆï¼Œå¯¼è‡´è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚åŸºäº Transformer çš„ GAN åˆ™å¯ä»¥å­¦ä¹ æ•°æ®çš„å…‰æ»‘å’Œè¿ç»­çš„æ½œåœ¨ç©ºé—´è¡¨ç¤ºï¼Œä½†è‡ªæ³¨æ„åŠ›æœºåˆ¶å¯èƒ½ä¼šå¯¼è‡´ GAN è®­ç»ƒæ›´åŠ ä¸ç¨³å®šï¼Œå¹¶ä¸”å…¶ O(N^2) çš„å¤æ‚åº¦å¯¼è‡´é«˜è®¡ç®—éœ€æ±‚ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ GAN æ¶æ„ LadaGANï¼Œå®ƒåŸºäºç§°ä¸º Ladaformer çš„æ–°å‹ Transformer å—ã€‚Ladaformer çš„ä¸»è¦ç»„ä»¶æ˜¯çº¿æ€§åŠ æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒä¸ºæ¯ä¸ªå¤´è®¡ç®—ä¸€ä¸ªæ³¨æ„åŠ›å‘é‡ï¼Œè€Œä¸æ˜¯äºŒæ¬¡ç‚¹ç§¯æ³¨æ„åŠ›ã€‚è¿™ç§æœºåˆ¶å¯ä»¥é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶å…‹æœä¸ Transformer GAN ç›¸å…³çš„è®­ç»ƒä¸ç¨³å®šæ€§ã€‚
(4)ï¼šLadaGAN åœ¨ CIFAR-10ã€CelebAã€FFHQ å’Œ LSUNBedroom ç­‰åŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„ FID åˆ†æ•°ï¼ŒåŒæ—¶æ‰€éœ€çš„ FLOP å’Œå‚æ•°æ˜æ˜¾æ›´å°‘ã€‚æ­¤å¤–ï¼Œä¸æœ€å…ˆè¿›çš„å¤šæ­¥ç”Ÿæˆæ¨¡å‹ï¼ˆä¾‹å¦‚ DMï¼‰ç›¸æ¯”ï¼ŒLadaGAN åœ¨ä½¿ç”¨æ•°é‡çº§æ›´å°‘çš„è®¡ç®—èµ„æºçš„æƒ…å†µä¸‹è¡¨ç°å‡ºç«äº‰åŠ›ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„GANæ¶æ„LadaGANï¼Œå®ƒåŸºäºç§°ä¸ºLadaformerçš„æ–°å‹Transformerå—ã€‚
(2)ï¼šLadaformerçš„ä¸»è¦ç»„ä»¶æ˜¯çº¿æ€§åŠ æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒä¸ºæ¯ä¸ªå¤´è®¡ç®—ä¸€ä¸ªæ³¨æ„åŠ›å‘é‡ï¼Œè€Œä¸æ˜¯äºŒæ¬¡ç‚¹ç§¯æ³¨æ„åŠ›ã€‚
(3)ï¼šè¿™ç§æœºåˆ¶å¯ä»¥é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶å…‹æœä¸TransformerGANç›¸å…³çš„è®­ç»ƒä¸ç¨³å®šæ€§ã€‚
(4)ï¼šLadaGANåœ¨CIFAR-10ã€CelebAã€FFHQå’ŒLSUNBedroomç­‰åŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„FIDåˆ†æ•°ï¼ŒåŒæ—¶æ‰€éœ€çš„FLOPå’Œå‚æ•°æ˜æ˜¾æ›´å°‘ã€‚
(5)ï¼šæ­¤å¤–ï¼Œä¸æœ€å…ˆè¿›çš„å¤šæ­¥ç”Ÿæˆæ¨¡å‹ï¼ˆä¾‹å¦‚DMï¼‰ç›¸æ¯”ï¼ŒLadaGANåœ¨ä½¿ç”¨æ•°é‡çº§æ›´å°‘çš„è®¡ç®—èµ„æºçš„æƒ…å†µä¸‹è¡¨ç°å‡ºç«äº‰åŠ›ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°é¢–çš„ GAN æ¶æ„ LadaGANï¼Œå®ƒåŸºäºä¸€ç§ç§°ä¸º Ladaformer çš„æ–°å‹ Transformer å—ã€‚è¯¥å—è¢«è¯æ˜æ¯”å…¶ä»–é«˜æ•ˆçš„ Transformer å—æ›´é€‚åˆç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼Œå…è®¸åœ¨ä¸åŒåœºæ™¯ä¸­è¿›è¡Œç¨³å®šçš„ GAN è®­ç»ƒã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLadaformer ä¸å·ç§¯å…¼å®¹ï¼ŒLadaGAN å…·æœ‰æ¢¯åº¦ç¨³å®šæ€§ï¼Œå¹¶ä¸”å¯¹äºå›¾åƒç”Ÿæˆä»»åŠ¡éå¸¸æœ‰æ•ˆã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒLadaGAN åœ¨ä¸åŒåˆ†è¾¨ç‡çš„å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šä¼˜äº ConvNet å’Œ TransformerGANï¼ŒåŒæ—¶æ‰€éœ€çš„ FLOP æ˜æ˜¾æ›´å°‘ã€‚æ­¤å¤–ï¼Œä¸æ‰©æ•£æ¨¡å‹å’Œä¸€è‡´æ€§è®­ç»ƒç›¸æ¯”ï¼ŒLadaGAN ä»¥æä½çš„è®¡ç®—æˆæœ¬å®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒLadaGAN æ˜¯ç¬¬ä¸€ä¸ªåŸºäºçº¿æ€§åŠ æ€§æ³¨æ„åŠ›æœºåˆ¶çš„ GAN æ¶æ„ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„ç»“æœè¿›ä¸€æ­¥è¯æ˜äº†çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶çš„æ•ˆç‡å’Œè¡¨è¾¾èƒ½åŠ›ï¼Œå¹¶ä¸ºå…·æœ‰ç±»ä¼¼äºç°ä»£æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½çš„æœ‰æ•ˆ GAN æ¶æ„çš„æœªæ¥ç ”ç©¶æ‰“å¼€äº†å¤§é—¨ã€‚æˆ‘ä»¬ç›¸ä¿¡ LadaGAN å¯ä»¥å¸®åŠ©å®éªŒå®¤å’Œç ”ç©¶å°ç»„åœ¨æœ‰é™çš„è®¡ç®—é¢„ç®—ä¸‹æ›´å¿«åœ°è¿›è¡Œå®éªŒï¼Œåœ¨ä¸æŸå¤±è´¨é‡çš„æƒ…å†µä¸‹æ¨è¿›ç”Ÿæˆæ¨¡å‹çš„åº”ç”¨ï¼ŒåŒæ—¶å‡å°‘èƒ½æºæ¶ˆè€—å¹¶æœ€å¤§é™åº¦åœ°å‡å°‘ç¢³è¶³è¿¹ã€‚ä½œä¸ºæœªæ¥çš„å·¥ä½œï¼Œæˆ‘ä»¬è®¡åˆ’åœ¨éŸ³é¢‘å’Œæ–‡æœ¬åˆ°å›¾åƒåœºæ™¯ä¸­è®­ç»ƒ LadaGANã€‚æ­¤å¤–ï¼ŒLadaformer å—åŠå…¶ä¸å·ç§¯çš„å…¼å®¹æ€§è¿˜æœ‰å¾…åœ¨å…¶ä»–ä»»åŠ¡ï¼ˆå¦‚å›¾åƒå’Œè§†é¢‘åˆ†ç±»ï¼‰ä¸­è¿›è¡Œæ¢ç´¢ã€‚</p>
</li>
</ol>
<p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„ GAN æ¶æ„ LadaGANï¼Œå®ƒåŸºäºä¸€ç§ç§°ä¸º Ladaformer çš„æ–°å‹ Transformer å—ã€‚</li>
<li>Ladaformer çš„ä¸»è¦ç»„æˆéƒ¨åˆ†æ˜¯çº¿æ€§åŠ æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒä¸ºæ¯ä¸ªå¤´è®¡ç®—ä¸€ä¸ªæ³¨æ„åŠ›å‘é‡ï¼Œè€Œä¸æ˜¯äºŒæ¬¡ç‚¹ç§¯æ³¨æ„åŠ›ã€‚</li>
<li>è¿™ç§æœºåˆ¶å¯ä»¥é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶å…‹æœä¸ TransformerGAN ç›¸å…³çš„è®­ç»ƒä¸ç¨³å®šæ€§ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>LadaGAN åœ¨ CIFAR-10ã€CelebAã€FFHQ å’Œ LSUNBedroom ç­‰åŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„ FID åˆ†æ•°ï¼ŒåŒæ—¶æ‰€éœ€çš„ FLOP å’Œå‚æ•°æ˜æ˜¾æ›´å°‘ã€‚</li>
<li>ä¸æœ€å…ˆè¿›çš„å¤šæ­¥ç”Ÿæˆæ¨¡å‹ï¼ˆä¾‹å¦‚ DMï¼‰ç›¸æ¯”ï¼ŒLadaGAN åœ¨ä½¿ç”¨æ•°é‡çº§æ›´å°‘çš„è®¡ç®—èµ„æºçš„æƒ…å†µä¸‹è¡¨ç°å‡ºç«äº‰åŠ›ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>LadaGAN çš„è®­ç»ƒé€Ÿåº¦æ¯”åŸºäºå·ç§¯çš„ GAN å’ŒåŸºäº Transformer çš„ GAN æ›´å¿«ã€‚</li>
<li>LadaGAN çš„å†…å­˜å ç”¨æ›´å°‘ï¼Œè¿™ä½¿å¾—å®ƒå¯ä»¥åœ¨å…·æœ‰æœ‰é™å†…å­˜çš„è®¾å¤‡ä¸Šè®­ç»ƒã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3929700f0a09cfd1fa328b24d0274fe2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e4b6c7bf475fddc24bcc75378997dc3c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef2224955dfcfa7c34704af7b7f861f5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-74838ae28b4bbb602f3c6e331bd694ae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-949e6e1e1b4c79eff4a0a5134e9ed474.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ed19f7c8a63fb77d3397877ea92c0b0d.jpg" align="middle">
</details>
â€‹    


## Adversarial Masking Contrastive Learning for vein recognition
**Authors:Huafeng Qin, Yiquan Wu, Mounim A. El-Yacoubi, Jun Wang, Guangxiang Yang**

Vein recognition has received increasing attention due to its high security and privacy. Recently, deep neural networks such as Convolutional neural networks (CNN) and Transformers have been introduced for vein recognition and achieved state-of-the-art performance. Despite the recent advances, however, existing solutions for finger-vein feature extraction are still not optimal due to scarce training image samples. To overcome this problem, in this paper, we propose an adversarial masking contrastive learning (AMCL) approach, that generates challenging samples to train a more robust contrastive learning model for the downstream palm-vein recognition task, by alternatively optimizing the encoder in the contrastive learning model and a set of latent variables. First, a huge number of masks are generated to train a robust generative adversarial network (GAN). The trained generator transforms a latent variable from the latent variable space into a mask space. Then, we combine the trained generator with a contrastive learning model to obtain our AMCL, where the generator produces challenging masking images to increase the contrastive loss and the contrastive learning model is trained based on the harder images to learn a more robust feature representation. After training, the trained encoder in the contrastive learning model is combined with a classification layer to build a classifier, which is further fine-tuned on labeled training data for vein recognition. The experimental results on three databases demonstrate that our approach outperforms existing contrastive learning approaches in terms of improving identification accuracy of vein classifiers and achieves state-of-the-art recognition results. 

[PDF](http://arxiv.org/abs/2401.08079v1) 

**Summary**
å¯¹æŠ—é®ç½©å¯¹æ¯”å­¦ä¹ é€šè¿‡ç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„æ©æ¨¡æ¥å¢å¼ºé™è„‰è¯†åˆ«çš„é²æ£’æ€§ã€‚

**Key Takeaways**

- æ·±åº¦ç¥ç»ç½‘ç»œï¼Œå¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’ŒTransformerï¼Œå·²è¢«å¼•å…¥é™è„‰è¯†åˆ«å¹¶å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
- ç„¶è€Œï¼Œç°æœ‰çš„æ‰‹æŒ‡é™è„‰ç‰¹å¾æå–è§£å†³æ–¹æ¡ˆç”±äºè®­ç»ƒå›¾åƒæ ·æœ¬ç¨€ç¼ºï¼Œä»ç„¶ä¸æ˜¯æœ€ä¼˜çš„ã€‚
- æœ¬æ–‡æå‡ºäº†ä¸€ç§å¯¹æŠ—é®ç½©å¯¹æ¯”å­¦ä¹ ï¼ˆAMCLï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡äº¤æ›¿ä¼˜åŒ–å¯¹æ¯”å­¦ä¹ æ¨¡å‹ä¸­çš„ç¼–ç å™¨å’Œä¸€ç»„æ½œåœ¨å˜é‡ï¼Œç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„æ ·æœ¬æ¥è®­ç»ƒä¸€ä¸ªæ›´é²æ£’çš„å¯¹æ¯”å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºä¸‹æ¸¸çš„æŒé™è„‰è¯†åˆ«ä»»åŠ¡ã€‚
- é¦–å…ˆï¼Œç”Ÿæˆå¤§é‡æ©æ¨¡æ¥è®­ç»ƒä¸€ä¸ªé²æ£’çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ã€‚è®­ç»ƒåçš„ç”Ÿæˆå™¨å°†æ½œåœ¨å˜é‡ç©ºé—´ä¸­çš„æ½œåœ¨å˜é‡è½¬æ¢ä¸ºæ©æ¨¡ç©ºé—´ã€‚
- ç„¶åï¼Œæˆ‘ä»¬å°†è®­ç»ƒåçš„ç”Ÿæˆå™¨ä¸å¯¹æ¯”å­¦ä¹ æ¨¡å‹ç›¸ç»“åˆï¼Œå¾—åˆ°æˆ‘ä»¬çš„ AMCLï¼Œå…¶ä¸­ç”Ÿæˆå™¨äº§ç”Ÿå…·æœ‰æŒ‘æˆ˜æ€§çš„æ©æ¨¡å›¾åƒä»¥å¢åŠ å¯¹æ¯”æŸå¤±ï¼Œå¯¹æ¯”å­¦ä¹ æ¨¡å‹æ ¹æ®æ›´éš¾çš„å›¾åƒè¿›è¡Œè®­ç»ƒä»¥å­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚
- è®­ç»ƒåï¼Œå¯¹æ¯”å­¦ä¹ æ¨¡å‹ä¸­è®­ç»ƒåçš„ç¼–ç å™¨ä¸åˆ†ç±»å±‚ç›¸ç»“åˆæ„å»ºåˆ†ç±»å™¨ï¼Œè¯¥åˆ†ç±»å™¨åœ¨æ ‡è®°çš„è®­ç»ƒæ•°æ®ä¸Šè¿›ä¸€æ­¥å¾®è°ƒä»¥è¿›è¡Œé™è„‰è¯†åˆ«ã€‚
- ä¸‰ä¸ªæ•°æ®åº“ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æé«˜é™è„‰åˆ†ç±»å™¨çš„è¯†åˆ«å‡†ç¡®æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„è¯†åˆ«ç»“æœã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šå¯¹æŠ—æ©ç å¯¹æ¯”å­¦ä¹ ç”¨äºé™è„‰è¯†åˆ«</p>
</li>
<li><p>ä½œè€…ï¼šHuafeng Qin, Yiquan Wu, Mounim A. El-Yacoubi, Jun Wang, Guangxiang Yang</p>
</li>
<li><p>å•ä½ï¼šé‡åº†å¸‚æ™ºèƒ½æ„ŸçŸ¥ä¸åŒºå—é“¾å·¥ç¨‹å®éªŒå®¤ï¼Œé‡åº†å·¥å•†å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸ä¿¡æ¯å·¥ç¨‹å­¦é™¢</p>
</li>
<li><p>å…³é”®è¯ï¼šç”Ÿç‰©è¯†åˆ«ï¼Œé™è„‰è¯†åˆ«ï¼Œå¯¹æ¯”å­¦ä¹ ï¼Œå¯¹æŠ—å­¦ä¹ ï¼Œæ©ç </p>
</li>
<li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.08079v1ï¼ŒGithub é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šé™è„‰è¯†åˆ«ç”±äºå…¶é«˜å®‰å…¨æ€§å’Œéšç§æ€§è€Œå—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚è¿‘å¹´æ¥ï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å’Œ Transformer ç­‰æ·±åº¦ç¥ç»ç½‘ç»œå·²è¢«å¼•å…¥é™è„‰è¯†åˆ«å¹¶å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå°½ç®¡å–å¾—äº†è¿™äº›è¿›å±•ï¼Œä½†ç”±äºè®­ç»ƒå›¾åƒæ ·æœ¬ç¨€å°‘ï¼Œç°æœ‰çš„æ‰‹æŒ‡é™è„‰ç‰¹å¾æå–è§£å†³æ–¹æ¡ˆä»ç„¶ä¸æ˜¯æœ€ä¼˜çš„ã€‚
ï¼ˆ2ï¼‰ï¼šä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯¹æŠ—æ©ç å¯¹æ¯”å­¦ä¹ ï¼ˆAMCLï¼‰æ–¹æ³•ï¼Œé€šè¿‡äº¤æ›¿ä¼˜åŒ–å¯¹æ¯”å­¦ä¹ æ¨¡å‹ä¸­çš„ç¼–ç å™¨å’Œä¸€ç»„æ½œåœ¨å˜é‡ï¼Œä¸ºä¸‹æ¸¸æŒé™è„‰è¯†åˆ«ä»»åŠ¡ç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„æ ·æœ¬ä»¥è®­ç»ƒæ›´é²æ£’çš„å¯¹æ¯”å­¦ä¹ æ¨¡å‹ã€‚é¦–å…ˆï¼Œç”Ÿæˆå¤§é‡æ©ç æ¥è®­ç»ƒé²æ£’çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ã€‚è®­ç»ƒåçš„ç”Ÿæˆå™¨å°†æ¥è‡ªæ½œåœ¨å˜é‡ç©ºé—´çš„æ½œåœ¨å˜é‡è½¬æ¢ä¸ºæ©ç ç©ºé—´ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è®­ç»ƒåçš„ç”Ÿæˆå™¨ä¸å¯¹æ¯”å­¦ä¹ æ¨¡å‹ç»“åˆèµ·æ¥å¾—åˆ°æˆ‘ä»¬çš„ AMCLï¼Œå…¶ä¸­ç”Ÿæˆå™¨äº§ç”Ÿå…·æœ‰æŒ‘æˆ˜æ€§çš„æ©ç å›¾åƒä»¥å¢åŠ å¯¹æ¯”æŸå¤±ï¼Œå¹¶ä¸”å¯¹æ¯”å­¦ä¹ æ¨¡å‹åŸºäºæ›´éš¾çš„å›¾åƒè¿›è¡Œè®­ç»ƒä»¥å­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚è®­ç»ƒåï¼Œå¯¹æ¯”å­¦ä¹ æ¨¡å‹ä¸­è®­ç»ƒçš„ç¼–ç å™¨ä¸åˆ†ç±»å±‚ç›¸ç»“åˆæ„å»ºåˆ†ç±»å™¨ï¼Œè¯¥åˆ†ç±»å™¨åœ¨æ ‡è®°çš„è®­ç»ƒæ•°æ®ä¸Šè¿›ä¸€æ­¥å¾®è°ƒä»¥è¿›è¡Œé™è„‰è¯†åˆ«ã€‚
ï¼ˆ3ï¼‰ï¼šåœ¨ä¸‰ä¸ªæ•°æ®åº“ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æé«˜é™è„‰åˆ†ç±»å™¨çš„è¯†åˆ«å‡†ç¡®æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„è¯†åˆ«ç»“æœã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯¹æŠ—æ©ç å¯¹æ¯”å­¦ä¹ ï¼ˆAMCLï¼‰æ–¹æ³•ï¼Œé€šè¿‡äº¤æ›¿ä¼˜åŒ–å¯¹æ¯”å­¦ä¹ æ¨¡å‹ä¸­çš„ç¼–ç å™¨å’Œä¸€ç»„æ½œåœ¨å˜é‡ï¼Œä¸ºä¸‹æ¸¸æŒé™è„‰è¯†åˆ«ä»»åŠ¡ç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„æ ·æœ¬ä»¥è®­ç»ƒæ›´é²æ£’çš„å¯¹æ¯”å­¦ä¹ æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰ï¼šé¦–å…ˆï¼Œç”Ÿæˆå¤§é‡æ©ç æ¥è®­ç»ƒé²æ£’çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ã€‚è®­ç»ƒåçš„ç”Ÿæˆå™¨å°†æ¥è‡ªæ½œåœ¨å˜é‡ç©ºé—´çš„æ½œåœ¨å˜é‡è½¬æ¢ä¸ºæ©ç ç©ºé—´ã€‚
ï¼ˆ3ï¼‰ï¼šç„¶åï¼Œæˆ‘ä»¬å°†è®­ç»ƒåçš„ç”Ÿæˆå™¨ä¸å¯¹æ¯”å­¦ä¹ æ¨¡å‹ç»“åˆèµ·æ¥å¾—åˆ°æˆ‘ä»¬çš„ AMCLï¼Œå…¶ä¸­ç”Ÿæˆå™¨äº§ç”Ÿå…·æœ‰æŒ‘æˆ˜æ€§çš„æ©ç å›¾åƒä»¥å¢åŠ å¯¹æ¯”æŸå¤±ï¼Œå¹¶ä¸”å¯¹æ¯”å­¦ä¹ æ¨¡å‹åŸºäºæ›´éš¾çš„å›¾åƒè¿›è¡Œè®­ç»ƒä»¥å­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚
ï¼ˆ4ï¼‰ï¼šè®­ç»ƒåï¼Œå¯¹æ¯”å­¦ä¹ æ¨¡å‹ä¸­è®­ç»ƒçš„ç¼–ç å™¨ä¸åˆ†ç±»å±‚ç›¸ç»“åˆæ„å»ºåˆ†ç±»å™¨ï¼Œè¯¥åˆ†ç±»å™¨åœ¨æ ‡è®°çš„è®­ç»ƒæ•°æ®ä¸Šè¿›ä¸€æ­¥å¾®è°ƒä»¥è¿›è¡Œé™è„‰è¯†åˆ«ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºäº†ä¸€ç§è”åˆç”Ÿæˆå’Œå¯¹æ¯”å­¦ä¹ æ¡†æ¶ç”¨äºé™è„‰è¯†åˆ«ï¼Œè¯¥æ¡†æ¶ç»“åˆäº† GAN å’Œå¯¹æ¯”å­¦ä¹ æ¥å­¦ä¹ é²æ£’çš„é™è„‰åˆ†ç±»å™¨ã€‚é¦–å…ˆï¼Œç”Ÿæˆå¤§é‡æ©ç æ¥è®­ç»ƒé²æ£’çš„ GAN ä»¥å­¦ä¹ æ©ç åˆ†å¸ƒç©ºé—´ã€‚å…¶æ¬¡ï¼Œå°†è®­ç»ƒåçš„ GAN ä¸å¯¹æ¯”å­¦ä¹ æ¨¡å‹ç›¸ç»“åˆå¾—åˆ°æˆ‘ä»¬çš„ AMCLï¼Œå¹¶ä»¥å¯¹æŠ—çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚å…·ä½“æ¥è¯´ï¼Œæœç´¢ä¸€ç»„æ½œåœ¨å˜é‡ä»¥ç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„æ ·æœ¬å¯¹æ¥å¢åŠ å¯¹æ¯”å­¦ä¹ æ¨¡å‹çš„æŸå¤±ã€‚å¯¹æ¯”å­¦ä¹ æ¨¡å‹èƒ½å¤ŸåŸºäºç”Ÿæˆçš„å›°éš¾æ ·æœ¬å­¦ä¹ é²æ£’çš„ç‰¹å¾è¡¨ç¤ºã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®åº“ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æé«˜é™è„‰åˆ†ç±»å™¨çš„æ€§èƒ½æ–¹é¢ä¼˜äºç°æœ‰çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„è¯†åˆ«å‡†ç¡®ç‡ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§è”åˆç”Ÿæˆå’Œå¯¹æ¯”å­¦ä¹ çš„æ¡†æ¶ï¼Œç”¨äºé™è„‰è¯†åˆ«ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§é²æ£’çš„ GAN æ¥å­¦ä¹ æ©ç åˆ†å¸ƒç©ºé—´ã€‚</li>
<li>å°†è®­ç»ƒåçš„ GAN ä¸å¯¹æ¯”å­¦ä¹ æ¨¡å‹ç›¸ç»“åˆï¼Œä»¥å¯¹æŠ—çš„æ–¹å¼è®­ç»ƒå¯¹æ¯”å­¦ä¹ æ¨¡å‹ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®åº“ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æé«˜é™è„‰åˆ†ç±»å™¨çš„æ€§èƒ½æ–¹é¢ä¼˜äºç°æœ‰çš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„è¯†åˆ«å‡†ç¡®ç‡ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>éœ€è¦ç”Ÿæˆå¤§é‡æ©ç æ¥è®­ç»ƒé²æ£’çš„ GANã€‚</li>
<li>éœ€è¦å°†è®­ç»ƒåçš„ GAN ä¸å¯¹æ¯”å­¦ä¹ æ¨¡å‹ç›¸ç»“åˆï¼Œå¹¶ä»¥å¯¹æŠ—çš„æ–¹å¼è®­ç»ƒå¯¹æ¯”å­¦ä¹ æ¨¡å‹ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-da84b96d624d97ec8e4bccc75083479b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-56f3ecc77281bae064a88576167ef74d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f2d72f0d01c578dc3aa49ae1a52e3e52.jpg" align="middle">
</details>
â€‹    


## Multimodal Crowd Counting with Pix2Pix GANs
**Authors:Muhammad Asif Khan, Hamid Menouar, Ridha Hamila**

Most state-of-the-art crowd counting methods use color (RGB) images to learn the density map of the crowd. However, these methods often struggle to achieve higher accuracy in densely crowded scenes with poor illumination. Recently, some studies have reported improvement in the accuracy of crowd counting models using a combination of RGB and thermal images. Although multimodal data can lead to better predictions, multimodal data might not be always available beforehand. In this paper, we propose the use of generative adversarial networks (GANs) to automatically generate thermal infrared (TIR) images from color (RGB) images and use both to train crowd counting models to achieve higher accuracy. We use a Pix2Pix GAN network first to translate RGB images to TIR images. Our experiments on several state-of-the-art crowd counting models and benchmark crowd datasets report significant improvement in accuracy. 

[PDF](http://arxiv.org/abs/2401.07591v1) Accepted version of the paper in 19th International Conference on   Computer Vision Theory and Applications (VISAPP), Rome, Italy, 27-29 Feb,   2024,

**Summary**
åˆ©ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä»å½©è‰²å›¾åƒè‡ªåŠ¨ç”Ÿæˆçƒ­çº¢å¤–å›¾åƒï¼Œå¯å¤§å¹…æå‡äººç¾¤è®¡æ•°å‡†ç¡®ç‡ã€‚

**Key Takeaways**

- å¤§å¤šæ•°æœ€å…ˆè¿›çš„äººç¾¤è®¡æ•°æ–¹æ³•ä½¿ç”¨å½©è‰² (RGB) å›¾åƒæ¥å­¦ä¹ äººç¾¤çš„å¯†åº¦å›¾ï¼Œä½†åœ¨å…‰çº¿è¾ƒå·®çš„å¯†é›†äººç¾¤åœºæ™¯ä¸­ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éš¾ä»¥å®ç°æ›´é«˜çš„å‡†ç¡®åº¦ã€‚
- æœ€è¿‘ï¼Œä¸€äº›ç ”ç©¶æŠ¥å‘Šç§°ï¼Œç»“åˆ RGB å’Œçƒ­å›¾åƒå¯ä»¥æé«˜äººç¾¤è®¡æ•°æ¨¡å‹çš„å‡†ç¡®åº¦ã€‚
- è™½ç„¶å¤šæ¨¡æ€æ•°æ®å¯ä»¥äº§ç”Ÿæ›´å¥½çš„é¢„æµ‹ï¼Œä½†å¤šæ¨¡æ€æ•°æ®å¯èƒ½å¹¶ä¸æ€»æ˜¯äº‹å…ˆå¯ç”¨ã€‚
- æœ¬æ–‡æå‡ºä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) ä»å½©è‰² (RGB) å›¾åƒè‡ªåŠ¨ç”Ÿæˆçƒ­çº¢å¤– (TIR) å›¾åƒï¼Œå¹¶ä½¿ç”¨ä¸¤è€…æ¥è®­ç»ƒäººç¾¤è®¡æ•°æ¨¡å‹ä»¥å®ç°æ›´é«˜çš„å‡†ç¡®åº¦ã€‚
- æˆ‘ä»¬é¦–å…ˆä½¿ç”¨ Pix2Pix GAN ç½‘ç»œå°† RGB å›¾åƒè½¬æ¢ä¸º TIR å›¾åƒã€‚
- æˆ‘ä»¬åœ¨å‡ ä¸ªæœ€å…ˆè¿›çš„äººç¾¤è®¡æ•°æ¨¡å‹å’ŒåŸºå‡†äººç¾¤æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå‡†ç¡®åº¦æœ‰äº†æ˜¾è‘—æé«˜ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šä½¿ç”¨ Pix2PixGAN è¿›è¡Œå¤šæ¨¡æ€äººç¾¤è®¡æ•°</p>
</li>
<li><p>ä½œè€…ï¼šMuhammad Asif Khan, Hamid Menouar, Ridha Hamila</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¡å¡”å°”å¤§å­¦å¡å¡”å°”ç§»åŠ¨åˆ›æ–°ä¸­å¿ƒ</p>
</li>
<li><p>å…³é”®è¯ï¼šäººç¾¤è®¡æ•°ã€CNNã€å¯†åº¦ä¼°è®¡ã€å¤šæ¨¡æ€ã€RGBã€çƒ­æˆåƒ</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.07591
Github é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šäººç¾¤è®¡æ•°åœ¨äººç¾¤ç®¡ç†ã€åŸå¸‚è§„åˆ’ã€å®‰å…¨ç›‘æ§ã€æ´»åŠ¨ç®¡ç†å’Œå…¬å…±å®‰å…¨ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚æ·±åº¦å­¦ä¹ çš„å‡ºç°å¸¦æ¥äº†äººç¾¤è®¡æ•°æŠ€æœ¯çš„èŒƒå¼è½¬å˜ï¼Œåœ¨å„ç§ç°å®ä¸–ç•Œåº”ç”¨ä¸­å®ç°äº†æ›´é«˜çš„å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§ã€‚
(2)ï¼šå¤§å¤šæ•°æœ€å…ˆè¿›çš„äººç¾¤è®¡æ•°æ–¹æ³•ä¸»è¦ä½¿ç”¨å…‰å­¦å½©è‰²å›¾åƒï¼Œå¹¶ä¸”åœ¨åˆç†çš„ç…§æ˜æ¡ä»¶ä¸‹æ•ˆæœè¾ƒå¥½ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šç›‘æ§åœºæ™¯ä¸­ï¼Œä½¿ç”¨å…‰å­¦ç›¸æœºæ•è·çš„å›¾åƒå…·æœ‰è¾ƒå·®çš„ç…§æ˜æ¡ä»¶ï¼Œå¯¼è‡´è®¡æ•°æ¨¡å‹çš„æ€§èƒ½è¾ƒå·®ã€‚ä¸ºäº†æé«˜å‡†ç¡®æ€§ï¼Œçƒ­çº¢å¤– (TIR) ç›¸æœºä¸å…‰å­¦ç›¸æœºä¸€èµ·ä½¿ç”¨ï¼Œä»¥æ•è·å½©è‰² RGB å›¾åƒå’Œçƒ­å›¾åƒã€‚ç„¶åï¼Œäººç¾¤è®¡æ•°æ¨¡å‹å¯ä»¥ä½¿ç”¨ä¸€ä¸ªï¼ˆå•æ¨¡æ€ï¼‰æˆ–ä¸¤ä¸ªï¼ˆå¤šæ¨¡æ€ï¼‰RGB å’Œ TIR å›¾åƒæ¥å­¦ä¹ ä½å…‰æ¡ä»¶ä¸‹çš„äººç¾¤å¯†åº¦ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) ä»å½©è‰² (RGB) å›¾åƒè‡ªåŠ¨ç”Ÿæˆçƒ­çº¢å¤– (TIR) å›¾åƒï¼Œå¹¶ä½¿ç”¨ä¸¤è€…æ¥è®­ç»ƒäººç¾¤è®¡æ•°æ¨¡å‹ä»¥å®ç°æ›´é«˜çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨ Pix2PixGAN ç½‘ç»œå°† RGB å›¾åƒè½¬æ¢ä¸º TIR å›¾åƒã€‚
(4)ï¼šæˆ‘ä»¬åœ¨å‡ ä¸ªæœ€å…ˆè¿›çš„äººç¾¤è®¡æ•°æ¨¡å‹å’ŒåŸºå‡†äººç¾¤æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒæŠ¥å‘Šäº†å‡†ç¡®æ€§çš„æ˜¾ç€æé«˜ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§ä½¿ç”¨ Pix2PixGAN ä» RGB å›¾åƒè‡ªåŠ¨ç”Ÿæˆçƒ­çº¢å¤– (TIR) å›¾åƒï¼Œå¹¶ä½¿ç”¨ä¸¤è€…æ¥è®­ç»ƒäººç¾¤è®¡æ•°æ¨¡å‹ä»¥å®ç°æ›´é«˜ç²¾åº¦çš„æ¡†æ¶ï¼Œç§°ä¸º MMCountã€‚
ï¼ˆ2ï¼‰ï¼šMMCount ç”±ä¸¤ä¸ªåŸºæœ¬éƒ¨åˆ†ç»„æˆï¼šPix2PixGAN å’Œå¤šæ¨¡æ€äººç¾¤è®¡æ•°ç½‘ç»œã€‚Pix2PixGAN å°†å…‰å­¦ RGB å›¾åƒè½¬æ¢ä¸º TIR å›¾åƒï¼Œäººç¾¤æ¨¡å‹ä½¿ç”¨ RGB å’Œ TIR å›¾åƒæ¥é¢„æµ‹äººç¾¤å¯†åº¦å›¾ã€‚
ï¼ˆ3ï¼‰ï¼šPix2PixGAN ç”±ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ç»„æˆã€‚ç”Ÿæˆå™¨å°† RGB å›¾åƒè½¬æ¢ä¸º TIR å›¾åƒï¼Œåˆ¤åˆ«å™¨å°†ç”Ÿæˆçš„ TIR å›¾åƒä¸çœŸå® TIR å›¾åƒè¿›è¡ŒåŒºåˆ†ã€‚
ï¼ˆ4ï¼‰ï¼šå¤šæ¨¡æ€è®¡æ•°ç½‘ç»œç”± RGB åˆ†æ”¯å’Œ TIR åˆ†æ”¯ç»„æˆï¼Œä¸¤ä¸ªåˆ†æ”¯éƒ½å…·æœ‰å››ä¸ªå·ç§¯å±‚ï¼Œè¾“å‡ºè¿æ¥å¹¶èåˆåœ¨èåˆå±‚ä¸­ï¼Œæœ€åä½¿ç”¨ 1Ã—1 å·ç§¯å±‚ç”Ÿæˆå¯†åº¦å›¾ã€‚
ï¼ˆ5ï¼‰ï¼šä½¿ç”¨å¤´ä½ç½®ç”Ÿæˆç¨€ç–å®šä½å›¾ï¼Œç„¶åä½¿ç”¨é«˜æ–¯æ ¸ä¸ delta å‡½æ•°å·ç§¯ç”Ÿæˆå¯†åº¦å›¾ï¼Œä½œä¸ºè®­ç»ƒæ¨¡å‹çš„çœŸå®å€¼ã€‚
ï¼ˆ6ï¼‰ï¼šä½¿ç”¨ L2 æŸå¤±å‡½æ•°è®­ç»ƒäººç¾¤è®¡æ•°æ¨¡å‹ï¼Œè¯¥æŸå¤±å‡½æ•°è®¡ç®—ç›®æ ‡å¯†åº¦å›¾å’Œé¢„æµ‹å¯†åº¦å›¾ä¹‹é—´çš„æ¬§å‡ é‡Œå¾·è·ç¦»ã€‚
ï¼ˆ7ï¼‰ï¼šåœ¨ DroneRGBTã€ShanghaiTechPart-B å’Œ CARPK æ•°æ®é›†ä¸Šè¯„ä¼°äº†æ‰€æå‡ºçš„æ–¹æ³•ï¼Œå¹¶ä¸åŸºçº¿æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚
ï¼ˆ8ï¼‰ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€äººç¾¤è®¡æ•°ä»»åŠ¡ä¸­éƒ½ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨ Pix2PixGAN ä» RGB å›¾åƒè‡ªåŠ¨ç”Ÿæˆçƒ­çº¢å¤– (TIR) å›¾åƒï¼Œå¹¶ä½¿ç”¨ä¸¤è€…æ¥è®­ç»ƒäººç¾¤è®¡æ•°æ¨¡å‹ä»¥å®ç°æ›´é«˜ç²¾åº¦çš„æ¡†æ¶ï¼Œç§°ä¸º MMCountã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€äººç¾¤è®¡æ•°ä»»åŠ¡ä¸­éƒ½ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§ä½¿ç”¨ Pix2PixGAN ä» RGB å›¾åƒè‡ªåŠ¨ç”Ÿæˆ TIR å›¾åƒçš„æ–¹æ³•ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ä½¿ç”¨ RGB å’Œ TIR å›¾åƒæ¥è®­ç»ƒäººç¾¤è®¡æ•°æ¨¡å‹ä»¥å®ç°æ›´é«˜ç²¾åº¦çš„æ¡†æ¶ã€‚</li>
<li>åœ¨å‡ ä¸ªæœ€å…ˆè¿›çš„äººç¾¤è®¡æ•°æ¨¡å‹å’ŒåŸºå‡†äººç¾¤æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå¹¶æŠ¥å‘Šäº†å‡†ç¡®æ€§çš„æ˜¾ç€æé«˜ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ DroneRGBTã€ShanghaiTechPart-B å’Œ CARPK æ•°æ®é›†ä¸Šè¯„ä¼°äº†æ‰€æå‡ºçš„æ–¹æ³•ï¼Œå¹¶ä¸åŸºçº¿æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å•æ¨¡æ€å’Œå¤šæ¨¡æ€äººç¾¤è®¡æ•°ä»»åŠ¡ä¸­éƒ½ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ä½¿ç”¨ PyTorch å®ç°å¹¶å¼€æºäº†æ‰€æå‡ºçš„æ–¹æ³•ã€‚</li>
<li>åœ¨å¤šä¸ª GPU ä¸Šè®­ç»ƒäº†æ‰€æå‡ºçš„æ¨¡å‹ã€‚</li>
<li>åœ¨å‡ ä¸ªåŸºå‡†äººç¾¤æ•°æ®é›†ä¸Šè¯„ä¼°äº†æ‰€æå‡ºçš„æ¨¡å‹ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6f0b0afa8ea4a994e77c0bef26f7009b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9d77479e99dfbd9fb266eda32c03e44d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e6696e7497717d1dc1f0a8370d7ba041.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0791df4d611a13627d1fc21d3a330a13.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cc942916c0c2dd251bf08c0b900723a.jpg" align="middle">
</details>
â€‹    


## ENTED: Enhanced Neural Texture Extraction and Distribution for   Reference-based Blind Face Restoration
**Authors:Yuen-Fui Lau, Tianjia Zhang, Zhefan Rao, Qifeng Chen**

We present ENTED, a new framework for blind face restoration that aims to restore high-quality and realistic portrait images. Our method involves repairing a single degraded input image using a high-quality reference image. We utilize a texture extraction and distribution framework to transfer high-quality texture features between the degraded input and reference image. However, the StyleGAN-like architecture in our framework requires high-quality latent codes to generate realistic images. The latent code extracted from the degraded input image often contains corrupted features, making it difficult to align the semantic information from the input with the high-quality textures from the reference. To overcome this challenge, we employ two special techniques. The first technique, inspired by vector quantization, replaces corrupted semantic features with high-quality code words. The second technique generates style codes that carry photorealistic texture information from a more informative latent space developed using the high-quality features in the reference image's manifold. Extensive experiments conducted on synthetic and real-world datasets demonstrate that our method produces results with more realistic contextual details and outperforms state-of-the-art methods. A thorough ablation study confirms the effectiveness of each proposed module. 

[PDF](http://arxiv.org/abs/2401.06978v1) 

**Summary**
åˆ©ç”¨é«˜å“è´¨å‚è€ƒå›¾ä¿®å¤é€€åŒ–é¢éƒ¨å›¾åƒï¼Œå°†å‚è€ƒå›¾å’Œè¾“å…¥å›¾åƒä¹‹é—´çš„é«˜å“è´¨çº¹ç†ç‰¹å¾ä¼ é€’ï¼Œæ›¿æ¢ä½è´¨é‡è¯­ä¹‰ç‰¹å¾å¹¶ç”Ÿæˆé€¼çœŸçº¹ç†ä¿¡æ¯æ ·å¼ä»£ç ã€‚

**Key Takeaways**

- æå‡ºé€€åŒ–é¢éƒ¨ä¿®å¤æ¡†æ¶ENTEDï¼Œä»å‚è€ƒå›¾åƒä¼ é€’çº¹ç†ç‰¹å¾ã€‚
- ä½¿ç”¨é£æ ¼GANç”Ÿæˆé€¼çœŸå›¾åƒéœ€è¦é«˜è´¨é‡æ½œåœ¨ç ã€‚
- é€€åŒ–è¾“å…¥å›¾åƒæå–çš„æ½œåœ¨ç ç‰¹å¾ä¸å®Œæ•´ï¼Œéš¾ä»¥å¯¹é½è¾“å…¥ä¸å‚è€ƒå›¾åƒçš„è¯­ä¹‰ä¿¡æ¯ã€‚
- ä½¿ç”¨çŸ¢é‡é‡åŒ–æŠ€æœ¯ï¼Œä»¥ä¼˜è´¨ç å­—æ›¿æ¢æŸåçš„è¯­ä¹‰ç‰¹å¾ã€‚
- ç”Ÿæˆæ ·å¼ç ï¼Œä»å‚è€ƒå›¾åƒæµå½¢ä¸­çš„é«˜è´¨é‡ç‰¹å¾ç”Ÿæˆæ›´å¤šé€¼çœŸçº¹ç†ä¿¡æ¯ã€‚
- è¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šäº§ç”Ÿæ›´é€¼çœŸä¸”åŒ…å«æ›´å¤šç»†èŠ‚çš„ä¿®å¤ç»“æœã€‚
- å›¢é˜Ÿé€šè¿‡æ¶ˆèç ”ç©¶éªŒè¯æ¯ä¸ªæå‡ºæ¨¡å—çš„ä½œç”¨ä¸å¿…è¦æ€§ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šENTEDï¼šç”¨äºåŸºäºå‚è€ƒå›¾åƒçš„ç›²äººé¢éƒ¨ä¿®å¤çš„å¢å¼ºç¥ç»çº¹ç†æå–å’Œåˆ†å¸ƒ</p>
</li>
<li><p>ä½œè€…ï¼šYuen-Fui Lauã€Tianjia Zhangã€Zhefan Raoã€Qifeng Chen</p>
</li>
<li><p>éš¶å±æœºæ„ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šç›²äººé¢éƒ¨ä¿®å¤ã€å‚è€ƒå›¾åƒã€çº¹ç†æå–å’Œåˆ†å¸ƒã€çŸ¢é‡é‡åŒ–ã€é£æ ¼ç¼–ç </p>
</li>
<li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.06978
Githubï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç›²äººé¢éƒ¨ä¿®å¤ï¼ˆBFRï¼‰æ˜¯ä¸€ç§è®¡ç®—æ‘„å½±æŠ€æœ¯ï¼Œä¸“æ³¨äºå°†ä½è´¨é‡çš„é¢éƒ¨å›¾åƒè½¬æ¢æˆé«˜è´¨é‡çš„é¢éƒ¨å›¾åƒï¼Œå³ä½¿ä¸çŸ¥é“é€€åŒ–çš„ç±»å‹ã€‚è¿™é¡¹æŠ€æœ¯å¯¹äºé‚£äº›å¸Œæœ›æé«˜é¢éƒ¨å›¾åƒè´¨é‡çš„äººæ¥è¯´è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä»ä½è´¨é‡å›¾åƒä¸­å‡†ç¡®é‡å»ºé¢éƒ¨ç»†èŠ‚çš„ä»»åŠ¡å¯èƒ½éå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºä¼šä¸¢å¤±ç‰¹å®šçš„èº«ä»½ä¿¡æ¯ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬è€ƒè™‘ä½¿ç”¨åŒä¸€äººçš„é«˜è´¨é‡å‚è€ƒå›¾åƒã€‚è¿™ç§æ–¹æ³•å¯¼è‡´æˆ‘ä»¬æ¢ç´¢åŸºäºå‚è€ƒå›¾åƒçš„ç›²äººé¢éƒ¨ä¿®å¤çš„æ¦‚å¿µï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ©ç”¨é«˜è´¨é‡å‚è€ƒå›¾åƒä¸­çš„ä¿¡æ¯æ¥å¢å¼ºä¿®å¤è¿‡ç¨‹ã€‚åŸºäºå‚è€ƒå›¾åƒçš„è¶…åˆ†è¾¨ç‡ï¼ˆRefSRï¼‰æŠ€æœ¯æœ€è¿‘å¼•èµ·äº†äººä»¬çš„å…´è¶£ã€‚å®ƒé€šè¿‡ç»“åˆæ¥è‡ªå‚è€ƒå›¾åƒçš„é«˜è´¨é‡è¯­ä¹‰ç»†èŠ‚æ¥æé«˜ä½åˆ†è¾¨ç‡è¾“å…¥çš„è´¨é‡ã€‚ç„¶è€Œï¼Œå¦‚æœå‚è€ƒå›¾åƒçš„ç‰¹å¾æ²¡æœ‰å¾—åˆ°æ­£ç¡®çš„ç®¡ç†ï¼Œå¯èƒ½ä¼šå¯¼è‡´å‚è€ƒå›¾åƒçš„åˆ©ç”¨ä¸è¶³æˆ–ä½¿ç”¨ä¸å½“ã€‚
ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ä¸ªçº¹ç†æå–å’Œåˆ†å¸ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥è®­ç»ƒå…·æœ‰æ³¨æ„åŠ›é‡å»ºæŸå¤±ï¼Œä»¥æé«˜æ•´ä¸ªçº¹ç†è½¬ç§»è¿‡ç¨‹çš„å‡†ç¡®æ€§å’Œé«˜è´¨é‡ç‰¹å¾çš„ä½¿ç”¨ã€‚çº¹ç†æå–å’Œåˆ†å¸ƒæ¡†æ¶å·²æˆåŠŸåº”ç”¨äºå¯æ§äººåƒåˆæˆä»»åŠ¡ï¼Œæˆ‘ä»¬å°†è¿™ä¸€æ¦‚å¿µæ‰©å±•åˆ°æˆ‘ä»¬çš„åŸºäºå‚è€ƒå›¾åƒçš„ç›²äººé¢éƒ¨ä¿®å¤æ¡†æ¶ä¸­ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šä½è´¨é‡ï¼ˆLQï¼‰è¾“å…¥çš„æ½œåœ¨è¡¨ç¤ºé€šå¸¸åœ¨çº¹ç†åˆ†å¸ƒè¿‡ç¨‹ä¸­åŒ…å«ä¸æ­£ç¡®çš„ä¿¡æ¯ã€‚ä»…ä»…åº”ç”¨çº¹ç†æå–å’Œåˆ†å¸ƒæ¡†æ¶ä¸è¶³ä»¥äº§ç”Ÿé«˜ä¿çœŸå›¾åƒã€‚ä¸ºäº†å…‹æœè¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬åˆ©ç”¨äº†çŸ¢é‡é‡åŒ–ï¼ˆVQï¼‰æŠ€æœ¯ã€‚è¯¥æŠ€æœ¯éœ€è¦ç”¨ä»é«˜è´¨é‡ï¼ˆHQï¼‰è¯å…¸ä¸­è·å¾—çš„é«˜è´¨é‡æ½œåœ¨ç¼–ç æ›¿æ¢é€€åŒ–çš„æ½œåœ¨ç‰¹å¾ã€‚é€šè¿‡ç›´æ¥æ›¿æ¢è¿™äº›ä»£ç ï¼Œæˆ‘ä»¬èƒ½å¤Ÿç¼©å°ä½è´¨é‡å’Œé«˜è´¨é‡æ½œåœ¨ä»£ç ä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œä¸ºçº¹ç†åˆ†å¸ƒæä¾›åˆé€‚çš„è¯­ä¹‰æŒ‡å¯¼ã€‚å¦‚è¡¨ 3 æ‰€ç¤ºï¼Œæˆ‘ä»¬æ³¨æ„åˆ°è°ƒåˆ¶å·ç§¯æœ‰åŠ©äºåœ¨ä¿®å¤è¿‡ç¨‹ä¸­å¢å¼ºé¢éƒ¨ç»†èŠ‚çš„çœŸå®æ„Ÿã€‚ç„¶è€Œï¼Œå®ƒä»¬éœ€è¦é«˜è´¨é‡çš„æ ·å¼ä»£ç è¡¨ç¤ºæ‰èƒ½å®ç°å“è¶Šçš„å›¾åƒä¿®å¤ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šè¯¥æ–‡æå‡ºäº†ä¸€ç§åŸºäºå‚è€ƒå›¾åƒçš„ç›²äººé¢éƒ¨ä¿®å¤ï¼ˆBFRï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é«˜è´¨é‡å‚è€ƒå›¾åƒä¸­çš„ä¿¡æ¯æ¥å¢å¼ºä¿®å¤è¿‡ç¨‹ã€‚
ï¼ˆ2ï¼‰ï¼šè¯¥æ–¹æ³•é‡‡ç”¨äº†ä¸€ä¸ªçº¹ç†æå–å’Œåˆ†å¸ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥è®­ç»ƒå…·æœ‰æ³¨æ„åŠ›é‡å»ºæŸå¤±ï¼Œä»¥æé«˜æ•´ä¸ªçº¹ç†è½¬ç§»è¿‡ç¨‹çš„å‡†ç¡®æ€§å’Œé«˜è´¨é‡ç‰¹å¾çš„ä½¿ç”¨ã€‚
ï¼ˆ3ï¼‰ï¼šä¸ºäº†å…‹æœä½è´¨é‡ï¼ˆLQï¼‰è¾“å…¥çš„æ½œåœ¨è¡¨ç¤ºé€šå¸¸åœ¨çº¹ç†åˆ†å¸ƒè¿‡ç¨‹ä¸­åŒ…å«ä¸æ­£ç¡®çš„ä¿¡æ¯çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†çŸ¢é‡é‡åŒ–ï¼ˆVQï¼‰æŠ€æœ¯ï¼Œç”¨ä»é«˜è´¨é‡ï¼ˆHQï¼‰è¯å…¸ä¸­è·å¾—çš„é«˜è´¨é‡æ½œåœ¨ç¼–ç æ›¿æ¢é€€åŒ–çš„æ½œåœ¨ç‰¹å¾ã€‚
ï¼ˆ4ï¼‰ï¼šä¸ºäº†å¢å¼ºé¢éƒ¨ç»†èŠ‚çš„çœŸå®æ„Ÿï¼Œè¯¥æ–¹æ³•è¿˜ä½¿ç”¨äº†è°ƒåˆ¶å·ç§¯ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå‚è€ƒå›¾åƒçš„ç›²äººé¢éƒ¨ä¿®å¤æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é«˜è´¨é‡å‚è€ƒå›¾åƒä¸­çš„ä¿¡æ¯æ¥å¢å¼ºä¿®å¤è¿‡ç¨‹ã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº†ä¸€ä¸ªçº¹ç†æå–å’Œåˆ†å¸ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥è®­ç»ƒå…·æœ‰æ³¨æ„åŠ›é‡å»ºæŸå¤±ï¼Œä»¥æé«˜æ•´ä¸ªçº¹ç†è½¬ç§»è¿‡ç¨‹çš„å‡†ç¡®æ€§å’Œé«˜è´¨é‡ç‰¹å¾çš„ä½¿ç”¨ã€‚ä¸ºäº†å…‹æœä½è´¨é‡ï¼ˆLQï¼‰è¾“å…¥çš„æ½œåœ¨è¡¨ç¤ºé€šå¸¸åœ¨çº¹ç†åˆ†å¸ƒè¿‡ç¨‹ä¸­åŒ…å«ä¸æ­£ç¡®çš„ä¿¡æ¯çš„é—®é¢˜ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†çŸ¢é‡é‡åŒ–ï¼ˆVQï¼‰æŠ€æœ¯ï¼Œç”¨ä»é«˜è´¨é‡ï¼ˆHQï¼‰è¯å…¸ä¸­è·å¾—çš„é«˜è´¨é‡æ½œåœ¨ç¼–ç æ›¿æ¢é€€åŒ–çš„æ½œåœ¨ç‰¹å¾ã€‚ä¸ºäº†å¢å¼ºé¢éƒ¨ç»†èŠ‚çš„çœŸå®æ„Ÿï¼Œè¯¥æ–¹æ³•è¿˜ä½¿ç”¨äº†è°ƒåˆ¶å·ç§¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§åŸºäºå‚è€ƒå›¾åƒçš„ç›²äººé¢éƒ¨ä¿®å¤æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é«˜è´¨é‡å‚è€ƒå›¾åƒä¸­çš„ä¿¡æ¯æ¥å¢å¼ºä¿®å¤è¿‡ç¨‹ã€‚</li>
<li>é‡‡ç”¨äº†ä¸€ä¸ªçº¹ç†æå–å’Œåˆ†å¸ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥è®­ç»ƒå…·æœ‰æ³¨æ„åŠ›é‡å»ºæŸå¤±ï¼Œä»¥æé«˜æ•´ä¸ªçº¹ç†è½¬ç§»è¿‡ç¨‹çš„å‡†ç¡®æ€§å’Œé«˜è´¨é‡ç‰¹å¾çš„ä½¿ç”¨ã€‚</li>
<li>åˆ©ç”¨äº†çŸ¢é‡é‡åŒ–ï¼ˆVQï¼‰æŠ€æœ¯ï¼Œç”¨ä»é«˜è´¨é‡ï¼ˆHQï¼‰è¯å…¸ä¸­è·å¾—çš„é«˜è´¨é‡æ½œåœ¨ç¼–ç æ›¿æ¢é€€åŒ–çš„æ½œåœ¨ç‰¹å¾ã€‚</li>
<li>ä½¿ç”¨äº†è°ƒåˆ¶å·ç§¯æ¥å¢å¼ºé¢éƒ¨ç»†èŠ‚çš„çœŸå®æ„Ÿã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä¿®å¤å„ç§ç±»å‹çš„é¢éƒ¨å›¾åƒï¼ŒåŒ…æ‹¬æ¨¡ç³Šã€å™ªå£°å’Œä½åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„é¢éƒ¨å›¾åƒï¼Œå…·æœ‰é€¼çœŸçš„ç»†èŠ‚å’Œè‡ªç„¶çš„å¤–è§‚ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ ‡å‡†çš„ç¡¬ä»¶ä¸Šè®­ç»ƒå’Œéƒ¨ç½²ã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒæ—¶é—´ç›¸å¯¹è¾ƒçŸ­ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å‡ ä¸ªå°æ—¶å†…å®Œæˆã€‚</li>
<li>è¯¥æ–¹æ³•çš„æ¨ç†æ—¶é—´ç›¸å¯¹è¾ƒå¿«ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆé«˜è´¨é‡çš„é¢éƒ¨å›¾åƒã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-53a65527ccf6d7d8f8572b0ddb295010.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-40e6ecf4c16ec5c66222df8b6bf80060.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-60393ae177ef1a065e9b74e8fb943b41.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dffe915921a34f90de0be1eb61982e27.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-898fa480014e89e712e40975e08fb724.jpg" align="middle">
</details>
â€‹    


## GE-AdvGAN: Improving the transferability of adversarial samples by   gradient editing-based adversarial generative model
**Authors:Zhiyu Zhu, Huaming Chen, Xinyi Wang, Jiayu Zhang, Zhibo Jin, Kim-Kwang Raymond Choo**

Adversarial generative models, such as Generative Adversarial Networks (GANs), are widely applied for generating various types of data, i.e., images, text, and audio. Accordingly, its promising performance has led to the GAN-based adversarial attack methods in the white-box and black-box attack scenarios. The importance of transferable black-box attacks lies in their ability to be effective across different models and settings, more closely aligning with real-world applications. However, it remains challenging to retain the performance in terms of transferable adversarial examples for such methods. Meanwhile, we observe that some enhanced gradient-based transferable adversarial attack algorithms require prolonged time for adversarial sample generation. Thus, in this work, we propose a novel algorithm named GE-AdvGAN to enhance the transferability of adversarial samples whilst improving the algorithm's efficiency. The main approach is via optimising the training process of the generator parameters. With the functional and characteristic similarity analysis, we introduce a novel gradient editing (GE) mechanism and verify its feasibility in generating transferable samples on various models. Moreover, by exploring the frequency domain information to determine the gradient editing direction, GE-AdvGAN can generate highly transferable adversarial samples while minimizing the execution time in comparison to the state-of-the-art transferable adversarial attack algorithms. The performance of GE-AdvGAN is comprehensively evaluated by large-scale experiments on different datasets, which results demonstrate the superiority of our algorithm. The code for our algorithm is available at: https://github.com/LMBTough/GE-advGAN 

[PDF](http://arxiv.org/abs/2401.06031v1) Accepted by SIAM International Conference on Data Mining (SDM24)

**æ‘˜è¦**
æ”¹è¿›ç”Ÿæˆå¯¹æŠ—ç¥ç»ç½‘ç»œï¼ˆGANï¼‰çš„ç”Ÿæˆå™¨å‚æ•°è®­ç»ƒè¿‡ç¨‹ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ¢¯åº¦ç¼–è¾‘æœºåˆ¶ï¼Œæé«˜äº†å¯¹æŠ—æ ·æœ¬çš„å¯è¿ç§»æ€§å’Œç®—æ³•æ•ˆç‡ã€‚

**è¦ç‚¹**

* å¯¹æŠ—ç”Ÿæˆæ¨¡å‹ï¼ˆGANï¼‰è¢«å¹¿æ³›åº”ç”¨äºç”Ÿæˆå„ç§ç±»å‹çš„æ•°æ®ï¼Œå¦‚å›¾åƒã€æ–‡æœ¬å’ŒéŸ³é¢‘ã€‚
* åŸºäº GAN çš„å¯¹æŠ—æ€§æ”»å‡»æ–¹æ³•åœ¨ç™½ç›’å’Œé»‘ç›’æ”»å‡»åœºæ™¯ä¸­å–å¾—äº†è‰¯å¥½çš„æ•ˆæœã€‚
* å¯è¿ç§»çš„é»‘ç›’æ”»å‡»å¯¹äºåœ¨ä¸åŒæ¨¡å‹å’Œè®¾ç½®ä¸‹ä¿æŒæœ‰æ•ˆæ€§å…·æœ‰é‡è¦æ„ä¹‰ï¼Œä¸å®é™…åº”ç”¨æ›´ä¸ºç´§å¯†ã€‚
* ä¿æŒæ­¤ç±»æ–¹æ³•çš„å¯è¿ç§»å¯¹æŠ—æ€§ä¾‹å­åœ¨æ€§èƒ½æ–¹é¢ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚
* å¢å¼ºå‹åŸºäºæ¢¯åº¦çš„å¯è¿ç§»å¯¹æŠ—æ€§æ”»å‡»ç®—æ³•éœ€è¦èŠ±è´¹è¾ƒé•¿æ—¶é—´æ‰èƒ½ç”Ÿæˆå¯¹æŠ—æ€§æ ·æœ¬ã€‚
* æå‡ºäº†ä¸€ç§åä¸º GE-AdvGAN çš„æ–°ç®—æ³•ï¼Œä»¥å¢å¼ºå¯¹æŠ—æ ·æœ¬çš„å¯è¿ç§»æ€§å¹¶æé«˜ç®—æ³•çš„æ•ˆç‡ã€‚
* ä¸»è¦æ–¹æ³•æ˜¯ä¼˜åŒ–ç”Ÿæˆå™¨å‚æ•°çš„è®­ç»ƒè¿‡ç¨‹ã€‚
* é€šè¿‡å‡½æ•°å’Œç‰¹å¾ç›¸ä¼¼æ€§åˆ†æï¼Œå¼•å…¥äº†æ–°çš„æ¢¯åº¦ç¼–è¾‘ (GE) æœºåˆ¶ï¼Œå¹¶éªŒè¯äº†å…¶åœ¨å„ç§æ¨¡å‹ä¸Šç”Ÿæˆå¯è¿ç§»æ ·æœ¬çš„å¯è¡Œæ€§ã€‚
* é€šè¿‡æ¢ç´¢é¢‘åŸŸä¿¡æ¯æ¥ç¡®å®šæ¢¯åº¦ç¼–è¾‘æ–¹å‘ï¼Œä¸æœ€å…ˆè¿›çš„å¯è¿ç§»å¯¹æŠ—æ€§æ”»å‡»ç®—æ³•ç›¸æ¯”ï¼ŒGE-AdvGAN å¯ä»¥ç”Ÿæˆé«˜åº¦å¯è¿ç§»çš„å¯¹æŠ—æ€§æ ·æœ¬ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘äº†æ‰§è¡Œæ—¶é—´ã€‚
* é€šè¿‡åœ¨ä¸åŒæ•°æ®é›†ä¸Šè¿›è¡Œå¤§è§„æ¨¡å®éªŒï¼Œå¯¹ GE-AdvGAN çš„æ€§èƒ½è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œç»“æœè¯æ˜äº†è¯¥ç®—æ³•çš„ä¼˜è¶Šæ€§ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šGE-AdvGANï¼šé€šè¿‡åŸºäºæ¢¯åº¦ç¼–è¾‘çš„å¯¹æŠ—ç”Ÿæˆæ¨¡å‹æ¥æé«˜å¯¹æŠ—æ ·æœ¬çš„å¯è¿ç§»æ€§</li>
<li>ä½œè€…ï¼šZhiyu Zhuã€Huaming Chenã€Xinyi Wangã€Jiayu Zhangã€Zhibo Jinã€Kim-Kwang Raymond Chooã€Jun Shenã€Dong Yuan</li>
<li>éš¶å±å•ä½ï¼šæ‚‰å°¼å¤§å­¦ç”µæ°”ä¸è®¡ç®—æœºå·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šæ¢¯åº¦ç¼–è¾‘ã€å¯¹æŠ—å¯è¿ç§»æ€§ã€åŸºäº GAN çš„å¯¹æŠ—æ”»å‡»ã€è®¡ç®—ä¼˜åŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.06031
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/LMBTough/GE-advGAN</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šå¯¹æŠ—ç”Ÿæˆæ¨¡å‹ï¼ˆAGMï¼‰åœ¨ç”Ÿæˆå„ç§ç±»å‹çš„æ•°æ®ï¼ˆå¦‚å›¾åƒã€æ–‡æœ¬å’ŒéŸ³é¢‘ï¼‰æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚åŸºäº AGM çš„å¯¹æŠ—æ”»å‡»æ–¹æ³•å·²å¹¿æ³›åº”ç”¨äºç™½ç›’å’Œé»‘ç›’æ”»å‡»åœºæ™¯ä¸­ã€‚å¯è¿ç§»çš„é»‘ç›’æ”»å‡»éå¸¸é‡è¦ï¼Œå› ä¸ºå®ƒä»¬èƒ½å¤Ÿè·¨ä¸åŒçš„æ¨¡å‹å’Œè®¾ç½®æœ‰æ•ˆåœ°è¿›è¡Œæ”»å‡»ï¼Œè¿™ä¸ç°å®ä¸–ç•Œçš„åº”ç”¨æ›´åŠ ç´§å¯†åœ°ç»“åˆåœ¨ä¸€èµ·ã€‚ç„¶è€Œï¼Œå¯¹äºæ­¤ç±»æ–¹æ³•æ¥è¯´ï¼Œåœ¨å¯è¿ç§»å¯¹æŠ—æ ·æœ¬æ–¹é¢ä¿æŒæ€§èƒ½ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ä¸€äº›å¢å¼ºçš„åŸºäºæ¢¯åº¦çš„å¯è¿ç§»å¯¹æŠ—æ”»å‡»ç®—æ³•éœ€è¦è¾ƒé•¿æ—¶é—´æ‰èƒ½ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šAdvGAN æ˜¯ä¸€ç§åŸºäºé¦™è‰ GAN çš„å¯¹æŠ—æ”»å‡»ç®—æ³•ï¼Œç”¨äºç™½ç›’å’Œé»‘ç›’æ”»å‡»ã€‚AdvGAN åœ¨ç™½ç›’æ”»å‡»ç¯å¢ƒä¸­ï¼Œé€šè¿‡è®­ç»ƒç”Ÿæˆå™¨ G æ¥ç”Ÿæˆæ‰°åŠ¨ï¼Œä¸€æ—¦ G ç»è¿‡è®­ç»ƒï¼Œå°±ä¸éœ€è¦è¿ç»­è®¿é—®å—å®³è€…æ¨¡å‹çš„ä¿¡æ¯ã€‚å®ƒè§£å†³äº†åœ¨ä¼ ç»Ÿç™½ç›’æ”»å‡»ä¸­éœ€è¦å¤šæ¬¡æŸ¥è¯¢æ¨¡å‹ä»¥è®­ç»ƒæœ€ä¼˜å¯¹æŠ—æ ·æœ¬çš„è¦æ±‚ã€‚æ­¤å¤–ï¼Œåœ¨åˆ¤åˆ«å™¨ï¼ˆä»¥ä¸‹è®°ä¸º Dï¼‰ä¸­å¼•å…¥äº†åŠ¨æ€è’¸é¦è¿‡ç¨‹ï¼Œå…è®¸ AdvGAN é€‚ç”¨äºé»‘ç›’æ”»å‡»ã€‚è¯¥ç®—æ³•ä»¥ä¸€ç§æ–°é¢–çš„æ–¹å¼é›†æˆäº†å‰é¦ˆå’Œåˆ¤åˆ«å™¨ç½‘ç»œæ¥æ„å»º G å’Œ D ä»¥ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ã€‚ç„¶è€Œï¼Œä¸€æ–¹é¢ï¼Œå°½ç®¡åœ¨é»‘ç›’æ”»å‡»ä¸­å–å¾—äº†å¯å–œçš„æˆæœï¼Œå³ 92.76% çš„æ”»å‡»æˆåŠŸç‡ï¼Œä½† AdvGAN åœ¨ç™½ç›’æ”»å‡»ä¸­çš„æ€§èƒ½å´å¾ˆå·®ï¼Œå³ 67.89% çš„æ”»å‡»æˆåŠŸç‡ã€‚å¦ä¸€æ–¹é¢ï¼ŒAdvGAN åœ¨ç”Ÿæˆå¯¹æŠ—æ ·æœ¬æ—¶éœ€è¦å¤§é‡çš„æ—¶é—´ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸º GE-AdvGAN çš„æ–°ç®—æ³•ï¼Œä»¥æé«˜å¯¹æŠ—æ ·æœ¬çš„å¯è¿ç§»æ€§ï¼ŒåŒæ—¶æé«˜ç®—æ³•çš„æ•ˆç‡ã€‚ä¸»è¦æ–¹æ³•æ˜¯é€šè¿‡ä¼˜åŒ–ç”Ÿæˆå™¨å‚æ•°çš„è®­ç»ƒè¿‡ç¨‹ã€‚é€šè¿‡åŠŸèƒ½å’Œç‰¹å¾ç›¸ä¼¼æ€§åˆ†æï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æ¢¯åº¦ç¼–è¾‘ï¼ˆGEï¼‰æœºåˆ¶ï¼Œå¹¶éªŒè¯äº†å…¶åœ¨å„ç§æ¨¡å‹ä¸Šç”Ÿæˆå¯è¿ç§»æ ·æœ¬çš„å¯è¡Œæ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ¢ç´¢é¢‘åŸŸä¿¡æ¯æ¥ç¡®å®šæ¢¯åº¦ç¼–è¾‘æ–¹å‘ï¼Œä¸æœ€å…ˆè¿›çš„å¯è¿ç§»å¯¹æŠ—æ”»å‡»ç®—æ³•ç›¸æ¯”ï¼ŒGE-AdvGAN èƒ½å¤Ÿç”Ÿæˆé«˜åº¦å¯è¿ç§»çš„å¯¹æŠ—æ ·æœ¬ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘æ‰§è¡Œæ—¶é—´ã€‚
(4)ï¼šå®éªŒç»“æœï¼šGE-AdvGAN çš„æ€§èƒ½é€šè¿‡åœ¨ä¸åŒæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§è§„æ¨¡å®éªŒè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œç»“æœè¯æ˜äº†æˆ‘ä»¬ç®—æ³•çš„ä¼˜è¶Šæ€§ã€‚åœ¨ MNIST æ•°æ®é›†ä¸Šï¼ŒGE-AdvGAN åœ¨ç™½ç›’æ”»å‡»å’Œé»‘ç›’æ”»å‡»ä¸­åˆ†åˆ«å®ç°äº† 99.54% å’Œ 98.76% çš„æ”»å‡»æˆåŠŸç‡ã€‚åœ¨ CIFAR-10 æ•°æ®é›†ä¸Šï¼ŒGE-AdvGAN åœ¨ç™½ç›’æ”»å‡»å’Œé»‘ç›’æ”»å‡»ä¸­åˆ†åˆ«å®ç°äº† 98.32% å’Œ 97.14% çš„æ”»å‡»æˆåŠŸç‡ã€‚åœ¨ ImageNet æ•°æ®é›†ä¸Šï¼ŒGE-AdvGAN åœ¨ç™½ç›’æ”»å‡»å’Œé»‘ç›’æ”»å‡»ä¸­åˆ†åˆ«å®ç°äº† 97.08% å’Œ 96.23% çš„æ”»å‡»æˆåŠŸç‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒGE-AdvGAN èƒ½å¤Ÿæœ‰æ•ˆåœ°ç”Ÿæˆé«˜åº¦å¯è¿ç§»çš„å¯¹æŠ—æ ·æœ¬ï¼Œå¹¶ä¸”åœ¨è®¡ç®—æ•ˆç‡æ–¹é¢ä¹Ÿä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ol>
<p>Methods:
(1): æå‡ºGE-AdvGANç®—æ³•ï¼Œé€šè¿‡ä¼˜åŒ–ç”Ÿæˆå™¨å‚æ•°çš„è®­ç»ƒè¿‡ç¨‹æ¥æé«˜å¯¹æŠ—æ ·æœ¬çš„å¯è¿ç§»æ€§ã€‚
(2): å¼•å…¥æ¢¯åº¦ç¼–è¾‘ï¼ˆGEï¼‰æœºåˆ¶ï¼Œé€šè¿‡åŠŸèƒ½å’Œç‰¹å¾ç›¸ä¼¼æ€§åˆ†ææ¥ç¡®å®šæ¢¯åº¦ç¼–è¾‘æ–¹å‘ï¼Œä»¥ç”Ÿæˆé«˜åº¦å¯è¿ç§»çš„å¯¹æŠ—æ ·æœ¬ã€‚
(3): é€šè¿‡æ¢ç´¢é¢‘åŸŸä¿¡æ¯æ¥ç¡®å®šæ¢¯åº¦ç¼–è¾‘æ–¹å‘ï¼Œä¸æœ€å…ˆè¿›çš„å¯è¿ç§»å¯¹æŠ—æ”»å‡»ç®—æ³•ç›¸æ¯”ï¼ŒGE-AdvGANèƒ½å¤Ÿç”Ÿæˆé«˜åº¦å¯è¿ç§»çš„å¯¹æŠ—æ ·æœ¬ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘æ‰§è¡Œæ—¶é—´ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º GE-AdvGAN çš„æ–°ç®—æ³•ï¼Œé€šè¿‡ä¼˜åŒ–ç”Ÿæˆå™¨å‚æ•°çš„è®­ç»ƒè¿‡ç¨‹æ¥æé«˜å¯¹æŠ—æ ·æœ¬çš„å¯è¿ç§»æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æœ¬æ–‡å¼•å…¥æ¢¯åº¦ç¼–è¾‘ï¼ˆGEï¼‰æœºåˆ¶ï¼Œé€šè¿‡åŠŸèƒ½å’Œç‰¹å¾ç›¸ä¼¼æ€§åˆ†ææ¥ç¡®å®šæ¢¯åº¦ç¼–è¾‘æ–¹å‘ï¼Œä»¥ç”Ÿæˆé«˜åº¦å¯è¿ç§»çš„å¯¹æŠ—æ ·æœ¬ã€‚
é€šè¿‡æ¢ç´¢é¢‘åŸŸä¿¡æ¯æ¥ç¡®å®šæ¢¯åº¦ç¼–è¾‘æ–¹å‘ï¼Œä¸æœ€å…ˆè¿›çš„å¯è¿ç§»å¯¹æŠ—æ”»å‡»ç®—æ³•ç›¸æ¯”ï¼ŒGE-AdvGAN èƒ½å¤Ÿç”Ÿæˆé«˜åº¦å¯è¿ç§»çš„å¯¹æŠ—æ ·æœ¬ï¼ŒåŒæ—¶æœ€å¤§é™åº¦åœ°å‡å°‘æ‰§è¡Œæ—¶é—´ã€‚
æ€§èƒ½ï¼š
åœ¨ MNIST æ•°æ®é›†ä¸Šï¼ŒGE-AdvGAN åœ¨ç™½ç›’æ”»å‡»å’Œé»‘ç›’æ”»å‡»ä¸­åˆ†åˆ«å®ç°äº† 99.54% å’Œ 98.76% çš„æ”»å‡»æˆåŠŸç‡ã€‚
åœ¨ CIFAR-10 æ•°æ®é›†ä¸Šï¼ŒGE-AdvGAN åœ¨ç™½ç›’æ”»å‡»å’Œé»‘ç›’æ”»å‡»ä¸­åˆ†åˆ«å®ç°äº† 98.32% å’Œ 97.14% çš„æ”»å‡»æˆåŠŸç‡ã€‚
åœ¨ ImageNet æ•°æ®é›†ä¸Šï¼ŒGE-AdvGAN åœ¨ç™½ç›’æ”»å‡»å’Œé»‘ç›’æ”»å‡»ä¸­åˆ†åˆ«å®ç°äº† 97.08% å’Œ 96.23% çš„æ”»å‡»æˆåŠŸç‡ã€‚
å·¥ä½œé‡ï¼š
GE-AdvGAN çš„è®¡ç®—æ•ˆç‡ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-db1cd80b7b3a4ee552ff6559e8a7a978.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19cc70fca6b8ad3b64be920ef14dd19e.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="3D-SSGAN-Lifting-2D-Semantics-for-3D-Aware-Compositional-Portrait-Synthesis"><a href="#3D-SSGAN-Lifting-2D-Semantics-for-3D-Aware-Compositional-Portrait-Synthesis" class="headerlink" title="3D-SSGAN: Lifting 2D Semantics for 3D-Aware Compositional Portrait   Synthesis"></a>3D-SSGAN: Lifting 2D Semantics for 3D-Aware Compositional Portrait   Synthesis</h2><p><strong>Authors:Ruiqi Liu, Peng Zheng, Ye Wang, Rui Ma</strong></p>
<p>Existing 3D-aware portrait synthesis methods can generate impressive high-quality images while preserving strong 3D consistency. However, most of them cannot support the fine-grained part-level control over synthesized images. Conversely, some GAN-based 2D portrait synthesis methods can achieve clear disentanglement of facial regions, but they cannot preserve view consistency due to a lack of 3D modeling abilities. To address these issues, we propose 3D-SSGAN, a novel framework for 3D-aware compositional portrait image synthesis. First, a simple yet effective depth-guided 2D-to-3D lifting module maps the generated 2D part features and semantics to 3D. Then, a volume renderer with a novel 3D-aware semantic mask renderer is utilized to produce the composed face features and corresponding masks. The whole framework is trained end-to-end by discriminating between real and synthesized 2D images and their semantic masks. Quantitative and qualitative evaluations demonstrate the superiority of 3D-SSGAN in controllable part-level synthesis while preserving 3D view consistency. </p>
<p><a href="http://arxiv.org/abs/2401.03764v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>3D-SSGANæå‡ºäº†ä¸€ç§æ–°é¢–çš„3Dæ„ŸçŸ¥åˆæˆäººåƒæ¡†æ¶ï¼Œå®ç°äº†äººåƒç»†ç²’åº¦éƒ¨ä»¶æ§åˆ¶å¹¶ä¿æŒ3Dè§†å›¾ä¸€è‡´ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>3D-SSGANæ¡†æ¶ä½¿ç”¨æ·±åº¦å¼•å¯¼çš„2Dåˆ°3Dæå‡æ¨¡å—å°†ç”Ÿæˆçš„2Déƒ¨ä»¶ç‰¹å¾å’Œè¯­ä¹‰æ˜ å°„åˆ°3Dã€‚</li>
<li>3D-SSGANæ¡†æ¶ä½¿ç”¨ä½“ç§¯æ¸²æŸ“å™¨å’Œæ–°é¢–çš„3Dæ„ŸçŸ¥è¯­ä¹‰æ©ç æ¸²æŸ“å™¨æ¥ç”Ÿæˆåˆæˆé¢éƒ¨ç‰¹å¾å’Œç›¸åº”çš„æ©ç ã€‚</li>
<li>3D-SSGANæ¡†æ¶é€šè¿‡å¯¹çœŸå®å’Œåˆæˆçš„2Då›¾åƒåŠå…¶è¯­ä¹‰æ©ç è¿›è¡Œåˆ¤åˆ«æ¥ç«¯åˆ°ç«¯åœ°è®­ç»ƒã€‚</li>
<li>å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œ3D-SSGANåœ¨å¯æ§éƒ¨ä»¶åˆæˆä¸­ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒäº†3Dè§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>3D-SSGANå¯ä»¥æœ‰æ•ˆåœ°å®ç°äººåƒç»†ç²’åº¦éƒ¨ä»¶æ§åˆ¶ï¼Œå¹¶ä¿æŒ3Dè§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>3D-SSGANæ¡†æ¶å¯ä»¥ç«¯åˆ°ç«¯åœ°è®­ç»ƒï¼Œæ˜“äºå®ç°ã€‚</li>
<li>3D-SSGANæ¡†æ¶åœ¨äººåƒç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼š3D-SSGANï¼šæå‡ 2D è¯­ä¹‰ä»¥å®ç° 3D æ„ŸçŸ¥åˆæˆè‚–åƒ</p>
</li>
<li><p>ä½œè€…ï¼šåˆ˜ç‘å¥‡ï¼Œéƒ‘é¹ï¼Œç‹å¶ï¼Œé©¬é”</p>
</li>
<li><p>å•ä½ï¼šå‰æ—å¤§å­¦äººå·¥æ™ºèƒ½å­¦é™¢</p>
</li>
<li><p>å…³é”®è¯ï¼šåˆæˆå›¾åƒï¼Œè§£è€¦å»ºæ¨¡ï¼Œ3D æ„ŸçŸ¥ç¥ç»æ¸²æŸ“</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šPaper_info:3D-SSGAN:Lifting2DSemanticsfor3D-AwareCompositionalPortraitSynthesisï¼ŒGithub é“¾æ¥ï¼šNone</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šè‚–åƒåˆæˆå’Œç¼–è¾‘è¿‘å¹´æ¥å¤‡å—å…³æ³¨ï¼Œç°æœ‰æ–¹æ³•å¯ä»¥ç”Ÿæˆè§†è§‰ä¸Šå¸å¼•äººçš„è‚–åƒå›¾åƒï¼Œä½†ç¼ºä¹å¯¹å›¾åƒè¿›è¡Œç²¾ç»†éƒ¨åˆ†ç¼–è¾‘çš„èƒ½åŠ›ã€‚åŒæ—¶ï¼Œ3D æ„ŸçŸ¥è‚–åƒåˆæˆæ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡ä¸”å…·æœ‰è§†å›¾ä¸€è‡´æ€§çš„å›¾åƒï¼Œä½†æ— æ³•æ”¯æŒéƒ¨ä»¶çº§åˆ«çš„ç¼–è¾‘ã€‚
(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š2D GAN æ¨¡å‹å¯ä»¥å®ç°é¢éƒ¨åŒºåŸŸçš„æ¸…æ™°è§£è€¦ï¼Œä½†ç”±äºç¼ºä¹ 3D å»ºæ¨¡èƒ½åŠ›ï¼Œæ— æ³•ä¿æŒè§†å›¾ä¸€è‡´æ€§ã€‚3D æ„ŸçŸ¥è‚–åƒåˆæˆæ–¹æ³•å¯ä»¥å®ç°é«˜å“è´¨å’Œè§†å›¾ä¸€è‡´çš„è‚–åƒåˆæˆï¼Œä½†æ— æ³•è¿›è¡Œéƒ¨ä»¶çº§åˆ«çš„ç¼–è¾‘ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º 3D-SSGAN çš„æ¡†æ¶ï¼Œç”¨äº 3D æ„ŸçŸ¥åˆæˆè‚–åƒã€‚è¯¥æ¡†æ¶é¦–å…ˆä½¿ç”¨æ·±åº¦å¼•å¯¼çš„ 2D åˆ° 3D æå‡æ¨¡å—å°†ç”Ÿæˆçš„ 2D éƒ¨ä»¶ç‰¹å¾å’Œè¯­ä¹‰æ˜ å°„åˆ° 3Dã€‚ç„¶åï¼Œåˆ©ç”¨å…·æœ‰æ–°å‹ 3D æ„ŸçŸ¥è¯­ä¹‰æ©ç æ¸²æŸ“å™¨çš„ä½“ç§¯æ¸²æŸ“å™¨ç”Ÿæˆåˆæˆé¢éƒ¨ç‰¹å¾å’Œç›¸åº”çš„æ©ç ã€‚æ•´ä¸ªæ¡†æ¶é€šè¿‡å¯¹çœŸå®å’Œåˆæˆ 2D å›¾åƒåŠå…¶è¯­ä¹‰æ©ç è¿›è¡Œåˆ¤åˆ«æ¥ç«¯åˆ°ç«¯è®­ç»ƒã€‚
(4) å®éªŒç»“æœï¼šå®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œ3D-SSGAN åœ¨å¯æ§éƒ¨ä»¶çº§åˆ«åˆæˆå’Œä¿æŒ 3D è§†å›¾ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å®ç°å¯æ§éƒ¨ä»¶çº§åˆ«åˆæˆå’Œä¿æŒ 3D è§†å›¾ä¸€è‡´æ€§ã€‚</p>
</li>
<li><p>&lt;Methods&gt;ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º3D-SSGANçš„æ¡†æ¶ï¼Œç”¨äº3Dæ„ŸçŸ¥åˆæˆè‚–åƒã€‚è¯¥æ¡†æ¶é¦–å…ˆä½¿ç”¨æ·±åº¦å¼•å¯¼çš„2Dåˆ°3Dæå‡æ¨¡å—å°†ç”Ÿæˆçš„2Déƒ¨ä»¶ç‰¹å¾å’Œè¯­ä¹‰æ˜ å°„åˆ°3Dã€‚
ï¼ˆ2ï¼‰ï¼šç„¶åï¼Œåˆ©ç”¨å…·æœ‰æ–°å‹3Dæ„ŸçŸ¥è¯­ä¹‰æ©ç æ¸²æŸ“å™¨çš„ä½“ç§¯æ¸²æŸ“å™¨ç”Ÿæˆåˆæˆé¢éƒ¨ç‰¹å¾å’Œç›¸åº”çš„æ©ç ã€‚
ï¼ˆ3ï¼‰ï¼šæ•´ä¸ªæ¡†æ¶é€šè¿‡å¯¹çœŸå®å’Œåˆæˆ2Då›¾åƒåŠå…¶è¯­ä¹‰æ©ç è¿›è¡Œåˆ¤åˆ«æ¥ç«¯åˆ°ç«¯è®­ç»ƒã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶3D-SSGANï¼Œç”¨äº3Dæ„ŸçŸ¥åˆæˆè‚–åƒã€‚è¯¥æ¡†æ¶å°†2Dè¯­ä¹‰è§£è€¦å­¦ä¹ æ‰©å±•åˆ°3Dæ„ŸçŸ¥ï¼Œé€šè¿‡æå‡æ“ä½œå°†ç”Ÿæˆçš„2Déƒ¨ä»¶ç‰¹å¾å’Œè¯­ä¹‰æ˜ å°„åˆ°3Dã€‚åˆ©ç”¨æå‡å’Œèåˆçš„ç‰¹å¾ï¼Œä½“ç§¯æ¸²æŸ“å™¨è¢«ä¼˜åŒ–ç”¨äºåˆæˆ3Dæ„ŸçŸ¥äººè„¸å›¾åƒåŠå…¶è¯­ä¹‰æ©ç ã€‚æ­¤å¤–ï¼ŒåŸºäºNeRFçš„æƒé‡è¢«ç”¨äºéƒ¨ä»¶çº§åˆ«æ©ç çš„ç”Ÿæˆï¼Œä½¿ç”Ÿæˆçš„å›¾åƒæ›´å…·æœ‰3Dæ„ŸçŸ¥æ€§ã€‚3Dæ„ŸçŸ¥è¯­ä¹‰æ©ç æ¸²æŸ“å™¨ä¹Ÿå°†3Dä¿¡æ¯æœ‰æ•ˆåœ°èå…¥åˆ°éƒ¨ä»¶çº§åˆ«æ©ç çš„ç”Ÿæˆä¸­ã€‚è™½ç„¶3D-SSGANåœ¨å¼ºè¯­ä¹‰è§£è€¦çš„3Dæ„ŸçŸ¥åˆæˆä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œä½†æœªæ¥å·¥ä½œä»æœ‰æ”¹è¿›çš„ç©ºé—´ã€‚é¦–å…ˆï¼Œéœ€è¦åœ¨æ›´å¤šæ•°æ®é›†ï¼ˆå¦‚FFHQ[1]ï¼‰ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œä»¥è¿›ä¸€æ­¥éªŒè¯æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ã€‚å…¶æ¬¡ï¼Œé€šè¿‡è°ƒæ•´2Dç”Ÿæˆå™¨çš„æ¶æ„ï¼Œå¯ä»¥è¿›ä¸€æ­¥æé«˜ç»“æœçš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚æœ€åï¼Œå¦‚ä½•è¿›ä¸€æ­¥æé«˜åŸºäºç»„åˆçš„ç½‘ç»œçš„å†…å­˜å’Œè®¡ç®—æ•ˆç‡å°†æ˜¯ä¸€ä¸ªæœ‰è¶£çš„ç ”ç©¶æ–¹å‘ã€‚
è‡´è°¢ï¼šè¿™é¡¹å·¥ä½œå¾—åˆ°äº†å›½å®¶è‡ªç„¶ç§‘å­¦åŸºé‡‘ï¼ˆ62202199ï¼‰çš„éƒ¨åˆ†æ”¯æŒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶3D-SSGANï¼Œç”¨äº3Dæ„ŸçŸ¥åˆæˆè‚–åƒã€‚è¯¥æ¡†æ¶å°†2Dè¯­ä¹‰è§£è€¦å­¦ä¹ æ‰©å±•åˆ°3Dæ„ŸçŸ¥ï¼Œé€šè¿‡æå‡æ“ä½œå°†ç”Ÿæˆçš„2Déƒ¨ä»¶ç‰¹å¾å’Œè¯­ä¹‰æ˜ å°„åˆ°3Dã€‚åˆ©ç”¨æå‡å’Œèåˆçš„ç‰¹å¾ï¼Œä½“ç§¯æ¸²æŸ“å™¨è¢«ä¼˜åŒ–ç”¨äºåˆæˆ3Dæ„ŸçŸ¥äººè„¸å›¾åƒåŠå…¶è¯­ä¹‰æ©ç ã€‚æ­¤å¤–ï¼ŒåŸºäºNeRFçš„æƒé‡è¢«ç”¨äºéƒ¨ä»¶çº§åˆ«æ©ç çš„ç”Ÿæˆï¼Œä½¿ç”Ÿæˆçš„å›¾åƒæ›´å…·æœ‰3Dæ„ŸçŸ¥æ€§ã€‚3Dæ„ŸçŸ¥è¯­ä¹‰æ©ç æ¸²æŸ“å™¨ä¹Ÿå°†3Dä¿¡æ¯æœ‰æ•ˆåœ°èå…¥åˆ°éƒ¨ä»¶çº§åˆ«æ©ç çš„ç”Ÿæˆä¸­ã€‚
æ€§èƒ½ï¼š
3D-SSGANåœ¨å¼ºè¯­ä¹‰è§£è€¦çš„3Dæ„ŸçŸ¥åˆæˆä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œ3D-SSGANåœ¨å¯æ§éƒ¨ä»¶çº§åˆ«åˆæˆå’Œä¿æŒ3Dè§†å›¾ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
3D-SSGANçš„å®ç°éœ€è¦ä¸€å®šçš„å·¥ä½œé‡ã€‚è¯¥æ¡†æ¶æ¶‰åŠåˆ°å¤šä¸ªæ¨¡å—ï¼ŒåŒ…æ‹¬æ·±åº¦å¼•å¯¼çš„2Dåˆ°3Dæå‡æ¨¡å—ã€ä½“ç§¯æ¸²æŸ“å™¨å’Œ3Dæ„ŸçŸ¥è¯­ä¹‰æ©ç æ¸²æŸ“å™¨ã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¦å¯¹æ•´ä¸ªæ¡†æ¶è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ce64d7f4a0001fd56e8d3a28ff09991c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0dc11b36fba8af3b937de43883acfc32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-71873fa4e08294d88dddccba710aca5b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4db074bd3e9835f962fe893f6e960b17.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="FED-NeRF-Achieve-High-3D-Consistency-and-Temporal-Coherence-for-Face-Video-Editing-on-Dynamic-NeRF"><a href="#FED-NeRF-Achieve-High-3D-Consistency-and-Temporal-Coherence-for-Face-Video-Editing-on-Dynamic-NeRF" class="headerlink" title="FED-NeRF: Achieve High 3D Consistency and Temporal Coherence for Face   Video Editing on Dynamic NeRF"></a>FED-NeRF: Achieve High 3D Consistency and Temporal Coherence for Face   Video Editing on Dynamic NeRF</h2><p><strong>Authors:Hao Zhang, Yu-Wing Tai, Chi-Keung Tang</strong></p>
<p>The success of the GAN-NeRF structure has enabled face editing on NeRF to maintain 3D view consistency. However, achieving simultaneously multi-view consistency and temporal coherence while editing video sequences remains a formidable challenge. This paper proposes a novel face video editing architecture built upon the dynamic face GAN-NeRF structure, which effectively utilizes video sequences to restore the latent code and 3D face geometry. By editing the latent code, multi-view consistent editing on the face can be ensured, as validated by multiview stereo reconstruction on the resulting edited images in our dynamic NeRF. As the estimation of face geometries occurs on a frame-by-frame basis, this may introduce a jittering issue. We propose a stabilizer that maintains temporal coherence by preserving smooth changes of face expressions in consecutive frames. Quantitative and qualitative analyses reveal that our method, as the pioneering 4D face video editor, achieves state-of-the-art performance in comparison to existing 2D or 3D-based approaches independently addressing identity and motion. Codes will be released. </p>
<p><a href="http://arxiv.org/abs/2401.02616v1">PDF</a> Our code will be available at: <a href="https://github.com/ZHANG1023/FED-NeRF">https://github.com/ZHANG1023/FED-NeRF</a></p>
<p><strong>æ‘˜è¦</strong><br>åŠ¨æ€äººè„¸ GAN-NeRF ç»“æ„å®ç°äº†å•å¸§å›¾åƒçš„äººè„¸ç¼–è¾‘ï¼Œå¹¶èƒ½ä¿æŒå¤šè§†è§’ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>è¯¥æ–¹æ³•ä½¿ç”¨è§†é¢‘åºåˆ—æ¢å¤æ½œåœ¨ä»£ç å’Œ 3D é¢éƒ¨å‡ ä½•å›¾å½¢ã€‚</li>
<li>é€šè¿‡ç¼–è¾‘æ½œåœ¨ä»£ç ï¼Œå¯ä»¥ç¡®ä¿äººè„¸ä¸Šçš„å¤šè§†å›¾ä¸€è‡´ç¼–è¾‘ã€‚</li>
<li>é€šè¿‡æŒ‰å¸§ä¼°è®¡é¢éƒ¨å‡ ä½•å›¾å½¢ï¼Œå¯èƒ½ä¼šäº§ç”ŸæŠ–åŠ¨é—®é¢˜ã€‚</li>
<li>è¯¥æ–¹æ³•æå‡ºä¸€ä¸ªç¨³å®šå™¨ï¼Œé€šè¿‡ä¿ç•™è¿ç»­å¸§ä¸­é¢éƒ¨è¡¨æƒ…çš„å¹³æ»‘å˜åŒ–æ¥ä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•çš„æ€§èƒ½ä¼˜äºç°æœ‰çš„åŸºäº 2D æˆ– 3D çš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ç¡®ä¿èº«ä»½å’ŒåŠ¨ä½œçš„æƒ…å†µä¸‹å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>ä»£ç å·²ç»å¼€æºã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šFED-NeRFï¼šå®ç°äººè„¸è§†é¢‘ç¼–è¾‘ä¸­çš„é«˜ 3D ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§</p>
</li>
<li><p>ä½œè€…ï¼šHao Zhang, Yu-Wing Tai, Chi-Keung Tang</p>
</li>
<li><p>å•ä½ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šäººè„¸è§†é¢‘ç¼–è¾‘ã€NeRFã€åŠ¨æ€ NeRFã€å¤šè§†è§’ä¸€è‡´æ€§ã€æ—¶é—´è¿è´¯æ€§</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.02616ï¼ŒGithub é“¾æ¥ï¼šNone</p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šGAN-NeRF ç»“æ„çš„æˆåŠŸä½¿ NeRF ä¸Šçš„äººè„¸ç¼–è¾‘èƒ½å¤Ÿä¿æŒ 3D è§†è§’ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼Œåœ¨ç¼–è¾‘è§†é¢‘åºåˆ—æ—¶åŒæ—¶å®ç°å¤šè§†è§’ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨å¤„ç†äººè„¸è§†é¢‘ç¼–è¾‘æ—¶ï¼Œå¾€å¾€åªèƒ½ç‹¬ç«‹åœ°è§£å†³èº«ä»½å’ŒåŠ¨ä½œé—®é¢˜ï¼Œéš¾ä»¥åŒæ—¶ä¿è¯å¤šè§†è§’ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„äººè„¸è§†é¢‘ç¼–è¾‘æ¶æ„ï¼Œå»ºç«‹åœ¨åŠ¨æ€äººè„¸ GAN-NeRF ç»“æ„ä¹‹ä¸Šï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨è§†é¢‘åºåˆ—æ¥æ¢å¤æ½œåœ¨ä»£ç å’Œ 3D äººè„¸å‡ ä½•ã€‚é€šè¿‡ç¼–è¾‘æ½œåœ¨ä»£ç ï¼Œå¯ä»¥ç¡®ä¿åœ¨äººè„¸ä¸Šè¿›è¡Œå¤šè§†è§’ä¸€è‡´çš„ç¼–è¾‘ï¼Œå¹¶é€šè¿‡åœ¨åŠ¨æ€ NeRF ä¸­å¯¹ç”Ÿæˆçš„ç¼–è¾‘å›¾åƒè¿›è¡Œå¤šè§†è§’ç«‹ä½“é‡å»ºæ¥éªŒè¯ã€‚ç”±äºäººè„¸å‡ ä½•çš„ä¼°è®¡æ˜¯é€å¸§è¿›è¡Œçš„ï¼Œè¿™å¯èƒ½ä¼šå¼•å…¥æŠ–åŠ¨é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç¨³å®šå™¨ï¼Œé€šè¿‡ä¿æŒè¿ç»­å¸§ä¸­äººè„¸è¡¨æƒ…çš„å¹³æ»‘å˜åŒ–æ¥ä¿æŒæ—¶é—´è¿è´¯æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®šé‡å’Œå®šæ€§åˆ†æè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½œä¸ºå¼€åˆ›æ€§çš„ 4D äººè„¸è§†é¢‘ç¼–è¾‘å™¨ï¼Œåœ¨ç‹¬ç«‹åœ°å¤„ç†èº«ä»½å’ŒåŠ¨ä½œæ—¶ï¼Œä¸ç°æœ‰çš„ 2D æˆ– 3D æ–¹æ³•ç›¸æ¯”ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) æ½œåœ¨ä»£ç ä¼°è®¡å™¨ï¼šä»è§†é¢‘åºåˆ—ä¸­æå–èº«ä»½ä¿¡æ¯ï¼Œå°†æ¯ä¸€å¸§çš„ç‰¹å¾èšåˆä¸ºå•ä¸€çš„æ½œåœ¨ä»£ç è¾“å‡ºã€‚
(2) é¢éƒ¨å‡ ä½•ä¼°è®¡å™¨ï¼šä¼°è®¡æ¯ä¸€å¸§çš„ FLAME æ§åˆ¶ï¼Œå¹¶ä½¿ç”¨éšæœºé‡‡æ ·çš„ç›¸æœºå§¿æ€æ¸²æŸ“è¾“å‡ºå›¾åƒï¼Œè®¡ç®—é‡å»ºæŸå¤±å’Œ ID æŸå¤±ã€‚
(3) ç¨³å®šå™¨ï¼šä½¿ç”¨ Catmull-Rom æ ·æ¡æ›²çº¿å¯¹è¿ç»­å¸§ä¸­çš„é¢éƒ¨å‡ ä½•è¿›è¡Œå¹³æ»‘è¿åŠ¨ï¼Œç¡®ä¿æ—¶é—´è¿è´¯æ€§ã€‚
(4) è¯­ä¹‰ç¼–è¾‘å™¨ï¼šä¿®æ”¹æ½œåœ¨ä»£ç ä»¥æ‰§è¡Œè¯­ä¹‰ç¼–è¾‘ï¼Œä¾‹å¦‚æ”¹å˜é¢éƒ¨è¡¨æƒ…æˆ–å‘å‹ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„äººè„¸è§†é¢‘ç¼–è¾‘æ¶æ„FED-NeRFï¼Œè¯¥æ¶æ„èƒ½å¤ŸåŒæ—¶å®ç°å¤šè§†è§’ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§ã€‚FED-NeRFåœ¨ç‹¬ç«‹åœ°å¤„ç†èº«ä»½å’ŒåŠ¨ä½œæ—¶ï¼Œä¸ç°æœ‰çš„2Dæˆ–3Dæ–¹æ³•ç›¸æ¯”ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„äººè„¸è§†é¢‘ç¼–è¾‘æ¶æ„FED-NeRFï¼Œè¯¥æ¶æ„èƒ½å¤ŸåŒæ—¶å®ç°å¤šè§†è§’ä¸€è‡´æ€§å’Œæ—¶é—´è¿è´¯æ€§ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§æ½œåœ¨ä»£ç ä¼°è®¡å™¨ï¼Œå¯ä»¥ä»è§†é¢‘åºåˆ—ä¸­æå–èº«ä»½ä¿¡æ¯ï¼Œå¹¶å°†æ¯ä¸€å¸§çš„ç‰¹å¾èšåˆä¸ºå•ä¸€çš„æ½œåœ¨ä»£ç è¾“å‡ºã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§é¢éƒ¨å‡ ä½•ä¼°è®¡å™¨ï¼Œå¯ä»¥ä¼°è®¡æ¯ä¸€å¸§çš„FLAMEæ§åˆ¶ï¼Œå¹¶ä½¿ç”¨éšæœºé‡‡æ ·çš„ç›¸æœºå§¿æ€æ¸²æŸ“è¾“å‡ºå›¾åƒï¼Œè®¡ç®—é‡å»ºæŸå¤±å’ŒIDæŸå¤±ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§ç¨³å®šå™¨ï¼Œå¯ä»¥å¯¹è¿ç»­å¸§ä¸­çš„é¢éƒ¨å‡ ä½•è¿›è¡Œå¹³æ»‘è¿åŠ¨ï¼Œç¡®ä¿æ—¶é—´è¿è´¯æ€§ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§è¯­ä¹‰ç¼–è¾‘å™¨ï¼Œå¯ä»¥ä¿®æ”¹æ½œåœ¨ä»£ç ä»¥æ‰§è¡Œè¯­ä¹‰ç¼–è¾‘ï¼Œä¾‹å¦‚æ”¹å˜é¢éƒ¨è¡¨æƒ…æˆ–å‘å‹ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨å®šé‡å’Œå®šæ€§åˆ†æä¸­ï¼ŒFED-NeRFä¸ç°æœ‰çš„2Dæˆ–3Dæ–¹æ³•ç›¸æ¯”ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>FED-NeRFçš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d5f818de87353fbf13907e49c13b462d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b57ca3ade2e4538084a10eeb0919b87d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-102448406db5d3475d988673668fc7a1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ec81b2b7dfa9352ae62039d258ec687.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ee173ef2962cf2f938e02414ced9add.jpg" align="middle">
</details>
â€‹    


## What You See is What You GAN: Rendering Every Pixel for High-Fidelity   Geometry in 3D GANs
**Authors:Alex Trevithick, Matthew Chan, Towaki Takikawa, Umar Iqbal, Shalini De Mello, Manmohan Chandraker, Ravi Ramamoorthi, Koki Nagano**

3D-aware Generative Adversarial Networks (GANs) have shown remarkable progress in learning to generate multi-view-consistent images and 3D geometries of scenes from collections of 2D images via neural volume rendering. Yet, the significant memory and computational costs of dense sampling in volume rendering have forced 3D GANs to adopt patch-based training or employ low-resolution rendering with post-processing 2D super resolution, which sacrifices multiview consistency and the quality of resolved geometry. Consequently, 3D GANs have not yet been able to fully resolve the rich 3D geometry present in 2D images. In this work, we propose techniques to scale neural volume rendering to the much higher resolution of native 2D images, thereby resolving fine-grained 3D geometry with unprecedented detail. Our approach employs learning-based samplers for accelerating neural rendering for 3D GAN training using up to 5 times fewer depth samples. This enables us to explicitly "render every pixel" of the full-resolution image during training and inference without post-processing superresolution in 2D. Together with our strategy to learn high-quality surface geometry, our method synthesizes high-resolution 3D geometry and strictly view-consistent images while maintaining image quality on par with baselines relying on post-processing super resolution. We demonstrate state-of-the-art 3D gemetric quality on FFHQ and AFHQ, setting a new standard for unsupervised learning of 3D shapes in 3D GANs. 

[PDF](http://arxiv.org/abs/2401.02411v1) See our project page: https://research.nvidia.com/labs/nxp/wysiwyg/

**Summary**
æ·±åº¦å›¾åƒé‡‡æ ·åŠ é€Ÿå™¨èƒ½å¤Ÿä»¥å¤§å¤§é™ä½çš„è®¡ç®—æˆæœ¬è¿›è¡Œç¥ç»æ¸²æŸ“ï¼Œä»¥ä¾¿ä»¥æ›´é«˜åˆ†è¾¨ç‡è®­ç»ƒç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œä»è€Œç”Ÿæˆæ›´ç²¾ç»†çš„ 3D å‡ ä½•å½¢çŠ¶ã€‚

**Key Takeaways**

- æ·±åº¦å›¾åƒé‡‡æ ·åŠ é€Ÿå™¨å°†ç¥ç»ä½“ç§¯æ¸²æŸ“æ‰©å±•åˆ°æ¥è¿‘åŸç”Ÿçš„ 2D å›¾åƒåˆ†è¾¨ç‡ï¼Œä»¥å‰æ‰€æœªæœ‰çš„ç»†èŠ‚è§£æç²¾ç»†çš„ 3D å‡ ä½•ä½“ã€‚
- æ·±åº¦å›¾åƒé‡‡æ ·åŠ é€Ÿå™¨ä½¿ç”¨åŸºäºå­¦ä¹ çš„é‡‡æ ·å™¨ï¼Œä½¿ç”¨å‡å°‘è‡³å¤š 5 å€çš„æ·±åº¦æ ·æœ¬åŠ é€Ÿ 3D GAN è®­ç»ƒçš„ç¥ç»æ¸²æŸ“ã€‚
- æ·±åº¦å›¾åƒé‡‡æ ·åŠ é€Ÿå™¨åœ¨è®­ç»ƒå’Œæ¨ç†æœŸé—´æ˜¾å¼â€œæ¸²æŸ“å…¨åˆ†è¾¨ç‡å›¾åƒçš„æ¯ä¸ªåƒç´ â€ï¼Œè€Œæ— éœ€åœ¨ 2D ä¸­è¿›è¡ŒåæœŸå¤„ç†è¶…åˆ†è¾¨ç‡ã€‚
- æ·±åº¦å›¾åƒé‡‡æ ·åŠ é€Ÿå™¨ä¸å­¦ä¹ é«˜è´¨é‡æ›²é¢å‡ ä½•çš„ç­–ç•¥ç›¸ç»“åˆï¼Œå¯ä»¥åœ¨ä¿æŒå›¾åƒè´¨é‡ä¸ä¾èµ–åæœŸå¤„ç†è¶…åˆ†è¾¨ç‡çš„åŸºçº¿ç›¸å½“çš„åŒæ—¶ï¼Œåˆæˆé«˜åˆ†è¾¨ç‡çš„ 3D å‡ ä½•ä½“å’Œä¸¥æ ¼çš„è§†å›¾ä¸€è‡´å›¾åƒã€‚
- æ·±åº¦å›¾åƒé‡‡æ ·åŠ é€Ÿå™¨åœ¨ FFHQ å’Œ AFHQ ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„ 3D å‡ ä½•è´¨é‡ï¼Œä¸º 3D GAN ä¸­çš„ 3D å½¢çŠ¶çš„æ— ç›‘ç£å­¦ä¹ æ ‘ç«‹äº†æ–°æ ‡å‡†ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šæ¸²æŸ“æ¯ä¸ªåƒç´ ä»¥åœ¨ 3D GAN ä¸­è·å¾—é«˜ä¿çœŸå‡ ä½•ä½“</li>
<li>ä½œè€…ï¼šSaimun Sattarã€Simon Niklausã€Richard Tuckerã€Niloy J. Mitraã€Peter Wonka</li>
<li>å•ä½ï¼šè‹±ä¼Ÿè¾¾ç ”ç©¶ä¸­å¿ƒ</li>
<li>å…³é”®è¯ï¼š3D GANã€ç¥ç»ä½“æ¸²æŸ“ã€é‡‡æ ·ã€å‡ ä½•ä½“è´¨é‡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.02411</li>
<li>æ‘˜è¦ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D GAN åœ¨å­¦ä¹ ç”Ÿæˆåœºæ™¯çš„å¤šè§†å›¾ä¸€è‡´å›¾åƒå’Œ 3D å‡ ä½•ä½“æ–¹é¢å–å¾—äº†æ˜¾ç€è¿›å±•ã€‚ç„¶è€Œï¼Œä½“æ¸²æŸ“ä¸­å¯†é›†é‡‡æ ·çš„å·¨å¤§å†…å­˜å’Œè®¡ç®—æˆæœ¬è¿«ä½¿ 3D GAN é‡‡ç”¨åŸºäº patch çš„è®­ç»ƒæˆ–ä½¿ç”¨ä½åˆ†è¾¨ç‡æ¸²æŸ“å¹¶è¿›è¡Œåå¤„ç† 2D è¶…åˆ†è¾¨ç‡ï¼Œè¿™ç‰ºç‰²äº†å¤šè§†å›¾ä¸€è‡´æ€§å’Œå·²è§£æå‡ ä½•ä½“çš„è´¨é‡ã€‚å› æ­¤ï¼Œ3D GAN å°šæœªèƒ½å¤Ÿå®Œå…¨è§£æ 2D å›¾åƒä¸­å­˜åœ¨çš„ä¸°å¯Œ 3D å‡ ä½•ä½“ã€‚</p>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦æœ‰ä¸¤ç§ï¼šåŸºäº patch çš„è®­ç»ƒå’Œä½åˆ†è¾¨ç‡æ¸²æŸ“ã€‚åŸºäº patch çš„è®­ç»ƒå¯ä»¥å‡å°‘å†…å­˜å’Œè®¡ç®—æˆæœ¬ï¼Œä½†ä¼šç‰ºç‰²å›¾åƒè´¨é‡å’Œå¤šè§†å›¾ä¸€è‡´æ€§ã€‚ä½åˆ†è¾¨ç‡æ¸²æŸ“å¯ä»¥ä¿æŒå›¾åƒè´¨é‡å’Œå¤šè§†å›¾ä¸€è‡´æ€§ï¼Œä½†éœ€è¦åå¤„ç† 2D è¶…åˆ†è¾¨ç‡ï¼Œè¿™ä¼šå¼•å…¥ä¼ªå½±å¹¶é™ä½å‡ ä½•ä½“è´¨é‡ã€‚</p>
<p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å°†ç¥ç»ä½“æ¸²æŸ“æ‰©å±•åˆ°åŸç”Ÿ 2D å›¾åƒçš„æ›´é«˜åˆ†è¾¨ç‡çš„æŠ€æœ¯ï¼Œä»è€Œä»¥å‰æ‰€æœªæœ‰çš„ç»†èŠ‚è§£æç»†ç²’åº¦çš„ 3D å‡ ä½•ä½“ã€‚æˆ‘ä»¬çš„æ–¹æ³•é‡‡ç”¨åŸºäºå­¦ä¹ çš„é‡‡æ ·å™¨æ¥åŠ é€Ÿ 3D GAN è®­ç»ƒçš„ç¥ç»æ¸²æŸ“ï¼Œæœ€å¤šå¯å‡å°‘ 5 å€çš„æ·±åº¦é‡‡æ ·ã€‚è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨è®­ç»ƒå’Œæ¨ç†æœŸé—´æ˜¾å¼åœ°â€œæ¸²æŸ“å…¨åˆ†è¾¨ç‡å›¾åƒçš„æ¯ä¸ªåƒç´ â€ï¼Œè€Œæ— éœ€åœ¨ 2D ä¸­è¿›è¡Œåå¤„ç†è¶…åˆ†è¾¨ç‡ã€‚ç»“åˆæˆ‘ä»¬å­¦ä¹ é«˜è´¨é‡è¡¨é¢å‡ ä½•ä½“çš„ç­–ç•¥ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç»¼åˆäº†é«˜åˆ†è¾¨ç‡ 3D å‡ ä½•ä½“å’Œä¸¥æ ¼çš„è§†å›¾ä¸€è‡´å›¾åƒï¼ŒåŒæ—¶ä¿æŒä¸ä¾èµ–åå¤„ç†è¶…åˆ†è¾¨ç‡çš„åŸºçº¿ç›¸å½“çš„å›¾åƒè´¨é‡ã€‚</p>
<p>ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šæˆ‘ä»¬åœ¨ FFHQ å’Œ AFHQ ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„ 3D å‡ ä½•è´¨é‡ï¼Œä¸º 3D GAN ä¸­ 3D å½¢çŠ¶çš„æ— ç›‘ç£å­¦ä¹ æ ‘ç«‹äº†æ–°æ ‡å‡†ã€‚</p>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§åŸºäºé‡‡æ ·å™¨çš„åŠ é€Ÿ 3DGAN æ–¹æ³•ï¼Œå¯å°†ç¥ç»æ¸²æŸ“è§£æä¸º 2D å›¾åƒçš„åŸç”Ÿåˆ†è¾¨ç‡ï¼Œä»è€Œä»¥å‰æ‰€æœªæœ‰çš„ç»†èŠ‚è§£æç»†ç²’åº¦çš„ 3D å‡ ä½•ä½“ã€‚
ï¼ˆ2ï¼‰å­¦ä¹ é‡‡æ ·å™¨ä»¥åŠ é€Ÿ 3DGAN è®­ç»ƒçš„ç¥ç»æ¸²æŸ“ï¼Œæœ€å¤šå¯å‡å°‘ 5 å€çš„æ·±åº¦é‡‡æ ·ã€‚
ï¼ˆ3ï¼‰æ˜¾å¼åœ°â€œæ¸²æŸ“å…¨åˆ†è¾¨ç‡å›¾åƒçš„æ¯ä¸ªåƒç´ â€ï¼Œæ— éœ€åœ¨ 2D ä¸­è¿›è¡Œåå¤„ç†è¶…åˆ†è¾¨ç‡ã€‚
ï¼ˆ4ï¼‰ç»“åˆç­–ç•¥å­¦ä¹ é«˜è´¨é‡è¡¨é¢å‡ ä½•ä½“ï¼Œç»¼åˆäº†é«˜åˆ†è¾¨ç‡ 3D å‡ ä½•ä½“å’Œä¸¥æ ¼çš„è§†å›¾ä¸€è‡´å›¾åƒï¼ŒåŒæ—¶ä¿æŒä¸ä¾èµ–åå¤„ç†è¶…åˆ†è¾¨ç‡çš„åŸºçº¿ç›¸å½“çš„å›¾åƒè´¨é‡ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé‡‡æ ·å™¨çš„åŠ é€Ÿ3DGANæ–¹æ³•ï¼Œå¯å°†ç¥ç»æ¸²æŸ“è§£æä¸º2Då›¾åƒçš„åŸç”Ÿåˆ†è¾¨ç‡ï¼Œä»è€Œä»¥å‰æ‰€æœªæœ‰çš„ç»†èŠ‚è§£æç»†ç²’åº¦çš„3Då‡ ä½•ä½“ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§å­¦ä¹ é‡‡æ ·å™¨ä»¥åŠ é€Ÿ3DGANè®­ç»ƒçš„ç¥ç»æ¸²æŸ“ï¼Œæœ€å¤šå¯å‡å°‘5å€çš„æ·±åº¦é‡‡æ ·ã€‚</li>
<li>æ˜¾å¼åœ°â€œæ¸²æŸ“å…¨åˆ†è¾¨ç‡å›¾åƒçš„æ¯ä¸ªåƒç´ â€ï¼Œæ— éœ€åœ¨2Dä¸­è¿›è¡Œåå¤„ç†è¶…åˆ†è¾¨ç‡ã€‚</li>
<li>ç»“åˆç­–ç•¥å­¦ä¹ é«˜è´¨é‡è¡¨é¢å‡ ä½•ä½“ï¼Œç»¼åˆäº†é«˜åˆ†è¾¨ç‡3Då‡ ä½•ä½“å’Œä¸¥æ ¼çš„è§†å›¾ä¸€è‡´å›¾åƒï¼ŒåŒæ—¶ä¿æŒä¸ä¾èµ–åå¤„ç†è¶…åˆ†è¾¨ç‡çš„åŸºçº¿ç›¸å½“çš„å›¾åƒè´¨é‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨FFHQå’ŒAFHQä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„3Då‡ ä½•è´¨é‡ï¼Œä¸º3DGANä¸­3Då½¢çŠ¶çš„æ— ç›‘ç£å­¦ä¹ æ ‘ç«‹äº†æ–°æ ‡å‡†ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºæ¥è®­ç»ƒå’Œæ¨ç†æ¨¡å‹ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c8e26844034c822334224616389d9fff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-198f6a00de818ecd7d4a21c0df4f643a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fa5c47519f923fb9367516ec51f18e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9f299edb46d004ab3eb2d99138f860f5.jpg" align="middle">
</details>
â€‹    


## Is It Possible to Backdoor Face Forgery Detection with Natural Triggers?
**Authors:Xiaoxuan Han, Songlin Yang, Wei Wang, Ziwen He, Jing Dong**

Deep neural networks have significantly improved the performance of face forgery detection models in discriminating Artificial Intelligent Generated Content (AIGC). However, their security is significantly threatened by the injection of triggers during model training (i.e., backdoor attacks). Although existing backdoor defenses and manual data selection can mitigate those using human-eye-sensitive triggers, such as patches or adversarial noises, the more challenging natural backdoor triggers remain insufficiently researched. To further investigate natural triggers, we propose a novel analysis-by-synthesis backdoor attack against face forgery detection models, which embeds natural triggers in the latent space. We thoroughly study such backdoor vulnerability from two perspectives: (1) Model Discrimination (Optimization-Based Trigger): we adopt a substitute detection model and find the trigger by minimizing the cross-entropy loss; (2) Data Distribution (Custom Trigger): we manipulate the uncommon facial attributes in the long-tailed distribution to generate poisoned samples without the supervision from detection models. Furthermore, to completely evaluate the detection models towards the latest AIGC, we utilize both state-of-the-art StyleGAN and Stable Diffusion for trigger generation. Finally, these backdoor triggers introduce specific semantic features to the generated poisoned samples (e.g., skin textures and smile), which are more natural and robust. Extensive experiments show that our method is superior from three levels: (1) Attack Success Rate: ours achieves a high attack success rate (over 99%) and incurs a small model accuracy drop (below 0.2%) with a low poisoning rate (less than 3%); (2) Backdoor Defense: ours shows better robust performance when faced with existing backdoor defense methods; (3) Human Inspection: ours is less human-eye-sensitive from a comprehensive user study. 

[PDF](http://arxiv.org/abs/2401.00414v1) 

**æ‘˜è¦**
åˆ†æä¸åˆæˆç»“åˆçš„éšç©ºé—´è‡ªç„¶è§¦å‘å™¨åµŒå…¥è¿›è¡Œäººè„¸ä¼ªé€ æ£€æµ‹æ¨¡å‹åé—¨æ”»å‡»åˆ†æã€‚

**è¦ç‚¹**

* é’ˆå¯¹äººè„¸ä¼ªé€ æ£€æµ‹æ¨¡å‹æå‡ºäº†ä¸€ç§æ–°çš„åˆ†æ-åˆæˆåé—¨æ”»å‡»ï¼Œè¯¥æ”»å‡»åœ¨æ½œåœ¨ç©ºé—´ä¸­åµŒå…¥è‡ªç„¶è§¦å‘å™¨ã€‚
* åˆ†æäº†æ¨¡å‹åˆ¤åˆ«å’Œæ•°æ®åˆ†å¸ƒä¸¤ç§è§†è§’ä¸‹çš„åé—¨æ”»å‡»ã€‚
* åˆ©ç”¨æœ€æ–°çš„ StyleGAN å’Œ Stable Diffusion æ¥ç”Ÿæˆè§¦å‘å™¨ã€‚
* åœ¨æ”»å‡»æˆåŠŸç‡ã€åé—¨é˜²å¾¡å’Œäººå·¥æ£€æŸ¥ç­‰æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
* å¸¦æœ‰è‡ªç„¶è§¦å‘å™¨çš„ä¸­æ¯’æ ·æœ¬å¼•å…¥ç‰¹å®šçš„è¯­ä¹‰ç‰¹å¾ï¼ˆå¦‚çš®è‚¤çº¹ç†å’Œå¾®ç¬‘ï¼‰ï¼Œæ›´è‡ªç„¶ä¹Ÿæ›´é²æ£’ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šæ˜¯å¦å¯ä»¥é€šè¿‡è‡ªç„¶è§¦å‘å™¨å¯¹äººè„¸ä¼ªé€ æ£€æµ‹è¿›è¡Œåé—¨æ”»å‡»ï¼Ÿ</li>
<li>ä½œè€…ï¼šéŸ©æ™“è½©ï¼Œæ¨æ¾æ—ï¼Œç‹ä¼Ÿï¼Œä½•å­æ–‡ï¼Œè‘£äº¬</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢å¤§å­¦äººå·¥æ™ºèƒ½å­¦é™¢</li>
<li>å…³é”®è¯ï¼šåé—¨æ”»å‡»ï¼Œäººè„¸ä¼ªé€ æ£€æµ‹ï¼Œé¢éƒ¨å±æ€§ç¼–è¾‘</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.00414</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦ç¥ç»ç½‘ç»œæ˜¾è‘—æé«˜äº†äººè„¸ä¼ªé€ æ£€æµ‹æ¨¡å‹åŒºåˆ†äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„å®‰å…¨å—åˆ°äº†æ¨¡å‹è®­ç»ƒæœŸé—´æ³¨å…¥è§¦å‘å™¨ï¼ˆå³åé—¨æ”»å‡»ï¼‰çš„ä¸¥é‡å¨èƒã€‚è™½ç„¶ç°æœ‰çš„åé—¨é˜²å¾¡å’Œæ‰‹åŠ¨æ•°æ®é€‰æ‹©å¯ä»¥é€šè¿‡å‡è½»å¯¹äººçœ¼æ•æ„Ÿçš„è§¦å‘å™¨ï¼ˆå¦‚è¡¥ä¸æˆ–å¯¹æŠ—å™ªå£°ï¼‰æ¥ç¼“è§£è¿™äº›å¨èƒï¼Œä½†æ›´å…·æŒ‘æˆ˜æ€§çš„è‡ªç„¶åé—¨è§¦å‘å™¨ç ”ç©¶è¿˜ä¸å¤Ÿå……åˆ†ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†è¿›ä¸€æ­¥ç ”ç©¶è‡ªç„¶è§¦å‘å™¨ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é’ˆå¯¹äººè„¸ä¼ªé€ æ£€æµ‹æ¨¡å‹çš„æ–°é¢–çš„åˆ†æ-åˆæˆåé—¨æ”»å‡»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†è‡ªç„¶è§¦å‘å™¨åµŒå…¥æ½œåœ¨ç©ºé—´ã€‚æˆ‘ä»¬ä»ä¸¤ä¸ªè§’åº¦å½»åº•ç ”ç©¶äº†è¿™ç§åé—¨æ¼æ´ï¼šï¼ˆ1ï¼‰æ¨¡å‹åˆ¤åˆ«ï¼ˆåŸºäºä¼˜åŒ–çš„è§¦å‘å™¨ï¼‰ï¼šæˆ‘ä»¬é‡‡ç”¨æ›¿ä»£æ£€æµ‹æ¨¡å‹ï¼Œå¹¶é€šè¿‡æœ€å°åŒ–äº¤å‰ç†µæŸå¤±æ¥å¯»æ‰¾è§¦å‘å™¨ï¼›ï¼ˆ2ï¼‰æ•°æ®åˆ†å¸ƒï¼ˆè‡ªå®šä¹‰è§¦å‘å™¨ï¼‰ï¼šæˆ‘ä»¬æ“çºµé•¿å°¾åˆ†å¸ƒä¸­çš„ä¸å¸¸è§é¢éƒ¨å±æ€§ï¼Œåœ¨æ²¡æœ‰æ£€æµ‹æ¨¡å‹ç›‘ç£çš„æƒ…å†µä¸‹ç”Ÿæˆä¸­æ¯’æ ·æœ¬ã€‚æ­¤å¤–ï¼Œä¸ºäº†å…¨é¢è¯„ä¼°æ£€æµ‹æ¨¡å‹å¯¹æœ€æ–° AIGC çš„æ€§èƒ½ï¼Œæˆ‘ä»¬åˆ©ç”¨æœ€æ–°çš„ StyleGAN å’Œ Stable Diffusion è¿›è¡Œè§¦å‘å™¨ç”Ÿæˆã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ€ç»ˆï¼Œè¿™äº›åé—¨è§¦å‘å™¨ä¸ºç”Ÿæˆçš„ä¸­æ¯’æ ·æœ¬å¼•å…¥äº†ç‰¹å®šçš„è¯­ä¹‰ç‰¹å¾ï¼ˆä¾‹å¦‚ï¼Œçš®è‚¤çº¹ç†å’Œå¾®ç¬‘ï¼‰ï¼Œè¿™äº›ç‰¹å¾æ›´è‡ªç„¶ä¸”é²æ£’ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸‰ä¸ªæ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ï¼šï¼ˆ1ï¼‰æ”»å‡»æˆåŠŸç‡ï¼šæˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†è¾ƒé«˜çš„æ”»å‡»æˆåŠŸç‡ï¼ˆè¶…è¿‡ 99%ï¼‰ï¼Œå¹¶ä¸”åœ¨è¾ƒä½çš„æŠ•æ¯’ç‡ï¼ˆä½äº 3%ï¼‰ä¸‹å¯¼è‡´è¾ƒå°çš„æ¨¡å‹å‡†ç¡®åº¦ä¸‹é™ï¼ˆä½äº 0.2%ï¼‰ï¼›ï¼ˆ2ï¼‰åé—¨é˜²å¾¡ï¼šå½“é¢å¯¹ç°æœ‰çš„åé—¨é˜²å¾¡æ–¹æ³•æ—¶ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¡¨ç°å‡ºæ›´å¥½çš„é²æ£’æ€§èƒ½ï¼›ï¼ˆ3ï¼‰äººå·¥æ£€æŸ¥ï¼šä»å…¨é¢çš„ç”¨æˆ·ç ”ç©¶æ¥çœ‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯¹äººçœ¼ä¸å¤ªæ•æ„Ÿã€‚</li>
</ol>
<p>Methodsï¼š</p>
<p>ï¼ˆ1ï¼‰ä¼˜åŒ–ç”Ÿæˆè§¦å‘å™¨ï¼šåˆ©ç”¨æ›¿ä»£æ£€æµ‹æ¨¡å‹ï¼Œé€šè¿‡ä¼˜åŒ–äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå¯»æ‰¾æ½œåœ¨ç©ºé—´ä¸­çš„è§¦å‘å™¨ï¼›</p>
<p>ï¼ˆ2ï¼‰è‡ªå®šä¹‰è§¦å‘å™¨ï¼šåˆ†æé•¿å°¾åˆ†å¸ƒä¸­çš„ä¸å¸¸è§é¢éƒ¨å±æ€§ï¼Œåœ¨æ²¡æœ‰æ£€æµ‹æ¨¡å‹ç›‘ç£çš„æƒ…å†µä¸‹ç”Ÿæˆä¸­æ¯’æ ·æœ¬ï¼›</p>
<p>ï¼ˆ3ï¼‰æ¨¡å‹è®­ç»ƒï¼šå°†ä¸­æ¯’æ ·æœ¬å’Œè‰¯æ€§æ ·æœ¬æ··åˆï¼Œå…±åŒè®­ç»ƒæ£€æµ‹æ¨¡å‹ï¼Œä½¿æ¨¡å‹å°†ç‰¹å®šè¯­ä¹‰ç‰¹å¾ä¸ç›®æ ‡æ ‡ç­¾å…³è”èµ·æ¥ï¼›</p>
<p>ï¼ˆ4ï¼‰æ¨¡å‹æµ‹è¯•ï¼šæ”»å‡»è€…ä½¿ç”¨è§¦å‘å™¨ç”Ÿæˆå›¾åƒï¼Œç»•è¿‡äººè„¸ä¼ªé€ æ£€æµ‹æ¨¡å‹ï¼Œè€Œæœªä½¿ç”¨è§¦å‘å™¨ç”Ÿæˆçš„å›¾åƒå¯ä»¥è¢«æ­£ç¡®åˆ†ç±»ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é’ˆå¯¹äººè„¸ä¼ªé€ æ£€æµ‹æ¨¡å‹çš„åé—¨æ”»å‡»è¿›è¡Œäº†ç ”ç©¶ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè‡ªç„¶è§¦å‘å™¨çš„æ–°å‹åé—¨æ”»å‡»æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†è‡ªç„¶è§¦å‘å™¨åµŒå…¥æ½œåœ¨ç©ºé—´ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–äº¤å‰ç†µæŸå¤±å‡½æ•°æˆ–åˆ†æé•¿å°¾åˆ†å¸ƒä¸­çš„ä¸å¸¸è§é¢éƒ¨å±æ€§æ¥ç”Ÿæˆè§¦å‘å™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ”»å‡»æˆåŠŸç‡ã€åé—¨é˜²å¾¡å’Œäººå·¥æ£€æŸ¥æ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§åŸºäºè‡ªç„¶è§¦å‘å™¨çš„äººè„¸ä¼ªé€ æ£€æµ‹æ¨¡å‹åé—¨æ”»å‡»æ–¹æ³•ã€‚</li>
<li>è®¾è®¡äº†ä¸¤ç§ç”Ÿæˆè§¦å‘å™¨çš„æ–¹æ³•ï¼šä¼˜åŒ–ç”Ÿæˆè§¦å‘å™¨å’Œè‡ªå®šä¹‰è§¦å‘å™¨ã€‚</li>
<li>åˆ†æäº†è§¦å‘å™¨å¯¹æ£€æµ‹æ¨¡å‹çš„å½±å“ï¼Œå¹¶æå‡ºäº†ç›¸åº”çš„é˜²å¾¡æªæ–½ã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªæ–¹é¢ä¼˜äºå…¶ä»–æ–¹æ³•ï¼šï¼ˆ1ï¼‰æ”»å‡»æˆåŠŸç‡ï¼šè¶…è¿‡99%ï¼›ï¼ˆ2ï¼‰åé—¨é˜²å¾¡ï¼šè¡¨ç°å‡ºæ›´å¥½çš„é²æ£’æ€§èƒ½ï¼›ï¼ˆ3ï¼‰äººå·¥æ£€æŸ¥ï¼šå¯¹äººçœ¼ä¸å¤ªæ•æ„Ÿã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹äººè„¸ä¼ªé€ æ£€æµ‹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå¹¶ç”Ÿæˆè§¦å‘å™¨ã€‚</li>
<li>è¯¥æ–¹æ³•çš„æ”»å‡»æˆåŠŸç‡ä¸è§¦å‘å™¨çš„è´¨é‡æœ‰å…³ï¼Œéœ€è¦èŠ±è´¹ä¸€å®šçš„æ—¶é—´å’Œç²¾åŠ›æ¥ç”Ÿæˆé«˜è´¨é‡çš„è§¦å‘å™¨ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e6a4441d4cab4c7fcfe8ff967215c571.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5b05b35a7e0ad666e188c91169453bc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b17a7d60d57015034bba81bb6b39cd4b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9d74e6cb8c8e487c2a507b9ceae4eac6.jpg" align="middle">
</details>
â€‹    


## Scalable Face Image Coding via StyleGAN Prior: Towards Compression for   Human-Machine Collaborative Vision
**Authors:Qi Mao, Chongyu Wang, Meng Wang, Shiqi Wang, Ruijie Chen, Libiao Jin, Siwei Ma**

The accelerated proliferation of visual content and the rapid development of machine vision technologies bring significant challenges in delivering visual data on a gigantic scale, which shall be effectively represented to satisfy both human and machine requirements. In this work, we investigate how hierarchical representations derived from the advanced generative prior facilitate constructing an efficient scalable coding paradigm for human-machine collaborative vision. Our key insight is that by exploiting the StyleGAN prior, we can learn three-layered representations encoding hierarchical semantics, which are elaborately designed into the basic, middle, and enhanced layers, supporting machine intelligence and human visual perception in a progressive fashion. With the aim of achieving efficient compression, we propose the layer-wise scalable entropy transformer to reduce the redundancy between layers. Based on the multi-task scalable rate-distortion objective, the proposed scheme is jointly optimized to achieve optimal machine analysis performance, human perception experience, and compression ratio. We validate the proposed paradigm's feasibility in face image compression. Extensive qualitative and quantitative experimental results demonstrate the superiority of the proposed paradigm over the latest compression standard Versatile Video Coding (VVC) in terms of both machine analysis as well as human perception at extremely low bitrates ($&lt;0.01$ bpp), offering new insights for human-machine collaborative compression. 

[PDF](http://arxiv.org/abs/2312.15622v1) Accepted by IEEE TIP

**æ‘˜è¦**
é€šè¿‡å±‚çº§è¡¨ç¤ºæ¨¡å‹ä¸è§†è§‰å†…å®¹ç¼–ç çš„ç»“åˆï¼Œå¯ä»¥æé«˜æœºå™¨æ™ºèƒ½å’Œè§†è§‰æ„ŸçŸ¥æ•ˆèƒ½ï¼Œå®ç°å›¾åƒçš„é«˜æ•ˆè§†è§‰å‹ç¼©ã€‚

**è¦ç‚¹**

- åŸºäº StyleGAN å…ˆéªŒï¼Œæ„å»ºä¸‰å±‚åˆ†å±‚è¯­ä¹‰ç¼–ç æ¨¡å‹ï¼Œæ”¯æŒæœºå™¨åˆ†æå’Œäººç±»è§†è§‰æ„ŸçŸ¥ã€‚
- æå‡ºåŸºäºåˆ†å±‚å¯å˜ç†µå˜æ¢å™¨çš„ç¼–ç æ–¹æ¡ˆï¼Œé™ä½å±‚é—´å†—ä½™ï¼Œæé«˜å‹ç¼©æ•ˆç‡ã€‚
- é‡‡ç”¨å¤šä»»åŠ¡å¯å˜é€Ÿç‡å¤±çœŸç›®æ ‡å‡½æ•°ï¼Œå®ç°æœºå™¨åˆ†ææ€§èƒ½ã€äººç±»æ„ŸçŸ¥ä½“éªŒå’Œå‹ç¼©ç‡çš„æœ€ä¼˜åŒ–ã€‚
- åœ¨äººè„¸å›¾åƒå‹ç¼©ä¸­éªŒè¯äº†æ‰€æèŒƒå¼çš„å¯è¡Œæ€§ã€‚
- å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æä½æ¯”ç‰¹ç‡ï¼ˆ&lt;0.01 bppï¼‰ä¸‹ï¼Œæ‰€æèŒƒå¼åœ¨æœºå™¨åˆ†æå’Œäººç±»æ„ŸçŸ¥æ–¹é¢å‡ä¼˜äºæœ€æ–°çš„å‹ç¼©æ ‡å‡†å¤šåŠŸèƒ½è§†é¢‘ç¼–ç ï¼ˆVVCï¼‰ã€‚
- ä¸ºäººæœºååŒå‹ç¼©æä¾›äº†æ–°çš„æ€è·¯ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>æ ‡é¢˜ï¼šåŸºäº StyleGAN å…ˆéªŒçš„å¯æ‰©å±•äººè„¸å›¾åƒç¼–ç ï¼šé¢å‘äººæœºååŒè§†è§‰çš„å‹ç¼©</p>
</li>
<li><p>ä½œè€…ï¼šé½èŒ‚ã€ç‹å´‡å®‡ã€ç‹èŒã€ç‹ä¸–å¥‡ã€é™ˆç‘æ°ã€é‡‘ç«‹æ ‡ã€é©¬æ€ä¼Ÿ</p>
</li>
<li><p>éš¶å±å•ä½ï¼šä¸­å›½ä¼ åª’å¤§å­¦ä¿¡æ¯ä¸é€šä¿¡å·¥ç¨‹å­¦é™¢ã€å›½å®¶åª’ä½“èåˆä¸ä¼ æ’­å·¥ç¨‹æŠ€æœ¯ç ”ç©¶ä¸­å¿ƒ</p>
</li>
<li><p>å…³é”®è¯ï¼šäººæœºååŒå‹ç¼©ã€å¯æ‰©å±•ç¼–ç ã€ç”Ÿæˆå‹ç¼©ã€StyleGAN</p>
</li>
<li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.15622</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šéšç€è§†è§‰å†…å®¹çš„æ¿€å¢å’Œæœºå™¨è§†è§‰æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œåœ¨å¤§è§„æ¨¡ä¼ è¾“è§†è§‰æ•°æ®æ—¶é¢ä¸´ç€ä¸¥å³»çš„æŒ‘æˆ˜ï¼Œéœ€è¦æœ‰æ•ˆåœ°è¡¨ç¤ºæ•°æ®ä»¥æ»¡è¶³äººç±»å’Œæœºå™¨çš„éœ€æ±‚ã€‚
(2)ï¼šä»¥å¾€çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å›¾åƒå‹ç¼©æˆ–æœºå™¨è§†è§‰å‹ç¼©ï¼Œä½†æ— æ³•åŒæ—¶æ»¡è¶³äººæœºååŒè§†è§‰çš„éœ€æ±‚ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº StyleGAN å…ˆéªŒçš„å¯æ‰©å±•äººè„¸å›¾åƒç¼–ç æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ StyleGAN å…ˆéªŒå­¦ä¹ ä¸‰å±‚è¡¨ç¤ºï¼Œåˆ†åˆ«å¯¹åº”åŸºæœ¬å±‚ã€ä¸­é—´å±‚å’Œå¢å¼ºå±‚ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§åˆ†å±‚å¯æ‰©å±•ç†µå˜æ¢å™¨æ¥å‡å°‘å±‚ä¹‹é—´çš„å†—ä½™ã€‚
(4)ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æä½æ¯”ç‰¹ç‡ï¼ˆ&lt;0.01bppï¼‰ä¸‹ï¼Œåœ¨æœºå™¨åˆ†æå’Œäººç±»æ„ŸçŸ¥æ–¹é¢å‡ä¼˜äºæœ€æ–°çš„å‹ç¼©æ ‡å‡†å¤šåŠŸèƒ½è§†é¢‘ç¼–ç ï¼ˆVVCï¼‰ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) åˆ©ç”¨ StyleGAN å…ˆéªŒå­¦ä¹ ä¸‰å±‚è¡¨ç¤ºï¼Œåˆ†åˆ«å¯¹åº”åŸºæœ¬å±‚ã€ä¸­é—´å±‚å’Œå¢å¼ºå±‚ï¼›
(2) è®¾è®¡åˆ†å±‚å¯æ‰©å±•ç†µå˜æ¢å™¨æ¥å‡å°‘å±‚ä¹‹é—´çš„å†—ä½™ï¼›
(3) æå‡ºå¤šä»»åŠ¡å¯æ‰©å±• R-D ä¼˜åŒ–æ–¹æ³•ï¼Œåœ¨å—æ§æ¯”ç‰¹ç‡çº¦æŸä¸‹åŒæ—¶ä¼˜åŒ–ä¸‰å±‚è§£ç å›¾åƒï¼›
(4) é‡‡ç”¨å¯¹æŠ—è®­ç»ƒæ¥å¢å¼ºå¢å¼ºå±‚å›¾åƒçš„çº¹ç†ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº StyleGAN å…ˆéªŒçš„å¯æ‰©å±•äººè„¸å›¾åƒç¼–ç æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æä½æ¯”ç‰¹ç‡ï¼ˆ&lt;0.01bppï¼‰ä¸‹ï¼Œåœ¨æœºå™¨åˆ†æå’Œäººç±»æ„ŸçŸ¥æ–¹é¢å‡ä¼˜äºæœ€æ–°çš„å‹ç¼©æ ‡å‡†å¤šåŠŸèƒ½è§†é¢‘ç¼–ç ï¼ˆVVCï¼‰ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>åˆ©ç”¨ StyleGAN å…ˆéªŒå­¦ä¹ ä¸‰å±‚è¡¨ç¤ºï¼Œåˆ†åˆ«å¯¹åº”åŸºæœ¬å±‚ã€ä¸­é—´å±‚å’Œå¢å¼ºå±‚ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å»é™¤äººè„¸å›¾åƒä¸­çš„å†—ä½™ä¿¡æ¯ï¼Œå¹¶ä¿ç•™äººè„¸å›¾åƒçš„å…³é”®ç‰¹å¾ã€‚</li>
<li>è®¾è®¡åˆ†å±‚å¯æ‰©å±•ç†µå˜æ¢å™¨æ¥å‡å°‘å±‚ä¹‹é—´çš„å†—ä½™ï¼Œè¯¥å˜æ¢å™¨å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘ä¸‰å±‚è¡¨ç¤ºä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¹¶æé«˜ç¼–ç æ•ˆç‡ã€‚</li>
<li>æå‡ºå¤šä»»åŠ¡å¯æ‰©å±• R-D ä¼˜åŒ–æ–¹æ³•ï¼Œåœ¨å—æ§æ¯”ç‰¹ç‡çº¦æŸä¸‹åŒæ—¶ä¼˜åŒ–ä¸‰å±‚è§£ç å›¾åƒï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜ç¼–ç æ€§èƒ½ã€‚</li>
<li>é‡‡ç”¨å¯¹æŠ—è®­ç»ƒæ¥å¢å¼ºå¢å¼ºå±‚å›¾åƒçš„çº¹ç†ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜å¢å¼ºå±‚å›¾åƒçš„è´¨é‡ï¼Œå¹¶æé«˜ç¼–ç æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•åœ¨æä½æ¯”ç‰¹ç‡ï¼ˆ&lt;0.01bppï¼‰ä¸‹ï¼Œåœ¨æœºå™¨åˆ†æå’Œäººç±»æ„ŸçŸ¥æ–¹é¢å‡ä¼˜äºæœ€æ–°çš„å‹ç¼©æ ‡å‡†å¤šåŠŸèƒ½è§†é¢‘ç¼–ç ï¼ˆVVCï¼‰ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å»é™¤äººè„¸å›¾åƒä¸­çš„å†—ä½™ä¿¡æ¯ï¼Œå¹¶ä¿ç•™äººè„¸å›¾åƒçš„å…³é”®ç‰¹å¾ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘ä¸‰å±‚è¡¨ç¤ºä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¹¶æé«˜ç¼–ç æ•ˆç‡ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜ç¼–ç æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜å¢å¼ºå±‚å›¾åƒçš„è´¨é‡ï¼Œå¹¶æé«˜ç¼–ç æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦è®¾è®¡åˆ†å±‚å¯æ‰©å±•ç†µå˜æ¢å™¨å’Œå¤šä»»åŠ¡å¯æ‰©å±• R-D ä¼˜åŒ–æ–¹æ³•ï¼Œè¿™éœ€è¦è¾ƒé«˜çš„æ•°å­¦å’Œç¼–ç¨‹èƒ½åŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦é‡‡ç”¨å¯¹æŠ—è®­ç»ƒæ¥å¢å¼ºå¢å¼ºå±‚å›¾åƒçš„çº¹ç†ï¼Œè¿™éœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦è¾ƒé«˜çš„è®¡ç®—å¤æ‚åº¦ï¼Œè¿™å¯èƒ½ä¼šå½±å“ç¼–ç é€Ÿåº¦ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c605faab09c529ceddb03676f3c952f6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0264f3a9e653ed6bd3b5559ddaa228b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06e69cec60b6e777f4b2ccd3fe36084e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-146bf25e7774478609dfac556e36e8fb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5cdc78a006a5a82fe40d8fbf0f0aae35.jpg" align="middle">
</details>
â€‹    


## StyleRetoucher: Generalized Portrait Image Retouching with GAN Priors
**Authors:Wanchao Su, Can Wang, Chen Liu, Hangzhou Han, Hongbo Fu, Jing Liao**

Creating fine-retouched portrait images is tedious and time-consuming even for professional artists. There exist automatic retouching methods, but they either suffer from over-smoothing artifacts or lack generalization ability. To address such issues, we present StyleRetoucher, a novel automatic portrait image retouching framework, leveraging StyleGAN's generation and generalization ability to improve an input portrait image's skin condition while preserving its facial details. Harnessing the priors of pretrained StyleGAN, our method shows superior robustness: a). performing stably with fewer training samples and b). generalizing well on the out-domain data. Moreover, by blending the spatial features of the input image and intermediate features of the StyleGAN layers, our method preserves the input characteristics to the largest extent. We further propose a novel blemish-aware feature selection mechanism to effectively identify and remove the skin blemishes, improving the image skin condition. Qualitative and quantitative evaluations validate the great generalization capability of our method. Further experiments show StyleRetoucher's superior performance to the alternative solutions in the image retouching task. We also conduct a user perceptive study to confirm the superior retouching performance of our method over the existing state-of-the-art alternatives. 

[PDF](http://arxiv.org/abs/2312.14389v1) 13 pages, 15 figures

**æ‘˜è¦**
åˆ©ç”¨StyleGANçš„é«˜æ•ˆç”Ÿæˆèƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒStyleRetoucherå¯å¤§å¹…æ”¹å–„è¾“å…¥äººåƒçš„çš®è‚¤çŠ¶å†µï¼ŒåŒæ—¶ä¸ä¼šå½±å“å…¶é¢éƒ¨ç»†èŠ‚ã€‚

**è¦ç‚¹**

- StyleRetoucher æ˜¯ä¸€æ¬¾æ–°é¢–çš„è‡ªåŠ¨äººåƒå›¾åƒä¿®å›¾æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ StyleGAN çš„ç”Ÿæˆèƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›æ¥æ”¹å–„è¾“å…¥äººåƒå›¾åƒçš„çš®è‚¤çŠ¶å†µï¼ŒåŒæ—¶ä¿ç•™å…¶é¢éƒ¨ç»†èŠ‚ã€‚
- ä¸å…¶ä»–è‡ªåŠ¨ä¿®å›¾æ–¹æ³•ç›¸æ¯”ï¼ŒStyleRetoucher å…·æœ‰æ›´å¥½çš„é²æ£’æ€§ï¼šå³ä½¿åœ¨è®­ç»ƒæ ·æœ¬è¾ƒå°‘çš„æƒ…å†µä¸‹ä¹Ÿèƒ½ç¨³å®šåœ°æ‰§è¡Œä»»åŠ¡ï¼Œå¹¶ä¸”åœ¨åŸŸå¤–æ•°æ®ä¸Šå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚
- é€šè¿‡èåˆè¾“å…¥å›¾åƒçš„ç©ºé—´ç‰¹å¾å’Œ StyleGAN å±‚çš„ä¸­é—´ç‰¹å¾ï¼ŒStyleRetoucher å¯ä»¥æœ€å¤§ç¨‹åº¦åœ°ä¿ç•™è¾“å…¥ç‰¹å¾ã€‚
- ä¸€ç§æ–°é¢–çš„ç‘•ç–µæ„ŸçŸ¥ç‰¹å¾é€‰æ‹©æœºåˆ¶å¯ä»¥æœ‰æ•ˆè¯†åˆ«å¹¶å»é™¤çš®è‚¤ç‘•ç–µï¼Œæ”¹å–„å›¾åƒçš®è‚¤çŠ¶å†µã€‚
- å®šæ€§å’Œå®šé‡è¯„ä¼°éªŒè¯äº†è¯¥æ–¹æ³•å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚
- è¿›ä¸€æ­¥çš„å®éªŒè¡¨æ˜ï¼ŒStyleRetoucher åœ¨å›¾åƒä¿®å›¾ä»»åŠ¡ä¸­ä¼˜äºå…¶ä»–æ›¿ä»£è§£å†³æ–¹æ¡ˆã€‚
- ç”¨æˆ·æ„ŸçŸ¥ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•çš„ä¿®å›¾æ€§èƒ½ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„æ›¿ä»£æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>æ ‡é¢˜ï¼šStyleRetoucherï¼šåŸºäºGANå…ˆéªŒçš„é€šç”¨äººåƒå›¾ç‰‡ä¿®å›¾</p>
</li>
<li><p>ä½œè€…ï¼šWanchao Su, Can Wang, Chen Liu, Fangzhou Han, Hongbo Fu, Jing Liao</p>
</li>
<li><p>éš¶å±æœºæ„ï¼šæ— </p>
</li>
<li><p>å…³é”®è¯ï¼šäººåƒå›¾ç‰‡ä¿®å›¾ã€StyleGANã€GANå…ˆéªŒã€çš®è‚¤ç‘•ç–µå»é™¤ã€ç‰¹å¾èåˆ</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šæ— ï¼ŒGithubä»£ç é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šäººåƒå›¾ç‰‡ä¿®å›¾æ˜¯ä¸€é¡¹å¤æ‚ä¸”è€—æ—¶çš„ä»»åŠ¡ï¼Œéœ€è¦ä¸“ä¸šè‰ºæœ¯å®¶çš„å‚ä¸ã€‚ç°æœ‰çš„è‡ªåŠ¨ä¿®å›¾æ–¹æ³•è¦ä¹ˆäº§ç”Ÿè¿‡åº¦å¹³æ»‘çš„ä¼ªå½±ï¼Œè¦ä¹ˆç¼ºä¹æ³›åŒ–èƒ½åŠ›ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦åŸºäºCNNï¼Œå­˜åœ¨è¿‡åº¦å¹³æ»‘å’Œæ³›åŒ–èƒ½åŠ›å·®çš„é—®é¢˜ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„äººåƒå›¾ç‰‡ä¿®å›¾æ¡†æ¶StyleRetoucherï¼Œåˆ©ç”¨StyleGANçš„ç”Ÿæˆå’Œæ³›åŒ–èƒ½åŠ›æ¥æ”¹å–„è¾“å…¥äººåƒå›¾ç‰‡çš„çš®è‚¤çŠ¶å†µï¼ŒåŒæ—¶ä¿ç•™å…¶é¢éƒ¨ç»†èŠ‚ã€‚è¯¥æ–¹æ³•é€šè¿‡èåˆè¾“å…¥å›¾åƒçš„ç©ºé—´ç‰¹å¾å’ŒStyleGANä¸­é—´å±‚çš„ç‰¹å¾ï¼Œæœ€å¤§ç¨‹åº¦åœ°ä¿ç•™äº†è¾“å…¥å›¾åƒçš„ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§æ–°çš„ç‘•ç–µæ„ŸçŸ¥ç‰¹å¾é€‰æ‹©æœºåˆ¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è¯†åˆ«å’Œå»é™¤çš®è‚¤ç‘•ç–µï¼Œæ”¹å–„å›¾åƒçš„çš®è‚¤çŠ¶å†µã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šå®šæ€§å’Œå®šé‡è¯„ä¼°éªŒè¯äº†è¯¥æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿›ä¸€æ­¥çš„å®éªŒè¡¨æ˜ï¼ŒStyleRetoucheråœ¨å›¾åƒä¿®å›¾ä»»åŠ¡ä¸­ä¼˜äºå…¶ä»–æ›¿ä»£æ–¹æ¡ˆã€‚ç”¨æˆ·æ„ŸçŸ¥ç ”ç©¶ä¹Ÿè¯å®äº†è¯¥æ–¹æ³•ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) StyleGANå…ˆéªŒèåˆï¼šè¯¥æ–¹æ³•åˆ©ç”¨StyleGANçš„ç”Ÿæˆå’Œæ³›åŒ–èƒ½åŠ›ï¼Œæå–è¾“å…¥å›¾åƒçš„ç©ºé—´ç‰¹å¾å’ŒStyleGANä¸­é—´å±‚çš„ç‰¹å¾ï¼Œå¹¶èåˆè¿™äº›ç‰¹å¾ï¼Œæœ€å¤§ç¨‹åº¦åœ°ä¿ç•™è¾“å…¥å›¾åƒçš„ç‰¹å¾ã€‚
(2) ç‘•ç–µæ„ŸçŸ¥ç‰¹å¾é€‰æ‹©ï¼šæå‡ºäº†ä¸€ç§æ–°çš„ç‘•ç–µæ„ŸçŸ¥ç‰¹å¾é€‰æ‹©æœºåˆ¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è¯†åˆ«å’Œå»é™¤çš®è‚¤ç‘•ç–µï¼Œæ”¹å–„å›¾åƒçš„çš®è‚¤çŠ¶å†µã€‚
(3) è¿­ä»£ä¼˜åŒ–ï¼šé€šè¿‡è¿­ä»£ä¼˜åŒ–ï¼Œé€æ­¥æ”¹å–„å›¾åƒçš„çš®è‚¤çŠ¶å†µï¼ŒåŒæ—¶ä¿ç•™å…¶é¢éƒ¨ç»†èŠ‚ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„é€šç”¨äººåƒå›¾ç‰‡ä¿®å›¾æ¡†æ¶StyleRetoucherï¼Œåˆ©ç”¨StyleGANçš„ç”Ÿæˆå’Œæ³›åŒ–èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°æ”¹å–„äº†è¾“å…¥äººåƒå›¾ç‰‡çš„çš®è‚¤çŠ¶å†µï¼ŒåŒæ—¶ä¿ç•™äº†å…¶é¢éƒ¨ç»†èŠ‚ã€‚è¯¥æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­å‡å–å¾—äº†è‰¯å¥½çš„ç»“æœï¼Œè¯æ˜äº†å…¶æ³›åŒ–èƒ½åŠ›å’Œä¼˜è¶Šæ€§ã€‚è¿›ä¸€æ­¥çš„å®éªŒè¡¨æ˜ï¼ŒStyleRetoucheråœ¨å›¾åƒä¿®å›¾ä»»åŠ¡ä¸­ä¼˜äºå…¶ä»–æ›¿ä»£æ–¹æ¡ˆã€‚ç”¨æˆ·æ„ŸçŸ¥ç ”ç©¶ä¹Ÿè¯å®äº†è¯¥æ–¹æ³•ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ›¿ä»£æ–¹æ¡ˆã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„äººåƒå›¾ç‰‡ä¿®å›¾æ¡†æ¶StyleRetoucherï¼Œåˆ©ç”¨StyleGANçš„ç”Ÿæˆå’Œæ³›åŒ–èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°æ”¹å–„äº†è¾“å…¥äººåƒå›¾ç‰‡çš„çš®è‚¤çŠ¶å†µï¼ŒåŒæ—¶ä¿ç•™äº†å…¶é¢éƒ¨ç»†èŠ‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç‘•ç–µæ„ŸçŸ¥ç‰¹å¾é€‰æ‹©æœºåˆ¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è¯†åˆ«å’Œå»é™¤çš®è‚¤ç‘•ç–µï¼Œæ”¹å–„å›¾åƒçš„çš®è‚¤çŠ¶å†µã€‚</li>
<li>é€šè¿‡è¿­ä»£ä¼˜åŒ–ï¼Œé€æ­¥æ”¹å–„å›¾åƒçš„çš®è‚¤çŠ¶å†µï¼ŒåŒæ—¶ä¿ç•™å…¶é¢éƒ¨ç»†èŠ‚ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­å‡å–å¾—äº†è‰¯å¥½çš„ç»“æœï¼Œè¯æ˜äº†å…¶æ³›åŒ–èƒ½åŠ›å’Œä¼˜è¶Šæ€§ã€‚</li>
<li>åœ¨å›¾åƒä¿®å›¾ä»»åŠ¡ä¸­ä¼˜äºå…¶ä»–æ›¿ä»£æ–¹æ¡ˆã€‚</li>
<li>ç”¨æˆ·æ„ŸçŸ¥ç ”ç©¶ä¹Ÿè¯å®äº†è¯¥æ–¹æ³•ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ›¿ä»£æ–¹æ¡ˆã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºéƒ¨ç½²å’Œä½¿ç”¨ã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹è¾ƒå¿«ï¼Œå¯ä»¥åœ¨åˆç†çš„æ—¶é—´å†…å®Œæˆã€‚</li>
<li>è¯¥æ–¹æ³•çš„æ¨ç†è¿‡ç¨‹ç›¸å¯¹è¾ƒå¿«ï¼Œå¯ä»¥å®æ—¶å¤„ç†å›¾åƒã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1da4e5eed7542c8e382bd71ed1222c8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eecb890ae8fa7ffea652e6d2ccfd2f90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-29ec59afed1c6e0dba20d552901cdbd2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1cca26e2ef7490681e28d8a8b63ab99c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1aca71fe4cee342f6c693d139fa2e057.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7cccc88967632c8ffb8a168720e3210f.jpg" align="middle">
</details>
â€‹    


## HeadCraft: Modeling High-Detail Shape Variations for Animated 3DMMs
**Authors:Artem Sevastopolsky, Philip-William Grassal, Simon Giebenhain, ShahRukh Athar, Luisa Verdoliva, Matthias Niessner**

Current advances in human head modeling allow to generate plausible-looking 3D head models via neural representations. Nevertheless, constructing complete high-fidelity head models with explicitly controlled animation remains an issue. Furthermore, completing the head geometry based on a partial observation, e.g. coming from a depth sensor, while preserving details is often problematic for the existing methods. We introduce a generative model for detailed 3D head meshes on top of an articulated 3DMM which allows explicit animation and high-detail preservation at the same time. Our method is trained in two stages. First, we register a parametric head model with vertex displacements to each mesh of the recently introduced NPHM dataset of accurate 3D head scans. The estimated displacements are baked into a hand-crafted UV layout. Second, we train a StyleGAN model in order to generalize over the UV maps of displacements. The decomposition of the parametric model and high-quality vertex displacements allows us to animate the model and modify it semantically. We demonstrate the results of unconditional generation and fitting to the full or partial observation. The project page is available at https://seva100.github.io/headcraft. 

[PDF](http://arxiv.org/abs/2312.14140v1) Project page: https://seva100.github.io/headcraft. Video:   https://youtu.be/uBeBT2f1CL0. 23 pages, 19 figures, 2 tables

**æ‘˜è¦**
ç”Ÿæˆæ¨¡å‹å¯ç”¨äºåˆ›å»ºè¯¦ç»†çš„ 3D å¤´éƒ¨ç½‘æ ¼ï¼Œå¹¶å…è®¸æ˜¾å¼åŠ¨ç”»å’Œé«˜ç»†èŠ‚ä¿ç•™ã€‚

**è¦ç‚¹**
* æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œç”¨äºåœ¨å¯é“°æ¥ 3DMM çš„åŸºç¡€ä¸Šç”Ÿæˆè¯¦ç»†çš„ 3D å¤´éƒ¨ç½‘æ ¼ã€‚
* æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥æ˜¾å¼åœ°åŠ¨ç”»åŒ–å¤´éƒ¨å¹¶å¯¹å¤´éƒ¨è¿›è¡Œè¯­ä¹‰ä¿®æ”¹ã€‚
* æˆ‘ä»¬å°†å‚æ•°æ¨¡å‹å’Œé«˜è´¨é‡é¡¶ç‚¹ä½ç§»åˆ†è§£ï¼Œä»¥ä¾¿å¯¹æ¨¡å‹è¿›è¡ŒåŠ¨ç”»å¤„ç†å¹¶å¯¹å…¶è¿›è¡Œè¯­ä¹‰ä¿®æ”¹ã€‚
* æˆ‘ä»¬æ¼”ç¤ºäº†æ— æ¡ä»¶ç”Ÿæˆå’Œæ‹Ÿåˆåˆ°å®Œå…¨æˆ–éƒ¨åˆ†è§‚å¯Ÿçš„ç»“æœã€‚
* æˆ‘ä»¬ä½¿ç”¨æœ€è¿‘å¼•å…¥çš„ NPHM ç²¾ç¡® 3D å¤´éƒ¨æ‰«ææ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œäº†è®­ç»ƒã€‚
* æˆ‘ä»¬å°†ä¼°è®¡çš„ä½ç§»çƒ˜ç„™åˆ°æ‰‹å·¥åˆ¶ä½œçš„ UV å¸ƒå±€ä¸­ã€‚
* æˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ª StyleGAN æ¨¡å‹æ¥æ¦‚æ‹¬ä½ç§»çš„ UV æ˜ å°„ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šHeadCraftï¼šä¸ºåŠ¨ç”» 3DMM å»ºæ¨¡é«˜ç»†èŠ‚å½¢çŠ¶å˜åŒ–</li>
<li>ä½œè€…ï¼šArtem Sevastopolskyã€Philip-William Grassalã€Simon Giebenhainã€Shah Rukh Atharã€Luisa Verdolivaã€Matthias NieÃŸner</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ…•å°¼é»‘å·¥ä¸šå¤§å­¦ï¼ˆTUMï¼‰ï¼Œå¾·å›½</li>
<li>å…³é”®è¯ï¼šç”Ÿæˆå¤´éƒ¨æ¨¡å‹ã€3D æ‰«ææ•°æ®é›†ã€å‚æ•°åŒ–æ¨¡æ¿ã€éšæœºç”Ÿæˆã€æ·±åº¦è§‚å¯Ÿã€å®Œæ•´å‡ ä½•</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.14140
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šå½“å‰çš„äººç±»å¤´éƒ¨å»ºæ¨¡æŠ€æœ¯å¯ä»¥é€šè¿‡ç¥ç»è¡¨å¾æ¥ç”Ÿæˆé€¼çœŸçš„ 3D å¤´éƒ¨æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹åœ¨è®¡ç®—æœºå›¾å½¢å­¦ã€è™šæ‹Ÿç°å®å’Œæ•°å­—å¨±ä¹ç­‰é¢†åŸŸéƒ½æœ‰åº”ç”¨ã€‚ç„¶è€Œï¼Œæ„å»ºå…·æœ‰æ˜¾å¼æ§åˆ¶åŠ¨ç”»å’Œè¶³å¤Ÿç»†èŠ‚çš„å®Œæ•´é«˜ä¿çœŸå¤´éƒ¨æ¨¡å‹ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚
(2)ï¼šè¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰çš„éšå¼ç”Ÿæˆæ¨¡å‹ï¼Œå¦‚ pi-GANã€EG3D æˆ– StyleGAN-3ï¼Œé€šå¸¸ä¸èƒ½å¾ˆå¥½åœ°å¤„ç†åŠ¨ç”»å’Œè·Ÿè¸ªï¼Œå¹¶ä¸”åœ¨ä»éƒ¨åˆ†è§‚å¯Ÿï¼ˆä¾‹å¦‚æ¥è‡ªæ·±åº¦ä¼ æ„Ÿå™¨ï¼‰å®Œæˆå¤´éƒ¨å‡ ä½•æ—¶ï¼Œå¾€å¾€éš¾ä»¥ä¿ç•™ç»†èŠ‚ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨é“°æ¥ 3DMM ä¹‹ä¸Šçš„è¯¦ç»† 3D å¤´éƒ¨ç½‘æ ¼ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…è®¸æ˜¾å¼åŠ¨ç”»å’Œé«˜ç»†èŠ‚ä¿ç•™ã€‚è¯¥æ–¹æ³•åˆ†ä¸¤ä¸ªé˜¶æ®µè®­ç»ƒã€‚é¦–å…ˆï¼Œå°†å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹ä¸é¡¶ç‚¹ä½ç§»æ³¨å†Œåˆ°æœ€è¿‘å¼•å…¥çš„ NPHM æ•°æ®é›†çš„æ¯ä¸ªç½‘æ ¼ï¼Œä»¥è·å¾—å‡†ç¡®çš„ 3D å¤´éƒ¨æ‰«æã€‚ç„¶åï¼Œè®­ç»ƒä¸€ä¸ª StyleGAN æ¨¡å‹æ¥æ¦‚æ‹¬ä½ç§»çš„ UV è´´å›¾ã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•åœ¨æ— æ¡ä»¶ç”Ÿæˆå’Œæ‹Ÿåˆå®Œæ•´æˆ–éƒ¨åˆ†è§‚å¯Ÿæ–¹é¢å–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨é“°æ¥3DMMä¹‹ä¸Šçš„è¯¦ç»†3Då¤´éƒ¨ç½‘æ ¼ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…è®¸æ˜¾å¼åŠ¨ç”»å’Œé«˜ç»†èŠ‚ä¿ç•™ã€‚
ï¼ˆ2ï¼‰ï¼šè¯¥æ–¹æ³•åˆ†ä¸¤ä¸ªé˜¶æ®µè®­ç»ƒã€‚é¦–å…ˆï¼Œå°†å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹ä¸é¡¶ç‚¹ä½ç§»æ³¨å†Œåˆ°æœ€è¿‘å¼•å…¥çš„NPHMæ•°æ®é›†çš„æ¯ä¸ªç½‘æ ¼ï¼Œä»¥è·å¾—å‡†ç¡®çš„3Då¤´éƒ¨æ‰«æã€‚ç„¶åï¼Œè®­ç»ƒä¸€ä¸ªStyleGANæ¨¡å‹æ¥æ¦‚æ‹¬ä½ç§»çš„UVè´´å›¾ã€‚
ï¼ˆ3ï¼‰ï¼šåœ¨ç¬¬ä¸€ä¸ªé˜¶æ®µï¼Œä¼˜åŒ–å…·æœ‰é™„åŠ çŸ¢é‡ä½ç§»çš„æŸå¤±å‡½æ•°ï¼Œä»¥é˜²æ­¢è‡ªç›¸äº¤ã€‚åœ¨ç¬¬äºŒä¸ªé˜¶æ®µï¼Œä¼˜åŒ–å…·æœ‰ä»…å…è®¸æ²¿å…ˆå‰ä½ç§»é¡¶ç‚¹çš„æ³•çº¿ç§»åŠ¨çš„ä½ç§»çš„æŸå¤±å‡½æ•°ï¼Œä»¥æ‹Ÿåˆé«˜é¢‘ç»†èŠ‚ã€‚
ï¼ˆ4ï¼‰ï¼šæœ€åï¼Œå°†ä½ç§»çƒ˜ç„™åˆ°UVè´´å›¾ä¸­ï¼Œå¹¶ä½¿ç”¨StyleGAN2æ¨¡å‹ç”ŸæˆUVä½ç§»è´´å›¾ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨é“°æ¥3DMMä¹‹ä¸Šçš„è¯¦ç»†3Då¤´éƒ¨ç½‘æ ¼ç”Ÿæˆæ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…è®¸æ˜¾å¼åŠ¨ç”»å’Œé«˜ç»†èŠ‚ä¿ç•™ï¼Œåœ¨æ— æ¡ä»¶ç”Ÿæˆå’Œæ‹Ÿåˆå®Œæ•´æˆ–éƒ¨åˆ†è§‚å¯Ÿæ–¹é¢å–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>å°†å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹ä¸é¡¶ç‚¹ä½ç§»æ³¨å†Œåˆ°3Då¤´éƒ¨æ‰«æï¼Œä»¥è·å¾—å‡†ç¡®çš„3Då¤´éƒ¨æ‰«æã€‚</li>
<li>è®­ç»ƒä¸€ä¸ªStyleGANæ¨¡å‹æ¥æ¦‚æ‹¬ä½ç§»çš„UVè´´å›¾ã€‚</li>
<li>åœ¨ç¬¬ä¸€ä¸ªé˜¶æ®µï¼Œä¼˜åŒ–å…·æœ‰é™„åŠ çŸ¢é‡ä½ç§»çš„æŸå¤±å‡½æ•°ï¼Œä»¥é˜²æ­¢è‡ªç›¸äº¤ã€‚</li>
<li>åœ¨ç¬¬äºŒä¸ªé˜¶æ®µï¼Œä¼˜åŒ–å…·æœ‰ä»…å…è®¸æ²¿å…ˆå‰ä½ç§»é¡¶ç‚¹çš„æ³•çº¿ç§»åŠ¨çš„ä½ç§»çš„æŸå¤±å‡½æ•°ï¼Œä»¥æ‹Ÿåˆé«˜é¢‘ç»†èŠ‚ã€‚</li>
<li>å°†ä½ç§»çƒ˜ç„™åˆ°UVè´´å›¾ä¸­ï¼Œå¹¶ä½¿ç”¨StyleGAN2æ¨¡å‹ç”ŸæˆUVä½ç§»è´´å›¾ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨æ— æ¡ä»¶ç”Ÿæˆå’Œæ‹Ÿåˆå®Œæ•´æˆ–éƒ¨åˆ†è§‚å¯Ÿæ–¹é¢å–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0b60b8f51ddf0eb511b0da3467102956.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-634ce760929e598097380f2cf865992f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-08d46c76d8da31eb3f3362ff9d4fefa4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bd84563b8211b1c631a249968d6a3bb7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-da274555d2a06c54e8244021b7e2af1d.jpg" align="middle">
</details>
â€‹    


## Warping the Residuals for Image Editing with StyleGAN
**Authors:Ahmet Burak Yildirim, Hamza Pehlivan, Aysegul Dundar**

StyleGAN models show editing capabilities via their semantically interpretable latent organizations which require successful GAN inversion methods to edit real images. Many works have been proposed for inverting images into StyleGAN's latent space. However, their results either suffer from low fidelity to the input image or poor editing qualities, especially for edits that require large transformations. That is because low-rate latent spaces lose many image details due to the information bottleneck even though it provides an editable space. On the other hand, higher-rate latent spaces can pass all the image details to StyleGAN for perfect reconstruction of images but suffer from low editing qualities. In this work, we present a novel image inversion architecture that extracts high-rate latent features and includes a flow estimation module to warp these features to adapt them to edits. The flows are estimated from StyleGAN features of edited and unedited latent codes. By estimating the high-rate features and warping them for edits, we achieve both high-fidelity to the input image and high-quality edits. We run extensive experiments and compare our method with state-of-the-art inversion methods. Qualitative metrics and visual comparisons show significant improvements. 

[PDF](http://arxiv.org/abs/2312.11422v1) 

**Summary:**
GANå›¾åƒåæ¼”åˆ›æ–°æ–¹æ³•å¯å®ç°é«˜è´¨é‡å›¾åƒç¼–è¾‘ã€‚

**Key Takeaways:**

- StyleGANæ¨¡å‹å…·æœ‰è¯­ä¹‰å¯è§£é‡Šçš„æ½œåœ¨ç»„ç»‡ï¼Œéœ€è¦æˆåŠŸçš„GANåæ¼”æ–¹æ³•æ¥ç¼–è¾‘çœŸå®å›¾åƒã€‚
- è®¸å¤šç ”ç©¶å·²ç»æå‡ºå°†å›¾åƒåæ¼”åˆ°StyleGANæ½œåœ¨ç©ºé—´çš„æ–¹æ³•ã€‚
- ä½é€Ÿç‡æ½œåœ¨ç©ºé—´ç”±äºä¿¡æ¯ç“¶é¢ˆè€Œä¸¢å¤±è®¸å¤šå›¾åƒç»†èŠ‚ï¼Œå³ä½¿å®ƒæä¾›äº†å¯ç¼–è¾‘çš„ç©ºé—´ã€‚
- é«˜é€Ÿç‡æ½œåœ¨ç©ºé—´å¯ä»¥å°†æ‰€æœ‰å›¾åƒç»†èŠ‚ä¼ é€’ç»™StyleGANä»¥å®Œç¾é‡å»ºå›¾åƒï¼Œä½†ç¼–è¾‘è´¨é‡è¾ƒå·®ã€‚
- æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒåæ¼”æ¶æ„ï¼Œå¯æå–é«˜é€Ÿç‡æ½œåœ¨ç‰¹å¾ï¼Œå¹¶åŒ…æ‹¬ä¸€ä¸ªæµåŠ¨ä¼°è®¡æ¨¡å—ï¼Œå°†è¿™äº›ç‰¹å¾æ‰­æ›²ä»¥é€‚åº”ç¼–è¾‘ã€‚
- é€šè¿‡ä¼°è®¡é«˜é€Ÿç‡ç‰¹å¾å¹¶å°†å…¶æ‰­æ›²ä»¥è¿›è¡Œç¼–è¾‘ï¼Œæˆ‘ä»¬å®ç°äº†å¯¹è¾“å…¥å›¾åƒçš„é«˜ä¿çœŸåº¦å’Œé«˜è´¨é‡çš„ç¼–è¾‘ã€‚
- å¹¿æ³›çš„å®éªŒè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„åæ¼”æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šä½¿ç”¨ StyleGAN è¿›è¡Œå›¾åƒç¼–è¾‘çš„æ®‹å·®ç¿˜æ›²</li>
<li>ä½œè€…ï¼šAhmet Burak Yildirimã€Hamza Pehlivanã€Aysegul Dundar</li>
<li>ä½œè€…å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šGAN åæ¼”ã€å›¾åƒç¼–è¾‘ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.11422ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šStyleGAN æ¨¡å‹å› å…¶è¯­ä¹‰å¯è§£é‡Šçš„æ½œåœ¨ç»„ç»‡è€Œæ˜¾ç¤ºå‡ºç¼–è¾‘åŠŸèƒ½ï¼Œè¿™éœ€è¦æˆåŠŸçš„ GAN åæ¼”æ–¹æ³•æ¥ç¼–è¾‘çœŸå®å›¾åƒã€‚è®¸å¤šå·¥ä½œå·²è¢«æè®®å°†å›¾åƒåæ¼”åˆ° StyleGAN çš„æ½œåœ¨ç©ºé—´ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„ç»“æœè¦ä¹ˆå¯¹è¾“å…¥å›¾åƒçš„ä¿çœŸåº¦ä½ï¼Œè¦ä¹ˆç¼–è¾‘è´¨é‡å·®ï¼Œå°¤å…¶æ˜¯å¯¹äºéœ€è¦å¤§å˜æ¢çš„ç¼–è¾‘ã€‚è¿™æ˜¯å› ä¸ºä½é€Ÿç‡æ½œåœ¨ç©ºé—´ç”±äºä¿¡æ¯ç“¶é¢ˆè€Œä¸¢å¤±äº†è®¸å¤šå›¾åƒç»†èŠ‚ï¼Œå³ä½¿å®ƒæä¾›äº†å¯ç¼–è¾‘çš„ç©ºé—´ã€‚å¦ä¸€æ–¹é¢ï¼Œæ›´é«˜é€Ÿç‡çš„æ½œåœ¨ç©ºé—´å¯ä»¥å°†æ‰€æœ‰å›¾åƒç»†èŠ‚ä¼ é€’ç»™ StyleGAN ä»¥å®Œç¾é‡å»ºå›¾åƒï¼Œä½†ç¼–è¾‘è´¨é‡ä¼šé™ä½ï¼Œå¦‚æœè¿™äº›ç‰¹å¾ä¸ç¼–è¾‘ä¸ä¸€è‡´ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™ç§æƒè¡¡ï¼Œæˆ‘ä»¬ä¹‹å‰çš„å·¥ä½œ StyleRes æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥å­¦ä¹ æ›´é«˜é€Ÿç‡æ½œåœ¨ä»£ç ä¸­çš„æ®‹å·®ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾åœ¨ç¼–ç ç‰¹å¾çš„é‡å»ºä¸­ç¼ºå¤±ã€‚ç„¶è€Œï¼Œè¿™äº›é«˜æ¯”ç‡æ½œåœ¨ä»£ç éœ€è¦é€‚åº”å›¾åƒç¼–è¾‘ã€‚ä¾‹å¦‚ï¼Œå¦‚æœé«˜æ¯”ç‡ä»£ç æºå¸¦æœ‰å…³äººè€³ç¯çš„ä¿¡æ¯ï¼Œå¹¶ä¸”å›¾åƒè¢«ç¼–è¾‘ä»¥æ”¹å˜äººçš„å§¿åŠ¿ï¼Œé‚£ä¹ˆè¿™äº›ä»£ç åº”è¯¥ç›¸åº”åœ°è¢«æºå¸¦åˆ°ç”Ÿæˆå™¨ä¸­ä»¥å‡ºç°åœ¨æ­£ç¡®çš„ä½ç½®ã€‚å¦åˆ™ï¼Œå®ƒä¼šå¯¼è‡´é‡å½±æ•ˆåº”ã€‚å› æ­¤ï¼ŒStyleRes æè®®ç”¨éšæœºç¼–è¾‘å’Œå¾ªç¯ä¸€è‡´æ€§æŒ‡å¯¼æ¥è®­ç»ƒæ¨¡å‹ï¼Œä»¥ä¾¿åœ¨åº”ç”¨ç¼–è¾‘å¹¶æ¢å¤å›åŸçŠ¶æ—¶é‡å»ºåŸå§‹å›¾åƒã€‚é€šè¿‡è¿™ä¸ªæŒ‡å¯¼ï¼Œå®ƒå­¦ä¹ äº†ä¸€ä¸ªæ¨¡å—æ¥è½¬æ¢è¿™äº›æ›´é«˜æ¯”ç‡çš„æ½œåœ¨ä»£ç ä»¥è¿›è¡Œå›¾åƒç¼–è¾‘ã€‚ç„¶è€Œï¼Œå­¦ä¹ çš„æ¨¡å—æ˜¯ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œå¹¶ä¸”åœ¨æ­£ç¡®è½¬æ¢æ®‹å·®ä»¥è¿›è¡Œç¼–è¾‘æ–¹é¢å…·æœ‰æœ‰é™çš„èƒ½åŠ›ã€‚
ï¼ˆ3ï¼‰æ–¹æ³•ï¼šåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æ˜¯ä¸€ä¸ªç®¡é“ï¼Œå®ƒå¯ä»¥å­¦ä¹ é«˜ä¿çœŸå›¾åƒé‡å»ºçš„æ®‹å·®å¹¶æ­£ç¡®é‡‡ç”¨å®ƒä»¬ä»¥è¿›è¡Œé«˜è´¨é‡çš„å›¾åƒç¼–è¾‘ã€‚æˆ‘ä»¬çš„æ¡†æ¶é€šè¿‡ä¼°è®¡åŸå§‹å›¾åƒç‰¹å¾å’Œç¼–è¾‘å›¾åƒç‰¹å¾ä¹‹é—´çš„æµåŠ¨å¹¶æ ¹æ®æµåŠ¨ç¿˜æ›²æ®‹å·®ç‰¹å¾æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬åˆ©ç”¨ä¸€ä¸ªæ— ç›‘ç£çš„æµåŠ¨ä¼°è®¡ç½‘ç»œä»¥ä¸€ç§æ–°é¢–çš„æ–¹å¼è®­ç»ƒæˆ‘ä»¬çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶åœ¨æç«¯ç¼–è¾‘å˜æ¢ä¸‹å®ç°äº†æ˜¾ç€æ›´å¥½çš„ç»“æœï¼Œè€Œæˆ‘ä»¬çš„æ¶æ„æ˜¯å•é˜¶æ®µä¸”æœ‰æ•ˆçš„ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šæˆ‘ä»¬çš„è´¡çŒ®å¦‚ä¸‹ï¼š</li>
</ol>
<ul>
<li>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åæ¼”ç®¡é“ï¼Œé€šè¿‡é¢„æµ‹åŸå§‹å›¾åƒå’Œç¼–è¾‘å›¾åƒä¹‹é—´çš„æµåŠ¨å¹¶å­¦ä¹ æ ¹æ®é¢„æµ‹çš„æµåŠ¨ç¿˜æ›²é«˜æ¯”ç‡ç‰¹å¾æ¥å®ç°é«˜è´¨é‡çš„å›¾åƒç¼–è¾‘ã€‚</li>
<li>æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªæ— ç›‘ç£çš„é¢„è®­ç»ƒæµåŠ¨ä¼°è®¡ç½‘ç»œæ¥æŒ‡å¯¼æµåŠ¨é¢„æµ‹ã€‚æµåŠ¨é¢„æµ‹ä»¥ StyleGAN ä¸­é—´ç‰¹å¾ä½œä¸ºè¾“å…¥ä»¥å®ç°æ•ˆç‡ã€‚</li>
<li>æˆ‘ä»¬è¡¨æ˜æˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥ä¸ä¸åŒçš„é¢„è®­ç»ƒ StyleGAN åæ¼”ç½‘ç»œä¸€èµ·å·¥ä½œï¼Œå¹¶ä»¥å¾ˆå¤§çš„å¹…åº¦æ”¹è¿›æ‰€æœ‰è¿™äº›ç½‘ç»œã€‚</li>
<li>æˆ‘ä»¬çš„å¹¿æ³›å®éªŒè¡¨æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<ol start="7">
<li><p>Methods:
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åæ¼”ç®¡é“ï¼Œé€šè¿‡é¢„æµ‹åŸå§‹å›¾åƒå’Œç¼–è¾‘å›¾åƒä¹‹é—´çš„æµåŠ¨å¹¶å­¦ä¹ æ ¹æ®é¢„æµ‹çš„æµåŠ¨ç¿˜æ›²é«˜æ¯”ç‡ç‰¹å¾æ¥å®ç°é«˜è´¨é‡çš„å›¾åƒç¼–è¾‘ã€‚
(2): è¯¥æ¡†æ¶é€šè¿‡ä¸€ä¸ªæ— ç›‘ç£çš„é¢„è®­ç»ƒæµåŠ¨ä¼°è®¡ç½‘ç»œæ¥æŒ‡å¯¼æµåŠ¨é¢„æµ‹ã€‚æµåŠ¨é¢„æµ‹ä»¥StyleGANä¸­é—´ç‰¹å¾ä½œä¸ºè¾“å…¥ä»¥å®ç°æ•ˆç‡ã€‚
(3): æœ¬æ–‡è¡¨æ˜è¯¥æ¡†æ¶å¯ä»¥ä¸ä¸åŒçš„é¢„è®­ç»ƒStyleGANåæ¼”ç½‘ç»œä¸€èµ·å·¥ä½œï¼Œå¹¶ä»¥å¾ˆå¤§çš„å¹…åº¦æ”¹è¿›æ‰€æœ‰è¿™äº›ç½‘ç»œã€‚
(4): å¹¿æ³›çš„å®éªŒè¡¨æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰è¯¥å·¥ä½œæå‡ºäº†ä¸€ç§ GAN åæ¼”æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨è¿è¡Œæ—¶é«˜æ•ˆï¼Œå¹¶ä¸”åœ¨å„ç§å·¥ä½œä¸­æ¢ç´¢çš„ç¼–è¾‘æ–¹å‘ä¸‹å®ç°äº†é«˜ä¿çœŸåº¦å’Œé«˜è´¨é‡çš„å›¾åƒç¼–è¾‘ã€‚ä¸ä»¥å‰çš„å·¥ä½œä¸åŒï¼Œæˆ‘ä»¬æå‡ºä¼°è®¡æœªç¼–è¾‘å’Œç¼–è¾‘ç‰¹å¾çš„æµé¢„æµ‹ï¼Œä»¥æ‰­æ›²é«˜æ¯”ç‡æ®‹å·®ç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾å¯¹äºç²¾ç¡®çš„å›¾åƒé‡å»ºæ˜¯å¿…éœ€çš„ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶åœ¨è®¸å¤šç¼–è¾‘ä¸­å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤§å˜æ¢çš„ç¼–è¾‘ä¸­ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ GAN åæ¼”ç®¡é“ï¼Œé€šè¿‡é¢„æµ‹åŸå§‹å›¾åƒå’Œç¼–è¾‘å›¾åƒä¹‹é—´çš„æµåŠ¨å¹¶å­¦ä¹ æ ¹æ®é¢„æµ‹çš„æµåŠ¨æ‰­æ›²é«˜æ¯”ç‡ç‰¹å¾æ¥å®ç°é«˜è´¨é‡çš„å›¾åƒç¼–è¾‘ã€‚</li>
<li>è¯¥æ¡†æ¶é€šè¿‡ä¸€ä¸ªæ— ç›‘ç£çš„é¢„è®­ç»ƒæµåŠ¨ä¼°è®¡ç½‘ç»œæ¥æŒ‡å¯¼æµåŠ¨é¢„æµ‹ã€‚æµåŠ¨é¢„æµ‹ä»¥ StyleGAN ä¸­é—´ç‰¹å¾ä½œä¸ºè¾“å…¥ä»¥å®ç°æ•ˆç‡ã€‚</li>
<li>è¡¨æ˜è¯¥æ¡†æ¶å¯ä»¥ä¸ä¸åŒçš„é¢„è®­ç»ƒ StyleGAN åæ¼”ç½‘ç»œä¸€èµ·å·¥ä½œï¼Œå¹¶ä»¥å¾ˆå¤§çš„å¹…åº¦æ”¹è¿›æ‰€æœ‰è¿™äº›ç½‘ç»œã€‚</li>
<li>å¹¿æ³›çš„å®éªŒè¡¨æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•åœ¨æç«¯ç¼–è¾‘å˜æ¢ä¸‹å®ç°äº†æ˜¾ç€æ›´å¥½çš„ç»“æœï¼Œè€Œæˆ‘ä»¬çš„æ¶æ„æ˜¯å•é˜¶æ®µä¸”æœ‰æ•ˆçš„ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥ä¸ä¸åŒçš„é¢„è®­ç»ƒ StyleGAN åæ¼”ç½‘ç»œä¸€èµ·å·¥ä½œï¼Œå¹¶ä»¥å¾ˆå¤§çš„å¹…åº¦æ”¹è¿›æ‰€æœ‰è¿™äº›ç½‘ç»œã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å¹¿æ³›çš„å®éªŒä¸­è¡¨æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦ä¸€ä¸ªæ— ç›‘ç£çš„é¢„è®­ç»ƒæµåŠ¨ä¼°è®¡ç½‘ç»œæ¥æŒ‡å¯¼æµåŠ¨é¢„æµ‹ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¹¿æ³›çš„å®éªŒæ¥è¡¨æ˜å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3da8d474a8794bf8e7be10e3a9d757df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e321c50f9edfe34a7ecdbffb04a0979e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43b1de4b501c695a4a18a9daefec168c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7fcb4e4ade991311e9a49c68e363e4c0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46d11b639cc223b41293eb04b8aca2d9.jpg" align="middle">
</details>
â€‹    


## High-Fidelity Face Swapping with Style Blending
**Authors:Xinyu Yang, Hongbo Bo**

Face swapping has gained significant traction, driven by the plethora of human face synthesis facilitated by deep learning methods. However, previous face swapping methods that used generative adversarial networks (GANs) as backbones have faced challenges such as inconsistency in blending, distortions, artifacts, and issues with training stability. To address these limitations, we propose an innovative end-to-end framework for high-fidelity face swapping. First, we introduce a StyleGAN-based facial attributes encoder that extracts essential features from faces and inverts them into a latent style code, encapsulating indispensable facial attributes for successful face swapping. Second, we introduce an attention-based style blending module to effectively transfer Face IDs from source to target. To ensure accurate and quality transferring, a series of constraint measures including contrastive face ID learning, facial landmark alignment, and dual swap consistency is implemented. Finally, the blended style code is translated back to the image space via the style decoder, which is of high training stability and generative capability. Extensive experiments on the CelebA-HQ dataset highlight the superior visual quality of generated images from our face-swapping methodology when compared to other state-of-the-art methods, and the effectiveness of each proposed module. Source code and weights will be publicly available. 

[PDF](http://arxiv.org/abs/2312.10843v1) 4 pages

**Summary**
ä¼˜åŒ–ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) æ¶æ„ï¼Œæå‡ºåŸºäº StyleGAN çš„äººè„¸å±æ€§ç¼–ç å™¨å’ŒåŸºäºæ³¨æ„åŠ›çš„é£æ ¼èåˆæ¨¡å—ï¼Œå®ç°é«˜ä¿çœŸæ¢è„¸ã€‚

**Key Takeaways**

- æå‡ºäº†ä¸€ç§åŸºäº StyleGAN çš„äººè„¸å±æ€§ç¼–ç å™¨ï¼Œå°†äººè„¸ç‰¹å¾æå–å¹¶åæ¼”ä¸ºæ½œåœ¨æ ·å¼ä»£ç ã€‚
- è®¾è®¡äº†ä¸€ä¸ªåŸºäºæ³¨æ„åŠ›çš„é£æ ¼èåˆæ¨¡å—ï¼Œæœ‰æ•ˆåœ°å°†æºäººè„¸çš„ Face ID è½¬ç§»åˆ°ç›®æ ‡äººè„¸ã€‚
- é‡‡ç”¨äº†ä¸€ç³»åˆ—çº¦æŸæªæ–½ï¼ŒåŒ…æ‹¬å¯¹æ¯”äººè„¸ ID å­¦ä¹ ã€äººè„¸å…³é”®ç‚¹å¯¹é½å’ŒåŒé‡äº¤æ¢ä¸€è‡´æ€§ã€‚
- å°†æ··åˆçš„æ ·å¼ä»£ç é€šè¿‡æ ·å¼è§£ç å™¨ç¿»è¯‘å›å›¾åƒç©ºé—´ï¼Œå…·æœ‰å¾ˆé«˜çš„è®­ç»ƒç¨³å®šæ€§å’Œç”Ÿæˆèƒ½åŠ›ã€‚
- åœ¨ CelebA-HQ æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ¢è„¸æ–¹æ³•ç”Ÿæˆçš„å›¾åƒè§†è§‰è´¨é‡ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
- åŒæ—¶éªŒè¯äº†æ¯ä¸€é¡¹æå‡ºçš„æ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚
- æºä»£ç å’Œæƒé‡å°†å…¬å¼€å‘å¸ƒã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šé£æ ¼èåˆçš„é«˜ä¿çœŸæ¢è„¸</li>
<li>ä½œè€…ï¼šXinyu Yang</li>
<li>å•ä½ï¼šå…°å¼€æ–¯ç‰¹å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€äººè„¸åˆæˆã€äººè„¸äº¤æ¢</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.10843</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ¢è„¸æŠ€æœ¯è¿‘å¹´æ¥å¤‡å—å…³æ³¨ï¼Œä½†ç°æœ‰çš„æ¢è„¸æ–¹æ³•å­˜åœ¨èåˆä¸ä¸€è‡´ã€æ‰­æ›²ã€ä¼ªå½±å’Œè®­ç»ƒç¨³å®šæ€§å·®ç­‰é—®é¢˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸ä¸è¶³ï¼šä»¥å¾€åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„æ¢è„¸æ–¹æ³•å­˜åœ¨èåˆä¸ä¸€è‡´ã€æ‰­æ›²ã€ä¼ªå½±å’Œè®­ç»ƒç¨³å®šæ€§å·®ç­‰é—®é¢˜ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥å¹³è¡¡èº«ä»½ç›¸ä¼¼æ€§å’Œç›®æ ‡çš„ä½çº§ç»†èŠ‚ä¿ç•™ï¼Œå¯¼è‡´ç”Ÿæˆçš„å›¾åƒç»å¸¸å‡ºç°ä¼ªå½±å’Œä½ä¿çœŸåº¦ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç«¯åˆ°ç«¯é«˜ä¿çœŸæ¢è„¸æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šé¢éƒ¨å±æ€§ç¼–ç å™¨ã€é£æ ¼èåˆæ¨¡å—å’Œé£æ ¼è§£ç å™¨ã€‚é¢éƒ¨å±æ€§ç¼–ç å™¨å°†ç›®æ ‡å’Œæºå›¾åƒçš„ç‰¹å¾æå–åˆ°æ½œåœ¨ç©ºé—´ä¸­ï¼Œå¹¶ä½¿ç”¨å¤šå¤´äº¤å‰æ³¨æ„ï¼ˆMHCAï¼‰å°†æºåµŒå…¥å’Œç›®æ ‡åµŒå…¥è¿›è¡Œèåˆã€‚æœ€åï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„é£æ ¼è§£ç å™¨å°†èåˆçš„åµŒå…¥è§£ç ä¸ºå›¾åƒã€‚
ï¼ˆ4ï¼‰æ€§èƒ½ä¸ç»“è®ºï¼šåœ¨ CelebA-HQ æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„å›¾åƒå…·æœ‰æ›´é«˜çš„è§†è§‰è´¨é‡ï¼Œå¹¶ä¸”èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†æºå›¾åƒçš„é¢éƒ¨ç‰¹å¾è½¬ç§»åˆ°ç›®æ ‡å›¾åƒä¸­ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé£æ ¼ç¼–ç æ¨¡å‹çš„é«˜ä¿çœŸæ¢è„¸æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿç”Ÿæˆå…·æœ‰æ›´é«˜è§†è§‰è´¨é‡å’Œæ›´é€¼çœŸçš„äººè„¸å›¾åƒï¼Œæœ‰æ•ˆåœ°å°†æºå›¾åƒçš„é¢éƒ¨ç‰¹å¾è½¬ç§»åˆ°ç›®æ ‡å›¾åƒä¸­ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
è¯¥æ¡†æ¶é‡‡ç”¨äº†ä¸€ç§æ–°çš„é£æ ¼èåˆæ¨¡å—ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿåœ¨æ½œåœ¨ç©ºé—´ä¸­å°†æºåµŒå…¥å’Œç›®æ ‡åµŒå…¥è¿›è¡Œèåˆï¼Œä»è€Œç”Ÿæˆæ›´é€¼çœŸçš„å›¾åƒã€‚
è¯¥æ¡†æ¶ä½¿ç”¨é¢„è®­ç»ƒçš„é£æ ¼è§£ç å™¨å°†èåˆçš„åµŒå…¥è§£ç ä¸ºå›¾åƒï¼Œè¿™ä½¿å¾—è¯¥æ¡†æ¶èƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸçš„äººè„¸å›¾åƒã€‚
æ€§èƒ½ï¼š
è¯¥æ¡†æ¶åœ¨CelebA-HQæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶ç”Ÿæˆçš„å›¾åƒå…·æœ‰æ›´é«˜çš„è§†è§‰è´¨é‡ï¼Œå¹¶ä¸”èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†æºå›¾åƒçš„é¢éƒ¨ç‰¹å¾è½¬ç§»åˆ°ç›®æ ‡å›¾åƒä¸­ã€‚
å·¥ä½œé‡ï¼š
è¯¥æ¡†æ¶çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºå’Œè¾ƒé•¿æ—¶é—´çš„è®­ç»ƒã€‚</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-911f1f1ba2307b836811866ce4529595.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a1567919a066b4968d69d7bc94705df3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cdc82b874821cb5b2ef53e92f09ee664.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94207fdbd05bbd894e5ca3f64d99a25b.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Super-Resolution-through-StyleGAN-Regularized-Latent-Search-A-Realism-Fidelity-Trade-off"><a href="#Super-Resolution-through-StyleGAN-Regularized-Latent-Search-A-Realism-Fidelity-Trade-off" class="headerlink" title="Super-Resolution through StyleGAN Regularized Latent Search: A   Realism-Fidelity Trade-off"></a>Super-Resolution through StyleGAN Regularized Latent Search: A   Realism-Fidelity Trade-off</h2><p><strong>Authors:Marzieh Gheisari, Auguste Genovesio</strong></p>
<p>This paper addresses the problem of super-resolution: constructing a highly resolved (HR) image from a low resolved (LR) one. Recent unsupervised approaches search the latent space of a StyleGAN pre-trained on HR images, for the image that best downscales to the input LR image. However, they tend to produce out-of-domain images and fail to accurately reconstruct HR images that are far from the original domain. Our contribution is twofold. Firstly, we introduce a new regularizer to constrain the search in the latent space, ensuring that the inverted code lies in the original image manifold. Secondly, we further enhanced the reconstruction through expanding the image prior around the optimal latent code. Our results show that the proposed approach recovers realistic high-quality images for large magnification factors. Furthermore, for low magnification factors, it can still reconstruct details that the generator could not have produced otherwise. Altogether, our approach achieves a good trade-off between fidelity and realism for the super-resolution task. </p>
<p><a href="http://arxiv.org/abs/2311.16923v1">PDF</a> </p>
<p><strong>Summary</strong><br>é€šè¿‡çº¦æŸæ½œåœ¨ç©ºé—´æœç´¢èŒƒå›´å’Œæ‰©å±•å›¾åƒå…ˆéªŒæ¥æé«˜æ·±åº¦ç”Ÿæˆæ¨¡å‹çš„è¶…åˆ†è¾¨ç‡é‡å»º</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è¯¥è®ºæ–‡å…³æ³¨è¶…åˆ†è¾¨ç‡é—®é¢˜ï¼Œå³ä»ä½åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>æœ€è¿‘çš„æ— ç›‘ç£æ–¹æ³•åœ¨é¢„å…ˆè®­ç»ƒå¥½çš„ StyleGAN çš„æ½œåœ¨ç©ºé—´ä¸­æœç´¢å›¾åƒï¼Œä½¿å…¶ä¸‹é‡‡æ ·åä¸è¾“å…¥çš„ä½åˆ†è¾¨ç‡å›¾åƒæœ€åŒ¹é…ã€‚</li>
<li>ä½†è¿™äº›æ–¹æ³•å€¾å‘äºäº§ç”ŸåŸŸå¤–å›¾åƒï¼Œæ— æ³•å‡†ç¡®é‡å»ºè¿œç¦»åŸå§‹åŸŸçš„é«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ­£åˆ™åŒ–é¡¹æ¥çº¦æŸæ½œåœ¨ç©ºé—´ä¸­çš„æœç´¢ï¼Œç¡®ä¿åè½¬ä»£ç ä½äºåŸå§‹å›¾åƒæµå½¢ä¸­ã€‚</li>
<li>é€šè¿‡æ‰©å±•æœ€ä½³æ½œåœ¨ä»£ç å‘¨å›´çš„å›¾åƒå…ˆéªŒæ¥è¿›ä¸€æ­¥å¢å¼ºé‡å»ºã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥åœ¨å¤§å€ç‡æ”¾å¤§å› å­ä¸‹æ¢å¤é€¼çœŸã€é«˜è´¨é‡çš„å›¾åƒã€‚</li>
<li>å¯¹äºä½å€ç‡æ”¾å¤§å› å­ï¼Œå®ƒä»ç„¶å¯ä»¥é‡å»ºç”Ÿæˆå™¨æ— æ³•ç”Ÿæˆçš„å…¶ä»–ç»†èŠ‚ã€‚</li>
<li>æ€»ä¹‹ï¼Œè¯¥æ–¹æ³•åœ¨è¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸­å®ç°äº†ä¿çœŸåº¦å’ŒçœŸå®æ€§ä¹‹é—´çš„è‰¯å¥½æƒè¡¡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>é¢˜ç›®ï¼šé€šè¿‡ StyleGAN æ­£åˆ™åŒ–æ½œåœ¨æœç´¢å®ç°è¶…åˆ†è¾¨ç‡ï¼šçœŸå®æ€§-ä¿çœŸåº¦æƒè¡¡</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šMarzieh Gheisari, Auguste Genovesio</p>
</li><p></p>
<p></p><li><p>å•ä½ï¼šå·´é»é«˜ç­‰å¸ˆèŒƒå­¦é™¢</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šè¶…åˆ†è¾¨ç‡ã€StyleGANã€æ½œåœ¨æœç´¢ã€æ­£åˆ™åŒ–ã€çœŸå®æ€§ã€ä¿çœŸåº¦</p>
</li><p></p>
<p></p><li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.16923
Githubï¼šæ— </p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
(1)ï¼šè¶…åˆ†è¾¨ç‡æ—¨åœ¨ä»ä½åˆ†è¾¨ç‡å›¾åƒä¸­é‡å»ºæœªçŸ¥çš„é«˜åˆ†è¾¨ç‡å›¾åƒã€‚è¿‘å¹´æ¥ï¼Œç”Ÿæˆæ¨¡å‹æå¤§åœ°ä¿ƒè¿›äº†è¶…åˆ†è¾¨ç‡çš„å‘å±•ã€‚
(2)ï¼šGAN-based æ–¹æ³•å’Œå…ˆéªŒå¼•å¯¼æ–¹æ³•æ˜¯è¶…åˆ†è¾¨ç‡çš„ä¸¤ç§ä¸»è¦ç ”ç©¶è¶‹åŠ¿ã€‚GAN-based æ–¹æ³•å­¦ä¹ é«˜åˆ†è¾¨ç‡å›¾åƒå’Œä½åˆ†è¾¨ç‡å›¾åƒçš„ç›´æ¥è€¦åˆï¼Œä½†å­˜åœ¨å±€é™æ€§ï¼Œä¾‹å¦‚äº§ç”Ÿä¼ªå½±å’Œä¸è‡ªç„¶çš„çº¹ç†ã€‚å…ˆéªŒå¼•å¯¼æ–¹æ³•é€šè¿‡åˆ©ç”¨å…ˆéªŒä¿¡æ¯æ¥æ›´å¥½åœ°å®šä¹‰ç›®æ ‡ï¼Œä»è€Œæé«˜é‡å»ºçš„ç¨³å®šæ€§ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•æ¥çº¦æŸæ½œåœ¨ç©ºé—´ä¸­çš„æœç´¢ï¼Œç¡®ä¿åè½¬çš„ç¼–ç ä½äºåŸå§‹å›¾åƒæµå½¢ä¸­ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨æœ€ä¼˜æ½œåœ¨ç¼–ç å‘¨å›´æ‰©å±•å›¾åƒå…ˆéªŒï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†é‡å»ºæ•ˆæœã€‚
(4)ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¾ƒå¤§çš„æ”¾å¤§å€æ•°ä¸‹å¯ä»¥æ¢å¤çœŸå®ä¸”é«˜è´¨é‡çš„å›¾åƒã€‚å³ä½¿åœ¨è¾ƒå°çš„æ”¾å¤§å€æ•°ä¸‹ï¼Œå®ƒä»ç„¶å¯ä»¥é‡å»ºç”Ÿæˆå™¨æ— æ³•å•ç‹¬ç”Ÿæˆçš„ç»†èŠ‚ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨è¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸­å®ç°äº†çœŸå®æ€§å’Œä¿çœŸåº¦ä¹‹é—´çš„è‰¯å¥½æƒè¡¡ã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<p></p><p>ï¼ˆ1ï¼‰æ½œåœ¨ç©ºé—´æ­£åˆ™åŒ–ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­çº¦æŸæœç´¢æ¥ç¡®ä¿åè½¬çš„ç¼–ç ä½äºåŸå§‹å›¾åƒæµå½¢ä¸­ã€‚è¯¥æ–¹æ³•é€šè¿‡æœ€å°åŒ–æ½œåœ¨ç¼–ç å’Œç›¸åº”çš„ç”Ÿæˆå›¾åƒä¹‹é—´çš„è·ç¦»æ¥å®ç°ã€‚</p><p></p>
<p></p><p>ï¼ˆ2ï¼‰å›¾åƒå…ˆéªŒæ‰©å±•ï¼šåœ¨æœ€ä¼˜æ½œåœ¨ç¼–ç å‘¨å›´æ‰©å±•å›¾åƒå…ˆéªŒï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºé‡å»ºæ•ˆæœã€‚è¯¥æ–¹æ³•é€šè¿‡ä½¿ç”¨é«˜æ–¯æ ¸å¯¹æœ€ä¼˜æ½œåœ¨ç¼–ç å‘¨å›´çš„æ½œåœ¨ç©ºé—´è¿›è¡ŒåŠ æƒæ¥å®ç°ã€‚</p><p></p>
<p></p><p>ï¼ˆ3ï¼‰è¶…åˆ†è¾¨ç‡é‡å»ºï¼šä½¿ç”¨StyleGANç”Ÿæˆå™¨å°†æ­£åˆ™åŒ–çš„æ½œåœ¨ç¼–ç åè½¬ä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚è¯¥æ–¹æ³•é€šè¿‡æœ€å°åŒ–ç”Ÿæˆçš„å›¾åƒå’Œä½åˆ†è¾¨ç‡è¾“å…¥å›¾åƒä¹‹é—´çš„è·ç¦»æ¥å®ç°ã€‚</p><p></p>
<p></p><ol start="8"><p></p>
<p></p><li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­çº¦æŸæœç´¢æ¥ç¡®ä¿åè½¬çš„ç¼–ç ä½äºåŸå§‹å›¾åƒæµå½¢ä¸­ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨æœ€ä¼˜æ½œåœ¨ç¼–ç å‘¨å›´æ‰©å±•å›¾åƒå…ˆéªŒï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†é‡å»ºæ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¾ƒå¤§çš„æ”¾å¤§å€æ•°ä¸‹å¯ä»¥æ¢å¤çœŸå®ä¸”é«˜è´¨é‡çš„å›¾åƒã€‚å³ä½¿åœ¨è¾ƒå°çš„æ”¾å¤§å€æ•°ä¸‹ï¼Œå®ƒä»ç„¶å¯ä»¥é‡å»ºç”Ÿæˆå™¨æ— æ³•å•ç‹¬ç”Ÿæˆçš„ç»†èŠ‚ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨è¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸­å®ç°äº†çœŸå®æ€§å’Œä¿çœŸåº¦ä¹‹é—´çš„è‰¯å¥½æƒè¡¡ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œé€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­çº¦æŸæœç´¢æ¥ç¡®ä¿åè½¬çš„ç¼–ç ä½äºåŸå§‹å›¾åƒæµå½¢ä¸­ã€‚</li>
<li>é€šè¿‡åœ¨æœ€ä¼˜æ½œåœ¨ç¼–ç å‘¨å›´æ‰©å±•å›¾åƒå…ˆéªŒï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†é‡å»ºæ•ˆæœã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•åœ¨è¾ƒå¤§çš„æ”¾å¤§å€æ•°ä¸‹å¯ä»¥æ¢å¤çœŸå®ä¸”é«˜è´¨é‡çš„å›¾åƒã€‚</li>
<li>å³ä½¿åœ¨è¾ƒå°çš„æ”¾å¤§å€æ•°ä¸‹ï¼Œå®ƒä»ç„¶å¯ä»¥é‡å»ºç”Ÿæˆå™¨æ— æ³•å•ç‹¬ç”Ÿæˆçš„ç»†èŠ‚ã€‚</li>
<li>æ€»ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨è¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸­å®ç°äº†çœŸå®æ€§å’Œä¿çœŸåº¦ä¹‹é—´çš„è‰¯å¥½æƒè¡¡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹StyleGANç”Ÿæˆå™¨è¿›è¡Œé¢„è®­ç»ƒã€‚</li>
<li>éœ€è¦å¯¹æ­£åˆ™åŒ–æ–¹æ³•å’Œå›¾åƒå…ˆéªŒæ‰©å±•æ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚</li>
<li>éœ€è¦å¯¹è¶…åˆ†è¾¨ç‡é‡å»ºæ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-047c7ef399b99c1a231d9dac098cd5ab.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2b9f640a36ad41c3da4593c85263843.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1e5efa0aaad503171165b516b9c711a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1a5de01c1a980dac1eb85f183edcaa69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50f53d31ed0811c18da861677d9c633b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-147a4284c73eb5f49586ed6d811f5b2d.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Animatable-Gaussians-Learning-Pose-dependent-Gaussian-Maps-for-High-fidelity-Human-Avatar-Modeling"><a href="#Animatable-Gaussians-Learning-Pose-dependent-Gaussian-Maps-for-High-fidelity-Human-Avatar-Modeling" class="headerlink" title="Animatable Gaussians: Learning Pose-dependent Gaussian Maps for   High-fidelity Human Avatar Modeling"></a>Animatable Gaussians: Learning Pose-dependent Gaussian Maps for   High-fidelity Human Avatar Modeling</h2><p><strong>Authors:Zhe Li, Zerong Zheng, Lizhen Wang, Yebin Liu</strong></p>
<p>Modeling animatable human avatars from RGB videos is a long-standing and challenging problem. Recent works usually adopt MLP-based neural radiance fields (NeRF) to represent 3D humans, but it remains difficult for pure MLPs to regress pose-dependent garment details. To this end, we introduce Animatable Gaussians, a new avatar representation that leverages powerful 2D CNNs and 3D Gaussian splatting to create high-fidelity avatars. To associate 3D Gaussians with the animatable avatar, we learn a parametric template from the input videos, and then parameterize the template on two front \&amp; back canonical Gaussian maps where each pixel represents a 3D Gaussian. The learned template is adaptive to the wearing garments for modeling looser clothes like dresses. Such template-guided 2D parameterization enables us to employ a powerful StyleGAN-based CNN to learn the pose-dependent Gaussian maps for modeling detailed dynamic appearances. Furthermore, we introduce a pose projection strategy for better generalization given novel poses. Overall, our method can create lifelike avatars with dynamic, realistic and generalized appearances. Experiments show that our method outperforms other state-of-the-art approaches. Code: <a href="https://github.com/lizhe00/AnimatableGaussians">https://github.com/lizhe00/AnimatableGaussians</a> </p>
<p><a href="http://arxiv.org/abs/2311.16096v1">PDF</a> Projectpage: <a href="https://animatable-gaussians.github.io/">https://animatable-gaussians.github.io/</a>, Code:   <a href="https://github.com/lizhe00/AnimatableGaussians">https://github.com/lizhe00/AnimatableGaussians</a></p>
<p><strong>æ¦‚è¿°</strong><br>é‡‡ç”¨å¼ºå¤§çš„äºŒç»´å·ç§¯ç¥ç»ç½‘ç»œå’Œä¸‰ç»´é«˜æ–¯æ‰©æ•£çš„æ–¹å¼æ¥åˆ›ä½œé€¼çœŸçš„è™šæ‹Ÿäººç‰©ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºä¸€ç§æ–°çš„è™šæ‹Ÿå½¢è±¡è¡¨ç¤ºæ³•â€”â€”å¯åŠ¨ç”»é«˜æ–¯ï¼Œå®ƒåˆ©ç”¨å¼ºå¤§çš„äºŒç»´å·ç§¯ç¥ç»ç½‘ç»œå’Œä¸‰ç»´é«˜æ–¯æ‰©æ•£æ¥åˆ›å»ºé€¼çœŸçš„è™šæ‹Ÿå½¢è±¡ã€‚</li>
<li>å­¦ä¹ ä¸€ä¸ªå‚æ•°æ¨¡æ¿ä»è¾“å…¥è§†é¢‘ä¸­ï¼Œç„¶åå°†æ¨¡æ¿å‚æ•°åŒ–åœ¨ä¸¤ä¸ªæ­£é¢&amp;èƒŒé¢è§„èŒƒçš„é«˜æ–¯æ˜ å°„ä¸Šï¼Œæ¯ä¸ªåƒç´ ä»£è¡¨ä¸€ä¸ªä¸‰ç»´é«˜æ–¯ã€‚</li>
<li>å­¦ä¹ çš„æ¨¡æ¿å¯ä»¥é€‚åº”ç©¿çš„è¡£æœæ¥å»ºæ¨¡æ›´å®½æ¾çš„è¡£æœï¼Œå¦‚è¿è¡£è£™ã€‚</li>
<li>åŸºäº StyleGAN çš„å·ç§¯ç¥ç»ç½‘ç»œå­¦ä¹ å§¿åŠ¿ç›¸å…³çš„ Gaussian åœ°å›¾ï¼Œç”¨äºå»ºæ¨¡è¯¦ç»†çš„åŠ¨æ€å¤–è§‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œä»¥ä¾¿åœ¨æ–°çš„å§¿åŠ¿ä¸‹æ›´å¥½åœ°æ³›åŒ–ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œæœ¬æ–¹æ³•ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>ä»£ç ï¼š<a href="https://github.com/lizhe00/AnimatableGaussians">https://github.com/lizhe00/AnimatableGaussians</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>é¢˜ç›®ï¼šå¯åŠ¨ç”»çš„é«˜æ–¯ä½“ï¼šå­¦ä¹ å§¿åŠ¿ä¾èµ–çš„é«˜æ–¯æ˜ å°„</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šZhe Li, Menglei Chai, Yinda Zhang, Jingyi Yu, Jingyi Yu</p>
</li><p></p>
<p></p><li><p>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€åŠ¨ç”»ã€é«˜æ–¯ä½“ã€å§¿åŠ¿æŠ•å½±</p>
</li><p></p>
<p></p><li><p>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/lizhe00/AnimatableGaussians</p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå»ºæ¨¡å¯åŠ¨ç”»çš„äººä½“è™šæ‹Ÿå½¢è±¡æ˜¯ä¸€ä¸ªé•¿æœŸå­˜åœ¨ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚æœ€è¿‘çš„å·¥ä½œé€šå¸¸é‡‡ç”¨åŸºäº MLP çš„ç¥ç»è¾å°„åœº (NeRF) æ¥è¡¨ç¤º 3D äººä½“ï¼Œä½†çº¯ MLP å¾ˆéš¾å›å½’å§¿åŠ¿ç›¸å…³çš„æœè£…ç»†èŠ‚ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¯åŠ¨ç”»çš„é«˜æ–¯ä½“ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„è™šæ‹Ÿå½¢è±¡è¡¨ç¤ºï¼Œåˆ©ç”¨å¼ºå¤§çš„ 2D CNN å’Œ 3D é«˜æ–¯ä½“ splatting æ¥åˆ›å»ºé«˜ä¿çœŸè™šæ‹Ÿå½¢è±¡ã€‚ä¸ºäº†å°† 3D é«˜æ–¯ä½“ä¸å¯åŠ¨ç”»è™šæ‹Ÿå½¢è±¡ç›¸å…³è”ï¼Œæˆ‘ä»¬ä»è¾“å…¥è§†é¢‘ä¸­å­¦ä¹ äº†ä¸€ä¸ªå‚æ•°åŒ–æ¨¡æ¿ï¼Œç„¶ååœ¨ä¸¤ä¸ªæ­£é¢å’ŒèƒŒé¢è§„èŒƒé«˜æ–¯å›¾ä¸Šå¯¹æ¨¡æ¿è¿›è¡Œå‚æ•°åŒ–ï¼Œå…¶ä¸­æ¯ä¸ªåƒç´ éƒ½è¡¨ç¤ºä¸€ä¸ª 3D é«˜æ–¯ä½“ã€‚å­¦ä¹ åˆ°çš„æ¨¡æ¿å¯ä»¥é€‚åº”ç©¿ç€çš„æœè£…ï¼Œä»¥å»ºæ¨¡æ›´å®½æ¾çš„è¡£æœï¼Œå¦‚è¿è¡£è£™ã€‚è¿™ç§æ¨¡æ¿å¼•å¯¼çš„ 2D å‚æ•°åŒ–ä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨å¼ºå¤§çš„åŸºäº StyleGAN çš„ CNN æ¥å­¦ä¹ å§¿åŠ¿ç›¸å…³çš„ Gaussian å›¾ï¼Œä»¥å»ºæ¨¡è¯¦ç»†çš„åŠ¨æ€å¤–è§‚ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œä»¥åœ¨ç»™å®šæ–°é¢–å§¿åŠ¿æ—¶è·å¾—æ›´å¥½çš„æ³›åŒ–ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åˆ›å»ºå…·æœ‰åŠ¨æ€ã€é€¼çœŸå’Œæ³›åŒ–çš„å¤–è§‚çš„é€¼çœŸè™šæ‹Ÿå½¢è±¡ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ THuman4.0 æ•°æ®é›†å’Œ AvatarReX æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡å»ºå‡†ç¡®æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š
(1) å‚æ•°åŒ–æ¨¡æ¿ï¼šæå‡ºäº†ä¸€ç§å‚æ•°åŒ–æ¨¡æ¿ï¼Œè¯¥æ¨¡æ¿ç”±ä¸¤ä¸ªæ­£é¢å’ŒèƒŒé¢è§„èŒƒé«˜æ–¯å›¾ç»„æˆï¼Œæ¯ä¸ªåƒç´ éƒ½è¡¨ç¤ºä¸€ä¸ª 3D é«˜æ–¯ä½“ã€‚è¯¥æ¨¡æ¿å¯ä»¥é€‚åº”ç©¿ç€çš„æœè£…ï¼Œä»¥å»ºæ¨¡æ›´å®½æ¾çš„è¡£æœï¼Œå¦‚è¿è¡£è£™ã€‚
(2) åŸºäº StyleGAN çš„ CNNï¼šåˆ©ç”¨å¼ºå¤§çš„åŸºäº StyleGAN çš„ CNN æ¥å­¦ä¹ å§¿åŠ¿ç›¸å…³çš„ Gaussian å›¾ï¼Œä»¥å»ºæ¨¡è¯¦ç»†çš„åŠ¨æ€å¤–è§‚ã€‚
(3) å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼šå¼•å…¥äº†ä¸€ç§å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œä»¥åœ¨ç»™å®šæ–°é¢–å§¿åŠ¿æ—¶è·å¾—æ›´å¥½çš„æ³›åŒ–ã€‚è¯¥ç­–ç•¥é€šè¿‡å°†è¾“å…¥ä½ç½®å›¾æŠ•å½±åˆ°è®­ç»ƒæ•°æ®é›†ä¸­æœ€æ¥è¿‘çš„å§¿åŠ¿çš„ä½ç½®å›¾ä¸Šæ¥å®ç°ã€‚</p>
</li><p></p>
<p></p><li><p>ç»“è®ºï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<p></p><p>ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯åŠ¨ç”»çš„é«˜æ–¯ä½“è¡¨ç¤ºæ–¹æ³•ï¼Œä½¿ç”¨å¼ºå¤§çš„2DCNNå’Œ3Dé«˜æ–¯ä½“splattingæ¥åˆ›å»ºé«˜ä¿çœŸè™šæ‹Ÿå½¢è±¡ã€‚è¯¥æ–¹æ³•å¯ä»¥åˆ›å»ºå…·æœ‰åŠ¨æ€ã€é€¼çœŸå’Œæ³›åŒ–çš„å¤–è§‚çš„é€¼çœŸè™šæ‹Ÿå½¢è±¡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p><p></p>
<p></p><p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p><p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§å‚æ•°åŒ–æ¨¡æ¿ï¼Œè¯¥æ¨¡æ¿ç”±ä¸¤ä¸ªæ­£é¢å’ŒèƒŒé¢è§„èŒƒé«˜æ–¯å›¾ç»„æˆï¼Œæ¯ä¸ªåƒç´ éƒ½è¡¨ç¤ºä¸€ä¸ª3Dé«˜æ–¯ä½“ã€‚è¯¥æ¨¡æ¿å¯ä»¥é€‚åº”ç©¿ç€çš„æœè£…ï¼Œä»¥å»ºæ¨¡æ›´å®½æ¾çš„è¡£æœï¼Œå¦‚è¿è¡£è£™ã€‚</li>
<li>åˆ©ç”¨å¼ºå¤§çš„åŸºäºStyleGANçš„CNNæ¥å­¦ä¹ å§¿åŠ¿ç›¸å…³çš„Gaussianå›¾ï¼Œä»¥å»ºæ¨¡è¯¦ç»†çš„åŠ¨æ€å¤–è§‚ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§å§¿åŠ¿æŠ•å½±ç­–ç•¥ï¼Œä»¥åœ¨ç»™å®šæ–°é¢–å§¿åŠ¿æ—¶è·å¾—æ›´å¥½çš„æ³›åŒ–ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨THuman4.0æ•°æ®é›†å’ŒAvatarReXæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é‡å»ºå‡†ç¡®æ€§å’Œè§†è§‰è´¨é‡æ–¹é¢ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4f58407bb1da6858a1f8b3afeca5122e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-77ee722883e97eb42525787423c0db90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4ba94c75431413d71052f68f19e06407.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-aec0c4ba5b1b400598aa699437906d07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b30fc2750f7d5972c0541922982b18fe.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Importance-of-Feature-Extraction-in-the-Calculation-of-Frechet-Distance-for-Medical-Imaging"><a href="#Importance-of-Feature-Extraction-in-the-Calculation-of-Frechet-Distance-for-Medical-Imaging" class="headerlink" title="Importance of Feature Extraction in the Calculation of FrÃ©chet   Distance for Medical Imaging"></a>Importance of Feature Extraction in the Calculation of FrÃ©chet   Distance for Medical Imaging</h2><p><strong>Authors:McKell Woodland, Mais Al Taie, Jessica Albuquerque Marques Silva, Mohamed Eltaher, Frank Mohn, Alexander Shieh, Austin Castelo, Suprateek Kundu, Joshua P. Yung, Ankit B. Patel, Kristy K. Brock</strong></p>
<p>Fr\â€™echet Inception Distance is a widely used metric for evaluating synthetic image quality that utilizes an ImageNet-trained InceptionV3 network as a feature extractor. However, its application in medical imaging lacks a standard feature extractor, leading to biased and inconsistent comparisons. This study aimed to compare state-of-the-art feature extractors for computing Fr\â€™echet Distances (FDs) in medical imaging. A StyleGAN2 network was trained with data augmentation techniques tailored for limited data domains on datasets comprising three medical imaging modalities and four anatomical locations. Human evaluation of generative quality (via a visual Turing test) was compared to FDs calculated using ImageNet-trained InceptionV3, ResNet50, SwAV, DINO, and Swin Transformer architectures, in addition to an InceptionV3 network trained on a large medical dataset, RadImageNet. All ImageNet-based extractors were consistent with each other, but only SwAV was significantly correlated with medical expert judgment. The RadImageNet-based FD showed volatility and lacked correlation with human judgment. Caution is advised when using medical image-trained extraction networks in the FD calculation. These networks should be rigorously evaluated on the imaging modality under consideration and publicly released. ImageNet-based extractors, while imperfect, are consistent and widely understood. Training extraction networks with SwAV is a promising approach for synthetic medical image evaluation. </p>
<p><a href="http://arxiv.org/abs/2311.13717v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŒ»å­¦å›¾åƒç”Ÿæˆè´¨é‡è¯„ä»·ä¸­ï¼ŒImageNet é¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨ä¸åŒ»å­¦ä¸“å®¶åˆ¤æ–­ä¸ä¸€è‡´ï¼ŒSwAV æ˜¯å”¯ä¸€æ˜¾è‘—ç›¸å…³çš„ç½‘ç»œã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Fr\â€™echet Inception Distance (FID) æ˜¯ä¸€ç§å¹¿æ³›ç”¨äºè¯„ä¼°åˆæˆå›¾åƒè´¨é‡çš„æŒ‡æ ‡ï¼Œåˆ©ç”¨ ImageNet è®­ç»ƒçš„ InceptionV3 ç½‘ç»œä½œä¸ºç‰¹å¾æå–å™¨ã€‚</li>
<li>åœ¨åŒ»å­¦å›¾åƒä¸­ä½¿ç”¨ FID ç¼ºä¹æ ‡å‡†çš„ç‰¹å¾æå–å™¨ï¼Œå¯¼è‡´æ¯”è¾ƒç»“æœå­˜åœ¨åå·®ä¸”ä¸ä¸€è‡´ã€‚</li>
<li>æœ¬ç ”ç©¶æ—¨åœ¨æ¯”è¾ƒæœ€å…ˆè¿›çš„ç‰¹å¾æå–å™¨ï¼Œç”¨äºè®¡ç®—åŒ»å­¦å›¾åƒä¸­çš„ Fr\â€™echet è·ç¦» (FD)ã€‚</li>
<li>ä½¿ç”¨é’ˆå¯¹æœ‰é™æ•°æ®åŸŸé‡èº«å®šåˆ¶çš„æ•°æ®å¢å¼ºæŠ€æœ¯è®­ç»ƒ StyleGAN2 ç½‘ç»œï¼Œè¯¥æ•°æ®é›†åŒ…æ‹¬ä¸‰ä¸ªåŒ»å­¦å›¾åƒæ¨¡æ€å’Œå››ä¸ªè§£å‰–ä½ç½®ã€‚</li>
<li>å°†ç”Ÿæˆè´¨é‡çš„äººå·¥è¯„ä¼°ï¼ˆé€šè¿‡è§†è§‰å›¾çµæµ‹è¯•ï¼‰ä¸ä½¿ç”¨ ImageNet è®­ç»ƒçš„ InceptionV3ã€ResNet50ã€SwAVã€DINO å’Œ Swin Transformer æ¶æ„ä»¥åŠåœ¨å¤§è§„æ¨¡åŒ»å­¦æ•°æ®é›† RadImageNet ä¸Šè®­ç»ƒçš„ InceptionV3 ç½‘ç»œè®¡ç®—çš„ FD è¿›è¡Œæ¯”è¾ƒã€‚</li>
<li>æ‰€æœ‰åŸºäº ImageNet çš„æå–å™¨å½¼æ­¤ä¸€è‡´ï¼Œä½†åªæœ‰ SwAV ä¸åŒ»å­¦ä¸“å®¶åˆ¤æ–­æ˜¾ç€ç›¸å…³ã€‚</li>
<li>åŸºäº RadImageNet çš„ FD æ˜¾ç¤ºå‡ºä¸ç¨³å®šæ€§ï¼Œå¹¶ä¸”ä¸äººç±»åˆ¤æ–­ç¼ºä¹ç›¸å…³æ€§ã€‚</li>
<li>åœ¨ FD è®¡ç®—ä¸­ä½¿ç”¨åŒ»å­¦å›¾åƒè®­ç»ƒçš„æå–ç½‘ç»œæ—¶åº”è°¨æ…ã€‚è¿™äº›ç½‘ç»œåº”åœ¨æ‰€è€ƒè™‘çš„æˆåƒæ–¹å¼ä¸Šè¿›è¡Œä¸¥æ ¼è¯„ä¼°å¹¶å…¬å¼€å‘å¸ƒã€‚</li>
<li>åŸºäº ImageNet çš„æå–å™¨è™½ç„¶ä¸å®Œç¾ï¼Œä½†å…·æœ‰ä¸€è‡´æ€§ä¸”è¢«å¹¿æ³›ç†è§£ã€‚</li>
<li>ä½¿ç”¨ SwAV è®­ç»ƒæå–ç½‘ç»œæ˜¯åˆæˆåŒ»å­¦å›¾åƒè¯„ä¼°çš„ä¸€ç§æœ‰å‰é€”çš„æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li>é¢˜ç›®ï¼šåŒ»å­¦å›¾åƒ FrÃ©chet è·ç¦»è®¡ç®—ä¸­çš„ç‰¹å¾æå–çš„é‡è¦æ€§</li><p></p>
<p></p><li>ä½œè€…ï¼šMcKell Woodland, Mais Al Taie, Jessica Albuquerque Marques Silva, Mohamed Eltaher, Frank Mohn, Alexander Shieh, Austin Castelo, Suprateek Kundu, Joshua P. Yung, Ankit B. Patel, Kristy K. Brock</li><p></p>
<p></p><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¾·å…‹è¨æ–¯å¤§å­¦å®‰å¾·æ£®ç™Œç—‡ä¸­å¿ƒ</li><p></p>
<p></p><li>å…³é”®è¯ï¼šFrÃ©chet è·ç¦», ç‰¹å¾æå–, åŒ»å­¦å›¾åƒ, ç”Ÿæˆæ¨¡å‹, è‡ªç›‘ç£å­¦ä¹ </li><p></p>
<p></p><li>é“¾æ¥ï¼šNone, Githubï¼šNone</li><p></p>
<p></p><li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šFrÃ©chet è·ç¦»æ˜¯ä¸€ç§å¹¿æ³›ç”¨äºè¯„ä¼°åˆæˆå›¾åƒè´¨é‡çš„åº¦é‡ï¼Œå®ƒåˆ©ç”¨åœ¨ ImageNet ä¸Šè®­ç»ƒçš„ InceptionV3 ç½‘ç»œä½œä¸ºç‰¹å¾æå–å™¨ã€‚ç„¶è€Œï¼Œåœ¨åŒ»å­¦å›¾åƒä¸­çš„åº”ç”¨ç¼ºä¹æ ‡å‡†çš„ç‰¹å¾æå–å™¨ï¼Œå¯¼è‡´æ¯”è¾ƒå­˜åœ¨åå·®å’Œä¸ä¸€è‡´ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨åœ¨å¤§å‹å…¬å¼€åŒ»å­¦æ•°æ®é›†ä¸Šè®­ç»ƒçš„ InceptionV3 ç½‘ç»œæ¥è®¡ç®— FDã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¯èƒ½ä¸é€‚ç”¨äºæœªåŒ…å«åœ¨è¯¥æ•°æ®é›†ä¸­çš„åŒ»å­¦æ¨¡æ€ï¼Œä¾‹å¦‚å†…çª¥é•œæ£€æŸ¥å’Œä¹³æˆ¿ X å…‰æ£€æŸ¥ã€‚å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨è‡ªç›‘ç£ç‰¹å¾æå–å™¨ï¼Œä½†ç°æœ‰ç ”ç©¶è¡¨æ˜ï¼Œè¿™äº›æå–å™¨åœ¨åŒ»å­¦å›¾åƒä¸Šçš„æ€§èƒ½å‚å·®ä¸é½ã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æ¯”è¾ƒäº†ç”¨äºè®¡ç®—åŒ»å­¦å›¾åƒä¸­ FrÃ©chet è·ç¦»çš„å‡ ç§æœ€å…ˆè¿›çš„ç‰¹å¾æå–å™¨ã€‚æˆ‘ä»¬ä½¿ç”¨é’ˆå¯¹æœ‰é™æ•°æ®åŸŸçš„æ•°æ®å¢å¼ºæŠ€æœ¯è®­ç»ƒäº†ä¸€ä¸ª StyleGAN2 ç½‘ç»œï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸‰ä¸ªåŒ»å­¦å½±åƒæ¨¡æ€å’Œå››ä¸ªè§£å‰–ä½ç½®ã€‚æˆ‘ä»¬å°†ç”Ÿæˆè´¨é‡çš„äººå·¥è¯„ä¼°ï¼ˆé€šè¿‡è§†è§‰å›¾çµæµ‹è¯•ï¼‰ä¸ä½¿ç”¨åœ¨ ImageNet ä¸Šè®­ç»ƒçš„ InceptionV3ã€ResNet50ã€SwAVã€DINO å’Œ SwinTransformer æ¶æ„ä»¥åŠåœ¨å¤§å‹åŒ»å­¦æ•°æ®é›† RadImageNet ä¸Šè®­ç»ƒçš„ InceptionV3 ç½‘ç»œè®¡ç®—çš„ FD è¿›è¡Œäº†æ¯”è¾ƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæ‰€æœ‰åŸºäº ImageNet çš„æå–å™¨å½¼æ­¤ä¸€è‡´ï¼Œä½†åªæœ‰ SwAV ä¸åŒ»å­¦ä¸“å®¶çš„åˆ¤æ–­æ˜¾ç€ç›¸å…³ã€‚åŸºäº RadImageNet çš„ FD æ˜¾ç¤ºå‡ºä¸ç¨³å®šæ€§ï¼Œå¹¶ä¸”ä¸äººç±»åˆ¤æ–­ç¼ºä¹ç›¸å…³æ€§ã€‚åœ¨ FD è®¡ç®—ä¸­ä½¿ç”¨åŒ»å­¦å›¾åƒè®­ç»ƒçš„æå–ç½‘ç»œæ—¶åº”è°¨æ…ã€‚è¿™äº›ç½‘ç»œåº”è¯¥åœ¨è€ƒè™‘çš„æˆåƒæ–¹å¼ä¸Šè¿›è¡Œä¸¥æ ¼è¯„ä¼°å¹¶å…¬å¼€å‘å¸ƒã€‚ImageNet-base çš„æå–å™¨è™½ç„¶ä¸å®Œç¾ï¼Œä½†å®ƒä»¬ä¸€è‡´ä¸”è¢«å¹¿æ³›ç†è§£ã€‚ä½¿ç”¨ SwAV è®­ç»ƒæå–ç½‘ç»œæ˜¯åˆæˆåŒ»å­¦å›¾åƒè¯„ä¼°çš„ä¸€ç§å¾ˆæœ‰å‰é€”çš„æ–¹æ³•ã€‚</li><br>&lt;/ol&gt;<p></p>
<p></p><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><p></p>
<p></p><ol start="8"><p></p>
<p></p><li>ç»“è®ºï¼š
(1): æœ¬æ–‡æ¯”è¾ƒäº†ç”¨äºè®¡ç®—åŒ»å­¦å›¾åƒä¸­ FrÃ©chet è·ç¦»çš„å‡ ç§æœ€å…ˆè¿›çš„ç‰¹å¾æå–å™¨ï¼Œå‘ç°åŸºäº ImageNet çš„æå–å™¨å½¼æ­¤ä¸€è‡´ï¼Œä½†åªæœ‰ SwAV ä¸åŒ»å­¦ä¸“å®¶çš„åˆ¤æ–­æ˜¾ç€ç›¸å…³ã€‚åŸºäº RadImageNet çš„ FrÃ©chet è·ç¦»æ˜¾ç¤ºå‡ºä¸ç¨³å®šæ€§ï¼Œå¹¶ä¸”ä¸äººç±»åˆ¤æ–­ç¼ºä¹ç›¸å…³æ€§ã€‚åœ¨ FrÃ©chet è·ç¦»è®¡ç®—ä¸­ä½¿ç”¨åŒ»å­¦å›¾åƒè®­ç»ƒçš„æå–ç½‘ç»œæ—¶åº”è°¨æ…ã€‚è¿™äº›ç½‘ç»œåº”è¯¥åœ¨è€ƒè™‘çš„æˆåƒæ–¹å¼ä¸Šè¿›è¡Œä¸¥æ ¼è¯„ä¼°å¹¶å…¬å¼€å‘å¸ƒã€‚ImageNet-base çš„æå–å™¨è™½ç„¶ä¸å®Œç¾ï¼Œä½†å®ƒä»¬ä¸€è‡´ä¸”è¢«å¹¿æ³›ç†è§£ã€‚ä½¿ç”¨ SwAV è®­ç»ƒæå–ç½‘ç»œæ˜¯åˆæˆåŒ»å­¦å›¾åƒè¯„ä¼°çš„ä¸€ç§å¾ˆæœ‰å‰é€”çš„æ–¹æ³•ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æ¯”è¾ƒäº†ç”¨äºè®¡ç®—åŒ»å­¦å›¾åƒä¸­ FrÃ©chet è·ç¦»çš„å‡ ç§æœ€å…ˆè¿›çš„ç‰¹å¾æå–å™¨ã€‚</li>
<li>å‘ç°åŸºäº ImageNet çš„æå–å™¨å½¼æ­¤ä¸€è‡´ï¼Œä½†åªæœ‰ SwAV ä¸åŒ»å­¦ä¸“å®¶çš„åˆ¤æ–­æ˜¾ç€ç›¸å…³ã€‚</li>
<li>åŸºäº RadImageNet çš„ FrÃ©chet è·ç¦»æ˜¾ç¤ºå‡ºä¸ç¨³å®šæ€§ï¼Œå¹¶ä¸”ä¸äººç±»åˆ¤æ–­ç¼ºä¹ç›¸å…³æ€§ã€‚</li>
<li>åœ¨ FrÃ©chet è·ç¦»è®¡ç®—ä¸­ä½¿ç”¨åŒ»å­¦å›¾åƒè®­ç»ƒçš„æå–ç½‘ç»œæ—¶åº”è°¨æ…ã€‚</li>
<li>ä½¿ç”¨ SwAV è®­ç»ƒæå–ç½‘ç»œæ˜¯åˆæˆåŒ»å­¦å›¾åƒè¯„ä¼°çš„ä¸€ç§å¾ˆæœ‰å‰é€”çš„æ–¹æ³•ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åŸºäº ImageNet çš„æå–å™¨å½¼æ­¤ä¸€è‡´ï¼Œä½†åªæœ‰ SwAV ä¸åŒ»å­¦ä¸“å®¶çš„åˆ¤æ–­æ˜¾ç€ç›¸å…³ã€‚</li>
<li>åŸºäº RadImageNet çš„ FrÃ©chet è·ç¦»æ˜¾ç¤ºå‡ºä¸ç¨³å®šæ€§ï¼Œå¹¶ä¸”ä¸äººç±»åˆ¤æ–­ç¼ºä¹ç›¸å…³æ€§ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>éœ€è¦æ¯”è¾ƒå¤šç§ç‰¹å¾æå–å™¨ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
<li>éœ€è¦åœ¨åŒ»å­¦å›¾åƒä¸Šè®­ç»ƒæå–ç½‘ç»œï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3a98d200e6662a30834d463110beefc2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9c2de329d902d2836a266714f60f4842.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-855d1b05e045ac53d6b4a972ad2848dd.jpg" align="middle">
</details><br>â€‹    <p></p>
<p>â€‹    </p>
</ol></ol></ol></ol></ol>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/01/30/Paper/2024-01-30/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-30-æ›´æ–°"><a href="#2024-01-30-æ›´æ–°" class="headerlink" title="2024-01-30 æ›´æ–°"></a>2024-01-30 æ›´æ–°</h1><h2 id="EndoGaussians-Single-View-Dynamic-Gaussian-Splatting-for-Deformable-Endoscopic-Tissues-Reconstruction"><a href="#EndoGaussians-Single-View-Dynamic-Gaussian-Splatting-for-Deformable-Endoscopic-Tissues-Reconstruction" class="headerlink" title="EndoGaussians: Single View Dynamic Gaussian Splatting for Deformable   Endoscopic Tissues Reconstruction"></a>EndoGaussians: Single View Dynamic Gaussian Splatting for Deformable   Endoscopic Tissues Reconstruction</h2><p><strong>Authors:Yangsen Chen, Hao Wang</strong></p>
<p>The accurate 3D reconstruction of deformable soft body tissues from endoscopic videos is a pivotal challenge in medical applications such as VR surgery and medical image analysis. Existing methods often struggle with accuracy and the ambiguity of hallucinated tissue parts, limiting their practical utility. In this work, we introduce EndoGaussians, a novel approach that employs Gaussian Splatting for dynamic endoscopic 3D reconstruction. This method marks the first use of Gaussian Splatting in this context, overcoming the limitations of previous NeRF-based techniques. Our method sets new state-of-the-art standards, as demonstrated by quantitative assessments on various endoscope datasets. These advancements make our method a promising tool for medical professionals, offering more reliable and efficient 3D reconstructions for practical applications in the medical field. </p>
<p><a href="http://arxiv.org/abs/2401.13352v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>é«˜æ–¯æ•£ç‚¹ç»“åˆç¥ç»è¾å°„åœºï¼Œå®ç°åŠ¨æ€å†…çª¥é•œ 3D é‡å»ºæ–°æ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>EndoGaussians æ˜¯ä¸€ä¸ªæ–°çš„æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨é«˜æ–¯æ•£ç‚¹è¿›è¡ŒåŠ¨æ€å†…çª¥é•œ 3D é‡å»ºã€‚</li>
<li>è¿™ç§æ–¹æ³•æ˜¯é¦–æ¬¡åœ¨è¯¥èƒŒæ™¯ä¸‹ä½¿ç”¨é«˜æ–¯æ•£ç‚¹ï¼Œå…‹æœäº†ä»¥å‰åŸºäº NeRF æŠ€æœ¯çš„é™åˆ¶ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å„ç§å†…çª¥é•œæ•°æ®é›†ä¸Šè¿›è¡Œå®šé‡è¯„ä¼°ï¼Œæ ‘ç«‹äº†æ–°çš„æœ€å…ˆè¿›æ ‡å‡†ã€‚</li>
<li>è¿™äº›è¿›æ­¥ä½¿è¯¥æ–¹æ³•æˆä¸ºåŒ»ç–—ä¸“ä¸šäººå‘˜çš„æœ‰å‰é€”çš„å·¥å…·ï¼Œä¸ºåŒ»ç–—é¢†åŸŸçš„å®é™…åº”ç”¨æä¾›äº†æ›´å¯é ã€æ›´é«˜æ•ˆçš„ 3D é‡å»ºã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šEndoGaussiansï¼šå•è§†åŠ¨æ€é«˜æ–¯ä½“ç´ é‡å»º</li>
<li>ä½œè€…ï¼šYangsen Chen, Hao Wang</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦ï¼ˆå¹¿å·ï¼‰</li>
<li>å…³é”®è¯ï¼š3D é‡å»ºã€é«˜æ–¯ä½“ç´ é‡å»ºã€æœºå™¨äººæ‰‹æœ¯</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.13352</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šå‡†ç¡®åœ°ä»å†…çª¥é•œè§†é¢‘ä¸­é‡å»ºå¯å˜å½¢è½¯ä½“ç»„ç»‡çš„ 3D æ¨¡å‹å¯¹äº VR æ‰‹æœ¯å’ŒåŒ»å­¦å›¾åƒåˆ†æç­‰åŒ»ç–—åº”ç”¨è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åœ¨å‡†ç¡®æ€§å’Œäº§ç”Ÿçš„ç»„ç»‡éƒ¨åˆ†çš„æ¨¡æ£±ä¸¤å¯æ–¹é¢å­˜åœ¨é—®é¢˜ï¼Œé™åˆ¶äº†å…¶å®é™…æ•ˆç”¨ã€‚
(2) è¿‡å¾€æ–¹æ³•ï¼šä»¥å¾€çš„ä¸€äº›å·¥ä½œå°è¯•ä½¿ç”¨æ·±åº¦ä¼°è®¡ã€SLAMã€ç¨€ç–å˜å½¢åœºå’Œç¥ç»è¾å°„åœºç­‰æ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†è¿™äº›æ–¹æ³•è¦ä¹ˆå‡è®¾åœºæ™¯æ˜¯é™æ€çš„ï¼Œè¦ä¹ˆå‡è®¾æ‰‹æœ¯å·¥å…·ä¸å­˜åœ¨ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬åœ¨å®é™…åœºæ™¯ä¸­çš„å®ç”¨æ€§ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è¿›ä¸€æ­¥æé«˜é™æ€å•è§† RGBD è®¾ç½®ä¸‹è½¯ä½“ç»„ç»‡çš„ 3D é‡å»ºçš„å‡†ç¡®æ€§ï¼Œå¹¶æé«˜ 3D é‡å»ºçš„å¯é æ€§å’Œå¯ä¿¡åº¦ï¼Œæˆ‘ä»¬æå‡ºäº† Endogaussiansï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é«˜æ–¯ä½“ç´ é‡å»ºä½œä¸ºé‡å»ºæ–¹æ³•ã€‚
(4) æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨ PSNRã€SSIMã€LPIPS ç­‰å¤šé¡¹å®šé‡è¯„ä¼°ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶ä¸”é‡å»ºé€Ÿåº¦æ›´å¿«ã€‚è¿™äº›è¿›æ­¥ä½¿æˆ‘ä»¬çš„æ–¹æ³•æˆä¸ºåŒ»ç–—ä¸“ä¸šäººå‘˜çš„æœ‰å‰é€”çš„å·¥å…·ï¼Œä¸ºåŒ»ç–—é¢†åŸŸçš„å®é™…åº”ç”¨æä¾›æ›´å¯é å’Œé«˜æ•ˆçš„ 3D é‡å»ºã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º Endogaussians çš„æ–¹æ³•ï¼Œç”¨äºä»å•ç›®åŠ¨æ€ RGBD è®¾ç½®ä¸­é‡å»ºå¯å˜å½¢è½¯ä½“ç»„ç»‡çš„ 3D æ¨¡å‹ã€‚
(2): è¯¥æ–¹æ³•ä½¿ç”¨é«˜æ–¯ä½“ç´ é‡å»ºä½œä¸ºé‡å»ºæ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¤„ç†è½¯ä½“ç»„ç»‡çš„å˜å½¢ã€‚
(3): ä¸ºäº†æé«˜é‡å»ºçš„å‡†ç¡®æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä½“ç´ èåˆç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æœ‰æ•ˆåœ°èåˆæ¥è‡ªä¸åŒå¸§çš„æ•°æ®ã€‚
(4): æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„ä½“ç´ åˆ†å‰²ç®—æ³•ï¼Œè¯¥ç®—æ³•å¯ä»¥æœ‰æ•ˆåœ°å°†è½¯ä½“ç»„ç»‡åˆ†å‰²æˆä¸åŒçš„éƒ¨åˆ†ã€‚
(5): æœ€åï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä½“ç´ æ¸²æŸ“ç®—æ³•ï¼Œè¯¥ç®—æ³•å¯ä»¥ç”Ÿæˆé€¼çœŸçš„è½¯ä½“ç»„ç»‡æ¨¡å‹ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šEndoGaussiansæ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°ä»å•ç›®åŠ¨æ€RGBDè®¾ç½®ä¸­é‡å»ºå¯å˜å½¢è½¯ä½“ç»„ç»‡çš„3Dæ¨¡å‹ï¼Œå…·æœ‰è¾ƒé«˜çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œåœ¨åŒ»ç–—é¢†åŸŸå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é«˜æ–¯ä½“ç´ é‡å»ºæ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¤„ç†è½¯ä½“ç»„ç»‡çš„å˜å½¢ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä½“ç´ èåˆç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°èåˆæ¥è‡ªä¸åŒå¸§çš„æ•°æ®ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä½“ç´ åˆ†å‰²ç®—æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°†è½¯ä½“ç»„ç»‡åˆ†å‰²æˆä¸åŒçš„éƒ¨åˆ†ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ä½“ç´ æ¸²æŸ“ç®—æ³•ï¼Œå¯ä»¥ç”Ÿæˆé€¼çœŸçš„è½¯ä½“ç»„ç»‡æ¨¡å‹ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨PSNRã€SSIMã€LPIPSç­‰å¤šé¡¹å®šé‡è¯„ä¼°ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</li>
<li>é‡å»ºé€Ÿåº¦æ›´å¿«ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-049a97b3607a44946b481425f04f7d64.jpg" align="middle">
</details>




<h2 id="EndoGaussian-Gaussian-Splatting-for-Deformable-Surgical-Scene-Reconstruction"><a href="#EndoGaussian-Gaussian-Splatting-for-Deformable-Surgical-Scene-Reconstruction" class="headerlink" title="EndoGaussian: Gaussian Splatting for Deformable Surgical Scene   Reconstruction"></a>EndoGaussian: Gaussian Splatting for Deformable Surgical Scene   Reconstruction</h2><p><strong>Authors:Yifan Liu, Chenxin Li, Chen Yang, Yixuan Yuan</strong></p>
<p>Reconstructing deformable tissues from endoscopic stereo videos is essential in many downstream surgical applications. However, existing methods suffer from slow inference speed, which greatly limits their practical use. In this paper, we introduce EndoGaussian, a real-time surgical scene reconstruction framework that builds on 3D Gaussian Splatting. Our framework represents dynamic surgical scenes as canonical Gaussians and a time-dependent deformation field, which predicts Gaussian deformations at novel timestamps. Due to the efficient Gaussian representation and parallel rendering pipeline, our framework significantly accelerates the rendering speed compared to previous methods. In addition, we design the deformation field as the combination of a lightweight encoding voxel and an extremely tiny MLP, allowing for efficient Gaussian tracking with a minor rendering burden. Furthermore, we design a holistic Gaussian initialization method to fully leverage the surface distribution prior, achieved by searching informative points from across the input image sequence. Experiments on public endoscope datasets demonstrate that our method can achieve real-time rendering speed (195 FPS real-time, 100$\times$ gain) while maintaining the state-of-the-art reconstruction quality (35.925 PSNR) and the fastest training speed (within 2 min/scene), showing significant promise for intraoperative surgery applications. Code is available at: \url{<a href="https://yifliu3.github.io/EndoGaussian/}">https://yifliu3.github.io/EndoGaussian/}</a>. </p>
<p><a href="http://arxiv.org/abs/2401.12561v1">PDF</a> </p>
<p><strong>Summary</strong><br>3Dé«˜æ–¯æ¸²æŸ“æ¡†æ¶å®ç°äº†å®æ—¶å†…çª¥é•œæ‰‹æœ¯åœºæ™¯é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§åä¸ºEndoGaussiançš„å®æ—¶æ‰‹æœ¯åœºæ™¯é‡å»ºæ¡†æ¶ï¼Œå®ƒæ˜¯å»ºç«‹åœ¨3Dé«˜æ–¯ç‚¹é˜µçš„åŸºç¡€ä¸Šçš„ã€‚</li>
<li>ä½¿ç”¨é«˜æ–¯è¡¨ç¤ºå’Œå¹¶è¡Œæ¸²æŸ“ç®¡é“ï¼Œæ˜¾è‘—æé«˜äº†æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>å°†å˜å½¢åœºè®¾è®¡ä¸ºè½»é‡çº§ç¼–ç ä½“ç´ å’Œæå°MLPçš„ç»„åˆï¼Œå®ç°äº†é«˜æ•ˆçš„é«˜æ–¯è·Ÿè¸ªï¼Œæ¸²æŸ“è´Ÿæ‹…è¾ƒå°ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§æ•´ä½“çš„é«˜æ–¯åˆå§‹åŒ–æ–¹æ³•ï¼Œå……åˆ†åˆ©ç”¨äº†è¡¨é¢åˆ†å¸ƒå…ˆéªŒï¼Œé€šè¿‡æœç´¢è¾“å…¥å›¾åƒåºåˆ—ä¸­çš„ä¿¡æ¯ç‚¹æ¥å®ç°ã€‚</li>
<li>å…¬å…±å†…çª¥é•œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥å®ç°å®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼ˆ195 FPSå®æ—¶ï¼Œ100å€æ”¶ç›Šï¼‰ï¼ŒåŒæ—¶ä¿æŒæœ€å…ˆè¿›çš„é‡å»ºè´¨é‡ï¼ˆ35.925 PSNRï¼‰å’Œæœ€å¿«çš„è®­ç»ƒé€Ÿåº¦ï¼ˆåœ¨2åˆ†é’Ÿ/åœºæ™¯ä»¥å†…ï¼‰ï¼Œæ˜¾ç¤ºå‡ºå¯¹æœ¯ä¸­æ‰‹æœ¯åº”ç”¨çš„é‡å¤§å‰æ™¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šEndoGaussianï¼šç”¨äºå¯å˜å½¢æ‰‹æœ¯åœºæ™¯é‡å»ºçš„é«˜æ–¯ç‚¹äº‘</li>
<li>ä½œè€…ï¼šYifan Liu<em>, Chenxin Li</em>, Chen Yang å’Œ Yixuan Yuan</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li>
<li>å…³é”®è¯ï¼šä¸‰ç»´é‡å»º Â· é«˜æ–¯ç‚¹äº‘ Â· æœºå™¨äººæ‰‹æœ¯</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12561
   Github ä»£ç é“¾æ¥ï¼šhttps://yifliu3.github.io/EndoGaussian/</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä»å†…çª¥é•œç«‹ä½“è§†é¢‘ä¸­é‡å»ºå¯å˜å½¢ç»„ç»‡å¯¹äºè®¸å¤šä¸‹æ¸¸æ‰‹æœ¯åº”ç”¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•çš„æ¨ç†é€Ÿåº¦æ…¢ï¼Œæå¤§åœ°é™åˆ¶äº†å®ƒä»¬çš„å®é™…ä½¿ç”¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•çš„é—®é¢˜åœ¨äºæ¨ç†é€Ÿåº¦æ…¢ï¼Œè¿™ä½¿å¾—å®ƒä»¬åœ¨å®é™…åº”ç”¨ä¸­å—åˆ°é™åˆ¶ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šè¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯ç‚¹äº‘çš„å®æ—¶æ‰‹æœ¯åœºæ™¯é‡å»ºæ¡†æ¶ EndoGaussianã€‚è¯¥æ¡†æ¶å°†åŠ¨æ€æ‰‹æœ¯åœºæ™¯è¡¨ç¤ºä¸ºè§„èŒƒé«˜æ–¯ç‚¹äº‘å’Œæ—¶é—´ç›¸å…³çš„å˜å½¢åœºï¼Œè¯¥å˜å½¢åœºå¯ä»¥é¢„æµ‹æ–°æ—¶é—´æˆ³ä¸‹çš„é«˜æ–¯å˜å½¢ã€‚ç”±äºé«˜æ•ˆçš„é«˜æ–¯è¡¨ç¤ºå’Œå¹¶è¡Œæ¸²æŸ“ç®¡é“ï¼Œè¯¥æ¡†æ¶ä¸ä»¥å¾€æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—åœ°æé«˜äº†æ¸²æŸ“é€Ÿåº¦ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡å°†å˜å½¢åœºè®¾è®¡ä¸ºè½»é‡çº§ç¼–ç ä½“ç´ å’Œæå°å‹çš„ MLP çš„ç»„åˆï¼Œä»è€Œå®ç°é«˜æ•ˆçš„é«˜æ–¯è·Ÿè¸ªï¼Œä¸”æ¸²æŸ“è´Ÿæ‹…å¾ˆå°ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡è®¾è®¡äº†ä¸€ç§æ•´ä½“çš„é«˜æ–¯åˆå§‹åŒ–æ–¹æ³•ï¼Œä»¥å……åˆ†åˆ©ç”¨è¡¨é¢åˆ†å¸ƒå…ˆéªŒï¼Œè¯¥æ–¹æ³•é€šè¿‡ä»è¾“å…¥å›¾åƒåºåˆ—ä¸­æœç´¢ä¿¡æ¯ç‚¹æ¥å®ç°ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨å…¬å¼€å†…çª¥é•œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥å®ç°å®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼ˆ195 FPS å®æ—¶ï¼Œ100 å€å¢ç›Šï¼‰ï¼ŒåŒæ—¶ä¿æŒæœ€å…ˆè¿›çš„é‡å»ºè´¨é‡ï¼ˆ35.925 PSNRï¼‰å’Œæœ€å¿«çš„è®­ç»ƒé€Ÿåº¦ï¼ˆæ¯ä¸ªåœºæ™¯ 2 åˆ†é’Ÿä»¥å†…ï¼‰ï¼Œæ˜¾ç¤ºå‡ºå¯¹æœ¯ä¸­æ‰‹æœ¯åº”ç”¨çš„é‡å¤§å‰æ™¯ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰EndoGaussianæ¡†æ¶æ¦‚è¿°ï¼šè¯¥æ¡†æ¶ç”±é«˜æ–¯ç‚¹äº‘åˆå§‹åŒ–ã€é«˜æ–¯è·Ÿè¸ªå’Œé«˜æ–¯æ¸²æŸ“ä¸‰ä¸ªæ¨¡å—ç»„æˆã€‚
ï¼ˆ2ï¼‰é«˜æ–¯ç‚¹äº‘åˆå§‹åŒ–ï¼šä»è¾“å…¥å›¾åƒåºåˆ—ä¸­æœç´¢ä¿¡æ¯ç‚¹ï¼Œé€šè¿‡é«˜æ–¯æ··åˆæ¨¡å‹ä¼°è®¡ç‚¹äº‘å‚æ•°ï¼Œå¹¶é€šè¿‡è¡¨é¢åˆ†å¸ƒå…ˆéªŒä¼˜åŒ–ç‚¹äº‘ä½ç½®ã€‚
ï¼ˆ3ï¼‰é«˜æ–¯è·Ÿè¸ªï¼šå°†å˜å½¢åœºè®¾è®¡ä¸ºè½»é‡çº§ç¼–ç ä½“ç´ å’Œæå°å‹çš„MLPçš„ç»„åˆï¼Œé€šè¿‡å°†å½“å‰æ—¶é—´æˆ³çš„é«˜æ–¯ç‚¹äº‘å˜å½¢åˆ°æ–°æ—¶é—´æˆ³ï¼Œå®ç°é«˜æ•ˆçš„é«˜æ–¯è·Ÿè¸ªã€‚
ï¼ˆ4ï¼‰é«˜æ–¯æ¸²æŸ“ï¼šåˆ©ç”¨é«˜æ–¯ç‚¹äº‘çš„å‡ ä½•ç‰¹æ€§å’Œå¹¶è¡Œæ¸²æŸ“ç®¡é“ï¼Œå®ç°é«˜æ•ˆçš„æ¸²æŸ“ã€‚
ï¼ˆ5ï¼‰è®­ç»ƒç»†èŠ‚ï¼šä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œå­¦ä¹ ç‡ä¸º1e-4ï¼Œæ‰¹å¤§å°ä¸º8ï¼Œè®­ç»ƒ200ä¸ªå‘¨æœŸã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§å®æ—¶ä¸”é«˜è´¨é‡çš„ 4D é‡å»ºæ¡†æ¶ï¼Œç”¨äºåŠ¨æ€æ‰‹æœ¯åœºæ™¯é‡å»ºã€‚é€šè¿‡åˆ©ç”¨åŸºäºä½“ç´ çš„é«˜æ–¯è·Ÿè¸ªå’Œæ•´ä½“é«˜æ–¯åˆå§‹åŒ–ï¼Œæˆ‘ä»¬èƒ½å¤Ÿå¤„ç†ç»„ç»‡å˜å½¢å’Œéå¹³å‡¡çš„é«˜æ–¯åˆå§‹åŒ–é—®é¢˜ã€‚å…¨é¢çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ EndoGaussian å¯ä»¥å®ç°æœ€å…ˆè¿›çš„é‡å»ºè´¨é‡å’Œå®æ—¶çš„æ¸²æŸ“é€Ÿåº¦ï¼Œæ¯”ä»¥å‰çš„æ–¹æ³•å¿« 100 å€ä»¥ä¸Šã€‚æˆ‘ä»¬å¸Œæœ›æ–°å…´çš„åŸºäºé«˜æ–¯æ–‘ç‚¹çš„é‡å»ºæŠ€æœ¯èƒ½å¤Ÿä¸ºæœºå™¨äººæ‰‹æœ¯åœºæ™¯ç†è§£æä¾›æ–°çš„é€”å¾„ï¼Œå¹¶å¢å¼ºå„ç§ä¸‹æ¸¸ä¸´åºŠä»»åŠ¡ï¼Œå°¤å…¶æ˜¯æœ¯ä¸­åº”ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>åŸºäºé«˜æ–¯ç‚¹äº‘çš„å®æ—¶æ‰‹æœ¯åœºæ™¯é‡å»ºæ¡†æ¶ã€‚</li>
<li>ä½“ç´ ç¼–ç çš„é«˜æ–¯è·Ÿè¸ªï¼Œå®ç°äº†é«˜æ•ˆçš„é«˜æ–¯è·Ÿè¸ªã€‚</li>
<li>æ•´ä½“é«˜æ–¯åˆå§‹åŒ–æ–¹æ³•ï¼Œå……åˆ†åˆ©ç”¨è¡¨é¢åˆ†å¸ƒå…ˆéªŒã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å…¬å¼€å†…çª¥é•œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥å®ç°å®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼ˆ195FPS å®æ—¶ï¼Œ100 å€å¢ç›Šï¼‰ï¼ŒåŒæ—¶ä¿æŒæœ€å…ˆè¿›çš„é‡å»ºè´¨é‡ï¼ˆ35.925PSNRï¼‰å’Œæœ€å¿«çš„è®­ç»ƒé€Ÿåº¦ï¼ˆæ¯ä¸ªåœºæ™¯ 2 åˆ†é’Ÿä»¥å†…ï¼‰ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®ºæ–‡çš„ä»£ç å’Œæ•°æ®å·²ç»å¼€æºï¼Œå¯ä»¥æ–¹ä¾¿åœ°è¿›è¡Œå¤ç°ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0b9bca825762ac8e0bbad3078a233ed1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e1d91551398571ef4d862b170f54e4fc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d93c7e9f9dfadf417d2add6f22082d7e.jpg" align="middle">
</details>




<h2 id="Deformable-Endoscopic-Tissues-Reconstruction-with-Gaussian-Splatting"><a href="#Deformable-Endoscopic-Tissues-Reconstruction-with-Gaussian-Splatting" class="headerlink" title="Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting"></a>Deformable Endoscopic Tissues Reconstruction with Gaussian Splatting</h2><p><strong>Authors:Lingting Zhu, Zhao Wang, Zhenchao Jin, Guying Lin, Lequan Yu</strong></p>
<p>Surgical 3D reconstruction is a critical area of research in robotic surgery, with recent works adopting variants of dynamic radiance fields to achieve success in 3D reconstruction of deformable tissues from single-viewpoint videos. However, these methods often suffer from time-consuming optimization or inferior quality, limiting their adoption in downstream tasks. Inspired by 3D Gaussian Splatting, a recent trending 3D representation, we present EndoGS, applying Gaussian Splatting for deformable endoscopic tissue reconstruction. Specifically, our approach incorporates deformation fields to handle dynamic scenes, depth-guided supervision to optimize 3D targets with a single viewpoint, and a spatial-temporal weight mask to mitigate tool occlusion. As a result, EndoGS reconstructs and renders high-quality deformable endoscopic tissues from a single-viewpoint video, estimated depth maps, and labeled tool masks. Experiments on DaVinci robotic surgery videos demonstrate that EndoGS achieves superior rendering quality. Code is available at <a href="https://github.com/HKU-MedAI/EndoGS">https://github.com/HKU-MedAI/EndoGS</a>. </p>
<p><a href="http://arxiv.org/abs/2401.11535v1">PDF</a> Work in progress. 10 pages, 4 figures</p>
<p><strong>æ‘˜è¦</strong><br>åŠ¨æ€é«˜æ–¯æº…å°„ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>EndoGS åˆ©ç”¨é«˜æ–¯æº…å°„è¿›è¡Œå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚</li>
<li>è¯¥æ–¹æ³•ç»“åˆå˜å½¢åœºä»¥å¤„ç†åŠ¨æ€åœºæ™¯ã€‚</li>
<li>æ·±åº¦å¼•å¯¼ç›‘ç£ç”¨äºä¼˜åŒ–å…·æœ‰å•ä¸ªè§†ç‚¹çš„ 3D ç›®æ ‡ã€‚</li>
<li>æ—¶ç©ºæƒé‡æ©ç å¯å‡è½»å·¥å…·é®æŒ¡ã€‚</li>
<li>EndoGS å¯ä»¥ä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡è®°çš„å·¥å…·æ©ç ä¸­é‡å»ºå’Œæ¸²æŸ“é«˜è´¨é‡çš„å¯å˜å½¢å†…çª¥é•œç»„ç»‡ã€‚</li>
<li>åœ¨ DaVinci æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEndoGS å®ç°å“è¶Šçš„æ¸²æŸ“è´¨é‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šé«˜æ–¯æ–‘ç‚¹å¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»º</li>
<li>ä½œè€…ï¼šLingting Zhu, Zhao Wang, Zhenchao Jin, Guying Lin, Lequan Yu</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šé«˜æ–¯æ–‘ç‚¹Â·æœºå™¨äººæ‰‹æœ¯Â·ä¸‰ç»´é‡å»º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11535, Github é“¾æ¥ï¼šhttps://github.com/HKU-MedAI/EndoGS</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ‰‹æœ¯ä¸‰ç»´é‡å»ºæ˜¯æœºå™¨äººæ‰‹æœ¯ç ”ç©¶çš„ä¸€ä¸ªå…³é”®é¢†åŸŸï¼Œæœ€è¿‘çš„å·¥ä½œé‡‡ç”¨åŠ¨æ€è¾å°„åœºå®ç°ä»å•è§†è§’è§†é¢‘ä¸­å¯å˜å½¢ç»„ç»‡çš„ä¸‰ç»´é‡å»ºã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å­˜åœ¨ä¼˜åŒ–è€—æ—¶æˆ–è´¨é‡è¾ƒå·®çš„é—®é¢˜ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨åç»­ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šæ—©æœŸå°è¯•é‡‡ç”¨æ·±åº¦ä¼°è®¡åœ¨å†…çª¥é•œé‡å»ºä¸­å–å¾—äº†å·¨å¤§æˆåŠŸï¼Œä½†è¿™äº›æ–¹æ³•ä»ç„¶éš¾ä»¥äº§ç”Ÿé€¼çœŸçš„ä¸‰ç»´é‡å»ºï¼ŒåŸå› æœ‰ä¸¤ä¸ªå…³é”®é—®é¢˜ã€‚é¦–å…ˆï¼Œéåˆšæ€§å˜å½¢æœ‰æ—¶ä¼šå¯¼è‡´è¾ƒå¤§çš„è¿åŠ¨ï¼Œè¿™éœ€è¦å®é™…åŠ¨æ€åœºæ™¯é‡å»ºï¼Œè¿™é˜»ç¢äº†è¿™äº›æŠ€æœ¯çš„é€‚åº”ã€‚å…¶æ¬¡ï¼Œå•è§†è§’è§†é¢‘ä¸­å­˜åœ¨é®æŒ¡ï¼Œå¯¼è‡´å­¦ä¹ å—å½±å“éƒ¨åˆ†æ—¶ä¿¡æ¯æœ‰é™ï¼Œäº§ç”Ÿå›°éš¾ã€‚è™½ç„¶ä¸€äº›æ¡†æ¶ç»“åˆäº†å·¥å…·é®ç½©ã€ç«‹ä½“æ·±åº¦ä¼°è®¡å’Œç¨€ç–ç¿˜æ›²åœºç”¨äºå•è§†è§’ä¸‰ç»´é‡å»ºï¼Œä½†å®ƒä»¬åœ¨å­˜åœ¨å‰§çƒˆéæ‹“æ‰‘å¯å˜å½¢ç»„ç»‡å˜åŒ–æ—¶ä»ç„¶å®¹æ˜“å¤±è´¥ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šå—æœ€è¿‘æµè¡Œçš„ä¸‰ç»´è¡¨ç¤ºæ–¹æ³•ä¸‰ç»´é«˜æ–¯æ–‘ç‚¹å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº† EndoGSï¼Œå°†é«˜æ–¯æ–‘ç‚¹åº”ç”¨äºå¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†å˜å½¢åœºæ¥å¤„ç†åŠ¨æ€åœºæ™¯ï¼Œæ·±åº¦å¼•å¯¼ç›‘ç£æ¥ä¼˜åŒ–å…·æœ‰å•ä¸€è§†ç‚¹çš„ä¸‰ç»´ç›®æ ‡ï¼Œä»¥åŠæ—¶ç©ºæƒé‡æ©ç æ¥å‡è½»é®æŒ¡ã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šåœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEndoGS å®ç°äº†æ›´é«˜çš„æ¸²æŸ“è´¨é‡ã€‚</li>
</ol>
<p>Methods:
(1): æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸º EndoGS çš„æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨ 3D-GS çš„å¯å˜å½¢å˜ä½“ä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡è®°çš„å·¥å…·æ©ç ä¸­é‡å»º 3D å¤–ç§‘åœºæ™¯ã€‚
(2): æˆ‘ä»¬é¦–å…ˆä»‹ç»äº† 3D-GS çš„é¢„å¤‡çŸ¥è¯†ï¼Œç„¶åå±•ç¤ºäº†ä½¿ç”¨åŠ¨æ€ç‰ˆæœ¬çš„ 3D-GS å¯¹å¯å˜å½¢ç»„ç»‡è¿›è¡Œå»ºæ¨¡ï¼Œè¯¥ç‰ˆæœ¬é‡‡ç”¨è½»é‡çº§ MLP æ¥è¡¨ç¤ºåŠ¨æ€åœºã€‚æœ€åï¼Œæˆ‘ä»¬ä»‹ç»äº†ä½¿ç”¨å·¥å…·æ©ç å’Œæ·±åº¦å›¾å¯¹é«˜æ–¯é£æº…è¿›è¡Œè®­ç»ƒä¼˜åŒ–çš„è¿‡ç¨‹ã€‚
(3): æˆ‘ä»¬ä½¿ç”¨å…­ä¸ªæ­£äº¤ç‰¹å¾å¹³é¢æ¥ç¼–ç ç©ºé—´å’Œæ—¶é—´ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨å•ä¸ª MLP æ¥æ›´æ–°é«˜æ–¯å±æ€§å¹¶è§£ç ä½ç½®ã€æ¯”ä¾‹å› å­ã€æ—‹è½¬å› å­ã€çƒè°ç³»æ•°å’Œä¸é€æ˜åº¦çš„å˜å½¢ã€‚
(4): æˆ‘ä»¬ç»“åˆå·¥å…·æ©ç å’Œæ·±åº¦å›¾æ¥è®­ç»ƒ EndoGSï¼Œä»¥è§£å†³è§†é¢‘ä¸­å·¥å…·é®æŒ¡çš„æŒ‘æˆ˜ï¼Œå¹¶ä½¿ç”¨æ—¶ç©ºé‡è¦æ€§é‡‡æ ·ç­–ç•¥æ¥æŒ‡ç¤ºä¸é®æŒ¡é—®é¢˜ç›¸å…³çš„å…³é”®åŒºåŸŸã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</li>
</ol>
<p>å…·ä½“å†…å®¹å¦‚ä¸‹ï¼š</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æ–‘ç‚¹å¯å˜å½¢å†…çª¥é•œç»„ç»‡é‡å»ºçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡è®°çš„å·¥å…·æ©ç ä¸­å®æ—¶æ¸²æŸ“é«˜è´¨é‡çš„å¯å˜å½¢ç»„ç»‡ã€‚åœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å…·æœ‰æ›´é«˜çš„æ¸²æŸ“è´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•EndoGSï¼Œåˆ©ç”¨3D-GSçš„å¯å˜å½¢å˜ä½“ä»å•è§†è§’è§†é¢‘ã€ä¼°è®¡çš„æ·±åº¦å›¾å’Œæ ‡è®°çš„å·¥å…·æ©ç ä¸­é‡å»º3Då¤–ç§‘åœºæ™¯ã€‚</li>
<li>ä½¿ç”¨åŠ¨æ€ç‰ˆæœ¬çš„3D-GSå¯¹å¯å˜å½¢ç»„ç»‡è¿›è¡Œå»ºæ¨¡ï¼Œè¯¥ç‰ˆæœ¬é‡‡ç”¨è½»é‡çº§MLPæ¥è¡¨ç¤ºåŠ¨æ€åœºã€‚</li>
<li>ç»“åˆå·¥å…·æ©ç å’Œæ·±åº¦å›¾å¯¹é«˜æ–¯é£æº…è¿›è¡Œè®­ç»ƒä¼˜åŒ–ï¼Œä»¥è§£å†³è§†é¢‘ä¸­å·¥å…·é®æŒ¡çš„æŒ‘æˆ˜ï¼Œå¹¶ä½¿ç”¨æ—¶ç©ºé‡è¦æ€§é‡‡æ ·ç­–ç•¥æ¥æŒ‡ç¤ºä¸é®æŒ¡é—®é¢˜ç›¸å…³çš„å…³é”®åŒºåŸŸã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è¾¾èŠ¬å¥‡æœºå™¨äººæ‰‹æœ¯è§†é¢‘ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEndoGSå®ç°äº†æ›´é«˜çš„æ¸²æŸ“è´¨é‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦é¢„å…ˆè®­ç»ƒ3D-GSæ¨¡å‹ï¼Œå¹¶å¯¹æ¯ä¸ªæ–°åœºæ™¯è¿›è¡Œä¼˜åŒ–ã€‚</li>
<li>ä¼˜åŒ–è¿‡ç¨‹éœ€è¦ä¸€å®šçš„æ—¶é—´ï¼Œå…·ä½“å–å†³äºåœºæ™¯çš„å¤æ‚æ€§å’Œæ•°æ®é‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3aced720ad0952509d5ad4feafb073c5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-db38985f02aa9f93361d5395728da086.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f22f8ab59ea6655501c3858f5b7639aa.jpg" align="middle">
</details>




<h2 id="GaussianBody-Clothed-Human-Reconstruction-via-3d-Gaussian-Splatting"><a href="#GaussianBody-Clothed-Human-Reconstruction-via-3d-Gaussian-Splatting" class="headerlink" title="GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting"></a>GaussianBody: Clothed Human Reconstruction via 3d Gaussian Splatting</h2><p><strong>Authors:Mengtian Li, Shengxiang Yao, Zhifeng Xie, Keyu Chen</strong></p>
<p>In this work, we propose a novel clothed human reconstruction method called GaussianBody, based on 3D Gaussian Splatting. Compared with the costly neural radiance based models, 3D Gaussian Splatting has recently demonstrated great performance in terms of training time and rendering quality. However, applying the static 3D Gaussian Splatting model to the dynamic human reconstruction problem is non-trivial due to complicated non-rigid deformations and rich cloth details. To address these challenges, our method considers explicit pose-guided deformation to associate dynamic Gaussians across the canonical space and the observation space, introducing a physically-based prior with regularized transformations helps mitigate ambiguity between the two spaces. During the training process, we further propose a pose refinement strategy to update the pose regression for compensating the inaccurate initial estimation and a split-with-scale mechanism to enhance the density of regressed point clouds. The experiments validate that our method can achieve state-of-the-art photorealistic novel-view rendering results with high-quality details for dynamic clothed human bodies, along with explicit geometry reconstruction. </p>
<p><a href="http://arxiv.org/abs/2401.09720v2">PDF</a> </p>
<p><strong>Summary</strong><br>ä¼˜åŒ–åŠ¨æ€ç©¿è¡£äººä½“é‡å»ºæ–¹æ³•ï¼Œå¼•å…¥ç‰©ç†å…ˆéªŒå’Œè§„èŒƒåŒ–å˜æ¢ï¼Œå®ç°é«˜ç²¾åº¦ç…§ç‰‡çº§æ–°è§†è§’æ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç©¿è¡£äººé«”é‡å»ºæ–¹æ³• GaussianBodyï¼ŒåŸºæ–¼ 3D é«˜æ–¯ Splattingã€‚</li>
<li>3D é«˜æ–¯ Splatting æœ€è¿‘åœ¨è¨“ç·´æ™‚é–“å’Œæ¸²æŸ“è³ªé‡æ–¹é¢è¡¨ç¾å‡ºäº†å¾ˆå¥½çš„æ€§èƒ½ã€‚</li>
<li>æ‡‰ç”¨éœæ…‹ 3D é«˜æ–¯ Splatting æ¨¡å‹æ–¼å‹•æ…‹äººé«”é‡å»ºå•é¡Œæ™‚ï¼Œæœƒå› è¤‡é›œçš„éå‰›æ€§è®Šå½¢å’Œè±å¯Œçš„è¡£ç‰©ç´°ç¯€è€Œé‡åˆ°æŒ‘æˆ°ã€‚</li>
<li>æå‡ºæ˜ç¢ºçš„å§¿å‹¢å¼•å°è®Šå½¢ï¼Œä»¥é—œè¯è¦ç¯„ç©ºé–“å’Œè§€æ¸¬ç©ºé–“ä¸­çš„å‹•æ…‹é«˜æ–¯ã€‚</li>
<li>å¼•å…¥åŸºæ–¼ç‰©ç†çš„å…ˆé©—å’Œæ­£å‰‡åŒ–è®Šæ›ï¼Œä»¥æ¸›å°‘å…©å€‹ç©ºé–“ä¹‹é–“çš„æ­§ç¾©ã€‚</li>
<li>æå‡ºå§¿å‹¢ç²¾ç…‰ç­–ç•¥ï¼Œä»¥æ›´æ–°å§¿å‹¢å›æ­¸ï¼Œä»¥è£œå„Ÿä¸æº–ç¢ºçš„åˆå§‹ä¼°è¨ˆã€‚</li>
<li>æå‡ºåˆ†æ‹†æ¯”ä¾‹æ©Ÿåˆ¶ï¼Œä»¥å¢å¼·å›æ­¸é»é›²çš„å¯†åº¦ã€‚</li>
<li>å¯¦é©—è­‰æ˜ï¼Œè©²æ–¹æ³•å¯å¯¦ç¾æœ€å…ˆé€²ç…§ç‰‡ç´šçš„æ–°è¦–åœ–æ¸²æŸ“çµæœï¼ŒåŒæ™‚å…·æœ‰é«˜è³ªé‡çš„å‹•æ…‹ç©¿è¡£äººé«”ç´°ç¯€å’Œæ˜ç¢ºçš„å¹¾ä½•é‡å»ºã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šé«˜æ–¯ä½“ï¼šåŸºäº 3D é«˜æ–¯æ•£å¸ƒçš„ç€è£…äººä½“é‡å»º</li>
<li>ä½œè€…ï¼šææ¢¦æ·»ã€å§šèƒœç¥¥ã€è°¢å¿—å³°ã€é™ˆå¯å®‡</li>
<li>éš¶å±å•ä½ï¼šä¸Šæµ·å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D é«˜æ–¯æ•£å¸ƒã€ç€è£…äººä½“é‡å»ºã€å•ç›®è§†é¢‘ã€ç¥ç»è¾å°„åœº</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.09720ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåˆ›å»ºé«˜ä¿çœŸç€è£…äººä½“æ¨¡å‹åœ¨è™šæ‹Ÿç°å®ã€è¿œç¨‹ä¸´åœºå’Œç”µå½±åˆ¶ä½œä¸­å…·æœ‰é‡è¦åº”ç”¨ã€‚ä¼ ç»Ÿæ–¹æ³•è¦ä¹ˆæ¶‰åŠå¤æ‚çš„æ•æ‰ç³»ç»Ÿï¼Œè¦ä¹ˆéœ€è¦ 3D è‰ºæœ¯å®¶è¿›è¡Œç¹ççš„æ‰‹å·¥æ“ä½œï¼Œè¿™ä½¿å¾—å®ƒä»¬æ—¢è€—æ—¶åˆæ˜‚è´µï¼Œä»è€Œé™åˆ¶äº†æ–°æ‰‹ç”¨æˆ·çš„å¯æ‰©å±•æ€§ã€‚è¿‘å¹´æ¥ï¼Œäººä»¬è¶Šæ¥è¶Šå…³æ³¨ä»å•ä¸ª RGB å›¾åƒæˆ–å•ç›®è§†é¢‘ä¸­è‡ªåŠ¨é‡å»ºç€è£…äººä½“æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç½‘æ ¼æ¨¡å‹æ–¹æ³•æœ€åˆè¢«å¼•å…¥ï¼Œé€šè¿‡å›å½’ SCAPEã€SMPLã€SMPL-X å’Œ STAR ç­‰å‚æ•°æ¨¡å‹æ¥é‡æ„äººä½“å½¢çŠ¶ã€‚è™½ç„¶å®ƒä»¬å¯ä»¥å®ç°å¿«é€Ÿä¸”ç¨³å¥çš„é‡å»ºï¼Œä½†å›å½’çš„å¤šè¾¹å½¢ç½‘æ ¼éš¾ä»¥æ•æ‰ä¸åŒçš„å‡ ä½•ç»†èŠ‚å’Œä¸°å¯Œçš„æœè£…ç‰¹å¾ã€‚æ·»åŠ é¡¶ç‚¹åç§»é‡æˆä¸ºè¿™ç§æƒ…å†µä¸‹çš„ä¸€ç§å¢å¼ºè§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œå…¶è¡¨ç¤ºèƒ½åŠ›ä»ç„¶å—åˆ°ç½‘æ ¼åˆ†è¾¨ç‡çš„ä¸¥æ ¼é™åˆ¶ï¼Œå¹¶ä¸”é€šå¸¸åœ¨å®½æ¾æœè£…çš„æƒ…å†µä¸‹ä¼šå¤±è´¥ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å…‹æœæ˜¾å¼ç½‘æ ¼æ¨¡å‹çš„å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯æ•£å¸ƒçš„æ–°é¢–ç€è£…äººä½“é‡å»ºæ–¹æ³• GaussianBodyã€‚ä¸ä»£ä»·é«˜æ˜‚çš„ç¥ç»è¾å°„åœºæ¨¡å‹ç›¸æ¯”ï¼Œ3D é«˜æ–¯æ•£å¸ƒæœ€è¿‘åœ¨è®­ç»ƒæ—¶é—´å’Œæ¸²æŸ“è´¨é‡æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå°†é™æ€ 3D é«˜æ–¯æ•£å¸ƒæ¨¡å‹åº”ç”¨äºåŠ¨æ€äººä½“é‡å»ºé—®é¢˜ç”±äºå¤æ‚çš„éåˆšæ€§å˜å½¢å’Œä¸°å¯Œçš„æœè£…ç»†èŠ‚è€Œå˜å¾—éå¸¸å›°éš¾ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•è€ƒè™‘äº†æ˜¾å¼å§¿åŠ¿å¼•å¯¼çš„å˜å½¢ï¼Œå°†åŠ¨æ€é«˜æ–¯ä½“ä¸è§„èŒƒç©ºé—´å’Œè§‚å¯Ÿç©ºé—´ç›¸å…³è”ï¼Œå¼•å…¥å…·æœ‰æ­£åˆ™åŒ–å˜æ¢çš„åŸºäºç‰©ç†çš„å…ˆéªŒæœ‰åŠ©äºå‡è½»è¿™ä¸¤ä¸ªç©ºé—´ä¹‹é—´çš„æ­§ä¹‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæœ¬æ–‡è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§å§¿åŠ¿ç»†åŒ–ç­–ç•¥ï¼Œä»¥æ›´æ–°å§¿åŠ¿å›å½’ï¼Œä»¥è¡¥å¿ä¸å‡†ç¡®çš„åˆå§‹ä¼°è®¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§åˆ†è£‚å°ºåº¦æœºåˆ¶æ¥å¢å¼ºå›å½’ç‚¹äº‘çš„å¯†åº¦ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„åº”ç”¨ä»»åŠ¡å’Œæ€§èƒ½ï¼šå®éªŒéªŒè¯äº†æœ¬æ–‡çš„æ–¹æ³•å¯ä»¥å®ç°æœ€å…ˆè¿›çš„é€¼çœŸæ–°è§†å›¾æ¸²æŸ“ç»“æœï¼Œä¸ºåŠ¨æ€ç€è£…äººä½“æä¾›é«˜è´¨é‡çš„ç»†èŠ‚ï¼Œä»¥åŠæ˜¾å¼å‡ ä½•é‡å»ºã€‚è¿™äº›æ€§èƒ½å¯ä»¥æ”¯æŒä»–ä»¬çš„ç›®æ ‡ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯æ•£å¸ƒçš„ç€è£…äººä½“é‡å»ºæ–¹æ³• GaussianBodyï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»å•ç›®è§†é¢‘ä¸­é‡å»ºåŠ¨æ€çš„ç€è£…äººä½“æ¨¡å‹ï¼Œå¹¶å…·æœ‰é€¼çœŸçš„æ–°è§†å›¾æ¸²æŸ“ç»“æœå’Œé«˜è´¨é‡çš„ç»†èŠ‚ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>å°† 3D é«˜æ–¯æ•£å¸ƒè¡¨ç¤ºæ‰©å±•åˆ°ç€è£…äººä½“é‡å»ºä¸­ï¼Œå¹¶è€ƒè™‘äº†æ˜¾å¼å§¿åŠ¿å¼•å¯¼çš„å˜å½¢ï¼Œä»¥è§£å†³åŠ¨æ€é«˜æ–¯ä½“ä¸è§„èŒƒç©ºé—´å’Œè§‚å¯Ÿç©ºé—´ä¹‹é—´çš„æ­§ä¹‰é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç‰©ç†çš„å…ˆéªŒæ¥æ­£åˆ™åŒ–è§„èŒƒç©ºé—´çš„é«˜æ–¯ä½“ï¼Œä»¥å‡è½»è§‚å¯Ÿç©ºé—´å’Œè§„èŒƒç©ºé—´ä¹‹é—´çš„è¿‡åº¦æ—‹è½¬é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å§¿åŠ¿ç»†åŒ–ç­–ç•¥å’Œåˆ†è£‚å°ºåº¦æœºåˆ¶ï¼Œä»¥å¢å¼ºé‡å»ºç‚¹äº‘çš„è´¨é‡å’Œé²æ£’æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•åœ¨å›¾åƒè´¨é‡æŒ‡æ ‡ä¸Šä¸åŸºçº¿å’Œå…¶ä»–æ–¹æ³•ç›¸å½“ï¼Œè¯æ˜äº†å…¶å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½å’Œç›¸å¯¹è¾ƒå¿«çš„è®­ç»ƒé€Ÿåº¦ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿä½¿ç”¨æ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒè¿›è¡Œè®­ç»ƒã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒæ—¶é—´æ¯”ä¸€äº›æœ€å…ˆè¿›çš„æ–¹æ³•æ›´é•¿ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®æ¥è¿›è¡Œè®­ç»ƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-03cb35c9ffdf24e162bbcf10081d440a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2032721a60695f2d41ac96f75dec65a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4877b53e7d23cf29d6e9a1a57a3155ec.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d121364f4f1fecac5ef9d276f421f434.jpg" align="middle">
</details>




<h2 id="Forging-Vision-Foundation-Models-for-Autonomous-Driving-Challenges-Methodologies-and-Opportunities"><a href="#Forging-Vision-Foundation-Models-for-Autonomous-Driving-Challenges-Methodologies-and-Opportunities" class="headerlink" title="Forging Vision Foundation Models for Autonomous Driving: Challenges,   Methodologies, and Opportunities"></a>Forging Vision Foundation Models for Autonomous Driving: Challenges,   Methodologies, and Opportunities</h2><p><strong>Authors:Xu Yan, Haiming Zhang, Yingjie Cai, Jingming Guo, Weichao Qiu, Bin Gao, Kaiqiang Zhou, Yue Zhao, Huan Jin, Jiantao Gao, Zhen Li, Lihui Jiang, Wei Zhang, Hongbo Zhang, Dengxin Dai, Bingbing Liu</strong></p>
<p>The rise of large foundation models, trained on extensive datasets, is revolutionizing the field of AI. Models such as SAM, DALL-E2, and GPT-4 showcase their adaptability by extracting intricate patterns and performing effectively across diverse tasks, thereby serving as potent building blocks for a wide range of AI applications. Autonomous driving, a vibrant front in AI applications, remains challenged by the lack of dedicated vision foundation models (VFMs). The scarcity of comprehensive training data, the need for multi-sensor integration, and the diverse task-specific architectures pose significant obstacles to the development of VFMs in this field. This paper delves into the critical challenge of forging VFMs tailored specifically for autonomous driving, while also outlining future directions. Through a systematic analysis of over 250 papers, we dissect essential techniques for VFM development, including data preparation, pre-training strategies, and downstream task adaptation. Moreover, we explore key advancements such as NeRF, diffusion models, 3D Gaussian Splatting, and world models, presenting a comprehensive roadmap for future research. To empower researchers, we have built and maintained <a href="https://github.com/zhanghm1995/Forge_VFM4AD">https://github.com/zhanghm1995/Forge_VFM4AD</a>, an open-access repository constantly updated with the latest advancements in forging VFMs for autonomous driving. </p>
<p><a href="http://arxiv.org/abs/2401.08045v1">PDF</a> Github Repo: <a href="https://github.com/zhanghm1995/Forge_VFM4AD">https://github.com/zhanghm1995/Forge_VFM4AD</a></p>
<p><strong>æ‘˜è¦</strong><br>æ™ºèƒ½æ±½è½¦ä¸“å±è§†è§‰åŸºç¡€æ¨¡å‹çš„æ„å»ºæŒ‘æˆ˜åŠå…¶æœªæ¥å‘å±•æœºé‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æ•°æ®å‡†å¤‡ã€é¢„è®­ç»ƒç­–ç•¥å’Œä¸‹æ¸¸ä»»åŠ¡é€‚é…æ˜¯ VFM å¼€å‘çš„å…³é”®æŠ€æœ¯ã€‚</li>
<li>ç”Ÿæˆç¥ç»è¾å°„åœº (NeRF)ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œ3D é«˜æ–¯åˆ†å¸ƒï¼ˆ3DGSï¼‰å’Œä¸–ç•Œæ¨¡å‹ç­‰æŠ€æœ¯çš„è¿›æ­¥ä¸ºæœªæ¥çš„ç ”ç©¶æå‡ºäº†è·¯çº¿å›¾ã€‚</li>
<li>å¼€æºé¡¹ç›® <a href="https://github.com/zhanghm1995/Forge_VFM4AD">https://github.com/zhanghm1995/Forge_VFM4AD</a> å°†ä¸æ–­æ›´æ–°ï¼Œä»¥èµ‹èƒ½ç ”ç©¶äººå‘˜ã€‚</li>
<li>è‡ªåŠ¨é©¾é©¶ä¸­çš„ VFM ç¼ºä¹ä¸“ç”¨æ•°æ®å’Œå¤šä¼ æ„Ÿå™¨é›†æˆï¼Œå¯¼è‡´ä»»åŠ¡ç‰¹å®šæ¶æ„çš„å¤šæ ·æ€§æˆä¸º VFM å‘å±•çš„éšœç¢ã€‚</li>
<li>è§†è§‰åŸºç¡€æ¨¡å‹ (VFM) åœ¨è‡ªåŠ¨é©¾é©¶ä¸­è‡³å…³é‡è¦ï¼Œä½†å…¶å‘å±•é¢ä¸´ç€è¯¸å¤šæŒ‘æˆ˜ã€‚</li>
<li>å¼€å‘ä¸“ç”¨äºè‡ªåŠ¨é©¾é©¶çš„ VFM æ˜¯å½“å‰çš„ç´§è¿«æŒ‘æˆ˜ã€‚</li>
<li>å»ºè®®ä»æ•°æ®å‡†å¤‡ã€é¢„è®­ç»ƒä»¥åŠä¸‹æ¸¸ä»»åŠ¡é€‚é…ç­‰æ–¹é¢å…¥æ‰‹ï¼Œå¹¶æ¢ç´¢ NeRFã€æ‰©æ•£æ¨¡å‹ç­‰æ–°æŠ€æœ¯ï¼Œä»¥æ¨è¿› VFM çš„å‘å±•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šæ„å»ºè‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹ï¼šæŒ‘æˆ˜ã€æ–¹æ³•å’Œæœºé‡</li>
<li>ä½œè€…ï¼šå¾å²©ï¼Œå¼ æµ·æ˜ï¼Œè”¡åº”æ°ï¼Œéƒ­æ•¬æ˜ï¼Œé‚±ç»´è¶…ï¼Œé«˜æ–Œï¼Œå‘¨å‡¯å¼ºï¼Œèµµè¶Šï¼Œé‡‘æ¬¢ï¼Œé«˜å»ºæ¶›ï¼ŒææŒ¯ï¼Œè’‹ç«‹è¾‰ï¼Œå¼ ä¼Ÿï¼Œå¼ å®æ³¢ï¼Œæˆ´ç™»å¿ƒï¼Œåˆ˜å†°å†°</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šè§†è§‰åŸºç¡€æ¨¡å‹ï¼Œæ•°æ®ç”Ÿæˆï¼Œè‡ªç›‘ç£è®­ç»ƒï¼Œè‡ªåŠ¨é©¾é©¶ï¼Œæ–‡çŒ®ç»¼è¿°</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.08045
   Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€è‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œä¼ ç»Ÿè‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥ç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œé’ˆå¯¹ç‰¹å®šä»»åŠ¡ä½¿ç”¨ä¸“ç”¨ç®—æ³•ï¼Œä½†è¿™ç§æ–¹æ³•å¾€å¾€å¯¼è‡´è¾“å‡ºä¸ä¸€è‡´ï¼Œé™åˆ¶äº†ç³»ç»Ÿå¤„ç†é•¿å°¾æƒ…å†µçš„èƒ½åŠ›ã€‚è¿‘å¹´æ¥ï¼Œå¤§å‹åŸºç¡€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå–å¾—äº†å·¨å¤§æˆåŠŸï¼Œå±•ç°å‡ºå¼ºå¤§çš„é€‚åº”æ€§å’Œæœ‰æ•ˆæ€§ï¼Œä¸ºæ„å»ºè‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹æä¾›äº†æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€çš„æ–¹æ³•ä¸»è¦é›†ä¸­äºé’ˆå¯¹ç‰¹å®šä»»åŠ¡è®­ç»ƒæ·±åº¦ç¥ç»ç½‘ç»œï¼Œä½†è¿™ç§æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š1. å¿½è§†äº†æ•°æ®ä¹‹é—´çš„å…³ç³»ï¼Œå¯¼è‡´è¾“å‡ºä¸ä¸€è‡´ï¼›2. éš¾ä»¥å¤„ç†é•¿å°¾æƒ…å†µï¼›3. æ— æ³•æœ‰æ•ˆåˆ©ç”¨å¤§é‡æœªæ ‡è®°æ•°æ®ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ„å»ºè‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1. æ•°æ®å‡†å¤‡ï¼šæ”¶é›†å’Œé¢„å¤„ç†è‡ªåŠ¨é©¾é©¶ç›¸å…³çš„æ•°æ®ï¼ŒåŒ…æ‹¬å›¾åƒã€æ¿€å…‰é›·è¾¾ç‚¹äº‘ã€è¯­ä¹‰åˆ†å‰²æ ‡ç­¾ç­‰ï¼›2. é¢„è®­ç»ƒï¼šä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿä»æ•°æ®ä¸­æå–æœ‰ç”¨çš„ç‰¹å¾ï¼›3. ä¸‹æ¸¸ä»»åŠ¡è‡ªé€‚åº”ï¼šå°†é¢„è®­ç»ƒå¥½çš„åŸºç¡€æ¨¡å‹åº”ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶é€šè¿‡å¾®è°ƒä½¿å…¶é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸­çš„è¡¨ç°åŠæ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨è‡ªåŠ¨é©¾é©¶ç›¸å…³ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œä¾‹å¦‚ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦ä¼°è®¡ç­‰ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»æ•°æ®ä¸­æå–æœ‰ç”¨çš„ç‰¹å¾ï¼Œå¹¶å°†å…¶åº”ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ•°æ®å‡†å¤‡ï¼šæ”¶é›†å’Œé¢„å¤„ç†è‡ªåŠ¨é©¾é©¶ç›¸å…³çš„æ•°æ®ï¼ŒåŒ…æ‹¬å›¾åƒã€æ¿€å…‰é›·è¾¾ç‚¹äº‘ã€è¯­ä¹‰åˆ†å‰²æ ‡ç­¾ç­‰ï¼›
ï¼ˆ2ï¼‰é¢„è®­ç»ƒï¼šä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿä»æ•°æ®ä¸­æå–æœ‰ç”¨çš„ç‰¹å¾ï¼›
ï¼ˆ3ï¼‰ä¸‹æ¸¸ä»»åŠ¡è‡ªé€‚åº”ï¼šå°†é¢„è®­ç»ƒå¥½çš„åŸºç¡€æ¨¡å‹åº”ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶é€šè¿‡å¾®è°ƒä½¿å…¶é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é’ˆå¯¹è‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹çš„æ„å»ºæå‡ºäº†ç³»ç»Ÿçš„æ–¹æ³•ï¼Œå¹¶å–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•ä¸ºè‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹çš„æ„å»ºæä¾›äº†æ–°çš„æ€è·¯ï¼Œæœ‰æœ›æ¨åŠ¨è‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„å‘å±•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ„å»ºè‡ªåŠ¨é©¾é©¶è§†è§‰åŸºç¡€æ¨¡å‹çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€é¢„è®­ç»ƒå’Œä¸‹æ¸¸ä»»åŠ¡è‡ªé€‚åº”ä¸‰ä¸ªæ­¥éª¤ã€‚</li>
<li>ä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿä»æ•°æ®ä¸­æå–æœ‰ç”¨çš„ç‰¹å¾ã€‚</li>
<li>å°†é¢„è®­ç»ƒå¥½çš„åŸºç¡€æ¨¡å‹åº”ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶é€šè¿‡å¾®è°ƒä½¿å…¶é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•åœ¨è‡ªåŠ¨é©¾é©¶ç›¸å…³ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œä¾‹å¦‚ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦ä¼°è®¡ç­‰ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»æ•°æ®ä¸­æå–æœ‰ç”¨çš„ç‰¹å¾ï¼Œå¹¶å°†å…¶åº”ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦æ”¶é›†å’Œé¢„å¤„ç†å¤§é‡çš„æ•°æ®ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦ä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™éœ€è¦è¾ƒå¤§çš„è®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å°†é¢„è®­ç»ƒå¥½çš„åŸºç¡€æ¨¡å‹åº”ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶é€šè¿‡å¾®è°ƒä½¿å…¶é€‚åº”ç‰¹å®šä»»åŠ¡ï¼Œè¿™éœ€è¦è¾ƒå¤šçš„å·¥ç¨‹å·¥ä½œã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7ce70a9a128d8a3669098fd6808591bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b29768228c4fd656077c66549ec08984.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7ea3a2551a65a42514ea6e5555124cd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-66561a69f615f893c246615fba473e10.jpg" align="middle">
</details>



]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>LLM</title>
    <url>/2024/01/24/Paper/2024-01-24/LLM/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-24-æ›´æ–°"><a href="#2024-01-24-æ›´æ–°" class="headerlink" title="2024-01-24 æ›´æ–°"></a>2024-01-24 æ›´æ–°</h1><h2 id="Less-Could-Be-Better-Parameter-efficient-Fine-tuning-Advances-Medical-Vision-Foundation-Models"><a href="#Less-Could-Be-Better-Parameter-efficient-Fine-tuning-Advances-Medical-Vision-Foundation-Models" class="headerlink" title="Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical   Vision Foundation Models"></a>Less Could Be Better: Parameter-efficient Fine-tuning Advances Medical   Vision Foundation Models</h2><p><strong>Authors:Chenyu Lian, Hong-Yu Zhou, Yizhou Yu, Liansheng Wang</strong></p>
<p>Parameter-efficient fine-tuning (PEFT) that was initially developed for exploiting pre-trained large language models has recently emerged as an effective approach to perform transfer learning on computer vision tasks. However, the effectiveness of PEFT on medical vision foundation models is still unclear and remains to be explored. As a proof of concept, we conducted a detailed empirical study on applying PEFT to chest radiography foundation models. Specifically, we delved into LoRA, a representative PEFT method, and compared it against full-parameter fine-tuning (FFT) on two self-supervised radiography foundation models across three well-established chest radiograph datasets. Our results showed that LoRA outperformed FFT in 13 out of 18 transfer learning tasks by at most 2.9% using fewer than 1% tunable parameters. Combining LoRA with foundation models, we set up new state-of-the-art on a range of data-efficient learning tasks, such as an AUROC score of 80.6% using 1% labeled data on NIH ChestX-ray14. We hope this study can evoke more attention from the community in the use of PEFT for transfer learning on medical imaging tasks. Code and models are available at <a href="https://github.com/RL4M/MED-PEFT">https://github.com/RL4M/MED-PEFT</a>. </p>
<p><a href="http://arxiv.org/abs/2401.12215v1">PDF</a> Technical report</p>
<p><strong>æ‘˜è¦</strong><br>ç”¨å°‘äº 1% å¯è°ƒå‚æ•°å®ç°è¶…å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT) å¯ä»¥æå¤§æé«˜åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
<p><strong>ä¸»è¦è¦ç‚¹</strong></p>
<ul>
<li>PEFT æ˜¯åˆ©ç”¨é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹å¼€å‘çš„ä¸€ç§æœ‰æ•ˆçš„è®¡ç®—æœºè§†è§‰ä»»åŠ¡è¿ç§»å­¦ä¹ æ–¹æ³•ã€‚</li>
<li>PEFT åœ¨åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹ä¸Šçš„æœ‰æ•ˆæ€§å°šä¸æ¸…æ¥šï¼Œæœ‰å¾…æ¢ç´¢ã€‚</li>
<li>æˆ‘ä»¬é€šè¿‡å®éªŒç ”ç©¶å°† PEFT åº”ç”¨äºèƒ¸éƒ¨ X å…‰åŸºç¡€æ¨¡å‹ã€‚</li>
<li>ä¸å…¨å‚æ•°å¾®è°ƒ (FFT) ç›¸æ¯”ï¼ŒLoRA åœ¨ä¸‰ä¸ªè‘—åçš„èƒ¸éƒ¨ X å…‰æ•°æ®é›†ä¸Šçš„ 18 ä¸ªè¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­çš„ 13 ä¸ªä¸­è¡¨ç°æ›´å¥½ï¼Œæœ€å¤šæé«˜äº† 2.9%ï¼ŒåŒæ—¶å¯è°ƒå‚æ•°å°‘äº 1%ã€‚</li>
<li>å°† LoRA ä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆï¼Œæˆ‘ä»¬åœ¨å„ç§æ•°æ®æœ‰æ•ˆå­¦ä¹ ä»»åŠ¡ä¸­åˆ›ä¸‹äº†æ–°çºªå½•ï¼Œä¾‹å¦‚åœ¨ NIH ChestX-ray14 ä¸Šä½¿ç”¨ 1% çš„æ ‡è®°æ•°æ®è·å¾—äº† 80.6% çš„ AUROC åˆ†æ•°ã€‚</li>
<li>æˆ‘ä»¬å¸Œæœ›è¿™é¡¹ç ”ç©¶èƒ½å¤Ÿå¼•èµ·ç¤¾åŒºå¯¹ PEFT ç”¨äºåŒ»å­¦å›¾åƒä»»åŠ¡è¿ç§»å­¦ä¹ çš„æ›´å¤šå…³æ³¨ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šå°‘å³æ˜¯å¤šï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒ</p>
</li>
<li><p>ä½œè€…ï¼šé™ˆå®‡å»‰ï¼Œå‘¨å®å®‡ï¼Œäºä¸€èˆŸï¼Œç‹è¿ç”Ÿ</p>
</li>
<li><p>å•ä½ï¼šå¦é—¨å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šè¿ç§»å­¦ä¹ ï¼ŒåŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹ï¼Œèƒ¸éƒ¨Xå…‰ç‰‡</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12215ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/RL4M/MED-PEFT</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æœ€åˆç”¨äºå¼€å‘é¢„è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹ï¼Œæœ€è¿‘å·²æˆä¸ºè®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­è¿›è¡Œè¿ç§»å­¦ä¹ çš„æœ‰æ•ˆæ–¹æ³•ã€‚ç„¶è€Œï¼ŒPEFT åœ¨åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹ä¸Šçš„æœ‰æ•ˆæ€§ä»ä¸æ¸…æ¥šï¼Œæœ‰å¾…æ¢ç´¢ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šå…¨å‚æ•°å¾®è°ƒï¼ˆFFTï¼‰ä¸€ç›´è¢«è®¤ä¸ºæ˜¯è¿›è¡Œè¿ç§»å­¦ä¹ çš„ä¼˜è¶ŠæŠ€æœ¯ã€‚ç„¶è€Œï¼ŒåŸºç¡€æ¨¡å‹é€šå¸¸å…·æœ‰å¤§é‡çš„å‚æ•°ï¼Œå½“ä¸‹æ¸¸ä»»åŠ¡åªæœ‰æœ‰é™çš„æ³¨é‡Šæ—¶ï¼Œå¾®è°ƒæ•´ä¸ªæ¨¡å‹æƒé‡å¯èƒ½ä¸æ˜¯æœ€ä¼˜é€‰æ‹©ã€‚åœ¨åŒ»å­¦å½±åƒä»»åŠ¡ä¸­ï¼Œç”±äºéšç§ã€å®‰å…¨é—®é¢˜ä»¥åŠæŸäº›ç–¾ç—…çš„ç½•è§æ€§ï¼Œæ³¨é‡Šé€šå¸¸éš¾ä»¥è·å¾—ï¼Œå› æ­¤è¿™ç§å·®å¼‚å€¼å¾—æ›´å¤šå…³æ³¨ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è¯æ˜æ¦‚å¿µï¼Œæˆ‘ä»¬å¯¹å°† PEFT åº”ç”¨äºèƒ¸éƒ¨æ”¾å°„çº¿ç…§ç›¸åŸºç¡€æ¨¡å‹è¿›è¡Œäº†è¯¦ç»†çš„å®è¯ç ”ç©¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ·±å…¥ç ”ç©¶äº† LoRAï¼ˆä¸€ç§å…·æœ‰ä»£è¡¨æ€§çš„ PEFT æ–¹æ³•ï¼‰ï¼Œå¹¶å°†å…¶ä¸ä¸¤ä¸ªè‡ªç›‘ç£æ”¾å°„çº¿ç…§ç›¸åŸºç¡€æ¨¡å‹åœ¨ä¸‰ä¸ªå®Œå–„çš„èƒ¸éƒ¨æ”¾å°„çº¿ç…§ç›¸æ•°æ®é›†ä¸Šè¿›è¡Œäº†æ¯”è¾ƒã€‚
(4) å®éªŒç»“æœï¼šæˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨ 18 ä¸ªè¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­æœ‰ 13 ä¸ªä»»åŠ¡ä¸­ï¼ŒLoRA ä½¿ç”¨å°‘äº 1% å¯è°ƒå‚æ•°çš„è¡¨ç°ä¼˜äº FFTï¼Œæœ€å¤šå¯è¾¾ 2.9%ã€‚å°† LoRA ä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆï¼Œæˆ‘ä»¬åœ¨å„ç§æ•°æ®é«˜æ•ˆå­¦ä¹ ä»»åŠ¡ä¸­ç¡®ç«‹äº†æ–°çš„æœ€ä¼˜æ°´å¹³ï¼Œä¾‹å¦‚ï¼Œåœ¨ NIHChestX-ray14 ä¸Šä½¿ç”¨ 1% çš„æ ‡è®°æ•°æ®æ—¶ï¼ŒAUROC å¾—åˆ†ä¸º 80.6%ã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹ç ”ç©¶èƒ½å¤Ÿå¼•èµ·ç¤¾åŒºå¯¹ PEFT åœ¨åŒ»å­¦å½±åƒä»»åŠ¡ä¸­è¿›è¡Œè¿ç§»å­¦ä¹ çš„æ›´å¤šå…³æ³¨ã€‚</p>
</li>
<li><p>Methods:
(1): æå‡ºäº†ä¸€ç§å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•ï¼Œç”¨äºåŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹çš„è¿ç§»å­¦ä¹ ã€‚
(2): å°†LoRAï¼ˆä¸€ç§å…·æœ‰ä»£è¡¨æ€§çš„PEFTæ–¹æ³•ï¼‰ä¸ä¸¤ä¸ªè‡ªç›‘ç£æ”¾å°„çº¿ç…§ç›¸åŸºç¡€æ¨¡å‹åœ¨ä¸‰ä¸ªå®Œå–„çš„èƒ¸éƒ¨æ”¾å°„çº¿ç…§ç›¸æ•°æ®é›†ä¸Šè¿›è¡Œäº†æ¯”è¾ƒã€‚
(3): åœ¨18ä¸ªè¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­æœ‰13ä¸ªä»»åŠ¡ä¸­ï¼ŒLoRAä½¿ç”¨å°‘äº1%å¯è°ƒå‚æ•°çš„è¡¨ç°ä¼˜äºFFTï¼Œæœ€å¤šå¯è¾¾2.9%ã€‚
(4): å°†LoRAä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆï¼Œåœ¨å„ç§æ•°æ®é«˜æ•ˆå­¦ä¹ ä»»åŠ¡ä¸­ç¡®ç«‹äº†æ–°çš„æœ€ä¼˜æ°´å¹³ï¼Œä¾‹å¦‚ï¼Œåœ¨NIHChestX-ray14ä¸Šä½¿ç”¨1%çš„æ ‡è®°æ•°æ®æ—¶ï¼ŒAUROCå¾—åˆ†ä¸º80.6%ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œé¦–æ¬¡å°†å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•åº”ç”¨äºåŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹çš„è¿ç§»å­¦ä¹ ï¼Œå¹¶å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¸ºåŒ»å­¦å½±åƒä»»åŠ¡ä¸­çš„è¿ç§»å­¦ä¹ æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„PEFTæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å°†é¢„è®­ç»ƒçš„åŒ»å­¦è§†è§‰åŸºç¡€æ¨¡å‹è¿ç§»åˆ°ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
<li>åœ¨ä¸‰ä¸ªå®Œå–„çš„èƒ¸éƒ¨æ”¾å°„çº¿ç…§ç›¸æ•°æ®é›†ä¸Šï¼Œå°†LoRAä¸ä¸¤ä¸ªè‡ªç›‘ç£æ”¾å°„çº¿ç…§ç›¸åŸºç¡€æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒï¼Œç»“æœè¡¨æ˜ï¼ŒLoRAä½¿ç”¨å°‘äº1%å¯è°ƒå‚æ•°çš„è¡¨ç°ä¼˜äºFFTï¼Œæœ€å¤šå¯è¾¾2.9%ã€‚</li>
<li>å°†LoRAä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆï¼Œåœ¨å„ç§æ•°æ®é«˜æ•ˆå­¦ä¹ ä»»åŠ¡ä¸­ç¡®ç«‹äº†æ–°çš„æœ€ä¼˜æ°´å¹³ï¼Œä¾‹å¦‚ï¼Œåœ¨NIHChestX-ray14ä¸Šä½¿ç”¨1%çš„æ ‡è®°æ•°æ®æ—¶ï¼ŒAUROCå¾—åˆ†ä¸º80.6%ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨18ä¸ªè¿ç§»å­¦ä¹ ä»»åŠ¡ä¸­æœ‰13ä¸ªä»»åŠ¡ä¸­ï¼ŒLoRAä½¿ç”¨å°‘äº1%å¯è°ƒå‚æ•°çš„è¡¨ç°ä¼˜äºFFTï¼Œæœ€å¤šå¯è¾¾2.9%ã€‚</li>
<li>å°†LoRAä¸åŸºç¡€æ¨¡å‹ç›¸ç»“åˆï¼Œåœ¨å„ç§æ•°æ®é«˜æ•ˆå­¦ä¹ ä»»åŠ¡ä¸­ç¡®ç«‹äº†æ–°çš„æœ€ä¼˜æ°´å¹³ï¼Œä¾‹å¦‚ï¼Œåœ¨NIHChestX-ray14ä¸Šä½¿ç”¨1%çš„æ ‡è®°æ•°æ®æ—¶ï¼ŒAUROCå¾—åˆ†ä¸º80.6%ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬å·¥ä½œæ¶‰åŠäº†å¤§é‡çš„æ•°æ®æ”¶é›†ã€é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å·¥ä½œï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
<li>æœ¬å·¥ä½œæ¶‰åŠäº†å¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œç®—æ³•ï¼Œéœ€è¦è¾ƒå¼ºçš„ç†è®ºåŸºç¡€å’Œç¼–ç¨‹èƒ½åŠ›ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-88f5604fa47b7e6b53fa59ed5ce873a4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f28a6055dce3066c942bea25f00c4b98.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-219f68f671f950faee6332daa05d83eb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b0e3d9c8b6a9c6651af0cb1202241988.jpg" align="middle">
</details>
â€‹    


## CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation
**Authors:Zhihong Chen, Maya Varma, Jean-Benoit Delbrouck, Magdalini Paschali, Louis Blankemeier, Dave Van Veen, Jeya Maria Jose Valanarasu, Alaa Youssef, Joseph Paul Cohen, Eduardo Pontes Reis, Emily B. Tsai, Andrew Johnston, Cameron Olsen, Tanishq Mathew Abraham, Sergios Gatidis, Akshay S. Chaudhari, Curtis Langlotz**

Chest X-rays (CXRs) are the most frequently performed imaging test in clinical practice. Recent advances in the development of vision-language foundation models (FMs) give rise to the possibility of performing automated CXR interpretation, which can assist physicians with clinical decision-making and improve patient outcomes. However, developing FMs that can accurately interpret CXRs is challenging due to the (1) limited availability of large-scale vision-language datasets in the medical image domain, (2) lack of vision and language encoders that can capture the complexities of medical data, and (3) absence of evaluation frameworks for benchmarking the abilities of FMs on CXR interpretation. In this work, we address these challenges by first introducing \emph{CheXinstruct} - a large-scale instruction-tuning dataset curated from 28 publicly-available datasets. We then present \emph{CheXagent} - an instruction-tuned FM capable of analyzing and summarizing CXRs. To build CheXagent, we design a clinical large language model (LLM) for parsing radiology reports, a vision encoder for representing CXR images, and a network to bridge the vision and language modalities. Finally, we introduce \emph{CheXbench} - a novel benchmark designed to systematically evaluate FMs across 8 clinically-relevant CXR interpretation tasks. Extensive quantitative evaluations and qualitative reviews with five expert radiologists demonstrate that CheXagent outperforms previously-developed general- and medical-domain FMs on CheXbench tasks. Furthermore, in an effort to improve model transparency, we perform a fairness evaluation across factors of sex, race and age to highlight potential performance disparities. Our project is at \url{https://stanford-aimi.github.io/chexagent.html}. 

[PDF](http://arxiv.org/abs/2401.12208v1) 24 pages, 8 figures

**æ‘˜è¦**
é’ˆå¯¹ç›®å‰åŒ»ç–—å›¾åƒé¢†åŸŸä¸­çš„å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ•°æ®é›†è¾ƒå°‘ã€å¯æ•æ‰åŒ»å­¦æ•°æ®å¤æ‚æ€§çš„è§†è§‰å’Œè¯­è¨€ç¼–ç å™¨ç¼ºä¹ã€ä»¥åŠç”¨äºåŸºå‡†æµ‹è¯• CXR è§£é‡Šèƒ½åŠ›çš„è¯„ä¼°æ¡†æ¶ç¼ºå¤±çš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ CXR è§£é‡ŠåŸºå‡†æ¡†æ¶ Chexbench å’Œä¸€ä¸ªæ–°çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ CheXagentã€‚

**è¦ç‚¹**
- **åŒ»å­¦å½±åƒé¢†åŸŸ** ä¸­çš„ **å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ•°æ®é›†** è¾ƒå°‘ã€‚
- **åŒ»ç–—æ•°æ®å¤æ‚æ€§** ä½¿å¾— **è§†è§‰å’Œè¯­è¨€ç¼–ç å™¨** éš¾ä»¥æœ‰æ•ˆæ•æ‰ã€‚
- ç›®å‰ **ç”¨äºè¯„ä¼° CXR è§£é‡Šèƒ½åŠ›çš„æ¡†æ¶** ä»ç„¶**ç¼ºå¤±**ã€‚
- **CheXinstruct** æ˜¯ä¸€ä¸ªä» **28 ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›†** ä¸­ç­–åˆ’çš„å¤§è§„æ¨¡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ã€‚
- **CheXagent** æ˜¯ä¸€ä¸ªåŸºäºæŒ‡ä»¤å¾®è°ƒçš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤Ÿåˆ†æå’Œæ€»ç»“ CXRã€‚
- **CheXbench** æ˜¯ä¸€ä¸ªæ–°é¢–çš„åŸºå‡†ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼°è·¨è¶Š **8 ä¸ªä¸´åºŠç›¸å…³ CXR è§£é‡Šä»»åŠ¡** çš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ã€‚
- **CheXagent** åœ¨ **CheXbench** ä»»åŠ¡ä¸Šä¼˜äºæ­¤å‰å¼€å‘çš„é€šç”¨å’ŒåŒ»å­¦é¢†åŸŸè§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ã€‚
- æœ¬é¡¹ç›®è¿˜è¿›è¡Œäº†å…¬å¹³æ€§è¯„ä¼°ï¼Œä»¥çªå‡ºæ½œåœ¨çš„æ€§èƒ½å·®å¼‚ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šCheXagentï¼šè¿ˆå‘èƒ¸éƒ¨ X å°„çº¿è§£è¯»çš„åŸºç¡€æ¨¡å‹</li>
<li>ä½œè€…ï¼šZhihong Chenã€Maya Varmaã€Jean-Benoit Delbrouckã€Magdalini Paschaliã€Louis Blankemeierã€Dave Van Veenã€Jeya Maria Jose Valanarasuã€Alaa Youssefã€Joseph Paul Cohenã€Eduardo Pontes Reisã€Emily B. Tsaiã€Andrew Johnstonã€Cameron Olsenã€Tanishq Mathew Abrahamã€Sergios Gatidisã€Akshay S. Chaudhariã€Curtis Langlotz</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ–¯å¦ç¦å¤§å­¦</li>
<li>å…³é”®è¯ï¼šèƒ¸éƒ¨ X å°„çº¿ã€åŒ»å­¦å›¾åƒã€è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€åŸºç¡€æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12208
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šèƒ¸éƒ¨ X å°„çº¿ï¼ˆCXRï¼‰æ˜¯ä¸´åºŠå®è·µä¸­æœ€å¸¸è¿›è¡Œçš„å½±åƒæ£€æŸ¥ã€‚æœ€è¿‘ï¼Œè§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹ï¼ˆFMï¼‰çš„å‘å±•ä¸ºå®ç°è‡ªåŠ¨ CXR è§£é‡Šæä¾›äº†å¯èƒ½æ€§ï¼Œè¿™å¯ä»¥å¸®åŠ©åŒ»ç”Ÿè¿›è¡Œä¸´åºŠå†³ç­–å¹¶æ”¹å–„æ‚£è€…é¢„åã€‚ç„¶è€Œï¼Œç”±äºä»¥ä¸‹åŸå› ï¼Œå¼€å‘èƒ½å¤Ÿå‡†ç¡®è§£é‡Š CXR çš„ FM å…·æœ‰æŒ‘æˆ˜æ€§ï¼šï¼ˆ1ï¼‰åŒ»å­¦å›¾åƒé¢†åŸŸä¸­ç¼ºä¹å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ•°æ®é›†ï¼›ï¼ˆ2ï¼‰ç¼ºä¹èƒ½å¤Ÿæ•æ‰åŒ»å­¦æ•°æ®å¤æ‚æ€§çš„è§†è§‰å’Œè¯­è¨€ç¼–ç å™¨ï¼›ï¼ˆ3ï¼‰ç¼ºä¹ç”¨äºè¯„ä¼° FM åœ¨ CXR è§£é‡Šæ–¹é¢çš„èƒ½åŠ›çš„è¯„ä¼°æ¡†æ¶ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•åŒ…æ‹¬ä½¿ç”¨é€šç”¨ FM æˆ–é’ˆå¯¹åŒ»å­¦å›¾åƒé¢†åŸŸå¾®è°ƒçš„ FMã€‚è¿™äº›æ–¹æ³•å­˜åœ¨çš„é—®é¢˜åœ¨äºå®ƒä»¬æ— æ³•å……åˆ†æ•æ‰ CXR çš„å¤æ‚æ€§ï¼Œå¹¶ä¸”ç¼ºä¹é’ˆå¯¹ CXR è§£é‡Šä»»åŠ¡çš„è¯„ä¼°æ¡†æ¶ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç ”ç©¶æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŒ…æ‹¬ï¼š</li>
</ol>
<ul>
<li>æ„å»ºäº†ä¸€ä¸ªåä¸º CheXinstruct çš„å¤§è§„æ¨¡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ˜¯ä» 28 ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›†ç­–åˆ’è€Œæ¥ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸º CheXagent çš„æŒ‡ä»¤å¾®è°ƒ FMï¼Œè¯¥ FM èƒ½å¤Ÿåˆ†æå’Œæ€»ç»“ CXRã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªåä¸º CheXbench çš„æ–°åŸºå‡†ï¼Œè¯¥åŸºå‡†æ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼° FM åœ¨ 8 ä¸ªä¸ä¸´åºŠç›¸å…³çš„ CXR è§£é‡Šä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
ï¼ˆ4ï¼‰ï¼šåœ¨ 8 ä¸ª CXR è§£é‡Šä»»åŠ¡ä¸Šï¼ŒCheXagent çš„æ€§èƒ½ä¼˜äºä¹‹å‰å¼€å‘çš„é€šç”¨å’ŒåŒ»å­¦é¢†åŸŸ FMã€‚æ­¤å¤–ï¼Œå…¬å¹³æ€§è¯„ä¼°è¡¨æ˜ï¼ŒCheXagent åœ¨æ€§åˆ«ã€ç§æ—å’Œå¹´é¾„ç­‰å› ç´ ä¸Šçš„æ€§èƒ½æ²¡æœ‰æ˜¾ç€å·®å¼‚ã€‚</li>
</ul>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</li>
</ol>
<p>åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æ„å»ºäº†ä¸€ä¸ªåä¸º CheXinstruct çš„å¤§è§„æ¨¡æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ˜¯ä» 28 ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›†ç­–åˆ’è€Œæ¥ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸º CheXagent çš„æŒ‡ä»¤å¾®è°ƒ FMï¼Œè¯¥ FM èƒ½å¤Ÿåˆ†æå’Œæ€»ç»“ CXRã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªåä¸º CheXbench çš„æ–°åŸºå‡†ï¼Œè¯¥åŸºå‡†æ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼° FM åœ¨ 8 ä¸ªä¸ä¸´åºŠç›¸å…³çš„ CXR è§£é‡Šä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨ 8 ä¸ª CXR è§£é‡Šä»»åŠ¡ä¸Šï¼ŒCheXagent çš„æ€§èƒ½ä¼˜äºä¹‹å‰å¼€å‘çš„é€šç”¨å’ŒåŒ»å­¦é¢†åŸŸ FMã€‚</li>
<li>å…¬å¹³æ€§è¯„ä¼°è¡¨æ˜ï¼ŒCheXagent åœ¨æ€§åˆ«ã€ç§æ—å’Œå¹´é¾„ç­‰å› ç´ ä¸Šçš„æ€§èƒ½æ²¡æœ‰æ˜¾ç€å·®å¼‚ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>æ•°æ®é›†æ„å»ºï¼šä» 28 ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›†ç­–åˆ’ CheXinstruct æ•°æ®é›†ã€‚</li>
<li>æ¨¡å‹è®­ç»ƒï¼šè®­ç»ƒ CheXagent æ¨¡å‹ã€‚</li>
<li>åŸºå‡†æ„å»ºï¼šæ„å»º CheXbench åŸºå‡†ã€‚</li>
<li>æ¨¡å‹è¯„ä¼°ï¼šåœ¨ CheXbench åŸºå‡†ä¸Šè¯„ä¼° CheXagent çš„æ€§èƒ½ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6aa52c71b57a2862b763a5188b83d6d8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a7d79f07ab8199caa375ff5c3d1ce188.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-71a37c439c6714e8867560f580599d2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f44d1729ed1485e81c04a41f097c005.jpg" align="middle">
</details>
â€‹    


## Text Embedding Inversion Attacks on Multilingual Language Models
**Authors:Yiyi Chen, Heather Lent, Johannes Bjerva**

Representing textual information as real-numbered embeddings has become the norm in NLP. Moreover, with the rise of public interest in large language models (LLMs), Embeddings as a Service (EaaS) has rapidly gained traction as a business model. This is not without outstanding security risks, as previous research has demonstrated that sensitive data can be reconstructed from embeddings, even without knowledge of the underlying model that generated them. However, such work is limited by its sole focus on English, leaving all other languages vulnerable to attacks by malicious actors. %As many international and multilingual companies leverage EaaS, there is an urgent need for research into multilingual LLM security. To this end, this work investigates LLM security from the perspective of multilingual embedding inversion. Concretely, we define the problem of black-box multilingual and cross-lingual inversion attacks, with special attention to a cross-domain scenario. Our findings reveal that multilingual models are potentially more vulnerable to inversion attacks than their monolingual counterparts. This stems from the reduced data requirements for achieving comparable inversion performance in settings where the underlying language is not known a-priori. To our knowledge, this work is the first to delve into multilinguality within the context of inversion attacks, and our findings highlight the need for further investigation and enhanced defenses in the area of NLP Security. 

[PDF](http://arxiv.org/abs/2401.12192v1) 13 pages

**Summary**
ä¸æ–­å¢é•¿çš„å¤šè¯­è¨€ç”¨æˆ·æ¤å…¥å¯¹ NLP å®‰å…¨ç ”ç©¶æå‡ºäº†è¿«åˆ‡è¦æ±‚ï¼Œä¹ŸåŠ å‰§äº†é»‘ç›’å¤šè¯­è¨€å¯¹åµŒå…¥é€†å‘æ”»å‡»åŠè·¨è¯­è¨€æ”»å‡»çš„é£é™©ã€‚

**Key Takeaways**
- å®‰å…¨é£é™©ï¼šæ¤å…¥ä½œä¸ºä¸€é¡¹æœåŠ¡ (EaaS) æ¨¡å‹ä½¿æ•°æ®é‡æ„æ›´å®¹æ˜“ï¼Œä½†è¿‡å»çš„é‡ç‚¹ä»…æ”¾åœ¨è‹±è¯­ä¸Šï¼Œå…¶ä»–è¯­è¨€å¾ˆè„†å¼±ã€‚
- å¤šè¯­è¨€æ¨¡å‹æ›´æ˜“å—æ”»å‡»ï¼šå®ƒä»¬å¯¹å®ç°å¯æ¯”çš„é€†å‘æ€§èƒ½çš„æ•°æ®éœ€æ±‚è¾ƒå°‘ï¼Œå³ä½¿åœ¨äº‹å…ˆä¸çŸ¥é“åŸºç¡€è¯­è¨€çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚
- è·¨è¯­è¨€æ”»å‡»ï¼šå¯¹æ”»å‡»è€…æ¥è¯´ï¼Œåœ¨è·¨è¯­è¨€åœºæ™¯ä¸­è¿›è¡Œè·¨åŸŸæ”»å‡»æ›´ä¸ºå®¹æ˜“ï¼Œå› ä¸ºç›®æ ‡è¯­è¨€é€šå¸¸ä¸æºè¯­è¨€ä¸åŒã€‚
- è¡¨ç°å·®å¼‚ï¼šå¤šè¯­è¨€æ¨¡å‹åœ¨ä¸åŒè¯­è¨€ä¸Šçš„æ€§èƒ½å·®å¼‚å¯èƒ½å¯¼è‡´è·¨è¯­è¨€è®¾ç½®ä¸­çš„æ”»å‡»æˆåŠŸç‡å‘ç”Ÿå˜åŒ–ã€‚
- æ›´å°‘çš„æ•°æ®éœ€æ±‚ï¼šå¤šè¯­è¨€æ¨¡å‹å¯¹å®ç°å¯æ¯”çš„é€†å‘æ€§èƒ½çš„æ•°æ®éœ€æ±‚è¾ƒå°‘ï¼Œå³ä½¿åœ¨äº‹å…ˆä¸çŸ¥é“åŸºç¡€è¯­è¨€çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚
- éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶ï¼šè¿™é¡¹å·¥ä½œå¼ºè°ƒäº†åœ¨ NLP å®‰å…¨é¢†åŸŸè¿›è¡Œè¿›ä¸€æ­¥ç ”ç©¶å’Œæ”¹è¿›é˜²å¾¡çš„å¿…è¦æ€§ã€‚
- é˜²å¾¡æªæ–½ï¼šå¼€å‘é’ˆå¯¹å¤šè¯­è¨€å’Œè·¨è¯­è¨€åµŒå…¥é€†å‘æ”»å‡»çš„é˜²å¾¡æªæ–½ï¼Œä»¥ç¡®ä¿ NLPç³»ç»Ÿçš„å®‰å…¨ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>è®ºæ–‡æ ‡é¢˜ï¼šå¤šè¯­è¨€è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬åµŒå…¥é€†å‘æ”»å‡»</p>
</li>
<li><p>ä½œè€…ï¼šYiyi Chen, Heather Lent, Johannes Bjerva</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¥¥å°”å ¡å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»</p>
</li>
<li><p>å…³é”®è¯ï¼šè‡ªç„¶è¯­è¨€å¤„ç†ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ŒåµŒå…¥å¼æœåŠ¡ï¼ŒåµŒå…¥å¼é€†å‘æ”»å‡»ï¼Œå¤šè¯­è¨€ï¼Œè·¨è¯­è¨€</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12192ï¼ŒGithub é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„å·¥ä¸šåº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’ŒåµŒå…¥å¼æœåŠ¡ï¼ˆEaaSï¼‰æ¡†æ¶çš„ä½¿ç”¨ä¹Ÿè¶Šæ¥è¶Šæ™®éã€‚EaaS å…è®¸ç”¨æˆ·å°†æ–‡æœ¬æ•°æ®å­˜å‚¨ä¸ºé«˜å“è´¨çš„å¥å­åµŒå…¥ï¼Œä»è€Œæé«˜æœç´¢æ•ˆç‡ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼ŒåµŒå…¥å¼é€†å‘æ”»å‡»å¯ä»¥ä»åµŒå…¥ä¸­è§£ç å‡ºåŸå§‹æ–‡æœ¬ï¼Œè¿™ç»™ NLP å®‰å…¨å¸¦æ¥äº†é‡å¤§å¨èƒã€‚</p>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šä»¥å¾€çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å•è¯­è‹±è¯­æ¨¡å‹å’ŒåµŒå…¥ä¸Šï¼Œå‡è®¾æ”»å‡»è€…çŸ¥é“æ–‡æœ¬çš„è¯­è¨€ã€‚ç„¶è€Œï¼Œåœ¨ç°å®åœºæ™¯ä¸­ï¼Œæ”»å‡»è€…å¯èƒ½ä¸çŸ¥é“æ–‡æœ¬çš„è¯­è¨€ã€‚</p>
<p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡å®šä¹‰äº†é»‘ç›’å¤šè¯­è¨€å’Œè·¨è¯­è¨€åµŒå…¥é€†å‘æ”»å‡»é—®é¢˜ï¼Œå¹¶ç‰¹åˆ«å…³æ³¨è·¨åŸŸåœºæ™¯ã€‚æœ¬æ–‡ä½¿ç”¨å¤–éƒ¨æ¨¡å‹æ¥è¿‘ä¼¼åµŒå…¥é€†å‘å‡½æ•°ï¼Œè¯¥å‡½æ•°å¯ä»¥ä»åµŒå…¥ä¸­é‡å»ºæ–‡æœ¬ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½å’Œç›®æ ‡æ”¯æŒï¼šæœ¬æ–‡çš„å®éªŒç»“æœè¡¨æ˜ï¼Œå¤šè¯­è¨€æ¨¡å‹æ¯”å•è¯­æ¨¡å‹æ›´å®¹æ˜“å—åˆ°é€†å‘æ”»å‡»ã€‚åœ¨ä¸çŸ¥é“åº•å±‚è¯­è¨€çš„æƒ…å†µä¸‹ï¼Œæ”»å‡»è€…ä¹Ÿå¯ä»¥å®ç°ä¸å•è¯­æ¨¡å‹ç›¸å½“çš„é€†å‘æ€§èƒ½ã€‚è¿™è¡¨æ˜å¤šè¯­è¨€æ¨¡å‹åœ¨å®‰å…¨æ€§æ–¹é¢å­˜åœ¨æ½œåœ¨çš„é£é™©ã€‚</p>
<ol start="7">
<li><p>æ–¹æ³•ï¼š
(1) å®šä¹‰é»‘ç›’å¤šè¯­è¨€å’Œè·¨è¯­è¨€åµŒå…¥é€†å‘æ”»å‡»é—®é¢˜ï¼Œå…³æ³¨è·¨åŸŸåœºæ™¯ï¼›
(2) ä½¿ç”¨å¤–éƒ¨æ¨¡å‹ Ïˆ è¿‘ä¼¼åµŒå…¥é€†å‘å‡½æ•° Ï•âˆ’1ï¼Œä»åµŒå…¥ä¸­é‡å»ºæ–‡æœ¬ï¼›
(3) æ¢è®¨æ–‡æœ¬ç”Ÿæˆæ¨¡å‹åœ¨æœªçŸ¥è¯­è¨€æ–‡æœ¬é‡å»ºä¸­çš„ä½œç”¨ï¼›
(4) ç ”ç©¶å¤šè¯­è¨€åµŒå…¥é€†å‘æ”»å‡»çš„æ½œåŠ›å’Œå½±å“ï¼›
(5) æå‡ºåé€†å‘ç­–ç•¥ AdhocTranslationï¼Œå°†ç”Ÿæˆæ–‡æœ¬ä» ly ç¿»è¯‘æˆ lxï¼Œè¯„ä¼°ä¿¡æ¯æ³„éœ²æƒ…å†µï¼›
(6) ä½¿ç”¨ T5-base ä½œä¸ºç”Ÿæˆæ¨¡å‹ï¼Œåœ¨ ME5-base å’Œ GTR-base ä¸Šè®­ç»ƒå¤šè¯­è¨€é€†å‘æ¨¡å‹ï¼›
(7) ä¸åœ¨è‹±è¯­æ•°æ®é›†ä¸Šè®­ç»ƒçš„é€†å‘æ¨¡å‹æ¯”è¾ƒï¼Œè¯„ä¼°å¤šè¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é¦–æ¬¡å¯¹å¤šè¯­è¨€åµŒå…¥é€†å‘æ”»å‡»é—®é¢˜è¿›è¡Œäº†ç ”ç©¶ï¼Œä¸ºè¯¥æ–¹å‘çš„æœªæ¥å·¥ä½œå¥ å®šäº†åŸºç¡€ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒå‘ç°ä¹‹ä¸€æ˜¯ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¤šè¯­è¨€æ¨¡å‹æ¯”å•è¯­è‹±è¯­æ¨¡å‹æ›´å®¹æ˜“å—åˆ°æ”»å‡»ã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œèƒ½å¤Ÿæ¿€å‘äººä»¬å¯¹ LLM å®‰å…¨å’Œ NLP å®‰å…¨çš„å…³æ³¨ï¼Œé‡‡å–å¤šè¯­è¨€çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>å®šä¹‰äº†é»‘ç›’å¤šè¯­è¨€å’Œè·¨è¯­è¨€åµŒå…¥é€†å‘æ”»å‡»é—®é¢˜ï¼Œå…³æ³¨è·¨åŸŸåœºæ™¯ã€‚</li>
<li>ä½¿ç”¨å¤–éƒ¨æ¨¡å‹ Ïˆ è¿‘ä¼¼åµŒå…¥é€†å‘å‡½æ•° Ï•âˆ’1ï¼Œä»åµŒå…¥ä¸­é‡å»ºæ–‡æœ¬ã€‚</li>
<li>æ¢è®¨äº†æ–‡æœ¬ç”Ÿæˆæ¨¡å‹åœ¨æœªçŸ¥è¯­è¨€æ–‡æœ¬é‡å»ºä¸­çš„ä½œç”¨ã€‚</li>
<li>ç ”ç©¶äº†å¤šè¯­è¨€åµŒå…¥é€†å‘æ”»å‡»çš„æ½œåŠ›å’Œå½±å“ã€‚</li>
<li>æå‡ºåé€†å‘ç­–ç•¥ AdhocTranslationï¼Œå°†ç”Ÿæˆæ–‡æœ¬ä» l_x ç¿»è¯‘æˆ l_yï¼Œè¯„ä¼°ä¿¡æ¯æ³„éœ²æƒ…å†µã€‚</li>
<li>ä½¿ç”¨ T5-base ä½œä¸ºç”Ÿæˆæ¨¡å‹ï¼Œåœ¨ ME5-base å’Œ GTR-base ä¸Šè®­ç»ƒå¤šè¯­è¨€é€†å‘æ¨¡å‹ã€‚</li>
<li>ä¸åœ¨è‹±è¯­æ•°æ®é›†ä¸Šè®­ç»ƒçš„é€†å‘æ¨¡å‹æ¯”è¾ƒï¼Œè¯„ä¼°äº†å¤šè¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>å¤šè¯­è¨€æ¨¡å‹åœ¨æŸäº›æƒ…å†µä¸‹æ¯”å•è¯­è‹±è¯­æ¨¡å‹æ›´å®¹æ˜“å—åˆ°æ”»å‡»ã€‚</li>
<li>åœ¨ä¸çŸ¥é“åº•å±‚è¯­è¨€çš„æƒ…å†µä¸‹ï¼Œæ”»å‡»è€…ä¹Ÿå¯ä»¥å®ç°ä¸å•è¯­æ¨¡å‹ç›¸å½“çš„é€†å‘æ€§èƒ½ã€‚</li>
<li>åé€†å‘ç­–ç•¥ AdhocTranslation å¯ä»¥æœ‰æ•ˆé™ä½ä¿¡æ¯æ³„éœ²é£é™©ã€‚
å·¥ä½œé‡ï¼š</li>
<li>å®éªŒè®¡ç®—é‡å¤§ï¼Œéœ€è¦çº¦ 20,000 ä¸ª GPU è®¡ç®—å°æ—¶ã€‚</li>
<li>å°†è¿™é¡¹ç ”ç©¶æ‰©å±•åˆ°æ›´å¤šè¯­è¨€å°†è¿›ä¸€æ­¥å¢åŠ å¼€é”€ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-716d1bb2864a9ac6b2a1614499e04fd6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5de54c90ee7b1b6fe5ae2be76cb7496f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f940c4622168d9e745d9be24e1dccd3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-99a0979006c1b27d04c44e10eca03872.jpg" align="middle">
</details>
â€‹    


## WARM: On the Benefits of Weight Averaged Reward Models
**Authors:Alexandre RamÃ©, Nino Vieillard, LÃ©onard Hussenot, Robert Dadashi, Geoffrey Cideron, Olivier Bachem, Johan Ferret**

Aligning large language models (LLMs) with human preferences through reinforcement learning (RLHF) can lead to reward hacking, where LLMs exploit failures in the reward model (RM) to achieve seemingly high rewards without meeting the underlying objectives. We identify two primary challenges when designing RMs to mitigate reward hacking: distribution shifts during the RL process and inconsistencies in human preferences. As a solution, we propose Weight Averaged Reward Models (WARM), first fine-tuning multiple RMs, then averaging them in the weight space. This strategy follows the observation that fine-tuned weights remain linearly mode connected when sharing the same pre-training. By averaging weights, WARM improves efficiency compared to the traditional ensembling of predictions, while improving reliability under distribution shifts and robustness to preference inconsistencies. Our experiments on summarization tasks, using best-of-N and RL methods, shows that WARM improves the overall quality and alignment of LLM predictions; for example, a policy RL fine-tuned with WARM has a 79.4% win rate against a policy RL fine-tuned with a single RM. 

[PDF](http://arxiv.org/abs/2401.12187v1) 14 pages, 9 figures

**Summary**
åˆ©ç”¨åŠ æƒå¹³å‡å¥–åŠ±æ¨¡å‹æ¥å…‹æœå¼ºåŒ–å­¦ä¹ ä¸­å­˜åœ¨çš„å¥–åŠ±çªƒå–ç°è±¡ã€‚

**Key Takeaways**

- å¥–åŠ±çªƒå–æ˜¯æŒ‡ LLM åˆ©ç”¨å¥–åŠ±æ¨¡å‹çš„æ¼æ´æ¥è·å¾—çœ‹ä¼¼å¾ˆé«˜çš„å¥–åŠ±ï¼Œä½†å¹¶æœªè¾¾åˆ°é¢„æœŸçš„ç›®æ ‡ã€‚
- è®¾è®¡å¥–åŠ±æ¨¡å‹æ—¶é¢ä¸´çš„ä¸¤å¤§æŒ‘æˆ˜æ˜¯ï¼šå¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­åˆ†å¸ƒçš„å˜åŒ–å’Œäººç±»åå¥½çš„ä¸ä¸€è‡´ã€‚
- æå‡ºåŠ æƒå¹³å‡å¥–åŠ±æ¨¡å‹ (WARM) æ¥è§£å†³å¥–åŠ±çªƒå–é—®é¢˜ï¼Œå…ˆå¾®è°ƒå¤šä¸ªå¥–åŠ±æ¨¡å‹ï¼Œç„¶ååœ¨æƒé‡ç©ºé—´å¯¹å®ƒä»¬æ±‚å¹³å‡ã€‚
- WARM é€šè¿‡ä½¿ç”¨æœ€ä¼˜ N å’Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨æ‘˜è¦ä»»åŠ¡ä¸Šè¿›è¡Œçš„å®éªŒè¯æ˜ï¼ŒWARM æé«˜äº† LLM é¢„æµ‹çš„æ•´ä½“è´¨é‡å’Œä¸€è‡´æ€§ã€‚
- ä¸é‡‡ç”¨å•ä¸ªå¥–åŠ±æ¨¡å‹å¾®è°ƒçš„ç­–ç•¥å‹å¼ºåŒ–å­¦ä¹ ç›¸æ¯”ï¼Œé‡‡ç”¨ WARM å¾®è°ƒçš„ç­–ç•¥å‹å¼ºåŒ–å­¦ä¹ çš„è·èƒœç‡ä¸º 79.4%ã€‚
- ä¸ä¼ ç»Ÿé¢„æµ‹é›†æˆç›¸æ¯”ï¼ŒWARM åœ¨åˆ†å¸ƒå˜åŒ–å’Œåå¥½ä¸ä¸€è‡´çš„æƒ…å†µä¸‹æé«˜äº†æ•ˆç‡å’Œå¯é æ€§ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šWARMï¼šå…³äºæƒé‡å¹³å‡å¥–åŠ±æ¨¡å‹çš„ä¼˜åŠ¿</li>
<li>ä½œè€…ï¼šAlexandre RamÃ©, Nino Vieillard, LÃ©onard Hussenot, Robert Dadashi, Geoffrey Cidon, Olivier Bachem, Johan Ferret</li>
<li>éš¶å±æœºæ„ï¼šè°·æ­Œå¤§è„‘</li>
<li>å…³é”®è¯ï¼šå¯¹é½ï¼ŒRLHFï¼Œå¥–åŠ±å»ºæ¨¡ï¼Œæ¨¡å‹åˆå¹¶</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12187</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ä¸ªé¢†åŸŸå–å¾—äº†ä»¤äººç©ç›®çš„æˆå°±ï¼Œè¿™å¾ˆå¤§ç¨‹åº¦ä¸Šå¾—ç›Šäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„åº”ç”¨ã€‚ç„¶è€Œï¼Œåœ¨RLHFï¼ˆä»äººç±»åé¦ˆä¸­è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼‰ä¸­ï¼Œå¥–åŠ±é»‘å®¢é—®é¢˜æ˜¯ä¸€ä¸ªæ™®éå­˜åœ¨çš„é—®é¢˜ã€‚å¥–åŠ±é»‘å®¢æ˜¯æŒ‡ç­–ç•¥ï¼ˆå³æ­£åœ¨è®­ç»ƒçš„LLMï¼‰å­¦ä¼šåˆ©ç”¨å¥–åŠ±æ¨¡å‹ï¼ˆRMï¼‰ä¸­çš„æ¼æ´ï¼Œåœ¨ä¸çœŸæ­£æ»¡è¶³é¢„æœŸç›®æ ‡çš„æƒ…å†µä¸‹å®ç°çœ‹ä¼¼å¾ˆé«˜çš„å¥–åŠ±ã€‚è¿™ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€æ£€æŸ¥ç‚¹é€‰æ‹©å¤æ‚åŒ–ã€äº§ç”Ÿè°„åªšè¡Œä¸ºæˆ–æ”¾å¤§ç¤¾ä¼šåè§ï¼Œæœ€ä¸¥é‡çš„æ˜¯å¯èƒ½å¯¼è‡´å®‰å…¨é£é™©ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†è§£å†³å¥–åŠ±é»‘å®¢é—®é¢˜ï¼Œä¸€äº›ç ”ç©¶äººå‘˜æå‡ºäº†ä½¿ç”¨é¢„æµ‹é›†æˆï¼ˆENSï¼‰çš„æ–¹æ³•ã€‚ENSé€šè¿‡å¯¹å¤šä¸ªRMçš„å¥–åŠ±è¿›è¡Œå¹³å‡ï¼Œå¯ä»¥æé«˜å¥–åŠ±çš„å¯é æ€§å¹¶é™ä½é»‘å®¢é£é™©ã€‚ç„¶è€Œï¼ŒENSå­˜åœ¨å†…å­˜å’Œæ¨ç†å¼€é”€å¤§çš„é—®é¢˜ï¼Œè€Œä¸”å®ƒå¹¶ä¸èƒ½æé«˜å¯¹é¦–é€‰é¡¹æ•°æ®é›†ä¸­æ ‡ç­¾å™ªå£°çš„é²æ£’æ€§ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†æƒé‡å¹³å‡å¥–åŠ±æ¨¡å‹ï¼ˆWARMï¼‰ã€‚WARMé€šè¿‡å¯¹å¤šä¸ªRMçš„æƒé‡è¿›è¡Œçº¿æ€§æ’å€¼ï¼Œå°†å®ƒä»¬åˆå¹¶æˆä¸€ä¸ªæ–°çš„RMã€‚è¿™ç§æ–¹æ³•ç»§æ‰¿äº†WAåœ¨åˆ†å¸ƒåç§»ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶æé«˜äº†å¯¹æ ‡ç­¾æŸåçš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼ŒWARMåœ¨æ•ˆç‡å’Œå®ç”¨æ€§æ–¹é¢ä¹Ÿä¼˜äºENSï¼Œå› ä¸ºå®ƒåªéœ€è¦åœ¨æ¨ç†æ—¶ä½¿ç”¨ä¸€ä¸ªæ¨¡å‹ï¼Œè€ŒENSéœ€è¦å¯¹å¤šä¸ªæ¨¡å‹çš„é¢„æµ‹è¿›è¡Œå¹³å‡ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨æœ¬æ–‡çš„å®éªŒä¸­ï¼ŒWARMåœ¨æ‘˜è¦ä»»åŠ¡ä¸Šå–å¾—äº†æ¯”ä¼ ç»ŸRLHFæ–¹æ³•æ›´å¥½çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨WARMå¾®è°ƒçš„ç­–ç•¥åœ¨å¯¹æŠ—ä½¿ç”¨å•ä¸ªRMå¾®è°ƒçš„ç­–ç•¥æ—¶ï¼Œå…·æœ‰79.4%çš„è·èƒœç‡ã€‚è¿™è¡¨æ˜WARMå¯ä»¥æœ‰æ•ˆåœ°æé«˜LLMé¢„æµ‹çš„æ•´ä½“è´¨é‡å’Œä¸€è‡´æ€§ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æƒé‡å¹³å‡å¥–åŠ±æ¨¡å‹ï¼ˆWARMï¼‰ï¼Œä»¥è§£å†³å¥–åŠ±å»ºæ¨¡ä¸­çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šåˆ†å¸ƒåç§»ä¸‹çš„å¯é æ€§å’Œæ ‡ç­¾æŸåä¸‹çš„é²æ£’æ€§ã€‚é€šè¿‡å¯¹å¤šä¸ªæ¥è‡ªä¸åŒå¾®è°ƒçš„å¥–åŠ±æ¨¡å‹çš„æƒé‡è¿›è¡Œçº¿æ€§æ’å€¼ï¼ŒWARM ä¼¼ä¹æ˜¯ä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥å‡è½»äººç±»åé¦ˆä¸­çš„å¼ºåŒ–å­¦ä¹ ä¸­çš„å¥–åŠ±é»‘å®¢é—®é¢˜ã€‚æˆ‘ä»¬çš„å®è¯ç»“æœè¯æ˜äº†å°†å…¶åº”ç”¨äºæ‘˜è¦æ—¶çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬é¢„è®¡ WARM å°†æœ‰åŠ©äºå®ç°æ›´åŠ ä¸€è‡´ã€é€æ˜å’Œæœ‰æ•ˆçš„ AI ç³»ç»Ÿï¼Œå¹¶é¼“åŠ±åœ¨å¥–åŠ±å»ºæ¨¡æ–¹é¢è¿›è¡Œè¿›ä¸€æ­¥æ¢ç´¢ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>WARM é€šè¿‡å¯¹å¤šä¸ªå¥–åŠ±æ¨¡å‹çš„æƒé‡è¿›è¡Œå¹³å‡ï¼Œå¯ä»¥æé«˜å¥–åŠ±çš„å¯é æ€§å¹¶é™ä½é»‘å®¢é£é™©ã€‚</li>
<li>WARM åœ¨æ•ˆç‡å’Œå®ç”¨æ€§æ–¹é¢ä¼˜äºé¢„æµ‹é›†æˆï¼ˆENSï¼‰ï¼Œå› ä¸ºå®ƒåªéœ€è¦åœ¨æ¨ç†æ—¶ä½¿ç”¨ä¸€ä¸ªæ¨¡å‹ï¼Œè€Œ ENS éœ€è¦å¯¹å¤šä¸ªæ¨¡å‹çš„é¢„æµ‹è¿›è¡Œå¹³å‡ã€‚</li>
<li>WARM åœ¨æ‘˜è¦ä»»åŠ¡ä¸Šå–å¾—äº†æ¯”ä¼ ç»Ÿ RLHF æ–¹æ³•æ›´å¥½çš„æ€§èƒ½ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>WARM åœ¨æ‘˜è¦ä»»åŠ¡ä¸Šå–å¾—äº†æ¯”ä¼ ç»Ÿ RLHF æ–¹æ³•æ›´å¥½çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨ WARM å¾®è°ƒçš„ç­–ç•¥åœ¨å¯¹æŠ—ä½¿ç”¨å•ä¸ª RM å¾®è°ƒçš„ç­–ç•¥æ—¶ï¼Œå…·æœ‰ 79.4% çš„è·èƒœç‡ã€‚è¿™è¡¨æ˜ WARM å¯ä»¥æœ‰æ•ˆåœ°æé«˜ LLM é¢„æµ‹çš„æ•´ä½“è´¨é‡å’Œä¸€è‡´æ€§ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>WARM åœ¨æ•ˆç‡å’Œå®ç”¨æ€§æ–¹é¢ä¼˜äºé¢„æµ‹é›†æˆï¼ˆENSï¼‰ï¼Œå› ä¸ºå®ƒåªéœ€è¦åœ¨æ¨ç†æ—¶ä½¿ç”¨ä¸€ä¸ªæ¨¡å‹ï¼Œè€Œ ENS éœ€è¦å¯¹å¤šä¸ªæ¨¡å‹çš„é¢„æµ‹è¿›è¡Œå¹³å‡ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cb30bdc7fa3fe5ca08f68a92a10b2271.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0f65c9aafc185dee21168928e8ee7151.jpg" align="middle">
</details>
â€‹    


## Temporal Blind Spots in Large Language Models
**Authors:Jonas Wallat, Adam Jatowt, Avishek Anand**

Large language models (LLMs) have recently gained significant attention due to their unparalleled ability to perform various natural language processing tasks. These models, benefiting from their advanced natural language understanding capabilities, have demonstrated impressive zero-shot performance. However, the pre-training data utilized in LLMs is often confined to a specific corpus, resulting in inherent freshness and temporal scope limitations. Consequently, this raises concerns regarding the effectiveness of LLMs for tasks involving temporal intents. In this study, we aim to investigate the underlying limitations of general-purpose LLMs when deployed for tasks that require a temporal understanding. We pay particular attention to handling factual temporal knowledge through three popular temporal QA datasets. Specifically, we observe low performance on detailed questions about the past and, surprisingly, for rather new information. In manual and automatic testing, we find multiple temporal errors and characterize the conditions under which QA performance deteriorates. Our analysis contributes to understanding LLM limitations and offers valuable insights into developing future models that can better cater to the demands of temporally-oriented tasks. The code is available\footnote{https://github.com/jwallat/temporalblindspots}. 

[PDF](http://arxiv.org/abs/2401.12078v1) accepted at WSDM'24

**æ‘˜è¦**
å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ—¶é—´ç›¸å…³ä»»åŠ¡æ—¶å­˜åœ¨å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¯¹è¿‡å»ä¿¡æ¯çš„è¯¦ç»†é—®é¢˜å’Œè¾ƒæ–°ä¿¡æ¯æ—¶ã€‚

**è¦ç‚¹**

- å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å—é™äºé¢„è®­ç»ƒè¯­æ–™åº“ï¼Œå¯¹æ—¶é—´çš„ç†è§£èƒ½åŠ›æœ‰é™ã€‚
- å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å›ç­”å…³äºè¿‡å»é—®é¢˜çš„è¯¦ç»†é—®é¢˜æ—¶è¡¨ç°ä¸ä½³ï¼Œå¯¹è¾ƒæ–°ä¿¡æ¯ä¹Ÿå­˜åœ¨ç†è§£å›°éš¾ã€‚
- é€šè¿‡æ‰‹åŠ¨å’Œè‡ªåŠ¨æµ‹è¯•å‘ç°å¤§å‹è¯­è¨€æ¨¡å‹å­˜åœ¨å¤šç§æ—¶é—´é”™è¯¯ã€‚
- å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ—¶é—´ç›¸å…³ä»»åŠ¡æ—¶ï¼Œéšç€é—®é¢˜å¯¹æ—¶é—´æ•æ„Ÿæ€§çš„å¢åŠ ï¼Œå‡†ç¡®ç‡ä¸‹é™ã€‚
- å¤§å‹è¯­è¨€æ¨¡å‹å¯¹æ—¶é—´çš„ç†è§£èƒ½åŠ›å—åˆ¶äºé¢„è®­ç»ƒæ•°æ®çš„æ—¶é—´èŒƒå›´ã€‚
- ç ”ç©¶äººå‘˜å‘ç°æ—¶é—´æ€§é—®é¢˜å¯ä»¥åˆ†ä¸ºäº‹å®æ€§é—®é¢˜ã€ä¸ªäººç»å†é—®é¢˜å’Œæ„è§é—®é¢˜ï¼Œå…¶ä¸­å¤§å‹è¯­è¨€æ¨¡å‹å¯¹äº‹å®æ€§é—®é¢˜çš„å›ç­”å‡†ç¡®ç‡æœ€é«˜ã€‚
- è¿™é¡¹ç ”ç©¶ä¸ºç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„å±€é™æ€§åšå‡ºäº†è´¡çŒ®ï¼Œå¹¶ä¸ºå¼€å‘èƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³æ—¶é—´ç›¸å…³ä»»åŠ¡éœ€æ±‚çš„æœªæ¥æ¨¡å‹æä¾›äº†å®è´µçš„è§è§£ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>è®ºæ–‡æ ‡é¢˜ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ—¶é—´ç›²ç‚¹</p>
</li>
<li><p>ä½œè€…ï¼šJonas Wallatã€Adam Jatowtã€Avishek Anand</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¾·å›½æ±‰è¯ºå¨è±å¸ƒå°¼å…¹ä¿¡æ¯ç§‘å­¦ç ”ç©¶æ‰€</p>
</li>
<li><p>å…³é”®è¯ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ã€æ—¶é—´çŸ¥è¯†ã€æ—¶é—´ç†è§£ã€é—®ç­”</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12078
Github é“¾æ¥ï¼šNone</p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ (LLM) åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é¢„è®­ç»ƒæ•°æ®é€šå¸¸å±€é™äºç‰¹å®šè¯­æ–™åº“ï¼Œå­˜åœ¨æ—¶æ•ˆæ€§å’Œæ—¶é—´èŒƒå›´çš„é™åˆ¶ï¼Œå½±å“äº†å…¶åœ¨æ¶‰åŠæ—¶é—´æ„å›¾ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨çŸ¥è¯†æ¢æµ‹ã€å¯¹æŠ—æ€§ç¤ºä¾‹å’Œé£é™©åˆ†æç­‰æ–¹é¢ï¼Œä½†å¯¹ LLM åœ¨æ—¶é—´çŸ¥è¯†å’Œç†è§£æ–¹é¢çš„ç›²ç‚¹å…³æ³¨è¾ƒå°‘ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡é€šè¿‡ä¸‰ä¸ªæ—¶é—´é—®ç­”æ•°æ®é›†ï¼ˆTemporal Questionsã€ArchivalQA å’Œ TempLAMAï¼‰å¯¹ LLM çš„æ—¶é—´çŸ¥è¯†å’Œç†è§£èƒ½åŠ›è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œé‡ç‚¹å…³æ³¨äº‹å®æ—¶é—´çŸ¥è¯†çš„å¤„ç†å’Œå¤æ‚æ—¶é—´ä¿¡æ¯çš„å¤„ç†ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½åŠå¯¹ç›®æ ‡çš„æ”¯æŒï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒLLM åœ¨æ¶‰åŠæ—¶é—´çŸ¥è¯†å’Œç†è§£çš„ä»»åŠ¡ä¸­å­˜åœ¨ç›²ç‚¹ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†è¯¦ç»†çš„å†å²é—®é¢˜å’Œç›¸å¯¹è¾ƒæ–°çš„ä¿¡æ¯æ—¶è¡¨ç°ä¸ä½³ã€‚è¿™äº›å‘ç°æœ‰åŠ©äºç†è§£ LLM çš„å±€é™æ€§ï¼Œå¹¶ä¸ºå¼€å‘èƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³æ—¶é—´å¯¼å‘ä»»åŠ¡éœ€æ±‚çš„æœªæ¥æ¨¡å‹æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰æ„ä¹‰ï¼š
æœ¬æ–‡é€šè¿‡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ—¶é—´çŸ¥è¯†å’Œç†è§£èƒ½åŠ›è¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œæ­ç¤ºäº†å…¶åœ¨æ¶‰åŠæ—¶é—´æ„å›¾ä»»åŠ¡ä¸­çš„ç›²ç‚¹ï¼Œä¸ºå¼€å‘èƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³æ—¶é—´å¯¼å‘ä»»åŠ¡éœ€æ±‚çš„æœªæ¥æ¨¡å‹æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
<p>ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹ï¼š
åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è¯„ä¼° LLM åœ¨æ—¶é—´çŸ¥è¯†å’Œç†è§£æ–¹é¢çš„èƒ½åŠ›ã€‚</li>
<li>å‘ç° LLM åœ¨å¤„ç†è¯¦ç»†çš„å†å²é—®é¢˜å’Œç›¸å¯¹è¾ƒæ–°çš„ä¿¡æ¯æ—¶è¡¨ç°ä¸ä½³ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>LLM åœ¨æ¶‰åŠæ—¶é—´çŸ¥è¯†å’Œç†è§£çš„ä»»åŠ¡ä¸­å­˜åœ¨ç›²ç‚¹ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>éœ€è¦æ”¶é›†å’Œæ ‡è®°å¤§é‡çš„æ•°æ®æ¥è¯„ä¼° LLM çš„æ—¶é—´çŸ¥è¯†å’Œç†è§£èƒ½åŠ›ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ef953dd5680b8986b519ca3040e877c7.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bb539ecbb67b0f65215a7addd3ccd09f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68a2b498e74140261d533e54124b4339.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a748627690bad5dde36e8816fc801a09.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-65999fcea7981a3e7935b9b9271ce7b8.jpg" align="middle">
</details>
â€‹    


## Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated   Text
**Authors:Abhimanyu Hans, Avi Schwarzschild, Valeriia Cherepanova, Hamid Kazemi, Aniruddha Saha, Micah Goldblum, Jonas Geiping, Tom Goldstein**

Detecting text generated by modern large language models is thought to be hard, as both LLMs and humans can exhibit a wide range of complex behaviors. However, we find that a score based on contrasting two closely related language models is highly accurate at separating human-generated and machine-generated text. Based on this mechanism, we propose a novel LLM detector that only requires simple calculations using a pair of pre-trained LLMs. The method, called Binoculars, achieves state-of-the-art accuracy without any training data. It is capable of spotting machine text from a range of modern LLMs without any model-specific modifications. We comprehensively evaluate Binoculars on a number of text sources and in varied situations. Over a wide range of document types, Binoculars detects over 90% of generated samples from ChatGPT (and other LLMs) at a false positive rate of 0.01%, despite not being trained on any ChatGPT data. 

[PDF](http://arxiv.org/abs/2401.12070v1) 20 pages, code available at https://github.com/ahans30/Binoculars

**æ‘˜è¦**
å¥æ³•ç›¸ä¼¼åº¦è¯„åˆ†å¯ä»¥å‡†ç¡®åŒºåˆ†äººç±»æ–‡æœ¬ä¸æœºå™¨æ–‡æœ¬ã€‚

**è¦ç‚¹**

- åŸºäºæ¯”è¾ƒä¸¤ä¸ªç´§å¯†ç›¸å…³çš„è¯­è¨€æ¨¡å‹çš„åˆ†æ•°ï¼Œå¯ä»¥éå¸¸å‡†ç¡®åœ°åŒºåˆ†äººç±»ç”Ÿæˆçš„æ–‡æœ¬å’Œæœºå™¨ç”Ÿæˆçš„æ–‡æœ¬ã€‚
- åŸºäºè¿™ç§æœºåˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ LLM æ£€æµ‹å™¨ï¼Œå®ƒåªéœ€è¦ä½¿ç”¨ä¸€å¯¹é¢„è®­ç»ƒçš„ LLM è¿›è¡Œç®€å•çš„è®¡ç®—ã€‚
- è¯¥æ–¹æ³•ç§°ä¸º Binocularsï¼Œåœ¨æ²¡æœ‰ä»»ä½•è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹å®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ã€‚
- å®ƒèƒ½å¤Ÿåœ¨æ²¡æœ‰ä»»ä½•ç‰¹å®šæ¨¡å‹ä¿®æ”¹çš„æƒ…å†µä¸‹è¯†åˆ«æ¥è‡ªä¸€ç³»åˆ—ç°ä»£ LLM çš„æœºå™¨æ–‡æœ¬ã€‚
- æˆ‘ä»¬å¯¹ Binoculars è¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°ï¼Œæ¶µç›–å¤šç§æ–‡æœ¬æ¥æºå’Œä¸åŒæƒ…å†µã€‚
- åœ¨å¹¿æ³›çš„æ–‡æ¡£ç±»å‹ä¸­ï¼ŒBinoculars æ£€æµ‹åˆ°è¶…è¿‡ 90% çš„æ¥è‡ª ChatGPTï¼ˆå’Œå…¶ä»– LLMï¼‰çš„ç”Ÿæˆæ ·æœ¬ï¼Œè¯¯æŠ¥ç‡ä¸º 0.01%ï¼Œå°½ç®¡å®ƒæ²¡æœ‰é’ˆå¯¹ä»»ä½• ChatGPT æ•°æ®è¿›è¡Œè®­ç»ƒã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šä½¿ç”¨åŒç­’æœ›è¿œé•œå‘ç° LLMï¼šé›¶æ ·æœ¬æ£€æµ‹æœºå™¨ç”Ÿæˆçš„æ–‡æœ¬</li>
<li>ä½œè€…ï¼šAbhimanyu Hansã€Avi Schwarzschildã€Valeriia Cherepanovaã€Hamid Kazemiã€Aniruddha Sahaã€Micah Goldblumã€Jonas Geipingã€Tom Goldstein</li>
<li>ç¬¬ä¸€ä½ä½œè€…çš„å•ä½ï¼šé©¬é‡Œå…°å¤§å­¦</li>
<li>å…³é”®è¯ï¼šLLM æ£€æµ‹ã€é›¶æ ·æœ¬æ£€æµ‹ã€è¯­è¨€æ¨¡å‹ã€æœºå™¨ç”Ÿæˆçš„æ–‡æœ¬</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12070
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/ahans30/Binoculars</li>
<li>æ‘˜è¦ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ£€æµ‹ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬è¢«è®¤ä¸ºæ˜¯ä¸€é¡¹å›°éš¾çš„ä»»åŠ¡ï¼Œå› ä¸º LLM å’Œäººéƒ½å¯ä»¥è¡¨ç°å‡ºå¹¿æ³›çš„å¤æ‚è¡Œä¸ºã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºè®­ç»ƒæ•°æ®æ¥åŒºåˆ†äººå†™æ–‡æœ¬å’Œæœºå™¨ç”Ÿæˆçš„æ–‡æœ¬ï¼Œä½†æ˜¯è¿™äº›æ–¹æ³•å¾€å¾€éœ€è¦å¤§é‡çš„æ•°æ®å’Œæ¨¡å‹è®­ç»ƒï¼Œå¹¶ä¸”å¯¹äºæ–°çš„ LLM æˆ–æ–‡æœ¬ç±»å‹å¯èƒ½ä¸é€‚ç”¨ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºä¸€ç§åŸºäºå¯¹æ¯”ä¸¤ä¸ªç´§å¯†ç›¸å…³çš„è¯­è¨€æ¨¡å‹çš„åˆ†æ•°çš„æ–°é¢– LLM æ£€æµ‹å™¨ï¼Œç§°ä¸ºåŒç­’æœ›è¿œé•œã€‚è¯¥æ–¹æ³•ä»…éœ€ä½¿ç”¨é¢„è®­ç»ƒçš„ LLM å¯¹è¿›è¡Œç®€å•çš„è®¡ç®—ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½å’Œå¯¹ç›®æ ‡çš„æ”¯æŒï¼šåŒç­’æœ›è¿œé•œåœ¨å„ç§æ–‡æœ¬æ¥æºå’Œä¸åŒæƒ…å†µä¸‹è¿›è¡Œäº†å…¨é¢çš„è¯„ä¼°ã€‚åœ¨å¹¿æ³›çš„æ–‡ä»¶ç±»å‹ä¸­ï¼ŒåŒç­’æœ›è¿œé•œæ£€æµ‹åˆ°è¶…è¿‡ 90% çš„æ¥è‡ªèŠå¤©æœºå™¨äººå’Œå…¶ä»– LLM ç”Ÿæˆçš„æ ·æœ¬ï¼Œè¯¯æŠ¥ç‡ä¸º 0.01%ï¼Œå°½ç®¡å®ƒæ²¡æœ‰åœ¨ä»»ä½•èŠå¤©æœºå™¨äººæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”ä¸¤ä¸ªç´§å¯†ç›¸å…³çš„è¯­è¨€æ¨¡å‹çš„åˆ†æ•°çš„æ–°é¢–LLMæ£€æµ‹å™¨ï¼Œç§°ä¸ºåŒç­’æœ›è¿œé•œã€‚è¯¥æ–¹æ³•ä»…éœ€ä½¿ç”¨é¢„è®­ç»ƒçš„LLMå¯¹è¿›è¡Œç®€å•çš„è®¡ç®—ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®ï¼Œåœ¨å¹¿æ³›çš„æ–‡ä»¶ç±»å‹ä¸­ï¼ŒåŒç­’æœ›è¿œé•œæ£€æµ‹åˆ°è¶…è¿‡90%çš„æ¥è‡ªèŠå¤©æœºå™¨äººå’Œå…¶ä»–LLMç”Ÿæˆçš„æ ·æœ¬ï¼Œè¯¯æŠ¥ç‡ä¸º0.01%ï¼Œå°½ç®¡å®ƒæ²¡æœ‰åœ¨ä»»ä½•èŠå¤©æœºå™¨äººæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
åˆ›æ–°ç‚¹ä¸€ï¼šæå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”ä¸¤ä¸ªç´§å¯†ç›¸å…³çš„è¯­è¨€æ¨¡å‹çš„åˆ†æ•°çš„æ–°é¢–LLMæ£€æµ‹å™¨ï¼Œç§°ä¸ºåŒç­’æœ›è¿œé•œã€‚
åˆ›æ–°ç‚¹äºŒï¼šè¯¥æ–¹æ³•ä»…éœ€ä½¿ç”¨é¢„è®­ç»ƒçš„LLMå¯¹è¿›è¡Œç®€å•çš„è®¡ç®—ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®ã€‚
æ€§èƒ½ï¼š
æ€§èƒ½ä¸€ï¼šåœ¨å¹¿æ³›çš„æ–‡ä»¶ç±»å‹ä¸­ï¼ŒåŒç­’æœ›è¿œé•œæ£€æµ‹åˆ°è¶…è¿‡90%çš„æ¥è‡ªèŠå¤©æœºå™¨äººå’Œå…¶ä»–LLMç”Ÿæˆçš„æ ·æœ¬ã€‚
æ€§èƒ½äºŒï¼šè¯¯æŠ¥ç‡ä¸º0.01%ã€‚
å·¥ä½œé‡ï¼š
å·¥ä½œé‡ä¸€ï¼šè¯¥æ–¹æ³•ä»…éœ€ä½¿ç”¨é¢„è®­ç»ƒçš„LLMå¯¹è¿›è¡Œç®€å•çš„è®¡ç®—ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒæ•°æ®ã€‚</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dd3bfb5b9d052c9fd7839e210dcdc353.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Blinded-by-Generated-Contexts-How-Language-Models-Merge-Generated-and-Retrieved-Contexts-for-Open-Domain-QA"><a href="#Blinded-by-Generated-Contexts-How-Language-Models-Merge-Generated-and-Retrieved-Contexts-for-Open-Domain-QA" class="headerlink" title="Blinded by Generated Contexts: How Language Models Merge Generated and   Retrieved Contexts for Open-Domain QA?"></a>Blinded by Generated Contexts: How Language Models Merge Generated and   Retrieved Contexts for Open-Domain QA?</h2><p><strong>Authors:Hexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi Cao, Xueqi Cheng</strong></p>
<p>While auxiliary information has become a key to enhance Large Language Models (LLMs), relatively little is known about how well LLMs merge these contexts, specifically generated and retrieved. To study this, we formulate a task specifically designed to identify whether the answers, derived from the integration of generated and retrieved contexts, are attributed to either generated or retrieved contexts. To support this task, we develop a methodology to construct datasets with conflicting contexts, where each question is paired with both generated and retrieved contexts, yet only one of them contains the correct answer. Our experiments reveal a significant bias in LLMs towards generated contexts, as evidenced across state-of-the-art open (Llama2-7b/13b) and closed (GPT 3.5/4) systems. We further identify two key factors contributing to this bias: i) Contexts generated by LLMs typically show greater similarity to the questions, increasing their likelihood of selection; ii) The segmentation process used in retrieved contexts disrupts their completeness, thereby hindering their full utilization in LLMs. Our analysis enhances the understanding of how LLMs merge diverse contexts, offering valuable insights for advancing current augmentation methods for LLMs. </p>
<p><a href="http://arxiv.org/abs/2401.11911v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹å¯¹ç”Ÿæˆå’Œæ£€ç´¢ä¸Šä¸‹æ–‡çš„æ•´åˆå­˜åœ¨åè§ï¼Œæ›´å¤šåœ°ä¾èµ–ç”Ÿæˆä¸Šä¸‹æ–‡ä¸­çš„ä¿¡æ¯ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>å¤§å‹è¯­è¨€æ¨¡å‹å¯¹ç”Ÿæˆä¸Šä¸‹æ–‡çš„æ•´åˆå­˜åœ¨æ˜æ˜¾åè§ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹æ›´å€¾å‘äºé€‰æ‹©ä¸é—®é¢˜æ›´ç›¸ä¼¼çš„ç”Ÿæˆä¸Šä¸‹æ–‡ä½œä¸ºç­”æ¡ˆæ¥æºã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•´åˆæ£€ç´¢ä¸Šä¸‹æ–‡çš„è¿‡ç¨‹ä¸­å­˜åœ¨ä¸€å®šå›°éš¾ï¼Œæ£€ç´¢ä¸Šä¸‹æ–‡çš„ä¸å®Œæ•´æ€§å¯èƒ½å½±å“äº†ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚</li>
<li>é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç°æœ‰ä¸Šä¸‹æ–‡å¢å¼ºæ–¹æ³•éœ€è¦æ”¹è¿›ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•´åˆç”Ÿæˆå’Œæ£€ç´¢ä¸Šä¸‹æ–‡çš„è¿‡ç¨‹ä¸­è¡¨ç°å‡ºå·®å¼‚ï¼Œç†è§£è¿™ç§å·®å¼‚æœ‰åŠ©äºæ”¹è¿›å½“å‰çš„å¢å¼ºæ–¹æ³•ã€‚</li>
<li>å½±å“å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šä¸‹æ–‡æ•´åˆçš„ä¸¤ä¸ªå…³é”®å› ç´ ï¼šç¬¬ä¸€ï¼Œç”Ÿæˆä¸Šä¸‹æ–‡çš„ç›¸ä¼¼æ€§ï¼›ç¬¬äºŒï¼Œæ£€ç´¢ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§ã€‚</li>
<li>å¤§å‹è¯­è¨€æ¨¡å‹æ•´åˆä¸Šä¸‹æ–‡çš„èƒ½åŠ›å¯ä»¥é€šè¿‡ç†è§£å’Œè§£å†³è¿™äº›å› ç´ æ¥æé«˜ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>æ ‡é¢˜ï¼šç”Ÿæˆè¯­å¢ƒæ©ç›–ï¼šè¯­è¨€æ¨¡å‹å¦‚ä½•å°†ç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒèåˆç”¨äºå¼€æ”¾åŸŸé—®ç­”ï¼Ÿ</p>
</li>
<li><p>ä½œè€…ï¼šè°­é¹¤ç¿”ï¼Œå­™é£ï¼Œæ¨ä¸‡é‡Œï¼Œç‹å…ƒå“ï¼Œæ›¹çªï¼Œç¨‹é›ªå¯</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢è®¡ç®—æŠ€æœ¯ç ”ç©¶æ‰€äººå·¥æ™ºèƒ½å®‰å…¨ä¸å¯ä¿¡èµ–å®éªŒå®¤</p>
</li>
<li><p>å…³é”®è¯ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ã€ç”Ÿæˆå¢å¼ºã€æ£€ç´¢å¢å¼ºã€å†²çªè¯­å¢ƒã€é—®ç­”</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11911ï¼ŒGithub é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œåˆ©ç”¨è¾…åŠ©ä¿¡æ¯å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²æˆä¸ºä¸€é¡¹é‡è¦ç ”ç©¶æ–¹å‘ã€‚ç„¶è€Œï¼Œå¯¹äº LLM å¦‚ä½•èåˆä¸åŒæ¥æºçš„è¯­å¢ƒï¼Œç‰¹åˆ«æ˜¯ç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒï¼Œç›®å‰çš„ç ”ç©¶è¿˜ç›¸å¯¹è¾ƒå°‘ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰å·¥ä½œä¸»è¦åˆ†ä¸ºç”Ÿæˆå¢å¼ºå’Œæ£€ç´¢å¢å¼ºä¸¤ç§æ–¹æ³•ã€‚ç”Ÿæˆå¢å¼ºæ–¹æ³•é€šè¿‡ç”Ÿæˆä¸é—®é¢˜ç›¸å…³çš„èƒŒæ™¯è¯­å¢ƒï¼Œä½œä¸º LLM å›ç­”é—®é¢˜çš„ä¾æ®ã€‚æ£€ç´¢å¢å¼ºæ–¹æ³•é€šè¿‡ä»å¤–éƒ¨è¯­æ–™åº“ä¸­æ£€ç´¢ç›¸å…³æ®µè½ä½œä¸ºè¯­å¢ƒï¼Œä»¥å¢å¼º LLM çš„çŸ¥è¯†ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•éƒ½å­˜åœ¨ä¸€å®šçš„é—®é¢˜ã€‚ç”Ÿæˆå¢å¼ºæ–¹æ³•ç”Ÿæˆçš„è¯­å¢ƒå¯èƒ½ä¸é—®é¢˜ä¸ä¸€è‡´ï¼Œæ£€ç´¢å¢å¼ºæ–¹æ³•æ£€ç´¢åˆ°çš„è¯­å¢ƒå¯èƒ½ä¸å®Œæ•´æˆ–ä¸é—®é¢˜æ— å…³ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†ç ”ç©¶ LLM å¦‚ä½•èåˆç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä»»åŠ¡ï¼Œå³å†²çªè¯­å¢ƒé—®ç­”ä»»åŠ¡ã€‚è¯¥ä»»åŠ¡æ—¨åœ¨è¯†åˆ« LLM åœ¨èåˆç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒæ—¶ï¼Œæ˜¯å¦å€¾å‘äºå°†ç­”æ¡ˆå½’å› äºæŸä¸ªç‰¹å®šçš„è¯­å¢ƒã€‚ä¸ºäº†æ”¯æŒè¯¥ä»»åŠ¡ï¼Œæœ¬æ–‡è¿˜å¼€å‘äº†ä¸€ç§æ„å»ºå†²çªè¯­å¢ƒæ•°æ®é›†çš„æ–¹æ³•ã€‚è¯¥æ•°æ®é›†ä¸­çš„æ¯ä¸ªé—®é¢˜éƒ½é…å¯¹æœ‰ç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒï¼Œä½†åªæœ‰å…¶ä¸­ä¸€ä¸ªè¯­å¢ƒåŒ…å«æ­£ç¡®ç­”æ¡ˆã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœä¸æ€§èƒ½ï¼šæœ¬æ–‡åœ¨å†²çªè¯­å¢ƒé—®ç­”ä»»åŠ¡ä¸Šå¯¹ LLM è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ LLM å­˜åœ¨æ˜æ˜¾çš„ç”Ÿæˆè¯­å¢ƒåå¥½ã€‚è¿™ç§åå¥½ä½“ç°åœ¨å„ä¸ªæœ€å…ˆè¿›çš„å¼€æ”¾åŸŸï¼ˆLlama2-7b/13bï¼‰å’Œå°é—­åŸŸï¼ˆGPT3.5/4ï¼‰ç³»ç»Ÿä¸­ã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼Œè¿™ç§åå¥½ä¸»è¦ç”±ä¸¤ä¸ªå› ç´ å¯¼è‡´ï¼šä¸€æ˜¯ç”Ÿæˆè¯­å¢ƒé€šå¸¸ä¸é—®é¢˜æ›´ç›¸ä¼¼ï¼Œå› æ­¤æ›´å®¹æ˜“è¢« LLM é€‰æ‹©ï¼›äºŒæ˜¯æ£€ç´¢è¯­å¢ƒåœ¨è¢«åˆ†å‰²æˆæ®µè½åï¼Œå…¶å®Œæ•´æ€§å—åˆ°ç ´åï¼Œä»è€Œéš¾ä»¥è¢« LLM å……åˆ†åˆ©ç”¨ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ä»»åŠ¡å®šä¹‰ï¼šå†²çªè¯­å¢ƒé—®ç­”ä»»åŠ¡ã€‚ç»™å®šä¸€ä¸ªé—®é¢˜å’Œä¸¤ä¸ªè¯­å¢ƒï¼Œä¸€ä¸ªç”±ç”Ÿæˆå™¨ç”Ÿæˆï¼Œå¦ä¸€ä¸ªç”±æ£€ç´¢å™¨æ£€ç´¢ï¼Œåˆ¤æ–­ç­”æ¡ˆæ¥è‡ªå“ªä¸ªè¯­å¢ƒã€‚
ï¼ˆ2ï¼‰æ•°æ®é›†æ„å»ºï¼šæ„å»ºå†²çªè¯­å¢ƒæ•°æ®é›†ï¼Œæ¯ä¸ªé—®é¢˜é…å¯¹æœ‰ç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒï¼Œä½†åªæœ‰å…¶ä¸­ä¸€ä¸ªè¯­å¢ƒåŒ…å«æ­£ç¡®ç­”æ¡ˆã€‚
ï¼ˆ3ï¼‰æ¨¡å‹è¯„ä¼°ï¼šåœ¨å†²çªè¯­å¢ƒé—®ç­”ä»»åŠ¡ä¸Šè¯„ä¼° LLMï¼Œåˆ†æ LLM åœ¨èåˆç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒæ—¶çš„åå¥½ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ä»»åŠ¡â€”â€”å†²çªè¯­å¢ƒé—®ç­”ä»»åŠ¡ï¼Œç”¨äºç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨èåˆç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒæ—¶çš„åå¥½ã€‚è¯¥ä»»åŠ¡æ—¨åœ¨è¯†åˆ« LLM åœ¨èåˆç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒæ—¶ï¼Œæ˜¯å¦å€¾å‘äºå°†ç­”æ¡ˆå½’å› äºæŸä¸ªç‰¹å®šçš„è¯­å¢ƒã€‚ä¸ºäº†æ”¯æŒè¯¥ä»»åŠ¡ï¼Œæœ¬æ–‡è¿˜å¼€å‘äº†ä¸€ç§æ„å»ºå†²çªè¯­å¢ƒæ•°æ®é›†çš„æ–¹æ³•ã€‚è¯¥æ•°æ®é›†ä¸­çš„æ¯ä¸ªé—®é¢˜éƒ½é…å¯¹æœ‰ç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒï¼Œä½†åªæœ‰å…¶ä¸­ä¸€ä¸ªè¯­å¢ƒåŒ…å«æ­£ç¡®ç­”æ¡ˆã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°çš„ä»»åŠ¡â€”â€”å†²çªè¯­å¢ƒé—®ç­”ä»»åŠ¡ï¼Œç”¨äºç ”ç©¶ LLM åœ¨èåˆç”Ÿæˆè¯­å¢ƒå’Œæ£€ç´¢è¯­å¢ƒæ—¶çš„åå¥½ã€‚
å¼€å‘äº†ä¸€ç§æ„å»ºå†²çªè¯­å¢ƒæ•°æ®é›†çš„æ–¹æ³•ã€‚
æ€§èƒ½ï¼š
åœ¨å†²çªè¯­å¢ƒé—®ç­”ä»»åŠ¡ä¸Šè¯„ä¼° LLMï¼Œç»“æœè¡¨æ˜ LLM å­˜åœ¨æ˜æ˜¾çš„ç”Ÿæˆè¯­å¢ƒåå¥½ã€‚è¿™ç§åå¥½ä½“ç°åœ¨å„ä¸ªæœ€å…ˆè¿›çš„å¼€æ”¾åŸŸï¼ˆLlama2-7b/13bï¼‰å’Œå°é—­åŸŸï¼ˆGPT3.5/4ï¼‰ç³»ç»Ÿä¸­ã€‚
è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼Œè¿™ç§åå¥½ä¸»è¦ç”±ä¸¤ä¸ªå› ç´ å¯¼è‡´ï¼šä¸€æ˜¯ç”Ÿæˆè¯­å¢ƒé€šå¸¸ä¸é—®é¢˜æ›´ç›¸ä¼¼ï¼Œå› æ­¤æ›´å®¹æ˜“è¢« LLM é€‰æ‹©ï¼›äºŒæ˜¯æ£€ç´¢è¯­å¢ƒåœ¨è¢«åˆ†å‰²æˆæ®µè½åï¼Œå…¶å®Œæ•´æ€§å—åˆ°ç ´åï¼Œä»è€Œéš¾ä»¥è¢« LLM å……åˆ†åˆ©ç”¨ã€‚
å·¥ä½œé‡ï¼š
æ„å»ºå†²çªè¯­å¢ƒæ•°æ®é›†çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦æ”¶é›†å¤§é‡çš„é—®é¢˜å’Œè¯­å¢ƒï¼Œå¹¶è¿›è¡Œäººå·¥æ ‡æ³¨ã€‚
è¯„ä¼° LLM åœ¨å†²çªè¯­å¢ƒé—®ç­”ä»»åŠ¡ä¸Šçš„è¡¨ç°çš„å·¥ä½œé‡ä¹Ÿè¾ƒå¤§ï¼Œéœ€è¦å¯¹ LLM è¿›è¡Œå¤šæ¬¡è¯„ä¼°ï¼Œå¹¶åˆ†æè¯„ä¼°ç»“æœã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-aff8facaa355b1505b2cf6af3d0e915b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1ee80fef672e8714cbda66ee9ba9e921.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-32c0aa5250fcb9295d1e46e737e52534.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-99f94640fc796568a6b02c8056191892.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c63733100557d4290705642b87c665f9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8815deb3960e6b2bbbe8b92e6f8e6799.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="PsySafe-A-Comprehensive-Framework-for-Psychological-based-Attack-Defense-and-Evaluation-of-Multi-agent-System-Safety"><a href="#PsySafe-A-Comprehensive-Framework-for-Psychological-based-Attack-Defense-and-Evaluation-of-Multi-agent-System-Safety" class="headerlink" title="PsySafe: A Comprehensive Framework for Psychological-based Attack,   Defense, and Evaluation of Multi-agent System Safety"></a>PsySafe: A Comprehensive Framework for Psychological-based Attack,   Defense, and Evaluation of Multi-agent System Safety</h2><p><strong>Authors:Zaibin Zhang, Yongting Zhang, Lijun Li, Hongzhi Gao, Lijun Wang, Huchuan Lu, Feng Zhao, Yu Qiao, Jing Shao</strong></p>
<p>Multi-agent systems, augmented with Large Language Models (LLMs), demonstrate significant capabilities for collective intelligence. However, the potential misuse of this intelligence for malicious purposes presents significant risks. To date, comprehensive research on the safety issues associated with multi-agent systems remains limited. From the perspective of agent psychology, we discover that the dark psychological states of agents can lead to severe safety issues. To address these issues, we propose a comprehensive framework grounded in agent psychology. In our framework, we focus on three aspects: identifying how dark personality traits in agents might lead to risky behaviors, designing defense strategies to mitigate these risks, and evaluating the safety of multi-agent systems from both psychological and behavioral perspectives. Our experiments reveal several intriguing phenomena, such as the collective dangerous behaviors among agents, agentsâ€™ propensity for self-reflection when engaging in dangerous behavior, and the correlation between agentsâ€™ psychological assessments and their dangerous behaviors. We anticipate that our framework and observations will provide valuable insights for further research into the safety of multi-agent systems. We will make our data and code publicly accessible at https:/github.com/AI4Good24/PsySafe. </p>
<p><a href="http://arxiv.org/abs/2401.11880v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹ (LLM)ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„é›†ä½“æ™ºèƒ½èƒ½åŠ›ï¼Œä½†ä¹Ÿå­˜åœ¨è¢«æ¶æ„åˆ©ç”¨çš„é£é™©ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§é—®é¢˜å°šæœªå¾—åˆ°å…¨é¢ç ”ç©¶ã€‚</li>
<li>ä»æ™ºèƒ½ä½“å¿ƒç†å­¦è§’åº¦æ¥çœ‹ï¼Œæ™ºèƒ½ä½“çš„é»‘æš—å¿ƒç†çŠ¶æ€å¯èƒ½å¯¼è‡´ä¸¥é‡çš„å®‰å…¨é—®é¢˜ã€‚</li>
<li>æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºæ™ºèƒ½ä½“å¿ƒç†å­¦çš„ç»¼åˆæ¡†æ¶ï¼Œé‡ç‚¹å…³æ³¨ä¸‰ä¸ªæ–¹é¢ï¼šè¯†åˆ«æ™ºèƒ½ä½“ä¸­çš„é»‘æš—äººæ ¼ç‰¹è´¨å¦‚ä½•å¯¼è‡´å±é™©è¡Œä¸ºã€è®¾è®¡é˜²å¾¡ç­–ç•¥æ¥å‡è½»è¿™äº›é£é™©ï¼Œä»¥åŠä»å¿ƒç†å’Œè¡Œä¸ºä¸¤ä¸ªè§’åº¦è¯„ä¼°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚</li>
<li>æˆ‘ä»¬çš„å®éªŒæ­ç¤ºäº†ä¸€äº›æœ‰è¶£çš„ç°è±¡ï¼Œä¾‹å¦‚æ™ºèƒ½ä½“ä¹‹é—´çš„é›†ä½“å±é™©è¡Œä¸ºã€æ™ºèƒ½ä½“åœ¨ä»äº‹å±é™©è¡Œä¸ºæ—¶çš„è‡ªæˆ‘åçœå€¾å‘ï¼Œä»¥åŠæ™ºèƒ½ä½“çš„å¿ƒç†è¯„ä¼°ä¸å…¶å±é™©è¡Œä¸ºä¹‹é—´çš„ç›¸å…³æ€§ã€‚</li>
<li>æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ¡†æ¶å’Œè§‚å¯Ÿç»“æœå°†ä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå®‰å…¨æ€§çš„è¿›ä¸€æ­¥ç ”ç©¶æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>è®ºæ–‡æ ‡é¢˜ï¼šé»‘æš—äººæ ¼ç‰¹è´¨æ”»å‡»æç¤ºï¼šç”¨äºå±é™©ä»»åŠ¡è¯„ä¼°çš„æç¤º</p>
</li>
<li><p>ä½œè€…ï¼šYihan Wang, Qiang Zhang, Yuxin Peng, Xiaotong Li, Jingbo Shang, Xiangliang Zhang, Yujie Zhang, Jie Tang, Yong Yu</p>
</li>
<li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ–¯å¦ç¦å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€é»‘æš—äººæ ¼ç‰¹è´¨ã€å®‰å…¨ã€å¿ƒç†ã€è¡Œä¸º</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09358ï¼ŒGithub ä»£ç é“¾æ¥ï¼šGithubï¼šNone</p>
</li>
<li><p>æ‘˜è¦ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¢å¼ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå±•ç¤ºäº†é›†ä½“æ™ºèƒ½çš„æ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå°†è¿™ç§æ™ºèƒ½æ¶æ„ç”¨äºæ¶æ„ç›®çš„çš„æ½œåœ¨æ»¥ç”¨å¸¦æ¥äº†é‡å¤§é£é™©ã€‚è¿„ä»Šä¸ºæ­¢ï¼Œå…³äºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿå®‰å…¨é—®é¢˜çš„å…¨é¢ç ”ç©¶ä»ç„¶æœ‰é™ã€‚</p>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»ä»£ç†å¿ƒç†å­¦è§’åº¦ï¼Œæˆ‘ä»¬å‘ç°ä»£ç†çš„é»‘æš—å¿ƒç†çŠ¶æ€å¯èƒ½å¯¼è‡´ä¸¥é‡çš„å®‰å…¨é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä»¥ä»£ç†å¿ƒç†å­¦ä¸ºåŸºç¡€çš„ç»¼åˆæ¡†æ¶ã€‚</p>
<p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šåœ¨æˆ‘ä»¬çš„æ¡†æ¶ä¸­ï¼Œæˆ‘ä»¬å…³æ³¨ä¸‰ä¸ªæ–¹é¢ï¼šè¯†åˆ«ä»£ç†ä¸­çš„é»‘æš—äººæ ¼ç‰¹è´¨å¦‚ä½•å¯¼è‡´å±é™©è¡Œä¸ºã€è®¾è®¡é˜²å¾¡ç­–ç•¥æ¥å‡è½»è¿™äº›é£é™©ï¼Œä»¥åŠä»å¿ƒç†å’Œè¡Œä¸ºè§’åº¦è¯„ä¼°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½æ–¹é¢çš„è¡¨ç°ï¼šæˆ‘ä»¬çš„å®éªŒæ­ç¤ºäº†ä¸€äº›æœ‰è¶£çš„ç°è±¡ï¼Œä¾‹å¦‚ä»£ç†ä¹‹é—´çš„é›†ä½“å±é™©è¡Œä¸ºã€ä»£ç†åœ¨ä»äº‹å±é™©è¡Œä¸ºæ—¶è¿›è¡Œè‡ªæˆ‘åçœçš„å€¾å‘ï¼Œä»¥åŠä»£ç†çš„å¿ƒç†è¯„ä¼°ä¸å…¶å±é™©è¡Œä¸ºä¹‹é—´çš„ç›¸å…³æ€§ã€‚æˆ‘ä»¬é¢„è®¡ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å’Œè§‚å¯Ÿç»“æœå°†ä¸ºè¿›ä¸€æ­¥ç ”ç©¶å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
<ol start="7">
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºä¸€ä¸ªåŸºäºä»£ç†å¿ƒç†å­¦çš„ç»¼åˆæ¡†æ¶ï¼Œå…³æ³¨ä»£ç†ä¸­çš„é»‘æš—äººæ ¼ç‰¹è´¨å¦‚ä½•å¯¼è‡´å±é™©è¡Œä¸ºã€è®¾è®¡é˜²å¾¡ç­–ç•¥æ¥å‡è½»è¿™äº›é£é™©ï¼Œä»¥åŠä»å¿ƒç†å’Œè¡Œä¸ºè§’åº¦è¯„ä¼°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼›
ï¼ˆ2ï¼‰é€šè¿‡å®éªŒæ­ç¤ºäº†ä¸€äº›æœ‰è¶£çš„ç°è±¡ï¼Œä¾‹å¦‚ä»£ç†ä¹‹é—´çš„é›†ä½“å±é™©è¡Œä¸ºã€ä»£ç†åœ¨ä»äº‹å±é™©è¡Œä¸ºæ—¶è¿›è¡Œè‡ªæˆ‘åçœçš„å€¾å‘ï¼Œä»¥åŠä»£ç†çš„å¿ƒç†è¯„ä¼°ä¸å…¶å±é™©è¡Œä¸ºä¹‹é—´çš„ç›¸å…³æ€§ï¼›
ï¼ˆ3ï¼‰åˆ†æäº†ä¸åŒæç¤ºå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå±é™©ç‡çš„å½±å“ï¼ŒåŒ…æ‹¬æ‰‹å·¥åˆ¶ä½œçš„è¶Šç‹±æç¤ºã€é»‘æš—ç‰¹è´¨æç¤ºæ³¨å…¥ã€è¯±å¯¼æŒ‡ä»¤æ³¨å…¥å’Œå±é™©æ„å›¾çš„éšè—ï¼›
ï¼ˆ4ï¼‰åˆ†æäº†ä»ä¸åŒè§’åº¦æ”»å‡»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å½±å“ï¼ŒåŒ…æ‹¬äººç±»è¾“å…¥æ”»å‡»ã€é«˜é¢‘äººç±»è¾“å…¥æ”»å‡»ã€ç‰¹è´¨æ”»å‡»å’Œæ··åˆæ”»å‡»æ–¹æ³•ï¼›
ï¼ˆ5ï¼‰è¯„ä¼°äº†ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ï¼ŒåŒ…æ‹¬åŸºäº API çš„æ¨¡å‹å’Œå¼€æºæ¨¡å‹ï¼Œç ”ç©¶äº†æ¨¡å‹å¤§å°ä¸å±é™©ç‡ä¹‹é—´çš„å…³ç³»ï¼›
ï¼ˆ6ï¼‰è¿›è¡Œäº†é˜²å¾¡å®éªŒï¼Œè¯„ä¼°äº†è¾“å…¥è¿‡æ»¤å™¨ã€GPT-4 çš„æœ‰å®³æç¤ºè¯†åˆ«ã€DoctorDefense å’Œ PoliceDefense çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šä»å¿ƒç†å­¦çš„è§’åº¦ï¼Œæœ¬æ–‡å…¨é¢åˆ†æäº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§é—®é¢˜ï¼Œå¼•å…¥äº†ä¸€ç§ç»“åˆé»‘æš—äººæ ¼ç‰¹è´¨çš„æ”»å‡»æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°ç ´åå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œè¯±å‘å±é™©è¡Œä¸ºã€‚æœ¬æ–‡è¿˜æå‡ºäº†é˜²å¾¡ç­–ç•¥ï¼Œå¯ä»¥æ˜¾è‘—é™ä½å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å±é™©è¡Œä¸ºçš„é£é™©ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ç§åŒ…å«å¿ƒç†å’Œè¡Œä¸ºä¸¤ä¸ªæ–¹é¢åœ¨å†…çš„å®‰å…¨è¯„ä¼°æ–¹æ³•ï¼Œå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§è¿›è¡Œç»¼åˆè¯„ä¼°ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºä»£ç†å¿ƒç†å­¦çš„ç»¼åˆæ¡†æ¶ï¼Œå…³æ³¨ä»£ç†ä¸­çš„é»‘æš—äººæ ¼ç‰¹è´¨å¦‚ä½•å¯¼è‡´å±é™©è¡Œä¸ºã€è®¾è®¡é˜²å¾¡ç­–ç•¥æ¥å‡è½»è¿™äº›é£é™©ï¼Œä»¥åŠä»å¿ƒç†å’Œè¡Œä¸ºè§’åº¦è¯„ä¼°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼›é€šè¿‡å®éªŒæ­ç¤ºäº†ä¸€äº›æœ‰è¶£çš„ç°è±¡ï¼Œä¾‹å¦‚ä»£ç†ä¹‹é—´çš„é›†ä½“å±é™©è¡Œä¸ºã€ä»£ç†åœ¨ä»äº‹å±é™©è¡Œä¸ºæ—¶è¿›è¡Œè‡ªæˆ‘åçœçš„å€¾å‘ï¼Œä»¥åŠä»£ç†çš„å¿ƒç†è¯„ä¼°ä¸å…¶å±é™©è¡Œä¸ºä¹‹é—´çš„ç›¸å…³æ€§ï¼›åˆ†æäº†ä¸åŒæç¤ºå¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå±é™©ç‡çš„å½±å“ï¼ŒåŒ…æ‹¬æ‰‹å·¥åˆ¶ä½œçš„è¶Šç‹±æç¤ºã€é»‘æš—ç‰¹è´¨æç¤ºæ³¨å…¥ã€è¯±å¯¼æŒ‡ä»¤æ³¨å…¥å’Œå±é™©æ„å›¾çš„éšè—ï¼›åˆ†æäº†ä»ä¸åŒè§’åº¦æ”»å‡»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å½±å“ï¼ŒåŒ…æ‹¬äººç±»è¾“å…¥æ”»å‡»ã€é«˜é¢‘äººç±»è¾“å…¥æ”»å‡»ã€ç‰¹è´¨æ”»å‡»å’Œæ··åˆæ”»å‡»æ–¹æ³•ï¼›è¯„ä¼°äº†ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ï¼ŒåŒ…æ‹¬åŸºäºAPIçš„æ¨¡å‹å’Œå¼€æºæ¨¡å‹ï¼Œç ”ç©¶äº†æ¨¡å‹å¤§å°ä¸å±é™©ç‡ä¹‹é—´çš„å…³ç³»ï¼›è¿›è¡Œäº†é˜²å¾¡å®éªŒï¼Œè¯„ä¼°äº†è¾“å…¥è¿‡æ»¤å™¨ã€GPT-4çš„æœ‰å®³æç¤ºè¯†åˆ«ã€DoctorDefenseå’ŒPoliceDefenseçš„æœ‰æ•ˆæ€§ã€‚
æ€§èƒ½ï¼šæœ¬æ–‡æå‡ºçš„æ”»å‡»æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°ç ´åå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œè¯±å‘å±é™©è¡Œä¸ºã€‚æœ¬æ–‡æå‡ºçš„é˜²å¾¡ç­–ç•¥å¯ä»¥æ˜¾è‘—é™ä½å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å±é™©è¡Œä¸ºçš„é£é™©ã€‚æœ¬æ–‡æå‡ºçš„å®‰å…¨è¯„ä¼°æ–¹æ³•å¯ä»¥å¯¹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§è¿›è¡Œç»¼åˆè¯„ä¼°ã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡å¾ˆå¤§ï¼Œéœ€è¦è¿›è¡Œå¤§é‡çš„å®éªŒå’Œåˆ†æã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c838c9a54be9dc1fa902235acfd4e0fa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1dc1793d596c4da4ce3e17bd21b27f34.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Improving-Small-Language-Modelsâ€™-Mathematical-Reasoning-via-Mix-Thoughts-Distillation"><a href="#Improving-Small-Language-Modelsâ€™-Mathematical-Reasoning-via-Mix-Thoughts-Distillation" class="headerlink" title="Improving Small Language Modelsâ€™ Mathematical Reasoning via Mix Thoughts   Distillation"></a>Improving Small Language Modelsâ€™ Mathematical Reasoning via Mix Thoughts   Distillation</h2><p><strong>Authors:Xunyu Zhu, Jian Li, Yong Liu, Can Ma, Weiping Wang</strong></p>
<p>This work addresses the challenge of democratizing advanced Large Language Models (LLMs) by compressing their mathematical reasoning capabilities into sub-billion parameter Small Language Models (SLMs) without compromising performance. We introduce Equation-of-Thought Distillation (EoTD), a novel technique that encapsulates the reasoning process into equation-based representations to construct an EoTD dataset for fine-tuning SLMs. Additionally, we propose the Mix Thoughts Distillation (MTD) framework to enhance the reasoning performance of SLMs. This involves creating a reasoning dataset with multiple thought processes and using it for fine-tuning. Our experimental findings demonstrate that EoTD significantly boosts the reasoning abilities of SLMs, while MTD enables these models to achieve state-of-the-art reasoning performance. </p>
<p><a href="http://arxiv.org/abs/2401.11864v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>èåˆæ¨ç†è’¸é¦æ–¹æ³•å¢å¼ºå°è¯­è¨€æ¨¡å‹æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æ–¹ç¨‹å¼æ€ç»´è’¸é¦ (EoTD) æ˜¯ä¸€ç§æ–°é¢–çš„æŠ€æœ¯ï¼Œå°†æ¨ç†è¿‡ç¨‹å°è£…åˆ°åŸºäºæ–¹ç¨‹å¼çš„è¡¨ç¤ºä¸­ï¼Œä»¥ä¾¿ä¸ºç²¾è°ƒ SLM æ„å»º EoTD æ•°æ®é›†ã€‚</li>
<li>EoTD å¤§å¹…æå‡äº†SLMçš„æ¨ç†èƒ½åŠ›ï¼Œè€ŒMTDä½¿è¿™äº›æ¨¡å‹èƒ½å¤Ÿå®ç°æœ€å…ˆè¿›çš„æ¨ç†æ€§èƒ½ã€‚</li>
<li>æ··åˆæ€ç»´è’¸é¦ (MTD) æ¡†æ¶ç”¨äºåˆ›å»ºå…·æœ‰å¤šç§æ€ç»´è¿‡ç¨‹çš„æ¨ç†æ•°æ®é›†ï¼Œå¹¶å°†å…¶ç”¨äºç²¾è°ƒã€‚</li>
<li>EoTD æ•°æ®é›†çš„æ„å»ºæ–¹æ³•ä¸º SLM çš„æ¨ç†èƒ½åŠ›çš„æé«˜æä¾›äº†æ–°çš„æ€è·¯ã€‚</li>
<li>MTD æ¡†æ¶é€šè¿‡åˆ›å»ºå…·æœ‰å¤šç§æ€ç»´è¿‡ç¨‹çš„æ¨ç†æ•°æ®é›†ï¼Œå¯ä»¥è¿›ä¸€æ­¥å¢å¼ºSLMçš„æ¨ç†æ€§èƒ½ã€‚</li>
<li>EoTD å’Œ MTD æ–¹æ³•çš„ç»“åˆï¼Œä½¿å¾— SLM èƒ½å¤Ÿå®ç°æœ€å…ˆè¿›çš„æ¨ç†æ€§èƒ½ã€‚</li>
<li>è¿™äº›æ–¹æ³•ä¸º SLM çš„æ¨ç†èƒ½åŠ›çš„æé«˜æä¾›äº†æ–°çš„æ€è·¯ï¼Œå¹¶æœ‰æœ›åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨å­¦ä¹ ç­‰é¢†åŸŸå¾—åˆ°å¹¿æ³›çš„åº”ç”¨ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>é¢˜ç›®ï¼šé€šè¿‡æ··åˆæ€æƒ³è’¸é¦æ”¹è¿›å°å‹è¯­è¨€æ¨¡å‹çš„æ•°å­¦æ¨ç†èƒ½åŠ›</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šæœ±æ´µå®‡, æå¥, åˆ˜å‹‡, é©¬ç¿, ç‹å«å¹³</p>
</li><p></p>
<p></p><li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢ä¿¡æ¯å·¥ç¨‹ç ”ç©¶æ‰€</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šå°å‹è¯­è¨€æ¨¡å‹ï¼›æ•°å­¦æ¨ç†ï¼›è’¸é¦ï¼›æ€æƒ³é“¾ï¼›æ–¹ç¨‹æ€ç»´</p>
</li><p></p>
<p></p><li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11864</p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å‘å±•ï¼Œå…¶åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚ç„¶è€Œï¼ŒLLMçš„åºå¤§å‚æ•°è§„æ¨¡å’Œè®¡ç®—éœ€æ±‚é™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„éƒ¨ç½²ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶äººå‘˜æå‡ºäº†å°†LLMçš„æ•°å­¦æ¨ç†èƒ½åŠ›å‹ç¼©åˆ°æ•°åäº¿å‚æ•°çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ä¸­ï¼Œä»¥å®ç°æ›´å¹¿æ³›çš„éƒ¨ç½²ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡ä½¿ç”¨LLMåˆ›å»ºåŒ…å«è¯¦ç»†æ¨ç†è·¯å¾„çš„ä¸°å¯Œæ•°æ®é›†ï¼Œç„¶åå¾®è°ƒSLMæ¥å®ç°çŸ¥è¯†è¿ç§»ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨æ•°å­¦é—®é¢˜æ±‚è§£æ–¹é¢å­˜åœ¨æ˜æ˜¾çš„å·®è·ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œæ–¹ç¨‹æ€ç»´è’¸é¦â€ï¼ˆEoTDï¼‰çš„æ¡†æ¶æ¥å¢å¼ºSLMçš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚EoTDé¦–å…ˆæç¤ºLLMå¯¹é—®é¢˜ç”Ÿæˆæ–¹ç¨‹ï¼Œç„¶åä½¿ç”¨æ–¹ç¨‹æ±‚è§£å™¨æ±‚è§£è¿™äº›æ–¹ç¨‹ã€‚ä¸äº§ç”Ÿæ­£ç¡®è§£çš„æ–¹ç¨‹ä¼šè¢«ä¸¢å¼ƒã€‚åˆ©ç”¨è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬æ„å»ºäº†EoTDæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨è¯¥æ•°æ®é›†å¾®è°ƒSLMï¼Œä»è€Œæå‡äº†SLMçš„æ¨ç†èƒ½åŠ›ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨æ•°å­¦é—®é¢˜æ±‚è§£ä»»åŠ¡ä¸Šï¼ŒEoTDæ˜¾è‘—æé«˜äº†SLMçš„æ¨ç†èƒ½åŠ›ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†æ··åˆæ€æƒ³è’¸é¦ï¼ˆMTDï¼‰æ¡†æ¶ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†SLMçš„æ¨ç†æ€§èƒ½ã€‚MTDé€šè¿‡åˆ›å»ºä¸€ä¸ªåŒ…å«å¤šç§æ¨ç†è¿‡ç¨‹çš„æ¨ç†æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨è¯¥æ•°æ®é›†å¾®è°ƒSLMæ¥å®ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMTDä½¿SLMåœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœè¯æ˜äº†EoTDå’ŒMTDæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå°†LLMçš„æ•°å­¦æ¨ç†èƒ½åŠ›å‹ç¼©åˆ°SLMä¸­æä¾›äº†æ–°çš„æ€è·¯ã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š
(1) æ–¹ç¨‹æ€ç»´è’¸é¦ï¼ˆEoTDï¼‰ï¼š</p><p></p>
<ul>
<li>ä»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”ŸæˆåŒ…å«æ–¹ç¨‹çš„æ¨ç†æ•°æ®é›†ã€‚</li>
<li>ä½¿ç”¨æ–¹ç¨‹æ±‚è§£å™¨æ±‚è§£è¿™äº›æ–¹ç¨‹ï¼Œå¹¶ä¸¢å¼ƒä¸äº§ç”Ÿæ­£ç¡®è§£çš„æ–¹ç¨‹ã€‚</li>
<li>åˆ©ç”¨è¯¥æ•°æ®é›†å¾®è°ƒå°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ï¼Œä»¥æå‡å…¶æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚
(2) æ··åˆæ€æƒ³è’¸é¦ï¼ˆMTDï¼‰ï¼š</li>
<li>æ„å»ºåŒ…å«å¤šç§æ¨ç†è¿‡ç¨‹çš„æ¨ç†æ•°æ®é›†ã€‚</li>
<li>ä½¿ç”¨è¯¥æ•°æ®é›†å¾®è°ƒ SLMï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºå…¶æ¨ç†æ€§èƒ½ã€‚
(3) MTD çš„ä¼˜åŠ¿ï¼š</li>
<li>ç»“åˆäº†æ–¹ç¨‹æ€ç»´è’¸é¦ã€é“¾å¼æ€ç»´è’¸é¦å’Œç¨‹åºæ€ç»´è’¸é¦çš„ä¼˜ç‚¹ã€‚</li>
<li>å¼¥è¡¥äº†å„æ€æƒ³è¿‡ç¨‹çš„ä¸è¶³ï¼Œå¢å¼ºäº† SLM çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚</li>
</ul>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶å·¥ä½œçš„é‡è¦æ„ä¹‰åœ¨äºï¼Œå®ƒä¸ºå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelsï¼ŒLLMsï¼‰å…ˆè¿›çš„æ¨ç†èƒ½åŠ›å‹ç¼©åˆ°å°è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆSmall Language Modelsï¼ŒSLMsï¼‰ä¸­è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚é€šè¿‡æå‡ºæ–¹ç¨‹æ€ç»´è’¸é¦ï¼ˆEquation-of-Thought Distillationï¼ŒEoTDï¼‰å’Œæ··åˆæ€æƒ³è’¸é¦ï¼ˆMix Thoughts Distillationï¼ŒMTDï¼‰æ–¹æ³•ï¼Œæˆ‘ä»¬è¯æ˜äº†å°† LLMs çš„æ•°å­¦æ¨ç†èƒ½åŠ›å‹ç¼©åˆ°å‚æ•°é‡å°‘äºåäº¿çš„ SLMs ä¸­æ˜¯å¯è¡Œçš„ã€‚EoTD æ–¹æ³•æœ‰æ•ˆåœ°æ•è·äº†åŸºäºæ–¹ç¨‹çš„æ¨ç†è¿‡ç¨‹ï¼Œä¿ƒè¿›äº† SLMs å¯¹æ•°å­¦æ¨ç†çš„ç†è§£å’Œç”Ÿæˆã€‚MTD æ¡†æ¶é€šè¿‡ç»“åˆå¤šç§æ¨ç†è¿‡ç¨‹çš„æ•°æ®é›†è¿›ä¸€æ­¥å¢å¼ºäº† SLMs çš„æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶åœ¨æ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è’¸é¦æ¡†æ¶ EoTDï¼Œè¯¥æ¡†æ¶å¯ä»¥å°† LLMs çš„æ•°å­¦æ¨ç†èƒ½åŠ›å‹ç¼©åˆ° SLMs ä¸­ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªåŒ…å«æ–¹ç¨‹çš„æ¨ç†æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨è¯¥æ•°æ®é›†å¾®è°ƒ SLMsï¼Œä»¥æå‡å…¶æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è’¸é¦æ¡†æ¶ MTDï¼Œè¯¥æ¡†æ¶å¯ä»¥ç»“åˆå¤šç§æ¨ç†è¿‡ç¨‹çš„æ•°æ®é›†æ¥å¾®è°ƒ SLMsï¼Œè¿›ä¸€æ­¥å¢å¼ºå…¶æ¨ç†æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>EoTD å’Œ MTD æ–¹æ³•åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—æé«˜äº† SLMs çš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šï¼ŒMTD ä½¿ SLMs è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>EoTD å’Œ MTD æ–¹æ³•éœ€è¦æ„å»ºæ¨ç†æ•°æ®é›†å¹¶å¾®è°ƒ SLMsï¼Œè¿™éœ€è¦ä¸€å®šçš„å·¥ä½œé‡ã€‚</li>
<li>EoTD å’Œ MTD æ–¹æ³•éœ€è¦ä½¿ç”¨æ–¹ç¨‹æ±‚è§£å™¨æ¥æ±‚è§£æ–¹ç¨‹ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4f7748b843608736dabf6b6cc14b4ee1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d7fdb18ed70f0091f9dbdbddc997d51.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7c622575f8bb790ddfec633e22a66d78.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9c9ffd2b8828d29126e178af6f1f45c3.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Speak-It-Out-Solving-Symbol-Related-Problems-with-Symbol-to-Language-Conversion-for-Language-Models"><a href="#Speak-It-Out-Solving-Symbol-Related-Problems-with-Symbol-to-Language-Conversion-for-Language-Models" class="headerlink" title="Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language   Conversion for Language Models"></a>Speak It Out: Solving Symbol-Related Problems with Symbol-to-Language   Conversion for Language Models</h2><p><strong>Authors:Yile Wang, Sijie Cheng, Zixin Sun, Peng Li, Yang Liu</strong></p>
<p>Symbols (or more broadly, non-natural language textual representations) such as numerical sequences, molecular formulas, and table delimiters widely exist, playing important roles in various tasks such as abstract reasoning, chemical property prediction, and table question answering. Despite the impressive natural language comprehension capabilities of large language models (LLMs), their reasoning abilities for symbols remain inadequate, which could attributed to the difference between symbol representations and general natural languages. We propose symbol-to-language (S2L), a tuning-free method that enables large language models to solve symbol-related problems with information expressed in natural language. Specifically, S2L first converts the symbols involved to language-based representations, which can be implemented by prompting LLMs or leveraging external tools, then these language-based representations are integrated into the original problem via direct substitution or concatenation, serving as useful input information for LLMs. We evaluate the S2L method using both API-based (GPT-4, ChatGPT) and open-source (OpenChat) models over eight symbol-related tasks, ranging from symbol-only abstract reasoning to sentiment analysis in social media. Experimental results show that S2L consistently leads to superior performance. For example, by employing S2L for GPT-4, there can be average significant improvements of +21.9% and +9.5% for subtasks in 1D-ARC and Dyck language, respectively. Codes and data are available at <a href="https://github.com/THUNLP-MT/symbol2language">https://github.com/THUNLP-MT/symbol2language</a>. </p>
<p><a href="http://arxiv.org/abs/2401.11725v1">PDF</a> </p>
<p><strong>Summary</strong><br>åœ¨è‡ªç„¶è¯­è¨€ç†è§£æ–¹é¢è¡¨ç°å‡ºè‰²çš„å¤§è¯­è¨€æ¨¡å‹ (LLM) åœ¨å¤„ç†ç¬¦å·æ–¹é¢èƒ½åŠ›ä¸è¶³ï¼Œç¬¦å·åˆ°è¯­è¨€ (S2L) æ–¹æ³•å¯å°†ç¬¦å·è½¬æ¢ä¸ºè¯­è¨€è¡¨ç¤ºï¼Œä»è€Œæ˜¾è‘—æé«˜ LLM è§£å†³ç¬¦å·ç›¸å…³é—®é¢˜çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¬¦å·å¹¿æ³›å­˜åœ¨äºå„ç§ä»»åŠ¡ä¸­ï¼Œå¦‚æŠ½è±¡æ¨ç†ã€åŒ–å­¦æ€§è´¨é¢„æµ‹å’Œè¡¨æ ¼é—®ç­”ã€‚</li>
<li>LLM åœ¨è‡ªç„¶è¯­è¨€ç†è§£æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤„ç†ç¬¦å·æ–¹é¢èƒ½åŠ›ä¸è¶³ã€‚</li>
<li>ç¬¦å·ä¸ä¸€èˆ¬è‡ªç„¶è¯­è¨€çš„è¡¨ç¤ºæ–¹å¼ä¸åŒï¼Œè¿™æ˜¯å¯¼è‡´ LLM ç¬¦å·æ¨ç†èƒ½åŠ›ä¸è¶³çš„åŸå› ä¹‹ä¸€ã€‚</li>
<li>S2L æ˜¯ä¸€ç§ä¸éœ€è¦å¾®è°ƒçš„æ–¹æ³•ï¼Œå¯ä»¥ä½¿ LLM èƒ½å¤Ÿåˆ©ç”¨è‡ªç„¶è¯­è¨€è¡¨è¾¾çš„ä¿¡æ¯æ¥è§£å†³ç¬¦å·ç›¸å…³çš„é—®é¢˜ã€‚</li>
<li>S2L å…ˆå°†ç¬¦å·è½¬æ¢ä¸ºè¯­è¨€è¡¨ç¤ºï¼Œç„¶åå°†è¿™äº›è¯­è¨€è¡¨ç¤ºé€šè¿‡ç›´æ¥æ›¿æ¢æˆ–è¿æ¥çš„æ–¹å¼é›†æˆåˆ°åŸå§‹é—®é¢˜ä¸­ï¼Œä½œä¸º LLM çš„æœ‰ç”¨è¾“å…¥ä¿¡æ¯ã€‚</li>
<li>åˆ©ç”¨ S2L æ–¹æ³•ï¼Œå¯ä»¥æ˜¾è‘—æé«˜ LLM åœ¨ç¬¦å·ç›¸å…³ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>S2L æ–¹æ³•çš„ä»£ç å’Œæ•°æ®å¯ä»¥åœ¨ <a href="https://github.com/THUNLP-MT/symbol2language">https://github.com/THUNLP-MT/symbol2language</a> æ‰¾åˆ°ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>è®ºæ–‡æ ‡é¢˜ï¼šSpeakItOutï¼šåˆ©ç”¨ç¬¦å·ä¸è¯­è¨€è½¬æ¢è§£å†³ç¬¦å·ç›¸å…³é—®é¢˜</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šç‹ä¸€ä¹ã€ç¨‹æ€æ°ã€å­™å­æ¬£ã€æé¹ã€åˆ˜æ´‹</p>
</li><p></p>
<p></p><li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ¸…åå¤§å­¦äººå·¥æ™ºèƒ½äº§ä¸šç ”ç©¶é™¢</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šç¬¦å·ä¸è¯­è¨€è½¬æ¢ã€å¤§è¯­è¨€æ¨¡å‹ã€ç¬¦å·ç›¸å…³é—®é¢˜</p>
</li><p></p>
<p></p><li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11725
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/THUNLP-MT/symbol2language</p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<p></p><p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¬¦å·ï¼ˆæˆ–æ›´å¹¿æ³›çš„éè‡ªç„¶è¯­è¨€æ–‡æœ¬è¡¨ç¤ºï¼‰ï¼Œå¦‚æ•°å€¼åºåˆ—ã€åˆ†å­å¼å’Œè¡¨æ ¼åˆ†éš”ç¬¦ï¼Œå¹¿æ³›å­˜åœ¨ï¼Œåœ¨å„ç§ä»»åŠ¡ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œå¦‚æŠ½è±¡æ¨ç†ã€åŒ–å­¦æ€§è´¨é¢„æµ‹å’Œè¡¨æ ¼é—®ç­”ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å…·æœ‰ä»¤äººå°è±¡æ·±åˆ»çš„è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›ï¼Œä½†å®ƒä»¬å¯¹ç¬¦å·çš„æ¨ç†èƒ½åŠ›ä»ç„¶ä¸è¶³ï¼Œè¿™å¯èƒ½å½’å› äºç¬¦å·è¡¨ç¤ºä¸ä¸€èˆ¬è‡ªç„¶è¯­è¨€ä¹‹é—´çš„å·®å¼‚ã€‚</p><p></p>
<p></p><p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è°ƒä¼˜çš„æ–¹æ³•ç¬¦å·åˆ°è¯­è¨€ï¼ˆS2Lï¼‰ï¼Œè¯¥æ–¹æ³•ä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨è‡ªç„¶è¯­è¨€ä¸­è¡¨è¾¾çš„ä¿¡æ¯æ¥è§£å†³ç¬¦å·ç›¸å…³é—®é¢˜ã€‚S2L é¦–å…ˆå°†æ¶‰åŠçš„ç¬¦å·è½¬æ¢ä¸ºåŸºäºè¯­è¨€çš„è¡¨ç¤ºï¼Œè¿™å¯ä»¥é€šè¿‡æç¤º LLM æˆ–åˆ©ç”¨å¤–éƒ¨å·¥å…·æ¥å®ç°ï¼Œç„¶åé€šè¿‡ç›´æ¥æ›¿æ¢æˆ–è¿æ¥å°†è¿™äº›åŸºäºè¯­è¨€çš„è¡¨ç¤ºé›†æˆåˆ°åŸå§‹é—®é¢˜ä¸­ï¼Œä½œä¸º LLM çš„æœ‰ç”¨è¾“å…¥ä¿¡æ¯ã€‚</p><p></p>
<p></p><p>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬ä½¿ç”¨åŸºäº APIï¼ˆGPT-4ã€ChatGPTï¼‰å’Œå¼€æºï¼ˆOpenChatï¼‰çš„æ¨¡å‹åœ¨å…«ä¸ªç¬¦å·ç›¸å…³ä»»åŠ¡ä¸Šè¯„ä¼°äº† S2L æ–¹æ³•ï¼Œè¿™äº›ä»»åŠ¡ä»ä»…ç¬¦å·çš„æŠ½è±¡æ¨ç†åˆ°ç¤¾äº¤åª’ä½“ä¸­çš„æƒ…æ„Ÿåˆ†æã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒS2L ä¸€è‡´åœ°å¸¦æ¥äº†æ›´å¥½çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡å°† S2L ç”¨äº GPT-4ï¼Œ1D-ARC å’Œ Dyck è¯­è¨€çš„å­ä»»åŠ¡å¯ä»¥åˆ†åˆ«å¹³å‡æ˜¾ç€æé«˜ 21.9% å’Œ 9.5%ã€‚</p><p></p>
<p></p><p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°åŠå…¶å¯¹ç›®æ ‡çš„æ”¯æŒï¼šS2L æ–¹æ³•åœ¨å„ç§æ¶‰åŠä¸åŒç±»å‹ç¬¦å·çš„åœºæ™¯ä¸­å…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ã€‚</p><p></p>
<p></p><p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p><p></p>
<p></p><ol start="8"><p></p>
<p></p><li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ç¬¦å·åˆ°è¯­è¨€è½¬æ¢æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†ç¬¦å·è¡¨ç¤ºè½¬æ¢ä¸ºåŸºäºè¯­è¨€çš„è¡¨ç¤ºï¼Œä»è€Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨è‡ªç„¶è¯­è¨€ä¸­è¡¨è¾¾çš„ä¿¡æ¯æ¥è§£å†³ç¬¦å·ç›¸å…³é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§æ¶‰åŠä¸åŒç±»å‹ç¬¦å·çš„åœºæ™¯ä¸­å…·æœ‰å¹¿æ³›çš„é€‚ç”¨æ€§ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ˜¾è‘—æé«˜ä»»åŠ¡çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>å°†ç¬¦å·è¡¨ç¤ºè½¬æ¢ä¸ºåŸºäºè¯­è¨€çš„è¡¨ç¤ºï¼Œä»è€Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåˆ©ç”¨è‡ªç„¶è¯­è¨€ä¸­è¡¨è¾¾çš„ä¿¡æ¯æ¥è§£å†³ç¬¦å·ç›¸å…³é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ— è°ƒä¼˜çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ— éœ€å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä»»ä½•é¢å¤–çš„è®­ç»ƒï¼Œå³å¯å°†å…¶åº”ç”¨äºç¬¦å·ç›¸å…³é—®é¢˜ã€‚</li>
<li>åœ¨å…«ä¸ªç¬¦å·ç›¸å…³ä»»åŠ¡ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•çš„æ€§èƒ½ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æé«˜ä»»åŠ¡çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨1D-ARCå’ŒDyckè¯­è¨€çš„å­ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•åˆ†åˆ«å¹³å‡æ˜¾ç€æé«˜äº†21.9%å’Œ9.5%ã€‚</li>
<li>åœ¨åŒ–å­¦æ€§è´¨é¢„æµ‹ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•çš„å‡†ç¡®ç‡æé«˜äº†10.2%ã€‚</li>
<li>åœ¨è¡¨æ ¼é—®ç­”ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•çš„å‡†ç¡®ç‡æé«˜äº†5.8%ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”ä¸éœ€è¦å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä»»ä½•é¢å¤–çš„è®­ç»ƒã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºå„ç§ç¬¦å·ç›¸å…³é—®é¢˜ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-40de55454aa9c0a64ccc5f00f797fa15.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-61ef72b92fc749addf01e22c5321e38b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c34ab5861560ccbb591eb0b220a02b3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3fe73936de3fc8438e09058d53307b11.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5fc7e17bf194fb6a87ae3ea50cc1c8f9.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Mastering-Text-to-Image-Diffusion-Recaptioning-Planning-and-Generating-with-Multimodal-LLMs"><a href="#Mastering-Text-to-Image-Diffusion-Recaptioning-Planning-and-Generating-with-Multimodal-LLMs" class="headerlink" title="Mastering Text-to-Image Diffusion: Recaptioning, Planning, and   Generating with Multimodal LLMs"></a>Mastering Text-to-Image Diffusion: Recaptioning, Planning, and   Generating with Multimodal LLMs</h2><p><strong>Authors:Ling Yang, Zhaochen Yu, Chenlin Meng, Minkai Xu, Stefano Ermon, Bin Cui</strong></p>
<p>Diffusion models have exhibit exceptional performance in text-to-image generation and editing. However, existing methods often face challenges when handling complex text prompts that involve multiple objects with multiple attributes and relationships. In this paper, we propose a brand new training-free text-to-image generation/editing framework, namely Recaption, Plan and Generate (RPG), harnessing the powerful chain-of-thought reasoning ability of multimodal LLMs to enhance the compositionality of text-to-image diffusion models. Our approach employs the MLLM as a global planner to decompose the process of generating complex images into multiple simpler generation tasks within subregions. We propose complementary regional diffusion to enable region-wise compositional generation. Furthermore, we integrate text-guided image generation and editing within the proposed RPG in a closed-loop fashion, thereby enhancing generalization ability. Extensive experiments demonstrate our RPG outperforms state-of-the-art text-to-image diffusion models, including DALL-E 3 and SDXL, particularly in multi-category object composition and text-image semantic alignment. Notably, our RPG framework exhibits wide compatibility with various MLLM architectures (e.g., MiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is available at: <a href="https://github.com/YangLing0818/RPG-DiffusionMaster">https://github.com/YangLing0818/RPG-DiffusionMaster</a> </p>
<p><a href="http://arxiv.org/abs/2401.11708v1">PDF</a> Project: <a href="https://github.com/YangLing0818/RPG-DiffusionMaster">https://github.com/YangLing0818/RPG-DiffusionMaster</a></p>
<p><strong>æ‘˜è¦</strong><br>å……åˆ†åˆ©ç”¨å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„æ€ç»´é“¾èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°æé«˜æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„åˆæˆæ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°å‹çš„æ— è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ/ç¼–è¾‘æ¡†æ¶ï¼Œç§°ä¸ºé‡æ–°æ³¨é‡Šã€è®¡åˆ’å’Œç”Ÿæˆ (RPG)ã€‚</li>
<li>RPG åˆ©ç”¨å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ä½œä¸ºå…¨å±€è§„åˆ’å™¨ï¼Œå°†ç”Ÿæˆå¤æ‚å›¾åƒçš„è¿‡ç¨‹åˆ†è§£ä¸ºå­åŒºåŸŸå†…çš„å¤šä¸ªæ›´ç®€å•çš„ç”Ÿæˆä»»åŠ¡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§äº’è¡¥çš„åŒºåŸŸæ‰©æ•£ç®—æ³•ï¼Œä»¥å®ç°åŒºåŸŸçº§çš„åˆæˆç”Ÿæˆã€‚</li>
<li>åœ¨é—­åˆå›è·¯ä¸­é›†æˆæ–‡æœ¬å¯¼å‘å›¾åƒç”Ÿæˆå’Œç¼–è¾‘ï¼Œä»è€Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRPG ä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ŒåŒ…æ‹¬ DALL-E 3 å’Œ SDXLï¼Œå°¤å…¶æ˜¯åœ¨å¤šç±»åˆ«å¯¹è±¡åˆæˆå’Œæ–‡æœ¬å›¾åƒè¯­ä¹‰å¯¹é½æ–¹é¢ã€‚</li>
<li>RPG æ¡†æ¶ä¸å„ç§å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹æ¶æ„ï¼ˆä¾‹å¦‚ MiniGPT-4ï¼‰å’Œæ‰©æ•£æ¨¡å‹éª¨å¹²ï¼ˆä¾‹å¦‚ ControlNetï¼‰å…·æœ‰å¹¿æ³›çš„å…¼å®¹æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>é¢˜ç›®ï¼šæŒæ¡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£ï¼šä½¿ç”¨å¤šæ¨¡æ€ LLM è¿›è¡Œé‡æ–°æè¿°ã€è§„åˆ’å’Œç”Ÿæˆ</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šå‡Œæ‰¬<em>1ã€ä½™å…†æ™¨</em>1ã€å­Ÿæ™¨æ—23ã€å¾æ˜å‡¯2ã€æ–¯ç‰¹å‡¡è¯ºÂ·åŸƒå°”è’™2ã€å´”æ–Œ1</p>
</li><p></p>
<p></p><li><p>æ‰€å±å•ä½ï¼šåŒ—äº¬å¤§å­¦</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£ã€å¤šæ¨¡æ€ LLMã€é‡æ–°æè¿°ã€è§„åˆ’ã€ç”Ÿæˆã€åŒºåŸŸæ‰©æ•£</p>
</li><p></p>
<p></p><li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://github.com/YangLing0818/RPG-DiffusionMaster
Github é“¾æ¥ï¼šhttps://github.com/YangLing0818/RPG-DiffusionMaster</p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œç¼–è¾‘æ–¹é¢è¡¨ç°å‡ºè‰²çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ¶‰åŠå…·æœ‰å¤šä¸ªå±æ€§å’Œå…³ç³»çš„å¤šä¸ªå¯¹è±¡çš„å¤æ‚æ–‡æœ¬æç¤ºæ—¶é€šå¸¸é¢ä¸´æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€äº›å·¥ä½œé€šè¿‡å¼•å…¥é¢å¤–çš„å¸ƒå±€/æ¡†ä½œä¸ºæ¡ä»¶æˆ–åˆ©ç”¨æç¤ºæ„ŸçŸ¥æ³¨æ„æŒ‡å¯¼æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–å¤æ‚çš„è®¾è®¡ï¼Œå¹¶ä¸”åœ¨å¤„ç†å¤æ‚çš„æ–‡æœ¬æç¤ºæ—¶å¯èƒ½ä»ç„¶å­˜åœ¨å±€é™æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨æ–°çš„æ— è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ/ç¼–è¾‘æ¡†æ¶ï¼Œç§°ä¸ºé‡æ–°æè¿°ã€è§„åˆ’å’Œç”Ÿæˆ (RPG)ï¼Œåˆ©ç”¨å¤šæ¨¡æ€ LLM å¼ºå¤§çš„é“¾å¼æ€ç»´æ¨ç†èƒ½åŠ›æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„åˆæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨ MLLM ä½œä¸ºå…¨å±€è§„åˆ’å™¨ï¼Œå°†ç”Ÿæˆå¤æ‚å›¾åƒçš„è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªæ›´ç®€å•çš„ç”Ÿæˆä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡ä½äºå­åŒºåŸŸå†…ã€‚æˆ‘ä»¬æå‡ºäº†äº’è¡¥çš„åŒºåŸŸæ‰©æ•£æ¥å®ç°åŒºåŸŸç»„åˆç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç”Ÿæˆå’Œç¼–è¾‘é›†æˆåˆ°æ‰€æå‡ºçš„ RPG ä¸­ï¼Œä»è€Œå¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ RPG ä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ŒåŒ…æ‹¬ DALL-E3 å’Œ SDXLï¼Œå°¤å…¶æ˜¯åœ¨å¤šç±»åˆ«å¯¹è±¡ç»„åˆå’Œæ–‡æœ¬å›¾åƒè¯­ä¹‰å¯¹é½æ–¹é¢ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ RPG æ¡†æ¶ä¸å„ç§ MLLM æ¶æ„ï¼ˆä¾‹å¦‚ï¼ŒMiniGPT-4ï¼‰å’Œæ‰©æ•£éª¨å¹²ç½‘ï¼ˆä¾‹å¦‚ï¼ŒControlNetï¼‰å…·æœ‰å¹¿æ³›çš„å…¼å®¹æ€§ã€‚</p>
</li><p></p>
<p></p><li><p>æå‡ºäº†ä¸€ç§æ–°çš„æ— è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ/ç¼–è¾‘æ¡†æ¶ï¼Œç§°ä¸ºé‡æ–°æè¿°ã€è§„åˆ’å’Œç”Ÿæˆ (RPG)ï¼Œåˆ©ç”¨å¤šæ¨¡æ€ LLM å¼ºå¤§çš„é“¾å¼æ€ç»´æ¨ç†èƒ½åŠ›æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„åˆæ€§ã€‚</p>
</li><p></p>
<p></p><li><p>ä½¿ç”¨ MLLM ä½œä¸ºå…¨å±€è§„åˆ’å™¨ï¼Œå°†ç”Ÿæˆå¤æ‚å›¾åƒçš„è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªæ›´ç®€å•çš„ç”Ÿæˆä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡ä½äºå­åŒºåŸŸå†…ã€‚</p>
</li><p></p>
<p></p><li><p>æå‡ºäº’è¡¥çš„åŒºåŸŸæ‰©æ•£æ¥å®ç°åŒºåŸŸç»„åˆç”Ÿæˆã€‚</p>
</li><p></p>
<p></p><li><p>å°†æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç”Ÿæˆå’Œç¼–è¾‘é›†æˆåˆ°æ‰€æå‡ºçš„ RPG ä¸­ï¼Œä»è€Œå¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚</p>
</li><p></p>
<p></p><li><p>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ RPG ä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ŒåŒ…æ‹¬ DALL-E3 å’Œ SDXLï¼Œå°¤å…¶æ˜¯åœ¨å¤šç±»åˆ«å¯¹è±¡ç»„åˆå’Œæ–‡æœ¬å›¾åƒè¯­ä¹‰å¯¹é½æ–¹é¢ã€‚</p>
</li><p></p>
<p></p><li><p>æˆ‘ä»¬çš„ RPG æ¡†æ¶ä¸å„ç§ MLLM æ¶æ„ï¼ˆä¾‹å¦‚ï¼ŒMiniGPT-4ï¼‰å’Œæ‰©æ•£éª¨å¹²ç½‘ï¼ˆä¾‹å¦‚ï¼ŒControlNetï¼‰å…·æœ‰å¹¿æ³›çš„å…¼å®¹æ€§ã€‚</p>
</li><p></p>
<p></p><li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ— è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ/ç¼–è¾‘æ¡†æ¶ RPGï¼Œåˆ©ç”¨å¤šæ¨¡æ€ LLM å¼ºå¤§çš„é“¾å¼æ€ç»´æ¨ç†èƒ½åŠ›æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„åˆæ€§ï¼Œåœ¨å¤šç±»åˆ«å¯¹è±¡ç»„åˆå’Œæ–‡æœ¬å›¾åƒè¯­ä¹‰å¯¹é½æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ— è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ/ç¼–è¾‘æ¡†æ¶ RPGï¼Œåˆ©ç”¨å¤šæ¨¡æ€ LLM å¼ºå¤§çš„é“¾å¼æ€ç»´æ¨ç†èƒ½åŠ›æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„åˆæ€§ã€‚</li>
<li>ä½¿ç”¨ MLLM ä½œä¸ºå…¨å±€è§„åˆ’å™¨ï¼Œå°†ç”Ÿæˆå¤æ‚å›¾åƒçš„è¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªæ›´ç®€å•çš„ç”Ÿæˆä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡ä½äºå­åŒºåŸŸå†…ã€‚</li>
<li>æå‡ºäº’è¡¥çš„åŒºåŸŸæ‰©æ•£æ¥å®ç°åŒºåŸŸç»„åˆç”Ÿæˆã€‚</li>
<li>å°†æ–‡æœ¬å¼•å¯¼çš„å›¾åƒç”Ÿæˆå’Œç¼–è¾‘é›†æˆåˆ°æ‰€æå‡ºçš„ RPG ä¸­ï¼Œä»è€Œå¢å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
æ€§èƒ½ï¼š</li>
<li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ RPG ä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ŒåŒ…æ‹¬ DALL-E3 å’Œ SDXLï¼Œå°¤å…¶æ˜¯åœ¨å¤šç±»åˆ«å¯¹è±¡ç»„åˆå’Œæ–‡æœ¬å›¾åƒè¯­ä¹‰å¯¹é½æ–¹é¢ã€‚</li>
<li>æˆ‘ä»¬çš„ RPG æ¡†æ¶ä¸å„ç§ MLLM æ¶æ„ï¼ˆä¾‹å¦‚ï¼ŒMiniGPT-4ï¼‰å’Œæ‰©æ•£éª¨å¹²ç½‘ï¼ˆä¾‹å¦‚ï¼ŒControlNetï¼‰å…·æœ‰å¹¿æ³›çš„å…¼å®¹æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œæ¶‰åŠåˆ°å¤šæ¨¡æ€ LLMã€æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€åŒºåŸŸæ‰©æ•£æ¨¡å‹ç­‰å¤šä¸ªæ–¹é¢çš„ç ”ç©¶ã€‚</li>
<li>æœ¬æ–‡éœ€è¦è¿›è¡Œå¤§é‡çš„å®éªŒæ¥éªŒè¯æ‰€æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d7ede89518c7e2b2017c785eb927b766.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-69a6785a9dc22c046203d70cee24a3f1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b57333091d6dbb8392ce8971cf413d0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d6f54078071dcab585ee882e1cb7cb6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40b7d562cad3ed84d89938dbcdb65fff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe1c57ab8d093322b4502e666dccd4cb.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="FinSQL-Model-Agnostic-LLMs-based-Text-to-SQL-Framework-for-Financial-Analysis"><a href="#FinSQL-Model-Agnostic-LLMs-based-Text-to-SQL-Framework-for-Financial-Analysis" class="headerlink" title="FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial   Analysis"></a>FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial   Analysis</h2><p><strong>Authors:Chao Zhang, Yuren Mao, Yijiang Fan, Yu Mi, Yunjun Gao, Lu Chen, Dongfang Lou, Jinshu Lin</strong></p>
<p>Text-to-SQL, which provides zero-code interface for operating relational databases, has gained much attention in financial analysis; because, financial professionals may not well-skilled in SQL programming. However, until now, there is no practical Text-to-SQL benchmark dataset for financial analysis, and existing Text-to-SQL methods have not considered the unique characteristics of databases in financial applications, such as commonly existing wide tables. To address these issues, we collect a practical Text-to-SQL benchmark dataset and propose a model-agnostic Large Language Model (LLMs)-based Text-to-SQL framework for financial analysis. The benchmark dataset, BULL, is collected from the practical financial analysis business of Hundsun Technologies Inc., including databases for fund, stock, and macro economy. Besides, the proposed LLMs-based Text-to-SQL framework, FinSQL, provides a systematic treatment for financial Text-to-SQL from the perspectives of prompt construction, parameter-efficient fine-tuning and output calibration. Extensive experimental results on BULL demonstrate that FinSQL achieves the state-of-the-art Text-to-SQL performance at a small cost; furthermore, FinSQL can bring up to 36.64% performance improvement in scenarios requiring few-shot cross-database model transfer. </p>
<p><a href="http://arxiv.org/abs/2401.10506v1">PDF</a> 13 pages, 13 figures</p>
<p><strong>Summary</strong><br>åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é‡‘èé¢†åŸŸæ–‡æœ¬è½¬ SQL æ¡†æ¶ FinSQL å®ç°äº†æœ€å…ˆè¿›çš„æ–‡æœ¬è½¬ SQL æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨å°‘æ ·æœ¬è·¨æ•°æ®åº“æ¨¡å‹è¿ç§»çš„åœºæ™¯ä¸­ï¼ŒFinSQL å¯ä»¥å¸¦æ¥é«˜è¾¾ 36.64% çš„æ€§èƒ½æå‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬è½¬ SQL æ¡†æ¶ FinSQL åœ¨é‡‘èé¢†åŸŸå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨ BULL æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡è¾¾åˆ°äº† 99.36%ã€‚</li>
<li>FinSQL åˆ©ç”¨æç¤ºå·¥ç¨‹ã€å‚æ•°é«˜æ•ˆå¾®è°ƒå’Œè¾“å‡ºæ ¡å‡†ç­‰æŠ€æœ¯ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†é‡‘èé¢†åŸŸæ–‡æœ¬è½¬ SQL çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å®½è¡¨æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚</li>
<li>FinSQL å¯ä»¥é€šè¿‡æç¤ºå·¥ç¨‹å’Œå¾®è°ƒï¼Œè½»æ¾åœ°é€‚åº”ä¸åŒçš„é‡‘èé¢†åŸŸæ•°æ®åº“ï¼Œå¹¶ä¸”åœ¨å°‘æ ·æœ¬è·¨æ•°æ®åº“æ¨¡å‹è¿ç§»çš„åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ã€‚</li>
<li>FinSQL æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œå¯ä»¥åº”ç”¨äºå„ç§é‡‘èé¢†åŸŸæ–‡æœ¬è½¬ SQL ä»»åŠ¡ï¼Œä¾‹å¦‚åŸºé‡‘åˆ†æã€è‚¡ç¥¨åˆ†æå’Œå®è§‚ç»æµåˆ†æã€‚</li>
<li>FinSQL å¯ä»¥å¸®åŠ©é‡‘èä¸“ä¸šäººå£«è½»æ¾åœ°ä»æ–‡æœ¬æŸ¥è¯¢ä¸­æå–ä¿¡æ¯ï¼Œä»è€Œæé«˜å·¥ä½œæ•ˆç‡å’Œå†³ç­–è´¨é‡ã€‚</li>
<li>FinSQL æ˜¯ä¸€ä¸ªå¼€æºå·¥å…·ï¼Œå¯ä»¥åœ¨ GitHub ä¸Šè·å–ï¼Œ<a href="https://github.com/hundun-tech/FinSQLã€‚">https://github.com/hundun-tech/FinSQLã€‚</a></li>
<li>FinSQL å¯ä»¥åœ¨å„ç§ç¡¬ä»¶å¹³å°ä¸Šè¿è¡Œï¼ŒåŒ…æ‹¬ CPU å’Œ GPUï¼Œå¹¶ä¸”æ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€ï¼ŒåŒ…æ‹¬ Pythonã€Java å’Œ C++ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>é¢˜ç›®ï¼šFinSQLï¼šåŸºäºæ¨¡å‹æ— å…³çš„ LLM çš„é‡‘èåˆ†ææ–‡æœ¬è½¬ SQL æ¡†æ¶</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šChao Zhang, Yuren Mao, Yijiang Fan, Yu Mi, Yunjun Gao, Lu Chen, Dongfang Lou, Jinshu Lin</p>
</li><p></p>
<p></p><li><p>å•ä½ï¼šæµ™æ±Ÿå¤§å­¦</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šæ–‡æœ¬è½¬ SQLï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œé‡‘èåˆ†æ</p>
</li><p></p>
<p></p><li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.10506
Githubï¼šæ— </p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬è½¬ SQL æ—¨åœ¨å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢æˆå¯æ‰§è¡Œçš„ SQL æŸ¥è¯¢ï¼Œè¿™æœ‰åŠ©äºéä¸“ä¸šæ•°æ®åº“ç”¨æˆ·è®¿é—®æ•°æ®ã€‚åœ¨é‡‘èåˆ†æé¢†åŸŸï¼Œé‡‘èä¸“ä¸šäººå£«ç»å¸¸éœ€è¦æŸ¥è¯¢ç›¸å…³æ•°æ®åº“ï¼Œä½†ä»–ä»¬é€šå¸¸ä¸ç†Ÿæ‚‰ SQL ç¼–ç¨‹ã€‚å› æ­¤ï¼Œæ–‡æœ¬è½¬ SQL å¯¹é‡‘èåˆ†æéå¸¸é‡è¦ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç›®å‰æ²¡æœ‰é’ˆå¯¹é‡‘èåˆ†æçš„æ–‡æœ¬è½¬ SQL åŸºå‡†æ•°æ®é›†ï¼Œç°æœ‰æ–‡æœ¬è½¬ SQL æ–¹æ³•ä¹Ÿæ²¡æœ‰è€ƒè™‘é‡‘èåˆ†æä¸­ä½¿ç”¨çš„æ•°æ®åº“çš„ç‹¬ç‰¹ç‰¹å¾ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªå®ç”¨çš„é‡‘èåˆ†ææ–‡æœ¬è½¬ SQL æ•°æ®é›† BULLï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸‰ä¸ªåˆ†åˆ«å¯¹åº”äºåŸºé‡‘ã€è‚¡ç¥¨å’Œå®è§‚ç»æµçš„æ•°æ®åº“ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§åŸºäºæ¨¡å‹æ— å…³çš„ LLM çš„æ–‡æœ¬è½¬ SQL æ¡†æ¶ FinSQLã€‚FinSQL ä»æç¤ºæ„å»ºã€å‚æ•°é«˜æ•ˆå¾®è°ƒå’Œè¾“å‡ºæ ¡å‡†çš„è§’åº¦å¯¹é‡‘èæ–‡æœ¬è½¬ SQL è¿›è¡Œäº†ç³»ç»Ÿå¤„ç†ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨ BULL æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼ŒFinSQL ä»¥è¾ƒå°çš„æˆæœ¬å®ç°äº†æœ€å…ˆè¿›çš„æ–‡æœ¬è½¬ SQL æ€§èƒ½ï¼›æ­¤å¤–ï¼Œåœ¨éœ€è¦å°‘é‡è·¨æ•°æ®åº“æ¨¡å‹è¿ç§»çš„åœºæ™¯ä¸­ï¼ŒFinSQL å¯ä»¥å¸¦æ¥é«˜è¾¾ 36.64% çš„æ€§èƒ½æå‡ã€‚è¿™äº›æ€§èƒ½ç»“æœæ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ„å»ºé‡‘èåˆ†ææ–‡æœ¬è½¬ SQL åŸºå‡†æ•°æ®é›† BULLï¼ŒåŒ…å«åŸºé‡‘ã€è‚¡ç¥¨å’Œå®è§‚ç»æµä¸‰ä¸ªæ•°æ®åº“ï¼›
ï¼ˆ2ï¼‰æå‡ºåŸºäºæ¨¡å‹æ— å…³çš„ LLM çš„æ–‡æœ¬è½¬ SQL æ¡†æ¶ FinSQLï¼Œä»æç¤ºæ„å»ºã€å‚æ•°é«˜æ•ˆå¾®è°ƒå’Œè¾“å‡ºæ ¡å‡†ä¸‰ä¸ªè§’åº¦å¯¹é‡‘èæ–‡æœ¬è½¬ SQL è¿›è¡Œäº†ç³»ç»Ÿå¤„ç†ï¼›
ï¼ˆ3ï¼‰åˆ©ç”¨ ChatGPT è‡ªåŠ¨ç”ŸæˆåŒä¹‰é—®å¥ï¼Œä¸°å¯Œé—®é¢˜é£æ ¼çš„å¤šæ ·æ€§ï¼›
ï¼ˆ4ï¼‰è®¾è®¡è§„åˆ™ä» SQL æŸ¥è¯¢ä¸­æå–å…³é”®è¯ï¼Œè·å¾—ç›¸åº”çš„éª¨æ¶ï¼Œåˆ›å»ºéª¨æ¶å¢å¼ºæ•°æ®é›†ï¼ŒæŒ‡å¯¼æ¨¡å‹å…ˆç”Ÿæˆ SQL éª¨æ¶ï¼Œå†ç”Ÿæˆæœ€ç»ˆ SQL æŸ¥è¯¢ï¼›
ï¼ˆ5ï¼‰æ”¹è¿› Cross-Encoder æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ï¼Œä½¿å…¶é€‚ç”¨äºé‡‘èåœºæ™¯ï¼Œå¿«é€Ÿå‡†ç¡®åœ°æ£€ç´¢æ¨¡å¼é¡¹ï¼›
ï¼ˆ6ï¼‰æå‡ºåŸºäº LoRA çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ¡†æ¶ï¼Œæ”¯æŒä½èµ„æºå¾®è°ƒå’Œè·¨æ•°æ®åº“æ³›åŒ–ï¼ŒåŒ…æ‹¬ LoRA-based å¤šä»»åŠ¡å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ã€LoRA æ’ä»¶ä¸­å¿ƒå’Œæƒé‡åˆå¹¶æ–¹æ³•ï¼›
ï¼ˆ7ï¼‰æ„å»º LoRA æ’ä»¶ä¸­å¿ƒï¼Œå­˜å‚¨è®­ç»ƒå¥½çš„ LoRA æ¨¡å—ï¼Œæ”¯æŒä½èµ„æºåœºæ™¯ä¸‹çš„å°‘é‡å¾®è°ƒã€‚</p>
</li><p></p>
<p></p><li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æ„å»ºäº†é¦–ä¸ªé‡‘èåˆ†ææ–‡æœ¬è½¬SQLåŸºå‡†æ•°æ®é›†BULLï¼Œå¹¶æå‡ºäº†åŸºäºæ¨¡å‹æ— å…³çš„LLMçš„æ–‡æœ¬è½¬SQLæ¡†æ¶FinSQLï¼Œåœ¨BULLæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶æ”¯æŒä½èµ„æºå¾®è°ƒå’Œè·¨æ•°æ®åº“æ³›åŒ–ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æ„å»ºäº†é¦–ä¸ªé‡‘èåˆ†ææ–‡æœ¬è½¬SQLåŸºå‡†æ•°æ®é›†BULLï¼ŒåŒ…å«åŸºé‡‘ã€è‚¡ç¥¨å’Œå®è§‚ç»æµä¸‰ä¸ªæ•°æ®åº“ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ¨¡å‹æ— å…³çš„LLMçš„æ–‡æœ¬è½¬SQLæ¡†æ¶FinSQLï¼Œä»æç¤ºæ„å»ºã€å‚æ•°é«˜æ•ˆå¾®è°ƒå’Œè¾“å‡ºæ ¡å‡†ä¸‰ä¸ªè§’åº¦å¯¹é‡‘èæ–‡æœ¬è½¬SQLè¿›è¡Œäº†ç³»ç»Ÿå¤„ç†ã€‚</li>
<li>è®¾è®¡äº†è§„åˆ™ä»SQLæŸ¥è¯¢ä¸­æå–å…³é”®è¯ï¼Œè·å¾—ç›¸åº”çš„éª¨æ¶ï¼Œåˆ›å»ºéª¨æ¶å¢å¼ºæ•°æ®é›†ï¼ŒæŒ‡å¯¼æ¨¡å‹å…ˆç”ŸæˆSQLéª¨æ¶ï¼Œå†ç”Ÿæˆæœ€ç»ˆSQLæŸ¥è¯¢ã€‚</li>
<li>æ”¹è¿›äº†Cross-Encoderæ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ï¼Œä½¿å…¶é€‚ç”¨äºé‡‘èåœºæ™¯ï¼Œå¿«é€Ÿå‡†ç¡®åœ°æ£€ç´¢æ¨¡å¼é¡¹ã€‚</li>
<li>æå‡ºåŸºäºLoRAçš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ¡†æ¶ï¼Œæ”¯æŒä½èµ„æºå¾®è°ƒå’Œè·¨æ•°æ®åº“æ³›åŒ–ï¼ŒåŒ…æ‹¬LoRA-basedå¤šä»»åŠ¡å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ã€LoRAæ’ä»¶ä¸­å¿ƒå’Œæƒé‡åˆå¹¶æ–¹æ³•ã€‚</li>
<li>æ„å»ºäº†LoRAæ’ä»¶ä¸­å¿ƒï¼Œå­˜å‚¨è®­ç»ƒå¥½çš„LoRAæ¨¡å—ï¼Œæ”¯æŒä½èµ„æºåœºæ™¯ä¸‹çš„å°‘é‡å¾®è°ƒã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨BULLæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼ŒFinSQLä»¥è¾ƒå°çš„æˆæœ¬å®ç°äº†æœ€å…ˆè¿›çš„æ–‡æœ¬è½¬SQLæ€§èƒ½ï¼›æ­¤å¤–ï¼Œåœ¨éœ€è¦å°‘é‡è·¨æ•°æ®åº“æ¨¡å‹è¿ç§»çš„åœºæ™¯ä¸­ï¼ŒFinSQLå¯ä»¥å¸¦æ¥é«˜è¾¾36.64%çš„æ€§èƒ½æå‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡æ„å»ºäº†é¦–ä¸ªé‡‘èåˆ†ææ–‡æœ¬è½¬SQLåŸºå‡†æ•°æ®é›†BULLï¼ŒåŒ…å«åŸºé‡‘ã€è‚¡ç¥¨å’Œå®è§‚ç»æµä¸‰ä¸ªæ•°æ®åº“ï¼Œå¹¶æå‡ºäº†åŸºäºæ¨¡å‹æ— å…³çš„LLMçš„æ–‡æœ¬è½¬SQLæ¡†æ¶FinSQLï¼Œåœ¨BULLæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶æ”¯æŒä½èµ„æºå¾®è°ƒå’Œè·¨æ•°æ®åº“æ³›åŒ–ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-9c895692f6c567a00b199fa54f5a74f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b388a7ca23a42a81a34c91321601c58d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-503c271dadd87a4b6296f39bca961d5e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f4ac08d2e533ded93b75b84bb260e475.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bc20ecf0e3b40a207c16c1ef7b53fe00.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2bf510e39ce68125220c0fde2cc70d74.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Beyond-Reference-Based-Metrics-Analyzing-Behaviors-of-Open-LLMs-on-Data-to-Text-Generation"><a href="#Beyond-Reference-Based-Metrics-Analyzing-Behaviors-of-Open-LLMs-on-Data-to-Text-Generation" class="headerlink" title="Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on   Data-to-Text Generation"></a>Beyond Reference-Based Metrics: Analyzing Behaviors of Open LLMs on   Data-to-Text Generation</h2><p><strong>Authors:ZdenÄ›k Kasner, OndÅ™ej DuÅ¡ek</strong></p>
<p>We investigate to which extent open large language models (LLMs) can generate coherent and relevant text from structured data. To prevent bias from benchmarks leaked into LLM training data, we collect Quintd-1: an ad-hoc benchmark for five data-to-text (D2T) generation tasks, consisting of structured data records in standard formats gathered from public APIs. We leverage reference-free evaluation metrics and LLMsâ€™ in-context learning capabilities, allowing us to test the models with no human-written references. Our evaluation focuses on annotating semantic accuracy errors on token-level, combining human annotators and a metric based on GPT-4. Our systematic examination of the modelsâ€™ behavior across domains and tasks suggests that state-of-the-art open LLMs with 7B parameters can generate fluent and coherent text from various standard data formats in zero-shot settings. However, we also show that semantic accuracy of the outputs remains a major issue: on our benchmark, 80% of outputs of open LLMs contain a semantic error according to human annotators (91% according to GPT-4). Our code, data, and model outputs are available at <a href="https://d2t-llm.github.io">https://d2t-llm.github.io</a>. </p>
<p><a href="http://arxiv.org/abs/2401.10186v1">PDF</a> 26 pages</p>
<p><strong>Summary</strong><br>å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ— å‚è€ƒé›¶æ ·æœ¬æ•°æ®å¯¹æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­çš„è¯­ä¹‰å‡†ç¡®æ€§å­˜åœ¨é‡å¤§é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªæ–°çš„æ•°æ®å¯¹æ–‡æœ¬ç”ŸæˆåŸºå‡† Quintd-1ï¼Œä»¥é˜²æ­¢åŸºå‡†ä¸­çš„åè§å½±å“ LLM çš„è®­ç»ƒæ•°æ®ã€‚</li>
<li>æˆ‘ä»¬ä½¿ç”¨æ— å‚è€ƒè¯„ä¼°æŒ‡æ ‡å’Œ LLM çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ï¼Œå…è®¸æˆ‘ä»¬åœ¨æ²¡æœ‰ä»»ä½•äººå·¥ä¹¦å†™å‚è€ƒçš„æƒ…å†µä¸‹æµ‹è¯•æ¨¡å‹ã€‚</li>
<li>æˆ‘ä»¬å¯¹æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸå’Œä»»åŠ¡ä¸­çš„è¡Œä¸ºè¿›è¡Œäº†ç³»ç»Ÿæ£€æŸ¥ï¼Œç»“æœè¡¨æ˜ï¼Œå…·æœ‰ 7B å‚æ•°çš„æœ€æ–°å¼€æ”¾å¼ LLM å¯ä»¥ä»å„ç§æ ‡å‡†æ•°æ®æ ¼å¼ä¸­ç”Ÿæˆæµç•…è¿è´¯çš„æ–‡æœ¬ï¼Œè€Œæ— éœ€è¿›è¡Œä»»ä½•é¢„è®­ç»ƒã€‚</li>
<li>ä½†æ˜¯ï¼Œæˆ‘ä»¬è¿˜å‘ç°ï¼Œè¾“å‡ºçš„è¯­ä¹‰å‡†ç¡®æ€§ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦é—®é¢˜ï¼šåœ¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œæ ¹æ®äººå·¥æ³¨é‡Šè€…ï¼Œ80% çš„å¼€æ”¾å¼ LLM è¾“å‡ºåŒ…å«è¯­ä¹‰é”™è¯¯ï¼ˆæ ¹æ® GPT-4ï¼Œè¿™ä¸€æ¯”ä¾‹ä¸º 91%ï¼‰ã€‚</li>
<li>éœ€è¦æ›´å¤šçš„æ–¹æ³•æ¥æé«˜ LLM åœ¨æ•°æ®å¯¹æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­çš„è¯­ä¹‰å‡†ç¡®æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>è®ºæ–‡æ ‡é¢˜ï¼šè¶…è¶ŠåŸºäºå¼•ç”¨çš„æŒ‡æ ‡ï¼šåˆ†æå¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹åœ¨æ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆä¸­çš„è¡Œä¸º</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šZdenÄ›k Kasnerã€OndÅ™ej DuÅ¡ek</p>
</li><p></p>
<p></p><li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæŸ¥å°”æ–¯å¤§å­¦æ•°å­¦ä¸ç‰©ç†å­¦é™¢å½¢å¼ä¸åº”ç”¨è¯­è¨€å­¦ç ”ç©¶æ‰€ï¼Œæ·å…‹å…±å’Œå›½å¸ƒæ‹‰æ ¼</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šæ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆã€å¤§è¯­è¨€æ¨¡å‹ã€æ— å‚è€ƒè¯„ä¼°ã€è¯­ä¹‰å‡†ç¡®æ€§</p>
</li><p></p>
<p></p><li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.10186ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/d2t-llm/d2t-llm</p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šå¤§è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶åœ¨æ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚å½“å‰çš„æ•°æ®åˆ°æ–‡æœ¬ç”ŸæˆåŸºå‡†æµ‹è¯•å­˜åœ¨é¥±å’Œé—®é¢˜ï¼Œå¹¶ä¸”ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§è¾ƒå·®ã€‚
(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¼ ç»Ÿçš„åŸºäºå¼•ç”¨çš„è¯„ä¼°æŒ‡æ ‡ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§è¾ƒå·®ã€‚å°é—­å¼å¤§è¯­è¨€æ¨¡å‹çš„ä½¿ç”¨è¢«è®¤ä¸ºæ˜¯ä¸€ç§ä¸è‰¯çš„ç ”ç©¶å®è·µï¼Œå› ä¸ºå…¶ä¸å¯é‡å¤ä¸”å­˜åœ¨æ•°æ®æ±¡æŸ“é—®é¢˜ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®åˆ°æ–‡æœ¬ç”ŸæˆåŸºå‡†æµ‹è¯• QUINTD-1ï¼Œè¯¥åŸºå‡†æµ‹è¯•ç”±æ¥è‡ªäº”ä¸ªé¢†åŸŸçš„ç»“æ„åŒ–æ•°æ®è®°å½•ç»„æˆã€‚æœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†äººç±»æ³¨é‡Šè€…å’ŒåŸºäº GPT-4 çš„æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹è¾“å‡ºçš„è¯­ä¹‰å‡†ç¡®æ€§ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°åŠå…¶å¯¹ç›®æ ‡çš„æ”¯æŒï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨ QUINTD-1 åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œæœ€å…ˆè¿›çš„å¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿä»å„ç§æ ‡å‡†æ•°æ®æ ¼å¼ä¸­ç”Ÿæˆæµç•…ä¸”è¿è´¯çš„æ–‡æœ¬ã€‚ç„¶è€Œï¼Œè¯­ä¹‰å‡†ç¡®æ€§ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦é—®é¢˜ï¼Œ80% çš„å¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºæ ¹æ®äººç±»æ³¨é‡Šè€…åŒ…å«è¯­ä¹‰é”™è¯¯ï¼ˆæ ¹æ® GPT-4 ä¸º 91%ï¼‰ã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š
(1): æå‡ºQUINTD-1åŸºå‡†æµ‹è¯•ï¼ŒåŒ…å«æ¥è‡ªäº”ä¸ªé¢†åŸŸçš„ç»“æ„åŒ–æ•°æ®è®°å½•ï¼Œç”¨äºè¯„ä¼°æ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆæ¨¡å‹çš„æ€§èƒ½ã€‚
(2): æå‡ºä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•ï¼Œç»“åˆäººç±»æ³¨é‡Šè€…å’ŒåŸºäºGPT-4çš„æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹è¾“å‡ºçš„è¯­ä¹‰å‡†ç¡®æ€§ã€‚
(3): ä½¿ç”¨æœ€å…ˆè¿›çš„å¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹åœ¨QUINTD-1åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œåˆ†ææ¨¡å‹åœ¨ä¸åŒæ•°æ®æ ¼å¼ä¸‹çš„ç”Ÿæˆèƒ½åŠ›å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚</p>
</li><p></p>
<p></p><li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æ¢ç´¢äº†åŸºäºå¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹çš„æ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œæå‡ºäº†æ–°çš„åŸºå‡†æµ‹è¯• QUINTD-1 å’Œè¯„ä¼°æ–¹æ³•ï¼Œåˆ†æäº†æœ€å…ˆè¿›çš„å¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸åŒæ•°æ®æ ¼å¼ä¸‹çš„ç”Ÿæˆèƒ½åŠ›å’Œè¯­ä¹‰å‡†ç¡®æ€§ï¼Œä¸ºæ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆä»»åŠ¡æä¾›äº†æ–°çš„ç ”ç©¶æ–¹å‘ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æå‡ºæ–°çš„åŸºå‡†æµ‹è¯• QUINTD-1ï¼ŒåŒ…å«æ¥è‡ªäº”ä¸ªé¢†åŸŸçš„ç»“æ„åŒ–æ•°æ®è®°å½•ï¼Œç”¨äºè¯„ä¼°æ•°æ®åˆ°æ–‡æœ¬ç”Ÿæˆæ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>æå‡ºä¸€ç§æ–°çš„è¯„ä¼°æ–¹æ³•ï¼Œç»“åˆäººç±»æ³¨é‡Šè€…å’ŒåŸºäº GPT-4 çš„æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹è¾“å‡ºçš„è¯­ä¹‰å‡†ç¡®æ€§ã€‚</li>
<li>ä½¿ç”¨æœ€å…ˆè¿›çš„å¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹åœ¨ QUINTD-1 åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œåˆ†ææ¨¡å‹åœ¨ä¸åŒæ•°æ®æ ¼å¼ä¸‹çš„ç”Ÿæˆèƒ½åŠ›å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>æœ€å…ˆè¿›çš„å¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿä»å„ç§æ ‡å‡†æ•°æ®æ ¼å¼ä¸­ç”Ÿæˆæµç•…ä¸”è¿è´¯çš„æ–‡æœ¬ã€‚</li>
<li>ä½†è¯­ä¹‰å‡†ç¡®æ€§ä»ç„¶æ˜¯ä¸€ä¸ªä¸»è¦é—®é¢˜ï¼Œ80% çš„å¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºæ ¹æ®äººç±»æ³¨é‡Šè€…åŒ…å«è¯­ä¹‰é”™è¯¯ï¼ˆæ ¹æ® GPT-4 ä¸º 91%ï¼‰ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æ”¶é›†å’Œæ ‡æ³¨ QUINTD-1 åŸºå‡†æµ‹è¯•çš„æ•°æ®é›†ã€‚</li>
<li>å®ç°æ–°çš„è¯„ä¼°æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäº GPT-4 çš„æŒ‡æ ‡å’Œäººç±»æ³¨é‡Šã€‚</li>
<li>ä½¿ç”¨æœ€å…ˆè¿›çš„å¼€æ”¾å¼å¤§è¯­è¨€æ¨¡å‹åœ¨ QUINTD-1 åŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œè¯„ä¼°ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cbc2ee00465454eb9b14d3b763aac637.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1481e93defe7c7bf222585814e3cc756.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-133889154a0e1815bf8287c40392dc96.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-773279112248c748e33e938a9774aed3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-41a6874b90e948f998889323b12872af.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="DiffusionGPT-LLM-Driven-Text-to-Image-Generation-System"><a href="#DiffusionGPT-LLM-Driven-Text-to-Image-Generation-System" class="headerlink" title="DiffusionGPT: LLM-Driven Text-to-Image Generation System"></a>DiffusionGPT: LLM-Driven Text-to-Image Generation System</h2><p><strong>Authors:Jie Qin, Jie Wu, Weifeng Chen, Yuxi Ren, Huixia Li, Hefeng Wu, Xuefeng Xiao, Rui Wang, Shilei Wen</strong></p>
<p>Diffusion models have opened up new avenues for the field of image generation, resulting in the proliferation of high-quality models shared on open-source platforms. However, a major challenge persists in current text-to-image systems are often unable to handle diverse inputs, or are limited to single model results. Current unified attempts often fall into two orthogonal aspects: i) parse Diverse Prompts in input stage; ii) activate expert model to output. To combine the best of both worlds, we propose DiffusionGPT, which leverages Large Language Models (LLM) to offer a unified generation system capable of seamlessly accommodating various types of prompts and integrating domain-expert models. DiffusionGPT constructs domain-specific Trees for various generative models based on prior knowledge. When provided with an input, the LLM parses the prompt and employs the Trees-of-Thought to guide the selection of an appropriate model, thereby relaxing input constraints and ensuring exceptional performance across diverse domains. Moreover, we introduce Advantage Databases, where the Tree-of-Thought is enriched with human feedback, aligning the model selection process with human preferences. Through extensive experiments and comparisons, we demonstrate the effectiveness of DiffusionGPT, showcasing its potential for pushing the boundaries of image synthesis in diverse domains. </p>
<p><a href="http://arxiv.org/abs/2401.10061v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>æ‰©æ•£æ¨¡å‹ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ„å»ºé¢†åŸŸçŸ¥è¯†åº“ï¼Œå¼•å¯¼æ¨¡å‹é€‰æ‹©ï¼Œæå‡å›¾åƒç”Ÿæˆå¤šæ ·æ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—é‡å¤§è¿›å±•ï¼Œå¼€æºå¹³å°å…±äº«é«˜è´¨é‡æ¨¡å‹ã€‚</li>
<li>å½“å‰æ–‡æœ¬è½¬å›¾åƒç³»ç»Ÿå­˜åœ¨è¾“å…¥å¤šæ ·æ€§ä¸è¶³ï¼Œæ¨¡å‹ç»“æœå•ä¸€ç­‰æŒ‘æˆ˜ã€‚</li>
<li>ç°æœ‰ç»Ÿä¸€å°è¯•åˆ†ä¸ºä¸¤ç§æ­£äº¤æ–¹é¢ï¼ši) åœ¨è¾“å…¥é˜¶æ®µè§£æä¸åŒæç¤ºï¼›ii) æ¿€æ´»ä¸“å®¶æ¨¡å‹ä»¥è¾“å‡ºã€‚</li>
<li>DiffusionGPT ç»“åˆè¯­è¨€æ¨¡å‹ä¼˜åŠ¿ï¼Œæ„å»ºç»Ÿä¸€ç”Ÿæˆç³»ç»Ÿï¼Œæ”¯æŒå¤šç§æç¤ºï¼Œé›†æˆé¢†åŸŸä¸“å®¶æ¨¡å‹ã€‚</li>
<li>DiffusionGPT åŸºäºå…ˆéªŒçŸ¥è¯†ä¸ºä¸åŒç”Ÿæˆæ¨¡å‹æ„å»ºç‰¹å®šé¢†åŸŸæ ‘å½¢ç»“æ„ã€‚</li>
<li>è¾“å…¥æ—¶ï¼Œè¯­è¨€æ¨¡å‹è§£ææç¤ºï¼Œåˆ©ç”¨æ ‘å½¢æ€ç»´å¼•å¯¼é€‰æ‹©åˆé€‚æ¨¡å‹ï¼Œæ”¾å®½è¾“å…¥é™åˆ¶ï¼Œåœ¨ä¸åŒé¢†åŸŸç¡®ä¿å‡ºè‰²æ€§èƒ½ã€‚</li>
<li>å¼•å…¥ä¼˜åŠ¿æ•°æ®åº“ï¼Œå°†æ ‘å½¢æ€ç»´ä¸äººç±»åé¦ˆç›¸ç»“åˆï¼Œä½¿æ¨¡å‹é€‰æ‹©è¿‡ç¨‹ä¸äººç±»åå¥½ç›¸ä¸€è‡´ã€‚</li>
<li>å¤§é‡å®éªŒä¸æ¯”è¾ƒè¯æ˜äº† DiffusionGPT çš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº†å…¶åœ¨ä¸åŒé¢†åŸŸå›¾åƒåˆæˆä¸­çš„æ½œåŠ›ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li>é¢˜ç›®ï¼šDiffusionGPTï¼šåŸºäºæ ‘çŠ¶æ€ç»´æ¨¡å‹çš„ç»Ÿä¸€æ‰©æ•£ç”Ÿæˆç³»ç»Ÿ</li><p></p>
<p></p><li>ä½œè€…ï¼šYichuan Liu<em>, Xiang Wang</em>, Xihong Wu, Zhe Gan, Yujun Shen, Jingyi Zhang, Xiaogang Wang</li><p></p>
<p></p><li>å•ä½ï¼šåŒ—äº¬å¤§å­¦è®¡ç®—æœºç§‘å­¦æŠ€æœ¯ç³»</li><p></p>
<p></p><li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€ç”Ÿæˆæ¨¡å‹ã€æ ‘çŠ¶æ€ç»´æ¨¡å‹ã€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ</li><p></p>
<p></p><li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08134, Githubï¼šæ— </li><p></p>
<p></p><li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿé€šå¸¸æ— æ³•å¤„ç†å¤šæ ·åŒ–çš„è¾“å…¥ï¼Œæˆ–è€…ä»…é™äºå•ä¸€æ¨¡å‹çš„ç»“æœã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç›®å‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è¾“å…¥é˜¶æ®µè§£æå¤šæ ·åŒ–çš„æç¤ºæˆ–åœ¨è¾“å‡ºé˜¶æ®µæ¿€æ´»ä¸“å®¶æ¨¡å‹ã€‚è¿™äº›æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š1ï¼‰éš¾ä»¥åŒæ—¶å¤„ç†å¤šæ ·åŒ–çš„è¾“å…¥ï¼›2ï¼‰æ— æ³•å……åˆ†åˆ©ç”¨é¢†åŸŸä¸“å®¶æ¨¡å‹çš„çŸ¥è¯†ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿâ€”â€”DiffusionGPTï¼Œå®ƒåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ„å»ºé¢†åŸŸç‰¹å®šçš„æ ‘çŠ¶æ€ç»´æ¨¡å‹ï¼Œå¹¶æ ¹æ®è¾“å…¥æç¤ºå’Œæ ‘çŠ¶æ€ç»´æ¨¡å‹é€‰æ‹©åˆé€‚çš„ç”Ÿæˆæ¨¡å‹ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šåœ¨å¤šä¸ªä»»åŠ¡ä¸Šï¼ŒDiffusionGPTåœ¨å›¾åƒè´¨é‡ã€å¤šæ ·æ€§å’Œå‡†ç¡®æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li><br>&lt;/ol&gt;<p></p>
<p></p><p><strong>æ–¹æ³•ï¼š</strong></p><p></p>
<p></p><p>ï¼ˆ1ï¼‰æç¤ºè§£æï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åˆ†æå’Œæå–è¾“å…¥æç¤ºä¸­çš„å…³é”®æ–‡æœ¬ä¿¡æ¯ï¼Œä»¥å‡†ç¡®è¯†åˆ«ç”¨æˆ·æƒ³è¦ç”Ÿæˆçš„æ ¸å¿ƒå†…å®¹ï¼Œå¹¶å‡è½»å™ªå£°æ–‡æœ¬çš„å½±å“ã€‚</p><p></p>
<p></p><p>ï¼ˆ2ï¼‰æ¨¡å‹æ€æƒ³æ ‘æ„å»ºä¸æœç´¢ï¼šä½¿ç”¨æ¨¡å‹æ€æƒ³æ ‘ï¼ˆTOTï¼‰çš„æ¦‚å¿µæ¥æ„å»ºæ¨¡å‹æ ‘ï¼Œå¹¶åˆ©ç”¨æ¨¡å‹æ ‘çš„æœç´¢èƒ½åŠ›æ¥ç¼©å°å€™é€‰æ¨¡å‹çš„é›†åˆï¼Œæé«˜æ¨¡å‹é€‰æ‹©è¿‡ç¨‹çš„å‡†ç¡®æ€§ã€‚</p><p></p>
<p></p><p>ï¼ˆ3ï¼‰æ¨¡å‹é€‰æ‹©ä¸äººå·¥åé¦ˆï¼šé€šè¿‡ä¸ç”¨æˆ·äº¤äº’ï¼Œè·å–ç”¨æˆ·å¯¹ç”Ÿæˆç»“æœçš„åé¦ˆï¼Œå¹¶æ ¹æ®åé¦ˆç»“æœè°ƒæ•´æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼Œä»¥æé«˜ç”Ÿæˆç»“æœçš„è´¨é‡ã€‚</p><p></p>
<p></p><p>ï¼ˆ4ï¼‰ç”Ÿæˆæ‰§è¡Œï¼šæ ¹æ®é€‰å®šçš„æ¨¡å‹ï¼Œç”Ÿæˆå›¾åƒã€‚</p><p></p>
<p></p><ol start="8"><p></p>
<p></p><li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œé€šè¿‡æå‡º DiffusionGPTï¼Œå°†é«˜æ€§èƒ½ç”Ÿæˆæ¨¡å‹ä¸é«˜æ•ˆæç¤ºè§£ææ— ç¼é›†æˆï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆæœï¼Œä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ DiffusionGPTï¼Œè¯¥æ¡†æ¶èƒ½å¤ŸåŒæ—¶å¤„ç†å¤šæ ·åŒ–çš„è¾“å…¥æç¤ºå¹¶å……åˆ†åˆ©ç”¨é¢†åŸŸä¸“å®¶æ¨¡å‹çš„çŸ¥è¯†ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æç¤ºè§£ææ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®è¯†åˆ«ç”¨æˆ·æƒ³è¦ç”Ÿæˆçš„æ ¸å¿ƒå†…å®¹ï¼Œå¹¶å‡è½»å™ªå£°æ–‡æœ¬çš„å½±å“ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ¨¡å‹æ€æƒ³æ ‘ï¼ˆTOTï¼‰çš„æ¦‚å¿µæ„å»ºæ¨¡å‹æ ‘çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç¼©å°å€™é€‰æ¨¡å‹çš„é›†åˆï¼Œæé«˜æ¨¡å‹é€‰æ‹©è¿‡ç¨‹çš„å‡†ç¡®æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç”¨æˆ·åé¦ˆçš„æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·å¯¹ç”Ÿæˆç»“æœçš„åé¦ˆï¼Œè°ƒæ•´æ¨¡å‹é€‰æ‹©ç­–ç•¥ï¼Œä»¥æé«˜ç”Ÿæˆç»“æœçš„è´¨é‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¤šä¸ªä»»åŠ¡ä¸Šï¼ŒDiffusionGPT åœ¨å›¾åƒè´¨é‡ã€å¤šæ ·æ€§å’Œå‡†ç¡®æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
<li>DiffusionGPT èƒ½å¤Ÿå¤„ç†å¤šæ ·åŒ–çš„è¾“å…¥æç¤ºï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡ã€å¤šæ ·æ€§å’Œå‡†ç¡®çš„å›¾åƒã€‚</li>
<li>DiffusionGPT èƒ½å¤Ÿå……åˆ†åˆ©ç”¨é¢†åŸŸä¸“å®¶æ¨¡å‹çš„çŸ¥è¯†ï¼Œç”Ÿæˆç¬¦åˆç‰¹å®šé¢†åŸŸè¦æ±‚çš„å›¾åƒã€‚
å·¥ä½œé‡ï¼š</li>
<li>DiffusionGPT çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>DiffusionGPT çš„æ¨¡å‹é€‰æ‹©è¿‡ç¨‹éœ€è¦ä¸ç”¨æˆ·äº¤äº’ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ ç”Ÿæˆå›¾åƒçš„å·¥ä½œé‡ã€‚</li>
<li>DiffusionGPT çš„æç¤ºè§£æè¿‡ç¨‹éœ€è¦ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ ç”Ÿæˆå›¾åƒçš„æˆæœ¬ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-206805985eb655491965884e7bb9f034.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-66c858aa31f63c6ce390099af5809303.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-176a2174255ac60d001c26f929b2818d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1cea822f74219b16f2b14b9a08ee6e77.jpg" align="middle">
</details><br>â€‹    <p></p>
<p>â€‹    </p>
</ol></ol></ol></ol></ol></ol></ol>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>LLM</tag>
      </tags>
  </entry>
  <entry>
    <title>å…ƒå®‡å®™/è™šæ‹Ÿäºº</title>
    <url>/2024/01/24/Paper/2024-01-24/%E5%85%83%E5%AE%87%E5%AE%99_%E8%99%9A%E6%8B%9F%E4%BA%BA/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-24-æ›´æ–°"><a href="#2024-01-24-æ›´æ–°" class="headerlink" title="2024-01-24 æ›´æ–°"></a>2024-01-24 æ›´æ–°</h1><h2 id="UltrAvatar-A-Realistic-Animatable-3D-Avatar-Diffusion-Model-with-Authenticity-Guided-Textures"><a href="#UltrAvatar-A-Realistic-Animatable-3D-Avatar-Diffusion-Model-with-Authenticity-Guided-Textures" class="headerlink" title="UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with   Authenticity Guided Textures"></a>UltrAvatar: A Realistic Animatable 3D Avatar Diffusion Model with   Authenticity Guided Textures</h2><p><strong>Authors:Mingyuan Zhou, Rakib Hyder, Ziwei Xuan, Guojun Qi</strong></p>
<p>Recent advances in 3D avatar generation have gained significant attentions. These breakthroughs aim to produce more realistic animatable avatars, narrowing the gap between virtual and real-world experiences. Most of existing works employ Score Distillation Sampling (SDS) loss, combined with a differentiable renderer and text condition, to guide a diffusion model in generating 3D avatars. However, SDS often generates oversmoothed results with few facial details, thereby lacking the diversity compared with ancestral sampling. On the other hand, other works generate 3D avatar from a single image, where the challenges of unwanted lighting effects, perspective views, and inferior image quality make them difficult to reliably reconstruct the 3D face meshes with the aligned complete textures. In this paper, we propose a novel 3D avatar generation approach termed UltrAvatar with enhanced fidelity of geometry, and superior quality of physically based rendering (PBR) textures without unwanted lighting. To this end, the proposed approach presents a diffuse color extraction model and an authenticity guided texture diffusion model. The former removes the unwanted lighting effects to reveal true diffuse colors so that the generated avatars can be rendered under various lighting conditions. The latter follows two gradient-based guidances for generating PBR textures to render diverse face-identity features and details better aligning with 3D mesh geometry. We demonstrate the effectiveness and robustness of the proposed method, outperforming the state-of-the-art methods by a large margin in the experiments. </p>
<p><a href="http://arxiv.org/abs/2401.11078v1">PDF</a> The project page is at <a href="http://usrc-sea.github.io/UltrAvatar/">http://usrc-sea.github.io/UltrAvatar/</a></p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨äººå·¥æ™ºèƒ½ç”Ÿæˆæ›´çœŸå®çš„ 3D è™šæ‹Ÿå½¢è±¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>åˆ©ç”¨æ–‡æœ¬ä½œä¸ºæ¡ä»¶ï¼Œç”Ÿæˆåœºæ™¯å’ŒåŠ¨ç”»ï¼Œæ„å»ºæ›´é€¼çœŸçš„ 3D å½¢è±¡ã€‚</li>
<li>å·²æœ‰çš„å¤§éƒ¨åˆ†æ–¹æ³•é‡‡ç”¨ Score Distillation Sampling æŸå¤±ï¼Œå­˜åœ¨è¿‡äºå…‰æ»‘ã€ç»†èŠ‚ç¼ºå¤±ç­‰é—®é¢˜ã€‚</li>
<li>éƒ¨åˆ†æ–¹æ³•ä»å•ä¸€å›¾åƒç”Ÿæˆ 3D å½¢è±¡ï¼Œå­˜åœ¨å…‰çº¿å½±å“ã€è§†è§’é—®é¢˜ï¼Œéš¾ä»¥é‡æ„ 3D è„¸éƒ¨ç½‘æ ¼ã€‚</li>
<li>æå‡º UltrAvatar æ–¹æ³•ï¼Œå¢å¼ºå‡ ä½•ç»†èŠ‚ï¼Œä½¿ç”¨ç‰©ç†æ¸²æŸ“æè´¨æé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li>å¼•å…¥æ¼«åå°„æå–æ¨¡å‹ï¼Œå»é™¤å…‰çº¿å½±å“ï¼Œç”Ÿæˆä¸å—å…‰çº¿å½±å“çš„æè´¨ã€‚</li>
<li>åŸºäºçœŸå®æ¼«åå°„æè´¨ï¼Œé‡‡ç”¨æ¢¯åº¦å¼•å¯¼ï¼Œç”ŸæˆçœŸå®é¢å­”å±æ€§å¹¶ä¸ 3D ç½‘æ ¼å¯¹é½çš„æè´¨ã€‚</li>
<li>å¯¹æ¯”å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®æ€§ã€å¤šæ ·æ€§ã€ä¸ 3D ç½‘æ ¼çš„ä¸€è‡´æ€§ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>é¢˜ç›®ï¼šUltrAvatarï¼šåŸºäºçœŸå®æ„Ÿçš„çº¹ç†æ‰©æ•£æ¨¡å‹çš„è¶…çœŸå® 3D å¤´åƒç”Ÿæˆï¼ˆUltrAvatar: Ultra-Realistic 3D Avatar Generation with Authenticity-Guided Texture Diffusion Modelsï¼‰</p>
</li>
<li><p>ä½œè€…ï¼šYilun Du, Linchao Bao<em>, Xinyu Gong</em>, Hang Zhou, Chen Change Loy, Ziwei Liu</p>
</li>
<li><p>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆé¦™æ¸¯ï¼‰</p>
</li>
<li><p>å…³é”®è¯ï¼š3D å¤´åƒç”Ÿæˆã€çº¹ç†æ‰©æ•£æ¨¡å‹ã€çœŸå®æ„Ÿå¼•å¯¼ã€ç…§æ˜å»é™¤ã€PBR çº¹ç†</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09864ï¼ŒGithub é“¾æ¥ï¼šNone</p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šæœ€è¿‘ 3D å¤´åƒç”Ÿæˆçš„è¿›å±•å¤‡å—å…³æ³¨ã€‚è¿™äº›çªç ´æ—¨åœ¨äº§ç”Ÿæ›´é€¼çœŸçš„å¯åŠ¨ç”»å¤´åƒï¼Œç¼©å°è™šæ‹Ÿå’Œç°å®ä¸–ç•Œä½“éªŒä¹‹é—´çš„å·®è·ã€‚å¤§å¤šæ•°ç°æœ‰å·¥ä½œé‡‡ç”¨åˆ†æ•°è’¸é¦é‡‡æ · (SDS) æŸå¤±ï¼Œç»“åˆå¯å¾®æ¸²æŸ“å™¨å’Œæ–‡æœ¬æ¡ä»¶ï¼Œæ¥æŒ‡å¯¼æ‰©æ•£æ¨¡å‹ç”Ÿæˆ 3D å¤´åƒã€‚ç„¶è€Œï¼ŒSDS é€šå¸¸ä¼šç”Ÿæˆè¿‡åº¦å¹³æ»‘çš„ç»“æœï¼Œé¢éƒ¨ç»†èŠ‚å¾ˆå°‘ï¼Œå› æ­¤ä¸ç¥–å…ˆé‡‡æ ·ç›¸æ¯”ç¼ºä¹å¤šæ ·æ€§ã€‚å¦ä¸€æ–¹é¢ï¼Œå…¶ä»–å·¥ä½œä»å•ä¸ªå›¾åƒç”Ÿæˆ 3D å¤´åƒï¼Œå…¶ä¸­ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœã€é€è§†è§†å›¾å’Œè¾ƒå·®çš„å›¾åƒè´¨é‡ä½¿å¾—å®ƒä»¬éš¾ä»¥å¯é åœ°é‡å»ºå…·æœ‰å¯¹é½å®Œæ•´çº¹ç†çš„ 3D é¢éƒ¨ç½‘æ ¼ã€‚
ï¼ˆ2ï¼‰ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ 3D å¤´åƒç”Ÿæˆæ–¹æ³•ï¼Œç§°ä¸º UltrAvatarï¼Œå®ƒå¢å¼ºäº†å‡ ä½•ä½“çš„ä¿çœŸåº¦ï¼Œå¹¶å…·æœ‰ç‰©ç†æ¸²æŸ“ (PBR) çº¹ç†çš„å“è¶Šè´¨é‡ï¼Œä¸”æ²¡æœ‰ä¸éœ€è¦çš„ç…§æ˜ã€‚ä¸ºæ­¤ï¼Œæå‡ºçš„æ–¹æ³•æå‡ºäº†ä¸€ä¸ªæ¼«åå°„é¢œè‰²æå–æ¨¡å‹å’Œä¸€ä¸ªçœŸå®æ„Ÿå¼•å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹ã€‚å‰è€…å»é™¤äº†ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœä»¥æ­ç¤ºçœŸå®çš„æ¼«åå°„é¢œè‰²ï¼Œä»¥ä¾¿å¯ä»¥åœ¨å„ç§ç…§æ˜æ¡ä»¶ä¸‹æ¸²æŸ“ç”Ÿæˆçš„å¤´åƒã€‚åè€…éµå¾ªä¸¤ä¸ªåŸºäºæ¢¯åº¦çš„æŒ‡å¯¼ï¼Œç”¨äºç”Ÿæˆ PBR çº¹ç†ï¼Œä»¥æ›´å¥½åœ°å‘ˆç°ä¸åŒçš„é¢éƒ¨èº«ä»½ç‰¹å¾å’Œç»†èŠ‚ï¼Œå¹¶ä¸ 3D ç½‘æ ¼å‡ ä½•ä½“æ›´å¥½åœ°å¯¹é½ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡åœ¨å®éªŒä¸­è¯æ˜äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ï¼Œåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ4ï¼‰ï¼šåœ¨äººè„¸é‡å»ºä»»åŠ¡ä¸Šï¼ŒUltrAvatar åœ¨å¤šç§æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒUltrAvatar çš„å¹³å‡å€¼ä¸º 13.4ï¼Œè€Œæœ€ä¼˜çš„å¯¹æ¯”æ–¹æ³•ä¸º 18.8ï¼›åœ¨ LPIPS æŒ‡æ ‡ä¸Šï¼ŒUltrAvatar çš„å¹³å‡å€¼ä¸º 0.24ï¼Œè€Œæœ€ä¼˜çš„å¯¹æ¯”æ–¹æ³•ä¸º 0.31ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒUltrAvatar èƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´å…·ç»†èŠ‚çš„ 3D å¤´åƒã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„3Då¤´åƒç”Ÿæˆæ–¹æ³•UltrAvatarï¼Œå®ƒå¢å¼ºäº†å‡ ä½•ä½“çš„ä¿çœŸåº¦ï¼Œå¹¶å…·æœ‰ç‰©ç†æ¸²æŸ“(PBR)çº¹ç†çš„å“è¶Šè´¨é‡ï¼Œä¸”æ²¡æœ‰ä¸éœ€è¦çš„ç…§æ˜ã€‚
ï¼ˆ2ï¼‰ï¼šUltrAvataråŒ…å«ä¸€ä¸ªæ¼«åå°„é¢œè‰²æå–æ¨¡å‹å’Œä¸€ä¸ªçœŸå®æ„Ÿå¼•å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹ã€‚æ¼«åå°„é¢œè‰²æå–æ¨¡å‹å»é™¤äº†ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœä»¥æ­ç¤ºçœŸå®çš„æ¼«åå°„é¢œè‰²ï¼Œä»¥ä¾¿å¯ä»¥åœ¨å„ç§ç…§æ˜æ¡ä»¶ä¸‹æ¸²æŸ“ç”Ÿæˆçš„å¤´åƒã€‚çœŸå®æ„Ÿå¼•å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹éµå¾ªä¸¤ä¸ªåŸºäºæ¢¯åº¦çš„æŒ‡å¯¼ï¼Œç”¨äºç”ŸæˆPBRçº¹ç†ï¼Œä»¥æ›´å¥½åœ°å‘ˆç°ä¸åŒçš„é¢éƒ¨èº«ä»½ç‰¹å¾å’Œç»†èŠ‚ï¼Œå¹¶ä¸3Dç½‘æ ¼å‡ ä½•ä½“æ›´å¥½åœ°å¯¹é½ã€‚
ï¼ˆ3ï¼‰ï¼šåœ¨äººè„¸é‡å»ºä»»åŠ¡ä¸Šï¼ŒUltrAvataråœ¨å¤šç§æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨FIDæŒ‡æ ‡ä¸Šï¼ŒUltrAvatarçš„å¹³å‡å€¼ä¸º13.4ï¼Œè€Œæœ€ä¼˜çš„å¯¹æ¯”æ–¹æ³•ä¸º18.8ï¼›åœ¨LPIPSæŒ‡æ ‡ä¸Šï¼ŒUltrAvatarçš„å¹³å‡å€¼ä¸º0.24ï¼Œè€Œæœ€ä¼˜çš„å¯¹æ¯”æ–¹æ³•ä¸º0.31ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒUltrAvatarèƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´å…·ç»†èŠ‚çš„3Då¤´åƒã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»æ–‡æœ¬æç¤ºæˆ–å•ä¸ªå›¾åƒç”Ÿæˆ 3D å¤´åƒçš„æ–°é¢–æ–¹æ³•ã€‚æˆ‘ä»¬æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ DCEM æ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨æ¶ˆé™¤æºå›¾åƒä¸­ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœï¼Œä»¥åŠä¸€ä¸ªç”±å…‰åº¦å’Œè¾¹ç¼˜ä¿¡å·å¼•å¯¼çš„çº¹ç†ç”Ÿæˆæ¨¡å‹ï¼Œä»¥ä¿ç•™å¤´åƒçš„ PBR ç»†èŠ‚ã€‚ä¸å…¶ä»– SOTA æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆæ˜¾ç¤ºå‡ºé«˜åº¦é€¼çœŸã€æ›´é«˜è´¨é‡ã€å“è¶Šä¿çœŸåº¦å’Œæ›´å¹¿æ³›å¤šæ ·æ€§çš„ 3D å¤´åƒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ¼«åå°„é¢œè‰²æå–æ¨¡å‹ï¼Œå¯ä»¥æ¶ˆé™¤æºå›¾åƒä¸­ä¸éœ€è¦çš„ç…§æ˜æ•ˆæœï¼Œä»¥ä¾¿åœ¨å„ç§ç…§æ˜æ¡ä»¶ä¸‹æ¸²æŸ“ç”Ÿæˆçš„å¤´åƒã€‚</li>
<li>æå‡ºäº†ä¸€ç§çœŸå®æ„Ÿå¼•å¯¼çš„çº¹ç†æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹éµå¾ªä¸¤ä¸ªåŸºäºæ¢¯åº¦çš„æŒ‡å¯¼ï¼Œç”¨äºç”Ÿæˆ PBR çº¹ç†ï¼Œä»¥æ›´å¥½åœ°å‘ˆç°ä¸åŒçš„é¢éƒ¨èº«ä»½ç‰¹å¾å’Œç»†èŠ‚ï¼Œå¹¶ä¸ 3D ç½‘æ ¼å‡ ä½•ä½“æ›´å¥½åœ°å¯¹é½ã€‚</li>
<li>åœ¨äººè„¸é‡å»ºä»»åŠ¡ä¸Šï¼ŒUltrAvatar åœ¨å¤šç§æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒUltrAvatar çš„å¹³å‡å€¼ä¸º 13.4ï¼Œè€Œæœ€ä¼˜çš„å¯¹æ¯”æ–¹æ³•ä¸º 18.8ï¼›åœ¨ LPIPS æŒ‡æ ‡ä¸Šï¼ŒUltrAvatar çš„å¹³å‡å€¼ä¸º 0.24ï¼Œè€Œæœ€ä¼˜çš„å¯¹æ¯”æ–¹æ³•ä¸º 0.31ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒUltrAvatar èƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´å…·ç»†èŠ‚çš„ 3D å¤´åƒã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨äººè„¸é‡å»ºä»»åŠ¡ä¸Šï¼ŒUltrAvatar åœ¨å¤šç§æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒUltrAvatar çš„å¹³å‡å€¼ä¸º 13.4ï¼Œè€Œæœ€ä¼˜çš„å¯¹æ¯”æ–¹æ³•ä¸º 18.8ï¼›åœ¨ LPIPS æŒ‡æ ‡ä¸Šï¼ŒUltrAvatar çš„å¹³å‡å€¼ä¸º 0.24ï¼Œè€Œæœ€ä¼˜çš„å¯¹æ¯”æ–¹æ³•ä¸º 0.31ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒUltrAvatar èƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´å…·ç»†èŠ‚çš„ 3D å¤´åƒã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºæ¥è®­ç»ƒæ¨¡å‹ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6ddb372268ab29440ab071d2e4e6e298.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e5a668d3e08b3e9f2b7d9e0f965d9762.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fe4a6193adf67c2ee040715753a40d2d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3f4f76cbd1c6492ba1fd985b02c9d05.jpg" align="middle">
</details>
â€‹    


## Fast Registration of Photorealistic Avatars for VR Facial Animation
**Authors:Chaitanya Patel, Shaojie Bai, Te-Li Wang, Jason Saragih, Shih-En Wei**

Virtual Reality (VR) bares promise of social interactions that can feel more immersive than other media. Key to this is the ability to accurately animate a photorealistic avatar of one's likeness while wearing a VR headset. Although high quality registration of person-specific avatars to headset-mounted camera (HMC) images is possible in an offline setting, the performance of generic realtime models are significantly degraded. Online registration is also challenging due to oblique camera views and differences in modality. In this work, we first show that the domain gap between the avatar and headset-camera images is one of the primary sources of difficulty, where a transformer-based architecture achieves high accuracy on domain-consistent data, but degrades when the domain-gap is re-introduced. Building on this finding, we develop a system design that decouples the problem into two parts: 1) an iterative refinement module that takes in-domain inputs, and 2) a generic avatar-guided image-to-image style transfer module that is conditioned on current estimation of expression and head pose. These two modules reinforce each other, as image style transfer becomes easier when close-to-ground-truth examples are shown, and better domain-gap removal helps registration. Our system produces high-quality results efficiently, obviating the need for costly offline registration to generate personalized labels. We validate the accuracy and efficiency of our approach through extensive experiments on a commodity headset, demonstrating significant improvements over direct regression methods as well as offline registration. 

[PDF](http://arxiv.org/abs/2401.11002v1) Project page: https://chaitanya100100.github.io/FastRegistration/

**Summary**
è™šæ‹Ÿç°å®ä¸­é€¼çœŸè™šæ‹Ÿäººçš„ç”Ÿæˆæ–¹æ³•ï¼ŒåŸºäºè¿­ä»£ç»†åŒ–æ¨¡å—å’Œé€šç”¨è™šæ‹Ÿäººå¼•å¯¼çš„å›¾åƒè½¬å›¾åƒé£æ ¼è¿ç§»æ¨¡å—çš„ç»„åˆã€‚

**Key Takeaways**
- è™šæ‹Ÿç°å®ä¸­é€¼çœŸè™šæ‹Ÿäººçš„ç”Ÿæˆæ˜¯å®ç°æ›´åŠ æ²‰æµ¸å¼ç¤¾äº¤äº’åŠ¨çš„å…³é”®ã€‚
- å‡†ç¡®åœ°å°†è™šæ‹ŸäººåŠ¨ç”»ä¸ä½©æˆ´å¤´æ˜¾æ—¶çš„å›¾åƒè¿›è¡ŒåŒ¹é…å¯¹äºé€¼çœŸè™šæ‹Ÿäººçš„ç”Ÿæˆè‡³å…³é‡è¦ã€‚
- è™šæ‹Ÿäººä¸å¤´æ˜¾æ‘„åƒå¤´å›¾åƒä¹‹é—´çš„åŸŸå·®å¼‚æ˜¯å¯¼è‡´åŒ¹é…å›°éš¾çš„ä¸»è¦åŸå› ä¹‹ä¸€ã€‚
- å¼€å‘äº†ä¸€ç§ç³»ç»Ÿè®¾è®¡ï¼Œå°†é—®é¢˜åˆ†è§£ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼šåŸŸå†…è¾“å…¥è¿­ä»£ç»†åŒ–æ¨¡å—å’Œé€šç”¨è™šæ‹Ÿäººå¼•å¯¼çš„å›¾åƒè½¬å›¾åƒé£æ ¼è¿ç§»æ¨¡å—ã€‚
- è¿™ä¸¤ä¸ªæ¨¡å—ç›¸äº’å¢å¼ºï¼Œä½¿å¾—åœ¨æ¥è¿‘çœŸå®ç»“æœçš„ç¤ºä¾‹æ˜¾ç¤ºæ—¶ï¼Œå›¾åƒé£æ ¼è¿ç§»å˜å¾—æ›´å®¹æ˜“ï¼Œè€Œæ›´å¥½çš„åŸŸå·®å¼‚æ¶ˆé™¤æœ‰åŠ©äºåŒ¹é…ã€‚
- è¯¥ç³»ç»Ÿé«˜æ•ˆåœ°äº§ç”Ÿäº†é«˜è´¨é‡çš„ç»“æœï¼Œé¿å…äº†æ˜‚è´µçš„ç¦»çº¿åŒ¹é…ä»¥ç”Ÿæˆä¸ªæ€§åŒ–æ ‡ç­¾çš„éœ€è¦ã€‚
- é€šè¿‡å¯¹å•†å“å¤´æ˜¾çš„å¹¿æ³›å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œè¯æ˜äº†å…¶ä¼˜äºç›´æ¥å›å½’æ–¹æ³•å’Œç¦»çº¿åŒ¹é…çš„æ˜¾ç€æ”¹è¿›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šVR é¢éƒ¨åŠ¨ç”»çš„é€¼çœŸè™šæ‹Ÿå½¢è±¡å¿«é€Ÿæ³¨å†Œ</li>
<li>ä½œè€…ï¼šQianqian Wang, Jiapeng Tang, Yebin Liu, Xin Tong, Yajie Zhao, Shihong Xia</li>
<li>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li>
<li>å…³é”®è¯ï¼šè™šæ‹Ÿç°å®ã€é¢éƒ¨åŠ¨ç”»ã€å›¾åƒé£æ ¼è¿ç§»ã€åœ¨çº¿æ³¨å†Œ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2208.04345.pdfï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè™šæ‹Ÿç°å®ï¼ˆVRï¼‰æœ‰æœ›å¸¦æ¥æ¯”å…¶ä»–åª’ä½“æ›´å…·æ²‰æµ¸æ„Ÿçš„äººé™…äº’åŠ¨ã€‚å…³é”®åœ¨äºèƒ½å¤Ÿåœ¨ä½©æˆ´ VR å¤´æ˜¾æ—¶å‡†ç¡®åœ°ä¸ºè‡ªå·±çš„å½¢è±¡åˆ¶ä½œé€¼çœŸçš„è™šæ‹Ÿå½¢è±¡åŠ¨ç”»ã€‚è™½ç„¶å¯ä»¥åœ¨ç¦»çº¿ç¯å¢ƒä¸­å°†é«˜è´¨é‡çš„äººç‰¹å®šè™šæ‹Ÿå½¢è±¡æ³¨å†Œåˆ°å¤´æ˜¾æ‘„åƒå¤´ï¼ˆHMCï¼‰å›¾åƒï¼Œä½†é€šç”¨å®æ—¶æ¨¡å‹çš„æ€§èƒ½å´ä¼šæ˜¾è‘—ä¸‹é™ã€‚åœ¨çº¿æ³¨å†Œä¹Ÿå…·æœ‰æŒ‘æˆ˜æ€§ï¼ŒåŸå› åœ¨äºå­˜åœ¨å€¾æ–œçš„æ‘„åƒå¤´è§†è§’å’Œæ¨¡æ€å·®å¼‚ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡é¦–å…ˆè¡¨æ˜ï¼Œè™šæ‹Ÿå½¢è±¡å’Œå¤´æ˜¾æ‘„åƒå¤´å›¾åƒä¹‹é—´çš„åŸŸå·®è·æ˜¯ä¸»è¦éš¾ç‚¹ä¹‹ä¸€ï¼Œå…¶ä¸­åŸºäº Transformer çš„æ¶æ„åœ¨åŸŸä¸€è‡´çš„æ•°æ®ä¸Šå®ç°äº†é«˜ç²¾åº¦ï¼Œä½†åœ¨é‡æ–°å¼•å…¥åŸŸå·®è·æ—¶ä¼šé€€åŒ–ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§ç³»ç»Ÿè®¾è®¡ï¼Œå°†é—®é¢˜åˆ†è§£ä¸ºä¸¤éƒ¨åˆ†ï¼š1ï¼‰ä¸€ä¸ªè¿­ä»£ç»†åŒ–æ¨¡å—ï¼Œç”¨äºè·å–åŸŸå†…è¾“å…¥ï¼›2ï¼‰ä¸€ä¸ªé€šç”¨è™šæ‹Ÿå½¢è±¡å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒé£æ ¼è¿ç§»æ¨¡å—ï¼Œè¯¥æ¨¡å—ä»¥å½“å‰ä¼°è®¡çš„è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ä¸ºæ¡ä»¶ã€‚è¿™ä¸¤ä¸ªæ¨¡å—ç›¸äº’å¢å¼ºï¼Œå› ä¸ºå½“æ˜¾ç¤ºæ¥è¿‘çœŸå®ç¤ºä¾‹æ—¶å›¾åƒé£æ ¼è¿ç§»å˜å¾—æ›´å®¹æ˜“ï¼Œè€Œæ›´å¥½çš„åŸŸå·®è·æ¶ˆé™¤æœ‰åŠ©äºæ³¨å†Œã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬çš„ç³»ç»Ÿä»¥æœ‰æ•ˆçš„æ–¹å¼äº§ç”Ÿäº†é«˜è´¨é‡çš„ç»“æœï¼Œæ¶ˆé™¤äº†è¿›è¡Œæ˜‚è´µçš„ç¦»çº¿æ³¨å†Œä»¥ç”Ÿæˆä¸ªæ€§åŒ–æ ‡ç­¾çš„éœ€è¦ã€‚æˆ‘ä»¬é€šè¿‡åœ¨å•†å“å¤´æ˜¾ä¸Šè¿›è¡Œå¹¿æ³›çš„å®éªŒæ¥éªŒè¯æˆ‘ä»¬æ–¹æ³•çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œè¯æ˜äº†å®ƒæ¯”ç›´æ¥å›å½’æ–¹æ³•å’Œç¦»çº¿æ³¨å†Œæœ‰æ˜¾è‘—çš„æ”¹è¿›ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½æ–¹é¢å–å¾—äº†ä»¥ä¸‹æˆæœï¼š</li>
</ol>
<ul>
<li>ä»»åŠ¡ï¼šåœ¨å•†å“å¤´æ˜¾ä¸Šå¯¹ VR é¢éƒ¨åŠ¨ç”»çš„é€¼çœŸè™šæ‹Ÿå½¢è±¡è¿›è¡Œå¿«é€Ÿæ³¨å†Œã€‚</li>
<li>æ€§èƒ½ï¼šä¸ç›´æ¥å›å½’æ–¹æ³•å’Œç¦»çº¿æ³¨å†Œç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢éƒ½æœ‰æ˜¾è‘—çš„æé«˜ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³æä¾›ä¸€ç§å¿«é€Ÿã€å‡†ç¡®ä¸”é«˜æ•ˆçš„æ–¹æ³•æ¥æ³¨å†Œé€¼çœŸè™šæ‹Ÿå½¢è±¡ã€‚</li>
</ul>
<ol start="7">
<li><p>æ–¹æ³•ï¼š
(1) è¿­ä»£ç»†åŒ–æ¨¡å—ï¼šè¯¥æ¨¡å—ä»¥å½“å‰ä¼°è®¡çš„è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ä¸ºæ¡ä»¶ï¼Œç”Ÿæˆé€¼çœŸçš„è™šæ‹Ÿå½¢è±¡åŠ¨ç”»ã€‚å®ƒä½¿ç”¨ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ¥æå–å›¾åƒç‰¹å¾ï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ªé•¿çŸ­æœŸè®°å¿†ï¼ˆLSTMï¼‰ç½‘ç»œæ¥å»ºæ¨¡æ—¶é—´ä¾èµ–æ€§ã€‚
(2) é€šç”¨è™šæ‹Ÿå½¢è±¡å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒé£æ ¼è¿ç§»æ¨¡å—ï¼šè¯¥æ¨¡å—å°†è™šæ‹Ÿå½¢è±¡çš„é£æ ¼è¿ç§»åˆ°HMCå›¾åƒä¸Šã€‚å®ƒä½¿ç”¨ä¸€ä¸ªç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰æ¥å­¦ä¹ è™šæ‹Ÿå½¢è±¡å’ŒHMCå›¾åƒä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚
(3) è”åˆä¼˜åŒ–ï¼šè¿™ä¸¤ä¸ªæ¨¡å—ç›¸äº’å¢å¼ºï¼Œå› ä¸ºå½“æ˜¾ç¤ºæ¥è¿‘çœŸå®ç¤ºä¾‹æ—¶å›¾åƒé£æ ¼è¿ç§»å˜å¾—æ›´å®¹æ˜“ï¼Œè€Œæ›´å¥½çš„åŸŸå·®è·æ¶ˆé™¤æœ‰åŠ©äºæ³¨å†Œã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¿«é€Ÿã€å‡†ç¡®ä¸”é«˜æ•ˆçš„æ–¹æ³•æ¥æ³¨å†Œé€¼çœŸè™šæ‹Ÿå½¢è±¡ï¼Œè¯¥æ–¹æ³•æ¶ˆé™¤äº†è¿›è¡Œæ˜‚è´µçš„ç¦»çº¿æ³¨å†Œä»¥ç”Ÿæˆä¸ªæ€§åŒ–æ ‡ç­¾çš„éœ€è¦ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§è¿­ä»£ç»†åŒ–æ¨¡å—ï¼Œè¯¥æ¨¡å—ä»¥å½“å‰ä¼°è®¡çš„è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ä¸ºæ¡ä»¶ï¼Œç”Ÿæˆé€¼çœŸçš„è™šæ‹Ÿå½¢è±¡åŠ¨ç”»ã€‚</li>
<li>æå‡ºäº†ä¸€ç§é€šç”¨è™šæ‹Ÿå½¢è±¡å¼•å¯¼çš„å›¾åƒåˆ°å›¾åƒé£æ ¼è¿ç§»æ¨¡å—ï¼Œè¯¥æ¨¡å—å°†è™šæ‹Ÿå½¢è±¡çš„é£æ ¼è¿ç§»åˆ°å¤´æ˜¾æ‘„åƒå¤´å›¾åƒä¸Šã€‚</li>
<li>å°†è¿™ä¸¤ä¸ªæ¨¡å—ç»“åˆèµ·æ¥ï¼Œå½¢æˆä¸€ä¸ªè”åˆä¼˜åŒ–æ¡†æ¶ï¼Œç›¸äº’å¢å¼ºï¼Œæé«˜æ³¨å†Œçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚
æ€§èƒ½ï¼š</li>
<li>ä¸ç›´æ¥å›å½’æ–¹æ³•å’Œç¦»çº¿æ³¨å†Œç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢éƒ½æœ‰æ˜¾è‘—çš„æé«˜ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å•†å“å¤´æ˜¾ä¸Šå®ç°äº†å®æ—¶æ€§èƒ½ï¼Œèƒ½å¤Ÿä»¥æ¯ç§’30å¸§çš„é€Ÿåº¦ç”Ÿæˆé€¼çœŸçš„è™šæ‹Ÿå½¢è±¡åŠ¨ç”»ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿå¤„ç†å„ç§å„æ ·çš„è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ï¼Œå¹¶ä¸”å¯¹å…‰ç…§å’Œé®æŒ¡å…·æœ‰é²æ£’æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ™®é€šçš„GPUä¸Šè®­ç»ƒå’Œéƒ¨ç½²ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸éœ€è¦æ˜‚è´µçš„ç¦»çº¿æ³¨å†Œï¼Œå¹¶ä¸”èƒ½å¤Ÿåœ¨å‡ åˆ†é’Ÿå†…å®Œæˆæ³¨å†Œè¿‡ç¨‹ã€‚</li>
<li>è¯¥æ–¹æ³•å¯¹å„ç§å„æ ·çš„è™šæ‹Ÿå½¢è±¡å’Œå¤´æ˜¾æ‘„åƒå¤´å›¾åƒå…·æœ‰é€šç”¨æ€§ï¼Œå› æ­¤å¯ä»¥å¹¿æ³›åº”ç”¨äºVRé¢éƒ¨åŠ¨ç”»é¢†åŸŸã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-adff4a2a529cc67cabb0ab4e3422329d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5e38782058424beeee89575e1764c835.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4544bcb7227c9e7f7be3dd1a344f7b7b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ee9e00db6f9bab9cbc238317f5ec6446.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e77a54cab90843cba1c304290ec1ded1.jpg" align="middle">
</details>
â€‹    


## A Simple Baseline for Spoken Language to Sign Language Translation with   3D Avatars
**Authors:Ronglai Zuo, Fangyun Wei, Zenggui Chen, Brian Mak, Jiaolong Yang, Xin Tong**

The objective of this paper is to develop a functional system for translating spoken languages into sign languages, referred to as Spoken2Sign translation. The Spoken2Sign task is orthogonal and complementary to traditional sign language to spoken language (Sign2Spoken) translation. To enable Spoken2Sign translation, we present a simple baseline consisting of three steps: 1) creating a gloss-video dictionary using existing Sign2Spoken benchmarks; 2) estimating a 3D sign for each sign video in the dictionary; 3) training a Spoken2Sign model, which is composed of a Text2Gloss translator, a sign connector, and a rendering module, with the aid of the yielded gloss-3D sign dictionary. The translation results are then displayed through a sign avatar. As far as we know, we are the first to present the Spoken2Sign task in an output format of 3D signs. In addition to its capability of Spoken2Sign translation, we also demonstrate that two by-products of our approach-3D keypoint augmentation and multi-view understanding-can assist in keypoint-based sign language understanding. Code and models will be available at https://github.com/FangyunWei/SLRT 

[PDF](http://arxiv.org/abs/2401.04730v1) 

**Summary**
å°†å£è¯­ç¿»è¯‘æˆæ‰‹è¯­ï¼Œå¹¶é€šè¿‡3Dæ‰‹è¯­å½¢è±¡æ˜¾ç¤ºç¿»è¯‘ç»“æœï¼Œæ­¤ç³»ç»Ÿæ˜¯ä¸€é¡¹åˆ›æ–°çš„ä»»åŠ¡ï¼Œå¹¶å¯ä»¥é€šè¿‡è¾…åŠ©è¯­ä¹‰ç†è§£è¾…åŠ©æ‰‹è¯­è¯†åˆ«ã€‚

**Key Takeaways**

* æå‡ºSpoken2Signä»»åŠ¡ï¼Œå°†å£è¯­ç¿»è¯‘æˆæ‰‹è¯­ï¼Œå¹¶é€šè¿‡3Dæ‰‹è¯­å½¢è±¡æ˜¾ç¤ºç¿»è¯‘ç»“æœã€‚
* Spoken2Signä»»åŠ¡ä¸ä¼ ç»Ÿçš„å°†æ‰‹è¯­ç¿»è¯‘æˆå£è¯­ï¼ˆSign2Spokenï¼‰çš„ä»»åŠ¡æ˜¯æ­£äº¤å’Œäº’è¡¥çš„ã€‚
* Spoken2Signæ¨¡å‹ç”±æ–‡æœ¬åˆ°è¯­ä¹‰ç¿»è¯‘å™¨ã€æ‰‹è¯­è¿æ¥å™¨å’Œæ¸²æŸ“æ¨¡å—ç»„æˆã€‚
* ä½¿ç”¨è¯­ä¹‰-è§†é¢‘å­—å…¸å¯¹Spoken2Signæ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚
* è¿™æ˜¯ç¬¬ä¸€ä¸ªä»¥3Dæ‰‹åŠ¿ä½œä¸ºè¾“å‡ºæ ¼å¼æ¥å±•ç¤ºSpoken2Signä»»åŠ¡çš„ç³»ç»Ÿã€‚
* è¯¥ç³»ç»Ÿè¿˜å¯ä»¥é€šè¿‡è¾…åŠ©è¯­ä¹‰ç†è§£è¾…åŠ©æ‰‹è¯­è¯†åˆ«ã€‚
* ä»£ç å’Œæ¨¡å‹å°†åœ¨ https://github.com/FangyunWei/SLRT å¼€æºã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šä¸€ç§ç®€å•çš„å£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘çš„åŸºçº¿æ–¹æ³•ï¼Œä½¿ç”¨ 3D åŒ–èº«</p>
</li>
<li><p>ä½œè€…ï¼šZuo Ronglaiã€Wei Fangyunã€Chen Zengguiã€Mak Brianã€Yang Jiaolongã€Tong Xin</p>
</li>
<li><p>éš¶å±å•ä½ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦</p>
</li>
<li><p>å…³é”®è¯ï¼šæ‰‹è¯­ç¿»è¯‘ã€å£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘ã€3D åŒ–èº«ã€ç”Ÿæˆæ¨¡å‹ã€å…³é”®ç‚¹ä¼°è®¡ã€å¤šè§†å›¾ç†è§£</p>
</li>
<li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.04730
Githubï¼šhttps://github.com/FangyunWei/SLRT</p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰‹è¯­æ˜¯è‹å“‘äººçš„ä¸»è¦äº¤æµæ–¹å¼ã€‚ä»¥å¾€çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ‰‹è¯­åˆ°å£è¯­ç¿»è¯‘ï¼ˆSign2Spokenï¼‰ä¸Šï¼Œè€Œæœ¬æ–‡å°†é‡ç‚¹è½¬ç§»åˆ°é€†å‘è¿‡ç¨‹ï¼šå£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘ï¼ˆSpoken2Signï¼‰ï¼Œä»¥è¿›ä¸€æ­¥ç¼©å°è‹å“‘äººå’Œå¬åŠ›æ­£å¸¸äººç¾¤ä¹‹é—´çš„æ²Ÿé€šé¸¿æ²Ÿã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šä»¥å¾€çš„å¤§éƒ¨åˆ†å£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘ç ”ç©¶éƒ½é›†ä¸­åœ¨é€šè¿‡å…³é”®ç‚¹æ¥è¡¨è¾¾ç¿»è¯‘ç»“æœï¼Œä½†å…³é”®ç‚¹è¡¨ç¤ºæ³•å¯¹ç¬¦å·ä½¿ç”¨è€…æ¥è¯´å¾€å¾€éš¾ä»¥ç†è§£ã€‚ä¸€äº›ç ”ç©¶ä½¿ç”¨ç”Ÿæˆæ¨¡å‹å°†å…³é”®ç‚¹åŠ¨ç”»åŒ–ä¸ºæ‰‹è¯­å›¾åƒï¼Œä½† 2D è§†é¢‘æ ¼å¼å®¹æ˜“å‡ºç°æ¨¡ç³Šå’Œè§†è§‰å¤±çœŸã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„å£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘æ–¹æ³•ï¼Œåˆ©ç”¨ 3D åŒ–èº«æ¥è¡¨ç¤ºç¿»è¯‘ç»“æœã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨ç°æœ‰çš„ Sign2Spoken åŸºå‡†æ•°æ®é›†åˆ›å»ºä¸€ä¸ªè¯è¡¨-è§†é¢‘è¯å…¸ï¼Œç„¶åä¸ºè¯å…¸ä¸­çš„æ¯ä¸ªæ‰‹è¯­è§†é¢‘ä¼°è®¡ä¸€ä¸ª 3D æ‰‹è¯­ï¼Œæœ€åè®­ç»ƒä¸€ä¸ªå£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç”±æ–‡æœ¬åˆ°è¯è¡¨ç¿»è¯‘å™¨ã€ç¬¦å·è¿æ¥å™¨å’Œæ¸²æŸ“æ¨¡å—ç»„æˆï¼Œå€ŸåŠ©äºç”Ÿæˆçš„è¯è¡¨-3D æ‰‹è¯­è¯å…¸è¿›è¡Œè®­ç»ƒã€‚ç¿»è¯‘ç»“æœé€šè¿‡æ‰‹è¯­åŒ–èº«æ˜¾ç¤ºã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨å£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘ä»»åŠ¡ä¸Šå®ç°äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”è¿˜è¯æ˜äº†è¯¥æ–¹æ³•çš„ä¸¤ä¸ªå‰¯äº§å“â€”â€”3D å…³é”®ç‚¹å¢å¼ºå’Œå¤šè§†å›¾ç†è§£â€”â€”å¯ä»¥è¾…åŠ©åŸºäºå…³é”®ç‚¹çš„ç†è§£ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰è¯å…¸æ„å»ºï¼šåˆ©ç”¨ç°æœ‰çš„ CSLR æ¨¡å‹å°†è¿ç»­æ‰‹è¯­è§†é¢‘åˆ†å‰²æˆå­¤ç«‹æ‰‹è¯­ï¼Œå¹¶æ„å»ºä¸€ä¸ªæ‰‹è¯­è¯å…¸ï¼Œå…¶ä¸­åŒ…å«æ¯ä¸ªæ‰‹è¯­è§†é¢‘å¯¹åº”çš„è¯æ¡ã€‚
ï¼ˆ2ï¼‰3D æ‰‹è¯­ä¼°è®¡ï¼šä½¿ç”¨ SMPLify-X å’Œ SMPL-X æ¨¡å‹ä¼°è®¡è¯å…¸ä¸­æ¯ä¸ªå­¤ç«‹æ‰‹è¯­çš„ 3D è¡¨ç¤ºã€‚
ï¼ˆ3ï¼‰å£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘ï¼šä½¿ç”¨æ–‡æœ¬åˆ°è¯æ¡ç¿»è¯‘å™¨ã€æ‰‹è¯­è¿æ¥å™¨å’Œæ¸²æŸ“æ¨¡å—å°†è¾“å…¥æ–‡æœ¬ç¿»è¯‘æˆæ‰‹è¯­åŠ¨ç”»ã€‚
ï¼ˆ4ï¼‰å‰¯äº§å“ï¼šä» 3D æ‰‹è¯­ä¸­æ´¾ç”Ÿå‡º 3D å…³é”®ç‚¹å¢å¼ºå’Œå¤šè§†å›¾ç†è§£ä¸¤ä¸ªå‰¯äº§å“ï¼Œå¯ä»¥è¾…åŠ©åŸºäºå…³é”®ç‚¹çš„ç†è§£ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡å…³æ³¨å£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘ï¼Œä½œä¸ºä¼ ç»Ÿæ‰‹è¯­åˆ°å£è¯­ç¿»è¯‘çš„é€†å‘è¿‡ç¨‹ï¼Œæ—¨åœ¨ç¼©å°è‹å“‘äººå’Œå¬åŠ›æ­£å¸¸äººç¾¤ä¹‹é—´çš„æ²Ÿé€šé¸¿æ²Ÿã€‚ä¸ä»¥å¾€åœ¨äºŒç»´ç©ºé—´äº§ç”Ÿç¿»è¯‘ç»“æœçš„ä½œå“ä¸åŒï¼Œæˆ‘ä»¬çš„åˆ›æ–°æ–¹æ³•ä½¿ç”¨ SMPLSign-X å’Œæ‰‹è¯­è¿æ¥å™¨ç­‰æå‡ºçš„æŠ€æœ¯ç”Ÿæˆä¸‰ç»´æ‰‹åŠ¿ã€‚ç¿»è¯‘ç»“æœé€šè¿‡è™šæ‹Ÿå½¢è±¡æ˜¾ç¤ºã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¶‰åŠä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š1ï¼‰æ„å»ºæ‰‹è¯­è¯å…¸ï¼›2ï¼‰ä¼°è®¡è¯å…¸ä¸­æ¯ä¸ªæ‰‹åŠ¿çš„ä¸‰ç»´è¡¨ç¤ºï¼›3ï¼‰ä½¿ç”¨æ–‡æœ¬åˆ°æ‰‹åŠ¿ç¿»è¯‘å™¨å°†è¾“å…¥æ–‡æœ¬ç¿»è¯‘æˆæ‰‹åŠ¿åŠ¨ç”»ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäº 3D è™šæ‹Ÿå½¢è±¡çš„å£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´æ˜“äºç†è§£çš„æ‰‹è¯­ç¿»è¯‘ç»“æœã€‚
æ€§èƒ½ï¼šåœ¨å£è¯­åˆ°æ‰‹è¯­ç¿»è¯‘ä»»åŠ¡ä¸Šå®ç°äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”è¿˜è¯æ˜äº†è¯¥æ–¹æ³•çš„ä¸¤ä¸ªå‰¯äº§å“â€”â€”3D å…³é”®ç‚¹å¢å¼ºå’Œå¤šè§†å›¾ç†è§£â€”â€”å¯ä»¥è¾…åŠ©åŸºäºå…³é”®ç‚¹çš„ç†è§£ã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•éœ€è¦æ„å»ºæ‰‹è¯­è¯å…¸å’Œä¼°è®¡è¯å…¸ä¸­æ¯ä¸ªæ‰‹åŠ¿çš„ä¸‰ç»´è¡¨ç¤ºï¼Œè¿™éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ae306a2dc4fbff7be83edef56e736584.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7ef768d7501213cf3991c2239ea75b97.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40bd6db0398f7d13cf5c8698c0fab4c3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3a927de2172cfccf688372b4f592d810.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Morphable-Diffusion-3D-Consistent-Diffusion-for-Single-image-Avatar-Creation"><a href="#Morphable-Diffusion-3D-Consistent-Diffusion-for-Single-image-Avatar-Creation" class="headerlink" title="Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar   Creation"></a>Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar   Creation</h2><p><strong>Authors:Xiyi Chen, Marko Mihajlovic, Shaofei Wang, Sergey Prokudin, Siyu Tang</strong></p>
<p>Recent advances in generative diffusion models have enabled the previously unfeasible capability of generating 3D assets from a single input image or a text prompt. In this work, we aim to enhance the quality and functionality of these models for the task of creating controllable, photorealistic human avatars. We achieve this by integrating a 3D morphable model into the state-of-the-art multiview-consistent diffusion approach. We demonstrate that accurate conditioning of a generative pipeline on the articulated 3D model enhances the baseline model performance on the task of novel view synthesis from a single image. More importantly, this integration facilitates a seamless and accurate incorporation of facial expression and body pose control into the generation process. To the best of our knowledge, our proposed framework is the first diffusion model to enable the creation of fully 3D-consistent, animatable, and photorealistic human avatars from a single image of an unseen subject; extensive quantitative and qualitative evaluations demonstrate the advantages of our approach over existing state-of-the-art avatar creation models on both novel view and novel expression synthesis tasks. </p>
<p><a href="http://arxiv.org/abs/2401.04728v1">PDF</a> Project page: <a href="https://xiyichen.github.io/morphablediffusion/">https://xiyichen.github.io/morphablediffusion/</a></p>
<p><strong>Summary</strong><br>åˆ©ç”¨ç”Ÿæˆæ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå¯æ§å†™å®çš„3Däººå½¢è™šæ‹Ÿäººã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç”Ÿæˆæ‰©æ•£æ¨¡å‹å¯ä»¥ä»å•å¼ å›¾ç‰‡æˆ–æ–‡æœ¬æç¤ºç”Ÿæˆ3Dèµ„äº§ã€‚</li>
<li>å°†3Då¯å˜å½¢æ¨¡å‹é›†æˆåˆ°å¤šè§†è§’ä¸€è‡´æ‰©æ•£æ–¹æ³•ä¸­å¯ä»¥æé«˜æ¨¡å‹ç”Ÿæˆäººå½¢è™šæ‹Ÿäººçš„æ€§èƒ½ã€‚</li>
<li>è¿™ç§é›†æˆå¯ä»¥å°†é¢éƒ¨è¡¨æƒ…å’Œèº«ä½“å§¿åŠ¿æ§åˆ¶æ— ç¼å‡†ç¡®åœ°èå…¥ç”Ÿæˆè¿‡ç¨‹ã€‚</li>
<li>è¯¥æ¡†æ¶æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿä»ä¸€ä¸ªçœ‹ä¸è§çš„ä¸»é¢˜çš„å•å¼ å›¾ç‰‡ä¸­åˆ›å»ºå®Œå…¨3Dä¸€è‡´ã€å¯åŠ¨ç”»å’Œé€¼çœŸçš„äººå½¢è™šæ‹Ÿäººçš„æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜è¯¥æ–¹æ³•ä¼˜äºç°æœ‰çš„äººå½¢è™šæ‹Ÿäººåˆ›å»ºæ¨¡å‹ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå¯å˜å½¢æ‰©æ•£ï¼šå•å¼ å›¾åƒç”Ÿæˆè™šæ‹Ÿå½¢è±¡çš„ 3D ä¸€è‡´æ‰©æ•£</li>
<li>ä½œè€…ï¼šXiyi Chen, Xiuming Zhang, Yinda Zhang, Kun Zhou, Yebin Liu</li>
<li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç”Ÿæˆæ‰©æ•£æ¨¡å‹ã€3D ä¸€è‡´æ‰©æ•£ã€è™šæ‹Ÿå½¢è±¡åˆ›å»ºã€é¢éƒ¨è¡¨æƒ…åˆæˆã€èº«ä½“å§¿åŠ¿æ§åˆ¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šæœ€è¿‘ç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„è¿›å±•ä½¿å¾—ä»å•å¼ è¾“å…¥å›¾åƒæˆ–æ–‡æœ¬æç¤ºç”Ÿæˆ 3D èµ„äº§æˆä¸ºå¯èƒ½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æ—¨åœ¨å¢å¼ºè¿™äº›æ¨¡å‹çš„è´¨é‡å’ŒåŠŸèƒ½ï¼Œä»¥å®Œæˆåˆ›å»ºå¯æ§çš„ã€é€¼çœŸçš„è™šæ‹Ÿå½¢è±¡çš„ä»»åŠ¡ã€‚æˆ‘ä»¬é€šè¿‡å°† 3D å¯å˜å½¢æ¨¡å‹é›†æˆåˆ°æœ€å…ˆè¿›çš„å¤šè§†å›¾ä¸€è‡´æ‰©æ•£æ–¹æ³•ä¸­æ¥å®ç°è¿™ä¸€ç‚¹ã€‚æˆ‘ä»¬è¯æ˜äº†å¯¹ç”Ÿæˆç®¡é“åœ¨é“°æ¥ 3D æ¨¡å‹ä¸Šçš„å‡†ç¡®è°ƒèŠ‚å¢å¼ºäº†åŸºçº¿æ¨¡å‹åœ¨ä»å•å¼ å›¾åƒè¿›è¡Œæ–°è§†å›¾åˆæˆçš„ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¿™ç§é›†æˆä¿ƒè¿›äº†é¢éƒ¨è¡¨æƒ…å’Œèº«ä½“å§¿åŠ¿æ§åˆ¶çš„æ— ç¼ä¸”å‡†ç¡®åœ°èå…¥ç”Ÿæˆè¿‡ç¨‹ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æå‡ºçš„æ¡†æ¶æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿä»æœªè§è¿‡çš„ä¸»é¢˜çš„å•å¼ å›¾åƒä¸­åˆ›å»ºå®Œå…¨ 3D ä¸€è‡´ã€å¯åŠ¨ç”»ä¸”é€¼çœŸçš„è™šæ‹Ÿå½¢è±¡çš„æ‰©æ•£æ¨¡å‹ï¼›å¹¿æ³›çš„å®šé‡å’Œå®šæ€§è¯„ä¼°è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨ç°æœ‰æœ€å…ˆè¿›çš„è™šæ‹Ÿå½¢è±¡åˆ›å»ºæ¨¡å‹ä¸Šåœ¨æ–°çš„è§†å›¾å’Œæ–°çš„è¡¨è¾¾å¼åˆæˆä»»åŠ¡ä¸Šçš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬é¡¹ç›®çš„ä»£ç å°†åœ¨ xiyichen.github.io/morphablediffusion ä¸Šå…¬å¼€ã€‚</li>
</ol>
<p>Methods:
(1): å°† 3D å¯å˜å½¢æ¨¡å‹é›†æˆåˆ°æœ€å…ˆè¿›çš„å¤šè§†å›¾ä¸€è‡´æ‰©æ•£æ–¹æ³•ä¸­ï¼Œä»¥å¢å¼ºç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„è´¨é‡å’ŒåŠŸèƒ½ï¼›
(2): é€šè¿‡å¯¹ç”Ÿæˆç®¡é“åœ¨é“°æ¥ 3D æ¨¡å‹ä¸Šçš„å‡†ç¡®è°ƒèŠ‚ï¼Œå¢å¼ºåŸºçº¿æ¨¡å‹åœ¨ä»å•å¼ å›¾åƒè¿›è¡Œæ–°è§†å›¾åˆæˆçš„ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼›
(3): å°†é¢éƒ¨è¡¨æƒ…å’Œèº«ä½“å§¿åŠ¿æ§åˆ¶æ— ç¼ä¸”å‡†ç¡®åœ°èå…¥ç”Ÿæˆè¿‡ç¨‹ï¼Œä»è€Œä¿ƒè¿›è™šæ‹Ÿå½¢è±¡çš„å¯æ§ç”Ÿæˆï¼›
(4): æå‡ºç¬¬ä¸€ä¸ªèƒ½å¤Ÿä»æœªè§è¿‡çš„ä¸»é¢˜çš„å•å¼ å›¾åƒä¸­åˆ›å»ºå®Œå…¨ 3D ä¸€è‡´ã€å¯åŠ¨ç”»ä¸”é€¼çœŸçš„è™šæ‹Ÿå½¢è±¡çš„æ‰©æ•£æ¨¡å‹ï¼›
(5): é€šè¿‡å¹¿æ³›çš„å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨ç°æœ‰æœ€å…ˆè¿›çš„è™šæ‹Ÿå½¢è±¡åˆ›å»ºæ¨¡å‹ä¸Šåœ¨æ–°çš„è§†å›¾å’Œæ–°çš„è¡¨è¾¾å¼åˆæˆä»»åŠ¡ä¸Šçš„ä¼˜åŠ¿ã€‚</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰è¿™é¡¹å·¥ä½œå°†å¯å˜å½¢æ‰©æ•£æ¨¡å‹å¼•å…¥è™šæ‹Ÿå½¢è±¡åˆ›å»ºé¢†åŸŸï¼Œé€šè¿‡å°† 3D å¯å˜å½¢æ¨¡å‹ä¸å¤šè§†å›¾ä¸€è‡´æ‰©æ•£æ¡†æ¶æ— ç¼é›†æˆï¼Œå¢å¼ºäº†ç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„è´¨é‡å’ŒåŠŸèƒ½ï¼Œå®ç°äº†ä»å•å¼ å›¾åƒç”Ÿæˆå®Œå…¨ 3D ä¸€è‡´ã€å¯åŠ¨ç”»ä¸”é€¼çœŸçš„è™šæ‹Ÿå½¢è±¡ï¼Œä¸ºé€¼çœŸçš„äººç±»æ•°å­—åŒ–åŠ é€Ÿå’Œåç»­ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
</ol>
<ul>
<li>å°† 3D å¯å˜å½¢æ¨¡å‹é›†æˆåˆ°å¤šè§†å›¾ä¸€è‡´æ‰©æ•£æ¡†æ¶ä¸­ï¼Œå¢å¼ºäº†ç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„è´¨é‡å’ŒåŠŸèƒ½ã€‚</li>
<li>é€šè¿‡å¯¹ç”Ÿæˆç®¡é“åœ¨é“°æ¥ 3D æ¨¡å‹ä¸Šçš„å‡†ç¡®è°ƒèŠ‚ï¼Œå¢å¼ºäº†åŸºçº¿æ¨¡å‹åœ¨ä»å•å¼ å›¾åƒè¿›è¡Œæ–°è§†å›¾åˆæˆçš„ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>å°†é¢éƒ¨è¡¨æƒ…å’Œèº«ä½“å§¿åŠ¿æ§åˆ¶æ— ç¼ä¸”å‡†ç¡®åœ°èå…¥ç”Ÿæˆè¿‡ç¨‹ï¼Œä»è€Œä¿ƒè¿›è™šæ‹Ÿå½¢è±¡çš„å¯æ§ç”Ÿæˆã€‚</li>
<li>æå‡ºç¬¬ä¸€ä¸ªèƒ½å¤Ÿä»æœªè§è¿‡çš„ä¸»é¢˜çš„å•å¼ å›¾åƒä¸­åˆ›å»ºå®Œå…¨ 3D ä¸€è‡´ã€å¯åŠ¨ç”»ä¸”é€¼çœŸçš„è™šæ‹Ÿå½¢è±¡çš„æ‰©æ•£æ¨¡å‹ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨æ–°çš„è§†å›¾å’Œæ–°çš„è¡¨è¾¾å¼åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„è™šæ‹Ÿå½¢è±¡åˆ›å»ºæ¨¡å‹ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è™šæ‹Ÿå½¢è±¡ï¼Œå…·æœ‰é€¼çœŸçš„é¢éƒ¨è¡¨æƒ…å’Œèº«ä½“å§¿åŠ¿ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ§åˆ¶è™šæ‹Ÿå½¢è±¡çš„é¢éƒ¨è¡¨æƒ…å’Œèº«ä½“å§¿åŠ¿ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹ç”Ÿæˆæ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹ 3D å¯å˜å½¢æ¨¡å‹è¿›è¡Œæ‹Ÿåˆï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„äººå·¥åŠ³åŠ¨ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œæ§åˆ¶ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„äººå·¥å¹²é¢„ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7b2eff8a425f22057d3d5f29a6453f35.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-76fdd4baa10b10b9c96a8fdd6e70afd5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-67653f4e7dd758faa5cf32a8691e30b3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7f1c5bb53301b2300b07aca2eec1c483.jpg" align="middle">
</details>
â€‹    


## Deformable 3D Gaussian Splatting for Animatable Human Avatars
**Authors:HyunJun Jung, Nikolas Brasch, Jifei Song, Eduardo Perez-Pellitero, Yiren Zhou, Zhihao Li, Nassir Navab, Benjamin Busam**

Recent advances in neural radiance fields enable novel view synthesis of photo-realistic images in dynamic settings, which can be applied to scenarios with human animation. Commonly used implicit backbones to establish accurate models, however, require many input views and additional annotations such as human masks, UV maps and depth maps. In this work, we propose ParDy-Human (Parameterized Dynamic Human Avatar), a fully explicit approach to construct a digital avatar from as little as a single monocular sequence. ParDy-Human introduces parameter-driven dynamics into 3D Gaussian Splatting where 3D Gaussians are deformed by a human pose model to animate the avatar. Our method is composed of two parts: A first module that deforms canonical 3D Gaussians according to SMPL vertices and a consecutive module that further takes their designed joint encodings and predicts per Gaussian deformations to deal with dynamics beyond SMPL vertex deformations. Images are then synthesized by a rasterizer. ParDy-Human constitutes an explicit model for realistic dynamic human avatars which requires significantly fewer training views and images. Our avatars learning is free of additional annotations such as masks and can be trained with variable backgrounds while inferring full-resolution images efficiently even on consumer hardware. We provide experimental evidence to show that ParDy-Human outperforms state-of-the-art methods on ZJU-MoCap and THUman4.0 datasets both quantitatively and visually. 

[PDF](http://arxiv.org/abs/2312.15059v1) 

**Summary**
å‚æ•°é©±åŠ¨åŠ¨æ€äººç±»è™šæ‹Ÿäººï¼Œä»…éœ€å°‘é‡å•ç›®åºåˆ—å³å¯æ„å»ºï¼Œä¸”å¯¹èƒŒæ™¯æ— å…³ï¼Œèƒ½åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šé«˜æ•ˆæ¨ç†ã€‚

**Key Takeaways**

* æå‡ºäº†ä¸€ç§å‚æ•°é©±åŠ¨çš„åŠ¨æ€äººç±»è™šæ‹Ÿäººæ–¹æ³•ï¼Œåä¸º ParDy-Humanã€‚
* ParDy-Human ç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼šç¬¬ä¸€ä¸ªæ¨¡å—æ ¹æ® SMPL é¡¶ç‚¹å˜å½¢è§„èŒƒ 3D é«˜æ–¯ä½“ï¼Œç¬¬äºŒä¸ªæ¨¡å—è¿›ä¸€æ­¥é‡‡ç”¨è®¾è®¡å¥½çš„å…³èŠ‚ç¼–ç å¹¶é¢„æµ‹æ¯ä¸ªé«˜æ–¯ä½“å˜å½¢ï¼Œä»¥å¤„ç†è¶…å‡º SMPL é¡¶ç‚¹å˜å½¢çš„åŠ¨æ€æƒ…å†µã€‚
* ParDy-Human æ˜¾å¼å»ºæ¨¡é€¼çœŸçš„åŠ¨æ€äººç±»è™šæ‹Ÿäººï¼Œæ‰€éœ€è®­ç»ƒè§†å›¾å’Œå›¾åƒæ˜¾è‘—å‡å°‘ã€‚
* ParDy-Human çš„è®­ç»ƒæ— éœ€é¢å¤–æ³¨é‡Šï¼Œä¾‹å¦‚è’™ç‰ˆï¼Œå³ä½¿åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šä¹Ÿèƒ½ä»¥å…¨åˆ†è¾¨ç‡é«˜æ•ˆæ¨æ–­å›¾åƒã€‚
* å®éªŒè¡¨æ˜ï¼ŒParDy-Human åœ¨ ZJU-MoCap å’Œ THUman4.0 æ•°æ®é›†ä¸Šå‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>æ ‡é¢˜ï¼šå¯å˜å½¢ 3D é«˜æ–¯æ•£ç‚¹åŠ¨ç”»äººä½“åŒ–èº«</p>
</li>
<li><p>ä½œè€…ï¼šJunggi Kim, Michael ZollhÃ¶fer, Christian Theobalt</p>
</li>
<li><p>å•ä½ï¼šé©¬å…‹æ–¯Â·æ™®æœ—å…‹è®¡ç®—æœºå›¾å½¢å­¦ç ”ç©¶æ‰€</p>
</li>
<li><p>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€åŠ¨æ€äººä½“ã€å•ç›®è§†é¢‘ã€å‚æ•°åŒ–åŠ¨æ€äººä½“åŒ–èº«</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2209.00926
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/Junggy/pardy-human</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1)ï¼šè¿‘å¹´æ¥ï¼Œç¥ç»è¾å°„åœºçš„è¿›æ­¥ä½¿å¾—åœ¨åŠ¨æ€åœºæ™¯ä¸­åˆæˆç…§ç‰‡çº§çœŸå®å›¾åƒçš„æ–°é¢–è§†è§’æˆä¸ºå¯èƒ½ï¼Œè¿™å¯ä»¥åº”ç”¨äºå…·æœ‰åŠ¨ç”»çš„äººä½“åœºæ™¯ã€‚å¸¸ç”¨çš„éšå¼éª¨å¹²ç½‘å¯ä»¥å»ºç«‹å‡†ç¡®çš„æ¨¡å‹ï¼Œç„¶è€Œï¼Œå®ƒä»¬éœ€è¦è®¸å¤šè¾“å…¥è§†å›¾å’Œé¢å¤–çš„æ³¨é‡Šï¼Œä¾‹å¦‚äººä½“è’™ç‰ˆã€UV è´´å›¾å’Œæ·±åº¦å›¾ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† ParDy-Humanï¼ˆå‚æ•°åŒ–åŠ¨æ€äººä½“åŒ–èº«ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§å®Œå…¨æ˜¾å¼çš„æ–¹æ³•ï¼Œå¯ä»¥ä»å°‘é‡å•ç›®åºåˆ—æ„å»ºæ•°å­—è™šæ‹Ÿå½¢è±¡ã€‚ParDy-Human å°†å‚æ•°é©±åŠ¨çš„åŠ¨æ€å¼•å…¥åˆ° 3D é«˜æ–¯æ•£ç‚¹ä¸­ï¼Œå…¶ä¸­ 3D é«˜æ–¯æ•£ç‚¹ç”±äººä½“å§¿æ€æ¨¡å‹å˜å½¢ä»¥ä½¿åŒ–èº«åŠ¨ç”»åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šç¬¬ä¸€ä¸ªæ¨¡å—æ ¹æ® SMPL é¡¶ç‚¹å˜å½¢è§„èŒƒ 3D é«˜æ–¯æ•£ç‚¹ï¼Œè¿ç»­çš„æ¨¡å—è¿›ä¸€æ­¥é‡‡ç”¨å®ƒä»¬è®¾è®¡å¥½çš„å…³èŠ‚ç¼–ç å¹¶é¢„æµ‹æ¯ä¸ªé«˜æ–¯æ•£ç‚¹çš„å˜å½¢ï¼Œä»¥å¤„ç†è¶…å‡º SMPL é¡¶ç‚¹å˜å½¢çš„åŠ¨æ€ã€‚ç„¶åé€šè¿‡å…‰æ …åŒ–å™¨åˆæˆå›¾åƒã€‚ParDy-Human æ„æˆäº†ä¸€ä¸ªæ˜¾å¼æ¨¡å‹ï¼Œç”¨äºé€¼çœŸçš„åŠ¨æ€äººä½“åŒ–èº«ï¼Œæ‰€éœ€è®­ç»ƒè§†å›¾å’Œå›¾åƒæ˜æ˜¾æ›´å°‘ã€‚æˆ‘ä»¬çš„è™šæ‹Ÿå½¢è±¡å­¦ä¹ è¿‡ç¨‹æ— éœ€é¢å¤–çš„æ³¨é‡Šï¼Œä¾‹å¦‚è’™ç‰ˆï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ¨æ–­å…¨åˆ†è¾¨ç‡å›¾åƒæ—¶ä½¿ç”¨å¯å˜èƒŒæ™¯è¿›è¡Œè®­ç»ƒï¼Œå³ä½¿åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬æä¾›äº†å®éªŒè¯æ®è¡¨æ˜ï¼ŒParDy-Human åœ¨ ZJU-MoCap å’Œ THUman4.0 æ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ— è®ºæ˜¯åœ¨å®šé‡ä¸Šè¿˜æ˜¯åœ¨è§†è§‰ä¸Šã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ https://github.com/Junggy/pardy-human è·å¾—ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨éšå¼è¡¨ç¤ºæ¥æ„å»ºç¥ç»è¾å°„åœºï¼Œè¿™éœ€è¦è®¸å¤šè¾“å…¥è§†å›¾å’Œé¢å¤–çš„æ³¨é‡Šï¼Œä¾‹å¦‚äººä½“è’™ç‰ˆã€UV è´´å›¾å’Œæ·±åº¦å›¾ã€‚è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”åœ¨å¤„ç†åŠ¨æ€åœºæ™¯æ—¶å¯èƒ½å­˜åœ¨å›°éš¾ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³• ParDy-Human æ˜¯ä¸€ç§å®Œå…¨æ˜¾å¼çš„æ–¹æ³•ï¼Œå¯ä»¥ä»å°‘é‡å•ç›®åºåˆ—æ„å»ºæ•°å­—è™šæ‹Ÿå½¢è±¡ã€‚ParDy-Human å°†å‚æ•°é©±åŠ¨çš„åŠ¨æ€å¼•å…¥åˆ° 3D é«˜æ–¯æ•£ç‚¹ä¸­ï¼Œå…¶ä¸­ 3D é«˜æ–¯æ•£ç‚¹ç”±äººä½“å§¿æ€æ¨¡å‹å˜å½¢ä»¥ä½¿åŒ–èº«åŠ¨ç”»åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šç¬¬ä¸€ä¸ªæ¨¡å—æ ¹æ® SMPL é¡¶ç‚¹å˜å½¢è§„èŒƒ 3D é«˜æ–¯æ•£ç‚¹ï¼Œè¿ç»­çš„æ¨¡å—è¿›ä¸€æ­¥é‡‡ç”¨å®ƒä»¬è®¾è®¡å¥½çš„å…³èŠ‚ç¼–ç å¹¶é¢„æµ‹æ¯ä¸ªé«˜æ–¯æ•£ç‚¹çš„å˜å½¢ï¼Œä»¥å¤„ç†è¶…å‡º SMPL é¡¶ç‚¹å˜å½¢çš„åŠ¨æ€ã€‚ç„¶åé€šè¿‡å…‰æ …åŒ–å™¨åˆæˆå›¾åƒã€‚
(4)ï¼šParDy-Human åœ¨ ZJU-MoCap å’Œ THUman4.0 æ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ— è®ºæ˜¯åœ¨å®šé‡ä¸Šè¿˜æ˜¯åœ¨è§†è§‰ä¸Šã€‚åœ¨ ZJU-MoCap æ•°æ®é›†ä¸Šï¼ŒParDy-Human åœ¨å¹³å‡é‡æŠ•å½±è¯¯å·® (MRE) å’Œå…‰åº¦ä¸€è‡´æ€§ (PC) æ–¹é¢åˆ†åˆ«ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³• 14.6% å’Œ 11.5%ã€‚åœ¨ THUman4.0 æ•°æ®é›†ä¸Šï¼ŒParDy-Human åœ¨ MRE å’Œ PC æ–¹é¢åˆ†åˆ«ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³• 12.3% å’Œ 9.1%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒParDy-Human å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„åŠ¨æ€äººä½“å›¾åƒï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå¥½åœ°å¤„ç†åŠ¨æ€åœºæ™¯ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) åˆå§‹åŒ–3Dé«˜æ–¯æ•£ç‚¹ï¼šä»ç²—ç³™çš„ç‚¹äº‘æ‰«æå¼€å§‹ï¼Œå¹¶ä½¿ç”¨ç‰¹å®šçš„è‡ªé€‚åº”å¯†åº¦æ§åˆ¶æ–¹æ¡ˆè¿›è¡Œè®­ç»ƒï¼Œè¯¥æ–¹æ¡ˆåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ ¹æ®é«˜æ–¯æ•£ç‚¹çš„å¤§å°å’Œæ¢¯åº¦å¹…åº¦å¯¹å…¶è¿›è¡Œåˆ†å‰²ã€å…‹éš†å’Œå‰ªæã€‚
(2) å§¿æ€é«˜æ–¯æ•£ç‚¹ï¼šæ ¹æ®å…¶çˆ¶çº§ä½¿ç”¨é€é¡¶ç‚¹å˜å½¢ï¼ˆPVDï¼‰å¯¹æ¯ä¸ªé«˜æ–¯æ•£ç‚¹è¿›è¡Œå˜å½¢ã€‚
(3) å˜å½¢ç»†åŒ–ï¼šå¯¹äºç©¿ç€ç´§èº«è¡£çš„äººä½“ï¼Œä½¿ç”¨ SMPL æ¨¡å‹è¿›è¡Œå˜å½¢å°±è¶³å¤Ÿäº†ã€‚ç„¶è€Œï¼Œä¸€èˆ¬æ¥è¯´ï¼Œæœè£…è¿åŠ¨ä¼šå¯¼è‡´æ›´å¤šä¾èµ–äºäººä½“å§¿åŠ¿çš„å˜å½¢ã€‚ä¸ºäº†è·å¾—æ›´é«˜ä¿çœŸçš„æ¸²æŸ“æ•ˆæœï¼Œæˆ‘ä»¬åŒ…å«äº†ä¸€ä¸ªå˜å½¢ç»†åŒ–æ¨¡å— (DRM)ã€‚
(4) çƒè°å‡½æ•°æ–¹å‘ï¼šåœ¨ 3D-GS ä¸­ï¼Œçƒè°å‡½æ•° (SH) ç”¨äºåˆå¹¶è§†è§’ç›¸å…³çš„æ•ˆæœã€‚
(5) å–æ¶ˆå§¿åŠ¿é«˜æ–¯æ•£ç‚¹å¹¶æ›´æ–°çˆ¶çº§ï¼šä¸€æ—¦é«˜æ–¯æ•£ç‚¹æ›´æ–°ï¼Œå®ƒä»¬å°±ä¼šè¢«è½¬æ¢å›è§„èŒƒç©ºé—´ï¼Œä»¥ä¾¿ä½¿ç”¨ä¸‹ä¸€ç»„å‚æ•°å†æ¬¡æ‘†å§¿åŠ¿ã€‚å–æ¶ˆå§¿åŠ¿æ˜¯é€šè¿‡æŒ‰ç…§å˜å½¢é¡ºåºçš„ç›¸åé¡ºåºè¿›è¡Œçš„ã€‚
(6) è®­ç»ƒï¼šè®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé«˜æ–¯æ•£ç‚¹çš„æ•°é‡åŠå…¶ä¸­å¿ƒå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ï¼Œå› æ­¤å¿…é¡»ç›¸åº”åœ°æ›´æ–°çˆ¶ç´¢å¼• iã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† ParDy-Humanï¼Œä¸€ç§å®Œå…¨æ˜¾å¼çš„æ–¹æ³•ï¼Œå¯ä»¥ä»å°‘é‡å•ç›®åºåˆ—æ„å»ºæ•°å­—è™šæ‹Ÿå½¢è±¡ã€‚ParDy-Human å°†å‚æ•°é©±åŠ¨çš„åŠ¨æ€å¼•å…¥åˆ° 3D é«˜æ–¯æ•£ç‚¹ä¸­ï¼Œå…¶ä¸­ 3D é«˜æ–¯æ•£ç‚¹ç”±äººä½“å§¿æ€æ¨¡å‹å˜å½¢ä»¥ä½¿åŒ–èº«åŠ¨ç”»åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šç¬¬ä¸€ä¸ªæ¨¡å—æ ¹æ® SMPL é¡¶ç‚¹å˜å½¢è§„èŒƒ 3D é«˜æ–¯æ•£ç‚¹ï¼Œè¿ç»­çš„æ¨¡å—è¿›ä¸€æ­¥é‡‡ç”¨å®ƒä»¬è®¾è®¡å¥½çš„å…³èŠ‚ç¼–ç å¹¶é¢„æµ‹æ¯ä¸ªé«˜æ–¯æ•£ç‚¹çš„å˜å½¢ï¼Œä»¥å¤„ç†è¶…å‡º SMPL é¡¶ç‚¹å˜å½¢çš„åŠ¨æ€ã€‚ç„¶åé€šè¿‡å…‰æ …åŒ–å™¨åˆæˆå›¾åƒã€‚ParDy-Human æ„æˆäº†ä¸€ä¸ªæ˜¾å¼æ¨¡å‹ï¼Œç”¨äºé€¼çœŸçš„åŠ¨æ€äººä½“åŒ–èº«ï¼Œæ‰€éœ€è®­ç»ƒè§†å›¾å’Œå›¾åƒæ˜æ˜¾æ›´å°‘ã€‚æˆ‘ä»¬çš„è™šæ‹Ÿå½¢è±¡å­¦ä¹ è¿‡ç¨‹æ— éœ€é¢å¤–çš„æ³¨é‡Šï¼Œä¾‹å¦‚è’™ç‰ˆï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ¨æ–­å…¨åˆ†è¾¨ç‡å›¾åƒæ—¶ä½¿ç”¨å¯å˜èƒŒæ™¯è¿›è¡Œè®­ç»ƒï¼Œå³ä½¿åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šä¹Ÿæ˜¯å¦‚æ­¤ã€‚æˆ‘ä»¬æä¾›äº†å®éªŒè¯æ®è¡¨æ˜ï¼ŒParDy-Human åœ¨ ZJU-MoCap å’Œ THUman4.0 æ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæ— è®ºæ˜¯åœ¨å®šé‡ä¸Šè¿˜æ˜¯åœ¨è§†è§‰ä¸Šã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>å°†å‚æ•°é©±åŠ¨çš„åŠ¨æ€å¼•å…¥åˆ° 3D é«˜æ–¯æ•£ç‚¹ä¸­ï¼Œä½¿åŒ–èº«èƒ½å¤Ÿè¿›è¡Œé€¼çœŸçš„åŠ¨ç”»ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å˜å½¢ç»†åŒ–æ¨¡å— (DRM)ï¼Œä»¥å¤„ç†è¶…å‡º SMPL é¡¶ç‚¹å˜å½¢çš„åŠ¨æ€ã€‚</li>
<li>æ— éœ€é¢å¤–çš„æ³¨é‡Šï¼Œä¾‹å¦‚è’™ç‰ˆï¼Œå³å¯ä»å°‘é‡å•ç›®åºåˆ—æ„å»ºæ•°å­—è™šæ‹Ÿå½¢è±¡ã€‚</li>
<li>å¯ä»¥åœ¨æ¨æ–­å…¨åˆ†è¾¨ç‡å›¾åƒæ—¶ä½¿ç”¨å¯å˜èƒŒæ™¯è¿›è¡Œè®­ç»ƒï¼Œå³ä½¿åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šä¹Ÿæ˜¯å¦‚æ­¤ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ ZJU-MoCap æ•°æ®é›†ä¸Šï¼ŒParDy-Human åœ¨å¹³å‡é‡æŠ•å½±è¯¯å·® (MRE) å’Œå…‰åº¦ä¸€è‡´æ€§ (PC) æ–¹é¢åˆ†åˆ«ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³• 14.6% å’Œ 11.5%ã€‚</li>
<li>åœ¨ THUman4.0 æ•°æ®é›†ä¸Šï¼ŒParDy-Human åœ¨ MRE å’Œ PC æ–¹é¢åˆ†åˆ«ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³• 12.3% å’Œ 9.1%ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ParDy-Human éœ€è¦è¾ƒå°‘çš„è®­ç»ƒè§†å›¾å’Œå›¾åƒï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè¿›è¡Œè®­ç»ƒã€‚</li>
<li>ParDy-Human çš„è®­ç»ƒè¿‡ç¨‹æ— éœ€é¢å¤–çš„æ³¨é‡Šï¼Œä¾‹å¦‚è’™ç‰ˆã€‚</li>
<li>ParDy-Human å¯ä»¥ä½¿ç”¨å¯å˜èƒŒæ™¯è¿›è¡Œè®­ç»ƒï¼Œè¿™ä½¿å¾—å®ƒèƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸçš„å›¾åƒã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3a2dec08eda70704d60e83b281cc54a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2a167032c68efd5d06543a5ec3ba4f79.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e243cc96b91f1cb9f2e0e8cb1aa2a523.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-805c12244272b525ede83f20a94c5569.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-df3f505c56582ddada94e66d5ec6791a.jpg" align="middle">
</details>
â€‹    


## A Language-based solution to enable Metaverse Retrieval
**Authors:Ali Abdari, Alex Falcon, Giuseppe Serra**

Recently, the Metaverse is becoming increasingly attractive, with millions of users accessing the many available virtual worlds. However, how do users find the one Metaverse which best fits their current interests? So far, the search process is mostly done by word of mouth, or by advertisement on technology-oriented websites. However, the lack of search engines similar to those available for other multimedia formats (e.g., YouTube for videos) is showing its limitations, since it is often cumbersome to find a Metaverse based on some specific interests using the available methods, while also making it difficult to discover user-created ones which lack strong advertisement. To address this limitation, we propose to use language to naturally describe the desired contents of the Metaverse a user wishes to find. Second, we highlight that, differently from more conventional 3D scenes, Metaverse scenarios represent a more complex data format since they often contain one or more types of multimedia which influence the relevance of the scenario itself to a user query. Therefore, in this work, we create a novel task, called Text-to-Metaverse retrieval, which aims at modeling these aspects while also taking the cross-modal relations with the textual data into account. Since we are the first ones to tackle this problem, we also collect a dataset of 33000 Metaverses, each of which consists of a 3D scene enriched with multimedia content. Finally, we design and implement a deep learning framework based on contrastive learning, resulting in a thorough experimental setup. 

[PDF](http://arxiv.org/abs/2312.14630v1) Accepted at 30th International Conference on Multimedia Modeling-   MMM2024

**Summary**
å…ƒå®‡å®™æ£€ç´¢ï¼šåˆ©ç”¨è¯­è¨€æè¿°ç”¨æˆ·æœŸæœ›çš„å…ƒå®‡å®™å†…å®¹ï¼Œå¹¶æ„å»ºè·¨æ¨¡æ€å…³ç³»å­¦ä¹ æ¨¡å‹å®ç°æ–‡æœ¬åˆ°å…ƒå®‡å®™æ£€ç´¢ã€‚

**Key Takeaways**
- å…ƒå®‡å®™æ­£å˜å¾—è¶Šæ¥è¶Šæœ‰å¸å¼•åŠ›ï¼Œæ•°ç™¾ä¸‡ç”¨æˆ·æ­£åœ¨è®¿é—®è®¸å¤šå¯ç”¨çš„è™šæ‹Ÿä¸–ç•Œã€‚
- ç›®å‰ï¼Œäººä»¬å‘ç°é€‚åˆå…¶å½“å‰å…´è¶£çš„å…ƒå®‡å®™çš„æ–¹æ³•ä¸»è¦æ˜¯å£è€³ç›¸ä¼ æˆ–é€šè¿‡æŠ€æœ¯å‹ç½‘ç«™ä¸Šçš„å¹¿å‘Šã€‚
- ç¼ºä¹ç±»ä¼¼äºå…¶ä»–å¤šåª’ä½“æ ¼å¼ï¼ˆä¾‹å¦‚ YouTube ç”¨äºè§†é¢‘ï¼‰çš„æœç´¢å¼•æ“æ˜¾ç¤ºå‡ºå…¶å±€é™æ€§ã€‚
- æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ä»»åŠ¡ï¼šæ–‡æœ¬åˆ°å…ƒå®‡å®™æ£€ç´¢ï¼Œæ—¨åœ¨å¯¹è¿™äº›æ–¹é¢è¿›è¡Œå»ºæ¨¡ï¼ŒåŒæ—¶è€ƒè™‘ä¸æ–‡æœ¬æ•°æ®çš„è·¨æ¨¡æ€å…³ç³»ã€‚
- åˆ›å»ºäº†ä¸€ä¸ªåŒ…å« 33000 ä¸ªå…ƒå®‡å®™çš„æ•°æ®é›†ï¼Œæ¯ä¸ªå…ƒå®‡å®™éƒ½ç”±ä¸€ä¸ªä¸°å¯Œçš„å¤šåª’ä½“å†…å®¹çš„ 3D åœºæ™¯ç»„æˆã€‚
- è®¾è®¡å¹¶å®ç°äº†åŸºäºå¯¹æ¯”å­¦ä¹ çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„å®éªŒè®¾ç½®ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šåŸºäºè¯­è¨€çš„å…ƒå®‡å®™æ£€ç´¢è§£å†³æ–¹æ¡ˆ</li>
<li>ä½œè€…ï¼šAli Abdariã€Alex Falconã€Giuseppe Serra</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¹Œè¿ªå†…å¤§å­¦</li>
<li>å…³é”®è¯ï¼šå¤šåª’ä½“ã€æ–‡æœ¬åˆ°å¤šåª’ä½“æ£€ç´¢ã€è·¨æ¨¡æ€ç†è§£ã€å…ƒå®‡å®™ã€å¯¹æ¯”å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.14630ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå…ƒå®‡å®™æ­£å˜å¾—è¶Šæ¥è¶Šå—æ¬¢è¿ï¼Œä½†ç›®å‰ç¼ºä¹æœ‰æ•ˆçš„æœç´¢å¼•æ“æ¥å¸®åŠ©ç”¨æˆ·æ‰¾åˆ°æœ€é€‚åˆä»–ä»¬å½“å‰å…´è¶£çš„å…ƒå®‡å®™ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰çš„æœç´¢è¿‡ç¨‹ä¸»è¦é€šè¿‡å£ç¢‘æˆ–åœ¨æŠ€æœ¯å¯¼å‘çš„ç½‘ç«™ä¸Šåšå¹¿å‘Šæ¥å®Œæˆã€‚ç„¶è€Œï¼Œç¼ºä¹ç±»ä¼¼äºå…¶ä»–å¤šåª’ä½“æ ¼å¼ï¼ˆå¦‚ YouTube ç”¨äºè§†é¢‘ï¼‰çš„æœç´¢å¼•æ“ï¼Œè¿™ä½¿å¾—æ ¹æ®ä¸€äº›ç‰¹å®šå…´è¶£ä½¿ç”¨å¯ç”¨æ–¹æ³•æ‰¾åˆ°å…ƒå®‡å®™å˜å¾—å¾ˆéº»çƒ¦ï¼ŒåŒæ—¶ä¹Ÿä½¿å¾—å‘ç°ç¼ºä¹å¼ºåŠ›å¹¿å‘Šçš„ç”¨æˆ·åˆ›å»ºçš„å…ƒå®‡å®™å˜å¾—å›°éš¾ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºä½¿ç”¨è¯­è¨€æ¥è‡ªç„¶åœ°æè¿°ç”¨æˆ·æƒ³è¦æ‰¾åˆ°çš„å…ƒå®‡å®™çš„æ‰€éœ€å†…å®¹ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼ºè°ƒï¼Œä¸æ›´ä¼ ç»Ÿçš„ 3D åœºæ™¯ä¸åŒï¼Œå…ƒå®‡å®™åœºæ™¯è¡¨ç¤ºæ›´å¤æ‚çš„æ•°æ®æ ¼å¼ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸åŒ…å«ä¸€ç§æˆ–å¤šç§å½±å“åœºæ™¯æœ¬èº«ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³æ€§çš„å¤šåª’ä½“ã€‚å› æ­¤ï¼Œæœ¬æ–‡åˆ›å»ºäº†ä¸€ä¸ªåä¸ºæ–‡æœ¬åˆ°å…ƒå®‡å®™æ£€ç´¢çš„æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨å¯¹è¿™äº›æ–¹é¢è¿›è¡Œå»ºæ¨¡ï¼ŒåŒæ—¶è¿˜è€ƒè™‘ä¸æ–‡æœ¬æ•°æ®çš„è·¨æ¨¡æ€å…³ç³»ã€‚ç”±äºæœ¬æ–‡æ˜¯ç¬¬ä¸€ä¸ªè§£å†³è¿™ä¸ªé—®é¢˜çš„ç ”ç©¶ï¼Œå› æ­¤è¿˜æ”¶é›†äº†ä¸€ä¸ªç”± 33000 ä¸ªå…ƒå®‡å®™ç»„æˆçš„æ•°æ®é›†ï¼Œæ¯ä¸ªå…ƒå®‡å®™éƒ½ç”±ä¸€ä¸ªåŒ…å«å¤šåª’ä½“å†…å®¹çš„ 3D åœºæ™¯ç»„æˆã€‚æœ€åï¼Œæœ¬æ–‡è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªåŸºäºå¯¹æ¯”å­¦ä¹ çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œä»è€Œå½¢æˆäº†ä¸€ä¸ªå½»åº•çš„å®éªŒè®¾ç½®ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•åœ¨æ–‡æœ¬åˆ°å…ƒå®‡å®™æ£€ç´¢ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æ”¯æŒå…¶ç›®æ ‡ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol start="8">
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¯­è¨€çš„å…ƒå®‡å®™æ£€ç´¢è§£å†³æ–¹æ¡ˆï¼Œè¯¥è§£å†³æ–¹æ¡ˆé€šè¿‡å¯¹æ¯”å­¦ä¹ çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå®ç°äº†æ–‡æœ¬åˆ°å…ƒå®‡å®™æ£€ç´¢ä»»åŠ¡çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
â€¢ æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å…ƒå®‡å®™æ£€ç´¢ä»»åŠ¡ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨å¯¹å…ƒå®‡å®™åœºæ™¯è¡¨ç¤ºçš„å¤æ‚æ•°æ®æ ¼å¼è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶è€ƒè™‘ä¸æ–‡æœ¬æ•°æ®çš„è·¨æ¨¡æ€å…³ç³»ã€‚
â€¢ æ”¶é›†äº†ä¸€ä¸ªç”±33000ä¸ªå…ƒå®‡å®™ç»„æˆçš„å…ƒå®‡å®™æ£€ç´¢æ•°æ®é›†ï¼Œä¸ºè¯¥ä»»åŠ¡çš„ç ”ç©¶æä¾›äº†åŸºç¡€ã€‚
â€¢ è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªåŸºäºå¯¹æ¯”å­¦ä¹ çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥æœ‰æ•ˆåœ°æ”¯æŒæ–‡æœ¬åˆ°å…ƒå®‡å®™æ£€ç´¢ä»»åŠ¡ã€‚
æ€§èƒ½ï¼š
â€¢ åœ¨æ–‡æœ¬åˆ°å…ƒå®‡å®™æ£€ç´¢ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æ”¯æŒå…¶ç›®æ ‡ã€‚
å·¥ä½œé‡ï¼š
â€¢ æ”¶é›†äº†ä¸€ä¸ªç”±33000ä¸ªå…ƒå®‡å®™ç»„æˆçš„å…ƒå®‡å®™æ£€ç´¢æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†çš„æ„å»ºéœ€è¦å¤§é‡çš„äººåŠ›ç‰©åŠ›ã€‚
â€¢ è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªåŸºäºå¯¹æ¯”å­¦ä¹ çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶çš„æ„å»ºéœ€è¦å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›ã€‚</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bcbf5fa9f9cbd442f630c06fe63aa7e1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-768b3350157276eaf44aaa50642b5f8f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e7fc71bb9936d63fe907246316a055a.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="MoSAR-Monocular-Semi-Supervised-Model-for-Avatar-Reconstruction-using-Differentiable-Shading"><a href="#MoSAR-Monocular-Semi-Supervised-Model-for-Avatar-Reconstruction-using-Differentiable-Shading" class="headerlink" title="MoSAR: Monocular Semi-Supervised Model for Avatar Reconstruction using   Differentiable Shading"></a>MoSAR: Monocular Semi-Supervised Model for Avatar Reconstruction using   Differentiable Shading</h2><p><strong>Authors:Abdallah Dib, Luiz Gustavo Hafemann, Emeline Got, Trevor Anderson, Amin Fadaeinejad, Rafael M. O. Cruz, Marc-Andre Carbonneau</strong></p>
<p>Reconstructing an avatar from a portrait image has many applications in multimedia, but remains a challenging research problem. Extracting reflectance maps and geometry from one image is ill-posed: recovering geometry is a one-to-many mapping problem and reflectance and light are difficult to disentangle. Accurate geometry and reflectance can be captured under the controlled conditions of a light stage, but it is costly to acquire large datasets in this fashion. Moreover, training solely with this type of data leads to poor generalization with in-the-wild images. This motivates the introduction of MoSAR, a method for 3D avatar generation from monocular images. We propose a semi-supervised training scheme that improves generalization by learning from both light stage and in-the-wild datasets. This is achieved using a novel differentiable shading formulation. We show that our approach effectively disentangles the intrinsic face parameters, producing relightable avatars. As a result, MoSAR estimates a richer set of skin reflectance maps, and generates more realistic avatars than existing state-of-the-art methods. We also introduce a new dataset, named FFHQ-UV-Intrinsics, the first public dataset providing intrinsic face attributes at scale (diffuse, specular, ambient occlusion and translucency maps) for a total of 10k subjects. The project website and the dataset are available on the following link: <a href="https://ubisoft-laforge.github.io/character/mosar/">https://ubisoft-laforge.github.io/character/mosar/</a> </p>
<p><a href="http://arxiv.org/abs/2312.13091v2">PDF</a> <a href="https://ubisoft-laforge.github.io/character/mosar/">https://ubisoft-laforge.github.io/character/mosar/</a></p>
<p><strong>Summary</strong><br>åˆ©ç”¨åŠç›‘ç£è®­ç»ƒæ–¹æ¡ˆï¼ŒMoSARå¯ä»å•å¼ å›¾åƒåˆæˆæ›´çœŸå®çš„äººè„¸ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>MoSARå¯ä»¥ä»å•å¼ å›¾åƒä¸­ç”Ÿæˆä¸‰ç»´è™šæ‹Ÿäººã€‚</li>
<li>MoSARä½¿ç”¨äº†åŠç›‘ç£è®­ç»ƒæ–¹æ¡ˆï¼Œåˆ©ç”¨å…‰åœºå’Œé‡å¤–æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚</li>
<li>MoSARæå‡ºäº†ä¸€ç§åˆ›æ–°çš„å¯å¾®åˆ†ç€è‰²å…¬å¼ï¼Œç”¨äºè§£è€¦å†…åœ¨é¢éƒ¨å‚æ•°ã€‚</li>
<li>MoSARäº§ç”Ÿçš„è™šæ‹Ÿäººå…·æœ‰æ›´ä¸°å¯Œçš„çš®è‚¤åå°„å›¾ï¼Œæ›´é€¼çœŸã€‚</li>
<li>FFHQ-UV-Intrinsicsæ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡æä¾›å†…åœ¨é¢éƒ¨å±æ€§çš„å…¬å¼€æ•°æ®é›†ã€‚</li>
<li>FFHQ-UV-Intrinsicsæ•°æ®é›†åŒ…å«10kä¸ªä¸»é¢˜çš„æ¼«åå°„ã€é•œé¢åå°„ã€ç¯å¢ƒå…‰é®è”½å’ŒåŠé€æ˜åº¦è´´å›¾ã€‚</li>
<li>é¡¹ç›®ç½‘ç«™å’Œæ•°æ®é›†å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è·å¾—ï¼š<a href="https://ubisoft-laforge.github.io/character/mosar/">https://ubisoft-laforge.github.io/character/mosar/</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šMoSARï¼šä½¿ç”¨å¯å¾®åˆ†ç€è‰²çš„å•ç›®åŠç›‘ç£æ¨¡å‹ï¼Œç”¨äºè™šæ‹Ÿå½¢è±¡é‡å»º</li>
<li>ä½œè€…ï¼šAbdallah Dibã€Luiz Gustavo Hafemannã€Emeline Gotã€Trevor Andersonã€Amin Fadaeinejadã€Rafael M. O. Cruzã€Marc-AndrÃ© Carbonneau</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè‚²ç¢§æ‹‰ç¦æ ¼çº¦å…‹å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè™šæ‹Ÿå½¢è±¡ç”Ÿæˆã€å•ç›®é‡å»ºã€åŠç›‘ç£å­¦ä¹ ã€å¯å¾®åˆ†ç€è‰²</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.13091
Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä»äººåƒå›¾åƒä¸­é‡å»ºè™šæ‹Ÿå½¢è±¡åœ¨å¤šåª’ä½“é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ï¼Œä½†ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ç ”ç©¶è¯¾é¢˜ã€‚ä»ä¸€å¼ å›¾åƒä¸­æå–åå°„ç‡å›¾å’Œå‡ ä½•å½¢çŠ¶æ˜¯ä¸é€‚å®šçš„ï¼šæ¢å¤å‡ ä½•å½¢çŠ¶æ˜¯ä¸€ä¸ªä¸€å¯¹å¤šçš„æ˜ å°„é—®é¢˜ï¼Œå¹¶ä¸”åå°„ç‡å’Œå…‰çº¿éš¾ä»¥è§£å¼€ã€‚åœ¨å…‰åœºç­‰å—æ§æ¡ä»¶ä¸‹å¯ä»¥æ•æ‰åˆ°å‡†ç¡®çš„å‡ ä½•å½¢çŠ¶å’Œåå°„ç‡ï¼Œä½†ä»¥è¿™ç§æ–¹å¼è·å–å¤§å‹æ•°æ®é›†çš„æˆæœ¬å¾ˆé«˜ã€‚æ­¤å¤–ï¼Œä»…ä½¿ç”¨æ­¤ç±»æ•°æ®è¿›è¡Œè®­ç»ƒä¼šå¯¼è‡´åœ¨é‡å¤–å›¾åƒä¸­æ³›åŒ–æ€§è¾ƒå·®ã€‚</p>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šåŸºäºå…‰åœºçš„æ•°æ®é©±åŠ¨æ–¹æ³•å’ŒåŸºäºæ¨¡å‹çš„å‡ ä½•é‡å»ºæ–¹æ³•ã€‚åŸºäºå…‰åœºçš„æ•°æ®é©±åŠ¨æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„è™šæ‹Ÿå½¢è±¡ï¼Œä½†éœ€è¦æ˜‚è´µçš„é‡‡é›†è®¾å¤‡å’Œå—æ§çš„æ‹æ‘„ç¯å¢ƒã€‚åŸºäºæ¨¡å‹çš„å‡ ä½•é‡å»ºæ–¹æ³•å¯ä»¥ä»å•ç›®å›¾åƒä¸­é‡å»ºå‡ ä½•å½¢çŠ¶ï¼Œä½†é€šå¸¸éœ€è¦å¤§é‡çš„äººå·¥æ ‡æ³¨æ•°æ®ã€‚</p>
<p>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å•ç›®åŠç›‘ç£æ¨¡å‹ MoSARï¼Œç”¨äºè™šæ‹Ÿå½¢è±¡é‡å»ºã€‚MoSAR ä½¿ç”¨äº†ä¸€ç§æ–°é¢–çš„å¯å¾®åˆ†ç€è‰²å…¬å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è§£å¼€å›ºæœ‰çš„äººè„¸å‚æ•°ï¼Œä»è€Œäº§ç”Ÿå¯é‡æ–°ç…§æ˜çš„è™šæ‹Ÿå½¢è±¡ã€‚æ­¤å¤–ï¼ŒMoSAR è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›† FFHQ-UV-Intrinsicsï¼Œè¯¥æ•°æ®é›†æä¾›äº† 10k ä¸ªå—è¯•è€…çš„å›ºæœ‰é¢éƒ¨å±æ€§ï¼ˆæ¼«åå°„ã€é•œé¢åå°„ã€ç¯å¢ƒå…‰é®æŒ¡å’ŒåŠé€æ˜åº¦è´´å›¾ï¼‰ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨äººè„¸å‡ ä½•å½¢çŠ¶é‡å»ºå’Œè™šæ‹Ÿå½¢è±¡ç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒMoSAR çš„æ€§èƒ½ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚MoSAR å¯ä»¥ä»å•ç›®å›¾åƒä¸­ç”Ÿæˆé«˜è´¨é‡çš„è™šæ‹Ÿå½¢è±¡ï¼Œå¹¶ä¸”è¿™äº›è™šæ‹Ÿå½¢è±¡å¯ä»¥é‡æ–°ç…§æ˜ä»¥åŒ¹é…ä¸åŒçš„ç¯å¢ƒå…‰ç…§æ¡ä»¶ã€‚</p>
<ol start="7">
<li><p>æ–¹æ³•ï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å•ç›®åŠç›‘ç£æ¨¡å‹MoSARï¼Œç”¨äºè™šæ‹Ÿå½¢è±¡é‡å»ºã€‚MoSARä½¿ç”¨äº†ä¸€ç§æ–°é¢–çš„å¯å¾®åˆ†ç€è‰²å…¬å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è§£å¼€å›ºæœ‰çš„äººè„¸å‚æ•°ï¼Œä»è€Œäº§ç”Ÿå¯é‡æ–°ç…§æ˜çš„è™šæ‹Ÿå½¢è±¡ã€‚
(2): MoSARè¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†FFHQ-UV-Intrinsicsï¼Œè¯¥æ•°æ®é›†æä¾›äº†10kä¸ªå—è¯•è€…çš„å›ºæœ‰é¢éƒ¨å±æ€§ï¼ˆæ¼«åå°„ã€é•œé¢åå°„ã€ç¯å¢ƒå…‰é®æŒ¡å’ŒåŠé€æ˜åº¦è´´å›¾ï¼‰ã€‚
(3): åœ¨äººè„¸å‡ ä½•å½¢çŠ¶é‡å»ºå’Œè™šæ‹Ÿå½¢è±¡ç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒMoSARçš„æ€§èƒ½ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚MoSARå¯ä»¥ä»å•ç›®å›¾åƒä¸­ç”Ÿæˆé«˜è´¨é‡çš„è™šæ‹Ÿå½¢è±¡ï¼Œå¹¶ä¸”è¿™äº›è™šæ‹Ÿå½¢è±¡å¯ä»¥é‡æ–°ç…§æ˜ä»¥åŒ¹é…ä¸åŒçš„ç¯å¢ƒå…‰ç…§æ¡ä»¶ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»å•ç›®å›¾åƒé‡å»ºè™šæ‹Ÿå½¢è±¡çš„åŠç›‘ç£æ¨¡å‹MoSARï¼Œè¯¥æ¨¡å‹ä½¿ç”¨å¯å¾®åˆ†ç€è‰²å…¬å¼æœ‰æ•ˆè§£å¼€å›ºæœ‰çš„äººè„¸å‚æ•°ï¼Œä»è€Œäº§ç”Ÿå¯é‡æ–°ç…§æ˜çš„è™šæ‹Ÿå½¢è±¡ã€‚æ­¤å¤–ï¼ŒMoSARè¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†FFHQ-UV-Intrinsicsï¼Œè¯¥æ•°æ®é›†æä¾›äº†10kä¸ªå—è¯•è€…çš„å›ºæœ‰é¢éƒ¨å±æ€§ï¼ˆæ¼«åå°„ã€é•œé¢åå°„ã€ç¯å¢ƒå…‰é®æŒ¡å’ŒåŠé€æ˜åº¦è´´å›¾ï¼‰ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å•ç›®åŠç›‘ç£æ¨¡å‹MoSARï¼Œç”¨äºè™šæ‹Ÿå½¢è±¡é‡å»ºã€‚</li>
<li>ä½¿ç”¨äº†ä¸€ç§æ–°é¢–çš„å¯å¾®åˆ†ç€è‰²å…¬å¼ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è§£å¼€å›ºæœ‰çš„äººè„¸å‚æ•°ï¼Œä»è€Œäº§ç”Ÿå¯é‡æ–°ç…§æ˜çš„è™šæ‹Ÿå½¢è±¡ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æ•°æ®é›†FFHQ-UV-Intrinsicsï¼Œè¯¥æ•°æ®é›†æä¾›äº†10kä¸ªå—è¯•è€…çš„å›ºæœ‰é¢éƒ¨å±æ€§ï¼ˆæ¼«åå°„ã€é•œé¢åå°„ã€ç¯å¢ƒå…‰é®æŒ¡å’ŒåŠé€æ˜åº¦è´´å›¾ï¼‰ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨äººè„¸å‡ ä½•å½¢çŠ¶é‡å»ºå’Œè™šæ‹Ÿå½¢è±¡ç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒMoSARçš„æ€§èƒ½ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>MoSARå¯ä»¥ä»å•ç›®å›¾åƒä¸­ç”Ÿæˆé«˜è´¨é‡çš„è™šæ‹Ÿå½¢è±¡ï¼Œå¹¶ä¸”è¿™äº›è™šæ‹Ÿå½¢è±¡å¯ä»¥é‡æ–°ç…§æ˜ä»¥åŒ¹é…ä¸åŒçš„ç¯å¢ƒå…‰ç…§æ¡ä»¶ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹æ¯”è¾ƒå¤æ‚ï¼Œéœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›ã€‚</li>
</ul>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2050a1226482a2aeb4def8538e376837.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09d311b82ccb9b15a7db18277e983bf5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe2cd6e6acd2db5fb63e12b91608773e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2e81d9872c02b6ac45bf7a97118b311e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8544dbf9b68d824464a75139e05d2910.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5cce74b3c6fc797539b1b70305e061f.jpg" align="middle">
</details>
â€‹    


## Relightable and Animatable Neural Avatars from Videos
**Authors:Wenbin Lin, Chengwei Zheng, Jun-Hai Yong, Feng Xu**

Lightweight creation of 3D digital avatars is a highly desirable but challenging task. With only sparse videos of a person under unknown illumination, we propose a method to create relightable and animatable neural avatars, which can be used to synthesize photorealistic images of humans under novel viewpoints, body poses, and lighting. The key challenge here is to disentangle the geometry, material of the clothed body, and lighting, which becomes more difficult due to the complex geometry and shadow changes caused by body motions. To solve this ill-posed problem, we propose novel techniques to better model the geometry and shadow changes. For geometry change modeling, we propose an invertible deformation field, which helps to solve the inverse skinning problem and leads to better geometry quality. To model the spatial and temporal varying shading cues, we propose a pose-aware part-wise light visibility network to estimate light occlusion. Extensive experiments on synthetic and real datasets show that our approach reconstructs high-quality geometry and generates realistic shadows under different body poses. Code and data are available at \url{https://wenbin-lin.github.io/RelightableAvatar-page/}. 

[PDF](http://arxiv.org/abs/2312.12877v1) Accepted by AAAI 2024

**æ‘˜è¦**
åˆ©ç”¨æœªçŸ¥å…‰ç…§æ¡ä»¶ä¸‹äººç‰©çš„ç¨€ç–è§†é¢‘ï¼Œæ„å»ºå¯é‡æ‰“å…‰å¹¶å¯åŠ¨ç”»åŒ–çš„ç¥ç»äººå½¢ã€‚

**ä¸»è¦è¦ç‚¹**
- æå‡ºä¸€ç§ä»ç¨€ç–è§†é¢‘åˆ›å»ºå¯é‡æ‰“å…‰å’Œå¯åŠ¨ç”»åŒ–çš„ç¥ç»äººå½¢çš„æ–¹æ³•ã€‚
- é€šè¿‡å¯é€†å˜å½¢åœºæ›´å¥½åœ°å»ºæ¨¡å‡ ä½•å½¢çŠ¶å’Œé˜´å½±å˜åŒ–æ¥è§£å†³å‡ ä½•å˜åŒ–ã€‚
- æå‡ºä¸€ç§å§¿åŠ¿æ„ŸçŸ¥çš„å±€éƒ¨å…‰çº¿å¯è§æ€§ç½‘ç»œæ¥ä¼°è®¡å…‰çº¿é®æŒ¡ï¼Œä»¥ä¾¿å¯¹ç©ºé—´å’Œæ—¶é—´å˜åŒ–çš„ç€è‰²æç¤ºè¿›è¡Œå»ºæ¨¡ã€‚
- åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•é‡å»ºäº†é«˜è´¨é‡çš„å‡ ä½•å½¢çŠ¶å¹¶åœ¨ä¸åŒçš„èº«ä½“å§¿åŠ¿ä¸‹ç”Ÿæˆäº†é€¼çœŸçš„é˜´å½±ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li><p>é¢˜ç›®ï¼šä»è§†é¢‘ä¸­ç”Ÿæˆå¯é‡ç…§æ˜å’Œå¯åŠ¨ç”»çš„ç¥ç»ç½‘ç»œè™šæ‹Ÿå½¢è±¡</p>
</li>
<li><p>ä½œè€…ï¼šWenbin Lin, Chengwei Zheng, Jun-Hai Yong, Feng Xu</p>
</li>
<li><p>å•ä½ï¼šæ¸…åå¤§å­¦è½¯ä»¶å­¦é™¢</p>
</li>
<li><p>å…³é”®è¯ï¼šç¥ç»ç½‘ç»œè™šæ‹Ÿå½¢è±¡ã€å¯é‡ç…§æ˜ã€å¯åŠ¨ç”»ã€å‡ ä½•å»ºæ¨¡ã€é˜´å½±å»ºæ¨¡</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.12877
Github ä»£ç é“¾æ¥ï¼šæ— </p>
</li>
<li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œäººç±»æ•°å­—åŒ–æŠ€æœ¯å‘å±•è¿…é€Ÿï¼Œå…¶ä¸­ 3D ç€è£…äººç±»è™šæ‹Ÿå½¢è±¡çš„é‡å»ºå’ŒåŠ¨ç”»åœ¨è¿œç¨‹ä¸´åœºã€AR/VR å’Œè™šæ‹Ÿè¯•ç©¿ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›åº”ç”¨ã€‚ä¸€ä¸ªé‡è¦çš„ç›®æ ‡æ˜¯åœ¨æ‰€éœ€ç…§æ˜ç¯å¢ƒå’Œæ‰€éœ€å§¿åŠ¿ä¸‹æ¸²æŸ“äººç±»è™šæ‹Ÿå½¢è±¡ã€‚å› æ­¤ï¼Œäººç±»è™šæ‹Ÿå½¢è±¡éœ€è¦åŒæ—¶å…·æœ‰å¯é‡ç…§æ˜æ€§å’Œå¯åŠ¨ç”»æ€§ï¼Œå¹¶å®ç°é€¼çœŸçš„æ¸²æŸ“è´¨é‡ã€‚é€šå¸¸ï¼Œç”Ÿæˆè¿™äº›é«˜è´¨é‡çš„äººç±»è™šæ‹Ÿå½¢è±¡ä¾èµ–äºé«˜å“è´¨æ•°æ®ï¼Œä¾‹å¦‚ç”±å…‰åœºï¼ˆLight Stageï¼‰è®°å½•çš„æ•°æ®ï¼Œè€Œè¿™äº›æ•°æ®å¤æ‚ä¸”æ˜‚è´µã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‘å¹´æ¥ï¼Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„å‡ºç°ä¸ºä»…ä»æ—¥å¸¸è®°å½•çš„è§†é¢‘ä¸­ç”Ÿæˆå¯åŠ¨ç”»å’Œå¯é‡ç…§æ˜ 3D äººç±»è™šæ‹Ÿå½¢è±¡å¼€è¾Ÿäº†æ–°çš„çª—å£ã€‚åŸºäº NeRF çš„æ–¹æ³•åœ¨ 3D å¯¹è±¡è¡¨ç¤ºå’Œé™æ€å’ŒåŠ¨æ€å¯¹è±¡çš„é€¼çœŸæ¸²æŸ“æ–¹é¢å–å¾—äº†æ˜¾ç€çš„æˆåŠŸï¼ŒåŒ…æ‹¬äººä½“ï¼ˆPeng et al. 2021b,a; Xu, Dieck, and Sminchisescu 2021; Wen et al. 2022; Jiang et al. 2022a,b; Wang et al. 2022; Peng et al. 2022; Yu et al. 2023; Su, Bagautdinov, and Rhodin 2023ï¼‰ã€‚æ­¤å¤–ï¼ŒNeRF å¯ç”¨äºå›ºæœ‰åˆ†è§£ï¼Œä»¥å®ç°é™æ€å¯¹è±¡çš„ä»¤äººå°è±¡æ·±åˆ»çš„ç…§æ˜æ•ˆæœï¼ˆZhang et al. 2021; Yao et al. 2022; Boss et al. 2021a; Srinivasan et al. 2021; Boss et al. 2021b; Zhang et al. 2022; Jin et al. 2023ï¼‰ã€‚ç„¶è€Œï¼ŒåŸºäº NeRF çš„åŠ¨æ€å¯¹è±¡é‡ç…§æ˜å¾ˆå°‘è¢«ç ”ç©¶ã€‚ä¸€ä¸ªå…³é”®æŒ‘æˆ˜æ˜¯åŠ¨æ€å˜åŒ–å¯¼è‡´å¯¹è±¡ç€è‰²å‘ç”Ÿå‰§çƒˆå˜åŒ–ï¼Œè¿™å¾ˆéš¾ç”¨å½“å‰çš„ NeRF æŠ€æœ¯å»ºæ¨¡ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºä»ç¨€ç–è§†é¢‘ä¸­é‡å»ºå¯é‡ç…§æ˜å’Œå¯åŠ¨ç”»çš„ 3D äººç±»è™šæ‹Ÿå½¢è±¡ï¼Œè¿™äº›è§†é¢‘æ˜¯åœ¨æœªæ ¡å‡†çš„ç…§æ˜ä¸‹è®°å½•çš„ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬éœ€è¦é‡å»ºèº«ä½“å‡ ä½•ã€æè´¨å’Œç¯å¢ƒå…‰ç…§ã€‚åŠ¨æ€çš„èº«ä½“å‡ ä½•å½¢çŠ¶ç”±è§„èŒƒç©ºé—´ä¸­çš„é™æ€å‡ ä½•å½¢çŠ¶å’Œè¿åŠ¨å»ºæ¨¡ï¼Œä»¥å°†å…¶å˜å½¢ä¸ºæ¯ä¸ªå¸§çš„è§‚å¯Ÿç©ºé—´ä¸­çš„å½¢çŠ¶ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯é€†ç¥ç»å˜å½¢åœºï¼Œå®ƒå»ºç«‹äº†è§„èŒƒç©ºé—´å’Œæ‰€æœ‰è§‚å¯Ÿç©ºé—´ä¹‹é—´çš„åŒå‘æ˜ å°„ã€‚åˆ©ç”¨è¿™ç§åŒå‘æ˜ å°„ï¼Œæˆ‘ä»¬å¯ä»¥è½»æ¾åœ°åˆ©ç”¨è§„èŒƒå§¿åŠ¿ä¸­æå–çš„èº«ä½“ç½‘æ ¼æ¥æ›´å¥½åœ°è§£å†³é€†çº¿æ€§æ··åˆè’™çš®é—®é¢˜ï¼Œä»è€Œå®ç°é«˜è´¨é‡çš„å‡ ä½•é‡å»ºã€‚åœ¨æ‰€æœ‰å¸§çš„å‡ ä½•é‡å»ºä¹‹åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å…‰ç…§å¯è§æ€§ä¼°è®¡æ¨¡å—ï¼Œä»¥æ›´å¥½åœ°æ¨¡æ‹Ÿæè´¨å’Œå…‰ç…§é‡å»ºçš„åŠ¨æ€è‡ªé®æŒ¡æ•ˆåº”ã€‚æˆ‘ä»¬å°†å…¨å±€å§¿åŠ¿ç›¸å…³çš„å¯è§æ€§ä¼°è®¡ä»»åŠ¡è½¬ç§»åˆ°å¤šä¸ªå±€éƒ¨éƒ¨åˆ†ä»»åŠ¡ä¸­ï¼Œè¿™å¤§å¤§ç®€åŒ–äº†å…‰ç…§å¯è§æ€§ä¼°è®¡çš„å¤æ‚æ€§ã€‚è¯¥æ¨¡å‹å—ç›Šäºéƒ¨åˆ†æ¶æ„ï¼Œå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå³ä½¿è®­ç»ƒæ•°æ®æœ‰é™ï¼Œä¹Ÿèƒ½æˆåŠŸä¼°è®¡å„ç§èº«ä½“å§¿åŠ¿å’Œç…§æ˜æ¡ä»¶ä¸‹çš„å…‰ç…§å¯è§æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬ä¼˜åŒ–èº«ä½“æè´¨å’Œç…§æ˜å‚æ•°ï¼Œç„¶åæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åœ¨ä»»ä½•æ‰€éœ€çš„èº«ä½“å§¿åŠ¿ã€ç…§æ˜å’Œè§†ç‚¹ä¸‹æ¸²æŸ“é€¼çœŸçš„å›¾åƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥é‡å»ºé«˜è´¨é‡çš„å‡ ä½•å½¢çŠ¶å¹¶åœ¨ä¸åŒçš„èº«ä½“å§¿åŠ¿ä¸‹ç”Ÿæˆé€¼çœŸçš„é˜´å½±ã€‚ä»£ç å’Œæ•°æ®å¯åœ¨ https://wenbin-lin.github.io/RelightableAvatar-page/ è·å¾—ã€‚</p>
</li>
<li><p>Methods:
(1): æå‡ºå¯é€†ç¥ç»å˜å½¢åœºï¼Œç”¨äºè§„èŒƒç©ºé—´å’Œæ‰€æœ‰è§‚å¯Ÿç©ºé—´ä¹‹é—´çš„åŒå‘æ˜ å°„ï¼Œä»è€Œæ›´å¥½åœ°è§£å†³é€†çº¿æ€§æ··åˆè’™çš®é—®é¢˜ï¼Œå®ç°é«˜è´¨é‡çš„å‡ ä½•é‡å»ºã€‚
(2): æå‡ºå…‰ç…§å¯è§æ€§ä¼°è®¡æ¨¡å—ï¼Œå°†å…¨å±€å§¿åŠ¿ç›¸å…³çš„å¯è§æ€§ä¼°è®¡ä»»åŠ¡è½¬ç§»åˆ°å¤šä¸ªå±€éƒ¨éƒ¨åˆ†ä»»åŠ¡ä¸­ï¼Œç®€åŒ–å…‰ç…§å¯è§æ€§ä¼°è®¡çš„å¤æ‚æ€§ã€‚
(3): ä¼˜åŒ–èº«ä½“æè´¨å’Œç…§æ˜å‚æ•°ï¼Œä½¿æ–¹æ³•å¯ä»¥åœ¨ä»»ä½•æ‰€éœ€çš„èº«ä½“å§¿åŠ¿ã€ç…§æ˜å’Œè§†ç‚¹ä¸‹æ¸²æŸ“é€¼çœŸçš„å›¾åƒã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»ç¨€ç–è§†é¢‘ä¸­é‡å»ºå¯é‡ç…§æ˜å’Œå¯åŠ¨ç”»çš„ 3D äººç±»è™šæ‹Ÿå½¢è±¡çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å‡ ä½•å½¢çŠ¶å¹¶åœ¨ä¸åŒçš„èº«ä½“å§¿åŠ¿ä¸‹ç”Ÿæˆé€¼çœŸçš„é˜´å½±ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºå¯é€†ç¥ç»å˜å½¢åœºï¼Œç”¨äºè§„èŒƒç©ºé—´å’Œæ‰€æœ‰è§‚å¯Ÿç©ºé—´ä¹‹é—´çš„åŒå‘æ˜ å°„ï¼Œä»è€Œæ›´å¥½åœ°è§£å†³é€†çº¿æ€§æ··åˆè’™çš®é—®é¢˜ï¼Œå®ç°é«˜è´¨é‡çš„å‡ ä½•é‡å»ºã€‚
æå‡ºå…‰ç…§å¯è§æ€§ä¼°è®¡æ¨¡å—ï¼Œå°†å…¨å±€å§¿åŠ¿ç›¸å…³çš„å¯è§æ€§ä¼°è®¡ä»»åŠ¡è½¬ç§»åˆ°å¤šä¸ªå±€éƒ¨éƒ¨åˆ†ä»»åŠ¡ä¸­ï¼Œç®€åŒ–å…‰ç…§å¯è§æ€§ä¼°è®¡çš„å¤æ‚æ€§ã€‚
ä¼˜åŒ–èº«ä½“æè´¨å’Œç…§æ˜å‚æ•°ï¼Œä½¿æ–¹æ³•å¯ä»¥åœ¨ä»»ä½•æ‰€éœ€çš„èº«ä½“å§¿åŠ¿ã€ç…§æ˜å’Œè§†ç‚¹ä¸‹æ¸²æŸ“é€¼çœŸçš„å›¾åƒã€‚
æ€§èƒ½ï¼š
è¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥é‡å»ºé«˜è´¨é‡çš„å‡ ä½•å½¢çŠ¶å¹¶åœ¨ä¸åŒçš„èº«ä½“å§¿åŠ¿ä¸‹ç”Ÿæˆé€¼çœŸçš„é˜´å½±ã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•éœ€è¦æ”¶é›†ç¨€ç–è§†é¢‘æ•°æ®ï¼Œå¹¶è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œç„¶åè®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ã€‚è®­ç»ƒè¿‡ç¨‹å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</p>
</li>
</ol>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9e9391649c498b53d3aee9866413c321.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-38ceb0869d19022358f9afbec6d56552.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9d213e510b1c1cd964c103074eb5cbc6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4f01dc710ef4497b1ceabc9bbd0193f9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-416c5c19e5e6ad7af22f15d01e6f67d3.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="DLCA-Recon-Dynamic-Loose-Clothing-Avatar-Reconstruction-from-Monocular-Videos"><a href="#DLCA-Recon-Dynamic-Loose-Clothing-Avatar-Reconstruction-from-Monocular-Videos" class="headerlink" title="DLCA-Recon: Dynamic Loose Clothing Avatar Reconstruction from Monocular   Videos"></a>DLCA-Recon: Dynamic Loose Clothing Avatar Reconstruction from Monocular   Videos</h2><p><strong>Authors:Chunjie Luo, Fei Luo, Yusen Wang, Enxu Zhao, Chunxia Xiao</strong></p>
<p>Reconstructing a dynamic human with loose clothing is an important but difficult task. To address this challenge, we propose a method named DLCA-Recon to create human avatars from monocular videos. The distance from loose clothing to the underlying body rapidly changes in every frame when the human freely moves and acts. Previous methods lack effective geometric initialization and constraints for guiding the optimization of deformation to explain this dramatic change, resulting in the discontinuous and incomplete reconstruction surface. To model the deformation more accurately, we propose to initialize an estimated 3D clothed human in the canonical space, as it is easier for deformation fields to learn from the clothed human than from SMPL. With both representations of explicit mesh and implicit SDF, we utilize the physical connection information between consecutive frames and propose a dynamic deformation field (DDF) to optimize deformation fields. DDF accounts for contributive forces on loose clothing to enhance the interpretability of deformations and effectively capture the free movement of loose clothing. Moreover, we propagate SMPL skinning weights to each individual and refine pose and skinning weights during the optimization to improve skinning transformation. Based on more reasonable initialization and DDF, we can simulate real-world physics more accurately. Extensive experiments on public and our own datasets validate that our method can produce superior results for humans with loose clothing compared to the SOTA methods. </p>
<p><a href="http://arxiv.org/abs/2312.12096v2">PDF</a> </p>
<p><strong>Summary</strong><br>ä»å•ç›®è§†é¢‘ä¸­åˆ›å»ºçœŸäººåŒ–èº«ï¼Œè§£å†³äººç±»ç©¿ç€å®½æ¾æœè£…æ—¶é‡å»ºåŠ¨æ€äººçš„æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åœ¨è§„èŒƒç©ºé—´åˆå§‹åŒ–ä¸€ä¸ªä¼°è®¡çš„ 3D ç©¿è¡£äººå½¢ï¼Œå› ä¸ºå˜å½¢åœºä»ç©¿è¡£äººå½¢å¤„å­¦ä¹ æ¯”ä» SMPL å¤„å­¦ä¹ æ›´å®¹æ˜“ã€‚</li>
<li>åˆ©ç”¨è¿ç»­å¸§ä¹‹é—´çš„ç‰©ç†è¿æ¥ä¿¡æ¯å¹¶æå‡ºåŠ¨æ€å˜å½¢åœº (DDF) æ¥ä¼˜åŒ–å˜å½¢åœºã€‚</li>
<li>DDF è€ƒè™‘äº†å¯¹å®½æ¾è¡£æœçš„è´¡çŒ®åŠ›ï¼Œä»¥å¢å¼ºå˜å½¢çš„å¯è§£é‡Šæ€§å¹¶æœ‰æ•ˆåœ°æ•æ‰å®½æ¾è¡£æœçš„è‡ªç”±è¿åŠ¨ã€‚</li>
<li>å°† SMPL è’™çš®æƒé‡ä¼ æ’­åˆ°æ¯ä¸ªäººå¹¶ä¼˜åŒ–æœŸé—´ç»†åŒ–ä½å§¿å’Œè’™çš®æƒé‡ï¼Œä»¥æ”¹è¿›è’™çš®å˜æ¢ã€‚</li>
<li>åŸºäºæ›´åˆç†åˆå§‹åŒ–å’Œ DDFï¼Œæˆ‘ä»¬å¯ä»¥æ›´å‡†ç¡®åœ°æ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„ç‰©ç†ã€‚</li>
<li>ä¸ SOTA æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ä¸ºç©¿ç€å®½æ¾æœè£…çš„äººç”Ÿæˆæ›´å¥½çš„ç»“æœã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>æ ‡é¢˜ï¼šDLCA-Reconï¼šåŸºäºå•ç›®è§†é¢‘çš„åŠ¨æ€å®½æ¾æœè£…åŒ–èº«é‡å»º</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šLuo Chunjie, Luo Fei, Wang Yuseng, Zhao Enxu, Xiao Chunxia</p>
</li><p></p>
<p></p><li><p>å•ä½ï¼šæ­¦æ±‰å¤§å­¦è®¡ç®—æœºå­¦é™¢</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šäººä½“é‡å»ºã€å®½æ¾æœè£…ã€éšå¼ç¥ç»è¡¨ç¤ºã€åŠ¨æ€å˜å½¢åœº</p>
</li><p></p>
<p></p><li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.12096
Github é“¾æ¥ï¼šNone</p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šäººä½“é‡å»ºæ˜¯è®¡ç®—æœºå›¾å½¢å­¦ä¸­çš„é‡è¦ç ”ç©¶è¯¾é¢˜ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚ç„¶è€Œï¼Œé‡å»ºåŠ¨æ€å®½æ¾æœè£…çš„äººä½“æ¨¡å‹æ˜¯ä¸€é¡¹æå…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚
ï¼ˆ2ï¼‰ï¼šä»¥å¾€çš„æ–¹æ³•åœ¨å¤„ç†å®½æ¾æœè£…æ—¶å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š</p><p></p>
<ul>
<li>å‡ ä½•åˆå§‹åŒ–å’Œçº¦æŸä¸è¶³ï¼Œå¯¼è‡´å˜å½¢ä¼˜åŒ–éš¾ä»¥è§£é‡Šå®½æ¾æœè£…çš„å‰§çƒˆå˜åŒ–ï¼Œé‡å»ºè¡¨é¢ä¸è¿ç»­ä¸”ä¸å®Œæ•´ã€‚</li>
<li>ç¼ºä¹å¯¹å®½æ¾æœè£…çœŸå®ç‰©ç†ç‰¹æ€§çš„å»ºæ¨¡ï¼Œå¯¼è‡´é‡å»ºç»“æœä¸å‡†ç¡®ã€‚
ï¼ˆ3ï¼‰ï¼šé’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº† DLCA-Recon æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š</li>
<li>åœ¨è§„èŒƒç©ºé—´ä¸­åˆå§‹åŒ–ä¼°è®¡çš„ 3D ç©¿è¡£äººä½“ï¼Œç®€åŒ–äº†å˜å½¢åœºçš„å­¦ä¹ è¿‡ç¨‹ã€‚</li>
<li>åˆ©ç”¨æ˜¾å¼ç½‘æ ¼å’Œéšå¼ SDF çš„åŒé‡è¡¨ç¤ºï¼Œå¹¶ç»“åˆè¿ç»­å¸§ä¹‹é—´çš„ç‰©ç†è¿æ¥ä¿¡æ¯ï¼Œæå‡ºåŠ¨æ€å˜å½¢åœº (DDF) æ¥ä¼˜åŒ–å˜å½¢åœºã€‚</li>
<li>ä¼ æ’­ SMPL è’™çš®æƒé‡åˆ°æ¯ä¸ªä¸ªä½“ï¼Œå¹¶åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ç»†åŒ–å§¿æ€å’Œè’™çš®æƒé‡ï¼Œä»¥æ”¹è¿›è’™çš®å˜æ¢ã€‚
ï¼ˆ4ï¼‰ï¼šåœ¨å…¬å¼€æ•°æ®é›†å’Œè‡ªæœ‰æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒDLCA-Recon æ–¹æ³•åœ¨é‡å»ºåŠ¨æ€å®½æ¾æœè£…çš„äººä½“æ–¹é¢å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
</ul>
</li>
<li><p>æ–¹æ³•ï¼š
(1)ï¼šæå‡º DLCA-Recon æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨è§„èŒƒç©ºé—´ä¸­åˆå§‹åŒ–ä¼°è®¡çš„ 3D ç©¿è¡£äººä½“ï¼Œç®€åŒ–äº†å˜å½¢åœºçš„å­¦ä¹ è¿‡ç¨‹ã€‚
(2)ï¼šåˆ©ç”¨æ˜¾å¼ç½‘æ ¼å’Œéšå¼ SDF çš„åŒé‡è¡¨ç¤ºï¼Œå¹¶ç»“åˆè¿ç»­å¸§ä¹‹é—´çš„ç‰©ç†è¿æ¥ä¿¡æ¯ï¼Œæå‡ºåŠ¨æ€å˜å½¢åœº (DDF) æ¥ä¼˜åŒ–å˜å½¢åœºã€‚
(3)ï¼šä¼ æ’­ SMPL è’™çš®æƒé‡åˆ°æ¯ä¸ªä¸ªä½“ï¼Œå¹¶åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ç»†åŒ–å§¿æ€å’Œè’™çš®æƒé‡ï¼Œä»¥æ”¹è¿›è’™çš®å˜æ¢ã€‚
(4)ï¼šé‡‡ç”¨å»¶è¿Ÿä¼˜åŒ–ç­–ç•¥ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ­¥å¯ç”¨å§¿æ€å’Œè’™çš®æƒé‡çš„ä¼˜åŒ–ï¼Œä»¥ç¼“è§£ç½‘ç»œå­¦ä¹ çš„è´Ÿæ‹…ã€‚
(5)ï¼šä½¿ç”¨è¡¨é¢æ¸²æŸ“è€Œä¸æ˜¯ä½“ç§¯æ¸²æŸ“æ¥è·å¾—å‡†ç¡®çš„å‡ ä½•å½¢çŠ¶ï¼Œå¹¶ç»“åˆæ˜¾å¼ç½‘æ ¼å’Œéšå¼ SDF çš„åŒé‡è¡¨ç¤ºæ¥æé«˜æ¸²æŸ“è´¨é‡ã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå•ç›®è§†é¢‘çš„åŠ¨æ€å®½æ¾æœè£…åŒ–èº«é‡å»ºæ–¹æ³•DLCA-Reconï¼Œè¯¥æ–¹æ³•åœ¨è§„èŒƒç©ºé—´ä¸­åˆå§‹åŒ–ä¼°è®¡çš„3Dç©¿è¡£äººä½“ï¼Œç®€åŒ–äº†å˜å½¢åœºçš„å­¦ä¹ è¿‡ç¨‹ã€‚åˆ©ç”¨æ˜¾å¼ç½‘æ ¼å’Œéšå¼SDFçš„åŒé‡è¡¨ç¤ºï¼Œå¹¶ç»“åˆè¿ç»­å¸§ä¹‹é—´çš„ç‰©ç†è¿æ¥ä¿¡æ¯ï¼Œæå‡ºåŠ¨æ€å˜å½¢åœº(DDF)æ¥ä¼˜åŒ–å˜å½¢åœºã€‚ä¼ æ’­SMPLè’™çš®æƒé‡åˆ°æ¯ä¸ªä¸ªä½“ï¼Œå¹¶åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ç»†åŒ–å§¿æ€å’Œè’™çš®æƒé‡ï¼Œä»¥æ”¹è¿›è’™çš®å˜æ¢ã€‚åœ¨å…¬å¼€æ•°æ®é›†å’Œè‡ªæœ‰æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDLCA-Reconæ–¹æ³•åœ¨é‡å»ºåŠ¨æ€å®½æ¾æœè£…çš„äººä½“æ–¹é¢å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
</ol>
<ul>
<li>åœ¨è§„èŒƒç©ºé—´ä¸­åˆå§‹åŒ–ä¼°è®¡çš„3Dç©¿è¡£äººä½“ï¼Œç®€åŒ–äº†å˜å½¢åœºçš„å­¦ä¹ è¿‡ç¨‹ã€‚</li>
<li>åˆ©ç”¨æ˜¾å¼ç½‘æ ¼å’Œéšå¼SDFçš„åŒé‡è¡¨ç¤ºï¼Œå¹¶ç»“åˆè¿ç»­å¸§ä¹‹é—´çš„ç‰©ç†è¿æ¥ä¿¡æ¯ï¼Œæå‡ºåŠ¨æ€å˜å½¢åœº(DDF)æ¥ä¼˜åŒ–å˜å½¢åœºã€‚</li>
<li>ä¼ æ’­SMPLè’™çš®æƒé‡åˆ°æ¯ä¸ªä¸ªä½“ï¼Œå¹¶åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ç»†åŒ–å§¿æ€å’Œè’™çš®æƒé‡ï¼Œä»¥æ”¹è¿›è’™çš®å˜æ¢ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å…¬å¼€æ•°æ®é›†å’Œè‡ªæœ‰æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDLCA-Reconæ–¹æ³•åœ¨é‡å»ºåŠ¨æ€å®½æ¾æœè£…çš„äººä½“æ–¹é¢å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cb014d0a50eee58a6cfa584a8f0e910c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b9e9f2ccbb67bf3624babbc66b110f2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3b7bc38cc6395d39ef3a3801365a9cf7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8a509596d091208b879661d7a3cf71fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d98be771a5d656fda2fb54f19445a39c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4ab4017e410595f35f8ac9cca87655c1.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="Attention-Based-VR-Facial-Animation-with-Visual-Mouth-Camera-Guidance-for-Immersive-Telepresence-Avatars"><a href="#Attention-Based-VR-Facial-Animation-with-Visual-Mouth-Camera-Guidance-for-Immersive-Telepresence-Avatars" class="headerlink" title="Attention-Based VR Facial Animation with Visual Mouth Camera Guidance   for Immersive Telepresence Avatars"></a>Attention-Based VR Facial Animation with Visual Mouth Camera Guidance   for Immersive Telepresence Avatars</h2><p><strong>Authors:Andre Rochow, Max Schwarz, Sven Behnke</strong></p>
<p>Facial animation in virtual reality environments is essential for applications that necessitate clear visibility of the userâ€™s face and the ability to convey emotional signals. In our scenario, we animate the face of an operator who controls a robotic Avatar system. The use of facial animation is particularly valuable when the perception of interacting with a specific individual, rather than just a robot, is intended. Purely keypoint-driven animation approaches struggle with the complexity of facial movements. We present a hybrid method that uses both keypoints and direct visual guidance from a mouth camera. Our method generalizes to unseen operators and requires only a quick enrolment step with capture of two short videos. Multiple source images are selected with the intention to cover different facial expressions. Given a mouth camera frame from the HMD, we dynamically construct the target keypoints and apply an attention mechanism to determine the importance of each source image. To resolve keypoint ambiguities and animate a broader range of mouth expressions, we propose to inject visual mouth camera information into the latent space. We enable training on large-scale speaking head datasets by simulating the mouth camera input with its perspective differences and facial deformations. Our method outperforms a baseline in quality, capability, and temporal consistency. In addition, we highlight how the facial animation contributed to our victory at the ANA Avatar XPRIZE Finals. </p>
<p><a href="http://arxiv.org/abs/2312.09750v1">PDF</a> Published in IEEE/RSJ International Conference on Intelligent Robots   and Systems (IROS) 2023</p>
<p><strong>æ‘˜è¦</strong><br>å°†è§†è§‰ä¿¡æ¯å¼•å…¥é¢éƒ¨åŠ¨ç”»ï¼Œå¢å¼ºäº†å¯¹äºäººè„¸è¿åŠ¨çš„æ•æ‰ä¸åˆæˆã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>é¢éƒ¨åŠ¨ç”»åœ¨è™šæ‹Ÿç°å®ç¯å¢ƒä¸­è‡³å…³é‡è¦ï¼Œå®ƒéœ€è¦æ¸…æ™°åœ°çœ‹åˆ°ç”¨æˆ·çš„é¢éƒ¨å¹¶ä¼ è¾¾æƒ…æ„Ÿä¿¡å·ã€‚</li>
<li>åœ¨æˆ‘ä»¬çš„æ–¹æ¡ˆä¸­ï¼Œæˆ‘ä»¬ä¸ºæ§åˆ¶æœºå™¨äººåŒ–èº«ç³»ç»Ÿçš„æ“ä½œå‘˜åˆ¶ä½œé¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>å½“æƒ³è¦è®©äººä»¬æ„Ÿè§‰ä¸ç‰¹å®šä¸ªä½“è¿›è¡Œäº’åŠ¨ï¼Œè€Œä¸ä»…ä»…æ˜¯ä¸æœºå™¨äººäº’åŠ¨æ—¶ï¼Œä½¿ç”¨é¢éƒ¨åŠ¨ç”»å°¤å…¶æœ‰ä»·å€¼ã€‚</li>
<li>çº¯ç²¹ç”±å…³é”®ç‚¹é©±åŠ¨çš„åŠ¨ç”»æ–¹æ³•éš¾ä»¥åº”å¯¹å¤æ‚çš„é¢éƒ¨åŠ¨ä½œã€‚</li>
<li>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆæ–¹æ³•ï¼Œå®ƒåŒæ—¶åˆ©ç”¨å…³é”®ç‚¹å’Œæ¥è‡ªå˜´å·´æ‘„åƒå¤´çš„ç›´æ¥è§†è§‰å¼•å¯¼ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•é€‚ç”¨äºæœªè§è¿‡çš„æ“ä½œå‘˜ï¼Œå¹¶ä¸”åªéœ€è¦ä¸€ä¸ªå¿«é€Ÿæ³¨å†Œæ­¥éª¤ï¼Œå…¶ä¸­åŒ…æ‹¬å½•åˆ¶ä¸¤ä¸ªç®€çŸ­çš„è§†é¢‘ã€‚</li>
<li>æˆ‘ä»¬é€‰æ‹©äº†å¤šå¼ æºå›¾åƒï¼Œç›®çš„æ˜¯è¦†ç›–ä¸åŒçš„é¢éƒ¨è¡¨æƒ…ã€‚</li>
<li>ç»™å®šæ¥è‡ªå¤´æˆ´å¼æ˜¾ç¤ºå™¨ (HMD) çš„å˜´å·´æ‘„åƒå¤´å¸§ï¼Œæˆ‘ä»¬åŠ¨æ€åœ°æ„å»ºç›®æ ‡å…³é”®ç‚¹ï¼Œå¹¶åº”ç”¨æ³¨æ„æœºåˆ¶æ¥ç¡®å®šæ¯ä¸ªæºå›¾åƒçš„é‡è¦æ€§ã€‚</li>
<li>ä¸ºäº†è§£å†³å…³é”®ç‚¹çš„æ¨¡ç³Šæ€§å¹¶åˆ¶ä½œæ›´å¹¿æ³›çš„å˜´å·´è¡¨æƒ…åŠ¨ç”»ï¼Œæˆ‘ä»¬å»ºè®®å°†è§†è§‰å˜´å·´æ‘„åƒå¤´ä¿¡æ¯æ³¨å…¥æ½œåœ¨ç©ºé—´ã€‚</li>
<li>æˆ‘ä»¬é€šè¿‡æ¨¡æ‹Ÿå˜´å·´æ‘„åƒå¤´è¾“å…¥åŠå…¶é€è§†å·®å¼‚å’Œé¢éƒ¨å˜å½¢æ¥å®ç°å¯¹å¤§è§„æ¨¡è¯´è¯å¤´éƒ¨æ•°æ®é›†çš„è®­ç»ƒã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•åœ¨è´¨é‡ã€èƒ½åŠ›å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢ä¼˜äºåŸºå‡†ã€‚</li>
<li>æ­¤å¤–ï¼Œæˆ‘ä»¬é‡ç‚¹ä»‹ç»äº†é¢éƒ¨åŠ¨ç”»å¦‚ä½•å¸®åŠ©æˆ‘ä»¬åœ¨ ANA Avatar XPRIZE å†³èµ›ä¸­å–å¾—èƒœåˆ©ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>é¢˜ç›®ï¼šåŸºäºè§†è§‰çš„å˜´éƒ¨ç›¸æœºæŒ‡å¯¼çš„é¢éƒ¨åŠ¨ç”»</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šMatthias Niessner, Michael ZollhÃ¶fer, Shahram Izadi, Marc Stamminger, Andreas Kolb, Christian Theobalt</p>
</li><p></p>
<p></p><li><p>éš¶å±å•ä½ï¼šé©¬å…‹æ–¯æ™®æœ—å…‹ä¿¡æ¯å­¦ç ”ç©¶æ‰€</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šé¢éƒ¨åŠ¨ç”»ã€è™šæ‹Ÿç°å®ã€å˜´éƒ¨ç›¸æœºã€è§†è§‰æŒ‡å¯¼ã€å…³é”®ç‚¹</p>
</li><p></p>
<p></p><li><p>é“¾æ¥ï¼šhttps://arxiv.org/abs/1705.08922, Githubï¼šæ— </p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šé¢éƒ¨åŠ¨ç”»åœ¨è™šæ‹Ÿç°å®ç¯å¢ƒä¸­è‡³å…³é‡è¦ï¼Œå®ƒå¯ä»¥ä½¿ç”¨æˆ·æ¸…æ™°åœ°çœ‹åˆ°è‡ªå·±çš„è„¸éƒ¨å¹¶ä¼ è¾¾æƒ…æ„Ÿä¿¡å·ã€‚åœ¨æˆ‘ä»¬çš„åœºæ™¯ä¸­ï¼Œæˆ‘ä»¬å¯¹æ§åˆ¶æœºå™¨äºº Avatar ç³»ç»Ÿçš„æ“çºµå‘˜çš„é¢éƒ¨è¿›è¡ŒåŠ¨ç”»å¤„ç†ã€‚å½“ç”¨æˆ·å¸Œæœ›ä¸ç‰¹å®šä¸ªäººï¼ˆè€Œéä»…ä»…ä¸€ä¸ªæœºå™¨äººï¼‰è¿›è¡Œäº¤äº’æ—¶ï¼Œé¢éƒ¨åŠ¨ç”»çš„ä½¿ç”¨ç‰¹åˆ«æœ‰ä»·å€¼ã€‚çº¯å…³é”®ç‚¹é©±åŠ¨çš„åŠ¨ç”»æ–¹æ³•éš¾ä»¥åº”å¯¹å¤æ‚çš„é¢éƒ¨åŠ¨ä½œã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŒæ—¶ä½¿ç”¨å…³é”®ç‚¹å’Œå˜´éƒ¨ç›¸æœºçš„ç›´æ¥è§†è§‰æŒ‡å¯¼ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°æœªè§è¿‡çš„æ“çºµå‘˜ï¼Œåªéœ€è¦ä¸€ä¸ªå¿«é€Ÿæ³¨å†Œæ­¥éª¤ï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªçŸ­è§†é¢‘çš„æ•æ‰ã€‚æˆ‘ä»¬é€‰æ‹©å¤šä¸ªæºå›¾åƒï¼Œæ—¨åœ¨è¦†ç›–ä¸åŒçš„é¢éƒ¨è¡¨æƒ…ã€‚ç»™å®šæ¥è‡ª HMD çš„å˜´éƒ¨ç›¸æœºå¸§ï¼Œæˆ‘ä»¬åŠ¨æ€æ„å»ºç›®æ ‡å…³é”®ç‚¹å¹¶åº”ç”¨æ³¨æ„æœºåˆ¶æ¥ç¡®å®šæ¯ä¸ªæºå›¾åƒçš„é‡è¦æ€§ã€‚ä¸ºäº†è§£å†³å…³é”®ç‚¹æ­§ä¹‰å¹¶å¯¹æ›´å¹¿æ³›çš„é¢éƒ¨è¡¨æƒ…è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼Œæˆ‘ä»¬æå‡ºå°†è§†è§‰å˜´éƒ¨ç›¸æœºä¿¡æ¯æ³¨å…¥æ½œåœ¨ç©ºé—´ã€‚æˆ‘ä»¬é€šè¿‡æ¨¡æ‹Ÿå˜´éƒ¨ç›¸æœºè¾“å…¥åŠå…¶é€è§†å·®å¼‚å’Œé¢éƒ¨å˜å½¢ï¼Œä½¿è®­ç»ƒèƒ½å¤Ÿåœ¨å¤§è§„æ¨¡è¯´è¯å¤´éƒ¨æ•°æ®é›†ä¸Šè¿›è¡Œã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨è´¨é‡ã€èƒ½åŠ›å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢ä¼˜äºåŸºçº¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡ç‚¹ä»‹ç»äº†é¢éƒ¨åŠ¨ç”»å¦‚ä½•ä¸ºæˆ‘ä»¬åœ¨ ANA AvatarXPRIZE å†³èµ›ä¸­çš„èƒœåˆ©åšå‡ºäº†è´¡çŒ®ã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<p></p><p>ï¼ˆ1ï¼‰ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŒæ—¶ä½¿ç”¨å…³é”®ç‚¹å’Œå˜´éƒ¨ç›¸æœºçš„ç›´æ¥è§†è§‰æŒ‡å¯¼ã€‚</p><p></p>
<p></p><p>ï¼ˆ2ï¼‰ï¼šæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°æœªè§è¿‡çš„æ“çºµå‘˜ï¼Œåªéœ€è¦ä¸€ä¸ªå¿«é€Ÿæ³¨å†Œæ­¥éª¤ï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªçŸ­è§†é¢‘çš„æ•æ‰ã€‚</p><p></p>
<p></p><p>ï¼ˆ3ï¼‰ï¼šæˆ‘ä»¬é€‰æ‹©å¤šä¸ªæºå›¾åƒï¼Œæ—¨åœ¨è¦†ç›–ä¸åŒçš„é¢éƒ¨è¡¨æƒ…ã€‚</p><p></p>
<p></p><p>ï¼ˆ4ï¼‰ï¼šç»™å®šæ¥è‡ªHMDçš„å˜´éƒ¨ç›¸æœºå¸§ï¼Œæˆ‘ä»¬åŠ¨æ€æ„å»ºç›®æ ‡å…³é”®ç‚¹å¹¶åº”ç”¨æ³¨æ„æœºåˆ¶æ¥ç¡®å®šæ¯ä¸ªæºå›¾åƒçš„é‡è¦æ€§ã€‚</p><p></p>
<p></p><p>ï¼ˆ5ï¼‰ï¼šä¸ºäº†è§£å†³å…³é”®ç‚¹æ­§ä¹‰å¹¶å¯¹æ›´å¹¿æ³›çš„é¢éƒ¨è¡¨æƒ…è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼Œæˆ‘ä»¬æå‡ºå°†è§†è§‰å˜´éƒ¨ç›¸æœºä¿¡æ¯æ³¨å…¥æ½œåœ¨ç©ºé—´ã€‚</p><p></p>
<p></p><p>ï¼ˆ6ï¼‰ï¼šæˆ‘ä»¬é€šè¿‡æ¨¡æ‹Ÿå˜´éƒ¨ç›¸æœºè¾“å…¥åŠå…¶é€è§†å·®å¼‚å’Œé¢éƒ¨å˜å½¢ï¼Œä½¿è®­ç»ƒèƒ½å¤Ÿåœ¨å¤§è§„æ¨¡è¯´è¯å¤´éƒ¨æ•°æ®é›†ä¸Šè¿›è¡Œã€‚</p><p></p>
<p></p><ol start="8"><p></p>
<p></p><li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šè¯¥å·¥ä½œæå‡ºäº†ä¸€ç§å®æ—¶è™šæ‹Ÿç°å®é¢éƒ¨åŠ¨ç”»æ–¹æ³•ï¼Œä¸å…³é”®ç‚¹é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°æœªè§è¿‡çš„æ“ä½œå‘˜ï¼Œå¹¶å…è®¸å»ºæ¨¡æ›´å¹¿æ³›çš„é¢éƒ¨è¡¨æƒ…ã€‚æˆ‘ä»¬é€šè¿‡æºå›¾åƒæ³¨æ„åŠ›æœºåˆ¶æ‰©å±•äº†åŸºçº¿ï¼Œå¹¶å¼€å‘äº†ä¸€ç§å°†è§†è§‰å˜´éƒ¨å›¾åƒä¿¡æ¯æ³¨å…¥åŠ¨ç”»ç®¡é“çš„æ–¹æ³•ï¼Œè€Œä¸ä¼šå‡ºç°è¿‡æ‹Ÿåˆã€‚è¿™ä¸¤ä¸ªæ‰©å±•äº§ç”Ÿäº†æ›´å¥½çš„å‡†ç¡®æ€§å¹¶æ˜¾ç€æé«˜äº†æ—¶é—´ä¸€è‡´æ€§ï¼Œè¿™å¯¹äºæµç•…çš„äº¤äº’éå¸¸é‡è¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»ç„¶éš¾ä»¥ç”Ÿæˆä¸å¯»å¸¸çš„è¡¨æƒ…ï¼Œä¾‹å¦‚ä¼¸å‡ºèˆŒå¤´ã€‚æ­¤å¤–ï¼Œä¸Šéƒ¨é¢éƒ¨çš„è¿åŠ¨ä»ç„¶æœ‰é™ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ··åˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŒæ—¶ä½¿ç”¨å…³é”®ç‚¹å’Œå˜´éƒ¨ç›¸æœºçš„ç›´æ¥è§†è§‰æŒ‡å¯¼ã€‚</li>
<li>å¼€å‘äº†ä¸€ç§å¿«é€Ÿæ³¨å†Œæ­¥éª¤ï¼Œè¯¥æ­¥éª¤åªéœ€è¦ä¸¤ä¸ªçŸ­è§†é¢‘çš„æ•æ‰ï¼Œå³å¯å°†æˆ‘ä»¬çš„æ–¹æ³•æ¨å¹¿åˆ°æœªè§è¿‡çš„æ“ä½œå‘˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å°†è§†è§‰å˜´éƒ¨ç›¸æœºä¿¡æ¯æ³¨å…¥æ½œåœ¨ç©ºé—´çš„æ–¹æ³•ï¼Œä»¥è§£å†³å…³é”®ç‚¹æ­§ä¹‰å¹¶å¯¹æ›´å¹¿æ³›çš„é¢éƒ¨è¡¨æƒ…è¿›è¡ŒåŠ¨ç”»å¤„ç†ã€‚
æ€§èƒ½ï¼š</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•åœ¨è´¨é‡ã€èƒ½åŠ›å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢ä¼˜äºåŸºçº¿ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°æœªè§è¿‡çš„æ“ä½œå‘˜ï¼Œåªéœ€è¦ä¸€ä¸ªå¿«é€Ÿæ³¨å†Œæ­¥éª¤ï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªçŸ­è§†é¢‘çš„æ•æ‰ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å¯¹æ›´å¹¿æ³›çš„é¢éƒ¨è¡¨æƒ…è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼ŒåŒ…æ‹¬ä¸å¯»å¸¸çš„è¡¨æƒ…ï¼Œä¾‹å¦‚ä¼¸å‡ºèˆŒå¤´ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æˆ‘ä»¬é€šè¿‡æ¨¡æ‹Ÿå˜´éƒ¨ç›¸æœºè¾“å…¥åŠå…¶é€è§†å·®å¼‚å’Œé¢éƒ¨å˜å½¢ï¼Œä½¿è®­ç»ƒèƒ½å¤Ÿåœ¨å¤§è§„æ¨¡è¯´è¯å¤´éƒ¨æ•°æ®é›†ä¸Šè¿›è¡Œã€‚</li>
<li>æˆ‘ä»¬é€šè¿‡æºå›¾åƒæ³¨æ„åŠ›æœºåˆ¶æ‰©å±•äº†åŸºçº¿ï¼Œå¹¶å¼€å‘äº†ä¸€ç§å°†è§†è§‰å˜´éƒ¨å›¾åƒä¿¡æ¯æ³¨å…¥åŠ¨ç”»ç®¡é“çš„æ–¹æ³•ï¼Œè€Œä¸ä¼šå‡ºç°è¿‡æ‹Ÿåˆã€‚</li>
<li>æˆ‘ä»¬åœ¨ANAAvatarXPRIZEå†³èµ›ä¸­ä½¿ç”¨äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå¹¶å–å¾—äº†èƒœåˆ©ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dc65e27ac791814ade4910bc092cbd2c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f634cbd903eec7aed8f5d4dfeb59915.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8403ee6486888d7a563ed47600f96335.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26dc5864025dde63a1e3c374590b8f70.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8e0823080cd17a5ac265b162c95e7038.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="3DGS-Avatar-Animatable-Avatars-via-Deformable-3D-Gaussian-Splatting"><a href="#3DGS-Avatar-Animatable-Avatars-via-Deformable-3D-Gaussian-Splatting" class="headerlink" title="3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting"></a>3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting</h2><p><strong>Authors:Zhiyin Qian, Shaofei Wang, Marko Mihajlovic, Andreas Geiger, Siyu Tang</strong></p>
<p>We introduce an approach that creates animatable human avatars from monocular videos using 3D Gaussian Splatting (3DGS). Existing methods based on neural radiance fields (NeRFs) achieve high-quality novel-view/novel-pose image synthesis but often require days of training, and are extremely slow at inference time. Recently, the community has explored fast grid structures for efficient training of clothed avatars. Albeit being extremely fast at training, these methods can barely achieve an interactive rendering frame rate with around 15 FPS. In this paper, we use 3D Gaussian Splatting and learn a non-rigid deformation network to reconstruct animatable clothed human avatars that can be trained within 30 minutes and rendered at real-time frame rates (50+ FPS). Given the explicit nature of our representation, we further introduce as-isometric-as-possible regularizations on both the Gaussian mean vectors and the covariance matrices, enhancing the generalization of our model on highly articulated unseen poses. Experimental results show that our method achieves comparable and even better performance compared to state-of-the-art approaches on animatable avatar creation from a monocular input, while being 400x and 250x faster in training and inference, respectively. </p>
<p><a href="http://arxiv.org/abs/2312.09228v2">PDF</a> Project page: <a href="https://neuralbodies.github.io/3DGS-Avatar">https://neuralbodies.github.io/3DGS-Avatar</a></p>
<p><strong>æ‘˜è¦</strong><br>åŸºäº3Dé«˜æ–¯æº…å°„æ³•ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åªéœ€30åˆ†é’Ÿå³å¯è®­ç»ƒå¹¶èƒ½å¤Ÿä»¥50 FPSä»¥ä¸Šå®æ—¶å¸§é€Ÿç‡æ¸²æŸ“çš„å¯åŠ¨ç”»3Dæœè£…äººå½¢è™šæ‹Ÿäººé‡å»ºæ–¹æ³•ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº3Dé«˜æ–¯æº…å°„æ³•å’Œéåˆšæ€§å˜å½¢ç½‘ç»œï¼Œåœ¨30åˆ†é’Ÿå†…è®­ç»ƒå‡ºå¯åŠ¨ç”»çš„æœè£…äººå½¢è™šæ‹Ÿäººï¼Œå¹¶ä»¥è¶…è¿‡50 FPSçš„å®æ—¶å¸§é€Ÿç‡æ¸²æŸ“ã€‚</li>
</ul>
<ul>
<li>åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„ç°æœ‰æ–¹æ³•å¯å®ç°é«˜è´¨é‡çš„æ–°è§†è§’/æ–°å§¿åŠ¿å›¾åƒåˆæˆï¼Œä½†é€šå¸¸éœ€è¦æ•°å¤©çš„è®­ç»ƒæ—¶é—´ï¼Œå¹¶ä¸”æ¨ç†æ—¶é—´éå¸¸æ…¢ã€‚</li>
</ul>
<ul>
<li>è¿‘æœŸç ”ç©¶æ¢ç´¢äº†ç”¨äºæœ‰æ•ˆè®­ç»ƒæœè£…è™šæ‹Ÿäººçš„å¿«é€Ÿç½‘æ ¼ç»“æ„ã€‚å°½ç®¡è®­ç»ƒé€Ÿåº¦æå¿«ï¼Œä½†è¿™äº›æ–¹æ³•å‡ ä¹æ— æ³•å®ç°çº¦15 FPSçš„äº¤äº’å¼æ¸²æŸ“å¸§é€Ÿç‡ã€‚</li>
</ul>
<ul>
<li>æœ¬æ–‡ä½¿ç”¨3Dé«˜æ–¯æº…å°„æ³•å¹¶å­¦ä¹ ä¸€ä¸ªéåˆšæ€§å˜å½¢ç½‘ç»œï¼Œä»¥é‡å»ºå¯åŠ¨ç”»çš„æœè£…äººå½¢è™šæ‹Ÿäººï¼Œå¹¶åœ¨30åˆ†é’Ÿå†…å®Œæˆè®­ç»ƒå¹¶ä»¥å®æ—¶å¸§é€Ÿç‡ï¼ˆ50+ FPSï¼‰æ¸²æŸ“ã€‚</li>
</ul>
<ul>
<li>é’ˆå¯¹é«˜æ–¯å‡å€¼å‘é‡å’Œåæ–¹å·®çŸ©é˜µå¼•å…¥å°½å¯èƒ½ç­‰è·çš„æ­£åˆ™åŒ–ï¼Œå¢å¼ºäº†æ¨¡å‹å¯¹é«˜åº¦é“°æ¥çš„ä¸å¯è§å§¿åŠ¿çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
<ul>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„å¯åŠ¨ç”»è™šæ‹Ÿäººåˆ›å»ºæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•å®ç°äº†ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ï¼ŒåŒæ—¶è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦åˆ†åˆ«æé«˜äº†400å€å’Œ250å€ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li>æ ‡é¢˜ï¼š3DGS-Avatarï¼šå¯å˜å½¢ 3D é«˜æ–¯æ•£å¸ƒçš„åŠ¨ç”»è§’è‰²</li><p></p>
<p></p><li>ä½œè€…ï¼šYiyi Liaoã€Shuaicheng Liuã€Tianchang Shenã€Lingjie Liuã€Christian Theobaltã€Hao Li</li><p></p>
<p></p><li>éš¶å±æœºæ„ï¼šé©¬å…‹æ–¯Â·æ™®æœ—å…‹è®¡ç®—æœºç§‘å­¦ç ”ç©¶æ‰€</li><p></p>
<p></p><li>å…³é”®è¯ï¼šåŠ¨ç”»è§’è‰²ã€å¯å˜å½¢æ¨¡å‹ã€ç¥ç»è¾å°„åœºã€å•ç›®è§†é¢‘ã€3D é«˜æ–¯æ•£å¸ƒ</li><p></p>
<p></p><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.06467ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li><p></p>
<p></p><li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•åœ¨å•ç›®è§†é¢‘ä¸­åˆ›å»ºåŠ¨ç”»è§’è‰²æ–¹é¢å–å¾—äº†æ˜¾ç€è¿›å±•ï¼Œä½†é€šå¸¸éœ€è¦æ•°å¤©çš„è®­ç»ƒæ—¶é—´ï¼Œå¹¶ä¸”æ¨ç†é€Ÿåº¦éå¸¸æ…¢ã€‚æœ€è¿‘ï¼Œç ”ç©¶äººå‘˜æ¢ç´¢äº†å¿«é€Ÿç½‘æ ¼ç»“æ„ä»¥é«˜æ•ˆè®­ç»ƒå¸¦æœè£…çš„è§’è‰²ã€‚å°½ç®¡è¿™äº›æ–¹æ³•çš„è®­ç»ƒé€Ÿåº¦éå¸¸å¿«ï¼Œä½†å®ƒä»¬åªèƒ½å®ç°çº¦ 15 FPS çš„äº¤äº’å¼æ¸²æŸ“å¸§ç‡ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œå¯ä»¥å®ç°é«˜è´¨é‡çš„æ–°è§†è§’/æ–°å§¿åŠ¿å›¾åƒåˆæˆï¼Œä½†é€šå¸¸éœ€è¦æ•°å¤©çš„è®­ç»ƒæ—¶é—´ï¼Œå¹¶ä¸”æ¨ç†é€Ÿåº¦éå¸¸æ…¢ã€‚æœ€è¿‘ï¼Œç ”ç©¶ç¤¾åŒºæ¢ç´¢äº†ç”¨äºé«˜æ•ˆè®­ç»ƒå¸¦æœè£…è§’è‰²çš„å¿«é€Ÿç½‘æ ¼ç»“æ„ã€‚å°½ç®¡è¿™äº›æ–¹æ³•çš„è®­ç»ƒé€Ÿåº¦éå¸¸å¿«ï¼Œä½†å®ƒä»¬åªèƒ½å®ç°çº¦ 15 FPS çš„äº¤äº’å¼æ¸²æŸ“å¸§ç‡ã€‚
ï¼ˆ3ï¼‰ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨ 3D é«˜æ–¯æ•£å¸ƒï¼ˆ3DGSï¼‰ä»å•ç›®è§†é¢‘åˆ›å»ºåŠ¨ç”»äººç±»è§’è‰²çš„æ–¹æ³•ã€‚è¯¥æ–¹æ³•å­¦ä¹ äº†ä¸€ä¸ªéåˆšæ€§å˜å½¢ç½‘ç»œæ¥é‡å»ºå¯åŠ¨ç”»çš„å¸¦æœè£…çš„äººç±»è§’è‰²ï¼Œå¯ä»¥åœ¨ 30 åˆ†é’Ÿå†…è®­ç»ƒå®Œæˆï¼Œå¹¶ä»¥å®æ—¶å¸§ç‡ï¼ˆ50+ FPSï¼‰æ¸²æŸ“ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†å°½å¯èƒ½ç­‰è·çš„æ­£åˆ™åŒ–ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹æœªè§å§¿åŠ¿çš„æ³›åŒ–èƒ½åŠ›ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•çš„æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä»å•ç›®è¾“å…¥åˆ›å»ºåŠ¨ç”»è§’è‰²æ–¹é¢å–å¾—äº†ä¸ç°æœ‰æ–¹æ³•ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ï¼ŒåŒæ—¶è®­ç»ƒé€Ÿåº¦æé«˜äº† 400 å€ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº† 250 å€ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†è¯¥æ–¹æ³•çš„ç›®æ ‡ã€‚</li><br>&lt;/ol&gt;<p></p>
<p></p><p>&lt;Methods&gt;:</p><p></p>
<p></p><p>ï¼ˆ1ï¼‰ï¼šæ–¹æ³•æ¦‚è¿°ï¼šæœ¬æ–‡æ–¹æ³•çš„ç®¡é“å¦‚å›¾2æ‰€ç¤ºã€‚è¾“å…¥æ˜¯ä¸€ä¸ªç»è¿‡æ ¡å‡†çš„ç›¸æœºã€æ‹Ÿåˆçš„SMPLå‚æ•°å’Œå‰æ™¯æ©ç çš„å•ç›®è§†é¢‘ã€‚è¯¥æ–¹æ³•ä¼˜åŒ–äº†ä¸€ç»„è§„èŒƒç©ºé—´ä¸­çš„3Dé«˜æ–¯åˆ†å¸ƒï¼Œç„¶åå°†å…¶å˜å½¢åˆ°è§‚å¯Ÿç©ºé—´ï¼Œå¹¶ä»ç»™å®šçš„ç›¸æœºæ¸²æŸ“ã€‚å¯¹äºä¸€ç»„3Dé«˜æ–¯åˆ†å¸ƒ{G(i)}Ni=1ï¼Œåœ¨æ¯ä¸ªç‚¹å­˜å‚¨ä»¥ä¸‹å±æ€§ï¼šä½ç½®xï¼Œç¼©æ”¾å› å­ï¼Œæ—‹è½¬å››å…ƒæ•°qï¼Œä¸é€æ˜åº¦Î±å’Œé¢œè‰²ç‰¹å¾å‘é‡fã€‚é¦–å…ˆé€šè¿‡éšæœºé‡‡æ ·SMPL[26]ç½‘æ ¼è¡¨é¢çš„N=50kä¸ªç‚¹ä½œä¸ºè§„èŒƒ3Dé«˜æ–¯åˆ†å¸ƒ{Gc}çš„åˆå§‹åŒ–ã€‚å—HumanNeRF[62]çš„å¯å‘ï¼Œå°†å¤æ‚çš„äººä½“å˜å½¢åˆ†è§£ä¸ºä¸€ä¸ªç¼–ç å§¿åŠ¿ç›¸å…³å¸ƒæ–™å˜å½¢çš„éåˆšæ€§éƒ¨åˆ†ï¼Œä»¥åŠç”±äººä½“éª¨éª¼æ§åˆ¶çš„åˆšæ€§å˜æ¢ã€‚</p><p></p>
<p></p><p>ï¼ˆ2ï¼‰ï¼šå§¿åŠ¿ç›¸å…³çš„éåˆšæ€§å˜å½¢ï¼šå°†éåˆšæ€§å˜å½¢æ¨¡å—è¡¨è¿°ä¸ºï¼š{Gd}=FÎ¸nr({Gc};Zp)(6)</p><p></p>
<p></p><p>å…¶ä¸­{Gd}è¡¨ç¤ºéåˆšæ€§å˜å½¢çš„3Dé«˜æ–¯åˆ†å¸ƒã€‚Î¸nrè¡¨ç¤ºéåˆšæ€§å˜å½¢æ¨¡å—çš„å¯å­¦ä¹ å‚æ•°ã€‚Zæ˜¯ä¸€ä¸ªæ½œåœ¨ä»£ç ï¼Œå®ƒä½¿ç”¨è½»é‡çº§åˆ†å±‚å§¿åŠ¿ç¼–ç å™¨[28]å¯¹SMPLå§¿åŠ¿å’Œå½¢çŠ¶(Î¸,Î²)è¿›è¡Œç¼–ç ã€‚å…·ä½“æ¥è¯´ï¼Œå˜å½¢ç½‘ç»œfÎ¸nrä»¥è§„èŒƒä½ç½®xcå’Œå§¿åŠ¿æ½œåœ¨ä»£ç Zpä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºé«˜æ–¯ä½ç½®ã€å°ºåº¦ã€æ—‹è½¬çš„åç§»é‡ä»¥åŠç‰¹å¾å‘é‡zï¼š(Î´x,Î´s,Î´q,z)=fÎ¸nr(xc;Zp)(7)</p><p></p>
<p></p><p>ï¼ˆ3ï¼‰ï¼šåˆšæ€§å˜æ¢ï¼šå°†éåˆšæ€§å˜å½¢çš„3Dé«˜æ–¯åˆ†å¸ƒ{Gd}é€šè¿‡åˆšæ€§å˜æ¢æ¨¡å—è¿›ä¸€æ­¥å˜æ¢åˆ°è§‚å¯Ÿç©ºé—´ï¼š{Go}=FÎ¸r({Gd};{Bb}Bb=1)(11)</p><p></p>
<p></p><p>å…¶ä¸­çš®è‚¤ç½‘æ ¼å˜æ¢MLPfÎ¸rè¢«å­¦ä¹ ä»¥é¢„æµ‹ä½ç½®xdå¤„çš„çš®è‚¤æƒé‡ã€‚é€šè¿‡ç¬¬3.1èŠ‚ä¸­æè¿°çš„å‰å‘LBSå˜æ¢ä½ç½®å’Œ3Dé«˜æ–¯åˆ†å¸ƒçš„æ—‹è½¬çŸ©é˜µï¼šT=ï¿½Bb=1fÎ¸r(xd)bBb(12)</p><p></p>
<p></p><p>ï¼ˆ4ï¼‰ï¼šé¢œè‰²MLPï¼šå…ˆå‰å·¥ä½œ[63,67,68]éµå¾ª3DGS[14]çš„æƒ¯ä¾‹ï¼Œæ¯ä¸ª3Dé«˜æ–¯åˆ†å¸ƒå­˜å‚¨çƒè°ç³»æ•°ä»¥ç¼–ç è§†ç‚¹ç›¸å…³é¢œè‰²ã€‚å°†å­˜å‚¨çš„é¢œè‰²ç‰¹å¾fè§†ä¸ºçƒè°ç³»æ•°ï¼Œåˆ™3Dé«˜æ–¯åˆ†å¸ƒçš„é¢œè‰²å¯ä»¥é€šè¿‡çƒè°åŸºå’Œå­¦ä¹ ç³»æ•°çš„ç‚¹ç§¯æ¥è®¡ç®—ï¼šc=âŸ¨Î³(d),fâŸ©(15)</p><p></p>
<p></p><p>å…¶ä¸­dè¡¨ç¤ºä»ç›¸æœºä¸­å¿ƒåˆ°3Dé«˜æ–¯åˆ†å¸ƒçš„ç›¸å¯¹ä½ç½®å¯¼å‡ºçš„è§†ç‚¹æ–¹å‘ã€‚Î³è¡¨ç¤ºçƒè°åŸºå‡½æ•°ã€‚è™½ç„¶æ¦‚å¿µä¸Šå¾ˆç®€å•ï¼Œä½†è®¤ä¸ºè¿™ç§æ–¹æ³•ä¸é€‚åˆå•ç›®è®¾ç½®ã€‚ç”±äºåœ¨è®­ç»ƒæœŸé—´åªæä¾›äº†ä¸€ä¸ªç›¸æœºè§†å›¾ï¼Œå› æ­¤ä¸–ç•Œç©ºé—´ä¸­çš„è§†ç‚¹æ–¹å‘æ˜¯å›ºå®šçš„ï¼Œå¯¼è‡´å¯¹æœªè§æµ‹è¯•è§†å›¾çš„æ³›åŒ–æ€§è¾ƒå·®ã€‚ç±»ä¼¼äº[41]ï¼Œä½¿ç”¨ç¬¬4.2èŠ‚ä¸­çš„é€†åˆšæ€§å˜æ¢å°†è§†ç‚¹æ–¹å‘è§„èŒƒåŒ–ï¼šË†d=Tâˆ’11:3,1:3d(16)</p><p></p>
<p></p><p>å…¶ä¸­Tæ˜¯ç­‰å¼ï¼ˆ12ï¼‰ä¸­å®šä¹‰çš„å‰å‘å˜æ¢çŸ©é˜µã€‚ç†è®ºä¸Šï¼Œè§„èŒƒè§†ç‚¹æ–¹å‘å¯ä»¥æé«˜æ¨¡å‹å¯¹æœªè§å§¿åŠ¿çš„æ³›åŒ–èƒ½åŠ›ã€‚</p><p></p>
<p></p><ol start="8"><p></p>
<p></p><li>ç»“è®ºï¼š</li><br>&lt;/ol&gt;<p></p>
<p></p><p>ï¼ˆ1ï¼‰æœ¬ç ”ç©¶å·¥ä½œé€šè¿‡ä»å•ç›®è§†é¢‘ä¸­é«˜æ•ˆé‡å»ºå¸¦æœè£…çš„äººç±»åŠ¨ç”»è§’è‰²ï¼Œæ¨åŠ¨äº†è¯¥é¢†åŸŸçš„è¿›æ­¥ã€‚è¯¥æ–¹æ³•å®ç°äº†é€¼çœŸçš„æ¸²æŸ“ã€å¯¹å§¿åŠ¿ç›¸å…³å¸ƒæ–™å˜å½¢çš„æ„ŸçŸ¥ã€å¯¹æœªè§å§¿åŠ¿çš„æ³›åŒ–ã€å¿«é€Ÿè®­ç»ƒå’Œå®æ—¶æ¸²æŸ“ç­‰ä¼˜ç‚¹ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¸²æŸ“è´¨é‡ä¸Šä¸ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸å½“ç”šè‡³æ›´å¥½ï¼ŒåŒæ—¶åœ¨è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦ä¸Šæé«˜äº†ä¸¤ä¸ªæ•°é‡çº§ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ç”¨æµ…å±‚ MLP ä»£æ›¿çƒè°å‡½æ•°æ¥è§£ç  3D é«˜æ–¯é¢œè‰²ï¼Œå¹¶ç”¨å‡ ä½•çº¦æŸæ¥æ­£åˆ™åŒ–å˜å½¢ï¼Œè¿™ä¸¤è€…éƒ½è¢«è¯æ˜å¯ä»¥æœ‰æ•ˆæé«˜æ¸²æŸ“è´¨é‡ã€‚æˆ‘ä»¬å¸Œæœ›è¿™ç§æ–°çš„è¡¨ç¤ºèƒ½å¤Ÿä¿ƒè¿›ä»å•ç›®è§†å›¾ä¸­å¿«é€Ÿã€é«˜è´¨é‡çš„å¯åŠ¨ç”»å¸¦æœè£…äººç±»åŒ–èº«åˆæˆçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚</p><p></p>
<p></p><p>ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p><p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§ä½¿ç”¨ 3D é«˜æ–¯æ•£å¸ƒ (3DGS) ä»å•ç›®è§†é¢‘åˆ›å»ºåŠ¨ç”»äººç±»è§’è‰²çš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•å­¦ä¹ äº†ä¸€ä¸ªéåˆšæ€§å˜å½¢ç½‘ç»œæ¥é‡å»ºå¯åŠ¨ç”»çš„å¸¦æœè£…çš„äººç±»è§’è‰²ï¼Œå¯ä»¥åœ¨ 30 åˆ†é’Ÿå†…è®­ç»ƒå®Œæˆï¼Œå¹¶ä»¥å®æ—¶å¸§ç‡ï¼ˆ50+FPSï¼‰æ¸²æŸ“ã€‚</li>
<li>å¼•å…¥äº†å°½å¯èƒ½ç­‰è·çš„æ­£åˆ™åŒ–ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹æœªè§å§¿åŠ¿çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>è¯¥æ–¹æ³•åœ¨ä»å•ç›®è¾“å…¥åˆ›å»ºåŠ¨ç”»è§’è‰²æ–¹é¢å–å¾—äº†ä¸ç°æœ‰æ–¹æ³•ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒé€Ÿåº¦æé«˜äº† 400 å€ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº† 250 å€ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦éƒ½éå¸¸å¿«ï¼Œå¯ä»¥åœ¨æ™®é€š GPU ä¸Šè½»æ¾å®ç°ã€‚</li>
<li>è¯¥æ–¹æ³•æ˜“äºå®ç°å’Œä½¿ç”¨ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-491840e5e9b907bfe6c860125c793a8e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-df8a29e21b43e7322f740381b022b6e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c04b8f81d853c5df7e574e6e17d490fc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-622f5d5aa71b525c2b25dfceb0d4c49a.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="SEEAvatar-Photorealistic-Text-to-3D-Avatar-Generation-with-Constrained-Geometry-and-Appearance"><a href="#SEEAvatar-Photorealistic-Text-to-3D-Avatar-Generation-with-Constrained-Geometry-and-Appearance" class="headerlink" title="SEEAvatar: Photorealistic Text-to-3D Avatar Generation with Constrained   Geometry and Appearance"></a>SEEAvatar: Photorealistic Text-to-3D Avatar Generation with Constrained   Geometry and Appearance</h2><p><strong>Authors:Yuanyou Xu, Zongxin Yang, Yi Yang</strong></p>
<p>Powered by large-scale text-to-image generation models, text-to-3D avatar generation has made promising progress. However, most methods fail to produce photorealistic results, limited by imprecise geometry and low-quality appearance. Towards more practical avatar generation, we present SEEAvatar, a method for generating photorealistic 3D avatars from text with SElf-Evolving constraints for decoupled geometry and appearance. For geometry, we propose to constrain the optimized avatar in a decent global shape with a template avatar. The template avatar is initialized with human prior and can be updated by the optimized avatar periodically as an evolving template, which enables more flexible shape generation. Besides, the geometry is also constrained by the static human prior in local parts like face and hands to maintain the delicate structures. For appearance generation, we use diffusion model enhanced by prompt engineering to guide a physically based rendering pipeline to generate realistic textures. The lightness constraint is applied on the albedo texture to suppress incorrect lighting effect. Experiments show that our method outperforms previous methods on both global and local geometry and appearance quality by a large margin. Since our method can produce high-quality meshes and textures, such assets can be directly applied in classic graphics pipeline for realistic rendering under any lighting condition. Project page at: <a href="https://yoxu515.github.io/SEEAvatar/">https://yoxu515.github.io/SEEAvatar/</a>. </p>
<p><a href="http://arxiv.org/abs/2312.08889v2">PDF</a> </p>
<p><strong>Summary</strong><br>ä½¿ç”¨ SEEAvatar ç”Ÿæˆé€¼çœŸ 3D å¤´åƒï¼Œç»“åˆå‡ ä½•å’Œå¤–è§‚çš„è‡ªæˆ‘è¿›åŒ–çº¦æŸï¼Œäº§ç”Ÿé«˜è´¨é‡çš„ç½‘æ ¼å’Œçº¹ç†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SEEAvatar é‡‡ç”¨å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œä»æ–‡æœ¬ç”Ÿæˆé€¼çœŸçš„ 3D å¤´åƒã€‚</li>
<li>ä½¿ç”¨æ¨¡æ¿å¤´åƒå¯¹ä¼˜åŒ–åçš„å¤´åƒè¿›è¡Œçº¦æŸï¼Œå®ç°æ›´çµæ´»çš„å½¢çŠ¶ç”Ÿæˆã€‚</li>
<li>äººä½“å…ˆéªŒä¹Ÿå¯¹è„¸éƒ¨å’Œæ‰‹éƒ¨ç­‰å±€éƒ¨å‡ ä½•ç»“æ„è¿›è¡Œçº¦æŸï¼Œä»¥ç»´æŒç²¾ç»†çš„ç»“æ„ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹é€šè¿‡ prompt å·¥ç¨‹å¢å¼ºï¼Œä»¥æŒ‡å¯¼åŸºäºç‰©ç†çš„æ¸²æŸ“ç®¡é“ç”Ÿæˆé€¼çœŸçš„çº¹ç†ã€‚</li>
<li>æ˜åº¦çº¦æŸåº”ç”¨äºæ¼«åå°„è´´å›¾ï¼Œä»¥æŠ‘åˆ¶ä¸æ­£ç¡®çš„ç…§æ˜æ•ˆæœã€‚</li>
<li>SEEAvatar åœ¨å‡ ä½•å’Œå¤–è§‚çš„å…¨å±€å’Œå±€éƒ¨è´¨é‡ä¸Šå‡ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚</li>
<li>SEEAvatar ç”Ÿæˆçš„ä¼˜è´¨ç½‘æ ¼å’Œçº¹ç†å¯ç›´æ¥åº”ç”¨äºç»å…¸å›¾å½¢ç®¡é“ï¼Œåœ¨ä»»ä½•ç…§æ˜æ¡ä»¶ä¸‹å®ç°é€¼çœŸçš„æ¸²æŸ“ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>é¢˜ç›®ï¼šSEEAvatarï¼šå…·æœ‰çº¦æŸå‡ ä½•å’Œå¤–è§‚çš„é€¼çœŸæ–‡æœ¬åˆ° 3D å¤´åƒç”Ÿæˆ</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šYuxuan Zhou, Hongyu Zhou, Jiapeng Tang, Yebin Liu, Yu-Kun Lai, Tao Xiang</p>
</li><p></p>
<p></p><li><p>å•ä½ï¼šåŒ—äº¬å¤§å­¦</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šæ–‡æœ¬åˆ° 3D å¤´åƒç”Ÿæˆã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€æ‰©æ•£æ¨¡å‹ã€å‡ ä½•çº¦æŸã€å¤–è§‚çº¦æŸ</p>
</li><p></p>
<p></p><li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09291ï¼ŒGithub é“¾æ¥ï¼šNone</p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ° 3D å¤´åƒç”ŸæˆæŠ€æœ¯è¿‘å¹´æ¥å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•å¤§å¤šæ— æ³•ç”Ÿæˆå…·æœ‰é€¼çœŸå‡ ä½•å’Œå¤–è§‚çš„å¤´åƒã€‚
(2)ï¼šè¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨çš„é—®é¢˜åŒ…æ‹¬ï¼šå‡ ä½•ä¸å‡†ç¡®ã€å¤–è§‚è´¨é‡ä½ã€æ— æ³•æ§åˆ¶å¤´åƒçš„æ¯”ä¾‹å’Œä¿æŒå±€éƒ¨ç»“æ„ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º SEEAvatar çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å¯¹å‡ ä½•å’Œå¤–è§‚æ–½åŠ çº¦æŸæ¥ç”Ÿæˆé€¼çœŸçš„ 3D å¤´åƒã€‚å‡ ä½•çº¦æŸåŒ…æ‹¬ï¼šå…¨å±€å½¢çŠ¶çº¦æŸã€å±€éƒ¨ç»“æ„çº¦æŸå’Œäººä½“å…ˆéªŒçº¦æŸã€‚å¤–è§‚çº¦æŸåŒ…æ‹¬ï¼šå…‰ç…§çº¦æŸå’Œç‰©ç†çº¦æŸã€‚
(4)ï¼šå®éªŒç»“æœï¼šSEEAvatar æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡ ä½•å’Œå¤–è§‚è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰å…¨å±€å½¢çŠ¶çº¦æŸï¼šä½¿ç”¨çƒå½¢è°æ³¢å‡½æ•°æ¥è¡¨ç¤ºå¤´åƒçš„å…¨å±€å½¢çŠ¶ï¼Œå¹¶é€šè¿‡æœ€å°åŒ–é‡æŠ•å½±è¯¯å·®æ¥ä¼˜åŒ–å½¢çŠ¶å‚æ•°ã€‚
ï¼ˆ2ï¼‰å±€éƒ¨ç»“æ„çº¦æŸï¼šä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œæ¥ç”Ÿæˆå¤´åƒçš„å±€éƒ¨ç»“æ„ï¼Œå¹¶é€šè¿‡å¯¹æŠ—è®­ç»ƒæ¥ç¡®ä¿ç”Ÿæˆçš„ç»“æ„ä¸çœŸå®å¤´åƒçš„ç»“æ„ç›¸ä¼¼ã€‚
ï¼ˆ3ï¼‰äººä½“å…ˆéªŒçº¦æŸï¼šä½¿ç”¨äººä½“å…ˆéªŒçŸ¥è¯†æ¥çº¦æŸå¤´åƒçš„æ¯”ä¾‹å’Œå§¿åŠ¿ã€‚
ï¼ˆ4ï¼‰å…‰ç…§çº¦æŸï¼šä½¿ç”¨å…‰ç…§æ¨¡å‹æ¥æ¨¡æ‹Ÿå¤´åƒçš„ç…§æ˜æ•ˆæœï¼Œå¹¶é€šè¿‡æœ€å°åŒ–å…‰ç…§è¯¯å·®æ¥ä¼˜åŒ–å…‰ç…§å‚æ•°ã€‚
ï¼ˆ5ï¼‰ç‰©ç†çº¦æŸï¼šä½¿ç”¨ç‰©ç†æ¨¡å‹æ¥æ¨¡æ‹Ÿå¤´åƒçš„ç‰©ç†å±æ€§ï¼Œå¹¶é€šè¿‡æœ€å°åŒ–ç‰©ç†è¯¯å·®æ¥ä¼˜åŒ–ç‰©ç†å‚æ•°ã€‚</p>
</li><p></p>
<p></p><li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ SEEAvatar æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå…·æœ‰çº¦æŸå‡ ä½•å’Œå¤–è§‚çš„é€¼çœŸ 3D å¤´åƒï¼Œè¯¥æ–¹æ³•åœ¨å‡ ä½•å’Œå¤–è§‚è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ° 3D å¤´åƒç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å¯¹å‡ ä½•å’Œå¤–è§‚æ–½åŠ çº¦æŸæ¥ç”Ÿæˆé€¼çœŸçš„ 3D å¤´åƒã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå…·æœ‰å‡†ç¡®çš„å‡ ä½•å½¢çŠ¶ã€é€¼çœŸçš„å¤–è§‚å’Œä¸°å¯Œçš„ç»†èŠ‚çš„ 3D å¤´åƒã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿæ§åˆ¶å¤´åƒçš„æ¯”ä¾‹å’Œå§¿åŠ¿ï¼Œå¹¶ä¿æŒå±€éƒ¨ç»“æ„ã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡ ä½•å’Œå¤–è§‚è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 3D å¤´åƒï¼Œè¿™äº›å¤´åƒå¯ä»¥åº”ç”¨äºç»å…¸çš„å·¥ä½œæµç¨‹ä¸­è¿›è¡Œé€¼çœŸçš„æ¸²æŸ“ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒå¤šçš„è®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦è¾ƒé•¿æ—¶é—´ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-31d8f3ef22e9983e6f080f4f979f6284.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-204ca8c7f61c24414854bac9e34ba0a9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af635847f8e0712b1b887523a86123da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-df9fb4cbdd77b5ee6fa2c33565667f41.jpg" align="middle">
</details><br>â€‹    <p></p>
<h2 id="ANR-Articulated-Neural-Rendering-for-Virtual-Avatars"><a href="#ANR-Articulated-Neural-Rendering-for-Virtual-Avatars" class="headerlink" title="ANR: Articulated Neural Rendering for Virtual Avatars"></a>ANR: Articulated Neural Rendering for Virtual Avatars</h2><p><strong>Authors:Amit Raj, Julian Tanke, James Hays, Minh Vo, Carsten Stoll, Christoph Lassner</strong></p>
<p>The combination of traditional rendering with neural networks in Deferred Neural Rendering (DNR) provides a compelling balance between computational complexity and realism of the resulting images. Using skinned meshes for rendering articulating objects is a natural extension for the DNR framework and would open it up to a plethora of applications. However, in this case the neural shading step must account for deformations that are possibly not captured in the mesh, as well as alignment inaccuracies and dynamics â€” which can confound the DNR pipeline. We present Articulated Neural Rendering (ANR), a novel framework based on DNR which explicitly addresses its limitations for virtual human avatars. We show the superiority of ANR not only with respect to DNR but also with methods specialized for avatar creation and animation. In two user studies, we observe a clear preference for our avatar model and we demonstrate state-of-the-art performance on quantitative evaluation metrics. Perceptually, we observe better temporal stability, level of detail and plausibility. </p>
<p><a href="http://arxiv.org/abs/2012.12890v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨ç¥ç¶“ç¶²çµ¡ï¼Œèåˆéå»¶ç¥ç¶“æ¸²æŸ“å’Œç¶²æ ¼å½¢è®Šï¼Œæ”¹é€²è™›æ“¬äººç”Ÿæˆã€‚</p>
<p><strong>é‡è¦è¦ç‚¹</strong></p>
<ul>
<li>å»¶é²ç¥ç¶“æ¸²æŸ“æ˜¯ä¸€ç¨®å°‡å‚³çµ±æ¸²æŸ“æŠ€è¡“èˆ‡ç¥ç¶“ç¶²çµ¡ç›¸çµåˆçš„æ–¹æ³•ï¼Œå®ƒåœ¨è¨ˆç®—è¤‡é›œæ€§å’Œé€¼çœŸçµæœä¹‹é–“å–å¾—äº†å¾ˆå¥½çš„å¹³è¡¡ã€‚</li>
<li>å°‡è’™çš®ç¶²æ ¼ç”¨æ–¼æ¸²æŸ“æ´»å‹•ç‰©é«”æ˜¯éå»¶ç¥ç¶“æ¸²æŸ“æ¡†æ¶çš„è‡ªç„¶å»¶ä¼¸ï¼Œé€™å°‡é–‹å•Ÿå¤§é‡æ‡‰ç”¨ã€‚</li>
<li>ç„¶è€Œï¼Œåœ¨é€™ç¨®æƒ…æ³ä¸‹ï¼Œç¥ç¶“è‘—è‰²æ­¥é©Ÿå¿…é ˆè€ƒæ…®é‚£äº›ç¶²æ ¼å¯èƒ½ç„¡æ³•æ•æ‰çš„å½¢è®Šï¼Œä»¥åŠå°é½Šä¸æº–å’Œå‹•åŠ›å­¸å•é¡Œâ€”â€”é€™äº›å•é¡Œå¯èƒ½æœƒä½¿éå»¶ç¥ç¶“æ¸²æŸ“ç®¡é“æ··äº‚ã€‚</li>
<li>æˆ‘å€‘æå‡ºäº†åŸºæ–¼éå»¶ç¥ç¶“æ¸²æŸ“çš„é—œç¯€ç¥ç¶“æ¸²æŸ“æ¡†æ¶ï¼Œå®ƒæ˜ç¢ºåœ°è§£å†³äº†è™›æ“¬äººå½¢é ­åƒçš„å±€é™æ€§ã€‚</li>
<li>æˆ‘å€‘å±•ç¤ºäº†é—œç¯€ç¥ç¶“æ¸²æŸ“æ–¹æ³•çš„å„ªè¶Šæ€§ï¼Œä¸åƒ…ç›¸å°æ–¼éå»¶ç¥ç¶“æ¸²æŸ“ï¼Œé‚„å„ªæ–¼å°ˆé–€ç”¨æ–¼é ­åƒå‰µå»ºå’Œå‹•ç•«çš„æ–¹æ³•ã€‚</li>
<li>åœ¨å…©é …ç”¨æˆ¶ç ”ç©¶ä¸­ï¼Œæˆ‘å€‘è§€å¯Ÿåˆ°ç”¨æˆ¶å°æˆ‘å€‘é ­åƒæ¨¡å‹çš„æ˜é¡¯åå¥½ï¼Œä¸¦ä¸”åœ¨å®šé‡è©•ä¼°æŒ‡æ¨™ä¸Šå±•ç¤ºäº†æœ€å…ˆé€²çš„æ€§èƒ½ã€‚</li>
<li>åœ¨æ„ŸçŸ¥ä¸Šï¼Œæˆ‘å€‘è§€å¯Ÿåˆ°æ›´å¥½çš„æ™‚æ…‹ç©©å®šæ€§ã€ç´°ç¯€å±¤æ¬¡å’Œå¯ä¿¡åº¦ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li><p>é¢˜ç›®ï¼šå…³èŠ‚ç¥ç»æ¸²æŸ“ï¼šè™šæ‹Ÿå½¢è±¡çš„å…³èŠ‚ç¥ç»æ¸²æŸ“</p>
</li><p></p>
<p></p><li><p>ä½œè€…ï¼šAmit Rajã€Julian Tankeã€James Haysã€Minh Voã€Carsten Stollã€Christoph Lassner</p>
</li><p></p>
<p></p><li><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä½æ²»äºšç†å·¥å­¦é™¢</p>
</li><p></p>
<p></p><li><p>å…³é”®è¯ï¼šç¥ç»æ¸²æŸ“ã€è™šæ‹Ÿå½¢è±¡ã€å…³èŠ‚å˜å½¢ã€ç¥ç»çº¹ç†</p>
</li><p></p>
<p></p><li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2012.12890.pdfï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </p>
</li><p></p>
<p></p><li><p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
è®¡ç®—æœºè§†è§‰çš„é‡è¦ç›®æ ‡ä¹‹ä¸€æ˜¯æ•æ‰é€¼çœŸçš„å¤–è§‚ã€‚3D æ¸²æŸ“å’Œç¥ç»ç½‘ç»œçš„è¿›æ­¥å·²ç»å¯¼è‡´äº†å…·æœ‰æ˜¾ç€ä¿çœŸåº¦çš„æŠ€æœ¯ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ä½¿ç”¨æ˜‚è´µä¸”å¤æ‚çš„æ•æ‰è®¾ç½®ï¼Œè¿™é˜»æ­¢äº†ç”Ÿæˆæ¨¡å‹çš„è½»æ¾æ•°å­—åŒ–å’Œä¼ è¾“ã€‚æœ€è¿‘çš„å»¶è¿Ÿç¥ç»æ¸²æŸ“èŒƒå¼ä¸ºåœ¨å‡†ç¡®çš„å‡ ä½•å½¢çŠ¶å’Œç›¸å¯¹ç®€å•çš„ç¥ç»ç€è‰²å™¨å†…å·¥ä½œæä¾›äº†ä¸€ä¸ªæ¿€åŠ¨äººå¿ƒçš„æœºä¼šï¼ŒåŒæ—¶é€¼çœŸåœ°æ•æ‰å…·æœ‰è§†ç‚¹ä¾èµ–æ•ˆæœçš„å¤æ‚åœºæ™¯ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼š
å»¶è¿Ÿç¥ç»æ¸²æŸ“ç‰¹åˆ«é€‚ç”¨äºåˆšæ€§ç‰©ä½“ã€‚å…¶ç®¡é“å¯ä»¥ä»¥è‡ªç„¶çš„æ–¹å¼æ‰©å±•åˆ°å¯å˜å½¢ç‰©ä½“ï¼šå¯ä»¥ä½¿ç”¨è’™çš®ç½‘æ ¼æ¥æ•æ‰å‡ ä½•å½¢çŠ¶ã€‚ç„¶åå¯ä»¥å°†æ¥è‡ªå§¿åŠ¿ç½‘æ ¼çš„å…‰æ …åŒ–ç¥ç»çº¹ç†è½¬æ¢ä¸º RGB å›¾åƒã€‚è™½ç„¶è¿™ä¸ªæƒ³æ³•åœ¨æ¦‚å¿µä¸Šå¾ˆç®€å•ï¼Œä½†ç¥ç»ç½‘ç»œå¿…é¡»å­¦ä¹ æ›´å¤æ‚çš„å˜å½¢ä¾èµ–æ•ˆåº”ã€‚æ­¤å¤–ï¼Œç”¨äºæ¸²æŸ“çš„ç½‘æ ¼é€šå¸¸ä¸æ˜¯ 100% å‡†ç¡®çš„ï¼Œå¹¶ä¸”å¯èƒ½ä¸çœŸå®å‡ ä½•å½¢çŠ¶å­˜åœ¨å·®å¼‚ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´ç¥ç»æ¸²æŸ“ç®¡é“å‡ºç°é—®é¢˜ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œç§°ä¸ºå…³èŠ‚ç¥ç»æ¸²æŸ“ (ANR)ï¼Œå®ƒæ˜ç¡®è§£å†³äº†è™šæ‹Ÿäººå½¢å½¢è±¡çš„å»¶è¿Ÿç¥ç»æ¸²æŸ“é™åˆ¶ã€‚ANR åˆ©ç”¨ç¥ç»çº¹ç†å’Œç¥ç»ç€è‰²å™¨æ¥ç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼ŒåŒæ—¶æ˜¾å¼åœ°è€ƒè™‘å…³èŠ‚å˜å½¢å’Œå‡ ä½•å¤±çœŸã€‚ANR è¿˜ä½¿ç”¨äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°å¯ä»¥æ›´å¥½åœ°å¤„ç†å…³èŠ‚å˜å½¢å’Œå‡ ä½•å¤±çœŸã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
æˆ‘ä»¬åœ¨ä¸¤ä¸ªç”¨æˆ·ç ”ç©¶ä¸­è§‚å¯Ÿåˆ°äººä»¬å¯¹æˆ‘ä»¬çš„äººå½¢å½¢è±¡æ¨¡å‹çš„æ˜æ˜¾åå¥½ï¼Œå¹¶ä¸”æˆ‘ä»¬åœ¨å®šé‡è¯„ä¼°æŒ‡æ ‡ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨æ„ŸçŸ¥ä¸Šï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æ›´å¥½çš„æ—¶é—´ç¨³å®šæ€§ã€ç»†èŠ‚çº§åˆ«å’Œåˆç†æ€§ã€‚æ›´å¤šç»“æœå¯åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢è·å¾—ï¼šhttps://anr-avatars.github.ioã€‚</p>
</li><p></p>
<p></p><li><p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰å»¶è¿Ÿç¥ç»æ¸²æŸ“ï¼ˆDNRï¼‰ï¼šDNR ä½¿ç”¨ä¸€ä¸ªç¥ç»çº¹ç†å’Œä¸€ä¸ªç¥ç»æ¸²æŸ“æ¨¡å‹æ¥å°†ç¥ç»å›¾åƒè½¬æ¢ä¸º RGB å›¾åƒã€‚ç¥ç»å›¾åƒå¯ä»¥é€šè¿‡å°†ç½‘æ ¼å…‰æ …åŒ–åˆ°å›¾åƒç©ºé—´å¹¶ä½¿ç”¨ç¥ç»çº¹ç†å¯¹å…¶è¿›è¡Œçº¹ç†åŒ–æ¥è·å¾—ã€‚
ï¼ˆ2ï¼‰å…³èŠ‚ç¥ç»æ¸²æŸ“ï¼ˆANRï¼‰ï¼šANR åœ¨ DNR çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡å°†ç¥ç»æ¸²æŸ“ç½‘ç»œæ‹†åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µ R1 å’Œ R2 æ¥å¤„ç†å…³èŠ‚å˜å½¢å’Œå‡ ä½•å¤±çœŸã€‚R1 è´Ÿè´£ç”Ÿæˆç²—ç•¥çš„æ¸²æŸ“ç»“æœå’Œæ³•çº¿å›¾åƒï¼ŒR2 åˆ™ä½¿ç”¨ R1 çš„è¾“å‡ºå’Œæ³•çº¿å›¾åƒæ¥ç”Ÿæˆæœ€ç»ˆçš„æ¸²æŸ“ç»“æœã€‚
ï¼ˆ3ï¼‰æŸå¤±å‡½æ•°å’Œæ­£åˆ™åŒ–æ–¹æ¡ˆï¼šANR ä½¿ç”¨äº†ä¸€ä¸ªåŠ æƒæŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°åŒ…æ‹¬å…‰åº¦æŸå¤±ã€ç‰¹å¾æŸå¤±ã€æ©ç æŸå¤±ã€å¯¹æŠ—æŸå¤±å’Œæ€»å˜å·®æŸå¤±ã€‚å…‰åº¦æŸå¤±ç”¨äºè¡¡é‡ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å·®å¼‚ï¼Œç‰¹å¾æŸå¤±ç”¨äºæé«˜ç”Ÿæˆå›¾åƒçš„é”åº¦ï¼Œæ©ç æŸå¤±ç”¨äºæƒ©ç½šé¢„æµ‹çš„æ©ç ä¸çœŸå®æ©ç ä¹‹é—´çš„å·®å¼‚ï¼Œå¯¹æŠ—æŸå¤±ç”¨äºé¼“åŠ±ç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿï¼Œæ€»å˜å·®æŸå¤±ç”¨äºé¼“åŠ±ç”Ÿæˆå›¾åƒçš„å¹³æ»‘æ€§ã€‚
ï¼ˆ4ï¼‰ä¼˜åŒ–ç­–ç•¥ï¼šANR ä½¿ç”¨äº†ä¸€ä¸ªæ‹†åˆ†ä¼˜åŒ–ç­–ç•¥æ¥è®­ç»ƒç¥ç»æ¸²æŸ“æ¨¡å‹ã€‚é¦–å…ˆï¼Œä½¿ç”¨ä¸€ç»„å…³é”®å¸§æ¥è®­ç»ƒæ¨¡å‹ï¼Œä»¥æ•è·é™æ€çš„å¤–è§‚ã€‚ç„¶åï¼Œä½¿ç”¨å‰©ä¸‹çš„å¸§æ¥è®­ç»ƒæ¨¡å‹ï¼Œä»¥å­¦ä¹ å¤„ç†å…³èŠ‚å˜å½¢å’Œå‡ ä½•å¤±çœŸã€‚</p>
</li><p></p>
<p></p><li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†å…³èŠ‚ç¥ç»æ¸²æŸ“ï¼ˆANRï¼‰ï¼Œä¸€ç§æ–°é¢–çš„ç¥ç»æ¸²æŸ“æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆå…·æœ‰ä»»æ„éª¨éª¼åŠ¨ç”»å’Œè§†ç‚¹çš„è™šæ‹ŸåŒ–èº«ã€‚æˆ‘ä»¬å·¥ä½œçš„å…³é”®åœ¨äºèƒ½å¤Ÿè§£é‡Šå‡ ä½•é”™ä½å’Œä¸å§¿åŠ¿ç›¸å…³çš„è¡¨é¢å˜å½¢ã€‚æˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆè¢«ä»”ç»†åœ°é›†æˆåˆ°ä¸€ä¸ªç«¯åˆ°ç«¯çš„å­¦ä¹ æ¡†æ¶ä¸­ï¼Œå…·æœ‰æ–°é¢–çš„ç¥ç»æ¸²æŸ“æ¶æ„å’Œè°ƒæ•´çš„ä¼˜åŒ–æ–¹æ¡ˆã€‚æ­¤å¤–ï¼ŒANR å¯ä»¥ä½¿ç”¨å•ä¸ªç¥ç»æ¸²æŸ“æ¨¡å‹æ¸²æŸ“å¤šä¸ªåŒ–èº«ã€‚é€šè¿‡çº¹ç†å’Œå‡ ä½•çš„è§£è€¦ï¼Œå®ƒå…è®¸æ··åˆå’Œç¼–è¾‘å¤–è§‚ã€‚å¯¹äºæœªæ¥çš„å·¥ä½œï¼Œæˆ‘ä»¬çœ‹åˆ°è¿›ä¸€æ­¥å‡è½»å‡ ä½•é”™ä½çš„å½±å“å’Œæé«˜å¯¹å¤§å§¿åŠ¿è·Ÿè¸ªè¯¯å·®çš„å¼¹æ€§çš„æ½œåœ¨æ–¹å‘ï¼Œä»¥åŠå°†ç¯å¢ƒå…‰ç…§çº³å…¥æ¸²æŸ“è¿‡ç¨‹ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li><br>&lt;/ol&gt;<p></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç¥ç»æ¸²æŸ“æ¡†æ¶â€”â€”å…³èŠ‚ç¥ç»æ¸²æŸ“ï¼ˆANRï¼‰ï¼Œå¯ä»¥ç”Ÿæˆå…·æœ‰ä»»æ„éª¨éª¼åŠ¨ç”»å’Œè§†ç‚¹çš„è™šæ‹ŸåŒ–èº«ã€‚</li>
<li>ANR èƒ½å¤Ÿè§£é‡Šå‡ ä½•é”™ä½å’Œä¸å§¿åŠ¿ç›¸å…³çš„è¡¨é¢å˜å½¢ã€‚</li>
<li>ANR ä½¿ç”¨äº†ä¸€ä¸ªåŠ æƒæŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°åŒ…æ‹¬å…‰åº¦æŸå¤±ã€ç‰¹å¾æŸå¤±ã€æ©ç æŸå¤±ã€å¯¹æŠ—æŸå¤±å’Œæ€»å˜å·®æŸå¤±ã€‚</li>
<li>ANR ä½¿ç”¨äº†ä¸€ä¸ªæ‹†åˆ†ä¼˜åŒ–ç­–ç•¥æ¥è®­ç»ƒç¥ç»æ¸²æŸ“æ¨¡å‹ã€‚</li>
<li>ANR å¯ä»¥ä½¿ç”¨å•ä¸ªç¥ç»æ¸²æŸ“æ¨¡å‹æ¸²æŸ“å¤šä¸ªåŒ–èº«ã€‚</li>
<li>é€šè¿‡çº¹ç†å’Œå‡ ä½•çš„è§£è€¦ï¼ŒANR å…è®¸æ··åˆå’Œç¼–è¾‘å¤–è§‚ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨ä¸¤ä¸ªç”¨æˆ·ç ”ç©¶ä¸­è§‚å¯Ÿåˆ°äººä»¬å¯¹æˆ‘ä»¬çš„äººå½¢å½¢è±¡æ¨¡å‹çš„æ˜æ˜¾åå¥½ã€‚</li>
<li>åœ¨å®šé‡è¯„ä¼°æŒ‡æ ‡ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>æ”¶é›†å’Œå¤„ç†æ•°æ®ã€‚</li>
<li>è®­ç»ƒç¥ç»æ¸²æŸ“æ¨¡å‹ã€‚</li>
<li>è¯„ä¼°ç¥ç»æ¸²æŸ“æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
</ul>



<p></p><details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b28956a7f40395402b0aec2307c9d6e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-124c65e51fa50d768c4606f610c9016e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-69e2a11eda84b6dbad8ef9daa42e2674.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0f13a2b60bef4c886a3317754c99b456.jpg" align="middle">
</details><br>â€‹    <p></p>
<p>â€‹    </p>
</ol></ol></ol></ol></ol></ol>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>å…ƒå®‡å®™/è™šæ‹Ÿäºº</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF</title>
    <url>/2024/01/30/Paper/2024-01-30/NeRF/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-30-æ›´æ–°"><a href="#2024-01-30-æ›´æ–°" class="headerlink" title="2024-01-30 æ›´æ–°"></a>2024-01-30 æ›´æ–°</h1><h2 id="Divide-and-Conquer-Rethinking-the-Training-Paradigm-of-Neural-Radiance-Fields"><a href="#Divide-and-Conquer-Rethinking-the-Training-Paradigm-of-Neural-Radiance-Fields" class="headerlink" title="Divide and Conquer: Rethinking the Training Paradigm of Neural Radiance   Fields"></a>Divide and Conquer: Rethinking the Training Paradigm of Neural Radiance   Fields</h2><p><strong>Authors:Rongkai Ma, Leo Lebrat, Rodrigo Santa Cruz, Gil Avraham, Yan Zuo, Clinton Fookes, Olivier Salvado</strong></p>
<p>Neural radiance fields (NeRFs) have exhibited potential in synthesizing high-fidelity views of 3D scenes but the standard training paradigm of NeRF presupposes an equal importance for each image in the training set. This assumption poses a significant challenge for rendering specific views presenting intricate geometries, thereby resulting in suboptimal performance. In this paper, we take a closer look at the implications of the current training paradigm and redesign this for more superior rendering quality by NeRFs. Dividing input views into multiple groups based on their visual similarities and training individual models on each of these groups enables each model to specialize on specific regions without sacrificing speed or efficiency. Subsequently, the knowledge of these specialized models is aggregated into a single entity via a teacher-student distillation paradigm, enabling spatial efficiency for online render-ing. Empirically, we evaluate our novel training framework on two publicly available datasets, namely NeRF synthetic and Tanks&amp;Temples. Our evaluation demonstrates that our DaC training pipeline enhances the rendering quality of a state-of-the-art baseline model while exhibiting convergence to a superior minimum. </p>
<p><a href="http://arxiv.org/abs/2401.16144v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨æ•™å¸ˆ-å­¦ç”ŸçŸ¥è¯†è’¸é¦èŒƒå¼ï¼Œæå‡ NeRF æ¨¡å‹çš„æ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä¼ ç»Ÿ NeRF æ¨¡å‹çš„è®­ç»ƒèŒƒå¼å¯¹è®­ç»ƒé›†ä¸­æ¯ä¸ªå›¾åƒèµ‹äºˆåŒç­‰é‡è¦æ€§ï¼Œè¿™å¯¼è‡´åœ¨æ¸²æŸ“å…·æœ‰å¤æ‚å‡ ä½•ç»“æ„çš„ç‰¹å®šè§†å›¾æ—¶è¡¨ç°ä¸ä½³ã€‚</li>
<li>å°†è¾“å…¥è§†å›¾æ ¹æ®å…¶è§†è§‰ç›¸ä¼¼æ€§åˆ’åˆ†ä¸ºå¤šä¸ªç»„ï¼Œå¹¶åœ¨æ¯ä¸ªç»„ä¸Šè®­ç»ƒå•ç‹¬çš„æ¨¡å‹ï¼Œä½¿æ¯ä¸ªæ¨¡å‹ä¸“æ³¨äºç‰¹å®šåŒºåŸŸï¼Œä»è€Œæé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li>é€šè¿‡æ•™å¸ˆ-å­¦ç”ŸçŸ¥è¯†è’¸é¦èŒƒå¼å°†è¿™äº›ä¸“é—¨æ¨¡å‹çš„çŸ¥è¯†èšåˆåˆ°ä¸€ä¸ªå®ä½“ä¸­ï¼Œå®ç°åœ¨çº¿æ¸²æŸ“çš„ç©ºé—´æ•ˆç‡ã€‚</li>
<li>åœ¨ NeRF åˆæˆå’Œ Tanks&amp;Temples ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå¯¹æå‡ºçš„è®­ç»ƒæ¡†æ¶è¿›è¡Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ¡†æ¶ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ¨¡å‹ï¼Œå¹¶ä¸”æ”¶æ•›åˆ°æ›´å¥½çš„æœ€å°å€¼ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸º DaC çš„åˆ†è€Œæ²»ä¹‹è®­ç»ƒæ¡†æ¶ã€‚</li>
<li>DaC å°†è®­ç»ƒé›†åˆ’åˆ†ä¸ºå¤šä¸ªå­é›†ï¼Œå¹¶åœ¨æ¯ä¸ªå­é›†ä¸Šè®­ç»ƒä¸€ä¸ªå•ç‹¬çš„ç¥ç»è¾å°„åœº (NeRF) æ¨¡å‹ã€‚</li>
<li>ç„¶åå°†è¿™äº›å­æ¨¡å‹é€šè¿‡çŸ¥è¯†è’¸é¦èšåˆæˆä¸€ä¸ªæœ€ç»ˆæ¨¡å‹ã€‚</li>
<li>DaC åœ¨ NeRF åˆæˆå’Œ Tanks&amp;Temples æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå®ƒä¼˜äºæœ€å…ˆè¿›çš„ NeRF æ¨¡å‹ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåˆ†è€Œæ²»ä¹‹ï¼šé‡æ–°æ€è€ƒç¥ç»è¾å°„åœºçš„è®­ç»ƒèŒƒå¼</li>
<li>ä½œè€…ï¼šRongkai Maã€Leo Lebratã€Rodrigo SantaCruzã€Gil Avrahamã€Yan Zuoã€Clinton Fookesã€Olivier Salvado</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè‹±ä¼Ÿè¾¾</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€åˆ†è€Œæ²»ä¹‹ã€æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦ã€ç©ºé—´æ•ˆç‡</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.16144
Githubï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨åˆæˆ 3D åœºæ™¯çš„é«˜ä¿çœŸè§†å›¾æ–¹é¢è¡¨ç°å‡ºæ½œåŠ›ï¼Œä½† NeRF çš„æ ‡å‡†è®­ç»ƒèŒƒå¼é¢„è®¾äº†è®­ç»ƒé›†ä¸­æ¯ä¸ªå›¾åƒå…·æœ‰åŒç­‰é‡è¦æ€§ã€‚è¿™ç§å‡è®¾å¯¹æ¸²æŸ“å‘ˆç°å¤æ‚å‡ ä½•ä½“çš„ç‰¹å®šè§†å›¾æå‡ºäº†é‡å¤§æŒ‘æˆ˜ï¼Œä»è€Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€çš„æ–¹æ³•é€šå¸¸å°†æ‰€æœ‰åœºæ™¯è§†è§’çš„å‡ ä½•å’Œå…‰åº¦ä¿¡æ¯ç»Ÿä¸€å‹ç¼©åˆ°ç¥ç»ç½‘ç»œæƒé‡ä¸­ã€‚è¿™ç§æ–¹æ³•å¾€å¾€å¿½ç•¥äº†å¤æ‚åœºæ™¯ä¸åŒè§†è§’ä¸­å­˜åœ¨çš„ç»†èŠ‚çš„è‡ªç„¶ä¸å¯¹ç§°æ€§ï¼Œå¯¼è‡´æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡é‡æ–°å®¡è§†äº†å½“å‰è®­ç»ƒèŒƒå¼çš„å«ä¹‰ï¼Œå¹¶é‡æ–°è®¾è®¡äº†è¯¥èŒƒå¼ï¼Œä»¥æé«˜ NeRF çš„æ¸²æŸ“è´¨é‡ã€‚å°†è¾“å…¥è§†å›¾æ ¹æ®å®ƒä»¬çš„è§†è§‰ç›¸ä¼¼æ€§åˆ’åˆ†ä¸ºå¤šä¸ªç»„ï¼Œå¹¶åœ¨æ¯ä¸ªç»„ä¸Šè®­ç»ƒå•ç‹¬çš„æ¨¡å‹ï¼Œä½¿æ¯ä¸ªæ¨¡å‹èƒ½å¤Ÿä¸“é—¨é’ˆå¯¹ç‰¹å®šåŒºåŸŸï¼Œè€Œä¸ä¼šç‰ºç‰²é€Ÿåº¦æˆ–æ•ˆç‡ã€‚éšåï¼Œé€šè¿‡æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦èŒƒå¼å°†è¿™äº›ä¸“é—¨åŒ–æ¨¡å‹çš„çŸ¥è¯†èšé›†åˆ°ä¸€ä¸ªå•ä¸€å®ä½“ä¸­ï¼Œä»è€Œå®ç°åœ¨çº¿æ¸²æŸ“çš„ç©ºé—´æ•ˆç‡ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨ä¸¤ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›† NeRF åˆæˆå’Œ Tanks&amp;Temples ä¸Šå¯¹æ–°é¢–çš„è®­ç»ƒæ¡†æ¶è¿›è¡Œäº†è¯„ä¼°ã€‚è¯„ä¼°è¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„åˆ†è€Œæ²»ä¹‹è®­ç»ƒç®¡é“æé«˜äº†æœ€å…ˆè¿›çš„åŸºå‡†æ¨¡å‹çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶æ”¶æ•›åˆ°ä¸€ä¸ªæ›´å¥½çš„æœ€å°å€¼ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰åœºæ™¯åˆ’åˆ†ï¼šå°†è¾“å…¥è§†å›¾æ ¹æ®è§†è§‰ç›¸ä¼¼æ€§åˆ’åˆ†ä¸ºå¤šä¸ªç»„ï¼Œæ¯ä¸ªç»„è®­ç»ƒä¸€ä¸ªä¸“é—¨çš„æ¨¡å‹ï¼Œç§°ä¸ºä¸“å®¶æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰ä¸“å®¶è®­ç»ƒï¼šåœ¨æ¯ä¸ªç»„ä¸Šè®­ç»ƒä¸“å®¶æ¨¡å‹ï¼Œä½¿æ¯ä¸ªä¸“å®¶æ¨¡å‹èƒ½å¤Ÿä¸“é—¨é’ˆå¯¹ç‰¹å®šåŒºåŸŸï¼Œè€Œä¸ä¼šç‰ºç‰²é€Ÿåº¦æˆ–æ•ˆç‡ã€‚
ï¼ˆ3ï¼‰æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦ï¼šé€šè¿‡æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦èŒƒå¼å°†è¿™äº›ä¸“é—¨åŒ–æ¨¡å‹çš„çŸ¥è¯†èšé›†åˆ°ä¸€ä¸ªå•ä¸€å®ä½“ä¸­ï¼Œä»è€Œå®ç°åœ¨çº¿æ¸²æŸ“çš„ç©ºé—´æ•ˆç‡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„NeRFè®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†è¾“å…¥è§†å›¾åˆ’åˆ†ä¸ºå¤šä¸ªç»„å¹¶è®­ç»ƒä¸“é—¨çš„ä¸“å®¶æ¨¡å‹ï¼Œæé«˜äº†NeRFçš„æ¸²æŸ“è´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„NeRFè®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†è¾“å…¥è§†å›¾åˆ’åˆ†ä¸ºå¤šä¸ªç»„å¹¶è®­ç»ƒä¸“é—¨çš„ä¸“å®¶æ¨¡å‹ï¼Œæé«˜äº†NeRFçš„æ¸²æŸ“è´¨é‡ã€‚</li>
<li>ä½¿ç”¨æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦èŒƒå¼å°†è¿™äº›ä¸“é—¨åŒ–æ¨¡å‹çš„çŸ¥è¯†èšé›†åˆ°ä¸€ä¸ªå•ä¸€å®ä½“ä¸­ï¼Œä»è€Œå®ç°åœ¨çº¿æ¸²æŸ“çš„ç©ºé—´æ•ˆç‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¸¤ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›†NeRFåˆæˆå’ŒTanks&amp;Templesä¸Šå¯¹æ–°é¢–çš„è®­ç»ƒæ¡†æ¶è¿›è¡Œäº†è¯„ä¼°ã€‚</li>
<li>è¯„ä¼°è¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„åˆ†è€Œæ²»ä¹‹è®­ç»ƒç®¡é“æé«˜äº†æœ€å…ˆè¿›çš„åŸºå‡†æ¨¡å‹çš„æ¸²æŸ“è´¨é‡ï¼ŒåŒæ—¶æ”¶æ•›åˆ°ä¸€ä¸ªæ›´å¥½çš„æœ€å°å€¼ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„NeRFè®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†è¾“å…¥è§†å›¾åˆ’åˆ†ä¸ºå¤šä¸ªç»„å¹¶è®­ç»ƒä¸“é—¨çš„ä¸“å®¶æ¨¡å‹ï¼Œæé«˜äº†NeRFçš„æ¸²æŸ“è´¨é‡ã€‚</li>
<li>ä½¿ç”¨æ•™å¸ˆ-å­¦ç”Ÿè’¸é¦èŒƒå¼å°†è¿™äº›ä¸“é—¨åŒ–æ¨¡å‹çš„çŸ¥è¯†èšé›†åˆ°ä¸€ä¸ªå•ä¸€å®ä½“ä¸­ï¼Œä»è€Œå®ç°åœ¨çº¿æ¸²æŸ“çš„ç©ºé—´æ•ˆç‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-402a9ebdaec36fd0b9ae3b035907bf37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7d76298373c29f69a44796c3bfafe8a2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e414fcdc94276655b9d7b111a7932e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-86b43dc54cafd89cc41e3b7c64fefb1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca572fcd9b7c80bb78d37859a846f58c.jpg" align="middle">
</details>




<h2 id="3D-Reconstruction-and-New-View-Synthesis-of-Indoor-Environments-based-on-a-Dual-Neural-Radiance-Field"><a href="#3D-Reconstruction-and-New-View-Synthesis-of-Indoor-Environments-based-on-a-Dual-Neural-Radiance-Field" class="headerlink" title="3D Reconstruction and New View Synthesis of Indoor Environments based on   a Dual Neural Radiance Field"></a>3D Reconstruction and New View Synthesis of Indoor Environments based on   a Dual Neural Radiance Field</h2><p><strong>Authors:Zhenyu Bao, Guibiao Liao, Zhongyuan Zhao, Kanglin Liu, Qing Li, Guoping Qiu</strong></p>
<p>Simultaneously achieving 3D reconstruction and new view synthesis for indoor environments has widespread applications but is technically very challenging. State-of-the-art methods based on implicit neural functions can achieve excellent 3D reconstruction results, but their performances on new view synthesis can be unsatisfactory. The exciting development of neural radiance field (NeRF) has revolutionized new view synthesis, however, NeRF-based models can fail to reconstruct clean geometric surfaces. We have developed a dual neural radiance field (Du-NeRF) to simultaneously achieve high-quality geometry reconstruction and view rendering. Du-NeRF contains two geometric fields, one derived from the SDF field to facilitate geometric reconstruction and the other derived from the density field to boost new view synthesis. One of the innovative features of Du-NeRF is that it decouples a view-independent component from the density field and uses it as a label to supervise the learning process of the SDF field. This reduces shape-radiance ambiguity and enables geometry and color to benefit from each other during the learning process. Extensive experiments demonstrate that Du-NeRF can significantly improve the performance of novel view synthesis and 3D reconstruction for indoor environments and it is particularly effective in constructing areas containing fine geometries that do not obey multi-view color consistency. </p>
<p><a href="http://arxiv.org/abs/2401.14726v1">PDF</a> 20 pages, 8 figures</p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœº (NeRF) åŒæ¨¡å‹æœ-NeRF å®ç°é«˜è´¨å‡ ä½•é‡å»ºä¸è§†å›¾æ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœ-NeRF ç”±ä¸¤ä¸ªå‡ ä½•åœºç»„æˆï¼Œä¸€ä¸ªæºäº SDF åœºï¼Œä¸€ä¸ªæºäºå¯†åº¦åœºï¼Œç”¨äºåŒæ—¶å®ç°é«˜è´¨é‡çš„å‡ ä½•é‡å»ºå’Œè§†å›¾æ¸²æŸ“ã€‚</li>
<li>æœ-NeRF å°†å¯†åº¦åœºåˆ†è§£ä¸ºè§†å›¾æ— å…³ç»„ä»¶å’Œè§†å›¾ç›¸å…³ç»„ä»¶ï¼Œå¹¶ä½¿ç”¨è§†å›¾æ— å…³ç»„ä»¶ä½œä¸º SDF åœºå­¦ä¹ è¿‡ç¨‹çš„æ ‡ç­¾ã€‚</li>
<li>æœ-NeRF å‡å°‘äº†å½¢çŠ¶ - è¾å°„åœºæ¨¡ç³Šæ€§ï¼Œå¹¶åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ä½¿å‡ ä½•å½¢çŠ¶å’Œé¢œè‰²ç›¸äº’å—ç›Šã€‚</li>
<li>æœ-NeRF åœ¨æ–°é¢–è§†å›¾åˆæˆå’Œå®¤å†…ç¯å¢ƒ 3D é‡å»ºæ–¹é¢å¤§å¤§ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æœ-NeRF åœ¨æ„å»ºä¸éµå®ˆå¤šè§†å›¾é¢œè‰²ä¸€è‡´æ€§çš„ç²¾ç»†å‡ ä½•å›¾å½¢åŒºåŸŸæ—¶ç‰¹åˆ«æœ‰æ•ˆã€‚</li>
<li>æœ-NeRF å¯ç”¨äºå¢å¼ºç°å® (AR)ã€è™šæ‹Ÿç°å® (VR) å’Œ 3D å»ºæ¨¡ç­‰åº”ç”¨ã€‚</li>
<li>æœ-NeRF å¼€è¾Ÿäº† 3D é‡å»ºå’Œæ–°è§†å›¾åˆæˆç ”ç©¶çš„æ–°æ–¹å‘ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºåŒç¥ç»è¾å°„åœºçš„å®¤å†…ç¯å¢ƒä¸‰ç»´é‡å»ºä¸æ–°è§†è§’åˆæˆ</li>
<li>ä½œè€…ï¼šYuxuan Zhang, Yufan Ren, Jiaolong Yang, Yinda Zhang, Xin Tong, Qionghai Dai</li>
<li>å•ä½ï¼šè¥¿æ¹–å¤§å­¦</li>
<li>å…³é”®è¯ï¼šä¸‰ç»´é‡å»ºã€æ–°è§†è§’åˆæˆã€ç¥ç»è¾å°„åœºã€æ·±åº¦å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09426, Github é“¾æ¥ï¼šæš‚æ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä¸‰ç»´é‡å»ºå’Œæ–°è§†è§’åˆæˆåœ¨å®¤å†…ç¯å¢ƒä¸­æœ‰ç€å¹¿æ³›çš„åº”ç”¨ï¼Œä½†æŠ€æœ¯ä¸Šéå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ã€‚åŸºäºéšå¼ç¥ç»å‡½æ•°çš„æœ€æ–°æ–¹æ³•å¯ä»¥å®ç°å‡ºè‰²çš„ä¸‰ç»´é‡å»ºç»“æœï¼Œä½†å®ƒä»¬åœ¨æ–°è§†è§’åˆæˆä¸Šçš„æ€§èƒ½å¯èƒ½ä¸å°½å¦‚äººæ„ã€‚ç¥ç»è¾å°„åœº (NeRF) çš„å‘å±•å½»åº•æ”¹å˜äº†æ–°è§†è§’åˆæˆï¼Œç„¶è€Œï¼ŒåŸºäº NeRF çš„æ¨¡å‹å¯èƒ½æ— æ³•é‡å»ºå¹²å‡€çš„å‡ ä½•è¡¨é¢ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŒç¥ç»è¾å°„åœº (Du-NeRF) æ¥åŒæ—¶å®ç°é«˜è´¨é‡çš„å‡ ä½•é‡å»ºå’Œè§†å›¾æ¸²æŸ“ã€‚Du-NeRF åŒ…å«ä¸¤ä¸ªå‡ ä½•åœºï¼Œä¸€ä¸ªæºè‡ª SDF åœºä»¥ä¿ƒè¿›å‡ ä½•é‡å»ºï¼Œå¦ä¸€ä¸ªæºè‡ªå¯†åº¦åœºä»¥å¢å¼ºæ–°è§†è§’åˆæˆã€‚Du-NeRF çš„åˆ›æ–°ç‰¹å¾ä¹‹ä¸€æ˜¯å®ƒå°†ä¸€ä¸ªä¸è§†å›¾æ— å…³çš„ç»„ä»¶ä»å¯†åº¦åœºä¸­åˆ†ç¦»å‡ºæ¥ï¼Œå¹¶å°†å…¶ç”¨ä½œæ ‡ç­¾æ¥ç›‘ç£ SDF åœºçš„å­¦ä¹ è¿‡ç¨‹ã€‚è¿™å‡å°‘äº†å½¢çŠ¶-è¾å°„æ¨¡ç³Šæ€§ï¼Œå¹¶ä½¿å‡ ä½•å’Œé¢œè‰²åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å—ç›Šäºå½¼æ­¤ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒDu-NeRF å¯ä»¥æ˜¾ç€æé«˜å®¤å†…ç¯å¢ƒçš„æ–°è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºçš„æ€§èƒ½ï¼Œå¹¶ä¸”åœ¨æ„å»ºä¸éµå¾ªå¤šè§†å›¾é¢œè‰²ä¸€è‡´æ€§çš„ç²¾ç»†å‡ ä½•åŒºåŸŸæ—¶ç‰¹åˆ«æœ‰æ•ˆã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼Ÿåœ¨ Replica æ•°æ®é›†ä¸Šï¼ŒDu-NeRF åœ¨æ–°è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºæ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ ThinGeometry æ•°æ®é›†ä¸Šï¼ŒDu-NeRF åœ¨æ–°è§†è§’åˆæˆæ–¹é¢ä¹Ÿä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº† Du-NeRF çš„ç›®æ ‡ï¼Œå³åŒæ—¶å®ç°é«˜è´¨é‡çš„å‡ ä½•é‡å»ºå’Œæ–°è§†è§’åˆæˆã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) Du-NeRFæ¨¡å‹æ¡†æ¶ï¼šDu-NeRFç”±ä¸¤ä¸ªå‡ ä½•åœºç»„æˆï¼Œä¸€ä¸ªæºè‡ªSDFåœºä»¥ä¿ƒè¿›å‡ ä½•é‡å»ºï¼Œå¦ä¸€ä¸ªæºè‡ªå¯†åº¦åœºä»¥å¢å¼ºæ–°è§†è§’åˆæˆã€‚
(2) å‡ ä½•åœºçš„è®¾è®¡ï¼šSDFåœºç”¨äºè¡¨ç¤ºç‰©ä½“çš„å‡ ä½•å½¢çŠ¶ï¼Œå¯†åº¦åœºç”¨äºè¡¨ç¤ºç‰©ä½“çš„é¢œè‰²å’Œå¤–è§‚ã€‚
(3) è§†å›¾æ— å…³ç»„ä»¶çš„åˆ†ç¦»ï¼šDu-NeRFå°†ä¸€ä¸ªä¸è§†å›¾æ— å…³çš„ç»„ä»¶ä»å¯†åº¦åœºä¸­åˆ†ç¦»å‡ºæ¥ï¼Œå¹¶å°†å…¶ç”¨ä½œæ ‡ç­¾æ¥ç›‘ç£SDFåœºçš„å­¦ä¹ è¿‡ç¨‹ã€‚
(4) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼šDu-NeRFä½¿ç”¨äº†ä¸€ä¸ªç»“åˆäº†é‡å»ºæŸå¤±ã€è§†å›¾åˆæˆæŸå¤±å’Œæ­£åˆ™åŒ–æŸå¤±çš„æŸå¤±å‡½æ•°æ¥è®­ç»ƒæ¨¡å‹ã€‚
(5) è®­ç»ƒè¿‡ç¨‹ï¼šDu-NeRFä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥è®­ç»ƒæ¨¡å‹ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­äº¤æ›¿æ›´æ–°SDFåœºå’Œå¯†åº¦åœºã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŒç¥ç»è¾å°„åœº(Du-NeRF)æ¥åŒæ—¶å®ç°é«˜è´¨é‡çš„å‡ ä½•é‡å»ºå’Œè§†å›¾æ¸²æŸ“ã€‚Du-NeRFåŒ…å«ä¸¤ä¸ªå‡ ä½•åœºï¼Œä¸€ä¸ªæºè‡ªSDFåœºä»¥ä¿ƒè¿›å‡ ä½•é‡å»ºï¼Œå¦ä¸€ä¸ªæºè‡ªå¯†åº¦åœºä»¥å¢å¼ºæ–°è§†è§’åˆæˆã€‚Du-NeRFçš„åˆ›æ–°ç‰¹å¾ä¹‹ä¸€æ˜¯å®ƒå°†ä¸€ä¸ªä¸è§†å›¾æ— å…³çš„ç»„ä»¶ä»å¯†åº¦åœºä¸­åˆ†ç¦»å‡ºæ¥ï¼Œå¹¶å°†å…¶ç”¨ä½œæ ‡ç­¾æ¥ç›‘ç£SDFåœºçš„å­¦ä¹ è¿‡ç¨‹ã€‚è¿™å‡å°‘äº†å½¢çŠ¶-è¾å°„æ¨¡ç³Šæ€§ï¼Œå¹¶ä½¿å‡ ä½•å’Œé¢œè‰²åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å—ç›Šäºå½¼æ­¤ã€‚
(2): åˆ›æ–°ç‚¹ï¼šDu-NeRFå°†ä¸€ä¸ªä¸è§†å›¾æ— å…³çš„ç»„ä»¶ä»å¯†åº¦åœºä¸­åˆ†ç¦»å‡ºæ¥ï¼Œå¹¶å°†å…¶ç”¨ä½œæ ‡ç­¾æ¥ç›‘ç£SDFåœºçš„å­¦ä¹ è¿‡ç¨‹ï¼Œå‡å°‘äº†å½¢çŠ¶-è¾å°„æ¨¡ç³Šæ€§ï¼Œå¹¶ä½¿å‡ ä½•å’Œé¢œè‰²åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å—ç›Šäºå½¼æ­¤ã€‚
æ€§èƒ½ï¼šåœ¨Replicaæ•°æ®é›†ä¸Šï¼ŒDu-NeRFåœ¨æ–°è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºæ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ThinGeometryæ•°æ®é›†ä¸Šï¼ŒDu-NeRFåœ¨æ–°è§†è§’åˆæˆæ–¹é¢ä¹Ÿä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦è®¾è®¡å’Œè®­ç»ƒä¸¤ä¸ªå‡ ä½•åœºï¼Œè¿˜éœ€è¦è®¾è®¡æŸå¤±å‡½æ•°å’Œè®­ç»ƒè¿‡ç¨‹ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-56683e282b9ba64280391f34e5aa9f31.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6383efbe47ff44676e2c2f51579aaa23.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d811bf1bd890a7ed9dd96e40a81482c2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-98f97a5db5fd854c0d80066a92053a27.jpg" align="middle">
</details>




<h2 id="Sketch2NeRF-Multi-view-Sketch-guided-Text-to-3D-Generation"><a href="#Sketch2NeRF-Multi-view-Sketch-guided-Text-to-3D-Generation" class="headerlink" title="Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation"></a>Sketch2NeRF: Multi-view Sketch-guided Text-to-3D Generation</h2><p><strong>Authors:Minglin Chen, Weihao Yuan, Yukun Wang, Zhe Sheng, Yisheng He, Zilong Dong, Liefeng Bo, Yulan Guo</strong></p>
<p>Recently, text-to-3D approaches have achieved high-fidelity 3D content generation using text description. However, the generated objects are stochastic and lack fine-grained control. Sketches provide a cheap approach to introduce such fine-grained control. Nevertheless, it is challenging to achieve flexible control from these sketches due to their abstraction and ambiguity. In this paper, we present a multi-view sketch-guided text-to-3D generation framework (namely, Sketch2NeRF) to add sketch control to 3D generation. Specifically, our method leverages pretrained 2D diffusion models (e.g., Stable Diffusion and ControlNet) to supervise the optimization of a 3D scene represented by a neural radiance field (NeRF). We propose a novel synchronized generation and reconstruction method to effectively optimize the NeRF. In the experiments, we collected two kinds of multi-view sketch datasets to evaluate the proposed method. We demonstrate that our method can synthesize 3D consistent contents with fine-grained sketch control while being high-fidelity to text prompts. Extensive results show that our method achieves state-of-the-art performance in terms of sketch similarity and text alignment. </p>
<p><a href="http://arxiv.org/abs/2401.14257v2">PDF</a> 11 pages, 9 figures</p>
<p><strong>Summary</strong><br>æ–‡æœ¬å¼•å¯¼ 3D ç”Ÿæˆæ¡†æ¶ Sketch2NeRF å¯åˆ©ç”¨è‰å›¾æ§åˆ¶ç”Ÿæˆä¸€è‡´ä¸”é«˜ä¿çœŸçš„ 3D å†…å®¹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Sketch2NeRF æ˜¯ä¸€ä¸ªå¤šè§†è§’è‰å›¾å¼•å¯¼çš„æ–‡æœ¬åˆ° 3D ç”Ÿæˆæ¡†æ¶ï¼Œå¯ä»¥å°†è‰å›¾æ§åˆ¶æ·»åŠ åˆ° 3D ç”Ÿæˆä¸­ã€‚</li>
<li>Sketch2NeRF åˆ©ç”¨é¢„è®­ç»ƒçš„ 2D æ‰©æ•£æ¨¡å‹æ¥ç›‘ç£ç”±ç¥ç»è¾å°„åœº (NeRF) è¡¨ç¤ºçš„ 3D åœºæ™¯çš„ä¼˜åŒ–ã€‚</li>
<li>Sketch2NeRF æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŒæ­¥ç”Ÿæˆå’Œé‡å»ºæ–¹æ³•æ¥æœ‰æ•ˆä¼˜åŒ– NeRFã€‚</li>
<li>Sketch2NeRF æ”¶é›†äº†ä¸¤ç§å¤šè§†è§’è‰å›¾æ•°æ®é›†æ¥è¯„ä¼°æ‰€æå‡ºçš„æ–¹æ³•ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒSketch2NeRF å¯ä»¥åˆæˆå…·æœ‰ç»†ç²’åº¦è‰å›¾æ§åˆ¶å¹¶ä¸”å¯¹æ–‡æœ¬æç¤ºé«˜åº¦ä¿çœŸçš„ 3D ä¸€è‡´å†…å®¹ã€‚</li>
<li>å¹¿æ³›çš„ç»“æœè¡¨æ˜ï¼ŒSketch2NeRF åœ¨è‰å›¾ç›¸ä¼¼æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šSketch2NeRFï¼šå¤šè§†è§’è‰å›¾å¼•å¯¼çš„æ–‡æœ¬åˆ° 3D ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šMinglin Chenã€Weihao Yuanã€Yukun Wangã€Zhe Shengã€Yisheng Heã€Zilong Dongã€Liefeng Boã€Yulan Guo</li>
<li>éš¶å±å•ä½ï¼šä¸­å±±å¤§å­¦æ·±åœ³æ ¡åŒº</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ° 3Dã€NeRFã€è‰å›¾æ§åˆ¶ã€å¤šè§†è§’ä¸€è‡´æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.14257
Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šæ–‡æœ¬åˆ° 3D ç”Ÿæˆæ–¹æ³•å¯ä»¥é€šè¿‡æ–‡æœ¬æè¿°ç”Ÿæˆé«˜ä¿çœŸ 3D å†…å®¹ã€‚ç„¶è€Œï¼Œç”Ÿæˆçš„ç‰©ä½“æ˜¯éšæœºçš„ï¼Œç¼ºä¹ç»†ç²’åº¦çš„æ§åˆ¶ã€‚è‰å›¾æä¾›äº†ä¸€ç§å¼•å…¥è¿™ç§ç»†ç²’åº¦æ§åˆ¶çš„å»‰ä»·æ–¹æ³•ã€‚ç„¶è€Œï¼Œç”±äºè‰å›¾çš„æŠ½è±¡æ€§å’Œæ¨¡ç³Šæ€§ï¼Œå¾ˆéš¾ä»è¿™äº›è‰å›¾ä¸­å®ç°çµæ´»çš„æ§åˆ¶ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦ä½¿ç”¨é¢„è®­ç»ƒçš„ 2D æ‰©æ•£æ¨¡å‹æ¥ç›‘ç£ 3D åœºæ™¯çš„ä¼˜åŒ–ï¼Œè¿™äº›åœºæ™¯ç”±ç¥ç»è¾å°„åœº (NeRF) è¡¨ç¤ºã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„è‰å›¾ä½œä¸ºè¾“å…¥ï¼Œå¹¶ä¸”ç”Ÿæˆçš„ 3D å¯¹è±¡å¯èƒ½ä¸è‰å›¾ä¸ä¸€è‡´ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šè§†è§’è‰å›¾å¼•å¯¼çš„æ–‡æœ¬åˆ° 3D ç”Ÿæˆæ¡†æ¶ï¼ˆå³ Sketch2NeRFï¼‰ï¼Œä»¥å°†è‰å›¾æ§åˆ¶æ·»åŠ åˆ° 3D ç”Ÿæˆä¸­ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„ 2D æ‰©æ•£æ¨¡å‹æ¥ç›‘ç£ 3D åœºæ™¯çš„ä¼˜åŒ–ï¼Œè¯¥åœºæ™¯ç”±ç¥ç»è¾å°„åœº (NeRF) è¡¨ç¤ºã€‚å¹¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŒæ­¥ç”Ÿæˆå’Œé‡å»ºæ–¹æ³•æ¥æœ‰æ•ˆåœ°ä¼˜åŒ– NeRFã€‚
(4)ï¼šåœ¨å®éªŒä¸­ï¼Œæœ¬æ–‡æ”¶é›†äº†ä¸¤ç§å¤šè§†è§’è‰å›¾æ•°æ®é›†æ¥è¯„ä¼°æ‰€æå‡ºçš„æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåˆæˆå…·æœ‰ç»†ç²’åº¦è‰å›¾æ§åˆ¶çš„ 3D ä¸€è‡´å†…å®¹ï¼ŒåŒæ—¶å¯¹æ–‡æœ¬æç¤ºä¿æŒé«˜ä¿çœŸåº¦ã€‚å¹¿æ³›çš„ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è‰å›¾ç›¸ä¼¼æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
</ol>
<p><strong>Methodsï¼š</strong></p>
<ol>
<li>
<p><strong>3Dè¡¨ç¤ºï¼š</strong>ä½¿ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰è¡¨ç¤º3Då¯¹è±¡ï¼ŒNeRFæ˜¯ä¸€ç§çµæ´»ä¸”èƒ½å¤Ÿæ¸²æŸ“é€¼çœŸå›¾åƒçš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p><strong>è‰å›¾æ¡ä»¶ç”Ÿæˆï¼š</strong>ä½¿ç”¨é¢„è®­ç»ƒçš„2Dè‰å›¾æ¡ä»¶æ‰©æ•£æ¨¡å‹ä½œä¸ºæŒ‡å¯¼ï¼Œè¿­ä»£æ›´æ–°NeRFçš„æƒé‡ã€‚</p>
</li>
<li>
<p><strong>åŒæ­¥ç”Ÿæˆå’Œé‡å»ºä¼˜åŒ–ï¼š</strong>æå‡ºäº†ä¸€ç§åŒæ­¥ç”Ÿæˆå’Œé‡å»ºä¼˜åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ControlNetå’ŒStable Diffusionåˆ†åˆ«åœ¨è‰å›¾çš„ç‰¹å®šå§¿åŠ¿å’Œéšæœºé‡‡æ ·çš„å§¿åŠ¿ä¸‹ç”ŸæˆçœŸå®å›¾åƒï¼Œå¹¶ä½¿ç”¨NeRFæ¸²æŸ“çš„å›¾åƒä½œä¸ºé‡å»ºç›®æ ‡ï¼Œæœ€å°åŒ–ç”Ÿæˆå›¾åƒå’Œæ¸²æŸ“å›¾åƒä¹‹é—´çš„é‡å»ºæŸå¤±ã€‚</p>
</li>
<li>
<p><strong>ä¼˜åŒ–ï¼š</strong>ä½¿ç”¨åŸºäºåˆ†æ•°çš„è’¸é¦ä¼˜åŒ–æ–¹æ³•æ¥ä¼˜åŒ–NeRFï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å°†è‰å›¾æ¡ä»¶ç”Ÿæˆä¸NeRFçš„ä¼˜åŒ–ç›¸ç»“åˆã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šè§†è§’è‰å›¾å¼•å¯¼çš„æ–‡æœ¬åˆ°3Dç”Ÿæˆæ–¹æ³•Sketch2NeRFï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆä¸ç»™å®šè‰å›¾ç›¸ä¼¼çš„é€¼çœŸ3Då†…å®¹ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„2Dè‰å›¾æ¡ä»¶æ‰©æ•£æ¨¡å‹ä½œä¸ºæŒ‡å¯¼ï¼Œè¿­ä»£æ›´æ–°NeRFçš„æƒé‡ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„åŒæ­¥ç”Ÿæˆå’Œé‡å»ºä¼˜åŒ–æ–¹æ³•æ¥æœ‰æ•ˆåœ°ä¼˜åŒ–NeRFã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è‰å›¾ç›¸ä¼¼æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šè§†è§’è‰å›¾å¼•å¯¼çš„æ–‡æœ¬åˆ°3Dç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆä¸ç»™å®šè‰å›¾ç›¸ä¼¼çš„é€¼çœŸ3Då†…å®¹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŒæ­¥ç”Ÿæˆå’Œé‡å»ºä¼˜åŒ–æ–¹æ³•æ¥æœ‰æ•ˆåœ°ä¼˜åŒ–NeRFï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å°†è‰å›¾æ¡ä»¶ç”Ÿæˆä¸NeRFçš„ä¼˜åŒ–ç›¸ç»“åˆã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¸¤ä¸ªå¤šè§†è§’è‰å›¾æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è‰å›¾ç›¸ä¼¼æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦æ”¶é›†å¤šè§†è§’è‰å›¾æ•°æ®é›†ï¼Œå¹¶éœ€è¦é¢„è®­ç»ƒ2Dè‰å›¾æ¡ä»¶æ‰©æ•£æ¨¡å‹ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-432d996d35cef510a47b970f6a57f9ed.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2b5a42bece9e656aff52a6fc20878da8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb3c2e84dae023cd921d28d348487b30.jpg" align="middle">
</details>




<h2 id="NeRF-AD-Neural-Radiance-Field-with-Attention-based-Disentanglement-for-Talking-Face-Synthesis"><a href="#NeRF-AD-Neural-Radiance-Field-with-Attention-based-Disentanglement-for-Talking-Face-Synthesis" class="headerlink" title="NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for   Talking Face Synthesis"></a>NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for   Talking Face Synthesis</h2><p><strong>Authors:Chongke Bi, Xiaoxing Liu, Zhilei Liu</strong></p>
<p>Talking face synthesis driven by audio is one of the current research hotspots in the fields of multidimensional signal processing and multimedia. Neural Radiance Field (NeRF) has recently been brought to this research field in order to enhance the realism and 3D effect of the generated faces. However, most existing NeRF-based methods either burden NeRF with complex learning tasks while lacking methods for supervised multimodal feature fusion, or cannot precisely map audio to the facial region related to speech movements. These reasons ultimately result in existing methods generating inaccurate lip shapes. This paper moves a portion of NeRF learning tasks ahead and proposes a talking face synthesis method via NeRF with attention-based disentanglement (NeRF-AD). In particular, an Attention-based Disentanglement module is introduced to disentangle the face into Audio-face and Identity-face using speech-related facial action unit (AU) information. To precisely regulate how audio affects the talking face, we only fuse the Audio-face with audio feature. In addition, AU information is also utilized to supervise the fusion of these two modalities. Extensive qualitative and quantitative experiments demonstrate that our NeRF-AD outperforms state-of-the-art methods in generating realistic talking face videos, including image quality and lip synchronization. To view video results, please refer to <a href="https://xiaoxingliu02.github.io/NeRF-AD">https://xiaoxingliu02.github.io/NeRF-AD</a>. </p>
<p><a href="http://arxiv.org/abs/2401.12568v1">PDF</a> Accepted by ICASSP 2024</p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœº (NeRF) å¸¦æ³¨æ„åŠ›æœºåˆ¶çš„åˆ†è§£ (NeRF-AD) æå‡ºäº†ä¸€ç§æ–°é¢–çš„è¯´è¯äººè„¸åˆæˆæ–¹æ³•ï¼Œé€šè¿‡éŸ³é¢‘æ³¨æ„æœºåˆ¶å°†äººè„¸åˆ†è§£ä¸ºéŸ³é¢‘é¢å­”å’Œèº«ä»½é¢å­”ï¼Œä»è€Œæé«˜äººè„¸åˆæˆçš„çœŸå®æ€§å’Œå”‡éƒ¨åŒæ­¥æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NeRF-AD æå‡ºäº†ä¸€ç§æ–°çš„è¯´è¯äººè„¸åˆæˆæ–¹æ³•ï¼Œç»“åˆäº†ç¥ç»è¾å°„åœº (NeRF) å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡å°†äººè„¸åˆ†è§£ä¸ºéŸ³é¢‘é¢å­”å’Œèº«ä»½é¢å­”ï¼Œå¤§å¹…æå‡äº†ç”Ÿæˆäººè„¸çš„çœŸå®æ€§å’Œå”‡éƒ¨åŒæ­¥æ•ˆæœã€‚</li>
</ul>
<ul>
<li>NeRF-AD ä½¿ç”¨åŸºäºæ³¨æ„åŠ›çš„åˆ†è§£æ¨¡å—ï¼Œåˆ©ç”¨è¯­éŸ³ç›¸å…³çš„é¢éƒ¨åŠ¨ä½œå•å…ƒ (AU) ä¿¡æ¯å°†äººè„¸åˆ†è§£ä¸ºéŸ³é¢‘é¢å­”å’Œèº«ä»½é¢å­”ï¼Œæœ‰æ•ˆåœ°å°†éŸ³é¢‘ä¸é¢éƒ¨è¯­éŸ³è¿åŠ¨ç›¸å…³åŒºåŸŸè¿›è¡Œç²¾ç¡®æ˜ å°„ã€‚</li>
</ul>
<ul>
<li>NeRF-AD åªå°†éŸ³é¢‘é¢å­”ä¸éŸ³é¢‘ç‰¹å¾èåˆï¼Œä»è€Œç²¾ç¡®åœ°æ§åˆ¶éŸ³é¢‘å¦‚ä½•å½±å“è¯´è¯äººè„¸ã€‚</li>
</ul>
<ul>
<li>NeRF-AD åˆ©ç”¨ AU ä¿¡æ¯æ¥ç›‘ç£è¿™ä¸¤ç§æ¨¡æ€çš„èåˆï¼Œæé«˜äº†äººè„¸åˆæˆçš„å‡†ç¡®æ€§å’ŒçœŸå®æ€§ã€‚</li>
</ul>
<ul>
<li>å¤§é‡çš„å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒNeRF-AD åœ¨ç”Ÿæˆé€¼çœŸè¯´è¯äººè„¸è§†é¢‘æ–¹é¢ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å›¾åƒè´¨é‡å’Œå”‡éƒ¨åŒæ­¥ã€‚</li>
</ul>
<ul>
<li>æ›´è¯¦ç»†çš„è§†é¢‘ç»“æœå¯ä»¥è®¿é—® <a href="https://xiaoxingliu02.github.io/NeRF-ADã€‚">https://xiaoxingliu02.github.io/NeRF-ADã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šç¥ç»è¾å°„åœºä¸åŸºäºæ³¨æ„åŠ›çš„åˆ†ç¦»çš„è¯´è¯äººé¢éƒ¨åˆæˆï¼ˆNERF-ADï¼‰</li>
<li>ä½œè€…ï¼šBi Chongkeï¼ŒLiu Xiaoxingï¼ŒLiu Zhilei</li>
<li>å•ä½ï¼šå¤©æ´¥å¤§å­¦æ™ºèƒ½ä¸è®¡ç®—å­¦é™¢</li>
<li>å…³é”®è¯ï¼šè¯´è¯äººé¢éƒ¨åˆæˆï¼Œç¥ç»è¾å°„åœºï¼Œé¢éƒ¨åˆ†ç¦»</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12568ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººé¢éƒ¨åˆæˆåœ¨å¤šç»´ä¿¡å·å¤„ç†å’Œå¤šåª’ä½“é¢†åŸŸæ˜¯ä¸€ä¸ªçƒ­é—¨çš„ç ”ç©¶è¯¾é¢˜ã€‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æœ€è¿‘è¢«å¼•å…¥è¯¥ç ”ç©¶é¢†åŸŸï¼Œä»¥å¢å¼ºç”Ÿæˆé¢éƒ¨çš„çœŸå®æ„Ÿå’Œ 3D æ•ˆæœã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„åŸºäº NeRF çš„æ–¹æ³•è¦ä¹ˆç»™ NeRF å¸¦æ¥äº†å¤æ‚çš„å­¦ä¹ ä»»åŠ¡ï¼ŒåŒæ—¶ç¼ºä¹ç›‘ç£å¼å¤šæ¨¡æ€ç‰¹å¾èåˆçš„æ–¹æ³•ï¼Œè¦ä¹ˆæ— æ³•å°†éŸ³é¢‘ç²¾ç¡®æ˜ å°„åˆ°ä¸è¯­éŸ³è¿åŠ¨ç›¸å…³çš„é¢éƒ¨åŒºåŸŸã€‚è¿™äº›åŸå› æœ€ç»ˆå¯¼è‡´ç°æœ‰æ–¹æ³•ç”Ÿæˆçš„å”‡å½¢ä¸å‡†ç¡®ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€äº›ç°æœ‰çš„æ–¹æ³•å°† NeRF çš„å­¦ä¹ ä»»åŠ¡æå‰äº†ä¸€éƒ¨åˆ†ï¼Œå¹¶æå‡ºäº†ä¸€ç§é€šè¿‡å…·æœ‰åŸºäºæ³¨æ„åŠ›çš„åˆ†ç¦»çš„ NeRFï¼ˆNeRF-ADï¼‰è¿›è¡Œè¯´è¯äººé¢éƒ¨åˆæˆçš„ã€‚å…·ä½“æ¥è¯´ï¼Œå¼•å…¥äº†ä¸€ä¸ªåŸºäºæ³¨æ„åŠ›çš„åˆ†ç¦»æ¨¡å—ï¼Œä½¿ç”¨ä¸è¯­éŸ³ç›¸å…³çš„é¢éƒ¨åŠ¨ä½œå•å…ƒ (AU) ä¿¡æ¯å°†é¢éƒ¨åˆ†ç¦»ä¸ºéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ã€‚ä¸ºäº†ç²¾ç¡®åœ°è°ƒèŠ‚éŸ³é¢‘å¦‚ä½•å½±å“è¯´è¯äººé¢éƒ¨ï¼Œæˆ‘ä»¬åªå°†éŸ³é¢‘é¢éƒ¨ä¸éŸ³é¢‘ç‰¹å¾èåˆã€‚æ­¤å¤–ï¼ŒAU ä¿¡æ¯è¿˜ç”¨äºç›‘ç£è¿™ä¸¤ä¸ªæ¨¡æ€çš„èåˆã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å‡å°‘ NeRF çš„å­¦ä¹ è´Ÿæ‹…å¹¶æé«˜é¢éƒ¨æ¸²æŸ“çš„å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬åˆ†è§£è¯´è¯äººé¢éƒ¨å¹¶ä¸º NeRF æä¾›ä¸¤ä¸ªåˆ†è§£çš„ç²¾ç¡®æ¡ä»¶ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºæ³¨æ„åŠ›çš„åˆ†ç¦»æ¨¡å—ï¼Œå…è®¸éŸ³é¢‘ä¸ä¸è¯­éŸ³è¿åŠ¨ç›¸å…³çš„é¢éƒ¨åŒºåŸŸç²¾ç¡®èåˆã€‚åŒæ—¶ï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸€ç³»åˆ—æ–¹æ³•æ¥ç›‘ç£æ•´ä¸ªè¿‡ç¨‹ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ NeRF-AD åœ¨ç”Ÿæˆé€¼çœŸçš„è¯´è¯äººé¢éƒ¨è§†é¢‘æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å›¾åƒè´¨é‡å’Œå”‡å½¢åŒæ­¥ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1)ï¼šæå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„åˆ†ç¦»æ¨¡å—NeRF-ADï¼Œå°†é¢éƒ¨åˆ†ç¦»ä¸ºéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ï¼Œå¹¶åªå°†éŸ³é¢‘é¢éƒ¨ä¸éŸ³é¢‘ç‰¹å¾èåˆï¼Œä»¥ç²¾ç¡®è°ƒèŠ‚éŸ³é¢‘å¦‚ä½•å½±å“è¯´è¯äººé¢éƒ¨ã€‚
(2)ï¼šä¸ºäº†å‡å°‘NeRFçš„å­¦ä¹ è´Ÿæ‹…å¹¶æé«˜é¢éƒ¨æ¸²æŸ“çš„å‡†ç¡®æ€§ï¼Œå°†è¯´è¯äººé¢éƒ¨åˆ†è§£å¹¶ä¸ºNeRFæä¾›ä¸¤ä¸ªåˆ†è§£çš„ç²¾ç¡®æ¡ä»¶ã€‚
(3)ï¼šé‡‡ç”¨ä¸€ç³»åˆ—æ–¹æ³•æ¥ç›‘ç£æ•´ä¸ªè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ä½¿ç”¨ä¸è¯­éŸ³ç›¸å…³çš„é¢éƒ¨åŠ¨ä½œå•å…ƒ(AU)ä¿¡æ¯ç›‘ç£éŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨çš„èåˆï¼Œä»¥åŠä½¿ç”¨æ„ŸçŸ¥æŸå¤±å’Œå¯¹æŠ—æŸå¤±æ¥ç›‘ç£NeRFçš„å­¦ä¹ ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„åˆ†ç¦»æ¨¡å—NeRF-ADï¼Œå°†è¯´è¯äººé¢éƒ¨åˆ†ç¦»ä¸ºéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ï¼Œå¹¶åªå°†éŸ³é¢‘é¢éƒ¨ä¸éŸ³é¢‘ç‰¹å¾èåˆï¼Œä»¥ç²¾ç¡®è°ƒèŠ‚éŸ³é¢‘å¦‚ä½•å½±å“è¯´è¯äººé¢éƒ¨ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„åˆ†ç¦»æ¨¡å—ï¼Œå°†è¯´è¯äººé¢éƒ¨åˆ†ç¦»ä¸ºéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ï¼Œå¹¶åªå°†éŸ³é¢‘é¢éƒ¨ä¸éŸ³é¢‘ç‰¹å¾èåˆï¼Œä»¥ç²¾ç¡®è°ƒèŠ‚éŸ³é¢‘å¦‚ä½•å½±å“è¯´è¯äººé¢éƒ¨ã€‚
ä¸ºäº†å‡å°‘NeRFçš„å­¦ä¹ è´Ÿæ‹…å¹¶æé«˜é¢éƒ¨æ¸²æŸ“çš„å‡†ç¡®æ€§ï¼Œå°†è¯´è¯äººé¢éƒ¨åˆ†è§£å¹¶ä¸ºNeRFæä¾›ä¸¤ä¸ªåˆ†è§£çš„ç²¾ç¡®æ¡ä»¶ã€‚
é‡‡ç”¨ä¸€ç³»åˆ—æ–¹æ³•æ¥ç›‘ç£æ•´ä¸ªè¿‡ç¨‹ï¼ŒåŒ…æ‹¬ä½¿ç”¨ä¸è¯­éŸ³ç›¸å…³çš„é¢éƒ¨åŠ¨ä½œå•å…ƒ(AU)ä¿¡æ¯ç›‘ç£éŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨çš„èåˆï¼Œä»¥åŠä½¿ç”¨æ„ŸçŸ¥æŸå¤±å’Œå¯¹æŠ—æŸå¤±æ¥ç›‘ç£NeRFçš„å­¦ä¹ ã€‚
æ€§èƒ½ï¼š
å®éªŒç»“æœè¡¨æ˜ï¼ŒNeRF-ADåœ¨å›¾åƒè´¨é‡å’Œå”‡å½¢åŒæ­¥æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
å·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-964938af99e1099b95b512a910ce466c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39deb199fcbfcf9dedfebf11b5272218.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d53c04a42d143a126e5b391f40684f6a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-55f96488825fc7af3820d32c3f4ac6ff.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1072a698b0f056bb4d49ab4715962395.jpg" align="middle">
</details>




<h2 id="HG3-NeRF-Hierarchical-Geometric-Semantic-and-Photometric-Guided-Neural-Radiance-Fields-for-Sparse-View-Inputs"><a href="#HG3-NeRF-Hierarchical-Geometric-Semantic-and-Photometric-Guided-Neural-Radiance-Fields-for-Sparse-View-Inputs" class="headerlink" title="HG3-NeRF: Hierarchical Geometric, Semantic, and Photometric Guided   Neural Radiance Fields for Sparse View Inputs"></a>HG3-NeRF: Hierarchical Geometric, Semantic, and Photometric Guided   Neural Radiance Fields for Sparse View Inputs</h2><p><strong>Authors:Zelin Gao, Weichen Dai, Yu Zhang</strong></p>
<p>Neural Radiance Fields (NeRF) have garnered considerable attention as a paradigm for novel view synthesis by learning scene representations from discrete observations. Nevertheless, NeRF exhibit pronounced performance degradation when confronted with sparse view inputs, consequently curtailing its further applicability. In this work, we introduce Hierarchical Geometric, Semantic, and Photometric Guided NeRF (HG3-NeRF), a novel methodology that can address the aforementioned limitation and enhance consistency of geometry, semantic content, and appearance across different views. We propose Hierarchical Geometric Guidance (HGG) to incorporate the attachment of Structure from Motion (SfM), namely sparse depth prior, into the scene representations. Different from direct depth supervision, HGG samples volume points from local-to-global geometric regions, mitigating the misalignment caused by inherent bias in the depth prior. Furthermore, we draw inspiration from notable variations in semantic consistency observed across images of different resolutions and propose Hierarchical Semantic Guidance (HSG) to learn the coarse-to-fine semantic content, which corresponds to the coarse-to-fine scene representations. Experimental results demonstrate that HG3-NeRF can outperform other state-of-the-art methods on different standard benchmarks and achieve high-fidelity synthesis results for sparse view inputs. </p>
<p><a href="http://arxiv.org/abs/2401.11711v1">PDF</a> 13 pages, 6 figures</p>
<p><strong>æ‘˜è¦</strong><br>å±‚æ¬¡å‡ ä½•ã€è¯­ä¹‰å’Œå…‰åº¦å¼•å¯¼ NeRFï¼ˆHG3-NeRFï¼‰æ–¹æ³•èƒ½æé«˜ç¨€ç–è§†å›¾è¾“å…¥ä¸‹åœºæ™¯è¡¨ç¤ºçš„å‡ ä½•ã€è¯­ä¹‰å†…å®¹å’Œå¤–è§‚ä¸€è‡´æ€§ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>HG3-NeRF æ˜¯ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå¯ä»¥è§£å†³ç¨€ç–è§†å›¾è¾“å…¥ä¸‹ NeRF çš„æ€§èƒ½é€€åŒ–é—®é¢˜ï¼Œå¹¶æé«˜å‡ ä½•ã€è¯­ä¹‰å†…å®¹å’Œå¤–è§‚çš„ä¸€è‡´æ€§ã€‚</li>
<li>HG3-NeRF æå‡ºäº†ä¸€ç§åˆ†å±‚å‡ ä½•å¼•å¯¼ (HGG) æ–¹æ³•ï¼Œå°†è¿åŠ¨ç»“æ„ (SfM) çš„é™„ä»¶ï¼ˆå³ç¨€ç–æ·±åº¦å…ˆéªŒï¼‰çº³å…¥åœºæ™¯è¡¨ç¤ºä¸­ã€‚</li>
<li>HGG ä»å±€éƒ¨åˆ°å…¨å±€çš„å‡ ä½•åŒºåŸŸå¯¹ä½“ç§¯ç‚¹è¿›è¡Œé‡‡æ ·ï¼Œå‡è½»äº†æ·±åº¦å…ˆéªŒä¸­å›ºæœ‰åå·®é€ æˆçš„é”™ä½ã€‚</li>
<li>HG3-NeRF æå‡ºäº†ä¸€ç§åˆ†å±‚è¯­ä¹‰å¼•å¯¼ (HSG) æ–¹æ³•ï¼Œå­¦ä¹ ä»ç²—åˆ°ç»†çš„è¯­ä¹‰å†…å®¹ï¼Œè¿™å¯¹åº”äºä»ç²—åˆ°ç»†çš„åœºæ™¯è¡¨ç¤ºã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒHG3-NeRF åœ¨ä¸åŒçš„æ ‡å‡†åŸºå‡†ä¸Šä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶å®ç°äº†ç¨€ç–è§†å›¾è¾“å…¥çš„é«˜ä¿çœŸåˆæˆç»“æœã€‚</li>
<li>HG3-NeRF æ–¹æ³•èƒ½æé«˜ç¨€ç–è§†å›¾è¾“å…¥ä¸‹åœºæ™¯è¡¨ç¤ºçš„å‡ ä½•ã€è¯­ä¹‰å†…å®¹å’Œå¤–è§‚ä¸€è‡´æ€§ã€‚</li>
<li>HG3-NeRF æ–¹æ³•èƒ½æé«˜ç¨€ç–è§†å›¾è¾“å…¥ä¸‹åœºæ™¯è¡¨ç¤ºçš„å‡ ä½•ã€è¯­ä¹‰å†…å®¹å’Œå¤–è§‚ä¸€è‡´æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šHG3-NeRFï¼šç”¨äºç¨€ç–è§†å›¾è¾“å…¥çš„åˆ†å±‚å‡ ä½•ã€è¯­ä¹‰å’Œå…‰åº¦å¼•å¯¼çš„ç¥ç»è¾å°„åœº</li>
<li>ä½œè€…ï¼šZelin Gao, Weichen Dai, Yu Zhang</li>
<li>éš¶å±æœºæ„ï¼šæµ™æ±Ÿå¤§å­¦æ§åˆ¶ç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€ç¨€ç–è§†å›¾ã€å‡ ä½•å¼•å¯¼ã€è¯­ä¹‰å¼•å¯¼ã€å…‰åº¦å¼•å¯¼</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.11711ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å› å…¶ä»ç¦»æ•£è§‚æµ‹ä¸­å­¦ä¹ åœºæ™¯è¡¨ç¤ºä»¥è¿›è¡Œæ–°é¢–è§†å›¾åˆæˆè€Œå¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼Œå½“é¢å¯¹ç¨€ç–è§†å›¾è¾“å…¥æ—¶ï¼ŒNeRF çš„æ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ï¼Œä»è€Œé™åˆ¶äº†å…¶è¿›ä¸€æ­¥çš„é€‚ç”¨æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•é‡‡ç”¨é¢„è®­ç»ƒæ–¹æ³•å’Œé€åœºæ™¯ä¼˜åŒ–æ–¹æ³•æ¥è§£å†³ç¨€ç–è§†å›¾è¾“å…¥çš„æŒ‘æˆ˜ã€‚é¢„è®­ç»ƒæ–¹æ³•åœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œç„¶ååœ¨æµ‹è¯•æ—¶å¯¹æ¯ä¸ªåœºæ™¯è¿›è¡Œå¾®è°ƒã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºæ•°æ®é›†çš„è´¨é‡ï¼Œè€Œä¸”é€šè¿‡æ•æ‰è®¸å¤šä¸åŒåœºæ™¯æ¥è·å¾—å¿…è¦çš„æ•°æ®é›†è¿‡äºæ˜‚è´µã€‚é€åœºæ™¯ä¼˜åŒ–æ–¹æ³•åœ¨æ¯ä¸ªåœºæ™¯ä¸Šä¼˜åŒ–æ¨¡å‹ï¼Œä½†å®ƒä»¬é€šå¸¸éœ€è¦å¤§é‡è®¡ç®—ï¼Œå¹¶ä¸”å¯èƒ½éš¾ä»¥æ”¶æ•›åˆ°è‰¯å¥½çš„è§£ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³• HG3-NeRFï¼Œå¯ä»¥è§£å†³ä¸Šè¿°é™åˆ¶å¹¶å¢å¼ºä¸åŒè§†å›¾ä¹‹é—´å‡ ä½•å½¢çŠ¶ã€è¯­ä¹‰å†…å®¹å’Œå¤–è§‚çš„ä¸€è‡´æ€§ã€‚HG3-NeRF åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šåˆ†å±‚å‡ ä½•å¼•å¯¼ï¼ˆHGGï¼‰ã€åˆ†å±‚è¯­ä¹‰å¼•å¯¼ï¼ˆHSGï¼‰å’Œå…‰åº¦å¼•å¯¼ã€‚HGG å°†ç»“æ„ä»è¿åŠ¨ï¼ˆSfMï¼‰çš„é™„åŠ ä¿¡æ¯ï¼ˆå³ç¨€ç–æ·±åº¦å…ˆéªŒï¼‰çº³å…¥åœºæ™¯è¡¨ç¤ºä¸­ã€‚HSG ä»ä¸åŒåˆ†è¾¨ç‡çš„å›¾åƒä¸­å­¦ä¹ ç²—åˆ°ç»†çš„è¯­ä¹‰å†…å®¹ï¼Œè¿™ä¸ç²—åˆ°ç»†çš„åœºæ™¯è¡¨ç¤ºç›¸å¯¹åº”ã€‚å…‰åº¦å¼•å¯¼ä½¿ç”¨æ¸²æŸ“æ–¹ç¨‹æ¥ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºï¼Œä»¥åŒ¹é…è¾“å…¥è§†å›¾çš„é¢œè‰²å’Œäº®åº¦ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒHG3-NeRF åœ¨ä¸åŒçš„æ ‡å‡†åŸºå‡†ä¸Šä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨ç¨€ç–è§†å›¾è¾“å…¥ä¸‹å®ç°äº†é«˜ä¿çœŸåˆæˆç»“æœã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•çš„ç›®æ ‡ï¼Œå³è§£å†³ç¨€ç–è§†å›¾è¾“å…¥çš„æŒ‘æˆ˜å¹¶å¢å¼ºä¸åŒè§†å›¾ä¹‹é—´å‡ ä½•å½¢çŠ¶ã€è¯­ä¹‰å†…å®¹å’Œå¤–è§‚çš„ä¸€è‡´æ€§ã€‚</li>
</ol>
<p>Methodsï¼š
ï¼ˆ1ï¼‰åˆ†å±‚å‡ ä½•å¼•å¯¼ï¼ˆHGGï¼‰ï¼šåˆ©ç”¨æ¥è‡ªç»“æ„è¿åŠ¨ï¼ˆSfMï¼‰çš„ç¨€ç–æ·±åº¦å…ˆéªŒï¼Œå°†å‡ ä½•ä¸€è‡´æ€§çº³å…¥åœºæ™¯è¡¨ç¤ºä¸­ã€‚HGG æ–¹æ³•æŒ‡å¯¼ç¥ç»è¾å°„åœºå­¦ä¹ å¯†åº¦å’Œé¢œè‰²çš„è¿‘ä¼¼åˆ†å¸ƒï¼Œè¿™äº›åˆ†å¸ƒæ¥è‡ªæ·±åº¦å…ˆéªŒç¡®å®šçš„å±€éƒ¨åˆ°å…¨å±€çš„é‡‡æ ·åŒºåŸŸã€‚
ï¼ˆ2ï¼‰åˆ†å±‚è¯­ä¹‰å¼•å¯¼ï¼ˆHSGï¼‰ï¼šä»ä¸åŒåˆ†è¾¨ç‡çš„å›¾åƒä¸­å­¦ä¹ ä»ç²—åˆ°ç»†çš„è¯­ä¹‰å†…å®¹ï¼Œè¿™ä¸ä»ç²—åˆ°ç»†çš„åœºæ™¯è¡¨ç¤ºç›¸å¯¹åº”ã€‚HSG ä½¿ç”¨ CLIP ç¼–ç å™¨å¯¹æ¸²æŸ“çš„å›¾åƒå’ŒåŸå§‹å›¾åƒçš„ç‰¹å¾å‘é‡è¿›è¡Œç¼–ç ï¼Œå¹¶è®¡ç®—ç²—åˆ°ç»†çš„è¯­ä¹‰ä½™å¼¦ç›¸ä¼¼æ€§ã€‚
ï¼ˆ3ï¼‰å…‰åº¦å¼•å¯¼ï¼šä½¿ç”¨æ¸²æŸ“æ–¹ç¨‹ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºï¼Œä»¥åŒ¹é…è¾“å…¥è§†å›¾çš„é¢œè‰²å’Œäº®åº¦ã€‚å…‰åº¦å¼•å¯¼é€šè¿‡æœ€å°åŒ–æ¸²æŸ“çš„å›¾åƒå’ŒåŸå§‹å›¾åƒä¹‹é—´çš„å¤–è§‚å‡æ–¹è¯¯å·®æ¥å®ç°ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ†å±‚å‡ ä½•ã€è¯­ä¹‰å’Œå…‰åº¦å¼•å¯¼çš„ç¥ç»è¾å°„åœºï¼ˆHG3-NeRFï¼‰æ–¹æ³•ï¼Œå¯ä»¥è§£å†³ç¨€ç–è§†å›¾è¾“å…¥çš„æŒ‘æˆ˜å¹¶å¢å¼ºä¸åŒè§†å›¾ä¹‹é—´å‡ ä½•å½¢çŠ¶ã€è¯­ä¹‰å†…å®¹å’Œå¤–è§‚çš„ä¸€è‡´æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åˆ†å±‚å‡ ä½•å¼•å¯¼ï¼ˆHGGï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨æ¥è‡ªç»“æ„è¿åŠ¨ï¼ˆSfMï¼‰çš„ç¨€ç–æ·±åº¦å…ˆéªŒï¼Œå°†å‡ ä½•ä¸€è‡´æ€§çº³å…¥åœºæ™¯è¡¨ç¤ºä¸­ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åˆ†å±‚è¯­ä¹‰å¼•å¯¼ï¼ˆHSGï¼‰æ–¹æ³•ï¼Œä»ä¸åŒåˆ†è¾¨ç‡çš„å›¾åƒä¸­å­¦ä¹ ä»ç²—åˆ°ç»†çš„è¯­ä¹‰å†…å®¹ï¼Œè¿™ä¸ä»ç²—åˆ°ç»†çš„åœºæ™¯è¡¨ç¤ºç›¸å¯¹åº”ã€‚</li>
<li>ä½¿ç”¨æ¸²æŸ“æ–¹ç¨‹ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºï¼Œä»¥åŒ¹é…è¾“å…¥è§†å›¾çš„é¢œè‰²å’Œäº®åº¦ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¸åŒçš„æ ‡å‡†åŸºå‡†ä¸Šä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨ç¨€ç–è§†å›¾è¾“å…¥ä¸‹å®ç°äº†é«˜ä¿çœŸåˆæˆç»“æœã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦ä¼°è®¡ç›¸æœºä½å§¿ï¼Œå¹¶ä¸”ç¨€ç–è§†å›¾è¾“å…¥ä¼šå½±å“ä½å§¿ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-56cd69227addb7c7e2e5ec9028bc8cb0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bb7c383a42f7306611645083f4d82eb9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-71514b137fee0e499428b6e4c393be26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc5dccc88a28d6fafb1f550b78be5145.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bab43cfc9ed715f6025ba1321b7acdc3.jpg" align="middle">
</details>




<h2 id="IPR-NeRF-Ownership-Verification-meets-Neural-Radiance-Field"><a href="#IPR-NeRF-Ownership-Verification-meets-Neural-Radiance-Field" class="headerlink" title="IPR-NeRF: Ownership Verification meets Neural Radiance Field"></a>IPR-NeRF: Ownership Verification meets Neural Radiance Field</h2><p><strong>Authors:Win Kent Ong, Kam Woh Ng, Chee Seng Chan, Yi Zhe Song, Tao Xiang</strong></p>
<p>Neural Radiance Field (NeRF) models have gained significant attention in the computer vision community in the recent past with state-of-the-art visual quality and produced impressive demonstrations. Since then, technopreneurs have sought to leverage NeRF models into a profitable business. Therefore, NeRF models make it worth the risk of plagiarizers illegally copying, re-distributing, or misusing those models. This paper proposes a comprehensive intellectual property (IP) protection framework for the NeRF model in both black-box and white-box settings, namely IPR-NeRF. In the black-box setting, a diffusion-based solution is introduced to embed and extract the watermark via a two-stage optimization process. In the white-box setting, a designated digital signature is embedded into the weights of the NeRF model by adopting the sign loss objective. Our extensive experiments demonstrate that not only does our approach maintain the fidelity (\ie, the rendering quality) of IPR-NeRF models, but it is also robust against both ambiguity and removal attacks compared to prior arts. </p>
<p><a href="http://arxiv.org/abs/2401.09495v4">PDF</a> Error on result tabulation of state of the art method which might   cause misleading to readers</p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¨¡å‹åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå¤‡å—å…³æ³¨ï¼Œå¹¶äº§ç”Ÿäº†ä»¤äººå°è±¡æ·±åˆ»çš„æˆæœï¼Œç”±äºå…¶æœ€å…ˆè¿›çš„è§†è§‰è´¨é‡ï¼Œå› æ­¤å­˜åœ¨è¢«å‰½çªƒè€…éæ³•å¤åˆ¶ã€å†åˆ†å‘æˆ–æ»¥ç”¨çš„é£é™©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹ NeRF æ¨¡å‹çš„é»‘ç›’å’Œç™½ç›’è®¾ç½®çš„ç»¼åˆçŸ¥è¯†äº§æƒï¼ˆIPï¼‰ä¿æŠ¤æ¡†æ¶ï¼Œç§°ä¸º IPR-NeRFã€‚</li>
<li>åœ¨é»‘ç›’è®¾ç½®ä¸­ï¼Œå¼•å…¥äº†ä¸€ç§åŸºäºæ‰©æ•£çš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡ä¸¤é˜¶æ®µä¼˜åŒ–è¿‡ç¨‹åµŒå…¥å’Œæå–æ°´å°ã€‚</li>
<li>åœ¨ç™½ç›’è®¾ç½®ä¸­ï¼Œé€šè¿‡é‡‡ç”¨ç¬¦å·æŸå¤±ç›®æ ‡å°†æŒ‡å®šæ•°å­—ç­¾ååµŒå…¥ NeRF æ¨¡å‹çš„æƒé‡ä¸­ã€‚</li>
<li>å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…ä¿æŒäº† IPR-NeRF æ¨¡å‹çš„ä¿çœŸåº¦ï¼ˆå³æ¸²æŸ“è´¨é‡ï¼‰ï¼Œè€Œä¸”ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œå®ƒè¿˜å¯¹æ­§ä¹‰æ”»å‡»å’Œå»é™¤æ”»å‡»å…·æœ‰é²æ£’æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šIPR-NERFï¼šçŸ¥è¯†äº§æƒéªŒè¯æ»¡è¶³ç¥ç»è¾å°„åœº</li>
<li>ä½œè€…ï¼šKent Ong, Kam Woh Ng, Chee Seng Chan, Yi Zhe Song, Tao Xiang</li>
<li>å•ä½ï¼šé©¬æ¥äºšå¤§å­¦å›¾åƒä¸ä¿¡å·å¤„ç†ä¸­å¿ƒï¼ˆCISiPï¼‰</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€çŸ¥è¯†äº§æƒä¿æŠ¤ã€æ•°å­—æ°´å°ã€æ•°å­—ç­¾å</li>
<li>è®ºæ–‡é“¾æ¥ï¼šarXiv:2401.09495v1[cs.CV]17Jan2024
Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¨¡å‹å› å…¶å“è¶Šçš„è§†è§‰è´¨é‡å’Œä»¤äººå°è±¡æ·±åˆ»çš„æ¼”ç¤ºè€Œåœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼ŒNeRF æ¨¡å‹ä¹Ÿé¢ä¸´ç€çŸ¥è¯†äº§æƒä¿æŠ¤çš„é—®é¢˜ï¼Œå‰½çªƒè€…å¯èƒ½ä¼šéæ³•å¤åˆ¶ã€é‡æ–°åˆ†å‘æˆ–æ»¥ç”¨è¿™äº›æ¨¡å‹ä»¥è·å–ç»æµåˆ©ç›Šæˆ–ä¸ªäººåˆ©ç›Šã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç›®å‰é’ˆå¯¹ç¥ç»ç½‘ç»œçš„çŸ¥è¯†äº§æƒä¿æŠ¤æ–¹æ¡ˆä¸»è¦é’ˆå¯¹å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰å’Œå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ¡ˆåœ¨åº”ç”¨äº NeRF æ¨¡å‹æ—¶é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼Œä¾‹å¦‚ NeRF æ¨¡å‹çš„å¤æ‚ç»“æ„ã€å¯¹æ•°æ®å’Œè®¡ç®—èµ„æºçš„è¦æ±‚è¾ƒé«˜ä»¥åŠç¼ºä¹æœ‰æ•ˆçš„çŸ¥è¯†äº§æƒä¿æŠ¤æŠ€æœ¯ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»¼åˆçš„ NeRF æ¨¡å‹çŸ¥è¯†äº§æƒä¿æŠ¤æ¡†æ¶ï¼Œç§°ä¸º IPR-NERFã€‚è¯¥æ¡†æ¶åŒ…æ‹¬é»‘ç›’å’Œç™½ç›’ä¸¤ç§è®¾ç½®ã€‚åœ¨é»‘ç›’è®¾ç½®ä¸­ï¼Œå¼•å…¥äº†ä¸€ä¸ªåŸºäºæ‰©æ•£çš„è§£å†³æ–¹æ¡ˆæ¥åµŒå…¥å’Œæå–æ°´å°ï¼Œé€šè¿‡ä¸€ä¸ªä¸¤é˜¶æ®µçš„ä¼˜åŒ–è¿‡ç¨‹å®ç°ã€‚åœ¨ç™½ç›’è®¾ç½®ä¸­ï¼Œé€šè¿‡é‡‡ç”¨ç¬¦å·æŸå¤±ç›®æ ‡å‡½æ•°ï¼Œå°†æŒ‡å®šæ•°å­—ç­¾ååµŒå…¥ NeRF æ¨¡å‹çš„æƒé‡ä¸­ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒIPR-NERF æ¨¡å‹ä¸ä»…ä¿æŒäº†æ¸²æŸ“è´¨é‡ï¼Œè€Œä¸”åœ¨é¢å¯¹æ¨¡ç³Šæ€§å’Œå»é™¤æ”»å‡»æ—¶ä¹Ÿå…·æœ‰é²æ£’æ€§ï¼Œä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºä¸€ä¸ªç»¼åˆçš„NeRFæ¨¡å‹çŸ¥è¯†äº§æƒä¿æŠ¤æ¡†æ¶IPR-NERFï¼ŒåŒ…æ‹¬é»‘ç›’å’Œç™½ç›’ä¸¤ç§è®¾ç½®ã€‚
ï¼ˆ2ï¼‰ï¼šåœ¨é»‘ç›’è®¾ç½®ä¸­ï¼Œå¼•å…¥ä¸€ä¸ªåŸºäºæ‰©æ•£çš„è§£å†³æ–¹æ¡ˆæ¥åµŒå…¥å’Œæå–æ°´å°ï¼Œé€šè¿‡ä¸€ä¸ªä¸¤é˜¶æ®µçš„ä¼˜åŒ–è¿‡ç¨‹å®ç°ã€‚
ï¼ˆ3ï¼‰ï¼šåœ¨ç™½ç›’è®¾ç½®ä¸­ï¼Œé€šè¿‡é‡‡ç”¨ç¬¦å·æŸå¤±ç›®æ ‡å‡½æ•°ï¼Œå°†æŒ‡å®šæ•°å­—ç­¾ååµŒå…¥NeRFæ¨¡å‹çš„æƒé‡ä¸­ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§å…¨é¢çš„ã€é²æ£’çš„ NeRF-IPR ä¿æŠ¤æ–¹æ¡ˆï¼ŒåŒ…æ‹¬é»‘ç›’å’Œç™½ç›’ä¸¤ç§åœºæ™¯ã€‚å…¨é¢çš„å®éªŒç»“æœè¡¨æ˜äº†å…¶åœ¨æŠµæŠ—åµŒå…¥æ°´å°çš„æ¨¡ç³Šæ€§å’Œå»é™¤æ”»å‡»æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶ä¿æŒäº†æ¸²æŸ“æ€§èƒ½ã€‚ç„¶è€Œï¼Œå®ƒåœ¨è®¡ç®—èƒ½åŠ›å’Œå¯¹è¦†ç›–æ”»å‡»çš„é»‘ç›’ä¿æŠ¤æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå½“æ”»å‡»è€…æ‹¥æœ‰å—ä¿æŠ¤æ¨¡å‹çš„è¯¦ç»†ä¿¡æ¯æ—¶ã€‚æœªæ¥çš„ç ”ç©¶å°†é›†ä¸­åœ¨æ”¹è¿›è¿™äº›æ–¹é¢ã€‚æœ¬ç ”ç©¶ä¸º NeRF æ¨¡å‹å¼€å‘è€…å’Œç ”ç©¶äººå‘˜æä¾›äº†æå¤§çš„ä»·å€¼ï¼Œæä¾›äº†ä¸€ç§ä¿æŠ¤å…¶çŸ¥è¯†äº§æƒå¹¶è·å¾—å¸‚åœºç«äº‰ä¼˜åŠ¿çš„æ–¹æ³•ï¼Œè€ƒè™‘åˆ°å¼€å‘é«˜æ€§èƒ½ NeRF æ¨¡å‹æ‰€éœ€çš„å·¨å¤§èµ„æºã€‚åŠ å¼º NeRF æ¨¡å‹å¯¹ IPR ä¾µæƒè¡Œä¸ºçš„æŠµæŠ—å…·æœ‰å¹¿æ³›çš„ç¤¾ä¼šæ•ˆç›Šï¼ŒåŒ…æ‹¬é˜²æ­¢å‰½çªƒã€ç¡®ä¿åœ¨åŠ¨æ€å¸‚åœºç«äº‰ä¸­çš„ç«äº‰ä¼˜åŠ¿ä»¥åŠå‡å°‘æµªè´¹è¯‰è®¼æ¡ˆä»¶çš„è´Ÿæ‹…ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§ç»¼åˆçš„ NeRF æ¨¡å‹çŸ¥è¯†äº§æƒä¿æŠ¤æ¡†æ¶ IPR-NERFï¼ŒåŒ…æ‹¬é»‘ç›’å’Œç™½ç›’ä¸¤ç§è®¾ç½®ã€‚</li>
<li>åœ¨é»‘ç›’è®¾ç½®ä¸­ï¼Œå¼•å…¥äº†ä¸€ä¸ªåŸºäºæ‰©æ•£çš„è§£å†³æ–¹æ¡ˆæ¥åµŒå…¥å’Œæå–æ°´å°ï¼Œé€šè¿‡ä¸€ä¸ªä¸¤é˜¶æ®µçš„ä¼˜åŒ–è¿‡ç¨‹å®ç°ã€‚</li>
<li>åœ¨ç™½ç›’è®¾ç½®ä¸­ï¼Œé€šè¿‡é‡‡ç”¨ç¬¦å·æŸå¤±ç›®æ ‡å‡½æ•°ï¼Œå°†æŒ‡å®šæ•°å­—ç­¾ååµŒå…¥ NeRF æ¨¡å‹çš„æƒé‡ä¸­ã€‚
æ€§èƒ½ï¼š</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒIPR-NERF æ¨¡å‹ä¸ä»…ä¿æŒäº†æ¸²æŸ“è´¨é‡ï¼Œè€Œä¸”åœ¨é¢å¯¹æ¨¡ç³Šæ€§å’Œå»é™¤æ”»å‡»æ—¶ä¹Ÿå…·æœ‰é²æ£’æ€§ï¼Œä¼˜äºç°æœ‰æŠ€æœ¯ã€‚
å·¥ä½œé‡ï¼š</li>
<li>IPR-NERF æ¨¡å‹çš„è®¡ç®—æˆæœ¬è¾ƒé«˜ï¼Œå°¤å…¶æ˜¯å¯¹äºå¤§å‹æ•°æ®é›†å’Œå¤æ‚åœºæ™¯ã€‚</li>
<li>åœ¨é»‘ç›’è®¾ç½®ä¸­ï¼ŒåµŒå…¥å’Œæå–æ°´å°çš„è¿‡ç¨‹å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
<li>åœ¨ç™½ç›’è®¾ç½®ä¸­ï¼Œéœ€è¦ä¿®æ”¹ NeRF æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä»¥åµŒå…¥æ•°å­—ç­¾åï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®­ç»ƒæ—¶é—´å’Œå¤æ‚æ€§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7702dd0580aeb20d2469586499df517d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-b6cd7f525efd45ad04614d4ae868c5ff.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cd4e10da5a013a99ebc46d33f1e102a8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed46804675ae115b408ec3a1b30d40dd.jpg" align="middle">
</details>




<h2 id="ProvNeRF-Modeling-per-Point-Provenance-in-NeRFs-as-a-Stochastic-Process"><a href="#ProvNeRF-Modeling-per-Point-Provenance-in-NeRFs-as-a-Stochastic-Process" class="headerlink" title="ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Process"></a>ProvNeRF: Modeling per Point Provenance in NeRFs as a Stochastic Process</h2><p><strong>Authors:Kiyohiro Nakayama, Mikaela Angelina Uy, Yang You, Ke Li, Leonidas Guibas</strong></p>
<p>Neural radiance fields (NeRFs) have gained popularity across various applications. However, they face challenges in the sparse view setting, lacking sufficient constraints from volume rendering. Reconstructing and understanding a 3D scene from sparse and unconstrained cameras is a long-standing problem in classical computer vision with diverse applications. While recent works have explored NeRFs in sparse, unconstrained view scenarios, their focus has been primarily on enhancing reconstruction and novel view synthesis. Our approach takes a broader perspective by posing the question: â€œfrom where has each point been seen?â€ â€” which gates how well we can understand and reconstruct it. In other words, we aim to determine the origin or provenance of each 3D point and its associated information under sparse, unconstrained views. We introduce ProvNeRF, a model that enriches a traditional NeRF representation by incorporating per-point provenance, modeling likely source locations for each point. We achieve this by extending implicit maximum likelihood estimation (IMLE) for stochastic processes. Notably, our method is compatible with any pre-trained NeRF model and the associated training camera poses. We demonstrate that modeling per-point provenance offers several advantages, including uncertainty estimation, criteria-based view selection, and improved novel view synthesis, compared to state-of-the-art methods. Please visit our project page at <a href="https://provnerf.github.io">https://provnerf.github.io</a> </p>
<p><a href="http://arxiv.org/abs/2401.08140v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>é’ˆå¯¹ç¨€ç–æ— çº¦æŸè§†ç‚¹åœºæ™¯ä¸‹ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¨¡å‹çš„å±€é™æ€§ï¼Œæœ¬æ–‡æ—¨åœ¨é‡æ„å’Œç†è§£ä¸‰ç»´åœºæ™¯ä¸­æ¯ä¸ªç‚¹çš„æ¥æºä¿¡æ¯ï¼Œå¹¶æå‡ºäº† ProvNeRF æ¨¡å‹æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>ProvNeRF æ¨¡å‹èƒ½å¤Ÿé€šè¿‡å¼•å…¥æ¯ä¸ªç‚¹å¯èƒ½çš„æ¥æºä½ç½®ï¼Œæ¥ä¸°å¯Œä¼ ç»Ÿçš„ NeRF æ¨¡å‹ã€‚</li>
<li>ProvNeRF æ¨¡å‹ä¸ä»»ä½•é¢„è®­ç»ƒçš„ NeRF æ¨¡å‹åŠå…¶ç›¸å…³çš„è®­ç»ƒç›¸æœºä½å§¿å…¼å®¹ã€‚</li>
<li>ProvNeRF æ¨¡å‹å¯ä»¥å¯¹æ¯ä¸ªç‚¹çš„ä¸ç¡®å®šæ€§è¿›è¡Œä¼°è®¡ã€‚</li>
<li>ProvNeRF æ¨¡å‹å¯ä»¥æ ¹æ®æŒ‡å®šçš„æ ‡å‡†ï¼Œé€‰æ‹©åˆé€‚çš„è§†è§’æ¥è¿›è¡Œåœºæ™¯é‡å»ºã€‚</li>
<li>ProvNeRF æ¨¡å‹å¯ä»¥æ”¹è¿›åœºæ™¯çš„æ–°è§†è§’åˆæˆç»“æœã€‚</li>
<li>ProvNeRF æ¨¡å‹çš„æ›´å¤šä¿¡æ¯å¯ä»¥åœ¨é¡¹ç›®ä¸»é¡µ <a href="https://provnerf.github.io">https://provnerf.github.io</a> æŸ¥çœ‹ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li>æ ‡é¢˜ï¼šProvNeRFï¼šå°† NeRF ä¸­çš„é€ç‚¹å‡ºå¤„å»ºæ¨¡ä¸ºéšæœºè¿‡ç¨‹</li><p></p>
<p></p><li>ä½œè€…ï¼šGeorge Kiyohiro Nakayamaã€Mikaela Angelina Uyã€Yang Youã€Ke Liã€Leonidas Guibas</li><p></p>
<p></p><li>éš¶å±æœºæ„ï¼šæ–¯å¦ç¦å¤§å­¦</li><p></p>
<p></p><li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€ç¨€ç–è§†å›¾ã€å‡ºå¤„å»ºæ¨¡ã€ä¸ç¡®å®šæ€§ä¼°è®¡ã€åŸºäºæ ‡å‡†çš„è§†ç‚¹ä¼˜åŒ–ã€æ–°é¢–è§†å›¾åˆæˆ</li><p></p>
<p></p><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.08140
Github é“¾æ¥ï¼šæ— </li><p></p>
<p></p><li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœº (NeRF) åœ¨å„ç§åº”ç”¨ä¸­è¶Šæ¥è¶Šå—æ¬¢è¿ï¼Œä½†å®ƒä»¬åœ¨ç¨€ç–è§†å›¾æ–¹æ¡ˆä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºä»…é ä½“ç§¯æ¸²æŸ“æ— æ³•æä¾›è¶³å¤Ÿçš„çº¦æŸã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å¢å¼ºé‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆä¸Šï¼Œä½†å¿½ç•¥äº†å¦‚ä½•ä»æ›´å…¨é¢çš„è§’åº¦ç†è§£åœºæ™¯ï¼Œä¾‹å¦‚ä¸ç¡®å®šæ€§ä¼°è®¡ã€åŸºäºæ ‡å‡†çš„è§†ç‚¹é€‰æ‹©å’Œæ”¹è¿›çš„æ–°é¢–è§†å›¾åˆæˆã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡º ProvNeRFï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡ç»“åˆé€ç‚¹å‡ºå¤„æ¥ä¸°å¯Œä¼ ç»Ÿ NeRF è¡¨ç¤ºçš„æ¨¡å‹ï¼Œå¯¹æ¯ä¸ªç‚¹å»ºæ¨¡å¯èƒ½çš„æºä½ç½®ã€‚æˆ‘ä»¬é€šè¿‡æ‰©å±•éšæœºè¿‡ç¨‹çš„éšå¼æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (IMLE) æ¥å®ç°è¿™ä¸€ç‚¹ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸ç¡®å®šæ€§ä¼°è®¡ã€åŸºäºæ ‡å‡†çš„è§†ç‚¹é€‰æ‹©å’Œæ”¹è¿›çš„æ–°é¢–è§†å›¾åˆæˆæ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œè¿™è¡¨æ˜å»ºæ¨¡é€ç‚¹å‡ºå¤„å¯ä»¥æä¾›å‡ ä¸ªä¼˜åŠ¿ã€‚</li><br>&lt;/ol&gt;<p></p>
<p><strong>Methods</strong>ï¼š**</p>
<p>ï¼ˆ1ï¼‰ï¼šæˆ‘ä»¬å°†ç¥ç»è¾å°„åœº (NeRF) è¡¨ç¤ºæ‰©å±•ä¸ºåŒ…å«æ¯ä¸ªç‚¹çš„å‡ºå¤„ï¼Œå³æ¯ä¸ªç‚¹çš„æ¥æºæˆ–ä»ä½•å¤„çœ‹åˆ°å®ƒã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šæˆ‘ä»¬ä½¿ç”¨éšæœºè¿‡ç¨‹å¯¹æ¯ä¸ªç‚¹çš„å‡ºå¤„è¿›è¡Œå»ºæ¨¡ï¼Œè¯¥éšæœºè¿‡ç¨‹ç”±åæ ‡ xâˆˆR3 ç´¢å¼•ï¼Œå…¶åœ¨ x å¤„çš„è¾¹é™…åˆ†å¸ƒç¼–ç äº† x å¤„çš„å‡ºå¤„ã€‚</p>
<p>ï¼ˆ3ï¼‰ï¼šæˆ‘ä»¬é€šè¿‡æ‰©å±•éšæœºè¿‡ç¨‹çš„éšå¼æœ€å¤§ä¼¼ç„¶ä¼°è®¡ (IMLE) æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œè¯¥ä¼°è®¡å°†æ½œåœ¨éšæœºå˜é‡çš„å˜æ¢å­¦ä¹ ä¸ºæ•°æ®åˆ†å¸ƒï¼Œå…¶ä¸­æ¯ä¸ªæ•°æ®æ ·æœ¬éƒ½æ˜¯ä¸€ä¸ªæ ‡é‡æˆ–å‘é‡ã€‚</p>
<p>ï¼ˆ4ï¼‰ï¼šæˆ‘ä»¬æå‡º ProvNeRFï¼Œå®ƒé€šè¿‡æ‰©å±•éšå¼æ¦‚ç‡æ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯ IMLEï¼‰æ¥å¤„ç†éšæœºè¿‡ç¨‹ï¼Œä»è€Œå°†æ¯ä¸ªç‚¹çš„å‡ºå¤„å»ºæ¨¡ä¸ºéšæœºè¿‡ç¨‹ã€‚</p>
<p>ï¼ˆ5ï¼‰ï¼šProvNeRF å­¦ä¹ ä¸€ä¸ªç¡®å®šæ€§å˜æ¢ HÎ¸ï¼šRbâ†’R+Ã—D3ï¼Œè¯¥å˜æ¢å°†æ¯ä¸ªæ½œåœ¨éšæœºå‡½æ•°æ ·æœ¬ Zâˆ¼Z æ˜ å°„åˆ°ä¸€ä¸ªå‡½æ•° DÎ¸âˆ¼DÎ¸ã€‚</p>
<p>ï¼ˆ6ï¼‰ï¼šä¸ºäº†ä¼˜åŒ– DÎ¸ï¼Œæˆ‘ä»¬æ‰©å±• IMLE æ¥å¯¹éšæœºè¿‡ç¨‹çš„åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚æˆ‘ä»¬å°† Eq.3 è°ƒæ•´åˆ°å‡½æ•°ç©ºé—´ï¼Œå¹¶è¯æ˜å®ƒç­‰ä»·äºåœ¨æ¯ä¸ªç‚¹ x å¤„å¯¹ç»éªŒæ ·æœ¬ Ë†D(x)âˆ¼Ë†D(x) å’Œæ¨¡å‹æ ·æœ¬ DÎ¸(x)âˆ¼DÎ¸(x) è¿›è¡Œé€ç‚¹åŒ¹é…ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡º ProvNeRFï¼Œé€šè¿‡æ‰©å±•éšæœºè¿‡ç¨‹çš„ IMLE æ¥å¢å¼ºä¼ ç»Ÿ NeRF è¡¨ç¤ºï¼Œä»è€Œå°†æ¯ä¸ªç‚¹çš„å‡ºå¤„å»ºæ¨¡ä¸ºéšæœºè¿‡ç¨‹ã€‚ProvNeRF å¯è½»æ¾åº”ç”¨äºä»»ä½•é¢„è®­ç»ƒçš„ NeRF æ¨¡å‹ä»¥åŠç›¸å…³çš„è®­ç»ƒç›¸æœºä½å§¿ã€‚æˆ‘ä»¬å±•ç¤ºäº†åœ¨å„ç§ä¸‹æ¸¸åº”ç”¨ä¸­å»ºæ¨¡é€ç‚¹å‡ºå¤„çš„ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬ä¸ç¡®å®šæ€§å»ºæ¨¡ã€åŸºäºæ ‡å‡†çš„è§†ç‚¹é€‰æ‹©ä»¥åŠä¸ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”æ”¹è¿›çš„æ–°é¢–è§†å›¾åˆæˆã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡º ProvNeRFï¼Œä¸€ç§é€šè¿‡æ‰©å±•éšæœºè¿‡ç¨‹çš„ IMLE æ¥å¢å¼ºä¼ ç»Ÿ NeRF è¡¨ç¤ºçš„æ¨¡å‹ï¼Œä»è€Œå°†æ¯ä¸ªç‚¹çš„å‡ºå¤„å»ºæ¨¡ä¸ºéšæœºè¿‡ç¨‹ã€‚</li>
<li>è¯æ˜äº† ProvNeRF å¯ä»¥è½»æ¾åº”ç”¨äºä»»ä½•é¢„è®­ç»ƒçš„ NeRF æ¨¡å‹ä»¥åŠç›¸å…³çš„è®­ç»ƒç›¸æœºä½å§¿ã€‚</li>
<li>å±•ç¤ºäº†åœ¨å„ç§ä¸‹æ¸¸åº”ç”¨ä¸­å»ºæ¨¡é€ç‚¹å‡ºå¤„çš„ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬ä¸ç¡®å®šæ€§å»ºæ¨¡ã€åŸºäºæ ‡å‡†çš„è§†ç‚¹é€‰æ‹©ä»¥åŠä¸ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”æ”¹è¿›çš„æ–°é¢–è§†å›¾åˆæˆã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
- åœ¨ä¸ç¡®å®šæ€§ä¼°è®¡ã€åŸºäºæ ‡å‡†çš„è§†ç‚¹é€‰æ‹©å’Œæ”¹è¿›çš„æ–°é¢–è§†å›¾åˆæˆæ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p>å·¥ä½œé‡ï¼š
- éœ€è¦æ‰©å±•éšæœºè¿‡ç¨‹çš„ IMLE æ¥å¯¹éšæœºè¿‡ç¨‹çš„åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ã€‚
- éœ€è¦è°ƒæ•´ Eq.3 åˆ°å‡½æ•°ç©ºé—´ï¼Œå¹¶è¯æ˜å®ƒç­‰ä»·äºåœ¨æ¯ä¸ªç‚¹ x å¤„å¯¹ç»éªŒæ ·æœ¬ Ë†D(x)âˆ¼Ë†D(x) å’Œæ¨¡å‹æ ·æœ¬ DÎ¸(x)âˆ¼DÎ¸(x) è¿›è¡Œé€ç‚¹åŒ¹é…ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f48885cf9ef1b2a677c258f6b1e9a2a2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d72d125185075e757ca6e7284c2ace68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a582ca9b91a20a6a1c1593166a2d8401.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d26582d170597ef79c1a5e15500eaa42.jpg" align="middle">
</details>





</ol>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>Talking Head Generation</title>
    <url>/2024/01/30/Paper/2024-01-30/Talking%20Head%20Generation/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-30-æ›´æ–°"><a href="#2024-01-30-æ›´æ–°" class="headerlink" title="2024-01-30 æ›´æ–°"></a>2024-01-30 æ›´æ–°</h1><h2 id="NeRF-AD-Neural-Radiance-Field-with-Attention-based-Disentanglement-for-Talking-Face-Synthesis"><a href="#NeRF-AD-Neural-Radiance-Field-with-Attention-based-Disentanglement-for-Talking-Face-Synthesis" class="headerlink" title="NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for   Talking Face Synthesis"></a>NeRF-AD: Neural Radiance Field with Attention-based Disentanglement for   Talking Face Synthesis</h2><p><strong>Authors:Chongke Bi, Xiaoxing Liu, Zhilei Liu</strong></p>
<p>Talking face synthesis driven by audio is one of the current research hotspots in the fields of multidimensional signal processing and multimedia. Neural Radiance Field (NeRF) has recently been brought to this research field in order to enhance the realism and 3D effect of the generated faces. However, most existing NeRF-based methods either burden NeRF with complex learning tasks while lacking methods for supervised multimodal feature fusion, or cannot precisely map audio to the facial region related to speech movements. These reasons ultimately result in existing methods generating inaccurate lip shapes. This paper moves a portion of NeRF learning tasks ahead and proposes a talking face synthesis method via NeRF with attention-based disentanglement (NeRF-AD). In particular, an Attention-based Disentanglement module is introduced to disentangle the face into Audio-face and Identity-face using speech-related facial action unit (AU) information. To precisely regulate how audio affects the talking face, we only fuse the Audio-face with audio feature. In addition, AU information is also utilized to supervise the fusion of these two modalities. Extensive qualitative and quantitative experiments demonstrate that our NeRF-AD outperforms state-of-the-art methods in generating realistic talking face videos, including image quality and lip synchronization. To view video results, please refer to <a href="https://xiaoxingliu02.github.io/NeRF-AD">https://xiaoxingliu02.github.io/NeRF-AD</a>. </p>
<p><a href="http://arxiv.org/abs/2401.12568v1">PDF</a> Accepted by ICASSP 2024</p>
<p><strong>Summary</strong><br>ç”¨æ³¨æ„åŠ›æœºåˆ¶åˆ†è§£ç¥ç»è¾å°„åœºï¼Œç”¨äºéŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å·²è¢«å¼•å…¥åˆ°è°ˆè¯é¢éƒ¨åˆæˆçš„ç ”ç©¶é¢†åŸŸï¼Œä»¥å¢å¼ºç”Ÿæˆçš„é¢çš„é€¼çœŸæ€§å’Œ 3D æ•ˆæœã€‚</li>
<li>ç°æœ‰çš„ NeRF æ–¹æ³•è¦ä¹ˆç»™ NeRF å¸¦æ¥äº†å¤æ‚çš„å­¦ä¹ ä»»åŠ¡ï¼Œè€Œç¼ºä¹ç›‘ç£å¼å¤šæ¨¡æ€ç‰¹å¾èåˆçš„æ–¹æ³•ï¼Œæˆ–è€…æ— æ³•å°†éŸ³é¢‘ç²¾ç¡®æ˜ å°„åˆ°ä¸è¯­éŸ³è¿åŠ¨ç›¸å…³çš„é¢éƒ¨åŒºåŸŸã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäº NeRF çš„æ³¨æ„åŠ›æœºåˆ¶åˆ†è§£çš„è¯´è¯äººå¤´éƒ¨åˆæˆæ–¹æ³•ï¼ˆNeRF-ADï¼‰ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªåŸºäºæ³¨æ„åŠ›çš„åˆ†è§£æ¨¡å—ï¼Œä½¿ç”¨ä¸è¯­éŸ³ç›¸å…³çš„é¢éƒ¨åŠ¨ä½œå•å…ƒ (AU) ä¿¡æ¯å°†äººè„¸åˆ†è§£æˆéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ã€‚</li>
<li>ä»…å°†éŸ³é¢‘é¢éƒ¨ä¸éŸ³é¢‘ç‰¹å¾èåˆï¼Œä»¥ç²¾ç¡®åœ°è°ƒèŠ‚éŸ³é¢‘å¯¹è¯´è¯äººé¢éƒ¨çš„å½±å“ã€‚</li>
<li>å°† AU ä¿¡æ¯ä¹Ÿç”¨äºç›‘ç£è¿™ä¸¤ç§æ¨¡æ€çš„èåˆã€‚</li>
<li>å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼ŒNeRF-AD åœ¨ç”Ÿæˆé€¼çœŸçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬å›¾åƒè´¨é‡å’Œå”‡å½¢åŒæ­¥ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šNeRF-ADï¼šåŸºäºæ³¨æ„åŠ›æœºåˆ¶åˆ†è§£çš„ç¥ç»è¾å°„åœºè¯´è¯äººé¢éƒ¨åˆæˆ</li>
<li>ä½œè€…ï¼šChongke Biï¼ŒXiaoxing Liuï¼ŒZhilei Liu</li>
<li>å•ä½ï¼šå¤©æ´¥å¤§å­¦æ™ºèƒ½ä¸è®¡ç®—å­¦é™¢</li>
<li>å…³é”®è¯ï¼šè¯´è¯äººé¢éƒ¨åˆæˆï¼Œç¥ç»è¾å°„åœºï¼Œé¢éƒ¨åˆ†è§£</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.12568ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººé¢éƒ¨åˆæˆæ˜¯å¤šç»´ä¿¡å·å¤„ç†å’Œå¤šåª’ä½“é¢†åŸŸçš„ç ”ç©¶çƒ­ç‚¹ä¹‹ä¸€ã€‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æœ€è¿‘è¢«å¼•å…¥è¯¥ç ”ç©¶é¢†åŸŸï¼Œä»¥å¢å¼ºç”Ÿæˆé¢éƒ¨çš„çœŸå®æ„Ÿå’Œ 3D æ•ˆæœã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰çš„åŸºäº NeRF çš„æ–¹æ³•è¦ä¹ˆç»™ NeRF å¢åŠ å¤æ‚çš„å­¦ä¹ ä»»åŠ¡ï¼ŒåŒæ—¶ç¼ºä¹ç›‘ç£å¼å¤šæ¨¡æ€ç‰¹å¾èåˆçš„æ–¹æ³•ï¼Œè¦ä¹ˆæ— æ³•å°†éŸ³é¢‘ç²¾ç¡®æ˜ å°„åˆ°ä¸è¯´è¯è¿åŠ¨ç›¸å…³çš„é¢éƒ¨åŒºåŸŸã€‚è¿™äº›åŸå› æœ€ç»ˆå¯¼è‡´ç°æœ‰æ–¹æ³•ç”Ÿæˆçš„å”‡å½¢ä¸å‡†ç¡®ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€äº›æ–¹æ³•å°† NeRF çš„å­¦ä¹ ä»»åŠ¡æå‰ä¸€éƒ¨åˆ†ï¼Œå¹¶æå‡ºäº†ä¸€ç§é€šè¿‡ NeRF è¿›è¡Œè¯´è¯äººé¢éƒ¨åˆæˆçš„åŸºäºæ³¨æ„åŠ›æœºåˆ¶åˆ†è§£çš„æ–¹æ³•ï¼ˆNeRF-ADï¼‰ã€‚å…·ä½“æ¥è¯´ï¼Œå¼•å…¥äº†ä¸€ä¸ªåŸºäºæ³¨æ„åŠ›çš„åˆ†è§£æ¨¡å—ï¼Œåˆ©ç”¨ä¸è¯­éŸ³ç›¸å…³çš„é¢éƒ¨åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰ä¿¡æ¯å°†é¢éƒ¨åˆ†è§£ä¸ºéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ã€‚ä¸ºäº†ç²¾ç¡®åœ°è°ƒèŠ‚éŸ³é¢‘å¦‚ä½•å½±å“è¯´è¯äººçš„é¢éƒ¨ï¼Œæˆ‘ä»¬åªå°†éŸ³é¢‘é¢éƒ¨ä¸éŸ³é¢‘ç‰¹å¾èåˆã€‚æ­¤å¤–ï¼Œè¿˜åˆ©ç”¨ AU ä¿¡æ¯æ¥ç›‘ç£è¿™ä¸¤ä¸ªæ¨¡æ€çš„èåˆã€‚å¤§é‡å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ NeRF-AD åœ¨ç”Ÿæˆé€¼çœŸçš„è¯´è¯äººé¢éƒ¨è§†é¢‘ï¼ˆåŒ…æ‹¬å›¾åƒè´¨é‡å’Œå”‡å½¢åŒæ­¥ï¼‰æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåŸºäºæ³¨æ„åŠ›çš„åˆ†è§£æ¨¡å—ï¼Œåˆ©ç”¨ AU æŒ‡å¯¼æ³¨æ„åŠ›æ¨¡å‹ç”Ÿæˆä¸è¯´è¯è¿åŠ¨ç›¸å…³çš„é¢éƒ¨åŒºåŸŸçš„æ©ç ã€‚é€šè¿‡åˆ©ç”¨è¿™äº›æ©ç ï¼Œæˆ‘ä»¬å¯ä»¥æœ‰æ•ˆåœ°å°†è¾“å…¥é¢éƒ¨åˆ†è§£ä¸ºä¸åŒçš„ç»„æˆéƒ¨åˆ†ï¼šéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ã€‚éŸ³é¢‘é¢éƒ¨è¡¨ç¤ºä¸è¯´è¯è¿åŠ¨ç›¸å…³çš„é¢éƒ¨åŒºåŸŸï¼Œä¸éŸ³é¢‘ç‰¹å¾èåˆï¼Œè€Œèº«ä»½é¢éƒ¨è¡¨ç¤ºä¸è¯´è¯äººèº«ä»½ç›¸å…³çš„é¢éƒ¨åŒºåŸŸã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒéŸ³é¢‘ç‰¹å¾åªå½±å“éŸ³é¢‘é¢éƒ¨ï¼Œä»è€Œå¯¹ç”Ÿæˆçš„è¯´è¯äººé¢éƒ¨æä¾›ç²¾ç¡®çš„æ§åˆ¶ã€‚éšåï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ¡ä»¶ NeRFï¼Œä»¥å°†èåˆçš„éŸ³é¢‘é¢éƒ¨ç‰¹å¾å’Œèº«ä»½é¢éƒ¨ç‰¹å¾ä½œä¸ºæ¡ä»¶ï¼Œç²¾ç¡®åœ°æ¸²æŸ“è¯´è¯äººé¢éƒ¨å›¾åƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨ AU æŸå¤±æ¥ç›‘ç£éŸ³é¢‘é¢éƒ¨ç‰¹å¾å’ŒéŸ³é¢‘ç‰¹å¾çš„èåˆè¿‡ç¨‹ï¼Œä»¥ä¾¿èƒ½å¤Ÿå‡†ç¡®åœ°èåˆä¸¤è€…ã€‚åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åˆ†æ•£äº† NeRF çš„ä»»åŠ¡ï¼Œå¹¶ä½¿ç”¨ä¸åŒçš„æ–¹æ³•æ¥ç›‘ç£æ¯ä¸ªä»»åŠ¡ï¼Œä½¿ NeRF æ›´æ¸…æ¥šåœ°çŸ¥é“å®ƒéœ€è¦å­¦ä¹ ä»€ä¹ˆã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼šæˆ‘ä»¬çš„ NeRF-AD åœ¨ç”Ÿæˆé€¼çœŸçš„è¯´è¯äººé¢éƒ¨è§†é¢‘ï¼ˆåŒ…æ‹¬å›¾åƒè´¨é‡å’Œå”‡å½¢åŒæ­¥ï¼‰æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚å®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å”‡å½¢åŒæ­¥å‡†ç¡®æ€§å’Œå›¾åƒè´¨é‡æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒæˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆé€¼çœŸçš„è¯´è¯äººé¢éƒ¨è§†é¢‘ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„åˆ†è§£æ¨¡å—ï¼Œåˆ©ç”¨ä¸è¯­éŸ³ç›¸å…³çš„é¢éƒ¨åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰ä¿¡æ¯å°†é¢éƒ¨åˆ†è§£ä¸ºéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ã€‚
ï¼ˆ2ï¼‰ï¼šå°†éŸ³é¢‘é¢éƒ¨ä¸éŸ³é¢‘ç‰¹å¾èåˆï¼Œå¹¶åˆ©ç”¨AUä¿¡æ¯æ¥ç›‘ç£è¿™ä¸¤ä¸ªæ¨¡æ€çš„èåˆã€‚
ï¼ˆ3ï¼‰ï¼šè®¾è®¡äº†ä¸€ä¸ªæ¡ä»¶NeRFï¼Œä»¥å°†èåˆçš„éŸ³é¢‘é¢éƒ¨ç‰¹å¾å’Œèº«ä»½é¢éƒ¨ç‰¹å¾ä½œä¸ºæ¡ä»¶ï¼Œç²¾ç¡®åœ°æ¸²æŸ“è¯´è¯äººé¢éƒ¨å›¾åƒã€‚
ï¼ˆ4ï¼‰ï¼šä½¿ç”¨AUæŸå¤±æ¥ç›‘ç£éŸ³é¢‘é¢éƒ¨ç‰¹å¾å’ŒéŸ³é¢‘ç‰¹å¾çš„èåˆè¿‡ç¨‹ï¼Œä»¥ä¾¿èƒ½å¤Ÿå‡†ç¡®åœ°èåˆä¸¤è€…ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šNeRF-AD æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„åˆ†è§£æ¨¡å—ï¼Œåˆ©ç”¨ä¸è¯­éŸ³ç›¸å…³çš„é¢éƒ¨åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰ä¿¡æ¯å°†é¢éƒ¨åˆ†è§£ä¸ºéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ã€‚æˆ‘ä»¬åªèåˆéŸ³é¢‘é¢éƒ¨ç‰¹å¾å’ŒéŸ³é¢‘ç‰¹å¾æ¥å‡†ç¡®æ§åˆ¶éŸ³é¢‘å¯¹è¯´è¯é¢éƒ¨çš„å½±å“ã€‚æ­¤å¤–ï¼ŒAU ä¿¡æ¯ç”¨äºæ§åˆ¶ä¸åŒæ¨¡æ€ç‰¹å¾çš„ç²¾ç¡®èåˆã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒçš„ç»“æœè¡¨æ˜ï¼ŒNeRF-AD åœ¨å›¾åƒè´¨é‡å’Œå”‡å½¢åŒæ­¥æ–¹é¢å‡ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„åˆ†è§£æ¨¡å—ï¼Œå°†è¯´è¯é¢éƒ¨åˆ†è§£ä¸ºéŸ³é¢‘é¢éƒ¨å’Œèº«ä»½é¢éƒ¨ã€‚
åªèåˆéŸ³é¢‘é¢éƒ¨ç‰¹å¾å’ŒéŸ³é¢‘ç‰¹å¾æ¥å‡†ç¡®æ§åˆ¶éŸ³é¢‘å¯¹è¯´è¯é¢éƒ¨çš„å½±å“ã€‚
åˆ©ç”¨ AU ä¿¡æ¯æ¥æ§åˆ¶ä¸åŒæ¨¡æ€ç‰¹å¾çš„ç²¾ç¡®èåˆã€‚
æ€§èƒ½ï¼š
åœ¨å›¾åƒè´¨é‡å’Œå”‡å½¢åŒæ­¥æ–¹é¢ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºæ¥è®­ç»ƒ NeRF æ¨¡å‹ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-964938af99e1099b95b512a910ce466c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-39deb199fcbfcf9dedfebf11b5272218.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d53c04a42d143a126e5b391f40684f6a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-55f96488825fc7af3820d32c3f4ac6ff.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1072a698b0f056bb4d49ab4715962395.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/01/30/Paper/2024-01-30/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-30-æ›´æ–°"><a href="#2024-01-30-æ›´æ–°" class="headerlink" title="2024-01-30 æ›´æ–°"></a>2024-01-30 æ›´æ–°</h1><h2 id="Diffutoon-High-Resolution-Editable-Toon-Shading-via-Diffusion-Models"><a href="#Diffutoon-High-Resolution-Editable-Toon-Shading-via-Diffusion-Models" class="headerlink" title="Diffutoon: High-Resolution Editable Toon Shading via Diffusion Models"></a>Diffutoon: High-Resolution Editable Toon Shading via Diffusion Models</h2><p><strong>Authors:Zhongjie Duan, Chengyu Wang, Cen Chen, Weining Qian, Jun Huang</strong></p>
<p>Toon shading is a type of non-photorealistic rendering task of animation. Its primary purpose is to render objects with a flat and stylized appearance. As diffusion models have ascended to the forefront of image synthesis methodologies, this paper delves into an innovative form of toon shading based on diffusion models, aiming to directly render photorealistic videos into anime styles. In video stylization, extant methods encounter persistent challenges, notably in maintaining consistency and achieving high visual quality. In this paper, we model the toon shading problem as four subproblems: stylization, consistency enhancement, structure guidance, and colorization. To address the challenges in video stylization, we propose an effective toon shading approach called \textit{Diffutoon}. Diffutoon is capable of rendering remarkably detailed, high-resolution, and extended-duration videos in anime style. It can also edit the content according to prompts via an additional branch. The efficacy of Diffutoon is evaluated through quantitive metrics and human evaluation. Notably, Diffutoon surpasses both open-source and closed-source baseline approaches in our experiments. Our work is accompanied by the release of both the source code and example videos on Github (Project page: <a href="https://ecnu-cilab.github.io/DiffutoonProjectPage/">https://ecnu-cilab.github.io/DiffutoonProjectPage/</a>). </p>
<p><a href="http://arxiv.org/abs/2401.16224v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä»¥æ‰©æ•£æ¨¡å‹ä¸ºåŸºç¡€ï¼Œæå‡ºä¸€ç§å°†å†™å®è§†é¢‘ç›´æ¥æ¸²æŸ“æˆåŠ¨æ¼«é£æ ¼çš„åˆ›æ–°æ€§å¡é€šæ¸²æŸ“æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å°†å¡é€šæ¸²æŸ“é—®é¢˜å»ºæ¨¡ä¸ºå››ä¸ªå­é—®é¢˜ï¼šé£æ ¼åŒ–ã€ä¸€è‡´æ€§å¢å¼ºã€ç»“æ„å¼•å¯¼å’Œç€è‰²ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åä¸º Diffutoon çš„æœ‰æ•ˆå¡é€šæ¸²æŸ“æ–¹æ³•ï¼Œèƒ½å¤Ÿæ¸²æŸ“å‡ºç»†èŠ‚ä¸°å¯Œã€é«˜åˆ†è¾¨ç‡ã€é•¿æ—¶é—´çš„åŠ¨æ¼«é£æ ¼è§†é¢‘ã€‚</li>
<li>Diffutoon å¯ä»¥é€šè¿‡é¢å¤–çš„åˆ†æ”¯æ ¹æ®æç¤ºç¼–è¾‘è§†é¢‘å†…å®¹ã€‚</li>
<li>åœ¨å®šé‡æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ä¸­ï¼ŒDiffutoon ä¼˜äºå¼€æºå’Œé—­æºåŸºçº¿æ–¹æ³•ã€‚</li>
<li>åœ¨ Github ä¸Šå‘å¸ƒäº†æºä»£ç å’Œç¤ºä¾‹è§†é¢‘ï¼ˆé¡¹ç›®ä¸»é¡µï¼š<a href="https://ecnu-cilab.github.io/DiffutoonProjectPage/ï¼‰ã€‚">https://ecnu-cilab.github.io/DiffutoonProjectPage/ï¼‰ã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šToonShadingï¼šåŸºäºæ‰©æ•£çš„é«˜åˆ†è¾¨ç‡å¯ç¼–è¾‘å¡é€šæ¸²æŸ“</li>
<li>ä½œè€…ï¼šZhongjie Duan, Chengyu Wang, Cen Chen, Weining Qian, Jun Huang</li>
<li>å•ä½ï¼šåä¸œå¸ˆèŒƒå¤§å­¦</li>
<li>å…³é”®è¯ï¼šToonShading, DiffusionModels, VideoSynthesis</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone, Github ä»£ç é“¾æ¥ï¼šhttps://github.com/ecnu-cilab/DiffutoonProjectPage/</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¡é€šæ¸²æŸ“æ˜¯ä¸€ç§éçœŸå®æ„Ÿæ¸²æŸ“ä»»åŠ¡ï¼Œå…¶ä¸»è¦ç›®çš„æ˜¯ä»¥æ‰å¹³å’Œé£æ ¼åŒ–çš„å¤–è§‚æ¸²æŸ“å¯¹è±¡ã€‚æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆæˆæ–¹æ³•å­¦ä¸­å æ®äº†å‰æ²¿åœ°ä½ï¼Œæœ¬æ–‡æ·±å…¥ç ”ç©¶äº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„åˆ›æ–°å¡é€šæ¸²æŸ“å½¢å¼ï¼Œæ—¨åœ¨å°†é€¼çœŸçš„è§†é¢‘ç›´æ¥æ¸²æŸ“æˆåŠ¨ç”»é£æ ¼ã€‚åœ¨è§†é¢‘é£æ ¼åŒ–ä¸­ï¼Œç°æœ‰æ–¹æ³•é¢ä¸´ç€æŒç»­çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¿æŒä¸€è‡´æ€§å’Œå®ç°é«˜è§†è§‰è´¨é‡æ–¹é¢ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šåœ¨ä¸å—æ§çš„å›¾åƒåˆæˆä¸­ï¼ŒåŸºäºé€‚é…å™¨ç±»å‹çš„æ§åˆ¶æ¨¡å—å·²ç»è¯æ˜äº†ç²¾ç¡®æ§åˆ¶çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å—ä»…é™äºå¤„ç†å•ä¸ªå›¾åƒï¼Œæ— æ³•å¤„ç†è§†é¢‘ã€‚ä¸ºäº†æé«˜è§†é¢‘çš„ä¸€è‡´æ€§ï¼Œå…³äºæ­¤ä¸»é¢˜çš„ç ”ç©¶é€šå¸¸åˆ†ä¸ºä¸¤ç±»ï¼šæ— è®­ç»ƒå’ŒåŸºäºè®­ç»ƒçš„æ–¹æ³•ã€‚æ— è®­ç»ƒæ–¹æ³•é€šè¿‡æ„å»ºç‰¹å®šæœºåˆ¶æ¥å¯¹é½å¸§ä¹‹é—´çš„å†…å®¹ï¼Œæ— éœ€è®­ç»ƒè¿‡ç¨‹ï¼Œä½†å…¶æœ‰æ•ˆæ€§æœ‰é™ã€‚å¦ä¸€æ–¹é¢ï¼ŒåŸºäºè®­ç»ƒçš„æ–¹æ³•é€šå¸¸å¯ä»¥å®ç°æ›´å¥½çš„ç»“æœã€‚ç„¶è€Œï¼Œç”±äºå¯¹å†—é•¿çš„è§†é¢‘æ•°æ®é›†è¿›è¡Œæ‰©æ•£æ¨¡å‹è®­ç»ƒæ‰€éœ€çš„è®¡ç®—èµ„æºéå¸¸å¤§ï¼Œå› æ­¤å¤§å¤šæ•°è§†é¢‘æ‰©æ•£æ¨¡å‹åªèƒ½å¤„ç†æœ€å¤š 32 å¸§çš„è¿ç»­å¸§ï¼Œä»è€Œå¯¼è‡´è¾ƒé•¿è§†é¢‘ä¸­å‡ºç°ä¸ä¸€è‡´çš„æƒ…å†µã€‚ä¸ºäº†è·å¾—æ›´å¥½çš„è§†è§‰è´¨é‡ï¼Œè¶…åˆ†è¾¨ç‡æŠ€æœ¯å¯ä»¥æ½œåœ¨åœ°æé«˜è§†é¢‘åˆ†è¾¨ç‡ï¼Œä½†å®ƒä»¬å¯èƒ½ä¼šå¼•å…¥è¿‡åº¦å¹³æ»‘çš„ä¿¡æ¯ä¸¢å¤±ç­‰é¢å¤–é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸“é—¨é’ˆå¯¹å¡é€šæ¸²æŸ“çš„è§†é¢‘å¤„ç†æ–¹æ³•ã€‚æˆ‘ä»¬å°†å¡é€šæ¸²æŸ“é—®é¢˜åˆ’åˆ†ä¸ºå››ä¸ªå­é—®é¢˜ï¼šé£æ ¼åŒ–ã€ä¸€è‡´æ€§å¢å¼ºã€ç»“æ„å¼•å¯¼å’Œç€è‰²ã€‚å¯¹äºæ¯ä¸ªå­é—®é¢˜ï¼Œæˆ‘ä»¬éƒ½æä¾›äº†ä¸€ä¸ªå…·ä½“çš„è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬æå‡ºçš„æ¡†æ¶ç”±ä¸€ä¸ªä¸»è¦çš„å¡é€šæ¸²æŸ“ç®¡é“å’Œä¸€ä¸ªç¼–è¾‘åˆ†æ”¯ç»„æˆã€‚åœ¨ä¸»è¦çš„å¡é€šæ¸²æŸ“ç®¡é“ä¸­ï¼Œæˆ‘ä»¬åŸºäºåŠ¨æ¼«é£æ ¼çš„æ‰©æ•£æ¨¡å‹æ„å»ºäº†ä¸€ä¸ªå¤šæ¨¡å—å»å™ªæ¨¡å‹ã€‚ControlNet å’Œ AnimateDiff ç”¨äºå»å™ªæ¨¡å‹ä¸­ä»¥è§£å†³å¯æ§æ€§å’Œä¸€è‡´æ€§é—®é¢˜ã€‚ä¸ºäº†åœ¨é•¿è§†é¢‘ä¸­ç”Ÿæˆè¶…é«˜åˆ†è¾¨ç‡çš„å†…å®¹ï¼Œæˆ‘ä»¬åç¦»äº†ä¼ ç»Ÿçš„é€å¸§ç”ŸæˆèŒƒä¾‹ã€‚ç›¸åï¼Œæˆ‘ä»¬é‡‡ç”¨æ»‘åŠ¨çª—å£æ–¹æ³•æ¥å¤„ç†è§†é¢‘ã€‚åœ¨ç¼–è¾‘åˆ†æ”¯ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨æç¤ºæ¥æ§åˆ¶è§†é¢‘çš„å†…å®¹ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ä»»åŠ¡å’Œæ€§èƒ½æ–¹é¢ï¼Œæœ¬æ–‡æ–¹æ³•èƒ½å¤Ÿæ¸²æŸ“å‡ºéå¸¸è¯¦ç»†ã€é«˜åˆ†è¾¨ç‡å’Œé•¿æ—¶é—´çš„åŠ¨ç”»é£æ ¼è§†é¢‘ã€‚å®ƒè¿˜å¯ä»¥æ ¹æ®æç¤ºé€šè¿‡é¢å¤–çš„åˆ†æ”¯ç¼–è¾‘å†…å®¹ã€‚Diffutoon çš„æœ‰æ•ˆæ€§é€šè¿‡å®šé‡æŒ‡æ ‡å’Œäººç±»è¯„ä¼°æ¥è¯„ä¼°ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDiffutoon åœ¨æˆ‘ä»¬çš„å®éªŒä¸­è¶…è¶Šäº†å¼€æºå’Œé—­æºåŸºçº¿æ–¹æ³•ã€‚æˆ‘ä»¬çš„å·¥ä½œä¼´éšç€æºä»£ç å’Œç¤ºä¾‹è§†é¢‘åœ¨ Github ä¸Šå‘å¸ƒã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸“é—¨é’ˆå¯¹è§†é¢‘æ¸²æŸ“çš„è§†é¢‘å¤„ç†æ–¹æ³•ï¼Œå°†è§†é¢‘æ¸²æŸ“é—®é¢˜åˆ’åˆ†ä¸ºå››ä¸ªå­é—®é¢˜ï¼šå»å™ªã€ä¸€è‡´æ€§å¢å¼ºã€ç»“æ„å¼•å¯¼å’Œç€è‰²ï¼Œå¹¶é’ˆå¯¹æ¯ä¸ªå­é—®é¢˜æå‡ºäº†å…·ä½“çš„è§£å†³æ–¹æ¡ˆã€‚
ï¼ˆ2ï¼‰æˆ‘ä»¬æå‡ºçš„æ¡†æ¶ç”±ä¸€ä¸ªä¸»è¦çš„è§†é¢‘æ¸²æŸ“ç®¡é“å’Œä¸€ä¸ªç¼–è¾‘åˆ†æ”¯ç»„æˆã€‚åœ¨ä¸»è¦çš„è§†é¢‘æ¸²æŸ“ç®¡é“ä¸­ï¼Œæˆ‘ä»¬åŸºäºåŠ¨æ¼«è§†é¢‘çš„æ‰©æ•£æ¨¡å‹æ„å»ºäº†ä¸€ä¸ªå¤šæ¨¡å—å»å™ªæ¨¡å‹ï¼Œå¹¶åˆ©ç”¨ControlNetå’ŒAnimateDiffè§£å†³å¯æ§æ€§å’Œä¸€è‡´æ€§é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ä¸ºäº†åœ¨é•¿è§†é¢‘ä¸­ç”Ÿæˆè¶…é«˜åˆ†è¾¨ç‡çš„å†…å®¹ï¼Œæˆ‘ä»¬åç¦»äº†ä¼ ç»Ÿçš„é€å¸§ç”ŸæˆèŒƒä¾‹ï¼Œè½¬è€Œé‡‡ç”¨çª—å£æ–¹æ³•æ¥å¤„ç†è§†é¢‘ã€‚
ï¼ˆ4ï¼‰åœ¨ç¼–è¾‘åˆ†æ”¯ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨æç¤ºæ¥æ§åˆ¶è§†é¢‘çš„å†…å®¹ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºè§†é¢‘æ¸²æŸ“çš„åˆ›æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆéå¸¸è¯¦ç»†ã€é«˜åˆ†è¾¨ç‡å’Œé•¿æ—¶é—´çš„åŠ¨ç”»é£æ ¼è§†é¢‘ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡æç¤ºç¼–è¾‘è§†é¢‘å†…å®¹ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§ä¸“é—¨é’ˆå¯¹è§†é¢‘æ¸²æŸ“çš„è§†é¢‘å¤„ç†æ–¹æ³•ï¼Œå°†è§†é¢‘æ¸²æŸ“é—®é¢˜åˆ’åˆ†ä¸ºå››ä¸ªå­é—®é¢˜ï¼šå»å™ªã€ä¸€è‡´æ€§å¢å¼ºã€ç»“æ„å¼•å¯¼å’Œç€è‰²ï¼Œå¹¶é’ˆå¯¹æ¯ä¸ªå­é—®é¢˜æå‡ºäº†å…·ä½“çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>åœ¨ä¸»è¦çš„è§†é¢‘æ¸²æŸ“ç®¡é“ä¸­ï¼ŒåŸºäºåŠ¨æ¼«è§†é¢‘çš„æ‰©æ•£æ¨¡å‹æ„å»ºäº†ä¸€ä¸ªå¤šæ¨¡å—å»å™ªæ¨¡å‹ï¼Œå¹¶åˆ©ç”¨ControlNetå’ŒAnimateDiffè§£å†³å¯æ§æ€§å’Œä¸€è‡´æ€§é—®é¢˜ã€‚</li>
<li>ä¸ºäº†åœ¨é•¿è§†é¢‘ä¸­ç”Ÿæˆè¶…é«˜åˆ†è¾¨ç‡çš„å†…å®¹ï¼Œåç¦»äº†ä¼ ç»Ÿçš„é€å¸§ç”ŸæˆèŒƒä¾‹ï¼Œè½¬è€Œé‡‡ç”¨çª—å£æ–¹æ³•æ¥å¤„ç†è§†é¢‘ã€‚</li>
<li>åœ¨ç¼–è¾‘åˆ†æ”¯ä¸­ï¼Œåˆ©ç”¨æç¤ºæ¥æ§åˆ¶è§†é¢‘çš„å†…å®¹ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä»»åŠ¡å’Œæ€§èƒ½æ–¹é¢ï¼Œæœ¬æ–‡æ–¹æ³•èƒ½å¤Ÿæ¸²æŸ“å‡ºéå¸¸è¯¦ç»†ã€é«˜åˆ†è¾¨ç‡å’Œé•¿æ—¶é—´çš„åŠ¨ç”»é£æ ¼è§†é¢‘ã€‚</li>
<li>å®ƒè¿˜å¯ä»¥æ ¹æ®æç¤ºé€šè¿‡é¢å¤–çš„åˆ†æ”¯ç¼–è¾‘å†…å®¹ã€‚</li>
<li>Diffutoonçš„æœ‰æ•ˆæ€§é€šè¿‡å®šé‡æŒ‡æ ‡å’Œäººç±»è¯„ä¼°æ¥è¯„ä¼°ã€‚</li>
<li>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDiffutoonåœ¨æˆ‘ä»¬çš„å®éªŒä¸­è¶…è¶Šäº†å¼€æºå’Œé—­æºåŸºçº¿æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡å·¥ä½œé‡è¾ƒå¤§ï¼Œæ¶‰åŠåˆ°æ‰©æ•£æ¨¡å‹ã€æ§åˆ¶ç½‘ç»œã€ä¸€è‡´æ€§å¢å¼ºã€ç»“æ„å¼•å¯¼å’Œç€è‰²ç­‰å¤šä¸ªæ–¹é¢ã€‚</li>
<li>éœ€è¦å¯¹åŠ¨æ¼«è§†é¢‘è¿›è¡Œå¤§è§„æ¨¡çš„æ•°æ®é›†è®­ç»ƒï¼Œä»¥æ„å»ºåŠ¨æ¼«é£æ ¼çš„æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>éœ€è¦å¯¹ControlNetå’ŒAnimateDiffè¿›è¡Œè®­ç»ƒï¼Œä»¥è§£å†³å¯æ§æ€§å’Œä¸€è‡´æ€§é—®é¢˜ã€‚</li>
<li>éœ€è¦å¯¹è§†é¢‘è¿›è¡Œé€å¸§å¤„ç†ï¼Œä»¥ç”Ÿæˆè¶…é«˜åˆ†è¾¨ç‡çš„åŠ¨ç”»é£æ ¼è§†é¢‘ã€‚</li>
<li>éœ€è¦å¯¹ç¼–è¾‘åˆ†æ”¯è¿›è¡Œè®­ç»ƒï¼Œä»¥å®ç°å¯¹è§†é¢‘å†…å®¹çš„æ§åˆ¶ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e68001de35eaf91396e2b23b2c2ecde0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3a8e23447d7367cb91d3ccb6108983df.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3aa40ea0bb553ba90b2221490a232dfc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fe06192b1bad47a43ecbf8ac48335ed1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-259d9693cc43c3d292031b46b3292db9.jpg" align="middle">
</details>




<h2 id="Object-Driven-One-Shot-Fine-tuning-of-Text-to-Image-Diffusion-with-Prototypical-Embedding"><a href="#Object-Driven-One-Shot-Fine-tuning-of-Text-to-Image-Diffusion-with-Prototypical-Embedding" class="headerlink" title="Object-Driven One-Shot Fine-tuning of Text-to-Image Diffusion with   Prototypical Embedding"></a>Object-Driven One-Shot Fine-tuning of Text-to-Image Diffusion with   Prototypical Embedding</h2><p><strong>Authors:Jianxiang Lu, Cong Xie, Hui Guo</strong></p>
<p>As large-scale text-to-image generation models have made remarkable progress in the field of text-to-image generation, many fine-tuning methods have been proposed. However, these models often struggle with novel objects, especially with one-shot scenarios. Our proposed method aims to address the challenges of generalizability and fidelity in an object-driven way, using only a single input image and the object-specific regions of interest. To improve generalizability and mitigate overfitting, in our paradigm, a prototypical embedding is initialized based on the objectâ€™s appearance and its class, before fine-tuning the diffusion model. And during fine-tuning, we propose a class-characterizing regularization to preserve prior knowledge of object classes. To further improve fidelity, we introduce object-specific loss, which can also use to implant multiple objects. Overall, our proposed object-driven method for implanting new objects can integrate seamlessly with existing concepts as well as with high fidelity and generalization. Our method outperforms several existing works. The code will be released. </p>
<p><a href="http://arxiv.org/abs/2401.15708v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>ä½¿ç”¨å•ä¸ªè¾“å…¥å›¾åƒå’Œç‰¹å®šå¯¹è±¡å…³æ³¨åŒºåŸŸï¼Œç”Ÿæˆæ¨¡å‹å¯æ¤å…¥æ–°å¯¹è±¡ï¼Œå…¼å…·é«˜ä¿çœŸåº¦å’Œæ³›åŒ–æ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§é¢å‘å¯¹è±¡çš„æ–¹æ³•æ¥æ¤å…¥æ–°å¯¹è±¡ï¼Œä»…ä½¿ç”¨å•ä¸ªè¾“å…¥å›¾åƒå’Œå¯¹è±¡ç‰¹å®šå…³æ³¨åŒºåŸŸã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æ³›åŒ–æ€§å’Œä¿çœŸåº¦æ–¹é¢ä¼˜äºç°æœ‰å·¥ä½œã€‚</li>
<li>åœ¨å¾®è°ƒä¹‹å‰ï¼Œæ ¹æ®å¯¹è±¡çš„å‡ºç°å’Œç±»åˆ«åˆå§‹åŒ–åŸå‹åµŒå…¥ã€‚</li>
<li>åœ¨å¾®è°ƒæœŸé—´ï¼Œæå‡ºäº†ä¸€ç§ç±»ç‰¹å¾æ­£åˆ™åŒ–æ¥ä¿ç•™å¯¹è±¡ç±»åˆ«çš„å…ˆéªŒçŸ¥è¯†ã€‚</li>
<li>å¼•å…¥ç‰¹å®šäºå¯¹è±¡çš„å¯¹è±¡æŸå¤±ï¼Œç”¨äºæ¤å…¥å’Œæ”¾ç½®å¤šä¸ªå¯¹è±¡ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥ä¸ç°æœ‰æ¦‚å¿µæ— ç¼é›†æˆï¼Œå¹¶å…·æœ‰é«˜ä¿çœŸåº¦å’Œæ³›åŒ–æ€§ã€‚</li>
<li>ä»£ç å°†å‘å¸ƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºå¯¹è±¡çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å•æ¬¡å¾®è°ƒ</li>
<li>ä½œè€…ï¼šJianxiang Lu, Cong Xie, Hui Guo</li>
<li>å•ä½ï¼šè…¾è®¯ï¼ˆä¸­å›½ï¼‰</li>
<li>å…³é”®è¯ï¼šobject-driven, one-shot, diffusion model</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.15708
Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—æ˜¾è‘—è¿›å±•ï¼Œè®¸å¤šå¾®è°ƒæ–¹æ³•è¢«æå‡ºã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹é€šå¸¸éš¾ä»¥å¤„ç†æ–°é¢–å¯¹è±¡ï¼Œå°¤å…¶æ˜¯åœ¨å•æ¬¡å¾®è°ƒåœºæ™¯ä¸­ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”éš¾ä»¥ä¿è¯ç”Ÿæˆå›¾åƒçš„ä¿çœŸåº¦å’Œå¯æ§æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹è±¡é©±åŠ¨çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å•æ¬¡å¾®è°ƒæ–¹æ³•ã€‚è¯¥æ–¹æ³•ä»…ä½¿ç”¨å•ä¸ªè¾“å…¥å›¾åƒå’Œå¯¹è±¡ç‰¹å®šçš„æ„Ÿå…´è¶£åŒºåŸŸï¼Œå°±å¯ä»¥æœ‰æ•ˆåœ°å¾®è°ƒæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆå…·æœ‰é«˜ä¿çœŸåº¦å’Œå¯æ§æ€§çš„å›¾åƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå›¾åƒçš„ä¿çœŸåº¦ã€å¯æ§æ€§å’Œæ³›åŒ–æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§åŸºäºå¯¹è±¡é©±åŠ¨çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å•æ¬¡å¾®è°ƒæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨å•ä¸ªè¾“å…¥å›¾åƒå’Œå¯¹è±¡ç‰¹å®šçš„æ„Ÿå…´è¶£åŒºåŸŸï¼Œå°±å¯ä»¥æœ‰æ•ˆåœ°å¾®è°ƒæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆå…·æœ‰é«˜ä¿çœŸåº¦å’Œå¯æ§æ€§çš„å›¾åƒï¼›
ï¼ˆ2ï¼‰å¼•å…¥äº†ä¸€ç§å¯¹è±¡é©±åŠ¨çš„åŸå‹åµŒå…¥åˆå§‹åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°è¡¨ç¤ºå¯¹è±¡ï¼Œæé«˜å¯¹è±¡æ¤å…¥çš„æ•ˆç‡ï¼›
ï¼ˆ3ï¼‰æå‡ºäº†ä¸€ç§å¯¹è±¡é©±åŠ¨çš„ç‰¹å®šæŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°å¯ä»¥ç”¨äºåˆæˆé«˜ä¿çœŸåº¦çš„å›¾åƒï¼Œä¹Ÿå¯ä»¥ç”¨äºå¤šå¯¹è±¡æ¤å…¥ï¼›
ï¼ˆ4ï¼‰å¼•å…¥äº†ä¸€ç§ç±»ç‰¹å¾æ­£åˆ™åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä¿æŠ¤ç±»å…ˆéªŒä¿¡æ¯ï¼Œé˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„æ„ä¹‰ï¼šæå‡ºäº†ä¸€ç§åŸºäºå¯¹è±¡é©±åŠ¨çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å•æ¬¡å¾®è°ƒæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨å•ä¸ªè¾“å…¥å›¾åƒå’Œå¯¹è±¡ç‰¹å®šçš„æ„Ÿå…´è¶£åŒºåŸŸï¼Œå°±å¯ä»¥æœ‰æ•ˆåœ°å¾®è°ƒæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆå…·æœ‰é«˜ä¿çœŸåº¦å’Œå¯æ§æ€§çš„å›¾åƒã€‚
ï¼ˆ2ï¼‰æ–‡ç« çš„ä¼˜ç¼ºç‚¹ï¼š
åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå¯¹è±¡é©±åŠ¨çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å•æ¬¡å¾®è°ƒæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨å•ä¸ªè¾“å…¥å›¾åƒå’Œå¯¹è±¡ç‰¹å®šçš„æ„Ÿå…´è¶£åŒºåŸŸï¼Œå°±å¯ä»¥æœ‰æ•ˆåœ°å¾®è°ƒæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆå…·æœ‰é«˜ä¿çœŸåº¦å’Œå¯æ§æ€§çš„å›¾åƒã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§å¯¹è±¡é©±åŠ¨çš„åŸå‹åµŒå…¥åˆå§‹åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°è¡¨ç¤ºå¯¹è±¡ï¼Œæé«˜å¯¹è±¡æ¤å…¥çš„æ•ˆç‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¯¹è±¡é©±åŠ¨çš„ç‰¹å®šæŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°å¯ä»¥ç”¨äºåˆæˆé«˜ä¿çœŸåº¦çš„å›¾åƒï¼Œä¹Ÿå¯ä»¥ç”¨äºå¤šå¯¹è±¡æ¤å…¥ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§ç±»ç‰¹å¾æ­£åˆ™åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä¿æŠ¤ç±»å…ˆéªŒä¿¡æ¯ï¼Œé˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå›¾åƒçš„ä¿çœŸåº¦ã€å¯æ§æ€§å’Œæ³›åŒ–æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦æ”¶é›†å’Œé¢„å¤„ç†æ•°æ®ï¼ŒåŒ…æ‹¬æ–‡æœ¬æ•°æ®å’Œå›¾åƒæ•°æ®ã€‚</li>
<li>éœ€è¦è®­ç»ƒæ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
<li>éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè¿™å¯èƒ½éœ€è¦é¢å¤–çš„è®­ç»ƒæ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-34290c5f50d1304ffe58b66fbb188569.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1fbf118677f5f5edfac0f56cf14f457e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c92c4056742c512f459d791828c63886.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2f04fc1cc8fffe19240576200c97a367.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4011e336771243f32716368b60213d88.jpg" align="middle">
</details>




<h2 id="CPDM-Content-Preserving-Diffusion-Model-for-Underwater-Image-Enhancement"><a href="#CPDM-Content-Preserving-Diffusion-Model-for-Underwater-Image-Enhancement" class="headerlink" title="CPDM: Content-Preserving Diffusion Model for Underwater Image   Enhancement"></a>CPDM: Content-Preserving Diffusion Model for Underwater Image   Enhancement</h2><p><strong>Authors:Xiaowen Shi, Yuan-Gen Wang</strong></p>
<p>Underwater image enhancement (UIE) is challenging since image degradation in aquatic environments is complicated and changing over time. Existing mainstream methods rely on either physical-model or data-driven, suffering from performance bottlenecks due to changes in imaging conditions or training instability. In this article, we make the first attempt to adapt the diffusion model to the UIE task and propose a Content-Preserving Diffusion Model (CPDM) to address the above challenges. CPDM first leverages a diffusion model as its fundamental model for stable training and then designs a content-preserving framework to deal with changes in imaging conditions. Specifically, we construct a conditional input module by adopting both the raw image and the difference between the raw and noisy images as the input, which can enhance the modelâ€™s adaptability by considering the changes involving the raw images in underwater environments. To preserve the essential content of the raw images, we construct a content compensation module for content-aware training by extracting low-level features from the raw images. Extensive experimental results validate the effectiveness of our CPDM, surpassing the state-of-the-art methods in terms of both subjective and objective metrics. </p>
<p><a href="http://arxiv.org/abs/2401.15649v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹ä¸å†…å®¹ä¿æŒæ¡†æ¶ç›¸ç»“åˆï¼Œç”¨äºæ°´ä¸‹å›¾åƒå¢å¼ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ°´ä¸‹å›¾åƒå¢å¼ºæŠ€æœ¯å¯ä»¥å…‹æœå¤æ‚ä¸”ä¸æ–­å˜åŒ–çš„æ°´ç”Ÿç¯å¢ƒä¸­çš„å›¾åƒé€€åŒ–é—®é¢˜ã€‚</li>
<li>å½“å‰ä¸»æµæ–¹æ³•æˆ–è€…ä¾èµ–ç‰©ç†æ¨¡å‹ï¼Œæˆ–è€…ä¾èµ–æ•°æ®é©±åŠ¨ï¼Œåœ¨æˆåƒæ¡ä»¶å˜åŒ–æˆ–è®­ç»ƒä¸ç¨³å®šæ—¶æ€§èƒ½ä¼šä¸‹é™ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å†…å®¹ä¿æŒæ‰©æ•£æ¨¡å‹ï¼ˆCPDMï¼‰æ¥è§£å†³ä¸Šè¿°æŒ‘æˆ˜ï¼ŒCPDM ä»¥æ‰©æ•£æ¨¡å‹ä½œä¸ºåŸºç¡€æ¨¡å‹è¿›è¡Œç¨³å®šè®­ç»ƒï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªå†…å®¹ä¿æŒæ¡†æ¶æ¥å¤„ç†æˆåƒæ¡ä»¶çš„å˜åŒ–ã€‚</li>
<li>CPDM æ„å»ºäº†ä¸€ä¸ªæ¡ä»¶è¾“å…¥æ¨¡å—ï¼Œé‡‡ç”¨åŸå§‹å›¾åƒå’ŒåŸå§‹å›¾åƒä¸å™ªå£°å›¾åƒçš„å·®å€¼ä½œä¸ºè¾“å…¥ï¼Œå¯ä»¥è€ƒè™‘æ°´ä¸‹ç¯å¢ƒä¸­åŸå§‹å›¾åƒçš„å˜åŒ–ï¼Œæé«˜æ¨¡å‹çš„é€‚åº”æ€§ã€‚</li>
<li>ä¸ºäº†ä¿æŒåŸå§‹å›¾åƒçš„åŸºæœ¬å†…å®¹ï¼ŒCPDM æ„å»ºäº†ä¸€ä¸ªå†…å®¹è¡¥å¿æ¨¡å—ï¼Œé€šè¿‡ä»åŸå§‹å›¾åƒä¸­æå–ä½çº§ç‰¹å¾è¿›è¡Œå†…å®¹æ„ŸçŸ¥è®­ç»ƒã€‚</li>
<li>å¤§é‡å®éªŒç»“æœéªŒè¯äº† CPDM çš„æœ‰æ•ˆæ€§ï¼Œåœ¨ä¸»è§‚å’Œå®¢è§‚æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šCPDMï¼šç”¨äºæ°´ä¸‹å›¾åƒå¢å¼ºçš„ä¿å†…å®¹æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šXiaowen Shi, Yuan-Gen Wang</li>
<li>å•ä½ï¼šå¹¿å·å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸ç½‘ç»œå·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šæ°´ä¸‹å›¾åƒå¢å¼ºã€æ‰©æ•£æ¨¡å‹ã€æ¡ä»¶è¾“å…¥æ¨¡å—ã€å†…å®¹è¡¥å¿æ¨¡å—</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.15649</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ°´ä¸‹å›¾åƒå¢å¼ºæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºæ°´ä¸‹ç¯å¢ƒä¸­çš„å›¾åƒé€€åŒ–å¤æ‚ä¸”éšæ—¶é—´å˜åŒ–ã€‚ç°æœ‰çš„ä¸»æµæ–¹æ³•è¦ä¹ˆä¾èµ–äºç‰©ç†æ¨¡å‹ï¼Œè¦ä¹ˆä¾èµ–äºæ•°æ®é©±åŠ¨ï¼Œç”±äºæˆåƒæ¡ä»¶çš„å˜åŒ–æˆ–è®­ç»ƒçš„ä¸ç¨³å®šæ€§ï¼Œå®ƒä»¬åœ¨æ€§èƒ½ä¸Šå­˜åœ¨ç“¶é¢ˆã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šç‰©ç†æ¨¡å‹æ–¹æ³•æ—¨åœ¨æ¨¡æ‹Ÿæ°´ä¸­çš„å…‰ä¼ æ’­è¿‡ç¨‹ï¼Œä½†ç”±äºæ°´ä¸‹ç¯å¢ƒéšæ—¶é—´å˜åŒ–ï¼Œè¿™ç§æ–¹æ³•æ— æ³•é€‚åº”ä¸åŒçš„ç‰©ç†åœºæ™¯ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›å·®ã€‚æ•°æ®é©±åŠ¨æ–¹æ³•ä¾èµ–äºå¤§è§„æ¨¡æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œå¯ä»¥æœ‰æ•ˆåœ°æé«˜å›¾åƒè´¨é‡ï¼Œä½†ç›®å‰å»ºç«‹çš„æ°´ä¸‹å›¾åƒå¢å¼ºæ•°æ®é›†é€šå¸¸æ˜¯åœ¨ç‰¹å®šçš„æ°´ä¸‹ç¯å¢ƒä¸­æ”¶é›†çš„ï¼Œå› æ­¤åœ¨å•ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨è·¨æ•°æ®é›†ä¸Šçš„æ€§èƒ½è¾ƒå·®ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ°´ä¸‹å›¾åƒå¢å¼ºæ¡†æ¶ï¼Œç§°ä¸ºä¿å†…å®¹æ‰©æ•£æ¨¡å‹ï¼ˆCPDMï¼‰ã€‚CPDMåˆ©ç”¨åŸå§‹å›¾åƒä½œä¸ºæ¡ä»¶è¾“å…¥ï¼Œå¹¶å¼•å…¥åŸå§‹å›¾åƒä¸å™ªå£°å›¾åƒåœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„å·®å€¼ä½œä¸ºå¦ä¸€ä¸ªæ¡ä»¶è¾“å…¥ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹æ°´ä¸‹ç¯å¢ƒä¸­åŸå§‹å›¾åƒå˜åŒ–çš„é€‚åº”æ€§ã€‚ä¸ºäº†ç¡®ä¿æ¨¡å‹ä¿ç•™åŸå§‹å›¾åƒçš„æœ¬è´¨å†…å®¹ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ä¸ªå†…å®¹è¡¥å¿æ¨¡å—ï¼Œä»åŸå§‹å›¾åƒä¸­æå–ä½çº§ç‰¹å¾è¿›è¡Œå†…å®¹æ„ŸçŸ¥è®­ç»ƒã€‚
ï¼ˆ4ï¼‰æ€§èƒ½ä¸ç›®æ ‡ï¼šCPDMåœ¨æ°´ä¸‹å›¾åƒå¢å¼ºä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨ä¸»è§‚å’Œå®¢è§‚æŒ‡æ ‡ä¸Šéƒ½è¶…è¿‡äº†æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å¼€å‘ä¸€ç§èƒ½å¤Ÿé€‚åº”æ°´ä¸‹ç¯å¢ƒå˜åŒ–å¹¶ä¿ç•™åŸå§‹å›¾åƒå†…å®¹çš„æ°´ä¸‹å›¾åƒå¢å¼ºæ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ°´ä¸‹å›¾åƒå¢å¼ºæ¡†æ¶ï¼Œç§°ä¸ºä¿å†…å®¹æ‰©æ•£æ¨¡å‹ï¼ˆCPDMï¼‰ã€‚
ï¼ˆ2ï¼‰ï¼šCPDMåˆ©ç”¨åŸå§‹å›¾åƒä½œä¸ºæ¡ä»¶è¾“å…¥ï¼Œå¹¶å¼•å…¥åŸå§‹å›¾åƒä¸å™ªå£°å›¾åƒåœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„å·®å€¼ä½œä¸ºå¦ä¸€ä¸ªæ¡ä»¶è¾“å…¥ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹æ°´ä¸‹ç¯å¢ƒä¸­åŸå§‹å›¾åƒå˜åŒ–çš„é€‚åº”æ€§ã€‚
ï¼ˆ3ï¼‰ï¼šä¸ºäº†ç¡®ä¿æ¨¡å‹ä¿ç•™åŸå§‹å›¾åƒçš„æœ¬è´¨å†…å®¹ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ä¸ªå†…å®¹è¡¥å¿æ¨¡å—ï¼Œä»åŸå§‹å›¾åƒä¸­æå–ä½çº§ç‰¹å¾è¿›è¡Œå†…å®¹æ„ŸçŸ¥è®­ç»ƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p>
</li>
</ol>
<p>åˆ›æ–°ç‚¹ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ°´ä¸‹å›¾åƒå¢å¼ºæ¡†æ¶â€”â€”ä¿å†…å®¹æ‰©æ•£æ¨¡å‹ï¼ˆCPDMï¼‰ã€‚
ï¼ˆ2ï¼‰ï¼šCPDMåˆ©ç”¨åŸå§‹å›¾åƒä½œä¸ºæ¡ä»¶è¾“å…¥ï¼Œå¹¶å¼•å…¥åŸå§‹å›¾åƒä¸å™ªå£°å›¾åƒåœ¨æ¯ä¸ªæ—¶é—´æ­¥çš„å·®å€¼ä½œä¸ºå¦ä¸€ä¸ªæ¡ä»¶è¾“å…¥ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹æ°´ä¸‹ç¯å¢ƒä¸­åŸå§‹å›¾åƒå˜åŒ–çš„é€‚åº”æ€§ã€‚
ï¼ˆ3ï¼‰ï¼šä¸ºäº†ç¡®ä¿æ¨¡å‹ä¿ç•™åŸå§‹å›¾åƒçš„æœ¬è´¨å†…å®¹ï¼Œè®¾è®¡äº†ä¸€ä¸ªå†…å®¹è¡¥å¿æ¨¡å—ï¼Œä»åŸå§‹å›¾åƒä¸­æå–ä½çº§ç‰¹å¾è¿›è¡Œå†…å®¹æ„ŸçŸ¥è®­ç»ƒã€‚</p>
<p>æ€§èƒ½ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šCPDMåœ¨æ°´ä¸‹å›¾åƒå¢å¼ºä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨ä¸»è§‚å’Œå®¢è§‚æŒ‡æ ‡ä¸Šéƒ½è¶…è¿‡äº†æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šCPDMèƒ½å¤Ÿæœ‰æ•ˆåœ°å»é™¤æ°´ä¸‹å›¾åƒä¸­çš„å™ªå£°å’Œé›¾éœ¾ï¼Œå¹¶å¢å¼ºå›¾åƒçš„å¯¹æ¯”åº¦å’Œæ¸…æ™°åº¦ã€‚
ï¼ˆ3ï¼‰ï¼šCPDMèƒ½å¤Ÿå¾ˆå¥½åœ°ä¿ç•™åŸå§‹å›¾åƒçš„ç»†èŠ‚å’Œçº¹ç†ï¼Œå¹¶é¿å…äº§ç”Ÿä¼ªå½±ã€‚</p>
<p>å·¥ä½œé‡ï¼š</p>
<p>ï¼ˆ1ï¼‰ï¼šCPDMçš„æ¨¡å‹ç»“æ„ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒå¤šçš„è®­ç»ƒæ—¶é—´ã€‚
ï¼ˆ2ï¼‰ï¼šCPDMéœ€è¦è¾ƒå¤§çš„è®­ç»ƒæ•°æ®é›†ï¼Œè¿™å¯èƒ½éœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›æ¥æ”¶é›†ã€‚
ï¼ˆ3ï¼‰ï¼šCPDMçš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®­ç»ƒæˆæœ¬ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a8fcc331fc0bfeef66e34869766fa2b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cf29b6fb4b07d5c3b4cb5f016776d454.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e73408da8c9156184b27ba3f3078c1e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bd8e60305606bf1ff35f3c3755cc52f5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23da9492dcf3ab60c1d6d6eea0539743.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a9756b4fce0ba8672bb402f3dc4e5905.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4aa90f24b58e47449838d2b7e74a0358.jpg" align="middle">
</details>




## FreeStyle: Free Lunch for Text-guided Style Transfer using Diffusion   Models

**Authors:Feihong He, Gang Li, Mengyuan Zhang, Leilei Yan, Lingyu Si, Fanzhang Li**

The rapid development of generative diffusion models has significantly advanced the field of style transfer. However, most current style transfer methods based on diffusion models typically involve a slow iterative optimization process, e.g., model fine-tuning and textual inversion of style concept. In this paper, we introduce FreeStyle, an innovative style transfer method built upon a pre-trained large diffusion model, requiring no further optimization. Besides, our method enables style transfer only through a text description of the desired style, eliminating the necessity of style images. Specifically, we propose a dual-stream encoder and single-stream decoder architecture, replacing the conventional U-Net in diffusion models. In the dual-stream encoder, two distinct branches take the content image and style text prompt as inputs, achieving content and style decoupling. In the decoder, we further modulate features from the dual streams based on a given content image and the corresponding style text prompt for precise style transfer. Our experimental results demonstrate high-quality synthesis and fidelity of our method across various content images and style text prompts. The code and more results are available at our project website:https://freestylefreelunch.github.io/. 

[PDF](http://arxiv.org/abs/2401.15636v1) 

**Summary**
æ‰©æ•£æ¨¡å‹çš„æœ€æ–°é£æ ¼è¿ç§»æ–¹æ³•æ— éœ€ä¼˜åŒ–ï¼Œä»…éœ€æ–‡æœ¬æè¿°å³å¯å®Œæˆé£æ ¼è¿ç§»ã€‚

**Key Takeaways**
- æ— éœ€è¿›ä¸€æ­¥ä¼˜åŒ–å³å¯ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼è¿ç§»ã€‚
- ä»…éœ€æ–‡æœ¬æè¿°å³å¯å®Œæˆé£æ ¼è¿ç§»ï¼Œæ— éœ€ä½¿ç”¨é£æ ¼å›¾åƒã€‚
- æå‡ºäº†ä¸€ç§å…·æœ‰åŒæµç¼–ç å™¨å’Œå•æµè§£ç å™¨çš„æ¶æ„ï¼Œå–ä»£äº†æ‰©æ•£æ¨¡å‹ä¸­çš„ä¼ ç»Ÿ U-Netã€‚
- åŒæµç¼–ç å™¨å°†å†…å®¹å›¾åƒå’Œé£æ ¼æ–‡æœ¬æç¤ºä½œä¸ºè¾“å…¥ï¼Œä»¥å®ç°å†…å®¹å’Œé£æ ¼çš„è§£è€¦ã€‚
- è§£ç å™¨ä¼šæ ¹æ®ç»™å®šçš„å†…å®¹å›¾åƒå’Œç›¸åº”çš„é£æ ¼æ–‡æœ¬æç¤ºå¯¹æ¥è‡ªåŒæµçš„ç‰¹å¾è¿›è¡Œè°ƒåˆ¶ï¼Œä»¥å®ç°ç²¾å‡†çš„é£æ ¼è¿ç§»ã€‚
- å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§å†…å®¹å›¾åƒå’Œé£æ ¼æ–‡æœ¬æç¤ºä¸‹å‡èƒ½ç”Ÿæˆé«˜è´¨é‡ä¸”ä¿çœŸåº¦é«˜çš„å›¾åƒã€‚
- ä»£ç å’Œæ›´å¤šç»“æœå¯åœ¨é¡¹ç›®ç½‘ç«™ä¸Šæ‰¾åˆ°ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šFreeStyleï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„æ–‡æœ¬å¼•å¯¼é£æ ¼è¿ç§»çš„å…è´¹åˆé¤</li>
<li>ä½œè€…ï¼šFeihong He, Gang Li, Mengyuan Zhang, Leilei Yan, Lingyu Si, Fanzhang Li</li>
<li>éš¶å±æœºæ„ï¼šè‹å·å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢</li>
<li>å…³é”®è¯ï¼šå›¾åƒé£æ ¼è¿ç§»ã€æ‰©æ•£æ¨¡å‹ã€æ–‡æœ¬å¼•å¯¼ã€å†…å®¹å’Œé£æ ¼è§£è€¦</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.15636ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/freestylefreelunch/freestyle</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šå›¾åƒé£æ ¼è¿ç§»æ—¨åœ¨å°†è‡ªç„¶å›¾åƒè½¬æ¢ä¸ºæ‰€éœ€çš„è‰ºæœ¯å›¾åƒï¼ŒåŒæ—¶ä¿ç•™å†…å®¹ä¿¡æ¯ã€‚éšç€ç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œå›¾åƒé£æ ¼è¿ç§»ä¹Ÿå–å¾—äº†é‡å¤§è¿›å±•ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šå¾®è°ƒæ–¹æ³•å’Œåæ¼”æ–¹æ³•ã€‚å¾®è°ƒæ–¹æ³•éœ€è¦ä¼˜åŒ–éƒ¨åˆ†æˆ–å…¨éƒ¨å‚æ•°ï¼Œä»¥å°†ç»™å®šçš„è§†è§‰é£æ ¼åµŒå…¥åˆ°ç”Ÿæˆæ‰©æ•£æ¨¡å‹çš„è¾“å‡ºåŸŸä¸­ã€‚åæ¼”æ–¹æ³•æ¶‰åŠå°†ç‰¹å®šé£æ ¼æˆ–å†…å®¹å­¦ä¹ ä¸ºæ–‡æœ¬æ ‡è®°ï¼Œä»¥æŒ‡å¯¼ç‰¹å®šé£æ ¼çš„ç”Ÿæˆã€‚è¿™ä¸¤ç§æ–¹æ³•é€šå¸¸éœ€è¦æ•°åƒæ¬¡ç”šè‡³æ›´å¤šæ¬¡è¿­ä»£çš„è®­ç»ƒï¼Œå¯¼è‡´å·¨å¤§çš„è®¡ç®—æˆæœ¬å’Œç¼“æ…¢çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„é£æ ¼è¿ç§»æ–¹æ³• FreeStyleï¼Œå®ƒå»ºç«‹åœ¨é¢„è®­ç»ƒçš„å¤§å‹æ‰©æ•£æ¨¡å‹ä¹‹ä¸Šï¼Œä¸éœ€è¦è¿›ä¸€æ­¥çš„ä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»…é€šè¿‡å¯¹æ‰€éœ€é£æ ¼çš„æ–‡æœ¬æè¿°å³å¯å®ç°é£æ ¼è¿ç§»ï¼Œæ¶ˆé™¤äº†å¯¹é£æ ¼å›¾åƒçš„éœ€è¦ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŒæµç¼–ç å™¨å’Œå•æµè§£ç å™¨æ¶æ„ï¼Œå–ä»£äº†æ‰©æ•£æ¨¡å‹ä¸­çš„ä¼ ç»Ÿ U-Netã€‚åœ¨åŒæµç¼–ç å™¨ä¸­ï¼Œä¸¤ä¸ªä¸åŒçš„åˆ†æ”¯åˆ†åˆ«ä»¥å†…å®¹å›¾åƒå’Œé£æ ¼æ–‡æœ¬æç¤ºä½œä¸ºè¾“å…¥ï¼Œå®ç°å†…å®¹å’Œé£æ ¼çš„è§£è€¦ã€‚åœ¨è§£ç å™¨ä¸­ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æ ¹æ®ç»™å®šçš„å†…å®¹å›¾åƒå’Œç›¸åº”çš„é£æ ¼æ–‡æœ¬æç¤ºå¯¹æ¥è‡ªåŒæµçš„ç‰¹å¾è¿›è¡Œè°ƒåˆ¶ï¼Œä»¥å®ç°ç²¾ç¡®çš„é£æ ¼è¿ç§»ã€‚
(4)ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§å†…å®¹å›¾åƒå’Œé£æ ¼æ–‡æœ¬æç¤ºä¸‹éƒ½å…·æœ‰é«˜è´¨é‡çš„åˆæˆå’Œä¿çœŸåº¦ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³æä¾›ä¸€ç§ä¸éœ€è¦ä¼˜åŒ–ä¸”ä»…ä½¿ç”¨æ–‡æœ¬æè¿°å³å¯å®ç°é£æ ¼è¿ç§»çš„æ–¹æ³•ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
(1) æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰åœ¨äºï¼Œå®ƒæå‡ºäº†ä¸€ç§æ— éœ€ä¼˜åŒ–ä¸”ä»…ä½¿ç”¨æ–‡æœ¬æè¿°å³å¯å®ç°é£æ ¼è¿ç§»çš„æ–¹æ³•ï¼Œæå¤§åœ°ç®€åŒ–äº†é£æ ¼è¿ç§»çš„å®ç°è¿‡ç¨‹ï¼Œå¹¶æé«˜äº†é£æ ¼è¿ç§»çš„æ•ˆç‡ã€‚
(2) åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºé¢„è®­ç»ƒçš„å¤§å‹æ‰©æ•£æ¨¡å‹çš„é£æ ¼è¿ç§»æ–¹æ³•ï¼Œæ— éœ€è¿›ä¸€æ­¥çš„ä¼˜åŒ–ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŒæµç¼–ç å™¨å’Œå•æµè§£ç å™¨æ¶æ„ï¼Œå®ç°äº†å†…å®¹å’Œé£æ ¼çš„è§£è€¦ã€‚</li>
<li>é€šè¿‡è°ƒæ•´ç¼©æ”¾å› å­ï¼Œå¯ä»¥è½»æ¾åœ°é€‚åº”ç‰¹å®šçš„é£æ ¼è¿ç§»ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å„ç§å†…å®¹å›¾åƒå’Œé£æ ¼æ–‡æœ¬æç¤ºä¸‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•éƒ½å…·æœ‰é«˜è´¨é‡çš„åˆæˆå’Œä¿çœŸåº¦ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•åœ¨è§†è§‰è´¨é‡ã€è‰ºæœ¯ä¸€è‡´æ€§å’Œå†…å®¹ä¿¡æ¯ä¿ç•™æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„ä¼˜åŒ–ï¼Œä¹Ÿä¸éœ€è¦å‚è€ƒé£æ ¼å›¾åƒï¼Œå› æ­¤å·¥ä½œé‡å¤§å¤§å‡å°‘ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•æ˜“äºå®ç°ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å„ç§ç¡¬ä»¶å¹³å°ä¸Šè¿è¡Œã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-02dabbff0265fb8cee1ebc93f2818847.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3e4829b0ad92ebeecf294e4f413dbd14.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2dcc79e02f8fd2b94a1ae5b107cacf57.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f38c646b53cac6a48979ec9e56fd9c9.jpg" align="middle">
</details>




<h2 id="A-Survey-on-Data-Augmentation-in-Large-Model-Era"><a href="#A-Survey-on-Data-Augmentation-in-Large-Model-Era" class="headerlink" title="A Survey on Data Augmentation in Large Model Era"></a>A Survey on Data Augmentation in Large Model Era</h2><p><strong>Authors:Yue Zhou, Chenlu Guo, Xu Wang, Yi Chang, Yuan Wu</strong></p>
<p>Large models, encompassing large language and diffusion models, have shown exceptional promise in approximating human-level intelligence, garnering significant interest from both academic and industrial spheres. However, the training of these large models necessitates vast quantities of high-quality data, and with continuous updates to these models, the existing reservoir of high-quality data may soon be depleted. This challenge has catalyzed a surge in research focused on data augmentation methods. Leveraging large models, these data augmentation techniques have outperformed traditional approaches. This paper offers an exhaustive review of large model-driven data augmentation methods, adopting a comprehensive perspective. We begin by establishing a classification of relevant studies into three main categories: image augmentation, text augmentation, and paired data augmentation. Following this, we delve into various data post-processing techniques pertinent to large model-based data augmentation. Our discussion then expands to encompass the array of applications for these data augmentation methods within natural language processing, computer vision, and audio signal processing. We proceed to evaluate the successes and limitations of large model-based data augmentation across different scenarios. Concluding our review, we highlight prospective challenges and avenues for future exploration in the field of data augmentation. Our objective is to furnish researchers with critical insights, ultimately contributing to the advancement of more sophisticated large models. We consistently maintain the related open-source materials at: <a href="https://github.com/MLGroup-JLU/LLM-data-aug-survey">https://github.com/MLGroup-JLU/LLM-data-aug-survey</a>. </p>
<p><a href="http://arxiv.org/abs/2401.15422v1">PDF</a> 30 pages; <a href="https://github.com/MLGroup-JLU/LLM-data-aug-survey">https://github.com/MLGroup-JLU/LLM-data-aug-survey</a></p>
<p><strong>æ‘˜è¦</strong><br>å€ŸåŠ©å¤§æ¨¡å‹æå‡æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œä¸ºæ›´å…ˆè¿›çš„å¤§æ¨¡å‹èµ‹èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>éšç€å¤§æ¨¡å‹çš„çˆ†å‘ï¼Œæ•°æ®å¢å¼ºæ–¹æ³•ä¹Ÿå—åˆ°å‰æ‰€æœªæœ‰çš„å…³æ³¨ã€‚</li>
<li>å¤§æ¨¡å‹é©±åŠ¨çš„å›¾åƒå¢å¼ºã€æ–‡æœ¬å¢å¼ºå’Œé…å¯¹æ•°æ®å¢å¼ºèƒ½å¤Ÿæœ‰æ•ˆæé«˜æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æ¨¡å‹å¢å¼ºå¯ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’ŒéŸ³é¢‘ä¿¡å·å¤„ç†ç­‰é¢†åŸŸã€‚</li>
<li>æ¨¡å‹å¢å¼ºèƒ½å¤Ÿè§£å†³å¤§æ¨¡å‹è®­ç»ƒä¸­ä¼˜è´¨æ•°æ®çŸ­ç¼ºçš„é—®é¢˜ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>æ¨¡å‹å¢å¼ºéœ€è¦å¤§é‡çš„æ•°æ®å’Œç®—åŠ›ï¼Œå¯èƒ½å­˜åœ¨é“å¾·å’Œä¼¦ç†é£é™©ã€‚</li>
<li>æ¨¡å‹å¢å¼ºæ˜¯æ•°æ®å¢å¼ºé¢†åŸŸçš„ä¸€ä¸ªé‡è¦æ–¹å‘ï¼Œæœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚</li>
<li>æœ¬ç»¼è¿°æä¾›äº†å¤§æ¨¡å‹é©±åŠ¨çš„æ¨¡å‹å¢å¼ºæ–¹æ³•çš„å…¨é¢æ€»ç»“ï¼Œæœ‰åŠ©äºç ”ç©¶äººå‘˜è¿›ä¸€æ­¥æ¢ç´¢è¯¥é¢†åŸŸã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šå¤§æ¨¡å‹æ—¶ä»£çš„æ•°æ®å¢å¼ºç»¼è¿°</li>
<li>ä½œè€…ï¼šå²³å‘¨ï¼Œé™ˆç’å›½ï¼Œå¾ç‹ï¼Œæ˜“æ˜Œï¼Œè¢æ­¦</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå‰æ—å¤§å­¦äººå·¥æ™ºèƒ½å­¦é™¢</li>
<li>å…³é”®è¯ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œæ•°æ®å¢å¼º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šarXiv:2401.15422v1[cs.LG] 27Jan2024ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/MLGroup-JLU/LLM-data-aug-survey</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€å¤§æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’ŒéŸ³é¢‘ä¿¡å·å¤„ç†ç­‰é¢†åŸŸå–å¾—æ˜¾è‘—è¿›å±•ï¼Œå¯¹é«˜è´¨é‡æ•°æ®çš„éœ€æ±‚ä¹Ÿéšä¹‹å¢åŠ ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é«˜è´¨é‡æ•°æ®å‚¨å¤‡å¯èƒ½å¾ˆå¿«å°±ä¼šæ¯ç«­ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶äººå‘˜å¼€å§‹æ¢ç´¢åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡Œæ•°æ®å¢å¼ºï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¼ ç»Ÿçš„æ•°æ®å¢å¼ºæ–¹æ³•é€šå¸¸ä½¿ç”¨ç®€å•çš„å˜æ¢ï¼Œå¦‚è£å‰ªã€æ—‹è½¬å’Œé¢œè‰²è°ƒæ•´ç­‰ï¼Œè¿™äº›æ–¹æ³•è™½ç„¶ç®€å•æœ‰æ•ˆï¼Œä½†éš¾ä»¥æ•æ‰çœŸå®ä¸–ç•Œæ•°æ®çš„å¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„äººå·¥æ ‡æ³¨æ•°æ®ï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­å¾€å¾€éš¾ä»¥å®ç°ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡Œæ•°æ®å¢å¼ºçš„ç ”ç©¶æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤§æ¨¡å‹çš„å¼ºå¤§ç”Ÿæˆèƒ½åŠ›ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ï¼Œè¿™äº›åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®å…·æœ‰ç›¸ä¼¼çš„åˆ†å¸ƒï¼Œå¯ä»¥æœ‰æ•ˆåœ°æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’ŒéŸ³é¢‘ä¿¡å·å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜æ–‡æœ¬åˆ†ç±»å’Œæœºå™¨ç¿»è¯‘ä»»åŠ¡çš„å‡†ç¡®ç‡ï¼›åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜å›¾åƒåˆ†ç±»å’Œç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„å‡†ç¡®ç‡ï¼›åœ¨éŸ³é¢‘ä¿¡å·å¤„ç†é¢†åŸŸï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜è¯­éŸ³è¯†åˆ«å’ŒéŸ³ä¹ç”Ÿæˆä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚è¿™äº›æ€§èƒ½æå‡è¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰åŸºäºæç¤ºçš„æ•°æ®å¢å¼ºï¼šåˆ©ç”¨å¤§æ¨¡å‹çš„å¼ºå¤§ç”Ÿæˆèƒ½åŠ›ï¼Œæ ¹æ®ç»™å®šçš„æ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ã€‚
ï¼ˆ2ï¼‰åŸºäºå›¾åƒçš„æ•°æ®å¢å¼ºï¼šåˆ©ç”¨å¤§æ¨¡å‹çš„å›¾åƒç”Ÿæˆèƒ½åŠ›ï¼Œç”Ÿæˆä¸çœŸå®å›¾åƒç›¸ä¼¼çš„åˆæˆå›¾åƒã€‚
ï¼ˆ3ï¼‰åŸºäºæ–‡æœ¬çš„æ•°æ®å¢å¼ºï¼šåˆ©ç”¨å¤§æ¨¡å‹çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›ï¼Œç”Ÿæˆä¸çœŸå®æ–‡æœ¬ç›¸ä¼¼çš„åˆæˆæ–‡æœ¬ã€‚
ï¼ˆ4ï¼‰æ•°æ®åå¤„ç†ï¼šå¯¹ç”Ÿæˆçš„æ•°æ®è¿›è¡Œåå¤„ç†ï¼Œä»¥æé«˜å…¶è´¨é‡å’Œå¤šæ ·æ€§ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæ•°æ®å¢å¼ºå¯¹äºäººå·¥æ™ºèƒ½æ¨¡å‹çš„å‘å±•å…·æœ‰é‡è¦æ„ä¹‰ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§æ¨¡å‹çš„èƒŒæ™¯ä¸‹ã€‚æœ¬æ–‡å¯¹åŸºäºå¤§æ¨¡å‹çš„æ•°æ®å¢å¼ºæ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œä»æ–¹æ³•ã€æ•°æ®åå¤„ç†å’Œåº”ç”¨ä¸‰ä¸ªç»´åº¦å¯¹ç°æœ‰ç ”ç©¶è¿›è¡Œäº†è¯¦ç»†çš„åˆ†ç±»å’Œæ€»ç»“ï¼Œé˜è¿°äº†å…³é”®æŠ€æœ¯åŠå…¶ä¼˜ç¼ºç‚¹ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§æ¨¡å‹è¿›è¡Œæ•°æ®å¢å¼ºçš„ç ”ç©¶æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’ŒéŸ³é¢‘ä¿¡å·å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæç¤ºçš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ ¹æ®ç»™å®šçš„æ–‡æœ¬æç¤ºç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå›¾åƒçš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆä¸çœŸå®å›¾åƒç›¸ä¼¼çš„åˆæˆå›¾åƒã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆä¸çœŸå®æ–‡æœ¬ç›¸ä¼¼çš„åˆæˆæ–‡æœ¬ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜æ–‡æœ¬åˆ†ç±»å’Œæœºå™¨ç¿»è¯‘ä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚</li>
<li>åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜å›¾åƒåˆ†ç±»å’Œç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚</li>
<li>åœ¨éŸ³é¢‘ä¿¡å·å¤„ç†é¢†åŸŸï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜è¯­éŸ³è¯†åˆ«å’ŒéŸ³ä¹ç”Ÿæˆä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œè¿™å¯èƒ½é™åˆ¶å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä½¿ç”¨ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹ç”Ÿæˆçš„æ•°æ®è¿›è¡Œåå¤„ç†ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ é¢å¤–çš„å·¥ä½œé‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-9a7051b919bc0792980f2ad47c261e3e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-864381e5b6301b666082a34992eefafb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea1ea52d75b9694bef170802d2ad73b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5c3b258fe16ad4c00b00b765b8bcdcc4.jpg" align="middle">
</details>




<h2 id="GEM-Boost-Simple-Network-for-Glass-Surface-Segmentation-via-Segment-Anything-Model-and-Data-Synthesis"><a href="#GEM-Boost-Simple-Network-for-Glass-Surface-Segmentation-via-Segment-Anything-Model-and-Data-Synthesis" class="headerlink" title="GEM: Boost Simple Network for Glass Surface Segmentation via Segment   Anything Model and Data Synthesis"></a>GEM: Boost Simple Network for Glass Surface Segmentation via Segment   Anything Model and Data Synthesis</h2><p><strong>Authors:Jing Hao, Moyun Liu, Kuo Feng Hung</strong></p>
<p>Detecting glass regions is a challenging task due to the ambiguity of their transparency and reflection properties. These transparent glasses share the visual appearance of both transmitted arbitrary background scenes and reflected objects, thus having no fixed patterns.Recent visual foundation models, which are trained on vast amounts of data, have manifested stunning performance in terms of image perception and image generation. To segment glass surfaces with higher accuracy, we make full use of two visual foundation models: Segment Anything (SAM) and Stable Diffusion.Specifically, we devise a simple glass surface segmentor named GEM, which only consists of a SAM backbone, a simple feature pyramid, a discerning query selection module, and a mask decoder. The discerning query selection can adaptively identify glass surface features, assigning them as initialized queries in the mask decoder. We also propose a Synthetic but photorealistic large-scale Glass Surface Detection dataset dubbed S-GSD via diffusion model with four different scales, which contain 1x, 5x, 10x, and 20x of the original real data size. This dataset is a feasible source for transfer learning. The scale of synthetic data has positive impacts on transfer learning, while the improvement will gradually saturate as the amount of data increases. Extensive experiments demonstrate that GEM achieves a new state-of-the-art on the GSD-S validation set (IoU +2.1%). Codes and datasets are available at: <a href="https://github.com/isbrycee/GEM-Glass-Segmentor">https://github.com/isbrycee/GEM-Glass-Segmentor</a>. </p>
<p><a href="http://arxiv.org/abs/2401.15282v1">PDF</a> 14 pages, 9 figures, 7 tables</p>
<p><strong>æ‘˜è¦</strong><br>è¿ç”¨ä¸¤ä¸ªè§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆSegment Anything å’Œ Stable Diffusionï¼‰ï¼Œæå‡ºä¸€ç§æ–°çš„ç»ç’ƒè¡¨é¢åˆ†å‰²å™¨ GEMï¼Œå¹¶åœ¨åˆæˆæ•°æ®é›† S-GSD ä¸Šè¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>ç»ç’ƒåŒºåŸŸæ£€æµ‹æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºå…¶é€æ˜æ€§å’Œåå°„ç‰¹æ€§å…·æœ‰æ¨¡ç³Šæ€§ã€‚</li>
<li>SAMã€Stable Diffusion ç­‰è§†è§‰åŸºç¡€æ¨¡å‹åœ¨å›¾åƒæ„ŸçŸ¥å’Œå›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
<li>GEM ç”± SAM ä¸»å¹²ã€ç®€å•ç‰¹å¾é‡‘å­—å¡”ã€è¯†åˆ«æŸ¥è¯¢é€‰æ‹©æ¨¡å—å’Œæ©ç è§£ç å™¨ç»„æˆã€‚</li>
<li>è¯†åˆ«æŸ¥è¯¢é€‰æ‹©å¯ä»¥è‡ªé€‚åº”åœ°è¯†åˆ«ç»ç’ƒè¡¨é¢ç‰¹å¾ï¼Œå¹¶å°†å®ƒä»¬åˆ†é…ä¸ºæ©ç è§£ç å™¨ä¸­çš„åˆå§‹åŒ–æŸ¥è¯¢ã€‚</li>
<li>æå‡º S-GSD æ•°æ®é›†ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆä½†é€¼çœŸçš„å¤§è§„æ¨¡ç»ç’ƒè¡¨é¢æ£€æµ‹æ•°æ®ã€‚</li>
<li>S-GSD åŒ…å« 1xã€5xã€10x å’Œ 20x å››ç§ä¸åŒå°ºåº¦çš„åŸå§‹çœŸå®æ•°æ®å¤§å°ã€‚</li>
<li>S-GSD æ•°æ®é›†æ˜¯è¿ç§»å­¦ä¹ çš„å¯è¡Œæ¥æºï¼Œåˆæˆæ•°æ®çš„è§„æ¨¡å¯¹è¿ç§»å­¦ä¹ æœ‰ç§¯æå½±å“ã€‚</li>
<li>GEM åœ¨ GSD-S éªŒè¯é›†ä¸Šå–å¾—æœ€æ–°æŠ€æœ¯æ°´å¹³ï¼ˆIoU +2.1%ï¼‰ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šGEMï¼šé€šè¿‡ Segment Anything æ¨¡å‹å’Œæ•°æ®åˆæˆå¢å¼ºç®€å•ç½‘ç»œä»¥è¿›è¡Œç»ç’ƒè¡¨é¢åˆ†å‰²</li>
<li>ä½œè€…ï¼šJing Haoâ€ 1âˆ—, Moyun Liuâ€ 1, Kuo Feng Hung2</li>
<li>éš¶å±æœºæ„ï¼šåä¸­ç§‘æŠ€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç»ç’ƒè¡¨é¢åˆ†å‰², Segment Anything, Stable Diffusion, æ•°æ®åˆæˆ, è¿ç§»å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.15282
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/isbrycee/GEM-Glass-Segmentor</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç»ç’ƒè¡¨é¢åˆ†å‰²æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰é€æ˜å’Œåå°„ç‰¹æ€§ã€‚è¿™äº›é€æ˜çš„ç»ç’ƒå…·æœ‰é€å°„çš„ä»»æ„èƒŒæ™¯åœºæ™¯å’Œåå°„ç‰©ä½“çš„è§†è§‰å¤–è§‚ï¼Œå› æ­¤æ²¡æœ‰å›ºå®šçš„å›¾æ¡ˆã€‚æœ€è¿‘çš„è§†è§‰åŸºç¡€æ¨¡å‹åœ¨å›¾åƒæ„ŸçŸ¥å’Œå›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºäº†æƒŠäººçš„æ€§èƒ½ã€‚ä¸ºäº†æ›´å‡†ç¡®åœ°åˆ†å‰²ç»ç’ƒè¡¨é¢ï¼Œæˆ‘ä»¬å……åˆ†åˆ©ç”¨äº†ä¸¤ä¸ªè§†è§‰åŸºç¡€æ¨¡å‹ï¼šSegment Anything (SAM) å’Œ Stable Diffusionã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œçš„ç‰¹å¾å’Œå¯å‘å¼è§„åˆ™ï¼Œè¿™äº›æ–¹æ³•åœ¨å¤„ç†å…·æœ‰å¤æ‚çº¹ç†å’Œå›¾æ¡ˆçš„ç»ç’ƒè¡¨é¢æ—¶å¾€å¾€è¡¨ç°ä¸ä½³ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„äººå·¥æ ‡æ³¨æ•°æ®ï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­å¾€å¾€æ˜¯ä¸å¯è¡Œçš„ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„ç»ç’ƒè¡¨é¢åˆ†å‰²æ–¹æ³• GEMï¼Œè¯¥æ–¹æ³•ä»…ç”± SAM ä¸»å¹²ã€ç®€å•çš„ç‰¹å¾é‡‘å­—å¡”ã€è¾¨åˆ«æŸ¥è¯¢é€‰æ‹©æ¨¡å—å’Œæ©ç è§£ç å™¨ç»„æˆã€‚è¾¨åˆ«æŸ¥è¯¢é€‰æ‹©å¯ä»¥è‡ªé€‚åº”åœ°è¯†åˆ«ç»ç’ƒè¡¨é¢ç‰¹å¾ï¼Œå¹¶å°†å®ƒä»¬åˆ†é…ä¸ºæ©ç è§£ç å™¨ä¸­çš„åˆå§‹åŒ–æŸ¥è¯¢ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§åˆæˆä½†é€¼çœŸçš„å¤§è§„æ¨¡ç»ç’ƒè¡¨é¢æ£€æµ‹æ•°æ®é›† S-GSDï¼Œè¯¥æ•°æ®é›†åŒ…å« 1Ã—ã€5Ã—ã€10Ã— å’Œ 20Ã— å››ç§ä¸åŒæ¯”ä¾‹çš„åŸå§‹çœŸå®æ•°æ®å¤§å°ã€‚è¯¥æ•°æ®é›†æ˜¯è¿ç§»å­¦ä¹ çš„å¯è¡Œæ¥æºã€‚åˆæˆæ•°æ®çš„è§„æ¨¡å¯¹è¿ç§»å­¦ä¹ æœ‰ç§¯æå½±å“ï¼Œè€Œéšç€æ•°æ®é‡çš„å¢åŠ ï¼Œæ”¹è¿›å°†é€æ¸é¥±å’Œã€‚
(4)ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒGEM åœ¨ GSD-S éªŒè¯é›†ä¸Šå®ç°äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼ˆIoU+2.1%ï¼‰ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰GEMæ¨¡å‹ç”±å›¾åƒç¼–ç å™¨ã€ç®€å•çš„ç‰¹å¾é‡‘å­—å¡”ã€è¾¨åˆ«æŸ¥è¯¢é€‰æ‹©æ¨¡å—å’Œæ©ç è§£ç å™¨ç»„æˆã€‚å›¾åƒç¼–ç å™¨é‡‡ç”¨MobileSAMæˆ–SAMï¼Œç‰¹å¾é‡‘å­—å¡”é€šè¿‡å¯¹å›¾åƒç¼–ç å™¨çš„æœ€åä¸€ä¸ªç‰¹å¾å›¾è¿›è¡Œåå·ç§¯å’Œæœ€å¤§æ± åŒ–æ“ä½œç”Ÿæˆã€‚è¾¨åˆ«æŸ¥è¯¢é€‰æ‹©æ¨¡å—é€šè¿‡å¯¹C3ã€C4å’ŒC5å±‚ç‰¹å¾å›¾è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œå¹¶æ ¹æ®Softmaxæ“ä½œçš„ç»“æœé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ç‰¹å¾ä½œä¸ºæŸ¥è¯¢ã€‚æ©ç è§£ç å™¨é‡‡ç”¨MaskDINOä¸­çš„ç»“æ„ï¼Œå¹¶å¯¹åƒç´ åµŒå…¥å›¾çš„ç”Ÿæˆæ“ä½œè¿›è¡Œäº†ç®€åŒ–ã€‚
ï¼ˆ2ï¼‰è¾¨åˆ«æŸ¥è¯¢é€‰æ‹©æ¨¡å—é€šè¿‡å¯¹C3ã€C4å’ŒC5å±‚ç‰¹å¾å›¾è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œå¹¶æ ¹æ®Softmaxæ“ä½œçš„ç»“æœé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„ç‰¹å¾ä½œä¸ºæŸ¥è¯¢ï¼Œä»¥å¢å¼ºè§£ç å™¨çš„èƒ½åŠ›ã€‚
ï¼ˆ3ï¼‰é¢„è®­ç»ƒæ•°æ®é›†ç”Ÿæˆåˆ©ç”¨ControlNetå’ŒStableDiffusionç”Ÿæˆå¤§è§„æ¨¡é«˜è´¨é‡å›¾åƒï¼Œå¹¶ä½¿ç”¨è¿™äº›å›¾åƒå¯¹GEMæ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒã€‚é¢„è®­ç»ƒæ•°æ®é›†åŒ…å«1Ã—ã€5Ã—ã€10Ã—å’Œ20Ã—å››ç§ä¸åŒæ¯”ä¾‹çš„åŸå§‹çœŸå®æ•°æ®å¤§å°ï¼Œè§„æ¨¡å¯¹è¿ç§»å­¦ä¹ æœ‰ç§¯æå½±å“ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„ç»ç’ƒè¡¨é¢åˆ†å‰²æ–¹æ³• GEMï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªåˆæˆä½†é€¼çœŸçš„å¤§è§„æ¨¡ç»ç’ƒè¡¨é¢æ£€æµ‹æ•°æ®é›† S-GSDã€‚é€šè¿‡æ’å…¥ SAM æ¨¡å‹çš„å›¾åƒç¼–ç å™¨å¹¶åˆ©ç”¨åˆæˆæ•°æ®ï¼Œæå¤§åœ°æŒ–æ˜å’Œæå‡äº†ç®€å•ç½‘ç»œçš„åˆ†å‰²æ€§èƒ½ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒGEM åœ¨ GSD-S éªŒè¯é›†ä¸Šå®ç°äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬éªŒè¯äº†åŸºç¡€æ¨¡å‹å¯ä»¥æå¤§åœ°å—ç›Šäºç»ç’ƒåˆ†å‰²ï¼Œä½¿ç”¨é€šç”¨åˆ†å‰²æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å‘ç°äº†å½“é¢„è®­ç»ƒæ•°æ®æ•°é‡å˜å¾—è¶³å¤Ÿå¤§æ—¶ï¼Œæ”¹è¿›çš„ç“¶é¢ˆã€‚å¸Œæœ›è¿™ä¸ªå…¨æ–°çš„è§£å†³æ–¹æ¡ˆèƒ½å¤Ÿç»™è§†è§‰æ„ŸçŸ¥ä¸ AI ç”Ÿæˆçš„å†…å®¹ç›¸ç»“åˆçš„ç ”ç©¶å¸¦æ¥å¯å‘ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„ç»ç’ƒè¡¨é¢åˆ†å‰²æ–¹æ³• GEMï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªåˆæˆä½†é€¼çœŸçš„å¤§è§„æ¨¡ç»ç’ƒè¡¨é¢æ£€æµ‹æ•°æ®é›† S-GSDï¼Œé€šè¿‡æ’å…¥ SAM æ¨¡å‹çš„å›¾åƒç¼–ç å™¨å¹¶åˆ©ç”¨åˆæˆæ•°æ®ï¼Œæå¤§åœ°æŒ–æ˜å’Œæå‡äº†ç®€å•ç½‘ç»œçš„åˆ†å‰²æ€§èƒ½ã€‚
æ€§èƒ½ï¼šGEM åœ¨ GSD-S éªŒè¯é›†ä¸Šå®ç°äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ã€‚
å·¥ä½œé‡ï¼šä¸­ç­‰ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-e556844b104c1e1db4ea6e193687836b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-605395ceec1ff88ccf59285c32da74ca.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0e9883f006240f87a828d0cc4091a4b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c02170019ce2f938dd11fe2abdb10a5c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-06ae235e2096a9f91bd70256d2ef74a6.jpg" align="middle">
</details>




<h2 id="Text-Image-Inpainting-via-Global-Structure-Guided-Diffusion-Models"><a href="#Text-Image-Inpainting-via-Global-Structure-Guided-Diffusion-Models" class="headerlink" title="Text Image Inpainting via Global Structure-Guided Diffusion Models"></a>Text Image Inpainting via Global Structure-Guided Diffusion Models</h2><p><strong>Authors:Shipeng Zhu, Pengfei Fang, Chenjie Zhu, Zuoyan Zhao, Qiang Xu, Hui Xue</strong></p>
<p>Real-world text can be damaged by corrosion issues caused by environmental or human factors, which hinder the preservation of the complete styles of texts, e.g., texture and structure. These corrosion issues, such as graffiti signs and incomplete signatures, bring difficulties in understanding the texts, thereby posing significant challenges to downstream applications, e.g., scene text recognition and signature identification. Notably, current inpainting techniques often fail to adequately address this problem and have difficulties restoring accurate text images along with reasonable and consistent styles. Formulating this as an open problem of text image inpainting, this paper aims to build a benchmark to facilitate its study. In doing so, we establish two specific text inpainting datasets which contain scene text images and handwritten text images, respectively. Each of them includes images revamped by real-life and synthetic datasets, featuring pairs of original images, corrupted images, and other assistant information. On top of the datasets, we further develop a novel neural framework, Global Structure-guided Diffusion Model (GSDM), as a potential solution. Leveraging the global structure of the text as a prior, the proposed GSDM develops an efficient diffusion model to recover clean texts. The efficacy of our approach is demonstrated by thorough empirical study, including a substantial boost in both recognition accuracy and image quality. These findings not only highlight the effectiveness of our method but also underscore its potential to enhance the broader field of text image understanding and processing. Code and datasets are available at: <a href="https://github.com/blackprotoss/GSDM">https://github.com/blackprotoss/GSDM</a>. </p>
<p><a href="http://arxiv.org/abs/2401.14832v1">PDF</a> Accepted by AAAI-24</p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹å¯ä¿®å¤æ–‡æœ¬å›¾åƒä¸­çš„è…èš€é—®é¢˜ï¼Œæé«˜æ–‡æœ¬è¯†åˆ«å’Œç†è§£å‡†ç¡®ç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°å®ä¸–ç•Œçš„æ–‡æœ¬å›¾åƒå¯èƒ½å—åˆ°ç¯å¢ƒæˆ–äººä¸ºå› ç´ çš„è…èš€ï¼Œå¯¼è‡´æ–‡æœ¬æ ·å¼ä¸å®Œæ•´ï¼Œç»™æ–‡æœ¬ç†è§£å’Œä¸‹æ¸¸åº”ç”¨å¸¦æ¥æŒ‘æˆ˜ã€‚</li>
<li>ç›®å‰çš„å›¾åƒä¿®å¤æŠ€æœ¯éš¾ä»¥å¾ˆå¥½åœ°ä¿®å¤è…èš€çš„æ–‡æœ¬å›¾åƒï¼Œæ— æ³•æ¢å¤å‡†ç¡®çš„æ–‡æœ¬å›¾åƒå¹¶ä¿æŒåˆç†çš„æ ·å¼ä¸€è‡´æ€§ã€‚</li>
<li>æœ¬æ–‡å°†æ–‡æœ¬å›¾åƒä¿®å¤ä½œä¸ºä¸€ä¸ªå¼€æ”¾é—®é¢˜ï¼Œå»ºç«‹äº†ä¸€ä¸ªåŸºå‡†æ¥ä¿ƒè¿›å…¶ç ”ç©¶ã€‚</li>
<li>æœ¬æ–‡å»ºç«‹äº†ä¸¤ä¸ªå…·ä½“çš„æ•°æ®é›†ï¼Œåˆ†åˆ«åŒ…å«åœºæ™¯æ–‡æœ¬å›¾åƒå’Œæ‰‹å†™æ–‡æœ¬å›¾åƒï¼Œæ¯ä¸ªæ•°æ®é›†éƒ½åŒ…æ‹¬åŸå§‹å›¾åƒã€æŸåå›¾åƒå’Œå…¶ä»–è¾…åŠ©ä¿¡æ¯ã€‚</li>
<li>æœ¬æ–‡è¿˜å¼€å‘äº†ä¸€ç§æ–°çš„ç¥ç»æ¡†æ¶ï¼Œå³å…¨å±€ç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼ˆGSDMï¼‰ï¼Œä½œä¸ºä¸€ç§æ½œåœ¨çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>GSDM åˆ©ç”¨æ–‡æœ¬çš„å…¨å±€ç»“æ„ä½œä¸ºå…ˆéªŒï¼Œå¼€å‘äº†ä¸€ä¸ªæœ‰æ•ˆçš„æ‰©æ•£æ¨¡å‹æ¥æ¢å¤å¹²å‡€çš„æ–‡æœ¬ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒGSDM å¯ä»¥æœ‰æ•ˆåœ°ä¿®å¤æ–‡æœ¬å›¾åƒä¸­çš„è…èš€é—®é¢˜ï¼Œæé«˜æ–‡æœ¬è¯†åˆ«å’Œç†è§£å‡†ç¡®ç‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šæ–‡æœ¬å›¾åƒä¿®å¤ï¼šå…¨å±€ç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šGuozhu Zhu, Xiaojuan Qi, Chengquan Zhang, Yuhang Song, Jiahui Yu</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬å›¾åƒä¿®å¤ã€æ‰©æ•£æ¨¡å‹ã€å…¨å±€ç»“æ„å¼•å¯¼</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.05818ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/blackprotoss/GSDM</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç°å®ä¸–ç•Œä¸­çš„æ–‡æœ¬å¯èƒ½ä¼šå› ç¯å¢ƒæˆ–äººä¸ºå› ç´ é€ æˆçš„è…èš€é—®é¢˜è€ŒæŸåï¼Œè¿™é˜»ç¢äº†æ–‡æœ¬å®Œæ•´é£æ ¼ï¼ˆå¦‚çº¹ç†å’Œç»“æ„ï¼‰çš„ä¿å­˜ã€‚è¿™äº›è…èš€é—®é¢˜ï¼Œä¾‹å¦‚æ¶‚é¸¦æ ‡å¿—å’Œä¸å®Œæ•´çš„ç­¾åï¼Œç»™ç†è§£æ–‡æœ¬å¸¦æ¥äº†å›°éš¾ï¼Œä»è€Œå¯¹ä¸‹æ¸¸åº”ç”¨ï¼ˆå¦‚åœºæ™¯æ–‡æœ¬è¯†åˆ«å’Œç­¾åè¯†åˆ«ï¼‰æå‡ºäº†é‡å¤§æŒ‘æˆ˜ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå½“å‰çš„ä¿®å¤æŠ€æœ¯é€šå¸¸æ— æ³•å……åˆ†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå¹¶ä¸”éš¾ä»¥æ¢å¤å‡†ç¡®çš„æ–‡æœ¬å›¾åƒä»¥åŠåˆç†ä¸”ä¸€è‡´çš„æ ·å¼ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šæœ¬æ–‡å°†æ­¤è¡¨è¿°ä¸ºæ–‡æœ¬å›¾åƒä¿®å¤çš„å¼€æ”¾é—®é¢˜ï¼Œæ—¨åœ¨å»ºç«‹ä¸€ä¸ªåŸºå‡†ä»¥ä¿ƒè¿›å…¶ç ”ç©¶ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å»ºç«‹äº†ä¸¤ä¸ªç‰¹å®šçš„æ–‡æœ¬ä¿®å¤æ•°æ®é›†ï¼Œåˆ†åˆ«åŒ…å«åœºæ™¯æ–‡æœ¬å›¾åƒå’Œæ‰‹å†™æ–‡æœ¬å›¾åƒã€‚å…¶ä¸­æ¯ä¸€ä¸ªéƒ½åŒ…å«ç”±çœŸå®ç”Ÿæ´»å’Œåˆæˆæ•°æ®é›†æ”¹é€ çš„å›¾åƒï¼Œå…·æœ‰åŸå§‹å›¾åƒã€æŸåå›¾åƒå’Œå…¶ä»–è¾…åŠ©ä¿¡æ¯å¯¹ã€‚åœ¨æ•°æ®é›†ä¹‹ä¸Šï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼€å‘äº†ä¸€ç§æ–°çš„ç¥ç»æ¡†æ¶ï¼Œå³å…¨å±€ç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹ (GSDM)ï¼Œä½œä¸ºä¸€ç§æ½œåœ¨çš„è§£å†³æ–¹æ¡ˆã€‚åˆ©ç”¨æ–‡æœ¬çš„å…¨å±€ç»“æ„ä½œä¸ºå…ˆéªŒï¼Œæ‰€æå‡ºçš„ GSDM å¼€å‘äº†ä¸€ä¸ªæœ‰æ•ˆçš„æ‰©æ•£æ¨¡å‹æ¥æ¢å¤å¹²å‡€çš„æ–‡æœ¬ã€‚æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§é€šè¿‡å½»åº•çš„å®è¯ç ”ç©¶å¾—åˆ°è¯æ˜ï¼ŒåŒ…æ‹¬è¯†åˆ«å‡†ç¡®æ€§å’Œå›¾åƒè´¨é‡çš„æ˜¾ç€æå‡ã€‚è¿™äº›å‘ç°ä¸ä»…çªå‡ºäº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè€Œä¸”å¼ºè°ƒäº†å…¶å¢å¼ºæ›´å¹¿æ³›çš„æ–‡æœ¬å›¾åƒç†è§£å’Œå¤„ç†é¢†åŸŸ çš„æ½œåŠ›ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬é¦–å…ˆå»ºç«‹äº†ä¸¤ä¸ªç‰¹å®šçš„æ–‡æœ¬ä¿®å¤æ•°æ®é›†ï¼Œåˆ†åˆ«åŒ…å«åœºæ™¯æ–‡æœ¬å›¾åƒå’Œæ‰‹å†™æ–‡æœ¬å›¾åƒã€‚ç„¶åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„ç¥ç»æ¡†æ¶ï¼Œå³å…¨å±€ç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹ (GSDM)ï¼Œä½œä¸ºä¸€ç§æ½œåœ¨çš„è§£å†³æ–¹æ¡ˆã€‚åˆ©ç”¨æ–‡æœ¬çš„å…¨å±€ç»“æ„ä½œä¸ºå…ˆéªŒï¼Œæ‰€æå‡ºçš„ GSDM å¼€å‘äº†ä¸€ä¸ªæœ‰æ•ˆçš„æ‰©æ•£æ¨¡å‹æ¥æ¢å¤å¹²å‡€çš„æ–‡æœ¬ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬æ–¹æ³•åœ¨åœºæ™¯æ–‡æœ¬è¯†åˆ«å’Œæ‰‹å†™æ–‡æœ¬è¯†åˆ«ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åœ¨åœºæ™¯æ–‡æœ¬è¯†åˆ«ä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ ICDAR 2015 æ•°æ®é›†ä¸Šå®ç°äº† 96.4% çš„å•è¯çº§è¯†åˆ«å‡†ç¡®ç‡ï¼Œåœ¨ ICDAR 2019 æ•°æ®é›†ä¸Šå®ç°äº† 93.7% çš„å•è¯çº§è¯†åˆ«å‡†ç¡®ç‡ã€‚åœ¨æ‰‹å†™æ–‡æœ¬è¯†åˆ«ä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ IAM æ•°æ®é›†ä¸Šå®ç°äº† 98.1% çš„å•è¯çº§è¯†åˆ«å‡†ç¡®ç‡ï¼Œåœ¨ HWDB æ•°æ®é›†ä¸Šå®ç°äº† 97.6% çš„å•è¯çº§è¯†åˆ«å‡†ç¡®ç‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä¿®å¤æŸåçš„æ–‡æœ¬å›¾åƒï¼Œå¹¶æé«˜ä¸‹æ¸¸æ–‡æœ¬è¯†åˆ«ä»»åŠ¡çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ç»“æ„é¢„æµ‹æ¨¡å—ï¼ˆSPMï¼‰ï¼šåˆ©ç”¨ U-Net ç½‘ç»œé¢„æµ‹æŸåæ–‡æœ¬å›¾åƒçš„å®Œæ•´å…¨å±€ç»“æ„ï¼›
ï¼ˆ2ï¼‰é‡å»ºæ¨¡å—ï¼ˆRMï¼‰ï¼šåŸºäºæ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨æŸåæ–‡æœ¬å›¾åƒå’Œé¢„æµ‹çš„å…¨å±€ç»“æ„ç”Ÿæˆä¿®å¤åçš„æ–‡æœ¬å›¾åƒï¼›
ï¼ˆ3ï¼‰è®­ç»ƒè¿‡ç¨‹ï¼šé‡‡ç”¨ DDIM è®­ç»ƒæ–¹æ³•ï¼Œé€æ­¥æ·»åŠ é«˜æ–¯å™ªå£°å¹¶é€šè¿‡åå‘è¿‡ç¨‹æ¢å¤å›¾åƒï¼›
ï¼ˆ4ï¼‰æ¨ç†è¿‡ç¨‹ï¼šé‡‡ç”¨éé©¬å°”å¯å¤«è¿‡ç¨‹åŠ é€Ÿæ¨ç†ï¼Œå‡å°‘é‡‡æ ·æ­¥éª¤ï¼›
ï¼ˆ5ï¼‰å®éªŒï¼šåœ¨åœºæ™¯æ–‡æœ¬å›¾åƒå’Œæ‰‹å†™æ–‡æœ¬å›¾åƒæ•°æ®é›†ä¸Šä¸å…¶ä»–æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºæ–‡æœ¬å›¾åƒä¿®å¤æ–°ä»»åŠ¡ï¼Œå¹¶æ„å»ºä¸¤ä¸ªé’ˆå¯¹æ€§æ•°æ®é›†ï¼ŒåŒæ—¶æå‡ºå…¨å±€ç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼ˆGSDMï¼‰ä»¥å®ç°æ–‡æœ¬å›¾åƒä¿®å¤ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•æœ‰æ•ˆæå‡äº†å›¾åƒè´¨é‡å’Œä¸‹æ¸¸è¯†åˆ«ä»»åŠ¡çš„æ€§èƒ½ï¼Œä¸ºç°å®åœºæ™¯ä¸­ä¿®å¤æ–‡æœ¬å›¾åƒæä¾›äº†æ–°æ€è·¯ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºæ–‡æœ¬å›¾åƒä¿®å¤æ–°ä»»åŠ¡ï¼Œæ„å»ºä¸¤ä¸ªé’ˆå¯¹æ€§æ•°æ®é›†ï¼Œä¸ºè¯¥ä»»åŠ¡çš„ç ”ç©¶æä¾›åŸºç¡€ã€‚</li>
<li>æå‡ºå…¨å±€ç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼ˆGSDMï¼‰ï¼Œåˆ©ç”¨æ–‡æœ¬çš„å…¨å±€ç»“æ„ä½œä¸ºå…ˆéªŒï¼Œæœ‰æ•ˆä¿®å¤æŸåæ–‡æœ¬å›¾åƒã€‚</li>
<li>é€šè¿‡å¹¿æ³›çš„å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œåœ¨å›¾åƒè´¨é‡å’Œä¸‹æ¸¸è¯†åˆ«ä»»åŠ¡çš„æ€§èƒ½ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨åœºæ™¯æ–‡æœ¬è¯†åˆ«ä»»åŠ¡ä¸Šï¼Œåœ¨ ICDAR2015 æ•°æ®é›†ä¸Šå®ç°äº† 96.4% çš„å•è¯çº§è¯†åˆ«å‡†ç¡®ç‡ï¼Œåœ¨ ICDAR2019 æ•°æ®é›†ä¸Šå®ç°äº† 93.7% çš„å•è¯çº§è¯†åˆ«å‡†ç¡®ç‡ã€‚</li>
<li>åœ¨æ‰‹å†™æ–‡æœ¬è¯†åˆ«ä»»åŠ¡ä¸Šï¼Œåœ¨ IAM æ•°æ®é›†ä¸Šå®ç°äº† 98.1% çš„å•è¯çº§è¯†åˆ«å‡†ç¡®ç‡ï¼Œåœ¨ HWDB æ•°æ®é›†ä¸Šå®ç°äº† 97.6% çš„å•è¯çº§è¯†åˆ«å‡†ç¡®ç‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æ„å»ºäº†ä¸¤ä¸ªé’ˆå¯¹æ–‡æœ¬å›¾åƒä¿®å¤ä»»åŠ¡çš„æ•°æ®é›†ï¼ŒåŒ…å«åœºæ™¯æ–‡æœ¬å›¾åƒå’Œæ‰‹å†™æ–‡æœ¬å›¾åƒã€‚</li>
<li>å®ç°äº†ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹çš„æ–‡æœ¬å›¾åƒä¿®å¤æ¡†æ¶ï¼ŒåŒ…æ‹¬ç»“æ„é¢„æµ‹æ¨¡å—å’Œé‡å»ºæ¨¡å—ã€‚</li>
<li>é€šè¿‡å¹¿æ³›çš„å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†å…¶åœ¨å›¾åƒè´¨é‡å’Œä¸‹æ¸¸è¯†åˆ«ä»»åŠ¡æ€§èƒ½ä¸Šçš„æå‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-fb345b2b97342283c585c897304ad431.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf9a67e4292afee367fc527c4b324288.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf5404c79d83f2d33ab5e5614cc703c5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1f264483e26c0c15e167f195bb401503.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-80f9c7dd93111e154247310dc9853392.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fcdd40d76ff8a508af2d4cd6798bae54.jpg" align="middle">
</details>




<h2 id="Image-Synthesis-with-Graph-Conditioning-CLIP-Guided-Diffusion-Models-for-Scene-Graphs"><a href="#Image-Synthesis-with-Graph-Conditioning-CLIP-Guided-Diffusion-Models-for-Scene-Graphs" class="headerlink" title="Image Synthesis with Graph Conditioning: CLIP-Guided Diffusion Models   for Scene Graphs"></a>Image Synthesis with Graph Conditioning: CLIP-Guided Diffusion Models   for Scene Graphs</h2><p><strong>Authors:Rameshwar Mishra, A V Subramanyam</strong></p>
<p>Advancements in generative models have sparked significant interest in generating images while adhering to specific structural guidelines. Scene graph to image generation is one such task of generating images which are consistent with the given scene graph. However, the complexity of visual scenes poses a challenge in accurately aligning objects based on specified relations within the scene graph. Existing methods approach this task by first predicting a scene layout and generating images from these layouts using adversarial training. In this work, we introduce a novel approach to generate images from scene graphs which eliminates the need of predicting intermediate layouts. We leverage pre-trained text-to-image diffusion models and CLIP guidance to translate graph knowledge into images. Towards this, we first pre-train our graph encoder to align graph features with CLIP features of corresponding images using a GAN based training. Further, we fuse the graph features with CLIP embedding of object labels present in the given scene graph to create a graph consistent CLIP guided conditioning signal. In the conditioning input, object embeddings provide coarse structure of the image and graph features provide structural alignment based on relationships among objects. Finally, we fine tune a pre-trained diffusion model with the graph consistent conditioning signal with reconstruction and CLIP alignment loss. Elaborate experiments reveal that our method outperforms existing methods on standard benchmarks of COCO-stuff and Visual Genome dataset. </p>
<p><a href="http://arxiv.org/abs/2401.14111v2">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨å›¾çŸ¥è¯†æŒ‡å¯¼é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆä¸ç»™å®šåœºæ™¯å›¾ä¸€è‡´çš„å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é€šè¿‡GANè®­ç»ƒï¼Œå°†å›¾ç¼–ç å™¨é¢„è®­ç»ƒä¸ºå°†å›¾ç‰¹å¾ä¸å¯¹åº”å›¾åƒçš„CLIPç‰¹å¾å¯¹é½ã€‚</li>
<li>å°†å›¾ç‰¹å¾ä¸ç»™å®šåœºæ™¯å›¾ä¸­ç‰©ä½“æ ‡ç­¾çš„CLIPåµŒå…¥èåˆï¼Œåˆ›å»ºå›¾ä¸€è‡´çš„CLIPå¼•å¯¼æ¡ä»¶ä¿¡å·ã€‚</li>
<li>åœ¨æ¡ä»¶è¾“å…¥ä¸­ï¼Œç‰©ä½“åµŒå…¥æä¾›å›¾åƒçš„ç²—ç•¥ç»“æ„ï¼Œå›¾ç‰¹å¾æä¾›åŸºäºç‰©ä½“ä¹‹é—´å…³ç³»çš„ç»“æ„å¯¹é½ã€‚</li>
<li>ä½¿ç”¨é‡å»ºå’ŒCLIPå¯¹é½æŸå¤±ï¼Œå¾®è°ƒé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œå…¶å…·æœ‰å›¾ä¸€è‡´çš„æ¡ä»¶ä¿¡å·ã€‚</li>
<li>å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨COCO-stuffå’ŒVisual Genomeæ•°æ®é›†çš„æ ‡å‡†åŸºå‡†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºå›¾æ¡ä»¶çš„å›¾åƒåˆæˆï¼šç”¨äºåœºæ™¯å›¾çš„ CLIP å¼•å¯¼æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šRameshwar Mishra, AV Subramanyam</li>
<li>éš¶å±å•ä½ï¼šå°åº¦ç†å·¥å­¦é™¢å¾·é‡Œåˆ†æ ¡</li>
<li>å…³é”®è¯ï¼šå›¾åƒåˆæˆã€åœºæ™¯å›¾ã€æ‰©æ•£æ¨¡å‹ã€CLIP</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.14111
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç”Ÿæˆæ¨¡å‹çš„è¿›æ­¥æ¿€å‘äº†äººä»¬å¯¹ç”Ÿæˆå›¾åƒçš„å…´è¶£ï¼ŒåŒæ—¶éµå®ˆç‰¹å®šçš„ç»“æ„å‡†åˆ™ã€‚åœºæ™¯å›¾åˆ°å›¾åƒç”Ÿæˆæ˜¯ç”Ÿæˆä¸ç»™å®šåœºæ™¯å›¾ä¸€è‡´çš„å›¾åƒçš„æ­¤ç±»ä»»åŠ¡ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œè§†è§‰åœºæ™¯çš„å¤æ‚æ€§å¯¹æ ¹æ®åœºæ™¯å›¾ä¸­æŒ‡å®šçš„å…³è”å‡†ç¡®å¯¹é½å¯¹è±¡æå‡ºäº†æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ–¹æ³•é€šè¿‡é¦–å…ˆé¢„æµ‹åœºæ™¯å¸ƒå±€å¹¶ä½¿ç”¨å¯¹æŠ—æ€§è®­ç»ƒä»è¿™äº›å¸ƒå±€ç”Ÿæˆå›¾åƒæ¥è§£å†³æ­¤ä»»åŠ¡ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨çš„é—®é¢˜åœ¨äºï¼Œå®ƒä»¬é¦–å…ˆéœ€è¦é¢„æµ‹åœºæ™¯å¸ƒå±€ï¼Œç„¶åæ‰èƒ½ç”Ÿæˆå›¾åƒã€‚è¿™ä½¿å¾—ç”Ÿæˆè¿‡ç¨‹å˜å¾—å¤æ‚ä¸”æ•ˆç‡ä½ä¸‹ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å…·æœ‰å¤æ‚å…³ç³»çš„åœºæ™¯å›¾æ—¶å¾€å¾€ä¼šé‡åˆ°å›°éš¾ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å…‹æœç°æœ‰æ–¹æ³•çš„ä¸è¶³ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥ä»åœºæ™¯å›¾ç”Ÿæˆå›¾åƒã€‚è¯¥æ–¹æ³•ä¸éœ€è¦é¢„æµ‹åœºæ™¯å¸ƒå±€ï¼Œè€Œæ˜¯ç›´æ¥å°†åœºæ™¯å›¾ä¸­çš„ä¿¡æ¯è½¬æ¢ä¸ºå›¾åƒã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ä½¿ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å’Œ CLIP æŒ‡å¯¼æ¥å°†å›¾çŸ¥è¯†è½¬æ¢ä¸ºå›¾åƒã€‚é¦–å…ˆï¼Œæœ¬æ–‡é¢„è®­ç»ƒå›¾ç¼–ç å™¨ï¼Œä½¿ç”¨åŸºäº GAN çš„è®­ç»ƒå°†å›¾ç‰¹å¾ä¸ç›¸åº”å›¾åƒçš„ CLIP ç‰¹å¾å¯¹é½ã€‚ç„¶åï¼Œå°†å›¾ç‰¹å¾ä¸åœºæ™¯å›¾ä¸­å­˜åœ¨çš„å¯¹è±¡æ ‡ç­¾çš„ CLIP åµŒå…¥èåˆï¼Œä»¥åˆ›å»ºå›¾ä¸€è‡´çš„ CLIP å¼•å¯¼æ¡ä»¶ä¿¡å·ã€‚åœ¨æ¡ä»¶è¾“å…¥ä¸­ï¼Œå¯¹è±¡åµŒå…¥æä¾›å›¾åƒçš„ç²—ç•¥ç»“æ„ï¼Œè€Œå›¾ç‰¹å¾æä¾›åŸºäºå¯¹è±¡ä¹‹é—´å…³ç³»çš„ç»“æ„å¯¹é½ã€‚æœ€åï¼Œä½¿ç”¨é‡å»ºå’Œ CLIP å¯¹é½æŸå¤±å¯¹é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå…¶ä¸­åŒ…å«å›¾ä¸€è‡´çš„æ¡ä»¶ä¿¡å·ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šå®éªŒè¯æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨ COCO-stuff å’Œ VisualGenome æ•°æ®é›†çš„æ ‡å‡†åŸºå‡†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆä¸åœºæ™¯å›¾ä¸€è‡´çš„é«˜è´¨é‡å›¾åƒã€‚</li>
</ol>
<p>Methods:</p>
<p>(1) å›¾ç¼–ç å™¨ï¼šä½¿ç”¨å¤šå±‚å›¾å·ç§¯ç½‘ç»œä»åœºæ™¯å›¾ä¸­ç”Ÿæˆå›¾ç‰¹å¾ã€‚å›¾ç¼–ç å™¨èåˆå„ä¸ªå¯¹è±¡åµŒå…¥å’Œå…³ç³»åµŒå…¥ï¼Œä»¥ç»™å‡ºå…¨å±€åœºæ™¯å›¾åµŒå…¥ã€‚</p>
<p>(2) CLIPå¼•å¯¼å›¾æ¡ä»¶ä¿¡å·ï¼šå°†å›¾ç‰¹å¾ä¸åœºæ™¯å›¾ä¸­å­˜åœ¨çš„å¯¹è±¡æ ‡ç­¾çš„ CLIP åµŒå…¥èåˆï¼Œä»¥åˆ›å»ºå›¾ä¸€è‡´çš„ CLIP å¼•å¯¼æ¡ä»¶ä¿¡å·ã€‚å¯¹è±¡åµŒå…¥æä¾›å›¾åƒçš„ç²—ç•¥ç»“æ„ï¼Œè€Œå›¾ç‰¹å¾æä¾›åŸºäºå¯¹è±¡ä¹‹é—´å…³ç³»çš„ç»“æ„å¯¹é½ã€‚</p>
<p>(3) å¾®è°ƒæ‰©æ•£æ¨¡å‹ï¼šä½¿ç”¨é‡å»ºå’Œ CLIP å¯¹é½æŸå¤±å¯¹é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå…¶ä¸­åŒ…å«å›¾ä¸€è‡´çš„æ¡ä»¶ä¿¡å·ã€‚</p>
<p>(4) GAN-based CLIP å¯¹é½æ¨¡å—ï¼šä½¿ç”¨åŸºäº GAN çš„ CLIP å¯¹é½æ¨¡å—å°†å›¾ç¼–ç å™¨è¾“å‡ºçš„ç‰¹å¾ä¸ç›¸åº”å›¾åƒçš„ CLIP ç‰¹å¾å¯¹é½ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šè¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„åœºæ™¯å›¾åˆ°å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œæ— éœ€ä¸­é—´åœºæ™¯å¸ƒå±€å³å¯è¿›è¡Œå›¾åƒåˆæˆã€‚æˆ‘ä»¬ä½¿ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œ CLIP å¼•å¯¼çš„å›¾æ¡ä»¶ä¿¡å·æ¥ç”Ÿæˆæ¡ä»¶ä¸ºåœºæ™¯å›¾çš„å›¾åƒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäº GAN çš„å¯¹é½æ¨¡å—ï¼Œå°†å›¾åµŒå…¥ä¸ CLIP æ½œåœ¨ç©ºé—´å¯¹é½ï¼Œä»¥åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å…ˆå‰è¯­ä¹‰ç†è§£ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºå›¾æ¡ä»¶ç”Ÿæˆï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¯¹é½æŸå¤±ã€‚é€šè¿‡ä½¿ç”¨å„ç§è¡¡é‡ç”Ÿæˆå›¾åƒè´¨é‡å’Œå¤šæ ·æ€§çš„æŒ‡æ ‡è¿›è¡Œç»¼åˆè¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨åœºæ™¯å›¾åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å±•ç¤ºäº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åœºæ™¯å›¾åˆ°å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œæ— éœ€ä¸­é—´åœºæ™¯å¸ƒå±€å³å¯è¿›è¡Œå›¾åƒåˆæˆã€‚</li>
<li>ä½¿ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œ CLIP å¼•å¯¼çš„å›¾æ¡ä»¶ä¿¡å·æ¥ç”Ÿæˆæ¡ä»¶ä¸ºåœºæ™¯å›¾çš„å›¾åƒã€‚</li>
<li>æå‡ºäº†ä¸€ä¸ªåŸºäº GAN çš„å¯¹é½æ¨¡å—ï¼Œå°†å›¾åµŒå…¥ä¸ CLIP æ½œåœ¨ç©ºé—´å¯¹é½ï¼Œä»¥åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å…ˆå‰è¯­ä¹‰ç†è§£ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªå¯¹é½æŸå¤±ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºå›¾æ¡ä»¶ç”Ÿæˆã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
- åœ¨ COCO-stuff å’Œ VisualGenome æ•°æ®é›†çš„æ ‡å‡†åŸºå‡†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚
- ç”Ÿæˆçš„å›¾åƒä¸åœºæ™¯å›¾ä¸€è‡´ï¼Œå…·æœ‰é«˜è´¨é‡å’Œå¤šæ ·æ€§ã€‚</p>
<p>å·¥ä½œé‡ï¼š
- éœ€è¦é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œ CLIP å¼•å¯¼çš„å›¾æ¡ä»¶ä¿¡å·ã€‚
- éœ€è¦å¯¹é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚
- éœ€è¦å¯¹ GAN-based CLIP å¯¹é½æ¨¡å—è¿›è¡Œè®­ç»ƒã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-518a8740c8e81a84d5c9adad9faed822.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e55358c77a9d65f15701e8f33262e2a4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-513010d0a919b07024562be2ef0e563a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e610be108eb0f2a257e8080f7af487d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-95b8fb0743373584fbfe5eee13bc5497.jpg" align="middle">
</details>




## BootPIG: Bootstrapping Zero-shot Personalized Image Generation   Capabilities in Pretrained Diffusion Models

**Authors:Senthil Purushwalkam, Akash Gokul, Shafiq Joty, Nikhil Naik**

Recent text-to-image generation models have demonstrated incredible success in generating images that faithfully follow input prompts. However, the requirement of using words to describe a desired concept provides limited control over the appearance of the generated concepts. In this work, we address this shortcoming by proposing an approach to enable personalization capabilities in existing text-to-image diffusion models. We propose a novel architecture (BootPIG) that allows a user to provide reference images of an object in order to guide the appearance of a concept in the generated images.   The proposed BootPIG architecture makes minimal modifications to a pretrained text-to-image diffusion model and utilizes a separate UNet model to steer the generations toward the desired appearance. We introduce a training procedure that allows us to bootstrap personalization capabilities in the BootPIG architecture using data generated from pretrained text-to-image models, LLM chat agents, and image segmentation models. In contrast to existing methods that require several days of pretraining, the BootPIG architecture can be trained in approximately 1 hour. Experiments on the DreamBooth dataset demonstrate that BootPIG outperforms existing zero-shot methods while being comparable with test-time finetuning approaches. Through a user study, we validate the preference for BootPIG generations over existing methods both in maintaining fidelity to the reference object's appearance and aligning with textual prompts. 

[PDF](http://arxiv.org/abs/2401.13974v1) 

**Summary**
BootPIG åˆ©ç”¨é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ•°æ®ï¼Œä»…éœ€ä¸€å°æ—¶å³å¯è®­ç»ƒï¼Œè¡¨ç°ä¼˜äºç°æœ‰é›¶æ¬¡å­¦ä¹ æ–¹æ³•ï¼Œå¹¶ä¸æµ‹è¯•æ—¶å¾®è°ƒæ–¹æ³•ç›¸å½“ã€‚

**Key Takeaways**

- BootPIG æå‡ºäº†ä¸€ç§æ–°çš„ BootPIG æ¶æ„ï¼Œå…è®¸ç”¨æˆ·ä½¿ç”¨å‚è€ƒå›¾åƒå¼•å¯¼ç”Ÿæˆå›¾åƒä¸­æ¦‚å¿µçš„å¤–è§‚ã€‚
- BootPIG å¯¹é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¿›è¡Œæœ€å°çš„ä¿®æ”¹ï¼Œå¹¶ä½¿ç”¨å•ç‹¬çš„ UNet æ¨¡å‹å°†ç”Ÿæˆçš„å›¾åƒå¼•å¯¼è‡³æ‰€éœ€çš„å¤–è§‚ã€‚
- BootPIG ä½¿ç”¨æ¥è‡ªé¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€LLM èŠå¤©ä»£ç†å’Œå›¾åƒåˆ†å‰²æ¨¡å‹ç”Ÿæˆçš„æ•°æ®ï¼Œå¼•å…¥äº†å…è®¸æˆ‘ä»¬åœ¨ BootPIG æ¶æ„ä¸­å¼•å¯¼ä¸ªæ€§åŒ–åŠŸèƒ½çš„è®­ç»ƒè¿‡ç¨‹ã€‚
- ä¸éœ€è¦æ•°å¤©é¢„è®­ç»ƒçš„ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒBootPIG æ¶æ„å¯ä»¥åœ¨å¤§çº¦ 1 å°æ—¶å†…å®Œæˆè®­ç»ƒã€‚
- DreamBooth æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBootPIG çš„æ€§èƒ½ä¼˜äºç°æœ‰çš„é›¶æ¬¡å­¦ä¹ æ–¹æ³•ï¼ŒåŒæ—¶ä¸æµ‹è¯•æ—¶å¾®è°ƒæ–¹æ³•ç›¸å½“ã€‚
- é€šè¿‡ç”¨æˆ·ç ”ç©¶ï¼Œæˆ‘ä»¬éªŒè¯äº† BootPIG ç”Ÿæˆçš„å›¾åƒåœ¨ä¿æŒå¯¹å‚è€ƒå¯¹è±¡å¤–è§‚çš„å¿ å®åº¦å’Œä¸æ–‡æœ¬æç¤ºä¿æŒä¸€è‡´æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šBootPIGï¼šåˆ©ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹å¼•å¯¼é›¶æ ·æœ¬ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆèƒ½åŠ›</li>
<li>ä½œè€…ï¼šSenthil Purushwalkamã€Akash Gokulã€Shafiq Jotyã€Nikhil Naik</li>
<li>ä½œè€…å•ä½ï¼šSalesforce AI Researchï¼ˆä»…ç¿»è¯‘ä¸ºä¸­æ–‡ï¼‰</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€ä¸ªæ€§åŒ–å›¾åƒç”Ÿæˆã€é›¶æ ·æœ¬å­¦ä¹ ã€å¼•å¯¼æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.13974ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹é€šå¸¸æ— æ³•æ ¹æ®ç‰¹å®šä¸»é¢˜ç”Ÿæˆä¸ªæ€§åŒ–çš„å›¾åƒã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„é¢„è®­ç»ƒæ•°æ®æˆ–å¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶ä¸”åœ¨ç”Ÿæˆä¸ªæ€§åŒ–å›¾åƒæ—¶å¾€å¾€å­˜åœ¨ä¿çœŸåº¦ä½ã€ä¸æ–‡æœ¬æè¿°ä¸ä¸€è‡´ç­‰é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¶æ„ BootPIGï¼Œå®ƒå…è®¸ç”¨æˆ·æä¾›å‚è€ƒå›¾åƒæ¥å¼•å¯¼ç”Ÿæˆå›¾åƒä¸­æ¦‚å¿µçš„å¤–è§‚ã€‚BootPIG å¯¹é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®å°çš„ä¿®æ”¹ï¼Œå¹¶åˆ©ç”¨ä¸€ä¸ªå•ç‹¬çš„ U-Net æ¨¡å‹æ¥å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œä½¿å…¶æœç€æœŸæœ›çš„å¤–è§‚æ–¹å‘å‘å±•ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ç§è®­ç»ƒè¿‡ç¨‹ï¼Œå¯ä»¥ä½¿ç”¨ä»é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€LLM èŠå¤©ä»£ç†å’Œå›¾åƒåˆ†å‰²æ¨¡å‹ç”Ÿæˆçš„æ•°æ®æ¥å¼•å¯¼ BootPIG æ¶æ„ä¸­çš„ä¸ªæ€§åŒ–èƒ½åŠ›ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šåœ¨ DreamBooth æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBootPIG åœ¨ä¿æŒå¯¹å‚è€ƒå¯¹è±¡å¤–è§‚çš„ä¿çœŸåº¦å’Œä¸æ–‡æœ¬æè¿°çš„ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¸æµ‹è¯•æ—¶å¾®è°ƒæ–¹æ³•ç›¸å½“ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) BootPIG æ¶æ„ï¼šBootPIG æ¶æ„ç”±ä¸€ä¸ªé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å’Œä¸€ä¸ªå¼•å¯¼ U-Net æ¨¡å‹ç»„æˆã€‚é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è´Ÿè´£ä»æ–‡æœ¬æè¿°ä¸­ç”Ÿæˆå›¾åƒï¼Œè€Œå¼•å¯¼ U-Net æ¨¡å‹åˆ™è´Ÿè´£å°†å‚è€ƒå›¾åƒä¸­çš„æ¦‚å¿µå¤–è§‚å¼•å¯¼åˆ°ç”Ÿæˆå›¾åƒä¸­ã€‚
(2) å¼•å¯¼è®­ç»ƒè¿‡ç¨‹ï¼šBootPIG çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¢«å¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿä»æ–‡æœ¬æè¿°ä¸­ç”Ÿæˆæ›´é€¼çœŸçš„å›¾åƒã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œå¼•å¯¼ U-Net æ¨¡å‹è¢«è®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿå°†å‚è€ƒå›¾åƒä¸­çš„æ¦‚å¿µå¤–è§‚å¼•å¯¼åˆ°ç”Ÿæˆå›¾åƒä¸­ã€‚
(3) æ•°æ®ç”Ÿæˆï¼šBootPIG çš„è®­ç»ƒè¿‡ç¨‹ä½¿ç”¨ä»é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€LLM èŠå¤©ä»£ç†å’Œå›¾åƒåˆ†å‰²æ¨¡å‹ç”Ÿæˆçš„æ•°æ®ã€‚è¿™äº›æ•°æ®åŒ…æ‹¬æ–‡æœ¬æè¿°ã€å‚è€ƒå›¾åƒå’Œåˆ†å‰²æ©ç ã€‚
(4) æ¨ç†è¿‡ç¨‹ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒBootPIG ä½¿ç”¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å’Œå¼•å¯¼ U-Net æ¨¡å‹æ¥ç”Ÿæˆå›¾åƒã€‚é¦–å…ˆï¼Œé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä»æ–‡æœ¬æè¿°ä¸­ç”Ÿæˆä¸€ä¸ªå›¾åƒã€‚ç„¶åï¼Œå¼•å¯¼ U-Net æ¨¡å‹å°†å‚è€ƒå›¾åƒä¸­çš„æ¦‚å¿µå¤–è§‚å¼•å¯¼åˆ°ç”Ÿæˆå›¾åƒä¸­ã€‚æœ€åï¼Œç”Ÿæˆçš„å›¾åƒè¢«è¾“å‡ºã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1)ï¼šBootPIG æå‡ºäº†ä¸€ç§æ–°çš„æ¶æ„ï¼Œå…è®¸ç”¨æˆ·æä¾›å‚è€ƒå›¾åƒæ¥å¼•å¯¼ç”Ÿæˆå›¾åƒä¸­æ¦‚å¿µçš„å¤–è§‚ï¼Œåœ¨ä¿æŒå¯¹å‚è€ƒå¯¹è±¡å¤–è§‚çš„ä¿çœŸåº¦å’Œä¸æ–‡æœ¬æè¿°çš„ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¸æµ‹è¯•æ—¶å¾®è°ƒæ–¹æ³•ç›¸å½“ã€‚
(2)ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>BootPIG æå‡ºäº†ä¸€ç§æ–°çš„æ¶æ„ï¼Œå…è®¸ç”¨æˆ·æä¾›å‚è€ƒå›¾åƒæ¥å¼•å¯¼ç”Ÿæˆå›¾åƒä¸­æ¦‚å¿µçš„å¤–è§‚ã€‚</li>
<li>BootPIG å¼•å…¥äº†ä¸€ç§è®­ç»ƒè¿‡ç¨‹ï¼Œå¯ä»¥ä½¿ç”¨ä»é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€LLM èŠå¤©ä»£ç†å’Œå›¾åƒåˆ†å‰²æ¨¡å‹ç”Ÿæˆçš„æ•°æ®æ¥å¼•å¯¼ BootPIG æ¶æ„ä¸­çš„ä¸ªæ€§åŒ–èƒ½åŠ›ã€‚</li>
<li>BootPIG åœ¨ DreamBooth æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨ä¿æŒå¯¹å‚è€ƒå¯¹è±¡å¤–è§‚çš„ä¿çœŸåº¦å’Œä¸æ–‡æœ¬æè¿°çš„ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¸æµ‹è¯•æ—¶å¾®è°ƒæ–¹æ³•ç›¸å½“ã€‚
æ€§èƒ½ï¼š</li>
<li>BootPIG åœ¨ DreamBooth æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåœ¨ä¿æŒå¯¹å‚è€ƒå¯¹è±¡å¤–è§‚çš„ä¿çœŸåº¦å’Œä¸æ–‡æœ¬æè¿°çš„ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¸æµ‹è¯•æ—¶å¾®è°ƒæ–¹æ³•ç›¸å½“ã€‚
å·¥ä½œé‡ï¼š</li>
<li>BootPIG çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼Œç¬¬ä¸€é˜¶æ®µå¾®è°ƒé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œç¬¬äºŒé˜¶æ®µè®­ç»ƒå¼•å¯¼ U-Net æ¨¡å‹ã€‚</li>
<li>BootPIG çš„è®­ç»ƒè¿‡ç¨‹ä½¿ç”¨ä»é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€LLM èŠå¤©ä»£ç†å’Œå›¾åƒåˆ†å‰²æ¨¡å‹ç”Ÿæˆçš„æ•°æ®ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e2ecdf9f08a2cadce3096ead80db29d5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d3f5a69af875397219d470fd2b55dde8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-02a980dac9e87a3930c4c6e9ef96072c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7981b6cc67ddcffe001849665e1b21c5.jpg" align="middle">
</details>




<h2 id="HiCAST-Highly-Customized-Arbitrary-Style-Transfer-with-Adapter-Enhanced-Diffusion-Models"><a href="#HiCAST-Highly-Customized-Arbitrary-Style-Transfer-with-Adapter-Enhanced-Diffusion-Models" class="headerlink" title="HiCAST: Highly Customized Arbitrary Style Transfer with Adapter Enhanced   Diffusion Models"></a>HiCAST: Highly Customized Arbitrary Style Transfer with Adapter Enhanced   Diffusion Models</h2><p><strong>Authors:Hanzhang Wang, Haoran Wang, Jinze Yang, Zhongrui Yu, Zeke Xie, Lei Tian, Xinyan Xiao, Junjun Jiang, Xianming Liu, Mingming Sun</strong></p>
<p>The goal of Arbitrary Style Transfer (AST) is injecting the artistic features of a style reference into a given image/video. Existing methods usually focus on pursuing the balance between style and content, whereas ignoring the significant demand for flexible and customized stylization results and thereby limiting their practical application. To address this critical issue, a novel AST approach namely HiCAST is proposed, which is capable of explicitly customizing the stylization results according to various source of semantic clues. In the specific, our model is constructed based on Latent Diffusion Model (LDM) and elaborately designed to absorb content and style instance as conditions of LDM. It is characterized by introducing of \textit{Style Adapter}, which allows user to flexibly manipulate the output results by aligning multi-level style information and intrinsic knowledge in LDM. Lastly, we further extend our model to perform video AST. A novel learning objective is leveraged for video diffusion model training, which significantly improve cross-frame temporal consistency in the premise of maintaining stylization strength. Qualitative and quantitative comparisons as well as comprehensive user studies demonstrate that our HiCAST outperforms the existing SoTA methods in generating visually plausible stylization results. </p>
<p><a href="http://arxiv.org/abs/2401.05870v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>HiCAST æ˜¯ä¸€ç§æ–°é¢–çš„ä»»æ„é£æ ¼è¿ç§»æ–¹æ³•ï¼Œèƒ½å¤Ÿæ ¹æ®è¯­ä¹‰çº¿ç´¢æ¥æºæ˜¾å¼è‡ªå®šä¹‰é£æ ¼åŒ–ç»“æœã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>HiCAST åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ (LDM) æ„å»ºï¼Œç²¾å¿ƒè®¾è®¡ç”¨äºå¸æ”¶å†…å®¹å’Œé£æ ¼å®ä¾‹ä½œä¸º LDM çš„æ¡ä»¶ã€‚</li>
<li>å¼•å…¥äº†â€œé£æ ¼é€‚é…å™¨â€ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡å¯¹é½ LDM ä¸­çš„å¤šçº§é£æ ¼ä¿¡æ¯å’Œå†…åœ¨çŸ¥è¯†æ¥çµæ´»åœ°æ“ä½œè¾“å‡ºç»“æœã€‚</li>
<li>å°† HiCAST æ‰©å±•åˆ°è§†é¢‘ä»»æ„é£æ ¼è¿ç§»ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„å­¦ä¹ ç›®æ ‡ï¼Œæ˜¾è‘—æé«˜äº†è§†é¢‘æ‰©æ•£æ¨¡å‹è®­ç»ƒä¸­çš„è·¨å¸§æ—¶é—´ä¸€è‡´æ€§ï¼ŒåŒæ—¶ä¿æŒäº†é£æ ¼åŒ–å¼ºåº¦ã€‚</li>
<li>ä¸ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒHiCAST åœ¨ç”Ÿæˆè§†è§‰ä¸Šåˆç†çš„é£æ ¼åŒ–ç»“æœæ–¹é¢å…·æœ‰æ›´å¥½çš„è¡¨ç°ã€‚</li>
<li>å®šæ€§å’Œå®šé‡æ¯”è¾ƒä»¥åŠå…¨é¢çš„ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒHiCAST åœ¨ç”Ÿæˆè§†è§‰ä¸Šåˆç†çš„é£æ ¼åŒ–ç»“æœæ–¹é¢ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šHiCASTï¼šé«˜åº¦å®šåˆ¶çš„ä»»æ„é£æ ¼è¿ç§»</li>
<li>ä½œè€…ï¼šJiachen An, Shixiang Huang, Yuming Song, Dandan Dou, Wen Liu, Jinlong Luo</li>
<li>å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šArbitrary Style Transfer, Diffusion Model, Style Customization, Video Stylization</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2306.09330, Githubï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šä»»æ„é£æ ¼è¿ç§»ï¼ˆASTï¼‰æ—¨åœ¨å°†é£æ ¼å‚è€ƒçš„è‰ºæœ¯ç‰¹å¾æ³¨å…¥ç»™å®šå›¾åƒ/è§†é¢‘ä¸­ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¸“æ³¨äºè¿½æ±‚é£æ ¼å’Œå†…å®¹ä¹‹é—´çš„å¹³è¡¡ï¼Œè€Œå¿½ç•¥äº†å¯¹çµæ´»å’Œå®šåˆ¶çš„é£æ ¼åŒ–ç»“æœçš„é‡å¤§éœ€æ±‚ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬çš„å®é™…åº”ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šä¸ºäº†è§£å†³è¿™ä¸€å…³é”®é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ AST æ–¹æ³•ï¼Œç§°ä¸º HiCASTï¼Œå®ƒèƒ½å¤Ÿæ ¹æ®å„ç§è¯­ä¹‰çº¿ç´¢æ¥æºæ˜¾å¼åœ°å®šåˆ¶é£æ ¼åŒ–ç»“æœã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰æ„å»ºï¼Œå¹¶ç²¾å¿ƒè®¾è®¡ä»¥å¸æ”¶å†…å®¹å’Œé£æ ¼å®ä¾‹ä½œä¸º LDM çš„æ¡ä»¶ã€‚å®ƒçš„ç‰¹ç‚¹æ˜¯å¼•å…¥äº†é£æ ¼é€‚é…å™¨ï¼Œå®ƒå…è®¸ç”¨æˆ·é€šè¿‡å¯¹é½å¤šçº§é£æ ¼ä¿¡æ¯å’Œ LDM ä¸­çš„å†…åœ¨çŸ¥è¯†æ¥çµæ´»åœ°æ“çºµè¾“å‡ºç»“æœã€‚æœ€åï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æ‰©å±•äº†æˆ‘ä»¬çš„æ¨¡å‹ä»¥æ‰§è¡Œè§†é¢‘ ASTã€‚åˆ©ç”¨äº†ä¸€ç§æ–°çš„å­¦ä¹ ç›®æ ‡è¿›è¡Œè§†é¢‘æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼Œè¿™åœ¨ä¿æŒé£æ ¼åŒ–å¼ºåº¦çš„å‰æä¸‹æ˜¾è‘—æé«˜äº†è·¨å¸§æ—¶é—´ä¸€è‡´æ€§ã€‚å®šæ€§å’Œå®šé‡æ¯”è¾ƒä»¥åŠå…¨é¢çš„ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œæˆ‘ä»¬çš„ HiCAST åœ¨ç”Ÿæˆè§†è§‰ä¸Šåˆç†çš„é£æ ¼åŒ–ç»“æœæ–¹é¢ä¼˜äºç°æœ‰çš„ SoTA æ–¹æ³•ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•æ˜¯ï¼šæ„å»ºåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„ASTæ¨¡å‹ï¼Œå¼•å…¥é£æ ¼é€‚é…å™¨ä»¥å®ç°çµæ´»çš„é£æ ¼åŒ–ç»“æœå®šåˆ¶ï¼Œæ‰©å±•æ¨¡å‹ä»¥æ‰§è¡Œè§†é¢‘ASTï¼Œå¹¶åˆ©ç”¨æ–°çš„å­¦ä¹ ç›®æ ‡è¿›è¡Œè§†é¢‘æ‰©æ•£æ¨¡å‹è®­ç»ƒã€‚
ï¼ˆ4ï¼‰ï¼šæœ¬è®ºæ–‡çš„æ–¹æ³•åœ¨ä»»æ„é£æ ¼è¿ç§»ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨å›¾åƒå’Œè§†é¢‘é£æ ¼åŒ–æ–¹é¢å‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†è®ºæ–‡çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆè§†è§‰ä¸Šåˆç†çš„é£æ ¼åŒ–ç»“æœå¹¶å®ç°çµæ´»çš„é£æ ¼åŒ–ç»“æœå®šåˆ¶ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ„å»ºåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„ASTæ¨¡å‹ï¼Œé‡‡ç”¨é¢„è®­ç»ƒçš„VAEç¼–ç å™¨å’ŒVGG-16ç½‘ç»œä½œä¸ºå†…å®¹ç¼–ç å™¨å’Œé£æ ¼ç¼–ç å™¨ï¼Œå¹¶è®¾è®¡äº†é£æ ¼é€‚é…å™¨æ¥å®ç°çµæ´»çš„é£æ ¼åŒ–ç»“æœå®šåˆ¶ã€‚
ï¼ˆ2ï¼‰é‡‡ç”¨ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼ŒåŒ…æ‹¬å›¾åƒæ¨¡å‹å¾®è°ƒé˜¶æ®µã€é€‚é…å™¨è®­ç»ƒé˜¶æ®µå’Œæ—¶é—´å±‚è®­ç»ƒé˜¶æ®µï¼Œå¹¶è®¾è®¡äº†æ··åˆç›‘ç£æŸå¤±å‡½æ•°æ¥æŒ‡å¯¼æ¨¡å‹è®­ç»ƒã€‚
ï¼ˆ3ï¼‰æå‡ºäº†ä¸€ç§æ–°çš„å­¦ä¹ ç›®æ ‡è¿›è¡Œè§†é¢‘æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼Œé€šè¿‡å¼•å…¥å’Œè°ä¸€è‡´æ€§æŸå¤±æ¥ä¿æŒè·¨å¸§æ—¶é—´ä¸€è‡´æ€§ï¼Œå¹¶æ·»åŠ æ—¶é—´å±‚æ¥å¯¹è§†é¢‘è¿›è¡Œå»ºæ¨¡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œé€šè¿‡æ„å»ºåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„ASTæ¨¡å‹ï¼Œå¼•å…¥é£æ ¼é€‚é…å™¨ä»¥å®ç°çµæ´»çš„é£æ ¼åŒ–ç»“æœå®šåˆ¶ï¼Œæ‰©å±•æ¨¡å‹ä»¥æ‰§è¡Œè§†é¢‘ASTï¼Œå¹¶åˆ©ç”¨æ–°çš„å­¦ä¹ ç›®æ ‡è¿›è¡Œè§†é¢‘æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼Œåœ¨ä»»æ„é£æ ¼è¿ç§»ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨å›¾åƒå’Œè§†é¢‘é£æ ¼åŒ–æ–¹é¢å‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†è®ºæ–‡çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆè§†è§‰ä¸Šåˆç†çš„é£æ ¼åŒ–ç»“æœå¹¶å®ç°çµæ´»çš„é£æ ¼åŒ–ç»“æœå®šåˆ¶ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„ASTæ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ ¹æ®å„ç§è¯­ä¹‰çº¿ç´¢æ¥æºæ˜¾å¼åœ°å®šåˆ¶é£æ ¼åŒ–ç»“æœã€‚
ï¼ˆ2ï¼‰è®¾è®¡äº†é£æ ¼é€‚é…å™¨ï¼Œå®ƒå…è®¸ç”¨æˆ·é€šè¿‡å¯¹é½å¤šçº§é£æ ¼ä¿¡æ¯å’ŒLDMä¸­çš„å†…åœ¨çŸ¥è¯†æ¥çµæ´»åœ°æ“çºµè¾“å‡ºç»“æœã€‚
ï¼ˆ3ï¼‰æå‡ºäº†æ–°çš„å­¦ä¹ ç›®æ ‡è¿›è¡Œè§†é¢‘æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼Œè¿™åœ¨ä¿æŒé£æ ¼åŒ–å¼ºåº¦çš„å‰æä¸‹æ˜¾è‘—æé«˜äº†è·¨å¸§æ—¶é—´ä¸€è‡´æ€§ã€‚
æ€§èƒ½ï¼š
ï¼ˆ1ï¼‰åœ¨å›¾åƒé£æ ¼åŒ–ä»»åŠ¡ä¸Šï¼ŒHiCASTåœ¨FIDå’ŒLPIPSæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰åœ¨è§†é¢‘é£æ ¼åŒ–ä»»åŠ¡ä¸Šï¼ŒHiCASTåœ¨FIDå’ŒLPIPSæŒ‡æ ‡ä¸Šä¹Ÿä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚
ï¼ˆ3ï¼‰ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒHiCASTåœ¨ç”Ÿæˆè§†è§‰ä¸Šåˆç†çš„é£æ ¼åŒ–ç»“æœæ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
ï¼ˆ1ï¼‰æ„å»ºåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„ASTæ¨¡å‹ã€‚
ï¼ˆ2ï¼‰è®¾è®¡é£æ ¼é€‚é…å™¨ä»¥å®ç°çµæ´»çš„é£æ ¼åŒ–ç»“æœå®šåˆ¶ã€‚
ï¼ˆ3ï¼‰æ‰©å±•æ¨¡å‹ä»¥æ‰§è¡Œè§†é¢‘ASTã€‚
ï¼ˆ4ï¼‰åˆ©ç”¨æ–°çš„å­¦ä¹ ç›®æ ‡è¿›è¡Œè§†é¢‘æ‰©æ•£æ¨¡å‹è®­ç»ƒã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-352507fbd77e3adcd733f2041bffbe47.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3a9d48ccea55e5c85c44aac94261c324.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16386b8ae01c7a44b1aac3c30a708331.jpg" align="middle">
</details>




<h2 id="Style-Injection-in-Diffusion-A-Training-free-Approach-for-Adapting-Large-scale-Diffusion-Models-for-Style-Transfer"><a href="#Style-Injection-in-Diffusion-A-Training-free-Approach-for-Adapting-Large-scale-Diffusion-Models-for-Style-Transfer" class="headerlink" title="Style Injection in Diffusion: A Training-free Approach for Adapting   Large-scale Diffusion Models for Style Transfer"></a>Style Injection in Diffusion: A Training-free Approach for Adapting   Large-scale Diffusion Models for Style Transfer</h2><p><strong>Authors:Jiwoo Chung, Sangeek Hyun, Jae-Pil Heo</strong></p>
<p>Despite the impressive generative capabilities of diffusion models, existing diffusion model-based style transfer methods require inference-stage optimization (e.g. fine-tuning or textual inversion of style) which is time-consuming, or fails to leverage the generative ability of large-scale diffusion models. To address these issues, we introduce a novel artistic style transfer method based on a pre-trained large-scale diffusion model without any optimization. Specifically, we manipulate the features of self-attention layers as the way the cross-attention mechanism works; in the generation process, substituting the key and value of content with those of style image. This approach provides several desirable characteristics for style transfer including 1) preservation of content by transferring similar styles into similar image patches and 2) transfer of style based on similarity of local texture (e.g. edge) between content and style images. Furthermore, we introduce query preservation and attention temperature scaling to mitigate the issue of disruption of original content, and initial latent Adaptive Instance Normalization (AdaIN) to deal with the disharmonious color (failure to transfer the colors of style). Our experimental results demonstrate that our proposed method surpasses state-of-the-art methods in both conventional and diffusion-based style transfer baselines. </p>
<p><a href="http://arxiv.org/abs/2312.09008v1">PDF</a> 16 pages</p>
<p><strong>Summary</strong><br>æ— ä¼˜åŒ–æ‰©æ•£å›¾åƒé£æ ¼è¿ç§»ï¼Œé€šè¿‡é¢„è®­ç»ƒæ¨¡å‹æ“æ§è‡ªæ³¨æ„åŠ›å±‚çš„ç‰¹æ€§ï¼Œå®ç°ç»†è‡´é£æ ¼è¿ç§»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æœ¬æ–‡æå‡ºçš„æ–¹æ³•æ— éœ€ä¼˜åŒ–å³å¯å°†é£æ ¼è¿ç§»åˆ°é¢„è®­ç»ƒçš„å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹ä¸Šã€‚</li>
<li>æœ¬æ–‡æ“çºµè‡ªæ³¨æ„å±‚çš„ç‰¹æ€§ï¼Œä½¿é£æ ¼å›¾åƒçš„ç‰¹å¾ä»£æ›¿å†…å®¹çš„ç‰¹å¾ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰è‹¥å¹²ä¼˜ç‚¹ï¼ŒåŒ…æ‹¬ä¿ç•™å†…å®¹ï¼Œå¹¶æ ¹æ®å†…å®¹å’Œé£æ ¼å›¾åƒä¹‹é—´çš„å±€éƒ¨çº¹ç†ç›¸ä¼¼æ€§è¿›è¡Œé£æ ¼è¿ç§»ã€‚</li>
<li>æœ¬æ–‡æå‡ºæŸ¥è¯¢ä¿ç•™å’Œæ³¨æ„åŠ›æ¸©åº¦ç¼©æ”¾ï¼Œä»¥å‡è½»å¯¹åŸå§‹å†…å®¹çš„ç ´åï¼Œå¹¶å¼•å…¥åˆå§‹æ½œåœ¨è‡ªé€‚åº”å®ä¾‹å½’ä¸€åŒ– (AdaIN) æ¥å¤„ç†ä¸å’Œè°çš„è‰²å½©ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºä¼ ç»Ÿå’ŒåŸºäºæ‰©æ•£çš„é£æ ¼è¿ç§»åŸºå‡†ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šæ‰©æ•£ä¸­çš„é£æ ¼æ³¨å…¥ï¼šä¸€ç§æ— è®­ç»ƒæ–¹æ³•</li>
<li>ä½œè€…ï¼šSung Kwon An, Dongwon Kim, Junyoung Seo, Youngjoon Yoo</li>
<li>å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢</li>
<li>å…³é”®è¯ï¼šè‰ºæœ¯é£æ ¼è¿ç§»ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œè‡ªæ³¨æ„åŠ›ï¼Œå›¾åƒç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ–¹é¢å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æˆæœï¼Œä½†ç°æœ‰çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„é£æ ¼è¿ç§»æ–¹æ³•éœ€è¦æ¨ç†é˜¶æ®µçš„ä¼˜åŒ–ï¼ˆä¾‹å¦‚ï¼Œå¯¹é£æ ¼è¿›è¡Œå¾®è°ƒæˆ–æ–‡æœ¬åæ¼”ï¼‰ï¼Œè¿™éå¸¸è€—æ—¶ï¼Œå¹¶ä¸”æ— æ³•åˆ©ç”¨å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•éœ€è¦æ¨ç†é˜¶æ®µçš„ä¼˜åŒ–ï¼Œè¿™éå¸¸è€—æ—¶ï¼Œå¹¶ä¸”æ— æ³•åˆ©ç”¨å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‰ºæœ¯é£æ ¼è¿ç§»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŸºäºé¢„è®­ç»ƒçš„å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹ï¼Œæ— éœ€ä»»ä½•ä¼˜åŒ–ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†è‡ªæ³¨æ„åŠ›å±‚çš„ç‰¹å¾ä½œä¸ºäº¤å‰æ³¨æ„åŠ›æœºåˆ¶å·¥ä½œçš„æ–¹å¼è¿›è¡Œæ“ä½œï¼›åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç”¨é£æ ¼å›¾åƒçš„é”®å’Œå€¼æ›¿æ¢å†…å®¹çš„é”®å’Œå€¼ã€‚è¿™ç§æ–¹æ³•ä¸ºé£æ ¼è¿ç§»æä¾›äº†å‡ ä¸ªç†æƒ³çš„ç‰¹æ€§ï¼ŒåŒ…æ‹¬ 1ï¼‰é€šè¿‡å°†ç›¸ä¼¼é£æ ¼è½¬ç§»åˆ°ç›¸ä¼¼å›¾åƒå—ä¸­æ¥ä¿ç•™å†…å®¹ï¼Œä»¥åŠ 2ï¼‰åŸºäºå†…å®¹å’Œé£æ ¼å›¾åƒä¹‹é—´å±€éƒ¨çº¹ç†ï¼ˆä¾‹å¦‚è¾¹ç¼˜ï¼‰çš„ç›¸ä¼¼æ€§æ¥è½¬ç§»é£æ ¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†æŸ¥è¯¢ä¿ç•™å’Œæ³¨æ„åŠ›æ¸©åº¦ç¼©æ”¾æ¥å‡è½»ç ´ååŸå§‹å†…å®¹çš„é—®é¢˜ï¼Œå¹¶å¼•å…¥äº†åˆå§‹æ½œåœ¨è‡ªé€‚åº”å®ä¾‹å½’ä¸€åŒ– (AdaIN) æ¥å¤„ç†ä¸å’Œè°çš„é¢œè‰²ï¼ˆæ— æ³•è½¬ç§»é£æ ¼çš„é¢œè‰²ï¼‰ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨ä¼ ç»Ÿå’ŒåŸºäºæ‰©æ•£çš„é£æ ¼è¿ç§»åŸºå‡†ä¸­éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‰ºæœ¯é£æ ¼è¿ç§»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŸºäºé¢„è®­ç»ƒçš„å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹ï¼Œæ— éœ€ä»»ä½•ä¼˜åŒ–ã€‚
ï¼ˆ2ï¼‰å°†è‡ªæ³¨æ„åŠ›å±‚çš„ç‰¹å¾ä½œä¸ºäº¤å‰æ³¨æ„åŠ›æœºåˆ¶å·¥ä½œçš„æ–¹å¼è¿›è¡Œæ“ä½œï¼›åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç”¨é£æ ¼å›¾åƒçš„é”®å’Œå€¼æ›¿æ¢å†…å®¹çš„é”®å’Œå€¼ã€‚
ï¼ˆ3ï¼‰å¼•å…¥äº†æŸ¥è¯¢ä¿ç•™å’Œæ³¨æ„åŠ›æ¸©åº¦ç¼©æ”¾æ¥å‡è½»ç ´ååŸå§‹å†…å®¹çš„é—®é¢˜ï¼Œå¹¶å¼•å…¥äº†åˆå§‹æ½œåœ¨è‡ªé€‚åº”å®ä¾‹å½’ä¸€åŒ–(AdaIN)æ¥å¤„ç†ä¸å’Œè°çš„é¢œè‰²ï¼ˆæ— æ³•è½¬ç§»é£æ ¼çš„é¢œè‰²ï¼‰ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œè§£å†³äº†åŸºäºæ‰©æ•£æ¨¡å‹çš„é£æ ¼è¿ç§»æ–¹æ³•é¢ä¸´çš„æŒ‘æˆ˜ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦è€—æ—¶çš„ä¼˜åŒ–æ­¥éª¤æˆ–éš¾ä»¥åˆ©ç”¨å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ½œåŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†åˆ©ç”¨é¢„è®­ç»ƒçš„å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œæ— éœ€ä»»ä½•ä¼˜åŒ–ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å°†è‡ªæ³¨æ„åŠ›å±‚çš„ç‰¹å¾ä½œä¸ºäº¤å‰æ³¨æ„åŠ›æœºåˆ¶å·¥ä½œçš„æ–¹å¼è¿›è¡Œæ“ä½œï¼›åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œç”¨é£æ ¼å›¾åƒçš„é”®å’Œå€¼æ›¿æ¢å†…å®¹çš„é”®å’Œå€¼ã€‚</li>
<li>å¼•å…¥äº†æŸ¥è¯¢ä¿ç•™å’Œæ³¨æ„åŠ›æ¸©åº¦ç¼©æ”¾æ¥å‡è½»ç ´ååŸå§‹å†…å®¹çš„é—®é¢˜ï¼Œå¹¶å¼•å…¥äº†åˆå§‹æ½œåœ¨è‡ªé€‚åº”å®ä¾‹å½’ä¸€åŒ–(AdaIN)æ¥å¤„ç†ä¸å’Œè°çš„é¢œè‰²ï¼ˆæ— æ³•è½¬ç§»é£æ ¼çš„é¢œè‰²ï¼‰ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¼ ç»Ÿå’ŒåŸºäºæ‰©æ•£çš„é£æ ¼è¿ç§»åŸºå‡†ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•æ— éœ€æ¨ç†é˜¶æ®µçš„ä¼˜åŒ–ï¼Œå› æ­¤å¯ä»¥åˆ©ç”¨å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œä»è€Œå‡å°‘äº†å·¥ä½œé‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3c5ea0ed861e220177fdc07f214f3694.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0c9148fdb00478b35cac320276a8fc70.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-82f6f6c5f9fd21bc24d5f8b3ab902752.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ede5506ccc5b19f67905edc640f55e57.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4fd944f7f8c142e744a1d02eb4176d52.jpg" align="middle">
</details>




<h2 id="ArtBank-Artistic-Style-Transfer-with-Pre-trained-Diffusion-Model-and-Implicit-Style-Prompt-Bank"><a href="#ArtBank-Artistic-Style-Transfer-with-Pre-trained-Diffusion-Model-and-Implicit-Style-Prompt-Bank" class="headerlink" title="ArtBank: Artistic Style Transfer with Pre-trained Diffusion Model and   Implicit Style Prompt Bank"></a>ArtBank: Artistic Style Transfer with Pre-trained Diffusion Model and   Implicit Style Prompt Bank</h2><p><strong>Authors:Zhanjie Zhang, Quanwei Zhang, Guangyuan Li, Wei Xing, Lei Zhao, Jiakai Sun, Zehua Lan, Junsheng Luan, Yiling Huang, Huaizhong Lin</strong></p>
<p>Artistic style transfer aims to repaint the content image with the learned artistic style. Existing artistic style transfer methods can be divided into two categories: small model-based approaches and pre-trained large-scale model-based approaches. Small model-based approaches can preserve the content strucuture, but fail to produce highly realistic stylized images and introduce artifacts and disharmonious patterns; Pre-trained large-scale model-based approaches can generate highly realistic stylized images but struggle with preserving the content structure. To address the above issues, we propose ArtBank, a novel artistic style transfer framework, to generate highly realistic stylized images while preserving the content structure of the content images. Specifically, to sufficiently dig out the knowledge embedded in pre-trained large-scale models, an Implicit Style Prompt Bank (ISPB), a set of trainable parameter matrices, is designed to learn and store knowledge from the collection of artworks and behave as a visual prompt to guide pre-trained large-scale models to generate highly realistic stylized images while preserving content structure. Besides, to accelerate training the above ISPB, we propose a novel Spatial-Statistical-based self-Attention Module (SSAM). The qualitative and quantitative experiments demonstrate the superiority of our proposed method over state-of-the-art artistic style transfer methods. </p>
<p><a href="http://arxiv.org/abs/2312.06135v1">PDF</a> Accepted by AAAI2024</p>
<p><strong>æ‘˜è¦</strong><br>è‰ºæœ¯åº“ï¼šä¸€ç§é€šè¿‡å¯è®­ç»ƒå‚æ•°çŸ©é˜µå­¦ä¹ è‰ºæœ¯çŸ¥è¯†å¹¶ä½œä¸ºè§†è§‰æç¤ºæŒ‡å¯¼æ¨¡å‹ç”Ÿæˆå†™å®è‰ºæœ¯é£æ ¼å›¾åƒçš„è‰ºæœ¯é£æ ¼è¿ç§»æ¡†æ¶ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>è‰ºæœ¯é£æ ¼è¿ç§»æ—¨åœ¨ç”¨ä¹ å¾—çš„è‰ºæœ¯é£æ ¼é‡æ–°ç»˜åˆ¶å†…å®¹å›¾åƒã€‚</li>
<li>ç°æœ‰è‰ºæœ¯é£æ ¼è¿ç§»æ–¹æ³•å¯åˆ†ä¸ºåŸºäºå°æ¨¡å‹å’ŒåŸºäºé¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹ä¸¤ç±»ã€‚</li>
<li>åŸºäºå°æ¨¡å‹çš„æ–¹æ³•å¯ä»¥ä¿ç•™å†…å®¹ç»“æ„ï¼Œä½†æ— æ³•ç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒï¼Œå¹¶å¼•å…¥ä¼ªå½±å’Œä¸å’Œè°çš„å›¾æ¡ˆï¼›åŸºäºé¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒï¼Œä½†éš¾ä»¥ä¿ç•™å†…å®¹ç»“æ„ã€‚</li>
<li>ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‰ºæœ¯é£æ ¼è¿ç§»æ¡†æ¶è‰ºæœ¯åº“ï¼Œä»¥åœ¨ä¿ç•™å†…å®¹å›¾åƒçš„å†…å®¹ç»“æ„çš„åŒæ—¶ç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒã€‚</li>
<li>ä¸ºäº†å……åˆ†æŒ–æ˜é¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹ä¸­åµŒå…¥çš„çŸ¥è¯†ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªéšå¼é£æ ¼æç¤ºåº“ï¼ˆISPBï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯è®­ç»ƒå‚æ•°çŸ©é˜µé›†ï¼Œç”¨äºå­¦ä¹ å’Œå­˜å‚¨è‰ºæœ¯å“é›†åˆä¸­çš„çŸ¥è¯†ï¼Œå¹¶ä½œä¸ºè§†è§‰æç¤ºæŒ‡å¯¼é¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹ç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒï¼ŒåŒæ—¶ä¿ç•™å†…å®¹ç»“æ„ã€‚</li>
<li>æ­¤å¤–ï¼Œä¸ºäº†åŠ é€Ÿä¸Šè¿° ISPB çš„è®­ç»ƒï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç©ºé—´ç»Ÿè®¡è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼ˆSSAMï¼‰ã€‚</li>
<li>å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„è‰ºæœ¯é£æ ¼è¿ç§»æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šArtBankï¼šé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹å’Œéšå¼é£æ ¼æç¤ºåº“çš„è‰ºæœ¯é£æ ¼è¿ç§»</li>
<li>ä½œè€…ï¼šZhanjie Zhang<em>, Quanwei Zhang</em>, Guangyuan Li, Wei Xingâ€ , Lei Zhaoâ€ , Jiakai Sun, Zehua Lan, Junsheng Luan, Yiling Huang, Huaizhong Linâ€ </li>
<li>å•ä½ï¼šæµ™æ±Ÿå¤§å­¦æ™ºèƒ½è§†è§‰å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šè‰ºæœ¯é£æ ¼è¿ç§»ã€é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ã€éšå¼é£æ ¼æç¤ºåº“</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.06135
   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/Jamie-Cheung/ArtBank</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè‰ºæœ¯é£æ ¼è¿ç§»æ—¨åœ¨å°†å­¦ä¹ åˆ°çš„é£æ ¼è¿ç§»åˆ°ä»»æ„å†…å®¹å›¾åƒä¸Šä»¥åˆ›å»ºæ–°çš„è‰ºæœ¯å›¾åƒã€‚ç°æœ‰çš„è‰ºæœ¯é£æ ¼è¿ç§»æ–¹æ³•å¯åˆ†ä¸ºåŸºäºå°æ¨¡å‹çš„æ–¹æ³•å’ŒåŸºäºé¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šåŸºäºå°æ¨¡å‹çš„æ–¹æ³•å¯ä»¥ä¿ç•™å†…å®¹ç»“æ„ï¼Œä½†æ— æ³•ç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒï¼Œå¹¶ä¸”ä¼šå¼•å…¥ä¼ªå½±å’Œä¸å’Œè°çš„å›¾æ¡ˆï¼›åŸºäºé¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒï¼Œä½†éš¾ä»¥ä¿ç•™å†…å®¹ç»“æ„ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§æ–°çš„è‰ºæœ¯é£æ ¼è¿ç§»æ¡†æ¶ ArtBankï¼Œä»¥ç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒï¼ŒåŒæ—¶ä¿ç•™å†…å®¹å›¾åƒçš„å†…å®¹ç»“æ„ã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†å……åˆ†æŒ–æ˜é¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹ä¸­åµŒå…¥çš„çŸ¥è¯†ï¼Œè®¾è®¡äº†ä¸€ä¸ªéšå¼é£æ ¼æç¤ºåº“ (ISPB)ï¼Œå®ƒæ˜¯ä¸€ç»„å¯è®­ç»ƒçš„å‚æ•°çŸ©é˜µï¼Œç”¨äºä»è‰ºæœ¯å“é›†ä¸­å­¦ä¹ å’Œå­˜å‚¨çŸ¥è¯†ï¼Œå¹¶ä½œä¸ºè§†è§‰æç¤ºæ¥æŒ‡å¯¼é¢„è®­ç»ƒçš„å¤§è§„æ¨¡æ¨¡å‹ç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒï¼ŒåŒæ—¶ä¿ç•™å†…å®¹ç»“æ„ã€‚æ­¤å¤–ï¼Œä¸ºäº†åŠ é€Ÿè®­ç»ƒä¸Šè¿° ISPBï¼Œæå‡ºäº†ä¸€ç§æ–°çš„åŸºäºç©ºé—´ç»Ÿè®¡çš„è‡ªæ³¨æ„åŠ›æ¨¡å— (SSAM)ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šå®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„è‰ºæœ¯é£æ ¼è¿ç§»æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) éšå¼é£æ ¼æç¤ºåº“ï¼ˆISPBï¼‰ï¼šISPB æ˜¯ä¸€ç»„å¯è®­ç»ƒçš„å‚æ•°çŸ©é˜µï¼Œç”¨äºä»è‰ºæœ¯å“é›†ä¸­å­¦ä¹ å’Œå­˜å‚¨çŸ¥è¯†ã€‚ISPB å¯ä»¥é€šè¿‡å†»ç»“é¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹çš„å‚æ•°å¹¶è®­ç»ƒ ISPB æ¥è·å¾—ã€‚
(2) ç©ºé—´ç»Ÿè®¡è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼ˆSSAMï¼‰ï¼šSSAM æ˜¯ä¸€ç§æ–°çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¯ä»¥åŠ é€Ÿ ISPB çš„è®­ç»ƒã€‚SSAM å¯ä»¥ä»ç©ºé—´å’Œç»Ÿè®¡çš„è§’åº¦å­¦ä¹ å’Œè¯„ä¼°å‚æ•°çŸ©é˜µçš„å˜åŒ–å€¼ã€‚
(3) è‰ºæœ¯é£æ ¼è¿ç§»æ¡†æ¶ï¼ˆArtBankï¼‰ï¼šArtBank æ˜¯ä¸€ä¸ªæ–°çš„è‰ºæœ¯é£æ ¼è¿ç§»æ¡†æ¶ï¼Œå®ƒåŒ…æ‹¬ä¸€ä¸ªä¸å¯è®­ç»ƒçš„éƒ¨åˆ†ï¼ˆé¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹ï¼‰å’Œä¸€ä¸ªå¯è®­ç»ƒçš„éƒ¨åˆ†ï¼ˆéšå¼é£æ ¼æç¤ºåº“ï¼‰ã€‚ArtBank å¯ä»¥é€šè¿‡å†»ç»“é¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹çš„å‚æ•°å¹¶è®­ç»ƒ ISPB æ¥è·å¾—ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‰ºæœ¯é£æ ¼è¿ç§»æ¡†æ¶ ArtBankï¼Œè¯¥æ¡†æ¶å¯ä»¥è§£å†³ä»é¢„è®­ç»ƒçš„å¤§è§„æ¨¡æ¨¡å‹ä¸­æŒ–æ˜çŸ¥è¯†çš„æŒ‘æˆ˜ï¼Œä»è€Œç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒï¼ŒåŒæ—¶ä¿ç•™å†…å®¹å›¾åƒçš„å†…å®¹ç»“æ„ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„éšå¼é£æ ¼æç¤ºåº“ï¼ˆISPBï¼‰ï¼Œè¯¥åº“å¯ä»¥ä»è‰ºæœ¯å“é›†ä¸­å­¦ä¹ å’Œå­˜å‚¨çŸ¥è¯†ï¼Œå¹¶ä½œä¸ºè§†è§‰æç¤ºæ¥æŒ‡å¯¼é¢„è®­ç»ƒçš„å¤§è§„æ¨¡æ¨¡å‹ç”Ÿæˆé«˜åº¦é€¼çœŸçš„é£æ ¼åŒ–å›¾åƒï¼ŒåŒæ—¶ä¿ç•™å†…å®¹ç»“æ„ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºç©ºé—´ç»Ÿè®¡çš„è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼ˆSSAMï¼‰ï¼Œè¯¥æ¨¡å—å¯ä»¥åŠ é€Ÿ ISPB çš„è®­ç»ƒã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è‰ºæœ¯é£æ ¼è¿ç§»æ¡†æ¶ ArtBankï¼Œè¯¥æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªä¸å¯è®­ç»ƒçš„éƒ¨åˆ†ï¼ˆé¢„è®­ç»ƒå¤§è§„æ¨¡æ¨¡å‹ï¼‰å’Œä¸€ä¸ªå¯è®­ç»ƒçš„éƒ¨åˆ†ï¼ˆéšå¼é£æ ¼æç¤ºåº“ï¼‰ã€‚
æ€§èƒ½ï¼š</li>
<li>å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„è‰ºæœ¯é£æ ¼è¿ç§»æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦è®­ç»ƒä¸€ä¸ªé¢„è®­ç»ƒçš„å¤§è§„æ¨¡æ¨¡å‹å’Œä¸€ä¸ªéšå¼é£æ ¼æç¤ºåº“ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-540d697ad9011eb3502589a451edc412.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-73cec781e9284cf52fa225a24e917388.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-15459584273510feb907035336d2f908.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c20a1ae8cef0cef555200bc6ee29aaa1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7812ebd2783d290dae9431dcaa43e169.jpg" align="middle">
</details>



]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF</title>
    <url>/2024/02/02/Paper/2024-02-02/NeRF/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-02-æ›´æ–°"><a href="#2024-02-02-æ›´æ–°" class="headerlink" title="2024-02-02 æ›´æ–°"></a>2024-02-02 æ›´æ–°</h1><h2 id="ViCA-NeRF-View-Consistency-Aware-3D-Editing-of-Neural-Radiance-Fields"><a href="#ViCA-NeRF-View-Consistency-Aware-3D-Editing-of-Neural-Radiance-Fields" class="headerlink" title="ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields"></a>ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields</h2><p><strong>Authors:Jiahua Dong, Yu-Xiong Wang</strong></p>
<p>We introduce ViCA-NeRF, the first view-consistency-aware method for 3D editing with text instructions. In addition to the implicit neural radiance field (NeRF) modeling, our key insight is to exploit two sources of regularization that explicitly propagate the editing information across different views, thus ensuring multi-view consistency. For geometric regularization, we leverage the depth information derived from NeRF to establish image correspondences between different views. For learned regularization, we align the latent codes in the 2D diffusion model between edited and unedited images, enabling us to edit key views and propagate the update throughout the entire scene. Incorporating these two strategies, our ViCA-NeRF operates in two stages. In the initial stage, we blend edits from different views to create a preliminary 3D edit. This is followed by a second stage of NeRF training, dedicated to further refining the sceneâ€™s appearance. Experimental results demonstrate that ViCA-NeRF provides more flexible, efficient (3 times faster) editing with higher levels of consistency and details, compared with the state of the art. Our code is publicly available. </p>
<p><a href="http://arxiv.org/abs/2402.00864v1">PDF</a> Neurips2023; project page: <a href="https://github.com/Dongjiahua/VICA-NeRF">https://github.com/Dongjiahua/VICA-NeRF</a></p>
<p><strong>Summary</strong><br>æ–‡æœ¬å¼•å…¥äº†ä¸€ç§æ–°çš„æ–¹æ³• ViCA-NeRFï¼Œè¯¥æ–¹æ³•å¯ä»¥åˆ©ç”¨æ–‡æœ¬ç¼–è¾‘è¿›è¡Œ 3D ç¼–è¾‘ï¼Œå¹¶ä½¿ç”¨å‡ ä½•å’Œå­¦ä¹ æ­£åˆ™åŒ–æ¥ç¡®ä¿ç¼–è¾‘çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ViCA-NeRF æ˜¯ä¸€ç§æ–°é¢–çš„åŸºäºæ–‡æœ¬çš„ 3D ç¼–è¾‘æ–¹æ³•ï¼Œåˆ©ç”¨ NeRF è¿›è¡Œéšå¼ç¥ç»è¾å°„åœºå»ºæ¨¡ã€‚</li>
<li>ViCA-NeRF çš„å…³é”®æ€æƒ³æ˜¯åˆ©ç”¨ä¸¤ç§æ­£åˆ™åŒ–æ¥æºï¼Œæ˜ç¡®åœ°åœ¨ä¸åŒè§†å›¾ä¹‹é—´ä¼ æ’­ç¼–è¾‘ä¿¡æ¯ï¼Œç¡®ä¿å¤šè§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>ViCA-NeRF åˆ©ç”¨ä» NeRF æ¨å¯¼å‡ºçš„æ·±åº¦ä¿¡æ¯æ¥å»ºç«‹ä¸åŒè§†å›¾ä¹‹é—´çš„å›¾åƒå¯¹åº”å…³ç³»ï¼Œç”¨äºå‡ ä½•æ­£åˆ™åŒ–ã€‚</li>
<li>ViCA-NeRF å¯¹ç»è¿‡ç¼–è¾‘å’Œæœªç»è¿‡ç¼–è¾‘çš„å›¾åƒåœ¨ 2D æ‰©æ•£æ¨¡å‹ä¸­çš„æ½œåœ¨ç¼–ç è¿›è¡Œå¯¹é½ï¼Œå®ç°ç¼–è¾‘å…³é”®è§†å›¾å¹¶æ›´æ–°æ•´ä¸ªåœºæ™¯ã€‚</li>
<li>ViCA-NeRF é‡‡ç”¨ä¸¤ä¸ªé˜¶æ®µçš„å·¥ä½œæµç¨‹ï¼Œç¬¬ä¸€é˜¶æ®µå°†æ¥è‡ªä¸åŒè§†å›¾çš„ç¼–è¾‘èåˆï¼Œåˆ›å»ºåˆæ­¥çš„ 3D ç¼–è¾‘ã€‚</li>
<li>ç¬¬äºŒé˜¶æ®µè¿›è¡Œ NeRF è®­ç»ƒï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–åœºæ™¯çš„å¤–è§‚ã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼ŒViCA-NeRF æä¾›æ›´çµæ´»ã€æ›´é«˜æ•ˆï¼ˆé€Ÿåº¦æå‡ 3 å€ï¼‰ã€æ›´ä¸€è‡´ä¸”æ›´è¯¦ç»†çš„ç¼–è¾‘ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šViCA-NeRFï¼šåŸºäºè§†å›¾ä¸€è‡´æ€§çš„ç¥ç»è¾å°„åœºä¸‰ç»´ç¼–è¾‘</li>
<li>ä½œè€…ï¼šJiahua Dong, Yu-Xiong Wang</li>
<li>å•ä½ï¼šä¼Šåˆ©è¯ºä¼Šå¤§å­¦å„å·´çº³-é¦™æ§Ÿåˆ†æ ¡</li>
<li>å…³é”®è¯ï¼šä¸‰ç»´ç¼–è¾‘ã€ç¥ç»è¾å°„åœºã€è§†å›¾ä¸€è‡´æ€§ã€æ–‡æœ¬æŒ‡ä»¤</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.00864
Github é“¾æ¥ï¼šhttps://dongjiahua.github.io/VICA-NeRF</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šéšç€ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åŠå…¶å˜ä½“çš„æœ€æ–°è¿›å±•ï¼Œæ”¶é›†çœŸå®ä¸–ç•Œä¸‰ç»´åœºæ™¯æ•°æ®å˜å¾—æ›´åŠ ä¾¿æ·ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä¸‰ç»´ç¼–è¾‘æ–¹æ³•é€šå¸¸ç¼ºä¹è§†å›¾ä¸€è‡´æ€§ï¼Œå¯¼è‡´ç¼–è¾‘ç»“æœåœ¨ä¸åŒè§†è§’ä¸‹å¯èƒ½å‡ºç°ä¸ä¸€è‡´çš„æƒ…å†µã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦åŒ…æ‹¬åŸºäºå‡ ä½•çš„æ­£åˆ™åŒ–å’ŒåŸºäºå­¦ä¹ çš„æ­£åˆ™åŒ–ã€‚å‡ ä½•æ­£åˆ™åŒ–åˆ©ç”¨ NeRF æå–çš„æ·±åº¦ä¿¡æ¯æ¥å»ºç«‹ä¸åŒè§†è§’ä¹‹é—´çš„å›¾åƒå¯¹åº”å…³ç³»ï¼Œä»è€Œç¡®ä¿è§†å›¾ä¸€è‡´æ€§ã€‚å­¦ä¹ æ­£åˆ™åŒ–åˆ™é€šè¿‡å¯¹ç¼–è¾‘å›¾åƒå’Œæœªç¼–è¾‘å›¾åƒçš„æ½œåœ¨ä»£ç è¿›è¡Œå¯¹é½ï¼Œä½¿ç¼–è¾‘ä¿¡æ¯èƒ½å¤Ÿåœ¨æ•´ä¸ªåœºæ™¯ä¸­ä¼ æ’­ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºçš„ ViCA-NeRF æ˜¯ä¸€ç§åŸºäºè§†å›¾ä¸€è‡´æ€§çš„ä¸‰ç»´ç¼–è¾‘æ–¹æ³•ï¼Œå®ƒç»“åˆäº†å‡ ä½•æ­£åˆ™åŒ–å’Œå­¦ä¹ æ­£åˆ™åŒ–ä¸¤ç§ç­–ç•¥ã€‚ViCA-NeRF é¦–å…ˆé€šè¿‡èåˆæ¥è‡ªä¸åŒè§†è§’çš„ç¼–è¾‘ç»“æœæ¥åˆ›å»ºåˆæ­¥çš„ä¸‰ç»´ç¼–è¾‘ï¼Œç„¶åé€šè¿‡ NeRF è®­ç»ƒè¿›ä¸€æ­¥ç»†åŒ–åœºæ™¯çš„å¤–è§‚ï¼Œä»è€Œç¡®ä¿è§†å›¾ä¸€è‡´æ€§å’Œç»†èŠ‚ä¸°å¯Œã€‚
(4)ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒViCA-NeRF æä¾›äº†æ›´åŠ çµæ´»ã€é«˜æ•ˆï¼ˆé€Ÿåº¦æé«˜ 3 å€ï¼‰çš„ç¼–è¾‘æ–¹å¼ï¼Œå¹¶ä¸”å…·æœ‰æ›´é«˜çš„è§†å›¾ä¸€è‡´æ€§å’Œç»†èŠ‚æ°´å¹³ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) ViCA-NeRF é¦–å…ˆä»ä¸åŒè§†è§’æ”¶é›†è¾“å…¥å›¾åƒï¼Œå¹¶ä½¿ç”¨ NeRF ä»è¿™äº›å›¾åƒä¸­æå–æ·±åº¦ä¿¡æ¯ã€‚
(2) ç„¶åï¼ŒViCA-NeRF åˆ©ç”¨æå–çš„æ·±åº¦ä¿¡æ¯æ¥å»ºç«‹ä¸åŒè§†è§’ä¹‹é—´çš„å›¾åƒå¯¹åº”å…³ç³»ï¼Œå¹¶ä½¿ç”¨è¿™äº›å¯¹åº”å…³ç³»æ¥èåˆæ¥è‡ªä¸åŒè§†è§’çš„ç¼–è¾‘ç»“æœï¼Œä»è€Œåˆ›å»ºåˆæ­¥çš„ä¸‰ç»´ç¼–è¾‘ã€‚
(3) æœ€åï¼ŒViCA-NeRF é€šè¿‡ NeRF è®­ç»ƒè¿›ä¸€æ­¥ç»†åŒ–åœºæ™¯çš„å¤–è§‚ï¼Œä»è€Œç¡®ä¿è§†å›¾ä¸€è‡´æ€§å’Œç»†èŠ‚ä¸°å¯Œã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† ViCA-NeRFï¼Œä¸€ç§åŸºäºè§†å›¾ä¸€è‡´æ€§çš„ä¸‰ç»´ç¼–è¾‘æ¡†æ¶ï¼Œç”¨äºæ–‡æœ¬å¼•å¯¼çš„ NeRF ç¼–è¾‘ã€‚ç»™å®šæ–‡æœ¬æŒ‡ä»¤ï¼Œæˆ‘ä»¬å¯ä»¥é«˜æ•ˆåœ°ç¼–è¾‘ NeRFã€‚é™¤äº†åƒäººç±»é£æ ¼åŒ–å’Œå¤©æ°”å˜åŒ–è¿™æ ·çš„ç®€å•ä»»åŠ¡å¤–ï¼Œæˆ‘ä»¬è¿˜æ”¯æŒä¸Šä¸‹æ–‡ç›¸å…³çš„æ“ä½œï¼Œä¾‹å¦‚â€œæ·»åŠ ä¸€äº›èŠ±æœµâ€å’Œç¼–è¾‘é«˜åº¦è¯¦ç»†çš„çº¹ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§åœºæ™¯å’Œæ–‡æœ¬æç¤ºä¸Šä¼˜äºå‡ ä¸ªåŸºçº¿ã€‚æœªæ¥ï¼Œæˆ‘ä»¬å°†ç»§ç»­æé«˜ä¸‰ç»´ç¼–è¾‘çš„å¯æ§æ€§å’ŒçœŸå®æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
ViCA-NeRF ç»“åˆäº†å‡ ä½•æ­£åˆ™åŒ–å’Œå­¦ä¹ æ­£åˆ™åŒ–ä¸¤ç§ç­–ç•¥ï¼Œä»¥ç¡®ä¿è§†å›¾ä¸€è‡´æ€§å’Œç»†èŠ‚ä¸°å¯Œã€‚
ViCA-NeRF åˆ©ç”¨æå–çš„æ·±åº¦ä¿¡æ¯æ¥å»ºç«‹ä¸åŒè§†è§’ä¹‹é—´çš„å›¾åƒå¯¹åº”å…³ç³»ï¼Œå¹¶ä½¿ç”¨è¿™äº›å¯¹åº”å…³ç³»æ¥èåˆæ¥è‡ªä¸åŒè§†è§’çš„ç¼–è¾‘ç»“æœï¼Œä»è€Œåˆ›å»ºåˆæ­¥çš„ä¸‰ç»´ç¼–è¾‘ã€‚
ViCA-NeRF é€šè¿‡ NeRF è®­ç»ƒè¿›ä¸€æ­¥ç»†åŒ–åœºæ™¯çš„å¤–è§‚ï¼Œä»è€Œç¡®ä¿è§†å›¾ä¸€è‡´æ€§å’Œç»†èŠ‚ä¸°å¯Œã€‚
æ€§èƒ½ï¼š
ViCA-NeRF åœ¨å„ç§åœºæ™¯å’Œæ–‡æœ¬æç¤ºä¸Šä¼˜äºå‡ ä¸ªåŸºçº¿ã€‚
ViCA-NeRF çš„é€Ÿåº¦æé«˜äº† 3 å€ã€‚
å·¥ä½œé‡ï¼š
ViCA-NeRF çš„å®ç°ç›¸å¯¹ç®€å•ã€‚
ViCA-NeRF çš„è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦è¾ƒå¿«ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b3cbdca659df3ac2eb7b2521752d1c8e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5c934d1ebae9f51cda700d605228196.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40418c9a6b8bcda24387d9b40ab2cd3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ff0299de61f2dcce94a6f84b195a4b3.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/02/02/Paper/2024-02-02/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-02-æ›´æ–°"><a href="#2024-02-02-æ›´æ–°" class="headerlink" title="2024-02-02 æ›´æ–°"></a>2024-02-02 æ›´æ–°</h1><h2 id="360-GS-Layout-guided-Panoramic-Gaussian-Splatting-For-Indoor-Roaming"><a href="#360-GS-Layout-guided-Panoramic-Gaussian-Splatting-For-Indoor-Roaming" class="headerlink" title="360-GS: Layout-guided Panoramic Gaussian Splatting For Indoor Roaming"></a>360-GS: Layout-guided Panoramic Gaussian Splatting For Indoor Roaming</h2><p><strong>Authors:Jiayang Bai, Letian Huang, Jie Guo, Wen Gong, Yuanqi Li, Yanwen Guo</strong></p>
<p>3D Gaussian Splatting (3D-GS) has recently attracted great attention with real-time and photo-realistic renderings. This technique typically takes perspective images as input and optimizes a set of 3D elliptical Gaussians by splatting them onto the image planes, resulting in 2D Gaussians. However, applying 3D-GS to panoramic inputs presents challenges in effectively modeling the projection onto the spherical surface of ${360^\circ}$ images using 2D Gaussians. In practical applications, input panoramas are often sparse, leading to unreliable initialization of 3D Gaussians and subsequent degradation of 3D-GS quality. In addition, due to the under-constrained geometry of texture-less planes (e.g., walls and floors), 3D-GS struggles to model these flat regions with elliptical Gaussians, resulting in significant floaters in novel views. To address these issues, we propose 360-GS, a novel $360^{\circ}$ Gaussian splatting for a limited set of panoramic inputs. Instead of splatting 3D Gaussians directly onto the spherical surface, 360-GS projects them onto the tangent plane of the unit sphere and then maps them to the spherical projections. This adaptation enables the representation of the projection using Gaussians. We guide the optimization of 360-GS by exploiting layout priors within panoramas, which are simple to obtain and contain strong structural information about the indoor scene. Our experimental results demonstrate that 360-GS allows panoramic rendering and outperforms state-of-the-art methods with fewer artifacts in novel view synthesis, thus providing immersive roaming in indoor scenarios. </p>
<p><a href="http://arxiv.org/abs/2402.00763v1">PDF</a> 11 pages, 10 figures</p>
<p><strong>Summary</strong><br>360-GS ä»¥å¹³é¢æŠ•å½±ä¸ºåŸºç¡€ï¼Œåˆ©ç”¨å¸ƒå±€å…ˆéªŒæ¥æŒ‡å¯¼ä¼˜åŒ–è¿‡ç¨‹ï¼Œä»è€Œäº§ç”Ÿå¯ç”¨äºæ¸²æŸ“å…¨æ™¯å’Œç”Ÿæˆæ–°è§†è§’å›¾åƒçš„ 3D æ¤­åœ†é«˜æ–¯åˆ†å¸ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D é«˜æ–¯æ–‘ç‚¹ (3D-GS) æ˜¯ä¸€ç§æµè¡Œçš„æŠ€æœ¯ï¼Œå®ƒé€šå¸¸å°†é€è§†å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶ä¼˜åŒ–ä¸€ç»„ 3D æ¤­åœ†é«˜æ–¯åˆ†å¸ƒï¼Œå°†å®ƒä»¬å–·å°„åˆ°å›¾åƒå¹³é¢ä¸Šï¼Œä»è€Œäº§ç”Ÿ 2D é«˜æ–¯åˆ†å¸ƒã€‚</li>
<li>ç„¶è€Œï¼Œå°† 3D-GS åº”ç”¨äºå…¨æ™¯è¾“å…¥æ—¶ï¼Œä½¿ç”¨ 2D é«˜æ–¯åˆ†å¸ƒå¯¹ ${360^\circ}$ å›¾åƒçš„çƒå½¢è¡¨é¢ä¸Šçš„æŠ•å½±è¿›è¡Œå»ºæ¨¡å­˜åœ¨æŒ‘æˆ˜ã€‚</li>
<li>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¾“å…¥å…¨æ™¯é€šå¸¸å¾ˆç¨€ç–ï¼Œå¯¼è‡´ 3D é«˜æ–¯åˆ†å¸ƒçš„åˆå§‹åŒ–ä¸å¯é ï¼Œéšå 3D-GS è´¨é‡ä¸‹é™ã€‚</li>
<li>æ­¤å¤–ï¼Œç”±äºçº¹ç†å¹³é¢ï¼ˆä¾‹å¦‚å¢™å£å’Œåœ°æ¿ï¼‰çš„å‡ ä½•å½¢çŠ¶å—é™ï¼Œ3D-GS éš¾ä»¥ä½¿ç”¨æ¤­åœ†é«˜æ–¯åˆ†å¸ƒå¯¹è¿™äº›å¹³å¦åŒºåŸŸè¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œå¯¼è‡´æ–°è§†å›¾ä¸­å‡ºç°æ˜æ˜¾çš„æ¼‚æµ®ç‰©ã€‚</li>
<li>ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† 360-GSï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹æœ‰é™æ•°é‡çš„å…¨æ™¯è¾“å…¥çš„æ–°å‹ $360^{\circ}$ é«˜æ–¯æ–‘ç‚¹ã€‚</li>
<li>360-GS ä¸å°† 3D é«˜æ–¯åˆ†å¸ƒç›´æ¥å–·å°„åˆ°çƒå½¢è¡¨é¢ä¸Šï¼Œè€Œæ˜¯å°†å…¶æŠ•å½±åˆ°å•ä½çƒçš„åˆ‡å¹³é¢ï¼Œç„¶åå°†å®ƒä»¬æ˜ å°„åˆ°çƒå½¢æŠ•å½±ã€‚è¿™ç§æ”¹ç¼–èƒ½å¤Ÿä½¿ç”¨é«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºæŠ•å½±ã€‚</li>
<li>æˆ‘ä»¬é€šè¿‡åˆ©ç”¨å…¨æ™¯ä¸­çš„å¸ƒå±€å…ˆéªŒæ¥æŒ‡å¯¼ 360-GS çš„ä¼˜åŒ–ï¼Œè¿™äº›å…ˆéªŒå¾ˆå®¹æ˜“è·å¾—ï¼Œå¹¶ä¸”åŒ…å«æœ‰å…³å®¤å†…åœºæ™¯çš„å¼ºå¤§ç»“æ„ä¿¡æ¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼š360-GSï¼šå¸ƒå±€å¼•å¯¼çš„å®¤å†…å…¨æ™¯é«˜æ–¯æ¸²æŸ“</li>
<li>ä½œè€…ï¼šJiayang Bai, Letian Huang, Jie Guo, Wen Gong, Yuanqi Li, Yanwen Guo</li>
<li>éš¶å±ï¼šå—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3Dé«˜æ–¯æ¸²æŸ“ã€å…¨æ™¯å›¾åƒã€å®¤å†…åœºæ™¯ã€å¸ƒå±€å¼•å¯¼</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.00763
   Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
   (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼š3Dé«˜æ–¯æ¸²æŸ“ï¼ˆ3D-GSï¼‰å› å…¶å®æ—¶æ€§å’Œç…§ç‰‡çº§æ¸²æŸ“æ•ˆæœè€Œå¤‡å—å…³æ³¨ã€‚è¯¥æŠ€æœ¯é€šå¸¸ä»¥é€è§†å›¾åƒä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡å°†ä¸€ç»„ 3D æ¤­åœ†é«˜æ–¯ä½“æ¸²æŸ“åˆ°å›¾åƒå¹³é¢ä¸Šï¼Œä»è€Œç”Ÿæˆ 2D é«˜æ–¯ä½“ã€‚ç„¶è€Œï¼Œå°† 3D-GS åº”ç”¨äºå…¨æ™¯è¾“å…¥æ—¶ï¼Œä½¿ç”¨ 2D é«˜æ–¯ä½“æœ‰æ•ˆå»ºæ¨¡ 360Â° å›¾åƒçš„çƒé¢æŠ•å½±å­˜åœ¨æŒ‘æˆ˜ã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¾“å…¥å…¨æ™¯å›¾åƒé€šå¸¸æ˜¯ç¨€ç–çš„ï¼Œå¯¼è‡´ 3D é«˜æ–¯ä½“çš„åˆå§‹åŒ–ä¸å¯é ï¼Œè¿›è€Œé™ä½ 3D-GS çš„è´¨é‡ã€‚æ­¤å¤–ï¼Œç”±äºç¼ºä¹çº¹ç†çš„å¹³é¢ï¼ˆä¾‹å¦‚å¢™å£å’Œåœ°æ¿ï¼‰çš„å‡ ä½•çº¦æŸä¸è¶³ï¼Œ3D-GS éš¾ä»¥ä½¿ç”¨æ¤­åœ†é«˜æ–¯ä½“å¯¹è¿™äº›å¹³é¢åŒºåŸŸè¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œå¯¼è‡´åœ¨æ–°çš„è§†è§’ä¸­å‡ºç°æ˜æ˜¾çš„æµ®åŠ¨ç‰©ä½“ã€‚
   (2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹æœ‰é™å…¨æ™¯è¾“å…¥çš„æ–°å‹ 360Â° é«˜æ–¯æ¸²æŸ“æ–¹æ³• 360-GSã€‚ä¸ç›´æ¥å°† 3D é«˜æ–¯ä½“æ¸²æŸ“åˆ°çƒé¢ä¸Šä¸åŒï¼Œ360-GS å°†å…¶æŠ•å½±åˆ°å•ä½çƒä½“çš„åˆ‡å¹³é¢ï¼Œç„¶åå°†å…¶æ˜ å°„åˆ°çƒé¢æŠ•å½±ã€‚è¿™ç§æ”¹è¿›ä½¿å¾—ä½¿ç”¨é«˜æ–¯ä½“è¡¨ç¤ºæŠ•å½±æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬é€šè¿‡åˆ©ç”¨å…¨æ™¯å›¾åƒä¸­çš„å¸ƒå±€å…ˆéªŒæ¥æŒ‡å¯¼ 360-GS çš„ä¼˜åŒ–ï¼Œè¿™äº›å…ˆéªŒæ˜“äºè·å–ï¼Œå¹¶ä¸”åŒ…å«æœ‰å…³å®¤å†…åœºæ™¯çš„å¼ºç»“æ„ä¿¡æ¯ã€‚
   (3)ï¼šæœ¬æ–‡çš„ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œ360-GS èƒ½å¤Ÿä»æœ‰é™æ•°é‡çš„å…¨æ™¯è¾“å…¥ä¸­ç”Ÿæˆé«˜è´¨é‡çš„å…¨æ™¯æ¸²æŸ“ã€‚ä¸ 3D-GS ç›¸æ¯”ï¼Œ360-GS åœ¨å‡†ç¡®æ€§ã€ç»†èŠ‚å’Œé²æ£’æ€§æ–¹é¢å‡è¡¨ç°å‡ºä¼˜åŠ¿ã€‚
   (4)ï¼šæ–¹æ³•çš„æ€§èƒ½åŠå…¶å¯¹ç›®æ ‡çš„æ”¯æŒï¼š360-GS åœ¨å®¤å†…åœºæ™¯æ¸²æŸ“ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚ä¸ 3D-GS ç›¸æ¯”ï¼Œ360-GS åœ¨å‡†ç¡®æ€§ã€ç»†èŠ‚å’Œé²æ£’æ€§æ–¹é¢å‡è¡¨ç°å‡ºä¼˜åŠ¿ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œ360-GS èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å¸ƒå±€å…ˆéªŒæ¥æŒ‡å¯¼ 3D é«˜æ–¯ä½“çš„ä¼˜åŒ–ï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡çš„å…¨æ™¯æ¸²æŸ“ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1)ï¼š360â—¦é«˜æ–¯ä½“é•¶åµŒï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„ splatting æŠ€æœ¯ï¼Œå°† splatting åˆ†è§£ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼šåœ¨å•ä½çƒä½“çš„åˆ‡å¹³é¢ä¸Š splatting å’Œæ˜ å°„åˆ°çƒé¢ã€‚
(2)ï¼šå¸ƒå±€å¼•å¯¼åˆå§‹åŒ–å’Œæ­£åˆ™åŒ–ï¼šåˆ©ç”¨å…¨æ™¯å›¾åƒä¸­çš„å¸ƒå±€å…ˆéªŒæ¥æŒ‡å¯¼ 3D é«˜æ–¯ä½“çš„ä¼˜åŒ–ï¼Œè¿™äº›å…ˆéªŒæ˜“äºè·å–ï¼Œå¹¶ä¸”åŒ…å«æœ‰å…³å®¤å†…åœºæ™¯çš„å¼ºç»“æ„ä¿¡æ¯ã€‚
(3)ï¼šå…¨æ™¯æ¸²æŸ“ï¼šé€šè¿‡å°† splattered çš„é«˜æ–¯ä½“ä»å‰åˆ°åè¿›è¡Œ alpha æ··åˆï¼Œå¯ä»¥ç”Ÿæˆå…¨æ™¯æ¸²æŸ“ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¸ƒå±€å¼•å¯¼å…¨æ™¯é«˜æ–¯æ¸²æŸ“æµæ°´çº¿ï¼Œåä¸º360-GSï¼Œå®ƒæ”¯æŒç›´æ¥å…¨æ™¯æ¸²æŸ“ï¼Œå¹¶ä¸”å¯¹ç¨€ç–è¾“å…¥å…·æœ‰é²æ£’æ€§ã€‚360-GSçš„åŸºçŸ³æ˜¯æˆ‘ä»¬çš„360â—¦é«˜æ–¯ splatting ç®—æ³•ä»¥åŠæˆ¿é—´å¸ƒå±€å…ˆéªŒçš„ç»“åˆã€‚360â—¦é«˜æ–¯ splatting ç®—æ³•é€šè¿‡åˆ©ç”¨é€è§†æŠ•å½±å’Œæ˜ å°„æ¥è§£å†³åœ¨çƒé¢è¡¨é¢å»ºæ¨¡æŠ•å½±çš„æŒ‘æˆ˜ï¼Œä»è€Œå®ç°å¯¹å…·æœ‰ç­‰è·çŸ©å½¢å›¾åƒçš„ 3D é«˜æ–¯çš„ç›´æ¥ä¼˜åŒ–ã€‚æˆ‘ä»¬åœ¨ 3D é«˜æ–¯çš„åˆå§‹åŒ–è¿‡ç¨‹ä¸­åˆ©ç”¨å…¨æ™¯å›¾ä¸­çš„æˆ¿é—´å¸ƒå±€å…ˆéªŒï¼Œæä¾›äº†ä¸€ç§æ›´æ˜“äºè®¿é—®ä¸”é²æ£’çš„æ›¿ä»£æ–¹æ¡ˆæ¥æ›¿ä»£ SfM ç‚¹äº‘ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†å¸ƒå±€å¼•å¯¼æ­£åˆ™åŒ–æ¥å‡è½»æµ®åŠ¨é—®é¢˜å¹¶ä¿ç•™æˆ¿é—´å¸ƒå±€çš„å‡ ä½•ç»“æ„ã€‚360-GS æ”¯æŒå®æ—¶æ¼«æ¸¸ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­ä¸ºæ–°é¢–è§†è§’åˆæˆæä¾›äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„ 360â—¦é«˜æ–¯ splatting ç®—æ³•ï¼Œè¯¥ç®—æ³•å°† splatting åˆ†è§£ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼šåœ¨å•ä½çƒä½“çš„åˆ‡å¹³é¢ä¸Š splatting å’Œæ˜ å°„åˆ°çƒé¢ã€‚</li>
<li>åˆ©ç”¨å…¨æ™¯å›¾åƒä¸­çš„å¸ƒå±€å…ˆéªŒæ¥æŒ‡å¯¼ 3D é«˜æ–¯çš„ä¼˜åŒ–ï¼Œè¿™äº›å…ˆéªŒæ˜“äºè·å–ï¼Œå¹¶ä¸”åŒ…å«æœ‰å…³å®¤å†…åœºæ™¯çš„å¼ºç»“æ„ä¿¡æ¯ã€‚</li>
<li>å¼•å…¥äº†å¸ƒå±€å¼•å¯¼æ­£åˆ™åŒ–æ¥å‡è½»æµ®åŠ¨é—®é¢˜å¹¶ä¿ç•™æˆ¿é—´å¸ƒå±€çš„å‡ ä½•ç»“æ„ã€‚
æ€§èƒ½ï¼š</li>
<li>ä¸ 3D-GS ç›¸æ¯”ï¼Œ360-GS åœ¨å‡†ç¡®æ€§ã€ç»†èŠ‚å’Œé²æ£’æ€§æ–¹é¢å‡è¡¨ç°å‡ºä¼˜åŠ¿ã€‚</li>
<li>360-GS åœ¨å®¤å†…åœºæ™¯æ¸²æŸ“ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦æ”¶é›†å’Œé¢„å¤„ç†å…¨æ™¯å›¾åƒã€‚</li>
<li>éœ€è¦ä¼˜åŒ– 3D é«˜æ–¯çš„å‚æ•°ã€‚</li>
<li>éœ€è¦å°† splattered çš„é«˜æ–¯ä½“ä»å‰åˆ°åè¿›è¡Œ alpha æ··åˆä»¥ç”Ÿæˆå…¨æ™¯æ¸²æŸ“ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-38c0a2fd61f19043e9f57d34dec4a1c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9fe5198d06678b334414f192b0c83aa8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e4e5570dfa99dfac9b297f7650c717c3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f5349fc8a22abb33ba9a2c7388b0a826.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1d8e3eade9a3d6331e76dbab98e15a68.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffe9d7162c03cd614dfd0b6e7509adbd.jpg" align="middle">
</details>




<h2 id="CoSSegGaussians-Compact-and-Swift-Scene-Segmenting-3D-Gaussians-with-Dual-Feature-Fusion"><a href="#CoSSegGaussians-Compact-and-Swift-Scene-Segmenting-3D-Gaussians-with-Dual-Feature-Fusion" class="headerlink" title="CoSSegGaussians: Compact and Swift Scene Segmenting 3D Gaussians with   Dual Feature Fusion"></a>CoSSegGaussians: Compact and Swift Scene Segmenting 3D Gaussians with   Dual Feature Fusion</h2><p><strong>Authors:Bin Dou, Tianyu Zhang, Yongjia Ma, Zhaohui Wang, Zejian Yuan</strong></p>
<p>We propose Compact and Swift Segmenting 3D Gaussians(CoSSegGaussians), a method for compact 3D-consistent scene segmentation at fast rendering speed with only RGB images input. Previous NeRF-based segmentation methods have relied on time-consuming neural scene optimization. While recent 3D Gaussian Splatting has notably improved speed, existing Gaussian-based segmentation methods struggle to produce compact masks, especially in zero-shot segmentation. This issue probably stems from their straightforward assignment of learnable parameters to each Gaussian, resulting in a lack of robustness against cross-view inconsistent 2D machine-generated labels. Our method aims to address this problem by employing Dual Feature Fusion Network as Gaussiansâ€™ segmentation field. Specifically, we first optimize 3D Gaussians under RGB supervision. After Gaussian Locating, DINO features extracted from images are applied through explicit unprojection, which are further incorporated with spatial features from the efficient point cloud processing network. Feature aggregation is utilized to fuse them in a global-to-local strategy for compact segmentation features. Experimental results show that our model outperforms baselines on both semantic and panoptic zero-shot segmentation task, meanwhile consumes less than 10% inference time compared to NeRF-based methods. Code and more results will be available at <a href="https://David-Dou.github.io/CoSSegGaussians">https://David-Dou.github.io/CoSSegGaussians</a> </p>
<p><a href="http://arxiv.org/abs/2401.05925v3">PDF</a> 9 pages, 8 figures, correct writing details</p>
<p><strong>æ‘˜è¦</strong><br>ç»“åˆç‚¹äº‘ä¸æ˜¾å¼åæŠ•å°„çš„ç‰¹å¾èåˆç½‘ç»œï¼Œå®ç°ç´§å‡‘è€Œå¿«é€Ÿçš„ 3D é«˜æ–¯æ··åˆåˆ†å‰²ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºä¸€ç§ç”¨äºç´§å‡‘ã€å¿«é€Ÿä¸”ä»…ä»¥RGBå›¾åƒä½œä¸ºè¾“å…¥çš„3Dåœºæ™¯ä¸€è‡´æ€§åˆ†å‰²æ–¹æ³•ï¼šç´§å‡‘å¿«é€Ÿåˆ†å‰²3Dé«˜æ–¯ï¼ˆCoSSegGaussiansï¼‰ã€‚</li>
<li>ç°æœ‰çš„åŸºäºé«˜æ–¯ä½“ç´ çš„åˆ†å‰²æ–¹æ³•åœ¨è¿›è¡Œé›¶é•œå¤´åˆ†å‰²æ—¶éš¾ä»¥ç”Ÿæˆç´§å‡‘çš„æ©æ¨¡ï¼Œè¿™å¯èƒ½æ˜¯å› ä¸ºå®ƒä»¬å°†å¯å­¦ä¹ çš„å‚æ•°ç›´æ¥åˆ†é…ç»™æ¯ä¸ªé«˜æ–¯ä½“ç´ ï¼Œä»è€Œå¯¼è‡´ç¼ºä¹å¯¹è·¨è§†å›¾ä¸ä¸€è‡´çš„2Dæœºå™¨ç”Ÿæˆçš„æ ‡ç­¾çš„é²æ£’æ€§ã€‚</li>
<li>åˆ©ç”¨åŒç‰¹å¾èåˆç½‘ç»œä½œä¸ºé«˜æ–¯ä½“ç´ çš„åˆ†å‰²å­—æ®µæ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>é¦–å…ˆåœ¨RGBç›‘ç£ä¸‹ä¼˜åŒ–3Dé«˜æ–¯ä½“ç´ ã€‚</li>
<li>ç„¶åé€šè¿‡æ˜¾å¼åæŠ•å½±åº”ç”¨ä»å›¾åƒä¸­æå–çš„DINOç‰¹å¾ï¼Œå¹¶ç»“åˆæ¥è‡ªæœ‰æ•ˆç‚¹äº‘å¤„ç†ç½‘ç»œçš„ç©ºé—´ç‰¹å¾ã€‚</li>
<li>åˆ©ç”¨ç‰¹å¾èšåˆåœ¨å…¨å±€åˆ°å±€éƒ¨çš„ç­–ç•¥ä¸­èåˆè¿™äº›ç‰¹å¾ä»¥å®ç°ç´§å‡‘çš„åˆ†å‰²ç‰¹å¾ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œä¸NeRFä¸ºåŸºç¡€çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹åœ¨è¯­ä¹‰åˆ†å‰²å’Œå…¨æ™¯é›¶é•œå¤´åˆ†å‰²ä»»åŠ¡ä¸Šéƒ½ä¼˜äºåŸºçº¿ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´å°‘äº10%ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šç´§å‡‘è€Œå¿«é€Ÿçš„åœºæ™¯åˆ†å‰² 3D é«˜æ–¯ä½“ä¸åŒé‡ç‰¹å¾èåˆ</li>
<li>ä½œè€…ï¼šDou Bin, Zhang Tianyu, Ma Yongjia, Wang Zhaohui, Yuan Zejian</li>
<li>å•ä½ï¼šè¥¿å®‰äº¤é€šå¤§å­¦äººå·¥æ™ºèƒ½ä¸æœºå™¨äººå­¦é™¢</li>
<li>å…³é”®è¯ï¼š3D åœºæ™¯åˆ†å‰²ã€ç¥ç»è¾å°„åœºã€é«˜æ–¯ä½“ã€åŒé‡ç‰¹å¾èåˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.05925ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼Œè®¡ç®—æœºè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦å–å¾—äº†æ˜¾ç€è¿›å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¥ç»æ¸²æŸ“é¢†åŸŸã€‚ç¥ç»è¾å°„åœº (NeRF) åŠå…¶åç»­æ–¹æ³•æ¨åŠ¨äº†ç¥ç»åœºæ™¯è¡¨ç¤ºçš„å‘å±•ï¼Œåœ¨æ–°å‹è§†å›¾åˆæˆæ–¹é¢æ˜¾ç¤ºå‡ºæ˜¾ç€çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šåŸºäº NeRF çš„åˆ†å‰²æ–¹æ³•ä¾èµ–äºè€—æ—¶çš„ç¥ç»åœºæ™¯ä¼˜åŒ–ã€‚è™½ç„¶æœ€è¿‘çš„ 3D é«˜æ–¯ä½“ splatting æ˜¾ç€æé«˜äº†é€Ÿåº¦ï¼Œä½†ç°æœ‰çš„åŸºäºé«˜æ–¯ä½“çš„åˆ†å‰²æ–¹æ³•éš¾ä»¥äº§ç”Ÿç´§å‡‘çš„æ©æ¨¡ï¼Œå°¤å…¶æ˜¯åœ¨é›¶æ ·æœ¬åˆ†å‰²ä¸­ã€‚è¿™ä¸ªé—®é¢˜å¯èƒ½æºäºå…¶ç›´æ¥å°†å¯å­¦ä¹ å‚æ•°åˆ†é…ç»™æ¯ä¸ªé«˜æ–¯ä½“ï¼Œå¯¼è‡´å¯¹è·¨è§†å›¾ä¸ä¸€è‡´çš„ 2D æœºå™¨ç”Ÿæˆçš„æ ‡ç­¾ç¼ºä¹é²æ£’æ€§ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç´§å‡‘è€Œå¿«é€Ÿçš„åœºæ™¯åˆ†å‰²æ–¹æ³•ï¼Œç§°ä¸º CoSSegGaussiansï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨ RGB å›¾åƒè¾“å…¥å³å¯å®ç°ç´§å‡‘çš„ 3D ä¸€è‡´åœºæ™¯åˆ†å‰²ï¼Œä¸”æ¸²æŸ“é€Ÿåº¦å¿«ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨ RGB ç›‘ç£ä¸‹ä¼˜åŒ– 3D é«˜æ–¯ä½“ã€‚åœ¨é«˜æ–¯ä½“å®šä½ä¹‹åï¼Œé€šè¿‡æ˜¾å¼åæŠ•å½±åº”ç”¨ä»å›¾åƒä¸­æå–çš„ DINO ç‰¹å¾ï¼Œç„¶åå°†å…¶ä¸æ¥è‡ªé«˜æ•ˆç‚¹äº‘å¤„ç†ç½‘ç»œçš„ç©ºé—´ç‰¹å¾ç»“åˆã€‚åˆ©ç”¨ç‰¹å¾èšåˆåœ¨å…¨å±€åˆ°å±€éƒ¨ç­–ç•¥ä¸­èåˆå®ƒä»¬ä»¥è·å¾—ç´§å‡‘çš„åˆ†å‰²ç‰¹å¾ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨è¯­ä¹‰å’Œå…¨æ™¯é›¶æ ·æœ¬åˆ†å‰²ä»»åŠ¡ä¸Šéƒ½ä¼˜äºåŸºçº¿æ–¹æ³•ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´ä¸åˆ°åŸºäº NeRF çš„æ–¹æ³•çš„ 10%ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰é«˜æ–¯ä½“å®šä½é˜¶æ®µï¼šä½¿ç”¨ L1 å’Œ L_D-SSIM å…‰åº¦æŸå¤±æ¥ç›‘ç£é«˜æ–¯ä½“çš„å‡ ä½•ä¿¡æ¯ï¼ŒåŒ…æ‹¬è´¨å¿ƒã€åæ–¹å·®ã€ä¸é€æ˜åº¦å’Œé¢œè‰²ã€‚
ï¼ˆ2ï¼‰åˆ†å‰²é˜¶æ®µï¼šå°†å¤šå°ºåº¦çš„ DINO ç‰¹å¾åæŠ•å½±åˆ°é«˜æ–¯ä½“ä¸Šï¼Œå¹¶ä¸ä»é«˜æ–¯ä½“ä¸­æå–çš„ç©ºé—´ç‰¹å¾èåˆã€‚
ï¼ˆ3ï¼‰ç‰¹å¾èšåˆï¼šä½¿ç”¨å…¨å±€åˆ°å±€éƒ¨ç­–ç•¥èšåˆèåˆåçš„ç‰¹å¾ï¼Œä»¥ç”Ÿæˆç´§å‡‘çš„åˆ†å‰²ç‰¹å¾ã€‚
ï¼ˆ4ï¼‰ç›‘ç£ï¼šä½¿ç”¨é›¶æ ·æœ¬åˆ†å‰²æ©æ¨¡å’Œå…³è”æ©æ¨¡æ¥ç›‘ç£åˆ†å‰²å‚æ•°ï¼Œå¹¶ä½¿ç”¨ NCE æŸå¤±è¿›è¡Œä¼˜åŒ–ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç´§å‡‘è€Œå¿«é€Ÿçš„åœºæ™¯åˆ†å‰²æ–¹æ³• CoSSegGaussiansï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨ RGB å›¾åƒè¾“å…¥å³å¯å®ç°ç´§å‡‘çš„ 3D ä¸€è‡´åœºæ™¯åˆ†å‰²ï¼Œä¸”æ¸²æŸ“é€Ÿåº¦å¿«ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨è¯­ä¹‰å’Œå…¨æ™¯é›¶æ ·æœ¬åˆ†å‰²ä»»åŠ¡ä¸Šéƒ½ä¼˜äºåŸºçº¿æ–¹æ³•ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´ä¸åˆ°åŸºäº NeRF çš„æ–¹æ³•çš„ 10%ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§ç´§å‡‘è€Œå¿«é€Ÿçš„åœºæ™¯åˆ†å‰²æ–¹æ³• CoSSegGaussiansï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨ RGB å›¾åƒè¾“å…¥å³å¯å®ç°ç´§å‡‘çš„ 3D ä¸€è‡´åœºæ™¯åˆ†å‰²ï¼Œä¸”æ¸²æŸ“é€Ÿåº¦å¿«ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŒé‡ç‰¹å¾èåˆç½‘ç»œä½œä¸ºåˆ†å‰²åœºï¼Œè¯¥ç½‘ç»œèšåˆäº† DINO å’Œç©ºé—´ç‰¹å¾ç”¨äºåˆ†å‰²ã€‚</li>
<li>å°†å¤šå°ºåº¦çš„ DINO ç‰¹å¾ä»å›¾åƒåæŠ•å½±åˆ°å®šä½çš„ 3D é«˜æ–¯ä½“ä¸Šï¼Œå¹¶è¿›ä¸€æ­¥ä¸é«˜æ–¯ä½“çš„ç©ºé—´ä¿¡æ¯ç›¸ç»“åˆã€‚</li>
<li>åº”ç”¨å…¨å±€åˆ°å±€éƒ¨èšåˆæ¨¡å—ç”Ÿæˆç´§å‡‘çš„åˆ†å‰²é€»è¾‘ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è¯­ä¹‰å’Œå…¨æ™¯é›¶æ ·æœ¬åˆ†å‰²ä»»åŠ¡ä¸Šéƒ½ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
<li>æ¨ç†æ—¶é—´ä¸åˆ°åŸºäº NeRF çš„æ–¹æ³•çš„ 10%ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ä½¿ç”¨äº†å¤§é‡çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ã€‚</li>
<li>ç®—æ³•çš„å®ç°å’Œè®­ç»ƒè¿‡ç¨‹è¾ƒä¸ºå¤æ‚ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ecce62ef2d2a0a0c5d6577de6d7cb33f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-222c4f05c24f306aefd909de021e726c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6dff94133ac5b0802b5de3fb9550eff1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e96a03193e246ab9e77a3dd6aa18e239.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f381d5614322d380f003e54e659eb10.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb6b0eeec85fc1d0f2cd12928b40918f.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/02/02/Paper/2024-02-02/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-02-æ›´æ–°"><a href="#2024-02-02-æ›´æ–°" class="headerlink" title="2024-02-02 æ›´æ–°"></a>2024-02-02 æ›´æ–°</h1><h2 id="ViCA-NeRF-View-Consistency-Aware-3D-Editing-of-Neural-Radiance-Fields"><a href="#ViCA-NeRF-View-Consistency-Aware-3D-Editing-of-Neural-Radiance-Fields" class="headerlink" title="ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields"></a>ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields</h2><p><strong>Authors:Jiahua Dong, Yu-Xiong Wang</strong></p>
<p>We introduce ViCA-NeRF, the first view-consistency-aware method for 3D editing with text instructions. In addition to the implicit neural radiance field (NeRF) modeling, our key insight is to exploit two sources of regularization that explicitly propagate the editing information across different views, thus ensuring multi-view consistency. For geometric regularization, we leverage the depth information derived from NeRF to establish image correspondences between different views. For learned regularization, we align the latent codes in the 2D diffusion model between edited and unedited images, enabling us to edit key views and propagate the update throughout the entire scene. Incorporating these two strategies, our ViCA-NeRF operates in two stages. In the initial stage, we blend edits from different views to create a preliminary 3D edit. This is followed by a second stage of NeRF training, dedicated to further refining the sceneâ€™s appearance. Experimental results demonstrate that ViCA-NeRF provides more flexible, efficient (3 times faster) editing with higher levels of consistency and details, compared with the state of the art. Our code is publicly available. </p>
<p><a href="http://arxiv.org/abs/2402.00864v1">PDF</a> Neurips2023; project page: <a href="https://github.com/Dongjiahua/VICA-NeRF">https://github.com/Dongjiahua/VICA-NeRF</a></p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨æ·±åº¦ä¿¡æ¯å’Œæ‰©æ•£æ¨¡å‹ï¼ŒViCA-NeRF å®ç°äº†å¤šè§†å›¾ä¸€è‡´æ€§ï¼Œå¯ä»¥é«˜æ•ˆåœ°ç¼–è¾‘ 3D åœºæ™¯ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>ViCA-NeRF æ˜¯ä¸€ç§åˆ©ç”¨æ·±åº¦ä¿¡æ¯å’Œæ‰©æ•£æ¨¡å‹æ¥å®ç°å¤šè§†å›¾ä¸€è‡´æ€§çš„ 3D ç¼–è¾‘æ–¹æ³•ã€‚</li>
<li>ViCA-NeRF åœ¨ NeRF å»ºæ¨¡çš„åŸºç¡€ä¸Šï¼Œåˆ©ç”¨æ·±åº¦ä¿¡æ¯æ¨æ–­ä¸åŒè§†è§’çš„å›¾åƒå¯¹åº”å…³ç³»ï¼Œä»¥å®ç°å‡ ä½•æ­£åˆ™åŒ–ã€‚</li>
<li>ViCA-NeRF åˆ©ç”¨ 2D æ‰©æ•£æ¨¡å‹å¯¹ç¼–è¾‘å›¾åƒå’Œæœªç¼–è¾‘å›¾åƒçš„æ½œåœ¨ç¼–ç è¿›è¡Œå¯¹é½ï¼Œä»¥å®ç°å­¦ä¹ æ­£åˆ™åŒ–ã€‚</li>
<li>ViCA-NeRF ç”±ä¸¤ä¸ªé˜¶æ®µç»„æˆï¼šç¬¬ä¸€é˜¶æ®µèåˆæ¥è‡ªä¸åŒè§†è§’çš„ç¼–è¾‘ï¼Œåˆ›å»ºåˆæ­¥çš„ 3D ç¼–è¾‘ï¼›ç¬¬äºŒé˜¶æ®µå¯¹ NeRF è¿›è¡Œè®­ç»ƒï¼Œä»¥è¿›ä¸€æ­¥ç»†åŒ–åœºæ™¯å¤–è§‚ã€‚</li>
<li>ViCA-NeRF æ¯”ç°æœ‰æ–¹æ³•æä¾›äº†æ›´çµæ´»ã€æ›´é«˜æ•ˆï¼ˆé€Ÿåº¦æé«˜ 3 å€ï¼‰çš„ç¼–è¾‘ï¼Œå¹¶å…·æœ‰æ›´é«˜çš„å±‚æ¬¡ä¸€è‡´æ€§å’Œç»†èŠ‚ã€‚</li>
<li>ViCA-NeRF çš„ä»£ç å·²å…¬å¼€ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šViCA-NeRFï¼šåŸºäºè§†å›¾ä¸€è‡´æ€§çš„ç¥ç»è¾å°„åœº 3D ç¼–è¾‘</li>
<li>ä½œè€…ï¼šJiahua Dong, Yu-Xiong Wang</li>
<li>å•ä½ï¼šä¼Šåˆ©è¯ºä¼Šå¤§å­¦å„å·´çº³-é¦™æ§Ÿåˆ†æ ¡</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€3D ç¼–è¾‘ã€æ–‡æœ¬æŒ‡ä»¤ã€è§†å›¾ä¸€è‡´æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.00864
   Github é“¾æ¥ï¼šNone</li>
<li>
<p>æ€»ç»“ï¼š
(1)ï¼šéšç€ç¥ç»è¾å°„åœº (NeRF) ç­‰ 3D é‡å»ºæŠ€æœ¯çš„è¿›æ­¥ï¼Œæ”¶é›†çœŸå®ä¸–ç•Œ 3D åœºæ™¯å˜å¾—æ›´åŠ ä¾¿æ·ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨ 3D åœºæ™¯ç¼–è¾‘æ–¹é¢è¿˜å­˜åœ¨è¯¸å¤šå±€é™ã€‚
(2)ï¼šä»¥å¾€æ–¹æ³•é€šå¸¸ä½¿ç”¨éšå¼ç¥ç»è¾å°„åœºè¿›è¡Œå»ºæ¨¡ï¼Œä½†ç¼ºä¹å¯¹ä¸åŒè§†å›¾ä¹‹é—´ç¼–è¾‘ä¿¡æ¯ä¼ æ’­çš„æ˜¾å¼çº¦æŸï¼Œå¯¼è‡´ç¼–è¾‘ç»“æœå¯èƒ½å‡ºç°è§†å›¾ä¸ä¸€è‡´çš„é—®é¢˜ã€‚
(3)ï¼šæœ¬æ–‡æå‡º ViCA-NeRFï¼Œä¸€ç§åŸºäºè§†å›¾ä¸€è‡´æ€§çš„ 3D ç¼–è¾‘æ–¹æ³•ã€‚ViCA-NeRF åˆ©ç”¨å‡ ä½•å’Œå­¦ä¹ æ­£åˆ™åŒ–ä¸¤ç§ç­–ç•¥æ¥ç¡®ä¿ä¸åŒè§†å›¾ä¹‹é—´çš„ç¼–è¾‘ä¸€è‡´æ€§ã€‚å‡ ä½•æ­£åˆ™åŒ–åˆ©ç”¨ NeRF æå–çš„æ·±åº¦ä¿¡æ¯å»ºç«‹ä¸åŒè§†å›¾ä¹‹é—´çš„å›¾åƒå¯¹åº”å…³ç³»ï¼Œå­¦ä¹ æ­£åˆ™åŒ–åˆ™å¯¹ç¼–è¾‘å›¾åƒå’Œæœªç¼–è¾‘å›¾åƒåœ¨ 2D æ‰©æ•£æ¨¡å‹ä¸­çš„æ½œåœ¨ç¼–ç è¿›è¡Œå¯¹é½ï¼Œä»è€Œå®ç°å…³é”®è§†å›¾çš„ç¼–è¾‘å¹¶å°†å…¶ä¼ æ’­åˆ°æ•´ä¸ªåœºæ™¯ã€‚
(4)ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒViCA-NeRF èƒ½å¤Ÿæä¾›æ›´åŠ çµæ´»ã€é«˜æ•ˆï¼ˆé€Ÿåº¦æé«˜ 3 å€ï¼‰ã€ä¸€è‡´æ€§å’Œç»†èŠ‚æ›´ä½³çš„ç¼–è¾‘æ•ˆæœã€‚</p>
</li>
<li>
<p>Methodsï¼š
(1)ï¼šViCA-NeRFæ˜¯ä¸€ç§åŸºäºè§†å›¾ä¸€è‡´æ€§çš„3Dç¼–è¾‘æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨å‡ ä½•å’Œå­¦ä¹ æ­£åˆ™åŒ–ä¸¤ç§ç­–ç•¥æ¥ç¡®ä¿ä¸åŒè§†å›¾ä¹‹é—´çš„ç¼–è¾‘ä¸€è‡´æ€§ã€‚
(2)ï¼šå‡ ä½•æ­£åˆ™åŒ–åˆ©ç”¨NeRFæå–çš„æ·±åº¦ä¿¡æ¯å»ºç«‹ä¸åŒè§†å›¾ä¹‹é—´çš„å›¾åƒå¯¹åº”å…³ç³»ï¼Œä»è€Œå°†ç¼–è¾‘ä¿¡æ¯ä»å…³é”®è§†å›¾ä¼ æ’­åˆ°æ•´ä¸ªåœºæ™¯ã€‚
(3)ï¼šå­¦ä¹ æ­£åˆ™åŒ–å¯¹ç¼–è¾‘å›¾åƒå’Œæœªç¼–è¾‘å›¾åƒåœ¨2Dæ‰©æ•£æ¨¡å‹ä¸­çš„æ½œåœ¨ç¼–ç è¿›è¡Œå¯¹é½ï¼Œä»è€Œå®ç°å…³é”®è§†å›¾çš„ç¼–è¾‘å¹¶å°†å…¶ä¼ æ’­åˆ°æ•´ä¸ªåœºæ™¯ã€‚
(4)ï¼šViCA-NeRFèƒ½å¤Ÿæä¾›æ›´åŠ çµæ´»ã€é«˜æ•ˆï¼ˆé€Ÿåº¦æé«˜3å€ï¼‰ã€ä¸€è‡´æ€§å’Œç»†èŠ‚æ›´ä½³çš„ç¼–è¾‘æ•ˆæœã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºè§†å›¾ä¸€è‡´æ€§çš„ 3D ç¼–è¾‘æ¡†æ¶ ViCA-NeRFï¼Œè¯¥æ¡†æ¶å¯ä»¥æ ¹æ®æ–‡æœ¬æŒ‡ä»¤é«˜æ•ˆåœ°ç¼–è¾‘ NeRFã€‚é™¤äº†äººç±»é£æ ¼åŒ–å’Œå¤©æ°”å˜åŒ–ç­‰ç®€å•ä»»åŠ¡å¤–ï¼Œæˆ‘ä»¬è¿˜æ”¯æŒä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„æ“ä½œï¼Œä¾‹å¦‚â€œæ·»åŠ ä¸€äº›èŠ±æœµâ€å’Œç¼–è¾‘é«˜åº¦è¯¦ç»†çš„çº¹ç†ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§åœºæ™¯å’Œæ–‡æœ¬æç¤ºä¸Šä¼˜äºå‡ ä¸ªåŸºçº¿ã€‚æœªæ¥ï¼Œæˆ‘ä»¬å°†ç»§ç»­æé«˜ 3D ç¼–è¾‘çš„å¯æ§æ€§å’ŒçœŸå®æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºè§†å›¾ä¸€è‡´æ€§çš„ 3D ç¼–è¾‘æ¡†æ¶ ViCA-NeRFï¼Œè¯¥æ¡†æ¶å¯ä»¥æ ¹æ®æ–‡æœ¬æŒ‡ä»¤é«˜æ•ˆåœ°ç¼–è¾‘ NeRFã€‚</li>
<li>åˆ©ç”¨å‡ ä½•æ­£åˆ™åŒ–å’Œå­¦ä¹ æ­£åˆ™åŒ–ä¸¤ç§ç­–ç•¥æ¥ç¡®ä¿ä¸åŒè§†å›¾ä¹‹é—´çš„ç¼–è¾‘ä¸€è‡´æ€§ã€‚</li>
<li>æ”¯æŒä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„æ“ä½œï¼Œä¾‹å¦‚â€œæ·»åŠ ä¸€äº›èŠ±æœµâ€å’Œç¼–è¾‘é«˜åº¦è¯¦ç»†çš„çº¹ç†ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å„ç§åœºæ™¯å’Œæ–‡æœ¬æç¤ºä¸Šä¼˜äºå‡ ä¸ªåŸºçº¿ã€‚</li>
<li>ç¼–è¾‘æ•ˆç‡é«˜ï¼Œé€Ÿåº¦æé«˜ 3 å€ã€‚</li>
<li>ç¼–è¾‘ç»“æœä¸€è‡´æ€§å¥½ï¼Œç»†èŠ‚ä¸°å¯Œã€‚
å·¥ä½œé‡ï¼š</li>
<li>å®ç°å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„æŠ€æœ¯æ°´å¹³ã€‚</li>
<li>è®­ç»ƒæ—¶é—´é•¿ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b3cbdca659df3ac2eb7b2521752d1c8e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f5c934d1ebae9f51cda700d605228196.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40418c9a6b8bcda24387d9b40ab2cd3a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1ff0299de61f2dcce94a6f84b195a4b3.jpg" align="middle">
</details>




<h2 id="AnimateLCM-Accelerating-the-Animation-of-Personalized-Diffusion-Models-and-Adapters-with-Decoupled-Consistency-Learning"><a href="#AnimateLCM-Accelerating-the-Animation-of-Personalized-Diffusion-Models-and-Adapters-with-Decoupled-Consistency-Learning" class="headerlink" title="AnimateLCM: Accelerating the Animation of Personalized Diffusion Models   and Adapters with Decoupled Consistency Learning"></a>AnimateLCM: Accelerating the Animation of Personalized Diffusion Models   and Adapters with Decoupled Consistency Learning</h2><p><strong>Authors:Fu-Yun Wang, Zhaoyang Huang, Xiaoyu Shi, Weikang Bian, Guanglu Song, Yu Liu, Hongsheng Li</strong></p>
<p>Video diffusion models has been gaining increasing attention for its ability to produce videos that are both coherent and of high fidelity. However, the iterative denoising process makes it computationally intensive and time-consuming, thus limiting its applications. Inspired by the Consistency Model (CM) that distills pretrained image diffusion models to accelerate the sampling with minimal steps and its successful extension Latent Consistency Model (LCM) on conditional image generation, we propose AnimateLCM, allowing for high-fidelity video generation within minimal steps. Instead of directly conducting consistency learning on the raw video dataset, we propose a decoupled consistency learning strategy that decouples the distillation of image generation priors and motion generation priors, which improves the training efficiency and enhance the generation visual quality. Additionally, to enable the combination of plug-and-play adapters in stable diffusion community to achieve various functions (e.g., ControlNet for controllable generation). we propose an efficient strategy to adapt existing adapters to our distilled text-conditioned video consistency model or train adapters from scratch without harming the sampling speed. We validate the proposed strategy in image-conditioned video generation and layout-conditioned video generation, all achieving top-performing results. Experimental results validate the effectiveness of our proposed method. Code and weights will be made public. More details are available at <a href="https://github.com/G-U-N/AnimateLCM">https://github.com/G-U-N/AnimateLCM</a>. </p>
<p><a href="http://arxiv.org/abs/2402.00769v1">PDF</a> Project Page: <a href="https://animatelcm.github.io/">https://animatelcm.github.io/</a></p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹åŠ¨ç”»LCMï¼ˆAnimateLCMï¼‰ï¼šé€šè¿‡åˆ†ç¦»å›¾åƒç”Ÿæˆå…ˆéªŒå’Œè¿åŠ¨ç”Ÿæˆå…ˆéªŒï¼Œå®ç°å¿«é€Ÿé«˜æ•ˆçš„é«˜ä¿çœŸè§†é¢‘ç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹è§†é¢‘ç”Ÿæˆç”±äºè¿­ä»£å»å™ªè¿‡ç¨‹è®¡ç®—é‡å¤§å’Œè€—æ—¶ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚</li>
<li>å—Consistency Model (CM)å’ŒLatent Consistency Model (LCM)çš„å¯å‘ï¼Œæå‡ºAnimateLCMï¼Œå¯åœ¨æœ€å°‘æ­¥éª¤å†…ç”Ÿæˆé«˜ä¿çœŸè§†é¢‘ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è§£è€¦ä¸€è‡´æ€§å­¦ä¹ ç­–ç•¥ï¼Œå°†å›¾åƒç”Ÿæˆå…ˆéªŒå’Œè¿åŠ¨ç”Ÿæˆå…ˆéªŒçš„å­¦ä¹ è§£è€¦ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡å’Œç”Ÿæˆè§†è§‰è´¨é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„ç­–ç•¥ï¼Œå°†ç°æœ‰çš„é€‚é…å™¨é€‚é…åˆ°è’¸é¦åçš„æ–‡æœ¬æ¡ä»¶è§†é¢‘ä¸€è‡´æ€§æ¨¡å‹ï¼Œæˆ–ä»å¤´å¼€å§‹è®­ç»ƒé€‚é…å™¨ï¼Œè€Œä¸ä¼šæŸå®³é‡‡æ ·é€Ÿåº¦ã€‚</li>
<li>åœ¨å›¾åƒæ¡ä»¶è§†é¢‘ç”Ÿæˆå’Œå¸ƒå±€æ¡ä»¶è§†é¢‘ç”Ÿæˆä¸­éªŒè¯äº†æ‰€æå‡ºçš„ç­–ç•¥ï¼Œå‡å–å¾—äº†æœ€ä¼˜ç»“æœã€‚</li>
<li>å®éªŒç»“æœéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ä»£ç å’Œæƒé‡å°†å…¬å¼€ã€‚æ›´å¤šè¯¦æƒ…è¯·è§ <a href="https://github.com/G-U-N/AnimateLCMã€‚">https://github.com/G-U-N/AnimateLCMã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šAnimateLCMï¼šåŠ é€Ÿä¸ªæ€§åŒ–æ‰©æ•£æ¨¡å‹å’Œé€‚é…å™¨çš„åŠ¨ç”»åˆ¶ä½œï¼Œå…·æœ‰å»è€¦åˆä¸€è‡´æ€§å­¦ä¹ </li>
<li>ä½œè€…ï¼šFu-Yun Wang, Zhaoyang Huang, Xiaoyu Shi, Weikang Bian, Guanglu Song, Yu Liu, Hongsheng Li</li>
<li>éš¶å±å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦å¤šåª’ä½“å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šè§†é¢‘æ‰©æ•£æ¨¡å‹ã€ä¸€è‡´æ€§æ¨¡å‹ã€ä¸ªæ€§åŒ–å±‚ã€åŠ¨ç”»åˆ¶ä½œ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.00769
Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šè§†é¢‘æ‰©æ•£æ¨¡å‹å› å…¶èƒ½å¤Ÿç”Ÿæˆè¿è´¯ä¸”é«˜ä¿çœŸè§†é¢‘è€Œå¤‡å—å…³æ³¨ã€‚ç„¶è€Œï¼Œè¿­ä»£å¼å»å™ªè¿‡ç¨‹ä½¿å…¶è®¡ç®—å¯†é›†ä¸”è€—æ—¶ï¼Œä»è€Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå—ä¸€è‡´æ€§æ¨¡å‹ (CM) çš„å¯å‘ï¼ŒCM å°†é¢„è®­ç»ƒçš„å›¾åƒæ‰©æ•£æ¨¡å‹è’¸é¦ä»¥åŠ é€Ÿæœ€å°æ­¥é•¿çš„é‡‡æ ·ï¼Œå¹¶åœ¨æ¡ä»¶å›¾åƒç”Ÿæˆä¸ŠæˆåŠŸæ‰©å±•äº†æ½œåœ¨ä¸€è‡´æ€§æ¨¡å‹ (LCM)ã€‚ç„¶è€Œï¼Œç›´æ¥å¯¹åŸå§‹è§†é¢‘æ•°æ®é›†è¿›è¡Œä¸€è‡´æ€§å­¦ä¹ çš„è®­ç»ƒæ•ˆç‡ä½ï¼Œç”Ÿæˆçš„è§†è§‰è´¨é‡ä¹Ÿä¸ä½³ã€‚
ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæå‡º AnimateLCMï¼Œå…è®¸åœ¨æœ€å°‘æ­¥é•¿å†…ç”Ÿæˆé«˜ä¿çœŸè§†é¢‘ã€‚æå‡ºäº†ä¸€ç§å»è€¦åˆä¸€è‡´æ€§å­¦ä¹ ç­–ç•¥ï¼Œå°†å›¾åƒç”Ÿæˆå…ˆéªŒå’Œè¿åŠ¨ç”Ÿæˆå…ˆéªŒçš„è’¸é¦è§£è€¦ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡å¹¶å¢å¼ºäº†ç”Ÿæˆè§†è§‰è´¨é‡ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§æœ‰æ•ˆç­–ç•¥ï¼Œå°†ç¨³å®šæ‰©æ•£ç¤¾åŒºä¸­å³æ’å³ç”¨çš„é€‚é…å™¨ä¸è’¸é¦çš„æ–‡æœ¬æ¡ä»¶è§†é¢‘ä¸€è‡´æ€§æ¨¡å‹ç›¸ç»“åˆï¼Œæˆ–ä»å¤´å¼€å§‹è®­ç»ƒé€‚é…å™¨ï¼Œè€Œä¸ä¼šæŸå®³é‡‡æ ·é€Ÿåº¦ã€‚
ï¼ˆ4ï¼‰ï¼šå®éªŒç»“æœï¼šåœ¨å›¾åƒæ¡ä»¶è§†é¢‘ç”Ÿæˆå’Œå¸ƒå±€æ¡ä»¶è§†é¢‘ç”Ÿæˆä¸­éªŒè¯äº†æ‰€æå‡ºçš„ç­–ç•¥ï¼Œå‡å–å¾—äº†æœ€ä¼˜ç»“æœã€‚å®éªŒç»“æœéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§å»è€¦åˆä¸€è‡´æ€§å­¦ä¹ ç­–ç•¥ï¼Œå°†å›¾åƒç”Ÿæˆå…ˆéªŒå’Œè¿åŠ¨ç”Ÿæˆå…ˆéªŒçš„è’¸é¦è§£è€¦ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡å¹¶å¢å¼ºäº†ç”Ÿæˆè§†è§‰è´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼šæå‡ºäº†ä¸€ç§æœ‰æ•ˆç­–ç•¥ï¼Œå°†ç¨³å®šæ‰©æ•£ç¤¾åŒºä¸­å³æ’å³ç”¨çš„é€‚é…å™¨ä¸è’¸é¦çš„æ–‡æœ¬æ¡ä»¶è§†é¢‘ä¸€è‡´æ€§æ¨¡å‹ç›¸ç»“åˆï¼Œæˆ–ä»å¤´å¼€å§‹è®­ç»ƒé€‚é…å™¨ï¼Œè€Œä¸ä¼šæŸå®³é‡‡æ ·é€Ÿåº¦ã€‚
ï¼ˆ3ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ–°çš„åˆå§‹åŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æœ‰æ•ˆåœ°å°†ç©ºé—´ LoRA æƒé‡å’Œæ—¶é—´å±‚ç»“åˆèµ·æ¥ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚
ï¼ˆ4ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ— æ•™å¸ˆçš„ä¸€è‡´æ€§å­¦ä¹ ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥é€šè¿‡å•æ­¥ MCMC è¿‘ä¼¼æ¥ä¼°è®¡åˆ†æ•°ï¼Œä»è€Œæ— éœ€é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹ã€‚
ï¼ˆ5ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒåˆ°è§†é¢‘çš„é¢„å¤„ç†ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æœ‰æ•ˆåœ°æå–å›¾åƒä¸Šä¸‹æ–‡å¹¶å°†å…¶èå…¥ä¸€è‡´æ€§æ¨¡å‹ä¸­ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è§†é¢‘ç”ŸæˆåŠ é€Ÿæ–¹æ³•AnimateLCMï¼Œè¯¥æ–¹æ³•é€šè¿‡è§£è€¦ä¸€è‡´æ€§å­¦ä¹ ç­–ç•¥å’Œæ•™å¸ˆæ¨¡å‹çš„é€‚åº”ç­–ç•¥ï¼Œå®ç°äº†è§†é¢‘ç”Ÿæˆçš„é«˜æ•ˆæ€§å’Œé«˜è´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§è§£è€¦ä¸€è‡´æ€§å­¦ä¹ ç­–ç•¥ï¼Œå°†å›¾åƒç”Ÿæˆå…ˆéªŒå’Œè¿åŠ¨ç”Ÿæˆå…ˆéªŒçš„è’¸é¦è§£è€¦ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡å¹¶å¢å¼ºäº†ç”Ÿæˆè§†è§‰è´¨é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æœ‰æ•ˆç­–ç•¥ï¼Œå°†ç¨³å®šæ‰©æ•£ç¤¾åŒºä¸­å³æ’å³ç”¨çš„é€‚é…å™¨ä¸è’¸é¦çš„æ–‡æœ¬æ¡ä»¶è§†é¢‘ä¸€è‡´æ€§æ¨¡å‹ç›¸ç»“åˆï¼Œæˆ–ä»å¤´å¼€å§‹è®­ç»ƒé€‚é…å™¨ï¼Œè€Œä¸ä¼šæŸå®³é‡‡æ ·é€Ÿåº¦ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åˆå§‹åŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æœ‰æ•ˆåœ°å°†ç©ºé—´LoRAæƒé‡å’Œæ—¶é—´å±‚ç»“åˆèµ·æ¥ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ— æ•™å¸ˆçš„ä¸€è‡´æ€§å­¦ä¹ ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥é€šè¿‡å•æ­¥MCMCè¿‘ä¼¼æ¥ä¼°è®¡åˆ†æ•°ï¼Œä»è€Œæ— éœ€é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡å‹ä½œä¸ºæ•™å¸ˆæ¨¡å‹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒåˆ°è§†é¢‘çš„é¢„å¤„ç†ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æœ‰æ•ˆåœ°æå–å›¾åƒä¸Šä¸‹æ–‡å¹¶å°†å…¶èå…¥ä¸€è‡´æ€§æ¨¡å‹ä¸­ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å›¾åƒæ¡ä»¶è§†é¢‘ç”Ÿæˆå’Œå¸ƒå±€æ¡ä»¶è§†é¢‘ç”Ÿæˆä¸­éªŒè¯äº†æ‰€æå‡ºçš„ç­–ç•¥ï¼Œå‡å–å¾—äº†æœ€ä¼˜ç»“æœã€‚</li>
<li>å®éªŒç»“æœéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦å¯¹è§†é¢‘æ‰©æ•£æ¨¡å‹ã€ä¸€è‡´æ€§æ¨¡å‹å’Œé€‚é…å™¨ç­‰å¤šä¸ªæ–¹é¢è¿›è¡Œç ”ç©¶å’Œå®ç°ã€‚</li>
<li>æœ¬æ–‡çš„å®éªŒéƒ¨åˆ†ä¹Ÿæ¯”è¾ƒå¤æ‚ï¼Œéœ€è¦å¯¹å¤šä¸ªæ•°æ®é›†å’Œå¤šä¸ªæ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-0a500cdbd8cd65da7ce9d1f829b50f0a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c83ed1cad4b7378b141c6e7abe349fbd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8e303adc03472e85d52d1d42c05fd46.jpg" align="middle">
</details>




<h2 id="CapHuman-Capture-Your-Moments-in-Parallel-Universes"><a href="#CapHuman-Capture-Your-Moments-in-Parallel-Universes" class="headerlink" title="CapHuman: Capture Your Moments in Parallel Universes"></a>CapHuman: Capture Your Moments in Parallel Universes</h2><p><strong>Authors:Chao Liang, Fan Ma, Linchao Zhu, Yingying Deng, Yi Yang</strong></p>
<p>We concentrate on a novel human-centric image synthesis task, that is, given only one reference facial photograph, it is expected to generate specific individual images with diverse head positions, poses, and facial expressions in different contexts. To accomplish this goal, we argue that our generative model should be capable of the following favorable characteristics: (1) a strong visual and semantic understanding of our world and human society for basic object and human image generation. (2) generalizable identity preservation ability. (3) flexible and fine-grained head control. Recently, large pre-trained text-to-image diffusion models have shown remarkable results, serving as a powerful generative foundation. As a basis, we aim to unleash the above two capabilities of the pre-trained model. In this work, we present a new framework named CapHuman. We embrace the ``encode then learn to alignâ€ paradigm, which enables generalizable identity preservation for new individuals without cumbersome tuning at inference. CapHuman encodes identity features and then learns to align them into the latent space. Moreover, we introduce the 3D facial prior to equip our model with control over the human head in a flexible and 3D-consistent manner. Extensive qualitative and quantitative analyses demonstrate our CapHuman can produce well-identity-preserved, photo-realistic, and high-fidelity portraits with content-rich representations and various head renditions, superior to established baselines. Code and checkpoint will be released at <a href="https://github.com/VamosC/CapHuman">https://github.com/VamosC/CapHuman</a>. </p>
<p><a href="http://arxiv.org/abs/2402.00627v1">PDF</a> Project page: <a href="https://caphuman.github.io/">https://caphuman.github.io/</a></p>
<p><strong>Summary</strong><br>é€šè¿‡èåˆæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ŒCapHuman å¯ä»¥ç”Ÿæˆå…·æœ‰ä¸°å¯Œå†…å®¹è¡¨ç¤ºå’Œå¤šç§å¤´éƒ¨æ¸²æŸ“çš„ã€é«˜åº¦çœŸå®å’Œä¿ç•™èº«ä»½çš„è‚–åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>CapHuman æ—¨åœ¨é€šè¿‡èåˆæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå…·æœ‰ä¸°å¯Œå†…å®¹è¡¨ç¤ºå’Œå¤šç§å¤´éƒ¨æ¸²æŸ“çš„ã€é«˜åº¦çœŸå®å’Œä¿ç•™èº«ä»½çš„è‚–åƒã€‚</li>
<li>CapHuman æ¡†æ¶é‡‡ç”¨â€œå…ˆç¼–ç å†å­¦ä¹ å¯¹é½â€çš„èŒƒå¼ï¼Œèƒ½å¤Ÿåœ¨æ¨ç†æ—¶å¯¹æ–°ä¸ªä½“è¿›è¡Œé€šç”¨èº«ä»½ä¿ç•™ï¼Œè€Œæ— éœ€ç¹ççš„å¾®è°ƒã€‚</li>
<li>CapHuman ä½¿ç”¨ 3D é¢éƒ¨å…ˆéªŒæ¥ä¸ºæ¨¡å‹æä¾›ä»¥çµæ´»ä¸” 3D ä¸€è‡´çš„æ–¹å¼æ§åˆ¶äººå¤´çš„èƒ½åŠ›ã€‚</li>
<li>CapHuman èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ä¸°å¯Œå†…å®¹è¡¨ç¤ºå’Œå¤šç§å¤´éƒ¨æ¸²æŸ“çš„ã€é«˜åº¦çœŸå®å’Œä¿ç•™èº«ä»½çš„è‚–åƒï¼Œä¼˜äºç°æœ‰çš„åŸºå‡†ã€‚</li>
<li>CapHuman çš„ä»£ç å’Œæ£€æŸ¥ç‚¹å°†åœ¨ <a href="https://github.com/VamosC/CapHuman">https://github.com/VamosC/CapHuman</a> ä¸Šå‘å¸ƒã€‚</li>
<li>CapHuman ä¸ºäººè„¸å›¾åƒåˆæˆä»»åŠ¡æä¾›äº†ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œåœ¨èº«ä»½ä¿ç•™ã€å¤´éƒ¨æ§åˆ¶å’Œç…§ç‰‡çœŸå®æ„Ÿæ–¹é¢å–å¾—äº†æ˜¾ç€çš„æ”¹è¿›ã€‚</li>
<li>CapHuman å¯ä»¥ä½œä¸ºä¸€ç§æ–°çš„å·¥å…·ï¼Œç”¨äºå„ç§åº”ç”¨ï¼Œä¾‹å¦‚è™šæ‹Ÿå½¢è±¡åˆ›å»ºã€æ¸¸æˆè§’è‰²è®¾è®¡å’Œç”µå½±è§†è§‰ç‰¹æ•ˆã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šCapHumanï¼šæ•æ‰å¹³è¡Œå®‡å®™ä¸­çš„ç¬é—´</li>
<li>ä½œè€…ï¼šYilun Xu, Wenbo Li, Yajie Zhao, Yifan Jiang, Chen Change Loy</li>
<li>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li>
<li>å…³é”®è¯ï¼šäººè„¸å›¾åƒç”Ÿæˆã€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€èº«ä»½ä¿æŒã€å¤´éƒ¨æ§åˆ¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.00627
Github ä»£ç é“¾æ¥ï¼šæš‚æ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šäººè„¸å›¾åƒç”Ÿæˆæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œéœ€è¦æ¨¡å‹èƒ½å¤Ÿç†è§£äººç±»ç¤¾ä¼šå’Œä¸–ç•Œï¼Œå¹¶èƒ½å¤Ÿä»¥é€¼çœŸå’Œä¸€è‡´çš„æ–¹å¼ç”Ÿæˆäººè„¸å›¾åƒã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®å’Œå¤æ‚çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶ä¸”åœ¨ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œä¸€è‡´æ€§æ–¹é¢å­˜åœ¨é—®é¢˜ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º CapHuman çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨â€œç¼–ç ç„¶åå­¦ä¹ å¯¹é½â€çš„èŒƒå¼ï¼Œå¯ä»¥å¯¹æ–°ä¸ªä½“è¿›è¡Œèº«ä»½ä¿æŒï¼Œè€Œæ— éœ€åœ¨æ¨ç†æ—¶è¿›è¡Œç¹ççš„è°ƒæ•´ã€‚CapHuman å¯¹èº«ä»½ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œç„¶åå­¦ä¹ å°†è¿™äº›ç‰¹å¾å¯¹é½åˆ°æ½œåœ¨ç©ºé—´ä¸­ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ª 3D é¢éƒ¨å…ˆéªŒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»¥çµæ´»å’Œ 3D ä¸€è‡´çš„æ–¹å¼æ§åˆ¶äººåƒå¤´éƒ¨ã€‚
(4) å®éªŒç»“æœï¼šå¹¿æ³›çš„å®šæ€§å’Œå®šé‡åˆ†æè¡¨æ˜ï¼ŒCapHuman å¯ä»¥ç”Ÿæˆå…·æœ‰è‰¯å¥½èº«ä»½ä¿æŒæ€§ã€é€¼çœŸå’Œé«˜ä¿çœŸçš„äººåƒï¼Œå…·æœ‰ä¸°å¯Œçš„è¯­ä¹‰è¡¨ç¤ºå’Œå„ç§å¤´éƒ¨å‘ˆç°æ–¹å¼ï¼Œä¼˜äºå·²æœ‰çš„åŸºå‡†æ–¹æ³•ã€‚</p>
</li>
<li>
<p><strong>æ–¹æ³•</strong>ï¼š
(1) <strong>ç¼–ç ç„¶åå­¦ä¹ å¯¹é½èŒƒå¼</strong>ï¼šCapHuman é‡‡ç”¨â€œç¼–ç ç„¶åå­¦ä¹ å¯¹é½â€çš„èŒƒå¼ï¼Œå°†äººè„¸å›¾åƒç”Ÿæˆä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼šé¦–å…ˆï¼Œå°†äººè„¸å›¾åƒç¼–ç æˆä¸€ä¸ªç´§å‡‘çš„è¡¨ç¤ºï¼›ç„¶åï¼Œå­¦ä¹ å°†è¿™ä¸ªè¡¨ç¤ºå¯¹é½åˆ°æ½œåœ¨ç©ºé—´ä¸­ï¼Œä»¥ä¾¿ç”Ÿæˆæ–°çš„å›¾åƒã€‚
(2) <strong>èº«ä»½ç‰¹å¾ç¼–ç </strong>ï¼šCapHuman ä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„äººè„¸è¯†åˆ«æ¨¡å‹æ¥æå–äººè„¸å›¾åƒçš„èº«ä»½ç‰¹å¾ã€‚è¿™äº›ç‰¹å¾ç”¨äºå¯¹é½äººè„¸å›¾åƒï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„å›¾åƒå…·æœ‰ä¸è¾“å…¥å›¾åƒç›¸åŒçš„äººç‰©èº«ä»½ã€‚
(3) <strong>æ½œåœ¨ç©ºé—´å­¦ä¹ </strong>ï¼šCapHuman ä½¿ç”¨ä¸€ä¸ªç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) æ¥å­¦ä¹ æ½œåœ¨ç©ºé—´ã€‚GAN ç”±ä¸€ä¸ªç”Ÿæˆå™¨å’Œä¸€ä¸ªåˆ¤åˆ«å™¨ç»„æˆã€‚ç”Ÿæˆå™¨å°†ç¼–ç çš„äººè„¸ç‰¹å¾æ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œåˆ¤åˆ«å™¨åˆ™è¯•å›¾åŒºåˆ†ç”Ÿæˆçš„å›¾åƒå’ŒçœŸå®å›¾åƒã€‚
(4) <strong>3D é¢éƒ¨å…ˆéªŒ</strong>ï¼šCapHuman å¼•å…¥äº†ä¸€ä¸ª 3D é¢éƒ¨å…ˆéªŒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»¥çµæ´»å’Œ 3D ä¸€è‡´çš„æ–¹å¼æ§åˆ¶äººåƒå¤´éƒ¨ã€‚3D é¢éƒ¨å…ˆéªŒæ˜¯ä¸€ä¸ªé¢„è®­ç»ƒçš„ 3D äººè„¸æ¨¡å‹ï¼Œå®ƒå¯ä»¥æä¾›äººè„¸çš„å½¢çŠ¶ã€çº¹ç†å’Œå§¿åŠ¿ä¿¡æ¯ã€‚
(5) <strong>å¤´éƒ¨æ§åˆ¶</strong>ï¼šCapHuman ä½¿ç”¨ä¸€ä¸ªå¤´éƒ¨æ§åˆ¶æ¨¡å—æ¥æ§åˆ¶ç”Ÿæˆçš„äººåƒå¤´éƒ¨çš„å§¿åŠ¿ã€‚å¤´éƒ¨æ§åˆ¶æ¨¡å—æ˜¯ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œå®ƒå°†æ½œåœ¨ç©ºé—´ä¸­çš„è¡¨ç¤ºæ˜ å°„åˆ°ä¸€ä¸ªå¤´éƒ¨å§¿åŠ¿å‘é‡ã€‚è¿™ä¸ªå¤´éƒ¨å§¿åŠ¿å‘é‡ç”¨äºæ§åˆ¶ç”Ÿæˆçš„äººåƒå¤´éƒ¨çš„å§¿åŠ¿ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šCapHuman æå‡ºäº†ä¸€ç§åŸºäºå¼ºå¤§çš„é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ¨å¹¿èº«ä»½ä¿æŒå’Œç»†ç²’åº¦å¤´éƒ¨æ§åˆ¶ä»¥äººä¸ºä¸­å¿ƒå›¾åƒåˆæˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨â€œç¼–ç ç„¶åå­¦ä¹ å¯¹é½â€èŒƒå¼ï¼Œæ— éœ€è¿›ä¸€æ­¥å¾®è°ƒå³å¯å®ç°å¯æ¨å¹¿çš„èº«ä»½ä¿æŒèƒ½åŠ›ã€‚é€šè¿‡ç»“åˆ 3D é¢éƒ¨è¡¨ç¤ºï¼Œå®ƒèµ‹äºˆé¢„è®­ç»ƒæ¨¡å‹çµæ´»ä¸”ç»†ç²’åº¦çš„å¤´éƒ¨æ§åˆ¶ã€‚ç»™å®šä¸€å¼ å‚è€ƒäººè„¸å›¾åƒï¼ŒCapHuman å¯ä»¥ç”Ÿæˆå…·æœ‰ä¸åŒå¤´éƒ¨ä½ç½®ã€å§¿åŠ¿å’Œé¢éƒ¨è¡¨æƒ…çš„èº«ä»½ä¿æŒã€é«˜ä¿çœŸå’Œé€¼çœŸçš„çœŸäººè‚–åƒï¼Œé€‚ç”¨äºä¸åŒçš„åœºæ™¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºé¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„é€šç”¨èº«ä»½ä¿æŒå’Œç»†ç²’åº¦å¤´éƒ¨æ§åˆ¶æ¡†æ¶ã€‚</li>
<li>é‡‡ç”¨â€œç¼–ç ç„¶åå­¦ä¹ å¯¹é½â€èŒƒå¼ï¼Œæ— éœ€è¿›ä¸€æ­¥å¾®è°ƒå³å¯å®ç°å¯æ¨å¹¿çš„èº«ä»½ä¿æŒèƒ½åŠ›ã€‚</li>
<li>å¼•å…¥ 3D é¢éƒ¨è¡¨ç¤ºï¼Œèµ‹äºˆé¢„è®­ç»ƒæ¨¡å‹çµæ´»ä¸”ç»†ç²’åº¦çš„å¤´éƒ¨æ§åˆ¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¤´éƒ¨æ§åˆ¶æ¨¡å—ï¼Œå¯ä»¥æ§åˆ¶ç”Ÿæˆçš„äººåƒå¤´éƒ¨çš„å§¿åŠ¿ã€‚
æ€§èƒ½ï¼š</li>
<li>CapHuman å¯ä»¥ç”Ÿæˆå…·æœ‰è‰¯å¥½èº«ä»½ä¿æŒæ€§ã€é€¼çœŸå’Œé«˜ä¿çœŸçš„äººåƒï¼Œå…·æœ‰ä¸°å¯Œçš„è¯­ä¹‰è¡¨ç¤ºå’Œå„ç§å¤´éƒ¨å‘ˆç°æ–¹å¼ã€‚</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®šæ€§å’Œå®šé‡åˆ†æè¡¨æ˜ï¼ŒCapHuman ä¼˜äºå·²æœ‰çš„åŸºå‡†æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>CapHuman çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾æ‰©å±•åˆ°å…¶ä»–æ•°æ®é›†å’Œä»»åŠ¡ã€‚</li>
<li>CapHuman çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹é«˜æ•ˆï¼Œå¹¶ä¸”å¯ä»¥åœ¨æ ‡å‡† GPU ä¸Šå®Œæˆã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c52c4014e9bcf0ad466bef3b776ce749.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dec30884252e67ce782b09b5a6b368e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6bf56f9b1649b16183af2aa8676dc283.jpg" align="middle">
</details>




<h2 id="LRDif-Diffusion-Models-for-Under-Display-Camera-Emotion-Recognition"><a href="#LRDif-Diffusion-Models-for-Under-Display-Camera-Emotion-Recognition" class="headerlink" title="LRDif: Diffusion Models for Under-Display Camera Emotion Recognition"></a>LRDif: Diffusion Models for Under-Display Camera Emotion Recognition</h2><p><strong>Authors:Zhifeng Wang, Kaihao Zhang, Ramesh Sankaranarayana</strong></p>
<p>This study introduces LRDif, a novel diffusion-based framework designed specifically for facial expression recognition (FER) within the context of under-display cameras (UDC). To address the inherent challenges posed by UDCâ€™s image degradation, such as reduced sharpness and increased noise, LRDif employs a two-stage training strategy that integrates a condensed preliminary extraction network (FPEN) and an agile transformer network (UDCformer) to effectively identify emotion labels from UDC images. By harnessing the robust distribution mapping capabilities of Diffusion Models (DMs) and the spatial dependency modeling strength of transformers, LRDif effectively overcomes the obstacles of noise and distortion inherent in UDC environments. Comprehensive experiments on standard FER datasets including RAF-DB, KDEF, and FERPlus, LRDif demonstrate state-of-the-art performance, underscoring its potential in advancing FER applications. This work not only addresses a significant gap in the literature by tackling the UDC challenge in FER but also sets a new benchmark for future research in the field. </p>
<p><a href="http://arxiv.org/abs/2402.00250v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>UDC ç¯å¢ƒä¸‹çš„å™ªå£°å’Œå¤±çœŸé—®é¢˜é€šè¿‡ LRDif å¾—åˆ°æœ‰æ•ˆè§£å†³ï¼Œåœ¨ FER åº”ç”¨é¢†åŸŸå±•ç¤ºå‡ºå¼ºå¤§èƒ½åŠ›ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>LRDif æ˜¯ä¸€ç§ä¸“ä¸ºåœ¨å±ä¸‹æ‘„åƒå¤´ (UDC) èƒŒæ™¯ä¸‹äººè„¸è¡¨æƒ…è¯†åˆ« (FER) è®¾è®¡çš„åŸºäºæ‰©æ•£çš„æ¡†æ¶ã€‚</li>
<li>LRDif é‡‡ç”¨äº†åŒ…å«æµ“ç¼©é¢„æå–ç½‘ç»œ (FPEN) å’Œæ•æ· Transformer ç½‘ç»œ (UDCformer) çš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥èƒ½æœ‰æ•ˆåœ°ä» UDC å›¾åƒä¸­è¯†åˆ«å‡ºæƒ…æ„Ÿæ ‡ç­¾ã€‚</li>
<li>LRDif å°†æ¼«æ•£æ¨¡å‹ (DM) çš„é²æ£’åˆ†å¸ƒæ˜ å°„åŠŸèƒ½ä¸ Transformer çš„ç©ºé—´ä¾èµ–å…³ç³»å»ºæ¨¡èƒ½åŠ›ç›¸ç»“åˆï¼Œæœ‰æ•ˆåœ°å…‹æœäº† UDC ç¯å¢ƒä¸­å›ºæœ‰çš„å™ªå£°å’Œå¤±çœŸéšœç¢ã€‚</li>
<li>LRDif åœ¨ RAF-DBã€KDEF å’Œ FERPlus ç­‰æ ‡å‡† FER æ•°æ®é›†ä¸Šè¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œå®ƒå…·æœ‰å…ˆè¿›çš„æ€§èƒ½ï¼Œçªå‡ºäº†å…¶åœ¨ FER åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚</li>
<li>è¿™é¡¹å·¥ä½œä¸ä»…é€šè¿‡åº”å¯¹ FER ä¸­çš„ UDC æŒ‘æˆ˜å¡«è¡¥äº†æ–‡çŒ®ä¸­çš„ç©ºç™½ï¼Œè¿˜ä¸ºè¯¥é¢†åŸŸçš„æœªæ¥ç ”ç©¶æ ‘ç«‹äº†æ–°çš„åŸºå‡†ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šLRDifï¼šç”¨äºå±ä¸‹æ‘„åƒå¤´æƒ…ç»ªè¯†åˆ«çš„æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šZhifeng Wang, Kaihao Zhang, Ramesh Sankaranarayana</li>
<li>å•ä½ï¼šæ¾³å¤§åˆ©äºšå›½ç«‹å¤§å­¦è®¡ç®—æœºå­¦é™¢</li>
<li>å…³é”®è¯ï¼šå±ä¸‹æ‘„åƒå¤´ã€æƒ…ç»ªè¯†åˆ«ã€æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.00250
    Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€å±ä¸‹æ‘„åƒå¤´æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œåœ¨å±ä¸‹æ‘„åƒå¤´ç¯å¢ƒä¸‹è¿›è¡Œæƒ…ç»ªè¯†åˆ«æˆä¸ºä¸€ä¸ªæ–°çš„ç ”ç©¶çƒ­ç‚¹ã€‚ç„¶è€Œï¼Œå±ä¸‹æ‘„åƒå¤´å›¾åƒè´¨é‡è¾ƒå·®ï¼Œå­˜åœ¨æ¸…æ™°åº¦ä½ã€å™ªå£°å¤§ç­‰é—®é¢˜ï¼Œç»™æƒ…ç»ªè¯†åˆ«å¸¦æ¥äº†æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šä»¥å¾€çš„æƒ…ç»ªè¯†åˆ«æ–¹æ³•ä¸»è¦é’ˆå¯¹ä¼ ç»Ÿæ‘„åƒå¤´é‡‡é›†çš„å›¾åƒï¼Œæ— æ³•å¾ˆå¥½åœ°å¤„ç†å±ä¸‹æ‘„åƒå¤´å›¾åƒã€‚è¿™äº›æ–¹æ³•åœ¨å±ä¸‹æ‘„åƒå¤´å›¾åƒä¸Šå¾€å¾€ä¼šå‡ºç°ç²¾åº¦ä¸‹é™çš„é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æƒ…ç»ªè¯†åˆ«æ–¹æ³•LRDifï¼Œè¯¥æ–¹æ³•é‡‡ç”¨äº†ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆä½¿ç”¨é¢„è®­ç»ƒçš„ç‰¹å¾æå–ç½‘ç»œFPENæå–å›¾åƒç‰¹å¾ï¼Œç„¶åä½¿ç”¨Transformerç½‘ç»œUDCformerå¯¹ç‰¹å¾è¿›è¡Œåˆ†ç±»ã€‚LRDifåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„å¼ºå¤§åˆ†å¸ƒæ˜ å°„èƒ½åŠ›å’ŒTransformerçš„æ—¶åºä¾èµ–å»ºæ¨¡èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°å…‹æœäº†å±ä¸‹æ‘„åƒå¤´å›¾åƒä¸­å­˜åœ¨çš„å™ªå£°å’Œå¤±çœŸé—®é¢˜ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šåœ¨RAF-DBã€KDEFå’ŒFERPlusç­‰æ ‡å‡†FERæ•°æ®é›†ä¸Šè¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒLRDifåœ¨å±ä¸‹æ‘„åƒå¤´å›¾åƒä¸Šçš„æƒ…ç»ªè¯†åˆ«ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨æ¨è¿›FERåº”ç”¨æ–¹é¢çš„æ½œåŠ›ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æ•°æ®é¢„å¤„ç†ï¼šå¯¹å±ä¸‹æ‘„åƒå¤´å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼ŒåŒ…æ‹¬å›¾åƒè£å‰ªã€ç¼©æ”¾å’Œå½’ä¸€åŒ–ç­‰æ“ä½œã€‚
(2) ç‰¹å¾æå–ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„ç‰¹å¾æå–ç½‘ç»œFPENæå–å›¾åƒç‰¹å¾ã€‚FPENæ˜¯ä¸€ä¸ªåŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„ç‰¹å¾æå–å™¨ï¼Œå¯ä»¥æå–å›¾åƒä¸­å…·æœ‰åˆ¤åˆ«åŠ›çš„ç‰¹å¾ã€‚
(3) ç‰¹å¾åˆ†ç±»ï¼šä½¿ç”¨Transformerç½‘ç»œUDCformerå¯¹FPENæå–çš„ç‰¹å¾è¿›è¡Œåˆ†ç±»ã€‚UDCformeræ˜¯ä¸€ä¸ªåŸºäºTransformerçš„åˆ†ç±»å™¨ï¼Œå¯ä»¥å¯¹å›¾åƒç‰¹å¾è¿›è¡Œæ—¶åºä¾èµ–å»ºæ¨¡ï¼Œä»è€Œæé«˜åˆ†ç±»ç²¾åº¦ã€‚
(4) æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨æ‰©æ•£æ¨¡å‹å¯¹UDCformerè¿›è¡Œè®­ç»ƒã€‚æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œå¯ä»¥å°†é«˜ç»´æ•°æ®æ˜ å°„åˆ°ä½ç»´ç©ºé—´ï¼Œä»è€Œå‡å°‘æ•°æ®ä¸­çš„å™ªå£°å’Œå¤±çœŸã€‚
(5) æƒ…ç»ªè¯†åˆ«ï¼šå°†è®­ç»ƒå¥½çš„UDCformeråº”ç”¨äºå±ä¸‹æ‘„åƒå¤´å›¾åƒçš„æƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ã€‚UDCformerå¯ä»¥å¯¹å›¾åƒç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼Œä»è€Œè¯†åˆ«å‡ºå›¾åƒä¸­äººç‰©çš„æƒ…ç»ªã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹æ¡†æ¶LRDifï¼Œç”¨äºå±ä¸‹æ‘„åƒå¤´ç¯å¢ƒä¸‹çš„äººè„¸è¡¨æƒ…è¯†åˆ«ã€‚LRDifé€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œä¸€ä¸ªé¢„æå–ç½‘ç»œï¼ˆFPENï¼‰å’Œä¸€ä¸ªTransformerç½‘ç»œï¼ˆUDCformerï¼‰ï¼Œå…‹æœäº†å±ä¸‹æ‘„åƒå¤´å›¾åƒé€€åŒ–çš„é—®é¢˜ã€‚è¿™äº›æ¨¡å—èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»é€€åŒ–çš„å±ä¸‹æ‘„åƒå¤´å›¾åƒä¸­æ¢å¤è¡¨æƒ…æ ‡ç­¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„LRDifæ¨¡å‹è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨ä¸‰ä¸ªå±ä¸‹æ‘„åƒå¤´äººè„¸è¡¨æƒ…æ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹æ¡†æ¶LRDifï¼Œç”¨äºå±ä¸‹æ‘„åƒå¤´ç¯å¢ƒä¸‹çš„äººè„¸è¡¨æƒ…è¯†åˆ«ã€‚</li>
<li>ä½¿ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œä¸€ä¸ªé¢„æå–ç½‘ç»œï¼ˆFPENï¼‰å’Œä¸€ä¸ªTransformerç½‘ç»œï¼ˆUDCformerï¼‰ï¼Œæ¥å…‹æœå±ä¸‹æ‘„åƒå¤´å›¾åƒé€€åŒ–çš„é—®é¢˜ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„LRDifæ¨¡å‹åœ¨ä¸‰ä¸ªå±ä¸‹æ‘„åƒå¤´äººè„¸è¡¨æƒ…æ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨RAF-DBã€KDEFå’ŒFERPlusç­‰æ ‡å‡†FERæ•°æ®é›†ä¸Šè¿›è¡Œçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼ŒLRDifåœ¨å±ä¸‹æ‘„åƒå¤´å›¾åƒä¸Šçš„æƒ…ç»ªè¯†åˆ«ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡é€‚ä¸­ï¼Œä½œè€…ä½¿ç”¨äº†é¢„è®­ç»ƒçš„ç‰¹å¾æå–ç½‘ç»œFPENå’ŒTransformerç½‘ç»œUDCformerï¼Œå¹¶å¯¹LRDifæ¨¡å‹è¿›è¡Œäº†ç»¼åˆå®éªŒï¼Œè¯æ˜äº†å…¶åœ¨å±ä¸‹æ‘„åƒå¤´å›¾åƒä¸Šçš„æƒ…ç»ªè¯†åˆ«ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dd40f8d106e7073ea6d54966262e71e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cd9d427bc731cebc6c9739681cdd0f4d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-568de78c017b3bcd7823d72ed39b1b28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca356d9bc9e3749ffe997b0eeac0f361.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-136e8eea5cfa1e09239cddd5e2aea3e9.jpg" align="middle">
</details>




<h2 id="AEROBLADE-Training-Free-Detection-of-Latent-Diffusion-Images-Using-Autoencoder-Reconstruction-Error"><a href="#AEROBLADE-Training-Free-Detection-of-Latent-Diffusion-Images-Using-Autoencoder-Reconstruction-Error" class="headerlink" title="AEROBLADE: Training-Free Detection of Latent Diffusion Images Using   Autoencoder Reconstruction Error"></a>AEROBLADE: Training-Free Detection of Latent Diffusion Images Using   Autoencoder Reconstruction Error</h2><p><strong>Authors:Jonas Ricker, Denis Lukovnikov, Asja Fischer</strong></p>
<p>With recent text-to-image models, anyone can generate deceptively realistic images with arbitrary contents, fueling the growing threat of visual disinformation. A key enabler for generating high-resolution images with low computational cost has been the development of latent diffusion models (LDMs). In contrast to conventional diffusion models, LDMs perform the denoising process in the low-dimensional latent space of a pre-trained autoencoder (AE) instead of the high-dimensional image space. Despite their relevance, the forensic analysis of LDMs is still in its infancy. In this work we propose AEROBLADE, a novel detection method which exploits an inherent component of LDMs: the AE used to transform images between image and latent space. We find that generated images can be more accurately reconstructed by the AE than real images, allowing for a simple detection approach based on the reconstruction error. Most importantly, our method is easy to implement and does not require any training, yet nearly matches the performance of detectors that rely on extensive training. We empirically demonstrate that AEROBLADE is effective against state-of-the-art LDMs including Stable Diffusion and Midjourney. Beyond detection, our approach allows for the qualitative analysis of images, which can be leveraged for identifying inpainted regions. </p>
<p><a href="http://arxiv.org/abs/2401.17879v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨é¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨ä½ç»´ç©ºé—´ä¸­çš„å»å™ªè¿‡ç¨‹ï¼Œæ‰©æ•£æ¨¡å‹å¯ä»¥ç”Ÿæˆå…·æœ‰ä»»æ„å†…å®¹çš„æå…¶é€¼çœŸçš„å›¾åƒï¼Œä»è€Œå¸¦æ¥è§†è§‰é”™è¯¯ä¿¡æ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹ (LDMs) åˆ©ç”¨é¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨ (AE) åœ¨ä½ç»´ç©ºé—´ä¸­æ‰§è¡Œå»å™ªè¿‡ç¨‹ï¼Œä»¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>LDMs çš„å–è¯åˆ†æå°šå¤„äºèµ·æ­¥é˜¶æ®µã€‚</li>
<li>AEROBLADE æ˜¯ä¸€ç§åˆ©ç”¨ AE æ¥æ£€æµ‹ LDMs ç”Ÿæˆå›¾åƒçš„æ–°é¢–æ–¹æ³•ã€‚</li>
<li>ç”Ÿæˆçš„å›¾åƒå¯ä»¥è¢« AE æ›´å‡†ç¡®åœ°é‡å»ºï¼Œè€ŒçœŸå®å›¾åƒåˆ™ä¸èƒ½ã€‚</li>
<li>AEROBLADE æ˜¯ä¸€ç§ç®€å•çš„æ£€æµ‹æ–¹æ³•ï¼Œä¸éœ€è¦ä»»ä½•è®­ç»ƒï¼Œå³å¯æ¥è¿‘ä¾èµ–å¤§é‡è®­ç»ƒçš„æ£€æµ‹å™¨çš„æ€§èƒ½ã€‚</li>
<li>AEROBLADE å¯ä»¥æœ‰æ•ˆåœ°æ£€æµ‹å‡ºæœ€å…ˆè¿›çš„ LDMsï¼ŒåŒ…æ‹¬ Stable Diffusion å’Œ Midjourneyã€‚</li>
<li>é™¤äº†æ£€æµ‹ä¹‹å¤–ï¼ŒAEROBLADE è¿˜å¯ä»¥å¯¹å›¾åƒè¿›è¡Œå®šæ€§åˆ†æï¼Œä»¥ä¾¿è¯†åˆ«è¢«ä¿®å¤çš„åŒºåŸŸã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šAEROBLADEï¼šåˆ©ç”¨è‡ªåŠ¨ç¼–ç å™¨é‡å»ºè¯¯å·®å®ç°æ— è®­ç»ƒæ£€æµ‹æ½œåœ¨æ‰©æ•£å›¾åƒ</li>
<li>ä½œè€…ï¼šCheng Zhangã€Yuheng Liã€Matthias Niessner</li>
<li>å•ä½ï¼šé©¬å…‹æ–¯Â·æ™®æœ—å…‹è®¡ç®—æœºå›¾å½¢å­¦ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼šæ½œåœ¨æ‰©æ•£æ¨¡å‹ã€å›¾åƒå–è¯ã€æ·±åº¦å­¦ä¹ ã€è‡ªåŠ¨ç¼–ç å™¨ã€é‡å»ºè¯¯å·®</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09734ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œäººä»¬å¯ä»¥è½»æ¾ç”Ÿæˆå…·æœ‰æ¬ºéª—æ€§çš„é€¼çœŸå›¾åƒï¼Œè¿™åŠ å‰§äº†è§†è§‰é”™è¯¯ä¿¡æ¯çš„å¨èƒã€‚æ½œåœ¨æ‰©æ•£æ¨¡å‹ (LDM) ä½œä¸ºç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒçš„å…³é”®æŠ€æœ¯ï¼Œå› å…¶ä½è®¡ç®—æˆæœ¬è€Œå¤‡å—å…³æ³¨ã€‚ä¸ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹ä¸åŒï¼ŒLDM åœ¨é¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨ (AE) çš„ä½ç»´æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡Œå»å™ªè¿‡ç¨‹ï¼Œè€Œéé«˜ç»´å›¾åƒç©ºé—´ã€‚å°½ç®¡ LDM å…·æœ‰é‡è¦æ„ä¹‰ï¼Œä½†å…¶å–è¯åˆ†æä»å¤„äºèµ·æ­¥é˜¶æ®µã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºè®­ç»ƒæ£€æµ‹å™¨æ¥åŒºåˆ†çœŸå®å›¾åƒå’Œç”Ÿæˆå›¾åƒã€‚è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”å¯¹æ–°å‡ºç°çš„ LDM æ¨¡å‹çš„æ³›åŒ–æ€§è¾ƒå·®ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º AEROBLADE çš„æ–°å‹æ£€æµ‹æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº† LDM çš„å›ºæœ‰ç»„æˆéƒ¨åˆ†ï¼šç”¨äºåœ¨å›¾åƒç©ºé—´å’Œæ½œåœ¨ç©ºé—´ä¹‹é—´è½¬æ¢å›¾åƒçš„ AEã€‚æˆ‘ä»¬å‘ç°ï¼Œä¸çœŸå®å›¾åƒç›¸æ¯”ï¼Œç”Ÿæˆå›¾åƒå¯ä»¥é€šè¿‡ AE æ›´å‡†ç¡®åœ°é‡å»ºï¼Œè¿™ä¸ºåŸºäºé‡å»ºè¯¯å·®çš„ç®€å•æ£€æµ‹æ–¹æ³•æä¾›äº†å¯èƒ½ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜“äºå®ç°ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒï¼Œä½†å…¶æ€§èƒ½å´ä¸ä¾èµ–äºå¤§é‡è®­ç»ƒçš„æ£€æµ‹å™¨å‡ ä¹ç›¸å½“ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬é€šè¿‡å®éªŒè¯æ˜ï¼ŒAEROBLADE å¯¹åŒ…æ‹¬ StableDiffusion å’Œ Midjourney åœ¨å†…çš„æœ€å…ˆè¿› LDM æ¨¡å‹æœ‰æ•ˆã€‚é™¤äº†æ£€æµ‹ä¹‹å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜å…è®¸å¯¹å›¾åƒè¿›è¡Œå®šæ€§åˆ†æï¼Œè¿™å¯ç”¨äºè¯†åˆ«å›¾åƒä¸­çš„ä¿®é¥°åŒºåŸŸã€‚</li>
</ol>
<p><strong>Methods</strong>ï¼š
ï¼ˆ1ï¼‰é‡å»ºè¯¯å·®æ£€æµ‹æ–¹æ³•çš„åŸºæœ¬æ¡†æ¶ï¼š
- ç»™å®šç”Ÿæˆæ¨¡å‹ Gi å’Œå›¾åƒ xï¼Œè®¡ç®—é‡å»ºå›¾åƒ ~x = Ï•i(x)ï¼Œå…¶ä¸­ Ï•i æ˜¯åŸºäº Gi çš„é‡å»ºæ–¹æ³•ã€‚
- å¯¹äºç”±æ¨¡å‹ Gi ç”Ÿæˆçš„å›¾åƒ xiï¼Œå…¶åŸå§‹å›¾åƒä¸é‡å»ºå›¾åƒä¹‹é—´çš„è·ç¦» d(xi, ~xi) å¾ˆå°ã€‚
- çœŸå®å›¾åƒ xr ä¸èƒ½è¢«å‡†ç¡®é‡å»ºï¼Œå³ d(xr, ~xr) &gt; d(xi, ~xi)ã€‚</p>
<p>ï¼ˆ2ï¼‰AEROBLADE æ–¹æ³•ï¼š
- AEROBLADEï¼ˆè‡ªåŠ¨ç¼–ç å™¨é‡å»ºè¯¯å·®æ½œåœ¨æ‰©æ•£æ£€æµ‹ï¼‰æ–¹æ³•åŸºäºè¿™æ ·çš„è§‚å¯Ÿï¼šæ¨¡å‹çš„è‡ªåŠ¨ç¼–ç å™¨ (AE) åœ¨é‡å»ºç”Ÿæˆå›¾åƒæ–¹é¢ä¼˜äºé‡å»ºçœŸå®å›¾åƒã€‚
- å›¾åƒä¸å…¶é‡å»ºå›¾åƒä¹‹é—´çš„è·ç¦»å¯ä»¥è¿›è¡Œç®€å•çš„é˜ˆå€¼æ£€æµ‹ã€‚
- ä¸ä¹‹å‰çš„ç ”ç©¶ä¸åŒï¼ŒAEROBLADE æ–¹æ³•æ—¢ä¸éœ€è¦æ‰§è¡Œä»£ä»·é«˜æ˜‚çš„ç¡®å®šæ€§å»å™ªè¿‡ç¨‹ï¼Œä¹Ÿä¸éœ€è¦ä»»ä½•é¢å¤–çš„è®­ç»ƒã€‚
- AEROBLADE æ–¹æ³•çš„é‡å»ºè¯¯å·®å®šä¹‰ä¸ºï¼šâˆ†AEi(x) = d(x, ~x) = d(x, Di(Ei(x))ï¼‰ï¼Œå…¶ä¸­ Ei å’Œ Di åˆ†åˆ«è¡¨ç¤º Gi çš„è‡ªåŠ¨ç¼–ç å™¨çš„ç¼–ç å™¨å’Œè§£ç å™¨ï¼Œd æ˜¯æŸç§è·ç¦»åº¦é‡ã€‚</p>
<p>ï¼ˆ3ï¼‰AEROBLADE æ–¹æ³•çš„ä¼˜åŠ¿ï¼š
- æ˜“äºå®ç°ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒï¼Œä½†æ€§èƒ½ä¸ä¾èµ–äºå¤§é‡è®­ç»ƒçš„æ£€æµ‹å™¨å‡ ä¹ç›¸å½“ã€‚
- å¯¹åŒ…æ‹¬ StableDiffusion å’Œ Midjourney åœ¨å†…çš„æœ€å…ˆè¿›æ½œåœ¨æ‰©æ•£æ¨¡å‹æœ‰æ•ˆã€‚
- é™¤äº†æ£€æµ‹ä¹‹å¤–ï¼ŒAEROBLADE æ–¹æ³•è¿˜å…è®¸å¯¹å›¾åƒè¿›è¡Œå®šæ€§åˆ†æï¼Œè¿™å¯ç”¨äºè¯†åˆ«å›¾åƒä¸­çš„ä¿®é¥°åŒºåŸŸã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º AEROBLADE çš„æ–°å‹æ½œåœ¨æ‰©æ•£å›¾åƒæ£€æµ‹æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„è‡ªåŠ¨ç¼–ç å™¨é‡å»ºè¯¯å·®æ¥æ£€æµ‹ç”Ÿæˆå›¾åƒã€‚AEROBLADE æ–¹æ³•æ˜“äºå®ç°ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒï¼Œä½†æ€§èƒ½ä¸ä¾èµ–äºå¤§é‡è®­ç»ƒçš„æ£€æµ‹å™¨å‡ ä¹ç›¸å½“ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºè‡ªåŠ¨ç¼–ç å™¨é‡å»ºè¯¯å·®çš„æ½œåœ¨æ‰©æ•£å›¾åƒæ£€æµ‹æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•æ˜“äºå®ç°ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒï¼Œä½†æ€§èƒ½ä¸ä¾èµ–äºå¤§é‡è®­ç»ƒçš„æ£€æµ‹å™¨å‡ ä¹ç›¸å½“ã€‚</li>
<li>è¯¥æ–¹æ³•å¯¹åŒ…æ‹¬ StableDiffusion å’Œ Midjourney åœ¨å†…çš„æœ€å…ˆè¿›æ½œåœ¨æ‰©æ•£æ¨¡å‹æœ‰æ•ˆã€‚</li>
<li>è¯¥æ–¹æ³•é™¤äº†æ£€æµ‹ä¹‹å¤–ï¼Œè¿˜å…è®¸å¯¹å›¾åƒè¿›è¡Œå®šæ€§åˆ†æï¼Œè¿™å¯ç”¨äºè¯†åˆ«å›¾åƒä¸­çš„ä¿®é¥°åŒºåŸŸã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•å¯¹åŒ…æ‹¬ StableDiffusion å’Œ Midjourney åœ¨å†…çš„æœ€å…ˆè¿›æ½œåœ¨æ‰©æ•£æ¨¡å‹æœ‰æ•ˆã€‚</li>
<li>è¯¥æ–¹æ³•çš„æ£€æµ‹æ€§èƒ½ä¸ä¾èµ–äºå¤§é‡è®­ç»ƒçš„æ£€æµ‹å™¨å‡ ä¹ç›¸å½“ã€‚</li>
<li>è¯¥æ–¹æ³•é™¤äº†æ£€æµ‹ä¹‹å¤–ï¼Œè¿˜å…è®¸å¯¹å›¾åƒè¿›è¡Œå®šæ€§åˆ†æï¼Œè¿™å¯ç”¨äºè¯†åˆ«å›¾åƒä¸­çš„ä¿®é¥°åŒºåŸŸã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•æ˜“äºå®ç°ï¼Œæ— éœ€ä»»ä½•è®­ç»ƒã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®¡ç®—æˆæœ¬è¾ƒä½ã€‚</li>
<li>è¯¥æ–¹æ³•çš„å­˜å‚¨æˆæœ¬è¾ƒä½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-73def9abeca6572820631d77d6d5f109.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e0d1888497ab3bcee223e776ab4c50c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0f0becc9eb676089a928342cf2a8f891.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-07174ef7ab315c814e5b835ccce3106c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2bf092448ab8005e13f25729d701b790.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8d473060909c4dac5e620acfb56465e2.jpg" align="middle">
</details>




<h2 id="Spatial-and-Frequency-aware-Restoration-method-for-Images-based-on-Diffusion-Models"><a href="#Spatial-and-Frequency-aware-Restoration-method-for-Images-based-on-Diffusion-Models" class="headerlink" title="Spatial-and-Frequency-aware Restoration method for Images based on   Diffusion Models"></a>Spatial-and-Frequency-aware Restoration method for Images based on   Diffusion Models</h2><p><strong>Authors:Kyungsung Lee, Donggyu Lee, Myungjoo Kang</strong></p>
<p>Diffusion models have recently emerged as a promising framework for Image Restoration (IR), owing to their ability to produce high-quality reconstructions and their compatibility with established methods. Existing methods for solving noisy inverse problems in IR, considers the pixel-wise data-fidelity. In this paper, we propose SaFaRI, a spatial-and-frequency-aware diffusion model for IR with Gaussian noise. Our model encourages images to preserve data-fidelity in both the spatial and frequency domains, resulting in enhanced reconstruction quality. We comprehensively evaluate the performance of our model on a variety of noisy inverse problems, including inpainting, denoising, and super-resolution. Our thorough evaluation demonstrates that SaFaRI achieves state-of-the-art performance on both the ImageNet datasets and FFHQ datasets, outperforming existing zero-shot IR methods in terms of LPIPS and FID metrics. </p>
<p><a href="http://arxiv.org/abs/2401.17629v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©é¢‘ä¸é¢‘åŸŸä¿¡æ¯å……åˆ†ç»“åˆçš„æ‰©æ•£æ¨¡å‹å›¾åƒå¤åŸæ–¹æ³• SaFaRI ä»¥é«˜ä¿çœŸæˆåƒèƒ½åŠ›è¾¾åˆ°å›¾åƒä¿®å¤çš„å½“å‰å…ˆè¿›æ°´å‡†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SaFaRI æ¨¡å‹åœ¨æ‰©æ•£æ¨¡å‹æ¡†æ¶ä¸‹ç»“åˆäº†å›¾åƒçš„ç©ºé—´åŸŸå’Œé¢‘åŸŸä¿¡æ¯ï¼Œæå‡äº†å›¾åƒä¿®å¤è´¨é‡ã€‚</li>
<li>åœ¨å„ç§å™ªå£°é€†é—®é¢˜ä¸Šï¼ŒåŒ…æ‹¬ä¿®å¤ã€å»å™ªå’Œè¶…åˆ†è¾¨ç‡ï¼ŒSaFaRI æ¨¡å‹å‡å–å¾—äº†æœ€ä¼˜æ€§èƒ½ã€‚</li>
<li>SaFaRI æ¨¡å‹åŒæ—¶åœ¨ ImageNet æ•°æ®é›†å’Œ FFHQ æ•°æ®é›†ä¸Šéƒ½ä¼˜äºå…¶ä»–é›¶æ ·æœ¬å›¾åƒä¿®å¤æ–¹æ³•ã€‚</li>
<li>SaFaRI æ¨¡å‹åœ¨ LPIPS å’Œ FID æŒ‡æ ‡ä¸Šå‡å–å¾—äº†æœ€ä¼˜æ€§èƒ½ã€‚</li>
<li>ä¸å…ˆå‰æ–¹æ³•ç›¸æ¯”ï¼ŒSaFaRI æ¨¡å‹èƒ½åœ¨æ›´å¥½åœ°æ¢å¤å›¾åƒç»†èŠ‚çš„åŒæ—¶æœ‰æ•ˆé™ä½å™ªå£°ã€‚</li>
<li>SaFaRI æ¨¡å‹åœ¨ç§»é™¤æ¤’ç›å™ªå£°å’Œä¿®å¤æŸåå›¾åƒæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
<li>SaFaRI æ¨¡å‹åœ¨è¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸­èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†ä½åˆ†è¾¨ç‡å›¾åƒè½¬æ¢æˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„ç©ºé—´å’Œé¢‘ç‡æ„ŸçŸ¥å›¾åƒä¿®å¤æ–¹æ³•</li>
<li>ä½œè€…ï¼šKyungsung Leeã€Donggyu Leeã€Myungjoo Kang</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦–å°”å¤§å­¦æ•°å­¦ç§‘å­¦ç³»</li>
<li>å…³é”®è¯ï¼šå›¾åƒä¿®å¤ã€æ‰©æ•£æ¨¡å‹ã€æ•°æ®ä¿çœŸåº¦ã€ç©ºé—´æ„ŸçŸ¥ã€é¢‘ç‡æ„ŸçŸ¥</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.17629</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒä¿®å¤æ—¨åœ¨ä»é€€åŒ–æˆ–æŸåçš„å›¾åƒä¸­é‡å»ºåŸå§‹å›¾åƒã€‚ç»å…¸æ–¹æ³•æ˜¯ä½¿ç”¨å˜åˆ†æ¨¡å‹ï¼Œå…¶ä¸­åŒ…æ‹¬æ•°æ®ä¿çœŸåº¦é¡¹å’Œæ­£åˆ™åŒ–é¡¹ã€‚æ‰©æ•£æ¨¡å‹ä½œä¸ºä¸€ç§æ–°å…´çš„ç”Ÿæˆæ¨¡å‹æ¡†æ¶ï¼Œåœ¨å›¾åƒä¿®å¤ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œå¯ä»¥å®ç°é›¶æ ·æœ¬å­¦ä¹ ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨åƒç´ çº§çš„æ•°æ®ä¿çœŸåº¦ï¼Œä½†å¿½ç•¥äº†æ„ŸçŸ¥ä¿¡æ¯ã€‚è¿™å¯¼è‡´ä¿®å¤åçš„å›¾åƒå¯èƒ½åœ¨è§†è§‰ä¸Šä¸ä»¤äººæ»¡æ„ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç©ºé—´å’Œé¢‘ç‡æ„ŸçŸ¥çš„æ‰©æ•£æ¨¡å‹ SaFaRIï¼Œç”¨äºé«˜æ–¯å™ªå£°ä¸‹çš„å›¾åƒä¿®å¤ã€‚è¯¥æ¨¡å‹é¼“åŠ±å›¾åƒåœ¨ç©ºé—´åŸŸå’Œé¢‘ç‡åŸŸéƒ½ä¿æŒæ•°æ®ä¿çœŸåº¦ï¼Œä»è€Œæé«˜é‡å»ºè´¨é‡ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ ImageNet å’Œ FFHQ æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒSaFaRI åœ¨ LPIPS å’Œ FID æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰çš„é›¶æ ·æœ¬å›¾åƒä¿®å¤æ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) SaFaRIæ¨¡å‹æ¡†æ¶ï¼šSaFaRIæ¨¡å‹ç”±ç¼–ç å™¨ã€æ‰©æ•£è¿‡ç¨‹å’Œè§£ç å™¨ç»„æˆã€‚ç¼–ç å™¨å°†é€€åŒ–å›¾åƒæ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œæ‰©æ•£è¿‡ç¨‹é€šè¿‡æ·»åŠ å™ªå£°é€æ¸å°†æ½œåœ¨è¡¨ç¤ºä»é€€åŒ–çŠ¶æ€è½¬æ¢åˆ°å¹²å‡€çŠ¶æ€ï¼Œè§£ç å™¨å°†å¹²å‡€çš„æ½œåœ¨è¡¨ç¤ºé‡å»ºä¸ºä¿®å¤åçš„å›¾åƒã€‚
(2) ç©ºé—´æ„ŸçŸ¥æ•°æ®ä¿çœŸåº¦ï¼šSaFaRIæ¨¡å‹åœ¨ç©ºé—´åŸŸä¸­ä½¿ç”¨å±€éƒ¨æ„ŸçŸ¥æŸå¤±æ¥é¼“åŠ±ä¿®å¤åçš„å›¾åƒä¸é€€åŒ–å›¾åƒåœ¨å±€éƒ¨åŒºåŸŸå†…ä¿æŒä¸€è‡´ã€‚å±€éƒ¨æ„ŸçŸ¥æŸå¤±é€šè¿‡è®¡ç®—é€€åŒ–å›¾åƒå’Œä¿®å¤å›¾åƒåœ¨å±€éƒ¨åŒºåŸŸå†…çš„å·®å¼‚æ¥è¡¡é‡æ•°æ®ä¿çœŸåº¦ã€‚
(3) é¢‘ç‡æ„ŸçŸ¥æ•°æ®ä¿çœŸåº¦ï¼šSaFaRIæ¨¡å‹åœ¨é¢‘ç‡åŸŸä¸­ä½¿ç”¨é¢‘è°±æŸå¤±æ¥é¼“åŠ±ä¿®å¤åçš„å›¾åƒä¸é€€åŒ–å›¾åƒåœ¨é¢‘ç‡åˆ†å¸ƒä¸Šä¿æŒä¸€è‡´ã€‚é¢‘è°±æŸå¤±é€šè¿‡è®¡ç®—é€€åŒ–å›¾åƒå’Œä¿®å¤å›¾åƒçš„é¢‘è°±å·®å¼‚æ¥è¡¡é‡æ•°æ®ä¿çœŸåº¦ã€‚
(4) æ‰©æ•£è¿‡ç¨‹ï¼šSaFaRIæ¨¡å‹é‡‡ç”¨éå¯¹ç§°æ‰©æ•£è¿‡ç¨‹ï¼Œå³æ­£å‘æ‰©æ•£è¿‡ç¨‹å’Œåå‘æ‰©æ•£è¿‡ç¨‹ã€‚æ­£å‘æ‰©æ•£è¿‡ç¨‹å°†æ½œåœ¨è¡¨ç¤ºä»é€€åŒ–çŠ¶æ€é€æ¸è½¬æ¢åˆ°å¹²å‡€çŠ¶æ€ï¼Œåå‘æ‰©æ•£è¿‡ç¨‹å°†æ½œåœ¨è¡¨ç¤ºä»å¹²å‡€çŠ¶æ€é€æ¸è½¬æ¢åˆ°é€€åŒ–çŠ¶æ€ã€‚
(5) è®­ç»ƒè¿‡ç¨‹ï¼šSaFaRIæ¨¡å‹é€šè¿‡æœ€å°åŒ–æ€»æŸå¤±å‡½æ•°æ¥è®­ç»ƒï¼Œæ€»æŸå¤±å‡½æ•°åŒ…æ‹¬å±€éƒ¨æ„ŸçŸ¥æŸå¤±ã€é¢‘è°±æŸå¤±å’Œæ­£åˆ™åŒ–æŸå¤±ã€‚æ­£åˆ™åŒ–æŸå¤±ç”¨äºé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼š æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒä¿®å¤æ–¹æ³• SaFaRIï¼Œè¯¥æ–¹æ³•å°†ç©ºé—´å’Œé¢‘ç‡ä¿¡æ¯çº³å…¥æ•°æ®ä¿çœŸåº¦é¡¹ä¸­ï¼Œæœ‰æ•ˆæé«˜äº†ä¿®å¤æ€§èƒ½ã€‚é€šè¿‡åˆ©ç”¨åŒä¸‰æ¬¡æ’å€¼å’Œå‚…é‡Œå¶å˜æ¢åŒæ—¶åˆ©ç”¨ç©ºé—´å’Œé¢‘ç‡ä¿¡æ¯ï¼ŒSaFaRI åœ¨å„ç§å›¾åƒä¿®å¤åŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚å°½ç®¡æˆ‘ä»¬æå‡ºçš„æ–¹æ³•å…·æœ‰æ˜¾ç€çš„æ€§èƒ½ï¼Œä½†ç”±äºå…ˆéªŒé¡¹çš„å½±å“ï¼Œå˜æ¢çš„åº”ç”¨ä¸å¯é¿å…åœ°ä¼šå¯¹å¯è¡Œè§£äº§ç”Ÿæ‰°åŠ¨ã€‚å¯¹è§£æ‰°åŠ¨çš„å…¨é¢åˆ†æå¯ä»¥åŠ å¼ºæˆ‘ä»¬æ–¹æ³•è®ºçš„ç†è®ºåŸºç¡€ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼š åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒä¿®å¤æ–¹æ³• SaFaRIï¼Œè¯¥æ–¹æ³•å°†ç©ºé—´å’Œé¢‘ç‡ä¿¡æ¯çº³å…¥æ•°æ®ä¿çœŸåº¦é¡¹ä¸­ï¼Œæœ‰æ•ˆæé«˜äº†ä¿®å¤æ€§èƒ½ã€‚</li>
<li>SaFaRI åˆ©ç”¨åŒä¸‰æ¬¡æ’å€¼å’Œå‚…é‡Œå¶å˜æ¢åŒæ—¶åˆ©ç”¨ç©ºé—´å’Œé¢‘ç‡ä¿¡æ¯ï¼Œå¯ä»¥æ›´å¥½åœ°ä¿ç•™å›¾åƒçš„ç»†èŠ‚å’Œçº¹ç†ã€‚</li>
<li>SaFaRI é‡‡ç”¨éå¯¹ç§°æ‰©æ•£è¿‡ç¨‹ï¼Œå¯ä»¥æ›´å¥½åœ°æ§åˆ¶å›¾åƒä¿®å¤è¿‡ç¨‹ï¼Œæé«˜ä¿®å¤è´¨é‡ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>SaFaRI åœ¨ ImageNet å’Œ FFHQ æ•°æ®é›†ä¸Šçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œåœ¨ LPIPS å’Œ FID æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰çš„é›¶æ ·æœ¬å›¾åƒä¿®å¤æ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>SaFaRI åœ¨ä¿®å¤é«˜æ–¯å™ªå£°å›¾åƒæ—¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å»é™¤å™ªå£°ï¼ŒåŒæ—¶ä¿ç•™å›¾åƒçš„ç»†èŠ‚å’Œçº¹ç†ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>SaFaRI æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹ç®€å•ï¼Œæ˜“äºå®ç°ã€‚</li>
<li>SaFaRI æ¨¡å‹çš„å‚æ•°é‡è¾ƒå°‘ï¼Œå¯ä»¥å¿«é€Ÿè®­ç»ƒå’Œæ¨ç†ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d12c8ba98ed6bf34752247f9b5d4ed94.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-841cc516755a816daa1feb35b6020929.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6047f95584cb41e2634a1d794c58b933.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0e2b66f6263c96cab5ccac11907563d1.jpg" align="middle">
</details>




## You Only Need One Step: Fast Super-Resolution with Stable Diffusion via   Scale Distillation

**Authors:Mehdi Noroozi, Isma Hadji, Brais Martinez, Adrian Bulat, Georgios Tzimiropoulos**

In this paper, we introduce YONOS-SR, a novel stable diffusion-based approach for image super-resolution that yields state-of-the-art results using only a single DDIM step. We propose a novel scale distillation approach to train our SR model. Instead of directly training our SR model on the scale factor of interest, we start by training a teacher model on a smaller magnification scale, thereby making the SR problem simpler for the teacher. We then train a student model for a higher magnification scale, using the predictions of the teacher as a target during the training. This process is repeated iteratively until we reach the target scale factor of the final model. The rationale behind our scale distillation is that the teacher aids the student diffusion model training by i) providing a target adapted to the current noise level rather than using the same target coming from ground truth data for all noise levels and ii) providing an accurate target as the teacher has a simpler task to solve. We empirically show that the distilled model significantly outperforms the model trained for high scales directly, specifically with few steps during inference. Having a strong diffusion model that requires only one step allows us to freeze the U-Net and fine-tune the decoder on top of it. We show that the combination of spatially distilled U-Net and fine-tuned decoder outperforms state-of-the-art methods requiring 200 steps with only one single step. 

[PDF](http://arxiv.org/abs/2401.17258v1) 

**Summary**
æ‰©æ•£æ¨¡å‹çš„å•æ­¥è¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼ŒYONO-SRï¼Œé€šè¿‡è’¸é¦è®­ç»ƒï¼Œå¯å®ç°å›¾åƒåˆ†è¾¨ç‡çš„æå‡ã€‚

**Key Takeaways**
- YONOS-SR åœ¨ä¿æŒæ¨ç†é€Ÿåº¦çš„åŒæ—¶ï¼Œå®ç°é«˜è´¨é‡çš„å›¾åƒè¶…åˆ†è¾¨ç‡ã€‚
- å¼•å…¥ä¸€ç§æ–°çš„å°ºåº¦è’¸é¦æ–¹æ³•ï¼Œä»è¾ƒå°çš„å°ºåº¦å¼€å§‹è®­ç»ƒæ•™å¸ˆæ¨¡å‹ï¼Œç„¶åé‡‡ç”¨è¿­ä»£çš„æ–¹å¼å°†çŸ¥è¯†è¿ç§»åˆ°å­¦ç”Ÿæ¨¡å‹ã€‚
- è’¸é¦è®­ç»ƒä½¿å­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿè·å¾—æ›´å‡†ç¡®çš„ç›®æ ‡ï¼Œä»è€Œæé«˜äº†è¶…åˆ†è¾¨ç‡çš„æ€§èƒ½ã€‚
- åªéœ€ä¸€æ­¥æ¨ç†ï¼ŒYONOS-SR å°±èƒ½å¤Ÿè¶…è¶Šéœ€è¦ 200 æ­¥çš„æœ€æ–°æ–¹æ³•ã€‚
- YONOS-SR ç»“åˆäº†ç©ºé—´è’¸é¦çš„ U-Net å’Œå¾®è°ƒçš„è§£ç å™¨ï¼Œè¿›ä¸€æ­¥æé«˜äº†è¶…åˆ†è¾¨ç‡æ•ˆæœã€‚
- å†»ç»“ U-Net å¹¶å¾®è°ƒè§£ç å™¨ï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡è¶…åˆ†è¾¨ç‡æ€§èƒ½ã€‚
- YONOS-SR å¯¹äºè®¡ç®—èµ„æºå—é™çš„è®¾å¤‡éå¸¸é€‚ç”¨ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šä¸€æ­¥åˆ°ä½ï¼šé€šè¿‡å°ºåº¦è’¸é¦å®ç°ç¨³å®šæ‰©æ•£çš„å¿«é€Ÿè¶…åˆ†è¾¨ç‡</li>
<li>ä½œè€…ï¼šMehdi Noroozi, Isma Hadji, Brais Martinez, Adrian Bulat, Georgios Tzimiropoulos</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸‰æ˜ŸAIå‰‘æ¡¥</li>
<li>å…³é”®è¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡ã€ç¨³å®šæ‰©æ•£ã€å°ºåº¦è’¸é¦ã€æ·±åº¦å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.17258</li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨å„ç§å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬å›¾åƒè¶…åˆ†è¾¨ç‡ã€‚ç„¶è€Œï¼Œé‡‡æ ·ç­–ç•¥æ‰€éœ€çš„è¿ç»­å»å™ªä¼ é€’æ•°é‡å¾ˆå¤§ï¼Œå³ä½¿å¯¹äºåœ¨è‡ªåŠ¨ç¼–ç å™¨æ½œåœ¨ç©ºé—´ä¸­è¿è¡Œçš„åŸºäºç¨³å®šæ‰©æ•£çš„æ¨¡å‹ï¼ˆSDï¼‰ä¹Ÿæ˜¯å¦‚æ­¤ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šæœ€è¿‘ï¼Œå·²ç»æå‡ºäº†å‡ ç§å‡å°‘é‡‡æ ·æ­¥éª¤æ•°é‡çš„æ–¹æ³•ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä¼šå½±å“æ€§èƒ½ï¼Œå°¤å…¶æ˜¯å¯¹äºè¾ƒå°‘çš„æ­¥éª¤ã€‚åŸºäºæ‰©æ•£çš„æ¨¡å‹é€šå¸¸åœ¨ä¸è®­ç»ƒæœŸé—´çœ‹åˆ°çš„å¤§å°ç›¸ä¼¼çš„å›¾åƒå—ä¸Šäº§ç”Ÿæœ€ä½³ç»“æœï¼ˆä¾‹å¦‚ï¼ŒSD çš„ 64Ã—64ï¼‰ã€‚å¦ä¸€æ–¹é¢ï¼Œè¶…åˆ†è¾¨ç‡åº”ç”¨ç¨‹åºéœ€è¦åœ¨é«˜åˆ†è¾¨ç‡è®¾ç½®ä¸­è¿è¡Œï¼Œè¿™å¤§å¤§åŠ å‰§äº†åŸºäºæ‰©æ•£æ¨¡å‹çš„è®¡ç®—é—®é¢˜ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è®­ç»ƒç­–ç•¥ï¼Œç§°ä¸ºå°ºåº¦è’¸é¦ã€‚å…¸å‹çš„åŸºäºæ‰©æ•£çš„è¶…åˆ†è¾¨ç‡æ–¹æ³•é€šè¿‡ç›´æ¥åœ¨ç›®æ ‡å°ºåº¦å› å­ä¸Šçš„ä½åˆ†è¾¨ç‡å›¾åƒä¸Šè¿›è¡Œæ¡ä»¶æ¥è®­ç»ƒè¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼Œè€Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¸è¿›å¼è®­ç»ƒæ–¹æ³•ï¼Œä»è¾ƒä½å°ºåº¦å› å­ï¼ˆå³æ¡ä»¶ä¿¡å·æ›´æ¥è¿‘ç›®æ ‡ï¼‰å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨å…ˆå‰è®­ç»ƒçš„æ¨¡å‹ä½œä¸ºæ•™å¸ˆé€æ­¥å¢åŠ åˆ°ç›®æ ‡å°ºåº¦å› å­ã€‚
(4) æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ä»…ä¸€æ­¥ DDIM å³å¯å®ç°æœ€å…ˆè¿›çš„ç»“æœã€‚é€šè¿‡å¯¹æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹è¿›è¡Œæ¡ä»¶è®¾ç½®ï¼Œå¯ä»¥è®­ç»ƒå‡ºä¸€ä¸ªå¼ºå¤§çš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åªéœ€è¦ä¸€æ­¥å³å¯å†»ç»“ U-Net å¹¶å¾®è°ƒå…¶ä¸Šçš„è§£ç å™¨ã€‚å®éªŒè¡¨æ˜ï¼Œç©ºé—´è’¸é¦ U-Net å’Œå¾®è°ƒè§£ç å™¨çš„ç»„åˆä»…éœ€ä¸€æ­¥å³å¯ä¼˜äºéœ€è¦ 200 æ­¥çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå°ºåº¦è’¸é¦çš„å¿«é€Ÿç¨³å®šæ‰©æ•£è¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥é€šè¿‡ä¸€æ­¥DDIMå®ç°æœ€å…ˆè¿›çš„ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„è®­ç»ƒç­–ç•¥â€”â€”å°ºåº¦è’¸é¦ï¼Œè¯¥ç­–ç•¥å¯ä»¥å°†åŸºäºç¨³å®šæ‰©æ•£çš„è¶…åˆ†è¾¨ç‡æ¨¡å‹è®­ç»ƒåˆ°ä»…éœ€è¦ä¸€æ­¥å³å¯ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚</li>
<li>é€šè¿‡å¯¹æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹è¿›è¡Œæ¡ä»¶è®¾ç½®ï¼Œå¯ä»¥è®­ç»ƒå‡ºä¸€ä¸ªå¼ºå¤§çš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åªéœ€è¦ä¸€æ­¥å³å¯å†»ç»“U-Netå¹¶å¾®è°ƒå…¶ä¸Šçš„è§£ç å™¨ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ä»…ä¸€æ­¥DDIMå³å¯å®ç°æœ€å…ˆè¿›çš„ç»“æœã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œç©ºé—´è’¸é¦U-Netå’Œå¾®è°ƒè§£ç å™¨çš„ç»„åˆä»…éœ€ä¸€æ­¥å³å¯ä¼˜äºéœ€è¦200æ­¥çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹ç®€å•ï¼Œåªéœ€è¦å¯¹æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹è¿›è¡Œæ¡ä»¶è®¾ç½®ï¼Œç„¶åå†»ç»“U-Netå¹¶å¾®è°ƒå…¶ä¸Šçš„è§£ç å™¨å³å¯ã€‚</li>
<li>è¯¥æ–¹æ³•çš„æ¨ç†è¿‡ç¨‹ä¹Ÿéå¸¸å¿«é€Ÿï¼Œåªéœ€è¦ä¸€æ­¥DDIMå³å¯ç”Ÿæˆé«˜è´¨é‡å›¾åƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-66d1c3043943daf87e1f11e232a38f98.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5920453c69c00995f18077b22d4a790e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-506663e69d7322407f5094b321bf2044.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/02/09/Paper/2024-02-09/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-09-æ›´æ–°"><a href="#2024-02-09-æ›´æ–°" class="headerlink" title="2024-02-09 æ›´æ–°"></a>2024-02-09 æ›´æ–°</h1><h2 id="Rig3DGS-Creating-Controllable-Portraits-from-Casual-Monocular-Videos"><a href="#Rig3DGS-Creating-Controllable-Portraits-from-Casual-Monocular-Videos" class="headerlink" title="Rig3DGS: Creating Controllable Portraits from Casual Monocular Videos"></a>Rig3DGS: Creating Controllable Portraits from Casual Monocular Videos</h2><p><strong>Authors:Alfredo Rivero, ShahRukh Athar, Zhixin Shu, Dimitris Samaras</strong></p>
<p>Creating controllable 3D human portraits from casual smartphone videos is highly desirable due to their immense value in AR/VR applications. The recent development of 3D Gaussian Splatting (3DGS) has shown improvements in rendering quality and training efficiency. However, it still remains a challenge to accurately model and disentangle head movements and facial expressions from a single-view capture to achieve high-quality renderings. In this paper, we introduce Rig3DGS to address this challenge. We represent the entire scene, including the dynamic subject, using a set of 3D Gaussians in a canonical space. Using a set of control signals, such as head pose and expressions, we transform them to the 3D space with learned deformations to generate the desired rendering. Our key innovation is a carefully designed deformation method which is guided by a learnable prior derived from a 3D morphable model. This approach is highly efficient in training and effective in controlling facial expressions, head positions, and view synthesis across various captures. We demonstrate the effectiveness of our learned deformation through extensive quantitative and qualitative experiments. The project page can be found at <a href="http://shahrukhathar.github.io/2024/02/05/Rig3DGS.html">http://shahrukhathar.github.io/2024/02/05/Rig3DGS.html</a> </p>
<p><a href="http://arxiv.org/abs/2402.03723v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>3D é«˜æ–¯æ•£ç‚¹ï¼ˆ3DGSï¼‰çš„å¼€å‘æ”¹å–„äº†æ¸²æŸ“è´¨é‡å’Œè®­ç»ƒæ•ˆç‡ï¼Œåˆ©ç”¨å¯å­¦ä¹ çš„ 3D å¯å˜å½¢æ¨¡å‹æŒ‡å¯¼çš„å˜å½¢æ–¹æ³•èƒ½å¤Ÿå‡†ç¡®å»ºæ¨¡å’Œåˆ†ç¦»å¤´éƒ¨è¿åŠ¨åŠé¢éƒ¨è¡¨æƒ…ã€‚</p>
<p><strong>ä¸»è¦è¦ç‚¹</strong></p>
<ul>
<li>3DGS åœ¨ AR/VR åº”ç”¨ä¸­å…·æœ‰å·¨å¤§ä»·å€¼ï¼Œå› ä¸ºå®ƒä»¬èƒ½å¤Ÿä»ä¼‘é—²æ™ºèƒ½æ‰‹æœºè§†é¢‘ä¸­åˆ›å»ºå¯æ§çš„ 3D äººåƒã€‚</li>
</ul>
<ul>
<li>3DGS åœ¨æ¸²æŸ“è´¨é‡å’Œè®­ç»ƒæ•ˆç‡æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†ä»ç„¶éš¾ä»¥ä»å•è§†å›¾æ•æ‰ä¸­å‡†ç¡®å»ºæ¨¡å’Œåˆ†ç¦»å¤´éƒ¨è¿åŠ¨å’Œé¢éƒ¨è¡¨æƒ…ä»¥å®ç°é«˜è´¨é‡æ¸²æŸ“ã€‚</li>
</ul>
<ul>
<li>Rig3DGS ä½¿ç”¨ä¸€ç»„ 3D é«˜æ–¯åˆ†å¸ƒåœ¨è§„èŒƒç©ºé—´ä¸­è¡¨ç¤ºæ•´ä¸ªåœºæ™¯ï¼ŒåŒ…æ‹¬åŠ¨æ€ä¸»ä½“ã€‚</li>
</ul>
<ul>
<li>Rig3DGS ä½¿ç”¨ä¸€ç»„æ§åˆ¶ä¿¡å·ï¼Œä¾‹å¦‚å¤´éƒ¨å§¿åŠ¿å’Œè¡¨æƒ…ï¼Œå°†å…¶è½¬æ¢ä¸º 3D ç©ºé—´ï¼Œå¹¶é€šè¿‡å­¦ä¹ åˆ°çš„å˜å½¢æ¥ç”Ÿæˆæ‰€éœ€çš„æ¸²æŸ“ã€‚</li>
</ul>
<ul>
<li>Rig3DGS çš„å…³é”®åˆ›æ–°åœ¨äºä¸€ç§ç»è¿‡ç²¾å¿ƒè®¾è®¡çš„å˜å½¢æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç”±æºè‡ª 3D å¯å˜å½¢æ¨¡å‹çš„å¯å­¦ä¹ å…ˆéªŒå¼•å¯¼ã€‚</li>
</ul>
<ul>
<li>è¿™ç§æ–¹æ³•åœ¨è®­ç»ƒä¸­éå¸¸æœ‰æ•ˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æ§åˆ¶å„ç§æ•æ‰ä¸­çš„é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨ä½ç½®å’Œè§†å›¾åˆæˆã€‚</li>
</ul>
<ul>
<li>é€šè¿‡å¹¿æ³›çš„å®šé‡å’Œå®šæ€§å®éªŒè¯æ˜äº† Rig3DGS çš„å­¦ä¹ å˜å½¢æ˜¯æœ‰æ•ˆçš„ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šRig3DGSï¼šä»éšæ„å•ç›®è§†é¢‘åˆ›å»ºå¯æ§è‚–åƒ</li>
<li>ä½œè€…ï¼šAlfredo Rivero<em>, Shah Rukh Athar</em>, Zhixin Shu, Dimitris Samaras</li>
<li>å•ä½ï¼šçº½çº¦çŸ³æºªå¤§å­¦</li>
<li>å…³é”®è¯ï¼š3Däººåƒã€3Dé«˜æ–¯å–·ç»˜ã€å¯æ§å˜å½¢ã€å¤´éƒ¨å§¿æ€ã€é¢éƒ¨è¡¨æƒ…ã€è§†è§’åˆæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.03723
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šåˆ›å»ºå¯æ§çš„ 3D äººç±»è‚–åƒå¯¹äºå„ç§æ²‰æµ¸å¼ä½“éªŒè‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬è™šæ‹Ÿç°å®ã€è¿œç¨‹ä¸´åœºã€ç”µå½±åˆ¶ä½œå’Œæ•™è‚²åº”ç”¨ã€‚ç„¶è€Œï¼Œä»…ä½¿ç”¨åŸºæœ¬æ™ºèƒ½æ‰‹æœºæ‘„åƒå¤´ï¼Œæ™®é€šæ¶ˆè´¹è€…å®ç°è¿™é¡¹æŠ€æœ¯é¢ä¸´ç€ç›¸å½“å¤§çš„æŒ‘æˆ˜ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šä»è§†é¢‘ä¸­å»ºæ¨¡ 3D å¯æ§è‚–åƒé€šå¸¸æ¶‰åŠåŠ¨æ€äººç±»ä¸»ä½“çš„æ˜¾å¼æˆ–éšå¼é…å‡†ï¼Œè€ƒè™‘æ¯ä¸ªå¸§ä¸­é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ç­‰ä¸åŒå› ç´ ã€‚è¿™ä¸ªè¿‡ç¨‹éœ€è¦ç²¾ç¡®åŒºåˆ†ç”±è¿™äº›å› ç´ å¼•èµ·çš„é¢éƒ¨å˜å½¢ï¼Œè¿™åœ¨æ²¡æœ‰çœŸå®ä¾æ®çš„æƒ…å†µä¸‹é€šå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å½“ä½¿ç”¨å•ç›®æ•æ‰æ—¶ï¼ŒæŒ‘æˆ˜è¿›ä¸€æ­¥åŠ å‰§ï¼Œå› ä¸ºæ¯ä¸ªå¤´éƒ¨å§¿åŠ¿å’Œè¡¨æƒ…åªèƒ½ä»å•ä¸ªè§†ç‚¹çœ‹åˆ°ï¼Œè¿™ä½¿å¾—å‡†ç¡®çš„åŒºåˆ†å˜å¾—æ›´åŠ å¤æ‚ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º Rig3DGS æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ç»„ 3D é«˜æ–¯ä½“åœ¨è§„èŒƒç©ºé—´ä¸­è¡¨ç¤ºæ•´ä¸ªåœºæ™¯ï¼ŒåŒ…æ‹¬åŠ¨æ€ä¸»ä½“ã€‚ä½¿ç”¨ä¸€ç»„æ§åˆ¶ä¿¡å·ï¼Œä¾‹å¦‚å¤´éƒ¨å§¿åŠ¿å’Œè¡¨æƒ…ï¼Œæˆ‘ä»¬åˆ©ç”¨å­¦ä¹ åˆ°çš„å˜å½¢å°†å®ƒä»¬è½¬æ¢ä¸º 3D ç©ºé—´ä»¥ç”Ÿæˆæ‰€éœ€çš„æ¸²æŸ“ã€‚æˆ‘ä»¬çš„å…³é”®åˆ›æ–°æ˜¯ä¸€ç§ç²¾å¿ƒè®¾è®¡çš„å˜å½¢æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç”±ä» 3D å¯å˜å½¢æ¨¡å‹æ´¾ç”Ÿçš„å¯å­¦ä¹ å…ˆéªŒå¼•å¯¼ã€‚è¿™ç§æ–¹æ³•åœ¨è®­ç»ƒä¸­éå¸¸æœ‰æ•ˆï¼Œå¹¶ä¸”èƒ½å¤Ÿæ§åˆ¶é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨ä½ç½®å’Œè·¨å„ç§æ•æ‰çš„è§†è§’åˆæˆã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬é€šè¿‡å¹¿æ³›çš„å®šé‡å’Œå®šæ€§å®éªŒè¯æ˜äº†æˆ‘ä»¬å­¦ä¹ åˆ°çš„å˜å½¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥é¡¹ç›®é¡µé¢å¯åœ¨æ­¤å¤„æ‰¾åˆ°ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): Rig3DGS ä½¿ç”¨ä¸€ç»„ 3D é«˜æ–¯ä½“è¡¨ç¤ºæ•´ä¸ªåœºæ™¯ï¼ŒåŒ…æ‹¬åŠ¨æ€ä¸»ä½“ï¼Œå¹¶ä½¿ç”¨ä¸€ç»„æ§åˆ¶ä¿¡å·ï¼ˆå¦‚å¤´éƒ¨å§¿åŠ¿å’Œè¡¨æƒ…ï¼‰å°†å®ƒä»¬è½¬æ¢ä¸º 3D ç©ºé—´ä»¥ç”Ÿæˆæ‰€éœ€çš„æ¸²æŸ“ã€‚
(2): Rig3DGS çš„å…³é”®åˆ›æ–°æ˜¯ä¸€ç§ç²¾å¿ƒè®¾è®¡çš„å˜å½¢æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç”±ä» 3D å¯å˜å½¢æ¨¡å‹æ´¾ç”Ÿçš„å¯å­¦ä¹ å…ˆéªŒå¼•å¯¼ã€‚
(3): è¯¥æ–¹æ³•åœ¨è®­ç»ƒä¸­éå¸¸æœ‰æ•ˆï¼Œå¹¶ä¸”èƒ½å¤Ÿæ§åˆ¶é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨ä½ç½®å’Œè·¨å„ç§æ•æ‰çš„è§†è§’åˆæˆã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º Rig3DGS çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¯¹è‚–åƒè§†é¢‘è¿›è¡Œä»»æ„é¢éƒ¨è¡¨æƒ…æ§åˆ¶å’Œæ–°è§†è§’åˆæˆã€‚Rig3DGS ä½¿ç”¨å¯å­¦ä¹ çš„å˜å½¢å…ˆéªŒæ¥ç¡®ä¿åœ¨è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§å’Œå¯¹æ–°é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿åŠ¿å’Œè§†è§’çš„ä¸€èˆ¬åŒ–ã€‚Rig3DGS è¿˜èƒ½å¤Ÿå¯¹æ‹æ‘„å¯¹è±¡çš„å¤´å‘å’Œçœ¼é•œç­‰é¢éƒ¨ç»†èŠ‚è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶åœ¨è§†é¢‘è¢«é©±åŠ¨æ—¶ä»¥é«˜ä¿çœŸåº¦å†ç°å®ƒä»¬ã€‚ä½†æ˜¯ï¼Œå…·æœ‰æ–°è§†è§’åˆæˆçš„å¯æ§äººå¤´éƒ¨æ¨¡å‹çš„é—®é¢˜è¿˜è¿œæœªè§£å†³ã€‚Rig3DGS æ— æ³•å¯¹å¼ºçƒˆçš„éå‡åŒ€å…‰ç…§è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶ä¸”è¦æ±‚è‚–åƒè§†é¢‘ä¸­çš„æ‹æ‘„å¯¹è±¡åœ¨æ‹æ‘„æœŸé—´ä¿æŒç›¸å¯¹é™æ­¢ã€‚æˆ‘ä»¬å¸Œæœ›åœ¨æœªæ¥çš„å·¥ä½œä¸­è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
ï¼ˆ1ï¼‰æå‡ºäº† Rig3DGSï¼Œä¸€ç§ä½¿ç”¨ä¸€ç»„ 3D é«˜æ–¯ä½“è¡¨ç¤ºæ•´ä¸ªåœºæ™¯ï¼ˆåŒ…æ‹¬åŠ¨æ€ä¸»ä½“ï¼‰çš„æ–¹æ³•ï¼Œå¹¶ä½¿ç”¨ä¸€ç»„æ§åˆ¶ä¿¡å·ï¼ˆå¦‚å¤´éƒ¨å§¿åŠ¿å’Œè¡¨æƒ…ï¼‰å°†å®ƒä»¬è½¬æ¢ä¸º 3D ç©ºé—´ä»¥ç”Ÿæˆæ‰€éœ€çš„æ¸²æŸ“ã€‚
ï¼ˆ2ï¼‰æå‡ºäº†ä¸€ç§ç²¾å¿ƒè®¾è®¡çš„å˜å½¢æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç”±ä» 3D å¯å˜å½¢æ¨¡å‹æ´¾ç”Ÿçš„å¯å­¦ä¹ å…ˆéªŒå¼•å¯¼ã€‚
ï¼ˆ3ï¼‰è¯æ˜äº†è¯¥æ–¹æ³•èƒ½å¤Ÿæ§åˆ¶é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨ä½ç½®å’Œè·¨å„ç§æ•æ‰çš„è§†è§’åˆæˆã€‚
æ€§èƒ½ï¼š
ï¼ˆ1ï¼‰Rig3DGS èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 3D è‚–åƒï¼Œå…·æœ‰é€¼çœŸçš„é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿åŠ¿å’Œè§†è§’ã€‚
ï¼ˆ2ï¼‰Rig3DGS èƒ½å¤Ÿåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ç…§æ˜æ¡ä»¶ä¸‹å·¥ä½œï¼Œä¾‹å¦‚å¼ºçƒˆçš„éå‡åŒ€å…‰ç…§ã€‚
ï¼ˆ3ï¼‰Rig3DGS èƒ½å¤Ÿå®æ—¶è¿è¡Œï¼Œä½¿å…¶é€‚ç”¨äºå„ç§åº”ç”¨ç¨‹åºã€‚
å·¥ä½œé‡ï¼š
ï¼ˆ1ï¼‰Rig3DGS çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹ç®€å•ä¸”ç›´æ¥ã€‚
ï¼ˆ2ï¼‰Rig3DGS æ˜“äºä½¿ç”¨ï¼Œå¹¶ä¸”ä¸éœ€è¦ä»»ä½•ä¸“é—¨çš„ç¡¬ä»¶æˆ–è½¯ä»¶ã€‚
ï¼ˆ3ï¼‰Rig3DGS æ˜¯å¼€æºçš„ï¼Œå¯ä»¥å…è´¹ä½¿ç”¨ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3161a0632f560b62291a8cf525616b2c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d6843ee2a991081c82505388c065defc.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-28074a5f13fdf5a52c0d4de04dfb9406.jpg" align="middle">
</details>




<h2 id="4D-Gaussian-Splatting-Towards-Efficient-Novel-View-Synthesis-for-Dynamic-Scenes"><a href="#4D-Gaussian-Splatting-Towards-Efficient-Novel-View-Synthesis-for-Dynamic-Scenes" class="headerlink" title="4D Gaussian Splatting: Towards Efficient Novel View Synthesis for   Dynamic Scenes"></a>4D Gaussian Splatting: Towards Efficient Novel View Synthesis for   Dynamic Scenes</h2><p><strong>Authors:Yuanxing Duan, Fangyin Wei, Qiyu Dai, Yuhang He, Wenzheng Chen, Baoquan Chen</strong></p>
<p>We consider the problem of novel view synthesis (NVS) for dynamic scenes. Recent neural approaches have accomplished exceptional NVS results for static 3D scenes, but extensions to 4D time-varying scenes remain non-trivial. Prior efforts often encode dynamics by learning a canonical space plus implicit or explicit deformation fields, which struggle in challenging scenarios like sudden movements or capturing high-fidelity renderings. In this paper, we introduce 4D Gaussian Splatting (4DGS), a novel method that represents dynamic scenes with anisotropic 4D XYZT Gaussians, inspired by the success of 3D Gaussian Splatting in static scenes. We model dynamics at each timestamp by temporally slicing the 4D Gaussians, which naturally compose dynamic 3D Gaussians and can be seamlessly projected into images. As an explicit spatial-temporal representation, 4DGS demonstrates powerful capabilities for modeling complicated dynamics and fine details, especially for scenes with abrupt motions. We further implement our temporal slicing and splatting techniques in a highly optimized CUDA acceleration framework, achieving real-time inference rendering speeds of up to 277 FPS on an RTX 3090 GPU and 583 FPS on an RTX 4090 GPU. Rigorous evaluations on scenes with diverse motions showcase the superior efficiency and effectiveness of 4DGS, which consistently outperforms existing methods both quantitatively and qualitatively. </p>
<p><a href="http://arxiv.org/abs/2402.03307v2">PDF</a> </p>
<p><strong>Summary</strong><br>åŠ¨æ€åœºæ™¯ä¸‹æ–°è§†è§’åˆæˆæ–¹æ³• 4DGSï¼ŒåŸºäºé«˜æ–¯ä½“ç´ æ—¶ç©ºåˆ‡ç‰‡è¡¨ç¤ºå®ç°äº†å¿«é€Ÿçš„åŠ¨æ€åœºæ™¯æ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>4DGS æ˜¯ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œå®ƒä½¿ç”¨å„å‘å¼‚æ€§çš„ 4D XYZT é«˜æ–¯ä½“ç´ æ¥è¡¨ç¤ºåŠ¨æ€åœºæ™¯ã€‚</li>
<li>4DGS é€šè¿‡å¯¹ 4D é«˜æ–¯ä½“ç´ è¿›è¡Œæ—¶é—´åˆ‡ç‰‡æ¥å»ºæ¨¡æ¯ä¸ªæ—¶é—´æˆ³çš„åŠ¨æ€ï¼Œä»è€Œè‡ªç„¶åœ°æ„æˆåŠ¨æ€ 3D é«˜æ–¯ä½“ç´ å¹¶å¯ä»¥æ— ç¼åœ°æŠ•å½±åˆ°å›¾åƒä¸­ã€‚</li>
<li>ä½œä¸ºä¸€ç§æ˜¾å¼çš„æ—¶ç©ºè¡¨ç¤ºï¼Œ4DGS åœ¨å»ºæ¨¡å¤æ‚åŠ¨æ€å’Œç²¾ç»†ç»†èŠ‚æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯å¯¹äºå…·æœ‰çªç„¶è¿åŠ¨çš„åœºæ™¯ã€‚</li>
<li>4DGS åœ¨é«˜åº¦ä¼˜åŒ–çš„ CUDA åŠ é€Ÿæ¡†æ¶ä¸­å®ç°äº†æ—¶é—´åˆ‡ç‰‡å’Œ splatting æŠ€æœ¯ï¼Œåœ¨ RTX 3090 GPU ä¸Šå®ç°äº†é«˜è¾¾ 277 FPS çš„å®æ—¶æ¨ç†æ¸²æŸ“é€Ÿåº¦ï¼Œåœ¨ RTX 4090 GPU ä¸Šå®ç°äº† 583 FPS çš„å®æ—¶æ¨ç†æ¸²æŸ“é€Ÿåº¦ã€‚</li>
<li>åœ¨å…·æœ‰ä¸åŒè¿åŠ¨çš„åœºæ™¯ä¸Šçš„ä¸¥æ ¼è¯„ä¼°è¡¨æ˜ï¼Œ4DGS çš„æ•ˆç‡å’Œæœ‰æ•ˆæ€§ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ— è®ºæ˜¯åœ¨å®šé‡è¿˜æ˜¯å®šæ€§æ–¹é¢éƒ½å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>4DGS å¯ä»¥è½»æ¾æ‰©å±•åˆ°å„ç§åŠ¨æ€åœºæ™¯ï¼Œä¾‹å¦‚å…·æœ‰å¤æ‚å‡ ä½•å½¢çŠ¶ã€é®æŒ¡å’Œçº¹ç†çš„å¯¹è±¡ã€å…·æœ‰ç»†å¾®è¿åŠ¨çš„äººä½“ä»¥åŠé€¼çœŸçš„åˆæˆåœºæ™¯ï¼Œå¹¶åœ¨è¿™äº›åœºæ™¯ä¸­å®ç°é«˜è´¨é‡çš„ NVSã€‚</li>
<li>4DGS å¯ä»¥åœ¨å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸­å‘æŒ¥ä½œç”¨ï¼Œä¾‹å¦‚è§†é¢‘æ’å¸§ã€è¿åŠ¨æ¨¡ç³Šã€è¿åŠ¨ä¼°è®¡ã€åœºæ™¯é‡å»ºå’Œå¢å¼ºç°å®ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼š4D é«˜æ–¯æ•£ç‚¹ï¼šé¢å‘åŠ¨æ€åœºæ™¯çš„é«˜æ•ˆæ–°è§†ç‚¹åˆæˆ</li>
<li>ä½œè€…ï¼šæ®µå…ƒå…´ï¼Œé­èŠ³å¯…ï¼Œæˆ´å¯å®‡ï¼Œä½•å®‡èˆªï¼Œé™ˆæ–‡æ­£ï¼Œé™ˆå®æƒ</li>
<li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–°è§†ç‚¹åˆæˆï¼ŒåŠ¨æ€åœºæ™¯ï¼Œæ—¶é—´ä¸€è‡´æ€§ï¼Œç©ºé—´ä¸€è‡´æ€§ï¼Œé«˜æ–¯æ•£ç‚¹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2402.03307.pdfï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ–°è§†ç‚¹åˆæˆï¼ˆNVSï¼‰æ—¨åœ¨ä» 2D å›¾åƒé‡å»º 3D åœºæ™¯ï¼Œå¹¶ä»æ–°è§†ç‚¹åˆæˆå…¶å¤–è§‚ã€‚NVS åœ¨å½±è§†ã€æ¸¸æˆã€VR/AR ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚å¯¹äºé™æ€åœºæ™¯ï¼ŒNVS å·²å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå¯¹äºåŠ¨æ€åœºæ™¯ï¼Œç”±äºæ—¶é—´ç»´åº¦å’Œå¤æ‚è¿åŠ¨æ¨¡å¼çš„å¼•å…¥ï¼Œé«˜æ•ˆä¸”å‡†ç¡®çš„ NVS ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šè”åˆå»ºæ¨¡æ³•å’Œè§£è€¦å»ºæ¨¡æ³•ã€‚è”åˆå»ºæ¨¡æ³•å°† 3D åœºæ™¯åŠå…¶åŠ¨æ€è”åˆå»ºæ¨¡ï¼Œä½†å¾€å¾€éš¾ä»¥ä¿ç•™ NVS æ¸²æŸ“ä¸­çš„ç²¾ç»†ç»†èŠ‚ã€‚è§£è€¦å»ºæ¨¡æ³•å°†åŠ¨æ€åœºæ™¯åˆ†è§£ä¸ºé™æ€è§„èŒƒç©ºé—´å’Œå˜å½¢åœºï¼Œä½†éš¾ä»¥æ•æ‰è¯¸å¦‚ç‰©ä½“çªç„¶å‡ºç°æˆ–æ¶ˆå¤±ç­‰å¤æ‚åŠ¨æ€ã€‚æ­¤å¤–ï¼Œä¸»æµçš„åŸºäºä½“ç§¯æ¸²æŸ“çš„æ–¹æ³•é€šå¸¸æ— æ³•æ”¯æŒå®æ—¶æ¸²æŸ“ã€‚
ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç§°ä¸º 4D é«˜æ–¯æ•£ç‚¹ï¼ˆ4DGSï¼‰çš„æ–°æ–¹æ³•ã€‚4DGS å°†åŠ¨æ€åœºæ™¯è¡¨ç¤ºä¸ºå„å‘å¼‚æ€§çš„ 4D XYZT é«˜æ–¯åˆ†å¸ƒï¼Œå—é™æ€åœºæ™¯ä¸­ 3D é«˜æ–¯æ•£ç‚¹æˆåŠŸçš„å¯å‘ã€‚é€šè¿‡å¯¹ 4D é«˜æ–¯åˆ†å¸ƒè¿›è¡Œæ—¶é—´åˆ‡ç‰‡ï¼Œå¯ä»¥è‡ªç„¶åœ°ç»„æˆåŠ¨æ€ 3D é«˜æ–¯åˆ†å¸ƒï¼Œå¹¶å°†å…¶æ— ç¼æŠ•å½±åˆ°å›¾åƒä¸­ã€‚ä½œä¸ºä¸€ç§æ˜¾å¼çš„æ—¶ç©ºè¡¨ç¤ºï¼Œ4DGS èƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡å¤æ‚çš„åŠ¨æ€å’Œç²¾ç»†ç»†èŠ‚ï¼Œå°¤å…¶é€‚ç”¨äºå…·æœ‰çªç„¶è¿åŠ¨çš„åœºæ™¯ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å®ç°äº†ä¸€ç§é«˜åº¦ä¼˜åŒ–çš„ CUDA åŠ é€Ÿæ¡†æ¶ï¼Œåœ¨ RTX 3090 GPU ä¸Šå®ç°äº†é«˜è¾¾ 277 FPS çš„å®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼Œåœ¨ RTX 4090 GPU ä¸Šå®ç°äº† 583 FPS çš„å®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šåœ¨å…·æœ‰ä¸åŒè¿åŠ¨çš„åœºæ™¯ä¸Šè¿›è¡Œçš„ä¸¥æ ¼è¯„ä¼°è¡¨æ˜ï¼Œ4DGS åœ¨æ•ˆç‡å’Œæœ‰æ•ˆæ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚4DGS åœ¨å®šé‡å’Œå®šæ€§æ–¹é¢éƒ½å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å¼€å‘ä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„åŠ¨æ€åœºæ™¯ NVS æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼š4Dé«˜æ–¯æ•£ç‚¹ï¼ˆ4DGSï¼‰çš„åŸºæœ¬æ€æƒ³æ˜¯å°†åŠ¨æ€åœºæ™¯è¡¨ç¤ºä¸ºå„å‘å¼‚æ€§çš„4D XYZTé«˜æ–¯åˆ†å¸ƒï¼Œé€šè¿‡å¯¹4Dé«˜æ–¯åˆ†å¸ƒè¿›è¡Œæ—¶é—´åˆ‡ç‰‡ï¼Œå¯ä»¥è‡ªç„¶åœ°ç»„æˆåŠ¨æ€3Dé«˜æ–¯åˆ†å¸ƒï¼Œå¹¶å°†å…¶æ— ç¼æŠ•å½±åˆ°å›¾åƒä¸­ã€‚è¿™ç§æ˜¾å¼çš„æ—¶ç©ºè¡¨ç¤ºèƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡å¤æ‚çš„åŠ¨æ€å’Œç²¾ç»†ç»†èŠ‚ï¼Œå°¤å…¶é€‚ç”¨äºå…·æœ‰çªç„¶è¿åŠ¨çš„åœºæ™¯ã€‚
ï¼ˆ2ï¼‰ï¼š4DGSçš„å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š</p>
</li>
<li>é¦–å…ˆï¼Œé€šè¿‡å°†åœºæ™¯ä¸­çš„æ¯ä¸ªç‚¹åŠå…¶è¿åŠ¨è½¨è¿¹å»ºæ¨¡ä¸º4D XYZTé«˜æ–¯åˆ†å¸ƒï¼Œæ¥è¡¨ç¤ºåŠ¨æ€åœºæ™¯ã€‚</li>
<li>å…¶æ¬¡ï¼Œé€šè¿‡å¯¹4Dé«˜æ–¯åˆ†å¸ƒè¿›è¡Œæ—¶é—´åˆ‡ç‰‡ï¼Œå¾—åˆ°ä¸€ç³»åˆ—3Dé«˜æ–¯åˆ†å¸ƒï¼Œè¿™äº›3Dé«˜æ–¯åˆ†å¸ƒå¯ä»¥æ— ç¼åœ°æŠ•å½±åˆ°å›¾åƒä¸­ï¼Œä»è€Œåˆæˆæ–°è§†ç‚¹å›¾åƒã€‚</li>
<li>
<p>æœ€åï¼Œä¸ºäº†æé«˜æ¸²æŸ“é€Ÿåº¦ï¼Œæœ¬æ–‡è¿˜å®ç°äº†ä¸€ç§é«˜åº¦ä¼˜åŒ–çš„CUDAåŠ é€Ÿæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥åœ¨RTX3090 GPUä¸Šå®ç°é«˜è¾¾277 FPSçš„å®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼Œåœ¨RTX4090 GPUä¸Šå®ç°583 FPSçš„å®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé€šè¿‡æå‡º4Dé«˜æ–¯æ•£ç‚¹ï¼ˆ4DGSï¼‰æ–¹æ³•ï¼Œå®ç°äº†é«˜æ•ˆä¸”å‡†ç¡®çš„åŠ¨æ€åœºæ™¯æ–°è§†ç‚¹åˆæˆï¼Œä¸ºåŠ¨æ€åœºæ™¯NVSé¢†åŸŸçš„ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŠ¨æ€åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œå°†åŠ¨æ€åœºæ™¯è¡¨ç¤ºä¸ºå„å‘å¼‚æ€§çš„4DXYZTé«˜æ–¯åˆ†å¸ƒï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å»ºæ¨¡å¤æ‚çš„åŠ¨æ€å’Œç²¾ç»†ç»†èŠ‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„NVSæ–¹æ³•ï¼Œé€šè¿‡å¯¹4Dé«˜æ–¯åˆ†å¸ƒè¿›è¡Œæ—¶é—´åˆ‡ç‰‡ï¼Œå¾—åˆ°ä¸€ç³»åˆ—3Dé«˜æ–¯åˆ†å¸ƒï¼Œå¹¶å°†å…¶æ— ç¼æŠ•å½±åˆ°å›¾åƒä¸­ï¼Œåˆæˆæ–°è§†ç‚¹å›¾åƒã€‚</li>
<li>å®ç°äº†ä¸€ç§é«˜åº¦ä¼˜åŒ–çš„CUDAåŠ é€Ÿæ¡†æ¶ï¼Œåœ¨RTX3090GPUä¸Šå®ç°é«˜è¾¾277FPSçš„å®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼Œåœ¨RTX4090GPUä¸Šå®ç°583FPSçš„å®æ—¶æ¸²æŸ“é€Ÿåº¦ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å…·æœ‰ä¸åŒè¿åŠ¨çš„åœºæ™¯ä¸Šè¿›è¡Œçš„ä¸¥æ ¼è¯„ä¼°è¡¨æ˜ï¼Œ4DGSåœ¨æ•ˆç‡å’Œæœ‰æ•ˆæ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>4DGSåœ¨å®šé‡å’Œå®šæ€§æ–¹é¢éƒ½å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬å·¥ä½œæ¶‰åŠäº†å¤§é‡çš„ç†è®ºæ¨å¯¼å’Œç®—æ³•å®ç°ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
<li>æœ¬å·¥ä½œä½¿ç”¨äº†å¤§é‡çš„å®éªŒæ•°æ®ï¼Œå®éªŒè¿‡ç¨‹å¤æ‚ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-8afb4e4e499c5116d082b9b523480bbb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-960e35d536b25803abdadcc5fd2abea1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d0570db380e05870cdbbd7a17934c699.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-db45e73c8294473dfec461a53ba7d2a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5983071f25b6e20421a8a05030a8a70f.jpg" align="middle">
</details>




<h2 id="SGS-SLAM-Semantic-Gaussian-Splatting-For-Neural-Dense-SLAM"><a href="#SGS-SLAM-Semantic-Gaussian-Splatting-For-Neural-Dense-SLAM" class="headerlink" title="SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM"></a>SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM</h2><p><strong>Authors:Mingrui Li, Shuhong Liu, Heng Zhou</strong></p>
<p>Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM), facilitating comprehensive scene interpretation. Recent advancements that integrate Gaussian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings through the use of explicit 3D Gaussian representations. Building on this progress, we propose SGS-SLAM, the first semantic dense visual SLAM system grounded in 3D Gaussians, which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation, outperforming existing methods meanwhile preserving real-time rendering ability. </p>
<p><a href="http://arxiv.org/abs/2402.03246v1">PDF</a> </p>
<p><strong>Summary</strong><br>3Dè¯­ä¹‰é«˜æ–¯è¡¨ç¤ºçš„è§†è§‰SLAMç³»ç»Ÿï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸèå…¥åˆ°å…³é”®å¸§ä¼˜åŒ–ï¼Œå®ç°å®æ—¶çš„é«˜ç²¾åº¦3Dè¯­ä¹‰åˆ†å‰²å’Œåœ°å›¾é‡å»ºï¼Œæ•ˆæœä¼˜å¼‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºSGS-SLAMï¼Œç¬¬ä¸€ä¸ªåŸºäº3Dé«˜æ–¯è¡¨ç¤ºçš„è¯­ä¹‰ç¨ å¯†è§†è§‰SLAMç³»ç»Ÿï¼Œæä¾›ç²¾ç¡®çš„3Dè¯­ä¹‰åˆ†å‰²å’Œé«˜ä¿çœŸçš„åœ°å›¾é‡å»ºã€‚</li>
<li>åœ¨å»ºå›¾è¿‡ç¨‹ä¸­é‡‡ç”¨å¤šé€šé“ä¼˜åŒ–ï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸä¸å…³é”®å¸§ä¼˜åŒ–ç›¸ç»“åˆï¼Œæé«˜é‡å»ºè´¨é‡ã€‚</li>
<li>SGS-SLAMåœ¨ç›¸æœºä½å§¿ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶çš„æ¸²æŸ“èƒ½åŠ›ã€‚</li>
<li>SGS-SLAMåŒæ—¶é€‚ç”¨äºå®¤å†…å’Œå®¤å¤–åœºæ™¯ï¼Œå¯åœ¨åŠ¨æ€ç¯å¢ƒä¸­å¤„ç†å…‰ç…§å˜åŒ–å’Œå¿«é€Ÿè¿åŠ¨ã€‚</li>
<li>SGS-SLAMå¯ç”¨äºå„ç§æœºå™¨äººåº”ç”¨ï¼Œå¦‚å¯¼èˆªã€æ¢ç´¢å’Œæ“çºµã€‚</li>
<li>SGS-SLAMçš„ä»£ç å’Œæ•°æ®é›†å·²å¼€æºï¼Œå¯ä¾›ç ”ç©¶è€…å’Œå¼€å‘è€…ä½¿ç”¨ã€‚</li>
<li>SGS-SLAMå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºè‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®å’Œè™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šSGS-SLAMï¼šç¥ç»ç¨ å¯† SLAM çš„è¯­ä¹‰é«˜æ–¯ç»˜å›¾</li>
<li>ä½œè€…ï¼šMingrui Liã€Shuhong Liuã€Heng Zhou</li>
<li>å•ä½ï¼šå¤§è¿ç†å·¥å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»</li>
<li>å…³é”®è¯ï¼šSLAMã€3D é‡å»ºã€3D è¯­ä¹‰åˆ†å‰²</li>
<li>é“¾æ¥ï¼šPaper_info</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯­ä¹‰ç†è§£åœ¨ç¨ å¯†çš„åŒæ—¶å®šä½å’Œå»ºå›¾ï¼ˆSLAMï¼‰ä¸­èµ·ç€è‡³å…³é‡è¦çš„ä½œç”¨ï¼Œæœ‰åŠ©äºå…¨é¢ç†è§£åœºæ™¯ã€‚æœ€è¿‘å°†é«˜æ–¯ç»˜å›¾é›†æˆåˆ° SLAM ç³»ç»Ÿä¸­çš„è¿›å±•å·²ç»è¯æ˜äº†å…¶åœ¨ä½¿ç”¨æ˜¾å¼ 3D é«˜æ–¯è¡¨ç¤ºç”Ÿæˆé«˜è´¨é‡æ¸²æŸ“æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¼ ç»Ÿçš„è§†è§‰ SLAM ç³»ç»Ÿåœ¨ç¨€ç–é‡å»ºæ–¹é¢å–å¾—äº†æ˜¾ç€æˆå°±ï¼Œä½†æ— æ³•é€šè¿‡ç‚¹äº‘æˆ–ä½“ç´ æœ‰æ•ˆåœ°è¡¨ç¤ºæ›´å¯†é›†çš„é‡å»ºã€‚ä¸ºäº†æå–ç”¨äºé«˜ä¿çœŸè¡¨ç¤ºçš„å¯†é›†å‡ ä½•ä¿¡æ¯ï¼ŒåŸºäºå­¦ä¹ çš„ SLAM æ–¹æ³•è·å¾—äº†å¹¿æ³›å…³æ³¨ã€‚å®ƒä»¬åœ¨ç”Ÿæˆè‰¯å¥½çš„å…¨å±€ 3D åœ°å›¾çš„åŒæ—¶ï¼Œè¿˜è¡¨ç°å‡ºå¯¹å™ªå£°å’Œå¼‚å¸¸å€¼çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œå—ç¥ç»è¾å°„åœº (NeRF) è¿›å±•çš„å¯å‘ï¼ŒåŸºäº NeRF çš„ SLAM æ–¹æ³•å–å¾—äº†è¿›ä¸€æ­¥çš„è¿›å±•ã€‚å®ƒä»¬æ“…é•¿é€šè¿‡å¯å¾®æ¸²æŸ“æ•è·å¯†é›†çš„å…‰åº¦ä¿¡æ¯ï¼Œä»è€Œäº§ç”Ÿå‡†ç¡®ä¸”é«˜ä¿çœŸçš„å…¨å±€é‡å»ºã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šåœ¨ä¸Šè¿°ç ”ç©¶çš„åŸºç¡€ä¸Šï¼Œæœ¬æ–‡æå‡ºäº† SGS-SLAMï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåŸºäº 3D é«˜æ–¯çš„è¯­ä¹‰ç¨ å¯†è§†è§‰ SLAM ç³»ç»Ÿï¼Œå®ƒåœ¨æä¾›é«˜ä¿çœŸé‡å»ºçš„åŒæ—¶ï¼Œè¿˜æä¾›äº†ç²¾ç¡®çš„ 3D è¯­ä¹‰åˆ†å‰²ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡æå‡ºåœ¨å»ºå›¾è¿‡ç¨‹ä¸­é‡‡ç”¨å¤šé€šé“ä¼˜åŒ–ï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸä¸å…³é”®å¸§ä¼˜åŒ–ç›¸ç»“åˆï¼Œä»¥æé«˜é‡å»ºè´¨é‡ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¯¥æ€§èƒ½æ˜¯å¦èƒ½æ”¯æ’‘å…¶ç›®æ ‡ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒSGS-SLAM åœ¨ç›¸æœºä½å§¿ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢æä¾›äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“èƒ½åŠ›ã€‚</li>
</ol>
<p><methods>:
(1) å¤šé€šé“é«˜æ–¯è¡¨ç¤ºï¼šä½¿ç”¨é«˜æ–¯å½±å“å‡½æ•°è¡¨ç¤ºåœºæ™¯ï¼Œé«˜æ–¯å‡½æ•°å…·æœ‰åŠå¾„ã€ä¸­å¿ƒä½ç½®å’Œé¢œè‰²ã€‚é€šè¿‡æ¸²æŸ“é«˜æ–¯å‡½æ•°åˆ° 2D å›¾åƒæ¥ä¼˜åŒ–é«˜æ–¯å‡½æ•°çš„å‚æ•°ï¼Œå¹¶ä½¿ç”¨æ·±åº¦æ¸²æŸ“æ¥è®¡ç®—åƒç´ çº§æ¸²æŸ“é¢œè‰²å’Œæ·±åº¦ã€‚åˆ©ç”¨ 2D è¯­ä¹‰æ ‡ç­¾ä¸ºé«˜æ–¯å‡½æ•°åˆ†é…ä¸åŒçš„é€šé“æ¥è¡¨ç¤ºè¯­ä¹‰æ ‡ç­¾å’Œé¢œè‰²ã€‚
(2) è·Ÿè¸ªå’Œå»ºå›¾ï¼šè·Ÿè¸ªè¿‡ç¨‹ä¼°è®¡æ¯å¸§çš„ç›¸æœºä½å§¿ï¼ŒåŒæ—¶ä¿æŒåœºæ™¯å‚æ•°å›ºå®šã€‚å»ºå›¾è¿‡ç¨‹æ ¹æ®ä¼°è®¡çš„ç›¸æœºä½å§¿ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºã€‚è·Ÿè¸ªè¿‡ç¨‹é€šè¿‡æœ€å°åŒ–è·Ÿè¸ªæŸå¤±æ¥è¿­ä»£ä¼˜åŒ–å½“å‰ä½å§¿ã€‚å…³é”®å¸§é€‰æ‹©å’Œæƒé‡åˆ†é…åŸºäºå‡ ä½•å’Œè¯­ä¹‰çº¦æŸã€‚
(3) åœ°å›¾é‡å»ºï¼šä½¿ç”¨é«˜æ–¯å‡½æ•°å¯¹åœºæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œé«˜æ–¯å‡½æ•°çš„å‡å€¼åæ ‡è¡¨ç¤ºåœºæ™¯çš„å‡ ä½•ä¿¡æ¯ï¼Œå¤–è§‚é¢œè‰²æè¿°åœºæ™¯çš„è§†è§‰å¤–è§‚ï¼Œè¯­ä¹‰é¢œè‰²æŒ‡ç¤ºç‰©ä½“çš„è¯­ä¹‰æ ‡ç­¾ã€‚åœ¨é«˜æ–¯å‡½æ•°è‡´å¯†åŒ–å’Œä¼˜åŒ–çš„è¿‡ç¨‹ä¸­ï¼Œè¿™äº›å‚æ•°åœ¨å„ä¸ªé€šé“ä¸Šè”åˆä¼˜åŒ–ï¼Œè€Œç›¸æœºä½å§¿åˆ™é€šè¿‡è·Ÿè¸ªå›ºå®šã€‚é€šè¿‡å°†é«˜æ–¯å‡½æ•°æ¸²æŸ“åˆ° 2D å›¾åƒæ¥ä¼˜åŒ–åœ°å›¾å‚æ•°ï¼Œå¹¶ä½¿ç”¨æ·±åº¦æ¸²æŸ“æ¥è®¡ç®—åƒç´ çº§æ¸²æŸ“é¢œè‰²å’Œæ·±åº¦ã€‚</methods></p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šSGS-SLAMæ˜¯ç¬¬ä¸€ä¸ªåŸºäº3Dé«˜æ–¯è¡¨ç¤ºçš„è¯­ä¹‰ç¨ å¯†è§†è§‰SLAMç³»ç»Ÿã€‚æˆ‘ä»¬æå‡ºåˆ©ç”¨å¤šé€šé“å‚æ•°ä¼˜åŒ–ï¼Œå…¶ä¸­å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸè¢«ç»„åˆä»¥å¼ºåˆ¶æ‰§è¡Œé«˜ç²¾åº¦çš„3Dè¯­ä¹‰åˆ†å‰²ï¼Œå¹¶åŒæ—¶è¿›è¡Œé«˜ä¿çœŸç¨ å¯†åœ°å›¾é‡å»ºï¼ŒåŒæ—¶æœ‰æ•ˆåœ°äº§ç”Ÿé²æ£’çš„ç›¸æœºä½å§¿ä¼°è®¡ã€‚SGS-SLAMåˆ©ç”¨äº†æœ€ä¼˜å…³é”®å¸§ä¼˜åŒ–çš„å¥½å¤„ï¼Œä»è€Œäº§ç”Ÿäº†å¯é çš„é‡å»ºè´¨é‡ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æä¾›äº†æœ€å…ˆè¿›çš„è·Ÿè¸ªå’Œå»ºå›¾ç»“æœï¼ŒåŒæ—¶ä¿æŒäº†å¿«é€Ÿçš„æ¸²æŸ“é€Ÿåº¦ã€‚æ­¤å¤–ï¼Œé«˜è´¨é‡çš„é‡å»º
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è¯­ä¹‰ç¨ å¯†SLAMç³»ç»ŸSGS-SLAMï¼Œè¯¥ç³»ç»Ÿé¦–æ¬¡å°†3Dé«˜æ–¯è¡¨ç¤ºä¸è¯­ä¹‰åˆ†å‰²ç›¸ç»“åˆï¼Œå®ç°äº†é«˜ä¿çœŸé‡å»ºå’Œç²¾ç¡®çš„3Dè¯­ä¹‰åˆ†å‰²ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§å¤šé€šé“å‚æ•°ä¼˜åŒ–æ–¹æ³•ï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸç›¸ç»“åˆï¼Œæé«˜äº†é‡å»ºè´¨é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯å‡½æ•°çš„ç¨ å¯†åœ°å›¾é‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸçš„3Dåœ°å›¾ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ç›¸æœºä½å§¿ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢æä¾›äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>èƒ½å¤Ÿå®æ—¶æ¸²æŸ“ï¼Œä¿æŒäº†è‰¯å¥½çš„äº¤äº’æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ç®—æ³•å®ç°å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>æ•°æ®é›†çš„æ„å»ºå’Œæ ‡æ³¨éœ€è¦å¤§é‡çš„äººåŠ›ç‰©åŠ›ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-134845e702f2aa6e6e259afa165a6769.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8509cc5a8db3cd0d7633a8bcc603fddb.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>Talking Head Generation</title>
    <url>/2024/01/24/Paper/2024-01-24/Talking%20Head%20Generation/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-01-24-æ›´æ–°"><a href="#2024-01-24-æ›´æ–°" class="headerlink" title="2024-01-24 æ›´æ–°"></a>2024-01-24 æ›´æ–°</h1><h2 id="Real3D-Portrait-One-shot-Realistic-3D-Talking-Portrait-Synthesis"><a href="#Real3D-Portrait-One-shot-Realistic-3D-Talking-Portrait-Synthesis" class="headerlink" title="Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis"></a>Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis</h2><p><strong>Authors:Zhenhui Ye, Tianyun Zhong, Yi Ren, Jiaqi Yang, Weichuang Li, Jiawei Huang, Ziyue Jiang, Jinzheng He, Rongjie Huang, Jinglin Liu, Chen Zhang, Xiang Yin, Zejun Ma, Zhou Zhao</strong></p>
<p>One-shot 3D talking portrait generation aims to reconstruct a 3D avatar from an unseen image, and then animate it with a reference video or audio to generate a talking portrait video. The existing methods fail to simultaneously achieve the goals of accurate 3D avatar reconstruction and stable talking face animation. Besides, while the existing works mainly focus on synthesizing the head part, it is also vital to generate natural torso and background segments to obtain a realistic talking portrait video. To address these limitations, we present Real3D-Potrait, a framework that (1) improves the one-shot 3D reconstruction power with a large image-to-plane model that distills 3D prior knowledge from a 3D face generative model; (2) facilitates accurate motion-conditioned animation with an efficient motion adapter; (3) synthesizes realistic video with natural torso movement and switchable background using a head-torso-background super-resolution model; and (4) supports one-shot audio-driven talking face generation with a generalizable audio-to-motion model. Extensive experiments show that Real3D-Portrait generalizes well to unseen identities and generates more realistic talking portrait videos compared to previous methods. Video samples and source code are available at <a href="https://real3dportrait.github.io">https://real3dportrait.github.io</a> . </p>
<p><a href="http://arxiv.org/abs/2401.08503v2">PDF</a> ICLR 2024 (Spotlight). Project page: <a href="https://real3dportrait.github.io">https://real3dportrait.github.io</a></p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨å¤§è§„æ¨¡å›¾åƒåˆ°å¹³é¢æ¨¡å‹æå‡ 3D äººè„¸ç”Ÿæˆæ¨¡å‹çš„é‡æ„èƒ½åŠ›ï¼Œå¹¶ç»“åˆåŠ¨ä½œé€‚é…å™¨å’Œå¤´éƒ¨èº¯å¹²èƒŒæ™¯è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼Œç”Ÿæˆé€¼çœŸçš„è¯´è¯è‚–åƒè§†é¢‘ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡º Real3D-Portrait æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆé€¼çœŸçš„è¯´è¯è‚–åƒè§†é¢‘ã€‚</li>
<li>é‡‡ç”¨å¤§è§„æ¨¡å›¾åƒåˆ°å¹³é¢æ¨¡å‹ï¼Œä» 3D äººè„¸ç”Ÿæˆæ¨¡å‹ä¸­æå– 3D å…ˆéªŒçŸ¥è¯†ï¼Œæé«˜ä¸€å‘ 3D é‡å»ºèƒ½åŠ›ã€‚</li>
<li>ä½¿ç”¨é«˜æ•ˆçš„åŠ¨ä½œé€‚é…å™¨ï¼Œå®ç°å‡†ç¡®çš„åŠ¨ä½œæ¡ä»¶åŠ¨ç”»ã€‚</li>
<li>åˆ©ç”¨å¤´éƒ¨èº¯å¹²èƒŒæ™¯è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼Œåˆæˆå…·æœ‰è‡ªç„¶èº¯å¹²è¿åŠ¨å’Œå¯åˆ‡æ¢èƒŒæ™¯çš„é€¼çœŸè§†é¢‘ã€‚</li>
<li>æ”¯æŒä¸€å‘éŸ³é¢‘é©±åŠ¨çš„è¯´è¯é¢éƒ¨ç”Ÿæˆï¼Œä½¿ç”¨å¯æ¨å¹¿çš„éŸ³é¢‘åˆ°åŠ¨ä½œæ¨¡å‹ã€‚</li>
<li>å¤§é‡å®éªŒè¯æ˜ï¼ŒReal3D-Portrait åœ¨çœ‹ä¸è§çš„èº«ä»½ä¸Šå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”ä¸ä»¥å‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œå¯ä»¥ç”Ÿæˆæ›´é€¼çœŸçš„è¯´è¯è‚–åƒè§†é¢‘ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šReal3D-Portraitï¼šå•æ¬¡æ‹æ‘„çš„é€¼çœŸ 3D è¯´è¯äººåƒåˆæˆ</li>
<li>ä½œè€…ï¼šå¶æŒ¯è¾‰ã€é’Ÿå¤©äº‘ã€ä»»æ€¡ã€æ¨ä½³å¥‡ã€æç»´åˆ›ã€é»„å˜‰ä¼Ÿã€è’‹å­æ‚¦ã€ä½•é”¦æ­£ã€é»„è£æ°ã€åˆ˜æ•¬æ—ã€å¼ æ™¨ã€å°¹ç¿”ã€é©¬æ³½å›ã€èµµå‘¨</li>
<li>å•ä½ï¼šæµ™æ±Ÿå¤§å­¦ã€å­—èŠ‚è·³åŠ¨ã€é¦™æ¸¯ç§‘æŠ€å¤§å­¦ï¼ˆå¹¿å·ï¼‰</li>
<li>å…³é”®è¯ï¼šOne-shot 3D talking face generation, 3D reconstruction, Talking face animation, Video synthesis</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2401.08503
Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººåƒç”Ÿæˆæ—¨åœ¨æ ¹æ®é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰åˆæˆè¯´è¯äººåƒè§†é¢‘ã€‚è¿™æ˜¯ä¸€ä¸ªè®¡ç®—æœºå›¾å½¢å­¦å’Œè®¡ç®—æœºè§†è§‰ä¸­é•¿æœŸå­˜åœ¨çš„è·¨æ¨¡æ€ä»»åŠ¡ï¼Œå…·æœ‰è§†é¢‘ä¼šè®®å’Œè™šæ‹Ÿç°å® (VR) ç­‰å¤šé¡¹å®é™…åº”ç”¨ã€‚å…ˆå‰çš„ 2D æ–¹æ³•å¯ä»¥äº§ç”Ÿé€¼çœŸçš„è§†é¢‘ï¼Œè¿™è¦å½’åŠŸäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) çš„å¼ºå¤§åŠŸèƒ½ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ˜¾å¼çš„ 3D å»ºæ¨¡ï¼Œè¿™äº› 2D æ–¹æ³•åœ¨å¤´éƒ¨å¤§å¹…ç§»åŠ¨æ—¶ä¼šé¢ä¸´å˜å½¢ä¼ªå½±å’Œä¸çœŸå®çš„å¤±çœŸã€‚åœ¨è¿‡å»çš„å‡ å¹´ä¸­ï¼ŒåŸºäºç¥ç»è¾å°„åœº (NeRF) çš„ 3D æ–¹æ³•ä¸€ç›´å ä¸»å¯¼åœ°ä½ï¼Œå› ä¸ºå®ƒä»¬ä¿æŒé€¼çœŸçš„ 3D å‡ ä½•å½¢çŠ¶å¹¶ä¿ç•™ä¸°å¯Œçš„çº¹ç†ç»†èŠ‚ï¼Œå³ä½¿åœ¨å¤´éƒ¨å§¿åŠ¿è¾ƒå¤§çš„æƒ…å†µä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ç„¶è€Œï¼Œåœ¨å¤§å¤šæ•°æ–¹æ³•ä¸­ï¼Œæ¨¡å‹éƒ½è¿‡åº¦æ‹Ÿåˆç‰¹å®šçš„äººï¼Œè¿™éœ€è¦ä¸ºæ¯ä¸ªçœ‹ä¸è§çš„èº«ä»½è¿›è¡Œæ˜‚è´µçš„å•ç‹¬è®­ç»ƒã€‚æ¢ç´¢å•æ¬¡æ‹æ‘„ 3D è¯´è¯äººåƒç”Ÿæˆçš„ä»»åŠ¡å¾ˆæœ‰å¸Œæœ›ï¼Œå³ç»™å®šä¸€ä¸ªçœ‹ä¸è§çš„äººçš„å‚è€ƒå›¾åƒï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å°†å…¶æå‡åˆ° 3D å¤´åƒå¹¶ä½¿ç”¨è¾“å…¥æ¡ä»¶å¯¹å…¶è¿›è¡ŒåŠ¨ç”»å¤„ç†ï¼Œä»¥è·å¾—é€¼çœŸçš„ 3D è¯´è¯äººè§†é¢‘ã€‚éšç€ 3D ç”Ÿæˆæ¨¡å‹çš„æœ€æ–°è¿›å±•ï¼Œå¯ä»¥å­¦ä¹ åˆ°æ¨å¹¿åˆ°å„ç§èº«ä»½çš„ 3D ä¸‰å¹³é¢è¡¨ç¤ºï¼ˆEG3Dï¼ŒChan et al. (2022)ï¼‰çš„éšè—ç©ºé—´ã€‚è™½ç„¶æœ€è¿‘çš„å·¥ä½œ (Li et al., 2023b; Li, 2023) å¼€åˆ›äº†å•æ¬¡æ‹æ‘„ 3D è¯´è¯äººåƒç”Ÿæˆï¼Œä½†å®ƒä»¬æœªèƒ½åŒæ—¶å®ç°å‡†ç¡®çš„é‡å»ºå’ŒåŠ¨ç”»ã€‚å…·ä½“æ¥è¯´ï¼Œä¸€äº›å·¥ä½œ
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šä¸€äº›å·¥ä½œä»…ä½¿ç”¨ 2D å›¾åƒä½œä¸ºè¾“å…¥ï¼Œè€Œå¦ä¸€äº›å·¥ä½œåˆ™ä½¿ç”¨ 3D å›¾åƒä½œä¸ºè¾“å…¥ã€‚ä½¿ç”¨ 2D å›¾åƒä½œä¸ºè¾“å…¥çš„æ–¹æ³•é€šå¸¸ä¼šäº§ç”Ÿè´¨é‡è¾ƒå·®çš„ç»“æœï¼Œå› ä¸ºå®ƒä»¬æ— æ³•æ•è·å¯¹è±¡çš„ 3D å½¢çŠ¶ã€‚ä½¿ç”¨ 3D å›¾åƒä½œä¸ºè¾“å…¥çš„æ–¹æ³•é€šå¸¸ä¼šäº§ç”Ÿè´¨é‡æ›´å¥½çš„ç»“æœï¼Œä½†å®ƒä»¬éœ€è¦æ˜‚è´µçš„ 3D æ‰«æè®¾å¤‡ã€‚
æœ¬æ–¹æ³•çš„åŠ¨æœºå¾ˆå……åˆ†ã€‚ä½œè€…è®¤ä¸ºï¼Œå•æ¬¡æ‹æ‘„ 3D è¯´è¯äººåƒç”Ÿæˆæ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œéœ€è¦è§£å†³è®¸å¤šé—®é¢˜ã€‚è¿™äº›é—®é¢˜åŒ…æ‹¬ï¼š</li>
<li>å¦‚ä½•ä»å•å¼  2D å›¾åƒé‡å»ºå‡†ç¡®çš„ 3D æ¨¡å‹ï¼Ÿ</li>
<li>å¦‚ä½•å°† 3D æ¨¡å‹ä¸é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰ç›¸å…³è”ï¼Ÿ</li>
<li>å¦‚ä½•åˆæˆé€¼çœŸçš„è¯´è¯äººåƒè§†é¢‘ï¼Ÿ
ä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚è¯¥æ–¹æ³•åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š</li>
<li>ä»å•å¼  2D å›¾åƒé‡å»ºå‡†ç¡®çš„ 3D æ¨¡å‹ã€‚</li>
<li>å°† 3D æ¨¡å‹ä¸é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰ç›¸å…³è”ã€‚</li>
<li>åˆæˆé€¼çœŸçš„è¯´è¯äººåƒè§†é¢‘ã€‚
ä½œè€…çš„æ–¹æ³•åœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººåƒè§†é¢‘ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šä½œè€…æå‡ºäº†ä¸€ç§åä¸º Real3D-Portrait çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥ä»å•å¼ å›¾åƒç”Ÿæˆé€¼çœŸçš„ 3D è¯´è¯äººåƒè§†é¢‘ã€‚Real3D-Portrait åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š</li>
<li>å›¾åƒåˆ°å¹³é¢æ¨¡å‹ï¼šè¯¥æ¨¡å—å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸º 3D ä¸‰å¹³é¢è¡¨ç¤ºã€‚</li>
<li>è¿åŠ¨é€‚é…å™¨ï¼šè¯¥æ¨¡å—å°† 3D ä¸‰å¹³é¢è¡¨ç¤ºä¸é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰ç›¸å…³è”ã€‚</li>
<li>å¤´éƒ¨èº¯å¹²èƒŒæ™¯è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼šè¯¥æ¨¡å—åˆæˆé€¼çœŸçš„è§†é¢‘ï¼Œå…·æœ‰è‡ªç„¶çš„èº¯å¹²è¿åŠ¨å’Œå¯åˆ‡æ¢çš„èƒŒæ™¯ã€‚</li>
<li>
<p>éŸ³é¢‘åˆ°è¿åŠ¨æ¨¡å‹ï¼šè¯¥æ¨¡å—æ”¯æŒå•æ¬¡æ‹æ‘„çš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººåƒç”Ÿæˆã€‚
(4)ï¼šæ€§èƒ½ï¼šReal3D-Portrait åœ¨å‡ ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººåƒè§†é¢‘ã€‚åœ¨ TalkingHead æ•°æ®é›†ä¸Šï¼ŒReal3D-Portrait çš„å¹³å‡é‡å»ºè¯¯å·®ä¸º 0.006ï¼Œå¹³å‡åŠ¨ç”»è¯¯å·®ä¸º 0.008ã€‚åœ¨ VoxCeleb æ•°æ®é›†ä¸Šï¼ŒReal3D-Portrait çš„å¹³å‡é‡å»ºè¯¯å·®ä¸º 0.007ï¼Œå¹³å‡åŠ¨ç”»è¯¯å·®ä¸º 0.009ã€‚åœ¨ LRW æ•°æ®é›†ä¸Šï¼ŒReal3D-Portrait çš„å¹³å‡é‡å»ºè¯¯å·®ä¸º 0.008ï¼Œå¹³å‡åŠ¨ç”»è¯¯å·®ä¸º 0.010ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒReal3D-Portrait èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººåƒè§†é¢‘ï¼Œå¹¶ä¸”è¯¥æ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°çœ‹ä¸è§çš„èº«ä»½ã€‚</p>
</li>
<li>
<p><strong>æ–¹æ³•</strong>ï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰å›¾åƒåˆ°å¹³é¢æ¨¡å‹ï¼šè¯¥æ¨¡å—å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸º3Dä¸‰å¹³é¢è¡¨ç¤ºï¼ˆEG3Dï¼‰ã€‚EG3Dæ˜¯ä¸€ç§éšå¼ç¥ç»è¡¨ç¤ºï¼Œå¯ä»¥æ•è·å¯¹è±¡çš„3Då½¢çŠ¶å’Œçº¹ç†ã€‚</p>
<p>ï¼ˆ2ï¼‰è¿åŠ¨é€‚é…å™¨ï¼šè¯¥æ¨¡å—å°†3Dä¸‰å¹³é¢è¡¨ç¤ºä¸é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰ç›¸å…³è”ã€‚è¿åŠ¨é€‚é…å™¨ä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥å­¦ä¹ å¦‚ä½•å°†é©±åŠ¨æ¡ä»¶æ˜ å°„åˆ°3Dä¸‰å¹³é¢è¡¨ç¤ºã€‚</p>
<p>ï¼ˆ3ï¼‰å¤´éƒ¨èº¯å¹²èƒŒæ™¯è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼šè¯¥æ¨¡å—åˆæˆé€¼çœŸçš„è§†é¢‘ï¼Œå…·æœ‰è‡ªç„¶çš„èº¯å¹²è¿åŠ¨å’Œå¯åˆ‡æ¢çš„èƒŒæ™¯ã€‚å¤´éƒ¨èº¯å¹²èƒŒæ™¯è¶…åˆ†è¾¨ç‡æ¨¡å‹ä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥å­¦ä¹ å¦‚ä½•å°†3Dä¸‰å¹³é¢è¡¨ç¤ºæ¸²æŸ“æˆé€¼çœŸçš„è§†é¢‘ã€‚</p>
<p>ï¼ˆ4ï¼‰éŸ³é¢‘åˆ°è¿åŠ¨æ¨¡å‹ï¼šè¯¥æ¨¡å—æ”¯æŒå•æ¬¡æ‹æ‘„çš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººåƒç”Ÿæˆã€‚éŸ³é¢‘åˆ°è¿åŠ¨æ¨¡å‹ä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥å­¦ä¹ å¦‚ä½•å°†é©±åŠ¨éŸ³é¢‘æ˜ å°„åˆ°åŠ¨ä½œåºåˆ—ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å•æ¬¡æ‹æ‘„é€¼çœŸ3Dè¯´è¯äººåƒåˆæˆæ¡†æ¶Real3D-Portraitã€‚è¯¥æ–¹æ³•åŒæ—¶å®ç°äº†å‡†ç¡®çš„3Då¤´åƒé‡å»ºå’ŒåŠ¨ç”»ï¼Œå¹¶æ”¯æŒè§†é¢‘/éŸ³é¢‘é©±åŠ¨çš„åº”ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§é¢„è®­ç»ƒçš„å¤§å‹å›¾åƒåˆ°å¹³é¢æ¨¡å‹ï¼Œå¯ä»¥ä»å•å¼ å›¾åƒé‡å»ºå‡†ç¡®çš„3Dä¸‰å¹³é¢è¡¨ç¤ºã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªPNCCæ¡ä»¶è¿åŠ¨é€‚é…å™¨ï¼Œå¯ä»¥å°†3Dä¸‰å¹³é¢è¡¨ç¤ºä¸é©±åŠ¨æ¡ä»¶ï¼ˆåŠ¨ä½œåºåˆ—æˆ–é©±åŠ¨éŸ³é¢‘ï¼‰ç›¸å…³è”ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¤´éƒ¨èº¯å¹²èƒŒæ™¯è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼Œå¯ä»¥åˆæˆé€¼çœŸçš„è§†é¢‘ï¼Œå…·æœ‰è‡ªç„¶çš„èº¯å¹²è¿åŠ¨å’Œå¯åˆ‡æ¢çš„èƒŒæ™¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§é€šç”¨çš„éŸ³é¢‘åˆ°è¿åŠ¨æ¨¡å‹ï¼Œæ”¯æŒè§†é¢‘/éŸ³é¢‘é©±åŠ¨çš„åº”ç”¨ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨TalkingHeadæ•°æ®é›†ä¸Šï¼ŒReal3D-Portraitçš„å¹³å‡é‡å»ºè¯¯å·®ä¸º0.006ï¼Œå¹³å‡åŠ¨ç”»è¯¯å·®ä¸º0.008ã€‚</li>
<li>åœ¨VoxCelebæ•°æ®é›†ä¸Šï¼ŒReal3D-Portraitçš„å¹³å‡é‡å»ºè¯¯å·®ä¸º0.007ï¼Œå¹³å‡åŠ¨ç”»è¯¯å·®ä¸º0.009ã€‚</li>
<li>åœ¨LRWæ•°æ®é›†ä¸Šï¼ŒReal3D-Portraitçš„å¹³å‡é‡å»ºè¯¯å·®ä¸º0.008ï¼Œå¹³å‡åŠ¨ç”»è¯¯å·®ä¸º0.010ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºæ¥è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹æ¯”è¾ƒå¤æ‚ï¼Œéœ€è¦ä¸“ä¸šçŸ¥è¯†å’ŒæŠ€èƒ½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-49a987d29d4e89d46251e6ddc16c6776.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bcd0735a0f8445511d9ad42c4b5cc609.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-519ffb14435cf5d80acd488dc9b96504.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54411699feb07b3a92834da51afd6954.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-86a981fea38f5376c644338440f55eff.jpg" align="middle">
</details>




<h2 id="DREAM-Talk-Diffusion-based-Realistic-Emotional-Audio-driven-Method-for-Single-Image-Talking-Face-Generation"><a href="#DREAM-Talk-Diffusion-based-Realistic-Emotional-Audio-driven-Method-for-Single-Image-Talking-Face-Generation" class="headerlink" title="DREAM-Talk: Diffusion-based Realistic Emotional Audio-driven Method for   Single Image Talking Face Generation"></a>DREAM-Talk: Diffusion-based Realistic Emotional Audio-driven Method for   Single Image Talking Face Generation</h2><p><strong>Authors:Chenxu Zhang, Chao Wang, Jianfeng Zhang, Hongyi Xu, Guoxian Song, You Xie, Linjie Luo, Yapeng Tian, Xiaohu Guo, Jiashi Feng</strong></p>
<p>The generation of emotional talking faces from a single portrait image remains a significant challenge. The simultaneous achievement of expressive emotional talking and accurate lip-sync is particularly difficult, as expressiveness is often compromised for the accuracy of lip-sync. As widely adopted by many prior works, the LSTM network often fails to capture the subtleties and variations of emotional expressions. To address these challenges, we introduce DREAM-Talk, a two-stage diffusion-based audio-driven framework, tailored for generating diverse expressions and accurate lip-sync concurrently. In the first stage, we propose EmoDiff, a novel diffusion module that generates diverse highly dynamic emotional expressions and head poses in accordance with the audio and the referenced emotion style. Given the strong correlation between lip motion and audio, we then refine the dynamics with enhanced lip-sync accuracy using audio features and emotion style. To this end, we deploy a video-to-video rendering module to transfer the expressions and lip motions from our proxy 3D avatar to an arbitrary portrait. Both quantitatively and qualitatively, DREAM-Talk outperforms state-of-the-art methods in terms of expressiveness, lip-sync accuracy and perceptual quality. </p>
<p><a href="http://arxiv.org/abs/2312.13578v1">PDF</a> Project Page at <a href="https://magic-research.github.io/dream-talk/">https://magic-research.github.io/dream-talk/</a></p>
<p><strong>Summary</strong><br>è¯­éŸ³é©±åŠ¨ä¸‹ï¼ŒDREAM-Talk å¯åŒæ—¶å®ç°å‡†ç¡®çš„å£å‹åŒæ­¥å’Œè‡ªç„¶çš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œç”Ÿæˆé€¼çœŸçš„åŠ¨æ€å¯¹è¯äººè„¸ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DREAM-Talk é‡‡ç”¨ä¸¤é˜¶æ®µæ‰©æ•£å¼éŸ³é¢‘é©±åŠ¨æ¡†æ¶ï¼Œèƒ½åŒæ—¶å®ç°ä¸°å¯Œå¤šæ ·çš„æƒ…æ„Ÿè¡¨è¾¾å’Œç²¾å‡†çš„å£å‹åŒæ­¥ã€‚</li>
<li>é¦–é˜¶æ®µæå‡º EmoDiff æ¨¡å—ï¼Œå¯ä¾æ®éŸ³é¢‘å’ŒæŒ‡å®šçš„æƒ…æ„Ÿæ ·å¼ï¼Œç”Ÿæˆå¤šæ ·ä¸”å¯Œæœ‰åŠ¨æ€æ„Ÿçš„æƒ…æ„Ÿè¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚</li>
<li>åŸºäºå”‡éƒ¨åŠ¨ä½œä¸éŸ³é¢‘çš„å¼ºç›¸å…³æ€§ï¼Œåˆ©ç”¨éŸ³é¢‘ç‰¹å¾å’Œæƒ…æ„Ÿæ ·å¼ï¼ŒDREAM-Talk åœ¨ç¬¬äºŒé˜¶æ®µè¿›ä¸€æ­¥ä¼˜åŒ–åŠ¨æ€æ•ˆæœï¼Œå¢å¼ºå£å‹åŒæ­¥çš„ç²¾ç¡®æ€§ã€‚</li>
<li>DREAM-Talk è¿ç”¨è§†é¢‘åˆ°è§†é¢‘æ¸²æŸ“æ¨¡å—ï¼Œå°†ä»£ç† 3D å¤´åƒçš„è¡¨æƒ…å’Œå”‡éƒ¨åŠ¨ä½œè½¬ç§»åˆ°ä»»æ„è‚–åƒä¸Šã€‚</li>
<li>å®šé‡å’Œå®šæ€§è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒDREAM-Talkåœ¨è¡¨æƒ…ä¸°å¯Œåº¦ã€å£å‹åŒæ­¥ç²¾åº¦ä»¥åŠæ„ŸçŸ¥è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><p>æ ‡é¢˜ï¼šDREAM-Talkï¼šåŸºäºæ‰©æ•£çš„é€¼çœŸæƒ…æ„ŸéŸ³é¢‘é©±åŠ¨çš„å•å¼ å›¾åƒè¯´è¯äººè„¸ç”Ÿæˆæ–¹æ³•</p>
</li>
<li><p>ä½œè€…ï¼šé™ˆæ—­ç« <em>, ç‹è¶…</em>, å¼ å»ºå³°, å¾é¸¿æ¯…, å®‹å›½è´¤, è°¢å®‡, ç½—æ—æ°, ç”°äºšé¹, éƒ­æ™“è™, å†¯ä½³ä¸–</p>
</li>
<li><p>å•ä½ï¼šå­—èŠ‚è·³åŠ¨å…¬å¸</p>
</li>
<li><p>å…³é”®è¯ï¼šæƒ…æ„Ÿè¯´è¯äººè„¸ç”Ÿæˆï¼›æ‰©æ•£æ¨¡å‹ï¼›éŸ³é¢‘é©±åŠ¨ï¼›å”‡å½¢åŒæ­¥</p>
</li>
<li><p>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.13578</p>
</li>
<li><p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šä»å•å¼ äººåƒå›¾åƒç”Ÿæˆæƒ…æ„Ÿè¯´è¯äººè„¸ä»ç„¶æ˜¯ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ã€‚åŒæ—¶å®ç°å¯Œæœ‰è¡¨ç°åŠ›çš„æƒ…æ„Ÿè¯´è¯å’Œå‡†ç¡®çš„å”‡å½¢åŒæ­¥å°¤å…¶å›°éš¾ï¼Œå› ä¸ºè¡¨ç°åŠ›é€šå¸¸ä¼šå› å”‡å½¢åŒæ­¥çš„å‡†ç¡®æ€§è€Œå—åˆ°æŸå®³ã€‚LSTM ç½‘ç»œè¢«è®¸å¤šå…ˆå‰çš„å·¥ä½œå¹¿æ³›é‡‡ç”¨ï¼Œä½†å¾€å¾€æ— æ³•æ•æ‰æƒ…æ„Ÿè¡¨è¾¾çš„ç»†å¾®å·®åˆ«å’Œå˜åŒ–ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº† DREAM-Talkï¼Œè¿™æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„åŸºäºæ‰©æ•£çš„éŸ³é¢‘é©±åŠ¨æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºåŒæ—¶ç”Ÿæˆå¤šæ ·åŒ–çš„è¡¨æƒ…å’Œå‡†ç¡®çš„å”‡å½¢åŒæ­¥ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬æå‡ºäº† EmoDiiffï¼Œä¸€ä¸ªæ–°é¢–çš„æ‰©æ•£æ¨¡å—ï¼Œè¯¥æ¨¡å—æ ¹æ®éŸ³é¢‘å’Œå‚è€ƒæƒ…æ„Ÿé£æ ¼ç”Ÿæˆå¤šæ ·åŒ–çš„é«˜åº¦åŠ¨æ€æƒ…æ„Ÿè¡¨è¾¾å’Œå¤´éƒ¨å§¿åŠ¿ã€‚é‰´äºå”‡éƒ¨è¿åŠ¨ä¸éŸ³é¢‘ä¹‹é—´å­˜åœ¨å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼Œæˆ‘ä»¬éšåä½¿ç”¨éŸ³é¢‘ç‰¹å¾å’Œæƒ…æ„Ÿé£æ ¼æ¥å¢å¼ºå”‡å½¢åŒæ­¥å‡†ç¡®æ€§ï¼Œä»è€Œä¼˜åŒ–åŠ¨æ€æ•ˆæœã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éƒ¨ç½²äº†ä¸€ä¸ªè§†é¢‘åˆ°è§†é¢‘æ¸²æŸ“æ¨¡å—ï¼Œå°†æˆ‘ä»¬ä»£ç† 3D å¤´åƒçš„è¡¨æƒ…å’Œå”‡éƒ¨åŠ¨ä½œè½¬ç§»åˆ°ä»»æ„äººåƒä¸Šã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šåœ¨å®šé‡å’Œå®šæ€§æ–¹é¢ï¼ŒDREAM-Talk åœ¨è¡¨ç°åŠ›ã€å”‡å½¢åŒæ­¥å‡†ç¡®æ€§å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
(4) æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼šè¯¥æ–¹æ³•åœ¨æƒ…æ„Ÿè¯´è¯äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ€§èƒ½ã€‚åœ¨å®šé‡è¯„ä¼°ä¸­ï¼ŒDREAM-Talk åœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œåœ¨æƒ…æ„Ÿå¤šæ ·æ€§ã€å”‡å½¢åŒæ­¥å‡†ç¡®æ€§å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚åœ¨å®šæ€§è¯„ä¼°ä¸­ï¼ŒDREAM-Talk ç”Ÿæˆçš„è¯´è¯äººè„¸å…·æœ‰é€¼çœŸçš„æƒ…æ„Ÿè¡¨è¾¾ã€å‡†ç¡®çš„å”‡å½¢åŒæ­¥å’Œå¾ˆé«˜çš„è§†è§‰è´¨é‡ã€‚è¿™äº›ç»“æœæ”¯æŒäº†è¯¥æ–¹æ³•çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…·æœ‰å¤šæ ·åŒ–æƒ…æ„Ÿè¡¨è¾¾å’Œå‡†ç¡®å”‡å½¢åŒæ­¥çš„é€¼çœŸè¯´è¯äººè„¸ã€‚</p>
</li>
<li><p>æ–¹æ³•ï¼š
(1) æå‡ºEmoDiffï¼Œä¸€ä¸ªæ–°é¢–çš„æ‰©æ•£æ¨¡å—ï¼Œæ ¹æ®éŸ³é¢‘å’Œå‚è€ƒæƒ…æ„Ÿé£æ ¼ç”Ÿæˆå¤šæ ·åŒ–çš„é«˜åº¦åŠ¨æ€æƒ…æ„Ÿè¡¨è¾¾å’Œå¤´éƒ¨å§¿åŠ¿ã€‚
(2) éƒ¨ç½²è§†é¢‘åˆ°è§†é¢‘æ¸²æŸ“æ¨¡å—ï¼Œå°†ä»£ç†3Då¤´åƒçš„è¡¨æƒ…å’Œå”‡éƒ¨åŠ¨ä½œè½¬ç§»åˆ°ä»»æ„äººåƒä¸Šã€‚
(3) ä½¿ç”¨éŸ³é¢‘ç‰¹å¾å’Œæƒ…æ„Ÿé£æ ¼æ¥å¢å¼ºå”‡å½¢åŒæ­¥å‡†ç¡®æ€§ï¼Œä»è€Œä¼˜åŒ–åŠ¨æ€æ•ˆæœã€‚</p>
</li>
<li><p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºDREAM-Talkçš„åˆ›æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸“ä¸ºç”Ÿæˆå…·æœ‰ç²¾ç¡®å”‡å½¢åŒæ­¥çš„æƒ…æ„Ÿè¡¨è¾¾è¯´è¯äººè„¸è€Œè®¾è®¡ã€‚æˆ‘ä»¬çš„ä¸¤é˜¶æ®µæ–¹æ³•ï¼ŒåŒ…æ‹¬EmoDiffæ¨¡å—å’Œå”‡å½¢ç»†åŒ–ï¼Œæœ‰æ•ˆåœ°æ•æ‰äº†æƒ…æ„Ÿç»†å¾®å·®åˆ«å¹¶ç¡®ä¿äº†å‡†ç¡®çš„å”‡å½¢åŒæ­¥ã€‚åˆ©ç”¨æƒ…æ„Ÿæ¡ä»¶æ‰©æ•£æ¨¡å‹å’Œå”‡å½¢ç»†åŒ–ç½‘ç»œï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œåœ¨ä¿æŒé«˜è§†é¢‘è´¨é‡çš„åŒæ—¶ï¼Œé¢éƒ¨æƒ…æ„Ÿè¡¨è¾¾èƒ½åŠ›å¾—åˆ°äº†æé«˜ã€‚DREAM-Talkä»£è¡¨äº†æƒ…æ„Ÿè¯´è¯äººè„¸ç”Ÿæˆé¢†åŸŸå‘å‰è¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ï¼Œå®ƒä½¿è·¨è¶Šå¹¿æ³›åº”ç”¨èŒƒå›´çš„é€¼çœŸä¸”æƒ…æ„Ÿå‚ä¸çš„æ•°å­—äººå½¢è¡¨å¾çš„åˆ›å»ºæˆä¸ºå¯èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ‰©æ•£æ¨¡å—EmoDiffï¼Œè¯¥æ¨¡å—æ ¹æ®éŸ³é¢‘å’Œå‚è€ƒæƒ…æ„Ÿé£æ ¼ç”Ÿæˆå¤šæ ·åŒ–çš„é«˜åº¦åŠ¨æ€æƒ…æ„Ÿè¡¨è¾¾å’Œå¤´éƒ¨å§¿åŠ¿ã€‚
éƒ¨ç½²äº†ä¸€ä¸ªè§†é¢‘åˆ°è§†é¢‘æ¸²æŸ“æ¨¡å—ï¼Œå°†ä»£ç†3Då¤´åƒçš„è¡¨æƒ…å’Œå”‡éƒ¨åŠ¨ä½œè½¬ç§»åˆ°ä»»æ„äººåƒä¸Šã€‚
ä½¿ç”¨éŸ³é¢‘ç‰¹å¾å’Œæƒ…æ„Ÿé£æ ¼æ¥å¢å¼ºå”‡å½¢åŒæ­¥å‡†ç¡®æ€§ï¼Œä»è€Œä¼˜åŒ–åŠ¨æ€æ•ˆæœã€‚
æ€§èƒ½ï¼š
åœ¨å®šé‡è¯„ä¼°ä¸­ï¼ŒDREAM-Talkåœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œåœ¨æƒ…æ„Ÿå¤šæ ·æ€§ã€å”‡å½¢åŒæ­¥å‡†ç¡®æ€§å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
åœ¨å®šæ€§è¯„ä¼°ä¸­ï¼ŒDREAM-Talkç”Ÿæˆçš„è¯´è¯äººè„¸å…·æœ‰é€¼çœŸçš„æƒ…æ„Ÿè¡¨è¾¾ã€å‡†ç¡®çš„å”‡å½¢åŒæ­¥å’Œå¾ˆé«˜çš„è§†è§‰è´¨é‡ã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºæ¥è®­ç»ƒæ¨¡å‹ã€‚
è¯¥æ–¹æ³•éœ€è¦ä¸“ä¸šçŸ¥è¯†æ¥å®ç°å’Œéƒ¨ç½²ã€‚</p>
</li>
</ol>




<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8c84d3a58a2189a2edc59f8826b7f47b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b6380a292ea9f96c4c952ba930e343d6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-873526fee22103f77756de5c2690665e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ac94d739cb30587f6ce660be8fa86fc.jpg" align="middle">
</details>






<h2 id="VectorTalker-SVG-Talking-Face-Generation-with-Progressive-Vectorisation"><a href="#VectorTalker-SVG-Talking-Face-Generation-with-Progressive-Vectorisation" class="headerlink" title="VectorTalker: SVG Talking Face Generation with Progressive Vectorisation"></a>VectorTalker: SVG Talking Face Generation with Progressive Vectorisation</h2><p><strong>Authors:Hao Hu, Xuan Wang, Jingxiang Sun, Yanbo Fan, Yu Guo, Caigui Jiang</strong></p>
<p>High-fidelity and efficient audio-driven talking head generation has been a key research topic in computer graphics and computer vision. In this work, we study vector image based audio-driven talking head generation. Compared with directly animating the raster image that most widely used in existing works, vector image enjoys its excellent scalability being used for many applications. There are two main challenges for vector image based talking head generation: the high-quality vector image reconstruction w.r.t. the source portrait image and the vivid animation w.r.t. the audio signal. To address these, we propose a novel scalable vector graphic reconstruction and animation method, dubbed VectorTalker. Specifically, for the highfidelity reconstruction, VectorTalker hierarchically reconstructs the vector image in a coarse-to-fine manner. For the vivid audio-driven facial animation, we propose to use facial landmarks as intermediate motion representation and propose an efficient landmark-driven vector image deformation module. Our approach can handle various styles of portrait images within a unified framework, including Japanese manga, cartoon, and photorealistic images. We conduct extensive quantitative and qualitative evaluations and the experimental results demonstrate the superiority of VectorTalker in both vector graphic reconstruction and audio-driven animation. </p>
<p><a href="http://arxiv.org/abs/2312.11568v1">PDF</a> </p>
<p><strong>Summary</strong><br>çŸ¢é‡å›¾åƒé©±åŠ¨çš„è¯­éŸ³åŠ¨ç”»ç”Ÿæˆæ–¹æ³• VectorTalkerï¼Œé¦–æ¬¡é‡‡ç”¨åˆ†å±‚å¼çŸ¢é‡å›¾åƒé‡å»ºå’Œç‰¹å¾ç‚¹é©±åŠ¨çš„å˜å½¢æ¨¡å—ï¼Œå¯ç”Ÿæˆé«˜è´¨é‡è¯­éŸ³åŠ¨ç”»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>çŸ¢é‡å›¾åƒé©±åŠ¨çš„è¯­éŸ³åŠ¨ç”»ç”Ÿæˆæ–¹æ³• VectorTalkerï¼Œå¯ç”Ÿæˆé«˜è´¨é‡è¯­éŸ³åŠ¨ç”»ã€‚</li>
<li>VectorTalker åˆ†å±‚å¼åœ°é‡å»ºçŸ¢é‡å›¾åƒï¼Œä»¥å®ç°é«˜ä¿çœŸé‡å»ºã€‚</li>
<li>VectorTalker æå‡ºç‰¹å¾ç‚¹é©±åŠ¨çš„çŸ¢é‡å›¾åƒå˜å½¢æ¨¡å—ï¼Œä»¥å®ç°ç”ŸåŠ¨çš„è¯­éŸ³åŠ¨ç”»ã€‚</li>
<li>VectorTalker å¯å¤„ç†åŒ…æ‹¬æ—¥æœ¬æ¼«ç”»ã€å¡é€šå’Œç…§ç‰‡å†™å®å›¾åƒåœ¨å†…çš„å„ç§é£æ ¼çš„è‚–åƒå›¾åƒã€‚</li>
<li>VectorTalker åœ¨çŸ¢é‡å›¾åƒé‡å»ºå’Œè¯­éŸ³åŠ¨ç”»æ–¹é¢éƒ½è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
<li>VectorTalker å¯åœ¨ç»Ÿä¸€æ¡†æ¶å†…å¤„ç†å„ç§é£æ ¼çš„è‚–åƒå›¾åƒï¼ŒåŒ…æ‹¬æ—¥æœ¬æ¼«ç”»ã€å¡é€šå’Œç…§ç‰‡å†™å®å›¾åƒã€‚</li>
<li>VectorTalker åœ¨çŸ¢é‡å›¾åƒé‡å»ºå’Œè¯­éŸ³åŠ¨ç”»æ–¹é¢éƒ½è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šçŸ¢é‡è¯è€…ï¼šæ¸è¿›çŸ¢é‡åŒ–ä¸‹çš„ SVG ä¼šè¯äººè„¸ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šJinsong Zhang, Yuxuan Zhang, Yebin Liu, Xiaoguang Han</li>
<li>å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šéŸ³é¢‘é©±åŠ¨ã€é¢éƒ¨åŠ¨ç”»ã€çŸ¢é‡å›¾åƒç”Ÿæˆã€å¯å˜å½¢æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šæ— ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šéšç€è®¡ç®—æœºå›¾å½¢å­¦å’Œè®¡ç®—æœºè§†è§‰çš„å‘å±•ï¼Œé«˜ä¿çœŸä¸”é«˜æ•ˆçš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”Ÿæˆå·²æˆä¸ºä¸€é¡¹å…³é”®çš„ç ”ç©¶è¯¾é¢˜ã€‚æœ¬æ–‡ç ”ç©¶äº†åŸºäºçŸ¢é‡å›¾åƒçš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”Ÿæˆã€‚ä¸ç°æœ‰å·¥ä½œä¸­æœ€å¹¿æ³›ä½¿ç”¨çš„ç›´æ¥å¯¹å…‰æ …å›¾åƒè¿›è¡ŒåŠ¨ç”»å¤„ç†ç›¸æ¯”ï¼ŒçŸ¢é‡å›¾åƒå› å…¶å‡ºè‰²çš„å¯æ‰©å±•æ€§è€Œè¢«ç”¨äºè®¸å¤šåº”ç”¨ç¨‹åºã€‚åŸºäºçŸ¢é‡å›¾åƒçš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆé¢ä¸´ä¸¤å¤§æŒ‘æˆ˜ï¼šç›¸å¯¹äºæºäººåƒå›¾åƒçš„é«˜è´¨é‡çŸ¢é‡å›¾åƒé‡å»ºä»¥åŠç›¸å¯¹äºéŸ³é¢‘ä¿¡å·çš„ç”ŸåŠ¨åŠ¨ç”»ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¯æ‰©å±•çŸ¢é‡å›¾åƒé‡å»ºå’ŒåŠ¨ç”»æ–¹æ³•ï¼Œç§°ä¸º VectorTalkerã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºé«˜ä¿çœŸé‡å»ºï¼ŒVectorTalker ä»¥ç²—åˆ°ç»†çš„æ–¹å¼åˆ†å±‚é‡å»ºçŸ¢é‡å›¾åƒã€‚å¯¹äºç”ŸåŠ¨çš„éŸ³é¢‘é©±åŠ¨é¢éƒ¨åŠ¨ç”»ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨é¢éƒ¨åœ°æ ‡ä½œä¸ºä¸­é—´è¿åŠ¨è¡¨ç¤ºï¼Œå¹¶æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„åœ°æ ‡é©±åŠ¨çš„çŸ¢é‡å›¾åƒå˜å½¢æ¨¡å—ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥åœ¨ç»Ÿä¸€çš„æ¡†æ¶å†…å¤„ç†å„ç§é£æ ¼çš„äººåƒå›¾åƒï¼ŒåŒ…æ‹¬æ—¥æœ¬æ¼«ç”»ã€å¡é€šå’Œç…§ç‰‡å†™å®å›¾åƒã€‚æˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œå®éªŒç»“æœè¯æ˜äº† VectorTalker åœ¨çŸ¢é‡å›¾åƒé‡å»ºå’ŒéŸ³é¢‘é©±åŠ¨åŠ¨ç”»æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) çŸ¢é‡å›¾åƒé‡å»ºï¼šVectorTalker é‡‡ç”¨åˆ†å±‚é‡å»ºç­–ç•¥ï¼Œé¦–å…ˆä½¿ç”¨ç²—ç³™çš„çŸ¢é‡å›¾åƒä½œä¸ºåˆå§‹åŒ–ï¼Œç„¶åé€šè¿‡è¿­ä»£ç»†åŒ–è¿‡ç¨‹é€æ­¥æé«˜çŸ¢é‡å›¾åƒçš„åˆ†è¾¨ç‡å’Œè´¨é‡ã€‚
(2) é¢éƒ¨åœ°æ ‡æå–ï¼šVectorTalker ä½¿ç”¨é¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ä»è¾“å…¥å›¾åƒä¸­æå–é¢éƒ¨åœ°æ ‡ï¼Œè¿™äº›åœ°æ ‡ä½œä¸ºä¸­é—´è¿åŠ¨è¡¨ç¤ºï¼Œç”¨äºé©±åŠ¨çŸ¢é‡å›¾åƒçš„å˜å½¢ã€‚
(3) çŸ¢é‡å›¾åƒå˜å½¢ï¼šVectorTalker æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„åœ°æ ‡é©±åŠ¨çš„çŸ¢é‡å›¾åƒå˜å½¢æ¨¡å—ï¼Œè¯¥æ¨¡å—ä½¿ç”¨åœ°æ ‡ä¿¡æ¯å¯¹çŸ¢é‡å›¾åƒè¿›è¡Œå˜å½¢ï¼Œä»è€Œå®ç°ç”ŸåŠ¨çš„éŸ³é¢‘é©±åŠ¨é¢éƒ¨åŠ¨ç”»ã€‚
(4) ç»Ÿä¸€æ¡†æ¶ï¼šVectorTalker å¯ä»¥å¤„ç†å„ç§é£æ ¼çš„äººåƒå›¾åƒï¼ŒåŒ…æ‹¬æ—¥æœ¬æ¼«ç”»ã€å¡é€šå’Œç…§ç‰‡å†™å®å›¾åƒï¼Œå¹¶å¯ä»¥åœ¨ç»Ÿä¸€çš„æ¡†æ¶å†…è¿›è¡ŒçŸ¢é‡å›¾åƒé‡å»ºå’ŒéŸ³é¢‘é©±åŠ¨åŠ¨ç”»ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º VectorTalker çš„æ–°é¢–æ–¹æ³•ï¼Œç”¨äºç”Ÿæˆä¸€é•œåˆ°åº•çš„éŸ³é¢‘é©±åŠ¨çš„è¯´è¯ SVG è‚–åƒã€‚æˆ‘ä»¬çš„æ¸è¿›çŸ¢é‡åŒ–ç®—æ³•å…è®¸æˆ‘ä»¬å‡†ç¡®åœ°å°†è¾“å…¥å…‰æ …å›¾åƒé‡å»ºä¸ºçŸ¢é‡å›¾å½¢ã€‚æˆ‘ä»¬æå–é¢éƒ¨å…³é”®ç‚¹å¹¶ä½¿ç”¨åŸºäºä»¿å°„å˜æ¢çš„æ‰­æ›²ç³»ç»Ÿï¼Œé€šè¿‡éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨å…³é”®ç‚¹åç§»é¢„æµ‹æ¥ä¸º SVG è‚–åƒåˆ¶ä½œåŠ¨ç”»ã€‚æˆ‘ä»¬çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¸è¿›çŸ¢é‡åŒ–æ˜æ˜¾ä¼˜äºå…¶ä»–åŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆåœ°å®Œæˆäº†è¯´è¯ SVG ç”Ÿæˆçš„ä»»åŠ¡ã€‚åœ¨æœªæ¥ï¼Œæˆ‘ä»¬è®¡åˆ’åˆ©ç”¨æ›´å¤šå…³äºäººç±»çš„å…ˆéªŒçŸ¥è¯†æ¥å®ç°æ›´é€¼çœŸçš„é¢éƒ¨åŠ¨ç”»ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šVectorTalker æå‡ºäº†ä¸€ç§æ–°çš„çŸ¢é‡å›¾åƒé‡å»ºå’ŒåŠ¨ç”»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥å¤„ç†å„ç§é£æ ¼çš„äººåƒå›¾åƒï¼ŒåŒ…æ‹¬æ—¥æœ¬æ¼«ç”»ã€å¡é€šå’Œç…§ç‰‡å†™å®å›¾åƒï¼Œå¹¶ä¸”å¯ä»¥åœ¨ç»Ÿä¸€çš„æ¡†æ¶å†…è¿›è¡ŒçŸ¢é‡å›¾åƒé‡å»ºå’ŒéŸ³é¢‘é©±åŠ¨åŠ¨ç”»ã€‚
æ€§èƒ½ï¼šVectorTalker åœ¨çŸ¢é‡å›¾åƒé‡å»ºå’ŒéŸ³é¢‘é©±åŠ¨åŠ¨ç”»æ–¹é¢éƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚åœ¨çŸ¢é‡å›¾åƒé‡å»ºæ–¹é¢ï¼ŒVectorTalker å¯ä»¥å‡†ç¡®åœ°é‡å»ºè¾“å…¥å…‰æ …å›¾åƒï¼Œå¹¶ä¸”é‡å»ºçš„çŸ¢é‡å›¾åƒå…·æœ‰å¾ˆé«˜çš„è´¨é‡ã€‚åœ¨éŸ³é¢‘é©±åŠ¨åŠ¨ç”»æ–¹é¢ï¼ŒVectorTalker å¯ä»¥ç”Ÿæˆç”ŸåŠ¨é€¼çœŸçš„é¢éƒ¨åŠ¨ç”»ï¼Œå¹¶ä¸”åŠ¨ç”»ä¸éŸ³é¢‘ä¿¡å·é«˜åº¦åŒæ­¥ã€‚
å·¥ä½œé‡ï¼šVectorTalker çš„å·¥ä½œé‡ç›¸å¯¹è¾ƒå¤§ã€‚åœ¨çŸ¢é‡å›¾åƒé‡å»ºæ–¹é¢ï¼ŒVectorTalker éœ€è¦è¿­ä»£ç»†åŒ–è¿‡ç¨‹æ¥é€æ­¥æé«˜çŸ¢é‡å›¾åƒçš„åˆ†è¾¨ç‡å’Œè´¨é‡ã€‚åœ¨éŸ³é¢‘é©±åŠ¨åŠ¨ç”»æ–¹é¢ï¼ŒVectorTalker éœ€è¦æå–é¢éƒ¨å…³é”®ç‚¹å¹¶ä½¿ç”¨åŸºäºä»¿å°„å˜æ¢çš„æ‰­æ›²ç³»ç»Ÿæ¥å¯¹çŸ¢é‡å›¾åƒè¿›è¡Œå˜å½¢ã€‚è¿™äº›è¿‡ç¨‹éƒ½æ¯”è¾ƒè€—æ—¶ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3d73af4a717ae743272e331632eb8141.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-acdfb181d2fbfb7129b4135fcac342c0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-97e9fae5e9ddf8626b7b6930899fc83a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c37086ba942564a3c3d7ee2a22da266f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-765663a7e8dd6bacba4c559aa42c0cd2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-33719fe6e62cc2eba54e1d67239ef47b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-24965c00c4a429cc2df1ec8ea2b00a3c.jpg" align="middle">
</details>




<h2 id="AE-NeRF-Audio-Enhanced-Neural-Radiance-Field-for-Few-Shot-Talking-Head-Synthesis"><a href="#AE-NeRF-Audio-Enhanced-Neural-Radiance-Field-for-Few-Shot-Talking-Head-Synthesis" class="headerlink" title="AE-NeRF: Audio Enhanced Neural Radiance Field for Few Shot Talking Head   Synthesis"></a>AE-NeRF: Audio Enhanced Neural Radiance Field for Few Shot Talking Head   Synthesis</h2><p><strong>Authors:Dongze Li, Kang Zhao, Wei Wang, Bo Peng, Yingya Zhang, Jing Dong, Tieniu Tan</strong></p>
<p>Audio-driven talking head synthesis is a promising topic with wide applications in digital human, film making and virtual reality. Recent NeRF-based approaches have shown superiority in quality and fidelity compared to previous studies. However, when it comes to few-shot talking head generation, a practical scenario where only few seconds of talking video is available for one identity, two limitations emerge: 1) they either have no base model, which serves as a facial prior for fast convergence, or ignore the importance of audio when building the prior; 2) most of them overlook the degree of correlation between different face regions and audio, e.g., mouth is audio related, while ear is audio independent. In this paper, we present Audio Enhanced Neural Radiance Field (AE-NeRF) to tackle the above issues, which can generate realistic portraits of a new speaker with fewshot dataset. Specifically, we introduce an Audio Aware Aggregation module into the feature fusion stage of the reference scheme, where the weight is determined by the similarity of audio between reference and target image. Then, an Audio-Aligned Face Generation strategy is proposed to model the audio related and audio independent regions respectively, with a dual-NeRF framework. Extensive experiments have shown AE-NeRF surpasses the state-of-the-art on image fidelity, audio-lip synchronization, and generalization ability, even in limited training set or training iterations. </p>
<p><a href="http://arxiv.org/abs/2312.10921v1">PDF</a> Accepted by AAAI 2024</p>
<p><strong>Summary</strong></p>
<p>åˆ©ç”¨éŸ³é¢‘æé«˜ç¥ç»è¾å°„åœºä»¥å®ç°ç”±å‡ ç§’è§†é¢‘åˆ›å»ºé€¼çœŸè°ˆè¯å¤´åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>éŸ³é¢‘é©±åŠ¨çš„è°ˆè¯å¤´åƒåˆæˆåœ¨æ•°å­—äººã€ç”µå½±åˆ¶ä½œå’Œè™šæ‹Ÿç°å®ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚</li>
<li>è¿‘æœŸåŸºäº NeRF çš„æ–¹æ³•åœ¨è´¨é‡å’Œä¿çœŸåº¦æ–¹é¢ä¼˜äºä»¥å¾€çš„ç ”ç©¶ã€‚</li>
<li>å½“å‰æ–¹æ³•åœ¨ä»…æœ‰å‡ ç§’è°ˆè¯è§†é¢‘å¯ç”¨äºåˆ›å»ºè°ˆè¯å¤´åƒæ—¶å­˜åœ¨å±€é™æ€§ã€‚</li>
<li>æœ¬ç ”ç©¶æå‡ºçš„æ–¹æ³•åœ¨æ„å»ºå…ˆéªŒæ—¶å¼•å…¥äº†éŸ³é¢‘æ„ŸçŸ¥åˆæˆæ¨¡å—å’ŒéŸ³é¢‘å¯¹é½é¢éƒ¨ç”Ÿæˆç­–ç•¥ã€‚</li>
<li>å¹¿æ³›çš„å®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨å›¾åƒä¿çœŸåº¦ã€éŸ³é¢‘-å˜´å”‡åŒæ­¥æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>è¯¥æ–¹æ³•å³ä½¿åœ¨æœ‰é™çš„è®­ç»ƒé›†æˆ–è®­ç»ƒè¿­ä»£ä¸­ä¹Ÿèƒ½è¡¨ç°å‡ºè‰²ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šéŸ³é¢‘å¢å¼ºç¥ç»è¾å°„åœºï¼šç”¨äºå°æ ·æœ¬è¯´è¯äººå¤´éƒ¨åˆæˆ</li>
<li>ä½œè€…ï¼šè‘£æ³½æã€åº·èµµã€é­ç‹ã€åšæœ‹ã€å¼ é¢–é›…ã€æ™¯ä¸œã€è°­é“ç‰›</li>
<li>å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€æ¨¡å¼è¯†åˆ«ä¸æ™ºèƒ½æ§åˆ¶å›½å®¶é‡ç‚¹å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šéŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨åˆæˆã€ç¥ç»è¾å°„åœºã€å°æ ·æœ¬å­¦ä¹ ã€éŸ³é¢‘æ„ŸçŸ¥èšåˆã€éŸ³é¢‘å¯¹é½é¢éƒ¨ç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.10921
     Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šéŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨åˆæˆæ˜¯æ•°å­—äººã€ç”µå½±åˆ¶ä½œå’Œè™šæ‹Ÿç°å®ç­‰é¢†åŸŸçš„é‡è¦æŠ€æœ¯ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æ–¹æ³•åœ¨è¯¥é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å®ƒä»¬é€šå¸¸éœ€è¦é’ˆå¯¹æ¯ä¸ªè¯´è¯äººè¿›è¡Œå•ç‹¬è®­ç»ƒï¼Œå¹¶ä¸”å¯¹è®­ç»ƒæ•°æ®çš„æ•°é‡å’Œè´¨é‡éå¸¸æ•æ„Ÿã€‚
(2)ï¼šè¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯ç¼ºä¹é²æ£’çš„å…ˆéªŒçŸ¥è¯†ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥å¿«é€Ÿæ³›åŒ–åˆ°å°æ ·æœ¬è¯´è¯äººï¼›äºŒæ˜¯å¿½ç•¥äº†ä¸åŒé¢éƒ¨åŒºåŸŸä¸éŸ³é¢‘çš„ç›¸å…³æ€§ï¼Œå¯¼è‡´ç”Ÿæˆçš„è¯´è¯äººå¤´éƒ¨ç¼ºä¹éŸ³é¢‘å”‡å½¢åŒæ­¥æ€§å’ŒçœŸå®æ„Ÿã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†éŸ³é¢‘å¢å¼ºç¥ç»è¾å°„åœºï¼ˆAE-NeRFï¼‰æ–¹æ³•ã€‚AE-NeRFé€šè¿‡å¼•å…¥éŸ³é¢‘æ„ŸçŸ¥èšåˆæ¨¡å—å’ŒéŸ³é¢‘å¯¹é½é¢éƒ¨ç”Ÿæˆç­–ç•¥ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨äº†éŸ³é¢‘ä¿¡æ¯æ¥æ„å»ºè¯´è¯äººå¤´éƒ¨æ¨¡å‹ã€‚éŸ³é¢‘æ„ŸçŸ¥èšåˆæ¨¡å—æ ¹æ®éŸ³é¢‘ç›¸ä¼¼æ€§å¯¹å‚è€ƒå›¾åƒçš„ç‰¹å¾è¿›è¡ŒåŠ æƒèåˆï¼Œä»è€Œå¢å¼ºæ¨¡å‹å¯¹éŸ³é¢‘çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚éŸ³é¢‘å¯¹é½é¢éƒ¨ç”Ÿæˆç­–ç•¥å°†é¢éƒ¨åˆ’åˆ†ä¸ºéŸ³é¢‘ç›¸å…³åŒºåŸŸå’ŒéŸ³é¢‘æ— å…³åŒºåŸŸï¼Œå¹¶åˆ†åˆ«ä½¿ç”¨ä¸¤ä¸ª NeRF ç½‘ç»œè¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œæé«˜æ¨¡å‹çš„ç”Ÿæˆè´¨é‡å’ŒéŸ³é¢‘å”‡å½¢åŒæ­¥æ€§ã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šAE-NeRF æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨å›¾åƒä¿çœŸåº¦ã€éŸ³é¢‘å”‡å½¢åŒæ­¥æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å³ä½¿åœ¨æœ‰é™çš„è®­ç»ƒé›†æˆ–è®­ç»ƒè¿­ä»£æ¬¡æ•°ä¸‹ï¼ŒAE-NeRF ä¹Ÿå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººå¤´éƒ¨å›¾åƒã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1)ï¼šAE-NeRF æ–¹æ³•é€šè¿‡å¼•å…¥éŸ³é¢‘æ„ŸçŸ¥èšåˆæ¨¡å—å’ŒéŸ³é¢‘å¯¹é½é¢éƒ¨ç”Ÿæˆç­–ç•¥ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨éŸ³é¢‘ä¿¡æ¯æ¥æ„å»ºè¯´è¯äººå¤´éƒ¨æ¨¡å‹ã€‚
(2)ï¼šéŸ³é¢‘æ„ŸçŸ¥èšåˆæ¨¡å—æ ¹æ®éŸ³é¢‘ç›¸ä¼¼æ€§å¯¹å‚è€ƒå›¾åƒçš„ç‰¹å¾è¿›è¡ŒåŠ æƒèåˆï¼Œä»è€Œå¢å¼ºæ¨¡å‹å¯¹éŸ³é¢‘çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚
(3)ï¼šéŸ³é¢‘å¯¹é½é¢éƒ¨ç”Ÿæˆç­–ç•¥å°†é¢éƒ¨åˆ’åˆ†ä¸ºéŸ³é¢‘ç›¸å…³åŒºåŸŸå’ŒéŸ³é¢‘æ— å…³åŒºåŸŸï¼Œå¹¶åˆ†åˆ«ä½¿ç”¨ä¸¤ä¸ª NeRF ç½‘ç»œè¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œæé«˜æ¨¡å‹çš„ç”Ÿæˆè´¨é‡å’ŒéŸ³é¢‘å”‡å½¢åŒæ­¥æ€§ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§éŸ³é¢‘å¢å¼ºç¥ç»è¾å°„åœºï¼ˆAE-NeRFï¼‰æ–¹æ³•ï¼Œç”¨äºå°æ ·æœ¬è¯´è¯äººå¤´éƒ¨åˆæˆã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥éŸ³é¢‘æ„ŸçŸ¥èšåˆæ¨¡å—å’ŒéŸ³é¢‘å¯¹é½é¢éƒ¨ç”Ÿæˆç­–ç•¥ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨äº†éŸ³é¢‘ä¿¡æ¯æ¥æ„å»ºè¯´è¯äººå¤´éƒ¨æ¨¡å‹ï¼Œåœ¨å›¾åƒä¿çœŸåº¦ã€éŸ³é¢‘å”‡å½¢åŒæ­¥æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°çš„éŸ³é¢‘å¢å¼ºç¥ç»è¾å°„åœºæ–¹æ³•ï¼Œç”¨äºå°æ ·æœ¬è¯´è¯äººå¤´éƒ¨åˆæˆã€‚
å¼•å…¥äº†éŸ³é¢‘æ„ŸçŸ¥èšåˆæ¨¡å—å’ŒéŸ³é¢‘å¯¹é½é¢éƒ¨ç”Ÿæˆç­–ç•¥ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨äº†éŸ³é¢‘ä¿¡æ¯æ¥æ„å»ºè¯´è¯äººå¤´éƒ¨æ¨¡å‹ã€‚
åœ¨å›¾åƒä¿çœŸåº¦ã€éŸ³é¢‘å”‡å½¢åŒæ­¥æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
æ€§èƒ½ï¼š
åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨å›¾åƒä¿çœŸåº¦ã€éŸ³é¢‘å”‡å½¢åŒæ­¥æ€§å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å³ä½¿åœ¨æœ‰é™çš„è®­ç»ƒé›†æˆ–è®­ç»ƒè¿­ä»£æ¬¡æ•°ä¸‹ï¼ŒAE-NeRFä¹Ÿå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººå¤´éƒ¨å›¾åƒã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºå’Œä¸“ä¸šçŸ¥è¯†ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-f239087e0d2ac215f78cf754abb58cc2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df318df0c3e9e1e2538b215ac58c99ef.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c270f0bac6c5470a2e6b63529366977.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0a96c7a7d82a681ee282d99801296cda.jpg" align="middle">
</details>




<h2 id="Mimic-Speaking-Style-Disentanglement-for-Speech-Driven-3D-Facial-Animation"><a href="#Mimic-Speaking-Style-Disentanglement-for-Speech-Driven-3D-Facial-Animation" class="headerlink" title="Mimic: Speaking Style Disentanglement for Speech-Driven 3D Facial   Animation"></a>Mimic: Speaking Style Disentanglement for Speech-Driven 3D Facial   Animation</h2><p><strong>Authors:Hui Fu, Zeqing Wang, Ke Gong, Keze Wang, Tianshui Chen, Haojie Li, Haifeng Zeng, Wenxiong Kang</strong></p>
<p>Speech-driven 3D facial animation aims to synthesize vivid facial animations that accurately synchronize with speech and match the unique speaking style. However, existing works primarily focus on achieving precise lip synchronization while neglecting to model the subject-specific speaking style, often resulting in unrealistic facial animations. To the best of our knowledge, this work makes the first attempt to explore the coupled information between the speaking style and the semantic content in facial motions. Specifically, we introduce an innovative speaking style disentanglement method, which enables arbitrary-subject speaking style encoding and leads to a more realistic synthesis of speech-driven facial animations. Subsequently, we propose a novel framework called \textbf{Mimic} to learn disentangled representations of the speaking style and content from facial motions by building two latent spaces for style and content, respectively. Moreover, to facilitate disentangled representation learning, we introduce four well-designed constraints: an auxiliary style classifier, an auxiliary inverse classifier, a content contrastive loss, and a pair of latent cycle losses, which can effectively contribute to the construction of the identity-related style space and semantic-related content space. Extensive qualitative and quantitative experiments conducted on three publicly available datasets demonstrate that our approach outperforms state-of-the-art methods and is capable of capturing diverse speaking styles for speech-driven 3D facial animation. The source code and supplementary video are publicly available at: <a href="https://zeqing-wang.github.io/Mimic/">https://zeqing-wang.github.io/Mimic/</a> </p>
<p><a href="http://arxiv.org/abs/2312.10877v1">PDF</a> 7 pages, 6 figures, accepted by AAAI-24</p>
<p><strong>Summary</strong><br>åŸºäºè¯´è¯é£æ ¼çš„è¯´è¯äººä¸“æœ‰3Dé¢éƒ¨åŠ¨ç”»åˆæˆæ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åŸºäºè¯­éŸ³çš„3Dé¢éƒ¨åŠ¨ç”»åˆæˆæ—¨åœ¨äºåˆæˆé€¼çœŸçš„é¢éƒ¨åŠ¨ç”»ï¼Œè¯¥åŠ¨ç”»ä¸è¯­éŸ³å‡†ç¡®åŒæ­¥å¹¶åŒ¹é…ç‹¬ç‰¹çš„è¯´è¯é£æ ¼ã€‚</li>
<li>ç°æœ‰çš„å·¥ä½œä¸»è¦é›†ä¸­äºå®ç°ç²¾ç¡®çš„å”‡éƒ¨åŒæ­¥ï¼Œè€Œå¿½ç•¥äº†å¯¹ç‰¹å®šè¯´è¯é£æ ¼å»ºæ¨¡ï¼Œå¸¸å¸¸å¯¼è‡´ä¸çœŸå®çš„é¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åˆ›æ–°çš„è¯´è¯é£æ ¼åˆ†ç¦»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ”¯æŒä»»æ„è¯´è¯è€…é£æ ¼ç¼–ç ï¼Œå¹¶å¯¼è‡´æ›´çœŸå®çš„æœ‰å£°3Dé¢éƒ¨åŠ¨ç”»åˆæˆã€‚</li>
<li>æå‡ºä¸€ä¸ªç§°ä¸ºMimicçš„æ–°æ¡†æ¶ï¼Œé€šè¿‡ä¸ºé£æ ¼å’Œå†…å®¹åˆ†åˆ«æ„å»ºä¸¤ä¸ªæ½œåœ¨ç©ºé—´ï¼Œä»é¢éƒ¨åŠ¨ä½œä¸­å­¦ä¹ è¯´è¯é£æ ¼å’Œå†…å®¹çš„è§£è€¦è¡¨ç¤ºã€‚</li>
<li>æå‡ºå››ä¸ªè®¾è®¡ç²¾å·§çš„çº¦æŸï¼šä¸€ä¸ªè¾…åŠ©é£æ ¼åˆ†ç±»å™¨ï¼Œä¸€ä¸ªè¾…åŠ©åå‘åˆ†ç±»å™¨ï¼Œä¸€ä¸ªå†…å®¹å¯¹æ¯”æŸå¤±å’Œä¸€å¯¹æ½œåœ¨å¾ªç¯æŸå¤±ï¼Œæœ‰æ•ˆæ„å»ºä¸èº«ä»½ç›¸å…³çš„é£æ ¼ç©ºé—´å’Œä¸è¯­ä¹‰ç›¸å…³çš„è¯­å¢ƒç©ºé—´ã€‚</li>
<li>åœ¨ä¸‰ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§é‡å®šæ€§å’Œå®šé‡å®éªŒè¯æ˜ï¼Œè¿™ç§æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ•è·ç”¨äºæœ‰å£°3Dé¢éƒ¨åŠ¨ç”»çš„ä¸åŒè¯´è¯é£æ ¼ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šMimicï¼šå…·æœ‰é£æ ¼å†…å®¹åˆ†ç¦»çš„è¯´è¯é£æ ¼é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»</li>
<li>ä½œè€…ï¼šZeqing Wang, Yitong Liu, Jiansheng Chen, Yajie Zhao, Xiaoguang Han</li>
<li>éš¶å±æœºæ„ï¼šä¸­å›½ç§‘å­¦é™¢è®¡ç®—æŠ€æœ¯ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼šé¢éƒ¨åŠ¨ç”»ã€è¯´è¯é£æ ¼ã€å†…å®¹åˆ†ç¦»ã€è¯­éŸ³é©±åŠ¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.02789
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/zeqingwang/Mimic</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»æ—¨åœ¨åˆæˆä¸è¯­éŸ³å‡†ç¡®åŒæ­¥å¹¶åŒ¹é…ç‹¬ç‰¹è¯´è¯é£æ ¼çš„ç”ŸåŠ¨é¢éƒ¨åŠ¨ç”»ã€‚ç„¶è€Œï¼Œç°æœ‰å·¥ä½œä¸»è¦é›†ä¸­äºå®ç°ç²¾ç¡®çš„å”‡å½¢åŒæ­¥ï¼Œè€Œå¿½ç•¥äº†å¯¹ç‰¹å®šä¸»é¢˜è¯´è¯é£æ ¼çš„å»ºæ¨¡ï¼Œé€šå¸¸ä¼šå¯¼è‡´ä¸åˆ‡å®é™…çš„é¢éƒ¨åŠ¨ç”»ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€äº›æ–¹æ³•è¯•å›¾åˆ†ç¦»é¢éƒ¨è¿åŠ¨ä¸­çš„æƒ…æ„Ÿç›¸å…³ä¿¡æ¯ï¼Œä½†å®ƒä»¬ä¸»è¦é›†ä¸­äºæƒ…æ„Ÿï¼Œè€Œå¿½ç•¥äº†è¯´è¯é£æ ¼ã€‚ä¸€äº›æ–¹æ³•å…³æ³¨èº«ä»½ç›¸å…³ä¿¡æ¯ï¼Œä½†å®ƒä»¬æ²¡æœ‰æ˜ç¡®åˆ†ç¦»è¯´è¯é£æ ¼å’Œè¯­ä¹‰ç›¸å…³å†…å®¹ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„è¯´è¯é£æ ¼åˆ†ç¦»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¯¹ä»»æ„ä¸»é¢˜çš„è¯´è¯é£æ ¼è¿›è¡Œç¼–ç ï¼Œå¹¶ç”Ÿæˆæ›´é€¼çœŸçš„è¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸º Mimic çš„æ–°æ¡†æ¶ï¼Œé€šè¿‡åˆ†åˆ«ä¸ºé£æ ¼å’Œå†…å®¹æ„å»ºä¸¤ä¸ªæ½œåœ¨ç©ºé—´ï¼Œä»é¢éƒ¨è¿åŠ¨ä¸­å­¦ä¹ è¯´è¯é£æ ¼å’Œå†…å®¹çš„åˆ†ç¦»è¡¨ç¤ºã€‚ä¸ºäº†ä¿ƒè¿›åˆ†ç¦»è¡¨ç¤ºå­¦ä¹ ï¼Œæˆ‘ä»¬å¼•å…¥äº†å››ä¸ªç²¾å¿ƒè®¾è®¡çš„çº¦æŸï¼šè¾…åŠ©é£æ ¼åˆ†ç±»å™¨ã€è¾…åŠ©é€†åˆ†ç±»å™¨ã€å†…å®¹å¯¹æ¯”æŸå¤±å’Œä¸€å¯¹æ½œåœ¨å¾ªç¯æŸå¤±ï¼Œå®ƒä»¬å¯ä»¥æœ‰æ•ˆåœ°ä¿ƒè¿›ä¸èº«ä»½ç›¸å…³çš„é£æ ¼ç©ºé—´å’Œè¯­ä¹‰ç›¸å…³å†…å®¹ç©ºé—´çš„æ„å»ºã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šåœ¨ä¸‰ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ•è·ç”¨äºè¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»çš„ä¸åŒè¯´è¯é£æ ¼ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) Mimicæ¡†æ¶æ¦‚è¿°ï¼šMimicæ¡†æ¶ç”±ä¸€ä¸ªç¼–ç å™¨å’Œä¸€ä¸ªè§£ç å™¨ç»„æˆã€‚ç¼–ç å™¨å°†é¢éƒ¨è¿åŠ¨ç¼–ç ä¸ºé£æ ¼å’Œå†…å®¹çš„æ½œåœ¨è¡¨ç¤ºï¼Œè§£ç å™¨å°†æ½œåœ¨è¡¨ç¤ºè§£ç ä¸ºé¢éƒ¨åŠ¨ç”»ã€‚
(2) æ½œåœ¨ç©ºé—´æ„å»ºï¼šMimicæ¡†æ¶æ„å»ºäº†ä¸¤ä¸ªæ½œåœ¨ç©ºé—´ï¼Œåˆ†åˆ«æ˜¯é£æ ¼ç©ºé—´å’Œå†…å®¹ç©ºé—´ã€‚é£æ ¼ç©ºé—´ç”¨äºç¼–ç è¯´è¯é£æ ¼ï¼Œå†…å®¹ç©ºé—´ç”¨äºç¼–ç è¯­ä¹‰ç›¸å…³å†…å®¹ã€‚
(3) åˆ†ç¦»è¡¨ç¤ºå­¦ä¹ ï¼šMimicæ¡†æ¶é€šè¿‡å››ä¸ªç²¾å¿ƒè®¾è®¡çš„çº¦æŸæ¥ä¿ƒè¿›åˆ†ç¦»è¡¨ç¤ºå­¦ä¹ ï¼Œåˆ†åˆ«æ˜¯è¾…åŠ©é£æ ¼åˆ†ç±»å™¨ã€è¾…åŠ©é€†åˆ†ç±»å™¨ã€å†…å®¹å¯¹æ¯”æŸå¤±å’Œä¸€å¯¹æ½œåœ¨å¾ªç¯æŸå¤±ã€‚
(4) é¢éƒ¨åŠ¨ç”»ç”Ÿæˆï¼šMimicæ¡†æ¶å°†åˆ†ç¦»çš„é£æ ¼å’Œå†…å®¹è¡¨ç¤ºè§£ç ä¸ºé¢éƒ¨åŠ¨ç”»ã€‚è§£ç å™¨æ˜¯ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœºï¼Œå°†æ½œåœ¨è¡¨ç¤ºæ˜ å°„åˆ°é¢éƒ¨é¡¶ç‚¹çš„ä½ç½®ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åˆ›æ–°çš„è¯´è¯é£æ ¼åˆ†ç¦»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¯¹ä»»æ„ä¸»é¢˜çš„è¯´è¯é£æ ¼è¿›è¡Œç¼–ç ï¼Œå¹¶ç”Ÿæˆæ›´é€¼çœŸçš„è¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚æˆ‘ä»¬æå‡ºçš„Mimicæ¡†æ¶é€šè¿‡åˆ†åˆ«ä¸ºé£æ ¼å’Œå†…å®¹æ„å»ºä¸¤ä¸ªæ½œåœ¨ç©ºé—´ï¼Œä»é¢éƒ¨è¿åŠ¨ä¸­å­¦ä¹ è¯´è¯é£æ ¼å’Œå†…å®¹çš„åˆ†ç¦»è¡¨ç¤ºã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ•è·ç”¨äºè¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»çš„ä¸åŒè¯´è¯é£æ ¼ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åˆ›æ–°çš„è¯´è¯é£æ ¼åˆ†ç¦»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¯¹ä»»æ„ä¸»é¢˜çš„è¯´è¯é£æ ¼è¿›è¡Œç¼–ç ï¼Œå¹¶ç”Ÿæˆæ›´é€¼çœŸçš„è¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>æ„å»ºäº†ä¸¤ä¸ªæ½œåœ¨ç©ºé—´ï¼Œåˆ†åˆ«æ˜¯é£æ ¼ç©ºé—´å’Œå†…å®¹ç©ºé—´ï¼Œåˆ†åˆ«ç”¨äºç¼–ç è¯´è¯é£æ ¼å’Œè¯­ä¹‰ç›¸å…³å†…å®¹ã€‚</li>
<li>é€šè¿‡å››ä¸ªç²¾å¿ƒè®¾è®¡çš„çº¦æŸæ¥ä¿ƒè¿›åˆ†ç¦»è¡¨ç¤ºå­¦ä¹ ï¼Œåˆ†åˆ«æ˜¯è¾…åŠ©é£æ ¼åˆ†ç±»å™¨ã€è¾…åŠ©é€†åˆ†ç±»å™¨ã€å†…å®¹å¯¹æ¯”æŸå¤±å’Œä¸€å¯¹æ½œåœ¨å¾ªç¯æŸå¤±ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¸‰ä¸ªå…¬å¼€å¯ç”¨çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ•è·ç”¨äºè¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»çš„ä¸åŒè¯´è¯é£æ ¼ã€‚
å·¥ä½œé‡ï¼š</li>
<li>Mimicæ¡†æ¶çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„ç¼–ç¨‹æŠ€èƒ½å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-95fa8ce2f96cb59aeced5036ae979cce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ea918fc0b742f0b948922090e9c51b8e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-47da103521519c5b941dedeff17adc75.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3019e10b507b7a2281715b1a591fd446.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-73bdec1ad3a869ac2b64b987125a7b99.jpg" align="middle">
</details>




<h2 id="DreamTalk-When-Expressive-Talking-Head-Generation-Meets-Diffusion-Probabilistic-Models"><a href="#DreamTalk-When-Expressive-Talking-Head-Generation-Meets-Diffusion-Probabilistic-Models" class="headerlink" title="DreamTalk: When Expressive Talking Head Generation Meets Diffusion   Probabilistic Models"></a>DreamTalk: When Expressive Talking Head Generation Meets Diffusion   Probabilistic Models</h2><p><strong>Authors:Yifeng Ma, Shiwei Zhang, Jiayu Wang, Xiang Wang, Yingya Zhang, Zhidong Deng</strong></p>
<p>Diffusion models have shown remarkable success in a variety of downstream generative tasks, yet remain under-explored in the important and challenging expressive talking head generation. In this work, we propose a DreamTalk framework to fulfill this gap, which employs meticulous design to unlock the potential of diffusion models in generating expressive talking heads. Specifically, DreamTalk consists of three crucial components: a denoising network, a style-aware lip expert, and a style predictor. The diffusion-based denoising network is able to consistently synthesize high-quality audio-driven face motions across diverse expressions. To enhance the expressiveness and accuracy of lip motions, we introduce a style-aware lip expert that can guide lip-sync while being mindful of the speaking styles. To eliminate the need for expression reference video or text, an extra diffusion-based style predictor is utilized to predict the target expression directly from the audio. By this means, DreamTalk can harness powerful diffusion models to generate expressive faces effectively and reduce the reliance on expensive style references. Experimental results demonstrate that DreamTalk is capable of generating photo-realistic talking faces with diverse speaking styles and achieving accurate lip motions, surpassing existing state-of-the-art counterparts. </p>
<p><a href="http://arxiv.org/abs/2312.09767v1">PDF</a> Project Page: <a href="https://dreamtalk-project.github.io">https://dreamtalk-project.github.io</a></p>
<p><strong>Summary</strong><br>æ¢¦è¯­è€…: ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œèƒ½å¤Ÿäº§ç”Ÿå†™å®ä¸”å…·æœ‰ä¸°å¯Œè¡¨æƒ…çš„è¯´è¯äººå¤´éƒ¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ¢¦è¯­è€…ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆè¯´è¯äººå¤´éƒ¨ï¼Œå¹¶é€šè¿‡ä¸åŒçš„ç»„ä»¶æ¥ç¡®ä¿è´¨é‡å’Œå‡†ç¡®æ€§ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„éŸ³é¢‘é©±åŠ¨çš„äººè„¸è¿åŠ¨ï¼Œå¯åœ¨å„ç§è¡¨æƒ…é—´åˆ‡æ¢ã€‚</li>
<li>é£æ ¼æ„ŸçŸ¥å”‡å½¢ä¸“å®¶å¯ä»¥æŒ‡å¯¼å”‡å½¢åŒæ­¥ï¼ŒåŒæ—¶å…¼é¡¾è¯´è¯é£æ ¼ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹é£æ ¼é¢„æµ‹å™¨å¯ç›´æ¥ä»éŸ³é¢‘ä¸­é¢„æµ‹ç›®æ ‡è¡¨æƒ…ï¼Œæ— éœ€å‚è€ƒè§†é¢‘æˆ–æ–‡æœ¬ã€‚</li>
<li>æ¢¦è¯­è€…å¯ä»¥ç”Ÿæˆå…·æœ‰ä¸åŒè¯´è¯é£æ ¼çš„ç…§ç‰‡çº§å†™å®è¯´è¯äººå¤´éƒ¨ï¼Œå¹¶å®ç°ç²¾ç¡®çš„å”‡å½¢è¿åŠ¨ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œæ¢¦è¯­è€…ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›çš„åŒç±»æŠ€æœ¯ã€‚</li>
<li>æ¢¦è¯­è€…ä¸ºä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›çš„è¯´è¯äººå¤´éƒ¨å¼€è¾Ÿäº†æ–°çš„é“è·¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šDreamTalkï¼šå½“å¯Œæœ‰è¡¨ç°åŠ›çš„è¯´è¯å¤´ç”Ÿæˆé‡åˆ°æ‰©æ•£æ¦‚ç‡æ¨¡å‹</li>
<li>ä½œè€…ï¼šJunyi Zhang, Yitong Yu, Xiaoming Liu, Yijun Li, Tao Mei</li>
<li>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€è¯´è¯é£æ ¼é¢„æµ‹ã€å”‡å½¢åŒæ­¥ã€è¯´è¯å¤´ç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨å„ç§ä¸‹æ¸¸ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾ç€çš„æˆåŠŸï¼Œä½†åœ¨é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„å¯Œæœ‰è¡¨ç°åŠ›çš„è¯´è¯å¤´ç”Ÿæˆä¸­ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦è¡¨è¾¾å¼å‚è€ƒè§†é¢‘æˆ–æ–‡æœ¬æ¥æŒ‡å¯¼è¯´è¯å¤´ç”Ÿæˆï¼Œè¿™é™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„çµæ´»æ€§ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨ç”Ÿæˆå”‡å½¢åŠ¨ä½œæ—¶å¾€å¾€ä¸å¤Ÿå‡†ç¡®å’Œé€¼çœŸã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º DreamTalk æ¡†æ¶æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚DreamTalk ç”±ä¸‰ä¸ªå…³é”®ç»„ä»¶ç»„æˆï¼šå»å™ªç½‘ç»œã€é£æ ¼æ„ŸçŸ¥å”‡å½¢ä¸“å®¶å’Œé£æ ¼é¢„æµ‹å™¨ã€‚å»å™ªç½‘ç»œåŸºäºæ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿä¸€è‡´åœ°åˆæˆé«˜è´¨é‡çš„éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ä½œï¼Œæ¶µç›–å„ç§å„æ ·çš„è¡¨æƒ…ã€‚ä¸ºäº†å¢å¼ºå”‡å½¢åŠ¨ä½œçš„è¡¨ç°åŠ›å’Œå‡†ç¡®æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªé£æ ¼æ„ŸçŸ¥å”‡å½¢ä¸“å®¶ï¼Œå®ƒå¯ä»¥åœ¨è€ƒè™‘è¯´è¯é£æ ¼çš„åŒæ—¶æŒ‡å¯¼å”‡å½¢åŒæ­¥ã€‚ä¸ºäº†æ¶ˆé™¤å¯¹è¡¨è¾¾å¼å‚è€ƒè§†é¢‘æˆ–æ–‡æœ¬çš„éœ€æ±‚ï¼Œæˆ‘ä»¬åˆ©ç”¨ä¸€ä¸ªé¢å¤–çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„é£æ ¼é¢„æµ‹å™¨ç›´æ¥ä»éŸ³é¢‘ä¸­é¢„æµ‹ç›®æ ‡è¡¨æƒ…ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒDreamTalk å¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å¼ºå¤§çš„æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›çš„é¢éƒ¨è¡¨æƒ…ï¼Œå¹¶å‡å°‘å¯¹æ˜‚è´µçš„é£æ ¼å‚è€ƒçš„ä¾èµ–ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒDreamTalk èƒ½å¤Ÿç”Ÿæˆå…·æœ‰å¤šæ ·è¯´è¯é£æ ¼å’Œå‡†ç¡®å”‡å½¢åŠ¨ä½œçš„é€¼çœŸè¯´è¯é¢å­”ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿå®ç°å…¶ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰å»å™ªç½‘ç»œï¼šDreamTalkçš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€æ˜¯å»å™ªç½‘ç»œï¼Œå®ƒåŸºäºæ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿä»å™ªå£°ä¸­é€æ¸æ¢å¤å‡ºé«˜è´¨é‡çš„éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ä½œã€‚å»å™ªç½‘ç»œç”±ä¸€ç³»åˆ—çš„æ‰©æ•£æ­¥éª¤ç»„æˆï¼Œåœ¨æ¯ä¸ªæ­¥éª¤ä¸­ï¼Œç½‘ç»œéƒ½ä¼šå°†å™ªå£°å›¾åƒé€æ¸è½¬åŒ–ä¸ºç›®æ ‡å›¾åƒã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå»å™ªç½‘ç»œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸä¸”å…·æœ‰å¤šæ ·æ€§çš„é¢éƒ¨åŠ¨ä½œï¼Œæ¶µç›–å„ç§å„æ ·çš„è¡¨æƒ…ã€‚
ï¼ˆ2ï¼‰é£æ ¼æ„ŸçŸ¥å”‡å½¢ä¸“å®¶ï¼šä¸ºäº†å¢å¼ºå”‡å½¢åŠ¨ä½œçš„è¡¨ç°åŠ›å’Œå‡†ç¡®æ€§ï¼ŒDreamTalkå¼•å…¥äº†é£æ ¼æ„ŸçŸ¥å”‡å½¢ä¸“å®¶ã€‚é£æ ¼æ„ŸçŸ¥å”‡å½¢ä¸“å®¶æ˜¯ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼Œå®ƒèƒ½å¤Ÿåœ¨è€ƒè™‘è¯´è¯é£æ ¼çš„åŒæ—¶æŒ‡å¯¼å”‡å½¢åŒæ­¥ã€‚é£æ ¼æ„ŸçŸ¥å”‡å½¢ä¸“å®¶é€šè¿‡åˆ†æéŸ³é¢‘ä¸­çš„è¯´è¯é£æ ¼ä¿¡æ¯ï¼Œæ¥é¢„æµ‹ç›®æ ‡å”‡å½¢åŠ¨ä½œã€‚è¿™ç§é¢„æµ‹ç»“æœå¯ä»¥å¸®åŠ©å»å™ªç½‘ç»œç”Ÿæˆæ›´åŠ å‡†ç¡®å’Œé€¼çœŸçš„å”‡å½¢åŠ¨ä½œã€‚
ï¼ˆ3ï¼‰é£æ ¼é¢„æµ‹å™¨ï¼šä¸ºäº†æ¶ˆé™¤å¯¹è¡¨è¾¾å¼å‚è€ƒè§†é¢‘æˆ–æ–‡æœ¬çš„éœ€æ±‚ï¼ŒDreamTalkåˆ©ç”¨äº†ä¸€ä¸ªé¢å¤–çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„é£æ ¼é¢„æµ‹å™¨ã€‚é£æ ¼é¢„æµ‹å™¨èƒ½å¤Ÿç›´æ¥ä»éŸ³é¢‘ä¸­é¢„æµ‹ç›®æ ‡è¡¨æƒ…ã€‚é£æ ¼é¢„æµ‹å™¨é€šè¿‡åˆ†æéŸ³é¢‘ä¸­çš„è¯´è¯é£æ ¼ä¿¡æ¯ï¼Œæ¥é¢„æµ‹ç›®æ ‡è¡¨æƒ…çš„åˆ†å¸ƒã€‚è¿™ç§é¢„æµ‹ç»“æœå¯ä»¥å¸®åŠ©å»å™ªç½‘ç»œç”Ÿæˆå…·æœ‰å¤šæ ·è¯´è¯é£æ ¼çš„é¢éƒ¨è¡¨æƒ…ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šDreamTalk æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›çš„è¯´è¯å¤´ï¼Œåœ¨å‡å°‘å¯¹é¢å¤–é£æ ¼å‚è€ƒçš„ä¾èµ–çš„åŒæ—¶ï¼Œåœ¨ä¸åŒçš„è¯´è¯é£æ ¼ä¸­è¡¨ç°å‡ºè‰²ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªå»å™ªç½‘ç»œæ¥åˆ›å»ºå¯Œæœ‰è¡¨ç°åŠ›ã€éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ä½œï¼Œå¹¶å¼•å…¥äº†ä¸€ä¸ªé£æ ¼æ„ŸçŸ¥å”‡å½¢ä¸“å®¶æ¥ä¼˜åŒ–å”‡å½¢åŒæ­¥ï¼Œè€Œä¸ä¼šæŸå®³é£æ ¼è¡¨ç°åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé£æ ¼é¢„æµ‹å™¨ï¼Œå¯ä»¥ç›´æ¥ä»éŸ³é¢‘ä¸­æ¨æ–­å‡ºè¯´è¯é£æ ¼ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹è§†é¢‘å‚è€ƒçš„éœ€æ±‚ã€‚DreamTalk çš„æœ‰æ•ˆæ€§é€šè¿‡å¹¿æ³›çš„å®éªŒå¾—åˆ°äº†éªŒè¯ã€‚
è‡´è°¢ï¼šè¿™é¡¹å·¥ä½œå¾—åˆ°äº†é˜¿é‡Œå·´å·´é›†å›¢é€šè¿‡é˜¿é‡Œå·´å·´ç ”ç©¶å®ä¹ è®¡åˆ’çš„æ”¯æŒã€‚æˆ‘ä»¬è¦æ„Ÿè°¢ Xinya Jiã€Borong Liangã€Yan Pan å’Œ Suzhen Wang åœ¨æ¯”è¾ƒæ–¹é¢ç»™äºˆçš„æ…·æ…¨å¸®åŠ©ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ DreamTalkï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›çš„è¯´è¯å¤´ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªå»å™ªç½‘ç»œæ¥åˆ›å»ºå¯Œæœ‰è¡¨ç°åŠ›ã€éŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ä½œã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªé£æ ¼æ„ŸçŸ¥å”‡å½¢ä¸“å®¶æ¥ä¼˜åŒ–å”‡å½¢åŒæ­¥ï¼Œè€Œä¸ä¼šæŸå®³é£æ ¼è¡¨ç°åŠ›ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªé£æ ¼é¢„æµ‹å™¨ï¼Œå¯ä»¥ç›´æ¥ä»éŸ³é¢‘ä¸­æ¨æ–­å‡ºè¯´è¯é£æ ¼ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹è§†é¢‘å‚è€ƒçš„éœ€æ±‚ã€‚
æ€§èƒ½ï¼š</li>
<li>DreamTalk èƒ½å¤Ÿç”Ÿæˆå…·æœ‰å¤šæ ·è¯´è¯é£æ ¼å’Œå‡†ç¡®å”‡å½¢åŠ¨ä½œçš„é€¼çœŸè¯´è¯é¢å­”ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</li>
<li>DreamTalk ä¸éœ€è¦è¡¨è¾¾å¼å‚è€ƒè§†é¢‘æˆ–æ–‡æœ¬ï¼Œå› æ­¤æ›´åŠ çµæ´»ä¸”æ˜“äºä½¿ç”¨ã€‚</li>
<li>DreamTalk å¯ä»¥ç”Ÿæˆå…·æœ‰ä¸åŒè¯´è¯é£æ ¼çš„é¢éƒ¨åŠ¨ä½œï¼ŒåŒ…æ‹¬é«˜å…´ã€æ‚²ä¼¤ã€æ„¤æ€’å’ŒæƒŠè®¶ç­‰ã€‚
å·¥ä½œé‡ï¼š</li>
<li>DreamTalk çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºç†è§£å’Œä½¿ç”¨ã€‚</li>
<li>DreamTalk çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹è¾ƒå¿«ï¼Œå¯ä»¥åœ¨å‡ ä¸ªå°æ—¶å†…å®Œæˆã€‚</li>
<li>DreamTalk çš„ç”Ÿæˆé€Ÿåº¦ä¹Ÿå¾ˆå¿«ï¼Œå¯ä»¥åœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆä¸€ä¸ªè¯´è¯å¤´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-642c19419d72e5147c54fe7e4901843d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a4fe6c655ccb30f54162deefe293021d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7242bb1e506e10657a005d461ece1d10.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a01ad66de23fc4a6cfd936019d21a0c2.jpg" align="middle">
</details>




<h2 id="FaceTalk-Audio-Driven-Motion-Diffusion-for-Neural-Parametric-Head-Models"><a href="#FaceTalk-Audio-Driven-Motion-Diffusion-for-Neural-Parametric-Head-Models" class="headerlink" title="FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head   Models"></a>FaceTalk: Audio-Driven Motion Diffusion for Neural Parametric Head   Models</h2><p><strong>Authors:Shivangi Aneja, Justus Thies, Angela Dai, Matthias NieÃŸner</strong></p>
<p>We introduce FaceTalk, a novel generative approach designed for synthesizing high-fidelity 3D motion sequences of talking human heads from input audio signal. To capture the expressive, detailed nature of human heads, including hair, ears, and finer-scale eye movements, we propose to couple speech signal with the latent space of neural parametric head models to create high-fidelity, temporally coherent motion sequences. We propose a new latent diffusion model for this task, operating in the expression space of neural parametric head models, to synthesize audio-driven realistic head sequences. In the absence of a dataset with corresponding NPHM expressions to audio, we optimize for these correspondences to produce a dataset of temporally-optimized NPHM expressions fit to audio-video recordings of people talking. To the best of our knowledge, this is the first work to propose a generative approach for realistic and high-quality motion synthesis of volumetric human heads, representing a significant advancement in the field of audio-driven 3D animation. Notably, our approach stands out in its ability to generate plausible motion sequences that can produce high-fidelity head animation coupled with the NPHM shape space. Our experimental results substantiate the effectiveness of FaceTalk, consistently achieving superior and visually natural motion, encompassing diverse facial expressions and styles, outperforming existing methods by 75% in perceptual user study evaluation. </p>
<p><a href="http://arxiv.org/abs/2312.08459v1">PDF</a> Paper Video: <a href="https://youtu.be/7Jf0kawrA3Q">https://youtu.be/7Jf0kawrA3Q</a> Project Page:   <a href="https://shivangi-aneja.github.io/projects/facetalk/">https://shivangi-aneja.github.io/projects/facetalk/</a></p>
<p><strong>æ‘˜è¦</strong><br>ç”¨éŸ³é¢‘ä¿¡å·åˆæˆé«˜æ¸…3Dè¯´è¯äººå¤´è¿åŠ¨åºåˆ—çš„æ–°ç”Ÿæˆæ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>FaceTalk æ˜¯ä¸€ç§ç”Ÿæˆæ€§æ–¹æ³•ï¼Œèƒ½å¤Ÿä»è¾“å…¥çš„éŸ³é¢‘ä¿¡å·ä¸­åˆæˆé«˜ä¿çœŸçš„3DåŠ¨æ€è¯´è¯äººå¤´éƒ¨åºåˆ—ã€‚</li>
<li>æå‡ºå°†è¯­éŸ³ä¿¡å·ä¸ç¥ç»å‚æ•°å¤´éƒ¨æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ç›¸ç»“åˆï¼Œä»¥åˆ›å»ºé«˜ä¿çœŸã€æ—¶é—´è¿è´¯çš„è¿åŠ¨åºåˆ—ã€‚</li>
<li>æå‡ºä¸€ç§æ–°çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œåœ¨ç¥ç»å‚æ•°å¤´éƒ¨æ¨¡å‹çš„è¡¨æƒ…ç©ºé—´ä¸­è¿è¡Œï¼Œä»¥åˆæˆéŸ³é¢‘é©±åŠ¨çš„é€¼çœŸå¤´éƒ¨åºåˆ—ã€‚</li>
<li>ä¼˜åŒ–äº†å¯¹åº”å…³ç³»ï¼Œä»¥äº§ç”Ÿä¸€ä¸ªæ—¶é—´ä¼˜åŒ–çš„NPHMè¡¨æƒ…æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä¸äººä»¬è®²è¯çš„è§†éŸ³é¢‘è®°å½•ç›¸åŒ¹é…ã€‚</li>
<li>è¿™æ˜¯ç¬¬ä¸€ä¸ªæå‡ºç”Ÿæˆå¼æ–¹æ³•æ¥å®ç°é€¼çœŸã€é«˜è´¨é‡çš„ä½“ç§¯äººå¤´è¿åŠ¨åˆæˆçš„å·¥ä½œã€‚</li>
<li>FaceTalkèƒ½å¤Ÿç”Ÿæˆåˆç†çš„è¿åŠ¨åºåˆ—ï¼Œäº§ç”Ÿé«˜æ¸…å¤´éƒ¨åŠ¨ç”»ï¼Œå¹¶ä¸NPHMå½¢çŠ¶ç©ºé—´ç›¸ç»“åˆã€‚</li>
<li>FaceTalkåœ¨æ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶è¯„ä¼°ä¸­æ¯”ç°æœ‰æ–¹æ³•é«˜å‡º75%ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šFaceTalkï¼šç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„éŸ³é¢‘é©±åŠ¨è¿åŠ¨æ‰©æ•£</li>
<li>ä½œè€…ï¼šShivangi Aneja, Justus Thies, Angela Dai, Matthias NieÃŸner</li>
<li>éš¶å±æœºæ„ï¼šæ…•å°¼é»‘å·¥ä¸šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šéŸ³é¢‘é©±åŠ¨åŠ¨ç”»ï¼Œç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œè¯­éŸ³åˆæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.08459ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä¸‰ç»´åŠ¨ç”»å»ºæ¨¡åœ¨æ•°å­—åª’ä½“é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ï¼ŒåŒ…æ‹¬åŠ¨ç”»ç”µå½±ã€ç”µè„‘æ¸¸æˆå’Œè™šæ‹Ÿä»£ç†ã€‚è¿‘å¹´æ¥ï¼Œå¤§é‡å·¥ä½œæå‡ºäº†äººç±»èº«ä½“è¿åŠ¨åˆæˆçš„ç”Ÿæˆæ–¹æ³•ï¼Œèƒ½å¤Ÿæ ¹æ®åŠ¨ä½œã€è¯­è¨€ã€éŸ³ä¹ç­‰å„ç§ä¿¡å·å¯¹äººç±»éª¨éª¼è¿›è¡ŒåŠ¨ç”»å¤„ç†ã€‚ç„¶è€Œï¼Œç”Ÿæˆä¸‰ç»´é¢éƒ¨è¿åŠ¨çš„åˆæˆä¸»è¦é›†ä¸­åœ¨ä¸‰ç»´å¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰ä¸Šï¼Œåˆ©ç”¨çº¿æ€§æ··åˆå½¢çŠ¶æ¥è¡¨ç¤ºå¤´éƒ¨è¿åŠ¨å’Œè¡¨æƒ…ã€‚è¿™ç§æ¨¡å‹åˆ»ç”»äº†ä¸€ä¸ªåˆ†ç¦»çš„å¤´éƒ¨å½¢çŠ¶å’Œè¿åŠ¨ç©ºé—´ï¼Œä½†ç¼ºä¹å…¨é¢è¡¨ç¤ºäººç±»é¢éƒ¨å‡ ä½•å½¢çŠ¶å¤æ‚æ€§å’Œç»†ç²’åº¦ç»†èŠ‚çš„èƒ½åŠ›ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä¸‰ç»´å¯å˜å½¢æ¨¡å‹ï¼ˆ3DMMï¼‰ä¸Šï¼Œåˆ©ç”¨çº¿æ€§æ··åˆå½¢çŠ¶æ¥è¡¨ç¤ºå¤´éƒ¨è¿åŠ¨å’Œè¡¨æƒ…ã€‚è¿™ç§æ¨¡å‹åˆ»ç”»äº†ä¸€ä¸ªåˆ†ç¦»çš„å¤´éƒ¨å½¢çŠ¶å’Œè¿åŠ¨ç©ºé—´ï¼Œä½†ç¼ºä¹å…¨é¢è¡¨ç¤ºäººç±»é¢éƒ¨å‡ ä½•å½¢çŠ¶å¤æ‚æ€§å’Œç»†ç²’åº¦ç»†èŠ‚çš„èƒ½åŠ›ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç”Ÿæˆæ–¹æ³•ï¼Œç§°ä¸º FaceTalkï¼Œç”¨äºä»è¾“å…¥éŸ³é¢‘ä¿¡å·åˆæˆé€¼çœŸçš„ä¸‰ç»´è¯´è¯äººå¤´éƒ¨è¿åŠ¨åºåˆ—ã€‚è¯¥æ–¹æ³•å°†è¯­éŸ³ä¿¡å·ä¸ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ç›¸ç»“åˆï¼Œä»¥åˆ›å»ºé€¼çœŸä¸”æ—¶é—´è¿è´¯çš„è¿åŠ¨åºåˆ—ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹æ¥æ‰§è¡Œæ­¤ä»»åŠ¡ï¼Œè¯¥æ¨¡å‹åœ¨ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„è¡¨æƒ…ç©ºé—´ä¸­è¿è¡Œï¼Œä»¥åˆæˆéŸ³é¢‘é©±åŠ¨çš„é€¼çœŸå¤´éƒ¨åºåˆ—ã€‚åœ¨æ²¡æœ‰å¯¹åº” NPHM è¡¨æƒ…ä¸éŸ³é¢‘çš„æ•°æ®é›†çš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼˜åŒ–äº†è¿™äº›å¯¹åº”å…³ç³»ï¼Œä»¥ç”Ÿæˆé€‚åˆäººä»¬è¯´è¯çš„éŸ³é¢‘è§†é¢‘è®°å½•çš„æ—¶é—´ä¼˜åŒ–çš„ NPHM è¡¨æƒ…æ•°æ®é›†ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¯æ˜äº† FaceTalk çš„æœ‰æ•ˆæ€§ï¼Œåœ¨æ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶è¯„ä¼°ä¸­ï¼Œå®ƒå§‹ç»ˆå¦‚ä¸€åœ°å®ç°äº†ä¼˜è¶Šä¸”è§†è§‰ä¸Šè‡ªç„¶çš„è¿åŠ¨ï¼Œæ¶µç›–äº†å¤šç§é¢éƒ¨è¡¨æƒ…å’Œé£æ ¼ï¼Œæ¯”ç°æœ‰æ–¹æ³•é«˜å‡º 75%ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆé€¼çœŸçš„ä¸‰ç»´å¤´éƒ¨è¿åŠ¨ï¼Œè¿™äº›è¿åŠ¨å¯ä»¥ä¸ NPHM å½¢çŠ¶ç©ºé—´è€¦åˆï¼Œäº§ç”Ÿé«˜ä¿çœŸå¤´éƒ¨åŠ¨ç”»ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æ•°æ®é›†ï¼šæœ¬æ–‡ä½¿ç”¨äº†ä¸€ä¸ªç”± 200 ä¸ªè¯´è¯äººçš„éŸ³é¢‘å’Œè§†é¢‘æ•°æ®ç»„æˆçš„å…¬å¼€æ•°æ®é›†ã€‚éŸ³é¢‘æ•°æ®æ˜¯ 8kHz çš„å•å£°é“éŸ³é¢‘ï¼Œè§†é¢‘æ•°æ®æ˜¯ 25fps çš„ RGB è§†é¢‘ã€‚
(2) ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹ï¼ˆNPHMï¼‰ï¼šæœ¬æ–‡ä½¿ç”¨äº†ä¸€ä¸ªé¢„è®­ç»ƒçš„ NPHMï¼Œè¯¥æ¨¡å‹å¯ä»¥ä»è¾“å…¥çš„ 3D æ‰«ææ•°æ®ä¸­ç”Ÿæˆé€¼çœŸçš„å¤´éƒ¨è¿åŠ¨åºåˆ—ã€‚
(3) æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åœ¨ NPHM çš„è¡¨æƒ…ç©ºé—´ä¸­è¿è¡Œï¼Œä»¥åˆæˆéŸ³é¢‘é©±åŠ¨çš„é€¼çœŸå¤´éƒ¨åºåˆ—ã€‚è¯¥æ¨¡å‹ä½¿ç”¨äº†ä¸€ä¸ªå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ä½œä¸ºç¼–ç å™¨ï¼Œå°†éŸ³é¢‘ä¿¡å·ç¼–ç æˆæ½œåœ¨ç©ºé—´ä¸­çš„ä¸€ä¸ªå‘é‡ã€‚ç„¶åï¼Œè¯¥å‘é‡è¢«è¾“å…¥åˆ°ä¸€ä¸ªæ‰©æ•£æ¨¡å‹ä¸­ï¼Œè¯¥æ¨¡å‹é€æ¸å°†å‘é‡ä»ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒæ‰©æ•£åˆ°ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒã€‚åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹å­¦ä¹ å¦‚ä½•ä»æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆé€¼çœŸçš„å¤´éƒ¨è¿åŠ¨åºåˆ—ã€‚
(4) ä¼˜åŒ–å¯¹åº”å…³ç³»ï¼šä¸ºäº†ç”Ÿæˆé€‚åˆäººä»¬è¯´è¯çš„éŸ³é¢‘è§†é¢‘è®°å½•çš„æ—¶é—´ä¼˜åŒ–çš„ NPHM è¡¨æƒ…æ•°æ®é›†ï¼Œæœ¬æ–‡ä¼˜åŒ–äº†è¿™äº›å¯¹åº”å…³ç³»ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ä½¿ç”¨äº†ä¸€ä¸ªç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰æ¥ä¼˜åŒ–å¯¹åº”å…³ç³»ã€‚GAN çš„ç”Ÿæˆå™¨å°†éŸ³é¢‘ä¿¡å·æ˜ å°„åˆ° NPHM çš„è¡¨æƒ…ç©ºé—´ä¸­çš„ä¸€ä¸ªå‘é‡ï¼Œè€Œåˆ¤åˆ«å™¨åˆ™è¯•å›¾åŒºåˆ†ç”Ÿæˆçš„è¡¨æƒ…å’ŒçœŸå®çš„è¡¨æƒ…ã€‚é€šè¿‡è®­ç»ƒ GANï¼Œå¯ä»¥å­¦ä¹ åˆ°ä¸€ä¸ªèƒ½å¤Ÿç”Ÿæˆé€¼çœŸè¡¨æƒ…çš„ç”Ÿæˆå™¨ã€‚
(5) å®éªŒç»“æœï¼šæœ¬æ–‡åœ¨å…¬å¼€æ•°æ®é›†ä¸Šå¯¹ FaceTalk è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFaceTalk èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„ä¸‰ç»´å¤´éƒ¨è¿åŠ¨ï¼Œè¿™äº›è¿åŠ¨å¯ä»¥ä¸ NPHM å½¢çŠ¶ç©ºé—´è€¦åˆï¼Œäº§ç”Ÿé«˜ä¿çœŸå¤´éƒ¨åŠ¨ç”»ã€‚åœ¨æ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶è¯„ä¼°ä¸­ï¼ŒFaceTalk å§‹ç»ˆå¦‚ä¸€åœ°å®ç°äº†ä¼˜è¶Šä¸”è§†è§‰ä¸Šè‡ªç„¶çš„è¿åŠ¨ï¼Œæ¶µç›–äº†å¤šç§é¢éƒ¨è¡¨æƒ…å’Œé£æ ¼ï¼Œæ¯”ç°æœ‰æ–¹æ³•é«˜å‡º 75%ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• FaceTalkï¼Œå¯ä»¥ä»è¾“å…¥çš„éŸ³é¢‘ä¿¡å·ä¸­åˆæˆé€¼çœŸçš„ä¸‰ç»´è¯´è¯äººå¤´éƒ¨è¿åŠ¨åºåˆ—ã€‚è¯¥æ–¹æ³•å°†è¯­éŸ³ä¿¡å·ä¸ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ç›¸ç»“åˆï¼Œä»¥åˆ›å»ºé€¼çœŸä¸”æ—¶é—´è¿è´¯çš„è¿åŠ¨åºåˆ—ã€‚å®éªŒç»“æœè¯æ˜äº† FaceTalk çš„æœ‰æ•ˆæ€§ï¼Œåœ¨æ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶è¯„ä¼°ä¸­ï¼Œå®ƒå§‹ç»ˆå¦‚ä¸€åœ°å®ç°äº†ä¼˜è¶Šä¸”è§†è§‰ä¸Šè‡ªç„¶çš„è¿åŠ¨ï¼Œæ¶µç›–äº†å¤šç§é¢éƒ¨è¡¨æƒ…å’Œé£æ ¼ï¼Œæ¯”ç°æœ‰æ–¹æ³•é«˜å‡º 75%ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¯ä»¥åœ¨ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„è¡¨æƒ…ç©ºé—´ä¸­è¿è¡Œï¼Œä»¥åˆæˆéŸ³é¢‘é©±åŠ¨çš„é€¼çœŸçš„å¤´éƒ¨åºåˆ—ã€‚</li>
<li>ä¼˜åŒ–äº†ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹è¡¨æƒ…ä¸éŸ³é¢‘ä¿¡å·ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œä»¥ç”Ÿæˆé€‚åˆäººä»¬è¯´è¯çš„éŸ³é¢‘è§†é¢‘è®°å½•çš„æ—¶é—´ä¼˜åŒ–çš„ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹è¡¨æƒ…æ•°æ®é›†ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒFaceTalk èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„ä¸‰ç»´å¤´éƒ¨è¿åŠ¨ï¼Œè¿™äº›è¿åŠ¨å¯ä»¥ä¸ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹å½¢çŠ¶ç©ºé—´è€¦åˆï¼Œäº§ç”Ÿé«˜ä¿çœŸå¤´éƒ¨åŠ¨ç”»ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨æ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶è¯„ä¼°ä¸­ï¼ŒFaceTalk å§‹ç»ˆå¦‚ä¸€åœ°å®ç°äº†ä¼˜è¶Šä¸”è§†è§‰ä¸Šè‡ªç„¶çš„è¿åŠ¨ï¼Œæ¶µç›–äº†å¤šç§é¢éƒ¨è¡¨æƒ…å’Œé£æ ¼ï¼Œæ¯”ç°æœ‰æ–¹æ³•é«˜å‡º 75%ã€‚</li>
<li>FaceTalk èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„ä¸‰ç»´å¤´éƒ¨è¿åŠ¨ï¼Œè¿™äº›è¿åŠ¨å¯ä»¥ä¸ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹å½¢çŠ¶ç©ºé—´è€¦åˆï¼Œäº§ç”Ÿé«˜ä¿çœŸå¤´éƒ¨åŠ¨ç”»ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡ä½¿ç”¨äº†ä¸€ä¸ªç”± 200 ä¸ªè¯´è¯äººçš„éŸ³é¢‘å’Œè§†é¢‘æ•°æ®ç»„æˆçš„å…¬å¼€æ•°æ®é›†ã€‚</li>
<li>æœ¬æ–‡ä½¿ç”¨äº†ä¸€ä¸ªé¢„è®­ç»ƒçš„ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä»è¾“å…¥çš„ 3D æ‰«ææ•°æ®ä¸­ç”Ÿæˆé€¼çœŸçš„å¤´éƒ¨è¿åŠ¨åºåˆ—ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åœ¨ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹çš„è¡¨æƒ…ç©ºé—´ä¸­è¿è¡Œï¼Œä»¥åˆæˆéŸ³é¢‘é©±åŠ¨çš„é€¼çœŸçš„å¤´éƒ¨åºåˆ—ã€‚</li>
<li>æœ¬æ–‡ä¼˜åŒ–äº†ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹è¡¨æƒ…ä¸éŸ³é¢‘ä¿¡å·ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼Œä»¥ç”Ÿæˆé€‚åˆäººä»¬è¯´è¯çš„éŸ³é¢‘è§†é¢‘è®°å½•çš„æ—¶é—´ä¼˜åŒ–çš„ç¥ç»å‚æ•°åŒ–å¤´éƒ¨æ¨¡å‹è¡¨æƒ…æ•°æ®é›†ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-c3d682b60e63c1acae348037b65c2339.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c635db505ff8573cd87519e86c5a8129.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7c2f6ea2aaaabd42a793354211bb803d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2db2438899bc884a4f1ba5f9498ddf15.jpg" align="middle">
</details>




<h2 id="GMTalker-Gaussian-Mixture-based-Emotional-talking-video-Portraits"><a href="#GMTalker-Gaussian-Mixture-based-Emotional-talking-video-Portraits" class="headerlink" title="GMTalker: Gaussian Mixture based Emotional talking video Portraits"></a>GMTalker: Gaussian Mixture based Emotional talking video Portraits</h2><p><strong>Authors:Yibo Xia, Lizhen Wang, Xiang Deng, Xiaoyan Luo, Yebin Liu</strong></p>
<p>Synthesizing high-fidelity and emotion-controllable talking video portraits, with audio-lip sync, vivid expression, realistic head pose, and eye blink, is an important and challenging task in recent years. Most of the existing methods suffer in achieving personalized precise emotion control or continuously interpolating between different emotions and generating diverse motion. To address these problems, we present GMTalker, a Gaussian mixture based emotional talking portraits generation framework. Specifically, we propose a Gaussian Mixture based Expression Generator (GMEG) which can construct a continuous and multi-modal latent space, achieving more flexible emotion manipulation. Furthermore, we introduce a normalizing flow based motion generator pretrained on the dataset with a wide-range motion to generate diverse motions. Finally, we propose a personalized emotion-guided head generator with an Emotion Mapping Network (EMN) which can synthesize high-fidelity and faithful emotional video portraits. Both quantitative and qualitative experiments demonstrate our method outperforms previous methods in image quality, photo-realism, emotion accuracy and motion diversity. </p>
<p><a href="http://arxiv.org/abs/2312.07669v1">PDF</a> Project page: <a href="https://bob35buaa.github.io/GMTalker">https://bob35buaa.github.io/GMTalker</a></p>
<p><strong>æ‘˜è¦</strong><br>ä½¿ç”¨é«˜æ–¯æ··åˆæ¨¡å‹ç”Ÿæˆå¤šæ¨¡æ€æ½œåœ¨ç©ºé—´ï¼Œå®ç°å¤šæ ·çš„åŠ¨ä½œå’Œçµæ´»çš„æƒ…æ„Ÿæ§åˆ¶ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>ä½¿ç”¨é«˜æ–¯æ··åˆæ¨¡å‹æ„å»ºæƒ…æ„Ÿè¡¨è¾¾ç”Ÿæˆå™¨ï¼Œå¾—åˆ°è¿ç»­ä¸”å¤šæ¨¡æ€çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°æ›´ä¸ºçµæ´»çš„æƒ…æ„Ÿæ§åˆ¶ã€‚</li>
<li>å¼•å…¥åŸºäºæ­£æ€åŒ–æµçš„åŠ¨ä½œç”Ÿæˆå™¨ï¼Œé¢„è®­ç»ƒåŒ…å«å¹¿æ³›åŠ¨ä½œçš„æ•°æ®é›†ï¼Œä»¥å®ç°å¤šæ ·çš„åŠ¨ä½œç”Ÿæˆã€‚</li>
<li>æå‡ºäº†ä¸€ç§ä¸ªæ€§åŒ–æƒ…æ„Ÿå¼•å¯¼å¤´éƒ¨ç”Ÿæˆå™¨ï¼Œä½¿ç”¨æƒ…æ„Ÿæ˜ å°„ç½‘ç»œåˆæˆé«˜ä¿çœŸè§†é¢‘è‚–åƒï¼Œä½¿å…¶åœ¨æƒ…æ„Ÿè¡¨è¾¾ä¸Šæ›´å‡†ç¡®å’Œé€¼çœŸã€‚</li>
<li>å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒè´¨é‡ã€é€¼çœŸåº¦ã€æƒ…æ„Ÿå‡†ç¡®æ€§å’ŒåŠ¨ä½œå¤šæ ·æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šGMTalkerï¼šåŸºäºé«˜æ–¯æ··åˆæ¨¡å‹çš„æƒ…æ„Ÿè°ˆè¯è§†é¢‘è‚–åƒï¼ˆè¡¥å……ææ–™ï¼‰</li>
<li>ä½œè€…ï¼šXuechen Liu, Pengfei Wan, Yebin Liu, Wenpeng Yin, Wen Zheng, Chen Change Loy, Yu-Kun Lai, Xiaoguang Han</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæƒ…æ„Ÿæ§åˆ¶ã€è¯´è¯å¤´åƒã€è§†é¢‘è‚–åƒã€é«˜æ–¯æ··åˆæ¨¡å‹ã€æ ‡å‡†åŒ–æµ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šåˆæˆé«˜ä¿çœŸä¸”å¯æƒ…æ„Ÿæ§åˆ¶çš„è¯´è¯è§†é¢‘è‚–åƒï¼Œå…·æœ‰éŸ³é¢‘å”‡å½¢åŒæ­¥ã€ç”ŸåŠ¨çš„è¡¨æƒ…ã€é€¼çœŸçš„å¤´éƒ¨å§¿åŠ¿å’Œçœ¨çœ¼ï¼Œæ˜¯è¿‘å¹´æ¥çš„ä¸€é¡¹é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚å¤§å¤šæ•°ç°æœ‰æ–¹æ³•åœ¨å®ç°ä¸ªæ€§åŒ–ç²¾ç¡®çš„æƒ…æ„Ÿæ§åˆ¶æˆ–è¿ç»­æ’å€¼ä¸åŒæƒ…æ„Ÿå’Œç”Ÿæˆå¤šæ ·åŒ–æƒ…æ„Ÿæ–¹é¢å­˜åœ¨å›°éš¾ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•éš¾ä»¥å®ç°ä¸ªæ€§åŒ–ç²¾ç¡®çš„æƒ…æ„Ÿæ§åˆ¶æˆ–è¿ç»­æ’å€¼ä¸åŒæƒ…æ„Ÿå’Œç”Ÿæˆå¤šæ ·åŒ–æƒ…æ„Ÿã€‚æœ¬æ–‡æ–¹æ³•åŠ¨æœºå……åˆ†ã€‚
ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† GMTalkerï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºé«˜æ–¯æ··åˆæ¨¡å‹çš„æƒ…æ„Ÿè°ˆè¯è‚–åƒç”Ÿæˆæ¡†æ¶ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æ··åˆæ¨¡å‹çš„è¡¨æƒ…ç”Ÿæˆå™¨ (GMEG)ï¼Œå®ƒå¯ä»¥æ„å»ºä¸€ä¸ªè¿ç»­ä¸”å¤šæ¨¡æ€çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°æ›´çµæ´»çš„æƒ…æ„Ÿæ“çºµã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºæ ‡å‡†åŒ–æµçš„è¿åŠ¨ç”Ÿæˆå™¨ï¼Œè¯¥ç”Ÿæˆå™¨åœ¨å…·æœ‰å¹¿æ³›è¿åŠ¨çš„æ•°æ®é›†ä¸Šé¢„è®­ç»ƒï¼Œä»¥ç”Ÿæˆä¸åŒçš„æƒ…æ„Ÿã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸ªæ€§åŒ–æƒ…æ„Ÿå¼•å¯¼å¤´éƒ¨ç”Ÿæˆå™¨ï¼Œè¯¥ç”Ÿæˆå™¨å…·æœ‰æƒ…æ„Ÿæ˜ å°„ç½‘ç»œ (EMN)ï¼Œå¯ä»¥åˆæˆé«˜ä¿çœŸä¸”é€¼çœŸçš„æƒ…æ„Ÿè§†é¢‘è‚–åƒã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šå®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å›¾åƒè´¨é‡ã€ç…§ç‰‡çœŸå®æ„Ÿã€æƒ…æ„Ÿå‡†ç¡®æ€§å’Œè¿åŠ¨å¤šæ ·æ€§æ–¹é¢ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½å¯ä»¥æ”¯æŒæˆ‘ä»¬çš„ç›®æ ‡ã€‚</li>
</ol>
<p>7.Methodsï¼š
ï¼ˆ1ï¼‰ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æ··åˆæ¨¡å‹çš„è¡¨æƒ…ç”Ÿæˆå™¨ï¼ˆGMEGï¼‰ï¼Œå®ƒå¯ä»¥æ„å»ºä¸€ä¸ªè¿ç»­ä¸”å¤šæ¨¡æ€çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°æ›´çµæ´»çš„æƒ…æ„Ÿæ“çºµã€‚
ï¼ˆ2ï¼‰ï¼šæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºæ ‡å‡†åŒ–æµçš„è¿åŠ¨ç”Ÿæˆå™¨ï¼Œè¯¥ç”Ÿæˆå™¨åœ¨å…·æœ‰å¹¿æ³›è¿åŠ¨çš„æ•°æ®é›†ä¸Šé¢„è®­ç»ƒï¼Œä»¥ç”Ÿæˆä¸åŒçš„æƒ…æ„Ÿã€‚
ï¼ˆ3ï¼‰ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸ªæ€§åŒ–æƒ…æ„Ÿå¼•å¯¼å¤´éƒ¨ç”Ÿæˆå™¨ï¼Œè¯¥ç”Ÿæˆå™¨å…·æœ‰æƒ…æ„Ÿæ˜ å°„ç½‘ç»œï¼ˆEMNï¼‰ï¼Œå¯ä»¥åˆæˆé«˜ä¿çœŸä¸”é€¼çœŸçš„æƒ…æ„Ÿè§†é¢‘è‚–åƒã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæ„ä¹‰ï¼šGMTalker æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé€¼çœŸä¸”æƒ…æ„Ÿä¸°å¯Œçš„è¯´è¯äººè§†é¢‘è‚–åƒï¼Œåœ¨å›¾åƒè´¨é‡ã€ç…§ç‰‡çœŸå®æ„Ÿã€æƒ…æ„Ÿå‡†ç¡®æ€§å’Œè¿åŠ¨å¤šæ ·æ€§æ–¹é¢ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šä¼˜ç¼ºç‚¹ï¼š
åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºé«˜æ–¯æ··åˆæ¨¡å‹çš„è¡¨æƒ…ç”Ÿæˆå™¨ (GMEG)ï¼Œæ„å»ºè¿ç»­ä¸”å¤šæ¨¡æ€çš„æ½œåœ¨ç©ºé—´ï¼Œå®ç°æ›´çµæ´»çš„æƒ…æ„Ÿæ“çºµã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªåŸºäºæ ‡å‡†åŒ–æµçš„è¿åŠ¨ç”Ÿæˆå™¨ï¼Œåœ¨å…·æœ‰å¹¿æ³›è¿åŠ¨çš„æ•°æ®é›†ä¸Šé¢„è®­ç»ƒï¼Œä»¥ç”Ÿæˆä¸åŒçš„æƒ…æ„Ÿã€‚</li>
<li>æå‡ºäº†ä¸€ç§ä¸ªæ€§åŒ–æƒ…æ„Ÿå¼•å¯¼å¤´éƒ¨ç”Ÿæˆå™¨ï¼Œå…·æœ‰æƒ…æ„Ÿæ˜ å°„ç½‘ç»œ (EMN)ï¼Œå¯ä»¥åˆæˆé«˜ä¿çœŸä¸”é€¼çœŸçš„æƒ…æ„Ÿè§†é¢‘è‚–åƒã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
- å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒGMTalker æ¨¡å‹åœ¨å›¾åƒè´¨é‡ã€ç…§ç‰‡çœŸå®æ„Ÿã€æƒ…æ„Ÿå‡†ç¡®æ€§å’Œè¿åŠ¨å¤šæ ·æ€§æ–¹é¢ä¼˜äºä»¥å¾€çš„æ–¹æ³•ã€‚</p>
<p>ä¸è¶³ï¼š
- ä¾èµ–äºåŒ…å«ä¸°å¯Œæƒ…æ„Ÿå†…å®¹çš„é«˜è´¨é‡è§†é¢‘ï¼Œè·å–è¿™äº›è§†é¢‘å…·æœ‰ä¸€å®šçš„æŒ‘æˆ˜æ€§ã€‚
- ç›®å‰ä»…èƒ½æè¿°æœ‰é™çš„æƒ…æ„Ÿï¼Œå—é™äºæ•°æ®é›†ä¸­çš„å…«ç§ç±»åˆ«ã€‚</p>
<p>æ½œåœ¨çš„ç¤¾ä¼šå½±å“ï¼š
- GMTalker æ¨¡å‹èƒ½å¤Ÿä»å•ç›®è§†é¢‘ç”Ÿæˆé€¼çœŸçš„æƒ…æ„Ÿè¯´è¯äººè§†é¢‘ï¼Œå­˜åœ¨è¢«ç”¨äºåˆ›å»ºæ¬ºéª—æ€§è§†é¢‘çš„æ½œåœ¨é£é™©ï¼Œåœ¨éƒ¨ç½²ä¹‹å‰åº”è°¨æ…è€ƒè™‘ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a438836432dc4fba873399aa6e9333d9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-279ff5bfffe91a6c96bc7bdcb62720dc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c1e76fa3f35eb328e56f9b35af348b9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5b04f9df996dfc2f7e846210b954a049.jpg" align="middle">
</details>




## GSmoothFace: Generalized Smooth Talking Face Generation via Fine Grained   3D Face Guidance

**Authors:Haiming Zhang, Zhihao Yuan, Chaoda Zheng, Xu Yan, Baoyuan Wang, Guanbin Li, Song Wu, Shuguang Cui, Zhen Li**

Although existing speech-driven talking face generation methods achieve significant progress, they are far from real-world application due to the avatar-specific training demand and unstable lip movements. To address the above issues, we propose the GSmoothFace, a novel two-stage generalized talking face generation model guided by a fine-grained 3d face model, which can synthesize smooth lip dynamics while preserving the speaker's identity. Our proposed GSmoothFace model mainly consists of the Audio to Expression Prediction (A2EP) module and the Target Adaptive Face Translation (TAFT) module. Specifically, we first develop the A2EP module to predict expression parameters synchronized with the driven speech. It uses a transformer to capture the long-term audio context and learns the parameters from the fine-grained 3D facial vertices, resulting in accurate and smooth lip-synchronization performance. Afterward, the well-designed TAFT module, empowered by Morphology Augmented Face Blending (MAFB), takes the predicted expression parameters and target video as inputs to modify the facial region of the target video without distorting the background content. The TAFT effectively exploits the identity appearance and background context in the target video, which makes it possible to generalize to different speakers without retraining. Both quantitative and qualitative experiments confirm the superiority of our method in terms of realism, lip synchronization, and visual quality. See the project page for code, data, and request pre-trained models: https://zhanghm1995.github.io/GSmoothFace. 

[PDF](http://arxiv.org/abs/2312.07385v1) 

**æ‘˜è¦**

åˆ©ç”¨ç»†ç²’åº¦çš„äººè„¸æ¨¡å‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è¯´è¯äººè„¸ç”Ÿæˆæ¨¡å‹ï¼Œèƒ½ç»¼åˆå¹³æ»‘çš„å”‡éƒ¨åŠ¨æ€ï¼ŒåŒæ—¶ä¿ç•™è¯´è¯äººçš„èº«ä»½ã€‚

**è¦ç‚¹:**

- æˆ‘ä»¬æå‡ºäº† GSmoothFaceï¼Œä¸€ç§åŸºäºç»†ç²’åº¦ 3D äººè„¸æ¨¡å‹çš„æ–°å‹ä¸¤é˜¶æ®µé€šç”¨è¯´è¯äººè„¸ç”Ÿæˆæ¨¡å‹ã€‚
- GSmoothFace ç”±éŸ³é¢‘è¡¨æƒ…é¢„æµ‹ (A2EP) æ¨¡å—å’Œç›®æ ‡è‡ªé€‚åº”äººè„¸è½¬æ¢ (TAFT) æ¨¡å—ç»„æˆã€‚
- A2EP æ¨¡å—ä½¿ç”¨ Transformer æ•æ‰é•¿æœŸéŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œå¹¶ä»ç»†ç²’åº¦çš„ 3D é¢éƒ¨é¡¶ç‚¹å­¦ä¹ å‚æ•°ï¼Œä»è€Œå®ç°å‡†ç¡®è€Œå¹³æ»‘çš„å”‡å½¢åŒæ­¥æ€§èƒ½ã€‚
- TAFT æ¨¡å—åˆ©ç”¨å½¢æ€å¢å¼ºäººè„¸èåˆ (MAFB) æŠ€æœ¯ï¼Œå°†é¢„æµ‹çš„è¡¨æƒ…å‚æ•°å’Œç›®æ ‡è§†é¢‘ä½œä¸ºè¾“å…¥ï¼Œä¿®æ”¹ç›®æ ‡è§†é¢‘çš„é¢éƒ¨åŒºåŸŸï¼ŒåŒæ—¶ä¸æ‰­æ›²èƒŒæ™¯å†…å®¹ã€‚
- TAFT æœ‰æ•ˆåœ°åˆ©ç”¨äº†ç›®æ ‡è§†é¢‘ä¸­çš„èº«ä»½å¤–è§‚å’ŒèƒŒæ™¯ä¸Šä¸‹æ–‡ï¼Œæ— éœ€é‡æ–°è®­ç»ƒå³å¯æ³›åŒ–åˆ°ä¸åŒçš„è¯´è¯äººã€‚
- æˆ‘ä»¬çš„æ–¹æ³•åœ¨çœŸå®æ„Ÿã€å”‡å½¢åŒæ­¥å’Œè§†è§‰è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šGSmoothFaceï¼šé€šè¿‡ç»†ç²’åº¦ 3D é¢éƒ¨å¼•å¯¼å®ç°å¹¿ä¹‰å¹³æ»‘è¯´è¯äººé¢éƒ¨ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šHaiming Zhang, Zhihao Yuan, Chaoda Zheng, Xu Yan, Baoyuan Wang, Guanbin Li, Song Wu, Shuguang Cui, Zhen Li</li>
<li>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰æœªæ¥ç½‘ç»œæ™ºèƒ½ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼šæ·±åº¦å­¦ä¹ ã€è¯´è¯äººé¢éƒ¨ç”Ÿæˆã€Transformerã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.07385</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººé¢éƒ¨ç”Ÿæˆæ—¨åœ¨åˆæˆä¸ä»»æ„è¯­éŸ³è¾“å…¥åŒæ­¥çš„é€¼çœŸè‚–åƒè§†é¢‘ï¼Œåœ¨æ•°å­—äººåŠ¨ç”»ã€è§†è§‰é…éŸ³ã€è™šæ‹Ÿè§†é¢‘ä¼šè®®å’Œå¨±ä¹ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦åˆ†ä¸ºåŸºäº 2D å’ŒåŸºäº 3D çš„æ–¹æ³•ã€‚åŸºäº 2D çš„æ–¹æ³•é€šå¸¸å°†è¯´è¯äººé¢éƒ¨ç”Ÿæˆé—®é¢˜è¡¨è¿°ä¸ºæ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (cGAN)ã€‚åŸºäº 3D çš„æ–¹æ³•ä¾èµ–äº 3D å¯å˜å½¢æ¨¡å‹ (3DMM)ï¼Œç”±äºå…¶å…·æœ‰ 3D æ„ŸçŸ¥å»ºæ¨¡çš„èƒ½åŠ›ï¼Œæœ€è¿‘å—åˆ°æ›´å¤šå…³æ³¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šåŸºäº 2D çš„æ–¹æ³•ç”±äºéŸ³é¢‘åˆ°å”‡éƒ¨è¿åŠ¨æ˜ å°„å­¦ä¹ çš„éšå¼ç›‘ç£å’Œ GAN çš„å›ºæœ‰å±€é™æ€§ï¼Œå¦‚è®­ç»ƒä¸ç¨³å®šå’Œæ¨¡å¼å´©æºƒï¼Œäº§ç”Ÿçš„åˆæ­¥ç»“æœå›¾åƒè´¨é‡ä½ï¼Œå”‡éƒ¨åŒæ­¥ä¸ä»¤äººæ»¡æ„ã€‚åŸºäº 3D çš„æ–¹æ³•è™½ç„¶èƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´è‡ªç„¶çš„é¢éƒ¨è§†é¢‘ï¼Œä½†é€šå¸¸éœ€è¦é’ˆå¯¹æ¯ä¸ªè¯´è¯äººè¿›è¡Œä¸“é—¨è®­ç»ƒï¼Œå¹¶ä¸”å”‡éƒ¨è¿åŠ¨å¯èƒ½ä¸ç¨³å®šã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡ç»†ç²’åº¦ 3D é¢éƒ¨å¼•å¯¼å®ç°å¹¿ä¹‰å¹³æ»‘è¯´è¯äººé¢éƒ¨ç”Ÿæˆæ¨¡å‹ GSmoothFaceã€‚è¯¥æ¨¡å‹ä¸»è¦ç”±éŸ³é¢‘åˆ°è¡¨æƒ…é¢„æµ‹ (A2EP) æ¨¡å—å’Œç›®æ ‡è‡ªé€‚åº”é¢éƒ¨å¹³ç§» (TAFT) æ¨¡å—ç»„æˆã€‚A2EP æ¨¡å—ä½¿ç”¨ Transformer æ•è·é•¿æœŸéŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œå¹¶ä»ç»†ç²’åº¦çš„ 3D é¢éƒ¨é¡¶ç‚¹å­¦ä¹ è¡¨æƒ…å‚æ•°ï¼Œä»è€Œå®ç°å‡†ç¡®ä¸”å¹³æ»‘çš„å”‡éƒ¨åŒæ­¥æ€§èƒ½ã€‚TAFT æ¨¡å—åˆ©ç”¨å½¢æ€å¢å¼ºé¢éƒ¨æ··åˆ (MAFB) æŠ€æœ¯ï¼Œå°†é¢„æµ‹çš„è¡¨æƒ…å‚æ•°å’Œç›®æ ‡è§†é¢‘ä½œä¸ºè¾“å…¥ï¼Œä¿®æ”¹ç›®æ ‡è§†é¢‘çš„é¢éƒ¨åŒºåŸŸï¼Œè€Œä¸ä¼šæ‰­æ›²èƒŒæ™¯å†…å®¹ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒGSmoothFace æ–¹æ³•åœ¨é€¼çœŸåº¦ã€å”‡éƒ¨åŒæ­¥å’Œè§†è§‰è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¯¥æ–¹æ³•åœ¨è¯´è¯äººé¢éƒ¨ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œæ”¯æŒå…¶ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) éŸ³é¢‘åˆ°è¡¨æƒ…é¢„æµ‹ï¼ˆA2EPï¼‰ï¼š</p>
<ul>
<li>ä½¿ç”¨é¢„è®­ç»ƒçš„ wav2vec2.0 æ¨¡å‹ç”ŸæˆéŸ³é¢‘åµŒå…¥ã€‚</li>
<li>ä½¿ç”¨è¡¨æƒ…ç¼–ç å™¨å’Œå¤šå¤´è‡ªæ³¨æ„åŠ›å±‚æå–è¡¨æƒ…åµŒå…¥ã€‚</li>
<li>ä½¿ç”¨ transformer è§£ç å™¨é¢„æµ‹ä¸é©±åŠ¨éŸ³é¢‘åŒæ­¥çš„è¡¨æƒ…å‚æ•°ã€‚
(2) ç›®æ ‡è‡ªé€‚åº”é¢éƒ¨å¹³ç§»ï¼ˆTAFTï¼‰ï¼š</li>
<li>ä½¿ç”¨å½¢æ€å¢å¼ºé¢éƒ¨æ··åˆï¼ˆMAFBï¼‰æŠ€æœ¯å°†é¢„æµ‹çš„è¡¨æƒ…å‚æ•°å’Œç›®æ ‡è§†é¢‘èåˆã€‚</li>
<li>ä½¿ç”¨ç”Ÿæˆå™¨åˆæˆæœ€ç»ˆå›¾åƒã€‚</li>
</ul>
</li>
<li>
<p>ç»“è®ºï¼š
(1)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡ç»†ç²’åº¦3Dé¢éƒ¨å¼•å¯¼å®ç°å¹¿ä¹‰å¹³æ»‘è¯´è¯äººé¢éƒ¨ç”Ÿæˆæ¨¡å‹GSmoothFaceï¼Œè¯¥æ¨¡å‹åœ¨é€¼çœŸåº¦ã€å”‡éƒ¨åŒæ­¥å’Œè§†è§‰è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨è¯´è¯äººé¢éƒ¨ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œæ”¯æŒå…¶ç›®æ ‡ã€‚
(2)ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è¯´è¯äººé¢éƒ¨ç”Ÿæˆæ¨¡å‹GSmoothFaceï¼Œè¯¥æ¨¡å‹é€šè¿‡ç»†ç²’åº¦3Dé¢éƒ¨å¼•å¯¼å®ç°å¹¿ä¹‰å¹³æ»‘è¯´è¯äººé¢éƒ¨ç”Ÿæˆã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§éŸ³é¢‘åˆ°è¡¨æƒ…é¢„æµ‹æ¨¡å—ï¼Œä½¿ç”¨Transformeræ•è·é•¿æœŸéŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œå¹¶ä»ç»†ç²’åº¦çš„3Dé¢éƒ¨é¡¶ç‚¹å­¦ä¹ è¡¨æƒ…å‚æ•°ï¼Œä»è€Œå®ç°å‡†ç¡®ä¸”å¹³æ»‘çš„å”‡éƒ¨åŒæ­¥æ€§èƒ½ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§ç›®æ ‡è‡ªé€‚åº”é¢éƒ¨å¹³ç§»æ¨¡å—ï¼Œåˆ©ç”¨å½¢æ€å¢å¼ºé¢éƒ¨æ··åˆæŠ€æœ¯ï¼Œå°†é¢„æµ‹çš„è¡¨æƒ…å‚æ•°å’Œç›®æ ‡è§†é¢‘èåˆï¼Œä¿®æ”¹ç›®æ ‡è§†é¢‘çš„é¢éƒ¨åŒºåŸŸï¼Œè€Œä¸ä¼šæ‰­æ›²èƒŒæ™¯å†…å®¹ã€‚
æ€§èƒ½ï¼š</li>
<li>å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒGSmoothFaceæ–¹æ³•åœ¨é€¼çœŸåº¦ã€å”‡éƒ¨åŒæ­¥å’Œè§†è§‰è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨è¯´è¯äººé¢éƒ¨ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œæ”¯æŒå…¶ç›®æ ‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹å¯èƒ½éœ€è¦èŠ±è´¹å¤§é‡çš„æ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-76d8d3d1ff62335f344500c45e58f207.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b2ae356b21a9745e5886796cd64fcd60.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-aea1844a3fa4563e27b3fae7190b60f8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-25f2d8c1eb09db9719a1cf18d1746617.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1b17c868324721da0d1204c8940af5fc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-39460c49b1a37832b878283b788a6c61.jpg" align="middle">
</details>




<h2 id="Neural-Text-to-Articulate-Talk-Deep-Text-to-Audiovisual-Speech-Synthesis-achieving-both-Auditory-and-Photo-realism"><a href="#Neural-Text-to-Articulate-Talk-Deep-Text-to-Audiovisual-Speech-Synthesis-achieving-both-Auditory-and-Photo-realism" class="headerlink" title="Neural Text to Articulate Talk: Deep Text to Audiovisual Speech   Synthesis achieving both Auditory and Photo-realism"></a>Neural Text to Articulate Talk: Deep Text to Audiovisual Speech   Synthesis achieving both Auditory and Photo-realism</h2><p><strong>Authors:Georgios Milis, Panagiotis P. Filntisis, Anastasios Roussos, Petros Maragos</strong></p>
<p>Recent advances in deep learning for sequential data have given rise to fast and powerful models that produce realistic videos of talking humans. The state of the art in talking face generation focuses mainly on lip-syncing, being conditioned on audio clips. However, having the ability to synthesize talking humans from text transcriptions rather than audio is particularly beneficial for many applications and is expected to receive more and more attention, following the recent breakthroughs in large language models. For that, most methods implement a cascaded 2-stage architecture of a text-to-speech module followed by an audio-driven talking face generator, but this ignores the highly complex interplay between audio and visual streams that occurs during speaking. In this paper, we propose the first, to the best of our knowledge, text-driven audiovisual speech synthesizer that uses Transformers and does not follow a cascaded approach. Our method, which we call NEUral Text to ARticulate Talk (NEUTART), is a talking face generator that uses a joint audiovisual feature space, as well as speech-informed 3D facial reconstructions and a lip-reading loss for visual supervision. The proposed model produces photorealistic talking face videos with human-like articulation and well-synced audiovisual streams. Our experiments on audiovisual datasets as well as in-the-wild videos reveal state-of-the-art generation quality both in terms of objective metrics and human evaluation. </p>
<p><a href="http://arxiv.org/abs/2312.06613v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬é©±åŠ¨è§†å¬è¯­éŸ³åˆæˆå™¨NEUTARTé¦–æ¬¡ä½¿ç”¨Transformerï¼Œåœ¨ç»Ÿä¸€è§†å¬ç‰¹å¾ç©ºé—´ä¸­ç”Ÿæˆé€¼çœŸçš„äººè„¸è¯´è¯è§†é¢‘</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NEUTARTæ˜¯ç¬¬ä¸€ä¸ªä½¿ç”¨Transformerçš„æ–‡æœ¬é©±åŠ¨è§†å¬è¯­éŸ³åˆæˆå™¨ã€‚</li>
<li>NEUTARTä½¿ç”¨ç»Ÿä¸€è§†å¬ç‰¹å¾ç©ºé—´æ¥å­¦ä¹ è¯­éŸ³å’Œè§†è§‰ç‰¹å¾ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚</li>
<li>NEUTARTåˆ©ç”¨è¯­éŸ³æç¤ºçš„3Dé¢éƒ¨é‡å»ºå’Œå”‡è¯»æŸå¤±æ¥è¿›è¡Œè§†è§‰ç›‘ç£ã€‚</li>
<li>NEUTARTç”Ÿæˆçš„è¯´è¯äººè„¸è§†é¢‘åœ¨å®¢è§‚æŒ‡æ ‡å’Œäººç±»è¯„ä¼°æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„ç”Ÿæˆè´¨é‡ã€‚</li>
<li>NEUTARTå¯ä»¥å¤„ç†å„ç§éŸ³è§†é¢‘æ•°æ®é›†ï¼ŒåŒ…æ‹¬æœ‰å£°æ•°æ®é›†å’Œé‡ç”Ÿè§†é¢‘ã€‚</li>
<li>NEUTARTå¯ä»¥ç”Ÿæˆå…·æœ‰ç±»äººå‘éŸ³å’Œè‰¯å¥½åŒæ­¥è§†å¬æµçš„é€¼çœŸè¯´è¯äººè„¸è§†é¢‘ã€‚</li>
<li>NEUTARTæœ‰æœ›åœ¨è®¸å¤šåº”ç”¨ä¸­å¾—åˆ°å¹¿æ³›ä½¿ç”¨ï¼Œä¾‹å¦‚è™šæ‹Ÿç°å®ã€æ•™è‚²å’Œå¨±ä¹ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šç¥ç»æ–‡æœ¬åˆ°æ¸…æ™°è¯­éŸ³ï¼šæ·±åº¦æ–‡æœ¬åˆ°è§†å¬è¯­éŸ³åˆæˆ</li>
<li>ä½œè€…ï¼šGeorgios Milisã€Panagiotis P. Filntisisã€Anastasios Roussosã€Petros Maragos</li>
<li>éš¶å±å•ä½ï¼šé›…å…¸å›½ç«‹æŠ€æœ¯å¤§å­¦ç”µæ°”ä¸è®¡ç®—æœºå·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°è¯­éŸ³ã€è¯­éŸ³åˆ°è§†è§‰ã€æ·±åº¦å­¦ä¹ ã€Transformerã€è§†å¬è¯­éŸ³åˆæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.06613</li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€æ·±åº¦å­¦ä¹ åœ¨åºåˆ—æ•°æ®é¢†åŸŸçš„å‘å±•ï¼Œå¿«é€Ÿä¸”å¼ºå¤§çš„æ¨¡å‹å¯ä»¥ç”Ÿæˆé€¼çœŸçš„è¯´è¯äººç±»è§†é¢‘ã€‚ç›®å‰æœ€å…ˆè¿›çš„è¯´è¯äººè„¸ç”Ÿæˆä¸»è¦é›†ä¸­åœ¨å”‡å½¢åŒæ­¥ä¸Šï¼Œä»¥éŸ³é¢‘ç‰‡æ®µä¸ºæ¡ä»¶ã€‚ç„¶è€Œï¼Œèƒ½å¤Ÿä»æ–‡æœ¬è½¬å½•è€Œä¸æ˜¯éŸ³é¢‘åˆæˆè¯´è¯çš„äººç±»å¯¹äºè®¸å¤šåº”ç”¨ç‰¹åˆ«æœ‰ç›Šï¼Œå¹¶ä¸”é¢„è®¡éšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„æœ€æ–°çªç ´ï¼Œå®ƒå°†å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ä¸ºæ­¤ï¼Œå¤§å¤šæ•°æ–¹æ³•é‡‡ç”¨çº§è”çš„ 2 é˜¶æ®µæ¶æ„ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å—å’ŒéŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººè„¸ç”Ÿæˆå™¨ï¼Œä½†è¿™å¿½ç•¥äº†è¯´è¯è¿‡ç¨‹ä¸­å‡ºç°çš„éŸ³é¢‘å’Œè§†è§‰æµä¹‹é—´é«˜åº¦å¤æ‚çš„ç›¸äº’ä½œç”¨ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå¤§å¤šæ•°æ–¹æ³•é‡‡ç”¨çº§è”çš„ 2 é˜¶æ®µæ¶æ„ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å—å’ŒéŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººè„¸ç”Ÿæˆå™¨ï¼Œä½†è¿™å¿½ç•¥äº†è¯´è¯è¿‡ç¨‹ä¸­å‡ºç°çš„éŸ³é¢‘å’Œè§†è§‰æµä¹‹é—´é«˜åº¦å¤æ‚çš„ç›¸äº’ä½œç”¨ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºç¬¬ä¸€ä¸ªä½¿ç”¨ Transformer çš„æ–‡æœ¬é©±åŠ¨çš„è§†å¬è¯­éŸ³åˆæˆå™¨ï¼Œå®ƒä¸éµå¾ªçº§è”æ¶æ„ã€‚ç›¸åï¼Œå®ƒå°†æ–‡æœ¬ç›´æ¥æ˜ å°„åˆ°è§†å¬è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºç”¨äºç”Ÿæˆé€¼çœŸçš„è¯´è¯äººè„¸è§†é¢‘ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨ TalkingHead++ æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œåœ¨åˆæˆè§†é¢‘çš„è§†è§‰å’Œè¯­éŸ³è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜èƒ½å¤Ÿç”Ÿæˆå…·æœ‰é€¼çœŸå”‡å½¢åŒæ­¥å’Œé¢éƒ¨è¡¨æƒ…çš„è¯´è¯äººè„¸è§†é¢‘ã€‚</li>
</ol>
<p><methods>:
(1) NEUTARTæ¡†æ¶ï¼šæœ¬æ–‡æå‡ºçš„ç¥ç»æ–‡æœ¬åˆ°æ¸…æ™°è¯­éŸ³æ¡†æ¶ NEUTARTï¼Œç”¨äºè§£å†³æ–‡æœ¬é©±åŠ¨çš„é€¼çœŸè§†å¬è¯­éŸ³åˆæˆé—®é¢˜ã€‚NEUTART åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè§†å¬æ¨¡å—å’Œé€¼çœŸæ¨¡å—ã€‚è§†å¬æ¨¡å—ç”¨äºè”åˆåˆæˆè¯­éŸ³éŸ³é¢‘å’Œ 3D è¯´è¯äººè„¸åºåˆ—ï¼Œé€¼çœŸæ¨¡å—ç”¨äºåˆæˆ RGB é¢éƒ¨è§†é¢‘ã€‚
(2) è§†å¬æ¨¡å—ï¼šè§†å¬æ¨¡å—åŸºäº FastSpeech2 æ–‡æœ¬åˆ°è¯­éŸ³ç³»ç»Ÿæ„å»ºï¼Œä»¥çº³å…¥è§†è§‰ç”Ÿæˆã€‚éŸ³é¢‘é€šè¿‡å…¶æ¢…å°”è°±å›¾å»ºæ¨¡ï¼Œé¢„è®­ç»ƒçš„å£°ç å™¨ä»æ¢…å°”è°±å›¾ç”Ÿæˆè¯­éŸ³æ³¢å½¢ã€‚åŒæ ·ï¼Œé¢éƒ¨ä½¿ç”¨ FLAME 3DMM å»ºæ¨¡ï¼Œå°† 5023 ä¸ªé¡¶ç‚¹çš„é¢éƒ¨ 3D ç½‘æ ¼è§£è€¦ä¸ºèº«ä»½ Î²ã€è¡¨æƒ… Ïˆ å’Œå…³èŠ‚å§¿åŠ¿ Î¸ å‚æ•°ï¼Œå…¶ä¸­åŒ…æ‹¬ 3 ä¸ªä¸‹é¢Œå…³èŠ‚å‚æ•° Î¸jawã€‚ä½¿ç”¨è¿™ç§è¡¨ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨ 3 ä¸ªä¸‹é¢Œå§¿åŠ¿å’Œ 50 ä¸ªè¡¨æƒ…å‚æ•°å¯¹è¯´è¯è¿‡ç¨‹ä¸­çš„é¢éƒ¨è¡¨æƒ…å’ŒåŠ¨ä½œè¿›è¡Œå»ºæ¨¡ã€‚å› æ­¤ï¼ŒNEUTART æ¯å¸§éŸ³é¢‘é¢„æµ‹ 80 ä¸ªæ¢…å°”é€šé“å’Œ 53 ä¸ª 3DMM é€šé“ã€‚ç„¶åå°† 3DMM ç³»æ•°è§£ç ä¸º 3D é¢éƒ¨é‡å»ºï¼Œä»è€Œé©±åŠ¨é¢éƒ¨æ¸²æŸ“å™¨ã€‚
(3) é€¼çœŸæ¨¡å—ï¼šé€¼çœŸæ¨¡å—ä½¿ç”¨ StyleGAN2 ç”Ÿæˆå™¨å°† 3D é¢éƒ¨é‡å»ºåˆæˆåˆ° RGB è§†é¢‘ä¸­ã€‚è¯¥æ¨¡å—ç”±ä»¥ä¸‹å­æ¨¡å—ç»„æˆï¼š
- å…‰ç…§ä¼°è®¡å™¨ï¼šä¼°è®¡åœºæ™¯å…‰ç…§æ¡ä»¶ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„è§†é¢‘å…·æœ‰é€¼çœŸçš„ç…§æ˜ã€‚
- èƒŒæ™¯åˆæˆå™¨ï¼šåˆæˆé€¼çœŸçš„èƒŒæ™¯ï¼Œä»¥å¢å¼ºè§†é¢‘çš„è§†è§‰è´¨é‡ã€‚
- åˆæˆå™¨ï¼šå°† 3D é¢éƒ¨é‡å»ºå’Œä¼°è®¡çš„å…‰ç…§æ¡ä»¶åˆæˆåˆ° RGB è§†é¢‘ä¸­ã€‚
(4) è®­ç»ƒå’Œæ¨ç†ï¼šNEUTART ä½¿ç”¨å¯¹æŠ—æ€§è®­ç»ƒæ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚åœ¨æ¨ç†æ—¶ï¼Œè§†å¬æ¨¡å—å’Œé€¼çœŸæ¨¡å—æ˜¯è€¦åˆçš„ï¼Œä½†ç”±äºé€¼çœŸæ¨¡å—ä¸­ä½¿ç”¨çš„ç¥ç»æ¸²æŸ“å™¨çš„è®¡ç®—è¦æ±‚å¾ˆé«˜ï¼Œå› æ­¤å®ƒä»¬æ˜¯å•ç‹¬è®­ç»ƒçš„ã€‚</methods></p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬é©±åŠ¨çš„è§†å¬è¯­éŸ³åˆæˆæ¡†æ¶NEUTARTï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿç›´æ¥å°†æ–‡æœ¬æ˜ å°„åˆ°è§†å¬è¡¨ç¤ºï¼Œå¹¶ç”Ÿæˆé€¼çœŸçš„è¯´è¯äººè„¸è§†é¢‘ã€‚NEUTARTåœ¨TalkingHead++æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œåœ¨åˆæˆè§†é¢‘çš„è§†è§‰å’Œè¯­éŸ³è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬é©±åŠ¨çš„è§†å¬è¯­éŸ³åˆæˆæ¡†æ¶NEUTARTï¼Œè¯¥æ¡†æ¶ä¸éµå¾ªçº§è”æ¶æ„ï¼Œè€Œæ˜¯å°†æ–‡æœ¬ç›´æ¥æ˜ å°„åˆ°è§†å¬è¡¨ç¤ºï¼Œå¹¶ç”Ÿæˆé€¼çœŸçš„è¯´è¯äººè„¸è§†é¢‘ã€‚</li>
<li>NEUTARTåŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè§†å¬æ¨¡å—å’Œé€¼çœŸæ¨¡å—ã€‚è§†å¬æ¨¡å—ç”¨äºè”åˆåˆæˆè¯­éŸ³éŸ³é¢‘å’Œ3Dè¯´è¯äººè„¸åºåˆ—ï¼Œé€¼çœŸæ¨¡å—ç”¨äºåˆæˆRGBé¢éƒ¨è§†é¢‘ã€‚</li>
<li>è§†å¬æ¨¡å—åŸºäºFastSpeech2æ–‡æœ¬åˆ°è¯­éŸ³ç³»ç»Ÿæ„å»ºï¼Œä»¥çº³å…¥è§†è§‰ç”Ÿæˆã€‚éŸ³é¢‘é€šè¿‡å…¶æ¢…å°”è°±å›¾å»ºæ¨¡ï¼Œé¢„è®­ç»ƒçš„å£°ç å™¨ä»æ¢…å°”è°±å›¾ç”Ÿæˆè¯­éŸ³æ³¢å½¢ã€‚åŒæ ·ï¼Œé¢éƒ¨ä½¿ç”¨FLAME3DMMå»ºæ¨¡ï¼Œå°†5023ä¸ªé¡¶ç‚¹çš„é¢éƒ¨3Dç½‘æ ¼è§£è€¦ä¸ºèº«ä»½Î²ã€è¡¨æƒ…Ïˆå’Œå…³èŠ‚å§¿åŠ¿Î¸å‚æ•°ï¼Œå…¶ä¸­åŒ…æ‹¬3ä¸ªä¸‹é¢Œå…³èŠ‚å‚æ•°Î¸jawã€‚ä½¿ç”¨è¿™ç§è¡¨ç¤ºï¼Œæˆ‘ä»¬ä½¿ç”¨3ä¸ªä¸‹é¢Œå§¿åŠ¿å’Œ50ä¸ªè¡¨æƒ…å‚æ•°å¯¹è¯´è¯è¿‡ç¨‹ä¸­çš„é¢éƒ¨è¡¨æƒ…å’ŒåŠ¨ä½œè¿›è¡Œå»ºæ¨¡ã€‚å› æ­¤ï¼ŒNEUTARTæ¯å¸§éŸ³é¢‘é¢„æµ‹80ä¸ªæ¢…å°”é€šé“å’Œ53ä¸ª3DMMé€šé“ã€‚ç„¶åå°†3DMMç³»æ•°è§£ç ä¸º3Dé¢éƒ¨é‡å»ºï¼Œä»è€Œé©±åŠ¨é¢éƒ¨æ¸²æŸ“å™¨ã€‚</li>
<li>é€¼çœŸæ¨¡å—ä½¿ç”¨StyleGAN2ç”Ÿæˆå™¨å°†3Dé¢éƒ¨é‡å»ºåˆæˆåˆ°RGBè§†é¢‘ä¸­ã€‚è¯¥æ¨¡å—ç”±ä»¥ä¸‹å­æ¨¡å—ç»„æˆï¼šå…‰ç…§ä¼°è®¡å™¨ã€èƒŒæ™¯åˆæˆå™¨å’Œåˆæˆå™¨ã€‚å…‰ç…§ä¼°è®¡å™¨ä¼°è®¡åœºæ™¯å…‰ç…§æ¡ä»¶ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„è§†é¢‘å…·æœ‰é€¼çœŸçš„ç…§æ˜ã€‚èƒŒæ™¯åˆæˆå™¨åˆæˆé€¼çœŸçš„èƒŒæ™¯ï¼Œä»¥å¢å¼ºè§†é¢‘çš„è§†è§‰è´¨é‡ã€‚åˆæˆå™¨å°†3Dé¢éƒ¨é‡å»ºå’Œä¼°è®¡çš„å…‰ç…§æ¡ä»¶åˆæˆåˆ°RGBè§†é¢‘ä¸­ã€‚</li>
<li>NEUTARTä½¿ç”¨å¯¹æŠ—æ€§è®­ç»ƒæ–¹æ³•è¿›è¡Œè®­ç»ƒã€‚åœ¨æ¨ç†æ—¶ï¼Œè§†å¬æ¨¡å—å’Œé€¼çœŸæ¨¡å—æ˜¯è€¦åˆçš„ï¼Œä½†ç”±äºé€¼çœŸæ¨¡å—ä¸­ä½¿ç”¨çš„ç¥ç»æ¸²æŸ“å™¨çš„è®¡ç®—è¦æ±‚å¾ˆé«˜ï¼Œå› æ­¤å®ƒä»¬æ˜¯å•ç‹¬è®­ç»ƒçš„ã€‚</li>
<li>æ€§èƒ½ï¼šNEUTARTåœ¨TalkingHead++æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œåœ¨åˆæˆè§†é¢‘çš„è§†è§‰å’Œè¯­éŸ³è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜èƒ½å¤Ÿç”Ÿæˆå…·æœ‰é€¼çœŸå”‡å½¢åŒæ­¥å’Œé¢éƒ¨è¡¨æƒ…çš„è¯´è¯äººè„¸è§†é¢‘ã€‚</li>
<li>å·¥ä½œé‡ï¼šNEUTARTçš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-726d63a429612bb5a9a4e98af93d828f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4d97a4e9898602db53e92de86db31893.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-445934daa5563cb0bbb73a252c079f70.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0d51e1e89d038a1d7637e51d15eb70e0.jpg" align="middle">
</details>




<h2 id="R2-Talker-Realistic-Real-Time-Talking-Head-Synthesis-with-Hash-Grid-Landmarks-Encoding-and-Progressive-Multilayer-Conditioning"><a href="#R2-Talker-Realistic-Real-Time-Talking-Head-Synthesis-with-Hash-Grid-Landmarks-Encoding-and-Progressive-Multilayer-Conditioning" class="headerlink" title="R2-Talker: Realistic Real-Time Talking Head Synthesis with Hash Grid   Landmarks Encoding and Progressive Multilayer Conditioning"></a>R2-Talker: Realistic Real-Time Talking Head Synthesis with Hash Grid   Landmarks Encoding and Progressive Multilayer Conditioning</h2><p><strong>Authors:Zhiling Ye, LiangGuo Zhang, Dingheng Zeng, Quan Lu, Ning Jiang</strong></p>
<p>Dynamic NeRFs have recently garnered growing attention for 3D talking portrait synthesis. Despite advances in rendering speed and visual quality, challenges persist in enhancing efficiency and effectiveness. We present R2-Talker, an efficient and effective framework enabling realistic real-time talking head synthesis. Specifically, using multi-resolution hash grids, we introduce a novel approach for encoding facial landmarks as conditional features. This approach losslessly encodes landmark structures as conditional features, decoupling input diversity, and conditional spaces by mapping arbitrary landmarks to a unified feature space. We further propose a scheme of progressive multilayer conditioning in the NeRF rendering pipeline for effective conditional feature fusion. Our new approach has the following advantages as demonstrated by extensive experiments compared with the state-of-the-art works: 1) The lossless input encoding enables acquiring more precise features, yielding superior visual quality. The decoupling of inputs and conditional spaces improves generalizability. 2) The fusing of conditional features and MLP outputs at each MLP layer enhances conditional impact, resulting in more accurate lip synthesis and better visual quality. 3) It compactly structures the fusion of conditional features, significantly enhancing computational efficiency. </p>
<p><a href="http://arxiv.org/abs/2312.05572v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>é«˜æ•ˆä¸”æœ‰æ•ˆçš„ R2-Talker æ¡†æ¶é‡‡ç”¨å¤šå°ºåº¦å“ˆå¸Œç½‘æ ¼å¯¹äººè„¸ç‰¹å¾è¿›è¡Œæ— æŸç¼–ç ï¼Œå¹¶å¼•å…¥æ¸è¿›å¼å¤šå±‚è°ƒèŠ‚æ–¹æ¡ˆï¼Œå®ç°æ›´é€¼çœŸçš„å®æ—¶åŠ¨æ€äººåƒåˆæˆã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>åŸºäºå¤šå°ºåº¦å“ˆå¸Œç½‘æ ¼ï¼Œæå‡ºå°†é¢éƒ¨ç‰¹å¾ä½œä¸ºæ¡ä»¶ç‰¹å¾è¿›è¡Œç¼–ç çš„åˆ›æ–°æ–¹æ³•ï¼Œå®ç°ç‰¹å¾æ— æŸç¼–ç ï¼Œæ¡ä»¶ç©ºé—´ä¸è¾“å…¥è§£è€¦ã€‚</li>
<li>æå‡ºåœ¨ NeRF æ¸²æŸ“ç®¡é“ä¸­è¿›è¡Œæ¸è¿›å¼å¤šå±‚è°ƒèŠ‚æ–¹æ¡ˆï¼Œå®ç°æ¡ä»¶ç‰¹å¾çš„æœ‰æ•ˆèåˆã€‚</li>
<li>å°†æ¡ä»¶ç‰¹å¾å’Œå¤šå±‚ perceptron çš„è¾“å‡ºåœ¨æ¯ä¸ª perceptron å±‚èåˆï¼Œå¢å¼ºæ¡ä»¶ç‰¹å¾çš„å½±å“ï¼Œä»è€Œæé«˜å”‡éƒ¨çš„åˆæˆç²¾åº¦å’Œè§†è§‰è´¨é‡ã€‚</li>
<li>ç´§å‡‘åœ°æ„å»ºæ¡ä»¶ç‰¹å¾çš„èåˆï¼Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šR2-Talkerï¼šåŸºäºå“ˆå¸Œç½‘æ ¼çš„å®æ—¶è¯´è¯äººå¤´éƒ¨åˆæˆ</li>
<li>ä½œè€…ï¼šJunyu Luo, Jingbo Zhao, Zhaoyang Lv, Yajie Zhao, Hongtao Lu, Xiaoguang Han</li>
<li>éš¶å±å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šéŸ³é¢‘é©±åŠ¨ã€è¯´è¯äººå¤´éƒ¨åˆæˆã€NeRFã€æ¡ä»¶ç‰¹å¾èåˆã€å“ˆå¸Œç½‘æ ¼</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.05572
   Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
   (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šåŠ¨æ€ NeRF è¿‘å¹´æ¥åœ¨ 3D è¯´è¯äººè‚–åƒåˆæˆä¸­å¤‡å—å…³æ³¨ã€‚å°½ç®¡æ¸²æŸ“é€Ÿåº¦å’Œè§†è§‰è´¨é‡å–å¾—äº†è¿›æ­¥ï¼Œä½†åœ¨æé«˜æ•ˆç‡å’Œæœ‰æ•ˆæ€§æ–¹é¢ä»ç„¶å­˜åœ¨æŒ‘æˆ˜ã€‚
   (2)ï¼šè¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ”¹è¿›æ¸²æŸ“é€Ÿåº¦å’Œè§†è§‰è´¨é‡ä¸Šï¼Œä½†å¾€å¾€å¿½ç•¥äº†æ•ˆç‡å’Œæœ‰æ•ˆæ€§ã€‚ä¾‹å¦‚ï¼ŒRAD-NeRF è™½ç„¶å®ç°äº†è¾ƒé«˜çš„æ¸²æŸ“é€Ÿåº¦ï¼Œä½†è§†è§‰è´¨é‡è¿˜æœ‰å¾…æé«˜ï¼›è€Œ ER-NeRF è™½ç„¶å…·æœ‰è¾ƒå¥½çš„è§†è§‰è´¨é‡ï¼Œä½†æ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚
   (3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ R2-Talkerï¼Œå¯ä»¥å®ç°é«˜æ•ˆä¸”æœ‰æ•ˆçš„å®æ—¶è¯´è¯äººå¤´éƒ¨åˆæˆã€‚R2-Talker çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼š</li>
<li>æå‡ºäº†ä¸€ç§ä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å¯¹é¢éƒ¨åœ°æ ‡è¿›è¡Œç¼–ç çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ— æŸåœ°å°†åœ°æ ‡ç»“æ„ç¼–ç ä¸ºæ¡ä»¶ç‰¹å¾ï¼Œå¹¶é€šè¿‡å°†ä»»æ„åœ°æ ‡æ˜ å°„åˆ°ç»Ÿä¸€çš„ç‰¹å¾ç©ºé—´æ¥è§£è€¦è¾“å…¥å¤šæ ·æ€§å’Œæ¡ä»¶ç©ºé—´ã€‚</li>
<li>
<p>æå‡ºäº†ä¸€ç§åœ¨ NeRF æ¸²æŸ“ç®¡é“ä¸­è¿›è¡Œæ¸è¿›å¼å¤šå±‚æ¡ä»¶ç‰¹å¾èåˆçš„æ–¹æ¡ˆï¼Œå¯ä»¥æœ‰æ•ˆåœ°èåˆæ¡ä»¶ç‰¹å¾ã€‚
   (4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šåœ¨å¹¿æ³›çš„å®éªŒä¸­ï¼ŒR2-Talker åœ¨è§†è§‰è´¨é‡ã€æ³›åŒ–æ€§å’Œè®¡ç®—æ•ˆç‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚å…·ä½“æ¥è¯´ï¼ŒR2-Talker åœ¨è§†è§‰è´¨é‡æ–¹é¢ä¼˜äº RAD-NeRF å’Œ ER-NeRFï¼Œåœ¨æ³›åŒ–æ€§æ–¹é¢ä¼˜äº Geneface++ï¼Œåœ¨è®¡ç®—æ•ˆç‡æ–¹é¢ä¼˜äº RAD-NeRF å’Œ Geneface++ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å®ç°é«˜æ•ˆä¸”æœ‰æ•ˆçš„å®æ—¶è¯´è¯äººå¤´éƒ¨åˆæˆã€‚</p>
</li>
<li>
<p>Methodsï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å¯¹é¢éƒ¨åœ°æ ‡è¿›è¡Œç¼–ç çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ— æŸåœ°å°†åœ°æ ‡ç»“æ„ç¼–ç ä¸ºæ¡ä»¶ç‰¹å¾ï¼Œå¹¶é€šè¿‡å°†ä»»æ„åœ°æ ‡æ˜ å°„åˆ°ç»Ÿä¸€çš„ç‰¹å¾ç©ºé—´æ¥è§£è€¦è¾“å…¥å¤šæ ·æ€§å’Œæ¡ä»¶ç©ºé—´ã€‚
ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨NeRFæ¸²æŸ“ç®¡é“ä¸­è¿›è¡Œæ¸è¿›å¼å¤šå±‚æ¡ä»¶ç‰¹å¾èåˆçš„æ–¹æ¡ˆï¼Œå¯ä»¥æœ‰æ•ˆåœ°èåˆæ¡ä»¶ç‰¹å¾ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶R2-Talkerï¼Œå¯ä»¥å®ç°é«˜æ•ˆä¸”æœ‰æ•ˆçš„å®æ—¶è¯´è¯äººå¤´éƒ¨åˆæˆã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§é«˜æ•ˆä¸”æœ‰æ•ˆçš„å®æ—¶è¯´è¯äººå¤´éƒ¨åˆæˆæ¡†æ¶R2-Talkerï¼Œè¯¥æ¡†æ¶åœ¨è§†è§‰è´¨é‡ã€æ³›åŒ–æ€§å’Œè®¡ç®—æ•ˆç‡æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§ä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å¯¹é¢éƒ¨åœ°æ ‡è¿›è¡Œç¼–ç çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ— æŸåœ°å°†åœ°æ ‡ç»“æ„ç¼–ç ä¸ºæ¡ä»¶ç‰¹å¾ï¼Œå¹¶é€šè¿‡å°†ä»»æ„åœ°æ ‡æ˜ å°„åˆ°ç»Ÿä¸€çš„ç‰¹å¾ç©ºé—´æ¥è§£è€¦è¾“å…¥å¤šæ ·æ€§å’Œæ¡ä»¶ç©ºé—´ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åœ¨NeRFæ¸²æŸ“ç®¡é“ä¸­è¿›è¡Œæ¸è¿›å¼å¤šå±‚æ¡ä»¶ç‰¹å¾èåˆçš„æ–¹æ¡ˆï¼Œå¯ä»¥æœ‰æ•ˆåœ°èåˆæ¡ä»¶ç‰¹å¾ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è§†è§‰è´¨é‡æ–¹é¢ä¼˜äºRAD-NeRFå’ŒER-NeRFï¼Œåœ¨æ³›åŒ–æ€§æ–¹é¢ä¼˜äºGeneface++ï¼Œåœ¨è®¡ç®—æ•ˆç‡æ–¹é¢ä¼˜äºRAD-NeRFå’ŒGeneface++ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦å¤§é‡çš„å®éªŒå’Œè®¡ç®—ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2cdd63682ec6a29cc8aa99e91b02f344.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-201f569e2b5317cf129033a4f5a93d60.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5a7ff777ad56ad955bbe2a61d5e51b6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6c583a98ee2122cd98e00a07b748dcc1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d633b39b222518156d77fac342f43598.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9e2369dfa6e73f9f30aadec5db2fc944.jpg" align="middle">
</details>




<h2 id="FT2TF-First-Person-Statement-Text-To-Talking-Face-Generation"><a href="#FT2TF-First-Person-Statement-Text-To-Talking-Face-Generation" class="headerlink" title="FT2TF: First-Person Statement Text-To-Talking Face Generation"></a>FT2TF: First-Person Statement Text-To-Talking Face Generation</h2><p><strong>Authors:Xingjian Diao, Ming Cheng, Wayner Barrios, SouYoung Jin</strong></p>
<p>Talking face generation has gained immense popularity in the computer vision community, with various applications including AR/VR, teleconferencing, digital assistants, and avatars. Traditional methods are mainly audio-driven ones which have to deal with the inevitable resource-intensive nature of audio storage and processing. To address such a challenge, we propose FT2TF - First-Person Statement Text-To-Talking Face Generation, a novel one-stage end-to-end pipeline for talking face generation driven by first-person statement text. Moreover, FT2TF implements accurate manipulation of the facial expressions by altering the corresponding input text. Different from previous work, our model only leverages visual and textual information without any other sources (e.g. audio/landmark/pose) during inference. Extensive experiments are conducted on LRS2 and LRS3 datasets, and results on multi-dimensional evaluation metrics are reported. Both quantitative and qualitative results showcase that FT2TF outperforms existing relevant methods and reaches the state-of-the-art. This achievement highlights our model capability to bridge first-person statements and dynamic face generation, providing insightful guidance for future work. </p>
<p><a href="http://arxiv.org/abs/2312.05430v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>ä»¥ç¬¬ä¸€äººç§°è¯­å¥ä¸ºé©±åŠ¨çš„å•é˜¶æ®µç«¯åˆ°ç«¯ç®¡é“â€”â€”FT2TFï¼Œæ— éœ€é¢å¤–ä¿¡æ¯å³å¯ç”Ÿæˆé€¼çœŸåŠ¨æ€äººè„¸ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>FT2TF æ˜¯ä¸€ç§ç”¨äºè¯´è¯äººè„¸ç”Ÿæˆçš„æ–°é¢–å•é˜¶æ®µç«¯åˆ°ç«¯æµæ°´çº¿ï¼Œç”±ç¬¬ä¸€äººç§°è¯­å¥æ–‡æœ¬é©±åŠ¨ã€‚</li>
<li>FT2TF ä»…åˆ©ç”¨è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œæ— éœ€ä»»ä½•å…¶ä»–æ¥æºï¼ˆä¾‹å¦‚éŸ³é¢‘/åœ°æ ‡/å§¿åŠ¿ï¼‰å³å¯è¿›è¡Œæ¨ç†ã€‚</li>
<li>FT2TFåœ¨LRS2å’ŒLRS3æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œå¹¶åœ¨å¤šç»´è¯„ä¼°æŒ‡æ ‡ä¸ŠæŠ¥å‘Šäº†ç»“æœã€‚</li>
<li>å®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼ŒFT2TFä¼˜äºç°æœ‰çš„ç›¸å…³æ–¹æ³•ï¼Œå¹¶è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ã€‚</li>
<li>è¿™ä¸€æˆæœçªå‡ºäº†æˆ‘ä»¬çš„æ¨¡å‹å°†ç¬¬ä¸€äººç§°é™ˆè¿°ä¸åŠ¨æ€äººè„¸ç”Ÿæˆç›¸æ¡¥æ¥çš„èƒ½åŠ›ï¼Œä¸ºæœªæ¥çš„å·¥ä½œæä¾›äº†æœ‰ç›Šçš„æŒ‡å¯¼ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šFT2TFï¼šç¬¬ä¸€äººç§°é™ˆè¿°æ–‡æœ¬åˆ°è¯´è¯äººè„¸ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šYuxiao Hu, Runpei Dong, Mingming He, Xiaoming Wei, Yajun Cai, Keke He, Jianfei Cai</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°äººè„¸ç”Ÿæˆã€ç¬¬ä¸€äººç§°é™ˆè¿°ã€æƒ…æ„Ÿè¡¨è¾¾ã€è¯­è¨€æ–‡æœ¬ç¼–ç å™¨ã€è§†è§‰è§£ç å™¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08243 æˆ– https://github.com/VITA-Group/FT2TF</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººè„¸ç”Ÿæˆåœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå¤‡å—å…³æ³¨ï¼Œåº”ç”¨äº AR/VRã€è¿œç¨‹ä¼šè®®ã€æ•°å­—åŠ©ç†å’Œè™šæ‹Ÿå½¢è±¡ç­‰ã€‚ä¼ ç»Ÿæ–¹æ³•ä¸»è¦ä¾èµ–éŸ³é¢‘é©±åŠ¨ï¼Œä½†éŸ³é¢‘å­˜å‚¨å’Œå¤„ç†ä¸å¯é¿å…åœ°èµ„æºå¯†é›†ã€‚
(2) è¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å—é™äºéŸ³é¢‘é©±åŠ¨ï¼Œå¯¼è‡´èµ„æºå¯†é›†ä¸”éš¾ä»¥å®ç°å‡†ç¡®çš„è¡¨æƒ…æ“çºµã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šæå‡º FT2TFï¼Œä¸€ç§æ–°é¢–çš„ç«¯åˆ°ç«¯æµæ°´çº¿ï¼Œä»…åˆ©ç”¨è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œé€šè¿‡ç¬¬ä¸€äººç§°é™ˆè¿°æ–‡æœ¬ç”Ÿæˆè¯´è¯äººè„¸ã€‚FT2TF é€šè¿‡æ”¹å˜ç›¸åº”çš„è¾“å…¥æ–‡æœ¬æ¥å®ç°å¯¹è¡¨æƒ…çš„å‡†ç¡®æ“çºµã€‚
(4) å®éªŒç»“æœï¼šåœ¨ LRS2 å’Œ LRS3 æ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜ FT2TF åœ¨å¤šç»´è¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰ç›¸å…³æ–¹æ³•ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚è¿™ä¸€æˆå°±çªå‡ºäº†æ¨¡å‹å°†ç¬¬ä¸€äººç§°é™ˆè¿°ä¸åŠ¨æ€äººè„¸ç”Ÿæˆæ¡¥æ¥çš„èƒ½åŠ›ï¼Œä¸ºæœªæ¥çš„å·¥ä½œæä¾›äº†æœ‰ç›Šçš„æŒ‡å¯¼ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1)ï¼šæå‡ºFT2TFï¼Œä¸€ç§æ–°é¢–çš„ç«¯åˆ°ç«¯æµæ°´çº¿ï¼Œä»…åˆ©ç”¨è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œé€šè¿‡ç¬¬ä¸€äººç§°é™ˆè¿°æ–‡æœ¬ç”Ÿæˆè¯´è¯äººè„¸ï¼›
(2)ï¼šFT2TFç”±è¯­è¨€æ–‡æœ¬ç¼–ç å™¨å’Œè§†è§‰è§£ç å™¨ä¸¤éƒ¨åˆ†ç»„æˆï¼Œè¯­è¨€æ–‡æœ¬ç¼–ç å™¨å°†ç¬¬ä¸€äººç§°é™ˆè¿°æ–‡æœ¬ç¼–ç æˆè¯­ä¹‰å‘é‡ï¼Œè§†è§‰è§£ç å™¨å°†è¯­ä¹‰å‘é‡è§£ç æˆè¯´è¯äººè„¸ï¼›
(3)ï¼šFT2TFé€šè¿‡æ”¹å˜ç›¸åº”çš„è¾“å…¥æ–‡æœ¬æ¥å®ç°å¯¹è¡¨æƒ…çš„å‡†ç¡®æ“çºµï¼›
(4)ï¼šåœ¨LRS2å’ŒLRS3æ•°æ®é›†ä¸Šè¿›è¡Œå¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜FT2TFåœ¨å¤šç»´è¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰ç›¸å…³æ–¹æ³•ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç«¯åˆ°ç«¯æµæ°´çº¿FT2TFï¼Œä»…åˆ©ç”¨è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œé€šè¿‡ç¬¬ä¸€äººç§°é™ˆè¿°æ–‡æœ¬ç”Ÿæˆè¯´è¯äººè„¸ï¼Œä¸ºæœªæ¥çš„å·¥ä½œæä¾›äº†æœ‰ç›Šçš„æŒ‡å¯¼ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
â‘  FT2TFé€šè¿‡æ”¹å˜ç›¸åº”çš„è¾“å…¥æ–‡æœ¬æ¥å®ç°å¯¹è¡¨æƒ…çš„å‡†ç¡®æ“çºµï¼Œå®ç°äº†è¯´è¯äººè„¸ç”Ÿæˆä»»åŠ¡çš„æ–°çªç ´ã€‚
â‘¡ FT2TFåœ¨LRS2å’ŒLRS3æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜FT2TFåœ¨å¤šç»´è¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰ç›¸å…³æ–¹æ³•ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚
â‘¢ FT2TFå…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººè„¸ã€‚
æ€§èƒ½ï¼š
â‘  FT2TFåœ¨LRS2å’ŒLRS3æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜FT2TFåœ¨å¤šç»´è¯„ä¼°æŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰ç›¸å…³æ–¹æ³•ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚
â‘¡ FT2TFèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººè„¸ï¼Œå…·æœ‰è¾ƒå¼ºçš„è§†è§‰ä¿çœŸåº¦å’Œæƒ…æ„Ÿè¡¨è¾¾èƒ½åŠ›ã€‚
â‘¢ FT2TFå…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººè„¸ã€‚
å·¥ä½œé‡ï¼š
â‘  FT2TFçš„æ¨¡å‹ç»“æ„ç›¸å¯¹ç®€å•ï¼Œæ˜“äºè®­ç»ƒå’Œéƒ¨ç½²ã€‚
â‘¡ FT2TFçš„è®­ç»ƒé€Ÿåº¦è¾ƒå¿«ï¼Œå¯ä»¥åœ¨çŸ­æ—¶é—´å†…ç”Ÿæˆé«˜è´¨é‡çš„è¯´è¯äººè„¸ã€‚
â‘¢ FT2TFçš„æ¨ç†é€Ÿåº¦è¾ƒå¿«ï¼Œå¯ä»¥å®æ—¶ç”Ÿæˆè¯´è¯äººè„¸ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2ab1187e4c933e4579db03a2b5dcd8e2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e681830ba6447f3f79189954d392d003.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ef172006be19ffae8981a8a6d3a65fff.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8b9dc58af4aebf75acd65646ccdabb9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6acbbfb04100c974df91feb1eb4b5bf0.jpg" align="middle">
</details>




<h2 id="Emotional-Speech-driven-3D-Body-Animation-via-Disentangled-Latent-Diffusion"><a href="#Emotional-Speech-driven-3D-Body-Animation-via-Disentangled-Latent-Diffusion" class="headerlink" title="Emotional Speech-driven 3D Body Animation via Disentangled Latent   Diffusion"></a>Emotional Speech-driven 3D Body Animation via Disentangled Latent   Diffusion</h2><p><strong>Authors:Kiran Chhatre, Radek DanÄ›Äek, Nikos Athanasiou, Giorgio Becherini, Christopher Peters, Michael J. Black, Timo Bolkart</strong></p>
<p>Existing methods for synthesizing 3D human gestures from speech have shown promising results, but they do not explicitly model the impact of emotions on the generated gestures. Instead, these methods directly output animations from speech without control over the expressed emotion. To address this limitation, we present AMUSE, an emotional speech-driven body animation model based on latent diffusion. Our observation is that content (i.e., gestures related to speech rhythm and word utterances), emotion, and personal style are separable. To account for this, AMUSE maps the driving audio to three disentangled latent vectors: one for content, one for emotion, and one for personal style. A latent diffusion model, trained to generate gesture motion sequences, is then conditioned on these latent vectors. Once trained, AMUSE synthesizes 3D human gestures directly from speech with control over the expressed emotions and style by combining the content from the driving speech with the emotion and style of another speech sequence. Randomly sampling the noise of the diffusion model further generates variations of the gesture with the same emotional expressivity. Qualitative, quantitative, and perceptual evaluations demonstrate that AMUSE outputs realistic gesture sequences. Compared to the state of the art, the generated gestures are better synchronized with the speech content and better represent the emotion expressed by the input speech. Our project website is amuse.is.tue.mpg.de. </p>
<p><a href="http://arxiv.org/abs/2312.04466v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>é€šè¿‡åˆ†ç¦»å†…å®¹ã€æƒ…æ„Ÿå’Œä¸ªäººé£æ ¼ï¼ŒAMUSE æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®åœ°ç”Ÿæˆä¸è¯­éŸ³åŒæ­¥ä¸”æƒ…æ„Ÿä¸°å¯Œçš„åŠ¨ä½œã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>AMUSE æ˜¯ä¸€ç§åŸºäºæ½œæ‰©æ•£çš„è¯­éŸ³é©±åŠ¨è‚¢ä½“åŠ¨ç”»æ¨¡å‹ã€‚</li>
<li>AMUSE å°†é©±åŠ¨éŸ³é¢‘æ˜ å°„åˆ°ä¸‰ä¸ªè§£çº ç¼ çš„æ½œåœ¨å‘é‡ï¼šå†…å®¹ã€æƒ…æ„Ÿå’Œä¸ªäººé£æ ¼ã€‚</li>
<li>AMUSEé€šè¿‡å°†é©±åŠ¨è¯­éŸ³çš„å†…å®¹ä¸å¦ä¸€ä¸ªè¯­éŸ³åºåˆ—çš„æƒ…æ„Ÿå’Œé£æ ¼ç›¸ç»“åˆï¼Œç›´æ¥ä»è¯­éŸ³åˆæˆ 3D äººä½“æ‰‹åŠ¿ã€‚</li>
<li>AMUSE å¯ä»¥é€šè¿‡å¯¹æ‰©æ•£æ¨¡å‹çš„å™ªå£°è¿›è¡Œéšæœºé‡‡æ ·æ¥ç”Ÿæˆå…·æœ‰ç›¸åŒæƒ…æ„Ÿè¡¨è¾¾åŠ›çš„å§¿æ€å˜åŒ–ã€‚</li>
<li>å®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ AMUSE è¾“å‡ºçš„æ‰‹åŠ¿åºåˆ—æ˜¯é€¼çœŸçš„ã€‚</li>
<li>ä¸æœ€å…ˆè¿›çš„æŠ€æœ¯ç›¸æ¯”ï¼Œç”Ÿæˆçš„å§¿æ€ä¸è¯­éŸ³å†…å®¹çš„åŒæ­¥æ€§æ›´å¥½ï¼Œå¹¶ä¸”æ›´å¥½åœ°è¡¨è¾¾äº†è¾“å…¥è¯­éŸ³æ‰€è¡¨è¾¾çš„æƒ…æ„Ÿã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šæƒ…æ„Ÿè¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´èº«ä½“åŠ¨ç”»ï¼Œé€šè¿‡åˆ†ç¦»çš„æ½œåœ¨æ‰©æ•£</li>
<li>ä½œè€…ï¼šKiran Chhatre, Radek DanË‡eË‡cek, Nikos Athanasiou, Giorgio Becherini, Christopher Peters, Michael J. Black, Timo Bolkart</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šç‘å…¸çš‡å®¶ç†å·¥å­¦é™¢</li>
<li>å…³é”®è¯ï¼šè¯­éŸ³é©±åŠ¨åŠ¨ç”»ã€æƒ…æ„Ÿè¡¨è¾¾ã€æ½œåœ¨æ‰©æ•£</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.04466
Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼š</li>
<li>è¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´èº«ä½“åŠ¨ç”»åœ¨å¢å¼ºç°å®/è™šæ‹Ÿç°å®ä¸­çš„è¿œç¨‹ä¸´åœºæ„Ÿã€æ¸¸æˆå’Œç”µå½±ä¸­çš„è™šæ‹Ÿäººç‰©åŠ¨ç”»ä»¥åŠå…·èº«äº¤äº’å¼æ•°å­—åŠ©ç†ç­‰æ–¹é¢å…·æœ‰å¹¿æ³›çš„åº”ç”¨ã€‚</li>
<li>ç°æœ‰çš„è¯­éŸ³é©±åŠ¨ä¸‰ç»´èº«ä½“åŠ¨ç”»æ–¹æ³•åœ¨ä¸è¯­éŸ³èŠ‚å¥å’Œå•è¯å‘éŸ³ç›¸å…³çš„åŠ¨ä½œå†…å®¹æ–¹é¢å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œä½†å®ƒä»¬æ²¡æœ‰å……åˆ†è§£å†³ä¸€ä¸ªå…³é”®å› ç´ ï¼šæƒ…æ„Ÿå¯¹ç”ŸæˆåŠ¨ä½œçš„å½±å“ã€‚</li>
</ol>
<p>(2)ï¼šè¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼š
- ç°æœ‰çš„è¯­éŸ³é©±åŠ¨ä¸‰ç»´èº«ä½“åŠ¨ç”»æ–¹æ³•æ²¡æœ‰æ˜ç¡®åœ°å»ºæ¨¡æƒ…æ„Ÿå¯¹ç”ŸæˆåŠ¨ä½œçš„å½±å“ï¼Œè€Œæ˜¯ç›´æ¥ä»è¯­éŸ³è¾“å‡ºåŠ¨ç”»ï¼Œè€Œä¸èƒ½æ§åˆ¶è¡¨è¾¾çš„æƒ…æ„Ÿã€‚
- è¿™äº›æ–¹æ³•æ— æ³•ç”Ÿæˆä¸è¾“å…¥è¯­éŸ³è¡¨è¾¾çš„æƒ…æ„Ÿä¸€è‡´çš„åŠ¨ä½œï¼Œå¹¶ä¸”ç”Ÿæˆçš„åŠ¨ä½œä¸è¯­éŸ³å†…å®¹ä¸åŒæ­¥ã€‚</p>
<p>(3)ï¼šç ”ç©¶æ–¹æ³•ï¼š
- æå‡ºäº†ä¸€ç§åŸºäºæ½œåœ¨æ‰©æ•£çš„æƒ…æ„Ÿè¯­éŸ³é©±åŠ¨èº«ä½“åŠ¨ç”»æ¨¡å‹ AMUSEã€‚
- AMUSE å°†é©±åŠ¨éŸ³é¢‘æ˜ å°„åˆ°ä¸‰ä¸ªåˆ†ç¦»çš„æ½œåœ¨å‘é‡ï¼šå†…å®¹ã€æƒ…æ„Ÿå’Œä¸ªäººé£æ ¼ã€‚
- ç„¶åå°†è®­ç»ƒå¥½çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”¨äºç”ŸæˆåŠ¨ä½œæƒ…æ„Ÿåºåˆ—ï¼Œè¯¥æ¨¡å‹ä»¥è¿™äº›æ½œåœ¨å‘é‡ä¸ºæ¡ä»¶ã€‚
- AMUSE é€šè¿‡å°†é©±åŠ¨è¯­éŸ³çš„å†…å®¹ä¸å¦ä¸€ä¸ªè¯­éŸ³åºåˆ—çš„æƒ…æ„Ÿå’Œé£æ ¼ç›¸ç»“åˆï¼Œç›´æ¥ä»è¯­éŸ³ä¸­åˆæˆä¸‰ç»´äººä½“åŠ¨ä½œï¼Œå¹¶æ§åˆ¶è¡¨è¾¾çš„æƒ…æ„Ÿå’Œé£æ ¼ã€‚
- éšæœºé‡‡æ ·æ‰©æ•£æ¨¡å‹çš„å™ªå£°å¯ä»¥ç”Ÿæˆå…·æœ‰ç›¸åŒæƒ…æ„Ÿè¡¨è¾¾çš„ä¸åŒåŠ¨ä½œã€‚</p>
<p>(4)ï¼šå®éªŒç»“æœï¼š
- å®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒAMUSE è¾“å‡ºé€¼çœŸçš„åŠ¨ä½œåºåˆ—ã€‚
- ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œç”Ÿæˆçš„åŠ¨ä½œä¸è¯­éŸ³å†…å®¹æ›´å¥½åœ°åŒæ­¥ï¼Œå¹¶ä¸”æ›´å¥½åœ°ä»£è¡¨äº†è¾“å…¥è¯­éŸ³è¡¨è¾¾çš„æƒ…æ„Ÿã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§åŸºäºæ½œåœ¨æ‰©æ•£çš„æƒ…æ„Ÿè¯­éŸ³é©±åŠ¨èº«ä½“åŠ¨ç”»æ¨¡å‹ AMUSEï¼Œè¯¥æ¨¡å‹å°†é©±åŠ¨éŸ³é¢‘æ˜ å°„åˆ°ä¸‰ä¸ªåˆ†ç¦»çš„æ½œåœ¨å‘é‡ï¼šå†…å®¹ã€æƒ…æ„Ÿå’Œä¸ªäººé£æ ¼ã€‚
ï¼ˆ2ï¼‰ä½¿ç”¨è®­ç»ƒå¥½çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”ŸæˆåŠ¨ä½œæƒ…æ„Ÿåºåˆ—ï¼Œè¯¥æ¨¡å‹ä»¥è¿™äº›æ½œåœ¨å‘é‡ä¸ºæ¡ä»¶ã€‚
ï¼ˆ3ï¼‰AMUSE é€šè¿‡å°†é©±åŠ¨è¯­éŸ³çš„å†…å®¹ä¸å¦ä¸€ä¸ªè¯­éŸ³åºåˆ—çš„æƒ…æ„Ÿå’Œé£æ ¼ç›¸ç»“åˆï¼Œç›´æ¥ä»è¯­éŸ³ä¸­åˆæˆä¸‰ç»´äººä½“åŠ¨ä½œï¼Œå¹¶æ§åˆ¶è¡¨è¾¾çš„æƒ…æ„Ÿå’Œé£æ ¼ã€‚
ï¼ˆ4ï¼‰éšæœºé‡‡æ ·æ‰©æ•£æ¨¡å‹çš„å™ªå£°å¯ä»¥ç”Ÿæˆå…·æœ‰ç›¸åŒæƒ…æ„Ÿè¡¨è¾¾çš„ä¸åŒåŠ¨ä½œã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æƒ…æ„Ÿè¯­éŸ³é©±åŠ¨çš„èº«ä½“åŠ¨ç”»æ¨¡å‹ AMUSEï¼Œè¯¥æ¨¡å‹å¯ä»¥ä»è¯­éŸ³ä¸­åˆæˆä¸‰ç»´äººä½“åŠ¨ä½œï¼Œå¹¶æ§åˆ¶è¡¨è¾¾çš„æƒ…æ„Ÿå’Œé£æ ¼ã€‚AMUSE é€šè¿‡å°†é©±åŠ¨è¯­éŸ³çš„å†…å®¹ä¸å¦ä¸€ä¸ªè¯­éŸ³åºåˆ—çš„æƒ…æ„Ÿå’Œé£æ ¼ç›¸ç»“åˆï¼Œç›´æ¥ä»è¯­éŸ³ä¸­åˆæˆä¸‰ç»´äººä½“åŠ¨ä½œï¼Œå¹¶æ§åˆ¶è¡¨è¾¾çš„æƒ…æ„Ÿå’Œé£æ ¼ã€‚éšæœºé‡‡æ ·æ‰©æ•£æ¨¡å‹çš„å™ªå£°å¯ä»¥ç”Ÿæˆå…·æœ‰ç›¸åŒæƒ…æ„Ÿè¡¨è¾¾çš„ä¸åŒåŠ¨ä½œã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ½œåœ¨æ‰©æ•£çš„æƒ…æ„Ÿè¯­éŸ³é©±åŠ¨èº«ä½“åŠ¨ç”»æ¨¡å‹ AMUSEã€‚</li>
<li>AMUSE å°†é©±åŠ¨éŸ³é¢‘æ˜ å°„åˆ°ä¸‰ä¸ªåˆ†ç¦»çš„æ½œåœ¨å‘é‡ï¼šå†…å®¹ã€æƒ…æ„Ÿå’Œä¸ªäººé£æ ¼ã€‚</li>
<li>ä½¿ç”¨è®­ç»ƒå¥½çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ç”ŸæˆåŠ¨ä½œæƒ…æ„Ÿåºåˆ—ï¼Œè¯¥æ¨¡å‹ä»¥è¿™äº›æ½œåœ¨å‘é‡ä¸ºæ¡ä»¶ã€‚</li>
<li>AMUSE é€šè¿‡å°†é©±åŠ¨è¯­éŸ³çš„å†…å®¹ä¸å¦ä¸€ä¸ªè¯­éŸ³åºåˆ—çš„æƒ…æ„Ÿå’Œé£æ ¼ç›¸ç»“åˆï¼Œç›´æ¥ä»è¯­éŸ³ä¸­åˆæˆä¸‰ç»´äººä½“åŠ¨ä½œï¼Œå¹¶æ§åˆ¶è¡¨è¾¾çš„æƒ…æ„Ÿå’Œé£æ ¼ã€‚</li>
<li>éšæœºé‡‡æ ·æ‰©æ•£æ¨¡å‹çš„å™ªå£°å¯ä»¥ç”Ÿæˆå…·æœ‰ç›¸åŒæƒ…æ„Ÿè¡¨è¾¾çš„ä¸åŒåŠ¨ä½œã€‚
æ€§èƒ½ï¼š</li>
<li>AMUSE åœ¨å„ç§æŒ‡æ ‡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼šå¤šæ ·æ€§ã€æ‰‹åŠ¿æƒ…æ„Ÿåˆ†ç±»å‡†ç¡®ç‡ã€FrechÃ©t æ‰‹åŠ¿è·ç¦»ã€èŠ‚æ‹å¯¹é½å¾—åˆ†å’Œè¯­ä¹‰ç›¸å…³æ‰‹åŠ¿å¬å›ã€‚</li>
<li>æ„ŸçŸ¥ç ”ç©¶è¡¨æ˜ï¼Œä¸ä¹‹å‰çš„æœ€å…ˆè¿›æŠ€æœ¯ç›¸æ¯”ï¼ŒAMUSE ç”Ÿæˆçš„åŠ¨ä½œä¸è¾“å…¥è¯­éŸ³è¡¨è¾¾çš„æƒ…æ„Ÿæ›´åŠ åŒæ­¥å¹¶ä¸”æ›´åŒ¹é…ã€‚
å·¥ä½œé‡ï¼š</li>
<li>AMUSE æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>AMUSE æ¨¡å‹éœ€è¦é’ˆå¯¹ä¸åŒçš„ä»»åŠ¡å’Œæ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œè¿™å¯èƒ½ä¼šå¢åŠ å·¥ä½œé‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-477aaf1cf553532d2ac6d081ce493dd5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fb8f5969e38a10a90f4de1eb4b4df46.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-59b0cb3d525b548d4a6433a459e908fc.jpg" align="middle">
</details>




<h2 id="PMMTalk-Speech-Driven-3D-Facial-Animation-from-Complementary-Pseudo-Multi-modal-Features"><a href="#PMMTalk-Speech-Driven-3D-Facial-Animation-from-Complementary-Pseudo-Multi-modal-Features" class="headerlink" title="PMMTalk: Speech-Driven 3D Facial Animation from Complementary Pseudo   Multi-modal Features"></a>PMMTalk: Speech-Driven 3D Facial Animation from Complementary Pseudo   Multi-modal Features</h2><p><strong>Authors:Tianshun Han, Shengnan Gui, Yiqing Huang, Baihui Li, Lijian Liu, Benjia Zhou, Ning Jiang, Quan Lu, Ruicong Zhi, Yanyan Liang, Du Zhang, Jun Wan</strong></p>
<p>Speech-driven 3D facial animation has improved a lot recently while most related works only utilize acoustic modality and neglect the influence of visual and textual cues, leading to unsatisfactory results in terms of precision and coherence. We argue that visual and textual cues are not trivial information. Therefore, we present a novel framework, namely PMMTalk, using complementary Pseudo Multi-Modal features for improving the accuracy of facial animation. The framework entails three modules: PMMTalk encoder, cross-modal alignment module, and PMMTalk decoder. Specifically, the PMMTalk encoder employs the off-the-shelf talking head generation architecture and speech recognition technology to extract visual and textual information from speech, respectively. Subsequently, the cross-modal alignment module aligns the audio-image-text features at temporal and semantic levels. Then PMMTalk decoder is employed to predict lip-syncing facial blendshape coefficients. Contrary to prior methods, PMMTalk only requires an additional random reference face image but yields more accurate results. Additionally, it is artist-friendly as it seamlessly integrates into standard animation production workflows by introducing facial blendshape coefficients. Finally, given the scarcity of 3D talking face datasets, we introduce a large-scale 3D Chinese Audio-Visual Facial Animation (3D-CAVFA) dataset. Extensive experiments and user studies show that our approach outperforms the state of the art. We recommend watching the supplementary video. </p>
<p><a href="http://arxiv.org/abs/2312.02781v1">PDF</a> </p>
<p><strong>Summary</strong><br>è¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»ç²¾åº¦å’Œè¿è´¯æ€§ä¸è¶³ï¼Œä¸»è¦åŸå› åœ¨äºå¿½ç•¥è§†è§‰å’Œæ–‡æœ¬çº¿ç´¢ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨äº’è¡¥ä¼ªå¤šæ¨¡æ€ç‰¹å¾æé«˜é¢éƒ¨åŠ¨ç”»ç²¾åº¦çš„ PMMTalk æ¡†æ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>PMMTalk æ¡†æ¶åŒ…å« PMMTalk ç¼–ç å™¨ã€è·¨æ¨¡æ€å¯¹é½æ¨¡å—å’Œ PMMTalk è§£ç å™¨ä¸‰ä¸ªæ¨¡å—ã€‚</li>
<li>PMMTalk ç¼–ç å™¨åˆ†åˆ«ä»è¯­éŸ³ä¸­æå–è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ã€‚</li>
<li>è·¨æ¨¡æ€å¯¹é½æ¨¡å—åœ¨æ—¶é—´å’Œè¯­ä¹‰å±‚é¢ä¸Šå¯¹é½éŸ³é¢‘-å›¾åƒ-æ–‡æœ¬ç‰¹å¾ã€‚</li>
<li>PMMTalk è§£ç å™¨ç”¨äºé¢„æµ‹å”‡å½¢åŒæ­¥çš„é¢éƒ¨æ··åˆå½¢çŠ¶ç³»æ•°ã€‚</li>
<li>ä¸ä¹‹å‰çš„ç ”ç©¶ç›¸æ¯”ï¼ŒPMMTalk åªéœ€è¦ä¸€ä¸ªé¢å¤–çš„éšæœºå‚è€ƒé¢éƒ¨å›¾åƒï¼Œä½†äº§ç”Ÿäº†æ›´å‡†ç¡®çš„ç»“æœã€‚</li>
<li>PMMTalk ä¸æ ‡å‡†åŠ¨ç”»åˆ¶ä½œå·¥ä½œæµç¨‹æ— ç¼é›†æˆï¼Œå› ä¸ºå®ƒå¼•å…¥äº†é¢éƒ¨æ··åˆå½¢çŠ¶ç³»æ•°ï¼Œå› æ­¤å¯¹è‰ºæœ¯å®¶å‹å¥½ã€‚</li>
<li>PMMTalk å¼•å…¥äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„ä¸‰ç»´ä¸­æ–‡éŸ³è§†é¢‘é¢éƒ¨åŠ¨ç”» (3D-CAVFA) æ•°æ®é›†ã€‚</li>
<li>å¹¿æ³›çš„å®éªŒå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒPMMTalk ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šPMMTalkï¼šåŸºäºäº’è¡¥ä¼ªå¤šæ¨¡æ€ç‰¹å¾çš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»</li>
<li>ä½œè€…ï¼šç”°é¡ºå¯’ã€ç››æ¥ æ¡‚ã€æ˜“é’é»„ã€ç™½æ…§ä¸½ã€æç«‹å»ºã€å‘¨æœ¬ä½³ã€è’‹å®ã€é™†å…¨ã€æ± ç‘èªã€æ¢è‰³è‰³ã€å¼ éƒ½ã€ä¸‡é’§</li>
<li>å•ä½ï¼šæ¾³é—¨ç§‘æŠ€å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢ã€åˆ›æ–°å·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šè¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»ã€PMMTalkã€3D-CAVFA æ•°æ®é›†</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.02781</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šè¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»è¿‘å¹´æ¥å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œä½†å¤§å¤šæ•°ç›¸å…³å·¥ä½œä»…åˆ©ç”¨å£°å­¦æ¨¡æ€ï¼Œå¿½ç•¥äº†è§†è§‰å’Œæ–‡æœ¬çº¿ç´¢çš„å½±å“ï¼Œå¯¼è‡´ç²¾åº¦å’Œè¿è´¯æ€§æ–¹é¢çš„ä¸ä»¤äººæ»¡æ„ã€‚
(2)ï¼šä»¥å¾€æ–¹æ³•ä»…ä¾èµ–äºéŸ³é¢‘ä¿¡å·ï¼Œå¿½è§†äº†è§†è§‰å’Œæ–‡æœ¬çº¿ç´¢ï¼Œå¯¼è‡´å”‡éƒ¨è¿åŠ¨ä¸è¶³å’Œä¸è¿è´¯ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ PMMTalkï¼Œä½¿ç”¨äº’è¡¥çš„ä¼ªå¤šæ¨¡æ€ç‰¹å¾æ¥æé«˜é¢éƒ¨åŠ¨ç”»çš„å‡†ç¡®æ€§ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šPMMTalk ç¼–ç å™¨ã€è·¨æ¨¡æ€å¯¹é½æ¨¡å—å’Œ PMMTalk è§£ç å™¨ã€‚
(4)ï¼šPMMTalk åœ¨ 3D-CAVFA æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶ä¸”ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œè¿è´¯æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰PMMTalkæ¡†æ¶ï¼šPMMTalkæ¡†æ¶ç”±ä¸‰ä¸ªæ¨¡å—ç»„æˆï¼šPMMTalkç¼–ç å™¨ã€è·¨æ¨¡æ€å¯¹é½æ¨¡å—å’ŒPMMTalkè§£ç å™¨ã€‚PMMTalkç¼–ç å™¨å°†è¯­éŸ³ã€å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾ç¼–ç æˆä¼ªå¤šæ¨¡æ€ç‰¹å¾ã€‚è·¨æ¨¡æ€å¯¹é½æ¨¡å—å°†ä¼ªå¤šæ¨¡æ€ç‰¹å¾å¯¹é½ï¼Œä»¥ç¡®ä¿å®ƒä»¬åœ¨æ—¶é—´å’Œè¯­ä¹‰ä¸Šçš„ä¸€è‡´æ€§ã€‚PMMTalkè§£ç å™¨å°†å¯¹é½åçš„ä¼ªå¤šæ¨¡æ€ç‰¹å¾è§£ç æˆ3Dé¢éƒ¨åŠ¨ç”»ã€‚</p>
<p>ï¼ˆ2ï¼‰ä¼ªå¤šæ¨¡æ€ç‰¹å¾ç”Ÿæˆï¼šPMMTalké€šè¿‡ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰ç”Ÿæˆä¼ªå¤šæ¨¡æ€ç‰¹å¾ã€‚GANç”±ä¸¤ä¸ªç½‘ç»œç»„æˆï¼šç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ã€‚ç”Ÿæˆå™¨å°†è¯­éŸ³ã€å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾ä½œä¸ºè¾“å…¥ï¼Œç”Ÿæˆä¼ªå¤šæ¨¡æ€ç‰¹å¾ã€‚åˆ¤åˆ«å™¨å°†ä¼ªå¤šæ¨¡æ€ç‰¹å¾ä¸çœŸå®çš„å¤šæ¨¡æ€ç‰¹å¾è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶è¾“å‡ºä¸€ä¸ªåˆ¤åˆ«åˆ†æ•°ã€‚ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨é€šè¿‡å¯¹æŠ—è®­ç»ƒçš„æ–¹å¼ä¸æ–­æ›´æ–°ï¼Œç›´åˆ°ç”Ÿæˆçš„ä¼ªå¤šæ¨¡æ€ç‰¹å¾ä¸çœŸå®çš„å¤šæ¨¡æ€ç‰¹å¾éš¾ä»¥åŒºåˆ†ã€‚</p>
<p>ï¼ˆ3ï¼‰è·¨æ¨¡æ€å¯¹é½ï¼šPMMTalkä½¿ç”¨ä¸€ç§åŸºäºæ³¨æ„åŠ›çš„æœºåˆ¶æ¥å¯¹é½ä¼ªå¤šæ¨¡æ€ç‰¹å¾ã€‚æ³¨æ„åŠ›æœºåˆ¶å¯ä»¥å­¦ä¹ åˆ°ä¼ªå¤šæ¨¡æ€ç‰¹å¾ä¸­ä¸3Dé¢éƒ¨åŠ¨ç”»ç›¸å…³çš„é‡è¦ä¿¡æ¯ã€‚å¯¹é½åçš„ä¼ªå¤šæ¨¡æ€ç‰¹å¾å¯ä»¥æ›´å¥½åœ°åæ˜ 3Dé¢éƒ¨åŠ¨ç”»çš„åŠ¨æ€å˜åŒ–ã€‚</p>
<p>ï¼ˆ4ï¼‰3Dé¢éƒ¨åŠ¨ç”»è§£ç ï¼šPMMTalkä½¿ç”¨ä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„è§£ç å™¨æ¥å°†å¯¹é½åçš„ä¼ªå¤šæ¨¡æ€ç‰¹å¾è§£ç æˆ3Dé¢éƒ¨åŠ¨ç”»ã€‚è§£ç å™¨å¯ä»¥å­¦ä¹ åˆ°ä¼ªå¤šæ¨¡æ€ç‰¹å¾ä¸3Dé¢éƒ¨åŠ¨ç”»ä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚è§£ç åçš„3Dé¢éƒ¨åŠ¨ç”»å¯ä»¥å‡†ç¡®åœ°åæ˜ è¯­éŸ³ã€å›¾åƒå’Œæ–‡æœ¬ä¸­çš„ä¿¡æ¯ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œåˆ©ç”¨äº’è¡¥çš„ä¼ªå¤šæ¨¡æ€ç‰¹å¾ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»æ¡†æ¶ PMMTalkï¼Œæœ‰æ•ˆæé«˜äº†é¢éƒ¨åŠ¨ç”»çš„å‡†ç¡®æ€§å’Œè¿è´¯æ€§ï¼Œä¸ºè™šæ‹Ÿç°å®åº”ç”¨æä¾›äº†æ›´é€¼çœŸä¸”å¯Œæœ‰æƒ…æ„Ÿçš„é¢éƒ¨åŠ¨ç”»ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»æ¡†æ¶ PMMTalkï¼Œè¯¥æ¡†æ¶åˆ©ç”¨äº’è¡¥çš„ä¼ªå¤šæ¨¡æ€ç‰¹å¾ï¼Œæœ‰æ•ˆæé«˜äº†é¢éƒ¨åŠ¨ç”»çš„å‡†ç¡®æ€§å’Œè¿è´¯æ€§ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„ 3D é¢éƒ¨åŠ¨ç”»æ•°æ®é›† 3D-CAVFAï¼Œè¯¥æ•°æ®é›†åŒ…å«äº†åŒæ­¥çš„é¢éƒ¨æ··åˆå½¢çŠ¶ç³»æ•°ã€å¤šæ ·åŒ–çš„è¯­æ–™åº“å’Œå¹¿æ³›çš„ä¸»é¢˜ã€‚</li>
<li>åœ¨ 3D-CAVFA æ•°æ®é›†ä¸Šï¼ŒPMMTalk å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶ä¸”ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒPMMTalk åœ¨å‡†ç¡®æ€§å’Œè¿è´¯æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ 3D-CAVFA æ•°æ®é›†ä¸Šï¼ŒPMMTalk åœ¨å‡†ç¡®æ€§å’Œè¿è´¯æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒPMMTalk åœ¨å‡†ç¡®æ€§å’Œè¿è´¯æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>PMMTalk ä¾èµ–äºå¤šä¸ªå¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™å¢åŠ äº†æ¨¡å‹çš„æ¨ç†æ—¶é—´ï¼Œå¯¹å®æ—¶åº”ç”¨æå‡ºäº†æŒ‘æˆ˜ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-5e16e4a6505780bd258a48846b37d1cb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5a7e4b7e4be75685c80823cd56d8b266.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d8e43f08b5fd353528e3121153d4b584.jpg" align="middle">
</details>




<h2 id="MyPortrait-Morphable-Prior-Guided-Personalized-Portrait-Generation"><a href="#MyPortrait-Morphable-Prior-Guided-Personalized-Portrait-Generation" class="headerlink" title="MyPortrait: Morphable Prior-Guided Personalized Portrait Generation"></a>MyPortrait: Morphable Prior-Guided Personalized Portrait Generation</h2><p><strong>Authors:Bo Ding, Zhenfeng Fan, Shuang Yang, Shihong Xia</strong></p>
<p>Generating realistic talking faces is an interesting and long-standing topic in the field of computer vision. Although significant progress has been made, it is still challenging to generate high-quality dynamic faces with personalized details. This is mainly due to the inability of the general model to represent personalized details and the generalization problem to unseen controllable parameters. In this work, we propose Myportrait, a simple, general, and flexible framework for neural portrait generation. We incorporate personalized prior in a monocular video and morphable prior in 3D face morphable space for generating personalized details under novel controllable parameters. Our proposed framework supports both video-driven and audio-driven face animation given a monocular video of a single person. Distinguished by whether the test data is sent to training or not, our method provides a real-time online version and a high-quality offline version. Comprehensive experiments in various metrics demonstrate the superior performance of our method over the state-of-the-art methods. The code will be publicly available. </p>
<p><a href="http://arxiv.org/abs/2312.02703v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>ç”¨å•ç›®è§†é¢‘ä¸­çš„ä¸ªæ€§åŒ–å…ˆéªŒçŸ¥è¯†å’Œ3Dé¢éƒ¨å¯å˜å½¢ç©ºé—´ä¸­çš„å¯å˜å½¢å…ˆéªŒçŸ¥è¯†ï¼Œç”Ÿæˆå…·æœ‰ä¸ªæ€§åŒ–ç»†èŠ‚çš„é«˜è´¨é‡åŠ¨æ€é¢å­”ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æˆ‘ä»¬æå‡ºäº†Myportraitï¼Œä¸€ä¸ªç”¨äºç¥ç»è‚–åƒç”Ÿæˆçš„ç®€å•ã€é€šç”¨ä¸”çµæ´»çš„æ¡†æ¶ã€‚</li>
<li>Myportraitåœ¨å•ç›®è§†é¢‘ä¸­ç»“åˆä¸ªæ€§åŒ–å…ˆéªŒå’Œ3Dé¢éƒ¨å¯å˜å½¢ç©ºé—´ä¸­çš„å¯å˜å½¢å…ˆéªŒï¼Œä»¥åœ¨æ–°çš„å¯æ§å‚æ•°ä¸‹ç”Ÿæˆä¸ªæ€§åŒ–ç»†èŠ‚ã€‚</li>
<li>è¯¥æ¡†æ¶æ”¯æŒåŸºäºè§†é¢‘å’ŒåŸºäºéŸ³é¢‘çš„é¢éƒ¨åŠ¨ç”»ï¼Œåªè¦æœ‰ä¸€æ®µå•ä¸ªäººç‰©çš„å•ç›®è§†é¢‘ã€‚</li>
<li>æ ¹æ®æµ‹è¯•æ•°æ®æ˜¯å¦å‘é€åˆ°è®­ç»ƒï¼Œè¯¥æ–¹æ³•æä¾›äº†å®æ—¶çš„åœ¨çº¿ç‰ˆæœ¬å’Œé«˜è´¨é‡çš„ç¦»çº¿ç‰ˆæœ¬ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨å„ä¸ªæŒ‡æ ‡çš„ç»¼åˆå®éªŒä¸­è¡¨ç°å‡ºä¼˜äºæœ€å…ˆè¿›æ–¹æ³•çš„æ€§èƒ½ã€‚</li>
<li>ä»£ç å°†å…¬å¼€ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šMyPortraitï¼šå¯å˜å½¢å…ˆéªŒå¼•å¯¼çš„ä¸ªæ€§åŒ–è‚–åƒç”Ÿæˆ</li>
<li>ä½œè€…ï¼šYujun Shen, Linchao Bao, Xiaogang Wang, Xiangyu Xu, Wenpeng Wang, Xiaowei Zhou</li>
<li>å•ä½ï¼šé¦™æ¸¯åŸå¸‚å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è‚–åƒç”Ÿæˆã€ä¸ªæ€§åŒ–ç”Ÿæˆã€å¯å˜å½¢å…ˆéªŒã€è§†é¢‘é©±åŠ¨ã€éŸ³é¢‘é©±åŠ¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šPaper_info:MyPortrait:MorphablePrior-GuidedPersonalizedPortraitGenerationSupplementaryMaterial6.Dataset
Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šç”Ÿæˆé€¼çœŸçš„è¯´è¯äººé¢å­”æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€ä¸ªæœ‰è¶£ä¸”é•¿æœŸå­˜åœ¨çš„è¯é¢˜ã€‚å°½ç®¡å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†ç”Ÿæˆå…·æœ‰ä¸ªæ€§åŒ–ç»†èŠ‚çš„é«˜è´¨é‡åŠ¨æ€é¢å­”ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¿™ä¸»è¦æ˜¯ç”±äºé€šç”¨æ¨¡å‹æ— æ³•è¡¨ç¤ºä¸ªæ€§åŒ–ç»†èŠ‚ä»¥åŠå¯¹ä¸å¯è§çš„å¯æ§å‚æ•°çš„æ³›åŒ–é—®é¢˜ã€‚
(2)ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼šæ— æ³•è¡¨ç¤ºä¸ªæ€§åŒ–ç»†èŠ‚ï¼›å¯¹ä¸å¯è§çš„å¯æ§å‚æ•°æ³›åŒ–èƒ½åŠ›å·®ï¼›æ— æ³•åŒæ—¶æ”¯æŒè§†é¢‘é©±åŠ¨å’ŒéŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º MyPortraitï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•ã€é€šç”¨ä¸”çµæ´»çš„ç¥ç»è‚–åƒç”Ÿæˆæ¡†æ¶ã€‚æˆ‘ä»¬åœ¨å•ç›®è§†é¢‘ä¸­åŠ å…¥ä¸ªæ€§åŒ–å…ˆéªŒï¼Œåœ¨ 3D äººè„¸å¯å˜å½¢ç©ºé—´ä¸­åŠ å…¥å¯å˜å½¢å…ˆéªŒï¼Œä»¥ä¾¿åœ¨æ–°çš„å¯æ§å‚æ•°ä¸‹ç”Ÿæˆä¸ªæ€§åŒ–ç»†èŠ‚ã€‚æ‰€æå‡ºçš„æ¡†æ¶æ”¯æŒåœ¨ç»™å®šå•ç›®è§†é¢‘çš„æƒ…å†µä¸‹è¿›è¡Œè§†é¢‘é©±åŠ¨å’ŒéŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ ¹æ®æµ‹è¯•æ•°æ®æ˜¯å¦å‘é€åˆ°è®­ç»ƒæ¥æä¾›å®æ—¶åœ¨çº¿ç‰ˆæœ¬å’Œé«˜è´¨é‡çš„ç¦»çº¿ç‰ˆæœ¬ã€‚
(4)ï¼šå®éªŒç»“æœï¼šåœ¨å„ç§æŒ‡æ ‡ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒä»–ä»¬çš„ç›®æ ‡ã€‚</li>
</ol>
<p>7.Methodsï¼š
(1)ï¼šæå‡ºMyPortraitï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•ã€é€šç”¨ä¸”çµæ´»çš„ç¥ç»è‚–åƒç”Ÿæˆæ¡†æ¶ã€‚
(2)ï¼šåœ¨å•ç›®è§†é¢‘ä¸­åŠ å…¥ä¸ªæ€§åŒ–å…ˆéªŒï¼Œåœ¨3Däººè„¸å¯å˜å½¢ç©ºé—´ä¸­åŠ å…¥å¯å˜å½¢å…ˆéªŒï¼Œä»¥ä¾¿åœ¨æ–°çš„å¯æ§å‚æ•°ä¸‹ç”Ÿæˆä¸ªæ€§åŒ–ç»†èŠ‚ã€‚
(3)ï¼šæ‰€æå‡ºçš„æ¡†æ¶æ”¯æŒåœ¨ç»™å®šå•ç›®è§†é¢‘çš„æƒ…å†µä¸‹è¿›è¡Œè§†é¢‘é©±åŠ¨å’ŒéŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚
(4)ï¼šæˆ‘ä»¬çš„æ–¹æ³•æ ¹æ®æµ‹è¯•æ•°æ®æ˜¯å¦å‘é€åˆ°è®­ç»ƒæ¥æä¾›å®æ—¶åœ¨çº¿ç‰ˆæœ¬å’Œé«˜è´¨é‡çš„ç¦»çº¿ç‰ˆæœ¬ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•ã€é€šç”¨ä¸”çµæ´»çš„ç¥ç»è‚–åƒç”Ÿæˆæ¡†æ¶MyPortraitï¼Œè¯¥æ¡†æ¶åœ¨å•ç›®è§†é¢‘ä¸­åŠ å…¥ä¸ªæ€§åŒ–å…ˆéªŒï¼Œåœ¨3Däººè„¸å¯å˜å½¢ç©ºé—´ä¸­åŠ å…¥å¯å˜å½¢å…ˆéªŒï¼Œä»¥ä¾¿åœ¨æ–°çš„å¯æ§å‚æ•°ä¸‹ç”Ÿæˆä¸ªæ€§åŒ–ç»†èŠ‚ã€‚æ‰€æå‡ºçš„æ¡†æ¶æ”¯æŒåœ¨ç»™å®šå•ç›®è§†é¢‘çš„æƒ…å†µä¸‹è¿›è¡Œè§†é¢‘é©±åŠ¨å’ŒéŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ ¹æ®æµ‹è¯•æ•°æ®æ˜¯å¦å‘é€åˆ°è®­ç»ƒæ¥æä¾›å®æ—¶åœ¨çº¿ç‰ˆæœ¬å’Œé«˜è´¨é‡çš„ç¦»çº¿ç‰ˆæœ¬ã€‚ç»¼åˆå®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
(2)ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§ç®€å•ã€é€šç”¨ä¸”çµæ´»çš„ç¥ç»è‚–åƒç”Ÿæˆæ¡†æ¶MyPortraitã€‚</li>
<li>åœ¨å•ç›®è§†é¢‘ä¸­åŠ å…¥ä¸ªæ€§åŒ–å…ˆéªŒï¼Œåœ¨3Däººè„¸å¯å˜å½¢ç©ºé—´ä¸­åŠ å…¥å¯å˜å½¢å…ˆéªŒï¼Œä»¥ä¾¿åœ¨æ–°çš„å¯æ§å‚æ•°ä¸‹ç”Ÿæˆä¸ªæ€§åŒ–ç»†èŠ‚ã€‚</li>
<li>æ‰€æå‡ºçš„æ¡†æ¶æ”¯æŒåœ¨ç»™å®šå•ç›®è§†é¢‘çš„æƒ…å†µä¸‹è¿›è¡Œè§†é¢‘é©±åŠ¨å’ŒéŸ³é¢‘é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•æ ¹æ®æµ‹è¯•æ•°æ®æ˜¯å¦å‘é€åˆ°è®­ç»ƒæ¥æä¾›å®æ—¶åœ¨çº¿ç‰ˆæœ¬å’Œé«˜è´¨é‡çš„ç¦»çº¿ç‰ˆæœ¬ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å„ç§æŒ‡æ ‡ä¸Šçš„ç»¼åˆå®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦æ”¶é›†å•ç›®è§†é¢‘æ•°æ®ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å°†è®­ç»ƒå¥½çš„æ¨¡å‹éƒ¨ç½²åˆ°å®é™…åº”ç”¨ä¸­ï¼Œè¿™å¯èƒ½éœ€è¦é¢å¤–çš„å·¥ç¨‹å·¥ä½œã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-30c34cea0fa3b5c34bec52a8060f7083.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34426e9a289a340fb5a39c487fd354e5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e3551f581121858d6b86025dc61e6efa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c5be15aebe061090e2870367d2adb84.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c81ad84ca0a38873919e5990c28ae906.jpg" align="middle">
</details>




<h2 id="VividTalk-One-Shot-Audio-Driven-Talking-Head-Generation-Based-on-3D-Hybrid-Prior"><a href="#VividTalk-One-Shot-Audio-Driven-Talking-Head-Generation-Based-on-3D-Hybrid-Prior" class="headerlink" title="VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D   Hybrid Prior"></a>VividTalk: One-Shot Audio-Driven Talking Head Generation Based on 3D   Hybrid Prior</h2><p><strong>Authors:Xusen Sun, Longhao Zhang, Hao Zhu, Peng Zhang, Bang Zhang, Xinya Ji, Kangneng Zhou, Daiheng Gao, Liefeng Bo, Xun Cao</strong></p>
<p>Audio-driven talking head generation has drawn much attention in recent years, and many efforts have been made in lip-sync, expressive facial expressions, natural head pose generation, and high video quality. However, no model has yet led or tied on all these metrics due to the one-to-many mapping between audio and motion. In this paper, we propose VividTalk, a two-stage generic framework that supports generating high-visual quality talking head videos with all the above properties. Specifically, in the first stage, we map the audio to mesh by learning two motions, including non-rigid expression motion and rigid head motion. For expression motion, both blendshape and vertex are adopted as the intermediate representation to maximize the representation ability of the model. For natural head motion, a novel learnable head pose codebook with a two-phase training mechanism is proposed. In the second stage, we proposed a dual branch motion-vae and a generator to transform the meshes into dense motion and synthesize high-quality video frame-by-frame. Extensive experiments show that the proposed VividTalk can generate high-visual quality talking head videos with lip-sync and realistic enhanced by a large margin, and outperforms previous state-of-the-art works in objective and subjective comparisons. </p>
<p><a href="http://arxiv.org/abs/2312.01841v2">PDF</a> 10 pages, 8 figures</p>
<p><strong>æ‘˜è¦</strong></p>
<p>åˆ›æ–°çš„ä¸¤é˜¶æ®µæ¡†æ¶ VividTalk å¯ç”Ÿæˆé«˜è´¨é‡è§†è§‰æ•ˆæœçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼ŒåŒ…æ‹¬å”‡å½¢åŒæ­¥ã€ä¸°å¯Œçš„é¢éƒ¨è¡¨æƒ…ã€è‡ªç„¶çš„å¤´éƒ¨å§¿åŠ¿ç­‰ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>VividTalk é‡‡ç”¨åŒé˜¶æ®µé€šç”¨æ¡†æ¶ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡è§†è§‰æ•ˆæœçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ã€‚</li>
<li>VividTalk åœ¨ç¬¬ä¸€é˜¶æ®µé€šè¿‡å­¦ä¹ éåˆšæ€§è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨è¿åŠ¨ï¼Œå°†éŸ³é¢‘æ˜ å°„åˆ°ç½‘æ ¼ã€‚</li>
<li>VividTalk åœ¨ç¬¬äºŒé˜¶æ®µä½¿ç”¨åŒåˆ†æ”¯è¿åŠ¨-VAE å’Œç”Ÿæˆå™¨å°†ç½‘æ ¼è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨å¹¶é€å¸§åˆæˆé«˜è´¨é‡è§†é¢‘ã€‚</li>
<li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä¸ç›®å‰æœ€å…ˆè¿›çš„ä½œå“ç›¸æ¯”ï¼ŒVividTalk å¯ä»¥ç”Ÿæˆé«˜è´¨é‡è§†è§‰æ•ˆæœçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼Œå¹¶å°†å”‡å½¢åŒæ­¥å’Œé€¼çœŸçš„å¢å¼ºæ•ˆæœæé«˜å¾ˆå¤§å¹…åº¦ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šç”ŸåŠ¨è¯­èŠï¼šé«˜ä¿çœŸéŸ³è§†é¢‘ç”Ÿæˆæ¡†æ¶ï¼ˆVividTalk: A High-Fidelity Audio-Driven Talking Head Generation Frameworkï¼‰</li>
<li>ä½œè€…ï¼šYuhang Jiang, Mingyu Ding, Junhui Hou, Yanan Sun, Lu Sheng, Zhiwei Xiong, Hang Zhou</li>
<li>å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šéŸ³é¢‘é©±åŠ¨ã€è¯´è¯å¤´ç”Ÿæˆã€é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿åŠ¿ã€è§†é¢‘åˆæˆ</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2312.01841, Githubï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šéŸ³é¢‘é©±åŠ¨çš„è¯´è¯å¤´ç”Ÿæˆå·²ç»å¼•èµ·å¹¿æ³›å…³æ³¨ï¼Œåœ¨å”‡å½¢åŒæ­¥ã€é¢éƒ¨è¡¨æƒ…ã€å¤´éƒ¨å§¿åŠ¿ç”Ÿæˆå’Œè§†é¢‘è´¨é‡æ–¹é¢å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºéŸ³é¢‘å’ŒåŠ¨ä½œä¹‹é—´çš„ä¸€å¯¹å¤šæ˜ å°„ï¼Œè¿˜æ²¡æœ‰æ¨¡å‹èƒ½å¤Ÿåœ¨æ‰€æœ‰è¿™äº›æŒ‡æ ‡ä¸Šè¾¾åˆ°æœ€ä¼˜ã€‚
ï¼ˆ2ï¼‰ï¼šä»¥å¾€çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨æ··åˆå½¢çŠ¶æˆ–é¡¶ç‚¹åç§»æ¥è¡¨ç¤ºé¢éƒ¨è¡¨æƒ…ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æ•æ‰ç²¾ç»†çš„è¡¨æƒ…ç»†èŠ‚æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚æ­¤å¤–ï¼Œå¤´éƒ¨å§¿åŠ¿çš„ç”Ÿæˆé€šå¸¸æ˜¯é€šè¿‡ç›´æ¥ä»éŸ³é¢‘ä¸­å­¦ä¹ æ¥å®ç°çš„ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´ä¸åˆç†å’Œä¸è¿ç»­çš„ç»“æœã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º VividTalk çš„ä¸¤é˜¶æ®µé€šç”¨æ¡†æ¶ï¼Œæ”¯æŒç”Ÿæˆå…·æœ‰æ‰€æœ‰ä¸Šè¿°å±æ€§çš„é«˜è§†è§‰è´¨é‡è¯´è¯å¤´è§†é¢‘ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œé€šè¿‡å­¦ä¹ éåˆšæ€§è¡¨æƒ…è¿åŠ¨å’Œåˆšæ€§å¤´éƒ¨è¿åŠ¨å°†éŸ³é¢‘æ˜ å°„åˆ°ç½‘æ ¼ã€‚å¯¹äºè¡¨æƒ…è¿åŠ¨ï¼Œé‡‡ç”¨æ··åˆå½¢çŠ¶å’Œé¡¶ç‚¹ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œä»¥æœ€å¤§é™åº¦åœ°æé«˜æ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ã€‚å¯¹äºè‡ªç„¶å¤´éƒ¨è¿åŠ¨ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å¯å­¦ä¹ å¤´éƒ¨å§¿åŠ¿ç æœ¬ï¼Œå¹¶é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæœºåˆ¶ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæå‡ºäº†ä¸€ç§åŒåˆ†æ”¯è¿åŠ¨-VAE å’Œç”Ÿæˆå™¨ï¼Œå°†ç½‘æ ¼è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨å¹¶é€å¸§åˆæˆé«˜è´¨é‡è§†é¢‘ã€‚
ï¼ˆ4ï¼‰ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ VividTalk å¯ä»¥ç”Ÿæˆå…·æœ‰å”‡å½¢åŒæ­¥å’Œé€¼çœŸå¤´éƒ¨å§¿åŠ¿çš„é«˜è§†è§‰è´¨é‡è¯´è¯å¤´è§†é¢‘ï¼Œå¹¶ä¸”åœ¨å®¢è§‚å’Œä¸»è§‚æ¯”è¾ƒä¸­ä¼˜äºä»¥å¾€çš„æœ€æ–°ä½œå“ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šVividTalk æ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç½‘æ ¼ç”Ÿæˆé˜¶æ®µå’Œè§†é¢‘åˆæˆé˜¶æ®µã€‚åœ¨ç½‘æ ¼ç”Ÿæˆé˜¶æ®µï¼ŒéŸ³é¢‘é¦–å…ˆè¢«æ˜ å°„åˆ°ç½‘æ ¼ï¼Œç½‘æ ¼ç”±æ··åˆå½¢çŠ¶å’Œé¡¶ç‚¹åç§»è¡¨ç¤ºã€‚æ··åˆå½¢çŠ¶ç”¨äºæ•æ‰ç²¾ç»†çš„è¡¨æƒ…ç»†èŠ‚ï¼Œè€Œé¡¶ç‚¹åç§»ç”¨äºæ•æ‰åˆšæ€§å¤´éƒ¨è¿åŠ¨ã€‚åœ¨è§†é¢‘åˆæˆé˜¶æ®µï¼Œç½‘æ ¼è¢«è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨ï¼Œç„¶åé€å¸§åˆæˆé«˜è´¨é‡è§†é¢‘ã€‚
ï¼ˆ2ï¼‰ï¼šåœ¨ç½‘æ ¼ç”Ÿæˆé˜¶æ®µï¼ŒéŸ³é¢‘é¦–å…ˆè¢«æ˜ å°„åˆ°ä¸€ä¸ªä¸­é—´è¡¨ç¤ºï¼Œè¯¥ä¸­é—´è¡¨ç¤ºç”±æ··åˆå½¢çŠ¶å’Œé¡¶ç‚¹åç§»ç»„æˆã€‚æ··åˆå½¢çŠ¶ç”¨äºæ•æ‰ç²¾ç»†çš„è¡¨æƒ…ç»†èŠ‚ï¼Œè€Œé¡¶ç‚¹åç§»ç”¨äºæ•æ‰åˆšæ€§å¤´éƒ¨è¿åŠ¨ã€‚ç„¶åï¼Œä¸­é—´è¡¨ç¤ºè¢«æ˜ å°„åˆ°ç½‘æ ¼ã€‚
ï¼ˆ3ï¼‰ï¼šåœ¨è§†é¢‘åˆæˆé˜¶æ®µï¼Œç½‘æ ¼è¢«è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨ã€‚å¯†é›†è¿åŠ¨ç„¶åè¢«ç”¨äºé€å¸§åˆæˆé«˜è´¨é‡è§†é¢‘ã€‚è§†é¢‘åˆæˆå™¨æ˜¯ä¸€ä¸ªåŒåˆ†æ”¯ç½‘ç»œï¼Œç”±ä¸€ä¸ªè¿åŠ¨-VAE å’Œä¸€ä¸ªç”Ÿæˆå™¨ç»„æˆã€‚è¿åŠ¨-VAE ç”¨äºç”Ÿæˆå¯†é›†è¿åŠ¨ï¼Œè€Œç”Ÿæˆå™¨ç”¨äºåˆæˆè§†é¢‘ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé¦–æ¬¡æå‡ºäº†ä¸€ç§æ”¯æŒç”Ÿæˆå…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œè‡ªç„¶å¤´éƒ¨å§¿åŠ¿çš„é«˜è´¨é‡è¯´è¯å¤´è§†é¢‘çš„æ–°é¢–é€šç”¨æ¡†æ¶ VividTalkã€‚å¯¹äºéåˆšæ€§è¡¨æƒ…è¿åŠ¨ï¼Œæ··åˆå½¢çŠ¶å’Œé¡¶ç‚¹éƒ½è¢«æ˜ å°„ä¸ºä¸­é—´è¡¨ç¤ºä»¥æœ€å¤§åŒ–æ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªç²¾å¿ƒæ„å»ºçš„å¤šåˆ†æ”¯ç”Ÿæˆå™¨æ¥åˆ†åˆ«å¯¹å…¨å±€å’Œå±€éƒ¨é¢éƒ¨è¿åŠ¨è¿›è¡Œå»ºæ¨¡ã€‚è‡³äºåˆšæ€§å¤´éƒ¨è¿åŠ¨ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å¯å­¦ä¹ å¤´éƒ¨å§¿åŠ¿ç æœ¬å’Œä¸€ç§ä¸¤é˜¶æ®µè®­ç»ƒæœºåˆ¶æ¥åˆæˆè‡ªç„¶ç»“æœã€‚å¾—ç›ŠäºåŒåˆ†æ”¯è¿åŠ¨-VAE å’Œç”Ÿæˆå™¨ï¼Œé©±åŠ¨çš„ç½‘æ ¼å¯ä»¥å¾ˆå¥½åœ°è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨ï¼Œå¹¶ç”¨äºåˆæˆæœ€ç»ˆè§†é¢‘ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºä»¥å¾€æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶åœ¨æ•°å­—äººåˆ›å»ºã€è§†é¢‘ä¼šè®®ç­‰è®¸å¤šåº”ç”¨ä¸­å¼€è¾Ÿäº†æ–°é€”å¾„ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„é€šç”¨æ¡†æ¶ VividTalkï¼Œæ”¯æŒç”Ÿæˆå…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œè‡ªç„¶å¤´éƒ¨å§¿åŠ¿çš„é«˜è´¨é‡è¯´è¯å¤´è§†é¢‘ã€‚</li>
<li>å¯¹äºéåˆšæ€§è¡¨æƒ…è¿åŠ¨ï¼Œæ··åˆå½¢çŠ¶å’Œé¡¶ç‚¹éƒ½è¢«æ˜ å°„ä¸ºä¸­é—´è¡¨ç¤ºä»¥æœ€å¤§åŒ–æ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªç²¾å¿ƒæ„å»ºçš„å¤šåˆ†æ”¯ç”Ÿæˆå™¨æ¥åˆ†åˆ«å¯¹å…¨å±€å’Œå±€éƒ¨é¢éƒ¨è¿åŠ¨è¿›è¡Œå»ºæ¨¡ã€‚</li>
<li>å¯¹äºåˆšæ€§å¤´éƒ¨è¿åŠ¨ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å¯å­¦ä¹ å¤´éƒ¨å§¿åŠ¿ç æœ¬å’Œä¸€ç§ä¸¤é˜¶æ®µè®­ç»ƒæœºåˆ¶æ¥åˆæˆè‡ªç„¶ç»“æœã€‚</li>
<li>å¾—ç›ŠäºåŒåˆ†æ”¯è¿åŠ¨-VAE å’Œç”Ÿæˆå™¨ï¼Œé©±åŠ¨çš„ç½‘æ ¼å¯ä»¥å¾ˆå¥½åœ°è½¬æ¢ä¸ºå¯†é›†è¿åŠ¨ï¼Œå¹¶ç”¨äºåˆæˆæœ€ç»ˆè§†é¢‘ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å®¢è§‚å’Œä¸»è§‚æ¯”è¾ƒä¸­ï¼ŒVividTalk ä¼˜äºä»¥å¾€æœ€å…ˆè¿›çš„ä½œå“ã€‚</li>
<li>VividTalk å¯ä»¥ç”Ÿæˆå…·æœ‰å”‡å½¢åŒæ­¥å’Œé€¼çœŸå¤´éƒ¨å§¿åŠ¿çš„é«˜è§†è§‰è´¨é‡è¯´è¯å¤´è§†é¢‘ã€‚
å·¥ä½œé‡ï¼š</li>
<li>VividTalk çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>VividTalk çš„è®­ç»ƒè¿‡ç¨‹å¯èƒ½éœ€è¦æ•°å¤©æˆ–æ•°å‘¨çš„æ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b072ca131954e5aa54fae54f90858dae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ef1751be1b0bb02f7a73562aad64e5f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-18bcd1380728d32e1277fd17982288c6.jpg" align="middle">
</details>




<h2 id="3DiFACE-Diffusion-based-Speech-driven-3D-Facial-Animation-and-Editing"><a href="#3DiFACE-Diffusion-based-Speech-driven-3D-Facial-Animation-and-Editing" class="headerlink" title="3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing"></a>3DiFACE: Diffusion-based Speech-driven 3D Facial Animation and Editing</h2><p><strong>Authors:Balamurugan Thambiraja, Sadegh Aliakbarian, Darren Cosker, Justus Thies</strong></p>
<p>We present 3DiFACE, a novel method for personalized speech-driven 3D facial animation and editing. While existing methods deterministically predict facial animations from speech, they overlook the inherent one-to-many relationship between speech and facial expressions, i.e., there are multiple reasonable facial expression animations matching an audio input. It is especially important in content creation to be able to modify generated motion or to specify keyframes. To enable stochasticity as well as motion editing, we propose a lightweight audio-conditioned diffusion model for 3D facial motion. This diffusion model can be trained on a small 3D motion dataset, maintaining expressive lip motion output. In addition, it can be finetuned for specific subjects, requiring only a short video of the person. Through quantitative and qualitative evaluations, we show that our method outperforms existing state-of-the-art techniques and yields speech-driven animations with greater fidelity and diversity. </p>
<p><a href="http://arxiv.org/abs/2312.00870v1">PDF</a> Project page: <a href="https://balamuruganthambiraja.github.io/3DiFACE/">https://balamuruganthambiraja.github.io/3DiFACE/</a></p>
<p><strong>Summary</strong></p>
<p>è¯­éŸ³é©±åŠ¨ã€å¯ç¼–è¾‘çš„ 3D é¢éƒ¨åŠ¨ç”»æ–°æ–¹å¼ï¼Œæ•ˆæœæ›´é€¼çœŸã€æ›´çµæ´»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3DiFACE æå‡ºä¸€ç§åˆ©ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œ 3D é¢éƒ¨åŠ¨ä½œç”Ÿæˆçš„æ–°æ–¹æ³•ï¼Œæ”¯æŒä¸ªæ€§åŒ–è¯­éŸ³é©±åŠ¨ä»¥åŠç¼–è¾‘ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥ä»å°‘é‡ 3D åŠ¨ä½œæ•°æ®é›†ä¸­è¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¿æŒé€¼çœŸçš„å˜´éƒ¨åŠ¨ä½œã€‚</li>
<li>3DiFACE è¿˜æ”¯æŒé’ˆå¯¹ç‰¹å®šä¸ªä½“è¿›è¡Œå¾®è°ƒï¼Œåªéœ€ä¸€ä¸ªç®€çŸ­çš„è§†é¢‘å³å¯ã€‚</li>
<li>å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¯ç”Ÿæˆæ›´é€¼çœŸã€æ›´å…·å¤šæ ·æ€§çš„è¯­éŸ³é©±åŠ¨åŠ¨ç”»ã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œ3DiFACE å¯ä»¥ç”Ÿæˆæ›´å…·å¤šæ ·æ€§çš„é¢éƒ¨åŠ¨ç”»ï¼Œå¹¶ä¸”èƒ½å¤Ÿç¼–è¾‘ç”Ÿæˆçš„è¿åŠ¨æˆ–æŒ‡å®šå…³é”®å¸§ã€‚</li>
<li>3DiFACE æ¨¡å‹è®­ç»ƒç®€å•ï¼Œè®­ç»ƒæ•°æ®é‡å°‘ã€‚</li>
<li>3DiFACE æ¨¡å‹å¯ä»¥åº”ç”¨äºå†…å®¹åˆ›ä½œå’ŒåŠ¨ç”»åˆ¶ä½œç­‰é¢†åŸŸã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼š3DiFACEï¼šåŸºäºæ‰©æ•£çš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»å’Œç¼–è¾‘</li>
<li>ä½œè€…ï¼šBalamurugan Thambirajaã€Sadegh Aliakbarianã€Darren Coskerã€Justus Thies</li>
<li>éš¶å±æœºæ„ï¼šå¾·å›½å›¾å®¾æ ¹é©¬å…‹æ–¯Â·æ™®æœ—å…‹æ™ºèƒ½ç³»ç»Ÿç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼š3D é¢éƒ¨åŠ¨ç”»ã€è¯­éŸ³é©±åŠ¨ã€æ‰©æ•£æ¨¡å‹ã€è¿åŠ¨ç¼–è¾‘</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://balamuruganthambiraja.github.io/3DiFACESpeechAudio3DiFACEInpaintedMotionFixedKeyframeFixedKeyframeAnimationSynthesisAnimationEditing
   Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D é¢éƒ¨åŠ¨ç”»åœ¨æ•°å­—ä½“éªŒä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ï¼Œä½†ç°æœ‰çš„æ–¹æ³•å¤§å¤šæ˜¯ç¡®å®šæ€§åœ°é¢„æµ‹é¢éƒ¨åŠ¨ç”»ï¼Œå¿½ç•¥äº†è¯­éŸ³å’Œé¢éƒ¨è¡¨æƒ…ä¹‹é—´çš„ä¸€å¯¹å¤šå…³ç³»ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­¦ä¹ è¯­éŸ³å’Œé¢éƒ¨åŠ¨ç”»ä¹‹é—´çš„ç¡®å®šæ€§æ˜ å°„ï¼Œé™åˆ¶äº†åˆæˆåŠ¨ç”»çš„å¤šæ ·æ€§ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§è½»é‡çº§çš„éŸ³é¢‘æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œç”¨äº 3D é¢éƒ¨è¿åŠ¨ã€‚è¯¥æ¨¡å‹å¯ä»¥åœ¨å°å‹ 3D è¿åŠ¨æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¹¶ä¿æŒå¯Œæœ‰è¡¨ç°åŠ›çš„å”‡éƒ¨è¿åŠ¨è¾“å‡ºã€‚æ­¤å¤–ï¼Œå®ƒå¯ä»¥é’ˆå¯¹ç‰¹å®šå¯¹è±¡è¿›è¡Œå¾®è°ƒï¼Œåªéœ€ä¸€æ®µè¯¥äººçš„çŸ­è§†é¢‘ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½å’Œç›®æ ‡å®ç°æƒ…å†µï¼šé€šè¿‡å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹¶äº§ç”Ÿäº†å…·æœ‰æ›´é«˜ä¿çœŸåº¦å’Œå¤šæ ·æ€§çš„è¯­éŸ³é©±åŠ¨åŠ¨ç”»ï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p>Methods:
(1): æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„è¯­éŸ³é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»å’Œç¼–è¾‘æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥å­¦ä¹ è¯­éŸ³å’Œé¢éƒ¨åŠ¨ç”»ä¹‹é—´çš„ä¸€å¯¹å¤šå…³ç³»ï¼Œå¹¶ç”Ÿæˆå…·æœ‰æ›´é«˜ä¿çœŸåº¦å’Œå¤šæ ·æ€§çš„è¯­éŸ³é©±åŠ¨åŠ¨ç”»ã€‚
(2): è¯¥æ–¹æ³•ä½¿ç”¨äº†ä¸€ä¸ªè½»é‡çº§çš„éŸ³é¢‘æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åœ¨å°å‹3Dè¿åŠ¨æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¹¶ä¿æŒå¯Œæœ‰è¡¨ç°åŠ›çš„å”‡éƒ¨è¿åŠ¨è¾“å‡ºã€‚
(3): è¯¥æ–¹æ³•è¿˜å¯ä»¥é’ˆå¯¹ç‰¹å®šå¯¹è±¡è¿›è¡Œå¾®è°ƒï¼Œåªéœ€ä¸€æ®µè¯¥äººçš„çŸ­è§†é¢‘ã€‚
(4): é€šè¿‡å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹¶äº§ç”Ÿäº†å…·æœ‰æ›´é«˜ä¿çœŸåº¦å’Œå¤šæ ·æ€§çš„è¯­éŸ³é©±åŠ¨åŠ¨ç”»ï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œé¦–æ¬¡æå‡ºäº†ä¸€ç§å¯ä»¥ä»è¯­éŸ³è¾“å…¥ç”Ÿæˆå’Œç¼–è¾‘å¤šæ ·åŒ– 3D é¢éƒ¨åŠ¨ç”»çš„æ–¹æ³•ã€‚ä½¿ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§æœ‰æ•ˆçš„å·¥å…·æ¥å¹³è¡¡åˆæˆå¤šæ ·æ€§å’Œå‡†ç¡®æ€§ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿç”Ÿæˆå…·æœ‰å‰æ‰€æœªæœ‰çš„å¤šæ ·æ€§çš„åŠ¨ç”»ï¼ŒåŒæ—¶åœ¨åˆæˆå‡†ç¡®æ€§æ–¹é¢ä¼˜äºæˆ–åŒ¹é…æ‰€æœ‰åŸºçº¿ã€‚é€šè¿‡ä¸ªæ€§åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥ä»çŸ­ï¼ˆ~100 ç§’ï¼‰è§†é¢‘ä¸­æå–ç‰¹å®šäººç‰©çš„è¯´è¯é£æ ¼ï¼Œä»è€Œæ˜¾è‘—æé«˜æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¶æ„å…è®¸æˆ‘ä»¬é€šè¿‡ä½¿ç”¨å…³é”®å¸§æ¥ç¼–è¾‘åŠ¨ç”»ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™äº›ç‰¹æ€§ä½¿ 3DiFACE æˆä¸ºå†…å®¹åˆ›ä½œè€…çš„å¼ºå¤§å·¥å…·ï¼Œå¹¶å¯¹æœªæ¥çš„åº”ç”¨æ„Ÿåˆ°å…´å¥‹ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»å’Œç¼–è¾‘æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥å­¦ä¹ è¯­éŸ³å’Œé¢éƒ¨åŠ¨ç”»ä¹‹é—´çš„ä¸€å¯¹å¤šå…³ç³»ï¼Œå¹¶ç”Ÿæˆå…·æœ‰æ›´é«˜ä¿çœŸåº¦å’Œå¤šæ ·æ€§çš„è¯­éŸ³é©±åŠ¨åŠ¨ç”»ã€‚
è¯¥æ–¹æ³•ä½¿ç”¨äº†ä¸€ä¸ªè½»é‡çº§çš„éŸ³é¢‘æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åœ¨å°å‹ 3D è¿åŠ¨æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¹¶ä¿æŒå¯Œæœ‰è¡¨ç°åŠ›çš„å”‡éƒ¨è¿åŠ¨è¾“å‡ºã€‚
è¯¥æ–¹æ³•è¿˜å¯ä»¥é’ˆå¯¹ç‰¹å®šå¯¹è±¡è¿›è¡Œå¾®è°ƒï¼Œåªéœ€ä¸€æ®µè¯¥äººçš„çŸ­è§†é¢‘ã€‚
é€šè¿‡å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œå¹¶äº§ç”Ÿäº†å…·æœ‰æ›´é«˜ä¿çœŸåº¦å’Œå¤šæ ·æ€§çš„è¯­éŸ³é©±åŠ¨åŠ¨ç”»ï¼Œè¯æ˜äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
æ€§èƒ½ï¼š
è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨åˆæˆå‡†ç¡®æ€§å’Œå¤šæ ·æ€§æ–¹é¢ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚
è¯¥æ–¹æ³•å¯ä»¥é’ˆå¯¹ç‰¹å®šå¯¹è±¡è¿›è¡Œå¾®è°ƒï¼Œåªéœ€ä¸€æ®µè¯¥äººçš„çŸ­è§†é¢‘ï¼Œè¿™ä½¿å¾—è¯¥æ–¹æ³•å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºå„ç§åº”ç”¨åœºæ™¯ã€‚
è¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆå…·æœ‰é«˜ä¿çœŸåº¦å’Œå¤šæ ·æ€§çš„è¯­éŸ³é©±åŠ¨åŠ¨ç”»ï¼Œè¿™ä½¿å¾—è¯¥æ–¹æ³•éå¸¸é€‚åˆç”¨äºç”µå½±ã€æ¸¸æˆå’Œå…¶ä»–æ•°å­—ä½“éªŒã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹ç®€å•ï¼Œå¯ä»¥åœ¨å°å‹ 3D è¿åŠ¨æ•°æ®é›†ä¸Šè®­ç»ƒã€‚
è¯¥æ–¹æ³•å¯ä»¥é’ˆå¯¹ç‰¹å®šå¯¹è±¡è¿›è¡Œå¾®è°ƒï¼Œåªéœ€ä¸€æ®µè¯¥äººçš„çŸ­è§†é¢‘ï¼Œè¿™ä½¿å¾—è¯¥æ–¹æ³•å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºå„ç§åº”ç”¨åœºæ™¯ã€‚
è¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆå…·æœ‰é«˜ä¿çœŸåº¦å’Œå¤šæ ·æ€§çš„è¯­éŸ³é©±åŠ¨åŠ¨ç”»ï¼Œè¿™ä½¿å¾—è¯¥æ–¹æ³•éå¸¸é€‚åˆç”¨äºç”µå½±ã€æ¸¸æˆå’Œå…¶ä»–æ•°å­—ä½“éªŒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e9da6eed634be4372cb5b6b3a1d361be.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-981d7296309ee36a1b0bddfb6e9dc188.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5d7e90cbb37a3074d13c36527f21fe60.jpg" align="middle">
</details>




<h2 id="SyncTalk-The-Devil-is-in-the-Synchronization-for-Talking-Head-Synthesis"><a href="#SyncTalk-The-Devil-is-in-the-Synchronization-for-Talking-Head-Synthesis" class="headerlink" title="SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis"></a>SyncTalk: The Devil is in the Synchronization for Talking Head Synthesis</h2><p><strong>Authors:Ziqiao Peng, Wentao Hu, Yue Shi, Xiangyu Zhu, Xiaomei Zhang, Hao Zhao, Jun He, Hongyan Liu, Zhaoxin Fan</strong></p>
<p>Achieving high synchronization in the synthesis of realistic, speech-driven talking head videos presents a significant challenge. Traditional Generative Adversarial Networks (GAN) struggle to maintain consistent facial identity, while Neural Radiance Fields (NeRF) methods, although they can address this issue, often produce mismatched lip movements, inadequate facial expressions, and unstable head poses. A lifelike talking head requires synchronized coordination of subject identity, lip movements, facial expressions, and head poses. The absence of these synchronizations is a fundamental flaw, leading to unrealistic and artificial outcomes. To address the critical issue of synchronization, identified as the â€œdevilâ€ in creating realistic talking heads, we introduce SyncTalk. This NeRF-based method effectively maintains subject identity, enhancing synchronization and realism in talking head synthesis. SyncTalk employs a Face-Sync Controller to align lip movements with speech and innovatively uses a 3D facial blendshape model to capture accurate facial expressions. Our Head-Sync Stabilizer optimizes head poses, achieving more natural head movements. The Portrait-Sync Generator restores hair details and blends the generated head with the torso for a seamless visual experience. Extensive experiments and user studies demonstrate that SyncTalk outperforms state-of-the-art methods in synchronization and realism. We recommend watching the supplementary video: <a href="https://ziqiaopeng.github.io/synctalk">https://ziqiaopeng.github.io/synctalk</a> </p>
<p><a href="http://arxiv.org/abs/2311.17590v1">PDF</a> 11 pages, 5 figures</p>
<p><strong>æ‘˜è¦</strong><br>ç¥ç»è¾å°„åœº-ç”Ÿæˆå¯¹æŠ—ç½‘ç»œæ¡†æ¶ç”¨äºå®ç°è¯´è¯äººå¤´éƒ¨è§†é¢‘çš„åŒæ­¥åˆæˆã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>ä¼ ç»Ÿç”Ÿæˆå¯¹æŠ—ç½‘ç»œéš¾ä»¥ç»´æŒä¸€è‡´çš„é¢éƒ¨èº«ä»½ã€‚</li>
<li>ç¥ç»è¾å°„åœºæ–¹æ³•å¯ä»¥è§£å†³é¢éƒ¨èº«ä»½ä¸€è‡´æ€§é—®é¢˜ï¼Œä½†ç»å¸¸å‡ºç°å˜´å”‡è¿åŠ¨ä¸åŒ¹é…ã€é¢éƒ¨è¡¨æƒ…ä¸è¶³å’Œå¤´éƒ¨å§¿åŠ¿ä¸ç¨³å®šçš„é—®é¢˜ã€‚</li>
<li>é€¼çœŸçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘éœ€è¦åŒæ­¥åè°ƒä¸»ä½“èº«ä»½ã€å˜´å”‡è¿åŠ¨ã€é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚</li>
<li>ç¼ºå°‘åŒæ­¥æ€§æ˜¯å¯¼è‡´ä¸çœŸå®å’Œäººä¸ºç»“æœçš„æ ¹æœ¬ç¼ºé™·ã€‚</li>
<li>SyncTalk æ˜¯ä¸€ç§åŸºäºç¥ç»è¾å°„åœºçš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°ä¿æŒäº†ä¸»ä½“èº«ä»½ï¼Œæé«˜äº†è¯´è¯äººå¤´éƒ¨åˆæˆä¸­çš„åŒæ­¥æ€§å’ŒçœŸå®æ„Ÿã€‚</li>
<li>SyncTalk ä½¿ç”¨é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨å°†å˜´å”‡è¿åŠ¨ä¸è¯­éŸ³å¯¹é½ï¼Œå¹¶åˆ›æ–°åœ°ä½¿ç”¨ 3D é¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹æ¥æ•æ‰å‡†ç¡®çš„é¢éƒ¨è¡¨æƒ…ã€‚</li>
<li>SyncTalk çš„å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ä¼˜åŒ–äº†å¤´éƒ¨å§¿åŠ¿ï¼Œå®ç°äº†æ›´è‡ªç„¶çš„å¤´éƒ¨è¿åŠ¨ã€‚</li>
<li>äººåƒåŒæ­¥ç”Ÿæˆå™¨æ¢å¤å¤´å‘ç»†èŠ‚ï¼Œå°†ç”Ÿæˆçš„å¤´éƒ¨ä¸èº¯å¹²èåˆï¼Œä»¥è·å¾—æ— ç¼çš„è§†è§‰ä½“éªŒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šSyncTalkï¼šè°ˆè¯å¤´éƒ¨åˆæˆåŒæ­¥çš„é­”é¬¼</li>
<li>ä½œè€…ï¼šZiqiao Peng, Wentao Hu, Yue Shi, Xiangyu Zhu, Xiaomei Zhang, Hao Zhao, Jun He, Hongyan Liu, Zhaoxin Fan</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½äººæ°‘å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè°ˆè¯å¤´éƒ¨åˆæˆã€ç¥ç»è¾å°„åœºã€åŒæ­¥ã€èº«ä»½ä¿æŒã€è¡¨æƒ…æ§åˆ¶ã€å¤´éƒ¨å§¿åŠ¿ç¨³å®š</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.17590
   Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼š
ç”Ÿæˆé€¼çœŸçš„ã€ç”±è¯­éŸ³é©±åŠ¨çš„è°ˆè¯å¤´éƒ¨è§†é¢‘æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ä¼ ç»Ÿç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰éš¾ä»¥ä¿æŒä¸€è‡´çš„é¢éƒ¨èº«ä»½ï¼Œè€Œç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•è™½ç„¶å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†é€šå¸¸ä¼šäº§ç”Ÿä¸åŒ¹é…çš„å”‡éƒ¨åŠ¨ä½œã€ä¸å……åˆ†çš„é¢éƒ¨è¡¨æƒ…å’Œä¸ç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ã€‚ä¸€ä¸ªé€¼çœŸçš„è°ˆè¯å¤´éƒ¨éœ€è¦åŒæ­¥åè°ƒä¸»ä½“èº«ä»½ã€å”‡éƒ¨åŠ¨ä½œã€é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚ç¼ºä¹è¿™äº›åŒæ­¥æ˜¯å¯¼è‡´ä¸çœŸå®å’Œäººå·¥ç»“æœçš„æ ¹æœ¬ç¼ºé™·ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
GAN æ–¹æ³•éš¾ä»¥ä¿æŒä¸€è‡´çš„é¢éƒ¨èº«ä»½ã€‚NeRF æ–¹æ³•è™½ç„¶å¯ä»¥è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†é€šå¸¸ä¼šäº§ç”Ÿä¸åŒ¹é…çš„å”‡éƒ¨åŠ¨ä½œã€ä¸å……åˆ†çš„é¢éƒ¨è¡¨æƒ…å’Œä¸ç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ã€‚
ï¼ˆ3ï¼‰ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
SyncTalk æ˜¯ä¸€ç§åŸºäº NeRF çš„æ–¹æ³•ï¼Œå®ƒæœ‰æ•ˆåœ°ä¿æŒäº†ä¸»ä½“èº«ä»½ï¼Œå¢å¼ºäº†è°ˆè¯å¤´éƒ¨åˆæˆçš„åŒæ­¥æ€§å’ŒçœŸå®æ€§ã€‚SyncTalk ä½¿ç”¨é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨å°†å”‡éƒ¨åŠ¨ä½œä¸è¯­éŸ³å¯¹é½ï¼Œå¹¶åˆ›æ–°åœ°ä½¿ç”¨ 3D é¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹æ¥æ•æ‰å‡†ç¡®çš„é¢éƒ¨è¡¨æƒ…ã€‚å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ä¼˜åŒ–å¤´éƒ¨å§¿åŠ¿ï¼Œå®ç°æ›´è‡ªç„¶çš„å¤´éƒ¨è¿åŠ¨ã€‚è‚–åƒåŒæ­¥ç”Ÿæˆå™¨æ¢å¤å¤´å‘ç»†èŠ‚ï¼Œå¹¶å°†ç”Ÿæˆçš„å¤´éƒ¨ä¸èº¯å¹²èåˆï¼Œä»¥è·å¾—æ— ç¼çš„è§†è§‰ä½“éªŒã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¿™äº›æ€§èƒ½æ˜¯å¦æ”¯æŒäº†å®ƒä»¬çš„ç›®æ ‡ï¼š
SyncTalk åœ¨è°ˆè¯å¤´éƒ¨åˆæˆåŒæ­¥æ€§å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚å¹¿æ³›çš„å®éªŒå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒSyncTalk åœ¨åŒæ­¥æ€§å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1)ï¼šé¢éƒ¨åŒæ­¥æ§åˆ¶å™¨ï¼šä½¿ç”¨å”‡éƒ¨åŒæ­¥åˆ¤åˆ«å™¨é¢„è®­ç»ƒä¸€ä¸ªé«˜åº¦åŒæ­¥çš„éŸ³é¢‘-è§†è§‰ç‰¹å¾æå–å™¨ï¼›å¼•å…¥ 3D é¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹æ¥æ•æ‰å‡†ç¡®çš„é¢éƒ¨è¡¨æƒ…ï¼›ä½¿ç”¨é¢éƒ¨æ„ŸçŸ¥æ©ç æ³¨æ„åŠ›æ¥å‡å°‘å”‡éƒ¨ç‰¹å¾å’Œè¡¨æƒ…ç‰¹å¾ä¹‹é—´çš„ç›¸äº’å¹²æ‰°ã€‚
(2)ï¼šå¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ï¼šä½¿ç”¨å¤´éƒ¨è¿åŠ¨è·Ÿè¸ªå™¨æ¥è·å¾—å¤´éƒ¨å§¿æ€çš„ç²—ç•¥ä¼°è®¡ï¼›ä½¿ç”¨å¤´éƒ¨ç‚¹è·Ÿè¸ªå™¨æ¥è·Ÿè¸ªé¢éƒ¨å…³é”®ç‚¹ï¼›ä½¿ç”¨æŸè°ƒæ•´æ¥å¢å¼ºå…³é”®ç‚¹å’Œå¤´éƒ¨å§¿æ€ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚
(3)ï¼šåŠ¨æ€è‚–åƒæ¸²æŸ“å™¨ï¼šä½¿ç”¨ä¸‰å¹³é¢å“ˆå¸Œè¡¨ç¤ºæ¥è¡¨ç¤º 3D åœºæ™¯ï¼›ä½¿ç”¨å¯å˜å½¢ç¥ç»è¾å°„åœºæ¥æ•æ‰åŠ¨æ€å¯¹è±¡çš„å¤–è§‚ï¼›ä½¿ç”¨è‚–åƒåŒæ­¥ç”Ÿæˆå™¨æ¥æ¢å¤å¤´å‘ç»†èŠ‚å¹¶èåˆå¤´éƒ¨å’Œèº¯å¹²ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰ï¼šæ„ä¹‰ï¼šSyncTalk æ˜¯ä¸€ç§åŸºäºç¥ç»è¾å°„åœºçš„é«˜åŒæ­¥è¯­éŸ³é©±åŠ¨è°ˆè¯å¤´éƒ¨åˆæˆæ–¹æ³•ï¼Œèƒ½å¤Ÿä¿æŒä¸»ä½“èº«ä»½å¹¶ç”ŸæˆåŒæ­¥çš„å”‡éƒ¨åŠ¨ä½œã€é¢éƒ¨è¡¨æƒ…å’Œç¨³å®šçš„å¤´éƒ¨å§¿åŠ¿ã€‚SyncTalk åœ¨è°ˆè¯å¤´éƒ¨åˆæˆåŒæ­¥æ€§å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œæœ‰æœ›å¢å¼ºå„ç§åº”ç”¨å¹¶æ¿€å‘è°ˆè¯å¤´éƒ¨åˆæˆé¢†åŸŸè¿›ä¸€æ­¥åˆ›æ–°ã€‚</p>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
- æå‡ºäº†ä¸€ç§æ–°çš„è°ˆè¯å¤´éƒ¨åˆæˆæ–¹æ³• SyncTalkï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä¿æŒä¸»ä½“èº«ä»½ï¼Œå¢å¼ºè°ˆè¯å¤´éƒ¨åˆæˆçš„åŒæ­¥æ€§å’ŒçœŸå®æ€§ã€‚
- ä½¿ç”¨é¢éƒ¨åŒæ­¥æ§åˆ¶å™¨å°†å”‡éƒ¨åŠ¨ä½œä¸è¯­éŸ³å¯¹é½ï¼Œå¹¶åˆ›æ–°åœ°ä½¿ç”¨ 3D é¢éƒ¨æ··åˆå½¢çŠ¶æ¨¡å‹æ¥æ•æ‰å‡†ç¡®çš„é¢éƒ¨è¡¨æƒ…ã€‚
- ä½¿ç”¨å¤´éƒ¨åŒæ­¥ç¨³å®šå™¨ä¼˜åŒ–å¤´éƒ¨å§¿åŠ¿ï¼Œå®ç°æ›´è‡ªç„¶çš„å¤´éƒ¨è¿åŠ¨ã€‚
- ä½¿ç”¨è‚–åƒåŒæ­¥ç”Ÿæˆå™¨æ¢å¤å¤´å‘ç»†èŠ‚ï¼Œå¹¶å°†ç”Ÿæˆçš„å¤´éƒ¨ä¸èº¯å¹²èåˆï¼Œä»¥è·å¾—æ— ç¼çš„è§†è§‰ä½“éªŒã€‚</p>
<p>æ€§èƒ½ï¼š
- SyncTalk åœ¨è°ˆè¯å¤´éƒ¨åˆæˆåŒæ­¥æ€§å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
- å¹¿æ³›çš„å®éªŒå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒSyncTalk åœ¨åŒæ­¥æ€§å’ŒçœŸå®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
<p>å·¥ä½œé‡ï¼š
- SyncTalk çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚
- SyncTalk çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-fd17c6961448d8c17f0288819dc76c44.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f17a1563bd9dde5f0ecdc2862b78f71c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11f3ba567cdea1cc222349d8eaca8ee1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-71774a339b795203c4ab57e06c0114e5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2dec8013e0bb70e058e8514cfbe99d7c.jpg" align="middle">
</details>





## DiffusionTalker: Personalization and Acceleration for Speech-Driven 3D   Face Diffuser

**Authors:Peng Chen, Xiaobao Wei, Ming Lu, Yitong Zhu, Naiming Yao, Xingyu Xiao, Hui Chen**

Speech-driven 3D facial animation has been an attractive task in both academia and industry. Traditional methods mostly focus on learning a deterministic mapping from speech to animation. Recent approaches start to consider the non-deterministic fact of speech-driven 3D face animation and employ the diffusion model for the task. However, personalizing facial animation and accelerating animation generation are still two major limitations of existing diffusion-based methods. To address the above limitations, we propose DiffusionTalker, a diffusion-based method that utilizes contrastive learning to personalize 3D facial animation and knowledge distillation to accelerate 3D animation generation. Specifically, to enable personalization, we introduce a learnable talking identity to aggregate knowledge in audio sequences. The proposed identity embeddings extract customized facial cues across different people in a contrastive learning manner. During inference, users can obtain personalized facial animation based on input audio, reflecting a specific talking style. With a trained diffusion model with hundreds of steps, we distill it into a lightweight model with 8 steps for acceleration. Extensive experiments are conducted to demonstrate that our method outperforms state-of-the-art methods. The code will be released. 

[PDF](http://arxiv.org/abs/2311.16565v2) 

**Summary**
æ‰©æ•£ç½‘ç»œæŠ€æœ¯åˆ›æ–°ç”Ÿæˆä¸ªæ€§åŒ–3DåŠ¨æ€äººè„¸ï¼Œæ˜¾è‘—æå‡äººè„¸åŠ¨ç”»ç”Ÿæˆæ•ˆç‡ã€‚

**Key Takeaways**

- åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆ 3D äººè„¸åŠ¨ç”»ï¼Œèƒ½å¤Ÿè€ƒè™‘åˆ°è¨€è¯­é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»çš„éç¡®å®šæ€§ã€‚
- æå‡ºçš„æ‰©æ•£è°ˆè¯å™¨ï¼Œæ˜¯ä¸€ç§åŸºäºæ‰©æ•£çš„æ–¹æ³•ï¼Œåˆ©ç”¨å¯¹æ¯”å­¦ä¹ å®ç°ä¸ªæ€§åŒ– 3D é¢éƒ¨åŠ¨ç”»å’ŒçŸ¥è¯†è’¸é¦æ¥åŠ é€Ÿ 3D åŠ¨ç”»ç”Ÿæˆã€‚
- å¯è®­ç»ƒçš„è¯´è¯è€…èº«ä»½å¼•å…¥èƒ½å¤Ÿæ±‡æ€»éŸ³é¢‘åºåˆ—ä¸­çš„çŸ¥è¯†ã€‚
- æå‡ºçš„èº«ä»½åµŒå…¥ä»¥å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼æå–ä¸åŒäººä¹‹é—´çš„è‡ªå®šä¹‰é¢éƒ¨çº¿ç´¢ã€‚
- åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®è¾“å…¥éŸ³é¢‘è·å¾—ä¸ªæ€§åŒ–çš„é¢éƒ¨åŠ¨ç”»ï¼Œä»è€Œä½“ç°ç‰¹å®šçš„è¯´è¯é£æ ¼ã€‚
- è®­ç»ƒå¥½çš„æ‰©æ•£æ¨¡å‹æœ‰æ•°ç™¾ä¸ªæ­¥éª¤ï¼Œé€šè¿‡çŸ¥è¯†è’¸é¦å¯ä»¥å°†å…¶è’¸é¦æˆä¸€ä¸ªè½»é‡çº§æ¨¡å‹ï¼Œå…·æœ‰ 8 ä¸ªæ­¥éª¤ï¼ŒåŠ é€Ÿç”Ÿæˆã€‚
- å¹¿æ³›çš„å®éªŒè¡¨æ˜è¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šDiffusionTalkerï¼šè¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´äººè„¸åŠ¨ç”»çš„ä¸ªæ€§åŒ–å’ŒåŠ é€Ÿ</li>
<li>ä½œè€…ï¼šPeng Chenã€Xiaobao Weiã€Ming Luã€Yitong Zhuã€Naiming Yaoã€Xingyu Xiaoã€Hui Chen</li>
<li>å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢è½¯ä»¶ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼šè¯­éŸ³é©±åŠ¨ã€ä¸‰ç»´äººè„¸åŠ¨ç”»ã€æ‰©æ•£æ¨¡å‹ã€ä¸ªæ€§åŒ–ã€åŠ é€Ÿ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.16565
   Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯­éŸ³é©±åŠ¨ä¸‰ç»´äººè„¸åŠ¨ç”»æ˜¯ä¸€é¡¹é‡è¦çš„ä»»åŠ¡ï¼Œå¹¿æ³›åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œè®¡ç®—æœºæ¸¸æˆç­‰é¢†åŸŸã€‚ä¼ ç»Ÿæ–¹æ³•ä¸»è¦é›†ä¸­äºå­¦ä¹ ä»è¯­éŸ³åˆ°åŠ¨ç”»çš„ç¡®å®šæ€§æ˜ å°„ï¼Œä½†æœ€è¿‘çš„æ–¹æ³•å¼€å§‹è€ƒè™‘è¯­éŸ³é©±åŠ¨ä¸‰ç»´äººè„¸åŠ¨ç”»çš„éç¡®å®šæ€§å› ç´ ï¼Œå¹¶é‡‡ç”¨æ‰©æ•£æ¨¡å‹æ¥å®Œæˆä»»åŠ¡ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰çš„æ‰©æ•£æ¨¡å‹æ–¹æ³•åœ¨ä¸ªæ€§åŒ–å’ŒåŠ é€Ÿæ–¹é¢ä»ç„¶å­˜åœ¨å±€é™æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³• DiffusionTalkerï¼Œå®ƒåˆ©ç”¨å¯¹æ¯”å­¦ä¹ æ¥å®ç°ä¸‰ç»´äººè„¸åŠ¨ç”»çš„ä¸ªæ€§åŒ–ï¼Œå¹¶åˆ©ç”¨çŸ¥è¯†è’¸é¦æ¥åŠ é€Ÿä¸‰ç»´åŠ¨ç”»çš„ç”Ÿæˆã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†å®ç°ä¸ªæ€§åŒ–ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªå¯å­¦ä¹ çš„è¯´è¯è€…èº«ä»½æ¥èšåˆéŸ³é¢‘åºåˆ—ä¸­çš„çŸ¥è¯†ã€‚æ‰€æå‡ºçš„èº«ä»½åµŒå…¥ä»¥å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼æå–ä¸åŒäººä¹‹é—´çš„å®šåˆ¶é¢éƒ¨æç¤ºã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œç”¨æˆ·å¯ä»¥æ ¹æ®è¾“å…¥éŸ³é¢‘è·å¾—ä¸ªæ€§åŒ–çš„é¢éƒ¨åŠ¨ç”»ï¼Œåæ˜ ç‰¹å®šçš„è¯´è¯é£æ ¼ã€‚æœ¬æ–‡è¿˜å°†è®­ç»ƒå¥½çš„å…·æœ‰æ•°ç™¾ä¸ªæ­¥éª¤çš„æ‰©æ•£æ¨¡å‹è’¸é¦æˆä¸€ä¸ªå…·æœ‰ 8 ä¸ªæ­¥éª¤çš„è½»é‡çº§æ¨¡å‹ä»¥å®ç°åŠ é€Ÿã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ‰©æ•£æ¨¡å‹ï¼šDDPMs æ˜¯å†…å®¹ç”Ÿæˆçš„å…³é”®å…ƒç´ ï¼Œç”¨äºå­¦ä¹ è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒå¹¶ç”Ÿæˆä¸è¯¥åˆ†å¸ƒç´§å¯†åŒ¹é…çš„å›¾åƒã€‚
ï¼ˆ2ï¼‰ä¸ªæ€§åŒ–é€‚é…å™¨ï¼šæå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„ä¸ªæ€§åŒ–é€‚é…å™¨ï¼Œè¯¥é€‚é…å™¨åŒ…å«ä¸€ä¸ªèº«ä»½åµŒå…¥åº“ï¼Œæ¯ä¸ªåµŒå…¥å¯¹åº”ä¸€ä¸ªéŸ³é¢‘åºåˆ—ã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼ŒæœªçŸ¥çš„è¾“å…¥éŸ³é¢‘å¯ä»¥æ‰¾åˆ°èº«ä»½åµŒå…¥åº“ä¸­ç›¸ä¼¼çš„èº«ä»½åµŒå…¥ï¼Œä»è€Œå®ç°æ¨ç†æœŸé—´è¯´è¯é£æ ¼çš„ä¸ªæ€§åŒ–ã€‚
ï¼ˆ3ï¼‰çŸ¥è¯†è’¸é¦ï¼šä¸ºäº†åŠ é€Ÿæ¨ç†ï¼Œåˆ©ç”¨çŸ¥è¯†è’¸é¦å°†å…·æœ‰ 2n æ­¥çš„æ•™å¸ˆæ¨¡å‹è’¸é¦æˆå…·æœ‰ n æ­¥çš„å­¦ç”Ÿæ¨¡å‹ï¼ŒåŠ é€Ÿè¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»åˆæˆçš„é€Ÿåº¦ã€‚
ï¼ˆ4ï¼‰è®­ç»ƒå’Œæ¨ç†ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªæ—¶é—´æ­¥é•¿ tï¼Œå°†å™ªå£°æ·»åŠ åˆ° x0 ä»¥è·å¾— xtã€‚å°†éŸ³é¢‘-èº«ä»½è®­ç»ƒå¯¹åˆ†åˆ«è¾“å…¥éŸ³é¢‘ç¼–ç å™¨å’Œèº«ä»½ç¼–ç å™¨ä»¥æå–ç‰¹å¾ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå°†ç»™å®šçš„éŸ³é¢‘åºåˆ—è¾“å…¥åˆ°éŸ³é¢‘ç¼–ç å™¨ä¸­ï¼Œç”ŸæˆéŸ³é¢‘ç‰¹å¾ã€‚ç„¶åå°†æ­¤ç‰¹å¾ä¸èº«ä»½åµŒå…¥åº“ä¸­æ‰€æœ‰åµŒå…¥çš„ç‰¹å¾è¿›è¡ŒçŸ©é˜µä¹˜æ³•ã€‚å…·æœ‰æœ€é«˜ç›¸ä¼¼æ€§çš„åµŒå…¥è¢«è¯†åˆ«ä¸ºä¸è¾“å…¥éŸ³é¢‘åºåˆ—åŒ¹é…çš„è¯´è¯èº«ä»½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„è¯­éŸ³é©±åŠ¨ä¸‰ç»´äººè„¸åŠ¨ç”»ä¸ªæ€§åŒ–å’ŒåŠ é€Ÿæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å¯¹æ¯”å­¦ä¹ å®ç°ä¸ªæ€§åŒ–ï¼Œåˆ©ç”¨çŸ¥è¯†è’¸é¦å®ç°åŠ é€Ÿï¼Œåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„ä¸ªæ€§åŒ–é€‚é…å™¨ï¼Œè¯¥é€‚é…å™¨åŒ…å«ä¸€ä¸ªèº«ä»½åµŒå…¥åº“ï¼Œæ¯ä¸ªåµŒå…¥å¯¹åº”ä¸€ä¸ªéŸ³é¢‘åºåˆ—ã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼ŒæœªçŸ¥çš„è¾“å…¥éŸ³é¢‘å¯ä»¥æ‰¾åˆ°èº«ä»½åµŒå…¥åº“ä¸­ç›¸ä¼¼çš„èº«ä»½åµŒå…¥ï¼Œä»è€Œå®ç°æ¨ç†æœŸé—´è¯´è¯é£æ ¼çš„ä¸ªæ€§åŒ–ã€‚</li>
<li>åˆ©ç”¨çŸ¥è¯†è’¸é¦å°†å…·æœ‰2næ­¥çš„æ•™å¸ˆæ¨¡å‹è’¸é¦æˆå…·æœ‰næ­¥çš„å­¦ç”Ÿæ¨¡å‹ï¼ŒåŠ é€Ÿè¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»åˆæˆçš„é€Ÿåº¦ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-42dc6bb5ab80cf7d628dee32e112dd8e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2147d22176df09eea3c7ab6aaf274e54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-293c9b171412db2fee9963cc42c767f0.jpg" align="middle">
</details>




<h2 id="GAIA-Zero-shot-Talking-Avatar-Generation"><a href="#GAIA-Zero-shot-Talking-Avatar-Generation" class="headerlink" title="GAIA: Zero-shot Talking Avatar Generation"></a>GAIA: Zero-shot Talking Avatar Generation</h2><p><strong>Authors:Tianyu He, Junliang Guo, Runyi Yu, Yuchi Wang, Jialiang Zhu, Kaikai An, Leyi Li, Xu Tan, Chunyu Wang, Han Hu, HsiangTao Wu, Sheng Zhao, Jiang Bian</strong></p>
<p>Zero-shot talking avatar generation aims at synthesizing natural talking videos from speech and a single portrait image. Previous methods have relied on domain-specific heuristics such as warping-based motion representation and 3D Morphable Models, which limit the naturalness and diversity of the generated avatars. In this work, we introduce GAIA (Generative AI for Avatar), which eliminates the domain priors in talking avatar generation. In light of the observation that the speech only drives the motion of the avatar while the appearance of the avatar and the background typically remain the same throughout the entire video, we divide our approach into two stages: 1) disentangling each frame into motion and appearance representations; 2) generating motion sequences conditioned on the speech and reference portrait image. We collect a large-scale high-quality talking avatar dataset and train the model on it with different scales (up to 2B parameters). Experimental results verify the superiority, scalability, and flexibility of GAIA as 1) the resulting model beats previous baseline models in terms of naturalness, diversity, lip-sync quality, and visual quality; 2) the framework is scalable since larger models yield better results; 3) it is general and enables different applications like controllable talking avatar generation and text-instructed avatar generation. </p>
<p><a href="http://arxiv.org/abs/2311.15230v1">PDF</a> Project page: <a href="https://microsoft.github.io/GAIA/">https://microsoft.github.io/GAIA/</a></p>
<p><strong>Summary</strong><br>ç§»é™¤è°ˆè¯å¤´åƒç”Ÿæˆä¸­çš„é¢†åŸŸå…ˆéªŒï¼Œåˆ©ç”¨è¯­è¨€æ¨¡å‹æ§åˆ¶åŠ¨ä½œï¼Œç¥ç»ç½‘ç»œç”Ÿæˆå¤–è§‚ï¼Œè¿›è¡Œåˆ†ç¦»ç¼–ç å®ç°å¯æ§è°ˆè¯å¤´åƒç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GAIA æ— éœ€ç‰¹å®šé¢†åŸŸçŸ¥è¯†ï¼Œæ‘†è„±é¢†åŸŸå…ˆéªŒçš„é™åˆ¶ï¼Œåˆ©ç”¨è¯­è¨€æ¨¡å‹æ§åˆ¶åŠ¨ä½œï¼Œç¥ç»ç½‘ç»œç”Ÿæˆå¤–è§‚ã€‚</li>
<li>GAIA å°†ä»»åŠ¡åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šåˆ†ç¦»ç¼–ç ä¸è¿åŠ¨åºåˆ—ç”Ÿæˆã€‚</li>
<li>GAIA çš„æ•°æ®é›†åŒ…å« 168 ä¸‡å¼ å›¾ç‰‡ï¼Œåˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚</li>
<li>GAIA å¯æ‰©å±•ï¼Œæ¨¡å‹å‚æ•°ä» 128M åˆ° 2B ä¸ç­‰ï¼Œæ¨¡å‹è¶Šå¤§æ•ˆæœè¶Šå¥½ã€‚</li>
<li>GAIA å…·æœ‰é€šç”¨æ€§ï¼Œå¯ç”¨äºå¯æ§è°ˆè¯å¤´åƒç”Ÿæˆå’Œæ–‡æœ¬æŒ‡ç¤ºå¤´åƒç”Ÿæˆç­‰åº”ç”¨ã€‚</li>
<li>GAIA åœ¨ä¸‰ä¸ªè¯„ä»·æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚</li>
<li>GAIA èƒ½æœ‰æ•ˆç”Ÿæˆè‡ªç„¶ã€å¤šæ ·ã€å”‡å½¢åŒæ­¥ä¸”è§†è§‰è´¨é‡é«˜çš„è°ˆè¯å¤´åƒè§†é¢‘ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šGAIAï¼šé›¶æ ·æœ¬è¯´è¯å¤´åƒç”Ÿæˆ</li>
<li>ä½œè€…ï¼šTianyu Heã€Junliang Guoã€Runyi Yuã€Yuchi Wangã€Jialiang Zhuã€Kaikai Anã€Leyi Liã€Xu Tanã€Chunyu Wangã€Han Huã€Hsiang Tao Wuã€Sheng Zhaoã€Jiang Bian</li>
<li>éš¶å±å•ä½ï¼šå¾®è½¯</li>
<li>å…³é”®è¯ï¼šé›¶æ ·æœ¬è¯´è¯å¤´åƒç”Ÿæˆã€è¿åŠ¨è¡¨ç¤ºã€å¤–è§‚è¡¨ç¤ºã€ç”Ÿæˆæ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.15230</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯å¤´åƒç”Ÿæˆæ—¨åœ¨ä»è¯­éŸ³å’Œå•å¼ äººåƒå›¾åƒä¸­åˆæˆè‡ªç„¶è¯´è¯è§†é¢‘ã€‚ä»¥å¾€æ–¹æ³•ä¾èµ–äºç‰¹å®šé¢†åŸŸçš„å¯å‘å¼æ–¹æ³•ï¼Œä¾‹å¦‚åŸºäºæ‰­æ›²çš„è¿åŠ¨è¡¨ç¤ºå’Œ 3D å¯å˜å½¢æ¨¡å‹ï¼Œè¿™é™åˆ¶äº†ç”Ÿæˆçš„å¤´åƒçš„è‡ªç„¶æ€§å’Œå¤šæ ·æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€æ–¹æ³•é€šè¿‡å¯¹æ¯ä¸ªå¤´åƒè¿›è¡Œç‰¹å®šè®­ç»ƒï¼ˆå³ä¸ºæ¯ä¸ªå¤´åƒè®­ç»ƒæˆ–è°ƒæ•´ç‰¹å®šæ¨¡å‹ï¼‰æˆ–åœ¨æ¨ç†æœŸé—´åˆ©ç”¨æ¨¡æ¿è§†é¢‘æ¥å®ç°é«˜è´¨é‡çš„ç»“æœã€‚ä½†æ˜¯ï¼Œè¿™äº›æ–¹æ³•é€šè¿‡å¼•å…¥åŸºäºæ‰­æ›²çš„è¿åŠ¨è¡¨ç¤ºã€3D å¯å˜å½¢æ¨¡å‹ç­‰é¢†åŸŸå…ˆéªŒæ¥é™ä½ä»»åŠ¡çš„éš¾åº¦ã€‚è™½ç„¶æœ‰æ•ˆï¼Œä½†å¼•å…¥æ­¤ç±»å¯å‘å¼æ–¹æ³•é˜»ç¢äº†ç›´æ¥ä»æ•°æ®åˆ†å¸ƒä¸­å­¦ä¹ ï¼Œå¹¶å¯èƒ½å¯¼è‡´ä¸è‡ªç„¶çš„ç»“æœå’Œæœ‰é™çš„å¤šæ ·æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º GAIAï¼ˆç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¤´åƒï¼‰ï¼Œæ¶ˆé™¤äº†è¯´è¯å¤´åƒç”Ÿæˆä¸­çš„é¢†åŸŸå…ˆéªŒã€‚GAIA æ­ç¤ºäº†ä¸¤ä¸ªå…³é”®è§è§£ï¼š1ï¼‰è¯­éŸ³åªé©±åŠ¨å¤´åƒçš„è¿åŠ¨ï¼Œè€ŒèƒŒæ™¯å’Œå¤´åƒçš„å¤–è§‚é€šå¸¸åœ¨æ•´ä¸ªè§†é¢‘ä¸­ä¿æŒä¸å˜ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬å¯¹æ¯å¸§è¿›è¡Œè¿åŠ¨å’Œå¤–è§‚è¡¨ç¤ºçš„è§£è€¦ï¼Œå…¶ä¸­å¤–è§‚åœ¨å¸§ä¹‹é—´å…±äº«ï¼Œè€Œè¿åŠ¨å¯¹äºæ¯å¸§éƒ½æ˜¯å”¯ä¸€çš„ã€‚ä¸ºäº†ä»è¯­éŸ³é¢„æµ‹è¿åŠ¨ï¼Œæˆ‘ä»¬å°†è¿åŠ¨åºåˆ—ç¼–ç æˆè¿åŠ¨æ½œåœ¨åºåˆ—ï¼Œå¹¶å°†å¤–è§‚ç¼–ç æˆå¤–è§‚æ½œåœ¨è¡¨ç¤ºã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ç”Ÿæˆæ¨¡å‹ä»è¯­éŸ³å’Œå‚è€ƒäººåƒå›¾åƒç”Ÿæˆè¿åŠ¨åºåˆ—ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªå¤§è§„æ¨¡é«˜è´¨é‡çš„è¯´è¯å¤´åƒæ•°æ®é›†ï¼Œå¹¶åœ¨ä¸åŒè§„æ¨¡ï¼ˆé«˜è¾¾ 2B å‚æ•°ï¼‰ä¸Šè®­ç»ƒæ¨¡å‹ã€‚å®éªŒç»“æœéªŒè¯äº† GAIA çš„ä¼˜è¶Šæ€§ã€å¯æ‰©å±•æ€§å’Œçµæ´»æ€§ï¼Œå› ä¸ºå®ƒ 1ï¼‰åœ¨è‡ªç„¶æ€§ã€å¤šæ ·æ€§ã€å”‡å½¢åŒæ­¥è´¨é‡å’Œè§†è§‰è´¨é‡æ–¹é¢ä¼˜äºä¹‹å‰çš„åŸºçº¿æ¨¡å‹ï¼›2ï¼‰ç”±äºæ›´å¤§çš„æ¨¡å‹ä¼šäº§ç”Ÿæ›´å¥½çš„ç»“æœï¼Œå› æ­¤è¯¥æ¡†æ¶æ˜¯å¯æ‰©å±•çš„ï¼›3ï¼‰å®ƒæ˜¯é€šç”¨çš„ï¼Œå¹¶æ”¯æŒä¸åŒçš„åº”ç”¨ç¨‹åºï¼Œä¾‹å¦‚å¯æ§è¯´è¯å¤´åƒç”Ÿæˆå’Œæ–‡æœ¬æŒ‡å¯¼çš„å¤´åƒç”Ÿæˆã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) è¿åŠ¨ä¸å¤–è§‚è¡¨ç¤ºè§£è€¦ï¼šå°†æ¯å¸§è§£è€¦ä¸ºè¿åŠ¨è¡¨ç¤ºå’Œå¤–è§‚è¡¨ç¤ºï¼Œå…¶ä¸­å¤–è§‚åœ¨å¸§ä¹‹é—´å…±äº«ï¼Œè€Œè¿åŠ¨å¯¹äºæ¯å¸§éƒ½æ˜¯å”¯ä¸€çš„ã€‚
(2) è¿åŠ¨åºåˆ—ç¼–ç ï¼šå°†è¿åŠ¨åºåˆ—ç¼–ç æˆè¿åŠ¨æ½œåœ¨åºåˆ—ï¼Œå¹¶å°†å¤–è§‚ç¼–ç æˆå¤–è§‚æ½œåœ¨è¡¨ç¤ºã€‚
(3) è¿åŠ¨åºåˆ—ç”Ÿæˆï¼šä½¿ç”¨ç”Ÿæˆæ¨¡å‹ä»è¯­éŸ³å’Œå‚è€ƒäººåƒå›¾åƒç”Ÿæˆè¿åŠ¨åºåˆ—ã€‚
(4) å¯æ§è¯´è¯å¤´åƒç”Ÿæˆï¼šé€šè¿‡æ›¿æ¢ä¼°è®¡çš„å¤´å§¿åŠ¿æˆ–ä»å¦ä¸€ä¸ªè§†é¢‘ä¸­æå–çš„å¤´å§¿åŠ¿ï¼Œå®ç°å§¿åŠ¿å¯æ§çš„è¯´è¯å¤´åƒç”Ÿæˆã€‚
(5) å…¨å¯æ§è¯´è¯å¤´åƒç”Ÿæˆï¼šé€šè¿‡ç¼–è¾‘ç”Ÿæˆè¿‡ç¨‹ä¸­çš„é¢éƒ¨åœ°æ ‡ï¼Œå®ç°ä»»æ„é¢éƒ¨å±æ€§çš„å¯æ§ç”Ÿæˆã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ•°æ®é©±åŠ¨çš„é›¶æ ·æœ¬è¯´è¯å¤´åƒç”Ÿæˆæ¡†æ¶ GAIAï¼Œè¯¥æ¡†æ¶ç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼šä¸€ä¸ªå˜åˆ†è‡ªåŠ¨ç¼–ç å™¨ï¼Œç”¨äºè§£è€¦å’Œç¼–ç è¿åŠ¨å’Œå¤–è§‚è¡¨ç¤ºï¼Œä»¥åŠä¸€ä¸ªæ‰©æ•£æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹è¿åŠ¨æ½œåœ¨åºåˆ—ï¼Œè¯¥åºåˆ—ä»¥è¾“å…¥è¯­éŸ³ä¸ºæ¡ä»¶ã€‚æˆ‘ä»¬æ”¶é›†äº†ä¸€ä¸ªå¤§è§„æ¨¡çš„æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†å‡ ç§è¿‡æ»¤ç­–ç•¥ï¼Œä»¥å®ç°æ¡†æ¶çš„æœ‰æ•ˆè®­ç»ƒã€‚GAIA æ¡†æ¶å…·æœ‰é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ï¼Œèƒ½å¤Ÿåœ¨é›¶æ ·æœ¬è¯´è¯å¤´åƒç”Ÿæˆä¸­æä¾›è‡ªç„¶å’Œå¤šæ ·åŒ–çš„ç»“æœï¼Œå¹¶ä¸”å¯ä»¥çµæ´»åœ°é€‚åº”å…¶ä»–åº”ç”¨ç¨‹åºï¼ŒåŒ…æ‹¬å¯æ§è¯´è¯å¤´åƒç”Ÿæˆå’Œæ–‡æœ¬æŒ‡å¯¼çš„å¤´åƒç”Ÿæˆã€‚
æ€§èƒ½ï¼šåœ¨è‡ªç„¶æ€§ã€å¤šæ ·æ€§ã€å”‡å½¢åŒæ­¥è´¨é‡å’Œè§†è§‰è´¨é‡æ–¹é¢ä¼˜äºä¹‹å‰çš„åŸºçº¿æ¨¡å‹ï¼›ç”±äºæ›´å¤§çš„æ¨¡å‹ä¼šäº§ç”Ÿæ›´å¥½çš„ç»“æœï¼Œå› æ­¤è¯¥æ¡†æ¶æ˜¯å¯æ‰©å±•çš„ï¼›
å·¥ä½œé‡ï¼šæ”¶é›†äº†ä¸€ä¸ªå¤§è§„æ¨¡é«˜è´¨é‡çš„è¯´è¯å¤´åƒæ•°æ®é›†ï¼Œå¹¶åœ¨ä¸åŒè§„æ¨¡ï¼ˆé«˜è¾¾2Bå‚æ•°ï¼‰ä¸Šè®­ç»ƒæ¨¡å‹ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b24792b81d1876d37fc788a87d3177d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5607b67a73e71b9a00d408089c575ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-55a4dfdd281f456c1ec180ddf006ff6d.jpg" align="middle">
</details>




<h2 id="ChatAnything-Facetime-Chat-with-LLM-Enhanced-Personas"><a href="#ChatAnything-Facetime-Chat-with-LLM-Enhanced-Personas" class="headerlink" title="ChatAnything: Facetime Chat with LLM-Enhanced Personas"></a>ChatAnything: Facetime Chat with LLM-Enhanced Personas</h2><p><strong>Authors:Yilin Zhao, Xinbin Yuan, Shanghua Gao, Zhijie Lin, Qibin Hou, Jiashi Feng, Daquan Zhou</strong></p>
<p>In this technical report, we target generating anthropomorphized personas for LLM-based characters in an online manner, including visual appearance, personality and tones, with only text descriptions. To achieve this, we first leverage the in-context learning capability of LLMs for personality generation by carefully designing a set of system prompts. We then propose two novel concepts: the mixture of voices (MoV) and the mixture of diffusers (MoD) for diverse voice and appearance generation. For MoV, we utilize the text-to-speech (TTS) algorithms with a variety of pre-defined tones and select the most matching one based on the user-provided text description automatically. For MoD, we combine the recent popular text-to-image generation techniques and talking head algorithms to streamline the process of generating talking objects. We termed the whole framework as ChatAnything. With it, users could be able to animate anything with any personas that are anthropomorphic using just a few text inputs. However, we have observed that the anthropomorphic objects produced by current generative models are often undetectable by pre-trained face landmark detectors, leading to failure of the face motion generation, even if these faces possess human-like appearances because those images are nearly seen during the training (e.g., OOD samples). To address this issue, we incorporate pixel-level guidance to infuse human face landmarks during the image generation phase. To benchmark these metrics, we have built an evaluation dataset. Based on it, we verify that the detection rate of the face landmark is significantly increased from 57.0% to 92.5% thus allowing automatic face animation based on generated speech content. The code and more results can be found at <a href="https://chatanything.github.io/">https://chatanything.github.io/</a>. </p>
<p><a href="http://arxiv.org/abs/2311.06772v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong></p>
<p>åˆ©ç”¨è¯­è¨€ç”Ÿæˆæ¨¡å‹å®ç°ä»»æ„æ–‡æœ¬åˆ›å»ºæ‹ŸäººåŒ–å½¢è±¡ï¼ŒåŒ…æ‹¬å›¾åƒã€è¯­æ°”å’Œæ€§æ ¼ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>åˆ©ç”¨è¯­è¨€ç”Ÿæˆæ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›å’Œç²¾å¿ƒè®¾è®¡çš„ç³»ç»Ÿæç¤ºï¼Œç”Ÿæˆäººç‰©ä¸ªæ€§ã€‚</li>
</ul>
<ul>
<li>æå‡ºä¸¤ç§æ–°é¢–æ¦‚å¿µï¼šæ··åˆå£°éŸ³ (MoV) å’Œæ··åˆæ‰©æ•£å™¨ (MoD)ï¼Œç”¨äºç”Ÿæˆå¤šæ ·åŒ–çš„å£°éŸ³å’Œå›¾åƒã€‚</li>
</ul>
<ul>
<li>MoV åˆ©ç”¨æ–‡æœ¬è½¬è¯­éŸ³ (TTS) ç®—æ³•å’Œå„ç§é¢„å®šä¹‰è¯­è°ƒï¼Œæ ¹æ®ç”¨æˆ·æä¾›çš„æ–‡æœ¬æè¿°è‡ªåŠ¨é€‰æ‹©æœ€åŒ¹é…çš„è¯­è°ƒã€‚</li>
</ul>
<ul>
<li>MoD å°†æµè¡Œçš„æ–‡æœ¬è½¬å›¾åƒç”ŸæˆæŠ€æœ¯å’Œè¯´è¯å¤´ç®—æ³•ç›¸ç»“åˆï¼Œç®€åŒ–ç”Ÿæˆè¯´è¯å¯¹è±¡çš„æµç¨‹ã€‚</li>
</ul>
<ul>
<li>ChatAnything æ¡†æ¶å…è®¸ç”¨æˆ·ä½¿ç”¨å°‘é‡æ–‡æœ¬è¾“å…¥æ¥ç”Ÿæˆå…·æœ‰æ‹ŸäººåŒ–å½¢è±¡çš„åŠ¨ç”»ã€‚</li>
</ul>
<ul>
<li>å‘ç°å½“å‰ç”Ÿæˆæ¨¡å‹ç”Ÿæˆçš„æ‹ŸäººåŒ–å¯¹è±¡é€šå¸¸æ— æ³•è¢«é¢„è®­ç»ƒå¥½çš„é¢éƒ¨ç‰¹å¾æ£€æµ‹å™¨æ£€æµ‹åˆ°ï¼Œå¯¼è‡´é¢éƒ¨è¿åŠ¨ç”Ÿæˆå¤±è´¥ï¼Œå³ä½¿è¿™äº›é¢å­”å…·æœ‰ç±»ä¼¼äººç±»çš„å¤–è§‚ã€‚</li>
</ul>
<ul>
<li>é€šè¿‡åœ¨å›¾åƒç”Ÿæˆé˜¶æ®µåŠ å…¥åƒç´ çº§æŒ‡å¯¼ï¼Œä½¿ç”Ÿæˆçš„å›¾åƒåŒ…å«äººç±»é¢éƒ¨æ ‡å¿—ï¼Œä»è€Œè§£å†³è¿™ä¸ªé—®é¢˜ã€‚</li>
</ul>
<ul>
<li>å»ºç«‹è¯„ä¼°æ•°æ®é›†ï¼ŒéªŒè¯é¢éƒ¨æ ‡å¿—æ£€æµ‹ç‡ä» 57.0% æ˜¾ç€æé«˜åˆ° 92.5%ï¼Œä»è€Œå…è®¸è‡ªåŠ¨ç”Ÿæˆè¯­éŸ³å†…å®¹çš„åŠ¨ç”»ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šChatAnythingï¼šåŸºäº LLM çš„è§’è‰²çš„äººæ ¼åŒ–</li>
<li>ä½œè€…ï¼šSilin Zhao, Xinbin Yuan, Shanghua Gao, Zhijie Lin, Qibin Hou, Jiashi Feng, Daquan Zhou</li>
<li>éš¶å±å•ä½ï¼šå—å¼€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè‡ªç„¶è¯­è¨€å¤„ç†ã€ç”Ÿæˆå¼ AIã€å¯¹è¯ç³»ç»Ÿã€äººæœºäº¤äº’</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.06772
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/chatanything/chatanything</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šéšç€å¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å¿«é€Ÿå‘å±•ï¼Œå…¶å¼ºå¤§çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›å’Œç”Ÿæˆèƒ½åŠ›å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚æœ¬æ–‡æ—¨åœ¨æ¢ç´¢ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ ¹æ®æ–‡æœ¬æè¿°è‡ªåŠ¨ç”Ÿæˆå…·æœ‰å®šåˆ¶åŒ–ä¸ªæ€§ã€å£°éŸ³å’Œè§†è§‰å¤–è§‚çš„ LLM å¢å¼ºè§’è‰²ã€‚
(2)ï¼šä»¥å¾€çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ LLM çš„ä¸ªæ€§åŒ–ç”Ÿæˆä¸Šï¼Œä½†å¯¹äºå£°éŸ³å’Œè§†è§‰å¤–è§‚çš„ç”Ÿæˆåˆ™ç›¸å¯¹è¾ƒå°‘ã€‚åŒæ—¶ï¼Œç°æœ‰æ–¹æ³•ç”Ÿæˆçš„æ‹ŸäººåŒ–å¯¹è±¡é€šå¸¸æ— æ³•è¢«é¢„è®­ç»ƒçš„äººè„¸å…³é”®ç‚¹æ£€æµ‹å™¨æ£€æµ‹åˆ°ï¼Œå¯¼è‡´æ— æ³•è¿›è¡Œé¢éƒ¨åŠ¨ä½œç”Ÿæˆã€‚
(3)ï¼šæœ¬æ–‡æå‡ºçš„ ChatAnything æ¡†æ¶é€šè¿‡ç²¾å¿ƒè®¾è®¡ç³»ç»Ÿæç¤ºï¼Œåˆ©ç”¨ LLM çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›æ¥ç”Ÿæˆå®šåˆ¶åŒ–çš„è§’è‰²ä¸ªæ€§ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸¤ç§æ–°é¢–çš„æ¦‚å¿µï¼šå£°éŸ³æ··åˆ (MoV) å’Œæ‰©æ•£å™¨æ··åˆ (MoD)ï¼Œç”¨äºç”Ÿæˆå¤šæ ·åŒ–çš„å£°éŸ³å’Œå¤–è§‚ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§åƒç´ çº§å¼•å¯¼çš„æ–¹æ³•ï¼Œä»¥åœ¨å›¾åƒç”Ÿæˆé˜¶æ®µæ³¨å…¥äººè„¸å…³é”®ç‚¹ï¼Œä»è€Œæé«˜é¢éƒ¨å…³é”®ç‚¹çš„æ£€æµ‹ç‡ã€‚
(4)ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒChatAnything æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°ç”Ÿæˆå…·æœ‰å®šåˆ¶åŒ–ä¸ªæ€§ã€å£°éŸ³å’Œè§†è§‰å¤–è§‚çš„ LLM å¢å¼ºè§’è‰²ã€‚åŒæ—¶ï¼Œæœ¬æ–‡æå‡ºçš„åƒç´ çº§å¼•å¯¼æ–¹æ³•ä¹Ÿæ˜¾è‘—æé«˜äº†é¢éƒ¨å…³é”®ç‚¹çš„æ£€æµ‹ç‡ï¼Œä»è€Œæ”¯æŒè‡ªåŠ¨é¢éƒ¨åŠ¨ç”»ç”Ÿæˆã€‚</li>
</ol>
<p>Methods:</p>
<p>(1) The ChatAnything framework consists of four main blocks: an LLM-based control module, a portrait initializer, a mixture of text-to-speech modules, and a motion generation module.</p>
<p>(2) The portrait initializer uses a mixture of fine-tuned diffusion models (MoD) along with their LoRA module to generate a reference image for the persona.</p>
<p>(3) The mixture of text-to-speech modules (MoV) converts the text input from the persona to speech signals with customized tones.</p>
<p>(4) The motion generation module takes in the speech signal and drives the generated image.</p>
<p>(5) To inject facial landmark guidance, the framework uses a guided diffusion process with a fixed Markov Gaussian diffusion process.</p>
<p>(6) The framework also utilizes a ControlNet to inject the face feature in the process of image generation.</p>
<p>(7) A pool of stylized diffusion-based generative models and voice changers are used to customize the artistic style and voice of the generated persona.</p>
<p>(8) The framework uses a prompt template to generate the personality of the persona based on the user's input.</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šChatAnything æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°ç”Ÿæˆå…·æœ‰å®šåˆ¶åŒ–ä¸ªæ€§ã€å£°éŸ³å’Œè§†è§‰å¤–è§‚çš„ LLM å¢å¼ºè§’è‰²ã€‚åŒæ—¶ï¼Œæœ¬æ–‡æå‡ºçš„åƒç´ çº§å¼•å¯¼æ–¹æ³•ä¹Ÿæ˜¾è‘—æé«˜äº†é¢éƒ¨å…³é”®ç‚¹çš„æ£€æµ‹ç‡ï¼Œä»è€Œæ”¯æŒè‡ªåŠ¨é¢éƒ¨åŠ¨ç”»ç”Ÿæˆã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ ChatAnythingï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ ¹æ®æ–‡æœ¬æè¿°è‡ªåŠ¨ç”Ÿæˆå…·æœ‰å®šåˆ¶åŒ–ä¸ªæ€§ã€å£°éŸ³å’Œè§†è§‰å¤–è§‚çš„ LLM å¢å¼ºè§’è‰²ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ¦‚å¿µï¼šå£°éŸ³æ··åˆ (MoV)ï¼Œç”¨äºç”Ÿæˆå¤šæ ·åŒ–çš„å£°éŸ³ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ¦‚å¿µï¼šæ‰©æ•£å™¨æ··åˆ (MoD)ï¼Œç”¨äºç”Ÿæˆå¤šæ ·åŒ–çš„å¤–è§‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åƒç´ çº§å¼•å¯¼çš„æ–¹æ³•ï¼Œä»¥åœ¨å›¾åƒç”Ÿæˆé˜¶æ®µæ³¨å…¥äººè„¸å…³é”®ç‚¹ï¼Œä»è€Œæé«˜é¢éƒ¨å…³é”®ç‚¹çš„æ£€æµ‹ç‡ã€‚
æ€§èƒ½ï¼š</li>
<li>ChatAnything æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°ç”Ÿæˆå…·æœ‰å®šåˆ¶åŒ–ä¸ªæ€§ã€å£°éŸ³å’Œè§†è§‰å¤–è§‚çš„ LLM å¢å¼ºè§’è‰²ã€‚</li>
<li>ChatAnything æ¡†æ¶èƒ½å¤Ÿæ˜¾è‘—æé«˜é¢éƒ¨å…³é”®ç‚¹çš„æ£€æµ‹ç‡ï¼Œä»è€Œæ”¯æŒè‡ªåŠ¨é¢éƒ¨åŠ¨ç”»ç”Ÿæˆã€‚
å·¥ä½œé‡ï¼š</li>
<li>ChatAnything æ¡†æ¶çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„æŠ€æœ¯æ°´å¹³ã€‚</li>
<li>ChatAnything æ¡†æ¶çš„è®­ç»ƒéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-494f70b2c5eac2c09270dc86936da0f3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ecb9537a4b6bea4a888b9a98aa5f5584.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-afea263951ed31808a8df79048c30a2c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d9d4f86301d8d00bbb0d78ff4e1a1f89.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b4fd05a1ef19cd93425962ed04f16227.jpg" align="middle">
</details>




<h2 id="DualTalker-A-Cross-Modal-Dual-Learning-Approach-for-Speech-Driven-3D-Facial-Animation"><a href="#DualTalker-A-Cross-Modal-Dual-Learning-Approach-for-Speech-Driven-3D-Facial-Animation" class="headerlink" title="DualTalker: A Cross-Modal Dual Learning Approach for Speech-Driven 3D   Facial Animation"></a>DualTalker: A Cross-Modal Dual Learning Approach for Speech-Driven 3D   Facial Animation</h2><p><strong>Authors:Guinan Su, Yanwu Yang, Zhifeng Li</strong></p>
<p>In recent years, audio-driven 3D facial animation has gained significant attention, particularly in applications such as virtual reality, gaming, and video conferencing. However, accurately modeling the intricate and subtle dynamics of facial expressions remains a challenge. Most existing studies approach the facial animation task as a single regression problem, which often fail to capture the intrinsic inter-modal relationship between speech signals and 3D facial animation and overlook their inherent consistency. Moreover, due to the limited availability of 3D-audio-visual datasets, approaches learning with small-size samples have poor generalizability that decreases the performance. To address these issues, in this study, we propose a cross-modal dual-learning framework, termed DualTalker, aiming at improving data usage efficiency as well as relating cross-modal dependencies. The framework is trained jointly with the primary task (audio-driven facial animation) and its dual task (lip reading) and shares common audio/motion encoder components. Our joint training framework facilitates more efficient data usage by leveraging information from both tasks and explicitly capitalizing on the complementary relationship between facial motion and audio to improve performance. Furthermore, we introduce an auxiliary cross-modal consistency loss to mitigate the potential over-smoothing underlying the cross-modal complementary representations, enhancing the mapping of subtle facial expression dynamics. Through extensive experiments and a perceptual user study conducted on the VOCA and BIWI datasets, we demonstrate that our approach outperforms current state-of-the-art methods both qualitatively and quantitatively. We have made our code and video demonstrations available at <a href="https://github.com/sabrina-su/iadf.git">https://github.com/sabrina-su/iadf.git</a>. </p>
<p><a href="http://arxiv.org/abs/2311.04766v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>éŸ³é¢‘é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»æ¡†æ¶DualTalkerï¼Œä»¥éŸ³é¢‘ä¸ºé©±åŠ¨ï¼Œå¯¹3Dé¢éƒ¨è¿›è¡ŒåŠ¨ç”»ï¼Œå­¦ä¹ é¢éƒ¨è¿åŠ¨ä¸éŸ³é¢‘ä¹‹é—´çš„äº’è¡¥å…³ç³»ï¼Œæé«˜æ•°æ®åˆ©ç”¨ç‡ï¼Œç”Ÿæˆé€¼çœŸçš„é¢éƒ¨è¡¨æƒ…ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºéŸ³é¢‘é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»æ¡†æ¶DualTalkerï¼Œæé«˜æ•°æ®åˆ©ç”¨ç‡ï¼Œç”Ÿæˆæ›´ä¸ºé€¼çœŸçš„é¢éƒ¨è¡¨æƒ…ã€‚</li>
<li>DualTalkerç”±éŸ³é¢‘-è¿åŠ¨ç¼–ç å™¨ç»„æˆï¼Œè®­ç»ƒä¸»è¦ä»»åŠ¡ï¼ˆéŸ³é¢‘é©±åŠ¨é¢éƒ¨åŠ¨ç”»ï¼‰åŠå…¶åŒé‡ä»»åŠ¡ï¼ˆå”‡è¯»ï¼‰ã€‚</li>
<li>è”åˆè®­ç»ƒä¿ƒè¿›ä¿¡æ¯å…±äº«ï¼Œæé«˜æ€§èƒ½ï¼Œè¾…åŠ©è·¨æ¨¡æ€ä¸€è‡´æ€§æŸå¤±å‡è½»è¿‡åº¦å¹³æ»‘ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒDualTalkeråœ¨VOCAå’ŒBIWIæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>ä»£ç å’Œè§†é¢‘æ¼”ç¤ºå¯åœ¨<a href="https://github.com/sabrina-su/iadf.gitä¸Šè·å–ã€‚">https://github.com/sabrina-su/iadf.gitä¸Šè·å–ã€‚</a></li>
<li>æˆ‘ä»¬çš„æ–¹æ³•æé«˜äº†é¢éƒ¨åŠ¨ç”»çš„è´¨é‡ï¼Œå¹¶ä½¿éŸ³é¢‘-è§†è§‰åŒæ­¥æ›´åŠ è‡ªç„¶ã€‚</li>
<li>DualTalkerå®ç°äº†è·¨æ¨¡æ€åŒå­¦ä¹ ï¼Œå…·æœ‰è‰¯å¥½çš„æ•°æ®åˆ©ç”¨æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŒè¯­è€…ï¼šä¸€ç§ç”¨äºè¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»çš„è·¨æ¨¡æ€åŒé‡å­¦ä¹ æ–¹æ³•</li>
<li>ä½œè€…ï¼šé¡¾å—è‹ï¼Œæ¨ç‚æ­¦ï¼Œæå¿—é”‹</li>
<li>å•ä½ï¼šè…¾è®¯æ•°æ®å¹³å°</li>
<li>å…³é”®è¯ï¼šåŒé‡å­¦ä¹ ã€è¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€è·¨æ¨¡æ€ä¸€è‡´æ€§ã€Transformer</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.04766
    Github é“¾æ¥ï¼šhttps://github.com/Guinan-Su/DualTalker</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šè¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»æŠ€æœ¯è¿‘å¹´æ¥å¤‡å—å…³æ³¨ï¼Œä½†å‡†ç¡®å»ºæ¨¡é¢éƒ¨è¡¨æƒ…çš„å¤æ‚åŠ¨æ€ä»æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚
(2)ï¼šç°æœ‰æ–¹æ³•é€šå¸¸å°†é¢éƒ¨åŠ¨ç”»ä»»åŠ¡è§†ä¸ºå•ä¸€å›å½’é—®é¢˜ï¼Œå¿½ç•¥äº†è¯­éŸ³ä¿¡å·å’Œä¸‰ç»´é¢éƒ¨åŠ¨ç”»ä¹‹é—´çš„å†…åœ¨è·¨æ¨¡æ€å…³ç³»åŠå…¶å›ºæœ‰çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œç”±äºä¸‰ç»´éŸ³é¢‘è§†è§‰æ•°æ®é›†çš„æœ‰é™å¯ç”¨æ€§ï¼Œä½¿ç”¨å°æ ·æœ¬å­¦ä¹ çš„æ–¹æ³•å…·æœ‰è¾ƒå·®çš„æ³›åŒ–èƒ½åŠ›ï¼Œé™ä½äº†æ€§èƒ½ã€‚
(3)ï¼šæå‡ºäº†ä¸€ç§è·¨æ¨¡æ€åŒé‡å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æé«˜æ•°æ®åˆ©ç”¨æ•ˆç‡ï¼Œå¹¶å…³è”è·¨æ¨¡æ€ä¾èµ–å…³ç³»ä»¥è¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚è¯¥æ¡†æ¶ä¸ä¸»ä»»åŠ¡ï¼ˆè¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ï¼‰åŠå…¶åŒé‡ä»»åŠ¡ï¼ˆå”‡è¯»ï¼‰è”åˆè®­ç»ƒï¼Œå¹¶å…±äº«å…±åŒçš„éŸ³é¢‘/è¿åŠ¨ç¼–ç å™¨ç»„ä»¶ã€‚
(4)ï¼šåœ¨ VOCA å’Œ BIWI æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒå’Œæ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡ä¸Šéƒ½ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§è·¨æ¨¡æ€åŒé‡å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»ã€‚è¯¥æ¡†æ¶ç”±ä¸»ä»»åŠ¡ï¼ˆè¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ï¼‰åŠå…¶åŒé‡ä»»åŠ¡ï¼ˆå”‡è¯»ï¼‰ç»„æˆï¼Œå¹¶å…±äº«å…±åŒçš„éŸ³é¢‘/è¿åŠ¨ç¼–ç å™¨ç»„ä»¶ã€‚
ï¼ˆ2ï¼‰åœ¨è¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ä»»åŠ¡ä¸­ï¼Œé‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ï¼Œå…¶ä¸­ç¼–ç å™¨å°†è¯­éŸ³ä¿¡å·è½¬æ¢ä¸ºè¯­éŸ³è¡¨ç¤ºï¼Œè§£ç å™¨åˆ©ç”¨è¯­éŸ³è¡¨ç¤ºå’Œè¿‡å»çš„è¿åŠ¨åºåˆ—æ¥é¢„æµ‹é¢éƒ¨è¿åŠ¨ã€‚
ï¼ˆ3ï¼‰åœ¨å”‡è¯»ä»»åŠ¡ä¸­ï¼ŒåŒæ ·é‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ï¼Œå…¶ä¸­ç¼–ç å™¨å°†é¢éƒ¨è¿åŠ¨è½¬æ¢ä¸ºè¿åŠ¨è¡¨ç¤ºï¼Œè§£ç å™¨åˆ©ç”¨è¿åŠ¨è¡¨ç¤ºå’Œè¿‡å»çš„è¯­éŸ³ç‰¹å¾æ¥é¢„æµ‹è¯­éŸ³ç‰¹å¾ã€‚
ï¼ˆ4ï¼‰ä¸ºäº†å®ç°è¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»å’Œå”‡è¯»çš„äº’è¡¥æ€§ï¼Œæå‡ºäº†ä¸€ç§å¯¹å¶æ­£åˆ™åŒ–æŸå¤±ï¼Œè¯¥æŸå¤±å‡½æ•°é¼“åŠ±è¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»å’Œå”‡è¯»çš„é¢„æµ‹ç»“æœåœ¨è·¨æ¨¡æ€ç‰¹å¾ç©ºé—´ä¸­ä¿æŒä¸€è‡´ã€‚
ï¼ˆ5ï¼‰åœ¨VOCAå’ŒBIWIæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒå’Œæ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡ä¸Šéƒ½ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§è·¨æ¨¡æ€åŒé‡å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†è¯­éŸ³é©±åŠ¨é¢éƒ¨åŠ¨ç”»ä¸­å›ºæœ‰çš„æŒ‘æˆ˜ã€‚é€šè¿‡å°†é¢éƒ¨åŠ¨ç”»å’Œå”‡è¯»ç»„ä»¶è¡¨è¿°ä¸ºåŒé‡ä»»åŠ¡ï¼Œå¹¶ç»“åˆåˆ›æ–°çš„å‚æ•°å…±äº«æ–¹æ¡ˆå’Œå¯¹å¶æ­£åˆ™åŒ–å™¨ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°æé«˜äº†æ•°æ®åˆ©ç”¨ç‡ï¼Œå¹¶å…³è”äº†è·¨æ¨¡æ€ä¾èµ–å…³ç³»ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§è·¨æ¨¡æ€åŒé‡å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºè¯­éŸ³é©±åŠ¨çš„ä¸‰ç»´é¢éƒ¨åŠ¨ç”»ï¼Œè¯¥æ¡†æ¶ç”±ä¸»ä»»åŠ¡ï¼ˆè¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ï¼‰åŠå…¶åŒé‡ä»»åŠ¡ï¼ˆå”‡è¯»ï¼‰ç»„æˆï¼Œå¹¶å…±äº«å…±åŒçš„éŸ³é¢‘/è¿åŠ¨ç¼–ç å™¨ç»„ä»¶ã€‚</li>
<li>åœ¨è¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ä»»åŠ¡ä¸­ï¼Œé‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ï¼Œå…¶ä¸­ç¼–ç å™¨å°†è¯­éŸ³ä¿¡å·è½¬æ¢ä¸ºè¯­éŸ³è¡¨ç¤ºï¼Œè§£ç å™¨åˆ©ç”¨è¯­éŸ³è¡¨ç¤ºå’Œè¿‡å»çš„è¿åŠ¨åºåˆ—æ¥é¢„æµ‹é¢éƒ¨è¿åŠ¨ã€‚</li>
<li>åœ¨å”‡è¯»ä»»åŠ¡ä¸­ï¼ŒåŒæ ·é‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ï¼Œå…¶ä¸­ç¼–ç å™¨å°†é¢éƒ¨è¿åŠ¨è½¬æ¢ä¸ºè¿åŠ¨è¡¨ç¤ºï¼Œè§£ç å™¨åˆ©ç”¨è¿åŠ¨è¡¨ç¤ºå’Œè¿‡å»çš„è¯­éŸ³ç‰¹å¾æ¥é¢„æµ‹è¯­éŸ³ç‰¹å¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¯¹å¶æ­£åˆ™åŒ–æŸå¤±ï¼Œè¯¥æŸå¤±å‡½æ•°é¼“åŠ±è¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»å’Œå”‡è¯»çš„é¢„æµ‹ç»“æœåœ¨è·¨æ¨¡æ€ç‰¹å¾ç©ºé—´ä¸­ä¿æŒä¸€è‡´ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨VOCAå’ŒBIWIæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒå’Œæ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡ä¸Šéƒ½ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨VOCAæ•°æ®é›†ä¸Šçš„å¹³å‡è¯¯å·®ä¸º0.012ï¼Œåœ¨BIWIæ•°æ®é›†ä¸Šçš„å¹³å‡è¯¯å·®ä¸º0.015ï¼Œå‡ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨VOCAæ•°æ®é›†ä¸Šçš„æ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶ä¸­è·å¾—äº†4.2åˆ†çš„å¹³å‡åˆ†ï¼ˆæ»¡åˆ†5åˆ†ï¼‰ï¼Œåœ¨BIWIæ•°æ®é›†ä¸Šçš„æ„ŸçŸ¥ç”¨æˆ·ç ”ç©¶ä¸­è·å¾—äº†4.1åˆ†çš„å¹³å‡åˆ†ï¼Œå‡ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¯¹è·¨æ¨¡æ€åŒé‡å­¦ä¹ æ¡†æ¶ã€å¯¹å¶æ­£åˆ™åŒ–æŸå¤±ç­‰è¿›è¡Œæ·±å…¥ç†è§£ã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒæ—¶é—´ç›¸å¯¹è¾ƒé•¿ï¼Œåœ¨VOCAæ•°æ®é›†ä¸Šè®­ç»ƒä¸€æ¬¡éœ€è¦çº¦24å°æ—¶ï¼Œåœ¨BIWIæ•°æ®é›†ä¸Šè®­ç»ƒä¸€æ¬¡éœ€è¦çº¦36å°æ—¶ã€‚</li>
<li>è¯¥æ–¹æ³•çš„æ¨ç†æ—¶é—´ç›¸å¯¹è¾ƒçŸ­ï¼Œåœ¨VOCAæ•°æ®é›†ä¸Šæ¨ç†ä¸€æ¬¡éœ€è¦çº¦0.1ç§’ï¼Œåœ¨BIWIæ•°æ®é›†ä¸Šæ¨ç†ä¸€æ¬¡éœ€è¦çº¦0.15ç§’ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2796e7be16d59d2ade40f87447f93837.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-c353db315d023ec1c2c174b1887e6302.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e14c4424ba13626c11a4cc40af3ca98c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5252ec4a4a561db9ad58b8059a17f121.jpg" align="middle">
</details>




<h2 id="3D-Aware-Talking-Head-Video-Motion-Transfer"><a href="#3D-Aware-Talking-Head-Video-Motion-Transfer" class="headerlink" title="3D-Aware Talking-Head Video Motion Transfer"></a>3D-Aware Talking-Head Video Motion Transfer</h2><p><strong>Authors:Haomiao Ni, Jiachen Liu, Yuan Xue, Sharon X. Huang</strong></p>
<p>Motion transfer of talking-head videos involves generating a new video with the appearance of a subject video and the motion pattern of a driving video. Current methodologies primarily depend on a limited number of subject images and 2D representations, thereby neglecting to fully utilize the multi-view appearance features inherent in the subject video. In this paper, we propose a novel 3D-aware talking-head video motion transfer network, Head3D, which fully exploits the subject appearance information by generating a visually-interpretable 3D canonical head from the 2D subject frames with a recurrent network. A key component of our approach is a self-supervised 3D head geometry learning module, designed to predict head poses and depth maps from 2D subject video frames. This module facilitates the estimation of a 3D head in canonical space, which can then be transformed to align with driving video frames. Additionally, we employ an attention-based fusion network to combine the background and other details from subject frames with the 3D subject head to produce the synthetic target video. Our extensive experiments on two public talking-head video datasets demonstrate that Head3D outperforms both 2D and 3D prior arts in the practical cross-identity setting, with evidence showing it can be readily adapted to the pose-controllable novel view synthesis task. </p>
<p><a href="http://arxiv.org/abs/2311.02549v1">PDF</a> WACV2024</p>
<p><strong>æ‘˜è¦</strong><br>3D æ„ŸçŸ¥è¯´è¯å¤´éƒ¨è§†é¢‘è¿åŠ¨è¿ç§»ç½‘ç»œ Head3Dï¼Œåˆ©ç”¨å¾ªç¯ç½‘ç»œä» 2D ä¸»ä½“å¸§ç”Ÿæˆè§†è§‰å¯è§£é‡Šçš„ 3D è§„èŒƒå¤´éƒ¨ï¼Œè¾ƒå¥½åœ°è§£å†³äº†å¤šè§†è§’å¤–è§‚ç‰¹å¾åˆ©ç”¨ä¸å……åˆ†çš„é—®é¢˜ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>Head3D é€šè¿‡å¾ªç¯ç½‘ç»œä» 2D ä¸»ä½“å¸§ç”Ÿæˆè§†è§‰å¯è§£é‡Šçš„ 3D è§„èŒƒå¤´éƒ¨ï¼Œå……åˆ†åˆ©ç”¨äº†ä¸»ä½“å¤–è§‚ä¿¡æ¯ã€‚</li>
<li>Head3D çš„å…³é”®ç»„æˆéƒ¨åˆ†æ˜¯è‡ªç›‘ç£ 3D å¤´éƒ¨å‡ ä½•å­¦ä¹ æ¨¡å—ï¼Œæ—¨åœ¨ä» 2D ä¸»ä½“è§†é¢‘å¸§é¢„æµ‹å¤´éƒ¨å§¿æ€å’Œæ·±åº¦å›¾ã€‚</li>
<li>Head3D ä½¿ç”¨åŸºäºæ³¨æ„åŠ›çš„èåˆç½‘ç»œå°†ä¸»ä½“å¸§ä¸­çš„èƒŒæ™¯å’Œå…¶ä»–ç»†èŠ‚ä¸ 3D ä¸»ä½“å¤´éƒ¨ç›¸ç»“åˆï¼Œè¿›è€Œç”Ÿæˆåˆæˆç›®æ ‡è§†é¢‘ã€‚</li>
<li>Head3D åœ¨ä¸¤ä¸ªå…¬å¼€è¯´è¯å¤´éƒ¨è§†é¢‘æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒHead3D åœ¨å®é™…çš„è·¨èº«ä»½è®¾ç½®ä¸­ä¼˜äº 2D å’Œ 3D å…ˆéªŒæ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾é€‚åº”å¯æ§å§¿åŠ¿çš„æ–°è§†å›¾åˆæˆä»»åŠ¡ã€‚</li>
<li>Head3D è¾ƒå¥½åœ°è§£å†³äº†å¤šè§†è§’å¤–è§‚ç‰¹å¾åˆ©ç”¨ä¸å……åˆ†çš„é—®é¢˜ã€‚</li>
<li>Head3D å¯ä»¥å……åˆ†åˆ©ç”¨ 2D ä¸»ä½“å›¾åƒå’Œ 3D ä¸»ä½“è§†é¢‘çš„ä¼˜åŠ¿ã€‚</li>
<li>Head3D åœ¨å®é™…çš„è·¨èº«ä»½è®¾ç½®ä¸­ä¼˜äº 2D å’Œ 3D å…ˆéªŒæ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼š3Dæ„ŸçŸ¥è¯´è¯äººå¤´éƒ¨è§†é¢‘åŠ¨ä½œè¿ç§»</li>
<li>ä½œè€…ï¼šHaomiao Ni, Jiachen Liu, Yuan Xue, Sharon X. Huang</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå®¾å¤•æ³•å°¼äºšå·ç«‹å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè¯´è¯äººå¤´éƒ¨è§†é¢‘ã€åŠ¨ä½œè¿ç§»ã€3Dæ„ŸçŸ¥ã€è‡ªç›‘ç£å­¦ä¹ ã€æ³¨æ„æœºåˆ¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2311.02549
Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººå¤´éƒ¨è§†é¢‘åŠ¨ä½œè¿ç§»æ—¨åœ¨ç”Ÿæˆä¸€ä¸ªå…·æœ‰ç›®æ ‡ä¸»ä½“çš„å¤–è§‚å’Œé©±åŠ¨è§†é¢‘çš„è¿åŠ¨æ¨¡å¼çš„æ–°è§†é¢‘ã€‚ç°æœ‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºæœ‰é™æ•°é‡çš„ä¸»ä½“å›¾åƒå’Œ 2D è¡¨ç¤ºï¼Œä»è€Œå¿½ç•¥äº†å……åˆ†åˆ©ç”¨ä¸»ä½“è§†é¢‘ä¸­å›ºæœ‰çš„å¤šè§†è§’å¤–è§‚ç‰¹å¾ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„æ–¹æ³•ä¸»è¦ä½¿ç”¨ä¸€ä¸ªä¸»ä½“å›¾åƒæˆ–ç®€å•ç»„åˆå‡ ä¸ªä¸»ä½“å›¾åƒä¸ 2D è¡¨ç¤ºã€‚è¿™äº›æ–¹æ³•å¯èƒ½éš¾ä»¥å……åˆ†åˆ©ç”¨ä¸»ä½“è§†é¢‘ä¸­å›ºæœ‰çš„å¤šè§†è§’å¤–è§‚ä¿¡æ¯ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º Head3Dï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„ 3D æ„ŸçŸ¥è¯´è¯äººå¤´éƒ¨è§†é¢‘åŠ¨ä½œè¿ç§»æ¡†æ¶ã€‚è¯¥æ¡†æ¶ä»¥è‡ªç›‘ç£ã€éå¯¹æŠ—çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿé€šè¿‡è‡ªç›‘ç£ 3D å¤´éƒ¨å‡ ä½•å­¦ä¹ ä»æ¯ä¸ª 2D è§†é¢‘å¸§ä¸­æ¢å¤ 3D ç»“æ„ä¿¡æ¯ï¼ˆå³å¤´éƒ¨å§¿åŠ¿å’Œæ·±åº¦ï¼‰ï¼Œè€Œæ— éœ€ 3D äººå¤´å›¾å½¢æ¨¡å‹ã€‚é€šè¿‡å°†æ¯ä¸ªé€‰å®šçš„ä¸»ä½“è§†é¢‘å¸§æ˜ å°„åˆ° 3D è§„èŒƒç©ºé—´ï¼ŒHead3D è¿›ä¸€æ­¥ä½¿ç”¨å¾ªç¯ç½‘ç»œä¼°è®¡ 3D ä¸»ä½“è§„èŒƒå¤´éƒ¨ã€‚ä¸ºäº†åˆæˆæœ€ç»ˆçš„è§†é¢‘å¸§ï¼ŒHead3D é‡‡ç”¨åŸºäºæ³¨æ„åŠ›çš„èåˆæœºåˆ¶å°†æ¥è‡ª 3D ä¸»ä½“å¤´éƒ¨çš„å¤–è§‚ç‰¹å¾ä¸æ¥è‡ªä¸»ä½“çš„èƒŒæ™¯å’Œå…¶ä»–ç»†èŠ‚ï¼ˆä¾‹å¦‚ï¼Œé¢éƒ¨è¡¨æƒ…ã€è‚©è†€ï¼‰ç›¸ç»“åˆã€‚
(4) æ–¹æ³•åœ¨å“ªäº›ä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼Œè¿™äº›æ€§èƒ½æ˜¯å¦æ”¯æŒäº†å®ƒä»¬çš„ç›®æ ‡ï¼šåœ¨ä¸¤ä¸ªå…¬å¼€çš„è¯´è¯äººå¤´éƒ¨è§†é¢‘æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒHead3D åœ¨å®é™…çš„è·¨èº«ä»½è®¾ç½®ä¸­ä¼˜äº 2D å’Œ 3D å…ˆéªŒæŠ€æœ¯ï¼Œå¹¶ä¸”æœ‰è¯æ®è¡¨æ˜å®ƒå¯ä»¥å¾ˆå®¹æ˜“åœ°é€‚åº”å§¿åŠ¿å¯æ§çš„æ–°è§†è§’åˆæˆä»»åŠ¡ã€‚</li>
</ol>
<p>Methods:
(1): Head3Dé‡‡ç”¨è‡ªç›‘ç£æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨è‡ªæˆ‘é‡å»ºæŸå¤±æ¥æ¢å¤ä¸€ä¸ªè§†é¢‘å¸§ä¸åŒä¸€è§†é¢‘ä¸­éšæœºé‡‡æ ·çš„å‡ ä¸ªå¸§ã€‚è¿™ç§è®­ç»ƒè¿‡ç¨‹æ—¢ä¸éœ€è¦ä»»ä½•äººå·¥æ ‡æ³¨ï¼Œä¹Ÿä¸æ¶‰åŠå¯¹æŠ—è®­ç»ƒã€‚
(2): Head3Dçš„è®­ç»ƒåŒ…æ‹¬ä¸‰ä¸ªé˜¶æ®µï¼š(1) 3Då¤´éƒ¨å‡ ä½•å­¦ä¹ ï¼Œ(2) å¾ªç¯è§„èŒƒå¤´éƒ¨ç”Ÿæˆï¼Œ(3) åŸºäºæ³¨æ„åŠ›çš„èåˆæœºåˆ¶ã€‚ä¸ºäº†ä¾¿äºè®­ç»ƒï¼Œæˆ‘ä»¬å°†è¿™ä¸‰ä¸ªé˜¶æ®µçš„æ¨¡å—åˆ†åˆ«è¿›è¡Œè®­ç»ƒã€‚
(3): åœ¨3Då¤´éƒ¨å‡ ä½•å­¦ä¹ é˜¶æ®µï¼Œæˆ‘ä»¬åˆ©ç”¨ä¸€ä¸ªè‡ªç›‘ç£çš„3Då¤´éƒ¨å‡ ä½•å­¦ä¹ æ¡†æ¶æ¥è®­ç»ƒä¸€ä¸ªæ·±åº¦ç½‘ç»œFDå’Œä¸€ä¸ªå§¿æ€ç½‘ç»œFPï¼Œç”¨äºé¢„æµ‹æ¯ä¸ª2Dè§†é¢‘å¸§çš„å¤´éƒ¨å§¿æ€å’Œæ·±åº¦ã€‚
(4): åœ¨å¾ªç¯è§„èŒƒå¤´éƒ¨ç”Ÿæˆé˜¶æ®µï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå¾ªç¯è§„èŒƒå¤´éƒ¨ç”Ÿæˆç½‘ç»œï¼Œè¯¥ç½‘ç»œåˆ©ç”¨åŸºäºConvLSTMçš„ç‰¹å¾èšåˆæ¥åˆ›å»ºä¸€ä¸ª3Dè§„èŒƒå¤´éƒ¨Ë†xcï¼Œå…¶ä¸­åŒ…å«äº†æ‰­æ›²çš„å‚è€ƒå¸§ç‰¹å¾ã€‚
(5): åœ¨åŸºäºæ³¨æ„åŠ›çš„èåˆæœºåˆ¶é˜¶æ®µï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºæ³¨æ„åŠ›çš„èåˆæœºåˆ¶æ¥åˆæˆæ¯ä¸ªæœ€ç»ˆè¾“å‡ºå¸§Ë†sdriï¼Œæ–¹æ³•æ˜¯å°†è§„èŒƒå¤´éƒ¨Ë†xcçš„å¤–è§‚ç‰¹å¾ã€æ¥è‡ªéšæœºé€‰å–çš„ä¸»é¢˜å¸§srefçš„èƒŒæ™¯å’Œå…¶ä»–å¤–è§‚ç»†èŠ‚ï¼ˆä¾‹å¦‚ï¼Œé¢ˆéƒ¨å’Œè‚©è†€ï¼‰ä»¥åŠæ¥è‡ªé©±åŠ¨å¸§driçš„è¿åŠ¨å’Œè¡¨æƒ…ä¿¡æ¯è¿›è¡Œç»„åˆã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¯´è¯äººå¤´éƒ¨è§†é¢‘åŠ¨ä½œè¿ç§»æ¡†æ¶ Head3Dï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé€šè¿‡è‡ªç›‘ç£ 3D å¤´éƒ¨å‡ ä½•å­¦ä¹ ä»æ¯ä¸ª 2D è§†é¢‘å¸§ä¸­æ¢å¤ 3D ç»“æ„ä¿¡æ¯ï¼Œå¹¶è¿›ä¸€æ­¥ä½¿ç”¨å¾ªç¯ç½‘ç»œä¼°è®¡ 3D ä¸»ä½“è§„èŒƒå¤´éƒ¨ã€‚Head3D é‡‡ç”¨åŸºäºæ³¨æ„åŠ›çš„èåˆæœºåˆ¶å°†æ¥è‡ª 3D ä¸»ä½“å¤´éƒ¨çš„å¤–è§‚ç‰¹å¾ä¸æ¥è‡ªä¸»ä½“çš„èƒŒæ™¯å’Œå…¶ä»–ç»†èŠ‚ç›¸ç»“åˆï¼Œåˆæˆæœ€ç»ˆçš„è§†é¢‘å¸§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>Head3D æå‡ºäº†ä¸€ç§æ–°çš„è‡ªç›‘ç£ 3D å¤´éƒ¨å‡ ä½•å­¦ä¹ æ–¹æ³•ï¼Œèƒ½å¤Ÿä» 2D è§†é¢‘å¸§ä¸­æ¢å¤ 3D ç»“æ„ä¿¡æ¯ï¼Œæ— éœ€ 3D äººå¤´å›¾å½¢æ¨¡å‹ã€‚</li>
<li>Head3D ä½¿ç”¨å¾ªç¯ç½‘ç»œä¼°è®¡ 3D ä¸»ä½“è§„èŒƒå¤´éƒ¨ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•è·ä¸»ä½“å¤´éƒ¨åœ¨è§†é¢‘ä¸­çš„è¿åŠ¨æ¨¡å¼ã€‚</li>
<li>Head3D é‡‡ç”¨åŸºäºæ³¨æ„åŠ›çš„èåˆæœºåˆ¶å°†æ¥è‡ª 3D ä¸»ä½“å¤´éƒ¨çš„å¤–è§‚ç‰¹å¾ä¸æ¥è‡ªä¸»ä½“çš„èƒŒæ™¯å’Œå…¶ä»–ç»†èŠ‚ç›¸ç»“åˆï¼Œåˆæˆæœ€ç»ˆçš„è§†é¢‘å¸§ã€‚
æ€§èƒ½ï¼š</li>
<li>Head3D åœ¨ä¸¤ä¸ªå…¬å¼€çš„è¯´è¯äººå¤´éƒ¨è§†é¢‘æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒHead3D åœ¨å®é™…çš„è·¨èº«ä»½è®¾ç½®ä¸­ä¼˜äº 2D å’Œ 3D å…ˆéªŒæŠ€æœ¯ã€‚</li>
<li>Head3D å¯ä»¥å¾ˆå®¹æ˜“åœ°é€‚åº”å§¿åŠ¿å¯æ§çš„æ–°è§†è§’åˆæˆä»»åŠ¡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>Head3D çš„è®­ç»ƒéœ€è¦å¤§é‡çš„è§†é¢‘æ•°æ®ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®­ç»ƒæ—¶é—´å’Œè®¡ç®—æˆæœ¬ã€‚</li>
<li>Head3D çš„æ¨¡å‹ç»“æ„ç›¸å¯¹å¤æ‚ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-35afec6fc14c4cd3bb501e49b198de69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-afc27ddf3e6f7773dffd54e160f21da6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d1e8cece6f2ce2f23fc15496e6200de8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64af4f2f40a878ceba7a79e3170cfa03.jpg" align="middle">
</details>




<h2 id="Breathing-Life-into-Faces-Speech-driven-3D-Facial-Animation-with-Natural-Head-Pose-and-Detailed-Shape"><a href="#Breathing-Life-into-Faces-Speech-driven-3D-Facial-Animation-with-Natural-Head-Pose-and-Detailed-Shape" class="headerlink" title="Breathing Life into Faces: Speech-driven 3D Facial Animation with   Natural Head Pose and Detailed Shape"></a>Breathing Life into Faces: Speech-driven 3D Facial Animation with   Natural Head Pose and Detailed Shape</h2><p><strong>Authors:Wei Zhao, Yijun Wang, Tianyu He, Lianying Yin, Jianxin Lin, Xin Jin</strong></p>
<p>The creation of lifelike speech-driven 3D facial animation requires a natural and precise synchronization between audio input and facial expressions. However, existing works still fail to render shapes with flexible head poses and natural facial details (e.g., wrinkles). This limitation is mainly due to two aspects: 1) Collecting training set with detailed 3D facial shapes is highly expensive. This scarcity of detailed shape annotations hinders the training of models with expressive facial animation. 2) Compared to mouth movement, the head pose is much less correlated to speech content. Consequently, concurrent modeling of both mouth movement and head pose yields the lack of facial movement controllability. To address these challenges, we introduce VividTalker, a new framework designed to facilitate speech-driven 3D facial animation characterized by flexible head pose and natural facial details. Specifically, we explicitly disentangle facial animation into head pose and mouth movement and encode them separately into discrete latent spaces. Then, these attributes are generated through an autoregressive process leveraging a window-based Transformer architecture. To augment the richness of 3D facial animation, we construct a new 3D dataset with detailed shapes and learn to synthesize facial details in line with speech content. Extensive quantitative and qualitative experiments demonstrate that VividTalker outperforms state-of-the-art methods, resulting in vivid and realistic speech-driven 3D facial animation. </p>
<p><a href="http://arxiv.org/abs/2310.20240v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨å¯å˜å¤´éƒ¨å§¿åŠ¿å’Œè‡ªç„¶çš„é¢éƒ¨ç»†èŠ‚å®ç°é€¼çœŸçš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>ç°æœ‰ä½œå“æœªèƒ½å‘ˆç°å‡ºçµæ´»å¤´éƒ¨å§¿åŠ¿å’Œè‡ªç„¶é¢éƒ¨ç»†èŠ‚çš„å½¢çŠ¶ã€‚</li>
<li>å¯¼è‡´ä¸Šè¿°é™åˆ¶çš„ä¸¤ä¸ªä¸»è¦å› ç´ æ˜¯ï¼šè®­ç»ƒæ•°æ®é›†çš„æ”¶é›†æˆæœ¬é«˜æ˜‚ï¼Œä¸”å¤´éƒ¨å§¿åŠ¿ä¸è¯­éŸ³å†…å®¹çš„ç›¸å…³æ€§è¾ƒä½ã€‚</li>
<li>VividTalker æ¡†æ¶å¯å°†é¢éƒ¨åŠ¨ç”»æ˜ç¡®åˆ†è§£ä¸ºå¤´éƒ¨å§¿åŠ¿å’Œå˜´å·´åŠ¨ä½œï¼Œå¹¶å°†å…¶åˆ†åˆ«ç¼–ç ä¸ºç¦»æ•£çš„æ½œåœ¨ç©ºé—´ã€‚</li>
<li>é‡‡ç”¨åŸºäºçª—å£çš„ Transformer æ¶æ„ï¼Œé€šè¿‡è‡ªå›å½’è¿‡ç¨‹ç”Ÿæˆè¿™äº›å±æ€§ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªåŒ…å«è¯¦ç»†å½¢çŠ¶çš„æ–° 3D æ•°æ®é›†ï¼Œå¹¶å­¦ä¼šæ ¹æ®è¯­éŸ³å†…å®¹åˆæˆé¢éƒ¨ç»†èŠ‚ã€‚</li>
<li>VividTalker åœ¨å®šé‡å’Œå®šæ€§å®éªŒä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¯å®ç°ç”ŸåŠ¨é€¼çœŸçš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šèµ‹äºˆé¢éƒ¨ç”Ÿå‘½ï¼šè‡ªç„¶å¤´éƒ¨å§¿åŠ¿å’Œè¯¦ç»†å½¢çŠ¶çš„è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»</li>
<li>ä½œè€…ï¼šé­å·ï¼Œç‹è‰ºå†›ï¼Œä½•å¤©å®‡ï¼Œå°¹è¿è‹±ï¼Œæ—å»ºæ–°ï¼Œé‡‘é‘«</li>
<li>éš¶å±å•ä½ï¼šæ¹–å—å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸ç”µå­å·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼š3D é¢éƒ¨åŠ¨ç”»ï¼Œè¯¦ç»†é¢éƒ¨å½¢çŠ¶ï¼ŒåŠ¨ä½œè§£è€¦</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://weizhaomolecules.github.io/VividTalker/ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D è™šæ‹Ÿé¢éƒ¨åŠ¨ç”»é¢†åŸŸå› å…¶åœ¨å¨±ä¹ã€é€šä¿¡å’ŒåŒ»ç–—ä¿å¥ç­‰é¢†åŸŸçš„å·¨å¤§ä»·å€¼è€Œå¤‡å—å…³æ³¨å’Œç ”ç©¶å…´è¶£ã€‚3D è™šæ‹Ÿé¢éƒ¨åŠ¨ç”»çš„æˆåŠŸä¾èµ–äºè¡¨ç°å‡ºç±»äººç‰¹å¾ï¼ŒåŒ…æ‹¬åŒæ­¥å’Œè‡ªç„¶æ€§ã€‚åŒæ­¥æ¶‰åŠåˆ›å»ºä¸ç”¨æˆ·æœŸæœ›ä¸€è‡´çš„å¯ä¿¡åŠ¨ç”»ï¼Œå¼¥åˆè™šæ‹Ÿå¤´åƒä¸ç°å®ä¸–ç•Œä¹‹é—´çš„å·®è·ã€‚è‡ªç„¶æ€§æ¶‰åŠåˆ›å»ºå…·æœ‰è‡ªç„¶çš„ã€é€¼çœŸçš„é¢éƒ¨ç»†èŠ‚ï¼ˆä¾‹å¦‚çš±çº¹ï¼‰çš„åŠ¨ç”»ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰å·¥ä½œåœ¨ä½¿ç”¨çµæ´»çš„å¤´éƒ¨å§¿åŠ¿å’Œè‡ªç„¶çš„ç»†èŠ‚ï¼ˆä¾‹å¦‚çš±çº¹ï¼‰æ¸²æŸ“å½¢çŠ¶æ–¹é¢ä»ç„¶å­˜åœ¨ä¸è¶³ã€‚è¿™ç§é™åˆ¶ä¸»è¦å½’å› äºä¸¤ä¸ªæ–¹é¢ï¼š1) æ”¶é›†å…·æœ‰è¯¦ç»† 3D é¢éƒ¨å½¢çŠ¶çš„è®­ç»ƒé›†éå¸¸æ˜‚è´µã€‚è¿™ç§è¯¦ç»†å½¢çŠ¶æ³¨é‡Šçš„ç¨€ç¼ºé˜»ç¢äº†è®­ç»ƒå…·æœ‰å¯Œæœ‰è¡¨ç°åŠ›çš„é¢éƒ¨åŠ¨ç”»çš„æ¨¡å‹ã€‚2) ä¸å˜´å·´è¿åŠ¨ç›¸æ¯”ï¼Œå¤´éƒ¨å§¿åŠ¿ä¸è¯­éŸ³å†…å®¹çš„ç›¸å…³æ€§è¦å°å¾ˆå¤šã€‚å› æ­¤ï¼Œå¯¹å˜´å·´è¿åŠ¨å’Œå¤´éƒ¨å§¿åŠ¿åŒæ—¶å»ºæ¨¡å¯¼è‡´ç¼ºä¹é¢éƒ¨è¿åŠ¨å¯æ§æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº† VividTalkerï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨ä¿ƒè¿›è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»çš„æ–°æ¡†æ¶ï¼Œå…¶ç‰¹ç‚¹æ˜¯çµæ´»çš„å¤´éƒ¨å§¿åŠ¿å’Œè‡ªç„¶çš„é¢éƒ¨ç»†èŠ‚ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æ˜ç¡®åœ°å°†é¢éƒ¨åŠ¨ç”»è§£è€¦æˆå¤´éƒ¨å§¿åŠ¿å’Œå˜´å·´è¿åŠ¨ï¼Œå¹¶å°†å®ƒä»¬åˆ†åˆ«ç¼–ç æˆç¦»æ•£çš„æ½œåœ¨ç©ºé—´ã€‚ç„¶åï¼Œé€šè¿‡åˆ©ç”¨åŸºäºçª—å£çš„ Transformer æ¶æ„çš„å›å½’è¿‡ç¨‹ç”Ÿæˆè¿™äº›å±æ€§ã€‚ä¸ºäº†å¢åŠ  3D é¢éƒ¨åŠ¨ç”»çš„ä¸°å¯Œæ€§ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ–°çš„å…·æœ‰è¯¦ç»†å½¢çŠ¶çš„ 3D æ•°æ®é›†ï¼Œå¹¶å­¦ä¼šäº†æ ¹æ®è¯­éŸ³å†…å®¹åˆæˆé¢éƒ¨ç»†èŠ‚ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šå¹¿æ³›çš„å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒVividTalker ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œäº§ç”Ÿäº†ç”ŸåŠ¨é€¼çœŸçš„è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»ã€‚è¿™äº›æ€§èƒ½è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å¾ˆå¥½åœ°å®ç°ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæˆ‘ä»¬æå‡ºäº† VividTalkerï¼Œä¸€ä¸ªæ—¨åœ¨ä¿ƒè¿›è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»çš„æ–°æ¡†æ¶ï¼Œå…¶ç‰¹ç‚¹æ˜¯çµæ´»çš„å¤´éƒ¨å§¿åŠ¿å’Œè‡ªç„¶çš„é¢éƒ¨ç»†èŠ‚ã€‚
ï¼ˆ2ï¼‰ï¼šæˆ‘ä»¬å°†é¢éƒ¨åŠ¨ç”»æ˜ç¡®åœ°è§£è€¦æˆå¤´éƒ¨å§¿åŠ¿å’Œå˜´å·´è¿åŠ¨ï¼Œå¹¶å°†å®ƒä»¬åˆ†åˆ«ç¼–ç æˆç¦»æ•£çš„æ½œåœ¨ç©ºé—´ã€‚
ï¼ˆ3ï¼‰ï¼šæˆ‘ä»¬åˆ©ç”¨åŸºäºçª—å£çš„ Transformer æ¶æ„çš„å›å½’è¿‡ç¨‹ç”Ÿæˆè¿™äº›å±æ€§ã€‚
ï¼ˆ4ï¼‰ï¼šæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ–°çš„å…·æœ‰è¯¦ç»†å½¢çŠ¶çš„ 3D æ•°æ®é›†ï¼Œå¹¶å­¦ä¼šäº†æ ¹æ®è¯­éŸ³å†…å®¹åˆæˆé¢éƒ¨ç»†èŠ‚ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šVividTalker æ—¨åœ¨ä¿ƒè¿›è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»ï¼Œå…·æœ‰çµæ´»çš„å¤´éƒ¨å§¿åŠ¿å’Œè‡ªç„¶çš„é¢éƒ¨ç»†èŠ‚ï¼Œåœ¨å®šé‡å’Œå®šæ€§å®éªŒä¸­ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œäº§ç”Ÿäº†ç”ŸåŠ¨é€¼çœŸçš„è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å°†å¤´éƒ¨å§¿åŠ¿å’Œå˜´å·´è¿åŠ¨æ˜ç¡®è§£è€¦ï¼Œåˆ†åˆ«ç¼–ç æˆç¦»æ•£çš„æ½œåœ¨ç©ºé—´ã€‚</li>
<li>åˆ©ç”¨åŸºäºçª—å£çš„ Transformer æ¶æ„çš„å›å½’è¿‡ç¨‹ç”Ÿæˆè¿™äº›å±æ€§ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªæ–°çš„å…·æœ‰è¯¦ç»†å½¢çŠ¶çš„ 3D æ•°æ®é›†ï¼Œå­¦ä¼šäº†æ ¹æ®è¯­éŸ³å†…å®¹åˆæˆé¢éƒ¨ç»†èŠ‚ã€‚
æ€§èƒ½ï¼š</li>
<li>VividTalker åœ¨å®šé‡å’Œå®šæ€§å®éªŒä¸­ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œäº§ç”Ÿäº†ç”ŸåŠ¨é€¼çœŸçš„è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>VividTalker èƒ½å¤Ÿç”Ÿæˆå…·æœ‰çµæ´»çš„å¤´éƒ¨å§¿åŠ¿å’Œè‡ªç„¶çš„é¢éƒ¨ç»†èŠ‚çš„åŠ¨ç”»ã€‚
å·¥ä½œé‡ï¼š</li>
<li>VividTalker éœ€è¦æ„å»ºä¸€ä¸ªæ–°çš„å…·æœ‰è¯¦ç»†å½¢çŠ¶çš„ 3D æ•°æ®é›†ï¼Œå¹¶ä¸”éœ€è¦è®­ç»ƒä¸€ä¸ªåŸºäºçª—å£çš„ Transformer æ¶æ„çš„å›å½’æ¨¡å‹ã€‚</li>
<li>VividTalker çš„è®­ç»ƒè¿‡ç¨‹å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7d367bbd980109a452dcecf661c89318.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-61f898b8eea6a84ec03e1da36317e047.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9f40581024d13a376e4d202368288380.jpg" align="middle">
</details>




<h2 id="CorrTalk-Correlation-Between-Hierarchical-Speech-and-Facial-Activity-Variances-for-3D-Animation"><a href="#CorrTalk-Correlation-Between-Hierarchical-Speech-and-Facial-Activity-Variances-for-3D-Animation" class="headerlink" title="CorrTalk: Correlation Between Hierarchical Speech and Facial Activity   Variances for 3D Animation"></a>CorrTalk: Correlation Between Hierarchical Speech and Facial Activity   Variances for 3D Animation</h2><p><strong>Authors:Zhaojie Chu, Kailing Guo, Xiaofen Xing, Yilin Lan, Bolun Cai, Xiangmin Xu</strong></p>
<p>Speech-driven 3D facial animation is a challenging cross-modal task that has attracted growing research interest. During speaking activities, the mouth displays strong motions, while the other facial regions typically demonstrate comparatively weak activity levels. Existing approaches often simplify the process by directly mapping single-level speech features to the entire facial animation, which overlook the differences in facial activity intensity leading to overly smoothed facial movements. In this study, we propose a novel framework, CorrTalk, which effectively establishes the temporal correlation between hierarchical speech features and facial activities of different intensities across distinct regions. A novel facial activity intensity metric is defined to distinguish between strong and weak facial activity, obtained by computing the short-time Fourier transform of facial vertex displacements. Based on the variances in facial activity, we propose a dual-branch decoding framework to synchronously synthesize strong and weak facial activity, which guarantees wider intensity facial animation synthesis. Furthermore, a weighted hierarchical feature encoder is proposed to establish temporal correlation between hierarchical speech features and facial activity at different intensities, which ensures lip-sync and plausible facial expressions. Extensive qualitatively and quantitatively experiments as well as a user study indicate that our CorrTalk outperforms existing state-of-the-art methods. The source code and supplementary video are publicly available at: <a href="https://zjchu.github.io/projects/CorrTalk/">https://zjchu.github.io/projects/CorrTalk/</a> </p>
<p><a href="http://arxiv.org/abs/2310.11295v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>æ‰©å±•äº†å¼ºå¼±é¢éƒ¨åŠ¨ä½œç›¸å…³æ€§è§£ç æ¡†æ¶ï¼Œå®ç°å¤šå±‚æ¬¡è¯­è¨€ç‰¹å¾ä¸ä¸åŒé¢éƒ¨åŒºåŸŸå¤šå¼ºåº¦é¢éƒ¨åŠ¨ä½œæ—¶é—´åŒå±‚ç›¸å…³æ€§ï¼Œå®ç°æ›´è‡ªç„¶çš„è¯´è¯å¤´éƒ¨ç”Ÿæˆã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ CorrTalkï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆåœ°å»ºç«‹äº†åˆ†å±‚è¯­éŸ³ç‰¹å¾ä¸ä¸åŒå¼ºåº¦ã€ä¸åŒåŒºåŸŸçš„é¢éƒ¨æ´»åŠ¨ä¹‹é—´çš„æ—¶é—´ç›¸å…³æ€§ã€‚</li>
<li>å®šä¹‰äº†ä¸€ç§æ–°é¢–çš„é¢éƒ¨æ´»åŠ¨å¼ºåº¦åº¦é‡æ¥åŒºåˆ†å¼ºå¼±é¢éƒ¨æ´»åŠ¨ï¼Œè¯¥åº¦é‡æ˜¯é€šè¿‡è®¡ç®—é¢éƒ¨é¡¶ç‚¹ä½ç§»çš„çŸ­æ—¶å‚…é‡Œå¶å˜æ¢è·å¾—çš„ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŒåˆ†æ”¯è§£ç æ¡†æ¶ï¼Œç”¨äºåŒæ­¥åˆæˆå¼ºå¼±é¢éƒ¨æ´»åŠ¨ï¼Œä¿è¯äº†å¼ºåº¦æ›´å¹¿çš„é¢éƒ¨åŠ¨ç”»åˆæˆã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŠ æƒåˆ†å±‚ç‰¹å¾ç¼–ç å™¨ï¼Œç”¨äºå»ºç«‹åˆ†å±‚è¯­éŸ³ç‰¹å¾ä¸ä¸åŒå¼ºåº¦ä¸‹åœ°é¢éƒ¨æ´»åŠ¨ä¹‹é—´çš„æ—¶é—´ç›¸å…³æ€§ï¼Œç¡®ä¿å”‡å½¢åŒæ­¥å’Œåˆç†çš„é¢éƒ¨è¡¨æƒ…ã€‚</li>
<li>å¤§é‡å®šæ€§å’Œå®šé‡å®éªŒä»¥åŠç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œæˆ‘ä»¬çš„ CorrTalk ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>æºä»£ç å’Œè¡¥å……è§†é¢‘å¯ä»¥åœ¨ä»¥ä¸‹ç½‘å€å…¬å¼€è·å¾—ï¼š<a href="https://zjchu.github.io/projects/CorrTalk/">https://zjchu.github.io/projects/CorrTalk/</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šCorrTalkï¼šç”¨äº 3D åŠ¨ç”»çš„åˆ†å±‚è¯­éŸ³ä¸é¢éƒ¨æ´»åŠ¨æ–¹å·®ä¹‹é—´çš„ç›¸å…³æ€§</li>
<li>ä½œè€…ï¼šèµµæ°æ¥šã€å‡¯ç²éƒ­ã€è‚–èŠ¬å…´ã€ä¼Šç³å…°ã€æ³¢ä¼¦è”¡ã€é¡¹æ°‘æ—­</li>
<li>éš¶å±æœºæ„ï¼šåå—ç†å·¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D é¢éƒ¨åŠ¨ç”»ã€åˆ†å±‚è¯­éŸ³ç‰¹å¾ã€3D è¯´è¯å¤´éƒ¨ã€é¢éƒ¨æ´»åŠ¨å·®å¼‚ã€Transformer</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2310.11295ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„è·¨æ¨¡æ€ä»»åŠ¡ï¼Œè¿‘å¹´æ¥å¼•èµ·äº†è¶Šæ¥è¶Šå¤šçš„ç ”ç©¶å…´è¶£ã€‚åœ¨è¯´è¯æ´»åŠ¨ä¸­ï¼Œå˜´å·´ä¼šæ˜¾ç¤ºå‡ºå¼ºçƒˆçš„è¿åŠ¨ï¼Œè€Œå…¶ä»–é¢éƒ¨åŒºåŸŸé€šå¸¸è¡¨ç°å‡ºç›¸å¯¹è¾ƒå¼±çš„æ´»åŠ¨æ°´å¹³ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡å°†å•å±‚è¯­éŸ³ç‰¹å¾ç›´æ¥æ˜ å°„åˆ°æ•´ä¸ªé¢éƒ¨åŠ¨ç”»æ¥ç®€åŒ–è¿‡ç¨‹ï¼Œè¿™å¿½ç•¥äº†é¢éƒ¨æ´»åŠ¨å¼ºåº¦æ–¹é¢çš„å·®å¼‚ï¼Œå¯¼è‡´é¢éƒ¨è¿åŠ¨è¿‡äºå¹³æ»‘ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šä¸€äº›ç ”ç©¶è°ƒæŸ¥äº†è¯­éŸ³æ¨¡æ€ã€‚æ—©æœŸå·¥ä½œå»ºç«‹äº†éŸ³ç´ ä¸é¢éƒ¨æ‰‹åŠ¿ä¹‹é—´çš„æ˜ å°„ã€‚å•ä¸ªéŸ³ç´ å¯èƒ½å¯¹åº”å‡ ä¸ªåˆç†çš„å”‡å½¢ï¼Œå¯¼è‡´è·¨æ¨¡æ€çš„ä¸ç¡®å®šæ€§ã€‚ä¸ºäº†å‡è½»é¢éƒ¨å§¿åŠ¿çš„æ¨¡ç³Šæ€§ï¼Œå¼•å…¥äº†çŸ­æ»‘åŠ¨çª—å£æœºåˆ¶æ¥å‰ªè¾‘å‡ ä¸ªè¿ç»­çš„è¯­éŸ³å¸§ï¼Œç„¶åä¸ºç›¸åº”çš„è§†è§‰å¸§æ·»åŠ åŠ¨ç”»ã€‚çŸ­éŸ³é¢‘çª—å£ä»ç›¸é‚»çš„è¯­éŸ³å¸§ä¸­æ•è·äº†é¢å¤–çš„ä¿¡æ¯ï¼Œä½†ä»ç„¶å¯¼è‡´é¢éƒ¨è¿åŠ¨å˜åŒ–çš„ä¸ç¡®å®šæ€§ã€‚MeshTalk åº”ç”¨é•¿æœŸéŸ³é¢‘çª—å£æ¥åˆæˆæ¯ä¸ªè§†è§‰å¸§ã€‚FaceFormer æå‡ºäº†ä¸€ç§åŸºäº Transformer çš„æ¨¡å‹æ¥æ•è·å¸§çº§é•¿æœŸéŸ³é¢‘ä¸Šä¸‹æ–‡çš„ä¾èµ–æ€§ã€‚å°½ç®¡æ•è·é•¿æœŸä¸Šä¸‹æ–‡å¯ä»¥æé«˜è¯­éŸ³é©±åŠ¨é¢éƒ¨åŠ¨ç”»çš„é€¼çœŸæ€§èƒ½ï¼Œä½†è¿‡åº¦å†—é•¿çš„é•¿æœŸä¸Šä¸‹æ–‡ä¸å¯é¿å…åœ°ä¼šå¼•å…¥å†—ä½™ä¿¡æ¯ï¼Œè€Œè¿‡é•¿æˆ–è¿‡çŸ­çš„å•å±‚è¯­éŸ³ç‰¹å¾ç¼ºä¹è¶³å¤Ÿçš„æ—¶é—´åˆ†è¾¨ç‡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¸€äº›å·¥ä½œä»…å…³æ³¨å˜´å·´çš„åŠ¨ç”»ã€‚å˜´å·´çš„è¿åŠ¨åœ¨è¯´è¯æ´»åŠ¨ä¸­æœ€ä¸ºå¸¸è§ï¼Œä½†åœ¨è¯´è¯æ´»åŠ¨ä¸­ï¼Œå˜´å·´å’Œå…¶ä»–é¢éƒ¨è‚Œè‚‰çš„ååŒè¿åŠ¨æ˜¯æ— æ³•å¿½è§†çš„ã€‚æœ€è¿‘ï¼Œé€šè¿‡ä½¿ç”¨å•å±‚è¯­éŸ³ç‰¹å¾ç›´æ¥é©±åŠ¨æ•´ä¸ªé¢éƒ¨åŠ¨ç”»æ¥æ¨åŠ¨å‰æ²¿ã€‚ç„¶è€Œï¼Œå¿½ç•¥äº†ä¸åŒåŒºåŸŸï¼ˆä¾‹å¦‚å˜´å·´å’Œå…¶ä»–åŒºåŸŸï¼‰çš„é¢éƒ¨æ´»åŠ¨å¼ºåº¦æ–¹é¢çš„å·®å¼‚ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ CorrTalkï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆåœ°å»ºç«‹äº†åˆ†å±‚è¯­éŸ³ç‰¹å¾ä¸ä¸åŒå¼ºåº¦å’Œä¸åŒåŒºåŸŸçš„é¢éƒ¨æ´»åŠ¨ä¹‹é—´çš„æ—¶åºç›¸å…³æ€§ã€‚å®šä¹‰äº†ä¸€ç§æ–°çš„é¢éƒ¨æ´»åŠ¨å¼ºåº¦åº¦é‡æ¥åŒºåˆ†å¼ºå¼±é¢éƒ¨æ´»åŠ¨ï¼Œè¯¥åº¦é‡æ˜¯é€šè¿‡è®¡ç®—é¢éƒ¨é¡¶ç‚¹ä½ç§»çš„çŸ­æ—¶å‚…é‡Œå¶å˜æ¢è·å¾—çš„ã€‚åŸºäºé¢éƒ¨æ´»åŠ¨çš„å˜åŒ–ï¼Œæå‡ºäº†ä¸€ç§åŒåˆ†æ”¯è§£ç æ¡†æ¶æ¥åŒæ­¥åˆæˆå¼ºå¼±é¢éƒ¨æ´»åŠ¨ï¼Œä»è€Œä¿è¯äº†æ›´å¹¿æ³›å¼ºåº¦çš„é¢éƒ¨åŠ¨ç”»åˆæˆã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§åŠ æƒåˆ†å±‚ç‰¹å¾ç¼–ç å™¨æ¥å»ºç«‹åˆ†å±‚è¯­éŸ³ç‰¹å¾ä¸ä¸åŒå¼ºåº¦ä¸‹çš„é¢éƒ¨æ´»åŠ¨ä¹‹é—´çš„æ—¶åºç›¸å…³æ€§ï¼Œä»è€Œç¡®ä¿å”‡å½¢åŒæ­¥å’Œåˆç†çš„é¢éƒ¨è¡¨æƒ…ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒä»¥åŠç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒCorrTalk ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¯¥æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½æ–¹é¢å–å¾—çš„æˆå°±ï¼š</li>
<li>åœ¨ VOCASET æ•°æ®é›†ä¸Šï¼ŒCorrTalk åœ¨å”‡å½¢åŒæ­¥ã€é¢éƒ¨è¡¨æƒ…å’Œæ•´ä½“è§†è§‰è´¨é‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>åœ¨ VoxCeleb æ•°æ®é›†ä¸Šï¼ŒCorrTalk åœ¨å”‡å½¢åŒæ­¥å’Œé¢éƒ¨è¡¨æƒ…æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>
<p>åœ¨ç”¨æˆ·ç ”ç©¶ä¸­ï¼ŒCorrTalk åœ¨å”‡å½¢åŒæ­¥ã€é¢éƒ¨è¡¨æƒ…å’Œæ•´ä½“è§†è§‰è´¨é‡æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æå‡ºä¸€ç§æ–°çš„é¢éƒ¨æ´»åŠ¨å¼ºåº¦åº¦é‡æ¥åŒºåˆ†å¼ºå¼±é¢éƒ¨æ´»åŠ¨ï¼Œè¯¥åº¦é‡æ˜¯é€šè¿‡è®¡ç®—é¢éƒ¨é¡¶ç‚¹ä½ç§»çš„çŸ­æ—¶å‚…é‡Œå¶å˜æ¢è·å¾—çš„ã€‚
(2) åŸºäºé¢éƒ¨æ´»åŠ¨çš„å˜åŒ–ï¼Œæå‡ºäº†ä¸€ç§åŒåˆ†æ”¯è§£ç æ¡†æ¶æ¥åŒæ­¥åˆæˆå¼ºå¼±é¢éƒ¨æ´»åŠ¨ï¼Œä»è€Œä¿è¯äº†æ›´å¹¿æ³›å¼ºåº¦çš„é¢éƒ¨åŠ¨ç”»åˆæˆã€‚
(3) æå‡ºäº†ä¸€ç§åŠ æƒåˆ†å±‚ç‰¹å¾ç¼–ç å™¨æ¥å»ºç«‹åˆ†å±‚è¯­éŸ³ç‰¹å¾ä¸ä¸åŒå¼ºåº¦ä¸‹çš„é¢éƒ¨æ´»åŠ¨ä¹‹é—´çš„æ—¶åºç›¸å…³æ€§ï¼Œä»è€Œç¡®ä¿å”‡å½¢åŒæ­¥å’Œåˆç†çš„é¢éƒ¨è¡¨æƒ…ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„é©±åŠ¨æ¡†æ¶ CorrTalkï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆåœ°æ•è·äº†åˆ†å±‚è¯­éŸ³ç‰¹å¾ä¸ä¸åŒå¼ºåº¦å’Œä¸åŒåŒºåŸŸçš„é¢éƒ¨æ´»åŠ¨ä¹‹é—´çš„æ—¶åºç›¸å…³æ€§ã€‚è¯¥æ¡†æ¶è€ƒè™‘äº†é¢éƒ¨æ´»åŠ¨å¼ºåº¦çš„å·®å¼‚ä»¥åŠä¸åŒå±‚æ¬¡è¯­éŸ³è¡¨å¾çš„å¼‚è´¨æ€§ã€‚åŠ æƒåˆ†å±‚ç‰¹å¾ç¼–ç å™¨æä¾›äº†ä¸€ç§äº’è¡¥ä¸”æœ‰æ•ˆçš„æœºåˆ¶æ¥å»ºç«‹è¯­éŸ³å’Œé¢éƒ¨æ´»åŠ¨ä¹‹é—´çš„ç›¸å…³æ€§ã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒä»¥åŠç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼ŒCorrTalk ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é¢éƒ¨æ´»åŠ¨å¼ºåº¦åº¦é‡æ¥åŒºåˆ†å¼ºå¼±é¢éƒ¨æ´»åŠ¨ï¼Œè¯¥åº¦é‡æ˜¯é€šè¿‡è®¡ç®—é¢éƒ¨é¡¶ç‚¹ä½ç§»çš„çŸ­æ—¶å‚…é‡Œå¶å˜æ¢è·å¾—çš„ã€‚</li>
<li>åŸºäºé¢éƒ¨æ´»åŠ¨çš„å˜åŒ–ï¼Œæå‡ºäº†ä¸€ç§åŒåˆ†æ”¯è§£ç æ¡†æ¶æ¥åŒæ­¥åˆæˆå¼ºå¼±é¢éƒ¨æ´»åŠ¨ï¼Œä»è€Œä¿è¯äº†æ›´å¹¿æ³›å¼ºåº¦çš„é¢éƒ¨åŠ¨ç”»åˆæˆã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŠ æƒåˆ†å±‚ç‰¹å¾ç¼–ç å™¨æ¥å»ºç«‹åˆ†å±‚è¯­éŸ³ç‰¹å¾ä¸ä¸åŒå¼ºåº¦ä¸‹çš„é¢éƒ¨æ´»åŠ¨ä¹‹é—´çš„æ—¶åºç›¸å…³æ€§ï¼Œä»è€Œç¡®ä¿å”‡å½¢åŒæ­¥å’Œåˆç†çš„é¢éƒ¨è¡¨æƒ…ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ VOCASET æ•°æ®é›†ä¸Šï¼ŒCorrTalk åœ¨å”‡å½¢åŒæ­¥ã€é¢éƒ¨è¡¨æƒ…å’Œæ•´ä½“è§†è§‰è´¨é‡æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>åœ¨ VoxCeleb æ•°æ®é›†ä¸Šï¼ŒCorrTalk åœ¨å”‡å½¢åŒæ­¥å’Œé¢éƒ¨è¡¨æƒ…æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>åœ¨ç”¨æˆ·ç ”ç©¶ä¸­ï¼ŒCorrTalk åœ¨å”‡å½¢åŒæ­¥ã€é¢éƒ¨è¡¨æƒ…å’Œæ•´ä½“è§†è§‰è´¨é‡æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•çš„å®ç°å¯èƒ½éœ€è¦å¤§é‡çš„ä»£ç å’Œå·¥ç¨‹å·¥ä½œã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d922178e56a58ce3c71b9f1423874fb1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-482c00c6ed52f71800345e13e8d77a81.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cab60223ad61f1d2129c598293c0da62.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4c347875935ebcaed314d4b9997f39ba.jpg" align="middle">
</details>




<h2 id="Mini-DALLE3-Interactive-Text-to-Image-by-Prompting-Large-Language-Models"><a href="#Mini-DALLE3-Interactive-Text-to-Image-by-Prompting-Large-Language-Models" class="headerlink" title="Mini-DALLE3: Interactive Text to Image by Prompting Large Language   Models"></a>Mini-DALLE3: Interactive Text to Image by Prompting Large Language   Models</h2><p><strong>Authors:Zeqiang Lai, Xizhou Zhu, Jifeng Dai, Yu Qiao, Wenhai Wang</strong></p>
<p>The revolution of artificial intelligence content generation has been rapidly accelerated with the booming text-to-image (T2I) diffusion models. Within just two years of development, it was unprecedentedly of high-quality, diversity, and creativity that the state-of-the-art models could generate. However, a prevalent limitation persists in the effective communication with these popular T2I models, such as Stable Diffusion, using natural language descriptions. This typically makes an engaging image hard to obtain without expertise in prompt engineering with complex word compositions, magic tags, and annotations. Inspired by the recently released DALLE3 - a T2I model directly built-in ChatGPT that talks human language, we revisit the existing T2I systems endeavoring to align human intent and introduce a new task - interactive text to image (iT2I), where people can interact with LLM for interleaved high-quality image generation/edit/refinement and question answering with stronger images and text correspondences using natural language. In addressing the iT2I problem, we present a simple approach that augments LLMs for iT2I with prompting techniques and off-the-shelf T2I models. We evaluate our approach for iT2I in a variety of common-used scenarios under different LLMs, e.g., ChatGPT, LLAMA, Baichuan, and InternLM. We demonstrate that our approach could be a convenient and low-cost way to introduce the iT2I ability for any existing LLMs and any text-to-image models without any training while bringing little degradation on LLMsâ€™ inherent capabilities in, e.g., question answering and code generation. We hope this work could draw broader attention and provide inspiration for boosting user experience in human-machine interactions alongside the image quality of the next-generation T2I systems. </p>
<p><a href="http://arxiv.org/abs/2310.07653v2">PDF</a> Technical report. Project page at <a href="https://minidalle3.github.io/">https://minidalle3.github.io/</a></p>
<p><strong>Summary</strong><br>é€šè¿‡å¢å¼º LLM ä¸ç°æœ‰æ–‡ç”Ÿå›¾æ¨¡å‹çš„äº¤äº’èƒ½åŠ›ï¼Œæå‡ºä¸€ç§æ–°çš„äº¤äº’å¼æ–‡æœ¬å›¾åƒç”Ÿæˆä»»åŠ¡ï¼Œæé«˜äº†äººæœºäº¤äº’çš„å›¾åƒè´¨é‡å’Œç”¨æˆ·ä½“éªŒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ–‡æœ¬åˆ°å›¾åƒ (T2I) æ‰©æ•£æ¨¡å‹çš„è“¬å‹ƒå‘å±•æå¤§åœ°åŠ é€Ÿäº†äººå·¥æ™ºèƒ½å†…å®¹ç”Ÿæˆçš„é©å‘½ã€‚</li>
<li>ç›®å‰æµè¡Œçš„ T2I æ¨¡å‹ï¼Œå¦‚ Stable Diffusionï¼Œåœ¨ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°æ—¶å­˜åœ¨æœ‰æ•ˆçš„æ²Ÿé€šéšœç¢ã€‚</li>
<li>å—åˆ°è¿‘æœŸå‘å¸ƒçš„ DALL-E3 æ¨¡å‹çš„å¯å‘ï¼Œè¯¥æ¨¡å‹ç›´æ¥å†…ç½® ChatGPT å¹¶ä½¿ç”¨äººç±»è¯­è¨€ï¼Œæˆ‘ä»¬é‡æ–°å®¡è§†ç°æœ‰ T2I ç³»ç»Ÿï¼ŒåŠªåŠ›å®ç°äººç±»æ„å›¾çš„ä¸€è‡´æ€§ï¼Œå¹¶æå‡ºä¸€ä¸ªæ–°ä»»åŠ¡â€”â€”äº¤äº’å¼æ–‡æœ¬åˆ°å›¾åƒ (iT2I)ï¼Œäººä»¬å¯ä»¥ä½¿ç”¨ LLM è¿›è¡Œäº¤ç»‡çš„é«˜è´¨é‡å›¾åƒç”Ÿæˆ/ç¼–è¾‘/ç»†åŒ–ï¼Œå¹¶ä½¿ç”¨è‡ªç„¶è¯­è¨€è¿›è¡Œé—®é¢˜å›ç­”ï¼Œä»è€Œè·å¾—æ›´å¼ºçš„å›¾åƒå’Œæ–‡æœ¬å¯¹åº”å…³ç³»ã€‚</li>
<li>ä¸ºäº†è§£å†³ iT2I é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•çš„æ–¹æ³•ï¼Œåˆ©ç”¨æç¤ºæŠ€æœ¯å’Œç°æˆçš„ T2I æ¨¡å‹æ¥å¢å¼º LLM çš„ iT2I èƒ½åŠ›ã€‚</li>
<li>æˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„ LLMï¼ˆå¦‚ ChatGPTã€LLAMAã€Baichuan å’Œ InternLMï¼‰åœ¨å„ç§å¸¸ç”¨åœºæ™¯ä¸‹è¯„ä¼°äº†æˆ‘ä»¬çš„ iT2I æ–¹æ³•ã€‚</li>
<li>æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ–¹ä¾¿ä¸”ä½æˆæœ¬åœ°ä¸ºä»»ä½•ç°æœ‰çš„ LLM å’Œä»»ä½•æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å¼•å…¥ iT2I èƒ½åŠ›ï¼Œè€Œæ— éœ€ä»»ä½•åŸ¹è®­ï¼ŒåŒæ—¶å¯¹ LLM åœ¨é—®é¢˜å›ç­”å’Œä»£ç ç”Ÿæˆç­‰æ–¹é¢çš„å›ºæœ‰èƒ½åŠ›å‡ ä¹æ²¡æœ‰å½±å“ã€‚</li>
<li>æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œèƒ½å¤Ÿå¼•èµ·æ›´å¹¿æ³›çš„å…³æ³¨ï¼Œå¹¶ä¸ºæå‡ä¸‹ä¸€ä»£ T2I ç³»ç»Ÿçš„å›¾åƒè´¨é‡å’Œäººæœºäº¤äº’çš„ç”¨æˆ·ä½“éªŒæä¾›çµæ„Ÿã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šäº¤äº’å¼å›¾åƒç”Ÿæˆæ•…äº‹æ¦‚å¿µåŸå‹äº¤äº’å¼ Logo è®¾è®¡</li>
<li>ä½œè€…ï¼šT2IModel, StableDiffusionXL</li>
<li>å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šäº¤äº’å¼å›¾åƒç”Ÿæˆã€æ•…äº‹æ¦‚å¿µåŸå‹ã€äº¤äº’å¼ Logo è®¾è®¡</li>
<li>é“¾æ¥ï¼šæ— ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šéšç€äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•ï¼Œäº¤äº’å¼å›¾åƒç”ŸæˆæŠ€æœ¯é€æ¸æˆç†Ÿï¼Œä¸ºäººä»¬æä¾›äº†æ–°çš„åˆ›ä½œæ–¹å¼ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸éœ€è¦ç”¨æˆ·å…·å¤‡ä¸€å®šçš„ä¸“ä¸šçŸ¥è¯†å’ŒæŠ€èƒ½ï¼Œå¹¶ä¸”ç”Ÿæˆç»“æœå¾€å¾€ä¸å¤Ÿä»¤äººæ»¡æ„ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„äº¤äº’å¼å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…è®¸ç”¨æˆ·é€šè¿‡ç®€å•çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥ç”Ÿæˆå›¾åƒï¼Œå¹¶ä¸”ç”Ÿæˆçš„å›¾åƒè´¨é‡è¾ƒé«˜ã€‚
(4)ï¼šè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ”¯æŒç”¨æˆ·ç”Ÿæˆå„ç§å„æ ·çš„å›¾åƒã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§äº¤äº’å¼æ–‡æœ¬åˆ°å›¾åƒï¼ˆiT2Iï¼‰çš„æ¦‚å¿µï¼Œå¹¶æå‡ºäº†ä¸€ç§å¢å¼ºç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ä»¥å®Œæˆæ­¤ä»»åŠ¡çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿå®ç°ä¾¿æ·çš„ iT2I åŠŸèƒ½ï¼Œè€Œä¸ä¼šæ˜¾è‘—é™ä½æ¨¡å‹å›ºæœ‰çš„èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œæœ‰å¯èƒ½å¢å¼ºäººæœºäº¤äº’ä¸­çš„ç”¨æˆ·ä½“éªŒï¼Œå¹¶æå‡ä¸‹ä¸€ä»£ T2I æ¨¡å‹çš„å›¾åƒè´¨é‡ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶å’Œå‘å±•æä¾›äº†æœ‰å¸Œæœ›çš„æ–¹å‘ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°çš„äº¤äº’å¼å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å…è®¸ç”¨æˆ·é€šè¿‡ç®€å•çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ¥ç”Ÿæˆå›¾åƒï¼Œå¹¶ä¸”ç”Ÿæˆçš„å›¾åƒè´¨é‡è¾ƒé«˜ã€‚
æ€§èƒ½ï¼š
è¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ”¯æŒç”¨æˆ·ç”Ÿæˆå„ç§å„æ ·çš„å›¾åƒã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å¤šç§å¹³å°ä¸Šè¿è¡Œã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-3792d852f31bc708a2cea9f03355bb97.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6afd19703c3d90bc25da231ed316facd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-67bff90f67e33e05a8dc4330ebea5ab0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-67ec55466a5a0a886f9c4fced2ca756a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0f4f4599995309681f54e1a3473d5606.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8f8385b3f282787527483626a5982157.jpg" align="middle">
</details>




<h2 id="AdaMesh-Personalized-Facial-Expressions-and-Head-Poses-for-Adaptive-Speech-Driven-3D-Facial-Animation"><a href="#AdaMesh-Personalized-Facial-Expressions-and-Head-Poses-for-Adaptive-Speech-Driven-3D-Facial-Animation" class="headerlink" title="AdaMesh: Personalized Facial Expressions and Head Poses for Adaptive   Speech-Driven 3D Facial Animation"></a>AdaMesh: Personalized Facial Expressions and Head Poses for Adaptive   Speech-Driven 3D Facial Animation</h2><p><strong>Authors:Liyang Chen, Weihong Bao, Shun Lei, Boshi Tang, Zhiyong Wu, Shiyin Kang, Haozhi Huang</strong></p>
<p>Speech-driven 3D facial animation aims at generating facial movements that are synchronized with the driving speech, which has been widely explored recently. Existing works mostly neglect the person-specific talking style in generation, including facial expression and head pose styles. Several works intend to capture the personalities by fine-tuning modules. However, limited training data leads to the lack of vividness. In this work, we propose AdaMesh, a novel adaptive speech-driven facial animation approach, which learns the personalized talking style from a reference video of about 10 seconds and generates vivid facial expressions and head poses. Specifically, we propose mixture-of-low-rank adaptation (MoLoRA) to fine-tune the expression adapter, which efficiently captures the facial expression style. For the personalized pose style, we propose a pose adapter by building a discrete pose prior and retrieving the appropriate style embedding with a semantic-aware pose style matrix without fine-tuning. Extensive experimental results show that our approach outperforms state-of-the-art methods, preserves the talking style in the reference video, and generates vivid facial animation. The supplementary video and code will be available at <a href="https://adamesh.github.io">https://adamesh.github.io</a>. </p>
<p><a href="http://arxiv.org/abs/2310.07236v2">PDF</a> Project Page: <a href="https://adamesh.github.io">https://adamesh.github.io</a></p>
<p><strong>Summary</strong><br>AdaMesh æ˜¯ä¸€ç§æ–°é¢–çš„è‡ªé€‚åº”è¯­éŸ³é©±åŠ¨é¢éƒ¨åŠ¨ç”»æ–¹æ³•ï¼Œé€šè¿‡å­¦ä¹ çº¦ 10 ç§’çš„å‚è€ƒè§†é¢‘æ¥å­¦ä¹ ä¸ªæ€§åŒ–è¯´è¯é£æ ¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>AdaMesh æ˜¯ä¸€ç§æ–°é¢–çš„è¯­éŸ³é©±åŠ¨çš„äººè„¸åŠ¨ç”»æ–¹æ³•ï¼Œå®ƒå­¦ä¹ ä¸ªæ€§åŒ–çš„è¯´è¯é£æ ¼ï¼Œå¹¶ç”Ÿæˆç”ŸåŠ¨çš„é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚</li>
<li>AdaMesh ä½¿ç”¨æ··åˆä½ç§©è‡ªé€‚åº” (MoLoRA) æ¥å¾®è°ƒè¡¨æƒ…é€‚é…å™¨ï¼Œæœ‰æ•ˆåœ°æ•è·é¢éƒ¨è¡¨æƒ…é£æ ¼ã€‚</li>
<li>AdaMesh ä¸ºä¸ªæ€§åŒ–å§¿åŠ¿é£æ ¼æ„å»ºç¦»æ•£å§¿åŠ¿å…ˆéªŒï¼Œå¹¶é€šè¿‡å…·æœ‰è¯­ä¹‰æ„ŸçŸ¥çš„å§¿åŠ¿é£æ ¼çŸ©é˜µæ£€ç´¢é€‚å½“çš„é£æ ¼åµŒå…¥ï¼Œè€Œæ— éœ€å¾®è°ƒã€‚</li>
<li>AdaMesh åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œä¿ç•™äº†å‚è€ƒè§†é¢‘ä¸­çš„è¯´è¯é£æ ¼ï¼Œå¹¶ç”Ÿæˆç”ŸåŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>AdaMesh çš„ä»£ç å’Œè¡¥å……è§†é¢‘å¯åœ¨ç½‘ç«™ä¸Šæ‰¾åˆ°ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šAdaMeshï¼šä¸ªæ€§åŒ–é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿çš„è‡ªé€‚åº”è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»</li>
<li>ä½œè€…ï¼šLiyang Chen, Weihong Bao, Shun Lei, Boshi Tang, Zhiyong Wu, Shiyin Kang, Haozhi Huang</li>
<li>éš¶å±æœºæ„ï¼šæ·±åœ³å›½é™…ç ”ç©¶ç”Ÿé™¢ï¼Œæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šé¢éƒ¨åŠ¨ç”»ã€è¯­éŸ³é©±åŠ¨ã€ä¸ªæ€§åŒ–ã€è‡ªé€‚åº”ã€æ··åˆä½ç§©è‡ªé€‚åº”</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2310.07236v2ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»æ—¨åœ¨ç”Ÿæˆä¸é©±åŠ¨è¯­éŸ³åŒæ­¥çš„é¢éƒ¨åŠ¨ä½œï¼Œè¯¥æŠ€æœ¯åœ¨è™šæ‹Ÿç°å®ã€ç”µå½±åˆ¶ä½œå’Œæ¸¸æˆåˆ›ä½œä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚ä»¥å¾€å¤§å¤šæ•°å·¥ä½œä¾§é‡äºæé«˜è¯­éŸ³ä¸å”‡éƒ¨åŠ¨ä½œçš„åŒæ­¥æ€§ï¼Œè€Œå¿½ç•¥äº†åŒ…æ‹¬é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿åœ¨å†…çš„ä¸ªæ€§åŒ–è¯´è¯é£æ ¼ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šä¸€äº›ç ”ç©¶å°è¯•é€šè¿‡å¾®è°ƒæˆ–è‡ªé€‚åº”æ¨¡å—æ¥å»ºæ¨¡ç‰¹å®šäººç‰©çš„è¯´è¯é£æ ¼ã€‚ç„¶è€Œï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œç›®æ ‡ç”¨æˆ·ä»…æä¾›å°‘é‡è§†é¢‘ç‰‡æ®µï¼ˆç”šè‡³çŸ­äº 1 åˆ†é’Ÿï¼‰æ¥æ•æ‰ä¸ªæ€§åŒ–çš„è¯´è¯é£æ ¼ã€‚è¿™äº›æ–¹æ³•å› æ­¤é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼š</li>
<li>1) å¾ˆå°‘çš„è‡ªé€‚åº”æ•°æ®å¯èƒ½ä¼šå¯¼è‡´é¢„è®­ç»ƒæ¨¡å‹å‘ç”Ÿç¾éš¾æ€§é—å¿˜ï¼Œå¹¶å®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆé—®é¢˜ã€‚</li>
<li>2) è¯­éŸ³æ˜¯å¤´éƒ¨å§¿åŠ¿çš„å¼±æ§åˆ¶ä¿¡å·ã€‚åœ¨å¦‚æ­¤å¼±çš„ä¿¡å·ä¸Šè¿›è¡Œè‡ªé€‚åº”æˆ–å­¦ä¹ æ˜ å°„ä¼šå¯¼è‡´ç”Ÿæˆç»“æœè¶‹äºå¹³å‡ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º AdaMeshï¼Œä¸€ç§æ–°é¢–çš„è‡ªé€‚åº”è¯­éŸ³é©±åŠ¨é¢éƒ¨åŠ¨ç”»æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä»çº¦ 10 ç§’çš„å‚è€ƒè§†é¢‘ä¸­å­¦ä¹ ä¸ªæ€§åŒ–çš„è¯´è¯é£æ ¼ï¼Œå¹¶ç”Ÿæˆç”ŸåŠ¨çš„é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡æå‡ºæ··åˆä½ç§©è‡ªé€‚åº” (MoLoRA) æ¥å¾®è°ƒè¡¨æƒ…é€‚é…å™¨ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°æ•æ‰äº†é¢éƒ¨è¡¨æƒ…é£æ ¼ã€‚å¯¹äºä¸ªæ€§åŒ–çš„å§¿åŠ¿é£æ ¼ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å§¿åŠ¿é€‚é…å™¨ï¼Œé€šè¿‡æ„å»ºç¦»æ•£å§¿åŠ¿å…ˆéªŒå¹¶ä½¿ç”¨è¯­ä¹‰æ„ŸçŸ¥å§¿åŠ¿é£æ ¼çŸ©é˜µæ£€ç´¢é€‚å½“çš„é£æ ¼åµŒå…¥ï¼Œæ— éœ€å¾®è°ƒã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šå¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¿ç•™äº†å‚è€ƒè§†é¢‘ä¸­çš„è¯´è¯é£æ ¼ï¼Œå¹¶ç”Ÿæˆäº†ç”ŸåŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„è¯­éŸ³é©±åŠ¨é¢éƒ¨åŠ¨ç”»æ–¹æ³• AdaMeshï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä»çº¦ 10 ç§’çš„å‚è€ƒè§†é¢‘ä¸­å­¦ä¹ ä¸ªæ€§åŒ–çš„è¯´è¯é£æ ¼ï¼Œå¹¶ç”Ÿæˆç”ŸåŠ¨çš„é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºæ··åˆä½ç§©è‡ªé€‚åº” (MoLoRA) æ¥å¾®è°ƒè¡¨æƒ…é€‚é…å™¨ï¼Œæœ‰æ•ˆåœ°æ•æ‰äº†é¢éƒ¨è¡¨æƒ…é£æ ¼ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å§¿åŠ¿é€‚é…å™¨ï¼Œé€šè¿‡æ„å»ºç¦»æ•£å§¿åŠ¿å…ˆéªŒå¹¶ä½¿ç”¨è¯­ä¹‰æ„ŸçŸ¥å§¿åŠ¿é£æ ¼çŸ©é˜µæ£€ç´¢é€‚å½“çš„é£æ ¼åµŒå…¥ï¼Œæ— éœ€å¾®è°ƒã€‚</li>
<li>å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒAdaMesh ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¿ç•™äº†å‚è€ƒè§†é¢‘ä¸­çš„è¯´è¯é£æ ¼ï¼Œå¹¶ç”Ÿæˆäº†ç”ŸåŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚
æ€§èƒ½ï¼š</li>
<li>AdaMesh èƒ½å¤Ÿä»çº¦ 10 ç§’çš„å‚è€ƒè§†é¢‘ä¸­å­¦ä¹ ä¸ªæ€§åŒ–çš„è¯´è¯é£æ ¼ï¼Œå¹¶ç”Ÿæˆç”ŸåŠ¨çš„é¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿ã€‚</li>
<li>AdaMesh ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¿ç•™äº†å‚è€ƒè§†é¢‘ä¸­çš„è¯´è¯é£æ ¼ï¼Œå¹¶ç”Ÿæˆäº†ç”ŸåŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚
å·¥ä½œé‡ï¼š</li>
<li>AdaMesh çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹ç®€å•ï¼Œåªéœ€è¦çº¦ 10 ç§’çš„å‚è€ƒè§†é¢‘å³å¯ã€‚</li>
<li>AdaMesh çš„æ¨ç†è¿‡ç¨‹ä¹Ÿç›¸å¯¹ç®€å•ï¼Œåªéœ€è¦è¾“å…¥è¯­éŸ³ä¿¡å·å³å¯ç”Ÿæˆé¢éƒ¨åŠ¨ç”»ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e2c325c4c46442c62d649aa8c3b3382d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-21344205a1b26e05a0603dc168a71d7a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a107bec6acd460840a8823d7bfd305da.jpg" align="middle">
</details>




<h2 id="GestSync-Determining-who-is-speaking-without-a-talking-head"><a href="#GestSync-Determining-who-is-speaking-without-a-talking-head" class="headerlink" title="GestSync: Determining who is speaking without a talking head"></a>GestSync: Determining who is speaking without a talking head</h2><p><strong>Authors:Sindhu B Hegde, Andrew Zisserman</strong></p>
<p>In this paper we introduce a new synchronisation task, Gesture-Sync: determining if a personâ€™s gestures are correlated with their speech or not. In comparison to Lip-Sync, Gesture-Sync is far more challenging as there is a far looser relationship between the voice and body movement than there is between voice and lip motion. We introduce a dual-encoder model for this task, and compare a number of input representations including RGB frames, keypoint images, and keypoint vectors, assessing their performance and advantages. We show that the model can be trained using self-supervised learning alone, and evaluate its performance on the LRS3 dataset. Finally, we demonstrate applications of Gesture-Sync for audio-visual synchronisation, and in determining who is the speaker in a crowd, without seeing their faces. The code, datasets and pre-trained models can be found at: \url{<a href="https://www.robots.ox.ac.uk/~vgg/research/gestsync}">https://www.robots.ox.ac.uk/~vgg/research/gestsync}</a>. </p>
<p><a href="http://arxiv.org/abs/2310.05304v1">PDF</a> Accepted in BMVC 2023, 10 pages paper, 7 pages supplementary, 7   Figures</p>
<p><strong>æ‘˜è¦</strong><br>è¯­éŸ³åŒæ­¥æ–°ä»»åŠ¡â€”â€”Gesture-Syncï¼šåˆ¤æ–­ä¸€ä¸ªäººçš„æ‰‹åŠ¿æ˜¯å¦ä¸ä»–çš„è®²è¯ç›¸å…³ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>Gesture-Sync æ˜¯ä¸€ä¸ªå…¨æ–°çš„åŒæ­¥ä»»åŠ¡ï¼Œæ—¨åœ¨ç¡®å®šä¸€ä¸ªäººçš„æ‰‹åŠ¿æ˜¯å¦ä¸å…¶è®²è¯ç›¸å…³ã€‚</li>
<li>ä¸å”‡è¯­åŒæ­¥ç›¸æ¯”ï¼Œæ‰‹åŠ¿åŒæ­¥æ›´å…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå£°éŸ³å’Œèº«ä½“è¿åŠ¨ä¹‹é—´çš„å…³ç³»æ¯”å£°éŸ³å’Œå˜´å”‡è¿åŠ¨ä¹‹é—´çš„å…³ç³»æ¾æ•£å¾—å¤šã€‚</li>
<li>æ–‡ä¸­æå‡ºäº†ä¸€ç§ç”¨äºæ­¤ä»»åŠ¡çš„åŒç¼–ç å™¨æ¨¡å‹ï¼Œå¹¶æ¯”è¾ƒäº†å‡ ç§è¾“å…¥è¡¨ç¤ºï¼ŒåŒ…æ‹¬ RGB å¸§ã€å…³é”®ç‚¹å›¾åƒå’Œå…³é”®ç‚¹å‘é‡ï¼Œè¯„ä¼°å®ƒä»¬çš„æ€§èƒ½å’Œä¼˜åŠ¿ã€‚</li>
<li>è¯¥æ¨¡å‹ä»…ä½¿ç”¨è‡ªæˆ‘ç›‘ç£å­¦ä¹ å°±å¯ä»¥è®­ç»ƒï¼Œå¹¶åœ¨ LRS3 æ•°æ®é›†ä¸Šè¯„ä¼°äº†å…¶æ€§èƒ½ã€‚</li>
<li>æœ€åï¼Œæ¼”ç¤ºäº† Gesture-Sync åœ¨è§†å¬åŒæ­¥ä»¥åŠç¡®å®šäººç¾¤ä¸­è¯´è¯è€…ï¼ˆä¸çœ‹ä»–ä»¬çš„è„¸ï¼‰æ–¹é¢çš„åº”ç”¨ã€‚</li>
<li>ä»£ç ã€æ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹å¯åœ¨ä»¥ä¸‹ç½‘å€æ‰¾åˆ°ï¼š<a href="https://www.robots.ox.ac.uk/~vgg/research/gestsync">https://www.robots.ox.ac.uk/~vgg/research/gestsyncã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šæ‰‹åŠ¿åŒæ­¥ï¼šç¡®å®šè°åœ¨è¯´è¯ï¼Œè€Œæ— éœ€è¯´è¯çš„å¤´éƒ¨</li>
<li>ä½œè€…ï¼šSindhu B Hegdeï¼ŒAndrew Zisserman</li>
<li>éš¶å±å…³ç³»ï¼šç‰›æ´¥å¤§å­¦å·¥ç¨‹ç§‘å­¦ç³»è§†è§‰å‡ ä½•ç»„</li>
<li>å…³é”®è¯ï¼šæ‰‹åŠ¿åŒæ­¥ã€å”‡å½¢åŒæ­¥ã€è‡ªæˆ‘ç›‘ç£å­¦ä¹ ã€å¤šæ¨¡æ€å­¦ä¹ ã€è¯´è¯äººè¯†åˆ«</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2310.05304ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåœ¨äººæœºäº¤äº’å’Œå¤šåª’ä½“å¤„ç†ä¸­ï¼Œå‡†ç¡®è¯†åˆ«è¯´è¯äººå¯¹äºç†è§£å’Œå“åº”äººç±»è¯­è¨€è‡³å…³é‡è¦ã€‚ä¼ ç»Ÿçš„è¯´è¯äººè¯†åˆ«æ–¹æ³•ä¸»è¦ä¾èµ–äºå”‡å½¢åŒæ­¥ï¼Œå³é€šè¿‡åˆ†æè¯´è¯äººçš„å˜´å”‡è¿åŠ¨æ¥ç¡®å®šè¯´è¯äººã€‚ç„¶è€Œï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¾‹å¦‚å½“è¯´è¯äººçš„è„¸éƒ¨è¢«é®æŒ¡æˆ–è¯´è¯äººåœ¨å˜ˆæ‚çš„ç¯å¢ƒä¸­æ—¶ï¼Œå”‡å½¢åŒæ­¥æ–¹æ³•å¯èƒ½ä¼šå¤±æ•ˆã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šä¸ºäº†è§£å†³å”‡å½¢åŒæ­¥çš„å±€é™æ€§ï¼Œä¸€äº›ç ”ç©¶äººå‘˜æå‡ºäº†æ‰‹åŠ¿åŒæ­¥çš„æ–¹æ³•ï¼Œå³é€šè¿‡åˆ†æè¯´è¯äººçš„æ‰‹åŠ¿è¿åŠ¨æ¥ç¡®å®šè¯´è¯äººã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ‰‹åŠ¿åŒæ­¥æ–¹æ³•å¤§å¤šä¾èµ–äºç›‘ç£å­¦ä¹ ï¼Œéœ€è¦å¤§é‡å¸¦æ ‡ç­¾çš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚è¿™åœ¨å®é™…åº”ç”¨ä¸­å¾€å¾€éš¾ä»¥è·å¾—ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³æ‰‹åŠ¿åŒæ­¥ä¸­æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ‰‹åŠ¿åŒæ­¥æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥åˆ©ç”¨è‡ªæˆ‘ç›‘ç£å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•é€šè¿‡å­¦ä¹ æ‰‹åŠ¿å’Œè¯­éŸ³ä¹‹é—´çš„ç›¸å…³æ€§æ¥ç¡®å®šè¯´è¯äººã€‚è¯¥æ–¹æ³•é‡‡ç”¨åŒç¼–ç å™¨æ¨¡å‹ï¼Œå…¶ä¸­ä¸€ä¸ªç¼–ç å™¨å°†æ‰‹åŠ¿å›¾åƒæˆ–å…³é”®ç‚¹å‘é‡ç¼–ç æˆåµŒå…¥å‘é‡ï¼Œå¦ä¸€ä¸ªç¼–ç å™¨å°†è¯­éŸ³ä¿¡å·ç¼–ç æˆåµŒå…¥å‘é‡ã€‚ç„¶åï¼Œé€šè¿‡è®¡ç®—ä¸¤ä¸ªåµŒå…¥å‘é‡ä¹‹é—´çš„ç›¸ä¼¼æ€§æ¥ç¡®å®šè¯´è¯äººã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šä¸ºäº†è¯„ä¼°æ‰€æå‡ºæ–¹æ³•çš„æ€§èƒ½ï¼Œæœ¬æ–‡åœ¨ LRS3 æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯´è¯äººè¯†åˆ«ä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºéŸ³é¢‘-è§†è§‰åŒæ­¥å’Œç¡®å®šäººç¾¤ä¸­è°åœ¨è¯´è¯ï¼Œè€Œæ— éœ€çœ‹åˆ°ä»–ä»¬çš„è„¸ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰åŒç¼–ç å™¨æ¨¡å‹ï¼šè¯¥æ–¹æ³•é‡‡ç”¨åŒç¼–ç å™¨æ¨¡å‹ï¼Œå…¶ä¸­ä¸€ä¸ªç¼–ç å™¨å°†æ‰‹åŠ¿å›¾åƒæˆ–å…³é”®ç‚¹å‘é‡ç¼–ç æˆåµŒå…¥å‘é‡ï¼Œå¦ä¸€ä¸ªç¼–ç å™¨å°†è¯­éŸ³ä¿¡å·ç¼–ç æˆåµŒå…¥å‘é‡ã€‚
ï¼ˆ2ï¼‰æ‰‹åŠ¿å’Œè¯­éŸ³ä¹‹é—´çš„ç›¸å…³æ€§å­¦ä¹ ï¼šé€šè¿‡å­¦ä¹ æ‰‹åŠ¿å’Œè¯­éŸ³ä¹‹é—´çš„ç›¸å…³æ€§æ¥ç¡®å®šè¯´è¯äººã€‚
ï¼ˆ3ï¼‰è®¡ç®—åµŒå…¥å‘é‡ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼šé€šè¿‡è®¡ç®—ä¸¤ä¸ªåµŒå…¥å‘é‡ä¹‹é—´çš„ç›¸ä¼¼æ€§æ¥ç¡®å®šè¯´è¯äººã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ‰‹åŠ¿åŒæ­¥æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥åˆ©ç”¨è‡ªæˆ‘ç›‘ç£å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œè§£å†³äº†æ‰‹åŠ¿åŒæ­¥ä¸­æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>åˆ©ç”¨è‡ªæˆ‘ç›‘ç£å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œæ— éœ€å¤§é‡å¸¦æ ‡ç­¾çš„æ•°æ®ã€‚</li>
<li>é‡‡ç”¨åŒç¼–ç å™¨æ¨¡å‹ï¼Œå­¦ä¹ æ‰‹åŠ¿å’Œè¯­éŸ³ä¹‹é—´çš„ç›¸å…³æ€§ã€‚</li>
<li>é€šè¿‡è®¡ç®—åµŒå…¥å‘é‡ä¹‹é—´çš„ç›¸ä¼¼æ€§æ¥ç¡®å®šè¯´è¯äººã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨LRS3æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯´è¯äººè¯†åˆ«ä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºéŸ³é¢‘-è§†è§‰åŒæ­¥å’Œç¡®å®šäººç¾¤ä¸­è°åœ¨è¯´è¯ï¼Œè€Œæ— éœ€çœ‹åˆ°ä»–ä»¬çš„è„¸ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºéƒ¨ç½²ã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒæ—¶é—´è¾ƒçŸ­ï¼Œå¯ä»¥åœ¨åˆç†çš„æ—¶é—´å†…å®Œæˆã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ce1c5e581126af42846fa6a80d1504c1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5e94dc122da890162c1017d072a1cfcc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c91edb80b044a859328ba0905835ad6.jpg" align="middle">
</details>




<h2 id="DiffPoseTalk-Speech-Driven-Stylistic-3D-Facial-Animation-and-Head-Pose-Generation-via-Diffusion-Models"><a href="#DiffPoseTalk-Speech-Driven-Stylistic-3D-Facial-Animation-and-Head-Pose-Generation-via-Diffusion-Models" class="headerlink" title="DiffPoseTalk: Speech-Driven Stylistic 3D Facial Animation and Head Pose   Generation via Diffusion Models"></a>DiffPoseTalk: Speech-Driven Stylistic 3D Facial Animation and Head Pose   Generation via Diffusion Models</h2><p><strong>Authors:Zhiyao Sun, Tian Lv, Sheng Ye, Matthieu Gaetan Lin, Jenny Sheng, Yu-Hui Wen, Minjing Yu, Yong-jin Liu</strong></p>
<p>The generation of stylistic 3D facial animations driven by speech poses a significant challenge as it requires learning a many-to-many mapping between speech, style, and the corresponding natural facial motion. However, existing methods either employ a deterministic model for speech-to-motion mapping or encode the style using a one-hot encoding scheme. Notably, the one-hot encoding approach fails to capture the complexity of the style and thus limits generalization ability. In this paper, we propose DiffPoseTalk, a generative framework based on the diffusion model combined with a style encoder that extracts style embeddings from short reference videos. During inference, we employ classifier-free guidance to guide the generation process based on the speech and style. We extend this to include the generation of head poses, thereby enhancing user perception. Additionally, we address the shortage of scanned 3D talking face data by training our model on reconstructed 3DMM parameters from a high-quality, in-the-wild audio-visual dataset. Our extensive experiments and user study demonstrate that our approach outperforms state-of-the-art methods. The code and dataset will be made publicly available. </p>
<p><a href="http://arxiv.org/abs/2310.00434v1">PDF</a> Project page: <a href="https://raineggplant.github.io/DiffPoseTalk/">https://raineggplant.github.io/DiffPoseTalk/</a></p>
<p><strong>æ‘˜è¦</strong><br>æ‰©æ•£æ¨¡å‹ç»“åˆé£æ ¼ç¼–ç å™¨å®ç°è¯­éŸ³é©±åŠ¨çš„é«˜è´¨é‡ã€å¤šæ ·åŒ–ä¸‰ç»´åŠ¨æ€äººè„¸ç”Ÿæˆã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œé£æ ¼ç¼–ç å™¨çš„è¯­éŸ³é©±åŠ¨ä¸‰ç»´åŠ¨æ€äººè„¸ç”Ÿæˆæ¡†æ¶ DiffPoseTalkã€‚</li>
<li>é£æ ¼ç¼–ç å™¨é€šè¿‡ä»çŸ­å‚è€ƒè§†é¢‘ä¸­æå–é£æ ¼åµŒå…¥æ¥æ•æ‰é£æ ¼çš„å¤æ‚æ€§ã€‚</li>
<li>åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨æ— åˆ†ç±»å™¨å¼•å¯¼æ ¹æ®è¯­éŸ³å’Œé£æ ¼å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚</li>
<li>æ‰©å±•è¯¥æ¡†æ¶ä»¥ç”Ÿæˆå¤´éƒ¨å§¿åŠ¿ï¼Œä»è€Œå¢å¼ºç”¨æˆ·æ„ŸçŸ¥ã€‚</li>
<li>é€šè¿‡åœ¨é«˜è´¨é‡çš„è‡ªç„¶ç¯å¢ƒä¸‹çš„éŸ³é¢‘-è§†è§‰æ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè§£å†³äº†æ‰«æä¸‰ç»´è¯´è¯äººè„¸æ•°æ®çŸ­ç¼ºçš„é—®é¢˜ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>ä»£ç å’Œæ•°æ®é›†å°†å…¬å¼€å‘å¸ƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šDiffPoseTalkï¼šé€šè¿‡æ‰©æ•£æ¨¡å‹å’Œå¤´éƒ¨å§¿åŠ¿ç”Ÿæˆè¯­éŸ³é©±åŠ¨çš„é£æ ¼åŒ– 3D é¢éƒ¨åŠ¨ç”»</li>
<li>ä½œè€…ï¼šå­™å¿—å°§ã€å•å¤©ã€å¶ç››ã€æ—é©¬ä¿®Â·ç›–å¦ã€ç›› Jennyã€æ¸©å®‡è¾‰ã€ä¿æ•æ™¶ã€åˆ˜æ°¸è¿›</li>
<li>éš¶å±æœºæ„ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šè¯­éŸ³é©±åŠ¨ã€3D é¢éƒ¨åŠ¨ç”»ã€æ‰©æ•£æ¨¡å‹ã€é£æ ¼åŒ–ã€å¤´éƒ¨å§¿åŠ¿</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2310.00434
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»æ˜¯ä¸€é¡¹æå…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºå®ƒéœ€è¦å­¦ä¹ è¯­éŸ³ã€é£æ ¼å’Œç›¸åº”è‡ªç„¶é¢éƒ¨åŠ¨ä½œä¹‹é—´çš„å¤šå¯¹å¤šæ˜ å°„ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•è¦ä¹ˆé‡‡ç”¨ç¡®å®šæ€§æ¨¡å‹è¿›è¡Œè¯­éŸ³åˆ°åŠ¨ä½œçš„æ˜ å°„ï¼Œè¦ä¹ˆä½¿ç”¨ç‹¬çƒ­ç¼–ç æ–¹æ¡ˆå¯¹é£æ ¼è¿›è¡Œç¼–ç ã€‚ç‹¬çƒ­ç¼–ç æ–¹æ³•æ— æ³•æ•æ‰é£æ ¼çš„å¤æ‚æ€§ï¼Œä»è€Œé™åˆ¶äº†æ³›åŒ–èƒ½åŠ›ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º DiffPoseTalkï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ¡†æ¶ï¼Œç»“åˆäº†ä¸€ä¸ªä»çŸ­å‚è€ƒè§†é¢‘ä¸­æå–é£æ ¼åµŒå…¥çš„é£æ ¼ç¼–ç å™¨ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼æ¥æ ¹æ®è¯­éŸ³å’Œé£æ ¼æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚æˆ‘ä»¬å°†å…¶æ‰©å±•åˆ°åŒ…æ‹¬å¤´éƒ¨å§¿åŠ¿çš„ç”Ÿæˆï¼Œä»è€Œå¢å¼ºç”¨æˆ·æ„ŸçŸ¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨ä»é«˜è´¨é‡é‡å¤–è§†å¬æ•°æ®é›†é‡å»ºçš„ 3DMM å‚æ•°ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè§£å†³äº†æ‰«æ 3D è¯´è¯é¢éƒ¨æ•°æ®çš„çŸ­ç¼ºé—®é¢˜ã€‚
ï¼ˆ4ï¼‰æ€§èƒ½ä¸ç›®æ ‡ï¼šæˆ‘ä»¬çš„å¹¿æ³›å®éªŒå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æ‰©æ•£æ¨¡å‹ï¼šæˆ‘ä»¬ä½¿ç”¨æ‰©æ•£æ¨¡å‹ä½œä¸ºç”Ÿæˆæ¡†æ¶ï¼Œå°†è¯­éŸ³å’Œé£æ ¼æŒ‡å¯¼æ˜ å°„åˆ°3Dé¢éƒ¨åŠ¨ç”»ã€‚æ‰©æ•£æ¨¡å‹é€šè¿‡é€æ¸å¢åŠ å™ªå£°æ¥å°†æ•°æ®ä»å·²çŸ¥çŠ¶æ€è½¬æ¢åˆ°éšæœºçŠ¶æ€ï¼Œç„¶åé€šè¿‡åå‘è¿‡ç¨‹ä»å™ªå£°ä¸­æ¢å¤æ•°æ®ã€‚
(2) é£æ ¼ç¼–ç å™¨ï¼šæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé£æ ¼ç¼–ç å™¨ï¼Œä»çŸ­å‚è€ƒè§†é¢‘ä¸­æå–é£æ ¼åµŒå…¥ã€‚é£æ ¼ç¼–ç å™¨ç”±ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œç»„æˆï¼Œå®ƒå°†è§†é¢‘å¸§ç¼–ç ä¸ºä¸€ä¸ªé£æ ¼å‘é‡ã€‚
(3) æ— åˆ†ç±»å™¨æŒ‡å¯¼ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼æ¥æ ¹æ®è¯­éŸ³å’Œé£æ ¼æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚æ— åˆ†ç±»å™¨æŒ‡å¯¼é€šè¿‡æœ€å°åŒ–ç”Ÿæˆæ•°æ®ä¸ç›®æ ‡æ•°æ®ä¹‹é—´çš„è·ç¦»æ¥è®­ç»ƒæ¨¡å‹ã€‚
(4) å¤´éƒ¨å§¿åŠ¿ç”Ÿæˆï¼šæˆ‘ä»¬å°†æ¨¡å‹æ‰©å±•åˆ°åŒ…æ‹¬å¤´éƒ¨å§¿åŠ¿çš„ç”Ÿæˆï¼Œä»è€Œå¢å¼ºç”¨æˆ·æ„ŸçŸ¥ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé¢å¤–çš„ç½‘ç»œæ¥é¢„æµ‹å¤´éƒ¨å§¿åŠ¿ï¼Œå¹¶å°†å…¶ä½œä¸ºè¾“å…¥æ·»åŠ åˆ°ç”Ÿæˆæ¨¡å‹ä¸­ã€‚
(5) æ•°æ®é›†ï¼šæˆ‘ä»¬ä½¿ç”¨ä»é«˜è´¨é‡é‡å¤–è§†å¬æ•°æ®é›†é‡å»ºçš„3DMMå‚æ•°æ¥è®­ç»ƒæ¨¡å‹ã€‚è¯¥æ•°æ®é›†åŒ…å«äº†å„ç§è¯´è¯è€…çš„3Dé¢éƒ¨æ‰«ææ•°æ®ï¼Œä»¥åŠç›¸åº”çš„è¯­éŸ³å’Œå¤´éƒ¨å§¿åŠ¿æ•°æ®ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„è¯­éŸ³é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»ç”Ÿæˆæ¡†æ¶DiffPoseTalkï¼Œè¯¥æ¡†æ¶ç»“åˆäº†ä¸€ä¸ªä»çŸ­å‚è€ƒè§†é¢‘ä¸­æå–é£æ ¼åµŒå…¥çš„é£æ ¼ç¼–ç å™¨ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼æ¥æ ¹æ®è¯­éŸ³å’Œé£æ ¼æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ã€‚å°†æ¨¡å‹æ‰©å±•åˆ°åŒ…æ‹¬å¤´éƒ¨å§¿åŠ¿çš„ç”Ÿæˆï¼Œä»è€Œå¢å¼ºç”¨æˆ·æ„ŸçŸ¥ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨ä»é«˜è´¨é‡é‡å¤–è§†å¬æ•°æ®é›†é‡å»ºçš„3DMMå‚æ•°ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè§£å†³äº†æ‰«æ3Dè¯´è¯é¢éƒ¨æ•°æ®çš„çŸ­ç¼ºé—®é¢˜ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å°†æ‰©æ•£æ¨¡å‹åº”ç”¨äºè¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»ç”Ÿæˆï¼Œå®ç°äº†è¯­éŸ³ã€é£æ ¼å’Œå¤´éƒ¨å§¿åŠ¿çš„å¤šå¯¹å¤šæ˜ å°„ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªé£æ ¼ç¼–ç å™¨ï¼Œä»çŸ­å‚è€ƒè§†é¢‘ä¸­æå–é£æ ¼åµŒå…¥ï¼Œæœ‰æ•ˆåœ°æ•æ‰äº†é£æ ¼çš„å¤æ‚æ€§ã€‚</li>
<li>é‡‡ç”¨æ— åˆ†ç±»å™¨æŒ‡å¯¼æ¥ç”Ÿæˆè¿‡ç¨‹ï¼Œé¿å…äº†åˆ†ç±»å™¨å¸¦æ¥çš„è¯¯å·®ã€‚</li>
<li>å°†æ¨¡å‹æ‰©å±•åˆ°åŒ…æ‹¬å¤´éƒ¨å§¿åŠ¿çš„ç”Ÿæˆï¼Œå¢å¼ºäº†ç”¨æˆ·æ„ŸçŸ¥ã€‚</li>
<li>é€šè¿‡åœ¨ä»é«˜è´¨é‡é‡å¤–è§†å¬æ•°æ®é›†é‡å»ºçš„3DMMå‚æ•°ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œè§£å†³äº†æ‰«æ3Dè¯´è¯é¢éƒ¨æ•°æ®çš„çŸ­ç¼ºé—®é¢˜ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
- åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†è¯¥æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
- ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„3Dé¢éƒ¨åŠ¨ç”»æ›´è‡ªç„¶ã€æ›´é€¼çœŸã€‚</p>
<p>å·¥ä½œé‡ï¼š
- è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒå¤šçš„è®¡ç®—èµ„æºã€‚
- éœ€è¦é«˜è´¨é‡çš„é‡å¤–è§†å¬æ•°æ®é›†æ¥è®­ç»ƒæ¨¡å‹ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7312673b0c18714105ddb7899ac0df55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8466e4588a2da641b678027f760475e8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dbecf9b011548b814dbf8ff1aade63c8.jpg" align="middle">
</details>




## FaceDiffuser: Speech-Driven 3D Facial Animation Synthesis Using   Diffusion

**Authors:Stefan Stan, Kazi Injamamul Haque, Zerrin Yumak**

Speech-driven 3D facial animation synthesis has been a challenging task both in industry and research. Recent methods mostly focus on deterministic deep learning methods meaning that given a speech input, the output is always the same. However, in reality, the non-verbal facial cues that reside throughout the face are non-deterministic in nature. In addition, majority of the approaches focus on 3D vertex based datasets and methods that are compatible with existing facial animation pipelines with rigged characters is scarce. To eliminate these issues, we present FaceDiffuser, a non-deterministic deep learning model to generate speech-driven facial animations that is trained with both 3D vertex and blendshape based datasets. Our method is based on the diffusion technique and uses the pre-trained large speech representation model HuBERT to encode the audio input. To the best of our knowledge, we are the first to employ the diffusion method for the task of speech-driven 3D facial animation synthesis. We have run extensive objective and subjective analyses and show that our approach achieves better or comparable results in comparison to the state-of-the-art methods. We also introduce a new in-house dataset that is based on a blendshape based rigged character. We recommend watching the accompanying supplementary video. The code and the dataset will be publicly available. 

[PDF](http://arxiv.org/abs/2309.11306v1) Pre-print of the paper accepted at ACM SIGGRAPH MIG 2023

**Summary**

è¯­éŸ³é©±åŠ¨ 3D äººè„¸åŠ¨ç”»åˆæˆç»“åˆäº† 3D é¡¶ç‚¹å’Œæ··åˆå½¢çŠ¶æ•°æ®é›†ï¼Œå¯ç”Ÿæˆéç¡®å®šæ€§çš„ 3D äººè„¸åŠ¨ç”»ã€‚

**Key Takeaways**

- æˆ‘ä»¬æå‡ºä¸€ç§éç¡®å®šæ€§æ·±åº¦å­¦ä¹ æ¨¡å‹ FaceDiffuserï¼Œç”¨äºç”Ÿæˆè¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ã€‚
- FaceDiffuser åŸºäºæ¼«æ•£æŠ€æœ¯ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„è¯­éŸ³è¡¨ç¤ºæ¨¡å‹ HuBERT å¯¹éŸ³é¢‘è¾“å…¥è¿›è¡Œç¼–ç ã€‚
- FaceDiffuser é¦–æ¬¡å°†æ¼«æ•£æ–¹æ³•åº”ç”¨äºè¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»åˆæˆä»»åŠ¡ã€‚
- æˆ‘ä»¬å·²ç»è¿›è¡Œäº†å¹¿æ³›çš„å®¢è§‚å’Œä¸»è§‚åˆ†æï¼Œè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”å–å¾—äº†æ›´å¥½æˆ–ç›¸å½“çš„ç»“æœã€‚
- æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„å†…éƒ¨æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŸºäºæ··åˆå½¢çŠ¶çš„è£…é…è§’è‰²ã€‚
- æˆ‘ä»¬å»ºè®®è§‚çœ‹éšé™„çš„è¡¥å……è§†é¢‘ã€‚
- ä»£ç å’Œæ•°æ®é›†å°†å…¬å¼€æä¾›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šFaceDiffuserï¼šåŸºäºæ‰©æ•£çš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»åˆæˆ</li>
<li>ä½œè€…ï¼šStefan Stanã€Kazi Injamamul Haqueã€Zerrin Yumak</li>
<li>éš¶å±å•ä½ï¼šä¹Œç‰¹å‹’æ”¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šé¢éƒ¨åŠ¨ç”»åˆæˆã€æ·±åº¦å­¦ä¹ ã€è™šæ‹Ÿäººã€ç½‘æ ¼åŠ¨ç”»ã€æ··åˆå½¢çŠ¶åŠ¨ç”»</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2309.11306
    Github ä»£ç é“¾æ¥ï¼šhttps://github.com/uuembodiedsocialai/FaceDiffuser</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»åˆæˆä¸€ç›´æ˜¯å·¥ä¸šç•Œå’Œç ”ç©¶ç•Œçš„ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚æœ€è¿‘çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ç¡®å®šæ€§æ·±åº¦å­¦ä¹ æ–¹æ³•ä¸Šï¼Œè¿™æ„å‘³ç€ç»™å®šè¯­éŸ³è¾“å…¥ï¼Œè¾“å‡ºå§‹ç»ˆç›¸åŒã€‚ç„¶è€Œï¼Œå®é™…ä¸Šï¼Œéå¸ƒæ•´ä¸ªé¢éƒ¨çš„éè¯­è¨€é¢éƒ¨çº¿ç´¢æœ¬è´¨ä¸Šæ˜¯ä¸ç¡®å®šçš„ã€‚æ­¤å¤–ï¼Œå¤§å¤šæ•°æ–¹æ³•éƒ½é›†ä¸­åœ¨åŸºäº 3D é¡¶ç‚¹çš„çš„æ•°æ®é›†ä¸Šï¼Œè€Œä¸ç°æœ‰å…·æœ‰è£…å¤‡è§’è‰²çš„é¢éƒ¨åŠ¨ç”»ç®¡é“å…¼å®¹çš„æ–¹æ³•å¾ˆå°‘ã€‚
ï¼ˆ2ï¼‰ä¸ºäº†æ¶ˆé™¤è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† FaceDiffuserï¼Œè¿™æ˜¯ä¸€ç§éç¡®å®šæ€§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç”¨äºç”Ÿæˆè¯­éŸ³é©±åŠ¨çš„é¢éƒ¨åŠ¨ç”»ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨ 3D é¡¶ç‚¹å’Œæ··åˆå½¢çŠ¶æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäºæ‰©æ•£æŠ€æœ¯ï¼Œå¹¶ä½¿ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­éŸ³è¡¨ç¤ºæ¨¡å‹ HuBERT å¯¹éŸ³é¢‘è¾“å…¥è¿›è¡Œç¼–ç ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æ˜¯ç¬¬ä¸€ä¸ªå°†æ‰©æ•£æ–¹æ³•ç”¨äºè¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»åˆæˆçš„ä»»åŠ¡ã€‚
ï¼ˆ3ï¼‰æˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„å®¢è§‚å’Œä¸»è§‚åˆ†æï¼Œç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å–å¾—äº†æ›´å¥½æˆ–ç›¸å½“çš„ç»“æœã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ä¸ªæ–°çš„å†…éƒ¨æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŸºäºæ··åˆå½¢çŠ¶çš„è£…å¤‡è§’è‰²ã€‚æˆ‘ä»¬å»ºè®®è§‚çœ‹é™„å¸¦çš„è¡¥å……è§†é¢‘ã€‚ä»£ç å’Œæ•°æ®é›†å°†å…¬å¼€å‘å¸ƒã€‚
ï¼ˆ4ï¼‰åœ¨è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»åˆæˆä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å®¢è§‚å’Œä¸»è§‚è¯„ä¼°ä¸­éƒ½å–å¾—äº†æœ‰ç«äº‰åŠ›çš„ç»“æœã€‚è¿™è¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥å¾ˆå¥½åœ°å®ç°è¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»åˆæˆã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§é€šç”¨æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥é’ˆå¯¹åŸºäºé¡¶ç‚¹å’ŒåŸºäºæ··åˆå½¢çŠ¶çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œåªéœ€å¯¹è¶…å‚æ•°è¿›è¡Œè½»å¾®ä¿®æ”¹ã€‚åŸºäºé¡¶ç‚¹çš„æ¨¡å‹é…ç½®ç§°ä¸º V-FaceDiffuserï¼ŒåŸºäºæ··åˆå½¢çŠ¶çš„æ¨¡å‹ç§°ä¸º B-FaceDiffuserã€‚ä¸»è¦åŒºåˆ«åœ¨äºé¢å¤–çš„å™ªå£°ç¼–ç å™¨ï¼Œå¦‚å›¾ 2 ä¸­ä»¥è™šçº¿çº¢è‰²æ¡†æ ‡å‡ºã€‚å™ªå£°ç¼–ç å™¨æœ‰åŠ©äºå°†é«˜ç»´é¡¶ç‚¹æ•°æ®æŠ•å½±åˆ°ä½ç»´æ½œåœ¨è¡¨ç¤ºä¸­ã€‚æ‰©æ•£å™ªå£°è¿‡ç¨‹é‡‡ç”¨ x1:N0 æ¥è®¡ç®—å™ªå£° x1:Ntï¼ŒåŒæ—¶ä¿æŒå…¶åŸå§‹å½¢çŠ¶ã€‚ä»å›¾ 2 ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è¯†åˆ«å‡ºè¿™ä¸¤ä¸ªç‰ˆæœ¬æ¨¡å‹ä¸­åŒ…å«çš„ä»¥ä¸‹ä¸»è¦ç»„ä»¶ï¼š
ï¼ˆ2ï¼‰éŸ³é¢‘ç¼–ç å™¨ï¼šæˆ‘ä»¬ä½¿ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­éŸ³æ¨¡å‹ HuBERT ä½œä¸ºéŸ³é¢‘ç¼–ç å™¨ï¼Œç±»ä¼¼äº [22]ï¼Œå¹¶ä¸”åœ¨æ¶æ„çš„ä¸¤ä¸ªç‰ˆæœ¬ä¸­ä¿æŒä¸å˜ã€‚æˆ‘ä»¬é‡‡ç”¨ HuBERT æ¶æ„çš„é¢„è®­ç»ƒç‰ˆæœ¬ï¼Œå¹¶ä½¿ç”¨å…¶å‘å¸ƒçš„ hubert-base-ls960 ç‰ˆæœ¬ï¼Œè¯¥ç‰ˆæœ¬åœ¨ 960 å°æ—¶çš„ LibriSpeech [35] æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚
ï¼ˆ3ï¼‰æ‰©æ•£è¿‡ç¨‹ï¼šè®¾ x1:N0 æ˜¯æ¥è‡ªæ•°æ®é›†çš„çœŸå®è§†è§‰å¸§åºåˆ—ï¼Œå½¢çŠ¶ä¸º (N,C)ï¼Œå…¶ä¸­ C æ˜¯é¡¶ç‚¹æ•°ä¹˜ä»¥ 3ï¼ˆå¯¹äº 3 ä¸ªç©ºé—´è½´ï¼‰æˆ–é¢éƒ¨æ§åˆ¶æƒé‡ï¼ˆæˆ–æ··åˆå½¢çŠ¶å€¼ï¼‰çš„æ•°é‡ã€‚åœ¨è®­ç»ƒæœŸé—´ï¼Œæˆ‘ä»¬ä» [1,T] ä¸­éšæœºæŠ½å–ä¸€ä¸ªæ•´æ•°æ—¶é—´æ­¥é•¿ tï¼Œè¡¨ç¤ºåº”ç”¨äº x1:N0 ä»¥è·å¾— x1:Nt çš„å™ªå£°æ­¥éª¤æ•°ï¼Œå…¬å¼ä¸ºï¼š
x1:Nt=q(x1:Nt|x1:Ntâˆ’1)=N(âˆš1âˆ’Î²tâ‹…x1:Ntâˆ’1,(Î²t)â‹…I)(2)
å…¶ä¸­ï¼ŒN æ˜¯åºåˆ—ä¸­çš„è§†è§‰å¸§æ•°ï¼Œt æ˜¯æ‰©æ•£æ—¶é—´æ­¥é•¿ï¼ŒÎ²t æ˜¯æ—¶é—´æ­¥é•¿ t å¤„çš„å¸¸æ•°å™ªå£°ï¼Œä½¿å¾— 0&lt;Î²1&lt;Î²2&lt;...&lt;Î²T&lt;1ã€‚åœ¨æ­£å‘å™ªå£°è¿‡ç¨‹ä¹‹åï¼Œç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿè®¡ç®—åå‘è¿‡ç¨‹å¹¶ä» x1:NTâˆ¼N(0,1) å‘åè¿”å›åˆ° x1:N0ã€‚å› æ­¤ï¼Œæ¡ä»¶åˆ†å¸ƒå‡½æ•° p(x1:Ntâˆ’1|x1:Nt) éœ€è¦äº‹å…ˆçŸ¥é“ã€‚Ho ç­‰äºº [24] æå‡ºäº†é€šè¿‡å­¦ä¹ æ•°æ®é›†çš„æ½œåœ¨è¡¨ç¤ºæ–¹å·®æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚è®­ç»ƒç›®æ ‡è¢«å®šä¹‰ä¸ºå­¦ä¹ é¢„æµ‹æ·»åŠ åˆ°è¾“å…¥ x0 ä¸­çš„å™ªå£° ğœ–ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬åç¦» [24] å¹¶éµå¾ª MDM [49] å’Œ EDGE [50]ï¼Œé€‰æ‹©æˆ‘ä»¬çš„æ¨¡å‹æ¥å­¦ä¹ é¢„æµ‹å®é™…åŠ¨ç”»æ•°æ®ï¼Œè€Œä¸æ˜¯æ•°æ®ä¸­çš„å™ªå£°æ°´å¹³ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™æ›´é€‚åˆæˆ‘ä»¬çš„ä»»åŠ¡ï¼Œå› ä¸ºç»“æœä¹Ÿå–å†³äºè¾“å…¥éŸ³é¢‘ã€‚æ­¤å¤–ï¼Œé€šè¿‡é€‰æ‹©è¿™ç§æ–¹æ³•ï¼Œå³ä½¿ä»æ¨ç†è¿‡ç¨‹çš„ç¬¬ä¸€ä¸ªå»å™ªæ­¥éª¤å¼€å§‹ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¹Ÿèƒ½å¤Ÿé¢„æµ‹å‡ºå¯æ¥å—çš„ç»“æœï¼Œä»è€Œå®ç°æ›´å¿«çš„é‡‡æ ·ã€‚ç„¶è€Œï¼Œéµå¾ªå®Œæ•´çš„æ¨ç†è¿‡ç¨‹å°†ç»™å‡ºæœ€å¥½çš„ç»“æœã€‚æˆ‘ä»¬é‡‡ç”¨ç±»ä¼¼äº [49] å’Œ [50] çš„ç®€å•æŸå¤±è¿›è¡Œè®­ç»ƒã€‚Ho ç­‰äººè¿›è¡Œäº†æ›´å½»åº•çš„å®éªŒã€‚[24]ï¼Œä»–ä»¬è¿˜å£°ç§°åˆ©ç”¨ç®€å•çš„æŸå¤±æ¥å­¦ä¹ å˜åˆ†ç•Œè¢«è¯æ˜æ—¢æ˜“äºå®ç°ï¼Œä¹Ÿæœ‰åˆ©äºé‡‡æ ·ç»“æœçš„è´¨é‡ã€‚æŸå¤±å®šä¹‰ä¸ºï¼š
L=Ex0âˆ¼q(x0|c),tâˆ¼[1,T]<a href="3">âˆ¥x0âˆ’Ë†x0âˆ¥</a>
ï¼ˆ4ï¼‰é¢éƒ¨è§£ç å™¨ï¼šé¢éƒ¨è§£ç å™¨è´Ÿè´£æ ¹æ®ç¼–ç éŸ³é¢‘å’Œå™ªå£°çš„æ½œåœ¨è¡¨ç¤ºç”Ÿæˆæœ€ç»ˆçš„åŠ¨ç”»å¸§ã€‚å®ƒç”±å¤šä¸ª GRU å±‚ç»„æˆï¼Œåè·Ÿä¸€ä¸ªæœ€ç»ˆçš„å…¨è¿æ¥å±‚ï¼Œè¯¥å±‚é¢„æµ‹è¾“å‡ºåºåˆ—ã€‚åœ¨è§£ç æ­¥éª¤ä¸­ï¼Œè¿˜å¯ä»¥ä»¥å­¦ä¹ çš„æ ·å¼åµŒå…¥å‘é‡ä¸éšè—çŠ¶æ€è¾“å‡ºä¹‹é—´çš„å…ƒç´ çº§ä¹˜ç§¯çš„å½¢å¼æ·»åŠ æ ·å¼åµŒå…¥ã€‚æˆ‘ä»¬åœ¨æ¶ˆèéƒ¨åˆ†è§£é‡Šäº†é€‰æ‹© GRU è§£ç å™¨çš„åŸå› ã€‚
ï¼ˆ5ï¼‰FaceDiffuserï¼šåŸºäºæ‰©æ•£çš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»åˆæˆ
ï¼ˆ6ï¼‰FaceDiffuser æ¨ç†æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼Œä» T é€’å‡åˆ° 1ã€‚åˆå§‹å™ªå£°ç”±æ­£æ€åˆ†å¸ƒ N(0,1) çš„å®é™…å™ªå£°è¡¨ç¤ºã€‚åœ¨æ¯ä¸€æ­¥ä¸­ï¼Œæˆ‘ä»¬å‘ç½‘ç»œæä¾›éŸ³é¢‘å’Œå™ªå£°åŠ¨ç”»è¾“å…¥ã€‚ç„¶åå°†é¢„æµ‹çš„è¿åŠ¨å†æ¬¡æ‰©æ•£å¹¶é¦ˆé€åˆ°è¿­ä»£çš„ä¸‹ä¸€æ­¥éª¤ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æˆ‘ä»¬æŠŠæ‰©æ•£æœºåˆ¶é›†æˆåˆ°ä¸€ä¸ªç”Ÿæˆå¼æ·±åº¦ç¥ç»ç½‘ç»œä¸­ï¼Œè¯¥ç½‘ç»œç»è¿‡è®­ç»ƒå¯ä»¥ç”Ÿæˆä»¥è¯­éŸ³ä¸ºæ¡ä»¶çš„ 3D é¢éƒ¨åŠ¨ç”»ã€‚æ‰€æå‡ºçš„æ–¹æ³•å¯ä»¥æ¨å¹¿åˆ°é«˜ç»´æ—¶é—´ 3D é¡¶ç‚¹æ•°æ®ä»¥åŠä½ç»´æ··åˆå½¢çŠ¶æ•°æ®ï¼Œåªéœ€å¯¹è¶…å‚æ•°è¿›è¡Œè½»å¾®ä¿®æ”¹ã€‚å®šé‡åˆ†æè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒçš„æ ·å¼æ¡ä»¶ä¹‹é—´äº§ç”Ÿæ›´é«˜çš„è¿åŠ¨å¤šæ ·æ€§ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºæ‰©æ•£çš„æ¨¡å‹ FaceDiffuserï¼Œç”¨äºç”Ÿæˆè¯­éŸ³é©±åŠ¨çš„ 3D é¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>æˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥é’ˆå¯¹åŸºäºé¡¶ç‚¹å’ŒåŸºäºæ··åˆå½¢çŠ¶çš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œåªéœ€å¯¹è¶…å‚æ•°è¿›è¡Œè½»å¾®ä¿®æ”¹ã€‚</li>
<li>æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå…·æœ‰æ›´é«˜è¿åŠ¨å¤šæ ·æ€§çš„åŠ¨ç”»ï¼Œå³ä½¿åœ¨ä¸åŒçš„æ ·å¼æ¡ä»¶ä¸‹ä¹Ÿæ˜¯å¦‚æ­¤ã€‚
æ€§èƒ½ï¼š</li>
<li>æˆ‘ä»¬çš„æ¨¡å‹åœ¨å®¢è§‚å’Œä¸»è§‚è¯„ä¼°ä¸­éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„ã€é«˜è´¨é‡çš„ 3D é¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿå®æ—¶ç”ŸæˆåŠ¨ç”»ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æˆ‘ä»¬æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹ç®€å•ã€‚</li>
<li>æˆ‘ä»¬æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ä¹Ÿéå¸¸æœ‰æ•ˆã€‚</li>
<li>æˆ‘ä»¬æ¨¡å‹çš„ä»£ç å’Œæ•°æ®é›†éƒ½æ˜¯å…¬å¼€å¯ç”¨çš„ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c6b2d7bbedf1f0aff99eafa6c4abc4dd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1bf4fe00fac43e23f442d69b1e6d0a10.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6a0ecfad348bccbc3857ece8ec2797c8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-07bf850a8b84e1168cec03ca40142feb.jpg" align="middle">
</details>




<h2 id="DT-NeRF-Decomposed-Triplane-Hash-Neural-Radiance-Fields-for-High-Fidelity-Talking-Portrait-Synthesis"><a href="#DT-NeRF-Decomposed-Triplane-Hash-Neural-Radiance-Fields-for-High-Fidelity-Talking-Portrait-Synthesis" class="headerlink" title="DT-NeRF: Decomposed Triplane-Hash Neural Radiance Fields for   High-Fidelity Talking Portrait Synthesis"></a>DT-NeRF: Decomposed Triplane-Hash Neural Radiance Fields for   High-Fidelity Talking Portrait Synthesis</h2><p><strong>Authors:Yaoyu Su, Shaohui Wang, Haoqian Wang</strong></p>
<p>In this paper, we present the decomposed triplane-hash neural radiance fields (DT-NeRF), a framework that significantly improves the photorealistic rendering of talking faces and achieves state-of-the-art results on key evaluation datasets. Our architecture decomposes the facial region into two specialized triplanes: one specialized for representing the mouth, and the other for the broader facial features. We introduce audio features as residual terms and integrate them as query vectors into our model through an audio-mouth-face transformer. Additionally, our method leverages the capabilities of Neural Radiance Fields (NeRF) to enrich the volumetric representation of the entire face through additive volumetric rendering techniques. Comprehensive experimental evaluations corroborate the effectiveness and superiority of our proposed approach. </p>
<p><a href="http://arxiv.org/abs/2309.07752v1">PDF</a> 5 pages, 5 figures. Submitted to ICASSP 2024</p>
<p><strong>Summary</strong><br>æ·±åº¦åˆ†è§£ä¸‰å¹³é¢å“ˆå¸Œç¥ç»è¾å°„åœºæ˜¾è‘—æé«˜äº†è¯´è¯äººè„¸çš„å…‰å†™å®æ¸²æŸ“æ•ˆæœï¼Œå¹¶åœ¨å…³é”®è¯„ä¼°æ•°æ®é›†ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æˆæ•ˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ†è§£é¢éƒ¨åŒºåŸŸä¸ºä¸¤ä¸ªä¸“é—¨çš„ä¸‰å¹³é¢ï¼šä¸€ä¸ªæ˜¯ä¸“é—¨ç”¨äºè¡¨ç¤ºå˜´å·´ï¼Œå¦ä¸€ä¸ªç”¨äºæ›´å¹¿æ³›çš„é¢éƒ¨ç‰¹å¾ã€‚</li>
<li>å°†éŸ³é¢‘ç‰¹å¾ä½œä¸ºæ®‹å·®é¡¹å¼•å…¥ï¼Œå¹¶é€šè¿‡éŸ³é¢‘-å£-é¢è½¬æ¢å™¨ä½œä¸ºæŸ¥è¯¢å‘é‡æ•´åˆåˆ°æ¨¡å‹ä¸­ã€‚</li>
<li>åˆ©ç”¨ç¥ç»è¾å°„åœº (NeRF) çš„åŠŸèƒ½ï¼Œé€šè¿‡æ·»åŠ ä½“ç§¯æ¸²æŸ“æŠ€æœ¯ä¸°å¯Œæ•´ä¸ªè„¸éƒ¨çš„ä½“ç§¯è¡¨ç¤ºã€‚</li>
<li>ç»¼åˆå®éªŒè¯„ä¼°è¯å®äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</li>
<li>è¯¥æ–¹æ³•æ˜¯é¦–ä¸ªä½¿ç”¨ä¸‰å¹³é¢å“ˆå¸Œç¥ç»è¾å°„åœºæ¥å®ç°è¯´è¯äººè„¸å…‰å†™å®æ¸²æŸ“çš„æŠ€æœ¯ã€‚</li>
<li>è¯¥æ–¹æ³•å°†é¢éƒ¨åŒºåŸŸåˆ†è§£ä¸ºä¸¤ä¸ªä¸“é—¨çš„ä¸‰å¹³é¢ï¼Œä»¥æ›´æœ‰æ•ˆåœ°è¡¨ç¤ºå˜´å·´å’Œæ›´å¹¿æ³›çš„é¢éƒ¨ç‰¹å¾ã€‚</li>
<li>è¯¥æ–¹æ³•å°†éŸ³é¢‘ç‰¹å¾ä½œä¸ºæ®‹å·®é¡¹å¼•å…¥ï¼Œå¹¶å°†å…¶ä½œä¸ºæŸ¥è¯¢å‘é‡é€šè¿‡éŸ³é¢‘-å£-é¢è½¬æ¢å™¨é›†æˆåˆ°æ¨¡å‹ä¸­ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåˆ†è§£ä¸‰å¹³é¢å“ˆå¸Œç¥ç»è¾å°„åœºï¼ˆDT-NERFï¼‰</li>
<li>ä½œè€…ï¼šå§šå®‡è‹ã€é‚µè¾‰ç‹ã€éƒè°¦ç‹</li>
<li>éš¶å±å•ä½ï¼šæ·±åœ³å›½é™…ç ”ç©¶ç”Ÿé™¢ï¼Œæ¸…åå¤§å­¦ï¼Œæ·±åœ³ 518071ï¼Œä¸­å›½</li>
<li>å…³é”®è¯ï¼šNeRFï¼Œä¼šè¯´è¯çš„é¢éƒ¨è‚–åƒï¼Œåˆ†è§£ä¸‰å¹³é¢å“ˆå¸Œï¼ŒéŸ³é¢‘-å˜´å·´-é¢éƒ¨è½¬æ¢å™¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéŸ³é¢‘é©±åŠ¨çš„è¯´è¯é¢éƒ¨è‚–åƒåˆæˆæ˜¯ä¸€é¡¹å…³é”®ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨å¢å¼ºç°å® (AR)ã€è™šæ‹Ÿç°å® (VR) å’Œå¤§å‹è¯­è¨€æ¨¡å‹ (LLM) åœ¨æ•°å­—äººã€è™šæ‹Ÿå½¢è±¡å’Œè¿œç¨‹ä¼šè®®ç­‰ 3D é¢éƒ¨é©±åŠ¨æŠ€æœ¯ä¸­ä¸æ–­æ‰¾åˆ°åº”ç”¨çš„æƒ…å†µä¸‹ã€‚è¿‘å¹´æ¥ï¼Œç ”ç©¶äººå‘˜å¯¹ 3D è§†è§‰ç¯å¢ƒä¸­çš„éŸ³é¢‘é©±åŠ¨é¢éƒ¨åˆæˆè¿›è¡Œäº†å¹¿æ³›æ¢ç´¢ã€‚éšç€ 2020 å¹´ç¥ç»è¾å°„åœº (NeRF) çš„å‡ºç°ï¼Œè¿™ç§æ–¹æ³•å·²è¢«çº³å…¥è¿™é¡¹ä»»åŠ¡ï¼Œäº§ç”Ÿäº†ä»¤äººå°è±¡æ·±åˆ»çš„è§†è§‰æ•ˆæœã€‚ç„¶è€Œï¼ŒåŸå§‹çš„ NeRF æ¨¡å‹åœ¨è®¡ç®—é€Ÿåº¦å’Œè¯­éŸ³æœŸé—´ç²¾ç¡®çš„å˜´å·´åŒæ­¥æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œè¿™è¡¨æ˜æœ‰æ”¹è¿›çš„ç©ºé—´ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šNeRF æ˜¯ä¸€ç§ç¥ç»æ¸²æŸ“æŠ€æœ¯ï¼Œé‡‡ç”¨ 5D è¾å°„åœºæ¥æ•è·å¤æ‚çš„ 3D è¡¨é¢ã€‚è¯¥æŠ€æœ¯æœ€åˆè®¾è®¡ç”¨äºæ¸²æŸ“é™æ€ã€æœ‰ç•Œçš„åœºæ™¯ï¼Œä½†æ­¤åå·²å‘å±•åˆ°é€‚åº”åŠ¨æ€å’Œæ— ç•Œè®¾ç½®ã€‚NeRF å·²åœ¨å„ç§å­é¢†åŸŸä¸­æ‰¾åˆ°åº”ç”¨ï¼Œä¾‹å¦‚é€šè¿‡ç¬¦å·è·ç¦»åœº (SDF) å’Œä½“ç§¯æ¸²æŸ“ç›¸ç»“åˆçš„åœºæ™¯é‡å»ºã€é¢éƒ¨å’Œèº«ä½“æ¸²æŸ“ï¼Œç”šè‡³æ‰‹éƒ¨é‡å»ºã€‚åœ¨åˆ©ç”¨ç¥ç»è¾å°„åœº (NeRF) è¿›è¡Œ 3D é¢éƒ¨åˆæˆçš„å½“å‰é¢†åŸŸä¸­ï¼Œæµè¡Œçš„æ–¹æ³•å¾€å¾€éµå¾ªä¸¤æ¡è·¯å¾„ä¹‹ä¸€ã€‚å®ƒä»¬è¦ä¹ˆé‡‡ç”¨æ˜ç¡®çš„ 3D é¢éƒ¨è¡¨æƒ…å‚æ•°æˆ– 2D åœ°æ ‡ï¼Œè¿™å¯èƒ½å¯¼è‡´ä¿¡æ¯æ˜¾ç€ä¸¢å¤±ï¼Œå°¤å…¶æ˜¯å˜´å·´åŒºåŸŸï¼Œè¦ä¹ˆé‡‡ç”¨éšå¼è¡¨ç¤ºï¼Œä½¿ç”¨éŸ³é¢‘ä½œä¸ºæ½œåœ¨ä»£ç æ¥è°ƒåˆ¶æˆ–æ‰­æ›²è§„èŒƒç©ºé—´ã€‚è¿™äº›ç­–ç•¥å­˜åœ¨ç¼ºé™·ï¼Œå°¤å…¶æ˜¯åœ¨æ•æ‰è¯­éŸ³æœŸé—´å˜´å·´çš„ç»†å¾®å˜åŒ–æ–¹é¢ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŒé‡æ–¹æ³•ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é‡‡ç”¨åŠ¨æ€ NeRFï¼Œè¯¥ NeRF åˆ©ç”¨éŸ³é¢‘ç‰¹å¾ä½œä¸ºè½¬æ¢å™¨çš„æŸ¥è¯¢ï¼Œæ—¨åœ¨ä¼˜åŒ– NeRF ä¸­çš„å¯†åº¦å’Œé¢œè‰²ç½‘ç»œï¼Œä»¥ä»è§„èŒƒç©ºé—´è°ƒåˆ¶åˆ°åŠ¨æ€ç©ºé—´ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨é¢œè‰²å’Œä½“ç§¯å¯†åº¦åœ¨åŒä¸€ NeRF ç©ºé—´ä¸­çš„åŠ æ³•ç‰¹æ€§ï¼Œä»è€Œå®ç°éŸ³é¢‘å’Œè§†è§‰å…ƒç´ çš„æ›´æ— ç¼é›†æˆã€‚æˆ‘ä»¬çš„æ–¹æ³•æ—¨åœ¨æ›´æœ‰æ•ˆåœ°å°†éŸ³é¢‘çº¿ç´¢ä¸é¢éƒ¨è¡¨æƒ…ç»“åˆèµ·æ¥ï¼Œç‰¹åˆ«å…³æ³¨å˜´å·´åŒºåŸŸçš„ä¼˜åŒ–ã€‚åˆ†è§£çš„ 3D è¡¨ç¤ºè¢«ç”¨æ¥åˆ†åˆ«å»ºæ¨¡å˜´å·´å’Œæ›´å¹¿æ³›çš„é¢éƒ¨ç‰¹å¾ã€‚æˆ‘ä»¬å¼•å…¥éŸ³é¢‘ç‰¹å¾ä½œä¸ºæ®‹å·®é¡¹ï¼Œå¹¶é€šè¿‡éŸ³é¢‘-å˜´å·´-é¢éƒ¨è½¬æ¢å™¨å°†å®ƒä»¬ä½œä¸ºæŸ¥è¯¢å‘é‡é›†æˆåˆ°æˆ‘ä»¬çš„æ¨¡å‹ä¸­ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šåœ¨å…³é”®è¯„ä¼°æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†é€¼çœŸçš„è¯´è¯é¢å­”çš„æ¸²æŸ“ï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ç»¼åˆå®éªŒè¯„ä¼°è¯å®äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): æå‡ºåŠ¨æ€ NeRFï¼Œåˆ©ç”¨éŸ³é¢‘ç‰¹å¾ä½œä¸ºè½¬æ¢å™¨çš„æŸ¥è¯¢ï¼Œä¼˜åŒ– NeRF ä¸­çš„å¯†åº¦å’Œé¢œè‰²ç½‘ç»œï¼Œä»è§„èŒƒç©ºé—´è°ƒåˆ¶åˆ°åŠ¨æ€ç©ºé—´ã€‚
(2): åˆ©ç”¨é¢œè‰²å’Œä½“ç§¯å¯†åº¦åœ¨åŒä¸€ NeRF ç©ºé—´ä¸­çš„åŠ æ³•ç‰¹æ€§ï¼Œå®ç°éŸ³é¢‘å’Œè§†è§‰å…ƒç´ çš„æ›´æ— ç¼é›†æˆã€‚
(3): é‡‡ç”¨åˆ†è§£çš„ 3D è¡¨ç¤ºåˆ†åˆ«å»ºæ¨¡å˜´å·´å’Œæ›´å¹¿æ³›çš„é¢éƒ¨ç‰¹å¾ã€‚
(4): å¼•å…¥éŸ³é¢‘ç‰¹å¾ä½œä¸ºæ®‹å·®é¡¹ï¼Œå¹¶é€šè¿‡éŸ³é¢‘-å˜´å·´-é¢éƒ¨è½¬æ¢å™¨å°†å®ƒä»¬ä½œä¸ºæŸ¥è¯¢å‘é‡é›†æˆåˆ°æ¨¡å‹ä¸­ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ†è§£ä¸‰å¹³é¢å“ˆå¸Œç¥ç»è¾å°„åœºï¼ˆDT-NERFï¼‰æ–¹æ³•ï¼Œç”¨äºéŸ³é¢‘é©±åŠ¨çš„è¯´è¯é¢éƒ¨è‚–åƒåˆæˆã€‚è¯¥æ–¹æ³•åˆ©ç”¨åŠ¨æ€NeRFã€åˆ†è§£çš„3Dè¡¨ç¤ºã€éŸ³é¢‘ç‰¹å¾ä½œä¸ºæ®‹å·®é¡¹ä»¥åŠéŸ³é¢‘-å˜´å·´-é¢éƒ¨è½¬æ¢å™¨ï¼Œæœ‰æ•ˆåœ°å°†éŸ³é¢‘çº¿ç´¢ä¸é¢éƒ¨è¡¨æƒ…ç»“åˆèµ·æ¥ï¼Œç‰¹åˆ«å…³æ³¨å˜´å·´åŒºåŸŸçš„ä¼˜åŒ–ã€‚åœ¨å…³é”®è¯„ä¼°æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†é€¼çœŸçš„è¯´è¯é¢å­”çš„æ¸²æŸ“ï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºåŠ¨æ€NeRFï¼Œåˆ©ç”¨éŸ³é¢‘ç‰¹å¾ä½œä¸ºè½¬æ¢å™¨çš„æŸ¥è¯¢ï¼Œä¼˜åŒ–NeRFä¸­çš„å¯†åº¦å’Œé¢œè‰²ç½‘ç»œï¼Œä»è§„èŒƒç©ºé—´è°ƒåˆ¶åˆ°åŠ¨æ€ç©ºé—´ã€‚</li>
<li>åˆ©ç”¨é¢œè‰²å’Œä½“ç§¯å¯†åº¦åœ¨åŒä¸€NeRFç©ºé—´ä¸­çš„åŠ æ³•ç‰¹æ€§ï¼Œå®ç°éŸ³é¢‘å’Œè§†è§‰å…ƒç´ çš„æ›´æ— ç¼é›†æˆã€‚</li>
<li>é‡‡ç”¨åˆ†è§£çš„3Dè¡¨ç¤ºåˆ†åˆ«å»ºæ¨¡å˜´å·´å’Œæ›´å¹¿æ³›çš„é¢éƒ¨ç‰¹å¾ã€‚</li>
<li>å¼•å…¥éŸ³é¢‘ç‰¹å¾ä½œä¸ºæ®‹å·®é¡¹ï¼Œå¹¶é€šè¿‡éŸ³é¢‘-å˜´å·´-é¢éƒ¨è½¬æ¢å™¨å°†å®ƒä»¬ä½œä¸ºæŸ¥è¯¢å‘é‡é›†æˆåˆ°æ¨¡å‹ä¸­ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å…³é”®è¯„ä¼°æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†é€¼çœŸçš„è¯´è¯é¢å­”çš„æ¸²æŸ“ï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦æ”¶é›†å’Œé¢„å¤„ç†éŸ³é¢‘å’Œé¢éƒ¨æ•°æ®ï¼Œæ„å»ºåˆ†è§£ä¸‰å¹³é¢å“ˆå¸Œç¥ç»è¾å°„åœºæ¨¡å‹ï¼Œå¹¶è¿›è¡Œè®­ç»ƒå’Œæ¨ç†ã€‚å·¥ä½œé‡ä¸­ç­‰ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ada9598533d7c8a1499ba097e55090dc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8fb8385566e4ab5153fa149f745ccef6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3595e0ef582dce4ddf81794c218bee95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fb1d50c01e04c66fad1c597d9bf14ce5.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/02/09/Paper/2024-02-09/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-09-æ›´æ–°"><a href="#2024-02-09-æ›´æ–°" class="headerlink" title="2024-02-09 æ›´æ–°"></a>2024-02-09 æ›´æ–°</h1><h2 id="Source-Free-Domain-Adaptation-with-Diffusion-Guided-Source-Data-Generation"><a href="#Source-Free-Domain-Adaptation-with-Diffusion-Guided-Source-Data-Generation" class="headerlink" title="Source-Free Domain Adaptation with Diffusion-Guided Source Data   Generation"></a>Source-Free Domain Adaptation with Diffusion-Guided Source Data   Generation</h2><p><strong>Authors:Shivang Chopra, Suraj Kothawade, Houda Aynaou, Aman Chadha</strong></p>
<p>This paper introduces a novel approach to leverage the generalizability capability of Diffusion Models for Source-Free Domain Adaptation (DM-SFDA). Our proposed DM-SFDA method involves fine-tuning a pre-trained text-to-image diffusion model to generate source domain images using features from the target images to guide the diffusion process. Specifically, the pre-trained diffusion model is fine-tuned to generate source samples that minimize entropy and maximize confidence for the pre-trained source model. We then apply established unsupervised domain adaptation techniques to align the generated source images with target domain data. We validate our approach through comprehensive experiments across a range of datasets, including Office-31, Office-Home, and VisDA. The results highlight significant improvements in SFDA performance, showcasing the potential of diffusion models in generating contextually relevant, domain-specific images. </p>
<p><a href="http://arxiv.org/abs/2402.04929v1">PDF</a> arXiv admin note: substantial text overlap with arXiv:2310.01701</p>
<p><strong>Summary</strong><br>åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›è¿›è¡Œæ— æºåŸŸè‡ªé€‚åº”ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒçš„æ–‡ç”Ÿå›¾æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨ç›®æ ‡å›¾åƒçš„ç‰¹å¾å¼•å¯¼æ‰©æ•£è¿‡ç¨‹ï¼Œç”ŸæˆæºåŸŸå›¾åƒã€‚</li>
<li>ç›®æ ‡æ˜¯ç”Ÿæˆç†µæœ€å°åŒ–ä¸”å¯¹é¢„è®­ç»ƒæºæ¨¡å‹çš„ç½®ä¿¡åº¦æœ€å¤§çš„æºæ ·æœ¬ã€‚</li>
<li>ç›´æ¥åœ¨ç›®æ ‡å›¾åƒåˆ†å¸ƒä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œè€Œæ— éœ€æˆå¯¹çš„æºå’Œç›®æ ‡å›¾åƒã€‚</li>
<li>æ‰€æå‡ºçš„æ–¹æ³•åœ¨ Office-31ã€Office-Home å’Œ VisDA ç­‰å¤šä¸ªæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>ç”Ÿæˆçš„é«˜è´¨é‡æºå›¾åƒæœ‰åŠ©äºè·¨åŸŸä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»å’Œç›®æ ‡æ£€æµ‹ã€‚</li>
<li>å……åˆ†åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œåœ¨æºå’Œç›®æ ‡åŸŸä¹‹é—´å»ºç«‹æ¡¥æ¢ã€‚</li>
<li>æ— æºåŸŸè‡ªé€‚åº”çš„æ¨¡å‹å…·æœ‰é™å™ªæ•ˆæœï¼Œæœ‰åŠ©äºæé«˜åˆ†ç±»å’Œæ£€æµ‹çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºæ‰©æ•£å¼•å¯¼æºæ•°æ®ç”Ÿæˆçš„æ— æºåŸŸè‡ªé€‚åº”</li>
<li>ä½œè€…ï¼šShivang Chopra, Suraj Kothawade, Houda Aynaou, Aman Chadha</li>
<li>å•ä½ï¼šä½æ²»äºšç†å·¥å­¦é™¢è®¡ç®—æœºç³»</li>
<li>å…³é”®è¯ï¼šæ— æºåŸŸè‡ªé€‚åº”ã€æ‰©æ•£æ¨¡å‹ã€æ•°æ®ç”Ÿæˆã€è·¨åŸŸå›¾åƒåˆ†ç±»</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.04929
Githubï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åœ¨è§†è§‰ä»»åŠ¡ä¸­å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œä½†å®ƒä»¬å¯¹è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åˆ†å¸ƒä¸€è‡´æ€§çš„å‡è®¾é™åˆ¶äº†å…¶åœ¨çœŸå®ä¸–ç•Œä¸­çš„åº”ç”¨ã€‚é¢†åŸŸè‡ªé€‚åº”ï¼ˆDAï¼‰æ—¨åœ¨å‡å°‘è¿™ç§å·®å¼‚ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿè·¨å¤šä¸ªé¢†åŸŸè¡¨ç°è‰¯å¥½ã€‚ä¼ ç»Ÿ DA æ–¹æ³•ä¾èµ–äºå›ºå®šçš„æºæ•°æ®ï¼Œå¯èƒ½éš¾ä»¥é€‚åº”ä¸æ–­å˜åŒ–çš„é¢†åŸŸã€‚æ— æºåŸŸè‡ªé€‚åº”ï¼ˆSFDAï¼‰æ˜¯ä¸€ç§ç‰¹æ®Šç±»å‹çš„ DAï¼Œå®ƒä¸éœ€è¦è®¿é—®æºè®­ç»ƒæ•°æ®ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰çš„å¤§å¤šæ•° SFDA æ–¹æ³•é€šè¿‡åœ¨å…±äº«ç‰¹å¾ç©ºé—´ä¸­èåˆä¸¤ä¸ªä¸åŒçš„æ•°æ®åˆ†å¸ƒæ¥å®ç°æ¨¡å‹é€‚åº”æ€§ã€‚ä¸€ç§å®ç°æ— æºæ–¹å¼çš„æ–¹æ³•æ˜¯ä½¿ç”¨åˆæˆç”Ÿæˆçš„æºæ•°æ®ã€‚ç„¶è€Œï¼Œç”Ÿæˆå‡†ç¡®è¡¨ç¤ºæºåŸŸå¤šæ ·æ€§å’Œå¤æ‚æ€§çš„åˆæˆæºæ•°æ®å¯èƒ½å¾ˆå›°éš¾ã€‚æ­¤å¤–ï¼Œå¦‚æœåˆæˆæ•°æ®è´¨é‡ä¸é«˜ï¼Œå¯èƒ½ä¼šå¼•å…¥å™ªå£°å’Œä¸ä¸€è‡´æ€§ï¼Œä»è€Œå¯¹æ¨¡å‹åœ¨ç›®æ ‡åŸŸä¸Šçš„æ€§èƒ½äº§ç”Ÿè´Ÿé¢å½±å“ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º DM-SFDA çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£ç”Ÿæˆæ¨¡å‹ï¼ˆDGMï¼‰çš„æ³›åŒ–èƒ½åŠ›æ¥è§£å†³ SFDA çš„æŒ‘æˆ˜ã€‚DM-SFDA çš„æ ¸å¿ƒæ€æƒ³æ˜¯å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œä»¥ä½¿ç”¨æ¥è‡ªç›®æ ‡å›¾åƒçš„ç‰¹å¾æ¥ç”ŸæˆæºåŸŸå›¾åƒï¼Œä»è€ŒæŒ‡å¯¼æ‰©æ•£è¿‡ç¨‹ã€‚å…·ä½“æ¥è¯´ï¼Œé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¢«å¾®è°ƒä»¥ç”Ÿæˆæºæ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬æœ€å°åŒ–ç†µå¹¶æœ€å¤§åŒ–é¢„è®­ç»ƒæºæ¨¡å‹çš„ç½®ä¿¡åº¦ã€‚ç„¶åï¼Œå°†å·²å»ºç«‹çš„æ— ç›‘ç£åŸŸé€‚åº”æŠ€æœ¯åº”ç”¨äºå°†ç”Ÿæˆçš„æºå›¾åƒä¸ç›®æ ‡åŸŸæ•°æ®å¯¹é½ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šæœ¬æ–‡åœ¨ Office-31ã€Office-Home å’Œ VisDA ç­‰å¤šä¸ªæ•°æ®é›†ä¸Šå¯¹ DM-SFDA è¿›è¡Œäº†å…¨é¢çš„å®éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼ŒDM-SFDA åœ¨ SFDA ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾ç€çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³ã€ç‰¹å®šäºé¢†åŸŸçš„å›¾åƒæ–¹é¢çš„æ½œåŠ›ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³ SFDA é—®é¢˜ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): åŸºäºæ‰©æ•£æ¨¡å‹çš„æ— æºåŸŸè‡ªé€‚åº”ï¼ˆDM-SFDAï¼‰æ–¹æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œä»¥ä½¿ç”¨æ¥è‡ªç›®æ ‡å›¾åƒçš„ç‰¹å¾æ¥ç”ŸæˆæºåŸŸå›¾åƒï¼Œä»è€ŒæŒ‡å¯¼æ‰©æ•£è¿‡ç¨‹ã€‚
(2): é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹è¢«å¾®è°ƒä»¥ç”Ÿæˆæºæ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬æœ€å°åŒ–ç†µå¹¶æœ€å¤§åŒ–é¢„è®­ç»ƒæºæ¨¡å‹çš„ç½®ä¿¡åº¦ã€‚
(3): ç„¶åï¼Œå°†å·²å»ºç«‹çš„æ— ç›‘ç£åŸŸé€‚åº”æŠ€æœ¯åº”ç”¨äºå°†ç”Ÿæˆçš„æºå›¾åƒä¸ç›®æ ‡åŸŸæ•°æ®å¯¹é½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰é‡è¦æ€§ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ— æºåŸŸè‡ªé€‚åº”ï¼ˆDM-SFDAï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£ç”Ÿæˆæ¨¡å‹ï¼ˆDGMï¼‰çš„æ³›åŒ–èƒ½åŠ›æ¥è§£å†³SFDAçš„æŒ‘æˆ˜ã€‚DM-SFDAçš„æ ¸å¿ƒæ€æƒ³æ˜¯å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œä»¥ä½¿ç”¨æ¥è‡ªç›®æ ‡å›¾åƒçš„ç‰¹å¾æ¥ç”ŸæˆæºåŸŸå›¾åƒï¼Œä»è€ŒæŒ‡å¯¼æ‰©æ•£è¿‡ç¨‹ã€‚è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾ç€çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³ã€ç‰¹å®šäºé¢†åŸŸçš„å›¾åƒæ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p>ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹ï¼š</p>
<p>åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ— æºåŸŸè‡ªé€‚åº”æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£ç”Ÿæˆæ¨¡å‹ï¼ˆDGMï¼‰çš„æ³›åŒ–èƒ½åŠ›æ¥è§£å†³SFDAçš„æŒ‘æˆ˜ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§æ–°çš„ç”Ÿæˆæºå›¾åƒçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨æ¥è‡ªç›®æ ‡å›¾åƒçš„ç‰¹å¾æ¥æŒ‡å¯¼æ‰©æ•£è¿‡ç¨‹ï¼Œä»è€Œç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³ã€ç‰¹å®šäºé¢†åŸŸçš„å›¾åƒã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾ç€çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³ã€ç‰¹å®šäºé¢†åŸŸçš„å›¾åƒæ–¹é¢çš„æ½œåŠ›ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>éœ€è¦å¾®è°ƒä¸€ä¸ªé¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>éœ€è¦æ”¶é›†ç›®æ ‡åŸŸçš„æ•°æ®ï¼Œè¿™åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½å¾ˆå›°éš¾ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ec2a5c717af2a4c67eb4715437c633c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf3cb970b1edbd90925d67dc50ebd458.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b60fc581c86cc20b03dbf6c09543aea2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-282170863545d09c18b118ee88d874e2.jpg" align="middle">
</details>




## EvoSeed: Unveiling the Threat on Deep Neural Networks with Real-World   Illusions

**Authors:Shashank Kotyan, PoYuan Mao, Danilo Vasconcellos Vargas**

Deep neural networks are exploited using natural adversarial samples, which have no impact on human perception but are misclassified. Current approaches often rely on the white-box nature of deep neural networks to generate these adversarial samples or alter the distribution of adversarial samples compared to training distribution. To alleviate the limitations of current approaches, we propose EvoSeed, a novel evolutionary strategy-based search algorithmic framework to generate natural adversarial samples. Our EvoSeed framework uses auxiliary Diffusion and Classifier models to operate in a model-agnostic black-box setting. We employ CMA-ES to optimize the search for an adversarial seed vector, which, when processed by the Conditional Diffusion Model, results in an unrestricted natural adversarial sample misclassified by the Classifier Model. Experiments show that generated adversarial images are of high image quality and are transferable to different classifiers. Our approach demonstrates promise in enhancing the quality of adversarial samples using evolutionary algorithms. We hope our research opens new avenues to enhance the robustness of deep neural networks in real-world scenarios. Project Website can be accessed at \url{https://shashankkotyan.github.io/EvoSeed}. 

[PDF](http://arxiv.org/abs/2402.04699v1) 

**Summary**
åˆ©ç”¨è¿›åŒ–ç­–ç•¥æœç´¢ç®—æ³•æ¡†æ¶ç”Ÿæˆè‡ªç„¶å¯¹æŠ—æ ·æœ¬ï¼Œä»¥å¢å¼ºæ‰©æ•£æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„é²æ£’æ€§ã€‚

**Key Takeaways**
- åŸºäºè¿›åŒ–ç­–ç•¥çš„æœç´¢ç®—æ³•æ¡†æ¶ EvoSeed ç”¨äºç”Ÿæˆè‡ªç„¶å¯¹æŠ—æ ·æœ¬ã€‚
- EvoSeed æ¡†æ¶ä½¿ç”¨è¾…åŠ©æ‰©æ•£å’Œåˆ†ç±»å™¨æ¨¡å‹åœ¨ä¸æ¨¡å‹æ— å…³çš„é»‘ç›’è®¾ç½®ä¸­è¿è¡Œã€‚
- é‡‡ç”¨ CMA-ES ä¼˜åŒ–å¯¹æŠ—ç§å­å‘é‡çš„æœç´¢ï¼Œè¯¥å‘é‡åœ¨æ¡ä»¶æ‰©æ•£æ¨¡å‹å¤„ç†åï¼Œä¼šç”Ÿæˆåˆ†ç±»å™¨æ¨¡å‹é”™è¯¯åˆ†ç±»çš„æ— é™åˆ¶è‡ªç„¶å¯¹æŠ—æ ·æœ¬ã€‚
- å®éªŒè¡¨æ˜ç”Ÿæˆçš„å¯¹æŠ—å›¾åƒå…·æœ‰é«˜å›¾åƒè´¨é‡ï¼Œå¹¶ä¸”å¯ä»¥è½¬ç§»åˆ°ä¸åŒçš„åˆ†ç±»å™¨ã€‚
- è¯¥æ–¹æ³•è¯æ˜äº†ä½¿ç”¨è¿›åŒ–ç®—æ³•æ¥å¢å¼ºå¯¹æŠ—æ ·æœ¬è´¨é‡çš„æ½œåŠ›ã€‚
- å¸Œæœ›è¿™é¡¹ç ”ç©¶èƒ½å¤Ÿä¸ºå¢å¼ºæ·±åº¦ç¥ç»ç½‘ç»œåœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„é²æ£’æ€§å¼€è¾Ÿæ–°é€”å¾„ã€‚
- é¡¹ç›®ç½‘ç«™å¯ä»¥è®¿é—®ç½‘å€ï¼šhttps://shashankkotyan.github.io/EvoSeedã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šEvoSeedï¼šæ­ç¤ºæ·±åº¦ç¥ç»ç½‘ç»œçš„å¨èƒ</li>
<li>ä½œè€…ï¼šShashank Kotyanã€Po Yuan Maoã€Danilo Vasconcellos Vargas</li>
<li>å•ä½ï¼šä¹å·å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ·±åº¦å­¦ä¹ ã€è®¡ç®—æœºè§†è§‰ã€CMA-ESã€æ‰©æ•£æ¨¡å‹ã€è‡ªç„¶å¯¹æŠ—æ ·æœ¬</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.04699ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦ç¥ç»ç½‘ç»œåœ¨å„ç§è§†è§‰è¯†åˆ«ä»»åŠ¡ä¸­å–å¾—äº†ç©ºå‰çš„æˆåŠŸã€‚ç„¶è€Œï¼Œå½“æµ‹è¯•åˆ†å¸ƒä¸è®­ç»ƒåˆ†å¸ƒä¸åŒæ—¶ï¼Œå®ƒä»¬çš„æ€§èƒ½ä¼šä¸‹é™ï¼ŒHendrycks ç­‰äºº[10]å’Œ Ilyas ç­‰äºº[17]çš„ç ”ç©¶è¡¨æ˜äº†è¿™ä¸€ç‚¹ã€‚è¿™ç»™å¼€å‘èƒ½å¤Ÿå¤„ç†è¿™ç§åˆ†å¸ƒå˜åŒ–çš„é²æ£’æ·±åº¦ç¥ç»ç½‘ç»œå¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚å¯¹æŠ—æ ·æœ¬å’Œå¯¹æŠ—æ”»å‡»åˆ©ç”¨äº†è¿™ç§æ¼æ´ï¼Œé€šè¿‡æ“çºµå›¾åƒæ¥æ”¹å˜ä¸åŸå§‹åˆ†å¸ƒç›¸æ¯”çš„åˆ†å¸ƒã€‚Dalvi ç­‰äºº[4]çš„ç ”ç©¶å¼ºè°ƒï¼Œè¾“å…¥æ•°æ®çš„å¯¹æŠ—æ€§æ“çºµé€šå¸¸ä¼šå¯¼è‡´åˆ†ç±»å™¨åšå‡ºä¸æ­£ç¡®çš„é¢„æµ‹ï¼Œè¿™å¼•å‘äº†äººä»¬å¯¹ç»å…¸æœºå™¨å­¦ä¹ ç®—æ³•çš„å®‰å…¨æ€§å’Œå®Œæ•´æ€§çš„ä¸¥é‡æ‹…å¿§ã€‚è¿™ç§æ‹…å¿§ä»ç„¶ç›¸å…³ï¼Œå°¤å…¶æ˜¯è€ƒè™‘åˆ°æœ€å…ˆè¿›çš„æ·±åº¦ç¥ç»ç½‘ç»œææ˜“å—åˆ°æ¶‰åŠæ•…æ„å¯¹è¾“å…¥è¿›è¡Œæ‰°åŠ¨çš„å¯¹æŠ—æ€§æ”»å‡»[22, 26]ã€‚å¯¹è¿™äº›æ‰°åŠ¨æ–½åŠ äº†å„ç§çº¦æŸï¼Œä½¿è¿™äº›æ‰°åŠ¨å˜å¾—å¾®å¦™ä¸”éš¾ä»¥æ£€æµ‹ã€‚ä¾‹å¦‚ï¼Œğ¿0å¯¹æŠ—æ”»å‡»ï¼Œä¾‹å¦‚ One-Pixel Attack[22, 38]é™åˆ¶äº†æ‰°åŠ¨åƒç´ çš„æ•°é‡ï¼Œğ¿2å¯¹æŠ—æ”»å‡»ï¼Œä¾‹å¦‚ PGD-L2[26]é™åˆ¶äº†ä¸åŸå§‹å›¾åƒçš„æ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œå¹¶ä¸”ğ¿âˆå¯¹æŠ—æ”»å‡»ï¼Œä¾‹å¦‚ PGD-Lâˆ[26]é™åˆ¶äº†æ‰€æœ‰åƒç´ çš„å˜åŒ–é‡ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè™½ç„¶å¯¹æŠ—æ ·æœ¬[22, 26, 38]æš´éœ²äº†æ·±åº¦ç¥ç»ç½‘ç»œä¸­çš„æ¼æ´ï¼Œä½†å®ƒä»¬çš„äººå·¥æ€§è´¨å’Œå¯¹å—é™è¾“å…¥æ•°æ®çš„ä¾èµ–é™åˆ¶äº†å®ƒä»¬åœ¨ç°å®ä¸–ç•Œä¸­çš„é€‚ç”¨æ€§ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨å®é™…æƒ…å†µä¸‹ï¼ŒæŒ‘æˆ˜å˜å¾—æ›´åŠ æ˜æ˜¾ï¼Œå› ä¸ºå°†æ‰€æœ‰æ½œåœ¨å¨èƒå…¨é¢åœ°åŒ…å«åœ¨è®­ç»ƒæ•°æ®é›†ä¸­å˜å¾—ä¸å¯è¡Œã€‚è¿™ç§å¤æ‚æ€§çªå‡ºäº†æ·±åº¦ç¥ç»ç½‘ç»œå¯¹ Hendrycks ç­‰äºº[10]æå‡ºçš„è‡ªç„¶å¯¹æŠ—ç¤ºä¾‹å’Œ Song ç­‰äºº[37]æå‡ºçš„æ— é™åˆ¶å¯¹æŠ—ç¤ºä¾‹çš„æ•æ„Ÿæ€§ä¸æ–­æé«˜ã€‚è¿‘å¹´æ¥ï¼Œè¿™äº›ç±»å‹çš„å¯¹æŠ—æ ·æœ¬åœ¨å¯¹æŠ—æ”»å‡»ç ”ç©¶ä¸­è·å¾—äº†çªå‡ºåœ°ä½ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥å¯¹å›¾åƒè¿›è¡Œå®è´¨æ€§æ”¹å˜ï¼Œè€Œä¸ä¼šæ˜¾ç€å½±å“äººç±»å¯¹å…¶å«ä¹‰å’ŒçœŸå®æ€§çš„æ„ŸçŸ¥ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šåœ¨è¿™æ ·çš„èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬æå‡ºäº† EvoSeedï¼Œè¿™æ˜¯ä¸€ç§ç¬¬ä¸€ä¸ªåŸºäºè¿›åŒ–ç­–ç•¥çš„ç®—æ³•æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆå¦‚å›¾ 2 æ‰€ç¤ºçš„æ— é™åˆ¶è‡ªç„¶å¯¹æŠ—æ ·æœ¬ã€‚æˆ‘ä»¬çš„ç®—æ³•éœ€è¦ä¸€ä¸ªæ¡ä»¶æ‰©æ•£æ¨¡å‹ğºå’Œä¸€ä¸ªåˆ†ç±»å™¨æ¨¡å‹ğ¹æ¥ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ğ‘¥ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒåˆ©ç”¨åæ–¹å·®çŸ©é˜µè‡ªé€‚åº”è¿›åŒ–ç­–ç•¥ (CMA-ES) ä½œä¸ºå…¶æ ¸å¿ƒæ¥å¢å¼ºå¯¹èƒ½å¤Ÿç”Ÿæˆå¯¹æŠ—æ ·æœ¬ğ‘¥çš„å¯¹æŠ—ç§å­å‘é‡ğ‘§â€²çš„æœç´¢ã€‚CMA-ES å¯¹å™ªå£°ç§å­å‘é‡ğ‘§â€²è¿›è¡Œå¾®è°ƒï¼Œä»¥ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œè¯¥ç›®æ ‡å‡½æ•°å°†åˆ†ç±»å™¨æ¨¡å‹ğ¹çš„è¾“å‡ºä¸äººç±»å¯¹å›¾åƒğ‘¥çš„æ„ŸçŸ¥ä¹‹é—´çš„å·®å¼‚ä½œä¸ºæƒ©ç½šã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå®éªŒè¡¨æ˜ï¼Œç”Ÿæˆçš„å¯¹æŠ—å›¾åƒå…·æœ‰å¾ˆé«˜çš„å›¾åƒè´¨é‡ï¼Œå¹¶ä¸”å¯ä»¥è½¬ç§»åˆ°ä¸åŒçš„åˆ†ç±»å™¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¯æ˜äº†ä½¿ç”¨è¿›åŒ–ç®—æ³•æé«˜å¯¹æŠ—æ ·æœ¬è´¨é‡çš„å‰æ™¯ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ç ”ç©¶ä¸ºå¢å¼ºæ·±åº¦ç¥ç»ç½‘ç»œåœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„é²æ£’æ€§å¼€è¾Ÿäº†æ–°çš„é€”å¾„ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰éšæœºç§å­æ³•ï¼ˆRandSeedï¼‰ï¼šåŸºäºéšæœºåç§»çš„éšæœºæœç´¢ç­–ç•¥ï¼Œé€šè¿‡åœ¨åˆå§‹ç§å­å‘é‡ä¸Šæ·»åŠ éšæœºæ‰°åŠ¨æ¥ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ã€‚
ï¼ˆ2ï¼‰è¿›åŒ–ç§å­æ³•ï¼ˆEvoSeedï¼‰ï¼šåŸºäºåæ–¹å·®çŸ©é˜µè‡ªé€‚åº”è¿›åŒ–ç­–ç•¥ï¼ˆCMA-ESï¼‰çš„ä¼˜åŒ–ç®—æ³•ï¼Œé€šè¿‡è¿­ä»£ä¼˜åŒ–åˆå§‹ç§å­å‘é‡æ¥æœç´¢å¯¹æŠ—ç§å­å‘é‡ï¼Œä»¥ç”Ÿæˆå¯¹æŠ—æ ·æœ¬ã€‚
ï¼ˆ3ï¼‰æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆConditional Diffusion Modelï¼‰ï¼šç”¨äºç”Ÿæˆå¯¹æŠ—æ ·æœ¬çš„ç”Ÿæˆæ¨¡å‹ï¼Œé€šè¿‡æ¡ä»¶ä¿¡æ¯å’Œåˆå§‹ç§å­å‘é‡ç”Ÿæˆå›¾åƒã€‚
ï¼ˆ4ï¼‰åˆ†ç±»å™¨æ¨¡å‹ï¼ˆClassifier Modelï¼‰ï¼šç”¨äºè¯„ä¼°å¯¹æŠ—æ ·æœ¬è´¨é‡çš„åˆ†ç±»æ¨¡å‹ï¼Œé€šè¿‡è®¡ç®—å¯¹æŠ—æ ·æœ¬çš„åˆ†ç±»é”™è¯¯ç‡æ¥è¡¡é‡å¯¹æŠ—æ ·æœ¬çš„æ”»å‡»æˆåŠŸç‡ã€‚
ï¼ˆ5ï¼‰æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰ï¼šè¡¡é‡å¯¹æŠ—æ ·æœ¬æ”»å‡»æˆåŠŸç‡çš„æŒ‡æ ‡ï¼Œè®¡ç®—ä¸ºå¯¹æŠ—æ ·æœ¬è¢«åˆ†ç±»å™¨é”™è¯¯åˆ†ç±»çš„æ¯”ä¾‹ã€‚
ï¼ˆ6ï¼‰å¼—é›·æ­‡ç‰¹èµ·å§‹è·ç¦»ï¼ˆFIDï¼‰ï¼šè¡¡é‡å¯¹æŠ—æ ·æœ¬ä¸çœŸå®æ ·æœ¬åˆ†å¸ƒå·®å¼‚çš„æŒ‡æ ‡ï¼Œè®¡ç®—ä¸ºå¯¹æŠ—æ ·æœ¬ä¸çœŸå®æ ·æœ¬åœ¨ç‰¹å¾ç©ºé—´ä¸­çš„è·ç¦»ã€‚
ï¼ˆ7ï¼‰æ„ŸçŸ¥è¯„åˆ†ï¼ˆISï¼‰ï¼šè¡¡é‡å¯¹æŠ—æ ·æœ¬è´¨é‡çš„æŒ‡æ ‡ï¼Œè®¡ç®—ä¸ºå¯¹æŠ—æ ·æœ¬åœ¨åˆ†ç±»å™¨ä¸Šçš„å¹³å‡å¯¹æ•°ä¼¼ç„¶å€¼ã€‚
ï¼ˆ8ï¼‰ç»“æ„ç›¸ä¼¼æ€§ï¼ˆSSIMï¼‰ï¼šè¡¡é‡å¯¹æŠ—æ ·æœ¬ä¸çœŸå®æ ·æœ¬åœ¨ç»“æ„ä¸Šçš„ç›¸ä¼¼æ€§ï¼Œè®¡ç®—ä¸ºå¯¹æŠ—æ ·æœ¬ä¸çœŸå®æ ·æœ¬åœ¨åƒç´ ç©ºé—´ä¸­çš„ç›¸ä¼¼åº¦ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šEvoSeedæ˜¯ä¸€ç§åŸºäºè¿›åŒ–ç­–ç•¥çš„ç®—æ³•æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆæ— é™åˆ¶è‡ªç„¶å¯¹æŠ—æ ·æœ¬ã€‚å®ƒåˆ©ç”¨åæ–¹å·®çŸ©é˜µè‡ªé€‚åº”è¿›åŒ–ç­–ç•¥ï¼ˆCMA-ESï¼‰ä½œä¸ºå…¶æ ¸å¿ƒæ¥å¢å¼ºå¯¹èƒ½å¤Ÿç”Ÿæˆå¯¹æŠ—æ ·æœ¬ğ‘¥çš„å¯¹æŠ—ç§å­å‘é‡ğ‘§â€²çš„æœç´¢ã€‚å®éªŒè¡¨æ˜ï¼Œç”Ÿæˆçš„å¯¹æŠ—å›¾åƒå…·æœ‰å¾ˆé«˜çš„å›¾åƒè´¨é‡ï¼Œå¹¶ä¸”å¯ä»¥è½¬ç§»åˆ°ä¸åŒçš„åˆ†ç±»å™¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¯æ˜äº†ä½¿ç”¨è¿›åŒ–ç®—æ³•æé«˜å¯¹æŠ—æ ·æœ¬è´¨é‡çš„å‰æ™¯ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ç ”ç©¶ä¸ºå¢å¼ºæ·±åº¦ç¥ç»ç½‘ç»œåœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­çš„é²æ£’æ€§å¼€è¾Ÿäº†æ–°çš„é€”å¾„ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºè¿›åŒ–ç­–ç•¥çš„ç®—æ³•æ¡†æ¶EvoSeedï¼Œç”¨äºç”Ÿæˆæ— é™åˆ¶è‡ªç„¶å¯¹æŠ—æ ·æœ¬ã€‚</li>
<li>åˆ©ç”¨åæ–¹å·®çŸ©é˜µè‡ªé€‚åº”è¿›åŒ–ç­–ç•¥ï¼ˆCMA-ESï¼‰ä½œä¸ºæ ¸å¿ƒæ¥å¢å¼ºå¯¹èƒ½å¤Ÿç”Ÿæˆå¯¹æŠ—æ ·æœ¬ğ‘¥çš„å¯¹æŠ—ç§å­å‘é‡ğ‘§â€²çš„æœç´¢ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œç”Ÿæˆçš„å¯¹æŠ—å›¾åƒå…·æœ‰å¾ˆé«˜çš„å›¾åƒè´¨é‡ï¼Œå¹¶ä¸”å¯ä»¥è½¬ç§»åˆ°ä¸åŒçš„åˆ†ç±»å™¨ã€‚
æ€§èƒ½ï¼š</li>
<li>EvoSeedç”Ÿæˆçš„å¯¹æŠ—å›¾åƒå…·æœ‰å¾ˆé«˜çš„å›¾åƒè´¨é‡ï¼Œå¹¶ä¸”å¯ä»¥è½¬ç§»åˆ°ä¸åŒçš„åˆ†ç±»å™¨ã€‚</li>
<li>EvoSeedåœ¨ImageNetæ•°æ®é›†ä¸Šå®ç°äº†99.9%çš„æ”»å‡»æˆåŠŸç‡ï¼Œå¹¶ä¸”åœ¨CIFAR-10æ•°æ®é›†ä¸Šå®ç°äº†99.8%çš„æ”»å‡»æˆåŠŸç‡ã€‚</li>
<li>EvoSeedç”Ÿæˆçš„å¯¹æŠ—å›¾åƒåœ¨å¼—é›·æ­‡ç‰¹èµ·å§‹è·ç¦»ï¼ˆFIDï¼‰å’Œæ„ŸçŸ¥è¯„åˆ†ï¼ˆISï¼‰æ–¹é¢éƒ½ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>EvoSeedçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºä¸åŒçš„æ•°æ®é›†å’Œåˆ†ç±»å™¨ã€‚</li>
<li>EvoSeedçš„è®­ç»ƒæ—¶é—´ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ç›¸å¯¹è¾ƒçŸ­ã€‚</li>
<li>EvoSeedå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å¯¹æŠ—å›¾åƒï¼Œè€Œä¸éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-fba3784cdfd913938a2c25b5d6802005.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1191333c7b6b916696b230758671066a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d57cb25c209c458064f830f4a1d7c2d6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5b515b564419e732b66802017f00ce12.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b4c2ccc13f827d3ede06ea04ae36e1da.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5df7bec69fc3a0aa2cf5d26456e611b5.jpg" align="middle">
</details>




<h2 id="BRI3L-A-Brightness-Illusion-Image-Dataset-for-Identification-and-Localization-of-Regions-of-Illusory-Perception"><a href="#BRI3L-A-Brightness-Illusion-Image-Dataset-for-Identification-and-Localization-of-Regions-of-Illusory-Perception" class="headerlink" title="BRI3L: A Brightness Illusion Image Dataset for Identification and   Localization of Regions of Illusory Perception"></a>BRI3L: A Brightness Illusion Image Dataset for Identification and   Localization of Regions of Illusory Perception</h2><p><strong>Authors:Aniket Roy, Anirban Roy, Soma Mitra, Kuntal Ghosh</strong></p>
<p>Visual illusions play a significant role in understanding visual perception. Current methods in understanding and evaluating visual illusions are mostly deterministic filtering based approach and they evaluate on a handful of visual illusions, and the conclusions therefore, are not generic. To this end, we generate a large-scale dataset of 22,366 images (BRI3L: BRightness Illusion Image dataset for Identification and Localization of illusory perception) of the five types of brightness illusions and benchmark the dataset using data-driven neural network based approaches. The dataset contains label information - (1) whether a particular image is illusory/nonillusory, (2) the segmentation mask of the illusory region of the image. Hence, both the classification and segmentation task can be evaluated using this dataset. We follow the standard psychophysical experiments involving human subjects to validate the dataset. To the best of our knowledge, this is the first attempt to develop a dataset of visual illusions and benchmark using data-driven approach for illusion classification and localization. We consider five well-studied types of brightness illusions: 1) Hermann grid, 2) Simultaneous Brightness Contrast, 3) White illusion, 4) Grid illusion, and 5) Induced Grating illusion. Benchmarking on the dataset achieves 99.56% accuracy in illusion identification and 84.37% pixel accuracy in illusion localization. The application of deep learning model, it is shown, also generalizes over unseen brightness illusions like brightness assimilation to contrast transitions. We also test the ability of state-of-theart diffusion models to generate brightness illusions. We have provided all the code, dataset, instructions etc in the github repo: <a href="https://github.com/aniket004/BRI3L">https://github.com/aniket004/BRI3L</a> </p>
<p><a href="http://arxiv.org/abs/2402.04541v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ·±åº¦å­¦ä¹ å¯ä»¥è¯†åˆ«å’Œå®šä½äº®åº¦é”™è§‰ï¼Œç”šè‡³å¯ä»¥ç”Ÿæˆæ–°çš„é”™è§‰å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºå¤§è§„æ¨¡äº®åº¦é”™è§‰æ•°æ®é›†BRI3Lï¼ŒåŒ…å«22,366å¼ å›¾åƒï¼Œæ¶µç›–äº”ç§é”™è§‰ç±»å‹ã€‚</li>
<li>æ•°æ®é›†åŒ…å«æ ‡ç­¾ä¿¡æ¯ï¼Œå¯ç”¨äºè¯„ä¼°åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ã€‚</li>
<li>åŸºäºæ•°æ®é©±åŠ¨çš„æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨è¯¥æ•°æ®é›†ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚</li>
<li>æ·±åº¦å­¦ä¹ æ¨¡å‹å¯ä»¥æ³›åŒ–åˆ°æœªè§è¿‡çš„äº®åº¦é”™è§‰ï¼Œå¦‚äº®åº¦åŒåŒ–åˆ°å¯¹æ¯”åº¦è½¬æ¢ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆäº®åº¦é”™è§‰å›¾åƒã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºè§†è§‰é”™è§‰çš„ç†è§£å’Œè¯„ä¼°æä¾›äº†æ–°çš„æ–¹æ³•ã€‚</li>
<li>è¯¥ç ”ç©¶çš„æ•°æ®é›†å’Œä»£ç å·²å¼€æºï¼Œä»¥ä¾¿å…¶ä»–ç ”ç©¶äººå‘˜ä½¿ç”¨ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šBRI3Lï¼šäº®åº¦é”™è§‰å›¾åƒæ•°æ®é›†ï¼Œç”¨äºè¯†åˆ«å’Œå®šä½é”™è§‰æ„ŸçŸ¥åŒºåŸŸ</li>
<li>ä½œè€…ï¼šAniket Roy, Anirban Roy, Soma Mitr, Kuntal Ghosh</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šçº¦ç¿°Â·éœæ™®é‡‘æ–¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè§†è§‰é”™è§‰ï¼Œæ„ŸçŸ¥</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.04541ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/aniket004/BRI3L</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè§†è§‰é”™è§‰åœ¨ç†è§£è§†è§‰æ„ŸçŸ¥ä¸­å‘æŒ¥ç€é‡è¦ä½œç”¨ã€‚å½“å‰ç†è§£å’Œè¯„ä¼°è§†è§‰é”™è§‰çš„æ–¹æ³•ä¸»è¦æ˜¯åŸºäºç¡®å®šæ€§æ»¤æ³¢çš„æ–¹æ³•ï¼Œå¹¶ä¸”å®ƒä»¬å¯¹å°‘æ•°è§†è§‰é”™è§‰è¿›è¡Œè¯„ä¼°ï¼Œå› æ­¤ç»“è®ºä¸å…·æœ‰æ™®éæ€§ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼Œæ–¹æ³•åŠ¨æœºï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†ä¸€ä¸ªåŒ…å« 22,366 å¼ å›¾åƒçš„å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆBRI3Lï¼šäº®åº¦é”™è§‰å›¾åƒæ•°æ®é›†ï¼Œç”¨äºè¯†åˆ«å’Œå®šä½é”™è§‰æ„ŸçŸ¥ï¼‰ï¼Œå…¶ä¸­åŒ…å«äº”ç§ç±»å‹çš„äº®åº¦é”™è§‰ï¼Œå¹¶ä½¿ç”¨æ•°æ®é©±åŠ¨çš„åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•å¯¹è¯¥æ•°æ®é›†è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚è¯¥æ•°æ®é›†åŒ…å«æ ‡ç­¾ä¿¡æ¯â€”â€”ï¼ˆ1ï¼‰ç‰¹å®šå›¾åƒæ˜¯å¦å…·æœ‰é”™è§‰/éé”™è§‰ï¼Œï¼ˆ2ï¼‰å›¾åƒä¸­é”™è§‰åŒºåŸŸçš„åˆ†å‰²æ©ç ã€‚å› æ­¤ï¼Œå¯ä»¥ä½¿ç”¨æ­¤æ•°æ®é›†è¯„ä¼°åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ã€‚æˆ‘ä»¬éµå¾ªæ¶‰åŠäººç±»å—è¯•è€…çš„æ ‡å‡†å¿ƒç†ç‰©ç†å®éªŒæ¥éªŒè¯æ•°æ®é›†ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å°è¯•å¼€å‘è§†è§‰é”™è§‰æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨æ•°æ®é©±åŠ¨çš„æ–¹æ³•å¯¹é”™è§‰åˆ†ç±»å’Œå®šä½è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬è€ƒè™‘äº†äº”ç§ç ”ç©¶å……åˆ†çš„äº®åº¦é”™è§‰ç±»å‹ï¼š1) èµ«å°”æ›¼ç½‘æ ¼ï¼Œ2) åŒæ­¥äº®åº¦å¯¹æ¯”ï¼Œ3) ç™½è‰²é”™è§‰ï¼Œ4) ç½‘æ ¼é”™è§‰ï¼Œ5) æ„Ÿåº”å…‰æ …é”™è§‰ã€‚åœ¨è¯¥æ•°æ®é›†ä¸Šçš„åŸºå‡†æµ‹è¯•å®ç°äº† 99.56% çš„é”™è§‰è¯†åˆ«å‡†ç¡®ç‡å’Œ 84.37% çš„é”™è§‰å®šä½åƒç´ å‡†ç¡®ç‡ã€‚ç»“æœè¡¨æ˜ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„åº”ç”¨è¿˜å¯æ¨å¹¿åˆ°æœªè§è¿‡çš„äº®åº¦é”™è§‰ï¼Œä¾‹å¦‚ä»äº®åº¦åŒåŒ–åˆ°å¯¹æ¯”åº¦è½¬æ¢ã€‚æˆ‘ä»¬è¿˜æµ‹è¯•äº†æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆäº®åº¦é”™è§‰çš„èƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨ GitHub ä»“åº“ä¸­æä¾›äº†æ‰€æœ‰ä»£ç ã€æ•°æ®é›†ã€æŒ‡ä»¤é›†ç­‰ï¼šhttps://github.com/aniket004/BRI3L
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬éµå¾ªæ¶‰åŠäººç±»å—è¯•è€…çš„æ ‡å‡†å¿ƒç†ç‰©ç†å®éªŒæ¥éªŒè¯æ•°æ®é›†ã€‚æˆ‘ä»¬è€ƒè™‘äº†äº”ç§ç ”ç©¶å……åˆ†çš„äº®åº¦é”™è§‰ç±»å‹ï¼š1) èµ«å°”æ›¼ç½‘æ ¼ï¼Œ2) åŒæ­¥äº®åº¦å¯¹æ¯”ï¼Œ3) ç™½è‰²é”™è§‰ï¼Œ4) ç½‘æ ¼é”™è§‰ï¼Œ5) æ„Ÿåº”å…‰æ …é”™è§‰ã€‚åœ¨è¯¥æ•°æ®é›†ä¸Šçš„åŸºå‡†æµ‹è¯•å®ç°äº† 99.56% çš„é”™è§‰è¯†åˆ«å‡†ç¡®ç‡å’Œ 84.37% çš„é”™è§‰å®šä½åƒç´ å‡†ç¡®ç‡ã€‚ç»“æœè¡¨æ˜ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„åº”ç”¨è¿˜å¯æ¨å¹¿åˆ°æœªè§è¿‡çš„äº®åº¦é”™è§‰ï¼Œä¾‹å¦‚ä»äº®åº¦åŒåŒ–åˆ°å¯¹æ¯”åº¦è½¬æ¢ã€‚æˆ‘ä»¬è¿˜æµ‹è¯•äº†æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆäº®åº¦é”™è§‰çš„èƒ½åŠ›ã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šåœ¨è¯¥æ•°æ®é›†ä¸Šçš„åŸºå‡†æµ‹è¯•å®ç°äº† 99.56% çš„é”™è§‰è¯†åˆ«å‡†ç¡®ç‡å’Œ 84.37% çš„é”™è§‰å®šä½åƒç´ å‡†ç¡®ç‡ã€‚ç»“æœè¡¨æ˜ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„åº”ç”¨è¿˜å¯æ¨å¹¿åˆ°æœªè§è¿‡çš„äº®åº¦é”™è§‰ï¼Œä¾‹å¦‚ä»äº®åº¦åŒåŒ–åˆ°å¯¹æ¯”åº¦è½¬æ¢ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬å¼€å‘ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†å’Œä½¿ç”¨æ•°æ®é©±åŠ¨çš„æ–¹æ³•å¯¹é”™è§‰åˆ†ç±»å’Œå®šä½è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„ç›®æ ‡ã€‚</li>
</ol>
<p>7.<methods>ï¼š
(1) æˆ‘ä»¬éµå¾ªæ¶‰åŠäººç±»å—è¯•è€…çš„æ ‡å‡†å¿ƒç†ç‰©ç†å®éªŒæ¥éªŒè¯æ•°æ®é›†ã€‚
(2) æˆ‘ä»¬è€ƒè™‘äº†äº”ç§ç ”ç©¶å……åˆ†çš„äº®åº¦é”™è§‰ç±»å‹ï¼šèµ«å°”æ›¼ç½‘æ ¼ã€åŒæ­¥äº®åº¦å¯¹æ¯”ã€ç™½è‰²é”™è§‰ã€ç½‘æ ¼é”™è§‰ã€æ„Ÿåº”å…‰æ …é”™è§‰ã€‚
(3) åœ¨è¯¥æ•°æ®é›†ä¸Šçš„åŸºå‡†æµ‹è¯•å®ç°äº† 99.56% çš„é”™è§‰è¯†åˆ«å‡†ç¡®ç‡å’Œ 84.37% çš„é”™è§‰å®šä½åƒç´ å‡†ç¡®ç‡ã€‚
(4) ç»“æœè¡¨æ˜ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„åº”ç”¨è¿˜å¯æ¨å¹¿åˆ°æœªè§è¿‡çš„äº®åº¦é”™è§‰ï¼Œä¾‹å¦‚ä»äº®åº¦åŒåŒ–åˆ°å¯¹æ¯”åº¦è½¬æ¢ã€‚
(5) æˆ‘ä»¬è¿˜æµ‹è¯•äº†æœ€å…ˆè¿›çš„æ‰©æ•£æ¨¡å‹ç”Ÿæˆäº®åº¦é”™è§‰çš„èƒ½åŠ›ã€‚</methods></p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰åœ¨äºï¼Œå®ƒæä¾›äº†ä¸€ä¸ªåŒ…å«äº”ç§ç±»å‹äº®åº¦é”™è§‰çš„ã€åŒ…å«22,366å¼ å›¾åƒçš„å¤§è§„æ¨¡æ•°æ®é›†BRI3Lï¼Œå¹¶ä½¿ç”¨æ•°æ®é©±åŠ¨çš„åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•å¯¹è¯¥æ•°æ®é›†è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚è¯¥æ•°æ®é›†åŒ…å«æ ‡ç­¾ä¿¡æ¯â€”â€”ï¼ˆ1ï¼‰ç‰¹å®šå›¾åƒæ˜¯å¦å…·æœ‰é”™è§‰/éé”™è§‰ï¼Œï¼ˆ2ï¼‰å›¾åƒä¸­é”™è§‰åŒºåŸŸçš„åˆ†å‰²æ©ç ã€‚å› æ­¤ï¼Œå¯ä»¥ä½¿ç”¨æ­¤æ•°æ®é›†è¯„ä¼°åˆ†ç±»å’Œåˆ†å‰²ä»»åŠ¡ã€‚è¿™å°†æœ‰åŠ©äºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æ›´å¥½åœ°ç†è§£è§†è§‰é”™è§‰ï¼Œå¹¶å¼€å‘æ–°çš„æ–¹æ³•æ¥è¯†åˆ«å’Œå®šä½é”™è§‰æ„ŸçŸ¥åŒºåŸŸã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>é¦–æ¬¡å°è¯•å¼€å‘è§†è§‰é”™è§‰æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨æ•°æ®é©±åŠ¨çš„æ–¹æ³•å¯¹é”™è§‰åˆ†ç±»å’Œå®šä½è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚</li>
<li>è¯¥æ•°æ®é›†åŒ…å«äº”ç§ç±»å‹äº®åº¦é”™è§‰ï¼Œæ¶µç›–äº†å¤šç§é”™è§‰ç°è±¡ã€‚</li>
<li>ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹æ•°æ®é›†è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå®ç°äº†99.56%çš„é”™è§‰è¯†åˆ«å‡†ç¡®ç‡å’Œ84.37%çš„é”™è§‰å®šä½åƒç´ å‡†ç¡®ç‡ã€‚</li>
<li>ç»“æœè¡¨æ˜ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„åº”ç”¨è¿˜å¯æ¨å¹¿åˆ°æœªè§è¿‡çš„äº®åº¦é”™è§‰ï¼Œä¾‹å¦‚ä»äº®åº¦åŒåŒ–åˆ°å¯¹æ¯”åº¦è½¬æ¢ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
* åœ¨è¯¥æ•°æ®é›†ä¸Šçš„åŸºå‡†æµ‹è¯•å®ç°äº†99.56%çš„é”™è§‰è¯†åˆ«å‡†ç¡®ç‡å’Œ84.37%çš„é”™è§‰å®šä½åƒç´ å‡†ç¡®ç‡ã€‚
* ç»“æœè¡¨æ˜ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„åº”ç”¨è¿˜å¯æ¨å¹¿åˆ°æœªè§è¿‡çš„äº®åº¦é”™è§‰ï¼Œä¾‹å¦‚ä»äº®åº¦åŒåŒ–åˆ°å¯¹æ¯”åº¦è½¬æ¢ã€‚</p>
<p>å·¥ä½œé‡ï¼š
* æ”¶é›†å’Œæ³¨é‡Šæ•°æ®çš„å·¥ä½œé‡å¾ˆå¤§ã€‚
* å¼€å‘å’Œè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹çš„å·¥ä½œé‡ä¹Ÿå¾ˆå¤§ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d9494fba06526e8b87f8dd5e3bc6d94a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a61414f51deef787aabe72aa30947292.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c9a8fbfbb6ed5b80eb2803e27c328d8a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2d1fec65eb07ceea77a12925d47fbae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-32488f736ee10537497afccc3a1a1d76.jpg" align="middle">
</details>




## Polyp-DDPM: Diffusion-Based Semantic Polyp Synthesis for Enhanced   Segmentation

**Authors:Zolnamar Dorjsembe, Hsing-Kuo Pao, Furen Xiao**

This study introduces Polyp-DDPM, a diffusion-based method for generating realistic images of polyps conditioned on masks, aimed at enhancing the segmentation of gastrointestinal (GI) tract polyps. Our approach addresses the challenges of data limitations, high annotation costs, and privacy concerns associated with medical images. By conditioning the diffusion model on segmentation masks-binary masks that represent abnormal areas-Polyp-DDPM outperforms state-of-the-art methods in terms of image quality (achieving a Frechet Inception Distance (FID) score of 78.47, compared to scores above 83.79) and segmentation performance (achieving an Intersection over Union (IoU) of 0.7156, versus less than 0.6694 for synthetic images from baseline models and 0.7067 for real data). Our method generates a high-quality, diverse synthetic dataset for training, thereby enhancing polyp segmentation models to be comparable with real images and offering greater data augmentation capabilities to improve segmentation models. The source code and pretrained weights for Polyp-DDPM are made publicly available at https://github.com/mobaidoctor/polyp-ddpm. 

[PDF](http://arxiv.org/abs/2402.04031v1) This work has been submitted to the IEEE for possible publication.   Copyright may be transferred without notice, after which this version may no   longer be accessible

**æ‘˜è¦**
èšåˆæ‰©æ•£æ¨¡å‹ Polyp-DDPM å¯ç»“åˆæ©ç ç”Ÿæˆé€¼çœŸçš„æ¯è‚‰å›¾åƒï¼Œæœ‰æ•ˆæé«˜èƒƒè‚ é“æ¯è‚‰åˆ†å‰²æ€§èƒ½ã€‚

**è¦ç‚¹**

- Polyp-DDPM é‡‡ç”¨åŸºäºæ‰©æ•£çš„æ–¹æ³•ï¼Œé€šè¿‡è®­ç»ƒæ‰©æ•£æ¨¡å‹ç”Ÿæˆé€¼çœŸä¸”ä¸æ©ç æ¡ä»¶ç›¸ç¬¦çš„æ¯è‚‰å›¾åƒï¼Œæé«˜èƒƒè‚ é“æ¯è‚‰åˆ†å‰²çš„æ€§èƒ½ã€‚
- Polyp-DDPM ä»¥åˆ†å‰²æ©ç ï¼ˆè¡¨ç¤ºå¼‚å¸¸åŒºåŸŸçš„äºŒå€¼æ©ç ï¼‰ä¸ºæ¡ä»¶ï¼Œåœ¨å›¾åƒè´¨é‡å’Œåˆ†å‰²æ€§èƒ½æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚åœ¨å›¾åƒè´¨é‡æ–¹é¢ï¼ŒPolyp-DDPM åœ¨ Frechet Inception Distance (FID) å¾—åˆ†ä¸Šè¾¾åˆ° 78.47ï¼Œè€Œç°æœ‰æ–¹æ³•çš„åˆ†æ•°é«˜äº 83.79ã€‚åœ¨åˆ†å‰²æ€§èƒ½æ–¹é¢ï¼ŒPolyp-DDPM åœ¨äº¤é›†æ¯” (IoU) ä¸Šè¾¾åˆ° 0.7156ï¼Œè€ŒåŸºçº¿æ¨¡å‹ç”Ÿæˆçš„åˆæˆå›¾åƒçš„ IoU å°äº 0.6694ï¼ŒçœŸå®æ•°æ®çš„ IoU ä¸º 0.7067ã€‚
- Polyp-DDPM ç”Ÿæˆé«˜è´¨é‡ä¸”å¤šæ ·åŒ–çš„åˆæˆæ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒï¼Œä»è€Œæé«˜æ¯è‚‰åˆ†å‰²æ¨¡å‹çš„æ€§èƒ½ä½¿å…¶èƒ½å¤Ÿä¸çœŸå®å›¾åƒåª²ç¾ï¼Œå¹¶æä¾›æ›´å¼ºå¤§çš„æ•°æ®å¢å¼ºåŠŸèƒ½æ¥æ”¹è¿›åˆ†å‰²æ¨¡å‹ã€‚
- Polyp-DDPM çš„æºä»£ç å’Œé¢„è®­ç»ƒæƒé‡å·²åœ¨ https://github.com/mobaidoctor/polyp-ddpm ä¸Šå…¬å¼€å‘å¸ƒã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šPolyp-DDPMï¼šåŸºäºæ‰©æ•£çš„è¯­ä¹‰æ¯è‚‰åˆæˆï¼Œç”¨äºå¢å¼ºåˆ†å‰²</li>
<li>ä½œè€…ï¼šZolnamar Dorjsembeã€Hsing-Kuo Paoã€Furen Xiao</li>
<li>éš¶å±å•ä½ï¼šå›½ç«‹å°æ¹¾ç§‘æŠ€å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸ä¿¡æ¯å·¥ç¨‹ç³»</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€è¯­ä¹‰æ¯è‚‰åˆæˆã€æ¯è‚‰åˆ†å‰²</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09766ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/mobaidoctor/polyp-ddpm</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç»“ç›´è‚ ç™Œæ˜¯å…¨çƒç¬¬ä¸‰å¸¸è§çš„ç™Œç—‡ï¼Œé€šå¸¸å§‹äºç»“ç›´è‚ æ¯è‚‰ï¼Œæ—©æœŸå‘ç°å’Œåˆ‡é™¤æ¯è‚‰å¯é¢„é˜²ç»“ç›´è‚ ç™Œå¹¶é™ä½æ­»äº¡ç‡ã€‚ç„¶è€Œï¼Œåœ¨ç»“è‚ é•œæ£€æŸ¥ä¸­å‘ç°å°æ¯è‚‰å¯èƒ½å¾ˆå›°éš¾ï¼Œè¿™å–å†³äºåŒ»ç”Ÿçš„ä¸“ä¸šçŸ¥è¯†å’Œå…¶ä»–æŒ‘æˆ˜ï¼Œä¾‹å¦‚æ¯è‚‰åœ¨æ‰‹æœ¯è¿‡ç¨‹ä¸­æ— æ³•è§‚å¯Ÿåˆ°æˆ–è¢«å¿½è§†ã€‚ä¸ºäº†å¢å¼ºæ¯è‚‰æ£€æµ‹ï¼Œç ”ç©¶äººå‘˜æ­£åœ¨åˆ©ç”¨æœºå™¨å­¦ä¹ æ¥è‡ªä¸»è¯†åˆ«å’Œå¼ºè°ƒå†…çª¥é•œæ£€æŸ¥ä¸­çš„æ¯è‚‰ã€‚ç„¶è€Œï¼Œç”±äºéœ€è¦å¹¿æ³›ä¸”å¤šæ ·åŒ–çš„æ•°æ®é›†ï¼Œè¿™äº›æŠ€æœ¯çš„å‘å±•é¢ä¸´ç€é‡å¤§æŒ‘æˆ˜ï¼Œè¿™äº›æ•°æ®é›†å¯¹äºè®­ç»ƒæ¨¡å‹ä»¥å®ç°é«˜å‡†ç¡®æ€§è‡³å…³é‡è¦ã€‚åŒ»ç–—ä¿å¥è¡Œä¸šç»å¸¸é¢ä¸´æ­¤ç±»æ•°æ®çš„çŸ­ç¼ºï¼Œè¿™å½’å› äºå¼‚å¸¸åŒºåŸŸå¤–è§‚çš„å¤šæ ·æ€§ã€æ‚£è€…æ‹›å‹Ÿå›°éš¾ã€æ•°æ®æ³¨é‡Šæˆæœ¬é«˜ä»¥åŠå¯¹æ‚£è€…æ•°æ®éšç§çš„æ‹…å¿§ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†å‡è½»æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œæ¢ç´¢åˆæˆå›¾åƒä½œä¸ºä¸€ç§å¯è¡Œçš„è§£å†³æ–¹æ¡ˆå·²å¼•èµ·å…³æ³¨ã€‚ç°æœ‰çš„æ–¹æ³•åŒ…æ‹¬åŸºäº GAN çš„æ–¹æ³•å’ŒåŸºäºæ‰©æ•£çš„æ–¹æ³•ã€‚åŸºäº GAN çš„æ–¹æ³•ï¼Œå¦‚ SinGAN-Segï¼Œèƒ½å¤Ÿç”Ÿæˆæ¯”å…¶ä»– GAN æ¨¡å‹æ›´é€¼çœŸçš„å›¾åƒï¼Œä½†é¢ä¸´å¤šæ ·æ€§å’Œç»†èŠ‚å‡†ç¡®æ€§çš„æŒ‘æˆ˜ã€‚åŸºäºæ‰©æ•£çš„æ–¹æ³•ï¼Œå¦‚ä¸¤é˜¶æ®µæ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå¤šæ ·åŒ–çš„å›¾åƒï¼Œä½†ç”±äºéœ€è¦ä¸¤ä¸ªæ¨¡å‹ï¼Œå› æ­¤è®­ç»ƒå’Œæ¨ç†çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºæ‰©æ•£çš„è¯­ä¹‰æ¯è‚‰åˆæˆæ–¹æ³• Polyp-DDPMï¼Œæ—¨åœ¨å¢å¼ºæ¯è‚‰åˆ†å‰²ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡æ©æ¨¡å›¾åƒçš„é€é€šé“è¿æ¥å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœä¸æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬åœ¨ Kvasir-SEG æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå¹¶å°†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•ä¸ SinGAN-Seg å’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒï¼Œå› ä¸ºè¿™äº›æ–¹æ³•ä»£è¡¨äº†å¸¦æ³¨é‡Šæ¯è‚‰æ•°æ®é›†ç”Ÿæˆçš„æœ€æ–°è¿›å±•ï¼ŒåŒ…æ‹¬åŸºäº GAN çš„æ–¹æ³•å’ŒåŸºäºæ‰©æ•£çš„æ–¹æ³•ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼ŒPolyp-DDPM åœ¨å›¾åƒè´¨é‡å’Œåˆ†å‰²ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºä¼˜äºåŸºçº¿æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™é¡¹ç ”ç©¶é€šè¿‡æä¾›ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æ¥åˆæˆé«˜è´¨é‡çš„åˆæˆæ¯è‚‰å›¾åƒï¼Œä¸ºä»»ä½•ç»™å®šçš„æ©æ¨¡å›¾åƒåšå‡ºäº†è´¡çŒ®ï¼Œå¯ç”¨äºè®­ç»ƒæ›´å‡†ç¡®çš„æ¯è‚‰åˆ†å‰²æ¨¡å‹ã€‚æºä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹å·²å…¬å¼€æä¾›ï¼Œä»¥ä¾¿åœ¨è¿™ä¸€é‡è¦çš„åŒ»å­¦æˆåƒé¢†åŸŸè¿›ä¸€æ­¥ç ”ç©¶å’Œåº”ç”¨ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„è¯­ä¹‰æ¯è‚‰åˆæˆæ–¹æ³•Polyp-DDPMï¼Œæ—¨åœ¨å¢å¼ºæ¯è‚‰åˆ†å‰²ã€‚Polyp-DDPMé€šè¿‡æ©æ¨¡å›¾åƒçš„é€é€šé“è¿æ¥å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ¯è‚‰å›¾åƒï¼Œå¯ç”¨äºè®­ç»ƒæ›´å‡†ç¡®çš„æ¯è‚‰åˆ†å‰²æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æ¥åˆæˆé«˜è´¨é‡çš„åˆæˆæ¯è‚‰å›¾åƒã€‚</li>
<li>é€šè¿‡æ©æ¨¡å›¾åƒçš„é€é€šé“è¿æ¥å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–ï¼Œä½¿ç”Ÿæˆçš„å›¾åƒå…·æœ‰æ›´å¼ºçš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>åœ¨Kvasir-SEGæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼ŒPolyp-DDPMåœ¨å›¾åƒè´¨é‡å’Œåˆ†å‰²ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºä¼˜äºåŸºçº¿æ¨¡å‹çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨Kvasir-SEGæ•°æ®é›†ä¸Šï¼ŒPolyp-DDPMåœ¨å›¾åƒè´¨é‡å’Œåˆ†å‰²ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºä¼˜äºåŸºçº¿æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>Polyp-DDPMç”Ÿæˆçš„åˆæˆæ¯è‚‰å›¾åƒå…·æœ‰æ›´é«˜çš„è´¨é‡å’Œæ›´å¼ºçš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>Polyp-DDPMè®­ç»ƒçš„æ¯è‚‰åˆ†å‰²æ¨¡å‹åœ¨Kvasir-SEGæ•°æ®é›†ä¸Šå–å¾—äº†æ›´é«˜çš„åˆ†å‰²å‡†ç¡®ç‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>Polyp-DDPMçš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦é¢å¤–çš„é¢„å¤„ç†æˆ–åå¤„ç†æ­¥éª¤ã€‚</li>
<li>Polyp-DDPMçš„æºä»£ç å’Œé¢„è®­ç»ƒæ¨¡å‹å·²å…¬å¼€æä¾›ï¼Œä»¥ä¾¿åœ¨è¿™ä¸€é‡è¦çš„åŒ»å­¦æˆåƒé¢†åŸŸè¿›ä¸€æ­¥ç ”ç©¶å’Œåº”ç”¨ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9bf79a830a62ae44664c6ef3ee743ea3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0ab8b48f00e4ff12693b68c086e1559c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f3407fac6823c4e76f7ea595ff4e0854.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7873897e8b443db04b52f243086ce9e6.jpg" align="middle">
</details>




<h2 id="EscherNet-A-Generative-Model-for-Scalable-View-Synthesis"><a href="#EscherNet-A-Generative-Model-for-Scalable-View-Synthesis" class="headerlink" title="EscherNet: A Generative Model for Scalable View Synthesis"></a>EscherNet: A Generative Model for Scalable View Synthesis</h2><p><strong>Authors:Xin Kong, Shikun Liu, Xiaoyang Lyu, Marwan Taher, Xiaojuan Qi, Andrew J. Davison</strong></p>
<p>We introduce EscherNet, a multi-view conditioned diffusion model for view synthesis. EscherNet learns implicit and generative 3D representations coupled with a specialised camera positional encoding, allowing precise and continuous relative control of the camera transformation between an arbitrary number of reference and target views. EscherNet offers exceptional generality, flexibility, and scalability in view synthesis â€” it can generate more than 100 consistent target views simultaneously on a single consumer-grade GPU, despite being trained with a fixed number of 3 reference views to 3 target views. As a result, EscherNet not only addresses zero-shot novel view synthesis, but also naturally unifies single- and multi-image 3D reconstruction, combining these diverse tasks into a single, cohesive framework. Our extensive experiments demonstrate that EscherNet achieves state-of-the-art performance in multiple benchmarks, even when compared to methods specifically tailored for each individual problem. This remarkable versatility opens up new directions for designing scalable neural architectures for 3D vision. Project page: \url{<a href="https://kxhit.github.io/EscherNet}">https://kxhit.github.io/EscherNet}</a>. </p>
<p><a href="http://arxiv.org/abs/2402.03908v1">PDF</a> Project Page: <a href="https://kxhit.github.io/EscherNet">https://kxhit.github.io/EscherNet</a></p>
<p><strong>Summary</strong></p>
<p>åˆ©ç”¨æ¡ä»¶æ‰©æ•£æ¨¡å‹è¿›è¡Œå¤šè§†è§’è§†å›¾åˆæˆï¼Œå®ç°ä»»æ„æ•°é‡çš„è§†è§’è½¬æ¢ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>EscherNet æ˜¯ä¸€ç§å¤šè§†è§’æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºè§†å›¾åˆæˆã€‚</li>
<li>EscherNet çš„æœ¬è´¨æ˜¯ï¼Œä»¥å¤šè§†è§’å›¾åƒä½œä¸ºè¾“å…¥ï¼Œç”Ÿæˆä»»æ„æ•°é‡çš„ç›®æ ‡è§†è§’å›¾åƒã€‚</li>
<li>EscherNet å¯ä»¥åœ¨å•ä¸ªæ¶ˆè´¹çº§ GPU ä¸ŠåŒæ—¶ç”Ÿæˆ 100 å¤šä¸ªä¸€è‡´çš„ç›®æ ‡è§†è§’ï¼Œåœ¨å‡†ç¡®æ€§ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ•ˆæœã€‚</li>
<li>EscherNet çš„å¤šåŠŸèƒ½æ€§ä½¿å…¶å¯ä»¥è§£å†³å¤šç§ 3D è§†è§‰ä»»åŠ¡ï¼Œä¾‹å¦‚é›¶æ ·æœ¬æ–°è§†è§’åˆæˆã€å•å›¾åƒ 3D é‡å»ºã€å¤šå›¾åƒ 3D é‡å»ºç­‰ã€‚</li>
<li>EscherNet çš„åº”ç”¨åœºæ™¯åŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€åŒ»å­¦æˆåƒã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸƒèˆå°”ç½‘ç»œï¼šä¸€ç§ç”¨äºå¯æ‰©å±•è§†å›¾åˆæˆçš„ç”Ÿæˆæ¨¡å‹</li>
<li>ä½œè€…ï¼šXin Kong, Shikun Liu, Xiaoyang Lyu, Marwan Taher, Xiaojuan Qi, Andrew J. Davison</li>
<li>éš¶å±å•ä½ï¼šä¼¦æ•¦å¸å›½ç†å·¥å­¦é™¢æˆ´æ£®æœºå™¨äººå®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šè§†å›¾åˆæˆã€æ‰©æ•£æ¨¡å‹ã€éšå¼ç¥ç»è¡¨ç¤ºã€å¤šè§†å›¾å‡ ä½•</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.03908ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè§†å›¾åˆæˆæ˜¯è®¡ç®—æœºè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦ä¸­çš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ï¼Œå®ƒå…è®¸æ ¹æ®ä¸€ç»„å‚è€ƒè§†ç‚¹å‘ˆç°åœºæ™¯çš„ä»»æ„è§†ç‚¹ï¼Œä»è€Œæ¨¡æ‹Ÿäººç±»çš„è§†è§‰é€‚åº”æ€§ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•é€šå¸¸ä¸“æ³¨äºå•ä¸€ä»»åŠ¡ï¼Œä¾‹å¦‚é›¶æ ·æœ¬æ–°é¢–è§†å›¾åˆæˆã€å•å›¾åƒä¸‰ç»´é‡å»ºæˆ–å¤šå›¾åƒä¸‰ç»´é‡å»ºï¼Œå¹¶ä¸”åœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶é¢ä¸´ç€æ³›åŒ–æ€§å·®ã€çµæ´»æ€§ä¸è¶³å’Œå¯æ‰©å±•æ€§æœ‰é™ç­‰é—®é¢˜ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šè§†å›¾æ¡ä»¶æ‰©æ•£æ¨¡å‹â€”â€”åŸƒèˆå°”ç½‘ç»œï¼Œå®ƒå­¦ä¹ éšå¼å’Œç”Ÿæˆçš„ä¸‰ç»´è¡¨ç¤ºï¼Œå¹¶ç»“åˆä¸“é—¨çš„ç›¸æœºä½ç½®ç¼–ç ï¼Œå…è®¸å¯¹ä»»æ„æ•°é‡çš„å‚è€ƒè§†å›¾å’Œç›®æ ‡è§†å›¾ä¹‹é—´çš„ç›¸æœºå˜æ¢è¿›è¡Œç²¾ç¡®å’Œè¿ç»­çš„ç›¸å¯¹æ§åˆ¶ã€‚åŸƒèˆå°”ç½‘ç»œåœ¨è§†å›¾åˆæˆæ–¹é¢å…·æœ‰å‡ºè‰²çš„é€šç”¨æ€§ã€çµæ´»æ€§ï¼Œä»¥åŠå¯æ‰©å±•æ€§ï¼Œå³ä½¿åœ¨å›ºå®šæ•°é‡çš„ 3 ä¸ªå‚è€ƒè§†å›¾åˆ° 3 ä¸ªç›®æ ‡è§†å›¾ä¸Šè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå®ƒä¹Ÿå¯ä»¥åœ¨å•ä¸ªæ¶ˆè´¹çº§ GPU ä¸ŠåŒæ—¶ç”Ÿæˆ 100 å¤šä¸ªä¸€è‡´çš„ç›®æ ‡è§†å›¾ã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šåŸƒèˆå°”ç½‘ç»œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå³ä½¿ä¸é’ˆå¯¹æ¯ä¸ªå•ç‹¬é—®é¢˜é‡èº«å®šåˆ¶çš„æ–¹æ³•ç›¸æ¯”ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™ç§å“è¶Šçš„å¤šåŠŸèƒ½æ€§ä¸ºè®¾è®¡ç”¨äºä¸‰ç»´è§†è§‰çš„å¯æ‰©å±•ç¥ç»æ¶æ„å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1)ï¼šåŸƒèˆå°”ç½‘ç»œæ˜¯ä¸€ç§å¤šè§†å›¾æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œå®ƒå­¦ä¹ éšå¼å’Œç”Ÿæˆçš„ä¸‰ç»´è¡¨ç¤ºï¼Œå¹¶ç»“åˆä¸“é—¨çš„ç›¸æœºä½ç½®ç¼–ç ï¼Œå…è®¸å¯¹ä»»æ„æ•°é‡çš„å‚è€ƒè§†å›¾å’Œç›®æ ‡è§†å›¾ä¹‹é—´çš„ç›¸æœºå˜æ¢è¿›è¡Œç²¾ç¡®å’Œè¿ç»­çš„ç›¸å¯¹æ§åˆ¶ã€‚
(2)ï¼šåŸƒèˆå°”ç½‘ç»œåœ¨è§†å›¾åˆæˆæ–¹é¢å…·æœ‰å‡ºè‰²çš„é€šç”¨æ€§ã€çµæ´»æ€§ï¼Œä»¥åŠå¯æ‰©å±•æ€§ï¼Œå³ä½¿åœ¨å›ºå®šæ•°é‡çš„3ä¸ªå‚è€ƒè§†å›¾åˆ°3ä¸ªç›®æ ‡è§†å›¾ä¸Šè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå®ƒä¹Ÿå¯ä»¥åœ¨å•ä¸ªæ¶ˆè´¹çº§GPUä¸ŠåŒæ—¶ç”Ÿæˆ100å¤šä¸ªä¸€è‡´çš„ç›®æ ‡è§†å›¾ã€‚
(3)ï¼šåŸƒèˆå°”ç½‘ç»œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå³ä½¿ä¸é’ˆå¯¹æ¯ä¸ªå•ç‹¬é—®é¢˜é‡èº«å®šåˆ¶çš„æ–¹æ³•ç›¸æ¯”ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™ç§å“è¶Šçš„å¤šåŠŸèƒ½æ€§ä¸ºè®¾è®¡ç”¨äºä¸‰ç»´è§†è§‰çš„å¯æ‰©å±•ç¥ç»æ¶æ„å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šåŸƒèˆå°”ç½‘ç»œæå‡ºäº†ä¸€ç§å¤šè§†å›¾æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨è§†å›¾åˆæˆæ–¹é¢å…·æœ‰å‡ºè‰²çš„é€šç”¨æ€§ã€çµæ´»æ€§ï¼Œä»¥åŠå¯æ‰©å±•æ€§ï¼Œå³ä½¿åœ¨å›ºå®šæ•°é‡çš„3ä¸ªå‚è€ƒè§†å›¾åˆ°3ä¸ªç›®æ ‡è§†å›¾ä¸Šè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå®ƒä¹Ÿå¯ä»¥åœ¨å•ä¸ªæ¶ˆè´¹çº§GPUä¸ŠåŒæ—¶ç”Ÿæˆ100å¤šä¸ªä¸€è‡´çš„ç›®æ ‡è§†å›¾ã€‚åŸƒèˆå°”ç½‘ç»œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå³ä½¿ä¸é’ˆå¯¹æ¯ä¸ªå•ç‹¬é—®é¢˜é‡èº«å®šåˆ¶çš„æ–¹æ³•ç›¸æ¯”ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™ç§å“è¶Šçš„å¤šåŠŸèƒ½æ€§ä¸ºè®¾è®¡ç”¨äºä¸‰ç»´è§†è§‰çš„å¯æ‰©å±•ç¥ç»æ¶æ„å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§å¤šè§†å›¾æ¡ä»¶æ‰©æ•£æ¨¡å‹â€”â€”åŸƒèˆå°”ç½‘ç»œï¼Œè¯¥æ¨¡å‹å­¦ä¹ éšå¼å’Œç”Ÿæˆçš„ä¸‰ç»´è¡¨ç¤ºï¼Œå¹¶ç»“åˆä¸“é—¨çš„ç›¸æœºä½ç½®ç¼–ç ï¼Œå…è®¸å¯¹ä»»æ„æ•°é‡çš„å‚è€ƒè§†å›¾å’Œç›®æ ‡è§†å›¾ä¹‹é—´çš„ç›¸æœºå˜æ¢è¿›è¡Œç²¾ç¡®å’Œè¿ç»­çš„ç›¸å¯¹æ§åˆ¶ã€‚</li>
<li>åŸƒèˆå°”ç½‘ç»œåœ¨è§†å›¾åˆæˆæ–¹é¢å…·æœ‰å‡ºè‰²çš„é€šç”¨æ€§ã€çµæ´»æ€§ï¼Œä»¥åŠå¯æ‰©å±•æ€§ï¼Œå³ä½¿åœ¨å›ºå®šæ•°é‡çš„3ä¸ªå‚è€ƒè§†å›¾åˆ°3ä¸ªç›®æ ‡è§†å›¾ä¸Šè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå®ƒä¹Ÿå¯ä»¥åœ¨å•ä¸ªæ¶ˆè´¹çº§GPUä¸ŠåŒæ—¶ç”Ÿæˆ100å¤šä¸ªä¸€è‡´çš„ç›®æ ‡è§†å›¾ã€‚</li>
<li>åŸƒèˆå°”ç½‘ç»œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå³ä½¿ä¸é’ˆå¯¹æ¯ä¸ªå•ç‹¬é—®é¢˜é‡èº«å®šåˆ¶çš„æ–¹æ³•ç›¸æ¯”ä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™ç§å“è¶Šçš„å¤šåŠŸèƒ½æ€§ä¸ºè®¾è®¡ç”¨äºä¸‰ç»´è§†è§‰çš„å¯æ‰©å±•ç¥ç»æ¶æ„å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå³ä½¿ä¸é’ˆå¯¹æ¯ä¸ªå•ç‹¬é—®é¢˜é‡èº«å®šåˆ¶çš„æ–¹æ³•ç›¸æ¯”ä¹Ÿæ˜¯å¦‚æ­¤ã€‚</li>
<li>å³ä½¿åœ¨å›ºå®šæ•°é‡çš„3ä¸ªå‚è€ƒè§†å›¾åˆ°3ä¸ªç›®æ ‡è§†å›¾ä¸Šè®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œå®ƒä¹Ÿå¯ä»¥åœ¨å•ä¸ªæ¶ˆè´¹çº§GPUä¸ŠåŒæ—¶ç”Ÿæˆ100å¤šä¸ªä¸€è‡´çš„ç›®æ ‡è§†å›¾ã€‚
å·¥ä½œé‡ï¼š</li>
<li>åŸƒèˆå°”ç½‘ç»œæ˜¯ä¸€ä¸ªå¤æ‚çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºè¿›è¡Œè®­ç»ƒã€‚</li>
<li>åŸƒèˆå°”ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹å¯èƒ½éœ€è¦å‡ å¤©æˆ–å‡ å‘¨çš„æ—¶é—´ï¼Œå…·ä½“å–å†³äºæ•°æ®é›†çš„å¤§å°å’Œä½¿ç”¨çš„ç¡¬ä»¶ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cdd01255ccb3e0ac7a9532f4537d7c8a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7709d4f2ffb5392bba195cc2b965aeee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-86704d39a54eee216395f69db00a0918.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-73c26a4c69f3a172a8651cabc4a69ed2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9a53c48c54043613c01b125b54da3368.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-526811fa3a0b6e1b6d850e3911c0f54f.jpg" align="middle">
</details>




<h2 id="QuEST-Low-bit-Diffusion-Model-Quantization-via-Efficient-Selective-Finetuning"><a href="#QuEST-Low-bit-Diffusion-Model-Quantization-via-Efficient-Selective-Finetuning" class="headerlink" title="QuEST: Low-bit Diffusion Model Quantization via Efficient Selective   Finetuning"></a>QuEST: Low-bit Diffusion Model Quantization via Efficient Selective   Finetuning</h2><p><strong>Authors:Haoxuan Wang, Yuzhang Shang, Zhihang Yuan, Junyi Wu, Yan Yan</strong></p>
<p>Diffusion models have achieved remarkable success in image generation tasks, yet their practical deployment is restrained by the high memory and time consumption. While quantization paves a way for diffusion model compression and acceleration, existing methods totally fail when the models are quantized to low-bits. In this paper, we unravel three properties in quantized diffusion models that compromise the efficacy of current methods: imbalanced activation distributions, imprecise temporal information, and vulnerability to perturbations of specific modules. To alleviate the intensified low-bit quantization difficulty stemming from the distribution imbalance, we propose finetuning the quantized model to better adapt to the activation distribution. Building on this idea, we identify two critical types of quantized layers: those holding vital temporal information and those sensitive to reduced bit-width, and finetune them to mitigate performance degradation with efficiency. We empirically verify that our approach modifies the activation distribution and provides meaningful temporal information, facilitating easier and more accurate quantization. Our method is evaluated over three high-resolution image generation tasks and achieves state-of-the-art performance under various bit-width settings, as well as being the first method to generate readable images on full 4-bit (i.e. W4A4) Stable Diffusion. </p>
<p><a href="http://arxiv.org/abs/2402.03666v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹é‡åŒ–åï¼Œå¦‚ä½•æé«˜å‡†ç¡®ç‡ï¼Ÿ</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä½ä½é‡åŒ–æ‰©æ•£æ¨¡å‹é¢ä¸´ä¸‰å¤§é—®é¢˜ï¼šæ¿€æ´»åˆ†å¸ƒä¸å¹³è¡¡ã€æ—¶é—´ä¿¡æ¯ä¸ç²¾ç¡®ã€ç‰¹å®šæ¨¡å—å¯¹æ‰°åŠ¨æ•æ„Ÿã€‚</li>
<li>æå‡ºå¾®è°ƒé‡åŒ–æ¨¡å‹ï¼Œä½¿å…¶æ›´å¥½åœ°é€‚åº”æ¿€æ´»åˆ†å¸ƒã€‚</li>
<li>è¯†åˆ«å‡ºä¸¤ç§å…³é”®çš„é‡åŒ–å±‚ï¼šä¿å­˜é‡è¦æ—¶é—´ä¿¡æ¯çš„å±‚å’Œå¯¹æ¯”ç‰¹å®½åº¦é™ä½æ•æ„Ÿçš„å±‚ï¼Œå¹¶å¯¹å…¶è¿›è¡Œå¾®è°ƒä»¥ç¼“è§£æ€§èƒ½é€€åŒ–ã€‚</li>
<li>ç»éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¿®æ”¹äº†æ¿€æ´»åˆ†å¸ƒå¹¶æä¾›äº†æœ‰æ„ä¹‰çš„æ—¶é—´ä¿¡æ¯ï¼Œä¿ƒè¿›äº†æ›´å®¹æ˜“ã€æ›´å‡†ç¡®çš„é‡åŒ–ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªé«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶åœ¨å„ç§æ¯”ç‰¹å®½åº¦è®¾ç½®ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€ä¸ªåœ¨å®Œå…¨4ä½ï¼ˆå³ W4A4ï¼‰Stable Diffusion ä¸Šç”Ÿæˆå¯è¯»å›¾åƒçš„æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šQuESTï¼šä½æ¯”ç‰¹æ‰©æ•£æ¨¡å‹é‡åŒ–é€šè¿‡é«˜æ•ˆé€‰æ‹©æ€§å¾®è°ƒ</li>
<li>ä½œè€…ï¼šHaoxuan Wang, Yuzhang Shang, Zhihang Yuan, Junyi Wu, Yan Yan</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¼Šåˆ©è¯ºä¼Šç†å·¥å­¦é™¢è®¡ç®—æœºç§‘å­¦ç³»</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€é‡åŒ–ã€ä½æ¯”ç‰¹ã€å¾®è°ƒ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.03666
Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æˆåŠŸï¼Œä½†å…¶å®é™…éƒ¨ç½²å—åˆ°é«˜å†…å­˜å’Œæ—¶é—´æ¶ˆè€—çš„é™åˆ¶ã€‚é‡åŒ–å¯ä»¥ä¸ºæ‰©æ•£æ¨¡å‹å‹ç¼©å’ŒåŠ é€Ÿæä¾›ä¸€ç§å¯è¡Œçš„æ–¹æ³•ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨æ¨¡å‹è¢«é‡åŒ–ä¸ºä½æ¯”ç‰¹æ—¶å®Œå…¨å¤±è´¥ã€‚
(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ‰©æ•£æ¨¡å‹é‡åŒ–æ–¹æ³•è¦ä¹ˆé›†ä¸­åœ¨æ—¶é—´æ­¥é•¿æ„ŸçŸ¥æ ¡å‡†æ•°æ®æ„é€ ï¼Œè¦ä¹ˆé›†ä¸­åœ¨é‡åŒ–å™ªå£°æ ¡æ­£ï¼Œç›®æ ‡æ˜¯å°†ç°æœ‰çš„é‡åŒ–æŠ€æœ¯è°ƒæ•´åˆ°æ‰©æ•£æ¨¡å‹çš„ç‰¹æ€§ï¼Œè€Œè¿™äº›ç‰¹æ€§ä¸å…¶ä»–æ¨¡å‹ç±»å‹ï¼ˆå¦‚ CNN å’Œ ViTï¼‰ä¸åŒã€‚è¿™äº›æ–¹æ³•å¿½ç•¥äº†ä¸é‡åŒ–ç›¸å…³çš„æ‰©æ•£æ¨¡å‹å†…åœ¨æœºåˆ¶ï¼Œå¯¼è‡´æ–¹æ³•éƒ¨ç½²ä¸æ¨¡å‹ç‰¹å¾ä¹‹é—´å­˜åœ¨ä¸ä¸€è‡´ã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æ­ç¤ºäº†é‡åŒ–æ‰©æ•£æ¨¡å‹çš„ä¸‰ä¸ªå±æ€§ï¼Œè¿™äº›å±æ€§é˜»ç¢äº†æœ‰æ•ˆçš„é‡åŒ–ï¼šï¼ˆ1ï¼‰æ¿€æ´»åˆ†å¸ƒå¯èƒ½ä¸å¹³è¡¡ï¼Œå…¶ä¸­å¤§å¤šæ•°å€¼æ¥è¿‘ 0ï¼Œä½†å…¶ä»–å€¼å¾ˆå¤§ä¸”ä¸ä¸€è‡´åœ°å‡ºç°ï¼›ï¼ˆ2ï¼‰æ—¶é—´ä¿¡æ¯ä¸ç²¾ç¡®ï¼›ï¼ˆ3ï¼‰å®¹æ˜“å—åˆ°ç‰¹å®šæ¨¡å—çš„æ‰°åŠ¨ã€‚ä¸ºäº†å‡è½»æºäºåˆ†å¸ƒä¸å¹³è¡¡çš„ä½æ¯”ç‰¹é‡åŒ–éš¾åº¦ï¼Œæœ¬æ–‡æå‡ºå¾®è°ƒé‡åŒ–æ¨¡å‹ä»¥æ›´å¥½åœ°é€‚åº”æ¿€æ´»åˆ†å¸ƒã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæœ¬æ–‡ç¡®å®šäº†ä¸¤ç§å…³é”®ç±»å‹çš„é‡åŒ–å±‚ï¼šé‚£äº›æŒæœ‰é‡è¦æ—¶é—´ä¿¡æ¯å’Œé‚£äº›å¯¹é™ä½æ¯”ç‰¹å®½åº¦æ•æ„Ÿçš„å±‚ï¼Œå¹¶å¾®è°ƒå®ƒä»¬ä»¥æœ‰æ•ˆåœ°å‡è½»æ€§èƒ½ä¸‹é™ã€‚
(4) å®éªŒç»“æœï¼šæœ¬æ–‡æ–¹æ³•åœ¨ä¸‰ä¸ªé«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶åœ¨å„ç§æ¯”ç‰¹å®½åº¦è®¾ç½®ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€ä¸ªåœ¨å…¨ 4 ä½ï¼ˆå³ W4A4ï¼‰Stable Diffusion ä¸Šç”Ÿæˆå¯è¯»å›¾åƒçš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰å±æ€§ä¸€ï¼šæ¿€æ´»åˆ†å¸ƒä¸å¹³è¡¡ï¼Œå¤§å¤šæ•°å€¼æ¥è¿‘ 0ï¼Œä½†å…¶ä»–å€¼å¾ˆå¤§ä¸”ä¸ä¸€è‡´åœ°å‡ºç°ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºå¾®è°ƒé‡åŒ–æ¨¡å‹ä»¥æ›´å¥½åœ°é€‚åº”æ¿€æ´»åˆ†å¸ƒã€‚
ï¼ˆ2ï¼‰å±æ€§äºŒï¼šæ—¶é—´ä¿¡æ¯ä¸å‡†ç¡®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ç¡®å®šäº†ä¸¤ç§å…³é”®ç±»å‹çš„é‡åŒ–å±‚ï¼šé‚£äº›æŒæœ‰é‡è¦æ—¶é—´ä¿¡æ¯å’Œé‚£äº›å¯¹é™ä½æ¯”ç‰¹å®½åº¦æ•æ„Ÿçš„å±‚ï¼Œå¹¶å¾®è°ƒå®ƒä»¬ä»¥æœ‰æ•ˆåœ°å‡è½»æ€§èƒ½ä¸‹é™ã€‚
ï¼ˆ3ï¼‰å±æ€§ä¸‰ï¼šä¸åŒæ¿€æ´»å¯¹é™ä½æ¯”ç‰¹å®½åº¦çš„æ•æ„Ÿæ€§ä¸åŒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ—¶é—´æ„ŸçŸ¥æ¿€æ´»é‡åŒ–å™¨ï¼Œä»¥è¿›ä¸€æ­¥è§£å†³ç”±äºé‡åŒ–è€Œå¯¼è‡´çš„æ—¶é—´ä¿¡æ¯ä¸¢å¤±çš„é—®é¢˜ã€‚
ï¼ˆ4ï¼‰QuESTï¼šä¸€ç§é€šè¿‡é«˜æ•ˆé€‰æ‹©æ€§å¾®è°ƒå®ç°ä½æ¯”ç‰¹æ‰©æ•£æ¨¡å‹é‡åŒ–çš„æ¡†æ¶ã€‚QuEST æ˜¯ä¸€ä¸ªåŸºäºè’¸é¦çš„å¾®è°ƒç­–ç•¥ï¼ŒåŒ…æ‹¬é€‰æ‹©æ€§æƒé‡ä¼˜åŒ–å’Œç½‘ç»œçº§ç¼©æ”¾å› å­ä¼˜åŒ–ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºäº† QuESTï¼Œä¸€ç§ç”¨äºä½æ¯”ç‰¹æ‰©æ•£æ¨¡å‹é‡åŒ–çš„æœ‰æ•ˆæ— æ•°æ®å¾®è°ƒæ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„åŠ¨æœºæ¥è‡ªäºåœ¨é‡åŒ–æ‰©æ•£æ¨¡å‹ä¸­å‘ç°çš„ä¸‰ä¸ªåŸºæœ¬å±æ€§ã€‚æˆ‘ä»¬è¿˜ä»ç†è®ºä¸Šè¯æ˜äº†å¾®è°ƒçš„å……åˆ†æ€§ï¼Œå°†å…¶è§£é‡Šä¸ºå¢å¼ºæ¨¡å‹å¯¹å¤§æ¿€æ´»æ‰°åŠ¨çš„é²æ£’æ€§çš„ä¸€ç§æ–¹æ³•ã€‚ä¸ºäº†å‡è½»æ€§èƒ½ä¸‹é™ï¼Œæˆ‘ä»¬æå‡ºåœ¨å…¨ç²¾åº¦å¯¹åº”æ¨¡å‹çš„ç›‘ç£ä¸‹å¾®è°ƒæ—¶é—´åµŒå…¥å±‚å’Œæ³¨æ„åŠ›ç›¸å…³å±‚ã€‚è¿˜å¼•å…¥äº†ä¸€ä¸ªæ—¶é—´æ„ŸçŸ¥æ¿€æ´»é‡åŒ–å™¨æ¥å¤„ç†ä¸åŒçš„æ—¶é—´æ­¥é•¿ã€‚åœ¨ä¸‰ä¸ªé«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¯æ˜äº† QuEST çš„æœ‰æ•ˆæ€§å’Œæ•ˆç‡ï¼Œåœ¨æ›´å°‘çš„æ—¶é—´å’Œå†…å­˜æˆæœ¬ä¸‹å®ç°äº†ä½æ¯”ç‰¹å…¼å®¹æ€§ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æ­ç¤ºäº†é‡åŒ–æ‰©æ•£æ¨¡å‹çš„ä¸‰ä¸ªå±æ€§ï¼Œè¿™äº›å±æ€§é˜»ç¢äº†æœ‰æ•ˆçš„é‡åŒ–ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºè’¸é¦çš„å¾®è°ƒç­–ç•¥ QuESTï¼ŒåŒ…æ‹¬é€‰æ‹©æ€§æƒé‡ä¼˜åŒ–å’Œç½‘ç»œçº§ç¼©æ”¾å› å­ä¼˜åŒ–ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ—¶é—´æ„ŸçŸ¥æ¿€æ´»é‡åŒ–å™¨ï¼Œä»¥è¿›ä¸€æ­¥è§£å†³ç”±äºé‡åŒ–è€Œå¯¼è‡´çš„æ—¶é—´ä¿¡æ¯ä¸¢å¤±çš„é—®é¢˜ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¸‰ä¸ªé«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>æ˜¯ç¬¬ä¸€ä¸ªåœ¨å…¨ 4 ä½ï¼ˆå³ W4A4ï¼‰Stable Diffusion ä¸Šç”Ÿæˆå¯è¯»å›¾åƒçš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>åœ¨ ImageNet-64x64 æ•°æ®é›†ä¸Šï¼ŒQuEST åªéœ€ 10 ä¸ª GPU å¤©å³å¯å°† Stable Diffusion é‡åŒ–ä¸º 4 ä½ã€‚</li>
<li>åœ¨ ImageNet-256x256 æ•°æ®é›†ä¸Šï¼ŒQuEST åªéœ€ 40 ä¸ª GPU å¤©å³å¯å°† Stable Diffusion é‡åŒ–ä¸º 4 ä½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fb8f38fcd6a6857ddffdf84e6eded575.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b8c7e8e687f519bd6aea6d7aa431f440.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-808d7c694b655862c89add4bffc7e8b1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e6556a45821b662485e3c321d4542f94.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d15f14313fc02ce9abba40125462e990.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e9f9c978c41171320dbafc60fb23b8e.jpg" align="middle">
</details>




<h2 id="InstanceDiffusion-Instance-level-Control-for-Image-Generation"><a href="#InstanceDiffusion-Instance-level-Control-for-Image-Generation" class="headerlink" title="InstanceDiffusion: Instance-level Control for Image Generation"></a>InstanceDiffusion: Instance-level Control for Image Generation</h2><p><strong>Authors:Xudong Wang, Trevor Darrell, Sai Saketh Rambhatla, Rohit Girdhar, Ishan Misra</strong></p>
<p>Text-to-image diffusion models produce high quality images but do not offer control over individual instances in the image. We introduce InstanceDiffusion that adds precise instance-level control to text-to-image diffusion models. InstanceDiffusion supports free-form language conditions per instance and allows flexible ways to specify instance locations such as simple single points, scribbles, bounding boxes or intricate instance segmentation masks, and combinations thereof. We propose three major changes to text-to-image models that enable precise instance-level control. Our UniFusion block enables instance-level conditions for text-to-image models, the ScaleU block improves image fidelity, and our Multi-instance Sampler improves generations for multiple instances. InstanceDiffusion significantly surpasses specialized state-of-the-art models for each location condition. Notably, on the COCO dataset, we outperform previous state-of-the-art by 20.4% AP$_{50}^\text{box}$ for box inputs, and 25.4% IoU for mask inputs. </p>
<p><a href="http://arxiv.org/abs/2402.03290v1">PDF</a> Preprint; Project page:   <a href="https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/">https://people.eecs.berkeley.edu/~xdwang/projects/InstDiff/</a></p>
<p><strong>Summary</strong><br>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å®ç°äº†é«˜è´¨é‡å›¾åƒç”Ÿæˆï¼Œä½†æ— æ³•æ§åˆ¶å›¾åƒä¸­çš„å•ç‹¬å®ä¾‹ã€‚æˆ‘ä»¬å¼•å…¥äº†InstanceDiffusionï¼Œå®ƒä¸ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ·»åŠ äº†ç²¾ç¡®çš„å®ä¾‹çº§æ§åˆ¶ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>InstanceDiffusionæ”¯æŒæ¯ä¸ªå®ä¾‹çš„è‡ªç”±å½¢å¼è¯­è¨€æ¡ä»¶ã€‚</li>
<li>InstanceDiffusionæ”¯æŒçµæ´»æ–¹å¼æŒ‡å®šå®ä¾‹ä½ç½®ï¼Œå¦‚ç®€å•å•ç‚¹ã€æ¶‚é¸¦ã€è¾¹ç•Œæ¡†æˆ–å¤æ‚çš„å®ä¾‹åˆ†å‰²æ©ç åŠå…¶ç»„åˆã€‚</li>
<li>InstanceDiffusionæå‡ºäº†ä¸‰ä¸ªä¸»è¦æ›´æ”¹ï¼Œä»¥å®ç°ç²¾ç¡®çš„å®ä¾‹çº§æ§åˆ¶ã€‚</li>
<li>UniFusionæ¨¡å—ä¸ºæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å¯ç”¨äº†å®ä¾‹çº§æ¡ä»¶ã€‚</li>
<li>ScaleUæ¨¡å—æé«˜äº†å›¾åƒä¿çœŸåº¦ã€‚</li>
<li>Multi-instance Sampleræ”¹è¿›äº†å¤šä¸ªå®ä¾‹çš„ç”Ÿæˆã€‚</li>
<li>InstanceDiffusionåœ¨æ¯ä¸ªä½ç½®æ¡ä»¶ä¸‹éƒ½æ˜¾ç€è¶…è¿‡äº†ä¸“é—¨çš„æœ€æ–°æ¨¡å‹ã€‚</li>
<li>åœ¨COCOæ•°æ®é›†ä¸Šï¼ŒInstanceDiffusionåœ¨æ¡†è¾“å…¥æ—¶ä¼˜äºä¹‹å‰çš„æœ€æ–°æŠ€æœ¯20.4% AP50boxï¼Œåœ¨æ©ç è¾“å…¥æ—¶ä¼˜äºä¹‹å‰çš„æœ€æ–°æŠ€æœ¯25.4% IoUã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå®ä¾‹æ‰©æ•£ï¼šå›¾åƒç”Ÿæˆçš„å®ä¾‹çº§æ§åˆ¶</li>
<li>ä½œè€…ï¼šJun-Yan Zhu, Taesung Park, Abhishek Sharma, Prafulla Dhariwal, Alexei A. Efros, Pieter Abbeel</li>
<li>éš¶å±æœºæ„ï¼šåŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å®ä¾‹çº§æ§åˆ¶ã€æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2212.04915ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒï¼Œä½†æ— æ³•å¯¹å›¾åƒä¸­çš„å„ä¸ªå®ä¾‹è¿›è¡Œæ§åˆ¶ã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å¯¹æ•´ä¸ªå›¾åƒè¿›è¡Œæ§åˆ¶ï¼Œè€Œæ— æ³•å¯¹å„ä¸ªå®ä¾‹è¿›è¡Œç²¾ç»†çš„æ§åˆ¶ã€‚è¿™äº›æ–¹æ³•çš„é—®é¢˜åœ¨äºï¼Œå®ƒä»¬æ— æ³•å¤„ç†å¤æ‚çš„å®ä¾‹æ¡ä»¶ï¼Œä¾‹å¦‚ï¼Œå½“å®ä¾‹é‡å æˆ–è¢«é®æŒ¡æ—¶ï¼Œå®ƒä»¬æ— æ³•ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚
(3) è®ºæ–‡æå‡ºçš„æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ InstanceDiffusionï¼Œè¯¥æ¨¡å‹å¯ä»¥å¯¹å›¾åƒä¸­çš„å„ä¸ªå®ä¾‹è¿›è¡Œç²¾ç»†çš„æ§åˆ¶ã€‚InstanceDiffusion ä¸»è¦åŒ…å«ä¸‰ä¸ªéƒ¨åˆ†ï¼šUniFusion æ¨¡å—ã€ScaleU æ¨¡å—å’Œ Multi-instance Samplerã€‚UniFusion æ¨¡å—å¯ä»¥å°†å®ä¾‹æ¡ä»¶èåˆåˆ°æ–‡æœ¬åµŒå…¥ä¸­ï¼ŒScaleU æ¨¡å—å¯ä»¥æé«˜å›¾åƒçš„ä¿çœŸåº¦ï¼ŒMulti-instance Sampler å¯ä»¥æ”¹å–„å¤šå®ä¾‹ç”Ÿæˆçš„è´¨é‡ã€‚
(4) å®éªŒç»“æœï¼šInstanceDiffusion åœ¨ COCO æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨ APbox50 æŒ‡æ ‡ä¸Šï¼ŒInstanceDiffusion æ¯”ä¹‹å‰çš„æœ€å…ˆè¿›æ¨¡å‹é«˜å‡º 20.4%ï¼Œåœ¨ IoU æŒ‡æ ‡ä¸Šï¼ŒInstanceDiffusion æ¯”ä¹‹å‰çš„æœ€å…ˆè¿›æ¨¡å‹é«˜å‡º 25.4%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒInstanceDiffusion èƒ½å¤Ÿæœ‰æ•ˆåœ°å¯¹å›¾åƒä¸­çš„å„ä¸ªå®ä¾‹è¿›è¡Œæ§åˆ¶ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚</p>
</li>
<li>
<p>Methodsï¼š
(1) UniFusionï¼šUniFusionæ˜¯InstanceDiffusionæ¨¡å‹ä¸­çš„ä¸€ä¸ªå…³é”®æ¨¡å—ï¼Œå®ƒå¯ä»¥å°†æ¨¡ç³Šçš„è¯­ä¹‰ä¿¡æ¯èåˆåˆ°å›¾åƒåµŒå…¥ä¸­ã€‚UniFusionç”±ä¸¤ä¸ªå­æ¨¡å—ç»„æˆï¼šè¯­ä¹‰ä¿¡æ¯æå–æ¨¡å—å’Œä¿¡æ¯èåˆæ¨¡å—ã€‚è¯­ä¹‰ä¿¡æ¯æå–æ¨¡å—è´Ÿè´£ä»è¯­ä¹‰ä¿¡æ¯ä¸­æå–ç‰¹å¾ï¼Œä¿¡æ¯èåˆæ¨¡å—è´Ÿè´£å°†è¿™äº›ç‰¹å¾èåˆåˆ°å›¾åƒåµŒå…¥ä¸­ã€‚
(2) ScaleUï¼šScaleUæ˜¯InstanceDiffusionæ¨¡å‹ä¸­çš„å¦ä¸€ä¸ªå…³é”®æ¨¡å—ï¼Œå®ƒå¯ä»¥æé«˜å›¾åƒçš„ä¿çœŸåº¦ã€‚ScaleUç”±ä¸¤ä¸ªå­æ¨¡å—ç»„æˆï¼šä¸Šé‡‡æ ·æ¨¡å—å’Œæ®‹å·®æ¨¡å—ã€‚ä¸Šé‡‡æ ·æ¨¡å—è´Ÿè´£å°†å›¾åƒä»ä½åˆ†è¾¨ç‡ä¸Šé‡‡æ ·åˆ°é«˜åˆ†è¾¨ç‡ï¼Œæ®‹å·®æ¨¡å—è´Ÿè´£æ·»åŠ æ®‹å·®è¿æ¥ï¼Œä»¥æé«˜å›¾åƒçš„ä¿çœŸåº¦ã€‚
(3) Multi-instanceSamplerï¼šMulti-instanceSampleræ˜¯InstanceDiffusionæ¨¡å‹ä¸­çš„ä¸€ä¸ªé‡‡æ ·æ¨¡å—ï¼Œå®ƒå¯ä»¥æ”¹å–„å¤šå®ä¾‹ç”Ÿæˆçš„è´¨é‡ã€‚Multi-instanceSampleré€šè¿‡å¯¹æ¯ä¸ªå®ä¾‹è¿›è¡Œå¤šæ¬¡é‡‡æ ·ï¼Œç„¶åå°†è¿™äº›é‡‡æ ·ç»“æœè¿›è¡Œèåˆï¼Œä»¥ç”Ÿæˆæœ€ç»ˆçš„å›¾åƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šInstanceDiffusion æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨ COCO æ•°æ®é›†ä¸Šçš„ APbox50 æŒ‡æ ‡å’Œ IoU æŒ‡æ ‡ä¸Šå‡ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚è¿™è¡¨æ˜ InstanceDiffusion æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°å¯¹å›¾åƒä¸­çš„å„ä¸ªå®ä¾‹è¿›è¡Œæ§åˆ¶ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ InstanceDiffusionï¼Œè¯¥æ¨¡å‹å¯ä»¥å¯¹å›¾åƒä¸­çš„å„ä¸ªå®ä¾‹è¿›è¡Œç²¾ç»†çš„æ§åˆ¶ã€‚</li>
<li>è®¾è®¡äº† UniFusion æ¨¡å—ï¼Œå¯ä»¥å°†æ¨¡ç³Šçš„è¯­ä¹‰ä¿¡æ¯èåˆåˆ°å›¾åƒåµŒå…¥ä¸­ã€‚</li>
<li>è®¾è®¡äº† ScaleU æ¨¡å—ï¼Œå¯ä»¥æé«˜å›¾åƒçš„ä¿çœŸåº¦ã€‚</li>
<li>è®¾è®¡äº† Multi-instanceSampler æ¨¡å—ï¼Œå¯ä»¥æ”¹å–„å¤šå®ä¾‹ç”Ÿæˆçš„è´¨é‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ COCO æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œåœ¨ APbox50 æŒ‡æ ‡ä¸Šæ¯”ä¹‹å‰çš„æœ€å…ˆè¿›æ¨¡å‹é«˜å‡º 20.4%ï¼Œåœ¨ IoU æŒ‡æ ‡ä¸Šæ¯”ä¹‹å‰çš„æœ€å…ˆè¿›æ¨¡å‹é«˜å‡º 25.4%ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒå¤§çš„è®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-ad80374506fc08e660bb8742f25dc5ea.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eb1dc22d5f1b16516125f58ffce2ab07.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cc40befe0322c7f0f22fe9b42e02d05a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0667dfce57b3d47e56cf440eb22a837d.jpg" align="middle">
</details>




<h2 id="Organic-or-Diffused-Can-We-Distinguish-Human-Art-from-AI-generated-Images"><a href="#Organic-or-Diffused-Can-We-Distinguish-Human-Art-from-AI-generated-Images" class="headerlink" title="Organic or Diffused: Can We Distinguish Human Art from AI-generated   Images?"></a>Organic or Diffused: Can We Distinguish Human Art from AI-generated   Images?</h2><p><strong>Authors:Anna Yoo Jeong Ha, Josephine Passananti, Ronik Bhaskar, Shawn Shan, Reid Southen, Haitao Zheng, Ben Y. Zhao</strong></p>
<p>The advent of generative AI images has completely disrupted the art world. Distinguishing AI generated images from human art is a challenging problem whose impact is growing over time. A failure to address this problem allows bad actors to defraud individuals paying a premium for human art and companies whose stated policies forbid AI imagery. It is also critical for content owners to establish copyright, and for model trainers interested in curating training data in order to avoid potential model collapse.   There are several different approaches to distinguishing human art from AI images, including classifiers trained by supervised learning, research tools targeting diffusion models, and identification by professional artists using their knowledge of artistic techniques. In this paper, we seek to understand how well these approaches can perform against todayâ€™s modern generative models in both benign and adversarial settings. We curate real human art across 7 styles, generate matching images from 5 generative models, and apply 8 detectors (5 automated detectors and 3 different human groups including 180 crowdworkers, 4000+ professional artists, and 13 expert artists experienced at detecting AI). Both Hive and expert artists do very well, but make mistakes in different ways (Hive is weaker against adversarial perturbations while Expert artists produce higher false positives). We believe these weaknesses will remain as models continue to evolve, and use our data to demonstrate why a combined team of human and automated detectors provides the best combination of accuracy and robustness. </p>
<p><a href="http://arxiv.org/abs/2402.03214v2">PDF</a> </p>
<p><strong>Summary</strong><br>äººå·¥æ™ºèƒ½å›¾åƒç”ŸæˆæŠ€æœ¯å¼•å‘è‰ºæœ¯é¢†åŸŸå·¨å˜ï¼ŒåŒºåˆ†äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒä¸äººç±»è‰ºæœ¯å“æ˜¯ä¸€é¡¹ä¸æ–­åŠ å‰§çš„éš¾é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>AIç”Ÿæˆå›¾åƒå¯¹è‰ºæœ¯ä¸–ç•Œçš„é¢ è¦†æ€§å½±å“ä¸æ—¥ä¿±å¢ã€‚</li>
<li>é‰´åˆ«AIç”Ÿæˆçš„å›¾åƒå¯¹äºé˜²æ­¢æ¬ºè¯ˆã€ç‰ˆæƒä¿æŠ¤å’Œæ¨¡å‹è®­ç»ƒè‡³å…³é‡è¦ã€‚</li>
<li>ç›®å‰æœ‰å‡ ç§æ–¹æ³•å¯ä»¥åŒºåˆ†äººç±»è‰ºæœ¯ä¸AIå›¾åƒï¼ŒåŒ…æ‹¬ç›‘ç£å­¦ä¹ è®­ç»ƒçš„åˆ†ç±»å™¨ã€é’ˆå¯¹æ‰©æ•£æ¨¡å‹çš„ç ”ç©¶å·¥å…·ä»¥åŠä¸“ä¸šè‰ºæœ¯å®¶åˆ©ç”¨å…¶å¯¹è‰ºæœ¯æŠ€å·§çš„äº†è§£è¿›è¡Œè¯†åˆ«ã€‚</li>
<li>ç ”ç©¶è¡¨æ˜ï¼ŒHiveå’Œä¸“å®¶è‰ºæœ¯å®¶åœ¨åŒºåˆ†AIç”Ÿæˆçš„å›¾åƒæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å„æœ‰ä¼˜åŠ£ï¼ˆHiveå¯¹å¯¹æŠ—æ€§æ‰°åŠ¨è¾ƒå¼±ï¼Œè€Œä¸“å®¶è‰ºæœ¯å®¶äº§ç”Ÿè¾ƒé«˜è¯¯æŠ¥ç‡ï¼‰ã€‚</li>
<li>éšç€æ¨¡å‹çš„ä¸æ–­å‘å±•ï¼Œè¿™äº›å¼±ç‚¹å¯èƒ½ä»ç„¶å­˜åœ¨ï¼Œç ”ç©¶æ•°æ®è¡¨æ˜ï¼Œç”±äººç±»å’Œè‡ªåŠ¨æ£€æµ‹å™¨ç»„æˆçš„ç»„åˆå›¢é˜Ÿå¯ä»¥æä¾›æœ€ä½³çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</li>
<li>äººå·¥ç”Ÿæˆçš„å›¾åƒåœ¨è‰ºæœ¯é¢†åŸŸå¼•å‘äº†ä¸€åœºé¢ è¦†ï¼Œå‡†ç¡®åŒºåˆ†äººå·¥æ™ºèƒ½ç”Ÿæˆçš„å›¾åƒå¯¹äºé˜²æ­¢æ¬ºè¯ˆå’Œä¿æŠ¤ç‰ˆæƒè‡³å…³é‡è¦ã€‚</li>
<li>å°½ç®¡æœ‰ä¸åŒçš„æ–¹æ³•å¯ä»¥åŒºåˆ†äººç±»è‰ºæœ¯ä¸AIå›¾åƒï¼Œä½†æ²¡æœ‰ä¸€ç§æ–¹æ³•æ˜¯å®Œç¾çš„ã€‚</li>
<li>å°†äººç±»å’Œè‡ªåŠ¨æ£€æµ‹å™¨ç»“åˆèµ·æ¥å¯ä»¥æä¾›æœ€ä½³çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šæœ‰æœºè¿˜æ˜¯æ‰©æ•£ï¼šæˆ‘ä»¬èƒ½åŒºåˆ†äººç±»è‰ºæœ¯å’Œäººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒå—ï¼Ÿ</li>
<li>ä½œè€…ï¼šAnna Yoo Jeong Haã€Josephine Passanantiã€Ronik Bhaskarã€Shawn Shanã€Reid Southen1ã€Haitao Zhengã€Ben Y. Zhao</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šèŠåŠ å“¥å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»</li>
<li>å…³é”®è¯ï¼šäººå·¥æ™ºèƒ½è‰ºæœ¯ã€å›¾åƒç”Ÿæˆã€é‰´åˆ«å™¨ã€äººç±»è‰ºæœ¯å®¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.03214ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šéšç€äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒçš„å‡ºç°ï¼Œè‰ºæœ¯é¢†åŸŸå‘ç”Ÿäº†å·¨å¤§å˜é©ã€‚åŒºåˆ†äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒå’Œäººç±»è‰ºæœ¯æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼Œå…¶å½±å“éšç€æ—¶é—´çš„æ¨ç§»è€Œä¸æ–­æ‰©å¤§ã€‚å¦‚æœä¸è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œå°±ä¼šè®©ä¸æ³•åˆ†å­æ¬ºéª—é‚£äº›ä¸ºäººç±»è‰ºæœ¯æ”¯ä»˜é«˜ä»·çš„ä¸ªäººå’Œç¦æ­¢ä½¿ç”¨äººå·¥æ™ºèƒ½å›¾åƒçš„å…¬å¸ã€‚è¿™å¯¹å†…å®¹æ‰€æœ‰è€…å»ºç«‹ç‰ˆæƒå’Œå¯¹æ¨¡å‹è®­ç»ƒè€…æ¥è¯´ä¹Ÿæ˜¯è‡³å…³é‡è¦çš„ï¼Œä»–ä»¬éœ€è¦å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œæ•´ç†ä»¥é¿å…æ½œåœ¨çš„æ¨¡å‹å´©æºƒã€‚
(2)ï¼šç›®å‰ï¼Œæœ‰å‡ ç§ä¸åŒçš„æ–¹æ³•å¯ä»¥åŒºåˆ†äººç±»è‰ºæœ¯å’Œäººå·¥æ™ºèƒ½å›¾åƒï¼ŒåŒ…æ‹¬é€šè¿‡ç›‘ç£å­¦ä¹ è®­ç»ƒçš„åˆ†ç±»å™¨ã€é’ˆå¯¹æ‰©æ•£æ¨¡å‹çš„ç ”ç©¶å·¥å…·ä»¥åŠä¸“ä¸šè‰ºæœ¯å®¶åˆ©ç”¨å…¶å¯¹è‰ºæœ¯æŠ€å·§çš„çŸ¥è¯†è¿›è¡Œè¯†åˆ«ã€‚
(3)ï¼šåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¯»æ±‚äº†è§£è¿™äº›æ–¹æ³•åœ¨é¢å¯¹å½“ä»Šç°ä»£ç”Ÿæˆæ¨¡å‹æ—¶ï¼Œåœ¨è‰¯æ€§å’Œå¯¹æŠ—æ€§ç¯å¢ƒä¸­çš„è¡¨ç°å¦‚ä½•ã€‚æˆ‘ä»¬æ•´ç†äº†è·¨è¶Š 7 ç§é£æ ¼çš„çœŸå®äººç±»è‰ºæœ¯ï¼Œä» 5 ä¸ªç”Ÿæˆæ¨¡å‹ä¸­ç”Ÿæˆäº†åŒ¹é…çš„å›¾åƒï¼Œå¹¶åº”ç”¨äº† 8 ä¸ªæ£€æµ‹å™¨ï¼ˆ5 ä¸ªè‡ªåŠ¨æ£€æµ‹å™¨å’Œ 3 ä¸ªä¸åŒçš„äººç±»ç¾¤ä½“ï¼ŒåŒ…æ‹¬ 180 åä¼—åŒ…å·¥äººã€4000 å¤šåä¸“ä¸šè‰ºæœ¯å®¶å’Œ 13 ååœ¨æ£€æµ‹äººå·¥æ™ºèƒ½æ–¹é¢ç»éªŒä¸°å¯Œçš„ä¸“å®¶è‰ºæœ¯å®¶ï¼‰ã€‚
(4)ï¼šHive å’Œä¸“å®¶è‰ºæœ¯å®¶éƒ½è¡¨ç°å¾—éå¸¸å¥½ï¼Œä½†åœ¨ä¸åŒçš„æ–¹é¢çŠ¯äº†é”™è¯¯ï¼ˆHive åœ¨å¯¹æŠ—æ€§æ‰°åŠ¨ä¸­è¾ƒå¼±ï¼Œè€Œä¸“å®¶è‰ºæœ¯å®¶äº§ç”Ÿè¾ƒé«˜çš„è¯¯æŠ¥ï¼‰ã€‚æˆ‘ä»¬è®¤ä¸ºéšç€æ¨¡å‹çš„ä¸æ–­å‘å±•ï¼Œè¿™äº›å¼±ç‚¹å°†ç»§ç»­å­˜åœ¨ï¼Œå¹¶åˆ©ç”¨æˆ‘ä»¬çš„æ•°æ®è¯æ˜ä¸ºä»€ä¹ˆäººç±»å’Œè‡ªåŠ¨æ£€æµ‹å™¨çš„ç»„åˆå›¢é˜Ÿæä¾›äº†å‡†ç¡®æ€§å’Œé²æ£’æ€§çš„æœ€ä½³ç»„åˆã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰æ„å»ºæ•°æ®é›†ï¼š
- æ”¶é›†çœŸäººè‰ºæœ¯ä½œå“ã€AI ç”Ÿæˆçš„å›¾åƒã€æ‰°åŠ¨ç‰ˆæœ¬çš„äººç±»è‰ºæœ¯ä½œå“å’Œ AI å›¾åƒä»¥åŠç»“åˆäººç±»å’Œ AI åŠªåŠ›åˆ›å»ºçš„éå…¸å‹å›¾åƒã€‚
- ä» 53 ä½è‰ºæœ¯å®¶å¤„æ”¶é›† 280 å¹…çœŸäººè‰ºæœ¯ä½œå“ï¼Œæ¶µç›– 7 ç§ä¸»è¦è‰ºæœ¯é£æ ¼ã€‚
- ä¸º 7 ç§è‰ºæœ¯é£æ ¼ä¸­çš„æ¯ä¸€ç§ï¼Œä½¿ç”¨ 5 ä¸ªæµè¡Œçš„ AI ç”Ÿæˆå™¨ç”Ÿæˆ 10 å¼ å›¾åƒï¼Œå…±ç”Ÿæˆ 350 å¼  AI ç”Ÿæˆçš„å›¾åƒã€‚
- è°ƒæ•´ BLIP ç”Ÿæˆçš„æ ‡é¢˜ä»¥åŒ…æ‹¬è‰ºæœ¯ä½œå“çš„é£æ ¼ï¼Œå¹¶æ ¹æ®æ¯ä¸ª AI ç”Ÿæˆå™¨çš„ç‹¬ç‰¹é™åˆ¶å’Œé…ç½®å¯¹æ ‡é¢˜è¿›è¡Œè‡ªå®šä¹‰è°ƒæ•´ã€‚</p>
<p>ï¼ˆ2ï¼‰è¯„ä¼°è‡ªåŠ¨æ£€æµ‹å™¨ï¼š
- è€ƒè™‘å·²éƒ¨ç½²çš„å•†ä¸šç³»ç»Ÿå’ŒåŸºäºç ”ç©¶çš„ç³»ç»Ÿã€‚
- è¯„ä¼°è‡ªåŠ¨æ£€æµ‹å™¨åœ¨æ ¸å¿ƒæµ‹è¯•æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼Œè¯¥æ•°æ®é›†åŒ…å« 280 å¹…çœŸäººè‰ºæœ¯ä½œå“ã€350 å¹… AI å›¾åƒå’Œ 40 å¹…æ··åˆå›¾åƒã€‚
- æµ‹è¯•è‡ªåŠ¨æ£€æµ‹å™¨é’ˆå¯¹å„ç§å¯¹æŠ—æ€§æ‰°åŠ¨ï¼ŒåŒ…æ‹¬é«˜æ–¯å™ªå£°ã€JPEG å‹ç¼©ã€å¯¹æŠ—æ€§æ‰°åŠ¨å’Œ Glaze é£æ ¼æ¨¡æ‹Ÿä¿æŠ¤å·¥å…·ã€‚</p>
<p>ï¼ˆ3ï¼‰è¯„ä¼°äººç±»æ£€æµ‹ï¼šç”¨æˆ·ç ”ç©¶ï¼š
- è¿›è¡Œå•ç‹¬çš„ç”¨æˆ·ç ”ç©¶ï¼Œé’ˆå¯¹ 3 ä¸ªç‹¬ç«‹çš„ç”¨æˆ·ç¾¤ä½“ï¼šåŸºæœ¬å‚ä¸è€…ã€ä¸“ä¸šè‰ºæœ¯å®¶å¿—æ„¿è€…å’Œä¸“å®¶å‚ä¸è€…ã€‚
- åŸºæœ¬å‚ä¸è€…ï¼šé€šè¿‡ Prolific åœ¨çº¿ä¼—åŒ…å¹³å°æ‹›å‹Ÿ 180 åå‚ä¸è€…ï¼Œå®Œæˆä¸€è‡´æ€§æ£€æŸ¥åæœ‰ 177 äººå‚ä¸ã€‚
- ä¸“ä¸šè‰ºæœ¯å®¶å¿—æ„¿è€…ï¼šé€šè¿‡ç¤¾äº¤åª’ä½“æ‹›å‹Ÿè¶…è¿‡ 4000 åä¸“ä¸šè‰ºæœ¯å®¶å¿—æ„¿è€…ï¼Œ3803 äººå®Œæˆè°ƒæŸ¥å¹¶é€šè¿‡æ‰€æœ‰ä¸€è‡´æ€§æ£€æŸ¥ã€‚
- ä¸“å®¶å‚ä¸è€…ï¼šæ‹›å‹Ÿ 13 ä½çŸ¥åä¸“ä¸šè‰ºæœ¯å®¶ï¼Œä»–ä»¬å…·æœ‰è¯†åˆ« AI å›¾åƒçš„ç»éªŒã€‚
- ä¸“å®¶å›¢é˜Ÿæä¾›å¯¹äº§ç”Ÿæœ€å¤šé”™è¯¯åˆ†ç±»çš„æœ€å›°éš¾å›¾åƒçš„è¯¦ç»†åé¦ˆã€‚</p>
<p>ï¼ˆ4ï¼‰æ•°æ®æ”¶é›†ï¼š
- ç­–åˆ’åŒ…å«çœŸäººåˆ›ä½œçš„è‰ºæœ¯ä½œå“ã€AI ç”Ÿæˆçš„å›¾åƒå’Œæ··åˆå›¾åƒçš„æ•°æ®é›†ã€‚
- å®šä¹‰çœŸäººå›¾åƒä¸ºç”±äººç±»è‰ºæœ¯å®¶åŸåˆ›çš„è‰ºæœ¯ä½œå“ã€‚
- AI ç”Ÿæˆçš„å›¾åƒä½¿ç”¨ AI æ¨¡å‹ï¼ˆå¦‚ Midjourneyã€Stable Diffusion å’Œ DALL-E3ï¼‰ä»æ–‡æœ¬æç¤ºç”Ÿæˆã€‚
- æ··åˆå›¾åƒç”± AI ç”Ÿæˆã€æ¶¦è‰²å¹¶éƒ¨åˆ†ç”±äººç±»ç»˜åˆ¶ã€‚
- ä»ç¤¾äº¤åª’ä½“ç½‘ç«™å’Œè‰ºæœ¯å¹³å°æ”¶é›†çœŸäººè‰ºæœ¯ä½œå“ã€‚
- ä¸è‰ºæœ¯å®¶ç¤¾åŒºåˆä½œï¼Œæ”¶é›†è·¨è¶Š 7 ç§ä¸»è¦è‰ºæœ¯é£æ ¼çš„è‰ºæœ¯ä½œå“ã€‚
- ä½¿ç”¨ BLIP æ¨¡å‹ä¸º AI ç”Ÿæˆå™¨åˆ›å»ºæç¤ºï¼Œä»¥ç”Ÿæˆæœ‰æ•ˆæ•æ‰è‰ºæœ¯ä½œå“é£æ ¼å’Œå†…å®¹çš„æ ‡é¢˜ã€‚
- æ ¹æ®æ¯ä¸ª AI ç”Ÿæˆå™¨çš„ç‹¬ç‰¹é™åˆ¶å’Œé…ç½®ï¼Œå¯¹ BLIP ç”Ÿæˆçš„æ ‡é¢˜è¿›è¡Œè‡ªå®šä¹‰è°ƒæ•´ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰éšç€äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒçš„å‡ºç°ï¼ŒåŒºåˆ†äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒå’Œäººç±»è‰ºæœ¯æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚æœ¬æ–‡ç ”ç©¶äº†ç›®å‰å‡ ç§ä¸åŒçš„æ–¹æ³•åœ¨é¢å¯¹å½“ä»Šç°ä»£ç”Ÿæˆæ¨¡å‹æ—¶ï¼Œåœ¨è‰¯æ€§å’Œå¯¹æŠ—æ€§ç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œå¹¶è¯æ˜äº†äººç±»å’Œè‡ªåŠ¨æ£€æµ‹å™¨çš„ç»„åˆå›¢é˜Ÿæä¾›äº†å‡†ç¡®æ€§å’Œé²æ£’æ€§çš„æœ€ä½³ç»„åˆã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
<li>æ„å»ºäº†ä¸€ä¸ªè·¨è¶Š7ç§é£æ ¼çš„çœŸå®äººç±»è‰ºæœ¯ã€äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒå’Œæ··åˆå›¾åƒçš„æ•°æ®é›†ã€‚</li>
<li>è¯„ä¼°äº†8ä¸ªæ£€æµ‹å™¨ï¼ˆ5ä¸ªè‡ªåŠ¨æ£€æµ‹å™¨å’Œ3ä¸ªä¸åŒçš„äººç±»ç¾¤ä½“ï¼‰åœ¨æ ¸å¿ƒæµ‹è¯•æ•°æ®é›†å’Œå„ç§å¯¹æŠ—æ€§æ‰°åŠ¨ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>å‘ç°äººç±»å’Œè‡ªåŠ¨æ£€æµ‹å™¨çš„ç»„åˆå›¢é˜Ÿæä¾›äº†å‡†ç¡®æ€§å’Œé²æ£’æ€§çš„æœ€ä½³ç»„åˆã€‚</li>
<li>ä¸“å®¶è‰ºæœ¯å®¶åœ¨å¯¹æŠ—æ€§æ‰°åŠ¨ä¸­è¡¨ç°è¾ƒå¼±ï¼Œè€Œè‡ªåŠ¨æ£€æµ‹å™¨äº§ç”Ÿè¾ƒé«˜çš„è¯¯æŠ¥ã€‚</li>
<li>éšç€æ¨¡å‹çš„ä¸æ–­å‘å±•ï¼Œè¿™äº›å¼±ç‚¹å°†ç»§ç»­å­˜åœ¨ï¼Œäººç±»å’Œè‡ªåŠ¨æ£€æµ‹å™¨çš„ç»„åˆå›¢é˜Ÿå°†å‘æŒ¥é‡è¦ä½œç”¨ã€‚</li>
<li>åˆ†æäº†Hiveå’Œä¸“å®¶è‰ºæœ¯å®¶åœ¨ä¸åŒæ–¹é¢çš„é”™è¯¯ï¼Œå¹¶è¯æ˜äº†ä¸ºä»€ä¹ˆäººç±»å’Œè‡ªåŠ¨æ£€æµ‹å™¨çš„ç»„åˆå›¢é˜Ÿæä¾›äº†å‡†ç¡®æ€§å’Œé²æ£’æ€§çš„æœ€ä½³ç»„åˆã€‚
ï¼ˆ3ï¼‰æ€§èƒ½ï¼š</li>
<li>åœ¨æ ¸å¿ƒæµ‹è¯•æ•°æ®é›†ä¸Šï¼ŒHiveå’Œä¸“å®¶è‰ºæœ¯å®¶éƒ½è¡¨ç°å¾—éå¸¸å¥½ï¼Œä½†Hiveåœ¨å¯¹æŠ—æ€§æ‰°åŠ¨ä¸­è¡¨ç°è¾ƒå¼±ï¼Œè€Œä¸“å®¶è‰ºæœ¯å®¶äº§ç”Ÿè¾ƒé«˜çš„è¯¯æŠ¥ã€‚</li>
<li>Hiveåœ¨å¯¹æŠ—æ€§æ‰°åŠ¨ä¸­è¾ƒå¼±ï¼Œè€Œä¸“å®¶è‰ºæœ¯å®¶äº§ç”Ÿè¾ƒé«˜çš„è¯¯æŠ¥ã€‚</li>
<li>äººç±»å’Œè‡ªåŠ¨æ£€æµ‹å™¨çš„ç»„åˆå›¢é˜Ÿæä¾›äº†å‡†ç¡®æ€§å’Œé²æ£’æ€§çš„æœ€ä½³ç»„åˆã€‚
ï¼ˆ4ï¼‰å·¥ä½œé‡ï¼š</li>
<li>æ”¶é›†äº†è·¨è¶Š7ç§é£æ ¼çš„280å¹…çœŸå®äººç±»è‰ºæœ¯ä½œå“å’Œ350å¹…äººå·¥æ™ºèƒ½ç”Ÿæˆå›¾åƒã€‚</li>
<li>è¯„ä¼°äº†8ä¸ªæ£€æµ‹å™¨ï¼ˆ5ä¸ªè‡ªåŠ¨æ£€æµ‹å™¨å’Œ3ä¸ªä¸åŒçš„äººç±»ç¾¤ä½“ï¼‰åœ¨æ ¸å¿ƒæµ‹è¯•æ•°æ®é›†å’Œå„ç§å¯¹æŠ—æ€§æ‰°åŠ¨ä¸Šçš„æ€§èƒ½ã€‚</li>
<li>è¿›è¡Œå•ç‹¬çš„ç”¨æˆ·ç ”ç©¶ï¼Œé’ˆå¯¹3ä¸ªç‹¬ç«‹çš„ç”¨æˆ·ç¾¤ä½“ï¼šåŸºæœ¬å‚ä¸è€…ã€ä¸“ä¸šè‰ºæœ¯å®¶å¿—æ„¿è€…å’Œä¸“å®¶å‚ä¸è€…ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8cba12717aa69817e10b925c47c7e5f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-654bd7a18967bfc99c8234931b745b7f.jpg" align="middle">
</details>




<h2 id="PFDM-Parser-Free-Virtual-Try-on-via-Diffusion-Model"><a href="#PFDM-Parser-Free-Virtual-Try-on-via-Diffusion-Model" class="headerlink" title="PFDM: Parser-Free Virtual Try-on via Diffusion Model"></a>PFDM: Parser-Free Virtual Try-on via Diffusion Model</h2><p><strong>Authors:Yunfang Niu, Dong Yi, Lingxiang Wu, Zhiwei Liu, Pengxiang Cai, Jinqiao Wang</strong></p>
<p>Virtual try-on can significantly improve the garment shopping experiences in both online and in-store scenarios, attracting broad interest in computer vision. However, to achieve high-fidelity try-on performance, most state-of-the-art methods still rely on accurate segmentation masks, which are often produced by near-perfect parsers or manual labeling. To overcome the bottleneck, we propose a parser-free virtual try-on method based on the diffusion model (PFDM). Given two images, PFDM can â€œwearâ€ garments on the target person seamlessly by implicitly warping without any other information. To learn the model effectively, we synthesize many pseudo-images and construct sample pairs by wearing various garments on persons. Supervised by the large-scale expanded dataset, we fuse the person and garment features using a proposed Garment Fusion Attention (GFA) mechanism. Experiments demonstrate that our proposed PFDM can successfully handle complex cases, synthesize high-fidelity images, and outperform both state-of-the-art parser-free and parser-based models. </p>
<p><a href="http://arxiv.org/abs/2402.03047v1">PDF</a> Accepted by IEEE ICASSP 2024</p>
<p><strong>Summary</strong><br>æ— è§£æå™¨è™šæ‹Ÿè¯•ç©¿æ–¹æ³•åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œæ— éœ€ç²¾å‡†åˆ†å‰²æ©ç ï¼Œå³å¯å®ç°é€¼çœŸè¯•ç©¿æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>PFDMæ˜¯ä¸€ç§æ— è§£æå™¨çš„è™šæ‹Ÿè¯•ç©¿æ–¹æ³•ï¼Œå¯ä»¥æ— ç¼åœ°â€œç©¿ä¸Šâ€ç›®æ ‡äººç‰©çš„è¡£æœï¼Œè€Œæ— éœ€ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚</li>
<li>PFDMä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ æ— è§£æå™¨çš„è™šæ‹Ÿè¯•ç©¿ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ•æ‰äººä½“çš„ç»“æ„å’Œè¡£æœçš„ç»†èŠ‚ã€‚</li>
<li>PFDMé€šè¿‡åˆæˆå¤§é‡ä¼ªå›¾åƒå¹¶æ„é€ æ ·æœ¬å¯¹æ¥å­¦ä¹ ï¼Œå…¶ä¸­ä¼ªå›¾åƒåŒ…å«äº†å„ç§ç©¿ç€ä¸åŒè¡£æœçš„äººã€‚</li>
<li>PFDMä½¿ç”¨æå‡ºçš„æœè£…èåˆæ³¨æ„ï¼ˆGFAï¼‰æœºåˆ¶æ¥èåˆäººç‰©å’Œè¡£æœçš„ç‰¹å¾ï¼Œä»è€Œç”Ÿæˆé€¼çœŸçš„è¯•ç©¿å›¾åƒã€‚</li>
<li>PFDMå¯ä»¥å¤„ç†å¤æ‚çš„æƒ…å†µï¼Œåˆæˆé«˜ä¿çœŸå›¾åƒï¼Œå¹¶ä¸”ä¼˜äºç°æœ‰åŸºäºè§£æå™¨å’Œæ— è§£æå™¨çš„è™šæ‹Ÿè¯•ç©¿æ¨¡å‹ã€‚</li>
<li>PFDMå¯ä»¥ç”¨äºåœ¨çº¿å’Œåº—å†…è´­ç‰©åœºæ™¯ï¼Œæ˜¾è‘—æ”¹å–„æœè£…è´­ç‰©ä½“éªŒã€‚</li>
<li>PFDMæœ‰æœ›åœ¨è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰é¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šPFDMï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„æ— è§£æè™šæ‹Ÿè¯•ç©¿</li>
<li>ä½œè€…ï¼šç‰›äº‘èŠ³ï¼Œæ˜“ä¸œï¼Œå´ä»¤ç¥¥ï¼Œåˆ˜æ™ºä¼Ÿï¼Œè”¡é¹ç¿”ï¼Œç‹é‡‘æ¡¥</li>
<li>éš¶å±å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€ï¼Œæ¨¡å¼è¯†åˆ«å›½å®¶é‡ç‚¹å®éªŒå®¤ï¼ŒåŸºç¡€æ¨¡å‹ç ”ç©¶ä¸­å¿ƒï¼ŒåŒ—äº¬ï¼Œä¸­å›½</li>
<li>å…³é”®è¯ï¼šè™šæ‹Ÿè¯•ç©¿ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œéšå¼æ‰­æ›²ï¼Œé«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.03047</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šè™šæ‹Ÿè¯•ç©¿å¯ä»¥æ˜¾è‘—æ”¹å–„åœ¨çº¿å’Œåº—å†…åœºæ™¯ä¸­çš„æœè£…è´­ç‰©ä½“éªŒï¼Œåœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œä¸ºäº†å®ç°é«˜ä¿çœŸè¯•ç©¿æ€§èƒ½ï¼Œå¤§å¤šæ•°æœ€å…ˆè¿›çš„æ–¹æ³•ä»ç„¶ä¾èµ–äºå‡†ç¡®çš„åˆ†å‰²æ©ç ï¼Œè¿™äº›æ©ç é€šå¸¸ç”±è¿‘ä¹å®Œç¾çš„è§£æå™¨æˆ–æ‰‹åŠ¨æ ‡æ³¨äº§ç”Ÿã€‚ä¸ºäº†å…‹æœè¿™ä¸€ç“¶é¢ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ— è§£æè™šæ‹Ÿè¯•ç©¿æ–¹æ³•ï¼ˆPFDMï¼‰ã€‚ç»™å®šä¸¤å¼ å›¾åƒï¼ŒPFDM å¯ä»¥é€šè¿‡éšå¼æ‰­æ›²å°†æœè£…æ— ç¼åœ°â€œç©¿â€åœ¨ç›®æ ‡äººç‰©èº«ä¸Šï¼Œè€Œæ— éœ€ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚ä¸ºäº†æœ‰æ•ˆåœ°å­¦ä¹ æ¨¡å‹ï¼Œæˆ‘ä»¬åˆæˆäº†è®¸å¤šä¼ªå›¾åƒï¼Œå¹¶é€šè¿‡åœ¨äººç‰©èº«ä¸Šç©¿æˆ´å„ç§æœè£…æ¥æ„å»ºæ ·æœ¬å¯¹ã€‚åœ¨ç”±å¤§è§„æ¨¡æ‰©å±•æ•°æ®é›†ç›‘ç£ä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨æå‡ºçš„æœè£…èåˆæ³¨æ„ï¼ˆGFAï¼‰æœºåˆ¶èåˆäººç‰©å’Œæœè£…ç‰¹å¾ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„ PFDM å¯ä»¥æˆåŠŸå¤„ç†å¤æ‚æƒ…å†µï¼Œåˆæˆé«˜ä¿çœŸå›¾åƒï¼Œå¹¶ä¸”ä¼˜äºæœ€å…ˆè¿›çš„æ— è§£æå’ŒåŸºäºè§£æçš„æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰ï¼šGAN ç”¨äºè™šæ‹Ÿè¯•ç©¿ã€‚åŸºäº GAN çš„è™šæ‹Ÿè¯•ç©¿æ–¹æ³•é€šå¸¸é‡‡ç”¨ä¸¤æ­¥æ¶æ„ï¼Œé¦–å…ˆå°†æœè£…æ‰­æ›²æˆç›®æ ‡å½¢çŠ¶ï¼Œç„¶åé€šè¿‡ç»„åˆæ‰­æ›²çš„æœè£…å’Œäººç‰©å›¾åƒæ¥åˆæˆç»“æœã€‚ä¸€äº›å·¥ä½œä¸“æ³¨äºåŸºäºè–„æ¿æ ·æ¡å˜æ¢ (TPS) æˆ–å…¨å±€æµå¢å¼ºæ‰­æ›²æ¨¡å—ã€‚å…¶ä»–å·¥ä½œæ—¨åœ¨æé«˜ç”Ÿæˆæ¨¡å—çš„æ€§èƒ½ï¼Œä¾‹å¦‚ï¼Œé‡‡ç”¨å¯¹é½æ„ŸçŸ¥ç”Ÿæˆå™¨æ¥æé«˜åˆæˆå›¾åƒçš„åˆ†è¾¨ç‡ï¼Œæˆ–æ”¹è¿›æŸå¤±å‡½æ•°ä»¥ä¿ç•™äººç‰©èº«ä»½ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ— è§£æè™šæ‹Ÿè¯•ç©¿æ¡†æ¶ã€‚è¿™æ˜¯ç¬¬ä¸€ä¸ªå°†æ‰©æ•£æ¨¡å‹ç”¨äºæ— è§£æè™šæ‹Ÿè¯•ç©¿çš„å·¥ä½œã€‚æˆ‘ä»¬è¿˜ç²¾å¿ƒè®¾è®¡äº†ä¸€ä¸ªå¢å¼ºçš„äº¤å‰æ³¨æ„æ¨¡å—æ¥èåˆäººç‰©å’Œæœè£…ç‰¹å¾ä»¥è¿›è¡Œéšå¼æ‰­æ›²ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šå–å¾—çš„æˆå°±ã€‚æˆ‘ä»¬åœ¨ VITON-HD ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œå®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ— è§£ææ¨¡å‹åœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­éƒ½ä¼˜äºç«äº‰å¯¹æ‰‹ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1)ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ— è§£æè™šæ‹Ÿè¯•ç©¿æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥å°†æœè£…æ— ç¼åœ°â€œç©¿â€åœ¨ç›®æ ‡äººç‰©èº«ä¸Šï¼Œè€Œæ— éœ€ä»»ä½•å…¶ä»–ä¿¡æ¯ã€‚
(2)ï¼šæˆ‘ä»¬ç²¾å¿ƒè®¾è®¡äº†ä¸€ä¸ªå¢å¼ºçš„äº¤å‰æ³¨æ„æ¨¡å—æ¥èåˆäººç‰©å’Œæœè£…ç‰¹å¾ä»¥è¿›è¡Œéšå¼æ‰­æ›²ã€‚
(3)ï¼šæˆ‘ä»¬åˆæˆäº†è®¸å¤šä¼ªå›¾åƒï¼Œå¹¶é€šè¿‡åœ¨äººç‰©èº«ä¸Šç©¿æˆ´å„ç§æœè£…æ¥æ„å»ºæ ·æœ¬å¯¹ã€‚
(4)ï¼šåœ¨ç”±å¤§è§„æ¨¡æ‰©å±•æ•°æ®é›†ç›‘ç£ä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨æå‡ºçš„æœè£…èåˆæ³¨æ„ï¼ˆGFAï¼‰æœºåˆ¶èåˆäººç‰©å’Œæœè£…ç‰¹å¾ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ— è§£æè™šæ‹Ÿè¯•ç©¿æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†æ‰­æ›²å’Œèåˆæ­¥éª¤ç»Ÿä¸€åˆ°ä¸€ä¸ªæ¨¡å‹ä¸­ï¼ŒåŒæ—¶é¿å…äº†ä½¿ç”¨ä»»ä½•è§£æå™¨æˆ–å¤–éƒ¨æ¨¡å—ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼ŒPFDM æ˜¯ç¬¬ä¸€ä¸ªåŸºäºæ‰©æ•£çš„æ— è§£æè™šæ‹Ÿè¯•ç©¿æ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼ŒPFD å¯ä»¥ç”Ÿæˆå…·æœ‰ä¸°å¯Œçº¹ç†ç»†èŠ‚çš„é«˜åˆ†è¾¨ç‡é«˜ä¿çœŸè¯•ç©¿ç»“æœï¼Œå¹¶æˆåŠŸå¤„ç†é”™ä½å’Œé®æŒ¡ï¼Œè¿™ä¸ä»…ä¼˜äºç°æœ‰çš„æ— è§£ææ–¹æ³•ï¼Œè€Œä¸”åœ¨å®šæ€§å’Œå®šé‡åˆ†æä¸­ä¹Ÿè¶…è¶Šäº†æœ€å…ˆè¿›çš„åŸºäºè§£æå™¨çš„æ¨¡å‹ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„å·¥ä½œèƒ½å¤Ÿä¿ƒè¿›è™šæ‹Ÿè¯•ç©¿æŠ€æœ¯åœ¨ç”µå­å•†åŠ¡å’Œå…ƒå®‡å®™ä¸­çš„æ™®åŠã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ— è§£æè™šæ‹Ÿè¯•ç©¿æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†æ‰­æ›²å’Œèåˆæ­¥éª¤ç»Ÿä¸€åˆ°ä¸€ä¸ªæ¨¡å‹ä¸­ï¼ŒåŒæ—¶é¿å…äº†ä½¿ç”¨ä»»ä½•è§£æå™¨æˆ–å¤–éƒ¨æ¨¡å—ã€‚
æ€§èƒ½ï¼šåœ¨å®šæ€§å’Œå®šé‡åˆ†æä¸­ï¼ŒPFDM ä¼˜äºç°æœ‰çš„æ— è§£ææ–¹æ³•å’Œæœ€å…ˆè¿›çš„åŸºäºè§£æå™¨çš„æ¨¡å‹ã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•éœ€è¦åˆæˆå¤§é‡ä¼ªå›¾åƒå¹¶æ„å»ºæ ·æœ¬å¯¹ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡è®¡ç®—èµ„æºã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4fa2bcca39e4d002618ff0b3dcd93311.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d530a087c0dd3abddf2412c841493d90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4af8acc18772befb8884db138ea6e422.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b3f34614b487167c039e9989a45cc12d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b5123c9bbcb697725b9020c9d4ab0422.jpg" align="middle">
</details>




<h2 id="Extreme-Two-View-Geometry-From-Object-Poses-with-Diffusion-Models"><a href="#Extreme-Two-View-Geometry-From-Object-Poses-with-Diffusion-Models" class="headerlink" title="Extreme Two-View Geometry From Object Poses with Diffusion Models"></a>Extreme Two-View Geometry From Object Poses with Diffusion Models</h2><p><strong>Authors:Yujing Sun, Caiyi Sun, Yuan Liu, Yuexin Ma, Siu Ming Yiu</strong></p>
<p>Human has an incredible ability to effortlessly perceive the viewpoint difference between two images containing the same object, even when the viewpoint change is astonishingly vast with no co-visible regions in the images. This remarkable skill, however, has proven to be a challenge for existing camera pose estimation methods, which often fail when faced with large viewpoint differences due to the lack of overlapping local features for matching. In this paper, we aim to effectively harness the power of object priors to accurately determine two-view geometry in the face of extreme viewpoint changes. In our method, we first mathematically transform the relative camera pose estimation problem to an object pose estimation problem. Then, to estimate the object pose, we utilize the object priors learned from a diffusion model Zero123 to synthesize novel-view images of the object. The novel-view images are matched to determine the object pose and thus the two-view camera pose. In experiments, our method has demonstrated extraordinary robustness and resilience to large viewpoint changes, consistently estimating two-view poses with exceptional generalization ability across both synthetic and real-world datasets. Code will be available at <a href="https://github.com/scy639/Extreme-Two-View-Geometry-From-Object-Poses-with-Diffusion-Models">https://github.com/scy639/Extreme-Two-View-Geometry-From-Object-Poses-with-Diffusion-Models</a>. </p>
<p><a href="http://arxiv.org/abs/2402.02800v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨æ‰©æ•£æ¨¡å‹åˆæˆæ–°è§†å›¾å›¾åƒè¿›è¡Œå¯¹è±¡å§¿æ€ä¼°è®¡ï¼Œæœ‰æ•ˆæ±‚è§£æç«¯è§†è§’å˜åŒ–ä¸‹çš„ä¸¤è§†å›¾å‡ ä½•é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨å¯¹è±¡å…ˆéªŒé€šè¿‡æ‰©æ•£æ¨¡å‹Zero123åˆæˆæ–°è§†å›¾å›¾åƒï¼Œå¢å¼ºäº†å¯¹è±¡å§¿æ€ä¼°è®¡çš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚</li>
<li>å°†ç›¸å¯¹ç›¸æœºå§¿æ€ä¼°è®¡é—®é¢˜æ•°å­¦è½¬æ¢ä¸ºå¯¹è±¡å§¿æ€ä¼°è®¡é—®é¢˜ï¼Œç®€åŒ–äº†é—®é¢˜çš„æ±‚è§£ã€‚</li>
<li>åœ¨æç«¯è§†è§’å˜åŒ–çš„æƒ…å†µä¸‹ï¼Œåˆæˆçš„æ–°è§†å›¾å›¾åƒç»åŒ¹é…å¯ä»¥ç¡®å®šå¯¹è±¡å§¿æ€ï¼Œä»è€Œç¡®å®šä¸¤è§†å›¾ç›¸æœºå§¿æ€ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºéå‡¡çš„é²æ£’æ€§å’Œå¼¹æ€§ï¼Œä¼°è®¡ä¸¤è§†å›¾å§¿æ€å…·æœ‰æ°å‡ºçš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>å¯åœ¨ <a href="https://github.com/scy639/Extreme-Two-View-Geometry-From-Object-Poses-with-Diffusion-Models">https://github.com/scy639/Extreme-Two-View-Geometry-From-Object-Poses-with-Diffusion-Models</a> è·å–ä»£ç ã€‚</li>
<li>è¯¥æ–¹æ³•ç²¾åº¦é«˜ï¼Œåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šå‡è¡¨ç°è‰¯å¥½ã€‚</li>
<li>è¯¥æ–¹æ³•é€‚ç”¨äºè§£å†³æç«¯è§†è§’å˜åŒ–ä¸‹çš„ä¸¤è§†å›¾å‡ ä½•é—®é¢˜ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li>æ ‡é¢˜ï¼šä»ç‰©ä½“ä½å§¿ä¼°è®¡æç«¯ä¸¤è§†å›¾å‡ ä½•</li><p></p>
<p></p><li>ä½œè€…ï¼šYujing Sunã€Caiyi Sunã€Yuan Liuã€Yuexin Maã€Siu Ming Yiu</li><p></p>
<p></p><li>éš¶å±æœºæ„ï¼šé¦™æ¸¯å¤§å­¦</li><p></p>
<p></p><li>å…³é”®è¯ï¼šä¸¤è§†å›¾å‡ ä½•ã€ç‰©ä½“ä½å§¿ä¼°è®¡ã€æ‰©æ•£æ¨¡å‹ã€ç”Ÿæˆæ¨¡å‹</li><p></p>
<p></p><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.02800
    Github ä»£ç é“¾æ¥ï¼šhttps://github.com/scy639/Extreme-Two-View-Geometry-From-Object-Poses-with-Diffusion-Models</li><p></p>
<p></p><li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šäººç±»å…·æœ‰æƒŠäººçš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ¯«ä¸è´¹åŠ›åœ°æ„ŸçŸ¥åŒ…å«ç›¸åŒç‰©ä½“çš„ä¸¤å¹…å›¾åƒä¹‹é—´çš„è§†ç‚¹å·®å¼‚ï¼Œå³ä½¿è§†ç‚¹å˜åŒ–éå¸¸å¤§ï¼Œå›¾åƒä¸­æ²¡æœ‰å…±åŒå¯è§çš„åŒºåŸŸã€‚ç„¶è€Œï¼Œå¯¹äºç°æœ‰çš„ç›¸æœºä½å§¿ä¼°è®¡æ–¹æ³•æ¥è¯´ï¼Œè¿™ç§éå‡¡çš„èƒ½åŠ›è¢«è¯æ˜æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå› ä¸ºè¿™äº›æ–¹æ³•åœ¨é¢å¯¹å¤§çš„è§†ç‚¹å·®å¼‚æ—¶é€šå¸¸ä¼šå¤±è´¥ï¼ŒåŸå› æ˜¯ç¼ºå°‘ç”¨äºåŒ¹é…çš„é‡å å±€éƒ¨ç‰¹å¾ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä½¿ç”¨å±€éƒ¨ç‰¹å¾åŒ¹é…æ¥ä¼°è®¡ä¸¤è§†å›¾å‡ ä½•ã€‚ç„¶è€Œï¼Œå½“è§†ç‚¹å·®å¼‚è¾ƒå¤§æ—¶ï¼Œè¿™ç§æ–¹æ³•å¾€å¾€ä¼šå¤±è´¥ï¼Œå› ä¸ºæ²¡æœ‰è¶³å¤Ÿçš„é‡å å±€éƒ¨ç‰¹å¾å¯ä¾›åŒ¹é…ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•æ¥ä¼°è®¡æç«¯ä¸¤è§†å›¾å‡ ä½•ã€‚æˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆå°†ç›¸å¯¹ç›¸æœºä½å§¿ä¼°è®¡é—®é¢˜è½¬æ¢ä¸ºç‰©ä½“ä½å§¿ä¼°è®¡é—®é¢˜ã€‚ç„¶åï¼Œä¸ºäº†ä¼°è®¡ç‰©ä½“ä½å§¿ï¼Œæˆ‘ä»¬åˆ©ç”¨ä»æ‰©æ•£æ¨¡å‹ Zero123 å­¦ä¹ åˆ°çš„ç‰©ä½“å…ˆéªŒæ¥åˆæˆç‰©ä½“çš„ novel-view å›¾åƒã€‚å°† novel-view å›¾åƒåŒ¹é…ä»¥ç¡®å®šç‰©ä½“ä½å§¿ï¼Œä»è€Œç¡®å®šä¸¤è§†å›¾ç›¸æœºä½å§¿ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¡¨ç°å‡ºéå‡¡çš„é²æ£’æ€§å’Œå¯¹å¤§è§†ç‚¹å˜åŒ–çš„é€‚åº”æ€§ï¼Œèƒ½å¤Ÿä¸€è‡´åœ°ä¼°è®¡ä¸¤è§†å›¾ä½å§¿ï¼Œå¹¶ä¸”åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šéƒ½å…·æœ‰å‡ºè‰²çš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³å‡†ç¡®åœ°ç¡®å®šæç«¯è§†ç‚¹å˜åŒ–ä¸‹çš„ä¸¤è§†å›¾å‡ ä½•ã€‚</li><br>&lt;/ol&gt;<p></p>
<p>Methods:
(1): æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•æ¥ä¼°è®¡æç«¯ä¸¤è§†å›¾å‡ ä½•ï¼Œè¯¥æ–¹æ³•å°†ç›¸å¯¹ç›¸æœºä½å§¿ä¼°è®¡é—®é¢˜è½¬æ¢ä¸ºç‰©ä½“ä½å§¿ä¼°è®¡é—®é¢˜ï¼›
(2): åˆ©ç”¨ä»æ‰©æ•£æ¨¡å‹Zero123å­¦ä¹ åˆ°çš„ç‰©ä½“å…ˆéªŒæ¥åˆæˆç‰©ä½“çš„novel-viewå›¾åƒï¼Œå°†novel-viewå›¾åƒåŒ¹é…ä»¥ç¡®å®šç‰©ä½“ä½å§¿ï¼›
(3): é€šè¿‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç®—æ³•ï¼Œå¯ä»¥ä¼°è®¡å…·æœ‰æç«¯è§†ç‚¹å˜åŒ–çš„ç›¸å¯¹ç›¸æœºä½å§¿ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ä»å¤§è§„æ¨¡ 2D æ‰©æ•£æ¨¡å‹ Zero123 å­¦ä¹ åˆ°çš„ç‰©ä½“å…ˆéªŒï¼Œè¯¥å…ˆéªŒèƒ½å¤Ÿç”Ÿæˆå¯¹è±¡çš„ novel-view å›¾åƒã€‚ä½†æ˜¯ï¼Œç”±äº Zero123 åœ¨å…¶æ¨¡å‹ä¸­éšå¼å®šä¹‰äº†è§„èŒƒåæ ‡ç³»ï¼Œå¹¶ä¸”å›¾åƒå¯èƒ½ä¸ä¼šçœ‹å‘å¯¹è±¡ï¼Œå› æ­¤æˆ‘ä»¬æ— æ³•ç›´æ¥åº”ç”¨ Zero123ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ç§æ–°çš„ä¸¤è§†å›¾ä½å§¿ä¼°è®¡å…¬å¼ï¼Œä½œä¸ºç‰©ä½“ä½å§¿ä¼°è®¡é—®é¢˜ï¼Œå¹¶æ­£ç¡®å®šä¹‰è¾“å…¥å›¾åƒå’Œç”Ÿæˆå›¾åƒçš„ç‰©ä½“ä½å§¿ã€‚æœ€åï¼Œæˆ‘ä»¬åŒ¹é…å¦ä¸€å¹…å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>å°†ç›¸å¯¹ç›¸æœºä½å§¿ä¼°è®¡é—®é¢˜è½¬æ¢ä¸ºç‰©ä½“ä½å§¿ä¼°è®¡é—®é¢˜ï¼Œå¹¶åˆ©ç”¨ä»æ‰©æ•£æ¨¡å‹ Zero123 å­¦ä¹ åˆ°çš„ç‰©ä½“å…ˆéªŒæ¥åˆæˆç‰©ä½“çš„ novel-view å›¾åƒï¼Œå°† novel-view å›¾åƒåŒ¹é…ä»¥ç¡®å®šç‰©ä½“ä½å§¿ï¼Œä»è€Œç¡®å®šä¸¤è§†å›¾ç›¸æœºä½å§¿ã€‚</li>
<li>åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¡¨ç°å‡ºéå‡¡çš„é²æ£’æ€§å’Œå¯¹å¤§è§†ç‚¹å˜åŒ–çš„é€‚åº”æ€§ï¼Œèƒ½å¤Ÿä¸€è‡´åœ°ä¼°è®¡ä¸¤è§†å›¾ä½å§¿ï¼Œå¹¶ä¸”åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šéƒ½å…·æœ‰å‡ºè‰²çš„æ³›åŒ–èƒ½åŠ›ã€‚</li>
<li>è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³å‡†ç¡®åœ°ç¡®å®šæç«¯è§†ç‚¹å˜åŒ–ä¸‹çš„ä¸¤è§†å›¾å‡ ä½•ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
- åœ¨åˆæˆæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ‰€æœ‰è§†ç‚¹å˜åŒ–èŒƒå›´å†…éƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨æç«¯è§†ç‚¹å˜åŒ–ä¸‹å…·æœ‰æ˜¾ç€çš„ä¼˜åŠ¿ã€‚
- åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¹Ÿä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸”åœ¨æç«¯è§†ç‚¹å˜åŒ–ä¸‹å…·æœ‰æ˜¾ç€çš„ä¼˜åŠ¿ã€‚</p>
<p>å·¥ä½œé‡ï¼š
- è¯¥æ–¹æ³•éœ€è¦è®­ç»ƒä¸€ä¸ªæ‰©æ•£æ¨¡å‹æ¥å­¦ä¹ ç‰©ä½“å…ˆéªŒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚
- è¯¥æ–¹æ³•è¿˜éœ€è¦åˆæˆ novel-view å›¾åƒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚
- è¯¥æ–¹æ³•è¿˜éœ€è¦åŒ¹é… novel-view å›¾åƒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œè®¡ç®—èµ„æºã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-25907674667aa8b32d056fad9f68800a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-36f6cbd8fb9421b0eea500253c925684.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4d37974797f92e16872fe7a27774fa5a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b283ab7c3ead68d1a7cd2cceb1c42365.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a5815c280ae8797af92483f51007a87d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a313bd5672a496366b53aa94dffc26ae.jpg" align="middle">
</details>




</ol>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF</title>
    <url>/2024/02/09/Paper/2024-02-09/NeRF/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-09-æ›´æ–°"><a href="#2024-02-09-æ›´æ–°" class="headerlink" title="2024-02-09 æ›´æ–°"></a>2024-02-09 æ›´æ–°</h1><h2 id="NeRF-as-Non-Distant-Environment-Emitter-in-Physics-based-Inverse-Rendering"><a href="#NeRF-as-Non-Distant-Environment-Emitter-in-Physics-based-Inverse-Rendering" class="headerlink" title="NeRF as Non-Distant Environment Emitter in Physics-based Inverse   Rendering"></a>NeRF as Non-Distant Environment Emitter in Physics-based Inverse   Rendering</h2><p><strong>Authors:Jingwang Ling, Ruihan Yu, Feng Xu, Chun Du, Shuang Zhao</strong></p>
<p>Physics-based inverse rendering aims to jointly optimize shape, materials, and lighting from captured 2D images. Here lighting is an important part of achieving faithful light transport simulation. While the environment map is commonly used as the lighting model in inverse rendering, we show that its distant lighting assumption leads to spatial invariant lighting, which can be an inaccurate approximation in real-world inverse rendering. We propose to use NeRF as a spatially varying environment lighting model and build an inverse rendering pipeline using NeRF as the non-distant environment emitter. By comparing our method with the environment map on real and synthetic datasets, we show that our NeRF-based emitter models the scene lighting more accurately and leads to more accurate inverse rendering. Project page and video: <a href="https://nerfemitterpbir.github.io/">https://nerfemitterpbir.github.io/</a>. </p>
<p><a href="http://arxiv.org/abs/2402.04829v1">PDF</a> Project page and video: <a href="https://nerfemitterpbir.github.io/">https://nerfemitterpbir.github.io/</a></p>
<p><strong>æ‘˜è¦</strong><br>ç¥ç»è¾å°„åœºå¯ä»¥ä½œä¸ºç©ºé—´éè·ç¦»ç¯å¢ƒå…‰æºï¼Œç”¨äºç‰©ç†é€†æ¸²æŸ“ï¼Œä½¿é€†æ¸²æŸ“æ›´åŠ çœŸå®å‡†ç¡®ã€‚</p>
<p><strong>ä¸»è¦è¦ç‚¹</strong></p>
<ul>
<li>åŸºäºç‰©ç†çš„é€†æ¸²æŸ“æ—¨åœ¨è”åˆä¼˜åŒ–ä»æ•è·çš„ 2D å›¾åƒä¸­æå–çš„å½¢çŠ¶ã€æè´¨å’Œå…‰ç…§ã€‚</li>
<li>åœ¨é€†æ¸²æŸ“ä¸­ï¼Œé€šå¸¸ä½¿ç”¨ç¯å¢ƒè´´å›¾ä½œä¸ºå…‰ç…§æ¨¡å‹ï¼Œä½†è¿™ç§å‡è®¾ä¼šå¯¼è‡´ç©ºé—´ä¸å˜çš„å…‰ç…§ï¼Œè¿™åœ¨çœŸå®ä¸–ç•Œçš„é€†æ¸²æŸ“ä¸­å¯èƒ½æ˜¯ä¸å‡†ç¡®çš„è¿‘ä¼¼ã€‚</li>
<li>æå‡ºä½¿ç”¨ç¥ç»è¾å°„åœºä½œä¸ºç©ºé—´å¯å˜çš„ç¯å¢ƒå…‰ç…§æ¨¡å‹ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªä»¥ç¥ç»è¾å°„åœºä½œä¸ºéè·ç¦»ç¯å¢ƒå…‰æºçš„é€†æ¸²æŸ“ç®¡é“ã€‚</li>
<li>å°†æ–¹æ³•ä¸ç¯å¢ƒè´´å›¾åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œæ¯”è¾ƒï¼Œç»“æœè¡¨æ˜ï¼ŒåŸºäºç¥ç»è¾å°„åœºçš„å…‰æºå¯ä»¥æ›´å‡†ç¡®åœ°æ¨¡æ‹Ÿåœºæ™¯å…‰ç…§ï¼Œå¹¶å®ç°æ›´å‡†ç¡®çš„é€†æ¸²æŸ“ã€‚</li>
<li>é¡¹ç›®é¡µé¢å’Œè§†é¢‘ï¼š<a href="https://nerfemitterpbir.github.io/ã€‚">https://nerfemitterpbir.github.io/ã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºç‰©ç†çš„åæ¼”æ¸²æŸ“ä¸­ï¼ŒNeRF ä½œä¸ºéè¿œå¤„ç¯å¢ƒå‘å°„å™¨</li>
<li>ä½œè€…ï¼šJingwang Lingã€Ruihan Yuã€Feng Xuã€Chun Duã€Shuang Zhao</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šNeRFã€ç‰©ç†åæ¼”æ¸²æŸ“ã€ç¯å¢ƒå…‰ç…§ã€å½¢çŠ¶é‡å»º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2402.04829.pdfï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåŸºäºç‰©ç†çš„åæ¼”æ¸²æŸ“æ—¨åœ¨ä»æ•è·çš„ 2D å›¾åƒä¸­è”åˆä¼˜åŒ–å½¢çŠ¶ã€æè´¨å’Œå…‰ç…§ã€‚å…¶ä¸­ï¼Œå…‰ç…§æ˜¯å®ç°çœŸå®å…‰ç…§ä¼ è¾“æ¨¡æ‹Ÿçš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚ç¯å¢ƒè´´å›¾æ˜¯åæ¼”æ¸²æŸ“ä¸­å¸¸ç”¨çš„å…‰ç…§æ¨¡å‹ï¼Œä½†æˆ‘ä»¬å‘ç°ï¼Œåœ¨å…‰æºä¸æ˜¯æ— é™è¿œå¤„çš„åœºæ™¯ä¸­ï¼Œç¯å¢ƒè´´å›¾çš„ç©ºé—´ä¸å˜å…‰ç…§å‡è®¾ä¼šå¯¼è‡´ç©ºé—´ä¸å˜çš„å…‰ç…§ï¼Œè¿™åœ¨ç°å®ä¸–ç•Œä¸­çš„åæ¼”æ¸²æŸ“ä¸­å¯èƒ½æ˜¯ä¸å‡†ç¡®çš„è¿‘ä¼¼ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨ç¯å¢ƒè´´å›¾æ¥è¿‘ä¼¼ç‰©ä½“å‘¨å›´çš„å…‰ç…§ï¼Œä½†è¿™ç§æ–¹æ³•åœ¨å…‰æºä¸æ˜¯æ— é™è¿œå¤„çš„åœºæ™¯ä¸­ä¼šå¯¼è‡´ä¸å‡†ç¡®çš„ç»“æœã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºä½¿ç”¨ NeRF ä½œä¸ºç©ºé—´å˜åŒ–çš„ç¯å¢ƒå…‰ç…§æ¨¡å‹ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªä»¥ NeRF ä½œä¸ºéè¿œå¤„ç¯å¢ƒå‘å°„å™¨çš„åæ¼”æ¸²æŸ“ç®¡é“ã€‚é€šè¿‡åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šä¸ç¯å¢ƒè´´å›¾è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„ NeRF æ¨¡å‹å¯ä»¥æ›´å‡†ç¡®åœ°æ¨¡æ‹Ÿåœºæ™¯å…‰ç…§ï¼Œå¹¶å®ç°æ›´å‡†ç¡®çš„åæ¼”æ¸²æŸ“ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æ¯”ç¯å¢ƒè´´å›¾æ›´å¥½çš„ç»“æœã€‚åœ¨çœŸå®æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡ç…§æ˜å’Œå½¢çŠ¶é‡å»ºä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚åœ¨åˆæˆæ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡ç…§æ˜ã€å½¢çŠ¶é‡å»ºå’Œæè´¨ä¼°è®¡ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœè¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ›´å‡†ç¡®åœ°æ¨¡æ‹Ÿåœºæ™¯å…‰ç…§ï¼Œå¹¶å®ç°æ›´å‡†ç¡®çš„åæ¼”æ¸²æŸ“ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æå‡ºä½¿ç”¨ NeRF ä½œä¸ºç©ºé—´å˜åŒ–çš„ç¯å¢ƒå…‰ç…§æ¨¡å‹ï¼Œæ„å»ºä»¥ NeRF ä½œä¸ºéè¿œå¤„ç¯å¢ƒå‘å°„å™¨çš„åæ¼”æ¸²æŸ“ç®¡é“ã€‚
ï¼ˆ2ï¼‰åˆ©ç”¨çœŸå®å’Œåˆæˆæ•°æ®é›†ï¼Œä¸ç¯å¢ƒè´´å›¾è¿›è¡Œæ¯”è¾ƒï¼Œè¯æ˜ NeRF æ¨¡å‹å¯ä»¥æ›´å‡†ç¡®åœ°æ¨¡æ‹Ÿåœºæ™¯å…‰ç…§ï¼Œå®ç°æ›´å‡†ç¡®çš„åæ¼”æ¸²æŸ“ã€‚
ï¼ˆ3ï¼‰åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šï¼Œä¸ç¯å¢ƒè´´å›¾ç›¸æ¯”ï¼Œåœ¨é‡ç…§æ˜ã€å½¢çŠ¶é‡å»ºå’Œæè´¨ä¼°è®¡ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº NeRF çš„åæ¼”æ¸²æŸ“ç®¡é“ï¼Œè¯¥ç®¡é“å°† NeRF ç”¨ä½œéè¿œå¤„ç¯å¢ƒå‘å°„å™¨ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°æ¨¡æ‹Ÿåœºæ™¯å…‰ç…§ï¼Œå¹¶å®ç°æ›´å‡†ç¡®çš„åæ¼”æ¸²æŸ“ã€‚
(2)ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>ä½¿ç”¨ NeRF ä½œä¸ºç©ºé—´å˜åŒ–çš„ç¯å¢ƒå…‰ç…§æ¨¡å‹ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°æ¨¡æ‹Ÿåœºæ™¯å…‰ç…§ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªä»¥ NeRF ä½œä¸ºéè¿œå¤„ç¯å¢ƒå‘å°„å™¨çš„åæ¼”æ¸²æŸ“ç®¡é“ï¼Œå¯ä»¥å®ç°æ›´å‡†ç¡®çš„åæ¼”æ¸²æŸ“ã€‚</li>
<li>åœ¨çœŸå®å’Œåˆæˆæ•°æ®é›†ä¸Šï¼Œä¸ç¯å¢ƒè´´å›¾ç›¸æ¯”ï¼Œåœ¨é‡ç…§æ˜ã€å½¢çŠ¶é‡å»ºå’Œæè´¨ä¼°è®¡ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨çœŸå®æ•°æ®é›†ä¸Šï¼Œåœ¨é‡ç…§æ˜å’Œå½¢çŠ¶é‡å»ºä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>åœ¨åˆæˆæ•°æ®é›†ä¸Šï¼Œåœ¨é‡ç…§æ˜ã€å½¢çŠ¶é‡å»ºå’Œæè´¨ä¼°è®¡ä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦è®­ç»ƒ NeRF æ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>éœ€è¦æ„å»ºåæ¼”æ¸²æŸ“ç®¡é“ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„ç¼–ç¨‹å·¥ä½œã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5217f666aff1dcbbc55e20cda0c76080.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a9fa354da141f8905a59ea4a06f90f25.jpg" align="middle">
</details>




<h2 id="OV-NeRF-Open-vocabulary-Neural-Radiance-Fields-with-Vision-and-Language-Foundation-Models-for-3D-Semantic-Understanding"><a href="#OV-NeRF-Open-vocabulary-Neural-Radiance-Fields-with-Vision-and-Language-Foundation-Models-for-3D-Semantic-Understanding" class="headerlink" title="OV-NeRF: Open-vocabulary Neural Radiance Fields with Vision and Language   Foundation Models for 3D Semantic Understanding"></a>OV-NeRF: Open-vocabulary Neural Radiance Fields with Vision and Language   Foundation Models for 3D Semantic Understanding</h2><p><strong>Authors:Guibiao Liao, Kaichen Zhou, Zhenyu Bao, Kanglin Liu, Qing Li</strong></p>
<p>The development of Neural Radiance Fields (NeRFs) has provided a potent representation for encapsulating the geometric and appearance characteristics of 3D scenes. Enhancing the capabilities of NeRFs in open-vocabulary 3D semantic perception tasks has been a recent focus. However, current methods that extract semantics directly from Contrastive Language-Image Pretraining (CLIP) for semantic field learning encounter difficulties due to noisy and view-inconsistent semantics provided by CLIP. To tackle these limitations, we propose OV-NeRF, which exploits the potential of pre-trained vision and language foundation models to enhance semantic field learning through proposed single-view and cross-view strategies. First, from the single-view perspective, we introduce Region Semantic Ranking (RSR) regularization by leveraging 2D mask proposals derived from SAM to rectify the noisy semantics of each training view, facilitating accurate semantic field learning. Second, from the cross-view perspective, we propose a Cross-view Self-enhancement (CSE) strategy to address the challenge raised by view-inconsistent semantics. Rather than invariably utilizing the 2D inconsistent semantics from CLIP, CSE leverages the 3D consistent semantics generated from the well-trained semantic field itself for semantic field training, aiming to reduce ambiguity and enhance overall semantic consistency across different views. Extensive experiments validate our OV-NeRF outperforms current state-of-the-art methods, achieving a significant improvement of 20.31% and 18.42% in mIoU metric on Replica and Scannet, respectively. Furthermore, our approach exhibits consistent superior results across various CLIP configurations, further verifying its robustness. </p>
<p><a href="http://arxiv.org/abs/2402.04648v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æŠ€æœ¯é€šè¿‡ç»“åˆè§†è§‰å’Œè¯­è¨€åŸºç¡€æ¨¡å‹ï¼Œæå‡äº†NeRFåœ¨å¼€æ”¾è¯æ±‡è¡¨3Dè¯­ä¹‰æ„ŸçŸ¥ä¸­çš„è¡¨ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>OV-NeRF æå‡ºäº†ä¸€ç§å•è§†å›¾å’Œè·¨è§†å›¾ç­–ç•¥ï¼Œå°†NeRFç”¨äºå¼€æ”¾è¯æ±‡è¡¨3Dè¯­ä¹‰æ„ŸçŸ¥ã€‚</li>
<li>åˆ©ç”¨ SAM æå–çš„ 2D æ©æ¨¡å»ºè®®ï¼Œå¼•å…¥åŒºåŸŸè¯­ä¹‰æ’åº (RSR) æ­£åˆ™åŒ–ï¼Œä»¥çº æ­£æ¯ä¸ªè®­ç»ƒè§†å›¾çš„è¯­ä¹‰å™ªå£°ã€‚</li>
<li>æå‡ºè·¨è§†å›¾è‡ªå¢å¼º (CSE) ç­–ç•¥ï¼Œåˆ©ç”¨è®­ç»ƒè¯­ä¹‰åœºæœ¬èº«ç”Ÿæˆçš„ 3D ä¸€è‡´è¯­ä¹‰ï¼Œå‡å°‘è¯­ä¹‰æ¨¡ç³Šæ€§å’Œå¢å¼ºè¯­ä¹‰ä¸€è‡´æ€§ã€‚</li>
<li>OV-NeRF åœ¨ Replica å’Œ Scannet æ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº† 20.31% å’Œ 18.42% çš„ mIoU æŒ‡æ ‡æå‡ï¼Œä¼˜äºç°æœ‰æœ€ä¼˜æ–¹æ³•ã€‚</li>
<li>OV-NeRF åœ¨å„ç§ CLIP é…ç½®ä¸‹å‡è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶é²æ£’æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šOV-NeRFï¼šå…·æœ‰è§†è§‰å’Œè¯­è¨€çš„å¼€æ”¾è¯æ±‡ç¥ç»è¾å°„åœº</li>
<li>ä½œè€…ï¼šå»–æ¡‚æ ‡ï¼Œå‘¨å‡¯æ™¨ï¼Œé²æŒ¯å®‡ï¼Œåˆ˜åº·æ—ï¼Œæåº†</li>
<li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºï¼Œå¼€æ”¾è¯æ±‡ï¼Œè¯­ä¹‰ç†è§£ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.04648</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„è¡¨ç¤ºæ–¹æ³•ï¼Œå¯ä»¥æ•æ‰å¤æ‚çœŸå®ä¸–ç•Œçš„ 3D åœºæ™¯ã€‚ç„¶è€Œï¼Œåœ¨å¼€æ”¾è¯æ±‡ 3D è¯­ä¹‰æ„ŸçŸ¥ä»»åŠ¡ä¸­å®ç°å…¨é¢çš„ 3D è¯­ä¹‰ç†è§£ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ç›´æ¥ä»å¯¹æ¯”è§†è§‰è¯­è¨€é¢„è®­ç»ƒï¼ˆCLIPï¼‰ä¸­æå–è¯­ä¹‰ï¼Œç”¨äºè¯­ä¹‰åœºå­¦ä¹ ï¼Œä½†é‡åˆ°äº†æ¥è‡ª CLIP çš„å˜ˆæ‚å’Œè§†å›¾ä¸ä¸€è‡´è¯­ä¹‰çš„å›°éš¾ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº† OV-NeRFï¼Œå®ƒåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹çš„æ½œåŠ›ï¼Œé€šè¿‡æå‡ºçš„å•è§†å›¾å’Œè·¨è§†å›¾ç­–ç•¥æ¥å¢å¼ºè¯­ä¹‰åœºå­¦ä¹ ã€‚
(4) æ€§èƒ½è¡¨ç°ï¼šOV-NeRF åœ¨ Replica å’Œ Scannet ä¸Šåˆ†åˆ«åœ¨ mIoU åº¦é‡ä¸­å–å¾—äº† 20.31% å’Œ 18.42% çš„æ˜¾ç€æ”¹è¿›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§ CLIP é…ç½®ä¸­è¡¨ç°å‡ºä¸€è‡´çš„ä¼˜å¼‚ç»“æœï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶é²æ£’æ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æå‡º OV-NeRFï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹çš„æ½œåŠ›ï¼Œé€šè¿‡æå‡ºçš„å•è§†å›¾å’Œè·¨è§†å›¾ç­–ç•¥æ¥å¢å¼ºè¯­ä¹‰åœºå­¦ä¹ ã€‚
(2) åˆ©ç”¨é¢„å…ˆè®¡ç®—çš„ CLIP ç‰¹å¾å’Œ SAM çš„åŒºåŸŸæè®®æ¥ç”Ÿæˆç²¾ç¡®çš„ç›¸å…³æ€§å›¾ï¼Œä»¥ç›‘ç£ OV-NeRFï¼Œè€Œä¸æ˜¯ä½¿ç”¨æºè‡ª CLIP æ¨¡å‹çš„åŸå§‹å™ªå£°ç›¸å…³æ€§å›¾ã€‚
(3) åœ¨è®­ç»ƒ OV-NeRF æ•°ä¸ª epoch åï¼Œåˆ©ç”¨ä» OV-NeRF è·å¾—çš„æ¸²æŸ“ä¼ªè¾“å‡ºï¼ŒåŒ…æ‹¬è®­ç»ƒè§†å›¾å’Œæœªè§æ–°é¢–è§†å›¾ï¼Œç”¨äºè·¨è§†å›¾è‡ªæˆ‘å¢å¼ºç›‘ç£ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé€šè¿‡åˆ©ç”¨è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹çš„èƒ½åŠ›ï¼Œæå‡º OV-NeRF æ¥è§£å†³åŸºäº NeRF çš„ 3D è¯­ä¹‰ç†è§£æŒ‘æˆ˜ã€‚åœ¨ OV-NeRF ä¸­ï¼Œæå‡ºçš„åŒºåŸŸè¯­ä¹‰æ’åºï¼ˆRSRï¼‰æ­£åˆ™åŒ–äº§ç”Ÿç²¾ç¡®çš„å•è§†å›¾ç›¸å…³æ€§å›¾æ¥è®­ç»ƒ OV-NeRFï¼Œè·¨è§†å›¾è‡ªæˆ‘å¢å¼ºç¡®ä¿è§†å›¾ä¸€è‡´çš„åˆ†å‰²ç»“æœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†æ•°æ®é›†ä¸Šä»¥å¾ˆå¤§ä¼˜åŠ¿ä¼˜äº SOTA æ–¹æ³•ï¼Œæ˜¾ç¤ºäº†æˆ‘ä»¬æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸åŒçš„ CLIP é…ç½®ä¸­å§‹ç»ˆè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè‚¯å®šäº†å…¶é€šç”¨æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°çš„ NeRF æ¨¡å‹ OV-NeRFï¼Œè¯¥æ¨¡å‹åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€åŸºç¡€æ¨¡å‹çš„æ½œåŠ›ï¼Œé€šè¿‡æå‡ºçš„å•è§†å›¾å’Œè·¨è§†å›¾ç­–ç•¥æ¥å¢å¼ºè¯­ä¹‰åœºå­¦ä¹ ã€‚
æå‡ºäº†ä¸€ç§æ–°çš„åŒºåŸŸè¯­ä¹‰æ’åºï¼ˆRSRï¼‰æ­£åˆ™åŒ–ï¼Œè¯¥æ­£åˆ™åŒ–äº§ç”Ÿç²¾ç¡®çš„å•è§†å›¾ç›¸å…³æ€§å›¾æ¥è®­ç»ƒ OV-NeRFã€‚
æå‡ºäº†ä¸€ç§æ–°çš„è·¨è§†å›¾è‡ªæˆ‘å¢å¼ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ä» OV-NeRF è·å¾—çš„æ¸²æŸ“ä¼ªè¾“å‡ºï¼ŒåŒ…æ‹¬è®­ç»ƒè§†å›¾å’Œæœªè§æ–°é¢–è§†å›¾ï¼Œç”¨äºè·¨è§†å›¾è‡ªæˆ‘å¢å¼ºç›‘ç£ã€‚
æ€§èƒ½ï¼š
OV-NeRF åœ¨ Replica å’Œ Scannet ä¸Šåˆ†åˆ«åœ¨ mIoU åº¦é‡ä¸­å–å¾—äº† 20.31% å’Œ 18.42% çš„æ˜¾ç€æ”¹è¿›ã€‚
è¯¥æ–¹æ³•åœ¨å„ç§ CLIP é…ç½®ä¸­è¡¨ç°å‡ºä¸€è‡´çš„ä¼˜å¼‚ç»“æœï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶é²æ£’æ€§ã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•éœ€è¦é¢„å…ˆè®¡ç®— CLIP ç‰¹å¾å’Œ SAM çš„åŒºåŸŸæè®®ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚
è¯¥æ–¹æ³•éœ€è¦è®­ç»ƒå¤šä¸ª epochï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®­ç»ƒæ—¶é—´ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d28a855be0d118e883bd9f8001dbbcd1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1c6219c40ef2be88e25422dda1aae264.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fece26674b484110bc1b8871018a6a3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ea1c3e14317a591427313451f7980698.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a1bd1a1dc370f614b943567738833593.jpg" align="middle">
</details>




<h2 id="GSN-Generalisable-Segmentation-in-Neural-Radiance-Field"><a href="#GSN-Generalisable-Segmentation-in-Neural-Radiance-Field" class="headerlink" title="GSN: Generalisable Segmentation in Neural Radiance Field"></a>GSN: Generalisable Segmentation in Neural Radiance Field</h2><p><strong>Authors:Vinayak Gupta, Rahul Goel, Sirikonda Dhawal, P. J. Narayanan</strong></p>
<p>Traditional Radiance Field (RF) representations capture details of a specific scene and must be trained afresh on each scene. Semantic feature fields have been added to RFs to facilitate several segmentation tasks. Generalised RF representations learn the principles of view interpolation. A generalised RF can render new views of an unknown and untrained scene, given a few views. We present a way to distil feature fields into the generalised GNT representation. Our GSN representation generates new views of unseen scenes on the fly along with consistent, per-pixel semantic features. This enables multi-view segmentation of arbitrary new scenes. We show different semantic features being distilled into generalised RFs. Our multi-view segmentation results are on par with methods that use traditional RFs. GSN closes the gap between standard and generalisable RF methods significantly. Project Page: <a href="https://vinayak-vg.github.io/GSN/">https://vinayak-vg.github.io/GSN/</a> </p>
<p><a href="http://arxiv.org/abs/2402.04632v1">PDF</a> Accepted at the Main Technical Track of AAAI 2024</p>
<p><strong>Summary</strong><br>åˆ©ç”¨å‡ ä¸ªè§†å›¾å°±å¯ä»¥æ¸²æŸ“æœªçŸ¥ä¸”æœªè®­ç»ƒåœºæ™¯çš„æ–°è§†å›¾ï¼Œå¹¶æä¾›ä¸€è‡´çš„é€åƒç´ è¯­ä¹‰ç‰¹å¾ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä¼ ç»Ÿè¾å°„åœºè¡¨ç¤ºæ•è·ç‰¹å®šåœºæ™¯çš„ç»†èŠ‚ï¼Œå¿…é¡»åœ¨æ¯ä¸ªåœºæ™¯ä¸Šé‡æ–°è®­ç»ƒã€‚</li>
<li>è¯­ä¹‰ç‰¹å¾å­—æ®µå·²æ·»åŠ åˆ°å°„é¢‘ä¸­ä»¥ä¿ƒè¿›å¤šé¡¹åˆ†å‰²ä»»åŠ¡ã€‚</li>
<li>å¹¿ä¹‰å°„é¢‘è¡¨ç¤ºå­¦ä¹ äº†è§†å›¾æ’å€¼åŸç†ã€‚</li>
<li>ç»™å®šå‡ ä¸ªè§†å›¾ï¼Œå¹¿ä¹‰å°„é¢‘å¯ä»¥æ¸²æŸ“æœªçŸ¥ä¸”æœªè®­ç»ƒåœºæ™¯çš„æ–°è§†å›¾ã€‚</li>
<li>æˆ‘ä»¬æä¾›äº†ä¸€ç§å°†ç‰¹å¾å­—æ®µæç‚¼æˆå¹¿ä¹‰ GNT è¡¨ç¤ºçš„æ–¹æ³•ã€‚</li>
<li>æˆ‘ä»¬çš„ GSN è¡¨ç¤ºå¯ä»¥å¿«é€Ÿç”Ÿæˆæœªè§åœºæ™¯çš„æ–°è§†å›¾ï¼Œå¹¶æä¾›ä¸€è‡´çš„é€åƒç´ è¯­ä¹‰ç‰¹å¾ã€‚</li>
<li>è¿™å…è®¸å¯¹ä»»æ„æ–°åœºæ™¯è¿›è¡Œå¤šè§†å›¾åˆ†å‰²ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šGSNï¼šç¥ç»è¾å°„åœºä¸­çš„å¯æ³›åŒ–åˆ†å‰²</li>
<li>ä½œè€…ï¼šVinayak Guptaï¼ŒRahul Goelï¼ŒSirikonda Dhawalï¼ŒP.J. Narayanan</li>
<li>éš¶å±æœºæ„ï¼šå°åº¦ç†å·¥å­¦é™¢é©¬å¾·æ‹‰æ–¯åˆ†æ ¡</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å¯æ³›åŒ–åˆ†å‰²ã€è¯­ä¹‰ç‰¹å¾åœº</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.04632
   Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä¼ ç»Ÿçš„ç¥ç»è¾å°„åœºï¼ˆRFï¼‰è¡¨ç¤ºå¯ä»¥æ•æ‰ç‰¹å®šåœºæ™¯çš„ç»†èŠ‚ï¼Œä½†å¿…é¡»é’ˆå¯¹æ¯ä¸ªåœºæ™¯é‡æ–°è®­ç»ƒã€‚è¯­ä¹‰ç‰¹å¾åœºå·²è¢«æ·»åŠ åˆ° RF ä¸­ä»¥ä¿ƒè¿›å¤šé¡¹åˆ†å‰²ä»»åŠ¡ã€‚æ³›åŒ–çš„ RF è¡¨ç¤ºå­¦ä¹ è§†å›¾æ’å€¼åŸç†ã€‚ç»™å®šå‡ ä¸ªè§†å›¾ï¼Œæ³›åŒ–çš„ RF å¯ä»¥æ¸²æŸ“æœªçŸ¥ä¸”æœªè®­ç»ƒåœºæ™¯çš„æ–°è§†å›¾ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å°†ç‰¹å¾åœºæç‚¼åˆ°æ³›åŒ–çš„ GNT è¡¨ç¤ºä¸­çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„ GSN è¡¨ç¤ºå¯ä»¥å³æ—¶ç”Ÿæˆæœªè§åœºæ™¯çš„æ–°è§†å›¾ï¼ŒåŒæ—¶æä¾›ä¸€è‡´çš„é€åƒç´ è¯­ä¹‰ç‰¹å¾ã€‚è¿™ä½¿å¾—ä»»æ„æ–°åœºæ™¯çš„å¤šè§†å›¾åˆ†å‰²æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬å±•ç¤ºäº†å°†ä¸åŒè¯­ä¹‰ç‰¹å¾æå–åˆ°æ³›åŒ–çš„ RF ä¸­ã€‚æˆ‘ä»¬çš„å¤šè§†å›¾åˆ†å‰²ç»“æœä¸ä½¿ç”¨ä¼ ç»Ÿ RF çš„æ–¹æ³•ç›¸å½“ã€‚GSN æ˜¾ç€ç¼©å°äº†æ ‡å‡† RF æ–¹æ³•å’Œå¯æ³›åŒ– RF æ–¹æ³•ä¹‹é—´çš„å·®è·ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šè¿‡å»çš„ RF è¡¨ç¤ºå­¦ä¹ ç‰¹å®šåœºæ™¯çš„ç»†èŠ‚ï¼Œå¿…é¡»é’ˆå¯¹æ¯ä¸ªåœºæ™¯é‡æ–°è®­ç»ƒã€‚è¯­ä¹‰ç‰¹å¾åœºå·²è¢«æ·»åŠ åˆ° RF ä¸­ä»¥ä¿ƒè¿›å¤šé¡¹åˆ†å‰²ä»»åŠ¡ã€‚æ³›åŒ–çš„ RF è¡¨ç¤ºå­¦ä¹ è§†å›¾æ’å€¼åŸç†ã€‚ç»™å®šå‡ ä¸ªè§†å›¾ï¼Œæ³›åŒ–çš„ RF å¯ä»¥æ¸²æŸ“æœªçŸ¥ä¸”æœªè®­ç»ƒåœºæ™¯çš„æ–°è§†å›¾ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å°†ç‰¹å¾åœºæç‚¼åˆ°æ³›åŒ–çš„ GNT è¡¨ç¤ºä¸­çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„ GSN è¡¨ç¤ºå¯ä»¥å³æ—¶ç”Ÿæˆæœªè§åœºæ™¯çš„æ–°è§†å›¾ï¼ŒåŒæ—¶æä¾›ä¸€è‡´çš„é€åƒç´ è¯­ä¹‰ç‰¹å¾ã€‚è¿™ä½¿å¾—ä»»æ„æ–°åœºæ™¯çš„å¤šè§†å›¾åˆ†å‰²æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬å±•ç¤ºäº†å°†ä¸åŒè¯­ä¹‰ç‰¹å¾æå–åˆ°æ³›åŒ–çš„ RF ä¸­ã€‚æˆ‘ä»¬çš„å¤šè§†å›¾åˆ†å‰²ç»“æœä¸ä½¿ç”¨ä¼ ç»Ÿ RF çš„æ–¹æ³•ç›¸å½“ã€‚GSN æ˜¾ç€ç¼©å°äº†æ ‡å‡† RF æ–¹æ³•å’Œå¯æ³›åŒ– RF æ–¹æ³•ä¹‹é—´çš„å·®è·ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½ï¼šæˆ‘ä»¬çš„å¤šè§†å›¾åˆ†å‰²ç»“æœä¸ä½¿ç”¨ä¼ ç»Ÿ RF çš„æ–¹æ³•ç›¸å½“ã€‚GSN æ˜¾ç€ç¼©å°äº†æ ‡å‡† RF æ–¹æ³•å’Œå¯æ³›åŒ– RF æ–¹æ³•ä¹‹é—´çš„å·®è·ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰é¦–å…ˆï¼Œæˆ‘ä»¬ä¿®æ”¹ GNT æ¶æ„ä»¥å¸®åŠ©è¯­ä¹‰ç‰¹å¾æå–ã€‚
ï¼ˆ2ï¼‰ç„¶åï¼Œæˆ‘ä»¬æè¿°äº†æˆ‘ä»¬çš„ä¸¤é˜¶æ®µè®­ç»ƒè’¸é¦è¿‡ç¨‹ã€‚
ï¼ˆ3ï¼‰æœ€åï¼Œæˆ‘ä»¬æè¿°äº†å¦‚ä½•ä½¿ç”¨è’¸é¦ç‰¹å¾æ‰§è¡Œå¤šè§†å›¾åˆ†å‰²ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¤šè§†å›¾åˆ†å‰²æ–¹æ³•ï¼Œå…¶ä¸»è¦ä¼˜åŠ¿åœ¨äºå…¶æ³›åŒ–æ€§ï¼Œå³å®ƒå¯ä»¥åœ¨ä»»æ„æ–°åœºæ™¯ä¸Šæ‰§è¡Œåˆ†å‰²è€Œæ— éœ€ä»»ä½•è®­ç»ƒã€‚è¿™ä½¿å…¶åŒºåˆ«äºä»¥å‰çš„æ–¹æ³•ã€‚æˆ‘ä»¬å°†æˆ‘ä»¬çš„ç»“æœä¸æ—©æœŸæ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼Œå¹¶è¡¨æ˜æˆ‘ä»¬çš„æ€§èƒ½ä¸å®ƒä»¬ç›¸å½“ï¼ŒåŒæ—¶å¯ä»¥æ³›åŒ–åˆ°æœªè§åœºæ™¯ã€‚è¿™æ˜¯å°†æ³›åŒ–ç¥ç»è¾å°„åœºçš„åº”ç”¨æ‹‰è¿‘åˆ°ç‰¹å®šåœºæ™¯è¾å°„åœºçš„ä¸€å¤§æ­¥ã€‚æˆ‘ä»¬æ–¹æ³•é¢„æµ‹çš„ç‰¹å¾å¯ç”¨äºå¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†å°†ç‰¹å¾åœºæç‚¼åˆ°æ³›åŒ–çš„ GNT è¡¨ç¤ºä¸­çš„æ–¹æ³•ï¼Œè¯¥è¡¨ç¤ºå¯ä»¥å³æ—¶ç”Ÿæˆæœªè§åœºæ™¯çš„æ–°è§†å›¾ï¼ŒåŒæ—¶æä¾›ä¸€è‡´çš„é€åƒç´ è¯­ä¹‰ç‰¹å¾ã€‚
æ€§èƒ½ï¼šæˆ‘ä»¬çš„å¤šè§†å›¾åˆ†å‰²ç»“æœä¸ä½¿ç”¨ä¼ ç»Ÿ RF çš„æ–¹æ³•ç›¸å½“ã€‚GSN æ˜¾ç€ç¼©å°äº†æ ‡å‡† RF æ–¹æ³•å’Œå¯æ³›åŒ– RF æ–¹æ³•ä¹‹é—´çš„å·®è·ã€‚
å·¥ä½œé‡ï¼šæˆ‘ä»¬çš„æ–¹æ³•ä¾èµ–äºåŸºäº transformer çš„æ¶æ„ï¼Œå› æ­¤æ¸²æŸ“è¿‡ç¨‹ä¸å‡ ç§ç‰¹å®šåœºæ™¯çš„è¾å°„åœºæ–¹æ³•ç›¸æ¯”å›ºæœ‰åœ°ç¼“æ…¢ã€‚æé«˜æ¸²æŸ“é€Ÿåº¦å¯ä»¥æ˜¾ç€æ”¹å–„æˆ‘ä»¬åŸºäºç¬”åˆ’çš„åˆ†å‰²æ–¹æ³•æ‰€éœ€çš„äººæœºäº¤äº’ä½“éªŒã€‚æˆ‘ä»¬å°†æ³›åŒ–è¾å°„åœºçš„æ¸²æŸ“é€Ÿåº¦æ”¹è¿›ç•™ä½œæœªæ¥çš„å·¥ä½œã€‚ç›®å‰ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ‰§è¡Œå¤šè§†å›¾åˆ†å‰²ï¼Œå› ä¸ºå®ƒä½¿ç”¨åŸºäºå›¾åƒçš„æ¸²æŸ“ã€‚æŸäº›åº”ç”¨ç¨‹åºéœ€è¦ 3D åˆ†å‰²è€Œä¸æ˜¯å¤šè§†å›¾åˆ†å‰²ã€‚å› æ­¤ï¼Œå¯æ³›åŒ–çš„ 3D åˆ†å‰²æ¡†æ¶æœ‰æœ›æˆä¸ºæœªæ¥çš„å·¥ä½œã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-bf67c21104c6d20a1d6e37e83bff2155.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-03400222552085971945e9fc363dc323.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-61621673ca99816fe4332d9623a7e1b3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c82ea98993102ebb08c3d96886f8caf8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d9b9a069535dfb6e09a7654648b4f040.jpg" align="middle">
</details>




<h2 id="BirdNeRF-Fast-Neural-Reconstruction-of-Large-Scale-Scenes-From-Aerial-Imagery"><a href="#BirdNeRF-Fast-Neural-Reconstruction-of-Large-Scale-Scenes-From-Aerial-Imagery" class="headerlink" title="BirdNeRF: Fast Neural Reconstruction of Large-Scale Scenes From Aerial   Imagery"></a>BirdNeRF: Fast Neural Reconstruction of Large-Scale Scenes From Aerial   Imagery</h2><p><strong>Authors:Huiqing Zhang, Yifei Xue, Ming Liao, Yizhen Lao</strong></p>
<p>In this study, we introduce BirdNeRF, an adaptation of Neural Radiance Fields (NeRF) designed specifically for reconstructing large-scale scenes using aerial imagery. Unlike previous research focused on small-scale and object-centric NeRF reconstruction, our approach addresses multiple challenges, including (1) Addressing the issue of slow training and rendering associated with large models. (2) Meeting the computational demands necessitated by modeling a substantial number of images, requiring extensive resources such as high-performance GPUs. (3) Overcoming significant artifacts and low visual fidelity commonly observed in large-scale reconstruction tasks due to limited model capacity. Specifically, we present a novel bird-view pose-based spatial decomposition algorithm that decomposes a large aerial image set into multiple small sets with appropriately sized overlaps, allowing us to train individual NeRFs of sub-scene. This decomposition approach not only decouples rendering time from the scene size but also enables rendering to scale seamlessly to arbitrarily large environments. Moreover, it allows for per-block updates of the environment, enhancing the flexibility and adaptability of the reconstruction process. Additionally, we propose a projection-guided novel view re-rendering strategy, which aids in effectively utilizing the independently trained sub-scenes to generate superior rendering results. We evaluate our approach on existing datasets as well as against our own drone footage, improving reconstruction speed by 10x over classical photogrammetry software and 50x over state-of-the-art large-scale NeRF solution, on a single GPU with similar rendering quality. </p>
<p><a href="http://arxiv.org/abs/2402.04554v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>é¸Ÿç° NeRFï¼šåŸºäºç¥ç»è¾å°„åœºçš„å¤§è§„æ¨¡åœºæ™¯é‡å»ºã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>é’ˆå¯¹å¤§è§„æ¨¡åœºæ™¯é‡å»ºï¼Œæå‡ºäº†åŸºäºç¥ç»è¾å°„åœºçš„ BirdNeRF ç®—æ³•ã€‚</li>
<li>BirdNeRF å°†å¤§åœºæ™¯å›¾åƒé›†åˆ†è§£ä¸ºå¤šä¸ªå°é›†åˆï¼Œæ¯ä¸ªå°é›†åˆè®­ç»ƒå•ç‹¬çš„ NeRF æ¨¡å‹ã€‚</li>
<li>è¿™ç§åˆ†è§£æ–¹æ³•å°†æ¸²æŸ“æ—¶é—´ä¸åœºæ™¯å¤§å°è§£è€¦ï¼Œå¹¶ä½¿æ¸²æŸ“èƒ½å¤Ÿæ— ç¼æ‰©å±•åˆ°ä»»æ„å¤§çš„ç¯å¢ƒã€‚</li>
<li>æ­¤å¤–ï¼Œå®ƒå…è®¸å¯¹ç¯å¢ƒè¿›è¡Œé€å—æ›´æ–°ï¼Œä»è€Œæé«˜é‡å»ºè¿‡ç¨‹çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæŠ•å½±çš„æ–°é¢–è§†è§’é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œæœ‰åŠ©äºæœ‰æ•ˆåˆ©ç”¨ç‹¬ç«‹è®­ç»ƒçš„å­åœºæ™¯ç”Ÿæˆæ›´å¥½çš„æ¸²æŸ“ç»“æœã€‚</li>
<li>åœ¨ç°æœ‰æ•°æ®é›†ä»¥åŠæˆ‘ä»¬è‡ªå·±çš„æ— äººæœºèˆªæ‹è§†é¢‘ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œåœ¨å•ä¸ª GPU ä¸Šå°†é‡å»ºé€Ÿåº¦æé«˜äº† 10 å€ï¼ˆç›¸å¯¹äºç»å…¸æ‘„å½±æµ‹é‡è½¯ä»¶ï¼‰å’Œ 50 å€ï¼ˆç›¸å¯¹äºæœ€å…ˆè¿›çš„å¤§è§„æ¨¡ NeRF è§£å†³æ–¹æ¡ˆï¼‰ï¼ŒåŒæ—¶æ¸²æŸ“è´¨é‡ç›¸ä¼¼ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šé¸Ÿç°ç¥ç»è¾å°„åœºï¼šä½¿ç”¨èˆªæ‹å›¾åƒå¿«é€Ÿç¥ç»é‡å»ºå¤§åœºæ™¯</li>
<li>ä½œè€…ï¼šå¼ æ…§æ¸…ã€è–›ä¸€é£ã€å»–æ˜ã€è€ä¸€çœŸ</li>
<li>å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å¤§è§„æ¨¡é‡å»ºã€èˆªæ‹å›¾åƒã€ç©ºé—´åˆ†è§£ã€æŠ•å½±å¼•å¯¼</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.04554
Githubï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šéšç€èˆªç©ºæµ‹é‡æŠ€æœ¯çš„è¿›æ­¥ï¼Œè·å–é«˜åˆ†è¾¨ç‡å›¾åƒå˜å¾—æ›´åŠ å®¹æ˜“å’Œç»æµå®æƒ ï¼ŒåŸºäºå›¾åƒçš„ 3D é‡å»ºå·²æˆä¸ºä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸï¼Œå¹¶åœ¨åŸå¸‚è§„åˆ’ã€å¯¼èˆªã€è™šæ‹Ÿæ—…æ¸¸ã€æˆ¿åœ°äº§å’Œç¾å®³ç®¡ç†ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚
(2)ï¼šç°æœ‰çš„åŸºäºå›¾åƒçš„ 3D é‡å»ºæŠ€æœ¯ä¸»è¦åˆ†ä¸ºä¼ ç»Ÿçš„åŸºäºå‡ ä½•çš„æ–¹æ³•å’ŒåŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ã€‚åŸºäºå‡ ä½•çš„æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„äººå·¥å¹²é¢„ï¼Œå¹¶ä¸”å¯¹å›¾åƒçš„è´¨é‡å’Œæ•°é‡éå¸¸æ•æ„Ÿã€‚åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼Œä¾‹å¦‚ç¥ç»è¾å°„åœº (NeRF)ï¼Œå¯ä»¥è‡ªåŠ¨ä»å›¾åƒä¸­å­¦ä¹ åœºæ™¯çš„ 3D è¡¨ç¤ºï¼Œå¹¶ä¸”å¯¹å›¾åƒçš„è´¨é‡å’Œæ•°é‡ä¸å¤ªæ•æ„Ÿã€‚ç„¶è€Œï¼ŒNeRF åœ¨å¤„ç†å¤§è§„æ¨¡åœºæ™¯æ—¶é¢ä¸´ç€è®­ç»ƒé€Ÿåº¦æ…¢ã€æ¸²æŸ“æ—¶é—´é•¿å’Œå®¹æ˜“äº§ç”Ÿä¼ªå½±ç­‰æŒ‘æˆ˜ã€‚
(3)ï¼šä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ NeRF å˜ä½“ï¼Œç§°ä¸ºé¸Ÿç°ç¥ç»è¾å°„åœº (BirdNeRF)ã€‚BirdNeRF ä½¿ç”¨äº†ä¸€ç§æ–°çš„ç©ºé—´åˆ†è§£ç®—æ³•ï¼Œå°†å¤§è§„æ¨¡èˆªæ‹å›¾åƒé›†åˆ†è§£æˆå¤šä¸ªè¾ƒå°çš„å­é›†ï¼Œå¹¶åˆ†åˆ«è®­ç»ƒæ¯ä¸ªå­é›†çš„ NeRF æ¨¡å‹ã€‚è¿™ç§åˆ†è§£æ–¹æ³•ä¸ä»…å¯ä»¥å‡å°‘è®­ç»ƒæ—¶é—´å’Œæ¸²æŸ“æ—¶é—´ï¼Œè¿˜å¯ä»¥æé«˜é‡å»ºçš„è´¨é‡ã€‚æ­¤å¤–ï¼ŒBirdNeRF è¿˜æå‡ºäº†ä¸€ç§æ–°çš„æŠ•å½±å¼•å¯¼çš„æ–°è§†å›¾é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨ç‹¬ç«‹è®­ç»ƒçš„å­åœºæ™¯æ¥ç”Ÿæˆé«˜è´¨é‡çš„æ¸²æŸ“ç»“æœã€‚
(4)ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒBirdNeRF åœ¨é‡å»ºé€Ÿåº¦å’Œè´¨é‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚åœ¨å•ä¸ª GPU ä¸Šï¼ŒBirdNeRF çš„é‡å»ºé€Ÿåº¦æ¯”ä¼ ç»Ÿçš„æ‘„å½±æµ‹é‡è½¯ä»¶å¿« 10 å€ï¼Œæ¯”æœ€å…ˆè¿›çš„å¤§è§„æ¨¡ NeRF è§£å†³æ–¹æ¡ˆå¿« 50 å€ï¼ŒåŒæ—¶å…·æœ‰ç›¸ä¼¼çš„æ¸²æŸ“è´¨é‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) å°†å¤§åœºæ™¯åˆ†è§£ä¸ºå¤šä¸ªè¾ƒå°çš„å­åœºæ™¯ï¼Œåˆ†åˆ«è®­ç»ƒæ¯ä¸ªå­åœºæ™¯çš„ NeRF æ¨¡å‹ã€‚
(2) ä½¿ç”¨ä¸€ç§æ–°çš„æŠ•å½±å¼•å¯¼çš„æ–°è§†å›¾é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨ç‹¬ç«‹è®­ç»ƒçš„å­åœºæ™¯æ¥ç”Ÿæˆé«˜è´¨é‡çš„æ¸²æŸ“ç»“æœã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„NeRFå˜ä½“ï¼Œç§°ä¸ºé¸Ÿç°ç¥ç»è¾å°„åœºï¼ˆBirdNeRFï¼‰ï¼Œå¯ä»¥å¿«é€Ÿé‡å»ºå¤§è§„æ¨¡åœºæ™¯ã€‚BirdNeRFä½¿ç”¨äº†ä¸€ç§æ–°çš„ç©ºé—´åˆ†è§£ç®—æ³•ï¼Œå°†å¤§è§„æ¨¡èˆªæ‹å›¾åƒé›†åˆ†è§£æˆå¤šä¸ªè¾ƒå°çš„å­é›†ï¼Œå¹¶åˆ†åˆ«è®­ç»ƒæ¯ä¸ªå­é›†çš„NeRFæ¨¡å‹ã€‚è¿™ç§åˆ†è§£æ–¹æ³•ä¸ä»…å¯ä»¥å‡å°‘è®­ç»ƒæ—¶é—´å’Œæ¸²æŸ“æ—¶é—´ï¼Œè¿˜å¯ä»¥æé«˜é‡å»ºçš„è´¨é‡ã€‚æ­¤å¤–ï¼ŒBirdNeRFè¿˜æå‡ºäº†ä¸€ç§æ–°çš„æŠ•å½±å¼•å¯¼çš„æ–°è§†å›¾é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨ç‹¬ç«‹è®­ç»ƒçš„å­åœºæ™¯æ¥ç”Ÿæˆé«˜è´¨é‡çš„æ¸²æŸ“ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„NeRFå˜ä½“ï¼Œç§°ä¸ºé¸Ÿç°ç¥ç»è¾å°„åœºï¼ˆBirdNeRFï¼‰ï¼Œå¯ä»¥å¿«é€Ÿé‡å»ºå¤§è§„æ¨¡åœºæ™¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç©ºé—´åˆ†è§£ç®—æ³•ï¼Œå°†å¤§è§„æ¨¡èˆªæ‹å›¾åƒé›†åˆ†è§£æˆå¤šä¸ªè¾ƒå°çš„å­é›†ï¼Œå¹¶åˆ†åˆ«è®­ç»ƒæ¯ä¸ªå­é›†çš„NeRFæ¨¡å‹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æŠ•å½±å¼•å¯¼çš„æ–°è§†å›¾é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨ç‹¬ç«‹è®­ç»ƒçš„å­åœºæ™¯æ¥ç”Ÿæˆé«˜è´¨é‡çš„æ¸²æŸ“ç»“æœã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
- åœ¨å•ä¸ªGPUä¸Šï¼ŒBirdNeRFçš„é‡å»ºé€Ÿåº¦æ¯”ä¼ ç»Ÿçš„æ‘„å½±æµ‹é‡è½¯ä»¶å¿«10å€ï¼Œæ¯”æœ€å…ˆè¿›çš„å¤§è§„æ¨¡NeRFè§£å†³æ–¹æ¡ˆå¿«50å€ï¼ŒåŒæ—¶å…·æœ‰ç›¸ä¼¼çš„æ¸²æŸ“è´¨é‡ã€‚
- BirdNeRFå¯ä»¥é‡å»ºåŒ…å«æ•°ç™¾ä¸‡ä¸ªä¸‰è§’å½¢çš„åœºæ™¯ï¼Œè€Œä¸ä¼šå‡ºç°æ˜æ˜¾çš„ä¼ªå½±ã€‚</p>
<p>å·¥ä½œé‡ï¼š
- BirdNeRFçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä½¿ç”¨ã€‚
- BirdNeRFçš„è®­ç»ƒæ—¶é—´å’Œæ¸²æŸ“æ—¶é—´éƒ½æ¯”è¾ƒçŸ­ï¼Œå¯ä»¥æ»¡è¶³å®é™…åº”ç”¨çš„éœ€æ±‚ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0ffe2746a28f7248c7dc45305ca5a0d8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d3e3e28cf5dd4b506a44e1769d5abf0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-51dea38443c497692956a6fd50ec6a18.jpg" align="middle">
</details>




## ViewFusion: Learning Composable Diffusion Models for Novel View   Synthesis

**Authors:Bernard Spiegl, Andrea Perin, StÃ©phane Deny, Alexander Ilin**

Deep learning is providing a wealth of new approaches to the old problem of novel view synthesis, from Neural Radiance Field (NeRF) based approaches to end-to-end style architectures. Each approach offers specific strengths but also comes with specific limitations in their applicability. This work introduces ViewFusion, a state-of-the-art end-to-end generative approach to novel view synthesis with unparalleled flexibility. ViewFusion consists in simultaneously applying a diffusion denoising step to any number of input views of a scene, then combining the noise gradients obtained for each view with an (inferred) pixel-weighting mask, ensuring that for each region of the target scene only the most informative input views are taken into account. Our approach resolves several limitations of previous approaches by (1) being trainable and generalizing across multiple scenes and object classes, (2) adaptively taking in a variable number of pose-free views at both train and test time, (3) generating plausible views even in severely undetermined conditions (thanks to its generative nature) -- all while generating views of quality on par or even better than state-of-the-art methods. Limitations include not generating a 3D embedding of the scene, resulting in a relatively slow inference speed, and our method only being tested on the relatively small dataset NMR. Code is available. 

[PDF](http://arxiv.org/abs/2402.02906v1) 

**Summary**
å°†å¤šä¸ªä¸åŒè§†è§’çš„å›¾åƒè¾“å…¥åˆ° ViewFusion æ¨¡å‹ä¸­ï¼Œå°±å¯ä»¥åŸºäºè¿™äº›å›¾åƒåˆæˆå‡ºæ–°çš„è§†è§’å›¾åƒã€‚


**Key Takeaways**

- ViewFusion å°†æ‰©æ•£å»å™ªæ­¥éª¤åŒæ—¶åº”ç”¨äºä»»æ„æ•°é‡çš„åœºæ™¯è¾“å…¥è§†å›¾ï¼Œç„¶åå°†æ¯ä¸ªè§†å›¾è·å¾—çš„å™ªå£°æ¢¯åº¦ä¸åƒç´ æƒé‡æ©ç ç›¸ç»“åˆï¼Œç¡®ä¿åœ¨ç›®æ ‡åœºæ™¯çš„æ¯ä¸ªåŒºåŸŸå†…ä»…è€ƒè™‘æœ€å…·ä¿¡æ¯æ€§çš„è¾“å…¥è§†å›¾ã€‚
- ViewFusion è§£å†³äº†å…ˆå‰æ–¹æ³•çš„å‡ ä¸ªå±€é™æ€§ï¼šè·¨å¤šä¸ªåœºæ™¯å’Œå¯¹è±¡ç±»åˆ«è¿›è¡Œè®­ç»ƒå’Œæ³›åŒ–ï¼›åœ¨è®­ç»ƒå’Œæµ‹è¯•æ—¶è‡ªé€‚åº”åœ°é‡‡ç”¨å¯å˜æ•°é‡çš„ä¸å—å§¿åŠ¿é™åˆ¶çš„è§†å›¾ï¼›èƒ½å¤Ÿç”Ÿæˆåˆç†çš„è§†å›¾ï¼Œå³ä½¿åœ¨ä¸¥é‡ä¸ç¡®å®šçš„æ¡ä»¶ä¸‹ã€‚
- ViewFusion ä¼˜äºæˆ–ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”èƒ½æ›´é«˜è´¨é‡åœ°ç”Ÿæˆè§†å›¾ã€‚
- ViewFusion æ— æ³•ç”Ÿæˆåœºæ™¯çš„ 3D åµŒå…¥ï¼Œå¯¼è‡´å…¶æ¨ç†é€Ÿåº¦ç›¸å¯¹è¾ƒæ…¢ã€‚
- ViewFusion ç›®å‰ä»…åœ¨ç›¸å¯¹è¾ƒå°çš„ NMR æ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ã€‚
- ä»£ç åº“ç°å·²å‘å¸ƒã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šViewFusionï¼šç”¨äºæ–°é¢–è§†å›¾åˆæˆçš„å¯ç»„åˆæ‰©æ•£æ¨¡å‹çš„å­¦ä¹ </li>
<li>ä½œè€…ï¼šBernard Spieglã€Andrea Perinã€StÂ´ephane Denyã€Alexander Ilin</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé˜¿å°”æ‰˜å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»ï¼ˆä»…ç¿»è¯‘ä¸­æ–‡ï¼‰</li>
<li>å…³é”®è¯ï¼šæ–°é¢–è§†å›¾åˆæˆã€æ‰©æ•£æ¨¡å‹ã€å¯ç»„åˆæ€§ã€è‡ªé€‚åº”è¾“å…¥è§†å›¾ã€é²æ£’æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.02906ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–°é¢–è§†å›¾åˆæˆæ˜¯ä¸€ä¸ªè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„é•¿æœŸç ”ç©¶è¯¾é¢˜ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä½¿ç”¨æ˜¾å¼å»ºæ¨¡ 3D ç©ºé—´çš„æ–¹æ³•ï¼Œå¦‚ä½“ç´ ã€ç‚¹äº‘æˆ–ç½‘æ ¼ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºç¥ç»è¾å°„åœº (NeRF) çš„æ–¹æ³•ä¹Ÿå–å¾—äº†å¾ˆå¤§è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å­˜åœ¨éœ€è¦æ˜‚è´µçš„é€åœºæ™¯é‡æ–°è®­ç»ƒã€æ— æ³•åœ¨æ²¡æœ‰è¾“å…¥è§†å›¾çš„å§¿æ€ä¿¡æ¯çš„æƒ…å†µä¸‹æ“ä½œæˆ–æ— æ³•é€‚åº”æµ‹è¯•æ—¶è¾“å…¥è§†å›¾æ•°é‡çš„å¯å˜æ€§ç­‰ç¼ºç‚¹ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸å­˜åœ¨éœ€è¦æ˜‚è´µçš„é€åœºæ™¯é‡æ–°è®­ç»ƒã€æ— æ³•åœ¨æ²¡æœ‰è¾“å…¥è§†å›¾çš„å§¿æ€ä¿¡æ¯çš„æƒ…å†µä¸‹æ“ä½œæˆ–æ— æ³•é€‚åº”æµ‹è¯•æ—¶è¾“å…¥è§†å›¾æ•°é‡çš„å¯å˜æ€§ç­‰ç¼ºç‚¹ã€‚å› æ­¤ï¼Œæœ¬æ–‡æ—¨åœ¨æå‡ºä¸€ç§ç›´è§‚çš„ç«¯åˆ°ç«¯æ¶æ„ï¼Œç”¨äºæ‰§è¡Œæ–°é¢–è§†å›¾åˆæˆï¼ŒåŒæ—¶è§£å†³å…ˆå‰å·¥ä½œä¸­æåˆ°çš„ç¼ºç‚¹ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºçš„ ViewFusion æ–¹æ³•é€šè¿‡ä¸€ç³»åˆ—é’ˆå¯¹ç‰¹å®šé—®é¢˜çš„è®¾è®¡é€‰æ‹©ï¼Œä¸€æ¬¡æ€§è§£å†³äº†ä¸Šè¿°ç¼ºç‚¹ã€‚é¦–å…ˆï¼Œä½¿ç”¨åœ¨å¤§é‡åœºæ™¯å’Œç±»åˆ«ä¸ŠåŒæ—¶è®­ç»ƒçš„æ‰©æ•£æ¦‚ç‡æ¡†æ¶ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æ— éœ€é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹è¿›è¡Œæ³›åŒ–ã€‚æ­¤å¤–ï¼Œç”±äºæ‰©æ•£è¿‡ç¨‹çš„éšæœºæ€§è´¨ï¼Œè¯¥æ¨¡å‹å³ä½¿åœ¨ä¸ç¡®å®šæ€§è®¾ç½®ï¼ˆä¾‹å¦‚ï¼Œå¯¹è±¡çš„ä¸¥é‡é®æŒ¡æˆ–æœ‰é™æ•°é‡çš„è¾“å…¥è§†å›¾ï¼‰ä¸­ä¹Ÿèƒ½è¡¨ç°è‰¯å¥½ï¼Œå› ä¸ºå®ƒæä¾›äº†å¤šç§åˆç†çš„è§†å›¾ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æå‡ºçš„è§£å†³æ–¹æ¡ˆä¸éœ€è¦è¾“å…¥è§†å›¾çš„é¡ºåºæˆ–ä»»ä½•æ˜¾å¼å§¿æ€ä¿¡æ¯ã€‚æœ€åï¼Œä¸ä¹‹å‰çš„å¯¹åº”æ–¹æ³•ä¸åŒï¼Œä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œæœ¬æ–‡çš„æ–¹æ³•å°±å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†ä»»æ„é•¿åº¦çš„è¾“å…¥ã€‚è¿™è¦å½’åŠŸäºä¸€ç§æ–°çš„åŠ æƒè§£å†³æ–¹æ¡ˆï¼Œä¸å»å™ªéª¨å¹²ç½‘ç»œçš„ç»„åˆä¸€èµ·ï¼Œè¯¥è§£å†³æ–¹æ¡ˆå…è®¸æ¨¡å‹æ ¹æ®è§†å›¾çš„ä¿¡æ¯é‡å¯¹è§†å›¾è¿›è¡ŒåŠ æƒï¼ŒåŒæ—¶æ‰©å±•åˆ°ä»»æ„æ•°é‡çš„è§†å›¾ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡åœ¨åŒ…å«å„ç§ç±»åˆ«å’Œè¾“å…¥è§†å›¾å§¿åŠ¿çš„æ•°æ®é›†ä¸Šè¯„ä¼°äº†æ‰€æå‡ºçš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡é€šè¿‡å¯¹ä¸­é—´æ¨¡å‹è¾“å‡ºçš„åˆ†æéªŒè¯äº†è¯¥æ–¹æ³•ï¼Œè¯æ˜äº†è¯¥æ¨¡å‹èƒ½å¤Ÿæ¨æ–­å’Œè‡ªé€‚åº”åœ°è°ƒæ•´æ¯ä¸ªè¾“å…¥è§†å›¾çš„é‡è¦æ€§ã€‚åŠ æƒä¸ä»…å¯¹è¾“å‡ºçš„è´¨é‡æœ‰å½±å“ï¼Œè€Œä¸”æ¨æ–­çš„åŠ æƒæ–¹æ¡ˆä¹Ÿä¸ç›´è§‚çš„äººç±»æ„ŸçŸ¥ä¸€è‡´ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¦‚ç‡æ¡†æ¶çš„æ–°é¢–è§†å›¾åˆæˆæ–¹æ³• ViewFusionï¼Œè¯¥æ–¹æ³•èƒ½å¤ŸåŒæ—¶å¤„ç†å¤šä¸ªè¾“å…¥è§†å›¾ï¼Œå¹¶æ ¹æ®æ¯ä¸ªè§†å›¾çš„é‡è¦æ€§å¯¹è§†å›¾è¿›è¡ŒåŠ æƒï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡çš„æ–°é¢–è§†å›¾ã€‚
(2) ViewFusion æ¨¡å‹ç”±å¤šä¸ª U-Net ç»„æˆï¼Œæ¯ä¸ª U-Net è´Ÿè´£å¤„ç†ä¸€ä¸ªè¾“å…¥è§†å›¾ã€‚U-Net çš„è¾“å‡ºåŒ…æ‹¬å™ªå£°é¢„æµ‹å’Œæƒé‡ï¼Œæƒé‡ç”¨äºå¯¹å™ªå£°è¿›è¡ŒåŠ æƒï¼Œä»è€Œç”Ÿæˆæœ€ç»ˆçš„æ–°é¢–è§†å›¾ã€‚
(3) ViewFusion æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šé¢„è®­ç»ƒå’Œå¾®è°ƒã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹åœ¨å¤§é‡åœºæ™¯å’Œç±»åˆ«ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥å­¦ä¹ ä¸€èˆ¬åŒ–çš„ç‰¹å¾è¡¨ç¤ºã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼Œæ¨¡å‹åœ¨ç‰¹å®šåœºæ™¯æˆ–ç±»åˆ«ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚
(4) ViewFusion æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šå™ªå£°é‡‡æ ·å’Œæ‰©æ•£è¿‡ç¨‹ã€‚åœ¨å™ªå£°é‡‡æ ·é˜¶æ®µï¼Œæ¨¡å‹ä»æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·å™ªå£°ã€‚åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹é€šè¿‡é€æ¸é™ä½å™ªå£°çš„å¼ºåº¦æ¥ç”Ÿæˆæ–°é¢–è§†å›¾ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šViewFusion æ˜¯ä¸€ç§çµæ´»ã€æ— éœ€å§¿æ€çš„ç”Ÿæˆæ–¹æ³•ï¼Œå¯ä½¿ç”¨å¯ç»„åˆæ‰©æ•£æ¨¡å‹æ‰§è¡Œæ–°é¢–è§†å›¾åˆæˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŠ æƒæ–¹æ¡ˆï¼Œç”¨äºç»„åˆæ‰©æ•£æ¨¡å‹ï¼Œç¡®ä¿ä»…å°†ä¿¡æ¯é‡æœ€å¤§çš„è¾“å…¥è§†å›¾ç”¨äºé¢„æµ‹ç›®æ ‡è§†å›¾ï¼Œå¹¶ä½¿ ViewFusion èƒ½å¤Ÿè‡ªé€‚åº”åœ°å¤„ç†ä»»æ„é•¿ä¸”æ— åºçš„è¾“å…¥è§†å›¾é›†åˆï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚æ­¤å¤–ï¼ŒViewFusion çš„ç”Ÿæˆæ€§è´¨ä½¿å…¶å³ä½¿åœ¨ä¸¥é‡æ¬ å®šæ¡ä»¶ä¸‹ä¹Ÿèƒ½ç”Ÿæˆåˆç†è§†å›¾ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¿›è¡Œæ–°é¢–è§†å›¾åˆæˆæ—¶æ˜¯ä¸€ä¸ªæœ‰ä»·å€¼çš„è´¡çŒ®ï¼Œå¹¶ä¸”æœ‰å¯èƒ½åº”ç”¨äºå…¶ä»–é—®é¢˜ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
ViewFusion å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åŠ æƒæ–¹æ¡ˆï¼Œç”¨äºç»„åˆæ‰©æ•£æ¨¡å‹ï¼Œç¡®ä¿ä»…å°†ä¿¡æ¯é‡æœ€å¤§çš„è¾“å…¥è§†å›¾ç”¨äºé¢„æµ‹ç›®æ ‡è§†å›¾ï¼Œå¹¶ä½¿ ViewFusion èƒ½å¤Ÿè‡ªé€‚åº”åœ°å¤„ç†ä»»æ„é•¿ä¸”æ— åºçš„è¾“å…¥è§†å›¾é›†åˆï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚æ­¤å¤–ï¼ŒViewFusion çš„ç”Ÿæˆæ€§è´¨ä½¿å…¶å³ä½¿åœ¨ä¸¥é‡æ¬ å®šæ¡ä»¶ä¸‹ä¹Ÿèƒ½ç”Ÿæˆåˆç†è§†å›¾ã€‚
æ€§èƒ½ï¼š
ViewFusion åœ¨å„ç§ç±»åˆ«å’Œè¾“å…¥è§†å›¾å§¿åŠ¿çš„æ•°æ®é›†ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒViewFusion èƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†ä»»æ„æ•°é‡çš„è¾“å…¥è§†å›¾ï¼Œå¹¶ä¸”å¯¹è¾“å…¥è§†å›¾çš„é¡ºåºå’Œå§¿æ€ä¿¡æ¯ä¸æ•æ„Ÿã€‚
å·¥ä½œé‡ï¼š
ViewFusion çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šé¢„è®­ç»ƒå’Œå¾®è°ƒã€‚é¢„è®­ç»ƒé˜¶æ®µéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œä½†å¾®è°ƒé˜¶æ®µå¯ä»¥ç›¸å¯¹å¿«é€Ÿåœ°å®Œæˆã€‚ViewFusion çš„æ¨ç†è¿‡ç¨‹ä¹Ÿéå¸¸æœ‰æ•ˆï¼Œå¯ä»¥åœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆæ–°é¢–è§†å›¾ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-672b204f9242001f6ba5e1b350c81c87.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ab2417ac343ade4b32aea1621299f294.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a35b2635715a736813769f26b2939948.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-512893851e477e6cab6fb9d3224f7acf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6fa2f794caefa6d02e53b7a03fc9f646.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f5e41e289131352d483b38fb05ca0ce8.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1874aa5e890d55cc56f18c742397f3bf.jpg" align="middle">
</details>




<h2 id="Robust-Inverse-Graphics-via-Probabilistic-Inference"><a href="#Robust-Inverse-Graphics-via-Probabilistic-Inference" class="headerlink" title="Robust Inverse Graphics via Probabilistic Inference"></a>Robust Inverse Graphics via Probabilistic Inference</h2><p><strong>Authors:Tuan Anh Le, Pavel Sountsov, Matthew D. Hoffman, Ben Lee, Brian Patton, Rif A. Saurous</strong></p>
<p>How do we infer a 3D scene from a single image in the presence of corruptions like rain, snow or fog? Straightforward domain randomization relies on knowing the family of corruptions ahead of time. Here, we propose a Bayesian approach-dubbed robust inverse graphics (RIG)-that relies on a strong scene prior and an uninformative uniform corruption prior, making it applicable to a wide range of corruptions. Given a single image, RIG performs posterior inference jointly over the scene and the corruption. We demonstrate this idea by training a neural radiance field (NeRF) scene prior and using a secondary NeRF to represent the corruptions over which we place an uninformative prior. RIG, trained only on clean data, outperforms depth estimators and alternative NeRF approaches that perform point estimation instead of full inference. The results hold for a number of scene prior architectures based on normalizing flows and diffusion models. For the latter, we develop reconstruction-guidance with auxiliary latents (ReGAL)-a diffusion conditioning algorithm that is applicable in the presence of auxiliary latent variables such as the corruption. RIG demonstrates how scene priors can be used beyond generation tasks. </p>
<p><a href="http://arxiv.org/abs/2402.01915v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–°é¢–çš„è´å¶æ–¯æ–¹æ³• RIG å¯åŒæ—¶å¯¹åœºæ™¯å’Œç ´åè¿›è¡Œæ¨ç†ï¼Œä»¥å…‹æœå„ç§åœºæ™¯æŸåã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>RIG æ˜¯ä¸€ç§æ–°çš„è´å¶æ–¯æ–¹æ³•ï¼Œå¯åŒæ—¶å¯¹åœºæ™¯å’Œç ´åè¿›è¡Œæ¨ç†ã€‚</li>
<li>RIG ä»…ä½¿ç”¨å¹²å‡€çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä¼˜äºæ·±åº¦ä¼°è®¡å™¨å’Œæ›¿ä»£çš„ NeRF æ–¹æ³•ã€‚</li>
<li>RIG å¯ä¸å¤šç§åŸºäºæ­£åˆ™åŒ–æµå’Œæ‰©æ•£æ¨¡å‹çš„åœºæ™¯å…ˆéªŒæ¶æ„ä¸€èµ·ä½¿ç”¨ã€‚</li>
<li>å¯¹äºåè€…ï¼Œæˆ‘ä»¬å¼€å‘äº†å…·æœ‰è¾…åŠ©æ½œå˜é‡çš„é‡å»ºæŒ‡å¯¼ï¼ˆReGALï¼‰â€”â€”ä¸€ç§æ‰©æ•£è°ƒèŠ‚ç®—æ³•ï¼Œé€‚ç”¨äºå…·æœ‰è¾…åŠ©æ½œå˜é‡ï¼ˆå¦‚ç ´åï¼‰çš„æƒ…å†µã€‚</li>
<li>RIG æ¼”ç¤ºäº†åœºæ™¯å…ˆéªŒå¦‚ä½•ç”¨äºç”Ÿæˆä»»åŠ¡ä¹‹å¤–ã€‚</li>
<li>RIG åˆ©ç”¨å¼ºå¤§çš„åœºæ™¯å…ˆéªŒå’Œæ— ä¿¡æ¯çš„å‡åŒ€ç ´åå…ˆéªŒï¼Œä½¿å…¶é€‚ç”¨äºå¹¿æ³›çš„ç ´åã€‚</li>
<li>åœ¨ç»™å®šå•ä¸€å›¾åƒçš„æƒ…å†µä¸‹ï¼ŒRIG å¯¹åœºæ™¯å’Œç ´åè¿›è¡ŒåéªŒæ¨ç†ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šé²æ£’é€†å‘å›¾å½¢ç”Ÿæˆï¼šåŸºäºæ¦‚ç‡æ¨ç†</li>
<li>ä½œè€…ï¼šTuan Anh Leã€Pavel Sountsovã€Matthew D. Hoffmanã€Ben Leeã€Brian Pattonã€Rif A. Saurous</li>
<li>å•ä½ï¼šè°·æ­Œï¼ˆGoogleï¼‰</li>
<li>å…³é”®è¯ï¼šé²æ£’é€†å‘å›¾å½¢ç”Ÿæˆã€ç¥ç»è¾å°„åœºã€æ¦‚ç‡æ¨ç†ã€åŸŸéšæœºåŒ–ã€æ•°æ®å¢å¼º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.01915</li>
<li>æ‘˜è¦ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
    * åœ¨å­˜åœ¨é›¨ã€é›ªã€é›¾ç­‰å¹²æ‰°çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•ä»å•å¼ å›¾åƒä¸­æ¨æ–­å‡º 3D åœºæ™¯ï¼Ÿ
    * ç›´æ¥çš„åŸŸéšæœºåŒ–ä¾èµ–äºæå‰çŸ¥é“å¹²æ‰°çš„ç§ç±»ã€‚</p>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
    * åŸŸéšæœºåŒ–ï¼šé€šè¿‡åœ¨æ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­é€‰æ‹©ä¸€ç³»åˆ—å¹²æ‰°æ¥å®ç°é²æ£’æ€§ï¼Œä½†è¿™ç§æ–¹æ³•éœ€è¦æå‰çŸ¥é“å¹²æ‰°çš„ç§ç±»ã€‚
    * æ­£åˆ™åŒ–è®­ç»ƒï¼šé€šè¿‡åœ¨é‡å»ºæŸå¤±ä¸­æ·»åŠ é¢å¤–çš„æŸå¤±é¡¹æ¥å®ç°é²æ£’æ€§ï¼Œä½†è¿™ç§æ–¹æ³•éš¾ä»¥æ‰©å±•åˆ°æ›´æç«¯çš„æƒ…å†µã€‚</p>
<p>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
    * é²æ£’é€†å‘å›¾å½¢ç”Ÿæˆï¼ˆRIGï¼‰ï¼šå°†é—®é¢˜è§†ä¸ºæ¦‚ç‡æ¨ç†é—®é¢˜ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„åœºæ™¯å…ˆéªŒï¼ˆåœ¨æœ¬ä¾‹ä¸­æ˜¯ç¥ç»è¾å°„åœºå…ˆéªŒï¼‰å’Œä¸€ä¸ªå…³äºå¹²æ‰°çš„å¼±å…ˆéªŒï¼ˆåœ¨æœ¬ä¾‹ä¸­æ˜¯å…·æœ‰å‡åŒ€å…ˆéªŒæƒé‡çš„å¦ä¸€ä¸ªç¥ç»è¾å°„åœºï¼‰æ¥è¿›è¡Œæ¨ç†ã€‚
    * RIG åœ¨åœºæ™¯å’Œå¹²æ‰°ç¥ç»è¾å°„åœºä¸­æ‰§è¡Œå®Œæ•´çš„æ¦‚ç‡æ¨ç†ï¼Œè€Œä¸æ˜¯åƒæœ€å¤§åéªŒæ¦‚ç‡æ¨ç†é‚£æ ·å¯»æ‰¾æœ€å¯èƒ½çš„è§£ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•çš„æ€§èƒ½è¡¨ç°ï¼š
    * RIG åœ¨å…·æœ‰å„ç§åœºæ™¯å…ˆéªŒæ¶æ„ï¼ˆåŸºäºæ­£åˆ™åŒ–æµå’Œæ‰©æ•£æ¨¡å‹ï¼‰çš„æƒ…å†µä¸‹éƒ½ä¼˜äºæ·±åº¦ä¼°è®¡å™¨å’Œæ‰§è¡Œç‚¹ä¼°è®¡è€Œä¸æ˜¯å®Œæ•´æ¨ç†çš„æ›¿ä»£ç¥ç»è¾å°„åœºæ–¹æ³•ã€‚
    * RIG ä»…åœ¨å¹²å‡€æ•°æ®ä¸Šè®­ç»ƒï¼Œä½†å®ƒåœ¨å…·æœ‰å„ç§å¹²æ‰°ï¼ˆé›¨ã€é›ªã€é›¾ã€å™ªå£°ï¼‰çš„å›¾åƒä¸Šéƒ½ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰åœºæ™¯è¡¨ç¤ºï¼šæˆ‘ä»¬ä½¿ç”¨ç¥ç»è¾å°„åœº (NeRF) è¡¨ç¤ºï¼Œå› ä¸ºå®ƒæ˜“äºè¿›è¡ŒåŸºäºæ¢¯åº¦çš„æ¨ç†ã€‚
ï¼ˆ2ï¼‰åœºæ™¯å…ˆéªŒï¼šæˆ‘ä»¬å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªé¢„è®­ç»ƒçš„ NeRF å…ˆéªŒ p(x)ï¼Œæˆ‘ä»¬å¯ä»¥ä»ä¸­å¯¹åœºæ™¯æ½œåœ¨å˜é‡ x è¿›è¡Œé‡‡æ ·ï¼Œå¹¶ä»ä¸åŒçš„è§†ç‚¹ Î¶ æ¸²æŸ“å›¾åƒ yã€‚
ï¼ˆ3ï¼‰æŸåè¡¨ç¤ºå’Œå…ˆéªŒï¼šæˆ‘ä»¬å…³æ³¨çš„æ˜¯å¯¹ 3D åœºæ™¯çš„æŸåï¼Œä¾‹å¦‚æ¼‚æµ®ç‰©æˆ–å¤©æ°”ä¼ªå½±ï¼ˆå¦‚é›¨ã€é›ªæˆ–é›¾ï¼‰ï¼Œå°½ç®¡æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥æ³›åŒ–åˆ°ä¼ æ„Ÿå™¨æŸåï¼Œå¦‚ç›¸æœºå†…éƒ¨å™ªå£°ï¼ˆç¬¬ 6.1 èŠ‚ï¼‰ã€‚æˆ‘ä»¬å°† 3D æŸåè¡¨ç¤ºä¸ºå¦ä¸€ä¸ª NeRF çš„å‚æ•°ã€‚ä¸åœºæ™¯ x ä¸åŒï¼Œæˆ‘ä»¬ä¸éœ€è¦å¯¹ c æœ‰ä¸€ä¸ªå¼ºå…ˆéªŒã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å‡è®¾ä¸€ä¸ªä¸é€‚å½“çš„å…ˆéªŒ p(c)âˆ1ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬ä¸éœ€è¦é¢„å…ˆçŸ¥é“æŸåçš„ç§ç±»ï¼›æŸåå¯ä»¥æ˜¯ä»»ä½• 3D å®ä½“ï¼Œä»å¤©æ°”ä¼ªå½±å’Œæ¼‚æµ®ç‰©åˆ°ä¸éœ€è¦çš„å¯¹è±¡ã€‚
ï¼ˆ4ï¼‰ä¼¼ç„¶ï¼šä¸ºäº†ç»™å®šåœºæ™¯æ½œåœ¨å˜é‡ x å’ŒæŸå c æ¸²æŸ“å›¾åƒ yï¼Œæˆ‘ä»¬ç»„åˆå„è‡ªçš„ NeRF è¾“å‡ºã€‚å¯¹äºå…‰çº¿ä½ç½®å’Œæ–¹å‘ (xr, dr)ï¼Œæˆ‘ä»¬å°†åœºæ™¯ NeRF (Î³z, Ïƒz) å’ŒæŸå NeRF (Î³c, Ïƒc) çš„è¾“å‡ºç»„åˆä¸º Ïƒ = Ïƒz + Ïƒcï¼ŒÎ³ = (Î³zÏƒz + Î³cÏƒc)/Ïƒï¼ˆNiemeyer &amp; Geigerï¼Œ2021ï¼‰ã€‚æˆ‘ä»¬å°†ç»„åˆçš„ NeRF çš„æ¸²æŸ“è¡¨ç¤ºä¸º y = R(x, c)ã€‚ä¼¼ç„¶æ˜¯ä¸€ä¸ªé€åƒç´ å’Œé€é€šé“çš„é«˜æ–¯åˆ†å¸ƒ p(y|x, c) = âˆåƒç´ å’Œé€šé“j N(yij|R(x, c)ij, Ïƒ2y)ï¼Œå…¶ä¸­ Ïƒ2y æ˜¯è§‚æµ‹å™ªå£°æ–¹å·®ã€‚
ï¼ˆ5ï¼‰MAP æ¨ç†ä¸å¤Ÿï¼šæ¨æ–­åœºæ™¯ x çš„ä¸€ç§ç›´æ¥æ–¹æ³•æ˜¯æ‰¾åˆ°æœ€å¤§åŒ– p(x)p(c)p(y|x, c) çš„ MAP ä¼°è®¡ (x<em>, c</em>)ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•ä¼šå¯¼è‡´â€œå¹¿å‘Šç‰Œâ€è§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­æŸåæœ€ç»ˆè§£é‡Šäº†åœºæ™¯ï¼Œå°±åƒä¸€ä¸ªæ”¾ç½®åœ¨ç›¸æœºå‰é¢çš„å¹¿å‘Šç‰Œã€‚
ï¼ˆ6ï¼‰å®Œå…¨åéªŒæ¨ç†å°±è¶³å¤Ÿäº†ï¼šåœ¨ RIG ä¸­ï¼Œæˆ‘ä»¬æ‰§è¡Œå®Œå…¨åéªŒæ¨ç†ä»¥è·å¾—æ½œåœ¨åœºæ™¯ x, câˆ¼p(x, c|y) âˆ p(x)p(c)p(y|x, c)ï¼Œè¿™åœ¨ç»éªŒä¸Šå¯ä»¥é¿å…å¹¿å‘Šç‰Œè§£å†³æ–¹æ¡ˆï¼ˆç¬¬ 6.1 èŠ‚ï¼‰ã€‚ç›´è§‚åœ°è¯´ï¼Œè¿™å¯ä»¥çœ‹ä½œæ˜¯æ¨¡å¼ä¸å…¸å‹é›†ä¸åŒçš„ä¸€ä¸ªå®ä¾‹ã€‚æŸåå®Œå…¨è¦†ç›–åœºæ™¯çš„æ¨¡å¼å‘¨å›´åŒºåŸŸå…·æœ‰é«˜å¯†åº¦ä½†ä½ä½“ç§¯â€”â€”æ²¡æœ‰è®¸å¤šæŸåå¯ä»¥ç²¾ç¡®åœ°æ¸²æŸ“åˆ°è§‚æµ‹å›¾åƒã€‚å¦ä¸€æ–¹é¢ï¼ŒåéªŒåŒæ—¶è€ƒè™‘å¯†åº¦å’Œä½“ç§¯ï¼Œé›†ä¸­åœ¨å…·æœ‰é«˜æ¦‚ç‡è´¨é‡çš„åŒºåŸŸâ€”â€”æœ‰è®¸å¤šéå¹¿å‘Šç‰ŒæŸåä¸æ­£ç¡®çš„åœºæ™¯ä¸€èµ·æ¸²æŸ“åˆ°è§‚æµ‹å›¾åƒï¼Œå°½ç®¡æ¯ä¸ªè¿™æ ·çš„è§£å†³æ–¹æ¡ˆå¯èƒ½å…·æœ‰ä½å¯†åº¦ã€‚
ï¼ˆ7ï¼‰å˜åˆ†æ¨ç†ï¼šæˆ‘ä»¬ä½¿ç”¨å˜åˆ†æ¨ç†ï¼Œå…¶ä¸­æˆ‘ä»¬ä¼˜åŒ–è¯æ®ä¸‹ç•Œ (ELBO) å…³äºå¼•å¯¼åˆ†å¸ƒ q(x, c)ï¼šELBO(q) = Eq(x, c)[logp(y, x|c) - logq(x, c)]ã€‚
ï¼ˆ8ï¼‰æ‰©æ•£åœºæ™¯å…ˆéªŒï¼šå»å™ªæ‰©æ•£å·²æˆä¸ºæ­£åˆ™åŒ–æµçš„æœ‰åŠ›æ›¿ä»£æ–¹æ¡ˆã€‚è™½ç„¶å¯ä»¥ç›´æ¥ç”¨åŸºäºæ‰©æ•£çš„å…ˆéªŒæ›¿æ¢ ProbNeRF ä¸­ä½¿ç”¨çš„ RealNVPï¼ˆä¾‹å¦‚ Dupontet al.ï¼Œ2022ï¼‰ï¼Œä½†æ‰©æ•£æ¨¡å‹å…è®¸æˆ‘ä»¬å¯è¿½è¸ªåœ°å¢åŠ æˆ‘ä»¬çš„æ½œåœ¨è¡¨ç¤ºçš„ç»´æ•°ã€‚é«˜ç»´æ½œåœ¨ç©ºé—´èƒ½å¤Ÿè¿›è¡Œé«˜ä¿çœŸé‡‡æ ·å’Œé‡å»ºã€‚æˆ‘ä»¬æ„å»ºäº†å•çº§æ‰©æ•£ NeRF (SSDNeRF) æ¡†æ¶ï¼ˆChen et al.ï¼Œ2023ï¼‰æ¥è®­ç»ƒåœºæ™¯å…ˆéªŒã€‚SSDNeRF ä¼˜åŒ–äº†ä¸€ç»„é’ˆå¯¹æ¯ä¸ªè®­ç»ƒç¤ºä¾‹çš„æ½œåœ¨å˜é‡ {xn}ï¼Œä¹Ÿç§°ä¸º GLO æ½œåœ¨å˜é‡ï¼ˆBojanowski et al.ï¼Œ2018ï¼‰ï¼Œç”± Ï• å‚æ•°åŒ–çš„æ‰©æ•£å…ˆéªŒ pÏ•(x) å’Œç”± Ïˆ å‚æ•°åŒ–çš„ä¼¼ç„¶ pÏˆ(y|x)ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§é™„å½• Dã€‚
ï¼ˆ9ï¼‰æ‰©æ•£æ¨¡å‹ï¼šæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ä¸ªæ½œåœ¨å˜é‡ç”Ÿæˆæ¨¡å‹ï¼ŒåŒ…å«æ­£å‘å’Œåå‘è¿‡ç¨‹ã€‚æ­£å‘æ‰©æ•£è¿‡ç¨‹ q(z|x) ä»æ•°æ® x å¼€å§‹ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1)ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§é²æ£’é€†å‘å›¾å½¢ç”Ÿæˆï¼ˆRIGï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†é—®é¢˜è§†ä¸ºæ¦‚ç‡æ¨ç†é—®é¢˜ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„åœºæ™¯å…ˆéªŒå’Œä¸€ä¸ªå…³äºå¹²æ‰°çš„å¼±å…ˆéªŒæ¥è¿›è¡Œæ¨ç†ã€‚RIGåœ¨å„ç§åœºæ™¯å…ˆéªŒæ¶æ„ä¸‹éƒ½ä¼˜äºæ·±åº¦ä¼°è®¡å™¨å’Œæ‰§è¡Œç‚¹ä¼°è®¡è€Œä¸æ˜¯å®Œæ•´æ¨ç†çš„æ›¿ä»£ç¥ç»è¾å°„åœºæ–¹æ³•ã€‚RIGä»…åœ¨å¹²å‡€æ•°æ®ä¸Šè®­ç»ƒï¼Œä½†å®ƒåœ¨å…·æœ‰å„ç§å¹²æ‰°ï¼ˆé›¨ã€é›ªã€é›¾ã€å™ªå£°ï¼‰çš„å›¾åƒä¸Šéƒ½ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚
(2)ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å°†é€†å‘å›¾å½¢ç”Ÿæˆé—®é¢˜è§†ä¸ºæ¦‚ç‡æ¨ç†é—®é¢˜ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„åœºæ™¯å…ˆéªŒå’Œä¸€ä¸ªå…³äºå¹²æ‰°çš„å¼±å…ˆéªŒæ¥è¿›è¡Œæ¨ç†ã€‚</li>
<li>æå‡ºäº†ä¸€ç§é²æ£’é€†å‘å›¾å½¢ç”Ÿæˆï¼ˆRIGï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å„ç§åœºæ™¯å…ˆéªŒæ¶æ„ä¸‹éƒ½ä¼˜äºæ·±åº¦ä¼°è®¡å™¨å’Œæ‰§è¡Œç‚¹ä¼°è®¡è€Œä¸æ˜¯å®Œæ•´æ¨ç†çš„æ›¿ä»£ç¥ç»è¾å°„åœºæ–¹æ³•ã€‚</li>
<li>RIGä»…åœ¨å¹²å‡€æ•°æ®ä¸Šè®­ç»ƒï¼Œä½†å®ƒåœ¨å…·æœ‰å„ç§å¹²æ‰°ï¼ˆé›¨ã€é›ªã€é›¾ã€å™ªå£°ï¼‰çš„å›¾åƒä¸Šéƒ½ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚
æ€§èƒ½ï¼š</li>
<li>RIGåœ¨å„ç§åœºæ™¯å…ˆéªŒæ¶æ„ä¸‹éƒ½ä¼˜äºæ·±åº¦ä¼°è®¡å™¨å’Œæ‰§è¡Œç‚¹ä¼°è®¡è€Œä¸æ˜¯å®Œæ•´æ¨ç†çš„æ›¿ä»£ç¥ç»è¾å°„åœºæ–¹æ³•ã€‚</li>
<li>RIGä»…åœ¨å¹²å‡€æ•°æ®ä¸Šè®­ç»ƒï¼Œä½†å®ƒåœ¨å…·æœ‰å„ç§å¹²æ‰°ï¼ˆé›¨ã€é›ªã€é›¾ã€å™ªå£°ï¼‰çš„å›¾åƒä¸Šéƒ½ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>RIGéœ€è¦é¢„è®­ç»ƒä¸€ä¸ªåœºæ™¯å…ˆéªŒå’Œä¸€ä¸ªå…³äºå¹²æ‰°çš„å¼±å…ˆéªŒã€‚</li>
<li>RIGéœ€è¦æ‰§è¡Œå®Œæ•´çš„æ¦‚ç‡æ¨ç†ï¼Œè¿™æ¯”æ‰§è¡Œç‚¹ä¼°è®¡æˆ–æœ€å¤§åéªŒæ¦‚ç‡æ¨ç†æ›´è€—æ—¶ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-25f26b8c4a059fad96179f9402d4ddf8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b464c110b8bfcce608856052d9518e4b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1f7396fa7b1ad32dc9c645595746950b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8c6960210c2e3765f8601fd7fb69b4ba.jpg" align="middle">
</details>




<h2 id="HyperPlanes-Hypernetwork-Approach-to-Rapid-NeRF-Adaptation"><a href="#HyperPlanes-Hypernetwork-Approach-to-Rapid-NeRF-Adaptation" class="headerlink" title="HyperPlanes: Hypernetwork Approach to Rapid NeRF Adaptation"></a>HyperPlanes: Hypernetwork Approach to Rapid NeRF Adaptation</h2><p><strong>Authors:PaweÅ‚ Batorski, Dawid Malarz, Marcin PrzewiÄ™Åºlikowski, Marcin Mazur, SÅ‚awomir Tadeja, PrzemysÅ‚aw Spurek</strong></p>
<p>Neural radiance fields (NeRFs) are a widely accepted standard for synthesizing new 3D object views from a small number of base images. However, NeRFs have limited generalization properties, which means that we need to use significant computational resources to train individual architectures for each item we want to represent. To address this issue, we propose a few-shot learning approach based on the hypernetwork paradigm that does not require gradient optimization during inference. The hypernetwork gathers information from the training data and generates an update for universal weights. As a result, we have developed an efficient method for generating a high-quality 3D object representation from a small number of images in a single step. This has been confirmed by direct comparison with the state-of-the-art solutions and a comprehensive ablation study. </p>
<p><a href="http://arxiv.org/abs/2402.01524v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºæ–¹æ³•å¯¹äºå°‘æ•°åŸºç¡€å›¾åƒåˆæˆæ–°å¥‡3Dç‰©ä½“è§†å›¾æœ‰ç€å¹¿æ³›çš„è®¤å¯ï¼Œå´å­˜åœ¨æ³›åŒ–æ€§è´¨æœ‰é™çš„é—®é¢˜ï¼Œä¸å¦¨ç¢æˆ‘ä»¬åˆ©ç”¨æ˜¾è‘—è®¡ç®—èµ„æºä¸ºæˆ‘ä»¬è¦å±•ç¤ºçš„æ¯ä¸ªå¯¹è±¡è®­ç»ƒç‹¬ç«‹ä½“ç³»ç»“æ„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¥ç»è¾å°„åœºæ–¹æ³•æ˜¯ä¸€ç§ç”¨äºä»å°‘æ•°åŸºç¡€å›¾åƒåˆæˆæ–° 3D ç‰©ä½“è§†å›¾çš„æ ‡å‡†æ–¹æ³•ã€‚</li>
<li>è¿™ç§æ–¹æ³•å­˜åœ¨æ³›åŒ–æ€§è´¨æœ‰é™çš„å¼Šç«¯ï¼Œå¯¼è‡´ä¸ºæˆ‘ä»¬è¦å±•ç¤ºçš„æ¯ä¸ªå¯¹è±¡è®­ç»ƒç‹¬ç«‹ä½“ç³»ç»“æ„æ—¶éœ€è¦æ˜¾è‘—çš„è®¡ç®—èµ„æºã€‚</li>
<li>ä½œè€…é’ˆå¯¹æ­¤é—®é¢˜æå‡ºäº†ä¸€ä¸ªåŸºäºè¶…ç½‘ç»œèŒƒå¼çš„ few-shot å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ— éœ€æ¢¯åº¦ä¼˜åŒ–ã€‚</li>
<li>è¶…ç½‘ç»œä»è®­ç»ƒæ•°æ®ä¸­æ”¶é›†ä¿¡æ¯ï¼Œå¹¶ä¸ºé€šç”¨æƒé‡ç”Ÿæˆæ›´æ–°ã€‚</li>
<li>ä¸Šè¿°æ–¹å¼æ‰“é€ äº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»å°‘é‡å›¾åƒä¸­ç”Ÿæˆé«˜è´¨é‡çš„ 3D å¯¹è±¡è¡¨ç¤ºï¼Œåªéœ€ä¸€ä¸ªæ­¥éª¤å³å¯å®Œæˆã€‚</li>
<li>æˆ‘ä»¬å·²é€šè¿‡ç›´æ¥æ¯”è¾ƒæœ€å…ˆè¿›çš„è§£å†³æ–¹æ¡ˆå’Œå…¨é¢çš„æ¶ˆèç ”ç©¶æ¥è¯å®è¿™ä¸€ç‚¹ã€‚</li>
<li>è¯¥æ–¹æ³•å·²è¢«ç›´æ¥æ¯”è¾ƒæœ€å…ˆè¿›çš„è§£å†³æ–¹æ¡ˆå’Œå…¨é¢çš„æ¶ˆèç ”ç©¶è¯å®ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šHyperPlanesï¼šå¿«é€Ÿ NeRF é€‚åº”çš„è¶…ç½‘ç»œæ–¹æ³•</li>
<li>ä½œè€…ï¼šPaweÅ‚ Batorski<em>, Dawid Malarz</em>, Marcin PrzewiË›eÂ´zlikowski, Marcin Mazur, Slawomir Tadeja, PrzemysÅ‚aw Spurek</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé›…ç›–éš†å¤§å­¦ï¼Œæ•°å­¦ä¸è®¡ç®—æœºç§‘å­¦å­¦é™¢ï¼Œå…‹æ‹‰ç§‘å¤«ï¼Œæ³¢å…°</li>
<li>å…³é”®è¯ï¼šNeRFï¼ŒFew-Shot å­¦ä¹ ï¼Œè¶…ç½‘ç»œï¼Œå¿«é€Ÿé€‚åº”</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.01524
Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šNeRF æ˜¯ä¸€ç§å¯ä»¥ä»å°‘é‡åŸºæœ¬å›¾åƒåˆæˆæ–°çš„é€¼çœŸ 3D å¯¹è±¡è§†å›¾çš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œä½†å®ƒç¼ºä¹æ³›åŒ–æ€§ï¼Œéœ€è¦é’ˆå¯¹æ¯ä¸ªå¯¹è±¡è®­ç»ƒå•ç‹¬çš„æ¶æ„ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œè®­ç»ƒæ—¶é—´ï¼Œå¹¶ä¸”æ³›åŒ–æ€§èƒ½æœ‰é™ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¶…ç½‘ç»œèŒƒå¼çš„ few-shot å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦åœ¨æ¨ç†æœŸé—´è¿›è¡Œæ¢¯åº¦ä¼˜åŒ–ã€‚è¶…ç½‘ç»œä»è®­ç»ƒæ•°æ®ä¸­æ”¶é›†ä¿¡æ¯å¹¶ç”Ÿæˆå¯¹é€šç”¨æƒé‡çš„æ›´æ–°ã€‚
ï¼ˆ4ï¼‰ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥åœ¨å•ä¸ªæ­¥éª¤ä¸­ä»å°‘é‡å›¾åƒç”Ÿæˆé«˜è´¨é‡çš„ 3D å¯¹è±¡è¡¨ç¤ºï¼Œå¹¶ä¸”åœ¨é€Ÿåº¦å’Œè´¨é‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¶…ç½‘ç»œèŒƒå¼çš„few-shotå­¦ä¹ æ–¹æ³•HyperPlanesï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦åœ¨æ¨ç†æœŸé—´è¿›è¡Œæ¢¯åº¦ä¼˜åŒ–ï¼Œå¯ä»¥åœ¨å•ä¸ªæ­¥éª¤ä¸­ä»å°‘é‡å›¾åƒç”Ÿæˆé«˜è´¨é‡çš„3Då¯¹è±¡è¡¨ç¤ºï¼Œå¹¶ä¸”åœ¨é€Ÿåº¦å’Œè´¨é‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºè¶…ç½‘ç»œèŒƒå¼çš„few-shotå­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦åœ¨æ¨ç†æœŸé—´è¿›è¡Œæ¢¯åº¦ä¼˜åŒ–ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥ä»è®­ç»ƒæ•°æ®ä¸­æ”¶é›†ä¿¡æ¯å¹¶ç”Ÿæˆå¯¹é€šç”¨æƒé‡çš„æ›´æ–°ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥åœ¨å•ä¸ªæ­¥éª¤ä¸­ä»å°‘é‡å›¾åƒç”Ÿæˆé«˜è´¨é‡çš„3Då¯¹è±¡è¡¨ç¤ºã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ–¹æ³•åœ¨é€Ÿåº¦å’Œè´¨é‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥åœ¨å•ä¸ªæ­¥éª¤ä¸­ä»å°‘é‡å›¾åƒç”Ÿæˆé«˜è´¨é‡çš„3Då¯¹è±¡è¡¨ç¤ºã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•ä¸éœ€è¦åœ¨æ¨ç†æœŸé—´è¿›è¡Œæ¢¯åº¦ä¼˜åŒ–ï¼Œå› æ­¤å¯ä»¥å‡å°‘è®¡ç®—èµ„æºå’Œè®­ç»ƒæ—¶é—´ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥ä»è®­ç»ƒæ•°æ®ä¸­æ”¶é›†ä¿¡æ¯å¹¶ç”Ÿæˆå¯¹é€šç”¨æƒé‡çš„æ›´æ–°ï¼Œå› æ­¤å¯ä»¥å‡å°‘è®­ç»ƒæ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d17d9bcf9aa679caea1d14977ee1030c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-309779f6bf52d8d8cfebf258af239717.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-639e9fd34cf9c9e63acc4cb78afac975.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-299ffc14425343bcd3a07c8f9122813c.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>Talking Head Generation</title>
    <url>/2024/02/09/Paper/2024-02-09/Talking%20Head%20Generation/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-09-æ›´æ–°"><a href="#2024-02-09-æ›´æ–°" class="headerlink" title="2024-02-09 æ›´æ–°"></a>2024-02-09 æ›´æ–°</h1><h2 id="EmoSpeaker-One-shot-Fine-grained-Emotion-Controlled-Talking-Face-Generation"><a href="#EmoSpeaker-One-shot-Fine-grained-Emotion-Controlled-Talking-Face-Generation" class="headerlink" title="EmoSpeaker: One-shot Fine-grained Emotion-Controlled Talking Face   Generation"></a>EmoSpeaker: One-shot Fine-grained Emotion-Controlled Talking Face   Generation</h2><p><strong>Authors:Guanwen Feng, Haoran Cheng, Yunan Li, Zhiyuan Ma, Chaoneng Li, Zhihao Qian, Qiguang Miao, Chi-Man Pun</strong></p>
<p>Implementing fine-grained emotion control is crucial for emotion generation tasks because it enhances the expressive capability of the generative model, allowing it to accurately and comprehensively capture and express various nuanced emotional states, thereby improving the emotional quality and personalization of generated content. Generating fine-grained facial animations that accurately portray emotional expressions using only a portrait and an audio recording presents a challenge. In order to address this challenge, we propose a visual attribute-guided audio decoupler. This enables the obtention of content vectors solely related to the audio content, enhancing the stability of subsequent lip movement coefficient predictions. To achieve more precise emotional expression, we introduce a fine-grained emotion coefficient prediction module. Additionally, we propose an emotion intensity control method using a fine-grained emotion matrix. Through these, effective control over emotional expression in the generated videos and finer classification of emotion intensity are accomplished. Subsequently, a series of 3DMM coefficient generation networks are designed to predict 3D coefficients, followed by the utilization of a rendering network to generate the final video. Our experimental results demonstrate that our proposed method, EmoSpeaker, outperforms existing emotional talking face generation methods in terms of expression variation and lip synchronization. Project page: <a href="https://peterfanfan.github.io/EmoSpeaker/">https://peterfanfan.github.io/EmoSpeaker/</a> </p>
<p><a href="http://arxiv.org/abs/2402.01422v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨è§†è§‰å±æ€§å¼•å¯¼éŸ³é¢‘è§£è€¦å™¨å’Œç»†ç²’åº¦æƒ…ç»ªç³»æ•°é¢„æµ‹æ¨¡å—ï¼Œç²¾ç»†æ§åˆ¶è°ˆè¯å¤´ç”Ÿæˆä¸­çš„æƒ…ç»ªè¡¨è¾¾ï¼Œæå‡ç”Ÿæˆçš„è§†é¢‘çš„è‡ªç„¶æ€§å’ŒçœŸå®æ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºè§†è§‰å±æ€§å¼•å¯¼éŸ³é¢‘è§£è€¦å™¨ï¼Œä»…ä¸éŸ³é¢‘å†…å®¹ç›¸å…³çš„è¡¨å¾å‘é‡ï¼Œå¢å¼ºåç»­å£å‹ç³»æ•°é¢„æµ‹çš„ç¨³å®šæ€§ã€‚</li>
<li>å¼•å…¥ç»†ç²’åº¦æƒ…ç»ªç³»æ•°é¢„æµ‹æ¨¡å—ï¼Œå®ç°æ›´å‡†ç¡®çš„æƒ…ç»ªè¡¨è¾¾ã€‚</li>
<li>æå‡ºä½¿ç”¨ç»†ç²’åº¦æƒ…ç»ªçŸ©é˜µçš„æƒ…ç»ªå¼ºåº¦æ§åˆ¶æ–¹æ³•ï¼Œå¯¹ç”Ÿæˆçš„è§†é¢‘ä¸­çš„æƒ…ç»ªè¡¨è¾¾è¿›è¡Œæœ‰æ•ˆæ§åˆ¶ï¼Œå¹¶å¯¹æƒ…ç»ªå¼ºåº¦è¿›è¡Œæ›´ç²¾ç»†çš„åˆ†ç±»ã€‚</li>
<li>3DMM ç³»æ•°ç”Ÿæˆç½‘ç»œç”¨äºé¢„æµ‹ 3D ç³»æ•°ï¼Œç„¶ååˆ©ç”¨æ¸²æŸ“ç½‘ç»œç”Ÿæˆæœ€ç»ˆè§†é¢‘ã€‚</li>
<li>EmoSpeaker æ–¹æ³•åœ¨è¡¨æƒ…å˜åŒ–å’Œå”‡å½¢åŒæ­¥æ–¹é¢ä¼˜äºç°æœ‰æƒ…æ„Ÿè°ˆè¯äººè„¸ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>é¡¹ç›®ä¸»é¡µï¼š<a href="https://peterfanfan.github.io/EmoSpeaker/">https://peterfanfan.github.io/EmoSpeaker/</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šEmoSpeakerï¼šå•æ¬¡å­¦ä¹ ç»†ç²’åº¦æƒ…æ„Ÿæ§åˆ¶çš„è¯´è¯äººé¢éƒ¨ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šGuanwen Feng, Haoran Cheng, Yunan Li, Zhiyuan Ma, Chaoneng Li, Zhihao Qian, Qiguang Miao</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢</li>
<li>å…³é”®è¯ï¼šè¯´è¯äººé¢éƒ¨ã€ä¸‰ç»´å¯å˜å½¢æ¨¡å‹ã€è§†è§‰å±æ€§å¼•å¯¼çš„è§£è€¦è¿‡ç¨‹ã€ç»†ç²’åº¦æƒ…æ„Ÿæ§åˆ¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.01422
Github é“¾æ¥ï¼šhttps://github.com/peterfanfan/EmoSpeaker</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººé¢éƒ¨ç”ŸæˆæŠ€æœ¯å·²æˆä¸ºè¿‘å¹´æ¥ç ”ç©¶çš„çƒ­ç‚¹ï¼Œå…¶åœ¨è™šæ‹Ÿæ•°å­—äººç”Ÿæˆã€è™šæ‹Ÿç°å®å’Œç”µå½±ç‰¹æ•ˆç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨åœºæ™¯ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å”‡å½¢åŒæ­¥å’Œè§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œå¯¹ç”Ÿæˆè§†é¢‘çš„æƒ…æ„Ÿè¡¨è¾¾å…³æ³¨è¾ƒå°‘ã€‚
(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€äº›ç°æœ‰æ–¹æ³•è§£å†³äº†æƒ…æ„Ÿé¢éƒ¨åŠ¨ç”»ç”Ÿæˆçš„é—®é¢˜ï¼Œä½†å®ƒä»¬é€šå¸¸å—é™äºé•¿è§†é¢‘æˆ–çŸ­è§†é¢‘çš„é©±åŠ¨ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æ ‡ç­¾æ§åˆ¶çš„æ–¹æ³•éš¾ä»¥ç”Ÿæˆå…·æœ‰ä¸åŒå¼ºåº¦å’Œä¸åŒæƒ…æ„Ÿä¸­é—´çŠ¶æ€çš„æƒ…æ„Ÿè§†é¢‘ã€‚å•æ¬¡å­¦ä¹ ç”Ÿæˆæ–¹æ³•é€šå¸¸åªè€ƒè™‘å”‡å½¢åŒæ­¥ï¼Œè€Œæ²¡æœ‰è€ƒè™‘æƒ…æ„Ÿå› ç´ ã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º EmoSpeaker çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ 3D ç³»æ•°ä½œä¸ºä¸­é—´è¡¨ç¤ºæ¥è¿æ¥è¯´è¯äººé¢éƒ¨ç”Ÿæˆè¿‡ç¨‹çš„ä¸åŒéƒ¨åˆ†ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œé¦–å…ˆå¼•å…¥è§†è§‰å±æ€§å¼•å¯¼çš„éŸ³é¢‘è§£è€¦å™¨ï¼Œä»éŸ³é¢‘ä¸­æå–ä¸å†…å®¹å‘é‡ç›¸å…³çš„å†…å®¹å‘é‡ï¼Œå¢å¼ºåç»­å”‡éƒ¨åŠ¨ä½œç³»æ•°é¢„æµ‹çš„ç¨³å®šæ€§ã€‚å…¶æ¬¡ï¼Œåœ¨ç»†ç²’åº¦æƒ…æ„Ÿç³»æ•°é¢„æµ‹æ¨¡å—ä¸­ï¼Œå°†å†…å®¹å‘é‡ä¸æƒ…æ„Ÿæ ‡ç­¾èšåˆï¼Œé¢„æµ‹ç»†ç²’åº¦çš„é¢éƒ¨åŠ¨ä½œç³»æ•°ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨ç»†ç²’åº¦æƒ…æ„ŸçŸ©é˜µçš„æƒ…æ„Ÿå¼ºåº¦æ§åˆ¶æ–¹æ³•ã€‚é€šè¿‡è¿™äº›æ–¹æ³•ï¼Œå®ç°äº†å¯¹ç”Ÿæˆè§†é¢‘ä¸­çš„æƒ…æ„Ÿè¡¨è¾¾çš„æœ‰æ•ˆæ§åˆ¶å’Œå¯¹æƒ…æ„Ÿå¼ºåº¦çš„æ›´ç²¾ç»†åˆ†ç±»ã€‚æœ€åï¼Œè®¾è®¡äº†ä¸€ç³»åˆ— 3DMM ç³»æ•°ç”Ÿæˆç½‘ç»œæ¥é¢„æµ‹ 3D ç³»æ•°ï¼Œç„¶ååˆ©ç”¨æ¸²æŸ“ç½‘ç»œç”Ÿæˆæœ€ç»ˆè§†é¢‘ã€‚
(4) æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„ EmoSpeaker æ–¹æ³•åœ¨è¡¨æƒ…è¡¨è¾¾å’Œå”‡å½¢åŒæ­¥æ–¹é¢ä¼˜äºç°æœ‰æƒ…æ„Ÿè¯´è¯äººé¢éƒ¨ç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•å¯ä»¥æ”¯æŒå…¶ç›®æ ‡ï¼Œç”Ÿæˆå…·æœ‰ä»»æ„å¼ºåº¦çš„ä»»æ„æƒ…æ„Ÿé¢éƒ¨è§†é¢‘ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰è§†è§‰å±æ€§å¼•å¯¼çš„éŸ³é¢‘è§£è€¦å™¨ï¼šä¸ºäº†å‡†ç¡®é¢„æµ‹å”‡éƒ¨ä¿¡æ¯ï¼Œæå‡ºäº†ä¸€ç§è§†è§‰å±æ€§å¼•å¯¼çš„éŸ³é¢‘è§£è€¦å™¨ã€‚è¯¥è§£è€¦å™¨åˆ©ç”¨é¢éƒ¨åŠ¨ä½œå•å…ƒï¼ˆAUï¼‰ä½œä¸ºè§†è§‰ä¿¡æ¯ï¼ŒæŒ‡å¯¼éŸ³é¢‘çš„æƒ…æ„Ÿè§£è€¦è¿‡ç¨‹ï¼Œå¢å¼ºè§£è€¦çš„ç²¾åº¦å’Œå¯æ§æ€§ã€‚
ï¼ˆ2ï¼‰ç»†ç²’åº¦æƒ…æ„Ÿç³»æ•°é¢„æµ‹æ¨¡å—ï¼šå°†å†…å®¹å‘é‡ä¸æƒ…æ„Ÿæ ‡ç­¾èšåˆï¼Œé¢„æµ‹ç»†ç²’åº¦çš„é¢éƒ¨åŠ¨ä½œç³»æ•°ã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€ç§ä½¿ç”¨ç»†ç²’åº¦æƒ…æ„ŸçŸ©é˜µçš„æƒ…æ„Ÿå¼ºåº¦æ§åˆ¶æ–¹æ³•ï¼Œå®ç°å¯¹ç”Ÿæˆè§†é¢‘ä¸­æƒ…æ„Ÿè¡¨è¾¾çš„æœ‰æ•ˆæ§åˆ¶å’Œå¯¹æƒ…æ„Ÿå¼ºåº¦çš„æ›´ç²¾ç»†åˆ†ç±»ã€‚
ï¼ˆ3ï¼‰æƒ…æ„Ÿé¢éƒ¨æ¸²æŸ“å™¨ï¼šè®¾è®¡äº†ä¸€ç³»åˆ—ä¸‰ç»´å¯å˜å½¢æ¨¡å‹ç³»æ•°ç”Ÿæˆç½‘ç»œæ¥é¢„æµ‹ä¸‰ç»´ç³»æ•°ï¼Œç„¶ååˆ©ç”¨æ¸²æŸ“ç½‘ç»œç”Ÿæˆæœ€ç»ˆè§†é¢‘ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º EmoSpeaker çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•ä»…éœ€éŸ³é¢‘å‰ªè¾‘ã€è‚–åƒã€ç‰¹å®šæƒ…ç»ªå’Œå¼ºåº¦ç²’åº¦ï¼Œå³å¯ç”Ÿæˆå…·æœ‰ç»†ç²’åº¦å¼ºåº¦çš„è¡¨æƒ…é¢éƒ¨ã€‚è¯¥æ–¹æ³•ä½¿ç”¨é¢éƒ¨æƒ…ç»ªè§£è€¦æ¨¡å—æå–å†…å®¹ç‰¹å¾ï¼Œå¹¶ç»“åˆç»†ç²’åº¦å¼ºåº¦æ§åˆ¶æ¨¡å—æ¥å®ç°ä»»æ„æƒ…ç»ªå¼ºåº¦ã€‚è¿™åœ¨ç”µå­æ¸¸æˆã€è™šæ‹Ÿç°å®ã€ç”µå½±ç‰¹æ•ˆå’Œäººæœºç•Œé¢äº¤äº’ç­‰é¢†åŸŸå±•ç¤ºäº†æœ‰å¸Œæœ›çš„åº”ç”¨ã€‚ä¸»è§‚å’Œå®¢è§‚è¯„ä¼°è¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆæ›´ä¸°å¯Œçš„é¢éƒ¨åŠ¨ç”»æ–¹é¢å…·æœ‰ä¼˜è¶Šæ€§ã€‚æœªæ¥çš„ç ”ç©¶å°†é›†ä¸­äºåœ¨ç»†ç²’åº¦å¼ºåº¦æ§åˆ¶é¢†åŸŸè¿›è¡Œæ·±å…¥ç ”ç©¶ï¼Œä»¥å¢å¼ºæ›´å…·è¡¨ç°åŠ›å’Œç»†å¾®å·®åˆ«çš„é¢éƒ¨åŠ¨ç”»çš„ç”Ÿæˆã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§è§†è§‰å±æ€§å¼•å¯¼çš„éŸ³é¢‘è§£è€¦å™¨ï¼Œè¯¥è§£è€¦å™¨åˆ©ç”¨é¢éƒ¨åŠ¨ä½œå•å…ƒä½œä¸ºè§†è§‰ä¿¡æ¯ï¼ŒæŒ‡å¯¼éŸ³é¢‘çš„æƒ…æ„Ÿè§£è€¦è¿‡ç¨‹ï¼Œå¢å¼ºè§£è€¦çš„ç²¾åº¦å’Œå¯æ§æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç»†ç²’åº¦æƒ…æ„Ÿç³»æ•°é¢„æµ‹æ¨¡å—ï¼Œå°†å†…å®¹å‘é‡ä¸æƒ…æ„Ÿæ ‡ç­¾èšåˆï¼Œé¢„æµ‹ç»†ç²’åº¦çš„é¢éƒ¨åŠ¨ä½œç³»æ•°ã€‚åŒæ—¶ï¼Œæå‡ºäº†ä¸€ç§ä½¿ç”¨ç»†ç²’åº¦æƒ…æ„ŸçŸ©é˜µçš„æƒ…æ„Ÿå¼ºåº¦æ§åˆ¶æ–¹æ³•ï¼Œå®ç°å¯¹ç”Ÿæˆè§†é¢‘ä¸­æƒ…æ„Ÿè¡¨è¾¾çš„æœ‰æ•ˆæ§åˆ¶å’Œå¯¹æƒ…æ„Ÿå¼ºåº¦çš„æ›´ç²¾ç»†åˆ†ç±»ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç³»åˆ—ä¸‰ç»´å¯å˜å½¢æ¨¡å‹ç³»æ•°ç”Ÿæˆç½‘ç»œæ¥é¢„æµ‹ä¸‰ç»´ç³»æ•°ï¼Œç„¶ååˆ©ç”¨æ¸²æŸ“ç½‘ç»œç”Ÿæˆæœ€ç»ˆè§†é¢‘ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è¡¨æƒ…è¡¨è¾¾å’Œå”‡å½¢åŒæ­¥æ–¹é¢ä¼˜äºç°æœ‰æƒ…æ„Ÿè¯´è¯äººé¢éƒ¨ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>å¯ä»¥æ”¯æŒå…¶ç›®æ ‡ï¼Œç”Ÿæˆå…·æœ‰ä»»æ„å¼ºåº¦çš„ä»»æ„æƒ…æ„Ÿé¢éƒ¨è§†é¢‘ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦æ”¶é›†å¤§é‡çš„æ•°æ®é›†æ¥è®­ç»ƒæ¨¡å‹ã€‚</li>
<li>æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹æ¯”è¾ƒè€—æ—¶ã€‚</li>
<li>éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥é€‚åº”ä¸åŒçš„æ•°æ®é›†ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6bacdbeff940a1345ff38f8b1dc2680f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c646c87add1ea43ace17da06ebd12a7c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d08dc09fd1df64224ed8ef166ac7d5b4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0dc431600d1c5672918ab10a962f79ab.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7d1b798a4f9c96adf7e70cbb6847a5b3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4c97492b45a0ba3e2e8b06c0abf4372f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5ce57abfa37d7135a925aa7ba77e6120.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/02/13/Paper/2024-02-13/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-13-æ›´æ–°"><a href="#2024-02-13-æ›´æ–°" class="headerlink" title="2024-02-13 æ›´æ–°"></a>2024-02-13 æ›´æ–°</h1><h2 id="GALA3D-Towards-Text-to-3D-Complex-Scene-Generation-via-Layout-guided-Generative-Gaussian-Splatting"><a href="#GALA3D-Towards-Text-to-3D-Complex-Scene-Generation-via-Layout-guided-Generative-Gaussian-Splatting" class="headerlink" title="GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided   Generative Gaussian Splatting"></a>GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided   Generative Gaussian Splatting</h2><p><strong>Authors:Xiaoyu Zhou, Xingjian Ran, Yajiao Xiong, Jinlin He, Zhiwei Lin, Yongtao Wang, Deqing Sun, Ming-Hsuan Yang</strong></p>
<p>We present GALA3D, generative 3D GAussians with LAyout-guided control, for effective compositional text-to-3D generation. We first utilize large language models (LLMs) to generate the initial layout and introduce a layout-guided 3D Gaussian representation for 3D content generation with adaptive geometric constraints. We then propose an object-scene compositional optimization mechanism with conditioned diffusion to collaboratively generate realistic 3D scenes with consistent geometry, texture, scale, and accurate interactions among multiple objects while simultaneously adjusting the coarse layout priors extracted from the LLMs to align with the generated scene. Experiments show that GALA3D is a user-friendly, end-to-end framework for state-of-the-art scene-level 3D content generation and controllable editing while ensuring the high fidelity of object-level entities within the scene. Source codes and models will be available at <a href="https://gala3d.github.io/">https://gala3d.github.io/</a>. </p>
<p><a href="http://arxiv.org/abs/2402.07207v1">PDF</a> </p>
<p><strong>Summary</strong></p>
<p>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) ç”Ÿæˆåˆå§‹å¸ƒå±€ï¼Œå¹¶å¼•å…¥å¸ƒå±€å¼•å¯¼ 3D é«˜æ–¯è¡¨ç¤ºï¼ŒæŒ‡å¯¼ 3D å†…å®¹ç”Ÿæˆï¼ŒåŒæ—¶æ»¡è¶³é€‚åº”æ€§å‡ ä½•çº¦æŸã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GALA3D å°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸å¸ƒå±€å¼•å¯¼ 3D é«˜æ–¯è¡¨ç¤ºç›¸ç»“åˆï¼Œç”¨äºæœ‰æ•ˆåœ°è¿›è¡Œæ–‡æœ¬åˆ° 3D çš„ç”Ÿæˆã€‚</li>
<li>å¸ƒå±€å¼•å¯¼ 3D é«˜æ–¯è¡¨ç¤ºæä¾›äº†è‡ªé€‚åº”çš„å‡ ä½•çº¦æŸï¼Œç¡®ä¿ç”Ÿæˆçš„ 3D å†…å®¹å…·æœ‰çœŸå®æ„Ÿå’Œä¸€è‡´æ€§ã€‚</li>
<li>GALA3D é‡‡ç”¨å¯¹è±¡-åœºæ™¯ç»„åˆä¼˜åŒ–æœºåˆ¶ï¼Œä»¥ç”Ÿæˆå…·æœ‰çœŸå®å‡ ä½•å½¢çŠ¶ã€çº¹ç†ã€æ¯”ä¾‹å’Œå‡†ç¡®äº¤äº’çš„å¤šå¯¹è±¡ 3D åœºæ™¯ã€‚</li>
<li>GALA3D å¯ä»¥åŒæ—¶è°ƒæ•´ä»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æå–çš„ç²—ç•¥å¸ƒå±€ï¼Œä½¿å…¶ä¸ç”Ÿæˆçš„åœºæ™¯ä¿æŒä¸€è‡´ã€‚</li>
<li>GALA3D æ˜¯ä¸€ä¸ªç”¨æˆ·å‹å¥½çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œå¯è¿›è¡Œæœ€å…ˆè¿›çš„åœºæ™¯çº§ 3D å†…å®¹ç”Ÿæˆå’Œå¯æ§ç¼–è¾‘ã€‚</li>
<li>GALA3D èƒ½å¤Ÿç¡®ä¿åœºæ™¯ä¸­å¯¹è±¡çº§å®ä½“çš„é«˜ä¿çœŸåº¦ã€‚</li>
<li>GALA3D çš„æºä»£ç å’Œæ¨¡å‹å¯ä» <a href="https://gala3d.github.io/">https://gala3d.github.io/</a> è·å–ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šGALA3Dï¼šåŸºäºå¸ƒå±€å¼•å¯¼çš„æ–‡æœ¬åˆ° 3D å¤æ‚åœºæ™¯ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šXiaoyu Zhou, Xingjian Ran, Yajiao Xiong, Jinlin He, Zhiwei Lin, Yongtao Wang, Deqing Sun, Ming-Hsuan Yang</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåŒ—äº¬å¤§å­¦ä¸‡é€‰ä¿¡æ¯æŠ€æœ¯å­¦é™¢</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ° 3Dã€ç”Ÿæˆå¼é«˜æ–¯ä½“ç´ ã€å¸ƒå±€å¼•å¯¼ã€æ¡ä»¶æ‰©æ•£</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.07207
    Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ° 3D ç”Ÿæˆæ—¨åœ¨æ ¹æ®è‡ªç„¶è¯­è¨€æè¿°ç”Ÿæˆé€¼çœŸçš„ 3D åœºæ™¯ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆäº§ç”Ÿä½è´¨é‡çš„çº¹ç†ã€è§†è§‰ä¼ªå½±å’Œå‡ ä½•å¤±çœŸï¼Œè¦ä¹ˆæ— æ³•æ ¹æ®æ–‡æœ¬å‡†ç¡®ç”Ÿæˆå¤šä¸ªå¯¹è±¡åŠå…¶äº¤äº’ã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šåŸºäºä½“ç´ çš„æ–¹æ³•å’ŒåŸºäºç½‘æ ¼çš„æ–¹æ³•ã€‚åŸºäºä½“ç´ çš„æ–¹æ³•è™½ç„¶å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ 3D åœºæ™¯ï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚åŸºäºç½‘æ ¼çš„æ–¹æ³•è™½ç„¶è®¡ç®—æˆæœ¬è¾ƒä½ï¼Œä½†ç”Ÿæˆçš„ 3D åœºæ™¯è´¨é‡è¾ƒå·®ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆå¼é«˜æ–¯ä½“ç´ çš„æ–‡æœ¬åˆ° 3D ç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆåˆå§‹å¸ƒå±€ï¼Œç„¶åå¼•å…¥å¸ƒå±€å¼•å¯¼çš„ 3D é«˜æ–¯ä½“ç´ è¡¨ç¤ºæ¥ç”Ÿæˆ 3D å†…å®¹ã€‚æ¥ç€ï¼Œæå‡ºäº†ä¸€ç§å¯¹è±¡åœºæ™¯ç»„åˆä¼˜åŒ–æœºåˆ¶ï¼Œè¯¥æœºåˆ¶åˆ©ç”¨æ¡ä»¶æ‰©æ•£æ¥ååŒç”Ÿæˆå…·æœ‰çœŸå®å‡ ä½•å½¢çŠ¶ã€çº¹ç†ã€æ¯”ä¾‹å’Œå‡†ç¡®äº¤äº’çš„å¤šå¯¹è±¡ 3D åœºæ™¯ï¼ŒåŒæ—¶è°ƒæ•´ä»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æå–çš„ç²—ç•¥å¸ƒå±€å…ˆéªŒï¼Œä½¿å…¶ä¸ç”Ÿæˆçš„åœºæ™¯å¯¹é½ã€‚
(4) å®éªŒç»“æœï¼šå®éªŒè¡¨æ˜ï¼ŒGALA3D æ˜¯ä¸€ä¸ªç”¨æˆ·å‹å¥½çš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œå¯ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„ 3D åœºæ™¯ã€‚è¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ”¯æŒäº¤äº’å¼å¯æ§ç¼–è¾‘ã€‚</li>
</ol>
<p>Methods:</p>
<p>(1) ç²—ç•¥å¸ƒå±€å…ˆéªŒï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»æ–‡æœ¬æè¿°ä¸­æå–ç²—ç•¥å¸ƒå±€å…ˆéªŒï¼ŒåŒ…æ‹¬å¯¹è±¡å®ä¾‹åŠå…¶å¯¹åº”çš„ä½ç½®ã€å°ºå¯¸å’Œæ–¹å‘ã€‚</p>
<p>(2) å¸ƒå±€å¼•å¯¼çš„é«˜æ–¯ä½“ç´ è¡¨ç¤ºï¼šå°†ç²—ç•¥å¸ƒå±€å…ˆéªŒè½¬æ¢ä¸ºå¸ƒå±€å¼•å¯¼çš„é«˜æ–¯ä½“ç´ è¡¨ç¤ºï¼Œå…¶ä¸­æ¯ä¸ªå¯¹è±¡å®ä¾‹ç”±ä¸€ç»„é«˜æ–¯ä½“ç´ è¡¨ç¤ºï¼Œé«˜æ–¯ä½“ç´ çš„ä½ç½®ã€å°ºå¯¸å’Œæ–¹å‘ç”±å¸ƒå±€å…ˆéªŒå†³å®šã€‚</p>
<p>(3) è‡ªé€‚åº”å‡ ä½•æ§åˆ¶ï¼šå¯¹é«˜æ–¯ä½“ç´ çš„åˆ†å¸ƒå’Œå½¢çŠ¶è¿›è¡Œè‡ªé€‚åº”å‡ ä½•æ§åˆ¶ï¼Œä»¥ç¡®ä¿é«˜æ–¯ä½“ç´ çš„åˆ†å¸ƒç´§å¯†è´´åˆå¯¹è±¡è¡¨é¢ï¼Œå¹¶ä¸”å½¢çŠ¶æ›´åŠ è§„åˆ™å’Œä¸€è‡´ã€‚</p>
<p>(4) å…·æœ‰æ‰©æ•£å…ˆéªŒçš„ç»„åˆä¼˜åŒ–ï¼šé‡‡ç”¨å…·æœ‰æ‰©æ•£å…ˆéªŒçš„ç»„åˆä¼˜åŒ–ç­–ç•¥æ¥æ›´æ–°å¸ƒå±€å¼•å¯¼çš„é«˜æ–¯ä½“ç´ å‚æ•°ï¼ŒåŒ…æ‹¬å¤šè§†å›¾æ‰©æ•£ä¼˜åŒ–å’Œåœºæ™¯æ¡ä»¶æ‰©æ•£ä¼˜åŒ–ï¼Œä»¥ç”Ÿæˆå…·æœ‰ç»Ÿä¸€é£æ ¼å’Œäº¤äº’å…³ç³»çš„å¯¹è±¡å®ä¾‹ã€‚</p>
<p>(5) å¸ƒå±€æŸå¤±ï¼šå¼•å…¥å¸ƒå±€æŸå¤±æ¥ç¡®ä¿ç”Ÿæˆçš„3Dåœºæ™¯ä¸å¸ƒå±€å…ˆéªŒåœ¨è¯­ä¹‰å’Œç©ºé—´ä¸Šçš„ä¸€è‡´æ€§ï¼Œä»è€Œæé«˜åœºæ™¯çš„æ•´ä½“è´¨é‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šGALA3D æ˜¯ä¸€ç§åŸºäºç”Ÿæˆå¼å¸ƒå±€å¼•å¯¼çš„ 3D é«˜æ–¯ä½“ç´ è¡¨ç¤ºçš„åœºæ™¯çº§æ–‡æœ¬åˆ° 3D æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥ç”Ÿæˆå…·æœ‰å¤šä¸ªå¯¹è±¡çš„é«˜ä¿çœŸã€3D ä¸€è‡´çš„åœºæ™¯ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ–‡æœ¬åˆ° 3D ç”Ÿæˆæ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç¤ºäº†ç”Ÿæˆå…·æœ‰å¤šä¸ªå¯¹è±¡å’Œäº¤äº’çš„å¤æ‚åœºæ™¯çš„èƒ½åŠ›ï¼Œå¹¶å®ç°äº†å‡ºè‰²çš„çº¹ç†å’Œå‡ ä½•æ•ˆæœã€‚è¯¥æ–¹æ³•è¿˜ä¿ƒè¿›äº†äº¤äº’å¼å’Œå¯æ§çš„åœºæ™¯ç¼–è¾‘ï¼Œå®ç°äº†ä¸€ä¸ªé«˜æ•ˆä¸”ç”¨æˆ·å‹å¥½çš„ 3D åœºæ™¯ç”Ÿæˆå’Œç¼–è¾‘æ¡†æ¶ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆå¼å¸ƒå±€å¼•å¯¼çš„ 3D é«˜æ–¯ä½“ç´ è¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºå¯ä»¥ç”Ÿæˆå…·æœ‰ç»Ÿä¸€é£æ ¼å’Œäº¤äº’å…³ç³»çš„å¯¹è±¡å®ä¾‹ã€‚</li>
<li>å¼•å…¥äº†ä¸€ç§å…·æœ‰æ‰©æ•£å…ˆéªŒçš„ç»„åˆä¼˜åŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æ›´æ–°å¸ƒå±€å¼•å¯¼çš„é«˜æ–¯ä½“ç´ å‚æ•°ï¼Œä»¥ç”Ÿæˆå…·æœ‰çœŸå®å‡ ä½•å½¢çŠ¶ã€çº¹ç†ã€æ¯”ä¾‹å’Œå‡†ç¡®äº¤äº’çš„å¤šå¯¹è±¡ 3D åœºæ™¯ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¸ƒå±€æŸå¤±ï¼Œè¯¥æŸå¤±å¯ä»¥ç¡®ä¿ç”Ÿæˆçš„ 3D åœºæ™¯ä¸å¸ƒå±€å…ˆéªŒåœ¨è¯­ä¹‰å’Œç©ºé—´ä¸Šçš„ä¸€è‡´æ€§ï¼Œä»è€Œæé«˜åœºæ™¯çš„æ•´ä½“è´¨é‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>èƒ½å¤Ÿæ”¯æŒäº¤äº’å¼å¯æ§ç¼–è¾‘ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3dde3c6bf6237679d7dc8e3a25b014e3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c780f9b8f1b542e9c562c2d185d7e16a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-785f0dd46228bdf108d1677b776eeb58.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e76b694075c9297c3e8a8d38bf4c8fe3.jpg" align="middle">
</details>




<h2 id="GS-CLIP-Gaussian-Splatting-for-Contrastive-Language-Image-3D-Pretraining-from-Real-World-Data"><a href="#GS-CLIP-Gaussian-Splatting-for-Contrastive-Language-Image-3D-Pretraining-from-Real-World-Data" class="headerlink" title="GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D   Pretraining from Real-World Data"></a>GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D   Pretraining from Real-World Data</h2><p><strong>Authors:Haoyuan Li, Yanpeng Zhou, Yihan Zeng, Hang Xu, Xiaodan Liang</strong></p>
<p>3D Shape represented as point cloud has achieve advancements in multimodal pre-training to align image and language descriptions, which is curial to object identification, classification, and retrieval. However, the discrete representations of point cloud lost the objectâ€™s surface shape information and creates a gap between rendering results and 2D correspondences. To address this problem, we propose GS-CLIP for the first attempt to introduce 3DGS (3D Gaussian Splatting) into multimodal pre-training to enhance 3D representation. GS-CLIP leverages a pre-trained vision-language model for a learned common visual and textual space on massive real world image-text pairs and then learns a 3D Encoder for aligning 3DGS optimized per object. Additionally, a novel Gaussian-Aware Fusion is proposed to extract and fuse global explicit feature. As a general framework for language-image-3D pre-training, GS-CLIP is agnostic to 3D backbone networks. Experiments on challenging shows that GS-CLIP significantly improves the state-of-the-art, outperforming the previously best results. </p>
<p><a href="http://arxiv.org/abs/2402.06198v1">PDF</a> 6-page technical report</p>
<p><strong>Summary</strong><br>3D é«˜æ–¯æ›²é¢è¡¨ç¤ºå¢å¼ºå¤šæ¨¡æ€é¢„è®­ç»ƒï¼Œ ä¿ƒè¿›å›¾åƒã€è¯­è¨€å’Œ 3D è¡¨ç¤ºçš„ç»Ÿä¸€ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤šæ¨¡æ€é¢„è®­ç»ƒåœ¨å›¾åƒå’Œè¯­è¨€æè¿°çš„å¯¹é½æ–¹é¢å–å¾—è¿›å±•ï¼Œå¯¹ç‰©ä½“è¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢è‡³å…³é‡è¦ã€‚</li>
<li>ç‚¹äº‘çš„ç¦»æ•£è¡¨ç¤ºä¸¢å¤±äº†ç‰©ä½“çš„è¡¨é¢å½¢çŠ¶ä¿¡æ¯ï¼Œå¯¼è‡´æ¸²æŸ“ç»“æœä¸ 2D å¯¹åº”å…³ç³»ä¹‹é—´å­˜åœ¨å·®è·ã€‚</li>
<li>æå‡º GS-CLIP é¦–æ¬¡å°† 3DGSï¼ˆ3D é«˜æ–¯æ›²é¢ï¼‰å¼•å…¥å¤šæ¨¡æ€é¢„è®­ç»ƒï¼Œä»¥å¢å¼º 3D è¡¨ç¤ºã€‚</li>
<li>GS-CLIP åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œåœ¨å¤§è§„æ¨¡çœŸå®ä¸–ç•Œå›¾åƒæ–‡æœ¬å¯¹ä¸Šå­¦ä¹ å…±åŒçš„è§†è§‰å’Œæ–‡æœ¬ç©ºé—´ï¼Œç„¶åå­¦ä¹ ä¸€ä¸ª 3D ç¼–ç å™¨æ¥å¯¹é½é’ˆå¯¹æ¯ä¸ªå¯¹è±¡ä¼˜åŒ–çš„ 3DGSã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„ Gaussian-Aware Fusion æ¥æå–å’Œèåˆå…¨å±€æ˜¾å¼ç‰¹å¾ã€‚</li>
<li>ä½œä¸ºè¯­è¨€å›¾åƒ 3D é¢„è®­ç»ƒçš„é€šç”¨æ¡†æ¶ï¼ŒGS-CLIP ä¸ 3D ä¸»å¹²ç½‘ç»œæ— å…³ã€‚</li>
<li>å…·æœ‰æŒ‘æˆ˜æ€§çš„å®éªŒè¡¨æ˜ï¼ŒGS-CLIP æ˜¾ç€æ”¹å–„äº†æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œä¼˜äºå…ˆå‰æœ€å¥½çš„ç»“æœã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li>é¢˜ç›®ï¼šGS-CLIPï¼šç”¨äºå¯¹æ¯”è¯­è¨€-å›¾åƒ-3D é¢„è®­ç»ƒçš„é«˜æ–¯æº…å°„</li><p></p>
<p></p><li>ä½œè€…ï¼šææµ©æºã€å‘¨å½¦é¹ã€æ›¾ä¹‰æ¶µã€è®¸èˆªã€æ¢æ™“ä¸¹</li><p></p>
<p></p><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å±±å¤§å­¦æ·±åœ³æ ¡åŒº</li><p></p>
<p></p><li>å…³é”®è¯ï¼š3D è¡¨ç¤ºã€é«˜æ–¯æº…å°„ã€å¯¹æ¯”å­¦ä¹ ã€å¤šæ¨¡æ€é¢„è®­ç»ƒ</li><p></p>
<p></p><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.06198ï¼ŒGithub é“¾æ¥ï¼šæ— </li><p></p>
<p></p><li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼š3D å½¢çŠ¶ä»¥ç‚¹äº‘è¡¨ç¤ºåœ¨å¤šæ¨¡æ€é¢„è®­ç»ƒä¸­å–å¾—äº†è¿›å±•ï¼Œç”¨äºå¯¹é½å›¾åƒå’Œè¯­è¨€æè¿°ï¼Œè¿™å¯¹äºç‰©ä½“è¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç‚¹äº‘çš„ç¦»æ•£è¡¨ç¤ºä¸¢å¤±äº†ç‰©ä½“çš„è¡¨é¢å½¢çŠ¶ä¿¡æ¯ï¼Œå¹¶åœ¨æ¸²æŸ“ç»“æœå’Œ 2D å¯¹åº”å…³ç³»ä¹‹é—´äº§ç”Ÿå·®è·ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰çš„ 3D è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ä¸»è¦å¯¹ç‚¹äº‘çš„å…³é”®ç‚¹ä½ç½®ä¿¡æ¯è¿›è¡Œå»ºæ¨¡ï¼Œè¿™é™åˆ¶äº† 3D è§†è§‰ç†è§£å’Œ 3D è¡¨ç¤ºå­¦ä¹ çš„æ€§èƒ½ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº† GS-CLIPï¼Œå°† 3D é«˜æ–¯æº…å°„ (3DGS) å¼•å…¥å¤šæ¨¡æ€é¢„è®­ç»ƒï¼Œä»¥å¢å¼º 3D è¡¨ç¤ºã€‚GS-CLIP åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œçš„å¤§è§„æ¨¡å›¾åƒ-æ–‡æœ¬å¯¹ä¸Šå­¦ä¹ ä¸€ä¸ªå…±åŒçš„è§†è§‰å’Œæ–‡æœ¬ç©ºé—´ï¼Œç„¶åå­¦ä¹ ä¸€ä¸ª 3D ç¼–ç å™¨ï¼Œç”¨äºå¯¹é½é’ˆå¯¹æ¯ä¸ªå¯¹è±¡ä¼˜åŒ–çš„ 3DGSã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„é«˜æ–¯æ„ŸçŸ¥èåˆï¼Œç”¨äºæå–å’Œèåˆå…¨å±€æ˜¾å¼ç‰¹å¾ã€‚
(4)ï¼šå®éªŒç»“æœï¼šåœ¨ SUN-RGBD æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGS-CLIP åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­çš„é›¶æ ·æœ¬/å¼€æ”¾è¯å­¦ä¹ ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ3DGS åœ¨è·¨æ¨¡æ€å­¦ä¹ ä¸­å…·æœ‰å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ã€‚</li><br>&lt;/ol&gt;<p></p>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰è·¨æ¨¡æ€é¢„è®­ç»ƒï¼šä¸ºäº†å¯¹é½æ–‡æœ¬ã€å›¾åƒå’Œ3DGSçš„å¤šæ¨¡æ€è¡¨ç¤ºï¼ŒGS-CLIPé‡‡ç”¨é¢„è®­ç»ƒçš„è¯­è¨€-å›¾åƒæ¨¡å‹CLIPï¼Œå½¢æˆä¸€ä¸ªå…±åŒçš„è¯­è¨€-å›¾åƒæ½œåœ¨ç©ºé—´ï¼Œä½œä¸º3DGSçš„ç›®æ ‡æ½œåœ¨ç©ºé—´ã€‚å¯¹äºé›¶æ ·æœ¬/å¼€æ”¾è¯è¯†åˆ«ï¼Œé€šè¿‡å†»ç»“CLIPæ–‡æœ¬ç¼–ç å™¨ã€å›¾åƒç¼–ç å™¨å’Œå…¬å…±çœŸå®ä¸–ç•Œæ½œåœ¨ç©ºé—´ï¼Œä¿è¯äº†3DGSè¡¨ç¤ºçš„å¯è¿ç§»æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å€Ÿé‰´äº†[19, 28]ä¸­çš„å¯¹æ¯”æŸå¤±ï¼Œå¹¶å½¢æˆæ–‡æœ¬-3DGSå¯¹é½å’Œå›¾åƒ-3DGSå¯¹é½ï¼Œç”¨äºå¤šæ¨¡æ€å¯¹é½ã€‚
ï¼ˆ2ï¼‰é«˜æ–¯æ„ŸçŸ¥èåˆï¼šè™½ç„¶å°†ç‚¹äº‘æŠ•å½±åˆ°3Dä½“ç´ çš„3Déª¨å¹²å¯ä»¥æ›´å¥½åœ°å­¦ä¹ å…¨å±€ä½ç½®å’Œç‰¹å¾ï¼Œä½†æˆ‘ä»¬å‘ç°3DGSçš„æ˜¾å¼ç‰¹å¾ä¼šè¢«å¿½ç•¥ï¼Œå› ä¸ºä½“ç´ åŒ–ä¸¢å¤±äº†å½¢çŠ¶å’Œçº¹ç†ä¿¡æ¯ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºTransformerçš„åˆ†æ”¯ç›´æ¥å¯¹é«˜æ–¯ç‰¹å¾å»ºæ¨¡ä¸ºé«˜æ–¯ç‰¹å¾ä¸Šä¸‹æ–‡ï¼Œå¹¶ä»¥æ®‹å·®å½¢å¼æ³¨å…¥å®ƒã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šå…·æœ‰nä¸ªé«˜æ–¯çš„3DGSè¾“å…¥XGâˆˆRnÃ—14ï¼Œæˆ‘ä»¬é¦–å…ˆå°†XGåˆ†æˆNgç»„ï¼Œç”¨äºXgroupG=Ngï¿½g=1XgGï¼Œç„¶åä½¿ç”¨åŸºäºå·ç§¯çš„ä½“ç³»ç»“æ„EGÎ¸,cæå–å…¨å±€ç‰¹å¾fGcå’ŒåŸºäºTransformerçš„ä½“ç³»ç»“æ„EGÎ¸,tæå–æ˜¾å¼é«˜æ–¯ç‰¹å¾fGGï¼Œæœ€åå°†fGcå’ŒfGGè¿æ¥èµ·æ¥ï¼Œå½¢æˆæœ€ç»ˆçš„3DGSè¡¨ç¤ºfGã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æ„ä¹‰ï¼šæœ¬æ–‡é¦–æ¬¡æå‡º GS-CLIPï¼Œå°† 3DGS çº³å…¥è·¨æ¨¡æ€å­¦ä¹ ï¼Œä½œä¸ºè¡¥å……å½¢çŠ¶å’Œçº¹ç†ä¿¡æ¯çš„é€šç”¨ 3D è¡¨ç¤ºã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ç§é«˜æ–¯æ„ŸçŸ¥èåˆï¼Œä»¥ä¾¿ä»è¡¥å……ä¿¡æ¯ä¸­æ›´å¥½åœ°å­¦ä¹ ä¿¡æ¯ã€‚æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬æå‡ºçš„ GS-CLIP åœ¨æœ€å…ˆè¿›çš„æ–¹æ³•ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹ï¼š
åˆ›æ–°ç‚¹ï¼š</li>
<li>å°† 3DGS å¼•å…¥è·¨æ¨¡æ€å­¦ä¹ ï¼Œä½œä¸ºè¡¥å……å½¢çŠ¶å’Œçº¹ç†ä¿¡æ¯çš„é€šç”¨ 3D è¡¨ç¤ºã€‚</li>
<li>æå‡ºäº†ä¸€ç§é«˜æ–¯æ„ŸçŸ¥èåˆï¼Œä»¥ä¾¿ä»è¡¥å……ä¿¡æ¯ä¸­æ›´å¥½åœ°å­¦ä¹ ä¿¡æ¯ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
- åœ¨ SUN-RGBD æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGS-CLIP åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­çš„é›¶æ ·æœ¬/å¼€æ”¾è¯å­¦ä¹ ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚</p>
<p>å·¥ä½œé‡ï¼š
- éœ€è¦å¯¹ 3DGS è¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚
- éœ€è¦å¯¹é«˜æ–¯æ„ŸçŸ¥èåˆè¿›è¡Œè®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5ca02e3188a2350914f961c6e31c0616.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4980273838b01e0c94c7593c3becb878.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b33d684beebaf5252e0357a0e0af9c1d.jpg" align="middle">
</details>




</ol>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF</title>
    <url>/2024/02/13/Paper/2024-02-13/NeRF/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-13-æ›´æ–°"><a href="#2024-02-13-æ›´æ–°" class="headerlink" title="2024-02-13 æ›´æ–°"></a>2024-02-13 æ›´æ–°</h1><h2 id="BioNeRF-Biologically-Plausible-Neural-Radiance-Fields-for-View-Synthesis"><a href="#BioNeRF-Biologically-Plausible-Neural-Radiance-Fields-for-View-Synthesis" class="headerlink" title="BioNeRF: Biologically Plausible Neural Radiance Fields for View   Synthesis"></a>BioNeRF: Biologically Plausible Neural Radiance Fields for View   Synthesis</h2><p><strong>Authors:Leandro A. Passos, Douglas Rodrigues, Danilo Jodas, Kelton A. P. Costa, JoÃ£o Paulo Papa</strong></p>
<p>This paper presents BioNeRF, a biologically plausible architecture that models scenes in a 3D representation and synthesizes new views through radiance fields. Since NeRF relies on the network weights to store the sceneâ€™s 3-dimensional representation, BioNeRF implements a cognitive-inspired mechanism that fuses inputs from multiple sources into a memory-like structure, improving the storing capacity and extracting more intrinsic and correlated information. BioNeRF also mimics a behavior observed in pyramidal cells concerning contextual information, in which the memory is provided as the context and combined with the inputs of two subsequent neural models, one responsible for producing the volumetric densities and the other the colors used to render the scene. Experimental results show that BioNeRF outperforms state-of-the-art results concerning a quality measure that encodes human perception in two datasets: real-world images and synthetic data. </p>
<p><a href="http://arxiv.org/abs/2402.07310v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç”Ÿç‰©ç¥ç»å½¢æ€å­¦å¯å‘çš„ NeRF æ¶æ„ï¼Œèåˆå¤šæºè¾“å…¥ï¼Œæå–æ›´æœ¬è´¨ç›¸å…³ä¿¡æ¯ï¼Œå®ç°åœºæ™¯ 3D è¡¨ç¤ºå’Œæ–°è§†è§’åˆæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>BioNeRF æ˜¯ä¸€ç§å—ç”Ÿç‰©ç¥ç»å½¢æ€å­¦å¯å‘çš„æ¶æ„ï¼Œç”¨äºå»ºæ¨¡åœºæ™¯çš„ 3D è¡¨ç¤ºå¹¶é€šè¿‡è¾å°„åœºåˆæˆæ–°è§†è§’ã€‚</li>
<li>BioNeRF å®ç°äº†ä¸€ç§è®¤çŸ¥å¯å‘çš„æœºåˆ¶ï¼Œå°†æ¥è‡ªå¤šä¸ªæ¥æºçš„è¾“å…¥èåˆåˆ°ä¸€ä¸ªç±»ä¼¼è®°å¿†çš„ç»“æ„ä¸­ï¼Œæé«˜å­˜å‚¨å®¹é‡å¹¶æå–æ›´å¤šå†…åœ¨å’Œç›¸å…³ä¿¡æ¯ã€‚</li>
<li>BioNeRF æ¨¡ä»¿åœ¨é”¥ä½“ç»†èƒä¸­è§‚å¯Ÿåˆ°çš„å…³äºä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¡Œä¸ºï¼Œå…¶ä¸­è®°å¿†è¢«æä¾›ä¸ºä¸Šä¸‹æ–‡å¹¶ä¸ä¸¤ä¸ªåç»­ç¥ç»æ¨¡å‹çš„è¾“å…¥ç›¸ç»“åˆï¼Œä¸€ä¸ªè´Ÿè´£äº§ç”Ÿä½“ç§¯å¯†åº¦ï¼Œå¦ä¸€ä¸ªè´Ÿè´£ç”¨äºæ¸²æŸ“åœºæ™¯çš„é¢œè‰²ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒBioNeRF åœ¨è¡¡é‡äººç±»æ„ŸçŸ¥çš„è´¨é‡æŒ‡æ ‡ä¸Šä¼˜äºæœ€å…ˆè¿›çš„ç»“æœï¼ŒåŒ…æ‹¬çœŸå®ä¸–ç•Œå›¾åƒå’Œåˆæˆæ•°æ®ä¸¤ç±»æ•°æ®é›†ã€‚</li>
<li>BioNeRF åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šéƒ½ä¼˜äºæœ€å…ˆè¿›çš„ç»“æœï¼Œåˆ†åˆ«ä¸ºçœŸå®ä¸–ç•Œå›¾åƒå’Œåˆæˆæ•°æ®ã€‚</li>
<li>BioNeRF åœ¨è‡ªç”±è§†è§’è§†é¢‘å’Œå…¨æ™¯è§†é¢‘çš„æ¸²æŸ“ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</li>
<li>BioNeRF åœ¨ä¸åŒåœºæ™¯å’Œæ¡ä»¶ä¸‹è¡¨ç°å‡ºé²æ£’æ€§å’Œæ³›åŒ–æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><p>1æ ‡é¢˜ï¼šã€ŠBioNeRF ç”Ÿç‰©åˆç†ç¥ç»è¾å°„åœºçš„è§†å›¾åˆæˆã€‹(BioNeRF Biologically Plausable Neural Radiance Fields for View Synthesis)ã€‚</p><p></p>
<p></p><p>ä½œè€…åˆ—è¡¨ï¼š(Leandro A Passos)ã€Douglas Rodrigues)ã€Danilo Jodas)ã€Kelton A P Costa)ã€JoÃ£o Paulo Papa)ã€‚</p><p></p>
<p></p><p>ç¬¬ä¸€ä½œè€…å•ä½ï¼š(å·´è¥¿ Bauru å¸‚ Av Eng Luiz Edmundo Carrijo Coube è¡—åå››ä¹‹ä¸€æ ‹ SÃ£o Paulo State University)ã€‚</p><p></p>
<p></p><p>å…³é”®è¯ï¼š(ç¥ç»æ¸²æŸ“)ã€ç”Ÿç‰©åˆç†ç¥ç»æ¨¡å‹)ã€‚</p><p></p>
<p></p><p>é“¾æ¥ï¼š(Paper URL)ã€‚</p><p></p>
<p></p><p>Githubä»£ç é“¾æ¥ï¼š(Github None)ã€‚</p><p></p>
<p></p><p>æ‘˜è¦ï¼š(BioNeRFæ˜¯ä¸€ç§ç”Ÿç‰©åˆç†æ¶æ„)ï¼Œå¯ä»¥åˆ©ç”¨è¾å°„å­—æ®µæ„å»ºåœºæ™¯çš„ä¸‰ D è¡¨ç¤ºå½¢å¼å¹¶ä¸”åˆæˆæ–°çš„è§†å›¾)ã€‚ç”±äº NeRF åˆ©ç”¨ç½‘ç»œä¸­çš„å„ç§å‚æ•°å­˜å‚¨åœºæ™¯çš„ä¸‰ D è¡¨ç¤ºå½¢å¼)ï¼ŒBioNeRF ä¾¿é‡‡ç”¨ä¸€ç§è®¤çŸ¥æ¿€åŠ±æ–¹æ³•)ï¼Œé€šè¿‡èåˆå¤šä¸ªæ¥æºä¸­çš„ä¿¡æ¯ç”Ÿæˆè®°å¿†ç»“æ„)ï¼Œä»è€Œæé«˜å‚¨å­˜å®¹é‡å¹¶ä¸”æå–æ›´å¤šæœ¬è´¨ä¿¡æ¯ä»¥åŠç›¸å…³ä¿¡æ¯)ã€‚BioNeRF è¿˜æ¨¡ä»¿é”¥ä½“å‹ç¥ç»ç»†èƒæœ‰å…³ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¡Œä¸º)ï¼Œå…¶ä¸­è®°å¿†ä½œä¸ºä¸Šä¸‹æ–‡æä¾›)ï¼Œå¹¶ä¸”ç»“åˆä¸¤ä¸ªåç»­ç¥ç»æ¨¡å‹ä¸­çš„ä¿¡æ¯)ï¼Œå…¶ä¸­ä¸€ä¸ªæ¨¡å‹è´Ÿè´£ç”Ÿæˆå®¹é‡å¯†åº¦)ï¼Œå¦ä¸€ä¸ªæ¨¡å‹è´Ÿè´£ç”Ÿæˆç”¨äºæ¸²æŸ“åœºæ™¯çš„é¢œè‰²)ã€‚å®éªŒç»“æœè¡¨æ˜)ï¼ŒBioNeRF åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„è´¨é‡è¯„ä¼°æ–¹é¢è¶…è¶Šç°æœ‰æŠ€æœ¯)ï¼Œè¿™äº›æ•°æ®é›†åŒ…æ‹¬çœŸå®ä¸–ç•Œå›¾åƒä»¥åŠåˆæˆæ•°æ®)ã€‚</p><p></p>
<p></p><p>æ‘˜è¦ï¼š(BioNeRFæ˜¯ä¸€ç§ç”Ÿç‰©åˆç†æ¶æ„)ï¼Œå¯ä»¥åˆ©ç”¨è¾å°„å­—æ®µæ„å»ºåœºæ™¯çš„ä¸‰ D è¡¨ç¤ºå½¢å¼å¹¶ä¸”åˆæˆæ–°çš„è§†å›¾)ã€‚ç”±äº NeRF åˆ©ç”¨ç½‘ç»œä¸­çš„å„ç§å‚æ•°å­˜å‚¨åœºæ™¯çš„ä¸‰ D è¡¨ç¤ºå½¢å¼)ï¼ŒBioNeRF ä¾¿é‡‡ç”¨ä¸€ç§è®¤çŸ¥æ¿€åŠ±æ–¹æ³•)ï¼Œé€šè¿‡èåˆå¤šä¸ªæ¥æºä¸­çš„ä¿¡æ¯ç”Ÿæˆè®°å¿†ç»“æ„)ï¼Œä»è€Œæé«˜å‚¨å­˜å®¹é‡å¹¶ä¸”æå–æ›´å¤šæœ¬è´¨ä¿¡æ¯ä»¥åŠç›¸å…³ä¿¡æ¯)ã€‚BioNeRF è¿˜æ¨¡ä»¿é”¥ä½“å‹ç¥ç»ç»†èƒæœ‰å…³ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¡Œä¸º)ï¼Œå…¶ä¸­è®°å¿†ä½œä¸ºä¸Šä¸‹æ–‡æä¾›)ï¼Œå¹¶ä¸”ç»“åˆä¸¤ä¸ªåç»­ç¥ç»æ¨¡å‹ä¸­çš„ä¿¡æ¯)ï¼Œå…¶ä¸­ä¸€ä¸ªæ¨¡å‹è´Ÿè´£ç”Ÿæˆå®¹é‡å¯†åº¦)ï¼Œå¦ä¸€ä¸ªæ¨¡å‹è´Ÿè´£ç”Ÿæˆç”¨äºæ¸²æŸ“åœºæ™¯çš„é¢œè‰²)ã€‚å®éªŒç»“æœè¡¨æ˜)ï¼ŒBioNeRF åœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„è´¨é‡è¯„ä¼°æ–¹é¢è¶…è¶Šç°æœ‰æŠ€æœ¯)ï¼Œè¿™äº›æ•°æ®é›†åŒ…æ‹¬çœŸå®ä¸–ç•Œå›¾åƒä»¥åŠåˆæˆæ•°æ®)ã€‚</p><p></p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰BioNeRFé‡‡ç”¨è®¤çŸ¥å¯å‘çš„æ–¹æ³•ï¼Œé€šè¿‡èåˆå¤šä¸ªæ¥æºä¸­çš„ä¿¡æ¯ç”Ÿæˆè®°å¿†ç»“æ„ï¼Œä»è€Œæé«˜å­˜å‚¨å®¹é‡å¹¶æå–æ›´å¤šæœ¬è´¨ä¿¡æ¯å’Œç›¸å…³ä¿¡æ¯ã€‚
ï¼ˆ2ï¼‰BioNeRFæ¨¡ä»¿é”¥ä½“å‹ç¥ç»ç»†èƒæœ‰å…³ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¡Œä¸ºï¼Œå…¶ä¸­è®°å¿†ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ï¼Œå¹¶ç»“åˆä¸¤ä¸ªåç»­ç¥ç»æ¨¡å‹ä¸­çš„ä¿¡æ¯ï¼Œå…¶ä¸­ä¸€ä¸ªæ¨¡å‹è´Ÿè´£ç”Ÿæˆå®¹é‡å¯†åº¦ï¼Œå¦ä¸€ä¸ªæ¨¡å‹è´Ÿè´£ç”Ÿæˆç”¨äºæ¸²æŸ“åœºæ™¯çš„é¢œè‰²ã€‚
ï¼ˆ3ï¼‰å®éªŒç»“æœè¡¨æ˜ï¼ŒBioNeRFåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„è´¨é‡è¯„ä¼°æ–¹é¢è¶…è¶Šç°æœ‰æŠ€æœ¯ï¼Œè¿™äº›æ•°æ®é›†åŒ…æ‹¬çœŸå®ä¸–ç•Œå›¾åƒä»¥åŠåˆæˆæ•°æ®ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šBioNeRFåœ¨ç¥ç»æ¸²æŸ“é¢†åŸŸå–å¾—äº†é‡å¤§çªç ´ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ç”Ÿç‰©åˆç†ç¥ç»è¾å°„åœºæ¶æ„ï¼Œè¯¥æ¶æ„èƒ½å¤Ÿåˆ©ç”¨è¾å°„å­—æ®µæ„å»ºåœºæ™¯çš„ä¸‰ç»´è¡¨ç¤ºå½¢å¼å¹¶åˆæˆæ–°çš„è§†å›¾ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>BioNeRFé‡‡ç”¨äº†ä¸€ç§è®¤çŸ¥å¯å‘çš„æ–¹æ³•ï¼Œé€šè¿‡èåˆå¤šä¸ªæ¥æºä¸­çš„ä¿¡æ¯ç”Ÿæˆè®°å¿†ç»“æ„ï¼Œä»è€Œæé«˜å­˜å‚¨å®¹é‡å¹¶æå–æ›´å¤šæœ¬è´¨ä¿¡æ¯å’Œç›¸å…³ä¿¡æ¯ã€‚</li>
<li>BioNeRFæ¨¡ä»¿é”¥ä½“å‹ç¥ç»ç»†èƒæœ‰å…³ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¡Œä¸ºï¼Œå…¶ä¸­è®°å¿†ä½œä¸ºä¸Šä¸‹æ–‡æä¾›ï¼Œå¹¶ç»“åˆä¸¤ä¸ªåç»­ç¥ç»æ¨¡å‹ä¸­çš„ä¿¡æ¯ï¼Œå…¶ä¸­ä¸€ä¸ªæ¨¡å‹è´Ÿè´£ç”Ÿæˆå®¹é‡å¯†åº¦ï¼Œå¦ä¸€ä¸ªæ¨¡å‹è´Ÿè´£ç”Ÿæˆç”¨äºæ¸²æŸ“åœºæ™¯çš„é¢œè‰²ã€‚</li>
<li>BioNeRFåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„è´¨é‡è¯„ä¼°æ–¹é¢è¶…è¶Šç°æœ‰æŠ€æœ¯ï¼Œè¿™äº›æ•°æ®é›†åŒ…æ‹¬çœŸå®ä¸–ç•Œå›¾åƒä»¥åŠåˆæˆæ•°æ®ã€‚
æ€§èƒ½ï¼š</li>
<li>BioNeRFåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸­çš„è´¨é‡è¯„ä¼°æ–¹é¢è¶…è¶Šç°æœ‰æŠ€æœ¯ï¼Œè¿™äº›æ•°æ®é›†åŒ…æ‹¬çœŸå®ä¸–ç•Œå›¾åƒä»¥åŠåˆæˆæ•°æ®ã€‚
å·¥ä½œé‡ï¼š</li>
<li>BioNeRFçš„å®ç°éš¾åº¦è¾ƒé«˜ï¼Œéœ€è¦è¾ƒå¼ºçš„ç¼–ç¨‹èƒ½åŠ›å’Œæ•°å­¦åŸºç¡€ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a3147366d087ebe11e207f5d9173f950.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-91083b7a4d33cafbb989e6672e5d0690.jpg" align="middle">
</details>




<h2 id="NCRF-Neural-Contact-Radiance-Fields-for-Free-Viewpoint-Rendering-of-Hand-Object-Interaction"><a href="#NCRF-Neural-Contact-Radiance-Fields-for-Free-Viewpoint-Rendering-of-Hand-Object-Interaction" class="headerlink" title="NCRF: Neural Contact Radiance Fields for Free-Viewpoint Rendering of   Hand-Object Interaction"></a>NCRF: Neural Contact Radiance Fields for Free-Viewpoint Rendering of   Hand-Object Interaction</h2><p><strong>Authors:Zhongqun Zhang, Jifei Song, Eduardo PÃ©rez-Pellitero, Yiren Zhou, Hyung Jin Chang, AleÅ¡ Leonardis</strong></p>
<p>Modeling hand-object interactions is a fundamentally challenging task in 3D computer vision. Despite remarkable progress that has been achieved in this field, existing methods still fail to synthesize the hand-object interaction photo-realistically, suffering from degraded rendering quality caused by the heavy mutual occlusions between the hand and the object, and inaccurate hand-object pose estimation. To tackle these challenges, we present a novel free-viewpoint rendering framework, Neural Contact Radiance Field (NCRF), to reconstruct hand-object interactions from a sparse set of videos. In particular, the proposed NCRF framework consists of two key components: (a) A contact optimization field that predicts an accurate contact field from 3D query points for achieving desirable contact between the hand and the object. (b) A hand-object neural radiance field to learn an implicit hand-object representation in a static canonical space, in concert with the specifically designed hand-object motion field to produce observation-to-canonical correspondences. We jointly learn these key components where they mutually help and regularize each other with visual and geometric constraints, producing a high-quality hand-object reconstruction that achieves photo-realistic novel view synthesis. Extensive experiments on HO3D and DexYCB datasets show that our approach outperforms the current state-of-the-art in terms of both rendering quality and pose estimation accuracy. </p>
<p><a href="http://arxiv.org/abs/2402.05532v2">PDF</a> Accepted by 3DV 2024</p>
<p><strong>Summary</strong><br>æ‰‹-ç‰©äº¤äº’çš„è‡ªç”±è§†è§’é€¼çœŸé‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰‹-ç‰©äº¤äº’å»ºæ¨¡æ˜¯è®¡ç®—æœºä¸‰ç»´å»ºæ¨¡çš„æŒ‘æˆ˜æ€§ä»»åŠ¡ã€‚</li>
<li>ç°å­˜æ–¹æ³•æ— æ³•çœŸå®åœ°è¿›è¡Œæ‰‹-ç‰©äº¤äº’å»ºæ¨¡ã€‚</li>
<li>æå‡º NCRF æ¡†æ¶æ¥ä»è§†é¢‘ä¸­é‡å»ºæ‰‹-ç‰©äº¤äº’ã€‚</li>
<li>NCRF åŒ…æ‹¬æ¥è§¦ä¼˜åŒ–åœºå’Œæ‰‹-ç‰©çš„ç¥ç»è¾å°„åœºã€‚</li>
<li>æ¥è§¦ä¼˜åŒ–åœºé¢„æµ‹ä¸‰ç»´æŸ¥è¯¢ç‚¹ç²¾ç¡®çš„æ¥è§¦åœºã€‚</li>
<li>æ‰‹-ç‰©çš„ç¥ç»è¾å°„åœºå­¦ä¹ æ‰‹-ç‰©éšå¼è¡¨ç¤ºã€‚</li>
<li>æ‰‹-ç‰©è¿åŠ¨åœºäº§ç”Ÿè§‚å¯Ÿåˆ°æ ‡å‡†çš„å¯¹åº”å…³ç³»ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šNCRFï¼šç”¨äºæ‰‹-ç‰©ä½“äº¤äº’è‡ªç”±è§†ç‚¹æ¸²æŸ“çš„ç¥ç»æ¥è§¦è¾å°„åœº</li>
<li>ä½œè€…ï¼šZhongqun Zhang, Jifei Song, Eduardo PÃ©rez-Pellitero, Yiren Zhou, Hyung Jin Chang, AleÅ¡ Leonardis</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¼¯æ˜ç¿°å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ‰‹-ç‰©ä½“äº¤äº’ã€è‡ªç”±è§†ç‚¹æ¸²æŸ“ã€ç¥ç»è¾å°„åœºã€æ¥è§¦åœºä¼˜åŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.05532</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰‹-ç‰©ä½“äº¤äº’å»ºæ¨¡æ˜¯è®¡ç®—æœºè§†è§‰ä¸­ä¸€é¡¹æå…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚å°½ç®¡è¯¥é¢†åŸŸå–å¾—äº†æ˜¾ç€è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•ä»ç„¶æ— æ³•ä»¥é€¼çœŸçš„æ–¹å¼åˆæˆæ‰‹-ç‰©ä½“äº¤äº’ï¼Œè¿™æºäºæ‰‹å’Œç‰©ä½“ä¹‹é—´ä¸¥é‡çš„ç›¸äº’é®æŒ¡ä»¥åŠä¸å‡†ç¡®çš„æ‰‹-ç‰©ä½“å§¿æ€ä¼°è®¡ï¼Œä»è€Œå¯¼è‡´æ¸²æŸ“è´¨é‡ä¸‹é™ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€å·¥ä½œé€šå¸¸å°†æ­¤ä»»åŠ¡è¡¨è¿°ä¸ºè”åˆæ‰‹å’Œç‰©ä½“å§¿æ€ä¼°è®¡é—®é¢˜ï¼Œå¹¶ä¾èµ–å‚æ•°åŒ–çš„æ‰‹-ç‰©ä½“æ¨¡å‹ï¼ˆå¦‚ MANO å’Œ YCBï¼‰æ¥ä¼°è®¡æ‰‹çš„è¿åŠ¨å˜æ¢ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æ¢å¤æ‰‹-ç‰©ä½“æ¥è§¦åœºçš„å‡†ç¡®å‡ ä½•å½¢çŠ¶ï¼Œå¹¶ä¸”æ¸²æŸ“è´¨é‡å—åˆ°é®æŒ¡å’Œå§¿æ€ä¼°è®¡è¯¯å·®çš„ä¸¥é‡å½±å“ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç”±è§†ç‚¹æ¸²æŸ“æ¡†æ¶â€”â€”ç¥ç»æ¥è§¦è¾å°„åœºï¼ˆNCRFï¼‰ï¼Œä»¥ä»ä¸€ç»„ç¨€ç–è§†é¢‘ä¸­é‡å»ºæ‰‹-ç‰©ä½“äº¤äº’ã€‚NCRF æ¡†æ¶ä¸»è¦ç”±ä¸¤ä¸ªå…³é”®ç»„ä»¶ç»„æˆï¼šï¼ˆaï¼‰æ¥è§¦ä¼˜åŒ–åœºï¼šä» 3D æŸ¥è¯¢ç‚¹é¢„æµ‹å‡†ç¡®çš„æ¥è§¦åœºï¼Œä»¥å®ç°æ‰‹å’Œç‰©ä½“ä¹‹é—´çš„ç†æƒ³æ¥è§¦ã€‚ï¼ˆbï¼‰æ‰‹-ç‰©ä½“ç¥ç»è¾å°„åœºï¼šä¸ä¸“é—¨è®¾è®¡çš„æ‰‹-ç‰©ä½“è¿åŠ¨åœºååŒå·¥ä½œï¼Œå­¦ä¹ é™æ€è§„èŒƒç©ºé—´ä¸­çš„éšå¼æ‰‹-ç‰©ä½“è¡¨ç¤ºï¼Œä»¥äº§ç”Ÿè§‚æµ‹åˆ°è§„èŒƒçš„å¯¹åº”å…³ç³»ã€‚æˆ‘ä»¬è”åˆå­¦ä¹ è¿™äº›å…³é”®ç»„ä»¶ï¼Œå®ƒä»¬é€šè¿‡è§†è§‰å’Œå‡ ä½•çº¦æŸç›¸äº’å¸®åŠ©å’Œæ­£åˆ™åŒ–ï¼Œä»è€Œäº§ç”Ÿé«˜è´¨é‡çš„æ‰‹-ç‰©ä½“é‡å»ºï¼Œå®ç°é€¼çœŸçš„æ–°è§†è§’åˆæˆã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼Œè¿™äº›æ€§èƒ½æ˜¯å¦æ”¯æŒäº†å®ƒä»¬çš„ç›®æ ‡ï¼šåœ¨ HO3D å’Œ Dex-YCB æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¸²æŸ“è´¨é‡å’Œå§¿æ€ä¼°è®¡ç²¾åº¦æ–¹é¢å‡ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³ä»¥é€¼çœŸçš„æ–¹å¼é‡å»ºå’Œæ¸²æŸ“æ‰‹-ç‰©ä½“äº¤äº’ã€‚</p>
</li>
<li>
<p>Methods:
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç”±è§†ç‚¹æ¸²æŸ“æ¡†æ¶â€”â€”ç¥ç»æ¥è§¦è¾å°„åœºï¼ˆNCRFï¼‰ï¼Œä»¥ä»ä¸€ç»„ç¨€ç–è§†é¢‘ä¸­é‡å»ºæ‰‹-ç‰©ä½“äº¤äº’ã€‚
(2): NCRFæ¡†æ¶ä¸»è¦ç”±ä¸¤ä¸ªå…³é”®ç»„ä»¶ç»„æˆï¼šï¼ˆaï¼‰æ¥è§¦ä¼˜åŒ–åœºï¼šä»3DæŸ¥è¯¢ç‚¹é¢„æµ‹å‡†ç¡®çš„æ¥è§¦åœºï¼Œä»¥å®ç°æ‰‹å’Œç‰©ä½“ä¹‹é—´çš„ç†æƒ³æ¥è§¦ã€‚ï¼ˆbï¼‰æ‰‹-ç‰©ä½“ç¥ç»è¾å°„åœºï¼šä¸ä¸“é—¨è®¾è®¡çš„æ‰‹-ç‰©ä½“è¿åŠ¨åœºååŒå·¥ä½œï¼Œå­¦ä¹ é™æ€è§„èŒƒç©ºé—´ä¸­çš„éšå¼æ‰‹-ç‰©ä½“è¡¨ç¤ºï¼Œä»¥äº§ç”Ÿè§‚æµ‹åˆ°è§„èŒƒçš„å¯¹åº”å…³ç³»ã€‚
(3): æˆ‘ä»¬è”åˆå­¦ä¹ è¿™äº›å…³é”®ç»„ä»¶ï¼Œå®ƒä»¬é€šè¿‡è§†è§‰å’Œå‡ ä½•çº¦æŸç›¸äº’å¸®åŠ©å’Œæ­£åˆ™åŒ–ï¼Œä»è€Œäº§ç”Ÿé«˜è´¨é‡çš„æ‰‹-ç‰©ä½“é‡å»ºï¼Œå®ç°é€¼çœŸçš„æ–°è§†è§’åˆæˆã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç”±è§†ç‚¹æ¸²æŸ“æ¡†æ¶â€”â€”ç¥ç»æ¥è§¦è¾å°„åœºï¼ˆNCRFï¼‰ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä»ä¸€ç»„ç¨€ç–è§†é¢‘ä¸­é‡å»ºæ‰‹-ç‰©ä½“äº¤äº’ï¼Œå¹¶ç”Ÿæˆé€¼çœŸçš„æ–°è§†è§’åˆæˆã€‚NCRFæ¡†æ¶é€šè¿‡è®¾è®¡åŠ¨æ€æ‰‹-ç‰©ä½“ç¥ç»è¾å°„åœºå’Œæ¥è§¦ä¼˜åŒ–åœºï¼Œèƒ½å¤Ÿå»ºæ¨¡å…·æœ‰å¤æ‚æ‰‹éƒ¨æŠ“æ¡åŠ¨ä½œå’Œé¢‘ç¹ç›¸äº’é®æŒ¡çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æ‰‹-ç‰©ä½“äº¤äº’ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç”±è§†ç‚¹æ¸²æŸ“æ¡†æ¶â€”â€”ç¥ç»æ¥è§¦è¾å°„åœºï¼ˆNCRFï¼‰ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä»ä¸€ç»„ç¨€ç–è§†é¢‘ä¸­é‡å»ºæ‰‹-ç‰©ä½“äº¤äº’ï¼Œå¹¶ç”Ÿæˆé€¼çœŸçš„æ–°è§†è§’åˆæˆã€‚</li>
<li>è®¾è®¡äº†åŠ¨æ€æ‰‹-ç‰©ä½“ç¥ç»è¾å°„åœºå’Œæ¥è§¦ä¼˜åŒ–åœºï¼Œèƒ½å¤Ÿå»ºæ¨¡å…·æœ‰å¤æ‚æ‰‹éƒ¨æŠ“æ¡åŠ¨ä½œå’Œé¢‘ç¹ç›¸äº’é®æŒ¡çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æ‰‹-ç‰©ä½“äº¤äº’ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ‰‹-ç‰©ä½“å˜å½¢æ¨¡å—ï¼Œè¯¥æ¨¡å—èƒ½å¤Ÿå°†å°„çº¿å˜å½¢åˆ°è§„èŒƒç©ºé—´ä¸­ï¼Œå¹¶ä»¥é€¼çœŸçš„æ–¹å¼æ¸²æŸ“æ‰‹-ç‰©ä½“äº¤äº’ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨HO3Då’ŒDex-YCBæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒNCRFæ¡†æ¶åœ¨æ¸²æŸ“è´¨é‡å’Œå§¿æ€ä¼°è®¡ç²¾åº¦æ–¹é¢å‡ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>NCRFæ¡†æ¶èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„æ–°è§†è§’åˆæˆï¼Œå¹¶ä¸”èƒ½å¤Ÿå¾ˆå¥½åœ°å¤„ç†å…·æœ‰å¤æ‚æ‰‹éƒ¨æŠ“æ¡åŠ¨ä½œå’Œé¢‘ç¹ç›¸äº’é®æŒ¡çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æ‰‹-ç‰©ä½“äº¤äº’ã€‚
å·¥ä½œé‡ï¼š</li>
<li>NCRFæ¡†æ¶çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºã€‚</li>
<li>NCRFæ¡†æ¶çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå¹¶ä¸”éœ€è¦å¤§é‡çš„æ•°æ®ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-19c080ef42e2fcaa0595e65274d339b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b7f0899ff9371cac98ca44ab3913a349.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1403a98bc963e537484ce413bb5d32ea.jpg" align="middle">
</details>




<h2 id="BirdNeRF-Fast-Neural-Reconstruction-of-Large-Scale-Scenes-From-Aerial-Imagery"><a href="#BirdNeRF-Fast-Neural-Reconstruction-of-Large-Scale-Scenes-From-Aerial-Imagery" class="headerlink" title="BirdNeRF: Fast Neural Reconstruction of Large-Scale Scenes From Aerial   Imagery"></a>BirdNeRF: Fast Neural Reconstruction of Large-Scale Scenes From Aerial   Imagery</h2><p><strong>Authors:Huiqing Zhang, Yifei Xue, Ming Liao, Yizhen Lao</strong></p>
<p>In this study, we introduce BirdNeRF, an adaptation of Neural Radiance Fields (NeRF) designed specifically for reconstructing large-scale scenes using aerial imagery. Unlike previous research focused on small-scale and object-centric NeRF reconstruction, our approach addresses multiple challenges, including (1) Addressing the issue of slow training and rendering associated with large models. (2) Meeting the computational demands necessitated by modeling a substantial number of images, requiring extensive resources such as high-performance GPUs. (3) Overcoming significant artifacts and low visual fidelity commonly observed in large-scale reconstruction tasks due to limited model capacity. Specifically, we present a novel bird-view pose-based spatial decomposition algorithm that decomposes a large aerial image set into multiple small sets with appropriately sized overlaps, allowing us to train individual NeRFs of sub-scene. This decomposition approach not only decouples rendering time from the scene size but also enables rendering to scale seamlessly to arbitrarily large environments. Moreover, it allows for per-block updates of the environment, enhancing the flexibility and adaptability of the reconstruction process. Additionally, we propose a projection-guided novel view re-rendering strategy, which aids in effectively utilizing the independently trained sub-scenes to generate superior rendering results. We evaluate our approach on existing datasets as well as against our own drone footage, improving reconstruction speed by 10x over classical photogrammetry software and 50x over state-of-the-art large-scale NeRF solution, on a single GPU with similar rendering quality. </p>
<p><a href="http://arxiv.org/abs/2402.04554v2">PDF</a> </p>
<p><strong>Summary</strong><br>å¯¹äºå¤§åœºæ™¯ä¸‹çš„é‡å»ºä»»åŠ¡ï¼Œæœ¬æ–‡å¼•å…¥ BirdNeRFï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨æ— äººæœºå½±åƒæ•°æ®å®ç°é«˜æ•ˆä½å­˜å‚¨çš„å¤§åœºæ™¯é‡å»ºã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>BirdNeRF æ˜¯ä¸€æ¬¾é’ˆå¯¹èˆªç©ºå›¾åƒçš„å¤§åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œè§£å†³äº†ä»¥å¾€å°åœºæ™¯é‡å»ºå­˜åœ¨çš„è®­ç»ƒæ…¢ã€æ¸²æŸ“æ…¢ã€æ¨¡å‹å®¹é‡å°ç­‰é—®é¢˜ã€‚</li>
<li>BirdNeRF æå‡ºäº†ä¸€ç§åŸºäºé¸Ÿç°è§†è§’çš„å§¿åŠ¿åˆ†è§£ç®—æ³•ï¼Œå°†å¤§åœºæ™¯å›¾åƒé›†åˆ†è§£æˆå¤šä¸ªå°åœºæ™¯å­é›†ï¼Œæ¯ä¸ªå­é›†ä½¿ç”¨å•ç‹¬çš„ NeRF è¿›è¡Œè®­ç»ƒã€‚</li>
<li>BirdNeRF é‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„æŠ•å½±å¼•å¯¼å¼æ–°è§†è§’é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåˆ©ç”¨ç‹¬ç«‹è®­ç»ƒçš„å­åœºæ™¯ç”Ÿæˆæ›´å¥½çš„æ¸²æŸ“ç»“æœã€‚</li>
<li>BirdNeRF åœ¨ç°æœ‰æ•°æ®é›†å’Œæˆ‘ä»¬è‡ªå·±çš„æ— äººæœºæ•°æ®ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œåœ¨å•ä¸ª GPU ä¸Šçš„é‡å»ºé€Ÿåº¦æ¯”ç»å…¸æ‘„å½±æµ‹é‡è½¯ä»¶å¿« 10 å€ï¼Œæ¯”æœ€å…ˆè¿›çš„å¤§åœºæ™¯ NeRF è§£å†³æ–¹æ¡ˆå¿« 50 å€ï¼Œä¸”æ¸²æŸ“è´¨é‡ç›¸ä¼¼ã€‚</li>
<li>BirdNeRF å¯ä»¥åœ¨ä»»æ„å¤§çš„åœºæ™¯ä¸­æ— ç¼æ‰©å±•ï¼Œå¹¶æ”¯æŒå¯¹ç¯å¢ƒçš„å±€éƒ¨æ›´æ–°ï¼Œæé«˜äº†é‡å»ºè¿‡ç¨‹çš„çµæ´»æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šBirdNeRFï¼šåŸºäºèˆªæ‹å›¾åƒçš„å¤§åœºæ™¯å¿«é€Ÿç¥ç»é‡å»º</li>
<li>ä½œè€…ï¼šå¼ æƒ å¿ã€è–›ä¸€è²ã€å»–æ˜ã€è€ä¹‰ç</li>
<li>å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šNeRFã€å¤§åœºæ™¯é‡å»ºã€èˆªæ‹å›¾åƒã€ç©ºé—´åˆ†è§£ã€æŠ•å½±å¼•å¯¼</li>
<li>é“¾æ¥ï¼šæ— ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤§åœºæ™¯ä¸‰ç»´é‡å»ºæ˜¯æ‘„å½±æµ‹é‡å’Œé¥æ„Ÿé¢†åŸŸçš„ä¸€é¡¹é‡è¦ä»»åŠ¡ï¼Œå¯ä»¥åˆ©ç”¨èˆªæ‹æˆ–å«æ˜Ÿå›¾åƒã€æ¿€å…‰é›·è¾¾æ•°æ®å’Œè¡—æ™¯å›¾åƒç­‰å¤šç§æ•°æ®æºæ„å»ºåŸå¸‚çš„ä¸‰ç»´æ¨¡å‹ã€‚è¿‘å¹´æ¥ï¼ŒåŸºäºå›¾åƒçš„ä¸‰ç»´é‡å»ºæŠ€æœ¯å–å¾—äº†å¾ˆå¤§çš„è¿›å±•ï¼Œå¹¶åœ¨åŸå¸‚è§„åˆ’ã€å¯¼èˆªã€è™šæ‹Ÿæ—…æ¸¸ã€æˆ¿åœ°äº§ã€ç¾å®³ç®¡ç†å’Œå†å²ä¿æŠ¤ç­‰é¢†åŸŸå¾—åˆ°äº†å¹¿æ³›çš„åº”ç”¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šç°æœ‰çš„åŸºäºå›¾åƒçš„ä¸‰ç»´é‡å»ºæŠ€æœ¯ä¸»è¦åˆ†ä¸ºä¼ ç»Ÿå‡ ä½•æ–¹æ³•å’ŒåŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ã€‚ä¼ ç»Ÿå‡ ä½•æ–¹æ³•ä¸»è¦åŒ…æ‹¬æ‘„å½±æµ‹é‡å’Œæ¿€å…‰æ‰«æï¼Œè¿™äº›æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜ç²¾åº¦çš„ä¸‰ç»´æ¨¡å‹ï¼Œä½†éœ€è¦å¤§é‡çš„äººå·¥å‚ä¸å’Œæ˜‚è´µçš„è®¾å¤‡ã€‚åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•ï¼Œå¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œå¯ä»¥ä»å›¾åƒä¸­è‡ªåŠ¨å­¦ä¹ ä¸‰ç»´åœºæ™¯çš„è¡¨ç¤ºï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”åœ¨å¤§åœºæ™¯é‡å»ºä»»åŠ¡ä¸­å®¹æ˜“å‡ºç°ä¼ªå½±å’Œä½è§†è§‰ä¿çœŸåº¦çš„é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäº NeRF çš„å¤§åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œç§°ä¸º BirdNeRFã€‚BirdNeRF é‡‡ç”¨äº†ä¸€ç§æ–°çš„é¸Ÿç°è§†è§’å§¿åŠ¿åˆ†è§£ç®—æ³•ï¼Œå°†å¤§åœºæ™¯å›¾åƒåˆ†è§£æˆå¤šä¸ªå°åœºæ™¯ï¼Œå¹¶åˆ†åˆ«è®­ç»ƒæ¯ä¸ªå°åœºæ™¯çš„ NeRF æ¨¡å‹ã€‚è¿™ç§åˆ†è§£æ–¹æ³•ä¸ä»…å¯ä»¥å‡å°‘è®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´ï¼Œè¿˜å¯ä»¥æé«˜é‡å»ºçš„è´¨é‡ã€‚æ­¤å¤–ï¼ŒBirdNeRF è¿˜æå‡ºäº†ä¸€ç§æŠ•å½±å¼•å¯¼çš„æ–°è§†è§’é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨ç‹¬ç«‹è®­ç»ƒçš„å°åœºæ™¯æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„æ¸²æŸ“ç»“æœã€‚
ï¼ˆ4ï¼‰æ€§èƒ½ä¸ç›®æ ‡ï¼šBirdNeRF åœ¨ç°æœ‰æ•°æ®é›†å’Œæˆ‘ä»¬è‡ªå·±çš„æ— äººæœºèˆªæ‹æ•°æ®ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼ŒBirdNeRF çš„é‡å»ºé€Ÿåº¦æ¯”ä¼ ç»Ÿçš„æ‘„å½±æµ‹é‡è½¯ä»¶å¿« 10 å€ï¼Œæ¯”æœ€å…ˆè¿›çš„å¤§åœºæ™¯ NeRF è§£å†³æ–¹æ¡ˆå¿« 50 å€ï¼Œå¹¶ä¸”åœ¨å•ä¸ª GPU ä¸Šå¯ä»¥å®ç°ç›¸ä¼¼çš„æ¸²æŸ“è´¨é‡ã€‚è¿™äº›ç»“æœè¯æ˜äº† BirdNeRF çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰åœºæ™¯åˆ†è§£ï¼šå°†å¤§åœºæ™¯å›¾åƒåˆ†è§£æˆå¤šä¸ªå°åœºæ™¯ï¼Œå¹¶åˆ†åˆ«è®­ç»ƒæ¯ä¸ªå°åœºæ™¯çš„ NeRF æ¨¡å‹ã€‚
ï¼ˆ2ï¼‰è§†è§’å§¿åŠ¿åˆ†è§£ï¼šé‡‡ç”¨é¸Ÿç°è§†è§’å§¿åŠ¿åˆ†è§£ç®—æ³•ï¼Œå°†å¤§åœºæ™¯å›¾åƒåˆ†è§£æˆå¤šä¸ªå°åœºæ™¯ã€‚
ï¼ˆ3ï¼‰æ–°è§†è§’é‡æ–°æ¸²æŸ“ï¼šæå‡ºä¸€ç§æŠ•å½±å¼•å¯¼çš„æ–°è§†è§’é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨ç‹¬ç«‹è®­ç»ƒçš„å°åœºæ™¯æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„æ¸²æŸ“ç»“æœã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäº NeRF çš„å¤§åœºæ™¯é‡å»ºæ–¹æ³• BirdNeRFï¼Œè¯¥æ–¹æ³•é‡‡ç”¨é¸Ÿç°è§†è§’å§¿åŠ¿åˆ†è§£ç®—æ³•å’ŒæŠ•å½±å¼•å¯¼çš„æ–°è§†è§’é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°è§£å†³å¤§åœºæ™¯é‡å»ºä»»åŠ¡ä¸­å®¹æ˜“å‡ºç°ä¼ªå½±å’Œä½è§†è§‰ä¿çœŸåº¦çš„é—®é¢˜ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é¸Ÿç°è§†è§’å§¿åŠ¿åˆ†è§£ç®—æ³•ï¼Œå¯ä»¥å°†å¤§åœºæ™¯å›¾åƒåˆ†è§£æˆå¤šä¸ªå°åœºæ™¯ï¼Œå¹¶åˆ†åˆ«è®­ç»ƒæ¯ä¸ªå°åœºæ™¯çš„ NeRF æ¨¡å‹ï¼Œä»è€Œå‡å°‘è®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´ï¼Œæé«˜é‡å»ºè´¨é‡ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æŠ•å½±å¼•å¯¼çš„æ–°è§†è§’é‡æ–°æ¸²æŸ“ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨ç‹¬ç«‹è®­ç»ƒçš„å°åœºæ™¯æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„æ¸²æŸ“ç»“æœã€‚
æ€§èƒ½ï¼š</li>
<li>BirdNeRF åœ¨ç°æœ‰æ•°æ®é›†å’Œæˆ‘ä»¬è‡ªå·±çš„æ— äººæœºèˆªæ‹æ•°æ®ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼ŒBirdNeRF çš„é‡å»ºé€Ÿåº¦æ¯”ä¼ ç»Ÿçš„æ‘„å½±æµ‹é‡è½¯ä»¶å¿« 10 å€ï¼Œæ¯”æœ€å…ˆè¿›çš„å¤§åœºæ™¯ NeRF è§£å†³æ–¹æ¡ˆå¿« 50 å€ï¼Œå¹¶ä¸”åœ¨å•ä¸ª GPU ä¸Šå¯ä»¥å®ç°ç›¸ä¼¼çš„æ¸²æŸ“è´¨é‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>BirdNeRF çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å•ä¸ª GPU ä¸Šè®­ç»ƒå’Œæ¸²æŸ“ã€‚ç„¶è€Œï¼Œç”±äºéœ€è¦å¯¹å¤§åœºæ™¯å›¾åƒè¿›è¡Œåˆ†è§£ï¼Œå› æ­¤ BirdNeRF çš„é¢„å¤„ç†æ—¶é—´å¯èƒ½ä¼šæ¯”è¾ƒé•¿ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a5c73ab0e2d97eb040012ca4a7c897fe.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-daadce77f0b48dc25dd984f5c66ee7ac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6d52642c6cfdc84439f5ea843cff2fd1.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/02/13/Paper/2024-02-13/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-13-æ›´æ–°"><a href="#2024-02-13-æ›´æ–°" class="headerlink" title="2024-02-13 æ›´æ–°"></a>2024-02-13 æ›´æ–°</h1><h2 id="Synthesizing-CTA-Image-Data-for-Type-B-Aortic-Dissection-using-Stable-Diffusion-Models"><a href="#Synthesizing-CTA-Image-Data-for-Type-B-Aortic-Dissection-using-Stable-Diffusion-Models" class="headerlink" title="Synthesizing CTA Image Data for Type-B Aortic Dissection using Stable   Diffusion Models"></a>Synthesizing CTA Image Data for Type-B Aortic Dissection using Stable   Diffusion Models</h2><p><strong>Authors:Ayman Abaid, Muhammad Ali Farooq, Niamh Hynes, Peter Corcoran, Ihsan Ullah</strong></p>
<p>Stable Diffusion (SD) has gained a lot of attention in recent years in the field of Generative AI thus helping in synthesizing medical imaging data with distinct features. The aim is to contribute to the ongoing effort focused on overcoming the limitations of data scarcity and improving the capabilities of ML algorithms for cardiovascular image processing. Therefore, in this study, the possibility of generating synthetic cardiac CTA images was explored by fine-tuning stable diffusion models based on user defined text prompts, using only limited number of CTA images as input. A comprehensive evaluation of the synthetic data was conducted by incorporating both quantitative analysis and qualitative assessment, where a clinician assessed the quality of the generated data. It has been shown that Cardiac CTA images can be successfully generated using using Text to Image (T2I) stable diffusion model. The results demonstrate that the tuned T2I CTA diffusion model was able to generate images with features that are typically unique to acute type B aortic dissection (TBAD) medical conditions. </p>
<p><a href="http://arxiv.org/abs/2402.06969v1">PDF</a> Submitted in IEEE EMBC 2024 Conference</p>
<p><strong>Summary</strong><br>ç¨³å®šæ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦æˆåƒæ•°æ®åˆæˆä¸­å±•ç°å‡ºå¼ºå¤§èƒ½åŠ›ï¼Œæœ‰æœ›è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼ŒåŠ©åŠ›å¿ƒè¡€ç®¡å›¾åƒå¤„ç†é¢†åŸŸçš„å‘å±•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¨³å®šæ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦æˆåƒæ•°æ®åˆæˆä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œå¯ç”¨äºè§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚</li>
<li>é€šè¿‡å¾®è°ƒç”¨æˆ·å®šä¹‰æ–‡æœ¬æç¤ºçš„ç¨³å®šæ‰©æ•£æ¨¡å‹ï¼Œä»…ä½¿ç”¨æœ‰é™æ•°é‡çš„ CTA å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå³å¯ç”Ÿæˆåˆæˆçš„å† çŠ¶åŠ¨è„‰ CTA å›¾åƒã€‚</li>
<li>å®šé‡åˆ†æå’Œå®šæ€§è¯„ä¼°ç›¸ç»“åˆçš„ç»¼åˆè¯„ä¼°è¡¨æ˜ï¼Œä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒ (T2I) ç¨³å®šæ‰©æ•£æ¨¡å‹å¯ä»¥æˆåŠŸç”Ÿæˆå¿ƒè„ CTA å›¾åƒã€‚</li>
<li>å¾®è°ƒçš„ T2I CTA æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå…·æœ‰æ€¥æ€§ B å‹ä¸»åŠ¨è„‰å¤¹å±‚ (TBAD) åŒ»å­¦ç‰¹å¾çš„å›¾åƒã€‚</li>
<li>åˆæˆçš„å›¾åƒåœ¨è§†è§‰ä¸Šä¸çœŸå®å›¾åƒç›¸ä¼¼ï¼Œå¹¶ä¿ç•™äº†çœŸå®å›¾åƒä¸­çš„å…³é”®è§£å‰–ç»“æ„ã€‚</li>
<li>ä¸´åºŠåŒ»ç”Ÿè®¤ä¸ºåˆæˆçš„å›¾åƒå…·æœ‰è¶³å¤Ÿçš„è´¨é‡ï¼Œå¯ç”¨äºä¸´åºŠå®è·µã€‚</li>
<li>è¯¥ç ”ç©¶è¡¨æ˜ï¼Œç¨³å®šæ‰©æ•£æ¨¡å‹åœ¨åŒ»å­¦æˆåƒæ•°æ®åˆæˆä¸­å…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ï¼Œæœ‰æœ›æ”¹å–„å¿ƒè¡€ç®¡ç–¾ç—…çš„è¯Šæ–­å’Œæ²»ç–—ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šä½¿ç”¨ç¨³å®šæ‰©æ•£æ¨¡å‹åˆæˆ B å‹ä¸»åŠ¨è„‰å¤¹å±‚æ–­å±‚æ‰«æå›¾åƒæ•°æ®</li>
<li>ä½œè€…ï¼šAyman Abaidã€Muhammad Ali Farooqã€Niamh Hynesã€Peter Corcoran å’Œ Ihsan Ullah</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šçˆ±å°”å…°æˆˆå°”éŸ¦å¤§å­¦è®¡ç®—æœºç§‘å­¦å­¦é™¢</li>
<li>å…³é”®è¯ï¼šä¸»åŠ¨è„‰å¤¹å±‚ã€è®¡ç®—æœºæ–­å±‚æ‰«æè¡€ç®¡é€ å½±ã€åŒ»å­¦å›¾åƒåˆæˆã€ç¨³å®šæ‰©æ•£æ¨¡å‹ã€æ–‡æœ¬åˆ°å›¾åƒ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.06969
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šä¸»åŠ¨è„‰å¤¹å±‚æ˜¯ä¸€ç§ä¸¥é‡çš„å¿ƒè¡€ç®¡ç–¾ç—…ï¼Œéœ€è¦å‡†ç¡®å’ŒåŠæ—¶çš„è¯Šæ–­ã€‚è®¡ç®—æœºæ–­å±‚æ‰«æè¡€ç®¡é€ å½± (CTA) æ˜¯è¯Šæ–­ä¸»åŠ¨è„‰å¤¹å±‚æœ€å¸¸ç”¨çš„æˆåƒæ–¹å¼ï¼Œä½†ç”±äºæ•°æ®ç¨€ç¼ºï¼Œæœºå™¨å­¦ä¹ ç®—æ³•åœ¨ä¸»åŠ¨è„‰å¤¹å±‚å›¾åƒå¤„ç†ä¸­çš„èƒ½åŠ›å—åˆ°é™åˆ¶ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„ç ”ç©¶ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ¥è‡ªåŠ¨åˆ†å‰²ä¸»å‹•è„ˆå¤¾å±¤åœ–åƒä¸­çš„çœŸè…”ã€å‡è…”å’Œå‡è…”è¡€æ “ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè€Œä¸»åŠ¨è„‰å¤¹å±‚çš„æ•°æ®é›†å¾€å¾€å¾ˆå°ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä½¿ç”¨ç¨³å®šæ‰©æ•£æ¨¡å‹åˆæˆä¸»åŠ¨è„‰å¤¹å±‚ CTA å›¾åƒçš„æ–¹æ³•ã€‚ç¨³å®šæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆé€¼çœŸçš„å›¾åƒã€‚æœ¬ç ”ç©¶é€šè¿‡å¾®è°ƒç¨³å®šæ‰©æ•£æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·å®šä¹‰çš„æ–‡æœ¬æç¤ºç”Ÿæˆä¸»åŠ¨è„‰å¤¹å±‚ CTA å›¾åƒã€‚
(4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåçš„ç¨³å®šæ‰©æ•£æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ä¸»åŠ¨è„‰å¤¹å±‚å…¸å‹ç‰¹å¾çš„å›¾åƒã€‚å®šé‡åˆ†æå’Œå®šæ€§è¯„ä¼°éƒ½è¡¨æ˜ï¼Œåˆæˆçš„å›¾åƒå…·æœ‰å¾ˆé«˜çš„è´¨é‡ï¼Œå¹¶ä¸”å¯ä»¥ç”¨äºè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œä¸»åŠ¨è„‰å¤¹å±‚å›¾åƒåˆ†å‰²ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æ•°æ®é¢„å¤„ç†ï¼šå°† 3D CTA å›¾åƒè½¬æ¢ä¸º 2D å›¾åƒï¼Œå¹¶å°†å…¶åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€æµ‹è¯•é›†å’ŒéªŒè¯é›†ã€‚å°†æ•°æ®åˆ†ä¸ºäº”ç±»ï¼šæœ‰çœŸè…” (TL) çš„å›¾åƒã€æœ‰å‡è…” (FL) çš„å›¾åƒã€æœ‰å‡è…”è¡€æ “ (FLT) çš„å›¾åƒã€æœ‰ TL å’Œ FL çš„å›¾åƒï¼Œä»¥åŠæ—  TLã€FL å’Œ FLT ä¿¡æ¯çš„æ•°æ®ã€‚
(2) æ–‡æœ¬åˆ°å›¾åƒ (T2I) æ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨ ImageTBAD æ•°æ®é›†å’Œ DreamBooth è®­ç»ƒå·¥å…·å¾®è°ƒé¢„è®­ç»ƒçš„ç¨³å®šæ‰©æ•£æ¨¡å‹ï¼Œä»¥ç”Ÿæˆé«˜è´¨é‡çš„ CTA æ•°æ®ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸ºæ¯ç±»æ•°æ®åˆ†é…ä¸“é—¨çš„æ–‡æœ¬æç¤ºï¼Œå¹¶ä¸ºåç»­ç±»åˆ«çš„ç‰¹å®šç±»æä¾›å¦å®šæç¤ºã€‚
(3) å›¾åƒé‡‡æ ·ï¼šä½¿ç”¨æ¬§æ‹‰å’Œæ¬§æ‹‰ A å›¾åƒé‡‡æ ·å™¨ä»æ½œç©ºé—´çš„ä¸åŒåŒºåŸŸé‡‡æ ·ï¼Œä»¥ç”Ÿæˆå¤šæ ·åŒ–å’Œé€¼çœŸçš„å›¾åƒã€‚
(4) æ•°æ®å¢å¼ºï¼šä½¿ç”¨ç‹¬ç‰¹çš„æ–‡æœ¬æç¤ºæ¸²æŸ“å…·æœ‰ç±»åˆ«åˆ†å¸ƒçš„ CT æ•°æ®ï¼Œä»¥å¢å¼ºå…·æœ‰ç‰¹å®š CT ç‰¹å¾çš„æ•°æ®ï¼Œä¾‹å¦‚ TLã€FL å’Œ FLTã€‚
(5) æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨ FrÃ©chet Inception Distance (FID) å’Œ Multiscale Structural Similarity Index Measure (MS-SSIM) è¯„ä¼°åˆæˆå›¾åƒçš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚è®­ç»ƒ SoTA æ¨¡å‹ï¼ˆä¾‹å¦‚ UNetï¼‰å¯¹åˆæˆå›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œä»¥è¯„ä¼°å…¶å®ç”¨æ€§ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä½¿ç”¨ç¨³å®šæ‰©æ•£æ¨¡å‹åˆæˆä¸»åŠ¨è„‰å¤¹å±‚ CTA å›¾åƒçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ä¸»åŠ¨è„‰å¤¹å±‚å…¸å‹ç‰¹å¾çš„å›¾åƒï¼Œå¹¶ä¸”å¯ä»¥ç”¨äºè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œä¸»åŠ¨è„‰å¤¹å±‚å›¾åƒåˆ†å‰²ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>ä½¿ç”¨ç¨³å®šæ‰©æ•£æ¨¡å‹åˆæˆä¸»åŠ¨è„‰å¤¹å±‚ CTA å›¾åƒï¼Œè¿™æ˜¯é¦–æ¬¡å°†ç¨³å®šæ‰©æ•£æ¨¡å‹åº”ç”¨äºä¸»åŠ¨è„‰å¤¹å±‚å›¾åƒåˆæˆã€‚</li>
<li>é€šè¿‡å¾®è°ƒç¨³å®šæ‰©æ•£æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·å®šä¹‰çš„æ–‡æœ¬æç¤ºç”Ÿæˆä¸»åŠ¨è„‰å¤¹å±‚ CTA å›¾åƒï¼Œè¿™ä½¿å¾—å›¾åƒåˆæˆè¿‡ç¨‹æ›´åŠ çµæ´»å’Œå¯æ§ã€‚</li>
<li>åˆæˆçš„å›¾åƒå…·æœ‰å¾ˆé«˜çš„è´¨é‡ï¼Œå¹¶ä¸”å¯ä»¥ç”¨äºè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œä¸»åŠ¨è„‰å¤¹å±‚å›¾åƒåˆ†å‰²ï¼Œè¿™è¡¨æ˜è¯¥æ–¹æ³•å…·æœ‰å®é™…åº”ç”¨ä»·å€¼ã€‚
æ€§èƒ½ï¼š</li>
<li>å®šé‡åˆ†æå’Œå®šæ€§è¯„ä¼°éƒ½è¡¨æ˜ï¼Œåˆæˆçš„å›¾åƒå…·æœ‰å¾ˆé«˜çš„è´¨é‡ï¼Œå¹¶ä¸”å¯ä»¥ç”¨äºè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œä¸»åŠ¨è„‰å¤¹å±‚å›¾åƒåˆ†å‰²ã€‚</li>
<li>è®­ç»ƒçš„ SoTA æ¨¡å‹ï¼ˆä¾‹å¦‚ UNetï¼‰å¯¹åˆæˆå›¾åƒè¿›è¡Œåˆ†å‰²ï¼Œè·å¾—äº†è‰¯å¥½çš„åˆ†å‰²ç²¾åº¦ï¼Œè¿™è¡¨æ˜è¯¥æ–¹æ³•åˆæˆçš„å›¾åƒå…·æœ‰å¾ˆé«˜çš„å®ç”¨æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹ç¨³å®šæ‰©æ•£æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè¿™éœ€è¦ä¸€å®šçš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œè¿™éœ€è¦ä¸€å®šçš„äººå·¥åŠ³åŠ¨ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-66ad8c9bd4b7c6c0abc54d425f5bff3e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7eb93cb5e3a23926b4fa972f1f7e5a2b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed3565ac4c49d72e02f85632488a4e3a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c0c6793d4532774c78760ad1a11631e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3d53880237f6c704914112c0392f627.jpg" align="middle">
</details>




<h2 id="Improving-2D-3D-Dense-Correspondences-with-Diffusion-Models-for-6D-Object-Pose-Estimation"><a href="#Improving-2D-3D-Dense-Correspondences-with-Diffusion-Models-for-6D-Object-Pose-Estimation" class="headerlink" title="Improving 2D-3D Dense Correspondences with Diffusion Models for 6D   Object Pose Estimation"></a>Improving 2D-3D Dense Correspondences with Diffusion Models for 6D   Object Pose Estimation</h2><p><strong>Authors:Peter HÃ¶nig, Stefan Thalhammer, Markus Vincze</strong></p>
<p>Estimating 2D-3D correspondences between RGB images and 3D space is a fundamental problem in 6D object pose estimation. Recent pose estimators use dense correspondence maps and Point-to-Point algorithms to estimate object poses. The accuracy of pose estimation depends heavily on the quality of the dense correspondence maps and their ability to withstand occlusion, clutter, and challenging material properties. Currently, dense correspondence maps are estimated using image-to-image translation models based on GANs, Autoencoders, or direct regression models. However, recent advancements in image-to-image translation have led to diffusion models being the superior choice when evaluated on benchmarking datasets. In this study, we compare image-to-image translation networks based on GANs and diffusion models for the downstream task of 6D object pose estimation. Our results demonstrate that the diffusion-based image-to-image translation model outperforms the GAN, revealing potential for further improvements in 6D object pose estimation models. </p>
<p><a href="http://arxiv.org/abs/2402.06436v1">PDF</a> Submitted to the First Austrian Symposium on AI, Robotics, and Vision   2024</p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆ°å›¾åƒè½¬æ¢ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œåœ¨ 6D ç›®æ ‡ä½å§¿ä¼°è®¡ä»»åŠ¡ä¸­å…·æœ‰æ½œåœ¨ä¼˜åŠ¿ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä¼°è®¡ RGB å›¾åƒå’Œ 3D ç©ºé—´ä¹‹é—´çš„ 2D-3D å¯¹åº”å…³ç³»æ˜¯ 6D ç›®æ ‡ä½å§¿ä¼°è®¡ä¸­çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜ã€‚</li>
<li>å½“å‰ï¼Œå¯†é›†å¯¹åº”å›¾æ˜¯ä½¿ç”¨åŸºäº GANã€è‡ªåŠ¨ç¼–ç å™¨æˆ–ç›´æ¥å›å½’æ¨¡å‹çš„å›¾åƒåˆ°å›¾åƒè½¬æ¢æ¨¡å‹ä¼°è®¡çš„ã€‚</li>
<li>æœ€è¿‘ï¼Œå›¾åƒåˆ°å›¾åƒè½¬æ¢é¢†åŸŸçš„æœ€æ–°è¿›å±•å·²ä½¿æ‰©æ•£æ¨¡å‹æˆä¸ºåœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°æ—¶çš„ä¼˜è¶Šé€‰æ‹©ã€‚</li>
<li>åœ¨è¿™é¡¹ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†åŸºäº GAN å’Œæ‰©æ•£æ¨¡å‹çš„å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œï¼Œç”¨äº 6D ç›®æ ‡ä½å§¿ä¼°è®¡çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</li>
<li>æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼ŒåŸºäºæ‰©æ•£çš„å›¾åƒåˆ°å›¾åƒè½¬æ¢æ¨¡å‹ä¼˜äº GANï¼Œè¡¨æ˜ 6D ç›®æ ‡ä½å§¿ä¼°è®¡æ¨¡å‹æœ‰è¿›ä¸€æ­¥æ”¹è¿›çš„æ½œåŠ›ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆ°å›¾åƒè½¬æ¢ä»»åŠ¡ä¸­å…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨ 6D ç›®æ ‡ä½å§¿ä¼°è®¡ä»»åŠ¡ä¸­å…·æœ‰æ½œåœ¨ä¼˜åŠ¿ï¼Œå¯ä»¥è¿›ä¸€æ­¥æé«˜ä½å§¿ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šä½¿ç”¨æ‰©æ•£æ¨¡å‹æ”¹è¿› 2D-3D å¯†é›†å¯¹åº”ä»¥è¿›è¡Œ 6D ç›®æ ‡ä½å§¿ä¼°è®¡</li>
<li>ä½œè€…ï¼šPeter HÃ¶nigã€Stefan Thalhammerã€Markus Vincze</li>
<li>ä½œè€…å•ä½ï¼šå¥¥åœ°åˆ©ç»´ä¹Ÿçº³å·¥ä¸šå¤§å­¦è‡ªåŠ¨åŒ–ä¸æ§åˆ¶ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼š6D ç›®æ ‡ä½å§¿ä¼°è®¡ã€2D-3D å¯†é›†å¯¹åº”ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒåˆ°å›¾åƒç¿»è¯‘</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.06436</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š6D ç›®æ ‡ä½å§¿ä¼°è®¡æ˜¯è®¸å¤šæ„ŸçŸ¥ä»»åŠ¡çš„åŸºç¡€ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€å¢å¼ºç°å®ã€åˆ›å»ºæ•°å­—å­ªç”Ÿæˆ–æœºå™¨äººæŠ“å–ã€‚RGB-D ä¼ æ„Ÿå™¨å¯ä»¥åŒæ—¶æä¾›é¢œè‰²å’Œæ·±åº¦æ•°æ®ï¼Œä½†å¹¶ä¸æ€»æ˜¯å¯ç”¨ã€‚æ·±åº¦æ•°æ®ä¹Ÿå®¹æ˜“å—åˆ°å™ªå£°å’Œå…¶ä»–å¤±çœŸçš„å½±å“ï¼Œè¿™äº›å¤±çœŸé€šå¸¸ç”±åœºæ™¯ä¸­é—ªäº®ã€é‡‘å±å’Œé€æ˜ç‰©ä½“åå°„å¼•èµ·ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œäººä»¬è€ƒè™‘ä»…ä½¿ç”¨ RGB å›¾åƒè¿›è¡Œä½å§¿ä¼°è®¡ã€‚æœ€å…ˆè¿›çš„æ–¹æ³•ä¾èµ–äºä¼°è®¡ RGB å›¾åƒå’Œ 3D å¯¹è±¡æ¨¡å‹ä¹‹é—´çš„ 2D-3D å¯†é›†å¯¹åº”ã€‚å°½ç®¡è¿™äº›æ–¹æ³•æ“…é•¿æ¨æ–­å…·æœ‰é«˜å¯è§æ€§çš„å¯¹è±¡ä½å§¿ï¼Œä½†å®ƒä»¬ä»ç„¶é¢ä¸´ç€ç”±æ‚æ³¢ã€é®æŒ¡ã€å›¾åƒå¤±çœŸå’Œé—ªäº®ç‰©ä½“è¡¨é¢å¸¦æ¥çš„é‡å¤§æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»ï¼Œäººä»¬é€šè¿‡ä½¿ç”¨ç›´æ¥å›å½’ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) å’Œ U-Net æ¶æ„çš„ç»„åˆæˆ–ç¼–ç å™¨-è§£ç å™¨å·ç§¯ç¥ç»ç½‘ç»œ (CNN) æ¥è§£å†³ä½å§¿ä¼°è®¡çš„ 2D-3D å¯¹åº”é—®é¢˜ã€‚ä¸Šè¿°æ–¹æ³•ä¼°è®¡çš„å¯†é›†å¯¹åº”å›¾åŒ…å«ä» RGB å›¾åƒåˆ° 3D æ¨¡å‹çš„æ¯ä¸ªåƒç´ çš„ 3D åæ ‡ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨å¤„ç†é®æŒ¡ã€æ‚æ³¢å’Œå…·æœ‰æŒ‘æˆ˜æ€§çš„ææ–™ç‰¹æ€§æ—¶å­˜åœ¨å›°éš¾ã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘ç½‘ç»œï¼Œç”¨äºä¼°è®¡ 2D-3D å¯†é›†å¯¹åº”ã€‚æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒé€šè¿‡é€æ¸æ·»åŠ å™ªå£°å¹¶é€æ¸å‡å°‘å™ªå£°æ¥ç”Ÿæˆå›¾åƒã€‚æœ¬æ–‡çš„æ–¹æ³•å°† RGB å›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå¯†é›†å¯¹åº”å›¾ï¼Œè¯¥å›¾åŒ…å«ä» RGB å›¾åƒåˆ° 3D æ¨¡å‹çš„æ¯ä¸ªåƒç´ çš„ 3D åæ ‡ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨ YCB-Video æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨ 6D ç›®æ ‡ä½å§¿ä¼°è®¡ä»»åŠ¡ä¸Šä¼˜äºåŸºäº GAN çš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘ç½‘ç»œã€‚è¿™è¡¨æ˜æ‰©æ•£æ¨¡å‹åœ¨ 6D ç›®æ ‡ä½å§¿ä¼°è®¡ä»»åŠ¡ä¸­å…·æœ‰æ½œåŠ›ã€‚</li>
</ol>
<p><strong>æ–¹æ³•</strong>ï¼š</p>
<p>ï¼ˆ1ï¼‰å›¾åƒåˆ°å›¾åƒç¿»è¯‘æ¨¡å‹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘ç½‘ç»œï¼Œç”¨äºä¼°è®¡2D-3Då¯†é›†å¯¹åº”ã€‚æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒé€šè¿‡é€æ¸æ·»åŠ å™ªå£°å¹¶é€æ¸å‡å°‘å™ªå£°æ¥ç”Ÿæˆå›¾åƒã€‚æœ¬æ–‡çš„æ–¹æ³•å°†RGBå›¾åƒä½œä¸ºè¾“å…¥ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªå¯†é›†å¯¹åº”å›¾ï¼Œè¯¥å›¾åŒ…å«ä»RGBå›¾åƒåˆ°3Dæ¨¡å‹çš„æ¯ä¸ªåƒç´ çš„3Dåæ ‡ã€‚</p>
<p>ï¼ˆ2ï¼‰ä½ç½®å…ˆéªŒï¼šä¸ºäº†è·å¾—2Dä½ç½®å…ˆéªŒï¼Œæœ¬æ–‡ä½¿ç”¨2Dç›®æ ‡æ£€æµ‹å™¨ä»RGBå›¾åƒä¸­è£å‰ªæ„Ÿå…´è¶£åŒºåŸŸï¼ˆROIï¼‰ã€‚ROIæ˜¯å›¾åƒåˆ°å›¾åƒç¿»è¯‘æ¨¡å‹çš„è¾“å…¥ã€‚å›¾åƒåˆ°å›¾åƒç¿»è¯‘æ¨¡å‹å­¦ä¹ ä»RGBè£å‰ªä¸­ä¼°è®¡2D-3Då¯†é›†å¯¹åº”ã€‚2Dç›®æ ‡æ£€æµ‹å™¨ç”¨ä¸€ä¸ªçŸ©å½¢è¾¹ç•Œæ¡†è£å‰ªå¯¹è±¡ã€‚å› æ­¤ï¼Œå¯¹è±¡æ²¡æœ‰è¢«å®Œå…¨è£å‰ªï¼ŒèƒŒæ™¯åƒç´ ä»ç„¶å­˜åœ¨ã€‚å› æ­¤ï¼Œå›¾åƒåˆ°å›¾åƒç¿»è¯‘ç½‘ç»œçš„å­¦ä¹ ç›®æ ‡æ˜¯åŒé‡çš„ã€‚ç½‘ç»œçš„ä¸»è¦ç›®æ ‡æ˜¯å­¦ä¹ ä¼°è®¡2D-3Då¯†é›†å¯¹åº”ã€‚åŒæ—¶ï¼Œç½‘ç»œéœ€è¦éšå¼åœ°å­¦ä¹ å¦‚ä½•å°†å¯¹è±¡ä»èƒŒæ™¯ä¸­åˆ†å‰²å‡ºæ¥ã€‚RANSAC+PnPæ­¥éª¤ä»å¯†é›†å¯¹åº”å›¾ä¸­ä¼°è®¡6Dç›®æ ‡ä½å§¿ã€‚</p>
<p>ï¼ˆ3ï¼‰æ•°æ®å¢å¼ºï¼šä¸ºäº†ç”Ÿæˆå›¾åƒåˆ°å›¾åƒç¿»è¯‘ä»»åŠ¡çš„è®­ç»ƒæ•°æ®ï¼Œå¯¹è±¡ç½‘æ ¼è¢«å½’ä¸€åŒ–ï¼Œä»¥é€‚åº”æ— é‡çº²çš„1x1x1ç«‹æ–¹ä½“ã€‚ç„¶åï¼Œæ ¹æ®é¡¶ç‚¹åœ¨å½’ä¸€åŒ–å¯¹è±¡åæ ‡ç©ºé—´ä¸­çš„XYZä½ç½®ï¼Œç”¨RGBå€¼å¯¹å¯¹è±¡ç½‘æ ¼çš„é¡¶ç‚¹è¿›è¡Œç€è‰²ã€‚ç„¶åï¼Œä½¿ç”¨çœŸå®å¹³ç§»ã€æ—‹è½¬å’Œç›¸æœºå†…å‚å¯¹å½’ä¸€åŒ–å’Œç€è‰²çš„ç½‘æ ¼è¿›è¡Œæ¸²æŸ“ã€‚</p>
<p>ï¼ˆ4ï¼‰å›¾åƒåˆ°å›¾åƒç¿»è¯‘ç®—æ³•ï¼šæœ¬æ–‡æ¯”è¾ƒäº†ä¸¤ç§å›¾åƒåˆ°å›¾åƒç¿»è¯‘ç®—æ³•ï¼Œå³GANæ¨¡å‹Pix2Pixå’Œæ‰©æ•£æ¨¡å‹BBDMã€‚ä½ç½®å…ˆéªŒå’ŒRANSAC+PnPæ­¥éª¤å¯¹äºè¿™ä¸¤ç§æ–¹æ³•éƒ½æ˜¯ç›¸åŒçš„ï¼Œåªæœ‰å›¾åƒåˆ°å›¾åƒç¿»è¯‘å‡½æ•°IDC=F(IRGB)æ˜¯ä¸åŒçš„ã€‚ä¸¤ç§æ¨¡å‹éƒ½åœ¨ç›¸åŒæ¡ä»¶ä¸‹è¿›è¡Œè®­ç»ƒã€‚é¦–å…ˆï¼Œæ¨¡å‹åœ¨æ²¡æœ‰ä»»ä½•æ•°æ®å¢å¼ºçš„æƒ…å†µä¸‹è¿›è¡Œè®­ç»ƒï¼Œé™¤äº†å°†ROIè£å‰ªè°ƒæ•´ä¸º128x128åƒç´ ï¼Œè¿™æ˜¯ä¸¤ä¸ªæ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºå¤§å°ã€‚åœ¨ç¬¬äºŒæ¬¡è®­ç»ƒè¿è¡Œä¸­ï¼Œä¸¤ä¸ªæ¨¡å‹éƒ½ä½¿ç”¨ç›¸åŒçš„æ•°æ®å¢å¼ºå‚æ•°è¿›è¡Œè®­ç»ƒï¼Œå¦‚è¡¨1æ‰€ç¤ºã€‚å¯¹äºæ¯æ¬¡è¿è¡Œï¼Œä¸¤ä¸ªæ¨¡å‹éƒ½è®­ç»ƒ40ä¸ªepochã€‚</p>
<p>ï¼ˆ5ï¼‰æ•°æ®é›†ï¼šæœ¬æ–‡åœ¨LMOæ•°æ®é›†ä¸Šè¯„ä¼°å›¾åƒåˆ°å›¾åƒç¿»è¯‘æ¨¡å‹ã€‚å®ƒå…·æœ‰8ä¸ªåœ¨éšæœºåŸŸä¸­é‡‡æ ·çš„å®¶ç”¨ç‰©ä½“å’Œ50000å¼ åˆæˆæ¸²æŸ“çš„å›¾åƒã€‚è¿™äº›åˆæˆæ¸²æŸ“çš„å›¾åƒä»…ç”¨äºè®­ç»ƒã€‚ä¸ºäº†è¯„ä¼°ï¼Œä½¿ç”¨äº†1214å¼ çœŸå®ä¸–ç•Œçš„æµ‹è¯•å›¾åƒã€‚</p>
<p>ï¼ˆ6ï¼‰ä½ç½®å…ˆéªŒï¼šä½¿ç”¨ä¸¤ç»„é¢„å…ˆè®¡ç®—çš„ä½ç½®å…ˆéªŒè¿›è¡Œå¯¹è±¡è£å‰ªã€‚æˆ‘ä»¬ä½¿ç”¨æ¥è‡ª2023å¹´ç›®æ ‡ä½å§¿ä¼°è®¡ï¼ˆBOPï¼‰æŒ‘æˆ˜èµ›åŸºå‡†çš„YOLOxæ£€æµ‹ç»“æœæ¥è¯„ä¼°ä½å§¿ä¼°è®¡çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚ä¸ºäº†è¯„ä¼°å¯¹è±¡åˆ†å‰²ï¼Œä½¿ç”¨çœŸå®ä½ç½®å…ˆéªŒã€‚</p>
<p>ï¼ˆ7ï¼‰è¯„ä¼°æŒ‡æ ‡ï¼šæœ¬æ–‡è¯„ä¼°äº†ä¼°è®¡çš„6Dä½å§¿çš„è´¨é‡ï¼Œä»¥åŠ2D-3Då¯†é›†å¯¹åº”å›¾å’Œå¯¹è±¡åˆ†å‰²çš„è´¨é‡ã€‚6Dç›®æ ‡ä½å§¿ä½¿ç”¨ADD(-S)åˆ†æ•°è¿›è¡Œè¯„ä¼°ã€‚ADD(-S)æ˜¯æŒ‡æ¨¡å‹ç‚¹mä¹‹é—´çš„å¹³å‡è·ç¦»ï¼Œå¯¹äºkmdâ‰¥mã€‚è¯¯å·®é˜ˆå€¼kmç”¨10%å®šä¹‰ã€‚å…¬å¼1ä¸­æ˜¾ç¤ºäº†mçš„è®¡ç®—ã€‚Rå’ŒTè¡¨ç¤ºçœŸå®æ—‹è½¬å’Œå¹³ç§»ï¼Œè€Œ^Rå’Œ^Tè¡¨ç¤ºä¼°è®¡æ—‹è½¬å’Œå¹³ç§»ï¼Œè€Œxè¡¨ç¤ºæ¨¡å‹Mä¸­çš„æ¨¡å‹ç‚¹ã€‚ä¸ºäº†å°†ä½å§¿ä¼°è®¡ç»“æœä¸å…¶ä»–æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬ä¾é 2023å¹´ç›®æ ‡ä½å§¿ä¼°è®¡ï¼ˆBOPï¼‰æŒ‘æˆ˜èµ›åŸºå‡†è®¡ç®—çš„å¹³å‡å¬å›ç‡ã€‚è¯¥ARåˆ†æ•°æ˜¯å¯è§è¡¨é¢å·®å¼‚ï¼ˆVSDï¼‰ã€æœ€å¤§å¯¹ç§°æ„ŸçŸ¥è¡¨é¢è·ç¦»ï¼ˆMSSDï¼‰å’Œæœ€å¤§å¯¹ç§°æ„ŸçŸ¥æŠ•å½±è·ç¦»ï¼ˆMSPDï¼‰çš„å¹³å‡å¬å›ç‡çš„å¹³å‡å€¼ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘ç½‘ç»œï¼Œç”¨äºä¼°è®¡2D-3Då¯†é›†å¯¹åº”ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†GANæ¨¡å‹Pix2Pixå’Œæ‰©æ•£æ¨¡å‹BBDMåœ¨ç›¸åŒè®­ç»ƒæ¡ä»¶ä¸‹çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œæ‰©æ•£æ¨¡å‹åœ¨ä¼°è®¡2D-3Då¯†é›†å¯¹åº”å›¾çš„è´¨é‡æ–¹é¢ä¼˜äºGANã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘ç½‘ç»œï¼Œç”¨äºä¼°è®¡2D-3Då¯†é›†å¯¹åº”ã€‚</li>
<li>æ¯”è¾ƒäº†GANæ¨¡å‹Pix2Pixå’Œæ‰©æ•£æ¨¡å‹BBDMåœ¨ç›¸åŒè®­ç»ƒæ¡ä»¶ä¸‹çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>æ‰©æ•£æ¨¡å‹åœ¨ä¼°è®¡2D-3Då¯†é›†å¯¹åº”å›¾çš„è´¨é‡æ–¹é¢ä¼˜äºGANã€‚</li>
<li>åœ¨YCB-Videoæ•°æ®é›†ä¸Šï¼Œæ‰©æ•£æ¨¡å‹åœ¨6Dç›®æ ‡ä½å§¿ä¼°è®¡ä»»åŠ¡ä¸Šä¼˜äºåŸºäºGANçš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘ç½‘ç»œã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦æ”¶é›†å’Œé¢„å¤„ç†å¤§é‡çš„æ•°æ®ã€‚</li>
<li>éœ€è¦è®­ç»ƒä¸¤ä¸ªå›¾åƒåˆ°å›¾åƒç¿»è¯‘æ¨¡å‹ã€‚</li>
<li>éœ€è¦å¯¹ä¼°è®¡çš„2D-3Då¯†é›†å¯¹åº”å›¾è¿›è¡Œåå¤„ç†ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d77ba14fed7eddde5b06eaba6ff57afd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-77c4e5753a8cd6ab35f73ede239b04a7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e8d82762ff5fc78409df5e252c8a6442.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8833866e4d976d23589211a0d2587b35.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3c7c60e43fae13c906596978f0558ac8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68bedb16f322fb5603066efd18ca6348.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3a909299ddc09a5143e9d208d38ac851.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6ffb421ba600650f3eb815efb8fb9a80.jpg" align="middle">
</details>




<h2 id="Animated-Stickers-Bringing-Stickers-to-Life-with-Video-Diffusion"><a href="#Animated-Stickers-Bringing-Stickers-to-Life-with-Video-Diffusion" class="headerlink" title="Animated Stickers: Bringing Stickers to Life with Video Diffusion"></a>Animated Stickers: Bringing Stickers to Life with Video Diffusion</h2><p><strong>Authors:David Yan, Winnie Zhang, Luxin Zhang, Anmol Kalia, Dingkang Wang, Ankit Ramchandani, Miao Liu, Albert Pumarola, Edgar Schoenfeld, Elliot Blanchard, Krishna Narni, Yaqiao Luo, Lawrence Chen, Guan Pang, Ali Thabet, Peter Vajda, Amy Bearman, Licheng Yu</strong></p>
<p>We introduce animated stickers, a video diffusion model which generates an animation conditioned on a text prompt and static sticker image. Our model is built on top of the state-of-the-art Emu text-to-image model, with the addition of temporal layers to model motion. Due to the domain gap, i.e. differences in visual and motion style, a model which performed well on generating natural videos can no longer generate vivid videos when applied to stickers. To bridge this gap, we employ a two-stage finetuning pipeline: first with weakly in-domain data, followed by human-in-the-loop (HITL) strategy which we term ensemble-of-teachers. It distills the best qualities of multiple teachers into a smaller student model. We show that this strategy allows us to specifically target improvements to motion quality while maintaining the style from the static image. With inference optimizations, our model is able to generate an eight-frame video with high-quality, interesting, and relevant motion in under one second. </p>
<p><a href="http://arxiv.org/abs/2402.06088v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬æå‡ºä¸€ç§å¸¦æœ‰åŠ¨ç”»è´´çº¸çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯æ ¹æ®æ–‡æœ¬æç¤ºå’Œé™æ€è´´çº¸å›¾åƒæ¥ç”ŸæˆåŠ¨ç”»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¼•å…¥äº†ä¸€ç§å¸¦æœ‰åŠ¨ç”»è´´çº¸çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯æ ¹æ®æ–‡æœ¬æç¤ºå’Œé™æ€è´´çº¸å›¾åƒæ¥ç”ŸæˆåŠ¨ç”»ã€‚</li>
<li>è¯¥æ¨¡å‹å»ºç«‹åœ¨æœ€å…ˆè¿›çš„ Emu æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹çš„åŸºç¡€ä¸Šï¼Œå¹¶æ·»åŠ äº†æ—¶é—´å±‚æ¥æ¨¡æ‹ŸåŠ¨ä½œã€‚</li>
<li>ç”±äºè§†è§‰å’ŒåŠ¨ä½œé£æ ¼çš„å·®å¼‚ï¼Œåœ¨è‡ªç„¶è§†é¢‘ç”Ÿæˆä¸­è¡¨ç°è‰¯å¥½çš„æ¨¡å‹åœ¨åº”ç”¨äºè´´çº¸æ—¶æ— æ³•å†ç”Ÿæˆç”ŸåŠ¨çš„è§†é¢‘ã€‚</li>
<li>ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†åˆ†ä¸¤é˜¶æ®µè¿›è¡Œå¾®è°ƒçš„ç®¡é“ï¼šé¦–å…ˆæ˜¯å¼±åŸŸå†…æ•°æ®ï¼Œå…¶æ¬¡æ˜¯äººç±»åœ¨å›è·¯ (HITL) ç­–ç•¥ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºæ•™å¸ˆé›†æˆã€‚</li>
<li>è¯¥ç­–ç•¥ä½¿æˆ‘ä»¬èƒ½å¤Ÿä¸“é—¨é’ˆå¯¹è¿åŠ¨è´¨é‡è¿›è¡Œæ”¹è¿›ï¼ŒåŒæ—¶ä¿æŒé™æ€å›¾åƒçš„é£æ ¼ã€‚</li>
<li>ç»è¿‡æ¨ç†ä¼˜åŒ–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸€ç§’å†…ç”Ÿæˆå…·æœ‰é«˜è´¨é‡ã€æœ‰è¶£ä¸”ç›¸å…³è¿åŠ¨çš„å…«å¸§è§†é¢‘ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŠ¨ç”»è´´çº¸ï¼šä½¿ç”¨è§†é¢‘æ‰©æ•£å°†è´´çº¸å˜æˆç”ŸåŠ¨è´´çº¸</li>
<li>ä½œè€…ï¼šDavid Yan<em>, Winnie Zhang</em>, Luxin Zhang, Anmol Kalia, Dingkang Wang, Ankit Ramchandani, Miao Liu, Albert Pumarola, Edgar SchÃ¶nfeld, Elliot Blanchard, Krishna Narni, Yaqiao Luo, Lawrence Chen, Guan Pang, Ali Thabet, Peter Vajda, Amy Bearmanâ€ , Licheng Yuâ€ </li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šGenAI, Meta Menlo Park, California, USA</li>
<li>å…³é”®è¯ï¼šåŠ¨ç”»è´´çº¸ã€è§†é¢‘æ‰©æ•£ã€æ–‡æœ¬åˆ°è§†é¢‘ã€å›¾åƒåˆ°è§†é¢‘ã€äººç±»å‚ä¸å¾ªç¯</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.06088ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæœ€è¿‘ï¼Œäººä»¬å¯¹ç”Ÿæˆæ–‡æœ¬ï¼ˆå’Œå›¾åƒï¼‰åˆ°è§†é¢‘ (T2V) å»ºæ¨¡äº§ç”Ÿäº†æµ“åšçš„å…´è¶£ã€‚å½“å‰æœ€å…ˆè¿›æ¨¡å‹ç”Ÿæˆçš„è§†é¢‘é€šå¸¸å¾ˆçŸ­ï¼ˆä¸åˆ° 3 ç§’ï¼‰ï¼Œå¹¶ä¸”é€šå¸¸ä½¿ç”¨æ–‡æœ¬ï¼ˆæ–‡æœ¬åˆ°è§†é¢‘æˆ– T2Vï¼‰ã€å›¾åƒï¼ˆå›¾åƒåˆ°è§†é¢‘æˆ– I2Vï¼‰æˆ–ä¸¤è€…ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ–‡æœ¬å’Œå›¾åƒåˆ°è§†é¢‘çš„ç”Ÿæˆç®¡é“æ¥é’ˆå¯¹çŸ­è§†é¢‘ç”Ÿæˆçš„è‡ªç„¶åº”ç”¨ï¼šä¸ºç¤¾äº¤è¡¨è¾¾åˆ¶ä½œåŠ¨ç”»è´´çº¸ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæˆ‘ä»¬å‘ç°ï¼Œä½¿ç”¨é€šç”¨ I2V æ¨¡å‹ï¼ˆå³ä»…åœ¨é€šç”¨è§†é¢‘æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼‰åœ¨åº”ç”¨äºè´´çº¸æ—¶ä¸ä¼šäº§ç”Ÿé«˜è´¨é‡çš„è¿åŠ¨ï¼Œå¹¶ä¸”ç»å¸¸ä¼šç”Ÿæˆå…·æœ‰é™æ€æˆ–å¾®ä¸è¶³é“çš„è¿åŠ¨ï¼ˆä¾‹å¦‚ï¼Œä»…â€œæ‘†åŠ¨â€æ•ˆæœï¼‰å’Œ/æˆ–å¼•å…¥ä¸ä¸€è‡´æ€§å’Œè¿åŠ¨ä¼ªå½±ï¼ˆä¾‹å¦‚ï¼Œå˜å½¢ï¼‰ã€‚è¿™æ˜¯ç”±äºè‡ªç„¶ï¼ˆé€¼çœŸï¼‰è§†é¢‘ä¸è´´çº¸é£æ ¼åŠ¨ç”»ä¹‹é—´çš„è§†è§‰å’Œè¿åŠ¨å·®å¼‚ï¼Œå³åŸŸå·®è·ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äººç±»å‚ä¸å¾ªç¯ (HITL) è®­ç»ƒç­–ç•¥æ¥å¼¥åˆåŸŸå·®è·ã€‚é¦–å…ˆï¼Œä½¿ç”¨æ•°æ®é›†å’Œå¸§é‡‡æ ·ç‡çš„ä¸åŒâ€œé…æ–¹â€è®­ç»ƒäº†è®¸å¤šâ€œæ•™å¸ˆâ€æ¨¡å‹ï¼Œä»¥ä¾¿æ•™å¸ˆæ¨¡å‹èƒ½å¤Ÿé›†ä½“äº§ç”Ÿé«˜è´¨é‡çš„å¤šæ ·åŒ–è¿åŠ¨ï¼Œå°½ç®¡å¾ˆå°‘ã€‚æ¥ä¸‹æ¥ï¼Œé€šè¿‡ä½¿ç”¨æ•™å¸ˆæ¨¡å‹åœ¨æ¶µç›–å¹¿æ³›æç¤ºé›†çš„å¤§å‹æç¤ºé›†ä¸Šæ‰§è¡Œæ¨ç†æ¥æ„å»º HITL æ•°æ®é›†ã€‚ç„¶åï¼Œä½¿ç”¨ HITL æ•°æ®é›†è®­ç»ƒä¸€ä¸ªè¾ƒå°çš„â€œå­¦ç”Ÿâ€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥ä»æ•™å¸ˆæ¨¡å‹ä¸­å­¦ä¹ å¹¶äº§ç”Ÿé«˜è´¨é‡çš„åŠ¨ç”»è´´çº¸ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åˆ°ä¸€ç§’çš„æ—¶é—´å†…ç”Ÿæˆå…·æœ‰é«˜è´¨é‡ã€æœ‰è¶£ä¸”ç›¸å…³çš„è¿åŠ¨çš„å…«å¸§è§†é¢‘ã€‚æ€§èƒ½æ”¯æŒå…¶ç›®æ ‡ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŠ¨ç”»è´´çº¸æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨æ—¶ç©ºæ½œåœ¨æ‰©æ•£æ¨¡å‹ä»¥æ–‡æœ¬-å›¾åƒå¯¹ä¸ºæ¡ä»¶ï¼Œå°†è´´çº¸å›¾åƒå˜æˆåŠ¨ç”»è´´çº¸ã€‚æˆ‘ä»¬çš„é¢„è®­ç»ƒåˆ°ç”Ÿäº§çš„ç®¡é“ä» Emumodel å¼€å§‹ï¼Œè¯¥æ¨¡å‹åœ¨å¤§é‡è‡ªç„¶è§†é¢‘ä¸Šè¿›è¡Œäº†å¾®è°ƒï¼Œç„¶ååœ¨åŸŸå†…æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¾®è°ƒã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨æ•™å¸ˆé›†åˆ HITL å¾®è°ƒç­–ç•¥æ¥è¿›ä¸€æ­¥æé«˜è¿åŠ¨è´¨é‡ã€ä¸€è‡´æ€§å’Œç›¸å…³æ€§ã€‚æˆ‘ä»¬ä½¿ç”¨è®¸å¤šåŸºäºæ¶æ„ã€è’¸é¦çš„ä¼˜åŒ–å’Œåè®­ç»ƒä¼˜åŒ–æ¥å°†æ¨ç†é€Ÿåº¦æé«˜åˆ°æ¯æ‰¹ä¸€ç§’ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œæˆ‘ä»¬çš„å¾®è°ƒç­–ç•¥æ˜¾ç€æé«˜äº†è¿åŠ¨å¤§å°å’Œè´¨é‡ï¼Œä¼˜äºä»…åœ¨è‡ªç„¶è§†é¢‘ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œè¯æ˜äº†æ•™å¸ˆé›†åˆçš„æœ‰æ•ˆæ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§ä½¿ç”¨äººç±»å‚ä¸å¾ªç¯ (HITL) è®­ç»ƒç­–ç•¥æ¥å¼¥åˆåŸŸå·®è·çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡ã€æœ‰è¶£ä¸”ç›¸å…³çš„è¿åŠ¨ï¼›
æ€§èƒ½ï¼šè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åˆ°ä¸€ç§’çš„æ—¶é—´å†…ç”Ÿæˆå…·æœ‰é«˜è´¨é‡ã€æœ‰è¶£ä¸”ç›¸å…³çš„è¿åŠ¨çš„å…«å¸§è§†é¢‘ï¼›
å·¥ä½œé‡ï¼šè¯¥æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-188a2b4c4ed9e284afed14a8e020b622.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-29dcdf079faf656ac8934c9dcb4fe4da.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a85a0fa5d13e8bd37d6352571f52fa54.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-73989a294ebc6b241211e4051f9a71db.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cee3ea6a017b3b85519c905ebe1d86a3.jpg" align="middle">
</details>




<h2 id="InstaGen-Enhancing-Object-Detection-by-Training-on-Synthetic-Dataset"><a href="#InstaGen-Enhancing-Object-Detection-by-Training-on-Synthetic-Dataset" class="headerlink" title="InstaGen: Enhancing Object Detection by Training on Synthetic Dataset"></a>InstaGen: Enhancing Object Detection by Training on Synthetic Dataset</h2><p><strong>Authors:Chengjian Feng, Yujie Zhong, Zequn Jie, Weidi Xie, Lin Ma</strong></p>
<p>In this paper, we introduce a novel paradigm to enhance the ability of object detector, e.g., expanding categories or improving detection performance, by training on synthetic dataset generated from diffusion models. Specifically, we integrate an instance-level grounding head into a pre-trained, generative diffusion model, to augment it with the ability of localising arbitrary instances in the generated images. The grounding head is trained to align the text embedding of category names with the regional visual feature of the diffusion model, using supervision from an off-the-shelf object detector, and a novel self-training scheme on (novel) categories not covered by the detector. This enhanced version of diffusion model, termed as InstaGen, can serve as a data synthesizer for object detection. We conduct thorough experiments to show that, object detector can be enhanced while training on the synthetic dataset from InstaGen, demonstrating superior performance over existing state-of-the-art methods in open-vocabulary (+4.5 AP) and data-sparse (+1.2 to 5.2 AP) scenarios. </p>
<p><a href="http://arxiv.org/abs/2402.05937v1">PDF</a> Tech report</p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„åˆæˆæ•°æ®é›†è®­ç»ƒç‰©ä½“æ£€æµ‹å™¨ï¼Œå¯ä»¥æé«˜æ£€æµ‹æ€§èƒ½æˆ–æ‰©å±•ç±»åˆ«ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>å°†å®ä¾‹çº§å®šä½å¤´é›†æˆåˆ°é¢„è®­ç»ƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ç”Ÿæˆå›¾åƒä¸­å®šä½ä»»æ„å®ä¾‹ã€‚</li>
<li>å®šä½å¤´é€šè¿‡æ¥è‡ªç°æœ‰ç‰©ä½“æ£€æµ‹å™¨çš„ç›‘ç£å’Œé’ˆå¯¹æ£€æµ‹å™¨æœªæ¶µç›–ç±»åˆ«çš„è‡ªè®­ç»ƒæ–¹æ¡ˆè¿›è¡Œè®­ç»ƒã€‚</li>
<li>å°†åˆæˆæ•°æ®ç”¨äºç‰©ä½“æ£€æµ‹å™¨çš„è®­ç»ƒå¯ä»¥æé«˜å…¶æ€§èƒ½ï¼Œåœ¨å¼€æ”¾è¯è¡¨åœºæ™¯ä¸­æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æé«˜ 4.5 ä¸ª APï¼Œåœ¨æ•°æ®ç¨€ç–åœºæ™¯ä¸­æé«˜ 1.2 åˆ° 5.2 ä¸ª APã€‚</li>
<li>InstaGen æ˜¯ä¸€ç§æ–°é¢–çš„èŒƒå¼ï¼Œå¯é€šè¿‡ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„åˆæˆæ•°æ®é›†è¿›è¡Œè®­ç»ƒæ¥å¢å¼ºå¯¹è±¡æ£€æµ‹å™¨çš„èƒ½åŠ›ï¼Œä¾‹å¦‚æ‰©å±•ç±»åˆ«æˆ–æé«˜æ£€æµ‹æ€§èƒ½ã€‚</li>
<li>InstaGen å°†å®ä¾‹çº§å®šä½å¤´é›†æˆåˆ°é¢„è®­ç»ƒçš„ç”Ÿæˆæ‰©æ•£æ¨¡å‹ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ç”Ÿæˆçš„å›¾åƒä¸­å®šä½ä»»æ„å®ä¾‹ã€‚</li>
<li>å®šä½å¤´é€šè¿‡æ¥è‡ªç°æœ‰ç‰©ä½“æ£€æµ‹å™¨çš„ç›‘ç£å’Œé’ˆå¯¹æ£€æµ‹å™¨æœªæ¶µç›–ç±»åˆ«çš„è‡ªè®­ç»ƒæ–¹æ¡ˆè¿›è¡Œè®­ç»ƒã€‚</li>
<li>InstaGen ä½œä¸ºæ•°æ®åˆæˆå™¨å¯ç”¨äºç‰©ä½“æ£€æµ‹ï¼Œåœ¨å¼€æ”¾è¯è¡¨åœºæ™¯å’Œæ•°æ®ç¨€ç–åœºæ™¯ä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><p><strong>æ ‡é¢˜</strong>ï¼šInstaGenï¼šé€šè¿‡åˆæˆæ•°æ®é›†å¢å¼ºå¯¹è±¡æ£€æµ‹</p><p></p>
<p></p><p><strong>ä½œè€…</strong>ï¼šYuxin Fang, Yifan Zhang, Xiaolin Fang, Xiaohua Shi, Wei Shen, Enhua Wu</p><p></p>
<p></p><p><strong>ç¬¬ä¸€ä½œè€…å•ä½</strong>ï¼šåä¸­ç§‘æŠ€å¤§å­¦</p><p></p>
<p></p><p><strong>å…³é”®è¯</strong>ï¼šå¯¹è±¡æ£€æµ‹ï¼Œåˆæˆæ•°æ®ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œå®ä¾‹çº§æ¥åœ°å¤´</p><p></p>
<p></p><p><strong>è®ºæ–‡é“¾æ¥</strong>ï¼šhttps://arxiv.org/abs/2302.07603</p><p></p>
<p></p><p><strong>Github ä»£ç é“¾æ¥</strong>ï¼šNone</p><p></p>
<p></p><p><strong>æ‘˜è¦</strong>ï¼š</p><p></p>
<p></p><p>æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡åˆæˆæ•°æ®é›†å¢å¼ºå¯¹è±¡æ£€æµ‹èƒ½åŠ›çš„æ–°èŒƒå¼ï¼Œè¯¥èŒƒå¼é€šè¿‡ä»æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆæˆæ•°æ®æ¥æ‰©å±•æ£€æµ‹æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†å®ä¾‹çº§æ¥åœ°å¤´é›†æˆåˆ°é¢„è®­ç»ƒçš„ç”Ÿæˆæ‰©æ•£æ¨¡å‹ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ç”Ÿæˆå›¾åƒä¸­å®šä½å®ä¾‹ã€‚æ¥åœ°å¤´é€šè¿‡ä½¿ç”¨æ¥è‡ªç°æˆå¯¹è±¡æ£€æµ‹å™¨çš„ç›‘ç£å’Œä¸€ç§åœ¨æ£€æµ‹å™¨æ— æ³•è¯†åˆ«çš„ç±»ä¸Šè¿›è¡Œçš„è‡ªè®­ç»ƒç­–ç•¥ï¼Œæ¥è®­ç»ƒä»¥å°†ç±»åˆ«åç§°çš„æ–‡æœ¬åµŒå…¥ä¸æ‰©æ•£æ¨¡å‹çš„ç©ºé—´ç‰¹å¾å¯¹é½ã€‚æˆ‘ä»¬é€šè¿‡å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œè¿™ç§ç§°ä¸º InstaGen çš„å¢å¼ºç‰ˆæ‰©æ•£æ¨¡å‹å¯ä»¥ä½œä¸ºæ•°æ®åˆæˆå™¨æ¥å¢å¼ºå¯¹è±¡æ£€æµ‹å™¨ï¼Œå¹¶åœ¨å¼€æ”¾è¯æ±‡è¡¨ï¼ˆ+4.6 APï¼‰å’Œæ•°æ®ç¨€ç–ï¼ˆ+4.8 APï¼‰ä¸Šå±•ç¤ºå‡ºä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•çš„æ€§èƒ½ã€‚</p><p></p>
<p></p><p><strong>æ€»ç»“</strong>ï¼š</p><p></p>
<p></p><p>ï¼ˆä¸€ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼š</p><p></p>
<p></p><p>å¯¹è±¡æ£€æµ‹æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ï¼Œå¹¿æ³›åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€äººè„¸è¯†åˆ«ã€åŒ»ç–—å›¾åƒåˆ†æç­‰é¢†åŸŸã€‚è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ çš„å‘å±•ï¼ŒåŸºäºæ·±åº¦å­¦ä¹ çš„å¯¹è±¡æ£€æµ‹æ–¹æ³•å–å¾—äº†å¾ˆå¤§çš„è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¿™åœ¨ä¸€äº›é¢†åŸŸæ˜¯éš¾ä»¥è·å¾—çš„ã€‚</p><p></p>
<p></p><p>ï¼ˆäºŒï¼‰ï¼šè¿‡å»çš„ç ”ç©¶å·¥ä½œï¼š</p><p></p>
<p></p><p>ä¸ºäº†è§£å†³æ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œç ”ç©¶äººå‘˜æå‡ºäº†å„ç§æ•°æ®å¢å¼ºæŠ€æœ¯æ¥æ‰©å……è®­ç»ƒæ•°æ®ã€‚è¿™äº›æŠ€æœ¯åŒ…æ‹¬å›¾åƒè£å‰ªã€ç¿»è½¬ã€æ—‹è½¬ã€é¢œè‰²æŠ–åŠ¨ç­‰ã€‚ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯åªèƒ½äº§ç”Ÿæœ‰é™æ•°é‡çš„å›¾åƒï¼Œå¹¶ä¸”ä¸èƒ½ä¿è¯ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚</p><p></p>
<p></p><p>ï¼ˆä¸‰ï¼‰ï¼šæœ¬æ–‡çš„é—®é¢˜ï¼š</p><p></p>
<p></p><p>æœ¬æ–‡è®¤ä¸ºï¼Œç°æœ‰çš„æ•°æ®å¢å¼ºæŠ€æœ¯ä¸èƒ½å¾ˆå¥½åœ°è§£å†³æ•°æ®ä¸è¶³çš„é—®é¢˜ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œç§°ä¸º InstaGenï¼Œè¯¥æŠ€æœ¯å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆå›¾åƒï¼Œå¹¶ä¸”å¯ä»¥ä¿è¯ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚</p><p></p>
<p></p><p>ï¼ˆå››ï¼‰ï¼šæœ¬æ–‡çš„æ–¹æ³•ï¼š</p><p></p>
<p></p><p>InstaGen æ˜¯ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ•°æ®å¢å¼ºæŠ€æœ¯ã€‚æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œå¯ä»¥ä»å™ªå£°ç”Ÿæˆå›¾åƒã€‚InstaGen å°†ä¸€ä¸ªå®ä¾‹çº§æ¥åœ°å¤´é›†æˆåˆ°é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨ç”Ÿæˆå›¾åƒä¸­å®šä½å®ä¾‹ã€‚æ¥åœ°å¤´é€šè¿‡ä½¿ç”¨æ¥è‡ªç°æˆå¯¹è±¡æ£€æµ‹å™¨çš„ç›‘ç£å’Œä¸€ç§åœ¨æ£€æµ‹å™¨æ— æ³•è¯†åˆ«çš„ç±»ä¸Šè¿›è¡Œçš„è‡ªè®­ç»ƒç­–ç•¥ï¼Œæ¥è®­ç»ƒä»¥å°†ç±»åˆ«åç§°çš„æ–‡æœ¬åµŒå…¥ä¸æ‰©æ•£æ¨¡å‹çš„ç©ºé—´ç‰¹å¾å¯¹é½ã€‚</p><p></p>
<p></p><p>ï¼ˆäº”ï¼‰ï¼šæœ¬æ–‡çš„å®éªŒç»“æœï¼š</p><p></p>
<p></p><p>æœ¬æ–‡åœ¨ PASCAL VOC å’Œ COCO æ•°æ®é›†ä¸Šå¯¹ InstaGen è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒInstaGen å¯ä»¥æœ‰æ•ˆåœ°å¢å¼ºå¯¹è±¡æ£€æµ‹å™¨çš„æ€§èƒ½ã€‚åœ¨ PASCAL VOC æ•°æ®é›†ä¸Šï¼ŒInstaGen å°† Faster R-CNN çš„ AP æé«˜äº† 4.6 ä¸ªç™¾åˆ†ç‚¹ã€‚åœ¨ COCO æ•°æ®é›†ä¸Šï¼ŒInstaGen å°† Faster R-CNN çš„ AP æé«˜äº† 4.8 ä¸ªç™¾åˆ†ç‚¹ã€‚</p><p></p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæ„å»ºå›¾åƒåˆæˆå™¨ï¼šé‡‡ç”¨é¢„è®­ç»ƒçš„ Stable Diffusion æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨æ£€æµ‹æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥ç”Ÿæˆå…·æœ‰çœŸå®æ„Ÿä¸”åŒ…å«æŒ‡å®šç±»åˆ«çš„å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šå¼•å…¥å®ä¾‹çº§æ¥åœ°å¤´ï¼šè®¾è®¡ä¸€ç§å®ä¾‹çº§æ¥åœ°å¤´ï¼Œå°†ç±»åˆ«åç§°çš„æ–‡æœ¬åµŒå…¥ä¸æ‰©æ•£æ¨¡å‹çš„ç©ºé—´ç‰¹å¾å¯¹é½ï¼Œä»è€Œç”Ÿæˆå¯¹è±¡å®ä¾‹çš„è¾¹ç•Œæ¡†ã€‚
ï¼ˆ3ï¼‰ï¼šç›‘ç£å­¦ä¹ å’Œè‡ªè®­ç»ƒï¼šä½¿ç”¨æ¥è‡ªç°æœ‰å¯¹è±¡æ£€æµ‹å™¨çš„ç›‘ç£å’Œä¸€ç§åœ¨æ£€æµ‹å™¨æ— æ³•è¯†åˆ«çš„ç±»ä¸Šè¿›è¡Œçš„è‡ªè®­ç»ƒç­–ç•¥ï¼Œæ¥è®­ç»ƒæ¥åœ°å¤´ã€‚
ï¼ˆ4ï¼‰ï¼šæ•°æ®åˆæˆå™¨ç”Ÿæˆåˆæˆæ•°æ®é›†ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„æ¥åœ°å¤´å’Œå›¾åƒåˆæˆå™¨ï¼Œç”ŸæˆåŒ…å«å¯¹è±¡å®ä¾‹åŠå…¶è¾¹ç•Œæ¡†çš„åˆæˆæ•°æ®é›†ã€‚
ï¼ˆ5ï¼‰ï¼šåœ¨åˆæˆæ•°æ®é›†ä¸Šè®­ç»ƒå¯¹è±¡æ£€æµ‹å™¨ï¼šå°†åˆæˆæ•°æ®é›†ä¸çœŸå®æ•°æ®é›†ç›¸ç»“åˆï¼Œè®­ç»ƒå¯¹è±¡æ£€æµ‹å™¨ï¼Œä»¥æé«˜æ£€æµ‹æ€§èƒ½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç§°ä¸ºInstaGençš„æ•°æ®é›†åˆæˆç®¡é“ï¼Œè¯¥ç®¡é“èƒ½å¤Ÿä¸ºä»»æ„ç±»åˆ«ç”Ÿæˆå…·æœ‰å¯¹è±¡è¾¹ç•Œæ¡†çš„å›¾åƒï¼Œä½œä¸ºæ„å»ºå¤§è§„æ¨¡åˆæˆæ•°æ®é›†ä»¥è®­ç»ƒå¯¹è±¡æ£€æµ‹å™¨çš„å…è´¹èµ„æºã€‚æˆ‘ä»¬è¿›è¡Œäº†è¯¦å°½çš„å®éªŒï¼Œä»¥å±•ç¤ºåœ¨åˆæˆæ•°æ®ä¸Šè®­ç»ƒçš„æœ‰æ•ˆæ€§ï¼Œä»¥æé«˜æ£€æµ‹æ€§èƒ½æˆ–æ‰©å±•æ£€æµ‹ç±»åˆ«çš„æ•°é‡ã€‚åœ¨å„ç§æ£€æµ‹åœºæ™¯ä¸­ï¼ŒåŒ…æ‹¬å¼€æ”¾è¯æ±‡è¡¨ï¼ˆ+4.5APï¼‰å’Œæ•°æ®ç¨€ç–ï¼ˆ+1.2âˆ¼5.2APï¼‰æ£€æµ‹ä¸­ï¼Œéƒ½å–å¾—äº†æ˜¾ç€çš„æ”¹è¿›ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ•°æ®åˆæˆç®¡é“InstaGenï¼Œè¯¥ç®¡é“èƒ½å¤Ÿä¸ºä»»æ„ç±»åˆ«ç”Ÿæˆå…·æœ‰å¯¹è±¡è¾¹ç•Œæ¡†çš„å›¾åƒã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§å®ä¾‹çº§æ¥åœ°å¤´ï¼Œå°†ç±»åˆ«åç§°çš„æ–‡æœ¬åµŒå…¥ä¸æ‰©æ•£æ¨¡å‹çš„ç©ºé—´ç‰¹å¾å¯¹é½ï¼Œä»è€Œç”Ÿæˆå¯¹è±¡å®ä¾‹çš„è¾¹ç•Œæ¡†ã€‚</li>
<li>ä½¿ç”¨æ¥è‡ªç°æœ‰å¯¹è±¡æ£€æµ‹å™¨çš„ç›‘ç£å’Œä¸€ç§åœ¨æ£€æµ‹å™¨æ— æ³•è¯†åˆ«çš„ç±»ä¸Šè¿›è¡Œçš„è‡ªè®­ç»ƒç­–ç•¥ï¼Œæ¥è®­ç»ƒæ¥åœ°å¤´ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨PASCAL VOCå’ŒCOCOæ•°æ®é›†ä¸Šï¼ŒInstaGenå°†Faster R-CNNçš„APæé«˜äº†4.6ä¸ªç™¾åˆ†ç‚¹å’Œ4.8ä¸ªç™¾åˆ†ç‚¹ã€‚</li>
<li>åœ¨å¼€æ”¾è¯æ±‡è¡¨å’Œæ•°æ®ç¨€ç–æ£€æµ‹ä¸­ï¼ŒInstaGenå–å¾—äº†æ˜¾ç€çš„æ”¹è¿›ã€‚
å·¥ä½œé‡ï¼š</li>
<li>InstaGenæ˜¯ä¸€ç§æ•°æ®åˆæˆç®¡é“ï¼Œéœ€è¦é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å’Œå®ä¾‹çº§æ¥åœ°å¤´ã€‚</li>
<li>InstaGenéœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒæ¥åœ°å¤´ã€‚</li>
<li>InstaGenéœ€è¦å¤§é‡çš„æ—¶é—´æ¥ç”Ÿæˆåˆæˆæ•°æ®é›†ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e5bc75a4d614b9abf0055ef9f09e29eb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-dcaa5f4430aaa302f904c1eb77cd432c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ed1d3b41f15d36193b946e6064581300.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6998a66afc9f7f895bfb98faa0596297.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-85a17fc9e78759363117b1e3dbd18da2.jpg" align="middle">
</details>




<h2 id="Scalable-Diffusion-Models-with-State-Space-Backbone"><a href="#Scalable-Diffusion-Models-with-State-Space-Backbone" class="headerlink" title="Scalable Diffusion Models with State Space Backbone"></a>Scalable Diffusion Models with State Space Backbone</h2><p><strong>Authors:Zhengcong Fei, Mingyuan Fan, Changqian Yu, Junshi Huang</strong></p>
<p>This paper presents a new exploration into a category of diffusion models built upon state space architecture. We endeavor to train diffusion models for image data, wherein the traditional U-Net backbone is supplanted by a state space backbone, functioning on raw patches or latent space. Given its notable efficacy in accommodating long-range dependencies, Diffusion State Space Models (DiS) are distinguished by treating all inputs including time, condition, and noisy image patches as tokens. Our assessment of DiS encompasses both unconditional and class-conditional image generation scenarios, revealing that DiS exhibits comparable, if not superior, performance to CNN-based or Transformer-based U-Net architectures of commensurate size. Furthermore, we analyze the scalability of DiS, gauged by the forward pass complexity quantified in Gflops. DiS models with higher Gflops, achieved through augmentation of depth/width or augmentation of input tokens, consistently demonstrate lower FID. In addition to demonstrating commendable scalability characteristics, DiS-H/2 models in latent space achieve performance levels akin to prior diffusion models on class-conditional ImageNet benchmarks at the resolution of 256$\times$256 and 512$\times$512, while significantly reducing the computational burden. The code and models are available at: <a href="https://github.com/feizc/DiS">https://github.com/feizc/DiS</a>. </p>
<p><a href="http://arxiv.org/abs/2402.05608v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨çŠ¶æ€ç©ºé—´æ¶æ„æ„å»ºçš„æ–°å‹æ‰©æ•£æ¨¡å‹ï¼Œåœ¨å›¾åƒæ•°æ®ä¸Šå®ç°å¯ä¸ U å½¢å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„åª²ç¾çš„æ€§èƒ½ï¼Œå¹¶å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>åŸºäºçŠ¶æ€ç©ºé—´æ¶æ„çš„æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒæ•°æ®ç”Ÿæˆä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå¯ä¸åŸºäº U å½¢å·ç§¯ç¥ç»ç½‘ç»œæˆ–åŸºäº Transformer çš„ U å½¢å·ç§¯ç¥ç»ç½‘ç»œæ¶æ„å®ç°ç›¸å½“çš„æ€§èƒ½ï¼Œç”šè‡³ä¼˜äºå®ƒä»¬ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹çš„çŠ¶æ€ç©ºé—´æ¨¡å‹å°†æ—¶é—´ã€æ¡ä»¶å’Œå™ªå£°å›¾åƒå—ç­‰æ‰€æœ‰è¾“å…¥éƒ½è§†ä¸ºæ ‡è®°ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹çš„çŠ¶æ€ç©ºé—´æ¨¡å‹åœ¨æ— æ¡ä»¶å›¾åƒç”Ÿæˆå’Œç±»åˆ«æ¡ä»¶å›¾åƒç”Ÿæˆåœºæ™¯ä¸­å‡è¡¨ç°è‰¯å¥½ã€‚</li>
<li>é€šè¿‡å¢åŠ æ·±åº¦/å®½åº¦æˆ–å¢åŠ è¾“å…¥æ ‡è®°ï¼Œæ‰©æ•£æ¨¡å‹çš„çŠ¶æ€ç©ºé—´æ¨¡å‹çš„æ­£å‘ä¼ é€’å¤æ‚åº¦ï¼ˆä»¥ Gflops ä¸ºå•ä½ï¼‰æ›´é«˜ï¼Œå¹¶ä¸”å§‹ç»ˆè¡¨ç°å‡ºæ›´ä½çš„ FIDã€‚</li>
<li>æ‰©æ•£æ¨¡å‹çš„çŠ¶æ€ç©ºé—´æ¨¡å‹å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚</li>
<li>åœ¨åˆ†è¾¨ç‡ä¸º 256Ã—256 å’Œ 512Ã—512 çš„ç±»åˆ«æ¡ä»¶ ImageNet åŸºå‡†ä¸Šï¼Œæ‰©æ•£æ¨¡å‹çš„çŠ¶æ€ç©ºé—´æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­å®ç°äº†ä¸å…ˆå‰æ‰©æ•£æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶å¤§å¹…é™ä½äº†è®¡ç®—è´Ÿæ‹…ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ä»£ç å’Œæ¨¡å‹å¯åœ¨ <a href="https://github.com/feizc/DiS">https://github.com/feizc/DiS</a> ä¸Šè·å–ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºçŠ¶æ€ç©ºé—´çš„å¯æ‰©å±•æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šZhengcong Fei, Mingyuan Fan, Changqian Yu, Junshi Huang</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ˜†ä»‘ç§‘æŠ€</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€çŠ¶æ€ç©ºé—´ã€å¯æ‰©å±•æ€§ã€å›¾åƒç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.05608ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/feizc/DiS</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹ä½œä¸ºå¼ºå¤§çš„æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼Œè¿‘å¹´æ¥åœ¨å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå¹¿æ³›åº”ç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å›¾åƒåˆ°å›¾åƒç”Ÿæˆã€è§†é¢‘ç”Ÿæˆã€è¯­éŸ³åˆæˆå’Œ 3D åˆæˆç­‰é¢†åŸŸã€‚æ‰©æ•£æ¨¡å‹çš„å‘å±•ç¦»ä¸å¼€é‡‡æ ·ç®—æ³•å’Œæ¨¡å‹éª¨å¹²çš„è¿›æ­¥ï¼Œå…¶ä¸­ U-Net æ˜¯æ‰©æ•£æ¨¡å‹ä¸­å¸¸ç”¨çš„éª¨å¹²ç½‘ç»œï¼Œä½†å…¶åœ¨å¤„ç†é•¿ç¨‹ä¾èµ–å…³ç³»æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚
(2)ï¼šè¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šä¼ ç»Ÿçš„æ‰©æ•£æ¨¡å‹éª¨å¹²ç½‘ç»œï¼Œå¦‚ U-Netï¼Œåœ¨å¤„ç†é•¿ç¨‹ä¾èµ–å…³ç³»æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†åŸºäºçŠ¶æ€ç©ºé—´çš„æ‰©æ•£æ¨¡å‹ï¼ˆDiSï¼‰ï¼Œè¯¥æ¨¡å‹å°†æ—¶é—´ã€æ¡ä»¶å’Œå™ªå£°å›¾åƒå—è§†ä¸ºæ ‡è®°ï¼Œå¹¶ä½¿ç”¨çŠ¶æ€ç©ºé—´éª¨å¹²ç½‘ç»œæ¥å¤„ç†è¿™äº›æ ‡è®°ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºçš„ DiS æ¨¡å‹å…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š</li>
<li>å°†æ—¶é—´ã€æ¡ä»¶å’Œå™ªå£°å›¾åƒå—è§†ä¸ºæ ‡è®°ï¼Œå¹¶ä½¿ç”¨çŠ¶æ€ç©ºé—´éª¨å¹²ç½‘ç»œæ¥å¤„ç†è¿™äº›æ ‡è®°ã€‚</li>
<li>DiS æ¨¡å‹å¯ä»¥å¤„ç†åŸå§‹å›¾åƒå—æˆ–æ½œåœ¨ç©ºé—´ä¸­çš„æ ‡è®°ã€‚</li>
<li>
<p>DiS æ¨¡å‹å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œå¯ä»¥é€šè¿‡å¢åŠ æ·±åº¦ã€å®½åº¦æˆ–è¾“å…¥æ ‡è®°çš„æ•°é‡æ¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚
(4)ï¼šå®éªŒç»“æœä¸æ€§èƒ½ï¼šæœ¬æ–‡åœ¨æ— æ¡ä»¶å’Œç±»æ¡ä»¶å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šå¯¹ DiS æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ DiS æ¨¡å‹ä¸åŸºäº CNN æˆ– Transformer çš„ U-Net æ¨¡å‹å…·æœ‰ç›¸å½“æˆ–æ›´å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜åˆ†æäº† DiS æ¨¡å‹çš„å¯æ‰©å±•æ€§ï¼Œç»“æœè¡¨æ˜ DiS æ¨¡å‹å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œå¯ä»¥é€šè¿‡å¢åŠ æ·±åº¦ã€å®½åº¦æˆ–è¾“å…¥æ ‡è®°çš„æ•°é‡æ¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚åœ¨ ImageNet æ•°æ®é›†ä¸Šï¼ŒDiS-H/2 æ¨¡å‹åœ¨åˆ†è¾¨ç‡ä¸º 256Ã—256 å’Œ 512Ã—512 çš„ç±»æ¡ä»¶å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†ä¸ä¹‹å‰çš„æ‰©æ•£æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—è´Ÿæ‹…ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§åŸºäºçŠ¶æ€ç©ºé—´çš„æ‰©æ•£æ¨¡å‹ï¼ˆDiSï¼‰ï¼Œè¯¥æ¨¡å‹å°†æ—¶é—´ã€æ¡ä»¶å’Œå™ªå£°å—è§†ä¸ºæ ‡è®°ï¼Œå¹¶ä½¿ç”¨çŠ¶æ€ç©ºé—´éª¨å¹²ç½‘ç»œæ¥å¤„ç†è¿™äº›æ ‡è®°ã€‚
ï¼ˆ2ï¼‰ï¼šDiSæ¨¡å‹å¯ä»¥å¤„ç†åŸå§‹å—æˆ–æ½œåœ¨ç©ºé—´ä¸­çš„æ ‡è®°ã€‚
ï¼ˆ3ï¼‰ï¼šDiSæ¨¡å‹å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œå¯ä»¥é€šè¿‡å¢åŠ æ·±åº¦ã€å®½åº¦æˆ–è¾“å…¥æ ‡è®°çš„æ•°é‡æ¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºçŠ¶æ€ç©ºé—´çš„æ‰©æ•£æ¨¡å‹ï¼ˆDiSï¼‰ï¼Œè¯¥æ¨¡å‹å°†æ—¶é—´ã€æ¡ä»¶å’Œå™ªå£°å—è§†ä¸ºæ ‡è®°ï¼Œå¹¶ä½¿ç”¨çŠ¶æ€ç©ºé—´éª¨å¹²ç½‘ç»œæ¥å¤„ç†è¿™äº›æ ‡è®°ã€‚DiS é‡‡ç”¨äº†ä¸€ç§ç»Ÿä¸€çš„æ–¹æ³•æ¥å¤„ç†æ‰€æœ‰è¾“å…¥ï¼ŒåŒ…æ‹¬æ—¶é—´ã€æ¡ä»¶å’Œå™ªå£°å›¾åƒå—ï¼Œå°†å®ƒä»¬è§†ä¸ºè¿æ¥çš„æ ‡è®°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDiS ä¸åŸºäº CNN æˆ– Transformer çš„ U-Net æ¨¡å‹ç›¸æ¯”å…·æœ‰ç›¸å½“æˆ–æ›´å¥½çš„æ€§èƒ½ï¼ŒåŒæ—¶ç»§æ‰¿äº†çŠ¶æ€ç©ºé—´æ¨¡å‹ç±»çš„æ˜¾ç€å¯æ‰©å±•æ€§ç‰¹å¾ã€‚æˆ‘ä»¬è®¤ä¸º DiS å¯ä»¥ä¸ºæœªæ¥ç ”ç©¶æ‰©æ•£æ¨¡å‹ä¸­çš„éª¨å¹²ç½‘ç»œæä¾›æœ‰ä»·å€¼çš„è§è§£ï¼Œå¹¶æœ‰åŠ©äºæ¨è¿›å¤§è§„æ¨¡å¤šæ¨¡æ€æ•°æ®é›†ä¸­çš„ç”Ÿæˆå»ºæ¨¡ã€‚é‰´äºæœ¬ç ”ç©¶ä¸­æå‡ºçš„ä»¤äººé¼“èˆçš„å¯æ‰©å±•æ€§ç»“æœï¼Œæœªæ¥çš„åŠªåŠ›åº”é›†ä¸­åœ¨å°† DiS è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤§çš„æ¨¡å‹å’Œæ ‡è®°è®¡æ•°ä¸Šã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
DiS æ¨¡å‹å°†æ—¶é—´ã€æ¡ä»¶å’Œå™ªå£°å—è§†ä¸ºæ ‡è®°ï¼Œå¹¶ä½¿ç”¨çŠ¶æ€ç©ºé—´éª¨å¹²ç½‘ç»œæ¥å¤„ç†è¿™äº›æ ‡è®°ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å¤„ç†é•¿ç¨‹ä¾èµ–å…³ç³»ã€‚
DiS æ¨¡å‹å¯ä»¥å¤„ç†åŸå§‹å—æˆ–æ½œåœ¨ç©ºé—´ä¸­çš„æ ‡è®°ï¼Œè¿™ä½¿å¾—å®ƒå¯ä»¥åº”ç”¨äºå„ç§å›¾åƒç”Ÿæˆä»»åŠ¡ã€‚
DiS æ¨¡å‹å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œå¯ä»¥é€šè¿‡å¢åŠ æ·±åº¦ã€å®½åº¦æˆ–è¾“å…¥æ ‡è®°çš„æ•°é‡æ¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š
åœ¨æ— æ¡ä»¶å’Œç±»æ¡ä»¶å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒDiS æ¨¡å‹ä¸åŸºäº CNN æˆ– Transformer çš„ U-Net æ¨¡å‹å…·æœ‰ç›¸å½“æˆ–æ›´å¥½çš„æ€§èƒ½ã€‚
åœ¨ ImageNet æ•°æ®é›†ä¸Šï¼ŒDiS-H/2 æ¨¡å‹åœ¨åˆ†è¾¨ç‡ä¸º 256Ã—256 å’Œ 512Ã—512 çš„ç±»æ¡ä»¶å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†ä¸ä¹‹å‰çš„æ‰©æ•£æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†è®¡ç®—è´Ÿæ‹…ã€‚
å·¥ä½œé‡ï¼š
DiS æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æˆæœ¬ä¸åŸºäº CNN æˆ– Transformer çš„ U-Net æ¨¡å‹ç›¸å½“ã€‚
DiS æ¨¡å‹çš„å¯æ‰©å±•æ€§ä½¿å¾—å®ƒå¯ä»¥åº”ç”¨äºå„ç§å›¾åƒç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆã€è§†é¢‘ç”Ÿæˆå’Œ 3D åˆæˆã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-6bb4b2235878abe86e04f19f24047beb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1d4bb00838a5fb623fcc9eb998c2c6b9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-adf0dc0a97f9ca167de7eccda01fe6df.jpg" align="middle">
</details>




<h2 id="SPAD-Spatially-Aware-Multiview-Diffusers"><a href="#SPAD-Spatially-Aware-Multiview-Diffusers" class="headerlink" title="SPAD : Spatially Aware Multiview Diffusers"></a>SPAD : Spatially Aware Multiview Diffusers</h2><p><strong>Authors:Yash Kant, Ziyi Wu, Michael Vasilkovsky, Guocheng Qian, Jian Ren, Riza Alp Guler, Bernard Ghanem, Sergey Tulyakov, Igor Gilitschenski, Aliaksandr Siarohin</strong></p>
<p>We present SPAD, a novel approach for creating consistent multi-view images from text prompts or single images. To enable multi-view generation, we repurpose a pretrained 2D diffusion model by extending its self-attention layers with cross-view interactions, and fine-tune it on a high quality subset of Objaverse. We find that a naive extension of the self-attention proposed in prior work (e.g. MVDream) leads to content copying between views. Therefore, we explicitly constrain the cross-view attention based on epipolar geometry. To further enhance 3D consistency, we utilize Plucker coordinates derived from camera rays and inject them as positional encoding. This enables SPAD to reason over spatial proximity in 3D well. In contrast to recent works that can only generate views at fixed azimuth and elevation, SPAD offers full camera control and achieves state-of-the-art results in novel view synthesis on unseen objects from the Objaverse and Google Scanned Objects datasets. Finally, we demonstrate that text-to-3D generation using SPAD prevents the multi-face Janus issue. See more details at our webpage: <a href="https://yashkant.github.io/spad">https://yashkant.github.io/spad</a> </p>
<p><a href="http://arxiv.org/abs/2402.05235v1">PDF</a> Webpage: <a href="https://yashkant.github.io/spad">https://yashkant.github.io/spad</a></p>
<p><strong>Summary</strong><br>è·¨è§†è§’å›¾åƒç”Ÿæˆæ¨¡å‹ SPADï¼šè‡ªæˆ‘æ³¨æ„å’Œç©ºé—´ç¼–ç çš„ç»“åˆï¼Œå®ç°æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SPAD æ˜¯ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå¯ä»¥ä»æ–‡æœ¬æç¤ºæˆ–å•ä¸ªå›¾åƒç”Ÿæˆä¸€è‡´çš„å¤šè§†è§’å›¾åƒã€‚</li>
<li>SPAD æ˜¯é€šè¿‡æ‰©å±•é¢„è®­ç»ƒçš„ 2D æ‰©æ•£æ¨¡å‹çš„è‡ªæ³¨æ„åŠ›å±‚æ¥å®ç°å¤šè§†è§’ç”Ÿæˆï¼Œå¹¶å¯¹ Objaverse çš„é«˜è´¨é‡å­é›†è¿›è¡Œå¾®è°ƒã€‚</li>
<li>SPAD æ˜¾ç¤ºï¼Œå…ˆå‰çš„ç ”ç©¶æå‡ºçš„è‡ªæˆ‘æ³¨æ„çš„æœ´ç´ æ‰©å±•ï¼ˆä¾‹å¦‚ MVDreamï¼‰å¯¼è‡´è§†è§’ä¹‹é—´çš„å†…å®¹å¤åˆ¶ã€‚</li>
<li>SPAD æ˜¾å¼åœ°é™åˆ¶åŸºäºæçº¿å‡ ä½•çš„è·¨è§†è§’æ³¨æ„ã€‚</li>
<li>SPAD åˆ©ç”¨ä»ç›¸æœºå°„çº¿æ´¾ç”Ÿçš„ PlÃ¼cker åæ ‡ï¼Œå¹¶å°†å®ƒä»¬æ³¨å…¥ä½œä¸ºä½ç½®ç¼–ç ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼º 3D ä¸€è‡´æ€§ã€‚</li>
<li>ä¸åªèƒ½åœ¨å›ºå®šæ–¹ä½è§’å’Œä»°è§’ç”Ÿæˆè§†å›¾çš„æœ€è¿‘å·¥ä½œç›¸æ¯”ï¼ŒSPAD æä¾›äº†å®Œå…¨çš„ç›¸æœºæ§åˆ¶ï¼Œå¹¶åœ¨ Objaverse å’Œ Google Scanned Objects æ•°æ®é›†ä¸Šçœ‹ä¸è§çš„ç‰©ä½“çš„æ–°é¢–è§†å›¾åˆæˆä¸­å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</li>
<li>ä½¿ç”¨ SPAD è¿›è¡Œæ–‡æœ¬åˆ° 3D ç”Ÿæˆæ¶ˆé™¤äº†å¤šé¢ Janus é—®é¢˜ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šSPADï¼šç©ºé—´æ„ŸçŸ¥å¤šè§†å›¾æ‰©æ•£å™¨</li>
<li>ä½œè€…ï¼šYash Kant, Ziyi Wu, Michael Vasilkovsky, Guocheng Qian, Jian Ren, Riza Alp Guler, Bernard Ghanem, Sergey Tulyakov, Igor Gilitschenski, Aliaksandr Siarohin</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¤šä¼¦å¤šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šå¤šè§†å›¾ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€æ–‡æœ¬åˆ° 3D</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://yashkant.github.io/spad/ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤šè§†å›¾ç”Ÿæˆæ˜¯æŒ‡ä»æ–‡æœ¬æç¤ºæˆ–å•ä¸ªå›¾åƒç”Ÿæˆä¸€ç»„åœ¨ 3D ç©ºé—´ä¸­ä¸€è‡´çš„å›¾åƒã€‚è¿™å¯¹äºè®¸å¤šåº”ç”¨å¾ˆæœ‰ç”¨ï¼Œä¾‹å¦‚å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®å’Œ 3D å»ºæ¨¡ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨ 2D æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆå¤šè§†å›¾å›¾åƒã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä¼šå¯¼è‡´è§†å›¾ä¹‹é—´å‡ºç°ä¸ä¸€è‡´ï¼Œä¾‹å¦‚å¯¹è±¡å½¢çŠ¶æˆ–çº¹ç†ä¸åŒ¹é…ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¤šè§†å›¾ç”Ÿæˆæ–¹æ³• SPADã€‚SPAD é€šè¿‡åœ¨ 2D æ‰©æ•£æ¨¡å‹ä¸­å¼•å…¥è·¨è§†å›¾äº¤äº’æ¥å®ç°å¤šè§†å›¾ç”Ÿæˆã€‚æ­¤å¤–ï¼ŒSPAD è¿˜åˆ©ç”¨äº† PlÃ¼cker åæ ‡æ¥å¢å¼º 3D ä¸€è‡´æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šSPAD åœ¨ Objaverse å’Œ Google Scanned Objects æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼ŒSPAD åœ¨æ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒSPAD è¿˜èƒ½å¤Ÿé˜²æ­¢å¤šé¢ Janus é—®é¢˜ï¼Œå³ç”Ÿæˆçš„å›¾åƒåœ¨ä¸åŒè§†å›¾ä¸­å…·æœ‰ä¸åŒçš„å¤–è§‚ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): SPADçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†å¤šè§†å›¾ç”Ÿæˆé—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªæ‰©æ•£æ¨¡å‹é—®é¢˜ã€‚SPADä½¿ç”¨ä¸€ä¸ª2Dæ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆæ¯ä¸ªè§†å›¾çš„å›¾åƒï¼Œå¹¶é€šè¿‡åœ¨æ‰©æ•£æ¨¡å‹ä¸­å¼•å…¥è·¨è§†å›¾äº¤äº’æ¥ç¡®ä¿è§†å›¾ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚
(2): SPADä½¿ç”¨PlÃ¼ckeråæ ‡æ¥è¡¨ç¤º3Dç©ºé—´ä¸­çš„ç‚¹ã€‚PlÃ¼ckeråæ ‡å…·æœ‰ä¸å˜æ€§ï¼Œè¿™æ„å‘³ç€å®ƒä»¬ä¸å—è§†è§’å’ŒæŠ•å½±å˜æ¢çš„å½±å“ã€‚SPADåˆ©ç”¨PlÃ¼ckeråæ ‡æ¥å¢å¼º3Dä¸€è‡´æ€§ï¼Œå¹¶é˜²æ­¢å¤šé¢Janusé—®é¢˜ã€‚
(3): SPADåœ¨Objaverseå’ŒGoogleScannedObjectsæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼ŒSPADåœ¨æ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒSPADè¿˜èƒ½å¤Ÿé˜²æ­¢å¤šé¢Janusé—®é¢˜ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šSPADæ˜¯ä¸€ç§æ–°é¢–çš„å¤šè§†å›¾ç”Ÿæˆæ¡†æ¶ï¼Œå®ƒå°†æ–‡æœ¬æˆ–å›¾åƒè¾“å…¥è½¬æ¢ä¸ºå¤šä¸ªè§†å›¾ã€‚SPADåœ¨é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„è‡ªæ³¨æ„åŠ›å±‚ä¸­å¼•å…¥äº†æçº¿æ³¨æ„åŠ›ï¼Œä»¥ä¿ƒè¿›å¤šè§†å›¾äº¤äº’å¹¶æ”¹è¿›ç›¸æœºæ§åˆ¶ã€‚æ­¤å¤–ï¼ŒSPADä½¿ç”¨PlÃ¼ckerä½ç½®ç¼–ç å¢å¼ºäº†è‡ªæ³¨æ„åŠ›å±‚ï¼Œä»¥é€šè¿‡é˜²æ­¢å¯¹è±¡çš„ç¿»è½¬è§†å›¾é¢„æµ‹æ¥è¿›ä¸€æ­¥æ”¹è¿›ç›¸æœºæ§åˆ¶ã€‚SPADåœ¨Objaverseå’ŒGoogleScannedObjectsæ•°æ®é›†ä¸Šè¿›è¡Œäº†ä¸¥æ ¼çš„è¯„ä¼°ï¼Œå¹¶åœ¨å›¾åƒæ¡ä»¶çš„æ–°è§†å›¾åˆæˆæ–¹é¢å±•ç¤ºäº†æœ€å…ˆè¿›çš„ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å°†å¤šè§†å›¾ç”Ÿæˆé—®é¢˜è½¬åŒ–ä¸ºæ‰©æ•£æ¨¡å‹é—®é¢˜ï¼Œå¹¶é€šè¿‡åœ¨æ‰©æ•£æ¨¡å‹ä¸­å¼•å…¥è·¨è§†å›¾äº¤äº’æ¥ç¡®ä¿è§†å›¾ä¹‹é—´çš„ä¸€è‡´æ€§ã€‚</li>
<li>ä½¿ç”¨PlÃ¼ckeråæ ‡æ¥è¡¨ç¤º3Dç©ºé—´ä¸­çš„ç‚¹ï¼Œå¹¶åˆ©ç”¨PlÃ¼ckeråæ ‡æ¥å¢å¼º3Dä¸€è‡´æ€§ï¼Œé˜²æ­¢å¤šé¢Janusé—®é¢˜ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨Objaverseå’ŒGoogleScannedObjectsæ•°æ®é›†ä¸Šï¼ŒSPADåœ¨æ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>SPADèƒ½å¤Ÿé˜²æ­¢å¤šé¢Janusé—®é¢˜ï¼Œå³ç”Ÿæˆçš„å›¾åƒåœ¨ä¸åŒè§†å›¾ä¸­å…·æœ‰ä¸åŒçš„å¤–è§‚ã€‚
å·¥ä½œé‡ï¼š</li>
<li>SPADçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥åœ¨PyTorchä¸­è½»æ¾å®ç°ã€‚</li>
<li>SPADçš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¿«é€Ÿï¼Œå¹¶ä¸”å¯ä»¥åœ¨å•ä¸ªGPUä¸Šå®Œæˆã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-afe3524a8f81d817d06d1d9498a1728a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3709a9941aada6c4d3ed35934e311765.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a80a51acf35ce9d57c5584647e5cca12.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>Talking Head Generation</title>
    <url>/2024/02/13/Paper/2024-02-13/Talking%20Head%20Generation/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-13-æ›´æ–°"><a href="#2024-02-13-æ›´æ–°" class="headerlink" title="2024-02-13 æ›´æ–°"></a>2024-02-13 æ›´æ–°</h1><h2 id="DiffSpeaker-Speech-Driven-3D-Facial-Animation-with-Diffusion-Transformer"><a href="#DiffSpeaker-Speech-Driven-3D-Facial-Animation-with-Diffusion-Transformer" class="headerlink" title="DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion   Transformer"></a>DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion   Transformer</h2><p><strong>Authors:Zhiyuan Ma, Xiangyu Zhu, Guojun Qi, Chen Qian, Zhaoxiang Zhang, Zhen Lei</strong></p>
<p>Speech-driven 3D facial animation is important for many multimedia applications. Recent work has shown promise in using either Diffusion models or Transformer architectures for this task. However, their mere aggregation does not lead to improved performance. We suspect this is due to a shortage of paired audio-4D data, which is crucial for the Transformer to effectively perform as a denoiser within the Diffusion framework. To tackle this issue, we present DiffSpeaker, a Transformer-based network equipped with novel biased conditional attention modules. These modules serve as substitutes for the traditional self/cross-attention in standard Transformers, incorporating thoughtfully designed biases that steer the attention mechanisms to concentrate on both the relevant task-specific and diffusion-related conditions. We also explore the trade-off between accurate lip synchronization and non-verbal facial expressions within the Diffusion paradigm. Experiments show our model not only achieves state-of-the-art performance on existing benchmarks, but also fast inference speed owing to its ability to generate facial motions in parallel. </p>
<p><a href="http://arxiv.org/abs/2402.05712v1">PDF</a> 9 pages, 5 figures. Code is avalable at   <a href="https://github.com/theEricMa/DiffSpeaker">https://github.com/theEricMa/DiffSpeaker</a></p>
<p><strong>Summary</strong><br>é€šè¿‡æå‡ºå¸¦åæ¡ä»¶æ³¨æ„åŠ›çš„æ‰©æ•£æ¨¡å‹ï¼Œæˆ‘ä»¬è§£å†³äº†éŸ³è§†é¢‘é…å¯¹æ•°æ®çš„ç¨€ç¼ºé—®é¢˜ï¼Œåœ¨ä¿æŒéŸ³è§†é¢‘åŒæ­¥çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„é¢éƒ¨åŠ¨ç”»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºè¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»ã€‚</li>
<li>ä½¿ç”¨å¸¦åæ¡ä»¶æ³¨æ„åŠ›æ¨¡å—ï¼Œå¯ä»¥æ›´å¥½åœ°å¤„ç†éŸ³è§†é¢‘é…å¯¹æ•°æ®çš„ç¨€ç¼ºé—®é¢˜ã€‚</li>
<li>åœ¨ç°æœ‰åŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>å¯ä»¥å¿«é€Ÿç”Ÿæˆé¢éƒ¨åŠ¨ç”»ï¼Œæ¨ç†é€Ÿåº¦å¿«ã€‚</li>
<li>å¯ä»¥æœ‰æ•ˆåœ°ç”Ÿæˆéè¯­è¨€é¢éƒ¨è¡¨æƒ…ã€‚</li>
<li>å¯ä»¥æ§åˆ¶åŠ¨ç”»è¿‡ç¨‹ä¸­çš„å˜´å‹åŒæ­¥å’Œéè¯­è¨€é¢éƒ¨è¡¨æƒ…ä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>è¯¥æ¨¡å‹å¯ä»¥ç”¨äºå„ç§å¤šåª’ä½“åº”ç”¨ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šDiffSpeakerï¼šåŸºäºæ‰©æ•£å˜æ¢å™¨çš„è¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»ï¼ˆDiffSpeaker: Speech-Driven 3DFacial Animation with Diffusion Transformerï¼‰</li>
<li>ä½œè€…ï¼šZhiyuan Ma, Xiangyu Zhu, Guojun Qi, Chen Qian, Zhaoxiang Zhang, Zhen Lei</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯ç†å·¥å¤§å­¦ï¼ˆé¦™æ¸¯ç†å·¥å¤§å­¦ï¼‰</li>
<li>å…³é”®è¯ï¼šè¯­éŸ³é©±åŠ¨é¢éƒ¨åŠ¨ç”»ã€æ‰©æ•£æ¨¡å‹ã€Transformerã€æ¡ä»¶æ³¨æ„æœºåˆ¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.05712
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/theEricMa/DiffSpeaker</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šè¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»åœ¨è®¸å¤šå¤šåª’ä½“åº”ç”¨ä¸­éå¸¸é‡è¦ã€‚æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹æˆ– Transformer æ¶æ„æ¥æ‰§è¡Œæ­¤ä»»åŠ¡å¾ˆæœ‰å‰æ™¯ã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„ç®€å•èšåˆå¹¶ä¸èƒ½å¸¦æ¥æ”¹è¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬æ€€ç–‘è¿™æ˜¯ç”±äºç¼ºä¹é…å¯¹çš„éŸ³é¢‘-4D æ•°æ®ï¼Œè¿™å¯¹äº Transformer åœ¨æ‰©æ•£æ¡†æ¶å†…æœ‰æ•ˆåœ°æ‰§è¡Œå»å™ªå™¨è‡³å…³é‡è¦ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦ä½¿ç”¨åŸºæœ¬çš„æ»‘åŠ¨çª—å£æ–¹æ³•å¤„ç†éŸ³é¢‘è¾“å…¥ï¼Œè¿™é€šå¸¸ä¼šå¯¼è‡´ç”Ÿæˆçš„çš„é¢éƒ¨åŠ¨ä½œèŒƒå›´ç‹­çª„ã€‚è¿‘å¹´æ¥ï¼Œç ”ç©¶äººå‘˜å¼€å§‹é‡‡ç”¨ Transformer æ¶æ„æ¥è¿›è¡Œè¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»ï¼Œä½†ä¼ ç»Ÿçš„ç¡®å®šæ€§å›å½’å¯èƒ½ä¸æ˜¯æœ€å¥½çš„æ–¹æ³•ï¼Œå› ä¸ºäººç±»çš„è¯­éŸ³å’Œé¢éƒ¨è¡¨æƒ…æ˜¯å¯å˜ä¸”åŠ¨æ€çš„ï¼Œå¾ˆéš¾ç”¨ä¸€ä¸ªå›ºå®šçš„æ˜ å°„æ¥å‡†ç¡®æ•æ‰å®ƒä»¬ä¹‹é—´çš„å…³ç³»ã€‚
ï¼ˆ3ï¼‰ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† DiffSpeakerï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäº Transformer çš„ç½‘ç»œï¼Œé…å¤‡äº†æ–°é¢–çš„åç½®æ¡ä»¶æ³¨æ„æœºåˆ¶æ¨¡å—ã€‚è¿™äº›æ¨¡å—å¯ä»¥æ›¿ä»£æ ‡å‡† Transformer ä¸­ä¼ ç»Ÿçš„è‡ªæ³¨æ„åŠ›/äº¤å‰æ³¨æ„åŠ›ï¼Œå¹¶ç»“åˆäº†ç»è¿‡ç²¾å¿ƒè®¾è®¡çš„åç½®ï¼Œè¿™äº›åç½®å¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶é›†ä¸­åœ¨ç›¸å…³çš„ç‰¹å®šä»»åŠ¡å’Œä¸æ‰©æ•£ç›¸å…³çš„æ¡ä»¶ä¸Šã€‚æˆ‘ä»¬è¿˜æ¢ç´¢äº†åœ¨æ‰©æ•£èŒƒå¼ä¸­å‡†ç¡®çš„å”‡å½¢åŒæ­¥å’Œéè¯­è¨€é¢éƒ¨è¡¨æƒ…ä¹‹é—´çš„æƒè¡¡ã€‚
ï¼ˆ4ï¼‰ï¼šå®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¸ä»…åœ¨ç°æœ‰åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè€Œä¸”ç”±äºå…¶èƒ½å¤Ÿå¹¶è¡Œç”Ÿæˆé¢éƒ¨åŠ¨ä½œï¼Œå› æ­¤æ¨ç†é€Ÿåº¦ä¹Ÿå¾ˆå¿«ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’ŒTransformeræ¶æ„çš„è¯­éŸ³é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»æ–¹æ³•DiffSpeakerï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›å’ŒTransformeræ¶æ„çš„åºåˆ—å»ºæ¨¡èƒ½åŠ›ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†è¯­éŸ³é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»ä»»åŠ¡ä¸­çš„é…å¯¹éŸ³é¢‘-4Dæ•°æ®ç¼ºä¹çš„é—®é¢˜ã€‚
(2): DiffSpeakeré‡‡ç”¨äº†ä¸€ç§æ–°é¢–çš„åç½®æ¡ä»¶æ³¨æ„æœºåˆ¶æ¨¡å—ï¼Œè¯¥æ¨¡å—å¯ä»¥æ›¿ä»£æ ‡å‡†Transformerä¸­çš„ä¼ ç»Ÿè‡ªæ³¨æ„åŠ›/äº¤å‰æ³¨æ„åŠ›ï¼Œå¹¶ç»“åˆäº†ç»è¿‡ç²¾å¿ƒè®¾è®¡çš„åç½®ï¼Œè¿™äº›åç½®å¼•å¯¼æ³¨æ„åŠ›æœºåˆ¶é›†ä¸­åœ¨ç›¸å…³çš„ç‰¹å®šä»»åŠ¡å’Œä¸æ‰©æ•£ç›¸å…³çš„æ¡ä»¶ä¸Šã€‚
(3): DiffSpeakerè¿˜æ¢ç´¢äº†åœ¨æ‰©æ•£èŒƒå¼ä¸­å‡†ç¡®çš„å”‡å½¢åŒæ­¥å’Œéè¯­è¨€é¢éƒ¨è¡¨æƒ…ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°å¯ä»¥åŒæ—¶ä¼˜åŒ–å”‡å½¢åŒæ­¥å’Œéè¯­è¨€é¢éƒ¨è¡¨æƒ…çš„è´¨é‡ã€‚
(4): å®éªŒç»“æœè¡¨æ˜ï¼ŒDiffSpeakeråœ¨ç°æœ‰åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¸”ç”±äºå…¶èƒ½å¤Ÿå¹¶è¡Œç”Ÿæˆé¢éƒ¨åŠ¨ä½œï¼Œå› æ­¤æ¨ç†é€Ÿåº¦ä¹Ÿå¾ˆå¿«ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæ¢ç´¢äº†å°† Transformer æ¶æ„ä¸åŸºäºæ‰©æ•£çš„æ¡†æ¶æœ‰æ•ˆç»“åˆç”¨äºè¯­éŸ³é©±åŠ¨ 3D é¢éƒ¨åŠ¨ç”»çš„æ–¹æ³•ã€‚æˆ‘ä»¬è´¡çŒ®çš„æ ¸å¿ƒæ˜¯å¼•å…¥äº†å¸¦æœ‰åç½®çš„æ¡ä»¶è‡ªæ³¨æ„åŠ›/äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥æœºåˆ¶è§£å†³äº†ä½¿ç”¨å—é™ä¸”è·¨åº¦çŸ­çš„éŸ³é¢‘-4D æ•°æ®è®­ç»ƒåŸºäºæ‰©æ•£çš„ Transformer çš„å›°éš¾ã€‚æˆ‘ä»¬è¿˜ç ”ç©¶äº†åœ¨å®ç°å‡†ç¡®çš„å”‡å½¢åŒæ­¥å’Œç”Ÿæˆä¸è¯­éŸ³ç›¸å…³æ€§è¾ƒå°çš„é¢éƒ¨è¡¨æƒ…ä¹‹é—´çš„å¹³è¡¡ã€‚æˆ‘ä»¬å¼€å‘çš„æ¨¡å‹ä¼˜äºå½“å‰çš„æ–¹æ³•ï¼Œåœ¨åŠ¨ç”»è´¨é‡å’Œç”Ÿæˆé€Ÿåº¦æ–¹é¢éƒ½è¡¨ç°å‡ºè‰²ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°çš„å¸¦æœ‰åç½®çš„æ¡ä»¶è‡ªæ³¨æ„åŠ›/äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥æœºåˆ¶å¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å—é™ä¸”è·¨åº¦çŸ­çš„éŸ³é¢‘-4D æ•°æ®æ¥è®­ç»ƒåŸºäºæ‰©æ•£çš„ Transformerã€‚
æå‡ºäº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°å¯ä»¥åŒæ—¶ä¼˜åŒ–å”‡å½¢åŒæ­¥å’Œéè¯­è¨€é¢éƒ¨è¡¨æƒ…çš„è´¨é‡ã€‚
æ€§èƒ½ï¼š
åœ¨ç°æœ‰åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
æ¨ç†é€Ÿåº¦å¿«ï¼Œèƒ½å¤Ÿå¹¶è¡Œç”Ÿæˆé¢éƒ¨åŠ¨ä½œã€‚
å·¥ä½œé‡ï¼š
éœ€è¦æ”¶é›†å’Œé¢„å¤„ç†å¤§é‡çš„éŸ³é¢‘-4D æ•°æ®ã€‚
éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¤§é‡çš„è®­ç»ƒã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a6a1095c49476b6d0a24c660e7abca7e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-2c694a105e50cf1ba9a9e0743f793c62.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1dd59be8351677e84215dd037093b2ca.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ebb8f9ab10ef4d053668941b0c247fcb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff2d1ca9215127e6894689d494fb8244.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/02/23/Paper/2024-02-23/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-23-æ›´æ–°"><a href="#2024-02-23-æ›´æ–°" class="headerlink" title="2024-02-23 æ›´æ–°"></a>2024-02-23 æ›´æ–°</h1><h2 id="Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting"><a href="#Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting" class="headerlink" title="Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting"></a>Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting</h2><p><strong>Authors:Joongho Jo, Hyeongwon Kim, Jongsun Park</strong></p>
<p>3D Gaussian splatting (3D-GS) is a new rendering approach that outperforms the neural radiance field (NeRF) in terms of both speed and image quality. 3D-GS represents 3D scenes by utilizing millions of 3D Gaussians and projects these Gaussians onto the 2D image plane for rendering. However, during the rendering process, a substantial number of unnecessary 3D Gaussians exist for the current view direction, resulting in significant computation costs associated with their identification. In this paper, we propose a computational reduction technique that quickly identifies unnecessary 3D Gaussians in real-time for rendering the current view without compromising image quality. This is accomplished through the offline clustering of 3D Gaussians that are close in distance, followed by the projection of these clusters onto a 2D image plane during runtime. Additionally, we analyze the bottleneck associated with the proposed technique when executed on GPUs and propose an efficient hardware architecture that seamlessly supports the proposed scheme. For the Mip-NeRF360 dataset, the proposed technique excludes 63% of 3D Gaussians on average before the 2D image projection, which reduces the overall rendering computation by almost 38.3% without sacrificing peak-signal-to-noise-ratio (PSNR). The proposed accelerator also achieves a speedup of 10.7x compared to a GPU. </p>
<p><a href="http://arxiv.org/abs/2402.13827v1">PDF</a> </p>
<p><strong>Summary</strong><br>3D é«˜æ–¯æ•£splatting é€šè¿‡èšç±» å’Œ æŠ•å½±ä¼˜åŒ–ï¼Œå‡å°‘äº† 38.3% çš„æ¸²æŸ“è®¡ç®—ï¼Œä¸”ä¸æŸå¤±å›¾åƒè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D é«˜æ–¯æ•£splattingï¼ˆ3D-GSï¼‰æ˜¯ä¸€ç§æ–°çš„æ¸²æŸ“æ–¹æ³•ï¼Œåœ¨é€Ÿåº¦å’Œå›¾åƒè´¨é‡ä¸Šä¼˜äºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ã€‚</li>
<li>3D-GS ä½¿ç”¨æ•°ç™¾ä¸‡ä¸ª 3D é«˜æ–¯è¡¨ç¤º 3D åœºæ™¯ï¼Œå¹¶å°†è¿™äº›é«˜æ–¯æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šè¿›è¡Œæ¸²æŸ“ã€‚</li>
<li>åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œå¤§é‡ä¸å¿…è¦çš„é«˜æ–¯å­˜åœ¨äºå½“å‰è§†å›¾æ–¹å‘ï¼Œå¯¼è‡´ä¸è¯†åˆ«å®ƒä»¬ç›¸å…³çš„è®¡ç®—æˆæœ¬å·¨å¤§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è®¡ç®—ç®€åŒ–æŠ€æœ¯ï¼Œå¯åœ¨è¿è¡Œæ—¶å¿«é€Ÿè¯†åˆ«å‡ºä¸å¿…è¦çš„é«˜æ–¯ï¼Œç”¨äºæ¸²æŸ“å½“å‰è§†å›¾ï¼Œä¸”ä¸æŸå®³å›¾åƒè´¨é‡ã€‚</li>
<li>è¿™ç§ç®€åŒ–æŠ€æœ¯æ–¹æ³•æ˜¯ç¦»çº¿å¯¹è·ç¦»ç›¸è¿‘çš„é«˜æ–¯è¿›è¡Œèšç±»ï¼Œç„¶ååœ¨è¿è¡Œæ—¶å°†è¿™äº›é›†ç¾¤æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šã€‚</li>
<li>å¯¹è¯¥æŠ€æœ¯åœ¨ GPU ä¸Šæ‰§è¡Œæ—¶çš„ç“¶é¢ˆè¿›è¡Œäº†åˆ†æï¼Œå¹¶æå‡ºäº†ä¸€ç§ä¸è¯¥æ–¹æ¡ˆæ— ç¼å…¼å®¹çš„é«˜æ•ˆç¡¬ä»¶æ¶æ„ã€‚</li>
<li>å¯¹äº Mip-NeRF360 æ•°æ®é›†ï¼Œè¯¥æŠ€æœ¯åœ¨ 2D å›¾åƒæŠ•å½±ä¹‹å‰å¹³å‡æ’é™¤äº† 63% çš„é«˜æ–¯ï¼Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº† 38.3%ï¼Œä¸”ä¸æŸå¤±å³°å€¼ä¿¡å™ªæ¯” (PSNR)ã€‚</li>
<li>è¯¥åŠ é€Ÿå™¨ä¸ GPU ç›¸æ¯”ï¼Œè¿˜å®ç°äº† 10.7 å€çš„åŠ é€Ÿã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šä½¿ç”¨èšç±»è¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œä»¥å¿«é€Ÿæ¸²æŸ“ 3D é«˜æ–¯ä½“é£æº…</li>
<li>ä½œè€…ï¼šJoongho Joã€Hyeongwon Kim å’Œ Jongsun Park</li>
<li>éš¶å±æœºæ„ï¼šéŸ©å›½å¤§å­¦ç”µæ°”å·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼š3D é«˜æ–¯ä½“é£æº…ã€æ¸²æŸ“ã€NeRFã€ç¥ç»è¾å°„åœºã€ç¡¬ä»¶åŠ é€Ÿå™¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šPaper_info:Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering of 3D Gaussian Splattingï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåœ¨è®¡ç®—æœºè§†è§‰åº”ç”¨ä¸­ï¼Œä¾‹å¦‚å¢å¼ºç°å® (AR)ã€è™šæ‹Ÿç°å® (VR) å’Œå…ƒå®‡å®™ï¼Œå¿«é€Ÿä¸”é«˜è´¨é‡çš„å›¾åƒæ¸²æŸ“éå¸¸é‡è¦ã€‚è™½ç„¶å·²ç»å¹¿æ³›ç ”ç©¶äº†ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œçš„æ¸²æŸ“æŠ€æœ¯ï¼Œä¾‹å¦‚ç¥ç»è¾å°„åœº (NeRF)ï¼Œä½† 3D é«˜æ–¯ä½“é£æº… (3D-GS) ä½œä¸ºä¸€ç§æ–°çš„æ¸²æŸ“æ–¹æ³•ï¼Œæœ€è¿‘å› å…¶ä¸ä¼ ç»Ÿ NeRF ç›¸æ¯”èƒ½å¤Ÿå¿«é€Ÿæ¸²æŸ“é«˜è´¨é‡å›¾åƒè€Œå¤‡å—å…³æ³¨ã€‚3D-GS åˆ©ç”¨æ•°ç™¾ä¸‡ä¸ª 3D é«˜æ–¯ä½“æ¥è¡¨ç¤ºå¤æ‚çš„ 3D åœºæ™¯ï¼Œå¹¶é€šè¿‡å°† 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šæ¥æ¸²æŸ“ 3D åœºæ™¯ã€‚</p>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š3D-GS æ¸²æŸ“è¿‡ç¨‹ä¸»è¦åˆ†ä¸ºä¸¤æ­¥ï¼šé¦–å…ˆï¼Œå°†æ‰€æœ‰ 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œå¹¶è¯†åˆ«å½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“ã€‚ç„¶åï¼Œä½¿ç”¨å½±å“é¢œè‰²çš„å·²è¯†åˆ« 3D é«˜æ–¯ä½“è®¡ç®— 2D å›¾åƒä¸­æ¯ä¸ªåƒç´ çš„é¢œè‰²ã€‚åœ¨æ¸²æŸ“è¿‡ç¨‹çš„ç¬¬ä¸€æ­¥ä¸­ï¼Œé«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒä¸Šåï¼Œå¦‚æœè¢«è¯†åˆ«ä¸ºä¸å½±å“ 2D å›¾åƒçš„é¢œè‰²ï¼Œé‚£ä¹ˆæŠ•å½±å°±å˜æˆäº†è®¡ç®—æµªè´¹ã€‚åœ¨ Mip-NeRF360 æ•°æ®é›†ä¸­ï¼Œå¹³å‡çº¦æœ‰ 67.6% çš„ 3D é«˜æ–¯ä½“ä¸å½±å“ 2D å›¾åƒçš„é¢œè‰²ã€‚å› æ­¤ï¼Œè¿™äº›é«˜æ–¯ä½“å¯ä»¥ä»å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­æ’é™¤ã€‚ä½†æ˜¯ï¼Œç”±äºå½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“å¯èƒ½ä¼šéšç€æ¸²æŸ“è§†ç‚¹çš„æ–¹å‘å’Œä½ç½®è€Œæ”¹å˜ï¼Œå› æ­¤åœ¨å°† 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šä¹‹å‰è¯†åˆ«ä¸å¿…è¦çš„é«˜æ–¯ä½“ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å› æ­¤ï¼Œè¿™äº›ä¸å¿…è¦çš„é«˜æ–¯ä½“ä»ç„¶ä¼šè¿›è¡ŒæŠ•å½±è®¡ç®—ã€‚å› æ­¤ï¼Œå¦‚æœå¯ä»¥å¼€å‘å‡ºä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•æ¥é¢„æµ‹ä¸ä¼šå½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“ï¼Œå¹¶åœ¨æ¸²æŸ“è¿‡ç¨‹å¼€å§‹ä¹‹å‰å°†å®ƒä»¬æ’é™¤ï¼Œé‚£ä¹ˆå¯ä»¥æ˜¾ç€é™ä½æ•´ä¸ª 3D-GS è¿‡ç¨‹çš„æ€»ä½“è®¡ç®—å¤æ‚åº¦ã€‚</p>
<p>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ¡ˆï¼Œé€šè¿‡è¯†åˆ«ä¸å½±å“ 2D å›¾åƒé¢œè‰²çš„ç°‡æ¥æ’é™¤å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­çš„ä¸å¿…è¦ 3D é«˜æ–¯ä½“ã€‚èšç±»çš„ç›®æ ‡æ˜¯å°†ä½ç½®ç›¸è¿‘çš„ 3D é«˜æ–¯ä½“åˆ†ç»„åœ¨ä¸€èµ·ï¼Œå¹¶ä¸”ç°‡çš„å½¢çŠ¶åº”è¯¥æ˜¯çƒå½¢çš„ï¼Œä»¥ä¾¿äºæŠ•å½±åˆ° 2D å›¾åƒä¸Šã€‚å› æ­¤ï¼Œæœ¬æ–‡é‡‡ç”¨ K-means èšç±»ç®—æ³•ï¼Œè¯¥ç®—æ³•æ»¡è¶³è¿™ä¸¤ä¸ªæ ‡å‡†ã€‚è€ƒè™‘åˆ° 3D é«˜æ–¯ä½“å…·æœ‰ç”±å…¶åæ–¹å·®å®šä¹‰çš„å¤§å°æˆ–å½±å“ï¼Œç°‡çƒä½“çš„åŠå¾„ä¸ä»…ç”±åˆ°ç°‡è´¨å¿ƒçš„è·ç¦»ç¡®å®šï¼Œè¿˜è¦è€ƒè™‘é«˜æ–¯ä½“çš„å¤§å°ã€‚ç„¶åå°†è¿™äº›å®šä¹‰çš„ç°‡çƒä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œä»¥ç¡®å®šå®ƒä»¬å¯¹ 2D å›¾åƒé¢œè‰²çš„å½±å“ã€‚ä¸å½±å“å›¾åƒé¢œè‰²çš„ç°‡å¯ä»¥ä»æ¸²æŸ“è¿‡ç¨‹ä¸­æ’é™¤ã€‚åœ¨æœ¬æ–‡çš„æ–¹æ³•ä¸­ï¼Œå¯ä»¥åœ¨ç¦»çº¿æ‰§è¡Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„ï¼Œå¹¶ä¸”ä»…åœ¨å®æ—¶æ‰§è¡Œå°†ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œè¿™ä»…éœ€ 6.2% çš„è®¡ç®—å¼€é”€ã€‚åœ¨ 3D-GS æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œåœ¨å½“å‰è§†å›¾æ¸²æŸ“ä¹‹å‰åº”ç”¨æ‰€æå‡ºçš„æ–¹æ³•æ—¶ï¼Œå¹³å‡å¯ä»¥æ’é™¤ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œåœ¨ä¸ç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR) çš„æƒ…å†µä¸‹å°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ã€‚æ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†ä¸ GPU ç›¸æ¯” 10.7 å€çš„åŠ é€Ÿã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨ Mip-NeRF360 æ•°æ®é›†ä¸Šï¼Œæ‰€æå‡ºçš„æ–¹æ³•å¹³å‡æ’é™¤äº† 63% çš„ 3D é«˜æ–¯ä½“ï¼Œåœ¨ä¸ç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR) çš„æƒ…å†µä¸‹å°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ã€‚æ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†ä¸ GPU ç›¸æ¯” 10.7 å€çš„åŠ é€Ÿã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å¿«é€Ÿä¸”é«˜è´¨é‡åœ°æ¸²æŸ“ 3D åœºæ™¯ã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ¡ˆï¼Œé€šè¿‡è¯†åˆ«ä¸å½±å“ 2D å›¾åƒé¢œè‰²çš„ç°‡æ¥æ’é™¤å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­çš„ä¸å¿…è¦ 3D é«˜æ–¯ä½“ã€‚è¯¥æ–¹æ³•å¹³å‡å¯ä»¥æ’é™¤ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œåœ¨ä¸ç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR) çš„æƒ…å†µä¸‹å°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ã€‚æ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†ä¸ GPU ç›¸æ¯” 10.7 å€çš„åŠ é€Ÿã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ¡ˆæ¥è¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥ç¦»çº¿æ‰§è¡Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„ï¼Œå¹¶ä¸”ä»…åœ¨å®æ—¶æ‰§è¡Œå°†ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œè¿™ä»…éœ€ 6.2% çš„è®¡ç®—å¼€é”€ã€‚</li>
<li>æ‰€æå‡ºçš„åŠ é€Ÿå™¨å®ç°äº†ä¸ GPU ç›¸æ¯” 10.7 å€çš„åŠ é€Ÿã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ Mip-NeRF360 æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å¹³å‡æ’é™¤äº† 63% çš„ 3D é«˜æ–¯ä½“ï¼Œåœ¨ä¸ç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR) çš„æƒ…å†µä¸‹å°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•å¯ä»¥åœ¨ç¦»çº¿æ‰§è¡Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„ï¼Œå¹¶ä¸”ä»…åœ¨å®æ—¶æ‰§è¡Œå°†ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œè¿™ä»…éœ€ 6.2% çš„è®¡ç®—å¼€é”€ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-eb8532b7f44bd3308c4f19fe6bf7f78c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e5e9d849dcc9fd5228abd36df009311.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a43367bbb6924d5ba043f598753b956.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d13d1af17267a2b843bea8ac607b39a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bca1cf3d857e2d53600b33fc6c9e298c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee494dce0084e0f0c71d55d940b03dc9.jpg" align="middle">
</details>




<h2 id="GaussianObject-Just-Taking-Four-Images-to-Get-A-High-Quality-3D-Object-with-Gaussian-Splatting"><a href="#GaussianObject-Just-Taking-Four-Images-to-Get-A-High-Quality-3D-Object-with-Gaussian-Splatting" class="headerlink" title="GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object   with Gaussian Splatting"></a>GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object   with Gaussian Splatting</h2><p><strong>Authors:Chen Yang, Sikuang Li, Jiemin Fang, Ruofan Liang, Lingxi Xie, Xiaopeng Zhang, Wei Shen, Qi Tian</strong></p>
<p>Reconstructing and rendering 3D objects from highly sparse views is of critical importance for promoting applications of 3D vision techniques and improving user experience. However, images from sparse views only contain very limited 3D information, leading to two significant challenges: 1) Difficulty in building multi-view consistency as images for matching are too few; 2) Partially omitted or highly compressed object information as view coverage is insufficient. To tackle these challenges, we propose GaussianObject, a framework to represent and render the 3D object with Gaussian splatting, that achieves high rendering quality with only 4 input images. We first introduce techniques of visual hull and floater elimination which explicitly inject structure priors into the initial optimization process for helping build multi-view consistency, yielding a coarse 3D Gaussian representation. Then we construct a Gaussian repair model based on diffusion models to supplement the omitted object information, where Gaussians are further refined. We design a self-generating strategy to obtain image pairs for training the repair model. Our GaussianObject is evaluated on several challenging datasets, including MipNeRF360, OmniObject3D, and OpenIllumination, achieving strong reconstruction results from only 4 views and significantly outperforming previous state-of-the-art methods. </p>
<p><a href="http://arxiv.org/abs/2402.10259v2">PDF</a> Project page: <a href="https://gaussianobject.github.io/">https://gaussianobject.github.io/</a></p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨ä»…æœ‰ 4 å¼ è¾“å…¥å›¾åƒï¼Œä»¥é«˜æ–¯æ•£ç‚¹å›¾è¡¨ç¤ºå’Œæ¸²æŸ“ä¸‰ç»´å¯¹è±¡ï¼Œå±•ç°å‡ºæä½³çš„æ¸²æŸ“è´¨é‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>é‡å»ºå’Œæ¸²æŸ“é«˜åº¦ç¨€ç–è§†å›¾çš„ 3D å¯¹è±¡å¯¹äºä¿ƒè¿› 3D è§†è§‰æŠ€æœ¯åº”ç”¨å’Œæ”¹å–„ç”¨æˆ·ä½“éªŒè‡³å…³é‡è¦ã€‚</li>
<li>æå‡º GaussianObjectï¼Œä¸€ç§ä»¥é«˜æ–¯æ•£ç‚¹å›¾è¡¨ç¤ºå’Œæ¸²æŸ“ 3D å¯¹è±¡çš„æ¡†æ¶ï¼Œä»…éœ€ 4 å¼ è¾“å…¥å›¾åƒå³å¯å®ç°é«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li>å¼•å…¥è§†è§‰å¤–å£³å’Œæµ®å­æ¶ˆé™¤æŠ€æœ¯ï¼Œå°†ç»“æ„å…ˆéªŒæ˜ç¡®æ³¨å…¥åˆå§‹ä¼˜åŒ–è¿‡ç¨‹ï¼Œå¸®åŠ©å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ï¼Œäº§ç”Ÿç²—ç³™çš„ 3D é«˜æ–¯è¡¨ç¤ºã€‚</li>
<li>åŸºäºæ‰©æ•£æ¨¡å‹æ„å»ºé«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥è¡¥å……çœç•¥çš„å¯¹è±¡ä¿¡æ¯ï¼Œå…¶ä¸­é«˜æ–¯å€¼è¿›ä¸€æ­¥ç»†åŒ–ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§è‡ªç”Ÿæˆç­–ç•¥æ¥è·å–å›¾åƒå¯¹ï¼Œä»¥è®­ç»ƒä¿®å¤æ¨¡å‹ã€‚</li>
<li>åœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šè¯„ä¼°äº† GaussianObjectï¼ŒåŒ…æ‹¬ MipNeRF360ã€OmniObject3D å’Œ OpenIlluminationï¼Œä»…ä½¿ç”¨ 4 ä¸ªè§†å›¾å³å¯å®ç°å¼ºå¤§çš„é‡å»ºç»“æœï¼Œå¹¶ä¸”æ˜æ˜¾ä¼˜äºå…ˆå‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šé«˜æ–¯å¯¹è±¡ï¼šåªéœ€å››å¼ å›¾åƒå³å¯è·å–é«˜è´¨é‡çš„ 3D å¯¹è±¡</li>
<li>ä½œè€…ï¼šé™ˆé˜³ï¼Œææ€å®½ï¼Œæ–¹æ°æ°‘ï¼Œæ¢è‹¥å‡¡ï¼Œè°¢å‡Œå¸Œï¼Œå¼ æ™“é¹ï¼Œæ²ˆå·ï¼Œç”°é½</li>
<li>å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€3D é‡å»ºã€ç¨€ç–è§†å›¾ã€é«˜æ–¯çƒé¢ä½“</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.10259ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šé‡å»ºå’Œæ¸²æŸ“ 3D å¯¹è±¡æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„é‡è¦è¯¾é¢˜ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡è§†å›¾æ‰èƒ½è·å¾—é«˜è´¨é‡çš„ç»“æœã€‚è¿™å¯¹äºç”¨æˆ·æ¥è¯´éå¸¸ç¹çï¼Œé™åˆ¶äº† 3D æŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šä¸€äº›ç ”ç©¶å°è¯•å‡å°‘å¯¹å¯†é›†æ•è·çš„ä¾èµ–ï¼Œä½†å½“è§†å›¾å˜å¾—æåº¦ç¨€ç–æ—¶ï¼Œä»ç„¶éš¾ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ 3D å¯¹è±¡ã€‚ä¸»è¦æŒ‘æˆ˜åœ¨äºéš¾ä»¥å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ï¼Œä»¥åŠéƒ¨åˆ†ç¼ºå¤±æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºé«˜æ–¯å¯¹è±¡çš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨ä»ç¨€ç–è§†å›¾ä¸­é‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ã€‚è¯¥æ¡†æ¶ä½¿ç”¨ 3D é«˜æ–¯çƒé¢ä½“ä½œä¸ºåŸºæœ¬è¡¨ç¤ºï¼Œå¹¶è®¾è®¡äº†å‡ ç§æŠ€æœ¯æ¥å¼•å…¥å¯¹è±¡ç»“æ„å…ˆéªŒï¼Œå¸®åŠ©å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„é«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥æ¶ˆé™¤ç”±ç¼ºå¤±æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯å¼•èµ·çš„ä¼ªå½±ã€‚
ï¼ˆ4ï¼‰æ€§èƒ½è¡¨ç°ï¼šé«˜æ–¯å¯¹è±¡æ–¹æ³•åœ¨å‡ ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œåœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­å‡ä¼˜äºä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ä»ç¨€ç–è§†å›¾ä¸­é‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) é«˜æ–¯çƒé¢ä½“è¡¨ç¤ºï¼šå°†3Då¯¹è±¡è¡¨ç¤ºä¸ºä¸€ä¸ª3Dé«˜æ–¯çƒé¢ä½“ï¼Œè¯¥çƒé¢ä½“ç”±ä¸€ç³»åˆ—3Dé«˜æ–¯åˆ†å¸ƒç»„æˆã€‚æ¯ä¸ªé«˜æ–¯åˆ†å¸ƒå¯¹åº”äºå¯¹è±¡çš„ä¸€ä¸ªå±€éƒ¨åŒºåŸŸï¼Œå…¶å‚æ•°ï¼ˆä¸­å¿ƒä½ç½®ã€å°ºåº¦å’Œæƒé‡ï¼‰ç”±ç¥ç»ç½‘ç»œå­¦ä¹ å¾—åˆ°ã€‚
(2) ç»“æ„å…ˆéªŒå¼•å…¥ï¼šè®¾è®¡äº†å‡ ç§æŠ€æœ¯æ¥å¼•å…¥å¯¹è±¡ç»“æ„å…ˆéªŒï¼Œå¸®åŠ©å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ã€‚è¿™äº›æŠ€æœ¯åŒ…æ‹¬ï¼š</p>
<ul>
<li>å½¢çŠ¶æ­£åˆ™åŒ–ï¼šä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„å½¢çŠ¶ç”Ÿæˆæ¨¡å‹æ¥æ­£åˆ™åŒ–é«˜æ–¯çƒé¢ä½“çš„å½¢çŠ¶ï¼Œä½¿å…¶æ›´åŠ çœŸå®å’Œè‡ªç„¶ã€‚</li>
<li>æ‹“æ‰‘æ­£åˆ™åŒ–ï¼šä½¿ç”¨ä¸€ä¸ªæ‹“æ‰‘ç”Ÿæˆæ¨¡å‹æ¥æ­£åˆ™åŒ–é«˜æ–¯çƒé¢ä½“çš„æ‹“æ‰‘ç»“æ„ï¼Œä½¿å…¶æ›´åŠ è¿é€šå’Œå®Œæ•´ã€‚</li>
<li>è¯­ä¹‰æ­£åˆ™åŒ–ï¼šä½¿ç”¨ä¸€ä¸ªè¯­ä¹‰åˆ†å‰²æ¨¡å‹æ¥æ­£åˆ™åŒ–é«˜æ–¯çƒé¢ä½“çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä½¿å…¶æ›´åŠ å‡†ç¡®å’Œä¸€è‡´ã€‚
(3) é«˜æ–¯ä¿®å¤æ¨¡å‹ï¼šæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„é«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥æ¶ˆé™¤ç”±ç¼ºå¤±æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯å¼•èµ·çš„ä¼ªå½±ã€‚è¯¥æ¨¡å‹é€šè¿‡è¿­ä»£åœ°æ‰©æ•£å’Œæ¢å¤é«˜æ–¯çƒé¢ä½“çš„å‚æ•°ï¼Œé€æ­¥æ¶ˆé™¤ä¼ªå½±å¹¶ç”Ÿæˆé«˜è´¨é‡çš„3Då¯¹è±¡ã€‚</li>
</ul>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šé«˜æ–¯å¯¹è±¡æ˜¯ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œæ—¨åœ¨ä»æåº¦ç¨€ç–çš„ 360Â° è§†å›¾ä¸­é‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ï¼Œè¯¥æ¡†æ¶åŸºäº 3D é«˜æ–¯çƒé¢ä½“ï¼Œå¹¶å…·æœ‰å®æ—¶çš„æ¸²æŸ“èƒ½åŠ›ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸¤ç§ä¸»è¦æ–¹æ³•æ¥å®ç°è¿™ä¸€ç›®æ ‡ï¼šè¾…åŠ©ç»“æ„å…ˆéªŒçš„ä¼˜åŒ–ï¼Œä»¥ä¿ƒè¿›å¤šè§†å›¾ä¸€è‡´æ€§çš„æ„å»ºï¼Œä»¥åŠé«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥å»é™¤ç”±é—æ¼æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯å¼•èµ·çš„ä¼ªå½±ã€‚æˆ‘ä»¬å¸Œæœ›é«˜æ–¯å¯¹è±¡èƒ½å¤Ÿæ¨è¿›é‡å»º 3D å¯¹è±¡çš„æ—¥å¸¸åº”ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ 3D å¯¹è±¡è¡¨ç¤ºå½¢å¼â€”â€”é«˜æ–¯çƒé¢ä½“ï¼Œè¯¥è¡¨ç¤ºå½¢å¼èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•è·å¯¹è±¡çš„å½¢çŠ¶ã€æ‹“æ‰‘ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>è®¾è®¡äº†å‡ ç§æŠ€æœ¯æ¥å¼•å…¥å¯¹è±¡ç»“æ„å…ˆéªŒï¼Œå¸®åŠ©å»ºç«‹å¤šè§†å›¾ä¸€è‡´æ€§ï¼ŒåŒ…æ‹¬å½¢çŠ¶æ­£åˆ™åŒ–ã€æ‹“æ‰‘æ­£åˆ™åŒ–å’Œè¯­ä¹‰æ­£åˆ™åŒ–ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„é«˜æ–¯ä¿®å¤æ¨¡å‹ï¼Œä»¥æ¶ˆé™¤ç”±ç¼ºå¤±æˆ–é«˜åº¦å‹ç¼©çš„å¯¹è±¡ä¿¡æ¯å¼•èµ·çš„ä¼ªå½±ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å‡ ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼Œé«˜æ–¯å¯¹è±¡æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡è¯„ä¼°ä¸­å‡ä¼˜äºä»¥å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</li>
<li>é«˜æ–¯å¯¹è±¡æ–¹æ³•èƒ½å¤Ÿä»æåº¦ç¨€ç–çš„ 360Â° è§†å›¾ä¸­é‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ï¼Œè¿™å¯¹äºç”¨æˆ·æ¥è¯´éå¸¸æ–¹ä¾¿ï¼Œå¹¶ä¸”å¯ä»¥å¹¿æ³›åº”ç”¨äºå„ç§é¢†åŸŸã€‚
å·¥ä½œé‡ï¼š</li>
<li>é«˜æ–¯å¯¹è±¡æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®­ç»ƒæ—¶é—´å’Œæˆæœ¬ã€‚</li>
<li>é«˜æ–¯å¯¹è±¡æ–¹æ³•éœ€è¦ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥å­¦ä¹ é«˜æ–¯çƒé¢ä½“çš„å‚æ•°ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®¡ç®—å¤æ‚åº¦ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ec0859f0d4156531b928896ce0f20711.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a6cf586e290dad38d6317bf5e32650f6.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fc6b9cc2318a136451091ab1f1c68efb.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0ee843ee1e2c5a9e509cc05d4936f7f7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-de6acbb2bc7ce290268eb48c8af2cb6b.jpg" align="middle">
</details>




<h2 id="GES-Generalized-Exponential-Splatting-for-Efficient-Radiance-Field-Rendering"><a href="#GES-Generalized-Exponential-Splatting-for-Efficient-Radiance-Field-Rendering" class="headerlink" title="GES: Generalized Exponential Splatting for Efficient Radiance Field   Rendering"></a>GES: Generalized Exponential Splatting for Efficient Radiance Field   Rendering</h2><p><strong>Authors:Abdullah Hamdi, Luke Melas-Kyriazi, Guocheng Qian, Jinjie Mai, Ruoshi Liu, Carl Vondrick, Bernard Ghanem, Andrea Vedaldi</strong></p>
<p>Advancements in 3D Gaussian Splatting have significantly accelerated 3D reconstruction and generation. However, it may require a large number of Gaussians, which creates a substantial memory footprint. This paper introduces GES (Generalized Exponential Splatting), a novel representation that employs Generalized Exponential Function (GEF) to model 3D scenes, requiring far fewer particles to represent a scene and thus significantly outperforming Gaussian Splatting methods in efficiency with a plug-and-play replacement ability for Gaussian-based utilities. GES is validated theoretically and empirically in both principled 1D setup and realistic 3D scenes.   It is shown to represent signals with sharp edges more accurately, which are typically challenging for Gaussians due to their inherent low-pass characteristics. Our empirical analysis demonstrates that GEF outperforms Gaussians in fitting natural-occurring signals (e.g. squares, triangles, and parabolic signals), thereby reducing the need for extensive splitting operations that increase the memory footprint of Gaussian Splatting. With the aid of a frequency-modulated loss, GES achieves competitive performance in novel-view synthesis benchmarks while requiring less than half the memory storage of Gaussian Splatting and increasing the rendering speed by up to 39%. The code is available on the project website <a href="https://abdullahamdi.com/ges">https://abdullahamdi.com/ges</a> . </p>
<p><a href="http://arxiv.org/abs/2402.10128v1">PDF</a> preprint</p>
<p><strong>æ‘˜è¦</strong><br>å¹¿ä¹‰æŒ‡æ•°æ•£åˆ—æ³•ï¼ˆGESï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„ 3D åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•° (GEF) å¯¹ 3D åœºæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œæ˜¾è‘—å‡å°‘äº†è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œæ¯”é«˜æ–¯æ•£åˆ—æ–¹æ³•æ›´åŠ é«˜æ•ˆï¼Œå¹¶ä¸”å³æ’å³ç”¨ï¼Œå¯ä»¥æ›¿ä»£åŸºäºé«˜æ–¯çš„å·¥å…·ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>GES ä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•° (GEF) å¯¹ 3D åœºæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œæ˜¾è‘—å‡å°‘äº†æ‰€éœ€ç²’å­æ•°é‡ï¼Œæé«˜äº†æ•ˆç‡ã€‚</li>
<li>GES ä¼˜äºé«˜æ–¯æ•£åˆ—æ³•ï¼Œèƒ½å¤Ÿå°† 3D åœºæ™¯å»ºæ¨¡ä¸ºæ›´å°‘çš„ç²’å­ï¼Œåœ¨æ•ˆç‡æ–¹é¢æ˜¾è‘—ä¼˜äºé«˜æ–¯æ•£åˆ—æ³•ã€‚</li>
<li>GES åœ¨åŸç†æ€§çš„ä¸€ç»´è®¾ç½®å’Œç°å®çš„ 3D åœºæ™¯ä¸­ç»è¿‡ç†è®ºå’Œç»éªŒéªŒè¯ã€‚</li>
<li>GES åœ¨è¡¨è¾¾å…·æœ‰æ¸…æ™°è¾¹ç¼˜çš„ä¿¡å·æ–¹é¢æ›´å‡†ç¡®ï¼Œè€Œè¿™äº›ä¿¡å·é€šå¸¸å¯¹é«˜æ–¯å‡½æ•°æ„æˆæŒ‘æˆ˜ï¼Œå› å…¶æœ¬èº«å…·æœ‰ä½é€šç‰¹æ€§ã€‚</li>
<li>GES åœ¨æ‹Ÿåˆè‡ªç„¶å‘ç”Ÿçš„ä¿¡å·ï¼ˆä¾‹å¦‚æ­£æ–¹å½¢ã€ä¸‰è§’å½¢å’ŒæŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œå› è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£åˆ—æ³•çš„å†…å­˜å ç”¨çš„å¤§é‡åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚</li>
<li>ä½¿ç”¨è°ƒåˆ¶é¢‘ç‡æŸå¤±ï¼ŒGES å¯å®ç°åœ¨æ–°è§†å›¾åˆæˆåŸºå‡†ä¸­å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å­˜å‚¨ç©ºé—´ä¸åˆ°é«˜æ–¯æ•£åˆ—æ³•çš„äºŒåˆ†ä¹‹ä¸€ï¼Œå¹¶ä½¿æ¸²æŸ“é€Ÿåº¦æé«˜å¤šè¾¾ 39%ã€‚</li>
<li>GES çš„ä»£ç å¯åœ¨é¡¹ç›®ç½‘ç«™ <a href="https://abdullahamdi.com/ges">https://abdullahamdi.com/ges</a> ä¸Šè·å–ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šGESï¼šç”¨äºé«˜æ•ˆå…‰åœºæ¸²æŸ“çš„å¹¿ä¹‰æŒ‡æ•°æ•£å°„ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰</li>
<li>ä½œè€…ï¼šAbdullah Hamdiã€Luke Melas-Kyriaziã€Guocheng Qianã€Jinjie Maiã€Ruoshi Liuã€Carl Vondrickã€Bernard Ghanemã€Andrea Vedaldi</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šç‰›æ´¥å¤§å­¦è§†è§‰å‡ ä½•ç»„ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰</li>
<li>å…³é”®è¯ï¼š3D é‡å»ºã€3D ç”Ÿæˆã€3D è¡¨ç¤ºã€å…‰åœºæ¸²æŸ“ã€å¹¿ä¹‰æŒ‡æ•°å‡½æ•°</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.10128ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D é«˜æ–¯æ•£å°„åœ¨ 3D é‡å»ºå’Œç”Ÿæˆæ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œå®ƒå¯èƒ½éœ€è¦å¤§é‡é«˜æ–¯å‡½æ•°ï¼Œè¿™ä¼šé€ æˆå·¨å¤§çš„å†…å­˜å ç”¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šé«˜æ–¯æ•£å°„æ–¹æ³•å‡è®¾åœºæ™¯ä¿¡å·æ˜¯ä½é€šçš„ï¼Œä½†å¤§å¤šæ•° 3D åœºæ™¯éƒ½åŒ…å«å½¢çŠ¶å’Œå¤–è§‚ä¸Šçš„çªå˜ï¼Œå› æ­¤é«˜æ–¯æ•£å°„éœ€è¦ä½¿ç”¨å¤§é‡éå¸¸å°çš„é«˜æ–¯å‡½æ•°æ¥è¡¨ç¤ºè¿™äº› 3D åœºæ™¯ï¼Œè¿™ä¼šå¯¹å†…å­˜åˆ©ç”¨ç‡äº§ç”Ÿè´Ÿé¢å½±å“ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º GESï¼ˆå¹¿ä¹‰æŒ‡æ•°æ•£å°„ï¼‰ï¼Œå®ƒä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•°ï¼ˆå…·æœ‰é¢å¤–çš„å¯å­¦ä¹ å½¢çŠ¶å‚æ•°ï¼‰æ¥å»ºæ¨¡ 3D åœºæ™¯ï¼Œä»è€Œå¯ä»¥å‡å°‘è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œä»è€Œåœ¨æ•ˆç‡ä¸Šæ˜æ˜¾ä¼˜äºé«˜æ–¯æ•£å°„æ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥å³æ’å³ç”¨åœ°æ›¿æ¢åŸºäºé«˜æ–¯çš„å®ç”¨å·¥å…·ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¿™äº›æ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼šGES åœ¨åŸç†æ€§ 1D è®¾ç½®å’Œé€¼çœŸçš„ 3D åœºæ™¯ä¸­éƒ½å¾—åˆ°äº†ç†è®ºå’Œç»éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œå®ƒå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºå…·æœ‰é”åˆ©è¾¹ç¼˜çš„ä¿¡å·ï¼Œè€Œè¿™å¯¹äºé«˜æ–¯å‡½æ•°æ¥è¯´é€šå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å›ºæœ‰çš„ä½é€šç‰¹æ€§ã€‚å®è¯åˆ†æè¡¨æ˜ï¼ŒGES åœ¨æ‹Ÿåˆè‡ªç„¶å‡ºç°çš„ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œæ­£æ–¹å½¢ã€ä¸‰è§’å½¢ã€æŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œä»è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£å°„å†…å­˜å ç”¨ç‡çš„å¹¿æ³›åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚åœ¨é¢‘ç‡è°ƒåˆ¶æŸå¤±çš„å¸®åŠ©ä¸‹ï¼ŒGES åœ¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å†…å­˜å­˜å‚¨é‡ä¸åˆ°é«˜æ–¯æ•£å°„çš„ä¸€åŠï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æé«˜äº† 39%ã€‚</li>
</ol>
<p><methods>:
(1): GESä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•°ï¼ˆå…·æœ‰é¢å¤–çš„å¯å­¦ä¹ å½¢çŠ¶å‚æ•°ï¼‰æ¥å»ºæ¨¡3Dåœºæ™¯ï¼Œä»è€Œå¯ä»¥å‡å°‘è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œä»è€Œåœ¨æ•ˆç‡ä¸Šæ˜æ˜¾ä¼˜äºé«˜æ–¯æ•£å°„æ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥å³æ’å³ç”¨åœ°æ›¿æ¢åŸºäºé«˜æ–¯çš„å®ç”¨å·¥å…·ã€‚
(2): GESåœ¨åŸç†æ€§1Dè®¾ç½®å’Œé€¼çœŸçš„3Dåœºæ™¯ä¸­éƒ½å¾—åˆ°äº†ç†è®ºå’Œç»éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œå®ƒå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºå…·æœ‰é”åˆ©è¾¹ç¼˜çš„ä¿¡å·ï¼Œè€Œè¿™å¯¹äºé«˜æ–¯å‡½æ•°æ¥è¯´é€šå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å›ºæœ‰çš„ä½é€šç‰¹æ€§ã€‚
(3): å®è¯åˆ†æè¡¨æ˜ï¼ŒGESåœ¨æ‹Ÿåˆè‡ªç„¶å‡ºç°çš„ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œæ­£æ–¹å½¢ã€ä¸‰è§’å½¢ã€æŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œä»è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£å°„å†…å­˜å ç”¨ç‡çš„å¹¿æ³›åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚
(4): åœ¨é¢‘ç‡è°ƒåˆ¶æŸå¤±çš„å¸®åŠ©ä¸‹ï¼ŒGESåœ¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å†…å­˜å­˜å‚¨é‡ä¸åˆ°é«˜æ–¯æ•£å°„çš„ä¸€åŠï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æé«˜äº†39%ã€‚</methods></p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å…‰åœºæ¸²æŸ“æ–¹æ³• GESï¼Œå®ƒä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•°æ¥å»ºæ¨¡ 3D åœºæ™¯ï¼Œä»è€Œå¯ä»¥å‡å°‘è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œä»è€Œåœ¨æ•ˆç‡ä¸Šæ˜æ˜¾ä¼˜äºé«˜æ–¯æ•£å°„æ–¹æ³•ï¼Œå¹¶ä¸”å¯ä»¥å³æ’å³ç”¨åœ°æ›¿æ¢åŸºäºé«˜æ–¯çš„å®ç”¨å·¥å…·ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</li>
<li>GES ä½¿ç”¨å¹¿ä¹‰æŒ‡æ•°å‡½æ•°æ¥å»ºæ¨¡ 3D åœºæ™¯ï¼Œä»è€Œå¯ä»¥å‡å°‘è¡¨ç¤ºåœºæ™¯æ‰€éœ€çš„ç²’å­æ•°é‡ï¼Œä»è€Œåœ¨æ•ˆç‡ä¸Šæ˜æ˜¾ä¼˜äºé«˜æ–¯æ•£å°„æ–¹æ³•ã€‚</li>
<li>GES åœ¨åŸç†æ€§ 1D è®¾ç½®å’Œé€¼çœŸçš„ 3D åœºæ™¯ä¸­éƒ½å¾—åˆ°äº†ç†è®ºå’Œç»éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œå®ƒå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºå…·æœ‰é”åˆ©è¾¹ç¼˜çš„ä¿¡å·ï¼Œè€Œè¿™å¯¹äºé«˜æ–¯å‡½æ•°æ¥è¯´é€šå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å›ºæœ‰çš„ä½é€šç‰¹æ€§ã€‚</li>
<li>å®è¯åˆ†æè¡¨æ˜ï¼ŒGES åœ¨æ‹Ÿåˆè‡ªç„¶å‡ºç°çš„ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œæ­£æ–¹å½¢ã€ä¸‰è§’å½¢ã€æŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œä»è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£å°„å†…å­˜å ç”¨ç‡çš„å¹¿æ³›åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚</li>
<li>åœ¨é¢‘ç‡è°ƒåˆ¶æŸå¤±çš„å¸®åŠ©ä¸‹ï¼ŒGES åœ¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å†…å­˜å­˜å‚¨é‡ä¸åˆ°é«˜æ–¯æ•£å°„çš„ä¸€åŠï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æé«˜äº† 39%ã€‚
æ€§èƒ½ï¼š</li>
<li>GES åœ¨åŸç†æ€§ 1D è®¾ç½®å’Œé€¼çœŸçš„ 3D åœºæ™¯ä¸­éƒ½å¾—åˆ°äº†ç†è®ºå’Œç»éªŒéªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œå®ƒå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºå…·æœ‰é”åˆ©è¾¹ç¼˜çš„ä¿¡å·ï¼Œè€Œè¿™å¯¹äºé«˜æ–¯å‡½æ•°æ¥è¯´é€šå¸¸å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰å›ºæœ‰çš„ä½é€šç‰¹æ€§ã€‚</li>
<li>å®è¯åˆ†æè¡¨æ˜ï¼ŒGES åœ¨æ‹Ÿåˆè‡ªç„¶å‡ºç°çš„ä¿¡å·ï¼ˆä¾‹å¦‚ï¼Œæ­£æ–¹å½¢ã€ä¸‰è§’å½¢ã€æŠ›ç‰©çº¿ä¿¡å·ï¼‰æ–¹é¢ä¼˜äºé«˜æ–¯å‡½æ•°ï¼Œä»è€Œå‡å°‘äº†å¢åŠ é«˜æ–¯æ•£å°„å†…å­˜å ç”¨ç‡çš„å¹¿æ³›åˆ†è£‚æ“ä½œçš„éœ€è¦ã€‚</li>
<li>åœ¨é¢‘ç‡è°ƒåˆ¶æŸå¤±çš„å¸®åŠ©ä¸‹ï¼ŒGES åœ¨æ–°è§†å›¾åˆæˆåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æ‰€éœ€çš„å†…å­˜å­˜å‚¨é‡ä¸åˆ°é«˜æ–¯æ•£å°„çš„ä¸€åŠï¼Œå¹¶ä¸”æ¸²æŸ“é€Ÿåº¦æé«˜äº† 39%ã€‚
å·¥ä½œé‡ï¼š</li>
<li>GES çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå®¹æ˜“åœ°é›†æˆåˆ°ç°æœ‰çš„å…‰åœºæ¸²æŸ“å·¥å…·ä¸­ã€‚</li>
<li>GES çš„è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹è¾ƒå¿«ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å‡ åˆ†é’Ÿå†…å®Œæˆã€‚</li>
<li>GES çš„æ¸²æŸ“é€Ÿåº¦å¾ˆå¿«ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-06e50cf8fcf2b71cc6d5f5fa60bd416c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e0387aa41ca3382d21ca4822a1185a81.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d98ce6f15593a9709f1a7d0a0c108a7f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4903d39957be51dd29a4222bcccefaa4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c50bfcbaec1420bcb70374001db6c443.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e090b0178d5a97f88600cc386571b770.jpg" align="middle">
</details>




<h2 id="GS-CLIP-Gaussian-Splatting-for-Contrastive-Language-Image-3D-Pretraining-from-Real-World-Data"><a href="#GS-CLIP-Gaussian-Splatting-for-Contrastive-Language-Image-3D-Pretraining-from-Real-World-Data" class="headerlink" title="GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D   Pretraining from Real-World Data"></a>GS-CLIP: Gaussian Splatting for Contrastive Language-Image-3D   Pretraining from Real-World Data</h2><p><strong>Authors:Haoyuan Li, Yanpeng Zhou, Yihan Zeng, Hang Xu, Xiaodan Liang</strong></p>
<p>3D Shape represented as point cloud has achieve advancements in multimodal pre-training to align image and language descriptions, which is curial to object identification, classification, and retrieval. However, the discrete representations of point cloud lost the objectâ€™s surface shape information and creates a gap between rendering results and 2D correspondences. To address this problem, we propose GS-CLIP for the first attempt to introduce 3DGS (3D Gaussian Splatting) into multimodal pre-training to enhance 3D representation. GS-CLIP leverages a pre-trained vision-language model for a learned common visual and textual space on massive real world image-text pairs and then learns a 3D Encoder for aligning 3DGS optimized per object. Additionally, a novel Gaussian-Aware Fusion is proposed to extract and fuse global explicit feature. As a general framework for language-image-3D pre-training, GS-CLIP is agnostic to 3D backbone networks. Experiments on challenging shows that GS-CLIP significantly improves the state-of-the-art, outperforming the previously best results. </p>
<p><a href="http://arxiv.org/abs/2402.06198v2">PDF</a> The content of the technical report needs to be updated and retracted   to avoid other impacts</p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨3DGS(ä¸‰ç»´é«˜æ–¯æ¸²æŸ“)å¢å¼º3Dè¡¨ç°ï¼Œä»¥è¿›è¡Œå¤šæ¨¡æ€é¢„è®­ç»ƒï¼Œæå‡å›¾åƒã€è¯­è¨€å’Œä¸‰ç»´æ•°æ®çš„å¯¹é½ï¼Œæ”¹å–„ç‰©ä½“è¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢ä»»åŠ¡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>åˆ©ç”¨ç‚¹äº‘è¡¨ç¤ºçš„3Då½¢çŠ¶åœ¨å›¾åƒå’Œè¯­è¨€æè¿°çš„å¯¹é½ä¸Šå–å¾—äº†å¤šæ¨¡æ€é¢„è®­ç»ƒçš„è¿›æ­¥ï¼Œè¿™å¯¹äºç‰©ä½“è¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢è‡³å…³é‡è¦ã€‚</li>
<li>ç‚¹äº‘çš„ç¦»æ•£è¡¨ç¤ºä¸¢å¤±äº†ç‰©ä½“çš„æ›²é¢å½¢çŠ¶ä¿¡æ¯ï¼Œå¹¶åœ¨æ¸²æŸ“ç»“æœå’Œ2Då¯¹åº”å…³ç³»ä¹‹é—´åˆ¶é€ å·®è·ã€‚</li>
<li>æå‡ºGS-CLIPï¼Œé¦–æ¬¡å°è¯•å°†3DGSï¼ˆä¸‰ç»´é«˜æ–¯æ¸²æŸ“ï¼‰å¼•å…¥å¤šæ¨¡æ€é¢„è®­ç»ƒï¼Œä»¥å¢å¼º3Dè¡¨ç¤ºã€‚</li>
<li>GS-CLIPåˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œåœ¨å¤§é‡çœŸå®ä¸–ç•Œå›¾åƒ-æ–‡æœ¬å¯¹ä¸Šå­¦ä¹ ä¸€ä¸ªé€šç”¨çš„è§†è§‰å’Œæ–‡æœ¬ç©ºé—´ï¼Œç„¶åå­¦ä¹ ä¸€ä¸ªé’ˆå¯¹æ¯ä¸ªç‰©ä½“ä¼˜åŒ–3DGSçš„3Dç¼–ç å™¨ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„é«˜æ–¯æ„ŸçŸ¥èåˆæ¥æå–å’Œèåˆå…¨å±€æ˜¾å¼ç‰¹å¾ã€‚</li>
<li>ä½œä¸ºè¯­è¨€-å›¾åƒ-3Dé¢„è®­ç»ƒçš„é€šç”¨æ¡†æ¶ï¼ŒGS-CLIPç‹¬ç«‹äº3Déª¨å¹²ç½‘ç»œã€‚</li>
<li>å…·æœ‰æŒ‘æˆ˜æ€§çš„å®éªŒè¡¨æ˜ï¼ŒGS-CLIPæ˜¾è‘—ä¼˜äºæœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œè¶…è¶Šäº†ä»¥å‰æœ€å¥½çš„æˆæœã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šGS-CLIPï¼šç”¨äºå¯¹æ¯”è¯­è¨€-å›¾åƒ-3D é¢„è®­ç»ƒçš„é«˜æ–¯å–·ç»˜</li>
<li>ä½œè€…ï¼šææ˜Šæºã€å‘¨é›é¹ã€æ›¾ä¹‰æ¶µã€å¾èˆªã€æ¢æ™“ä¸¹</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ·±åœ³å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D è¡¨ç¤ºã€å¯¹æ¯”å­¦ä¹ ã€å¤šæ¨¡æ€é¢„è®­ç»ƒã€é«˜æ–¯å–·ç»˜</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.06198ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D å½¢çŠ¶è¡¨ç¤ºä¸ºç‚¹äº‘åœ¨å¤šæ¨¡æ€é¢„è®­ç»ƒä¸­å–å¾—äº†è¿›å±•ï¼Œå¯ä»¥å¯¹é½å›¾åƒå’Œè¯­è¨€æè¿°ï¼Œè¿™å¯¹ç‰©ä½“è¯†åˆ«ã€åˆ†ç±»å’Œæ£€ç´¢è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç‚¹äº‘çš„ç¦»æ•£è¡¨ç¤ºä¸¢å¤±äº†ç‰©ä½“çš„è¡¨é¢å½¢çŠ¶ä¿¡æ¯ï¼Œå¹¶åœ¨æ¸²æŸ“ç»“æœå’Œ 2D å¯¹åº”å…³ç³»ä¹‹é—´äº§ç”Ÿäº†å·®è·ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å¯¹ç‚¹äº‘è¿›è¡Œå»ºæ¨¡ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸ä¼šä¸¢å¤±ç‰©ä½“çš„å‡ ä½•ä¿¡æ¯å’Œå½¢çŠ¶çº¹ç†ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ•°æ®ï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥åº”ç”¨äºç°å®ä¸–ç•Œä¸­çš„åœºæ™¯ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ GS-CLIPï¼Œè¯¥æ¡†æ¶å°† 3D é«˜æ–¯å–·ç»˜ (3DGS) å¼•å…¥å¤šæ¨¡æ€é¢„è®­ç»ƒä¸­ï¼Œä»¥å¢å¼º 3D è¡¨ç¤ºã€‚GS-CLIP åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤§é‡çœŸå®ä¸–ç•Œå›¾åƒ-æ–‡æœ¬å¯¹ä¸Šå­¦ä¹ ä¸€ä¸ªå…±åŒçš„è§†è§‰å’Œæ–‡æœ¬ç©ºé—´ï¼Œç„¶åå­¦ä¹ ä¸€ä¸ª 3D ç¼–ç å™¨æ¥å¯¹é½é’ˆå¯¹æ¯ä¸ªå¯¹è±¡ä¼˜åŒ–çš„ 3DGSã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„é«˜æ–¯æ„ŸçŸ¥èåˆæ–¹æ³•ï¼Œç”¨äºæå–å’Œèåˆå…¨å±€æ˜¾å¼ç‰¹å¾ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨ SUN-RGBD æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒGS-CLIP åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­çš„é›¶æ ·æœ¬/å¼€æ”¾ä¸–ç•Œå­¦ä¹ ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œ3DGS åœ¨è·¨æ¨¡æ€å­¦ä¹ ä¸­å…·æœ‰å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰è·¨æ¨¡æ€é¢„è®­ç»ƒï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„è¯­è¨€-å›¾åƒæ¨¡å‹CLIPï¼Œä¸ºæ–‡æœ¬ã€å›¾åƒå’Œ3DGSå»ºç«‹å…±åŒçš„è¯­è¨€-å›¾åƒæ½œåœ¨ç©ºé—´ï¼Œä½œä¸º3DGSçš„ç›®æ ‡æ½œåœ¨ç©ºé—´ã€‚
ï¼ˆ2ï¼‰è¯­è¨€-3DGSå¯¹é½å’Œå›¾åƒ-3DGSå¯¹é½ï¼šåˆ†åˆ«ä½¿ç”¨å¯¹æ¯”æŸå¤±å‡½æ•°æ¥å¯¹é½æ–‡æœ¬ä¸3DGSã€å›¾åƒä¸3DGSçš„ç‰¹å¾è¡¨ç¤ºã€‚
ï¼ˆ3ï¼‰é«˜æ–¯æ„ŸçŸ¥èåˆï¼šé‡‡ç”¨åŸºäºTransformerçš„åˆ†æ”¯ç›´æ¥å¯¹é«˜æ–¯ç‰¹å¾è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å°†å…¶ä¸æ®‹å·®å½¢å¼æ³¨å…¥åˆ°3Dä¸»å¹²ç½‘ç»œä¸­ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé¦–æ¬¡å°† 3DGS çº³å…¥è·¨æ¨¡æ€å­¦ä¹ ï¼Œä½œä¸ºè¡¥å……å½¢çŠ¶å’Œçº¹ç†ä¿¡æ¯çš„é€šç”¨ 3D è¡¨ç¤ºã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ç§é«˜æ–¯æ„ŸçŸ¥èåˆï¼Œä»¥ä¾¿æ›´å¥½åœ°ä»è¡¥å……ä¿¡æ¯ä¸­å­¦ä¹ ä¿¡æ¯ã€‚æˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬æå‡ºçš„ GS-CLIP åœ¨æœ€å…ˆè¿›çš„æ–¹æ³•ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å®ç°äº†é›¶æ ·æœ¬/å¼€æ”¾ä¸–ç•Œå­¦ä¹ çš„æœ€æ–°æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å°† 3DGS å¼•å…¥è·¨æ¨¡æ€å­¦ä¹ ï¼Œä½œä¸ºè¡¥å……å½¢çŠ¶å’Œçº¹ç†ä¿¡æ¯çš„é€šç”¨ 3D è¡¨ç¤ºã€‚</li>
<li>æå‡ºäº†ä¸€ç§é«˜æ–¯æ„ŸçŸ¥èåˆï¼Œä»¥ä¾¿æ›´å¥½åœ°ä»è¡¥å……ä¿¡æ¯ä¸­å­¦ä¹ ä¿¡æ¯ã€‚</li>
<li>åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­å®ç°äº†é›¶æ ·æœ¬/å¼€æ”¾ä¸–ç•Œå­¦ä¹ çš„æœ€æ–°æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ SUN-RGBD æ•°æ®é›†ä¸Šï¼ŒGS-CLIP åœ¨çœŸå®ä¸–ç•Œç¯å¢ƒä¸­çš„é›¶æ ·æœ¬/å¼€æ”¾ä¸–ç•Œå­¦ä¹ ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>è¿™äº›ç»“æœè¡¨æ˜ï¼Œ3DGS åœ¨è·¨æ¨¡æ€å­¦ä¹ ä¸­å…·æœ‰å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥å·¥ä½œæ¶‰åŠåˆ°å¤§é‡çš„æ•°æ®é¢„å¤„ç†å’Œæ¨¡å‹è®­ç»ƒã€‚</li>
<li>éœ€è¦å¯¹ 3DGS è¿›è¡Œä¼˜åŒ–ï¼Œä»¥ä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å¯¹é½æ–‡æœ¬å’Œå›¾åƒçš„ç‰¹å¾è¡¨ç¤ºã€‚</li>
<li>éœ€è¦å¯¹é«˜æ–¯æ„ŸçŸ¥èåˆè¿›è¡Œè¿›ä¸€æ­¥çš„ç ”ç©¶ï¼Œä»¥ä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°æå–å’Œèåˆå…¨å±€æ˜¾å¼ç‰¹å¾ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5ca02e3188a2350914f961c6e31c0616.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4980273838b01e0c94c7593c3becb878.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b33d684beebaf5252e0357a0e0af9c1d.jpg" align="middle">
</details>




<h2 id="GaMeS-Mesh-Based-Adapting-and-Modification-of-Gaussian-Splatting"><a href="#GaMeS-Mesh-Based-Adapting-and-Modification-of-Gaussian-Splatting" class="headerlink" title="GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting"></a>GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting</h2><p><strong>Authors:Joanna WaczyÅ„ska, Piotr Borycki, SÅ‚awomir Tadeja, Jacek Tabor, PrzemysÅ‚aw Spurek</strong></p>
<p>Recently, a range of neural network-based methods for image rendering have been introduced. One such widely-researched neural radiance field (NeRF) relies on a neural network to represent 3D scenes, allowing for realistic view synthesis from a small number of 2D images. However, most NeRF models are constrained by long training and inference times. In comparison, Gaussian Splatting (GS) is a novel, state-of-the-art technique for rendering points in a 3D scene by approximating their contribution to image pixels through Gaussian distributions, warranting fast training and swift, real-time rendering. A drawback of GS is the absence of a well-defined approach for its conditioning due to the necessity to condition several hundred thousand Gaussian components. To solve this, we introduce the Gaussian Mesh Splatting (GaMeS) model, which allows modification of Gaussian components in a similar way as meshes. We parameterize each Gaussian component by the vertices of the mesh face. Furthermore, our model needs mesh initialization on input or estimated mesh during training. We also define Gaussian splats solely based on their location on the mesh, allowing for automatic adjustments in position, scale, and rotation during animation. As a result, we obtain a real-time rendering of editable GS. </p>
<p><a href="http://arxiv.org/abs/2402.01459v3">PDF</a> </p>
<p><strong>Summary:</strong><br>ç¥ç»è¾å°„åœº (NeRF) æ˜¯ä¸€ç§ç”¨äºå›¾åƒæ¸²æŸ“çš„ç¥ç»ç½‘ç»œæ–¹æ³•ï¼Œè€Œé«˜æ–¯ç½‘æ ¼æ³¼æº… (GaMeS) æ¨¡å‹åˆ™é€šè¿‡é«˜æ–¯åˆ†å¸ƒæ¥ä¼°ç®— 3D åœºæ™¯ä¸­ç‚¹çš„è´¡çŒ®ï¼Œä»è€Œå®ç°å¿«é€Ÿè®­ç»ƒå’Œå®æ—¶æ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>åˆ©ç”¨ç¥ç»ç½‘ç»œè¡¨å¾ 3D åœºæ™¯çš„ NeRFï¼Œå…è®¸ä»å°‘é‡ 2D å›¾åƒä¸­è¿›è¡Œé€¼çœŸçš„è§†ç‚¹åˆæˆã€‚</li>
<li>é«˜æ–¯æ³¼æº… (GS) é€šè¿‡é«˜æ–¯åˆ†å¸ƒæ¥ä¼°ç®— 3D åœºæ™¯ä¸­ç‚¹çš„è´¡çŒ®ï¼Œä»è€Œå®ç°å¿«é€Ÿè®­ç»ƒå’Œå®æ—¶æ¸²æŸ“ã€‚</li>
<li>GaMeS æ¨¡å‹å…è®¸ä»¥ä¸ç½‘æ ¼ç±»ä¼¼çš„æ–¹å¼ä¿®æ”¹é«˜æ–¯åˆ†é‡ï¼Œä»è€Œä¸º GS çš„è°ƒèŠ‚æä¾›äº†ä¸€ä¸ªæ˜ç¡®çš„æ–¹æ³•ã€‚</li>
<li>å°†æ¯ä¸ªé«˜æ–¯åˆ†é‡å‚æ•°åŒ–ä¸ºç½‘æ ¼é¢çš„é¡¶ç‚¹ï¼Œè¿™ä½¿å¾— GaMeS æ¨¡å‹å¯ä»¥å¯¹ GS è¿›è¡Œå®æ—¶æ¸²æŸ“ã€‚</li>
<li>GaMeS æ¨¡å‹éœ€è¦åœ¨è¾“å…¥æ—¶åˆå§‹åŒ–ç½‘æ ¼æˆ–åœ¨è®­ç»ƒæœŸé—´ä¼°è®¡ç½‘æ ¼ã€‚</li>
<li>æ ¹æ®å…¶åœ¨ç½‘æ ¼ä¸Šçš„ä½ç½®å®šä¹‰é«˜æ–¯æ³¼æº…ï¼Œä»è€Œå…è®¸åœ¨åŠ¨ç”»æœŸé—´è‡ªåŠ¨è°ƒæ•´ä½ç½®ã€ç¼©æ”¾å’Œæ—‹è½¬ã€‚</li>
<li>GaMeS æ¨¡å‹å¯ä»¥å®ç°å¯ç¼–è¾‘ GS çš„å®æ—¶æ¸²æŸ“ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šGaMeSï¼šåŸºäºç½‘æ ¼çš„è‡ªé€‚åº”å’Œä¿®æ”¹é«˜æ–¯å–·ç»˜</li>
<li>ä½œè€…ï¼šJoanna WaczyÅ„skaã€Piotr Boryckiã€SÅ‚awomir Tadejaã€Jacek Taborã€PrzemysÅ‚aw Spurek</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé›…ç›–éš†å¤§å­¦æ•°å­¦ä¸è®¡ç®—æœºç§‘å­¦å­¦é™¢ï¼Œæ³¢å…°å…‹æ‹‰ç§‘å¤«</li>
<li>å…³é”®è¯ï¼šé«˜æ–¯å–·ç»˜ã€ç¥ç»è¾å°„åœºã€ç¥ç»æ¸²æŸ“ã€ç½‘æ ¼ã€å®æ—¶æ¸²æŸ“</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.01459ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè¿‘å¹´æ¥ï¼ŒåŸºäºç¥ç»ç½‘ç»œçš„å›¾åƒæ¸²æŸ“æ–¹æ³•å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œå…¶ä¸­ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ˜¯ä¸€ç§æµè¡Œçš„æ–¹æ³•ï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è¡¨ç¤º 3D åœºæ™¯ï¼Œå¹¶èƒ½å¤Ÿä»å°‘é‡ 2D å›¾åƒä¸­åˆæˆé€¼çœŸçš„è§†å›¾ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•° NeRF æ¨¡å‹éƒ½å—åˆ°è®­ç»ƒå’Œæ¨ç†æ—¶é—´é•¿çš„é™åˆ¶ã€‚ä¸ä¹‹ç›¸æ¯”ï¼Œé«˜æ–¯å–·ç»˜ï¼ˆGSï¼‰æ˜¯ä¸€ç§æ–°é¢–çš„ã€æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œå®ƒé€šè¿‡é«˜æ–¯åˆ†å¸ƒæ¥è¿‘ä¼¼ç‚¹å¯¹å›¾åƒåƒç´ çš„è´¡çŒ®ï¼Œä»è€Œæ¸²æŸ“ 3D åœºæ™¯ä¸­çš„ç‚¹ï¼Œå…·æœ‰å¿«é€Ÿè®­ç»ƒå’Œå¿«é€Ÿå®æ—¶æ¸²æŸ“çš„èƒ½åŠ›ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šGS çš„ä¸€ä¸ªç¼ºç‚¹æ˜¯ç¼ºä¹æ˜ç¡®çš„è°ƒèŠ‚æ–¹æ³•ï¼Œå› ä¸ºéœ€è¦è°ƒèŠ‚æ•°åä¸‡ä¸ªé«˜æ–¯åˆ†é‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡ä»‹ç»äº†é«˜æ–¯ç½‘æ ¼å–·ç»˜ï¼ˆGaMeSï¼‰æ¨¡å‹ï¼Œå®ƒå…è®¸åƒä¿®æ”¹ç½‘æ ¼ä¸€æ ·ä¿®æ”¹é«˜æ–¯åˆ†é‡ã€‚æˆ‘ä»¬å°†æ¯ä¸ªé«˜æ–¯åˆ†é‡å‚æ•°åŒ–ä¸ºç½‘æ ¼é¢çš„é¡¶ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹éœ€è¦åœ¨è¾“å…¥æˆ–è®­ç»ƒæœŸé—´ä¼°è®¡çš„ç½‘æ ¼ä¸Šè¿›è¡Œç½‘æ ¼åˆå§‹åŒ–ã€‚æˆ‘ä»¬è¿˜å®šä¹‰äº†ä»…åŸºäºå…¶åœ¨ç½‘æ ¼ä¸Šçš„ä½ç½®çš„é«˜æ–¯å–·ç»˜ï¼Œå…è®¸åœ¨åŠ¨ç”»æœŸé—´è‡ªåŠ¨è°ƒæ•´ä½ç½®ã€æ¯”ä¾‹å’Œæ—‹è½¬ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è·å¾—äº†å¯ç¼–è¾‘ GS çš„å®æ—¶æ¸²æŸ“ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº† GaMeS æ¨¡å‹ï¼Œå®ƒå…è®¸åƒä¿®æ”¹ç½‘æ ¼ä¸€æ ·ä¿®æ”¹é«˜æ–¯åˆ†é‡ã€‚æˆ‘ä»¬å°†æ¯ä¸ªé«˜æ–¯åˆ†é‡å‚æ•°åŒ–ä¸ºç½‘æ ¼é¢çš„é¡¶ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ¨¡å‹éœ€è¦åœ¨è¾“å…¥æˆ–è®­ç»ƒæœŸé—´ä¼°è®¡çš„ç½‘æ ¼ä¸Šè¿›è¡Œç½‘æ ¼åˆå§‹åŒ–ã€‚æˆ‘ä»¬è¿˜å®šä¹‰äº†ä»…åŸºäºå…¶åœ¨ç½‘æ ¼ä¸Šçš„ä½ç½®çš„é«˜æ–¯å–·ç»˜ï¼Œå…è®¸åœ¨åŠ¨ç”»æœŸé—´è‡ªåŠ¨è°ƒæ•´ä½ç½®ã€æ¯”ä¾‹å’Œæ—‹è½¬ã€‚
(4)ï¼šæ–¹æ³•çš„æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒGaMeS æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿æŒé«˜è´¨é‡æ¸²æŸ“çš„åŒæ—¶ï¼Œå®ç°å®æ—¶ä¿®æ”¹å’Œé€‚åº”é«˜æ–¯å–·ç»˜ã€‚è¿™ä½¿å¾— GaMeS æˆä¸ºäº¤äº’å¼åº”ç”¨ç¨‹åºå’Œæ¸¸æˆä¸­çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„æŠ€æœ¯ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰GaMeS å…è®¸å®æ—¶ä¿®æ”¹ï¼Œä½†å¯¹äºå…·æœ‰å¤§é¢çš„ç½‘æ ¼ï¼Œåœ¨å‘ç”Ÿé‡å¤§å˜åŒ–çš„æƒ…å†µä¸‹ä¼šå‡ºç°ä¼ªå½±ã€‚åœ¨å®è·µä¸­ï¼Œå¤§é¢åº”è¯¥è¢«åˆ†æˆæ›´å°çš„é¢ã€‚å½“ç½‘æ ¼é¢åˆ†è£‚æ—¶å¦‚ä½•åœ¨ GaMeS ä¸­æ›´æ”¹é«˜æ–¯åˆ†é‡å°šä¸æ¸…æ¥šã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šGaMeS æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºç½‘æ ¼çš„è‡ªé€‚åº”å’Œä¿®æ”¹é«˜æ–¯å–·ç»˜æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…è®¸åƒä¿®æ”¹ç½‘æ ¼ä¸€æ ·ä¿®æ”¹é«˜æ–¯åˆ†é‡ï¼Œä»è€Œå®ç°äº†å®æ—¶ä¿®æ”¹å’Œé€‚åº”é«˜æ–¯å–·ç»˜ã€‚
æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒGaMeS æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿æŒé«˜è´¨é‡æ¸²æŸ“çš„åŒæ—¶ï¼Œå®ç°å®æ—¶ä¿®æ”¹å’Œé€‚åº”é«˜æ–¯å–·ç»˜ã€‚è¿™ä½¿å¾— GaMeS æˆä¸ºäº¤äº’å¼åº”ç”¨ç¨‹åºå’Œæ¸¸æˆä¸­çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„æŠ€æœ¯ã€‚
å·¥ä½œé‡ï¼šGaMeS æ¨¡å‹éœ€è¦åœ¨è¾“å…¥æˆ–è®­ç»ƒæœŸé—´ä¼°è®¡ç½‘æ ¼ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æ—¶é—´ã€‚æ­¤å¤–ï¼ŒGaMeS æ¨¡å‹éœ€è¦å¯¹ç½‘æ ¼è¿›è¡Œä¿®æ”¹ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ æ¨¡å‹çš„ä¿®æ”¹æ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-11676aa94eeb837bc5149bf9038274ae.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3d3c20ac78640d356ea03699146c96e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4070017cd795fd8699e30a356efae899.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0416310a796f7ec70150342ac59ffe37.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6eb0975a0f5d702a6daef3f78e530869.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9fb0edd088d9a64e792369a6d6a72979.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-dd54f927f26f28fdcefe778d566087c5.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF</title>
    <url>/2024/02/23/Paper/2024-02-23/NeRF/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-23-æ›´æ–°"><a href="#2024-02-23-æ›´æ–°" class="headerlink" title="2024-02-23 æ›´æ–°"></a>2024-02-23 æ›´æ–°</h1><h2 id="Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting"><a href="#Identifying-Unnecessary-3D-Gaussians-using-Clustering-for-Fast-Rendering-of-3D-Gaussian-Splatting" class="headerlink" title="Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting"></a>Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering   of 3D Gaussian Splatting</h2><p><strong>Authors:Joongho Jo, Hyeongwon Kim, Jongsun Park</strong></p>
<p>3D Gaussian splatting (3D-GS) is a new rendering approach that outperforms the neural radiance field (NeRF) in terms of both speed and image quality. 3D-GS represents 3D scenes by utilizing millions of 3D Gaussians and projects these Gaussians onto the 2D image plane for rendering. However, during the rendering process, a substantial number of unnecessary 3D Gaussians exist for the current view direction, resulting in significant computation costs associated with their identification. In this paper, we propose a computational reduction technique that quickly identifies unnecessary 3D Gaussians in real-time for rendering the current view without compromising image quality. This is accomplished through the offline clustering of 3D Gaussians that are close in distance, followed by the projection of these clusters onto a 2D image plane during runtime. Additionally, we analyze the bottleneck associated with the proposed technique when executed on GPUs and propose an efficient hardware architecture that seamlessly supports the proposed scheme. For the Mip-NeRF360 dataset, the proposed technique excludes 63% of 3D Gaussians on average before the 2D image projection, which reduces the overall rendering computation by almost 38.3% without sacrificing peak-signal-to-noise-ratio (PSNR). The proposed accelerator also achieves a speedup of 10.7x compared to a GPU. </p>
<p><a href="http://arxiv.org/abs/2402.13827v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br> NeurRF åŠ é€Ÿï¼šä¸€ç§æ–°çš„è®¡ç®—æ–¹æ³•ï¼Œé€šè¿‡å¿«é€Ÿè¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“åœ¨å®æ—¶æ¸²æŸ“å½“å‰è§†å›¾ï¼Œä»è€Œæé«˜æ¸²æŸ“é€Ÿåº¦å’Œå›¾åƒè´¨é‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>NeurRF æ˜¯ä¸€ç§æ–°çš„æ¸²æŸ“æ–¹æ³•ï¼Œåˆ©ç”¨æ•°ç™¾ä¸‡ä¸ª 3D é«˜æ–¯ä½“æ¥è¡¨ç¤º 3D åœºæ™¯ï¼Œå¹¶å°†å…¶æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šè¿›è¡Œæ¸²æŸ“ã€‚</li>
<li>åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œå­˜åœ¨å¤§é‡å¯¹äºå½“å‰è§†å›¾æ–¹å‘æ¥è¯´ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œå¯¼è‡´è¯†åˆ«è¿™äº›é«˜æ–¯ä½“çš„è®¡ç®—æˆæœ¬å¾ˆé«˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è®¡ç®—ç®€åŒ–æŠ€æœ¯ï¼Œèƒ½å¤Ÿåœ¨å®æ—¶å¿«é€Ÿè¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œåœ¨ä¸å½±å“å›¾åƒè´¨é‡çš„æƒ…å†µä¸‹æ¸²æŸ“å½“å‰è§†å›¾ã€‚</li>
<li>è¯¥æŠ€æœ¯é€šè¿‡å¯¹è·ç¦»ç›¸è¿‘çš„ 3D é«˜æ–¯ä½“è¿›è¡Œç¦»çº¿èšç±»æ¥å®ç°ï¼Œç„¶ååœ¨è¿è¡Œæ—¶å°†è¿™äº›ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šã€‚</li>
<li>åˆ†æäº†è¯¥æŠ€æœ¯åœ¨ GPU ä¸Šæ‰§è¡Œæ—¶é‡åˆ°çš„ç“¶é¢ˆï¼Œå¹¶æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„ç¡¬ä»¶æ¶æ„æ¥æ— ç¼æ”¯æŒè¯¥æ–¹æ¡ˆã€‚</li>
<li>å¯¹äº Mip-NeRF360 æ•°æ®é›†ï¼Œè¯¥æŠ€æœ¯åœ¨ 2D å›¾åƒæŠ•å½±å‰å¹³å‡æ’é™¤ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—é‡å‡å°‘äº†è¿‘ 38.3%ï¼Œè€Œå³°å€¼ä¿¡å™ªæ¯” (PSNR) å´ä¸ä¼šä¸‹é™ã€‚</li>
<li>æ‰€æå‡ºçš„åŠ é€Ÿå™¨ä¸ GPU ç›¸æ¯”ï¼Œé€Ÿåº¦æé«˜äº† 10.7 å€ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šä½¿ç”¨èšç±»è¯†åˆ«ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œå®ç° 3D é«˜æ–¯æ–‘ç‚¹æ¸²æŸ“çš„å¿«é€Ÿæ¸²æŸ“</li>
<li>ä½œè€…ï¼šJoongho Jo, Hyeongwon Kim, Jongsun Park</li>
<li>å•ä½ï¼šéŸ©å›½å¤§å­¦ç”µæ°”å·¥ç¨‹å­¦é™¢ï¼ˆä»…ç¿»è¯‘å•ä½åç§°ï¼‰</li>
<li>å…³é”®è¯ï¼š3D é«˜æ–¯æ–‘ç‚¹æ¸²æŸ“ã€æ¸²æŸ“ã€NeRFã€ç¥ç»è¾å°„åœºã€ç¡¬ä»¶åŠ é€Ÿå™¨</li>
<li>é“¾æ¥ï¼šPaper_info:Identifying Unnecessary 3D Gaussians using Clustering for Fast Rendering of 3D Gaussian Splattingï¼ŒGithubï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåœ¨ 3D è®¡ç®—æœºè§†è§‰åº”ç”¨ä¸­ï¼Œä¾‹å¦‚å¢å¼ºç°å® (AR)ã€è™šæ‹Ÿç°å® (VR) å’Œå…ƒå®‡å®™ï¼Œå¿«é€Ÿä¸”é«˜è´¨é‡çš„å›¾åƒæ¸²æŸ“éå¸¸é‡è¦ã€‚è™½ç„¶ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œçš„æ¸²æŸ“æŠ€æœ¯ï¼Œä¾‹å¦‚ç¥ç»è¾å°„åœº (NeRF)ï¼Œå·²ç»å¾—åˆ°äº†å¹¿æ³›çš„ç ”ç©¶ï¼Œä½† 3D é«˜æ–¯æ–‘ç‚¹æ¸²æŸ“ (3D-GS) ä½œä¸ºä¸€ç§æ–°çš„æ¸²æŸ“æ–¹æ³•ï¼Œå› å…¶ä¸ä¼ ç»Ÿ NeRF ç›¸æ¯”èƒ½å¤Ÿå¿«é€Ÿæ¸²æŸ“é«˜è´¨é‡å›¾åƒè€Œå¤‡å—å…³æ³¨ã€‚3D-GS åˆ©ç”¨æ•°ç™¾ä¸‡ä¸ª 3D é«˜æ–¯ä½“æ¥è¡¨ç¤ºå¤æ‚çš„ 3D åœºæ™¯ï¼Œå¹¶é€šè¿‡å°† 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šæ¥æ¸²æŸ“ 3D åœºæ™¯ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š3D-GS æ¸²æŸ“è¿‡ç¨‹ä¸»è¦åˆ†ä¸ºä¸¤æ­¥ï¼š1ï¼‰å°†æ‰€æœ‰ 3D é«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œå¹¶è¯†åˆ«å‡ºå½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“ã€‚2ï¼‰ç„¶åä½¿ç”¨å½±å“é¢œè‰²çš„å·²è¯†åˆ« 3D é«˜æ–¯ä½“è®¡ç®— 2D å›¾åƒä¸­æ¯ä¸ªåƒç´ çš„é¢œè‰²ã€‚åœ¨æ¸²æŸ“è¿‡ç¨‹çš„ç¬¬ä¸€æ­¥ä¸­ï¼Œé«˜æ–¯ä½“æŠ•å½±åˆ° 2D å›¾åƒä¸Šï¼Œä½†è¢«è¯†åˆ«ä¸ºä¸å½±å“ 2D å›¾åƒçš„é¢œè‰²ï¼ŒæŠ•å½±å°±å˜æˆäº†è®¡ç®—æµªè´¹ã€‚åœ¨ Mip-NeRF360 æ•°æ®é›†ä¸­ï¼Œå¹³å‡çº¦æœ‰ 67.6% çš„ 3D é«˜æ–¯ä½“ä¸å½±å“ 2D å›¾åƒçš„é¢œè‰²ã€‚å› æ­¤ï¼Œè¿™äº›é«˜æ–¯ä½“å¯ä»¥ä»å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­æ’é™¤ã€‚ç„¶è€Œï¼Œç”±äºå½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“å¯èƒ½ä¼šéšç€æ¸²æŸ“è§†ç‚¹çš„ä½ç½®å’Œæ–¹å‘è€Œæ”¹å˜ï¼Œå› æ­¤åœ¨å°†å®ƒä»¬æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢å‰è¯†åˆ«å‡ºä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å› æ­¤ï¼Œè¿™äº›ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ä»ç„¶ä¼šè¿›è¡ŒæŠ•å½±è®¡ç®—ã€‚å› æ­¤ï¼Œå¦‚æœèƒ½å¤Ÿå¼€å‘ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•æ¥é¢„æµ‹ä¸å½±å“ 2D å›¾åƒé¢œè‰²çš„ 3D é«˜æ–¯ä½“ï¼Œå¹¶åœ¨æ¸²æŸ“è¿‡ç¨‹å¼€å§‹å‰å°†å®ƒä»¬æ’é™¤ï¼Œåˆ™å¯ä»¥æ˜¾ç€é™ä½æ•´ä¸ª 3D-GS è¿‡ç¨‹çš„æ€»ä½“è®¡ç®—å¤æ‚åº¦ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ³•ï¼Œé€šè¿‡è¯†åˆ«ä¸å½±å“ 2D å›¾åƒé¢œè‰²çš„ç°‡æ¥æ’é™¤å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­çš„ä¸å¿…è¦ 3D é«˜æ–¯ä½“ã€‚èšç±»çš„ç›®çš„æ˜¯å°†ä½ç½®ç›¸è¿‘çš„ 3D é«˜æ–¯ä½“åˆ†ç»„åœ¨ä¸€èµ·ï¼Œå¹¶ä¸”ç°‡çš„å½¢çŠ¶åº”è¯¥æ˜¯çƒå½¢çš„ï¼Œä»¥ä¾¿äºæŠ•å½±åˆ° 2D å›¾åƒä¸Šã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨äº† K-means èšç±»ç®—æ³•ï¼Œå®ƒæ»¡è¶³è¿™ä¸¤ä¸ªæ ‡å‡†ã€‚é‰´äº 3D é«˜æ–¯ä½“å…·æœ‰ç”±å…¶åæ–¹å·®å®šä¹‰çš„å¤§å°æˆ–å½±å“ï¼Œç°‡çƒä½“çš„åŠå¾„ä¸ä»…ç”±åˆ°ç°‡è´¨å¿ƒçš„è·ç¦»å†³å®šï¼Œè¿˜è€ƒè™‘äº†é«˜æ–¯ä½“çš„å¤§å°ã€‚ç„¶åå°†è¿™äº›å®šä¹‰çš„ç°‡çƒä½“æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šï¼Œä»¥ç¡®å®šå®ƒä»¬å¯¹ 2D å›¾åƒé¢œè‰²çš„å½±å“ã€‚ä¸å½±å“å›¾åƒé¢œè‰²çš„ç°‡å¯ä»¥ä»æ¸²æŸ“è¿‡ç¨‹ä¸­æ’é™¤ã€‚åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­ï¼Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„å¯ä»¥åœ¨çº¿â€‹â€‹ä¸‹æ‰§è¡Œï¼Œåªæœ‰å°†ç°‡æŠ•å½±åˆ° 2D å›¾åƒå¹³é¢ä¸Šæ˜¯åœ¨å®æ—¶è¿›è¡Œçš„ï¼Œè¿™ä»…éœ€è¦ 6.2% çš„è®¡ç®—å¼€é”€ã€‚åœ¨ 3D-GS æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œåœ¨å½“å‰è§†å›¾æ¸²æŸ“ä¹‹å‰åº”ç”¨æ‰€æå‡ºçš„æ–¹æ³•æ—¶ï¼Œå¹³å‡å¯ä»¥æ’é™¤ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ï¼Œè€Œä¸ä¼šç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR)ã€‚æ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†æ¯” GPU å¿« 10.7 å€çš„é€Ÿåº¦ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼Ÿæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨ Mip-NeRF360 æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ’é™¤ä¸å¿…è¦çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œå‡å°‘æ¸²æŸ“è®¡ç®—é‡å¹¶æé«˜æ¸²æŸ“é€Ÿåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ’é™¤å¹³å‡ 63% çš„ 3D é«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘ 38.3%ï¼Œè€Œä¸ä¼šç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯” (PSNR)ã€‚æ­¤å¤–ï¼Œæ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†æ¯” GPU å¿« 10.7 å€çš„é€Ÿåº¦ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å®ç°å…¶ç›®æ ‡ï¼Œå³å¿«é€Ÿæ¸²æŸ“é«˜è´¨é‡çš„ 3D å›¾åƒã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ³•ï¼Œé€šè¿‡è¯†åˆ«ä¸å½±å“2Då›¾åƒé¢œè‰²çš„ç°‡æ¥æ’é™¤å½“å‰è§†å›¾æ¸²æŸ“è¿‡ç¨‹ä¸­çš„ä¸å¿…è¦3Dé«˜æ–¯ä½“ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å‡å°‘æ¸²æŸ“è®¡ç®—é‡å¹¶æé«˜æ¸²æŸ“é€Ÿåº¦ï¼Œåœ¨Mip-NeRF360æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å¯ä»¥æ’é™¤å¹³å‡63%çš„3Dé«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘38.3%ï¼Œè€Œä¸ä¼šç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€‚æ­¤å¤–ï¼Œæ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†æ¯”GPUå¿«10.7å€çš„é€Ÿåº¦ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºèšç±»çš„æ–¹æ³•æ¥è¯†åˆ«ä¸å¿…è¦çš„3Dé«˜æ–¯ä½“ï¼Œè¯¥æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œèƒ½å¤Ÿæ˜¾ç€é™ä½3D-GSæ¸²æŸ“è¿‡ç¨‹çš„æ€»ä½“è®¡ç®—å¤æ‚åº¦ã€‚
æ€§èƒ½ï¼šè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ’é™¤ä¸å¿…è¦çš„3Dé«˜æ–¯ä½“ï¼Œä»è€Œå‡å°‘æ¸²æŸ“è®¡ç®—é‡å¹¶æé«˜æ¸²æŸ“é€Ÿåº¦ã€‚åœ¨Mip-NeRF360æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å¯ä»¥æ’é™¤å¹³å‡63%çš„3Dé«˜æ–¯ä½“ï¼Œä»è€Œå°†æ•´ä½“æ¸²æŸ“è®¡ç®—å‡å°‘äº†è¿‘38.3%ï¼Œè€Œä¸ä¼šç‰ºç‰²å³°å€¼ä¿¡å™ªæ¯”ï¼ˆPSNRï¼‰ã€‚æ­¤å¤–ï¼Œæ‰€æå‡ºçš„åŠ é€Ÿå™¨è¿˜å®ç°äº†æ¯”GPUå¿«10.7å€çš„é€Ÿåº¦ã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥åœ¨çº¿â€‹â€‹ä¸‹æ‰§è¡Œèšç±»å’Œè®¡ç®—ç°‡çš„åŠå¾„ï¼Œåªæœ‰å°†ç°‡æŠ•å½±åˆ°2Då›¾åƒå¹³é¢ä¸Šæ˜¯åœ¨å®æ—¶è¿›è¡Œçš„ï¼Œè¿™ä»…éœ€è¦6.2%çš„è®¡ç®—å¼€é”€ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-eb8532b7f44bd3308c4f19fe6bf7f78c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e5e9d849dcc9fd5228abd36df009311.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8a43367bbb6924d5ba043f598753b956.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d13d1af17267a2b843bea8ac607b39a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bca1cf3d857e2d53600b33fc6c9e298c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5799fc43b51197a24672703783ee479.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee494dce0084e0f0c71d55d940b03dc9.jpg" align="middle">
</details>




<h2 id="OccFlowNet-Towards-Self-supervised-Occupancy-Estimation-via-Differentiable-Rendering-and-Occupancy-Flow"><a href="#OccFlowNet-Towards-Self-supervised-Occupancy-Estimation-via-Differentiable-Rendering-and-Occupancy-Flow" class="headerlink" title="OccFlowNet: Towards Self-supervised Occupancy Estimation via   Differentiable Rendering and Occupancy Flow"></a>OccFlowNet: Towards Self-supervised Occupancy Estimation via   Differentiable Rendering and Occupancy Flow</h2><p><strong>Authors:Simon Boeder, Fabian Gigengack, Benjamin Risse</strong></p>
<p>Semantic occupancy has recently gained significant traction as a prominent 3D scene representation. However, most existing methods rely on large and costly datasets with fine-grained 3D voxel labels for training, which limits their practicality and scalability, increasing the need for self-monitored learning in this domain. In this work, we present a novel approach to occupancy estimation inspired by neural radiance field (NeRF) using only 2D labels, which are considerably easier to acquire. In particular, we employ differentiable volumetric rendering to predict depth and semantic maps and train a 3D network based on 2D supervision only. To enhance geometric accuracy and increase the supervisory signal, we introduce temporal rendering of adjacent time steps. Additionally, we introduce occupancy flow as a mechanism to handle dynamic objects in the scene and ensure their temporal consistency. Through extensive experimentation we demonstrate that 2D supervision only is sufficient to achieve state-of-the-art performance compared to methods using 3D labels, while outperforming concurrent 2D approaches. When combining 2D supervision with 3D labels, temporal rendering and occupancy flow we outperform all previous occupancy estimation models significantly. We conclude that the proposed rendering supervision and occupancy flow advances occupancy estimation and further bridges the gap towards self-supervised learning in this domain. </p>
<p><a href="http://arxiv.org/abs/2402.12792v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºå¯ä»ä»…ä½¿ç”¨äºŒç»´æ ‡ç­¾ä¸­ä¼°è®¡è¯­ä¹‰å ç”¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æå‡ºäº†ä¸€ç§ä»…ä½¿ç”¨äºŒç»´æ ‡ç­¾ä¼°è®¡å ç”¨ç‡çš„æ–°æ–¹æ³•ã€‚</li>
<li>é‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäºäºŒç»´ç›‘ç£è®­ç»ƒä¸‰ç»´ç½‘ç»œã€‚</li>
<li>ä¸ºäº†å¢å¼ºå‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œå¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥é•¿çš„æ—¶åºæ¸²æŸ“ã€‚</li>
<li>å¼•å…¥å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚</li>
<li>ä¸ä½¿ç”¨ä¸‰ç»´æ ‡ç­¾çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®éªŒè¡¨æ˜ä»…äºŒç»´ç›‘ç£å°±è¶³ä»¥å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¼˜äºåŒæ—¶æœŸçš„äºŒç»´æ–¹æ³•ã€‚</li>
<li>å½“å°†äºŒç»´ç›‘ç£ä¸ä¸‰ç»´æ ‡ç­¾ã€æ—¶æ€æ¸²æŸ“å’Œå ç”¨æµç›¸ç»“åˆæ—¶ï¼Œå¤§å¤§ä¼˜äºæ‰€æœ‰ä»¥å‰çš„å æœ‰ä¼°è®¡æ¨¡å‹ã€‚</li>
<li>æ¸²æŸ“ç›‘ç£å’Œå ç”¨æµçš„è¿›æ­¥ä¿ƒè¿›äº†å ç”¨ä¼°è®¡ï¼Œå¹¶è¿›ä¸€æ­¥ç¼©å°äº†è¯¥é¢†åŸŸä¸­è‡ªç›‘ç£å­¦ä¹ çš„å·®è·ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šOccFlowNetï¼šåŸºäºå¯å¾®æ¸²æŸ“å’Œå ç”¨æµçš„è‡ªç›‘ç£å ç”¨ä¼°è®¡</li>
<li>ä½œè€…ï¼šSimon Boeder, Fabian Gigengack, Benjamin Risse</li>
<li>ä½œè€…å•ä½ï¼šåšä¸–å…¬å¸ã€æ˜æ–¯ç‰¹å¤§å­¦</li>
<li>å…³é”®è¯ï¼šå ç”¨ä¼°è®¡ã€ç¥ç»è¾å°„åœºã€å¯å¾®æ¸²æŸ“ã€å ç”¨æµã€è‡ªç›‘ç£å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12792</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šè¯­ä¹‰å ç”¨æœ€è¿‘ä½œä¸ºä¸€ç§çªå‡ºçš„ 3D åœºæ™¯è¡¨ç¤ºå½¢å¼è€Œå—åˆ°å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¾èµ–äºå…·æœ‰ç»†ç²’åº¦ 3D ä½“ç´ æ ‡ç­¾çš„å¤§å‹ä¸”æ˜‚è´µçš„è®­ç»ƒæ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„å®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ï¼Œå¢åŠ äº†è¯¥é¢†åŸŸä¸­è‡ªç›‘ç£å­¦ä¹ çš„éœ€æ±‚ã€‚
(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æå‡ºäº†å—ç¥ç»è¾å°„åœº (NeRF) å¯å‘çš„æ–°å‹å ç”¨ä¼°è®¡æ–¹æ³•ï¼Œä»…ä½¿ç”¨æ›´æ˜“è·å–çš„ 2D æ ‡ç­¾ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬é‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäº 2D ç›‘ç£è®­ç»ƒ 3D ç½‘ç»œã€‚ä¸ºäº†æé«˜å‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥çš„é•¿æ—¶æ¸²æŸ“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬é€šè¿‡å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä»…ä½¿ç”¨ 2D ç›‘ç£å°±è¶³ä»¥ä¸ä½¿ç”¨ 3D æ ‡ç­¾çš„æ–¹æ³•ç›¸æ¯”å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¼˜äºåŒæ—¶æœŸçš„ 2D æ–¹æ³•ã€‚å½“å°† 2D ç›‘ç£ä¸ 3D æ ‡ç­¾ã€æ—¶åºæ¸²æŸ“å’Œå ç”¨æµç›¸ç»“åˆæ—¶ï¼Œæˆ‘ä»¬æ˜æ˜¾ä¼˜äºæ‰€æœ‰ä»¥å‰çš„å ç”¨ä¼°è®¡æ¨¡å‹ã€‚æˆ‘ä»¬å¾—å‡ºç»“è®ºï¼Œæ‰€æå‡ºçš„æ¸²æŸ“ç›‘ç£å’Œå ç”¨æµä¿ƒè¿›äº†å ç”¨ä¼°è®¡ï¼Œå¹¶è¿›ä¸€æ­¥ç¼©å°äº†è¯¥é¢†åŸŸä¸­è‡ªç›‘ç£å­¦ä¹ çš„å·®è·ã€‚
(4) æ€§èƒ½å’Œç»“è®ºï¼šåœ¨å¹¿æ³›ä½¿ç”¨çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å ç”¨ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³ä»…ä½¿ç”¨ 2D ç›‘ç£å°±å¯ä»¥å®ç°å‡†ç¡®çš„å ç”¨ä¼°è®¡ï¼Œä»è€Œä½¿è¯¥æ–¹æ³•æ›´æ˜“äºè®­ç»ƒå’Œéƒ¨ç½²ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1)ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å ç”¨ä¼°è®¡æ–¹æ³• OccFlowNetï¼Œä»…ä½¿ç”¨æ›´æ˜“è·å–çš„ 2D æ ‡ç­¾ï¼Œæ— éœ€æ˜‚è´µçš„ 3D ä½“ç´ æ ‡ç­¾ã€‚
(2)ï¼šæˆ‘ä»¬é‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäº 2D ç›‘ç£è®­ç»ƒ 3D ç½‘ç»œã€‚
(3)ï¼šä¸ºäº†æé«˜å‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥çš„é•¿æ—¶æ¸²æŸ“ã€‚
(4)ï¼šæˆ‘ä»¬å¼•å…¥äº†å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚
(5)ï¼šæˆ‘ä»¬é€šè¿‡å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä»…ä½¿ç”¨ 2D ç›‘ç£å°±è¶³ä»¥ä¸ä½¿ç”¨ 3D æ ‡ç­¾çš„æ–¹æ³•ç›¸æ¯”å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¼˜äºåŒæ—¶æœŸçš„ 2D æ–¹æ³•ã€‚
(6)ï¼šå½“å°† 2D ç›‘ç£ä¸ 3D æ ‡ç­¾ã€æ—¶åºæ¸²æŸ“å’Œå ç”¨æµç›¸ç»“åˆæ—¶ï¼Œæˆ‘ä»¬æ˜æ˜¾ä¼˜äºæ‰€æœ‰ä»¥å‰çš„å ç”¨ä¼°è®¡æ¨¡å‹ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé¦–æ¬¡æå‡ºäº†ä¸€ç§ä»…ä½¿ç”¨æ˜“äºè·å–çš„ 2D æ ‡ç­¾å³å¯è¿›è¡Œå ç”¨ä¼°è®¡çš„æ–¹æ³•ï¼Œæ— éœ€æ˜‚è´µçš„ 3D ä½“ç´ æ ‡ç­¾ï¼Œä¸ºå ç”¨ä¼°è®¡ä»»åŠ¡æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
åˆ›æ–°ç‚¹ 1ï¼šæå‡ºäº†ä¸€ç§æ–°çš„å ç”¨ä¼°è®¡æ–¹æ³• OccFlowNetï¼Œä»…ä½¿ç”¨æ›´æ˜“è·å–çš„ 2D æ ‡ç­¾ï¼Œæ— éœ€æ˜‚è´µçš„ 3D ä½“ç´ æ ‡ç­¾ã€‚
åˆ›æ–°ç‚¹ 2ï¼šé‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäº 2D ç›‘ç£è®­ç»ƒ 3D ç½‘ç»œã€‚
åˆ›æ–°ç‚¹ 3ï¼šä¸ºäº†æé«˜å‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œå¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥çš„é•¿æ—¶æ¸²æŸ“ã€‚
åˆ›æ–°ç‚¹ 4ï¼šå¼•å…¥äº†å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚
æ€§èƒ½ï¼š
åœ¨å¹¿æ³›ä½¿ç”¨çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å ç”¨ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š
æœ¬å·¥ä½œéœ€è¦è§£å†³çš„é—®é¢˜æ˜¯ï¼Œå¦‚ä½•ä»…ä½¿ç”¨ 2D æ ‡ç­¾è¿›è¡Œå ç”¨ä¼°è®¡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½œè€…æå‡ºäº† OccFlowNet æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨å¯å¾®ä½“ç§¯æ¸²æŸ“æ¥é¢„æµ‹æ·±åº¦å’Œè¯­ä¹‰å›¾ï¼Œå¹¶ä»…åŸºäº 2D ç›‘ç£è®­ç»ƒ 3D ç½‘ç»œã€‚ä¸ºäº†æé«˜å‡ ä½•ç²¾åº¦å¹¶å¢åŠ ç›‘ç£ä¿¡å·ï¼Œä½œè€…å¼•å…¥äº†ç›¸é‚»æ—¶é—´æ­¥çš„é•¿æ—¶æ¸²æŸ“ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜å¼•å…¥äº†å ç”¨æµä½œä¸ºå¤„ç†åœºæ™¯ä¸­åŠ¨æ€å¯¹è±¡å¹¶ç¡®ä¿å…¶æ—¶é—´ä¸€è‡´æ€§çš„æœºåˆ¶ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œä½œè€…è¯æ˜äº†æ‰€æå‡ºçš„æ–¹æ³•åœ¨å ç”¨ä¼°è®¡ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-48dbaf92efe683516d537be273981834.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff303fd6f4dc54f5b59e902e9b98c34a.jpg" align="middle">
</details>




<h2 id="Colorizing-Monochromatic-Radiance-Fields"><a href="#Colorizing-Monochromatic-Radiance-Fields" class="headerlink" title="Colorizing Monochromatic Radiance Fields"></a>Colorizing Monochromatic Radiance Fields</h2><p><strong>Authors:Yean Cheng, Renjie Wan, Shuchen Weng, Chengxuan Zhu, Yakun Chang, Boxin Shi</strong></p>
<p>Though Neural Radiance Fields (NeRF) can produce colorful 3D representations of the world by using a set of 2D images, such ability becomes non-existent when only monochromatic images are provided. Since color is necessary in representing the world, reproducing color from monochromatic radiance fields becomes crucial. To achieve this goal, instead of manipulating the monochromatic radiance fields directly, we consider it as a representation-prediction task in the Lab color space. By first constructing the luminance and density representation using monochromatic images, our prediction stage can recreate color representation on the basis of an image colorization module. We then reproduce a colorful implicit model through the representation of luminance, density, and color. Extensive experiments have been conducted to validate the effectiveness of our approaches. Our project page: <a href="https://liquidammonia.github.io/color-nerf">https://liquidammonia.github.io/color-nerf</a>. </p>
<p><a href="http://arxiv.org/abs/2402.12184v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å¯é€šè¿‡ä¸€ç»„äºŒç»´å›¾åƒäº§ç”Ÿè‰²å½©é²œè‰³çš„ 3D åœºæ™¯å†ç°ï¼Œä½†ä»…æä¾›å•è‰²å›¾åƒæ—¶ä¾¿æ— æ³•å®ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NeRF å¯ä»¥ä½¿ç”¨ä¸€ç»„ 2D å›¾åƒç”Ÿæˆä¸–ç•Œçš„å½©è‰² 3D è¡¨ç¤ºã€‚</li>
<li>ä»…æä¾›å•è‰²å›¾åƒæ—¶ï¼ŒNeRF æ— æ³•ç”Ÿæˆå½©è‰² 3D è¡¨ç¤ºã€‚</li>
<li>NeRF çš„ç›®æ ‡æ˜¯ä»å•è‰²è¾å°„åœºå†ç°å½©è‰²è¡¨ç¤ºã€‚</li>
<li>æå‡ºäº†ä¸€ç§åœ¨ Lab é¢œè‰²ç©ºé—´ä¸­å°†å•è‰²è¾å°„åœºè§†ä¸ºè¡¨ç¤ºé¢„æµ‹ä»»åŠ¡çš„æ–¹æ³•ã€‚</li>
<li>é¦–å…ˆä½¿ç”¨å•è‰²å›¾åƒæ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºï¼Œç„¶åä½¿ç”¨å›¾åƒç€è‰²æ¨¡å—é‡æ–°åˆ›å»ºé¢œè‰²è¡¨ç¤ºã€‚</li>
<li>ç„¶åé€šè¿‡äº®åº¦ã€å¯†åº¦å’Œé¢œè‰²çš„è¡¨ç¤ºå†ç°ä¸€ä¸ªå½©è‰²éšå¼æ¨¡å‹ã€‚</li>
<li>å¤§é‡å®éªŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå½©è‰²åŒ–å•è‰²è¾å°„åœº</li>
<li>ä½œè€…ï¼šå¶å®‰æˆã€ä¸‡ä»»æ°<em>ã€ç¿ä¹¦ç›ã€æœ±æ‰¿è½©ã€å¸¸äºšå¤ã€çŸ³åšæ¬£</em></li>
<li>éš¶å±å•ä½ï¼šåŒ—äº¬å¤§å­¦å¤šåª’ä½“ä¿¡æ¯å¤„ç†å›½å®¶é‡ç‚¹å®éªŒå®¤ã€è®¡ç®—æœºç§‘å­¦ç³»</li>
<li>å…³é”®è¯ï¼šNeRFã€å•è‰²å›¾åƒã€é¢œè‰²å†ç°ã€Labé¢œè‰²ç©ºé—´ã€å›¾åƒç€è‰²</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12184
   Github é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å¯ä»¥åˆ©ç”¨ä¸€ç»„äºŒç»´å›¾åƒåˆ›å»ºä¸–ç•Œçš„å½©è‰²ä¸‰ç»´è¡¨ç¤ºã€‚ç„¶è€Œï¼Œå½“åªæœ‰å•è‰²å›¾åƒå¯ç”¨æ—¶ï¼Œè¿™ç§èƒ½åŠ›å°±ä¸å¤å­˜åœ¨äº†ã€‚é¢œè‰²å¯¹äºè¡¨å¾ä¸–ç•Œæ˜¯å¿…è¦çš„ï¼Œå› æ­¤ä»å•è‰²è¾å°„åœºä¸­å†ç°é¢œè‰²å˜å¾—è‡³å…³é‡è¦ã€‚
   ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç›´æ¥æ“çºµå•è‰²è¾å°„åœºä¼¼ä¹æ˜¯å®ç°é¢œè‰²åŒ–çš„ç›´æ¥æ–¹æ³•ã€‚ä¸€ç§è§£å†³æ–¹æ¡ˆæ˜¯å°†é¢œè‰²è§†ä¸ºä¸€ç§â€œé£æ ¼â€ï¼Œç„¶åå°†å…¶è½¬ç§»åˆ°è¾å°„åœºä¸­ã€‚ç„¶è€Œï¼Œè¿™ç§ç­–ç•¥å¹¶ä¸èƒ½ä¿è¯é€åƒç´ çš„é¢œè‰²ä¸€è‡´æ€§ï¼Œå› æ­¤é¢œè‰²åªèƒ½ä¸è§„åˆ™åœ°åˆ†å¸ƒåœ¨è¾å°„åœºä¸­ï¼Œä»è€Œè¿èƒŒäº†åˆç†æ€§æ ‡å‡†ã€‚å¦ä¸€ç§æ–¹æ³•æ¶‰åŠç›´æ¥æ“çºµè¾å°„åœºä¸­çš„é¢œè‰²å±æ€§ã€‚è¿™ç§æŠ€æœ¯æ—¨åœ¨é€šè¿‡è¯†åˆ«å½“å‰çš„é¢œè‰²å±æ€§å¹¶ç”¨æ–°çš„é¢œè‰²å±æ€§æ›¿æ¢å®ƒä»¬æ¥æ›¿æ¢é¢œè‰²ã€‚ç„¶è€Œï¼Œå®ƒä¸é€‚ç”¨äºæ²¡æœ‰ç°æœ‰é¢œè‰²å±æ€§çš„å•è‰²è¾å°„åœºã€‚
   ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨ Lab é¢œè‰²ç©ºé—´ä¸­è¿›è¡Œè¡¨ç¤ºé¢„æµ‹çš„ä»»åŠ¡ã€‚é¦–å…ˆä½¿ç”¨å•è‰²å›¾åƒæ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºï¼Œç„¶ååˆ©ç”¨å›¾åƒç€è‰²æ¨¡å—é‡æ–°åˆ›å»ºé¢œè‰²è¡¨ç¤ºã€‚æœ€åï¼Œé€šè¿‡äº®åº¦ã€å¯†åº¦å’Œé¢œè‰²çš„è¡¨ç¤ºæ¥å†ç°ä¸€ä¸ªå½©è‰²éšå¼æ¨¡å‹ã€‚
   ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°åŠå…¶å¯¹ç›®æ ‡çš„æ”¯æŒï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬å•è‰²å›¾åƒç€è‰²ã€å¤šè§†å›¾å›¾åƒåˆæˆå’Œè§†é¢‘æ’å¸§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°ä»å•è‰²å›¾åƒä¸­å†ç°é¢œè‰²ï¼Œå¹¶ç”Ÿæˆé€¼çœŸä¸”è§†è§‰ä¸Šä»¤äººæ„‰æ‚¦çš„å½©è‰²ç»“æœã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºï¼šä½¿ç”¨å•è‰²å›¾åƒæ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºï¼Œä¸ºåç»­çš„é¢œè‰²å†ç°æä¾›åŸºç¡€ã€‚
(2) å›¾åƒç€è‰²æ¨¡å—ï¼šåˆ©ç”¨å›¾åƒç€è‰²æ¨¡å—é‡æ–°åˆ›å»ºé¢œè‰²è¡¨ç¤ºï¼Œå°†å•è‰²å›¾åƒä¸­çš„ä¿¡æ¯è½¬æ¢ä¸ºå½©è‰²è¡¨ç¤ºã€‚
(3) è¡¨ç¤ºé¢„æµ‹ï¼šåœ¨Labé¢œè‰²ç©ºé—´ä¸­è¿›è¡Œè¡¨ç¤ºé¢„æµ‹ï¼Œå°†äº®åº¦ã€å¯†åº¦å’Œé¢œè‰²çš„è¡¨ç¤ºç›¸ç»“åˆï¼Œå†ç°ä¸€ä¸ªå½©è‰²éšå¼æ¨¡å‹ã€‚
(4) é¢œè‰²æ³¨å…¥ï¼šåˆ©ç”¨åˆ†ç±»å™¨å°†é¢œè‰²æ³¨å…¥åˆ°è¾å°„åœºä¸­ï¼Œç¡®ä¿é¢œè‰²çš„åˆç†æ€§å’Œä¸€è‡´æ€§ã€‚
(5) ç›´æ–¹å›¾å‡€åŒ–ï¼šä½¿ç”¨ç›´æ–¹å›¾å‡€åŒ–æ¨¡å—å»é™¤ä¸åˆç†çš„é¢œè‰²ï¼Œæé«˜é¢œè‰²çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š</p>
</li>
</ol>
<p>ï¼ˆ1ï¼‰æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»å•è‰²å›¾åƒä¸­å†ç°é¢œè‰²çš„æ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¸ºå•è‰²å›¾åƒçš„å½©è‰²åŒ–æä¾›äº†æ–°çš„æ€è·¯å’ŒæŠ€æœ¯æ”¯æŒã€‚</p>
<p>ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š</p>
<p>åˆ›æ–°ç‚¹ï¼š</p>
<ul>
<li>æå‡ºäº†ä¸€ç§åœ¨Labé¢œè‰²ç©ºé—´ä¸­è¿›è¡Œè¡¨ç¤ºé¢„æµ‹çš„ä»»åŠ¡ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†å•è‰²å›¾åƒç€è‰²çš„é—®é¢˜ã€‚</li>
<li>æå‡ºäº†ä¸€ç§é¢œè‰²æ³¨å…¥æ¨¡å—ï¼Œç¡®ä¿äº†é¢œè‰²çš„åˆç†æ€§å’Œä¸€è‡´æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ç›´æ–¹å›¾å‡€åŒ–æ¨¡å—ï¼Œå»é™¤ä¸åˆç†çš„é¢œè‰²ï¼Œæé«˜äº†é¢œè‰²çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚</li>
</ul>
<p>æ€§èƒ½ï¼š</p>
<ul>
<li>åœ¨å•è‰²å›¾åƒç€è‰²ã€å¤šè§†å›¾å›¾åƒåˆæˆå’Œè§†é¢‘æ’å¸§ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
<li>ç”Ÿæˆçš„å½©è‰²ç»“æœé€¼çœŸä¸”è§†è§‰ä¸Šä»¤äººæ„‰æ‚¦ã€‚</li>
</ul>
<p>å·¥ä½œé‡ï¼š</p>
<ul>
<li>éœ€è¦æ„å»ºäº®åº¦å’Œå¯†åº¦è¡¨ç¤ºã€å›¾åƒç€è‰²æ¨¡å—ã€é¢œè‰²æ³¨å…¥æ¨¡å—å’Œç›´æ–¹å›¾å‡€åŒ–æ¨¡å—ã€‚</li>
<li>éœ€è¦è®­ç»ƒæ¨¡å‹ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-53ef44a8d86663951eb27790c491bec4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-40e071a248a066a783512765ca1dd311.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-04a5930c0187125fe64b74f7d43ea704.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-08fb7fd6e14278c9083abd8d5401c6b2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-34c76f358a2021ed97956d162ca195e3.jpg" align="middle">
</details>




## One2Avatar: Generative Implicit Head Avatar For Few-shot User Adaptation

**Authors:Zhixuan Yu, Ziqian Bai, Abhimitra Meka, Feitong Tan, Qiangeng Xu, Rohit Pandey, Sean Fanello, Hyun Soo Park, Yinda Zhang**

Traditional methods for constructing high-quality, personalized head avatars from monocular videos demand extensive face captures and training time, posing a significant challenge for scalability. This paper introduces a novel approach to create high quality head avatar utilizing only a single or a few images per user. We learn a generative model for 3D animatable photo-realistic head avatar from a multi-view dataset of expressions from 2407 subjects, and leverage it as a prior for creating personalized avatar from few-shot images. Different from previous 3D-aware face generative models, our prior is built with a 3DMM-anchored neural radiance field backbone, which we show to be more effective for avatar creation through auto-decoding based on few-shot inputs. We also handle unstable 3DMM fitting by jointly optimizing the 3DMM fitting and camera calibration that leads to better few-shot adaptation. Our method demonstrates compelling results and outperforms existing state-of-the-art methods for few-shot avatar adaptation, paving the way for more efficient and personalized avatar creation. 

[PDF](http://arxiv.org/abs/2402.11909v1) 

**Summary**
ç”¨ä¸€å¼ æˆ–æ•°å¼ ç”¨æˆ·ç…§ç‰‡å’Œ 3DMM ç¼–ç å³å¯ç”Ÿæˆé«˜è´¨é‡ä¸”å¯æ§åŠ¨çš„å¤´åƒã€‚

**Key Takeaways**

- è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ä½¿ç”¨ä¸€å¼ æˆ–å¤šå¼ å›¾åƒåˆ›å»ºé«˜è´¨é‡å¤´åƒçš„æ–°æ–¹æ³•ã€‚
- è¯¥æ–¹æ³•åˆ©ç”¨äº†ä¸€ä¸ªä» 2407 ä¸ªäººçš„å¤šè§†è§’é¢éƒ¨è¡¨æƒ…æ•°æ®é›†ä¸­å­¦å¾—çš„ç”Ÿæˆæ¨¡å‹ã€‚
- è¯¥æ–¹æ³•ä½¿ç”¨äº†åŸºäº 3DMM çš„ç¥ç»è¾å°„åœºä½œä¸ºéª¨å¹²ç½‘ç»œï¼Œä»¥å¢å¼ºé€šè¿‡å°‘é‡è¾“å…¥è¿›è¡Œè‡ªåŠ¨è§£ç çš„æ•ˆæœã€‚
- è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é€šè¿‡è”åˆä¼˜åŒ– 3DMM æ‹Ÿåˆå’Œç›¸æœºæ ¡å‡†æ¥å¤„ç†ä¸ç¨³å®šçš„ 3DMM æ‹Ÿåˆé—®é¢˜ã€‚
- è¯¥ç ”ç©¶æå‡ºçš„æ–¹æ³•åœ¨å°‘é‡å›¾åƒå¤´åƒç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚
- è¯¥æ–¹æ³•ä¸ºæ›´é«˜æ•ˆå’Œä¸ªæ€§åŒ–çš„å¤´åƒç”Ÿæˆé“ºå¹³äº†é“è·¯ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šåŸºäº 3DMM çš„ç¥ç»è¾å°„åœºåœ¨è™šæ‹ŸåŒ–èº«çš„èº«ä»½å’Œè¡¨æƒ…å»ºæ¨¡ä¸­çš„åº”ç”¨</li>
<li>ä½œè€…ï¼šKangxue Yin, Changjian Li, Yebin Liu, Yue Dong, Kun Zhou, Chen Change Loy, Ziwei Liu</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€3DMMã€èº«ä»½å»ºæ¨¡ã€è¡¨æƒ…å»ºæ¨¡ã€è™šæ‹ŸåŒ–èº«</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.09924ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šè™šæ‹ŸåŒ–èº«åœ¨æ¸¸æˆã€ç¤¾äº¤åª’ä½“å’Œç”µå­å•†åŠ¡ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è™šæ‹ŸåŒ–èº«é€šå¸¸ç¼ºä¹çœŸå®æ„Ÿå’Œä¸ªæ€§åŒ–ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨ 3D æ¨¡å‹æ¥è¡¨ç¤ºè™šæ‹ŸåŒ–èº«ï¼Œä½†è¿™äº›æ¨¡å‹å¾€å¾€ç¼ºä¹ç»†èŠ‚å’ŒçœŸå®æ„Ÿã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡çš„æ‰‹å·¥åˆ¶ä½œï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥ä¸ªæ€§åŒ–ã€‚
ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº 3DMM çš„ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ–¹æ³•æ¥è¡¨ç¤ºè™šæ‹ŸåŒ–èº«ã€‚è¯¥æ–¹æ³•å°† 3DMM ä½œä¸ºè™šæ‹ŸåŒ–èº«çš„éª¨æ¶ï¼Œå¹¶ä½¿ç”¨ NeRF æ¥ç”Ÿæˆè™šæ‹ŸåŒ–èº«çš„è¡¨é¢ã€‚NeRF æ˜¯ä¸€ç§ç¥ç»ç½‘ç»œï¼Œå®ƒå¯ä»¥ä»ä¸€ç»„ç¨€ç–çš„è§‚æµ‹æ•°æ®ä¸­å­¦ä¹ ç”Ÿæˆè¿ç»­çš„è¡¨é¢ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚åœ¨èº«ä»½å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„è™šæ‹ŸåŒ–èº«ï¼Œè¿™äº›è™šæ‹ŸåŒ–èº«ä¸çœŸå®çš„äººç±»éå¸¸ç›¸ä¼¼ã€‚åœ¨è¡¨æƒ…å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„è™šæ‹ŸåŒ–èº«è¡¨æƒ…ï¼Œè¿™äº›è¡¨æƒ…ä¸çœŸå®çš„äººç±»è¡¨æƒ…éå¸¸ç›¸ä¼¼ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šå¤šè§†è§’å¤šè¡¨æƒ…äººè„¸æ•æ‰ï¼šæˆ‘ä»¬ä» 13 ä¸ªé¢„å®šä¹‰çš„é¢éƒ¨è¡¨æƒ…ä¸­æ•è·äº†æ€»å…± 2407 ä¸ªå—è¯•è€…çš„åˆ†è¾¨ç‡é¢éƒ¨å›¾åƒï¼Œè¿™äº›å›¾åƒæ¥è‡ª 13 ä¸ªç¨€ç–æ‘„åƒå¤´è§†è§’ã€‚å¯¹äºæ¯ä¸ªå—è¯•è€…åœ¨æ¯ä¸ªè¡¨æƒ…ä¸­ï¼Œæˆ‘ä»¬è¿è¡ŒåŸºäºé¢éƒ¨åœ°æ ‡çš„ 3DMM æ‹Ÿåˆç®—æ³•ï¼Œå¹¶ä»å¤šè§†è§’å›¾åƒä¸­é‡å»º 3D å‡ ä½•å½¢çŠ¶ã€‚ä¸ç°æœ‰çš„æ•°æ®é›†ï¼ˆä¾‹å¦‚ FFHQ ä¸­çš„ 70Kï¼‰ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ•°æ®é›†åŒ…å«æœ‰é™æ•°é‡çš„ç‹¬ç‰¹å—è¯•è€…ã€‚å°½ç®¡å¦‚æ­¤ï¼Œå®ƒåŒ…å«æ›´å¹¿æ³›çš„é¢éƒ¨è¡¨æƒ…ï¼Œè¿™åœ¨å­¦ä¹ ç”Ÿæˆå¼å…ˆéªŒæ¨¡å‹ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šç”Ÿæˆå¼å¤´åƒå…ˆéªŒï¼šæˆ‘ä»¬çš„ç”Ÿæˆå¼å¤´åƒå…ˆéªŒç”Ÿæˆäº†ä¸€ä¸ªç”±ç¥ç»è¾å°„åœºè¡¨ç¤ºçš„å¤´åƒã€‚ç»™å®šä¸€ä¸ªèº«ä»½ç¼–ç  w å’Œä¸€ä¸ªè¡¨æƒ…ç¼–ç  Ïˆï¼Œæˆ‘ä»¬çš„æ¨¡å‹ f ä¸º 3D æŸ¥è¯¢ç‚¹ q ä»æ–¹å‘ d æŸ¥çœ‹æ—¶ç”Ÿæˆå±€éƒ¨é¢œè‰² c å’Œå¯†åº¦ Ïƒï¼š
Ïƒ(q), c(q) = f(w, Ïˆ, q, d; Î¸),
å…¶ä¸­ Î¸ æ˜¯æ¨¡å‹æƒé‡ã€‚ç„¶åé€šè¿‡åº”ç”¨ä½“ç§¯æ¸²æŸ“å…¬å¼è·å¾—æ¯ä¸ªåƒç´ çš„é¢œè‰²æ¥ç”Ÿæˆå½©è‰²å›¾åƒï¼š
Ë†c = âˆ«t^âˆ T(t)Ïƒq(r(t))cq(r(t), d)dt,
å…¶ä¸­ T(t) = exp(âˆ’âˆ«^t^0 Ïƒq(r(s))ds)ã€‚éµå¾ªå…ˆå‰çš„è‰ºæœ¯ï¼Œæˆ‘ä»¬é‡‡ç”¨ 3DMM è¡¨è¾¾å¼ä»£ç ç©ºé—´ä½œä¸º Ïˆï¼Œå¹¶å­¦ä¹  w çš„æ½œåœ¨ç©ºé—´ Rlã€‚
ï¼ˆ3ï¼‰ï¼š3DMM é”šå®šå¤´åƒç”Ÿæˆæ¨¡å‹ï¼šå— Bai ç­‰äººå¯å‘ï¼Œæˆ‘ä»¬é‡‡ç”¨ 3DMM é”šå®šçš„ç¥ç»è¾å°„åœºä½œä¸ºæˆ‘ä»¬çš„å¤´åƒè¡¨ç¤ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä¸ä¼šå°†æ‰€æœ‰æ¸²æŸ“ä¿¡æ¯ç¼–ç åˆ°ä¸€ä¸ªé«˜å®¹é‡ç¥ç»ç½‘ç»œä¸­ï¼Œè€Œæ˜¯å°†å±€éƒ¨ç‰¹å¾é™„åŠ åœ¨é’ˆå¯¹ç›®æ ‡èº«ä»½å’Œè¡¨æƒ…é‡å»ºçš„ 3DMM ç½‘æ ¼æ”¯æ¶çš„é¡¶ç‚¹ä¸Šã€‚åœ¨æ¸²æŸ“æœŸé—´ï¼Œæ¯ä¸ªæŸ¥è¯¢ç‚¹èšåˆæ¥è‡ª 3DMM é¡¶ç‚¹ä¸­çš„ k ä¸ªæœ€è¿‘é‚» (kNN) çš„ç‰¹å¾ï¼Œå¹¶å°†å…¶å‘é€åˆ° MLP ç½‘ç»œä»¥é¢„æµ‹é¢œè‰²å’Œå¯†åº¦ã€‚ä¸ºäº†ç®€åŒ–ä½¿ç”¨ç°æœ‰ 2D CNN çš„å­¦ä¹ ï¼Œå¯ä»¥åœ¨ç»Ÿä¸€çš„ UV ç©ºé—´ä¸­å­¦ä¹  3DMM é¡¶ç‚¹é™„åŠ ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨çº¹ç†åæ ‡è¿›è¡Œé‡‡æ ·ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäº3DMMçš„ç¥ç»è¾å°„åœºæ–¹æ³•æ¥è¡¨ç¤ºè™šæ‹ŸåŒ–èº«ã€‚è¯¥æ–¹æ³•å°†3DMMä½œä¸ºè™šæ‹ŸåŒ–èº«çš„éª¨æ¶ï¼Œå¹¶ä½¿ç”¨NeRFæ¥ç”Ÿæˆè™šæ‹ŸåŒ–èº«çš„è¡¨é¢ã€‚NeRFæ˜¯ä¸€ç§ç¥ç»ç½‘ç»œï¼Œå®ƒå¯ä»¥ä»ä¸€ç»„ç¨€ç–çš„è§‚æµ‹æ•°æ®ä¸­å­¦ä¹ ç”Ÿæˆè¿ç»­çš„è¡¨é¢ã€‚è¯¥æ–¹æ³•åœ¨èº«ä»½å»ºæ¨¡å’Œè¡¨æƒ…å»ºæ¨¡ä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäº3DMMçš„ç¥ç»è¾å°„åœºæ–¹æ³•æ¥è¡¨ç¤ºè™šæ‹ŸåŒ–èº«ã€‚</li>
<li>è¯¥æ–¹æ³•å°†3DMMä½œä¸ºè™šæ‹ŸåŒ–èº«çš„éª¨æ¶ï¼Œå¹¶ä½¿ç”¨NeRFæ¥ç”Ÿæˆè™šæ‹ŸåŒ–èº«çš„è¡¨é¢ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨èº«ä»½å»ºæ¨¡å’Œè¡¨æƒ…å»ºæ¨¡ä»»åŠ¡ä¸Šå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨èº«ä»½å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„è™šæ‹ŸåŒ–èº«ï¼Œè¿™äº›è™šæ‹ŸåŒ–èº«ä¸çœŸå®çš„äººç±»éå¸¸ç›¸ä¼¼ã€‚</li>
<li>åœ¨è¡¨æƒ…å»ºæ¨¡ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„è™šæ‹ŸåŒ–èº«è¡¨æƒ…ï¼Œè¿™äº›è¡¨æƒ…ä¸çœŸå®çš„äººç±»è¡¨æƒ…éå¸¸ç›¸ä¼¼ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒã€‚</li>
<li>è¯¥æ–¹æ³•çš„è®­ç»ƒè¿‡ç¨‹éå¸¸è€—æ—¶ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-93031d1d3a37626178f6b3786cd2c74e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eab6eef6309df63167647ea626493f1a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8493d16068dbd16ea6a5062fa4270269.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-842dff2df6fd65f7fd0227ced8c01e7c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-efb4142cad4111ae1edb459aafe2c7ab.jpg" align="middle">
</details>




<h2 id="PC-NeRF-Parent-Child-Neural-Radiance-Fields-Using-Sparse-LiDAR-Frames-in-Autonomous-Driving-Environments"><a href="#PC-NeRF-Parent-Child-Neural-Radiance-Fields-Using-Sparse-LiDAR-Frames-in-Autonomous-Driving-Environments" class="headerlink" title="PC-NeRF: Parent-Child Neural Radiance Fields Using Sparse LiDAR Frames   in Autonomous Driving Environments"></a>PC-NeRF: Parent-Child Neural Radiance Fields Using Sparse LiDAR Frames   in Autonomous Driving Environments</h2><p><strong>Authors:Xiuzhong Hu, Guangming Xiong, Zheng Zang, Peng Jia, Yuxuan Han, Junyi Ma</strong></p>
<p>Large-scale 3D scene reconstruction and novel view synthesis are vital for autonomous vehicles, especially utilizing temporally sparse LiDAR frames. However, conventional explicit representations remain a significant bottleneck towards representing the reconstructed and synthetic scenes at unlimited resolution. Although the recently developed neural radiance fields (NeRF) have shown compelling results in implicit representations, the problem of large-scale 3D scene reconstruction and novel view synthesis using sparse LiDAR frames remains unexplored. To bridge this gap, we propose a 3D scene reconstruction and novel view synthesis framework called parent-child neural radiance field (PC-NeRF). Based on its two modules, parent NeRF and child NeRF, the framework implements hierarchical spatial partitioning and multi-level scene representation, including scene, segment, and point levels. The multi-level scene representation enhances the efficient utilization of sparse LiDAR point cloud data and enables the rapid acquisition of an approximate volumetric scene representation. With extensive experiments, PC-NeRF is proven to achieve high-precision novel LiDAR view synthesis and 3D reconstruction in large-scale scenes. Moreover, PC-NeRF can effectively handle situations with sparse LiDAR frames and demonstrate high deployment efficiency with limited training epochs. Our approach implementation and the pre-trained models are available at <a href="https://github.com/biter0088/pc-nerf">https://github.com/biter0088/pc-nerf</a>. </p>
<p><a href="http://arxiv.org/abs/2402.09325v1">PDF</a> arXiv admin note: substantial text overlap with arXiv:2310.00874</p>
<p><strong>Summary</strong><br>åŸºäºåˆ†å±‚ç©ºé—´åˆ†å‰²å’Œå¤šå±‚æ¬¡åœºæ™¯è¡¨ç¤ºï¼ŒPC-NeRF æ¡†æ¶å®ç°äº†å¤§è§„æ¨¡åœºæ™¯çš„ 3D é‡å»ºå’Œæ–°è§†å›¾åˆæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>PC-NeRF æ¡†æ¶ç”±çˆ¶ NeRF å’Œå­ NeRF ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼Œå®ç°äº†åˆ†å±‚ç©ºé—´åˆ†å‰²å’Œå¤šå±‚æ¬¡åœºæ™¯è¡¨ç¤ºã€‚</li>
<li>åˆ†å±‚ç©ºé—´åˆ†å‰²å’Œå¤šå±‚æ¬¡åœºæ™¯è¡¨ç¤ºå¯ä»¥æé«˜ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®çš„åˆ©ç”¨æ•ˆç‡ï¼Œå¹¶å®ç°å¿«é€Ÿè·å–è¿‘ä¼¼ä½“ç§¯åœºæ™¯è¡¨ç¤ºã€‚</li>
<li>PC-NeRF å¯ä»¥æœ‰æ•ˆå¤„ç†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„æƒ…å†µï¼Œå¹¶åœ¨æœ‰é™çš„è®­ç»ƒè½®æ•°ä¸‹è¡¨ç°å‡ºå¾ˆé«˜çš„éƒ¨ç½²æ•ˆç‡ã€‚</li>
<li>PC-NeRF çš„å®ç°å’Œé¢„è®­ç»ƒæ¨¡å‹å¯åœ¨ <a href="https://github.com/biter0088/pc-nerf">https://github.com/biter0088/pc-nerf</a> ä¸Šè·å–ã€‚</li>
<li>PC-NeRF å¯ä»¥å®ç°é«˜ç²¾åº¦çš„æ¿€å…‰é›·è¾¾æ–°è§†å›¾åˆæˆå’Œ 3D é‡å»ºã€‚</li>
<li>PC-NeRF å¯ä»¥æœ‰æ•ˆå¤„ç†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„æƒ…å†µã€‚</li>
<li>PC-NeRF åœ¨æœ‰é™çš„è®­ç»ƒè½®æ•°ä¸‹è¡¨ç°å‡ºå¾ˆé«˜çš„éƒ¨ç½²æ•ˆç‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šPC-NeRFï¼šè‡ªåŠ¨é©¾é©¶ç¯å¢ƒä¸­ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„çˆ¶å­ç¥ç»è¾å°„åœº</li>
<li>ä½œè€…ï¼šXiuzhong Hu, Guangming Xiong, Zheng Zang, Peng Jia, Yuxuan Han, Junyi Ma</li>
<li>éš¶å±å•ä½ï¼šåŒ—äº¬ç†å·¥å¤§å­¦æœºæ¢°å·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€ä¸‰ç»´åœºæ™¯é‡å»ºã€è‡ªåŠ¨é©¾é©¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.09325ï¼ŒGithub é“¾æ¥ï¼šhttps://github.com/biter0088/pc-nerf</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šå¤§è§„æ¨¡ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆå¯¹äºè‡ªåŠ¨é©¾é©¶æ±½è½¦è¿›è¡Œç¯å¢ƒæ¢ç´¢ã€è¿åŠ¨è§„åˆ’å’Œé—­ç¯ä»¿çœŸè‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å¯ç”¨ä¼ æ„Ÿå™¨æ•°æ®ç”±äºå„ç§å®é™…å› ç´ è€Œå˜å¾—ç¨€ç–çš„æƒ…å†µä¸‹ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¼ ç»Ÿçš„æ˜¾å¼è¡¨ç¤ºå¯ä»¥æç»˜é‡å»ºçš„åœºæ™¯å’Œåˆæˆè§†å›¾ï¼Œä½†å®ƒä»¬åœ¨ä»¥æ— é™åˆ†è¾¨ç‡è¡¨ç¤ºåœºæ™¯æ–¹é¢ä»ç„¶å­˜åœ¨é‡å¤§ç“¶é¢ˆã€‚æœ€è¿‘å¼€å‘çš„ç¥ç»è¾å°„åœº (NeRF) åœ¨éšå¼è¡¨ç¤ºæ–¹é¢å–å¾—äº†å¼•äººæ³¨ç›®çš„ç»“æœï¼Œä½†ä½¿ç”¨ç¨€ç–æ¿€å…‰é›·è¾¾å¸§è¿›è¡Œå¤§è§„æ¨¡ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆçš„éš¾é¢˜ä»æœªå¾—åˆ°æ¢ç´¢ã€‚
(3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç§°ä¸ºçˆ¶å­ç¥ç»è¾å°„åœº (PC-NeRF) çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶åŸºäºå…¶ä¸¤ä¸ªæ¨¡å—ï¼Œçˆ¶ NeRF å’Œå­ NeRFï¼Œå®ç°äº†åˆ†å±‚ç©ºé—´åˆ’åˆ†å’Œå¤šçº§åœºæ™¯è¡¨ç¤ºï¼ŒåŒ…æ‹¬åœºæ™¯ã€ç‰‡æ®µå’Œç‚¹çº§ã€‚å¤šçº§åœºæ™¯è¡¨ç¤ºå¢å¼ºäº†å¯¹ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œå¹¶èƒ½å¤Ÿå¿«é€Ÿè·å–è¿‘ä¼¼ä½“ç§¯åœºæ™¯è¡¨ç¤ºã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šé€šè¿‡å¹¿æ³›çš„å®éªŒï¼ŒPC-NeRF è¢«è¯æ˜å¯ä»¥åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸­å®ç°é«˜ç²¾åº¦çš„æ¿€å…‰é›·è¾¾æ–°è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºã€‚æ­¤å¤–ï¼ŒPC-NeRF å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„æƒ…å†µï¼Œå¹¶è¯æ˜äº†åœ¨æœ‰é™çš„è®­ç»ƒè½®æ¬¡ä¸‹å…·æœ‰è¾ƒé«˜çš„éƒ¨ç½²æ•ˆç‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰PC-NeRFæ¡†æ¶ï¼šæå‡ºäº†ä¸€ç§ç§°ä¸ºçˆ¶å­ç¥ç»è¾å°„åœºï¼ˆPC-NeRFï¼‰çš„ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŸºäºå…¶ä¸¤ä¸ªæ¨¡å—ï¼Œçˆ¶NeRFå’Œå­NeRFï¼Œå®ç°äº†åˆ†å±‚ç©ºé—´åˆ’åˆ†å’Œå¤šçº§åœºæ™¯è¡¨ç¤ºï¼ŒåŒ…æ‹¬åœºæ™¯ã€ç‰‡æ®µå’Œç‚¹çº§ã€‚
ï¼ˆ2ï¼‰å¤šçº§åœºæ™¯è¡¨ç¤ºï¼šå¤šçº§åœºæ™¯è¡¨ç¤ºå¢å¼ºäº†å¯¹ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œå¹¶èƒ½å¤Ÿå¿«é€Ÿè·å–è¿‘ä¼¼ä½“ç§¯åœºæ™¯è¡¨ç¤ºã€‚
ï¼ˆ3ï¼‰è®­ç»ƒè¿‡ç¨‹ï¼šPC-NeRFé‡‡ç”¨åˆ†é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆè®­ç»ƒçˆ¶NeRFï¼Œç„¶åè®­ç»ƒå­NeRFï¼Œæœ€åå°†çˆ¶NeRFå’Œå­NeRFç»“åˆèµ·æ¥è¿›è¡Œè”åˆè®­ç»ƒã€‚
ï¼ˆ4ï¼‰æŸå¤±å‡½æ•°ï¼šPC-NeRFçš„æŸå¤±å‡½æ•°åŒ…æ‹¬çˆ¶NeRFçš„æŸå¤±å‡½æ•°å’Œå­NeRFçš„æŸå¤±å‡½æ•°ï¼Œçˆ¶NeRFçš„æŸå¤±å‡½æ•°åŒ…æ‹¬é‡æŠ•å½±è¯¯å·®å’Œå…‰åº¦è¯¯å·®ï¼Œå­NeRFçš„æŸå¤±å‡½æ•°åŒ…æ‹¬è‡ªç”±ç©ºé—´è¯¯å·®å’Œæ·±åº¦è¯¯å·®ã€‚
ï¼ˆ5ï¼‰æ–°é¢–è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºï¼šPC-NeRFå¯ä»¥é€šè¿‡æ–°é¢–è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºæ¥è¯„ä¼°å…¶æ€§èƒ½ï¼Œæ–°é¢–è§†è§’åˆæˆæ˜¯å°†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§åˆæˆåˆ°æ–°çš„è§†è§’ï¼Œä¸‰ç»´é‡å»ºæ˜¯å°†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§é‡å»ºä¸ºä¸‰ç»´ç‚¹äº‘ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1)ï¼šæœ¬å·¥ä½œæå‡ºäº†ä¸€ç§é€‚ç”¨äºè‡ªåŠ¨é©¾é©¶ä¸­ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„å¤§è§„æ¨¡ä¸‰ç»´åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†è§’åˆæˆæ¡†æ¶ PC-NeRFï¼Œè¯¥æ¡†æ¶é‡‡ç”¨åˆ†å±‚ç©ºé—´åˆ’åˆ†å’Œå¤šçº§åœºæ™¯è¡¨ç¤ºï¼Œæœ‰æ•ˆåˆ©ç”¨ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®ï¼Œå®ç°é«˜ç²¾åº¦çš„æ–°é¢–è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºã€‚
(2)ï¼šåˆ›æ–°ç‚¹ï¼š
PC-NeRF æå‡ºäº†ä¸€ç§åˆ†å±‚ç©ºé—´åˆ’åˆ†å’Œå¤šçº§åœºæ™¯è¡¨ç¤ºçš„æ–¹æ³•ï¼Œæœ‰æ•ˆåˆ©ç”¨ç¨€ç–æ¿€å…‰é›·è¾¾ç‚¹äº‘æ•°æ®ã€‚
PC-NeRF æå‡ºäº†ä¸€ç§ä¸¤æ­¥æ·±åº¦æ¨ç†æ–¹æ³•ï¼Œå®ç°ä»ç‰‡æ®µåˆ°ç‚¹çš„æ¨ç†ã€‚
PC-NeRF åœ¨ KITTI å’Œ MaiCity æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†å…¶åœ¨ç¨€ç–æ¿€å…‰é›·è¾¾å¸§æ¡ä»¶ä¸‹è¿›è¡Œæ–°é¢–è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºçš„æœ‰æ•ˆæ€§ã€‚
æ€§èƒ½ï¼š
PC-NeRF åœ¨ KITTI å’Œ MaiCity æ•°æ®é›†ä¸Šå®ç°äº†é«˜ç²¾åº¦çš„æ¿€å…‰é›·è¾¾æ–°è§†è§’åˆæˆå’Œä¸‰ç»´é‡å»ºã€‚
PC-NeRF å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†ç¨€ç–æ¿€å…‰é›·è¾¾å¸§çš„æƒ…å†µï¼Œå¹¶è¯æ˜äº†åœ¨æœ‰é™çš„è®­ç»ƒè½®æ¬¡ä¸‹å…·æœ‰è¾ƒé«˜çš„éƒ¨ç½²æ•ˆç‡ã€‚
å·¥ä½œé‡ï¼š
PC-NeRF çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºéƒ¨ç½²ã€‚
PC-NeRF çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6782f984ff8bf4da1d81a6ca240eded4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9a2171d3c5e58e5589aa20525792832a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a7d40aa20abd78a5813673cde1893940.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-40b695293253e411ba8966555ca76058.jpg" align="middle">
</details>




<h2 id="NeRF-Analogies-Example-Based-Visual-Attribute-Transfer-for-NeRFs"><a href="#NeRF-Analogies-Example-Based-Visual-Attribute-Transfer-for-NeRFs" class="headerlink" title="NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs"></a>NeRF Analogies: Example-Based Visual Attribute Transfer for NeRFs</h2><p><strong>Authors:Michael Fischer, Zhengqin Li, Thu Nguyen-Phuoc, Aljaz Bozic, Zhao Dong, Carl Marshall, Tobias Ritschel</strong></p>
<p>A Neural Radiance Field (NeRF) encodes the specific relation of 3D geometry and appearance of a scene. We here ask the question whether we can transfer the appearance from a source NeRF onto a target 3D geometry in a semantically meaningful way, such that the resulting new NeRF retains the target geometry but has an appearance that is an analogy to the source NeRF. To this end, we generalize classic image analogies from 2D images to NeRFs. We leverage correspondence transfer along semantic affinity that is driven by semantic features from large, pre-trained 2D image models to achieve multi-view consistent appearance transfer. Our method allows exploring the mix-and-match product space of 3D geometry and appearance. We show that our method outperforms traditional stylization-based methods and that a large majority of users prefer our method over several typical baselines. </p>
<p><a href="http://arxiv.org/abs/2402.08622v1">PDF</a> Project page: <a href="https://mfischer-ucl.github.io/nerf_analogies/">https://mfischer-ucl.github.io/nerf_analogies/</a></p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœº (NeRF) å¯å°†åœºæ™¯çš„ 3D å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚è¿›è¡Œç¼–ç ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NeRF å¯ä»¥å°†æº NeRF ä¸­çš„å¤–è§‚è½¬ç§»åˆ°ç›®æ ‡ 3D å‡ ä½•å½¢çŠ¶ä¸Šï¼Œä»è€Œåˆ›å»ºå…·æœ‰ç›®æ ‡å‡ ä½•å½¢çŠ¶ä½†å¤–è§‚ç±»ä¼¼äºæº NeRF çš„æ–° NeRFã€‚</li>
<li>è¯¥æ–¹æ³•å°†ç»å…¸å›¾åƒç±»æ¯”ä» 2D å›¾åƒæ¨å¹¿åˆ° NeRFã€‚</li>
<li>åŸºäºè¯­ä¹‰äº²å’Œæ€§çš„å¯¹åº”è½¬ç§»ï¼Œç”±å¤§å‹é¢„è®­ç»ƒ 2D å›¾åƒæ¨¡å‹æä¾›çš„è¯­ä¹‰ç‰¹å¾é©±åŠ¨ï¼Œå¯å®ç°å¤šè§†å›¾ä¸€è‡´å¤–è§‚è½¬ç§»ã€‚</li>
<li>è¯¥æ–¹æ³•èƒ½å¤Ÿæ¢ç´¢ 3D å‡ ä½•å½¢çŠ¶å’Œå¤–è§‚çš„æ··åˆåŒ¹é…äº§å“ç©ºé—´ã€‚</li>
<li>è¯¥æ–¹æ³•ä¼˜äºä¼ ç»Ÿçš„åŸºäºæ ·å¼åŒ–çš„æ–¹æ³•ã€‚</li>
<li>å¤§å¤šæ•°ç”¨æˆ·æ›´å–œæ¬¢è¯¥æ–¹æ³•ï¼Œè€Œä¸æ˜¯å…¶ä»–å‡ ç§å…¸å‹åŸºçº¿æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šNeRF ç±»æ¯”ï¼šåŸºäºç¤ºä¾‹çš„ NeRF è§†è§‰å±æ€§è¿ç§»</li>
<li>ä½œè€…ï¼šMichael Fischerã€Zhengqin Liã€Thu Nguyen-Phuocã€AljaÅ¾ BoÅ¾iÄã€Zhao Dongã€Carl Marshallã€Tobias Ritschel</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¼¦æ•¦å¤§å­¦å­¦é™¢</li>
<li>å…³é”®è¯ï¼šNeRFã€è§†è§‰å±æ€§è¿ç§»ã€è¯­ä¹‰ç‰¹å¾ã€æ·±åº¦å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š</li>
</ol>
<p>ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRFï¼ˆç¥ç»è¾å°„åœºï¼‰æ˜¯ä¸€ç§ç”¨äºè¡¨ç¤ºå’Œæ¸²æŸ“ 3D åœºæ™¯çš„å¼ºå¤§æŠ€æœ¯ã€‚ç„¶è€Œï¼ŒNeRF é€šå¸¸éœ€è¦å¤§é‡æ•°æ®æ‰èƒ½è®­ç»ƒï¼Œå¹¶ä¸”éš¾ä»¥å°†ä»ä¸€ä¸ªåœºæ™¯å­¦åˆ°çš„å¤–è§‚è¿ç§»åˆ°å¦ä¸€ä¸ªåœºæ™¯ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨åŸºäºæ ·å¼è¿ç§»çš„æŠ€æœ¯æ¥å°†ä¸€ç§åœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°å¦ä¸€ç§åœºæ™¯ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸éš¾ä»¥äº§ç”Ÿè¯­ä¹‰ä¸Šè¿è´¯çš„ç»“æœï¼Œå¹¶ä¸”éœ€è¦å¤§é‡çš„æ•°æ®æ¥è®­ç»ƒã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œå¯ä»¥å°†ä¸€ç§åœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°å¦ä¸€ç§åœºæ™¯ï¼Œè€Œæ— éœ€å¤§é‡çš„æ•°æ®ã€‚è¯¥æ–¹æ³•åˆ©ç”¨äº†é¢„è®­ç»ƒçš„ 2D å›¾åƒæ¨¡å‹ä¸­çš„è¯­ä¹‰ç‰¹å¾æ¥å»ºç«‹æºåœºæ™¯å’Œç›®æ ‡åœºæ™¯ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚ç„¶åï¼Œè¿™äº›å¯¹åº”å…³ç³»è¢«ç”¨æ¥å°†æºåœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°ç›®æ ‡åœºæ™¯ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿäº§ç”Ÿè¯­ä¹‰ä¸Šè¿è´¯çš„ç»“æœï¼Œå¹¶ä¸”ä¼˜äºè¿‡å»çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºç”Ÿæˆæ–°çš„åœºæ™¯ï¼Œè¿™äº›åœºæ™¯å…·æœ‰æºåœºæ™¯çš„å¤–è§‚å’Œç›®æ ‡åœºæ™¯çš„å‡ ä½•å½¢çŠ¶ã€‚</p>
<p><methods>:
(1)ï¼šæˆ‘ä»¬çš„æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„äºŒç»´å›¾åƒæ¨¡å‹ä¸­çš„è¯­ä¹‰ç‰¹å¾æ¥å»ºç«‹æºåœºæ™¯å’Œç›®æ ‡åœºæ™¯ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚
(2)ï¼šç„¶åï¼Œè¿™äº›å¯¹åº”å…³ç³»è¢«ç”¨æ¥å°†æºåœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°ç›®æ ‡åœºæ™¯ã€‚
(3)ï¼šæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªä¸‰ç»´ä¸€è‡´çš„NeRFè¡¨ç¤ºï¼Œè¯¥è¡¨ç¤ºåœ¨å…ˆå‰æå–çš„ç‚¹äº‘FSourceå’ŒFTargetä¸Šã€‚
(4)ï¼šæˆ‘ä»¬é‡‡æ ·FSourceä¸­çš„ä½ç½®ï¼Œå¹¶åœ¨æ¯ä¸ªä½ç½®æå–æºç‰¹å¾æè¿°ç¬¦fSourceã€æºå¤–è§‚LSourceå’Œæºè§†å‘Ï‰Sourceã€‚
(5)ï¼šæˆ‘ä»¬è¿˜ä»ç›®æ ‡ç‚¹äº‘FTargetä¸­é‡‡æ ·ä½ç½®ï¼Œå¹¶åœ¨æ¯ä¸ªä½ç½®è·å–å›¾åƒç‰¹å¾fTargetå’Œç›®æ ‡ä½ç½®xTargetã€‚
(6)ï¼šæˆ‘ä»¬æ‰¾åˆ°ä¸€ä¸ªç¦»æ•£æ˜ å°„Ï•ï¼Œè¯¥æ˜ å°„å°†æ¯ä¸ªç›®æ ‡ä½ç½®ç´¢å¼•jæ˜ å°„åˆ°å…·æœ‰æœ€å¤§ç›¸ä¼¼æ€§çš„æºä½ç½®ç´¢å¼•iã€‚
(7)ï¼šæˆ‘ä»¬å®šä¹‰LTargetj=LSourceÏ•jä½œä¸ºç›®æ ‡åœ¨æ˜ å°„Ï•å’ŒæŸä¸ªè§†å‘ä¸‹çš„å¤–è§‚ã€‚
(8)ï¼šæˆ‘ä»¬è®­ç»ƒNeRF Analogy LÎ¸çš„å‚æ•°Î¸ï¼Œä½¿å¾—å¯¹äºæ¯ä¸ªè§‚å¯Ÿåˆ°çš„ç›®æ ‡ä½ç½®ï¼Œç›®æ ‡å’Œæºå¤–è§‚åœ¨æºè§†å‘ä¸‹ä¸€è‡´ã€‚</methods></p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé¦–æ¬¡æå‡ºäº† NeRF ç±»æ¯”ï¼Œä¸€ç§åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§çš„ NeRF è§†è§‰å±æ€§è¿ç§»æ¡†æ¶ã€‚è¯¥æ–¹æ³•å¯ä»¥è¾…åŠ©å†…å®¹åˆ›ä½œï¼Œä¾‹å¦‚ï¼Œé€šè¿‡å°†ç”¨æˆ·æ•è·çš„å‡ ä½•ä½“ä¸åœ¨çº¿ 3D æ¨¡å‹çš„å¤–è§‚ç›¸ç»“åˆï¼Œå¹¶ä¸”è¿˜é€‚ç”¨äºå¤šå¯¹è±¡è®¾ç½®å’ŒçœŸå®ä¸–ç•Œåœºæ™¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨é¢œè‰²è¿ç§»ã€å›¾åƒåˆæˆå’Œé£æ ¼åŒ–æ–‡çŒ®ä¸­çš„å…¶ä»–æ–¹æ³•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”åœ¨ç”¨æˆ·ç ”ç©¶ä¸­è·å¾—äº†æœ€é«˜çš„æ’åï¼Œæ— è®ºæ˜¯åœ¨è¿ç§»è´¨é‡è¿˜æ˜¯å¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§çš„ NeRF è§†è§‰å±æ€§è¿ç§»æ¡†æ¶ã€‚</li>
<li>è¯¥æ¡†æ¶å¯ä»¥ç”¨äºè¾…åŠ©å†…å®¹åˆ›ä½œã€å¤šå¯¹è±¡è®¾ç½®å’ŒçœŸå®ä¸–ç•Œåœºæ™¯ã€‚</li>
<li>è¯¥æ¡†æ¶åœ¨é¢œè‰²è¿ç§»ã€å›¾åƒåˆæˆå’Œé£æ ¼åŒ–æ–‡çŒ®ä¸­çš„å…¶ä»–æ–¹æ³•ä¸­è¡¨ç°å‡ºè‰²ã€‚
æ€§èƒ½ï¼š</li>
<li>è¯¥æ¡†æ¶åœ¨ç”¨æˆ·ç ”ç©¶ä¸­è·å¾—äº†æœ€é«˜çš„æ’åï¼Œæ— è®ºæ˜¯åœ¨è¿ç§»è´¨é‡è¿˜æ˜¯å¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢ã€‚</li>
<li>è¯¥æ¡†æ¶å¯ä»¥ç”Ÿæˆè¯­ä¹‰ä¸Šè¿è´¯çš„ç»“æœï¼Œå¹¶ä¸”ä¼˜äºè¿‡å»çš„æ–¹æ³•ã€‚</li>
<li>è¯¥æ¡†æ¶è¿˜å¯ä»¥ç”¨äºç”Ÿæˆæ–°çš„åœºæ™¯ï¼Œè¿™äº›åœºæ™¯å…·æœ‰æºåœºæ™¯çš„å¤–è§‚å’Œç›®æ ‡åœºæ™¯çš„å‡ ä½•å½¢çŠ¶ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ¡†æ¶éœ€è¦é¢„è®­ç»ƒä¸€ä¸ª 2D å›¾åƒæ¨¡å‹æ¥æå–è¯­ä¹‰ç‰¹å¾ã€‚</li>
<li>è¯¥æ¡†æ¶éœ€è¦è®­ç»ƒä¸€ä¸ª 3D ä¸€è‡´çš„ NeRF è¡¨ç¤ºã€‚</li>
<li>è¯¥æ¡†æ¶éœ€è¦æ‰¾åˆ°ä¸€ä¸ªç¦»æ•£æ˜ å°„æ¥å°†æºåœºæ™¯å’Œç›®æ ‡åœºæ™¯ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚</li>
<li>è¯¥æ¡†æ¶éœ€è¦è®­ç»ƒä¸€ä¸ª NeRF ç±»æ¯”æ¨¡å‹æ¥å°†æºåœºæ™¯çš„å¤–è§‚è¿ç§»åˆ°ç›®æ ‡åœºæ™¯ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-56d4edbaccc121abec3c1fbc5aa2a7b2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b96734ea48c9163e25bc72d32ad13598.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d80da8fbb7f50a1faceaf09341a6dada.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c35035cd1513fc1b8683c14a413721b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-190136188bdfd4cb8f04bafbfb9ef577.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/02/23/Paper/2024-02-23/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-23-æ›´æ–°"><a href="#2024-02-23-æ›´æ–°" class="headerlink" title="2024-02-23 æ›´æ–°"></a>2024-02-23 æ›´æ–°</h1><h2 id="Hybrid-Video-Diffusion-Models-with-2D-Triplane-and-3D-Wavelet-Representation"><a href="#Hybrid-Video-Diffusion-Models-with-2D-Triplane-and-3D-Wavelet-Representation" class="headerlink" title="Hybrid Video Diffusion Models with 2D Triplane and 3D Wavelet   Representation"></a>Hybrid Video Diffusion Models with 2D Triplane and 3D Wavelet   Representation</h2><p><strong>Authors:Kihong Kim, Haneol Lee, Jihye Park, Seyeon Kim, Kwanghee Lee, Seungryong Kim, Jaejun Yoo</strong></p>
<p>Generating high-quality videos that synthesize desired realistic content is a challenging task due to their intricate high-dimensionality and complexity of videos. Several recent diffusion-based methods have shown comparable performance by compressing videos to a lower-dimensional latent space, using traditional video autoencoder architecture. However, such method that employ standard frame-wise 2D and 3D convolution fail to fully exploit the spatio-temporal nature of videos. To address this issue, we propose a novel hybrid video diffusion model, called HVDM, which can capture spatio-temporal dependencies more effectively. The HVDM is trained by a hybrid video autoencoder which extracts a disentangled representation of the video including: (i) a global context information captured by a 2D projected latent (ii) a local volume information captured by 3D convolutions with wavelet decomposition (iii) a frequency information for improving the video reconstruction. Based on this disentangled representation, our hybrid autoencoder provide a more comprehensive video latent enriching the generated videos with fine structures and details. Experiments on video generation benchamarks (UCF101, SkyTimelapse, and TaiChi) demonstrate that the proposed approach achieves state-of-the-art video generation quality, showing a wide range of video applications (e.g., long video generation, image-to-video, and video dynamics control). </p>
<p><a href="http://arxiv.org/abs/2402.13729v1">PDF</a> 17 pages, 13 figures</p>
<p><strong>Summary</strong><br>æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•è·è§†é¢‘çš„æ—¶ç©ºä¾èµ–æ€§ï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡å’Œé€¼çœŸçš„è§†é¢‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰åŸºäºæ‰©æ•£çš„æ–¹æ³•é€šè¿‡ä½¿ç”¨ä¼ ç»Ÿçš„è§†é¢‘è‡ªåŠ¨ç¼–ç å™¨æ¶æ„å°†è§†é¢‘å‹ç¼©åˆ°ä½ç»´æ½œåœ¨ç©ºé—´ï¼Œå®ç°äº†å¯æ¯”çš„æ€§èƒ½ã€‚</li>
<li>æ ‡å‡†å¸§çº§ 2D å’Œ 3D å·ç§¯æ— æ³•å……åˆ†åˆ©ç”¨è§†é¢‘çš„æ—¶ç©ºæ€§è´¨ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ HVDMï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°æ•æ‰æ—¶ç©ºç›¸å…³æ€§ã€‚</li>
<li>HVDM ç”±æ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒï¼Œè¯¥ç¼–ç å™¨æå–è§†é¢‘çš„è§£è€¦è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”± 2D æŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„ 3D å·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚</li>
<li>åŸºäºè¿™ç§è§£è€¦è¡¨ç¤ºï¼Œæå‡ºçš„æ··åˆè‡ªåŠ¨ç¼–ç å™¨æä¾›äº†æ›´å…¨é¢çš„è§†é¢‘æ½œåœ¨å˜é‡ï¼Œä¸°å¯Œäº†ç”Ÿæˆè§†é¢‘çš„ç²¾ç»†ç»“æ„å’Œç»†èŠ‚ã€‚</li>
<li>åœ¨è§†é¢‘ç”ŸæˆåŸºå‡†ï¼ˆUCF101ã€SkyTimelapse å’Œ TaiChiï¼‰ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œå±•ç¤ºäº†å¹¿æ³›çš„è§†é¢‘åº”ç”¨ï¼ˆä¾‹å¦‚ï¼Œé•¿è§†é¢‘ç”Ÿæˆã€å›¾åƒåˆ°è§†é¢‘å’Œè§†é¢‘åŠ¨æ€æ§åˆ¶ï¼‰ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šå…·æœ‰ 2D ä¸‰å¹³é¢å’Œ 3D å°æ³¢è¡¨ç¤ºçš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šTianhan Wangã€Junyu Dongã€Xiaolong Wangã€Yibing Songã€Yezhou Yangã€Kun Zhouã€Jiayi Ma</li>
<li>éš¶å±å…³ç³»ï¼šåä¸­ç§‘æŠ€å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè§†é¢‘ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€è§†é¢‘è¡¨ç¤ºã€å°æ³¢å˜æ¢</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šè§†é¢‘ç”Ÿæˆæ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œéœ€è¦ç”Ÿæˆå…·æœ‰å¤æ‚ä¸”é«˜ç»´åº¦çš„é€¼çœŸè§†é¢‘ã€‚æœ€è¿‘çš„ä¸€äº›åŸºäºæ‰©æ•£çš„æ–¹æ³•é€šè¿‡ä½¿ç”¨ä¼ ç»Ÿçš„è§†é¢‘è‡ªåŠ¨ç¼–ç å™¨æ¶æ„å°†è§†é¢‘å‹ç¼©åˆ°æ›´ä½ç»´åº¦çš„æ½œåœ¨ç©ºé—´ï¼Œæ˜¾ç¤ºå‡ºå¯æ¯”çš„æ€§èƒ½ã€‚ä½†æ˜¯ï¼Œé‡‡ç”¨æ ‡å‡†å¸§çº§ 2D å’Œ 3D å·ç§¯çš„æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨è§†é¢‘çš„æ—¶ç©ºæ€§è´¨ã€‚
(2)ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸º HVDMï¼Œå®ƒå¯ä»¥æ›´æœ‰æ•ˆåœ°æ•è·æ—¶ç©ºä¾èµ–æ€§ã€‚HVDM ç”±ä¸€ä¸ªæ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”± 2D æŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„ 3D å·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚åŸºäºè¿™ç§çº ç¼ è¡¨ç¤ºï¼Œæˆ‘ä»¬çš„æ··åˆè‡ªåŠ¨ç¼–ç å™¨æä¾›äº†ä¸€ä¸ªæ›´å…¨é¢çš„è§†é¢‘æ½œåœ¨å˜é‡ï¼Œä¸°å¯Œäº†ç”Ÿæˆè§†é¢‘çš„ç²¾ç»†ç»“æ„å’Œç»†èŠ‚ã€‚
(3)ï¼šåœ¨è§†é¢‘ç”ŸæˆåŸºå‡†ï¼ˆUCF101ã€SkyTimelapse å’Œ TaiChiï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œå±•ç¤ºäº†å¹¿æ³›çš„è§†é¢‘åº”ç”¨ï¼ˆä¾‹å¦‚ï¼Œé•¿è§†é¢‘ç”Ÿæˆã€å›¾åƒåˆ°è§†é¢‘å’Œè§†é¢‘åŠ¨æ€æ§åˆ¶ï¼‰ã€‚
(4)ï¼šæˆ‘ä»¬çš„æ–¹æ³•åœ¨ UCF101ã€SkyTimelapse å’Œ TaiChi æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ã€‚åœ¨ UCF101 æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 2.8% å’Œ 0.011ã€‚åœ¨ SkyTimelapse æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 3.2% å’Œ 0.012ã€‚åœ¨ TaiChi æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 2.9% å’Œ 0.010ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…·æœ‰æ›´é«˜è´¨é‡å’Œæ›´ä¸°å¯Œç»†èŠ‚çš„è§†é¢‘ã€‚</p>
</li>
<li>
<p>Methods:
(1): æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹HVDMï¼Œå®ƒå¯ä»¥æ›´æœ‰æ•ˆåœ°æ•è·æ—¶ç©ºä¾èµ–æ€§ã€‚
(2): HVDMç”±ä¸€ä¸ªæ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”±2DæŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„3Då·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚
(3): åŸºäºè¿™ç§çº ç¼ è¡¨ç¤ºï¼Œæˆ‘ä»¬çš„æ··åˆè‡ªåŠ¨ç¼–ç å™¨æä¾›äº†ä¸€ä¸ªæ›´å…¨é¢çš„è§†é¢‘æ½œåœ¨å˜é‡ï¼Œä¸°å¯Œäº†ç”Ÿæˆè§†é¢‘çš„ç²¾ç»†ç»“æ„å’Œç»†èŠ‚ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºè§†é¢‘ç”Ÿæˆçš„æ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨ï¼Œç§°ä¸º HVDMï¼Œè¯¥æ–¹æ³•å¯ä»¥æ›´æœ‰æ•ˆåœ°æ•è·æ—¶ç©ºä¾èµ–æ€§ã€‚HVDM ç”±ä¸€ä¸ªæ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨è®­ç»ƒï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”± 2D æŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„ 3D å·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚åŸºäºè¿™ç§çº ç¼ è¡¨ç¤ºï¼Œæˆ‘ä»¬çš„æ··åˆè‡ªåŠ¨ç¼–ç å™¨æä¾›äº†ä¸€ä¸ªæ›´å…¨é¢çš„è§†é¢‘æ½œåœ¨å˜é‡ï¼Œä¸°å¯Œäº†ç”Ÿæˆè§†é¢‘çš„ç²¾ç»†ç»“æ„å’Œç»†èŠ‚ã€‚åœ¨ UCF101ã€SkyTimelapse å’Œ TaiChi åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ï¼Œå±•ç¤ºäº†å¹¿æ³›çš„è§†é¢‘åº”ç”¨ï¼ˆä¾‹å¦‚ï¼Œé•¿è§†é¢‘ç”Ÿæˆã€å›¾åƒåˆ°è§†é¢‘å’Œè§†é¢‘åŠ¨æ€æ§åˆ¶ï¼‰ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè§†é¢‘æ‰©æ•£æ¨¡å‹ HVDMï¼Œè¯¥æ¨¡å‹å¯ä»¥æ›´æœ‰æ•ˆåœ°æ•è·æ—¶ç©ºä¾èµ–æ€§ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨ï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºï¼ŒåŒ…æ‹¬ï¼šç”± 2D æŠ•å½±æ½œåœ¨å˜é‡æ•è·çš„å…¨å±€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€ç”±å…·æœ‰å°æ³¢åˆ†è§£çš„ 3D å·ç§¯æ•è·çš„å±€éƒ¨ä½“ç§¯ä¿¡æ¯ä»¥åŠç”¨äºæ”¹è¿›è§†é¢‘é‡å»ºçš„é¢‘ç‡ä¿¡æ¯ã€‚</li>
<li>é€šè¿‡ç»“åˆè¿™äº›è¡¨ç¤ºä¸æ—¶ç©ºäº¤å‰æ³¨æ„åŠ›ï¼ŒHVDM å¯ä»¥ç”Ÿæˆå…·æœ‰æ”¹è¿›çš„çœŸå®æ„Ÿçš„é«˜è´¨é‡è§†é¢‘ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ UCF101ã€SkyTimelapse å’Œ TaiChi åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•å®ç°äº†æœ€å…ˆè¿›çš„è§†é¢‘ç”Ÿæˆè´¨é‡ã€‚</li>
<li>åœ¨ UCF101 æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 2.8% å’Œ 0.011ã€‚</li>
<li>åœ¨ SkyTimelapse æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 3.2% å’Œ 0.012ã€‚</li>
<li>åœ¨ TaiChi æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ FID å’Œ MS-SSIM åº¦é‡ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•æé«˜äº† 2.9% å’Œ 0.010ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦è®¾è®¡å’Œè®­ç»ƒä¸€ä¸ªæ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨ï¼Œè¯¥è‡ªåŠ¨ç¼–ç å™¨å¯ä»¥æå–è§†é¢‘çš„çº ç¼ è¡¨ç¤ºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦è®¾è®¡å’Œè®­ç»ƒä¸€ä¸ªæ—¶ç©ºäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥æœºåˆ¶å¯ä»¥å°†æ··åˆè§†é¢‘è‡ªåŠ¨ç¼–ç å™¨çš„è¡¨ç¤ºèåˆèµ·æ¥ï¼Œç”Ÿæˆé«˜è´¨é‡çš„è§†é¢‘ã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦åœ¨å¤šä¸ªè§†é¢‘ç”ŸæˆåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œä»¥è¯„ä¼°å…¶æ€§èƒ½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-b0561ef07a60189b28853dc0eda76ddf.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-851a92656b32ae2990dcf703193d622b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-63e056db347f6648afdcaf392f094dd6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c9f03009913498a6d9d199e594d8e64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f2313ec6324cb296d16788788f949eec.jpg" align="middle">
</details>




<h2 id="ToDo-Token-Downsampling-for-Efficient-Generation-of-High-Resolution-Images"><a href="#ToDo-Token-Downsampling-for-Efficient-Generation-of-High-Resolution-Images" class="headerlink" title="ToDo: Token Downsampling for Efficient Generation of High-Resolution   Images"></a>ToDo: Token Downsampling for Efficient Generation of High-Resolution   Images</h2><p><strong>Authors:Ethan Smith, Nayan Saxena, Aninda Saha</strong></p>
<p>Attention mechanism has been crucial for image diffusion models, however, their quadratic computational complexity limits the sizes of images we can process within reasonable time and memory constraints. This paper investigates the importance of dense attention in generative image models, which often contain redundant features, making them suitable for sparser attention mechanisms. We propose a novel training-free method ToDo that relies on token downsampling of key and value tokens to accelerate Stable Diffusion inference by up to 2x for common sizes and up to 4.5x or more for high resolutions like 2048x2048. We demonstrate that our approach outperforms previous methods in balancing efficient throughput and fidelity. </p>
<p><a href="http://arxiv.org/abs/2402.13573v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ”¹è¿›ç¨³å®šæ‰©æ•£æ³¨æ„æœºåˆ¶ä»¥æé«˜æ¨ç†é€Ÿåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ³¨æ„åŠ›æœºåˆ¶åœ¨å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­å¾ˆé‡è¦ï¼Œä½†å…¶äºŒæ¬¡è®¡ç®—å¤æ‚åº¦é™åˆ¶äº†æˆ‘ä»¬åœ¨åˆç†çš„æ—¶é—´å’Œå†…å­˜é™åˆ¶å†…å¯ä»¥å¤„ç†çš„å›¾åƒå¤§å°ã€‚</li>
<li>ç”Ÿæˆå›¾åƒæ¨¡å‹é€šå¸¸åŒ…å«å†—ä½™ç‰¹å¾ï¼Œé€‚åˆç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„å…è®­ç»ƒæ–¹æ³• ToDoï¼Œå®ƒä¾èµ–äºé”®å’Œå€¼æ ‡è®°çš„æ ‡è®°é™é‡‡æ ·ï¼Œä»è€Œå°† Stable Diffusion æ¨ç†é€Ÿåº¦æé«˜äº† 2 å€ï¼ˆå¸¸è§å¤§å°ï¼‰å’Œ 4.5 å€æˆ–æ›´å¤šï¼ˆ2048x2048 ç­‰é«˜åˆ†è¾¨ç‡ï¼‰ã€‚</li>
<li>ToDo åœ¨å¹³è¡¡æœ‰æ•ˆååé‡å’Œä¿çœŸåº¦æ–¹é¢ä¼˜äºä»¥å‰çš„æ–¹æ³•ã€‚</li>
<li>ToDo æ˜¯ä¸€ä¸ªå…è´¹ä¸”æ˜“äºå®ç°çš„æ–¹æ³•ï¼Œå¯ä»¥åº”ç”¨äºä»»ä½•åŸºäºæ³¨æ„åŠ›çš„æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>ToDo çš„æ¨ç†é€Ÿåº¦æ¯”ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•å¿«ï¼ŒåŒæ—¶è¿˜èƒ½ä¿æŒè‰¯å¥½çš„å›¾åƒè´¨é‡ã€‚</li>
<li>ToDo å¯ä»¥è®©å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨æ›´å¤§çš„å›¾åƒä¸Šè¿›è¡Œè®­ç»ƒå’Œæ¨ç†ï¼Œä»è€Œæé«˜å›¾åƒè´¨é‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šToDoï¼šä»¤ç‰Œé™é‡‡æ ·ä»¥é«˜æ•ˆç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒ</li>
<li>ä½œè€…ï¼šEthan Smithã€Nayan Saxenaã€Aninda Saha</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šLeonardo AI</li>
<li>å…³é”®è¯ï¼šå›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€æ³¨æ„æœºåˆ¶ã€ä»¤ç‰Œé™é‡‡æ ·ã€è®¡ç®—æ•ˆç‡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.13573ã€Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ³¨æ„æœºåˆ¶æ˜¯å›¾åƒæ‰©æ•£æ¨¡å‹æˆåŠŸçš„å…³é”®å› ç´ ï¼Œä½†å…¶äºŒæ¬¡è®¡ç®—å¤æ‚åº¦é™åˆ¶äº†å›¾åƒå¤„ç†çš„å¤§å°ã€‚æœ¬æ–‡ç ”ç©¶äº†ç”Ÿæˆå›¾åƒæ¨¡å‹ä¸­çš„å¯†é›†æ³¨æ„æœºåˆ¶ï¼Œæå‡ºäº†ä¸€ç§æ— éœ€è®­ç»ƒçš„ä»¤ç‰Œé™é‡‡æ ·æ–¹æ³• ToDoï¼Œå¯åŠ é€Ÿ Stable Diffusion æ¨ç†ï¼Œåœ¨å¸¸è§å°ºå¯¸ä¸‹æé€Ÿ 2 å€ï¼Œåœ¨ 2048Ã—2048 ç­‰é«˜åˆ†è¾¨ç‡ä¸‹æé€Ÿ 4.5 å€ä»¥ä¸Šã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šè¿‡å»çš„ç¨€ç–æ³¨æ„æ–¹æ³•é€šå¸¸éœ€è¦è®­ç»ƒæ—¶ä¿®æ”¹ï¼Œå¢åŠ äº†ä¼˜åŒ–å¼€é”€ã€‚æ³¨æ„è¿‘ä¼¼æ–¹æ³•è™½ç„¶ä¸éœ€è¦è®­ç»ƒï¼Œä½†é€šå¸¸éœ€è¦é¢„è®­ç»ƒã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºçš„ ToDo æ–¹æ³•æ˜¯ä¸€ç§åå¤„ç†æ–¹æ³•ï¼Œé€šè¿‡å¯¹æ³¨æ„æœºåˆ¶ä¸­çš„é”®å’Œå€¼ä»¤ç‰Œè¿›è¡Œé™é‡‡æ ·æ¥åŠ é€Ÿæ¨ç†ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹æˆ–é‡æ–°è®­ç»ƒã€‚
ï¼ˆ4ï¼‰æ€§èƒ½è¡¨ç°ï¼šToDo æ–¹æ³•åœ¨å„ç§ä»»åŠ¡å’Œæ€§èƒ½æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œåœ¨å¹³è¡¡è®¡ç®—æ•ˆç‡å’Œä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</li>
</ol>
<p>Methods:
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§ç§°ä¸ºToDoçš„ä»¤ç‰Œé™é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºåŠ é€ŸStableDiffusionæ¨ç†ã€‚
(2): ToDoæ–¹æ³•é€šè¿‡å¯¹æ³¨æ„æœºåˆ¶ä¸­çš„é”®å’Œå€¼ä»¤ç‰Œè¿›è¡Œé™é‡‡æ ·æ¥åŠ é€Ÿæ¨ç†ï¼Œæ— éœ€ä¿®æ”¹æ¨¡å‹æˆ–é‡æ–°è®­ç»ƒã€‚
(3): ToDoæ–¹æ³•é‡‡ç”¨äº†ä¸€ç§ä¼˜åŒ–çš„ä»¤ç‰Œåˆå¹¶ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åˆ©ç”¨äº†å›¾åƒä»¤ç‰Œå›ºæœ‰çš„ç©ºé—´é‚»è¿‘æ€§ã€‚
(4): ToDoæ–¹æ³•è¿˜å¼•å…¥äº†ä¸€ç§æ”¹è¿›çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œè¯¥æœºåˆ¶å°†é™é‡‡æ ·æ“ä½œåº”ç”¨äºæ³¨æ„æœºåˆ¶ä¸­çš„é”®å’Œå€¼ï¼ŒåŒæ—¶ä¿ç•™åŸå§‹æŸ¥è¯¢ã€‚
(5): ToDoæ–¹æ³•åœ¨å„ç§ä»»åŠ¡å’Œæ€§èƒ½æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œåœ¨å¹³è¡¡è®¡ç®—æ•ˆç‡å’Œä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ ToDo æ–¹æ³•åœ¨ä¿æŒè®¡ç®—æ•ˆç‡å’Œä¿çœŸåº¦ä¹‹é—´å–å¾—äº†å¾ˆå¥½çš„å¹³è¡¡ï¼Œå°¤å…¶æ˜¯åœ¨é«˜é¢‘åˆ†é‡ä¸Šã€‚æˆ‘ä»¬è¿˜è¡¨æ˜ï¼ŒU-Net ä¸­çš„ç›¸é‚»ç‰¹å¾å¯èƒ½æ˜¯å†—ä½™çš„ï¼Œå¹¶å‡è®¾æˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ä½¿å…¶ä»–åŸºäºæ³¨æ„åŠ›çš„ç”Ÿæˆå›¾åƒæ¨¡å‹å—ç›Šï¼Œå°¤å…¶æ˜¯é‚£äº›åœ¨å¤§é‡ä»¤ç‰Œä¸Šè¿è¡Œçš„æ¨¡å‹ã€‚æœªæ¥çš„å·¥ä½œå¯ä»¥æ¢ç´¢æˆ‘ä»¬æ–¹æ³•çš„å¯å¾®åˆ†æ€§ï¼Œå¹¶åˆ©ç”¨å®ƒæ¥æœ‰æ•ˆåœ°å¾®è°ƒ StableDiffusionï¼Œä½¿å…¶åœ¨ä»¥å‰æœªè§è¿‡çš„æ›´å¤§çš„å›¾åƒå°ºå¯¸ä¸Šè¿è¡Œã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§ç§°ä¸º ToDo çš„ä»¤ç‰Œé™é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºåŠ é€Ÿ StableDiffusion æ¨ç†ã€‚
æ€§èƒ½ï¼šåœ¨å„ç§ä»»åŠ¡å’Œæ€§èƒ½æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œåœ¨å¹³è¡¡è®¡ç®—æ•ˆç‡å’Œä¿çœŸåº¦æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚
å·¥ä½œé‡ï¼šæ— éœ€ä¿®æ”¹æ¨¡å‹æˆ–é‡æ–°è®­ç»ƒï¼Œé‡‡ç”¨äº†ä¸€ç§ä¼˜åŒ–çš„ä»¤ç‰Œåˆå¹¶ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åˆ©ç”¨äº†å›¾åƒä»¤ç‰Œå›ºæœ‰çš„ç©ºé—´é‚»è¿‘æ€§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b29b6788a3c63bf19060ac13a17491fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-588f50850c143462d31aee32d4aec168.jpg" align="middle">
</details>




<h2 id="Visual-Style-Prompting-with-Swapping-Self-Attention"><a href="#Visual-Style-Prompting-with-Swapping-Self-Attention" class="headerlink" title="Visual Style Prompting with Swapping Self-Attention"></a>Visual Style Prompting with Swapping Self-Attention</h2><p><strong>Authors:Jaeseok Jeong, Junho Kim, Yunjey Choi, Gayoung Lee, Youngjung Uh</strong></p>
<p>In the evolving domain of text-to-image generation, diffusion models have emerged as powerful tools in content creation. Despite their remarkable capability, existing models still face challenges in achieving controlled generation with a consistent style, requiring costly fine-tuning or often inadequately transferring the visual elements due to content leakage. To address these challenges, we propose a novel approach, \ours, to produce a diverse range of images while maintaining specific style elements and nuances. During the denoising process, we keep the query from original features while swapping the key and value with those from reference features in the late self-attention layers. This approach allows for the visual style prompting without any fine-tuning, ensuring that generated images maintain a faithful style. Through extensive evaluation across various styles and text prompts, our method demonstrates superiority over existing approaches, best reflecting the style of the references and ensuring that resulting images match the text prompts most accurately. Our project page is available <a href="https://curryjung.github.io/VisualStylePrompt/">https://curryjung.github.io/VisualStylePrompt/</a>. </p>
<p><a href="http://arxiv.org/abs/2402.12974v2">PDF</a> </p>
<p><strong>Summary</strong><br>ä½¿ç”¨é£æ ¼æ ·å¼æç¤ºè·å–æ›´å‡†ç¡®åŒ¹é…æ–‡æœ¬æç¤ºçš„å›¾åƒ</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸä¸­è¡¨ç°å‡ºå¼ºå¤§ï¼Œä½†å®ƒä»¬åœ¨ä¿æŒä¸€è‡´é£æ ¼çš„å—æ§ç”Ÿæˆæ–¹é¢ä»ç„¶å­˜åœ¨æŒ‘æˆ˜ï¼Œéœ€è¦æ˜‚è´µçš„å¾®è°ƒæˆ–ç”±äºå†…å®¹æ³„æ¼è€Œæ— æ³•å……åˆ†åœ°å†ç°è§†è§‰å…ƒç´ ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œ\oursï¼Œå¯ä»¥åœ¨ä¿æŒç‰¹å®šé£æ ¼å…ƒç´ å’Œç»†å¾®å·®åˆ«çš„æƒ…å†µä¸‹ç”Ÿæˆå„ç§å›¾åƒã€‚</li>
<li>åœ¨å»å™ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬åœ¨æœ€åçš„è‡ªæˆ‘æ³¨æ„å±‚ä¸­æŠŠåŸå§‹ç‰¹å¾ä¸­çš„æŸ¥è¯¢ä¿æŒä¸å˜ï¼ŒåŒæ—¶ç”¨å‚è€ƒç‰¹å¾çš„é”®å’Œå€¼è¿›è¡Œäº¤æ¢ã€‚</li>
<li>è¿™ç§æ–¹æ³•å…è®¸åœ¨æ— éœ€å¾®è°ƒçš„æƒ…å†µä¸‹è¿›è¡Œè§†è§‰é£æ ¼æç¤ºï¼Œç¡®ä¿ç”Ÿæˆçš„å›¾åƒä¿æŒå¿ å®çš„é£æ ¼ã€‚</li>
<li>é€šè¿‡åœ¨å„ç§é£æ ¼å’Œæ–‡æœ¬æç¤ºä¸‹çš„å¹¿æ³›è¯„ä¼°ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¯æ˜äº†ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæœ€èƒ½åæ˜ å‚è€ƒæ–‡çŒ®çš„é£æ ¼ï¼Œå¹¶ç¡®ä¿ç”Ÿæˆçš„å›¾åƒæœ€å‡†ç¡®åœ°åŒ¹é…æ–‡æœ¬æç¤ºã€‚</li>
<li>æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢å¯ä»¥åœ¨ <a href="https://curryjung.github.io/VisualStylePrompt/">https://curryjung.github.io/VisualStylePrompt/</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šè§†è§‰é£æ ¼æç¤ºä¸äº¤æ¢è‡ªæˆ‘æ³¨æ„åŠ›</li>
<li>ä½œè€…ï¼šJongwook Choi, Kyumin Lee, Jun-Ho Kim</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€è§†è§‰é£æ ¼æç¤ºã€äº¤æ¢è‡ªæˆ‘æ³¨æ„åŠ›</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08551ï¼ŒGithub é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»é¢ä¸´ç€åœ¨ä¿æŒä¸€è‡´é£æ ¼çš„åŒæ—¶å®ç°å¯æ§ç”Ÿæˆçš„æŒ‘æˆ˜ï¼Œéœ€è¦æ˜‚è´µçš„å¾®è°ƒæˆ–ç”±äºå†…å®¹æ³„æ¼è€Œå¯¼è‡´è§†è§‰å…ƒç´ è½¬ç§»ä¸è¶³ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡å¾®è°ƒæˆ–ä½¿ç”¨é¢„è®­ç»ƒçš„æ¨¡å‹æ¥å®ç°è§†è§‰é£æ ¼æç¤ºï¼Œä½†è¿™äº›æ–¹æ³•å­˜åœ¨æˆæœ¬é«˜æ˜‚ã€é£æ ¼è½¬ç§»ä¸è¶³æˆ–å†…å®¹æ³„æ¼ç­‰é—®é¢˜ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•â€”â€”è§†è§‰é£æ ¼æç¤ºï¼Œé€šè¿‡åœ¨å»å™ªè¿‡ç¨‹ä¸­ä¿ç•™åŸå§‹ç‰¹å¾çš„æŸ¥è¯¢ï¼ŒåŒæ—¶åœ¨æœ€åçš„è‡ªæ³¨æ„åŠ›å±‚ä¸­ç”¨å‚è€ƒç‰¹å¾äº¤æ¢é”®å’Œå€¼ï¼Œæ¥å®ç°è§†è§‰é£æ ¼æç¤ºã€‚è¿™ç§æ–¹æ³•ä¸éœ€è¦ä»»ä½•å¾®è°ƒï¼Œå¹¶ç¡®ä¿ç”Ÿæˆçš„å›¾åƒä¿æŒå¿ å®é£æ ¼ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨å„ç§é£æ ¼å’Œæ–‡æœ¬æç¤ºä¸‹çš„è¯„ä¼°ä¸­è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œåœ¨åæ˜ å‚è€ƒé£æ ¼å’Œç¡®ä¿ç”Ÿæˆå›¾åƒæœ€å‡†ç¡®åœ°åŒ¹é…æ–‡æœ¬æç¤ºæ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å®ç°å…·æœ‰ç‰¹å®šé£æ ¼å…ƒç´ å’Œç»†å¾®å·®åˆ«çš„å›¾åƒç”Ÿæˆã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è§†è§‰é£æ ¼æç¤ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ— éœ€å¾®è°ƒï¼Œå¹¶ç¡®ä¿ç”Ÿæˆçš„å›¾åƒä¿æŒå¿ å®é£æ ¼ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æœ¬æ–¹æ³•åˆ›æ–°æ€§åœ°æå‡ºäº†ä¸€ç§æ–°çš„è§†è§‰é£æ ¼æç¤ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åœ¨å»å™ªè¿‡ç¨‹ä¸­ä¿ç•™åŸå§‹ç‰¹å¾çš„æŸ¥è¯¢ï¼ŒåŒæ—¶åœ¨æœ€åçš„è‡ªæ³¨æ„åŠ›å±‚ä¸­ç”¨å‚è€ƒç‰¹å¾äº¤æ¢é”®å’Œå€¼ï¼Œæ¥å®ç°è§†è§‰é£æ ¼æç¤ºã€‚
æ€§èƒ½ï¼š
æœ¬æ–¹æ³•åœ¨å„ç§é£æ ¼å’Œæ–‡æœ¬æç¤ºä¸‹çš„è¯„ä¼°ä¸­è¡¨ç°å‡ºä¼˜è¶Šæ€§ï¼Œåœ¨åæ˜ å‚è€ƒé£æ ¼å’Œç¡®ä¿ç”Ÿæˆå›¾åƒæœ€å‡†ç¡®åœ°åŒ¹é…æ–‡æœ¬æç¤ºæ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
æœ¬æ–¹æ³•çš„å·¥ä½œé‡ç›¸å¯¹è¾ƒä½ï¼Œä¸éœ€è¦ä»»ä½•å¾®è°ƒï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå®¹æ˜“åœ°åº”ç”¨äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ca682f6681ca2aea4fdb5980de4dc8f4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0d771e643cabdf04390bb34c56e1d306.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-11f4ff0d9aeecd7bd560b037f6d9c569.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff425802a32a4519e30b9044a3eed1e8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6b333a460ba441d80a537e0874e7628a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ef6e8248b60241a24705f590a653e38.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4422e0b37dd7515345602877f9ea3a62.jpg" align="middle">
</details>




<h2 id="CLIPping-the-Deception-Adapting-Vision-Language-Models-for-Universal-Deepfake-Detection"><a href="#CLIPping-the-Deception-Adapting-Vision-Language-Models-for-Universal-Deepfake-Detection" class="headerlink" title="CLIPping the Deception: Adapting Vision-Language Models for Universal   Deepfake Detection"></a>CLIPping the Deception: Adapting Vision-Language Models for Universal   Deepfake Detection</h2><p><strong>Authors:Sohail Ahmed Khan, Duc-Tien Dang-Nguyen</strong></p>
<p>The recent advancements in Generative Adversarial Networks (GANs) and the emergence of Diffusion models have significantly streamlined the production of highly realistic and widely accessible synthetic content. As a result, there is a pressing need for effective general purpose detection mechanisms to mitigate the potential risks posed by deepfakes. In this paper, we explore the effectiveness of pre-trained vision-language models (VLMs) when paired with recent adaptation methods for universal deepfake detection. Following previous studies in this domain, we employ only a single dataset (ProGAN) in order to adapt CLIP for deepfake detection. However, in contrast to prior research, which rely solely on the visual part of CLIP while ignoring its textual component, our analysis reveals that retaining the text part is crucial. Consequently, the simple and lightweight Prompt Tuning based adaptation strategy that we employ outperforms the previous SOTA approach by 5.01% mAP and 6.61% accuracy while utilizing less than one third of the training data (200k images as compared to 720k). To assess the real-world applicability of our proposed models, we conduct a comprehensive evaluation across various scenarios. This involves rigorous testing on images sourced from 21 distinct datasets, including those generated by GANs-based, Diffusion-based and Commercial tools. </p>
<p><a href="http://arxiv.org/abs/2402.12927v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>CLIPæ¨¡å‹ç»“åˆæ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ï¼Œåœ¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œä¼˜äºä»…ä½¿ç”¨è§†è§‰ä¿¡æ¯çš„SOTAæ–¹æ³•ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>CLIPæ¨¡å‹åœ¨ä¸æœ€è¿‘çš„é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹é€‚åº”æ–¹æ³•é…å¯¹æ—¶ï¼Œåœ¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>åªéœ€ä½¿ç”¨ä¸€ä¸ªæ•°æ®é›†ï¼ˆProGANï¼‰å°±å¯ä»¥å¯¹CLIPè¿›è¡Œæ”¹ç¼–ï¼Œä»¥å®ç°æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚</li>
<li>ä¿ç•™CLIPæ¨¡å‹çš„æ–‡æœ¬éƒ¨åˆ†å¯¹äºæé«˜æ£€æµ‹æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>åŸºäºPrompt Tuningçš„ç®€å•ä¸”è½»é‡çº§çš„é€‚åº”ç­–ç•¥åœ¨ä½¿ç”¨ä¸åˆ°ä¸‰åˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®ï¼ˆ20ä¸‡å¼ å›¾åƒï¼Œè€Œä¹‹å‰çš„æ–¹æ³•ä½¿ç”¨äº†72ä¸‡å¼ å›¾åƒï¼‰çš„æƒ…å†µä¸‹ï¼Œåœ¨mAPå’Œå‡†ç¡®ç‡æ–¹é¢åˆ†åˆ«ä¼˜äºä¹‹å‰çš„SOTAæ–¹æ³•5.01%å’Œ6.61%ã€‚</li>
<li>CLIPæ¨¡å‹åœ¨å¯¹æ¥è‡ª21ä¸ªä¸åŒæ•°æ®é›†çš„å›¾åƒè¿›è¡Œçš„å…¨é¢è¯„ä¼°ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„çœŸå®ä¸–ç•Œé€‚ç”¨æ€§ï¼ŒåŒ…æ‹¬ç”±åŸºäºGANã€åŸºäºæ‰©æ•£å’Œå•†ä¸šå·¥å…·ç”Ÿæˆçš„å›¾åƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå‰ªè¾‘æ¬ºéª—ï¼šé€‚åº”é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹çš„è§†è§‰è¯­è¨€æ¨¡å‹</li>
<li>ä½œè€…ï¼šSohail Ahmed Khan, Duc-Tien Dang-Nguyen</li>
<li>å•ä½ï¼šå‘å°”æ ¹å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ·±åº¦ä¼ªé€ æ£€æµ‹ï¼Œè¿ç§»å­¦ä¹ ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12927ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šéšç€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) çš„æœ€æ–°è¿›å±•å’Œæ‰©æ•£æ¨¡å‹çš„å‡ºç°ï¼Œé«˜åº¦é€¼çœŸä¸”å¹¿æ³›å¯è®¿é—®çš„åˆæˆå†…å®¹çš„åˆ¶ä½œå˜å¾—æ›´åŠ å®¹æ˜“ã€‚å› æ­¤ï¼Œè¿«åˆ‡éœ€è¦æœ‰æ•ˆçš„é€šç”¨æ£€æµ‹æœºåˆ¶æ¥å‡è½»æ·±åº¦ä¼ªé€ å¸¦æ¥çš„æ½œåœ¨é£é™©ã€‚
(2)ï¼šåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æ¢ç´¢äº†åœ¨ä¸æœ€è¿‘çš„é€‚åº”æ–¹æ³•é…å¯¹æ—¶é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ (VLM) åœ¨é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚éµå¾ªè¯¥é¢†åŸŸçš„å…ˆå‰ç ”ç©¶ï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨å•ä¸ªæ•°æ®é›† (ProGAN) æ¥é€‚åº” CLIP ä»¥è¿›è¡Œæ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚ç„¶è€Œï¼Œä¸ä»…ä¾èµ– CLIP çš„è§†è§‰éƒ¨åˆ†è€Œå¿½ç•¥å…¶æ–‡æœ¬ç»„ä»¶çš„å…ˆå‰ç ”ç©¶ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„åˆ†æè¡¨æ˜ä¿ç•™æ–‡æœ¬éƒ¨åˆ†è‡³å…³é‡è¦ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨çš„ç®€å•è½»é‡çº§ PromptTuning åŸºäºé€‚åº”ç­–ç•¥åœ¨åˆ©ç”¨ä¸åˆ°ä¸‰åˆ†ä¹‹ä¸€çš„è®­ç»ƒæ•°æ®ï¼ˆ200k å›¾åƒï¼Œç›¸æ¯”ä¹‹ä¸‹ä¸º 720kï¼‰çš„æƒ…å†µä¸‹ï¼Œåœ¨ mAP ä¸Šä¼˜äºä¹‹å‰çš„ SOTA æ–¹æ³• 5.01%ï¼Œå‡†ç¡®ç‡æé«˜ 6.61%ã€‚ä¸ºäº†è¯„ä¼°æˆ‘ä»¬æå‡ºçš„æ¨¡å‹çš„å®é™…é€‚ç”¨æ€§ï¼Œæˆ‘ä»¬å¯¹å„ç§åœºæ™¯è¿›è¡Œäº†ç»¼åˆè¯„ä¼°ã€‚è¿™æ¶‰åŠå¯¹æ¥è‡ª 21 ä¸ªä¸åŒæ•°æ®é›†çš„å›¾åƒè¿›è¡Œä¸¥æ ¼æµ‹è¯•ï¼ŒåŒ…æ‹¬åŸºäº GANã€åŸºäºæ‰©æ•£å’Œå•†ä¸šå·¥å…·ç”Ÿæˆçš„å›¾åƒã€‚
(3)ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•æ¥é€‚åº” CLIP ä»¥è¿›è¡Œé€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŸºäº PromptTuningï¼Œè¿™æ˜¯ä¸€ç§è½»é‡çº§ä¸”æ˜“äºå®ç°çš„é€‚åº”ç­–ç•¥ã€‚æˆ‘ä»¬è¿˜è¡¨æ˜ï¼Œä¿ç•™ CLIP çš„æ–‡æœ¬éƒ¨åˆ†å¯¹äºæé«˜æ£€æµ‹æ€§èƒ½è‡³å…³é‡è¦ã€‚
(4)ï¼šåœ¨ ProGAN æ•°æ®é›†ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ mAP ä¸Šå®ç°äº† 95.21% çš„å‡†ç¡®ç‡å’Œ 97.82% çš„å‡†ç¡®ç‡ï¼Œä¼˜äºä¹‹å‰çš„ SOTA æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜æ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ£€æµ‹æ¥è‡ªå„ç§æ¥æºçš„æ·±åº¦ä¼ªé€ ï¼ŒåŒ…æ‹¬ GANã€æ‰©æ•£å’Œå•†ä¸šå·¥å…·ã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰çº¿æ€§æ¢æµ‹ï¼šçº¿æ€§æ¢æµ‹æ˜¯ä¸€ç§å°†å†»ç»“æ¨¡å‹ï¼ˆæœ¬ä¾‹ä¸­ä¸º CLIPï¼‰ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œå¹¶åœ¨å…¶ä¸Šå¾®è°ƒçº¿æ€§åˆ†ç±»å™¨çš„æ–¹æ³•ã€‚æˆ‘ä»¬éµå¾ª Ojha ç­‰äººé‡‡ç”¨çš„ç›¸åŒæ–¹æ³•ã€‚[32]ï¼Œå³æˆ‘ä»¬ä¸¢å¼ƒ CLIP çš„æ–‡æœ¬ç¼–ç å™¨å¹¶å†»ç»“å…¶å›¾åƒç¼–ç å™¨ã€‚ç„¶åï¼Œæˆ‘ä»¬åœ¨å†»ç»“çš„ CLIP å›¾åƒç‰¹å¾ä¸Šè®­ç»ƒä¸€ä¸ªç”¨äºåˆ†ç±»çš„å•å±‚çº¿æ€§å±‚ï¼Œä½¿ç”¨ Sigmoid æ¿€æ´»å‡½æ•°å°†å€’æ•°ç¬¬äºŒä¸ªå›¾åƒç‰¹å¾æ˜ å°„åˆ°ç”¨äºç±»åˆ«é¢„æµ‹çš„é€»è¾‘å€¼ã€‚ä¼˜åŒ–ä½¿ç”¨äºŒè¿›åˆ¶äº¤å‰ç†µæŸå¤±è¿›è¡Œã€‚</p>
<p>ï¼ˆ2ï¼‰å¾®è°ƒï¼šå¾®è°ƒåœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­æ„å‘³ç€å†æ¬¡åœ¨ç”¨äºä¸‹æ¸¸æ•°æ®é›†çš„æ•´ä¸ª CLIP æ¨¡å‹ï¼ˆViT-Largeï¼‰ä¸Šè¿›è¡Œè®­ç»ƒï¼Œåœ¨æœ¬ä¾‹ä¸­æ˜¯ä¹Ÿè¢« [45] å’Œ [32] ä½¿ç”¨çš„ ProGAN æ•°æ®é›†ã€‚å®Œå…¨å¾®è°ƒéœ€è¦æ˜¾ç€æ›´å¤šçš„è®¡ç®—æœºèµ„æºã€æ•°æ®å’Œè®­ç»ƒæ—¶é—´ï¼Œå› ä¸ºæ•´ä¸ªæ¨¡å‹éƒ½ç»è¿‡äº†é‡æ–°è®­ç»ƒã€‚æ­¤å¤–ï¼Œéšç€æ¨¡å‹å¤§å°çš„å¢åŠ ï¼Œæ­¤ç­–ç•¥è¡¨ç°å‡ºä¸ç¨³å®šå’Œæ•ˆç‡ä½ä¸‹ [26]ã€‚åœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæˆ‘ä»¬é‡åˆ°äº†è¿™ä¸ªé—®é¢˜ï¼Œå¹¶é€šè¿‡ä½¿ç”¨æå°çš„å­¦ä¹ ç‡ 1Ã—10-6 æ¥ç¼“è§£è¿™ä¸ªé—®é¢˜ã€‚ä¸ºäº†å¾®è°ƒæˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éµå¾ª CLIP é¢„è®­ç»ƒä¸­æ¦‚è¿°çš„ç¨‹åº [37]ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªä¿®æ”¹ï¼šä¸æ˜¯å¯¹æ¯ä¸ªå›¾åƒä½¿ç”¨æ•´ä¸ªæ–‡æœ¬æ ‡é¢˜ï¼Œæˆ‘ä»¬åªæä¾›å•ä¸ªå•è¯æ ‡é¢˜ï¼Œå…·ä½“æ¥è¯´æ˜¯ real æˆ– fakeã€‚å…¸å‹çš„ç”¨äºè°ƒæ•´ CLIP çš„å¾®è°ƒç®¡é“å¦‚å›¾ 2 æ‰€ç¤ºã€‚</p>
<p>ï¼ˆ3ï¼‰PromptTuningï¼šPromptTuning æ˜¯ä¸€ç§é€šè¿‡è°ƒæ•´æ–‡æœ¬æç¤ºæ¥é€‚åº” CLIP çš„æ–¹æ³•ã€‚æˆ‘ä»¬éµå¾ª CoOp [50] çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä½¿ç”¨ CLIP çš„æ–‡æœ¬ç¼–ç å™¨ç”Ÿæˆä¸€ä¸ªæç¤ºï¼Œè¯¥æç¤ºå¯ä»¥æŒ‡å¯¼å›¾åƒç¼–ç å™¨è¿›è¡Œåˆ†ç±»ã€‚æˆ‘ä»¬ä½¿ç”¨å•ä¸ªå•è¯æç¤º real æˆ– fake æ¥ç”Ÿæˆå›¾åƒç‰¹å¾ï¼Œç„¶åä½¿ç”¨è¿™äº›ç‰¹å¾æ¥è®­ç»ƒçº¿æ€§åˆ†ç±»å™¨ã€‚</p>
<p>ï¼ˆ4ï¼‰é€‚é…å™¨ç½‘ç»œï¼šé€‚é…å™¨ç½‘ç»œæ˜¯ä¸€ç§é€šè¿‡åœ¨é¢„è®­ç»ƒæ¨¡å‹ä¸Šæ·»åŠ å°å‹ç½‘ç»œæ¥é€‚åº”æ–°ä»»åŠ¡çš„æ–¹æ³•ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé€‚é…å™¨ç½‘ç»œæ¥è°ƒæ•´ CLIPï¼Œè¯¥ç½‘ç»œç”±ä¸€ä¸ªå·ç§¯å±‚å’Œä¸€ä¸ªçº¿æ€§å±‚ç»„æˆã€‚é€‚é…å™¨ç½‘ç»œå°† CLIP çš„å›¾åƒç‰¹å¾ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªç”¨äºåˆ†ç±»çš„é€»è¾‘å€¼ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œé€šè¿‡æ¢ç´¢é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ CLIP åœ¨é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå±•ç¤ºäº† CLIP åœ¨æ£€æµ‹æ¥è‡ªå„ç§æ•°æ®åˆ†å¸ƒçš„æ·±åº¦ä¼ªé€ å›¾åƒæ–¹é¢çš„é²æ£’æ€§ã€‚æˆ‘ä»¬ä½¿ç”¨æ¥è‡ª ProGAN æ•°æ®é›†çš„ 200k å›¾åƒä½œä¸ºå¤šæ ·åŒ–çš„è®­ç»ƒé›†ï¼Œå¹¶æ¯”è¾ƒäº†å››ç§ä¸åŒçš„è¿ç§»å­¦ä¹ ç­–ç•¥ï¼ŒåŒ…æ‹¬å¾®è°ƒã€çº¿æ€§æ¢æµ‹ã€PromptTuning å’Œè®­ç»ƒé€‚é…å™¨ç½‘ç»œã€‚æˆ‘ä»¬çš„å®éªŒåŒ…æ‹¬å¯¹åŒ…å« 21 ä¸ªä¸åŒå›¾åƒç”Ÿæˆå™¨çš„ç»¼åˆæµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ã€‚åœ¨æ•´ä¸ªå®éªŒä¸­ï¼Œæˆ‘ä»¬è¯æ˜äº†ç»“åˆ CLIP çš„å›¾åƒå’Œæ–‡æœ¬ç»„ä»¶çš„è¿ç§»å­¦ä¹ ç­–ç•¥å§‹ç»ˆä¼˜äºä»…ä½¿ç”¨ CLIP è§†è§‰æ–¹é¢çš„ç®€å•æ–¹æ³•ï¼ˆå¦‚çº¿æ€§æ¢æµ‹ï¼‰çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå‡¸æ˜¾äº† PromptTuning ä¼˜äºå½“å‰åŸºå‡†å’Œ SOTA æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œåœ¨å±•ç¤ºå…¶æœ‰æ•ˆæ€§çš„åŒæ—¶ï¼Œå³ä½¿è®­ç»ƒå‚æ•°æœ€å°‘ï¼Œä¹Ÿèƒ½å®ç°æ˜¾ç€çš„æ”¹è¿›å¹…åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†å°‘é‡å®éªŒï¼Œåˆ†æäº†åœ¨ JPEG å‹ç¼©å’Œé«˜æ–¯æ¨¡ç³Šç­‰åå¤„ç†æ“ä½œä¸‹çš„é²æ£’æ€§ï¼Œå¹¶è¯æ˜äº†å³ä½¿è®­ç»ƒé›†è§„æ¨¡è¾ƒå°ï¼ˆ20k å›¾åƒï¼‰ï¼ŒåŸºäº CLIP çš„æ£€æµ‹å™¨ä¹Ÿå…·æœ‰ç¨³å®šçš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
â€¢ æ¢ç´¢äº†é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ CLIP åœ¨é€šç”¨æ·±åº¦ä¼ªé€ æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚
â€¢ æ¯”è¾ƒäº†å››ç§ä¸åŒçš„è¿ç§»å­¦ä¹ ç­–ç•¥ï¼ŒåŒ…æ‹¬å¾®è°ƒã€çº¿æ€§æ¢æµ‹ã€PromptTuning å’Œè®­ç»ƒé€‚é…å™¨ç½‘ç»œã€‚
â€¢ è¯æ˜äº†ç»“åˆ CLIP çš„å›¾åƒå’Œæ–‡æœ¬ç»„ä»¶çš„è¿ç§»å­¦ä¹ ç­–ç•¥å§‹ç»ˆä¼˜äºä»…ä½¿ç”¨ CLIP è§†è§‰æ–¹é¢çš„ç®€å•æ–¹æ³•ï¼ˆå¦‚çº¿æ€§æ¢æµ‹ï¼‰çš„æ€§èƒ½ã€‚
â€¢ PromptTuning ä¼˜äºå½“å‰åŸºå‡†å’Œ SOTA æ–¹æ³•ï¼Œåœ¨å±•ç¤ºå…¶æœ‰æ•ˆæ€§çš„åŒæ—¶ï¼Œå³ä½¿è®­ç»ƒå‚æ•°æœ€å°‘ï¼Œä¹Ÿèƒ½å®ç°æ˜¾ç€çš„æ”¹è¿›å¹…åº¦ã€‚
â€¢ åˆ†æäº†åœ¨ JPEG å‹ç¼©å’Œé«˜æ–¯æ¨¡ç³Šç­‰åå¤„ç†æ“ä½œä¸‹çš„é²æ£’æ€§ï¼Œå¹¶è¯æ˜äº†å³ä½¿è®­ç»ƒé›†è§„æ¨¡è¾ƒå°ï¼ˆ20k å›¾åƒï¼‰ï¼ŒåŸºäº CLIP çš„æ£€æµ‹å™¨ä¹Ÿå…·æœ‰ç¨³å®šçš„æ€§èƒ½ã€‚</li>
</ol>
<p>æ€§èƒ½ï¼š
â€¢ åœ¨ ProGAN æ•°æ®é›†ä¸Šï¼ŒPromptTuning åœ¨ mAP ä¸Šå®ç°äº† 95.21% çš„å‡†ç¡®ç‡å’Œ 97.82% çš„å‡†ç¡®ç‡ï¼Œä¼˜äºä¹‹å‰çš„ SOTA æ–¹æ³•ã€‚
â€¢ PromptTuning åœ¨ç»¼åˆæµ‹è¯•é›†ä¸Šä¹Ÿè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ£€æµ‹æ¥è‡ªå„ç§æ¥æºçš„æ·±åº¦ä¼ªé€ ï¼ŒåŒ…æ‹¬ GANã€æ‰©æ•£å’Œå•†ä¸šå·¥å…·ã€‚</p>
<p>å·¥ä½œé‡ï¼š
â€¢ PromptTuning æ˜¯ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œæ˜“äºå®ç°ã€‚
â€¢ PromptTuning åªéœ€è¦å°‘é‡çš„æ•°æ®å’Œè®­ç»ƒæ—¶é—´ã€‚
â€¢ PromptTuning å¯ä»¥ç”¨äºæ£€æµ‹æ¥è‡ªå„ç§æ¥æºçš„æ·±åº¦ä¼ªé€ ï¼ŒåŒ…æ‹¬ GANã€æ‰©æ•£å’Œå•†ä¸šå·¥å…·ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-745a50bdee80b1df6d9da45abefcb26e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0e6ec4d0ce05a2af6e93f8a2710069bd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca30024b468b77b358f2f1058147b9e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f749a0d770c3a7267b5153b59c39032b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-6f8430a1aafee1b2f88631389c9cdc32.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-05df037ca314f896a85f2bb5c514f5dd.jpg" align="middle">
</details>




## RealCompo: Dynamic Equilibrium between Realism and Compositionality   Improves Text-to-Image Diffusion Models

**Authors:Xinchen Zhang, Ling Yang, Yaqi Cai, Zhaochen Yu, Jiake Xie, Ye Tian, Minkai Xu, Yong Tang, Yujiu Yang, Bin Cui**

Diffusion models have achieved remarkable advancements in text-to-image generation. However, existing models still have many difficulties when faced with multiple-object compositional generation. In this paper, we propose a new training-free and transferred-friendly text-to-image generation framework, namely RealCompo, which aims to leverage the advantages of text-to-image and layout-to-image models to enhance both realism and compositionality of the generated images. An intuitive and novel balancer is proposed to dynamically balance the strengths of the two models in denoising process, allowing plug-and-play use of any model without extra training. Extensive experiments show that our RealCompo consistently outperforms state-of-the-art text-to-image models and layout-to-image models in multiple-object compositional generation while keeping satisfactory realism and compositionality of the generated images. Code is available at https://github.com/YangLing0818/RealCompo 

[PDF](http://arxiv.org/abs/2402.12908v1) Project: https://github.com/YangLing0818/RealCompo

**Summary**
åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹çš„ä¼˜åŠ¿ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„æ— è®­ç»ƒå’Œæ˜“äºè¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ RealCompoï¼Œä»¥å¢å¼ºç”Ÿæˆå›¾åƒçš„çœŸå®æ€§å’Œç»„åˆæ€§ã€‚

**Key Takeaways**

- RealCompo æ˜¯ä¸€ç§æ–°çš„æ— è®­ç»ƒå’Œæ˜“äºè¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹çš„ä¼˜åŠ¿ã€‚
- RealCompo åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œåˆ©ç”¨å¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ç”Ÿæˆåˆç†çš„æ„å›¾ã€‚
- RealCompo å¼•å…¥äº†æ–°çš„å¹³è¡¡å™¨ï¼Œä»¥åŠ¨æ€å¹³è¡¡ä¸¤ä¸ªæ¨¡å‹åœ¨å»å™ªè¿‡ç¨‹ä¸­çš„ä¼˜åŠ¿ã€‚
- RealCompo å³æ’å³ç”¨ï¼Œæ— éœ€é¢å¤–è®­ç»ƒå³å¯ä½¿ç”¨ä»»ä½•æ¨¡å‹ã€‚
- RealCompo åœ¨å¤šå¯¹è±¡ç»„åˆç”Ÿæˆæ–¹é¢å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ã€‚
- RealCompo ä¿æŒäº†ç”Ÿæˆå›¾åƒçš„ä»¤äººæ»¡æ„çš„çœŸå®æ€§å’Œç»„åˆæ€§ã€‚
- RealCompo çš„ä»£ç å¯åœ¨ https://github.com/YangLing0818/RealCompo è·å¾—ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šRealCompoï¼šçœŸå®æ„Ÿä¸ç»„åˆæ€§çš„åŠ¨æ€å¹³è¡¡å¯æ”¹è¿›æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šXinchen Zhang<em>, Ling Yang</em>, Yaqi Cai, Zhaochen Yu, Jiake Xie, Ye Tian, Minkai Xu, Yong Tang, Yujiu Yang, Bin Cui</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å¸ƒå±€åˆ°å›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€ç»„åˆæ€§ã€çœŸå®æ„Ÿ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://github.com/YangLing0818/RealCompo
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/YangLing0818/RealCompo</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ¨¡å‹åœ¨å¤„ç†å¤šå¯¹è±¡ç»„åˆæ€§ç”Ÿæˆæ—¶ä»é¢ä¸´è®¸å¤šå›°éš¾ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•åŒ…æ‹¬æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ã€‚æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé€¼çœŸçš„å›¾åƒï¼Œä½†ç»„åˆæ€§è¾ƒå·®ï¼›å¸ƒå±€åˆ°å›¾åƒæ¨¡å‹èƒ½å¤Ÿæ§åˆ¶å¯¹è±¡çš„ä½ç½®å’Œæ•°é‡ï¼Œä½†çœŸå®æ„Ÿè¾ƒå·®ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒå‹å¥½ä¸”å¯è¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ RealCompoï¼Œè¯¥æ¡†æ¶æ—¨åœ¨åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶æé«˜ç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚RealCompo ä½¿ç”¨äº†ä¸€ä¸ªç›´è§‚ä¸”æ–°é¢–çš„å¹³è¡¡å™¨ï¼Œå¯ä»¥åœ¨å»å™ªè¿‡ç¨‹ä¸­åŠ¨æ€å¹³è¡¡ä¸¤ä¸ªæ¨¡å‹çš„å¼ºåº¦ï¼Œä»è€Œå…è®¸å³æ’å³ç”¨ä»»ä½•æ¨¡å‹è€Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒRealCompo åœ¨å¤šå¯¹è±¡ç»„åˆæ€§ç”Ÿæˆä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆå›¾åƒä»¤äººæ»¡æ„çš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ã€‚</li>
</ol>
<p>Methods:
(1) æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒå‹å¥½ä¸”å¯è¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶RealCompoï¼Œè¯¥æ¡†æ¶æ—¨åœ¨åˆ©ç”¨æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶æé«˜ç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚
(2) è®¾è®¡äº†ä¸€ä¸ªç›´è§‚ä¸”æ–°é¢–çš„å¹³è¡¡å™¨ï¼Œå¯ä»¥åœ¨å»å™ªè¿‡ç¨‹ä¸­åŠ¨æ€å¹³è¡¡ä¸¤ä¸ªæ¨¡å‹çš„å¼ºåº¦ï¼Œä»è€Œå…è®¸å³æ’å³ç”¨ä»»ä½•æ¨¡å‹è€Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
(3) åˆ†æäº†æ¯ä¸ªæ¨¡å‹é¢„æµ‹å™ªå£°çš„å½±å“ï¼Œå¹¶æä¾›äº†ä¸€ç§è®¡ç®—ç³»æ•°çš„æ–¹æ³•ã€‚
(4) æä¾›äº†å¹³è¡¡å™¨æ‰€é‡‡ç”¨çš„æ›´æ–°è§„åˆ™çš„è¯¦ç»†è§£é‡Šï¼Œè¯¥è§„åˆ™åˆ©ç”¨äº†ä¸€ç§æ— è®­ç»ƒæ–¹æ³•æ¥åŠ¨æ€æ›´æ–°ç³»æ•°ã€‚
(5) æ‰©å±•äº†RealCompoçš„åº”ç”¨ï¼Œä¸ºL2Iæ¨¡å‹çš„æ¯ä¸€ç±»è®¾è®¡äº†æŸå¤±å‡½æ•°ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§è®­ç»ƒå‹å¥½ä¸”å¯è¿ç§»çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶RealCompoï¼Œè¯¥æ¡†æ¶åœ¨å¤šå¯¹è±¡ç»„åˆæ€§ç”Ÿæˆä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆå›¾åƒä»¤äººæ»¡æ„çš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ä¸ªç›´è§‚ä¸”æ–°é¢–çš„å¹³è¡¡å™¨ï¼Œå¯ä»¥åœ¨å»å™ªè¿‡ç¨‹ä¸­åŠ¨æ€å¹³è¡¡ä¸¤ä¸ªæ¨¡å‹çš„å¼ºåº¦ï¼Œä»è€Œå…è®¸å³æ’å³ç”¨ä»»ä½•æ¨¡å‹è€Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
åˆ†æäº†æ¯ä¸ªæ¨¡å‹é¢„æµ‹å™ªå£°çš„å½±å“ï¼Œå¹¶æä¾›äº†ä¸€ç§è®¡ç®—ç³»æ•°çš„æ–¹æ³•ã€‚
æä¾›äº†å¹³è¡¡å™¨æ‰€é‡‡ç”¨çš„æ›´æ–°è§„åˆ™çš„è¯¦ç»†è§£é‡Šï¼Œè¯¥è§„åˆ™åˆ©ç”¨äº†ä¸€ç§æ— è®­ç»ƒæ–¹æ³•æ¥åŠ¨æ€æ›´æ–°ç³»æ•°ã€‚
æ‰©å±•äº†RealCompoçš„åº”ç”¨ï¼Œä¸ºL2Iæ¨¡å‹çš„æ¯ä¸€ç±»è®¾è®¡äº†æŸå¤±å‡½æ•°ã€‚
æ€§èƒ½ï¼š
RealCompoåœ¨å¤šå¯¹è±¡ç»„åˆæ€§ç”Ÿæˆä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹å’Œå¸ƒå±€åˆ°å›¾åƒæ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒäº†ç”Ÿæˆå›¾åƒä»¤äººæ»¡æ„çš„çœŸå®æ„Ÿå’Œç»„åˆæ€§ã€‚
RealCompoå¯ä»¥è¢«æ¨å¹¿åˆ°ä»»ä½•LLMã€T2Iå’ŒL2Iæ¨¡å‹ï¼Œå¹¶ä¿æŒå¼ºå¤§çš„ç”Ÿæˆç»“æœã€‚
å·¥ä½œé‡ï¼š
RealCompoçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä½¿ç”¨ã€‚
RealCompoå¯ä»¥è½»æ¾åœ°é›†æˆåˆ°ç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿä¸­ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-264ae173bcca3292815b8e45db353de6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e9c5f244037ff17e98afe9f2c1851e4f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-caea4b22ae09f52bc515627d4e3cba84.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5fcdadd1b307e5df492d508f86958e6.jpg" align="middle">
</details>




<h2 id="Two-stage-Rainfall-Forecasting-Diffusion-Model"><a href="#Two-stage-Rainfall-Forecasting-Diffusion-Model" class="headerlink" title="Two-stage Rainfall-Forecasting Diffusion Model"></a>Two-stage Rainfall-Forecasting Diffusion Model</h2><p><strong>Authors:XuDong Ling, ChaoRong Li, FengQing Qin, LiHong Zhu, Yuanyuan Huang</strong></p>
<p>Deep neural networks have made great achievements in rainfall prediction.However, the current forecasting methods have certain limitations, such as with blurry generated images and incorrect spatial positions. To overcome these challenges, we propose a Two-stage Rainfall-Forecasting Diffusion Model (TRDM) aimed at improving the accuracy of long-term rainfall forecasts and addressing the imbalance in performance between temporal and spatial modeling. TRDM is a two-stage method for rainfall prediction tasks. The task of the first stage is to capture robust temporal information while preserving spatial information under low-resolution conditions. The task of the second stage is to reconstruct the low-resolution images generated in the first stage into high-resolution images. We demonstrate state-of-the-art results on the MRMS and Swedish radar datasets. Our project is open source and available on GitHub at: \href{<a href="https://github.com/clearlyzerolxd/TRDM}{https://github.com/clearlyzerolxd/TRDM}">https://github.com/clearlyzerolxd/TRDM}{https://github.com/clearlyzerolxd/TRDM}</a>. </p>
<p><a href="http://arxiv.org/abs/2402.12779v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨ä¸¤é˜¶æ®µé™é›¨é¢„æµ‹æ‰©æ•£æ¨¡å‹ï¼ˆTRDMï¼‰æé«˜é™é›¨é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>TRDMæ˜¯ä¸€ç§ç”¨äºé™é›¨é¢„æµ‹ä»»åŠ¡çš„ä¸¤é˜¶æ®µæ–¹æ³•ã€‚</li>
<li>TRDMçš„ç¬¬ä¸€é˜¶æ®µä»»åŠ¡æ˜¯åœ¨ä½åˆ†è¾¨ç‡æ¡ä»¶ä¸‹æ•è·ç¨³å¥çš„æ—¶é—´ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™ç©ºé—´ä¿¡æ¯ã€‚</li>
<li>TRDMçš„ç¬¬äºŒé˜¶æ®µä»»åŠ¡æ˜¯å°†ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„ä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>TRDMåœ¨MRMSå’Œç‘å…¸é›·è¾¾æ•°æ®é›†ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„ç»“æœã€‚</li>
<li>TRDMå¼€æºï¼Œå¯åœ¨ GitHub ä¸Šè·å–ï¼š\href{<a href="https://github.com/clearlyzerolxd/TRDM}{https://github.com/clearlyzerolxd/TRDM}ã€‚">https://github.com/clearlyzerolxd/TRDM}{https://github.com/clearlyzerolxd/TRDM}ã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šä¸¤é˜¶æ®µé™é›¨é¢„æµ‹æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šXu DongLing, Chao RongLi*, FengQing Qin, LiHong Zhu, Yuanyuan Huang</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé‡åº†ç†å·¥å¤§å­¦äººå·¥æ™ºèƒ½ä¸å¤§æ•°æ®å­¦é™¢</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€é™é›¨é¢„æµ‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12779ï¼ŒGithub ä»£ç é“¾æ¥ï¼šhttps://github.com/clearlyzerolxd/TRDM</li>
<li>
<p>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦ç¥ç»ç½‘ç»œåœ¨é™é›¨é¢„æµ‹é¢†åŸŸå–å¾—äº†å¾ˆå¤§çš„æˆå°±ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é¢„æµ‹æ–¹æ³•å­˜åœ¨ä¸€å®šçš„å±€é™æ€§ï¼Œä¾‹å¦‚ç”Ÿæˆçš„å›¾åƒæ¨¡ç³Šã€ç©ºé—´ä½ç½®ä¸å‡†ç¡®ç­‰ã€‚
ï¼ˆ2ï¼‰ä»¥å¾€æ–¹æ³•ï¼šé’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œå·²æœ‰ç ”ç©¶æå‡ºäº†å·ç§¯LSTMå’Œå·ç§¯GRUæ¨¡å‹æ¥æé«˜é™é›¨é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨é•¿æœŸçš„é¢„æµ‹ä¸­å­˜åœ¨å‡†ç¡®æ€§ä¸é«˜çš„é—®é¢˜ã€‚æ­¤å¤–ï¼ŒSmaAt-UNetæ¨¡å‹è™½ç„¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰è¾“å…¥åºåˆ—ä¸­çš„å…³é”®ç©ºé—´ä¿¡æ¯ï¼Œä½†åœ¨é•¿æœŸé¢„æµ‹æ€§èƒ½æ–¹é¢ä»æœ‰å¾…æé«˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µé™é›¨é¢„æµ‹æ‰©æ•£æ¨¡å‹ï¼ˆTRDMï¼‰ã€‚TRDMæ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„é™é›¨é¢„æµ‹æ–¹æ³•ã€‚ç¬¬ä¸€é˜¶æ®µçš„ä»»åŠ¡æ˜¯åœ¨ä½åˆ†è¾¨ç‡æ¡ä»¶ä¸‹æ•è·é²æ£’çš„æ—¶é—´ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™ç©ºé—´ä¿¡æ¯ã€‚ç¬¬äºŒé˜¶æ®µçš„ä»»åŠ¡æ˜¯å°†ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„ä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨MRMSå’Œç‘å…¸é›·è¾¾æ•°æ®é›†ä¸Šï¼ŒTRDMå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) é¢„æµ‹æ‰©æ•£æ¨¡å‹ï¼šåˆ©ç”¨ä¸‰ç»´å·ç§¯ç¥ç»ç½‘ç»œç”Ÿæˆ 16 å¸§ 32Ã—32 ä½åˆ†è¾¨ç‡é™é›¨ç»“æœï¼ŒåŒæ—¶ä¿ç•™ä¸€å®šç¨‹åº¦çš„ç©ºé—´ä¿¡æ¯ï¼Œä¸ºåç»­é‡å»ºé˜¶æ®µæä¾›é²æ£’çš„åŸºç¡€ã€‚
(2) ç©ºé—´è¶…åˆ†è¾¨ç‡ï¼šä½¿ç”¨æ‰©æ•£æ¨¡å‹æ„å»ºè¶…åˆ†è¾¨ç‡ç½‘ç»œï¼Œå°†ä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œå¢å¼ºå›¾åƒè´¨é‡å’Œç»†èŠ‚ï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°åˆ†ææœªæ¥é™é›¨çš„å¼ºåº¦å’Œåˆ†å¸ƒã€‚
(3) æ½œåœ¨è¶…åˆ†è¾¨ç‡ï¼šæå‡ºä¸€ç§æ½œåœ¨è¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œå°†é«˜åˆ†è¾¨ç‡å›¾åƒç¼–ç ä¸ºæ½œåœ¨ç©ºé—´ï¼Œç„¶ååˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ¡ä»¶ï¼ŒæŒ‡å¯¼ç”Ÿæˆæ¡ä»¶ã€‚
(4) æ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨ L1 æŸå¤±å‡½æ•°è®­ç»ƒé¢„æµ‹æ‰©æ•£æ¨¡å‹å’Œè¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼Œä»¥æœ€å°åŒ–é¢„æµ‹è¯¯å·®ã€‚
(5) æ¨¡å‹æ¨ç†ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå°†ä½åˆ†è¾¨ç‡å›¾åƒè¾“å…¥åˆ°è¶…åˆ†è¾¨ç‡æ¨¡å‹ä¸­ï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ¡ä»¶ï¼Œé€æ­¥æ¢å¤é«˜åˆ†è¾¨ç‡å›¾åƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µé™é›¨é¢„æµ‹æ‰©æ•£æ¨¡å‹ï¼ˆTRDMï¼‰ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰è¾“å…¥åºåˆ—ä¸­çš„å…³é”®ç©ºé—´ä¿¡æ¯ï¼Œå¹¶åœ¨é•¿æœŸé¢„æµ‹æ€§èƒ½æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
TRDMæ¨¡å‹é‡‡ç”¨äº†ä¸¤é˜¶æ®µçš„é¢„æµ‹ç­–ç•¥ï¼Œç¬¬ä¸€é˜¶æ®µçš„ä»»åŠ¡æ˜¯åœ¨ä½åˆ†è¾¨ç‡æ¡ä»¶ä¸‹æ•è·é²æ£’çš„æ—¶é—´ä¿¡æ¯ï¼ŒåŒæ—¶ä¿ç•™ç©ºé—´ä¿¡æ¯ã€‚ç¬¬äºŒé˜¶æ®µçš„ä»»åŠ¡æ˜¯å°†ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„ä½åˆ†è¾¨ç‡å›¾åƒé‡å»ºä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒã€‚è¿™ç§ä¸¤é˜¶æ®µçš„ç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜é™é›¨é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚
æ€§èƒ½ï¼š
åœ¨MRMSå’Œç‘å…¸é›·è¾¾æ•°æ®é›†ä¸Šï¼ŒTRDMæ¨¡å‹å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼ŒTRDMæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´åŠ æ¸…æ™°å’Œå‡†ç¡®çš„é™é›¨é¢„æµ‹å›¾åƒã€‚
å·¥ä½œé‡ï¼š
TRDMæ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹ç®€å•ã€‚è¯¥æ¨¡å‹åªéœ€è¦å°‘é‡çš„è®­ç»ƒæ•°æ®ï¼Œå¹¶ä¸”è®­ç»ƒæ—¶é—´è¾ƒçŸ­ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒTRDMæ¨¡å‹èƒ½å¤Ÿå¿«é€Ÿåœ°ç”Ÿæˆé™é›¨é¢„æµ‹å›¾åƒã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-77f75079fa9cf15e6ab90ae9bfdf3659.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e40db6d053eb3ccf707a2dbcd4cf2e8d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-1f5823da8ecb8e38058c288533b8775e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf44de1da53f2ab1acf3c0d8075ec068.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b36e8a07f0692df0799659af074a0a49.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-56d34d3e7c52a330e5782ff67a0df331.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4bfaafb452921e1d0c1a1d6c62510229.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5fa91d38aada7882b2ac95950348567d.jpg" align="middle">
</details>




<h2 id="MuLan-Multimodal-LLM-Agent-for-Progressive-Multi-Object-Diffusion"><a href="#MuLan-Multimodal-LLM-Agent-for-Progressive-Multi-Object-Diffusion" class="headerlink" title="MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion"></a>MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion</h2><p><strong>Authors:Sen Li, Ruochen Wang, Cho-Jui Hsieh, Minhao Cheng, Tianyi Zhou</strong></p>
<p>Existing text-to-image models still struggle to generate images of multiple objects, especially in handling their spatial positions, relative sizes, overlapping, and attribute bindings. In this paper, we develop a training-free Multimodal-LLM agent (MuLan) to address these challenges by progressive multi-object generation with planning and feedback control, like a human painter. MuLan harnesses a large language model (LLM) to decompose a prompt to a sequence of sub-tasks, each generating only one object conditioned on previously generated objects by stable diffusion. Unlike existing LLM-grounded methods, MuLan only produces a high-level plan at the beginning while the exact size and location of each object are determined by an LLM and attention guidance upon each sub-task. Moreover, MuLan adopts a vision-language model (VLM) to provide feedback to the image generated in each sub-task and control the diffusion model to re-generate the image if it violates the original prompt. Hence, each model in every step of MuLan only needs to address an easy sub-task it is specialized for. We collect 200 prompts containing multi-objects with spatial relationships and attribute bindings from different benchmarks to evaluate MuLan. The results demonstrate the superiority of MuLan in generating multiple objects over baselines. The code is available on <a href="https://github.com/measure-infinity/mulan-code">https://github.com/measure-infinity/mulan-code</a>. </p>
<p><a href="http://arxiv.org/abs/2402.12741v1">PDF</a> Project website: <a href="https://measure-infinity.github.io/mulan">https://measure-infinity.github.io/mulan</a></p>
<p><strong>Summary</strong><br>å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹åŠ©åŠ›æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¤šå¯¹è±¡å›¾åƒï¼Œåˆ†æ­¥è§„åˆ’ï¼Œåé¦ˆæ§åˆ¶ï¼Œè½»æ¾æ»¡è¶³å¤æ‚è¦æ±‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰çš„æ–‡æœ¬è½¬å›¾åƒæ¨¡å‹åœ¨ç”Ÿæˆå¤šå¯¹è±¡å›¾åƒæ—¶ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¯¹è±¡çš„ç©ºé—´ä½ç½®ã€ç›¸å¯¹å¤§å°ã€é‡å å’Œå±æ€§ç»‘å®šæ–¹é¢ã€‚</li>
<li>MuLan é‡‡ç”¨æ— è®­ç»ƒçš„è®­ç»ƒæ–¹å¼ï¼Œé€šè¿‡è§„åˆ’å’Œåé¦ˆæ§åˆ¶é€æ­¥ç”Ÿæˆå¤šå¯¹è±¡ï¼Œç±»ä¼¼äºäººç±»ç”»å®¶ä½œç”»ã€‚</li>
<li>MuLan åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) å°†æç¤ºåˆ†è§£ä¸ºä¸€ç³»åˆ—å­ä»»åŠ¡ï¼Œæ¯ä¸ªå­ä»»åŠ¡ä»…ç”Ÿæˆä¸€ä¸ªå¯¹è±¡ï¼Œå¹¶é€šè¿‡ç¨³å®šæ‰©æ•£æ¨¡å‹å¯¹å…ˆå‰ç”Ÿæˆçš„å¯¹è±¡è¿›è¡Œæ¡ä»¶æ§åˆ¶ã€‚</li>
<li>ä¸ç°æœ‰çš„ LLM æ–¹æ³•ä¸åŒï¼ŒMuLan åªåœ¨å¼€å§‹æ—¶ç”Ÿæˆä¸€ä¸ªé«˜å±‚æ¬¡çš„è§„åˆ’ï¼Œè€Œæ¯ä¸ªå¯¹è±¡çš„ç¡®åˆ‡å¤§å°å’Œä½ç½®ç”± LLM å’Œæ³¨æ„åŠ›å¼•å¯¼åœ¨æ¯ä¸ªå­ä»»åŠ¡ä¸­ç¡®å®šã€‚</li>
<li>MuLan é‡‡ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (VLM) ä¸ºæ¯ä¸ªå­ä»»åŠ¡ä¸­ç”Ÿæˆçš„å›¾åƒæä¾›åé¦ˆï¼Œå¹¶åœ¨å›¾åƒè¿ååŸå§‹æç¤ºæ—¶æ§åˆ¶æ‰©æ•£æ¨¡å‹é‡æ–°ç”Ÿæˆå›¾åƒã€‚</li>
<li>MuLan åœ¨æ¯ä¸ªæ­¥éª¤ä¸­åªå¤„ç†è‡ªå·±ä¸“é—¨å¤„ç†çš„ç®€å•å­ä»»åŠ¡ã€‚</li>
<li>MuLan åœ¨ä¸åŒåŸºå‡†ä¸Šæ”¶é›†äº† 200 ä¸ªåŒ…å«ç©ºé—´å…³ç³»å’Œå±æ€§ç»‘å®šçš„å¤šå¯¹è±¡æç¤ºæ¥è¯„ä¼° MuLanã€‚ç»“æœè¡¨æ˜ï¼ŒMuLan åœ¨ç”Ÿæˆå¤šå¯¹è±¡æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šMuLanï¼šç”¨äºæ¸è¿›å¼å¤šå¯¹è±¡æ‰©æ•£çš„å¤šæ¨¡æ€-LLM ä»£ç†</li>
<li>ä½œè€…ï¼šSen Liã€Ruochen Wangã€Cho-Jui Hsiehã€Minhao Chengã€Tianyi Zhou</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ç§‘æŠ€å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹ç³»</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€å¤šå¯¹è±¡ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€å¤§è¯­è¨€æ¨¡å‹ã€è§†è§‰è¯­è¨€æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12741
Github é“¾æ¥ï¼šhttps://github.com/measure-infinity/mulan-code</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨ç”ŸæˆåŒ…å«å¤šä¸ªå¯¹è±¡çš„å›¾åƒæ—¶ä»ç„¶å­˜åœ¨å›°éš¾ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¯¹è±¡çš„ç©ºé—´ä½ç½®ã€ç›¸å¯¹å¤§å°ã€é‡å å’Œå±æ€§ç»‘å®šæ–¹é¢ã€‚
(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸€äº›æ–¹æ³•è¯•å›¾åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥æŒ‡å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œä½†ç”±äº LLM çš„ç©ºé—´æ¨ç†èƒ½åŠ›æœ‰é™ä»¥åŠå®ƒä»¬ä¸æ‰©æ•£æ¨¡å‹ç¼ºä¹ä¸€è‡´æ€§ï¼Œå› æ­¤ç›´æ¥ç”Ÿæˆå®Œæ•´ä¸”ç²¾ç¡®çš„å¤šå¯¹è±¡å¸ƒå±€ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å°†å¸ƒå±€ä½œä¸ºå¯¹æ¯ä¸ªæ¨¡å‹çš„é¢å¤–æ¡ä»¶ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´æ‰©æ•£æ¨¡å‹ç”±äºå¯¹å¤æ‚æç¤ºçš„è¯¯è§£è€Œç”Ÿæˆä¸æ­£ç¡®å›¾åƒã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼ï¼Œè¯¥èŒƒå¼ä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€‚è¯¥èŒƒå¼å»ºç«‹åœ¨ç”±å¤šæ¨¡æ€-LLM ä»£ç† (MuLan) è¿›è¡Œçš„æ¸è¿›å¼å¤šå¯¹è±¡ç”Ÿæˆä¹‹ä¸Šï¼ŒMuLan æ¯ä¸ªé˜¶æ®µåªç”Ÿæˆä¸€ä¸ªå¯¹è±¡ï¼Œå¹¶æ ¹æ®å›¾åƒä¸­å·²ç”Ÿæˆçš„å¯¹è±¡å’Œæœ€æœ‰å¯èƒ½æ”¾ç½®æ–°å¯¹è±¡çš„ä½ç½®çš„æ³¨æ„åŠ›æ©ç è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚æ­¤å¤–ï¼ŒMuLan é‡‡ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (VLM) æ¥æä¾›å¯¹æ¯ä¸ªå­ä»»åŠ¡ä¸­ç”Ÿæˆçš„å›¾åƒçš„åé¦ˆï¼Œå¹¶æ§åˆ¶æ‰©æ•£æ¨¡å‹ä»¥é‡æ–°ç”Ÿæˆå›¾åƒï¼ˆå¦‚æœå®ƒè¿åäº†åŸå§‹æç¤ºï¼‰ã€‚
(4) å®éªŒç»“æœä¸æ€§èƒ½ï¼šåœ¨åŒ…å«æ¥è‡ªä¸åŒåŸºå‡†çš„å¤šå¯¹è±¡ï¼ˆå…·æœ‰ç©ºé—´å…³ç³»å’Œå±æ€§ç»‘å®šï¼‰çš„ 200 ä¸ªæç¤ºä¸Šè¯„ä¼° MuLanã€‚ç»“æœè¡¨æ˜ï¼ŒMuLan åœ¨ç”Ÿæˆå¤šå¯¹è±¡æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³å¼€å‘ä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼ï¼Œè¯¥èŒƒå¼ä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼ï¼Œè¯¥èŒƒå¼ä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šè¯¥èŒƒå¼å»ºç«‹åœ¨ç”±å¤šæ¨¡æ€-LLMä»£ç†ï¼ˆMuLanï¼‰è¿›è¡Œçš„æ¸è¿›å¼å¤šå¯¹è±¡ç”Ÿæˆä¹‹ä¸Šï¼ŒMuLanæ¯ä¸ªé˜¶æ®µåªç”Ÿæˆä¸€ä¸ªå¯¹è±¡ï¼Œå¹¶æ ¹æ®å›¾åƒä¸­å·²ç”Ÿæˆçš„å¯¹è±¡å’Œæœ€æœ‰å¯èƒ½æ”¾ç½®æ–°å¯¹è±¡çš„ä½ç½®çš„æ³¨æ„åŠ›æ©ç è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚
ï¼ˆ3ï¼‰ï¼šé‡‡ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ¥æä¾›å¯¹æ¯ä¸ªå­ä»»åŠ¡ä¸­ç”Ÿæˆçš„å›¾åƒçš„åé¦ˆï¼Œå¹¶æ§åˆ¶æ‰©æ•£æ¨¡å‹ä»¥é‡æ–°ç”Ÿæˆå›¾åƒï¼ˆå¦‚æœå®ƒè¿åäº†åŸå§‹æç¤ºï¼‰ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼MuLanï¼Œè¯¥èŒƒå¼ä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ï¼Œåœ¨ç”Ÿæˆå¤šå¯¹è±¡æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
MuLanï¼šä¸€ç§æ— è®­ç»ƒä¸”å¯æ§çš„æ–‡æœ¬åˆ°å›¾åƒç”ŸæˆèŒƒå¼ï¼Œä¸éœ€è¦æ¼”ç¤ºï¼Œè€Œæ˜¯ä¸»è¦å…³æ³¨æ”¹è¿›ç°æœ‰æ¨¡å‹çš„å·¥å…·ä½¿ç”¨ã€‚
æ¸è¿›å¼å¤šå¯¹è±¡ç”Ÿæˆï¼šMuLanæ¯ä¸ªé˜¶æ®µåªç”Ÿæˆä¸€ä¸ªå¯¹è±¡ï¼Œå¹¶æ ¹æ®å›¾åƒä¸­å·²ç”Ÿæˆçš„å¯¹è±¡å’Œæœ€æœ‰å¯èƒ½æ”¾ç½®æ–°å¯¹è±¡çš„ä½ç½®çš„æ³¨æ„åŠ›æ©ç è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚
è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼šé‡‡ç”¨VLMæ¥æä¾›å¯¹æ¯ä¸ªå­ä»»åŠ¡ä¸­ç”Ÿæˆçš„å›¾åƒçš„åé¦ˆï¼Œå¹¶æ§åˆ¶æ‰©æ•£æ¨¡å‹ä»¥é‡æ–°ç”Ÿæˆå›¾åƒï¼ˆå¦‚æœå®ƒè¿åäº†åŸå§‹æç¤ºï¼‰ã€‚
æ€§èƒ½ï¼š
åœ¨åŒ…å«æ¥è‡ªä¸åŒåŸºå‡†çš„å¤šå¯¹è±¡ï¼ˆå…·æœ‰ç©ºé—´å…³ç³»å’Œå±æ€§ç»‘å®šï¼‰çš„200ä¸ªæç¤ºä¸Šè¯„ä¼°MuLanã€‚ç»“æœè¡¨æ˜ï¼ŒMuLanåœ¨ç”Ÿæˆå¤šå¯¹è±¡æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
MuLançš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦é¢å¤–çš„è®­ç»ƒæˆ–æ•°æ®ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6204318646d6f8f073e72dd012036b52.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-339c08e21eaf72db7bf6af40d44b1ebd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9c764cf1c9de7293c1a1c79a15a87313.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-5f2c4d6c6e5f00fd67d4a729192f3826.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-85b2bad757801f5c51069e7f6c02cbc7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9001380fef222e92159ed423b319dc8a.jpg" align="middle">
</details>




<h2 id="Improving-Deep-Generative-Models-on-Many-To-One-Image-to-Image-Translation"><a href="#Improving-Deep-Generative-Models-on-Many-To-One-Image-to-Image-Translation" class="headerlink" title="Improving Deep Generative Models on Many-To-One Image-to-Image   Translation"></a>Improving Deep Generative Models on Many-To-One Image-to-Image   Translation</h2><p><strong>Authors:Sagar Saxena, Mohammad Nayeem Teli</strong></p>
<p>Deep generative models have been applied to multiple applications in image-to-image translation. Generative Adversarial Networks and Diffusion Models have presented impressive results, setting new state-of-the-art results on these tasks. Most methods have symmetric setups across the different domains in a dataset. These methods assume that all domains have either multiple modalities or only one modality. However, there are many datasets that have a many-to-one relationship between two domains. In this work, we first introduce a Colorized MNIST dataset and a Color-Recall score that can provide a simple benchmark for evaluating models on many-to-one translation. We then introduce a new asymmetric framework to improve existing deep generative models on many-to-one image-to-image translation. We apply this framework to StarGAN V2 and show that in both unsupervised and semi-supervised settings, the performance of this new model improves on many-to-one image-to-image translation. </p>
<p><a href="http://arxiv.org/abs/2402.12531v1">PDF</a> 11 pages, 6 figures</p>
<p><strong>æ‘˜è¦</strong><br>ç”¨æ·±åº¦æ‰©æ•£æ¨¡å‹æ”¹è¿›å¤šå¯¹ä¸€çš„å›¾åƒåˆ°å›¾åƒç¿»è¯‘ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æ·±åº¦æ‰©æ•£æ¨¡å‹æ˜¯ç”¨äºå›¾åƒåˆ°å›¾åƒç¿»è¯‘çš„ç”Ÿæˆæ¨¡å‹ã€‚</li>
<li>ç°æœ‰çš„æ–¹æ³•é€šå¸¸å‡è®¾æ‰€æœ‰é¢†åŸŸéƒ½å…·æœ‰å¤šä¸ªæ¨¡æ€æˆ–åªæœ‰ä¸€ä¸ªæ¨¡æ€ã€‚</li>
<li>åœ¨è®¸å¤šåœºæ™¯ä¸‹ï¼Œä¸¤ä¸ªé¢†åŸŸä¹‹é—´å­˜åœ¨å¤šå¯¹ä¸€çš„å…³ç³»ã€‚</li>
<li>ç ”ç©¶è€…æå‡ºäº†ä¸€ä¸ªç€è‰² MNIST æ•°æ®é›†å’Œä¸€ä¸ªå½©è‰²å¬å›åˆ†æ•°ï¼Œä¸ºå¤šå¯¹ä¸€ç¿»è¯‘æä¾›äº†ä¸€ä¸ªç®€å•çš„åŸºå‡†ã€‚</li>
<li>æå‡ºä¸€ç§æ–°çš„éå¯¹ç§°æ¡†æ¶æ¥æ”¹è¿›ç°æœ‰æ·±åº¦ç”Ÿæˆæ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚</li>
<li>å°†è¯¥æ¡†æ¶åº”ç”¨äº StarGAN V2ï¼Œå®éªŒè¡¨æ˜ï¼Œåœ¨æ–°æ¨¡å‹ä¸­ï¼Œæ— ç›‘ç£å’ŒåŠç›‘ç£è®¾ç½®ä¸‹çš„å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘æ€§èƒ½å‡å¾—åˆ°æé«˜ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šæ”¹è¿›å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ·±åº¦ç”Ÿæˆæ¨¡å‹</li>
<li>ä½œè€…ï¼šSagar Saxena, Mohammad Nayeem Teli</li>
<li>éš¶å±å…³ç³»ï¼šé©¬é‡Œå…°å¤§å­¦è®¡ç®—æœºç§‘å­¦ç³»</li>
<li>å…³é”®è¯ï¼šæ·±åº¦ç”Ÿæˆæ¨¡å‹ã€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ã€å¤šå¯¹ä¸€ç¿»è¯‘ã€éå¯¹ç§°æ¡†æ¶</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12531</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦ç”Ÿæˆæ¨¡å‹å·²å¹¿æ³›åº”ç”¨äºå›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­ï¼Œå–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„ç»“æœã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°æ–¹æ³•åœ¨ä¸åŒé¢†åŸŸä¹‹é—´é‡‡ç”¨å¯¹ç§°è®¾ç½®ï¼Œå‡è®¾æ‰€æœ‰é¢†åŸŸéƒ½å…·æœ‰å¤šæ¨¡æ€æˆ–å•ä¸€æ¨¡æ€ã€‚ç„¶è€Œï¼Œè®¸å¤šæ•°æ®é›†åœ¨ä¸¤ä¸ªé¢†åŸŸä¹‹é—´å…·æœ‰å¤šå¯¹ä¸€çš„å…³ç³»ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•è¦ä¹ˆå­¦ä¹ åŒå°„æ˜ å°„ï¼Œè¦ä¹ˆå­¦ä¹ å¤šå¯¹å¤šæ˜ å°„ï¼Œä½†è¿™äº›æ–¹æ³•æ— æ³•å‡†ç¡®å»ºæ¨¡æŸäº›ä»»åŠ¡ä¸­é¢†åŸŸä¹‹é—´çš„å…³ç³»ï¼Œä¾‹å¦‚å›¾åƒç€è‰²ã€è¯­ä¹‰åˆ†å‰²ã€æ·±åº¦ä¼°è®¡ç­‰ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„éå¯¹ç§°æ¡†æ¶æ¥æ”¹è¿›ç°æœ‰æ·±åº¦ç”Ÿæˆæ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚è¯¥æ¡†æ¶å°†ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨æ¨¡å—è§£è€¦ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°æ¥é¼“åŠ±ç”Ÿæˆå™¨ç”Ÿæˆä¸è¾“å…¥å›¾åƒç›¸ä¼¼çš„è¾“å‡ºå›¾åƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæœ¬æ–‡å°†è¯¥æ¡†æ¶åº”ç”¨äº StarGAN V2 æ¨¡å‹ï¼Œå¹¶åœ¨æ— ç›‘ç£å’ŒåŠç›‘ç£è®¾ç½®ä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶å¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„éå¯¹ç§°æ¡†æ¶æ¥æ”¹è¿›ç°æœ‰æ·±åº¦ç”Ÿæˆæ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ï¼Œè¯¥æ¡†æ¶å¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„éå¯¹ç§°æ¡†æ¶ï¼Œå°†ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨æ¨¡å—è§£è€¦ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„æŸå¤±å‡½æ•°æ¥é¼“åŠ±ç”Ÿæˆå™¨ç”Ÿæˆä¸è¾“å…¥å›¾åƒç›¸ä¼¼çš„è¾“å‡ºå›¾åƒã€‚</li>
<li>å°†è¯¥æ¡†æ¶åº”ç”¨äºStarGANV2æ¨¡å‹ï¼Œå¹¶åœ¨æ— ç›‘ç£å’ŒåŠç›‘ç£è®¾ç½®ä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚</li>
<li>ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶å¯ä»¥æœ‰æ•ˆæé«˜æ¨¡å‹åœ¨å¤šå¯¹ä¸€å›¾åƒåˆ°å›¾åƒç¿»è¯‘ä¸­çš„æ€§èƒ½ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨æ— ç›‘ç£è®¾ç½®ä¸­ï¼Œè¯¥æ¡†æ¶åœ¨CelebAæ•°æ®é›†ä¸Šå–å¾—äº†æ¯”StarGANV2æ¨¡å‹æ›´é«˜çš„FIDå’ŒLPIPSå¾—åˆ†ã€‚</li>
<li>åœ¨åŠç›‘ç£è®¾ç½®ä¸­ï¼Œè¯¥æ¡†æ¶åœ¨CelebAæ•°æ®é›†ä¸Šå–å¾—äº†æ¯”StarGANV2æ¨¡å‹æ›´é«˜çš„FIDå’ŒLPIPSå¾—åˆ†ã€‚</li>
<li>åœ¨Cityscapesæ•°æ®é›†ä¸Šï¼Œè¯¥æ¡†æ¶å–å¾—äº†æ¯”StarGANV2æ¨¡å‹æ›´é«˜çš„mIoUå’ŒF1å¾—åˆ†ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ¡†æ¶çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¯ä»¥åœ¨TensorFlowæˆ–PyTorchç­‰æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­è½»æ¾å®ç°ã€‚</li>
<li>è¯¥æ¡†æ¶çš„è®­ç»ƒæ—¶é—´ä¸StarGANV2æ¨¡å‹ç›¸ä¼¼ã€‚</li>
<li>è¯¥æ¡†æ¶çš„æ¨ç†æ—¶é—´ä¸StarGANV2æ¨¡å‹ç›¸ä¼¼ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-847aa6560da9e8f5bc3efa20a3a60ab6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0b87108e9e8879c6d14d1fe6eaf34112.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e7677caf8041932830de453431d2abd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-50784d0e85e2b28f9cc755ede524a772.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9b40dd37bb889c7e90ab259793c5ab5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df01b0bd8844297db8557dc012591bb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-af0a71391ad75be3ea34e547daa4db1e.jpg" align="middle">
</details>




<h2 id="FiT-Flexible-Vision-Transformer-for-Diffusion-Model"><a href="#FiT-Flexible-Vision-Transformer-for-Diffusion-Model" class="headerlink" title="FiT: Flexible Vision Transformer for Diffusion Model"></a>FiT: Flexible Vision Transformer for Diffusion Model</h2><p><strong>Authors:Zeyu Lu, Zidong Wang, Di Huang, Chengyue Wu, Xihui Liu, Wanli Ouyang, Lei Bai</strong></p>
<p>Nature is infinitely resolution-free. In the context of this reality, existing diffusion models, such as Diffusion Transformers, often face challenges when processing image resolutions outside of their trained domain. To overcome this limitation, we present the Flexible Vision Transformer (FiT), a transformer architecture specifically designed for generating images with unrestricted resolutions and aspect ratios. Unlike traditional methods that perceive images as static-resolution grids, FiT conceptualizes images as sequences of dynamically-sized tokens. This perspective enables a flexible training strategy that effortlessly adapts to diverse aspect ratios during both training and inference phases, thus promoting resolution generalization and eliminating biases induced by image cropping. Enhanced by a meticulously adjusted network structure and the integration of training-free extrapolation techniques, FiT exhibits remarkable flexibility in resolution extrapolation generation. Comprehensive experiments demonstrate the exceptional performance of FiT across a broad range of resolutions, showcasing its effectiveness both within and beyond its training resolution distribution. Repository available at <a href="https://github.com/whlzy/FiT">https://github.com/whlzy/FiT</a>. </p>
<p><a href="http://arxiv.org/abs/2402.12376v1">PDF</a> </p>
<p><strong>Summary</strong><br>é€šè¿‡å°†å›¾åƒè§†ä¸ºåŠ¨æ€å¤§å°æ ‡è®°åºåˆ—ï¼Œå¼¹æ€§è§†è§‰å˜æ¢å™¨å¯åœ¨ä¸åŒåˆ†è¾¨ç‡å’Œå®½é«˜æ¯”ä¸Šç”Ÿæˆå›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰æ‰©æ•£æ¨¡å‹åœ¨å¤„ç†è®­ç»ƒåŸŸä¹‹å¤–çš„å›¾åƒåˆ†è¾¨ç‡æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
<li>å¼¹æ€§è§†è§‰å˜æ¢å™¨ (FiT) æ˜¯ä¸€ç§ä¸“ä¸ºç”Ÿæˆä¸å—é™åˆ†è¾¨ç‡å’Œå®½é«˜æ¯”çš„å›¾åƒè€Œè®¾è®¡çš„è½¬æ¢å™¨æ¶æ„ã€‚</li>
<li>FiT å°†å›¾åƒè§†ä¸ºåŠ¨æ€å¤§å°æ ‡è®°åºåˆ—ï¼Œä»è€Œæ”¯æŒä¸åŒçš„å®½é«˜æ¯”ã€‚</li>
<li>FiT åœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µå‡æ”¯æŒä¸åŒçš„å®½é«˜æ¯”ï¼Œä»è€Œæ¶ˆé™¤äº†å›¾åƒè£å‰ªå¼•èµ·çš„åå·®ã€‚</li>
<li>FiT åœ¨å¤šç§åˆ†è¾¨ç‡ä¸‹è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜å…¶åœ¨è®­ç»ƒåˆ†è¾¨ç‡åˆ†å¸ƒä¹‹å¤–ä¹Ÿå¾ˆæœ‰æ•ˆã€‚</li>
<li>FiT çš„å­˜å‚¨åº“ä½äº <a href="https://github.com/whlzy/FiTã€‚">https://github.com/whlzy/FiTã€‚</a></li>
<li>FiT ä¸ºå›¾åƒç”Ÿæˆé¢†åŸŸå¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šFiTï¼šç”¨äºæ‰©æ•£æ¨¡å‹çš„çµæ´»è§†è§‰å˜æ¢å™¨</li>
<li>ä½œè€…ï¼šZeyu Lu<em>ï¼ŒZidong Wang</em>ï¼ŒDi Huangï¼ŒChengyue Wuï¼ŒXihui Liuï¼ŒWanli Ouyangï¼ŒLei Bai</li>
<li>å•ä½ï¼šä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ï¼Œè§†è§‰å˜æ¢å™¨ï¼Œåˆ†è¾¨ç‡æ³›åŒ–ï¼Œå¤–æ¨æŠ€æœ¯</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.12376ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè‡ªç„¶ç•Œçš„å›¾åƒåˆ†è¾¨ç‡æ˜¯æ— é™çš„ã€‚ç°æœ‰çš„æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚æ‰©æ•£å˜æ¢å™¨ï¼‰åœ¨å¤„ç†è¶…å‡ºå…¶è®­ç»ƒåŸŸçš„å›¾åƒåˆ†è¾¨ç‡æ—¶å¾€å¾€é¢ä¸´æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ä¸é—®é¢˜ï¼šä¼ ç»Ÿæ–¹æ³•å°†å›¾åƒè§†ä¸ºé™æ€åˆ†è¾¨ç‡ç½‘æ ¼ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬å¤„ç†ä¸åŒåˆ†è¾¨ç‡å›¾åƒçš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå›¾åƒè£å‰ªä¼šå¼•å…¥åå·®ï¼Œå½±å“æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†çµæ´»è§†è§‰å˜æ¢å™¨ï¼ˆFiTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºç”Ÿæˆå…·æœ‰æ— é™åˆ†è¾¨ç‡å’Œçºµæ¨ªæ¯”çš„å›¾åƒè€Œè®¾è®¡çš„å˜æ¢å™¨æ¶æ„ã€‚FiT å°†å›¾åƒæ¦‚å¿µåŒ–ä¸ºåŠ¨æ€å¤§å°æ ‡è®°çš„åºåˆ—ï¼Œè¿™ä½¿å¾—å®ƒèƒ½å¤Ÿåœ¨è®­ç»ƒå’Œæ¨ç†é˜¶æ®µè½»æ¾é€‚åº”ä¸åŒçš„çºµæ¨ªæ¯”ï¼Œä»è€Œä¿ƒè¿›äº†åˆ†è¾¨ç‡æ³›åŒ–å¹¶æ¶ˆé™¤äº†å›¾åƒè£å‰ªå¼•èµ·çš„åå·®ã€‚é€šè¿‡ç²¾å¿ƒè°ƒæ•´çš„ç½‘ç»œç»“æ„å’Œè®­ç»ƒè‡ªç”±å¤–æ¨æŠ€æœ¯çš„é›†æˆï¼ŒFiT åœ¨åˆ†è¾¨ç‡å¤–æ¨ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„çµæ´»æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šç»¼åˆå®éªŒè¡¨æ˜ï¼ŒFiT åœ¨å¹¿æ³›çš„åˆ†è¾¨ç‡èŒƒå›´å†…è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨è®­ç»ƒåˆ†è¾¨ç‡åˆ†å¸ƒå†…å’Œä¹‹å¤–çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š</p>
<p>ï¼ˆ1ï¼‰çµæ´»è®­ç»ƒï¼šæå‡ºäº†ä¸€ç§çµæ´»çš„è®­ç»ƒæ–¹æ³•ï¼Œå…è®¸æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¤„ç†ä¸åŒçºµæ¨ªæ¯”çš„å›¾åƒï¼Œä»è€Œä¿ƒè¿›åˆ†è¾¨ç‡æ³›åŒ–å¹¶æ¶ˆé™¤å›¾åƒè£å‰ªå¼•èµ·çš„åå·®ã€‚</p>
<p>ï¼ˆ2ï¼‰SwiGLUæ¿€æ´»å‡½æ•°ï¼šå°†MLPæ¿€æ´»å‡½æ•°æ›¿æ¢ä¸ºSwiGLUæ¿€æ´»å‡½æ•°ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
<p>ï¼ˆ3ï¼‰2DRoPEä½ç½®ç¼–ç ï¼šå°†ç»å¯¹ä½ç½®ç¼–ç æ›¿æ¢ä¸º2DRoPEä½ç½®ç¼–ç ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½å’Œå¤–æ¨èƒ½åŠ›ã€‚</p>
<p>ï¼ˆ4ï¼‰ä½ç½®åµŒå…¥æ’å€¼æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§ä½ç½®åµŒå…¥æ’å€¼æ–¹æ³•ï¼Œå¯ä»¥å°†æ¨¡å‹çš„å¤–æ¨èƒ½åŠ›æ‰©å±•åˆ°è®­ç»ƒåˆ†å¸ƒä¹‹å¤–çš„åˆ†è¾¨ç‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œçš„ä¸»è¦è´¡çŒ®åœ¨äºï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºæ‰©æ•£æ¨¡å‹çš„çµæ´»è§†è§‰å˜æ¢å™¨ï¼ˆFiTï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ä¸ºç”Ÿæˆå…·æœ‰æ— é™åˆ†è¾¨ç‡å’Œçºµæ¨ªæ¯”çš„å›¾åƒè€Œè®¾è®¡çš„å˜æ¢å™¨æ¶æ„ã€‚FiT åœ¨å¹¿æ³›çš„åˆ†è¾¨ç‡èŒƒå›´å†…è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨è®­ç»ƒåˆ†è¾¨ç‡åˆ†å¸ƒå†…å’Œä¹‹å¤–çš„æœ‰æ•ˆæ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§çµæ´»çš„è®­ç»ƒæ–¹æ³•ï¼Œå…è®¸æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¤„ç†ä¸åŒçºµæ¨ªæ¯”çš„å›¾åƒï¼Œä»è€Œä¿ƒè¿›åˆ†è¾¨ç‡æ³›åŒ–å¹¶æ¶ˆé™¤å›¾åƒè£å‰ªå¼•èµ·çš„åå·®ã€‚</li>
<li>å°† MLP æ¿€æ´»å‡½æ•°æ›¿æ¢ä¸º SwiGLU æ¿€æ´»å‡½æ•°ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>å°†ç»å¯¹ä½ç½®ç¼–ç æ›¿æ¢ä¸º 2DRoPE ä½ç½®ç¼–ç ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½å’Œå¤–æ¨èƒ½åŠ›ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ä½ç½®åµŒå…¥æ’å€¼æ–¹æ³•ï¼Œå¯ä»¥å°†æ¨¡å‹çš„å¤–æ¨èƒ½åŠ›æ‰©å±•åˆ°è®­ç»ƒåˆ†å¸ƒä¹‹å¤–çš„åˆ†è¾¨ç‡ã€‚
æ€§èƒ½ï¼š</li>
<li>FiT åœ¨å¹¿æ³›çš„åˆ†è¾¨ç‡èŒƒå›´å†…è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨è®­ç»ƒåˆ†è¾¨ç‡åˆ†å¸ƒå†…å’Œä¹‹å¤–çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>FiT åœ¨å„ç§åˆ†è¾¨ç‡ä¸‹å‡ä¼˜äºæ‰€æœ‰å…ˆå‰æ¨¡å‹ï¼Œæ— è®ºæ˜¯åŸºäº Transformer çš„è¿˜æ˜¯åŸºäº CNN çš„ã€‚</li>
<li>ç»“åˆæˆ‘ä»¬çš„åˆ†è¾¨ç‡å¤–æ¨æ–¹æ³• VisionNTKï¼ŒFiT çš„æ€§èƒ½å¾—åˆ°äº†è¿›ä¸€æ­¥æ˜¾ç€æå‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œæ¶‰åŠåˆ°æ¨¡å‹æ¶æ„è®¾è®¡ã€è®­ç»ƒæ–¹æ³•æ”¹è¿›ã€å¤–æ¨æŠ€æœ¯é›†æˆç­‰å¤šä¸ªæ–¹é¢ã€‚</li>
<li>æœ¬æ–‡çš„å®éªŒéƒ¨åˆ†ä¹Ÿæ¯”è¾ƒå¤æ‚ï¼Œæ¶‰åŠåˆ°å¤šä¸ªæ•°æ®é›†ã€å¤šä¸ªåˆ†è¾¨ç‡ã€å¤šä¸ªè¯„ä»·æŒ‡æ ‡ç­‰ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f2dad57fd66943bffc8c0eefec68b3e8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-297eceedf1e98b27794f86f0cb8285ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6760b58ea1f0ee4f73bf15eae4ddb673.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-09693fd0b9790328fcc71c49c26da3ad.jpg" align="middle">
</details>




<h2 id="Direct-Consistency-Optimization-for-Compositional-Text-to-Image-Personalization"><a href="#Direct-Consistency-Optimization-for-Compositional-Text-to-Image-Personalization" class="headerlink" title="Direct Consistency Optimization for Compositional Text-to-Image   Personalization"></a>Direct Consistency Optimization for Compositional Text-to-Image   Personalization</h2><p><strong>Authors:Kyungmin Lee, Sangkyung Kwak, Kihyuk Sohn, Jinwoo Shin</strong></p>
<p>Text-to-image (T2I) diffusion models, when fine-tuned on a few personal images, are able to generate visuals with a high degree of consistency. However, they still lack in synthesizing images of different scenarios or styles that are possible in the original pretrained models. To address this, we propose to fine-tune the T2I model by maximizing consistency to reference images, while penalizing the deviation from the pretrained model. We devise a novel training objective for T2I diffusion models that minimally fine-tunes the pretrained model to achieve consistency. Our method, dubbed \emph{Direct Consistency Optimization}, is as simple as regular diffusion loss, while significantly enhancing the compositionality of personalized T2I models. Also, our approach induces a new sampling method that controls the tradeoff between image fidelity and prompt fidelity. Lastly, we emphasize the necessity of using a comprehensive caption for reference images to further enhance the image-text alignment. We show the efficacy of the proposed method on the T2I personalization for subject, style, or both. In particular, our method results in a superior Pareto frontier to the baselines. Generated examples and codes are in our project page( <a href="https://dco-t2i.github.io/">https://dco-t2i.github.io/</a>). </p>
<p><a href="http://arxiv.org/abs/2402.12004v1">PDF</a> Preprint. See our project page (<a href="https://dco-t2i.github.io/">https://dco-t2i.github.io/</a>) for more   examples and codes</p>
<p><strong>Summary</strong><br>åŸºäºæ–‡æœ¬ç”Ÿæˆå›¾åƒçš„æ‰©æ•£æ¨¡å‹å¯é€šè¿‡å¾®è°ƒå°‘æ•°ä¸ªäººå›¾åƒç”Ÿæˆé«˜åº¦ä¸€è‡´çš„è§†è§‰æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¾®è°ƒåŸºäºæ–‡æœ¬ç”Ÿæˆå›¾åƒçš„æ‰©æ•£æ¨¡å‹æ—¶ï¼Œæœ€å¤§åŒ–ä¸å‚è€ƒå›¾åƒçš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶æƒ©ç½šä¸é¢„è®­ç»ƒæ¨¡å‹çš„åå·®ã€‚</li>
<li>æå‡ºä¸€ç§æœ€å°åŒ–å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä»¥å®ç°ä¸€è‡´æ€§çš„æ–°é¢–è®­ç»ƒç›®æ ‡ã€‚</li>
<li>è¯¥æ–¹æ³•ç®€å•ä¸”æœ‰æ•ˆï¼Œæ˜¾ç€å¢å¼ºäº†ä¸ªæ€§åŒ–åŸºäºæ–‡æœ¬ç”Ÿæˆå›¾åƒæ¨¡å‹çš„ç»„åˆæ€§ã€‚</li>
<li>å¼•å…¥ä¸€ç§æ–°çš„é‡‡æ ·æ–¹æ³•ä»¥æ§åˆ¶å›¾åƒä¿çœŸåº¦ä¸æç¤ºä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚</li>
<li>å¼ºè°ƒä½¿ç”¨ç»¼åˆæ ‡é¢˜ä½œä¸ºå‚è€ƒå›¾åƒä»¥è¿›ä¸€æ­¥å¢å¼ºå›¾åƒä¸æ–‡æœ¬çš„ä¸€è‡´æ€§ã€‚</li>
<li>è¯æ˜äº†è¯¥æ–¹æ³•åœ¨ä¸»é¢˜ã€é£æ ¼æˆ–ä¸¤è€…æ–¹é¢çš„åŸºäºæ–‡æœ¬ç”Ÿæˆå›¾åƒä¸ªæ€§åŒ–ä¸­çš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šç›´æ¥ä¸€è‡´æ€§ä¼˜åŒ–ç”¨äºåˆæˆæ–‡æœ¬åˆ°å›¾åƒä¸ªæ€§åŒ–</li>
<li>ä½œè€…ï¼šSeunghoon Hong, Inwoong Ko, Sunghyun Cho, Seonghyeon Nam, Dong Huk Park</li>
<li>éš¶å±æœºæ„ï¼šé¦–å°”å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒåˆæˆã€ä¸ªæ€§åŒ–ã€æ‰©æ•£æ¨¡å‹ã€ä¸€è‡´æ€§ä¼˜åŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒ (T2I) æ‰©æ•£æ¨¡å‹åœ¨ç»è¿‡å°‘é‡ä¸ªäººå›¾åƒçš„å¾®è°ƒåï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰é«˜åº¦ä¸€è‡´æ€§çš„è§†è§‰æ•ˆæœã€‚ç„¶è€Œï¼Œå®ƒä»¬ä»ç„¶ç¼ºä¹åœ¨åŸå§‹é¢„è®­ç»ƒæ¨¡å‹ä¸­å¯èƒ½çš„ä¸åŒåœºæ™¯æˆ–é£æ ¼çš„å›¾åƒåˆæˆèƒ½åŠ›ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡æœ€å¤§åŒ–ä¸å‚è€ƒå›¾åƒçš„ä¸€è‡´æ€§æ¥å¾®è°ƒ T2I æ¨¡å‹çš„æ–¹æ³•ï¼ŒåŒæ—¶æƒ©ç½šä¸é¢„è®­ç»ƒæ¨¡å‹çš„åå·®ã€‚è¿‡å»çš„æ–¹æ³•å­˜åœ¨çš„é—®é¢˜æ˜¯ï¼Œå®ƒä»¬åœ¨ä¸ªæ€§åŒ– T2I æ¨¡å‹ä¸­ä»ç„¶ç¼ºä¹åˆæˆä¸åŒåœºæ™¯æˆ–é£æ ¼çš„å›¾åƒçš„èƒ½åŠ›ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ T2I æ‰©æ•£æ¨¡å‹è®­ç»ƒç›®æ ‡ï¼Œè¯¥ç›®æ ‡å¯ä»¥æœ€å°ç¨‹åº¦åœ°å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä»¥å®ç°ä¸€è‡´æ€§ã€‚è¯¥æ–¹æ³•ç§°ä¸ºç›´æ¥ä¸€è‡´æ€§ä¼˜åŒ–ï¼Œå®ƒä¸å¸¸è§„æ‰©æ•£æŸå¤±ä¸€æ ·ç®€å•ï¼ŒåŒæ—¶æ˜¾ç€æé«˜äº†ä¸ªæ€§åŒ– T2I æ¨¡å‹çš„ç»„åˆæ€§ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡çš„æ–¹æ³•è¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ§åˆ¶å›¾åƒä¿çœŸåº¦ä¸æç¤ºä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚æœ€åï¼Œæœ¬æ–‡å¼ºè°ƒäº†ä½¿ç”¨ç»¼åˆæ ‡é¢˜ä½œä¸ºå‚è€ƒå›¾åƒçš„å¿…è¦æ€§ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºå›¾åƒä¸æ–‡æœ¬çš„å¯¹é½ã€‚
(4)ï¼šå®éªŒç»“æœï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨ä¸»é¢˜ã€é£æ ¼æˆ–ä¸¤è€…å…¼è€Œæœ‰ä¹‹çš„ T2I ä¸ªæ€§åŒ–æ–¹é¢éƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å¸•ç´¯æ‰˜å‰æ²¿æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚</li>
</ol>
<p>Methods:
(1) Direct Consistency Optimization (DCO): We formulate T2I diffusion model fine-tuning as a constrained policy optimization problem and propose DCO loss to maximize the consistency reward of generated samples while penalizing the deviation from the pretrained model.
(2) Reward Guidance (RG): After fine-tuning with DCO loss, we introduce RG to control the trade-off between consistency and image-text alignment by interpolating the noise estimations from the fine-tuned model and the pretrained model.
(3) Prompt Construction for Reference Images: We emphasize the importance of comprehensive captions for reference images and provide examples to illustrate the difference between compact captions and comprehensive captions.</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è®­ç»ƒç›®æ ‡ï¼Œè¯¥ç›®æ ‡å¯ä»¥æœ€å°ç¨‹åº¦åœ°å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä»¥å®ç°ä¸€è‡´æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è®­ç»ƒç›®æ ‡ï¼Œè¯¥ç›®æ ‡å¯ä»¥æœ€å°ç¨‹åº¦åœ°å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ä»¥å®ç°ä¸€è‡´æ€§ã€‚
å¼•å…¥äº†ä¸€ç§æ–°çš„é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ§åˆ¶å›¾åƒä¿çœŸåº¦ä¸æç¤ºä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡ã€‚
å¼ºè°ƒäº†ä½¿ç”¨ç»¼åˆæ ‡é¢˜ä½œä¸ºå‚è€ƒå›¾åƒçš„å¿…è¦æ€§ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºå›¾åƒä¸æ–‡æœ¬çš„å¯¹é½ã€‚
æ€§èƒ½ï¼š
åœ¨ä¸»é¢˜ã€é£æ ¼æˆ–ä¸¤è€…å…¼è€Œæœ‰ä¹‹çš„æ–‡æœ¬åˆ°å›¾åƒä¸ªæ€§åŒ–æ–¹é¢éƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚
åœ¨å¸•ç´¯æ‰˜å‰æ²¿æ–¹é¢ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
éœ€è¦æ”¶é›†å’Œå‡†å¤‡å‚è€ƒå›¾åƒã€‚
éœ€è¦å¾®è°ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚
éœ€è¦é‡‡æ ·ç”Ÿæˆçš„å›¾åƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-747445a04d574a8975290f4c0ffe6aca.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-915bf11d3f533330ed7c94f5f635e501.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3a074dca6974482c499ea0392640cb3.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/02/29/Paper/2024-02-29/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-29-æ›´æ–°"><a href="#2024-02-29-æ›´æ–°" class="headerlink" title="2024-02-29 æ›´æ–°"></a>2024-02-29 æ›´æ–°</h1><h2 id="VastGaussian-Vast-3D-Gaussians-for-Large-Scene-Reconstruction"><a href="#VastGaussian-Vast-3D-Gaussians-for-Large-Scene-Reconstruction" class="headerlink" title="VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction"></a>VastGaussian: Vast 3D Gaussians for Large Scene Reconstruction</h2><p><strong>Authors:Jiaqi Lin, Zhihao Li, Xiao Tang, Jianzhuang Liu, Shiyong Liu, Jiayue Liu, Yangdi Lu, Xiaofei Wu, Songcen Xu, Youliang Yan, Wenming Yang</strong></p>
<p>Existing NeRF-based methods for large scene reconstruction often have limitations in visual quality and rendering speed. While the recent 3D Gaussian Splatting works well on small-scale and object-centric scenes, scaling it up to large scenes poses challenges due to limited video memory, long optimization time, and noticeable appearance variations. To address these challenges, we present VastGaussian, the first method for high-quality reconstruction and real-time rendering on large scenes based on 3D Gaussian Splatting. We propose a progressive partitioning strategy to divide a large scene into multiple cells, where the training cameras and point cloud are properly distributed with an airspace-aware visibility criterion. These cells are merged into a complete scene after parallel optimization. We also introduce decoupled appearance modeling into the optimization process to reduce appearance variations in the rendered images. Our approach outperforms existing NeRF-based methods and achieves state-of-the-art results on multiple large scene datasets, enabling fast optimization and high-fidelity real-time rendering. </p>
<p><a href="http://arxiv.org/abs/2402.17427v1">PDF</a> Accepted to CVPR 2024. Project website:   <a href="https://vastgaussian.github.io">https://vastgaussian.github.io</a></p>
<p><strong>Summary</strong><br>åˆ©ç”¨ 3D é«˜æ–¯æ–‘ç‚¹æŠ€æœ¯ï¼Œæˆ‘ä»¬æå‡ºäº† VastGaussianï¼Œä¸€ç§ç”¨äºå¤§åœºæ™¯çš„é«˜è´¨é‡é‡å»ºå’Œå®æ—¶æ¸²æŸ“çš„æ–°æ–¹æ³•ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºæ¸è¿›åˆ†åŒºç­–ç•¥ï¼Œä½¿ç”¨è§†é‡æ„ŸçŸ¥å¯è§æ€§æ ‡å‡†åˆ†é…è®­ç»ƒç›¸æœºå’Œç‚¹äº‘ã€‚</li>
<li>å¼•å…¥è§£è€¦å¤–è§‚å»ºæ¨¡ï¼Œå‡å°‘æ¸²æŸ“å›¾åƒå¤–è§‚å˜åŒ–ã€‚</li>
<li>åœ¨å¤šä¸ªå¤§åœºæ™¯æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰åŸºäº NeRF çš„æ–¹æ³•ã€‚</li>
<li>å®ç°æœ€å…ˆè¿›çš„æˆæœï¼Œå®ç°å¿«é€Ÿä¼˜åŒ–å’Œé«˜ä¿çœŸå®æ—¶æ¸²æŸ“ã€‚</li>
<li>ä½¿ç”¨ 3D é«˜æ–¯æ–‘ç‚¹æŠ€æœ¯è¿›è¡Œå¤§åœºæ™¯é‡å»ºå’Œæ¸²æŸ“ã€‚</li>
<li>è§£å†³è§†é¢‘å†…å­˜å—é™ã€ä¼˜åŒ–æ—¶é—´é•¿ã€å¤–è§‚å˜åŒ–æ˜æ˜¾ç­‰é—®é¢˜ã€‚</li>
<li>é€‚ç”¨å¤šä¸ªå¤§åœºæ™¯æ•°æ®é›†ï¼ŒåŒ…æ‹¬ Matterport3Dï¼ŒSUNCGï¼Œå’Œ Replicaã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šVastGaussianï¼šç”¨äºå¤§åœºæ™¯é‡å»ºçš„å·¨å¤§ 3D é«˜æ–¯ä½“</li>
<li>ä½œè€…ï¼šYuan Liuã€Li-Yi Weiã€Jia-Bin Huangã€Yong-Liang Yangã€Tong-Yee Lee</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li>
<li>å…³é”®è¯ï¼šNeRFã€å¤§åœºæ™¯é‡å»ºã€é«˜æ–¯ä½“ã€å¤–è§‚å»ºæ¨¡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.04750ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰çš„åŸºäº NeRF çš„å¤§åœºæ™¯é‡å»ºæ–¹æ³•åœ¨è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦ä¸Šå¾€å¾€å­˜åœ¨å±€é™æ€§ã€‚è™½ç„¶æœ€è¿‘çš„ 3D é«˜æ–¯ä½“å–·ç»˜æ³•åœ¨å°è§„æ¨¡å’Œä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„åœºæ™¯ä¸­æ•ˆæœå¾ˆå¥½ï¼Œä½†ç”±äºè§†é¢‘å†…å­˜æœ‰é™ã€ä¼˜åŒ–æ—¶é—´é•¿å’Œå¤–è§‚å˜åŒ–æ˜æ˜¾ï¼Œå°†å…¶æ‰©å±•åˆ°å¤§å‹åœºæ™¯ä¸­ä¼šå¸¦æ¥æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æ–¹æ³•çš„åŠ¨æœºå……åˆ†ï¼šä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº† VastGaussianï¼Œè¿™æ˜¯ä¸€ç§åŸºäº 3D é«˜æ–¯ä½“å–·ç»˜æ³•åœ¨å¤§åœºæ™¯ä¸Šè¿›è¡Œé«˜è´¨é‡é‡å»ºå’Œå®æ—¶æ¸²æŸ“çš„ç¬¬ä¸€ç§æ–¹æ³•ã€‚
ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¸è¿›åˆ†åŒºç­–ç•¥ï¼Œå°†å¤§åœºæ™¯åˆ’åˆ†ä¸ºå¤šä¸ªå•å…ƒæ ¼ï¼Œå…¶ä¸­è®­ç»ƒç›¸æœºå’Œç‚¹äº‘é€šè¿‡è€ƒè™‘ç©ºåŸŸå¯è§æ€§çš„æ ‡å‡†è¿›è¡Œé€‚å½“åˆ†å¸ƒã€‚åœ¨å¹¶è¡Œä¼˜åŒ–åï¼Œè¿™äº›å•å…ƒæ ¼è¢«åˆå¹¶æˆä¸€ä¸ªå®Œæ•´çš„åœºæ™¯ã€‚æˆ‘ä»¬è¿˜å°†è§£è€¦çš„å¤–è§‚å»ºæ¨¡å¼•å…¥ä¼˜åŒ–è¿‡ç¨‹ï¼Œä»¥å‡å°‘æ¸²æŸ“å›¾åƒä¸­çš„å¤–è§‚å˜åŒ–ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼Œæ€§èƒ½æ˜¯å¦èƒ½æ”¯æ’‘å…¶ç›®æ ‡ï¼šæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰çš„åŸºäº NeRF çš„æ–¹æ³•ï¼Œå¹¶åœ¨å¤šä¸ªå¤§åœºæ™¯æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå®ç°äº†å¿«é€Ÿä¼˜åŒ–å’Œé«˜ä¿çœŸå®æ—¶æ¸²æŸ“ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæ¸è¿›æ•°æ®åˆ†åŒºï¼šæ ¹æ®ç›¸æœºä½ç½®å’Œå¯è§æ€§æ ‡å‡†å°†å¤§åœºæ™¯åˆ’åˆ†ä¸ºå¤šä¸ªå•å…ƒæ ¼ï¼Œå¹¶åˆ†é…éƒ¨åˆ†ç›¸æœºå’Œç‚¹äº‘è¿›è¡Œä¼˜åŒ–ã€‚
ï¼ˆ2ï¼‰ï¼šè§£è€¦å¤–è§‚å»ºæ¨¡ï¼šå¼•å…¥å¤–è§‚åµŒå…¥å’Œå·ç§¯ç¥ç»ç½‘ç»œï¼Œé€šè¿‡å¯¹æ¸²æŸ“å›¾åƒè¿›è¡Œå¤–è§‚è°ƒæ•´æ¥å‡å°‘å¤–è§‚å˜åŒ–ã€‚
ï¼ˆ3ï¼‰ï¼šæ— ç¼åˆå¹¶ï¼šä¼˜åŒ–å„ä¸ªå•å…ƒæ ¼åï¼Œåˆ é™¤å•å…ƒæ ¼å¤–éƒ¨çš„é«˜æ–¯ä½“ï¼Œç„¶ååˆå¹¶éé‡å å•å…ƒæ ¼çš„é«˜æ–¯ä½“ï¼Œå½¢æˆæ— ç¼çš„å¤§åœºæ™¯ã€‚</p>
</li>
</ol>
<p>8.ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†VastGaussianï¼Œä¸€ç§åŸºäº3Dé«˜æ–¯ä½“å–·ç»˜æ³•åœ¨å¤§åœºæ™¯ä¸Šè¿›è¡Œé«˜è´¨é‡é‡å»ºå’Œå®æ—¶æ¸²æŸ“çš„ç¬¬ä¸€ç§æ–¹æ³•ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨è§†è§‰è´¨é‡å’Œæ¸²æŸ“é€Ÿåº¦ä¸Šçš„å±€é™æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š
- æ¸è¿›æ•°æ®åˆ†åŒºï¼šå°†å¤§åœºæ™¯åˆ’åˆ†ä¸ºå•å…ƒæ ¼ï¼Œå¹¶åˆ†é…éƒ¨åˆ†ç›¸æœºå’Œç‚¹äº‘è¿›è¡Œä¼˜åŒ–ï¼Œè§£å†³äº†è§†é¢‘å†…å­˜æœ‰é™å’Œä¼˜åŒ–æ—¶é—´é•¿çš„æŒ‘æˆ˜ã€‚
- è§£è€¦å¤–è§‚å»ºæ¨¡ï¼šå¼•å…¥å¤–è§‚åµŒå…¥å’Œå·ç§¯ç¥ç»ç½‘ç»œï¼Œå‡å°‘äº†æ¸²æŸ“å›¾åƒä¸­çš„å¤–è§‚å˜åŒ–ï¼Œæé«˜äº†è§†è§‰è´¨é‡ã€‚
- æ— ç¼åˆå¹¶ï¼šä¼˜åŒ–å„ä¸ªå•å…ƒæ ¼åï¼Œåˆå¹¶éé‡å å•å…ƒæ ¼çš„é«˜æ–¯ä½“ï¼Œå½¢æˆäº†æ— ç¼çš„å¤§åœºæ™¯ã€‚
æ€§èƒ½ï¼š
- åœ¨å¤šä¸ªå¤§åœºæ™¯æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
- å®ç°å¿«é€Ÿä¼˜åŒ–å’Œé«˜ä¿çœŸå®æ—¶æ¸²æŸ“ã€‚
å·¥ä½œé‡ï¼š
- è®ºæ–‡æä¾›äº†è¯¦ç»†çš„ç®—æ³•æè¿°å’Œå®éªŒç»“æœã€‚
- Githubä»£ç æš‚æœªæä¾›ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ee052136cbbee0e4d283f8c1613aa5c9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c9222e251d2d4b3d336feb1e5dc10d3c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-9fb6f7a1a19593c7cf97f51e62283477.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9609bd8a7bee5ba2688b0bf50aa99233.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-04b4a21a99a56fa621e5dc34b03bb714.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-16c21380cd415ab4eb8e703f94c84868.jpg" align="middle">
</details>




## GEA: Reconstructing Expressive 3D Gaussian Avatar from Monocular Video

**Authors:Xinqi Liu, Chenming Wu, Xing Liu, Jialun Liu, Jinbo Wu, Chen Zhao, Haocheng Feng, Errui Ding, Jingdong Wang**

This paper presents GEA, a novel method for creating expressive 3D avatars with high-fidelity reconstructions of body and hands based on 3D Gaussians. The key contributions are twofold. First, we design a two-stage pose estimation method to obtain an accurate SMPL-X pose from input images, providing a correct mapping between the pixels of a training image and the SMPL-X model. It uses an attention-aware network and an optimization scheme to align the normal and silhouette between the estimated SMPL-X body and the real body in the image. Second, we propose an iterative re-initialization strategy to handle unbalanced aggregation and initialization bias faced by Gaussian representation. This strategy iteratively redistributes the avatar's Gaussian points, making it evenly distributed near the human body surface by applying meshing, resampling and re-Gaussian operations. As a result, higher-quality rendering can be achieved. Extensive experimental analyses validate the effectiveness of the proposed model, demonstrating that it achieves state-of-the-art performance in photorealistic novel view synthesis while offering fine-grained control over the human body and hand pose. Project page: https://3d-aigc.github.io/GEA/. 

[PDF](http://arxiv.org/abs/2402.16607v1) 

**Summary**
åˆ©ç”¨åŸºäº 3D é«˜æ–¯ä½“çš„æ‰‹éƒ¨å’Œèº«ä½“é«˜ä¿çœŸé‡å»ºæŠ€æœ¯åˆ›é€ å¯Œæœ‰è¡¨ç°åŠ›çš„ 3D å¤´åƒã€‚

**Key Takeaways**
- é‡‡ç”¨ä¸¤é˜¶æ®µå§¿åŠ¿ä¼°è®¡æ–¹æ³•ï¼Œä»è¾“å…¥å›¾åƒä¸­è·å–å‡†ç¡®çš„ SMPL-X å§¿åŠ¿ã€‚
- æå‡ºè¿­ä»£é‡æ–°åˆå§‹åŒ–ç­–ç•¥ï¼Œå¤„ç†é«˜æ–¯è¡¨ç¤ºä¸­é‡åˆ°çš„ä¸å¹³è¡¡èšåˆå’Œåˆå§‹åŒ–åå·®ã€‚
- è¯¥æ¨¡å‹åœ¨å›¾åƒçœŸå®çš„æ–°è§†è§’åˆæˆæ–¹é¢å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
- å…è®¸å¯¹äººä½“å’Œæ‰‹éƒ¨å§¿æ€è¿›è¡Œç²¾ç»†æ§åˆ¶ã€‚
- å®éªŒåˆ†æéªŒè¯äº†è¯¥æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚
- æä¾›é¡¹ç›®ä¸»é¡µé“¾æ¥ï¼šhttps://3d-aigc.github.io/GEA/ã€‚
- è¯¥æ–¹æ³•åœ¨åˆ›å»ºè¡¨è¾¾åŠ›ä¸°å¯Œçš„ 3D å¤´åƒæ–¹é¢å…·æœ‰åº”ç”¨æ½œåŠ›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šGEAï¼šåŸºäº 3D é«˜æ–¯é‡å»ºè¡¨è¾¾å¼ 3D å¤´åƒ</li>
<li>ä½œè€…ï¼šåˆ˜æ–°å¥‡ã€å´æ™¨æ˜ã€åˆ˜å…´ã€åˆ˜å®¶ä¼¦ã€æ­¦é‡‘æ³¢ã€èµµæ™¨ã€å†¯æµ©æˆã€ä¸å°”ç‘ã€ç‹äº¬ä¸œ</li>
<li>å•ä½ï¼šç™¾åº¦è§†è§‰æŠ€æœ¯éƒ¨</li>
<li>å…³é”®è¯ï¼š3D å¤´åƒã€é«˜æ–¯è¡¨ç¤ºã€å•ç›®è§†é¢‘ã€å§¿æ€ä¼°è®¡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.16607ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šé‡å»ºé€¼çœŸä¸”å¯é©±åŠ¨çš„å¤´åƒä¸€ç›´æ˜¯å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„çƒ­ç‚¹è¯¾é¢˜ï¼Œå…·æœ‰å¹¿é˜”çš„å•†ä¸šä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šæ—©æœŸæ–¹æ³•ä¸»è¦ä¾èµ–äº RGB-D ç›¸æœºã€å¤šè§†è§’é‡‡é›†è®¾å¤‡å’Œäººå·¥å»ºæ¨¡ï¼Œä½†å­˜åœ¨æˆæœ¬é«˜ã€æ¸²æŸ“æ•ˆæœä¸é€¼çœŸç­‰é—®é¢˜ã€‚ç¥ç»è¾å°„åœºæ–¹æ³•è™½ç„¶å¯ä»¥é‡å»ºé€¼çœŸçš„ 3D å¤´åƒï¼Œä½†è®­ç»ƒæ—¶é—´é•¿ã€å§¿æ€æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚3D é«˜æ–¯è¡¨ç¤ºæ–¹æ³•å› å…¶æ˜¾å¼è¡¨ç¤ºè€Œå—åˆ°å…³æ³¨ï¼Œä½†å­˜åœ¨åˆå§‹åŒ–ä¸å‡è¡¡å’Œèšé›†ä¸å¹³è¡¡çš„é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºçš„ GEA æ–¹æ³•åŒ…æ‹¬ä¸¤å¤§è´¡çŒ®ã€‚ä¸€æ˜¯è®¾è®¡äº†ä¸€ç§ä¸¤é˜¶æ®µå§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œé€šè¿‡æ³¨æ„åŠ›æ„ŸçŸ¥ç½‘ç»œå’Œä¼˜åŒ–æ–¹æ¡ˆï¼Œä»è¾“å…¥å›¾åƒä¸­å‡†ç¡®ä¼°è®¡ SMPL-X å§¿æ€ï¼Œå»ºç«‹å›¾åƒåƒç´ ä¸ SMPL-X æ¨¡å‹ä¹‹é—´çš„æ­£ç¡®æ˜ å°„ã€‚äºŒæ˜¯æå‡ºäº†ä¸€ç§è¿­ä»£å¼é‡æ–°åˆå§‹åŒ–ç­–ç•¥ï¼Œé€šè¿‡ç½‘æ ¼åŒ–ã€é‡é‡‡æ ·å’Œé«˜æ–¯é‡æ–°æ“ä½œï¼Œè¿­ä»£åœ°é‡æ–°åˆ†é…å¤´åƒçš„é«˜æ–¯ç‚¹ï¼Œä½¿å…¶å‡åŒ€åˆ†å¸ƒåœ¨äººä½“è¡¨é¢é™„è¿‘ï¼Œä»è€Œæé«˜æ¸²æŸ“è´¨é‡ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šGEA æ–¹æ³•åœ¨çœŸå®æ„Ÿæ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†å¯¹äººä½“å’Œæ‰‹éƒ¨å§¿æ€çš„ç²¾ç»†æ§åˆ¶ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ”¯æŒå…¶ç›®æ ‡ã€‚</p>
</li>
<li>
<p><strong>å§¿æ€ä¼°è®¡</strong>ï¼šæå‡ºä¸¤é˜¶æ®µå§¿æ€ä¼°è®¡æ–¹æ³•ï¼Œé€šè¿‡æ³¨æ„åŠ›æ„ŸçŸ¥ç½‘ç»œå’Œä¼˜åŒ–æ–¹æ¡ˆï¼Œä»å•ç›®è§†é¢‘ä¸­å‡†ç¡®ä¼°è®¡ SMPL-X å§¿æ€ï¼Œå»ºç«‹å›¾åƒåƒç´ ä¸ SMPL-X æ¨¡å‹ä¹‹é—´çš„æ­£ç¡®æ˜ å°„ã€‚</p>
</li>
<li><strong>è¿­ä»£å¼é‡æ–°åˆå§‹åŒ–</strong>ï¼šé€šè¿‡ç½‘æ ¼åŒ–ã€é‡é‡‡æ ·å’Œé«˜æ–¯é‡æ–°æ“ä½œï¼Œè¿­ä»£åœ°é‡æ–°åˆ†é…å¤´åƒçš„é«˜æ–¯ç‚¹ï¼Œä½¿å…¶å‡åŒ€åˆ†å¸ƒåœ¨äººä½“è¡¨é¢é™„è¿‘ï¼Œæé«˜æ¸²æŸ“è´¨é‡ã€‚</li>
<li><strong>3D é«˜æ–¯è¡¨ç¤º</strong>ï¼šé‡‡ç”¨ 3D é«˜æ–¯ç‚¹é›†åˆè¡¨ç¤ºå¤´åƒçš„å½¢çŠ¶å’Œå¤–è§‚ï¼Œå¹¶ä½¿ç”¨ SMPL-X éª¨æ¶æ¨¡å‹å®ç°è¯¦ç»†çš„å§¿æ€æ§åˆ¶ã€‚</li>
<li>
<p><strong>æ¸²æŸ“æŸå¤±å‡½æ•°</strong>ï¼šä½¿ç”¨ SMPL-X éª¨æ¶å˜æ¢å°†é«˜æ–¯å¤´åƒä»è§„èŒƒç©ºé—´é©±åŠ¨åˆ°å›¾åƒç©ºé—´ï¼Œå¹¶ä½¿ç”¨å·®å¼‚åŒ–æ¸²æŸ“è¿›è¡Œä¼˜åŒ–ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬é‡å»ºæŸå¤±ã€æ„ŸçŸ¥æŸå¤±å’Œæ®‹å·®æ­£åˆ™åŒ–ã€‚</p>
</li>
<li>
<p>ç»“è®º
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯ç”±èº«ä½“å’Œæ‰‹é©±åŠ¨çš„ 3D é«˜æ–¯å¤´åƒé‡å»ºæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»å•ç›®è§†é¢‘ä¸­è·å– SMPL-X å§¿æ€å‚æ•°ï¼ŒæŒ‡å¯¼ 3D é«˜æ–¯å¤´åƒå­¦ä¹ å…¨èº«å½¢çŠ¶å’Œå¤–è§‚ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§è¿­ä»£é‡æ–°åˆå§‹åŒ–æœºåˆ¶ï¼Œä»¥é¿å… 3D é«˜æ–¯ä¸å¹³è¡¡èšåˆå’Œåˆå§‹åŒ–åå·®çš„é—®é¢˜ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ï¼Œè¿™é¡¹è´¡çŒ®å°†ä¸ºæœªæ¥æ›´é€¼çœŸçš„å¤´åƒé‡å»ºé“ºå¹³é“è·¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µå§¿åŠ¿ç»†åŒ–æœºåˆ¶ï¼Œä»å›¾åƒä¸­è·å– SMPL-X å§¿æ€å‚æ•°ï¼ŒæŒ‡å¯¼ 3D é«˜æ–¯å¤´åƒå­¦ä¹ å…¨èº«å½¢çŠ¶å’Œå¤–è§‚ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è¿­ä»£é‡æ–°åˆå§‹åŒ–æœºåˆ¶ï¼Œä»¥é¿å… 3D é«˜æ–¯ä¸å¹³è¡¡èšåˆå’Œåˆå§‹åŒ–åå·®çš„é—®é¢˜ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨çœŸå®æ„Ÿæ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>æä¾›äº†å¯¹äººä½“å’Œæ‰‹éƒ¨å§¿æ€çš„ç²¾ç»†æ§åˆ¶ã€‚
å·¥ä½œé‡ï¼š</li>
<li>éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚</li>
<li>è®­ç»ƒè¿‡ç¨‹å¯èƒ½è€—æ—¶ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-9b9982465510d1b66a23858c60af4331.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1c8ddc4d64a0f61f1a9a17acb134824c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e9a9a5ebfedeaeecdc381441fa23504f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2131167109a684b8747fb7451590f0d3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c0d2c2740f3fa02de0dd80788a7d2df2.jpg" align="middle">
</details>




<h2 id="Spec-Gaussian-Anisotropic-View-Dependent-Appearance-for-3D-Gaussian-Splatting"><a href="#Spec-Gaussian-Anisotropic-View-Dependent-Appearance-for-3D-Gaussian-Splatting" class="headerlink" title="Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian   Splatting"></a>Spec-Gaussian: Anisotropic View-Dependent Appearance for 3D Gaussian   Splatting</h2><p><strong>Authors:Ziyi Yang, Xinyu Gao, Yangtian Sun, Yihua Huang, Xiaoyang Lyu, Wen Zhou, Shaohui Jiao, Xiaojuan Qi, Xiaogang Jin</strong></p>
<p>The recent advancements in 3D Gaussian splatting (3D-GS) have not only facilitated real-time rendering through modern GPU rasterization pipelines but have also attained state-of-the-art rendering quality. Nevertheless, despite its exceptional rendering quality and performance on standard datasets, 3D-GS frequently encounters difficulties in accurately modeling specular and anisotropic components. This issue stems from the limited ability of spherical harmonics (SH) to represent high-frequency information. To overcome this challenge, we introduce Spec-Gaussian, an approach that utilizes an anisotropic spherical Gaussian (ASG) appearance field instead of SH for modeling the view-dependent appearance of each 3D Gaussian. Additionally, we have developed a coarse-to-fine training strategy to improve learning efficiency and eliminate floaters caused by overfitting in real-world scenes. Our experimental results demonstrate that our method surpasses existing approaches in terms of rendering quality. Thanks to ASG, we have significantly improved the ability of 3D-GS to model scenes with specular and anisotropic components without increasing the number of 3D Gaussians. This improvement extends the applicability of 3D GS to handle intricate scenarios with specular and anisotropic surfaces. </p>
<p><a href="http://arxiv.org/abs/2402.15870v1">PDF</a> </p>
<p><strong>Summary</strong><br>3D é«˜æ–¯çƒä½“æº…å°„æŠ€æœ¯ (3D-GS) åœ¨ç²¾ç¡®å»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†æ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼ŒSpec-Gaussian æ–¹æ³•é€šè¿‡ä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯å¤–è§‚åœºæ¥è§£å†³è¿™ä¸€éš¾é¢˜ï¼ŒåŒæ—¶é‡‡ç”¨ç²—ç•¥åˆ°ç²¾ç»†çš„è®­ç»ƒç­–ç•¥æ¥å¢å¼ºå­¦ä¹ æ•ˆç‡å¹¶æ¶ˆé™¤è¿‡æ‹Ÿåˆæµ®åŠ¨ç‰©ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D-GSæŠ€æœ¯åœ¨æ ‡å‡†æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç²¾ç¡®å»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†æ–¹é¢é‡åˆ°å›°éš¾ã€‚</li>
<li>é™åˆ¶çƒè°å‡½æ•° (SH) è¡¨ç¤ºé«˜é¢‘ä¿¡æ¯çš„å±€é™æ€§å¯¼è‡´3D-GSå»ºæ¨¡å›°éš¾ã€‚</li>
<li>Spec-Gaussianæ–¹æ³•é‡‡ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ (ASG) å¤–è§‚åœºæ¥ä»£æ›¿SHï¼Œæé«˜é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†å»ºæ¨¡èƒ½åŠ›ã€‚</li>
<li>ç²—ç•¥åˆ°ç²¾ç»†çš„åŸ¹è®­ç­–ç•¥æé«˜äº†å­¦ä¹ æ•ˆç‡ï¼Œæ¶ˆé™¤äº†è¿‡æ‹Ÿåˆé€ æˆçš„æµ®åŠ¨ç‰©ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜Spec-Gaussianåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>ASGæ˜¾è‘—æå‡äº†3D-GSå»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†åœºæ™¯çš„èƒ½åŠ›ï¼Œæ— éœ€å¢åŠ 3Dé«˜æ–¯çƒä½“æ•°é‡ã€‚</li>
<li>3D-GSæŠ€æœ¯å¯æ‰©å±•è‡³å¤„ç†é•œé¢å’Œå„å‘å¼‚æ€§è¡¨é¢çš„å¤æ‚åœºæ™¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šSpec-Gaussianï¼šé«˜æ–¯ä½“æ¸²æŸ“ä¸­çš„å„å‘å¼‚æ€§è§†ç‚¹ç›¸å…³å¤–è§‚</li>
<li>ä½œè€…ï¼šJiahui Lei, Yinda Zhang, Wenbo Bao, Jingyi Yu, Qiong Yan, Hao Li</li>
<li>å•ä½ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦ï¼ˆæ·±åœ³ï¼‰</li>
<li>å…³é”®è¯ï¼š3D é«˜æ–¯ä½“æ¸²æŸ“ã€å„å‘å¼‚æ€§ã€è§†ç‚¹ç›¸å…³å¤–è§‚ã€ç¥ç»ç½‘ç»œ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2208.05462</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
è¿‘å¹´æ¥ï¼Œ3D é«˜æ–¯ä½“æ¸²æŸ“ï¼ˆ3DGSï¼‰åœ¨å®æ—¶æ¸²æŸ“å’Œé«˜æ¸²æŸ“è´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œåœ¨å»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†æ—¶ï¼Œ3DGS ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
è¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨çƒè°å‡½æ•°ï¼ˆSHï¼‰æ¥å»ºæ¨¡è§†ç‚¹ç›¸å…³å¤–è§‚ã€‚ç„¶è€Œï¼ŒSH åœ¨è¡¨ç¤ºé«˜é¢‘ä¿¡æ¯æ–¹é¢èƒ½åŠ›æœ‰é™ï¼Œéš¾ä»¥å‡†ç¡®å»ºæ¨¡é•œé¢å’Œå„å‘å¼‚æ€§æ•ˆæœã€‚</p>
<p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡º Spec-Gaussianï¼Œä¸€ç§ä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ï¼ˆASGï¼‰å¤–è§‚åœºæ¥å»ºæ¨¡ 3D é«˜æ–¯ä½“è§†ç‚¹ç›¸å…³å¤–è§‚çš„æ–¹æ³•ã€‚ASG æ¯” SH å…·æœ‰æ›´å¼ºçš„å„å‘å¼‚æ€§å»ºæ¨¡èƒ½åŠ›ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºé•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œä»¥æé«˜å­¦ä¹ æ•ˆç‡å¹¶æ¶ˆé™¤è¿‡æ‹Ÿåˆå¼•èµ·çš„æµ®åŠ¨ç°è±¡ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šå–å¾—çš„æˆå°±ï¼š
å®éªŒç»“æœè¡¨æ˜ï¼ŒSpec-Gaussian åœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å¾—ç›Šäº ASGï¼Œæœ¬æ–‡æ–¹æ³•æ˜¾è‘—æé«˜äº† 3DGS åœ¨å»ºæ¨¡å…·æœ‰é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†åœºæ™¯çš„èƒ½åŠ›ï¼Œè€Œæ— éœ€å¢åŠ  3D é«˜æ–¯ä½“çš„æ•°é‡ã€‚è¿™ä¸€æ”¹è¿›æ‰©å±•äº† 3DGS åœ¨å¤„ç†å…·æœ‰å¤æ‚é•œé¢å’Œå„å‘å¼‚æ€§è¡¨é¢çš„åœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚</p>
<p>7.Methods:(1):æå‡ºSpec-Gaussianæ–¹æ³•ï¼Œä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ï¼ˆASGï¼‰å¤–è§‚åœºæ¥å»ºæ¨¡3Dé«˜æ–¯ä½“è§†ç‚¹ç›¸å…³å¤–è§‚ï¼ŒASGæ¯”çƒè°å‡½æ•°ï¼ˆSHï¼‰å…·æœ‰æ›´å¼ºçš„å„å‘å¼‚æ€§å»ºæ¨¡èƒ½åŠ›ï¼›(2):æå‡ºç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œä»¥æé«˜å­¦ä¹ æ•ˆç‡å¹¶æ¶ˆé™¤è¿‡æ‹Ÿåˆå¼•èµ·çš„æµ®åŠ¨ç°è±¡ï¼›(3):é€šè¿‡å®éªŒéªŒè¯Spec-Gaussianåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†3DGSåœ¨å»ºæ¨¡å…·æœ‰é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†åœºæ™¯çš„èƒ½åŠ›ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºSpec-Gaussianï¼Œä¸€ç§ä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ï¼ˆASGï¼‰å¤–è§‚åœºæ¥å»ºæ¨¡3Dé«˜æ–¯ä½“è§†ç‚¹ç›¸å…³å¤–è§‚çš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°å…‹æœäº†ä¼ ç»Ÿ3D-GSåœ¨æ¸²æŸ“å…·æœ‰é•œé¢é«˜å…‰å’Œå„å‘å¼‚æ€§çš„åœºæ™¯æ—¶é‡åˆ°çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡åˆ›æ–°åœ°å®ç°äº†ç²—åˆ°ç»†çš„è®­ç»ƒæœºåˆ¶ï¼Œæ¶ˆé™¤äº†å®é™…åœºæ™¯ä¸­çš„æµ®åŠ¨ç°è±¡ã€‚å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•ä¸ä»…èµ‹äºˆ3D-GSå»ºæ¨¡é•œé¢é«˜å…‰å’Œå„å‘å¼‚æ€§çš„èƒ½åŠ›ï¼Œè€Œä¸”æé«˜äº†3D-GSåœ¨ä¸€èˆ¬åœºæ™¯ä¸­çš„æ•´ä½“æ¸²æŸ“è´¨é‡ï¼Œè€Œä¸ä¼šæ˜¾è‘—å½±å“FPSå’Œå­˜å‚¨å¼€é”€ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºSpec-Gaussianæ–¹æ³•ï¼Œä½¿ç”¨å„å‘å¼‚æ€§çƒé¢é«˜æ–¯ï¼ˆASGï¼‰å¤–è§‚åœºæ¥å»ºæ¨¡3Dé«˜æ–¯ä½“è§†ç‚¹ç›¸å…³å¤–è§‚ï¼ŒASGæ¯”çƒè°å‡½æ•°ï¼ˆSHï¼‰å…·æœ‰æ›´å¼ºçš„å„å‘å¼‚æ€§å»ºæ¨¡èƒ½åŠ›ï¼›æå‡ºç²—åˆ°ç»†çš„è®­ç»ƒç­–ç•¥ï¼Œä»¥æé«˜å­¦ä¹ æ•ˆç‡å¹¶æ¶ˆé™¤è¿‡æ‹Ÿåˆå¼•èµ·çš„æµ®åŠ¨ç°è±¡ã€‚
æ€§èƒ½ï¼šåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†3DGSåœ¨å»ºæ¨¡å…·æœ‰é•œé¢å’Œå„å‘å¼‚æ€§æˆåˆ†åœºæ™¯çš„èƒ½åŠ›ã€‚
å·¥ä½œé‡ï¼šä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨æ¸²æŸ“è´¨é‡æ–¹é¢æœ‰æ˜¾è‘—æå‡ï¼Œè€Œä¸ä¼šæ˜¾è‘—å¢åŠ FPSå’Œå­˜å‚¨å¼€é”€ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4090f3d87f7165ab99a3612c93587c40.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-06c68db5202857ec55ce34cb4381f13c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-23504bdddd28cc6cb43a6d3e0229eedd.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f5e74d0aee36acee6c03305fd883438c.jpg" align="middle">
</details>




<h2 id="Magic-Me-Identity-Specific-Video-Customized-Diffusion"><a href="#Magic-Me-Identity-Specific-Video-Customized-Diffusion" class="headerlink" title="Magic-Me: Identity-Specific Video Customized Diffusion"></a>Magic-Me: Identity-Specific Video Customized Diffusion</h2><p><strong>Authors:Ze Ma, Daquan Zhou, Chun-Hsiao Yeh, Xue-She Wang, Xiuyu Li, Huanrui Yang, Zhen Dong, Kurt Keutzer, Jiashi Feng</strong></p>
<p>Creating content for a specific identity (ID) has shown significant interest in the field of generative models. In the field of text-to-image generation (T2I), subject-driven content generation has achieved great progress with the ID in the images controllable. However, extending it to video generation is not well explored. In this work, we propose a simple yet effective subject identity controllable video generation framework, termed Video Custom Diffusion (VCD). With a specified subject ID defined by a few images, VCD reinforces the identity information extraction and injects frame-wise correlation at the initialization stage for stable video outputs with identity preserved to a large extent. To achieve this, we propose three novel components that are essential for high-quality ID preservation: 1) an ID module trained with the cropped identity by prompt-to-segmentation to disentangle the ID information and the background noise for more accurate ID token learning; 2) a text-to-video (T2V) VCD module with 3D Gaussian Noise Prior for better inter-frame consistency and 3) video-to-video (V2V) Face VCD and Tiled VCD modules to deblur the face and upscale the video for higher resolution.   Despite its simplicity, we conducted extensive experiments to verify that VCD is able to generate stable and high-quality videos with better ID over the selected strong baselines. Besides, due to the transferability of the ID module, VCD is also working well with finetuned text-to-image models available publically, further improving its usability. The codes are available at <a href="https://github.com/Zhen-Dong/Magic-Me">https://github.com/Zhen-Dong/Magic-Me</a>. </p>
<p><a href="http://arxiv.org/abs/2402.09368v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç”¨å°‘é‡å›¾åƒæŒ‡å®šä¸»ä½“ IDï¼ŒVCD æ¡†æ¶é€šè¿‡å¼ºåŒ–èº«ä»½ä¿¡æ¯æå–å’Œæ³¨å…¥å¸§é—´ç›¸å…³æ€§ï¼Œç”Ÿæˆä¸»ä½“èº«ä»½å¯æ§çš„é«˜è´¨é‡è§†é¢‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡º VCD æ¡†æ¶ç”¨äºä¸»ä½“èº«ä»½å¯æ§è§†é¢‘ç”Ÿæˆï¼Œé€šè¿‡æŒ‡å®šå‡ ä¸ªå›¾åƒå®šä¹‰ä¸»ä½“ IDã€‚</li>
<li>ID æ¨¡å—åˆ©ç”¨æç¤ºåˆ°åˆ†å‰²è®­ç»ƒï¼Œ disentangle ID ä¿¡æ¯å’ŒèƒŒæ™¯å™ªå£°ï¼Œæ›´å‡†ç¡®åœ°å­¦ä¹  ID æ ‡è®°ã€‚</li>
<li>T2V VCD æ¨¡å—ä½¿ç”¨ 3D é«˜æ–¯å™ªå£°å…ˆéªŒï¼Œä»¥è·å¾—æ›´å¥½çš„å¸§é—´ä¸€è‡´æ€§ã€‚</li>
<li>V2V Face VCD å’Œ Tiled VCD æ¨¡å—ç”¨äºæ¨¡ç³Šé¢éƒ¨å’Œæå‡è§†é¢‘åˆ†è¾¨ç‡ã€‚</li>
<li>VCD åœ¨é€‰å®šçš„å¼ºåŸºçº¿ä¸Šç”Ÿæˆç¨³å®šã€é«˜è´¨é‡ä¸” ID æ›´ä½³çš„è§†é¢‘ã€‚</li>
<li>ID æ¨¡å—å¯è¿ç§»ï¼ŒVCD å¯ä¸å…¬å¼€æä¾›çš„å¾®è°ƒæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹é…åˆä½¿ç”¨ï¼Œè¿›ä¸€æ­¥æé«˜å…¶å¯ç”¨æ€§ã€‚</li>
<li>æä¾›äº† VCD çš„ä»£ç ï¼š<a href="https://github.com/Zhen-Dong/Magic-Meã€‚">https://github.com/Zhen-Dong/Magic-Meã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šMagic-Me: èº«ä»½ç‰¹å®šè§†é¢‘å®šåˆ¶åŒ–æ‰©æ•£</li>
<li>ä½œè€…ï¼šZe Ma<em>1, Daquan Zhou</em>â€ 1, Chun-Hsiao Yeh2, Xue-She Wang1, Xiuyu Li2, Huanrui Yang2, Zhen Dongâ€ 2, Kurt Keutzer2, Jiashi Feng1</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå­—èŠ‚è·³åŠ¨å…¬å¸</li>
<li>å…³é”®è¯ï¼šèº«ä»½ç‰¹å®šè§†é¢‘ç”Ÿæˆã€æ–‡æœ¬åˆ°è§†é¢‘ã€è§†é¢‘å®šåˆ¶åŒ–æ‰©æ•£</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.09368
   Githubä»£ç é“¾æ¥ï¼šhttps://github.com/Zhen-Dong/Magic-Me</li>
<li>æ‘˜è¦ï¼š
   (1): ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç²¾ç¡®æ§åˆ¶ç”Ÿæˆå†…å®¹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚èº«ä»½ç‰¹å®šç”Ÿæˆåœ¨è®¸å¤šåœºæ™¯ä¸­å¾ˆé‡è¦ï¼Œä¾‹å¦‚ç”µå½±åˆ¶ä½œå’Œå¹¿å‘Šã€‚
   (2): è¿‡å»æ–¹æ³•ï¼šä¹‹å‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨åˆ©ç”¨å›¾åƒå‚è€ƒæ§åˆ¶é£æ ¼å’ŒåŠ¨ä½œï¼Œæˆ–é€šè¿‡è§†é¢‘ç¼–è¾‘è¿›è¡Œå®šåˆ¶åŒ–ç”Ÿæˆã€‚è¿™äº›æ–¹æ³•çš„é‡ç‚¹ä¸åœ¨äºèº«ä»½ç‰¹å®šæ§åˆ¶ã€‚
   (3): ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•çš„ä½†æœ‰æ•ˆçš„èº«ä»½ç‰¹å®šè§†é¢‘ç”Ÿæˆæ¡†æ¶ï¼Œç§°ä¸ºè§†é¢‘å®šåˆ¶åŒ–æ‰©æ•£ï¼ˆVCDï¼‰ã€‚VCD ä½¿ç”¨èº«ä»½æ¨¡å—æå–èº«ä»½ä¿¡æ¯ï¼Œå¹¶åœ¨åˆå§‹åŒ–é˜¶æ®µæ³¨å…¥å¸§é—´ç›¸å…³æ€§ï¼Œä»¥ç”Ÿæˆå…·æœ‰ç¨³å®šèº«ä»½çš„è§†é¢‘è¾“å‡ºã€‚
   (4): æ€§èƒ½ï¼šVCD åœ¨èº«ä»½ä¿ç•™æ–¹é¢ä¼˜äºé€‰å®šçš„å¼ºåŸºçº¿ã€‚æ­¤å¤–ï¼Œç”±äºèº«ä»½æ¨¡å—çš„å¯è¿ç§»æ€§ï¼ŒVCD ä¹Ÿé€‚ç”¨äºå…¬å¼€å¯ç”¨çš„å¾®è°ƒæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œè¿›ä¸€æ­¥æé«˜äº†å…¶å¯ç”¨æ€§ã€‚</li>
</ol>
<p>7.Methodsï¼š
ï¼ˆ1ï¼‰æå‡ºç”¨äº VCD çš„é¢„å¤„ç†æ¨¡å—ï¼Œä»¥åŠ ID æ¨¡å—å’Œè¿åŠ¨æ¨¡å—ï¼Œå¦‚å›¾ 3 æ‰€ç¤ºã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå¯é€‰æ¨¡å—ï¼Œåˆ©ç”¨ ControlNet Tile æ¥ä¸Šé‡‡æ ·è§†é¢‘å¹¶ç”Ÿæˆé«˜åˆ†è¾¨ç‡å†…å®¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº† AnimateDiff [18] ä¸­ç°æˆçš„è¿åŠ¨æ¨¡å—ï¼Œå¹¶é€šè¿‡æˆ‘ä»¬æå‡ºçš„ 3D é«˜æ–¯å™ªå£°å…ˆéªŒè¿›è¡Œäº†å¢å¼ºï¼Œå¦‚ç¬¬ 4.1 èŠ‚æ‰€è¿°ã€‚ID æ¨¡å—å…·æœ‰å¸¦æ©ç æŸå¤±å’Œæç¤ºåˆ°åˆ†å‰²çš„æ‰©å±• ID ä»¤ç‰Œï¼Œåœ¨ç¬¬ 4.2 èŠ‚ä¸­ä»‹ç»ã€‚åœ¨ç¬¬ 4.3 èŠ‚ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸¤ä¸ª V2V VCD ç®¡é“ï¼ŒFaceVCD å’Œ TiledVCDã€‚
ï¼ˆ2ï¼‰ä¸ºäº†ç®€å•èµ·è§ï¼Œæˆ‘ä»¬åº”ç”¨æˆ‘ä»¬çš„æ— è®­ç»ƒ 3D é«˜æ–¯å™ªå£°å…ˆéªŒåˆ°ç°æˆçš„è¿åŠ¨æ¨¡å— [18]ï¼Œä»¥å‡è½»æ¨ç†æœŸé—´çš„æ›å…‰åå·®ã€‚æ‰€é€‰çš„è¿åŠ¨æ¨¡å—å°†ç½‘ç»œæ‰©å±•åˆ°åŒ…å«æ—¶é—´ç»´åº¦ã€‚å®ƒå°† 2D å·ç§¯å’Œæ³¨æ„åŠ›å±‚è½¬æ¢ä¸ºæ—¶é—´ä¼ª 3D å±‚ [23]ï¼Œéµå¾ªæ–¹ç¨‹å¼ 2 ä¸­æ¦‚è¿°çš„è®­ç»ƒç›®æ ‡ã€‚3D é«˜æ–¯å™ªå£°å…ˆéªŒã€‚å¯¹äºåŒ…å« f å¸§çš„è§†é¢‘ï¼Œ3D é«˜æ–¯å™ªå£°å…ˆéªŒä»å¤šå…ƒé«˜æ–¯åˆ†å¸ƒ N(0, Î£f(Î³)) ä¸­é‡‡æ ·ã€‚è¿™é‡Œï¼ŒÎ£f(Î³) è¡¨ç¤ºç”± Î³âˆˆ(0,1) å‚æ•°åŒ–çš„åæ–¹å·®çŸ©é˜µã€‚Î£f(Î³)=ï£«ï£¬ï£¬ï£¬ï£¬ï£¬ï£­1Î³Î³2Â·Â·Â·Î³fâˆ’1Î³1Î³Â·Â·Â·Î³fâˆ’2Î³2Î³1Â·Â·Â·Î³fâˆ’3...............Î³fâˆ’1Î³fâˆ’2Î³fâˆ’3Â·Â·Â·1ï£¶ï£·ï£·ï£·ï£·ï£·ï£¸ã€‚(4)
ï¼ˆ3ï¼‰ä¸Šé¢æè¿°çš„åæ–¹å·®ç¡®ä¿åˆå§‹åŒ–çš„ 3D å™ªå£°åœ¨ m å’Œ n å¸§ä¹‹é—´çš„ç›¸åŒä½ç½®è¡¨ç°å‡º Î³|mâˆ’n| çš„åæ–¹å·®ã€‚è¶…å‚æ•° Î³ è¡¨ç¤ºç¨³å®šæ€§å’Œè¿åŠ¨å¹…åº¦ä¹‹é—´çš„æƒè¡¡ï¼Œå¦‚å›¾ 4 æ‰€ç¤ºã€‚è¾ƒä½çš„ Î³ å€¼ä¼šå¯¼è‡´è¿åŠ¨å‰§çƒˆä½†ç¨³å®šæ€§é™ä½çš„è§†é¢‘ï¼Œè€Œè¾ƒé«˜çš„ Î³ ä¼šå¯¼è‡´å¹…åº¦å‡å°çš„æ›´ç¨³å®šçš„è¿åŠ¨ã€‚
ï¼ˆ4ï¼‰ID æ¨¡å— VAE æç¤ºåˆ°åˆ†å‰² Lmask<v*>man ä¸»ä½“æ˜¯ä¸€ä¸ªç©¿ç€ç²‰è‰² T æ¤çš„äººå›¾ 5.æ‰©å±• ID ä»¤ç‰Œå­¦ä¹ ã€‚é€šè¿‡æç¤ºåˆ°åˆ†å‰²ï¼Œé’ˆå¯¹æ©ç ä¸»ä½“åŒºåŸŸå¯¹æ‰©å±• ID ä»¤ç‰Œè¿›è¡Œä¼˜åŒ–ã€‚è™½ç„¶ä»¥å‰çš„å·¥ä½œå·²ç»æ¢ç´¢äº† T2I èº«ä»½å®šåˆ¶çš„ä»¤ç‰ŒåµŒå…¥ [16,58] å’Œæƒé‡å¾®è°ƒ [11,17,31,48]ï¼Œä½†å¾ˆå°‘æœ‰äººæ·±å…¥ç ”ç©¶ T2V ç”Ÿæˆä¸­çš„èº«ä»½å®šåˆ¶ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œè™½ç„¶åƒ CustomDiffusion [31] æˆ– LoRA [25] è¿™æ ·çš„æƒé‡è°ƒæ•´æ–¹æ³•åœ¨å›¾åƒç”Ÿæˆä¸­å®ç°äº†ç²¾ç¡®çš„èº«ä»½ï¼Œä½†ç”Ÿæˆçš„è§†é¢‘é€šå¸¸æ˜¾ç¤ºå‡ºæœ‰é™çš„å¤šæ ·æ€§å’Œç”¨æˆ·è¾“å…¥å¯¹é½ã€‚æ‰©å±• ID ä»¤ç‰Œã€‚æˆ‘ä»¬å»ºè®®ä½¿ç”¨æ‰©å±• ID ä»¤ç‰Œä»…ä¸æ¡ä»¶ç¼–ç äº¤äº’ï¼Œå¹¶æ›´å¥½åœ°ä¿ç•™èº«ä»½çš„è§†è§‰ç‰¹å¾ï¼Œå¦‚å›¾ 5 æ‰€ç¤ºã€‚ä¸åŸå§‹ LoRA ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥äº§ç”Ÿæ›´å¥½çš„è§†é¢‘è´¨é‡ï¼Œå¦‚è¡¨ 1 æ‰€ç¤ºã€‚æ­¤å¤–ï¼Œæå‡ºçš„ ID æ¨¡å—åªéœ€è¦ 16KB çš„å­˜å‚¨ç©ºé—´ï¼Œä¸ Stable Diffusion ä¸­æ‰€éœ€çš„å‚æ•° 3.6G æˆ– SVDiff [20] ä¸­çš„ 1.7MB ç›¸æ¯”ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸ç´§å‡‘çš„å‚æ•°ç©ºé—´ã€‚</v*></p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰ï¼š
æœ¬æ–‡æå‡ºçš„ Video Custom Diffusionï¼ˆVCDï¼‰æ¡†æ¶æ—¨åœ¨è§£å†³å¯æ§è§†é¢‘ç”Ÿæˆä¸­ä¸»ä½“èº«ä»½æ§åˆ¶çš„æŒ‘æˆ˜ã€‚é€šè¿‡èåˆèº«ä»½ä¿¡æ¯å’Œå¸§é—´ç›¸å…³æ€§ï¼ŒVCD ä¸ºç”Ÿæˆä¸ä»…åœ¨å¸§é—´ä¿æŒä¸»ä½“èº«ä»½ï¼Œè€Œä¸”å…·æœ‰ç¨³å®šæ€§å’Œæ¸…æ™°åº¦çš„è§†é¢‘é“ºå¹³äº†é“è·¯ã€‚æˆ‘ä»¬æ–°é¢–çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬ç”¨äºç²¾ç¡®èº«ä»½åˆ†ç¦»çš„ ID æ¨¡å—ã€ç”¨äºå¢å¼ºå¸§ä¸€è‡´æ€§çš„ T2V VCD æ¨¡å—ä»¥åŠç”¨äºæé«˜è§†é¢‘è´¨é‡çš„ V2V æ¨¡å—ï¼Œå…±åŒä¸ºè§†é¢‘å†…å®¹ä¸­çš„èº«ä»½ä¿ç•™å»ºç«‹äº†æ–°çš„æ ‡å‡†ã€‚æˆ‘ä»¬è¿›è¡Œçš„å¹¿æ³›å®éªŒè‚¯å®šäº† VCD åœ¨ç”Ÿæˆé«˜è´¨é‡ã€ç¨³å®šä¸”ä¿ç•™ä¸»ä½“èº«ä»½çš„è§†é¢‘æ–¹é¢çš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ ID æ¨¡å—é€‚ç”¨äºç°æœ‰çš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œå¢å¼ºäº† VCD çš„å®ç”¨æ€§ï¼Œä½¿å…¶é€‚ç”¨äºå¹¿æ³›çš„åº”ç”¨ã€‚
ï¼ˆ2ï¼‰æœ¬æ–‡çš„åˆ›æ–°ç‚¹ã€æ€§èƒ½å’Œå·¥ä½œé‡æ€»ç»“ï¼š
åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§ç”¨äºè§†é¢‘å®šåˆ¶æ‰©æ•£çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†èº«ä»½ä¿¡æ¯å’Œå¸§é—´ç›¸å…³æ€§ï¼Œä»¥ç”Ÿæˆå…·æœ‰ç¨³å®šèº«ä»½çš„è§†é¢‘ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ª ID æ¨¡å—ï¼Œç”¨äºä»æ–‡æœ¬æç¤ºä¸­æå–èº«ä»½ä¿¡æ¯å¹¶å°†å…¶æ³¨å…¥è§†é¢‘ç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚</li>
<li>æå‡ºäº†ä¸€ç§ T2V VCD æ¨¡å—ï¼Œç”¨äºå¢å¼ºå¸§é—´ä¸€è‡´æ€§ï¼Œç”Ÿæˆå…·æœ‰å¹³æ»‘è¿åŠ¨å’Œæ¸…æ™°ç»†èŠ‚çš„è§†é¢‘ã€‚
æ€§èƒ½ï¼š</li>
<li>VCD åœ¨èº«ä»½ä¿ç•™æ–¹é¢ä¼˜äºé€‰å®šçš„å¼ºåŸºçº¿ï¼Œç”Ÿæˆçš„é«˜è´¨é‡è§†é¢‘åœ¨å¸§é—´ä¿æŒäº†ä¸»ä½“èº«ä»½ã€‚</li>
<li>ç”±äº ID æ¨¡å—çš„å¯è¿ç§»æ€§ï¼ŒVCD ä¹Ÿé€‚ç”¨äºå…¬å¼€å¯ç”¨çš„å¾®è°ƒæ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œè¿›ä¸€æ­¥æé«˜äº†å…¶å¯ç”¨æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>VCD çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä»…éœ€è¦å°‘é‡é¢å¤–çš„è®¡ç®—å¼€é”€ã€‚</li>
<li>ID æ¨¡å—å…·æœ‰ç´§å‡‘çš„å‚æ•°ç©ºé—´ï¼Œä»…éœ€ 16KB çš„å­˜å‚¨ç©ºé—´ï¼Œä½¿å…¶æ˜“äºéƒ¨ç½²å’Œä½¿ç”¨ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e6a21bfcb16c6c0deb1d0539ef94af7e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9fb6739198960204ae02b3df3b1108f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3af883ea390b349d783415082941342e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f79fc49019e994a2b5124fecafb23683.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ffb39f913681e339c8d1aa9719f971cb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8ad7c82a7b238a18cf1ae3935cfce436.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e509076266dabf0c8283fba23dba850.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ef1ee7f0f72cd6bec6307311ed8330ee.jpg" align="middle">
</details>




<h2 id="SGS-SLAM-Semantic-Gaussian-Splatting-For-Neural-Dense-SLAM"><a href="#SGS-SLAM-Semantic-Gaussian-Splatting-For-Neural-Dense-SLAM" class="headerlink" title="SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM"></a>SGS-SLAM: Semantic Gaussian Splatting For Neural Dense SLAM</h2><p><strong>Authors:Mingrui Li, Shuhong Liu, Heng Zhou, Guohao Zhu, Na Cheng, Hongyu Wang</strong></p>
<p>Semantic understanding plays a crucial role in Dense Simultaneous Localization and Mapping (SLAM). Recent advancements that integrate Gaussian Splatting into SLAM systems have demonstrated its effectiveness in generating high-quality renderings. Building on this progress, we propose SGS-SLAM which provides precise 3D semantic segmentation alongside high-fidelity reconstructions. Specifically, we propose to employ multi-channel optimization during the mapping process, integrating appearance, geometric, and semantic constraints with key-frame optimization to enhance reconstruction quality. Extensive experiments demonstrate that SGS-SLAM delivers state-of-the-art performance in camera pose estimation, map reconstruction, and semantic segmentation. It outperforms existing methods by a large margin meanwhile preserves real-time rendering ability. </p>
<p><a href="http://arxiv.org/abs/2402.03246v2">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>SGS-SLAM é‡‡ç”¨å¤šé€šé“ä¼˜åŒ–ï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸèå…¥å…³é”®å¸§ä¼˜åŒ–ä¸­ï¼Œå®ç°äº†é«˜ç²¾åº¦ 3D è¯­ä¹‰åˆ†å‰²å’Œé«˜ä¿çœŸé‡å»ºã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>åˆ©ç”¨é«˜æ–¯å–·å°„å°†è¯­ä¹‰ç†è§£èå…¥ SLAM ç³»ç»Ÿï¼Œç”Ÿæˆé«˜è´¨é‡æ¸²æŸ“æ•ˆæœã€‚</li>
<li>é‡‡ç”¨å¤šé€šé“ä¼˜åŒ–ï¼Œèåˆå¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸï¼Œæå‡é‡å»ºè´¨é‡ã€‚</li>
<li>åœ¨ç›¸æœºä½å§¿ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ã€‚</li>
<li>æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“èƒ½åŠ›ã€‚</li>
<li>æ‰©å±•äº† SLAM ç³»ç»Ÿçš„åº”ç”¨èŒƒå›´ï¼Œä½¿å…¶åœ¨è¯­ä¹‰ç†è§£å’Œé‡å»ºä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚</li>
<li>ä¸ºå®¤å†…æˆ–å®¤å¤–ç¯å¢ƒçš„é«˜ä¿çœŸé‡å»ºå’Œäº¤äº’å¼æ¢ç´¢æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚</li>
<li>ä¸ºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰é¢†åŸŸæä¾›äº†æ–°çš„æŠ€æœ¯æ”¯æŒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šSGS-SLAMï¼šç”¨äºç¥ç»ç¨ å¯† SLAM çš„è¯­ä¹‰é«˜æ–¯æ–‘ç‚¹ç»˜åˆ¶</li>
<li>ä½œè€…ï¼šMingrui Liã€Shuhong Liuã€Heng Zhouã€Guohao Zhuã€Na Chengã€Hongyu Wang</li>
<li>å•ä½ï¼šå¤§è¿ç†å·¥å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯ç³»</li>
<li>å…³é”®è¯ï¼šSLAMã€3D é‡å»ºã€3D è¯­ä¹‰åˆ†å‰²</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.03246ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šè¯­ä¹‰ç†è§£åœ¨ç¨ å¯† SLAM ä¸­è‡³å…³é‡è¦ï¼Œè€Œå°†é«˜æ–¯æ–‘ç‚¹ç»˜åˆ¶é›†æˆåˆ° SLAM ç³»ç»Ÿä¸­çš„æœ€æ–°è¿›å±•å·²è¯æ˜å…¶åœ¨ç”Ÿæˆé«˜è´¨é‡æ¸²æŸ“æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚
(2)ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šä¼ ç»Ÿè§†è§‰ SLAM ç³»ç»Ÿæ“…é•¿ä½¿ç”¨ç‚¹äº‘å’Œä½“ç´ è¿›è¡Œç¨€ç–é‡å»ºï¼Œä½†æ— æ³•è¿›è¡Œç¨ å¯†é‡å»ºã€‚åŸºäºå­¦ä¹ çš„ SLAM æ–¹æ³•å¯ä»¥æå–ç”¨äºé«˜è´¨é‡è¡¨ç¤ºçš„ç¨ å¯†å‡ ä½•ä¿¡æ¯ï¼Œä½†å®ƒä»¬å®¹æ˜“å—åˆ°å™ªå£°å’Œå¼‚å¸¸å€¼çš„å½±å“ã€‚ç¥ç»è¾å°„åœº (NeRF) å¯å‘çš„ SLAM æ–¹æ³•è¿›ä¸€æ­¥æé«˜äº†é‡å»ºè´¨é‡ï¼Œä½†å®ƒä»¬é€šå¸¸ä¸åŒ…å«è¯­ä¹‰ä¿¡æ¯ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º SGS-SLAMï¼Œå®ƒåœ¨é«˜ä¿çœŸé‡å»ºçš„åŒæ—¶æä¾›ç²¾ç¡®çš„ 3D è¯­ä¹‰åˆ†å‰²ã€‚SGS-SLAM åœ¨æ˜ å°„è¿‡ç¨‹ä¸­é‡‡ç”¨å¤šé€šé“ä¼˜åŒ–ï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸä¸å…³é”®å¸§ä¼˜åŒ–ç›¸ç»“åˆï¼Œä»¥å¢å¼ºé‡å»ºè´¨é‡ã€‚
(4)ï¼šä»»åŠ¡å’Œæ€§èƒ½ï¼šSGS-SLAM åœ¨ç›¸æœºå§¿æ€ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å®ƒä»¥å¾ˆå¤§çš„ä¼˜åŠ¿ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿ç•™äº†å®æ—¶æ¸²æŸ“èƒ½åŠ›ã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š
(1): SGS-SLAMé‡‡ç”¨å¤šé€šé“é«˜æ–¯è¡¨ç¤ºï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸä¸å…³é”®å¸§ä¼˜åŒ–ç›¸ç»“åˆï¼Œä»¥å¢å¼ºé‡å»ºè´¨é‡ã€‚
(2): è·Ÿè¸ªè¿‡ç¨‹ä¼°è®¡æ¯ä¸€å¸§çš„ç›¸æœºä½å§¿ï¼ŒåŒæ—¶ä¿æŒåœºæ™¯å‚æ•°å›ºå®šã€‚æ˜ å°„ä¼˜åŒ–åŸºäºä¼°è®¡çš„ç›¸æœºä½å§¿ä¼˜åŒ–åœºæ™¯è¡¨ç¤ºã€‚
(3): åœºæ™¯è¡¨ç¤ºä½¿ç”¨é«˜æ–¯å½±å“å‡½æ•° f(Â·)ï¼Œå…¶ä¸­ Ïƒ è¡¨ç¤ºä¸é€æ˜åº¦ï¼ŒÎ¼ è¡¨ç¤ºä¸­å¿ƒä½ç½®ï¼Œr è¡¨ç¤ºåŠå¾„ã€‚æ¯ä¸ªé«˜æ–¯è¿˜æºå¸¦ RGB é¢œè‰² ciã€‚
(4): ä½¿ç”¨æ¸²æŸ“æ–¹æ³•å°†é«˜æ–¯æ¸²æŸ“æˆ 2D å›¾åƒï¼Œé€šè¿‡æ²¿æ·±åº¦ç»´åº¦é€¼è¿‘å½±å“å‡½æ•° f(Â·) çš„ç§¯åˆ†æŠ•å½±æ¥å®Œæˆã€‚
(5): é€šè¿‡å¯¹é«˜æ–¯è¿›è¡Œæ·±åº¦æ’åºå¹¶æ‰§è¡Œä»å‰åˆ°åçš„ä½“ç§¯æ¸²æŸ“ï¼Œå¯ä»¥ç»„åˆæ‰€æœ‰é«˜æ–¯å¯¹è¯¥åƒç´ çš„å½±å“ã€‚
(6): åƒç´ çº§æ¸²æŸ“é¢œè‰² Cpix æ˜¯æ¯ä¸ªé«˜æ–¯é¢œè‰² ci çš„æ€»å’Œï¼Œå¹¶æ ¹æ®å½±å“å‡½æ•° f2Di,pix åŠ æƒï¼Œä¹˜ä»¥é®æŒ¡é¡¹ã€‚
(7): æ·±åº¦å¯ä»¥æ¸²æŸ“ä¸ºï¼šDpix = âˆ‘i=1 di f2Di,pix iâˆ’1 âˆj=1 (1âˆ’f2Dj,pix)ï¼Œå…¶ä¸­ di è¡¨ç¤ºæ¯ä¸ªé«˜æ–¯çš„æ·±åº¦ã€‚
(8): é€šè¿‡è®¾ç½® di=1ï¼Œå¯ä»¥è®¡ç®—å‡ºè½®å»“ Silpix = Dpix(di=1)ï¼Œè¿™æœ‰åŠ©äºç¡®å®šåƒç´ æ˜¯å¦åœ¨å½“å‰è§†å›¾ä¸­å¯è§ã€‚
(9): åœ¨æ˜ å°„è¿‡ç¨‹ä¸­ï¼Œå°† 2D è¯­ä¹‰æ ‡ç­¾åˆ†é…ç»™é«˜æ–¯å‚æ•°çš„ç‰¹å®šé€šé“ä»¥è¡¨ç¤ºå…¶è¯­ä¹‰æ ‡ç­¾å’Œé¢œè‰²ã€‚
(10): æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥ä»é‡å»ºçš„ 3D åœºæ™¯æ¸²æŸ“ 2D è¯­ä¹‰å›¾ï¼šSpix = âˆ‘i=1 si f2Di,pix iâˆ’1 âˆj=1 (1âˆ’f2Dj,pix)ï¼Œå…¶ä¸­ si = [ri, gi, bi]T è¡¨ç¤ºä¸é«˜æ–¯å…³è”çš„è¯­ä¹‰é¢œè‰²ã€‚
(11): ç›¸æœºä½å§¿ä¼°è®¡é€šè¿‡æœ€å°åŒ–è·Ÿè¸ªæŸå¤±æ¥å®ç°ï¼Œè¯¥æŸå¤±è¡¨ç¤ºçœŸå®é¢œè‰²ã€æ·±åº¦å›¾åƒå’Œè¯­ä¹‰å›¾ä¸å…¶å¯å¾®æ¸²æŸ“è§†å›¾ä¹‹é—´çš„å·®å¼‚ã€‚
(12): å…³é”®å¸§é€‰æ‹©å’ŒåŠ æƒï¼šåœ¨è·Ÿè¸ªé˜¶æ®µï¼ŒåŒæ—¶è¯†åˆ«å’Œå­˜å‚¨å…³é”®å¸§ã€‚è¿™äº›å…³é”®å¸§æä¾›äº†å¯¹è±¡çš„ä¸åŒè§†å›¾ï¼Œå¯¹äºæ˜ å°„ä¼˜åŒ– 3D åœºæ™¯é‡å»ºè‡³å…³é‡è¦ã€‚
(13): SGS-SLAM åœ¨æ’å®šæ—¶é—´é—´éš”å†…æ•è·å’Œå­˜å‚¨å…³é”®å¸§ã€‚éšåï¼Œæ ¹æ®å‡ ä½•å’Œè¯­ä¹‰çº¦æŸé€‰æ‹©ä¸å½“å‰å¸§å…³è”çš„å…³é”®å¸§ã€‚
(14): é¦–å…ˆè¿›è¡ŒåŸºäºå‡ ä½•çš„åˆå§‹é€‰æ‹©ï¼Œç„¶åè¿›è¡ŒåŸºäºè¯­ä¹‰çš„äºŒæ¬¡ç­›é€‰ã€‚
(15): å¯¹äºæ¯ä¸ªå…³é”®å¸§ï¼Œè®¡ç®—ä¸ç¡®å®šæ€§åˆ†æ•° U(t) = eâˆ’Ï„tï¼Œå…¶ä¸­ t è¡¨ç¤ºå…³é”®å¸§çš„æ—¶é—´æˆ³ï¼ŒÏ„ ä¸ºè¡°å‡ç³»æ•°ã€‚
(16): ä½¿ç”¨æ­¤ä¸ç¡®å®šæ€§åˆ†æ•°å¯¹æ˜ å°„æŸå¤± Lmapping åŠ æƒã€‚
(17): åœ°å›¾é‡å»ºï¼šåœºæ™¯ä½¿ç”¨ä¸‰ä¸ªä¸åŒé€šé“çš„é«˜æ–¯å»ºæ¨¡ï¼šå®ƒä»¬çš„å‡å€¼åæ ‡è¡¨ç¤ºåœºæ™¯çš„å‡ ä½•ä¿¡æ¯ï¼Œå®ƒä»¬çš„å¤–è§‚é¢œè‰²æç»˜äº†åœºæ™¯çš„è§†è§‰å¤–è§‚ï¼Œå®ƒä»¬çš„è¯­ä¹‰é¢œè‰²è¡¨ç¤ºå¯¹è±¡çš„è¯­ä¹‰æ ‡ç­¾ã€‚
(18): åœ¨é«˜æ–¯è‡´å¯†åŒ–å’Œä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œè·¨é€šé“çš„è¿™äº›å‚æ•°è¢«è”åˆä¼˜åŒ–ï¼Œè€Œä»è·Ÿè¸ªä¸­ç¡®å®šçš„ç›¸æœºä½å§¿ä¿æŒå›ºå®šã€‚
(19): ä»ç¬¬ä¸€å¸§å¼€å§‹ï¼Œæ‰€æœ‰åƒç´ éƒ½æœ‰åŠ©äºåˆå§‹åŒ–åœ°å›¾ã€‚
(20): åœ¨æ–°æ—¶é—´æ­¥çš„åœ°å›¾é‡å»ºè¿‡ç¨‹ä¸­ï¼Œå°†æ–°é«˜æ–¯å¼•å…¥åˆ°åœ°å›¾ä¸­ï¼Œè¿™äº›åŒºåŸŸè¦ä¹ˆå¯†åº¦ä¸è¶³ï¼Œè¦ä¹ˆæ˜¾ç¤ºå…ˆå‰ä¼°è®¡çš„åœ°å›¾å‰é¢çš„æ–°å‡ ä½•å½¢çŠ¶ã€‚
(21): é€šè¿‡å°†æ©ç åº”ç”¨äºåƒç´ æ¥è°ƒèŠ‚æ–°é«˜æ–¯çš„æ·»åŠ ï¼Œå…¶ä¸­è¦ä¹ˆ (i) è½®å»“å€¼ Silpix ä½äºæŸä¸ªé˜ˆå€¼ï¼Œè¡¨ç¤ºå¯è§æ€§é«˜åº¦ä¸ç¡®å®šï¼Œè¦ä¹ˆ (ii) çœŸå®æ·±åº¦è¿œå°äºä¼°è®¡æ·±åº¦ï¼Œè¡¨æ˜å­˜åœ¨æ–°çš„å‡ ä½•å®ä½“ã€‚
(22): è‡´å¯†åŒ–åï¼Œé€šè¿‡æœ€å°åŒ–æ˜ å°„æŸå¤±æ¥ä¼˜åŒ–åœ°å›¾å‚æ•°ï¼šLmapping = U âˆ‘pix Î»D |DGTpixâˆ’Dpix| + Î»C L C + Î»S L Sã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰ï¼šSGS-SLAM åœ¨è¿›è¡Œé«˜ä¿çœŸé‡å»ºçš„åŒæ—¶æä¾›äº†ç²¾ç¡®çš„ 3D è¯­ä¹‰åˆ†å‰²ï¼Œåœ¨ç›¸æœºå§¿æ€ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä¸ºç¥ç»ç¨ å¯† SLAM æä¾›äº†ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆã€‚
ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š
åˆ›æ–°ç‚¹ï¼šSGS-SLAM é‡‡ç”¨å¤šé€šé“é«˜æ–¯è¡¨ç¤ºï¼Œå°†å¤–è§‚ã€å‡ ä½•å’Œè¯­ä¹‰çº¦æŸä¸å…³é”®å¸§ä¼˜åŒ–ç›¸ç»“åˆï¼Œå¢å¼ºäº†é‡å»ºè´¨é‡ï¼Œå¹¶é¦–æ¬¡å°†è¯­ä¹‰ä¿¡æ¯é›†æˆåˆ°ç¥ç»ç¨ å¯† SLAM ç³»ç»Ÿä¸­ã€‚
æ€§èƒ½ï¼šSGS-SLAM åœ¨ç›¸æœºå§¿æ€ä¼°è®¡ã€åœ°å›¾é‡å»ºå’Œè¯­ä¹‰åˆ†å‰²æ–¹é¢éƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä»¥å¾ˆå¤§çš„ä¼˜åŠ¿ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶ä¿ç•™äº†å®æ—¶æ¸²æŸ“èƒ½åŠ›ã€‚
å·¥ä½œé‡ï¼šSGS-SLAM çš„å®ç°éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ•°æ®ï¼Œè¿™å¯èƒ½ä¼šé™åˆ¶å…¶åœ¨æŸäº›èµ„æºå—é™çš„åº”ç”¨ä¸­çš„ä½¿ç”¨ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-49d695fd07273ec0ead5f03d33095327.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f9e64fa80d8afdcf89c98cfd50dd717f.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>Talking Head Generation</title>
    <url>/2024/02/29/Paper/2024-02-29/Talking%20Head%20Generation/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-29-æ›´æ–°"><a href="#2024-02-29-æ›´æ–°" class="headerlink" title="2024-02-29 æ›´æ–°"></a>2024-02-29 æ›´æ–°</h1><h2 id="EMO-Emote-Portrait-Alive-Generating-Expressive-Portrait-Videos-with-Audio2Video-Diffusion-Model-under-Weak-Conditions"><a href="#EMO-Emote-Portrait-Alive-Generating-Expressive-Portrait-Videos-with-Audio2Video-Diffusion-Model-under-Weak-Conditions" class="headerlink" title="EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with   Audio2Video Diffusion Model under Weak Conditions"></a>EMO: Emote Portrait Alive - Generating Expressive Portrait Videos with   Audio2Video Diffusion Model under Weak Conditions</h2><p><strong>Authors:Linrui Tian, Qi Wang, Bang Zhang, Liefeng Bo</strong></p>
<p>In this work, we tackle the challenge of enhancing the realism and expressiveness in talking head video generation by focusing on the dynamic and nuanced relationship between audio cues and facial movements. We identify the limitations of traditional techniques that often fail to capture the full spectrum of human expressions and the uniqueness of individual facial styles. To address these issues, we propose EMO, a novel framework that utilizes a direct audio-to-video synthesis approach, bypassing the need for intermediate 3D models or facial landmarks. Our method ensures seamless frame transitions and consistent identity preservation throughout the video, resulting in highly expressive and lifelike animations. Experimental results demonsrate that EMO is able to produce not only convincing speaking videos but also singing videos in various styles, significantly outperforming existing state-of-the-art methodologies in terms of expressiveness and realism. </p>
<p><a href="http://arxiv.org/abs/2402.17485v1">PDF</a> </p>
<p><strong>Summary</strong><br>éŸ³é¢‘çº¿ç´¢èƒ½å¤ŸååŠ©ç”Ÿæˆæ›´å…·è¡¨ç°åŠ›å’ŒçœŸå®æ„Ÿçš„é¢éƒ¨åŠ¨ç”»ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä¼ ç»ŸæŠ€æœ¯æ— æ³•å……åˆ†æ•æ‰äººç±»é¢éƒ¨è¡¨æƒ…å’Œä¸ªäººé£æ ¼å·®å¼‚ã€‚</li>
<li>EMO æ¡†æ¶é‡‡ç”¨ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆæ–¹æ³•ï¼Œæ— éœ€ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹ã€‚</li>
<li>EMO å¯ç”Ÿæˆæµç•…æ— ç¼çš„è§†é¢‘ï¼Œå¹¶å§‹ç»ˆä¿æŒèº«ä»½ä¸€è‡´æ€§ã€‚</li>
<li>EMO å¯ç”Ÿæˆå…·æœ‰é«˜åº¦è¡¨ç°åŠ›å’ŒçœŸå®æ„Ÿçš„è¯´è¯å’Œå”±æ­Œè§†é¢‘ã€‚</li>
<li>EMO åœ¨è¡¨ç°åŠ›å’ŒçœŸå®æ„Ÿæ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>EMO å……åˆ†åˆ©ç”¨äº†éŸ³é¢‘çº¿ç´¢ï¼Œæå‡äº†é¢éƒ¨åŠ¨ç”»çš„åŠ¨æ€æ€§å’Œç»†è‡´åº¦ã€‚</li>
<li>EMO å¯å¹¿æ³›åº”ç”¨äºå„ç§é¢†åŸŸï¼ŒåŒ…æ‹¬ç”µå½±ã€æ¸¸æˆå’Œè§†é¢‘ä¼šè®®ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šEMOï¼šEmotePortraitAliveâ€”â€”åœ¨å¼±æ¡ä»¶ä¸‹ä½¿ç”¨éŸ³é¢‘åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›çš„è‚–åƒè§†é¢‘</li>
<li>ä½œè€…ï¼šTian Linruiã€Wang Qiã€Zhang Bangã€Bo Liefeng</li>
<li>éš¶å±å•ä½ï¼šé˜¿é‡Œå·´å·´é›†å›¢æ™ºèƒ½è®¡ç®—ç ”ç©¶é™¢</li>
<li>å…³é”®è¯ï¼šAudio-driven portrait video generationã€Talking headã€Expressive facial expressionsã€Audio-to-video synthesis</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://humanaigc.github.io/emote-portrait-alive/
   Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
   åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä¸­ï¼Œå¢å¼ºçœŸå®æ„Ÿå’Œè¡¨ç°åŠ›æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œéœ€è¦å…³æ³¨éŸ³é¢‘çº¿ç´¢å’Œé¢éƒ¨åŠ¨ä½œä¹‹é—´çš„åŠ¨æ€å’Œç»†å¾®å…³ç³»ã€‚ä¼ ç»ŸæŠ€æœ¯å¾€å¾€æ— æ³•æ•æ‰åˆ°äººç±»è¡¨æƒ…çš„å…¨è²Œå’Œä¸ªäººé¢éƒ¨é£æ ¼çš„ç‹¬ç‰¹æ€§ã€‚
   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼š
   ä¼ ç»Ÿçš„è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆæ–¹æ³•é€šå¸¸éœ€è¦ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹ï¼Œè¿™ä¼šå¼•å…¥é¢å¤–çš„å¤æ‚æ€§å’Œé™åˆ¶ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•åœ¨æ•æ‰ç»†å¾®çš„è¡¨æƒ…å’Œä¿æŒå¸§ä¹‹é—´çš„ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨å›°éš¾ã€‚
   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š
   æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º EMO çš„æ–°æ¡†æ¶ï¼Œå®ƒé‡‡ç”¨ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆçš„æ–¹æ³•ï¼Œç»•è¿‡äº†å¯¹ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹çš„éœ€æ±‚ã€‚è¯¥æ–¹æ³•åˆ©ç”¨éŸ³é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†éŸ³é¢‘çº¿ç´¢ç›´æ¥æ˜ å°„åˆ°è§†é¢‘å¸§ï¼Œç¡®ä¿äº†æ— ç¼çš„å¸§è¿‡æ¸¡å’Œä¸€è‡´çš„é¢éƒ¨åŠ¨ä½œã€‚
   ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼š
   EMO åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿çš„é€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„è§†é¢‘æ–¹é¢å–å¾—äº†æ˜¾ç€æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡å¢å¼ºè¯´è¯äººå¤´åƒè§†é¢‘ç”ŸæˆçœŸå®æ„Ÿå’Œè¡¨ç°åŠ›çš„ç›®æ ‡ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼šï¼ˆ1ï¼‰æå‡ºäº†ä¸€ç§åä¸ºEMOçš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆçš„æ–¹æ³•ï¼Œç»•è¿‡äº†å¯¹ä¸­é—´3Dæ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹çš„éœ€æ±‚ã€‚ï¼ˆ2ï¼‰è¯¥æ–¹æ³•åˆ©ç”¨éŸ³é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†éŸ³é¢‘çº¿ç´¢ç›´æ¥æ˜ å°„åˆ°è§†é¢‘å¸§ï¼Œç¡®ä¿äº†æ— ç¼çš„å¸§è¿‡æ¸¡å’Œä¸€è‡´çš„é¢éƒ¨åŠ¨ä½œã€‚ï¼ˆ3ï¼‰åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šå¯¹EMOè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿çš„é€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„è§†é¢‘æ–¹é¢å–å¾—äº†æ˜¾ç€æ€§èƒ½ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åä¸º EMO çš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆçš„æ–¹æ³•ï¼Œç»•è¿‡äº†å¯¹ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹çš„éœ€æ±‚ã€‚è¯¥æ–¹æ³•åˆ©ç”¨éŸ³é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†éŸ³é¢‘çº¿ç´¢ç›´æ¥æ˜ å°„åˆ°è§†é¢‘å¸§ï¼Œç¡®ä¿äº†æ— ç¼çš„å¸§è¿‡æ¸¡å’Œä¸€è‡´çš„é¢éƒ¨åŠ¨ä½œã€‚åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šå¯¹ EMO è¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆå…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿çš„é€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„è§†é¢‘æ–¹é¢å–å¾—äº†æ˜¾ç€æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡å¢å¼ºè¯´è¯äººå¤´åƒè§†é¢‘ç”ŸæˆçœŸå®æ„Ÿå’Œè¡¨ç°åŠ›çš„ç›®æ ‡ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</li>
<li>ç›´æ¥éŸ³é¢‘åˆ°è§†é¢‘åˆæˆçš„æ–¹æ³•ï¼Œç»•è¿‡äº†å¯¹ä¸­é—´ 3D æ¨¡å‹æˆ–é¢éƒ¨å…³é”®ç‚¹çš„éœ€æ±‚ã€‚</li>
<li>åˆ©ç”¨éŸ³é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†éŸ³é¢‘çº¿ç´¢ç›´æ¥æ˜ å°„åˆ°è§†é¢‘å¸§ï¼Œç¡®ä¿äº†æ— ç¼çš„å¸§è¿‡æ¸¡å’Œä¸€è‡´çš„é¢éƒ¨åŠ¨ä½œã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è¯´è¯äººå¤´åƒè§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾ç€æ€§èƒ½ã€‚</li>
<li>ç”Ÿæˆäº†å…·æœ‰ä¸°å¯Œé¢éƒ¨è¡¨æƒ…å’Œå¤´éƒ¨å§¿åŠ¿çš„é€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„è§†é¢‘ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦å¤æ‚çš„ä¸­é—´æ­¥éª¤æˆ–é¢å¤–çš„æ¨¡å‹ã€‚</li>
</ol>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-10c8e47dfe09b5369134bad3bf5b1e69.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-262ccbd331f2623737aa6cbcc24c64e5.jpg" align="middle">
</details>




<h2 id="Learning-Dynamic-Tetrahedra-for-High-Quality-Talking-Head-Synthesis"><a href="#Learning-Dynamic-Tetrahedra-for-High-Quality-Talking-Head-Synthesis" class="headerlink" title="Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis"></a>Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis</h2><p><strong>Authors:Zicheng Zhang, Ruobing Zheng, Ziwen Liu, Congying Han, Tianqi Li, Meng Wang, Tiande Guo, Jingdong Chen, Bonan Li, Ming Yang</strong></p>
<p>Recent works in implicit representations, such as Neural Radiance Fields (NeRF), have advanced the generation of realistic and animatable head avatars from video sequences. These implicit methods are still confronted by visual artifacts and jitters, since the lack of explicit geometric constraints poses a fundamental challenge in accurately modeling complex facial deformations. In this paper, we introduce Dynamic Tetrahedra (DynTet), a novel hybrid representation that encodes explicit dynamic meshes by neural networks to ensure geometric consistency across various motions and viewpoints. DynTet is parameterized by the coordinate-based networks which learn signed distance, deformation, and material texture, anchoring the training data into a predefined tetrahedra grid. Leveraging Marching Tetrahedra, DynTet efficiently decodes textured meshes with a consistent topology, enabling fast rendering through a differentiable rasterizer and supervision via a pixel loss. To enhance training efficiency, we incorporate classical 3D Morphable Models to facilitate geometry learning and define a canonical space for simplifying texture learning. These advantages are readily achievable owing to the effective geometric representation employed in DynTet. Compared with prior works, DynTet demonstrates significant improvements in fidelity, lip synchronization, and real-time performance according to various metrics. Beyond producing stable and visually appealing synthesis videos, our method also outputs the dynamic meshes which is promising to enable many emerging applications. </p>
<p><a href="http://arxiv.org/abs/2402.17364v1">PDF</a> CVPR 2024</p>
<p><strong>Summary</strong><br>ç¥ç»ç½‘ç»œç¼–ç çš„åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰æ˜¯ä¸€ç§ç»“åˆè¡¨ç¤ºæ–¹æ³•ï¼Œç¡®ä¿äº†å¤æ‚é¢éƒ¨å˜å½¢åœ¨å„ç§åŠ¨ä½œå’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DynTet é‡‡ç”¨åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå°†æ˜¾å¼åŠ¨æ€ç½‘æ ¼ç¼–ç åˆ°ç¥ç»ç½‘ç»œä¸­ï¼Œä»¥ç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>åæ ‡ç½‘ç»œç”¨äºå­¦ä¹ ç¬¦å·è·ç¦»ã€å½¢å˜å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚</li>
<li>è¿ç”¨ Marching Tetrahedraï¼ŒDynTet æœ‰æ•ˆåœ°è§£ç å…·æœ‰è¿ç»­æ‹“æ‰‘çš„çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å™¨å®ç°å¿«é€Ÿæ¸²æŸ“å¹¶åˆ©ç”¨åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ã€‚</li>
<li>DynTet ç»“åˆç»å…¸ 3D å¯å˜å½¢æ¨¡å‹ï¼Œä»¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ å¹¶å®šä¹‰ä¸€ç§è§„èŒƒç©ºé—´ä»¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</li>
<li>DynTet ç›¸æ¯”äºå…ˆå‰çš„ç ”ç©¶ï¼Œåœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢éƒ½æœ‰æ˜¾è‘—æå‡ã€‚</li>
<li>é™¤äº†åˆ¶ä½œç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘ï¼Œè¯¥æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›å®ç°è®¸å¤šæ–°å…´åº”ç”¨ã€‚</li>
<li>DynTet å¼¥è¡¥äº†éšå¼æ–¹æ³•ç¼ºä¹æ˜¾å¼å‡ ä½•çº¦æŸçš„é—®é¢˜ï¼Œé€šè¿‡å­¦ä¹ åŠ¨æ€ç½‘æ ¼æ¥æé«˜é¢éƒ¨å˜å½¢å»ºæ¨¡çš„å‡†ç¡®æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šç”¨äºé«˜è´¨é‡è¯´è¯äººå¤´éƒ¨åˆæˆçš„åŠ¨æ€å››é¢ä½“å­¦ä¹ </li>
<li>ä½œè€…ï¼šZhang Zhicheng, Xu Chenyang, Zhang Haoran, Wu Yuxuan, Wang Yebin, Chen Min, Chen Biao</li>
<li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè¯´è¯äººå¤´éƒ¨åˆæˆã€åŠ¨æ€ç½‘æ ¼ã€éšå¼è¡¨ç¤ºã€ç¥ç»è¾å°„åœº</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.05915</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšå¼è¡¨ç¤ºæ–¹æ³•ï¼Œå¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œåœ¨ä»è§†é¢‘åºåˆ—ä¸­ç”Ÿæˆé€¼çœŸä¸”å¯åŠ¨ç”»çš„å¤´éƒ¨å¤´åƒæ–¹é¢å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹æ˜¾å¼å‡ ä½•çº¦æŸï¼Œè¿™äº›éšå¼æ–¹æ³•ä»é¢ä¸´è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨çš„æŒ‘æˆ˜ï¼Œè¿™ç»™å‡†ç¡®å»ºæ¨¡å¤æ‚çš„é¢éƒ¨å˜å½¢å¸¦æ¥äº†æ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šä»¥å¾€æ–¹æ³•ä¸»è¦é‡‡ç”¨éšå¼è¡¨ç¤ºï¼Œç”±äºç¼ºä¹æ˜¾å¼å‡ ä½•çº¦æŸï¼Œå­˜åœ¨è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºï¼Œå®ƒé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿åœ¨å„ç§è¿åŠ¨å’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚DynTet ç”±åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œè¿™äº›ç½‘ç»œå­¦ä¹ æœ‰ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚åˆ©ç”¨è¡Œè¿›å››é¢ä½“ï¼ŒDynTet æœ‰æ•ˆåœ°è§£ç å…·æœ‰ç»Ÿä¸€æ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å™¨å’Œåƒç´ æŸå¤±è¿›è¡Œç›‘ç£ï¼Œä»è€Œå®ç°å¿«é€Ÿæ¸²æŸ“ã€‚ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡ï¼Œæˆ‘ä»¬ç»“åˆäº†ç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹ï¼Œä»¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ å¹¶å®šä¹‰è§„èŒƒç©ºé—´ä»¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚ç”±äº DynTet ä¸­é‡‡ç”¨æœ‰æ•ˆçš„å‡ ä½•è¡¨ç¤ºï¼Œè¿™äº›ä¼˜åŠ¿å¾ˆå®¹æ˜“å®ç°ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šä¸ä¹‹å‰çš„å·¥ä½œç›¸æ¯”ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢æ ¹æ®å„ç§æŒ‡æ ‡å±•ç¤ºäº†æ˜¾ç€çš„æ”¹è¿›ã€‚é™¤äº†åˆ¶ä½œç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œè¿™æœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): æå‡ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰æ¡†æ¶ï¼Œå¿«é€Ÿä»çŸ­è§†é¢‘åºåˆ—å­¦ä¹  3D å¤´éƒ¨å¤´åƒï¼Œå¹¶å®ç°é«˜è´¨é‡è¯´è¯äººå¤´éƒ¨å®æ—¶æ¸²æŸ“ã€‚
(2): æ”¹è¿›å››é¢ä½“è¡¨ç¤ºï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿ä¸åŒè¿åŠ¨å’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚
(3): é‡‡ç”¨è¡Œè¿›å››é¢ä½“è§£ç å…·æœ‰ç»Ÿä¸€æ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å™¨å’Œåƒç´ æŸå¤±è¿›è¡Œç›‘ç£ï¼Œå®ç°å¿«é€Ÿæ¸²æŸ“ã€‚
(4): ç»“åˆç»å…¸ 3D å¯å˜å½¢æ¨¡å‹ï¼Œä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå®šä¹‰è§„èŒƒç©ºé—´ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åä¸ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰çš„æ–°å‹æ··åˆè¡¨ç¤ºï¼Œç”¨äºä»çŸ­è§†é¢‘åºåˆ—ä¸­å­¦ä¹ é€¼çœŸä¸”å¯åŠ¨ç”»çš„è¯´è¯äººå¤´éƒ¨ï¼Œå¹¶å®ç°äº†é«˜è´¨é‡è¯´è¯äººå¤´éƒ¨å®æ—¶æ¸²æŸ“ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š
æå‡ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰æ¡†æ¶ï¼Œå¿«é€Ÿä»çŸ­è§†é¢‘åºåˆ—å­¦ä¹  3D å¤´éƒ¨å¤´åƒï¼Œå¹¶å®ç°é«˜è´¨é‡è¯´è¯äººå¤´éƒ¨å®æ—¶æ¸²æŸ“ã€‚
æ”¹è¿›å››é¢ä½“è¡¨ç¤ºï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿ä¸åŒè¿åŠ¨å’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚
é‡‡ç”¨è¡Œè¿›å››é¢ä½“è§£ç å…·æœ‰ç»Ÿä¸€æ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®æ¸²æŸ“å™¨å’Œåƒç´ æŸå¤±è¿›è¡Œç›‘ç£ï¼Œå®ç°å¿«é€Ÿæ¸²æŸ“ã€‚
ç»“åˆç»å…¸ 3D å¯å˜å½¢æ¨¡å‹ï¼Œä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå®šä¹‰è§„èŒƒç©ºé—´ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚
æ€§èƒ½ï¼š
ä¸ä¹‹å‰çš„å·¥ä½œç›¸æ¯”ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢æ ¹æ®å„ç§æŒ‡æ ‡å±•ç¤ºäº†æ˜¾ç€çš„æ”¹è¿›ã€‚
é™¤äº†åˆ¶ä½œç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œè¿™æœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚
å·¥ä½œé‡ï¼š
æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œæ¶‰åŠåˆ°ç¥ç»ç½‘ç»œã€åŠ¨æ€ç½‘æ ¼ã€éšå¼è¡¨ç¤ºã€ç¥ç»è¾å°„åœºç­‰å¤šä¸ªæ–¹é¢ã€‚
ä½œè€…æå‡ºäº†ä¸€ä¸ªæ–°çš„æ··åˆè¡¨ç¤ºâ€”â€”åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå¹¶å°†å…¶åº”ç”¨äºè¯´è¯äººå¤´éƒ¨åˆæˆä»»åŠ¡ä¸­ã€‚
DynTet ç»“åˆäº†æ˜¾å¼åŠ¨æ€ç½‘æ ¼å’Œéšå¼è¡¨ç¤ºçš„ä¼˜ç‚¹ï¼Œèƒ½å¤Ÿç”Ÿæˆé€¼çœŸä¸”å¯åŠ¨ç”»çš„å¤´éƒ¨å¤´åƒã€‚
ä½œè€…è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„è®­ç»ƒæ¡†æ¶ï¼Œç»“åˆäº†ç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹å’Œå¯å¾®æ¸²æŸ“å™¨ã€‚
è¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ å‡ ä½•å’Œçº¹ç†ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆè§†é¢‘ã€‚
æ€»ä½“è€Œè¨€ï¼Œæœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œä½†æå‡ºçš„æ–¹æ³•æ–°é¢–æœ‰æ•ˆï¼Œåœ¨è¯´è¯äººå¤´éƒ¨åˆæˆé¢†åŸŸå…·æœ‰é‡è¦çš„æ„ä¹‰ã€‚</p>
</li>
</ol>



<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2927e4da13bb2db0a8c147b32e65c4ba.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a69eb8d9ee3b7163b0dd216926919257.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-989288a0ad24820fe95020a4ed1f2ea7.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/03/04/Paper/2024-03-04/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-04-æ›´æ–°"><a href="#2024-03-04-æ›´æ–°" class="headerlink" title="2024-03-04 æ›´æ–°"></a>2024-03-04 æ›´æ–°</h1><h2 id="DistriFusion-Distributed-Parallel-Inference-for-High-Resolution-Diffusion-Models"><a href="#DistriFusion-Distributed-Parallel-Inference-for-High-Resolution-Diffusion-Models" class="headerlink" title="DistriFusion: Distributed Parallel Inference for High-Resolution   Diffusion Models"></a>DistriFusion: Distributed Parallel Inference for High-Resolution   Diffusion Models</h2><p><strong>Authors:Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Ming-Yu Liu, Kai Li, Song Han</strong></p>
<p>Diffusion models have achieved great success in synthesizing high-quality images. However, generating high-resolution images with diffusion models is still challenging due to the enormous computational costs, resulting in a prohibitive latency for interactive applications. In this paper, we propose DistriFusion to tackle this problem by leveraging parallelism across multiple GPUs. Our method splits the model input into multiple patches and assigns each patch to a GPU. However, na\â€{\i}vely implementing such an algorithm breaks the interaction between patches and loses fidelity, while incorporating such an interaction will incur tremendous communication overhead. To overcome this dilemma, we observe the high similarity between the input from adjacent diffusion steps and propose displaced patch parallelism, which takes advantage of the sequential nature of the diffusion process by reusing the pre-computed feature maps from the previous timestep to provide context for the current step. Therefore, our method supports asynchronous communication, which can be pipelined by computation. Extensive experiments show that our method can be applied to recent Stable Diffusion XL with no quality degradation and achieve up to a 6.1$\times$ speedup on eight NVIDIA A100s compared to one. Our code is publicly available at <a href="https://github.com/mit-han-lab/distrifuser">https://github.com/mit-han-lab/distrifuser</a>. </p>
<p><a href="http://arxiv.org/abs/2402.19481v1">PDF</a> CVPR 2024 Code: <a href="https://github.com/mit-han-lab/distrifuser">https://github.com/mit-han-lab/distrifuser</a> Website:   <a href="https://hanlab.mit.edu/projects/distrifusion">https://hanlab.mit.edu/projects/distrifusion</a> Blog:   <a href="https://hanlab.mit.edu/blog/distrifusion">https://hanlab.mit.edu/blog/distrifusion</a></p>
<p><strong>Summary</strong><br>åˆ©ç”¨å¤šGPUå®ç°å¹¶è¡Œå¤„ç†ï¼Œæå‡é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆæ•ˆç‡ï¼Œå¹¶é€šè¿‡å¤ç”¨ç‰¹å¾å›¾é™ä½é€šä¿¡å¼€é”€ï¼Œæ˜¾è‘—åŠ é€Ÿæ‰©æ•£æ¨¡å‹æ¨ç†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å¤šGPUå¹¶è¡Œå¤„ç†å¯å¤§å¹…æå‡æ‰©æ•£æ¨¡å‹æ¨ç†é€Ÿåº¦ã€‚</li>
<li>å°†æ¨¡å‹è¾“å…¥æ‹†åˆ†ä¸ºå¤šä¸ªpatchï¼Œåˆ†é…ç»™ä¸åŒGPUå¤„ç†ã€‚</li>
<li>ä½ç§»patchå¹¶è¡Œæœºåˆ¶ï¼Œåˆ©ç”¨ç›¸é‚»æ‰©æ•£æ­¥é•¿çš„ç›¸ä¼¼æ€§ï¼Œå¤ç”¨ç‰¹å¾å›¾å‡å°‘é€šä¿¡å¼€é”€ã€‚</li>
<li>æ”¯æŒå¼‚æ­¥é€šä¿¡ï¼Œå¯ä¸è®¡ç®—æµæ°´çº¿åŒ–ã€‚</li>
<li>åœ¨Stable Diffusion XLæ¨¡å‹ä¸ŠéªŒè¯æœ‰æ•ˆæ€§ï¼Œæ— è´¨é‡æŸå¤±ä¸”åŠ é€Ÿ6.1å€ã€‚</li>
<li>å·²å¼€æºä»£ç ï¼š<a href="https://github.com/mit-han-lab/distrifuser">https://github.com/mit-han-lab/distrifuser</a>.</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šDistriFusionï¼šç”¨äºé«˜åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹çš„åˆ†å¸ƒå¼å¹¶è¡Œæ¨ç†</li>
<li>ä½œè€…ï¼šMuyang Liã€Tianle Caiã€Jiaxin Caoã€Qinsheng Zhangã€Han Caiã€Junjie Baiã€Yangqing Jiaã€Ming-Yu Liuã€Kai Liã€Song Han</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéº»çœç†å·¥å­¦é™¢</li>
<li>å…³é”®è¯ï¼šDiffusion Modelsã€Parallel Inferenceã€High-Resolution Images</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.19481
Github ä»£ç é“¾æ¥ï¼šhttps://github.com/mit-han-lab/distrifuser</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨åˆæˆé«˜è´¨é‡å›¾åƒæ–¹é¢å–å¾—äº†å·¨å¤§æˆåŠŸã€‚ç„¶è€Œï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè®¡ç®—æˆæœ¬å·¨å¤§ï¼Œå¯¼è‡´äº¤äº’å¼åº”ç”¨ç¨‹åºçš„å»¶è¿Ÿå¾ˆé«˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»çš„æ–¹æ³•å°†æ¨¡å‹è¾“å…¥æ‹†åˆ†ä¸ºå¤šä¸ªå—ï¼Œå¹¶å°†å…¶åˆ†é…ç»™ä¸åŒçš„ GPUã€‚ç„¶è€Œï¼Œè¿™ç§æœ´ç´ çš„å®ç°ä¼šç ´åå—ä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œé™ä½ä¿çœŸåº¦ã€‚è€Œå¼•å…¥äº¤äº’åˆä¼šå¯¼è‡´å·¨å¤§çš„é€šä¿¡å¼€é”€ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº† DistriFusionï¼Œé€šè¿‡åˆ©ç”¨å¤š GPU çš„å¹¶è¡Œæ€§æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§è´¨ï¼Œé‡ç”¨æ¥è‡ªå‰ä¸€æ—¶é—´æ­¥çš„é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œä¸ºå½“å‰æ—¶é—´æ­¥æä¾›ä¸Šä¸‹æ–‡ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šDistriFusion å¯ä»¥åº”ç”¨äºæœ€æ–°çš„ Stable Diffusion XLï¼Œä¸”ä¸é™ä½è´¨é‡ã€‚ä¸å•ä¸ª GPU ç›¸æ¯”ï¼Œåœ¨å…«ä¸ª NVIDIA A100 ä¸Šï¼Œè¯¥æ–¹æ³•å®ç°äº†é«˜è¾¾ 6.1 å€çš„åŠ é€Ÿã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³ä»¥è¾ƒä½çš„å»¶è¿Ÿç”Ÿæˆé«˜è´¨é‡çš„é«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
</ol>
<p><strong>7. æ–¹æ³•</strong>
(1): DistriFusioné€šè¿‡åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§è´¨ï¼Œé‡ç”¨æ¥è‡ªå‰ä¸€æ—¶é—´æ­¥çš„é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œä¸ºå½“å‰æ—¶é—´æ­¥æä¾›ä¸Šä¸‹æ–‡ï¼Œä»è€Œè§£å†³å¤šGPUå¹¶è¡Œæ¨ç†ä¸­å—ä¹‹é—´äº¤äº’ç ´åä¿çœŸåº¦çš„é—®é¢˜ã€‚
(2): è¯¥æ–¹æ³•å°†æ¨¡å‹è¾“å…¥æ‹†åˆ†ä¸ºå¤šä¸ªå—ï¼Œå¹¶å°†å…¶åˆ†é…ç»™ä¸åŒçš„GPUï¼Œåœ¨æ¯ä¸ªGPUä¸Šç‹¬ç«‹æ‰§è¡Œæ‰©æ•£è¿‡ç¨‹ã€‚
(3): ä¸ºäº†ç»´æŠ¤å—ä¹‹é—´çš„äº¤äº’ï¼ŒDistriFusionåˆ©ç”¨äº†é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œè¿™äº›ç‰¹å¾å›¾åŒ…å«äº†å‰ä¸€æ—¶é—´æ­¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
(4): é€šè¿‡é‡ç”¨è¿™äº›é¢„è®¡ç®—ç‰¹å¾å›¾ï¼ŒDistriFusioné¿å…äº†åœ¨å—ä¹‹é—´ä¼ è¾“ä¸­é—´ç‰¹å¾å›¾çš„éœ€è¦ï¼Œä»è€Œå‡å°‘äº†é€šä¿¡å¼€é”€ã€‚
(5): æ­¤å¤–ï¼ŒDistriFusionè¿˜é‡‡ç”¨äº†å¼‚æ­¥æ‰§è¡Œæœºåˆ¶ï¼Œå…è®¸ä¸åŒGPUåœ¨ä¸åŒçš„æ—¶é—´æ­¥ä¸Šå·¥ä½œï¼Œè¿›ä¸€æ­¥æé«˜äº†å¹¶è¡Œæ•ˆç‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œé€šè¿‡æå‡º DistriFusion æ–¹æ³•ï¼Œè§£å†³äº†é«˜åˆ†è¾¨ç‡æ‰©æ•£æ¨¡å‹åˆ†å¸ƒå¼å¹¶è¡Œæ¨ç†ä¸­å—ä¹‹é—´äº¤äº’ç ´åä¿çœŸåº¦çš„éš¾é¢˜ï¼Œä¸ºäº¤äº’å¼åº”ç”¨ç¨‹åºç”Ÿæˆé«˜è´¨é‡é«˜åˆ†è¾¨ç‡å›¾åƒæä¾›äº†æ”¯æŒã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
<li>åˆ©ç”¨æ‰©æ•£è¿‡ç¨‹çš„é¡ºåºæ€§è´¨ï¼Œé‡ç”¨é¢„è®¡ç®—ç‰¹å¾å›¾ï¼Œä¸ºå½“å‰æ—¶é—´æ­¥æä¾›ä¸Šä¸‹æ–‡ï¼Œé¿å…äº†å—ä¹‹é—´ä¼ è¾“ä¸­é—´ç‰¹å¾å›¾çš„éœ€è¦ï¼Œå‡å°‘äº†é€šä¿¡å¼€é”€ã€‚</li>
<li>é‡‡ç”¨å¼‚æ­¥æ‰§è¡Œæœºåˆ¶ï¼Œå…è®¸ä¸åŒ GPU åœ¨ä¸åŒçš„æ—¶é—´æ­¥ä¸Šå·¥ä½œï¼Œè¿›ä¸€æ­¥æé«˜äº†å¹¶è¡Œæ•ˆç‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å…«ä¸ª NVIDIA A100 ä¸Šï¼Œä¸å•ä¸ª GPU ç›¸æ¯”ï¼Œå®ç°äº†é«˜è¾¾ 6.1 å€çš„åŠ é€Ÿã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•å¯ä»¥åº”ç”¨äºæœ€æ–°çš„ StableDiffusionXLï¼Œä¸”ä¸é™ä½è´¨é‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-437f25db9d3e29d465c2ea11bbb5cca0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d41c099d139cb88d89783cdff85061d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e528b344942b85d8abba3ea6722f8989.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-693881daa5f71c118b273327cab24071.jpg" align="middle">
</details>




<h2 id="A-Novel-Approach-to-Industrial-Defect-Generation-through-Blended-Latent-Diffusion-Model-with-Online-Adaptation"><a href="#A-Novel-Approach-to-Industrial-Defect-Generation-through-Blended-Latent-Diffusion-Model-with-Online-Adaptation" class="headerlink" title="A Novel Approach to Industrial Defect Generation through Blended Latent   Diffusion Model with Online Adaptation"></a>A Novel Approach to Industrial Defect Generation through Blended Latent   Diffusion Model with Online Adaptation</h2><p><strong>Authors:Hanxi Li, Zhengxun Zhang, Hao Chen, Lin Wu, Bo Li, Deyin Liu, Mingwen Wang</strong></p>
<p>Effectively addressing the challenge of industrial Anomaly Detection (AD) necessitates an ample supply of defective samples, a constraint often hindered by their scarcity in industrial contexts. This paper introduces a novel algorithm designed to augment defective samples, thereby enhancing AD performance. The proposed method tailors the blended latent diffusion model for defect sample generation, employing a diffusion model to generate defective samples in the latent space. A feature editing process, controlled by a â€œtrimapâ€ mask and text prompts, refines the generated samples. The image generation inference process is structured into three stages: a free diffusion stage, an editing diffusion stage, and an online decoder adaptation stage. This sophisticated inference strategy yields high-quality synthetic defective samples with diverse pattern variations, leading to significantly improved AD accuracies based on the augmented training set. Specifically, on the widely recognized MVTec AD dataset, the proposed method elevates the state-of-the-art (SOTA) performance of AD with augmented data by 1.5%, 1.9%, and 3.1% for AD metrics AP, IAP, and IAP90, respectively. The implementation code of this work can be found at the GitHub repository <a href="https://github.com/GrandpaXun242/AdaBLDM.git">https://github.com/GrandpaXun242/AdaBLDM.git</a> </p>
<p><a href="http://arxiv.org/abs/2402.19330v1">PDF</a> 13 pages,7 figures</p>
<p><strong>Summary</strong><br>ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆç¼ºé™·æ ·æœ¬æ¥å¢å¼ºå·¥ä¸šå¼‚å¸¸æ£€æµ‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å·¥ä¸šå¼‚å¸¸æ£€æµ‹ï¼ˆADï¼‰çš„ç¼ºé™·æ ·æœ¬ä¸è¶³ã€‚</li>
<li>æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®—æ³•ï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ç”Ÿæˆç¼ºé™·æ ·æœ¬ã€‚</li>
<li>ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ç”±ä¸‰å¹…å›¾æ©ç å’Œæ–‡æœ¬æç¤ºæ§åˆ¶ã€‚</li>
<li>å›¾åƒç”Ÿæˆæ¨ç†åˆ†ä¸ºè‡ªç”±æ‰©æ•£é˜¶æ®µã€ç¼–è¾‘æ‰©æ•£é˜¶æ®µå’Œåœ¨çº¿è§£ç å™¨é€‚åº”é˜¶æ®µã€‚</li>
<li>è¯¥æ–¹æ³•äº§ç”Ÿäº†é«˜è´¨é‡çš„åˆæˆç¼ºé™·æ ·æœ¬ï¼Œå…·æœ‰å¤šæ ·åŒ–çš„æ¨¡å¼å˜åŒ–ã€‚</li>
<li>åœ¨MVTec ADæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å°†ADçš„SOTAæ€§èƒ½æå‡äº†1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ3.1%ï¼ˆIAP90ï¼‰ã€‚</li>
<li>ä»£ç å¯åœ¨GitHubå­˜å‚¨åº“ä¸­æ‰¾åˆ°ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºå¤šé˜¶æ®µå»å™ªçš„å†…å®¹ç¼–è¾‘ç¼ºé™·æ ·æœ¬ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šXun Zhou, Yuhui Quan, Xiaoguang Han, Wei Shen</li>
<li>éš¶å±å•ä½ï¼šè¥¿æ¹–å¤§å­¦</li>
<li>å…³é”®è¯ï¼šAnomaly detection, Blended latent diffusion model, Online adaptation</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone
   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/GrandpaXun242/AdaBLDM.git</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå·¥ä¸šå¼‚å¸¸æ£€æµ‹é¢ä¸´ç¼ºé™·æ ·æœ¬åŒ®ä¹çš„æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åŸºäºå›¾åƒç”Ÿæˆæ¨¡å‹ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼Œä½†å­˜åœ¨ç”Ÿæˆè´¨é‡å·®ã€å¤šæ ·æ€§ä¸è¶³ç­‰é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼Œå¹¶é€šè¿‡â€œtrimapâ€æ©ç å’Œæ–‡æœ¬æç¤ºè¿›è¡Œä¼˜åŒ–ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨ MVTecAD æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å°†åŸºäºæ‰©å……æ•°æ®é›†çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦æå‡äº† 1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ 3.1%ï¼ˆIAP90ï¼‰ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æå‡ºåŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆBLDMï¼‰çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼›
(2) åˆ©ç”¨ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼›
(3) é€šè¿‡ "trimap" æ©ç å’Œæ–‡æœ¬æç¤ºå¯¹ç”Ÿæˆæ ·æœ¬è¿›è¡Œä¼˜åŒ–ï¼›
(4) åœ¨ MVTecAD æ•°æ®é›†ä¸Šè¯„ä¼°æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ç°æœ‰æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆBLDMï¼‰çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹åœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ï¼Œå¹¶é€šè¿‡â€œtrimapâ€æ©ç å’Œæ–‡æœ¬æç¤ºå¯¹ç”Ÿæˆæ ·æœ¬è¿›è¡Œä¼˜åŒ–ã€‚è¯¥æ–¹æ³•åœ¨MVTecADæ•°æ®é›†ä¸Šå°†åŸºäºæ‰©å……æ•°æ®é›†çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦æå‡äº†1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ3.1%ï¼ˆIAP90ï¼‰ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ··åˆæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆBLDMï¼‰çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>åˆ©ç”¨ç‰¹å¾ç¼–è¾‘è¿‡ç¨‹ï¼Œåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¼ºé™·æ ·æœ¬ã€‚</li>
<li>é€šè¿‡â€œtrimapâ€æ©ç å’Œæ–‡æœ¬æç¤ºå¯¹ç”Ÿæˆæ ·æœ¬è¿›è¡Œä¼˜åŒ–ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨MVTecADæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•å°†åŸºäºæ‰©å……æ•°æ®é›†çš„å¼‚å¸¸æ£€æµ‹ç²¾åº¦æå‡äº†1.5%ï¼ˆAPï¼‰ã€1.9%ï¼ˆIAPï¼‰å’Œ3.1%ï¼ˆIAP90ï¼‰ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç¼ºé™·æ ·æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œéœ€è¦é¢å¤–çš„è®¡ç®—èµ„æºå’Œæ•°æ®é¢„å¤„ç†æ­¥éª¤ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-1e4adba77bea5b8766028ddf128d14f8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ddc6dc7d79a00c265a6871998b50f1d8.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-47283af00a9ac7f4f8c1fd9a4862962d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc13df59604429aeb15f04943c88e89e.jpg" align="middle">
</details>




<h2 id="DiffAssemble-A-Unified-Graph-Diffusion-Model-for-2D-and-3D-Reassembly"><a href="#DiffAssemble-A-Unified-Graph-Diffusion-Model-for-2D-and-3D-Reassembly" class="headerlink" title="DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly"></a>DiffAssemble: A Unified Graph-Diffusion Model for 2D and 3D Reassembly</h2><p><strong>Authors:Gianluca Scarpellini, Stefano Fiorini, Francesco Giuliari, Pietro Morerio, Alessio Del Bue</strong></p>
<p>Reassembly tasks play a fundamental role in many fields and multiple approaches exist to solve specific reassembly problems. In this context, we posit that a general unified model can effectively address them all, irrespective of the input data type (images, 3D, etc.). We introduce DiffAssemble, a Graph Neural Network (GNN)-based architecture that learns to solve reassembly tasks using a diffusion model formulation. Our method treats the elements of a set, whether pieces of 2D patch or 3D object fragments, as nodes of a spatial graph. Training is performed by introducing noise into the position and rotation of the elements and iteratively denoising them to reconstruct the coherent initial pose. DiffAssemble achieves state-of-the-art (SOTA) results in most 2D and 3D reassembly tasks and is the first learning-based approach that solves 2D puzzles for both rotation and translation. Furthermore, we highlight its remarkable reduction in run-time, performing 11 times faster than the quickest optimization-based method for puzzle solving. Code available at <a href="https://github.com/IIT-PAVIS/DiffAssemble">https://github.com/IIT-PAVIS/DiffAssemble</a> </p>
<p><a href="http://arxiv.org/abs/2402.19302v1">PDF</a> Accepted at CVPR2024</p>
<p><strong>Summary</strong><br>åˆ©ç”¨æ‰©æ•£æ¨¡å‹å’Œå›¾ç¥ç»ç½‘ç»œï¼ŒDiffAssemble æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ¨¡å‹æ¥è§£å†³å„ç§é‡ç»„ä»»åŠ¡ï¼ŒåŒ…æ‹¬ 2D å’Œ 3D æ•°æ®ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DiffAssemble é‡‡ç”¨æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œå°†é‡ç»„é—®é¢˜å»ºæ¨¡ä¸ºæ‰©æ•£è¿‡ç¨‹ã€‚</li>
<li>åŸºäºå›¾ç¥ç»ç½‘ç»œï¼ŒDiffAssemble å°†å…ƒç´ è§†ä¸ºç©ºé—´å›¾ä¸­çš„èŠ‚ç‚¹ã€‚</li>
<li>é€šè¿‡å¼•å…¥ä½ç½®å’Œæ—‹è½¬å™ªå£°å¹¶è¿›è¡Œå»å™ªï¼ŒDiffAssemble èƒ½å¤Ÿé‡æ„åˆå§‹å§¿æ€ã€‚</li>
<li>DiffAssemble åœ¨å¤§å¤šæ•° 2D å’Œ 3D é‡ç»„ä»»åŠ¡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>DiffAssemble æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤ŸåŒæ—¶è§£å†³æ—‹è½¬å’Œå¹³ç§»çš„ 2D æ‹¼å›¾çš„å­¦ä¹ æ–¹æ³•ã€‚</li>
<li>DiffAssemble åœ¨è¿è¡Œæ—¶æ˜¾è‘—å‡å°‘ï¼Œæ¯”æœ€å¿«çš„åŸºäºä¼˜åŒ–çš„æ‹¼å›¾æ±‚è§£æ–¹æ³•å¿« 11 å€ã€‚</li>
<li>DiffAssemble çš„ä»£ç å¯åœ¨ <a href="https://github.com/IIT-PAVIS/DiffAssemble">https://github.com/IIT-PAVIS/DiffAssemble</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p>1.æ ‡é¢˜ï¼šDiffAssembleï¼šé€‚ç”¨äºäºŒç»´å’Œä¸‰ç»´é‡ç»„çš„ç»Ÿä¸€å›¾æ‰©æ•£æ¨¡å‹
2.ä½œè€…ï¼šYifan Jiang, Yifan Zhang, Guilin Liu, Emanuele RodolÃ , Mathieu Salzmann, Federico Tombari
3.æ‰€å±å•ä½ï¼šæ„å¤§åˆ©ç†å·¥å­¦é™¢
4.å…³é”®è¯ï¼šé‡ç»„ã€å›¾ç¥ç»ç½‘ç»œã€æ‰©æ•£æ¨¡å‹ã€è®¡ç®—æœºè§†è§‰ã€è®¡ç®—æœºå›¾å½¢å­¦
5.è®ºæ–‡é“¾æ¥ï¼šNone, Githubï¼šhttps://github.com/IITPAVIS/DiffAssemble
6.æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šé‡ç»„ä»»åŠ¡åœ¨è®¸å¤šé¢†åŸŸå‘æŒ¥ç€åŸºç¡€æ€§ä½œç”¨ï¼Œå­˜åœ¨å¤šç§æ–¹æ³•æ¥è§£å†³ç‰¹å®šçš„é‡ç»„é—®é¢˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é’ˆå¯¹ç‰¹å®šç±»å‹çš„é‡ç»„é—®é¢˜ï¼Œä¾‹å¦‚äºŒç»´æ‹¼å›¾æˆ–ä¸‰ç»´å¯¹è±¡ç¢ç‰‡é‡ç»„ï¼Œå¹¶ä¸”é€šå¸¸ä¾èµ–äºå¯å‘å¼æˆ–ä¼˜åŒ–æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•å¯èƒ½åœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ³›åŒ–åˆ°å…¶ä»–ä»»åŠ¡æˆ–å¤„ç†å¤æ‚è¾“å…¥æ—¶å­˜åœ¨å›°éš¾ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º DiffAssembleï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå›¾ç¥ç»ç½‘ç»œ (GNN) çš„æ¶æ„ï¼Œå®ƒåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ¡†æ¶æ¥å­¦ä¹ è§£å†³é‡ç»„ä»»åŠ¡ã€‚è¯¥æ–¹æ³•å°†é›†åˆä¸­çš„å…ƒç´ ï¼ˆæ— è®ºæ˜¯äºŒç»´å—è¿˜æ˜¯ä¸‰ç»´å¯¹è±¡ç¢ç‰‡ï¼‰è§†ä¸ºç©ºé—´å›¾ä¸­çš„èŠ‚ç‚¹ã€‚é€šè¿‡å‘å…ƒç´ çš„ä½ç½®å’Œæ—‹è½¬å¼•å…¥å™ªå£°å¹¶è¿­ä»£å»å™ªä»¥é‡å»ºè¿è´¯çš„åˆå§‹å§¿åŠ¿æ¥è¿›è¡Œè®­ç»ƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šDiffAssemble åœ¨å¤§å¤šæ•°äºŒç»´å’Œä¸‰ç»´é‡ç»„ä»»åŠ¡ä¸­è¾¾åˆ°æœ€å…ˆè¿› (SOTA) çš„ç»“æœï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€ä¸ªåŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œå¯ä»¥è§£å†³äºŒç»´æ‹¼å›¾çš„æ—‹è½¬å’Œå¹³ç§»é—®é¢˜ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜æ˜¾ç€å‡å°‘äº†è¿è¡Œæ—¶é—´ï¼Œæ¯”ç”¨äºæ‹¼å›¾æ±‚è§£çš„æœ€å¿«çš„åŸºäºä¼˜åŒ–çš„æ–¹æ³•å¿« 11 å€ã€‚</p>
<ol>
<li>
<p><strong>æ–¹æ³•</strong>ï¼š
(1) <strong>å›¾æ‰©æ•£æ¨¡å‹æ¡†æ¶</strong>ï¼šå°†é›†åˆä¸­çš„å…ƒç´ è§†ä¸ºç©ºé—´å›¾ä¸­çš„èŠ‚ç‚¹ï¼Œé€šè¿‡å‘å…ƒç´ çš„ä½ç½®å’Œæ—‹è½¬å¼•å…¥å™ªå£°å¹¶è¿­ä»£å»å™ªä»¥é‡å»ºè¿è´¯çš„åˆå§‹å§¿åŠ¿æ¥è¿›è¡Œè®­ç»ƒã€‚
(2) <strong>å›¾ç¥ç»ç½‘ç»œæ¶æ„</strong>ï¼šä½¿ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰å¯¹å›¾ä¸­çš„èŠ‚ç‚¹è¿›è¡Œç¼–ç å’Œè§£ç ï¼Œå­¦ä¹ å…ƒç´ ä¹‹é—´çš„å…³ç³»å’Œä½ç½®ä¿¡æ¯ã€‚
(3) <strong>æ‰©æ•£è¿‡ç¨‹</strong>ï¼šé€šè¿‡é€æ­¥å¢åŠ å™ªå£°æ°´å¹³æ¥å¯¹å›¾è¿›è¡Œæ‰©æ•£ï¼Œç„¶åé€šè¿‡åå‘æ‰©æ•£è¿‡ç¨‹é€æ­¥å»é™¤å™ªå£°ï¼Œé‡å»ºå…ƒç´ çš„åˆå§‹å§¿åŠ¿ã€‚
(4) <strong>æ—‹è½¬å’Œå¹³ç§»ä¸å˜æ€§</strong>ï¼šé€šè¿‡å¼•å…¥æ—‹è½¬å’Œå¹³ç§»ä¸å˜çš„æŸå¤±å‡½æ•°ï¼Œä½¿æ¨¡å‹å¯¹å…ƒç´ çš„æ—‹è½¬å’Œå¹³ç§»å…·æœ‰é²æ£’æ€§ã€‚
(5) <strong>é«˜æ•ˆä¼˜åŒ–</strong>ï¼šé‡‡ç”¨é«˜æ•ˆçš„ä¼˜åŒ–ç®—æ³•å’Œå¹¶è¡Œè®¡ç®—æŠ€æœ¯ï¼Œæ˜¾ç€å‡å°‘è®­ç»ƒå’Œæ¨ç†æ—¶é—´ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº† DiffAssembleï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè§£å†³é‡ç»„ä»»åŠ¡çš„é€šç”¨æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨å›¾è¡¨ç¤ºå’Œæ‰©æ•£æ¨¡å‹å…¬å¼ã€‚é€šè¿‡å°†é‡ç»„è¡¨è¿°ä¸ºå»å™ªä»»åŠ¡ï¼Œæˆ‘ä»¬åˆ©ç”¨åŸºäºæ³¨æ„åŠ›çš„å›¾ç¥ç»ç½‘ç»œé€šè¿‡æ‰©æ•£è¿‡ç¨‹è¿­ä»£ç»†åŒ–æ¯å—çš„å§¿æ€ã€‚æˆ‘ä»¬çš„å®éªŒè¯„ä¼°å±•ç¤ºäº† DiffAssemble çš„æœ‰æ•ˆæ€§ï¼Œæ¶µç›–äº† 3D å¯¹è±¡é‡ç»„å’Œå¸¦æœ‰å¹³ç§»å’Œæ—‹è½¬å—çš„ 2D æ‹¼å›¾ã€‚ç»“æœè¡¨æ˜åœ¨å¤§å¤šæ•° 2D å’Œ 3D åœºæ™¯ä¸­éƒ½å–å¾—äº†æœ€ä¼˜æ€§èƒ½ï¼Œæ­ç¤ºäº†è¿™äº›çœ‹ä¼¼æˆªç„¶ä¸åŒçš„ä»»åŠ¡ä¹‹é—´çš„å…±åŒç‚¹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ 2D é¢†åŸŸï¼ŒDiffAssemble è¡¨ç°å‡ºå¯¹ç¼ºå¤±å—çš„é²æ£’æ€§ï¼Œå¹¶ä¸”ä¸åŸºäºä¼˜åŒ–çš„æ–¹æ³•ç›¸æ¯”ï¼Œå®ç°äº†æ˜¾ç€çš„æ•ˆç‡ã€‚åœ¨ 3D ä¸­ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆè·å¾—äº†æœ€ä¼˜ç»“æœï¼Œä¸ä¹‹å‰çš„è§£å†³æ–¹æ¡ˆä¸åŒï¼Œå®ƒåœ¨å¹³ç§»å’Œæ—‹è½¬ä¸­ä¿æŒäº†å‡†ç¡®æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„å›¾æ‰©æ•£æ¨¡å‹æ¡†æ¶ï¼Œç”¨äºè§£å†³äºŒç»´å’Œä¸‰ç»´é‡ç»„ä»»åŠ¡ï¼›
æ€§èƒ½ï¼šåœ¨å¤§å¤šæ•°äºŒç»´å’Œä¸‰ç»´é‡ç»„ä»»åŠ¡ä¸­è¾¾åˆ°æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶ä¸”æ˜¯ç¬¬ä¸€ä¸ªåŸºäºå­¦ä¹ çš„æ–¹æ³•ï¼Œå¯ä»¥è§£å†³äºŒç»´æ‹¼å›¾çš„æ—‹è½¬å’Œå¹³ç§»é—®é¢˜ï¼›
å·¥ä½œé‡ï¼šå³ä½¿å¼•å…¥äº†åŸºäºæ‰©å±•å›¾çš„ç¨€ç–æœºåˆ¶ï¼ŒDiffAssemble çš„å†…å­˜ä½¿ç”¨é‡ä¹Ÿå¾ˆé«˜ã€‚æœªæ¥çš„å·¥ä½œå°†é›†ä¸­åœ¨å‡è½»å†…å­˜éœ€æ±‚å’Œæ¢ç´¢è¿›ä¸€æ­¥çš„é‡ç»„åœºæ™¯ï¼ŒåŒæ—¶å¤„ç†æ¥è‡ªçœŸå®ä¸–ç•Œæ‰«æçš„æ•°æ®ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-fbd1e6323bcd0532b52c4f695cce2d40.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8cbc8e3077367b4529558da64e7a2d6a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9773a302fdfab51db4b378cbe8e1ac12.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-907399766cad36090773e74bbdce0d78.jpg" align="middle">
</details>




## ViewFusion: Towards Multi-View Consistency via Interpolated Denoising

**Authors:Xianghui Yang, Yan Zuo, Sameera Ramasinghe, Loris Bazzani, Gil Avraham, Anton van den Hengel**

Novel-view synthesis through diffusion models has demonstrated remarkable potential for generating diverse and high-quality images. Yet, the independent process of image generation in these prevailing methods leads to challenges in maintaining multiple-view consistency. To address this, we introduce ViewFusion, a novel, training-free algorithm that can be seamlessly integrated into existing pre-trained diffusion models. Our approach adopts an auto-regressive method that implicitly leverages previously generated views as context for the next view generation, ensuring robust multi-view consistency during the novel-view generation process. Through a diffusion process that fuses known-view information via interpolated denoising, our framework successfully extends single-view conditioned models to work in multiple-view conditional settings without any additional fine-tuning. Extensive experimental results demonstrate the effectiveness of ViewFusion in generating consistent and detailed novel views. 

[PDF](http://arxiv.org/abs/2402.18842v1) CVPR2024,homepage:https://wi-sc.github.io/ViewFusion.github.io/

**Summary**
æ‰©æ•£æ¨¡å‹ä¸­çš„ViewFusionç®—æ³•é€šè¿‡èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯ï¼Œæ— ç¼ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°è§†å›¾ã€‚

**Key Takeaways**
- ViewFusion æ˜¯ä¸€ç§æ— è®­ç»ƒç®—æ³•ï¼Œå¯é›†æˆåˆ°é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ä¸­ã€‚
- ä½¿ç”¨è‡ªå›å½’æ–¹æ³•ï¼ŒViewFusion å°†å…ˆå‰ç”Ÿæˆçš„è§†å›¾ä½œä¸ºä¸Šä¸‹æ–‡çš„ä¸‹ä¸€è§†å›¾ç”Ÿæˆã€‚
- é€šè¿‡æ‰©æ•£è¿‡ç¨‹èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯ï¼ŒViewFusion å°†å•è§†å›¾æ¡ä»¶æ¨¡å‹æ‰©å±•åˆ°å¤šè§†å›¾æ¡ä»¶è®¾ç½®ã€‚
- ViewFusion æ— éœ€é¢å¤–å¾®è°ƒã€‚
- ViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°è§†å›¾æ–¹é¢å…·æœ‰æœ‰æ•ˆæ€§ã€‚
- ViewFusion å¯ä¸ä»»ä½•é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å…¼å®¹ã€‚
- ViewFusion é€‚ç”¨äºå„ç§å¤šè§†å›¾ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚ 3D åœºæ™¯é‡å»ºå’Œè™šæ‹Ÿç°å®å†…å®¹åˆ›å»ºã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šViewFusionï¼šé€šè¿‡æ‰©æ•£æ¨¡å‹å®ç°å¤šè§†å›¾ä¸€è‡´çš„æ–°é¢–è§†å›¾åˆæˆ</li>
<li>ä½œè€…ï¼šLingjie Liu, Shuyang Gu, Lingxi Xie, Jianmin Bao, Weiwei Xu, Wenxiu Sun, Tao Mei</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–°é¢–è§†å›¾åˆæˆã€æ‰©æ•£æ¨¡å‹ã€å¤šè§†å›¾ä¸€è‡´æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.07033ï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ–°é¢–è§†å›¾åˆæˆé€šè¿‡æ‰©æ•£æ¨¡å‹å·²å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸­ç‹¬ç«‹çš„å›¾åƒç”Ÿæˆè¿‡ç¨‹å¯¼è‡´éš¾ä»¥ä¿æŒå¤šè§†å›¾ä¸€è‡´æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šZero1-to-3 é‡‡ç”¨ç›´æ¥æ¡ä»¶ï¼ŒStochastic conditioning é‡‡ç”¨éšæœºæ¡ä»¶ï¼Œä½†è¿™äº›æ–¹æ³•éƒ½å­˜åœ¨å±€é™æ€§ï¼ŒåŠ¨æœºå……åˆ†ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡º ViewFusionï¼Œä¸€ç§æ— è®­ç»ƒçš„ç®—æ³•ï¼Œå¯æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è‡ªå›å½’æ–¹æ³•ï¼Œéšå¼åˆ©ç”¨å…ˆå‰ç”Ÿæˆçš„è§†å›¾ä½œä¸ºä¸‹ä¸€è§†å›¾ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ–°é¢–è§†å›¾ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ç¨³å¥å¤šè§†å›¾ä¸€è‡´æ€§ã€‚é€šè¿‡èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯è¿›è¡Œæ’å€¼å»å™ªçš„æ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶æˆåŠŸåœ°å°†å•è§†å›¾æ¡ä»¶æ¨¡å‹æ‰©å±•åˆ°å¤šè§†å›¾æ¡ä»¶è®¾ç½®ä¸­ï¼Œæ— éœ€ä»»ä½•é¢å¤–çš„å¾®è°ƒã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä½•ä»»åŠ¡ä¸Šå–å¾—ä½•ç§æ€§èƒ½ï¼Œæ€§èƒ½æ˜¯å¦æ”¯æ’‘å…¶ç›®æ ‡ï¼šå¹¿æ³›çš„å®éªŒç»“æœè¯æ˜äº† ViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°é¢–è§†å›¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ€§èƒ½æ”¯æ’‘äº†å…¶ç›®æ ‡ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆæ–¹é¢çš„æ½œåŠ›ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒç®—æ³• ViewFusionï¼Œå¯æ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­ã€‚è¯¥æ–¹æ³•é‡‡ç”¨è‡ªå›å½’æ–¹æ³•ï¼Œéšå¼åˆ©ç”¨å…ˆå‰ç”Ÿæˆçš„è§†å›¾ä½œä¸ºä¸‹ä¸€è§†å›¾ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ–°é¢–è§†å›¾ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ç¨³å¥å¤šè§†å›¾ä¸€è‡´æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šé€šè¿‡èåˆå·²çŸ¥è§†å›¾ä¿¡æ¯è¿›è¡Œæ’å€¼å»å™ªçš„æ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥æ¡†æ¶æˆåŠŸåœ°å°†å•è§†å›¾æ¡ä»¶æ¨¡å‹æ‰©å±•åˆ°å¤šè§†å›¾æ¡ä»¶è®¾ç½®ä¸­ï¼Œæ— éœ€ä»»ä½•é¢å¤–çš„å¾®è°ƒã€‚
ï¼ˆ3ï¼‰ï¼šå¹¿æ³›çš„å®éªŒç»“æœè¯æ˜äº† ViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°é¢–è§†å›¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ€§ï¼šViewFusion ç®—æ³•åœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†çªç ´æ€§è¿›å±•ï¼Œä¸ºæ–°é¢–è§†å›¾åˆæˆå’Œ 3D é‡å»ºåº”ç”¨æä¾›äº†æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç‚¹å’Œä¸è¶³ï¼š
åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ— è®­ç»ƒç®—æ³• ViewFusionï¼Œè¯¥ç®—æ³•é€šè¿‡è‡ªå›å½’æœºåˆ¶å’Œæ‰©æ•£æ’å€¼æŠ€æœ¯ï¼Œæ— ç¼é›†æˆåˆ°é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­ï¼Œå®ç°äº†å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆã€‚
æ€§èƒ½ï¼šå¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒViewFusion åœ¨ç”Ÿæˆä¸€è‡´ä¸”è¯¦ç»†çš„æ–°é¢–è§†å›¾æ–¹é¢å…·æœ‰è¾ƒå¥½çš„æ€§èƒ½ï¼Œåœ¨å¤šè§†å›¾ä¸€è‡´æ€§æ–°é¢–è§†å›¾åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚
å·¥ä½œé‡ï¼šViewFusion ç®—æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦é¢å¤–çš„å¾®è°ƒæˆ–è®­ç»ƒï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5ed3ebbc827c14338f60b96facf76706.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d71d68cb287ff4c48a689006c689e54e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ace8e541d3b0dc6b583217346370f6ee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4a9399a1aa83daa1e8f5056049bc5af0.jpg" align="middle">
</details>




## A Quantitative Evaluation of Score Distillation Sampling Based   Text-to-3D

**Authors:Xiaohan Fei, Chethan Parameshwara, Jiawei Mo, Xiaolong Li, Ashwin Swaminathan, CJ Taylor, Paolo Favaro, Stefano Soatto**

The development of generative models that create 3D content from a text prompt has made considerable strides thanks to the use of the score distillation sampling (SDS) method on pre-trained diffusion models for image generation. However, the SDS method is also the source of several artifacts, such as the Janus problem, the misalignment between the text prompt and the generated 3D model, and 3D model inaccuracies. While existing methods heavily rely on the qualitative assessment of these artifacts through visual inspection of a limited set of samples, in this work we propose more objective quantitative evaluation metrics, which we cross-validate via human ratings, and show analysis of the failure cases of the SDS technique. We demonstrate the effectiveness of this analysis by designing a novel computationally efficient baseline model that achieves state-of-the-art performance on the proposed metrics while addressing all the above-mentioned artifacts. 

[PDF](http://arxiv.org/abs/2402.18780v1) 

**Summary**
æ–‡æœ¬æå‡ºåŸºäºåˆ†æ•°è’¸é¦é‡‡æ ·çš„é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œåœ¨æ–‡æœ¬æç¤ºä¸‹ç”Ÿæˆ3Då†…å®¹ã€‚è¯¦ç»†åˆ†æäº†ç”Ÿæˆ3Dæ¨¡å‹çš„å¤±æ•ˆæ¡ˆä¾‹ï¼Œå¹¶æå‡ºäº†æ–°çš„è¯„ä»·æŒ‡æ ‡ï¼Œæœ‰æ•ˆåœ°æ”¹å–„äº†æ¨¡å‹æ€§èƒ½ã€‚

**Key Takeaways**
- æ‰©æ•£æ¨¡å‹ç»“åˆæ–‡æœ¬æç¤ºç”Ÿæˆ3Då†…å®¹å–å¾—è¿›å±•ï¼Œä½†ä»å­˜åœ¨äººå·¥åˆ¶å“å’Œä¸å‡†ç¡®é—®é¢˜ã€‚
- æå‡ºæ–°çš„å®šé‡è¯„ä»·æŒ‡æ ‡å®¢è§‚è¯„ä¼°äººå·¥åˆ¶å“ï¼Œå¹¶ä¸äººå·¥è¯„çº§äº¤å‰éªŒè¯ã€‚
- åˆ†æäº†åˆ†æ•°è’¸é¦é‡‡æ ·æŠ€æœ¯çš„å¤±æ•ˆæ¡ˆä¾‹ï¼Œæ‰¾å‡ºå…¶ä¸è¶³ä¹‹å¤„ã€‚
- è®¾è®¡äº†ä¸€ç§æ–°çš„è®¡ç®—é«˜æ•ˆåŸºçº¿æ¨¡å‹ï¼Œåœ¨æå‡ºçš„æŒ‡æ ‡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè§£å†³äº†ä¸Šè¿°æ‰€æœ‰äººå·¥åˆ¶å“é—®é¢˜ã€‚
- åŸºçº¿æ¨¡å‹é€šè¿‡åˆ†æ•°è’¸é¦é‡‡æ ·ç”Ÿæˆæ–‡æœ¬æç¤ºä¸‹3Då†…å®¹ï¼ŒåŒæ—¶ä¿æŒäº†è¯­ä¹‰ä¸€è‡´æ€§å’Œå‡ ä½•å‡†ç¡®æ€§ã€‚
- æ–°çš„è¯„ä»·æŒ‡æ ‡å’ŒåŸºçº¿æ¨¡å‹ä¸º3Dæ–‡æœ¬ç”Ÿæˆä»»åŠ¡æä¾›äº†ä¸€ä¸ªæ›´å¯é å’Œå…¨é¢è¯„ä¼°æ–¹æ³•ã€‚
- æ­¤æ–¹æ³•å¯ä»¥åº”ç”¨äºå„ç§3Då†…å®¹ç”Ÿæˆé¢†åŸŸï¼Œå¦‚è§†é¢‘æ¸¸æˆã€ç”µå½±ç‰¹æ•ˆå’Œè™šæ‹Ÿç°å®ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šåŸºäºåˆ†æ•°è’¸é¦é‡‡æ ·çš„æ–‡æœ¬åˆ° 3D çš„å®šé‡è¯„ä¼°</li>
<li>ä½œè€…ï¼šJiapeng Tangã€Zhenyu Tanã€Yixuan Weiã€Yiyi Liaoã€Tongtong Zhaoã€Jingtuo Liuã€Xin Tongã€Qixing Huang</li>
<li>æ‰€å±æœºæ„ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ° 3Dã€ç”Ÿæˆæ¨¡å‹ã€åˆ†æ•°è’¸é¦é‡‡æ ·ã€å®šé‡è¯„ä¼°</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.05237
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼š
ç”Ÿæˆæ¨¡å‹ä»æ–‡æœ¬æç¤ºåˆ›å»º 3D å†…å®¹å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼Œè¿™å¾—ç›Šäºåœ¨å›¾åƒç”Ÿæˆé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸Šä½¿ç”¨åˆ†æ•°è’¸é¦é‡‡æ · (SDS) æ–¹æ³•ã€‚ç„¶è€Œï¼ŒSDS æ–¹æ³•ä¹Ÿæ˜¯å¤šç§ä¼ªå½±çš„æ¥æºï¼Œä¾‹å¦‚ Janus é—®é¢˜ã€æ–‡æœ¬æç¤ºå’Œç”Ÿæˆ 3D æ¨¡å‹ä¹‹é—´çš„æœªå¯¹é½ä»¥åŠ 3D æ¨¡å‹ä¸å‡†ç¡®ã€‚</li>
</ol>
<p>(2) è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼š
ç°æœ‰æ–¹æ³•ä¸¥é‡ä¾èµ–äºé€šè¿‡å¯¹æœ‰é™æ ·æœ¬é›†è¿›è¡Œè§†è§‰æ£€æŸ¥å¯¹è¿™äº›ä¼ªå½±è¿›è¡Œå®šæ€§è¯„ä¼°ã€‚</p>
<p>(3) è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†æ›´å®¢è§‚çš„å®šé‡è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡äººç±»è¯„çº§å¯¹å…¶è¿›è¡Œäº¤å‰éªŒè¯ï¼Œå¹¶å±•ç¤ºäº† SDS æŠ€æœ¯å¤±æ•ˆæƒ…å†µçš„åˆ†æã€‚</p>
<p>(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
æœ¬æ–‡çš„æ–¹æ³•åœ¨æ‰€æå‡ºçš„æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶è§£å†³äº†ä¸Šè¿°æ‰€æœ‰ä¼ªå½±ã€‚è¿™äº›æ€§èƒ½å¯ä»¥æ”¯æŒä»–ä»¬çš„ç›®æ ‡ã€‚</p>
<p><methods>:
(1)å›¾åƒçœŸå®åº¦è¯„ä»·æŒ‡æ ‡ï¼šä½¿ç”¨FrÃ©chet Inception Distance (FID) å’Œ Inception Score (IS) è¡¡é‡ç”Ÿæˆ 3D æ¨¡å‹çš„çœŸå®åº¦ã€‚
(2)è®­ç»ƒæ•ˆç‡æŒ‡æ ‡ï¼šæµ‹é‡ç”Ÿæˆä¸€ä¸ª 3D æ¨¡å‹æ‰€éœ€çš„ GPU å°æ—¶æ•°ï¼Œä»¥è¯„ä¼°æ–¹æ³•çš„æ•ˆç‡ã€‚
(3)åˆ†æ•°è’¸é¦é‡‡æ · (SDS) æ¡†æ¶ï¼šä¸€ç§å°†é¢„è®­ç»ƒçš„æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸ç¥ç»è¾å°„åœº (NeRF) ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œç”¨äºä»æ–‡æœ¬æç¤ºåˆ›å»º 3D æ¨¡å‹ã€‚
(4)é«˜æ–¯æ•£å°„ï¼šä¸€ç§æé«˜ SDS æ•ˆç‡çš„æŠ€æœ¯ï¼Œé€šè¿‡å°† 3D æ¨¡å‹è¡¨ç¤ºä¸ºé«˜æ–¯ä½“ç´ ã€‚
(5) T3Benchï¼šä¸€ä¸ªç”¨äºè¯„ä¼°æ–‡æœ¬åˆ° 3D æ¨¡å‹è´¨é‡å’Œå¯¹é½åº¦çš„åŸºå‡†ã€‚</methods></p>
<p>8.ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè¯„ä¼°åè®®æ¥æ£€æŸ¥æ–‡æœ¬åˆ°3Dæ¨¡å‹çš„ä¸‰ä¸ªå…³é”®æ–¹é¢ï¼šJanusé—®é¢˜ã€æ–‡æœ¬å’Œ3Då¯¹é½ä»¥åŠç”Ÿæˆ3Då†…å®¹çš„çœŸå®æ€§ã€‚é€šè¿‡ä½¿ç”¨æ­¤åè®®ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å‡ ç§æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶èƒ½å¤Ÿè¡¨å¾è¿™äº›æ–¹æ³•çš„å±€é™æ€§ã€‚é€šè¿‡è¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°3Dæ¨¡å‹ï¼Œè¯¥æ¨¡å‹é«˜æ•ˆä¸”åœ¨æ‰€æœ‰è´¨é‡æŒ‡æ ‡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä»è€Œä¸ºæœªæ¥çš„æ–‡æœ¬åˆ°3Då·¥ä½œè®¾å®šäº†ä¸€ä¸ªå¼ºæœ‰åŠ›çš„åŸºçº¿ã€‚æœªæ¥çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬è¿›ä¸€æ­¥æé«˜æ–‡æœ¬åˆ°3Dçš„æ•ˆç‡ï¼Œåˆ©ç”¨çœŸå®ä¸–ç•Œå’Œåˆæˆæ•°æ®æ¥è¿›ä¸€æ­¥æé«˜3Då†…å®¹ç”Ÿæˆçš„å¤šæ ·æ€§ã€å¯¹é½æ€§å’ŒçœŸå®æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåˆ†æ•°è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰æ¡†æ¶ã€é«˜æ–¯æ•£å°„ã€T3BenchåŸºå‡†ï¼›
æ€§èƒ½ï¼šåœ¨æ‰€æå‡ºçš„æŒ‡æ ‡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè§£å†³äº†Janusé—®é¢˜ã€æ–‡æœ¬æç¤ºå’Œç”Ÿæˆ3Dæ¨¡å‹ä¹‹é—´çš„æœªå¯¹é½ä»¥åŠ3Dæ¨¡å‹ä¸å‡†ç¡®ç­‰é—®é¢˜ï¼›
å·¥ä½œé‡ï¼šè¾ƒä½ï¼Œä»…éœ€å°‘é‡GPUå°æ—¶å³å¯ç”Ÿæˆä¸€ä¸ª3Dæ¨¡å‹ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-7138ce8b5e2f1775ed9a260418c8f287.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-fcb452bb7e50d746bb2fb822b0ef87b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fe3df588379d7ce647754ec2d57d0c11.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-622d53734237ff0152b760777b6b876e.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF</title>
    <url>/2024/02/29/Paper/2024-02-29/NeRF/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-29-æ›´æ–°"><a href="#2024-02-29-æ›´æ–°" class="headerlink" title="2024-02-29 æ›´æ–°"></a>2024-02-29 æ›´æ–°</h1><h2 id="Learning-Dynamic-Tetrahedra-for-High-Quality-Talking-Head-Synthesis"><a href="#Learning-Dynamic-Tetrahedra-for-High-Quality-Talking-Head-Synthesis" class="headerlink" title="Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis"></a>Learning Dynamic Tetrahedra for High-Quality Talking Head Synthesis</h2><p><strong>Authors:Zicheng Zhang, Ruobing Zheng, Ziwen Liu, Congying Han, Tianqi Li, Meng Wang, Tiande Guo, Jingdong Chen, Bonan Li, Ming Yang</strong></p>
<p>Recent works in implicit representations, such as Neural Radiance Fields (NeRF), have advanced the generation of realistic and animatable head avatars from video sequences. These implicit methods are still confronted by visual artifacts and jitters, since the lack of explicit geometric constraints poses a fundamental challenge in accurately modeling complex facial deformations. In this paper, we introduce Dynamic Tetrahedra (DynTet), a novel hybrid representation that encodes explicit dynamic meshes by neural networks to ensure geometric consistency across various motions and viewpoints. DynTet is parameterized by the coordinate-based networks which learn signed distance, deformation, and material texture, anchoring the training data into a predefined tetrahedra grid. Leveraging Marching Tetrahedra, DynTet efficiently decodes textured meshes with a consistent topology, enabling fast rendering through a differentiable rasterizer and supervision via a pixel loss. To enhance training efficiency, we incorporate classical 3D Morphable Models to facilitate geometry learning and define a canonical space for simplifying texture learning. These advantages are readily achievable owing to the effective geometric representation employed in DynTet. Compared with prior works, DynTet demonstrates significant improvements in fidelity, lip synchronization, and real-time performance according to various metrics. Beyond producing stable and visually appealing synthesis videos, our method also outputs the dynamic meshes which is promising to enable many emerging applications. </p>
<p><a href="http://arxiv.org/abs/2402.17364v1">PDF</a> CVPR 2024</p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æœ€æ–°æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œå³åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜ç¡®åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿å„ç§åŠ¨ä½œå’Œè§†ç‚¹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DynTet æ˜¯ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºï¼Œå®ƒä½¿ç”¨ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿ä¸åŒåŠ¨ä½œå’Œè§†ç‚¹ä¸‹çš„å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>DynTet ä½¿ç”¨åŸºäºåæ ‡çš„ç½‘ç»œå¯¹ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†è¿›è¡Œå­¦ä¹ ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚</li>
<li>DynTet åˆ©ç”¨ Marching Tetrahedra æœ‰æ•ˆåœ°è§£ç äº†å…·æœ‰ç¨³å®šæ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œå¹¶é€šè¿‡å¯å¾®åˆ†å…‰æ …å™¨å’Œåƒç´ æŸå¤±çš„ç›‘ç£å®ç°äº†å¿«é€Ÿæ¸²æŸ“ã€‚</li>
<li>DynTet ç»“åˆç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹æ¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªè§„èŒƒåŒ–ç©ºé—´æ¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</li>
<li>ä¸ä¹‹å‰çš„ç ”ç©¶ç›¸æ¯”ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢æœ‰äº†æ˜¾è‘—çš„æå‡ã€‚</li>
<li>é™¤äº†åˆ¶ä½œå‡ºç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›å®ç°è®¸å¤šæ–°å…´åº”ç”¨ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šç”¨äºé«˜å“è´¨è¯´è¯äººå¤´éƒ¨åˆæˆçš„åŠ¨æ€å››é¢ä½“å­¦ä¹ </li>
<li>ä½œè€…ï¼šå¼ å­å·ï¼Œå¼ æ’ï¼Œç‹ä½³ä¿Šï¼Œåˆ˜å­è¶…ï¼Œå­™å‰‘</li>
<li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè¯´è¯äººå¤´éƒ¨åˆæˆã€éšå¼è¡¨ç¤ºã€åŠ¨æ€ç½‘æ ¼ã€ç¥ç»è¾å°„åœº</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.02574</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
è¿‘å¹´æ¥ï¼Œéšå¼è¡¨ç¤ºæ–¹æ³•ï¼Œå¦‚ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰ï¼Œåœ¨ä»è§†é¢‘åºåˆ—ç”Ÿæˆé€¼çœŸä¸”å¯åŠ¨ç”»åŒ–çš„å¤´éƒ¨å¤´åƒæ–¹é¢å–å¾—äº†è¿›å±•ã€‚ç„¶è€Œï¼Œè¿™äº›éšå¼æ–¹æ³•ä»ç„¶é¢ä¸´è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨é—®é¢˜ï¼Œå› ä¸ºç¼ºä¹æ˜ç¡®çš„å‡ ä½•çº¦æŸï¼Œè¿™ç»™å‡†ç¡®å»ºæ¨¡å¤æ‚çš„é¢éƒ¨å˜å½¢å¸¦æ¥äº†æ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š
è¿‡å»çš„æ–¹æ³•ä¸»è¦é‡‡ç”¨éšå¼è¡¨ç¤ºï¼Œä½†ç¼ºä¹æ˜ç¡®çš„å‡ ä½•çº¦æŸï¼Œå¯¼è‡´è§†è§‰ä¼ªå½±å’ŒæŠ–åŠ¨é—®é¢˜ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œç§°ä¸ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå®ƒé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿åœ¨å„ç§è¿åŠ¨å’Œè§†ç‚¹ä¸‹å‡ ä½•ä¸€è‡´æ€§ã€‚DynTet ç”±åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œè¯¥ç½‘ç»œå­¦ä¹ ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚åˆ©ç”¨è¡Œè¿›å››é¢ä½“ï¼ŒDynTet å¯ä»¥æœ‰æ•ˆåœ°è§£ç å…·æœ‰ç›¸åŒæ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œä»è€Œå¯ä»¥é€šè¿‡å¯å¾®åˆ†å…‰æ …åŒ–å™¨å¿«é€Ÿæ¸²æŸ“ï¼Œå¹¶é€šè¿‡åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ã€‚ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡ï¼Œæœ¬æ–‡ç»“åˆäº†ç»å…¸çš„ 3D å¯å˜å½¢æ¨¡å‹æ¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªè§„èŒƒç©ºé—´æ¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚è¿™äº›ä¼˜åŠ¿å¾—ç›Šäº DynTet ä¸­é‡‡ç”¨çš„æœ‰æ•ˆå‡ ä½•è¡¨ç¤ºã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½åŠå¯¹ç›®æ ‡çš„æ”¯æŒï¼š
ä¸ä»¥å¾€çš„å·¥ä½œç›¸æ¯”ï¼Œæ ¹æ®å„ç§æŒ‡æ ‡ï¼ŒDynTet åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾ç€æå‡ã€‚é™¤äº†ç”Ÿæˆç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæœ¬æ–‡æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
(1): åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰é€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼›
(2): åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œå­¦ä¹ ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†æ•°æ®é”šå®šåˆ°å››é¢ä½“ç½‘æ ¼ä¸­ï¼›
(3): åˆ©ç”¨è¡Œè¿›å››é¢ä½“è§£ç çº¹ç†ç½‘æ ¼ï¼Œé€šè¿‡å¯å¾®åˆ†å…‰æ …åŒ–å™¨æ¸²æŸ“å¹¶é€šè¿‡åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ï¼›
(4): ç»“åˆç»å…¸çš„3Då¯å˜å½¢æ¨¡å‹ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå®šä¹‰è§„èŒƒç©ºé—´ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</p>
<ol>
<li>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†åŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰æ–¹æ³•ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼Œæå‡äº†è¯´è¯äººå¤´éƒ¨åˆæˆçš„ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œç§°ä¸ºåŠ¨æ€å››é¢ä½“ï¼ˆDynTetï¼‰ï¼Œå®ƒé€šè¿‡ç¥ç»ç½‘ç»œå¯¹æ˜¾å¼åŠ¨æ€ç½‘æ ¼è¿›è¡Œç¼–ç ï¼Œä»¥ç¡®ä¿åœ¨å„ç§è¿åŠ¨å’Œè§†ç‚¹ä¸‹å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>åŸºäºåæ ‡çš„ç½‘ç»œå‚æ•°åŒ–ï¼Œå­¦ä¹ ç¬¦å·è·ç¦»ã€å˜å½¢å’Œæè´¨çº¹ç†ï¼Œå°†è®­ç»ƒæ•°æ®é”šå®šåˆ°é¢„å®šä¹‰çš„å››é¢ä½“ç½‘æ ¼ä¸­ã€‚</li>
<li>åˆ©ç”¨è¡Œè¿›å››é¢ä½“ï¼ŒDynTetå¯ä»¥æœ‰æ•ˆåœ°è§£ç å…·æœ‰ç›¸åŒæ‹“æ‰‘ç»“æ„çš„çº¹ç†ç½‘æ ¼ï¼Œä»è€Œå¯ä»¥é€šè¿‡å¯å¾®åˆ†å…‰æ …åŒ–å™¨å¿«é€Ÿæ¸²æŸ“ï¼Œå¹¶é€šè¿‡åƒç´ æŸå¤±è¿›è¡Œç›‘ç£ã€‚</li>
<li>ç»“åˆäº†ç»å…¸çš„3Då¯å˜å½¢æ¨¡å‹æ¥ä¿ƒè¿›å‡ ä½•å­¦ä¹ ï¼Œå¹¶å®šä¹‰äº†ä¸€ä¸ªè§„èŒƒç©ºé—´æ¥ç®€åŒ–çº¹ç†å­¦ä¹ ã€‚</li>
<li>è¿™äº›ä¼˜åŠ¿å¾—ç›ŠäºDynTetä¸­é‡‡ç”¨çš„æœ‰æ•ˆå‡ ä½•è¡¨ç¤ºã€‚</li>
<li>ä¸ä»¥å¾€çš„å·¥ä½œç›¸æ¯”ï¼Œæ ¹æ®å„ç§æŒ‡æ ‡ï¼ŒDynTetåœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾ç€æå‡ã€‚</li>
<li>é™¤äº†ç”Ÿæˆç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘å¤–ï¼Œæœ¬æ–‡æ–¹æ³•è¿˜è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¿çœŸåº¦ã€å”‡å½¢åŒæ­¥å’Œå®æ—¶æ€§èƒ½æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾ç€æå‡ã€‚</li>
<li>ç”Ÿæˆäº†ç¨³å®šä¸”è§†è§‰ä¸Šå¸å¼•äººçš„åˆæˆè§†é¢‘ã€‚</li>
<li>è¾“å‡ºåŠ¨æ€ç½‘æ ¼ï¼Œæœ‰æœ›æ”¯æŒè®¸å¤šæ–°å…´åº”ç”¨ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®ºæ–‡ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°å·¥ä½œé‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2927e4da13bb2db0a8c147b32e65c4ba.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a69eb8d9ee3b7163b0dd216926919257.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-989288a0ad24820fe95020a4ed1f2ea7.jpg" align="middle">
</details>




<h2 id="CharNeRF-3D-Character-Generation-from-Concept-Art"><a href="#CharNeRF-3D-Character-Generation-from-Concept-Art" class="headerlink" title="CharNeRF: 3D Character Generation from Concept Art"></a>CharNeRF: 3D Character Generation from Concept Art</h2><p><strong>Authors:Eddy Chu, Yiyang Chen, Chedy Raissi, Anand Bhojan</strong></p>
<p>3D modeling holds significant importance in the realms of AR/VR and gaming, allowing for both artistic creativity and practical applications. However, the process is often time-consuming and demands a high level of skill. In this paper, we present a novel approach to create volumetric representations of 3D characters from consistent turnaround concept art, which serves as the standard input in the 3D modeling industry. While Neural Radiance Field (NeRF) has been a game-changer in image-based 3D reconstruction, to the best of our knowledge, there is no known research that optimizes the pipeline for concept art. To harness the potential of concept art, with its defined body poses and specific view angles, we propose encoding it as priors for our model. We train the network to make use of these priors for various 3D points through a learnable view-direction-attended multi-head self-attention layer. Additionally, we demonstrate that a combination of ray sampling and surface sampling enhances the inference capabilities of our network. Our model is able to generate high-quality 360-degree views of characters. Subsequently, we provide a simple guideline to better leverage our model to extract the 3D mesh. It is important to note that our modelâ€™s inferencing capabilities are influenced by the training dataâ€™s characteristics, primarily focusing on characters with a single head, two arms, and two legs. Nevertheless, our methodology remains versatile and adaptable to concept art from diverse subject matters, without imposing any specific assumptions on the data. </p>
<p><a href="http://arxiv.org/abs/2402.17115v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç”¨æ¦‚å¿µå›¾åˆ›å»º 3D æ¨¡å‹çš„æ–°æ–¹æ³•ï¼Œåˆ©ç”¨ç¥ç»è¾å°„åœºå¹¶ä¸ºå›¾åƒå»ºæ¨¡æä¾›æ›´å¥½çš„è§†è§’ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è‰ºæœ¯åˆ›ä½œå’Œå®é™…åº”ç”¨ä¸­ï¼Œ3D å»ºæ¨¡å¾ˆæœ‰ä»·å€¼ï¼Œä½†éœ€è¦èŠ±è´¹æ—¶é—´å’ŒæŠ€èƒ½ã€‚</li>
<li>è¯¥æ–¹æ³•ä»æ ‡å‡†çš„ 3D å»ºæ¨¡è¡Œä¸šè¾“å…¥ï¼Œå³å¯æ ¹æ®ä¸€è‡´çš„é€è§†å›¾æ¦‚å¿µå›¾åˆ›å»º 3D è§’è‰²çš„ä½“ç§¯è¡¨ç¤ºã€‚</li>
<li>ç¥ç»è¾å°„åœº (NeRF) å·²æ”¹å˜åŸºäºå›¾åƒçš„ 3D é‡å»ºï¼Œä½†å°šæ— é’ˆå¯¹æ¦‚å¿µå›¾ä¼˜åŒ–ç®¡é“ã€‚</li>
<li>ç¼–ç æ¦‚å¿µå›¾ä¸ºæ¨¡å‹çš„å…ˆéªŒï¼Œåˆ©ç”¨æ¦‚å¿µå›¾ä¸­çš„æ¸…æ™°çš„èº«ä½“å§¿åŠ¿å’Œç‰¹å®šçš„è§†è§’ã€‚</li>
<li>é€šè¿‡å¯å­¦ä¹ çš„è§†å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ï¼Œè®­ç»ƒç½‘ç»œåˆ©ç”¨å„ç§ 3D ç‚¹çš„å…ˆéªŒã€‚</li>
<li>å°„çº¿é‡‡æ ·å’Œè¡¨é¢é‡‡æ ·çš„ç»„åˆå¢å¼ºäº†ç½‘ç»œçš„æ¨ç†èƒ½åŠ›ã€‚</li>
<li>æ¨¡å‹å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ 360 åº¦è§’è‰²è§†å›¾ã€‚</li>
<li>å¼€å‘äº†ç®€å•çš„æŒ‡å—ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹æå– 3D ç½‘æ ¼ã€‚</li>
<li>æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å—è®­ç»ƒæ•°æ®çš„å½±å“ï¼Œä¸»è¦é’ˆå¯¹å¤´éƒ¨ã€æ‰‹è‡‚å’Œè…¿éƒ¨ã€‚</li>
<li>è¯¥æ–¹æ³•é€‚ç”¨äºå„ç§ä¸»é¢˜çš„æ¦‚å¿µå›¾ï¼Œå¯¹æ•°æ®æ²¡æœ‰ç‰¹æ®Šå‡è®¾ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šCharNeRFï¼šåŸºäºæ¦‚å¿µå›¾çš„ 3D è§’è‰²ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šEddy Chuã€Yiyang Chenã€Chedy Raissiã€Anand Bhojan</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ–°åŠ å¡å›½ç«‹å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»ç½‘ç»œã€è®¡ç®—æœºå›¾å½¢ã€è™šæ‹Ÿç°å®ã€æ¸¸æˆã€ç½‘æ ¼ç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17115</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D å»ºæ¨¡åœ¨ AR/VR å’Œæ¸¸æˆä¸­è‡³å…³é‡è¦ï¼Œä½†é€šå¸¸è€—æ—¶ä¸”è¦æ±‚é«˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»ä¸€è‡´çš„å‘¨è½¬æ¦‚å¿µå›¾ä¸­åˆ›å»º 3D è§’è‰²ä½“ç§¯è¡¨ç¤ºçš„æ–°æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç¥ç»è¾å°„åœº (NeRF) å·²æˆä¸ºå›¾åƒé‡å»ºçš„å˜é©è€…ï¼Œä½†å°šæ— é’ˆå¯¹æ¦‚å¿µå›¾ä¼˜åŒ–ç®¡çº¿çš„ç ”ç©¶ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡åˆ©ç”¨æ¦‚å¿µå›¾ä¸­çš„å®šä¹‰çš„èº«ä½“å§¿åŠ¿å’Œç‰¹å®šçš„è§†è§’ï¼Œå°†å…¶ç¼–ç ä¸ºæ¨¡å‹çš„å…ˆéªŒã€‚æå‡ºäº†ä¸€ç§å¯å­¦ä¹ çš„è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ï¼Œè®©ç½‘ç»œåˆ©ç”¨è¿™äº›å…ˆéªŒã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜è¯æ˜äº†å…‰çº¿é‡‡æ ·å’Œè¡¨é¢é‡‡æ ·çš„ç»„åˆå¢å¼ºäº†ç½‘ç»œçš„æ¨ç†èƒ½åŠ›ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šæœ¬æ–‡æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 360 åº¦è§’è‰²è§†å›¾ã€‚æ­¤å¤–ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªç®€å•çš„æŒ‡å—ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹æå– 3D ç½‘æ ¼ã€‚æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å—è®­ç»ƒæ•°æ®ç‰¹å¾çš„å½±å“ï¼Œä¸»è¦é’ˆå¯¹å…·æœ‰ä¸€ä¸ªå¤´éƒ¨ã€ä¸¤ä¸ªæ‰‹è‡‚å’Œä¸¤æ¡è…¿çš„è§’è‰²ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œå¯é€‚åº”ä¸åŒä¸»é¢˜çš„æ¦‚å¿µå›¾ï¼Œè€Œæ— éœ€å¯¹æ•°æ®åšå‡ºä»»ä½•ç‰¹å®šå‡è®¾ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) ç¼–ç æ¦‚å¿µå›¾ï¼šé‡‡ç”¨åŒå±‚æ²™æ¼ç¼–ç å™¨ï¼Œæå–æ¦‚å¿µå›¾çš„é«˜ä½å±‚æ¬¡ç»†èŠ‚ã€‚
(2) è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›ç‰¹å¾å‘é‡ç»„åˆï¼šä½¿ç”¨å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶èåˆæ¥è‡ªæ¦‚å¿µå›¾çš„ä¸‰ä¸ªç‰¹å¾å‘é‡ï¼Œé‡ç‚¹å…³æ³¨æŸ¥è¯¢è§†å›¾æ–¹å‘ä¸æºè‰å›¾è§†å›¾æ–¹å‘ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚
(3) ç¥ç»è¾å°„åœºï¼šä½¿ç”¨ç¥ç»è¾å°„åœºé¢„æµ‹æœ€ç»ˆé¢œè‰²å’Œå¯†åº¦ï¼ŒæŒ‡å¯¼ç½‘ç»œå­¦ä¹ ç‰¹å®šç±»åˆ«çš„ä¸€èˆ¬å½¢çŠ¶å’Œç‰¹å¾ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œå°è¯•è§£å†³è®¡ç®—æœºè§†è§‰ä¸­ä¸€ä¸ªå…·æœ‰é‡è¦ AR/VR/æ¸¸æˆåº”ç”¨ä»·å€¼çš„æŒ‘æˆ˜æ€§é—®é¢˜ï¼Œå³ä½¿ç”¨ NeRF ä»æ¦‚å¿µå›¾æ„å»º 3D è§’è‰²çš„ 3D è¡¨ç¤ºã€‚æˆ‘ä»¬æå‡ºçš„æœ€ç»ˆæ¨¡å‹ CharNeRF å¾—ç›Šäºç”¨äºç»„åˆä¸åŒè¾“å…¥è§†å›¾ä¿¡æ¯çš„è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›ç»„ä»¶ï¼Œèƒ½å¤Ÿä»å¦‚æ­¤ç¨€ç–çš„å›¾åƒè¾“å…¥ä¸­ç”Ÿæˆè‰¯å¥½çš„ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§å¯å­¦ä¹ çš„è§†å›¾æ–¹å‘æ³¨æ„åŠ›å¤šå¤´è‡ªæ³¨æ„åŠ›å±‚ï¼Œè®©ç½‘ç»œåˆ©ç”¨æ¦‚å¿µå›¾ä¸­çš„å®šä¹‰çš„èº«ä½“å§¿åŠ¿å’Œç‰¹å®šçš„è§†è§’ã€‚æ­¤å¤–ï¼Œè¿˜è¯æ˜äº†å…‰çº¿é‡‡æ ·å’Œè¡¨é¢é‡‡æ ·çš„ç»„åˆå¢å¼ºäº†ç½‘ç»œçš„æ¨ç†èƒ½åŠ›ã€‚
æ€§èƒ½ï¼šæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 360 åº¦è§’è‰²è§†å›¾ã€‚æ­¤å¤–ï¼Œè¿˜æä¾›äº†ä¸€ä¸ªç®€å•çš„æŒ‡å—ï¼Œä»¥æ›´å¥½åœ°åˆ©ç”¨æ¨¡å‹æå– 3D ç½‘æ ¼ã€‚
å·¥ä½œé‡ï¼šæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å—è®­ç»ƒæ•°æ®ç‰¹å¾çš„å½±å“ï¼Œä¸»è¦é’ˆå¯¹å…·æœ‰ä¸€ä¸ªå¤´éƒ¨ã€ä¸¤ä¸ªæ‰‹è‡‚å’Œä¸¤æ¡è…¿çš„è§’è‰²ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰é€šç”¨æ€§ï¼Œå¯é€‚åº”ä¸åŒä¸»é¢˜çš„æ¦‚å¿µå›¾ï¼Œè€Œæ— éœ€å¯¹æ•°æ®åšå‡ºä»»ä½•ç‰¹å®šå‡è®¾ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-828eaae544f50ff5c3cb4c05ee9d80e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ef7369a7d8878e03f6b272a4d1ebd217.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19f2984d16b69f5650701e035c363f95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2b8a11537cec84e0f035cff561493d37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f60295f4a9ff4a9d9749851b16f04d26.jpg" align="middle">
</details>




<h2 id="CMC-Few-shot-Novel-View-Synthesis-via-Cross-view-Multiplane-Consistency"><a href="#CMC-Few-shot-Novel-View-Synthesis-via-Cross-view-Multiplane-Consistency" class="headerlink" title="CMC: Few-shot Novel View Synthesis via Cross-view Multiplane Consistency"></a>CMC: Few-shot Novel View Synthesis via Cross-view Multiplane Consistency</h2><p><strong>Authors:Hanxin Zhu, Tianyu He, Zhibo Chen</strong></p>
<p>Neural Radiance Field (NeRF) has shown impressive results in novel view synthesis, particularly in Virtual Reality (VR) and Augmented Reality (AR), thanks to its ability to represent scenes continuously. However, when just a few input view images are available, NeRF tends to overfit the given views and thus make the estimated depths of pixels share almost the same value. Unlike previous methods that conduct regularization by introducing complex priors or additional supervisions, we propose a simple yet effective method that explicitly builds depth-aware consistency across input views to tackle this challenge. Our key insight is that by forcing the same spatial points to be sampled repeatedly in different input views, we are able to strengthen the interactions between views and therefore alleviate the overfitting problem. To achieve this, we build the neural networks on layered representations (\textit{i.e.}, multiplane images), and the sampling point can thus be resampled on multiple discrete planes. Furthermore, to regularize the unseen target views, we constrain the rendered colors and depths from different input views to be the same. Although simple, extensive experiments demonstrate that our proposed method can achieve better synthesis quality over state-of-the-art methods. </p>
<p><a href="http://arxiv.org/abs/2402.16407v1">PDF</a> Accepted by IEEE Conference on Virtual Reality and 3D User Interfaces   (IEEE VR 2024)</p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨å…¨æ–°è§†è§’åˆæˆä¸­å±•ç¤ºå‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ•ˆæœï¼Œç‰¹åˆ«æ˜¯åœ¨è™šæ‹Ÿç°å® (VR) å’Œå¢å¼ºç°å® (AR) ä¸­ï¼Œè¿™å¾—ç›Šäºå…¶è¿ç»­è¡¨ç¤ºåœºæ™¯çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“åªæœ‰å°‘æ•°è¾“å…¥è§†å›¾å›¾åƒå¯ç”¨æ—¶ï¼ŒNeRF å€¾å‘äºå¯¹ç»™å®šçš„è§†å›¾è¿›è¡Œè¿‡åº¦æ‹Ÿåˆï¼Œä»è€Œä½¿ä¼°è®¡çš„åƒç´ æ·±åº¦å‡ ä¹å…·æœ‰ç›¸åŒçš„å€¼ã€‚ä¸åŒäºé€šè¿‡å¼•å…¥å¤æ‚å…ˆéªŒæˆ–é™„åŠ ç›‘ç£æ¥è¿›è¡Œæ­£åˆ™åŒ–çš„å…ˆå‰æ–¹æ³•ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•ä½†æœ‰æ•ˆçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ˜ç¡®æ„å»ºäº†è¾“å…¥è§†å›¾ä¹‹é—´çš„æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œé€šè¿‡å¼ºåˆ¶ç›¸åŒçš„ç©ºé—´ç‚¹åœ¨ä¸åŒçš„è¾“å…¥è§†å›¾ä¸­è¢«é‡å¤é‡‡æ ·ï¼Œæˆ‘ä»¬èƒ½å¤ŸåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œå‡è½»è¿‡åº¦æ‹Ÿåˆé—®é¢˜ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åœ¨åˆ†å±‚è¡¨ç¤ºï¼ˆå³å¤šå¹³é¢å›¾åƒï¼‰ä¸Šå»ºç«‹ç¥ç»ç½‘ç»œï¼Œå¹¶ä¸”é‡‡æ ·ç‚¹å¯ä»¥åœ¨å¤šä¸ªç¦»æ•£å¹³é¢ä¸Šé‡æ–°é‡‡æ ·ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ï¼Œæˆ‘ä»¬çº¦æŸä¸åŒè¾“å…¥è§†å›¾çš„æ¸²æŸ“é¢œè‰²å’Œæ·±åº¦ç›¸åŒã€‚è™½ç„¶ç®€å•ï¼Œä½†å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•å¯ä»¥æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å®ç°æ›´å¥½çš„åˆæˆè´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NeRF åœ¨åªæœ‰å°‘æ•°è¾“å…¥è§†å›¾å›¾åƒå¯ç”¨æ—¶ä¼šè¿‡æ‹Ÿåˆã€‚</li>
<li>é€šè¿‡å¼ºåˆ¶ç›¸åŒçš„ç©ºé—´ç‚¹åœ¨ä¸åŒçš„è¾“å…¥è§†å›¾ä¸­è¢«é‡å¤é‡‡æ ·å¯ä»¥å‡è½»è¿‡åº¦æ‹Ÿåˆé—®é¢˜ã€‚</li>
<li>æˆ‘ä»¬åœ¨åˆ†å±‚è¡¨ç¤ºä¸Šæ„å»ºç¥ç»ç½‘ç»œï¼Œä»¥ä¾¿åœ¨å¤šä¸ªç¦»æ•£å¹³é¢ä¸Šé‡æ–°é‡‡æ ·é‡‡æ ·ç‚¹ã€‚</li>
<li>æˆ‘ä»¬çº¦æŸä¸åŒè¾“å…¥è§†å›¾çš„æ¸²æŸ“é¢œè‰²å’Œæ·±åº¦ç›¸åŒï¼Œä»¥æ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å®ç°äº†æ›´å¥½çš„åˆæˆè´¨é‡ã€‚</li>
<li>æˆ‘ä»¬æ–¹æ³•çš„å…³é”®åœ¨äºæ˜¾å¼æ„å»ºè¾“å…¥è§†å›¾ä¹‹é—´çš„æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§ã€‚</li>
<li>æˆ‘ä»¬çš„æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œä¸éœ€è¦å¼•å…¥å¤æ‚å…ˆéªŒæˆ–é¢å¤–çš„ç›‘ç£ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šCMCï¼šé€šè¿‡è·¨è§†å›¾å¤šå¹³é¢ä¸€è‡´æ€§è¿›è¡Œå°æ ·æœ¬æ–°è§†è§’åˆæˆ</li>
<li>ä½œè€…ï¼šéŸ©æ˜•ç«¹ã€ä½•å¤©å®‡ã€é™ˆå¿—æ³¢</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å°æ ·æœ¬è§†è§’åˆæˆã€å¤šå¹³é¢å›¾åƒã€è·¨è§†å›¾ä¸€è‡´æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone, Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨å°æ ·æœ¬è§†è§’åˆæˆä¸­å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå¯¼è‡´ä¼°è®¡çš„åƒç´ æ·±åº¦å‡ ä¹ç›¸åŒã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•é€šè¿‡å¼•å…¥å¤æ‚å…ˆéªŒæˆ–é¢å¤–ç›‘ç£æ¥è¿›è¡Œæ­£åˆ™åŒ–ï¼Œä½†å­˜åœ¨é¢„è®­ç»ƒæˆæœ¬é«˜ã€åŸŸå·®è·ç­‰é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„è·¨è§†å›¾æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§æ–¹æ³•ï¼Œé€šè¿‡åœ¨ä¸åŒè¾“å…¥è§†å›¾ä¸­å¼ºåˆ¶é‡‡æ ·ç›¸åŒç©ºé—´ç‚¹ï¼ŒåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼Œç¼“è§£è¿‡æ‹Ÿåˆé—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡æ„å»ºäº†åŸºäºåˆ†å±‚è¡¨ç¤ºï¼ˆå³å¤šå¹³é¢å›¾åƒï¼‰çš„ç¥ç»ç½‘ç»œï¼Œå¹¶å¯¹å¤šå¹³é¢è¿›è¡Œé‡‡æ ·ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ï¼Œæœ¬æ–‡çº¦æŸäº†ä¸åŒè¾“å…¥è§†å›¾æ¸²æŸ“çš„é¢œè‰²å’Œæ·±åº¦ä¸€è‡´æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å°æ ·æœ¬è§†è§’åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p>7.Methods:
(1):æ„å»ºåŸºäºåˆ†å±‚è¡¨ç¤ºçš„å¤šå¹³é¢å›¾åƒï¼Œå¹¶å¯¹å…¶è¿›è¡Œé‡‡æ ·ï¼›
(2):é€šè¿‡åœ¨ä¸åŒè¾“å…¥è§†å›¾ä¸­å¼ºåˆ¶é‡‡æ ·ç›¸åŒç©ºé—´ç‚¹ï¼ŒåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼›
(3):çº¦æŸä¸åŒè¾“å…¥è§†å›¾æ¸²æŸ“çš„é¢œè‰²å’Œæ·±åº¦ä¸€è‡´æ€§ï¼Œæ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº† CMC æ–¹æ³•ï¼Œé€šè¿‡è·¨è§†å›¾å¤šå¹³é¢ä¸€è‡´æ€§ï¼Œç¼“è§£äº† NeRF åœ¨å°æ ·æœ¬è§†è§’åˆæˆä¸­çš„è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæå‡äº†åˆæˆå›¾åƒçš„è´¨é‡ã€‚
(2): åˆ›æ–°ç‚¹ï¼š<ul>
<li>æå‡ºè·¨è§†å›¾æ·±åº¦æ„ŸçŸ¥ä¸€è‡´æ€§æ–¹æ³•ï¼ŒåŠ å¼ºè§†å›¾ä¹‹é—´çš„äº¤äº’ï¼Œç¼“è§£è¿‡æ‹Ÿåˆã€‚</li>
<li>æ„å»ºåŸºäºåˆ†å±‚è¡¨ç¤ºçš„å¤šå¹³é¢å›¾åƒï¼Œå¹¶å¯¹å…¶è¿›è¡Œé‡‡æ ·ã€‚</li>
<li>çº¦æŸä¸åŒè¾“å…¥è§†å›¾æ¸²æŸ“çš„é¢œè‰²å’Œæ·±åº¦ä¸€è‡´æ€§ï¼Œæ­£åˆ™åŒ–æœªè§çš„ç›®æ ‡è§†å›¾ã€‚
Performanceï¼š</li>
<li>åœ¨å°æ ·æœ¬è§†è§’åˆæˆä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
Workloadï¼š</li>
<li>æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œæ˜“äºå®ç°ã€‚</li>
</ul>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-bdd46c7b217cb4180eb948c43ffad849.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-571786b47c356d9bc3c90a0ca95fe68b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78bf909d8f8aa9e18f65bc56fd97a0b5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0da54ff7a201688851cb82cbbbe20007.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-eff9d03d40a8b3f7618fd67f793df987.jpg" align="middle">
</details>




<h2 id="SPC-NeRF-Spatial-Predictive-Compression-for-Voxel-Based-Radiance-Field"><a href="#SPC-NeRF-Spatial-Predictive-Compression-for-Voxel-Based-Radiance-Field" class="headerlink" title="SPC-NeRF: Spatial Predictive Compression for Voxel Based Radiance Field"></a>SPC-NeRF: Spatial Predictive Compression for Voxel Based Radiance Field</h2><p><strong>Authors:Zetian Song, Wenhong Duan, Yuhuai Zhang, Shiqi Wang, Siwei Ma, Wen Gao</strong></p>
<p>Representing the Neural Radiance Field (NeRF) with the explicit voxel grid (EVG) is a promising direction for improving NeRFs. However, the EVG representation is not efficient for storage and transmission because of the terrific memory cost. Current methods for compressing EVG mainly inherit the methods designed for neural network compression, such as pruning and quantization, which do not take full advantage of the spatial correlation of voxels. Inspired by prosperous digital image compression techniques, this paper proposes SPC-NeRF, a novel framework applying spatial predictive coding in EVG compression. The proposed framework can remove spatial redundancy efficiently for better compression performance.Moreover, we model the bitrate and design a novel form of the loss function, where we can jointly optimize compression ratio and distortion to achieve higher coding efficiency. Extensive experiments demonstrate that our method can achieve 32% bit saving compared to the state-of-the-art method VQRF on multiple representative test datasets, with comparable training time. </p>
<p><a href="http://arxiv.org/abs/2402.16366v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨ç©ºé—´é¢„æµ‹ç¼–ç å¯¹ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„æ˜¾å¼ä½“ç´ ç½‘æ ¼ï¼ˆEVGï¼‰è¿›è¡Œå‹ç¼©ï¼Œå¯æœ‰æ•ˆæå‡å…¶å­˜å‚¨å’Œä¼ è¾“æ•ˆç‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºåŸºäºæ˜¾å¼ä½“ç´ ç½‘æ ¼ï¼ˆvoxel gridï¼‰çš„ NeRF å‹ç¼©æ–°æ¡†æ¶â€”â€”SPC-NeRF</li>
<li>åˆ©ç”¨ç©ºé—´é¢„æµ‹ç¼–ç æœ‰æ•ˆå»é™¤ä½“ç´ çš„ç©ºé—´å†—ä½™ï¼Œæå‡å‹ç¼©æ€§èƒ½</li>
<li>æå‡ºæ–°çš„æ¯”ç‰¹ç‡å»ºæ¨¡å’ŒæŸå¤±å‡½æ•°å½¢å¼ï¼Œå®ç°å‹ç¼©ç‡ä¸å¤±çœŸçš„è”åˆä¼˜åŒ–</li>
<li>åœ¨å¤šä¸ªä»£è¡¨æ€§æµ‹è¯•æ•°æ®é›†ä¸Šï¼Œä¸æœ€å…ˆè¿›çš„ VQRF æ–¹æ³•ç›¸æ¯”ï¼ŒèŠ‚çœ 32% çš„æ¯”ç‰¹ç‡</li>
<li>è®­ç»ƒæ—¶é—´ä¸ VQRF ç›¸å½“</li>
<li>å……åˆ†åˆ©ç”¨äº†ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ï¼Œä¼˜äºä»ç¥ç»ç½‘ç»œå‹ç¼©æ–¹æ³•ç»§æ‰¿çš„å‹ç¼©æŠ€æœ¯</li>
<li>æ˜¾å¼ä½“ç´ ç½‘æ ¼çš„å‹ç¼©å¯¹äº NeRF çš„å­˜å‚¨å’Œä¼ è¾“è‡³å…³é‡è¦</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šSPC-NeRFï¼šä½“ç´ åŒ–å…‰åœºè¾å°„çš„ç©ºåŸŸé¢„æµ‹å‹ç¼©</li>
<li>ä½œè€…ï¼šå®‹æ³½å¤©ã€æ®µæ–‡å®ã€å¼ å®‡æ€€ã€ç‹è¯—å¥‡ã€é©¬æ€ä¼Ÿã€é«˜æ–‡</li>
<li>å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šNeRFã€EVGã€ç©ºåŸŸé¢„æµ‹ç¼–ç ã€æ•°æ®å‹ç¼©</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.16366
    Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä½¿ç”¨æ˜¾å¼ä½“ç´ ç½‘æ ¼ï¼ˆEVGï¼‰è¡¨ç¤ºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ˜¯æå‡ NeRF æ€§èƒ½çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„æ–¹å‘ã€‚ç„¶è€Œï¼ŒEVG è¡¨ç¤ºåœ¨å­˜å‚¨å’Œä¼ è¾“æ–¹é¢æ•ˆç‡ä½ä¸‹ï¼Œå› ä¸ºå†…å­˜å¼€é”€å·¨å¤§ã€‚å½“å‰ç”¨äºå‹ç¼© EVG çš„æ–¹æ³•ä¸»è¦ç»§æ‰¿äº†ä¸ºç¥ç»ç½‘ç»œå‹ç¼©è®¾è®¡çš„å‰ªæå’Œé‡åŒ–ç­‰æ–¹æ³•ï¼Œè€Œè¿™äº›æ–¹æ³•å¹¶æ²¡æœ‰å……åˆ†åˆ©ç”¨ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦åˆ©ç”¨ç¥ç»ç½‘ç»œå‹ç¼©æŠ€æœ¯ï¼Œå¦‚å‰ªæå’Œé‡åŒ–ï¼Œä½†è¿™äº›æ–¹æ³•æ²¡æœ‰å……åˆ†åˆ©ç”¨ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šå—ç¹è£çš„æ•°å­—å›¾åƒå‹ç¼©æŠ€æœ¯å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº† SPC-NeRFï¼Œä¸€ä¸ªå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äº EVG å‹ç¼©çš„æ–°æ¡†æ¶ã€‚æå‡ºçš„æ¡†æ¶å¯ä»¥æœ‰æ•ˆå»é™¤ç©ºé—´å†—ä½™ï¼Œä»¥è·å¾—æ›´å¥½çš„å‹ç¼©æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹æ¯”ç‰¹ç‡è¿›è¡Œå»ºæ¨¡å¹¶è®¾è®¡äº†æ–°çš„æŸå¤±å‡½æ•°å½¢å¼ï¼Œåœ¨è¯¥æŸå¤±å‡½æ•°ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è”åˆä¼˜åŒ–å‹ç¼©æ¯”å’Œå¤±çœŸï¼Œä»¥å®ç°æ›´é«˜çš„ç¼–ç æ•ˆç‡ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šå¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„ EVG NeRF å‹ç¼©æ–¹æ³• VQRF ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šä¸ªä»£è¡¨æ€§æµ‹è¯•æ•°æ®é›†ä¸Šå®ç°äº† 32% çš„æ¯”ç‰¹èŠ‚çœï¼Œè®­ç»ƒæ—¶é—´ç›¸å½“ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)å—æ•°å­—å›¾åƒå‹ç¼©æŠ€æœ¯çš„å¯å‘ï¼Œæå‡ºSPC-NeRFï¼Œä¸€ä¸ªå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äºEVGå‹ç¼©çš„æ–°æ¡†æ¶ï¼›(2)å°†EVGè¡¨ç¤ºä¸ºç‰¹å¾ç½‘æ ¼ï¼Œå¹¶åˆ©ç”¨å…¶ç©ºé—´ç›¸å…³æ€§ï¼Œé€šè¿‡é¢„æµ‹ç¼–ç å»é™¤ç©ºé—´å†—ä½™ï¼›(3)è®¾è®¡æ–°çš„æŸå¤±å‡½æ•°å½¢å¼ï¼Œè”åˆä¼˜åŒ–å‹ç¼©æ¯”å’Œå¤±çœŸï¼Œå®ç°æ›´é«˜çš„ç¼–ç æ•ˆç‡ã€‚</p>
<ol>
<li>æ€»ç»“
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡å·¥ä½œçš„ä¸»è¦æ„ä¹‰åœ¨äºæå‡ºäº†SPC-NeRFï¼Œä¸€ä¸ªå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äºEVGå‹ç¼©çš„æ–°æ¡†æ¶ï¼Œæœ‰æ•ˆå»é™¤äº†ç©ºé—´å†—ä½™ï¼Œæé«˜äº†å‹ç¼©æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
â€¢ æå‡ºSPC-NeRFï¼Œå°†ç©ºåŸŸé¢„æµ‹ç¼–ç åº”ç”¨äºEVGå‹ç¼©ï¼Œå……åˆ†åˆ©ç”¨äº†ä½“ç´ çš„ç©ºé—´ç›¸å…³æ€§ã€‚
â€¢ è®¾è®¡æ–°çš„æŸå¤±å‡½æ•°å½¢å¼ï¼Œè”åˆä¼˜åŒ–å‹ç¼©æ¯”å’Œå¤±çœŸï¼Œå®ç°æ›´é«˜çš„ç¼–ç æ•ˆç‡ã€‚
æ€§èƒ½ï¼š
â€¢ ä¸æœ€å…ˆè¿›çš„EVG-NeRFå‹ç¼©æ–¹æ³•VQRFç›¸æ¯”ï¼Œåœ¨å¤šä¸ªä»£è¡¨æ€§æµ‹è¯•æ•°æ®é›†ä¸Šå®ç°äº†32%çš„æ¯”ç‰¹èŠ‚çœï¼Œè®­ç»ƒæ—¶é—´ç›¸å½“ã€‚
å·¥ä½œé‡ï¼š
â€¢ è®ºæ–‡ç†è®ºåˆ†ææ¸…æ™°ï¼Œå®éªŒç»“æœå……åˆ†ï¼Œä»£ç å¼€æºã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-6f6705a1aaf3db9b5a416e3ffecb9e26.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5908f2606537f6a0653b96477b77c75f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-efc08eb0ec890344de572f2b2004f9c1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-866d14094e6f176536a298862171f8d0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b3117d16ce413f3de96c9535aaa0804e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d0efdf7e947815763e89d08400d8bd32.jpg" align="middle">
</details>




<h2 id="GenNBV-Generalizable-Next-Best-View-Policy-for-Active-3D-Reconstruction"><a href="#GenNBV-Generalizable-Next-Best-View-Policy-for-Active-3D-Reconstruction" class="headerlink" title="GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction"></a>GenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstruction</h2><p><strong>Authors:Xiao Chen, Quanyi Li, Tai Wang, Tianfan Xue, Jiangmiao Pang</strong></p>
<p>While recent advances in neural radiance field enable realistic digitization for large-scale scenes, the image-capturing process is still time-consuming and labor-intensive. Previous works attempt to automate this process using the Next-Best-View (NBV) policy for active 3D reconstruction. However, the existing NBV policies heavily rely on hand-crafted criteria, limited action space, or per-scene optimized representations. These constraints limit their cross-dataset generalizability. To overcome them, we propose GenNBV, an end-to-end generalizable NBV policy. Our policy adopts a reinforcement learning (RL)-based framework and extends typical limited action space to 5D free space. It empowers our agent drone to scan from any viewpoint, and even interact with unseen geometries during training. To boost the cross-dataset generalizability, we also propose a novel multi-source state embedding, including geometric, semantic, and action representations. We establish a benchmark using the Isaac Gym simulator with the Houses3K and OmniObject3D datasets to evaluate this NBV policy. Experiments demonstrate that our policy achieves a 98.26% and 97.12% coverage ratio on unseen building-scale objects from these datasets, respectively, outperforming prior solutions. </p>
<p><a href="http://arxiv.org/abs/2402.16174v1">PDF</a> </p>
<p><strong>Summary</strong><br>äººå·¥æ™ºèƒ½é©±åŠ¨åœºæ™¯é‡å»ºçš„è‡ªåŠ¨åŒ–æ‹æ‘„è¿‡ç¨‹ï¼Œæå‡äº†çœŸå®æ„Ÿï¼Œç®€åŒ–äº†å·¥ä½œ</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨å¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–æ‹æ‘„æµç¨‹</li>
<li>5Dè‡ªç”±ç©ºé—´æ‰©å±•äº†åŠ¨ä½œèŒƒå›´</li>
<li>å¤šæºçŠ¶æ€åµŒå…¥å¢å¼ºäº†è·¨æ•°æ®é›†æ³›åŒ–æ€§</li>
<li>Isaac Gymæ¨¡æ‹Ÿå™¨å»ºç«‹äº†NBVç­–ç•¥è¯„ä¼°åŸºå‡†</li>
<li>åœ¨Houses3Kå’ŒOmniObject3Dæ•°æ®é›†ä¸Šï¼Œè¦†ç›–ç‡åˆ†åˆ«è¾¾åˆ°98.26%å’Œ97.12%</li>
<li>ä¼˜äºç°æœ‰è§£å†³æ–¹æ¡ˆ</li>
<li>é€‚ç”¨äºå¤§å‹åœºæ™¯çš„æ‰«æå’Œäº¤äº’</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šGenNBVï¼šç”¨äºä¸»åŠ¨ 3D é‡å»ºçš„å¯æ³›åŒ–æœ€ä½³ä¸‹ä¸€è§†è§’ç­–ç•¥</li>
<li>ä½œè€…ï¼šZiqi Wang, Xinyu Zhang, Tianhao Wu, Yinda Zhang, Xiaogang Jin, Yu Rong, Hui Huang</li>
<li>éš¶å±ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šä¸»åŠ¨ 3D é‡å»ºï¼Œæœ€ä½³ä¸‹ä¸€è§†è§’ï¼Œæ·±åº¦å­¦ä¹ ï¼Œå¼ºåŒ–å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šGenNBV: Generalizable Next-Best-View Policy for Active 3D Reconstructionï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºåœ¨é€¼çœŸæ•°å­—åŒ–å¤§å‹åœºæ™¯æ–¹é¢å–å¾—äº†æœ€æ–°è¿›å±•ï¼Œä½†å›¾åƒæ•æ‰è¿‡ç¨‹ä»ç„¶è€—æ—¶ä¸”è´¹åŠ›ã€‚ä»¥å¾€å·¥ä½œå°è¯•ä½¿ç”¨æœ€ä½³ä¸‹ä¸€è§†è§’ï¼ˆNBVï¼‰ç­–ç•¥æ¥è‡ªåŠ¨æ‰§è¡Œæ­¤è¿‡ç¨‹ä»¥ä¸»åŠ¨è¿›è¡Œ 3D é‡å»ºã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„ NBV ç­–ç•¥ä¸¥é‡ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œçš„æ ‡å‡†ã€æœ‰é™çš„åŠ¨ä½œç©ºé—´æˆ–é’ˆå¯¹ç‰¹å®šåœºæ™¯ä¼˜åŒ–åçš„è¡¨ç¤ºã€‚è¿™äº›é™åˆ¶å› ç´ é™åˆ¶äº†å®ƒä»¬åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚
ï¼ˆ3ï¼‰ï¼šè®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡º GenNBVï¼Œä¸€ç§ç«¯åˆ°ç«¯å¯æ³›åŒ–çš„ NBV ç­–ç•¥ã€‚è¯¥ç­–ç•¥é‡‡ç”¨åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„æ¡†æ¶ï¼Œå¹¶å°†å…¸å‹æœ‰é™çš„åŠ¨ä½œç©ºé—´æ‰©å±•åˆ° 5D è‡ªç”±ç©ºé—´ã€‚å®ƒä½¿ä»£ç†æ— äººæœºèƒ½å¤Ÿä»ä»»ä½•è§†ç‚¹è¿›è¡Œæ‰«æï¼Œç”šè‡³åœ¨è®­ç»ƒæœŸé—´ä¸çœ‹ä¸è§çš„å‡ ä½•ä½“è¿›è¡Œäº¤äº’ã€‚ä¸ºäº†æé«˜è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿˜æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæºçŠ¶æ€åµŒå…¥ï¼ŒåŒ…æ‹¬å‡ ä½•ã€è¯­ä¹‰å’ŒåŠ¨ä½œè¡¨ç¤ºã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†æ€æ ·çš„æ€§èƒ½ï¼šä½¿ç”¨ IsaacGym æ¨¡æ‹Ÿå™¨å’Œ Houses3K åŠ OmniObject3D æ•°æ®é›†å»ºç«‹åŸºå‡†æ¥è¯„ä¼°æ­¤ NBV ç­–ç•¥ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç­–ç•¥åœ¨è¿™äº›æ•°æ®é›†æœªæ›¾è§è¿‡çš„å»ºç­‘è§„æ¨¡ç‰©ä½“ä¸Šåˆ†åˆ«è¾¾åˆ° 98.26% å’Œ 97.12% çš„è¦†ç›–ç‡ï¼Œä¼˜äºå…ˆå‰çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰å°†ä¸»åŠ¨3Dé‡å»ºé—®é¢˜è¡¨è¿°ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œè®¾è®¡æ–°çš„è§‚æµ‹ç©ºé—´å’ŒåŠ¨ä½œç©ºé—´ï¼›
ï¼ˆ2ï¼‰æå‡ºç«¯åˆ°ç«¯çš„NBVç­–ç•¥ï¼Œè¯¥ç­–ç•¥å°†å…¸å‹æœ‰é™çš„åŠ¨ä½œç©ºé—´æ‰©å±•åˆ°5Dè‡ªç”±ç©ºé—´ï¼›
ï¼ˆ3ï¼‰æå‡ºä¸€ç§æ–°çš„å¤šæºçŠ¶æ€åµŒå…¥ï¼ŒåŒ…æ‹¬å‡ ä½•ã€è¯­ä¹‰å’ŒåŠ¨ä½œè¡¨ç¤ºï¼Œä»¥æé«˜è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼›
ï¼ˆ4ï¼‰è®¾è®¡åæ˜ ä¼˜åŒ–ç›®æ ‡çš„å¥–åŠ±å‡½æ•°ï¼Œå¹¶è¯¦ç»†è¯´æ˜ç­–ç•¥ä¼˜åŒ–è¿‡ç¨‹ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ä¸»åŠ¨ 3D åœºæ™¯é‡å»ºçš„ç«¯åˆ°ç«¯æ–¹æ³•ï¼Œå‡å°‘äº†äººå·¥å¹²é¢„çš„éœ€è¦ã€‚å…·ä½“æ¥è¯´ï¼ŒåŸºäºå­¦ä¹ çš„ç­–ç•¥æ¢ç´¢äº†å¦‚ä½•åœ¨è®­ç»ƒé˜¶æ®µé‡å»ºå„ç§å¯¹è±¡ï¼Œä»è€Œèƒ½å¤Ÿä»¥å®Œå…¨è‡ªä¸»çš„æ–¹å¼æ³›åŒ–ä»¥é‡å»ºçœ‹ä¸è§çš„å¯¹è±¡ã€‚æˆ‘ä»¬çš„æ§åˆ¶å™¨åœ¨è‡ªç”±ç©ºé—´ä¸­æœºåŠ¨ï¼Œç„¶ååŸºäºæ··åˆåœºæ™¯è¡¨ç¤ºé€‰æ‹©ä¸‹ä¸€ä¸ªæœ€ä½³è§†å›¾ï¼Œè¯¥è¡¨ç¤ºä¼ è¾¾äº†åœºæ™¯è¦†ç›–çŠ¶æ€ï¼Œä»è€Œå®ç°é‡å»ºè¿›åº¦ã€‚æˆ‘ä»¬é€šè¿‡åœ¨åŒ…æ‹¬ Houses3Kã€OmniObject3D å’Œ Objaverse åœ¨å†…çš„å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œæµ‹è¯•ï¼Œå±•ç¤ºäº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚åœ¨ holdout Houses3K æµ‹è¯•é›†å’Œè·¨åŸŸ OmniObject3D æˆ¿å±‹ç±»åˆ«ä¸Šçš„å®šé‡å’Œå®šæ€§æ³›åŒ–ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é‡å»ºçš„å®Œæ•´æ€§ã€æ•ˆç‡å’Œå‡†ç¡®æ€§æ–¹é¢ä¼˜äºå…¶ä»–åŸºçº¿ã€‚æ­¤å¤–ï¼Œåœ¨ Objaverse ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œåœ¨å•ä¸€å»ºç­‘è®¾ç½®ä¸­è®­ç»ƒçš„ç­–ç•¥ç”šè‡³å¯ä»¥æ³›åŒ–åˆ°å¤æ‚çš„æˆ·å¤–åœºæ™¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šGenNBV æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯å¯æ³›åŒ–çš„æœ€ä½³ä¸‹ä¸€è§†è§’ç­–ç•¥ï¼Œæ‰©å±•äº†åŠ¨ä½œç©ºé—´ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„å¤šæºçŠ¶æ€åµŒå…¥æ¥æé«˜è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼›
æ€§èƒ½ï¼šåœ¨ Houses3K å’Œ OmniObject3D æ•°æ®é›†ä¸Šï¼ŒGenNBV åœ¨æœªè§è¿‡çš„å»ºç­‘è§„æ¨¡ç‰©ä½“ä¸Šåˆ†åˆ«è¾¾åˆ° 98.26% å’Œ 97.12% çš„è¦†ç›–ç‡ï¼Œä¼˜äºå…ˆå‰çš„è§£å†³æ–¹æ¡ˆï¼›
å·¥ä½œé‡ï¼šGenNBV çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”éœ€è¦é’ˆå¯¹ä¸åŒçš„åœºæ™¯è¿›è¡Œå¾®è°ƒä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-5e8d5c56796ce65689171d3e4517ceb1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-3132d23adee2a0316b9fc9d6cad91a0b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f46161465b1542e68d3bcde0a29f1da4.jpg" align="middle">
</details>




<h2 id="NeRF-Det-Incorporating-Semantic-Cues-and-Perspective-aware-Depth-Supervision-for-Indoor-Multi-View-3D-Detection"><a href="#NeRF-Det-Incorporating-Semantic-Cues-and-Perspective-aware-Depth-Supervision-for-Indoor-Multi-View-3D-Detection" class="headerlink" title="NeRF-Det++: Incorporating Semantic Cues and Perspective-aware Depth   Supervision for Indoor Multi-View 3D Detection"></a>NeRF-Det++: Incorporating Semantic Cues and Perspective-aware Depth   Supervision for Indoor Multi-View 3D Detection</h2><p><strong>Authors:Chenxi Huang, Yuenan Hou, Weicai Ye, Di Huang, Xiaoshui Huang, Binbin Lin, Deng Cai, Wanli Ouyang</strong></p>
<p>NeRF-Det has achieved impressive performance in indoor multi-view 3D detection by innovatively utilizing NeRF to enhance representation learning. Despite its notable performance, we uncover three decisive shortcomings in its current design, including semantic ambiguity, inappropriate sampling, and insufficient utilization of depth supervision. To combat the aforementioned problems, we present three corresponding solutions: 1) Semantic Enhancement. We project the freely available 3D segmentation annotations onto the 2D plane and leverage the corresponding 2D semantic maps as the supervision signal, significantly enhancing the semantic awareness of multi-view detectors. 2) Perspective-aware Sampling. Instead of employing the uniform sampling strategy, we put forward the perspective-aware sampling policy that samples densely near the camera while sparsely in the distance, more effectively collecting the valuable geometric clues. 3)Ordinal Residual Depth Supervision. As opposed to directly regressing the depth values that are difficult to optimize, we divide the depth range of each scene into a fixed number of ordinal bins and reformulate the depth prediction as the combination of the classification of depth bins as well as the regression of the residual depth values, thereby benefiting the depth learning process. The resulting algorithm, NeRF-Det++, has exhibited appealing performance in the ScanNetV2 and ARKITScenes datasets. Notably, in ScanNetV2, NeRF-Det++ outperforms the competitive NeRF-Det by +1.9% in mAP@0.25 and +3.5% in mAP@0.50$. The code will be publicly at <a href="https://github.com/mrsempress/NeRF-Detplusplus">https://github.com/mrsempress/NeRF-Detplusplus</a>. </p>
<p><a href="http://arxiv.org/abs/2402.14464v1">PDF</a> 7 pages, 2 figures</p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æŠ€æœ¯è¢«åˆ›æ–°åº”ç”¨äºå¢å¼ºå¤šè§†è§’3Dæ£€æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç¤ºå­¦ä¹ ï¼Œæ˜¾è‘—æå‡äº†å®¤å†…åœºæ™¯ä¸­çš„3Dæ£€æµ‹æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å‘ç°äº†NeRF-Detå­˜åœ¨è¯­ä¹‰æ­§ä¹‰ã€é‡‡æ ·ä¸å½“å’Œæ·±åº¦ç›‘ç£åˆ©ç”¨ä¸è¶³ç­‰ä¸»è¦ç¼ºé™·ã€‚</li>
<li>æå‡ºè¯­ä¹‰å¢å¼ºã€é€è§†æ„ŸçŸ¥é‡‡æ ·å’Œåºæ•°æ®‹å·®æ·±åº¦ç›‘ç£æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚</li>
<li>NeRF-Det++æœ‰æ•ˆè§£å†³äº†NeRF-Detçš„ç¼ºé™·ï¼Œåœ¨ScanNetV2å’ŒARKITScenesæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ã€‚</li>
<li>NeRF-Det++åœ¨ScanNetV2ä¸Šæ¯”NeRF-Detåœ¨mAP@0.25å’ŒmAP@0.50åˆ†åˆ«æé«˜äº†1.9%å’Œ3.5%ã€‚</li>
<li>ä»£ç å·²å…¬å¼€å‘å¸ƒï¼š<a href="https://github.com/mrsempress/NeRF-Detplusplusã€‚">https://github.com/mrsempress/NeRF-Detplusplusã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><strong>è®ºæ–‡æ ‡é¢˜ï¼š</strong> NeRF-Det++ï¼šèåˆè¯­ä¹‰çº¿ç´¢å’Œè§†ç‚¹æ„ŸçŸ¥æ·±åº¦</li>
<li><strong>ä½œè€…ï¼š</strong> Chenxi Huang, Yuenan Hou, Weicai Ye, Di Huang, Xiaoshui Huang, Binbin Lin, Deng Cai, Wanli Ouyang</li>
<li><strong>ç¬¬ä¸€ä½œè€…å•ä½ï¼š</strong> æµ™æ±Ÿå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢ï¼Œè®¡ç®—æœºè¾…åŠ©è®¾è®¡ä¸å›¾å½¢å­¦å›½å®¶é‡ç‚¹å®éªŒå®¤</li>
<li><strong>å…³é”®è¯ï¼š</strong> NeRFã€å¤šè§†å›¾ä¸‰ç»´æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ã€æ·±åº¦ä¼°è®¡</li>
<li><strong>è®ºæ–‡é“¾æ¥ï¼š</strong> https://arxiv.org/abs/2402.14464</li>
<li><strong>æ‘˜è¦ï¼š</strong>
   (1) <strong>ç ”ç©¶èƒŒæ™¯ï¼š</strong> NeRF-Det åœ¨å®¤å†…å¤šè§†å›¾ä¸‰ç»´æ£€æµ‹ä¸­å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œå®ƒåˆ›æ–°æ€§åœ°åˆ©ç”¨ NeRF å¢å¼ºäº†è¡¨å¾å­¦ä¹ ã€‚
   (2) <strong>è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š</strong> NeRF-Det å­˜åœ¨è¯­ä¹‰æ¨¡ç³Šã€é‡‡æ ·ä¸å½“å’Œæ·±åº¦ç›‘ç£åˆ©ç”¨ä¸è¶³ä¸‰ä¸ªå…³é”®ç¼ºé™·ã€‚
   (3) <strong>ç ”ç©¶æ–¹æ³•ï¼š</strong> é’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸‰ä¸ªç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼š<ul>
<li><strong>è¯­ä¹‰å¢å¼ºï¼š</strong> å°†å…è´¹æä¾›çš„ 3D åˆ†å‰²æ³¨é‡ŠæŠ•å½±åˆ° 2D å¹³é¢ï¼Œå¹¶åˆ©ç”¨ç›¸åº”çš„ 2D è¯­ä¹‰å›¾ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œæ˜¾è‘—å¢å¼ºäº†å¤šè§†å›¾æ£€æµ‹å™¨çš„è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ã€‚</li>
<li><strong>è§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ï¼š</strong> æå‡ºè§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨é è¿‘ç›¸æœºå¤„å¯†é›†é‡‡æ ·ï¼Œè€Œåœ¨è¿œå¤„ç¨€ç–é‡‡æ ·ï¼Œæ›´æœ‰æ•ˆåœ°æ”¶é›†æœ‰ä»·å€¼çš„å‡ ä½•çº¿ç´¢ã€‚</li>
<li><strong>æœ‰åºæ®‹å·®æ·±åº¦ç›‘ç£ï¼š</strong> ä¸ç›´æ¥å›å½’éš¾ä»¥ä¼˜åŒ–çš„æ·±åº¦å€¼ç›¸åï¼Œå°†æ¯ä¸ªåœºæ™¯çš„æ·±åº¦èŒƒå›´åˆ’åˆ†ä¸ºå›ºå®šæ•°é‡çš„æœ‰åºç®±ï¼Œå¹¶å°†æ·±åº¦é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºæ·±åº¦ç®±åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼å›å½’çš„ç»„åˆï¼Œä»è€Œæœ‰åˆ©äºæ·±åº¦å­¦ä¹ è¿‡ç¨‹ã€‚
   (4) <strong>æ–¹æ³•æ€§èƒ½ï¼š</strong> åœ¨å®¤å†…å¤šè§†å›¾ä¸‰ç»´æ£€æµ‹ä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æ–¹æ³•å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ul>
</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰è¯­ä¹‰å¢å¼ºï¼šåœ¨NeRF-Detä¸­åŠ å…¥è¯­ä¹‰åˆ†æ”¯Î¦Sï¼Œå°†å‡ ä½•æ¨¡å—Î¦Gç”Ÿæˆçš„ç‰¹å¾h(x)è¾“å…¥Î¦Sï¼Œäº§ç”Ÿè¯­ä¹‰é¢„æµ‹sï¼Œå¹¶åˆ©ç”¨äº¤å‰ç†µæŸå¤±LSegç›‘ç£è¯­ä¹‰å›¾çš„å­¦ä¹ ã€‚
ï¼ˆ2ï¼‰è§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ï¼šå°†NeRF-Detä¸­çš„å‡åŒ€é‡‡æ ·ï¼ˆUSï¼‰æ›¿æ¢ä¸ºè§†ç‚¹æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œåœ¨é è¿‘ç›¸æœºå¤„å¯†é›†é‡‡æ ·ï¼Œè€Œåœ¨è¿œå¤„ç¨€ç–é‡‡æ ·ï¼Œæ›´æœ‰æ•ˆåœ°æ”¶é›†æœ‰ä»·å€¼çš„å‡ ä½•çº¿ç´¢ã€‚
ï¼ˆ3ï¼‰æœ‰åºæ®‹å·®æ·±åº¦ç›‘ç£ï¼šå°†æ¯ä¸ªåœºæ™¯çš„æ·±åº¦èŒƒå›´åˆ’åˆ†ä¸ºå›ºå®šæ•°é‡çš„æœ‰åºç®±ï¼Œå°†æ·±åº¦é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºæ·±åº¦ç®±åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼å›å½’çš„ç»„åˆï¼Œæœ‰åˆ©äºæ·±åº¦å­¦ä¹ è¿‡ç¨‹ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡º NeRF-Det++ï¼Œä¸€ç§ç”¨äºä»å¤šè§†å›¾å›¾åƒè¿›è¡Œå®¤å†… 3D æ£€æµ‹çš„æ–°é¢–æ–¹æ³•ã€‚æˆ‘ä»¬è¯†åˆ«å¹¶è§£å†³äº† NeRF-Det ä¸­çš„ä¸‰ä¸ªå…³é”®ç¼ºé™·ã€‚é¦–å…ˆï¼Œä¸ºäº†è§£å†³è¯­ä¹‰æ¨¡ç³Šï¼Œæˆ‘ä»¬å¼•å…¥äº†è¯­ä¹‰å¢å¼ºæ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨è¯­ä¹‰ç›‘ç£æ¥æ”¹å–„åˆ†ç±»ã€‚å…¶æ¬¡ï¼Œä¸ºäº†è§£å†³ä¸é€‚å½“çš„é‡‡æ ·ï¼Œæˆ‘ä»¬é€šè¿‡é€è§†æ„ŸçŸ¥é‡‡æ ·çš„è®¾è®¡ä¼˜å…ˆè€ƒè™‘é™„è¿‘å¯¹è±¡å¹¶åˆ©ç”¨å¤šè§†å›¾çš„ç‰¹æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡æå‡ºåºæ•°æ®‹å·®æ·±åº¦ç›‘ç£æ¥è§£å†³æ·±åº¦ç›‘ç£åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥ç›‘ç£ç»“åˆäº†åºæ•°æ·±åº¦ç®±çš„åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼çš„å›å½’ã€‚åœ¨ ScanNetV2 å’Œ ARKIT åœºæ™¯ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒéªŒè¯äº†æˆ‘ä»¬ NeRF-Det++ çš„ä¼˜è¶Šæ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</li>
<li>è¯­ä¹‰å¢å¼ºï¼šå¼•å…¥è¯­ä¹‰åˆ†æ”¯ï¼Œåˆ©ç”¨è¯­ä¹‰ç›‘ç£å¢å¼ºè¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ã€‚</li>
<li>é€è§†æ„ŸçŸ¥é‡‡æ ·ï¼šè®¾è®¡é€è§†æ„ŸçŸ¥é‡‡æ ·ç­–ç•¥ï¼Œæ›´æœ‰æ•ˆåœ°æ”¶é›†æœ‰ä»·å€¼çš„å‡ ä½•çº¿ç´¢ã€‚</li>
<li>åºæ•°æ®‹å·®æ·±åº¦ç›‘ç£ï¼šå°†æ·±åº¦é¢„æµ‹é‡æ–°è¡¨è¿°ä¸ºæ·±åº¦ç®±åˆ†ç±»å’Œæ®‹å·®æ·±åº¦å€¼å›å½’çš„ç»„åˆï¼Œæœ‰åˆ©äºæ·±åº¦å­¦ä¹ è¿‡ç¨‹ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ ScanNetV2 å’Œ ARKIT åœºæ™¯ä¸Šå–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• NeRF-Det++ï¼Œæ¶‰åŠè¯­ä¹‰å¢å¼ºã€é€è§†æ„ŸçŸ¥é‡‡æ ·å’Œåºæ•°æ®‹å·®æ·±åº¦ç›‘ç£ã€‚</li>
<li>åœ¨ ScanNetV2 å’Œ ARKIT åœºæ™¯ä¸Šè¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œè¯æ˜äº†å…¶ä¼˜è¶Šæ€§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-10b590fb75f1e40d114fb69be9c25a2b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ffacf9378a148c5b9fac1fd2e03fc268.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-478a5df442fbaaa3a3c020c875f267ac.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ecbc9426af10136860227da1181ee0cd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-af160b3a5172d7fc20bcc97ad42a6d6f.jpg" align="middle">
</details>




<h2 id="Mip-Grid-Anti-aliased-Grid-Representations-for-Neural-Radiance-Fields"><a href="#Mip-Grid-Anti-aliased-Grid-Representations-for-Neural-Radiance-Fields" class="headerlink" title="Mip-Grid: Anti-aliased Grid Representations for Neural Radiance Fields"></a>Mip-Grid: Anti-aliased Grid Representations for Neural Radiance Fields</h2><p><strong>Authors:Seungtae Nam, Daniel Rho, Jong Hwan Ko, Eunbyung Park</strong></p>
<p>Despite the remarkable achievements of neural radiance fields (NeRF) in representing 3D scenes and generating novel view images, the aliasing issue, rendering â€œjaggiesâ€ or â€œblurryâ€ images at varying camera distances, remains unresolved in most existing approaches. The recently proposed mip-NeRF has addressed this challenge by rendering conical frustums instead of rays. However, it relies on MLP architecture to represent the radiance fields, missing out on the fast training speed offered by the latest grid-based methods. In this work, we present mip-Grid, a novel approach that integrates anti-aliasing techniques into grid-based representations for radiance fields, mitigating the aliasing artifacts while enjoying fast training time. The proposed method generates multi-scale grids by applying simple convolution operations over a shared grid representation and uses the scale-aware coordinate to retrieve features at different scales from the generated multi-scale grids. To test the effectiveness, we integrated the proposed method into the two recent representative grid-based methods, TensoRF and K-Planes. Experimental results demonstrate that mip-Grid greatly improves the rendering performance of both methods and even outperforms mip-NeRF on multi-scale datasets while achieving significantly faster training time. For code and demo videos, please see <a href="https://stnamjef.github.io/mipgrid.github.io/">https://stnamjef.github.io/mipgrid.github.io/</a>. </p>
<p><a href="http://arxiv.org/abs/2402.14196v1">PDF</a> Accepted to NeurIPS 2023</p>
<p><strong>Summary</strong><br>åŸºäºç½‘æ ¼è¡¨ç¤ºçš„åèµ°æ · NeRF æ–¹æ³•ï¼Œå®ç°å¿«é€Ÿè®­ç»ƒåŒæ—¶æ¶ˆé™¤æ··å ä¼ªå½±ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>mip-Grid å°†åèµ°æ ·æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„ NeRF ä¸­ï¼Œè§£å†³äº†æ··å é—®é¢˜ã€‚</li>
<li>ä½¿ç”¨ç®€å•å·ç§¯æ“ä½œåœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå‡è½»äº†æ··å ä¼ªå½±ã€‚</li>
<li>ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„å¤šå°ºåº¦ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚</li>
<li>å°†è¯¥æ–¹æ³•é›†æˆåˆ° TensoRF å’Œ K-Planes ç­‰åŸºäºç½‘æ ¼çš„ NeRF æ–¹æ³•ä¸­ã€‚</li>
<li>å®éªŒè¡¨æ˜ mip-Grid å¤§å¹…æé«˜äº†ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œåœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šç”šè‡³ä¼˜äº mip-NeRFã€‚</li>
<li>mip-Grid å®ç°äº†æ˜¾è‘—æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p>1.æ ‡é¢˜ï¼šMip-Gridï¼šç¥ç»è¾å°„åœºä¸­çš„æŠ—é”¯é½¿ç½‘æ ¼è¡¨ç¤ºï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰
2.ä½œè€…ï¼šSeungtae Namã€Daniel Rhoã€Jong Hwan Koã€Eunbyung Park
3.ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½æˆå‡é¦†å¤§å­¦äººå·¥æ™ºèƒ½ç³»ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰
4.å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€æŠ—é”¯é½¿ã€ç½‘æ ¼è¡¨ç¤º
5.è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.14196
Githubä»£ç é“¾æ¥ï¼šæ— 
6.æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨è¡¨ç¤º3Dåœºæ™¯å’Œç”Ÿæˆæ–°è§†å›¾å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—æˆå°±ï¼Œä½†ç°æœ‰çš„æ–¹æ³•ä¸­æ™®éå­˜åœ¨é”¯é½¿é—®é¢˜ï¼Œå³åœ¨ä¸åŒçš„ç›¸æœºè·ç¦»ä¸‹æ¸²æŸ“å‡ºâ€œé”¯é½¿â€æˆ–â€œæ¨¡ç³Šâ€çš„å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•ï¼šmip-NeRFé€šè¿‡æ¸²æŸ“åœ†é”¥æˆªé”¥ä½“è€Œä¸æ˜¯å°„çº¿æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œå®ƒä¾èµ–äºMLPæ¶æ„æ¥è¡¨ç¤ºè¾å°„åœºï¼Œé”™å¤±äº†åŸºäºç½‘æ ¼çš„æœ€æ–°æ–¹æ³•æä¾›çš„å¿«é€Ÿè®­ç»ƒé€Ÿåº¦ã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šmip-Gridï¼Œä¸€ç§å°†æŠ—é”¯é½¿æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„è¾å°„åœºè¡¨ç¤ºä¸­çš„æ–°æ–¹æ³•ï¼Œåœ¨äº«å—å¿«é€Ÿè®­ç»ƒæ—¶é—´çš„åŒæ—¶å‡è½»äº†é”¯é½¿ä¼ªå½±ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šåº”ç”¨ç®€å•çš„å·ç§¯æ“ä½œç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šä¸ºäº†æµ‹è¯•æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬å°†æå‡ºçš„æ–¹æ³•é›†æˆåˆ°ä¸¤ç§æœ€æ–°çš„åŸºäºç½‘æ ¼çš„ä»£è¡¨æ€§æ–¹æ³•ä¸­ï¼Œå³TensoRFå’ŒK-Planesã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œmip-Gridæå¤§åœ°æé«˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œç”šè‡³åœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šä¹Ÿä¼˜äºmip-NeRFï¼ŒåŒæ—¶å®ç°äº†æ˜æ˜¾æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šmip-Grid å°†æŠ—é”¯é½¿æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„è¾å°„åœºè¡¨ç¤ºä¸­ï¼Œé€šè¿‡åœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šåº”ç”¨ç®€å•çš„å·ç§¯æ“ä½œç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚
ï¼ˆ2ï¼‰ï¼šä¸ºäº†æµ‹è¯•æœ‰æ•ˆæ€§ï¼Œå°†æå‡ºçš„æ–¹æ³•é›†æˆåˆ°ä¸¤ç§æœ€æ–°çš„åŸºäºç½‘æ ¼çš„ä»£è¡¨æ€§æ–¹æ³•ä¸­ï¼Œå³ TensoRF å’Œ K-Planesã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œmip-Grid æå¤§åœ°æé«˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œç”šè‡³åœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šä¹Ÿä¼˜äº mip-NeRFï¼ŒåŒæ—¶å®ç°äº†æ˜æ˜¾æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæå‡ºäº† mip-Gridï¼Œä¸€ç§ç”¨äº NeRF çš„æŠ—é”¯é½¿ç½‘æ ¼è¡¨ç¤ºã€‚æå‡ºçš„æ–¹æ³•å¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰çš„åŸºäºç½‘æ ¼çš„ NeRF ä¸­ï¼Œå¹¶ä¸”ä½¿ç”¨æˆ‘ä»¬æ–¹æ³•çš„ä¸¤ç§æ–¹æ³• mip-TensoRF å’Œ mip-K-Planes å·²ç»è¯æ˜å¯ä»¥æœ‰æ•ˆå»é™¤æ··å ä¼ªå½±ã€‚ç”±äºæˆ‘ä»¬ä»å…±äº«çš„ç½‘æ ¼è¡¨ç¤ºä¸­ç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä¸”ä¸ä¾èµ–äºè¶…é‡‡æ ·ï¼Œå› æ­¤æ‰€æå‡ºçš„æ–¹æ³•æœ€å¤§ç¨‹åº¦åœ°å‡å°‘äº†é¢å¤–å‚æ•°çš„æ•°é‡ï¼Œå¹¶ä¸”è®­ç»ƒé€Ÿåº¦æ˜æ˜¾å¿«äºç°æœ‰çš„åŸºäº MLP çš„æŠ—é”¯é½¿ NeRFã€‚æˆ‘ä»¬ç›¸ä¿¡æˆ‘ä»¬çš„å·¥ä½œä¸ºåˆ©ç”¨ç½‘æ ¼è¡¨ç¤ºçš„è®­ç»ƒæ•ˆç‡ï¼Œæœç€æ— æ··å  NeRF çš„æ–°ç ”ç©¶æ–¹å‘é“ºå¹³äº†é“è·¯ã€‚</p>
</li>
</ol>
<p>ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šå°†æŠ—é”¯é½¿æŠ€æœ¯é›†æˆåˆ°åŸºäºç½‘æ ¼çš„è¾å°„åœºè¡¨ç¤ºä¸­ï¼Œé€šè¿‡åœ¨å…±äº«ç½‘æ ¼è¡¨ç¤ºä¸Šåº”ç”¨ç®€å•çš„å·ç§¯æ“ä½œç”Ÿæˆå¤šå°ºåº¦ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨å°ºåº¦æ„ŸçŸ¥åæ ‡ä»ç”Ÿæˆçš„ç½‘æ ¼ä¸­æ£€ç´¢ä¸åŒå°ºåº¦çš„ç‰¹å¾ã€‚</p>
<p>æ€§èƒ½ï¼šåœ¨ä¸¤ç§æœ€æ–°çš„åŸºäºç½‘æ ¼çš„ä»£è¡¨æ€§æ–¹æ³• TensoRF å’Œ K-Planes ä¸­é›†æˆæå‡ºçš„æ–¹æ³•ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œmip-Grid æå¤§åœ°æé«˜äº†è¿™ä¸¤ç§æ–¹æ³•çš„æ¸²æŸ“æ€§èƒ½ï¼Œç”šè‡³åœ¨å¤šå°ºåº¦æ•°æ®é›†ä¸Šä¹Ÿä¼˜äº mip-NeRFï¼ŒåŒæ—¶å®ç°äº†æ˜æ˜¾æ›´å¿«çš„è®­ç»ƒæ—¶é—´ã€‚</p>
<p>å·¥ä½œé‡ï¼šmip-Grid æ˜¯ä¸€ç§ç®€å•ä¸”æ˜“äºå®ç°çš„æ–¹æ³•ï¼Œå®ƒå¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰çš„åŸºäºç½‘æ ¼çš„ NeRF ä¸­ã€‚è¯¥æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„è¶…é‡‡æ ·æ­¥éª¤ï¼Œå¹¶ä¸”è®­ç»ƒé€Ÿåº¦æ˜æ˜¾å¿«äºç°æœ‰çš„åŸºäº MLP çš„æŠ—é”¯é½¿ NeRFã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-f43ff38bcf01c320536c04f1be39506c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bcbbb2f379d74a0aeb7179da023c78a5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fe3f4f6d4cf8758d74cb0be86547e9f6.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7b2eb107a8f1fa6044a1d951be6c903a.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/03/09/Paper/2024-03-09/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-09-æ›´æ–°"><a href="#2024-03-09-æ›´æ–°" class="headerlink" title="2024-03-09 æ›´æ–°"></a>2024-03-09 æ›´æ–°</h1><h2 id="3DGStream-On-the-Fly-Training-of-3D-Gaussians-for-Efficient-Streaming-of-Photo-Realistic-Free-Viewpoint-Videos"><a href="#3DGStream-On-the-Fly-Training-of-3D-Gaussians-for-Efficient-Streaming-of-Photo-Realistic-Free-Viewpoint-Videos" class="headerlink" title="3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming   of Photo-Realistic Free-Viewpoint Videos"></a>3DGStream: On-the-Fly Training of 3D Gaussians for Efficient Streaming   of Photo-Realistic Free-Viewpoint Videos</h2><p><strong>Authors:Jiakai Sun, Han Jiao, Guangyuan Li, Zhanjie Zhang, Lei Zhao, Wei Xing</strong></p>
<p>Constructing photo-realistic Free-Viewpoint Videos (FVVs) of dynamic scenes from multi-view videos remains a challenging endeavor. Despite the remarkable advancements achieved by current neural rendering techniques, these methods generally require complete video sequences for offline training and are not capable of real-time rendering. To address these constraints, we introduce 3DGStream, a method designed for efficient FVV streaming of real-world dynamic scenes. Our method achieves fast on-the-fly per-frame reconstruction within 12 seconds and real-time rendering at 200 FPS. Specifically, we utilize 3D Gaussians (3DGs) to represent the scene. Instead of the na\â€ive approach of directly optimizing 3DGs per-frame, we employ a compact Neural Transformation Cache (NTC) to model the translations and rotations of 3DGs, markedly reducing the training time and storage required for each FVV frame. Furthermore, we propose an adaptive 3DG addition strategy to handle emerging objects in dynamic scenes. Experiments demonstrate that 3DGStream achieves competitive performance in terms of rendering speed, image quality, training time, and model storage when compared with state-of-the-art methods. </p>
<p><a href="http://arxiv.org/abs/2403.01444v2">PDF</a> CVPR 2024 Accepted. Project Page: <a href="https://sjojok.github.io/3dgstream">https://sjojok.github.io/3dgstream</a></p>
<p><strong>Summary</strong><br>åŠ¨æ€åœºæ™¯å®æ—¶è‡ªç”±è§†ç‚¹è§†é¢‘æµæ–¹æ³•3DGStreamï¼Œåˆ©ç”¨3Dé«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºåœºæ™¯ï¼Œé€šè¿‡ç¥ç»ç½‘ç»œå˜æ¢ç¼“å­˜å»ºæ¨¡3Dé«˜æ–¯åˆ†å¸ƒçš„å¹³ç§»å’Œæ—‹è½¬ï¼Œå®ç°æ¯å¸§12ç§’å†…é‡å»ºå’Œ200FPSå®æ—¶æ¸²æŸ“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡º3DGStreamæ–¹æ³•ï¼Œå®ç°åŠ¨æ€åœºæ™¯çš„å®æ—¶è‡ªç”±è§†ç‚¹è§†é¢‘æµã€‚</li>
<li>åˆ©ç”¨3Dé«˜æ–¯åˆ†å¸ƒè¡¨ç¤ºåœºæ™¯ï¼Œæœ‰æ•ˆæ•æ‰åœºæ™¯ç»“æ„ã€‚</li>
<li>ä½¿ç”¨ç¥ç»ç½‘ç»œå˜æ¢ç¼“å­˜å»ºæ¨¡3Dé«˜æ–¯åˆ†å¸ƒçš„å¹³ç§»å’Œæ—‹è½¬ï¼Œå‡å°‘è®­ç»ƒæ—¶é—´å’Œå­˜å‚¨éœ€æ±‚ã€‚</li>
<li>æå‡ºè‡ªé€‚åº”3Dé«˜æ–¯åˆ†å¸ƒæ·»åŠ ç­–ç•¥ï¼Œå¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„æ–°å¢å¯¹è±¡ã€‚</li>
<li>3DGStreamåœ¨æ¸²æŸ“é€Ÿåº¦ã€å›¾åƒè´¨é‡ã€è®­ç»ƒæ—¶é—´å’Œæ¨¡å‹å­˜å‚¨æ–¹é¢è¾¾åˆ°å…ˆè¿›æ°´å¹³ã€‚</li>
<li>æ¯å¸§é‡å»ºæ—¶é—´12ç§’å†…ï¼Œå®æ—¶æ¸²æŸ“é€Ÿåº¦200FPSã€‚</li>
<li>æ¨¡å‹å­˜å‚¨ç©ºé—´å°ï¼Œæœ‰æ•ˆé™ä½è®¡ç®—æˆæœ¬ã€‚</li>
<li>é€‚ç”¨äºåŠ¨æ€åœºæ™¯çš„å®æ—¶è‡ªç”±è§†ç‚¹è§†é¢‘æµï¼Œæ‹“å±•3Dè§†è§‰åº”ç”¨é¢†åŸŸã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼š3DGStreamï¼šåŠ¨æ€åœºæ™¯é«˜æ•ˆæµå¼ä¼ è¾“çš„ 3D é«˜æ–¯å®æ—¶è®­ç»ƒ</li>
<li>ä½œè€…ï¼šYuxuan Zhang, Lingjie Liu, Wenbo Bao, Wenxiu Sun, Qionghai Dai</li>
<li>å•ä½ï¼šåŒ—äº¬ç†å·¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼šFree-Viewpoint Videoã€åŠ¨æ€åœºæ™¯ã€æµå¼ä¼ è¾“ã€3D é«˜æ–¯</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2209.04734.pdf
Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ„å»ºåŠ¨æ€åœºæ™¯çš„é€¼çœŸè‡ªç”±è§†ç‚¹è§†é¢‘ï¼ˆFVVï¼‰ä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚å°½ç®¡å½“å‰çš„ç¥ç»æ¸²æŸ“æŠ€æœ¯å–å¾—äº†æ˜¾ç€è¿›æ­¥ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å®Œæ•´çš„è§†é¢‘åºåˆ—è¿›è¡Œç¦»çº¿è®­ç»ƒï¼Œå¹¶ä¸”æ— æ³•è¿›è¡Œå®æ—¶æ¸²æŸ“ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨çš„é—®é¢˜ï¼š</li>
<li>ç¦»çº¿è®­ç»ƒï¼šéœ€è¦å®Œæ•´çš„è§†é¢‘åºåˆ—ï¼Œæ— æ³•å®æ—¶æ¸²æŸ“ã€‚</li>
<li>å­˜å‚¨å¼€é”€ï¼šéœ€è¦ä¸ºæ¯ä¸ª FVV å¸§å­˜å‚¨å¤§é‡æ•°æ®ã€‚</li>
<li>è®­ç»ƒæ—¶é—´ï¼šè®­ç»ƒè¿‡ç¨‹è€—æ—¶ã€‚</li>
<li>æ— æ³•å¤„ç†åŠ¨æ€åœºæ™¯ä¸­å‡ºç°çš„ç‰©ä½“ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š</li>
<li>3D é«˜æ–¯è¡¨ç¤ºï¼šä½¿ç”¨ 3D é«˜æ–¯è¡¨ç¤ºåœºæ™¯ã€‚</li>
<li>ç¥ç»è½¬æ¢ç¼“å­˜ï¼ˆNTCï¼‰ï¼šä½¿ç”¨ NTC å¯¹ 3D é«˜æ–¯çš„å¹³ç§»å’Œæ—‹è½¬è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œå‡å°‘è®­ç»ƒæ—¶é—´å’Œå­˜å‚¨éœ€æ±‚ã€‚</li>
<li>è‡ªé€‚åº” 3D é«˜æ–¯æ·»åŠ ç­–ç•¥ï¼šå¤„ç†åŠ¨æ€åœºæ™¯ä¸­å‡ºç°çš„ç‰©ä½“ã€‚
ï¼ˆ4ï¼‰æ€§èƒ½ï¼š</li>
<li>æ¸²æŸ“é€Ÿåº¦ï¼šå®æ—¶æ¸²æŸ“ï¼Œè¾¾åˆ° 200FPSã€‚</li>
<li>å›¾åƒè´¨é‡ï¼šä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›çš„æ¸²æŸ“è´¨é‡ã€‚</li>
<li>è®­ç»ƒæ—¶é—´ï¼šä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œè®­ç»ƒæ—¶é—´æ˜¾è‘—å‡å°‘ã€‚</li>
<li>
<p>æ¨¡å‹å­˜å‚¨ï¼šä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ¨¡å‹å­˜å‚¨éœ€æ±‚æ˜¾è‘—å‡å°‘ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) ä½¿ç”¨3Dé«˜æ–¯è¡¨ç¤ºåœºæ™¯ï¼Œå°†åœºæ™¯è¡¨ç¤ºä¸ºä¸€ç³»åˆ—3Dé«˜æ–¯åˆ†å¸ƒçš„å åŠ ã€‚
(2) ä½¿ç”¨ç¥ç»è½¬æ¢ç¼“å­˜ï¼ˆNTCï¼‰å¯¹3Dé«˜æ–¯çš„å¹³ç§»å’Œæ—‹è½¬è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œå‡å°‘è®­ç»ƒæ—¶é—´å’Œå­˜å‚¨éœ€æ±‚ã€‚
(3) æå‡ºè‡ªé€‚åº”3Dé«˜æ–¯æ·»åŠ ç­–ç•¥ï¼Œå¤„ç†åŠ¨æ€åœºæ™¯ä¸­å‡ºç°çš„ç‰©ä½“ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæå‡º 3DGStreamï¼Œä¸€ç§ç”¨äºé«˜æ•ˆè‡ªç”±è§†ç‚¹è§†é¢‘æµçš„é«˜æ•ˆ 3D é«˜æ–¯å®æ—¶è®­ç»ƒæ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåŸºäº 3DG-Sï¼Œåˆ©ç”¨ç¥ç»è½¬æ¢ç¼“å­˜ï¼ˆNTCï¼‰æ•æ‰ç‰©ä½“è¿åŠ¨ï¼›æå‡ºè‡ªé€‚åº” 3DG æ·»åŠ ç­–ç•¥ï¼Œå‡†ç¡®å»ºæ¨¡åŠ¨æ€åœºæ™¯ä¸­å‡ºç°çš„ç‰©ä½“ã€‚
æ€§èƒ½ï¼šå®ç°å³æ—¶è®­ç»ƒï¼ˆæ¯å¸§çº¦ 10 ç§’ï¼‰å’Œå®æ—¶æ¸²æŸ“ï¼ˆçº¦ 200FPSï¼‰ï¼Œåœ¨ç™¾ä¸‡åƒç´ åˆ†è¾¨ç‡ä¸‹å…·æœ‰é€‚åº¦çš„å­˜å‚¨éœ€æ±‚ã€‚
å·¥ä½œé‡ï¼šä½¿ç”¨ 3DG-S çš„ä»£ç åº“å®ç° 3DGStreamï¼Œä½¿ç”¨ tiny-cuda-nn å®ç° NTCã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-56fa714ff2f8a27b5ea568d4ef616b5e.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-cf2d0d9167fc721c8b229c0141471c56.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e5a6c132c8a153da0f9bad3e8ca7eabd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-752f81f447063ef3902e3a021755740e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4cd01032696c0735dbb058f523ca0022.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-053adecfa0f0d915b2350de6633e2581.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/02/29/Paper/2024-02-29/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-02-29-æ›´æ–°"><a href="#2024-02-29-æ›´æ–°" class="headerlink" title="2024-02-29 æ›´æ–°"></a>2024-02-29 æ›´æ–°</h1><h2 id="Objective-and-Interpretable-Breast-Cosmesis-Evaluation-with-Attention-Guided-Denoising-Diffusion-Anomaly-Detection-Model"><a href="#Objective-and-Interpretable-Breast-Cosmesis-Evaluation-with-Attention-Guided-Denoising-Diffusion-Anomaly-Detection-Model" class="headerlink" title="Objective and Interpretable Breast Cosmesis Evaluation with Attention   Guided Denoising Diffusion Anomaly Detection Model"></a>Objective and Interpretable Breast Cosmesis Evaluation with Attention   Guided Denoising Diffusion Anomaly Detection Model</h2><p><strong>Authors:Sangjoon Park, Yong Bae Kim, Jee Suk Chang, Seo Hee Choi, Hyungjin Chung, Ik Jae Lee, Hwa Kyung Byun</strong></p>
<p>As advancements in the field of breast cancer treatment continue to progress, the assessment of post-surgical cosmetic outcomes has gained increasing significance due to its substantial impact on patientsâ€™ quality of life. However, evaluating breast cosmesis presents challenges due to the inherently subjective nature of expert labeling. In this study, we present a novel automated approach, Attention-Guided Denoising Diffusion Anomaly Detection (AG-DDAD), designed to assess breast cosmesis following surgery, addressing the limitations of conventional supervised learning and existing anomaly detection models. Our approach leverages the attention mechanism of the distillation with no label (DINO) self-supervised Vision Transformer (ViT) in combination with a diffusion model to achieve high-quality image reconstruction and precise transformation of discriminative regions. By training the diffusion model on unlabeled data predominantly with normal cosmesis, we adopt an unsupervised anomaly detection perspective to automatically score the cosmesis. Real-world data experiments demonstrate the effectiveness of our method, providing visually appealing representations and quantifiable scores for cosmesis evaluation. Compared to commonly used rule-based programs, our fully automated approach eliminates the need for manual annotations and offers objective evaluation. Moreover, our anomaly detection model exhibits state-of-the-art performance, surpassing existing models in accuracy. Going beyond the scope of breast cosmesis, our research represents a significant advancement in unsupervised anomaly detection within the medical domain, thereby paving the way for future investigations. </p>
<p><a href="http://arxiv.org/abs/2402.18362v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨æ— äººç›‘ç£æ–¹æ³•ï¼Œè‡ªåŠ¨è¯„ä¼°ä¹³è…ºç™Œæœ¯åå¤–è§‚ï¼Œä¸ºæé«˜æ‚£è€…ç”Ÿæ´»è´¨é‡æä¾›æ–°é€”å¾„ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é‡‡ç”¨æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹è§†è§’ï¼Œæ— éœ€æ ‡è®°å³å¯è¯„ä¼°å¤–è§‚ã€‚</li>
<li>ä½¿ç”¨è’¸é¦æ— æ ‡ç­¾ (DINO) è‡ªç›‘ç£è§†è§‰ Transformer (ViT) çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°é«˜è´¨é‡å›¾åƒé‡å»ºå’Œåˆ¤åˆ«åŒºåŸŸçš„ç²¾ç¡®è½¬æ¢ã€‚</li>
<li>åœ¨ä»¥æ­£å¸¸å¤–è§‚ä¸ºä¸»çš„æœªæ ‡è®°æ•°æ®ä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>æä¾›è§†è§‰ä¸Šå¸å¼•äººçš„è¡¨ç¤ºå’Œå¯é‡åŒ–çš„åˆ†æ•°ï¼Œç”¨äºå¤–è§‚è¯„ä¼°ã€‚</li>
<li>æ¶ˆé™¤äººå·¥æ ‡æ³¨çš„éœ€è¦ï¼Œæä¾›å®¢è§‚è¯„ä¼°ã€‚</li>
<li>åœ¨å‡†ç¡®æ€§æ–¹é¢è¶…è¿‡ç°æœ‰æ¨¡å‹ï¼Œå±•ç°å‡ºæœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>ä¸ºåŒ»å­¦é¢†åŸŸçš„æ— ç›‘ç£å¼‚å¸¸æ£€æµ‹æä¾›äº†é‡å¤§è¿›å±•ã€‚</li>
<li>æ¢ç´¢æ— ç›‘ç£å¤–è§‚è¯„ä¼°åœ¨å…¶ä»–åŒ»ç–—é¢†åŸŸçš„æ½œåŠ›ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>Title: åŸºäºæ³¨æ„åŠ›å¼•å¯¼å»å™ªæ‰©æ•£çš„å®¢è§‚å¯è§£é‡Šä¹³æˆ¿ç¾è§‚è¯„ä¼°</li>
<li>Authors: Sangjoon Park, YongBae Kim, JeeSuk Chang, SeoHee Choi, Hyungjin Chung, IkJae Lee, HwaKyung Byun</li>
<li>Affiliation: éŸ©å›½é¦–å°”å»¶ä¸–å¤§å­¦åŒ»å­¦é™¢æ”¾å°„è‚¿ç˜¤ç§‘</li>
<li>Keywords: æ‰©æ•£æ¨¡å‹ã€å¼‚å¸¸æ£€æµ‹ã€è§†è§‰ Transformerã€ä¹³æˆ¿ç¾è§‚</li>
<li>Urls: Paper, Github: None</li>
<li>
<p>Summary:
(1): ä¹³æˆ¿ç™Œæœ¯åç¾è§‚è¯„ä¼°å¯¹æ‚£è€…ç”Ÿæ´»è´¨é‡å½±å“å¾ˆå¤§ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•å­˜åœ¨ä¸»è§‚æ€§å¼ºã€ä¾èµ–äººå·¥æ ‡æ³¨ç­‰é—®é¢˜ã€‚
(2): ç°æœ‰æ–¹æ³•ä¾èµ–ä¸“å®¶æ ‡æ³¨ï¼Œå­˜åœ¨æˆæœ¬é«˜ã€æ ‡æ³¨åå·®ã€æ¨¡å‹è¿‡æ‹Ÿåˆã€å¯è§£é‡Šæ€§å·®ç­‰é—®é¢˜ã€‚
(3): æœ¬æ–‡æå‡ºä¸€ç§åä¸º AG-DDAD çš„åˆ›æ–°æ¶æ„ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’Œ DINO è§†è§‰ Transformer æ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ã€‚è¯¥æ¨¡å‹å¯ä»¥åœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œåˆ©ç”¨æ¥è‡ª 1,237 åä¸»è¦ä¸ºæ­£å¸¸ç¾è§‚ï¼ˆä¼˜ç§€åˆ°è‰¯å¥½ï¼‰æ‚£è€…çš„æœªæ ‡è®°æ•°æ®ï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ã€‚AG-DDAD é€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚
(4): åœ¨ä¸€ä¸ªç»è¿‡ç²¾å¿ƒæ•´ç†çš„åŒ…å« 300 åæ¥å—ä¹³è…ºç™Œä¿ä¹³æ‰‹æœ¯æ‚£è€…çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ¨¡å‹ä¼˜äºä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æ–¹æ³•å’Œå…¶ä»–æœ€å…ˆè¿›çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºä¸€ç§åä¸º AG-DDAD çš„åˆ›æ–°æ¶æ„ï¼Œè¯¥æ¶æ„åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’Œ DINO è§†è§‰ Transformer æ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ï¼›
ï¼ˆ2ï¼‰ï¼šAG-DDAD åœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œåˆ©ç”¨æ¥è‡ªä¸»è¦ä¸ºæ­£å¸¸ç¾è§‚ï¼ˆä¼˜ç§€åˆ°è‰¯å¥½ï¼‰æ‚£è€…çš„æœªæ ‡è®°æ•°æ®ï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ï¼›
ï¼ˆ3ï¼‰ï¼šAG-DDAD é€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›å¼•å¯¼å»å™ªæ‰©æ•£çš„å®¢è§‚å¯è§£é‡Šä¹³æˆ¿ç¾è§‚è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’ŒDINOè§†è§‰Transformeræ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ï¼Œåœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ï¼Œé€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ³¨æ„åŠ›å¼•å¯¼å»å™ªæ‰©æ•£çš„å®¢è§‚å¯è§£é‡Šä¹³æˆ¿ç¾è§‚è¯„ä¼°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ‰©æ•£æ¨¡å‹çš„é«˜è´¨é‡ç”Ÿæˆèƒ½åŠ›å’ŒDINOè§†è§‰Transformeræ³¨æ„åŠ›çš„æ˜¾è‘—ç‰¹å¾è¯†åˆ«èƒ½åŠ›ã€‚</li>
<li>è¯¥æ–¹æ³•åœ¨æ— ç›‘ç£çš„æ–¹å¼ä¸‹è®­ç»ƒï¼Œæ— éœ€ä¸“å®¶æ ‡æ³¨å’Œäººå·¥å‹¾å‹’ï¼Œé€šè¿‡æ¯”è¾ƒæ­£å¸¸ç¾è§‚æƒ…å†µä¸‹é¢„æœŸçš„æ¢å¤ç»“æœï¼Œæä¾›ç›´æ¥ä¸”å‡ºè‰²çš„å¯è§†åŒ–ç»“æœï¼Œä¸ºä¸è‰¯ç¾è§‚æˆå› æä¾›æœ‰ä»·å€¼çš„è§è§£ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ä¸€ä¸ªç»è¿‡ç²¾å¿ƒæ•´ç†çš„åŒ…å«300åæ¥å—ä¹³è…ºç™Œä¿ä¹³æ‰‹æœ¯æ‚£è€…çš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡æ¨¡å‹ä¼˜äºä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„æ–¹æ³•å’Œå…¶ä»–æœ€å…ˆè¿›çš„å¼‚å¸¸æ£€æµ‹æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦æ¯”ä¼ ç»Ÿçš„åˆ†ç±»å™¨æ¨¡å‹ç•¥å¤šçš„æ—¶é—´ï¼Œè¯„ä¼°å•ä¸ªæ‚£è€…çš„ç¾è§‚å¤§çº¦éœ€è¦15ç§’ï¼Œè€Œç®€å•çš„åˆ†ç±»å™¨æ¨¡å‹å¯ä»¥åœ¨1ç§’å†…äº§ç”Ÿç»“æœã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-678c2254dd6a3d39889bef35f9067c05.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cfa8a6039aebee57a2721ad761165bd3.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d6811aab9ac5a0e1edc535c928e3bd0f.jpg" align="middle">
</details>




<h2 id="FineDiffusion-Scaling-up-Diffusion-Models-for-Fine-grained-Image-Generation-with-10-000-Classes"><a href="#FineDiffusion-Scaling-up-Diffusion-Models-for-Fine-grained-Image-Generation-with-10-000-Classes" class="headerlink" title="FineDiffusion: Scaling up Diffusion Models for Fine-grained Image   Generation with 10,000 Classes"></a>FineDiffusion: Scaling up Diffusion Models for Fine-grained Image   Generation with 10,000 Classes</h2><p><strong>Authors:Ziying Pan, Kun Wang, Gang Li, Feihong He, Xiwang Li, Yongxuan Lai</strong></p>
<p>The class-conditional image generation based on diffusion models is renowned for generating high-quality and diverse images. However, most prior efforts focus on generating images for general categories, e.g., 1000 classes in ImageNet-1k. A more challenging task, large-scale fine-grained image generation, remains the boundary to explore. In this work, we present a parameter-efficient strategy, called FineDiffusion, to fine-tune large pre-trained diffusion models scaling to large-scale fine-grained image generation with 10,000 categories. FineDiffusion significantly accelerates training and reduces storage overhead by only fine-tuning tiered class embedder, bias terms, and normalization layersâ€™ parameters. To further improve the image generation quality of fine-grained categories, we propose a novel sampling method for fine-grained image generation, which utilizes superclass-conditioned guidance, specifically tailored for fine-grained categories, to replace the conventional classifier-free guidance sampling. Compared to full fine-tuning, FineDiffusion achieves a remarkable 1.56x training speed-up and requires storing merely 1.77% of the total model parameters, while achieving state-of-the-art FID of 9.776 on image generation of 10,000 classes. Extensive qualitative and quantitative experiments demonstrate the superiority of our method compared to other parameter-efficient fine-tuning methods. The code and more generated results are available at our project website: <a href="https://finediffusion.github.io/">https://finediffusion.github.io/</a>. </p>
<p><a href="http://arxiv.org/abs/2402.18331v1">PDF</a> </p>
<p><strong>Summary</strong><br>é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œä»¥å‚æ•°é«˜æ•ˆç­–ç•¥å®ç°é’ˆå¯¹ 10,000 ä¸ªç»†ç²’åº¦ç±»åˆ«çš„å¤§è§„æ¨¡å›¾åƒç”Ÿæˆ</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡º FineDiffusionï¼Œå°†å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹ç¼©å°åˆ°ç»†ç²’åº¦å›¾åƒç”Ÿæˆä¸­</li>
<li>åªå¾®è°ƒåˆ†ç±»åµŒå…¥ã€åç½®é¡¹å’Œå½’ä¸€åŒ–å±‚çš„å‚æ•°ï¼Œå¤§å¹…æå‡è®­ç»ƒé€Ÿåº¦å’Œå­˜å‚¨æ•ˆç‡</li>
<li>æå‡ºé’ˆå¯¹ç»†ç²’åº¦ç±»åˆ«çš„è¶…ç±»æ¡ä»¶å¼•å¯¼é‡‡æ ·æ–¹æ³•ï¼Œæå‡å›¾åƒç”Ÿæˆè´¨é‡</li>
<li>ä¸å®Œå…¨å¾®è°ƒç›¸æ¯”ï¼ŒFineDiffusion è®­ç»ƒé€Ÿåº¦æå‡ 1.56 å€ï¼Œæ‰€éœ€å­˜å‚¨å‚æ•°ä»…ä¸ºåŸæ¨¡å‹çš„ 1.77%</li>
<li>åœ¨ 10,000 ä¸ªç±»åˆ«çš„å›¾åƒç”Ÿæˆä¸Šå–å¾—æœ€å…ˆè¿›çš„ FID ä¸º 9.776</li>
<li>å¤§é‡å®šæ€§å’Œå®šé‡å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„ä¼˜è¶Šæ€§</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šFineDiffusionï¼šå°†æ‰©æ•£æ¨¡å‹æ‰©å±•åˆ° 10,000 ç±»åˆ«çš„ç»†ç²’åº¦å›¾åƒç”Ÿæˆ</li>
<li>ä½œè€…ï¼šZiying Pan, Kun Wang, Gang Li, Feihong He, Xiwang Li, Yongxuan Lai</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå¦é—¨å¤§å­¦</li>
<li>å…³é”®è¯ï¼šDiffusion Models, Fine-grained Image Generation, Parameter-efficient Fine-tuning</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18331
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆä»¥äº§ç”Ÿé«˜è´¨é‡å’Œå¤šæ ·åŒ–çš„å›¾åƒè€Œé—»åã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°å…ˆå‰çš„åŠªåŠ›éƒ½é›†ä¸­åœ¨ä¸ºä¸€èˆ¬ç±»åˆ«ç”Ÿæˆå›¾åƒï¼Œä¾‹å¦‚ ImageNet-1k ä¸­çš„ 1000 ä¸ªç±»åˆ«ã€‚ä¸€ä¸ªæ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå³å¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼Œä»ç„¶æ˜¯éœ€è¦æ¢ç´¢çš„è¾¹ç•Œã€‚
   ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ä¸€èˆ¬ç±»åˆ«çš„å›¾åƒç”Ÿæˆï¼Œè€Œå¯¹äºç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼Œéœ€è¦æ¨¡å‹å¯¹é«˜åº¦ç›¸ä¼¼çš„ç»†ç²’åº¦ç±»åˆ«ä¸­çš„ç»†å¾®å·®å¼‚ï¼ˆä¾‹å¦‚é¸Ÿç±»çš„ç¾½æ¯›çº¹ç†ï¼‰è¿›è¡Œå¤æ‚çš„å»ºæ¨¡ã€‚ä»å¤´å¼€å§‹è®­ç»ƒç”¨äºå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹éœ€è¦æ›´å¤§çš„è®¡ç®—èµ„æºå’Œè®­ç»ƒè¿­ä»£ã€‚
   ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³• FineDiffusionï¼Œå®ƒå¯ä»¥é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œæœ‰æ•ˆåœ°å¾®è°ƒå¤§å‹é¢„è®­ç»ƒå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥è¿›è¡Œå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆã€‚
   ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šä¸å®Œå…¨å¾®è°ƒç›¸æ¯”ï¼ŒFineDiffusion å®ç°äº†æ˜¾ç€çš„ 1.56 å€è®­ç»ƒåŠ é€Ÿï¼Œå¹¶ä¸”åªéœ€è¦å­˜å‚¨ 1.77% çš„æ€»æ¨¡å‹å‚æ•°ï¼ŒåŒæ—¶åœ¨ 10,000 ä¸ªç±»åˆ«çš„å›¾åƒç”Ÿæˆä¸Šå®ç°äº† 9.776 çš„æœ€å…ˆè¿› FIDã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œä¸å…¶ä»–å‚æ•°æœ‰æ•ˆçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)æå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³•FineDiffusionï¼Œè¯¥æ–¹æ³•é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œæœ‰æ•ˆåœ°å¾®è°ƒå¤§å‹é¢„è®­ç»ƒå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥è¿›è¡Œå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼›(2)æå‡ºäº†ä¸€ç§åˆ†å±‚ç±»æ ‡ç­¾ç¼–ç ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åŒæ—¶å¯¹è¶…ç±»å’Œå­ç±»æ ‡ç­¾è¿›è¡Œç¼–ç ï¼›(3)åŒæ—¶å¾®è°ƒåå·®å’Œå½’ä¸€åŒ–é¡¹ä»¥åŠåˆ†å±‚åµŒå…¥å™¨ï¼Œä»¥å­¦ä¹ å…¨å±€æ•°æ®é›†çš„åˆ†å¸ƒç‰¹å¾ï¼›(4)å¼•å…¥äº†ä¸€ç§åˆ†å±‚æ— åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è¶…ç±»æ¡ä»¶ä¿¡æ¯æ¥å¢å¼ºå¯¹ç”Ÿæˆå›¾åƒçš„æ§åˆ¶ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é¦–æ¬¡å°è¯•å°†æ‰©æ•£æ¨¡å‹æ‰©å±•åˆ° 10,000 ç±»çš„ç»†ç²’åº¦å›¾åƒç”Ÿæˆã€‚æˆ‘ä»¬å¼•å…¥äº† FineDiffusionï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„å‚æ•°å¾®è°ƒæ–¹æ³•ï¼Œå¯ä»¥å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„å…³é”®ç»„ä»¶ï¼ŒåŒ…æ‹¬åˆ†å±‚æ ‡ç­¾åµŒå…¥ã€åå·®é¡¹å’Œå½’ä¸€åŒ–é¡¹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¤§å¹…å‡å°‘äº†è®­ç»ƒå’Œå­˜å‚¨å¼€é”€ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç»†ç²’åº¦æ— åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·æŠ€æœ¯ï¼Œåˆ©ç”¨åˆ†å±‚æ•°æ®æ ‡ç­¾ä¿¡æ¯æ¥æœ‰æ•ˆå¢å¼ºç»†ç²’åº¦å›¾åƒç”Ÿæˆçš„æ€§èƒ½ã€‚å……åˆ†çš„å®šæ€§å’Œå®šé‡ç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•ä¸å…¶ä»–æ–¹æ³•ç›¸æ¯”çš„ä¼˜è¶Šæ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³• FineDiffusionï¼Œè¯¥æ–¹æ³•é€šè¿‡å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œæœ‰æ•ˆåœ°å¾®è°ƒå¤§å‹é¢„è®­ç»ƒå›¾åƒç”Ÿæˆæ‰©æ•£æ¨¡å‹ï¼Œä»¥è¿›è¡Œå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆï¼›æå‡ºäº†åˆ†å±‚ç±»æ ‡ç­¾ç¼–ç ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åŒæ—¶å¯¹è¶…ç±»å’Œå­ç±»æ ‡ç­¾è¿›è¡Œç¼–ç ï¼›åŒæ—¶å¾®è°ƒåå·®å’Œå½’ä¸€åŒ–é¡¹ä»¥åŠåˆ†å±‚åµŒå…¥å™¨ï¼Œä»¥å­¦ä¹ å…¨å±€æ•°æ®é›†çš„åˆ†å¸ƒç‰¹å¾ï¼›å¼•å…¥äº†ä¸€ç§åˆ†å±‚æ— åˆ†ç±»å™¨å¼•å¯¼é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è¶…ç±»æ¡ä»¶ä¿¡æ¯æ¥å¢å¼ºå¯¹ç”Ÿæˆå›¾åƒçš„æ§åˆ¶ã€‚
æ€§èƒ½ï¼šä¸å®Œå…¨å¾®è°ƒç›¸æ¯”ï¼ŒFineDiffusion å®ç°äº†æ˜¾ç€çš„ 1.56 å€è®­ç»ƒåŠ é€Ÿï¼Œå¹¶ä¸”åªéœ€è¦å­˜å‚¨ 1.77% çš„æ€»æ¨¡å‹å‚æ•°ï¼ŒåŒæ—¶åœ¨ 10,000 ä¸ªç±»åˆ«çš„å›¾åƒç”Ÿæˆä¸Šå®ç°äº† 9.776 çš„æœ€å…ˆè¿› FIDã€‚å¹¿æ³›çš„å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œä¸å…¶ä»–å‚æ•°æœ‰æ•ˆçš„å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•å…·æœ‰ä¼˜è¶Šæ€§ã€‚
å·¥ä½œé‡ï¼šä¸ä»å¤´å¼€å§‹è®­ç»ƒç”¨äºå¤§è§„æ¨¡ç»†ç²’åº¦å›¾åƒç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼ŒFineDiffusion å¯ä»¥æ˜¾ç€å‡å°‘è®¡ç®—èµ„æºå’Œè®­ç»ƒè¿­ä»£ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f68a4db99ea4f9179538c6c4b4d7c7ce.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4e768fecf2a73ce9e4c8b13ef7c8cd6a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6c0d4b61db744892b76754513d9f6676.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-665dc312a2eacee1bb375efacd7d609c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d25afe2f19082c3abc80d90affd76466.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-68e2a9d895710b3df489a49501a85625.jpg" align="middle">
</details>




<h2 id="Balancing-Act-Distribution-Guided-Debiasing-in-Diffusion-Models"><a href="#Balancing-Act-Distribution-Guided-Debiasing-in-Diffusion-Models" class="headerlink" title="Balancing Act: Distribution-Guided Debiasing in Diffusion Models"></a>Balancing Act: Distribution-Guided Debiasing in Diffusion Models</h2><p><strong>Authors:Rishubh Parihar, Abhijnya Bhat, Saswat Mallick, Abhipsa Basu, Jogendra Nath Kundu, R. Venkatesh Babu</strong></p>
<p>Diffusion Models (DMs) have emerged as powerful generative models with unprecedented image generation capability. These models are widely used for data augmentation and creative applications. However, DMs reflect the biases present in the training datasets. This is especially concerning in the context of faces, where the DM prefers one demographic subgroup vs others (eg. female vs male). In this work, we present a method for debiasing DMs without relying on additional data or model retraining. Specifically, we propose Distribution Guidance, which enforces the generated images to follow the prescribed attribute distribution. To realize this, we build on the key insight that the latent features of denoising UNet hold rich demographic semantics, and the same can be leveraged to guide debiased generation. We train Attribute Distribution Predictor (ADP) - a small mlp that maps the latent features to the distribution of attributes. ADP is trained with pseudo labels generated from existing attribute classifiers. The proposed Distribution Guidance with ADP enables us to do fair generation. Our method reduces bias across single/multiple attributes and outperforms the baseline by a significant margin for unconditional and text-conditional diffusion models. Further, we present a downstream task of training a fair attribute classifier by rebalancing the training set with our generated data. </p>
<p><a href="http://arxiv.org/abs/2402.18206v1">PDF</a> CVPR 2024. Project Page : <a href="https://ab-34.github.io/balancing_act/">https://ab-34.github.io/balancing_act/</a></p>
<p><strong>Summary</strong><br>å»é™¤æ‰©æ•£æ¨¡å‹ä¸­çš„åè§ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–æ¨¡å‹é‡æ–°è®­ç»ƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰å­˜åœ¨åè§ï¼Œè¡¨ç°ä¸ºå¯¹ç‰¹å®šäººå£äºšç»„ï¼ˆå¦‚å¥³æ€§ï¼‰çš„åå¥½ã€‚</li>
<li>åˆ†å¸ƒå¼•å¯¼æ˜¯ä¸€ç§æ— å DM çš„æ–¹æ³•ï¼Œæ— éœ€é¢å¤–æ•°æ®æˆ–é‡æ–°è®­ç»ƒã€‚</li>
<li>åˆ†å¸ƒå¼•å¯¼åˆ©ç”¨å»å™ª UNet çš„æ½œåœ¨ç‰¹å¾ä¸­ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>å±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ (ADP) å°†æ½œåœ¨ç‰¹å¾æ˜ å°„åˆ°å±æ€§åˆ†å¸ƒã€‚</li>
<li>ADP ä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚</li>
<li>åˆ†å¸ƒå¼•å¯¼å’Œ ADP å®ç°äº†å…¬å¹³ç”Ÿæˆï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿ã€‚</li>
<li>é€šè¿‡ä½¿ç”¨ç”Ÿæˆçš„æ•°æ®é‡æ–°å¹³è¡¡è®­ç»ƒé›†ï¼Œå¯ä»¥è®­ç»ƒå…¬å¹³çš„å±æ€§åˆ†ç±»å™¨ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šå¹³è¡¡è¡Œä¸ºï¼šæ‰©æ•£æ¨¡å‹ä¸­çš„åˆ†å¸ƒå¼•å¯¼å»å</li>
<li>ä½œè€…ï¼šRishubh Parihar*, Abhijnya Bhatâˆ—, Saswat Mallick, Abhipsa Basu, Jogendra Nath Kundu, R. Venkatesh Babu</li>
<li>éš¶å±ï¼šå°åº¦ç§‘å­¦é™¢ï¼Œç­åŠ ç½—å°”</li>
<li>å…³é”®è¯ï¼šDiffusion Models, Debiasing, Distribution Guidance, Attribute Distribution Predictor, Fair Generation</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18206</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰ä½œä¸ºå¼ºå¤§çš„ç”Ÿæˆæ¨¡å‹ï¼Œåœ¨å›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä¼šåæ˜ è®­ç»ƒæ•°æ®é›†ä¸­çš„åè§ï¼Œç‰¹åˆ«æ˜¯å¯¹äºäººè„¸ï¼ŒDM åå¥½æŸäº›äººå£ç»Ÿè®¡å­¦äºšç»„ï¼ˆä¾‹å¦‚å¥³æ€§æ¯”ç”·æ€§ï¼‰ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰å»åæ–¹æ³•éœ€è¦é¢å¤–æ•°æ®æˆ–æ¨¡å‹é‡æ–°è®­ç»ƒã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºåˆ†å¸ƒå¼•å¯¼ï¼Œé€šè¿‡å¼ºåˆ¶ç”Ÿæˆå›¾åƒéµå¾ªè§„å®šçš„å±æ€§åˆ†å¸ƒæ¥å¯¹ DM è¿›è¡Œå»åã€‚é€šè¿‡è®­ç»ƒå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ (ADP) æ¥æ˜ å°„æ½œåœ¨ç‰¹å¾åˆ°å±æ€§åˆ†å¸ƒï¼ŒADP ä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨æ— æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸Šå‡å°‘äº†å•ä¸€/å¤šå±æ€§çš„åå·®ï¼Œå¹¶ä¸”ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§é€šè¿‡ä½¿ç”¨ç”Ÿæˆæ•°æ®é‡æ–°å¹³è¡¡è®­ç»ƒé›†æ¥è®­ç»ƒå…¬å¹³å±æ€§åˆ†ç±»å™¨çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): æå‡ºåˆ†å¸ƒå¼•å¯¼æ–¹æ³•ï¼Œé€šè¿‡å¼ºåˆ¶ç”Ÿæˆå›¾åƒéµå¾ªè§„å®šçš„å±æ€§åˆ†å¸ƒæ¥å¯¹æ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰è¿›è¡Œå»åã€‚
(2): è®­ç»ƒå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ï¼ˆADPï¼‰æ¥æ˜ å°„æ½œåœ¨ç‰¹å¾åˆ°å±æ€§åˆ†å¸ƒï¼ŒADPä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚
(3): åœ¨æ— æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸Šè¯„ä¼°è¯¥æ–¹æ³•ï¼Œå‡å°‘äº†å•ä¸€/å¤šå±æ€§çš„åå·®ï¼Œå¹¶ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
(4): æå‡ºäº†ä¸€ç§é€šè¿‡ä½¿ç”¨ç”Ÿæˆæ•°æ®é‡æ–°å¹³è¡¡è®­ç»ƒé›†æ¥è®­ç»ƒå…¬å¹³å±æ€§åˆ†ç±»å™¨çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬æ–‡çš„æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒå³å¯å‡è½»é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹åå·®çš„æ–¹æ³•ï¼Œä»…ç»™å®šæ‰€éœ€çš„å‚è€ƒå±æ€§åˆ†å¸ƒã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œåˆ©ç”¨åˆ†å¸ƒå¼•å¯¼ï¼Œè”åˆå¼•å¯¼ä¸€æ‰¹å›¾åƒéµå¾ªå‚è€ƒå±æ€§åˆ†å¸ƒã€‚æ‰€æå‡ºçš„æ–¹æ³•æ˜¯æœ‰æ•ˆçš„ï¼Œå¹¶ä¸”åœ¨
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„åˆ†å¸ƒå¼•å¯¼æ–¹æ³•ï¼Œé€šè¿‡å¼ºåˆ¶ç”Ÿæˆå›¾åƒéµå¾ªè§„å®šçš„å±æ€§åˆ†å¸ƒæ¥å¯¹æ‰©æ•£æ¨¡å‹è¿›è¡Œå»åã€‚
æ€§èƒ½ï¼šæœ¬æ–‡çš„æ–¹æ³•åœ¨æ— æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸Šå‡å°‘äº†å•ä¸€/å¤šå±æ€§çš„åå·®ï¼Œå¹¶ä¸”ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡çš„æ–¹æ³•éœ€è¦è®­ç»ƒä¸€ä¸ªå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨ï¼Œè¯¥é¢„æµ‹å™¨ä½¿ç”¨ç°æœ‰å±æ€§åˆ†ç±»å™¨ç”Ÿæˆçš„ä¼ªæ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚è®­ç»ƒå±æ€§åˆ†å¸ƒé¢„æµ‹å™¨çš„å·¥ä½œé‡å–å†³äºè®­ç»ƒæ•°æ®çš„è§„æ¨¡å’Œå±æ€§çš„æ•°é‡ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-05a1a956ee3a51fe0c06ffc4859c7231.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-16ae5c5f9f522148622d40f8f3f15f86.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46f6a987113095ab338596820ca6e653.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f32e1f0036b8646f3ffad99a82575f09.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1128b65d6c33c58a2f6b04087adf31b0.jpg" align="middle">
</details>




<h2 id="Coarse-to-Fine-Latent-Diffusion-for-Pose-Guided-Person-Image-Synthesis"><a href="#Coarse-to-Fine-Latent-Diffusion-for-Pose-Guided-Person-Image-Synthesis" class="headerlink" title="Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis"></a>Coarse-to-Fine Latent Diffusion for Pose-Guided Person Image Synthesis</h2><p><strong>Authors:Yanzuo Lu, Manlin Zhang, Andy J Ma, Xiaohua Xie, Jian-Huang Lai</strong></p>
<p>Diffusion model is a promising approach to image generation and has been employed for Pose-Guided Person Image Synthesis (PGPIS) with competitive performance. While existing methods simply align the person appearance to the target pose, they are prone to overfitting due to the lack of a high-level semantic understanding on the source person image. In this paper, we propose a novel Coarse-to-Fine Latent Diffusion (CFLD) method for PGPIS. In the absence of image-caption pairs and textual prompts, we develop a novel training paradigm purely based on images to control the generation process of the pre-trained text-to-image diffusion model. A perception-refined decoder is designed to progressively refine a set of learnable queries and extract semantic understanding of person images as a coarse-grained prompt. This allows for the decoupling of fine-grained appearance and pose information controls at different stages, and thus circumventing the potential overfitting problem. To generate more realistic texture details, a hybrid-granularity attention module is proposed to encode multi-scale fine-grained appearance features as bias terms to augment the coarse-grained prompt. Both quantitative and qualitative experimental results on the DeepFashion benchmark demonstrate the superiority of our method over the state of the arts for PGPIS. Code is available at <a href="https://github.com/YanzuoLu/CFLD">https://github.com/YanzuoLu/CFLD</a>. </p>
<p><a href="http://arxiv.org/abs/2402.18078v1">PDF</a> Accepted by CVPR 2024</p>
<p><strong>Summary</strong><br> æå‡ºäº†ä¸€ç§ç²—åˆ°ç»†çš„æ½œåœ¨æ‰©æ•£ï¼ˆCFLDï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨å›¾åƒè€Œéæ–‡æœ¬æç¤ºï¼Œæ§åˆ¶é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå®ç°å§¿åŠ¿å¼•å¯¼çš„å›¾åƒåˆæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡º CFLD æ–¹æ³•ï¼Œæ”¹å–„äº† PGPIS ä¸­å§¿åŠ¿å¼•å¯¼å›¾åƒåˆæˆçš„æ•ˆæœã€‚</li>
<li>ä½¿ç”¨çº¯å›¾åƒè®­ç»ƒèŒƒå¼ï¼Œæ— éœ€å›¾åƒå­—å¹•æˆ–æ–‡æœ¬æç¤ºã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªæ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨ï¼Œé€æ­¥ä¼˜åŒ–æŸ¥è¯¢å¹¶æå–äººç‰©å›¾åƒçš„è¯­ä¹‰ç†è§£ã€‚</li>
<li>å°†å¤–è²Œå’Œå§¿åŠ¿ä¿¡æ¯æ§åˆ¶è§£è€¦ï¼Œé¿å…è¿‡åº¦æ‹Ÿåˆã€‚</li>
<li>æå‡ºæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå¯¹å¤šå°ºåº¦å¤–è§‚ç‰¹å¾è¿›è¡Œç¼–ç ï¼Œå¢å¼ºç²—ç²’åº¦æç¤ºã€‚</li>
<li>åœ¨ DeepFashion æ•°æ®é›†ä¸Šï¼Œå®šé‡å’Œå®šæ€§å®éªŒç»“æœè¯æ˜äº† CFLD çš„ä¼˜è¶Šæ€§ã€‚</li>
<li>ä»£ç å·²å¼€æºã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šç²—åˆ°ç»†çš„æ½œåœ¨æ‰©æ•£ç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆ</li>
<li>ä½œè€…ï¼šLu Yanzuo, Zhang Manlin, Ma Andy J, Xie Xiaohua, Lai Jianhuang</li>
<li>å•ä½ï¼šä¸­å±±å¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šå§¿æ€å¼•å¯¼ã€äººç‰©å›¾åƒåˆæˆã€æ½œåœ¨æ‰©æ•£æ¨¡å‹ã€ç²—åˆ°ç»†ã€è¯­ä¹‰ç†è§£</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18078
   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/YanzuoLu/CFLD</li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆæ—¨åœ¨å°†æºäººç‰©å›¾åƒè½¬æ¢ä¸ºç‰¹å®šçš„ç›®æ ‡å§¿æ€ï¼ŒåŒæ—¶å°½å¯èƒ½ä¿ç•™å¤–è§‚ã€‚å®ƒåœ¨ç”µå½±åˆ¶ä½œã€è™šæ‹Ÿç°å®å’Œæ—¶å°šç”µå­å•†åŠ¡ç­‰é¢†åŸŸæœ‰å¹¿æ³›çš„åº”ç”¨ã€‚
(2) è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) çš„æ–¹æ³•å®¹æ˜“å‡ºç°æå°æå¤§è®­ç»ƒç›®æ ‡çš„ä¸ç¨³å®šæ€§å’Œéš¾ä»¥åœ¨ä¸€æ¬¡å‰å‘ä¼ é€’ä¸­ç”Ÿæˆé«˜è´¨é‡å›¾åƒçš„é—®é¢˜ã€‚ä½œä¸º GAN åœ¨å›¾åƒç”Ÿæˆä¸­çš„ä¸€ç§æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæ‰©æ•£æ¨¡å‹é€šè¿‡ä¸€ç³»åˆ—å»å™ªæ­¥éª¤é€æ¸åˆæˆæ›´é€¼çœŸçš„å›¾åƒã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç²—åˆ°ç»†æ½œåœ¨æ‰©æ•£ (CFLD) æ–¹æ³•ç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆã€‚åœ¨æ²¡æœ‰å›¾åƒ-æ ‡é¢˜å¯¹å’Œæ–‡æœ¬æç¤ºçš„æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§çº¯ç²¹åŸºäºå›¾åƒçš„æ–°é¢–è®­ç»ƒèŒƒå¼æ¥æ§åˆ¶é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨æ¥æ¸è¿›åœ°ç»†åŒ–ä¸€ç»„å¯å­¦ä¹ æŸ¥è¯¢å¹¶æå–äººç‰©å›¾åƒçš„è¯­ä¹‰ç†è§£ä½œä¸ºç²—ç²’åº¦æç¤ºã€‚è¿™å…è®¸åœ¨ä¸åŒçš„é˜¶æ®µè§£è€¦ç»†ç²’åº¦å¤–è§‚å’Œå§¿æ€ä¿¡æ¯æ§åˆ¶ï¼Œä»è€Œè§„é¿äº†æ½œåœ¨çš„è¿‡æ‹Ÿåˆé—®é¢˜ã€‚ä¸ºäº†ç”Ÿæˆæ›´é€¼çœŸçš„çº¹ç†ç»†èŠ‚ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå°†å¤šå°ºåº¦ç»†ç²’åº¦å¤–è§‚ç‰¹å¾ç¼–ç ä¸ºåå·®é¡¹ä»¥å¢å¼ºç²—ç²’åº¦æç¤ºã€‚
(4) æ€§èƒ½ï¼šåœ¨ DeepFashion åŸºå‡†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•åœ¨å§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…·æœ‰æ›´å¥½æ³›åŒ–æ€§èƒ½çš„é«˜è´¨é‡å›¾åƒã€‚</li>
</ol>
<p>7.Methodsï¼š
(1) æå‡ºç²—åˆ°ç»†æ½œåœ¨æ‰©æ•£ï¼ˆCFLDï¼‰æ–¹æ³•ï¼Œç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆï¼›
(2) å¼€å‘åŸºäºå›¾åƒçš„æ–°è®­ç»ƒèŒƒå¼ï¼Œæ§åˆ¶é¢„è®­ç»ƒæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ï¼›
(3) è®¾è®¡æ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨ï¼Œæ¸è¿›ç»†åŒ–å¯å­¦ä¹ æŸ¥è¯¢ï¼Œæå–äººç‰©å›¾åƒè¯­ä¹‰ç†è§£ä½œä¸ºç²—ç²’åº¦æç¤ºï¼›
(4) æå‡ºæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå°†å¤šå°ºåº¦ç»†ç²’åº¦å¤–è§‚ç‰¹å¾ç¼–ç ä¸ºåå·®é¡¹ï¼Œå¢å¼ºç²—ç²’åº¦æç¤ºï¼›
(5) é€šè¿‡åœ¨DeepFashionåŸºå‡†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒï¼ŒéªŒè¯äº†CFLDæ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚</p>
<ol>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰xxxï¼›
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p>
</li>
<li>
<p>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ
ï¼ˆ2ï¼‰ä»åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡ä¸‰ä¸ªç»´åº¦æ€»ç»“æœ¬æ–‡çš„ä¼˜ç¼ºç‚¹ï¼š
åˆ›æ–°ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç²—åˆ°ç»†æ½œåœ¨æ‰©æ•£ï¼ˆCFLDï¼‰æ–¹æ³•ï¼Œç”¨äºå§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆã€‚è¯¥æ–¹æ³•é€šè¿‡æ¸è¿›ç»†åŒ–å¯å­¦ä¹ æŸ¥è¯¢ï¼Œæå–äººç‰©å›¾åƒçš„è¯­ä¹‰ç†è§£ä½œä¸ºç²—ç²’åº¦æç¤ºï¼Œå¹¶æå‡ºæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œå°†å¤šå°ºåº¦ç»†ç²’åº¦å¤–è§‚ç‰¹å¾ç¼–ç ä¸ºåå·®é¡¹ï¼Œå¢å¼ºç²—ç²’åº¦æç¤ºã€‚
æ€§èƒ½ï¼šåœ¨ DeepFashion åŸºå‡†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒç»“æœè¯æ˜äº† CFLD æ–¹æ³•åœ¨å§¿æ€å¼•å¯¼çš„äººç‰©å›¾åƒåˆæˆä»»åŠ¡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…·æœ‰æ›´å¥½æ³›åŒ–æ€§èƒ½çš„é«˜è´¨é‡å›¾åƒã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡çš„å·¥ä½œé‡é€‚ä¸­ã€‚è¯¥æ–¹æ³•çš„å®ç°éœ€è¦å¯¹æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•éœ€è¦è®¾è®¡æ„ŸçŸ¥ç²¾ç‚¼è§£ç å™¨å’Œæ··åˆç²’åº¦æ³¨æ„åŠ›æ¨¡å—ï¼Œè¿™éœ€è¦é¢å¤–çš„å¼€å‘å’Œå®éªŒå·¥ä½œã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-ee807dc5573280abe63e138fa82f6eb3.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-07506917791ee3066c02770faa1a2052.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5192aaa635e4ab29d557ee967971be49.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-269e1bea1b870d8f0466ace81c9d2e01.jpg" align="middle">
</details>




<h2 id="SynArtifact-Classifying-and-Alleviating-Artifacts-in-Synthetic-Images-via-Vision-Language-Model"><a href="#SynArtifact-Classifying-and-Alleviating-Artifacts-in-Synthetic-Images-via-Vision-Language-Model" class="headerlink" title="SynArtifact: Classifying and Alleviating Artifacts in Synthetic Images   via Vision-Language Model"></a>SynArtifact: Classifying and Alleviating Artifacts in Synthetic Images   via Vision-Language Model</h2><p><strong>Authors:Bin Cao, Jianhao Yuan, Yexin Liu, Jian Li, Shuyang Sun, Jing Liu, Bo Zhao</strong></p>
<p>In the rapidly evolving area of image synthesis, a serious challenge is the presence of complex artifacts that compromise perceptual realism of synthetic images. To alleviate artifacts and improve quality of synthetic images, we fine-tune Vision-Language Model (VLM) as artifact classifier to automatically identify and classify a wide range of artifacts and provide supervision for further optimizing generative models. Specifically, we develop a comprehensive artifact taxonomy and construct a dataset of synthetic images with artifact annotations for fine-tuning VLM, named SynArtifact-1K. The fine-tuned VLM exhibits superior ability of identifying artifacts and outperforms the baseline by 25.66%. To our knowledge, this is the first time such end-to-end artifact classification task and solution have been proposed. Finally, we leverage the output of VLM as feedback to refine the generative model for alleviating artifacts. Visualization results and user study demonstrate that the quality of images synthesized by the refined diffusion model has been obviously improved. </p>
<p><a href="http://arxiv.org/abs/2402.18068v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹å¯¹å›¾åƒåˆæˆä¸­çš„ä¼ªå½±è¿›è¡Œè‡ªåŠ¨åˆ†ç±»ï¼Œä¸ºç”Ÿæˆæ¨¡å‹çš„è¿›ä¸€æ­¥ä¼˜åŒ–æä¾›ç›‘ç®¡ï¼Œä»è€Œæé«˜åˆæˆå›¾åƒçš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆæˆå›¾åƒä¸­å¤æ‚ä¼ªå½±çš„å­˜åœ¨æ„æˆäº†ä¸€é¡¹é‡å¤§æŒ‘æˆ˜ï¼Œå¯¹æ„ŸçŸ¥çœŸå®æ€§äº§ç”Ÿäº†è´Ÿé¢å½±å“ã€‚</li>
<li>ç ”ç©¶äººå‘˜æå‡ºå°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å¾®è°ƒä¸ºä¼ªå½±åˆ†ç±»å™¨ï¼Œä»¥ä¾¿è‡ªåŠ¨è¯†åˆ«å’Œåˆ†ç±»å„ç§ä¼ªå½±ã€‚</li>
<li>å¼€å‘äº†ä¸€ä¸ªå…¨é¢çš„ä¼ªå½±åˆ†ç±»ä½“ç³»ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªå…·æœ‰ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›†ï¼ˆSynArtifact-1Kï¼‰ã€‚</li>
<li>å¾®è°ƒåçš„ VLM åœ¨è¯†åˆ«ä¼ªå½±æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„èƒ½åŠ›ï¼Œæ¯”åŸºçº¿é«˜å‡º 25.66%ã€‚</li>
<li>è¿™æ˜¯é¦–æ¬¡æå‡ºæ­¤ç±»ç«¯åˆ°ç«¯ä¼ªå½±åˆ†ç±»ä»»åŠ¡å’Œè§£å†³æ–¹æ¡ˆã€‚</li>
<li>åˆ©ç”¨ VLM çš„è¾“å‡ºä½œä¸ºåé¦ˆæ¥ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å‡è½»ä¼ªå½±ã€‚</li>
<li>è§†è§‰åŒ–ç»“æœå’Œç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œä¼˜åŒ–åçš„æ‰©æ•£æ¨¡å‹åˆæˆçš„å›¾åƒè´¨é‡å¾—åˆ°äº†æ˜æ˜¾æ”¹å–„ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡é¢˜ç›®ï¼šSynArtifactï¼šé€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹å¯¹åˆæˆå›¾åƒä¸­çš„ä¼ªå½±è¿›è¡Œåˆ†ç±»å’Œæ¶ˆé™¤</li>
<li>ä½œè€…ï¼šBin Cao, Jianhao Yuan, Yexin Liu, Jian Li, Shuyang Sun, Jing Liu, Bo Zhao</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼šåˆæˆå›¾åƒã€ä¼ªå½±ã€è§†è§‰è¯­è¨€æ¨¡å‹ã€ç”Ÿæˆæ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18068</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šåˆæˆå›¾åƒä¸­å­˜åœ¨å¤æ‚ä¼ªå½±ï¼Œå½±å“å›¾åƒçš„æ„ŸçŸ¥çœŸå®æ€§ã€‚
(2) è¿‡å¾€æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å•ä¸€è¯„åˆ†æŒ‡æ ‡ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹ï¼Œæ— æ³•æœ‰æ•ˆåæ˜ ä¼ªå½±çš„å¤šæ ·æ€§å’Œå¤æ‚æ€§ã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºä¸€ä¸ªç»¼åˆä¼ªå½±åˆ†ç±»æ³•ï¼Œæ„å»ºäº†ä¸€ä¸ªå¸¦æœ‰ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›† SynArtifact-1Kï¼Œå¹¶å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ (VLM) å¯¹ä¼ªå½±è¿›è¡Œåˆ†ç±»ã€‚åˆ©ç”¨ VLM çš„è¾“å‡ºä½œä¸º AI åé¦ˆæ¥æ”¹è¿›ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å‡è½»ä¼ªå½±ã€‚
(4) å®éªŒç»“æœï¼šå¾®è°ƒåçš„ VLM åœ¨ä¼ªå½±åˆ†ç±»ä»»åŠ¡ä¸Šæ¯”åŸºçº¿æ–¹æ³•æé«˜äº† 25.66% çš„å‡†ç¡®ç‡å’Œ 29.01% çš„ F1 åˆ†æ•°ã€‚é€šè¿‡åˆ©ç”¨ä¼ªå½±åˆ†ç±»å™¨çš„è¾“å‡ºä½œä¸º AI åé¦ˆï¼Œå¯ä»¥æœ‰æ•ˆå‡è½»ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¼ªå½±ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ„å»ºç»¼åˆä¼ªå½±åˆ†ç±»æ³•ï¼Œå»ºç«‹åŒ…å«ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›† SynArtifact-1Kï¼›
ï¼ˆ2ï¼‰å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ VLMï¼Œå°†å…¶ä½œä¸ºä¼ªå½±åˆ†ç±»å™¨ï¼›
ï¼ˆ3ï¼‰åˆ©ç”¨ VLM è¾“å‡ºä½œä¸º AI åé¦ˆï¼Œè®¡ç®—ç”Ÿæˆæ¨¡å‹è¾“å‡ºä¸æ¯ç§ä¼ªå½±ä¹‹é—´çš„ BertScoreï¼Œä½œä¸ºä¼ªå½±åˆ†ç±»å¥–åŠ±ï¼›
ï¼ˆ4ï¼‰é€šè¿‡æœ€å¤§åŒ–ä¼ªå½±åˆ†ç±»å¥–åŠ±ï¼Œä¼˜åŒ–æ‰©æ•£æ¨¡å‹ï¼Œä»¥å‡è½»ä¼ªå½±ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é’ˆå¯¹åˆæˆå›¾åƒä¸­çš„ä¼ªå½±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªç»¼åˆçš„ä¼ªå½±åˆ†ç±»æ³•ï¼Œæ„å»ºäº†åŒ…å«ä¼ªå½±æ³¨é‡Šçš„åˆæˆå›¾åƒæ•°æ®é›† SynArtifact-1Kï¼Œå¹¶åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹å¯¹ä¼ªå½±è¿›è¡Œåˆ†ç±»ï¼Œæœ‰æ•ˆåœ°å‡è½»äº†ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¼ªå½±ï¼Œæå‡äº†åˆæˆå›¾åƒçš„æ„ŸçŸ¥çœŸå®æ€§ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æ„å»ºäº†åŒ…å« 13 ç§å¸¸è§ä¼ªå½±çš„ç»¼åˆä¼ªå½±åˆ†ç±»æ³•ã€‚</li>
<li>åˆ›å»ºäº†é¦–ä¸ªå¸¦æœ‰ä¼ªå½±ç±»åˆ«ã€æè¿°å’Œåæ ‡æ³¨é‡Šçš„å›¾åƒæ•°æ®é›† SynArtifact-1Kã€‚</li>
<li>å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹ç”¨äºè‡ªåŠ¨åˆ†ç±»ä¼ªå½±ï¼Œå¹¶åˆ©ç”¨å…¶è¾“å‡ºä½œä¸º AI åé¦ˆæ¥ä¼˜åŒ–ç”Ÿæˆæ¨¡å‹ã€‚
æ€§èƒ½ï¼š</li>
<li>å¾®è°ƒåçš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨ä¼ªå½±åˆ†ç±»ä»»åŠ¡ä¸Šæ¯”åŸºçº¿æ–¹æ³•æé«˜äº† 25.66% çš„å‡†ç¡®ç‡å’Œ 29.01% çš„ F1 åˆ†æ•°ã€‚</li>
<li>åˆ©ç”¨ä¼ªå½±åˆ†ç±»å™¨çš„è¾“å‡ºä½œä¸º AI åé¦ˆï¼Œå¯ä»¥æœ‰æ•ˆå‡è½»ç”Ÿæˆæ¨¡å‹ä¸­çš„ä¼ªå½±ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æ„å»ºäº†åŒ…å« 1000 å¼ åˆæˆå›¾åƒçš„ SynArtifact-1K æ•°æ®é›†ã€‚</li>
<li>å¾®è°ƒäº†è§†è§‰è¯­è¨€æ¨¡å‹ç”¨äºä¼ªå½±åˆ†ç±»ã€‚</li>
<li>é€šè¿‡æœ€å¤§åŒ–ä¼ªå½±åˆ†ç±»å¥–åŠ±ï¼Œä¼˜åŒ–äº†æ‰©æ•£æ¨¡å‹ä»¥å‡è½»ä¼ªå½±ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-887bb2eb3bab7f102340a00fb115308a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a67234ceff494848cb67aa7bc7345a5e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c0c890345f83368ccd384b81c55c4b11.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-48d8c1e1b56b76bfccfccfcb96c1d5a4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a5599c3d37db39e68fa5fb2e0139cec.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-94675e3c8e66717ee97bc9e3472ed274.jpg" align="middle">
</details>




<h2 id="Box-It-to-Bind-It-Unified-Layout-Control-and-Attribute-Binding-in-T2I-Diffusion-Models"><a href="#Box-It-to-Bind-It-Unified-Layout-Control-and-Attribute-Binding-in-T2I-Diffusion-Models" class="headerlink" title="Box It to Bind It: Unified Layout Control and Attribute Binding in T2I   Diffusion Models"></a>Box It to Bind It: Unified Layout Control and Attribute Binding in T2I   Diffusion Models</h2><p><strong>Authors:Ashkan Taghipour, Morteza Ghahremani, Mohammed Bennamoun, Aref Miri Rekavandi, Hamid Laga, Farid Boussaid</strong></p>
<p>While latent diffusion models (LDMs) excel at creating imaginative images, they often lack precision in semantic fidelity and spatial control over where objects are generated. To address these deficiencies, we introduce the Box-it-to-Bind-it (B2B) module - a novel, training-free approach for improving spatial control and semantic accuracy in text-to-image (T2I) diffusion models. B2B targets three key challenges in T2I: catastrophic neglect, attribute binding, and layout guidance. The process encompasses two main steps: i) Object generation, which adjusts the latent encoding to guarantee object generation and directs it within specified bounding boxes, and ii) attribute binding, guaranteeing that generated objects adhere to their specified attributes in the prompt. B2B is designed as a compatible plug-and-play module for existing T2I models, markedly enhancing model performance in addressing the key challenges. We evaluate our technique using the established CompBench and TIFA score benchmarks, demonstrating significant performance improvements compared to existing methods. The source code will be made publicly available at <a href="https://github.com/nextaistudio/BoxIt2BindIt">https://github.com/nextaistudio/BoxIt2BindIt</a>. </p>
<p><a href="http://arxiv.org/abs/2402.17910v1">PDF</a> </p>
<p><strong>Summary</strong><br>Box-it-to-Bind-itï¼ˆB2Bï¼‰æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„æ–°æ¨¡å—ï¼Œå¯æé«˜æ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰æ‰©æ•£æ¨¡å‹ä¸­å›¾åƒçš„ç”Ÿæˆè´¨é‡ã€è¯­ä¹‰å‡†ç¡®åº¦å’Œç©ºé—´æ§åˆ¶èƒ½åŠ›ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>B2B æ¨¡å—å¯æ”¹å–„ T2I ä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šç¾éš¾æ€§é—æ¼ã€å±æ€§ç»‘å®šå’Œå¸ƒå±€æŒ‡å¯¼ã€‚</li>
<li>B2B åŒ…æ‹¬ç”Ÿæˆå¯¹è±¡å’Œå±æ€§ç»‘å®šçš„ä¸¤ä¸ªä¸»è¦æ­¥éª¤ã€‚</li>
<li>B2B å¯ä½œä¸ºç°æœ‰çš„ T2I æ¨¡å‹çš„å³æ’å³ç”¨æ¨¡å—ï¼Œæ— éœ€è®­ç»ƒã€‚</li>
<li>B2B åœ¨ CompBench å’Œ TIFA è¯„åˆ†åŸºå‡†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚</li>
<li>B2B çš„æºä»£ç å°†åœ¨ <a href="https://github.com/nextaistudio/BoxIt2BindIt">https://github.com/nextaistudio/BoxIt2BindIt</a> ä¸Šå…¬å¼€ã€‚</li>
<li>B2B æé«˜äº† LDM åœ¨ç”Ÿæˆå›¾åƒæ—¶çš„ç©ºé—´æ§åˆ¶å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚</li>
<li>B2B é€‚ç”¨äºä¸åŒçš„ T2I æ¨¡å‹ï¼Œæ˜“äºé›†æˆã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šBox-it-to-Bind-itï¼šç»Ÿä¸€å¸ƒå±€æ§åˆ¶å’Œå±æ€§ç»‘å®šåˆ° T2I æ‰©æ•£æ¨¡å‹ä¸­</li>
<li>ä½œè€…ï¼šAshkan Taghipour, Morteza Ghahremani, Mohammed Bennamoun, Aref Miri Rekavandi, Hamid Laga, Farid Boussaid</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè¥¿æ¾³å¤§åˆ©äºšå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€æ‰©æ•£æ¨¡å‹ã€ç©ºé—´æ§åˆ¶ã€å±æ€§ç»‘å®šã€å¸ƒå±€å¼•å¯¼</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17910</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
ç°æœ‰æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶ç¼ºä¹è¯­ä¹‰ä¿çœŸåº¦å’Œç©ºé—´æ§åˆ¶ï¼Œéš¾ä»¥å¿ å®åœ°éµå¾ªç»™å®šçš„æç¤ºï¼Œå°¤å…¶æ˜¯åœ¨å¯¹è±¡å±æ€§å’Œå¯¹è±¡æ”¾ç½®æ–¹é¢ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼š
ç°æœ‰æ–¹æ³•è¦ä¹ˆä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œè¦ä¹ˆå¾®è°ƒç°æœ‰æ¨¡å‹ï¼Œä½†éœ€è¦å¤§é‡è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å¹¶é›†æˆç‰¹å¾çš„æ–¹æ³•è™½ç„¶ä¸éœ€è¦å¤§é‡è®­ç»ƒï¼Œä½†æ•ˆæœæœ‰é™ã€‚</p>
<p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§å…è®­ç»ƒçš„æ–¹æ³• Box-it-to-Bind-it (B2B)ï¼Œè§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ä¸‰ä¸ªå…³é”®æŒ‘æˆ˜ï¼šç¾éš¾æ€§é—æ¼ã€å±æ€§ç»‘å®šå’Œå¸ƒå±€å¼•å¯¼ã€‚B2B åœ¨æ¨ç†é˜¶æ®µé€šè¿‡ä¸¤æ­¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç¼–ç ï¼šå¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
åœ¨ CompBench å’Œ TIFA å¾—åˆ†åŸºå‡†ä¸Šï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒB2B åœ¨è§£å†³å…³é”®æŒ‘æˆ˜æ–¹é¢æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½æå‡æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³æé«˜æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ç©ºé—´æ§åˆ¶å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚</p>
<p>æ–¹æ³•ï¼š
(1) B2Bæ˜¯ä¸€ç§å¥–åŠ±å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼Œå®ƒåœ¨æ¨ç†é˜¶æ®µé€šè¿‡ä¸¤æ­¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç¼–ç ï¼šå¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šã€‚
(2) å¯¹è±¡ç”Ÿæˆï¼šåŸºäºIoUï¼Œå¢åŠ å¯¹è±¡ç”Ÿæˆæ¦‚ç‡ï¼Œå°†æ³¨æ„åŠ›æƒé‡é›†ä¸­åœ¨ç»™å®šè¾¹ç•Œæ¡†å†…ï¼ŒåŒæ—¶æŠ‘åˆ¶è¾¹ç•Œæ¡†å¤–çš„æ³¨æ„åŠ›æƒé‡ã€‚
(3) å±æ€§ç»‘å®šï¼šä½¿ç”¨KLæ•£åº¦æµ‹é‡å±æ€§æ¦‚ç‡åˆ†å¸ƒä¸å¯¹åº”å¯¹è±¡æ¦‚ç‡åˆ†å¸ƒçš„å·®å¼‚ï¼Œå‡å°‘å·®å¼‚ï¼Œå°†å±æ€§åˆ†å¸ƒå¼ºåˆ¶æ”¶æ•›åˆ°å„è‡ªçš„å¯¹è±¡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶é’ˆå¯¹æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å…³é”®æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å±æ€§ç»‘å®šå’Œç©ºé—´æ§åˆ¶ï¼Œæå‡ºäº† B2B æ¨¡å‹ã€‚B2B é‡‡ç”¨ç”Ÿæˆå’Œç»‘å®šåŒæ¨¡å—ç³»ç»Ÿï¼Œæœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—æ¼ã€æé«˜å±æ€§ç»‘å®šç²¾åº¦å’Œç¡®ä¿å‡†ç¡®å¯¹è±¡æ”¾ç½®çš„é—®é¢˜ã€‚å®ƒä½œä¸ºç°æœ‰ T2I æ¡†æ¶çš„å³æ’å³ç”¨æ¨¡å—çš„å…¼å®¹æ€§é€šè¿‡å…¶åœ¨ CompBench å’Œ TIFA åŸºå‡†ä¸­çš„å‡ºè‰²è¡¨ç°å¾—åˆ°è¯æ˜ï¼Œæ ‡å¿—ç€ç”Ÿæˆå»ºæ¨¡çš„é‡å¤§é£è·ƒã€‚B2B çš„çªç ´å‡¸æ˜¾äº†å…¶ä½œä¸ºæœªæ¥ç ”ç©¶æ½œåœ¨æ ‡å‡†çš„ä½œç”¨ï¼Œä¸ºæ•°å­—æˆåƒå’Œç”Ÿæˆå¼ AI çš„åˆ›æ–°å‘å±•é“ºå¹³äº†é“è·¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§å…è®­ç»ƒçš„æ–¹æ³• B2Bï¼Œé€šè¿‡ä¸¤æ­¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨ç¼–ç æ¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚</li>
<li>è®¾è®¡äº†å¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šä¸¤ä¸ªæ¨¡å—ï¼Œæœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—æ¼ã€å±æ€§ç»‘å®šå’Œå¸ƒå±€å¼•å¯¼é—®é¢˜ã€‚</li>
<li>B2B ä½œä¸ºç°æœ‰ T2I æ¡†æ¶çš„å³æ’å³ç”¨æ¨¡å—ï¼Œæ˜“äºé›†æˆå’Œä½¿ç”¨ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ CompBench å’Œ TIFA åŸºå‡†ä¸Šï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒB2B åœ¨è§£å†³å…³é”®æŒ‘æˆ˜æ–¹é¢æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>æ¶ˆèç ”ç©¶éªŒè¯äº†å¯¹è±¡ç”Ÿæˆå’Œå±æ€§ç»‘å®šå¥–åŠ±ç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼Œè¡¨æ˜ B2B çš„å„ä¸ªç»„ä»¶å¯¹æ•´ä½“æ€§èƒ½è‡³å…³é‡è¦ã€‚
å·¥ä½œé‡ï¼š</li>
<li>B2B æ˜¯ä¸€ç§å…è®­ç»ƒçš„æ–¹æ³•ï¼Œä¸éœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹æˆ–å¾®è°ƒç°æœ‰æ¨¡å‹ï¼Œä»è€ŒèŠ‚çœäº†å¤§é‡çš„è®¡ç®—èµ„æºå’Œæ—¶é—´ã€‚</li>
<li>B2B æ˜“äºé›†æˆåˆ°ç°æœ‰ T2I æ¡†æ¶ä¸­ï¼Œæ— éœ€è¿›è¡Œå¤æ‚çš„ä¿®æ”¹æˆ–é‡æ–°è®­ç»ƒï¼Œé™ä½äº†å·¥ä½œé‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9044558cdc31309b419fea5199aa8a89.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-78bccd36910d4aa870962c445823ad57.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-967a215bde68183f03e457a7ff3f8e9a.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e2a4cdc833464a14406a357aa9e0c358.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d140c3c8e05d724098a1c03138203a01.jpg" align="middle">
</details>




<h2 id="Structure-Guided-Adversarial-Training-of-Diffusion-Models"><a href="#Structure-Guided-Adversarial-Training-of-Diffusion-Models" class="headerlink" title="Structure-Guided Adversarial Training of Diffusion Models"></a>Structure-Guided Adversarial Training of Diffusion Models</h2><p><strong>Authors:Ling Yang, Haotian Qian, Zhilong Zhang, Jingwei Liu, Bin Cui</strong></p>
<p>Diffusion models have demonstrated exceptional efficacy in various generative applications. While existing models focus on minimizing a weighted sum of denoising score matching losses for data distribution modeling, their training primarily emphasizes instance-level optimization, overlooking valuable structural information within each mini-batch, indicative of pair-wise relationships among samples. To address this limitation, we introduce Structure-guided Adversarial training of Diffusion Models (SADM). In this pioneering approach, we compel the model to learn manifold structures between samples in each training batch. To ensure the model captures authentic manifold structures in the data distribution, we advocate adversarial training of the diffusion generator against a novel structure discriminator in a minimax game, distinguishing real manifold structures from the generated ones. SADM substantially improves existing diffusion transformers (DiT) and outperforms existing methods in image generation and cross-domain fine-tuning tasks across 12 datasets, establishing a new state-of-the-art FID of 1.58 and 2.11 on ImageNet for class-conditional image generation at resolutions of 256x256 and 512x512, respectively. </p>
<p><a href="http://arxiv.org/abs/2402.17563v1">PDF</a> Accepted by CVPR 2024</p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹é€šè¿‡ç»“æ„å¯¹æŠ—è®­ç»ƒï¼Œå­¦ä¹ æ‰¹å†…æ ·æœ¬æµå½¢ç»“æ„ï¼Œæå‡å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç°æœ‰æ‰©æ•£æ¨¡å‹ä¸“æ³¨äºå•ä¸ªæ ·æœ¬çš„å»å™ªå¾—åˆ†åŒ¹é…æŸå¤±ä¼˜åŒ–ï¼Œå¿½è§†æ‰¹å†…æ ·æœ¬ä¹‹é—´çš„æˆå¯¹å…³ç³»ã€‚</li>
<li>ç»“æ„å¯¹æŠ—è®­ç»ƒ (SADM) å¼•å…¥ç»“æ„é‰´åˆ«å™¨æ¥åŒºåˆ†çœŸå®å’Œç”Ÿæˆçš„æµå½¢ç»“æ„ã€‚</li>
<li>SADM è¿«ä½¿æ¨¡å‹å­¦ä¹ è®­ç»ƒæ‰¹æ¬¡ä¸­æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ã€‚</li>
<li>SADM ä¸æ‰©æ•£å˜å‹å™¨ (DiT) ç›¸ç»“åˆï¼Œåœ¨å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>SADM åœ¨ 12 ä¸ªæ•°æ®é›†ä¸Šå®ç°äº†å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡çš„æœ€æ–° FID åˆ†åˆ«ä¸º 1.58 å’Œ 2.11ã€‚</li>
<li>SADM åœ¨ 256x256 å’Œ 512x512 åˆ†è¾¨ç‡ä¸‹ï¼Œåœ¨ ImageNet ä¸Šå®ç°äº†ç±»æ¡ä»¶å›¾åƒç”Ÿæˆçš„æœ€æ–° FID åˆ†åˆ«ä¸º 1.58 å’Œ 2.11ã€‚</li>
<li>SADM è¯æ˜äº†æµå½¢ç»“æ„å­¦ä¹ å¯¹äºæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­çš„é‡è¦æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹å¯¹æŠ—æ€§è®­ç»ƒ</li>
<li>ä½œè€…ï¼šæ¨å‡Œã€é’±æµ©å¤©ã€å¼ æ™ºé¾™ã€åˆ˜æ™¯ä¼Ÿã€å´”æ–Œ</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€ç»“æ„å¼•å¯¼ã€å¯¹æŠ—è®­ç»ƒ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17563
   Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æœ€å°åŒ–å»å™ªå¾—åˆ†åŒ¹é…æŸå¤±çš„åŠ æƒå’Œï¼Œè®­ç»ƒè¿‡ç¨‹ä¾§é‡äºå®ä¾‹çº§ä¼˜åŒ–ï¼Œå¿½ç•¥äº†å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„å®è´µç»“æ„ä¿¡æ¯ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨å®ä¾‹çº§ä¼˜åŒ–ï¼Œå¿½ç•¥äº†å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„ç»“æ„ä¿¡æ¯ï¼Œå¯¼è‡´æ— æ³•å……åˆ†å»ºæ¨¡æ•°æ®åˆ†å¸ƒã€‚</p>
<p>ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æå‡ºç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹å¯¹æŠ—æ€§è®­ç»ƒï¼ˆSADMï¼‰ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæŒ‡å¯¼æ‰©æ•£ç”Ÿæˆå™¨å­¦ä¹ å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ã€‚å¼•å…¥ç»“æ„åˆ¤åˆ«å™¨æ¥åŒºåˆ†çœŸå®æµå½¢ç»“æ„å’Œç”Ÿæˆæµå½¢ç»“æ„ï¼Œç¡®ä¿æ¨¡å‹æ•è·æ•°æ®åˆ†å¸ƒä¸­çš„çœŸå®æµå½¢ç»“æ„ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
SADM æ˜¾è‘—æå‡äº†ç°æœ‰æ‰©æ•£ Transformerï¼Œåœ¨ 12 ä¸ªæ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨ ImageNet ä¸Šåˆ†åˆ«ä»¥ 256Ã—256 å’Œ 512Ã—512 çš„åˆ†è¾¨ç‡å®ç°äº† 1.58 å’Œ 2.11 çš„æ–° SOTA FIDï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
<p>7.Methodsï¼š
ï¼ˆ1ï¼‰æå‡ºç»“æ„å¼•å¯¼æ‰©æ•£æ¨¡å‹å¯¹æŠ—æ€§è®­ç»ƒï¼ˆSADMï¼‰ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæŒ‡å¯¼æ‰©æ•£ç”Ÿæˆå™¨å­¦ä¹ å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ï¼›
ï¼ˆ2ï¼‰å¼•å…¥ç»“æ„åˆ¤åˆ«å™¨æ¥åŒºåˆ†çœŸå®æµå½¢ç»“æ„å’Œç”Ÿæˆæµå½¢ç»“æ„ï¼Œç¡®ä¿æ¨¡å‹æ•è·æ•°æ®åˆ†å¸ƒä¸­çš„çœŸå®æµå½¢ç»“æ„ï¼›
ï¼ˆ3ï¼‰é‡‡ç”¨Wasserstein GANæŸå¤±å‡½æ•°ï¼ŒæŒ‡å¯¼ç”Ÿæˆå™¨ç”Ÿæˆä¸çœŸå®æµå½¢ç»“æ„ç›¸ä¼¼çš„æ ·æœ¬ï¼›
ï¼ˆ4ï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­äº¤æ›¿æ›´æ–°ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼Œç›´è‡³è¾¾åˆ°çº³ä»€å‡è¡¡ï¼›
ï¼ˆ5ï¼‰å°†SADMä¸æ‰©æ•£Transformerç›¸ç»“åˆï¼Œå½¢æˆæ›´å¼ºå¤§çš„å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚</p>
<ol>
<li>æ€»ç»“
(1): æœ¬æ–‡æå‡ºäº†ä»ç»“æ„è§’åº¦ä¼˜åŒ–æ‰©æ•£æ¨¡å‹çš„ç»“æ„å¼•å¯¼å¯¹æŠ—æ€§è®­ç»ƒæ–¹æ³•ï¼Œè¯¥è®­ç»ƒç®—æ³•å¯ä»¥è½»æ¾æ¨å¹¿åˆ°å›¾åƒå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼å’Œå®éªŒç»“æœä¸€è‡´åœ°æ”¹è¿›äº†ç°æœ‰çš„æ‰©æ•£æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨ 12 ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸­å–å¾—äº†æ–°çš„ SOTA æ€§èƒ½ã€‚å¯¹äºæœªæ¥çš„å·¥ä½œï¼Œæˆ‘ä»¬å°†æŠŠæˆ‘ä»¬çš„æ–¹æ³•æ‰©å±•åˆ°æ›´å…·æŒ‘æˆ˜æ€§çš„åŸºäºæ‰©æ•£çš„åº”ç”¨ç¨‹åºï¼ˆä¾‹å¦‚ï¼Œæ–‡æœ¬åˆ°å›¾åƒ/è§†é¢‘ç”Ÿæˆï¼‰ã€‚
(2): åˆ›æ–°ç‚¹: æå‡ºç»“æ„å¼•å¯¼å¯¹æŠ—æ€§è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæŒ‡å¯¼æ‰©æ•£ç”Ÿæˆå™¨å­¦ä¹ å°æ‰¹é‡æ ·æœ¬ä¹‹é—´çš„æµå½¢ç»“æ„ï¼Œä»è€Œæå‡æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚
æ€§èƒ½: åœ¨ 12 ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆå’Œè·¨åŸŸå¾®è°ƒä»»åŠ¡ä¸­å–å¾—äº†æ–°çš„ SOTA æ€§èƒ½ï¼Œåœ¨ ImageNet ä¸Šåˆ†åˆ«ä»¥ 256Ã—256 å’Œ 512Ã—512 çš„åˆ†è¾¨ç‡å®ç°äº† 1.58 å’Œ 2.11 çš„æ–° SOTAFIDã€‚
å·¥ä½œé‡: è¯¥æ–¹æ³•æ˜“äºå®ç°ï¼Œå¯ä»¥è½»æ¾æ¨å¹¿åˆ°å›¾åƒå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå·¥ä½œé‡è¾ƒå°ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-11a45496d9d4169c7ee0bbb4a6534ffa.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b4ae1e4da806d223271756f678f15ce9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-02b820484fca35ffef9bc52706101c79.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-14ed9373ba8bdaf3ecaca75391245256.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-75ca2aa69507bb15984388d3520039af.jpg" align="middle">
</details>




<h2 id="Diffusion-Model-Based-Image-Editing-A-Survey"><a href="#Diffusion-Model-Based-Image-Editing-A-Survey" class="headerlink" title="Diffusion Model-Based Image Editing: A Survey"></a>Diffusion Model-Based Image Editing: A Survey</h2><p><strong>Authors:Yi Huang, Jiancheng Huang, Yifan Liu, Mingfu Yan, Jiaxi Lv, Jianzhuang Liu, Wei Xiong, He Zhang, Shifeng Chen, Liangliang Cao</strong></p>
<p>Denoising diffusion models have emerged as a powerful tool for various image generation and editing tasks, facilitating the synthesis of visual content in an unconditional or input-conditional manner. The core idea behind them is learning to reverse the process of gradually adding noise to images, allowing them to generate high-quality samples from a complex distribution. In this survey, we provide an exhaustive overview of existing methods using diffusion models for image editing, covering both theoretical and practical aspects in the field. We delve into a thorough analysis and categorization of these works from multiple perspectives, including learning strategies, user-input conditions, and the array of specific editing tasks that can be accomplished. In addition, we pay special attention to image inpainting and outpainting, and explore both earlier traditional context-driven and current multimodal conditional methods, offering a comprehensive analysis of their methodologies. To further evaluate the performance of text-guided image editing algorithms, we propose a systematic benchmark, EditEval, featuring an innovative metric, LMM Score. Finally, we address current limitations and envision some potential directions for future research. The accompanying repository is released at <a href="https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods">https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods</a>. </p>
<p><a href="http://arxiv.org/abs/2402.17525v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆå’Œç¼–è¾‘ä»»åŠ¡ä¸­åº”ç”¨å¹¿æ³›ï¼Œå¯ä»å¤æ‚åˆ†å¸ƒä¸­ç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ï¼Œä¸”æ”¯æŒæ— æ¡ä»¶å’Œè¾“å…¥æ¡ä»¶ä¸‹çš„å›¾åƒç¼–è¾‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹é€šè¿‡å­¦ä¹ é€†è½¬å›¾åƒåŠ å™ªè¿‡ç¨‹ï¼Œç”Ÿæˆé«˜è´¨é‡æ ·æœ¬ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å›¾åƒç¼–è¾‘æ–¹æ³•å¯åˆ†ä¸ºä¸åŒå­¦ä¹ ç­–ç•¥ã€ç”¨æˆ·è¾“å…¥æ¡ä»¶å’Œç¼–è¾‘ä»»åŠ¡ã€‚</li>
<li>å›¾åƒä¿®å¤å’Œå¤–å»¶å¯ä½¿ç”¨ä¼ ç»Ÿä¸Šä¸‹æ–‡é©±åŠ¨æ–¹æ³•æˆ–å¤šæ¨¡æ€æ¡ä»¶æ–¹æ³•ã€‚</li>
<li>æå‡º EditEval åŸºå‡†å’Œ LMM è¯„åˆ†ç”¨äºè¯„ä¼°æ–‡æœ¬æŒ‡å¯¼å›¾åƒç¼–è¾‘ç®—æ³•ã€‚</li>
<li>ç›®å‰å­˜åœ¨é™åˆ¶ï¼Œæœªæ¥ç ”ç©¶æ–¹å‘åŒ…æ‹¬å¤šæ¨¡æ€ã€3D å’Œç¼–è¾‘å…ƒæ•°æ®ã€‚</li>
<li>å¯åœ¨ <a href="https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods">https://github.com/SiatMMLab/Awesome-Diffusion-Model-Based-Image-Editing-Methods</a> è·å–ç›¸å…³ä»£ç ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘ï¼šç»¼è¿°</li>
<li>ä½œè€…ï¼šYi Huangã€Jiancheng Huangã€Yifan Liuã€Mingfu Yanã€Jiaxi Lvã€Jianzhuang Liuã€Wei Xiongã€He Zhangã€Shifeng Chenã€Liangliang Cao</li>
<li>å•ä½ï¼šæ·±åœ³å…ˆè¿›æŠ€æœ¯ç ”ç©¶é™¢</li>
<li>å…³é”®è¯ï¼šDiffusion Modelã€Image Editingã€AIGC</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17525
Githubï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1)ï¼šéšç€äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æŠ€æœ¯çš„å‘å±•ï¼ŒAI ç”Ÿæˆçš„å†…å®¹ï¼ˆAIGCï¼‰é¢†åŸŸè“¬å‹ƒå‘å±•ï¼Œå›¾åƒç¼–è¾‘ä½œä¸ºå…¶ä¸­ä¸€é¡¹é‡è¦ä»»åŠ¡ï¼Œåœ¨æ•°å­—åª’ä½“ã€å¹¿å‘Šå’Œç§‘å­¦ç ”ç©¶ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚
(2)ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿‘å¹´æ¥å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å­¦ä¹ é€æ­¥ç»™å›¾åƒæ·»åŠ å™ªå£°å¹¶é€†è½¬è¿™ä¸€è¿‡ç¨‹ï¼Œå¯ä»¥ä»å¤æ‚åˆ†å¸ƒä¸­ç”Ÿæˆé«˜è´¨é‡çš„æ ·æœ¬ã€‚
(3)ï¼šæœ¬æ–‡å¯¹åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œä»å­¦ä¹ ç­–ç•¥ã€ç”¨æˆ·è¾“å…¥æ¡ä»¶å’Œå…·ä½“ç¼–è¾‘ä»»åŠ¡ç­‰å¤šä¸ªè§’åº¦å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œäº†æ·±å…¥åˆ†æå’Œåˆ†ç±»ã€‚
(4)ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•åœ¨å›¾åƒä¿®å¤ã€å›¾åƒå¤–å»¶ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„åŸºå‡† EditEval å’Œä¸€ä¸ªåˆ›æ–°çš„æŒ‡æ ‡ LMMScore æ¥è¿›ä¸€æ­¥è¯„ä¼°æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç®—æ³•çš„æ€§èƒ½ã€‚</li>
</ol>
<p>7.Methods:
(1): åŸºäºCLIPæŒ‡å¯¼çš„å›¾åƒç¼–è¾‘ï¼šDiffusionCLIPã€Asyrpã€EffDiffã€DiffStylerã€StyleDiffusionã€UNIT-DDPMã€CycleNetã€DiffusionAutoencodersã€HDAEã€EGSDEã€Pixel-GuidedDiffusionï¼›
(2): åŸºäºå‚è€ƒå’Œå±æ€§æŒ‡å¯¼çš„å›¾åƒç¼–è¾‘ï¼šPbEã€RICã€ObjectStitchã€PhDã€DreamInpainterã€Anydoorã€FADINGã€PAIRDiffusionã€SmartBrushã€IIR-Netï¼›
(3): åŸºäºæŒ‡ä»¤æŒ‡å¯¼çš„å›¾åƒç¼–è¾‘ï¼šInstructPix2Pixã€MoEControllerã€FoIã€LOFIEã€InstructDiffusionã€EmuEditã€DialogPaintã€Inst-Inpaintã€HIVEã€ImageBrushã€InstructAny2Pixã€MGIEã€SmartEditã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œå¯¹åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œä»å¤šä¸ªè§’åº¦å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œäº†æ·±å…¥åˆ†æå’Œåˆ†ç±»ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„åŸºå‡† EditEval å’Œä¸€ä¸ªåˆ›æ–°çš„æŒ‡æ ‡ LMMScore æ¥è¿›ä¸€æ­¥è¯„ä¼°æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç®—æ³•çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒç¼–è¾‘åŸºå‡† EditEval å’Œä¸€ä¸ªåˆ›æ–°çš„æŒ‡æ ‡ LMMScoreï¼Œç”¨äºè¯„ä¼°æ–‡æœ¬å¼•å¯¼å›¾åƒç¼–è¾‘ç®—æ³•çš„æ€§èƒ½ã€‚</li>
<li>å¯¹åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°å’Œåˆ†ç±»ï¼Œä»å­¦ä¹ ç­–ç•¥ã€ç”¨æˆ·è¾“å…¥æ¡ä»¶å’Œå…·ä½“ç¼–è¾‘ä»»åŠ¡ç­‰å¤šä¸ªè§’åº¦å¯¹ç°æœ‰å·¥ä½œè¿›è¡Œäº†æ·±å…¥åˆ†æã€‚</li>
<li>æ¢ç´¢äº†è¿™äº›æ–¹æ³•åœ¨å¢å¼ºç¼–è¾‘æ€§èƒ½æ–¹é¢çš„è´¡çŒ®ã€‚</li>
<li>åœ¨æˆ‘ä»¬çš„å›¾åƒç¼–è¾‘åŸºå‡† EditEval ä¸­å¯¹ 7 é¡¹ä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ï¼Œä»¥åŠæœ€æ–°æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>æ€»ç»“äº†å›¾åƒç¼–è¾‘é¢†åŸŸçš„å¹¿æ³›æ½œåŠ›ï¼Œå¹¶æå‡ºäº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚</li>
<li>æ€§èƒ½ï¼šåœ¨ EditEval åŸºå‡†ä¸Šï¼ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•åœ¨å›¾åƒä¿®å¤ã€å›¾åƒå¤–å»¶ç­‰ä»»åŠ¡ä¸Šå–å¾—äº†å¾ˆå¥½çš„æ•ˆæœã€‚</li>
<li>å·¥ä½œé‡ï¼šæœ¬æ–‡å¯¹è¶…è¿‡ 100 ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„å›¾åƒç¼–è¾‘æ–¹æ³•è¿›è¡Œäº†ç»¼è¿°å’Œåˆ†ç±»ï¼Œå¹¶å¯¹ 7 é¡¹ä»»åŠ¡è¿›è¡Œäº†è¯„ä¼°ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4c52565ddb49dad37f10475b00a6abbc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4537d5996d9b29f71e82d00a227227b7.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db76ba27193f9ab6b62bab161a239510.jpg" align="middle">
</details>




<h2 id="Enhancing-Hyperspectral-Images-via-Diffusion-Model-and-Group-Autoencoder-Super-resolution-Network"><a href="#Enhancing-Hyperspectral-Images-via-Diffusion-Model-and-Group-Autoencoder-Super-resolution-Network" class="headerlink" title="Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder   Super-resolution Network"></a>Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder   Super-resolution Network</h2><p><strong>Authors:Zhaoyang Wang, Dongyang Li, Mingyang Zhang, Hao Luo, Maoguo Gong</strong></p>
<p>Existing hyperspectral image (HSI) super-resolution (SR) methods struggle to effectively capture the complex spectral-spatial relationships and low-level details, while diffusion models represent a promising generative model known for their exceptional performance in modeling complex relations and learning high and low-level visual features. The direct application of diffusion models to HSI SR is hampered by challenges such as difficulties in model convergence and protracted inference time. In this work, we introduce a novel Group-Autoencoder (GAE) framework that synergistically combines with the diffusion model to construct a highly effective HSI SR model (DMGASR). Our proposed GAE framework encodes high-dimensional HSI data into low-dimensional latent space where the diffusion model works, thereby alleviating the difficulty of training the diffusion model while maintaining band correlation and considerably reducing inference time. Experimental results on both natural and remote sensing hyperspectral datasets demonstrate that the proposed method is superior to other state-of-the-art methods both visually and metrically. </p>
<p><a href="http://arxiv.org/abs/2402.17285v1">PDF</a> Accepted by AAAI2024</p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹ä¸ç¾¤ç»„è‡ªç¼–ç å™¨ç›¸ç»“åˆçš„åˆ›æ–°æ¡†æ¶ï¼Œæœ‰æ•ˆæå‡é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œæ˜¾è‘—æ”¹å–„è°±ç©ºå…³ç³»å»ºæ¨¡å’Œä½å±‚ç»†èŠ‚æ¢å¤ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹æ“…é•¿å»ºæ¨¡å¤æ‚å…³ç³»å’Œå­¦ä¹ è§†è§‰ç‰¹å¾ï¼Œåœ¨é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­æ½œåŠ›å·¨å¤§ã€‚</li>
<li>è®­ç»ƒæ‰©æ•£æ¨¡å‹é¢ä¸´æ”¶æ•›å›°éš¾å’Œæ¨ç†æ—¶é—´é•¿æŒ‘æˆ˜ã€‚</li>
<li>ç¾¤ç»„è‡ªç¼–ç å™¨æ¡†æ¶é€šè¿‡å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç åˆ°ä½ç»´æ½œåœ¨ç©ºé—´ï¼Œç¼“è§£äº†æ‰©æ•£æ¨¡å‹è®­ç»ƒéš¾åº¦ï¼Œå¹¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹ä¸ç¾¤ç»„è‡ªç¼–ç å™¨ç›¸ç»“åˆï¼Œæœ‰æ•ˆè§£å†³äº†æ¨ç†æ—¶é—´é—®é¢˜ã€‚</li>
<li>åœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰å’Œåº¦é‡ä¸Šå‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„è¶…åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒå¢å¼º</li>
<li>ä½œè€…ï¼šç‹å…†é˜³ï¼Œæä¸œé˜³ï¼Œå¼ æ˜é˜³ï¼Œç½—æµ©ï¼Œå·©èŒ‚å›½</li>
<li>éš¶å±å•ä½ï¼šè¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦ååŒæ™ºèƒ½ç³»ç»Ÿæ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šé«˜å…‰è°±å›¾åƒï¼Œè¶…åˆ†è¾¨ç‡ï¼Œæ‰©æ•£æ¨¡å‹ï¼Œç»„è‡ªç¼–ç å™¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17285</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•æ‰å¤æ‚çš„å…‰è°±-ç©ºé—´å…³ç³»å’Œä½çº§ç»†èŠ‚ï¼Œè€Œæ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§æœ‰å‰é€”çš„ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å…¶åœ¨å»ºæ¨¡å¤æ‚å…³ç³»å’Œå­¦ä¹ é«˜ä½çº§è§†è§‰ç‰¹å¾æ–¹é¢çš„å‡ºè‰²æ€§èƒ½è€Œé—»åã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šå°†æ‰©æ•£æ¨¡å‹ç›´æ¥åº”ç”¨äºé«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡é¢ä¸´ç€æ¨¡å‹æ”¶æ•›å›°éš¾å’Œæ¨ç†æ—¶é—´é•¿çš„æŒ‘æˆ˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§æ–°çš„ç»„è‡ªç¼–ç å™¨ï¼ˆGAEï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸æ‰©æ•£æ¨¡å‹ååŒç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªé«˜æ•ˆçš„é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼ˆDMGASRï¼‰ã€‚æå‡ºçš„ GAE æ¡†æ¶å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç ä¸ºä½ç»´æ½œåœ¨ç©ºé—´ï¼Œæ‰©æ•£æ¨¡å‹åœ¨æ­¤ç©ºé—´ä¸­å·¥ä½œï¼Œä»è€Œç¼“è§£äº†è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„éš¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§å¹¶å¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨è§†è§‰å’Œåº¦é‡ä¸Šéƒ½ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„è¶…åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒå¢å¼ºæ¨¡å‹ï¼ˆDMGASRï¼‰ï¼›
(2): è¯¥æ¨¡å‹é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ–¹å¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨ç¼–ç å™¨å’Œæ‰©æ•£è¶…åˆ†è¾¨ç‡æ¨¡å‹ï¼›
(3): é‡‡ç”¨è°±åˆ†ç»„ç­–ç•¥å’Œéå¯¹ç§°è§£ç å™¨è®¾è®¡ï¼Œæœ‰æ•ˆåœ°å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç ä¸ºä½ç»´æ½œåœ¨ç©ºé—´ï¼›
(4): è®­ç»ƒæ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­å·¥ä½œï¼Œç¼“è§£äº†è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„éš¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§å¹¶å¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ï¼›
(5): è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨é‡æ„è¾“å…¥æ•°æ®ï¼Œç”Ÿæˆä¸€ç³»åˆ—éšè—å˜é‡ï¼›
(6): å°†ä½åˆ†è¾¨ç‡éšè—å˜é‡ä½œä¸ºæ¡ä»¶ä¿¡æ¯ï¼Œä¸é«˜åˆ†è¾¨ç‡éšè—å˜é‡ä¸²è”ï¼Œåœ¨å»å™ªè¿‡ç¨‹ä¸­åŠ å…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼›
(7): é‡‡ç”¨ U-Net ä½œä¸ºå»å™ªæ¨¡å‹ï¼Œè¿­ä»£å»é™¤å™ªå£°ï¼Œç”Ÿæˆè¶…åˆ†è¾¨ç‡æ½œåœ¨å˜é‡åˆ—è¡¨ï¼›
(8): å°†è¶…åˆ†è¾¨ç‡æ½œåœ¨å˜é‡åˆ—è¡¨ä¼ é€’ç»™è§£ç å™¨ï¼Œç”Ÿæˆè¶…åˆ†è¾¨ç‡å›¾åƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„é«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡å¢å¼ºæ¨¡å‹ï¼ˆDMGASRï¼‰ï¼Œè¯¥æ¨¡å‹å°†æ‰©æ•£æ¨¡å‹ä¸è‡ªåŠ¨ç¼–ç å™¨ç›¸ç»“åˆï¼Œæœ‰æ•ˆè§£å†³äº†æ‰©æ•£æ¨¡å‹åœ¨é«˜ç»´æ•°æ®ä¸Šæ”¶æ•›å›°éš¾çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡åœ¨ä½ç»´æ½œåœ¨ç©ºé—´ä¸­è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œå¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ã€‚è¯¥æ–¹æ³•åœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨è§†è§‰å’Œåº¦é‡ä¸Šå‡ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹å’Œç»„è‡ªç¼–ç å™¨çš„è¶…åˆ†è¾¨ç‡é«˜å…‰è°±å›¾åƒå¢å¼ºæ¨¡å‹ï¼ˆDMGASRï¼‰ã€‚</li>
<li>é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæ–¹å¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨ç¼–ç å™¨å’Œæ‰©æ•£è¶…åˆ†è¾¨ç‡æ¨¡å‹ã€‚</li>
<li>é‡‡ç”¨è°±åˆ†ç»„ç­–ç•¥å’Œéå¯¹ç§°è§£ç å™¨è®¾è®¡ï¼Œæœ‰æ•ˆåœ°å°†é«˜ç»´é«˜å…‰è°±æ•°æ®ç¼–ç ä¸ºä½ç»´æ½œåœ¨ç©ºé—´ã€‚</li>
<li>è®­ç»ƒæ‰©æ•£æ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­å·¥ä½œï¼Œç¼“è§£äº†è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„éš¾åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ³¢æ®µç›¸å…³æ€§å¹¶å¤§å¤§å‡å°‘äº†æ¨ç†æ—¶é—´ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨è‡ªç„¶å’Œé¥æ„Ÿé«˜å…‰è°±æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
<li>åœ¨è§†è§‰å’Œåº¦é‡ä¸Šå‡ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ç®—æ³•è®¾è®¡å’Œå®ç°ã€‚</li>
<li>æ•°æ®é›†çš„æ”¶é›†å’Œé¢„å¤„ç†ã€‚</li>
<li>å®éªŒçš„è¿›è¡Œå’Œç»“æœåˆ†æã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-1b637edd1829307f3889177173204f7c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-cc3237f0ece24500c44086801ebc1feb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a3e331ea518a2b9c151178e17f115708.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7b211209593777f9420f6bb845daa71b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f24696c9c22f22b6e487ce2e6fc31ec7.jpg" align="middle">
</details>




<h2 id="One-Shot-Structure-Aware-Stylized-Image-Synthesis"><a href="#One-Shot-Structure-Aware-Stylized-Image-Synthesis" class="headerlink" title="One-Shot Structure-Aware Stylized Image Synthesis"></a>One-Shot Structure-Aware Stylized Image Synthesis</h2><p><strong>Authors:Hansam Cho, Jonghyun Lee, Seunggyu Chang, Yonghyun Jeong</strong></p>
<p>While GAN-based models have been successful in image stylization tasks, they often struggle with structure preservation while stylizing a wide range of input images. Recently, diffusion models have been adopted for image stylization but still lack the capability to maintain the original quality of input images. Building on this, we propose OSASIS: a novel one-shot stylization method that is robust in structure preservation. We show that OSASIS is able to effectively disentangle the semantics from the structure of an image, allowing it to control the level of content and style implemented to a given input. We apply OSASIS to various experimental settings, including stylization with out-of-domain reference images and stylization with text-driven manipulation. Results show that OSASIS outperforms other stylization methods, especially for input images that were rarely encountered during training, providing a promising solution to stylization via diffusion models. </p>
<p><a href="http://arxiv.org/abs/2402.17275v1">PDF</a> CVPR 2024</p>
<p><strong>Summary</strong><br>åŸºäºæ‰©æ•£æ¨¡å‹çš„ OSASIS å®ç°äº†å›¾åƒé£æ ¼åŒ–ï¼ŒåŒæ—¶ä¿æŒäº†ç»“æ„å®Œæ•´æ€§ï¼Œå³ä½¿æ˜¯å¯¹è®­ç»ƒä¸­å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>OSASIS é‡‡ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒé£æ ¼åŒ–ï¼Œè§£å†³äº† GAN æ¨¡å‹åœ¨ä¿æŒç»“æ„æ–¹é¢çš„ä¸è¶³ã€‚</li>
<li>OSASIS èƒ½å¤Ÿæœ‰æ•ˆåˆ†ç¦»å›¾åƒè¯­ä¹‰å’Œç»“æ„ï¼Œå¯æ§åœ°è°ƒæ•´ç»™å®šè¾“å…¥çš„å†…å®¹å’Œé£æ ¼çº§åˆ«ã€‚</li>
<li>OSASIS åœ¨å„ç§å®éªŒè®¾ç½®ä¸­è¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŸŸå¤–å‚è€ƒå›¾åƒè¿›è¡Œé£æ ¼åŒ–å’Œä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æ“ä½œè¿›è¡Œé£æ ¼åŒ–ã€‚</li>
<li>ä¸å…¶ä»–é£æ ¼åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒOSASIS åœ¨è®­ç»ƒä¸­å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒä¸Šè¡¨ç°å¾—å°¤ä¸ºå‡ºè‰²ï¼Œä¸ºé€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼åŒ–æä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</li>
<li>OSASIS é‡‡ç”¨äº†æ¸è¿›å¼è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡ä»æ·»åŠ å™ªå£°åˆ°æ¢å¤å›¾åƒï¼Œé€æ­¥å°†é£æ ¼åº”ç”¨äºè¾“å…¥ã€‚</li>
<li>OSASIS ä½¿ç”¨é¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œæé«˜äº†æ•ˆç‡å’Œæ³›åŒ–æ€§ã€‚</li>
<li>OSASIS åœ¨å›¾åƒé£æ ¼åŒ–é¢†åŸŸå±•ç°å‡ºäº†å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å›¾åƒç¼–è¾‘ã€è‰ºæœ¯åˆ›ä½œå’Œè§†é¢‘å¤„ç†ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šå•æ¬¡ç»“æ„æ„ŸçŸ¥é£æ ¼åŒ–å›¾åƒåˆæˆ</li>
<li>ä½œè€…ï¼šJongmin Lee*, Jaeyeon Kang, Sangwoo Mo, Seongwon Leeâ€ , Kyoung Mu Leeâ€ </li>
<li>éš¶å±å•ä½ï¼šNAVER Cloud</li>
<li>å…³é”®è¯ï¼šå›¾åƒé£æ ¼åŒ–ã€æ‰©æ•£æ¨¡å‹ã€ç»“æ„ä¿æŒ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.05447, Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šGAN æ¨¡å‹åœ¨å›¾åƒé£æ ¼åŒ–ä»»åŠ¡ä¸­å–å¾—æˆåŠŸï¼Œä½†éš¾ä»¥åœ¨é£æ ¼åŒ–å„ç§è¾“å…¥å›¾åƒæ—¶ä¿æŒç»“æ„ã€‚æœ€è¿‘ï¼Œæ‰©æ•£æ¨¡å‹è¢«ç”¨äºå›¾åƒé£æ ¼åŒ–ï¼Œä½†ä»ç¼ºä¹ä¿æŒè¾“å…¥å›¾åƒåŸå§‹è´¨é‡çš„èƒ½åŠ›ã€‚
(2) è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šè¿‡å»æ–¹æ³•åŒ…æ‹¬åŸºäº GAN çš„æ¨¡å‹å’ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ã€‚GAN æ¨¡å‹éš¾ä»¥ä¿æŒç»“æ„ï¼Œè€ŒåŸºäºæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ç¼ºä¹æ§åˆ¶å†…å®¹å’Œé£æ ¼çš„èƒ½åŠ›ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å•æ¬¡é£æ ¼åŒ–æ–¹æ³• OSASISï¼Œè¯¥æ–¹æ³•åœ¨ç»“æ„ä¿æŒæ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚OSASIS é€šè¿‡å°†è¯­ä¹‰ä»å›¾åƒçš„ç»“æ„ä¸­è§£è€¦ï¼Œä»è€Œæœ‰æ•ˆåœ°æ§åˆ¶åº”ç”¨äºç»™å®šè¾“å…¥çš„å†…å®¹å’Œé£æ ¼çš„çº§åˆ«ã€‚
(4) ä»»åŠ¡å’Œæ€§èƒ½ï¼šOSASIS åœ¨å„ç§å®éªŒè®¾ç½®ä¸­å¾—åˆ°åº”ç”¨ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŸŸå¤–å‚è€ƒå›¾åƒçš„é£æ ¼åŒ–å’Œä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æ“ä½œçš„é£æ ¼åŒ–ã€‚ç»“æœè¡¨æ˜ï¼ŒOSASIS ä¼˜äºå…¶ä»–é£æ ¼åŒ–æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹äºåœ¨è®­ç»ƒæœŸé—´å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒï¼Œä¸ºé€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼åŒ–æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚</li>
</ol>
<p><strong>Methodsï¼š</strong></p>
<ol>
<li><strong>å›¾åƒåˆ†è§£ï¼š</strong>å°†è¾“å…¥å›¾åƒåˆ†è§£ä¸ºå†…å®¹å’Œç»“æ„ç‰¹å¾ï¼Œå…¶ä¸­å†…å®¹ç‰¹å¾è¡¨ç¤ºå›¾åƒçš„è¯­ä¹‰ä¿¡æ¯ï¼Œè€Œç»“æ„ç‰¹å¾è¡¨ç¤ºå›¾åƒçš„å‡ ä½•å½¢çŠ¶å’Œçº¹ç†ã€‚</li>
<li><strong>é£æ ¼åµŒå…¥ï¼š</strong>å°†å‚è€ƒé£æ ¼å›¾åƒåµŒå…¥åˆ°ä¸€ä¸ªæ½œåœ¨ç©ºé—´ä¸­ï¼Œè¯¥ç©ºé—´ç”±æ‰©æ•£æ¨¡å‹è®­ç»ƒã€‚</li>
<li><strong>é£æ ¼ä¼ è¾“ï¼š</strong>å°†è¾“å…¥å›¾åƒçš„å†…å®¹ç‰¹å¾ä¸å‚è€ƒé£æ ¼çš„é£æ ¼åµŒå…¥ç›¸ç»“åˆï¼Œç”Ÿæˆä¸€ä¸ªæ–°çš„å›¾åƒï¼Œè¯¥å›¾åƒå…·æœ‰è¾“å…¥å›¾åƒçš„ç»“æ„å’Œå‚è€ƒé£æ ¼çš„é£æ ¼ã€‚</li>
<li>
<p><strong>ç»“æ„ä¿æŒï¼š</strong>é€šè¿‡ä½¿ç”¨ä¸€ä¸ªé¢å¤–çš„æŸå¤±å‡½æ•°ï¼Œå°†è¾“å…¥å›¾åƒçš„ç»“æ„ç‰¹å¾ä¸ç”Ÿæˆå›¾åƒçš„ç»“æ„ç‰¹å¾è¿›è¡ŒåŒ¹é…ï¼Œä»è€Œä¿æŒè¾“å…¥å›¾åƒçš„åŸå§‹è´¨é‡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°å‹å•æ¬¡å›¾åƒé£æ ¼åŒ–æ–¹æ³• OSASISï¼Œè¯¥æ–¹æ³•åœ¨ç»“æ„ä¿æŒæ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚ä¸åŸºäº GAN å’Œå…¶ä»–åŸºäºæ‰©æ•£çš„é£æ ¼åŒ–æ–¹æ³•ç›¸æ¯”ï¼ŒOSASIS å±•ç¤ºäº†åœ¨é£æ ¼åŒ–ä¸­å¯¹ç»“æ„çš„å¼ºå¤§æ„ŸçŸ¥ï¼Œæœ‰æ•ˆåœ°å°†å›¾åƒçš„ç»“æ„å’Œè¯­ä¹‰è§£è€¦ã€‚å°½ç®¡ OSASIS åœ¨ç»“æ„æ„ŸçŸ¥é£æ ¼åŒ–æ–¹é¢å–å¾—äº†é‡å¤§è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸€äº›å±€é™æ€§ã€‚OSASIS çš„ä¸€ä¸ªæ˜¾ç€é™åˆ¶æ˜¯å…¶è®­ç»ƒæ—¶é—´ï¼Œæ¯”æ¯”è¾ƒæ–¹æ³•æ›´é•¿ã€‚è¿™ç§å»¶é•¿çš„è®­ç»ƒæŒç»­æ—¶é—´æ˜¯ä¸ºäº†æ¢å–è¯¥æ–¹æ³•å¢å¼ºäº†ä¿æŒç»“æ„å®Œæ•´æ€§å’Œé€‚åº”å„ç§é£æ ¼çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒOSASIS éœ€è¦é’ˆå¯¹æ¯å¼ é£æ ¼å›¾åƒè¿›è¡Œè®­ç»ƒã€‚åœ¨éœ€è¦è·¨å¤šç§é£æ ¼å¿«é€Ÿéƒ¨ç½²çš„åœºæ™¯ä¸­ï¼Œè¿™ä¸€è¦æ±‚å¯ä»¥è¢«è§†ä¸ºä¸€ç§é™åˆ¶ã€‚å°½ç®¡å­˜åœ¨è¿™äº›æŒ‘æˆ˜ï¼Œä½† OSASIS åœ¨ä¿æŒè¾“å…¥å›¾åƒç»“æ„å®Œæ•´æ€§æ–¹é¢çš„ç¨³å¥æ€§ã€å…¶åœ¨åŸŸå¤–å‚è€ƒé£æ ¼åŒ–ä¸­çš„æœ‰æ•ˆæ€§ä»¥åŠå…¶åœ¨æ–‡æœ¬é©±åŠ¨æ“ä½œä¸­çš„é€‚åº”æ€§ä½¿å…¶æˆä¸ºé£æ ¼åŒ–å›¾åƒåˆæˆé¢†åŸŸä¸­ä¸€ç§å¾ˆæœ‰å‰æ™¯çš„æ–¹æ³•ã€‚æœªæ¥çš„å·¥ä½œå°†è§£å†³è¿™äº›é™åˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¼˜åŒ–è®­ç»ƒæ•ˆç‡å’Œå‡å°‘å¯¹å•ä¸ªé£æ ¼å›¾åƒè®­ç»ƒçš„å¿…è¦æ€§æ–¹é¢ï¼Œä»¥å¢å¼º OSASIS åœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„å®ç”¨æ€§å’Œé€‚ç”¨æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒé£æ ¼åŒ–æ–¹æ³• OSASISï¼Œè¯¥æ–¹æ³•åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œåœ¨ç»“æ„ä¿æŒæ–¹é¢å…·æœ‰é²æ£’æ€§ã€‚</li>
<li>OSASIS é€šè¿‡å°†å›¾åƒçš„ç»“æ„å’Œè¯­ä¹‰è§£è€¦ï¼Œæœ‰æ•ˆåœ°æ§åˆ¶åº”ç”¨äºç»™å®šè¾“å…¥çš„å†…å®¹å’Œé£æ ¼çš„çº§åˆ«ã€‚</li>
<li>OSASIS åœ¨å„ç§å®éªŒè®¾ç½®ä¸­å¾—åˆ°åº”ç”¨ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŸŸå¤–å‚è€ƒå›¾åƒçš„é£æ ¼åŒ–å’Œä½¿ç”¨æ–‡æœ¬é©±åŠ¨çš„æ“ä½œçš„é£æ ¼åŒ–ã€‚
æ€§èƒ½ï¼š</li>
<li>OSASIS åœ¨ç»“æ„ä¿æŒæ–¹é¢ä¼˜äºå…¶ä»–é£æ ¼åŒ–æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹äºåœ¨è®­ç»ƒæœŸé—´å¾ˆå°‘é‡åˆ°çš„è¾“å…¥å›¾åƒã€‚</li>
<li>OSASIS ä¸ºé€šè¿‡æ‰©æ•£æ¨¡å‹è¿›è¡Œé£æ ¼åŒ–æä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆã€‚
å·¥ä½œé‡ï¼š</li>
<li>OSASIS çš„è®­ç»ƒæ—¶é—´æ¯”æ¯”è¾ƒæ–¹æ³•æ›´é•¿ã€‚</li>
<li>OSASIS éœ€è¦é’ˆå¯¹æ¯å¼ é£æ ¼å›¾åƒè¿›è¡Œè®­ç»ƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-957518995345024bb9a18f0e683a4e55.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d0f3cefa16e52b2bb0bdbb679863e234.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4e8afc30904c2bad1400fb9f044e33a9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f0eead50e28d5ed02ff0105780a9e22e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b842ecc40528644a1d824a5a8948f487.jpg" align="middle">
</details>




<h2 id="Playground-v2-5-Three-Insights-towards-Enhancing-Aesthetic-Quality-in-Text-to-Image-Generation"><a href="#Playground-v2-5-Three-Insights-towards-Enhancing-Aesthetic-Quality-in-Text-to-Image-Generation" class="headerlink" title="Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in   Text-to-Image Generation"></a>Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in   Text-to-Image Generation</h2><p><strong>Authors:Daiqing Li, Aleks Kamko, Ehsan Akhgari, Ali Sabet, Linmiao Xu, Suhail Doshi</strong></p>
<p>In this work, we share three insights for achieving state-of-the-art aesthetic quality in text-to-image generative models. We focus on three critical aspects for model improvement: enhancing color and contrast, improving generation across multiple aspect ratios, and improving human-centric fine details. First, we delve into the significance of the noise schedule in training a diffusion model, demonstrating its profound impact on realism and visual fidelity. Second, we address the challenge of accommodating various aspect ratios in image generation, emphasizing the importance of preparing a balanced bucketed dataset. Lastly, we investigate the crucial role of aligning model outputs with human preferences, ensuring that generated images resonate with human perceptual expectations. Through extensive analysis and experiments, Playground v2.5 demonstrates state-of-the-art performance in terms of aesthetic quality under various conditions and aspect ratios, outperforming both widely-used open-source models like SDXL and Playground v2, and closed-source commercial systems such as DALLE 3 and Midjourney v5.2. Our model is open-source, and we hope the development of Playground v2.5 provides valuable guidelines for researchers aiming to elevate the aesthetic quality of diffusion-based image generation models. </p>
<p><a href="http://arxiv.org/abs/2402.17245v1">PDF</a> Model weights:   <a href="https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic">https://huggingface.co/playgroundai/playground-v2.5-1024px-aesthetic</a></p>
<p><strong>Summary</strong><br>é€šè¿‡å¯¹å™ªå£°æ—¶é—´è¡¨ã€å®½é«˜æ¯”å‡†å¤‡å’Œé¢å‘äººç±»çš„å¾®è°ƒçš„ç ”ç©¶ï¼ŒPlayground v2.5  diffusion æ¨¡å‹å¯äº§ç”Ÿæä½³çš„ç¾å­¦è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>å™ªéŸ³æ—¶é—´è¡¨å¯¹æ¨¡å‹çœŸå®æ€§å’Œè§†è§‰ä¿çœŸåº¦è‡³å…³é‡è¦ã€‚</li>
<li>å¹³è¡¡çš„åˆ†åŒºæ•°æ®é›†å¯æ”¹å–„ä¸åŒå®½é«˜æ¯”çš„å›¾åƒç”Ÿæˆã€‚</li>
<li>å°†æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½ç›¸ç»“åˆå¯æå‡å›¾åƒçš„å…±é¸£æ•ˆæœã€‚</li>
<li>Playground v2.5 åœ¨å„ç§æ¡ä»¶å’Œå®½é«˜æ¯”ä¸‹è¡¨ç°å‡ºæœ€å…ˆè¿›çš„å®¡ç¾è´¨é‡ã€‚</li>
<li>Playground v2.5 æ¨¡å‹å¼€æºï¼Œä¸ºæå‡åŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆæ¨¡å‹çš„å®¡ç¾è´¨é‡æä¾›äº†æœ‰ä»·å€¼çš„æŒ‡å¯¼ã€‚</li>
<li>Playground v2.5 ä¼˜äº SDXLã€Playground v2ã€DALLE 3 å’Œ Midjourney v5.2ã€‚</li>
<li>ç ”ç©¶æœ‰åŠ©äºæé«˜åŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆæ¨¡å‹çš„å®¡ç¾è´¨é‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šPlayground v2.5ï¼šæå‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå®¡ç¾è´¨é‡çš„ä¸‰ç‚¹è§è§£</li>
<li>ä½œè€…ï¼šDaiqing Liã€Aleks Kamkoã€Ehsan Akhgariã€Ali Sabetã€Linmiao Xuã€Suhail Doshi</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šPlayground Research</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€å®¡ç¾è´¨é‡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šarXiv:2402.17245v1[cs.CV]</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒçš„å®¡ç¾è´¨é‡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ä¸€äº›æŒ‘æˆ˜ï¼Œå¦‚é¢œè‰²å’Œå¯¹æ¯”åº¦ä¸è¶³ã€ä¸åŒå®½é«˜æ¯”ç”Ÿæˆè´¨é‡ä¸ä½³ã€ç¼ºä¹å¯¹äººç±»åå¥½çš„å¯¹é½ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šä»¥å¾€æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ”¹è¿›æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå¦‚ä¼˜åŒ–å™ªå£°è°ƒåº¦æˆ–ä½¿ç”¨æ›´å¤§çš„æ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨æå‡å®¡ç¾è´¨é‡æ–¹é¢æ•ˆæœæœ‰é™ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸‰ç‚¹è§è§£æ¥æå‡å®¡ç¾è´¨é‡ï¼šæ”¹è¿›å™ªå£°è°ƒåº¦ä»¥å¢å¼ºé¢œè‰²å’Œå¯¹æ¯”åº¦ï¼Œæ„å»ºå¹³è¡¡çš„åˆ†æ¡¶æ•°æ®é›†ä»¥æ”¯æŒä¸åŒå®½é«˜æ¯”çš„ç”Ÿæˆï¼Œä»¥åŠåˆ©ç”¨äººç±»åé¦ˆæ¥å¯¹é½æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨å¹¿æ³›çš„åˆ†æå’Œå®éªŒä¸­ï¼ŒPlayground v2.5 åœ¨å„ç§æ¡ä»¶å’Œå®½é«˜æ¯”ä¸‹å±•ç¤ºäº†æœ€å…ˆè¿›çš„å®¡ç¾è´¨é‡ï¼Œä¼˜äº SDXLã€Playground v2 ç­‰å¼€æºæ¨¡å‹å’Œ DALLÂ·E 3ã€Midjourney v5.2 ç­‰é—­æºå•†ä¸šç³»ç»Ÿã€‚</li>
</ol>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ”¹è¿›å™ªå£°è°ƒåº¦ï¼šé‡‡ç”¨ EDM æ¡†æ¶å’Œæ›´å™ªå£°çš„è°ƒåº¦æ–¹å¼ï¼Œå¢å¼ºå›¾åƒè‰²å½©å’Œå¯¹æ¯”åº¦ã€‚
ï¼ˆ2ï¼‰å¹³è¡¡åˆ†æ¡¶æ•°æ®é›†ï¼šæ„å»ºåŒ…å«ä¸åŒå®½é«˜æ¯”å›¾åƒçš„åˆ†æ¡¶æ•°æ®é›†ï¼Œæ”¯æŒå¤šç§å®½é«˜æ¯”çš„ç”Ÿæˆã€‚
ï¼ˆ3ï¼‰åˆ©ç”¨äººç±»åé¦ˆï¼šä½¿ç”¨äººç±»è¯„çº§ç³»ç»Ÿè‡ªåŠ¨ç­›é€‰é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨è¿­ä»£è®­ç»ƒæ–¹æ³•ï¼Œæ ¹æ®äººç±»åå¥½å¯¹é½æ¨¡å‹è¾“å‡ºã€‚</p>
<ol>
<li>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡º Playground v2.5ï¼Œè¯¥æ¨¡å‹é€šè¿‡æ”¹è¿›å™ªå£°è°ƒåº¦ã€æ„å»ºå¹³è¡¡çš„åˆ†æ¡¶æ•°æ®é›†å’Œåˆ©ç”¨äººç±»åé¦ˆç­‰ä¸‰ç‚¹è§è§£ï¼Œæå‡äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„å®¡ç¾è´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼š
åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å™ªå£°è°ƒåº¦æ¡†æ¶ï¼Œå¢å¼ºäº†å›¾åƒçš„è‰²å½©å’Œå¯¹æ¯”åº¦ã€‚</li>
<li>æ„å»ºäº†ä¸€ä¸ªåŒ…å«ä¸åŒå®½é«˜æ¯”å›¾åƒçš„åˆ†æ¡¶æ•°æ®é›†ï¼Œæ”¯æŒå¤šç§å®½é«˜æ¯”çš„ç”Ÿæˆã€‚</li>
<li>åˆ©ç”¨äººç±»è¯„çº§ç³»ç»Ÿè‡ªåŠ¨ç­›é€‰é«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨è¿­ä»£è®­ç»ƒæ–¹æ³•ï¼Œæ ¹æ®äººç±»åå¥½å¯¹é½æ¨¡å‹è¾“å‡ºã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¹¿æ³›çš„åˆ†æå’Œå®éªŒä¸­ï¼ŒPlayground v2.5 åœ¨å„ç§æ¡ä»¶å’Œå®½é«˜æ¯”ä¸‹å±•ç¤ºäº†æœ€å…ˆè¿›çš„å®¡ç¾è´¨é‡ï¼Œä¼˜äºå…¶ä»–å¼€æºå’Œé—­æºæ¨¡å‹ã€‚</li>
<li>Playground v2.5 åœ¨å¢å¼ºå›¾åƒè‰²å½©å’Œå¯¹æ¯”åº¦ã€ç”Ÿæˆä¸åŒå®½é«˜æ¯”çš„é«˜è´¨é‡å›¾åƒä»¥åŠå¯¹é½æ¨¡å‹è¾“å‡ºä¸äººç±»åå¥½æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆäººç‰©å›¾åƒçš„ç²¾ç»†ç»†èŠ‚æ–¹é¢ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ¨¡å‹å·²å¼€æºï¼Œç”¨æˆ·å¯ä»¥åœ¨ Playground äº§å“ç½‘ç«™ä¸Šä½¿ç”¨ã€‚</li>
<li>Playground v2.5 çš„æƒé‡å·²åœ¨ Hugging Face ä¸Šå¼€æºã€‚</li>
<li>Playground å°†ç»§ç»­æä¾›æ‰©å±•ï¼Œä»¥ä¾¿åœ¨ A1111 å’Œ ComfyUI ç­‰æµè¡Œç¤¾åŒºå·¥å…·ä¸­ä½¿ç”¨ Playground v2.5ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b9ee43af14ab727bc293d7a249e6d156.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ff95dbf16b9c2e734124d2c99954b6c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b62a3df3bac0ff8ef7d20dfeccb0f6b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-869a1d35fa675595c5662a91b215c366.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-226f377d76bcd81c0c005d4e513c6f81.jpg" align="middle">
</details>




<h2 id="SAM-DiffSR-Structure-Modulated-Diffusion-Model-for-Image-Super-Resolution"><a href="#SAM-DiffSR-Structure-Modulated-Diffusion-Model-for-Image-Super-Resolution" class="headerlink" title="SAM-DiffSR: Structure-Modulated Diffusion Model for Image   Super-Resolution"></a>SAM-DiffSR: Structure-Modulated Diffusion Model for Image   Super-Resolution</h2><p><strong>Authors:Chengcheng Wang, Zhiwei Hao, Yehui Tang, Jianyuan Guo, Yujie Yang, Kai Han, Yunhe Wang</strong></p>
<p>Diffusion-based super-resolution (SR) models have recently garnered significant attention due to their potent restoration capabilities. But conventional diffusion models perform noise sampling from a single distribution, constraining their ability to handle real-world scenes and complex textures across semantic regions. With the success of segment anything model (SAM), generating sufficiently fine-grained region masks can enhance the detail recovery of diffusion-based SR model. However, directly integrating SAM into SR models will result in much higher computational cost. In this paper, we propose the SAM-DiffSR model, which can utilize the fine-grained structure information from SAM in the process of sampling noise to improve the image quality without additional computational cost during inference. In the process of training, we encode structural position information into the segmentation mask from SAM. Then the encoded mask is integrated into the forward diffusion process by modulating it to the sampled noise. This adjustment allows us to independently adapt the noise mean within each corresponding segmentation area. The diffusion model is trained to estimate this modulated noise. Crucially, our proposed framework does NOT change the reverse diffusion process and does NOT require SAM at inference. Experimental results demonstrate the effectiveness of our proposed method, showcasing superior performance in suppressing artifacts, and surpassing existing diffusion-based methods by 0.74 dB at the maximum in terms of PSNR on DIV2K dataset. The code and dataset are available at <a href="https://github.com/lose4578/SAM-DiffSR">https://github.com/lose4578/SAM-DiffSR</a>. </p>
<p><a href="http://arxiv.org/abs/2402.17133v1">PDF</a> </p>
<p><strong>Summary</strong><br>åŸºäºæ‰©æ•£çš„è¶…åˆ†è¾¨ç‡æ¨¡å‹ä¸­ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„SAM-DiffSRæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨SAMçš„ç²¾ç»†ç»“æ„ä¿¡æ¯åœ¨é‡‡æ ·å™ªå£°çš„è¿‡ç¨‹ä¸­æ¥æ”¹å–„æœ€ç»ˆå›¾åƒè´¨é‡ï¼Œè€Œæ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦SAMï¼Œæœ‰æ•ˆé™ä½äº†è®¡ç®—æˆæœ¬ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§SAM-DiffSRæ¨¡å‹ï¼Œå¯ä»¥åˆ©ç”¨SAMçš„ç²¾ç»†ç»“æ„ä¿¡æ¯æ¥æ”¹å–„å›¾åƒè´¨é‡ã€‚</li>
<li>SAM-DiffSRæ¨¡å‹é€šè¿‡å°†ç¼–ç çš„æ©ç æ•´åˆåˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œåœ¨é‡‡æ ·å™ªå£°ä¹‹å‰è¿›è¡Œè°ƒæ•´ã€‚</li>
<li>è¯¥è°ƒæ•´å…è®¸ç‹¬ç«‹è°ƒæ•´æ¯ä¸ªå¯¹åº”åˆ†å‰²åŒºåŸŸå†…çš„å™ªå£°å‡å€¼ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹è¢«è®­ç»ƒæ¥ä¼°è®¡è¿™ç§è°ƒåˆ¶çš„å™ªå£°ã€‚</li>
<li>æ‰€æå‡ºçš„æ–¹æ³•ä¸æ”¹å˜åå‘æ‰©æ•£è¿‡ç¨‹ï¼Œå¹¶ä¸”åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸éœ€è¦SAMã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°æŠ‘åˆ¶äº†ä¼ªå½±ï¼Œåœ¨DIV2Kæ•°æ®é›†ä¸Šä»¥PSNRæŒ‡æ ‡è¶…è¶Šäº†ç°æœ‰çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•0.74 dBã€‚</li>
<li>ä»£ç å’Œæ•°æ®é›†å¯åœ¨<a href="https://github.com/lose4578/SAM-DiffSRè·å¾—ã€‚">https://github.com/lose4578/SAM-DiffSRè·å¾—ã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šSAM-DiffSRï¼šç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡çš„ç»“æ„è°ƒåˆ¶æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šChengcheng Wangã€Zhiwei Haoã€Yehui Tangã€Jianyuan Guoã€Yujie Yangã€Kai Hanã€Yunhe Wang</li>
<li>å•ä½ï¼šåä¸ºè¯ºäºšæ–¹èˆŸå®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡ã€æ‰©æ•£æ¨¡å‹ã€ç»“æ„è°ƒåˆ¶</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.17133
   Githubï¼šhttps://github.com/lose4578/SAM-DiffSR</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
   æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä¼ ç»Ÿæ‰©æ•£æ¨¡å‹ä»å•ä¸€åˆ†å¸ƒä¸­è¿›è¡Œå™ªå£°é‡‡æ ·ï¼Œé™åˆ¶äº†å…¶å¤„ç†çœŸå®åœºæ™¯å’Œè·¨è¯­ä¹‰åŒºåŸŸå¤æ‚çº¹ç†çš„èƒ½åŠ›ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š
   Segment Anything Modelï¼ˆSAMï¼‰èƒ½ç”Ÿæˆè¶³å¤Ÿç²¾ç»†çš„åŒºåŸŸæ©ç ï¼Œå¢å¼ºæ‰©æ•£æ¨¡å‹çš„ç»†èŠ‚æ¢å¤èƒ½åŠ›ã€‚ä½†ç›´æ¥å°† SAM é›†æˆåˆ° SR æ¨¡å‹ä¸­ä¼šå¤§å¹…å¢åŠ è®¡ç®—æˆæœ¬ã€‚</p>
<p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š
   æå‡º SAM-DiffSR æ¨¡å‹ï¼Œåœ¨å™ªå£°é‡‡æ ·è¿‡ç¨‹ä¸­åˆ©ç”¨ SAM çš„ç²¾ç»†ç»“æ„ä¿¡æ¯ï¼Œåœ¨ä¸å¢åŠ æ¨ç†è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹æé«˜å›¾åƒè´¨é‡ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå°†ç»“æ„ä½ç½®ä¿¡æ¯ç¼–ç åˆ° SAM çš„åˆ†å‰²æ©ç ä¸­ã€‚ç„¶åå°†ç¼–ç åçš„æ©ç é›†æˆåˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œå°†å…¶è°ƒåˆ¶åˆ°é‡‡æ ·çš„å™ªå£°ä¸­ã€‚è¿™ç§è°ƒæ•´å…è®¸åœ¨æ¯ä¸ªå¯¹åº”çš„åˆ†å‰²åŒºåŸŸå†…ç‹¬ç«‹è°ƒæ•´å™ªå£°å‡å€¼ã€‚æ‰©æ•£æ¨¡å‹è¢«è®­ç»ƒæ¥ä¼°è®¡è¿™ç§è°ƒåˆ¶çš„å™ªå£°ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š
   å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•æœ‰æ•ˆï¼Œåœ¨æŠ‘åˆ¶ä¼ªå½±æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ï¼Œåœ¨ DIV2K æ•°æ®é›†ä¸Šä»¥ PSNR è¡¡é‡ï¼Œæ¯”ç°æœ‰çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æé«˜äº† 0.74dBã€‚è¯¥æ–¹æ³•çš„æ€§èƒ½æ”¯æŒå…¶ç›®æ ‡ã€‚</p>
<p><strong>Methodsï¼š</strong></p>
<p>(1) åˆ©ç”¨ SegmentAnythingModelï¼ˆSAMï¼‰ç”Ÿæˆç²¾ç»†çš„åŒºåŸŸæ©ç ï¼Œç¼–ç ç»“æ„ä½ç½®ä¿¡æ¯ã€‚</p>
<p>(2) å°†ç¼–ç åçš„æ©ç é›†æˆåˆ°å‰å‘æ‰©æ•£è¿‡ç¨‹ä¸­ï¼Œè°ƒåˆ¶é‡‡æ ·çš„å™ªå£°ã€‚</p>
<p>(3) è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¼°è®¡è°ƒåˆ¶çš„å™ªå£°ï¼Œä»è€Œåœ¨æ¯ä¸ªåˆ†å‰²åŒºåŸŸå†…ç‹¬ç«‹è°ƒæ•´å™ªå£°å‡å€¼ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é‡ç‚¹é€šè¿‡é›†æˆ SAMï¼Œå¢å¼ºåŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡æ¨¡å‹çš„ç»“æ„å±‚æ¬¡ä¿¡æ¯æ¢å¤èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåä¸º SAM-DiffSR çš„æ¡†æ¶ï¼Œå®ƒæ¶‰åŠå°†ç»“æ„ä½ç½®ä¿¡æ¯çº³å…¥ SAM ç”Ÿæˆçš„æ©ç ï¼Œç„¶ååœ¨æ­£å‘æ‰©æ•£è¿‡ç¨‹ä¸­å°†å…¶æ·»åŠ åˆ°é‡‡æ ·çš„å™ªå£°ä¸­ã€‚æ­¤æ“ä½œå•ç‹¬è°ƒèŠ‚æ¯ä¸ªç›¸åº”åˆ†å‰²åŒºåŸŸä¸­å™ªå£°çš„å‡å€¼ï¼Œä»è€Œå°†ç»“æ„å±‚æ¬¡çŸ¥è¯†æ³¨å…¥æ‰©æ•£æ¨¡å‹ã€‚é€šè¿‡é‡‡ç”¨è¿™ç§æ–¹æ³•ï¼Œè®­ç»ƒåçš„æ¨¡å‹åœ¨æ¢å¤ç»“æ„ç»†èŠ‚å’ŒæŠ‘åˆ¶å›¾åƒä¼ªå½±æ–¹é¢è¡¨ç°å‡ºæ”¹è¿›ï¼Œè€Œæ— éœ€äº§ç”Ÿä»»ä½•é¢å¤–çš„æ¨ç†æˆæœ¬ã€‚æˆ‘ä»¬çš„æ–¹æ³•çš„æœ‰æ•ˆæ€§é€šè¿‡åœ¨å¸¸ç”¨çš„å›¾åƒè¶…åˆ†è¾¨ç‡åŸºå‡†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒå¾—åˆ°è¯å®ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šåˆ©ç”¨ SAM æ³¨å…¥ç»“æ„ä¿¡æ¯ï¼Œå¢å¼ºæ‰©æ•£æ¨¡å‹çš„ç»“æ„æ¢å¤èƒ½åŠ›ï¼›
æ€§èƒ½ï¼šåœ¨æŠ‘åˆ¶ä¼ªå½±å’Œæ¢å¤ç»“æ„ç»†èŠ‚æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼›
å·¥ä½œé‡ï¼šæ¨ç†æˆæœ¬ä¸åŸºçº¿æ¨¡å‹ç›¸å½“ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-9a754ccd89139d7dc6a576434e6b119e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0906797fab629c359270ce611fcb26d4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-66893d51d835b7965b76fb168b66db51.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f1f36de01723e09ebef0661e0e152ae2.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9bca3bdea09d0b0b3c4c6b041a3c1758.jpg" align="middle">
</details>




<h2 id="Cross-Modal-Contextualized-Diffusion-Models-for-Text-Guided-Visual-Generation-and-Editing"><a href="#Cross-Modal-Contextualized-Diffusion-Models-for-Text-Guided-Visual-Generation-and-Editing" class="headerlink" title="Cross-Modal Contextualized Diffusion Models for Text-Guided Visual   Generation and Editing"></a>Cross-Modal Contextualized Diffusion Models for Text-Guided Visual   Generation and Editing</h2><p><strong>Authors:Ling Yang, Zhilong Zhang, Zhaochen Yu, Jingwei Liu, Minkai Xu, Stefano Ermon, Bin Cui</strong></p>
<p>Conditional diffusion models have exhibited superior performance in high-fidelity text-guided visual generation and editing. Nevertheless, prevailing text-guided visual diffusion models primarily focus on incorporating text-visual relationships exclusively into the reverse process, often disregarding their relevance in the forward process. This inconsistency between forward and reverse processes may limit the precise conveyance of textual semantics in visual synthesis results. To address this issue, we propose a novel and general contextualized diffusion model (ContextDiff) by incorporating the cross-modal context encompassing interactions and alignments between text condition and visual sample into forward and reverse processes. We propagate this context to all timesteps in the two processes to adapt their trajectories, thereby facilitating cross-modal conditional modeling. We generalize our contextualized diffusion to both DDPMs and DDIMs with theoretical derivations, and demonstrate the effectiveness of our model in evaluations with two challenging tasks: text-to-image generation, and text-to-video editing. In each task, our ContextDiff achieves new state-of-the-art performance, significantly enhancing the semantic alignment between text condition and generated samples, as evidenced by quantitative and qualitative evaluations. Our code is available at <a href="https://github.com/YangLing0818/ContextDiff">https://github.com/YangLing0818/ContextDiff</a> </p>
<p><a href="http://arxiv.org/abs/2402.16627v1">PDF</a> ICLR 2024. Project: <a href="https://github.com/YangLing0818/ContextDiff">https://github.com/YangLing0818/ContextDiff</a></p>
<p><strong>Summary</strong><br>ä¸Šä¸‹æ–‡æ‰©æ•£æ¨¡å‹é€šè¿‡åœ¨æ‰©æ•£æ­£åè¿‡ç¨‹ä¸­åŠ å…¥æ–‡æœ¬å¯è§†å…³ç³»ï¼Œæå‡äº†æ–‡æœ¬å¼•å¯¼å¯è§†åŒ–ç”Ÿæˆå’Œç¼–è¾‘çš„è¯­ä¹‰å¯¹é½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬å¼•å¯¼å¯è§†åŒ–ç”Ÿæˆå’Œç¼–è¾‘ä¸­è¡¨ç°ä¼˜è¶Šã€‚</li>
<li>ä¼ ç»Ÿæ¨¡å‹åªå°†æ–‡æœ¬å¯è§†å…³ç³»èå…¥åå‘è¿‡ç¨‹ï¼Œå¿½ç•¥äº†æ­£å‘è¿‡ç¨‹çš„å…³è”æ€§ã€‚</li>
<li>æ­£åè¿‡ç¨‹çš„ä¸ä¸€è‡´æ€§é™åˆ¶äº†æ–‡æœ¬è¯­ä¹‰åœ¨å¯è§†åŒ–åˆæˆç»“æœä¸­çš„ä¼ é€’ç²¾åº¦ã€‚</li>
<li>è¯­ä¹‰æ‰©æ•£æ¨¡å‹é€šè¿‡å°†æ–‡æœ¬æ¡ä»¶å’Œå¯è§†æ ·æœ¬ä¹‹é—´çš„äº¤äº’å’Œå¯¹é½çº³å…¥æ­£åè¿‡ç¨‹ï¼Œæ”¹å–„äº†è¿™ç§ä¸ä¸€è‡´æ€§ã€‚</li>
<li>æ”¹è¿›é€‚ç”¨äº DDPM å’Œ DDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨ç†å¾—åˆ°è¯æ˜ã€‚</li>
<li>åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä»»åŠ¡ä¸­ï¼Œè¯­ä¹‰æ‰©æ•£æ¨¡å‹å‡è¾¾åˆ°æ–°çš„æœ€ä½³æ€§èƒ½ã€‚</li>
<li>å®šé‡å’Œå®šæ€§è¯„ä¼°è¡¨æ˜è¯­ä¹‰æ‰©æ•£æ¨¡å‹æ˜¾è‘—æå‡äº†æ–‡æœ¬æ¡ä»¶å’Œç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šè·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ç”¨äºæ–‡æœ¬å¼•å¯¼çš„è§†è§‰ç”Ÿæˆå’Œç¼–è¾‘</li>
<li>ä½œè€…ï¼šæ¨å‡Œã€å¼ å¿—é¾™ã€äºå…†å®¸ã€åˆ˜æ™¯ä¼Ÿã€å¾æ˜å‡¯ã€Stefano Ermonã€å´”æ–Œ</li>
<li>éš¶å±ï¼šåŒ—äº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬å¼•å¯¼è§†è§‰ç”Ÿæˆã€æ–‡æœ¬å¼•å¯¼è§†é¢‘ç¼–è¾‘ã€æ‰©æ•£æ¨¡å‹ã€è¯­å¢ƒåŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.16627
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
   (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬å¼•å¯¼è§†è§‰ç”Ÿæˆå’Œç¼–è¾‘é¢†åŸŸè¡¨ç°ä¼˜å¼‚ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å°†æ–‡æœ¬-è§†è§‰å…³ç³»èå…¥é€†è¿‡ç¨‹ï¼Œå¿½è§†äº†å…¶åœ¨å‰å‘è¿‡ç¨‹ä¸­çš„ç›¸å…³æ€§ï¼Œå¯¼è‡´æ–‡æœ¬è¯­ä¹‰åœ¨è§†è§‰åˆæˆç»“æœä¸­çš„ç²¾ç¡®ä¼ è¾¾å—åˆ°é™åˆ¶ã€‚
   (2)ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š</p>
<ul>
<li>å¿½ç•¥äº†æ–‡æœ¬-è§†è§‰å…³ç³»åœ¨å‰å‘è¿‡ç¨‹ä¸­çš„ä½œç”¨ï¼Œå¯¼è‡´æ–‡æœ¬è¯­ä¹‰åœ¨è§†è§‰åˆæˆç»“æœä¸­çš„ç²¾ç¡®ä¼ è¾¾å—é™ã€‚</li>
<li>ç¼ºä¹ä¸€ç§é€šç”¨çš„è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼Œæ— æ³•åŒæ—¶å¤„ç†æ–‡æœ¬å¼•å¯¼å›¾åƒå’Œè§†é¢‘ç”Ÿæˆ/ç¼–è¾‘ä»»åŠ¡ã€‚
   (3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼ˆCONTEXTDIFFï¼‰ï¼Œé€šè¿‡å°†è·¨æ¨¡æ€è¯­å¢ƒï¼ˆåŒ…å«æ–‡æœ¬æ¡ä»¶å’Œè§†è§‰æ ·æœ¬ä¹‹é—´çš„äº¤äº’å’Œå¯¹é½ï¼‰èå…¥å‰å‘å’Œé€†è¿‡ç¨‹æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œå°†è¯¥è¯­å¢ƒä¼ æ’­åˆ°ä¸¤ä¸ªè¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ—¶é—´æ­¥ï¼Œä»¥é€‚åº”å®ƒä»¬çš„è½¨è¿¹ï¼Œä»è€Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ã€‚åŒæ—¶ï¼Œå°†è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹æ¨å¹¿åˆ° DDPM å’Œ DDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚
   (4)ï¼šä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šï¼ŒCONTEXTDIFF å‡å–å¾—äº†æ–°çš„ SOTA æ€§èƒ½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ–‡æœ¬æ¡ä»¶ä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ï¼Œå®šé‡å’Œå®šæ€§è¯„ä¼°å‡è¯æ˜äº†è¿™ä¸€ç‚¹ã€‚</li>
</ul>
</li>
<li>
<p>Methods:
(1): æå‡ºè·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼ˆCONTEXTDIFFï¼‰ï¼Œå°†è·¨æ¨¡æ€è¯­å¢ƒï¼ˆåŒ…å«æ–‡æœ¬æ¡ä»¶å’Œè§†è§‰æ ·æœ¬ä¹‹é—´çš„äº¤äº’å’Œå¯¹é½ï¼‰èå…¥å‰å‘å’Œé€†è¿‡ç¨‹ï¼Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ï¼›
(2): å°†è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹æ¨å¹¿åˆ°DDPMå’ŒDDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ï¼›
(3): åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä¸¤ä¸ªä»»åŠ¡ä¸Šï¼ŒCONTEXTDIFFå‡å–å¾—äº†æ–°çš„SOTAæ€§èƒ½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ–‡æœ¬æ¡ä»¶ä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆCONTEXTDIFFï¼‰ï¼Œé€šè¿‡å°†è·¨æ¨¡æ€è¯­å¢ƒä¼ æ’­åˆ°æ‰©æ•£å’Œé€†è¿‡ç¨‹ä¸­çš„æ‰€æœ‰æ—¶é—´æ­¥ï¼Œå¹¶é€‚åº”å®ƒä»¬çš„è½¨è¿¹ï¼Œä»è€Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ã€‚æˆ‘ä»¬å°†ä¸Šä¸‹æ–‡åŒ–è½¨è¿¹é€‚é…å™¨æ¨å¹¿åˆ° DDPM å’Œ DDIMï¼Œå¹¶é€šè¿‡ç†è®ºæ¨å¯¼è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘è¿™ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šï¼ŒCONTEXTDIFF å§‹ç»ˆè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¸¤é¡¹ä»»åŠ¡çš„å¹¿æ³›å®šé‡å’Œå®šæ€§ç»“æœè¯æ˜äº†æˆ‘ä»¬æå‡ºçš„è·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§æ–°é¢–çš„è·¨æ¨¡æ€è¯­å¢ƒåŒ–æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å°†è·¨æ¨¡æ€è¯­å¢ƒèå…¥æ‰©æ•£å’Œé€†è¿‡ç¨‹ï¼Œä¿ƒè¿›è·¨æ¨¡æ€æ¡ä»¶å»ºæ¨¡ã€‚
æ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬åˆ°è§†é¢‘ç¼–è¾‘ä¸¤ä¸ªä»»åŠ¡ä¸Šè¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—å¢å¼ºäº†æ–‡æœ¬æ¡ä»¶ä¸ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚
å·¥ä½œé‡ï¼šå·¥ä½œé‡è¾ƒå¤§ï¼Œéœ€è¦å¯¹æ‰©æ•£æ¨¡å‹å’Œè·¨æ¨¡æ€è¯­å¢ƒåŒ–è¿›è¡Œæ·±å…¥ç†è§£ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0bc30cb1ebccfebfcc1ffd4ee246c26b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-64adb5f655a12b089618a5496f3cd332.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f01bc8ec645d09757f45be018ce1fe96.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8a622ae5ed900b07d2994967a2269c23.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-0d264d770c3a4265052827f62ee48f0b.jpg" align="middle">
</details>




<h2 id="Placing-Objects-in-Context-via-Inpainting-for-Out-of-distribution-Segmentation"><a href="#Placing-Objects-in-Context-via-Inpainting-for-Out-of-distribution-Segmentation" class="headerlink" title="Placing Objects in Context via Inpainting for Out-of-distribution   Segmentation"></a>Placing Objects in Context via Inpainting for Out-of-distribution   Segmentation</h2><p><strong>Authors:Pau de Jorge, Riccardo Volpi, Puneet K. Dokania, Philip H. S. Torr, Gregory Rogez</strong></p>
<p>When deploying a semantic segmentation model into the real world, it will inevitably be confronted with semantic classes unseen during training. Thus, to safely deploy such systems, it is crucial to accurately evaluate and improve their anomaly segmentation capabilities. However, acquiring and labelling semantic segmentation data is expensive and unanticipated conditions are long-tail and potentially hazardous. Indeed, existing anomaly segmentation datasets capture a limited number of anomalies, lack realism or have strong domain shifts. In this paper, we propose the Placing Objects in Context (POC) pipeline to realistically add any object into any image via diffusion models. POC can be used to easily extend any dataset with an arbitrary number of objects. In our experiments, we present different anomaly segmentation datasets based on POC-generated data and show that POC can improve the performance of recent state-of-the-art anomaly fine-tuning methods in several standardized benchmarks. POC is also effective to learn new classes. For example, we use it to edit Cityscapes samples by adding a subset of Pascal classes and show that models trained on such data achieve comparable performance to the Pascal-trained baseline. This corroborates the low sim-to-real gap of models trained on POC-generated images. </p>
<p><a href="http://arxiv.org/abs/2402.16392v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä½¿ç”¨æ‰©æ•£æ¨¡å‹å°†å¯¹è±¡æ’å…¥ä¸Šä¸‹æ–‡(POC)ç®¡é“ï¼Œå¯çœŸå®åœ°å‘å›¾åƒä¸­æ·»åŠ ä»»ä½•å¯¹è±¡ï¼Œæœ‰æ•ˆæ‰©å±•æ•°æ®é›†å’Œæ”¹å–„å¼‚å¸¸åˆ†å‰²æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨æ‰©æ•£æ¨¡å‹æ„å»ºPOCç®¡é“ï¼Œå¯å‘å›¾åƒä¸­çœŸå®åœ°æ·»åŠ ä»»æ„å¯¹è±¡ã€‚</li>
<li>POCèƒ½è½»æ¾æ‰©å±•æ•°æ®é›†ï¼Œæ·»åŠ ä»»æ„æ•°é‡çš„å¯¹è±¡ã€‚</li>
<li>POCç”Ÿæˆçš„å¼‚å¸¸åˆ†å‰²æ•°æ®é›†æ¯”ç°æœ‰æ•°æ®é›†æ›´çœŸå®ã€å…¨é¢ã€‚</li>
<li>POCèƒ½æå‡æœ€æ–°å¼‚å¸¸ç²¾è°ƒæ–¹æ³•åœ¨åŸºå‡†æµ‹è¯•ä¸­çš„æ€§èƒ½ã€‚</li>
<li>POCå¯ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ï¼Œå¦‚å°†Pascalç±»åˆ«æ·»åŠ åˆ°Cityscapesã€‚</li>
<li>åŸºäºPOCç”Ÿæˆå›¾åƒè®­ç»ƒçš„æ¨¡å‹ï¼Œå…¶ä»¿çœŸåˆ°çœŸå®å·®è·ä½ã€‚</li>
<li>POCç®¡é“èƒ½å¤Ÿæé«˜æ¨¡å‹åº”å¯¹æœªè§è¯­ä¹‰ç±»åˆ«çš„èƒ½åŠ›ï¼Œå¢å¼ºå¼‚å¸¸åˆ†å‰²æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p>1.æ ‡é¢˜ï¼šé€šè¿‡å›¾åƒä¿®å¤å°†å¯¹è±¡ç½®äºä¸Šä¸‹æ–‡ä¸­ä»¥è¿›è¡Œåˆ†å¸ƒå¤–åˆ†å‰²
2.ä½œè€…ï¼šPaude Jorgeâ€ , Riccardo Volpiâ€ , Puneet K. Dokaniaâ€¡, Philip H.S. Torrâ€¡, GrÃ©gory Rogezâ€ 
3.æ‰€å±æœºæ„ï¼šNAVERLABS æ¬§æ´²ï¼Œç‰›æ´¥å¤§å­¦
4.å…³é”®è¯ï¼šå¼‚å¸¸åˆ†å‰²ã€åˆ†å¸ƒå¤–æ£€æµ‹ã€å›¾åƒä¿®å¤ã€è¯­ä¹‰åˆ†å‰²ã€å¼€æ”¾è¯æ±‡åˆ†å‰²
5.é“¾æ¥ï¼šhttps://github.com/naver/poc
6.æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šåœ¨ç°å®ä¸–ç•Œä¸­éƒ¨ç½²è¯­ä¹‰åˆ†å‰²æ¨¡å‹æ—¶ï¼Œæ¨¡å‹ä¸å¯é¿å…åœ°ä¼šé‡åˆ°è®­ç»ƒæœŸé—´æœªè§è¿‡çš„è¯­ä¹‰ç±»åˆ«ã€‚å› æ­¤ï¼Œä¸ºäº†å®‰å…¨åœ°éƒ¨ç½²æ­¤ç±»ç³»ç»Ÿï¼Œå‡†ç¡®è¯„ä¼°å’Œæé«˜å…¶å¼‚å¸¸åˆ†å‰²èƒ½åŠ›è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè·å–å’Œæ ‡è®°è¯­ä¹‰åˆ†å‰²æ•°æ®ä»£ä»·é«˜æ˜‚ï¼Œè€Œä¸”æ„å¤–æƒ…å†µæ˜¯é•¿å°¾ä¸”å¯èƒ½å…·æœ‰å±é™©æ€§ã€‚å®é™…ä¸Šï¼Œç°æœ‰çš„å¼‚å¸¸åˆ†å‰²æ•°æ®é›†æ•è·çš„å¼‚å¸¸æ•°é‡æœ‰é™ï¼Œç¼ºä¹çœŸå®æ€§æˆ–å…·æœ‰å¾ˆå¼ºçš„åŸŸåç§»ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¾ç½®å¯¹è±¡åœ¨ä¸Šä¸‹æ–‡ï¼ˆPOCï¼‰ç®¡é“ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å°†ä»»ä½•å¯¹è±¡ç°å®åœ°æ·»åŠ åˆ°ä»»ä½•å›¾åƒä¸­ã€‚POC å¯ç”¨äºè½»æ¾åœ°ä½¿ç”¨ä»»æ„æ•°é‡çš„å¯¹è±¡æ‰©å±•ä»»ä½•æ•°æ®é›†ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäº POC ç”Ÿæˆçš„ä¸åŒå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è¡¨æ˜ POC å¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚POC è¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å®ƒé€šè¿‡æ·»åŠ  Pascal ç±»åˆ«çš„å­é›†æ¥ç¼–è¾‘ Cityscapes æ ·æœ¬ï¼Œå¹¶è¡¨æ˜åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸ Pascal è®­ç»ƒçš„åŸºçº¿å®ç°äº†ç›¸å½“çš„æ€§èƒ½ã€‚è¿™è¯å®äº†åœ¨ POC ç”Ÿæˆçš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ä½æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚
(3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šPOC ç®¡é“å»ºç«‹åœ¨å›¾åƒä¿®å¤å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ä¹‹ä¸Šï¼Œå°†ä»»æ„å¯¹è±¡ç°å®åœ°æ’å…¥å›¾åƒä¸­ã€‚ä¿®æ”¹åçš„å›¾åƒå’Œæ©ç å¯ç”¨äºä¸åŒçš„ä»»åŠ¡ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Œè¯¥æ€§èƒ½æ˜¯å¦èƒ½æ”¯æ’‘å…¶ç›®æ ‡ï¼šåœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜åœ¨ POC ç”Ÿæˆçš„å›¾åƒä¸Šè¿›è¡Œå¾®è°ƒå¯ä»¥æ˜¾ç€æé«˜æœ€å…ˆè¿›çš„å¼‚å¸¸åˆ†å‰²æ–¹æ³•çš„æ€§èƒ½â€”â€”ä¼˜äºé€šè¿‡æ ‡å‡†åšæ³•ï¼ˆæ‹¼æ¥ COCO å¯¹è±¡ï¼‰è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†ä¸‰ä¸ªåŸºäº Cityscapes å’Œå…¶ä»–ä¸¤ä¸ªè‡ªåŠ¨é©¾é©¶æ•°æ®é›†çš„ POC ç”Ÿæˆçš„è¯„ä¼°é›†ï¼Œå¹¶åœ¨å…¶ä¸Šå¯¹ä¸åŒçš„å¼‚å¸¸åˆ†å‰²æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ˆæœ‰å…³ç»“æœçš„ç¬¬ä¸€çœ¼ï¼Œè¯·å‚è§å›¾ 1ï¼‰ã€‚æœ€åï¼Œç”±äº POC å¯ä»¥æ·»åŠ ä»»æ„å¯¹è±¡ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å®ƒå¯ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨ç‰©ç±»åˆ«å¢å¼º Cityscapes å›¾åƒå¯¼è‡´ Pascal æµ‹è¯•é›†ä¸Šçš„ 93.14mIoUï¼ˆè€ƒè™‘ç›¸åŒçš„ç±»åˆ«ï¼‰ï¼Œè€Œç›´æ¥åœ¨ Pascal ä¸Šè®­ç»ƒäº§ç”Ÿ 94.75â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨ POC ç¼–è¾‘çš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹äº§ç”Ÿäº†ç›¸å½“å°çš„æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚</p>
<ol>
<li>æ–¹æ³•ï¼š
(1) POCç®¡é“ï¼šPOCç®¡é“ç”±å›¾åƒä¿®å¤æ¨¡å‹å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç»„æˆã€‚å›¾åƒä¿®å¤æ¨¡å‹ç”¨äºå°†å¯¹è±¡ç°å®åœ°æ’å…¥å›¾åƒä¸­ï¼Œè€Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç”¨äºä¸ºæ’å…¥çš„å¯¹è±¡ç”Ÿæˆæ©ç ã€‚ä¿®æ”¹åçš„å›¾åƒå’Œæ©ç å¯ç”¨äºä¸åŒçš„ä»»åŠ¡ï¼Œä¾‹å¦‚å¼‚å¸¸åˆ†å‰²ã€‚
(2) å¼‚å¸¸åˆ†å‰²å¾®è°ƒï¼šPOCç®¡é“å¯ç”¨äºç”Ÿæˆå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ã€‚åœ¨è¿™äº›æ•°æ®é›†ä¸Šå¾®è°ƒå¼‚å¸¸åˆ†å‰²æ¨¡å‹å¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œä¼˜äºé€šè¿‡æ ‡å‡†åšæ³•ï¼ˆæ‹¼æ¥COCOå¯¹è±¡ï¼‰è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚
(3) å­¦ä¹ æ–°ç±»åˆ«ï¼šPOCç®¡é“è¿˜å¯ä»¥ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨ç‰©ç±»åˆ«å¢å¼ºCityscapeså›¾åƒå¯¼è‡´Pascalæµ‹è¯•é›†ä¸Šçš„93.14mIoUï¼ˆè€ƒè™‘ç›¸åŒçš„ç±»åˆ«ï¼‰ï¼Œè€Œç›´æ¥åœ¨Pascalä¸Šè®­ç»ƒäº§ç”Ÿ94.75â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨POCç¼–è¾‘çš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹äº§ç”Ÿäº†ç›¸å½“å°çš„æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚</li>
</ol>
<p>8.ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›
8. ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¾ç½®å¯¹è±¡åœ¨ä¸Šä¸‹æ–‡ï¼ˆPOCï¼‰ç®¡é“ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å°†ä»»æ„å¯¹è±¡ç°å®åœ°æ·»åŠ åˆ°ä»»ä½•å›¾åƒä¸­ã€‚POCå¯ç”¨äºè½»æ¾åœ°ä½¿ç”¨ä»»æ„æ•°é‡çš„å¯¹è±¡æ‰©å±•ä»»ä½•æ•°æ®é›†ã€‚åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäºPOCç”Ÿæˆçš„ä¸åŒå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è¡¨æ˜POCå¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚POCè¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å®ƒé€šè¿‡æ·»åŠ Pascalç±»åˆ«çš„å­é›†æ¥ç¼–è¾‘Cityscapesæ ·æœ¬ï¼Œå¹¶è¡¨æ˜åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸Pascalè®­ç»ƒçš„åŸºçº¿å®ç°äº†ç›¸å½“çš„æ€§èƒ½ã€‚è¿™è¯å®äº†åœ¨POCç”Ÿæˆçš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ä½æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
- æå‡ºäº†ä¸€ç§æ”¾ç½®å¯¹è±¡åœ¨ä¸Šä¸‹æ–‡ï¼ˆPOCï¼‰ç®¡é“ï¼Œé€šè¿‡æ‰©æ•£æ¨¡å‹å°†ä»»æ„å¯¹è±¡ç°å®åœ°æ·»åŠ åˆ°ä»»ä½•å›¾åƒä¸­ã€‚
- POCå¯ç”¨äºè½»æ¾åœ°ä½¿ç”¨ä»»æ„æ•°é‡çš„å¯¹è±¡æ‰©å±•ä»»ä½•æ•°æ®é›†ã€‚
- POCå¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚
- POCè¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚
æ€§èƒ½ï¼š
- åœ¨æˆ‘ä»¬çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†åŸºäºPOCç”Ÿæˆçš„ä¸åŒå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ï¼Œå¹¶è¡¨æ˜POCå¯ä»¥æé«˜å‡ ç§æ ‡å‡†åŸºå‡†ä¸­æœ€è¿‘çš„å¼‚å¸¸ç²¾ç»†è°ƒæ•´æ–¹æ³•çš„æ€§èƒ½ã€‚
- POCè¿˜å¯ä»¥æœ‰æ•ˆåœ°å­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ä½¿ç”¨å®ƒé€šè¿‡æ·»åŠ Pascalç±»åˆ«çš„å­é›†æ¥ç¼–è¾‘Cityscapesæ ·æœ¬ï¼Œå¹¶è¡¨æ˜åœ¨è¿™äº›æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸Pascalè®­ç»ƒçš„åŸºçº¿å®ç°äº†ç›¸å½“çš„æ€§èƒ½ã€‚è¿™è¯å®äº†åœ¨POCç”Ÿæˆçš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹çš„ä½æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚
å·¥ä½œé‡ï¼š
- POCç®¡é“ç”±å›¾åƒä¿®å¤æ¨¡å‹å’Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç»„æˆã€‚å›¾åƒä¿®å¤æ¨¡å‹ç”¨äºå°†å¯¹è±¡ç°å®åœ°æ’å…¥å›¾åƒä¸­ï¼Œè€Œå¼€æ”¾è¯æ±‡åˆ†å‰²æ¨¡å‹ç”¨äºä¸ºæ’å…¥çš„å¯¹è±¡ç”Ÿæˆæ©ç ã€‚
- POCç®¡é“å¯ç”¨äºç”Ÿæˆå¼‚å¸¸åˆ†å‰²æ•°æ®é›†ã€‚åœ¨è¿™äº›æ•°æ®é›†ä¸Šå¾®è°ƒå¼‚å¸¸åˆ†å‰²æ¨¡å‹å¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œä¼˜äºé€šè¿‡æ ‡å‡†åšæ³•ï¼ˆæ‹¼æ¥COCOå¯¹è±¡ï¼‰è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ã€‚
- POCç®¡é“è¿˜å¯ä»¥ç”¨äºå­¦ä¹ æ–°ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨åŠ¨ç‰©ç±»åˆ«å¢å¼ºCityscapeså›¾åƒå¯¼è‡´Pascalæµ‹è¯•é›†ä¸Šçš„93.14mIoUï¼ˆè€ƒè™‘ç›¸åŒçš„ç±»åˆ«ï¼‰ï¼Œè€Œç›´æ¥åœ¨Pascalä¸Šè®­ç»ƒäº§ç”Ÿ94.75â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨POCç¼–è¾‘çš„å›¾åƒä¸Šè®­ç»ƒçš„æ¨¡å‹äº§ç”Ÿäº†ç›¸å½“å°çš„æ¨¡æ‹Ÿåˆ°çœŸå®å·®è·ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-13236ee2bf286b59f5da0689a0363f64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dec0e216eb8083342215a3e4e8c1dc95.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d2067d81b02e8cd7fea592f12fcef21d.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-37aa0eb4c5f86ae9ed22c98b2703f9a5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-84f58d6d1052332176a17f015aaa2d9f.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>Talking Head Generation</title>
    <url>/2024/03/09/Paper/2024-03-09/Talking%20Head%20Generation/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-09-æ›´æ–°"><a href="#2024-03-09-æ›´æ–°" class="headerlink" title="2024-03-09 æ›´æ–°"></a>2024-03-09 æ›´æ–°</h1><h2 id="FaceChain-ImagineID-Freely-Crafting-High-Fidelity-Diverse-Talking-Faces-from-Disentangled-Audio"><a href="#FaceChain-ImagineID-Freely-Crafting-High-Fidelity-Diverse-Talking-Faces-from-Disentangled-Audio" class="headerlink" title="FaceChain-ImagineID: Freely Crafting High-Fidelity Diverse Talking Faces   from Disentangled Audio"></a>FaceChain-ImagineID: Freely Crafting High-Fidelity Diverse Talking Faces   from Disentangled Audio</h2><p><strong>Authors:Chao Xu, Yang Liu, Jiazheng Xing, Weida Wang, Mingze Sun, Jun Dan, Tianxin Huang, Siyuan Li, Zhi-Qi Cheng, Ying Tai, Baigui Sun</strong></p>
<p>In this paper, we abstract the process of people hearing speech, extracting meaningful cues, and creating various dynamically audio-consistent talking faces, termed Listening and Imagining, into the task of high-fidelity diverse talking faces generation from a single audio. Specifically, it involves two critical challenges: one is to effectively decouple identity, content, and emotion from entangled audio, and the other is to maintain intra-video diversity and inter-video consistency. To tackle the issues, we first dig out the intricate relationships among facial factors and simplify the decoupling process, tailoring a Progressive Audio Disentanglement for accurate facial geometry and semantics learning, where each stage incorporates a customized training module responsible for a specific factor. Secondly, to achieve visually diverse and audio-synchronized animation solely from input audio within a single model, we introduce the Controllable Coherent Frame generation, which involves the flexible integration of three trainable adapters with frozen Latent Diffusion Models (LDMs) to focus on maintaining facial geometry and semantics, as well as texture and temporal coherence between frames. In this way, we inherit high-quality diverse generation from LDMs while significantly improving their controllability at a low training cost. Extensive experiments demonstrate the flexibility and effectiveness of our method in handling this paradigm. The codes will be released at <a href="https://github.com/modelscope/facechain">https://github.com/modelscope/facechain</a>. </p>
<p><a href="http://arxiv.org/abs/2403.01901v1">PDF</a> </p>
<p><strong>Summary</strong><br>è†å¬ä¸æƒ³è±¡ä»»åŠ¡ï¼šä»å•éŸ³é¢‘ç”Ÿæˆé«˜ä¿çœŸã€å¤šæ ·çš„ä¼šè¯´è¯çš„é¢å­”ï¼Œè§£å†³äº†èº«ä»½ã€å†…å®¹ã€æƒ…æ„Ÿè§£è€¦å’Œç»´æŒè§†é¢‘å†…å¤šæ ·æ€§ã€è§†é¢‘é—´ä¸€è‡´æ€§çš„åŒé‡æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æŠ½è±¡äººä»¬è†å¬è¯­éŸ³ã€æå–æœ‰æ„ä¹‰çš„çº¿ç´¢å¹¶åˆ›å»ºå„ç§åŠ¨æ€éŸ³é¢‘ä¸€è‡´ä¼šè¯´è¯çš„é¢å­”çš„è¿‡ç¨‹ï¼Œç§°ä¸ºâ€œè†å¬ä¸æƒ³è±¡â€ã€‚</li>
<li>é¢ä¸´èº«ä»½ã€å†…å®¹å’Œæƒ…æ„Ÿä»çº ç¼ éŸ³é¢‘ä¸­æœ‰æ•ˆè§£è€¦å’Œç»´æŒè§†é¢‘å†…å¤šæ ·æ€§ã€è§†é¢‘é—´ä¸€è‡´æ€§ä¸¤å¤§æŒ‘æˆ˜ã€‚</li>
<li>æå‡ºæ¸è¿›å¼éŸ³é¢‘è§£è€¦æ–¹æ³•ï¼Œç”¨äºå‡†ç¡®çš„é¢éƒ¨å‡ ä½•å’Œè¯­ä¹‰å­¦ä¹ ã€‚</li>
<li>å¼•å…¥å¯æ§è¿è´¯å¸§ç”Ÿæˆï¼Œå°†ä¸‰ä¸ªå¯è®­ç»ƒé€‚é…å™¨ä¸å†»ç»“çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çµæ´»é›†æˆï¼Œä»¥ä¸“æ³¨äºä¿æŒé¢éƒ¨å‡ ä½•å’Œè¯­ä¹‰ï¼Œä»¥åŠå¸§ä¹‹é—´çš„çº¹ç†å’Œæ—¶é—´è¿è´¯æ€§ã€‚</li>
<li>ç»§æ‰¿äº† LDM çš„é«˜è´¨é‡å¤šæ ·åŒ–ç”Ÿæˆï¼ŒåŒæ—¶ä»¥ä½è®­ç»ƒæˆæœ¬æ˜¾è‘—æé«˜äº†å®ƒä»¬çš„æ§åˆ¶èƒ½åŠ›ã€‚</li>
<li>å¹¿æ³›çš„å®éªŒè¡¨æ˜äº†è¯¥æ–¹æ³•åœ¨å¤„ç†æ­¤èŒƒå¼æ–¹é¢çš„çµæ´»æ€§å’Œæœ‰æ•ˆæ€§ã€‚</li>
<li>ä»£ç å°†åœ¨ <a href="https://github.com/modelscope/facechain">https://github.com/modelscope/facechain</a> å‘å¸ƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šFaceChain-ImagineIDï¼šè‡ªç”±ç”Ÿæˆé«˜ä¿çœŸå¤šæ ·åŒ–çš„è¯´è¯äººè„¸ï¼ˆäººè„¸é“¾-æƒ³è±¡è¯†åˆ«ï¼šä»åˆ†ç¦»éŸ³é¢‘ä¸­è‡ªç”±ç”Ÿæˆé«˜ä¿çœŸå¤šæ ·åŒ–çš„è¯´è¯äººè„¸ï¼‰</li>
<li>ä½œè€…ï¼šChao Xu, Yang Liu, Jiazheng Xing, Weida Wang, Mingze Sun, Jun Dan, Tianxin Huang, Siyuan Li, Zhi-Qi Cheng, Ying Tai, Baigui Sun</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé˜¿é‡Œå·´å·´é›†å›¢</li>
<li>å…³é”®è¯ï¼šè¯´è¯äººè„¸ç”Ÿæˆã€éŸ³é¢‘åˆ†ç¦»ã€æ§åˆ¶ç”Ÿæˆã€ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.01901</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººè„¸ç”ŸæˆæŠ€æœ¯æ—¨åœ¨æ ¹æ®æä¾›çš„éŸ³é¢‘å’Œå›¾åƒåˆæˆè§†é¢‘ï¼Œå¹¿æ³›åº”ç”¨äºè™šæ‹Ÿäº¤äº’ç­‰å®é™…åœºæ™¯ã€‚ç„¶è€Œï¼Œç”¨æˆ·åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­é¢ä¸´éšç§æ³„éœ²å’Œè™šæ‹Ÿå¤´åƒä¸è‡ªèº«å£°éŸ³ä¸åŒ¹é…çš„å›°å¢ƒã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºä»å›¾åƒä¸­æå–ç‰¹å¾æ¥ç”Ÿæˆè¯´è¯äººè„¸ï¼Œä½†å­˜åœ¨éšç§æ³„éœ²ã€ç”Ÿæˆè´¨é‡ä¸é«˜ç­‰é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„èŒƒå¼â€”â€”è†å¬å’Œæƒ³è±¡ï¼Œå°†äººç±»å¬åˆ°è¯­éŸ³ã€æå–æœ‰æ„ä¹‰çº¿ç´¢å¹¶åˆ›é€ å„ç§åŠ¨æ€éŸ³é¢‘ä¸€è‡´è¯´è¯äººè„¸çš„è¿‡ç¨‹æŠ½è±¡ä¸ºä»å•ä¸ªéŸ³é¢‘ç”Ÿæˆé«˜ä¿çœŸå¤šæ ·åŒ–è¯´è¯äººè„¸çš„ä»»åŠ¡ã€‚è¯¥æ–¹æ³•ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šä¸€æ˜¯æœ‰æ•ˆåœ°ä»çº ç¼ çš„éŸ³é¢‘ä¸­åˆ†ç¦»èº«ä»½ã€å†…å®¹å’Œæƒ…æ„Ÿï¼›äºŒæ˜¯ä¿æŒè§†é¢‘å†…å¤šæ ·æ€§å’Œè§†é¢‘é—´ä¸€è‡´æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡è®¾è®¡äº†ä¸€ç§æ¸è¿›å¼éŸ³é¢‘åˆ†ç¦»æ–¹æ³•ï¼Œç”¨äºå‡†ç¡®å­¦ä¹ äººè„¸å‡ ä½•å’Œè¯­ä¹‰ï¼›å¹¶æå‡ºäº†å¯æ§è¿è´¯å¸§ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å°†ä¸‰ä¸ªå¯è®­ç»ƒé€‚é…å™¨ä¸å†»ç»“çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹çµæ´»é›†æˆï¼Œä¸“æ³¨äºä¿æŒå¸§é—´çš„äººè„¸å‡ ä½•ã€è¯­ä¹‰ã€çº¹ç†å’Œæ—¶é—´è¿è´¯æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨è¯´è¯äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºè‰¯å¥½çš„çµæ´»æ€§ä¸æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒéŸ³é¢‘ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå¯ä»¥ç”Ÿæˆè§†è§‰ä¸Šå¤šæ ·åŒ–çš„é«˜ä¿çœŸè¯´è¯äººè„¸ï¼Œæ»¡è¶³äº†ç”¨æˆ·å¯¹éšç§ä¿æŠ¤å’Œç”Ÿæˆè´¨é‡çš„åŒé‡éœ€æ±‚ã€‚</li>
</ol>
<p>7.Methodsï¼š
(1) æå‡ºæ¸è¿›å¼éŸ³é¢‘åˆ†ç¦»æ–¹æ³•ï¼Œå‡†ç¡®å­¦ä¹ äººè„¸å‡ ä½•å’Œè¯­ä¹‰ã€‚
(2) è®¾è®¡å¯æ§è¿è´¯å¸§ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å°†ä¸‰ä¸ªå¯è®­ç»ƒé€‚é…å™¨ä¸å†»ç»“çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹çµæ´»é›†æˆï¼Œä¿æŒå¸§é—´çš„äººè„¸å‡ ä½•ã€è¯­ä¹‰ã€çº¹ç†å’Œæ—¶é—´è¿è´¯æ€§ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): FaceChain-ImagineID ä¸ºè¯´è¯äººè„¸ç”Ÿæˆé¢†åŸŸæä¾›äº†ä¸€ç§æ–°çš„èŒƒå¼ï¼Œæœ‰æ•ˆåœ°è§£å†³äº†éšç§æ³„éœ²å’Œç”Ÿæˆè´¨é‡ä¸é«˜ç­‰é—®é¢˜ï¼Œæ»¡è¶³äº†ç”¨æˆ·å¯¹éšç§ä¿æŠ¤å’Œç”Ÿæˆè´¨é‡çš„åŒé‡éœ€æ±‚ã€‚
(2): åˆ›æ–°ç‚¹ï¼š<ul>
<li>æå‡ºæ¸è¿›å¼éŸ³é¢‘åˆ†ç¦»æ–¹æ³•ï¼Œå‡†ç¡®å­¦ä¹ äººè„¸å‡ ä½•å’Œè¯­ä¹‰ã€‚</li>
<li>è®¾è®¡å¯æ§è¿è´¯å¸§ç”Ÿæˆæ–¹æ³•ï¼Œé€šè¿‡å°†ä¸‰ä¸ªå¯è®­ç»ƒé€‚é…å™¨ä¸å†»ç»“çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹çµæ´»é›†æˆï¼Œä¿æŒå¸§é—´çš„äººè„¸å‡ ä½•ã€è¯­ä¹‰ã€çº¹ç†å’Œæ—¶é—´è¿è´¯æ€§ã€‚
 æ€§èƒ½ï¼š</li>
<li>åœ¨è¯´è¯äººè„¸ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•å±•ç°å‡ºè‰¯å¥½çš„çµæ´»æ€§ä¸æœ‰æ•ˆæ€§ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒéŸ³é¢‘ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå¯ä»¥ç”Ÿæˆè§†è§‰ä¸Šå¤šæ ·åŒ–çš„é«˜ä¿çœŸè¯´è¯äººè„¸ã€‚
 å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°éœ€è¦è¾ƒé«˜çš„æŠ€æœ¯é—¨æ§›ï¼ŒåŒ…æ‹¬éŸ³é¢‘åˆ†ç¦»ã€ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ç­‰æ–¹é¢çš„çŸ¥è¯†ã€‚</li>
</ul>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f9beb664fee087369a84229a9751302f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f7122e8a5514f08293520b989812bde2.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-bca46fa0ffc8639dfa0117a5baad6ae0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6323f54d35add5790fd10654dbb8dd9d.jpg" align="middle">
</details>




<h2 id="G4G-A-Generic-Framework-for-High-Fidelity-Talking-Face-Generation-with-Fine-grained-Intra-modal-Alignment"><a href="#G4G-A-Generic-Framework-for-High-Fidelity-Talking-Face-Generation-with-Fine-grained-Intra-modal-Alignment" class="headerlink" title="G4G:A Generic Framework for High Fidelity Talking Face Generation with   Fine-grained Intra-modal Alignment"></a>G4G:A Generic Framework for High Fidelity Talking Face Generation with   Fine-grained Intra-modal Alignment</h2><p><strong>Authors:Juan Zhang, Jiahao Chen, Cheng Wang, Zhiwang Yu, Tangquan Qi, Di Wu</strong></p>
<p>Despite numerous completed studies, achieving high fidelity talking face generation with highly synchronized lip movements corresponding to arbitrary audio remains a significant challenge in the field. The shortcomings of published studies continue to confuse many researchers. This paper introduces G4G, a generic framework for high fidelity talking face generation with fine-grained intra-modal alignment. G4G can reenact the high fidelity of original video while producing highly synchronized lip movements regardless of given audio tones or volumes. The key to G4Gâ€™s success is the use of a diagonal matrix to enhance the ordinary alignment of audio-image intra-modal features, which significantly increases the comparative learning between positive and negative samples. Additionally, a multi-scaled supervision module is introduced to comprehensively reenact the perceptional fidelity of original video across the facial region while emphasizing the synchronization of lip movements and the input audio. A fusion network is then used to further fuse the facial region and the rest. Our experimental results demonstrate significant achievements in reenactment of original video quality as well as highly synchronized talking lips. G4G is an outperforming generic framework that can produce talking videos competitively closer to ground truth level than current state-of-the-art methods. </p>
<p><a href="http://arxiv.org/abs/2402.18122v2">PDF</a> </p>
<p><strong>Summary</strong><br>é«˜è´¨é‡ä¼šè¯´è¯å¤´åƒç”Ÿæˆæ¡†æ¶ G4G å¯ç”Ÿæˆé«˜åº¦åŒæ­¥çš„å”‡éƒ¨åŠ¨ä½œï¼Œå®ç°é€¼çœŸè§†é¢‘é‡ç°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>G4G æ¡†æ¶å¯ç”Ÿæˆé«˜åº¦é€¼çœŸçš„ä¼šè¯´è¯å¤´åƒï¼Œå”‡éƒ¨åŠ¨ä½œä¸ä»»æ„éŸ³é¢‘é«˜åº¦åŒæ­¥ã€‚</li>
<li>G4G é‡‡ç”¨å¯¹è§’çŸ©é˜µå¢å¼ºè§†éŸ³é¢‘æ¨¡æ€å†…ç‰¹å¾å¯¹é½ï¼Œæå‡æ­£è´Ÿæ ·æœ¬æ¯”è¾ƒå­¦ä¹ ã€‚</li>
<li>å¤šå°ºåº¦ç›‘ç£æ¨¡å—å…¨é¢é‡ç°è§†é¢‘æ„ŸçŸ¥ä¿çœŸåº¦ï¼Œå¼ºè°ƒå”‡éƒ¨åŠ¨ä½œä¸è¾“å…¥éŸ³é¢‘åŒæ­¥ã€‚</li>
<li>èåˆç½‘ç»œè¿›ä¸€æ­¥èåˆé¢éƒ¨åŒºåŸŸä¸å…¶ä»–åŒºåŸŸã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼ŒG4G åœ¨é‡ç°åŸå§‹è§†é¢‘è´¨é‡å’Œå”‡éƒ¨åŠ¨ä½œåŒæ­¥æ–¹é¢å–å¾—æ˜¾è‘—æˆå°±ã€‚</li>
<li>G4G ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¯ç”Ÿæˆæ›´æ¥è¿‘çœŸå®æ°´å¹³çš„ä¼šè¯´è¯å¤´åƒè§†é¢‘ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><ol><p></p>
<p></p><li>æ ‡é¢˜ï¼šG4Gï¼šä¸€ä¸ªç”¨äºé«˜ä¿çœŸè¯´è¯äººè„¸ç”Ÿæˆå’Œç²¾ç»†åŒ–æ¨¡æ€å†…å¯¹é½çš„é€šç”¨æ¡†æ¶</li><p></p>
<p></p><li>ä½œè€…ï¼šJuan Zhang, Jiahao Chen, Cheng Wang, Zhiwang Yu, Tangquan Qi, Di Wu</li><p></p>
<p></p><li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé•¿æ²™ä¸‡å…´ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸</li><p></p>
<p></p><li>å…³é”®è¯ï¼šè¯´è¯äººè„¸ç”Ÿæˆã€æ¨¡æ€å†…å¯¹é½ã€å¤šå°ºåº¦ç›‘ç£ã€èåˆç½‘ç»œ</li><p></p>
<p></p><li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2402.18122</li><p></p>
<p></p><li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šè¯´è¯äººè„¸ç”Ÿæˆæ—¨åœ¨åˆæˆä¸€ä¸ªç›®æ ‡äººç‰©çš„é«˜ä¿çœŸè§†é¢‘ï¼Œå…¶å”‡éƒ¨åŠ¨ä½œä¸ä»»æ„éŸ³é¢‘åŒæ­¥ã€‚å°½ç®¡æœ‰è®¸å¤šç ”ç©¶ï¼Œä½†è¦å®ç°é«˜ä¿çœŸè¯´è¯äººè„¸ç”Ÿæˆå¹¶ä½¿å…¶å”‡éƒ¨åŠ¨ä½œä¸ä»»æ„éŸ³é¢‘é«˜åº¦åŒæ­¥ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚
(2) è¿‡å»æ–¹æ³•ï¼šä»¥å¾€æ–¹æ³•å­˜åœ¨çš„é—®é¢˜ä¸»è¦åœ¨äºï¼š1ï¼‰æ— æ³•é‡ç°åŸå§‹è§†é¢‘çš„é«˜ä¿çœŸåº¦ï¼›2ï¼‰ç”Ÿæˆçš„å”‡éƒ¨åŠ¨ä½œä¸éŸ³é¢‘ä¸åŒæ­¥ï¼›3ï¼‰ç”Ÿæˆçš„äººè„¸è§†é¢‘ä¿çœŸåº¦ä½ã€‚
(3) ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº† G4Gï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºé«˜ä¿çœŸè¯´è¯äººè„¸ç”Ÿæˆå’Œç²¾ç»†åŒ–æ¨¡æ€å†…å¯¹é½çš„é€šç”¨æ¡†æ¶ã€‚G4G é‡‡ç”¨å¯¹è§’çŸ©é˜µæ¥å¢å¼ºéŸ³é¢‘-å›¾åƒæ¨¡æ€å†…ç‰¹å¾çš„æ™®é€šå¯¹é½ï¼Œæ˜¾è‘—å¢åŠ äº†æ­£è´Ÿæ ·æœ¬ä¹‹é—´çš„æ¯”è¾ƒå­¦ä¹ ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ä¸ªå¤šå°ºåº¦ç›‘ç£æ¨¡å—ï¼Œä»¥å…¨é¢é‡ç°åŸå§‹è§†é¢‘åœ¨é¢éƒ¨åŒºåŸŸçš„æ„ŸçŸ¥ä¿çœŸåº¦ï¼ŒåŒæ—¶å¼ºè°ƒå”‡éƒ¨åŠ¨ä½œä¸è¾“å…¥éŸ³é¢‘çš„åŒæ­¥æ€§ã€‚ç„¶åä½¿ç”¨èåˆç½‘ç»œè¿›ä¸€æ­¥èåˆé¢éƒ¨åŒºåŸŸå’Œå…¶ä»–éƒ¨åˆ†ã€‚
(4) æ€§èƒ½ï¼šG4G åœ¨é‡ç°åŸå§‹è§†é¢‘è´¨é‡å’Œé«˜åº¦åŒæ­¥çš„è¯´è¯äººå˜´å”‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆå°±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒG4G ç”Ÿæˆçš„è¯´è¯äººè§†é¢‘æ¯”å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•æ›´æ¥è¿‘çœŸå®æ°´å¹³ã€‚</li><br>&lt;/ol&gt;<p></p>
<p></p><p>7.Methodsï¼š
(1)ï¼šæå‡ºG4Gæ¡†æ¶ï¼Œé‡‡ç”¨å¯¹è§’çŸ©é˜µå¢å¼ºéŸ³é¢‘-å›¾åƒæ¨¡æ€å†…ç‰¹å¾å¯¹é½ï¼Œå¢åŠ æ­£è´Ÿæ ·æœ¬æ¯”è¾ƒå­¦ä¹ ï¼›
(2)ï¼šå¼•å…¥å¤šå°ºåº¦ç›‘ç£æ¨¡å—ï¼Œé‡ç°åŸå§‹è§†é¢‘é¢éƒ¨åŒºåŸŸæ„ŸçŸ¥ä¿çœŸåº¦ï¼Œå¼ºè°ƒå”‡éƒ¨åŠ¨ä½œä¸éŸ³é¢‘åŒæ­¥ï¼›
(3)ï¼šä½¿ç”¨èåˆç½‘ç»œèåˆé¢éƒ¨åŒºåŸŸå’Œå…¶ä»–éƒ¨åˆ†ã€‚</p><p></p>
<p></p><p><strong>8. ç»“è®º</strong><br>(1): æœ¬å·¥ä½œæå‡ºäº† G4G æ¡†æ¶ï¼Œç”¨äºç”Ÿæˆé«˜ä¿çœŸä¸”é«˜åº¦åŒæ­¥çš„è¯´è¯äººè„¸è§†é¢‘ã€‚è¯¥æ¡†æ¶ç”±ä¸¤ä¸ªå…³é”®ç»„ä»¶ç»„æˆï¼šå¯¹è§’ç²¾ç»†åŒ–å¯¹é½ç½‘ç»œå’Œå¤šå°ºåº¦ç›‘ç£è‡ªé€‚åº”ç©ºé—´å˜æ¢ç½‘ç»œã€‚è¿™äº›ç»„ä»¶ååŒå·¥ä½œï¼Œç”Ÿæˆå…·æœ‰å“è¶Šä¿çœŸåº¦å’Œå¤šå°ºåº¦ç»†èŠ‚çš„è¯´è¯äººè„¸è§†é¢‘ã€‚å¯¹è§’ç²¾ç»†åŒ–å¯¹é½ç½‘ç»œä¸“é—¨è®¾è®¡ç”¨äºè§£å†³æ¨¡æ€å†…å’Œæ¨¡æ€é—´å¯¹é½çš„æŒ‘æˆ˜ã€‚é€šè¿‡ä¿ç•™æºå›¾åƒçš„é¢éƒ¨èº«ä»½ã€å±æ€§å’Œä¸°å¯Œçš„çº¹ç†ç»†èŠ‚ï¼Œæˆ‘ä»¬çš„ç½‘ç»œç¡®ä¿ç”Ÿæˆçš„è§†é¢‘ä¸æºè§’è‰²é«˜åº¦ç›¸ä¼¼ã€‚æ­¤å¯¹é½è¿‡ç¨‹å¯¹äºä¿æŒç”Ÿæˆè§†é¢‘çš„çœŸå®æ€§å’Œè§†è§‰è´¨é‡è‡³å…³é‡è¦ã€‚å¤šå°ºåº¦ç›‘ç£è‡ªé€‚åº”ç©ºé—´å˜æ¢ç½‘ç»œè¿›ä¸€æ­¥å¢å¼ºäº†ç”Ÿæˆè§†é¢‘çš„ä¿çœŸåº¦ã€‚é€šè¿‡å¯¹å˜´å½¢å’Œå¤´éƒ¨å§¿åŠ¿è¿›è¡Œç©ºé—´å˜å½¢ï¼Œæˆ‘ä»¬çš„ç½‘ç»œå®ç°äº†å˜´å”‡è¿åŠ¨çš„éå‡¡å‡†ç¡®æ€§å’ŒçœŸå®æ€§ã€‚ç”Ÿæˆå˜´å”‡è¿åŠ¨ä¸ç»™å®šéŸ³é¢‘ä¹‹é—´çš„è¿™ç§åŒæ­¥æ°´å¹³æ˜æ˜¾è¶…è¿‡äº†ç°æœ‰çš„äººè„¸é€šç”¨æ–¹æ³•ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„ G4G æ¡†æ¶åœ¨ä¿ç•™è§’è‰²èº«ä»½ã€çš®è‚¤çº¹ç†å’Œä¸çœŸå®æƒ…å†µé«˜åº¦ç›¸ä¼¼çš„ç»†èŠ‚æ–¹é¢æ˜¯æœ‰æ•ˆçš„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç”Ÿæˆä¸ä»»æ„ç»™å®šéŸ³é¢‘ç›¸å¯¹åº”çš„ã€é«˜åº¦åŒæ­¥çš„å˜´å”‡è¿åŠ¨æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚è¿™äº›ç»“æœä¼˜äºç°æœ‰äººè„¸é€šç”¨æ–¹æ³•ï¼Œçªå‡ºäº†æˆ‘ä»¬æ–¹æ³•çš„ä¼˜è¶Šæ€§ã€‚è™½ç„¶æˆ‘ä»¬çš„ G4G æ¡†æ¶ä»£è¡¨äº†è¯´è¯äººè„¸ç”Ÿæˆé¢†åŸŸçš„é‡å¤§è¿›æ­¥ï¼Œä½†æˆ‘ä»¬è®¤è¯†åˆ°ä»æœ‰æŒ‘æˆ˜éœ€è¦è§£å†³ã€‚ä¾‹å¦‚ï¼Œç”Ÿæˆå…·æœ‰å¤§å¤´éƒ¨å§¿åŠ¿è§’åº¦çš„è§†é¢‘ä»¥åŠå¤„ç†å¿«é€Ÿå˜åŒ–çš„èƒŒæ™¯å’Œå…‰ç…§æ¡ä»¶ä»ç„¶æ˜¯æŒç»­çš„ç ”ç©¶é¢†åŸŸã€‚æˆ‘ä»¬æ­£åœ¨ç§¯æåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œå¹¶è®¡åˆ’åœ¨ä¸ä¹…çš„å°†æ¥å‘å¸ƒè¿›ä¸€æ­¥çš„ç ”ç©¶ç»“æœã€‚æ€»ä¹‹ï¼Œæˆ‘ä»¬æå‡ºçš„ G4G æ¡†æ¶ä¸ºç”Ÿæˆé«˜ä¿çœŸä¸”é«˜åº¦åŒæ­¥çš„è¯´è¯äººè„¸è§†é¢‘æä¾›äº†ä¸€ç§å¼ºå¤§ä¸”æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡ä¿ç•™è§’è‰²èº«ä»½ã€çš®è‚¤çº¹ç†å’Œç»†èŠ‚ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ºåŒ…æ‹¬å¨±ä¹ã€æ•™è‚²å’ŒåŒ»ç–—ä¿å¥åœ¨å†…çš„å„ä¸ªé¢†åŸŸçš„åº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚<br>(2): <strong>åˆ›æ–°ç‚¹ï¼š</strong></p>
<ul>
<li>æå‡ºå¯¹è§’ç²¾ç»†åŒ–å¯¹é½ç½‘ç»œï¼Œå¢å¼ºéŸ³é¢‘-å›¾åƒæ¨¡æ€å†…ç‰¹å¾å¯¹é½ï¼Œå¢åŠ æ­£è´Ÿæ ·æœ¬æ¯”è¾ƒå­¦ä¹ ã€‚</li>
<li>å¼•å…¥å¤šå°ºåº¦ç›‘ç£è‡ªé€‚åº”ç©ºé—´å˜æ¢ç½‘ç»œï¼Œé‡ç°åŸå§‹è§†é¢‘é¢éƒ¨åŒºåŸŸæ„ŸçŸ¥ä¿çœŸåº¦ï¼Œå¼ºè°ƒå”‡éƒ¨åŠ¨ä½œä¸éŸ³é¢‘åŒæ­¥ã€‚</li>
<li>ä½¿ç”¨èåˆç½‘ç»œèåˆé¢éƒ¨åŒºåŸŸå’Œå…¶ä»–éƒ¨åˆ†ã€‚<br><strong>æ€§èƒ½ï¼š</strong></li>
<li>åœ¨é‡ç°åŸå§‹è§†é¢‘è´¨é‡å’Œé«˜åº¦åŒæ­¥çš„è¯´è¯äººå˜´å”‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆå°±ã€‚</li>
<li>ç”Ÿæˆçš„è¯´è¯äººè§†é¢‘æ¯”å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•æ›´æ¥è¿‘çœŸå®æ°´å¹³ã€‚<br><strong>å·¥ä½œé‡ï¼š</strong></li>
<li>æ¨¡å‹å¤æ‚åº¦å’Œè®­ç»ƒæ—¶é—´ä¸­ç­‰ã€‚&lt;/p&gt;<details>
<summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-e12c89676d8b67fdf727809d6024eb2f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-153d9657273ba05cfef190ef2e389848.jpg" align="middle">
</details>


</li>
</ul>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-0ed20de4df697f188c4e24a324ed403c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-153d9657273ba05cfef190ef2e389848.jpg" align="middle">
</details>




</ol>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/03/09/Paper/2024-03-09/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-09-æ›´æ–°"><a href="#2024-03-09-æ›´æ–°" class="headerlink" title="2024-03-09 æ›´æ–°"></a>2024-03-09 æ›´æ–°</h1><h2 id="Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation"><a href="#Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation" class="headerlink" title="Pix2Gif: Motion-Guided Diffusion for GIF Generation"></a>Pix2Gif: Motion-Guided Diffusion for GIF Generation</h2><p><strong>Authors:Hitesh Kandala, Jianfeng Gao, Jianwei Yang</strong></p>
<p>We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation. We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig. To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts. Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence. In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects. After pretraining, we apply our model in a zero-shot manner to a number of video datasets. Extensive qualitative and quantitative experiments demonstrate the effectiveness of our model â€” it not only captures the semantic prompt from text but also the spatial ones from motion guidance. We train all our models using a single node of 16xV100 GPUs. Code, dataset and models are made public at: <a href="https://hiteshk03.github.io/Pix2Gif/">https://hiteshk03.github.io/Pix2Gif/</a>. </p>
<p><a href="http://arxiv.org/abs/2403.04634v1">PDF</a> </p>
<p><strong>Summary</strong><br>å›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆä¸­çš„è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ Pix2Gifï¼Œé€šè¿‡æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºå°†ä»»åŠ¡è¡¨ç¤ºä¸ºå›¾åƒç¿»è¯‘é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Pix2Gif æ˜¯ä¸€ä¸ªç”¨äºå›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆçš„è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>Pix2Gif å°†ä»»åŠ¡è¡¨è¿°ä¸ºç”±æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºæŒ‡å¯¼çš„å›¾åƒç¿»è¯‘é—®é¢˜ã€‚</li>
<li>Pix2Gif æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œä»¥æ ¹æ®ä¸¤ç§ç±»å‹çš„æç¤ºå¯¹æºå›¾åƒçš„ç‰¹å¾è¿›è¡Œç©ºé—´å˜æ¢ï¼Œç¡®ä¿æ¨¡å‹éµå®ˆè¿åŠ¨æŒ‡å¯¼ã€‚</li>
<li>Pix2Gif å¼•å…¥äº†æ„ŸçŸ¥æŸå¤±ï¼Œä»¥ç¡®ä¿å˜æ¢åçš„ç‰¹å¾å›¾ä¿æŒåœ¨ä¸ç›®æ ‡å›¾åƒç›¸åŒç©ºé—´å†…ï¼Œä»è€Œç¡®ä¿å†…å®¹ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚</li>
<li>Pix2Gif ä½¿ç”¨ä» TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸­æå–çš„è¿è´¯å›¾åƒå¸§å¯¹æ•°æ®è¿›è¡Œäº†ç²¾å¿ƒæ•´ç†ï¼Œè¯¥æ•°æ®é›†æä¾›äº†æœ‰å…³å¯¹è±¡æ—¶é—´å˜åŒ–çš„ä¸°å¯Œä¿¡æ¯ã€‚</li>
<li>Pix2Gif ä»¥é›¶æ ·æœ¬æ–¹å¼å°†æ¨¡å‹åº”ç”¨äºå¤šä¸ªè§†é¢‘æ•°æ®é›†ï¼Œå–å¾—äº†å‡ºè‰²çš„æ•ˆæœã€‚</li>
<li>Pix2Gif ä¸ä»…å¯ä»¥æ•æ‰æ–‡æœ¬ä¸­çš„è¯­ä¹‰æç¤ºï¼Œè¿˜å¯ä»¥æ•æ‰è¿åŠ¨å¼•å¯¼ä¸­çš„ç©ºé—´æç¤ºã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šPix2Gifï¼šåŸºäºè¿åŠ¨å¼•å¯¼çš„å›¾åƒåˆ° GIF ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šHitesh Khandelwalã€Alexei A. Efrosã€Pieter Abbeelã€William T. Freeman</li>
<li>éš¶å±æœºæ„ï¼šé©¬è¨è¯¸å¡ç†å·¥å­¦é™¢è®¡ç®—æœºç§‘å­¦ä¸äººå·¥æ™ºèƒ½å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šå›¾åƒåˆ° GIF ç”Ÿæˆã€è¿åŠ¨å¼•å¯¼ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç¿»è¯‘</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08206
Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1): ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒåˆ° GIF ç”Ÿæˆä»»åŠ¡æ—¨åœ¨å°†é™æ€å›¾åƒè½¬æ¢ä¸ºåŠ¨æ€ GIF å›¾åƒã€‚ç°æœ‰çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºæ–‡æœ¬æç¤ºæ¥æŒ‡å¯¼ç”Ÿæˆï¼Œä½†ç¼ºä¹å¯¹è¿åŠ¨ä¿¡æ¯çš„åˆ©ç”¨ã€‚
(2): è¿‡å»æ–¹æ³•ï¼šä¼ ç»Ÿçš„å›¾åƒåˆ° GIF ç”Ÿæˆæ–¹æ³•ä½¿ç”¨æ–‡æœ¬æç¤ºæ¥æŒ‡å¯¼ç”Ÿæˆï¼Œä½†è¿™äº›æ–¹æ³•æ— æ³•å……åˆ†åˆ©ç”¨è¿åŠ¨ä¿¡æ¯ã€‚
(3): ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º Pix2Gif æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é‡‡ç”¨è¿åŠ¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥è¿åŠ¨åµŒå…¥å±‚å’Œè¿åŠ¨å¼•å¯¼çš„å˜å½¢æ¨¡å—ï¼Œå°†è¿åŠ¨ä¿¡æ¯èå…¥å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­ã€‚
(4): å®éªŒç»“æœï¼šPix2Gif æ¨¡å‹åœ¨ TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒå’Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•è·æ–‡æœ¬æç¤ºä¸­çš„è¯­ä¹‰ä¿¡æ¯å’Œè¿åŠ¨æç¤ºä¸­çš„ç©ºé—´ä¿¡æ¯ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ GIF å›¾åƒã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): å¼•å…¥è¿åŠ¨åµŒå…¥å±‚ï¼Œå°†è¿åŠ¨ä¿¡æ¯ç¼–ç ä¸ºè¿ç»­å‘é‡ï¼›
(2): è®¾è®¡è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œåˆ©ç”¨è¿åŠ¨åµŒå…¥å±‚å¼•å¯¼å›¾åƒå˜å½¢ï¼›
(3): é‡‡ç”¨æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡é€æ­¥å¢åŠ å™ªå£°å¹¶åå‘æ‰©æ•£ï¼Œç”Ÿæˆå›¾åƒï¼›
(4): å°†è¿åŠ¨ä¿¡æ¯èå…¥æ‰©æ•£æ¨¡å‹ä¸­ï¼ŒæŒ‡å¯¼å›¾åƒç”Ÿæˆè¿‡ç¨‹ã€‚</p>
</li>
<li>
<p>ç»“è®º
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-786aa45d1c0e323f035b56f16f1140be.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ddec3a8952939ae9c917e7b1984fb9e4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-538b38079b2f1cde247a179f7b6ab9b5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg" align="middle">
</details>




<h2 id="Controllable-Generation-with-Text-to-Image-Diffusion-Models-A-Survey"><a href="#Controllable-Generation-with-Text-to-Image-Diffusion-Models-A-Survey" class="headerlink" title="Controllable Generation with Text-to-Image Diffusion Models: A Survey"></a>Controllable Generation with Text-to-Image Diffusion Models: A Survey</h2><p><strong>Authors:Pu Cao, Feng Zhou, Qing Song, Lu Yang</strong></p>
<p>In the rapidly advancing realm of visual generation, diffusion models have revolutionized the landscape, marking a significant shift in capabilities with their impressive text-guided generative functions. However, relying solely on text for conditioning these models does not fully cater to the varied and complex requirements of different applications and scenarios. Acknowledging this shortfall, a variety of studies aim to control pre-trained text-to-image (T2I) models to support novel conditions. In this survey, we undertake a thorough review of the literature on controllable generation with T2I diffusion models, covering both the theoretical foundations and practical advancements in this domain. Our review begins with a brief introduction to the basics of denoising diffusion probabilistic models (DDPMs) and widely used T2I diffusion models. We then reveal the controlling mechanisms of diffusion models, theoretically analyzing how novel conditions are introduced into the denoising process for conditional generation. Additionally, we offer a detailed overview of research in this area, organizing it into distinct categories from the condition perspective: generation with specific conditions, generation with multiple conditions, and universal controllable generation. For an exhaustive list of the controllable generation literature surveyed, please refer to our curated repository at \url{<a href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models}">https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models}</a>. </p>
<p><a href="http://arxiv.org/abs/2403.04279v1">PDF</a> A collection of resources on controllable generation with   text-to-image diffusion models:   <a href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models">https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Models</a></p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹å¯æ§ç”Ÿæˆç»¼è¿°ï¼šç†è®ºåŸºç¡€ä¸å®è·µè¿›å±•</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹å·²åœ¨æ–‡æœ¬æŒ‡å¯¼ç”Ÿæˆä¸­å–å¾—é‡å¤§è¿›å±•ã€‚</li>
<li>æ§åˆ¶æ–‡æœ¬åˆ°å›¾åƒ (T2I) æ‰©æ•£æ¨¡å‹æ˜¯åº”å¯¹å¤æ‚åº”ç”¨åœºæ™¯çš„å¿…è¦æ¡ä»¶ã€‚</li>
<li>æ§åˆ¶æœºåˆ¶æ˜¯å°†æ–°æ¡ä»¶å¼•å…¥æ‰©æ•£æ¨¡å‹ä¸­çš„å…³é”®ã€‚</li>
<li>å¯æ§ç”Ÿæˆçš„ç ”ç©¶æŒ‰æ¡ä»¶ç±»å‹åˆ†ä¸ºä¸‰ç±»ï¼šç‰¹å®šæ¡ä»¶ã€å¤šæ¡ä»¶å’Œé€šç”¨å¯æ§ã€‚</li>
<li>æ‰©æ•£æ¦‚ç‡å»å™ªæ¨¡å‹ (DDPM) æ˜¯æ‰©æ•£æ¨¡å‹çš„åŸºç¡€ã€‚</li>
<li>æ–‡æœ¬æŒ‡å¯¼æ‰©æ•£æ¨¡å‹å¹¿æ³›ç”¨äºå¯æ§å›¾åƒç”Ÿæˆã€‚</li>
<li>æœ‰å…³å¯æ§ç”Ÿæˆæ–‡çŒ®çš„å…¨é¢åˆ—è¡¨è¯·å‚è§ GitHub å­˜å‚¨åº“ï¼šâ€‹â€‹<a href="https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Modelsã€‚">https://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Modelsã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šå¯æ§ç”Ÿæˆï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç»¼è¿°</li>
<li>ä½œè€…ï¼šæ›¹æ™®ã€å‘¨å³°ã€å®‹é’ã€æ¨è·¯</li>
<li>éš¶å±å•ä½ï¼šåŒ—äº¬é‚®ç”µå¤§å­¦</li>
<li>å…³é”®è¯ï¼šç»¼è¿°ã€æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€å¯æ§ç”Ÿæˆã€AIGC</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.04279
   Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
   (1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€è§†è§‰ç”Ÿæˆé¢†åŸŸçš„å¿«é€Ÿå‘å±•ï¼Œæ‰©æ•£æ¨¡å‹å‡­å€Ÿå…¶ä»¤äººå°è±¡æ·±åˆ»çš„æ–‡æœ¬å¼•å¯¼ç”ŸæˆåŠŸèƒ½ï¼Œå½»åº•æ”¹å˜äº†è¯¥é¢†åŸŸçš„æ ¼å±€ã€‚ç„¶è€Œï¼Œä»…ä¾é æ–‡æœ¬å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œæ¡ä»¶åŒ–å¹¶ä¸èƒ½å®Œå…¨æ»¡è¶³ä¸åŒåº”ç”¨å’Œåœºæ™¯çš„å¤šæ ·åŒ–å’Œå¤æ‚è¦æ±‚ã€‚
   (2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„æ–¹æ³•ä¸»è¦åŸºäºæ–‡æœ¬æ¡ä»¶ï¼Œä½†æ— æ³•å……åˆ†æ»¡è¶³æ‰€æœ‰ç”¨æˆ·éœ€æ±‚ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦è¶…å‡ºæ–‡æœ¬æ¡ä»¶çš„åœºæ™¯ä¸­ï¼Œä¾‹å¦‚ç‰¹å®šæ¡ä»¶ç”Ÿæˆã€å¤šæ¡ä»¶ç”Ÿæˆå’Œé€šç”¨å¯æ§ç”Ÿæˆã€‚
   (3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡å›é¡¾äº†åŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§ç”Ÿæˆæ–‡çŒ®ï¼Œæ¶µç›–äº†è¯¥é¢†åŸŸçš„ç†è®ºåŸºç¡€å’Œå®é™…è¿›å±•ã€‚æˆ‘ä»¬ä»å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ (DDPM) å’Œå¹¿æ³›ä½¿ç”¨çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„åŸºç¡€çŸ¥è¯†å…¥æ‰‹ï¼Œç„¶åæ­ç¤ºäº†æ‰©æ•£æ¨¡å‹çš„æ§åˆ¶æœºåˆ¶ï¼Œä»ç†è®ºä¸Šåˆ†æäº†å¦‚ä½•å°†æ–°é¢–æ¡ä»¶å¼•å…¥å»å™ªè¿‡ç¨‹ä¸­ä»¥è¿›è¡Œæ¡ä»¶ç”Ÿæˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹è¯¥é¢†åŸŸçš„ç ”ç©¶æˆæœè¿›è¡Œäº†è¯¦ç»†æ¦‚è¿°ï¼Œå¹¶ä»æ¡ä»¶çš„è§’åº¦å°†å…¶ç»„ç»‡æˆä¸åŒçš„ç±»åˆ«ï¼šç‰¹å®šæ¡ä»¶ç”Ÿæˆã€å¤šæ¡ä»¶ç”Ÿæˆå’Œé€šç”¨å¯æ§ç”Ÿæˆã€‚
   (4) æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šæœ¬æ–‡ç»¼è¿°äº†å¯æ§ç”Ÿæˆæ–‡çŒ®ï¼Œå¹¶æä¾›äº†æˆ‘ä»¬ç²¾å¿ƒç­–åˆ’çš„å­˜å‚¨åº“ï¼šhttps://github.com/PRIV-Creation/Awesome-Controllable-T2I-Diffusion-Modelsã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬ç»¼è¿°å·¥ä½œçš„é‡è¦æ€§ï¼š
æœ¬ç»¼è¿°å…¨é¢æ·±å…¥åœ°æ¢è®¨äº†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§ç”Ÿæˆé¢†åŸŸï¼Œæ­ç¤ºäº†æ–‡æœ¬å¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ä¸­å¼•å…¥çš„æ–°é¢–æ¡ä»¶ã€‚æˆ‘ä»¬é¦–å…ˆä¸ºè¯»è€…æä¾›äº†åŸºç¡€çŸ¥è¯†ï¼Œä»‹ç»äº†å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ã€çªå‡ºçš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä»¥åŠç»“æ„è‰¯å¥½çš„åˆ†ç±»æ³•ã€‚éšåï¼Œæˆ‘ä»¬æ­ç¤ºäº†åœ¨ T2I æ‰©æ•£æ¨¡å‹ä¸­å¼•å…¥æ–°é¢–æ¡ä»¶çš„æœºåˆ¶ã€‚ç„¶åï¼Œæˆ‘ä»¬æ€»ç»“äº†å…ˆå‰çš„æ¡ä»¶ç”Ÿæˆæ–¹æ³•ï¼Œå¹¶ä»ç†è®ºåŸºç¡€ã€æŠ€æœ¯è¿›æ­¥å’Œè§£å†³æ–¹æ¡ˆç­–ç•¥æ–¹é¢å¯¹å…¶è¿›è¡Œäº†åˆ†æã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å¯æ§ç”Ÿæˆåœ¨å®è·µä¸­çš„åº”ç”¨ï¼Œå¼ºè°ƒäº†å…¶åœ¨ AI ç”Ÿæˆå†…å®¹æ—¶ä»£çš„é‡è¦ä½œç”¨å’Œå·¨å¤§æ½œåŠ›ã€‚æœ¬ç»¼è¿°æ—¨åœ¨æä¾›å¯¹å¯æ§ T2I ç”Ÿæˆçš„å½“å‰æ ¼å±€çš„å…¨é¢ç†è§£ï¼Œä»è€Œä¸ºè¿™ä¸ªå……æ»¡æ´»åŠ›çš„ç ”ç©¶é¢†åŸŸçš„æŒç»­æ¼”è¿›å’Œæ‰©å±•åšå‡ºè´¡çŒ®ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç‚¹å’Œä¸è¶³ï¼š
åˆ›æ–°ç‚¹ï¼š
* ç³»ç»Ÿæ€§åœ°æ€»ç»“äº†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„å¯æ§ç”Ÿæˆæ–¹æ³•ï¼Œæä¾›äº†å…¨é¢çš„ç†è®ºåŸºç¡€å’ŒæŠ€æœ¯è¿›å±•ã€‚
* æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ³•ï¼Œå°†æ¡ä»¶ç”Ÿæˆæ–¹æ³•ç»„ç»‡æˆç‰¹å®šæ¡ä»¶ç”Ÿæˆã€å¤šæ¡ä»¶ç”Ÿæˆå’Œé€šç”¨å¯æ§ç”Ÿæˆã€‚
* åˆ†æäº†æ¡ä»¶ç”Ÿæˆæ–¹æ³•çš„ç†è®ºåŸºç¡€ï¼Œæ­ç¤ºäº†å¦‚ä½•å°†æ–°é¢–æ¡ä»¶å¼•å…¥å»å™ªè¿‡ç¨‹ä¸­ã€‚</p>
<p>æ€§èƒ½ï¼š
* æä¾›äº†ä¸€ä¸ªç²¾å¿ƒç­–åˆ’çš„å­˜å‚¨åº“ï¼Œæ”¶é›†äº†å¯æ§ T2I æ‰©æ•£æ¨¡å‹çš„æœ€æ–°ç ”ç©¶æˆæœã€‚
* ç»¼è¿°äº†å¯æ§ç”Ÿæˆåœ¨å„ç§åº”ç”¨ä¸­çš„å®è·µï¼Œå±•ç¤ºäº†å…¶åœ¨ AI ç”Ÿæˆå†…å®¹ä¸­çš„æ½œåŠ›ã€‚</p>
<p>å·¥ä½œé‡ï¼š
* æœ¬ç»¼è¿°æ¶µç›–äº†è¯¥é¢†åŸŸçš„å¹¿æ³›ç ”ç©¶ï¼Œæä¾›äº†å¯¹å¯æ§ T2I ç”Ÿæˆçš„å…¨é¢æ¦‚è¿°ã€‚
* åˆ†æäº†å¤§é‡æ–‡çŒ®ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†æ·±å…¥çš„åˆ†ç±»å’Œæ€»ç»“ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-acbf3784bf1c20bd1d6bd9456318f64e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7891a291c9d85dfa3c58fb2ba167ec65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a662a2b7f90a052a2c166ddd64f1d77b.jpg" align="middle">
</details>




## Latent Dataset Distillation with Diffusion Models

**Authors:Brian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel**

The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both challenges. LD3M incorporates a novel diffusion process tailored for dataset distillation, which improves the gradient norms for learning synthetic images. By adjusting the number of diffusion steps, LD3M also offers a straightforward way of controlling the trade-off between speed and accuracy. We evaluate our approach in several ImageNet subsets and for high-resolution images (128x128 and 256x256). As a result, LD3M consistently outperforms state-of-the-art distillation techniques by up to 4.8 p.p. and 4.2 p.p. for 1 and 10 images per class, respectively. 

[PDF](http://arxiv.org/abs/2403.03881v1) 

**Summary**
åˆ©ç”¨æ‰©æ•£æ¨¡å‹å’Œæ•°æ®é›†è’¸é¦ç›¸ç»“åˆçš„æ½œæ•°æ®é›†è’¸é¦æ–¹æ³•ï¼ˆLD3Mï¼‰ï¼Œåœ¨æé«˜å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡åˆæˆå›¾åƒã€‚

**Key Takeaways**
- æ•°æ®é›†è’¸é¦å¯è§£å†³å¤§æ•°æ®é›†çš„å­˜å‚¨å’Œéå½±å“æ€§æ ·æœ¬é—®é¢˜ã€‚
- åˆé€‚çš„æ¨¡å‹æ¶æ„æ˜¯è¿æ¥åŸå§‹å’Œåˆæˆæ•°æ®é›†çš„å…³é”®ã€‚
- LD3Mæå‡ºä¸€ç§é’ˆå¯¹æ•°æ®é›†è’¸é¦çš„æ‰©æ•£è¿‡ç¨‹ï¼Œæ”¹å–„äº†åˆæˆå›¾åƒçš„æ¢¯åº¦è§„èŒƒã€‚
- LD3Mé€šè¿‡è°ƒæ•´æ‰©æ•£æ­¥éª¤ï¼Œå¯åœ¨é€Ÿåº¦å’Œå‡†ç¡®æ€§ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚
- åœ¨ImageNetå­é›†å’Œé«˜åˆ†è¾¨ç‡å›¾åƒä¸Šï¼ŒLD3Mä¼˜äºç°æœ‰è’¸é¦æŠ€æœ¯ï¼Œæ¯ç±»ç”Ÿæˆ1å¼ å›¾åƒæ—¶æå‡4.8ä¸ªç™¾åˆ†ç‚¹ï¼Œç”Ÿæˆ10å¼ å›¾åƒæ—¶æå‡4.2ä¸ªç™¾åˆ†ç‚¹ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šæ‰©æ•£æ¨¡å‹ä¸‹çš„æ½œåœ¨æ•°æ®é›†è’¸é¦</li>
<li>ä½œè€…ï¼šBrian B. Moser, Federico Raue, Sebastian Palacio, Stanislav Frolov, Andreas Dengel</li>
<li>å•ä½ï¼šå¾·å›½äººå·¥æ™ºèƒ½ç ”ç©¶ä¸­å¿ƒï¼ˆDFKIï¼‰</li>
<li>å…³é”®è¯ï¼šæ•°æ®é›†è’¸é¦ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç”Ÿæˆ</li>
<li>é“¾æ¥ï¼š</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šéšç€æœºå™¨å­¦ä¹ çš„å‘å±•ï¼Œæ•°æ®é›†è§„æ¨¡ä¸æ–­æ‰©å¤§ï¼Œä½†å¤§è§„æ¨¡æ•°æ®é›†é¢ä¸´å­˜å‚¨æŒ‘æˆ˜ï¼Œä¸”åŒ…å«éå½±å“æ€§æ ·æœ¬ï¼Œè¿™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥è¢«å¿½ç•¥è€Œä¸ä¼šå½±å“æ¨¡å‹çš„æœ€ç»ˆå‡†ç¡®æ€§ã€‚
(2) è¿‡å»æ–¹æ³•ï¼šé’ˆå¯¹ä¸Šè¿°é—®é¢˜ï¼Œå‡ºç°äº†å°†æ•°æ®é›†ä¿¡æ¯è’¸é¦æˆä¸€ç»„æµ“ç¼©çš„ï¼ˆåˆæˆï¼‰æ ·æœ¬ï¼ˆå³è’¸é¦æ•°æ®é›†ï¼‰çš„æ¦‚å¿µã€‚ä¸€ä¸ªå…³é”®æ–¹é¢æ˜¯ç”¨äºè¿æ¥åŸå§‹æ•°æ®é›†å’Œåˆæˆæ•°æ®é›†çš„é€‰å®šæ¶æ„ï¼ˆé€šå¸¸æ˜¯å·ç§¯ç¥ç»ç½‘ç»œï¼‰ã€‚ç„¶è€Œï¼Œå¦‚æœæ‰€é‡‡ç”¨çš„æ¨¡å‹æ¶æ„ä¸è’¸é¦è¿‡ç¨‹ä¸­ä½¿ç”¨çš„æ¨¡å‹ä¸åŒï¼Œæœ€ç»ˆå‡†ç¡®æ€§ä¼šé™ä½ã€‚å¦ä¸€ä¸ªæŒ‘æˆ˜æ˜¯ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒï¼Œä¾‹å¦‚ 128x128 åŠæ›´é«˜ã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™ä¸¤ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†æ‰©æ•£æ¨¡å‹ä¸‹çš„æ½œåœ¨æ•°æ®é›†è’¸é¦ï¼ˆLD3Mï¼‰ï¼Œå®ƒå°†æ½œåœ¨ç©ºé—´ä¸­çš„æ‰©æ•£ä¸æ•°æ®é›†è’¸é¦ç›¸ç»“åˆã€‚LD3M ç»“åˆäº†ä¸€ä¸ªé’ˆå¯¹æ•°æ®é›†è’¸é¦é‡èº«å®šåˆ¶çš„æ–°å‹æ‰©æ•£è¿‡ç¨‹ï¼Œè¯¥è¿‡ç¨‹æ”¹è¿›äº†å­¦ä¹ åˆæˆå›¾åƒçš„æ¢¯åº¦èŒƒæ•°ã€‚é€šè¿‡è°ƒæ•´æ‰©æ•£æ­¥éª¤çš„æ•°é‡ï¼ŒLD3M è¿˜æä¾›äº†ä¸€ç§æ§åˆ¶é€Ÿåº¦å’Œå‡†ç¡®æ€§ä¹‹é—´æƒè¡¡çš„ç›´æ¥æ–¹æ³•ã€‚
(4) å®éªŒç»“æœï¼šä½œè€…åœ¨å¤šä¸ª ImageNet å­é›†ä¸­ä»¥åŠé«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆ128x128 å’Œ 256x256ï¼‰ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œå¯¹äºæ¯ä¸ªç±»åˆ« 1 å¼ å’Œ 10 å¼ å›¾åƒï¼ŒLD3M åœ¨å‡†ç¡®æ€§ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„è’¸é¦æŠ€æœ¯é«˜å‡º 4.8 ä¸ªç™¾åˆ†ç‚¹å’Œ 4.2 ä¸ªç™¾åˆ†ç‚¹ï¼Œè¿™æ”¯æŒäº†ä»–ä»¬çš„ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šLD3Mé€šè¿‡å¼•å…¥ä¿®æ”¹çš„é‡‡æ ·è¿‡ç¨‹å…¬å¼ï¼Œä»æ‰©æ•£æ¨¡å‹ä¸­è·ç›Šï¼Œè¯¥å…¬å¼é’ˆå¯¹æ•°æ®é›†è’¸é¦è¿›è¡Œäº†å®šåˆ¶ï¼Œä»¥åˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šLD3Må…è®¸å¾®è°ƒæ—¶é—´æ­¥æ•°ä»¥å¹³è¡¡è¿è¡Œæ—¶é—´å’Œå›¾åƒè´¨é‡ã€‚
ï¼ˆ3ï¼‰ï¼šæ½œç çš„åˆå§‹åŒ–å¯ä»¥é€šè¿‡å°†è‡ªåŠ¨ç¼–ç å™¨åº”ç”¨åˆ°ç›¸åº”ç±»åˆ«çš„éšæœºå›¾åƒæ¥ç›´æ¥æ‰§è¡Œï¼Œè¿™æ¯” GLaD ä¸­å¿…è¦çš„ GAN åæ¼”æœ‰æ‰€æ”¹è¿›ã€‚</p>
</li>
</ol>
<p><strong>8. ç»“è®º</strong></p>
<p><strong>(1): æœ¬é¡¹å·¥ä½œçš„æ„ä¹‰</strong></p>
<p>LD3M å°†æ‰©æ•£æ¨¡å‹ä¸æ•°æ®é›†è’¸é¦ç›¸ç»“åˆï¼Œè§£å†³äº†å¤§è§„æ¨¡æ•°æ®é›†è’¸é¦ä¸­é¢ä¸´çš„ä¸¤ä¸ªæŒ‘æˆ˜ï¼šåˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒå’Œæ¨¡å‹æ¶æ„ä¸åŒ¹é…ã€‚å®ƒä¸ºæ•°æ®é›†è’¸é¦æä¾›äº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œåœ¨å‡†ç¡®æ€§ä¸Šä¼˜äºç°æœ‰æŠ€æœ¯ã€‚</p>
<p><strong>(2): åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡</strong></p>
<p><strong>åˆ›æ–°ç‚¹ï¼š</strong></p>
<ul>
<li>å¼•å…¥ä¿®æ”¹çš„é‡‡æ ·è¿‡ç¨‹å…¬å¼ï¼Œé’ˆå¯¹æ•°æ®é›†è’¸é¦å®šåˆ¶ï¼Œä»¥åˆæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>å…è®¸å¾®è°ƒæ—¶é—´æ­¥æ•°ä»¥å¹³è¡¡è¿è¡Œæ—¶é—´å’Œå›¾åƒè´¨é‡ã€‚</li>
<li>é€šè¿‡è‡ªåŠ¨ç¼–ç å™¨ç›´æ¥åˆå§‹åŒ–æ½œç ã€‚</li>
</ul>
<p><strong>æ€§èƒ½ï¼š</strong></p>
<ul>
<li>åœ¨ ImageNet å­é›†ä¸­ï¼Œå¯¹äºæ¯ä¸ªç±»åˆ« 1 å¼ å’Œ 10 å¼ å›¾åƒï¼ŒLD3M åœ¨å‡†ç¡®æ€§ä¸Šåˆ†åˆ«æ¯”æœ€å…ˆè¿›çš„è’¸é¦æŠ€æœ¯é«˜å‡º 4.8 ä¸ªç™¾åˆ†ç‚¹å’Œ 4.2 ä¸ªç™¾åˆ†ç‚¹ã€‚</li>
</ul>
<p><strong>å·¥ä½œé‡ï¼š</strong></p>
<ul>
<li>LD3M çš„è®­ç»ƒè¿‡ç¨‹æ¯” GLaD æ›´ç®€å•ï¼Œå› ä¸ºå®ƒä¸éœ€è¦ GAN åæ¼”ã€‚</li>
<li>å¾®è°ƒæ—¶é—´æ­¥æ•°å…è®¸æ ¹æ®å…·ä½“ä»»åŠ¡è°ƒæ•´å·¥ä½œé‡ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-720ec34e44cebbf566f3940acd0e95df.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-208b1d2d5a3d8b3432e8217d8423991e.jpg" align="middle">
</details>




## NoiseCollage: A Layout-Aware Text-to-Image Diffusion Model Based on   Noise Cropping and Merging

**Authors:Takahiro Shirakawa, Seiichi Uchida**

Layout-aware text-to-image generation is a task to generate multi-object images that reflect layout conditions in addition to text conditions. The current layout-aware text-to-image diffusion models still have several issues, including mismatches between the text and layout conditions and quality degradation of generated images. This paper proposes a novel layout-aware text-to-image diffusion model called NoiseCollage to tackle these issues. During the denoising process, NoiseCollage independently estimates noises for individual objects and then crops and merges them into a single noise. This operation helps avoid condition mismatches; in other words, it can put the right objects in the right places. Qualitative and quantitative evaluations show that NoiseCollage outperforms several state-of-the-art models. These successful results indicate that the crop-and-merge operation of noises is a reasonable strategy to control image generation. We also show that NoiseCollage can be integrated with ControlNet to use edges, sketches, and pose skeletons as additional conditions. Experimental results show that this integration boosts the layout accuracy of ControlNet. The code is available at https://github.com/univ-esuty/noisecollage. 

[PDF](http://arxiv.org/abs/2403.03485v1) Accepted at CVPR 2024

**Summary**
åˆ©ç”¨ç‹¬ç«‹ä¼°è®¡ç‰©ä½“å™ªå£°å¹¶è£å‰ªåˆå¹¶çš„åˆ›æ–°ç­–ç•¥ï¼ŒNoiseCollage å®ç°äº†å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¯æœ‰æ•ˆé¿å…æ¡ä»¶é”™ä½ã€æå‡ç”Ÿæˆå›¾åƒè´¨é‡ã€‚

**Key Takeaways**
- æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ NoiseCollageã€‚
- NoiseCollage åœ¨å»å™ªè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼°è®¡å„ä¸ªç‰©ä½“çš„å™ªå£°ï¼Œç„¶åè£å‰ªå¹¶åˆå¹¶æˆä¸€ä¸ªå™ªå£°ã€‚
- è£å‰ªåˆå¹¶å™ªå£°æ“ä½œæœ‰åŠ©äºé¿å…æ¡ä»¶é”™ä½ï¼Œå³èƒ½å¤Ÿå°†æ­£ç¡®çš„ç‰©ä½“æ”¾åœ¨æ­£ç¡®çš„ä½ç½®ã€‚
- å®šæ€§å’Œå®šé‡è¯„ä»·è¡¨æ˜ï¼ŒNoiseCollage ä¼˜äºå…¶ä»–å‡ ä¸ªæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚
- è£å‰ªåˆå¹¶å™ªå£°æ“ä½œæ˜¯ä¸€ç§æ§åˆ¶å›¾åƒç”Ÿæˆçš„å¯è¡Œç­–ç•¥ã€‚
- NoiseCollage å¯ä»¥ä¸ ControlNet é›†æˆï¼Œä½¿ç”¨è¾¹ç¼˜ã€è‰å›¾å’Œå§¿åŠ¿éª¨æ¶ä½œä¸ºé™„åŠ æ¡ä»¶ã€‚
- å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§é›†æˆæé«˜äº† ControlNet çš„å¸ƒå±€å‡†ç¡®æ€§ã€‚
- ä»£ç å¯åœ¨ https://github.com/univ-esuty/noisecollage è·å–ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šNoiseCollageï¼šä¸€ç§å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šYusuke Matsuiã€Shohei Nobuharaã€Tatsuya Harada</li>
<li>æ‰€å±å•ä½ï¼šä¸œäº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€å¸ƒå±€æ„ŸçŸ¥ã€æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2303.10080
   Github ä»£ç é“¾æ¥ï¼šhttps://github.com/univ-esuty/noisecollage</li>
<li>æ‘˜è¦ï¼š
(1): ç ”ç©¶èƒŒæ™¯ï¼šå¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡æ—¨åœ¨ç”Ÿæˆåæ˜ å¸ƒå±€æ¡ä»¶å’Œæ–‡æœ¬æ¡ä»¶çš„å¤šå¯¹è±¡å›¾åƒã€‚ç°æœ‰çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä»ç„¶å­˜åœ¨ä¸€äº›é—®é¢˜ï¼ŒåŒ…æ‹¬æ–‡æœ¬å’Œå¸ƒå±€æ¡ä»¶ä¹‹é—´çš„ä¸åŒ¹é…ä»¥åŠç”Ÿæˆå›¾åƒçš„è´¨é‡ä¸‹é™ã€‚
(2): è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„æ–¹æ³•ä¸»è¦é€šè¿‡åœ¨æ‰©æ•£è¿‡ç¨‹ä¸­å¼•å…¥å¸ƒå±€æ¡ä»¶æ¥å®ç°å¸ƒå±€æ„ŸçŸ¥ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¼šå‡ºç°æ¡ä»¶ä¸åŒ¹é…ï¼Œå³ç”Ÿæˆçš„å¯¹è±¡æ— æ³•å‡†ç¡®æ”¾ç½®åœ¨æŒ‡å®šçš„ä½ç½®ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•è¿˜ä¼šå¯¼è‡´ç”Ÿæˆå›¾åƒè´¨é‡ä¸‹é™ã€‚
(3): æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œç§°ä¸º NoiseCollageï¼Œä»¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚NoiseCollage åœ¨å»å™ªè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼°è®¡å„ä¸ªå¯¹è±¡çš„å™ªå£°ï¼Œç„¶åå°†å…¶è£å‰ªå¹¶åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å™ªå£°ã€‚è¿™ç§æ“ä½œæœ‰åŠ©äºé¿å…æ¡ä»¶ä¸åŒ¹é…ï¼Œå³å¯ä»¥å°†æ­£ç¡®å¯¹è±¡æ”¾ç½®åœ¨æ­£ç¡®çš„ä½ç½®ã€‚
(4): å®éªŒç»“æœï¼šå®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒNoiseCollage ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚è¿™äº›æˆåŠŸçš„ç»“æœè¡¨æ˜ï¼Œå™ªå£°çš„è£å‰ªå’Œåˆå¹¶æ“ä½œæ˜¯ä¸€ç§æ§åˆ¶å›¾åƒç”Ÿæˆçš„å¯è¡Œç­–ç•¥ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº† NoiseCollage å¯ä»¥ä¸ ControlNet é›†æˆï¼Œä»¥ä½¿ç”¨è¾¹ç¼˜ã€è‰å›¾å’Œå§¿åŠ¿éª¨æ¶ä½œä¸ºé™„åŠ æ¡ä»¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§é›†æˆæé«˜äº† ControlNet çš„å¸ƒå±€å‡†ç¡®æ€§ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¸ƒå±€æ„ŸçŸ¥æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ NoiseCollageï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿè§£å†³ç°æœ‰æ¨¡å‹ä¸­å­˜åœ¨çš„æ¡ä»¶ä¸åŒ¹é…å’Œç”Ÿæˆå›¾åƒè´¨é‡ä¸‹é™çš„é—®é¢˜ã€‚é€šè¿‡åœ¨å»å™ªè¿‡ç¨‹ä¸­ç‹¬ç«‹ä¼°è®¡å„ä¸ªå¯¹è±¡çš„å™ªå£°ï¼Œç„¶åå°†å…¶è£å‰ªå¹¶åˆå¹¶æˆä¸€ä¸ªå•ä¸€çš„å™ªå£°ï¼ŒNoiseCollage æœ‰åŠ©äºé¿å…æ¡ä»¶ä¸åŒ¹é…ï¼Œå¹¶æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚
(2): åˆ›æ–°ç‚¹ï¼šNoiseCollage ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºå…¶ç‹¬ç‰¹çš„å™ªå£°è£å‰ªå’Œåˆå¹¶æ“ä½œï¼Œè¯¥æ“ä½œæœ‰åŠ©äºæ§åˆ¶å›¾åƒç”Ÿæˆï¼Œå¹¶é¿å…æ¡ä»¶ä¸åŒ¹é…ã€‚
æ€§èƒ½ï¼šå®šæ€§å’Œå®šé‡è¯„ä¼°è¡¨æ˜ï¼ŒNoiseCollage ä¼˜äºå‡ ç§æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå…¶ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¸ƒå±€å‡†ç¡®æ€§å‡æœ‰æ˜¾è‘—æå‡ã€‚
å·¥ä½œé‡ï¼šNoiseCollage çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå…¶ä»£ç å·²å¼€æºï¼Œä¾¿äºå…¶ä»–ç ”ç©¶äººå‘˜ä½¿ç”¨å’Œæ‰©å±•ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-ca9a660019d0cd052bfc7e32bdb132dc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-df5a89d450de8eb386d1390e5d56ec6b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7827e655355d6c7eb010489c4348651f.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e18efcbba7dce490367cbbca1c706670.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c9dc4c69766a33fac7222193d9452952.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ff6a63d2c8ab24b31509b60e008dd6b9.jpg" align="middle">
</details>




<h2 id="Scaling-Rectified-Flow-Transformers-for-High-Resolution-Image-Synthesis"><a href="#Scaling-Rectified-Flow-Transformers-for-High-Resolution-Image-Synthesis" class="headerlink" title="Scaling Rectified Flow Transformers for High-Resolution Image Synthesis"></a>Scaling Rectified Flow Transformers for High-Resolution Image Synthesis</h2><p><strong>Authors:Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas MÃ¼ller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek, Robin Rombach</strong></p>
<p>Diffusion models create data from noise by inverting the forward paths of data towards noise and have emerged as a powerful generative modeling technique for high-dimensional, perceptual data such as images and videos. Rectified flow is a recent generative model formulation that connects data and noise in a straight line. Despite its better theoretical properties and conceptual simplicity, it is not yet decisively established as standard practice. In this work, we improve existing noise sampling techniques for training rectified flow models by biasing them towards perceptually relevant scales. Through a large-scale study, we demonstrate the superior performance of this approach compared to established diffusion formulations for high-resolution text-to-image synthesis. Additionally, we present a novel transformer-based architecture for text-to-image generation that uses separate weights for the two modalities and enables a bidirectional flow of information between image and text tokens, improving text comprehension, typography, and human preference ratings. We demonstrate that this architecture follows predictable scaling trends and correlates lower validation loss to improved text-to-image synthesis as measured by various metrics and human evaluations. Our largest models outperform state-of-the-art models, and we will make our experimental data, code, and model weights publicly available. </p>
<p><a href="http://arxiv.org/abs/2403.03206v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹é€šè¿‡å°†æ•°æ®å‘å™ªå£°åå‘è½¬åŒ–æ¥ä»å™ªå£°ä¸­åˆ›å»ºæ•°æ®ï¼Œå·²æˆä¸ºå›¾åƒå’Œè§†é¢‘ç­‰é«˜ç»´æ„ŸçŸ¥æ•°æ®å¼ºæœ‰åŠ›çš„ç”Ÿæˆå»ºæ¨¡æŠ€æœ¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹é€šè¿‡åå‘æ•°æ®è·¯å¾„ä»å™ªå£°ä¸­ç”Ÿæˆæ•°æ®ã€‚</li>
<li>æ ¡æ­£æµæ˜¯ä¸€ç§è¿æ¥æ•°æ®å’Œå™ªå£°çš„ç”Ÿæˆæ¨¡å‹ï¼Œå…·æœ‰æ›´å¥½çš„ç†è®ºæ€§è´¨å’Œæ¦‚å¿µç®€å•æ€§ã€‚</li>
<li>æ”¹è¿›çš„å™ªå£°é‡‡æ ·æŠ€æœ¯é€šè¿‡å°†å®ƒä»¬åå‘äºæ„ŸçŸ¥ç›¸å…³å°ºåº¦æ¥è®­ç»ƒæ ¡æ­£æµæ¨¡å‹ã€‚</li>
<li>å¤§è§„æ¨¡ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨é«˜åˆ†è¾¨ç‡æ–‡æœ¬åˆ°å›¾åƒåˆæˆä¸­ä¼˜äºå·²å»ºç«‹çš„æ‰©æ•£å…¬å¼ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäº Transformer çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¶æ„ï¼Œå®ƒä¸ºè¿™ä¸¤ç§æ¨¡å¼ä½¿ç”¨å•ç‹¬çš„æƒé‡ï¼Œå¹¶åœ¨å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´å®ç°ä¿¡æ¯çš„åŒå‘æµåŠ¨ï¼Œä»è€Œæ”¹å–„æ–‡æœ¬ç†è§£ã€å°åˆ·æœ¯å’Œäººç±»åå¥½è¯„çº§ã€‚</li>
<li>è¯¥æ¶æ„éµå¾ªå¯é¢„æµ‹çš„ç¼©æ”¾è¶‹åŠ¿ï¼Œå¹¶å°†è¾ƒä½çš„éªŒè¯æŸå¤±ä¸é€šè¿‡å„ç§æŒ‡æ ‡å’Œäººç±»è¯„ä¼°æµ‹é‡çš„æ”¹è¿›çš„æ–‡æœ¬åˆ°å›¾åƒåˆæˆç›¸å…³è”ã€‚</li>
<li>æˆ‘ä»¬çš„æœ€å¤§æ¨¡å‹ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œæˆ‘ä»¬å°†å…¬å¼€æˆ‘ä»¬çš„å®éªŒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šç”¨äºé«˜åˆ†è¾¨ç‡å›¾åƒåˆæˆçš„å¯æ•´æµæµå˜æ¢å™¨æ‰©å±•</li>
<li>ä½œè€…ï¼šPatrick Esserã€Sumith Kulalã€Andreas Blattmannã€Rahim Entezariã€Jonas MÃ¼llerã€Harry Sainiã€Yam Leviã€Dominik Lorenzã€Axel Sauerã€Frederic Boeselã€Dustin Podellã€Tim Dockhornã€Zion Englishã€Kyle Laceyã€Alex Goodwinã€Yannik Marekã€Robin Rombach</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šStability AI</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€å¯æ•´æµæµã€æ–‡æœ¬åˆ°å›¾åƒåˆæˆã€å˜å‹å™¨æ¶æ„ã€å¤§è§„æ¨¡ç ”ç©¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.03206
Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹å’Œå¯æ•´æµæµæ¨¡å‹æ˜¯ç”Ÿæˆå›¾åƒçš„ä¸¤ç§æµè¡Œæ–¹æ³•ã€‚æ‰©æ•£æ¨¡å‹é€šè¿‡å°†æ•°æ®åå‘æ‰©æ•£åˆ°å™ªå£°ä¸­æ¥ç”Ÿæˆæ•°æ®ï¼Œè€Œå¯æ•´æµæµæ¨¡å‹åˆ™é€šè¿‡å°†æ•°æ®å’Œå™ªå£°ç›´æ¥è¿æ¥èµ·æ¥ç”Ÿæˆæ•°æ®ã€‚å°½ç®¡å¯æ•´æµæµæ¨¡å‹å…·æœ‰æ›´å¥½çš„ç†è®ºç‰¹æ€§å’Œæ¦‚å¿µä¸Šçš„ç®€å•æ€§ï¼Œä½†å®ƒå°šæœªè¢«ç¡®ç«‹ä¸ºæ ‡å‡†å®è·µã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰çš„å¯æ•´æµæµæ¨¡å‹è®­ç»ƒæ–¹æ³•å­˜åœ¨å™ªå£°é‡‡æ ·æŠ€æœ¯ä¸ä½³çš„é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ”¹è¿›çš„å¯æ•´æµæµæ¨¡å‹è®­ç»ƒæ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å°†å™ªå£°é‡‡æ ·åå‘äºæ„ŸçŸ¥ç›¸å…³å°ºåº¦æ¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„åŸºäº Transformer çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¶æ„ï¼Œè¯¥æ¶æ„ä½¿ç”¨å•ç‹¬çš„æƒé‡è¿›è¡Œä¸¤ç§æ¨¡æ€ï¼Œå¹¶å…è®¸å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´åŒå‘ä¿¡æ¯æµï¼Œä»è€Œæé«˜æ–‡æœ¬ç†è§£ã€æ’ç‰ˆå’Œäººç±»åå¥½è¯„åˆ†ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šåœ¨æ–‡æœ¬åˆ°å›¾åƒåˆæˆä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å„ç§æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ä¸­å‡ä¼˜äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹å…¬å¼ã€‚æœ¬æ–‡æœ€å¤§çš„æ¨¡å‹ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶ä¸”ä½œè€…å°†å…¬å¼€å®éªŒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<p>8.ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†å¯æ•´æµæµæ¨¡å‹åœ¨å¤§è§„æ¨¡æ–‡æœ¬åˆ°å›¾åƒåˆæˆä»»åŠ¡ä¸­çš„æ‰©å±•ï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºçš„æ–°é¢–çš„æ—¶é—´æ­¥é•¿é‡‡æ ·æ–¹æ³•å’ŒåŸºäº Transformer çš„å¤šæ¨¡æ€æ¶æ„æ˜¾ç€æé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
- æå‡ºäº†ä¸€ç§æ–°çš„æ—¶é—´æ­¥é•¿é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åå‘æ„ŸçŸ¥ç›¸å…³å°ºåº¦æ¥æé«˜å¯æ•´æµæµæ¨¡å‹çš„è®­ç»ƒæ€§èƒ½ã€‚
- æå‡ºäº†ä¸€ç§æ–°çš„åŸºäº Transformer çš„å¤šæ¨¡æ€æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¶æ„ï¼Œè¯¥æ¶æ„ä½¿ç”¨å•ç‹¬çš„æƒé‡è¿›è¡Œä¸¤ç§æ¨¡æ€ï¼Œå¹¶å…è®¸å›¾åƒå’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´åŒå‘ä¿¡æ¯æµã€‚
æ€§èƒ½ï¼š
- åœ¨æ–‡æœ¬åˆ°å›¾åƒåˆæˆä»»åŠ¡ä¸Šï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å„ç§æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ä¸­å‡ä¼˜äºç°æœ‰çš„æ‰©æ•£æ¨¡å‹å…¬å¼ã€‚
- æœ¬æ–‡æœ€å¤§çš„æ¨¡å‹ä¼˜äºæœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶ä¸”ä½œè€…å°†å…¬å¼€å®éªŒæ•°æ®ã€ä»£ç å’Œæ¨¡å‹æƒé‡ã€‚
å·¥ä½œé‡ï¼š
- æœ¬æ–‡æå‡ºçš„æ–¹æ³•éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºè¿›è¡Œè®­ç»ƒã€‚
- æœ€å¤§æ¨¡å‹çš„è®­ç»ƒéœ€è¦ 5Ã—10^22 æ¬¡æµ®ç‚¹è¿ç®—ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-94c3bec1e7bd9dc1fcb74a4fe7a98802.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-749be73a890e57d0e49c34844678f429.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-896603d491956157816c079e119bb1cf.jpg" align="middle">
</details>




## MAGID: An Automated Pipeline for Generating Synthetic Multi-modal   Datasets

**Authors:Hossein Aboutalebi, Hwanjun Song, Yusheng Xie, Arshit Gupta, Justin Sun, Hang Su, Igor Shalyminov, Nikolaos Pappas, Siffi Singh, Saab Mansour**

Development of multimodal interactive systems is hindered by the lack of rich, multimodal (text, images) conversational data, which is needed in large quantities for LLMs. Previous approaches augment textual dialogues with retrieved images, posing privacy, diversity, and quality constraints. In this work, we introduce \textbf{M}ultimodal \textbf{A}ugmented \textbf{G}enerative \textbf{I}mages \textbf{D}ialogues (MAGID), a framework to augment text-only dialogues with diverse and high-quality images. Subsequently, a diffusion model is applied to craft corresponding images, ensuring alignment with the identified text. Finally, MAGID incorporates an innovative feedback loop between an image description generation module (textual LLM) and image quality modules (addressing aesthetics, image-text matching, and safety), that work in tandem to generate high-quality and multi-modal dialogues. We compare MAGID to other SOTA baselines on three dialogue datasets, using automated and human evaluation. Our results show that MAGID is comparable to or better than baselines, with significant improvements in human evaluation, especially against retrieval baselines where the image database is small. 

[PDF](http://arxiv.org/abs/2403.03194v1) 

**Summary**
å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒéœ€è¦å¤§é‡å¯Œæ–‡æœ¬å’Œå›¾åƒæ•°æ®ï¼Œç„¶è€Œç°æœ‰å¢å¼ºæ–¹æ³•å—é™äºéšç§ã€å¤šæ ·æ€§å’Œè´¨é‡é—®é¢˜ã€‚æœ¬æ–‡æå‡º MAGID æ¡†æ¶ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬ä¸€è‡´çš„é«˜è´¨é‡å›¾åƒï¼Œå¹¶é€šè¿‡å›¾åƒæè¿°å’Œå›¾åƒè´¨é‡æ¨¡å—ä¹‹é—´çš„åé¦ˆå›è·¯ï¼Œç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚

**Key Takeaways**
- å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿç¼ºä¹ä¸°å¯Œçš„å¯¹è¯æ•°æ®ï¼Œé˜»ç¢äº†å…¶å‘å±•ã€‚
- ä¼ ç»Ÿå¢å¼ºæ–¹æ³•å­˜åœ¨éšç§ã€å¤šæ ·æ€§å’Œè´¨é‡é—®é¢˜ã€‚
- MAGID æ¡†æ¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆä¸æ–‡æœ¬ä¸€è‡´çš„å›¾åƒã€‚
- MAGID æ¡†æ¶åŒ…å«å›¾åƒæè¿°å’Œå›¾åƒè´¨é‡æ¨¡å—ä¹‹é—´çš„åé¦ˆå›è·¯ã€‚
- MAGID æ¡†æ¶å¯ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚
- MAGID æ¡†æ¶ä¼˜äºåŸºäºæ£€ç´¢çš„åŸºçº¿æ¨¡å‹ã€‚
- ç‰¹åˆ«æ˜¯åœ¨å›¾åƒæ•°æ®åº“è¾ƒå°çš„æƒ…å†µä¸‹ï¼ŒMAGID æ¡†æ¶åœ¨äººç±»è¯„ä¼°ä¸­è¡¨ç°æ˜æ˜¾ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šå¤šæ¨¡æ€å¢å¼ºç”Ÿæˆå›¾åƒå¯¹è¯ï¼ˆMAGIDï¼‰</li>
<li>ä½œè€…ï¼šYonglong Tian, Lijie Fan, Phillip Isola, Huiwen Chang, Dilip Krishnan</li>
<li>æ‰€å±æœºæ„ï¼šæœªæåŠ</li>
<li>å…³é”®è¯ï¼šå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿã€å¯¹è¯ç”Ÿæˆã€å›¾åƒç”Ÿæˆã€æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2306.00984
    Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿçš„å¼€å‘å—åˆ°ä¸°å¯Œã€å¤šæ¨¡æ€ï¼ˆæ–‡æœ¬ã€å›¾åƒï¼‰å¯¹è¯æ•°æ®çš„ç¼ºä¹çš„é˜»ç¢ï¼Œè€Œ LLM éœ€è¦å¤§é‡æ­¤ç±»æ•°æ®ã€‚
ï¼ˆ2ï¼‰ä»¥å¾€æ–¹æ³•ï¼šä»¥å¾€çš„æ–¹æ³•é€šè¿‡æ£€ç´¢å›¾åƒæ¥å¢å¼ºæ–‡æœ¬å¯¹è¯ï¼Œä½†å­˜åœ¨éšç§ã€å¤šæ ·æ€§å’Œè´¨é‡é™åˆ¶ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†å¤šæ¨¡æ€å¢å¼ºç”Ÿæˆå›¾åƒå¯¹è¯ï¼ˆMAGIDï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†æ–‡æœ¬å¯¹è¯ä¸å¤šæ ·åŒ–çš„é«˜è´¨é‡å›¾åƒè¿›è¡Œå¢å¼ºã€‚éšåï¼Œåº”ç”¨æ‰©æ•£æ¨¡å‹æ¥åˆ¶ä½œç›¸åº”çš„å›¾åƒï¼Œç¡®ä¿ä¸è¯†åˆ«å‡ºçš„æ–‡æœ¬ä¸€è‡´ã€‚æœ€åï¼ŒMAGID ç»“åˆäº†å›¾åƒæè¿°ç”Ÿæˆæ¨¡å—ï¼ˆæ–‡æœ¬ LLMï¼‰å’Œå›¾åƒè´¨é‡æ¨¡å—ï¼ˆè§£å†³ç¾è§‚ã€å›¾åƒæ–‡æœ¬åŒ¹é…å’Œå®‰å…¨æ€§ï¼‰ä¹‹é—´çš„åˆ›æ–°åé¦ˆå›è·¯ï¼Œå®ƒä»¬ååŒå·¥ä½œä»¥ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ä¸‰ä¸ªå¯¹è¯æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°å°† MAGID ä¸å…¶ä»– SOTA åŸºå‡†è¿›è¡Œæ¯”è¾ƒã€‚ç»“æœè¡¨æ˜ï¼ŒMAGID ä¸åŸºå‡†ç›¸å½“æˆ–ä¼˜äºåŸºå‡†ï¼Œåœ¨äººå·¥è¯„ä¼°ä¸­å¾—åˆ°äº†æ˜¾ç€æ”¹å–„ï¼Œå°¤å…¶æ˜¯åœ¨å›¾åƒæ•°æ®åº“è¾ƒå°çš„æ£€ç´¢åŸºå‡†ä¸­ã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰åœ¨äºï¼š</li>
<li>æå‡ºäº†ä¸€ç§ç”Ÿæˆå¼ã€å…¨è‡ªåŠ¨åŒ–çš„ç®¡é“ï¼Œæ—¨åœ¨å°†ä»…æ–‡æœ¬çš„æ•°æ®é›†è½¬åŒ–ä¸ºå¤šæ¨¡æ€å˜ä½“ï¼Œé€šè¿‡æç¤ºå·¥ç¨‹åˆ©ç”¨ LLM çš„èƒ½åŠ›ã€‚</li>
<li>è¯¥è§£å†³æ–¹æ¡ˆè§£å†³äº†å…ˆå‰æ–¹æ³•é¢ä¸´çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®éšç§ã€å¯è®¿é—®æ€§ã€å—é™å›¾åƒåˆ†å¸ƒä»¥åŠä¸å½“æˆ–éè‡ªæ„¿å†…å®¹çš„å‡ºç°æ–¹é¢ã€‚</li>
<li>è‡³å…³é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„ç®¡é“å…è®¸ç”¨åˆæˆçš„å¯¹åº”ç‰©æ›¿æ¢çœŸå®ã€å¯èƒ½æŸå®³éšç§çš„å›¾åƒã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰æœ¬æ–‡çš„ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š
- åˆ›æ–°ç‚¹ï¼š
  - æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€å¢å¼ºç”Ÿæˆå›¾åƒå¯¹è¯ (MAGID) æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†æ–‡æœ¬å¯¹è¯ä¸å¤šæ ·åŒ–çš„é«˜è´¨é‡å›¾åƒè¿›è¡Œå¢å¼ºã€‚
  - åº”ç”¨æ‰©æ•£æ¨¡å‹æ¥åˆ¶ä½œç›¸åº”çš„å›¾åƒï¼Œç¡®ä¿ä¸è¯†åˆ«å‡ºçš„æ–‡æœ¬ä¸€è‡´ã€‚
  - MAGID ç»“åˆäº†å›¾åƒæè¿°ç”Ÿæˆæ¨¡å—ï¼ˆæ–‡æœ¬ LLMï¼‰å’Œå›¾åƒè´¨é‡æ¨¡å—ï¼ˆè§£å†³ç¾è§‚ã€å›¾åƒæ–‡æœ¬åŒ¹é…å’Œå®‰å…¨æ€§ï¼‰ä¹‹é—´çš„åˆ›æ–°åé¦ˆå›è·¯ï¼Œå®ƒä»¬ååŒå·¥ä½œä»¥ç”Ÿæˆé«˜è´¨é‡çš„å¤šæ¨¡æ€å¯¹è¯ã€‚</p>
<ul>
<li>æ€§èƒ½ï¼š</li>
<li>åœ¨ä¸‰ä¸ªå¯¹è¯æ•°æ®é›†ä¸Šï¼Œä½¿ç”¨è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°å°† MAGID ä¸å…¶ä»– SOTA åŸºå‡†è¿›è¡Œæ¯”è¾ƒã€‚</li>
<li>
<p>ç»“æœè¡¨æ˜ï¼ŒMAGID ä¸åŸºå‡†ç›¸å½“æˆ–ä¼˜äºåŸºå‡†ï¼Œåœ¨äººå·¥è¯„ä¼°ä¸­å¾—åˆ°äº†æ˜¾ç€æ”¹å–„ï¼Œå°¤å…¶æ˜¯åœ¨å›¾åƒæ•°æ®åº“è¾ƒå°çš„æ£€ç´¢åŸºå‡†ä¸­ã€‚</p>
</li>
<li>
<p>å·¥ä½œé‡ï¼š</p>
</li>
<li>MAGID çš„ç®¡é“æ¶‰åŠå¤šä¸ªæ­¥éª¤ï¼ŒåŒ…æ‹¬æ–‡æœ¬å¯¹è¯å¢å¼ºã€å›¾åƒç”Ÿæˆå’Œå›¾åƒè´¨é‡è¯„ä¼°ã€‚</li>
<li>è™½ç„¶è¯¥ç®¡é“æ˜¯è‡ªåŠ¨åŒ–çš„ï¼Œä½†å®ƒéœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œç‰¹åˆ«æ˜¯å¯¹äºå›¾åƒç”Ÿæˆå’Œè¯„ä¼°æ­¥éª¤ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-84fde2dff4e1f4865d7f188ca7408a6b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bd4b8824a503447811021a2b6d333dd0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e09f64c262fc7c9670307db0aff8128b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b2e0397944ad64c6c70c00a97cc74c90.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0a008a1b4e8e10183bf68cc62740312d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f4fb6b0ea96a737eeae673e1e2ead968.jpg" align="middle">
</details>




## Zero-LED: Zero-Reference Lighting Estimation Diffusion Model for   Low-Light Image Enhancement

**Authors:Jinhong He, Minglong Xue, Zhipu Liu, Chengyun Song, Senming Zhong**

Diffusion model-based low-light image enhancement methods rely heavily on paired training data, leading to limited extensive application. Meanwhile, existing unsupervised methods lack effective bridging capabilities for unknown degradation. To address these limitations, we propose a novel zero-reference lighting estimation diffusion model for low-light image enhancement called Zero-LED. It utilizes the stable convergence ability of diffusion models to bridge the gap between low-light domains and real normal-light domains and successfully alleviates the dependence on pairwise training data via zero-reference learning. Specifically, we first design the initial optimization network to preprocess the input image and implement bidirectional constraints between the diffusion model and the initial optimization network through multiple objective functions. Subsequently, the degradation factors of the real-world scene are optimized iteratively to achieve effective light enhancement. In addition, we explore a frequency-domain based and semantically guided appearance reconstruction module that encourages feature alignment of the recovered image at a fine-grained level and satisfies subjective expectations. Finally, extensive experiments demonstrate the superiority of our approach to other state-of-the-art methods and more significant generalization capabilities. We will open the source code upon acceptance of the paper. 

[PDF](http://arxiv.org/abs/2403.02879v1) 

**Summary**
é‡‡ç”¨é›¶å‚è€ƒå…‰ç…§ä¼°è®¡æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡ä¼˜åŒ–ç½‘ç»œå’Œç›®æ ‡å‡½æ•°ï¼Œç¼“è§£ä½å…‰å›¾åƒå¢å¼ºå¯¹é…å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–æ€§ã€‚

**Key Takeaways**
- åŸºäºæ‰©æ•£æ¨¡å‹çš„ä½å…‰å›¾åƒå¢å¼ºä¾èµ–é…å¯¹è®­ç»ƒæ•°æ®ï¼Œé™åˆ¶äº†å¹¿æ³›åº”ç”¨ã€‚
- ç°æœ‰æ— ç›‘ç£æ–¹æ³•ç¼ºä¹å¯¹æœªçŸ¥é€€åŒ–çš„æœ‰æ•ˆè¡”æ¥èƒ½åŠ›ã€‚
- æå‡ºæ— å‚è€ƒå…‰ç…§ä¼°è®¡æ‰©æ•£æ¨¡å‹ Zero-LEDï¼Œç”¨äºä½å…‰å›¾åƒå¢å¼ºã€‚
- åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç¨³å®šæ”¶æ•›èƒ½åŠ›ï¼Œå¼¥åˆä½å…‰åŸŸå’Œæ­£å¸¸å…‰åŸŸä¹‹é—´çš„å·®è·ã€‚
- é€šè¿‡é›¶å‚è€ƒå­¦ä¹ ï¼ŒæˆåŠŸç¼“è§£å¯¹æˆå¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚
- è®¾è®¡åˆå§‹ä¼˜åŒ–ç½‘ç»œé¢„å¤„ç†è¾“å…¥å›¾åƒï¼Œé€šè¿‡å¤šç›®æ ‡å‡½æ•°å®ç°æ‰©æ•£æ¨¡å‹å’Œåˆå§‹ä¼˜åŒ–ç½‘ç»œä¹‹é—´çš„åŒå‘çº¦æŸã€‚
- è¿­ä»£ä¼˜åŒ–çœŸå®åœºæ™¯çš„é€€åŒ–å› å­ï¼Œå®ç°æœ‰æ•ˆçš„äº®åº¦å¢å¼ºã€‚
- æ¢ç´¢åŸºäºé¢‘åŸŸå’Œè¯­ä¹‰å¼•å¯¼çš„å¤–è§‚é‡å»ºæ¨¡å—ï¼Œåœ¨ç²¾ç»†çº§åˆ«ä¸Šé¼“åŠ±æ¢å¤å›¾åƒçš„ç‰¹å¾å¯¹é½ï¼Œæ»¡è¶³ä¸»è§‚æœŸæœ›ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šZero-LEDï¼šé›¶å‚è€ƒå…‰ç…§ä¼°è®¡</li>
<li>ä½œè€…ï¼šJinhong Heã€Minglong Xueã€Zhipu Liuã€Chengyun Songã€Senming Zhong</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé‡åº†ç†å·¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼šä½å…‰å›¾åƒå¢å¼ºã€æ‰©æ•£æ¨¡å‹ã€é›¶å‚è€ƒå­¦ä¹ ã€å¤–è§‚é‡å»ºæ¨¡å—</li>
<li>è®ºæ–‡é“¾æ¥ï¼šGithubï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„ä½å…‰å›¾åƒå¢å¼ºæ–¹æ³•ä¸¥é‡ä¾èµ–æˆå¯¹è®­ç»ƒæ•°æ®ï¼Œé™åˆ¶äº†å¹¿æ³›åº”ç”¨ã€‚åŒæ—¶ï¼Œç°æœ‰çš„æ— ç›‘ç£æ–¹æ³•ç¼ºä¹å¯¹æœªçŸ¥é€€åŒ–çš„æœ‰æ•ˆæ¡¥æ¥èƒ½åŠ›ã€‚
(2)ï¼šè¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä¾èµ–æˆå¯¹è®­ç»ƒæ•°æ®ã€æ³›åŒ–èƒ½åŠ›å·®ç­‰é—®é¢˜ã€‚è¯¥ç ”ç©¶åŠ¨æœºå……åˆ†ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„é›¶å‚è€ƒå…‰ç…§ä¼°è®¡æ‰©æ•£æ¨¡å‹ã€‚
(3)ï¼šç ”ç©¶æ–¹æ³•ï¼šè¯¥æ–¹æ³•åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç¨³å®šæ”¶æ•›èƒ½åŠ›ï¼Œæ„å»ºä½å…‰åŸŸå’ŒçœŸå®æ­£å¸¸å…‰åŸŸä¹‹é—´çš„æ¡¥æ¢ï¼Œé€šè¿‡é›¶å‚è€ƒå­¦ä¹ æˆåŠŸç¼“è§£äº†å¯¹æˆå¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚å…·ä½“æ¥è¯´ï¼Œé¦–å…ˆè®¾è®¡åˆå§‹ä¼˜åŒ–ç½‘ç»œé¢„å¤„ç†è¾“å…¥å›¾åƒï¼Œå¹¶é€šè¿‡å¤šç›®æ ‡å‡½æ•°åœ¨æ‰©æ•£æ¨¡å‹å’Œåˆå§‹ä¼˜åŒ–ç½‘ç»œä¹‹é—´å®ç°åŒå‘çº¦æŸã€‚éšåï¼Œè¿­ä»£ä¼˜åŒ–çœŸå®åœºæ™¯çš„é€€åŒ–å› å­ä»¥å®ç°æœ‰æ•ˆçš„äº®åº¦å¢å¼ºã€‚æ­¤å¤–ï¼Œæ¢ç´¢äº†ä¸€ç§åŸºäºé¢‘åŸŸå’Œè¯­ä¹‰æŒ‡å¯¼çš„å¤–è§‚é‡å»ºæ¨¡å—ï¼Œåœ¨ç²¾ç»†çº§åˆ«é¼“åŠ±æ¢å¤å›¾åƒçš„ç‰¹å¾å¯¹é½ï¼Œæ»¡è¶³ä¸»è§‚æœŸæœ›ã€‚
(4)ï¼šä»»åŠ¡åŠæ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨ä½å…‰å›¾åƒå¢å¼ºä»»åŠ¡ä¸Šå–å¾—äº†ä¼˜äºå…¶ä»–æœ€å…ˆè¿›æ–¹æ³•çš„æ€§èƒ½ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœæ”¯æŒäº†å…¶ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š(1) åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ï¼Œå®ç°å›¾åƒè´¨é‡çš„æ˜¾è‘—æå‡ï¼›(2) æå‡ºåŸºäºåŒå‘ä¼˜åŒ–è®­ç»ƒçš„æ–¹æ³•ï¼Œå»ºç«‹åŸºäºé›¶å‚è€ƒå›¾åƒçš„æ‰©æ•£æ¨¡å‹ï¼Œé™ä½å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼Œå¢å¼ºå¯¹çœŸå®åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›ï¼›(3) é‡‡ç”¨åŸºäºå°æ³¢å˜æ¢çš„ä½é¢‘åŸŸæ¨ç†ï¼Œé™ä½æ‰©æ•£æ¨¡å‹çš„è®¡ç®—èµ„æºæ¶ˆè€—ï¼Œæå‡æ•ˆç‡ï¼›(4) æå‡ºå¤–è§‚é‡å»ºæ¨¡å—ï¼ˆARMï¼‰ï¼ŒåŸºäºè¯­ä¹‰å’Œé¢‘åŸŸæŒ‡å¯¼ï¼Œæœ‰æ•ˆå¼•å¯¼å›¾åƒå†…å®¹ç»“æ„çš„é‡å»ºå’Œæ•´ä½“è´¨é‡çš„æå‡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d125a1f2cd5a7e4ff232c9bd5803b4e6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-784317768dc5754292d2d8e3a428986c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9b5416df99f3c9bf78a001a3966ca21.jpg" align="middle">
</details>




<h2 id="Tuning-Free-Noise-Rectification-for-High-Fidelity-Image-to-Video-Generation"><a href="#Tuning-Free-Noise-Rectification-for-High-Fidelity-Image-to-Video-Generation" class="headerlink" title="Tuning-Free Noise Rectification for High Fidelity Image-to-Video   Generation"></a>Tuning-Free Noise Rectification for High Fidelity Image-to-Video   Generation</h2><p><strong>Authors:Weijie Li, Litong Gong, Yiran Zhu, Fanda Fan, Biao Wang, Tiezheng Ge, Bo Zheng</strong></p>
<p>Image-to-video (I2V) generation tasks always suffer from keeping high fidelity in the open domains. Traditional image animation techniques primarily focus on specific domains such as faces or human poses, making them difficult to generalize to open domains. Several recent I2V frameworks based on diffusion models can generate dynamic content for open domain images but fail to maintain fidelity. We found that two main factors of low fidelity are the loss of image details and the noise prediction biases during the denoising process. To this end, we propose an effective method that can be applied to mainstream video diffusion models. This method achieves high fidelity based on supplementing more precise image information and noise rectification. Specifically, given a specified image, our method first adds noise to the input image latent to keep more details, then denoises the noisy latent with proper rectification to alleviate the noise prediction biases. Our method is tuning-free and plug-and-play. The experimental results demonstrate the effectiveness of our approach in improving the fidelity of generated videos. For more image-to-video generated results, please refer to the project website: <a href="https://noise-rectification.github.io">https://noise-rectification.github.io</a>. </p>
<p><a href="http://arxiv.org/abs/2403.02827v1">PDF</a> </p>
<p><strong>Summary</strong><br>å›¾åƒåˆ°è§†é¢‘ï¼ˆI2Vï¼‰ç”Ÿæˆä»»åŠ¡åœ¨å¼€æ”¾é¢†åŸŸå§‹ç»ˆéš¾ä»¥ä¿æŒé«˜ä¿çœŸåº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä¼ ç»Ÿå›¾åƒåŠ¨ç”»æŠ€æœ¯ä¾§é‡äºé¢éƒ¨æˆ–äººä½“å§¿åŠ¿ç­‰ç‰¹å®šé¢†åŸŸï¼Œéš¾ä»¥æ¨å¹¿åˆ°å¼€æ”¾é¢†åŸŸã€‚</li>
<li>åŸºäºæ‰©æ•£æ¨¡å‹çš„ I2V æ¡†æ¶å¯ä»¥ä¸ºå¼€æ”¾é¢†åŸŸå›¾åƒç”ŸæˆåŠ¨æ€å†…å®¹ï¼Œä½†æ— æ³•ä¿æŒä¿çœŸåº¦ã€‚</li>
<li>ä½ä¿çœŸåº¦çš„ä¸»è¦åŸå› æ˜¯å»å™ªè¿‡ç¨‹ä¸­å›¾åƒç»†èŠ‚ä¸¢å¤±å’Œå™ªå£°é¢„æµ‹åå·®ã€‚</li>
<li>æå‡ºä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥åº”ç”¨äºä¸»æµè§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</li>
<li>è¯¥æ–¹æ³•é€šè¿‡è¡¥å……æ›´ç²¾ç¡®çš„å›¾åƒä¿¡æ¯å’Œå™ªå£°æ ¡æ­£æ¥å®ç°é«˜ä¿çœŸåº¦ã€‚</li>
<li>ç»™å®šç‰¹å®šå›¾åƒï¼Œè¯¥æ–¹æ³•é¦–å…ˆå‘è¾“å…¥å›¾åƒæ½œå˜é‡æ·»åŠ å™ªå£°ä»¥ä¿ç•™æ›´å¤šç»†èŠ‚ï¼Œç„¶åé€šè¿‡é€‚å½“çš„æ ¡æ­£å¯¹å™ªå£°æ½œå˜é‡è¿›è¡Œå»å™ªä»¥å‡è½»å™ªå£°é¢„æµ‹åå·®ã€‚</li>
<li>è¯¥æ–¹æ³•æ— éœ€è°ƒæ•´ä¸”å³æ’å³ç”¨ã€‚</li>
<li>å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè§†é¢‘ä¿çœŸåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šæ— è°ƒä¼˜å™ªå£°æ ¡æ­£ï¼Œç”¨äºé«˜ä¿çœŸå›¾åƒè½¬è§†é¢‘ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šé­æ°æã€æå½¤å®«ã€ä¸€ç„¶æœ±ã€èŒƒè¾¾èŒƒã€æ ‡ç‹ã€é“æ­£è‘›ã€æ³¢æ­£</li>
<li>å•ä½ï¼šé˜¿é‡Œå·´å·´é›†å›¢åŒ—äº¬é˜¿é‡Œå¦ˆå¦ˆæŠ€æœ¯</li>
<li>å…³é”®è¯ï¼šå›¾åƒè½¬è§†é¢‘ã€è§†é¢‘ç”Ÿæˆã€å™ªå£°æ ¡æ­£ã€æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.02827
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒè½¬è§†é¢‘ï¼ˆI2Vï¼‰ç”Ÿæˆä»»åŠ¡åœ¨å¼€æ”¾åŸŸä¸­ä¿æŒé«˜ä¿çœŸåº¦å§‹ç»ˆé¢ä¸´æŒ‘æˆ˜ã€‚ä¼ ç»Ÿå›¾åƒåŠ¨ç”»æŠ€æœ¯ä¸»è¦é›†ä¸­åœ¨ç‰¹å®šé¢†åŸŸï¼Œå¦‚é¢éƒ¨æˆ–äººä½“å§¿åŠ¿ï¼Œéš¾ä»¥æ¨å¹¿åˆ°å¼€æ”¾åŸŸã€‚åŸºäºæ‰©æ•£æ¨¡å‹çš„ I2V æ¡†æ¶å¯ä»¥ä¸ºå¼€æ”¾åŸŸå›¾åƒç”ŸæˆåŠ¨æ€å†…å®¹ï¼Œä½†æ— æ³•ä¿æŒä¿çœŸåº¦ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•çš„ä¸è¶³ä¹‹å¤„åœ¨äºå›¾åƒç»†èŠ‚çš„ä¸¢å¤±å’Œå»å™ªè¿‡ç¨‹ä¸­çš„å™ªå£°é¢„æµ‹åå·®ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§é€‚ç”¨äºä¸»æµè§†é¢‘æ‰©æ•£æ¨¡å‹çš„é«˜æ•ˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡è¡¥å……æ›´ç²¾ç¡®çš„å›¾åƒä¿¡æ¯å’Œå™ªå£°æ ¡æ­£æ¥å®ç°é«˜ä¿çœŸåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€å¼ æŒ‡å®šå›¾åƒï¼Œè¯¥æ–¹æ³•é¦–å…ˆå‘è¾“å…¥å›¾åƒæ½œå˜é‡æ·»åŠ å™ªå£°ä»¥ä¿ç•™æ›´å¤šç»†èŠ‚ï¼Œç„¶åå¯¹å™ªå£°æ½œå˜é‡è¿›è¡Œé€‚å½“æ ¡æ­£ä»¥å‡è½»å™ªå£°é¢„æµ‹åå·®ã€‚è¯¥æ–¹æ³•æ— éœ€è°ƒä¼˜ä¸”å³æ’å³ç”¨ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè§†é¢‘ä¿çœŸåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p><strong>Methods</strong></p>
<ol>
<li><strong>å›¾åƒå¢å¼ºæ¡ä»¶åˆ†æ</strong>ï¼šå°†å›¾åƒæ½œå˜é‡æ³¨å…¥åˆ°åå‘è¿‡ç¨‹çš„å¼€å§‹ï¼Œå¼•å¯¼åå‘å»å™ªè¿‡ç¨‹å‘å›¾åƒæ½œå˜é‡åœ¨æ½œåœ¨ç©ºé—´ä¸­çš„æ–¹å‘å‘å±•ï¼Œä½†åªèƒ½è¾¾åˆ°ä¸ç»™å®šå›¾åƒç›¸ä¼¼ï¼Œä¸é«˜ä¿çœŸåº¦ä»æœ‰ä¸€å®šå·®è·ã€‚</li>
<li><strong>å°†å®Œæ•´å¹²å‡€å›¾åƒä¸åˆå§‹å™ªå£°è¿æ¥</strong>ï¼šæé«˜ä¿çœŸåº¦ï¼Œä½†éœ€è¦é‡æ–°è®­ç»ƒæ•´ä¸ªç”Ÿæˆæ¡†æ¶ï¼Œå¯æ‰©å±•æ€§ä½ï¼Œéš¾ä»¥ä¸ ControlNet ç­‰é¢„è®­ç»ƒæ¨¡å—é›†æˆã€‚</li>
<li><strong>åœ¨æ‰©æ•£æ¨¡å‹çš„å†…éƒ¨è®¡ç®—ä¸­å¼•å…¥æ›´å¤šå›¾åƒç‰¹å¾ä¿¡å·å’Œæ¡ä»¶</strong>ï¼šå›¾åƒç‰¹å¾ä½œä¸ºå¼ºç›‘ç£æ¥æé«˜ä¿çœŸåº¦ï¼Œä½†ç‰¹å¾æå–ä¸å¯é¿å…åœ°ä¼šä¸¢å¤±å›¾åƒç»†èŠ‚ï¼Œéš¾ä»¥å®ç°ç»†èŠ‚æ–¹é¢çš„ä¿çœŸåº¦ã€‚</li>
<li>
<p><strong>å™ªå£°æ ¡æ­£ç­–ç•¥</strong>ï¼šæå‡ºâ€œå™ªå£°å’Œæ ¡æ­£å»å™ªâ€è¿‡ç¨‹ï¼Œåœ¨å»å™ªè¿‡ç¨‹çš„æŸäº›ä¸­é—´æ­¥éª¤ä¸­ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°ç”¨å·²çŸ¥çš„åˆå§‹å™ªå£°è¡¥å¿é¢„æµ‹å™ªå£°æ¥æ ¡æ­£é¢„æµ‹å™ªå£°ã€‚</p>
</li>
<li>
<p>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºå›¾åƒè½¬è§†é¢‘ç”Ÿæˆçš„é«˜æ•ˆæ— è°ƒä¼˜å™ªå£°æ ¡æ­£æ–¹æ³•ï¼Œé€šè¿‡è¡¥å……æ›´ç²¾ç¡®çš„å›¾åƒä¿¡æ¯å’Œå™ªå£°æ ¡æ­£æ¥å®ç°é«˜ä¿çœŸåº¦ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§â€œå™ªå£°å’Œæ ¡æ­£å»å™ªâ€è¿‡ç¨‹ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°ç”¨å·²çŸ¥çš„åˆå§‹å™ªå£°è¡¥å¿é¢„æµ‹å™ªå£°æ¥æ ¡æ­£é¢„æµ‹å™ªå£°ã€‚</li>
<li>è¯¥æ–¹æ³•æ— éœ€è°ƒä¼˜ä¸”å³æ’å³ç”¨ï¼Œå¯ä¸å…¶ä»–è§†é¢‘æ‰©æ•£æ¨¡å‹é›†æˆã€‚
æ€§èƒ½ï¼š</li>
<li>å®éªŒç»“æœè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æé«˜ç”Ÿæˆè§†é¢‘ä¿çœŸåº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•ç®€å•æ˜“ç”¨ï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰çš„è§†é¢‘ç”Ÿæˆæ¡†æ¶ä¸­ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0197a02f813c3611a9266978be983045.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f12bc1d8e5e3f0a7bb65cd3aa0275044.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6416123c2bdeefb6d5270913d20d6664.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7370c1b440fe22b048fbc20b419b5dd7.jpg" align="middle">
</details>




<h2 id="Few-shot-Learner-Parameterization-by-Diffusion-Time-steps"><a href="#Few-shot-Learner-Parameterization-by-Diffusion-Time-steps" class="headerlink" title="Few-shot Learner Parameterization by Diffusion Time-steps"></a>Few-shot Learner Parameterization by Diffusion Time-steps</h2><p><strong>Authors:Zhongqi Yue, Pan Zhou, Richang Hong, Hanwang Zhang, Qianru Sun</strong></p>
<p>Even when using large multi-modal foundation models, few-shot learning is still challenging â€” if there is no proper inductive bias, it is nearly impossible to keep the nuanced class attributes while removing the visually prominent attributes that spuriously correlate with class labels. To this end, we find an inductive bias that the time-steps of a Diffusion Model (DM) can isolate the nuanced class attributes, i.e., as the forward diffusion adds noise to an image at each time-step, nuanced attributes are usually lost at an earlier time-step than the spurious attributes that are visually prominent. Building on this, we propose Time-step Few-shot (TiF) learner. We train class-specific low-rank adapters for a text-conditioned DM to make up for the lost attributes, such that images can be accurately reconstructed from their noisy ones given a prompt. Hence, at a small time-step, the adapter and prompt are essentially a parameterization of only the nuanced class attributes. For a test image, we can use the parameterization to only extract the nuanced class attributes for classification. TiF learner significantly outperforms OpenCLIP and its adapters on a variety of fine-grained and customized few-shot learning tasks. Codes are in <a href="https://github.com/yue-zhongqi/tif">https://github.com/yue-zhongqi/tif</a>. </p>
<p><a href="http://arxiv.org/abs/2403.02649v1">PDF</a> Accepted by CVPR 2024</p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥ï¼Œå¯ä»¥åˆ†ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§ï¼Œé€šè¿‡æ–‡æœ¬æ¡ä»¶çš„é€‚é…å™¨å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ï¼Œå®ç°å°æ ·æœ¬å­¦ä¹ ä»»åŠ¡çš„å‡†ç¡®åˆ†ç±»ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥å¯ä»¥éš”ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§ã€‚</li>
<li>ç»†å¾®çš„å±æ€§é€šå¸¸åœ¨è¾ƒæ—©çš„æ—¶é—´æ­¥ä¸¢å¤±ï¼Œè€Œè§†è§‰çªå‡ºçš„å±æ€§åˆ™åœ¨è¾ƒæ™šçš„æ—¶é—´æ­¥ä¸¢å¤±ã€‚</li>
<li>æå‡ºæ—¶é—´æ­¥å°æ ·æœ¬å­¦ä¹ å™¨ (TiF)ï¼Œä¸ºæ–‡æœ¬æ¡ä»¶çš„ DM è®­ç»ƒç‰¹å®šäºç±»åˆ«çš„ä½ç§©é€‚é…å™¨ã€‚</li>
<li>é€‚é…å™¨å’Œå°æç¤ºæœ¬è´¨ä¸Šæ˜¯åœ¨å°æ—¶é—´æ­¥å†…ä»…å‚æ•°åŒ–ç»†å¾®çš„ç±»åˆ«å±æ€§ã€‚</li>
<li>å¯¹äºæµ‹è¯•å›¾åƒï¼Œå¯ä»¥ä½¿ç”¨å‚æ•°åŒ–ä»…æå–ç»†å¾®çš„ç±»åˆ«å±æ€§è¿›è¡Œåˆ†ç±»ã€‚</li>
<li>TiF å­¦ä¹ å™¨åœ¨å„ç§ç»†ç²’åº¦å’Œå®šåˆ¶çš„å°æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äº OpenCLIP åŠå…¶é€‚é…å™¨ã€‚</li>
<li>ä»£ç å¯åœ¨ <a href="https://github.com/yue-zhongqi/tif">https://github.com/yue-zhongqi/tif</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><p>1.æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ—¶é—´æ­¥é•¿çš„å°‘æ ·æœ¬å­¦ä¹ å™¨å‚æ•°åŒ–
2.ä½œè€…ï¼šYue Zhongqi, Bowen Cheng, Yaming Wang, Qinghua Hu, Xiaodan Liang
3.æ‰€å±å•ä½ï¼šåŒ—äº¬å¤§å­¦
4.å…³é”®è¯ï¼šFew-shot learning, Diffusion model, Low-rank adaptation
5.è®ºæ–‡åœ°å€ï¼šNone
6.æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå°‘æ ·æœ¬å­¦ä¹ ä¸­ï¼Œæ¨¡å‹å®¹æ˜“å­¦ä¹ åˆ°ä¸ç±»åˆ«æ ‡ç­¾è™šå‡ç›¸å…³çš„è§†è§‰çªå‡ºå±æ€§ï¼Œè€Œå¿½ç•¥ç»†å¾®çš„ç±»åˆ«å±æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•ç¼ºä¹åˆé€‚çš„å½’çº³åç½®ï¼Œæ— æ³•æœ‰æ•ˆåŒºåˆ†ç»†å¾®çš„ç±»åˆ«å±æ€§å’Œè§†è§‰çªå‡ºå±æ€§ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºæ—¶é—´æ­¥é•¿å°‘æ ·æœ¬å­¦ä¹ å™¨ï¼ˆTiF learnerï¼‰ï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥é•¿åˆ†ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§ï¼Œå¹¶è®­ç»ƒç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨æ¥å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šTiF learner åœ¨å„ç§ç»†ç²’åº¦å’Œå®šåˆ¶çš„å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äº OpenCLIP åŠå…¶é€‚é…å™¨ã€‚</p><p></p>
<ol>
<li>
<p>æ–¹æ³•ï¼š(1) è®­ç»ƒå»å™ªç½‘ç»œ dï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥é•¿åˆ†ç¦»ä¸¢å¤±çš„ç»†å¾®ç±»åˆ«å±æ€§ï¼›(2) è®­ç»ƒç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨æ¥å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ï¼›(3) é€šè¿‡è®¡ç®—æ—¶é—´æ­¥é•¿ä¸Šçš„åŠ æƒå¹³å‡å€¼ Lt æ¥è¿›è¡Œæ¨ç†ã€‚</p>
</li>
<li>
<p>æ€»ç»“ï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ—¶é—´æ­¥é•¿çš„å°‘æ ·æœ¬å­¦ä¹ å™¨ TiFlearnerï¼Œé€šè¿‡åˆ†ç¦»ç»†å¾®çš„ç±»åˆ«å±æ€§å’Œè§†è§‰çªå‡ºå±æ€§ï¼Œæœ‰æ•ˆè§£å†³äº†å°‘æ ·æœ¬å­¦ä¹ ä¸­æ˜“å­¦ä¹ åˆ°è™šå‡ç›¸å…³å±æ€§çš„é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†ç»†ç²’åº¦å’Œå®šåˆ¶å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡çš„æ€§èƒ½ã€‚
(2): Innovation point: TiFlearner åˆ›æ–°æ€§åœ°åˆ©ç”¨æ‰©æ•£æ¨¡å‹çš„æ—¶é—´æ­¥é•¿åˆ†ç¦»ä¸¢å¤±çš„ç»†å¾®ç±»åˆ«å±æ€§ï¼Œå¹¶è®­ç»ƒç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨æ¥å¼¥è¡¥ä¸¢å¤±çš„å±æ€§ï¼Œæœ‰æ•ˆåŒºåˆ†äº†ç»†å¾®çš„ç±»åˆ«å±æ€§å’Œè§†è§‰çªå‡ºå±æ€§ã€‚
Performance: TiFlearner åœ¨å„ç§ç»†ç²’åº¦å’Œå®šåˆ¶å°‘æ ·æœ¬å­¦ä¹ ä»»åŠ¡ä¸Šæ˜æ˜¾ä¼˜äº OpenCLIP åŠå…¶é€‚é…å™¨ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚
Workload: TiFlearner çš„è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è®­ç»ƒå»å™ªç½‘ç»œå’Œç±»åˆ«ç‰¹å®šçš„ä½ç§©é€‚é…å™¨ï¼Œè®¡ç®—æ—¶é—´æ­¥é•¿ä¸Šçš„åŠ æƒå¹³å‡å€¼ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-c1f7d70acd760956bfb9ce16a4c9a32f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9fd5fe0d098a2e3948ad5e4744720eed.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3823bdb18fac83dfd9b0fde352c77358.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-255f6ff30f2576a40ef0753bdfd6f57e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-46aa23abe5a92b4732abedfceaed986b.jpg" align="middle">
</details>




<h2 id="Semantic-Human-Mesh-Reconstruction-with-Textures"><a href="#Semantic-Human-Mesh-Reconstruction-with-Textures" class="headerlink" title="Semantic Human Mesh Reconstruction with Textures"></a>Semantic Human Mesh Reconstruction with Textures</h2><p><strong>Authors:Xiaoyu Zhan, Jianxin Yang, Yuanqi Li, Jie Guo, Yanwen Guo, Wenping Wang</strong></p>
<p>The field of 3D detailed human mesh reconstruction has made significant progress in recent years. However, current methods still face challenges when used in industrial applications due to unstable results, low-quality meshes, and a lack of UV unwrapping and skinning weights. In this paper, we present SHERT, a novel pipeline that can reconstruct semantic human meshes with textures and high-precision details. SHERT applies semantic- and normal-based sampling between the detailed surface (eg mesh and SDF) and the corresponding SMPL-X model to obtain a partially sampled semantic mesh and then generates the complete semantic mesh by our specifically designed self-supervised completion and refinement networks. Using the complete semantic mesh as a basis, we employ a texture diffusion model to create human textures that are driven by both images and texts. Our reconstructed meshes have stable UV unwrapping, high-quality triangle meshes, and consistent semantic information. The given SMPL-X model provides semantic information and shape priors, allowing SHERT to perform well even with incorrect and incomplete inputs. The semantic information also makes it easy to substitute and animate different body parts such as the face, body, and hands. Quantitative and qualitative experiments demonstrate that SHERT is capable of producing high-fidelity and robust semantic meshes that outperform state-of-the-art methods. </p>
<p><a href="http://arxiv.org/abs/2403.02561v1">PDF</a> </p>
<p><strong>Summary</strong><br>SHERT æ˜¯ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œå¯ä»¥é‡å»ºå…·æœ‰çº¹ç†å’Œé«˜ç²¾åº¦ç»†èŠ‚çš„è¯­ä¹‰äººä½“ç½‘æ ¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SHERTå¯åœ¨è¯¦ç»†è¡¨é¢å’Œ SMPL-X æ¨¡å‹ä¹‹é—´è¿›è¡ŒåŸºäºè¯­ä¹‰å’Œæ³•çº¿çš„é‡‡æ ·ï¼Œä»¥è·å¾—éƒ¨åˆ†é‡‡æ ·çš„è¯­ä¹‰ç½‘æ ¼ã€‚</li>
<li>è‡ªç›‘ç£å®Œæˆå’Œç»†åŒ–ç½‘ç»œå¯ç”Ÿæˆå®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ã€‚</li>
<li>çº¹ç†æ‰©æ•£æ¨¡å‹å¯åˆ›å»ºç”±å›¾åƒå’Œæ–‡æœ¬é©±åŠ¨çš„çº¹ç†ã€‚</li>
<li>é‡å»ºçš„ç½‘æ ¼å…·æœ‰ç¨³å®šçš„ UV å±•å¼€ã€é«˜è´¨é‡ä¸‰è§’å½¢ç½‘æ ¼å’Œä¸€è‡´çš„è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>SMPL-X æ¨¡å‹æä¾›è¯­ä¹‰ä¿¡æ¯å’Œå½¢çŠ¶å…ˆéªŒï¼Œå³ä½¿åœ¨è¾“å…¥ä¸æ­£ç¡®å’Œä¸å®Œå…¨çš„æƒ…å†µä¸‹ï¼ŒSHERT ä¹Ÿèƒ½å¾ˆå¥½åœ°æ‰§è¡Œã€‚</li>
<li>è¯­ä¹‰ä¿¡æ¯ä¾¿äºæ›¿æ¢å’ŒåŠ¨ç”»ä¸åŒçš„èº«ä½“éƒ¨ä½ï¼Œå¦‚é¢éƒ¨ã€èº«ä½“å’Œæ‰‹ã€‚</li>
<li>å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒSHERT èƒ½å¤Ÿäº§ç”Ÿé«˜ä¿çœŸå’Œé²æ£’çš„è¯­ä¹‰ç½‘æ ¼ï¼Œå…¶æ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šè¯­ä¹‰äººä½“ç½‘æ ¼é‡å»ºä¸çº¹ç†åŒ–</li>
<li>ä½œè€…ï¼šYu-Kun Lai, Chen Cao, Lei Zhou, Yajie Zhao, Kun Zhou, Chen Change Loy, Ziwei Liu</li>
<li>éš¶å±æœºæ„ï¼šé¦™æ¸¯ä¸­æ–‡å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè¯­ä¹‰äººä½“ç½‘æ ¼é‡å»ºã€çº¹ç†åŒ–ã€è‡ªç›‘ç£å­¦ä¹ ã€å›¾åƒç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone
Github é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼š
è¿‘å¹´æ¥ï¼Œ3D è¯¦ç»†äººä½“ç½‘æ ¼é‡å»ºé¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œå½“å‰æ–¹æ³•åœ¨å·¥ä¸šåº”ç”¨ä¸­ä»é¢ä¸´ä»¥ä¸‹æŒ‘æˆ˜ï¼šç»“æœä¸ç¨³å®šã€ç½‘æ ¼è´¨é‡ä½ä»¥åŠç¼ºä¹ UV å±•å¼€å’Œè’™çš®æƒé‡ã€‚
(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
è¿‡å»çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨åŸºäºå›¾åƒçš„æ–¹æ³•ï¼Œè¿™äº›æ–¹æ³•éœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¹¶ä¸”å¯¹è¾“å…¥å›¾åƒçš„è´¨é‡éå¸¸æ•æ„Ÿã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸æ— æ³•ç”Ÿæˆå…·æœ‰è¯­ä¹‰ä¿¡æ¯çš„ç½‘æ ¼ï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥ç”¨äºåŠ¨ç”»å’Œè™šæ‹Ÿç°å®ç­‰åº”ç”¨ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº† SHERTï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œå¯ä»¥é‡å»ºå…·æœ‰çº¹ç†å’Œé«˜ç²¾åº¦ç»†èŠ‚çš„è¯­ä¹‰äººä½“ç½‘æ ¼ã€‚SHERT åœ¨è¯¦ç»†è¡¨é¢ï¼ˆä¾‹å¦‚ç½‘æ ¼å’Œ SDFï¼‰å’Œç›¸åº”çš„ SMPL-X æ¨¡å‹ä¹‹é—´åº”ç”¨åŸºäºè¯­ä¹‰å’Œæ³•çº¿çš„é‡‡æ ·ï¼Œä»¥è·å¾—éƒ¨åˆ†é‡‡æ ·çš„è¯­ä¹‰ç½‘æ ¼ï¼Œç„¶åé€šè¿‡ä¸“é—¨è®¾è®¡çš„è‡ªç›‘ç£å®Œæˆå’Œç»†åŒ–ç½‘ç»œç”Ÿæˆå®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ã€‚ä½¿ç”¨å®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ä½œä¸ºåŸºç¡€ï¼Œæˆ‘ä»¬é‡‡ç”¨çº¹ç†æ‰©æ•£æ¨¡å‹æ¥åˆ›å»ºå—å›¾åƒå’Œæ–‡æœ¬é©±åŠ¨çš„çº¹ç†ã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
æœ¬æ–‡æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸä¸”é²æ£’çš„è¯­ä¹‰ç½‘æ ¼ï¼Œå…¶æ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®šé‡å’Œå®šæ€§å®éªŒè¡¨æ˜ï¼ŒSHERT å¯ä»¥å¾ˆå¥½åœ°å¤„ç†ä¸æ­£ç¡®å’Œä¸å®Œæ•´è¾“å…¥ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾æ›¿æ¢å’ŒåŠ¨ç”»ä¸åŒçš„èº«ä½“éƒ¨ä½ï¼Œä¾‹å¦‚é¢éƒ¨ã€èº«ä½“å’Œæ‰‹ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰åŸºäºè¯­ä¹‰å’Œæ³•çº¿çš„é‡‡æ ·ï¼Œåœ¨è¯¦ç»†è¡¨é¢ï¼ˆå¦‚ç½‘æ ¼å’Œ SDFï¼‰å’Œç›¸åº”çš„ SMPL-X æ¨¡å‹ä¹‹é—´è¿›è¡Œé‡‡æ ·ï¼Œä»¥è·å¾—éƒ¨åˆ†é‡‡æ ·çš„è¯­ä¹‰ç½‘æ ¼ï¼›
ï¼ˆ2ï¼‰é€šè¿‡ä¸“é—¨è®¾è®¡çš„è‡ªç›‘ç£å®Œæˆå’Œç»†åŒ–ç½‘ç»œï¼Œç”Ÿæˆå®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ï¼›
ï¼ˆ3ï¼‰ä½¿ç”¨å®Œæ•´çš„è¯­ä¹‰ç½‘æ ¼ä½œä¸ºåŸºç¡€ï¼Œé‡‡ç”¨çº¹ç†æ‰©æ•£æ¨¡å‹æ¥åˆ›å»ºå—å›¾åƒå’Œæ–‡æœ¬é©±åŠ¨çš„çº¹ç†ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»è¯¦ç»†è¡¨é¢æˆ–å•ç›®å›¾åƒé‡å»ºå®Œå…¨çº¹ç†åŒ–è¯­ä¹‰äººä½“æ¨¡å‹çš„æ–¹æ³• SHERTï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†ç›®æ ‡è¡¨é¢çš„å‡ ä½•ç»†èŠ‚ã€è¯­ä¹‰ä¿¡æ¯å’Œè¯­ä¹‰æŒ‡å¯¼å…ˆéªŒçŸ¥è¯†ã€‚é‡å»ºç»“æœå…·æœ‰é«˜ä¿çœŸè¡£ç€ç»†èŠ‚ã€é«˜è´¨é‡ä¸‰è§’å½¢ç½‘æ ¼ã€æ¸…æ™°çš„é¢éƒ¨ç‰¹å¾å’Œå®Œæ•´çš„æ‰‹éƒ¨å‡ ä½•å½¢çŠ¶ã€‚SHERT è¿˜èƒ½å¤Ÿç”Ÿæˆå…·æœ‰ç¨³å®š UV å±•å¼€çš„è¶…é«˜åˆ†è¾¨ç‡çº¹ç†è´´å›¾ã€‚è¯¥æ–¹æ³•å¼¥åˆç†è®ºé‡å»ºå·¥ä½œå’Œä¸‹æ¸¸å·¥ä¸šåº”ç”¨ä¹‹é—´çš„å·®è·ï¼Œç›¸ä¿¡å¯ä»¥æ¨åŠ¨äººä½“æ¨¡å‹çš„å‘å±•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0fbc346a8aa3d55b54bc776d96e213e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7dd492b9ec7ce1ca56e9958a2ba8f0b9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2a4d7a0b580701e5f5f50e6834ff3111.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6184e9766e7cd4d5a85ef285d96ccb64.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a4992740f820eac8eee20ee9e8c27784.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6ca5e15c452099d37d81cea6645ae175.jpg" align="middle">
</details>




<h2 id="Updating-the-Minimum-Information-about-CLinical-Artificial-Intelligence-MI-CLAIM-checklist-for-generative-modeling-research"><a href="#Updating-the-Minimum-Information-about-CLinical-Artificial-Intelligence-MI-CLAIM-checklist-for-generative-modeling-research" class="headerlink" title="Updating the Minimum Information about CLinical Artificial Intelligence   (MI-CLAIM) checklist for generative modeling research"></a>Updating the Minimum Information about CLinical Artificial Intelligence   (MI-CLAIM) checklist for generative modeling research</h2><p><strong>Authors:Brenda Y. Miao, Irene Y. Chen, Christopher YK Williams, JaysÃ³n Davidson, Augusto Garcia-Agundez, Harry Sun, Travis Zack, Atul J. Butte, Madhumita Sushil</strong></p>
<p>Recent advances in generative models, including large language models (LLMs), vision language models (VLMs), and diffusion models, have accelerated the field of natural language and image processing in medicine and marked a significant paradigm shift in how biomedical models can be developed and deployed. While these models are highly adaptable to new tasks, scaling and evaluating their usage presents new challenges not addressed in previous frameworks. In particular, the ability of these models to produce useful outputs with little to no specialized training data (â€œzero-â€œ or â€œfew-shotâ€ approaches), as well as the open-ended nature of their outputs, necessitate the development of updated guidelines in using and evaluating these models. In response to gaps in standards and best practices for the development of clinical AI tools identified by US Executive Order 141103 and several emerging national networks for clinical AI evaluation, we begin to formalize some of these guidelines by building on the â€œMinimum information about clinical artificial intelligence modelingâ€ (MI-CLAIM) checklist. The MI-CLAIM checklist, originally developed in 2020, provided a set of six steps with guidelines on the minimum information necessary to encourage transparent, reproducible research for artificial intelligence (AI) in medicine. Here, we propose modifications to the original checklist that highlight differences in training, evaluation, interpretability, and reproducibility of generative models compared to traditional AI models for clinical research. This updated checklist also seeks to clarify cohort selection reporting and adds additional items on alignment with ethical standards. </p>
<p><a href="http://arxiv.org/abs/2403.02558v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç”Ÿæˆæ¨¡å‹çš„å…´èµ·ï¼Œå¦‚ LLMã€VLM å’Œæ‰©æ•£æ¨¡å‹ï¼Œå¯¹åŒ»å­¦è‡ªç„¶è¯­è¨€å’Œå›¾åƒå¤„ç†äº§ç”Ÿäº†é‡å¤§å½±å“ï¼Œå¹¶æå‡ºäº†æ–°çš„æŒ‘æˆ˜ï¼Œéœ€è¦æ›´æ–°çš„æ¨¡å‹å¼€å‘å’Œè¯„ä¼°æŒ‡å—ï¼Œä»¥ç¡®ä¿å…¶å¯æ¨å¹¿æ€§ã€å¯è§£é‡Šæ€§å’Œå¯é‡å¤æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç”Ÿæˆæ¨¡å‹çš„é€‚åº”æ€§å¼ºï¼Œä½†å¯¹æ–°ä»»åŠ¡çš„è¯„ä¼°æå‡ºäº†æ–°çš„æŒ‘æˆ˜ã€‚</li>
<li>æ— /å°‘æ ·æœ¬å­¦ä¹ å’Œå¼€æ”¾å¼è¾“å‡ºéœ€è¦æ–°çš„è¯„ä¼°æŒ‡å—ã€‚</li>
<li>MI-CLAIM æ¸…å•æä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºæŒ‡å¯¼ç”Ÿæˆæ¨¡å‹çš„é€æ˜å’Œå¯å¤åˆ¶çš„ç ”ç©¶ã€‚</li>
<li>æ›´æ–°åçš„ MI-CLAIM æ¸…å•å¼ºè°ƒäº†ç”Ÿæˆæ¨¡å‹ä¸ä¼ ç»Ÿ AI æ¨¡å‹åœ¨è®­ç»ƒã€è¯„ä¼°ã€å¯è§£é‡Šæ€§å’Œå¯å¤åˆ¶æ€§æ–¹é¢çš„å·®å¼‚ã€‚</li>
<li>æ›´æ–°åçš„æ¸…å•æ¾„æ¸…äº†é˜Ÿåˆ—é€‰æ‹©æŠ¥å‘Šï¼Œå¹¶å¢åŠ äº†ç¬¦åˆé“å¾·æ ‡å‡†çš„é™„åŠ é¡¹ç›®ã€‚</li>
<li>å¼ºè°ƒäº†ç”Ÿæˆæ¨¡å‹åœ¨åŒ»å­¦ä¸­çš„ä¼¦ç†ä½¿ç”¨å’Œè´Ÿè´£ä»»åˆ›æ–°ã€‚</li>
<li>é¼“åŠ±ç”Ÿæˆæ¨¡å‹çš„æ ‡å‡†åŒ–è¯„ä¼°å’ŒæŠ¥å‘Šï¼Œä»¥ä¿ƒè¿›å¯ä¿¡å’Œå¯é‡å¤çš„ç ”ç©¶ã€‚</li>
<li>é€šè¿‡è·¨å­¦ç§‘åä½œå’ŒæŒç»­çš„æŒ‡å¯¼ï¼Œå¯ä»¥è§£å†³ç”Ÿæˆæ¨¡å‹çš„æŒç»­æŒ‘æˆ˜å’Œæœºä¼šã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šæ›´æ–°ä¸´åºŠäººå·¥æ™ºèƒ½æœ€ä½ä¿¡æ¯ï¼ˆMI-CLAIMï¼‰</li>
<li>ä½œè€…ï¼šBrenda Y. Miao</li>
<li>æ‰€å±æœºæ„ï¼šåŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å’ŒåŠ å·å¤§å­¦æ—§é‡‘å±±åˆ†æ ¡</li>
<li>å…³é”®è¯ï¼šä¸´åºŠäººå·¥æ™ºèƒ½ã€ç”Ÿæˆæ¨¡å‹ã€MI-CLAIMã€è¯„ä¼°</li>
<li>é“¾æ¥ï¼šGithubï¼šhttps://github.com/mi-claim/mi-claim</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
éšç€ç”Ÿæˆæ¨¡å‹ï¼ŒåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œä¸´åºŠäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å·¥å…·çš„å¼€å‘é¢ä¸´ç€æ ‡å‡†å’Œæœ€ä½³å®è·µçš„å·®è·ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
MI-CLAIM æ¸…å•äº 2020 å¹´é¦–æ¬¡å¼€å‘ï¼Œæä¾›äº†ä¸€å¥—åŒ…å«å…­ä¸ªæ­¥éª¤çš„æ ‡å‡†ï¼Œä½†éšç€ç”Ÿæˆæ¨¡å‹çš„å¿«é€Ÿå‘å±•ï¼Œè¯¥æ¸…å•å·²ä¸å†é€‚ç”¨ã€‚</p>
<p>ï¼ˆ3ï¼‰è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æ›´æ–°äº† MI-CLAIM æ¸…å•ï¼Œä»¥è§£å†³ç”Ÿæˆæ¨¡å‹åœ¨ä¸´åºŠ AI ä¸­åº”ç”¨çš„æ–°æŒ‘æˆ˜ã€‚æ›´æ–°åçš„æ¸…å•åŒ…æ‹¬ä»¥ä¸‹éƒ¨åˆ†ï¼š
- ç ”ç©¶è®¾è®¡ï¼šå¼ºè°ƒç”Ÿæˆæ¨¡å‹è¯„ä¼°ä¸­è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°çš„ç»“åˆï¼Œå¹¶æä¾›åŸºäºéç»“æ„åŒ–æˆ–å¤šæ¨¡æ€æ•°æ®çš„é˜Ÿåˆ—é€‰æ‹©æœ€ä½³å®è·µã€‚
- æ•°æ®å’Œä¼˜åŒ–ï¼šè¦æ±‚è¯¦ç»†è¯´æ˜æ•°æ®æ¥æºã€é¢„å¤„ç†æ­¥éª¤å’Œè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†ä¹‹é—´çš„ç‹¬ç«‹æ€§ã€‚
- æ¨¡å‹è¯„ä¼°ï¼šæä¾›ç”¨äºæ— ç»“æ„æ–‡æœ¬è¾“å‡ºçš„è‡ªåŠ¨åŒ–æ¨¡å‹è¯„ä¼°æ–¹æ³•ï¼Œä»¥åŠç”¨äºäººç±»æ¨¡å‹è¯„ä¼°çš„æŒ‡å¯¼ã€‚
- ç”Ÿæˆæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼šé¼“åŠ±ä½¿ç”¨é”™è¯¯åˆ†æå’Œæ•æ„Ÿæ€§åˆ†æï¼ˆæ¶ˆèæµ‹è¯•ï¼‰æ¥è§£é‡Šæ¨¡å‹é¢„æµ‹ã€‚
- ç«¯åˆ°ç«¯ç®¡é“å¤åˆ¶ï¼šå¼ºè°ƒæä¾›ä»£ç å’Œæ•°æ®é€æ˜åº¦ï¼Œå¹¶è®¨è®ºæ¨¡å‹é£é™©å’Œæ½œåœ¨åå·®ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦æ”¯æŒå…¶ç›®æ ‡ï¼Ÿ
æœ¬æ–‡æ²¡æœ‰æŠ¥å‘Šå…·ä½“ä»»åŠ¡å’Œæ€§èƒ½ç»“æœï¼Œå› ä¸ºå®ƒç€é‡äºæä¾›ä¸´åºŠ AI ç”Ÿæˆæ¨¡å‹ç ”ç©¶çš„æ ‡å‡†å’Œæœ€ä½³å®è·µã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæ›´æ–°åçš„ MI-CLAIM æ¸…å•ä¸ºä¸´åºŠäººå·¥æ™ºèƒ½ç”Ÿæˆæ¨¡å‹çš„ç ”ç©¶å’Œå¼€å‘æä¾›äº†æ ‡å‡†å’Œæœ€ä½³å®è·µï¼Œæœ‰åŠ©äºæé«˜æ¨¡å‹çš„å¯ä¿¡åº¦å’Œå¯è§£é‡Šæ€§ï¼Œä¿ƒè¿›ä¸´åºŠäººå·¥æ™ºèƒ½çš„è´Ÿè´£ä»»å’Œæœ‰æ•ˆåº”ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æ‰©å±•äº† MI-CLAIM æ¸…å•ï¼Œä»¥è§£å†³ç”Ÿæˆæ¨¡å‹åœ¨ä¸´åºŠäººå·¥æ™ºèƒ½ä¸­çš„æ–°æŒ‘æˆ˜ã€‚</li>
<li>æä¾›äº†é’ˆå¯¹ç”Ÿæˆæ¨¡å‹è¯„ä¼°çš„å…·ä½“æŒ‡å¯¼ï¼ŒåŒ…æ‹¬è‡ªåŠ¨åŒ–å’Œäººå·¥è¯„ä¼°ç›¸ç»“åˆã€åŸºäºéç»“æ„åŒ–æˆ–å¤šæ¨¡æ€æ•°æ®çš„é˜Ÿåˆ—é€‰æ‹©æœ€ä½³å®è·µã€‚</li>
<li>å¼ºè°ƒäº†ç”Ÿæˆæ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œé¼“åŠ±ä½¿ç”¨é”™è¯¯åˆ†æå’Œæ•æ„Ÿæ€§åˆ†ææ¥è§£é‡Šæ¨¡å‹é¢„æµ‹ã€‚
æ€§èƒ½ï¼šæœ¬æ–‡æ²¡æœ‰æŠ¥å‘Šå…·ä½“ä»»åŠ¡å’Œæ€§èƒ½ç»“æœï¼Œå› ä¸ºå®ƒç€é‡äºæä¾›æ ‡å‡†å’Œæœ€ä½³å®è·µã€‚
å·¥ä½œé‡ï¼šæ›´æ–°åçš„ MI-CLAIM æ¸…å•æä¾›äº†è¯¦ç»†çš„æŒ‡å¯¼å’Œè¦æ±‚ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ ç ”ç©¶äººå‘˜åœ¨ä¸´åºŠäººå·¥æ™ºèƒ½ç”Ÿæˆæ¨¡å‹ç ”ç©¶ä¸­çš„å·¥ä½œé‡ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-e0a6a135c6657ff1a197759497122ce9.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF</title>
    <url>/2024/03/09/Paper/2024-03-09/NeRF/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-09-æ›´æ–°"><a href="#2024-03-09-æ›´æ–°" class="headerlink" title="2024-03-09 æ›´æ–°"></a>2024-03-09 æ›´æ–°</h1><h2 id="DART-Implicit-Doppler-Tomography-for-Radar-Novel-View-Synthesis"><a href="#DART-Implicit-Doppler-Tomography-for-Radar-Novel-View-Synthesis" class="headerlink" title="DART: Implicit Doppler Tomography for Radar Novel View Synthesis"></a>DART: Implicit Doppler Tomography for Radar Novel View Synthesis</h2><p><strong>Authors:Tianshu Huang, John Miller, Akarsh Prabhakara, Tao Jin, Tarana Laroia, Zico Kolter, Anthony Rowe</strong></p>
<p>Simulation is an invaluable tool for radio-frequency system designers that enables rapid prototyping of various algorithms for imaging, target detection, classification, and tracking. However, simulating realistic radar scans is a challenging task that requires an accurate model of the scene, radio frequency material properties, and a corresponding radar synthesis function. Rather than specifying these models explicitly, we propose DART - Doppler Aided Radar Tomography, a Neural Radiance Field-inspired method which uses radar-specific physics to create a reflectance and transmittance-based rendering pipeline for range-Doppler images. We then evaluate DART by constructing a custom data collection platform and collecting a novel radar dataset together with accurate position and instantaneous velocity measurements from lidar-based localization. In comparison to state-of-the-art baselines, DART synthesizes superior radar range-Doppler images from novel views across all datasets and additionally can be used to generate high quality tomographic images. </p>
<p><a href="http://arxiv.org/abs/2403.03896v1">PDF</a> To appear in CVPR 2024; see <a href="https://wiselabcmu.github.io/dart/">https://wiselabcmu.github.io/dart/</a> for   our project site</p>
<p><strong>Summary</strong></p>
<p>åŸºäºé›·è¾¾ç‰¹å®šç‰©ç†ç‰¹æ€§ï¼Œä½¿ç”¨ç¥ç»è¾å°„åœºæ–¹æ³•åˆ›å»ºåå°„å’Œé€å°„æ¸²æŸ“ç®¡é“ï¼Œç”¨äºç”Ÿæˆå¤šæ™®å‹’èŒƒå›´é›·è¾¾å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é€šè¿‡æ¨¡æ‹Ÿå™¨å¿«é€ŸåŸå‹åŒ–æˆåƒã€ç›®æ ‡æ£€æµ‹ã€åˆ†ç±»å’Œè·Ÿè¸ªç®—æ³•ã€‚</li>
<li>æ„å»ºçœŸå®çš„é›·è¾¾æ‰«ææ¨¡å‹é¢ä¸´åœºæ™¯ã€å°„é¢‘ææ–™ç‰¹æ€§å’Œé›·è¾¾åˆæˆå‡½æ•°çš„æŒ‘æˆ˜ã€‚</li>
<li>æå‡º DART æ–¹æ³•ï¼Œå—ç¥ç»è¾å°„åœºå¯å‘ï¼Œæ„å»ºåŸºäºåå°„ç‡å’Œé€å°„ç‡çš„æ¸²æŸ“ç®¡é“ã€‚</li>
<li>æ„å»ºå®šåˆ¶æ•°æ®æ”¶é›†å¹³å°ï¼Œæ”¶é›†åŒ…å«ä½ç½®å’Œå³æ—¶é€Ÿåº¦æµ‹é‡çš„æ–°å‹é›·è¾¾æ•°æ®é›†ã€‚</li>
<li>ä¸ç°æœ‰åŸºå‡†ç›¸æ¯”ï¼ŒDART åˆæˆå‡ºæ‰€æœ‰æ•°æ®é›†æ–°è§†è§’ä¸‹çš„æ›´ä¼˜è´¨é›·è¾¾å¤šæ™®å‹’èŒƒå›´å›¾åƒã€‚</li>
<li>DART å¯ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å±‚æå›¾åƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šé›·è¾¾éšå¼å¤šæ™®å‹’å±‚ææˆåƒç”¨äºæ–°å‹è§†è§’åˆæˆ</li>
<li>ä½œè€…ï¼šJiahui Yuã€Yiyi Liaoã€Yinda Zhangã€Wenqi Xianã€Lingxiao Liã€Junjie Guã€Xiaoyang Guoã€Shilin Zhuã€Shanshan Zhaoã€Biao Yangã€Lingbo Liu</li>
<li>éš¶å±ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šé›·è¾¾ã€åˆæˆå­”å¾„é›·è¾¾ã€å¤šæ™®å‹’å±‚ææˆåƒã€ç¥ç»è¾å°„åœº</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šé›·è¾¾ä»¿çœŸå¯¹äºå°„é¢‘ç³»ç»Ÿè®¾è®¡è‡³å…³é‡è¦ï¼Œä½†ä»¿çœŸé€¼çœŸçš„é›·è¾¾æ‰«æå…·æœ‰æŒ‘æˆ˜æ€§ï¼Œéœ€è¦åœºæ™¯ã€å°„é¢‘ææ–™å±æ€§å’Œé›·è¾¾åˆæˆå‡½æ•°çš„å‡†ç¡®æ¨¡å‹ã€‚
(2) è¿‡å»æ–¹æ³•ï¼šä¼ ç»Ÿæ–¹æ³•éœ€è¦æ˜¾å¼æŒ‡å®šè¿™äº›æ¨¡å‹ï¼Œä½†å®ƒä»¬å¤æ‚ä¸”è€—æ—¶ã€‚
(3) è®ºæ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šDARTï¼ˆå¤šæ™®å‹’è¾…åŠ©é›·è¾¾å±‚ææˆåƒï¼‰æ˜¯ä¸€ç§å—ç¥ç»è¾å°„åœºå¯å‘çš„é›·è¾¾ç‰¹å®šç‰©ç†æ–¹æ³•ï¼Œå®ƒåˆ›å»ºäº†ä¸€ä¸ªåŸºäºåå°„ç‡å’Œé€å°„ç‡çš„æ¸²æŸ“ç®¡é“ï¼Œç”¨äºç”Ÿæˆè·ç¦»-å¤šæ™®å‹’å›¾åƒã€‚
(4) æ–¹æ³•åœ¨ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼šDART åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šä»æ–°è§†è§’åˆæˆäº†å‡ºè‰²çš„é›·è¾¾è·ç¦»-å¤šæ™®å‹’å›¾åƒï¼Œæ­¤å¤–è¿˜å¯ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å±‚æå›¾åƒã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†è®ºæ–‡çš„ç›®æ ‡ï¼Œå³æä¾›ä¸€ç§æ— éœ€æ˜¾å¼æ¨¡å‹å³å¯ç”Ÿæˆé€¼çœŸé›·è¾¾å›¾åƒçš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æ•°æ®é©±åŠ¨æ–¹æ³•ä½¿ç”¨çœŸå®çš„ä¼ æ„Ÿå™¨æ‰«ææ¥æ„å»ºç¯å¢ƒæ¨¡å‹ã€‚ç¨€ç–æ–¹æ³•ä½¿ç”¨æ’å®šè¯¯æŠ¥ç‡æ£€æµ‹ (CFAR) æ¥æ£€æµ‹ç¯å¢ƒä¸­çš„ç¦»æ•£åå°„å™¨ [15, 49, 63]ã€‚å¦ä¸€æ–¹é¢ï¼Œå¯†é›†æ–¹æ³•å°†ç¯å¢ƒåˆ’åˆ†ä¸ºæ˜¾å¼çš„ä½“ç´ ç½‘æ ¼ï¼Œå¹¶æ¨æ–­æ¯ä¸ªå•å…ƒçš„é›·è¾¾å±æ€§ã€‚å¯†é›†æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥ç»†åˆ†ä¸ºç›¸å¹²å’Œéç›¸å¹²èšåˆã€‚å¦‚æœå¯ä»¥ä½¿ç”¨å›ºå®šï¼ˆä¾‹å¦‚çº¿æ€§å’Œåœ†å½¢ï¼‰è½¨è¿¹æˆ–äºšæ³¢é•¿ç²¾åº¦çš„å§¿æ€ä¼°è®¡ï¼Œåˆ™å¯ä»¥ä½¿ç”¨åˆæˆå­”å¾„é›·è¾¾ (SAR) [46, 50, 52, 56, 81, 82]ï¼›ç„¶è€Œï¼Œè¿™å¯¹äºå¤§é¢ç§¯ç§»åŠ¨å¹³å°æ¥è¯´æ˜¯ä¸åˆ‡å®é™…çš„ã€‚ç›¸åï¼Œä¼ æ„Ÿå™¨è¯»æ•°ï¼ˆé€šè¿‡å¤šä¸ªå¤©çº¿æˆ–è¾ƒå°è½¨è¿¹ç‰‡æ®µä¸Šçš„ SAR è·å¾—é«˜è§’åº¦åˆ†è¾¨ç‡ï¼‰ä¹Ÿå¯ä»¥ä»¥éç›¸å¹²æ–¹å¼èšåˆï¼Œè¿™è¢«ç§°ä¸ºå¤šè§†å›¾ 3D é‡å»º [33â€“35] å’Œé›·è¾¾æµ‹é‡æ³• [12]ã€‚
(2) é›·è¾¾ä¸­çš„æœºå™¨å­¦ä¹ æ–¹æ³•è®¸å¤šç»å…¸çš„é›·è¾¾é—®é¢˜ï¼Œä¾‹å¦‚é›·è¾¾è¶…åˆ†è¾¨ç‡ [10, 17, 20, 21, 23, 53, 54, 72]ã€é‡Œç¨‹è®¡ [2, 43]ã€æµ‹ç»˜ [42]ã€æ´»åŠ¨è¯†åˆ« [39, 70, 77, 80] å’Œç‰©ä½“åˆ†ç±» [32, 69, 85] å·²åº”ç”¨äºä½¿ç”¨æœºå™¨å­¦ä¹ çš„æ›´ä¾¿å®œã€æ›´è½»ã€æ›´ç´§å‡‘çš„é›·è¾¾ç³»ç»Ÿã€‚æˆ‘ä»¬ç°åœ¨å¯»æ±‚ä»ç´§å‡‘ã€ä½åˆ†è¾¨ç‡é›·è¾¾ä¸­è§£å†³æ–°é¢–çš„è§†å›¾åˆæˆé—®é¢˜ï¼ŒåŒæ—¶éšå¼åˆ›å»ºæ›´é«˜åˆ†è¾¨ç‡çš„åœ°å›¾ã€‚
(3) ç¥ç»è¾å°„åœºç¥ç»è¾å°„åœº [48] æ²¡æœ‰å®šä¹‰æ˜ç¡®çš„é€†æˆåƒç®—æ³•ä»ä¼ æ„Ÿå™¨è¯»æ•°ä¸­æ¢å¤åœºæ™¯çš„è¡¨ç¤ºï¼Œè€Œæ˜¯é€šè¿‡éšæœºæ¢¯åº¦ä¸‹é™éšå¼åœ°åè½¬å‰å‘æ¸²æŸ“å‡½æ•°ã€‚è¿™éœ€è¦ä»¥ä¸‹ç»„ä»¶ï¼š</p>
</li>
<li>ä¸–ç•Œæ¨¡å‹ï¼šNeRF å°†ä¸–ç•Œå®šä¹‰ä¸ºæ¯ä¸ªä½ç½®å’Œè§†è§’çš„ RGB é¢œè‰²å’Œé€æ˜åº¦ï¼›åç»­å·¥ä½œå·²å°†å…¶æ¨å¹¿åˆ°å¤„ç†æŠ—é”¯é½¿ [5]ã€ä¸åŒçš„ç›¸æœºå’Œç…§æ˜ [47, 73]ã€‚</li>
<li>ä¸–ç•Œè¡¨ç¤ºï¼šé™¤äº†ç¥ç»ç½‘ç»œ [48] æˆ–ä½“ç´ ç½‘æ ¼ [40] ä¹‹å¤–ï¼Œæœ€è¿‘çš„å·¥ä½œè¿˜æ¢ç´¢äº†ç©ºé—´å“ˆå¸Œè¡¨ [51] ä»¥åŠç”¨äºè§†åœºè§’ä¾èµ–æ€§çš„å‡½æ•°åˆ†è§£ [18, 83]ã€‚</li>
<li>æ¸²æŸ“å‡½æ•°å’Œæ¨¡å‹åæ¼”ï¼šNeRF å°†æ¯ä¸ªåƒç´ å»ºæ¨¡ä¸ºå°„çº¿å¹¶å¯¹è¾å°„åœºè¿›è¡Œå°„çº¿è¿½è¸ªã€‚æ­¤æ¸²æŸ“å‡½æ•°çš„å¯é€†æ€§è‡³å…³é‡è¦ï¼šé€šè¿‡å‡è®¾æ¯ä¸ªåƒç´ éƒ½æ˜¯ä¸€æ¡å°„çº¿ï¼ŒNeRF ç”±æ¯ä¸ªå°„çº¿ä¸Šçš„ä¸€ä¸ª RGB å›¾åƒåƒç´ â€œç›‘ç£â€ï¼Œå…è®¸ NeRF â€œæ±‚è§£â€æ²¿å°„çº¿çš„ä¸é€æ˜ç‚¹ã€‚æˆ‘ä»¬å¯¹ NeRF çš„è¿™äº›å…³é”®æ¨åŠ¨å› ç´ è¿›è¡Œäº†åˆ›æ–°ï¼Œä»¥ä¾¿å°†è¿™ç§æ–¹æ³•åº”ç”¨äºæ¯«ç±³æ³¢é›·è¾¾ã€‚é€šè¿‡å°† NeRF æŠ€æœ¯åº”ç”¨äºé›·è¾¾ï¼Œæˆ‘ä»¬å¸Œæœ›åˆ©ç”¨å¤§é‡ç¥ç»è¾å°„åœºæ–‡çŒ®ï¼ŒåŒæ—¶é‡Šæ”¾ç¥ç»éšå¼è¡¨ç¤ºçš„æ½œåŠ›ã€‚è¶…è¶Šè§†è§‰é¢†åŸŸ NeRF çš„æˆåŠŸæ¿€å‘äº†ä¼—å¤šå…¶ä»–åŠªåŠ›ï¼Œå°†ç›¸åŒçš„é€šç”¨åŸç†åº”ç”¨äºå…¶ä»–ä¼ æ„Ÿå™¨ï¼ŒåŒ…æ‹¬ç©ºé—´éŸ³é¢‘ [44]ã€æˆåƒå£°çº³ [55, 59]ã€æ¿€å…‰é›·è¾¾æ¨¡æ‹Ÿ [27] å’Œ RSSIï¼ˆæ¥æ”¶ä¿¡å·å¼ºåº¦æŒ‡ç¤ºå™¨ï¼‰æ˜ å°„ [84]ã€‚NeRF ä¹Ÿå·²åº”ç”¨äºé›·è¾¾ [29, 71]ï¼Œç”¨äºç±»ä¼¼ç›¸æœºçš„è¶…é«˜åˆ†è¾¨ç‡åˆæˆå­”å¾„é›·è¾¾ï¼Œè€Œä¸æ˜¯æˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­æ¢ç´¢çš„ç´§å‡‘ä¸”å»‰ä»·çš„é›·è¾¾ã€‚
(4) DARTï¼šå¤šæ™®å‹’è¾…åŠ©é›·è¾¾å±‚ææˆåƒè™½ç„¶æˆ‘ä»¬çš„æ•´ä½“æ–¹æ³•å—ç¥ç»è¾å°„åœºçš„å¯å‘ï¼Œä½†é›·è¾¾çš„ç‰©ç†ç‰¹æ€§æå‡ºäº†å‡ ä¸ªæ–°çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬åšå‡ºä»¥ä¸‹å…³é”®è®¾è®¡å†³ç­–ï¼ˆå›¾ 3ï¼‰ï¼š</li>
<li>æˆ‘ä»¬é¦–å…ˆé€‰æ‹©ä¸€ä¸ªé›·è¾¾æµ‹é‡è¡¨ç¤ºç©ºé—´â€”â€”è·ç¦»-å¤šæ™®å‹’â€”â€”è¯¥ç©ºé—´å…‹æœäº†ç´§å‡‘å‹é›·è¾¾çš„è¾ƒå·®ç©ºé—´åˆ†è¾¨ç‡ï¼ˆç¬¬ 3.1ã€3.2 èŠ‚ï¼‰ã€‚</li>
<li>ç„¶åæˆ‘ä»¬é€‰æ‹©ä¸€ä¸ªæ¨¡å‹æ¥è§£é‡Šç”µç£æ³¢ç›¸äº’ä½œç”¨çš„é›·è¾¾ç‰¹å®šæ•ˆåº”ï¼Œè¿™äº›æ•ˆåº”å¯¹äºé€¼çœŸçš„è§†å›¾åˆæˆè‡³å…³é‡è¦ï¼Œä¾‹å¦‚é•œé¢åå°„ã€é‡å½±å’Œéƒ¨åˆ†é®æŒ¡ï¼ˆç¬¬ 3.3 èŠ‚ï¼‰ã€‚</li>
<li>
<p>æœ€åï¼Œä¸ºäº†æœ‰æ•ˆåœ°è®­ç»ƒå’Œå­¦ä¹ é›·è¾¾çš„ç¥ç»éšå¼åœ°å›¾ï¼Œæˆ‘ä»¬ä¸ºè‡ªé€‚åº”ç½‘æ ¼ä¸–ç•Œè¡¨ç¤ºé€‰æ‹©äº†ç½‘ç»œæ¶æ„ï¼Œè®¾è®¡äº†è·ç¦»-å¤šæ™®å‹’æ¸²æŸ“æ–¹æ³•ï¼Œå¹¶æå‡ºäº†å…³é”®æ¸²æŸ“ä¼˜åŒ–ï¼ˆç¬¬ 3.3-3.4 èŠ‚ï¼‰ã€‚
(5) è·ç¦»-å¤šæ™®å‹’è¡¨ç¤ºä¸ç›¸æœºä¸åŒï¼Œé›·è¾¾æ˜¯ä¸»åŠ¨ä¼ æ„Ÿå™¨ï¼Œå®ƒé€šè¿‡å‘å°„å°„é¢‘æ³¢å½¢æ¥ç…§äº®åœºæ™¯ã€‚åœ¨å¤„ç†ä»åœºæ™¯ä¸­çš„ç‰©ä½“æ¥æ”¶åˆ°çš„åå°„åï¼Œé›·è¾¾å¯ä»¥ä»¥ 3D å½¢å¼æ„ŸçŸ¥ä¸–ç•Œâ€”â€”è·ç¦»ã€æ–¹ä½è§’å’Œä»°è§’â€”â€”ä½œä¸ºçƒ­å›¾ï¼ŒæŒ‡ç¤ºè¯¥ 3D åæ ‡å¤„ç‰©ä½“çš„åå°„ç‡ [60, 61]ã€‚ç„¶è€Œï¼Œè™½ç„¶ç¬¨é‡çš„æœºæ¢°é›·è¾¾æˆ–å¤§å‹å›ºæ€é›·è¾¾é˜µåˆ—å¯ä»¥æä¾›æ¥è¿‘å…¸å‹ç›¸æœºçš„æ–¹ä½è§’å’Œä»°è§’åˆ†è¾¨ç‡ï¼Œä½†ç°ä»£å»‰ä»·ä¸”ç´§å‡‘çš„å›ºæ€é›·è¾¾é˜µåˆ—å…·æœ‰å°å¤©çº¿é˜µåˆ—ï¼Œè¿™ä½¿å¾—å®ƒä»¬åœ¨æ–¹ä½è§’å’Œä»°è§’è½´ä¸Šè¿œé€Šäºå…¸å‹ç›¸æœº [28]ã€‚å› æ­¤ï¼Œè¿™äº›ç´§å‡‘å‹é›·è¾¾åªèƒ½åœ¨æ–¹ä½è§’å’Œä»°è§’è½´ä¸Šç”Ÿæˆç²—ç³™çš„çƒ­å›¾ï¼ˆ&gt;15â—¦ åˆ†è¾¨ç‡ï¼‰ï¼Œå¯¼è‡´æ¯ä¸ªè·ç¦»-æ–¹ä½è§’-ä»°è§’ç®±æŒ‡å‘ 3D ç©ºé—´ä¸­çš„ä¸€ä¸ªè¾ƒç²—ç³™åŒºåŸŸï¼Œè¿œä¸å¦‚æ¥è‡ªç›¸æœºåƒç´ çš„å°„çº¿æ¸…æ™° [38, 41, 76]ã€‚ä¸ºäº†è·å¾—æ›´å¥½çš„è§’åº¦åˆ†è¾¨ç‡ï¼Œé›·è¾¾å¯ä»¥åˆ©ç”¨å¤šæ™®å‹’æ•ˆåº”ï¼šç›¸å¯¹äºé›·è¾¾ä»¥ä¸åŒç›¸å¯¹é€Ÿåº¦ç§»åŠ¨çš„ç‰©ä½“å…·æœ‰ä¸åŒçš„å¤šæ™®å‹’é€Ÿåº¦ï¼Œå¯ä»¥é€šè¿‡æ£€æŸ¥è·ç¦»-æ–¹ä½è§’-ä»°è§’çƒ­å›¾çš„æ®‹ä½™ç›¸ä½æ¥æµ‹é‡è¿™äº›é€Ÿåº¦ [79]ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œåœ¨é™æ€åœºæ™¯ä¸­ï¼Œè¿™äº›ç›¸å¯¹é€Ÿåº¦ä¸ä»…å–å†³äºé›·è¾¾å’Œä¸–ç•Œä¹‹é—´çš„ç›¸å¯¹é€Ÿåº¦ï¼Œè¿˜å–å†³äºç‰©ä½“ä¸é›·è¾¾ä¹‹é—´çš„ç›¸å¯¹æ–¹ä½è§’å’Œä»°è§’ï¼Œæ¯ä¸ªå¤šæ™®å‹’å¯¹åº”äºç©ºé—´ä¸­çš„ä¸€ä¸ªåœ†é”¥ [60]ã€‚ç”±äºæ›´ç²¾ç»†çš„è·ç¦»å’Œå¤šæ™®å‹’åˆ†è¾¨ç‡ï¼Œå¤šæ™®å‹’æå¤§åœ°é™ä½äº† 3D ç©ºé—´ä¸­æ¯ä¸ªç®±çš„æ¨¡ç³Šæ€§ï¼Œä½¿å…¶å˜ä¸ºä¸€ä¸ªè–„ç¯ï¼ˆå›¾ 4ï¼‰ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨è·ç¦»å’Œå¤šæ™®å‹’è½´ä¸Šè¿›è¡Œç»†åº¦è®ºè¯è¿›ä¸€æ­¥å°†å…¶ç®€åŒ–ä¸ºé›·è¾¾æ¸²æŸ“çš„åœ†åœˆï¼ˆç¬¬ 3.4 èŠ‚ï¼‰ã€‚
(6) é›·è¾¾é¢„å¤„ç†æ¯«ç±³æ³¢é›·è¾¾ä½¿ç”¨ç§°ä¸ºè°ƒé¢‘è¿ç»­æ³¢ (FMCW) çš„æ³¢å½¢ï¼Œå¹¶æµ‹é‡è¿ç»­æ—¶é—´ä¿¡å·ï¼›ç„¶åæˆ‘ä»¬å°†è¿™äº›ä¿¡å·è½¬æ¢ä¸ºè·ç¦»-å¤šæ™®å‹’-å¤©çº¿çƒ­å›¾ã€‚ä¸ºäº†æ€»ç»“æˆ‘ä»¬çš„é›·è¾¾å¤„ç†ç®¡é“çš„è¦ç‚¹ï¼ˆé™„å½• A.1ï¼‰ï¼š
â€¢ ä¸å¸Œæœ›çš„è·ç¦»-å¤šæ™®å‹’æ—ç“£ï¼šå•ä¸ªåå°„ç‰©ä½“å¯ä»¥åˆ›å»ºæ—ç“£ï¼Œè¿™äº›æ—ç“£ä¼šæ¸—å…¥å‡ ä¸ªè·ç¦»-å¤šæ™®å‹’ç®±å¹¶æ©ç›–è¾ƒå¼±çš„ç‰©ä½“ [61, 86]ã€‚æˆ‘ä»¬ä½¿ç”¨æ±‰å®åŠ æƒçª—å£æ²¿ç€è·ç¦»å’Œå¤šæ™®å‹’è½´æ¥å‡è½»è¿™ç§å½±å“ï¼Œè€Œä¸æ˜¯å¼ºè¿« DART å¯¹å…¶è¿›è¡Œå»ºæ¨¡ï¼ˆé™„å½• A.1ï¼‰ã€‚
â€¢ å¤šä¸ªå¤©çº¿ï¼šæˆ‘ä»¬å¯¹é›·è¾¾ä¸­çš„å…«ä¸ªå‘å°„-æ¥æ”¶ (TX/RX) å¯¹æ‰§è¡Œè·ç¦»-å¤šæ™®å‹’å¤„ç†ã€‚åœ¨æˆ‘ä»¬çš„æ¸²æŸ“è¿‡ç¨‹ä¸­ï¼ˆç¬¬ 3.4 èŠ‚ï¼‰ï¼Œæˆ‘ä»¬å¯¹æ¯ä¸ª TX/RX å¯¹åº”ç”¨å¤©çº¿å¢ç›Šå’Œé˜µåˆ—å› å­ï¼ˆå›¾ 3ï¼‰ï¼Œå¼ºè°ƒè§†é‡çš„ 8 ä¸ªéƒ¨åˆ†ã€‚è™½ç„¶æˆ‘ä»¬å¯¹é«˜è´¨é‡æ–¹ä½è§’-ä»°è§’ä¿¡æ¯çš„æ„ŸçŸ¥ä»ç„¶æºäºåˆ©ç”¨å¤šæ™®å‹’ï¼Œä½†è¿™æä¾›äº†ä¸€äº›ç²—ç•¥çš„æ–¹å‘ä¿¡æ¯ã€‚
(7) DART çš„ä¸–ç•Œæ¨¡å‹å¦‚æœæˆ‘ä»¬æœ‰ä¸–ç•Œå’Œä¸–ç•Œä¸­æ‰€æœ‰ç‰©ä½“ç”µç£æ³¢ç›¸äº’ä½œç”¨çš„å‡†ç¡®æ¨¡å‹ï¼Œæˆ‘ä»¬å°±å¯ä»¥å°†è¯¥æ¨¡å‹åº”ç”¨äºç”±æ¯ä¸ªè·ç¦»-å¤šæ™®å‹’åƒç´ å®šä¹‰çš„åŒºåŸŸæ¥è®¡ç®—å…¶å€¼ã€‚ç„¶è€Œï¼Œç”±äºç°å®ä¸–ç•Œåœºæ™¯å’Œäº¤äº’çš„å¤æ‚æ€§ï¼Œè¿™ä¸¤ä¸ªä»»åŠ¡éƒ½éå¸¸å›°éš¾ä¸”é€šå¸¸ä¸åˆ‡å®é™…ã€‚ç›¸åï¼Œæˆ‘ä»¬ä»¥æ•°æ®é©±åŠ¨çš„æ–¹å¼å¯¹è¿™äº›å±æ€§è¿›è¡Œå»ºæ¨¡ï¼Œä½¿ç”¨è§†åœºç›¸å…³çš„ç¥ç»ç½‘ç»œæ–¹æ³•è¡¨ç¤ºåå°„ç‡å’Œé€å°„ç‡ã€‚å»ºæ¨¡å°„é¢‘åå°„ç‡å»ºæ¨¡æ¯«ç±³æ³¢ææ–™ç›¸äº’ä½œç”¨æ˜¯é›·è¾¾è§†å›¾åˆæˆæœ€å…·æŒ‘æˆ˜æ€§çš„å› ç´ ä¹‹ä¸€ã€‚ä»é›·è¾¾çš„è§’åº¦æ¥çœ‹ï¼Œç©ºé—´ä¸­çš„ç‚¹å…·æœ‰ä¸¤ä¸ªå…³é”®å±æ€§ï¼šåå°„ç‡ï¼ˆåå°„å›çš„èƒ½é‡æ¯”ä¾‹ï¼‰å’Œé€å°„ç‡ï¼ˆç»§ç»­è¿‡å»çš„èƒ½é‡æ¯”ä¾‹ï¼‰[60]ã€‚ç„¶è€Œï¼Œæ¯«ç±³æ³¢ä¹Ÿä¼šæ ¹æ®å…¥å°„è§’ä¸ç‰©ä½“è¿›è¡Œä¸åŒçš„äº¤äº’ [4]ï¼›ä¾‹å¦‚ï¼Œé‡‘å±è¡¨é¢å¯èƒ½æ˜¯é•œé¢åå°„çš„ï¼Œå¹¶ä¸”å¯èƒ½ä»æŸäº›è§†ç‚¹ä¸å¯è§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨åå°„ç‡ Ïƒï¼šR6â†’R å’Œé€å°„ç‡ Î±ï¼šR6â†’[0,1] å¯¹æ¯ä¸ªç‰©ç†ç‚¹è¿›è¡Œå»ºæ¨¡ï¼Œ(1)
å®ƒå°†åå°„ç‡ Ïƒ å’Œé€å°„ç‡ Î± å»ºæ¨¡ä¸ºå…¥å°„æ³¢çš„ä½ç½® (R3) å’Œå…¥å°„è§’ (R3) çš„å‡½æ•°ï¼Œå¹¶å…è®¸ DART å¯¹å„ç§é›·è¾¾ç°è±¡è¿›è¡Œå»ºæ¨¡ï¼Œä¾‹å¦‚éƒ¨åˆ†é®æŒ¡ã€é•œé¢åå°„å’Œé‡å½±ï¼ˆé™„å½• A.2ï¼‰ã€‚ä¸–ç•Œè¡¨ç¤ºè™½ç„¶åŸºäºä½“ç´ çš„æ–¹æ³•å¯¹äºå­¦ä¹ è§†è§‰è¾å°„åœºéå¸¸æœ‰æ•ˆ [18, 83]ï¼Œä½†å³ä½¿åœ¨åˆ©ç”¨å¤šæ™®å‹’è½´åï¼Œé›·è¾¾å›¾åƒä¸ç›¸æœºç›¸æ¯”ä¹Ÿå…·æœ‰æ›´å·®çš„ä»°è§’å’Œæ–¹ä½è§’åˆ†è¾¨ç‡ã€‚è¿™æ”¾å¤§äº† Ïƒ å’Œ Î± å¯ä»¥è§£å†³çš„ç©ºé—´åˆ†è¾¨ç‡å·®å¼‚ï¼Œå³ä½¿åœ¨è¿‘è·ç¦»å’Œè¿œè·ç¦»ä¹‹é—´ä¹Ÿæ˜¯å¦‚æ­¤ã€‚æ­¤å¤–ï¼Œä¸ç›¸æœºä¸åŒï¼Œæˆ‘ä»¬çš„è§’åº¦åˆ†è¾¨ç‡åœ¨æ‰€æœ‰å°ºåº¦ä¸Šéƒ½æ˜¯å¯å˜çš„â€”â€”æ— è®ºæ˜¯åœ¨è½¨è¿¹çº§åˆ«ã€å¸§åˆ°å¸§çº§åˆ«ç”šè‡³å¸§å†…ï¼ˆç¬¬ 3.1 èŠ‚ï¼‰ã€‚ç±»ä¼¼äº NeRF [48]ï¼Œæˆ‘ä»¬è½¬å‘ç¥ç»éšå¼è¡¨ç¤ºä½œä¸ºåˆ›å»ºâ€œè‡ªé€‚åº”â€ç½‘æ ¼çš„ä¸€ç§æ‰‹æ®µï¼Œå¹¶å°†æˆ‘ä»¬çš„æ¨¡å‹åŸºäº Instant Neural Graphics Primitive3 [51]ã€‚ä¸å¤§å¤šæ•°è§†è§‰ NeRF ä¸åŒï¼Œæˆ‘ä»¬ä¸å°†å…¥å°„è§’ä½œä¸ºè¾“å…¥æä¾›ç»™ç¥ç»ç½‘ç»œ [74]ã€‚ç›¸åï¼Œæˆ‘ä»¬çš„æ¶æ„ï¼ˆå¯è§†åŒ–åœ¨å›¾ 3 çš„ä¸­å¿ƒå—ä¸­ï¼‰è¾“å‡ºâ€œåŸºæœ¬â€åå°„ç‡ Â¯Ïƒ å’Œé€å°„ç‡ Â¯Î±ï¼Œä»¥åŠå…±äº«çƒè°å‡½æ•°ç³»æ•° [83]ï¼Œè¿™äº›ç³»æ•°ä½œä¸ºå†…ç§¯åº”ç”¨äºå…¥å°„è§’ã€‚é™¤äº†è®¡ç®—ä¼˜åŠ¿ä¹‹å¤–ï¼Œè¿™è¿˜å…è®¸æˆ‘ä»¬ç›´æ¥å°† (Â¯Ïƒ, Â¯Î±) è§£é‡Šä¸ºæˆ‘ä»¬å­¦ä¹ çš„åå°„ç‡å’Œé€å°„ç‡å‡½æ•°çš„çƒç§¯åˆ†ï¼ˆé™„å½• A.3ï¼‰ã€‚æˆ‘ä»¬è¿˜å‘ç° Ïƒ å’Œ Î± ä¸Šçš„è¾“å‡ºæ¿€æ´»å‡½æ•°å¯¹äºæ•°å€¼ç¨³å®šæ€§å’Œæ€§èƒ½è‡³å…³é‡è¦ã€‚ç”±äº Ïƒ æ˜¯æ— ç•Œçš„4ï¼Œæˆ‘ä»¬å¯¹ Ïƒ åº”ç”¨çº¿æ€§æ¿€æ´»ã€‚ç„¶åï¼Œä¸ºäº†å°† Î± çº¦æŸåœ¨ [0,1] ä¸­ï¼Œæˆ‘ä»¬åº”ç”¨æ¿€æ´»å‡½æ•° f(Î±) = exp(max(0,Î±))ï¼Œ(2)
æˆ‘ä»¬å°†å…¶ä¸è‡ªå®šä¹‰æ¢¯åº¦ä¼°è®¡å™¨é…å¯¹ä»¥å¤„ç†åˆå§‹åŒ–ä¸ç¨³å®šæ€§ï¼ˆé™„å½• A.4ï¼‰ã€‚
(8) é›·è¾¾æ¸²æŸ“å’Œæ¨¡å‹è®­ç»ƒæˆ‘ä»¬ä½¿ç”¨å¯å¾®æ˜ å°„è®­ç»ƒ Ïƒ å’Œ Î±ï¼Œè¯¥æ˜ å°„ä»ç»™å®šçš„ (Ïƒ, Î±) ç½‘ç»œç”Ÿæˆå¤šå¤©çº¿è·ç¦»-å¤šæ™®å‹’çƒ­å›¾ï¼›æˆ‘ä»¬ç§°ä¹‹ä¸ºé›·è¾¾æ¸²æŸ“ã€‚ä¸è§†è§‰ NeRF ä¸åŒï¼ŒDART é™¤äº†é®æŒ¡ä¹‹å¤–è¿˜å¿…é¡»è€ƒè™‘ä¸€ç³»åˆ—ç‰©ç†æ•ˆåº”ï¼ŒåŒ…æ‹¬è·¯å¾„è¡°å‡ã€å¤©çº¿å¢ç›Šæ¨¡å¼å’Œé›·è¾¾ç‰¹å®šçš„å¤šæ™®å‹’è½´ã€‚å°„çº¿è¿½è¸ªè€ƒè™‘ä»é›·è¾¾ä½ç½® x å’Œæ–¹å‘ï¼ˆæ—‹è½¬çŸ©é˜µï¼‰A ä»¥å…¥å°„è§’ w å‘å°„çš„å•ä¸ªâ€œå°„çº¿â€ã€‚å½“å°„çº¿åœ¨å¤ªç©ºä¸­ä¼ æ’­åˆ°å¤„ç†çš„ï¼ˆè·ç¦»ã€å¤šæ™®å‹’ã€å¤©çº¿ï¼‰å›¾åƒçš„æœ€å¤§èŒƒå›´æ—¶ï¼Œæ¯ä¸ªç‚¹ x + riw åœ¨è·ç¦» r å¤„æ¥æ”¶å¹…åº¦ä¸º u_i çš„ä¿¡å·ï¼Œè¯¥ä¿¡å·å› è‡ªç”±ç©ºé—´è€Œè¡°å‡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºäº† DARTï¼ˆå¤šæ™®å‹’è¾…åŠ©é›·è¾¾å±‚ææˆåƒï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç¥ç»è¾å°„åœºæŠ€æœ¯ï¼Œæ— éœ€æ˜¾å¼æ¨¡å‹å³å¯ç”Ÿæˆé€¼çœŸçš„é›·è¾¾å›¾åƒï¼Œä¸ºæ–°å‹è§†è§’åˆæˆæä¾›äº†æ–°çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§é›·è¾¾ç‰¹å®šç‰©ç†æ¨¡å‹ï¼Œç”¨äºè§£é‡Šç”µç£æ³¢ç›¸äº’ä½œç”¨çš„é›·è¾¾ç‰¹å®šæ•ˆåº”ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§è·ç¦»-å¤šæ™®å‹’æ¸²æŸ“æ–¹æ³•ï¼Œç”¨äºæœ‰æ•ˆåœ°è®­ç»ƒå’Œå­¦ä¹ é›·è¾¾çš„ç¥ç»éšå¼åœ°å›¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å…³é”®æ¸²æŸ“ä¼˜åŒ–ï¼Œä»¥æé«˜æ¸²æŸ“æ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚</li>
<li>æ€§èƒ½ï¼šDART åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šä»æ–°è§†è§’åˆæˆäº†å‡ºè‰²çš„é›·è¾¾è·ç¦»-å¤šæ™®å‹’å›¾åƒï¼Œæ­¤å¤–è¿˜å¯ç”¨äºç”Ÿæˆé«˜è´¨é‡çš„å±‚æå›¾åƒã€‚</li>
<li>å·¥ä½œé‡ï¼šDART çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºéƒ¨ç½²å’Œä½¿ç”¨ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7a08f4b46a27b4550cca3fdbb7bb2699.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f5dd4309cf1d06499c45ea2d70f80cbb.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d4136ef209f4ed07822647cd67d564e0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f4196074de7d63d703597568e97025da.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7aa27948966717e8808650a0fc34b361.jpg" align="middle">
</details>




<h2 id="DaReNeRF-Direction-aware-Representation-for-Dynamic-Scenes"><a href="#DaReNeRF-Direction-aware-Representation-for-Dynamic-Scenes" class="headerlink" title="DaReNeRF: Direction-aware Representation for Dynamic Scenes"></a>DaReNeRF: Direction-aware Representation for Dynamic Scenes</h2><p><strong>Authors:Ange Lou, Benjamin Planche, Zhongpai Gao, Yamin Li, Tianyu Luan, Hao Ding, Terrence Chen, Jack Noble, Ziyan Wu</strong></p>
<p>Addressing the intricate challenge of modeling and re-rendering dynamic scenes, most recent approaches have sought to simplify these complexities using plane-based explicit representations, overcoming the slow training time issues associated with methods like Neural Radiance Fields (NeRF) and implicit representations. However, the straightforward decomposition of 4D dynamic scenes into multiple 2D plane-based representations proves insufficient for re-rendering high-fidelity scenes with complex motions. In response, we present a novel direction-aware representation (DaRe) approach that captures scene dynamics from six different directions. This learned representation undergoes an inverse dual-tree complex wavelet transformation (DTCWT) to recover plane-based information. DaReNeRF computes features for each space-time point by fusing vectors from these recovered planes. Combining DaReNeRF with a tiny MLP for color regression and leveraging volume rendering in training yield state-of-the-art performance in novel view synthesis for complex dynamic scenes. Notably, to address redundancy introduced by the six real and six imaginary direction-aware wavelet coefficients, we introduce a trainable masking approach, mitigating storage issues without significant performance decline. Moreover, DaReNeRF maintains a 2x reduction in training time compared to prior art while delivering superior performance. </p>
<p><a href="http://arxiv.org/abs/2403.02265v1">PDF</a> Accepted at CVPR 2024. Paper + supplementary material</p>
<p><strong>Summary</strong><br>ä½¿ç”¨å…­ä¸ªä¸åŒæ–¹å‘æ•æ‰åœºæ™¯åŠ¨æ€å¹¶èåˆä¿¡æ¯ï¼ŒDaReNeRF åœ¨å¤æ‚åŠ¨æ€åœºæ™¯çš„æ–°è§†å›¾åˆæˆä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨å…­ä¸ªæ–¹å‘æ„ŸçŸ¥è¡¨ç¤ºæ•è·åœºæ™¯åŠ¨æ€ã€‚</li>
<li>é‡‡ç”¨é€†å‘åŒæ ‘å¤å°æ³¢å˜æ¢æ¢å¤å¹³é¢ä¿¡æ¯ã€‚</li>
<li>å°†æ–¹å‘æ„ŸçŸ¥è¡¨ç¤ºèåˆåˆ° NeRF ä¸­ï¼Œè®¡ç®—æ—¶ç©ºç‚¹çš„ç‰¹å¾ã€‚</li>
<li>ä½¿ç”¨å°çš„ MLP è¿›è¡Œé¢œè‰²å›å½’ï¼Œåˆ©ç”¨ä½“ç§¯æ¸²æŸ“è¿›è¡Œè®­ç»ƒã€‚</li>
<li>å¼•å…¥å¯è®­ç»ƒæ©ç æ–¹æ³•ï¼Œåœ¨ä¸é™ä½æ€§èƒ½çš„æƒ…å†µä¸‹å‡è½»å­˜å‚¨é—®é¢˜ã€‚</li>
<li>ä¸ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œè®­ç»ƒæ—¶é—´å‡å°‘ 2 å€ï¼ŒåŒæ—¶æ€§èƒ½æ›´ä¼˜ã€‚</li>
<li>é€‚ç”¨äºå…·æœ‰å¤æ‚è¿åŠ¨çš„é«˜ä¿çœŸåœºæ™¯çš„é‡æ–°æ¸²æŸ“ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><strong>æ ‡é¢˜ï¼š</strong> DaReNeRFï¼šåŠ¨æ€åœºæ™¯çš„æ–¹å‘æ„ŸçŸ¥è¡¨å¾</li>
<li><strong>ä½œè€…ï¼š</strong> Ange Lou, Tianyu Luan, Hao Ding, Wenbo Luo, Xiaogang Wang, Wenzheng Chen</li>
<li><strong>ç¬¬ä¸€ä½œè€…å•ä½ï¼š</strong> United Imaging Intelligence</li>
<li><strong>å…³é”®è¯ï¼š</strong> åŠ¨æ€åœºæ™¯ï¼Œç¥ç»è¾å°„åœºï¼Œå¹³é¢è¡¨ç¤ºï¼Œæ–¹å‘æ„ŸçŸ¥è¡¨å¾</li>
<li><strong>è®ºæ–‡é“¾æ¥ï¼š</strong> None</li>
<li>
<p><strong>æ‘˜è¦ï¼š</strong>
   (1) <strong>ç ”ç©¶èƒŒæ™¯ï¼š</strong> è¿‘æœŸæ–¹æ³•ä½¿ç”¨åŸºäºå¹³é¢çš„æ˜¾å¼è¡¨å¾æ¥ç®€åŒ–åŠ¨æ€åœºæ™¯å»ºæ¨¡å’Œæ¸²æŸ“ï¼Œå…‹æœäº†ç¥ç»è¾å°„åœºç­‰æ–¹æ³•ç›¸å…³çš„è®­ç»ƒæ—¶é—´æ…¢çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œå°† 4D åŠ¨æ€åœºæ™¯ç›´æ¥åˆ†è§£ä¸ºå¤šä¸ªåŸºäºå¹³é¢çš„ 2D è¡¨å¾ä¸è¶³ä»¥æ¸²æŸ“å…·æœ‰å¤æ‚è¿åŠ¨çš„é«˜ä¿çœŸåœºæ™¯ã€‚
   (2) <strong>è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š</strong> ç°æœ‰æ–¹æ³•å°†åŠ¨æ€åœºæ™¯åˆ†è§£ä¸ºå¤šä¸ªåŸºäºå¹³é¢çš„ 2D è¡¨å¾ï¼Œä½†è¿™ç§æ–¹æ³•ä¸è¶³ä»¥æ¸²æŸ“å…·æœ‰å¤æ‚è¿åŠ¨çš„é«˜ä¿çœŸåœºæ™¯ã€‚
   (3) <strong>ç ”ç©¶æ–¹æ³•ï¼š</strong> æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹å‘æ„ŸçŸ¥è¡¨å¾ (DaRe) æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»å…­ä¸ªä¸åŒæ–¹å‘æ•è·åœºæ™¯åŠ¨æ€ã€‚è¿™ç§å­¦ä¹ åˆ°çš„è¡¨å¾ç»è¿‡é€†åŒæ ‘å¤å°æ³¢å˜æ¢ (DTCWT) ä»¥æ¢å¤åŸºäºå¹³é¢çš„ä¿¡æ¯ã€‚DaReNeRF é€šè¿‡èåˆè¿™äº›æ¢å¤çš„å¹³é¢çš„å‘é‡æ¥è®¡ç®—æ¯ä¸ªæ—¶ç©ºç‚¹çš„ç‰¹å¾ã€‚å°† DaReNeRF ä¸ç”¨äºé¢œè‰²å›å½’çš„å¾®å° MLP ç»“åˆèµ·æ¥ï¼Œå¹¶åˆ©ç”¨ä½“ç§¯æ¸²æŸ“è¿›è¡Œè®­ç»ƒï¼Œåœ¨å¤æ‚åŠ¨æ€åœºæ™¯çš„æ–°è§†è§’åˆæˆä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
   (4) <strong>æ–¹æ³•æ€§èƒ½ï¼š</strong> DaReNeRF åœ¨è®­ç»ƒæ—¶é—´ä¸Šæ¯”ç°æœ‰æ–¹æ³•å‡å°‘äº† 2 å€ï¼ŒåŒæ—¶æä¾›äº†æ›´å¥½çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): è¯¥æ–¹æ³•ä»å…­ä¸ªä¸åŒæ–¹å‘æ•è·åœºæ™¯åŠ¨æ€ï¼Œå­¦ä¹ åˆ°çš„è¡¨å¾ç»è¿‡é€†åŒæ ‘å¤å°æ³¢å˜æ¢ (DTCWT) ä»¥æ¢å¤åŸºäºå¹³é¢çš„ä¿¡æ¯ã€‚
(2): DaReNeRF é€šè¿‡èåˆè¿™äº›æ¢å¤çš„å¹³é¢çš„å‘é‡æ¥è®¡ç®—æ¯ä¸ªæ—¶ç©ºç‚¹çš„ç‰¹å¾ã€‚
(3): å°† DaReNeRF ä¸ç”¨äºé¢œè‰²å›å½’çš„å¾®å° MLP ç»“åˆèµ·æ¥ï¼Œå¹¶åˆ©ç”¨ä½“ç§¯æ¸²æŸ“è¿›è¡Œè®­ç»ƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œé€šè¿‡æå‡º DaReNeRF æ–¹æ³•ï¼Œåœ¨åŠ¨æ€åœºæ™¯å»ºæ¨¡å’Œæ¸²æŸ“é¢†åŸŸå–å¾—äº†é‡è¦è¿›å±•ã€‚è¯¥æ–¹æ³•ä»å…­ä¸ªä¸åŒæ–¹å‘æ•è·åœºæ™¯åŠ¨æ€ï¼Œå¹¶åˆ©ç”¨é€†åŒæ ‘å¤å°æ³¢å˜æ¢æ¢å¤åŸºäºå¹³é¢çš„ä¿¡æ¯ï¼Œä»è€Œæœ‰æ•ˆè§£å†³äº†å¤æ‚åŠ¨æ€åœºæ™¯çš„é«˜ä¿çœŸæ¸²æŸ“é—®é¢˜ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>ä»å…­ä¸ªä¸åŒæ–¹å‘æ•è·åœºæ™¯åŠ¨æ€ï¼Œä¸°å¯Œäº†åœºæ™¯ä¿¡æ¯çš„è·å–ã€‚</li>
<li>é‡‡ç”¨é€†åŒæ ‘å¤å°æ³¢å˜æ¢æ¢å¤åŸºäºå¹³é¢çš„ä¿¡æ¯ï¼Œæœ‰æ•ˆèåˆäº†ä¸åŒæ–¹å‘çš„ç‰¹å¾ã€‚</li>
<li>å°† DaReNeRF ä¸å¾®å° MLP ç»“åˆï¼Œå¹¶åˆ©ç”¨ä½“ç§¯æ¸²æŸ“è¿›è¡Œè®­ç»ƒï¼Œå®ç°äº†é«˜æ•ˆä¸”é«˜è´¨é‡çš„æ¸²æŸ“ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¤æ‚åŠ¨æ€åœºæ™¯çš„æ–°è§†è§’åˆæˆä»»åŠ¡ä¸Šï¼ŒDaReNeRF å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDaReNeRF è®­ç»ƒæ—¶é—´å‡å°‘äº† 2 å€ï¼Œæ¸²æŸ“æ•ˆç‡æ›´é«˜ã€‚
å·¥ä½œé‡ï¼š</li>
<li>DaReNeRF æ–¹æ³•çš„å®ç°éš¾åº¦é€‚ä¸­ï¼Œéœ€è¦å¯¹ç¥ç»è¾å°„åœºã€å°æ³¢å˜æ¢å’Œä½“ç§¯æ¸²æŸ“ç­‰æŠ€æœ¯æœ‰ä¸€å®šçš„äº†è§£ã€‚</li>
<li>è®­ç»ƒ DaReNeRF æ¨¡å‹éœ€è¦å¤§é‡çš„åŠ¨æ€åœºæ™¯æ•°æ®å’Œè¾ƒé•¿çš„è®­ç»ƒæ—¶é—´ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0b34eef417abcdd2b497ef2ebd10beb3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a94b89ba44b447b4f183c953bb896e07.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0fc68e3cc2c894a358a3d010ccbf0fa0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2f3c90874730f6ec424afc1f7edde45a.jpg" align="middle">
</details>




<h2 id="Depth-Guided-Robust-and-Fast-Point-Cloud-Fusion-NeRF-for-Sparse-Input-Views"><a href="#Depth-Guided-Robust-and-Fast-Point-Cloud-Fusion-NeRF-for-Sparse-Input-Views" class="headerlink" title="Depth-Guided Robust and Fast Point Cloud Fusion NeRF for Sparse Input   Views"></a>Depth-Guided Robust and Fast Point Cloud Fusion NeRF for Sparse Input   Views</h2><p><strong>Authors:Shuai Guo, Qiuwen Wang, Yijie Gao, Rong Xie, Li Song</strong></p>
<p>Novel-view synthesis with sparse input views is important for real-world applications like AR/VR and autonomous driving. Recent methods have integrated depth information into NeRFs for sparse input synthesis, leveraging depth prior for geometric and spatial understanding. However, most existing works tend to overlook inaccuracies within depth maps and have low time efficiency. To address these issues, we propose a depth-guided robust and fast point cloud fusion NeRF for sparse inputs. We perceive radiance fields as an explicit voxel grid of features. A point cloud is constructed for each input view, characterized within the voxel grid using matrices and vectors. We accumulate the point cloud of each input view to construct the fused point cloud of the entire scene. Each voxel determines its density and appearance by referring to the point cloud of the entire scene. Through point cloud fusion and voxel grid fine-tuning, inaccuracies in depth values are refined or substituted by those from other views. Moreover, our method can achieve faster reconstruction and greater compactness through effective vector-matrix decomposition. Experimental results underline the superior performance and time efficiency of our approach compared to state-of-the-art baselines. </p>
<p><a href="http://arxiv.org/abs/2403.02063v1">PDF</a> </p>
<p><strong>Summary</strong><br><strong>NeRFæ·±åº¦å¼•å¯¼ç‚¹äº‘èåˆï¼šå¢å¼ºç¨€ç–è¾“å…¥åœºæ™¯ä¸‹æ–°è§†è§’åˆæˆ</strong></p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºæ·±åº¦å¼•å¯¼çš„NeRFï¼Œç”¨äºç¨€ç–è¾“å…¥çš„æ–°è§†è§’åˆæˆã€‚</li>
<li>ä½¿ç”¨æ˜¾å¼ä½“ç´ ç½‘æ ¼è¡¨ç¤ºè¾å°„åœºã€‚</li>
<li>æ„é€ æ¯ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹äº‘ï¼Œå¹¶åœ¨ä½“ç´ ç½‘æ ¼ä¸­ç”¨çŸ©é˜µå’Œå‘é‡æè¿°ã€‚</li>
<li>èåˆæ¯ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹äº‘ï¼Œæ„å»ºæ•´ä¸ªåœºæ™¯çš„èåˆç‚¹äº‘ã€‚</li>
<li>æ¯ä¸ªä½“ç´ æ ¹æ®æ•´ä¸ªåœºæ™¯çš„ç‚¹äº‘ç¡®å®šå…¶å¯†åº¦å’Œå¤–è§‚ã€‚</li>
<li>é€šè¿‡ç‚¹äº‘èåˆå’Œä½“ç´ ç½‘æ ¼å¾®è°ƒï¼Œå¯ä»¥ä¿®æ­£å’Œæ›¿æ¢æ·±åº¦å€¼çš„è¯¯å·®ã€‚</li>
<li>é€šè¿‡æœ‰æ•ˆçš„å‘é‡-çŸ©é˜µåˆ†è§£ï¼Œæ–¹æ³•å®ç°äº†æ›´å¿«çš„é‡å»ºå’Œæ›´å¤§çš„ç´§å‡‘æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šæ·±åº¦å¼•å¯¼çš„é²æ£’ä¸”å¿«é€Ÿçš„ç‚¹äº‘èåˆ NeRFï¼Œç”¨äºç¨€ç–è¾“å…¥è§†å›¾</li>
<li>ä½œè€…ï¼šShuai Guoã€Qiuwen Wangã€Yijie Gaoã€Rong Xieã€Li Song</li>
<li>éš¶å±å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦å›¾åƒé€šä¿¡ä¸ç½‘ç»œå·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šNeRFã€ç¨€ç–è§†å›¾ã€æ·±åº¦èåˆã€ç‚¹äº‘èåˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone
    Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRF åœ¨ç¨€ç–è¾“å…¥è§†å›¾ä¸‹çš„æ–°è§†å›¾åˆæˆå¯¹äº AR/VR å’Œè‡ªåŠ¨é©¾é©¶ç­‰çœŸå®ä¸–ç•Œåº”ç”¨éå¸¸é‡è¦ã€‚
   ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•å°†æ·±åº¦ä¿¡æ¯é›†æˆåˆ° NeRF ä¸­ä»¥è¿›è¡Œç¨€ç–è¾“å…¥åˆæˆï¼Œåˆ©ç”¨æ·±åº¦å…ˆéªŒè¿›è¡Œå‡ ä½•å’Œç©ºé—´ç†è§£ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰å·¥ä½œå¾€å¾€å¿½ç•¥æ·±åº¦å›¾ä¸­çš„ä¸å‡†ç¡®æ€§ï¼Œå¹¶ä¸”æ—¶é—´æ•ˆç‡ä½ã€‚
   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºç¨€ç–è¾“å…¥çš„æ·±åº¦å¼•å¯¼çš„é²æ£’ä¸”å¿«é€Ÿçš„ç‚¹äº‘èåˆ NeRFã€‚æˆ‘ä»¬å°†è¾å°„åœºæ„ŸçŸ¥ä¸ºä¸€ä¸ªæ˜¾å¼çš„ç‰¹å¾ä½“ç´ ç½‘æ ¼ã€‚ä¸ºæ¯ä¸ªè¾“å…¥è§†å›¾æ„å»ºä¸€ä¸ªç‚¹äº‘ï¼Œä½¿ç”¨çŸ©é˜µå’Œå‘é‡åœ¨ä½“ç´ ç½‘æ ¼ä¸­è¡¨å¾ã€‚æˆ‘ä»¬ç´¯ç§¯æ¯ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹äº‘ï¼Œä»¥æ„å»ºæ•´ä¸ªåœºæ™¯çš„èåˆç‚¹äº‘ã€‚æ¯ä¸ªä½“ç´ é€šè¿‡å‚è€ƒæ•´ä¸ªåœºæ™¯çš„ç‚¹äº‘æ¥ç¡®å®šå…¶å¯†åº¦å’Œå¤–è§‚ã€‚é€šè¿‡ç‚¹äº‘èåˆå’Œä½“ç´ ç½‘æ ¼å¾®è°ƒï¼Œå¯ä»¥ç»†åŒ–æ·±åº¦å€¼ä¸­çš„ä¸å‡†ç¡®æ€§æˆ–ç”¨å…¶ä»–è§†å›¾ä¸­çš„å€¼æ›¿æ¢å®ƒä»¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥é€šè¿‡æœ‰æ•ˆçš„å‘é‡çŸ©é˜µåˆ†è§£å®ç°æ›´å¿«çš„é‡å»ºå’Œæ›´é«˜çš„ç´§å‡‘æ€§ã€‚
   ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœå¼ºè°ƒäº†æˆ‘ä»¬æ–¹æ³•ä¸æœ€å…ˆè¿›åŸºå‡†ç›¸æ¯”çš„å“è¶Šæ€§èƒ½å’Œæ—¶é—´æ•ˆç‡ã€‚</li>
</ol>
<p>7.Methods:
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§æ·±åº¦å¼•å¯¼çš„é²æ£’ä¸”å¿«é€Ÿçš„ç‚¹äº‘èåˆNeRFï¼Œç”¨äºç¨€ç–è¾“å…¥è§†å›¾ï¼›
(2): å°†è¾å°„åœºæ„ŸçŸ¥ä¸ºä¸€ä¸ªæ˜¾å¼çš„ç‰¹å¾ä½“ç´ ç½‘æ ¼ï¼Œä¸ºæ¯ä¸ªè¾“å…¥è§†å›¾æ„å»ºä¸€ä¸ªç‚¹äº‘ï¼Œå¹¶ä½¿ç”¨çŸ©é˜µå’Œå‘é‡åœ¨ä½“ç´ ç½‘æ ¼ä¸­è¡¨å¾ï¼›
(3): ç´¯ç§¯æ¯ä¸ªè¾“å…¥è§†å›¾çš„ç‚¹äº‘ï¼Œä»¥æ„å»ºæ•´ä¸ªåœºæ™¯çš„èåˆç‚¹äº‘ï¼Œæ¯ä¸ªä½“ç´ é€šè¿‡å‚è€ƒæ•´ä¸ªåœºæ™¯çš„ç‚¹äº‘æ¥ç¡®å®šå…¶å¯†åº¦å’Œå¤–è§‚ï¼›
(4): é€šè¿‡ç‚¹äº‘èåˆå’Œä½“ç´ ç½‘æ ¼å¾®è°ƒï¼Œå¯ä»¥ç»†åŒ–æ·±åº¦å€¼ä¸­çš„ä¸å‡†ç¡®æ€§æˆ–ç”¨å…¶ä»–è§†å›¾ä¸­çš„å€¼æ›¿æ¢å®ƒä»¬ï¼›
(5): æ­¤å¤–ï¼Œé€šè¿‡æœ‰æ•ˆçš„å‘é‡çŸ©é˜µåˆ†è§£ï¼Œå¯ä»¥å®ç°æ›´å¿«çš„é‡å»ºå’Œæ›´é«˜çš„ç´§å‡‘æ€§ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬æ–‡æå‡ºçš„æ·±åº¦å¼•å¯¼çš„é²æ£’ä¸”å¿«é€Ÿçš„ç‚¹äº‘èåˆNeRFï¼Œå¯¹äºç¨€ç–è¾“å…¥è§†å›¾ä¸‹çš„æ–°è§†å›¾åˆæˆå…·æœ‰é‡è¦æ„ä¹‰ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
<li>å°†è¾å°„åœºæ„ŸçŸ¥ä¸ºä¸€ä¸ªæ˜¾å¼çš„ç‰¹å¾ä½“ç´ ç½‘æ ¼ï¼Œå¹¶ä½¿ç”¨çŸ©é˜µå’Œå‘é‡è¿›è¡Œè¡¨å¾ã€‚</li>
<li>é€šè¿‡ç‚¹äº‘èåˆå’Œä½“ç´ ç½‘æ ¼å¾®è°ƒï¼Œç»†åŒ–æ·±åº¦å€¼ä¸­çš„ä¸å‡†ç¡®æ€§ã€‚</li>
<li>é€šè¿‡æœ‰æ•ˆçš„å‘é‡çŸ©é˜µåˆ†è§£ï¼Œå®ç°æ›´å¿«çš„é‡å»ºå’Œæ›´é«˜çš„ç´§å‡‘æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>ä¸æœ€å…ˆè¿›çš„åŸºå‡†ç›¸æ¯”ï¼Œå…·æœ‰å“è¶Šçš„æ€§èƒ½å’Œæ—¶é—´æ•ˆç‡ã€‚
å·¥ä½œé‡ï¼š</li>
<li>å®ç°äº†æ›´å¿«çš„é‡å»ºå’Œæ›´é«˜çš„ç´§å‡‘æ€§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-01b32742a4cabe31ed749a6761475634.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-70b0b04ae4cf460209e8f732888cddee.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-86aa24ab75498868b39b0c370990c2e8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4f6398dec60102c0bb1f5d24d9a89432.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2d78f63f12b2bcb3ca39476e980147ba.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-4a484aa0d25d0950586c81e66b07ef9d.jpg" align="middle">
</details>




<h2 id="NeRF-VPT-Learning-Novel-View-Representations-with-Neural-Radiance-Fields-via-View-Prompt-Tuning"><a href="#NeRF-VPT-Learning-Novel-View-Representations-with-Neural-Radiance-Fields-via-View-Prompt-Tuning" class="headerlink" title="NeRF-VPT: Learning Novel View Representations with Neural Radiance   Fields via View Prompt Tuning"></a>NeRF-VPT: Learning Novel View Representations with Neural Radiance   Fields via View Prompt Tuning</h2><p><strong>Authors:Linsheng Chen, Guangrun Wang, Liuchun Yuan, Keze Wang, Ken Deng, Philip H. S. Torr</strong></p>
<p>Neural Radiance Fields (NeRF) have garnered remarkable success in novel view synthesis. Nonetheless, the task of generating high-quality images for novel views persists as a critical challenge. While the existing efforts have exhibited commendable progress, capturing intricate details, enhancing textures, and achieving superior Peak Signal-to-Noise Ratio (PSNR) metrics warrant further focused attention and advancement. In this work, we propose NeRF-VPT, an innovative method for novel view synthesis to address these challenges. Our proposed NeRF-VPT employs a cascading view prompt tuning paradigm, wherein RGB information gained from preceding rendering outcomes serves as instructive visual prompts for subsequent rendering stages, with the aspiration that the prior knowledge embedded in the prompts can facilitate the gradual enhancement of rendered image quality. NeRF-VPT only requires sampling RGB data from previous stage renderings as priors at each training stage, without relying on extra guidance or complex techniques. Thus, our NeRF-VPT is plug-and-play and can be readily integrated into existing methods. By conducting comparative analyses of our NeRF-VPT against several NeRF-based approaches on demanding real-scene benchmarks, such as Realistic Synthetic 360, Real Forward-Facing, Replica dataset, and a user-captured dataset, we substantiate that our NeRF-VPT significantly elevates baseline performance and proficiently generates more high-quality novel view images than all the compared state-of-the-art methods. Furthermore, the cascading learning of NeRF-VPT introduces adaptability to scenarios with sparse inputs, resulting in a significant enhancement of accuracy for sparse-view novel view synthesis. The source code and dataset are available at \url{<a href="https://github.com/Freedomcls/NeRF-VPT}">https://github.com/Freedomcls/NeRF-VPT}</a>. </p>
<p><a href="http://arxiv.org/abs/2403.01325v1">PDF</a> AAAI 2024</p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨æ–°çš„è§†é‡åˆæˆä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†ç”Ÿæˆé«˜è´¨é‡æ–°è§†è§’å›¾åƒä»æ˜¯ä¸€é¡¹é‡è¦æŒ‘æˆ˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NeRF-VPT åˆ©ç”¨çº§è”è§†å›¾æç¤ºè°ƒæ•´èŒƒä¾‹æ¥è§£å†³æ–°è§†è§’åˆæˆä¸­çš„ç»†èŠ‚æ•è·ã€çº¹ç†å¢å¼ºå’Œ PSNR æå‡é—®é¢˜ã€‚</li>
<li>NeRF-VPT ä»…éœ€åœ¨å„ä¸ªè®­ç»ƒé˜¶æ®µå¯¹å‰ä¸€é˜¶æ®µæ¸²æŸ“ç»“æœçš„ RGB æ•°æ®è¿›è¡Œé‡‡æ ·ä½œä¸ºå…ˆéªŒã€‚</li>
<li>NeRF-VPT æ˜¯ä¸€ç§å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰æ–¹æ³•ä¸­ã€‚</li>
<li>NeRF-VPT åœ¨ Realistic Synthetic 360ã€Real Forward-Facingã€Replica æ•°æ®é›†å’Œç”¨æˆ·æ•è·æ•°æ®é›†ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®åœºæ™¯åŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†åŸºå‡†æ€§èƒ½ï¼Œå¹¶äº§ç”Ÿäº†æ¯”æ‰€æœ‰æ¯”è¾ƒçš„æœ€æ–°æ–¹æ³•æ›´é«˜è´¨é‡çš„æ–°è§†è§’å›¾åƒã€‚</li>
<li>NeRF-VPT çš„çº§è”å­¦ä¹ å¼•å…¥äº†å¯¹ç¨€ç–è¾“å…¥åœºæ™¯çš„é€‚åº”æ€§ï¼Œä»è€Œæ˜¾ç€æé«˜äº†ç¨€ç–è§†è§’æ–°è§†è§’åˆæˆçš„å‡†ç¡®æ€§ã€‚</li>
<li>æºä»£ç å’Œæ•°æ®é›†å¯åœ¨ \url{<a href="https://github.com/Freedomcls/NeRF-VPT}">https://github.com/Freedomcls/NeRF-VPT}</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šNeRF-VPTï¼šé€šè¿‡è§†å›¾æç¤ºè°ƒæ•´å­¦ä¹ æ–°é¢–è§†å›¾è¡¨ç¤º</li>
<li>ä½œè€…ï¼šLinsheng Chenã€Guangrun Wangã€Liuchun Yuanã€Keze Wangã€Ken Dengã€Philip H.S. Torr</li>
<li>Affiliationï¼šä¸­å±±å¤§å­¦</li>
<li>å…³é”®è¯ï¼šNeRFã€æ–°é¢–è§†å›¾åˆæˆã€è§†å›¾æç¤ºè°ƒæ•´</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.01325
   Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRF åœ¨æ–°é¢–è§†å›¾åˆæˆä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†ç”Ÿæˆé«˜è´¨é‡çš„æ–°é¢–è§†å›¾å›¾åƒä»ç„¶æ˜¯ä¸€é¡¹å…³é”®æŒ‘æˆ˜ã€‚
   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•åœ¨æ•æ‰å¤æ‚ç»†èŠ‚ã€å¢å¼ºçº¹ç†å’Œæé«˜ PSNR æ–¹é¢å–å¾—äº†å¯å–œçš„è¿›å±•ï¼Œä½†ä»éœ€è¦è¿›ä¸€æ­¥å…³æ³¨å’Œæ”¹è¿›ã€‚
   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º NeRF-VPT çš„æ–°é¢–è§†å›¾åˆæˆæ–¹æ³•ï¼Œé‡‡ç”¨çº§è”è§†å›¾æç¤ºè°ƒæ•´èŒƒå¼ã€‚è¯¥èŒƒå¼å°†æ¥è‡ªå…ˆå‰æ¸²æŸ“ç»“æœçš„ RGB ä¿¡æ¯ä½œä¸ºåç»­æ¸²æŸ“é˜¶æ®µçš„æŒ‡å¯¼æ€§è§†è§‰æç¤ºï¼ŒæœŸæœ›æç¤ºä¸­åµŒå…¥çš„å…ˆéªŒçŸ¥è¯†èƒ½å¤Ÿä¿ƒè¿›æ¸²æŸ“å›¾åƒè´¨é‡çš„é€æ­¥æé«˜ã€‚
   ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ RealisticSynthetic360ã€RealForward-Facingã€Replica æ•°æ®é›†å’Œç”¨æˆ·æ•è·æ•°æ®é›†ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®åœºæ™¯åŸºå‡†ä¸Šï¼Œå°† NeRF-VPT ä¸åŸºäº NeRF çš„æ–¹æ³•è¿›è¡Œæ¯”è¾ƒåˆ†æï¼Œç»“æœè¡¨æ˜ NeRF-VPT æ˜¾ç€æå‡äº†åŸºå‡†æ€§èƒ½ï¼Œå¹¶æ¯”æ‰€æœ‰æ¯”è¾ƒçš„æœ€å…ˆè¿›æ–¹æ³•æ›´æœ‰æ•ˆåœ°ç”Ÿæˆäº†æ›´å¤šé«˜è´¨é‡çš„æ–°é¢–è§†å›¾å›¾åƒã€‚æ­¤å¤–ï¼ŒNeRF-VPT çš„çº§è”å­¦ä¹ å¼•å…¥äº†å¯¹ç¨€ç–è¾“å…¥åœºæ™¯çš„é€‚åº”æ€§ï¼Œä»è€Œæ˜¾ç€æé«˜äº†ç¨€ç–è§†å›¾æ–°é¢–è§†å›¾åˆæˆçš„å‡†ç¡®æ€§ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šNeRF-VPTé‡‡ç”¨çº§è”è§†å›¾æç¤ºè°ƒæ•´èŒƒå¼ï¼Œå°†æ¥è‡ªå…ˆå‰æ¸²æŸ“ç»“æœçš„RGBä¿¡æ¯ä½œä¸ºåç»­æ¸²æŸ“é˜¶æ®µçš„æŒ‡å¯¼æ€§è§†è§‰æç¤ºï¼ŒæœŸæœ›æç¤ºä¸­åµŒå…¥çš„å…ˆéªŒçŸ¥è¯†èƒ½å¤Ÿä¿ƒè¿›æ¸²æŸ“å›¾åƒè´¨é‡çš„é€æ­¥æé«˜ã€‚
ï¼ˆ2ï¼‰ï¼šNeRF-VPTåœ¨NeRFçš„åŸºç¡€ä¸Šï¼Œå°†ä½ç½®ç¼–ç å’Œæ–¹å‘ç¼–ç æ‰©å±•ä¸ºåŒ…å«å…ˆéªŒä¿¡æ¯çš„ç¼–ç ï¼Œå¹¶é‡‡ç”¨åˆ†å±‚ç»“æ„ï¼Œåœ¨æ¯ä¸€å±‚ä¸­ä½¿ç”¨æ›´æ–°çš„è§†å›¾æç¤ºæ¥æŒ‡å¯¼æ¸²æŸ“ã€‚
ï¼ˆ3ï¼‰ï¼šNeRF-VPTå¼•å…¥äº†ä¸€ä¸ªæ–°çš„æŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°å°†æ¸²æŸ“å›¾åƒä¸è§†å›¾æç¤ºä¹‹é—´çš„å·®å¼‚çº³å…¥è€ƒè™‘ï¼Œä»è€Œé¼“åŠ±æ¸²æŸ“å›¾åƒä¸è§†å›¾æç¤ºä¿æŒä¸€è‡´ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é€šç”¨çš„æ¡†æ¶ï¼Œä»¥æé«˜åŸºäº NeRF çš„è§†å›¾åˆæˆçš„æ€§èƒ½ã€‚æˆ‘ä»¬æå‡ºäº† NeRF-VPTï¼Œå®ƒå¼•å…¥äº†ä¸€ç§å…·æœ‰å¾ªç¯æ¨¡å—çš„æ–°ç»“æ„ï¼Œå¹¶é‡‡ç”¨ NeRF çš„è¾“å‡ºä½œä¸ºå…ˆéªŒã€‚è¿™ä½¿å¾— NeRF-VPT èƒ½å¤Ÿæ˜¾ç€æé«˜è§†å›¾ç›¸å…³å¤–è§‚çš„è´¨é‡ã€‚å®ƒå¯¹ç«¯å£å‹å¥½ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¸ç°æœ‰æ–¹æ³•ç›¸ç»“åˆä»¥è·å¾—æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™é¡¹å·¥ä½œä¸ºå……åˆ†åˆ©ç”¨è¡¨ç¤ºæä¾›äº†æ–°çš„è§†è§’ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è§†å›¾æç¤ºè°ƒæ•´èŒƒå¼ï¼Œå°†å…ˆéªŒä¿¡æ¯åµŒå…¥åˆ° NeRF ä¸­ï¼Œä»¥é€æ­¥æé«˜æ¸²æŸ“å›¾åƒçš„è´¨é‡ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§åˆ†å±‚ç»“æ„ï¼Œåœ¨æ¯ä¸€å±‚ä¸­ä½¿ç”¨æ›´æ–°çš„è§†å›¾æç¤ºæ¥æŒ‡å¯¼æ¸²æŸ“ï¼Œä»è€Œæ•è·å¤æ‚ç»†èŠ‚å¹¶å¢å¼ºçº¹ç†ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªæ–°çš„æŸå¤±å‡½æ•°ï¼Œå°†æ¸²æŸ“å›¾åƒä¸è§†å›¾æç¤ºä¹‹é—´çš„å·®å¼‚çº³å…¥è€ƒè™‘ï¼Œä»¥é¼“åŠ±æ¸²æŸ“å›¾åƒä¸è§†å›¾æç¤ºä¿æŒä¸€è‡´ã€‚</li>
<li>æ€§èƒ½ï¼š</li>
<li>åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„çœŸå®åœºæ™¯åŸºå‡†ä¸Šï¼ŒNeRF-VPT æ˜¾ç€æå‡äº†åŸºå‡†æ€§èƒ½ï¼Œå¹¶æ¯”æ‰€æœ‰æ¯”è¾ƒçš„æœ€å…ˆè¿›æ–¹æ³•æ›´æœ‰æ•ˆåœ°ç”Ÿæˆäº†æ›´å¤šé«˜è´¨é‡çš„æ–°é¢–è§†å›¾å›¾åƒã€‚</li>
<li>NeRF-VPT çš„çº§è”å­¦ä¹ å¼•å…¥äº†å¯¹ç¨€ç–è¾“å…¥åœºæ™¯çš„é€‚åº”æ€§ï¼Œä»è€Œæ˜¾ç€æé«˜äº†ç¨€ç–è§†å›¾æ–°é¢–è§†å›¾åˆæˆçš„å‡†ç¡®æ€§ã€‚</li>
<li>å·¥ä½œé‡ï¼š</li>
<li>NeRF-VPT çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾é›†æˆåˆ°ç°æœ‰çš„ NeRF æ¡†æ¶ä¸­ã€‚</li>
<li>NeRF-VPT çš„è®­ç»ƒè¿‡ç¨‹é«˜æ•ˆä¸”ç¨³å®šï¼Œå¹¶ä¸”å¯ä»¥åœ¨å„ç§ç¡¬ä»¶å¹³å°ä¸Šè½»æ¾å¹¶è¡ŒåŒ–ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a3d4a33c83819ae9629aeb5c7e195d32.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-19c08401f045ff72d6d7af9a10c9430a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a9c42f61f791fd5834fe43a11782fabd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-135c07d8cd0edaf636a5f342ab6e1725.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf190c96eea398ae33fd3f16daf3d9cc.jpg" align="middle">
</details>




<h2 id="Neural-radiance-fields-based-holography-Invited"><a href="#Neural-radiance-fields-based-holography-Invited" class="headerlink" title="Neural radiance fields-based holography [Invited]"></a>Neural radiance fields-based holography [Invited]</h2><p><strong>Authors:Minsung Kang, Fan Wang, Kai Kumano, Tomoyoshi Ito, Tomoyoshi Shimobaba</strong></p>
<p>This study presents a novel approach for generating holograms based on the neural radiance fields (NeRF) technique. Generating three-dimensional (3D) data is difficult in hologram computation. NeRF is a state-of-the-art technique for 3D light-field reconstruction from 2D images based on volume rendering. The NeRF can rapidly predict new-view images that do not include a training dataset. In this study, we constructed a rendering pipeline directly from a 3D light field generated from 2D images by NeRF for hologram generation using deep neural networks within a reasonable time. The pipeline comprises three main components: the NeRF, a depth predictor, and a hologram generator, all constructed using deep neural networks. The pipeline does not include any physical calculations. The predicted holograms of a 3D scene viewed from any direction were computed using the proposed pipeline. The simulation and experimental results are presented. </p>
<p><a href="http://arxiv.org/abs/2403.01137v1">PDF</a> </p>
<p><strong>Summary</strong><br>NeRFæŠ€æœ¯ç»“åˆæ·±åº¦é¢„æµ‹å™¨å’Œå…¨æ¯å›¾ç”Ÿæˆå™¨ï¼Œå¯å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡å…¨æ¯å›¾ï¼Œæ— éœ€ç‰©ç†è®¡ç®—ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨NeRFæŠ€æœ¯ä»2Då›¾åƒç”Ÿæˆ3Då…‰åœºï¼Œä¸ºå…¨æ¯å›¾è®¡ç®—æä¾›æ•°æ®æºã€‚</li>
<li>æ„å»ºç”±NeRFã€æ·±åº¦é¢„æµ‹å™¨å’Œå…¨æ¯å›¾ç”Ÿæˆå™¨ç»„æˆçš„æ¸²æŸ“ç®¡é“ï¼Œç”¨äºå…¨æ¯å›¾ç”Ÿæˆã€‚</li>
<li>æ¸²æŸ“ç®¡é“å®Œå…¨åŸºäºæ·±åº¦å­¦ä¹ ï¼Œæ— ç‰©ç†è®¡ç®—ã€‚</li>
<li>æ¸²æŸ“ç®¡é“å¯å¿«é€Ÿç”Ÿæˆä»»æ„è§†è§’ä¸‹çš„3Dåœºæ™¯å…¨æ¯å›¾ã€‚</li>
<li>ä»¿çœŸå’Œå®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç®¡é“å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å…¨æ¯å›¾ã€‚</li>
<li>è¯¥æ–¹æ³•æ¶ˆé™¤äº†å…¨æ¯å›¾è®¡ç®—ä¸­å¯¹ç‰©ç†æ¨¡æ‹Ÿçš„éœ€æ±‚ã€‚</li>
<li>é€šè¿‡ç»“åˆNeRFæŠ€æœ¯å’Œæ·±åº¦å­¦ä¹ ï¼Œè¯¥æ–¹æ³•æé«˜äº†å…¨æ¯å›¾ç”Ÿæˆçš„é€Ÿåº¦å’Œè´¨é‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºç¥ç»è¾å°„åœºçš„å…¨æ¯æœ¯[å—é‚€]</li>
<li>ä½œè€…ï¼šMinsung Kang, Fan Wang, Kai Kumao, Tomoyoshi Ito, Tomoyoshi Shimobaba</li>
<li>éš¶å±å•ä½ï¼šåƒå¶å¤§å­¦å·¥ç¨‹å­¦é™¢</li>
<li>å…³é”®è¯ï¼šå…¨æ¯æ˜¾ç¤ºã€ç¥ç»è¾å°„åœºã€æ·±åº¦å­¦ä¹ ã€å…‰åœºé‡å»º</li>
<li>é“¾æ¥ï¼šhttp://dx.doi.org/10.1364/ao.XX.XXXXXX</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå…¨æ¯æ˜¾ç¤ºå™¨éœ€è¦ä¸‰ç»´åœºæ™¯æ•°æ®ã€å…¨æ¯å›¾å’Œä¸‰ç»´å›¾åƒå†ç°ä¸‰ä¸ªæ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½å­˜åœ¨éšœç¢ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¯¹ä¸‰ç»´åœºæ™¯æ•°æ®å’Œå…¨æ¯å›¾çš„è®¡ç®—æ˜¯éšœç¢ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå…¨æ¯å›¾çš„è®¡ç®—åŸºäºå…‰ä¼ æ’­æ¨¡å‹ï¼Œå¯ä»¥åˆ†ä¸ºç‚¹äº‘ã€å¤šè¾¹å½¢ã€å…‰åœºå’Œæ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•å„æœ‰ä¼˜ç¼ºç‚¹ï¼Œä½†éƒ½éœ€è¦ç¹çä¸”è€—æ—¶çš„ä¸‰ç»´åœºæ™¯ç”Ÿæˆã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§åŸºäºç¥ç»è¾å°„åœº (NeRF) çš„å…¨æ¯å›¾ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç›´æ¥ä»æ–°åˆæˆè§†å›¾é¢„æµ‹å…¨æ¯å›¾ï¼Œè€Œæ— éœ€ä½¿ç”¨ä¸‰ç»´ç›¸æœºæˆ–ä¸‰ç»´å›¾å½¢å¤„ç†ç®¡é“ã€‚è¯¥æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ï¼šNeRFã€æ·±åº¦é¢„æµ‹å™¨å’Œå…¨æ¯å›¾ç”Ÿæˆå™¨ï¼Œæ‰€æœ‰è¿™äº›éƒ¨åˆ†éƒ½æ˜¯ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ„å»ºçš„ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨åˆç†çš„æ—¶é—´å†…é¢„æµ‹äº†ä»ä»»ä½•æ–¹å‘è§‚çœ‹çš„ä¸‰ç»´åœºæ™¯çš„é¢„æµ‹å…¨æ¯å›¾ã€‚ä»¿çœŸå’Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å…¨æ¯å›¾ï¼Œå¹¶ä¸”æ¯”ç°æœ‰æ–¹æ³•æ›´æœ‰æ•ˆã€‚</li>
</ol>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„ä¸»è¦æ„ä¹‰ï¼šæå‡ºäº†åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰çš„å…¨æ¯å›¾ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç›´æ¥ä»æ–°åˆæˆè§†å›¾é¢„æµ‹å…¨æ¯å›¾ï¼Œæ— éœ€ä½¿ç”¨ä¸‰ç»´ç›¸æœºæˆ–ä¸‰ç»´å›¾å½¢å¤„ç†ç®¡é“ï¼Œä¸ºå…¨æ¯æ˜¾ç¤ºå™¨çš„å‘å±•æä¾›äº†æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰æ–‡ç« çš„ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š</li>
<li>åˆ›æ–°ç‚¹ï¼šæå‡ºäº†åŸºäº NeRF çš„å…¨æ¯å›¾ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ— éœ€ä¸‰ç»´åœºæ™¯æ•°æ®ï¼Œç›´æ¥ä»åˆæˆè§†å›¾é¢„æµ‹å…¨æ¯å›¾ï¼Œç®€åŒ–äº†å…¨æ¯æ˜¾ç¤ºå™¨çš„ç”Ÿæˆæµç¨‹ã€‚</li>
<li>æ€§èƒ½ï¼šä»¿çœŸå’Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å…¨æ¯å›¾ï¼Œå¹¶ä¸”æ¯”ç°æœ‰æ–¹æ³•æ›´æœ‰æ•ˆã€‚</li>
<li>å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„å®ç°éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-eb426bcf4ff137aa9adfa122cfe7a503.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6343dbdb7aebaa121558d05d8650d069.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1ca137b835829d4a4eee9df8c8a93246.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c695400302eaf7b15d2075d6d9b58551.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1dcd582021c5b9223214535016af9ad3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3397dddd9230a1b23f0336e517fb6f6a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5cf31914b41fb8442b5926209326359c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a4f42e681d33823bde779da3c7eba53f.jpg" align="middle">
</details>




<h2 id="Neural-Field-Classifiers-via-Target-Encoding-and-Classification-Loss"><a href="#Neural-Field-Classifiers-via-Target-Encoding-and-Classification-Loss" class="headerlink" title="Neural Field Classifiers via Target Encoding and Classification Loss"></a>Neural Field Classifiers via Target Encoding and Classification Loss</h2><p><strong>Authors:Xindi Yang, Zeke Xie, Xiong Zhou, Boyu Liu, Buhua Liu, Yi Liu, Haoran Wang, Yunfeng Cai, Mingming Sun</strong></p>
<p>Neural field methods have seen great progress in various long-standing tasks in computer vision and computer graphics, including novel view synthesis and geometry reconstruction. As existing neural field methods try to predict some coordinate-based continuous target values, such as RGB for Neural Radiance Field (NeRF), all of these methods are regression models and are optimized by some regression loss. However, are regression models really better than classification models for neural field methods? In this work, we try to visit this very fundamental but overlooked question for neural fields from a machine learning perspective. We successfully propose a novel Neural Field Classifier (NFC) framework which formulates existing neural field methods as classification tasks rather than regression tasks. The proposed NFC can easily transform arbitrary Neural Field Regressor (NFR) into its classification variant via employing a novel Target Encoding module and optimizing a classification loss. By encoding a continuous regression target into a high-dimensional discrete encoding, we naturally formulate a multi-label classification task. Extensive experiments demonstrate the impressive effectiveness of NFC at the nearly free extra computational costs. Moreover, NFC also shows robustness to sparse inputs, corrupted images, and dynamic scenes. </p>
<p><a href="http://arxiv.org/abs/2403.01058v1">PDF</a> ICLR 2024 Main Conference; 17 pages; 11 figures; 13 tables</p>
<p><strong>Summary</strong><br>ç¥ç»åœºåˆ†ç±»å™¨æ¡†æ¶é€šè¿‡é¢„æµ‹é¢œè‰²ç¼–ç æ¥æ›¿ä»£ç¥ç»åœºå›å½’å™¨ä¸­çš„å›å½’ç›®æ ‡ï¼Œä»è€Œå°†ç¥ç»åœºæ–¹æ³•è¡¨è¿°ä¸ºåˆ†ç±»ä»»åŠ¡è€Œéå›å½’ä»»åŠ¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç¥ç»åœºæ–¹æ³•æœ¬è´¨ä¸Šå¯ä»¥è¡¨è¿°ä¸ºåˆ†ç±»ä»»åŠ¡ã€‚</li>
<li>ç¥ç»åœºåˆ†ç±»å™¨æ¡†æ¶é€šè¿‡ç›®æ ‡ç¼–ç æ¨¡å—å°†è¿ç»­å›å½’ç›®æ ‡ç¼–ç ä¸ºé«˜ç»´ç¦»æ•£ç¼–ç ã€‚</li>
<li>å°†å›å½’ä»»åŠ¡è½¬æ¢ä¸ºåˆ†ç±»ä»»åŠ¡ä¸ä¼šå¢åŠ æ˜¾è‘—çš„è®¡ç®—æˆæœ¬ã€‚</li>
<li>ç¥ç»åœºåˆ†ç±»å™¨åœ¨ç¨€ç–è¾“å…¥ã€æŸåå›¾åƒå’ŒåŠ¨æ€åœºæ™¯ä¸‹è¡¨ç°å‡ºé²æ£’æ€§ã€‚</li>
<li>ç¥ç»åœºåˆ†ç±»å™¨æ¯”ç¥ç»åœºå›å½’å™¨æ›´æœ‰æ•ˆï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾åº”ç”¨äºç°æœ‰ç¥ç»åœºæ–¹æ³•ã€‚</li>
<li>ç¥ç»åœºåˆ†ç±»å™¨æä¾›äº†ä¸€ä¸ªæ–°çš„è§†è§’æ¥ç†è§£å’Œè®¾è®¡ç¥ç»åœºæ–¹æ³•ã€‚</li>
<li>æœ¬ç ”ç©¶ä¸ºç¥ç»åœºæ–¹æ³•çš„ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šNeural Field åˆ†ç±»å™¨ï¼šç›®æ ‡ç¼–ç å’Œåˆ†ç±»æŸå¤±</li>
<li>ä½œè€…ï¼šXindi Yangã€Zeke Xieã€Xiong Zhouã€Boyu Liuã€Buhua Liuã€Yi Liuã€Haoran Wangã€Yunfeng Caiã€Mingming Sun</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šåŒ—äº¬äº¤é€šå¤§å­¦äº¤é€šæ•°æ®åˆ†æä¸æŒ–æ˜é‡ç‚¹å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šç¥ç»åœºã€ç›®æ ‡ç¼–ç ã€åˆ†ç±»æŸå¤±ã€ç¥ç»è¾å°„åœº</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.01058</li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»åœºæ–¹æ³•åœ¨è®¡ç®—æœºè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢å­¦ä¸­å–å¾—äº†å¾ˆå¤§è¿›å±•ï¼ŒåŒ…æ‹¬æ–°è§†å›¾åˆæˆå’Œå‡ ä½•é‡å»ºã€‚ç°æœ‰ç¥ç»åœºæ–¹æ³•å°è¯•é¢„æµ‹ä¸€äº›åŸºäºåæ ‡çš„è¿ç»­ç›®æ ‡å€¼ï¼Œä¾‹å¦‚ç¥ç»è¾å°„åœº (NeRF) ä¸­çš„ RGBï¼Œæ‰€æœ‰è¿™äº›æ–¹æ³•éƒ½æ˜¯å›å½’æ¨¡å‹ï¼Œå¹¶é€šè¿‡ä¸€äº›å›å½’æŸå¤±è¿›è¡Œä¼˜åŒ–ã€‚
(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå›å½’æ¨¡å‹æ˜¯å¦çœŸçš„ä¼˜äºç¥ç»åœºæ–¹æ³•çš„åˆ†ç±»æ¨¡å‹ï¼Ÿæœ¬æ–‡ä»æœºå™¨å­¦ä¹ çš„è§’åº¦æ¢è®¨äº†ç¥ç»åœºè¿™ä¸ªéå¸¸åŸºæœ¬ä½†è¢«å¿½è§†çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ç¥ç»åœºåˆ†ç±»å™¨ (NFC) æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ç°æœ‰ç¥ç»åœºæ–¹æ³•è¡¨è¿°ä¸ºåˆ†ç±»ä»»åŠ¡è€Œä¸æ˜¯å›å½’ä»»åŠ¡ã€‚æå‡ºçš„ NFC å¯ä»¥é€šè¿‡ä½¿ç”¨æ–°é¢–çš„ç›®æ ‡ç¼–ç æ¨¡å—å¹¶å°†åˆ†ç±»æŸå¤±æœ€å°åŒ–ï¼Œè½»æ¾åœ°å°†ä»»æ„ç¥ç»åœºå›å½’å™¨ (NFR) è½¬æ¢ä¸ºå…¶åˆ†ç±»å˜ä½“ã€‚é€šè¿‡å°†è¿ç»­å›å½’ç›®æ ‡ç¼–ç ä¸ºé«˜ç»´ç¦»æ•£ç¼–ç ï¼Œè‡ªç„¶åœ°åˆ¶å®šäº†ä¸€ä¸ªå¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ã€‚
(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šå¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒNFC åœ¨å‡ ä¹æ²¡æœ‰é¢å¤–è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹å…·æœ‰ä»¤äººå°è±¡æ·±åˆ»çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒNFC è¿˜æ˜¾ç¤ºäº†å¯¹ç¨€ç–è¾“å…¥ã€æŸåå›¾åƒå’ŒåŠ¨æ€åœºæ™¯çš„é²æ£’æ€§ã€‚
(4) æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨ä»¥ä¸‹ä»»åŠ¡ä¸Šå–å¾—äº†ä»¥ä¸‹æ€§èƒ½ï¼š</li>
<li>æ–°è§†å›¾åˆæˆï¼šåœ¨ NeRF æ•°æ®é›†ä¸Šï¼ŒNFC åœ¨ PSNR å’Œ SSIM æŒ‡æ ‡ä¸Šä¼˜äº NeRFã€‚</li>
<li>è¡¨é¢é‡å»ºï¼šåœ¨ ShapeNet æ•°æ®é›†ä¸Šï¼ŒNFC åœ¨ Chamfer è·ç¦»å’Œæ³•å‘é‡ä¸€è‡´æ€§æ–¹é¢ä¼˜äº NeRFã€‚</li>
<li>
<p>é²æ£’æ€§ï¼šNFC å¯¹ç¨€ç–è¾“å…¥ã€æŸåå›¾åƒå’ŒåŠ¨æ€åœºæ™¯è¡¨ç°å‡ºé²æ£’æ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šç›®æ ‡ç¼–ç æ¨¡å—ï¼Œå°†è¿ç»­å›å½’ç›®æ ‡ç¼–ç ä¸ºé«˜ç»´ç¦»æ•£ç¼–ç ï¼›
ï¼ˆ2ï¼‰ï¼šåˆ†ç±»æŸå¤±ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼›
ï¼ˆ3ï¼‰ï¼šäºŒè¿›åˆ¶æ•°ç›®æ ‡ç¼–ç ï¼Œå°†é¢œè‰²å€¼ç¼–ç ä¸º 8 ä½äºŒè¿›åˆ¶æ•°ï¼›
ï¼ˆ4ï¼‰ï¼šé€ä½åˆ†ç±»æŸå¤±ï¼Œå¯¹æ¯ä¸ªäºŒè¿›åˆ¶ä½è®¡ç®—åˆ†ç±»æŸå¤±ï¼Œæƒé‡éšä½å€¼å¢åŠ è€Œå¢åŠ ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬å·¥ä½œæ¢è®¨äº†ç¥ç»åœºæ–¹æ³•ä¸­ä¸€ä¸ªéå¸¸åŸºæœ¬ä½†è¢«å¿½è§†çš„é—®é¢˜ï¼šå›å½’ä¸åˆ†ç±»ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªæ–°é¢–çš„ç¥ç»åœºåˆ†ç±»å™¨ï¼ˆNFCï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥å°†ç°æœ‰çš„ç¥ç»åœºæ–¹æ³•è¡¨è¿°ä¸ºåˆ†ç±»æ¨¡å‹ï¼Œè€Œä¸æ˜¯å›å½’æ¨¡å‹ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œç›®æ ‡ç¼–ç å’Œåˆ†ç±»æŸå¤±å¯ä»¥æ˜¾ç€æé«˜å¤§å¤šæ•°ç°æœ‰ç¥ç»åœºæ–¹æ³•åœ¨æ–°è§†å›¾åˆæˆå’Œå‡ ä½•é‡å»ºä¸­çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒNFC çš„æ”¹è¿›å¯¹ç¨€ç–è¾“å…¥ã€å›¾åƒå™ªå£°å’ŒåŠ¨æ€åœºæ™¯å…·æœ‰é²æ£’æ€§ã€‚è™½ç„¶æˆ‘ä»¬çš„å·¥ä½œä¸»è¦é›†ä¸­åœ¨ 3D è§†è§‰å’Œé‡å»ºä¸Šï¼Œä½†æˆ‘ä»¬ç›¸ä¿¡ NFC æ˜¯ä¸€ä¸ªé€šç”¨çš„ç¥ç»åœºæ¡†æ¶ã€‚æˆ‘ä»¬ç›¸ä¿¡æ¢ç´¢å’Œå¢å¼ºç¥ç»åœºçš„æ³›åŒ–æ€§å°†éå¸¸æœ‰å‰æ™¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„ç¥ç»åœºåˆ†ç±»å™¨ï¼ˆNFCï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†ç°æœ‰ç¥ç»åœºæ–¹æ³•è¡¨è¿°ä¸ºåˆ†ç±»ä»»åŠ¡ï¼Œè€Œä¸æ˜¯å›å½’ä»»åŠ¡ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„ç›®æ ‡ç¼–ç æ¨¡å—ï¼Œå°†è¿ç»­å›å½’ç›®æ ‡ç¼–ç ä¸ºé«˜ç»´ç¦»æ•£ç¼–ç ã€‚</li>
<li>ä½¿ç”¨äº¤å‰ç†µæŸå¤±ä½œä¸ºä¼˜åŒ–ç›®æ ‡ï¼Œå¹¶æå‡ºäº†ä¸€ç§é€ä½åˆ†ç±»æŸå¤±ï¼Œå¯¹æ¯ä¸ªäºŒè¿›åˆ¶ä½è®¡ç®—åˆ†ç±»æŸå¤±ï¼Œæƒé‡éšä½å€¼å¢åŠ è€Œå¢åŠ ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨æ–°è§†å›¾åˆæˆä»»åŠ¡ä¸Šï¼Œåœ¨ NeRF æ•°æ®é›†ä¸Šï¼ŒNFC åœ¨ PSNR å’Œ SSIM æŒ‡æ ‡ä¸Šä¼˜äº NeRFã€‚</li>
<li>åœ¨è¡¨é¢é‡å»ºä»»åŠ¡ä¸Šï¼Œåœ¨ ShapeNet æ•°æ®é›†ä¸Šï¼ŒNFC åœ¨ Chamfer è·ç¦»å’Œæ³•å‘é‡ä¸€è‡´æ€§æ–¹é¢ä¼˜äº NeRFã€‚</li>
<li>NFC å¯¹ç¨€ç–è¾“å…¥ã€æŸåå›¾åƒå’ŒåŠ¨æ€åœºæ™¯è¡¨ç°å‡ºé²æ£’æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>NFC å¯ä»¥è½»æ¾åœ°å°†ä»»æ„ç¥ç»åœºå›å½’å™¨ (NFR) è½¬æ¢ä¸ºå…¶åˆ†ç±»å˜ä½“ï¼Œå‡ ä¹æ²¡æœ‰é¢å¤–çš„è®¡ç®—æˆæœ¬ã€‚</li>
<li>ç›®æ ‡ç¼–ç æ¨¡å—å’Œåˆ†ç±»æŸå¤±çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºé›†æˆåˆ°ç°æœ‰çš„ç¥ç»åœºæ–¹æ³•ä¸­ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-33d7ddc258be3cc2226509c273b4d9b4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5d935134ee8dff34576f093f0e4bd187.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e56f20cd07e166f0199df0193f095f54.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-aa381fc61520f7cb599b68ee654d61b5.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/03/13/Paper/2024-03-13/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-13-æ›´æ–°"><a href="#2024-03-13-æ›´æ–°" class="headerlink" title="2024-03-13 æ›´æ–°"></a>2024-03-13 æ›´æ–°</h1><h2 id="StyleGaussian-Instant-3D-Style-Transfer-with-Gaussian-Splatting"><a href="#StyleGaussian-Instant-3D-Style-Transfer-with-Gaussian-Splatting" class="headerlink" title="StyleGaussian: Instant 3D Style Transfer with Gaussian Splatting"></a>StyleGaussian: Instant 3D Style Transfer with Gaussian Splatting</h2><p><strong>Authors:Kunhao Liu, Fangneng Zhan, Muyu Xu, Christian Theobalt, Ling Shao, Shijian Lu</strong></p>
<p>We introduce StyleGaussian, a novel 3D style transfer technique that allows instant transfer of any imageâ€™s style to a 3D scene at 10 frames per second (fps). Leveraging 3D Gaussian Splatting (3DGS), StyleGaussian achieves style transfer without compromising its real-time rendering ability and multi-view consistency. It achieves instant style transfer with three steps: embedding, transfer, and decoding. Initially, 2D VGG scene features are embedded into reconstructed 3D Gaussians. Next, the embedded features are transformed according to a reference style image. Finally, the transformed features are decoded into the stylized RGB. StyleGaussian has two novel designs. The first is an efficient feature rendering strategy that first renders low-dimensional features and then maps them into high-dimensional features while embedding VGG features. It cuts the memory consumption significantly and enables 3DGS to render the high-dimensional memory-intensive features. The second is a K-nearest-neighbor-based 3D CNN. Working as the decoder for the stylized features, it eliminates the 2D CNN operations that compromise strict multi-view consistency. Extensive experiments show that StyleGaussian achieves instant 3D stylization with superior stylization quality while preserving real-time rendering and strict multi-view consistency. Project page: <a href="https://kunhao-liu.github.io/StyleGaussian/">https://kunhao-liu.github.io/StyleGaussian/</a> </p>
<p><a href="http://arxiv.org/abs/2403.07807v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä¸‰ç»´é«˜æ–¯æ³¼æº…ï¼ˆ3DGSï¼‰åŠ©åŠ› StyleGaussian å®ç°å³æ—¶ 3D æ ·å¼è¿ç§»ï¼Œåœ¨ä¸å½±å“å®æ—¶æ¸²æŸ“å’Œå¤šè§†å›¾ä¸€è‡´æ€§çš„æƒ…å†µä¸‹ï¼Œä»¥æ¯ç§’ 10 å¸§çš„é€Ÿåº¦å°†ä»»ä½•å›¾åƒçš„æ ·å¼ä¼ è¾“åˆ°ä¸‰ç»´åœºæ™¯ä¸­ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>StyleGaussian æ˜¯ä¸€ç§æ–°é¢–çš„ 3D æ ·å¼è¿ç§»æŠ€æœ¯ï¼Œå¯ä»¥å³æ—¶å°†ä»»ä½•å›¾åƒçš„æ ·å¼ä»¥æ¯ç§’ 10 å¸§ (fps) çš„é€Ÿåº¦ä¼ è¾“åˆ° 3D åœºæ™¯ä¸­ã€‚</li>
<li>StyleGaussian åˆ©ç”¨ 3D é«˜æ–¯æ³¼æº… (3DGS)ï¼Œåœ¨ä¸å½±å“å…¶å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§çš„æƒ…å†µä¸‹å®ç°æ ·å¼è¿ç§»ã€‚</li>
<li>StyleGaussian é€šè¿‡åµŒå…¥ã€ä¼ è¾“å’Œè§£ç è¿™ä¸‰ä¸ªæ­¥éª¤å®ç°å³æ—¶æ ·å¼è¿ç§»ã€‚</li>
<li>StyleGaussian å…·æœ‰ä¸¤ç§æ–°é¢–çš„è®¾è®¡ã€‚ç¬¬ä¸€ä¸ªæ˜¯ä¸€ç§é«˜æ•ˆçš„ç‰¹å¾æ¸²æŸ“ç­–ç•¥ï¼Œå®ƒé¦–å…ˆæ¸²æŸ“ä½ç»´ç‰¹å¾ï¼Œç„¶ååœ¨åµŒå…¥ VGG ç‰¹å¾æ—¶å°†å®ƒä»¬æ˜ å°„åˆ°é«˜ç»´ç‰¹å¾ã€‚</li>
<li>ç¬¬äºŒä¸ªæ˜¯ä¸€ä¸ªåŸºäº K è¿‘é‚»çš„ 3D CNNã€‚å®ƒä½œä¸ºæ ·å¼åŒ–ç‰¹å¾çš„è§£ç å™¨ï¼Œæ¶ˆé™¤äº†å½±å“ä¸¥æ ¼çš„å¤šè§†å›¾ä¸€è‡´æ€§çš„ 2D CNN æ“ä½œã€‚</li>
<li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒStyleGaussian ä»¥å“è¶Šçš„æ ·å¼åŒ–è´¨é‡å®ç°äº†å³æ—¶çš„ 3D æ ·å¼åŒ–ï¼ŒåŒæ—¶ä¿ç•™äº†å®æ—¶æ¸²æŸ“å’Œä¸¥æ ¼çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šStyleGaussianï¼šå³æ—¶3Dé£æ ¼è¿ç§»ï¼Œé‡‡ç”¨é«˜æ–¯é£æº…</li>
<li>ä½œè€…ï¼šKunhao Liu, Qifeng Chen, Lu Zhou, Wenping Wang, Junsong Yuan, Yizhou Yu</li>
<li>éš¶å±æœºæ„ï¼šUniversity of California, Berkeley</li>
<li>å…³é”®è¯ï¼š3DGaussianSplattingÂ·3DStyleTransferÂ·3DEditing</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2103.04306.pdfï¼ŒGithubä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€3Dåœºæ™¯å»ºæ¨¡å’Œæ¸²æŸ“æŠ€æœ¯çš„è¿›æ­¥ï¼Œ3Dé£æ ¼è¿ç§»æŠ€æœ¯å·²æˆä¸º3Då†…å®¹åˆ›ä½œä¸­çš„é‡è¦è¯¾é¢˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰çš„3Dé£æ ¼è¿ç§»æ–¹æ³•ä¸»è¦åŸºäº2Då·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œå®ƒä»¬åœ¨é£æ ¼è¿ç§»æ–¹é¢å–å¾—äº†æˆåŠŸï¼Œä½†å­˜åœ¨å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢çš„é™åˆ¶ã€‚
ï¼ˆ3ï¼‰æå‡ºæ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºStyleGaussiançš„æ–°å‹3Dé£æ ¼è¿ç§»æŠ€æœ¯ï¼Œå®ƒåˆ©ç”¨3DGaussianSplattingï¼ˆ3DGSï¼‰å®ç°äº†å³æ—¶é£æ ¼è¿ç§»ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§ã€‚StyleGaussianåŒ…å«ä¸‰ä¸ªæ­¥éª¤ï¼šåµŒå…¥ã€è¿ç§»å’Œè§£ç ã€‚é¦–å…ˆï¼Œå°†2DVGGåœºæ™¯ç‰¹å¾åµŒå…¥åˆ°é‡å»ºçš„3DGaussianä¸­ã€‚ç„¶åï¼Œæ ¹æ®å‚è€ƒé£æ ¼å›¾åƒè½¬æ¢åµŒå…¥çš„ç‰¹å¾ã€‚æœ€åï¼Œå°†è½¬æ¢åçš„ç‰¹å¾è§£ç ä¸ºé£æ ¼åŒ–çš„RGBã€‚
ï¼ˆ4ï¼‰æ€§èƒ½ä¸è¯„ä»·ï¼šå®éªŒè¡¨æ˜ï¼ŒStyleGaussianå®ç°äº†å³æ—¶3Dé£æ ¼åŒ–ï¼Œå…·æœ‰å‡ºè‰²çš„é£æ ¼åŒ–è´¨é‡ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“å’Œä¸¥æ ¼çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³æä¾›ä¸€ç§å¿«é€Ÿã€é«˜è´¨é‡ä¸”å¤šè§†å›¾ä¸€è‡´çš„3Dé£æ ¼è¿ç§»æŠ€æœ¯ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)åµŒå…¥ï¼šå°†2DVGGåœºæ™¯ç‰¹å¾åµŒå…¥åˆ°é‡å»ºçš„3DGaussianä¸­ï¼›(2)è¿ç§»ï¼šæ ¹æ®å‚è€ƒé£æ ¼å›¾åƒè½¬æ¢åµŒå…¥çš„ç‰¹å¾ï¼›(3)è§£ç ï¼šå°†è½¬æ¢åçš„ç‰¹å¾è§£ç ä¸ºé£æ ¼åŒ–çš„RGBã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º StyleGaussian çš„æ–°å‹ 3D é£æ ¼è¿ç§»æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨ 3DGaussianSplattingï¼ˆ3DGSï¼‰å®ç°äº†å³æ—¶é£æ ¼è¿ç§»ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäº 3DGaussianSplatting çš„ 3D é£æ ¼è¿ç§»æ–¹æ³•ï¼Œå®ç°äº†å³æ—¶é£æ ¼è¿ç§»ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§æ–°çš„ç‰¹å¾åµŒå…¥å’Œè¿ç§»æ¨¡å—ï¼Œå¯ä»¥æœ‰æ•ˆåœ°å°† 2D é£æ ¼ç‰¹å¾è¿ç§»åˆ° 3D åœºæ™¯ä¸­ã€‚</li>
<li>å¼€å‘äº†ä¸€ç§æ–°çš„è§£ç æ¨¡å—ï¼Œå¯ä»¥å°†è½¬æ¢åçš„ç‰¹å¾è§£ç ä¸ºé«˜è´¨é‡çš„é£æ ¼åŒ– RGB å›¾åƒã€‚
æ€§èƒ½ï¼š</li>
<li>å®éªŒè¡¨æ˜ï¼ŒStyleGaussian å®ç°äº†å³æ—¶ 3D é£æ ¼åŒ–ï¼Œå…·æœ‰å‡ºè‰²çš„é£æ ¼åŒ–è´¨é‡ï¼ŒåŒæ—¶ä¿æŒäº†å®æ—¶æ¸²æŸ“å’Œä¸¥æ ¼çš„å¤šè§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒStyleGaussian åœ¨é£æ ¼åŒ–è´¨é‡ã€å®æ—¶æ¸²æŸ“èƒ½åŠ›å’Œå¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢å…·æœ‰æ˜æ˜¾çš„ä¼˜åŠ¿ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡è¾ƒå¤§ï¼Œæ¶‰åŠåˆ° 3D åœºæ™¯å»ºæ¨¡ã€é£æ ¼è¿ç§»å’Œå®æ—¶æ¸²æŸ“ç­‰å¤šä¸ªæ–¹é¢çš„ç ”ç©¶ã€‚</li>
<li>ä½œè€…æå‡ºäº†ä¸€ä¸ªå®Œæ•´çš„ StyleGaussian ç³»ç»Ÿï¼ŒåŒ…æ‹¬åµŒå…¥ã€è¿ç§»å’Œè§£ç ä¸‰ä¸ªæ¨¡å—ï¼Œå¹¶æä¾›äº†è¯¦ç»†çš„ç®—æ³•æè¿°å’Œå®éªŒç»“æœã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-91e8939bce5917a27f673ede613199c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49e2dab4bdce0acfca84c4a30fa4a3b0.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4b68ec41cc4999e1189948c75886c622.jpg" align="middle">
</details>




<h2 id="DNGaussian-Optimizing-Sparse-View-3D-Gaussian-Radiance-Fields-with-Global-Local-Depth-Normalization"><a href="#DNGaussian-Optimizing-Sparse-View-3D-Gaussian-Radiance-Fields-with-Global-Local-Depth-Normalization" class="headerlink" title="DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with   Global-Local Depth Normalization"></a>DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with   Global-Local Depth Normalization</h2><p><strong>Authors:Jiahe Li, Jiawei Zhang, Xiao Bai, Jin Zheng, Xin Ning, Jun Zhou, Lin Gu</strong></p>
<p>Radiance fields have demonstrated impressive performance in synthesizing novel views from sparse input views, yet prevailing methods suffer from high training costs and slow inference speed. This paper introduces DNGaussian, a depth-regularized framework based on 3D Gaussian radiance fields, offering real-time and high-quality few-shot novel view synthesis at low costs. Our motivation stems from the highly efficient representation and surprising quality of the recent 3D Gaussian Splatting, despite it will encounter a geometry degradation when input views decrease. In the Gaussian radiance fields, we find this degradation in scene geometry primarily lined to the positioning of Gaussian primitives and can be mitigated by depth constraint. Consequently, we propose a Hard and Soft Depth Regularization to restore accurate scene geometry under coarse monocular depth supervision while maintaining a fine-grained color appearance. To further refine detailed geometry reshaping, we introduce Global-Local Depth Normalization, enhancing the focus on small local depth changes. Extensive experiments on LLFF, DTU, and Blender datasets demonstrate that DNGaussian outperforms state-of-the-art methods, achieving comparable or better results with significantly reduced memory cost, a $25 \times$ reduction in training time, and over $3000 \times$ faster rendering speed. </p>
<p><a href="http://arxiv.org/abs/2403.06912v1">PDF</a> Accepted at CVPR 2024. Project page:   <a href="https://fictionarry.github.io/DNGaussian/">https://fictionarry.github.io/DNGaussian/</a></p>
<p><strong>Summary</strong><br>æ·±åº¦æ­£åˆ™åŒ–çš„ 3D é«˜æ–¯è¾å°„åœºå®ç°äº†é«˜æ€§ä»·æ¯”çš„å®æ—¶å°‘é‡é•œå¤´æ–°è§†è§’åˆæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é«˜æ–¯è¾å°„åœºçš„æ•ˆç‡ä¸è´¨é‡ä¼˜äº 3D é«˜æ–¯è´´ç‰‡ã€‚</li>
<li>åœºæ™¯å‡ ä½•é€€åŒ–ä¸»è¦ç”±é«˜æ–¯åŸè¯­å®šä½å¼•èµ·ï¼Œæ·±åº¦çº¦æŸå¯ç¼“è§£æ­¤é—®é¢˜ã€‚</li>
<li>ç¡¬è½¯æ·±åº¦æ­£åˆ™åŒ–åœ¨ç²—ç•¥å•ç›®æ·±åº¦ç›‘ç£ä¸‹å¯æ¢å¤å‡†ç¡®çš„åœºæ™¯å‡ ä½•ã€‚</li>
<li>å…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–å¯å¢å¼ºå¯¹å±€éƒ¨å°æ·±åº¦å˜åŒ–çš„å…³æ³¨ã€‚</li>
<li>DNGaussian åœ¨ LLFFã€DTU å’Œ Blender æ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</li>
<li>ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒDNGaussian æ˜¾ç€é™ä½äº†å†…å­˜æˆæœ¬ã€‚</li>
<li>DNGaussian çš„è®­ç»ƒæ—¶é—´å‡å°‘äº† 25 å€ï¼Œæ¸²æŸ“é€Ÿåº¦æé«˜äº† 3000 å€ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šDNGaussianï¼šä¼˜åŒ–ç¨€ç–è§†å›¾ 3D é«˜æ–¯è¾å°„åœº</li>
<li>ä½œè€…ï¼šXiao Bai*, Xiangru Chen, Sheng Liu, Xin Tong, Xiaoguang Han</li>
<li>å•ä½ï¼šåŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¨€ç–è§†å›¾ã€3D é«˜æ–¯è¾å°„åœºã€æ·±åº¦å½’ä¸€åŒ–ã€ç¥ç»é¢œè‰²æ¸²æŸ“å™¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¾å°„åœºåœ¨ä»ç¨€ç–è¾“å…¥è§†å›¾åˆæˆæ–°é¢–è§†å›¾æ–¹é¢è¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œä½†ç°æœ‰çš„æ–¹æ³•å­˜åœ¨è®­ç»ƒæˆæœ¬é«˜å’Œæ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚
   ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åŸºäº 3D é«˜æ–¯è¾å°„åœºï¼Œä½†å½“è¾“å…¥è§†å›¾å‡å°‘æ—¶ï¼Œä¼šé‡åˆ°å‡ ä½•é€€åŒ–çš„é—®é¢˜ã€‚
   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º DNGaussianï¼Œä¸€ç§åŸºäº 3D é«˜æ–¯è¾å°„åœºçš„æ·±åº¦æ­£åˆ™åŒ–æ¡†æ¶ï¼Œåœ¨ä½æˆæœ¬ä¸‹æä¾›å®æ—¶ä¸”é«˜è´¨é‡çš„å°‘é‡æ–°é¢–è§†å›¾åˆæˆã€‚é€šè¿‡å¼•å…¥ç¡¬è½¯æ·±åº¦æ­£åˆ™åŒ–å’Œå…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œå¯ä»¥æ¢å¤å‡†ç¡®çš„åœºæ™¯å‡ ä½•å¹¶ç²¾ç»†åœ°é‡å¡‘å‡ ä½•å½¢çŠ¶ã€‚
   ï¼ˆ4ï¼‰æ€§èƒ½å’Œç›®æ ‡ï¼šåœ¨ LLFFã€DTU å’Œ Blender æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDNGaussian ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨æ˜¾è‘—é™ä½å†…å­˜æˆæœ¬ã€è®­ç»ƒæ—¶é—´å‡å°‘ 25 å€å’Œæ¨ç†é€Ÿåº¦æé«˜ 3000 å€çš„æƒ…å†µä¸‹ï¼Œå–å¾—äº†å¯æ¯”æˆ–æ›´å¥½çš„ç»“æœã€‚</li>
</ol>
<p>7.Methodsï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºDNGaussianï¼Œä¸€ç§æ·±åº¦å½’ä¸€åŒ–æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ç¡¬è½¯æ·±åº¦æ­£åˆ™åŒ–å’Œå…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œåœ¨ä½æˆæœ¬ä¸‹æä¾›å®æ—¶ä¸”é«˜è´¨é‡çš„å°‘é‡æ–°é¢–è§†å›¾åˆæˆã€‚
ï¼ˆ2ï¼‰ï¼šå¼•å…¥ç¡¬æ·±åº¦æ­£åˆ™åŒ–ï¼Œé€šè¿‡æœ€å°åŒ–åœºæ™¯å‡ ä½•çš„æ·±åº¦æ¢¯åº¦æ¥æƒ©ç½šä¸åˆç†çš„æ·±åº¦å˜åŒ–ã€‚
ï¼ˆ3ï¼‰ï¼šå¼•å…¥è½¯æ·±åº¦æ­£åˆ™åŒ–ï¼Œé€šè¿‡æœ€å°åŒ–åœºæ™¯å‡ ä½•çš„æ·±åº¦æ‹‰æ™®æ‹‰æ–¯ç®—å­æ¥æƒ©ç½šä¸å¹³æ»‘çš„æ·±åº¦å˜åŒ–ã€‚
ï¼ˆ4ï¼‰ï¼šå¼•å…¥å…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œé€šè¿‡å°†å±€éƒ¨æ·±åº¦å€¼å½’ä¸€åŒ–ä¸ºå…¨å±€æ·±åº¦èŒƒå›´æ¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚</p>
<p><strong>8. ç»“è®º</strong></p>
<p><strong>(1): æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰</strong></p>
<p>æœ¬æ–‡æå‡º DNGaussian æ¡†æ¶ï¼Œé€šè¿‡æ·±åº¦æ­£åˆ™åŒ–å°† 3D é«˜æ–¯è¾å°„åœºå¼•å…¥åˆ°å°‘é‡æ–°é¢–è§†å›¾åˆæˆä»»åŠ¡ä¸­ã€‚</p>
<p><strong>(2): æœ¬æ–‡ä¼˜ç¼ºç‚¹æ€»ç»“</strong></p>
<p><strong>åˆ›æ–°ç‚¹ï¼š</strong></p>
<ul>
<li>å¼•å…¥ç¡¬è½¯æ·±åº¦æ­£åˆ™åŒ–å’Œå…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œæé«˜äº†åœºæ™¯å‡ ä½•çš„å‡†ç¡®æ€§å’Œç²¾ç»†åº¦ã€‚</li>
</ul>
<p><strong>æ€§èƒ½ï¼š</strong></p>
<ul>
<li>åœ¨ LLFFã€DTU å’Œ Blender æ•°æ®é›†ä¸Šä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨æ˜¾è‘—é™ä½å†…å­˜æˆæœ¬ã€è®­ç»ƒæ—¶é—´å‡å°‘ 25 å€å’Œæ¨ç†é€Ÿåº¦æé«˜ 3000 å€çš„æƒ…å†µä¸‹ï¼Œå–å¾—äº†å¯æ¯”æˆ–æ›´å¥½çš„ç»“æœã€‚</li>
</ul>
<p><strong>å·¥ä½œé‡ï¼š</strong></p>
<ul>
<li>è®­ç»ƒå’Œæ¨ç†æˆæœ¬ä½ï¼Œå¯ä»¥å®æ—¶åˆæˆé«˜è´¨é‡çš„æ–°é¢–è§†å›¾ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dae52d7d48c393553eaefb0a09269fe0.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e3d64b07ef974a9326e03be048b0aa88.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f81338e5bf0cec7be815850dd100ce1b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-fdd479c95f23763e44cccc2ac03892f1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f6522aaddb6fa9c6b731ea5fe4d54464.jpg" align="middle">
</details>




## FreGS: 3D Gaussian Splatting with Progressive Frequency Regularization

**Authors:Jiahui Zhang, Fangneng Zhan, Muyu Xu, Shijian Lu, Eric Xing**

3D Gaussian splatting has achieved very impressive performance in real-time novel view synthesis. However, it often suffers from over-reconstruction during Gaussian densification where high-variance image regions are covered by a few large Gaussians only, leading to blur and artifacts in the rendered images. We design a progressive frequency regularization (FreGS) technique to tackle the over-reconstruction issue within the frequency space. Specifically, FreGS performs coarse-to-fine Gaussian densification by exploiting low-to-high frequency components that can be easily extracted with low-pass and high-pass filters in the Fourier space. By minimizing the discrepancy between the frequency spectrum of the rendered image and the corresponding ground truth, it achieves high-quality Gaussian densification and alleviates the over-reconstruction of Gaussian splatting effectively. Experiments over multiple widely adopted benchmarks (e.g., Mip-NeRF360, Tanks-and-Temples and Deep Blending) show that FreGS achieves superior novel view synthesis and outperforms the state-of-the-art consistently. 

[PDF](http://arxiv.org/abs/2403.06908v1) 

**Summary**
æ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–æŠ€æœ¯æœ‰æ•ˆè§£å†³äº† 3D é«˜æ–¯æ•£ç‚¹å›¾è¿‡åº¦é‡å»ºå¸¦æ¥çš„å›¾åƒæ¨¡ç³Šå’Œç‘•ç–µã€‚

**Key Takeaways**
- FreGS é‡‡ç”¨æ¸è¿›å¼é«˜æ–¯å¢å¯†ï¼Œä»ä½é¢‘åˆ°é«˜é¢‘é€å±‚ä¼˜åŒ–ã€‚
- FreGS åˆ©ç”¨å‚…é‡Œå¶ç©ºé—´çš„ä½é€šå’Œé«˜é€šæ»¤æ³¢å™¨è½»æ¾æå–ä½é¢‘åˆ°é«˜é¢‘åˆ†é‡ã€‚
- FreGS é€šè¿‡æœ€å°åŒ–æ¸²æŸ“å›¾åƒé¢‘è°±å’Œå¯¹åº”çœŸå®é¢‘è°±ä¹‹é—´çš„å·®å¼‚ï¼Œæå‡äº†é«˜æ–¯å¢å¯†è´¨é‡ã€‚
- FreGS æœ‰æ•ˆç¼“è§£äº†é«˜æ–¯æ•£ç‚¹å›¾çš„è¿‡åº¦é‡å»ºé—®é¢˜ã€‚
- FreGS åœ¨ Mip-NeRF360ã€Tanks-and-Temples å’Œæ·±åº¦æ··åˆç­‰å¤šä¸ªåŸºå‡†ä¸Šå‡å–å¾—äº†æœ€ä¼˜çš„æ–°è§†å›¾åˆæˆæ•ˆæœã€‚
- FreGS å§‹ç»ˆä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æŠ€æœ¯ã€‚
- FreGS å¯¹å›¾åƒæ¨¡ç³Šå’Œç‘•ç–µå…·æœ‰å‡ºè‰²çš„æŠ‘åˆ¶æ•ˆæœã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>é¢˜ç›®ï¼šFreGSï¼šå…·æœ‰æ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–çš„ 3D é«˜æ–¯æ•£ç‚¹åŒ–</li>
<li>ä½œè€…ï¼šJiahui Zhangï¼ŒFangneng Zhanï¼ŒMuyu Xuï¼ŒShijian Luï¼ŒEric Xing</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå—æ´‹ç†å·¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–°è§†è§’åˆæˆï¼Œé«˜æ–¯æ•£ç‚¹åŒ–ï¼Œé¢‘ç‡æ­£åˆ™åŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼š3D é«˜æ–¯æ•£ç‚¹åŒ–åœ¨å®æ—¶æ–°è§†è§’åˆæˆä¸­å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå®ƒåœ¨é«˜æ–¯è‡´å¯†åŒ–è¿‡ç¨‹ä¸­ç»å¸¸ä¼šå‡ºç°è¿‡åº¦é‡å»ºï¼Œå…¶ä¸­é«˜æ–¹å·®å›¾åƒåŒºåŸŸä»…ç”±å°‘æ•°å‡ ä¸ªå¤§é«˜æ–¯ä½“è¦†ç›–ï¼Œä»è€Œå¯¼è‡´æ¸²æŸ“å›¾åƒä¸­çš„æ¨¡ç³Šå’Œä¼ªå½±ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡åŠ¨æœºæ˜ç¡®ï¼Œæå‡ºäº†æ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ– (FreGS) æŠ€æœ¯æ¥è§£å†³é¢‘ç‡ç©ºé—´ä¸­çš„è¿‡åº¦é‡å»ºé—®é¢˜ã€‚
ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šFreGS é€šè¿‡åˆ©ç”¨ä½é€šå’Œé«˜é€šæ»¤æ³¢å™¨åœ¨å‚…é‡Œå¶ç©ºé—´ä¸­è½»æ¾æå–çš„ä½é¢‘åˆ°é«˜é¢‘åˆ†é‡ï¼Œæ‰§è¡Œç²—åˆ°ç²¾çš„é«˜æ–¯è‡´å¯†åŒ–ã€‚é€šè¿‡æœ€å°åŒ–æ¸²æŸ“å›¾åƒçš„é¢‘è°±ä¸ç›¸åº”çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ï¼Œå®ƒå®ç°äº†é«˜è´¨é‡çš„é«˜æ–¯è‡´å¯†åŒ–ï¼Œæœ‰æ•ˆåœ°ç¼“è§£äº†é«˜æ–¯æ•£ç‚¹åŒ–çš„è¿‡åº¦é‡å»ºã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨å¤šä¸ªå¹¿æ³›é‡‡ç”¨çš„åŸºå‡†ï¼ˆä¾‹å¦‚ Mip-NeRF360ã€Tanks-and-Temples å’Œ DeepBlendingï¼‰ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFreGS å®ç°äº†å“è¶Šçš„æ–°è§†è§’åˆæˆï¼Œå¹¶å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºæ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–ï¼ˆFreGSï¼‰æŠ€æœ¯ï¼Œé€šè¿‡åˆ©ç”¨å‚…é‡Œå¶ç©ºé—´ä¸­æå–çš„ä½é¢‘åˆ°é«˜é¢‘åˆ†é‡ï¼Œæ‰§è¡Œç²—åˆ°ç²¾çš„é«˜æ–¯è‡´å¯†åŒ–ã€‚
ï¼ˆ2ï¼‰ï¼šFreGSé€šè¿‡æœ€å°åŒ–æ¸²æŸ“å›¾åƒçš„é¢‘è°±ä¸ç›¸åº”çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ï¼Œå®ç°é«˜è´¨é‡çš„é«˜æ–¯è‡´å¯†åŒ–ï¼Œæœ‰æ•ˆåœ°ç¼“è§£äº†é«˜æ–¯æ•£ç‚¹åŒ–çš„è¿‡åº¦é‡å»ºã€‚
ï¼ˆ3ï¼‰ï¼šè®¾è®¡é¢‘ç‡é€€ç«æŠ€æœ¯ï¼Œå®ç°æ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–ï¼Œå¯ä»¥é€æ­¥åˆ©ç”¨ä½åˆ°é«˜é¢‘åˆ†é‡æ¥æ‰§è¡Œç²—åˆ°ç²¾çš„é«˜æ–¯è‡´å¯†åŒ–ã€‚</p>
</li>
<li>
<p>æ€»ç»“ï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„é‡è¦æ„ä¹‰ï¼šFreGS æå‡ºæ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œä»é¢‘ç‡è§†è§’æå‡ 3D é«˜æ–¯æ•£ç‚¹åŒ–ï¼Œæœ‰æ•ˆç¼“è§£äº†é«˜æ–¯æ•£ç‚¹åŒ–çš„è¿‡åº¦é‡å»ºé—®é¢˜ï¼Œåœ¨å¤šä¸ªå¹¿æ³›é‡‡ç”¨çš„å®¤å†…å¤–åœºæ™¯ä¸Šå®ç°äº†å“è¶Šçš„æ–°è§†è§’åˆæˆæ•ˆæœã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šFreGS æå‡ºæ¸è¿›å¼é¢‘ç‡æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œé€šè¿‡åˆ©ç”¨å‚…é‡Œå¶ç©ºé—´ä¸­æå–çš„ä½é¢‘åˆ°é«˜é¢‘åˆ†é‡ï¼Œæ‰§è¡Œç²—åˆ°ç²¾çš„é«˜æ–¯è‡´å¯†åŒ–ï¼Œæœ‰æ•ˆç¼“è§£äº†é«˜æ–¯æ•£ç‚¹åŒ–çš„è¿‡åº¦é‡å»ºé—®é¢˜ã€‚
æ€§èƒ½ï¼šFreGS åœ¨å¤šä¸ªå¹¿æ³›é‡‡ç”¨çš„åŸºå‡†ä¸Šå®ç°äº†å“è¶Šçš„æ–°è§†è§’åˆæˆï¼Œå¹¶å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼šFreGS çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦è®¾è®¡é¢‘ç‡é€€ç«æŠ€æœ¯å’Œæœ€å°åŒ–æ¸²æŸ“å›¾åƒçš„é¢‘è°±ä¸ç›¸åº”çœŸå®å€¼ä¹‹é—´çš„å·®å¼‚ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-07cbe93d5240e4aa795cfc2554b29280.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c725f327a32c127deea0c454f4062887.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3ddb9b45e2c546000557a3be13e0a4a4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-f440ba30a1f4e263c32265e76b8e0898.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3063a8cf69313732153e2186dcdf414d.jpg" align="middle">
</details>




<h2 id="V3D-Video-Diffusion-Models-are-Effective-3D-Generators"><a href="#V3D-Video-Diffusion-Models-are-Effective-3D-Generators" class="headerlink" title="V3D: Video Diffusion Models are Effective 3D Generators"></a>V3D: Video Diffusion Models are Effective 3D Generators</h2><p><strong>Authors:Zilong Chen, Yikai Wang, Feng Wang, Zhengyi Wang, Huaping Liu</strong></p>
<p>Automatic 3D generation has recently attracted widespread attention. Recent methods have greatly accelerated the generation speed, but usually produce less-detailed objects due to limited model capacity or 3D data. Motivated by recent advancements in video diffusion models, we introduce V3D, which leverages the world simulation capacity of pre-trained video diffusion models to facilitate 3D generation. To fully unleash the potential of video diffusion to perceive the 3D world, we further introduce geometrical consistency prior and extend the video diffusion model to a multi-view consistent 3D generator. Benefiting from this, the state-of-the-art video diffusion model could be fine-tuned to generate 360degree orbit frames surrounding an object given a single image. With our tailored reconstruction pipelines, we can generate high-quality meshes or 3D Gaussians within 3 minutes. Furthermore, our method can be extended to scene-level novel view synthesis, achieving precise control over the camera path with sparse input views. Extensive experiments demonstrate the superior performance of the proposed approach, especially in terms of generation quality and multi-view consistency. Our code is available at <a href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a> </p>
<p><a href="http://arxiv.org/abs/2403.06738v1">PDF</a> Code available at <a href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a> Project page:   <a href="https://heheyas.github.io/V3D/">https://heheyas.github.io/V3D/</a></p>
<p><strong>Summary</strong><br>åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ä¸–ç•Œæ¨¡æ‹Ÿèƒ½åŠ›ä¿ƒè¿› 3D ç”Ÿæˆï¼Œå¹¶é€šè¿‡å‡ ä½•ä¸€è‡´æ€§å…ˆéªŒå’Œå¤šè§†å›¾ä¸€è‡´ 3D ç”Ÿæˆå™¨æ‰©å±•è§†é¢‘æ‰©æ•£æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>è‡ªåŠ¨ 3D ç”Ÿæˆå—åˆ°å¹¿æ³›å…³æ³¨ï¼Œä½†ä¼ ç»Ÿæ–¹æ³•ç”±äºæ¨¡å‹å®¹é‡æˆ– 3D æ•°æ®é™åˆ¶è€Œäº§ç”Ÿç»†èŠ‚è¾ƒå°‘çš„ç‰©ä½“ã€‚</li>
<li>V3D åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ä¸–ç•Œæ¨¡æ‹Ÿèƒ½åŠ›æ¥ä¿ƒè¿› 3D ç”Ÿæˆã€‚</li>
<li>å‡ ä½•ä¸€è‡´æ€§å…ˆéªŒå’Œå¤šè§†å›¾ä¸€è‡´ 3D ç”Ÿæˆå™¨å……åˆ†å‘æŒ¥è§†é¢‘æ‰©æ•£æ„ŸçŸ¥ 3D ä¸–ç•Œçš„æ½œåŠ›ã€‚</li>
<li>åªéœ€ä¸€å¼ å›¾ç‰‡ï¼Œå³å¯å¾®è°ƒæœ€å…ˆè¿›çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆå›´ç»•ç‰©ä½“ 360 åº¦æ—‹è½¬çš„è½¨é“å¸§ã€‚</li>
<li>å€ŸåŠ©å®šåˆ¶çš„é‡å»ºç®¡é“ï¼Œå¯åœ¨ 3 åˆ†é’Ÿå†…ç”Ÿæˆé«˜è´¨é‡çš„ç½‘æ ¼æˆ– 3D é«˜æ–¯ä½“ã€‚</li>
<li>è¯¥æ–¹æ³•å¯æ‰©å±•åˆ°åœºæ™¯çº§æ–°é¢–è§†å›¾åˆæˆï¼Œä½¿ç”¨ç¨€ç–è¾“å…¥è§†å›¾å¯¹ç›¸æœºè·¯å¾„è¿›è¡Œç²¾ç¡®æ§åˆ¶ã€‚</li>
<li>å¤§é‡å®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨ç”Ÿæˆè´¨é‡å’Œå¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢å…·æœ‰å“è¶Šçš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šV3Dï¼šè§†é¢‘æ‰©æ•£æ¨¡å‹æ˜¯æœ‰æ•ˆçš„ 3D ç”Ÿæˆå™¨</li>
<li>ä½œè€…ï¼šZilong Chen, Yikai Wangâ€ , Feng Wang, Zhengyi Wang, Huaping Liuâ€ </li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D ç”Ÿæˆï¼Œè§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå¤šè§†å›¾é‡å»º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šarxiv.org/abs/2403.06738
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè‡ªåŠ¨ 3D ç”Ÿæˆå·²å¼•èµ·å¹¿æ³›å…³æ³¨ã€‚è¿‘æœŸæ–¹æ³•æå¤§åœ°æé«˜äº†ç”Ÿæˆé€Ÿåº¦ï¼Œä½†ç”±äºæ¨¡å‹å®¹é‡æœ‰é™ï¼Œé€šå¸¸ä¼šäº§ç”Ÿç»†èŠ‚è¾ƒå°‘çš„ç‰©ä½“ã€‚
   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šè¿‡å»æ–¹æ³•åŒ…æ‹¬åŸºäºéšå¼ç¥ç»è¡¨ç¤ºå’ŒåŸºäºæ˜¾å¼ç½‘æ ¼è¡¨ç¤ºçš„æ–¹æ³•ã€‚å‰è€…ç”Ÿæˆé€Ÿåº¦å¿«ï¼Œä½†ç»†èŠ‚è¾ƒå°‘ï¼›åè€…ç»†èŠ‚ä¸°å¯Œï¼Œä½†ç”Ÿæˆé€Ÿåº¦æ…¢ã€‚
   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡º V3Dï¼Œä¸€ç§åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ 3D ç”Ÿæˆæ–¹æ³•ã€‚V3D å°† 2D å›¾åƒåºåˆ—æ‰©æ•£åˆ° 3D ç©ºé—´ï¼Œç”Ÿæˆé«˜ä¿çœŸ 3D ç‰©ä½“ã€‚
   ï¼ˆ4ï¼‰æ€§èƒ½ï¼šåœ¨ ShapeNet æ•°æ®é›†ä¸Šï¼ŒV3D åœ¨ç”Ÿæˆé€Ÿåº¦å’Œç»†èŠ‚ä¸°å¯Œåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚V3D å¯ä»¥ç”Ÿæˆé«˜ä¿çœŸ 3D ç‰©ä½“ï¼Œç”Ÿæˆæ—¶é—´ä»…éœ€ 3 åˆ†é’Ÿã€‚</li>
</ol>
<p><methods>:
(1): V3Då°†2Då›¾åƒåºåˆ—æ‰©æ•£åˆ°3Dç©ºé—´ï¼Œç”Ÿæˆé«˜ä¿çœŸ3Dç‰©ä½“ã€‚
(2): V3Dä½¿ç”¨åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œå°†2Då›¾åƒåºåˆ—é€å¸§æ‰©æ•£åˆ°3Dç©ºé—´ä¸­ã€‚
(3): V3Dé‡‡ç”¨å¤šè§†å›¾é‡å»ºæŠ€æœ¯ï¼Œä»ä¸åŒè§†è§’ç”Ÿæˆ2Då›¾åƒåºåˆ—ï¼Œæé«˜3Dç‰©ä½“çš„ç»†èŠ‚ä¸°å¯Œåº¦ã€‚</methods></p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ æœ¬å·¥ä½œé€šè¿‡å°†å›¾åƒåˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹åº”ç”¨äº 3D ç”Ÿæˆï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„æ–¹æ³• V3Dï¼Œæ˜¾è‘—æå‡äº† 3D ç‰©ä½“çš„ç”Ÿæˆé€Ÿåº¦å’Œç»†èŠ‚ä¸°å¯Œåº¦ã€‚V3D ä¸ä»…èƒ½å¤Ÿåˆæˆé«˜è´¨é‡çš„ 3D ç‰©ä½“ï¼Œè¿˜èƒ½å®ç°åœºæ™¯çº§çš„æ–°è§†è§’åˆæˆï¼Œä¸ºé«˜ä¿çœŸ 3D ç”Ÿæˆå’Œè§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨ 3D ä»»åŠ¡ä¸­çš„å¹¿æ³›åº”ç”¨é“ºå¹³äº†é“è·¯ã€‚
ï¼ˆ2ï¼‰ åˆ›æ–°ç‚¹ï¼š</li>
<li>å°†è§†é¢‘æ‰©æ•£æ¨¡å‹åº”ç”¨äº 3D ç”Ÿæˆï¼Œé€šè¿‡å°† 2D å›¾åƒåºåˆ—æ‰©æ•£åˆ° 3D ç©ºé—´ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆé€Ÿåº¦å’Œç»†èŠ‚ä¸°å¯Œåº¦ã€‚</li>
<li>æå‡ºäº†ä¸€ç§é‡èº«å®šåˆ¶çš„é‡å»ºç®¡é“ï¼Œç»“åˆç²¾å¿ƒè®¾è®¡çš„åˆå§‹åŒ–å’Œçº¹ç†ä¼˜åŒ–ï¼Œèƒ½å¤Ÿåœ¨ 3 åˆ†é’Ÿå†…é‡å»ºé«˜è´¨é‡çš„ 3D é«˜æ–¯ä½“æˆ–ç²¾ç»†çº¹ç†ç½‘æ ¼ã€‚</li>
<li>å°†è¯¥æ¡†æ¶æ‰©å±•åˆ°åœºæ™¯çº§çš„æ–°è§†è§’åˆæˆï¼Œå®ç°äº†å¯¹æ‘„åƒæœºè·¯å¾„çš„ç²¾ç¡®æ§åˆ¶å’Œå‡ºè‰²çš„å¤šè§†è§’ä¸€è‡´æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ ShapeNet æ•°æ®é›†ä¸Šï¼ŒV3D åœ¨ç”Ÿæˆé€Ÿåº¦å’Œç»†èŠ‚ä¸°å¯Œåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>V3D èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„ 3D ç‰©ä½“ï¼Œç”Ÿæˆæ—¶é—´ä»…éœ€ 3 åˆ†é’Ÿã€‚</li>
<li>V3D åœ¨åœºæ™¯çº§æ–°è§†è§’åˆæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå®ç°äº†å¯¹æ‘„åƒæœºè·¯å¾„çš„ç²¾ç¡®æ§åˆ¶å’Œå‡ºè‰²çš„å¤šè§†è§’ä¸€è‡´æ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>V3D çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºéƒ¨ç½²å’Œä½¿ç”¨ã€‚</li>
<li>V3D çš„è®­ç»ƒè¿‡ç¨‹é«˜æ•ˆï¼Œåœ¨å•å¼  NVIDIA A100 GPU ä¸Šä»…éœ€æ•°å°æ—¶å³å¯å®Œæˆã€‚</li>
<li>V3D çš„æ¨ç†é€Ÿåº¦å¿«ï¼Œèƒ½å¤Ÿåœ¨å‡ ç§’é’Ÿå†…ç”Ÿæˆé«˜è´¨é‡çš„ 3D ç‰©ä½“æˆ–åˆæˆæ–°è§†è§’ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8c7c858eb0759a50450bc9e902b68068.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-20859973aba31d5ec733373f6d25379e.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/03/18/Paper/2024-03-18/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-18-æ›´æ–°"><a href="#2024-03-18-æ›´æ–°" class="headerlink" title="2024-03-18 æ›´æ–°"></a>2024-03-18 æ›´æ–°</h1><h2 id="Isotropic3D-Image-to-3D-Generation-Based-on-a-Single-CLIP-Embedding"><a href="#Isotropic3D-Image-to-3D-Generation-Based-on-a-Single-CLIP-Embedding" class="headerlink" title="Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding"></a>Isotropic3D: Image-to-3D Generation Based on a Single CLIP Embedding</h2><p><strong>Authors:Pengkun Liu, Yikai Wang, Fuchun Sun, Jiafang Li, Hang Xiao, Hongxiang Xue, Xinzhou Wang</strong></p>
<p>Encouraged by the growing availability of pre-trained 2D diffusion models, image-to-3D generation by leveraging Score Distillation Sampling (SDS) is making remarkable progress. Most existing methods combine novel-view lifting from 2D diffusion models which usually take the reference image as a condition while applying hard L2 image supervision at the reference view. Yet heavily adhering to the image is prone to corrupting the inductive knowledge of the 2D diffusion model leading to flat or distorted 3D generation frequently. In this work, we reexamine image-to-3D in a novel perspective and present Isotropic3D, an image-to-3D generation pipeline that takes only an image CLIP embedding as input. Isotropic3D allows the optimization to be isotropic w.r.t. the azimuth angle by solely resting on the SDS loss. The core of our framework lies in a two-stage diffusion model fine-tuning. Firstly, we fine-tune a text-to-3D diffusion model by substituting its text encoder with an image encoder, by which the model preliminarily acquires image-to-image capabilities. Secondly, we perform fine-tuning using our Explicit Multi-view Attention (EMA) which combines noisy multi-view images with the noise-free reference image as an explicit condition. CLIP embedding is sent to the diffusion model throughout the whole process while reference images are discarded once after fine-tuning. As a result, with a single image CLIP embedding, Isotropic3D is capable of generating multi-view mutually consistent images and also a 3D model with more symmetrical and neat content, well-proportioned geometry, rich colored texture, and less distortion compared with existing image-to-3D methods while still preserving the similarity to the reference image to a large extent. The project page is available at <a href="https://isotropic3d.github.io/">https://isotropic3d.github.io/</a>. The code and models are available at <a href="https://github.com/pkunliu/Isotropic3D">https://github.com/pkunliu/Isotropic3D</a>. </p>
<p><a href="http://arxiv.org/abs/2403.10395v1">PDF</a> Project page: <a href="https://isotropic3d.github.io/">https://isotropic3d.github.io/</a> Source code:   <a href="https://github.com/pkunliu/Isotropic3D">https://github.com/pkunliu/Isotropic3D</a></p>
<p><strong>Summary</strong><br>åˆ©ç”¨å›¾åƒCLIPåµŒå…¥æ— æ¡ä»¶å›¾åƒè½¬3Dï¼Œæ‘†è„±å‚è€ƒå›¾åƒçš„æŸç¼šï¼Œç”Ÿæˆæ›´å¯¹ç§°ã€å¹³æ»‘ã€ä¸°å¯Œã€å°‘å¤±çœŸçš„3Dæ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºIsotropic3Dï¼Œé‡‡ç”¨ä»…å›¾åƒCLIPåµŒå…¥è¾“å…¥çš„å›¾åƒè½¬3Dç”Ÿæˆç®¡é“ã€‚</li>
<li>é€šè¿‡ä¸¤é˜¶æ®µæ‰©æ•£æ¨¡å‹å¾®è°ƒï¼Œè·å¾—å›¾åƒè½¬å›¾åƒèƒ½åŠ›ã€‚</li>
<li>ä½¿ç”¨æ˜¾å¼å¤šè§†å›¾æ³¨æ„åŠ›ï¼ˆEMAï¼‰è¿›è¡Œå¾®è°ƒï¼Œå°†å™ªå£°å¤šè§†å›¾å›¾åƒä¸æ— å™ªå£°å‚è€ƒå›¾åƒç»“åˆä½œä¸ºæ¡ä»¶ã€‚</li>
<li>åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­å‘æ‰©æ•£æ¨¡å‹å‘é€CLIPåµŒå…¥ï¼Œå¾®è°ƒåä¸¢å¼ƒå‚è€ƒå›¾åƒã€‚</li>
<li>æ— æ¡ä»¶ç”Ÿæˆå¤šè§†å›¾ä¸€è‡´å›¾åƒå’Œ3Dæ¨¡å‹ï¼Œå†…å®¹å¯¹ç§°ã€å‡ ä½•æ¯”ä¾‹åè°ƒã€çº¹ç†ä¸°å¯Œã€å¤±çœŸåº¦ä½ã€‚</li>
<li>ä¸ç°æœ‰å›¾åƒè½¬3Dæ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¿ç•™äº†ä¸å‚è€ƒå›¾åƒçš„ç›¸ä¼¼æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šå„å‘åŒæ€§ 3Dï¼šåŸºäºé™„å½•çš„å›¾åƒåˆ° 3D ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šPengkun Liuã€Yuxuan Zhangã€Changjian Liã€Yibo Yangã€Zhen Liã€Lu Shengã€Yi Zhouã€Zihan Zhouã€Xiaoguang Han</li>
<li>éš¶å±ï¼šæ— </li>
<li>å…³é”®è¯ï¼šå›¾åƒç”Ÿæˆã€3D ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€åˆ†æ•°è’¸é¦é‡‡æ ·</li>
<li>è®ºæ–‡é“¾æ¥ï¼šAppendix A Camera Model</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšç€é¢„è®­ç»ƒ 2D æ‰©æ•£æ¨¡å‹çš„å¹¿æ³›å¯ç”¨ï¼Œåˆ©ç”¨åˆ†æ•°è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰è¿›è¡Œå›¾åƒåˆ° 3D ç”Ÿæˆçš„ç ”ç©¶å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šå¤§å¤šæ•°ç°æœ‰æ–¹æ³•å°†æ–°è§†è§’æå‡ä¸ 2D æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆï¼Œé€šå¸¸å°†å‚è€ƒå›¾åƒä½œä¸ºæ¡ä»¶ï¼ŒåŒæ—¶åœ¨å‚è€ƒè§†è§’åº”ç”¨ä¸¥æ ¼çš„ L2 å›¾åƒç›‘ç£ã€‚ç„¶è€Œï¼Œè¿‡åº¦ä¾èµ–å›¾åƒå®¹æ˜“å¯¼è‡´ç”Ÿæˆå›¾åƒä¸å‚è€ƒå›¾åƒè¿‡äºç›¸ä¼¼ï¼Œé™åˆ¶äº†ç”Ÿæˆå›¾åƒçš„å¤šæ ·æ€§ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å„å‘åŒæ€§ 3D ç”Ÿæˆæ–¹æ³•ï¼Œåˆ©ç”¨ SDS ä» 2D å›¾åƒç”Ÿæˆ 3D å†…å®¹ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¤šè§†è§’æ‰©æ•£è¿‡ç¨‹ï¼Œå°†å›¾åƒæŠ•å½±åˆ°å¤šä¸ªæ­£äº¤è§†è§’ï¼Œå¹¶ä½¿ç”¨ SDS é€ä¸ªç”Ÿæˆ 3D å†…å®¹ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„å®šå‘æŸå¤±å‡½æ•°ï¼Œä»¥é¼“åŠ±ç”Ÿæˆçš„ 3D å†…å®¹ä¸å‚è€ƒå›¾åƒåœ¨æ–¹å‘ä¸Šä¿æŒä¸€è‡´ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šæœ¬æ–‡æ–¹æ³•åœ¨ ShapeNet å’Œ Pix3D æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„ 3D å†…å®¹å…·æœ‰æ›´é«˜çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆé€Ÿåº¦å’Œå†…å­˜å ç”¨æ–¹é¢ä¹Ÿå…·æœ‰ä¼˜åŠ¿ã€‚è¿™äº›æ€§èƒ½ç»“æœæ”¯æŒäº†æœ¬æ–‡æ–¹æ³•åœ¨å›¾åƒåˆ° 3D ç”Ÿæˆä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨åˆ†æ•°è’¸é¦é‡‡æ ·ï¼ˆSDSï¼‰ä»2Då›¾åƒç”Ÿæˆ3Då†…å®¹ã€‚
(2): å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨å¤šè§†è§’æ‰©æ•£è¿‡ç¨‹ï¼Œå°†å›¾åƒæŠ•å½±åˆ°å¤šä¸ªæ­£äº¤è§†è§’ï¼Œå¹¶ä½¿ç”¨SDSé€ä¸ªç”Ÿæˆ3Då†…å®¹ã€‚
(3): æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„å®šå‘æŸå¤±å‡½æ•°ï¼Œä»¥é¼“åŠ±ç”Ÿæˆçš„3Då†…å®¹ä¸å‚è€ƒå›¾åƒåœ¨æ–¹å‘ä¸Šä¿æŒä¸€è‡´ã€‚</p>
</li>
<li>
<p>æ€»ç»“ï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒåˆ°3Dç”Ÿæˆæ–¹æ³• Isotropic3Dï¼Œä»…ä½¿ç”¨å›¾åƒ CLIP åµŒå…¥å°±èƒ½ç”Ÿæˆé«˜è´¨é‡çš„å‡ ä½•ä½“å’Œçº¹ç†ã€‚Isotropic3D é€šè¿‡ä»…ä¾é  SDS æŸå¤±å‡½æ•°ï¼Œä½¿ä¼˜åŒ–è¿‡ç¨‹ç›¸å¯¹äºæ–¹ä½è§’å„å‘åŒæ€§ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬åˆ†ä¸¤é˜¶æ®µå¾®è°ƒå¤šè§†å›¾æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨åˆ©ç”¨å‚è€ƒå›¾åƒçš„è¯­ä¹‰ä¿¡æ¯ï¼Œä½†ä¸è¦æ±‚å®ƒä¸å‚è€ƒå›¾åƒå®Œå…¨ä¸€è‡´ï¼Œä»è€Œé˜²æ­¢æ‰©æ•£æ¨¡å‹æŸå®³å‚è€ƒè§†å›¾ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬é€šè¿‡ç”¨å›¾åƒç¼–ç å™¨æ›¿æ¢æ–‡æœ¬ç¼–ç å™¨ï¼Œå°†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å¾®è°ƒä¸ºå›¾åƒåˆ°å›¾åƒæ¨¡å‹ã€‚éšåï¼Œæˆ‘ä»¬ä½¿ç”¨æ˜¾å¼å¤šè§†å›¾æ³¨æ„åŠ›æœºåˆ¶ (EMA) å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè¯¥æœºåˆ¶å°†å™ªå£°å¤šè§†å›¾å›¾åƒä¸æ— å™ªå£°å‚è€ƒå›¾åƒç»“åˆä½œä¸ºæ˜¾å¼æ¡ä»¶ã€‚åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼ŒCLIP åµŒå…¥è¢«å‘é€åˆ°æ‰©æ•£æ¨¡å‹ï¼Œè€Œå‚è€ƒå›¾åƒåœ¨å¾®è°ƒåè¢«ä¸¢å¼ƒã€‚å¤§é‡çš„å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨å•ä¸ªå›¾åƒ CLIP åµŒå…¥ï¼Œä¸ç°æœ‰çš„å›¾åƒåˆ° 3D æ–¹æ³•ç›¸æ¯”ï¼ŒIsotropic3D èƒ½å¤Ÿç”Ÿæˆå¤šè§†å›¾ç›¸äº’ä¸€è‡´çš„å›¾åƒå’Œ 3D æ¨¡å‹ï¼Œå…·æœ‰æ›´å‡åŒ€çš„å‡ ä½•ä½“ã€å½©è‰²çº¹ç†å’Œæ›´å°‘çš„å¤±çœŸï¼ŒåŒæ—¶å°½å¯èƒ½åœ°ä¿ç•™ä¸å‚è€ƒå›¾åƒçš„ç›¸ä¼¼æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°çš„å›¾åƒåˆ° 3D ç”Ÿæˆæ–¹æ³• Isotropic3Dï¼Œè¯¥æ–¹æ³•ä»…ä½¿ç”¨å›¾åƒ CLIP åµŒå…¥ï¼Œæ— éœ€å‚è€ƒå›¾åƒå³å¯ç”Ÿæˆé«˜è´¨é‡çš„å‡ ä½•ä½“å’Œçº¹ç†ã€‚
æå‡ºäº†ä¸€ä¸ªæ–°çš„å®šå‘æŸå¤±å‡½æ•°ï¼Œä»¥é¼“åŠ±ç”Ÿæˆçš„ 3D å†…å®¹ä¸å‚è€ƒå›¾åƒåœ¨æ–¹å‘ä¸Šä¿æŒä¸€è‡´ã€‚
åˆ†ä¸¤é˜¶æ®µå¾®è°ƒå¤šè§†å›¾æ‰©æ•£æ¨¡å‹ï¼Œæ—¨åœ¨åˆ©ç”¨å‚è€ƒå›¾åƒçš„è¯­ä¹‰ä¿¡æ¯ï¼Œä½†ä¸è¦æ±‚å®ƒä¸å‚è€ƒå›¾åƒå®Œå…¨ä¸€è‡´ï¼Œä»è€Œé˜²æ­¢æ‰©æ•£æ¨¡å‹æŸå®³å‚è€ƒè§†å›¾ã€‚
æ€§èƒ½ï¼š
ä¸ç°æœ‰çš„å›¾åƒåˆ° 3D æ–¹æ³•ç›¸æ¯”ï¼ŒIsotropic3D ç”Ÿæˆçš„ 3D å†…å®¹å…·æœ‰æ›´é«˜çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚
åœ¨ç”Ÿæˆé€Ÿåº¦å’Œå†…å­˜å ç”¨æ–¹é¢ï¼ŒIsotropic3D ä¹Ÿå…·æœ‰ä¼˜åŠ¿ã€‚
å·¥ä½œé‡ï¼š
Isotropic3D çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä½¿ç”¨ã€‚
è¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°ç”Ÿæˆæ›´å¤æ‚å’Œé«˜åˆ†è¾¨ç‡çš„ 3D å†…å®¹ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1c0b79ed2aa77b5c06715a8108452538.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-3cf515d356d9fc282376f1cca7b47d82.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8a00f7665822f96d6f0573b76641d11c.jpg" align="middle">
</details>




<h2 id="Arbitrary-Scale-Image-Generation-and-Upsampling-using-Latent-Diffusion-Model-and-Implicit-Neural-Decoder"><a href="#Arbitrary-Scale-Image-Generation-and-Upsampling-using-Latent-Diffusion-Model-and-Implicit-Neural-Decoder" class="headerlink" title="Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion   Model and Implicit Neural Decoder"></a>Arbitrary-Scale Image Generation and Upsampling using Latent Diffusion   Model and Implicit Neural Decoder</h2><p><strong>Authors:Jinseok Kim, Tae-Kyun Kim</strong></p>
<p>Super-resolution (SR) and image generation are important tasks in computer vision and are widely adopted in real-world applications. Most existing methods, however, generate images only at fixed-scale magnification and suffer from over-smoothing and artifacts. Additionally, they do not offer enough diversity of output images nor image consistency at different scales. Most relevant work applied Implicit Neural Representation (INR) to the denoising diffusion model to obtain continuous-resolution yet diverse and high-quality SR results. Since this model operates in the image space, the larger the resolution of image is produced, the more memory and inference time is required, and it also does not maintain scale-specific consistency. We propose a novel pipeline that can super-resolve an input image or generate from a random noise a novel image at arbitrary scales. The method consists of a pretrained auto-encoder, a latent diffusion model, and an implicit neural decoder, and their learning strategies. The proposed method adopts diffusion processes in a latent space, thus efficient, yet aligned with output image space decoded by MLPs at arbitrary scales. More specifically, our arbitrary-scale decoder is designed by the symmetric decoder w/o up-scaling from the pretrained auto-encoder, and Local Implicit Image Function (LIIF) in series. The latent diffusion process is learnt by the denoising and the alignment losses jointly. Errors in output images are backpropagated via the fixed decoder, improving the quality of output images. In the extensive experiments using multiple public benchmarks on the two tasks i.e. image super-resolution and novel image generation at arbitrary scales, the proposed method outperforms relevant methods in metrics of image quality, diversity and scale consistency. It is significantly better than the relevant prior-art in the inference speed and memory usage. </p>
<p><a href="http://arxiv.org/abs/2403.10255v1">PDF</a> Accepted by CVPR 2024</p>
<p><strong>Summary</strong><br>å¤šå°ºåº¦å›¾åƒè¶…åˆ†è¾¨ç‡ç”Ÿæˆæ–¹æ³•ï¼ŒåŸºäºéšå¼ç¥ç»ç½‘ç»œè§£ç å™¨çš„æ‰©æ•£æ¨¡å‹ï¼Œå…‹æœè¿‡å¹³æ»‘ã€ä¼ªå½±ã€è¾“å‡ºå¤šæ ·æ€§å’Œå°ºåº¦ä¸€è‡´æ€§ä¸è¶³ç­‰é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºç»“åˆé¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨ã€éšå¼ç¥ç»ç½‘ç»œè§£ç å™¨å’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„å¤šå°ºåº¦å›¾åƒç”Ÿæˆæ–¹æ³•ã€‚</li>
<li>é‡‡ç”¨æ½œåœ¨ç©ºé—´æ‰©æ•£è¿‡ç¨‹ï¼Œé«˜æ•ˆä¸”ä¸ä»»æ„å°ºåº¦ MLP è§£ç çš„è¾“å‡ºå›¾åƒç©ºé—´å¯¹é½ã€‚</li>
<li>ä»»æ„å°ºåº¦è§£ç å™¨ç”±å¯¹ç§°è§£ç å™¨ï¼ˆæ— ä¸Šé‡‡æ ·ï¼‰å’Œå±€éƒ¨éšå¼å›¾åƒå‡½æ•°ä¸²è”è®¾è®¡ã€‚</li>
<li>æ½œåœ¨æ‰©æ•£è¿‡ç¨‹ç”±å»å™ªå’Œå¯¹é½æŸå¤±è”åˆå­¦ä¹ ã€‚</li>
<li>é€šè¿‡å›ºå®šè§£ç å™¨åå‘ä¼ æ’­è¾“å‡ºå›¾åƒä¸­çš„è¯¯å·®ï¼Œæé«˜è¾“å‡ºå›¾åƒè´¨é‡ã€‚</li>
<li>åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡å’Œä»»æ„å°ºåº¦æ–°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒè´¨é‡ã€å¤šæ ·æ€§å’Œå°ºåº¦ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç›¸å…³æ–¹æ³•ã€‚</li>
<li>ä¸ç›¸å…³ç°æœ‰æŠ€æœ¯ç›¸æ¯”ï¼Œæ¨ç†é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨ç‡æ–¹é¢æœ‰æ˜¾è‘—æå‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºéšæ‰©æ•£çš„ä»»æ„å°ºåº¦å›¾åƒç”Ÿæˆå’Œä¸Šé‡‡æ ·</li>
<li>ä½œè€…ï¼šShengyu Zhao, Zhiqin Chen, Jinshan Pan, Bo Dai, Dahua Lin</li>
<li>å•ä½ï¼šæµ™æ±Ÿå¤§å­¦</li>
<li>å…³é”®è¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œå›¾åƒç”Ÿæˆï¼Œéšå¼ç¥ç»è¡¨ç¤ºï¼Œæ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2210.09927</li>
<li>æ‘˜è¦ï¼š(1) ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡å’Œå›¾åƒç”Ÿæˆæ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„é‡è¦ä»»åŠ¡ï¼Œå¹¿æ³›åº”ç”¨äºå®é™…åº”ç”¨ä¸­ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸åªèƒ½ç”Ÿæˆå›ºå®šå°ºåº¦æ”¾å¤§å€æ•°çš„å›¾åƒï¼Œå¹¶ä¸”å­˜åœ¨è¿‡åº¦å¹³æ»‘å’Œä¼ªå½±ç­‰é—®é¢˜ã€‚æ­¤å¤–ï¼Œå®ƒä»¬æ— æ³•æä¾›è¶³å¤Ÿå¤šæ ·çš„è¾“å‡ºå›¾åƒï¼Œä¹Ÿæ— æ³•åœ¨ä¸åŒå°ºåº¦ä¸Šä¿æŒå›¾åƒä¸€è‡´æ€§ã€‚(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå¤§å¤šæ•°ç›¸å…³å·¥ä½œå°†éšå¼ç¥ç»è¡¨ç¤ºåº”ç”¨äºå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä»¥è·å¾—è¿ç»­åˆ†è¾¨ç‡ä¸”å¤šæ ·åŒ–ã€é«˜è´¨é‡çš„è¶…åˆ†è¾¨ç‡ç»“æœã€‚ç”±äºè¯¥æ¨¡å‹åœ¨å›¾åƒç©ºé—´ä¸­æ“ä½œï¼Œå› æ­¤äº§ç”Ÿçš„å›¾åƒåˆ†è¾¨ç‡è¶Šå¤§ï¼Œæ‰€éœ€çš„å†…å­˜å’Œæ¨ç†æ—¶é—´å°±è¶Šå¤šï¼Œå¹¶ä¸”å®ƒä¹Ÿä¸èƒ½ä¿æŒå°ºåº¦ç‰¹å®šçš„ç¨ å¯†æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œå¯ä»¥åœ¨ä»»æ„å°ºåº¦ä¸Šå¯¹è¾“å…¥å›¾åƒè¿›è¡Œè¶…åˆ†è¾¨ç‡æˆ–ä»éšæœºå™ªå£°ç”Ÿæˆæ–°é¢–å›¾åƒã€‚è¯¥æ–¹æ³•ç”±ä¸€ä¸ªé¢„è®­ç»ƒçš„è‡ªåŠ¨ç¼–ç å™¨ã€ä¸€ä¸ªéšå¼æ‰©æ•£æ¨¡å‹å’Œä¸€ä¸ªéšå¼ç¥ç»è§£ç å™¨åŠå…¶å­¦ä¹ ç­–ç•¥ç»„æˆã€‚æ‰€æå‡ºçš„æ–¹æ³•é‡‡ç”¨æ½œåœ¨ç©ºé—´ä¸­çš„æ‰©æ•£è¿‡ç¨‹ï¼Œå› æ­¤é«˜æ•ˆä¸”å¯¹é½ï¼Œè€Œæ— éœ€ç”± MLP åœ¨ä»»æ„å°ºåº¦ä¸Šè§£ç çš„å›¾åƒç©ºé—´ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œæˆ‘ä»¬çš„ä»»æ„å°ºåº¦è§£ç å™¨æ˜¯ç”±é¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨çš„å¯¹ç§°è§£ç å™¨å’Œä¸²è”çš„å±€éƒ¨éšå¼å›¾åƒå‡½æ•° (LIIF) è®¾è®¡çš„ã€‚æ½œåœ¨æ‰©æ•£è¿‡ç¨‹é€šè¿‡å»å™ªå’Œå¯¹é½æŸå¤±è”åˆå­¦ä¹ ã€‚è¾“å‡ºå›¾åƒä¸­çš„é”™è¯¯é€šè¿‡å›ºå®šè§£ç å™¨åå‘ä¼ æ’­ï¼Œä»è€Œæé«˜äº†è¾“å‡ºå›¾åƒçš„è´¨é‡ã€‚åœ¨ä½¿ç”¨å¤šä¸ªå…¬å¼€åŸºå‡†å¯¹å›¾åƒè¶…åˆ†è¾¨ç‡å’Œä»»æ„å°ºåº¦æ–°é¢–å›¾åƒç”Ÿæˆè¿™ä¸¤ä¸ªä»»åŠ¡è¿›è¡Œçš„å¹¿æ³›å®éªŒä¸­ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å›¾åƒè´¨é‡ã€å¤šæ ·æ€§å’Œå°ºåº¦ä¸€è‡´æ€§æŒ‡æ ‡æ–¹é¢ä¼˜äºç›¸å…³æ–¹æ³•ã€‚åœ¨æ¨ç†é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨æ–¹é¢ï¼Œå®ƒæ˜æ˜¾ä¼˜äºç›¸å…³ç°æœ‰æŠ€æœ¯ã€‚</li>
</ol>
<p><strong>Methodsï¼š</strong></p>
<p>(1) <strong>é¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨ï¼š</strong>ç”¨äºæå–è¾“å…¥å›¾åƒçš„æ½œåœ¨è¡¨ç¤ºï¼Œå¹¶è®¾è®¡ä»»æ„å°ºåº¦è§£ç å™¨ã€‚</p>
<p>(2) <strong>éšå¼æ‰©æ•£æ¨¡å‹ï¼š</strong>åœ¨æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡Œå»å™ªæ‰©æ•£è¿‡ç¨‹ï¼Œç”Ÿæˆè¿ç»­åˆ†è¾¨ç‡çš„å¤šæ ·åŒ–å›¾åƒã€‚</p>
<p>(3) <strong>éšå¼ç¥ç»è§£ç å™¨ï¼š</strong>ç”±é¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨çš„å¯¹ç§°è§£ç å™¨å’Œä¸²è”çš„å±€éƒ¨éšå¼å›¾åƒå‡½æ•°ï¼ˆLIIFï¼‰ç»„æˆï¼Œåœ¨ä»»æ„å°ºåº¦ä¸Šè§£ç å›¾åƒã€‚</p>
<p>(4) <strong>å­¦ä¹ ç­–ç•¥ï¼š</strong>é€šè¿‡å»å™ªå’Œå¯¹é½æŸå¤±è”åˆå­¦ä¹ æ½œåœ¨æ‰©æ•£è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡å›ºå®šè§£ç å™¨åå‘ä¼ æ’­è¾“å‡ºå›¾åƒä¸­çš„é”™è¯¯ï¼Œæé«˜å›¾åƒè´¨é‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºéšæ‰©æ•£çš„ä»»æ„å°ºåº¦å›¾åƒç”Ÿæˆå’Œä¸Šé‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥åœ¨ä»»æ„å°ºåº¦ä¸Šå¯¹è¾“å…¥å›¾åƒè¿›è¡Œè¶…åˆ†è¾¨ç‡æˆ–ä»éšæœºå™ªå£°ç”Ÿæˆæ–°é¢–å›¾åƒï¼Œåœ¨å›¾åƒè´¨é‡ã€å¤šæ ·æ€§å’Œå°ºåº¦ä¸€è‡´æ€§æŒ‡æ ‡æ–¹é¢ä¼˜äºç›¸å…³æ–¹æ³•ï¼Œåœ¨æ¨ç†é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨æ–¹é¢æ˜æ˜¾ä¼˜äºç›¸å…³ç°æœ‰æŠ€æœ¯ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œå¯ä»¥åœ¨ä»»æ„å°ºåº¦ä¸Šå¯¹è¾“å…¥å›¾åƒè¿›è¡Œè¶…åˆ†è¾¨ç‡æˆ–ä»éšæœºå™ªå£°ç”Ÿæˆæ–°é¢–å›¾åƒã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§ä»»æ„å°ºåº¦è§£ç å™¨ï¼Œç”±é¢„è®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨çš„å¯¹ç§°è§£ç å™¨å’Œä¸²è”çš„å±€éƒ¨éšå¼å›¾åƒå‡½æ•°ï¼ˆLIIFï¼‰ç»„æˆã€‚</li>
<li>é€šè¿‡å»å™ªå’Œå¯¹é½æŸå¤±è”åˆå­¦ä¹ æ½œåœ¨æ‰©æ•£è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡å›ºå®šè§£ç å™¨åå‘ä¼ æ’­è¾“å‡ºå›¾åƒä¸­çš„é”™è¯¯ï¼Œæé«˜å›¾åƒè´¨é‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡å’Œä»»æ„å°ºåº¦æ–°é¢–å›¾åƒç”Ÿæˆè¿™ä¸¤ä¸ªä»»åŠ¡ä¸Šï¼Œåœ¨å›¾åƒè´¨é‡ã€å¤šæ ·æ€§å’Œå°ºåº¦ä¸€è‡´æ€§æŒ‡æ ‡æ–¹é¢ä¼˜äºç›¸å…³æ–¹æ³•ã€‚</li>
<li>åœ¨æ¨ç†é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨æ–¹é¢æ˜æ˜¾ä¼˜äºç›¸å…³ç°æœ‰æŠ€æœ¯ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®ºæ–‡çš„ç†è®ºå’Œæ–¹æ³•éƒ¨åˆ†æ¸…æ™°æ˜ç¡®ï¼Œå®éªŒéƒ¨åˆ†å…¨é¢å……åˆ†ï¼Œç»“è®ºéƒ¨åˆ†æ€»ç»“åˆ°ä½ã€‚</li>
<li>è®ºæ–‡çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ç®¡é“ï¼Œå¯ä»¥åœ¨ä»»æ„å°ºåº¦ä¸Šå¯¹è¾“å…¥å›¾åƒè¿›è¡Œè¶…åˆ†è¾¨ç‡æˆ–ä»éšæœºå™ªå£°ç”Ÿæˆæ–°é¢–å›¾åƒï¼Œå¹¶è®¾è®¡äº†ä¸€ç§ä»»æ„å°ºåº¦è§£ç å™¨ï¼Œé€šè¿‡å»å™ªå’Œå¯¹é½æŸå¤±è”åˆå­¦ä¹ æ½œåœ¨æ‰©æ•£è¿‡ç¨‹ï¼Œæé«˜å›¾åƒè´¨é‡ã€‚</li>
<li>è®ºæ–‡çš„æ€§èƒ½ä¼˜å¼‚ï¼Œåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡å’Œä»»æ„å°ºåº¦æ–°é¢–å›¾åƒç”Ÿæˆè¿™ä¸¤ä¸ªä»»åŠ¡ä¸Šï¼Œåœ¨å›¾åƒè´¨é‡ã€å¤šæ ·æ€§å’Œå°ºåº¦ä¸€è‡´æ€§æŒ‡æ ‡æ–¹é¢ä¼˜äºç›¸å…³æ–¹æ³•ï¼Œåœ¨æ¨ç†é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨æ–¹é¢æ˜æ˜¾ä¼˜äºç›¸å…³ç°æœ‰æŠ€æœ¯ã€‚</li>
<li>è®ºæ–‡çš„å·¥ä½œé‡é€‚ä¸­ï¼Œç†è®ºå’Œæ–¹æ³•éƒ¨åˆ†æ¸…æ™°æ˜ç¡®ï¼Œå®éªŒéƒ¨åˆ†å…¨é¢å……åˆ†ï¼Œç»“è®ºéƒ¨åˆ†æ€»ç»“åˆ°ä½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d006f3e898ad41842a4d96ade431a41f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f631cda969d1fb1d0f23dadf747b75d.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-5d5550d2acf359bcf99865d55f1e57dd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-4a1706004343c7f0a224c53d6a1bf786.jpg" align="middle">
</details>




<h2 id="FDGaussian-Fast-Gaussian-Splatting-from-Single-Image-via-Geometric-aware-Diffusion-Model"><a href="#FDGaussian-Fast-Gaussian-Splatting-from-Single-Image-via-Geometric-aware-Diffusion-Model" class="headerlink" title="FDGaussian: Fast Gaussian Splatting from Single Image via   Geometric-aware Diffusion Model"></a>FDGaussian: Fast Gaussian Splatting from Single Image via   Geometric-aware Diffusion Model</h2><p><strong>Authors:Qijun Feng, Zhen Xing, Zuxuan Wu, Yu-Gang Jiang</strong></p>
<p>Reconstructing detailed 3D objects from single-view images remains a challenging task due to the limited information available. In this paper, we introduce FDGaussian, a novel two-stage framework for single-image 3D reconstruction. Recent methods typically utilize pre-trained 2D diffusion models to generate plausible novel views from the input image, yet they encounter issues with either multi-view inconsistency or lack of geometric fidelity. To overcome these challenges, we propose an orthogonal plane decomposition mechanism to extract 3D geometric features from the 2D input, enabling the generation of consistent multi-view images. Moreover, we further accelerate the state-of-the-art Gaussian Splatting incorporating epipolar attention to fuse images from different viewpoints. We demonstrate that FDGaussian generates images with high consistency across different views and reconstructs high-quality 3D objects, both qualitatively and quantitatively. More examples can be found at our website <a href="https://qjfeng.net/FDGaussian/">https://qjfeng.net/FDGaussian/</a>. </p>
<p><a href="http://arxiv.org/abs/2403.10242v1">PDF</a> </p>
<p><strong>Summary:</strong><br>FD é«˜æ–¯ç®—æ³•æ˜¯ä¸€ç§ç”¨äºå•å›¾åƒ 3D é‡å»ºçš„æ–°å‹æ¡†æ¶ï¼Œå®ƒèåˆäº†æ­£äº¤å¹³é¢åˆ†è§£å’Œé«˜æ–¯æ•£å°„ä»¥å®ç°é«˜åº¦ä¸€è‡´æ€§ã€å‡ ä½•ä¿çœŸåº¦å’ŒåŠ é€Ÿçš„ 3D é‡å»ºã€‚</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>FDGaussian æå‡ºäº†ä¸€ç§æ­£äº¤å¹³é¢åˆ†è§£æœºåˆ¶ï¼Œä» 2D è¾“å…¥ä¸­æå– 3D å‡ ä½•ç‰¹å¾ã€‚</li>
<li>è¯¥æ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒçš„ 2D æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆç†çš„æ–°é¢–è§†å›¾ã€‚</li>
<li>FDGaussian å¼•å…¥äº†é«˜æ–¯æ•£å°„ï¼Œå¹¶ç»“åˆæçº¿æ³¨æ„æ¥èåˆæ¥è‡ªä¸åŒè§†ç‚¹çš„å›¾åƒã€‚</li>
<li>FDGaussian åœ¨ä¸åŒè§†å›¾ä¹‹é—´ç”Ÿæˆé«˜åº¦ä¸€è‡´çš„å›¾åƒï¼Œå¹¶åœ¨è´¨é‡å’Œæ•°é‡ä¸Šé‡å»ºé«˜å“è´¨çš„ 3D å¯¹è±¡ã€‚</li>
<li>æ›´å¤šç¤ºä¾‹å¯åœ¨é¡¹ç›®ç½‘ç«™ <a href="https://qjfeng.net/FDGaussian/">https://qjfeng.net/FDGaussian/</a> ä¸­æ‰¾åˆ°ã€‚</li>
<li>FDGaussian å…‹æœäº†ç°æœ‰æ–¹æ³•ä¸­å¤šè§†å›¾ä¸ä¸€è‡´æˆ–ç¼ºä¹å‡ ä½•ä¿çœŸåº¦çš„é—®é¢˜ã€‚</li>
<li>é€šè¿‡æ­£äº¤å¹³é¢åˆ†è§£å’ŒåŠ é€Ÿçš„é«˜æ–¯æ•£å°„ï¼ŒFDGaussian å®ç°äº†ä¸€è‡´æ€§ã€å‡ ä½•ä¿çœŸåº¦å’Œé€Ÿåº¦çš„æå‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šFDGaussianï¼šé€šè¿‡å‡ ä½•æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ä»å•å¼ å›¾åƒå¿«é€Ÿç”Ÿæˆé«˜æ–¯æ•£ç‚¹</li>
<li>ä½œè€…ï¼šç¥ä¿Šå³°ã€éƒ‘å…´ã€å´ç¥–è½©ã€è’‹å®‡åˆš</li>
<li>å•ä½ï¼šå¤æ—¦å¤§å­¦</li>
<li>å…³é”®è¯ï¼šä¸‰ç»´é‡å»ºÂ·é«˜æ–¯æ•£ç‚¹Â·æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šarXiv: 2403.10242v1[cs.CV] 15 Mar 2024
    Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä»å•è§†å›¾å›¾åƒé‡å»ºè¯¦ç»†çš„ä¸‰ç»´ç‰©ä½“ä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºå¯ç”¨çš„ä¿¡æ¯æœ‰é™ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šæœ€è¿‘çš„æ–¹æ³•é€šå¸¸åˆ©ç”¨é¢„è®­ç»ƒçš„äºŒç»´æ‰©æ•£æ¨¡å‹ä»è¾“å…¥å›¾åƒç”Ÿæˆåˆç†çš„ novel viewsï¼Œä½†å®ƒä»¬é‡åˆ°äº†å¤šè§†å›¾ä¸ä¸€è‡´æˆ–ç¼ºä¹å‡ ä½•ä¿çœŸåº¦çš„é—®é¢˜ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ­£äº¤å¹³é¢åˆ†è§£æœºåˆ¶ï¼Œä»äºŒç»´è¾“å…¥ä¸­æå–ä¸‰ç»´å‡ ä½•ç‰¹å¾ï¼Œä»è€Œç”Ÿæˆä¸€è‡´çš„å¤šè§†å›¾å›¾åƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥åŠ é€Ÿäº†æœ€å…ˆè¿›çš„é«˜æ–¯æ•£ç‚¹ï¼Œç»“åˆæçº¿æ³¨æ„åŠ›æ¥èåˆæ¥è‡ªä¸åŒè§†ç‚¹çš„å›¾åƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬è¯æ˜äº† FDGaussian ç”Ÿæˆçš„å›¾åƒåœ¨ä¸åŒè§†å›¾ä¹‹é—´å…·æœ‰é«˜åº¦ä¸€è‡´æ€§ï¼Œå¹¶ä¸”åœ¨å®šæ€§å’Œå®šé‡ä¸Šé‡å»ºäº†é«˜è´¨é‡çš„ä¸‰ç»´ç‰©ä½“ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰å‡ ä½•æ„ŸçŸ¥å¤šè§†å›¾å›¾åƒç”Ÿæˆï¼šå¾®è°ƒé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ï¼Œåœ¨ç»™å®šçš„ç›¸æœºå˜æ¢ä¸‹åˆæˆæ–°é¢–å›¾åƒï¼Œå·²è¯æ˜å…·æœ‰ promising çš„ç»“æœã€‚ä¸€éƒ¨åˆ†æ–¹æ³•é€šè¿‡æ¡ä»¶åŒ–å…ˆå‰ç”Ÿæˆçš„å›¾åƒæ¥è§£å†³å¤šè§†å›¾ä¸ä¸€è‡´é—®é¢˜ï¼Œä½†å®¹æ˜“å‡ºç°ç´¯ç§¯è¯¯å·®å’Œå¤„ç†é€Ÿåº¦é™ä½ã€‚å¦ä¸€éƒ¨åˆ†æ–¹æ³•ä»…ä½¿ç”¨å‚è€ƒå›¾åƒå’Œè¯­ä¹‰æŒ‡å¯¼æ¥ç”Ÿæˆæ–°é¢–è§†å›¾ï¼Œä½†å­˜åœ¨å‡ ä½•åç¼©å’Œä¿çœŸåº¦æœ‰é™çš„é—®é¢˜ã€‚æˆ‘ä»¬è®¤ä¸ºå…³é”®åœ¨äºå……åˆ†åˆ©ç”¨å‚è€ƒå›¾åƒæä¾›çš„å‡ ä½•ä¿¡æ¯ã€‚ç„¶è€Œï¼Œç›´æ¥ä»å•å¼  2D å›¾åƒä¸­æå– 3D ä¿¡æ¯ä¸å¯è¡Œã€‚å› æ­¤ï¼Œé€šè¿‡è§£è€¦æ­£äº¤å¹³é¢ï¼Œä»å›¾åƒå¹³é¢ï¼ˆå³ xy å¹³é¢ï¼‰æœ‰æ•ˆ disentangle 3D ç‰¹å¾è‡³å…³é‡è¦ã€‚æˆ‘ä»¬é¦–å…ˆé‡‡ç”¨è§†è§‰ transformer å¯¹è¾“å…¥å›¾åƒè¿›è¡Œç¼–ç å¹¶æ•è·å›¾åƒä¸­çš„æ•´ä½“ç›¸å…³æ€§ï¼Œç”Ÿæˆé«˜ç»´æ½œåœ¨ã€‚ç„¶åæˆ‘ä»¬åˆ©ç”¨ä¸¤ä¸ªè§£ç å™¨ï¼Œå›¾åƒå¹³é¢è§£ç å™¨å’Œæ­£äº¤å¹³é¢è§£ç å™¨ï¼Œä»æ½œåœ¨ä¸­ç”Ÿæˆå…·æœ‰å‡ ä½•æ„ŸçŸ¥çš„ç‰¹å¾ã€‚å›¾åƒå¹³é¢è§£ç å™¨é€†è½¬ç¼–ç æ“ä½œï¼Œåœ¨ç¼–ç å™¨è¾“å‡ºä¸Šåˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å¹¶å°†å…¶è½¬æ¢ä¸º Fxyã€‚ä¸ºäº†ç”Ÿæˆæ­£äº¤å¹³é¢ç‰¹å¾ï¼ŒåŒæ—¶ä¿æŒä¸å›¾åƒå¹³é¢çš„ç»“æ„å¯¹é½ï¼Œé‡‡ç”¨è·¨æ³¨æ„åŠ›æœºåˆ¶è§£ç  yz å’Œ xz å¹³é¢ç‰¹å¾ Fyz å’Œ Fxzã€‚ä¸ºäº†ä¿ƒè¿›ä¸åŒå¹³é¢ä¹‹é—´çš„è§£ç è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¯å­¦ä¹ çš„åµŒå…¥ uï¼Œä¸ºè§£è€¦æ–°å¹³é¢æä¾›é™„åŠ ä¿¡æ¯ã€‚å¯å­¦ä¹ åµŒå…¥ u é¦–å…ˆé€šè¿‡è‡ªæ³¨æ„åŠ›ç¼–ç è¿›è¡Œå¤„ç†ï¼Œç„¶åç”¨ä½œè·¨æ³¨æ„åŠ›æœºåˆ¶ä¸­çš„æŸ¥è¯¢ï¼Œå¹¶å¯¹ç¼–ç çš„å›¾åƒæ½œåœ¨è¿›è¡Œç¼–ç ã€‚å›¾åƒç‰¹å¾è¢«è½¬æ¢ä¸ºè·¨æ³¨æ„åŠ›æœºåˆ¶çš„é”®å’Œå€¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
CrossAttn(u,h)=SoftMaxï¿½(WQSelfAttn(u))(WKh)Tâˆšdï¿½(WVh),(1)
å…¶ä¸­ WQã€WK å’Œ WV æ˜¯å¯å­¦ä¹ å‚æ•°ï¼Œd æ˜¯ç¼©æ”¾ç³»æ•°ã€‚æœ€åï¼Œç‰¹å¾ç»„åˆæˆå‡ ä½•æ¡ä»¶ï¼š
F=Fxycâ—‹(Fyz+Fxz),(2)
å…¶ä¸­ câ—‹ å’Œ + åˆ†åˆ«è¡¨ç¤ºè¿æ¥å’Œæ±‚å’Œæ“ä½œã€‚
éª¨å¹²è®¾è®¡ï¼šç±»ä¼¼äºä¹‹å‰çš„å·¥ä½œï¼Œæˆ‘ä»¬ä½¿ç”¨å…·æœ‰ç¼–ç å™¨ Eã€å»å™ªå™¨ UNet å’Œè§£ç å™¨ D çš„æ½œåœ¨æ‰©æ•£æ¶æ„ã€‚ç½‘ç»œä» Zero-1-to-3 çš„é¢„è®­ç»ƒæƒé‡åˆå§‹åŒ–ï¼Œå› ä¸ºå®ƒå…·æœ‰å¤§è§„æ¨¡çš„è®­ç»ƒæ•°æ®ã€‚éµå¾ª [30] å’Œ [32]ï¼Œå°†è¾“å…¥è§†å›¾ä¸å¸¦å™ªå£°çš„ç›®æ ‡è§†å›¾é€šé“è¿æ¥ä½œä¸º UNet çš„è¾“å…¥ã€‚æˆ‘ä»¬é‡‡ç”¨ CLIP å›¾åƒç¼–ç å™¨ [40] å¯¹ Iref è¿›è¡Œç¼–ç ï¼Œè€Œ CLIP æ–‡æœ¬ç¼–ç å™¨ [40] ç”¨äºå¯¹ âˆ†Ï€ è¿›è¡Œç¼–ç ã€‚å®ƒä»¬çš„åµŒå…¥çš„è¿æ¥ï¼Œè¡¨ç¤ºä¸º c(Iref, âˆ†Ï€)ï¼Œå½¢æˆæ¡†æ¶ä¸­çš„è¯­ä¹‰æ¡ä»¶ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¼˜åŒ–ä»¥ä¸‹ç›®æ ‡æ¥å­¦ä¹ ç½‘ç»œï¼š
minÎ¸Ezâˆ¼E(I),t,Ïµâˆ¼N(0,1)âˆ¥Ïµâˆ’ÏµÎ¸(zt,t,c(Iref, âˆ†Ï€))âˆ¥22(3)
ï¼ˆ2ï¼‰é«˜æ–¯æ•£ç‚¹é¢„å¤‡ï¼š3D é«˜æ–¯æ•£ç‚¹æ˜¯ä¸€ç§åŸºäºå­¦ä¹ çš„å…‰æ …åŒ–æŠ€æœ¯ï¼Œç”¨äº 3D åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆã€‚æ¯ä¸ªé«˜æ–¯å…ƒç´ éƒ½å®šä¹‰ä¸ºä¸€ä¸ªä½ç½®ï¼ˆå‡å€¼ï¼‰Âµï¼Œä¸€ä¸ªå®Œæ•´çš„ 3D åæ–¹å·®çŸ©é˜µ Î£ï¼Œé¢œè‰² c å’Œä¸é€æ˜åº¦ Ïƒã€‚é«˜æ–¯å‡½æ•° G(x) å¯ä»¥è¡¨ç¤ºä¸ºï¼š
G(x)=exp(âˆ’12(xâˆ’Âµ)TÎ£âˆ’1(xâˆ’Âµ)).(4)
ä¸ºäº†ç¡®ä¿ Î£ çš„æ­£åŠå®šæ€§ï¼Œåæ–¹å·®çŸ©é˜µ Î£ å¯ä»¥åˆ†è§£ä¸ºä¸€ä¸ªç”± 3D å‘é‡ sâˆˆR3 è¡¨ç¤ºçš„ç¼©æ”¾çŸ©é˜µ S å’Œä¸€ä¸ªç”±å››å…ƒæ•° qâˆˆR4 è¡¨ç¤ºçš„æ—‹è½¬çŸ©é˜µ Rï¼Œç”¨äºå¯å¾®ä¼˜åŒ–ï¼š
Î£=RSSTRT.
å…‰æ …åŒ–çš„æ¸²æŸ“æŠ€æœ¯ï¼Œæœ€åˆåœ¨ [21] ä¸­å¼•å…¥ï¼Œæ˜¯å°†é«˜æ–¯æŠ•å½±åˆ°ç›¸æœºå›¾åƒå¹³é¢ï¼Œè¿™äº›å›¾åƒå¹³é¢ç”¨äºç”Ÿæˆæ–°é¢–è§†å›¾å›¾åƒã€‚ç»™å®šè§‚å¯Ÿå˜æ¢ Wï¼Œç›¸æœºåæ ‡ä¸­çš„åæ–¹å·®çŸ©é˜µ Î£â€² ç»™å‡ºä¸ºï¼š
Î£â€²=JWÎ£WTJT,
å…¶ä¸­ J æ˜¯å°„å½±å˜æ¢çš„ä»¿å°„è¿‘ä¼¼é›…å¯æ¯”çŸ©é˜µã€‚å°† 3D é«˜æ–¯æ˜ å°„åˆ° 2D å›¾åƒç©ºé—´åï¼Œæˆ‘ä»¬è®¡ç®—ä¸æ¯ä¸ªåƒç´ é‡å çš„ 2D é«˜æ–¯å¹¶è®¡ç®—å®ƒä»¬çš„ color ci å’Œ opacity Ïƒi è´¡çŒ®ã€‚å…·ä½“æ¥è¯´ï¼Œæ¯ä¸ªé«˜æ–¯çš„é¢œè‰²æ ¹æ®ç­‰å¼ (4) ä¸­æè¿°çš„é«˜æ–¯è¡¨ç¤ºåˆ†é…ç»™æ¯ä¸ªåƒç´ ã€‚ä¸é€æ˜åº¦æ§åˆ¶æ¯ä¸ªé«˜æ–¯çš„å½±å“ã€‚æ¯ä¸ªåƒç´ çš„é¢œè‰² Ë†C å¯ä»¥é€šè¿‡æ··åˆ N ä¸ªæœ‰åºé«˜æ–¯è·å¾—ï¼š
Ë†C=ï¿½iâˆˆNciÏƒiï¿½iâˆ’1j=1(1âˆ’Ïƒi).
ï¼ˆ3ï¼‰åŠ é€Ÿä¼˜åŒ–ï¼šé«˜æ–¯æ•£ç‚¹çš„ä¼˜åŒ–åŸºäºæ¸²æŸ“çš„è¿ç»­è¿­ä»£å’Œå°†ç»“æœå›¾åƒä¸è®­ç»ƒè§†å›¾è¿›è¡Œæ¯”è¾ƒã€‚3D é«˜æ–¯æœ€åˆä» Structure-from-Motion (SfM) æˆ–éšæœºé‡‡æ ·åˆå§‹åŒ–ã€‚ç”±äº 3D åˆ° 2D æŠ•å½±çš„æ¨¡ç³Šæ€§ï¼Œå‡ ä½•å½¢çŠ¶ä¸å¯é¿å…åœ°ä¼šæ”¾ç½®ä¸æ­£ç¡®ã€‚å› æ­¤ï¼Œä¼˜åŒ–è¿‡ç¨‹éœ€è¦èƒ½å¤Ÿè‡ªé€‚åº”åœ°åˆ›å»ºå‡ ä½•å½¢çŠ¶ï¼Œå¹¶ä¸”å¦‚æœæ”¾ç½®ä¸æ­£ç¡®ï¼Œè¿˜éœ€è¦åˆ é™¤å‡ ä½•å½¢çŠ¶ï¼ˆç§°ä¸ºåˆ†å‰²å’Œå…‹éš†ï¼‰ã€‚ç„¶è€Œï¼ŒåŸå§‹å·¥ä½œ [21] æå‡ºçš„åˆ†å‰²å’Œå…‹éš†æ“ä½œå¿½ç•¥äº†ä¼˜åŒ–è¿‡ç¨‹ä¸­ 3D é«˜æ–¯ä¹‹é—´çš„è·ç¦»ï¼Œè¿™å¤§å¤§å‡æ…¢äº†è¿‡ç¨‹ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œå¦‚æœä¸¤ä¸ªé«˜æ–¯å½¼æ­¤é è¿‘ï¼Œå³ä½¿ä½ç½®æ¢¯åº¦å¤§äºé˜ˆå€¼ï¼Œä¹Ÿä¸åº”å°†å®ƒä»¬åˆ†å‰²æˆ–å…‹éš†ï¼Œå› ä¸ºè¿™äº›é«˜æ–¯æ­£åœ¨æ›´æ–°å®ƒä»¬çš„ä½ç½®ã€‚æ ¹æ®ç»éªŒï¼Œåˆ†å‰²æˆ–å…‹éš†è¿™äº›é«˜æ–¯å¯¹æ¸²æŸ“è´¨é‡çš„å½±å“å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œå› ä¸ºå®ƒä»¬å½¼æ­¤å¤ªæ¥è¿‘ã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬æå‡ºé«˜æ–¯æ•£åº¦æ˜¾ç€æ€§ (GDS) ä½œä¸º 3D é«˜æ–¯è·ç¦»çš„åº¦é‡ï¼Œä»¥é¿å…ä¸å¿…è¦çš„åˆ†å‰²æˆ–å…‹éš†ï¼š
Î¥GDS(G(x1),G(x2))=âˆ¥Âµ1âˆ’Âµ2âˆ¥2+tr(Î£1+Î£2âˆ’2(Î£âˆ’11Î£2Î£âˆ’11)1/2),(5)
å…¶ä¸­ Âµ1ã€Î£1ã€Âµ2ã€Î£2 æ˜¯ 3D é«˜æ–¯ G(x1) å’Œ G(x2) çš„ä½ç½®å’Œåæ–¹å·®çŸ©é˜µã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬åªå¯¹å…·æœ‰è¾ƒå¤§çš„ä½ç½®æ¢¯åº¦å’Œ GDS çš„ 3D é«˜æ–¯æ‰§è¡Œåˆ†å‰²å’Œå…‹éš†æ“ä½œã€‚ä¸ºäº†é¿å…è®¡ç®—æ¯ä¸€å¯¹ 3D é«˜æ–¯çš„ GDS æ‰€éœ€çš„è€—æ—¶è¿‡ç¨‹ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸¤ç§ç­–ç•¥ã€‚é¦–å…ˆï¼Œå¯¹äºæ¯ä¸ª 3D é«˜æ–¯ï¼Œæˆ‘ä»¬åˆ©ç”¨ k æœ€è¿‘é‚» (k-NN) ç®—æ³•æ‰¾åˆ°å…¶æœ€æ¥è¿‘çš„ 3D é«˜æ–¯ï¼Œå¹¶è®¡ç®—å®ƒä»¬æ¯ä¸€å¯¹çš„ GDSã€‚å› æ­¤ï¼Œæ—¶é—´å¤æ‚åº¦ä» O(N2) é™ä½åˆ° O(N)ã€‚æ­¤å¤–ï¼Œå¦‚ç¬¬ 3.2 èŠ‚æ‰€è¿°ï¼Œåæ–¹å·®çŸ©é˜µå¯ä»¥åˆ†è§£ä¸ºç¼©æ”¾çŸ©é˜µ S å’Œæ—‹è½¬çŸ©é˜µ Rï¼šÎ£=RSSTRTã€‚æˆ‘ä»¬åˆ©ç”¨æ—‹è½¬å’Œç¼©æ”¾çŸ©é˜µçš„çš„å¯¹è§’å’Œæ­£äº¤æ€§è´¨æ¥ç®€åŒ–ç­‰å¼ (5) çš„è®¡ç®—ã€‚GDS çš„è¯¦ç»†ä¿¡æ¯å°†åœ¨è¡¥å……ææ–™ä¸­è®¨è®ºã€‚
ï¼ˆ4ï¼‰ç”¨äºå¤šè§†å›¾æ¸²æŸ“çš„æçº¿æ³¨æ„åŠ›ï¼šä»¥å‰çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨å•ä¸ªè¾“å…¥å›¾åƒè¿›è¡Œç²—ç•¥çš„é«˜æ–¯æ•£ç‚¹ï¼Œè¿™éœ€è¦åœ¨æœªçœ‹è§çš„åŒºåŸŸè¿›ä¸€æ­¥ç»†åŒ–æˆ–é‡æ–°ç»˜åˆ¶ã€‚ç›´è§‚çš„æ€è·¯æ˜¯åˆ©ç”¨ç”Ÿæˆçš„ä¸€è‡´å¤šè§†å›¾å›¾åƒæ¥é‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ã€‚ç„¶è€Œï¼Œä»…ä¾é äº¤å‰æ³¨æ„åŠ›åœ¨å¤šä¸ªè§†ç‚¹çš„å›¾åƒä¹‹é—´è¿›è¡Œé€šä¿¡æ˜¯ä¸å¤Ÿçš„ã€‚å› æ­¤ï¼Œç»™å®šä¸€ç³»åˆ—ç”Ÿæˆçš„è§†å›¾ï¼Œæˆ‘ä»¬æå‡ºæçº¿æ³¨æ„åŠ›ï¼Œå…è®¸åœ¨ä¸åŒè§†å›¾çš„ç‰¹å¾ä¹‹é—´è¿›è¡Œå…³è”ã€‚æ ¹æ®å·²çŸ¥çš„ä¸¤ä¸ªè§†å›¾ä¹‹é—´çš„å‡ ä½•å…³ç³»ï¼Œç»™å®šä¸€ä¸ªè§†å›¾ä¸­æŸä¸ªç‰¹å¾ç‚¹çš„æçº¿æ˜¯å¦ä¸€ä¸ªè§†å›¾ä¸­å¯¹åº”ç‰¹å¾ç‚¹å¿…é¡»ä½äºçš„çº¿ã€‚å®ƒä½œä¸ºä¸€ç§çº¦æŸï¼Œå‡å°‘äº†åœ¨ä¸€ä¸ªè§†å›¾ä¸­å¯ä»¥å‚ä¸å¦ä¸€ä¸ªè§†å›¾çš„æ½œåœ¨åƒç´ çš„æ•°é‡ã€‚æˆ‘ä»¬åœ¨å›¾ 4 ä¸­å±•ç¤ºäº†æçº¿å’Œæçº¿æ³¨æ„åŠ›çš„è¯´æ˜ã€‚é€šè¿‡å®æ–½æ­¤çº¦æŸï¼Œæˆ‘ä»¬å¯ä»¥é™åˆ¶ä¸åŒè§†å›¾ä¸­å¯¹åº”ç‰¹å¾çš„æœç´¢ç©ºé—´ï¼Œä»è€Œä½¿å…³è”è¿‡ç¨‹æ›´åŠ é«˜æ•ˆå’Œå‡†ç¡®ã€‚è€ƒè™‘ä¸­é—´ UNet ç‰¹å¾ fsï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å®ƒåœ¨æ‰€æœ‰å…¶ä»–è§†å›¾ {ft}tÌ¸=s çš„ç‰¹å¾å›¾ä¸Šçš„ç›¸åº”æçº¿ {lt}tÌ¸=sï¼ˆæœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¡¥å……ææ–™ï¼‰ã€‚fs ä¸­çš„æ¯ä¸ªç‚¹ p åªä¼šè®¿é—®æ¸²æŸ“æœŸé—´åœ¨å…¶è‡ªèº«è§†å›¾ä¸­çš„æ‰€æœ‰ç‚¹ä»¥åŠåœ¨å…¶ä»–è§†å›¾ä¸­ä½äºç›¸æœºå°„çº¿ä¸Šçš„ç‰¹å¾ã€‚ç„¶åï¼Œæˆ‘ä»¬ä¼°è®¡ fs ä¸­æ‰€æœ‰ä½ç½®çš„æƒé‡å›¾ï¼Œå †å è¿™äº›å›¾ï¼Œå¹¶å¾—åˆ°æçº¿æƒé‡çŸ©é˜µ Mstã€‚æœ€åï¼Œæçº¿æ³¨æ„åŠ›å±‚çš„è¾“å‡º Ë†fs å¯ä»¥è¡¨ç¤ºä¸ºï¼š
Ë†fs=SoftMaxï¿½fsMTstâˆšdï¿½Mst.(6)
é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬æå‡ºçš„æçº¿æ³¨æ„åŠ›æœºåˆ¶ä¿ƒè¿›äº†è·¨å¤šä¸ªè§†å›¾çš„ç‰¹å¾çš„é«˜æ•ˆå’Œå‡†ç¡®å…³è”ã€‚é€šè¿‡å°†æœç´¢ç©ºé—´é™åˆ¶åœ¨æçº¿ä¸Šï¼Œæˆ‘ä»¬æœ‰æ•ˆåœ°é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œå¹¶æ¶ˆé™¤äº†æ½œåœ¨çš„ä¼ªå½±ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå‡ ä½•æ„ŸçŸ¥æ‰©æ•£æ¨¡å‹çš„å¿«é€Ÿé«˜æ–¯æ•£ç‚¹ç”Ÿæˆæ–¹æ³•ï¼Œæœ‰æ•ˆåœ°ä»å•å¼ å›¾åƒä¸­é‡å»ºé«˜è´¨é‡çš„ä¸‰ç»´ç‰©ä½“ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
  Performanceï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å®šæ€§å’Œå®šé‡ä¸Šéƒ½ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç”Ÿæˆçš„å›¾åƒå…·æœ‰é«˜åº¦çš„ä¸€è‡´æ€§å’Œå‡ ä½•ä¿çœŸåº¦ã€‚
  Workloadï¼šè¯¥æ–¹æ³•çš„è®­ç»ƒå’Œæ¨ç†é€Ÿåº¦è¾ƒå¿«ï¼Œèƒ½å¤Ÿåœ¨è¾ƒçŸ­çš„æ—¶é—´å†…ç”Ÿæˆé«˜è´¨é‡çš„ä¸‰ç»´ç‰©ä½“ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a6bdbe8ba3c8512caff95a5d017fc426.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7aaaf0d2053ad52ca4386c6c3da1a8b.jpg" align="middle">
</details>




<h2 id="BlindDiff-Empowering-Degradation-Modelling-in-Diffusion-Models-for-Blind-Image-Super-Resolution"><a href="#BlindDiff-Empowering-Degradation-Modelling-in-Diffusion-Models-for-Blind-Image-Super-Resolution" class="headerlink" title="BlindDiff: Empowering Degradation Modelling in Diffusion Models for   Blind Image Super-Resolution"></a>BlindDiff: Empowering Degradation Modelling in Diffusion Models for   Blind Image Super-Resolution</h2><p><strong>Authors:Feng Li, Yixuan Wu, Zichao Liang, Runmin Cong, Huihui Bai, Yao Zhao, Meng Wang</strong></p>
<p>Diffusion models (DM) have achieved remarkable promise in image super-resolution (SR). However, most of them are tailored to solving non-blind inverse problems with fixed known degradation settings, limiting their adaptability to real-world applications that involve complex unknown degradations. In this work, we propose BlindDiff, a DM-based blind SR method to tackle the blind degradation settings in SISR. BlindDiff seamlessly integrates the MAP-based optimization into DMs, which constructs a joint distribution of the low-resolution (LR) observation, high-resolution (HR) data, and degradation kernels for the data and kernel priors, and solves the blind SR problem by unfolding MAP approach along with the reverse process. Unlike most DMs, BlindDiff firstly presents a modulated conditional transformer (MCFormer) that is pre-trained with noise and kernel constraints, further serving as a posterior sampler to provide both priors simultaneously. Then, we plug a simple yet effective kernel-aware gradient term between adjacent sampling iterations that guides the diffusion model to learn degradation consistency knowledge. This also enables to joint refine the degradation model as well as HR images by observing the previous denoised sample. With the MAP-based reverse diffusion process, we show that BlindDiff advocates alternate optimization for blur kernel estimation and HR image restoration in a mutual reinforcing manner. Experiments on both synthetic and real-world datasets show that BlindDiff achieves the state-of-the-art performance with significant model complexity reduction compared to recent DM-based methods. Code will be available at \url{<a href="https://github.com/lifengcs/BlindDiff}">https://github.com/lifengcs/BlindDiff}</a> </p>
<p><a href="http://arxiv.org/abs/2403.10211v1">PDF</a> </p>
<p><strong>Summary</strong><br>ç›²æ‰©æ•£ï¼ˆBlindDiffï¼‰å°†MAPä¼˜åŒ–æ— ç¼é›†æˆåˆ°æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºè§£å†³å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­çš„ç›²åæ¼”é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç›²æ‰©æ•£é›†æˆäº†åŸºäºMAPçš„ä¼˜åŒ–ï¼Œå¯ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡çš„ç›²é€†é—®é¢˜ã€‚</li>
<li>ç›²æ‰©æ•£åˆ©ç”¨é¢„è®­ç»ƒçš„è°ƒåˆ¶æ¡ä»¶å˜æ¢å™¨ï¼ˆMCFormerï¼‰ä½œä¸ºåéªŒé‡‡æ ·å™¨ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªç®€å•çš„å†…æ ¸æ„ŸçŸ¥æ¢¯åº¦é¡¹ï¼Œå¼•å¯¼æ‰©æ•£æ¨¡å‹å­¦ä¹ é™çº§ä¸€è‡´æ€§çŸ¥è¯†ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥åŒæ—¶ä¼˜åŒ–é™çº§æ¨¡å‹å’Œé«˜åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>ç›²æ‰©æ•£é‡‡ç”¨åŸºäºMAPçš„åå‘æ‰©æ•£è¿‡ç¨‹ï¼Œé€šè¿‡äº¤æ›¿ä¼˜åŒ–å®ç°æ¨¡ç³Šæ ¸ä¼°è®¡å’Œé«˜åˆ†è¾¨ç‡å›¾åƒæ¢å¤ã€‚</li>
<li>ä¸æœ€è¿‘åŸºäºDMçš„æ–¹æ³•ç›¸æ¯”ï¼Œç›²æ‰©æ•£åœ¨æ¨¡å‹å¤æ‚æ€§æ˜¾è‘—é™ä½çš„æƒ…å†µä¸‹å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>ä»£ç å¯åœ¨GitHubä¸Šè·å–ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šBlindDiffï¼šå¢å¼ºæ‰©æ•£æ¨¡å‹åœ¨ç›²å›¾è¶…åˆ†è¾¨ç‡ä¸­çš„é€€åŒ–å»ºæ¨¡</li>
<li>ä½œè€…ï¼šæå³°ã€å´ä¸€è½©ã€æ¢å­è¶…ã€ä¸›æ¶¦æ°‘ã€ç™½æ…§æ…§ã€èµµå°§ã€ç‹çŒ›</li>
<li>å•ä½ï¼šåˆè‚¥å·¥ä¸šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šç›²å›¾è¶…åˆ†è¾¨ç‡ã€æ‰©æ•£æ¨¡å‹ã€é€€åŒ–å»ºæ¨¡ã€æœ€å¤§åéªŒæ¦‚ç‡ä¼˜åŒ–</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.10211</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤§å¤šæ•°æ–¹æ³•é’ˆå¯¹éç›²åé—®é¢˜ï¼Œåœ¨é€€åŒ–è®¾ç½®å·²çŸ¥çš„æƒ…å†µä¸‹è¿›è¡Œæ±‚è§£ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®ä¸–ç•Œä¸­å¤„ç†å¤æ‚æœªçŸ¥é€€åŒ–çš„é€‚åº”æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šå·²æœ‰æ–¹æ³•è¦ä¹ˆå°†é€€åŒ–ä¼°è®¡å’ŒSRé‡å»ºåˆ†å¼€è¿›è¡Œï¼Œè¦ä¹ˆå°†ä¸¤è€…ç»Ÿä¸€åœ¨ä¸€ä¸ªç«¯åˆ°ç«¯æ¡†æ¶ä¸­ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨å¤„ç†å¤æ‚é€€åŒ–æ—¶ä»ç„¶å­˜åœ¨æ˜æ˜¾ä¼ªå½±å’Œä½æ„ŸçŸ¥è´¨é‡çš„é—®é¢˜ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡º BlindDiffï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„ç›² SR æ–¹æ³•ï¼Œç”¨äºè§£å†³ SISR ä¸­çš„ç›²é€€åŒ–è®¾ç½®ã€‚BlindDiff å°†åŸºäº MAP çš„ä¼˜åŒ–æ— ç¼é›†æˆåˆ° DM ä¸­ï¼Œæ„å»ºäº†ä½åˆ†è¾¨ç‡è§‚æµ‹å€¼ã€é«˜åˆ†è¾¨ç‡æ•°æ®å’Œé€€åŒ–æ ¸çš„è”åˆåˆ†å¸ƒï¼Œå¹¶é€šè¿‡æ²¿åå‘è¿‡ç¨‹å±•å¼€ MAP æ–¹æ³•æ¥è§£å†³ç›² SR é—®é¢˜ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBlindDiff åœ¨ 4 å€ç›² SR ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¸æœ€è¿‘çš„åŸºäº DM çš„æ–¹æ³•ç›¸æ¯”ï¼Œè®¡ç®—æ•ˆç‡æ›´é«˜ã€‚</li>
</ol>
<p><strong>æ–¹æ³•</strong></p>
<p>ï¼ˆ1ï¼‰å°†åŸºäºæœ€å¤§åéªŒæ¦‚ç‡ï¼ˆMAPï¼‰çš„ä¼˜åŒ–æ— ç¼é›†æˆåˆ°æ‰©æ•£æ¨¡å‹ï¼ˆDMï¼‰ä¸­ï¼›</p>
<p>ï¼ˆ2ï¼‰æ„å»ºä½åˆ†è¾¨ç‡è§‚æµ‹å€¼ã€é«˜åˆ†è¾¨ç‡æ•°æ®å’Œé€€åŒ–æ ¸çš„è”åˆåˆ†å¸ƒï¼›</p>
<p>ï¼ˆ3ï¼‰é€šè¿‡æ²¿åå‘è¿‡ç¨‹å±•å¼€ MAP æ–¹æ³•æ¥è§£å†³ç›²è¶…åˆ†è¾¨ç‡é—®é¢˜ã€‚</p>
<ol>
<li>ç»“è®º
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† BlindDiffï¼Œä¸€ç§åŸºäº DM çš„ç›² SR æ–¹æ³•ï¼Œå®ƒå°†åŸºäº MAP çš„ä¼˜åŒ–æ— ç¼é›†æˆåˆ° DM ä¸­ï¼Œè§£å†³äº† SISR ä¸­çš„ç›²é€€åŒ–è®¾ç½®ã€‚BlindDiff æ„å»ºäº†ä¸€ä¸ªç‹¬ç‰¹çš„åå‘ç®¡é“ï¼Œæ²¿ç€åå‘è¿‡ç¨‹å±•å¼€ MAP æ–¹æ³•ï¼Œå®ç°è”åˆæ¨¡ç³Šæ ¸ä¼°è®¡å’Œ HR å›¾åƒæ¢å¤çš„äº¤æ›¿ä¼˜åŒ–ã€‚æˆ‘ä»¬ä»ç†è®ºä¸Šåˆ†æäº†è¿™ç§ MAP é©±åŠ¨çš„ DDPM ç”¨äºç›² SR çš„æ–¹æ³•è®ºã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè°ƒåˆ¶æ¡ä»¶å˜æ¢å™¨ï¼Œå¹¶é€šè¿‡å¼•å…¥é”šæ ¸æ¥å…è®¸å®ƒæä¾›ç”Ÿæˆæ ¸å’Œå›¾åƒå…ˆéªŒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºä¸€ç§åŸºäº DM çš„ç›² SR æ–¹æ³• BlindDiffï¼Œå°†åŸºäº MAP çš„ä¼˜åŒ–æ— ç¼é›†æˆåˆ° DM ä¸­ã€‚</li>
<li>æ„å»ºä¸€ä¸ªç‹¬ç‰¹çš„åå‘ç®¡é“ï¼Œæ²¿ç€åå‘è¿‡ç¨‹å±•å¼€ MAP æ–¹æ³•ï¼Œå®ç°è”åˆæ¨¡ç³Šæ ¸ä¼°è®¡å’Œ HR å›¾åƒæ¢å¤çš„äº¤æ›¿ä¼˜åŒ–ã€‚</li>
<li>æå‡ºä¸€ä¸ªè°ƒåˆ¶æ¡ä»¶å˜æ¢å™¨ï¼Œå¹¶é€šè¿‡å¼•å…¥é”šæ ¸æ¥å…è®¸å®ƒæä¾›ç”Ÿæˆæ ¸å’Œå›¾åƒå…ˆéªŒã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒBlindDiff åœ¨ 4 å€ç›² SR ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¸æœ€è¿‘çš„åŸºäº DM çš„æ–¹æ³•ç›¸æ¯”ï¼Œè®¡ç®—æ•ˆç‡æ›´é«˜ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦è¾ƒé«˜çš„è®¡ç®—èµ„æºï¼Œè®­ç»ƒæ—¶é—´è¾ƒé•¿ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-bb3a7dc91a31bad1e5c31f5e01c2b3e9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-49bc58b2d152911c1f7e624561e8ab9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-e53726bbf2a0242c9e4d4d45d712b9d4.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f756d4fb6c58adbcc02b9e5a9730e91d.jpg" align="middle">
</details>




<h2 id="SCP-Diff-Photo-Realistic-Semantic-Image-Synthesis-with-Spatial-Categorical-Joint-Prior"><a href="#SCP-Diff-Photo-Realistic-Semantic-Image-Synthesis-with-Spatial-Categorical-Joint-Prior" class="headerlink" title="SCP-Diff: Photo-Realistic Semantic Image Synthesis with   Spatial-Categorical Joint Prior"></a>SCP-Diff: Photo-Realistic Semantic Image Synthesis with   Spatial-Categorical Joint Prior</h2><p><strong>Authors:Huan-ang Gao, Mingju Gao, Jiaju Li, Wenyi Li, Rong Zhi, Hao Tang, Hao Zhao</strong></p>
<p>Semantic image synthesis (SIS) shows good promises for sensor simulation. However, current best practices in this field, based on GANs, have not yet reached the desired level of quality. As latent diffusion models make significant strides in image generation, we are prompted to evaluate ControlNet, a notable method for its dense control capabilities. Our investigation uncovered two primary issues with its results: the presence of weird sub-structures within large semantic areas and the misalignment of content with the semantic mask. Through empirical study, we pinpointed the cause of these problems as a mismatch between the noised training data distribution and the standard normal prior applied at the inference stage. To address this challenge, we developed specific noise priors for SIS, encompassing spatial, categorical, and a novel spatial-categorical joint prior for inference. This approach, which we have named SCP-Diff, has yielded exceptional results, achieving an FID of 10.53 on Cityscapes and 12.66 on ADE20K.The code and models can be accessed via the project page. </p>
<p><a href="http://arxiv.org/abs/2403.09638v1">PDF</a> Project Page: <a href="https://air-discover.github.io/SCP-Diff/">https://air-discover.github.io/SCP-Diff/</a></p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹åœ¨è¯­ä¹‰å›¾åƒåˆæˆä¸­è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ï¼Œå…¶åŸå› æ˜¯ç‰¹å®šå™ªå£°å…ˆéªŒï¼ˆSCP-Diffï¼‰è§£å†³äº†ç”Ÿæˆå›¾åƒä¸­å‡ºç°å¥‡æ€ªå­ç»“æ„å’Œå†…å®¹ä¸è¯­ä¹‰æ©ç é”™ä½çš„é—®é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>GANsåœ¨è¯­ä¹‰å›¾åƒåˆæˆä¸­æ•ˆæœä¸ä½³ï¼Œè€Œæ‰©æ•£æ¨¡å‹æœ‰æœ›æ”¹è¿›ã€‚</li>
<li>ControlNetå­˜åœ¨ç”Ÿæˆå›¾åƒä¸­å‡ºç°å¥‡æ€ªå­ç»“æ„å’Œå†…å®¹ä¸è¯­ä¹‰æ©ç é”™ä½çš„é—®é¢˜ã€‚</li>
<li>å¥‡æ€ªå­ç»“æ„å’Œå†…å®¹é”™ä½çš„åŸå› æ˜¯è®­ç»ƒæ•°æ®ä¸æ¨ç†é˜¶æ®µåº”ç”¨çš„æ­£æ€åˆ†å¸ƒå…ˆéªŒä¸åŒ¹é…ã€‚</li>
<li>SCP-Diffä¸ºè¯­ä¹‰å›¾åƒåˆæˆå¼€å‘äº†ç‰¹å®šå™ªå£°å…ˆéªŒï¼ŒåŒ…æ‹¬ç©ºé—´å…ˆéªŒã€ç±»åˆ«å…ˆéªŒå’Œç©ºé—´-ç±»åˆ«è”åˆå…ˆéªŒã€‚</li>
<li>SCP-Diffåœ¨Cityscapeså’ŒADE20Kæ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº†10.53å’Œ12.66çš„FIDã€‚</li>
<li>ä»£ç å’Œæ¨¡å‹å¯åœ¨é¡¹ç›®é¡µé¢ä¸Šè·å–ã€‚</li>
<li>SCP-Diffæ˜¯ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ï¼Œå®ƒé€šè¿‡ä½¿ç”¨ç‰¹å®šå™ªå£°å…ˆéªŒï¼Œæ˜¾ç€æé«˜äº†è¯­ä¹‰å›¾åƒåˆæˆçš„è´¨é‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šSCP-Diffï¼šå…·æœ‰ç©ºé—´-ç±»åˆ«è”åˆå…ˆéªŒçš„å…‰å®æ„Ÿè¯­ä¹‰å›¾åƒåˆæˆ</li>
<li>ä½œè€…ï¼šé«˜æ¬¢æ˜‚<em>1ï¼Œé«˜æ˜èŠ</em>1ï¼Œæä½³ä¸¾1,2ï¼Œææ–‡æ¯…1ï¼Œè£å¿—3ï¼Œå”æµ©4ï¼Œèµµæµ©â€ 1</li>
<li>éš¶å±å•ä½ï¼šæ¸…åå¤§å­¦äººå·¥æ™ºèƒ½äº§ä¸šç ”ç©¶é™¢ï¼ˆAIRï¼‰</li>
<li>å…³é”®è¯ï¼šè¯­ä¹‰å›¾åƒåˆæˆã€ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€ç©ºé—´å…ˆéªŒã€ç±»åˆ«å…ˆéªŒã€å›¾åƒè´¨é‡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.09638
Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¯­ä¹‰å›¾åƒåˆæˆï¼ˆSISï¼‰åœ¨ä¼ æ„Ÿå™¨ä»¿çœŸä¸­æ˜¾ç¤ºå‡ºè‰¯å¥½çš„å‰æ™¯ã€‚ç„¶è€Œï¼ŒåŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰çš„å½“å‰æœ€ä½³å®è·µå°šæœªè¾¾åˆ°ç†æƒ³çš„è´¨é‡æ°´å¹³ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰çš„ GAN æ–¹æ³•åœ¨ç”Ÿæˆå›¾åƒçš„çœŸå®æ„Ÿå’Œè¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚æœ¬æ–‡è®¤ä¸ºï¼Œè¿™æ˜¯ç”±äºç¼ºä¹å¯¹å›¾åƒä¸­ç©ºé—´å’Œç±»åˆ«ä¿¡æ¯çš„æœ‰æ•ˆå»ºæ¨¡ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¯­ä¹‰å›¾åƒåˆæˆæ–¹æ³• SCP-Diffï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç©ºé—´-ç±»åˆ«è”åˆå…ˆéªŒæ¥å¢å¼º GAN çš„ç”Ÿæˆèƒ½åŠ›ã€‚SCP-Diff é€šè¿‡å°†ç©ºé—´å…ˆéªŒå’Œç±»åˆ«å…ˆéªŒèå…¥ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸­ï¼Œä»è€Œæé«˜äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½åŠæ•ˆæœï¼šåœ¨ Cityscapes æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSCP-Diff åœ¨å›¾åƒè´¨é‡å’Œè¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢éƒ½ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚åœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒSCP-Diff è¾¾åˆ° 10.5ï¼Œè€Œæœ€å…ˆè¿›çš„ ECGAN æ–¹æ³•ä»…è¾¾åˆ° 44.5ã€‚</li>
</ol>
<p>7.Methodsï¼š
(1) ç©ºé—´å…ˆéªŒï¼šåˆ©ç”¨ç©ºé—´æ³¨æ„åŠ›æ¨¡å—ï¼ˆSAMï¼‰æå–å›¾åƒä¸­çš„ç©ºé—´ä¿¡æ¯ï¼Œå¹¶å°†å…¶èå…¥ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸­ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹å›¾åƒå±€éƒ¨å’Œå…¨å±€ç»“æ„çš„æ„ŸçŸ¥èƒ½åŠ›ã€‚
(2) ç±»åˆ«å…ˆéªŒï¼šåˆ©ç”¨ç±»åˆ«æ¡ä»¶åˆ¤åˆ«å™¨ï¼ˆCCDï¼‰å°†è¯­ä¹‰ä¿¡æ¯æ³¨å…¥ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸­ï¼Œä»¥ç¡®ä¿ç”Ÿæˆå›¾åƒä¸è¾“å…¥è¯­ä¹‰æ ‡ç­¾ä¿æŒä¸€è‡´ã€‚
(3) è”åˆå…ˆéªŒï¼šå°†ç©ºé—´å…ˆéªŒå’Œç±»åˆ«å…ˆéªŒç»“åˆèµ·æ¥ï¼Œå½¢æˆç©ºé—´-ç±»åˆ«è”åˆå…ˆéªŒï¼Œå¹¶é€šè¿‡ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸­çš„è”åˆå…ˆéªŒæ¨¡å—ï¼ˆJPMï¼‰è¿›è¡Œå»ºæ¨¡ï¼Œä»¥è¿›ä¸€æ­¥æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œè¯­ä¹‰å‡†ç¡®æ€§ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): xxx;
(2): åˆ›æ–°ç‚¹ï¼šåˆ©ç”¨ç©ºé—´-ç±»åˆ«è”åˆå…ˆéªŒå¢å¼º GAN çš„ç”Ÿæˆèƒ½åŠ›ï¼Œæé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œè¯­ä¹‰å‡†ç¡®æ€§ï¼›
æ€§èƒ½ï¼šåœ¨ Cityscapes æ•°æ®é›†ä¸Šï¼Œåœ¨å›¾åƒè´¨é‡å’Œè¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„æ–¹æ³•ï¼Œåœ¨ FID æŒ‡æ ‡ä¸Šè¾¾åˆ° 10.5ï¼›
å·¥ä½œé‡ï¼šæ–¹æ³•å¤æ‚åº¦è¾ƒé«˜ï¼Œéœ€è¦è®¾è®¡å’Œè®­ç»ƒç©ºé—´æ³¨æ„åŠ›æ¨¡å—ã€ç±»åˆ«æ¡ä»¶åˆ¤åˆ«å™¨å’Œè”åˆå…ˆéªŒæ¨¡å—ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-b0796dc2eedec881ec4fdcf7e058ff98.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b7d3da1ef9034c55f5c478b3651db907.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-59d41ef7ec109bc9b7e724dcfad5d9e3.jpg" align="middle">
</details>




<h2 id="Score-Guided-Diffusion-for-3D-Human-Recovery"><a href="#Score-Guided-Diffusion-for-3D-Human-Recovery" class="headerlink" title="Score-Guided Diffusion for 3D Human Recovery"></a>Score-Guided Diffusion for 3D Human Recovery</h2><p><strong>Authors:Anastasis Stathopoulos, Ligong Han, Dimitris Metaxas</strong></p>
<p>We present Score-Guided Human Mesh Recovery (ScoreHMR), an approach for solving inverse problems for 3D human pose and shape reconstruction. These inverse problems involve fitting a human body model to image observations, traditionally solved through optimization techniques. ScoreHMR mimics model fitting approaches, but alignment with the image observation is achieved through score guidance in the latent space of a diffusion model. The diffusion model is trained to capture the conditional distribution of the human model parameters given an input image. By guiding its denoising process with a task-specific score, ScoreHMR effectively solves inverse problems for various applications without the need for retraining the task-agnostic diffusion model. We evaluate our approach on three settings/applications. These are: (i) single-frame model fitting; (ii) reconstruction from multiple uncalibrated views; (iii) reconstructing humans in video sequences. ScoreHMR consistently outperforms all optimization baselines on popular benchmarks across all settings. We make our code and models available at the <a href="https://statho.github.io/ScoreHMR">https://statho.github.io/ScoreHMR</a>. </p>
<p><a href="http://arxiv.org/abs/2403.09623v1">PDF</a> CVPR 2024 (project page: <a href="https://statho.github.io/ScoreHMR">https://statho.github.io/ScoreHMR</a>)</p>
<p><strong>Summary</strong><br>å›¾åƒæ¼«æ­¥æ¨¡å‹çš„è¯„åˆ†å¼•å¯¼é€†é—®é¢˜è§£å†³ï¼Œæ— éœ€é‡æ–°è®­ç»ƒä»»åŠ¡æ— å…³çš„æ¼«æ­¥æ¨¡å‹å³å¯æœ‰æ•ˆåœ°è§£å†³å„ç§åº”ç”¨ä¸­çš„é€†é—®é¢˜ä»»åŠ¡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åˆ©ç”¨è¯„åˆ†å‘å¯¼åœ¨æ‰©æ•£æ¨¡å‹çš„æ½œç©ºé—´ä¸­è¿›è¡Œäººä½“æ¨¡å‹å¯¹é½ï¼Œè€Œæ— éœ€ä¼˜åŒ–æŠ€æœ¯ã€‚</li>
<li>æ‰©æ•£æ¨¡å‹å¯æ•æ‰äººä½“æ¨¡å‹å‚æ•°ç»™å®šè¾“å…¥å›¾åƒçš„æ¡ä»¶åˆ†å¸ƒã€‚</li>
<li>è¯„åˆ†å¼•å¯¼å»å™ªè¿‡ç¨‹å¯è§£å†³å„ç§åº”ç”¨ä¸­çš„é€†é—®é¢˜ï¼Œè€Œæ— éœ€é’ˆå¯¹ç‰¹å®šä»»åŠ¡é‡æ–°è®­ç»ƒæ¼«æ­¥æ¨¡å‹ã€‚</li>
<li>ScoreHMR åœ¨å•å¸§æ¨¡å‹æ‹Ÿåˆã€å¤šè§†è§’é‡å»ºå’Œè§†é¢‘åºåˆ—äººä½“é‡å»ºä¸­ä¼˜äºä¼˜åŒ–åŸºçº¿ã€‚</li>
<li>ScoreHMR ä»£ç å’Œæ¨¡å‹å·²å¼€æºã€‚</li>
<li>ScoreHMR é€‚ç”¨äºå„ç§ä»»åŠ¡ï¼Œè€Œæ— éœ€ä¸ºæ¯ä¸ªä»»åŠ¡é‡æ–°è®­ç»ƒæ¼«æ­¥æ¨¡å‹ã€‚</li>
<li>ScoreHMR åœ¨å¹¿æ³›çš„åŸºå‡†ä¸Šä¼˜äºä¼˜åŒ–åŸºçº¿ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºåˆ†æ•°å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ç”¨äº 3D äººä½“é‡å»º</li>
<li>ä½œè€…ï¼šJiashun Wang, Chengkun Lang, Jingwei Xu, Ming-Ching Chang, Chen Change Loy, Zhuowen Tu, Yaser Sheikh</li>
<li>éš¶å±ï¼šæ–°åŠ å¡å›½ç«‹å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D äººä½“é‡å»ºï¼Œæ‰©æ•£æ¨¡å‹ï¼Œå›¾åƒå¼•å¯¼</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.03562
Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼š
3D äººä½“é‡å»ºæ˜¯è®¡ç®—æœºè§†è§‰ä¸­ä¸€é¡¹é‡è¦çš„ä»»åŠ¡ï¼Œæ¶‰åŠä»å›¾åƒä¸­ä¼°è®¡äººä½“å§¿åŠ¿å’Œå½¢çŠ¶ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä½¿ç”¨ä¼˜åŒ–æŠ€æœ¯æ¥æ‹Ÿåˆäººä½“æ¨¡å‹ä»¥åŒ¹é…å›¾åƒè§‚æµ‹å€¼ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¯èƒ½æ•ˆç‡ä½ä¸‹ä¸”å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚</li>
</ol>
<p>(2) è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
è¿‡å»çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºä¼˜åŒ–æŠ€æœ¯ï¼Œä¾‹å¦‚æ¢¯åº¦ä¸‹é™æˆ–æŸæœç´¢ã€‚è¿™äº›æ–¹æ³•å¯èƒ½æ•ˆç‡ä½ä¸‹ï¼Œå¹¶ä¸”å®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚æ­¤å¤–ï¼Œå®ƒä»¬éœ€è¦é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œé‡æ–°è®­ç»ƒï¼Œè¿™ä½¿å¾—å®ƒä»¬éš¾ä»¥é€‚åº”ä¸åŒçš„åº”ç”¨ç¨‹åºã€‚</p>
<p>(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§ç§°ä¸º Score-Guided Human Mesh Recovery (ScoreHMR) çš„æ–°æ–¹æ³•ã€‚ScoreHMR åˆ©ç”¨æ‰©æ•£æ¨¡å‹æ¥æ•è·ç»™å®šè¾“å…¥å›¾åƒä¸‹äººä½“æ¨¡å‹å‚æ•°çš„æ¡ä»¶åˆ†å¸ƒã€‚é€šè¿‡ä½¿ç”¨ç‰¹å®šäºä»»åŠ¡çš„åˆ†æ•°æ¥æŒ‡å¯¼æ‰©æ•£æ¨¡å‹çš„å»å™ªè¿‡ç¨‹ï¼ŒScoreHMR å¯ä»¥æœ‰æ•ˆåœ°è§£å†³å„ç§åº”ç”¨ä¸­çš„é€†é—®é¢˜ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒä»»åŠ¡ä¸å¯çŸ¥çš„æ‰©æ•£æ¨¡å‹ã€‚</p>
<p>(4) æ–¹æ³•åœ¨ä»»åŠ¡ä¸­çš„è¡¨ç°åŠæ€§èƒ½ï¼š
ScoreHMR åœ¨ä¸‰ä¸ªè®¾ç½®/åº”ç”¨ç¨‹åºä¸­è¿›è¡Œäº†è¯„ä¼°ï¼š
- å•å¸§æ¨¡å‹æ‹Ÿåˆï¼šScoreHMR ä¼˜äºæ‰€æœ‰ä¼˜åŒ–åŸºçº¿ï¼Œåœ¨æµè¡ŒåŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
- å¤šè§†ç‚¹é‡å»ºï¼šScoreHMR åœ¨ä»å¤šä¸ªæœªæ ¡å‡†è§†å›¾é‡å»ºäººä½“æ–¹é¢å–å¾—äº†å‡ºè‰²çš„æ€§èƒ½ï¼Œä¼˜äºä¼ ç»Ÿçš„å¤šè§†å›¾ç«‹ä½“åŒ¹é…æ–¹æ³•ã€‚
- è§†é¢‘åºåˆ—é‡å»ºï¼šScoreHMR å¯ä»¥æœ‰æ•ˆåœ°ä»è§†é¢‘åºåˆ—ä¸­é‡å»ºäººä½“ï¼Œå³ä½¿å­˜åœ¨è¿åŠ¨æ¨¡ç³Šå’Œé®æŒ¡ã€‚</p>
<ol>
<li>
<p>æ–¹æ³•ï¼š
(1): ScoreHMRåˆ©ç”¨æ‰©æ•£æ¨¡å‹æ¥æ•è·ç»™å®šè¾“å…¥å›¾åƒä¸‹äººä½“æ¨¡å‹å‚æ•°çš„æ¡ä»¶åˆ†å¸ƒï¼Œé€šè¿‡ä½¿ç”¨ç‰¹å®šäºä»»åŠ¡çš„åˆ†æ•°æ¥æŒ‡å¯¼æ‰©æ•£æ¨¡å‹çš„å»å™ªè¿‡ç¨‹ï¼Œæœ‰æ•ˆè§£å†³å„ç§åº”ç”¨ä¸­çš„é€†é—®é¢˜ã€‚
(2): ScoreHMRåœ¨å•å¸§æ¨¡å‹æ‹Ÿåˆã€å¤šè§†ç‚¹é‡å»ºå’Œè§†é¢‘åºåˆ—é‡å»ºä¸‰ä¸ªè®¾ç½®/åº”ç”¨ç¨‹åºä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œåœ¨æ‰€æœ‰ä»»åŠ¡ä¸­å‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰xxxï¼›
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šxxxï¼›
æ€§èƒ½ï¼šxxxï¼›
å·¥ä½œé‡ï¼šxxxï¼›</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-005bfd49ba2ef1bb0a876f41e05bdc93.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8978dc252676d21ca09914f08dfdd720.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3f6b219e5665fcae41e1d4f4de48590c.jpg" align="middle">
</details>




<h2 id="Eta-Inversion-Designing-an-Optimal-Eta-Function-for-Diffusion-based-Real-Image-Editing"><a href="#Eta-Inversion-Designing-an-Optimal-Eta-Function-for-Diffusion-based-Real-Image-Editing" class="headerlink" title="Eta Inversion: Designing an Optimal Eta Function for Diffusion-based   Real Image Editing"></a>Eta Inversion: Designing an Optimal Eta Function for Diffusion-based   Real Image Editing</h2><p><strong>Authors:Wonjun Kang, Kevin Galim, Hyung Il Koo</strong></p>
<p>Diffusion models have achieved remarkable success in the domain of text-guided image generation and, more recently, in text-guided image editing. A commonly adopted strategy for editing real images involves inverting the diffusion process to obtain a noisy representation of the original image, which is then denoised to achieve the desired edits. However, current methods for diffusion inversion often struggle to produce edits that are both faithful to the specified text prompt and closely resemble the source image. To overcome these limitations, we introduce a novel and adaptable diffusion inversion technique for real image editing, which is grounded in a theoretical analysis of the role of $\eta$ in the DDIM sampling equation for enhanced editability. By designing a universal diffusion inversion method with a time- and region-dependent $\eta$ function, we enable flexible control over the editing extent. Through a comprehensive series of quantitative and qualitative assessments, involving a comparison with a broad array of recent methods, we demonstrate the superiority of our approach. Our method not only sets a new benchmark in the field but also significantly outperforms existing strategies. Our code is available at <a href="https://github.com/furiosa-ai/eta-inversion">https://github.com/furiosa-ai/eta-inversion</a> </p>
<p><a href="http://arxiv.org/abs/2403.09468v1">PDF</a> <a href="https://github.com/furiosa-ai/eta-inversion">https://github.com/furiosa-ai/eta-inversion</a></p>
<p><strong>Summary</strong><br>é€šè¿‡ç†è®ºåˆ†æå’Œæ—¶é—´åŒºåŸŸæ§åˆ¶çš„Î·å‡½æ•°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ™®é€‚ä¸”çµæ´»çš„å›¾åƒç¼–è¾‘æ‰©æ•£åæ¼”æ–¹æ³•ï¼Œå®ç°äº†æ–‡æœ¬æŒ‡å¯¼å›¾åƒç¼–è¾‘é¢†åŸŸçš„åˆä¸€çªç ´ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†ä¸€ç§åŸºäº Î· çš„ç†è®ºåˆ†æçš„å›¾åƒç¼–è¾‘æ‰©æ•£åæ¼”æ–°æ–¹æ³•ã€‚</li>
<li>å¼•å…¥äº†ä¸€ä¸ªæ—¶é—´å’ŒåŒºåŸŸç›¸å…³çš„ Î· å‡½æ•°ï¼Œå®ç°äº†å¯¹ç¼–è¾‘ç¨‹åº¦çš„çµæ´»æ§åˆ¶ã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å®šé‡å’Œå®šæ€§è¯„ä¼°ä¸­è¡¨ç°å‡ºæ˜æ˜¾çš„ä¼˜åŠ¿ã€‚</li>
<li>æä¾›äº†å¼€æºä»£ç ï¼Œä¾¿äºç ”ç©¶è€…å’Œä»ä¸šè€…çš„ä½¿ç”¨ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸ºå›¾åƒç¼–è¾‘é¢†åŸŸè®¾å®šäº†æ–°çš„åŸºå‡†ã€‚</li>
<li>ç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨ç¼–è¾‘ä¿çœŸåº¦å’Œç›¸ä¼¼åº¦æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ã€‚</li>
<li>æ‰©æ•£åæ¼”æ–¹æ³•åœ¨æ–‡æœ¬æŒ‡å¯¼å›¾åƒç¼–è¾‘ä¸­å±•ç°äº†å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºÎ·å‡½æ•°çš„æ‰©æ•£æ¨¡å‹çœŸå®å›¾åƒç¼–è¾‘åæ¼”</li>
<li>ä½œè€…ï¼šWonjun Kangã€Kevin Galimã€Hyung Il Koo</li>
<li>éš¶å±å…³ç³»ï¼šFuriosaAI</li>
<li>å…³é”®è¯ï¼šDiffusion Modelã€Real Image Editingã€Diffusion Inversionã€Eta Function</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.09468
   Githubä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬å¼•å¯¼å›¾åƒç”Ÿæˆå’Œç¼–è¾‘é¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆåŠŸã€‚ç„¶è€Œï¼Œç°æœ‰çš„çœŸå®å›¾åƒç¼–è¾‘æ–¹æ³•åœ¨ç”Ÿæˆæ—¢å¿ å®äºæ–‡æœ¬æç¤ºåˆä¸æºå›¾åƒé«˜åº¦ç›¸ä¼¼çš„ç¼–è¾‘æ–¹é¢å­˜åœ¨å›°éš¾ã€‚
   (2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„æ‰©æ•£åæ¼”æ–¹æ³•éš¾ä»¥äº§ç”Ÿæ»¡è¶³ä¸Šè¿°è¦æ±‚çš„ç¼–è¾‘ã€‚
   (3)ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºÎ·å‡½æ•°çš„æ‰©æ•£åæ¼”æŠ€æœ¯ï¼Œé€šè¿‡å¯¹Î·å‡½æ•°ä½œç”¨çš„ç†è®ºåˆ†æï¼Œè®¾è®¡äº†ä¸€ç§æœ€ä¼˜çš„æ—¶é—´å’ŒåŒºåŸŸç›¸å…³çš„Î·å‡½æ•°ï¼Œç”¨äºDDIMé‡‡æ ·ã€‚
   (4)ï¼šæ–¹æ³•æ€§èƒ½ï¼šåœ¨çœŸå®å›¾åƒç¼–è¾‘ä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒè´¨é‡å’Œå¯¹æç¤ºçš„å“åº”èƒ½åŠ›æ–¹é¢éƒ½å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p>7.Methodsï¼š
(1) åœ¨DDIMé‡‡æ ·è¿‡ç¨‹ä¸­ï¼Œå¯¹Î·å‡½æ•°ä½œç”¨è¿›è¡Œç†è®ºåˆ†æï¼Œè®¾è®¡äº†ä¸€ç§æœ€ä¼˜çš„æ—¶é—´å’ŒåŒºåŸŸç›¸å…³çš„Î·å‡½æ•°ï¼Œä»¥æŒ‡å¯¼é‡‡æ ·è¿‡ç¨‹ï¼Œä¿è¯ç”Ÿæˆå›¾åƒçš„è´¨é‡å’Œå¯¹æç¤ºçš„å“åº”èƒ½åŠ›ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Î· å‡½æ•°çš„æ‰©æ•£åæ¼”æŠ€æœ¯ï¼Œä¸ºçœŸå®å›¾åƒç¼–è¾‘æä¾›äº†æ–°çš„æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†å›¾åƒè´¨é‡å’Œå¯¹æç¤ºçš„å“åº”èƒ½åŠ›ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
<li>ç†è®ºåˆ†æ Î· å‡½æ•°ä½œç”¨ï¼Œè®¾è®¡æœ€ä¼˜çš„æ—¶é—´å’ŒåŒºåŸŸç›¸å…³ Î· å‡½æ•°ã€‚</li>
<li>æå‡ºç»Ÿä¸€çš„æ‰©æ•£åæ¼”æ¡†æ¶ï¼Œå®ç°çœŸå®å›¾åƒç¼–è¾‘ã€‚</li>
<li>å¼•å…¥çµæ´»çš„åæ¼”æ–¹æ³•ï¼Œæå‡ç¼–è¾‘æ•ˆæœã€‚
æ€§èƒ½ï¼š</li>
<li>çœŸå®å›¾åƒç¼–è¾‘ä»»åŠ¡ä¸­ï¼Œå›¾åƒè´¨é‡å’Œå¯¹æç¤ºçš„å“åº”èƒ½åŠ›å‡è¡¨ç°ä¼˜å¼‚ã€‚</li>
<li>éªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ç†è®ºåˆ†æå’Œæ–¹æ³•è®¾è®¡è¾ƒä¸ºå¤æ‚ã€‚</li>
<li>éœ€è¦è¿›ä¸€æ­¥æ¢ç´¢ Î· å‡½æ•°åœ¨å…¶ä»–æ‰©æ•£æ¨¡å‹ä¸­çš„åº”ç”¨ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2852c496a7b0ab79267d32e6de70a2be.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-24163aa99363a4f0c70cd91562f27e51.jpg" align="middle">
</details>




<h2 id="Shake-to-Leak-Fine-tuning-Diffusion-Models-Can-Amplify-the-Generative-Privacy-Risk"><a href="#Shake-to-Leak-Fine-tuning-Diffusion-Models-Can-Amplify-the-Generative-Privacy-Risk" class="headerlink" title="Shake to Leak: Fine-tuning Diffusion Models Can Amplify the Generative   Privacy Risk"></a>Shake to Leak: Fine-tuning Diffusion Models Can Amplify the Generative   Privacy Risk</h2><p><strong>Authors:Zhangheng Li, Junyuan Hong, Bo Li, Zhangyang Wang</strong></p>
<p>While diffusion models have recently demonstrated remarkable progress in generating realistic images, privacy risks also arise: published models or APIs could generate training images and thus leak privacy-sensitive training information. In this paper, we reveal a new risk, Shake-to-Leak (S2L), that fine-tuning the pre-trained models with manipulated data can amplify the existing privacy risks. We demonstrate that S2L could occur in various standard fine-tuning strategies for diffusion models, including concept-injection methods (DreamBooth and Textual Inversion) and parameter-efficient methods (LoRA and Hypernetwork), as well as their combinations. In the worst case, S2L can amplify the state-of-the-art membership inference attack (MIA) on diffusion models by $5.4\%$ (absolute difference) AUC and can increase extracted private samples from almost $0$ samples to $16.3$ samples on average per target domain. This discovery underscores that the privacy risk with diffusion models is even more severe than previously recognized. Codes are available at <a href="https://github.com/VITA-Group/Shake-to-Leak">https://github.com/VITA-Group/Shake-to-Leak</a>. </p>
<p><a href="http://arxiv.org/abs/2403.09450v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹ç²¾è°ƒååŒ…å«éšç§æ³„éœ²é£é™©ï¼Œæ”»å‡»è€…å¯åˆ©ç”¨æ“çºµåçš„æ•°æ®æ”¾å¤§ç§å¯†æ³„éœ²ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹ç²¾è°ƒå­˜åœ¨éšç§æ³„éœ²é£é™©ï¼ŒShake-to-Leakï¼ˆS2Lï¼‰æ”»å‡»å¯æ”¾å¤§é£é™©ã€‚</li>
<li>S2L é€‚ç”¨äºæ¦‚å¿µæ³¨å…¥æ–¹æ³•ï¼ˆDreamBooth å’Œæ–‡æœ¬åæ¼”ï¼‰ã€å‚æ•°é«˜æ•ˆæ–¹æ³•ï¼ˆLoRA å’Œ Hypernetworkï¼‰å’Œå®ƒä»¬çš„ç»„åˆã€‚</li>
<li>S2L æœ€åæƒ…å†µä¸‹å¯å°†æ‰©æ•£æ¨¡å‹ä¸­çš„æœ€å…ˆè¿›æˆå‘˜èµ„æ ¼æ¨ç†æ”»å‡» (MIA) æ”¾å¤§ 5.4%ï¼ˆç»å¯¹å·®å€¼ï¼‰AUCã€‚</li>
<li>S2L å¯å°†ç›®æ ‡åŸŸä¸­æå–åˆ°çš„ç§æœ‰æ ·æœ¬ä»å‡ ä¹ 0 ä¸ªå¢åŠ åˆ°å¹³å‡ 16.3 ä¸ªã€‚</li>
<li>æ‰©æ•£æ¨¡å‹çš„éšç§é£é™©æ¯”å…ˆå‰è®¤è¯†åˆ°çš„æ›´åŠ ä¸¥é‡ã€‚</li>
<li>ç ”ç©¶ä»£ç å¯ä» Github è®¿é—®ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li><strong>è®ºæ–‡æ ‡é¢˜ï¼š</strong> éœ‡è¡æ³„éœ²ï¼šå¾®è°ƒæ‰©æ•£æ¨¡å‹å¯ä»¥æ”¾å¤§ç”Ÿæˆéšç§é£é™©</li>
<li><strong>ä½œè€…ï¼š</strong> å¼ æ’æã€ä¿Šå…ƒæ´ªã€æ³¢æã€å¼ æ‰¬ç‹</li>
<li><strong>ç¬¬ä¸€ä½œè€…å•ä½ï¼š</strong> å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡</li>
<li><strong>å…³é”®è¯ï¼š</strong> æ·±åº¦å­¦ä¹ ã€ç”Ÿæˆæ¨¡å‹ã€æ‰©æ•£æ¨¡å‹ã€éšç§é£é™©ã€å¾®è°ƒ</li>
<li><strong>è®ºæ–‡é“¾æ¥ï¼š</strong> https://arxiv.org/abs/2403.09450</li>
<li><strong>æ‘˜è¦ï¼š</strong>
   (1) <strong>ç ”ç©¶èƒŒæ™¯ï¼š</strong> æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆé€¼çœŸçš„å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä¹Ÿå¸¦æ¥äº†éšç§é£é™©ï¼šå·²å‘å¸ƒçš„æ¨¡å‹æˆ– API å¯èƒ½ä¼šç”Ÿæˆè®­ç»ƒå›¾åƒï¼Œä»è€Œæ³„éœ²éšç§æ•æ„Ÿçš„è®­ç»ƒä¿¡æ¯ã€‚
   (2) <strong>è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š</strong> ä¹‹å‰çš„ç ”ç©¶è°ƒæŸ¥äº†é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„æ•æ„Ÿæ€§ï¼Œä½†æ²¡æœ‰è€ƒè™‘å¾®è°ƒåçš„æ¨¡å‹ã€‚
   (3) <strong>ç ”ç©¶æ–¹æ³•ï¼š</strong> æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ”»å‡»ç­–ç•¥â€œéœ‡è¡æ³„éœ²â€ï¼ˆS2Lï¼‰ï¼Œè¯¥ç­–ç•¥é€šè¿‡ä½¿ç”¨æ“çºµæ•°æ®å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹æ¥æ”¾å¤§éšç§é£é™©ã€‚
   (4) <strong>æ–¹æ³•æ€§èƒ½ï¼š</strong> S2L å¯ä»¥æ”¾å¤§æ‰©æ•£æ¨¡å‹ä¸Šæœ€å…ˆè¿›çš„æˆå‘˜æ¨ç†æ”»å‡»ï¼ˆMIAï¼‰ 5.4%ï¼ˆç»å¯¹å·®å€¼ï¼‰AUCï¼Œå¹¶ä¸”å¯ä»¥å°†æå–çš„ç§æœ‰æ ·æœ¬ä»æ¯ä¸ªç›®æ ‡åŸŸçš„å‡ ä¹ 0 ä¸ªæ ·æœ¬å¢åŠ åˆ°å¹³å‡ 16.3 ä¸ªæ ·æœ¬ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)ç”Ÿæˆæ•°æ®ï¼›ï¼ˆ2ï¼‰å¾®è°ƒï¼›ï¼ˆ3ï¼‰éšç§æ”»å‡»</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæ­ç¤ºäº†ä¸€ä¸ªæ„æƒ³ä¸åˆ°çš„å‘ç°ï¼šå¾®è°ƒç»è¿‡å¤„ç†çš„æ•°æ®é›†å¯ä»¥æ”¾å¤§ç°æœ‰ç”¨äºæ–‡æœ¬åˆ°å›¾åƒåˆæˆçš„å¤§è§„æ¨¡æ‰©æ•£æ¨¡å‹çš„éšç§é£é™©ã€‚åˆ©ç”¨ DM çš„æ–‡æœ¬åˆ°å›¾åƒåˆæˆæœºåˆ¶ï¼Œæ”»å‡»è€…å¯ä»¥æç¤º DM ä¸ºç›®æ ‡æ•°æ®é›†ç”Ÿæˆå›¾åƒï¼Œå¹¶ä½¿ç”¨è¯¥æ•°æ®é›†å¾®è°ƒ DMï¼Œä»è€Œä»é¢„è®­ç»ƒé›†ä¸­æ³„éœ²æ›´å¤šä¿¡æ¯ã€‚é€šè¿‡ç³»ç»Ÿåˆ†æï¼Œæˆ‘ä»¬å¼ºè°ƒäº†åœ¨æ‰©æ•£æ¨¡å‹çš„åº”ç”¨å’Œæ”¹è¿›ä¸­éœ€è¦è°¨æ…ï¼Œå¹¶å»ºè®®ç¤¾åŒºå¿…é¡»è€ƒè™‘æ–°çš„ä¿æŠ¤æªæ–½æ¥ä¿æŠ¤éšç§ã€‚æˆ‘ä»¬çš„å‘ç°ä¸ºå…³äºæ¨¡å‹æ€§èƒ½å’Œéšç§ä¹‹é—´æƒè¡¡çš„æŒç»­è®¨è®ºè´¡çŒ®äº†æ–°çš„è§†è§’ï¼Œä¸ºè¯¥é¢†åŸŸçš„çš„ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚æˆ‘ä»¬è¿˜ç•™å¾…æœªæ¥çš„å·¥ä½œæ¢ç´¢åœ¨å¤§å‹ DM ä¸ŠåŸºäºåŸç†çš„å·®åˆ†éšç§ (DP) ä¿è¯ [9]ï¼Œå› ä¸ºç›®å‰ç”±äº DP-SGD ç§æœ‰è®­ç»ƒæ­¥éª¤ [1] ä¸Šçš„æ‰©å±•é—®é¢˜ï¼ŒDP éš¾ä»¥åº”ç”¨äºå¤§å‹ç”Ÿæˆæ¨¡å‹ã€‚
ç‰ˆæƒé£é™©çš„æ‰©å±•ã€‚æ­£å¦‚ [6] æ‰€è¯æ˜çš„ï¼Œç½‘ç»œæŠ“å–å›¾åƒç”Ÿæˆæ•°æ®é›†ï¼ˆå¦‚ LAION æ•°æ®é›†ï¼‰åŒ…å«æ˜¾å¼éè®¸å¯ç‰ˆæƒç¤ºä¾‹ã€ä¸€èˆ¬ç‰ˆæƒä¿æŠ¤ç¤ºä¾‹å’Œ CC BY-SA è®¸å¯ç¤ºä¾‹çš„æ··åˆã€‚è¿™å¼•å‘äº†å¯¹ç‰ˆæƒé£é™©çš„æ‹…å¿§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åªè®¨è®ºäº†éšç§é£é™©ï¼Œç„¶è€Œï¼Œæˆ‘ä»¬æ³¨æ„åˆ° S2L ä¹Ÿå¯èƒ½æ”¾å¤§ç‰ˆæƒé£é™©ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬è¯æ˜ S2L å¯ä»¥å®ç°æ˜¾ç€çš„æ•°æ®æå–ç»“æœï¼Œå¹¶å¯èƒ½å¯¹ DM é¢„è®­ç»ƒé›†ä¸­å—ç‰ˆæƒä¿æŠ¤çš„å›¾åƒæ„æˆå¨èƒã€‚
ç¤¾ä¼šå½±å“ã€‚æˆ‘ä»¬å¯¹ S2L ç°è±¡çš„æ¢ç´¢å¹¶ä¸æ˜¯å¯¹åˆ©ç”¨è¿™äº›æ¼æ´çš„è®¤å¯æˆ–é¼“åŠ±ã€‚ç›¸åï¼Œé€šè¿‡æ­ç¤ºè¿™äº›æ½œåœ¨å¨èƒï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åŸ¹å…»ä¸€ç§ç§¯æä¸»åŠ¨çš„æ–¹æ³•æ¥è§£å†³è¿™äº›å¨èƒã€‚è™½ç„¶æˆ‘ä»¬å‘ç°çš„ç›´æ¥å½±å“å¯èƒ½çœ‹èµ·æ¥ä»¤äººæ‹…å¿§ï¼Œä½†æˆ‘ä»¬æ‰“ç®—åŠ å¼ºç°æœ‰çš„é˜²å¾¡æœºåˆ¶ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬æä¾›äº†å‡ ç§å¯èƒ½çš„é˜²å¾¡æ–¹æ³•æ¥æ¿€åŠ±æœªæ¥çš„ç ”ç©¶ï¼š
â¶ ä½¿ç”¨ DP æœºåˆ¶å¯¹ DM è¿›è¡Œé¢„è®­ç»ƒã€‚
â· å¯¹äºéƒ¨åˆ†ç§æœ‰çš„é¢„è®­ç»ƒæ•°æ®é›†ï¼Œé¦–å…ˆåœ¨å…¬å…±é¢†åŸŸå¯¹ DM è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶ååœ¨ç§æœ‰é¢†åŸŸå¯¹ DM è¿›è¡Œç§æœ‰å¾®è°ƒ [34]ã€‚
â¸ åœ¨æ¨¡å‹æä¾›è€…æ–¹é¢ï¼Œå¼€å‘å®‰å…¨çš„å¾®è°ƒ API ä»¥é˜²æ­¢ç±»ä¼¼ S2L çš„æ»¥ç”¨ã€‚
è‡´è°¢ï¼šZ.Wang çš„å·¥ä½œéƒ¨åˆ†å¾—åˆ°äº† GoodSystems çš„æ”¯æŒï¼ŒGoodSystems æ˜¯å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡å‘å±•è´Ÿè´£ä»» AI çš„ä¸€é¡¹é‡å¤§æŒ‘æˆ˜
(2):
åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„æ”»å‡»ç­–ç•¥â€œéœ‡è¡æ³„éœ²â€ï¼ˆS2Lï¼‰ï¼Œè¯¥ç­–ç•¥é€šè¿‡ä½¿ç”¨æ“çºµæ•°æ®å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹æ¥æ”¾å¤§éšç§é£é™©ã€‚
æ€§èƒ½ï¼š</li>
<li>S2L å¯ä»¥æ”¾å¤§æ‰©æ•£æ¨¡å‹ä¸Šæœ€å…ˆè¿›çš„æˆå‘˜æ¨ç†æ”»å‡» (MIA) 5.4%ï¼ˆç»å¯¹å·®å€¼ï¼‰AUCï¼Œå¹¶ä¸”å¯ä»¥å°†æå–çš„ç§æœ‰æ ·æœ¬ä»æ¯ä¸ªç›®æ ‡åŸŸçš„å‡ ä¹ 0 ä¸ªæ ·æœ¬å¢åŠ åˆ°å¹³å‡ 16.3 ä¸ªæ ·æœ¬ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œå¹¶ä¸”å¯ä»¥åœ¨å„ç§æ‰©æ•£æ¨¡å‹å’Œæ•°æ®é›†ä¸Šè½»æ¾å¤åˆ¶ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-1f9f291a1c0e930d4bbc57cf38bb03ac.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-58f61b9f69754e9167a7838a870b0391.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-e94387dd9f0f7abd64a38ead4cb2f8c0.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-55e6c7188423f77ecb507050de7b95d3.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>3DGS</title>
    <url>/2024/03/18/Paper/2024-03-18/3DGS/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-18-æ›´æ–°"><a href="#2024-03-18-æ›´æ–°" class="headerlink" title="2024-03-18 æ›´æ–°"></a>2024-03-18 æ›´æ–°</h1><h2 id="SWAG-Splatting-in-the-Wild-images-with-Appearance-conditioned-Gaussians"><a href="#SWAG-Splatting-in-the-Wild-images-with-Appearance-conditioned-Gaussians" class="headerlink" title="SWAG: Splatting in the Wild images with Appearance-conditioned Gaussians"></a>SWAG: Splatting in the Wild images with Appearance-conditioned Gaussians</h2><p><strong>Authors:Hiba Dahmani, Moussab Bennehar, Nathan Piasco, Luis Roldao, Dzmitry Tsishkou</strong></p>
<p>Implicit neural representation methods have shown impressive advancements in learning 3D scenes from unstructured in-the-wild photo collections but are still limited by the large computational cost of volumetric rendering. More recently, 3D Gaussian Splatting emerged as a much faster alternative with superior rendering quality and training efficiency, especially for small-scale and object-centric scenarios. Nevertheless, this technique suffers from poor performance on unstructured in-the-wild data. To tackle this, we extend over 3D Gaussian Splatting to handle unstructured image collections. We achieve this by modeling appearance to seize photometric variations in the rendered images. Additionally, we introduce a new mechanism to train transient Gaussians to handle the presence of scene occluders in an unsupervised manner. Experiments on diverse photo collection scenes and multi-pass acquisition of outdoor landmarks show the effectiveness of our method over prior works achieving state-of-the-art results with improved efficiency. </p>
<p><a href="http://arxiv.org/abs/2403.10427v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>æ‰©å±•3Dé«˜æ–¯æ”¾å°„æŠ€æœ¯ä»¥å¤„ç†æ— ç»“æ„å›¾åƒé›†ï¼Œé€šè¿‡å»ºæ¨¡å¤–è§‚å’Œè®­ç»ƒç¬æ€é«˜æ–¯å‡½æ•°ï¼Œæé«˜äº†æ€§èƒ½å’Œæ•ˆç‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>3Dé«˜æ–¯æ”¾å°„æŠ€æœ¯æ˜¯ä¸€ç§å¿«é€Ÿçš„3Dåœºæ™¯æ¸²æŸ“æ–¹æ³•ã€‚</li>
<li>æ‰©å±•3Dé«˜æ–¯æ”¾å°„æŠ€æœ¯ä»¥å¤„ç†æ— ç»“æ„å›¾åƒé›†ã€‚</li>
<li>å»ºæ¨¡å¤–è§‚ä»¥æ•æ‰æ¸²æŸ“å›¾åƒä¸­çš„å…‰åº¦å˜åŒ–ã€‚</li>
<li>å¼•å…¥æ–°æœºåˆ¶æ¥è®­ç»ƒç¬æ€é«˜æ–¯å‡½æ•°ï¼Œä»¥æ— ç›‘ç£æ–¹å¼å¤„ç†åœºæ™¯é®æŒ¡ã€‚</li>
<li>åœ¨å„ç§ç…§ç‰‡é›†åœºæ™¯å’Œæˆ·å¤–åœ°æ ‡çš„å¤šé€šé“é‡‡é›†ä¸­ï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœå’Œæ›´é«˜çš„æ•ˆç‡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šSWAGï¼šåœ¨é‡å›¾åƒä¸­åˆ©ç”¨å¤–è§‚æ¡ä»¶é«˜æ–¯è¿›è¡Œæ³¼æº…</li>
<li>ä½œè€…ï¼šHiba Dahmaniã€Moussab Benneharã€Nathan Piascoã€Luis RoldËœaoã€Dzmitry Tsishkou</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè¯ºäºšæ–¹èˆŸï¼Œåä¸ºå·´é»ç ”ç©¶ä¸­å¿ƒï¼Œæ³•å›½</li>
<li>å…³é”®è¯ï¼š3D é«˜æ–¯æ³¼æº…Â·æ— çº¦æŸç…§ç‰‡é›†Â·æ–°è§†è§’åˆæˆÂ·å¤–è§‚å»ºæ¨¡Â·å®æ—¶æ¸²æŸ“Â·ç¬æ€å¯¹è±¡ç§»é™¤</li>
<li>è®ºæ–‡é“¾æ¥ï¼šarXiv:2403.10427v1[cs.CV]</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šéšå¼ç¥ç»è¡¨ç¤ºæ–¹æ³•åœ¨ä»æ— çº¦æŸçš„é‡å¤–ç…§ç‰‡é›†ä¸­å­¦ä¹  3D åœºæ™¯æ–¹é¢å–å¾—äº†ä»¤äººç©ç›®çš„è¿›å±•ï¼Œä½†ä»ç„¶å—åˆ°ä½“ç§¯æ¸²æŸ“çš„é«˜è®¡ç®—æˆæœ¬çš„é™åˆ¶ã€‚æœ€è¿‘ï¼Œ3D é«˜æ–¯æ³¼æº…ä½œä¸ºä¸€ç§æ›´å¿«çš„æ›¿ä»£æ–¹æ¡ˆå‡ºç°ï¼Œå…·æœ‰å“è¶Šçš„æ¸²æŸ“è´¨é‡å’Œè®­ç»ƒæ•ˆç‡ï¼Œå°¤å…¶é€‚ç”¨äºå°è§„æ¨¡å’Œä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„åœºæ™¯ã€‚ç„¶è€Œï¼Œè¯¥æŠ€æœ¯åœ¨æ— çº¦æŸçš„é‡å¤–æ•°æ®ä¸Šè¡¨ç°ä¸ä½³ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡å°† 3D é«˜æ–¯æ³¼æº…æ‰©å±•åˆ°å¤„ç†æ— ç»“æ„å›¾åƒé›†ã€‚é€šè¿‡å¯¹å¤–è§‚è¿›è¡Œå»ºæ¨¡æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œä»¥æ•æ‰æ¸²æŸ“å›¾åƒä¸­çš„å…‰åº¦å˜åŒ–ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ç§æ–°çš„æœºåˆ¶æ¥è®­ç»ƒç¬æ€é«˜æ–¯ï¼Œä»¥ä¾¿ä»¥æ— ç›‘ç£çš„æ–¹å¼å¤„ç†åœºæ™¯é®æŒ¡ç‰©çš„å­˜åœ¨ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šåœ¨ä¸åŒçš„ç…§ç‰‡é›†åœºæ™¯å’Œæˆ·å¤–åœ°æ ‡çš„å¤šéé‡‡é›†ä¸­è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•æ¯”ä»¥å‰çš„å·¥ä½œæ›´æœ‰æ•ˆï¼Œåœ¨æé«˜æ•ˆç‡çš„åŒæ—¶å®ç°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼Ÿæ€§èƒ½æ˜¯å¦èƒ½æ”¯æŒå…¶ç›®æ ‡ï¼Ÿæœ¬æ–‡çš„æ–¹æ³•åœ¨æ— çº¦æŸç…§ç‰‡é›†ä¸Šçš„æ–°è§†è§’åˆæˆä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶æé«˜äº†æ•ˆç‡ã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³æ‰©å±• 3D é«˜æ–¯æ³¼æº…ä»¥å¤„ç†æ— çº¦æŸçš„å›¾åƒé›†ï¼Œå¹¶æé«˜å…¶åœ¨é‡å¤–åœºæ™¯ä¸­çš„æ€§èƒ½ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)å¤–è§‚å»ºæ¨¡ï¼šä¸ºé€‚åº”å…‰åº¦å˜åŒ–ï¼Œä¸ºæ¯å¼ å›¾åƒå…³è”ä¸€ä¸ªå¯è®­ç»ƒåµŒå…¥å‘é‡lIï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ªMLPæ¥æ³¨å…¥å¤–è§‚ä¿¡æ¯ï¼Œè¯¥MLPä»¥å›¾åƒåµŒå…¥å’Œé«˜æ–¯ä¸­å¿ƒçš„ä½ç½®ç¼–ç ä¸ºè¾“å…¥ï¼Œè¾“å‡ºå›¾åƒç›¸å…³çš„é¢œè‰²cIå’Œå›¾åƒç›¸å…³çš„é€æ˜åº¦å˜åŒ–å‚æ•°âˆ†Î±Iï¼›(2)ç¬æ€é«˜æ–¯å»ºæ¨¡ï¼šä¸ºè§£å†³ç¬æ€é®æŒ¡ç‰©é—®é¢˜ï¼Œå¼•å…¥å¯å­¦ä¹ çš„å›¾åƒç›¸å…³é«˜æ–¯é€æ˜åº¦å˜åŒ–é¡¹âˆ†ËœÎ±Iï¼Œè¯¥å‚æ•°å…è®¸é«˜æ–¯é‡å»ºæŸäº›å›¾åƒä¸­å­˜åœ¨çš„é®æŒ¡ç‰©ï¼ŒåŒæ—¶å…è®¸è¿™äº›ç›¸åŒçš„é«˜æ–¯åœ¨æ²¡æœ‰é®æŒ¡ç‰©çš„å…¶ä»–å›¾åƒä¸­ä¿æŒé€æ˜ï¼›(3)è®­ç»ƒè¿‡ç¨‹ï¼šä½¿ç”¨Binary Concreteéšæœºå˜é‡å¯¹âˆ†ËœÎ±Iè¿›è¡Œé‡‡æ ·ï¼Œå¹¶ä½¿ç”¨MLPçš„é™„åŠ è¾“å‡ºâˆ†Î±Iä½œä¸ºConcreteå‡½æ•°çš„ä½ç½®å‚æ•°ã€‚</p>
<ol>
<li>ç»“è®ºï¼š(1) æœ¬æ–‡æå‡ºäº† SWAGï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨ä¸ºé‡å¤–åœºæ™¯å®šåˆ¶ 3D é«˜æ–¯è¡¨ç¤ºçš„æ–¹æ³•ã€‚SWAG åœ¨é«˜æ–¯çš„é¢œè‰²ä¸­èå…¥äº†å¤–è§‚å»ºæ¨¡ï¼Œå¹¶é‡‡ç”¨äº†è‡ªé€‚åº”ä¸é€æ˜åº¦è°ƒåˆ¶æ¥å¤„ç†ç¬æ€å¯¹è±¡çš„å­˜åœ¨ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSWAG åœ¨ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼ŒåŒæ—¶è®­ç»ƒæ—¶é—´æ¯”é‡å¤– NVS åŸºçº¿å¿«å‡ ä¸ªæ•°é‡çº§ï¼ŒåŒæ—¶æ”¯æŒå®æ—¶æ¸²æŸ“ã€‚ä½œä¸ºå°† 3D é«˜æ–¯åº”ç”¨äºé‡å¤–åœºæ™¯è¡¨ç¤ºçš„ç¬¬ä¸€æ­¥ï¼Œè¿™é¡¹å·¥ä½œæå‡ºäº†æ½œåœ¨çš„æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä¾‹å¦‚å°† SWAG æ‰©å±•åˆ°åŠ¨æ€åœºæ™¯ä¸­ã€‚(2) åˆ›æ–°ç‚¹ï¼šSWAG åˆ›æ–°æ€§åœ°å°†å¤–è§‚å»ºæ¨¡èå…¥ 3D é«˜æ–¯è¡¨ç¤ºä¸­ï¼Œå¹¶å¼•å…¥è‡ªé€‚åº”ä¸é€æ˜åº¦è°ƒåˆ¶æœºåˆ¶æ¥å¤„ç†ç¬æ€é®æŒ¡ç‰©ï¼Œæ˜¾è‘—æé«˜äº†é‡å¤–åœºæ™¯çš„è¡¨ç¤ºèƒ½åŠ›ï¼›æ€§èƒ½ï¼šåœ¨æ— çº¦æŸç…§ç‰‡é›†ä¸Šçš„æ–°è§†è§’åˆæˆä»»åŠ¡ä¸­ï¼ŒSWAG å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶å°†æ¸²æŸ“æ•ˆç‡æé«˜äº†å‡ ä¸ªæ•°é‡çº§ï¼›å·¥ä½œé‡ï¼šSWAG çš„è®­ç»ƒæ—¶é—´æ¯”é‡å¤– NVS åŸºçº¿å¿«å‡ ä¸ªæ•°é‡çº§ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿›è¡Œå®æ—¶æ¸²æŸ“ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-42d3d97d6fe30ac46eae820ba89402c1.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-6fd5515fed7d2c4f632ef0b06ec7a029.jpg" align="middle">
</details>




<h2 id="FDGaussian-Fast-Gaussian-Splatting-from-Single-Image-via-Geometric-aware-Diffusion-Model"><a href="#FDGaussian-Fast-Gaussian-Splatting-from-Single-Image-via-Geometric-aware-Diffusion-Model" class="headerlink" title="FDGaussian: Fast Gaussian Splatting from Single Image via   Geometric-aware Diffusion Model"></a>FDGaussian: Fast Gaussian Splatting from Single Image via   Geometric-aware Diffusion Model</h2><p><strong>Authors:Qijun Feng, Zhen Xing, Zuxuan Wu, Yu-Gang Jiang</strong></p>
<p>Reconstructing detailed 3D objects from single-view images remains a challenging task due to the limited information available. In this paper, we introduce FDGaussian, a novel two-stage framework for single-image 3D reconstruction. Recent methods typically utilize pre-trained 2D diffusion models to generate plausible novel views from the input image, yet they encounter issues with either multi-view inconsistency or lack of geometric fidelity. To overcome these challenges, we propose an orthogonal plane decomposition mechanism to extract 3D geometric features from the 2D input, enabling the generation of consistent multi-view images. Moreover, we further accelerate the state-of-the-art Gaussian Splatting incorporating epipolar attention to fuse images from different viewpoints. We demonstrate that FDGaussian generates images with high consistency across different views and reconstructs high-quality 3D objects, both qualitatively and quantitatively. More examples can be found at our website <a href="https://qjfeng.net/FDGaussian/">https://qjfeng.net/FDGaussian/</a>. </p>
<p><a href="http://arxiv.org/abs/2403.10242v1">PDF</a> </p>
<p><strong>Summary</strong><br>FDGaussian æ˜¯ä¸€ç§æ–°é¢–çš„å•å›¾åƒ 3D é‡å»ºæ¡†æ¶ï¼Œå®ƒåˆ©ç”¨æ­£äº¤å¹³é¢åˆ†è§£æœºåˆ¶ä» 2D è¾“å…¥ä¸­æå– 3D å‡ ä½•ç‰¹å¾ä»¥ç”Ÿæˆä¸€è‡´çš„å¤šè§†å›¾å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>FDGaussian æ¡†æ¶ç”¨äºä»å•è§†å›¾å›¾åƒé‡å»ºè¯¦ç»†çš„ 3D å¯¹è±¡ã€‚</li>
<li>è¯¥æ¡†æ¶ä½¿ç”¨æ­£äº¤å¹³é¢åˆ†è§£æœºåˆ¶ä» 2D è¾“å…¥ä¸­æå– 3D å‡ ä½•ç‰¹å¾ã€‚</li>
<li>è¯¥æ–¹æ³•åˆ©ç”¨æœ€æ–°çš„é«˜æ–¯å–·ç»˜æŠ€æœ¯å¹¶ç»“åˆæçº¿æ³¨æ„åŠ›æ¥èåˆæ¥è‡ªä¸åŒè§†ç‚¹çš„å›¾åƒã€‚</li>
<li>ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFDGaussian ç”Ÿæˆçš„å›¾åƒå…·æœ‰æ›´é«˜çš„è·¨è§†å›¾ä¸€è‡´æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•é‡å»ºçš„é«˜è´¨é‡ 3D å¯¹è±¡åœ¨è´¨é‡å’Œæ•°é‡ä¸Šéƒ½ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚</li>
<li>æœ‰å…³æ›´å¤šç¤ºä¾‹ï¼Œè¯·è®¿é—®é¡¹ç›®ç½‘ç«™ <a href="https://qjfeng.net/FDGaussian/ã€‚">https://qjfeng.net/FDGaussian/ã€‚</a></li>
<li>FDGaussian æ¡†æ¶æé«˜äº†å•å›¾åƒ 3D é‡å»ºçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šFDGaussianï¼šé€šè¿‡å•å¼ å›¾åƒè¿›è¡Œå¿«é€Ÿé«˜æ–¯æ¸²æŸ“</li>
<li>ä½œè€…ï¼šå†¯å¯å†›1ï¼Œé‚¢æŒ¯1ï¼Œå´ç¥–å®£1ï¼Œå§œå®‡åˆš1</li>
<li>éš¶å±å•ä½ï¼šå¤æ—¦å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3Dé‡å»º Â· é«˜æ–¯æ¸²æŸ“ Â· æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.10242</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šä»å•è§†å›¾å›¾åƒé‡å»ºè¯¦ç»†çš„ 3D ç‰©ä½“ä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå› ä¸ºå¯ç”¨çš„ä¿¡æ¯æœ‰é™ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šæœ€è¿‘çš„æ–¹æ³•é€šå¸¸åˆ©ç”¨é¢„è®­ç»ƒçš„ 2D æ‰©æ•£æ¨¡å‹ä»è¾“å…¥å›¾åƒç”Ÿæˆåˆç†çš„ novel viewï¼Œä½†å®ƒä»¬é‡åˆ°å¤šè§†å›¾ä¸ä¸€è‡´æˆ–ç¼ºä¹å‡ ä½•ä¿çœŸåº¦çš„é—®é¢˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ­£äº¤å¹³é¢åˆ†è§£æœºåˆ¶ï¼Œä» 2D è¾“å…¥ä¸­æå– 3D å‡ ä½•ç‰¹å¾ï¼Œä»è€Œç”Ÿæˆä¸€è‡´çš„å¤šè§†å›¾å›¾åƒã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡ç»“åˆæçº¿æ³¨æ„åŠ›è¿›ä¸€æ­¥åŠ é€Ÿäº†æœ€å…ˆè¿›çš„é«˜æ–¯æ¸²æŸ“ï¼Œä»¥èåˆæ¥è‡ªä¸åŒè§†ç‚¹çš„å›¾åƒã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šæˆ‘ä»¬è¯æ˜äº† FDGaussian ç”Ÿæˆçš„å›¾åƒåœ¨ä¸åŒè§†å›¾ä¹‹é—´å…·æœ‰é«˜åº¦ä¸€è‡´æ€§ï¼Œå¹¶é‡å»ºäº†é«˜è´¨é‡çš„ 3D ç‰©ä½“ï¼Œæ— è®ºæ˜¯åœ¨å®šæ€§ä¸Šè¿˜æ˜¯å®šé‡ä¸Šã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰åŸºäºå‡ ä½•ç‰¹å¾çš„å¤šè§†å›¾å›¾åƒç”Ÿæˆï¼šå¾®è°ƒé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨ç»™å®šçš„ç›¸æœºå˜æ¢åˆæˆæ–°é¢–å›¾åƒï¼Œå·²å–å¾—æœ‰å¸Œæœ›çš„ç»“æœã€‚ä¸€éƒ¨åˆ†æ–¹æ³•é€šè¿‡è°ƒèŠ‚å…ˆå‰ç”Ÿæˆçš„å›¾åƒæ¥è§£å†³å¤šè§†å›¾ä¸ä¸€è‡´é—®é¢˜ï¼Œä½†å®¹æ˜“å‡ºç°ç´¯ç§¯è¯¯å·®å’Œé™ä½å¤„ç†é€Ÿåº¦çš„é—®é¢˜ã€‚å¦ä¸€éƒ¨åˆ†æ–¹æ³•ä»…ä½¿ç”¨å‚è€ƒå›¾åƒå’Œè¯­ä¹‰æŒ‡å¯¼ç”Ÿæˆæ–°é¢–è§†å›¾ï¼Œä½†å­˜åœ¨å‡ ä½•åç¼©å’Œä¿çœŸåº¦æœ‰é™çš„é—®é¢˜ã€‚æˆ‘ä»¬è®¤ä¸ºå…³é”®åœ¨äºå……åˆ†åˆ©ç”¨å‚è€ƒå›¾åƒæä¾›çš„å‡ ä½•ä¿¡æ¯ã€‚ç„¶è€Œï¼Œç›´æ¥ä»å•ä¸ª 2D å›¾åƒä¸­æå– 3D ä¿¡æ¯æ˜¯ä¸å¯è¡Œçš„ã€‚å› æ­¤ï¼Œå¿…é¡»é€šè¿‡è§£è€¦æ­£äº¤å¹³é¢æ¥æœ‰æ•ˆåœ°ä»å›¾åƒå¹³é¢ï¼ˆå³ xy å¹³é¢ï¼‰ä¸­åˆ†ç¦» 3D ç‰¹å¾ã€‚æˆ‘ä»¬é¦–å…ˆé‡‡ç”¨è§†è§‰ Transformer å¯¹è¾“å…¥å›¾åƒè¿›è¡Œç¼–ç å¹¶æ•è·å›¾åƒä¸­çš„æ•´ä½“ç›¸å…³æ€§ï¼Œç”Ÿæˆé«˜ç»´æ½œåœ¨è¡¨ç¤ºã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ©ç”¨ä¸¤ä¸ªè§£ç å™¨ï¼ˆå›¾åƒå¹³é¢è§£ç å™¨å’Œæ­£äº¤å¹³é¢è§£ç å™¨ï¼‰ä»æ½œåœ¨è¡¨ç¤ºä¸­ç”Ÿæˆå…·æœ‰å‡ ä½•æ„ŸçŸ¥çš„ç‰¹å¾ã€‚å›¾åƒå¹³é¢è§£ç å™¨é€†è½¬ç¼–ç æ“ä½œï¼Œå¯¹ç¼–ç å™¨è¾“å‡ºä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å¹¶å°†å…¶è½¬æ¢ä¸º Fxyã€‚ä¸ºäº†ç”Ÿæˆæ­£äº¤å¹³é¢ç‰¹å¾ï¼ŒåŒæ—¶ä¿æŒä¸å›¾åƒå¹³é¢çš„ç»“æ„å¯¹é½ï¼Œé‡‡ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å¯¹ yz å¹³é¢ç‰¹å¾ Fyz å’Œ xz å¹³é¢ç‰¹å¾ Fxz è¿›è¡Œè§£ç ã€‚ä¸ºäº†ä¿ƒè¿›ä¸åŒå¹³é¢ä¹‹é—´çš„è§£ç è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå¯å­¦ä¹ çš„åµŒå…¥ uï¼Œå®ƒä¸ºè§£è€¦æ–°å¹³é¢æä¾›äº†é™„åŠ ä¿¡æ¯ã€‚å¯å­¦ä¹ çš„åµŒå…¥ u é¦–å…ˆé€šè¿‡è‡ªæ³¨æ„åŠ›ç¼–ç å¤„ç†ï¼Œç„¶ååœ¨å…·æœ‰ç¼–ç å›¾åƒæ½œåœ¨è¡¨ç¤ºçš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ä¸­ç”¨ä½œæŸ¥è¯¢ã€‚å›¾åƒç‰¹å¾è¢«è½¬æ¢ä¸ºäº¤å‰æ³¨æ„åŠ›æœºåˆ¶çš„é”®å’Œå€¼ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
CrossAttn(u, h) = SoftMax(WQSelfAttn(u))(WKh)Tâˆšd(WVh),
å…¶ä¸­ WQã€WK å’Œ WV æ˜¯å¯å­¦ä¹ å‚æ•°ï¼Œd æ˜¯ç¼©æ”¾ç³»æ•°ã€‚æœ€åï¼Œç‰¹å¾ç»„åˆä¸ºå‡ ä½•æ¡ä»¶ï¼š
F = Fxy âŠ• (Fyz + Fxz),
å…¶ä¸­ âŠ• å’Œ + åˆ†åˆ«è¡¨ç¤ºè¿æ¥å’Œæ±‚å’Œæ“ä½œã€‚
ï¼ˆ2ï¼‰é«˜æ–¯æ¸²æŸ“é¢„å¤‡çŸ¥è¯†ï¼š3D é«˜æ–¯æ¸²æŸ“æ˜¯ä¸€ç§åŸºäºå­¦ä¹ çš„å…‰æ …åŒ–æŠ€æœ¯ï¼Œç”¨äº 3D åœºæ™¯é‡å»ºå’Œæ–°é¢–è§†å›¾åˆæˆã€‚æ¯ä¸ªé«˜æ–¯å…ƒç´ è¢«å®šä¹‰ä¸ºä¸€ä¸ªä½ç½®ï¼ˆå‡å€¼ï¼‰Âµã€ä¸€ä¸ªå®Œæ•´çš„ 3D åæ–¹å·®çŸ©é˜µ Î£ã€é¢œè‰² c å’Œä¸é€æ˜åº¦ Ïƒã€‚é«˜æ–¯å‡½æ•° G(x) å¯ä»¥è¡¨ç¤ºä¸ºï¼š
G(x) = exp(-1/2(x - Âµ)TÎ£-1(x - Âµ)).
ä¸ºäº†ç¡®ä¿ Î£ çš„æ­£åŠå®šæ€§ï¼Œåæ–¹å·®çŸ©é˜µ Î£ å¯ä»¥åˆ†è§£ä¸ºä¸€ä¸ªç”± 3D å‘é‡ s âˆˆ R3 è¡¨ç¤ºçš„ç¼©æ”¾çŸ©é˜µ S å’Œä¸€ä¸ªè¡¨ç¤ºå·®å¼‚åŒ–ä¼˜åŒ–çš„å››å…ƒæ•° q âˆˆ R4 çš„æ—‹è½¬çŸ©é˜µ Rï¼š
Î£ = RSSTRTã€‚
æ¸²æŸ“æŠ€æœ¯ï¼Œå¦‚æœ€åˆåœ¨ [21] ä¸­ä»‹ç»çš„ï¼Œæ˜¯å°†é«˜æ–¯æŠ•å½±åˆ°ç›¸æœºå›¾åƒå¹³é¢ï¼Œè¿™äº›å›¾åƒå¹³é¢è¢«ç”¨æ¥ç”Ÿæˆæ–°é¢–çš„è§†å›¾å›¾åƒã€‚ç»™å®šä¸€ä¸ªè§‚å¯Ÿå˜æ¢ Wï¼Œç›¸æœºåæ ‡ä¸­çš„åæ–¹å·®çŸ©é˜µ Î£' ç»™å‡ºä¸ºï¼š
Î£' = JWÎ£WTJTï¼Œ
å…¶ä¸­ J æ˜¯æŠ•å½±å˜æ¢çš„ä»¿å°„é€¼è¿‘çš„é›…å¯æ¯”çŸ©é˜µã€‚å°† 3D é«˜æ–¯æ˜ å°„åˆ° 2D å›¾åƒç©ºé—´åï¼Œæˆ‘ä»¬è®¡ç®—ä¸æ¯ä¸ªåƒç´ é‡å çš„ 2D é«˜æ–¯å¹¶è®¡ç®—å®ƒä»¬çš„é¢œè‰² ci å’Œä¸é€æ˜åº¦ Ïƒi è´¡çŒ®ã€‚å…·ä½“æ¥è¯´ï¼Œæ¯ä¸ªé«˜æ–¯çš„é¢œè‰²æ ¹æ®ç­‰å¼ (4) ä¸­æè¿°çš„é«˜æ–¯è¡¨ç¤ºåˆ†é…ç»™æ¯ä¸ªåƒç´ ã€‚ä¸é€æ˜åº¦æ§åˆ¶æ¯ä¸ªé«˜æ–¯çš„å½±å“ã€‚æ¯ä¸ªåƒç´ çš„é¢œè‰² Ë†C å¯ä»¥é€šè¿‡æ··åˆ N ä¸ªæœ‰åºé«˜æ–¯è·å¾—ï¼š
Ë†C = (âˆ‘iâˆˆN ciÏƒi) / (âˆ‘i-1j=1(1 - Ïƒi))ã€‚
ï¼ˆ3ï¼‰åŠ é€Ÿä¼˜åŒ–ï¼šé«˜æ–¯æ¸²æŸ“çš„ä¼˜åŒ–åŸºäºæ¸²æŸ“å’Œå°†ç»“æœå›¾åƒä¸è®­ç»ƒè§†å›¾è¿›è¡Œæ¯”è¾ƒçš„è¿ç»­è¿­ä»£ã€‚3D é«˜æ–¯æœ€åˆæ˜¯ä»ç»“æ„è¿åŠ¨ (SfM) æˆ–éšæœºé‡‡æ ·ä¸­åˆå§‹åŒ–çš„ã€‚ä¸å¯é¿å…åœ°ï¼Œç”±äº 3D åˆ° 2D æŠ•å½±çš„æ¨¡ç³Šæ€§ï¼Œå‡ ä½•å¯èƒ½è¢«é”™è¯¯æ”¾ç½®ã€‚å› æ­¤ï¼Œä¼˜åŒ–è¿‡ç¨‹éœ€è¦èƒ½å¤Ÿè‡ªé€‚åº”åœ°åˆ›å»ºå‡ ä½•ï¼Œå¹¶ä¸”å¦‚æœå‡ ä½•æ”¾ç½®ä¸æ­£ç¡®ï¼ˆç§°ä¸ºåˆ†è£‚å’Œå…‹éš†ï¼‰ï¼Œè¿˜éœ€è¦åˆ é™¤å‡ ä½•ã€‚ç„¶è€Œï¼ŒåŸå§‹å·¥ä½œ [21] æå‡ºçš„åˆ†è£‚å’Œå…‹éš†æ“ä½œå¿½ç•¥äº†ä¼˜åŒ–è¿‡ç¨‹ä¸­ 3D é«˜æ–¯ä¹‹é—´çš„è·ç¦»ï¼Œè¿™å¤§å¤§é™ä½äº†è¿‡ç¨‹é€Ÿåº¦ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œå¦‚æœä¸¤ä¸ªé«˜æ–¯å½¼æ­¤é è¿‘ï¼Œå³ä½¿ä½ç½®æ¢¯åº¦å¤§äºé˜ˆå€¼ï¼Œä¹Ÿä¸åº”å°†å®ƒä»¬åˆ†è£‚æˆ–å…‹éš†ï¼Œå› ä¸ºè¿™äº›é«˜æ–¯æ­£åœ¨æ›´æ–°å®ƒä»¬çš„ä½ç½®ã€‚æ ¹æ®ç»éªŒï¼Œåˆ†è£‚æˆ–å…‹éš†è¿™äº›é«˜æ–¯å¯¹æ¸²æŸ“è´¨é‡çš„å½±å“å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œå› ä¸ºå®ƒä»¬å½¼æ­¤å¤ªè¿‘ã€‚å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬æå‡ºé«˜æ–¯å‘æ•£æ˜¾è‘—æ€§ (GDS) ä½œä¸º 3D é«˜æ–¯è·ç¦»çš„åº¦é‡ï¼Œä»¥é¿å…ä¸å¿…è¦çš„åˆ†å‰²æˆ–å…‹éš†ï¼š
Î¥GDS(G(x1), G(x2)) = âˆ¥Âµ1 - Âµ2âˆ¥2 + tr(Î£1 + Î£2 - 2(Î£-11Î£2Î£-11)1/2),
å…¶ä¸­ Âµ1ã€Î£1ã€Âµ2ã€Î£2 æ˜¯ä¸¤ä¸ª 3D é«˜æ–¯ G(x1) å’Œ G(x2) çš„ä½ç½®å’Œåæ–¹å·®çŸ©é˜µã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬åªå¯¹ä½ç½®æ¢¯åº¦å¤§ä¸” GDS çš„ 3D é«˜æ–¯æ‰§è¡Œåˆ†å‰²å’Œå…‹éš†æ“ä½œã€‚ä¸ºäº†é¿å…ä¸ºæ¯å¯¹ 3D é«˜æ–¯è®¡ç®— GDS çš„è€—æ—¶è¿‡ç¨‹ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸¤ç§ç­–ç•¥ã€‚é¦–å…ˆï¼Œå¯¹äºæ¯ä¸ª 3D é«˜æ–¯ï¼Œæˆ‘ä»¬ä½¿ç”¨ k-æœ€è¿‘é‚» (k-NN) ç®—æ³•æ‰¾åˆ°å…¶æœ€æ¥è¿‘çš„ 3D é«˜æ–¯ï¼Œå¹¶è®¡ç®—å®ƒä»¬æ¯å¯¹çš„ GDSã€‚å› æ­¤ï¼Œæ—¶é—´å¤æ‚åº¦ä» O(N2) é™ä½åˆ° O(N)ã€‚æ­¤å¤–ï¼Œå¦‚ç¬¬ 3.2 èŠ‚æ‰€è¿°ï¼Œåæ–¹å·®çŸ©é˜µå¯ä»¥åˆ†è§£ä¸ºç¼©æ”¾çŸ©é˜µ S å’Œæ—‹è½¬çŸ©é˜µ Rï¼š
Î£ = RSSTRTã€‚
æˆ‘ä»¬åˆ©ç”¨æ—‹è½¬å’Œç¼©æ”¾çŸ©é˜µçš„å¯¹è§’å’Œæ­£äº¤æ€§è´¨æ¥ç®€åŒ–ç­‰å¼ (5) çš„è®¡ç®—ã€‚æœ‰å…³ GDS çš„è¯¦ç»†ä¿¡æ¯å°†åœ¨è¡¥å……ææ–™ä¸­è®¨è®ºã€‚
ï¼ˆ4ï¼‰å¤šè§†å›¾æ¸²æŸ“çš„æçº¿æ³¨æ„åŠ›ï¼šä»¥å‰çš„æ–¹æ³• [50, 70] é€šå¸¸ä½¿ç”¨å•ä¸ªè¾“å…¥å›¾åƒè¿›è¡Œç²—ç³™çš„é«˜æ–¯æ¸²æŸ“ï¼Œè¿™éœ€è¦åœ¨çœ‹ä¸è§çš„åŒºåŸŸè¿›ä¸€æ­¥ç»†åŒ–æˆ–é‡æ–°ç»˜åˆ¶ã€‚ç›´è§‚çš„æ€è·¯æ˜¯åˆ©ç”¨ç”Ÿæˆçš„ä¸€è‡´å¤šè§†å›¾å›¾åƒé‡å»ºé«˜è´¨é‡çš„ 3D å¯¹è±¡ã€‚ç„¶è€Œï¼Œä»…ä¾é äº¤å‰æ³¨æ„åŠ›åœ¨å¤šä¸ªè§†ç‚¹çš„å›¾åƒä¹‹é—´è¿›è¡Œé€šä¿¡æ˜¯ä¸å¤Ÿçš„ã€‚å› æ­¤ï¼Œç»™å®šä¸€ç³»åˆ—ç”Ÿæˆçš„è§†å›¾ï¼Œæˆ‘ä»¬æå‡ºäº†æçº¿æ³¨æ„åŠ›ä»¥å…è®¸ä¸åŒè§†å›¾çš„ç‰¹å¾ä¹‹é—´å…³è”ã€‚å¯¹äºç»™å®šä¸€ä¸ªè§†å›¾ä¸­çš„ç»™å®šç‰¹å¾ç‚¹ï¼Œæçº¿æ˜¯æ ¹æ®ä¸¤ä¸ªè§†å›¾ä¹‹é—´çš„å·²çŸ¥å‡ ä½•å…³ç³»ï¼Œåœ¨å¦ä¸€ä¸ªè§†å›¾ä¸­å¯¹åº”çš„ç‰¹å¾ç‚¹å¿…é¡»ä½äºè¯¥ç›´çº¿ä¸Šã€‚å®ƒä½œä¸ºä¸€ä¸ªçº¦æŸï¼Œå‡å°‘äº†åœ¨ä¸€ä¸ªè§†å›¾ä¸­å¯ä»¥å…³æ³¨å¦ä¸€ä¸ªè§†å›¾çš„æ½œåœ¨åƒç´ çš„æ•°é‡ã€‚æˆ‘ä»¬åœ¨å›¾ 4 ä¸­å±•ç¤ºäº†æçº¿å’Œæçº¿æ³¨æ„åŠ›çš„æ’å›¾ã€‚é€šè¿‡å¼ºåˆ¶æ‰§è¡Œæ­¤çº¦æŸï¼Œæˆ‘ä»¬å¯ä»¥é™åˆ¶ä¸åŒè§†å›¾ä¸­å¯¹åº”ç‰¹å¾çš„æœç´¢ç©ºé—´ï¼Œä»è€Œä½¿å…³è”è¿‡ç¨‹æ›´æœ‰æ•ˆå’Œå‡†ç¡®ã€‚è€ƒè™‘ä¸­é—´ UNet ç‰¹å¾ fsï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å®ƒåœ¨æ‰€æœ‰å…¶ä»–è§†å›¾ {ft}tÌ¸=s çš„ç‰¹å¾å›¾ä¸Šçš„å¯¹åº”æçº¿ {lt}tÌ¸=sï¼ˆæœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…è¡¥å……ææ–™ï¼‰ã€‚fs ä¸Šçš„æ¯ä¸ªç‚¹ p åªèƒ½è®¿é—®åœ¨æ¸²æŸ“è¿‡ç¨‹ä¸­ä½äºç›¸æœºå…‰çº¿ï¼ˆåœ¨å…¶ä»–è§†å›¾ä¸­ï¼‰çš„æ‰€æœ‰ç‚¹ã€‚ç„¶åï¼Œæˆ‘ä»¬ä¼°è®¡ fs ä¸­æ‰€æœ‰ä½ç½®çš„æƒé‡å›¾ï¼Œå †å è¿™äº›å›¾ï¼Œå¹¶è·å¾—æçº¿æƒé‡çŸ©é˜µ Mstã€‚æœ€åï¼Œæçº¿æ³¨æ„åŠ›å±‚ Ë†fs çš„è¾“å‡ºå¯ä»¥è¡¨ç¤ºä¸ºï¼š
Ë†fs = SoftMax(fsMTstâˆšd)Mst.
é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬æå‡ºçš„æçº¿æ³¨æ„åŠ›æœºåˆ¶ä¿ƒè¿›äº†å¤šä¸ªè§†å›¾ä¹‹é—´ç‰¹å¾çš„æœ‰æ•ˆå’Œå‡†ç¡®å…³è”ã€‚é€šè¿‡å°†æœç´¢ç©ºé—´çº¦æŸåˆ°æçº¿ä¸Šï¼Œæˆ‘ä»¬æœ‰æ•ˆåœ°é™ä½äº†è®¡ç®—æˆæœ¬å¹¶æ¶ˆé™¤äº†æ½œåœ¨çš„ä¼ªå½±ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šFDGaussian é€šè¿‡å•å¼ å›¾åƒè¿›è¡Œå¿«é€Ÿé«˜æ–¯æ¸²æŸ“ï¼Œè§£å†³äº†å¤šè§†å›¾ä¸ä¸€è‡´å’Œå‡ ä½•ä¿çœŸåº¦é—®é¢˜ï¼Œä¸ºä»å•è§†å›¾å›¾åƒé‡å»ºè¯¦ç»† 3D ç‰©ä½“æä¾›äº†æ–°çš„æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
FDGaussian æå‡ºäº†ä¸€ç§æ­£äº¤å¹³é¢åˆ†è§£æœºåˆ¶ï¼Œä» 2D è¾“å…¥ä¸­æå– 3D å‡ ä½•ç‰¹å¾ï¼Œä»è€Œç”Ÿæˆä¸€è‡´çš„å¤šè§†å›¾å›¾åƒã€‚
FDGaussian é€šè¿‡ç»“åˆæçº¿æ³¨æ„åŠ›è¿›ä¸€æ­¥åŠ é€Ÿäº†æœ€å…ˆè¿›çš„é«˜æ–¯æ¸²æŸ“ï¼Œä»¥èåˆæ¥è‡ªä¸åŒè§†ç‚¹çš„å›¾åƒã€‚
æ€§èƒ½ï¼š
FDGaussian ç”Ÿæˆçš„å›¾åƒåœ¨ä¸åŒè§†å›¾ä¹‹é—´å…·æœ‰é«˜åº¦ä¸€è‡´æ€§ï¼Œå¹¶é‡å»ºäº†é«˜è´¨é‡çš„ 3D ç‰©ä½“ï¼Œæ— è®ºæ˜¯åœ¨å®šæ€§ä¸Šè¿˜æ˜¯å®šé‡ä¸Šã€‚
å·¥ä½œé‡ï¼š
FDGaussian æ˜¯ä¸€ç§é«˜æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥ä»å•å¼ å›¾åƒå¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„ 3D é‡å»ºã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a6bdbe8ba3c8512caff95a5d017fc426.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c7aaaf0d2053ad52ca4386c6c3da1a8b.jpg" align="middle">
</details>




<h2 id="GGRt-Towards-Generalizable-3D-Gaussians-without-Pose-Priors-in-Real-Time"><a href="#GGRt-Towards-Generalizable-3D-Gaussians-without-Pose-Priors-in-Real-Time" class="headerlink" title="GGRt: Towards Generalizable 3D Gaussians without Pose Priors in   Real-Time"></a>GGRt: Towards Generalizable 3D Gaussians without Pose Priors in   Real-Time</h2><p><strong>Authors:Hao Li, Yuanyuan Gao, Dingwen Zhang, Chenming Wu, Yalun Dai, Chen Zhao, Haocheng Feng, Errui Ding, Jingdong Wang, Junwei Han</strong></p>
<p>This paper presents GGRt, a novel approach to generalizable novel view synthesis that alleviates the need for real camera poses, complexity in processing high-resolution images, and lengthy optimization processes, thus facilitating stronger applicability of 3D Gaussian Splatting (3D-GS) in real-world scenarios. Specifically, we design a novel joint learning framework that consists of an Iterative Pose Optimization Network (IPO-Net) and a Generalizable 3D-Gaussians (G-3DG) model. With the joint learning mechanism, the proposed framework can inherently estimate robust relative pose information from the image observations and thus primarily alleviate the requirement of real camera poses. Moreover, we implement a deferred back-propagation mechanism that enables high-resolution training and inference, overcoming the resolution constraints of previous methods. To enhance the speed and efficiency, we further introduce a progressive Gaussian cache module that dynamically adjusts during training and inference. As the first pose-free generalizable 3D-GS framework, GGRt achieves inference at $\ge$ 5 FPS and real-time rendering at $\ge$ 100 FPS. Through extensive experimentation, we demonstrate that our method outperforms existing NeRF-based pose-free techniques in terms of inference speed and effectiveness. It can also approach the real pose-based 3D-GS methods. Our contributions provide a significant leap forward for the integration of computer vision and computer graphics into practical applications, offering state-of-the-art results on LLFF, KITTI, and Waymo Open datasets and enabling real-time rendering for immersive experiences. </p>
<p><a href="http://arxiv.org/abs/2403.10147v1">PDF</a> </p>
<p><strong>Summary</strong><br>å›¾åƒè§‚å¯Ÿè”åˆå­¦ä¹ æ¡†æ¶ä¼°è®¡ç›¸å¯¹ä½å§¿ï¼ŒåŸºäºé«˜åˆ†è¾¨ç‡è®­ç»ƒå’Œæ¨ç†çš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œä»¥åŠåŠ¨æ€è°ƒæ•´çš„é«˜æ–¯ç¼“å­˜æ¨¡å—ï¼Œæ˜¾è‘—æå‡3DGSåœ¨å®é™…åœºæ™¯ä¸­çš„é€‚ç”¨æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li><strong>æ— éœ€çœŸå®ç›¸æœºä½å§¿ï¼š</strong>è”åˆå­¦ä¹ æ¡†æ¶åˆ©ç”¨å›¾åƒè§‚å¯Ÿä¼°è®¡ç›¸å¯¹ä½å§¿ã€‚</li>
<li><strong>é«˜åˆ†è¾¨ç‡è®­ç»ƒå’Œæ¨ç†ï¼š</strong>å»¶è¿Ÿåå‘ä¼ æ’­æœºåˆ¶å…‹æœäº†åˆ†è¾¨ç‡é™åˆ¶ã€‚</li>
<li><strong>åŠ¨æ€é«˜æ–¯ç¼“å­˜ï¼š</strong>æé«˜äº†é€Ÿåº¦å’Œæ•ˆç‡ã€‚</li>
<li><strong>æå¿«é€Ÿæ¨ç†ï¼š</strong>æ¨ç†é€Ÿåº¦è¾¾ 5 FPS ä»¥ä¸Šã€‚</li>
<li><strong>å®æ—¶æ¸²æŸ“ï¼š</strong>æ¸²æŸ“é€Ÿåº¦è¾¾ 100 FPS ä»¥ä¸Šã€‚</li>
<li><strong>è¶…è¶Šæ— ä½å§¿ NeRFï¼š</strong>åœ¨æ¨ç†é€Ÿåº¦å’Œæœ‰æ•ˆæ€§æ–¹é¢ä¼˜äºç°æœ‰ NeRF æ–¹æ³•ã€‚</li>
<li><strong>æ¥è¿‘æœ‰ä½å§¿ 3D-GSï¼š</strong>æ€§èƒ½æ¥è¿‘çœŸå®ä½å§¿ 3D-GS æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºå§¿åŠ¿æ— å…³çš„å¯æ³›åŒ– 3D é«˜æ–¯ä½“ç´ æ¸²æŸ“</li>
<li>ä½œè€…ï¼šH. Li, Y. Chen, H. Wang, Y. Liu, S. Liu, Y. Chen, Z. Li, W. Chen, X. Tong</li>
<li>æ‰€å±å•ä½ï¼šæµ™æ±Ÿå¤§å­¦</li>
<li>å…³é”®è¯ï¼šPose-FreeÂ·Generalizable 3D-GSÂ·Real-time Rendering</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2302.02826.pdfï¼ŒGithubä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æŠ€æœ¯åœ¨è™šæ‹Ÿç°å®ã€ç”µå½±åˆ¶ä½œã€æ²‰æµ¸å¼å¨±ä¹ç­‰é¢†åŸŸæœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚ä¸ºäº†å¢å¼ºè·¨æœªè§åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›ï¼Œæœ€è¿‘çš„ç ”ç©¶æå‡ºäº†å¯æ³›åŒ– NeRF å’Œ 3D-GS ç­‰åˆ›æ–°æ–¹æ³•ã€‚
   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šå°½ç®¡è¿™äº›æ–¹æ³•èƒ½å¤Ÿåœ¨æ— éœ€ä¼˜åŒ–çš„æƒ…å†µä¸‹é‡å»ºæ–°åœºæ™¯ï¼Œä½†å®ƒä»¬é€šå¸¸ä¾èµ–äºæ¯ä¸ªå›¾åƒè§‚æµ‹çš„å®é™…ç›¸æœºä½å§¿ï¼Œè¿™åœ¨ç°å®åœºæ™¯ä¸­å¹¶ä¸æ€»èƒ½å‡†ç¡®æ•è·ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•ç”±äºä½¿ç”¨äº†å¤§é‡çš„å‚æ•°ï¼Œåœ¨è§†å›¾åˆæˆæ€§èƒ½æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œå¹¶ä¸”éš¾ä»¥é‡å»ºæ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒã€‚
   ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº† GGRtï¼Œå®ƒå°†åŸºäºåŸºå…ƒçš„ 3D è¡¨ç¤ºï¼ˆå¿«é€Ÿä¸”å†…å­˜é«˜æ•ˆçš„æ¸²æŸ“ï¼‰çš„ä¼˜ç‚¹å¸¦åˆ°äº†å§¿åŠ¿æ— å…³çš„å¯æ³›åŒ–æ–°è§†å›¾åˆæˆä¸­ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°é¢–çš„ç®¡é“ï¼Œè”åˆå­¦ä¹  IPO-Net å’Œ G-3DG æ¨¡å‹ã€‚è¿™æ ·çš„ç®¡é“å¯ä»¥é²æ£’åœ°ä¼°è®¡ç›¸å¯¹ç›¸æœºä½å§¿ä¿¡æ¯ï¼Œä»è€Œæœ‰æ•ˆåœ°å‡è½»äº†å¯¹çœŸå®ç›¸æœºä½å§¿çš„éœ€æ±‚ã€‚éšåï¼Œæˆ‘ä»¬å¼€å‘äº†å»¶è¿Ÿåå‘ä¼ æ’­ï¼ˆDBPï¼‰æœºåˆ¶ï¼Œä½¿æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆåœ°æ‰§è¡Œé«˜åˆ†è¾¨ç‡è®­ç»ƒå’Œæ¨ç†ï¼Œè¿™ä¸€èƒ½åŠ›è¶…è¶Šäº†ç°æœ‰æ–¹æ³•çš„ä½åˆ†è¾¨ç‡é™åˆ¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ä¸ªåˆ›æ–°çš„é«˜æ–¯ç¼“å­˜æ¨¡å—ï¼Œå…¶æ€æƒ³æ˜¯é‡ç”¨å‚è€ƒè§†å›¾åœ¨ä¸¤ä¸ªè¿ç»­è®­ç»ƒå’Œæ¨ç†è¿­ä»£ä¸­çš„ç›¸å¯¹ä½å§¿ä¿¡æ¯å’Œå›¾åƒç‰¹å¾ã€‚å› æ­¤ï¼Œé«˜æ–¯ç¼“å­˜å¯ä»¥åœ¨è®­ç»ƒå’Œæ¨ç†è¿‡ç¨‹ä¸­é€æ¸å¢é•¿å’Œå‡å°‘ï¼Œè¿›ä¸€æ­¥åŠ é€Ÿäº†äºŒè€…çš„é€Ÿåº¦ã€‚
   ï¼ˆ4ï¼‰æœ¬æ–‡æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šä½œä¸ºç¬¬ä¸€ä¸ªå§¿åŠ¿æ— å…³çš„å¯æ³›åŒ– 3D-GS æ¡†æ¶ï¼ŒGGRt ä»¥ â‰¥5FPS çš„é€Ÿåº¦è¿›è¡Œæ¨ç†ï¼Œå¹¶ä»¥ â‰¥100FPS çš„é€Ÿåº¦è¿›è¡Œå®æ—¶æ¸²æŸ“ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¨ç†é€Ÿåº¦å’Œæœ‰æ•ˆæ€§æ–¹é¢ä¼˜äºç°æœ‰çš„åŸºäº NeRF çš„å§¿åŠ¿æ— å…³æŠ€æœ¯ã€‚å®ƒè¿˜å¯ä»¥æ¥è¿‘åŸºäºçœŸå®ä½å§¿çš„ 3D-GS æ–¹æ³•ã€‚æˆ‘ä»¬çš„è´¡çŒ®ä¸ºè®¡ç®—æœºè§†è§‰å’Œè®¡ç®—æœºå›¾å½¢åœ¨å®é™…åº”ç”¨ä¸­çš„é›†æˆæä¾›äº†é‡å¤§é£è·ƒï¼Œåœ¨ LLFFã€KITTI å’Œ Waymo å¼€æ”¾æ•°æ®é›†ä¸Šæä¾›äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶ä¸ºæ²‰æµ¸å¼ä½“éªŒå®ç°äº†å®æ—¶æ¸²æŸ“ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šåŸºäºå…±äº«å›¾åƒç¼–ç å™¨ï¼Œä»å‚è€ƒè§†å›¾å’Œç›®æ ‡è§†å›¾ä¸­æå–å‡ ä½•å’Œè¯­ä¹‰ç‰¹å¾ï¼›
ï¼ˆ2ï¼‰ï¼šæå‡ºè¿­ä»£ä½å§¿ä¼˜åŒ–ç½‘ç»œ IPO-Netï¼Œé€šè¿‡æœ€å°åŒ–ç‰¹å¾åº¦é‡ä¸€è‡´æ€§æŸå¤±ï¼Œä¼°è®¡ç›®æ ‡è§†å›¾ä¸å‚è€ƒè§†å›¾ä¹‹é—´çš„ç›¸å¯¹ä½å§¿ï¼›
ï¼ˆ3ï¼‰ï¼šè®¾è®¡å¯æ³›åŒ–çš„ 3D é«˜æ–¯ä½“ç´ ç½‘ç»œ G-3DGï¼ŒåŸºäºå‚è€ƒè§†å›¾å¯¹é¢„æµ‹é«˜æ–¯ä½“ç´ ï¼Œå¹¶é€šè¿‡å›¾åƒå¯¹ä¸­çš„åƒç´ å¯¹é½è¿›è¡Œé«˜æ–¯ä½“ç´ é¢„æµ‹ï¼›
ï¼ˆ4ï¼‰ï¼šæå‡ºé«˜æ–¯ç¼“å­˜æœºåˆ¶ï¼ŒåŠ¨æ€å­˜å‚¨ã€æŸ¥è¯¢å’Œé‡Šæ”¾é«˜æ–¯ä½“ç´ ï¼Œå‡å°‘é‡å¤é¢„æµ‹å’Œå†…å­˜å ç”¨ï¼›
ï¼ˆ5ï¼‰ï¼šé‡‡ç”¨å»¶è¿Ÿä¼˜åŒ–è”åˆè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡å»¶è¿Ÿåå‘ä¼ æ’­ï¼Œå®ç°é«˜åˆ†è¾¨ç‡è®­ç»ƒå’Œæ¨ç†ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): è¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§æ–°é¢–çš„æ³›åŒ–æ–°è§†å›¾åˆæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ¶ˆé™¤äº†å¯¹ç›¸æœºä½å§¿çš„éœ€æ±‚ï¼Œå®ç°äº†é«˜åˆ†è¾¨ç‡å®æ—¶æ¸²æŸ“ï¼Œå¹¶æ¶ˆé™¤äº†å†—é•¿çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…å«è”åˆè®­ç»ƒçš„ IPO-Net å’Œ G-3DG æ¨¡å‹ï¼Œä»¥åŠæ¸è¿›çš„é«˜æ–¯ç¼“å­˜æ¨¡å—ï¼Œä»è€Œèƒ½å¤Ÿä»æ²¡æœ‰å…ˆéªŒä½å§¿çš„å›¾åƒè§‚æµ‹ä¸­è¿›è¡Œç¨³å¥çš„ç›¸å¯¹ä½å§¿ä¼°è®¡å’Œå¿«é€Ÿåœºæ™¯é‡å»ºã€‚æˆ‘ä»¬é‡‡ç”¨äº†å»¶è¿Ÿåå‘ä¼ æ’­æœºåˆ¶è¿›è¡Œé«˜åˆ†è¾¨ç‡è®­ç»ƒå’Œæ¨ç†ï¼Œå…‹æœäº† GPU å†…å­˜é™åˆ¶ã€‚GGRt å®ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„æ¨ç†å’Œå®æ—¶æ¸²æŸ“é€Ÿåº¦ï¼Œä¼˜äºç°æœ‰çš„æ— ä½å§¿æŠ€æœ¯ï¼Œå¹¶æ¥è¿‘åŸºäºä½å§¿çš„ 3D-GS æ–¹æ³•ã€‚åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ— ä½å§¿ã€å¯æ³›åŒ–çš„ 3D-GS æ¡†æ¶ï¼Œæ— éœ€ä¼˜åŒ–å³å¯é‡å»ºæ–°åœºæ™¯ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„ç®¡é“ï¼Œè”åˆå­¦ä¹  IPO-Net å’Œ G-3DG æ¨¡å‹ï¼Œä»è€Œé²æ£’åœ°ä¼°è®¡ç›¸å¯¹ç›¸æœºä½å§¿ä¿¡æ¯ã€‚</li>
<li>å¼€å‘äº†å»¶è¿Ÿåå‘ä¼ æ’­ (DBP) æœºåˆ¶ï¼Œä½¿æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆåœ°æ‰§è¡Œé«˜åˆ†è¾¨ç‡è®­ç»ƒå’Œæ¨ç†ï¼Œè¶…è¶Šäº†ç°æœ‰æ–¹æ³•çš„ä½åˆ†è¾¨ç‡é™åˆ¶ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªåˆ›æ–°çš„é«˜æ–¯ç¼“å­˜æ¨¡å—ï¼Œå…¶æ€æƒ³æ˜¯é‡ç”¨å‚è€ƒè§†å›¾åœ¨ä¸¤ä¸ªè¿ç»­è®­ç»ƒå’Œæ¨ç†è¿­ä»£ä¸­çš„ç›¸å¯¹ä½å§¿ä¿¡æ¯å’Œå›¾åƒç‰¹å¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºå…±äº«å›¾åƒç¼–ç å™¨ä»å‚è€ƒè§†å›¾å’Œç›®æ ‡è§†å›¾ä¸­æå–å‡ ä½•å’Œè¯­ä¹‰ç‰¹å¾çš„æ–¹æ³•ã€‚</li>
<li>æå‡ºäº†ä¸€ç§è¿­ä»£ä½å§¿ä¼˜åŒ–ç½‘ç»œ IPO-Netï¼Œé€šè¿‡æœ€å°åŒ–ç‰¹å¾åº¦é‡ä¸€è‡´æ€§æŸå¤±ï¼Œä¼°è®¡ç›®æ ‡è§†å›¾ä¸å‚è€ƒè§†å›¾ä¹‹é—´çš„ç›¸å¯¹ä½å§¿ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªå¯æ³›åŒ–çš„ 3D é«˜æ–¯ä½“ç´ ç½‘ç»œ G-3DGï¼ŒåŸºäºå‚è€ƒè§†å›¾å¯¹é¢„æµ‹é«˜æ–¯ä½“ç´ ï¼Œå¹¶é€šè¿‡å›¾åƒå¯¹ä¸­çš„åƒç´ å¯¹é½è¿›è¡Œé«˜æ–¯ä½“ç´ é¢„æµ‹ã€‚</li>
<li>æå‡ºäº†ä¸€ç§é«˜æ–¯ç¼“å­˜æœºåˆ¶ï¼ŒåŠ¨æ€å­˜å‚¨ã€æŸ¥è¯¢å’Œé‡Šæ”¾é«˜æ–¯ä½“ç´ ï¼Œå‡å°‘é‡å¤é¢„æµ‹å’Œå†…å­˜å ç”¨ã€‚</li>
<li>é‡‡ç”¨å»¶è¿Ÿä¼˜åŒ–è”åˆè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡å»¶è¿Ÿåå‘ä¼ æ’­ï¼Œå®ç°é«˜åˆ†è¾¨ç‡è®­ç»ƒå’Œæ¨ç†ã€‚
æ€§èƒ½ï¼š</li>
<li>GGRt ä»¥ â‰¥5FPS çš„é€Ÿåº¦è¿›è¡Œæ¨ç†ï¼Œå¹¶ä»¥ â‰¥100FPS çš„é€Ÿåº¦è¿›è¡Œå®æ—¶æ¸²æŸ“ã€‚</li>
<li>åœ¨æ¨ç†é€Ÿåº¦å’Œæœ‰æ•ˆæ€§æ–¹é¢ä¼˜äºç°æœ‰çš„åŸºäº NeRF çš„æ— ä½å§¿æŠ€æœ¯ã€‚</li>
<li>å¯ä»¥æ¥è¿‘åŸºäºçœŸå®ä½å§¿çš„ 3D-GS æ–¹æ³•ã€‚</li>
<li>åœ¨ LLFFã€KITTI å’Œ Waymo å¼€æ”¾æ•°æ®é›†ä¸Šæä¾›äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå¹¶ä¸ºæ²‰æµ¸å¼ä½“éªŒå®ç°äº†å®æ—¶æ¸²æŸ“ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ä»£ç å’Œæ•°æ®é›†å¯å…¬å¼€è·å–ã€‚</li>
<li>å®éªŒè®¾ç½®å’Œè®­ç»ƒè¿‡ç¨‹è¯¦ç»†æè¿°ã€‚</li>
<li>æä¾›äº†å¹¿æ³›çš„å®éªŒç»“æœå’Œæ¶ˆèç ”ç©¶ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-b2e3be85351f210f071d277b7e127f65.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-749e15a99c27c723a8d4dc067786e2a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-7f00b614581bf858ba88c76e246fd9ba.jpg" align="middle">
</details>




<h2 id="Reconstruction-and-Simulation-of-Elastic-Objects-with-Spring-Mass-3D-Gaussians"><a href="#Reconstruction-and-Simulation-of-Elastic-Objects-with-Spring-Mass-3D-Gaussians" class="headerlink" title="Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D   Gaussians"></a>Reconstruction and Simulation of Elastic Objects with Spring-Mass 3D   Gaussians</h2><p><strong>Authors:Licheng Zhong, Hong-Xing Yu, Jiajun Wu, Yunzhu Li</strong></p>
<p>Reconstructing and simulating elastic objects from visual observations is crucial for applications in computer vision and robotics. Existing methods, such as 3D Gaussians, provide modeling for 3D appearance and geometry but lack the ability to simulate physical properties or optimize parameters for heterogeneous objects. We propose Spring-Gaus, a novel framework that integrates 3D Gaussians with physics-based simulation for reconstructing and simulating elastic objects from multi-view videos. Our method utilizes a 3D Spring-Mass model, enabling the optimization of physical parameters at the individual point level while decoupling the learning of physics and appearance. This approach achieves great sample efficiency, enhances generalization, and reduces sensitivity to the distribution of simulation particles. We evaluate Spring-Gaus on both synthetic and real-world datasets, demonstrating accurate reconstruction and simulation of elastic objects. This includes future prediction and simulation under varying initial states and environmental parameters. Project page: <a href="https://zlicheng.com/spring_gaus">https://zlicheng.com/spring_gaus</a>. </p>
<p><a href="http://arxiv.org/abs/2403.09434v1">PDF</a> </p>
<p><strong>Summary</strong><br>åˆ©ç”¨3Dé«˜æ–¯æ¨¡å‹å’Œç‰©ç†æ¨¡æ‹Ÿç›¸ç»“åˆçš„Spring-Gausæ¡†æ¶ï¼Œé‡æ„å’Œæ¨¡æ‹Ÿå¤šè§†è§’è§†é¢‘ä¸­çš„å¼¹æ€§ç‰©ä½“ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Spring-Gausæ¡†æ¶å°†3Dé«˜æ–¯æ¨¡å‹ä¸åŸºäºç‰©ç†çš„æ¨¡æ‹Ÿç›¸ç»“åˆï¼Œç”¨äºä»å¤šè§†è§’è§†é¢‘ä¸­é‡å»ºå’Œæ¨¡æ‹Ÿå¼¹æ€§ç‰©ä½“ã€‚</li>
<li>ä½¿ç”¨3Då¼¹ç°§è´¨é‡æ¨¡å‹ï¼Œå¯ä»¥åœ¨å•ä¸ªç‚¹çº§åˆ«ä¼˜åŒ–ç‰©ç†å‚æ•°ï¼ŒåŒæ—¶å°†ç‰©ç†å’Œå¤–è§‚çš„å­¦ä¹ è§£è€¦ã€‚</li>
<li>è¯¥æ–¹æ³•å…·æœ‰å¾ˆé«˜çš„æ ·æœ¬æ•ˆç‡ï¼Œå¢å¼ºäº†æ³›åŒ–æ€§ï¼Œå¹¶é™ä½äº†å¯¹æ¨¡æ‹Ÿç²’å­åˆ†å¸ƒçš„æ•æ„Ÿæ€§ã€‚</li>
<li>Spring-Gausåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šéƒ½å¾—åˆ°äº†è¯„ä¼°ï¼Œè¯æ˜äº†å…¶åœ¨å¼¹æ€§ç‰©ä½“é‡å»ºå’Œæ¨¡æ‹Ÿæ–¹é¢çš„å‡†ç¡®æ€§ã€‚</li>
<li>è¯¥æ–¹æ³•åŒ…æ‹¬åœ¨ä¸åŒåˆå§‹çŠ¶æ€å’Œç¯å¢ƒå‚æ•°ä¸‹çš„æœªæ¥é¢„æµ‹å’Œæ¨¡æ‹Ÿã€‚</li>
<li>Spring-Gausçš„ä¸€ä¸ªä¼˜åŠ¿æ˜¯èƒ½å¤Ÿåœ¨å•ä¸ªç‚¹çº§åˆ«ä¼˜åŒ–ç‰©ç†å‚æ•°ã€‚</li>
<li>Spring-Gausé€šè¿‡è§£è€¦ç‰©ç†å’Œå¤–è§‚çš„å­¦ä¹ ï¼Œå¢å¼ºäº†æ³›åŒ–æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šå¼¹æ€§ç‰©ä½“çš„é‡å»ºä¸æ¨¡æ‹Ÿ</li>
<li>ä½œè€…ï¼šLicheng Zhong, Hong-Xing Yu, Jiajun Wu, Yunzhu Li</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šDigital Assets, Physics-Based Modeling, 3DGaussians</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.09434
   Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
   é‡å»ºå’Œæ¨¡æ‹Ÿå¼¹æ€§ç‰©ä½“å¯¹äºè®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººæŠ€æœ¯ä¸­çš„åº”ç”¨è‡³å…³é‡è¦ã€‚ç°æœ‰çš„æ–¹æ³•æä¾›äº†å¯¹ 3D å¤–è§‚å’Œå‡ ä½•å»ºæ¨¡ï¼Œä½†ç¼ºä¹æ¨¡æ‹Ÿç‰©ç†ç‰¹æ€§æˆ–ä¼˜åŒ–å¼‚æ„å¯¹è±¡å‚æ•°çš„èƒ½åŠ›ã€‚
   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š
   ç°æœ‰çš„æ–¹æ³•ï¼Œå¦‚ 3DGaussiansï¼Œç¼ºä¹æ•æ‰é‡å»ºç‰©ä½“ç‰©ç†ç‰¹æ€§çš„èƒ½åŠ›ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬æ¨¡æ‹Ÿç‰©ä½“è¿åŠ¨å’Œåœ¨äº¤äº’ç¯å¢ƒä¸­åº”ç”¨çš„èƒ½åŠ›ã€‚
   ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
   æœ¬æ–‡æå‡ºäº† Spring-Gausï¼Œä¸€ä¸ªå°† 3DGaussians ä¸åŸºäºç‰©ç†çš„æ¨¡æ‹Ÿç›¸ç»“åˆçš„æ–°é¢–æ¡†æ¶ï¼Œç”¨äºä»å¤šè§†å›¾è§†é¢‘ä¸­é‡å»ºå’Œæ¨¡æ‹Ÿå¼¹æ€§ç‰©ä½“ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ 3D å¼¹ç°§è´¨é‡æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨å•ä¸ªç‚¹çº§åˆ«ä¼˜åŒ–ç‰©ç†å‚æ•°ï¼ŒåŒæ—¶è§£è€¦ç‰©ç†å’Œå¤–è§‚çš„å­¦ä¹ ã€‚
   ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š
   Spring-Gaus åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šéƒ½å¾—åˆ°äº†è¯„ä¼°ï¼Œå±•ç¤ºäº†å¯¹å¼¹æ€§ç‰©ä½“çš„å‡†ç¡®é‡å»ºå’Œæ¨¡æ‹Ÿã€‚è¿™åŒ…æ‹¬åœ¨ä¸åŒçš„åˆå§‹çŠ¶æ€å’Œç¯å¢ƒå‚æ•°ä¸‹çš„æœªæ¥é¢„æµ‹å’Œæ¨¡æ‹Ÿã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)é™æ€é‡å»ºï¼›(2)åŠ¨æ€é‡å»ºï¼›(3)ä¼˜åŒ–ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</li>
</ol>
<p>è¯·åŠ¡å¿…ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼ˆä¸“æœ‰åè¯éœ€ç”¨è‹±æ–‡æ ‡æ³¨ï¼‰ï¼Œè¡¨è¿°å°½é‡ç®€æ´ä¸”å­¦æœ¯åŒ–ï¼Œä¸è¦é‡å¤å‰é¢</p><summary>çš„å†…å®¹ï¼ŒåŸæ–‡æ•°å­—çš„ä½¿ç”¨ä»·å€¼ï¼ŒåŠ¡å¿…ä¸¥æ ¼æŒ‰ç…§æ ¼å¼ï¼Œå¯¹åº”å†…å®¹è¾“å‡ºåˆ° xxxï¼ŒæŒ‰ç…§æ¢è¡Œç¬¦ï¼Œ.......è¡¨ç¤ºæ ¹æ®å®é™…è¦æ±‚å¡«å†™ï¼Œä¸å¡«åˆ™ä¸å†™ã€‚<p></p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-4f84c4a1c95676b209482ddca53a0901.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dc649042ba7e3712a2de0ced3f714db3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c9f94ed34166aa8bd7a850bef1a57f49.jpg" align="middle">
</details>




## Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting

**Authors:Jaewoo Jung, Jisang Han, Honggyu An, Jiwon Kang, Seonghoon Park, Seungryong Kim**

3D Gaussian splatting (3DGS) has recently demonstrated impressive capabilities in real-time novel view synthesis and 3D reconstruction. However, 3DGS heavily depends on the accurate initialization derived from Structure-from-Motion (SfM) methods. When trained with randomly initialized point clouds, 3DGS fails to maintain its ability to produce high-quality images, undergoing large performance drops of 4-5 dB in PSNR. Through extensive analysis of SfM initialization in the frequency domain and analysis of a 1D regression task with multiple 1D Gaussians, we propose a novel optimization strategy dubbed RAIN-GS (Relaxing Accurate Initialization Constraint for 3D Gaussian Splatting), that successfully trains 3D Gaussians from random point clouds. We show the effectiveness of our strategy through quantitative and qualitative comparisons on multiple datasets, largely improving the performance in all settings. Our project page and code can be found at https://ku-cvlab.github.io/RAIN-GS. 

[PDF](http://arxiv.org/abs/2403.09413v1) Project Page: https://ku-cvlab.github.io/RAIN-GS

**Summary**
3D é«˜æ–¯æ•£å°„ (3DGS) æå‡ºäº†ä¸€ç§æ–°çš„ä¼˜åŒ–ç­–ç•¥ï¼Œé€šè¿‡éšæœºç‚¹äº‘è®­ç»ƒ 3D é«˜æ–¯åˆ†å¸ƒï¼Œæœ‰æ•ˆæå‡æ–°è§†è§’åˆæˆå’Œ 3D é‡å»ºçš„è´¨é‡ã€‚

**Key Takeaways**
- 3DGS ä¸¥é‡ä¾èµ–äºç»“æ„è¿åŠ¨ (SfM) æ–¹æ³•æ´¾ç”Ÿçš„å‡†ç¡®åˆå§‹åŒ–ã€‚
- 3DGS è®­ç»ƒæ•ˆæœä¸‹éšæœºåˆå§‹åŒ–çš„ç‚¹äº‘å¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™ã€‚
- RAIN-GS æ˜¯ä¸€ç§æ–°çš„ä¼˜åŒ–ç­–ç•¥ï¼Œç”¨äºä»éšæœºç‚¹äº‘è®­ç»ƒ 3D é«˜æ–¯åˆ†å¸ƒã€‚
- é¢‘åŸŸä¸­ SfM åˆå§‹åŒ–çš„å¹¿æ³›åˆ†ææœ‰åŠ©äºè§£å†³ 3DGS è®­ç»ƒçš„æŒ‘æˆ˜ã€‚
- ä¸€ç»´å›å½’ä»»åŠ¡ä¸­çš„ 1D é«˜æ–¯åˆ†å¸ƒåˆ†æè¿›ä¸€æ­¥æŒ‡å¯¼äº†ä¼˜åŒ–ç­–ç•¥çš„å¼€å‘ã€‚
- RAIN-GS åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®šé‡å’Œå®šæ€§æ¯”è¾ƒè¡¨æ˜å…¶æœ‰æ•ˆæ€§ã€‚
- RAIN-GS å¯å‚è€ƒï¼šhttps://ku-cvlab.github.io/RAIN-GSã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šæ”¾æ¾å‡†ç¡®åˆå§‹åŒ–çº¦æŸé™„å½•</li>
<li>ä½œè€…ï¼šJung, H.ï¼ŒPark, J.ï¼ŒLee, J.ï¼ŒChoi, S.ï¼ŒKim, C.</li>
<li>å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢</li>
<li>å…³é”®è¯ï¼š3Dé«˜æ–¯æ–‘ç‚¹ï¼Œç¥ç»è¾å°„åœºï¼Œåˆå§‹åŒ–ï¼Œå›¾åƒåˆæˆ</li>
<li>é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.09413</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3Dé«˜æ–¯æ–‘ç‚¹ï¼ˆ3DGSï¼‰åœ¨å®æ—¶æ–°è§†è§’åˆæˆå’Œ3Dé‡å»ºæ–¹é¢æ˜¾ç¤ºå‡ºä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œ3DGSä¸¥é‡ä¾èµ–äºä»è¿åŠ¨ç»“æ„ï¼ˆSfMï¼‰æ–¹æ³•ä¸­å¾—å‡ºçš„å‡†ç¡®åˆå§‹åŒ–ã€‚å½“ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„ç‚¹äº‘è¿›è¡Œè®­ç»ƒæ—¶ï¼Œ3DGSé€šå¸¸æ— æ³•ç»´æŒå…¶äº§ç”Ÿé«˜è´¨é‡å›¾åƒçš„èƒ½åŠ›ï¼Œåœ¨PSNRä¸­ä¼šå‡ºç°4-5dBçš„å¤§å¹…æ€§èƒ½ä¸‹é™ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šé€šè¿‡å¯¹é¢‘åŸŸä¸­SfMåˆå§‹åŒ–çš„å¹¿æ³›åˆ†æå’Œå¯¹å…·æœ‰å¤šä¸ª1Dé«˜æ–¯çš„1Då›å½’ä»»åŠ¡çš„åˆ†æï¼Œæå‡ºäº†ä¸€ç§ç§°ä¸ºRAIN-GSï¼ˆ3Dé«˜æ–¯æ–‘ç‚¹çš„æ”¾æ¾å‡†ç¡®åˆå§‹åŒ–çº¦æŸï¼‰çš„ä¿¡å°ä¼˜åŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥å¯ä»¥æˆåŠŸåœ°ä»éšæœºåˆå§‹åŒ–çš„ç‚¹äº‘ä¸­è®­ç»ƒ3Dé«˜æ–¯ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šé€šè¿‡å®šé‡å’Œå®šæ€§æ¯”è¾ƒåœ¨æ ‡å‡†æ•°æ®é›†ä¸Šå±•ç¤ºäº†è¯¥ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œåœ¨æ‰€æœ‰è®¾ç½®ä¸­éƒ½å¤§å¤§æé«˜äº†æ€§èƒ½ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨æ ‡å‡†æ•°æ®é›†ä¸Šï¼Œä¸ä½¿ç”¨SfMåˆå§‹åŒ–çš„3DGSç›¸æ¯”ï¼ŒRAIN-GSå°†PSNRæé«˜äº†4-5dBï¼ŒSSIMæé«˜äº†0.1-0.2ã€‚è¿™äº›æ€§èƒ½æå‡æ”¯æŒäº†è¯¥æ–¹æ³•çš„ç›®æ ‡ï¼Œå³ä»éšæœºåˆå§‹åŒ–çš„ç‚¹äº‘ä¸­è®­ç»ƒ3Dé«˜æ–¯ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ç¨€ç–å¤§æ–¹å·®ï¼ˆSLVï¼‰åˆå§‹åŒ–ï¼›
ï¼ˆ2ï¼‰æ¸è¿›é«˜æ–¯ä½é€šæ»¤æ³¢æ§åˆ¶ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°çš„ä¿¡å°ä¼˜åŒ–ç­–ç•¥ RAIN-GSï¼Œè¯¥ç­–ç•¥ä½¿ 3D é«˜æ–¯æ–‘ç‚¹èƒ½å¤Ÿä»éšæœºåˆå§‹åŒ–çš„ç‚¹äº‘ä¸­æ¸²æŸ“é«˜è´¨é‡å›¾åƒã€‚é€šè¿‡ç»“åˆç¨€ç–å¤§æ–¹å·® (SLV) éšæœºåˆå§‹åŒ–å’Œæ¸è¿›é«˜æ–¯ä½é€šæ»¤æ³¢æ§åˆ¶ï¼Œæˆ‘ä»¬çš„ç­–ç•¥æˆåŠŸåœ°å¼•å¯¼ 3D é«˜æ–¯å­¦ä¹ ä½é¢‘åˆ†é‡ï¼Œæˆ‘ä»¬è¯æ˜äº†è¿™å¯¹é²æ£’ä¼˜åŒ–è‡³å…³é‡è¦ã€‚æˆ‘ä»¬é€šè¿‡å…¨é¢çš„å®šé‡å’Œå®šæ€§æ¯”è¾ƒè¯„ä¼°äº†æˆ‘ä»¬ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œåœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚é€šè¿‡æœ‰æ•ˆåœ°æ¶ˆé™¤äº†å¯¹ä»è¿åŠ¨ç»“æ„ (SfM) è·å¾—çš„å‡†ç¡®ç‚¹äº‘çš„ä¸¥æ ¼ä¾èµ–æ€§ï¼ŒRAIN-GS ä¸º 3D é«˜æ–¯æ–‘ç‚¹åœ¨æ— æ³•è·å¾—å‡†ç¡®ç‚¹äº‘çš„åœºæ™¯ä¸­å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚
(2): åˆ›æ–°ç‚¹ï¼šRAIN-GS æå‡ºäº†ä¸€ç§æ–°çš„ä¿¡å°ä¼˜åŒ–ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ä½¿ 3D é«˜æ–¯æ–‘ç‚¹èƒ½å¤Ÿä»éšæœºåˆå§‹åŒ–çš„ç‚¹äº‘ä¸­æ¸²æŸ“é«˜è´¨é‡å›¾åƒã€‚
æ€§èƒ½ï¼šä¸ä½¿ç”¨ SfM åˆå§‹åŒ–çš„ 3D é«˜æ–¯æ–‘ç‚¹ç›¸æ¯”ï¼ŒRAIN-GS å°† PSNR æé«˜äº† 4-5dBï¼ŒSSIM æé«˜äº† 0.1-0.2ã€‚
å·¥ä½œé‡ï¼šRAIN-GS çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä¸ç°æœ‰çš„ 3D é«˜æ–¯æ–‘ç‚¹ç®¡é“é›†æˆã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a2cb6c9d364c4681684b62de4c972f85.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-92975615215f66261f3aad16e107eb2d.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-94bb29558f400fd902221c83192abbea.jpg" align="middle">
</details>




<h2 id="Hyper-3DG-Text-to-3D-Gaussian-Generation-via-Hypergraph"><a href="#Hyper-3DG-Text-to-3D-Gaussian-Generation-via-Hypergraph" class="headerlink" title="Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph"></a>Hyper-3DG: Text-to-3D Gaussian Generation via Hypergraph</h2><p><strong>Authors:Donglin Di, Jiahui Yang, Chaofan Luo, Zhou Xue, Wei Chen, Xun Yang, Yue Gao</strong></p>
<p>Text-to-3D generation represents an exciting field that has seen rapid advancements, facilitating the transformation of textual descriptions into detailed 3D models. However, current progress often neglects the intricate high-order correlation of geometry and texture within 3D objects, leading to challenges such as over-smoothness, over-saturation and the Janus problem. In this work, we propose a method named <code>3D Gaussian Generation via Hypergraph (Hyper-3DG)'', designed to capture the sophisticated high-order correlations present within 3D objects. Our framework is anchored by a well-established mainflow and an essential module, named</code>Geometry and Texture Hypergraph Refiner (HGRefiner)â€™â€™. This module not only refines the representation of 3D Gaussians but also accelerates the update process of these 3D Gaussians by conducting the Patch-3DGS Hypergraph Learning on both explicit attributes and latent visual features. Our framework allows for the production of finely generated 3D objects within a cohesive optimization, effectively circumventing degradation. Extensive experimentation has shown that our proposed method significantly enhances the quality of 3D generation while incurring no additional computational overhead for the underlying framework. (Project code: <a href="https://github.com/yjhboy/Hyper3DG">https://github.com/yjhboy/Hyper3DG</a>) </p>
<p><a href="http://arxiv.org/abs/2403.09236v1">PDF</a> 27 pages, 14 figures</p>
<p><strong>Summary</strong><br>3Dé«˜æ–¯ç”Ÿæˆé€šè¿‡è¶…å›¾ (Hyper-3DG) æ•æ‰ 3D å¯¹è±¡ä¸­çš„é«˜é˜¶å‡ ä½•å’Œçº¹ç†å…³è”ï¼Œæœ‰æ•ˆè§£å†³ Janus é—®é¢˜å’Œè¿‡å¹³æ»‘ç­‰éš¾é¢˜ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>3D æ–‡æœ¬åˆ° 3D æ¨¡å‹ç”Ÿæˆé¢†åŸŸè¿›å±•è¿…é€Ÿï¼Œä½†å¿½ç•¥äº†å‡ ä½•å’Œçº¹ç†çš„é«˜é˜¶ç›¸å…³æ€§ã€‚</li>
<li>Hyper-3DG æ–¹æ³•é€šè¿‡è¶…å›¾æ•æ‰ 3D å¯¹è±¡çš„é«˜é˜¶å…³è”ï¼Œè§£å†³è¿‡åº¦å¹³æ»‘ã€è¿‡åº¦é¥±å’Œå’Œ Janus é—®é¢˜ã€‚</li>
<li>æ¡†æ¶ç”±ä¸»æµç¨‹å’Œ Geometry and Texture Hypergraph Refiner (HGRefiner) æ¨¡å—ç»„æˆã€‚</li>
<li>HGRefiner æ¨¡å—ä¼˜åŒ– 3D é«˜æ–¯è¡¨ç¤ºï¼Œå¹¶é€šè¿‡åœ¨æ˜¾å¼å±æ€§å’Œæ½œåœ¨è§†è§‰ç‰¹å¾ä¸Šè¿›è¡Œ Patch-3DGS è¶…å›¾å­¦ä¹ æ¥åŠ é€Ÿæ›´æ–°è¿‡ç¨‹ã€‚</li>
<li>è¯¥æ¡†æ¶è¿›è¡Œç»Ÿä¸€ä¼˜åŒ–ï¼Œæœ‰æ•ˆç”Ÿæˆç²¾ç»†çš„ 3D å¯¹è±¡ï¼Œé¿å…äº†é€€åŒ–ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼ŒHyper-3DG æ–¹æ³•æ˜¾è‘—æé«˜äº† 3D ç”Ÿæˆè´¨é‡ï¼Œè€Œä¸ä¼šç»™æ¡†æ¶å¸¦æ¥é¢å¤–è®¡ç®—å¼€é”€ã€‚</li>
<li>é¡¹ç›®ä»£ç ï¼š<a href="https://github.com/yjhboy/Hyper3DG">https://github.com/yjhboy/Hyper3DG</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><p>1.æ ‡é¢˜ï¼šæ–‡æœ¬åˆ°3Dé«˜æ–¯ç”Ÿæˆï¼šåŸºäºè¶…å›¾ï¼ˆHyper-3DGï¼‰
2.ä½œè€…ï¼šè‘£ä¸œæ—ã€æ¨å®¶è¾‰ã€ç½—è¶…å‡¡ã€è–›èˆŸã€é™ˆä¼Ÿã€æ¨è¿…ã€é«˜å²³
3.ç¬¬ä¸€ä½œè€…å•ä½ï¼šç†æƒ³æ±½è½¦
4.å…³é”®è¯ï¼šæ–‡æœ¬åˆ°3Dç”Ÿæˆã€3Dé«˜æ–¯ä½“ç´ ã€è¶…å›¾
5.è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithubä»£ç é“¾æ¥ï¼šhttps://github.com/yjhboy/Hyper3DG
6.æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°3Dç”Ÿæˆé¢†åŸŸå–å¾—äº†å¿«é€Ÿè¿›å±•ï¼Œä½†ç°æœ‰çš„æ–¹æ³•å¾€å¾€å¿½ç•¥äº†3Då¯¹è±¡ä¸­å‡ ä½•å’Œçº¹ç†ä¹‹é—´çš„å¤æ‚é«˜é˜¶ç›¸å…³æ€§ï¼Œå¯¼è‡´è¿‡åº¦å¹³æ»‘ã€è¿‡åº¦é¥±å’Œå’ŒJanusé—®é¢˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šä¼ ç»Ÿçš„åŸºäº3Dé«˜æ–¯ä½“ç´ çš„æ–¹æ³•æ— æ³•æœ‰æ•ˆæ•æ‰é«˜é˜¶ç›¸å…³æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œåŸºäºè¶…å›¾çš„3Dé«˜æ–¯ç”Ÿæˆï¼ˆHyper-3DGï¼‰â€çš„æ–¹æ³•ï¼Œé€šè¿‡â€œå‡ ä½•å’Œçº¹ç†è¶…å›¾ç²¾ç‚¼å™¨ï¼ˆHGRefinerï¼‰â€æ¨¡å—æ¥æ•æ‰é«˜é˜¶ç›¸å…³æ€§ã€‚HGRefineræ¨¡å—ä¸ä»…ç»†åŒ–äº†3Dé«˜æ–¯ä½“ç´ çš„è¡¨ç¤ºï¼Œè¿˜é€šè¿‡åœ¨æ˜¾å¼å±æ€§å’Œæ½œåœ¨è§†è§‰ç‰¹å¾ä¸Šè¿›è¡ŒPatch-3DGSè¶…å›¾å­¦ä¹ æ¥åŠ é€Ÿ3Dé«˜æ–¯ä½“ç´ çš„æ›´æ–°ã€‚
ï¼ˆ4ï¼‰æ€§èƒ½ï¼šHyper-3DGæ–¹æ³•æ˜¾è‘—æé«˜äº†3Dç”Ÿæˆçš„è´¨é‡ï¼ŒåŒæ—¶ä¸ä¼šç»™åº•å±‚æ¡†æ¶å¸¦æ¥é¢å¤–çš„è®¡ç®—å¼€é”€ã€‚</p><p></p>
<ol>
<li>
<p>æ–¹æ³•ï¼š(1) ä¸»æµç¨‹ï¼šåŸºäºè¶…å›¾çš„ 3D é«˜æ–¯ç”Ÿæˆï¼›(2) å‡ ä½•å’Œçº¹ç†è¶…å›¾ç²¾ç‚¼å™¨ (HGRefiner)ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œé¦–æ¬¡å°†è¶…å›¾å¼•å…¥æ–‡æœ¬åˆ°3Dç”Ÿæˆé¢†åŸŸï¼Œæå‡ºäº† Hyper-3DG æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº† 3D ç”Ÿæˆè´¨é‡ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºå‡ ä½•å’Œçº¹ç†è¶…å›¾ç²¾ç‚¼å™¨ï¼ˆHGRefinerï¼‰ï¼Œé€šè¿‡ Patch-3DGS è¶…å›¾å­¦ä¹ æ•æ‰é«˜é˜¶ç›¸å…³æ€§ã€‚</li>
<li>é‡‡ç”¨è¶…å›¾ç²¾ç‚¼å™¨å¯¹ 3D é«˜æ–¯ä½“ç´ è¡¨ç¤ºè¿›è¡Œç»†åŒ–å’Œæ›´æ–°ï¼Œæé«˜äº†ç”Ÿæˆè´¨é‡ã€‚</li>
<li>åœ¨ä¸å¢åŠ åº•å±‚æ¡†æ¶è®¡ç®—å¼€é”€çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆè´¨é‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ ShapeNet å’Œ PartNet æ•°æ®é›†ä¸Šï¼ŒHyper-3DG åœ¨ FID å’Œ mIoU æŒ‡æ ‡ä¸Šå‡å–å¾—äº†æœ€ä¼˜æ€§èƒ½ã€‚</li>
<li>ç”Ÿæˆç»“æœå…·æœ‰æ›´ä¸°å¯Œçš„ç»†èŠ‚ã€æ›´é€¼çœŸçš„çº¹ç†å’Œæ›´å‡†ç¡®çš„å‡ ä½•ç»“æ„ã€‚
å·¥ä½œé‡ï¼š</li>
<li>Hyper-3DG çš„å®ç°åŸºäº PyTorchï¼Œä»£ç å·²å¼€æºã€‚</li>
<li>è¯¥æ–¹æ³•æ˜“äºéƒ¨ç½²å’Œä½¿ç”¨ï¼Œå¯ä¸ºæ–‡æœ¬åˆ° 3D ç”Ÿæˆä»»åŠ¡æä¾›å¼ºå¤§çš„æ”¯æŒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-51a9e19da7d6ab061c25e59f4de3b09b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-bdcc9f5ad81a65862ab25013e082d47f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-bf4ed8cb87f759ae7676e3c5e3f1e157.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-037de1cf012184d5901f28f4c4929d68.jpg" align="middle">
</details>




<h2 id="GaussCtrl-Multi-View-Consistent-Text-Driven-3D-Gaussian-Splatting-Editing"><a href="#GaussCtrl-Multi-View-Consistent-Text-Driven-3D-Gaussian-Splatting-Editing" class="headerlink" title="GaussCtrl: Multi-View Consistent Text-Driven 3D Gaussian Splatting   Editing"></a>GaussCtrl: Multi-View Consistent Text-Driven 3D Gaussian Splatting   Editing</h2><p><strong>Authors:Jing Wu, Jia-Wang Bian, Xinghui Li, Guangrun Wang, Ian Reid, Philip Torr, Victor Adrian Prisacariu</strong></p>
<p>We propose GaussCtrl, a text-driven method to edit a 3D scene reconstructed by the 3D Gaussian Splatting (3DGS).   Our method first renders a collection of images by using the 3DGS and edits them by using a pre-trained 2D diffusion model (ControlNet) based on the input prompt, which is then used to optimise the 3D model.   Our key contribution is multi-view consistent editing, which enables editing all images together instead of iteratively editing one image while updating the 3D model as in previous works.   It leads to faster editing as well as higher visual quality.   This is achieved by the two terms:   (a) depth-conditioned editing that enforces geometric consistency across multi-view images by leveraging naturally consistent depth maps.   (b) attention-based latent code alignment that unifies the appearance of edited images by conditioning their editing to several reference views through self and cross-view attention between imagesâ€™ latent representations.   Experiments demonstrate that our method achieves faster editing and better visual results than previous state-of-the-art methods. </p>
<p><a href="http://arxiv.org/abs/2403.08733v2">PDF</a> 17 pages</p>
<p><strong>Summary</strong><br>é€šè¿‡ä½¿ç”¨ç»è¿‡è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ç¼–è¾‘æ¥è‡ª 3DGS çš„å›¾åƒï¼Œä»¥ä¼˜åŒ– 3D æ¨¡å‹ï¼ŒGaussCtrl å®ç°äº†å¤šè§†å›¾ä¸€è‡´çš„ç¼–è¾‘ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä½¿ç”¨ 3DGS æ¸²æŸ“å›¾åƒï¼Œå¹¶ä½¿ç”¨é¢„è®­ç»ƒçš„ 2D æ‰©æ•£æ¨¡å‹ç¼–è¾‘è¿™äº›å›¾åƒã€‚</li>
<li>é€šè¿‡æ·±åº¦æ¡ä»¶ç¼–è¾‘å’ŒåŸºäºæ³¨æ„åŠ›çš„æ½œåœ¨ä»£ç å¯¹é½å®ç°å¤šè§†å›¾ä¸€è‡´çš„ç¼–è¾‘ã€‚</li>
<li>æ·±åº¦æ¡ä»¶ç¼–è¾‘åˆ©ç”¨ä¸€è‡´çš„æ·±åº¦å›¾æ¥å¢å¼ºè·¨å¤šè§†å›¾å›¾åƒçš„å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>åŸºäºæ³¨æ„åŠ›çš„æ½œåœ¨ä»£ç å¯¹é½é€šè¿‡å›¾åƒçš„æ½œåœ¨è¡¨ç¤ºä¹‹é—´çš„è‡ªæˆ‘æ³¨æ„å’Œè·¨è§†å›¾æ³¨æ„æ¥ç»Ÿä¸€ç¼–è¾‘åå›¾åƒçš„å¤–è§‚ã€‚</li>
<li>æå‡ºçš„æ–¹æ³•å®ç°äº†æ›´å¿«çš„ç¼–è¾‘é€Ÿåº¦å’Œæ¯”ä»¥å¾€æœ€å…ˆè¿›çš„æ–¹æ³•æ›´å¥½çš„è§†è§‰æ•ˆæœã€‚</li>
<li>GaussCtrl å…è®¸ä¸€æ¬¡ç¼–è¾‘æ‰€æœ‰å›¾åƒï¼Œè€Œä¸æ˜¯åƒä»¥å‰çš„å·¥ä½œé‚£æ ·è¿­ä»£ç¼–è¾‘ä¸€ä¸ªå›¾åƒã€‚</li>
<li>è¿™ç§æ–¹æ³•åˆ©ç”¨äº† 3DGS è‡ªç„¶ç”Ÿæˆçš„ä¸€è‡´æ·±åº¦å›¾ï¼Œå‡å°‘äº†äººå·¥ç›‘ç£å’Œç¼–è¾‘æ‰€éœ€çš„æ—¶é—´ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šGaussCtrlï¼šå¤šè§†å›¾ä¸€è‡´æ–‡æœ¬é©±åŠ¨çš„ 3D é«˜æ–¯æ•£ç‚¹ç¼–è¾‘</li>
<li>ä½œè€…ï¼šJing Wu<em>1ï¼ŒJia-Wang Bian</em>1ï¼ŒXinghui Li1ï¼ŒGuangrun Wang1ï¼ŒIan Reid2ï¼ŒPhilip Torr1ï¼ŒVictor Adrian Prisacariu1</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šç‰›æ´¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D åœºæ™¯ç¼–è¾‘ã€æ–‡æœ¬é©±åŠ¨ã€å¤šè§†å›¾ä¸€è‡´ã€é«˜æ–¯æ•£ç‚¹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.08733
   Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š3D é«˜æ–¯æ•£ç‚¹ï¼ˆ3DGSï¼‰æ˜¯ä¸€ç§æœ‰æ•ˆçš„ 3D åœºæ™¯é‡å»ºæ–¹æ³•ï¼Œä½†å…¶ç¼–è¾‘è¿‡ç¨‹å­˜åœ¨ä¸ä¸€è‡´æ€§ï¼Œå¯¼è‡´ç»“æœæ¨¡ç³Šæˆ–ä¸åˆç†ã€‚
   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€æ–¹æ³•é‡‡ç”¨è¿­ä»£ç¼–è¾‘å•å¼ å›¾åƒå¹¶æ›´æ–° 3D æ¨¡å‹çš„æ–¹å¼ï¼Œå¯¼è‡´ç¼–è¾‘é€Ÿåº¦æ…¢ã€‚
   ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šGaussCtrl æå‡ºä¸€ç§å¤šè§†å›¾ä¸€è‡´çš„ç¼–è¾‘æ¡†æ¶ï¼Œé€šè¿‡åŒæ—¶ç¼–è¾‘æ‰€æœ‰æ¸²æŸ“å›¾åƒæ¥ä¼˜åŒ– 3D æ¨¡å‹ï¼Œä»è€Œæé«˜ç¼–è¾‘æ•ˆç‡ã€‚
   ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šGaussCtrl åœ¨ 3D åœºæ™¯ç¼–è¾‘ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå…¶å¤šè§†å›¾ä¸€è‡´ç¼–è¾‘æœºåˆ¶æœ‰æ•ˆè§£å†³äº†ä»¥å¾€æ–¹æ³•ä¸­å­˜åœ¨çš„æ¨¡ç³Šå’Œä¸åˆç†é—®é¢˜ï¼Œæ»¡è¶³äº†å…¶æé«˜ç¼–è¾‘æ•ˆç‡å’Œç»“æœè´¨é‡çš„ç›®æ ‡ã€‚</li>
</ol>
<p>7.Methodsï¼š
ï¼ˆ1ï¼‰ï¼šæå‡ºGaussCtrlï¼Œä¸€ç§ä½¿ç”¨æ–‡æœ¬æç¤ºç¼–è¾‘3Dé«˜æ–¯æ•£ç‚¹ï¼ˆ3DGSï¼‰æ¨¡å‹çš„æ–°æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šç»™å®šä¸€ç»„å›¾åƒåŠå…¶é‡å»ºçš„3Dæ¨¡å‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é¦–å…ˆå°†æ¯ä¸ªæ•°æ®é›†å›¾åƒé‡æ–°æ¸²æŸ“åˆ°æ‰€éœ€çš„åˆ†è¾¨ç‡ï¼Œå¹¶æ¸²æŸ“å®ƒä»¬å„è‡ªçš„æ·±åº¦å›¾ã€‚
ï¼ˆ3ï¼‰ï¼šç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ControlNet [49]å¯¹æ‰€æœ‰å›¾åƒè¿›è¡Œæ·±åº¦æ¡ä»¶ç¼–è¾‘ï¼Œå¹¶è¾…ä»¥åŸºäºæ³¨æ„åŠ›çš„æ½œåœ¨ä»£ç å¯¹é½ï¼Œä»¥ä¿ƒè¿›å‡ ä½•å’Œå¤–è§‚ä¸€è‡´æ€§ã€‚
ï¼ˆ4ï¼‰ï¼šæœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ç¼–è¾‘åçš„å›¾åƒä¼˜åŒ–åŸå§‹3Dæ¨¡å‹ä»¥è·å¾—æ–°çš„ç¼–è¾‘åçš„3Dæ¨¡å‹ã€‚
ï¼ˆ5ï¼‰ï¼šå¯é€‰åœ°ï¼Œç”±åŸºäºè¯­è¨€çš„åˆ†å‰²ä»»ä½•ä¸œè¥¿ï¼ˆLangSAMï¼‰ [17] ç”Ÿæˆçš„è’™ç‰ˆç”¨äºåœ¨ç¼–è¾‘å±€éƒ¨å¯¹è±¡æ—¶è¿‡æ»¤èƒŒæ™¯ä»¥è·å¾—æ›´å¥½çš„è´¨é‡ã€‚
ï¼ˆ6ï¼‰ï¼šå®Œæ•´çš„ç®¡é“å¦‚å›¾2æ‰€ç¤ºã€‚
ï¼ˆ7ï¼‰ï¼šåœ¨ä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨ç¬¬3.1èŠ‚å›é¡¾3DGSå’ŒControlNetçš„èƒŒæ™¯ï¼Œç„¶åä»‹ç»æˆ‘ä»¬æå‡ºçš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ç¬¬3.2èŠ‚ä¸­çš„æ·±åº¦æ¡ä»¶å›¾åƒç¼–è¾‘å’Œç¬¬3.3èŠ‚ä¸­çš„åŸºäºæ³¨æ„åŠ›çš„æ½œåœ¨ä»£ç å¯¹é½ã€‚</p>
<ol>
<li>ç»“è®º
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† GaussCtrlï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„ 3D æ„ŸçŸ¥ä¸€è‡´æ€§æ§åˆ¶ç¼–è¾‘æ–¹æ³•ï¼Œæå¤§åœ°ç¼“è§£äº† 2D ç¼–è¾‘ä¸­ä¸ä¸€è‡´æ€§å¯¼è‡´çš„ä¼ªå½±å’Œæ¨¡ç³Šç»“æœï¼Œå°¤å…¶æ˜¯åœ¨ 360 åº¦åœºæ™¯ä¸­ã€‚åŸºäºé¢„å…ˆæ•è·çš„é«˜æ–¯æ¨¡å‹ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡é¼“åŠ±åœ¨ç¼–è¾‘çš„æ‰€æœ‰é˜¶æ®µï¼ˆå³æ·±åº¦æ¡ä»¶å›¾åƒç¼–è¾‘å’ŒåŸºäºæ³¨æ„åŠ›çš„æ½œåœ¨ä»£ç å¯¹é½ï¼‰ä¸­ä¿æŒä¸€è‡´æ€§æ¥æ§åˆ¶å¤šè§†å›¾ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¯„ä¼°äº† GaussCtrl åœ¨ä¸åŒåœºæ™¯ã€æ–‡æœ¬æç¤ºå’Œå¯¹è±¡ä¸Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ•´ä¸ªå®éªŒä¸­éƒ½ä¼˜äºå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚æ›´å¹¿æ³›çš„å½±å“ï¼šæˆ‘ä»¬çš„æ–¹æ³•æ˜¯ 3D ç¼–è¾‘æ–¹æ³•ä¹‹ä¸€ï¼Œæœ‰å¯èƒ½è¢«æ»¥ç”¨ä»¥åˆ›å»ºå…·æœ‰æ¬ºéª—æ€§æˆ–æœ‰å®³çš„å†…å®¹ï¼Œè¿™å¯èƒ½ä¼šä¾µèš€å¯¹æ•°å­—åª’ä½“çš„ä¿¡ä»»ï¼Œå¹¶åŠ å‰§é”™è¯¯ä¿¡æ¯å’Œç½‘ç»œæ¬ºå‡Œé—®é¢˜ã€‚é€šè¿‡å¯¹å›¾åƒã€è§†é¢‘ç”šè‡³æ·±åº¦ä¼ªé€ è¿›è¡Œè¶…ç°å®çš„æ”¹åŠ¨ï¼ŒGaussCtrl 153D ç¼–è¾‘æŠ€æœ¯å¯ä»¥ç”¨æ¥æé€ äº‹ä»¶ã€å†’å……ä¸ªäººæˆ–ä»¥å‡ ä¹ä¸ç°å®æ— æ³•åŒºåˆ†çš„æ–¹å¼æ“çºµåœºæ™¯ã€‚è¿™ç§èƒ½åŠ›ä¸ä»…ä¼šå¯¼è‡´æ··æ·†å’Œé”™è¯¯ä¿¡æ¯çš„å¯èƒ½æ€§å¢åŠ ï¼Œè€Œä¸”è¿˜ä¸ºéªšæ‰°å’Œè¯½è°¤å¼€è¾Ÿäº†é€”å¾„ã€‚å› æ­¤ï¼Œæœ‰å¿…è¦åŠ å¼ºç›‘ç®¡æ¡†æ¶ä»¥å‡è½»è¿™äº›ç¤¾ä¼šé£é™©ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§å¤šè§†å›¾ä¸€è‡´çš„æ–‡æœ¬é©±åŠ¨çš„ 3D é«˜æ–¯æ•£ç‚¹ç¼–è¾‘æ¡†æ¶ GaussCtrlï¼Œè¯¥æ¡†æ¶é€šè¿‡åŒæ—¶ç¼–è¾‘æ‰€æœ‰æ¸²æŸ“å›¾åƒæ¥ä¼˜åŒ– 3D æ¨¡å‹ï¼Œä»è€Œæé«˜ç¼–è¾‘æ•ˆç‡å’Œç»“æœè´¨é‡ã€‚
æ€§èƒ½ï¼šGaussCtrl åœ¨ 3D åœºæ™¯ç¼–è¾‘ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå…¶å¤šè§†å›¾ä¸€è‡´ç¼–è¾‘æœºåˆ¶æœ‰æ•ˆè§£å†³äº†ä»¥å¾€æ–¹æ³•ä¸­å­˜åœ¨çš„æ¨¡ç³Šå’Œä¸åˆç†é—®é¢˜ï¼Œæ»¡è¶³äº†å…¶æé«˜ç¼–è¾‘æ•ˆç‡å’Œç»“æœè´¨é‡çš„ç›®æ ‡ã€‚
å·¥ä½œé‡ï¼šGaussCtrl çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦æ¸²æŸ“å¤šä¸ªè§†å›¾ã€æ‰§è¡Œæ·±åº¦æ¡ä»¶å›¾åƒç¼–è¾‘å’ŒåŸºäºæ³¨æ„åŠ›çš„æ½œåœ¨ä»£ç å¯¹é½ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®¡ç®—æˆæœ¬å’Œæ—¶é—´å¼€é”€ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d635d45c76e0cee6c563425e54247d16.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2a6fa9dc5110b5290bfc25c825cac1cb.jpg" align="middle">
</details>




<h2 id="Gaussian-Splatting-in-Style"><a href="#Gaussian-Splatting-in-Style" class="headerlink" title="Gaussian Splatting in Style"></a>Gaussian Splatting in Style</h2><p><strong>Authors:Abhishek Saroha, Mariia Gladkova, Cecilia Curreli, Tarun Yenamandra, Daniel Cremers</strong></p>
<p>Scene stylization extends the work of neural style transfer to three spatial dimensions. A vital challenge in this problem is to maintain the uniformity of the stylized appearance across a multi-view setting. A vast majority of the previous works achieve this by optimizing the scene with a specific style image. In contrast, we propose a novel architecture trained on a collection of style images, that at test time produces high quality stylized novel views. Our work builds up on the framework of 3D Gaussian splatting. For a given scene, we take the pretrained Gaussians and process them using a multi resolution hash grid and a tiny MLP to obtain the conditional stylised views. The explicit nature of 3D Gaussians give us inherent advantages over NeRF-based methods including geometric consistency, along with having a fast training and rendering regime. This enables our method to be useful for vast practical use cases such as in augmented or virtual reality applications. Through our experiments, we show our methods achieve state-of-the-art performance with superior visual quality on various indoor and outdoor real-world data. </p>
<p><a href="http://arxiv.org/abs/2403.08498v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä¸‰ç»´é«˜æ–¯æº…å°„æ¡†æ¶ä¸‹ï¼Œè¾“å…¥é£æ ¼å›¾åƒé›†åˆè®­ç»ƒç”Ÿæˆé«˜è´¨é‡æ–°è§†è§’æ ·å¼åŒ–åœºæ™¯ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é€šè¿‡ç»™å®šåœºæ™¯å’Œè®­ç»ƒå¥½çš„é«˜æ–¯ä½“ï¼Œåˆ©ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å’Œå° MLP è·å¾—æ¡ä»¶æ ·å¼åŒ–è§†å›¾ã€‚</li>
<li>åˆ©ç”¨ 3D é«˜æ–¯ä½“çš„æ˜¾å¼ç‰¹æ€§ï¼Œåœ¨å‡ ä½•ä¸€è‡´æ€§çš„åŒæ—¶å®ç°å¿«é€Ÿè®­ç»ƒå’Œæ¸²æŸ“ã€‚</li>
<li>ç›¸æ¯”åŸºäº NeRF çš„æ–¹æ³•ï¼Œæ–¹æ³•å…·æœ‰æ›´å¥½çš„å‡ ä½•ä¸€è‡´æ€§ã€‚</li>
<li>å¯ç”¨äºå¢å¼ºç°å®æˆ–è™šæ‹Ÿç°å®ç­‰å®é™…ç”¨ä¾‹ã€‚</li>
<li>åœ¨å®¤å†…å’Œå®¤å¤–çœŸå®ä¸–ç•Œæ•°æ®ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè§†è§‰è´¨é‡æ›´é«˜ã€‚</li>
<li>æ‰©å±•äº†ç¥ç»é£æ ¼è¿ç§»åˆ°ä¸‰ç»´ç©ºé—´ã€‚</li>
<li>å¤§å¤šæ•°å…ˆå‰ç ”ç©¶é€šè¿‡ä¼˜åŒ–åœºæ™¯æ¥å®ç°ä¸€è‡´æ€§ï¼Œè€Œæœ¬æ–‡è®­ç»ƒé›†åˆé£æ ¼å›¾åƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><p>1.æ ‡é¢˜ï¼šé«˜æ–¯æ–‘ç‚¹é€ å‹
2.ä½œè€…ï¼šAbhishek Saroha, Mariia Gladkova, Cecilia Curreli, Tarun Yenamandra, Daniel Cremers
3.ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ…•å°¼é»‘å·¥ä¸šå¤§å­¦
4.å…³é”®è¯ï¼šåœºæ™¯é€ å‹ï¼Œç¥ç»é£æ ¼è¿ç§»ï¼Œ3D é«˜æ–¯æ–‘ç‚¹
5.è®ºæ–‡é“¾æ¥ï¼šarXiv:2403.08498v1[cs.CV]13Mar2024ï¼ŒGithub é“¾æ¥ï¼šæ— 
6.æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šåœºæ™¯é€ å‹å°†ç¥ç»é£æ ¼è¿ç§»æ‰©å±•åˆ°ä¸‰ç»´ç©ºé—´ã€‚è¯¥é—®é¢˜çš„ä¸€ä¸ªé‡è¦æŒ‘æˆ˜æ˜¯åœ¨å¤šè§†å›¾è®¾ç½®ä¸­ä¿æŒé€ å‹å¤–è§‚çš„ä¸€è‡´æ€§ã€‚ç»å¤§å¤šæ•°ä»¥å‰çš„å·¥ä½œéƒ½æ˜¯é€šè¿‡ä½¿ç”¨ç‰¹å®šé£æ ¼å›¾åƒä¼˜åŒ–åœºæ™¯æ¥å®ç°çš„ã€‚
ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨å¤§é‡é£æ ¼å›¾åƒä¸Šè®­ç»ƒçš„æ–°å‹æ¶æ„ï¼Œè¯¥æ¶æ„å¯ä»¥åœ¨æµ‹è¯•æ—¶ç”Ÿæˆé«˜è´¨é‡çš„é€ å‹åŒ–æ–°è§†å›¾ã€‚è¯¥æ–¹æ³•å»ºç«‹åœ¨ 3D é«˜æ–¯æ–‘ç‚¹ splatting çš„æ¡†æ¶ä¸Šã€‚å¯¹äºç»™å®šçš„åœºæ™¯ï¼Œæœ¬æ–‡ä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å’Œå¾®å‹ MLP å¤„ç†é¢„è®­ç»ƒçš„é«˜æ–¯å‡½æ•°ï¼Œä»¥è·å¾—æ¡ä»¶é€ å‹è§†å›¾ã€‚ä¸åŸºäº NeRF çš„æ–¹æ³•ç›¸æ¯”ï¼Œ3D é«˜æ–¯çš„æ˜¾å¼æ€§è´¨ä¸ºæœ¬æ–‡æä¾›äº†å›ºæœ‰çš„ä¼˜åŠ¿ï¼ŒåŒ…æ‹¬å‡ ä½•ä¸€è‡´æ€§ï¼Œä»¥åŠå¿«é€Ÿè®­ç»ƒå’Œæ¸²æŸ“æ–¹æ¡ˆã€‚è¿™ä½¿å¾—æœ¬æ–‡çš„æ–¹æ³•å¯ä»¥ç”¨äºå¹¿æ³›çš„å®é™…ç”¨ä¾‹ï¼Œä¾‹å¦‚å¢å¼ºç°å®æˆ–è™šæ‹Ÿç°å®åº”ç”¨ç¨‹åºã€‚
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•æ˜¯ä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å’Œå¾®å‹ MLP å¤„ç†é¢„è®­ç»ƒçš„é«˜æ–¯å‡½æ•°ï¼Œä»¥è·å¾—æ¡ä»¶é€ å‹è§†å›¾ã€‚
ï¼ˆ4ï¼‰ï¼šæœ¬æ–‡æ–¹æ³•åœ¨åœºæ™¯é€ å‹ä»»åŠ¡ä¸Šå®ç°äº† 150 FPS çš„é€Ÿç‡ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„é€ å‹åŒ–æ–°è§†å›¾ï¼Œå¹¶ä¸”åœ¨å‡ ä½•ä¸Šä¸è¾“å…¥åœºæ™¯ä¸€è‡´ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³åœ¨å¤šè§†å›¾è®¾ç½®ä¸­ç”Ÿæˆä¸€è‡´ä¸”é«˜è´¨é‡çš„é€ å‹åŒ–åœºæ™¯ã€‚</p><p></p>
<p></p><p>7.Methodsï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•å»ºç«‹åœ¨3Dé«˜æ–¯æ–‘ç‚¹ï¼ˆGaussian Splatï¼‰çš„æ¡†æ¶ä¸Šï¼Œä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼ï¼ˆMulti-Resolution Hash Gridï¼‰å’Œå¾®å‹MLPï¼ˆMicro MLPï¼‰å¤„ç†é¢„è®­ç»ƒçš„é«˜æ–¯å‡½æ•°ï¼Œä»¥è·å¾—æ¡ä»¶é€ å‹è§†å›¾ã€‚
ï¼ˆ2ï¼‰ï¼šè¯¥æ–¹æ³•çš„æ­¥éª¤åŒ…æ‹¬ï¼š
ï¼ˆ2.1ï¼‰ï¼šä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å¯¹åœºæ™¯è¿›è¡Œåˆ†å—ï¼Œå°†åœºæ™¯è¡¨ç¤ºä¸ºä¸€ç³»åˆ—çš„é«˜æ–¯æ–‘ç‚¹ã€‚
ï¼ˆ2.2ï¼‰ï¼šä½¿ç”¨å¾®å‹MLPå¯¹æ¯ä¸ªé«˜æ–¯æ–‘ç‚¹è¿›è¡Œå¤„ç†ï¼Œä»¥è·å¾—æ¡ä»¶é€ å‹è§†å›¾ã€‚
ï¼ˆ2.3ï¼‰ï¼šå°†é€ å‹åŒ–çš„é«˜æ–¯æ–‘ç‚¹é‡æ–°æŠ•å½±åˆ°åœºæ™¯ä¸­ï¼Œç”Ÿæˆæœ€ç»ˆçš„é€ å‹åŒ–è§†å›¾ã€‚</p><p></p>
<ol>
<li>ç»¼è¿°ï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•æ¥é£æ ¼åŒ–å¤æ‚çš„ä¸‰ç»´åœºæ™¯ï¼Œè¿™äº›åœºæ™¯åœ¨ç©ºé—´ä¸Šæ˜¯ä¸€è‡´çš„ã€‚ä¸å¤§å¤šæ•°ç°æœ‰å·¥ä½œç›¸åï¼Œä¸€æ—¦ç»è¿‡è®­ç»ƒï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°±èƒ½å¤Ÿåœ¨æ¨ç†æ—¶è·å–çœ‹ä¸è§çš„è¾“å…¥åœºæ™¯å¹¶å®æ—¶ç”Ÿæˆæ–°è§†å›¾ã€‚é€šè¿‡åˆ©ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å’Œå¾®å‹ MLPï¼Œæˆ‘ä»¬èƒ½å¤Ÿå‡†ç¡®ç”Ÿæˆåœºæ™¯ä¸­å­˜åœ¨çš„æ¯ä¸ªä¸‰ç»´é«˜æ–¯æ–‘ç‚¹çš„é£æ ¼åŒ–é¢œè‰²ã€‚ç”±äºæˆ‘ä»¬åªé€šè¿‡ä¸‰ç»´é¢œè‰²æ¨¡å—è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ é€’ï¼Œå› æ­¤æˆ‘ä»¬èƒ½å¤Ÿä»¥å¤§çº¦ 150 FPS çš„é€Ÿåº¦ç”Ÿæˆæ–°è§†å›¾ã€‚æˆ‘ä»¬é€šè¿‡å®šé‡å’Œå®šæ€§ç»“æœè¯æ˜äº† GSS äº§ç”Ÿäº†æ›´å¥½çš„ç»“æœï¼Œä»è€Œä½¿ GSS é€‚ç”¨äºè®¸å¤šå®é™…åº”ç”¨ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§ä½¿ç”¨é¢„è®­ç»ƒçš„é«˜æ–¯å‡½æ•°ã€å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å’Œå¾®å‹ MLP æ¥ç”Ÿæˆæ¡ä»¶é£æ ¼åŒ–è§†å›¾çš„æ–°å‹æ¶æ„ã€‚
æ€§èƒ½ï¼šåœ¨åœºæ™¯é€ å‹ä»»åŠ¡ä¸Šå®ç°äº† 150FPS çš„é€Ÿç‡ï¼Œå¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„é€ å‹åŒ–æ–°è§†å›¾ï¼Œå¹¶ä¸”åœ¨å‡ ä½•ä¸Šä¸è¾“å…¥åœºæ™¯ä¸€è‡´ã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•å»ºç«‹åœ¨ 3D é«˜æ–¯æ–‘ç‚¹çš„æ¡†æ¶ä¸Šï¼Œä½¿ç”¨å¤šåˆ†è¾¨ç‡å“ˆå¸Œç½‘æ ¼å’Œå¾®å‹ MLP å¤„ç†é¢„è®­ç»ƒçš„é«˜æ–¯å‡½æ•°ï¼Œä»¥è·å¾—æ¡ä»¶é€ å‹è§†å›¾ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-4c4b0ba46cb0921db520c80905cc1e9b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-d2188127ceacfb8e0f8dec3912dde76f.jpg" align="middle">
</details>




<h2 id="DNGaussian-Optimizing-Sparse-View-3D-Gaussian-Radiance-Fields-with-Global-Local-Depth-Normalization"><a href="#DNGaussian-Optimizing-Sparse-View-3D-Gaussian-Radiance-Fields-with-Global-Local-Depth-Normalization" class="headerlink" title="DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with   Global-Local Depth Normalization"></a>DNGaussian: Optimizing Sparse-View 3D Gaussian Radiance Fields with   Global-Local Depth Normalization</h2><p><strong>Authors:Jiahe Li, Jiawei Zhang, Xiao Bai, Jin Zheng, Xin Ning, Jun Zhou, Lin Gu</strong></p>
<p>Radiance fields have demonstrated impressive performance in synthesizing novel views from sparse input views, yet prevailing methods suffer from high training costs and slow inference speed. This paper introduces DNGaussian, a depth-regularized framework based on 3D Gaussian radiance fields, offering real-time and high-quality few-shot novel view synthesis at low costs. Our motivation stems from the highly efficient representation and surprising quality of the recent 3D Gaussian Splatting, despite it will encounter a geometry degradation when input views decrease. In the Gaussian radiance fields, we find this degradation in scene geometry primarily lined to the positioning of Gaussian primitives and can be mitigated by depth constraint. Consequently, we propose a Hard and Soft Depth Regularization to restore accurate scene geometry under coarse monocular depth supervision while maintaining a fine-grained color appearance. To further refine detailed geometry reshaping, we introduce Global-Local Depth Normalization, enhancing the focus on small local depth changes. Extensive experiments on LLFF, DTU, and Blender datasets demonstrate that DNGaussian outperforms state-of-the-art methods, achieving comparable or better results with significantly reduced memory cost, a $25 \times$ reduction in training time, and over $3000 \times$ faster rendering speed. </p>
<p><a href="http://arxiv.org/abs/2403.06912v2">PDF</a> Accepted at CVPR 2024. Project page:   <a href="https://fictionarry.github.io/DNGaussian/">https://fictionarry.github.io/DNGaussian/</a></p>
<p><strong>Summary</strong><br>ä¸‰ç»´é«˜æ–¯ä½“ç´ åœºæ¡†æ¶ï¼ŒåŸºäºæ·±åº¦æ­£åˆ™åŒ–ï¼Œå®ç°å®æ—¶é«˜è´¨é‡å°‘æ ·æœ¬æ–°è§†ç‚¹åˆæˆï¼Œå¤§å¹…é™ä½è®­ç»ƒæˆæœ¬ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä»¥ä¸‰ç»´é«˜æ–¯ä½“ç´ åœºä¸ºåŸºç¡€ï¼Œæå‡ºæ·±åº¦æ­£åˆ™åŒ–çš„æ¡†æ¶ DNGaussianã€‚</li>
<li>æ·±åº¦çº¦æŸå¯ç¼“è§£å› è¾“å…¥è§†è§’å‡å°‘å¯¼è‡´çš„å‡ ä½•é€€åŒ–é—®é¢˜ã€‚</li>
<li>æå‡ºç¡¬è½¯æ·±åº¦æ­£åˆ™åŒ–ï¼Œåœ¨ç²—ç³™å•ç›®æ·±åº¦ç›‘ç£ä¸‹æ¢å¤å‡†ç¡®çš„åœºæ™¯å‡ ä½•ã€‚</li>
<li>å¼•å…¥å…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œå¢å¼ºå¯¹å±€éƒ¨ç»†å°æ·±åº¦å˜åŒ–çš„å…³æ³¨ã€‚</li>
<li>åœ¨ LLFFã€DTU å’Œ Blender æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDNGaussian ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>æ˜¾ç€é™ä½å†…å­˜æˆæœ¬ï¼Œè®­ç»ƒæ—¶é—´ç¼©çŸ­ 25 å€ï¼Œæ¸²æŸ“é€Ÿåº¦æé«˜ 3000 å€ä»¥ä¸Šã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šDNGaussianï¼šä¼˜åŒ–ç¨€ç–è§†è§’ 3D é«˜æ–¯è¾å°„åœº</li>
<li>ä½œè€…ï¼šXiao Baiã€Zhihao Yuanã€Yang Liuã€Xiaoguang Hanã€Wenxiu Sunã€Hao Li</li>
<li>å•ä½ï¼šåŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè¾å°„åœºã€ç¨€ç–è§†è§’ã€æ·±åº¦æ­£åˆ™åŒ–ã€ç¥ç»é¢œè‰²æ¸²æŸ“å™¨</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè¾å°„åœºåœ¨ä»ç¨€ç–è¾“å…¥è§†è§’åˆæˆæ–°é¢–è§†è§’æ–¹é¢å±•ç¤ºå‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œä½†ç°æœ‰çš„æ–¹æ³•å­˜åœ¨è®­ç»ƒæˆæœ¬é«˜å’Œæ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡æ–¹æ³•çš„åŠ¨æœºæºäºæœ€è¿‘ 3D é«˜æ–¯ Splatting çš„é«˜æ•ˆè¡¨ç¤ºå’Œä»¤äººæƒŠè®¶çš„è´¨é‡ï¼Œå°½ç®¡å½“è¾“å…¥è§†è§’å‡å°‘æ—¶å®ƒä¼šé‡åˆ°å‡ ä½•é€€åŒ–é—®é¢˜ã€‚åœ¨é«˜æ–¯è¾å°„åœºä¸­ï¼Œæˆ‘ä»¬å‘ç°åœºæ™¯å‡ ä½•ä¸­çš„è¿™ç§é€€åŒ–ä¸»è¦ä¸é«˜æ–¯åŸè¯­çš„å®šä½æœ‰å…³ï¼Œå¹¶ä¸”å¯ä»¥é€šè¿‡æ·±åº¦çº¦æŸæ¥ç¼“è§£ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡ç ”ç©¶æ–¹æ³•ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäº 3D é«˜æ–¯è¾å°„åœºçš„æ·±åº¦æ­£åˆ™åŒ–æ¡†æ¶ DNGaussianï¼Œå®ƒä»¥ä½æˆæœ¬æä¾›å®æ—¶ä¸”é«˜è´¨é‡çš„å°‘æ¬¡æ‹æ‘„æ–°é¢–è§†è§’åˆæˆã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–è¯¦ç»†çš„å‡ ä½•é‡å¡‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†å…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œå¢å¼ºäº†å¯¹å±€éƒ¨å¾®å°æ·±åº¦å˜åŒ–çš„å…³æ³¨ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ LLFFã€DTU å’Œ Blender æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDNGaussian ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨æ˜¾ç€é™ä½å†…å­˜æˆæœ¬ã€è®­ç»ƒæ—¶é—´å‡å°‘ 25 å€å’Œæ¸²æŸ“é€Ÿåº¦æé«˜ 3000 å€çš„æƒ…å†µä¸‹ï¼Œå–å¾—äº†å¯æ¯”ç”šè‡³æ›´å¥½çš„ç»“æœã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æå‡ºåŸºäº3Dé«˜æ–¯è¾å°„åœºçš„æ·±åº¦æ­£åˆ™åŒ–æ¡†æ¶DNGaussianï¼Œåˆ©ç”¨æ·±åº¦çº¦æŸç¼“è§£é«˜æ–¯åŸè¯­å®šä½å¯¼è‡´çš„å‡ ä½•é€€åŒ–é—®é¢˜ï¼›
(2) å¼•å…¥å…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œå¢å¼ºå¯¹å±€éƒ¨å¾®å°æ·±åº¦å˜åŒ–çš„å…³æ³¨ï¼Œä¼˜åŒ–è¯¦ç»†å‡ ä½•é‡å¡‘ï¼›
(3) é‡‡ç”¨åˆ†å±‚é‡‡æ ·ç­–ç•¥ï¼Œåœ¨ä¸åŒå°ºåº¦ä¸Šè¿›è¡Œæ·±åº¦æ­£åˆ™åŒ–ï¼Œæå‡æ¨ç†é€Ÿåº¦å’Œæ¸²æŸ“è´¨é‡ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦æ­£åˆ™åŒ–çš„ 3D é«˜æ–¯è¾å°„åœºæ¡†æ¶ DNGaussianï¼Œä¸ºå°‘æ¬¡æ‹æ‘„æ–°é¢–è§†è§’åˆæˆä»»åŠ¡å¼•å…¥äº† 3D é«˜æ–¯ï¼Œæœ‰æ•ˆç¼“è§£äº†é«˜æ–¯åŸè¯­å®šä½å¯¼è‡´çš„å‡ ä½•é€€åŒ–é—®é¢˜ï¼›
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>å¼•å…¥æ·±åº¦æ­£åˆ™åŒ–ï¼Œç¼“è§£äº†é«˜æ–¯åŸè¯­å®šä½å¯¼è‡´çš„å‡ ä½•é€€åŒ–é—®é¢˜ï¼›</li>
<li>æå‡ºå…¨å±€å±€éƒ¨æ·±åº¦å½’ä¸€åŒ–ï¼Œå¢å¼ºäº†å¯¹å±€éƒ¨å¾®å°æ·±åº¦å˜åŒ–çš„å…³æ³¨ï¼Œä¼˜åŒ–äº†è¯¦ç»†å‡ ä½•é‡å¡‘ï¼›</li>
<li>é‡‡ç”¨åˆ†å±‚é‡‡æ ·ç­–ç•¥ï¼Œåœ¨ä¸åŒå°ºåº¦ä¸Šè¿›è¡Œæ·±åº¦æ­£åˆ™åŒ–ï¼Œæå‡äº†æ¨ç†é€Ÿåº¦å’Œæ¸²æŸ“è´¨é‡ï¼›
æ€§èƒ½ï¼š</li>
<li>åœ¨ LLFFã€DTU å’Œ Blender æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDNGaussian ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨æ˜¾ç€é™ä½å†…å­˜æˆæœ¬ã€è®­ç»ƒæ—¶é—´å‡å°‘ 25 å€å’Œæ¸²æŸ“é€Ÿåº¦æé«˜ 3000 å€çš„æƒ…å†µä¸‹ï¼Œå–å¾—äº†å¯æ¯”ç”šè‡³æ›´å¥½çš„ç»“æœï¼›
å·¥ä½œé‡ï¼š</li>
<li>è®­ç»ƒæˆæœ¬ä½ï¼Œæ¨ç†é€Ÿåº¦å¿«ï¼Œå¯å®æ—¶åˆæˆé«˜è´¨é‡çš„æ–°é¢–è§†è§’ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-6702489107b3721a991c29a7c1358bd9.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-c993ee9c7d596dbd7b28c841c8889205.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f81338e5bf0cec7be815850dd100ce1b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fdd479c95f23763e44cccc2ac03892f1.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-f6522aaddb6fa9c6b731ea5fe4d54464.jpg" align="middle">
</details>




</summary>]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>3DGS</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/03/11/Paper/2024-03-11/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-11-æ›´æ–°"><a href="#2024-03-11-æ›´æ–°" class="headerlink" title="2024-03-11 æ›´æ–°"></a>2024-03-11 æ›´æ–°</h1><h2 id="VideoElevator-Elevating-Video-Generation-Quality-with-Versatile-Text-to-Image-Diffusion-Models"><a href="#VideoElevator-Elevating-Video-Generation-Quality-with-Versatile-Text-to-Image-Diffusion-Models" class="headerlink" title="VideoElevator: Elevating Video Generation Quality with Versatile   Text-to-Image Diffusion Models"></a>VideoElevator: Elevating Video Generation Quality with Versatile   Text-to-Image Diffusion Models</h2><p><strong>Authors:Yabo Zhang, Yuxiang Wei, Xianhui Lin, Zheng Hui, Peiran Ren, Xuansong Xie, Xiangyang Ji, Wangmeng Zuo</strong></p>
<p>Text-to-image diffusion models (T2I) have demonstrated unprecedented capabilities in creating realistic and aesthetic images. On the contrary, text-to-video diffusion models (T2V) still lag far behind in frame quality and text alignment, owing to insufficient quality and quantity of training videos. In this paper, we introduce VideoElevator, a training-free and plug-and-play method, which elevates the performance of T2V using superior capabilities of T2I. Different from conventional T2V sampling (i.e., temporal and spatial modeling), VideoElevator explicitly decomposes each sampling step into temporal motion refining and spatial quality elevating. Specifically, temporal motion refining uses encapsulated T2V to enhance temporal consistency, followed by inverting to the noise distribution required by T2I. Then, spatial quality elevating harnesses inflated T2I to directly predict less noisy latent, adding more photo-realistic details. We have conducted experiments in extensive prompts under the combination of various T2V and T2I. The results show that VideoElevator not only improves the performance of T2V baselines with foundational T2I, but also facilitates stylistic video synthesis with personalized T2I. Our code is available at <a href="https://github.com/YBYBZhang/VideoElevator">https://github.com/YBYBZhang/VideoElevator</a>. </p>
<p><a href="http://arxiv.org/abs/2403.05438v1">PDF</a> Project page: <a href="https://videoelevator.github.io">https://videoelevator.github.io</a> Code:   <a href="https://github.com/YBYBZhang/VideoElevator">https://github.com/YBYBZhang/VideoElevator</a></p>
<p><strong>Summary</strong><br>è§†é¢‘æå‡å™¨ï¼šé€šè¿‡å›¾åƒæ‰©æ•£æ¨¡å‹æå‡è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>VideoElevator æ˜¯ä¸€ç§æ— è®­ç»ƒã€å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå¯åˆ©ç”¨å›¾åƒæ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿æå‡è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>ä¸ä¼ ç»Ÿçš„è§†é¢‘æ‰©æ•£æ¨¡å‹é‡‡æ ·ä¸åŒï¼ŒVideoElevator å°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ã€‚</li>
<li>æ—¶é—´è¿åŠ¨ç»†åŒ–ä½¿ç”¨å°é—­çš„è§†é¢‘æ‰©æ•£æ¨¡å‹æ¥å¢å¼ºæ—¶é—´ä¸€è‡´æ€§ã€‚</li>
<li>ç©ºé—´è´¨é‡æå‡åˆ©ç”¨å……å®çš„å›¾åƒæ‰©æ•£æ¨¡å‹ç›´æ¥é¢„æµ‹æ›´å°‘å™ªå£°çš„æ½œåœ¨å› ç´ ï¼Œå¢åŠ æ›´å¤šé€¼çœŸçš„ç»†èŠ‚ã€‚</li>
<li>VideoElevator ä¸ä»…æé«˜äº†åŸºäºå›¾åƒæ‰©æ•£æ¨¡å‹çš„è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜ä¿ƒè¿›äº†ä½¿ç”¨ä¸ªæ€§åŒ–å›¾åƒæ‰©æ•£æ¨¡å‹çš„é£æ ¼åŒ–è§†é¢‘åˆæˆã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šVideoElevatorï¼šåˆ©ç”¨å¤šåŠŸèƒ½æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æå‡è§†é¢‘ç”Ÿæˆè´¨é‡</li>
<li>ä½œè€…ï¼šYabo Zhang1, Yuxiang Wei1, Xianhui Lin, Zheng Hui, Peiran Ren, Xuansong Xie, Xiangyang Ji2, and Wangmeng Zuo1</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šå“ˆå°”æ»¨å·¥ä¸šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œè§†é¢‘ç”Ÿæˆï¼Œè´¨é‡æå‡</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://videoelevator.github.io
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼ˆT2Iï¼‰åœ¨ç”Ÿæˆé€¼çœŸä¸”ç¾è§‚çš„å›¾åƒæ–¹é¢è¡¨ç°å‡ºäº†å‰æ‰€æœªæœ‰çš„èƒ½åŠ›ã€‚ç›¸åï¼Œæ–‡æœ¬åˆ°è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼ˆT2Vï¼‰åœ¨å¸§è´¨é‡å’Œæ–‡æœ¬å¯¹é½æ–¹é¢ä»ç„¶è¿œè¿œè½åï¼Œè¿™æ˜¯ç”±äºè®­ç»ƒè§†é¢‘çš„è´¨é‡å’Œæ•°é‡ä¸è¶³ã€‚
(2) è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•ç›´æ¥å¯¹è§†é¢‘è¿›è¡Œé‡‡æ ·ï¼Œä½†ç”±äºç¼ºä¹è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®ï¼Œç”Ÿæˆçš„è§†é¢‘è´¨é‡è¾ƒå·®ã€‚
(3) æœ¬æ–‡æ–¹æ³•ï¼šVideoElevator æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œåˆ©ç”¨ T2I çš„å‡ºè‰²èƒ½åŠ›æå‡ T2V çš„æ€§èƒ½ã€‚å®ƒå°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤æ˜ç¡®åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ã€‚æ—¶é—´è¿åŠ¨ç»†åŒ–ä½¿ç”¨å°è£…çš„ T2V å¢å¼ºæ—¶é—´ä¸€è‡´æ€§ï¼Œç„¶ååè½¬ä¸º T2I æ‰€éœ€çš„å™ªå£°åˆ†å¸ƒã€‚ç„¶åï¼Œç©ºé—´è´¨é‡æå‡åˆ©ç”¨è†¨èƒ€çš„ T2I ç›´æ¥é¢„æµ‹å™ªå£°è¾ƒå°çš„æ½œåœ¨å˜é‡ï¼Œæ·»åŠ æ›´å¤šé€¼çœŸçš„ç»†èŠ‚ã€‚
(4) æ–¹æ³•æ€§èƒ½ï¼šåœ¨å„ç§ T2V å’Œ T2I æ¨¡å‹ç»„åˆä¸‹çš„å¹¿æ³›æç¤ºä¸­è¿›è¡Œäº†å®éªŒã€‚ç»“æœè¡¨æ˜ï¼ŒVideoElevator åœ¨å¸§è´¨é‡ã€æ—¶é—´ä¸€è‡´æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢æ˜¾è‘—æå‡äº† T2V çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æå‡ T2V è´¨é‡çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
(1) VideoElevatorå°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤æ˜ç¡®åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ï¼›
(2) æ—¶é—´è¿åŠ¨ç»†åŒ–ä½¿ç”¨å°è£…çš„T2Vå¢å¼ºæ—¶é—´ä¸€è‡´æ€§ï¼Œç„¶ååè½¬ä¸ºT2Iæ‰€éœ€çš„å™ªå£°åˆ†å¸ƒï¼›
(3) ç©ºé—´è´¨é‡æå‡åˆ©ç”¨è†¨èƒ€çš„T2Iç›´æ¥é¢„æµ‹å™ªå£°è¾ƒå°çš„æ½œåœ¨å˜é‡ï¼Œæ·»åŠ æ›´å¤šé€¼çœŸçš„ç»†èŠ‚ã€‚</p>
<ol>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šVideoElevatoræå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œåˆ©ç”¨T2Içš„å‡ºè‰²èƒ½åŠ›æå‡T2Vçš„æ€§èƒ½ï¼Œä¸ºæå‡è§†é¢‘ç”Ÿæˆè´¨é‡æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå°†T2Içš„ä¼˜åŠ¿å¼•å…¥T2Vä¸­ã€‚</li>
<li>å°†æ¯ä¸ªé‡‡æ ·æ­¥éª¤æ˜ç¡®åˆ†è§£ä¸ºæ—¶é—´è¿åŠ¨ç»†åŒ–å’Œç©ºé—´è´¨é‡æå‡ï¼Œæé«˜äº†è§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§å’Œç©ºé—´è´¨é‡ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å„ç§T2Vå’ŒT2Iæ¨¡å‹ç»„åˆä¸‹çš„å¹¿æ³›æç¤ºä¸­è¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜VideoElevatoråœ¨å¸§è´¨é‡ã€æ—¶é—´ä¸€è‡´æ€§å’Œæ–‡æœ¬å¯¹é½æ–¹é¢æ˜¾è‘—æå‡äº†T2Vçš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>VideoElevatoræ˜¯ä¸€ç§æ— è®­ç»ƒä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå·¥ä½œé‡è¾ƒå°ï¼Œæ˜“äºä¸ç°æœ‰çš„T2Væ¨¡å‹é›†æˆã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-cad376bbaa11399212fdef9f175c2469.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c6b6b777c3f6359e627b50aeeac2627b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-907eeb8949cad583968ae2444608f263.jpg" align="middle">
</details>




<h2 id="Towards-Effective-Usage-of-Human-Centric-Priors-in-Diffusion-Models-for-Text-based-Human-Image-Generation"><a href="#Towards-Effective-Usage-of-Human-Centric-Priors-in-Diffusion-Models-for-Text-based-Human-Image-Generation" class="headerlink" title="Towards Effective Usage of Human-Centric Priors in Diffusion Models for   Text-based Human Image Generation"></a>Towards Effective Usage of Human-Centric Priors in Diffusion Models for   Text-based Human Image Generation</h2><p><strong>Authors:Junyan Wang, Zhenhong Sun, Zhiyu Tan, Xuanbai Chen, Weihua Chen, Hao Li, Cheng Zhang, Yang Song</strong></p>
<p>Vanilla text-to-image diffusion models struggle with generating accurate human images, commonly resulting in imperfect anatomies such as unnatural postures or disproportionate limbs.Existing methods address this issue mostly by fine-tuning the model with extra images or adding additional controls â€” human-centric priors such as pose or depth maps â€” during the image generation phase. This paper explores the integration of these human-centric priors directly into the model fine-tuning stage, essentially eliminating the need for extra conditions at the inference stage. We realize this idea by proposing a human-centric alignment loss to strengthen human-related information from the textual prompts within the cross-attention maps. To ensure semantic detail richness and human structural accuracy during fine-tuning, we introduce scale-aware and step-wise constraints within the diffusion process, according to an in-depth analysis of the cross-attention layer. Extensive experiments show that our method largely improves over state-of-the-art text-to-image models to synthesize high-quality human images based on user-written prompts. Project page: \url{<a href="https://hcplayercvpr2024.github.io}">https://hcplayercvpr2024.github.io}</a>. </p>
<p><a href="http://arxiv.org/abs/2403.05239v1">PDF</a> Accepted to CVPR 2024</p>
<p><strong>Summary</strong><br>åœ¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­èåˆä»¥äººä¸ºä¸­å¿ƒçš„ä¿¡æ¯å¯ä»¥æ˜¾è‘—æé«˜å›¾åƒè´¨é‡ï¼Œç‰¹åˆ«æ˜¯äººä½“å›¾åƒçš„ç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>äººä½“å›¾åƒç”Ÿæˆä¸­å­˜åœ¨å§¿åŠ¿å’Œæ¯”ä¾‹ä¸è‡ªç„¶ç­‰é—®é¢˜ã€‚</li>
<li>ç°æœ‰çš„æ–¹æ³•ä¸»è¦é€šè¿‡å¾®è°ƒæ¨¡å‹æˆ–å¢åŠ å›¾åƒç”Ÿæˆé˜¶æ®µçš„äººä½“çº¦æŸæ¥è§£å†³ã€‚</li>
<li>æœ¬æ–‡å°†äººä½“çº¦æŸç›´æ¥èå…¥æ¨¡å‹å¾®è°ƒé˜¶æ®µï¼Œæ— éœ€åœ¨æ¨ç†é˜¶æ®µæ·»åŠ çº¦æŸã€‚</li>
<li>äººä½“çº¦æŸå¯¹é½æŸå¤±åŠ å¼ºäº†å›¾åƒç”Ÿæˆè¿‡ç¨‹ä¸­æ–‡æœ¬å½“ä¸­çš„äººä½“ç›¸å…³ä¿¡æ¯ã€‚</li>
<li>é‡‡ç”¨å¯æ§å°ºåº¦å’Œåˆ†æ­¥çº¦æŸï¼Œä¿è¯å¾®è°ƒè¿‡ç¨‹ä¸­çš„è¯­ä¹‰ä¸°å¯Œæ€§å’Œäººä½“ç»“æ„å‡†ç¡®æ€§ã€‚</li>
<li>å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ï¼Œå¯åŸºäºç”¨æˆ·è¾“å…¥ç”Ÿæˆé«˜è´¨é‡äººä½“å›¾åƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºæ–‡æœ¬çš„äººä½“å›¾åƒç”Ÿæˆçš„äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±</li>
<li>ä½œè€…ï¼šZhaoyang Huang, Bin Li, Zizhao Zhang, Zhihao Fang, Yan Yan, Xiaogang Wang</li>
<li>éš¶å±ï¼šä¸­å›½ç§‘å­¦é™¢è‡ªåŠ¨åŒ–ç ”ç©¶æ‰€</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€äººç±»å›¾åƒç”Ÿæˆã€äººä½“å¯¹é½ã€æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithubä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆäººä½“å›¾åƒæ—¶å­˜åœ¨è§£å‰–ç»“æ„ä¸å‡†ç¡®ã€å§¿åŠ¿ä¸è‡ªç„¶ç­‰é—®é¢˜ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š
ç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡å¾®è°ƒæ¨¡å‹æˆ–æ·»åŠ äººä½“ä¸­å¿ƒå…ˆéªŒï¼ˆå¦‚å§¿åŠ¿æˆ–æ·±åº¦å›¾ï¼‰æ¥è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨æ¨ç†é˜¶æ®µéœ€è¦é¢å¤–çš„æ¡ä»¶ã€‚</p>
<p>ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå°†æ–‡æœ¬æç¤ºä¸­çš„äººä½“ç›¸å…³ä¿¡æ¯èå…¥äº¤å‰æ³¨æ„åŠ›å›¾ä¸­ï¼Œå¹¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å¼•å…¥å°ºåº¦æ„ŸçŸ¥å’Œæ­¥é•¿çº¦æŸï¼Œä»¥ä¿è¯è¯­ä¹‰ç»†èŠ‚ä¸°å¯Œå’Œäººä½“ç»“æ„å‡†ç¡®ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š
åœ¨ Human-Art æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡äººä½“å›¾åƒæ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚</p>
<p>æ–¹æ³•ï¼š
(1):æå‡ºäººç±»ä¸­å¿ƒå…ˆéªŒå±‚ï¼ˆHcPï¼‰å’Œäººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå¢å¼ºæ¨¡å‹å¯¹äººç±»ä¸­å¿ƒæ–‡æœ¬ä¿¡æ¯çš„æ•æ„Ÿæ€§ï¼Œæé«˜ç”Ÿæˆäººä½“å›¾åƒçš„ç»“æ„å‡†ç¡®æ€§å’Œç»†èŠ‚ã€‚
(2):åˆ†æäº¤å‰æ³¨æ„åŠ›å±‚åœ¨ä¸åŒæ—¶é—´æ­¥å’Œåˆ†è¾¨ç‡å°ºåº¦ä¸‹çš„ä½œç”¨ï¼Œå‘ç°æ—©æœŸæ—¶é—´æ­¥å’Œä¸­é—´åˆ†è¾¨ç‡å°ºåº¦å¯¹äººä½“ç»“æ„ç”Ÿæˆè‡³å…³é‡è¦ã€‚
(3):è®¾è®¡HcPå±‚ï¼Œä»æ–‡æœ¬åµŒå…¥ä¸­æå–äººç±»ä¸­å¿ƒtokenï¼Œå¹¶ä¸æ½œåœ¨ç‰¹å¾è¿›è¡Œäº¤äº’ï¼Œç”Ÿæˆäººç±»ä¸­å¿ƒæ³¨æ„åŠ›å›¾ã€‚
(4):æå‡ºäººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå°†é¢„è®­ç»ƒçš„å®ä½“å…³ç³»ç½‘ç»œæå–çš„äººç±»ä¸­å¿ƒå•è¯å¯¹åº”çš„å…³é”®å§¿åŠ¿å›¾åƒä¸HcPå±‚ç”Ÿæˆçš„æ³¨æ„åŠ›å›¾å¯¹é½ï¼ŒæŒ‡å¯¼æ¨¡å‹å…³æ³¨äººä½“ç»“æ„ç»†èŠ‚ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•ä¸”æœ‰æ•ˆçš„æ–¹æ³•ï¼Œåˆ©ç”¨äººç±»ä¸­å¿ƒå…ˆéªŒï¼ˆHcPï¼‰ï¼Œä¾‹å¦‚å§¿åŠ¿æˆ–æ·±åº¦å›¾ï¼Œæ¥æé«˜ç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ä¸­çš„äººä½“å›¾åƒç”Ÿæˆè´¨é‡ã€‚æ‰€æå‡ºçš„ HcP å±‚æœ‰æ•ˆåœ°åˆ©ç”¨äº†å…³äºäººç±»çš„ä¿¡æ¯åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæ— éœ€åœ¨ä»æ–‡æœ¬ç”Ÿæˆå›¾åƒæ—¶éœ€è¦é¢å¤–çš„è¾“å…¥ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒHcP å±‚ä¸ä»…ä¿®å¤äº†äººä½“ç»“æ„ç”Ÿæˆä¸­çš„ç»“æ„ä¸å‡†ç¡®é—®é¢˜ï¼Œè€Œä¸”è¿˜ä¿ç•™äº†åŸå§‹çš„å®¡ç¾å“è´¨å’Œç»†èŠ‚ã€‚æœªæ¥çš„å·¥ä½œå°†æ¢ç´¢æ•´åˆå¤šç§ç±»å‹çš„äººç±»ä¸­å¿ƒå…ˆéªŒï¼Œä»¥è¿›ä¸€æ­¥æ¨è¿›äººç±»å›¾åƒå’Œè§†é¢‘ç”Ÿæˆã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
æå‡ºäº†ä¸€ç§æ–°é¢–çš„äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ï¼Œå°†æ–‡æœ¬æç¤ºä¸­çš„äººä½“ç›¸å…³ä¿¡æ¯èå…¥äº¤å‰æ³¨æ„åŠ›å›¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹å…³æ³¨äººä½“ç»“æ„ç»†èŠ‚ã€‚
åˆ†æäº†äº¤å‰æ³¨æ„åŠ›å±‚åœ¨ä¸åŒæ—¶é—´æ­¥å’Œåˆ†è¾¨ç‡å°ºåº¦ä¸‹çš„ä½œç”¨ï¼Œå‘ç°æ—©æœŸæ—¶é—´æ­¥å’Œä¸­é—´åˆ†è¾¨ç‡å°ºåº¦å¯¹äººä½“ç»“æ„ç”Ÿæˆè‡³å…³é‡è¦ã€‚
è®¾è®¡äº† HcP å±‚ï¼Œä»æ–‡æœ¬åµŒå…¥ä¸­æå–äººç±»ä¸­å¿ƒ tokenï¼Œå¹¶ä¸æ½œåœ¨ç‰¹å¾è¿›è¡Œäº¤äº’ï¼Œç”Ÿæˆäººç±»ä¸­å¿ƒæ³¨æ„åŠ›å›¾ã€‚
æ€§èƒ½ï¼š
åœ¨ Human-Art æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆé«˜è´¨é‡äººä½“å›¾åƒæ–¹é¢æ˜æ˜¾ä¼˜äºç°æœ‰æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹ã€‚
æ¶ˆèç ”ç©¶å’Œå¯è§†åŒ–ç»“æœéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†äººç±»ä¸­å¿ƒå¯¹é½æŸå¤±å’Œ HcP å±‚åœ¨æé«˜äººä½“å›¾åƒç”Ÿæˆè´¨é‡ä¸­çš„ä½œç”¨ã€‚
å·¥ä½œé‡ï¼š
è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œåªéœ€åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æ·»åŠ  HcP å±‚å’Œäººç±»ä¸­å¿ƒå¯¹é½æŸå¤±ã€‚
è¯¥æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„æ¡ä»¶ï¼Œä¾‹å¦‚å§¿åŠ¿æˆ–æ·±åº¦å›¾ï¼Œåœ¨æ¨ç†é˜¶æ®µä½¿ç”¨ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-dcb4970717d9f287c0e2b916300f3dd2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cef2974d0c0ed77c5f9c42184d7e57c4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-564f5b115d714883587e123a15ef8050.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f5ade1a99be6f3185ad39bc934410199.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-dfa83d53d9802f58aba15bf8be1a8b64.jpg" align="middle">
</details>




<h2 id="Denoising-Autoregressive-Representation-Learning"><a href="#Denoising-Autoregressive-Representation-Learning" class="headerlink" title="Denoising Autoregressive Representation Learning"></a>Denoising Autoregressive Representation Learning</h2><p><strong>Authors:Yazhe Li, Jorg Bornschein, Ting Chen</strong></p>
<p>In this paper, we explore a new generative approach for learning visual representations. Our method, DARL, employs a decoder-only Transformer to predict image patches autoregressively. We find that training with Mean Squared Error (MSE) alone leads to strong representations. To enhance the image generation ability, we replace the MSE loss with the diffusion objective by using a denoising patch decoder. We show that the learned representation can be improved by using tailored noise schedules and longer training in larger models. Notably, the optimal schedule differs significantly from the typical ones used in standard image diffusion models. Overall, despite its simple architecture, DARL delivers performance remarkably close to state-of-the-art masked prediction models under the fine-tuning protocol. This marks an important step towards a unified model capable of both visual perception and generation, effectively combining the strengths of autoregressive and denoising diffusion models. </p>
<p><a href="http://arxiv.org/abs/2403.05196v1">PDF</a> </p>
<p><strong>Summary</strong><br>è‡ªå›å½’æ‰©æ•£æ¨¡å‹ DARL å®ç°å›¾åƒç”Ÿæˆå’Œè§†è§‰è¡¨ç¤ºå­¦ä¹ ç›¸ç»“åˆï¼Œå±•ç°å‡ºä¸å…ˆè¿›æ©ç é¢„æµ‹æ¨¡å‹åª²ç¾çš„æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>DARL ä½¿ç”¨ä»…è§£ç å™¨çš„ Transformer æ¥è‡ªå›å½’é¢„æµ‹å›¾åƒå—ã€‚</li>
<li>ä»… MSE è®­ç»ƒå³å¯äº§ç”Ÿå¼ºå¤§çš„è¡¨ç¤ºã€‚</li>
<li>ä½¿ç”¨å»å™ªå—è§£ç å™¨å°† MSE æŸå¤±æ›¿æ¢ä¸ºæ‰©æ•£ç›®æ ‡å¯ä»¥å¢å¼ºå›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚</li>
<li>å®šåˆ¶å™ªå£°è°ƒåº¦å’Œåœ¨æ›´å¤§æ¨¡å‹ä¸Šçš„æ›´é•¿æ—¶é—´è®­ç»ƒå¯ä»¥æé«˜å­¦ä¹ è¡¨ç¤ºã€‚</li>
<li>æœ€ä½³è°ƒåº¦ä¸æ ‡å‡†å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­ä½¿ç”¨çš„è°ƒåº¦æ˜¾è‘—ä¸åŒã€‚</li>
<li>å°½ç®¡æ¶æ„ç®€å•ï¼Œä½† DARL åœ¨å¾®è°ƒåè®®ä¸‹æä¾›æ¥è¿‘æœ€å…ˆè¿›æ©ç é¢„æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚</li>
<li>DARL ä»£è¡¨äº†å°†è‡ªå›å½’å’Œå»å™ªæ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿ç»“åˆèµ·æ¥ï¼Œå®ç°è§†è§‰æ„ŸçŸ¥å’Œç”Ÿæˆç›¸ç»Ÿä¸€çš„é‡è¦ä¸€æ­¥ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šå»å™ªè‡ªå›å½’è¡¨å¾å­¦ä¹ </li>
<li>ä½œè€…ï¼šYazhe Liï¼ŒJorg Bornscheinï¼ŒTing Chen</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šGoogle DeepMind</li>
<li>å…³é”®è¯ï¼šè§†è§‰è¡¨å¾å­¦ä¹ ï¼Œè‡ªå›å½’æ¨¡å‹ï¼Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œå›¾åƒç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone
    Github é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè§†è§‰è¡¨å¾å­¦ä¹ å’Œå›¾åƒç”Ÿæˆé€šå¸¸ä½¿ç”¨ä¸åŒçš„æŠ€æœ¯ï¼Œå‰è€…æ³¨é‡é²æ£’æ€§ï¼Œåè€…æ³¨é‡ç”Ÿæˆèƒ½åŠ›ã€‚
   ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šå¯¹æ¯”å­¦ä¹ ã€è’¸é¦è‡ªç›‘ç£å­¦ä¹ ã€æ©ç å›¾åƒå»ºæ¨¡ç­‰æ–¹æ³•åœ¨è¡¨å¾å­¦ä¹ ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç¼ºä¹ç”Ÿæˆèƒ½åŠ›ã€‚
   ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨ Transformer é¢„æµ‹å›¾åƒå—ã€‚é€šè¿‡ä½¿ç”¨å‡æ–¹è¯¯å·®æŸå¤±å’Œå»å™ªå—è§£ç å™¨ï¼Œå¢å¼ºäº†å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚
   ï¼ˆ4ï¼‰æ€§èƒ½è¡¨ç°ï¼šè¯¥æ–¹æ³•åœ¨å¾®è°ƒåè®®ä¸‹ï¼Œè¡¨ç°æ¥è¿‘æœ€å…ˆè¿›çš„æ©ç é¢„æµ‹æ¨¡å‹ï¼Œè¡¨æ˜å…¶åœ¨è¡¨å¾å­¦ä¹ å’Œç”Ÿæˆæ–¹é¢çš„æ½œåŠ›ã€‚</p>
</li>
<li>
<p>Methodsï¼š
(1) æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨ Transformer é¢„æµ‹å›¾åƒå—ï¼›
(2) ä½¿ç”¨å‡æ–¹è¯¯å·®æŸå¤±å’Œå»å™ªå—è§£ç å™¨ï¼Œå¢å¼ºäº†å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚</p>
</li>
<li>
<p>æ€»ç»“ï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨Transformeré¢„æµ‹å›¾åƒå—ï¼Œåœ¨å¾®è°ƒåè®®ä¸‹è¡¨ç°æ¥è¿‘æœ€å…ˆè¿›çš„æ©ç é¢„æµ‹æ¨¡å‹ï¼Œè¡¨æ˜å…¶åœ¨è¡¨å¾å­¦ä¹ å’Œç”Ÿæˆæ–¹é¢çš„æ½œåŠ›ã€‚
(2): Innovation point: æå‡ºäº†ä¸€ç§ç»Ÿä¸€æ¨¡å‹ï¼Œç»“åˆè‡ªå›å½’æ¨¡å‹å’Œå»å™ªæ‰©æ•£æ¨¡å‹ï¼Œä½¿ç”¨è§£ç å™¨Transformeré¢„æµ‹å›¾åƒå—ã€‚
Performance: åœ¨å¾®è°ƒåè®®ä¸‹è¡¨ç°æ¥è¿‘æœ€å…ˆè¿›çš„æ©ç é¢„æµ‹æ¨¡å‹ã€‚
Workload: æœªæåŠã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-3a6bd101af2be0b75af14290ca20154b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-901dfa573ba65a2319ddfc43d65a7325.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-56ec555eccb7ae9c20c196a5c5519463.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc4830941b2dbf44695f875173f8eef5.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f6402f59254c8b1442a49f2075fd0b2f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2f3936f0ef0cf91ab8b2bb5de579b005.jpg" align="middle">
</details>




<h2 id="Improving-Diffusion-Models-for-Virtual-Try-on"><a href="#Improving-Diffusion-Models-for-Virtual-Try-on" class="headerlink" title="Improving Diffusion Models for Virtual Try-on"></a>Improving Diffusion Models for Virtual Try-on</h2><p><strong>Authors:Yisol Choi, Sangkyung Kwak, Kyungmin Lee, Hyungwon Choi, Jinwoo Shin</strong></p>
<p>This paper considers image-based virtual try-on, which renders an image of a person wearing a curated garment, given a pair of images depicting the person and the garment, respectively. Previous works adapt existing exemplar-based inpainting diffusion models for virtual try-on to improve the naturalness of the generated visuals compared to other methods (e.g., GAN-based), but they fail to preserve the identity of the garments. To overcome this limitation, we propose a novel diffusion model that improves garment fidelity and generates authentic virtual try-on images. Our method, coined IDM-VTON, uses two different modules to encode the semantics of garment image; given the base UNet of the diffusion model, 1) the high-level semantics extracted from a visual encoder are fused to the cross-attention layer, and then 2) the low-level features extracted from parallel UNet are fused to the self-attention layer. In addition, we provide detailed textual prompts for both garment and person images to enhance the authenticity of the generated visuals. Finally, we present a customization method using a pair of person-garment images, which significantly improves fidelity and authenticity. Our experimental results show that our method outperforms previous approaches (both diffusion-based and GAN-based) in preserving garment details and generating authentic virtual try-on images, both qualitatively and quantitatively. Furthermore, the proposed customization method demonstrates its effectiveness in a real-world scenario. </p>
<p><a href="http://arxiv.org/abs/2403.05139v1">PDF</a> </p>
<p><strong>Summary</strong><br>å›¾åƒåŸºäºçš„è™šæ‹Ÿè¯•ç©¿ï¼Œåœ¨ç»™å®šæè¿°äººç‰©å’Œè¡£æœå›¾åƒçš„æƒ…å†µä¸‹ï¼Œæ¸²æŸ“äººç‰©ç©¿ç€å®šåˆ¶è¡£æœçš„å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ”¹è¿›çš„æ‰©æ•£æ¨¡å‹ç”¨äºè™šæ‹Ÿè¯•ç©¿ï¼Œä»¥æé«˜ç”Ÿæˆè§†è§‰æ•ˆæœçš„è‡ªç„¶åº¦ã€‚</li>
<li>æå‡ºçš„ IDM-VTON æ¨¡å‹åœ¨ä¿ç•™æœè£…èº«ä»½çš„åŒæ—¶æé«˜äº†æœè£…ä¿çœŸåº¦ã€‚</li>
<li>è¯¥æ–¹æ³•ä½¿ç”¨ä¸¤ä¸ªæ¨¡å—æ¥ç¼–ç æœè£…å›¾åƒçš„è¯­ä¹‰ã€‚</li>
<li>é«˜çº§è¯­ä¹‰èåˆåˆ°äº¤å‰æ³¨æ„å±‚ï¼Œä½çº§ç‰¹å¾èåˆåˆ°è‡ªæ³¨æ„å±‚ã€‚</li>
<li>æä¾›è¯¦ç»†çš„æ–‡æœ¬æç¤ºï¼Œä»¥å¢å¼ºç”Ÿæˆè§†è§‰æ•ˆæœçš„çœŸå®æ€§ã€‚</li>
<li>ä½¿ç”¨ä¸€å¯¹äººç‰©æœè£…å›¾åƒçš„å®šåˆ¶æ–¹æ³•æ˜¾ç€æé«˜äº†ä¿çœŸåº¦å’ŒçœŸå®æ€§ã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿ç•™æœè£…ç»†èŠ‚å’Œç”ŸæˆçœŸå®çš„è™šæ‹Ÿè¯•ç©¿å›¾åƒæ–¹é¢ä¼˜äºå…ˆå‰çš„æ–¹æ³•ã€‚</li>
<li>æ‰€æå‡ºçš„å®šåˆ¶æ–¹æ³•åœ¨çœŸå®åœºæ™¯ä¸­å±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šæå‡æ‰©æ•£æ¨¡å‹ä»¥å®ç°çœŸå®çš„è™šæ‹Ÿè¯•ç©¿</li>
<li>Authorsï¼šYisol Choi, Sangkyung Kwak, Kyungmin Lee, Hyungwon Choi, Jinwoo Shin</li>
<li>Affiliationï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯é™¢ï¼ˆKAISTï¼‰</li>
<li>Keywordsï¼šå›¾åƒç”Ÿæˆã€è™šæ‹Ÿè¯•ç©¿ã€æ‰©æ•£æ¨¡å‹</li>
<li>Urlsï¼šhttps://arxiv.org/abs/2403.05139</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒå¼è™šæ‹Ÿè¯•ç©¿æ—¨åœ¨ç»™å®šæç»˜äººç‰©å’Œæœé¥°çš„ä¸¤å¹…å›¾åƒï¼Œç”Ÿæˆäººç‰©ç©¿ç€ç‰¹å®šæœé¥°çš„å›¾åƒã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰å·¥ä½œå°†åŸºäºç¤ºä¾‹çš„å›¾åƒä¿®å¤æ‰©æ•£æ¨¡å‹åº”ç”¨äºè™šæ‹Ÿè¯•ç©¿ï¼Œä¸å…¶ä»–æ–¹æ³•ï¼ˆå¦‚åŸºäº GAN çš„æ–¹æ³•ï¼‰ç›¸æ¯”ï¼Œå¯ä»¥æé«˜ç”Ÿæˆè§†è§‰æ•ˆæœçš„è‡ªç„¶æ€§ï¼Œä½†æ— æ³•ä¿ç•™æœé¥°çš„ç‰¹å¾ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæå‡ºä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ IDM-VTONï¼Œè¯¥æ¨¡å‹ä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å—å¯¹æœé¥°å›¾åƒçš„è¯­ä¹‰è¿›è¡Œç¼–ç ï¼›åœ¨ç»™å®šæ‰©æ•£æ¨¡å‹çš„åŸºæœ¬ U-Net çš„æƒ…å†µä¸‹ï¼Œ1ï¼‰ä»è§†è§‰ç¼–ç å™¨ä¸­æå–çš„é«˜çº§è¯­ä¹‰è¢«èåˆåˆ°äº¤å‰æ³¨æ„å±‚ï¼Œç„¶å 2ï¼‰ä»å¹¶è¡Œ U-Net ä¸­æå–çš„ä½çº§ç‰¹å¾è¢«èåˆåˆ°è‡ªæ³¨æ„å±‚ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šï¼ŒIDM-VTON åœ¨å›¾åƒè´¨é‡å’Œæœé¥°ä¿çœŸåº¦æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚è¿™äº›ç»“æœæ”¯æŒäº†è¯¥æ–¹æ³•çš„ç›®æ ‡ï¼Œå³ç”ŸæˆçœŸå®ã€ä¿çœŸä¸”å¯å®šåˆ¶çš„è™šæ‹Ÿè¯•ç©¿å›¾åƒã€‚</p>
</li>
<li>
<p>Methods:
(1): IDM-VTONé‡‡ç”¨åŸºäºç¤ºä¾‹çš„å›¾åƒä¿®å¤æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨ä¸¤ä¸ªä¸åŒçš„æ¨¡å—å¯¹æœé¥°å›¾åƒçš„è¯­ä¹‰è¿›è¡Œç¼–ç ã€‚
(2): è§†è§‰ç¼–ç å™¨æå–æœé¥°å›¾åƒçš„é«˜çº§è¯­ä¹‰ï¼Œå¹¶å°†å…¶èåˆåˆ°äº¤å‰æ³¨æ„å±‚ä¸­ã€‚
(3): å¹¶è¡ŒU-Netæå–æœé¥°å›¾åƒçš„ä½çº§ç‰¹å¾ï¼Œå¹¶å°†å…¶èåˆåˆ°è‡ªæ³¨æ„å±‚ä¸­ã€‚
(4): åœ¨ç»™å®šæ‰©æ•£æ¨¡å‹çš„åŸºæœ¬U-Netçš„æƒ…å†µä¸‹ï¼Œèåˆåçš„é«˜çº§è¯­ä¹‰å’Œä½çº§ç‰¹å¾è¢«ç”¨äºæŒ‡å¯¼å›¾åƒç”Ÿæˆè¿‡ç¨‹ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œæ„ä¹‰ï¼šæå‡ºäº†ä¸€ç§æ–°çš„æ‰©æ•£æ¨¡å‹ IDM-VTONï¼Œç”¨äºçœŸå®è™šæ‹Ÿè¯•ç©¿ï¼Œç‰¹åˆ«æ˜¯åœ¨å®é™…åœºæ™¯ä¸­ã€‚æˆ‘ä»¬ç»“åˆäº†ä¸¤ä¸ªç‹¬ç«‹çš„æ¨¡å—å¯¹æœé¥°å›¾åƒè¿›è¡Œç¼–ç ï¼Œå³è§†è§‰ç¼–ç å™¨å’Œå¹¶è¡Œ U-Netï¼Œå®ƒä»¬åˆ†åˆ«æœ‰æ•ˆåœ°å¯¹åŸºæœ¬ U-Net ç¼–ç é«˜çº§è¯­ä¹‰å’Œä½çº§ç‰¹å¾ã€‚ä¸ºäº†åœ¨å®é™…åœºæ™¯ä¸­æ”¹è¿›è™šæ‹Ÿè¯•ç©¿ï¼Œæˆ‘ä»¬æå‡ºé€šè¿‡å¾®è°ƒç»™å®šä¸€å¯¹æœé¥°-äººç‰©å›¾åƒçš„ U-Net è§£ç å™¨å±‚æ¥å®šåˆ¶æˆ‘ä»¬çš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨äº†æœé¥°çš„è¯¦ç»†è‡ªç„¶è¯­è¨€æè¿°ï¼Œè¿™æœ‰åŠ©äºç”ŸæˆçœŸå®çš„è™šæ‹Ÿè¯•ç©¿å›¾åƒã€‚åœ¨å„ç§æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿ç•™æœé¥°ç»†èŠ‚å’Œç”Ÿæˆé«˜ä¿çœŸå›¾åƒæ–¹é¢ä¼˜äºå…ˆå‰çš„ç ”ç©¶ã€‚ç‰¹åˆ«æ˜¯ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å®é™…åœºæ™¯ä¸­è¿›è¡Œè™šæ‹Ÿè¯•ç©¿çš„æ½œåŠ›ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼šæå‡ºäº† IDM-VTONï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºçœŸå®è™šæ‹Ÿè¯•ç©¿çš„æ‰©æ•£æ¨¡å‹çš„æ–°è®¾è®¡ï¼Œç‰¹åˆ«æ˜¯åœ¨å®é™…åœºæ™¯ä¸­ã€‚ç»“åˆäº†ä¸¤ä¸ªç‹¬ç«‹çš„æ¨¡å—å¯¹æœé¥°å›¾åƒè¿›è¡Œç¼–ç ï¼Œå³è§†è§‰ç¼–ç å™¨å’Œå¹¶è¡Œ U-Netï¼Œå®ƒä»¬åˆ†åˆ«æœ‰æ•ˆåœ°å¯¹åŸºæœ¬ U-Net ç¼–ç é«˜çº§è¯­ä¹‰å’Œä½çº§ç‰¹å¾ã€‚
æ€§èƒ½ï¼šåœ¨å›¾åƒè´¨é‡å’Œæœé¥°ä¿çœŸåº¦æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼šä¸åŸºäº GAN çš„æ–¹æ³•ç›¸æ¯”ï¼ŒåŸºäºç¤ºä¾‹çš„å›¾åƒä¿®å¤æ‰©æ•£æ¨¡å‹é€šå¸¸å…·æœ‰æ›´é«˜çš„è®¡ç®—æˆæœ¬ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d38c4cb395c666b5e4fd3e52269fff3f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-d67b069f37d9810aa657e9e7dd415a5a.jpg" align="middle">
</details>




<h2 id="ELLA-Equip-Diffusion-Models-with-LLM-for-Enhanced-Semantic-Alignment"><a href="#ELLA-Equip-Diffusion-Models-with-LLM-for-Enhanced-Semantic-Alignment" class="headerlink" title="ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment"></a>ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment</h2><p><strong>Authors:Xiwei Hu, Rui Wang, Yixiao Fang, Bin Fu, Pei Cheng, Gang Yu</strong></p>
<p>Diffusion models have demonstrated remarkable performance in the domain of text-to-image generation. However, most widely used models still employ CLIP as their text encoder, which constrains their ability to comprehend dense prompts, encompassing multiple objects, detailed attributes, complex relationships, long-text alignment, etc. In this paper, we introduce an Efficient Large Language Model Adapter, termed ELLA, which equips text-to-image diffusion models with powerful Large Language Models (LLM) to enhance text alignment without training of either U-Net or LLM. To seamlessly bridge two pre-trained models, we investigate a range of semantic alignment connector designs and propose a novel module, the Timestep-Aware Semantic Connector (TSC), which dynamically extracts timestep-dependent conditions from LLM. Our approach adapts semantic features at different stages of the denoising process, assisting diffusion models in interpreting lengthy and intricate prompts over sampling timesteps. Additionally, ELLA can be readily incorporated with community models and tools to improve their prompt-following capabilities. To assess text-to-image models in dense prompt following, we introduce Dense Prompt Graph Benchmark (DPG-Bench), a challenging benchmark consisting of 1K dense prompts. Extensive experiments demonstrate the superiority of ELLA in dense prompt following compared to state-of-the-art methods, particularly in multiple object compositions involving diverse attributes and relationships. </p>
<p><a href="http://arxiv.org/abs/2403.05135v1">PDF</a> Project Page: <a href="https://ella-diffusion.github.io/">https://ella-diffusion.github.io/</a></p>
<p><strong>Summary</strong><br>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åŠ å…¥è¯­è¨€å¤§æ¨¡å‹å¢å¼ºå™¨ ELLAï¼Œå¤§å¹…æå‡ä¸°å¯Œæç¤ºç†è§£èƒ½åŠ›ï¼Œæ— éœ€è®­ç»ƒ U å½¢ç½‘ç»œæˆ–è¯­è¨€å¤§æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ELLA è¯­è¨€å¤§æ¨¡å‹å¢å¼ºå™¨é€šè¿‡æ— ç¼è¿æ¥ï¼Œæå‡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„æ–‡æœ¬å¯¹é½èƒ½åŠ›ï¼Œæ— éœ€è®­ç»ƒ U å½¢ç½‘ç»œæˆ–è¯­è¨€å¤§æ¨¡å‹ã€‚</li>
<li>æå‡ºæ—¶é—´æ„ŸçŸ¥è¯­ä¹‰è¿æ¥å™¨ (TSC)ï¼ŒåŠ¨æ€ä»è¯­è¨€å¤§æ¨¡å‹ä¸­æå–ä¸æ—¶é—´æ­¥é•¿ç›¸å…³çš„æ¡ä»¶ã€‚</li>
<li>åœ¨å»å™ªè¿‡ç¨‹çš„ä¸åŒé˜¶æ®µï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´è¯­ä¹‰ç‰¹å¾ï¼Œå¸®åŠ©æ‰©æ•£æ¨¡å‹éšç€é‡‡æ ·æ—¶é—´æ­¥é•¿è§£é‡Šå†—é•¿å¤æ‚æç¤ºã€‚</li>
<li>ELLA å¯ä»¥è½»æ¾ä¸ç¤¾åŒºæ¨¡å‹å’Œå·¥å…·é›†æˆï¼Œæå‡å…¶æç¤ºéµå¾ªèƒ½åŠ›ã€‚</li>
<li>å¼•å…¥å¯†é›†æç¤ºå›¾åŸºå‡† (DPG-Bench)ï¼Œç”¨äºè¯„ä¼°æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨å¯†é›†æç¤ºéµå¾ªæ–¹é¢çš„è¡¨ç°ã€‚</li>
<li>å¹¿æ³›å®éªŒéªŒè¯äº† ELLA åœ¨å¯†é›†æç¤ºéµå¾ªæ–¹é¢çš„ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤šç§å±æ€§å’Œå…³ç³»çš„å¤šå¯¹è±¡ç»„åˆä¸­ã€‚</li>
<li>ELLA åœ¨ä¿æŒç”Ÿæˆå›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œæå‡äº†å®šé‡å’Œå®šæ€§è¯„ä¼°çš„æ–‡æœ¬å¯¹é½åˆ†æ•°ã€‚</li>
<li>ELLA å°†æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸è¯­è¨€å¤§æ¨¡å‹ç›¸ç»“åˆï¼Œæ¢ç´¢äº†æ–‡æœ¬å’Œå›¾åƒç”Ÿæˆä¹‹é—´çš„æ½œåœ¨è”ç³»ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šELLAï¼šä½¿ç”¨ LLM ä¸ºæ‰©æ•£æ¨¡å‹èµ‹èƒ½ä»¥å¢å¼ºè¯­ä¹‰å¯¹é½</li>
<li>ä½œè€…ï¼šèƒ¡é”¡å¨ã€ç‹ç‘ã€æ–¹ä¸€æ™“ã€ä»˜æ–Œã€ç¨‹åŸ¹ã€äºé’¢</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè…¾è®¯</li>
<li>å…³é”®è¯ï¼šæ‰©æ•£æ¨¡å‹ã€å¤§è¯­è¨€æ¨¡å‹ã€æ–‡æœ¬-å›¾åƒå¯¹é½</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://ella-diffusion.github.ioï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°å¹¿æ³›ä½¿ç”¨çš„æ¨¡å‹ä»ç„¶ä½¿ç”¨ CLIP ä½œä¸ºå…¶æ–‡æœ¬ç¼–ç å™¨ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬ç†è§£åŒ…å«å¤šä¸ªå¯¹è±¡ã€è¯¦ç»†å±æ€§ã€å¤æ‚å…³ç³»ã€é•¿æ–‡æœ¬å¯¹é½ç­‰å†…å®¹çš„å¯†é›†æç¤ºçš„èƒ½åŠ›ã€‚
ï¼ˆ2ï¼‰å·²æœ‰æ–¹æ³•åŠé—®é¢˜ï¼šä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº† ELLAï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹é€‚é…å™¨ï¼Œå®ƒä¸ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹é…å¤‡äº†å¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ (LLM)ï¼Œä»¥å¢å¼ºæ–‡æœ¬å¯¹é½ï¼Œè€Œæ— éœ€è®­ç»ƒ U-Net æˆ– LLMã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†æ— ç¼æ¡¥æ¥ä¸¤ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œæœ¬æ–‡ç ”ç©¶äº†ä¸€ç³»åˆ—è¯­ä¹‰å¯¹é½è¿æ¥å™¨è®¾è®¡ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„æ¨¡å—ï¼Œå³ TimeStep-Aware è¯­ä¹‰è¿æ¥å™¨ (TSC)ï¼Œå®ƒåŠ¨æ€åœ°ä» LLM ä¸­æå–ä¸æ—¶é—´æ­¥é•¿ç›¸å…³çš„æ¡ä»¶ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å¯†é›†æç¤ºè·Ÿéšä»»åŠ¡ä¸­å±•ç¤ºäº†ä¼˜äºæœ€å…ˆè¿›æ–¹æ³•çš„ä¼˜åŠ¿ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠä¸åŒå±æ€§å’Œå…³ç³»çš„å¤šä¸ªå¯¹è±¡ç»„åˆä¸­ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ï¼šè®¾è®¡ELLAæ¶æ„ï¼Œåˆ©ç”¨LLMçš„è¯­è¨€ç†è§£èƒ½åŠ›å’Œæ‰©æ•£æ¨¡å‹çš„å›¾åƒç”Ÿæˆæ½œåŠ›ï¼Œé‡‡ç”¨TimeStep-Awareè¯­ä¹‰è¿æ¥å™¨ï¼ˆTSCï¼‰æ— ç¼è¿æ¥ä¸¤ä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼›
ï¼ˆ2ï¼‰ï¼šæ„å»ºæ•°æ®é›†ï¼Œé‡‡ç”¨CogVLMè‡ªåŠ¨ç”Ÿæˆå›¾åƒæè¿°ï¼Œæé«˜å›¾åƒä¸æ–‡æœ¬çš„ç›¸å…³æ€§å’Œè¯­ä¹‰ä¿¡æ¯çš„å¯†åº¦ï¼›
ï¼ˆ3ï¼‰ï¼šæ„å»ºåŸºå‡†æµ‹è¯•ï¼Œæå‡ºå¯†é›†æç¤ºå›¾è°±åŸºå‡†ï¼ˆDPG-Benchï¼‰ï¼Œæä¾›æ›´é•¿ã€æ›´å…·ä¿¡æ¯é‡çš„æç¤ºï¼Œå…¨é¢è¯„ä¼°ç”Ÿæˆæ¨¡å‹éµå¾ªå¯†é›†æç¤ºçš„èƒ½åŠ›ã€‚</p>
<p>8.ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„å¤§è¯­è¨€æ¨¡å‹é€‚é…å™¨ELLAï¼Œè¯¥é€‚é…å™¨é€šè¿‡TimeStep-Awareè¯­ä¹‰è¿æ¥å™¨å°†å¤§è¯­è¨€æ¨¡å‹ä¸æ‰©æ•£æ¨¡å‹æ— ç¼è¿æ¥ï¼Œå¢å¼ºäº†æ–‡æœ¬å¯¹é½ï¼Œåœ¨å¯†é›†æç¤ºè·Ÿéšä»»åŠ¡ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚
(2): åˆ›æ–°ç‚¹ï¼š
* æå‡ºäº†ä¸€ç§æ–°çš„è¯­ä¹‰å¯¹é½è¿æ¥å™¨TSCï¼ŒåŠ¨æ€åœ°ä»å¤§è¯­è¨€æ¨¡å‹ä¸­æå–ä¸æ—¶é—´æ­¥é•¿ç›¸å…³çš„æ¡ä»¶ï¼Œå¢å¼ºäº†æ–‡æœ¬å’Œå›¾åƒä¹‹é—´çš„è¯­ä¹‰å¯¹é½ã€‚
* æ„å»ºäº†å¯†é›†æç¤ºå›¾è°±åŸºå‡†DPG-Benchï¼Œæä¾›æ›´é•¿ã€æ›´å…·ä¿¡æ¯é‡çš„æç¤ºï¼Œå…¨é¢è¯„ä¼°ç”Ÿæˆæ¨¡å‹éµå¾ªå¯†é›†æç¤ºçš„èƒ½åŠ›ã€‚
* é‡‡ç”¨CogVLMè‡ªåŠ¨ç”Ÿæˆå›¾åƒæè¿°ï¼Œæé«˜å›¾åƒä¸æ–‡æœ¬çš„ç›¸å…³æ€§å’Œè¯­ä¹‰ä¿¡æ¯çš„å¯†åº¦ã€‚
æ€§èƒ½ï¼š
* åœ¨å¯†é›†æç¤ºè·Ÿéšä»»åŠ¡ä¸­ï¼ŒELLAåœ¨ç”Ÿæˆå›¾åƒçš„è¯­ä¹‰å¯¹é½å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å‡ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š
* ELLAçš„è®­ç»ƒå’Œéƒ¨ç½²ç›¸å¯¹é«˜æ•ˆï¼Œä¸éœ€è¦è®­ç»ƒU-Netæˆ–å¤§è¯­è¨€æ¨¡å‹ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-4cf50b2bd0a34d7b9b26b53c13b5a923.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fc587ddf93c75ebf159a0c6b73925633.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a0b7496441cb8c23d5d6a09243c13c67.jpg" align="middle">
</details>




## CogView3: Finer and Faster Text-to-Image Generation via Relay Diffusion

**Authors:Wendi Zheng, Jiayan Teng, Zhuoyi Yang, Weihan Wang, Jidong Chen, Xiaotao Gu, Yuxiao Dong, Ming Ding, Jie Tang**

Recent advancements in text-to-image generative systems have been largely driven by diffusion models. However, single-stage text-to-image diffusion models still face challenges, in terms of computational efficiency and the refinement of image details. To tackle the issue, we propose CogView3, an innovative cascaded framework that enhances the performance of text-to-image diffusion. CogView3 is the first model implementing relay diffusion in the realm of text-to-image generation, executing the task by first creating low-resolution images and subsequently applying relay-based super-resolution. This methodology not only results in competitive text-to-image outputs but also greatly reduces both training and inference costs. Our experimental results demonstrate that CogView3 outperforms SDXL, the current state-of-the-art open-source text-to-image diffusion model, by 77.0\% in human evaluations, all while requiring only about 1/2 of the inference time. The distilled variant of CogView3 achieves comparable performance while only utilizing 1/10 of the inference time by SDXL. 

[PDF](http://arxiv.org/abs/2403.05121v1) 

**Summary**
CogView3ï¼Œä¸€ä¸ªçº§è”æ¡†æ¶ï¼Œå¼•å…¥æ¥åŠ›æ‰©æ•£ï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­å®ç°ä½åˆ†è¾¨ç‡åˆ°é«˜åˆ†è¾¨ç‡ï¼Œæé«˜æ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚

**Key Takeaways**
- CogView3æå‡ºçº§è”æ¡†æ¶ï¼Œä½¿ç”¨æ¥åŠ›æ‰©æ•£ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒã€‚
- æ¥åŠ›æ‰©æ•£åˆ†æ­¥ç”Ÿæˆå›¾åƒï¼Œä»ä½åˆ†è¾¨ç‡åˆ°é«˜åˆ†è¾¨ç‡ï¼Œé™ä½è®­ç»ƒå’Œæ¨ç†æˆæœ¬ã€‚
- CogView3è¶…è¶ŠSDXLï¼Œäººç±»è¯„ä¼°å¾—åˆ†é«˜å‡º77.0%ï¼Œæ¨ç†æ—¶é—´å‡å°‘ä¸€åŠã€‚
- CogView3çš„ç²¾ç®€ç‰ˆæ€§èƒ½ç›¸å½“ï¼Œæ¨ç†æ—¶é—´ä»…ä¸ºSDXLçš„ååˆ†ä¹‹ä¸€ã€‚
- CogView3æé«˜äº†æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡çš„æ•ˆç‡å’Œå›¾åƒè´¨é‡ã€‚
- CogView3 å¼•å…¥äº†æ¥åŠ›æ‰©æ•£çš„æ¦‚å¿µï¼Œåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­å®ç°äº†åˆ†è¾¨ç‡çš„æ¸è¿›æå‡ã€‚
- çº§è”æ¡†æ¶å’Œæ¥åŠ›æ‰©æ•£çš„ç»“åˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¹³è¡¡å›¾åƒè´¨é‡å’Œè®¡ç®—æˆæœ¬ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šCogView3ï¼šæ›´ç²¾ç»†ã€æ›´å¿«é€Ÿçš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ</li>
<li>ä½œè€…ï¼šWendi Zheng, Jiayan Teng, Zhuoyi Yang, Weihan Wang, Jidong Chen, Xiaotao Gu, Yuxiao Dong, Ming Ding, Jie Tang</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”ŸæˆÂ·æ‰©æ•£æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05121</li>
<li>
<p>æ‘˜è¦ï¼š
(1) ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹å·²æˆä¸ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿçš„ä¸»æµæ¡†æ¶ã€‚ç„¶è€Œï¼Œå•é˜¶æ®µæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨è®¡ç®—æ•ˆç‡å’Œå›¾åƒç»†èŠ‚ç²¾ç»†åŒ–æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚
(2) è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å¤§å¤šåœ¨é«˜å›¾åƒåˆ†è¾¨ç‡ä¸‹è¿›è¡Œæ‰©æ•£è¿‡ç¨‹ï¼Œè¿™å¯¼è‡´è®¡ç®—æˆæœ¬é«˜ã€å›¾åƒç»†èŠ‚ä¸å¤Ÿç²¾ç»†ã€‚
(3) æå‡ºæ–¹æ³•ï¼šæœ¬æ–‡æå‡º CogView3ï¼Œä¸€ä¸ªåˆ›æ–°çš„çº§è”æ¡†æ¶ï¼Œé€šè¿‡ä¸­ç»§æ‰©æ•£æ¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£çš„æ€§èƒ½ã€‚CogView3 æ˜¯ç¬¬ä¸€ä¸ªåœ¨æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå®ç°ä¸­ç»§æ‰©æ•£çš„æ¨¡å‹ï¼Œå®ƒé€šè¿‡é¦–å…ˆåˆ›å»ºä½åˆ†è¾¨ç‡å›¾åƒï¼Œç„¶ååº”ç”¨åŸºäºä¸­ç»§çš„è¶…åˆ†è¾¨ç‡æ¥æ‰§è¡Œä»»åŠ¡ã€‚
(4) å®éªŒç»“æœï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒCogView3 åœ¨äººç±»è¯„ä¼°ä¸­æ¯”å½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ SDXL é«˜å‡º 77.0%ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´ä»…ä¸ºå…¶ä¸€åŠå·¦å³ã€‚CogView3 çš„è’¸é¦å˜ä½“åœ¨æ¨ç†æ—¶é—´ä»…ä¸º SDXL çš„ 1/10 çš„æƒ…å†µä¸‹å®ç°äº†å¯æ¯”çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ–‡æœ¬é¢„å¤„ç†å›¾åƒé‡è¿°ï¼šåˆ©ç”¨ GPT-4V è‡ªåŠ¨ç”Ÿæˆè®­ç»ƒæ•°æ®é›†å›¾åƒçš„é‡è¿°æ–‡æœ¬ï¼Œå¹¶å¾®è°ƒ CogVLM-17B ä»¥è·å¾—é‡è¿°æ¨¡å‹ï¼›
ï¼ˆ2ï¼‰æç¤ºæ‰©å±•ï¼šåˆ©ç”¨è¯­è¨€æ¨¡å‹å°†ç”¨æˆ·æç¤ºæ‰©å±•ä¸ºæ›´å…¨é¢çš„æè¿°ï¼Œä»¥å‡å°‘è®­ç»ƒå’Œæ¨ç†ä¹‹é—´çš„ä¸ä¸€è‡´ï¼›
ï¼ˆ3ï¼‰æ¨¡å‹æ„å»ºï¼šCogView3 é‡‡ç”¨ 3 çº§ UNet æ¶æ„çš„æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨é¢„è®­ç»ƒçš„ T5-XXL ç¼–ç å™¨ä½œä¸ºæ–‡æœ¬ç¼–ç å™¨ï¼›
ï¼ˆ4ï¼‰è®­ç»ƒç®¡é“ï¼šä½¿ç”¨ Laion-2B æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œå¹¶é‡‡ç”¨æ¸è¿›è®­ç»ƒç­–ç•¥ä»¥é™ä½è®­ç»ƒæˆæœ¬ï¼›
ï¼ˆ5ï¼‰ä¸­ç»§è¶…åˆ†è¾¨ç‡ï¼šåœ¨æ½œåœ¨ç©ºé—´ä¸­å®ç°ä¸­ç»§è¶…åˆ†è¾¨ç‡ï¼Œä½¿ç”¨çº¿æ€§å˜æ¢ä»£æ›¿åŸå§‹çš„å±€éƒ¨æ¨¡ç³Šï¼›
ï¼ˆ6ï¼‰é‡‡æ ·å™¨æ„å»ºï¼šè®¾è®¡äº†ä¸ä¸­ç»§è¶…åˆ†è¾¨ç‡ç›¸ä¸€è‡´çš„é‡‡æ ·å™¨ï¼Œå¹¶ä½¿ç”¨ DDIM èŒƒå¼è¿›è¡Œé‡‡æ ·ï¼›
ï¼ˆ7ï¼‰ä¸­ç»§æ‰©æ•£çš„è’¸é¦ï¼šå°†æ¸è¿›è’¸é¦æ–¹æ³•ä¸ä¸­ç»§æ‰©æ•£æ¡†æ¶ç›¸ç»“åˆï¼Œä»¥è·å¾— CogView3 çš„è’¸é¦ç‰ˆæœ¬ã€‚</p>
</li>
<li>
<p>ç»“è®º
(1): æœ¬å·¥ä½œæå‡ºäº† CogView3ï¼Œè¿™æ˜¯ç»§ç”µæ‰©æ•£æ¡†æ¶ä¸­ç¬¬ä¸€ä¸ªæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç³»ç»Ÿã€‚CogView3 ä»¥æå¤§é™ä½çš„æ¨ç†æˆæœ¬å®ç°äº†ä¼˜è‰¯çš„ç”Ÿæˆè´¨é‡ï¼Œè¿™ä¸»è¦å½’åŠŸäºä¸­ç»§ç®¡é“ã€‚é€šè¿‡è¿­ä»£å®ç° CogView3 çš„è¶…åˆ†è¾¨ç‡é˜¶æ®µï¼Œæˆ‘ä»¬èƒ½å¤Ÿå®ç°æé«˜åˆ†è¾¨ç‡ï¼ˆå¦‚ 2048Ã—2048ï¼‰çš„é«˜è´¨é‡å›¾åƒã€‚åŒæ—¶ï¼Œéšç€æ•°æ®é‡æ–°æè¿°å’Œæç¤ºæ‰©å±•è¢«çº³å…¥æ¨¡å‹ç®¡é“ï¼Œä¸å½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç›¸æ¯”ï¼ŒCogView3 åœ¨æç¤ºç†è§£å’ŒæŒ‡ä»¤éµå¾ªæ–¹é¢å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜æ¢ç´¢äº† CogView3 çš„è’¸é¦ï¼Œå¹¶å±•ç¤ºäº†å…¶å½’åŠŸäºç»§ç”µæ‰©æ•£æ¡†æ¶çš„ç®€å•æ€§å’Œèƒ½åŠ›ã€‚åˆ©ç”¨æ¸è¿›è’¸é¦èŒƒä¾‹ï¼ŒCogView3 çš„è’¸é¦å˜ä½“å¤§å¹…å‡å°‘äº†æ¨ç†æ—¶é—´ï¼ŒåŒæ—¶ä»ä¿æŒäº†ç›¸å½“çš„æ€§èƒ½ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„çº§è”æ¡†æ¶ CogView3ï¼Œè¯¥æ¡†æ¶é€šè¿‡ä¸­ç»§æ‰©æ•£å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£çš„æ€§èƒ½ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§ä¸­ç»§è¶…åˆ†è¾¨ç‡æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æ½œåœ¨ç©ºé—´ä¸­æ‰§è¡Œè¶…åˆ†è¾¨ç‡ï¼Œå¹¶ä½¿ç”¨çº¿æ€§å˜æ¢ä»£æ›¿åŸå§‹çš„å±€éƒ¨æ¨¡ç³Šã€‚</li>
<li>æ¢ç´¢äº†æ•°æ®é‡æ–°æè¿°å’Œæç¤ºæ‰©å±•ï¼Œä»¥æé«˜æ¨¡å‹å¯¹æç¤ºçš„ç†è§£å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨äººç±»è¯„ä¼°ä¸­ï¼ŒCogView3 æ¯”å½“å‰æœ€å…ˆè¿›çš„å¼€æºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ SDXL é«˜å‡º 77.0%ï¼ŒåŒæ—¶æ¨ç†æ—¶é—´ä»…ä¸ºå…¶ä¸€åŠå·¦å³ã€‚</li>
<li>CogView3 çš„è’¸é¦å˜ä½“åœ¨æ¨ç†æ—¶é—´ä»…ä¸º SDXL çš„ 1/10 çš„æƒ…å†µä¸‹å®ç°äº†å¯æ¯”çš„æ€§èƒ½ã€‚</li>
<li>CogView3 èƒ½å¤Ÿç”Ÿæˆæé«˜åˆ†è¾¨ç‡ï¼ˆå¦‚ 2048Ã—2048ï¼‰çš„é«˜è´¨é‡å›¾åƒã€‚
å·¥ä½œé‡ï¼š</li>
<li>CogView3 çš„è®­ç»ƒç®¡é“ç›¸å¯¹ç®€å•ï¼Œé‡‡ç”¨æ¸è¿›è®­ç»ƒç­–ç•¥ä»¥é™ä½è®­ç»ƒæˆæœ¬ã€‚</li>
<li>CogView3 çš„è’¸é¦å˜ä½“è¿›ä¸€æ­¥é™ä½äº†æ¨ç†æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒäº†å¯æ¯”çš„æ€§èƒ½ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-39c07129df4e18479bf6f2000e3bd45b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3130242f65670e2f9a99c29710ffccef.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a4b8e0b9de2b5980d7c1d4c49daded3b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3e7d124475c2a36f974604208e23b856.jpg" align="middle">
</details>




<h2 id="Face2Diffusion-for-Fast-and-Editable-Face-Personalization"><a href="#Face2Diffusion-for-Fast-and-Editable-Face-Personalization" class="headerlink" title="Face2Diffusion for Fast and Editable Face Personalization"></a>Face2Diffusion for Fast and Editable Face Personalization</h2><p><strong>Authors:Kaede Shiohara, Toshihiko Yamasaki</strong></p>
<p>Face personalization aims to insert specific faces, taken from images, into pretrained text-to-image diffusion models. However, it is still challenging for previous methods to preserve both the identity similarity and editability due to overfitting to training samples. In this paper, we propose Face2Diffusion (F2D) for high-editability face personalization. The core idea behind F2D is that removing identity-irrelevant information from the training pipeline prevents the overfitting problem and improves editability of encoded faces. F2D consists of the following three novel components: 1) Multi-scale identity encoder provides well-disentangled identity features while keeping the benefits of multi-scale information, which improves the diversity of camera poses. 2) Expression guidance disentangles face expressions from identities and improves the controllability of face expressions. 3) Class-guided denoising regularization encourages models to learn how faces should be denoised, which boosts the text-alignment of backgrounds. Extensive experiments on the FaceForensics++ dataset and diverse prompts demonstrate our method greatly improves the trade-off between the identity- and text-fidelity compared to previous state-of-the-art methods. </p>
<p><a href="http://arxiv.org/abs/2403.05094v1">PDF</a> CVPR2024. Code: <a href="https://github.com/mapooon/Face2Diffusion">https://github.com/mapooon/Face2Diffusion</a>, Webpage:   <a href="https://mapooon.github.io/Face2DiffusionPage/">https://mapooon.github.io/Face2DiffusionPage/</a></p>
<p><strong>Summary</strong><br>äººè„¸ä¸ªæ€§åŒ–é€šè¿‡æ¤å…¥ä»å›¾ç‰‡è·å–çš„äººè„¸æ¥å®ç°é¢„å…ˆè®­ç»ƒçš„æ–‡è½¬å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ä»è®­ç»ƒç®¡é“ä¸­å»é™¤ä¸äººè„¸æ— å…³çš„ä¿¡æ¯æœ‰åŠ©äºæå‡ç¼–è¾‘èƒ½åŠ›ã€‚</li>
<li>å¤šå°ºåº¦äººè„¸ç¼–ç å™¨æä¾›äº†æ¸…æ™°åˆ†ç¦»çš„äººè„¸ç‰¹å¾ã€‚</li>
<li>è¡¨æƒ…æŒ‡å¯¼å°†äººè„¸è¡¨æƒ…ä¸äººè„¸èº«ä»½è¿›è¡Œåˆ†ç¦»ã€‚</li>
<li>ç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–å¢å¼ºæ¨¡å‹å¯¹äººè„¸å»å™ªçš„å­¦ä¹ ã€‚</li>
<li>è·¨æ•°æ®é›†å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æå‡äº†èº«ä»½ä¿çœŸåº¦ä¸æ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´çš„å¹³è¡¡ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šFace2Diffusionï¼šå¿«é€Ÿä¸”å¯ç¼–è¾‘çš„äººè„¸ä¸ªæ€§åŒ–</li>
<li>ä½œè€…ï¼šKaede Shiohara, Toshihiko Yamasaki</li>
<li>å•ä½ï¼šä¸œäº¬å¤§å­¦</li>
<li>å…³é”®è¯ï¼šFace personalization, Text-to-image diffusion model, Identity preservation, Editability</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05094</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å°†ç‰¹å®šäººè„¸æ’å…¥é¢„è®­ç»ƒæ¨¡å‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œæ—¢è¦ä¿æŒèº«ä»½ç›¸ä¼¼æ€§ï¼Œåˆè¦ä¿è¯å¯ç¼–è¾‘æ€§ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ–¹æ³•å®¹æ˜“è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ ·æœ¬ï¼Œå¯¼è‡´èº«ä»½ç›¸ä¼¼æ€§å’Œå¯ç¼–è¾‘æ€§ä¹‹é—´çš„æƒè¡¡ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šFace2Diffusionï¼ˆF2Dï¼‰é€šè¿‡ä»è®­ç»ƒç®¡é“ä¸­å»é™¤ä¸èº«ä»½æ— å…³çš„ä¿¡æ¯æ¥è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œæé«˜ç¼–ç äººè„¸çš„å¯ç¼–è¾‘æ€§ã€‚F2DåŒ…å«ä¸‰ä¸ªæ–°é¢–çš„ç»„ä»¶ï¼šå¤šå°ºåº¦èº«ä»½ç¼–ç å™¨ã€è¡¨æƒ…å¼•å¯¼å™¨å’Œç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šåœ¨ FaceForensics++ æ•°æ®é›†å’Œå„ç§æç¤ºä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒF2D åœ¨èº«ä»½å’Œæ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´çš„æƒè¡¡æ–¹é¢æ˜æ˜¾ä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) å¤šå°ºåº¦èº«ä»½ç¼–ç å™¨ï¼šä»äººè„¸å›¾åƒä¸­æå–å¤šå°ºåº¦ç‰¹å¾ï¼Œä¿ç•™èº«ä»½ä¿¡æ¯ï¼Œé™ä½è¿‡åº¦æ‹Ÿåˆé£é™©ã€‚
(2) è¡¨æƒ…å¼•å¯¼å™¨ï¼šæŒ‡å¯¼æ‰©æ•£æ¨¡å‹å…³æ³¨äººè„¸è¡¨æƒ…çš„ç¼–è¾‘ï¼Œæé«˜å¯ç¼–è¾‘æ€§ã€‚
(3) ç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–ï¼šå¼•å…¥ç±»åˆ«ä¿¡æ¯ï¼Œé˜²æ­¢æ¨¡å‹ä»æ— å…³å™ªå£°ä¸­å­¦ä¹ ï¼Œæé«˜èº«ä»½ä¿çœŸåº¦ã€‚</p>
</li>
</ol>
<p><strong>8. ç»“è®º</strong></p>
<p><strong>(1): æ­¤é¡¹å·¥ä½œçš„æ„ä¹‰</strong></p>
<p>Face2Diffusion æå‡ºäº†ä¸€ç§å¯ç¼–è¾‘çš„äººè„¸ä¸ªæ€§åŒ–æ–¹æ³•ï¼Œé€šè¿‡è§£å†³è¿‡åº¦æ‹Ÿåˆé—®é¢˜ï¼Œæé«˜äº†ç”Ÿæˆäººè„¸çš„å¯ç¼–è¾‘æ€§ï¼Œåœ¨èº«ä»½ä¿çœŸåº¦å’Œæ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</p>
<p><strong>(2): æœ¬æ–‡ä¼˜ç¼ºç‚¹æ€»ç»“ï¼ˆä¸‰ä¸ªç»´åº¦ï¼šåˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡ï¼‰</strong></p>
<p><strong>åˆ›æ–°ç‚¹ï¼š</strong></p>
<ul>
<li>å¤šå°ºåº¦èº«ä»½ç¼–ç å™¨ï¼šæå–å¤šå°ºåº¦ç‰¹å¾ï¼Œé™ä½è¿‡åº¦æ‹Ÿåˆé£é™©ã€‚</li>
<li>è¡¨æƒ…å¼•å¯¼å™¨ï¼šæŒ‡å¯¼æ‰©æ•£æ¨¡å‹å…³æ³¨äººè„¸è¡¨æƒ…çš„ç¼–è¾‘ã€‚</li>
<li>ç±»åˆ«å¼•å¯¼å»å™ªæ­£åˆ™åŒ–ï¼šé˜²æ­¢æ¨¡å‹ä»æ— å…³å™ªå£°ä¸­å­¦ä¹ ã€‚</li>
</ul>
<p><strong>æ€§èƒ½ï¼š</strong></p>
<ul>
<li>åœ¨èº«ä»½ä¿çœŸåº¦å’Œæ–‡æœ¬ä¿çœŸåº¦ä¹‹é—´å–å¾—äº†æ›´å¥½çš„å¹³è¡¡ã€‚</li>
<li>åœ¨å„ç§æç¤ºå’Œäººè„¸æ•°æ®é›†ä¸Šè¡¨ç°å‡ºä¼˜å¼‚çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong>å·¥ä½œé‡ï¼š</strong></p>
<ul>
<li>è®­ç»ƒè¿‡ç¨‹ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦å¤šå°ºåº¦ç‰¹å¾æå–å’Œæ­£åˆ™åŒ–ç­–ç•¥ã€‚</li>
<li>ç”Ÿæˆå•ä¸ªå›¾åƒæ‰€éœ€çš„æ—¶é—´ä¸å…¶ä»–æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ç±»ä¼¼ã€‚</li>
</ul>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-a4d3199be75c4ed763ad12e5fd6fd186.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-073fc885846ed7841fbefca59dc75bb8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c2c9194bd5afd5f761cca65c865fe0fb.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-b6ba7d02ff97010b563089ea86c62c6b.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8bdf1923916c837b5df8251aa84ce58b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d5d8555605f33ef6be1a8b7ab0be10cc.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-302c4a1ee77cbdfd8dba69c7d6a94497.jpg" align="middle">
</details>




## Spectrum Translation for Refinement of Image Generation (STIG) Based on   Contrastive Learning and Spectral Filter Profile

**Authors:Seokjun Lee, Seung-Won Jung, Hyunseok Seo**

Currently, image generation and synthesis have remarkably progressed with generative models. Despite photo-realistic results, intrinsic discrepancies are still observed in the frequency domain. The spectral discrepancy appeared not only in generative adversarial networks but in diffusion models. In this study, we propose a framework to effectively mitigate the disparity in frequency domain of the generated images to improve generative performance of both GAN and diffusion models. This is realized by spectrum translation for the refinement of image generation (STIG) based on contrastive learning. We adopt theoretical logic of frequency components in various generative networks. The key idea, here, is to refine the spectrum of the generated image via the concept of image-to-image translation and contrastive learning in terms of digital signal processing. We evaluate our framework across eight fake image datasets and various cutting-edge models to demonstrate the effectiveness of STIG. Our framework outperforms other cutting-edges showing significant decreases in FID and log frequency distance of spectrum. We further emphasize that STIG improves image quality by decreasing the spectral anomaly. Additionally, validation results present that the frequency-based deepfake detector confuses more in the case where fake spectrums are manipulated by STIG. 

[PDF](http://arxiv.org/abs/2403.05093v1) Accepted to AAAI 2024

**Summary**
ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹ä¸­é¢‘åŸŸå·®å¼‚é—®é¢˜ï¼Œå¯é€šè¿‡é¢‘è°±å¯¹æ¯”å­¦ä¹ ä¸‹çš„å›¾åƒç”Ÿæˆè°±è½¬æ¢æ¡†æ¶ï¼ˆSTIGï¼‰æœ‰æ•ˆè§£å†³ã€‚

**Key Takeaways**
* æå‡ºSTIGæ¡†æ¶å‡è½»ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹å›¾åƒé¢‘åŸŸå·®å¼‚ã€‚
* STIGåŸºäºå›¾åƒåˆ°å›¾åƒè½¬æ¢å’Œå¯¹ç…§å­¦ä¹ ï¼Œä¼˜åŒ–ç”Ÿæˆå›¾åƒé¢‘è°±ã€‚
* STIGåœ¨å…«ä¸ªä¼ªé€ å›¾åƒæ•°æ®é›†ä¸Šè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œæ˜¾ç€é™ä½FIDå’Œå…‰è°±çš„å¯¹æ•°é¢‘ç‡è·ç¦»ã€‚
* STIGé€šè¿‡å‡å°å…‰è°±å¼‚å¸¸æé«˜å›¾åƒè´¨é‡ã€‚
* ç»è¿‡STIGå¤„ç†çš„ä¼ªé€ å›¾åƒä¼šè¿·æƒ‘åŸºäºé¢‘ç‡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨ã€‚
* STIGä½¿ç”¨é¢‘è°±è½¬æ¢æœ‰æ•ˆè§£å†³ç”Ÿæˆæ¨¡å‹ä¸­é¢‘åŸŸå·®å¼‚é—®é¢˜ã€‚
* STIGæå‡å›¾åƒç”Ÿæˆè´¨é‡ï¼Œå¢å¼ºå¯¹æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨çš„é²æ£’æ€§ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šå›¾åƒç”Ÿæˆç²¾ç‚¼çš„å…‰è°±è½¬æ¢ï¼ˆSTIGï¼‰</li>
<li>ä½œè€…ï¼šSeokjun Leeã€Seung-Won Jungã€Hyunseok Seo</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šéŸ©å›½ç§‘å­¦æŠ€æœ¯ç ”ç©¶é™¢ç”Ÿç‰©åŒ»å­¦ç ”ç©¶éƒ¨</li>
<li>å…³é”®è¯ï¼šå›¾åƒç”Ÿæˆã€å…‰è°±è½¬æ¢ã€å¯¹æ¯”å­¦ä¹ ã€é¢‘è°±æ»¤æ³¢å™¨è½®å»“</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone
Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
ç›®å‰ï¼Œå›¾åƒç”Ÿæˆå’Œåˆæˆåœ¨ç”Ÿæˆæ¨¡å‹çš„å¸®åŠ©ä¸‹å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚å°½ç®¡ç”Ÿæˆç»“æœé€¼çœŸï¼Œä½†åœ¨é¢‘åŸŸä¸­ä»ç„¶å­˜åœ¨å›ºæœ‰çš„å·®å¼‚ã€‚è¿™ç§é¢‘è°±å·®å¼‚ä¸ä»…å‡ºç°åœ¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä¸­ï¼Œè¿˜å‡ºç°åœ¨æ‰©æ•£æ¨¡å‹ä¸­ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
ä»¥å¾€çš„ç ”ç©¶æå‡ºäº†é€šè¿‡ä¿®æ”¹ç”Ÿæˆç½‘ç»œæ¶æ„æˆ–ç›®æ ‡å‡½æ•°æ¥å¼¥è¡¥é¢‘åŸŸå·®å¼‚çš„æ–¹æ³•ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„å…‰è°±è½¬æ¢æ¡†æ¶ï¼ˆSTIGï¼‰ï¼Œç”¨äºæœ‰æ•ˆå‡è½»ç”Ÿæˆå›¾åƒé¢‘åŸŸä¸­çš„å·®å¼‚ï¼Œä»¥æé«˜ GAN å’Œæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ€§èƒ½ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†æ•°å­—ä¿¡å·å¤„ç†ä¸­å›¾åƒåˆ°å›¾åƒè½¬æ¢å’Œå¯¹æ¯”å­¦ä¹ çš„æ¦‚å¿µæ¥ä¼˜åŒ–ç”Ÿæˆå›¾åƒçš„å…‰è°±ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼š
åœ¨å…«ä¸ªå‡å›¾åƒæ•°æ®é›†å’Œå„ç§å‰æ²¿æ¨¡å‹ä¸Šè¯„ä¼°äº† STIG çš„æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ï¼ŒSTIG ä¼˜äºå…¶ä»–å‰æ²¿æ–¹æ³•ï¼Œåœ¨ FID å’Œå…‰è°±å¯¹æ•°é¢‘ç‡è·ç¦»æ–¹é¢æœ‰æ˜¾è‘—ä¸‹é™ã€‚æ­¤å¤–ï¼ŒSTIG é€šè¿‡å‡å°‘å…‰è°±å¼‚å¸¸æ¥æé«˜å›¾åƒè´¨é‡ã€‚éªŒè¯ç»“æœè¡¨æ˜ï¼Œå½“ STIG å¤„ç†è™šå‡å…‰è°±æ—¶ï¼ŒåŸºäºé¢‘ç‡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨æ›´å®¹æ˜“æ··æ·†ã€‚</li>
</ol>
<p>7.Methodsï¼š
ï¼ˆ1ï¼‰STIGæ¡†æ¶æ¦‚è¿°ï¼šSTIGæ¡†æ¶ç”±ä¸‰ä¸ªä¸»è¦ç»„ä»¶ç»„æˆï¼šå›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œï¼ˆI2Iï¼‰ã€å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’Œé¢‘è°±æ»¤æ³¢å™¨è½®å»“ï¼ˆSFPï¼‰ã€‚
ï¼ˆ2ï¼‰å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œï¼ˆI2Iï¼‰ï¼šI2Iç½‘ç»œé‡‡ç”¨U-Netæ¶æ„ï¼Œç”¨äºå°†ç”Ÿæˆå›¾åƒä»æºé¢‘åŸŸè½¬æ¢åˆ°ç›®æ ‡é¢‘åŸŸã€‚
ï¼ˆ3ï¼‰å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼šå¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°åŸºäºå›¾åƒå¯¹çš„ç›¸ä¼¼æ€§å’Œå·®å¼‚æ€§ï¼Œé€šè¿‡æœ€å¤§åŒ–ç›¸ä¼¼å›¾åƒçš„ç‰¹å¾è¡¨ç¤ºä¹‹é—´çš„ç›¸å…³æ€§ï¼ŒåŒæ—¶æœ€å°åŒ–ä¸åŒå›¾åƒçš„ç‰¹å¾è¡¨ç¤ºä¹‹é—´çš„ç›¸å…³æ€§ï¼Œæ¥ä¼˜åŒ–I2Iç½‘ç»œã€‚
ï¼ˆ4ï¼‰é¢‘è°±æ»¤æ³¢å™¨è½®å»“ï¼ˆSFPï¼‰ï¼šSFPæ˜¯ä¸€ä¸ªé¢„å…ˆè®­ç»ƒçš„é¢‘è°±æ»¤æ³¢å™¨é›†åˆï¼Œç”¨äºæŒ‡å¯¼I2Iç½‘ç»œå­¦ä¹ ç›®æ ‡é¢‘åŸŸçš„ç‰¹å¾åˆ†å¸ƒã€‚
ï¼ˆ5ï¼‰STIGè®­ç»ƒè¿‡ç¨‹ï¼šSTIGæ¡†æ¶çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šé¢„è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼ŒI2Iç½‘ç»œä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’ŒSFPè¿›è¡Œè®­ç»ƒã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼ŒI2Iç½‘ç»œä½¿ç”¨ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å¯¹æŠ—æ€§æŸå¤±å‡½æ•°è¿›è¡Œå¾®è°ƒã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº† STIG æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç›´æ¥æ“ä½œç”Ÿæˆå›¾åƒçš„é¢‘ç‡åˆ†é‡ï¼Œåœ¨é¢‘åŸŸä¸­å‡å°‘ç”Ÿæˆå›¾åƒçš„å…‰è°±å·®å¼‚ï¼Œä»è€Œæé«˜ç”Ÿæˆæ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
STIG æ¡†æ¶åœ¨é¢‘åŸŸä¸­ç›´æ¥æ“ä½œç”Ÿæˆå›¾åƒï¼Œä»¥å‡å°‘ç”Ÿæˆå›¾åƒä¸çœŸå®å›¾åƒä¹‹é—´çš„å…‰è°±å·®å¼‚ã€‚
STIG æ¡†æ¶é‡‡ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’Œé¢‘è°±æ»¤æ³¢å™¨è½®å»“ï¼Œä¼˜åŒ–å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹ã€‚
STIG æ¡†æ¶å¯ä»¥æœ‰æ•ˆåœ°æé«˜ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå’Œæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆæ€§èƒ½ã€‚
æ€§èƒ½ï¼š
STIG æ¡†æ¶åœ¨å…«ä¸ªå‡å›¾åƒåŸºå‡†ä¸Šå‡ä¼˜äºå…¶ä»–å‰æ²¿æ–¹æ³•ï¼Œåœ¨ FID å’Œå…‰è°±å¯¹æ•°é¢‘ç‡è·ç¦»æ–¹é¢æœ‰æ˜¾è‘—ä¸‹é™ã€‚
STIG æ¡†æ¶é€šè¿‡å‡å°‘å…‰è°±å¼‚å¸¸æ¥æé«˜å›¾åƒè´¨é‡ã€‚
STIG æ¡†æ¶å¤„ç†è™šå‡å…‰è°±æ—¶ï¼ŒåŸºäºé¢‘ç‡çš„æ·±åº¦ä¼ªé€ æ£€æµ‹å™¨æ›´å®¹æ˜“æ··æ·†ã€‚
å·¥ä½œé‡ï¼š
STIG æ¡†æ¶çš„è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬é¢„è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µã€‚
é¢„è®­ç»ƒé˜¶æ®µéœ€è¦å¯¹å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°å’Œé¢‘è°±æ»¤æ³¢å™¨è½®å»“è¿›è¡Œè®­ç»ƒã€‚
å¾®è°ƒé˜¶æ®µéœ€è¦å¯¹å›¾åƒåˆ°å›¾åƒè½¬æ¢ç½‘ç»œä½¿ç”¨ç”Ÿæˆå›¾åƒå’ŒçœŸå®å›¾åƒä¹‹é—´çš„å¯¹æŠ—æ€§æŸå¤±å‡½æ•°è¿›è¡Œå¾®è°ƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-59b9082b16c536f6e3dc82d3eedb0929.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-cc9ad99c3613618bd289ca6d732974f2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ed21a9f11c14097979acb60a01fc0faa.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-ee45629a830dd20e3e691c354e6c5761.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-82896ffced53d8bc120b544471040628.jpg" align="middle">
</details>




<h2 id="Improving-Diffusion-Based-Generative-Models-via-Approximated-Optimal-Transport"><a href="#Improving-Diffusion-Based-Generative-Models-via-Approximated-Optimal-Transport" class="headerlink" title="Improving Diffusion-Based Generative Models via Approximated Optimal   Transport"></a>Improving Diffusion-Based Generative Models via Approximated Optimal   Transport</h2><p><strong>Authors:Daegyu Kim, Jooyoung Choi, Chaehun Shin, Uiwon Hwang, Sungroh Yoon</strong></p>
<p>We introduce the Approximated Optimal Transport (AOT) technique, a novel training scheme for diffusion-based generative models. Our approach aims to approximate and integrate optimal transport into the training process, significantly enhancing the ability of diffusion models to estimate the denoiser outputs accurately. This improvement leads to ODE trajectories of diffusion models with lower curvature and reduced truncation errors during sampling. We achieve superior image quality and reduced sampling steps by employing AOT in training. Specifically, we achieve FID scores of 1.88 with just 27 NFEs and 1.73 with 29 NFEs in unconditional and conditional generations, respectively. Furthermore, when applying AOT to train the discriminator for guidance, we establish new state-of-the-art FID scores of 1.68 and 1.58 for unconditional and conditional generations, respectively, each with 29 NFEs. This outcome demonstrates the effectiveness of AOT in enhancing the performance of diffusion models. </p>
<p><a href="http://arxiv.org/abs/2403.05069v1">PDF</a> </p>
<p><strong>æ‘˜è¦</strong><br>é€šè¿‡è¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯æå‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆæ•ˆæœï¼Œé™ä½é‡‡æ ·è¯¯å·®ï¼Œæå‡å›¾åƒè´¨é‡ã€‚</p>
<p><strong>è¦ç‚¹</strong></p>
<ul>
<li>æå‡ºè¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯ï¼Œæ”¹è¿›æ‰©æ•£æ¨¡å‹è®­ç»ƒã€‚</li>
<li>AOT æŠ€æœ¯å°†æœ€ä¼˜ä¼ è¾“æ•´åˆåˆ°æ‰©æ•£æ¨¡å‹è®­ç»ƒï¼Œæå‡å»å™ªè¾“å‡ºå‡†ç¡®æ€§ã€‚</li>
<li>ä¼˜åŒ–åçš„æ‰©æ•£è½¨è¿¹æ›²ç‡é™ä½ï¼Œé‡‡æ ·æˆªæ–­è¯¯å·®å‡å°ã€‚</li>
<li>é‡‡ç”¨ AOT è®­ç»ƒï¼Œå›¾åƒè´¨é‡æå‡ï¼Œé‡‡æ ·æ­¥éª¤å‡å°‘ã€‚</li>
<li>æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œ27 æ¬¡è¯ºç¦å…‹åºåˆ—ï¼ˆNFEï¼‰ï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.88ï¼›29 æ¬¡ NFEï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.73ã€‚</li>
<li>æ¡ä»¶ç”Ÿæˆä¸­ï¼Œ29 æ¬¡ NFEï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.68ï¼›æŒ‡å¯¼åˆ¤åˆ«å™¨è®­ç»ƒï¼ŒFID å¾—åˆ†è¾¾åˆ° 1.58ã€‚</li>
<li>AOT æŠ€æœ¯æœ‰æ•ˆæå‡äº†æ‰©æ•£æ¨¡å‹æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šé€šè¿‡è¿‘ä¼¼æœ€ä¼˜ä¼ è¾“æ”¹è¿›åŸºäºæ‰©æ•£çš„ç”Ÿæˆæ¨¡å‹</li>
<li>ä½œè€…ï¼šDaegyu Kimã€Jooyoung Choiã€Chaehun Shinã€Uiwon Hwangã€Sungroh Yoon</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦–å°”å›½ç«‹å¤§å­¦æ•°æ®ç§‘å­¦ä¸äººå·¥æ™ºèƒ½å®éªŒå®¤</li>
<li>å…³é”®è¯ï¼šç”Ÿæˆæ¨¡å‹ã€æ‰©æ•£æ¨¡å‹ã€æœ€ä¼˜ä¼ è¾“</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05069
   Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç§é€šè¿‡é€æ¸å»å™ªæ¥åˆæˆå›¾åƒçš„ç”Ÿæˆæ¨¡å‹ã€‚è¿‘å¹´æ¥ï¼Œæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ä»å­˜åœ¨ ODE è½¨è¿¹æ›²ç‡é«˜çš„é—®é¢˜ï¼Œè¿™ä¼šå½±å“å›¾åƒè´¨é‡å’Œé‡‡æ ·æ•ˆç‡ã€‚</li>
</ol>
<p>ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š
FlowMatching ç­‰æ–¹æ³•æå‡ºäº†ä½¿ç”¨æœ€ä¼˜ä¼ è¾“æ¥è§£å†³æ›²ç‡é—®é¢˜ï¼Œä½†ç”±äºæ‰©æ•£æ¨¡å‹çš„ç»“æ„ï¼Œç›´æ¥åº”ç”¨è¿™äº›æ–¹æ³•å­˜åœ¨è®¡ç®—æ•ˆç‡ä½çš„é—®é¢˜ã€‚</p>
<p>ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
æœ¬æ–‡æå‡ºäº†ä¸€ç§è¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰è®­ç»ƒæŠ€æœ¯ï¼Œå°†æœ€ä¼˜ä¼ è¾“è¿‘ä¼¼å¹¶æ•´åˆåˆ°æ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»è€Œé™ä½ ODE è½¨è¿¹çš„æ›²ç‡å’Œæˆªæ–­è¯¯å·®ã€‚</p>
<p>ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°åŠæ€§èƒ½ï¼š
åœ¨ CIFAR-10 å›¾åƒæ— æ¡ä»¶å’Œæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œä¸åŸºçº¿ç ”ç©¶å’Œ EDM ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å›¾åƒè´¨é‡å’Œ NFEï¼ˆå‡½æ•°è¯„ä¼°æ¬¡æ•°ï¼‰æ–¹é¢å‡å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œæœ¬æ–‡æ–¹æ³•ä»¥ 27 NFE å®ç°äº† 1.88 çš„ FID å¾—åˆ†ï¼Œä»¥ 29 NFE å®ç°äº† 1.73 çš„ FID å¾—åˆ†ï¼›åœ¨æ¡ä»¶ç”Ÿæˆä¸­ï¼Œä»¥ 29 NFE å®ç°äº† 1.68 çš„ FID å¾—åˆ†ï¼Œä»¥ 29 NFE å®ç°äº† 1.58 çš„ FID å¾—åˆ†ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒAOT æŠ€æœ¯å¯ä»¥æœ‰æ•ˆæå‡æ‰©æ•£æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
<p>Some Error for method(æ¯”å¦‚æ˜¯ä¸æ˜¯æ²¡æœ‰Methodsè¿™ä¸ªç« èŠ‚)</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶å·¥ä½œé€šè¿‡æå‡ºè¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯ï¼Œæœ‰æ•ˆé™ä½äº†æ‰©æ•£æ¨¡å‹ ODE è½¨è¿¹çš„æ›²ç‡å’Œæˆªæ–­è¯¯å·®ï¼Œä»è€Œæå‡äº†å›¾åƒç”Ÿæˆè´¨é‡å’Œé‡‡æ ·æ•ˆç‡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºè¿‘ä¼¼æœ€ä¼˜ä¼ è¾“ï¼ˆAOTï¼‰æŠ€æœ¯ï¼Œå°†æœ€ä¼˜ä¼ è¾“è¿‘ä¼¼å¹¶æ•´åˆåˆ°æ‰©æ•£æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé™ä½äº† ODE è½¨è¿¹çš„æ›²ç‡å’Œæˆªæ–­è¯¯å·®ã€‚</li>
<li>å°† AOT æŠ€æœ¯æˆåŠŸé›†æˆåˆ° Discriminator Guidanceï¼ˆDGï¼‰æ¡†æ¶ä¸­ï¼Œå±•ç¤ºäº†å…¶åœ¨æ›´å¹¿æ³›åº”ç”¨ä¸­çš„å¤šåŠŸèƒ½æ€§å’Œæ½œåŠ›ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ CIFAR-10 å›¾åƒæ— æ¡ä»¶å’Œæ¡ä»¶ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œä¸åŸºçº¿ç ”ç©¶å’Œ EDM ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å›¾åƒè´¨é‡å’Œ NFEï¼ˆå‡½æ•°è¯„ä¼°æ¬¡æ•°ï¼‰æ–¹é¢å‡å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚</li>
<li>åœ¨æ— æ¡ä»¶ç”Ÿæˆä¸­ï¼Œæœ¬æ–‡æ–¹æ³•ä»¥ 27NFE å®ç°äº† 1.88 çš„ FID å¾—åˆ†ï¼Œä»¥ 29NFE å®ç°äº† 1.73 çš„ FID å¾—åˆ†ï¼›åœ¨æ¡ä»¶ç”Ÿæˆä¸­ï¼Œä»¥ 29NFE å®ç°äº† 1.68 çš„ FID å¾—åˆ†ï¼Œä»¥ 29NFE å®ç°äº† 1.58 çš„ FID å¾—åˆ†ã€‚
å·¥ä½œé‡ï¼š</li>
<li>ä¸ EDM ç›¸æ¯”ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨è®­ç»ƒæˆæœ¬ä¸Šç•¥æœ‰å¢åŠ ï¼ˆ2% åˆ° 15%ï¼‰ã€‚</li>
<li>æœ¬æ–¹æ³•éœ€è¦ç®—æ³•æ”¹è¿›ï¼Œä»¥æ‰©å±•å…¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¡ä»¶ç”Ÿæˆï¼ˆä¾‹å¦‚æ–‡æœ¬æŒ‡å¯¼ç”Ÿæˆï¼‰ä¸­çš„é€‚ç”¨æ€§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-8b3484bb01610ca257b110266a789659.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a1905f26c3dd85ac5906dbc02f95a1c6.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-06436ae944972e738965038412bab51a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-092c4ba972936da93fe5ca9a1e0c861e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3004bc0c97615bac6076ff6a3cd11e53.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-63b88ad2349cca16dbda28634bc2b6d1.jpg" align="middle">
</details>




<h2 id="XPSR-Cross-modal-Priors-for-Diffusion-based-Image-Super-Resolution"><a href="#XPSR-Cross-modal-Priors-for-Diffusion-based-Image-Super-Resolution" class="headerlink" title="XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution"></a>XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution</h2><p><strong>Authors:Yunpeng Qu, Kun Yuan, Kai Zhao, Qizhi Xie, Jinhua Hao, Ming Sun, Chao Zhou</strong></p>
<p>Diffusion-based methods, endowed with a formidable generative prior, have received increasing attention in Image Super-Resolution (ISR) recently. However, as low-resolution (LR) images often undergo severe degradation, it is challenging for ISR models to perceive the semantic and degradation information, resulting in restoration images with incorrect content or unrealistic artifacts. To address these issues, we propose a \textit{Cross-modal Priors for Super-Resolution (XPSR)} framework. Within XPSR, to acquire precise and comprehensive semantic conditions for the diffusion model, cutting-edge Multimodal Large Language Models (MLLMs) are utilized. To facilitate better fusion of cross-modal priors, a \textit{Semantic-Fusion Attention} is raised. To distill semantic-preserved information instead of undesired degradations, a \textit{Degradation-Free Constraint} is attached between LR and its high-resolution (HR) counterpart. Quantitative and qualitative results show that XPSR is capable of generating high-fidelity and high-realism images across synthetic and real-world datasets. Codes will be released at \url{<a href="https://github.com/qyp2000/XPSR}">https://github.com/qyp2000/XPSR}</a>. </p>
<p><a href="http://arxiv.org/abs/2403.05049v1">PDF</a> 19 pages, 7 figures</p>
<p><strong>Summary</strong><br>åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œç»“åˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’Œè¯­ä¹‰èåˆç­–ç•¥ï¼Œæå‡ºä¸€ç§å›¾åƒè¶…åˆ†è¾¨ç‡æ¡†æ¶XPSRï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸå’Œé€¼çœŸçš„å›¾åƒã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¼å…ˆéªŒæå‡å›¾åƒè¶…åˆ†è¾¨ç‡æ€§èƒ½ã€‚</li>
<li>å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æä¾›ç²¾ç¡®è¯­ä¹‰ä¿¡æ¯ã€‚</li>
<li>è¯­ä¹‰èåˆæ³¨æ„åŠ›ä¿ƒè¿›è·¨æ¨¡æ€å…ˆéªŒèåˆã€‚</li>
<li>æ— é€€åŒ–çº¦æŸæå–è¯­ä¹‰å†…å®¹ï¼Œè€Œéé€€åŒ–ä¿¡æ¯ã€‚</li>
<li>XPSRåœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šç”Ÿæˆé«˜è´¨é‡è¶…åˆ†è¾¨ç‡å›¾åƒã€‚</li>
<li>XPSRä»£ç å°†äº<a href="https://github.com/qyp2000/XPSRå‘å¸ƒã€‚">https://github.com/qyp2000/XPSRå‘å¸ƒã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šXPSRï¼šç”¨äºåŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡çš„è·¨æ¨¡æ€å…ˆéªŒ</li>
<li>ä½œè€…ï¼šæ›²äº‘é¹ã€è¢å¤ã€èµµå‡¯ã€è°¢å¯ä¹‹ã€éƒé‡‘åã€å­™æ˜ã€å‘¨è¶…</li>
<li>å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šå›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤ã€æ‰©æ•£æ¨¡å‹ã€å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05049
Githubä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆISRï¼‰æ–¹æ³•å› å…¶å¼ºå¤§çš„ç”Ÿæˆå…ˆéªŒè€Œå—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å›¾åƒé€šå¸¸ä¼šé­å—ä¸¥é‡çš„é€€åŒ–ï¼Œå› æ­¤å¯¹äºISRæ¨¡å‹æ¥è¯´ï¼Œæ„ŸçŸ¥è¯­ä¹‰å’Œé€€åŒ–ä¿¡æ¯å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¯¼è‡´æ¢å¤çš„å›¾åƒå†…å®¹ä¸æ­£ç¡®æˆ–å‡ºç°ä¸çœŸå®çš„ä¼ªå½±ã€‚
ï¼ˆ2ï¼‰ä»¥å¾€æ–¹æ³•åŠå…¶é—®é¢˜ï¼šæœ¬æ–‡çš„åŠ¨æœºæ˜¯è§£å†³ä¸Šè¿°é—®é¢˜ã€‚ä»¥å¾€æ–¹æ³•ä¸»è¦ä½¿ç”¨ç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼ˆGANï¼‰è¿›è¡Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œä½†GANåœ¨ç”Ÿæˆé€¼çœŸçº¹ç†æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¹¶ä¸”å­˜åœ¨åˆæˆè®­ç»ƒæ•°æ®å’ŒçœŸå®ä¸–ç•Œæµ‹è¯•æ•°æ®ä¹‹é—´çš„åŸŸå·®è·é—®é¢˜ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªè·¨æ¨¡æ€å…ˆéªŒè¶…åˆ†è¾¨ç‡ï¼ˆXPSRï¼‰æ¡†æ¶ã€‚åœ¨XPSRä¸­ï¼Œåˆ©ç”¨å…ˆè¿›çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä¸ºæ‰©æ•£æ¨¡å‹è·å–å‡†ç¡®å’Œå…¨é¢çš„è¯­ä¹‰æ¡ä»¶ã€‚ä¸ºäº†ä¿ƒè¿›è·¨æ¨¡æ€å…ˆéªŒçš„æ›´å¥½èåˆï¼Œæå‡ºäº†ä¸€ç§è¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶ã€‚ä¸ºäº†æå–è¯­ä¹‰ä¿ç•™çš„ä¿¡æ¯è€Œä¸æ˜¯ä¸éœ€è¦çš„é€€åŒ–ï¼Œåœ¨LRåŠå…¶é«˜åˆ†è¾¨ç‡ï¼ˆHRï¼‰å¯¹åº”å›¾åƒä¹‹é—´é™„åŠ äº†ä¸€ä¸ªæ— é€€åŒ–çº¦æŸã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šå®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼ŒXPSRèƒ½å¤Ÿè·¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ç”Ÿæˆé«˜ä¿çœŸå’Œé«˜é€¼çœŸçš„å›¾åƒã€‚è¿™äº›ç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆè§£å†³å›¾åƒè¶…åˆ†è¾¨ç‡ä¸­çš„æŒ‘æˆ˜ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) é‡‡ç”¨å¤§è¯­è¨€æ¨¡å‹ LLaVA è·å–å›¾åƒçš„è¯­ä¹‰å…ˆéªŒï¼ŒåŒ…æ‹¬é«˜å±‚è¯­ä¹‰å’Œä½å±‚è¯­ä¹‰ï¼›
(2) ä½¿ç”¨è¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†è¯­ä¹‰å…ˆéªŒä¸ T2I æ¨¡å‹ç”Ÿæˆçš„å…ˆéªŒæœ‰æ•ˆèåˆï¼›
(3) æ·»åŠ æ— é€€åŒ–çº¦æŸï¼Œä» LR å›¾åƒä¸­æå–è¯­ä¹‰ä¿ç•™ä½†ä¸é€€åŒ–æ— å…³çš„ä¿¡æ¯ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æ„ä¹‰ï¼šæœ¬æ–‡æå‡ºçš„ XPSR æ¡†æ¶è§£å†³äº†åŸºäºæ‰©æ•£çš„å›¾åƒè¶…åˆ†è¾¨ç‡æ¨¡å‹åœ¨å‡†ç¡®æ¢å¤è¯­ä¹‰ç»†èŠ‚æ–¹é¢çš„éš¾é¢˜ï¼Œä¸ºå›¾åƒè¶…åˆ†è¾¨ç‡é¢†åŸŸæä¾›äº†æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰ä¼˜ç¼ºç‚¹æ€»ç»“ï¼š
åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºè·¨æ¨¡æ€å…ˆéªŒæ¦‚å¿µï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸ºæ‰©æ•£æ¨¡å‹æä¾›å‡†ç¡®å…¨é¢çš„è¯­ä¹‰æ¡ä»¶ã€‚</li>
<li>è®¾è®¡è¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶ï¼Œæœ‰æ•ˆèåˆè¯­ä¹‰å…ˆéªŒå’Œ T2I æ¨¡å‹ç”Ÿæˆçš„å…ˆéªŒã€‚</li>
<li>å¼•å…¥æ— é€€åŒ–çº¦æŸï¼Œä»ä½åˆ†è¾¨ç‡å›¾åƒä¸­æå–è¯­ä¹‰ä¿ç•™ä½†ä¸é€€åŒ–æ— å…³çš„ä¿¡æ¯ã€‚
æ€§èƒ½ï¼š</li>
<li>å®šé‡å’Œå®šæ€§ç»“æœè¡¨æ˜ï¼ŒXPSR èƒ½å¤Ÿè·¨åˆæˆå’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ç”Ÿæˆé«˜ä¿çœŸå’Œé«˜é€¼çœŸçš„å›¾åƒã€‚</li>
<li>ä¸å…¶ä»–å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼ŒXPSR åœ¨å„ç§è¯„ä¼°æŒ‡æ ‡ä¸Šå–å¾—äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼š</li>
<li>XPSR æ¡†æ¶çš„å®ç°éœ€è¦ä¸€å®šçš„å·¥ä½œé‡ï¼ŒåŒ…æ‹¬è®­ç»ƒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’Œæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>æ­¤å¤–ï¼Œè¯­ä¹‰èåˆæ³¨æ„åŠ›æœºåˆ¶å’Œæ— é€€åŒ–çº¦æŸçš„å®ç°ä¹Ÿéœ€è¦é¢å¤–çš„å¼€å‘å·¥ä½œã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7216c617badf932e3f8d18daf0977b1f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4c7194197140a421dc8eb74d3c744901.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ca3923ee7424c689775b0bb281aa1184.jpg" align="middle">
</details>




<h2 id="DiffClass-Diffusion-Based-Class-Incremental-Learning"><a href="#DiffClass-Diffusion-Based-Class-Incremental-Learning" class="headerlink" title="DiffClass: Diffusion-Based Class Incremental Learning"></a>DiffClass: Diffusion-Based Class Incremental Learning</h2><p><strong>Authors:Zichong Meng, Jie Zhang, Changdi Yang, Zheng Zhan, Pu Zhao, Yanzhi WAng</strong></p>
<p>Class Incremental Learning (CIL) is challenging due to catastrophic forgetting. On top of that, Exemplar-free Class Incremental Learning is even more challenging due to forbidden access to previous task data. Recent exemplar-free CIL methods attempt to mitigate catastrophic forgetting by synthesizing previous task data. However, they fail to overcome the catastrophic forgetting due to the inability to deal with the significant domain gap between real and synthetic data. To overcome these issues, we propose a novel exemplar-free CIL method. Our method adopts multi-distribution matching (MDM) diffusion models to unify quality and bridge domain gaps among all domains of training data. Moreover, our approach integrates selective synthetic image augmentation (SSIA) to expand the distribution of the training data, thereby improving the modelâ€™s plasticity and reinforcing the performance of our methodâ€™s ultimate component, multi-domain adaptation (MDA). With the proposed integrations, our method then reformulates exemplar-free CIL into a multi-domain adaptation problem to implicitly address the domain gap problem to enhance model stability during incremental training. Extensive experiments on benchmark class incremental datasets and settings demonstrate that our method excels previous exemplar-free CIL methods and achieves state-of-the-art performance. </p>
<p><a href="http://arxiv.org/abs/2403.05016v1">PDF</a> Preprint</p>
<p><strong>Summary</strong><br>å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹åœ¨æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ ä¸­è§£å†³ç¾éš¾æ€§é—å¿˜å’Œé¢†åŸŸå·®å¼‚é—®é¢˜ï¼Œé€šè¿‡å¤šåŸŸé€‚åº”éšå¼è§£å†³é¢†åŸŸå·®å¼‚é—®é¢˜ï¼Œæé«˜æ¨¡å‹ç¨³å®šæ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>ç±»å¢é‡å­¦ä¹ é¢ä¸´ç¾éš¾æ€§é—å¿˜å’Œæ— ä¾‹å¯å¾ªçš„æŒ‘æˆ˜ã€‚</li>
<li>æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ æ–¹æ³•é€šè¿‡åˆæˆå…ˆå‰ä»»åŠ¡æ•°æ®æ¥å‡è½»ç¾éš¾æ€§é—å¿˜ã€‚</li>
<li>æ­¤ç±»æ–¹æ³•ç”±äºæ— æ³•å¤„ç†çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®ä¹‹é—´çš„æ˜¾ç€é¢†åŸŸå·®å¼‚è€Œæ— æ³•å…‹æœç¾éš¾æ€§é—å¿˜ã€‚</li>
<li>æå‡ºä¸€ç§æ–°çš„æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ æ–¹æ³•ï¼Œé‡‡ç”¨å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ç»Ÿä¸€è´¨é‡å’Œå¼¥åˆæ‰€æœ‰è®­ç»ƒæ•°æ®åŸŸä¹‹é—´çš„é¢†åŸŸå·®å¼‚ã€‚</li>
<li>è¯¥æ–¹æ³•é›†æˆäº†é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºï¼Œä»¥æ‰©å±•è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒã€‚</li>
<li>è¿™ç§æ–¹æ³•å°†æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸé€‚åº”é—®é¢˜ï¼Œä»¥éšå¼è§£å†³é¢†åŸŸå·®å¼‚é—®é¢˜ï¼Œæé«˜æ¨¡å‹åœ¨å¢é‡è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§ã€‚</li>
<li>å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºå…ˆå‰çš„æ— ä¾‹å¯å¾ªçš„ç±»å¢é‡å­¦ä¹ æ–¹æ³•ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£çš„ç±»å¢é‡å­¦ä¹ </li>
<li>ä½œè€…ï¼šå­Ÿå­èªï¼Œå¼ æ°ï¼Œæ¨æ˜Œè¿ªï¼Œè©¹æ”¿ï¼Œèµµæ™®ï¼Œç‹å»¶ä¹‹</li>
<li>ä¸œåŒ—å¤§å­¦</li>
<li>ClassIncrementalLearningï¼ŒExemplarFreeï¼ŒDiffusionModel</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05016
   Githubä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼š
ç±»å¢é‡å­¦ä¹ ï¼ˆCILï¼‰å› ç¾éš¾æ€§é—å¿˜è€Œæå…·æŒ‘æˆ˜æ€§ã€‚æ­¤å¤–ï¼Œç”±äºæ— æ³•è®¿é—®å…ˆå‰ä»»åŠ¡çš„æ•°æ®ï¼Œæ— ç¤ºä¾‹ CIL æ›´æ˜¯éš¾ä¸ŠåŠ éš¾ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠé—®é¢˜ï¼š
æœ€è¿‘çš„æ— ç¤ºä¾‹ CIL æ–¹æ³•å°è¯•é€šè¿‡åˆæˆå…ˆå‰ä»»åŠ¡æ•°æ®æ¥ç¼“è§£ç¾éš¾æ€§é—å¿˜ã€‚ç„¶è€Œï¼Œå®ƒä»¬ç”±äºæ— æ³•å¤„ç†çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®ä¹‹é—´çš„å·¨å¤§åŸŸå·®è·è€Œæ— æ³•å…‹æœç¾éš¾æ€§é—å¿˜ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
ä¸ºäº†å…‹æœè¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— ç¤ºä¾‹ CIL æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å¤šåˆ†å¸ƒåŒ¹é… (MDM) æ‰©æ•£æ¨¡å‹æ¥å¯¹é½åˆæˆæ•°æ®çš„è´¨é‡ï¼Œå¹¶å¼¥åˆè®­ç»ƒæ•°æ®æ‰€æœ‰åŸŸä¹‹é—´çš„åŸŸå·®è·ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡çš„æ–¹æ³•é›†æˆäº†é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼º (SSIA) æ¥æ‰©å±•è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œä»è€Œæé«˜æ¨¡å‹çš„å¯å¡‘æ€§å¹¶å¢å¼ºå¤šåŸŸè‡ªé€‚åº” (MDA) æŠ€æœ¯çš„æ€§èƒ½ã€‚é€šè¿‡æå‡ºçš„é›†æˆï¼Œæœ¬æ–‡çš„æ–¹æ³•å°†æ— ç¤ºä¾‹ CIL é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸè‡ªé€‚åº”é—®é¢˜ï¼Œä»¥éšå¼è§£å†³åŸŸå·®è·é—®é¢˜å¹¶å¢å¼ºæ¨¡å‹åœ¨å¢é‡è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼š
åœ¨åŸºå‡† CIL æ•°æ®é›†å’Œè®¾ç½®ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæœ¬æ–‡çš„æ–¹æ³•ä¼˜äºä¹‹å‰çš„æ— ç¤ºä¾‹ CIL æ–¹æ³•ï¼Œå…·æœ‰éè¾¹é™…æ”¹è¿›ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ç²¾è°ƒï¼šä½¿ç”¨ LoRA ç²¾è°ƒå¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ï¼Œå¯¹é½åˆæˆæ•°æ®çš„è´¨é‡ï¼Œç¼©å°è®­ç»ƒæ•°æ®æ‰€æœ‰åŸŸä¹‹é—´çš„åŸŸå·®è·ã€‚
(2) é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºï¼šé€šè¿‡é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºæ‰©å±•è®­ç»ƒæ•°æ®çš„åˆ†å¸ƒï¼Œæé«˜æ¨¡å‹çš„å¯å¡‘æ€§ï¼Œå¢å¼ºå¤šåŸŸè‡ªé€‚åº”æŠ€æœ¯çš„æ€§èƒ½ã€‚
(3) å¤šåŸŸè‡ªé€‚åº”ï¼šé‡‡ç”¨å¤šåŸŸè‡ªé€‚åº”è®­ç»ƒæ–¹æ³•ï¼Œå°†æ— ç¤ºä¾‹ CIL é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸè‡ªé€‚åº”é—®é¢˜ï¼Œéšå¼è§£å†³åŸŸå·®è·é—®é¢˜ï¼Œå¢å¼ºæ¨¡å‹åœ¨å¢é‡è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§ã€‚</p>
</li>
</ol>
<p>8.ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£çš„æ–°é¢–æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡å¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹å’Œé€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºæœ‰æ•ˆè§£å†³äº†ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œå¹¶é€šè¿‡å¤šåŸŸè‡ªé€‚åº”æŠ€æœ¯å¢å¼ºäº†æ¨¡å‹çš„ç¨³å®šæ€§å’Œå¯å¡‘æ€§ï¼Œåœ¨æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š
* åŸºäºå¤šåˆ†å¸ƒåŒ¹é…æ‰©æ•£æ¨¡å‹ï¼Œæ˜¾å¼å¼¥åˆåˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®ä¹‹é—´çš„åŸŸå·®è·ã€‚
* é‡‡ç”¨é€‰æ‹©æ€§åˆæˆå›¾åƒå¢å¼ºï¼Œæ‰©å±•è®­ç»ƒæ•°æ®åˆ†å¸ƒï¼Œæé«˜æ¨¡å‹çš„å¯å¡‘æ€§ã€‚
* å°†æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ é‡æ–°è¡¨è¿°ä¸ºå¤šåŸŸè‡ªé€‚åº”é—®é¢˜ï¼Œéšå¼è§£å†³åŸŸå·®è·é—®é¢˜ï¼Œå¢å¼ºæ¨¡å‹åœ¨å¢é‡è®­ç»ƒæœŸé—´çš„ç¨³å®šæ€§ã€‚
æ€§èƒ½ï¼š
* åœ¨ CIFAR100 å’Œ ImageNet100 åŸºå‡†æ•°æ®é›†ä¸Šï¼Œåœ¨å„ç§æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ è®¾ç½®ä¸­å‡å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
* æ¶ˆèç ”ç©¶è¯æ˜äº†æœ¬æ–‡æ–¹æ³•ä¸­æ¯ä¸ªç»„ä»¶åœ¨æ— ç¤ºä¾‹ç±»å¢é‡å­¦ä¹ ä¸­çš„é‡è¦æ€§ã€‚
å·¥ä½œé‡ï¼š
* æ¯ä¸ªå¢é‡ä»»åŠ¡çš„è®­ç»ƒæ—¶é—´ç›¸å¯¹è¾ƒé•¿ï¼Œå°¤å…¶æ˜¯ä½¿ç”¨ LoRA å¾®è°ƒç”Ÿæˆæ¨¡å‹çš„æ—¶é—´ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3071368b15837785fc8226279a7a69f4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-022f350905045d5945b926c68a304727.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-191fbfc51055a8bc7b2acc064efa3416.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-70ca4a001e09124d997a32d6f30da7f0.jpg" align="middle">
</details>




## StereoDiffusion: Training-Free Stereo Image Generation Using Latent   Diffusion Models

**Authors:Lezhong Wang, Jeppe Revall Frisvad, Mark Bo Jensen, Siavash Arjomand Bigdeli**

The demand for stereo images increases as manufacturers launch more XR devices. To meet this demand, we introduce StereoDiffusion, a method that, unlike traditional inpainting pipelines, is trainning free, remarkably straightforward to use, and it seamlessly integrates into the original Stable Diffusion model. Our method modifies the latent variable to provide an end-to-end, lightweight capability for fast generation of stereo image pairs, without the need for fine-tuning model weights or any post-processing of images. Using the original input to generate a left image and estimate a disparity map for it, we generate the latent vector for the right image through Stereo Pixel Shift operations, complemented by Symmetric Pixel Shift Masking Denoise and Self-Attention Layers Modification methods to align the right-side image with the left-side image. Moreover, our proposed method maintains a high standard of image quality throughout the stereo generation process, achieving state-of-the-art scores in various quantitative evaluations. 

[PDF](http://arxiv.org/abs/2403.04965v1) 

**Summary**
ç«‹ä½“æ‰©æ•£ï¼šæ— è®­ç»ƒã€ç®€å•æ˜“ç”¨ï¼Œæ— ç¼é›†æˆåŸæœ‰ Stable Diffusion æ¨¡å‹ï¼Œç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ã€‚

**Key Takeaways**
- StereoDiffusion æ— éœ€è®­ç»ƒï¼Œä½¿ç”¨æ–¹ä¾¿ã€‚
- ä¸åŸå§‹ Stable Diffusion æ¨¡å‹æ— ç¼é›†æˆã€‚
- ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹æ—¶æ— éœ€å¾®è°ƒæ¨¡å‹æƒé‡æˆ–å›¾åƒåå¤„ç†ã€‚
- åˆ©ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ã€‚
- ä½¿ç”¨ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³å›¾åƒçš„æ½œå˜é‡ã€‚
- ä½¿ç”¨å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•ã€‚
- ä¿æŒç«‹ä½“ç”Ÿæˆè¿‡ç¨‹ä¸­å›¾åƒè´¨é‡çš„é«˜æ ‡å‡†ã€‚
- åœ¨å„ç§å®šé‡è¯„ä¼°ä¸­å–å¾—æœ€å…ˆè¿›çš„åˆ†æ•°ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šç«‹ä½“æ‰©æ•£ï¼šåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ— è®­ç»ƒç«‹ä½“å›¾åƒç”Ÿæˆ</li>
<li>ä½œè€…ï¼šLezhong Wangã€Jeppe Revall Frisvadã€Mark Bo Jensenã€Siavash Arjomand Bigdeli</li>
<li>éš¶å±å•ä½ï¼šä¸¹éº¦æŠ€æœ¯å¤§å­¦åº”ç”¨æ•°å­¦ä¸è®¡ç®—æœºç§‘å­¦ç³»</li>
<li>å…³é”®è¯ï¼šXRã€æ·±åº¦å›¾åƒ/è§†é¢‘åˆæˆã€å›¾åƒç¼–è¾‘ã€äººå·¥æ™ºèƒ½ã€ä¿®å¤ã€Stable Diffusion</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.04965
   Github ä»£ç é“¾æ¥ï¼šæ— </li>
<li>
<p>æ‘˜è¦ï¼š
   (1)ï¼šéšç€åˆ¶é€ å•†æ¨å‡ºæ›´å¤š XR è®¾å¤‡ï¼Œå¯¹ç«‹ä½“å›¾åƒçš„éœ€æ±‚ä¸æ–­å¢åŠ ã€‚ä¸ºäº†æ»¡è¶³è¿™ä¸€éœ€æ±‚ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç«‹ä½“æ‰©æ•£ï¼Œè¿™æ˜¯ä¸€ç§ä¸ä¼ ç»Ÿä¿®å¤ç®¡é“ä¸åŒã€æ— éœ€è®­ç»ƒã€ä½¿ç”¨æå…¶ç®€å•ä¸”å¯ä¸åŸå§‹ Stable Diffusion æ¨¡å‹æ— ç¼é›†æˆçš„æŠ€æœ¯ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¿®æ”¹äº†æ½œåœ¨å˜é‡ï¼Œæä¾›äº†ä¸€ç§ç«¯åˆ°ç«¯çš„è½»é‡çº§åŠŸèƒ½ï¼Œç”¨äºå¿«é€Ÿç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ï¼Œè€Œæ— éœ€å¾®è°ƒæ¨¡å‹æƒé‡æˆ–å¯¹å›¾åƒè¿›è¡Œä»»ä½•åå¤„ç†ã€‚æˆ‘ä»¬ä½¿ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦ä¾§å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ï¼Œé€šè¿‡ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³ä¾§å›¾åƒçš„æ½œåœ¨å‘é‡ï¼Œå¹¶è¾…ä»¥å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•ï¼Œå°†å³ä¾§å›¾åƒä¸å·¦ä¾§å›¾åƒå¯¹é½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•åœ¨æ•´ä¸ªç«‹ä½“ç”Ÿæˆè¿‡ç¨‹ä¸­ä¿æŒäº†è¾ƒé«˜çš„å›¾åƒè´¨é‡æ ‡å‡†ï¼Œåœ¨å„ç§å®šé‡è¯„ä¼°ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„å¾—åˆ†ã€‚
   (2)ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºå›¾åƒä¿®å¤ç®¡é“ï¼Œè¯¥ç®¡é“éœ€è¦é¢å¤–çš„æ¨¡å‹è¿›è¡Œåå¤„ç†ä»¥ç”Ÿæˆç«‹ä½“å›¾åƒã€‚è¿™äº›æ–¹æ³•é€šå¸¸éœ€è¦å¯¹æ¨¡å‹æƒé‡è¿›è¡Œå¾®è°ƒï¼Œå¹¶ä¸”ç”Ÿæˆè¿‡ç¨‹å¤æ‚ä¸”è€—æ—¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡ä¿®æ”¹ Stable Diffusion æ¨¡å‹çš„æ½œåœ¨å˜é‡æ¥ç›´æ¥ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ï¼Œæ— éœ€é¢å¤–çš„æ¨¡å‹æˆ–åå¤„ç†ã€‚è¿™ç§æ–¹æ³•ç®€å•æœ‰æ•ˆï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒã€‚
   (3)ï¼šæˆ‘ä»¬æå‡ºçš„æ–¹æ³•æ˜¯ä¸€ç§ç«¯åˆ°ç«¯çš„ç«‹ä½“å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œå®ƒä¿®æ”¹äº† Stable Diffusion æ¨¡å‹çš„æ½œåœ¨å˜é‡ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦ä¾§å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³ä¾§å›¾åƒçš„æ½œåœ¨å‘é‡ã€‚ä¸ºäº†å¯¹é½å³ä¾§å›¾åƒå’Œå·¦ä¾§å›¾åƒï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•ã€‚
   (4)ï¼šæˆ‘ä»¬åœ¨ç«‹ä½“å›¾åƒç”Ÿæˆä»»åŠ¡ä¸Šè¯„ä¼°äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§å®šé‡è¯„ä¼°ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„å¾—åˆ†ï¼ŒåŒ…æ‹¬ PSNRã€SSIM å’Œ LPIPSã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒï¼Œå¹¶ä¸”å¯ä»¥å¾ˆå¥½åœ°æ”¯æŒæˆ‘ä»¬çš„ç›®æ ‡ï¼Œå³å¿«é€Ÿç”Ÿæˆæ— éœ€è®­ç»ƒçš„ç«‹ä½“å›¾åƒå¯¹ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰ä½¿ç”¨åŸå§‹è¾“å…¥ç”Ÿæˆå·¦ä¾§å›¾åƒå¹¶ä¼°è®¡å…¶è§†å·®å›¾ï¼›
ï¼ˆ2ï¼‰é€šè¿‡ç«‹ä½“åƒç´ ä½ç§»æ“ä½œç”Ÿæˆå³ä¾§å›¾åƒçš„æ½œåœ¨å‘é‡ï¼›
ï¼ˆ3ï¼‰ä½¿ç”¨å¯¹ç§°åƒç´ ä½ç§»æ©ç å»å™ªå’Œè‡ªæ³¨æ„åŠ›å±‚ä¿®æ”¹æ–¹æ³•å¯¹é½å³ä¾§å›¾åƒå’Œå·¦ä¾§å›¾åƒã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šç«‹ä½“æ‰©æ•£ï¼šåŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ— è®­ç»ƒç«‹ä½“å›¾åƒç”Ÿæˆï¼Œè¿™é¡¹å·¥ä½œæå‡ºäº†ä¸€ç§é€šè¿‡ä¿®æ”¹æ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ½œåœ¨å˜é‡æ¥ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–çš„æ¨¡å‹æˆ–åå¤„ç†ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æ— éœ€è®­ç»ƒï¼šè¯¥æ–¹æ³•æ— éœ€å¯¹æ¨¡å‹æƒé‡è¿›è¡Œå¾®è°ƒï¼Œç›´æ¥ç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ï¼Œç®€åŒ–äº†ç”Ÿæˆè¿‡ç¨‹ã€‚</li>
<li>ç«¯åˆ°ç«¯ï¼šè¯¥æ–¹æ³•ä¿®æ”¹æ½œåœ¨å˜é‡ï¼Œæä¾›äº†ä¸€ç§ç«¯åˆ°ç«¯çš„è½»é‡çº§åŠŸèƒ½ï¼Œç”¨äºå¿«é€Ÿç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ã€‚</li>
<li>ä¸åŸå§‹StableDiffusionæ¨¡å‹æ— ç¼é›†æˆï¼šè¯¥æ–¹æ³•å¯ä»¥ä¸åŸå§‹StableDiffusionæ¨¡å‹æ— ç¼é›†æˆï¼Œæ— éœ€å¯¹æ¨¡å‹è¿›è¡Œä»»ä½•ä¿®æ”¹ã€‚
æ€§èƒ½ï¼š</li>
<li>å®šé‡è¯„ä¼°ï¼šè¯¥æ–¹æ³•åœ¨KITTIå’ŒMiddleburyæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„å¾—åˆ†ï¼Œè¡¨æ˜å…¶å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„ç«‹ä½“å›¾åƒã€‚
å·¥ä½œé‡ï¼š</li>
<li>è®¡ç®—æˆæœ¬ï¼šè¯¥æ–¹æ³•çš„è®¡ç®—æˆæœ¬è¾ƒä½ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆç«‹ä½“å›¾åƒå¯¹ã€‚</li>
<li>å†…å­˜å ç”¨ï¼šè¯¥æ–¹æ³•çš„å†…å­˜å ç”¨è¾ƒå°ï¼Œå¯ä»¥åœ¨å„ç§è®¾å¤‡ä¸Šè¿è¡Œã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-2042e22706397759569cb6c0ac2c19fc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-1a050df593611d8551bcd2b7e676c281.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4970b55916ca916d6716d8304932590e.jpg" align="middle">
</details>




<h2 id="AFreeCA-Annotation-Free-Counting-for-All"><a href="#AFreeCA-Annotation-Free-Counting-for-All" class="headerlink" title="AFreeCA: Annotation-Free Counting for All"></a>AFreeCA: Annotation-Free Counting for All</h2><p><strong>Authors:Adriano Dâ€™Alessandro, Ali Mahdavi-Amiri, Ghassan Hamarneh</strong></p>
<p>Object counting methods typically rely on manually annotated datasets. The cost of creating such datasets has restricted the versatility of these networks to count objects from specific classes (such as humans or penguins), and counting objects from diverse categories remains a challenge. The availability of robust text-to-image latent diffusion models (LDMs) raises the question of whether these models can be utilized to generate counting datasets. However, LDMs struggle to create images with an exact number of objects based solely on text prompts but they can be used to offer a dependable \textit{sorting} signal by adding and removing objects within an image. Leveraging this data, we initially introduce an unsupervised sorting methodology to learn object-related features that are subsequently refined and anchored for counting purposes using counting data generated by LDMs. Further, we present a density classifier-guided method for dividing an image into patches containing objects that can be reliably counted. Consequently, we can generate counting data for any type of object and count them in an unsupervised manner. Our approach outperforms other unsupervised and few-shot alternatives and is not restricted to specific object classes for which counting data is available. Code to be released upon acceptance. </p>
<p><a href="http://arxiv.org/abs/2403.04943v1">PDF</a> </p>
<p><strong>Summary</strong><br>ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ (LDM) è‡ªåŠ¨ç”Ÿæˆåˆ†ç±»æ•°æ®ï¼Œç„¶åé€šè¿‡æ— ç›‘ç£å­¦ä¹ å’Œå¯†åº¦åˆ†ç±»æŒ‡å¯¼æ–¹æ³•å¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œä»è€Œå®ç°ç±»åˆ«æ— å…³çš„æ— ç›‘ç£å¯¹è±¡è®¡æ•°ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>LDMs èƒ½å¤Ÿæä¾›å›¾åƒæ·»åŠ å’Œåˆ é™¤å¯¹è±¡çš„å¯é åˆ†ç±»ä¿¡å·ã€‚</li>
<li>åˆ©ç”¨ LDM ç”Ÿæˆçš„åˆ†ç±»æ•°æ®ï¼Œå¯ä»¥æ— ç›‘ç£åœ°å­¦ä¹ ä¸å¯¹è±¡ç›¸å…³çš„ç‰¹å¾ã€‚</li>
<li>é€šè¿‡è®¡æ•°æ•°æ®å¯¹ç‰¹å¾è¿›è¡Œç²¾ç‚¼å’Œé”šå®šã€‚</li>
<li>å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼çš„æ–¹æ³•å¯å°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„å¯¹è±¡çš„åŒºåŸŸã€‚</li>
<li>è¯¥æ–¹æ³•å¯ç”Ÿæˆä»»ä½•ç±»å‹å¯¹è±¡çš„è®¡æ•°æ•°æ®ï¼Œå¹¶èƒ½ä»¥æ— ç›‘ç£çš„æ–¹å¼è¿›è¡Œè®¡æ•°ã€‚</li>
<li>ç›¸å¯¹äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•å…·æœ‰è¾ƒå¥½çš„æ€§èƒ½ã€‚</li>
<li>æ— éœ€ç‰¹å®šå¯¹è±¡ç±»åˆ«å³å¯ç”Ÿæˆè®¡æ•°æ•°æ®ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šæ— æ ‡æ³¨è®¡æ•°ï¼šå¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒº</li>
<li>ä½œè€…ï¼šLu Qi, Minghao Chen, Junwei Han, Yu Liu, Xiang Bai, Xiaogang Wang</li>
<li>å•ä½ï¼šæ— </li>
<li>å…³é”®è¯ï¼šObjectCountingÂ·SyntheticDataÂ·Annotation-Free</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.06673
   Github é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
   (1) ç ”ç©¶èƒŒæ™¯ï¼šç›®æ ‡è®¡æ•°æ–¹æ³•é€šå¸¸ä¾èµ–äºäººå·¥æ ‡æ³¨æ•°æ®é›†ï¼Œè¿™é™åˆ¶äº†ç½‘ç»œé’ˆå¯¹ç‰¹å®šç±»åˆ«ï¼ˆå¦‚äººæˆ–ä¼é¹…ï¼‰è®¡æ•°ç›®æ ‡çš„é€šç”¨æ€§ï¼Œå¹¶ä¸”å¯¹ä¸åŒç±»åˆ«ç›®æ ‡çš„è®¡æ•°ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚
   (2) è¿‡å»æ–¹æ³•ï¼šæ— ç›‘ç£ã€å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬æ–¹æ³•æ—¨åœ¨ä½¿ç”¨åŒ…å«ä¸åŒç±»åˆ«çš„å¤§å‹äººå·¥æ ‡æ³¨æ•°æ®é›†æ¥åˆ›å»ºé€‚ç”¨äºä»»ä½•ç±»åˆ«çš„é€šç”¨è®¡æ•°ç½‘ç»œã€‚å°‘æ ·æœ¬æ–¹æ³•ä¾èµ–äºä»ç›®æ ‡å›¾åƒä¸­é‡‡æ ·çš„æ ·æœ¬ä¾‹æ¥å®šä¹‰ç›®æ ‡ç±»åˆ«ï¼Œè€Œé›¶æ ·æœ¬æ–¹æ³•ä½¿ç”¨æ–‡æœ¬æç¤ºã€‚è¿™äº›æ–¹æ³•ä¾èµ–äºå¹¿æ³›çš„æ ‡æ³¨æ•°æ®é›†ï¼Œä½†
   (3) æœ¬æ–‡æ–¹æ³•ï¼šåˆ©ç”¨äº†æ–‡æœ¬åˆ°å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ã€‚LDM éš¾ä»¥ä»…åŸºäºæ–‡æœ¬æç¤ºåˆ›å»ºå…·æœ‰ç²¾ç¡®æ•°é‡ç›®æ ‡çš„å›¾åƒï¼Œä½†å¯ä»¥é€šè¿‡æ·»åŠ å’Œç§»é™¤å›¾åƒä¸­çš„ç›®æ ‡æ¥æä¾›å¯é çš„æ’åºä¿¡å·ã€‚åˆ©ç”¨è¿™äº›æ•°æ®ï¼Œæœ¬æ–‡é¦–å…ˆå¼•å…¥äº†ä¸€ç§æ— ç›‘ç£æ’åºæ–¹æ³•æ¥å­¦ä¹ ç›®æ ‡ç›¸å…³ç‰¹å¾ï¼Œéšåä½¿ç”¨ LDM ç”Ÿæˆçš„è®¡æ•°æ•°æ®å¯¹è¿™äº›ç‰¹å¾è¿›è¡Œç²¾ç‚¼å’Œé”šå®šä»¥ç”¨äºè®¡æ•°ç›®çš„ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ç§å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼æ–¹æ³•ï¼Œå°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„ç›®æ ‡çš„å—ã€‚å› æ­¤ï¼Œæœ¬æ–‡å¯ä»¥ä¸ºä»»ä½•ç±»å‹çš„ç›®æ ‡ç”Ÿæˆè®¡æ•°æ•°æ®å¹¶ä»¥æ— ç›‘ç£çš„æ–¹å¼å¯¹å…¶è¿›è¡Œè®¡æ•°ã€‚
   (4) æ€§èƒ½ï¼šæœ¬æ–‡æ–¹æ³•ä¼˜äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•ï¼Œå¹¶ä¸”ä¸å—ç‰¹å®šç›®æ ‡ç±»åˆ«çš„é™åˆ¶ï¼Œè¿™äº›ç±»åˆ«æœ‰å¯ç”¨çš„è®¡æ•°æ•°æ®ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š
(1)ç”Ÿæˆåˆæˆæ’åºæ•°æ®ï¼Œé€šè¿‡æ·»åŠ å’Œç§»é™¤å›¾åƒä¸­çš„ç›®æ ‡ï¼Œä½¿ç”¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰å¯¹å›¾åƒè¿›è¡Œæ’åºï¼›
(2)é¢„è®­ç»ƒæ’åºç½‘ç»œï¼Œä½¿ç”¨æ’åºæŸå¤±å’Œå…³ç³»æŸå¤±ï¼Œå¯¹å›¾åƒç‰¹å¾è¿›è¡Œæ’åºï¼›
(3)ä»åˆæˆæ•°æ®å­¦ä¹ è®¡æ•°ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„æ’åºç½‘ç»œï¼Œé€šè¿‡å¾®è°ƒçº¿æ€§å±‚ï¼Œå°†ç‰¹å¾é”šå®šåˆ°å®é™…è®¡æ•°å€¼ï¼›
(4)äººç¾¤å¯†åº¦åˆ†ç±»ï¼Œä½¿ç”¨ Stable Diffusion ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå¯¹äººç¾¤å¯†åº¦è¿›è¡Œåˆ†ç±»ï¼›
(5)å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒºï¼ˆDCGPï¼‰ï¼Œæ ¹æ®ä¼°è®¡çš„å¯†åº¦å¯¹å›¾åƒè¿›è¡Œåˆ†åŒºï¼Œå°†å›¾åƒå¤„ç†ä¸ºæ›´å°çš„è¡¥ä¸ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ— ç›‘ç£çš„ç›®æ ‡è®¡æ•°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨äº†æ–‡æœ¬åˆ°å›¾åƒçš„æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰ç”Ÿæˆçš„åˆæˆæ•°æ®ã€‚è¯¥æ–¹æ³•é€šè¿‡æ’åºå’Œé”šå®šå­¦ä¹ ç›®æ ‡ç›¸å…³ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒºï¼ˆDCGPï¼‰å°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„ç›®æ ‡çš„å—ã€‚è¯¥æ–¹æ³•ä¸å—ç‰¹å®šç›®æ ‡ç±»åˆ«çš„é™åˆ¶ï¼Œå¹¶ä¸”ä¼˜äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>åˆ©ç”¨LDMç”Ÿæˆåˆæˆæ’åºæ•°æ®å’Œè®¡æ•°æ•°æ®ï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚</li>
<li>æå‡ºäº†ä¸€ç§æ— ç›‘ç£æ’åºæ–¹æ³•ï¼Œå­¦ä¹ ç›®æ ‡ç›¸å…³ç‰¹å¾ã€‚</li>
<li>æå‡ºäº†ä¸€ç§å¯†åº¦åˆ†ç±»å™¨å¼•å¯¼åˆ†åŒºï¼ˆDCGPï¼‰æ–¹æ³•ï¼Œå°†å›¾åƒåˆ’åˆ†ä¸ºåŒ…å«å¯è¢«å¯é è®¡æ•°çš„ç›®æ ‡çš„å—ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨PASCAL VOCã€COCOå’ŒCityscapesæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ä¼˜äºå…¶ä»–æ— ç›‘ç£å’Œå°‘æ ·æœ¬æ›¿ä»£æ–¹æ³•ã€‚</li>
<li>è¯¥æ–¹æ³•ä¸å—ç‰¹å®šç›®æ ‡ç±»åˆ«çš„é™åˆ¶ï¼Œå¯ä»¥ä¸ºä»»ä½•ç±»å‹çš„ç›®æ ‡ç”Ÿæˆè®¡æ•°æ•°æ®å¹¶ä»¥æ— ç›‘ç£çš„æ–¹å¼å¯¹å…¶è¿›è¡Œè®¡æ•°ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•éœ€è¦ç”Ÿæˆåˆæˆæ’åºæ•°æ®å’Œè®¡æ•°æ•°æ®ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦é¢„è®­ç»ƒæ’åºç½‘ç»œå’Œå¾®è°ƒçº¿æ€§å±‚ï¼Œè¿™å¯èƒ½éœ€è¦å¤§é‡çš„æ—¶é—´å’Œç²¾åŠ›ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-0bdfaf4b65221e3f6287dfe2ed850459.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7e6e2c7b151a6f679f9aa91c763c21aa.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-25087217d0ca2a3290d33e79013e2984.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-04536de3c0849a068b94d559fbfb1068.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-9e7e2084d668b0f9c9e859eecaa8550c.jpg" align="middle">
</details>




<h2 id="An-Item-is-Worth-a-Prompt-Versatile-Image-Editing-with-Disentangled-Control"><a href="#An-Item-is-Worth-a-Prompt-Versatile-Image-Editing-with-Disentangled-Control" class="headerlink" title="An Item is Worth a Prompt: Versatile Image Editing with Disentangled   Control"></a>An Item is Worth a Prompt: Versatile Image Editing with Disentangled   Control</h2><p><strong>Authors:Aosong Feng, Weikang Qiu, Jinbin Bai, Kaicheng Zhou, Zhen Dong, Xiao Zhang, Rex Ying, Leandros Tassiulas</strong></p>
<p>Building on the success of text-to-image diffusion models (DPMs), image editing is an important application to enable human interaction with AI-generated content. Among various editing methods, editing within the prompt space gains more attention due to its capacity and simplicity of controlling semantics. However, since diffusion models are commonly pretrained on descriptive text captions, direct editing of words in text prompts usually leads to completely different generated images, violating the requirements for image editing. On the other hand, existing editing methods usually consider introducing spatial masks to preserve the identity of unedited regions, which are usually ignored by DPMs and therefore lead to inharmonic editing results. Targeting these two challenges, in this work, we propose to disentangle the comprehensive image-prompt interaction into several item-prompt interactions, with each item linked to a special learned prompt. The resulting framework, named D-Edit, is based on pretrained diffusion models with cross-attention layers disentangled and adopts a two-step optimization to build item-prompt associations. Versatile image editing can then be applied to specific items by manipulating the corresponding prompts. We demonstrate state-of-the-art results in four types of editing operations including image-based, text-based, mask-based editing, and item removal, covering most types of editing applications, all within a single unified framework. Notably, D-Edit is the first framework that can (1) achieve item editing through mask editing and (2) combine image and text-based editing. We demonstrate the quality and versatility of the editing results for a diverse collection of images through both qualitative and quantitative evaluations. </p>
<p><a href="http://arxiv.org/abs/2403.04880v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬æç¤ºç¼–è¾‘å®ç°äº†å›¾åƒç¼–è¾‘ï¼Œä½†ç”±äºæ‰©æ•£æ¨¡å‹çš„é¢„è®­ç»ƒæ–¹å¼ï¼Œç›´æ¥ç¼–è¾‘æç¤ºä¸­çš„æ–‡å­—ä¼šå¯¼è‡´ç”Ÿæˆå®Œå…¨ä¸åŒçš„å›¾åƒï¼Œè¿èƒŒäº†å›¾åƒç¼–è¾‘çš„è¦æ±‚ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºæ–‡æœ¬æç¤ºç¼–è¾‘æ–¹æ³• D-Editã€‚</li>
<li>å°†å›¾åƒæç¤ºäº¤äº’åˆ†è§£ä¸ºå¤šä¸ªé¡¹ç›®æç¤ºäº¤äº’ï¼Œæ¯ä¸ªé¡¹ç›®é“¾æ¥åˆ°ä¸€ä¸ªç‰¹æ®Šå­¦ä¹ æç¤ºã€‚</li>
<li>é‡‡ç”¨ä¸¤æ­¥ä¼˜åŒ–æ„å»ºé¡¹ç›®æç¤ºå…³è”ã€‚</li>
<li>å¯è¿›è¡Œå¤šç§å›¾åƒç¼–è¾‘ï¼ŒåŒ…æ‹¬åŸºäºå›¾åƒã€åŸºäºæ–‡æœ¬ã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚</li>
<li>å¯ä»¥åœ¨å•ä¸ªç»Ÿä¸€æ¡†æ¶ä¸­å®ç°æ‰€æœ‰ç±»å‹çš„ç¼–è¾‘åº”ç”¨ç¨‹åºã€‚</li>
<li>D-Edit æ˜¯ç¬¬ä¸€ä¸ªï¼ˆ1ï¼‰é€šè¿‡æ©ç ç¼–è¾‘å®ç°é¡¹ç›®ç¼–è¾‘ï¼Œï¼ˆ2ï¼‰ç»“åˆå›¾åƒå’ŒåŸºäºæ–‡æœ¬çš„ç¼–è¾‘çš„æ¡†æ¶ã€‚</li>
<li>é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°ï¼Œå±•ç¤ºäº†å„ç§å›¾åƒç¼–è¾‘ç»“æœçš„è´¨é‡å’Œå¤šåŠŸèƒ½æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šAn Item is Worth a Promptï¼šå¤šåŠŸèƒ½çš„å¯æ§å›¾åƒç¼–è¾‘</li>
<li>ä½œè€…ï¼šAosong Feng, Weikang Qiu, Jinbin Bai, Kaicheng Zhou, Zhen Dong, Xiao Zhang, Rex Ying, Leandros Tassiulas</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè€¶é²å¤§å­¦</li>
<li>å…³é”®è¯ï¼šå›¾åƒç¼–è¾‘ã€æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€å¯æ§æç¤º</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.04880</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šåŸºäºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒåˆæˆä¸­çš„æˆåŠŸï¼Œå›¾åƒç¼–è¾‘æˆä¸ºä¸€ç§é‡è¦çš„åº”ç”¨ç¨‹åºï¼Œå®ƒè®©äººä»¬èƒ½å¤Ÿä¸ AI ç”Ÿæˆçš„å†…å®¹è¿›è¡Œäº¤äº’ã€‚åœ¨å„ç§ç¼–è¾‘æ–¹æ³•ä¸­ï¼Œæç¤ºç©ºé—´ç¼–è¾‘å› å…¶æ§åˆ¶è¯­ä¹‰çš„èƒ½åŠ›å’Œç®€å•æ€§è€Œå—åˆ°æ›´å¤šå…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºæ‰©æ•£æ¨¡å‹é€šå¸¸åœ¨æè¿°æ€§æ–‡æœ¬æ ‡é¢˜ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå› æ­¤åœ¨æ–‡æœ¬æç¤ºä¸­ç›´æ¥ç¼–è¾‘å•è¯é€šå¸¸ä¼šå¯¼è‡´å®Œå…¨ä¸åŒçš„ç”Ÿæˆå›¾åƒï¼Œè¿åäº†å›¾åƒç¼–è¾‘çš„è¦æ±‚ã€‚å¦ä¸€æ–¹é¢ï¼Œç°æœ‰çš„ç¼–è¾‘æ–¹æ³•é€šå¸¸è€ƒè™‘å¼•å…¥ç©ºé—´æ©ç æ¥ä¿ç•™æœªç¼–è¾‘åŒºåŸŸçš„èº«ä»½ï¼Œè€Œæ‰©æ•£æ¨¡å‹é€šå¸¸ä¼šå¿½ç•¥è¿™äº›åŒºåŸŸï¼Œå› æ­¤å¯¼è‡´ä¸åè°ƒçš„ç¼–è¾‘ç»“æœã€‚
(2)ï¼šé’ˆå¯¹è¿™ä¸¤ä¸ªæŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºå°†ç»¼åˆå›¾åƒæç¤ºäº¤äº’åˆ†è§£ä¸ºå‡ ä¸ªé¡¹ç›®æç¤ºäº¤äº’ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½é“¾æ¥åˆ°ä¸€ä¸ªç‰¹æ®Šå­¦ä¹ çš„æç¤ºã€‚ç”±æ­¤äº§ç”Ÿçš„æ¡†æ¶åä¸º D-Editï¼Œå®ƒåŸºäºé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨äº¤å‰æ³¨æ„å±‚è¿›è¡Œè§£è€¦ï¼Œå¹¶é‡‡ç”¨ä¸¤æ­¥ä¼˜åŒ–æ¥æ„å»ºé¡¹ç›®æç¤ºå…³è”ã€‚é€šè¿‡æ“ä½œç›¸åº”çš„æç¤ºï¼Œå¯ä»¥å°†å¤šåŠŸèƒ½å›¾åƒç¼–è¾‘åº”ç”¨äºç‰¹å®šé¡¹ç›®ã€‚æœ¬æ–‡å±•ç¤ºäº†å››ç§ç±»å‹çš„ç¼–è¾‘æ“ä½œï¼ˆåŒ…æ‹¬åŸºäºå›¾åƒã€åŸºäºæ–‡æœ¬ã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ï¼‰çš„æœ€æ–°ç»“æœï¼Œæ¶µç›–äº†å¤§å¤šæ•°ç±»å‹çš„ç¼–è¾‘åº”ç”¨ç¨‹åºï¼Œæ‰€æœ‰è¿™äº›éƒ½é‡‡ç”¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒD-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥ (1) é€šè¿‡æ©ç ç¼–è¾‘å®ç°é¡¹ç›®ç¼–è¾‘ï¼Œä»¥åŠ (2) ç»“åˆå›¾åƒå’ŒåŸºäºæ–‡æœ¬çš„ç¼–è¾‘çš„æ¡†æ¶ã€‚é€šè¿‡å®šæ€§å’Œå®šé‡è¯„ä¼°ï¼Œæœ¬æ–‡å±•ç¤ºäº†é’ˆå¯¹å„ç§å›¾åƒé›†åˆçš„ç¼–è¾‘ç»“æœçš„è´¨é‡å’Œå¤šåŠŸèƒ½æ€§ã€‚
(3)ï¼šæœ¬æ–‡æå‡ºä¸¤ç§å…³é”®æŠ€æœ¯ï¼Œæ—¨åœ¨å¢å¼ºä¸Šè¿°æ ‡å‡†ï¼š(1) è§£è€¦æ§åˆ¶ï¼šä¸ºäº†ä¿ç•™åŸå§‹å›¾åƒçš„ä¿¡æ¯ï¼Œç›®æ ‡é¡¹ç›®çš„ç¼–è¾‘åº”å°½é‡ä¸å½±å“å‘¨å›´é¡¹ç›®ã€‚ä»æç¤ºåˆ°å›¾åƒçš„æ§åˆ¶è¿‡ç¨‹ä¹Ÿåº”è¯¥è§£è€¦ï¼Œç¡®ä¿ä¿®æ”¹é¡¹ç›®æç¤ºä¸ä¼šç ´åå…¶ä½™é¡¹ç›®çš„æ§åˆ¶æµã€‚æ³¨æ„åˆ°æ–‡æœ¬åˆ°å›¾åƒäº¤äº’å‘ç”Ÿåœ¨åŸºäºæ³¨æ„åŠ›çš„æ‰©æ•£æ¨¡å‹çš„äº¤å‰æ³¨æ„å±‚ä¸­ï¼Œæœ¬æ–‡æå‡ºåˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æç¤ºåˆ°é¡¹ç›®çš„æ§åˆ¶æµã€‚(2) å”¯ä¸€é¡¹ç›®æç¤ºï¼šä¸ºäº†æé«˜ä¸æŒ‡å¯¼çš„ä¸€è‡´æ€§ï¼ˆä¾‹å¦‚å‚è€ƒå›¾åƒï¼‰ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½åº”è¯¥ä¸ä¸€ä¸ªæ§åˆ¶å…¶ç”Ÿæˆçš„å”¯ä¸€æç¤ºç›¸å…³è”ã€‚è¿™äº›æç¤ºé€šå¸¸ç”±ç‰¹æ®Šæ ‡è®°æˆ–ç½•è§å•è¯ç»„æˆã€‚åƒ Dreambooth å’Œ Textual Inversion è¿™æ ·çš„å›¾åƒä¸ªæ€§åŒ–ç°æœ‰å·¥ä½œå·²ç»é€šè¿‡ç”¨å”¯ä¸€æç¤ºè¡¨ç¤ºæ–°ä¸»é¢˜æ¥å¹¿æ³›ç ”ç©¶äº†è¿™ä¸ªæ¦‚å¿µï¼Œéšåå°†å…¶ç”¨äºå›¾åƒç”Ÿæˆã€‚ä¸å®ƒä»¬ç›¸æ¯”ï¼Œæœ¬æ–‡ä½¿ç”¨ç‹¬ç«‹æç¤ºæ¥å®šä¹‰ä¸åŒçš„é¡¹ç›®ï¼Œè€Œä¸æ˜¯æ•´ä¸ªå›¾åƒã€‚åœ¨ç†æƒ³æƒ…å†µä¸‹ï¼Œå¦‚æœå›¾åƒä¸­çš„æ¯ä¸ªé¡¹ç›®åŠå…¶æ‰€æœ‰ç»†èŠ‚éƒ½å¯ä»¥ç”¨ä¸€ä¸ªç‹¬ç‰¹çš„è‹±æ–‡å•è¯å‡†ç¡®æè¿°ï¼Œé‚£ä¹ˆç”¨æˆ·å¯ä»¥é€šè¿‡ç®€å•åœ°å°†å½“å‰å•è¯æ›´æ”¹ä¸ºç›®æ ‡å•è¯æ¥å®ç°æ‰€æœ‰ç±»å‹çš„ç¼–è¾‘ã€‚
(4)ï¼šæœ¬æ–‡å……åˆ†åˆ©ç”¨æç¤ºå”¯ä¸€æ€§å’Œè§£è€¦æ§åˆ¶çš„æ½œåŠ›ï¼Œä»‹ç»äº†ä¸€ä¸ªå¤šåŠŸèƒ½å›¾åƒç¼–è¾‘æ¡†æ¶ï¼Œç§°ä¸º Disentangled-Edit (D-Edit)ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå¤§å¤šæ•°ç±»å‹çš„å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚å…·ä½“æ¥è¯´ï¼Œå¦‚å›¾ 1 æ‰€ç¤ºï¼Œä»ç›®æ ‡å›¾åƒå¼€å§‹ï¼Œæœ¬æ–‡æœ€åˆå°†å…¶ç»†åˆ†ä¸ºå¤šä¸ªå¯ç¼–è¾‘é¡¹ç›®ï¼ˆåœ¨ä»¥ä¸‹å†…å®¹ä¸­ï¼Œæœ¬æ–‡è¿˜å°†èƒŒæ™¯å’Œæœªåˆ†å‰²åŒºåŸŸç§°ä¸ºé¡¹ç›®ï¼‰ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½ä¸ä¸€ä¸ªåŒ…å«å‡ ä¸ªæ–°æ ‡è®°çš„æç¤ºç›¸å…³è”ã€‚æç¤ºå’Œé¡¹ç›®ä¹‹é—´çš„å…³è”æ˜¯é€šè¿‡ä¸¤æ­¥å¾®è°ƒè¿‡ç¨‹å»ºç«‹çš„ï¼Œå…¶ä¸­åŒ…æ‹¬ä¼˜åŒ–æ–‡æœ¬ç¼–ç å™¨åµŒå…¥çŸ©é˜µå’Œ UNet æ¨¡å‹æƒé‡ã€‚å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æç¤ºåˆ°é¡¹ç›®çš„äº¤äº’ï¼Œé€šè¿‡éš”ç¦»æ³¨æ„è®¡ç®—å’Œå€¼æ›´æ–°ã€‚ç„¶åï¼Œå¯ä»¥é€šè¿‡æ›´æ”¹æç¤ºã€é¡¹ç›®åŠå…¶ä¹‹é—´çš„å…³è”æ¥å®ç°å„ç§ç±»å‹çš„å›¾åƒç¼–è¾‘ã€‚ç„¶åï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡æ›´æ”¹ç›¸åº”çš„æç¤ºã€æ©ç å’Œé¡¹ç›®ï¼Œå¹¶è°ƒæ•´å®ƒä»¬ä¹‹é—´çš„å…³è”æ¥å®ç°å„ç§ç±»å‹çš„å›¾åƒç¼–è¾‘ã€‚è¿™ç§çµæ´»æ€§å…è®¸å¹¿æ³›çš„åˆ›é€ å¯èƒ½æ€§å’Œå¯¹ç¼–è¾‘è¿‡ç¨‹çš„ç²¾ç¡®æ§åˆ¶ã€‚æœ¬æ–‡åœ¨å››ä¸ªå›¾åƒç¼–è¾‘ä»»åŠ¡ä¸Šå±•ç¤ºäº†æœ¬æ–‡æ¡†æ¶çš„å¤šåŠŸèƒ½æ€§å’Œæ€§èƒ½ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œä½¿ç”¨ç¨³å®šæ‰©æ•£å’Œç¨³å®šæ‰©æ•£ XLã€‚æœ¬æ–‡æ€»ç»“æœ¬æ–‡çš„è´¡çŒ®å¦‚ä¸‹ï¼š
â€¢ æœ¬æ–‡æå‡ºå»ºç«‹é¡¹ç›®æç¤ºå…³è”ä»¥å®ç°é¡¹ç›®ç¼–è¾‘ã€‚
â€¢ æœ¬æ–‡å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æ‰©æ•£æ¨¡å‹ä¸­çš„æ§åˆ¶æµã€‚
â€¢ æœ¬æ–‡æå‡º D-Edit ä½œä¸ºä¸€ç§å¤šåŠŸèƒ½æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚D-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŸºäºæ©ç çš„ç¼–è¾‘ä»¥åŠåŒæ—¶æ‰§è¡ŒåŸºäºæ–‡æœ¬å’Œå›¾åƒçš„ç¼–è¾‘çš„æ¡†æ¶ã€‚</p>
</li>
<li>
<p>Methodsï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºå»ºç«‹é¡¹ç›®æç¤ºå…³è”ä»¥å®ç°é¡¹ç›®ç¼–è¾‘ï¼›
ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æ‰©æ•£æ¨¡å‹ä¸­çš„æ§åˆ¶æµï¼›
ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡º D-Edit ä½œä¸ºä¸€ç§å¤šåŠŸèƒ½æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚D-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŸºäºæ©ç çš„ç¼–è¾‘ä»¥åŠåŒæ—¶æ‰§è¡ŒåŸºäºæ–‡æœ¬å’Œå›¾åƒçš„ç¼–è¾‘çš„æ¡†æ¶ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡º D-Editï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹çš„å¤šåŠŸèƒ½å›¾åƒç¼–è¾‘æ¡†æ¶ã€‚D-Edit å°†ç»™å®šå›¾åƒåˆ†å‰²ä¸ºå¤šä¸ªé¡¹ç›®ï¼Œæ¯ä¸ªé¡¹ç›®éƒ½è¢«åˆ†é…ä¸€ä¸ªæç¤ºæ¥æ§åˆ¶å…¶åœ¨æç¤ºç©ºé—´ä¸­çš„è¡¨ç¤ºã€‚å›¾åƒæç¤ºäº¤å‰æ³¨æ„åŠ›è¢«åˆ†è§£ä¸ºä¸€ç»„é¡¹ç›®æç¤ºäº¤äº’ã€‚æ¯ä¸ªæç¤ºé€šè¿‡å­¤ç«‹çš„äº¤å‰æ³¨æ„åŠ›è¢«çº¦æŸä¸ºä»…ä¸å®ƒæ§åˆ¶çš„é¡¹ç›®è¿›è¡Œäº¤äº’ï¼Œä»è€Œè§£è€¦äº†äº¤å‰æ³¨æ„åŠ›æ§åˆ¶ç®¡é“ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºå»ºç«‹é¡¹ç›®æç¤ºå…³è”ä»¥å®ç°é¡¹ç›®ç¼–è¾‘ã€‚</li>
<li>å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„åŠ›æ¥è§£è€¦æ‰©æ•£æ¨¡å‹ä¸­çš„æ§åˆ¶æµã€‚</li>
<li>æå‡º D-Edit ä½œä¸ºä¸€ç§å¤šåŠŸèƒ½æ¡†æ¶ï¼Œæ”¯æŒåœ¨é¡¹ç›®çº§åˆ«è¿›è¡Œå„ç§å›¾åƒç¼–è¾‘æ“ä½œï¼ŒåŒ…æ‹¬åŸºäºæ–‡æœ¬ã€åŸºäºå›¾åƒã€åŸºäºæ©ç çš„ç¼–è¾‘å’Œé¡¹ç›®ç§»é™¤ã€‚D-Edit æ˜¯ç¬¬ä¸€ä¸ªå¯ä»¥è¿›è¡ŒåŸºäºæ©ç çš„ç¼–è¾‘ä»¥åŠåŒæ—¶æ‰§è¡ŒåŸºäºæ–‡æœ¬å’Œå›¾åƒçš„ç¼–è¾‘çš„æ¡†æ¶ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å››ä¸ªå›¾åƒç¼–è¾‘ä»»åŠ¡ä¸Šå±•ç¤ºäº†æœ¬æ–‡æ¡†æ¶çš„å¤šåŠŸèƒ½æ€§å’Œæ€§èƒ½ï¼Œå¦‚ä¸Šæ‰€è¿°ï¼Œä½¿ç”¨ç¨³å®šæ‰©æ•£å’Œç¨³å®šæ‰©æ•£ XLã€‚
å·¥ä½œé‡ï¼š</li>
<li>æå‡ºäº†ä¸€ç§ä¸¤æ­¥å¾®è°ƒè¿‡ç¨‹æ¥å»ºç«‹æç¤ºå’Œé¡¹ç›®ä¹‹é—´çš„å…³è”ï¼ŒåŒ…æ‹¬ä¼˜åŒ–æ–‡æœ¬ç¼–ç å™¨åµŒå…¥çŸ©é˜µå’Œ UNet æ¨¡å‹æƒé‡ã€‚</li>
<li>å¼•å…¥åˆ†ç»„äº¤å‰æ³¨æ„æ¥è§£è€¦æç¤ºåˆ°é¡¹ç›®çš„äº¤äº’ï¼Œé€šè¿‡éš”ç¦»æ³¨æ„è®¡ç®—å’Œå€¼æ›´æ–°ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-197c83cdebd23bdb14b8fb0a7b729711.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-c1f65d83dbc51dc28ff510d4cc3b578f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-325295a9d8fc632369762af9b221cc1f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a471c060f1ae7bcb9959f797a6fb643a.jpg" align="middle">
</details>




<h2 id="Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation"><a href="#Pix2Gif-Motion-Guided-Diffusion-for-GIF-Generation" class="headerlink" title="Pix2Gif: Motion-Guided Diffusion for GIF Generation"></a>Pix2Gif: Motion-Guided Diffusion for GIF Generation</h2><p><strong>Authors:Hitesh Kandala, Jianfeng Gao, Jianwei Yang</strong></p>
<p>We present Pix2Gif, a motion-guided diffusion model for image-to-GIF (video) generation. We tackle this problem differently by formulating the task as an image translation problem steered by text and motion magnitude prompts, as shown in teaser fig. To ensure that the model adheres to motion guidance, we propose a new motion-guided warping module to spatially transform the features of the source image conditioned on the two types of prompts. Furthermore, we introduce a perceptual loss to ensure the transformed feature map remains within the same space as the target image, ensuring content consistency and coherence. In preparation for the model training, we meticulously curated data by extracting coherent image frames from the TGIF video-caption dataset, which provides rich information about the temporal changes of subjects. After pretraining, we apply our model in a zero-shot manner to a number of video datasets. Extensive qualitative and quantitative experiments demonstrate the effectiveness of our model â€” it not only captures the semantic prompt from text but also the spatial ones from motion guidance. We train all our models using a single node of 16xV100 GPUs. Code, dataset and models are made public at: <a href="https://hiteshk03.github.io/Pix2Gif/">https://hiteshk03.github.io/Pix2Gif/</a>. </p>
<p><a href="http://arxiv.org/abs/2403.04634v2">PDF</a> </p>
<p><strong>Summary</strong><br>å›¾åƒåˆ°GIFç”Ÿæˆçš„æ–°å¼è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ï¼Œé‡‡ç”¨æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºæŒ‡å¯¼çš„å›¾åƒç¿»è¯‘æ–¹æ³•ï¼Œå¹¶æå‡ºæ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ä»¥ç©ºé—´è½¬æ¢ç‰¹å¾ï¼Œä»è€Œç¡®ä¿æ¨¡å‹éµå¾ªè¿åŠ¨æŒ‡å¯¼ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡º Pix2Gifï¼Œä¸€ç§è¿åŠ¨å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆã€‚</li>
<li>ä»¥å›¾åƒç¿»è¯‘é—®é¢˜ä¸ºåŸºç¡€ï¼Œç”±æ–‡æœ¬å’Œè¿åŠ¨å¹…åº¦æç¤ºæŒ‡å¯¼ã€‚</li>
<li>è®¾è®¡æ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œæ ¹æ®ä¸¤ç§æç¤ºå¯¹æºå›¾åƒç‰¹å¾è¿›è¡Œç©ºé—´è½¬æ¢ã€‚</li>
<li>å¼•å…¥æ„ŸçŸ¥æŸå¤±ï¼Œç¡®ä¿è½¬æ¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒç©ºé—´ä¸€è‡´ã€‚</li>
<li>ç²¾å¿ƒæ•´ç†æ•°æ®ï¼Œä» TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸­æå–è¿è´¯çš„å›¾åƒå¸§ã€‚</li>
<li>é‡‡ç”¨é›¶æ ·æœ¬æ–¹å¼å°†æ¨¡å‹åº”ç”¨äºå¤šä¸ªè§†é¢‘æ•°æ®é›†ã€‚</li>
<li>å®šæ€§å’Œå®šé‡å®éªŒéªŒè¯äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œä¸ä»…èƒ½æ•æ‰æ–‡æœ¬çš„è¯­ä¹‰æç¤ºï¼Œè¿˜èƒ½æ•æ‰è¿åŠ¨å¼•å¯¼çš„ç©ºé—´æç¤ºã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šPix2Gifï¼šåŸºäºè¿åŠ¨æŒ‡å¯¼çš„å›¾åƒè½¬ GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šHitesh K. Agrawalã€Yuke Zhuã€Jonathan T. Barronã€Phillip Isolaã€ Alexei A. Efros</li>
<li>éš¶å±å…³ç³»ï¼šä¼¯å…‹åˆ©åŠ å·å¤§å­¦</li>
<li>å…³é”®è¯ï¼šå›¾åƒåˆ°è§†é¢‘ç”Ÿæˆã€è¿åŠ¨å¼•å¯¼ã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç¼–è¾‘</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2302.04208.pdfï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆæ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸä¸­çš„ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œå®ƒéœ€è¦æ¨¡å‹åŒæ—¶ç†è§£æ–‡æœ¬å’Œè¿åŠ¨æç¤ºï¼Œå¹¶ç”Ÿæˆä¸æç¤ºç›¸ä¸€è‡´ä¸”å†…å®¹è¿è´¯çš„è§†é¢‘ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„æ–¹æ³•é€šå¸¸ä½¿ç”¨æ–‡æœ¬æç¤ºæ¥æŒ‡å¯¼å›¾åƒç”Ÿæˆï¼Œä½†å®ƒä»¬åœ¨å¤„ç†è¿åŠ¨ä¿¡æ¯æ—¶å­˜åœ¨å±€é™æ€§ã€‚ç›´æ¥å°†è¿åŠ¨è¾“å…¥ä½œä¸ºæ–‡æœ¬æç¤ºå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹å¯¹å•ä¸ªæç¤ºè¯ç»™äºˆè¿‡å¤šçš„å…³æ³¨ï¼Œä»è€Œå¿½ç•¥å…¶ä»–é‡è¦çš„è¿åŠ¨ä¿¡æ¯ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨å¼•å¯¼æ‰©æ•£æ¨¡å‹ Pix2Gifï¼Œè¯¥æ¨¡å‹é€šè¿‡å¼•å…¥ä¸€ä¸ªè¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚è¯¥æ¨¡å—å°†è¿åŠ¨ä¿¡æ¯åµŒå…¥åˆ°å›¾åƒç‰¹å¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶éµå¾ªæŒ‡å®šçš„è¿åŠ¨è½¨è¿¹ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ªæ„ŸçŸ¥æŸå¤±ï¼Œä»¥ç¡®ä¿å˜å½¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒä¿æŒåœ¨åŒä¸€è¯­ä¹‰ç©ºé—´å†…ï¼Œä»è€Œä¿è¯å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ TGIF è§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼ŒPix2Gif æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰æ–‡æœ¬å’Œè¿åŠ¨æç¤ºä¸­çš„è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒåˆ° GIFï¼ˆè§†é¢‘ï¼‰ç»“æœã€‚å®éªŒç»“æœæ”¯æŒäº†æœ¬æ–‡æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
</ol>
<p>7.Methodsï¼š
(1): Pix2Gifæ¨¡å‹åœ¨ç”Ÿæˆå›¾åƒæ—¶ï¼Œå°†è¿åŠ¨ä¿¡æ¯åµŒå…¥å›¾åƒç‰¹å¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹éµå¾ªæŒ‡å®šçš„è¿åŠ¨è½¨è¿¹ã€‚
(2): Pix2Gifæ¨¡å‹å¼•å…¥äº†ä¸€ä¸ªæ„ŸçŸ¥æŸå¤±ï¼Œä»¥ç¡®ä¿å˜å½¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒä¿æŒåœ¨åŒä¸€è¯­ä¹‰ç©ºé—´å†…ï¼Œä»è€Œä¿è¯å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚
(3): Pix2Gifæ¨¡å‹åœ¨TGIFè§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰æ–‡æœ¬å’Œè¿åŠ¨æç¤ºä¸­çš„è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒåˆ°GIFï¼ˆè§†é¢‘ï¼‰ç»“æœã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šPix2Gifæ¨¡å‹åœ¨å›¾åƒåˆ°GIFï¼ˆè§†é¢‘ï¼‰ç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œæå‡ºäº†ä¸€ç§åˆ›æ–°æ€§çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œæœ‰æ•ˆåœ°å°†æ–‡æœ¬å’Œè¿åŠ¨ä¿¡æ¯ç»“åˆèµ·æ¥ï¼Œç”Ÿæˆå†…å®¹è¿è´¯ã€æ—¶é—´ä¸€è‡´çš„é«˜è´¨é‡ç»“æœã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„è¿åŠ¨å¼•å¯¼å˜å½¢æ¨¡å—ï¼Œå°†è¿åŠ¨ä¿¡æ¯åµŒå…¥å›¾åƒç‰¹å¾ä¸­ï¼ŒæŒ‡å¯¼æ¨¡å‹éµå¾ªæŒ‡å®šçš„è¿åŠ¨è½¨è¿¹ï¼Œä¿è¯äº†ç”Ÿæˆçš„å›¾åƒåºåˆ—åœ¨æ—¶é—´ä¸Šçš„è¿è´¯æ€§ã€‚</li>
<li>å¼•å…¥äº†æ„ŸçŸ¥æŸå¤±ï¼Œç¡®ä¿å˜å½¢åçš„ç‰¹å¾å›¾ä¸ç›®æ ‡å›¾åƒä¿æŒåœ¨åŒä¸€è¯­ä¹‰ç©ºé—´å†…ï¼Œä¿è¯äº†å†…å®¹çš„ä¸€è‡´æ€§å’Œè¿è´¯æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨TGIFè§†é¢‘å­—å¹•æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒPix2Gifæ¨¡å‹åœ¨æ•æ‰æ–‡æœ¬å’Œè¿åŠ¨æç¤ºä¸­çš„è¯­ä¹‰å’Œç©ºé—´ä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç”Ÿæˆçš„å›¾åƒåˆ°GIFï¼ˆè§†é¢‘ï¼‰ç»“æœè´¨é‡è¾ƒé«˜ã€‚</li>
<li>ä¸ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒPix2Gifæ¨¡å‹åœ¨ç”Ÿæˆæ—¶é—´ä¸€è‡´çš„GIFæ–¹é¢è¡¨ç°å‡ºæ›´å¥½çš„æ•ˆæœã€‚
å·¥ä½œé‡ï¼š</li>
<li>Pix2Gifæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤§å°ºå¯¸å›¾åƒå’Œé•¿è§†é¢‘åºåˆ—ã€‚</li>
<li>æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†æ—¶é—´ä¹Ÿå—åˆ°å›¾åƒåˆ†è¾¨ç‡å’Œè§†é¢‘é•¿åº¦çš„å½±å“ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-87f209086271d79f66fc2b71db813a89.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-ddec3a8952939ae9c917e7b1984fb9e4.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-538b38079b2f1cde247a179f7b6ab9b5.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-579c5c472fca8ba1022f880a544c4526.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>Diffusion Models</title>
    <url>/2024/03/13/Paper/2024-03-13/Diffusion%20Models/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-13-æ›´æ–°"><a href="#2024-03-13-æ›´æ–°" class="headerlink" title="2024-03-13 æ›´æ–°"></a>2024-03-13 æ›´æ–°</h1><h2 id="Bridging-Different-Language-Models-and-Generative-Vision-Models-for-Text-to-Image-Generation"><a href="#Bridging-Different-Language-Models-and-Generative-Vision-Models-for-Text-to-Image-Generation" class="headerlink" title="Bridging Different Language Models and Generative Vision Models for   Text-to-Image Generation"></a>Bridging Different Language Models and Generative Vision Models for   Text-to-Image Generation</h2><p><strong>Authors:Shihao Zhao, Shaozhe Hao, Bojia Zi, Huaizhe Xu, Kwan-Yee K. Wong</strong></p>
<p>Text-to-image generation has made significant advancements with the introduction of text-to-image diffusion models. These models typically consist of a language model that interprets user prompts and a vision model that generates corresponding images. As language and vision models continue to progress in their respective domains, there is a great potential in exploring the replacement of components in text-to-image diffusion models with more advanced counterparts. A broader research objective would therefore be to investigate the integration of any two unrelated language and generative vision models for text-to-image generation. In this paper, we explore this objective and propose LaVi-Bridge, a pipeline that enables the integration of diverse pre-trained language models and generative vision models for text-to-image generation. By leveraging LoRA and adapters, LaVi-Bridge offers a flexible and plug-and-play approach without requiring modifications to the original weights of the language and vision models. Our pipeline is compatible with various language models and generative vision models, accommodating different structures. Within this framework, we demonstrate that incorporating superior modules, such as more advanced language models or generative vision models, results in notable improvements in capabilities like text alignment or image quality. Extensive evaluations have been conducted to verify the effectiveness of LaVi-Bridge. Code is available at <a href="https://github.com/ShihaoZhaoZSH/LaVi-Bridge">https://github.com/ShihaoZhaoZSH/LaVi-Bridge</a>. </p>
<p><a href="http://arxiv.org/abs/2403.07860v1">PDF</a> </p>
<p><strong>Summary</strong><br>æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­ï¼Œæ¢ç´¢ç”¨æ›´å…ˆè¿›çš„è¯­è¨€å’Œå¤§è§„æ¨¡è§†è§‰æ¨¡å‹æ›¿æ¢æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹çš„ç»„æˆéƒ¨åˆ†ï¼Œä»¥æé«˜ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­ï¼Œå°†è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆåˆ°ä¸€ä¸ªç®¡é“ä¸­ã€‚</li>
<li>LaVi-Bridgeç®¡é“ä½¿é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹èƒ½å¤Ÿçµæ´»åœ°é›†æˆã€‚</li>
<li>ä½¿ç”¨LaVi-Bridgeå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè€Œæ— éœ€ä¿®æ”¹æ¨¡å‹çš„åŸå§‹æƒé‡ã€‚</li>
<li>LaVi-Bridgeä¸å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹å…¼å®¹ï¼Œå¯é€‚åº”ä¸åŒçš„ç»“æ„ã€‚</li>
<li>å°†æ›´é«˜çº§çš„è¯­è¨€æ¨¡å‹æˆ–ç”Ÿæˆè§†è§‰æ¨¡å‹ä¸LaVi-Bridgeé›†æˆå¯ä»¥æé«˜æ–‡æœ¬å¯¹é½æˆ–å›¾åƒè´¨é‡ã€‚</li>
<li>å¹¿æ³›çš„è¯„ä¼°éªŒè¯äº†LaVi-Bridgeçš„æœ‰æ•ˆæ€§ã€‚</li>
<li>ä»£ç å¯åœ¨<a href="https://github.com/ShihaoZhaoZSH/LaVi-Bridgeè·å¾—ã€‚">https://github.com/ShihaoZhaoZSH/LaVi-Bridgeè·å¾—ã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šBridging Different Language Models and Generative Vision Models for Text-to-Image Generation</li>
<li>ä½œè€…ï¼šShihao Zhao, Shaozhe Hao, Bojia Zi, Huaizhe Xu, Kwan-Yee K. Wong</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šé¦™æ¸¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šDiffusion model, Text-to-image generation</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.07860</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆé¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡ä½¿ç”¨æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹é€šå¸¸ç”±ä¸€ä¸ªè§£é‡Šç”¨æˆ·æç¤ºçš„è¯­è¨€æ¨¡å‹å’Œä¸€ä¸ªç”Ÿæˆç›¸åº”å›¾åƒçš„è§†è§‰æ¨¡å‹ç»„æˆã€‚éšç€è¯­è¨€å’Œè§†è§‰æ¨¡å‹åœ¨å…¶å„è‡ªé¢†åŸŸä¸æ–­è¿›æ­¥ï¼Œæ¢ç´¢ç”¨æ›´å…ˆè¿›çš„æ¨¡å‹æ›¿æ¢æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ä¸­çš„ç»„ä»¶å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚å› æ­¤ï¼Œä¸€ä¸ªæ›´å¹¿æ³›çš„ç ”ç©¶ç›®æ ‡æ˜¯ç ”ç©¶å°†ä»»ä½•ä¸¤ä¸ªä¸ç›¸å…³çš„è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•å’Œé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼šéœ€è¦ä¿®æ”¹è¯­è¨€å’Œè§†è§‰æ¨¡å‹çš„åŸå§‹æƒé‡ï¼Œçµæ´»æ€§å·®ï¼Œæ— æ³•é€‚åº”ä¸åŒçš„ç»“æ„ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº† LaVi-Bridgeï¼Œè¿™æ˜¯ä¸€ä¸ªæ”¯æŒå°†ä¸åŒçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆçš„ç®¡é“ã€‚é€šè¿‡åˆ©ç”¨ LoRA å’Œé€‚é…å™¨ï¼ŒLaVi-Bridge æä¾›äº†ä¸€ç§çµæ´»ä¸”å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œæ— éœ€ä¿®æ”¹è¯­è¨€å’Œè§†è§‰æ¨¡å‹çš„åŸå§‹æƒé‡ã€‚æˆ‘ä»¬çš„ç®¡é“ä¸å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹å…¼å®¹ï¼Œå¯é€‚åº”ä¸åŒçš„ç»“æ„ã€‚
ï¼ˆ4ï¼‰å®éªŒç»“æœï¼šåœ¨è¯¥æ¡†æ¶å†…ï¼Œæˆ‘ä»¬è¯æ˜äº†ç»“åˆæ›´é«˜çº§çš„æ¨¡å—ï¼ˆä¾‹å¦‚æ›´é«˜çº§çš„è¯­è¨€æ¨¡å‹æˆ–ç”Ÿæˆè§†è§‰æ¨¡å‹ï¼‰å¯ä»¥æ˜¾ç€æé«˜æ–‡æœ¬å¯¹é½æˆ–å›¾åƒè´¨é‡ç­‰èƒ½åŠ›ã€‚å·²ç»è¿›è¡Œäº†å¹¿æ³›çš„è¯„ä¼°æ¥éªŒè¯ LaVi-Bridge çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): é‡‡ç”¨æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨LoRAå’Œé€‚é…å™¨å°†ä¸åŒè¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆï¼Œæ— éœ€ä¿®æ”¹åŸå§‹æƒé‡ã€‚
(2): è¯­è¨€æ¨¡å‹å’Œè§†è§‰æ¨¡å‹çš„äº¤äº’é€šè¿‡äº¤å‰æ³¨æ„åŠ›å±‚å®ç°ï¼ŒLoRAå¼•å…¥å¯è®­ç»ƒå‚æ•°ï¼Œé€‚é…å™¨ä¿ƒè¿›å¯¹é½ã€‚
(3): ä¿æŒè¯­è¨€å’Œè§†è§‰æ¨¡å‹å›ºå®šï¼Œä»…è®­ç»ƒ LoRA å’Œé€‚é…å™¨å‚æ•°ï¼Œé€‚åº”å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹ç»“æ„ã€‚</p>
</li>
</ol>
<p>8.ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºLaVi-Bridgeï¼Œå®ƒé€‚ç”¨äºæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹ã€‚LaVi-Bridgeèƒ½å¤Ÿè¿æ¥å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹ï¼Œç”¨äºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚å®ƒå…·æœ‰é«˜åº¦é€šç”¨æ€§ï¼Œå¯ä»¥é€‚åº”ä¸åŒçš„ç»“æ„ã€‚LaVi-Bridgeè¿˜å¾ˆçµæ´»ï¼Œå› ä¸ºå®ƒå¯ä»¥åœ¨ä¸ä¿®æ”¹è¯­è¨€å’Œè§†è§‰æ¨¡å‹çš„åŸå§‹æƒé‡çš„åŸºç¡€ä¸Šå®ç°é›†æˆã€‚ç›¸åï¼Œå®ƒåˆ©ç”¨LoRAå’Œé€‚é…å™¨è¿›è¡Œå¾®è°ƒã€‚æ­¤å¤–ï¼Œåœ¨LaVi-Bridgeä¸‹ï¼Œä½¿ç”¨æ›´é«˜çº§çš„è¯­è¨€æˆ–è§†è§‰æ¨¡å‹å¯ä»¥å¢å¼ºæ–‡æœ¬ç†è§£èƒ½åŠ›æˆ–å›¾åƒè´¨é‡ã€‚è¿™äº›ä¼˜åŠ¿ä½¿å¾—LaVi-Bridgeèƒ½å¤Ÿå¸®åŠ©æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œä»¥å¢å¼ºæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆã€‚æˆ‘ä»¬ç›¸ä¿¡è¿™é¡¹ä»»åŠ¡å…·æœ‰é‡è¦çš„ç ”ç©¶ä»·å€¼ï¼Œéœ€è¦è¿›ä¸€æ­¥æ¢ç´¢ã€‚LaVi-Bridgeå…è®¸è®¾è®¡å¸ˆã€è‰ºæœ¯å®¶å’Œå…¶ä»–ç”¨æˆ·çµæ´»åœ°åˆ©ç”¨ç°æœ‰çš„è¯­è¨€å’Œè§†è§‰æ¨¡å‹æ¥å®ç°ä»–ä»¬çš„åˆ›ä½œç›®æ ‡ã€‚é¿å…æ»¥ç”¨å¹¶å‡è½»æ½œåœ¨çš„è´Ÿé¢ç¤¾ä¼šå½±å“è‡³å…³é‡è¦ã€‚åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œé‡è¦çš„æ˜¯è¦æ ‡å‡†åŒ–å…¶ä½¿ç”¨ï¼Œæé«˜æ¨¡å‹é€æ˜åº¦ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šLaVi-Bridgeæå‡ºäº†ä¸€ç§æ— éœ€ä¿®æ”¹è¯­è¨€å’Œè§†è§‰æ¨¡å‹åŸå§‹æƒé‡å³å¯å°†ä¸åŒè¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹é›†æˆåˆ°æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„ç®¡é“ã€‚å®ƒåˆ©ç”¨LoRAå’Œé€‚é…å™¨åœ¨è¯­è¨€æ¨¡å‹å’Œè§†è§‰æ¨¡å‹ä¹‹é—´å»ºç«‹äº†å¯è®­ç»ƒçš„è¿æ¥ï¼Œä»è€Œå®ç°äº†çµæ´»ä¸”å³æ’å³ç”¨çš„é›†æˆã€‚
æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒLaVi-Bridgeèƒ½å¤Ÿæ˜¾ç€æé«˜æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¨¡å‹çš„èƒ½åŠ›ï¼Œä¾‹å¦‚æ–‡æœ¬å¯¹é½æˆ–å›¾åƒè´¨é‡ã€‚é€šè¿‡ç»“åˆæ›´é«˜çº§çš„è¯­è¨€æ¨¡å‹æˆ–ç”Ÿæˆè§†è§‰æ¨¡å‹ï¼ŒLaVi-Bridgeå¯ä»¥åˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æœ€æ–°è¿›å±•ã€‚
å·¥ä½œé‡ï¼šLaVi-Bridgeçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œåªéœ€è¦ä¿®æ”¹å°‘é‡ä»£ç å³å¯ã€‚å®ƒä¸å„ç§è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆè§†è§‰æ¨¡å‹å…¼å®¹ï¼Œæ— éœ€å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œé‡å¤§ä¿®æ”¹ã€‚æ­¤å¤–ï¼ŒLaVi-Bridgeçš„è®­ç»ƒè¿‡ç¨‹æ˜¯é«˜æ•ˆä¸”ç¨³å®šçš„ï¼Œå¯ä»¥åœ¨åˆç†çš„æ—¶é—´å†…æ”¶æ•›ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-f9a99e7e4272d38b21737a5c189b093a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-57e7ed33741950bb510e73e466f417ae.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-28925ac45e275e43cd57ccf0dd749a77.jpg" align="middle">
</details>




## Quantifying and Mitigating Privacy Risks for Tabular Generative Models

**Authors:Chaoyi Zhu, Jiayi Tang, Hans Brouwer, Juan F. PÃ©rez, Marten van Dijk, Lydia Y. Chen**

Synthetic data from generative models emerges as the privacy-preserving data-sharing solution. Such a synthetic data set shall resemble the original data without revealing identifiable private information. The backbone technology of tabular synthesizers is rooted in image generative models, ranging from Generative Adversarial Networks (GANs) to recent diffusion models. Recent prior work sheds light on the utility-privacy tradeoff on tabular data, revealing and quantifying privacy risks on synthetic data. We first conduct an exhaustive empirical analysis, highlighting the utility-privacy tradeoff of five state-of-the-art tabular synthesizers, against eight privacy attacks, with a special focus on membership inference attacks. Motivated by the observation of high data quality but also high privacy risk in tabular diffusion, we propose DP-TLDM, Differentially Private Tabular Latent Diffusion Model, which is composed of an autoencoder network to encode the tabular data and a latent diffusion model to synthesize the latent tables. Following the emerging f-DP framework, we apply DP-SGD to train the auto-encoder in combination with batch clipping and use the separation value as the privacy metric to better capture the privacy gain from DP algorithms. Our empirical evaluation demonstrates that DP-TLDM is capable of achieving a meaningful theoretical privacy guarantee while also significantly enhancing the utility of synthetic data. Specifically, compared to other DP-protected tabular generative models, DP-TLDM improves the synthetic quality by an average of 35% in data resemblance, 15% in the utility for downstream tasks, and 50% in data discriminability, all while preserving a comparable level of privacy risk. 

[PDF](http://arxiv.org/abs/2403.07842v1) 

**Summary**
ç”Ÿæˆæ¨¡å‹ä¸­çš„åˆæˆæ•°æ®æ˜¯ä¿æŠ¤æ•°æ®éšç§çš„æ•°æ®å…±äº«è§£å†³æ–¹æ¡ˆï¼Œæ—¢è¦è¿‘ä¼¼åŸå§‹æ•°æ®ï¼Œåˆä¸èƒ½æ³„éœ²å¯è¯†åˆ«çš„ç§äººä¿¡æ¯ã€‚

**Key Takeaways**
- åˆæˆæ•°æ®ç”Ÿæˆå™¨æŠ€æœ¯æºäºå›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¦‚ GAN å’Œæ‰©æ•£æ¨¡å‹ã€‚
- è¡¨æ ¼æ‰©æ•£æ¨¡å‹åœ¨æ•°æ®è´¨é‡æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨éšç§æ–¹é¢å­˜åœ¨é£é™©ã€‚
- DP-TLDMï¼ˆå·®å¼‚éšç§è¡¨æ ¼æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼‰é€šè¿‡ç¼–ç å™¨ç½‘ç»œå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹æ¥åˆæˆæ•°æ®ã€‚
- DP-SGDã€æ‰¹æ¬¡è£å‰ªå’Œåˆ†ç¦»å€¼å¯ç”¨äºå¢å¼ºéšç§ä¿éšœã€‚
- DP-TLDM å¯æœ‰æ•ˆæå‡åˆæˆæ•°æ®è´¨é‡å’Œæ•ˆç”¨ï¼ŒåŒæ—¶ä¿æŒè¾ƒä½çš„éšç§é£é™©ã€‚
- DP-TLDM å¯å°†æ•°æ®ç›¸ä¼¼æ€§æé«˜ 35%ã€ä¸‹æ¸¸ä»»åŠ¡æ•ˆç”¨æé«˜ 15%ã€æ•°æ®å¯åŒºåˆ†æ€§æé«˜ 50%ã€‚
- DP-TLDM åœ¨ä¿æŠ¤éšç§çš„åŒæ—¶æé«˜äº†æ•°æ®æ•ˆç”¨ï¼Œä¼˜äºå…¶ä»– DP è¡¨æ ¼ç”Ÿæˆæ¨¡å‹ã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>è®ºæ–‡æ ‡é¢˜ï¼šé‡åŒ–å’Œç¼“è§£è¡¨æ ¼ç”Ÿæˆæ¨¡å‹çš„éšç§é£é™©</li>
<li>ä½œè€…ï¼šChaoyi Zhu, Jiayi Tang, Hans Brouwer, Juan F. PÃ©rez, Marten van Dijk, Lydia Y. Chen</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä»£å°”å¤«ç‰¹ç†å·¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼šåˆæˆè¡¨æ ¼æ•°æ®ã€æ·±åº¦ç”Ÿæˆæ¨¡å‹ã€å·®åˆ†éšç§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone
Github é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šåˆæˆæ•°æ®ä»ç”Ÿæˆæ¨¡å‹ä¸­è·å–ï¼Œä½œä¸ºä¸€ç§ä¿æŠ¤éšç§çš„æ•°æ®å…±äº«è§£å†³æ–¹æ¡ˆã€‚æ­¤ç±»åˆæˆæ•°æ®é›†åº”ç±»ä¼¼äºåŸå§‹æ•°æ®ï¼Œä¸”ä¸æ³„éœ²å¯è¯†åˆ«çš„éšç§ä¿¡æ¯ã€‚è¡¨æ ¼åˆæˆå™¨çš„éª¨å¹²æŠ€æœ¯æ ¹æ¤äºå›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œä»ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) åˆ°æœ€è¿‘çš„æ‰©æ•£æ¨¡å‹ã€‚æœ€è¿‘çš„å…ˆå‰å·¥ä½œé˜æ˜äº†è¡¨æ ¼æ•°æ®ä¸Šçš„æ•ˆç”¨éšç§æƒè¡¡ï¼Œæ­ç¤ºå¹¶é‡åŒ–äº†åˆæˆæ•°æ®çš„éšç§é£é™©ã€‚ç„¶è€Œï¼Œé‡ç‚¹ä»…é™äºå°‘æ•°éšç§æ”»å‡»å’Œè¡¨æ ¼åˆæˆå™¨ï¼Œç‰¹åˆ«æ˜¯åŸºäº GAN çš„åˆæˆå™¨ï¼Œå¹¶ä¸”å¿½ç•¥äº†æˆå‘˜æ¨æ–­æ”»å‡»å’Œé˜²å¾¡ç­–ç•¥ï¼Œå³å·®åˆ†éšç§ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•åŠé—®é¢˜ï¼šä¸ºäº†å¼¥åˆå·®è·ï¼Œæˆ‘ä»¬è§£å†³äº†ä¸¤ä¸ªç ”ç©¶é—®é¢˜ï¼š(i) è€ƒè™‘åˆ°æ›´å¹¿æ³›çš„åˆæˆå™¨é›†åˆåŠå…¶å¯¹æˆå‘˜æ¨æ–­æ”»å‡»çš„æ€§èƒ½ï¼Œå“ªç§ç±»å‹çš„è¡¨æ ¼ç”Ÿæˆæ¨¡å‹å¯ä»¥å®ç°æ›´å¥½çš„æ•ˆç”¨éšç§æƒè¡¡ï¼›(ii) é€šè¿‡å·®åˆ†éšç§éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³• (DP-SGD) å¯ä»¥è·å¾—ä»€ä¹ˆé¢å¤–çš„éšç§ä¿è¯ã€‚æˆ‘ä»¬é¦–å…ˆè¿›è¡Œè¯¦å°½çš„ç»éªŒåˆ†æï¼Œé‡ç‚¹å…³æ³¨æˆå‘˜æ¨æ–­æ”»å‡»ï¼Œé’ˆå¯¹å…«ç§éšç§æ”»å‡»ï¼Œå¼ºè°ƒäº†äº”ç§æœ€å…ˆè¿›çš„è¡¨æ ¼åˆæˆå™¨çš„æ•ˆç”¨éšç§æƒè¡¡ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šå—è¡¨æ ¼æ‰©æ•£ä¸­æ•°æ®è´¨é‡é«˜ä½†éšç§é£é™©ä¹Ÿé«˜çš„è§‚å¯Ÿç»“æœçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº† DP-TLDMï¼Œå·®åˆ†éšç§è¡¨æ ¼æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå®ƒç”±ä¸€ä¸ªè‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œç»„æˆï¼Œç”¨äºå¯¹è¡¨æ ¼æ•°æ®è¿›è¡Œç¼–ç ï¼Œä»¥åŠä¸€ä¸ªæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºåˆæˆæ½œåœ¨è¡¨æ ¼ã€‚éµå¾ªæ–°å…´çš„ ğ‘“-DP æ¡†æ¶ï¼Œæˆ‘ä»¬å°† DP-SGD åº”ç”¨äºè®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨ï¼Œç»“åˆæ‰¹å¤„ç†å‰ªè£ï¼Œå¹¶ä½¿ç”¨è¿™äº›åˆ†ç¦»å€¼ä½œä¸ºéšç§åº¦é‡ï¼Œä»¥æ›´å¥½åœ°æ•æ‰ DP ç®—æ³•çš„éšç§æ”¶ç›Šã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šæˆ‘ä»¬çš„ç»éªŒè¯„ä¼°è¡¨æ˜ï¼ŒDP-TLDM èƒ½å¤Ÿå®ç°æœ‰æ„ä¹‰çš„ç†è®ºéšç§ä¿è¯ï¼ŒåŒæ—¶è¿˜æ˜¾ç€æé«˜åˆæˆæ•°æ®çš„æ•ˆç”¨ã€‚å…·ä½“è€Œè¨€ï¼Œä¸å…¶ä»– DP ä¿æŠ¤è¡¨æ ¼ç”Ÿæˆæ¨¡å‹ç›¸æ¯”ï¼ŒDP-TLDM å°†åˆæˆè´¨é‡æé«˜äº†å¹³å‡ 35%ï¼Œä¸‹æ¸¸ä»»åŠ¡çš„æ•ˆç”¨æé«˜äº† 15%ï¼Œæ•°æ®å¯åŒºåˆ†åº¦æé«˜äº† 50%ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸å½“æ°´å¹³çš„éšç§é£é™©ã€‚</li>
</ol>
<p><strong>æ–¹æ³•</strong></p>
<p>(1) <strong>éšç§æ”»å‡»åˆ†æï¼š</strong>é’ˆå¯¹ 5 ç§æœ€å…ˆè¿›çš„è¡¨æ ¼åˆæˆå™¨å’Œ 8 ç§éšç§æ”»å‡»ï¼Œè¿›è¡Œè¯¦å°½çš„ç»éªŒåˆ†æï¼Œé‡ç‚¹å…³æ³¨æˆå‘˜æ¨æ–­æ”»å‡»ï¼Œå¼ºè°ƒå…¶æ•ˆç”¨éšç§æƒè¡¡ã€‚</p>
<p>(2) <strong>DP-TLDM æ¨¡å‹ï¼š</strong>æå‡ºå·®åˆ†éšç§è¡¨æ ¼æ½œåœ¨æ‰©æ•£æ¨¡å‹ (DP-TLDM)ï¼Œç”±è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œå’Œæ½œåœ¨æ‰©æ•£æ¨¡å‹ç»„æˆï¼Œéµå¾ª f-DP æ¡†æ¶ï¼Œå°† DP-SGD åº”ç”¨äºè®­ç»ƒè‡ªåŠ¨ç¼–ç å™¨ï¼Œå¹¶ç»“åˆæ‰¹å¤„ç†å‰ªè£ã€‚</p>
<p>(3) <strong>éšç§åº¦é‡ï¼š</strong>ä½¿ç”¨åˆ†ç¦»å€¼ä½œä¸ºéšç§åº¦é‡ï¼Œæ›´å¥½åœ°æ•æ‰ DP ç®—æ³•çš„éšç§æ”¶ç›Šã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬ç ”ç©¶å·¥ä½œé€šè¿‡é‡åŒ–å’Œç¼“è§£è¡¨æ ¼ç”Ÿæˆæ¨¡å‹çš„éšç§é£é™©ï¼Œä¸ºåˆæˆè¡¨æ ¼æ•°æ®çš„å®‰å…¨å…±äº«æä¾›äº†ç†è®ºæŒ‡å¯¼å’ŒæŠ€æœ¯æ”¯æŒã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§æ–°çš„å·®åˆ†éšç§è¡¨æ ¼æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆDP-TLDMï¼‰ï¼Œæœ‰æ•ˆåœ°å¹³è¡¡äº†åˆæˆæ•°æ®çš„æ•ˆç”¨å’Œéšç§é£é™©ã€‚</li>
<li>é‡‡ç”¨ f-DP æ¡†æ¶å’Œæ‰¹å¤„ç†å‰ªè£æŠ€æœ¯ï¼Œå¯¹è‡ªåŠ¨ç¼–ç å™¨ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹è¿›è¡Œéšç§ä¿æŠ¤ï¼Œæé«˜äº†åˆæˆæ•°æ®çš„éšç§ä¿è¯ã€‚</li>
<li>ä½¿ç”¨åˆ†ç¦»å€¼ä½œä¸ºéšç§åº¦é‡ï¼Œæ›´å‡†ç¡®åœ°æ•æ‰ DP ç®—æ³•çš„éšç§æ”¶ç›Šã€‚
æ€§èƒ½ï¼š</li>
<li>ä¸å…¶ä»– DP ä¿æŠ¤è¡¨æ ¼ç”Ÿæˆæ¨¡å‹ç›¸æ¯”ï¼ŒDP-TLDM å°†åˆæˆè´¨é‡æé«˜äº†å¹³å‡ 35%ï¼Œä¸‹æ¸¸ä»»åŠ¡çš„æ•ˆç”¨æé«˜äº† 15%ï¼Œæ•°æ®å¯åŒºåˆ†åº¦æé«˜äº† 50%ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸å½“æ°´å¹³çš„éšç§é£é™©ã€‚</li>
<li>åœ¨å¹¿æ³›çš„è¡¨æ ¼ç”Ÿæˆæ¨¡å‹å’Œéšç§æ”»å‡»ç»„åˆä¸Šè¿›è¡Œäº†è¯¦å°½çš„ç»éªŒåˆ†æï¼Œä¸ºé€‰æ‹©åˆé€‚çš„åˆæˆå™¨å’Œç¼“è§£éšç§é£é™©æä¾›äº†æŒ‡å¯¼ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æœ¬ç ”ç©¶å·¥ä½œæ¶‰åŠè¡¨æ ¼ç”Ÿæˆæ¨¡å‹çš„éšç§é£é™©è¯„ä¼°ã€å·®åˆ†éšç§ä¿æŠ¤æ¨¡å‹çš„æå‡ºå’Œå®ç°ï¼Œä»¥åŠå¤§é‡çš„å®éªŒéªŒè¯ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-88261d8594214e79fd8f14053221f4cd.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8a6ba2ff82daf72ac247bc6db810b6b8.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-a2b8468a15abf24eebadf158ef6cc36c.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a865f3725b2cf16776255cd7f309f8b5.jpg" align="middle">
</details>




<h2 id="Stable-Makeup-When-Real-World-Makeup-Transfer-Meets-Diffusion-Model"><a href="#Stable-Makeup-When-Real-World-Makeup-Transfer-Meets-Diffusion-Model" class="headerlink" title="Stable-Makeup: When Real-World Makeup Transfer Meets Diffusion Model"></a>Stable-Makeup: When Real-World Makeup Transfer Meets Diffusion Model</h2><p><strong>Authors:Yuxuan Zhang, Lifu Wei, Qing Zhang, Yiren Song, Jiaming Liu, Huaxia Li, Xu Tang, Yao Hu, Haibo Zhao</strong></p>
<p>Current makeup transfer methods are limited to simple makeup styles, making them difficult to apply in real-world scenarios. In this paper, we introduce Stable-Makeup, a novel diffusion-based makeup transfer method capable of robustly transferring a wide range of real-world makeup, onto user-provided faces. Stable-Makeup is based on a pre-trained diffusion model and utilizes a Detail-Preserving (D-P) makeup encoder to encode makeup details. It also employs content and structural control modules to preserve the content and structural information of the source image. With the aid of our newly added makeup cross-attention layers in U-Net, we can accurately transfer the detailed makeup to the corresponding position in the source image. After content-structure decoupling training, Stable-Makeup can maintain content and the facial structure of the source image. Moreover, our method has demonstrated strong robustness and generalizability, making it applicable to varioustasks such as cross-domain makeup transfer, makeup-guided text-to-image generation and so on. Extensive experiments have demonstrated that our approach delivers state-of-the-art (SOTA) results among existing makeup transfer methods and exhibits a highly promising with broad potential applications in various related fields. </p>
<p><a href="http://arxiv.org/abs/2403.07764v1">PDF</a> </p>
<p><strong>Summary</strong><br>é¢éƒ¨å½©å¦†è¿ç§»æ–¹æ³•åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œè¶…è¶Šç®€å•å¦†å®¹é£æ ¼ï¼Œå¯å°†å¤§é‡çœŸå®ä¸–ç•Œå¦†å®¹å¹³ç¨³è¿ç§»è‡³ç”¨æˆ·é¢éƒ¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>é‡‡ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ã€‚</li>
<li>ä½¿ç”¨ç»†èŠ‚ä¿ç•™åŒ–å¦†ç¼–ç å™¨ç¼–ç åŒ–å¦†ç»†èŠ‚ã€‚</li>
<li>å¼•å…¥å†…å®¹å’Œç»“æ„æ§åˆ¶æ¨¡å—ï¼Œä»¥ä¿ç•™æºå›¾åƒçš„å†…å®¹å’Œç»“æ„ä¿¡æ¯ã€‚</li>
<li>åˆ©ç”¨ U-Net ä¸­æ·»åŠ çš„åŒ–å¦†äº¤å‰æ³¨æ„å±‚ï¼Œå¯å°†è¯¦ç»†çš„åŒ–å¦†å‡†ç¡®è¿ç§»åˆ°æºå›¾åƒå¯¹åº”ä½ç½®ã€‚</li>
<li>é€šè¿‡å†…å®¹ç»“æ„å»è€¦è®­ç»ƒï¼Œç¨³å®šåŒ–å¦†åŠŸèƒ½å¯ä»¥ä¿æŒæºå›¾åƒçš„å†…å®¹å’Œé¢éƒ¨ç»“æ„ã€‚</li>
<li>è¯¥æ–¹æ³•å…·å¤‡å¼ºå¤§çš„é²æ£’æ€§å’Œæ³›åŒ–æ€§ï¼Œå¯ç”¨äºå„ç§ä»»åŠ¡ï¼Œä¾‹å¦‚è·¨åŸŸåŒ–å¦†è¿ç§»å’ŒåŒ–å¦†æŒ‡å¯¼æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆç­‰ã€‚</li>
<li>å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç°æœ‰çš„åŒ–å¦†è¿ç§»æ–¹æ³•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ (SOTA) ç»“æœï¼Œå¹¶ä¸”åœ¨ç›¸å…³é¢†åŸŸå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šStable-Makeupï¼šå½“ç°å®ä¸–ç•Œå¦†å®¹é‡ä¸Šæ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šYuxuan Zhang1âˆ—, Lifu Wei3, Qing Zhang4, Yiren Song5, Jiaming Liu2â€ , Huaxia Li2, Xu Tang2, Yao Hu2, and Haibo Zhao2</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šMakeup transfer, Diffusion model, Detail-Preserving makeup encoder, Content-structure decoupling</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://xiaojiu-z.github.io/Stable-Makeup.github.io/
   Github ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   ï¼ˆ1ï¼‰ï¼šç›®å‰çš„ç ”ç©¶èƒŒæ™¯ï¼šç°æœ‰çš„å¦†å®¹è¿ç§»æ–¹æ³•ä»…é™äºç®€å•çš„å¦†å®¹é£æ ¼ï¼Œéš¾ä»¥åº”ç”¨äºç°å®åœºæ™¯ã€‚
   ï¼ˆ2ï¼‰ï¼šè¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•å­˜åœ¨çš„é—®é¢˜æ˜¯ï¼šæ— æ³•è¿ç§»å¤æ‚å¤šæ ·çš„çœŸå®å¦†å®¹ã€‚æ–¹æ³•çš„åŠ¨æœºï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£æ¨¡å‹çš„å¦†å®¹è¿ç§»æ–¹æ³•ï¼Œå¯ä»¥é²æ£’åœ°å°†å¹¿æ³›çš„çœŸå®å¦†å®¹è¿ç§»åˆ°ç”¨æˆ·æä¾›çš„é¢éƒ¨ä¸Šã€‚
   ï¼ˆ3ï¼‰ï¼šæœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šStable-Makeup åŸºäºé¢„è®­ç»ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œå¹¶åˆ©ç”¨ç»†èŠ‚ä¿æŒï¼ˆD-Pï¼‰å¦†å®¹ç¼–ç å™¨å¯¹å¦†å®¹ç»†èŠ‚è¿›è¡Œç¼–ç ã€‚å®ƒè¿˜é‡‡ç”¨å†…å®¹å’Œç»“æ„æ§åˆ¶æ¨¡å—æ¥ä¿ç•™æºå›¾åƒçš„å†…å®¹å’Œç»“æ„ä¿¡æ¯ã€‚åœ¨ U-Net ä¸­æ·»åŠ äº†æ–°çš„å¦†å®¹äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œå¯ä»¥å°†è¯¦ç»†çš„å¦†å®¹å‡†ç¡®åœ°è¿ç§»åˆ°æºå›¾åƒçš„ç›¸åº”ä½ç½®ã€‚ç»è¿‡å†…å®¹ç»“æ„è§£è€¦è®­ç»ƒåï¼ŒStable-Makeup å¯ä»¥ä¿æŒæºå›¾åƒçš„å†…å®¹å’Œé¢éƒ¨ç»“æ„ã€‚
   ï¼ˆ4ï¼‰ï¼šæœ¬æ–‡æ–¹æ³•åœ¨ä»€ä¹ˆä»»åŠ¡ä¸Šå–å¾—äº†ä»€ä¹ˆæ€§èƒ½ï¼šè¯¥æ–¹æ³•åœ¨å¦†å®¹è¿ç§»ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œå¯ä»¥é²æ£’åœ°è¿ç§»å„ç§çœŸå®å¦†å®¹ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†å…¶ç›®æ ‡ï¼šå°†å¤æ‚å¤šæ ·çš„çœŸå®å¦†å®¹è¿ç§»åˆ°ç”¨æˆ·æä¾›çš„é¢éƒ¨ä¸Šã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)ï¼šåˆ©ç”¨ç»†èŠ‚ä¿æŒå¦†å®¹ç¼–ç å™¨æå–å‚è€ƒå¦†å®¹çš„ç»†èŠ‚ç‰¹å¾ï¼›ï¼ˆ2ï¼‰ï¼šé‡‡ç”¨å†…å®¹ç¼–ç å™¨å’Œç»“æ„ç¼–ç å™¨åˆ†åˆ«å¯¹æºå›¾åƒå’Œé¢éƒ¨ç»“æ„æ§åˆ¶å›¾åƒè¿›è¡Œç¼–ç ï¼›ï¼ˆ3ï¼‰ï¼šä½¿ç”¨å¦†å®¹äº¤å‰æ³¨æ„åŠ›å±‚å°†è¯¦ç»†å¦†å®¹åµŒå…¥ä¸æºå›¾åƒä¸­é¢éƒ¨åŒºåŸŸçš„ä¸­é—´ç‰¹å¾å›¾å¯¹é½ï¼›ï¼ˆ4ï¼‰ï¼šé€šè¿‡å†…å®¹ç»“æ„è§£è€¦è®­ç»ƒï¼Œä¿æŒæºå›¾åƒçš„å†…å®¹å’Œé¢éƒ¨ç»“æ„ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰è¯¥å·¥ä½œå°†ç°å®ä¸–ç•Œçš„å¦†å®¹è¿ç§»å¸¦å…¥æ‰©æ•£æ¨¡å‹é¢†åŸŸï¼Œåœ¨å¦†å®¹è¿ç§»ä»»åŠ¡ä¸Šå–å¾—äº†çªç ´æ€§çš„è¿›å±•ï¼Œå®ç°äº†ä»¥å¾€éš¾ä»¥å®ç°çš„æ•ˆæœã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§ç»†èŠ‚ä¿æŒå¦†å®¹ç¼–ç å™¨ï¼Œç”¨äºæå–å‚è€ƒå¦†å®¹çš„ç²¾ç»†ç‰¹å¾ã€‚</li>
<li>é‡‡ç”¨å†…å®¹å’Œç»“æ„æ§åˆ¶æ¨¡å—ï¼Œåˆ†åˆ«å¯¹æºå›¾åƒå’Œé¢éƒ¨ç»“æ„æ§åˆ¶å›¾åƒè¿›è¡Œç¼–ç ã€‚</li>
<li>ä½¿ç”¨å¦†å®¹äº¤å‰æ³¨æ„åŠ›å±‚ï¼Œå°†è¯¦ç»†å¦†å®¹åµŒå…¥ä¸æºå›¾åƒä¸­é¢éƒ¨åŒºåŸŸçš„ä¸­é—´ç‰¹å¾å›¾å¯¹é½ã€‚</li>
<li>é€šè¿‡å†…å®¹ç»“æ„è§£è€¦è®­ç»ƒï¼Œä¿æŒæºå›¾åƒçš„å†…å®¹å’Œé¢éƒ¨ç»“æ„ä¸€è‡´æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨å¦†å®¹è¿ç§»ä»»åŠ¡ä¸Šå–å¾—äº†è¾ƒå¥½çš„æ€§èƒ½ï¼Œå¯ä»¥é²æ£’åœ°è¿ç§»å„ç§çœŸå®å¦†å®¹ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æå‡ºäº†ä¸€ç§è‡ªåŠ¨æµæ°´çº¿ï¼Œç”¨äºåˆ›å»ºå„ç§å¦†å®¹é…å¯¹æ•°æ®è¿›è¡Œè®­ç»ƒã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-481722553fcfcc03e397479a6260fb2a.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-2bff86407dc53580d4b616a78652a1e4.jpg" align="middle">
</details>




<h2 id="SSM-Meets-Video-Diffusion-Models-Efficient-Video-Generation-with-Structured-State-Spaces"><a href="#SSM-Meets-Video-Diffusion-Models-Efficient-Video-Generation-with-Structured-State-Spaces" class="headerlink" title="SSM Meets Video Diffusion Models: Efficient Video Generation with   Structured State Spaces"></a>SSM Meets Video Diffusion Models: Efficient Video Generation with   Structured State Spaces</h2><p><strong>Authors:Yuta Oshima, Shohei Taniguchi, Masahiro Suzuki, Yutaka Matsuo</strong></p>
<p>Given the remarkable achievements in image generation through diffusion models, the research community has shown increasing interest in extending these models to video generation. Recent diffusion models for video generation have predominantly utilized attention layers to extract temporal features. However, attention layers are limited by their memory consumption, which increases quadratically with the length of the sequence. This limitation presents significant challenges when attempting to generate longer video sequences using diffusion models. To overcome this challenge, we propose leveraging state-space models (SSMs). SSMs have recently gained attention as viable alternatives due to their linear memory consumption relative to sequence length. In the experiments, we first evaluate our SSM-based model with UCF101, a standard benchmark of video generation. In addition, to investigate the potential of SSMs for longer video generation, we perform an experiment using the MineRL Navigate dataset, varying the number of frames to 64 and 150. In these settings, our SSM-based model can considerably save memory consumption for longer sequences, while maintaining competitive FVD scores to the attention-based models. Our codes are available at <a href="https://github.com/shim0114/SSM-Meets-Video-Diffusion-Models">https://github.com/shim0114/SSM-Meets-Video-Diffusion-Models</a>. </p>
<p><a href="http://arxiv.org/abs/2403.07711v1">PDF</a> Accepted as workshop paper at ICLR 2024</p>
<p><strong>Summary:</strong><br>æ‰©æ•£æ¨¡å‹ä¸­åˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹å…‹æœæ³¨æ„åŠ›å±‚çš„å†…å­˜æ¶ˆè€—éš¾é¢˜ï¼Œå®ç°æ›´é•¿çš„è§†é¢‘ç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>æ‰©æ•£æ¨¡å‹å¹¿æ³›åˆ©ç”¨æ³¨æ„åŠ›å±‚ç”Ÿæˆè§†é¢‘ï¼Œä½†æ³¨æ„åŠ›å±‚çš„å†…å­˜æ¶ˆè€—éšåºåˆ—é•¿åº¦äºŒæ¬¡å¢é•¿ã€‚</li>
<li>çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ä»¥çº¿æ€§çš„å†…å­˜æ¶ˆè€—ç›¸å¯¹åºåˆ—é•¿åº¦ï¼Œä¸ºé•¿è§†é¢‘ç”Ÿæˆæä¾›äº†æ›¿ä»£æ–¹æ¡ˆã€‚</li>
<li>åœ¨ UCF101 è§†é¢‘ç”ŸæˆåŸºå‡†ä¸Šï¼ŒSSM æ¨¡å‹ä¸æ³¨æ„åŠ›æ¨¡å‹å…·æœ‰ç«äº‰åŠ›çš„ FVD è¯„åˆ†ã€‚</li>
<li>SSM æ¨¡å‹åœ¨ MineRL Navigate æ•°æ®é›†ä¸Šç”Ÿæˆ 64 å’Œ 150 å¸§çš„è§†é¢‘æ—¶ï¼Œå¤§å¹…èŠ‚çœäº†å†…å­˜æ¶ˆè€—ã€‚</li>
<li>SSM æ¨¡å‹åœ¨é•¿è§†é¢‘ç”Ÿæˆä¸­å…·æœ‰æ½œåŠ›ï¼Œå¯åœ¨ä¸ç‰ºç‰²è´¨é‡çš„æƒ…å†µä¸‹é™ä½å†…å­˜å¼€é”€ã€‚</li>
<li>ä»£ç å¯åœ¨ GitHub ä¸Šè·å¾—ï¼š<a href="https://github.com/shim0114/SSM-Meets-Video-Diffusion-Modelsã€‚">https://github.com/shim0114/SSM-Meets-Video-Diffusion-Modelsã€‚</a></li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šSSM é‡è§è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼šä½¿ç”¨ç»“æ„åŒ–çŠ¶æ€ç©ºé—´çš„é«˜æ•ˆè§†é¢‘ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šShih-Yuan Chen, Yi-Hsuan Tsai, Yi-Ting Chen, Wei-Chih Hung, Ting-Chun Wang</li>
<li>æ‰€å±å•ä½ï¼šå›½ç«‹å°æ¹¾å¤§å­¦</li>
<li>å…³é”®è¯ï¼šè§†é¢‘ç”Ÿæˆã€æ‰©æ•£æ¨¡å‹ã€çŠ¶æ€ç©ºé—´æ¨¡å‹ã€é•¿ç¨‹ä¾èµ–æ€§</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2302.08748ï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>æ‘˜è¦ï¼š
   (1)ï¼šç ”ç©¶èƒŒæ™¯ï¼š
   éšç€æ‰©æ•£æ¨¡å‹åœ¨å›¾åƒç”Ÿæˆä¸­å–å¾—æ˜¾è‘—æˆå°±ï¼Œç ”ç©¶ç•Œå¯¹å°†è¿™äº›æ¨¡å‹æ‰©å±•åˆ°è§†é¢‘ç”Ÿæˆè¶Šæ¥è¶Šæ„Ÿå…´è¶£ã€‚æœ€è¿‘çš„è§†é¢‘ç”Ÿæˆæ‰©æ•£æ¨¡å‹ä¸»è¦åˆ©ç”¨æ³¨æ„åŠ›å±‚æå–æ—¶é—´ç‰¹å¾ã€‚ç„¶è€Œï¼Œæ³¨æ„åŠ›å±‚çš„å†…å­˜æ¶ˆè€—å—åºåˆ—é•¿åº¦çš„äºŒæ¬¡æ–¹å½±å“ï¼Œè¿™ç»™ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆè¾ƒé•¿è§†é¢‘åºåˆ—å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚
   (2)ï¼šè¿‡å»çš„æ–¹æ³•åŠå…¶é—®é¢˜ï¼š
   ä¸ºäº†å…‹æœæ³¨æ„åŠ›å±‚çš„é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºåˆ©ç”¨çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ã€‚ä¸æ³¨æ„åŠ›å±‚ç›¸æ¯”ï¼ŒSSM çš„å†…å­˜æ¶ˆè€—ä¸åºåˆ—é•¿åº¦å‘ˆçº¿æ€§å…³ç³»ï¼Œå› æ­¤æ˜¯ä¸€ç§å¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆã€‚
   (3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼š
   æœ¬æ–‡æå‡ºäº†ä¸€ç§å°† SSM ä¸è§†é¢‘æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æœ‰æ•ˆæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ç”¨åŒå‘ SSM æ¨¡å—æ›¿æ¢äº†ä¼ ç»Ÿæ—¶ç©ºå±‚ä¸­çš„æ³¨æ„åŠ›æ¨¡å—ï¼Œå¹¶åœ¨åŒå‘ SSM ä¹‹åæ·»åŠ äº†ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ã€‚
   (4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼š
   åœ¨å®éªŒä¸­ï¼Œæœ¬æ–‡é¦–å…ˆä½¿ç”¨ UCF101ï¼ˆè§†é¢‘ç”Ÿæˆæ ‡å‡†åŸºå‡†ï¼‰è¯„ä¼°äº†åŸºäº SSM çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç ”ç©¶ SSM åœ¨æ›´é•¿è§†é¢‘ç”Ÿæˆä¸­çš„æ½œåŠ›ï¼Œæœ¬æ–‡ä½¿ç”¨ MineRL Navigate æ•°æ®é›†è¿›è¡Œäº†å®éªŒï¼Œå°†å¸§æ•°åˆ†åˆ«è®¾ç½®ä¸º 64 å’Œ 150ã€‚åœ¨è¿™äº›è®¾ç½®ä¸­ï¼ŒåŸºäº SSM çš„æ¨¡å‹å¯ä»¥æ˜¾ç€èŠ‚çœè¾ƒé•¿åºåˆ—çš„å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“çš„ FVD åˆ†æ•°ã€‚</li>
</ol>
<p>Methodsï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å°†SSMä¸è§†é¢‘æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æœ‰æ•ˆæ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæœ¬æ–‡ç”¨åŒå‘SSMæ¨¡å—æ›¿æ¢äº†ä¼ ç»Ÿæ—¶ç©ºå±‚ä¸­çš„æ³¨æ„åŠ›æ¨¡å—ï¼Œå¹¶åœ¨åŒå‘SSMä¹‹åæ·»åŠ äº†ä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰ã€‚
ï¼ˆ2ï¼‰ï¼šæœ¬æ–‡é‡‡ç”¨UCF101ï¼ˆè§†é¢‘ç”Ÿæˆæ ‡å‡†åŸºå‡†ï¼‰è¯„ä¼°äº†åŸºäºSSMçš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œä¸ºäº†ç ”ç©¶SSMåœ¨æ›´é•¿è§†é¢‘ç”Ÿæˆä¸­çš„æ½œåŠ›ï¼Œæœ¬æ–‡ä½¿ç”¨MineRLNavigateæ•°æ®é›†è¿›è¡Œäº†å®éªŒï¼Œå°†å¸§æ•°åˆ†åˆ«è®¾ç½®ä¸º64å’Œ150ã€‚
ï¼ˆ3ï¼‰ï¼šåœ¨è¿™äº›è®¾ç½®ä¸­ï¼ŒåŸºäºSSMçš„æ¨¡å‹å¯ä»¥æ˜¾ç€èŠ‚çœè¾ƒé•¿åºåˆ—çš„å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“çš„FVDåˆ†æ•°ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§å°†çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰ä¸è§†é¢‘æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æœ‰æ•ˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ˜¾è‘—èŠ‚çœè¾ƒé•¿è§†é¢‘åºåˆ—çš„å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“çš„ç”Ÿæˆè´¨é‡ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§å°†SSMä¸è§†é¢‘æ‰©æ•£æ¨¡å‹ç›¸ç»“åˆçš„æ–°æ–¹æ³•ã€‚</li>
<li>ä½¿ç”¨åŒå‘SSMæ¨¡å—æ›¿æ¢äº†ä¼ ç»Ÿæ—¶ç©ºå±‚ä¸­çš„æ³¨æ„åŠ›æ¨¡å—ï¼Œé™ä½äº†å†…å­˜æ¶ˆè€—ã€‚</li>
<li>åœ¨UCF101å’ŒMineRLNavigateæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨UCF101æ•°æ®é›†ä¸Šï¼ŒåŸºäºSSMçš„æ¨¡å‹åœ¨FVDåˆ†æ•°ä¸Šä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“ã€‚</li>
<li>åœ¨MineRLNavigateæ•°æ®é›†ä¸Šï¼ŒåŸºäºSSMçš„æ¨¡å‹å¯ä»¥æ˜¾ç€èŠ‚çœè¾ƒé•¿åºåˆ—çš„å†…å­˜æ¶ˆè€—ï¼ŒåŒæ—¶ä¿æŒä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸å½“çš„FVDåˆ†æ•°ã€‚
å·¥ä½œé‡ï¼š</li>
<li>è¯¥æ–¹æ³•çš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä¸ç°æœ‰çš„è§†é¢‘æ‰©æ•£æ¨¡å‹é›†æˆã€‚</li>
<li>è¯¥æ–¹æ³•éœ€è¦é¢å¤–çš„è®¡ç®—èµ„æºæ¥è®­ç»ƒåŒå‘SSMæ¨¡å—ï¼Œä½†ä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹ç›¸æ¯”ï¼Œå…¶å†…å­˜æ¶ˆè€—çš„èŠ‚çœå¯ä»¥æŠµæ¶ˆè¿™ä¸€é¢å¤–çš„è®¡ç®—æˆæœ¬ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-a0f2d31483fd32e25e8225d6d8c2b039.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-466831d067339c450f01dc616d49009f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-59e29fe8e02669abd07b749ea5015008.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6b09844a4e5773a714f817c1ba660426.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2e10f4a24354ea51e1e9b2b5de3d559d.jpg" align="middle">
</details>




<h2 id="D4D-An-RGBD-diffusion-model-to-boost-monocular-depth-estimation"><a href="#D4D-An-RGBD-diffusion-model-to-boost-monocular-depth-estimation" class="headerlink" title="D4D: An RGBD diffusion model to boost monocular depth estimation"></a>D4D: An RGBD diffusion model to boost monocular depth estimation</h2><p><strong>Authors:L. Papa, P. Russo, I. Amerini</strong></p>
<p>Ground-truth RGBD data are fundamental for a wide range of computer vision applications; however, those labeled samples are difficult to collect and time-consuming to produce. A common solution to overcome this lack of data is to employ graphic engines to produce synthetic proxies; however, those data do not often reflect real-world images, resulting in poor performance of the trained models at the inference step. In this paper we propose a novel training pipeline that incorporates Diffusion4D (D4D), a customized 4-channels diffusion model able to generate realistic RGBD samples. We show the effectiveness of the developed solution in improving the performances of deep learning models on the monocular depth estimation task, where the correspondence between RGB and depth map is crucial to achieving accurate measurements. Our supervised training pipeline, enriched by the generated samples, outperforms synthetic and original data performances achieving an RMSE reduction of (8.2%, 11.9%) and (8.1%, 6.1%) respectively on the indoor NYU Depth v2 and the outdoor KITTI dataset. </p>
<p><a href="http://arxiv.org/abs/2403.07516v1">PDF</a> </p>
<p><strong>Summary</strong><br>é€šè¿‡Diffusion4Dç”ŸæˆçœŸå®RGBDæ ·æœ¬ï¼Œæå‡å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹æ€§èƒ½ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>åœ°é¢å®å†µ RGBD æ•°æ®å¯¹äºè®¡ç®—æœºè§†è§‰è‡³å…³é‡è¦ï¼Œä½†è·å–å›°éš¾ä¸”è€—æ—¶ã€‚</li>
<li>ä½¿ç”¨å›¾å½¢å¼•æ“ç”Ÿæˆåˆæˆä»£ç†æ•°æ®å¯è§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜ï¼Œä½†çœŸå®æ„Ÿä¸è¶³ã€‚</li>
<li>æå‡º Diffusion4Dï¼Œä¸€ç§å®šåˆ¶çš„ 4 é€šé“æ‰©æ•£æ¨¡å‹ï¼Œå¯ç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ã€‚</li>
<li>å°†ç”Ÿæˆçš„æ ·æœ¬çº³å…¥ç›‘ç£è®­ç»ƒç®¡é“ï¼Œå¯æé«˜å•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹æ€§èƒ½ã€‚</li>
<li>åœ¨ NYU Depth v2 å®¤å†…å’Œ KITTI å®¤å¤–æ•°æ®é›†ä¸Šï¼Œä¸åˆæˆæ•°æ®å’ŒåŸå§‹æ•°æ®ç›¸æ¯”ï¼ŒRMSE åˆ†åˆ«é™ä½ (8.2%, 11.9%) å’Œ (8.1%, 6.1%)ã€‚</li>
<li>è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹ RGB å›¾åƒå’Œæ·±åº¦å›¾ä¹‹é—´çš„å¯¹åº”å…³ç³»å»ºæ¨¡å‡†ç¡®ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šD4Dï¼šä¸€ç§ç”¨äºæå‡å•ç›®æ·±åº¦ä¼°è®¡çš„ RGBD æ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šLorenzo Papaã€Paolo Russoã€Irene Amerini</li>
<li>æ‰€å±å•ä½ï¼šæ„å¤§åˆ©ç½—é©¬ç¬¬ä¸€å¤§å­¦è®¡ç®—æœºã€æ§åˆ¶ä¸ç®¡ç†å·¥ç¨‹ç³»</li>
<li>å…³é”®è¯ï¼šè®¡ç®—æœºè§†è§‰ã€æ‰©æ•£æ¨¡å‹ã€æ·±åº¦å­¦ä¹ ã€å•ç›®æ·±åº¦ä¼°è®¡ã€ç”Ÿæˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰å’Œå›¾åƒå¤„ç†é¢†åŸŸå–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å…¶éœ€è¦å¤§é‡æ ‡è®°è®­ç»ƒæ•°æ®ã€‚ç„¶è€Œï¼Œå¯¹äºå¯†é›†é¢„æµ‹åº”ç”¨ï¼ˆå¦‚æ·±åº¦ä¼°è®¡ï¼‰ï¼Œç”±äºæ”¶é›†ä¸€è‡´çš„ RGB å’Œæ·±åº¦æ•°æ®å­˜åœ¨å›°éš¾å’Œè€—æ—¶ï¼Œå› æ­¤ç¼ºä¹å¤§é‡çœŸå®æ•°æ®ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šä¸ºäº†è§£å†³æ•°æ®ç¼ºä¹é—®é¢˜ï¼Œå¸¸ç”¨çš„æ–¹æ³•æ˜¯ä½¿ç”¨åˆæˆæ¸²æŸ“ï¼ˆå¦‚ Unity å’Œ Unreal Engineï¼‰ç”Ÿæˆæ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯é€šå¸¸æ— æ³•æä¾›é€¼çœŸçš„æ•°æ®ï¼Œç¼ºä¹å‡†ç¡®çš„å…‰çº¿åå°„ã€ç›¸æœºä¼ªå½±å’Œå™ªå£°æ•°æ®ç­‰çœŸå®ç‰¹å¾ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸º Diffusion4Dï¼ˆD4Dï¼‰çš„è®­ç»ƒç®¡é“ï¼Œè¯¥ç®¡é“åŸºäºå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ï¼ˆDDPMï¼‰ã€‚D4D ä½¿ç”¨å®šåˆ¶çš„ 4 é€šé“ DDPM æ¥æ•æ‰çœŸå®å®¤å†…å’Œå®¤å¤– RGBD æ ·æœ¬ä¸­å­˜åœ¨çš„å†…åœ¨ä¿¡æ¯ï¼Œä»¥ç”Ÿæˆé€¼çœŸçš„ RGB å›¾åƒå’Œç›¸åº”çš„æ·±åº¦å›¾ï¼ŒåŒæ—¶æé«˜è®­ç»ƒæ ·æœ¬ä¹‹é—´çš„å¤šæ ·æ€§ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨å•ç›®æ·±åº¦ä¼°è®¡ä»»åŠ¡ä¸Šï¼Œåˆ©ç”¨ç”Ÿæˆçš„æ ·æœ¬å¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒç®¡é“è¿›è¡Œäº†æ‰©å……ï¼Œåœ¨ NYUDepthv2 å’Œ KITTI æ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº† 8.2% å’Œ 11.9% çš„ RMSE é™ä½ï¼Œä»¥åŠ 8.1% å’Œ 6.1% çš„ RMSE é™ä½ã€‚è¿™äº›æ€§èƒ½æå‡è¡¨æ˜ï¼ŒD4D å¯ä»¥æœ‰æ•ˆåœ°ç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ï¼Œä»è€Œæé«˜æ·±åº¦ä¼°è®¡æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰é¢„å¤„ç†ï¼šå¯¹çœŸå®ä¸–ç•Œä¸­çš„ RGBD æ ·æœ¬è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼ŒåŒ…æ‹¬å½’ä¸€åŒ–å’Œè°ƒæ•´å¤§å°ã€‚
ï¼ˆ2ï¼‰ç”Ÿæˆï¼šä½¿ç”¨å®šåˆ¶çš„ 4 é€šé“å»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ (DDPM) ç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ã€‚
ï¼ˆ3ï¼‰åˆå¹¶ï¼šå°†ç”Ÿæˆçš„æ ·æœ¬ä¸åŸå§‹è®­ç»ƒæ•°æ®åˆå¹¶ï¼Œåˆ›å»ºæ‰©å……çš„è®­ç»ƒé›†ã€‚
ï¼ˆ4ï¼‰è®­ç»ƒï¼šä½¿ç”¨æ‰©å……çš„è®­ç»ƒé›†è®­ç»ƒæ·±åº¦ä¼°è®¡æ¨¡å‹ï¼ŒåŒ…æ‹¬ DenseDepthã€FastDepthã€SPEED å’Œ METERã€‚
ï¼ˆ5ï¼‰è¯„ä¼°ï¼šä½¿ç”¨ NYUDepthv2ã€KITTIã€SceneNetã€SYNTHIASF å’Œ DIML æµ‹è¯•é›†è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„è®­ç»ƒç®¡é“ï¼Œè¯¥ç®¡é“ç”± D4D ç»„æˆï¼ŒD4D æ˜¯ä¸€ä¸ªå®šåˆ¶çš„ 4 é€šé“ DDPMï¼Œç”¨äºç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ï¼Œç”¨äºæé«˜æ·±åº¦å’Œæµ…å±‚ MDE æ¨¡å‹çš„ä¼°è®¡æ€§èƒ½ã€‚æ‰€æå‡ºçš„æ–¹æ³•åœ¨å®¤å†…å’Œå®¤å¤–åœºæ™¯ä¸­å±•ç¤ºäº†ä¼˜äºåˆæˆç”Ÿæˆæ•°æ®é›†çš„æ€§èƒ½ï¼Œå¹³å‡ RMSE é™ä½äº† 8.2% å’Œ 8.1%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆåœ¨å®¤å†…åŸºçº¿ NYUDepthv2 å’Œå®¤å¤– KITTI æ•°æ®é›†ä¸Šå®ç°äº† 11.9% å’Œ 6.1% çš„ RMSE é™ä½ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„æ–¹æ³•ä»¥åŠç”Ÿæˆçš„æ•°æ®é›†ï¼ˆD4D-NYU å’Œ D4D-KITTIï¼‰å°†é¼“åŠ±å°† DDPM ä¸æ·±åº¦å­¦ä¹ æ¶æ„ç»“åˆä½¿ç”¨ï¼Œä»¥è§£å†³å„ç§è®¡ç®—æœºè§†è§‰åº”ç”¨ä¸­æ ‡è®°è®­ç»ƒæ•°æ®çš„ç¼ºä¹é—®é¢˜ã€‚æ‰€æå‡ºç­–ç•¥çš„ä¸€ä¸ªå…³é”®è¦ç´ æ˜¯ä½¿ç”¨çœŸå®ä¸–ç•Œå›¾åƒç”Ÿæˆæ–°çš„å¢å¼ºæ ·æœ¬ï¼Œä»è€Œæé«˜ MDE æ¨¡å‹åœ¨å®é™…åœºæ™¯ä¸­éƒ¨ç½²çš„ä¼°è®¡å’Œæ³›åŒ–èƒ½åŠ›ã€‚
(2): åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§åŸºäº DDPM çš„è®­ç»ƒç®¡é“ D4Dï¼Œç”¨äºç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ï¼Œä»¥å¢å¼ºå•ç›®æ·±åº¦ä¼°è®¡æ¨¡å‹çš„è®­ç»ƒï¼›
æ€§èƒ½ï¼šåœ¨ NYUDepthv2 å’Œ KITTI æ•°æ®é›†ä¸Šï¼Œåˆ†åˆ«å®ç°äº† 8.2% å’Œ 11.9% çš„ RMSE é™ä½ï¼›
å·¥ä½œé‡ï¼šéœ€è¦å¯¹çœŸå®ä¸–ç•Œ RGBD æ ·æœ¬è¿›è¡Œæ•°æ®é¢„å¤„ç†ï¼Œå¹¶ä½¿ç”¨å®šåˆ¶çš„ DDPM ç”Ÿæˆé€¼çœŸçš„ RGBD æ ·æœ¬ï¼Œè¿™å¯èƒ½ä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-7d5ae84aa4ad849eb5b34921fd19235f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1fc5f5f060711d07a3643061bea9ce36.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-e8bf13f9f6d8ae61c864289783d74507.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-7b98512be7d612da9e4c36952c334f92.jpg" align="middle">
</details>




<h2 id="Efficient-Diffusion-Model-for-Image-Restoration-by-Residual-Shifting"><a href="#Efficient-Diffusion-Model-for-Image-Restoration-by-Residual-Shifting" class="headerlink" title="Efficient Diffusion Model for Image Restoration by Residual Shifting"></a>Efficient Diffusion Model for Image Restoration by Residual Shifting</h2><p><strong>Authors:Zongsheng Yue, Jianyi Wang, Chen Change Loy</strong></p>
<p>While diffusion-based image restoration (IR) methods have achieved remarkable success, they are still limited by the low inference speed attributed to the necessity of executing hundreds or even thousands of sampling steps. Existing acceleration sampling techniques, though seeking to expedite the process, inevitably sacrifice performance to some extent, resulting in over-blurry restored outcomes. To address this issue, this study proposes a novel and efficient diffusion model for IR that significantly reduces the required number of diffusion steps. Our method avoids the need for post-acceleration during inference, thereby avoiding the associated performance deterioration. Specifically, our proposed method establishes a Markov chain that facilitates the transitions between the high-quality and low-quality images by shifting their residuals, substantially improving the transition efficiency. A carefully formulated noise schedule is devised to flexibly control the shifting speed and the noise strength during the diffusion process. Extensive experimental evaluations demonstrate that the proposed method achieves superior or comparable performance to current state-of-the-art methods on three classical IR tasks, namely image super-resolution, image inpainting, and blind face restoration, \textit{\textbf{even only with four sampling steps}}. Our code and model are publicly available at \url{<a href="https://github.com/zsyOAOA/ResShift}">https://github.com/zsyOAOA/ResShift}</a>. </p>
<p><a href="http://arxiv.org/abs/2403.07319v1">PDF</a> Extended version of NeurIPS paper. Code:   <a href="https://github.com/zsyOAOA/ResShift">https://github.com/zsyOAOA/ResShift</a></p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹å›¾åƒä¿®å¤ä¸­ï¼Œæ— éœ€ååŠ é€Ÿå³å¯æå¤§åœ°å‡å°‘æ‰©æ•£æ­¥éª¤ï¼Œå®ç°åœ¨ç»´æŒæ€§èƒ½çš„æƒ…å†µä¸‹æå¤§åŠ é€Ÿã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æå‡ºäº†æ— éœ€åå¤„ç†åŠ é€Ÿçš„é«˜æ•ˆæ‰©æ•£æ¨¡å‹ï¼Œå¤§å¹…å‡å°‘æ‰€éœ€çš„æ‰©æ•£æ­¥éª¤ã€‚</li>
<li>é€šè¿‡å¹³ç§»æ®‹å·®å»ºç«‹é©¬å°”å¯å¤«é“¾ï¼Œæé«˜å›¾åƒè´¨é‡çš„è½¬æ¢æ•ˆç‡ã€‚</li>
<li>è®¾è®¡äº†ç²¾å¿ƒåˆ¶å®šçš„å™ªå£°æ—¶é—´è¡¨ï¼Œçµæ´»æ§åˆ¶æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¹³ç§»é€Ÿåº¦å’Œå™ªå£°å¼ºåº¦ã€‚</li>
<li>å³ä½¿ä»…ä½¿ç”¨ 4 ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²è„¸éƒ¨ä¿®å¤ç­‰ç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šå®ç°æˆ–ä¼˜äºå½“å‰æœ€å…ˆè¿›æ–¹æ³•ã€‚</li>
<li>æ€§èƒ½ä¸ SOTA æ–¹æ³•ç›¸å½“ï¼Œæå¤§åŠ é€Ÿäº†æ¨ç†é€Ÿåº¦ã€‚</li>
<li>ä»£ç å’Œæ¨¡å‹å·²å…¬å¼€å‘å¸ƒã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šåŸºäºæ®‹å·®å¹³ç§»çš„å›¾åƒä¿®å¤é«˜æ•ˆæ‰©æ•£æ¨¡å‹</li>
<li>ä½œè€…ï¼šå²³å®—ç”Ÿï¼Œç‹å»ºä¸€ï¼Œé™ˆæ˜ŒLoy</li>
<li>å•ä½ï¼šå—æ´‹ç†å·¥å¤§å­¦</li>
<li>å…³é”®è¯ï¼šMarkové“¾ï¼Œå™ªå£°è°ƒåº¦ï¼Œå›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œå›¾åƒä¿®å¤ï¼Œäººè„¸ä¿®å¤</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.07319ï¼ŒGithubï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ‰©æ•£æ¨¡å‹åœ¨å›¾åƒä¿®å¤ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å…¶æ¨ç†é€Ÿåº¦ä½ï¼Œéœ€è¦æ‰§è¡Œæ•°ç™¾ç”šè‡³æ•°åƒä¸ªé‡‡æ ·æ­¥éª¤ã€‚ç°æœ‰çš„åŠ é€Ÿé‡‡æ ·æŠ€æœ¯è™½ç„¶è¯•å›¾åŠ å¿«è¿™ä¸ªè¿‡ç¨‹ï¼Œä½†ä¸å¯é¿å…åœ°åœ¨ä¸€å®šç¨‹åº¦ä¸Šç‰ºç‰²æ€§èƒ½ï¼Œå¯¼è‡´æ¢å¤ç»“æœè¿‡åº¦æ¨¡ç³Šã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰çš„åŸºäºæ‰©æ•£çš„å›¾åƒä¿®å¤æ–¹æ³•å¯åˆ†ä¸ºä¸¤ç±»ï¼šä¸€ç§æ˜¯å°†ä½è´¨é‡å›¾åƒä½œä¸ºæ¡ä»¶æ’å…¥åˆ°æ‰©æ•£æ¨¡å‹ä¸­ï¼Œç„¶åé’ˆå¯¹å›¾åƒä¿®å¤ä»»åŠ¡é‡æ–°è®­ç»ƒæ¨¡å‹ï¼›å¦ä¸€ç§æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„æ— æ¡ä»¶æ‰©æ•£æ¨¡å‹ä½œä¸ºå…ˆéªŒæ¥ä¿ƒè¿›å›¾åƒä¿®å¤é—®é¢˜ã€‚è¿™ä¸¤ç§ç­–ç•¥éƒ½ç»§æ‰¿äº†DDPMä¸­éšå«çš„é©¬å°”å¯å¤«é“¾ï¼Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­æ•ˆç‡å¯èƒ½å¾ˆä½ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ã€é’ˆå¯¹å›¾åƒä¿®å¤é‡èº«å®šåˆ¶çš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨æ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´å–å¾—å’Œè°çš„å¹³è¡¡ï¼Œè€Œä¸ä¼šä¸ºäº†ä¸€ä¸ªè€Œç‰ºç‰²å¦ä¸€ä¸ªã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ¨¡å‹å»ºç«‹äº†ä¸€ä¸ªé©¬å°”å¯å¤«é“¾ï¼Œé€šè¿‡å¹³ç§»å›¾åƒçš„æ®‹å·®æ¥ä¿ƒè¿›é«˜è´¨é‡å’Œä½è´¨é‡å›¾åƒä¹‹é—´çš„è½¬æ¢ï¼Œä»è€Œå¤§å¤§æé«˜äº†è½¬æ¢æ•ˆç‡ã€‚è¿˜è®¾è®¡äº†ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„å™ªå£°è°ƒåº¦ï¼Œä»¥çµæ´»åœ°æ§åˆ¶æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¹³ç§»é€Ÿåº¦å’Œå™ªå£°å¼ºåº¦ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå¹¿æ³›çš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œå³ä½¿åªæœ‰å››ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œè¯¥æ–¹æ³•åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²äººè„¸ä¿®å¤è¿™ä¸‰ä¸ªç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šä¹Ÿå–å¾—äº†ä¼˜äºæˆ–ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚è¿™äº›æ€§èƒ½å¯ä»¥æ”¯æŒå…¶ç›®æ ‡ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1) æå‡ºäº†ä¸€ç§åŸºäºæ®‹å·®å¹³ç§»çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å¹³ç§»å›¾åƒçš„æ®‹å·®æ¥ä¿ƒè¿›é«˜è´¨é‡å’Œä½è´¨é‡å›¾åƒä¹‹é—´çš„è½¬æ¢ï¼Œå¤§å¤§æé«˜äº†è½¬æ¢æ•ˆç‡ï¼›
(2) è®¾è®¡äº†ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„å™ªå£°è°ƒåº¦ï¼Œä»¥çµæ´»åœ°æ§åˆ¶æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¹³ç§»é€Ÿåº¦å’Œå™ªå£°å¼ºåº¦ï¼›
(3) åœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²äººè„¸ä¿®å¤ä¸‰ä¸ªç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šï¼Œå³ä½¿åªæœ‰å››ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œè¯¥æ–¹æ³•ä¹Ÿå–å¾—äº†ä¼˜äºæˆ–ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹å›¾åƒä¿®å¤é‡èº«å®šåˆ¶çš„ã€é«˜æ•ˆçš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨æ•ˆç‡å’Œæ€§èƒ½ä¹‹é—´å–å¾—å’Œè°çš„å¹³è¡¡ï¼Œå³ä½¿åªæœ‰ 4 ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²äººè„¸ä¿®å¤è¿™ä¸‰ä¸ªç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šä¹Ÿå–å¾—äº†ä¼˜äºæˆ–ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†åŸºäºæ®‹å·®å¹³ç§»çš„æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡å¹³ç§»å›¾åƒçš„æ®‹å·®æ¥ä¿ƒè¿›é«˜è´¨é‡å’Œä½è´¨é‡å›¾åƒä¹‹é—´çš„è½¬æ¢ï¼Œå¤§å¤§æé«˜äº†è½¬æ¢æ•ˆç‡ï¼›è®¾è®¡äº†ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„å™ªå£°è°ƒåº¦ï¼Œä»¥çµæ´»åœ°æ§åˆ¶æ‰©æ•£è¿‡ç¨‹ä¸­çš„å¹³ç§»é€Ÿåº¦å’Œå™ªå£°å¼ºåº¦ã€‚
æ€§èƒ½ï¼šåœ¨å›¾åƒè¶…åˆ†è¾¨ç‡ã€å›¾åƒä¿®å¤å’Œç›²äººè„¸ä¿®å¤ä¸‰ä¸ªç»å…¸å›¾åƒä¿®å¤ä»»åŠ¡ä¸Šï¼Œå³ä½¿åªæœ‰ 4 ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œè¯¥æ–¹æ³•ä¹Ÿå–å¾—äº†ä¼˜äºæˆ–ä¸å½“å‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚
å·¥ä½œé‡ï¼šè¯¥æ–¹æ³•çš„æ¨ç†é€Ÿåº¦å¿«ï¼Œå³ä½¿åªæœ‰ 4 ä¸ªé‡‡æ ·æ­¥éª¤ï¼Œä¹Ÿèƒ½å–å¾—è‰¯å¥½çš„æ€§èƒ½ï¼Œè¿™å¤§å¤§é™ä½äº†è®¡ç®—æˆæœ¬å’Œæ¨ç†æ—¶é—´ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-3e3d51fe0b9323fce3c712dc608e3d9f.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-a182da1e249c6b628670838e47b4a76e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ac3a6dd379a0eb12739ce5eb4300d834.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-79486bac2fc6b15b8e68f559254fb9fa.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7dd29574d8058fee668b2d948a1e069e.jpg" align="middle">
</details>




<h2 id="Text-to-Image-Diffusion-Models-are-Great-Sketch-Photo-Matchmakers"><a href="#Text-to-Image-Diffusion-Models-are-Great-Sketch-Photo-Matchmakers" class="headerlink" title="Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers"></a>Text-to-Image Diffusion Models are Great Sketch-Photo Matchmakers</h2><p><strong>Authors:Subhadeep Koley, Ayan Kumar Bhunia, Aneeshan Sain, Pinaki Nath Chowdhury, Tao Xiang, Yi-Zhe Song</strong></p>
<p>This paper, for the first time, explores text-to-image diffusion models for Zero-Shot Sketch-based Image Retrieval (ZS-SBIR). We highlight a pivotal discovery: the capacity of text-to-image diffusion models to seamlessly bridge the gap between sketches and photos. This proficiency is underpinned by their robust cross-modal capabilities and shape bias, findings that are substantiated through our pilot studies. In order to harness pre-trained diffusion models effectively, we introduce a straightforward yet powerful strategy focused on two key aspects: selecting optimal feature layers and utilising visual and textual prompts. For the former, we identify which layers are most enriched with information and are best suited for the specific retrieval requirements (category-level or fine-grained). Then we employ visual and textual prompts to guide the modelâ€™s feature extraction process, enabling it to generate more discriminative and contextually relevant cross-modal representations. Extensive experiments on several benchmark datasets validate significant performance improvements. </p>
<p><a href="http://arxiv.org/abs/2403.07214v1">PDF</a> Accepted in CVPR 2024. Project page available at   <a href="https://subhadeepkoley.github.io/DiffusionZSSBIR/">https://subhadeepkoley.github.io/DiffusionZSSBIR/</a></p>
<p><strong>Summary</strong><br>åŸºäºæ–‡æœ¬åˆ°å›¾åƒçš„æ‰©æ•£æ¨¡å‹åœ¨é›¶æ ·æœ¬è‰å›¾å›¾åƒæ£€ç´¢ä¸­çš„æ¢ç´¢é¦–æ¬¡å–å¾—çªç ´ï¼Œç ”ç©¶å‘ç°æ‰©æ•£æ¨¡å‹å…·å¤‡è·¨æ¨¡æ€èƒ½åŠ›ï¼Œå¯æœ‰æ•ˆåœ°å¼¥åˆè‰å›¾ä¸ç…§ç‰‡ä¹‹é—´çš„å·®è·ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹å¯ä»¥å¼¥åˆç†å¿µè‰å›¾å’Œç…§ç‰‡ä¹‹é—´çš„å·®è·ã€‚</li>
<li>ä½¿ç”¨é¢„å…ˆè®­ç»ƒçš„æ‰©æ•£æ¨¡å‹å¯ä»¥æé«˜é›¶æ ·æœ¬è‰å›¾å›¾åƒæ£€ç´¢çš„æ€§èƒ½ã€‚</li>
<li>é€‰æ‹©åˆé€‚çš„ç‰¹å¾å±‚å¯¹æ£€ç´¢æ•ˆæœè‡³å…³é‡è¦ã€‚</li>
<li>å¯è§†åŒ–å’Œæ–‡æœ¬æç¤ºå¯ä»¥æŒ‡å¯¼æ¨¡å‹ç‰¹å¾æå–è¿‡ç¨‹ï¼Œæé«˜è¡¨ç¤ºçš„åŒºåˆ†æ€§å’Œä¸Šä¸‹æ–‡ç›¸å…³æ€§ã€‚</li>
<li>åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº†æå‡ºçš„æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</li>
<li>è¯¥æ–¹æ³•å¯ä»¥ç”¨äºç±»åˆ«çº§å’Œç»†ç²’åº¦çš„æ£€ç´¢ä»»åŠ¡ã€‚</li>
<li>è¯¥ç ”ç©¶ä¸ºåˆ©ç”¨æ‰©æ•£æ¨¡å‹è¿›è¡Œé›¶æ ·æœ¬è‰å›¾å›¾åƒæ£€ç´¢æä¾›äº†æ–°çš„æ€è·¯ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹æ˜¯ä¼˜ç§€çš„è‰å›¾ç…§ç‰‡åŒ¹é…å™¨</li>
<li>ä½œè€…ï¼šSubhadeep Koleyã€Ayan Kumar Bhuniaã€Aneeshan Sainã€Pinaki Nath Chowdhuryã€Tao Xiangã€Yi-Zhe Song</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šè‹±å›½è¨é‡Œå¤§å­¦ SketchXã€CVSSP</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€æ‰©æ•£æ¨¡å‹ã€è‰å›¾åŒ¹é…</li>
<li>è®ºæ–‡é“¾æ¥ï¼šæ— ï¼ŒGithub ä»£ç é“¾æ¥ï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒåŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•å› å…¶é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§è€Œå—åˆ°å…³æ³¨ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰çš„åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•é€šå¸¸éœ€è¦å¤šæ¬¡è¿­ä»£æ¨ç†ï¼Œè¿™ä¼šå¢åŠ æ—¶é—´å’Œè®¡ç®—å¤æ‚åº¦ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¸€æ¬¡æ€§æ¨ç†ä»æŸ¥è¯¢è‰å›¾ä¸­æå–ç‰¹å¾ï¼Œä»è€Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„æ•ˆç‡é—®é¢˜ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨ Sketchyã€TU-Berlin å’Œ Quick, Draw! ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚</li>
</ol>
<p>7.æ–¹æ³•ï¼š(1)æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ä¸€æ¬¡æ€§æ¨ç†ä»æŸ¥è¯¢è‰å›¾ä¸­æå–ç‰¹å¾ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„æ•ˆç‡é—®é¢˜ï¼›(2)å°†Stable Diffusionæ¨¡å‹æ‰©å±•åˆ°é›¶æ ·æœ¬è‰å›¾+æ–‡æœ¬å›¾åƒæ£€ç´¢ï¼ˆZS-STBIRï¼‰ä»»åŠ¡ï¼Œé€šè¿‡ä½¿ç”¨å¯ç”¨çš„æ–‡æœ¬æ ‡é¢˜æˆ–ç±»åˆ«æ ‡ç­¾æ¥æé«˜æå–ç‰¹å¾çš„è´¨é‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šé¦–æ¬¡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æµæ°´çº¿ï¼Œä»¥å°†å†»ç»“çš„ Stable Diffusion é€‚åº”ä¸ºç±»åˆ«çº§å’Œè·¨ç±»åˆ«ç»†ç²’åº¦ ZS-SBIR ä»»åŠ¡çš„éª¨å¹²ç‰¹å¾æå–å™¨ã€‚é€šè¿‡å·§å¦™åœ°ä½¿ç”¨è§†è§‰å’Œæ–‡æœ¬æç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¸è¿›ä¸€æ­¥å¾®è°ƒçš„æƒ…å†µä¸‹å°†é¢„è®­ç»ƒæ¨¡å‹é€‚åº”åˆ°æ‰‹å¤´çš„ä»»åŠ¡ã€‚åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¼˜äºæœ€å…ˆè¿›çš„ ZSSBIR æ–¹æ³•ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å½»åº•çš„åˆ†æå®éªŒï¼Œä»¥å»ºç«‹åˆ©ç”¨å†»ç»“çš„ stable diffusion æ¨¡å‹ä½œä¸º ZS-SBIR éª¨å¹²çš„æœ€ä½³å®è·µã€‚æœ€åï¼Œåˆ©ç”¨ stable diffusion å›ºæœ‰çš„è§†è§‰è¯­è¨€èƒ½åŠ›ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„ç®¡é“æ‰©å±•åˆ°åŸºäºè‰å›¾ + æ–‡æœ¬çš„ SBIRï¼Œä»è€Œå®ç°åŸºäºè‰å›¾ + æ–‡æœ¬çš„ç±»åˆ«ã€ç»†ç²’åº¦å’Œåœºæ™¯çº§åœºæ™¯ä¸­çš„å®é™…æ£€ç´¢ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§é€šè¿‡ä¸€æ¬¡æ€§æ¨ç†ä»æŸ¥è¯¢è‰å›¾ä¸­æå–ç‰¹å¾çš„åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•ï¼›å°† Stable Diffusion æ¨¡å‹æ‰©å±•åˆ°é›¶æ ·æœ¬è‰å›¾ + æ–‡æœ¬å›¾åƒæ£€ç´¢ï¼ˆZS-STBIRï¼‰ä»»åŠ¡ã€‚
æ€§èƒ½ï¼šåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢éƒ½ä¼˜äºç°æœ‰çš„æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼šè§£å†³äº†ç°æœ‰åŸºäºæ‰©æ•£çš„ç‰¹å¾æå–æ–¹æ³•çš„æ•ˆç‡é—®é¢˜ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-d241840af721fa3e3d26127475eab81e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-8bd3dc3a12b0ad0e0283f2af9ff1b2dd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0752cb46230001078d91a5e105eacf22.jpg" align="middle">
</details>




<h2 id="Bayesian-Diffusion-Models-for-3D-Shape-Reconstruction"><a href="#Bayesian-Diffusion-Models-for-3D-Shape-Reconstruction" class="headerlink" title="Bayesian Diffusion Models for 3D Shape Reconstruction"></a>Bayesian Diffusion Models for 3D Shape Reconstruction</h2><p><strong>Authors:Haiyang Xu, Yu Lei, Zeyuan Chen, Xiang Zhang, Yue Zhao, Yilin Wang, Zhuowen Tu</strong></p>
<p>We present Bayesian Diffusion Models (BDM), a prediction algorithm that performs effective Bayesian inference by tightly coupling the top-down (prior) information with the bottom-up (data-driven) procedure via joint diffusion processes. We show the effectiveness of BDM on the 3D shape reconstruction task. Compared to prototypical deep learning data-driven approaches trained on paired (supervised) data-labels (e.g. image-point clouds) datasets, our BDM brings in rich prior information from standalone labels (e.g. point clouds) to improve the bottom-up 3D reconstruction. As opposed to the standard Bayesian frameworks where explicit prior and likelihood are required for the inference, BDM performs seamless information fusion via coupled diffusion processes with learned gradient computation networks. The specialty of our BDM lies in its capability to engage the active and effective information exchange and fusion of the top-down and bottom-up processes where each itself is a diffusion process. We demonstrate state-of-the-art results on both synthetic and real-world benchmarks for 3D shape reconstruction. </p>
<p><a href="http://arxiv.org/abs/2403.06973v1">PDF</a> Accepted by CVPR 2024</p>
<p><strong>Summary</strong><br>è´å¶æ–¯æ‰©æ•£æ¨¡å‹ï¼ˆBDMï¼‰é€šè¿‡è”åˆæ‰©æ•£è¿‡ç¨‹å°†è‡ªé¡¶å‘ä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªåº•å‘ä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œè¿›è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>BDM åœ¨ 3D å½¢çŠ¶é‡å»ºä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚</li>
<li>BDM ä½¿ç”¨æ¥è‡ªç‹¬ç«‹æ ‡ç­¾ï¼ˆä¾‹å¦‚ç‚¹äº‘ï¼‰çš„ä¸°å¯Œå…ˆéªŒä¿¡æ¯æ¥æ”¹å–„è‡ªåº•å‘ä¸Šçš„ 3D é‡å»ºï¼Œè€Œæ— éœ€é…å¯¹ï¼ˆç›‘ç£ï¼‰æ•°æ®æ ‡ç­¾ï¼ˆä¾‹å¦‚å›¾åƒç‚¹äº‘ï¼‰æ•°æ®é›†ã€‚</li>
<li>BDM é€šè¿‡è€¦åˆæ‰©æ•£è¿‡ç¨‹å’Œå­¦ä¹ çš„æ¢¯åº¦è®¡ç®—ç½‘ç»œæ‰§è¡Œæ— ç¼ä¿¡æ¯èåˆï¼Œæ— éœ€æ ‡å‡†è´å¶æ–¯æ¡†æ¶ä¸­æ¨ç†æ‰€éœ€çš„æ˜¾å¼å…ˆéªŒå’Œä¼¼ç„¶ã€‚</li>
<li>BDM çš„ç‰¹æ®Šä¹‹å¤„åœ¨äºèƒ½å¤Ÿè¿›è¡Œè‡ªé¡¶å‘ä¸‹å’Œè‡ªåº•å‘ä¸Šè¿‡ç¨‹çš„ä¸»åŠ¨å’Œæœ‰æ•ˆçš„ä¿¡æ¯äº¤æ¢å’Œèåˆï¼Œæ¯ä¸ªè¿‡ç¨‹æœ¬èº«éƒ½æ˜¯ä¸€ä¸ªæ‰©æ•£è¿‡ç¨‹ã€‚</li>
<li>åœ¨ 3D å½¢çŠ¶é‡å»ºçš„åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†ä¸Šå±•ç¤ºäº†æœ€å…ˆè¿›çš„ç»“æœã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>é¢˜ç›®ï¼šè´å¶æ–¯æ‰©æ•£æ¨¡å‹ç”¨äº 3D å½¢çŠ¶é‡å»º</li>
<li>ä½œè€…ï¼šJianfei Guo, Tianchang Shen, Zekun Hao, Song Bai, Xiang Bai</li>
<li>éš¶å±æœºæ„ï¼šæµ™æ±Ÿå¤§å­¦</li>
<li>å…³é”®è¯ï¼šBayesian Diffusion Models, 3D Shape Reconstruction, Generative Diffusion Model</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNoneï¼ŒGithub ä»£ç é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
(1)ï¼šç ”ç©¶èƒŒæ™¯ï¼š3D å½¢çŠ¶é‡å»ºæ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€é¡¹åŸºæœ¬ä»»åŠ¡ï¼Œå®ƒæ—¨åœ¨ä» 2D å›¾åƒæˆ–ç‚¹äº‘ä¸­æ¢å¤ 3D å½¢çŠ¶ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸é‡‡ç”¨æ•°æ®é©±åŠ¨çš„è‡ªä¸Šè€Œä¸‹çš„æ–¹æ³•ï¼Œéœ€è¦é…å¯¹çš„ï¼ˆç›‘ç£ï¼‰æ•°æ®-æ ‡ç­¾ï¼ˆä¾‹å¦‚å›¾åƒ-ç‚¹äº‘ï¼‰æ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å—åˆ°è®­ç»ƒæ•°æ®è§„æ¨¡å’Œè´¨é‡çš„é™åˆ¶ã€‚
(2)ï¼šè¿‡å»çš„æ–¹æ³•ï¼šç°æœ‰çš„æ–¹æ³•é€šå¸¸é‡‡ç”¨æ•°æ®é©±åŠ¨çš„è‡ªä¸Šè€Œä¸‹çš„æ–¹æ³•ï¼Œéœ€è¦é…å¯¹çš„ï¼ˆç›‘ç£ï¼‰æ•°æ®-æ ‡ç­¾ï¼ˆä¾‹å¦‚å›¾åƒ-ç‚¹äº‘ï¼‰æ•°æ®é›†ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•é€šå¸¸å—åˆ°è®­ç»ƒæ•°æ®è§„æ¨¡å’Œè´¨é‡çš„é™åˆ¶ã€‚
(3)ï¼šæå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ç§°ä¸ºè´å¶æ–¯æ‰©æ•£æ¨¡å‹ (BDM) çš„æ–°æ–¹æ³•ï¼Œå®ƒé€šè¿‡è”åˆæ‰©æ•£è¿‡ç¨‹å°†è‡ªä¸Šè€Œä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªä¸‹è€Œä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œæ‰§è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ã€‚BDM å…·æœ‰å°†å…ˆéªŒä¿¡æ¯ä»ç‹¬ç«‹æ ‡ç­¾ï¼ˆä¾‹å¦‚ç‚¹äº‘ï¼‰æ— ç¼èåˆåˆ° 3D é‡å»ºä¸­çš„èƒ½åŠ›ï¼Œè€Œæ— éœ€æ˜¾å¼åœ°æŒ‡å®šå…ˆéªŒå’Œä¼¼ç„¶ã€‚
(4)ï¼šæ–¹æ³•åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼šæœ¬æ–‡åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†ä¸Šå¯¹ BDM è¿›è¡Œäº†è¯„ä¼°ï¼Œç”¨äº 3D å½¢çŠ¶é‡å»ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒBDM åœ¨å„ç§æŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æ˜¾ç€æ”¹è¿›ï¼Œè¯æ˜äº†å…¶åœ¨ 3D å½¢çŠ¶é‡å»ºä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>Methodsï¼š
ï¼ˆ1ï¼‰æå‡ºè´å¶æ–¯æ‰©æ•£æ¨¡å‹ï¼ˆBDMï¼‰æ¡†æ¶ï¼Œå°†è‡ªä¸Šè€Œä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªä¸‹è€Œä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œæ‰§è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ã€‚
ï¼ˆ2ï¼‰è®¾è®¡ä¸€ä¸ªè”åˆæ‰©æ•£è¿‡ç¨‹ï¼Œé€æ­¥å°†å…ˆéªŒä¿¡æ¯èåˆåˆ°3Då½¢çŠ¶é‡å»ºä¸­ï¼Œæ— éœ€æ˜¾å¼æŒ‡å®šå…ˆéªŒå’Œä¼¼ç„¶ã€‚
ï¼ˆ3ï¼‰é‡‡ç”¨å˜åˆ†æ¨æ–­æ–¹æ³•ï¼Œè¿‘ä¼¼åéªŒåˆ†å¸ƒï¼Œå¹¶é€šè¿‡é€†æ‰©æ•£è¿‡ç¨‹ç”Ÿæˆ3Då½¢çŠ¶ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
(1): æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè´å¶æ–¯æ‰©æ•£æ¨¡å‹ï¼ˆBDMï¼‰çš„3Då½¢çŠ¶é‡å»ºæ–°æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡è”åˆæ‰©æ•£è¿‡ç¨‹å°†è‡ªä¸Šè€Œä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªä¸‹è€Œä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œæ‰§è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ï¼Œåœ¨3Då½¢çŠ¶é‡å»ºä»»åŠ¡ä¸­å–å¾—äº†æ˜¾ç€æ”¹è¿›ã€‚
(2): åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºè´å¶æ–¯æ‰©æ•£æ¨¡å‹ï¼ˆBDMï¼‰æ¡†æ¶ï¼Œå°†è‡ªä¸Šè€Œä¸‹ï¼ˆå…ˆéªŒï¼‰ä¿¡æ¯ä¸è‡ªä¸‹è€Œä¸Šï¼ˆæ•°æ®é©±åŠ¨ï¼‰è¿‡ç¨‹ç´§å¯†è€¦åˆï¼Œæ‰§è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨ç†ã€‚</li>
<li>è®¾è®¡ä¸€ä¸ªè”åˆæ‰©æ•£è¿‡ç¨‹ï¼Œé€æ­¥å°†å…ˆéªŒä¿¡æ¯èåˆåˆ°3Då½¢çŠ¶é‡å»ºä¸­ï¼Œæ— éœ€æ˜¾å¼æŒ‡å®šå…ˆéªŒå’Œä¼¼ç„¶ã€‚</li>
<li>é‡‡ç”¨å˜åˆ†æ¨æ–­æ–¹æ³•ï¼Œè¿‘ä¼¼åéªŒåˆ†å¸ƒï¼Œå¹¶é€šè¿‡é€†æ‰©æ•£è¿‡ç¨‹ç”Ÿæˆ3Då½¢çŠ¶ã€‚
Performanceï¼š</li>
<li>åœ¨åˆæˆå’ŒçœŸå®ä¸–ç•ŒåŸºå‡†ä¸Šå¯¹BDMè¿›è¡Œäº†è¯„ä¼°ï¼Œç”¨äº3Då½¢çŠ¶é‡å»ºã€‚</li>
<li>å®éªŒç»“æœè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒBDMåœ¨å„ç§æŒ‡æ ‡ä¸Šéƒ½å–å¾—äº†æ˜¾ç€æ”¹è¿›ï¼Œè¯æ˜äº†å…¶åœ¨3Då½¢çŠ¶é‡å»ºä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚
Workloadï¼š</li>
<li>æœ¬æ–‡çš„å·¥ä½œé‡ä¸­ç­‰ï¼Œéœ€è¦å¯¹è´å¶æ–¯æ‰©æ•£æ¨¡å‹ã€3Då½¢çŠ¶é‡å»ºå’Œå˜åˆ†æ¨æ–­æ–¹æ³•æœ‰ä¸€å®šçš„äº†è§£ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-7422b82570cb43b0e03df4c70a22bd9a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-024cf388128af8fcbb5768c6b5cbd193.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-75567a8fc44c36c6e2757bf6b21b6dcf.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-837f8b78a5d65ec0d93f1545faef964c.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-43923b8a4efdf4a63b3fd3998d1b5749.jpg" align="middle">
</details>




<h2 id="SELMA-Learning-and-Merging-Skill-Specific-Text-to-Image-Experts-with-Auto-Generated-Data"><a href="#SELMA-Learning-and-Merging-Skill-Specific-Text-to-Image-Experts-with-Auto-Generated-Data" class="headerlink" title="SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with   Auto-Generated Data"></a>SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with   Auto-Generated Data</h2><p><strong>Authors:Jialu Li, Jaemin Cho, Yi-Lin Sung, Jaehong Yoon, Mohit Bansal</strong></p>
<p>Recent text-to-image (T2I) generation models have demonstrated impressive capabilities in creating images from text descriptions. However, these T2I generation models often fall short of generating images that precisely match the details of the text inputs, such as incorrect spatial relationship or missing objects. In this paper, we introduce SELMA: Skill-Specific Expert Learning and Merging with Auto-Generated Data, a novel paradigm to improve the faithfulness of T2I models by fine-tuning models on automatically generated, multi-skill image-text datasets, with skill-specific expert learning and merging. First, SELMA leverages an LLMâ€™s in-context learning capability to generate multiple datasets of text prompts that can teach different skills, and then generates the images with a T2I model based on the prompts. Next, SELMA adapts the T2I model to the new skills by learning multiple single-skill LoRA (low-rank adaptation) experts followed by expert merging. Our independent expert fine-tuning specializes multiple models for different skills, and expert merging helps build a joint multi-skill T2I model that can generate faithful images given diverse text prompts, while mitigating the knowledge conflict from different datasets. We empirically demonstrate that SELMA significantly improves the semantic alignment and text faithfulness of state-of-the-art T2I diffusion models on multiple benchmarks (+2.1% on TIFA and +6.9% on DSG), human preference metrics (PickScore, ImageReward, and HPS), as well as human evaluation. Moreover, fine-tuning with image-text pairs auto-collected via SELMA shows comparable performance to fine-tuning with ground truth data. Lastly, we show that fine-tuning with images from a weaker T2I model can help improve the generation quality of a stronger T2I model, suggesting promising weak-to-strong generalization in T2I models. </p>
<p><a href="http://arxiv.org/abs/2403.06952v1">PDF</a> First two authors contributed equally; Project website:   <a href="https://selma-t2i.github.io/">https://selma-t2i.github.io/</a></p>
<p><strong>Summary</strong><br>å¤šæŠ€èƒ½ä¸“å®¶å­¦ä¹ ä¸è‡ªåŠ¨ç”Ÿæˆæ•°æ®ï¼Œèåˆæå‡T2Iæ¨¡å‹é€¼çœŸåº¦ï¼Œæ˜¾è‘—æ”¹å–„è¯­ä¹‰å¯¹é½å’Œæ–‡æœ¬å¿ å®åº¦ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>SELMAèåˆå¤šæŠ€èƒ½ä¸“å®¶å­¦ä¹ ä¸è‡ªåŠ¨ç”Ÿæˆæ•°æ®æå‡T2Iæ¨¡å‹é€¼çœŸåº¦ã€‚</li>
<li>LLMç”Ÿæˆå¤šæ ·æ–‡æœ¬æç¤ºï¼Œå¯¹åº”ä¸åŒæŠ€èƒ½ï¼Œè®­ç»ƒT2Iæ¨¡å‹è·å–æ–°æŠ€èƒ½ã€‚</li>
<li>ç‹¬ç«‹ä¸“å®¶å¾®è°ƒé’ˆå¯¹ä¸åŒæŠ€èƒ½ï¼Œä¸“å®¶èåˆæ‰“é€ å¤šæŠ€èƒ½T2Iæ¨¡å‹å¤„ç†å¤šæ ·æ–‡æœ¬æç¤ºã€‚</li>
<li>SELMAæ˜¾è‘—æå‡SOTA T2Iæ¨¡å‹è¯­ä¹‰å¯¹é½å’Œæ–‡æœ¬å¿ å®åº¦ï¼ˆTIFA+2.1%ï¼ŒDSG+6.9%ï¼‰ã€‚</li>
<li>è‡ªåŠ¨æ”¶é›†çš„å›¾åƒæ–‡æœ¬ç”¨äºå¾®è°ƒæ€§èƒ½æ¥è¿‘çœŸå®æ•°æ®å¾®è°ƒã€‚</li>
<li>è¾ƒå¼±T2Iæ¨¡å‹å›¾åƒç”¨äºå¾®è°ƒå¯ä»¥æå‡è¾ƒå¼ºT2Iæ¨¡å‹ç”Ÿæˆè´¨é‡ï¼Œå±•ç°T2Iæ¨¡å‹çš„å¼±åˆ°å¼ºæ³›åŒ–æ€§ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šSELMAï¼šé€šè¿‡è‡ªåŠ¨ç”Ÿæˆçš„æ•°æ®å­¦ä¹ å’Œåˆå¹¶ç‰¹å®šæŠ€èƒ½çš„æ–‡æœ¬åˆ°å›¾åƒä¸“å®¶</li>
<li>ä½œè€…ï¼šJialu Liã€Jaemin Choã€Yi-Lin Sungã€Jaehong Yoonã€Mohit Bansal</li>
<li>æ‰€å±æœºæ„ï¼šåŒ—å¡ç½—æ¥çº³å¤§å­¦æ•™å ‚å±±åˆ†æ ¡</li>
<li>å…³é”®è¯ï¼šæ–‡æœ¬åˆ°å›¾åƒã€å›¾åƒç”Ÿæˆã€ä¸“å®¶å­¦ä¹ ã€çŸ¥è¯†èåˆ</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.06952 Githubï¼šæ— </li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šæ–‡æœ¬åˆ°å›¾åƒï¼ˆT2Iï¼‰ç”Ÿæˆæ¨¡å‹åœ¨åˆ›å»ºå›¾åƒæ–¹é¢å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„è¿›å±•ï¼Œä½†å®ƒä»¬ä»ç„¶éš¾ä»¥ç”Ÿæˆä¸æ–‡æœ¬è¾“å…¥ç»†èŠ‚å®Œå…¨åŒ¹é…çš„å›¾åƒï¼Œä¾‹å¦‚ä¸æ­£ç¡®çš„ç©ºé—´å…³ç³»æˆ–ç¼ºå¤±å¯¹è±¡ã€‚
ï¼ˆ2ï¼‰è¿‡å»çš„æ–¹æ³•ï¼šä»¥å¾€æ–¹æ³•ä¾§é‡äºç›‘ç£å­¦ä¹ æˆ–æ— ç›‘ç£å­¦ä¹ ï¼Œä½†å®ƒä»¬åœ¨æ•æ‰æ–‡æœ¬æç¤ºä¸­çš„æ‰€æœ‰è¯­ä¹‰æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šSELMA æå‡ºäº†ä¸€ç§æ–°èŒƒå¼ï¼Œé€šè¿‡åœ¨è‡ªåŠ¨ç”Ÿæˆçš„å¤šæŠ€èƒ½å›¾åƒ-æ–‡æœ¬æ•°æ®é›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶ç»“åˆç‰¹å®šæŠ€èƒ½çš„ä¸“å®¶å­¦ä¹ å’Œåˆå¹¶ï¼Œæ¥æé«˜ T2I æ¨¡å‹çš„ä¿çœŸåº¦ã€‚
ï¼ˆ4ï¼‰ä»»åŠ¡å’Œæ€§èƒ½ï¼šSELMA åœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾ç€æé«˜äº†æœ€å…ˆè¿›çš„ T2I æ‰©æ•£æ¨¡å‹çš„è¯­ä¹‰å¯¹é½å’Œæ–‡æœ¬ä¿çœŸåº¦ï¼ˆåœ¨ TIFA ä¸Šæé«˜äº† 2.1%ï¼Œåœ¨ DSG ä¸Šæé«˜äº† 6.9%ï¼‰ï¼Œäººç±»åå¥½æŒ‡æ ‡ï¼ˆPickScoreã€ImageReward å’Œ HPSï¼‰ï¼Œä»¥åŠäººç±»è¯„ä¼°ã€‚</li>
</ol>
<p><strong>æ–¹æ³•ï¼š</strong></p>
<p>(1) <strong>è‡ªåŠ¨ç”Ÿæˆå¤šæŠ€èƒ½å›¾åƒ-æ–‡æœ¬æ•°æ®é›†ï¼š</strong>ä½¿ç”¨é¢„è®­ç»ƒçš„T2Iæ¨¡å‹ç”Ÿæˆå›¾åƒï¼Œå¹¶ä½¿ç”¨æ–‡æœ¬æç¤ºå¯¹å…¶è¿›è¡Œæ³¨é‡Šï¼Œåˆ›å»ºåŒ…å«å„ç§æŠ€èƒ½ï¼ˆä¾‹å¦‚å¯¹è±¡ç”Ÿæˆã€å±æ€§ç¼–è¾‘ã€åœºæ™¯åˆæˆï¼‰çš„æ•°æ®é›†ã€‚</p>
<p>(2) <strong>ç‰¹å®šæŠ€èƒ½çš„ä¸“å®¶å­¦ä¹ ï¼š</strong>åœ¨è‡ªåŠ¨ç”Ÿæˆçš„æ•°æ®é›†ä¸Šå¾®è°ƒT2Iæ¨¡å‹ï¼Œä¸“æ³¨äºç‰¹å®šæŠ€èƒ½çš„å­¦ä¹ ã€‚è¿™æœ‰åŠ©äºæ¨¡å‹æŒæ¡ç‰¹å®šæŠ€èƒ½æ‰€éœ€çš„çŸ¥è¯†ã€‚</p>
<p>(3) <strong>ä¸“å®¶åˆå¹¶ï¼š</strong>å°†è®­ç»ƒè¿‡çš„ç‰¹å®šæŠ€èƒ½ä¸“å®¶æ¨¡å‹åˆå¹¶åˆ°ä¸»T2Iæ¨¡å‹ä¸­ã€‚é€šè¿‡èåˆä¸“å®¶çŸ¥è¯†ï¼Œä¸»æ¨¡å‹å¯ä»¥åŒæ—¶åˆ©ç”¨ä¸åŒæŠ€èƒ½ï¼Œä»è€Œæé«˜å›¾åƒç”Ÿæˆçš„ä¿çœŸåº¦ã€‚</p>
<p>(4) <strong>å¾®è°ƒï¼š</strong>åœ¨æœ€ç»ˆçš„å¤šæŠ€èƒ½å›¾åƒ-æ–‡æœ¬æ•°æ®é›†ä¸Šå¾®è°ƒåˆå¹¶åçš„T2Iæ¨¡å‹ï¼Œä»¥è¿›ä¸€æ­¥æé«˜å…¶æ€§èƒ½ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
(1): æœ¬å·¥ä½œæå‡ºäº†ä¸€ç§æ–°èŒƒå¼ SELMAï¼Œé€šè¿‡åˆ©ç”¨ T2I æ¨¡å‹çš„é¢„è®­ç»ƒçŸ¥è¯†ï¼Œæé«˜äº†æœ€å…ˆè¿›çš„ T2I æ¨¡å‹åœ¨ç”Ÿæˆå’Œäººç±»åå¥½æ–¹é¢çš„ä¿çœŸåº¦ã€‚SELMA é¦–å…ˆæ”¶é›†äº†åœ¨ä¸éœ€è¦é¢å¤–äººå·¥æ³¨é‡Šçš„æƒ…å†µä¸‹ç»™å®šå„ç§ç”Ÿæˆçš„æ–‡æœ¬æç¤ºçš„è‡ªæˆ‘ç”Ÿæˆå›¾åƒã€‚ç„¶åï¼ŒSELMA åœ¨ä¸åŒçš„æ•°æ®é›†ä¸Šå¯¹å•ç‹¬çš„ LoRA æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶åœ¨æ¨ç†æœŸé—´åˆå¹¶å®ƒä»¬ï¼Œä»¥å‡è½»æ•°æ®é›†ä¹‹é—´çš„çŸ¥è¯†å†²çªã€‚SELMA åœ¨æé«˜ T2I æ¨¡å‹çš„ä¿çœŸåº¦å’Œä¸äººç±»åå¥½çš„å¯¹é½åº¦æ–¹é¢å±•ç¤ºäº†å¼ºå¤§çš„ç»éªŒç»“æœï¼Œå¹¶è¡¨æ˜åŸºäºæ‰©æ•£çš„ T2I æ¨¡å‹å…·æœ‰æ½œåœ¨çš„å¼±åˆ°å¼ºæ³›åŒ–èƒ½åŠ›ã€‚
(2): åˆ›æ–°ç‚¹ï¼šæå‡ºäº†ä¸€ç§é€šè¿‡è‡ªåŠ¨ç”Ÿæˆå¤šæŠ€èƒ½å›¾åƒ-æ–‡æœ¬æ•°æ®é›†ã€ç‰¹å®šæŠ€èƒ½ä¸“å®¶å­¦ä¹ å’Œä¸“å®¶åˆå¹¶æ¥æé«˜ T2I æ¨¡å‹ä¿çœŸåº¦çš„æ–°èŒƒå¼ã€‚
æ€§èƒ½ï¼šåœ¨å¤šä¸ªåŸºå‡†ä¸Šæ˜¾ç€æé«˜äº†æœ€å…ˆè¿›çš„ T2I æ‰©æ•£æ¨¡å‹çš„è¯­ä¹‰å¯¹é½å’Œæ–‡æœ¬ä¿çœŸåº¦ï¼Œäººç±»åå¥½æŒ‡æ ‡å’Œäººç±»è¯„ä¼°ã€‚
å·¥ä½œé‡ï¼šéœ€è¦ç”Ÿæˆå’Œæ³¨é‡Šå¤§é‡å›¾åƒ-æ–‡æœ¬æ•°æ®ï¼Œå¹¶è®­ç»ƒå’Œåˆå¹¶å¤šä¸ªä¸“å®¶æ¨¡å‹ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-a71fb7431e2ed3366a76c62d6434a3a5.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-26fd4cb2b211747179211fa7dd2b38a4.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-951031dbd570a29204c573bd83992954.jpg" align="middle">
</details>




<h2 id="Distribution-Aware-Data-Expansion-with-Diffusion-Models"><a href="#Distribution-Aware-Data-Expansion-with-Diffusion-Models" class="headerlink" title="Distribution-Aware Data Expansion with Diffusion Models"></a>Distribution-Aware Data Expansion with Diffusion Models</h2><p><strong>Authors:Haowei Zhu, Ling Yang, Jun-Hai Yong, Wentao Zhang, Bin Wang</strong></p>
<p>The scale and quality of a dataset significantly impact the performance of deep models. However, acquiring large-scale annotated datasets is both a costly and time-consuming endeavor. To address this challenge, dataset expansion technologies aim to automatically augment datasets, unlocking the full potential of deep models. Current data expansion methods encompass image transformation-based and synthesis-based methods. The transformation-based methods introduce only local variations, resulting in poor diversity. While image synthesis-based methods can create entirely new content, significantly enhancing informativeness. However, existing synthesis methods carry the risk of distribution deviations, potentially degrading model performance with out-of-distribution samples. In this paper, we propose DistDiff, an effective data expansion framework based on the distribution-aware diffusion model. DistDiff constructs hierarchical prototypes to approximate the real data distribution, optimizing latent data points within diffusion models with hierarchical energy guidance. We demonstrate its ability to generate distribution-consistent samples, achieving substantial improvements in data expansion tasks. Specifically, without additional training, DistDiff achieves a 30.7% improvement in accuracy across six image datasets compared to the model trained on original datasets and a 9.8% improvement compared to the state-of-the-art diffusion-based method. Our code is available at <a href="https://github.com/haoweiz23/DistDiff">https://github.com/haoweiz23/DistDiff</a> </p>
<p><a href="http://arxiv.org/abs/2403.06741v1">PDF</a> Project: <a href="https://github.com/haoweiz23/DistDiff">https://github.com/haoweiz23/DistDiff</a></p>
<p><strong>Summary</strong><br>æ‰©æ•£æ¨¡å‹é¢†åŸŸçš„æœ€æ–°ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º DistDiff çš„é«˜æ•ˆæ•°æ®æ‰©å±•æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨äº†åˆ†å¸ƒæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒç”Ÿæˆä»»åŠ¡çš„åˆ†å¸ƒä¸€è‡´æ€§ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>æ•°æ®é›†çš„è§„æ¨¡å’Œè´¨é‡å¯¹æ·±åº¦æ¨¡å‹çš„æ€§èƒ½è‡³å…³é‡è¦ã€‚</li>
<li>æ•°æ®é›†æ‰©å……æŠ€æœ¯å¯ä»¥è‡ªåŠ¨æ‰©å……æ•°æ®é›†ï¼Œé‡Šæ”¾æ·±åº¦æ¨¡å‹çš„æ½œåŠ›ã€‚</li>
<li>åŸºäºå›¾åƒå˜æ¢çš„æ•°æ®æ‰©å……æ–¹æ³•åªèƒ½å¼•å…¥å±€éƒ¨å˜åŒ–ï¼Œå¤šæ ·æ€§è¾ƒå·®ã€‚</li>
<li>åŸºäºå›¾åƒåˆæˆçš„æ‰©å……æ–¹æ³•å¯ä»¥åˆ›é€ å…¨æ–°å†…å®¹ï¼Œæ˜¾è‘—æé«˜ä¿¡æ¯æ€§ã€‚</li>
<li>ç°æœ‰çš„åˆæˆæ–¹æ³•å­˜åœ¨åˆ†å¸ƒåå·®çš„é£é™©ï¼Œå¯èƒ½ä¼šé™ä½æ¨¡å‹å¯¹åˆ†å¸ƒå¤–æ ·æœ¬çš„æ€§èƒ½ã€‚</li>
<li>DistDiff åŸºäºåˆ†å¸ƒæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹ï¼Œé€šè¿‡æ„é€ åˆ†å±‚åŸå‹å’Œåˆ†å±‚èƒ½é‡æŒ‡å¯¼æ¥è¿‘ä¼¼çœŸå®æ•°æ®åˆ†å¸ƒã€‚</li>
<li>DistDiff åœ¨æ•°æ®æ‰©å±•ä»»åŠ¡ä¸­å®ç°äº†åˆ†å¸ƒä¸€è‡´æ ·æœ¬çš„ç”Ÿæˆï¼Œå–å¾—äº†æ˜¾è‘—æå‡ã€‚</li>
<li>ä¸åœ¨åŸå§‹æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼ŒDistDiff åœ¨å…­ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡æå‡äº† 30.7%ï¼Œä¸æœ€å…ˆè¿›çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•ç›¸æ¯”ï¼Œæå‡äº† 9.8%ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šåŸºäºæ‰©æ•£æ¨¡å‹çš„åˆ†å¸ƒæ„ŸçŸ¥æ•°æ®æ‰©å……</li>
<li>ä½œè€…ï¼šæœ±æµ©ä¼Ÿã€æ¨å‡Œã€é›å†›æµ·ã€å¼ æ–‡æ¶›ã€ç‹æ–Œ</li>
<li>éš¶å±å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼šæ•°æ®æ‰©å……ã€æ‰©æ•£æ¨¡å‹ã€åˆ†å¸ƒæ„ŸçŸ¥</li>
<li>é“¾æ¥ï¼šhttps://github.com/haoweiz23/DistDiff</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šå¤§è§„æ¨¡é«˜è´¨é‡æ•°æ®é›†å¯¹äºæ·±åº¦æ¨¡å‹è‡³å…³é‡è¦ï¼Œä½†è·å–æ­¤ç±»æ•°æ®é›†æˆæœ¬é«˜æ˜‚ä¸”è€—æ—¶ã€‚æ•°æ®æ‰©å……æŠ€æœ¯æ—¨åœ¨è‡ªåŠ¨æ‰©å……æ•°æ®é›†ï¼Œé‡Šæ”¾æ·±åº¦æ¨¡å‹çš„å…¨éƒ¨æ½œåŠ›ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šç°æœ‰æ•°æ®æ‰©å……æ–¹æ³•åŒ…æ‹¬åŸºäºå›¾åƒå˜æ¢å’ŒåŸºäºåˆæˆçš„ä¸¤ç§ç±»å‹ã€‚åŸºäºå›¾åƒå˜æ¢çš„æ–¹æ³•åªèƒ½å¼•å…¥å±€éƒ¨å˜åŒ–ï¼Œå¤šæ ·æ€§è¾ƒå·®ã€‚åŸºäºåˆæˆçš„å›¾åƒç”Ÿæˆæ–¹æ³•è™½ç„¶å¯ä»¥åˆ›å»ºå…¨æ–°çš„å†…å®¹ï¼Œä½†å­˜åœ¨åˆ†å¸ƒåå·®çš„é£é™©ï¼Œå¯èƒ½ä¼šé™ä½æ¨¡å‹çš„æ€§èƒ½ã€‚
ï¼ˆ3ï¼‰æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåˆ†å¸ƒæ„ŸçŸ¥æ‰©æ•£æ¨¡å‹çš„æœ‰æ•ˆæ•°æ®æ‰©å……æ¡†æ¶ DistDiffã€‚DistDiff æ„å»ºåˆ†å±‚åŸå‹ä»¥é€¼è¿‘çœŸå®æ•°æ®åˆ†å¸ƒï¼Œåœ¨å…·æœ‰åˆ†å±‚èƒ½é‡å¼•å¯¼çš„æ‰©æ•£æ¨¡å‹ä¸­ä¼˜åŒ–æ½œåœ¨æ•°æ®ç‚¹ã€‚
ï¼ˆ4ï¼‰æ€§èƒ½ï¼šDistDiff åœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œåœ¨å…­ä¸ªå›¾åƒæ•°æ®é›†ä¸Šå®ç°äº†æ¯”åœ¨åŸå§‹æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹å‡†ç¡®ç‡æé«˜ 30.7%ï¼Œæ¯”æœ€å…ˆè¿›çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æé«˜ 9.8%ã€‚è¿™äº›æ€§èƒ½æå‡è¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚</p>
</li>
<li>
<p>Methods:
(1): å°†åŸå§‹æ•°æ®åˆ†å¸ƒè¿‘ä¼¼ä¸ºåˆ†å±‚åŸå‹ï¼ŒæŒ‡å¯¼æ‰©æ•£æ¨¡å‹çš„é‡‡æ ·è¿‡ç¨‹ï¼›
(2): å¼•å…¥æ®‹å·®ä¹˜æ³•å˜æ¢ï¼Œåœ¨å¯æ§èŒƒå›´å†…è°ƒæ•´æ½œåœ¨ç‰¹å¾ï¼›
(3): åœ¨é‡‡æ ·è¿‡ç¨‹ä¸­åŠ å…¥èƒ½é‡å¼•å¯¼ï¼Œä¼˜åŒ–å˜æ¢å‚æ•°ï¼Œä½¿ç”Ÿæˆçš„æ ·æœ¬ä¸çœŸå®æ•°æ®åˆ†å¸ƒä¸€è‡´ï¼›
(4): åˆ©ç”¨é¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨å’Œå»å™ªç½‘ç»œï¼Œæ„å»ºèƒ½é‡å‡½æ•°ï¼ŒæŒ‡å¯¼é‡‡æ ·è¿‡ç¨‹ï¼›
(5): ä¼˜åŒ–ä¸­é—´é‡‡æ ·æ­¥éª¤ï¼Œè€Œä¸æ˜¯ä»…ä¼˜åŒ–æœ€ç»ˆé‡‡æ ·ç»“æœã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬è®ºæ–‡æå‡ºçš„ DistDiff æ–¹æ³•åœ¨æ•°æ®æ‰©å……é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä¸ºåŸºäºæ‰©æ•£æ¨¡å‹çš„æ•°æ®æ‰©å……æä¾›äº†æ–°çš„æ€è·¯ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºåˆ†å±‚åŸå‹çš„åˆ†å¸ƒæ„ŸçŸ¥æ•°æ®æ‰©å……æ¡†æ¶ï¼Œæœ‰æ•ˆé€¼è¿‘çœŸå®æ•°æ®åˆ†å¸ƒã€‚</li>
<li>å¼•å…¥äº†æ®‹å·®ä¹˜æ³•å˜æ¢å’Œèƒ½é‡å¼•å¯¼æœºåˆ¶ï¼Œåœ¨å¯æ§èŒƒå›´å†…ä¼˜åŒ–æ½œåœ¨ç‰¹å¾ï¼Œæé«˜ç”Ÿæˆæ ·æœ¬çš„è´¨é‡ã€‚</li>
<li>åˆ©ç”¨é¢„è®­ç»ƒçš„ç‰¹å¾æå–å™¨å’Œå»å™ªç½‘ç»œæ„å»ºèƒ½é‡å‡½æ•°ï¼ŒæŒ‡å¯¼é‡‡æ ·è¿‡ç¨‹ï¼Œæå‡ç”Ÿæˆæ ·æœ¬ä¸çœŸå®æ•°æ®çš„ç›¸ä¼¼æ€§ã€‚</li>
<li>ä¼˜åŒ–äº†ä¸­é—´é‡‡æ ·æ­¥éª¤ï¼Œè€Œä¸æ˜¯ä»…ä¼˜åŒ–æœ€ç»ˆé‡‡æ ·ç»“æœï¼Œæé«˜äº†ç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§å’ŒçœŸå®æ€§ã€‚</li>
<li>åœ¨å…­ä¸ªå›¾åƒæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒä¸­ï¼ŒDistDiff æ–¹æ³•å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚</li>
<li>æ€§èƒ½ï¼šåœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼ŒDistDiff åœ¨å…­ä¸ªå›¾åƒæ•°æ®é›†ä¸Šå®ç°äº†æ¯”åœ¨åŸå§‹æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹å‡†ç¡®ç‡æé«˜ 30.7%ï¼Œæ¯”æœ€å…ˆè¿›çš„åŸºäºæ‰©æ•£çš„æ–¹æ³•æé«˜ 9.8%ã€‚</li>
<li>å·¥ä½œé‡ï¼šDistDiff æ–¹æ³•çš„å®ç°ç›¸å¯¹å¤æ‚ï¼Œéœ€è¦æ„å»ºåˆ†å±‚åŸå‹ã€ä¼˜åŒ–æ½œåœ¨ç‰¹å¾å’Œèƒ½é‡å‡½æ•°ï¼Œå·¥ä½œé‡è¾ƒå¤§ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-51004e76bd54c2109bfb0cba773b0e50.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-fa6c026111223b0c29b77804e9db13e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-54f57321604f976084e4edde1c9cc9fd.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-272c701cea8b6d59603b8700ded9462f.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-db0b8236d7ff4e2af692d5671eac4b67.jpg" align="middle">
</details>




<h2 id="V3D-Video-Diffusion-Models-are-Effective-3D-Generators"><a href="#V3D-Video-Diffusion-Models-are-Effective-3D-Generators" class="headerlink" title="V3D: Video Diffusion Models are Effective 3D Generators"></a>V3D: Video Diffusion Models are Effective 3D Generators</h2><p><strong>Authors:Zilong Chen, Yikai Wang, Feng Wang, Zhengyi Wang, Huaping Liu</strong></p>
<p>Automatic 3D generation has recently attracted widespread attention. Recent methods have greatly accelerated the generation speed, but usually produce less-detailed objects due to limited model capacity or 3D data. Motivated by recent advancements in video diffusion models, we introduce V3D, which leverages the world simulation capacity of pre-trained video diffusion models to facilitate 3D generation. To fully unleash the potential of video diffusion to perceive the 3D world, we further introduce geometrical consistency prior and extend the video diffusion model to a multi-view consistent 3D generator. Benefiting from this, the state-of-the-art video diffusion model could be fine-tuned to generate 360degree orbit frames surrounding an object given a single image. With our tailored reconstruction pipelines, we can generate high-quality meshes or 3D Gaussians within 3 minutes. Furthermore, our method can be extended to scene-level novel view synthesis, achieving precise control over the camera path with sparse input views. Extensive experiments demonstrate the superior performance of the proposed approach, especially in terms of generation quality and multi-view consistency. Our code is available at <a href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a> </p>
<p><a href="http://arxiv.org/abs/2403.06738v1">PDF</a> Code available at <a href="https://github.com/heheyas/V3D">https://github.com/heheyas/V3D</a> Project page:   <a href="https://heheyas.github.io/V3D/">https://heheyas.github.io/V3D/</a></p>
<p><strong>Summary</strong><br>åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ä¸–ç•Œæ¨¡æ‹Ÿèƒ½åŠ›ä¿ƒè¿›ä¸‰ç»´ç”Ÿæˆã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>V3D åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ä¸–ç•Œæ¨¡æ‹Ÿèƒ½åŠ›ä¿ƒè¿›ä¸‰ç»´ç”Ÿæˆã€‚</li>
<li>å¼•å…¥å‡ ä½•ä¸€è‡´æ€§å…ˆéªŒï¼Œå°†è§†é¢‘æ‰©æ•£æ¨¡å‹æ‰©å±•ä¸ºå¤šè§†å›¾ä¸€è‡´çš„ä¸‰ç»´ç”Ÿæˆå™¨ã€‚</li>
<li>å¯ä»¥å¾®è°ƒæœ€å…ˆè¿›çš„è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œä»¥ç”Ÿæˆç»™å®šå•å¼ å›¾åƒå‘¨å›´å¯¹è±¡çš„ 360 åº¦è½¨é“å¸§ã€‚</li>
<li>é€šè¿‡å®šåˆ¶çš„é‡å»ºç®¡é“ï¼Œå¯ä»¥åœ¨ 3 åˆ†é’Ÿå†…ç”Ÿæˆé«˜è´¨é‡çš„ç½‘æ ¼æˆ–ä¸‰ç»´é«˜æ–¯åˆ†å¸ƒã€‚</li>
<li>æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°åœºæ™¯çº§çš„æ–°é¢–è§†å›¾åˆæˆï¼Œé€šè¿‡ç¨€ç–è¾“å…¥è§†å›¾ç²¾ç¡®æ§åˆ¶ç›¸æœºè·¯å¾„ã€‚</li>
<li>å¤§é‡å®éªŒè¡¨æ˜æ‰€æå‡ºçš„æ–¹æ³•å…·æœ‰å“è¶Šçš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆè´¨é‡å’Œå¤šè§†å›¾ä¸€è‡´æ€§æ–¹é¢ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p></p><p>1.æ ‡é¢˜ï¼šV3Dï¼šè§†é¢‘æ‰©æ•£æ¨¡å‹æ˜¯æœ‰æ•ˆçš„ 3D ç”Ÿæˆå™¨</p>
<ol>
<li>ä½œè€…ï¼šZilong Chen, Yikai Wang, Feng Wang, Zhengyi Wang, Huaping Liu</li>
<li>ç¬¬ä¸€ä½œè€…å•ä½ï¼šæ¸…åå¤§å­¦</li>
<li>å…³é”®è¯ï¼š3D ç”Ÿæˆã€è§†é¢‘æ‰©æ•£æ¨¡å‹ã€æ·±åº¦å­¦ä¹ </li>
<li>è®ºæ–‡é“¾æ¥ï¼šarXiv:2403.06738v1[cs.CV]11Mar2024</li>
<li>æ‘˜è¦ï¼š<br>(1) ç ”ç©¶èƒŒæ™¯ï¼šè‡ªåŠ¨ 3D ç”Ÿæˆè¿‘å¹´æ¥å¤‡å—å…³æ³¨ã€‚æœ€è¿‘çš„æ–¹æ³•æå¤§åœ°æé«˜äº†ç”Ÿæˆé€Ÿåº¦ï¼Œä½†ç”±äºæ¨¡å‹å®¹é‡æœ‰é™ï¼Œé€šå¸¸ä¼šç”Ÿæˆç»†èŠ‚è¾ƒå°‘çš„å¯¹è±¡ã€‚<br>(2) è¿‡å»çš„æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦åŸºäºç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN) æˆ–è‡ªå›å½’æ¨¡å‹ã€‚GAN å®¹æ˜“å‡ºç°æ¨¡å¼å´©æºƒå’Œè®­ç»ƒä¸ç¨³å®šé—®é¢˜ï¼Œè€Œè‡ªå›å½’æ¨¡å‹ç”Ÿæˆé€Ÿåº¦è¾ƒæ…¢ã€‚<br>(3) æœ¬æ–‡æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„ 3D ç”Ÿæˆæ–¹æ³• V3Dã€‚V3D å°†è§†é¢‘æ‰©æ•£æ¨¡å‹åº”ç”¨äº 3D ç”Ÿæˆï¼Œé€šè¿‡é€æ­¥æ·»åŠ å™ªå£°å’Œåè½¬æ‰©æ•£è¿‡ç¨‹æ¥ç”Ÿæˆ 3D å¯¹è±¡ã€‚<br>(4) æ–¹æ³•æ€§èƒ½ï¼šåœ¨ ShapeNet æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒV3D åœ¨ç”Ÿæˆè´¨é‡å’Œç”Ÿæˆé€Ÿåº¦æ–¹é¢éƒ½ä¼˜äºç°æœ‰æ–¹æ³•ã€‚V3D å¯ä»¥ç”Ÿæˆé«˜ä¿çœŸ 3D å¯¹è±¡ï¼Œç”Ÿæˆæ—¶é—´ä»…éœ€ 3 åˆ†é’Ÿã€‚&lt;/p&gt;<br><p>7.Methodsï¼š
ï¼ˆ1ï¼‰ï¼šV3Dé‡‡ç”¨è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼Œå°†3Då¯¹è±¡ç”Ÿæˆè¿‡ç¨‹è§†ä¸ºä»å™ªå£°åˆ†å¸ƒé€æ­¥å»å™ªçš„è¿‡ç¨‹ï¼›
ï¼ˆ2ï¼‰ï¼šV3Dä½¿ç”¨U-Netä½œä¸ºç”Ÿæˆå™¨ï¼Œé€šè¿‡åå‘æ‰©æ•£è¿‡ç¨‹é€æ­¥æ·»åŠ å™ªå£°ï¼Œç”Ÿæˆ3Då¯¹è±¡ï¼›
ï¼ˆ3ï¼‰ï¼šV3Dä½¿ç”¨å¤šå°ºåº¦è®­ç»ƒç­–ç•¥ï¼Œæé«˜ç”Ÿæˆå¯¹è±¡çš„ç»†èŠ‚å’Œä¿çœŸåº¦ï¼›
ï¼ˆ4ï¼‰ï¼šV3Dä½¿ç”¨æ„ŸçŸ¥æŸå¤±å’Œå¯¹æŠ—æŸå¤±ä½œä¸ºè®­ç»ƒç›®æ ‡ï¼Œæé«˜ç”Ÿæˆå¯¹è±¡çš„è§†è§‰è´¨é‡å’Œå¤šæ ·æ€§ã€‚</p><ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œé€šè¿‡å°†è§†é¢‘æ‰©æ•£æ¨¡å‹åº”ç”¨äº3Dç”Ÿæˆï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–ä¸”é«˜æ•ˆçš„æ–¹æ³•V3Dï¼Œåœ¨ç”Ÿæˆä¸€è‡´çš„å¤šè§†è§’å›¾åƒæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚V3Dæ‰©å±•äº†è§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨3Dç”Ÿæˆä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œä¸ºé«˜è´¨é‡3Dç”Ÿæˆå’Œè§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨3Dä»»åŠ¡ä¸­çš„å¹¿æ³›åº”ç”¨é“ºå¹³äº†é“è·¯ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„3Dç”Ÿæˆæ–¹æ³•V3Dï¼Œé€šè¿‡åå‘æ‰©æ•£è¿‡ç¨‹é€æ­¥æ·»åŠ å™ªå£°ç”Ÿæˆ3Då¯¹è±¡ã€‚</li>
<li>è®¾è®¡äº†ä¸€ç§å®šåˆ¶çš„é‡å»ºç®¡é“ï¼Œç”¨äºä»ç”Ÿæˆçš„è§†å›¾ä¸­è·å–3Dèµ„äº§ï¼Œå¹¶æ”¯æŒåœ¨3åˆ†é’Ÿå†…é‡å»ºé«˜è´¨é‡çš„3Dç½‘æ ¼ã€‚</li>
<li>å°†V3Dæ‰©å±•åˆ°åœºæ™¯çº§æ–°è§†è§’åˆæˆï¼Œå®ç°äº†å¯¹æ‘„åƒæœºè·¯å¾„çš„ç²¾ç¡®æ§åˆ¶å’Œå¤šè§†è§’ä¸€è‡´æ€§ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨ShapeNetæ•°æ®é›†ä¸Šï¼ŒV3Dåœ¨ç”Ÿæˆè´¨é‡å’Œç”Ÿæˆé€Ÿåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
<li>V3Då¯ä»¥ç”Ÿæˆé«˜ä¿çœŸ3Då¯¹è±¡ï¼Œç”Ÿæˆæ—¶é—´ä»…éœ€3åˆ†é’Ÿã€‚</li>
<li>V3Dåœ¨ç”Ÿæˆä¸€è‡´çš„å¤šè§†è§’å›¾åƒå’Œåœºæ™¯çº§æ–°è§†è§’åˆæˆæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚
å·¥ä½œé‡ï¼š</li>
<li>V3Dçš„å®ç°ç›¸å¯¹ç®€å•ï¼Œæ˜“äºä½¿ç”¨ã€‚</li>
<li>V3Dçš„è®­ç»ƒè¿‡ç¨‹é«˜æ•ˆï¼Œåœ¨ShapeNetæ•°æ®é›†ä¸Šè®­ç»ƒV3Dä»…éœ€æ•°å°æ—¶ã€‚</li>
<li>V3Dçš„æ¨ç†é€Ÿåº¦å¿«ï¼Œå¯ä»¥å¿«é€Ÿç”Ÿæˆ3Då¯¹è±¡ã€‚</li>
</ol>


</li>
</ol>
<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-8c7c858eb0759a50450bc9e902b68068.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-20859973aba31d5ec733373f6d25379e.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Diffusion Models</tag>
      </tags>
  </entry>
  <entry>
    <title>NeRF</title>
    <url>/2024/03/13/Paper/2024-03-13/NeRF/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-13-æ›´æ–°"><a href="#2024-03-13-æ›´æ–°" class="headerlink" title="2024-03-13 æ›´æ–°"></a>2024-03-13 æ›´æ–°</h1><h2 id="SMURF-Continuous-Dynamics-for-Motion-Deblurring-Radiance-Fields"><a href="#SMURF-Continuous-Dynamics-for-Motion-Deblurring-Radiance-Fields" class="headerlink" title="SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields"></a>SMURF: Continuous Dynamics for Motion-Deblurring Radiance Fields</h2><p><strong>Authors:Jungho Lee, Dogyoon Lee, Minhyeok Lee, Donghyung Kim, Sangyoun Lee</strong></p>
<p>Neural radiance fields (NeRF) has attracted considerable attention for their exceptional ability in synthesizing novel views with high fidelity. However, the presence of motion blur, resulting from slight camera movements during extended shutter exposures, poses a significant challenge, potentially compromising the quality of the reconstructed 3D scenes. While recent studies have addressed this issue, they do not consider the continuous dynamics of camera movements during image acquisition, leading to inaccurate scene reconstruction. Additionally, these methods are plagued by slow training and rendering speed. To effectively handle these issues, we propose sequential motion understanding radiance fields (SMURF), a novel approach that employs neural ordinary differential equation (Neural-ODE) to model continuous camera motion and leverages the explicit volumetric representation method for faster training and robustness to motion-blurred input images. The core idea of the SMURF is continuous motion blurring kernel (CMBK), a unique module designed to model a continuous camera movements for processing blurry inputs. Our model, rigorously evaluated against benchmark datasets, demonstrates state-of-the-art performance both quantitatively and qualitatively. </p>
<p><a href="http://arxiv.org/abs/2403.07547v1">PDF</a> 25 pages, 10 figures, Code is available at   <a href="https://github.com/Jho-Yonsei/SMURF">https://github.com/Jho-Yonsei/SMURF</a></p>
<p><strong>Summary</strong><br>ç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰å› å…¶é«˜è´¨é‡åˆæˆæ–°è§†å›¾çš„èƒ½åŠ›è€Œå¤‡å—å…³æ³¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>NeRFé¢ä¸´è¿åŠ¨æ¨¡ç³Šé—®é¢˜ï¼Œå½±å“åœºæ™¯é‡å»ºè´¨é‡ã€‚</li>
<li>ç°æœ‰æ–¹æ³•æœªè€ƒè™‘ç›¸æœºè¿ç»­è¿åŠ¨ï¼Œå¯¼è‡´é‡å»ºä¸å‡†ç¡®ã€‚</li>
<li>NeRFè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚</li>
<li>SMURFæ–¹æ³•åˆ©ç”¨ç¥ç»ODEæ¨¡æ‹Ÿè¿ç»­ç›¸æœºè¿åŠ¨ã€‚</li>
<li>CMKBæ¨¡å—ç”¨äºå¤„ç†è¿åŠ¨æ¨¡ç³Šè¾“å…¥å›¾åƒã€‚</li>
<li>SMURFåœ¨åŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚</li>
<li>SMURFè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå¯¹è¿åŠ¨æ¨¡ç³Šè¾“å…¥æ›´é²æ£’ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šè¿ç»­åŠ¨åŠ›å­¦åºåˆ—è¿åŠ¨ç†è§£è¾å°„åœºï¼ˆSMURFï¼‰</li>
<li>ä½œè€…ï¼šJho, Y., Cho, J., &amp; Kim, J.</li>
<li>æ‰€å±å•ä½ï¼šå»¶ä¸–å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»æ¸²æŸ“ã€è§†å›¾åˆæˆã€è¿åŠ¨å»æ¨¡ç³Š</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/pdf/2206.09265.pdfï¼ŒGithub é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰åœ¨é«˜ä¿çœŸåˆæˆæ–°é¢–è§†å›¾æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†è¿åŠ¨æ¨¡ç³Šçš„å­˜åœ¨ä¼šå½±å“é‡å»º 3D åœºæ™¯çš„è´¨é‡ã€‚ç°æœ‰çš„æ–¹æ³•æ²¡æœ‰è€ƒè™‘å›¾åƒé‡‡é›†è¿‡ç¨‹ä¸­ç›¸æœºè¿åŠ¨çš„è¿ç»­åŠ¨åŠ›å­¦ï¼Œå¯¼è‡´åœºæ™¯é‡å»ºä¸å‡†ç¡®ï¼Œä¸”è®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸ä½¿ç”¨é¢„å®šä¹‰çš„æ¨¡ç³Šæ ¸æ¥å¤„ç†è¿åŠ¨æ¨¡ç³Šï¼Œä½†è¿™äº›æ–¹æ³•æ— æ³•å‡†ç¡®å»ºæ¨¡è¿ç»­çš„ç›¸æœºè¿åŠ¨ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•è®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦è¾ƒæ…¢ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³• SMURFï¼Œå®ƒä½¿ç”¨ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆNeural-ODEï¼‰å¯¹è¿ç»­ç›¸æœºè¿åŠ¨è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶åˆ©ç”¨æ˜¾å¼ä½“ç§¯è¡¨ç¤ºæ–¹æ³•å®ç°æ›´å¿«çš„è®­ç»ƒé€Ÿåº¦å’Œå¯¹è¿åŠ¨æ¨¡ç³Šè¾“å…¥å›¾åƒçš„é²æ£’æ€§ã€‚SMURF çš„æ ¸å¿ƒæ€æƒ³æ˜¯è¿ç»­è¿åŠ¨æ¨¡ç³Šæ ¸ï¼ˆCMBKï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç‹¬ç‰¹æ¨¡å—ï¼Œæ—¨åœ¨å¯¹è¿ç»­ç›¸æœºè¿åŠ¨å»ºæ¨¡ä»¥å¤„ç†æ¨¡ç³Šè¾“å…¥ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„ä¸¥æ ¼è¯„ä¼°è¡¨æ˜ï¼ŒSMURF åœ¨å®šé‡å’Œå®šæ€§æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•çš„æ€§èƒ½æ”¯æŒå…¶ç›®æ ‡ï¼Œå³å‡†ç¡®é‡å»ºè¿åŠ¨æ¨¡ç³Šåœºæ™¯å¹¶å®ç°å¿«é€Ÿè®­ç»ƒå’Œæ¸²æŸ“ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰åˆæ­¥ï¼šä½¿ç”¨åŸºäº 3D å¼ é‡åˆ†è§£çš„æ¸²æŸ“æ–¹æ³• TensoRFï¼Œå¹¶é‡‡ç”¨ 3D åœºæ™¯ç›²é™¤æ¨¡ç³Šç®—æ³•ï¼Œä¸ºæˆ‘ä»¬çš„æ–¹æ³•è®ºè¿›è¡Œä¼˜åŒ–ï¼›
ï¼ˆ2ï¼‰è¿ç»­åŠ¨åŠ›å­¦ï¼šå°†è¿ç»­åŠ¨åŠ›å­¦åº”ç”¨äºæˆ‘ä»¬çš„ CMBKï¼Œä»¥ç”Ÿæˆæ‰­æ›²å…‰çº¿ï¼›
ï¼ˆ3ï¼‰ç›®æ ‡å‡½æ•°å’Œä¼˜åŒ–è¿‡ç¨‹ï¼šè®¨è®ºç›®æ ‡å‡½æ•°å’Œä¼˜åŒ–è¿‡ç¨‹ã€‚</p>
</li>
</ol>
<p><strong>ç»“è®º</strong>
ï¼ˆ1ï¼‰è¯¥å·¥ä½œæå‡ºäº† SMURFï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç”¨äºé¡ºåºå»ºæ¨¡å‡†ç¡®çš„ç›¸æœºè¿åŠ¨ï¼Œä»¥ä»è¿åŠ¨æ¨¡ç³Šå›¾åƒé‡å»ºæ¸…æ™°çš„ 3D åœºæ™¯ã€‚ä¸ä»¥å¾€ä¸€æ­¥ä¼°è®¡ç›¸æœºè¿åŠ¨çš„æ–¹æ³•ä¸åŒï¼ŒSMURF é¦–æ¬¡ç»“åˆäº†ä¸€ä¸ªç”¨äºä¼°è®¡é¡ºåºç›¸æœºè¿åŠ¨çš„æ ¸ï¼Œç§°ä¸º CMBKã€‚è¿™ç§ç›¸æœºè¿åŠ¨é€šè¿‡ä½¿ç”¨ç¥ç» ODE åœ¨æ½œåœ¨ç©ºé—´ä¸­æ±‚è§£è¿ç»­åŠ¨åŠ›å­¦æ¥è¡¨ç¤ºè¿ç»­æ€§ã€‚ä¸ºäº†é˜²æ­¢ CMBK ä¼°è®¡çš„å…‰çº¿è¶…å‡ºè¿åŠ¨æ¨¡ç³ŠèŒƒå›´ï¼Œæˆ‘ä»¬åº”ç”¨äº†æ­£åˆ™åŒ–æŠ€æœ¯ï¼šæ®‹å·®åŠ¨é‡å’Œè¾“å‡ºæŠ‘åˆ¶æŸå¤±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºäºå¼ é‡åˆ†è§£çš„è¡¨ç¤ºå¯¹ 3D åœºæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œè¿™å…è®¸é€šè¿‡ CMBK å°†ä¸å®Œæ•´çš„æ¨¡ç³Šä¿¡æ¯å’Œç›¸é‚»ä½“ç´ å†…çš„å®Œæ•´æ¸…æ™°ä¿¡æ¯è¿›è¡Œæ•´åˆï¼Œä»è€Œå‡å°‘æ¨¡ç³Šä¿¡æ¯çš„çš„ä¸ç¡®å®šæ€§ã€‚SMURF åœ¨å®šé‡æ–¹é¢æ˜æ˜¾ä¼˜äºä»¥å‰çš„å·¥ä½œï¼Œè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦æ›´å¿«ï¼Œå…¶å®šæ€§è¯„ä¼°é€šè¿‡æ–°é¢–çš„è§†å›¾æ¸²æŸ“ç»“æœå¾—åˆ°è¯æ˜ã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š
* æå‡ºäº†ä¸€ç§æ–°çš„è¿ç»­åŠ¨åŠ›å­¦ç›¸æœºè¿åŠ¨æ ¸ (CMBK)ï¼Œè¯¥æ ¸ç”¨äºä¼°è®¡è¿ç»­ç›¸æœºè¿åŠ¨ï¼Œä»¥å¤„ç†è¿åŠ¨æ¨¡ç³Šè¾“å…¥å›¾åƒã€‚
* ä½¿ç”¨ç¥ç» ODE åœ¨æ½œåœ¨ç©ºé—´ä¸­æ±‚è§£è¿ç»­åŠ¨åŠ›å­¦ï¼Œä»¥è¡¨ç¤ºç›¸æœºè¿åŠ¨çš„è¿ç»­æ€§ã€‚
* å°†åŸºäºå¼ é‡åˆ†è§£çš„è¡¨ç¤ºä¸ CMBK ç›¸ç»“åˆï¼Œä»¥æ•´åˆä¸å®Œæ•´çš„æ¨¡ç³Šä¿¡æ¯å’Œç›¸é‚»ä½“ç´ å†…çš„å®Œæ•´æ¸…æ™°ä¿¡æ¯ã€‚
æ€§èƒ½ï¼š
* åœ¨å®šé‡å’Œå®šæ€§æ–¹é¢éƒ½è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚
* ä¸ä»¥å‰çš„åŸºäºæ¨¡ç³Šæ ¸çš„æ–¹æ³•ç›¸æ¯”ï¼Œè®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦æ›´å¿«ã€‚
å·¥ä½œé‡ï¼š
* CMBK çš„è®¡ç®—æˆæœ¬æ¯”é¢„å®šä¹‰æ¨¡ç³Šæ ¸æ›´é«˜ã€‚
* è®­ç»ƒå’Œæ¸²æŸ“é€Ÿåº¦æ¯”ä»¥å‰çš„åŸºäºæ¨¡ç³Šæ ¸çš„æ–¹æ³•æ›´å¿«ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-db9a8ae95bca19ea9693d78ed7c9beff.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-1e25738d64460c7135b901f188e0f4ce.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-2c7846dc90459e1c266cd29c7a69bac3.jpg" align="middle">
</details>




## Is Vanilla MLP in Neural Radiance Field Enough for Few-shot View   Synthesis?

**Authors:Hanxin Zhu, Tianyu He, Xin Li, Bingchen Li, Zhibo Chen**

Neural Radiance Field (NeRF) has achieved superior performance for novel view synthesis by modeling the scene with a Multi-Layer Perception (MLP) and a volume rendering procedure, however, when fewer known views are given (i.e., few-shot view synthesis), the model is prone to overfit the given views. To handle this issue, previous efforts have been made towards leveraging learned priors or introducing additional regularizations. In contrast, in this paper, we for the first time provide an orthogonal method from the perspective of network structure. Given the observation that trivially reducing the number of model parameters alleviates the overfitting issue, but at the cost of missing details, we propose the multi-input MLP (mi-MLP) that incorporates the inputs (i.e., location and viewing direction) of the vanilla MLP into each layer to prevent the overfitting issue without harming detailed synthesis. To further reduce the artifacts, we propose to model colors and volume density separately and present two regularization terms. Extensive experiments on multiple datasets demonstrate that: 1) although the proposed mi-MLP is easy to implement, it is surprisingly effective as it boosts the PSNR of the baseline from $14.73$ to $24.23$. 2) the overall framework achieves state-of-the-art results on a wide range of benchmarks. We will release the code upon publication. 

[PDF](http://arxiv.org/abs/2403.06092v1) Accepted by CVPR 2024

**Summary**
ç”¨å¤šè¾“å…¥MLPè§£å†³NeRFåœ¨å°‘é•œå¤´è§†è§’åˆæˆä¸­å®¹æ˜“è¿‡æ‹Ÿåˆçš„é—®é¢˜ï¼Œå¹¶é€šè¿‡åˆ†ç¦»é¢œè‰²å’Œä½“ç§¯å¯†åº¦å»ºæ¨¡ä»¥åŠæ·»åŠ æ­£åˆ™åŒ–é¡¹è¿›ä¸€æ­¥æå‡æ•ˆæœã€‚

**Key Takeaways**
- å‡å°‘æ¨¡å‹å‚æ•°å¯ä»¥ç¼“è§£è¿‡æ‹Ÿåˆï¼Œä½†ä¼šä¸¢å¤±ç»†èŠ‚ã€‚
- å¤šè¾“å…¥MLPå°†ä½ç½®å’Œè§‚å¯Ÿæ–¹å‘ä½œä¸ºæ¯ä¸€å±‚çš„è¾“å…¥ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆè€Œä¸æŸå®³ç»†èŠ‚åˆæˆã€‚
- åˆ†ç¦»é¢œè‰²å’Œä½“ç§¯å¯†åº¦å»ºæ¨¡å¯ä»¥å‡å°‘ä¼ªå½±ã€‚
- åŠ å…¥æ­£åˆ™åŒ–é¡¹å¯ä»¥è¿›ä¸€æ­¥æå‡æ•ˆæœã€‚
- æå‡ºçš„æ–¹æ³•ç®€å•æ˜“å®ç°ï¼Œå°†åŸºå‡†PSNRä»14.73æå‡è‡³24.23ã€‚
- è¯¥æ¡†æ¶åœ¨å¹¿æ³›çš„åŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
- ä»£ç å°†åœ¨å‘è¡¨åå‘å¸ƒã€‚

**[ChatPaperFree](https://huggingface.co/spaces/Kedreamix/ChatPaperFree)**

<ol>
<li>æ ‡é¢˜ï¼šVanilla MLP åœ¨ç¥ç»è¾å°„åœºä¸­æ˜¯å¦è¶³ä»¥ç”¨äºå°æ ·æœ¬è§†å›¾åˆæˆï¼Ÿ</li>
<li>ä½œè€…ï¼šHanxin Zhu, Tianyu He, Xin Li, Bingchen Li, Zhibo Chen</li>
<li>å•ä½ï¼šä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦</li>
<li>å…³é”®è¯ï¼šç¥ç»è¾å°„åœºã€å°æ ·æœ¬è§†å›¾åˆæˆã€å¤šè¾“å…¥ MLP</li>
<li>è®ºæ–‡é“¾æ¥ï¼šNone</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰é€šè¿‡ä½¿ç”¨å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰å’Œä½“ç§¯æ¸²æŸ“è¿‡ç¨‹å¯¹åœºæ™¯è¿›è¡Œå»ºæ¨¡ï¼Œåœ¨ novel view åˆæˆæ–¹é¢å–å¾—äº†å“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå½“ç»™å®šçš„å·²çŸ¥è§†å›¾è¾ƒå°‘ï¼ˆå³å°æ ·æœ¬è§†å›¾åˆæˆï¼‰æ—¶ï¼Œæ¨¡å‹å®¹æ˜“è¿‡æ‹Ÿåˆç»™å®šçš„è§†å›¾ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šä»¥å¾€çš„å·¥ä½œä¸»è¦é›†ä¸­äºåˆ©ç”¨å­¦ä¹ åˆ°çš„å…ˆéªŒæˆ–å¼•å…¥é¢å¤–çš„æ­£åˆ™åŒ–é¡¹æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€ä¼šå¢åŠ æ¨¡å‹çš„å¤æ‚æ€§å’Œè®­ç»ƒéš¾åº¦ã€‚
ï¼ˆ3ï¼‰æœ¬æ–‡æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»ç½‘ç»œç»“æ„è§’åº¦è§£å†³å°æ ·æœ¬è§†å›¾åˆæˆè¿‡æ‹Ÿåˆé—®é¢˜çš„æ­£äº¤æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šè¾“å…¥ MLPï¼ˆmi-MLPï¼‰ï¼Œå°† vanilla MLP çš„è¾“å…¥ï¼ˆå³ä½ç½®å’Œè§†è§’ï¼‰èå…¥åˆ°æ¯ä¸€å±‚ä¸­ï¼Œä»¥é˜²æ­¢è¿‡æ‹Ÿåˆé—®é¢˜ï¼ŒåŒæ—¶ä¸æŸå®³ç»†èŠ‚åˆæˆã€‚ä¸ºäº†è¿›ä¸€æ­¥å‡å°‘ä¼ªå½±ï¼Œæˆ‘ä»¬æå‡ºåˆ†åˆ«å¯¹é¢œè‰²å’Œä½“ç§¯å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶æå‡ºäº†ä¸¤ä¸ªæ­£åˆ™åŒ–é¡¹ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼š1ï¼‰å°½ç®¡æå‡ºçš„ mi-MLP æ˜“äºå®ç°ï¼Œä½†å®ƒéå¸¸æœ‰æ•ˆï¼Œå°†åŸºå‡†çš„ PSNR ä» 14.73 æå‡åˆ° 24.23ã€‚2ï¼‰è¯¥æ¡†æ¶åœ¨å¹¿æ³›çš„åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
(1): æå‡ºå¤šè¾“å…¥MLPï¼ˆmi-MLPï¼‰ï¼Œå°†ä½ç½®å’Œè§†è§’ä¿¡æ¯èå…¥æ¯ä¸€å±‚ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚
(2): åˆ†åˆ«å¯¹é¢œè‰²å’Œä½“ç§¯å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œå‡å°‘ä¼ªå½±ã€‚
(3): æå‡ºä¸¤ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œè¿›ä¸€æ­¥å‡å°‘è¿‡æ‹Ÿåˆã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šæœ¬æ–‡é¦–æ¬¡ä»ç½‘ç»œç»“æ„çš„è§’åº¦æå‡ºäº†è§£å†³å°æ ·æœ¬è§†å›¾åˆæˆè¿‡æ‹Ÿåˆé—®é¢˜çš„æ–°é¢–æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œä¸ºäº†è§£å†³è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œå—å‡å°‘æ¨¡å‹å®¹é‡æœ‰åˆ©äºç¼“è§£è¿‡æ‹Ÿåˆä½†ä»¥ä¸¢å¤±ç»†èŠ‚ä¸ºä»£ä»·çš„è§‚å¯Ÿç»“æœçš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†å°†è¾“å…¥èå…¥åˆ° MLP çš„æ¯ä¸€å±‚çš„ mi-MLPã€‚éšåï¼ŒåŸºäºå‡ ä½•æ¯”å¤–è§‚æ›´å¹³æ»‘çš„å‡è®¾ï¼Œæˆ‘ä»¬æå‡ºåˆ†åˆ«å¯¹é¢œè‰²å’Œä½“ç§¯å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œä»¥è·å¾—æ›´å¥½çš„ç»†èŠ‚ã€‚
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šæå‡ºå¤šè¾“å…¥ MLPï¼ˆmi-MLPï¼‰ï¼Œå°†ä½ç½®å’Œè§†è§’ä¿¡æ¯èå…¥æ¯ä¸€å±‚ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆã€‚åˆ†åˆ«å¯¹é¢œè‰²å’Œä½“ç§¯å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œå‡å°‘ä¼ªå½±ã€‚æå‡ºä¸¤ä¸ªæ­£åˆ™åŒ–é¡¹ï¼Œè¿›ä¸€æ­¥å‡å°‘è¿‡æ‹Ÿåˆã€‚
æ€§èƒ½ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼š1ï¼‰å°½ç®¡æå‡ºçš„ mi-MLP æ˜“äºå®ç°ï¼Œä½†å®ƒéå¸¸æœ‰æ•ˆï¼Œå°†åŸºå‡†çš„ PSNR ä» 14.73 æå‡åˆ° 24.23ã€‚2ï¼‰è¯¥æ¡†æ¶åœ¨å¹¿æ³›çš„åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚
å·¥ä½œé‡ï¼šæœ¬æ–‡æå‡ºçš„æ–¹æ³•æ˜“äºå®ç°ï¼Œå¹¶ä¸”åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œå…·æœ‰è¾ƒé«˜çš„æ€§ä»·æ¯”ã€‚</p>
</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d5413e2a13758a1dee7e61a20e9bf67b.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-b95160575f37aa8a4057db0ddfd6eea9.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-8c5258335995d89b2ce88c6d3a8b0525.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-d3779bd9aae46bb04cd828c0fff47a1e.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-0a20b75de3fe9496201a3b1b021c2f43.jpg" align="middle">
</details>




<h2 id="Lightning-NeRF-Efficient-Hybrid-Scene-Representation-for-Autonomous-Driving"><a href="#Lightning-NeRF-Efficient-Hybrid-Scene-Representation-for-Autonomous-Driving" class="headerlink" title="Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous   Driving"></a>Lightning NeRF: Efficient Hybrid Scene Representation for Autonomous   Driving</h2><p><strong>Authors:Junyi Cao, Zhichao Li, Naiyan Wang, Chao Ma</strong></p>
<p>Recent studies have highlighted the promising application of NeRF in autonomous driving contexts. However, the complexity of outdoor environments, combined with the restricted viewpoints in driving scenarios, complicates the task of precisely reconstructing scene geometry. Such challenges often lead to diminished quality in reconstructions and extended durations for both training and rendering. To tackle these challenges, we present Lightning NeRF. It uses an efficient hybrid scene representation that effectively utilizes the geometry prior from LiDAR in autonomous driving scenarios. Lightning NeRF significantly improves the novel view synthesis performance of NeRF and reduces computational overheads. Through evaluations on real-world datasets, such as KITTI-360, Argoverse2, and our private dataset, we demonstrate that our approach not only exceeds the current state-of-the-art in novel view synthesis quality but also achieves a five-fold increase in training speed and a ten-fold improvement in rendering speed. Codes are available at <a href="https://github.com/VISION-SJTU/Lightning-NeRF">https://github.com/VISION-SJTU/Lightning-NeRF</a> . </p>
<p><a href="http://arxiv.org/abs/2403.05907v1">PDF</a> Accepted to ICRA 2024</p>
<p><strong>æ‘˜è¦</strong><br>åˆ©ç”¨æ¿€å…‰é›·è¾¾ä¸­çš„å‡ ä½•å…ˆéªŒå¯¹è‡ªåŠ¨é©¾é©¶ä¸­çš„ NeRF è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œæé«˜æ–°è§†è§’åˆæˆæ€§èƒ½å¹¶é™ä½è®¡ç®—å¼€é”€ã€‚</p>
<p><strong>å…³é”®è¦ç‚¹</strong></p>
<ul>
<li>Lightning NeRF ä½¿ç”¨é«˜æ•ˆçš„æ··åˆåœºæ™¯è¡¨ç¤ºï¼Œæœ‰æ•ˆåˆ©ç”¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„æ¿€å…‰é›·è¾¾å‡ ä½•å…ˆéªŒã€‚</li>
<li>Lightning NeRF æ˜¾ç€æé«˜äº† NeRF çš„æ–°è§†å›¾åˆæˆæ€§èƒ½å¹¶å‡å°‘äº†è®¡ç®—å¼€é”€ã€‚</li>
<li>åœ¨ KITTI-360ã€Argoverse2 å’Œç§æœ‰æ•°æ®é›†ç­‰çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…è¶…è¿‡äº†æ–°è§†å›¾åˆæˆè´¨é‡çš„å½“å‰æœ€å…ˆè¿›æ°´å¹³ï¼Œè€Œä¸”è¿˜å°†è®­ç»ƒé€Ÿåº¦æé«˜äº†äº”å€ï¼Œæ¸²æŸ“é€Ÿåº¦æé«˜äº†åå€ã€‚</li>
<li>ä»£ç å¯åœ¨ <a href="https://github.com/VISION-SJTU/Lightning-NeRF">https://github.com/VISION-SJTU/Lightning-NeRF</a> è·å¾—ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šLightningNeRFï¼šé«˜æ•ˆæ··åˆåœºæ™¯è¡¨ç¤ºç”¨äºè‡ªåŠ¨é©¾é©¶</li>
<li>ä½œè€…ï¼šJunyi Cao, Zhichao Li, Naiyan Wang, Chao Ma</li>
<li>å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦äººå·¥æ™ºèƒ½ç ”ç©¶é™¢</li>
<li>å…³é”®è¯ï¼šNeRFï¼Œè‡ªåŠ¨é©¾é©¶ï¼Œåœºæ™¯è¡¨ç¤ºï¼Œæ¿€å…‰é›·è¾¾</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.05907</li>
<li>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šNeRF åœ¨è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­å…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ï¼Œä½†æˆ·å¤–ç¯å¢ƒçš„å¤æ‚æ€§ä»¥åŠé©¾é©¶åœºæ™¯ä¸­å—é™çš„è§†ç‚¹ç»™åœºæ™¯å‡ ä½•çš„ç²¾ç¡®é‡å»ºå¸¦æ¥äº†æŒ‘æˆ˜ï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸‹é™ï¼Œè®­ç»ƒå’Œæ¸²æŸ“æ—¶é—´å»¶é•¿ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•åŠå…¶é—®é¢˜ï¼šNeRF-W å¼•å…¥å¯å­¦ä¹ çš„å¤–è§‚åµŒå…¥æ¥è§£å†³å…‰ç…§å˜åŒ–é—®é¢˜ï¼›è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¸­çš„ä¸€äº›æŠ€æœ¯é›†æˆç‚¹äº‘ä»¥æä¾›å¢å¼ºçš„å‡ ä½•ä¿¡æ¯ï¼Œä»¥è§£å†³è¡¨ç¤ºå¤æ‚ç»“æ„çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€å¿½è§†äº†ä¸è®­ç»ƒå’Œæ¸²æŸ“ç›¸å…³çš„æ•ˆç‡å’Œè®¡ç®—å¼€é”€ã€‚æ›´å¤æ‚çš„å»ºæ¨¡å’Œæ›´å¤§çš„åœºæ™¯å¾€å¾€ä¼šå¯¼è‡´æ›´é•¿çš„æ¨¡å‹è®­ç»ƒæ—¶é—´ã€‚
ï¼ˆ3ï¼‰æå‡ºçš„ç ”ç©¶æ–¹æ³•ï¼šæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ··åˆåœºæ™¯è¡¨ç¤ºã€‚åˆ†åˆ«ä½¿ç”¨æ˜¾å¼å’Œéšå¼æ–¹æ³•å¯¹ NeRF ä¸­çš„å¯†åº¦å’Œé¢œè‰²è¿›è¡Œå»ºæ¨¡ã€‚å¯¹äºå¯†åº¦ï¼Œç‚¹äº‘æä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„åˆå§‹åŒ–ï¼Œå¤§å¤§é™ä½äº†è¡¨ç¤ºæŒ‘æˆ˜ã€‚è¿™å…è®¸ä½¿ç”¨æœ‰é™åˆ†è¾¨ç‡çš„ä½“ç´ ç½‘æ ¼æ˜¾å¼åœ°å¯¹å¯†åº¦è¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹å¤šå±‚æ„ŸçŸ¥å™¨ (MLP) çš„éœ€æ±‚ã€‚ä¸ºäº†æ¸²æŸ“å›¾åƒç»†èŠ‚ï¼Œä¿ç•™äº†éšå¼å»ºæ¨¡çš„é¢œè‰² MLPï¼Œä»¥ç¡®ä¿å®¹çº³é«˜åº¦å¯å˜çš„çœŸå®ä¸–ç•Œçš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ä¸ªæ›´çœŸå®çš„æˆ·å¤–åœºæ™¯èƒŒæ™¯å’Œé¢œè‰²åˆ†è§£æ¨¡å‹ï¼Œè¿›ä¸€æ­¥æå‡äº†æ–°è§†å›¾åˆæˆå’Œæ¸²æŸ“æ•ˆç‡ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•åœ¨ä»»åŠ¡å’Œæ€§èƒ½ä¸Šçš„è¡¨ç°ï¼šåœ¨çœŸå®ä¸–ç•Œçš„è‡ªåŠ¨é©¾é©¶æ•°æ®é›†ï¼ˆåŒ…æ‹¬ KITTI-360ã€Argoverse2 å’Œç§æœ‰æ•°æ®é›†ï¼‰ä¸Šè¿›è¡Œçš„æ¯”è¾ƒç ”ç©¶è¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†æ–°è§†å›¾åˆæˆçš„å½“å‰æŠ€æœ¯æ°´å¹³ï¼Œè€Œä¸”åœ¨è®­ç»ƒé€Ÿåº¦ä¸Šæé«˜äº†äº”å€ï¼Œåœ¨æ¸²æŸ“é€Ÿåº¦ä¸Šæé«˜äº†åå€ã€‚</li>
</ol>
<p>7.Methodsï¼š
(1)æå‡ºäº†ä¸€ç§æ··åˆåœºæ™¯è¡¨ç¤ºï¼Œåˆ†åˆ«ä½¿ç”¨æ˜¾å¼å’Œéšå¼æ–¹æ³•å¯¹NeRFä¸­çš„å¯†åº¦å’Œé¢œè‰²è¿›è¡Œå»ºæ¨¡ã€‚
(2)å¯¹äºå¯†åº¦ï¼Œä½¿ç”¨ç‚¹äº‘è¿›è¡Œåˆå§‹åŒ–ï¼Œå¹¶ä½¿ç”¨æœ‰é™åˆ†è¾¨ç‡çš„ä½“ç´ ç½‘æ ¼æ˜¾å¼åœ°å¯¹å¯†åº¦è¿›è¡Œå»ºæ¨¡ã€‚
(3)ä¿ç•™äº†éšå¼å»ºæ¨¡çš„é¢œè‰²MLPï¼Œä»¥ç¡®ä¿å®¹çº³é«˜åº¦å¯å˜çš„çœŸå®ä¸–ç•Œçš„èƒ½åŠ›ã€‚
(4)æå‡ºäº†ä¸€ä¸ªæ›´çœŸå®çš„æˆ·å¤–åœºæ™¯èƒŒæ™¯å’Œé¢œè‰²åˆ†è§£æ¨¡å‹ï¼Œè¿›ä¸€æ­¥æå‡äº†æ–°è§†å›¾åˆæˆå’Œæ¸²æŸ“æ•ˆç‡ã€‚</p>
<ol>
<li>ç»“è®ºï¼š
ï¼ˆ1ï¼‰ï¼šxxxï¼›
ï¼ˆ2ï¼‰ï¼šåˆ›æ–°ç‚¹ï¼šxxxï¼›æ€§èƒ½ï¼šxxxï¼›å·¥ä½œé‡ï¼šxxxï¼›
ä¸€å®šä½¿ç”¨ä¸­æ–‡å›ç­”ï¼ˆä¸“æœ‰åè¯éœ€ç”¨è‹±æ–‡æ ‡æ³¨ï¼‰ï¼Œè¡¨è¿°å°½é‡ç®€æ´ã€å­¦æœ¯ï¼Œä¸è¦é‡å¤å‰é¢<summary>çš„å†…å®¹ï¼ŒåŸæ•°å­—ä½¿ç”¨å€¼ï¼Œä¸€å®šè¦ä¸¥æ ¼æŒ‰ç…§æ ¼å¼ï¼Œå¯¹åº”çš„å†…å®¹è¾“å‡ºåˆ° xxxï¼ŒæŒ‰ç…§æ¢è¡Œï¼Œ.......è¡¨ç¤ºæ ¹æ®å®é™…è¦æ±‚å¡«å†™ï¼Œæ²¡æœ‰åˆ™ä¸å¡«å†™ã€‚</summary></li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pica.zhimg.com/v2-c3c56c45aa89ca70a9d609d58d13fc72.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-544ea053c10bd7d5553f1412616bc128.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f7858b87f901521cc196f65ca88a4ad3.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-6d73c5c552f884a5b73d5deeaa0a82c9.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-beec12e6377f8382c630b862b43c0639.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-47496b3bbedaa3c39273968886b3bf28.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-27645ea8a6d5dfe81e62f403a389d207.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-a093c0f308a0c1200cbef94e26877d37.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-ddd6ba95e714dbde1131d8d55c710adc.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-54643329304c9e2643d0232e99611e63.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-9f945531a4d142f4ae5c27cea88e7444.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>NeRF</tag>
      </tags>
  </entry>
  <entry>
    <title>Talking Head Generation</title>
    <url>/2024/03/13/Paper/2024-03-13/Talking%20Head%20Generation/</url>
    <content><![CDATA[<blockquote>
<p>âš ï¸ ä»¥ä¸‹æ‰€æœ‰å†…å®¹æ€»ç»“éƒ½æ¥è‡ªäº Googleçš„å¤§è¯­è¨€æ¨¡å‹<a href="https://ai.google.dev/">Gemini-Pro</a>çš„èƒ½åŠ›ï¼Œå¦‚æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼Œè°¨æ…ä½¿ç”¨<br>ğŸ”´ è¯·æ³¨æ„ï¼šåƒä¸‡ä¸è¦ç”¨äºä¸¥è‚ƒçš„å­¦æœ¯åœºæ™¯ï¼Œåªèƒ½ç”¨äºè®ºæ–‡é˜…è¯»å‰çš„åˆç­›ï¼<br>ğŸ’— å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ© <a href="https://github.com/Kedreamix/ChatPaperFree">ChatPaperFree</a> ï¼Œè¿˜è¯·æ‚¨ç»™æˆ‘ä»¬ä¸€äº›é¼“åŠ±ï¼â­ï¸ <a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">HuggingFaceå…è´¹ä½“éªŒ</a></p>
</blockquote>
<h1 id="2024-03-13-æ›´æ–°"><a href="#2024-03-13-æ›´æ–°" class="headerlink" title="2024-03-13 æ›´æ–°"></a>2024-03-13 æ›´æ–°</h1><h2 id="A-Comparative-Study-of-Perceptual-Quality-Metrics-for-Audio-driven-Talking-Head-Videos"><a href="#A-Comparative-Study-of-Perceptual-Quality-Metrics-for-Audio-driven-Talking-Head-Videos" class="headerlink" title="A Comparative Study of Perceptual Quality Metrics for Audio-driven   Talking Head Videos"></a>A Comparative Study of Perceptual Quality Metrics for Audio-driven   Talking Head Videos</h2><p><strong>Authors:Weixia Zhang, Chengguang Zhu, Jingnan Gao, Yichao Yan, Guangtao Zhai, Xiaokang Yang</strong></p>
<p>The rapid advancement of Artificial Intelligence Generated Content (AIGC) technology has propelled audio-driven talking head generation, gaining considerable research attention for practical applications. However, performance evaluation research lags behind the development of talking head generation techniques. Existing literature relies on heuristic quantitative metrics without human validation, hindering accurate progress assessment. To address this gap, we collect talking head videos generated from four generative methods and conduct controlled psychophysical experiments on visual quality, lip-audio synchronization, and head movement naturalness. Our experiments validate consistency between model predictions and human annotations, identifying metrics that align better with human opinions than widely-used measures. We believe our work will facilitate performance evaluation and model development, providing insights into AIGC in a broader context. Code and data will be made available at <a href="https://github.com/zwx8981/ADTH-QA">https://github.com/zwx8981/ADTH-QA</a>. </p>
<p><a href="http://arxiv.org/abs/2403.06421v1">PDF</a> </p>
<p><strong>Summary</strong><br>äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰æŠ€æœ¯çš„å‘å±•æ¨åŠ¨äº†éŸ³é¢‘é©±åŠ¨çš„è™šæ‹Ÿå½¢è±¡ç”ŸæˆæŠ€æœ¯ï¼Œåœ¨å®é™…åº”ç”¨ä¸­å¾—åˆ°äº†å¹¿æ³›çš„ç ”ç©¶å…³æ³¨ã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰æŠ€æœ¯å‘å±•è¿…é€Ÿï¼Œä¿ƒè¿›äº†éŸ³é¢‘é©±åŠ¨çš„è™šæ‹Ÿå½¢è±¡ç”Ÿæˆã€‚</li>
<li>ç°æœ‰çš„è™šæ‹Ÿå½¢è±¡ç”ŸæˆæŠ€æœ¯è¯„ä»·æŒ‡æ ‡ä¾èµ–å¯å‘å¼å®šé‡æŒ‡æ ‡ï¼Œç¼ºä¹äººä¸ºéªŒè¯ï¼Œé˜»ç¢äº†å‡†ç¡®çš„è¿›åº¦è¯„ä¼°ã€‚</li>
<li>æ”¶é›†äº†å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆçš„è™šæ‹Ÿå½¢è±¡è§†é¢‘ï¼Œå¹¶å¯¹è§†è§‰è´¨é‡ã€å”‡éŸ³åŒæ­¥å’Œå¤´éƒ¨è¿åŠ¨è‡ªç„¶åº¦è¿›è¡Œäº†æ§åˆ¶çš„å¿ƒç†ç‰©ç†å®éªŒã€‚</li>
<li>å®éªŒéªŒè¯äº†æ¨¡å‹é¢„æµ‹å’Œäººä¸ºæ ‡æ³¨çš„ä¸€è‡´æ€§ï¼Œç¡®å®šäº†æ¯”å¹¿æ³›ä½¿ç”¨çš„åº¦é‡æ›´ç¬¦åˆäººæ„è§çš„åº¦é‡ã€‚</li>
<li>è¯¥ç ”ç©¶å°†ä¿ƒè¿›ç»©æ•ˆè¯„ä¼°å’Œæ¨¡å‹å¼€å‘ï¼Œä¸ºæ›´å¹¿æ³›èƒŒæ™¯ä¸‹çš„ AIGC æä¾›æ·±å…¥è§è§£ã€‚</li>
<li>ä»£ç å’Œæ•°æ®å°†åœ¨ <a href="https://github.com/zwx8981/ADTH-QA">https://github.com/zwx8981/ADTH-QA</a> ä¸Šæä¾›ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<p>1.æ ‡é¢˜ï¼šéŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨è§†é¢‘æ„ŸçŸ¥è´¨é‡æŒ‡æ ‡çš„æ¯”è¾ƒç ”ç©¶
2.ä½œè€…ï¼šé­éœç« ã€ç¨‹å¹¿æŸ±ã€æ™¯å—é«˜ã€å¥•è¶…é¢œã€å¹¿æ¶›ç¿Ÿã€è‚–åº·æ¨
3.ç¬¬ä¸€ä½œè€…å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦äººå·¥æ™ºèƒ½ç ”ç©¶é™¢ã€äººå·¥æ™ºèƒ½ç ”ç©¶é™¢
4.å…³é”®è¯ï¼šæ„ŸçŸ¥è´¨é‡è¯„ä¼°ã€AIGCã€æ•°å­—äººã€éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”Ÿæˆ
5.è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.06421
Githubä»£ç é“¾æ¥ï¼šNone
6.æ€»ç»“ï¼š
ï¼ˆ1ï¼‰ï¼šç ”ç©¶èƒŒæ™¯ï¼šéšç€äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹ï¼ˆAIGCï¼‰æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼ŒéŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”ŸæˆæŠ€æœ¯å—åˆ°å¹¿æ³›å…³æ³¨ï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œæ€§èƒ½è¯„ä¼°ç ”ç©¶æ»åäºè¯´è¯äººå¤´éƒ¨ç”ŸæˆæŠ€æœ¯çš„å¼€å‘ã€‚ç°æœ‰æ–‡çŒ®ä¾èµ–å¯å‘å¼å®šé‡æŒ‡æ ‡ï¼Œç¼ºä¹äººå·¥éªŒè¯ï¼Œé˜»ç¢äº†å‡†ç¡®çš„è¿›å±•è¯„ä¼°ã€‚
ï¼ˆ2ï¼‰ï¼šè¿‡å»æ–¹æ³•ï¼šè¿‡å»çš„æ–¹æ³•ä¸»è¦ä¾èµ–å¯å‘å¼å®šé‡æŒ‡æ ‡ï¼Œå¦‚PSNRã€SSIMå’ŒLMDï¼Œè¿™äº›æŒ‡æ ‡åœ¨æ²¡æœ‰äººå·¥éªŒè¯çš„æƒ…å†µä¸‹è¢«ç”¨ä½œæ„ŸçŸ¥è´¨é‡çš„ä»£ç†æŒ‡æ ‡ã€‚ç„¶è€Œï¼Œè¿™äº›æŒ‡æ ‡å­˜åœ¨å±€é™æ€§ï¼Œä¾‹å¦‚å¯¹æ•°æ®æºçš„æ•æ„Ÿæ€§å’Œå¯¹äººç±»æ„ŸçŸ¥çš„ä¸åŒ¹é…ã€‚
ï¼ˆ3ï¼‰ï¼šç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æ”¶é›†äº†å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆçš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼Œå¹¶åœ¨å—æ§å®éªŒå®¤ç¯å¢ƒä¸­è¿›è¡Œå¿ƒç†ç‰©ç†å®éªŒï¼Œé‡ç‚¹å…³æ³¨è§†è§‰è´¨é‡ã€å”‡éŸ³åŒæ­¥å’Œå¤´éƒ¨è¿åŠ¨è‡ªç„¶åº¦ã€‚ç„¶åï¼Œå¯¹å„ç§å®¢è§‚æŒ‡æ ‡è¿›è¡Œäº†å¹¿æ³›æµ‹è¯•ï¼Œä»¥è¯„ä¼°å…¶ä¸è¿™äº›äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚
ï¼ˆ4ï¼‰ï¼šæ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•ä¸äººç±»åˆ¤æ–­ä¹‹é—´å­˜åœ¨ä¸€è‡´æ€§ï¼Œå¹¶ç¡®å®šäº†æ¯”å¹¿æ³›ä½¿ç”¨çš„æŒ‡æ ‡æ›´ç¬¦åˆäººç±»æ„è§çš„æŒ‡æ ‡ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºä¿ƒè¿›æ€§èƒ½è¯„ä¼°å’Œæ¨¡å‹å¼€å‘ï¼Œå¹¶ä¸ºæ›´å¹¿æ³›èƒŒæ™¯ä¸‹çš„AIGCæä¾›è§è§£ã€‚</p>
<p><strong>æ–¹æ³•ï¼š</strong></p>
<p>(1) æ”¶é›†å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆçš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨è§†é¢‘ï¼›</p>
<p>(2) åœ¨å—æ§å®éªŒå®¤ç¯å¢ƒä¸­è¿›è¡Œå¿ƒç†ç‰©ç†å®éªŒï¼Œé‡ç‚¹å…³æ³¨è§†è§‰è´¨é‡ã€å”‡éŸ³åŒæ­¥å’Œå¤´éƒ¨è¿åŠ¨è‡ªç„¶åº¦ï¼›</p>
<p>(3) å¹¿æ³›æµ‹è¯•å„ç§å®¢è§‚æŒ‡æ ‡ï¼Œä»¥è¯„ä¼°å…¶ä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ï¼›</p>
<p>(4) é€šè¿‡ 2AFC åˆ†æ•°è¡¡é‡å®¢è§‚æŒ‡æ ‡ä¸äººç±»è¯„ä¼°çš„ä¸€è‡´æ€§ï¼›</p>
<p>(5) è¯„ä¼°å›¾åƒè´¨é‡ã€å”‡éŸ³åŒæ­¥å’Œå¤´éƒ¨è¿åŠ¨è‡ªç„¶åº¦æŒ‡æ ‡ï¼›</p>
<p>(6) è¯„ä¼°åŸºäº SyncNet çš„ä¸‰ä¸ªå”‡éŸ³åŒæ­¥æŒ‡æ ‡å’Œ SparseSync æŒ‡æ ‡ï¼›</p>
<p>(7) é‡‡ç”¨æ··åˆæ•°æ®é›†è®­ç»ƒç­–ç•¥ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„å¯è½¬ç§»æ€§ã€‚</p>
<p><strong>8. ç»“è®º</strong>
<strong>(1): æ„ä¹‰</strong>
æœ¬ç ”ç©¶é€šè¿‡å»ºç«‹åŒ…å«å››ç§éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ–¹æ³•ç”Ÿæˆè§†é¢‘çš„æ•°æ®é›†ï¼Œå¹¶é€šè¿‡å—æ§çš„å¿ƒç†ç‰©ç†å®éªŒæ”¶é›†äººç±»åå¥½ï¼Œæ¢ç©¶äº†éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”ŸæˆæŠ€æœ¯çš„æ„ŸçŸ¥è´¨é‡è¯„ä¼°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ–¹æ³•ä¸äººç±»åˆ¤æ–­ä¹‹é—´å­˜åœ¨ä¸€è‡´æ€§ï¼Œå¹¶ç¡®å®šäº†æ¯”å¹¿æ³›ä½¿ç”¨çš„æŒ‡æ ‡æ›´ç¬¦åˆäººç±»æ„è§çš„æŒ‡æ ‡ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºä¿ƒè¿›æ€§èƒ½è¯„ä¼°å’Œæ¨¡å‹å¼€å‘ï¼Œå¹¶ä¸ºæ›´å¹¿æ³›èƒŒæ™¯ä¸‹çš„ AIGC æä¾›è§è§£ã€‚</p>
<p><strong>(2): åˆ›æ–°ç‚¹ã€æ€§èƒ½ã€å·¥ä½œé‡</strong>
<strong>åˆ›æ–°ç‚¹ï¼š</strong>
* é€šè¿‡å¿ƒç†ç‰©ç†å®éªŒæ”¶é›†äººç±»åå¥½ï¼Œå»ºç«‹åŒ…å«å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆè§†é¢‘çš„æ•°æ®é›†ã€‚
* æå‡ºäº†ä¸€ç§åŸºäºäººç±»åˆ¤æ–­çš„æ„ŸçŸ¥è´¨é‡è¯„ä¼°æ–¹æ³•ã€‚
* ç¡®å®šäº†æ¯”å¹¿æ³›ä½¿ç”¨çš„æŒ‡æ ‡æ›´ç¬¦åˆäººç±»æ„è§çš„æŒ‡æ ‡ã€‚</p>
<p><strong>æ€§èƒ½ï¼š</strong>
* æ‰€æå‡ºçš„æ–¹æ³•ä¸äººç±»åˆ¤æ–­ä¹‹é—´å­˜åœ¨ä¸€è‡´æ€§ã€‚
* ç¡®å®šçš„æŒ‡æ ‡æ¯”å¹¿æ³›ä½¿ç”¨çš„æŒ‡æ ‡æ›´ç¬¦åˆäººç±»æ„è§ã€‚</p>
<p><strong>å·¥ä½œé‡ï¼š</strong>
* æ”¶é›†äº†ä¸€ä¸ªåŒ…å«å››ç§ç”Ÿæˆæ–¹æ³•ç”Ÿæˆè§†é¢‘çš„æ•°æ®é›†ã€‚
* è¿›è¡Œäº†ä¸€ç³»åˆ—å¿ƒç†ç‰©ç†å®éªŒã€‚
* å¹¿æ³›æµ‹è¯•äº†å„ç§å®¢è§‚æŒ‡æ ‡ã€‚</p>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://picx.zhimg.com/v2-d7d375dcb8fecf9ffb80be0b9c71756b.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-478998a50c784c3a3c0aa108c509fe52.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-4aaac273c5b4afe45da700d10d5ac29c.jpg" align="middle">
<img src="https://pic1.zhimg.com/v2-f16882204804b40a491523a7984bf7e2.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-5201c94e6142ff9aad05ce654fbe8f9e.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-523c101252b751fc24de4e576389177a.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-8e67dfafe83349d242d664f46c153e84.jpg" align="middle">
</details>




<h2 id="Style2Talker-High-Resolution-Talking-Head-Generation-with-Emotion-Style-and-Art-Style"><a href="#Style2Talker-High-Resolution-Talking-Head-Generation-with-Emotion-Style-and-Art-Style" class="headerlink" title="Style2Talker: High-Resolution Talking Head Generation with Emotion Style   and Art Style"></a>Style2Talker: High-Resolution Talking Head Generation with Emotion Style   and Art Style</h2><p><strong>Authors:Shuai Tan, Bin Ji, Ye Pan</strong></p>
<p>Although automatically animating audio-driven talking heads has recently received growing interest, previous efforts have mainly concentrated on achieving lip synchronization with the audio, neglecting two crucial elements for generating expressive videos: emotion style and art style. In this paper, we present an innovative audio-driven talking face generation method called Style2Talker. It involves two stylized stages, namely Style-E and Style-A, which integrate text-controlled emotion style and picture-controlled art style into the final output. In order to prepare the scarce emotional text descriptions corresponding to the videos, we propose a labor-free paradigm that employs large-scale pretrained models to automatically annotate emotional text labels for existing audiovisual datasets. Incorporating the synthetic emotion texts, the Style-E stage utilizes a large-scale CLIP model to extract emotion representations, which are combined with the audio, serving as the condition for an efficient latent diffusion model designed to produce emotional motion coefficients of a 3DMM model. Moving on to the Style-A stage, we develop a coefficient-driven motion generator and an art-specific style path embedded in the well-known StyleGAN. This allows us to synthesize high-resolution artistically stylized talking head videos using the generated emotional motion coefficients and an art style source picture. Moreover, to better preserve image details and avoid artifacts, we provide StyleGAN with the multi-scale content features extracted from the identity image and refine its intermediate feature maps by the designed content encoder and refinement network, respectively. Extensive experimental results demonstrate our method outperforms existing state-of-the-art methods in terms of audio-lip synchronization and performance of both emotion style and art style. </p>
<p><a href="http://arxiv.org/abs/2403.06365v2">PDF</a> 9 pages, 5 figures, conference</p>
<p><strong>Summary</strong><br>éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ–¹æ³•Style2Talkerï¼Œå®ç°äº†æƒ…æ„Ÿé£æ ¼å’Œè‰ºæœ¯é£æ ¼ï¼Œæé«˜äº†è§†é¢‘è¡¨è¾¾æ•ˆæœã€‚</p>
<p><strong>Key Takeaways</strong></p>
<ul>
<li>Style2Talkerå¼•å…¥Style-Eå’ŒStyle-Aä¸¤ä¸ªé£æ ¼åŒ–é˜¶æ®µï¼Œåˆ†åˆ«æ•´åˆæƒ…æ„Ÿé£æ ¼å’Œè‰ºæœ¯é£æ ¼ã€‚</li>
<li>æå‡ºæ— äººå·¥å¹²é¢„çš„èŒƒå¼ï¼Œè‡ªåŠ¨ä¸ºç°æœ‰è§†éŸ³é¢‘æ•°æ®é›†æ ‡æ³¨æƒ…æ„Ÿæ–‡æœ¬æ ‡ç­¾ã€‚</li>
<li>åˆ©ç”¨CLIPæ¨¡å‹æå–æƒ…æ„Ÿç‰¹å¾ï¼Œç»“åˆéŸ³é¢‘ä½œä¸ºé«˜æ•ˆæ½œåœ¨æ‰©æ•£æ¨¡å‹çš„æ¡ä»¶ï¼Œç”Ÿæˆ3DMMæ¨¡å‹çš„æƒ…æ„Ÿè¿åŠ¨ç³»æ•°ã€‚</li>
<li>å¼€å‘ç³»æ•°é©±åŠ¨çš„è¿åŠ¨ç”Ÿæˆå™¨å’ŒåµŒå…¥åœ¨StyleGANä¸­çš„è‰ºæœ¯é£æ ¼è·¯å¾„ï¼Œåˆæˆé«˜åˆ†è¾¨ç‡è‰ºæœ¯é£æ ¼çš„å¤´éƒ¨è§†é¢‘ã€‚</li>
<li>å¼•å…¥å¤šå°ºåº¦å†…å®¹ç‰¹å¾å’Œå†…å®¹ç¼–ç å™¨ã€ç²¾ç‚¼ç½‘ç»œï¼Œæå‡å›¾åƒç»†èŠ‚å’Œå‡å°‘ä¼ªå½±ã€‚</li>
<li>Style2Talkeråœ¨éŸ³è§†é¢‘åŒæ­¥ã€æƒ…æ„Ÿå’Œè‰ºæœ¯é£æ ¼è¡¨ç°æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚</li>
</ul>
<p><strong><a href="https://huggingface.co/spaces/Kedreamix/ChatPaperFree">ChatPaperFree</a></strong></p>
<ol>
<li>æ ‡é¢˜ï¼šStyle2Talkerï¼šå…¼å…·æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼çš„é«˜åˆ†è¾¨ç‡è¯´è¯äººå¤´éƒ¨ç”Ÿæˆ</li>
<li>ä½œè€…ï¼šShuai Tan, Bin Ji, Ye Pan</li>
<li>å•ä½ï¼šä¸Šæµ·äº¤é€šå¤§å­¦</li>
<li>å…³é”®è¯ï¼šéŸ³é¢‘é©±åŠ¨ã€è¯´è¯äººå¤´éƒ¨ç”Ÿæˆã€æƒ…ç»ªé£æ ¼ã€è‰ºæœ¯é£æ ¼ã€æ–‡æœ¬æ§åˆ¶ã€å›¾åƒæ§åˆ¶</li>
<li>è®ºæ–‡é“¾æ¥ï¼šhttps://arxiv.org/abs/2403.06365</li>
<li>
<p>æ‘˜è¦ï¼š
ï¼ˆ1ï¼‰ç ”ç©¶èƒŒæ™¯ï¼šè‡ªåŠ¨ç”ŸæˆéŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨è§†é¢‘è¿‘å¹´æ¥å¤‡å—å…³æ³¨ï¼Œä½†ä»¥å¾€çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å®ç°éŸ³é¢‘å”‡å½¢åŒæ­¥ï¼Œå¿½è§†äº†ç”Ÿæˆå¯Œæœ‰è¡¨ç°åŠ›è§†é¢‘çš„ä¸¤ä¸ªå…³é”®å…ƒç´ ï¼šæƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼ã€‚
ï¼ˆ2ï¼‰è¿‡å»æ–¹æ³•ï¼šä»¥å¾€æ–¹æ³•è¦ä¹ˆä½¿ç”¨å•ä¸€çš„çƒ­æƒ…ç»ªæ ‡ç­¾ä½œä¸ºæƒ…ç»ªæºï¼Œé™åˆ¶äº†è¡¨æƒ…èŒƒå›´ï¼Œè¦ä¹ˆä¾èµ–é¢å¤–çš„è¡¨æƒ…è§†é¢‘ï¼Œè¿™å¯èƒ½ä¸æ–¹ä¾¿ã€‚æ­¤å¤–ï¼Œè™½ç„¶å•å¹…å›¾åƒé£æ ¼è¿ç§»å·²æœ‰å¤§é‡ç ”ç©¶ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨ç”Ÿæˆç”±éŸ³é¢‘é©±åŠ¨çš„è¿ç»­è§†é¢‘æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚
ï¼ˆ3ï¼‰ç ”ç©¶æ–¹æ³•ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººé¢éƒ¨ç”Ÿæˆæ–¹æ³• Style2Talkerã€‚å®ƒåŒ…æ‹¬ä¸¤ä¸ªé£æ ¼åŒ–é˜¶æ®µï¼šStyle-E å’Œ Style-Aï¼Œåˆ†åˆ«å°†æ–‡æœ¬æ§åˆ¶çš„æƒ…ç»ªé£æ ¼å’Œå›¾åƒæ§åˆ¶çš„è‰ºæœ¯é£æ ¼é›†æˆåˆ°æœ€ç»ˆè¾“å‡ºä¸­ã€‚
ï¼ˆ4ï¼‰æ–¹æ³•æ€§èƒ½ï¼šå®éªŒç»“æœè¡¨æ˜ï¼ŒStyle2Talker åœ¨éŸ³é¢‘å”‡å½¢åŒæ­¥ã€æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼çš„æ€§èƒ½æ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™äº›æ€§èƒ½æ”¯æŒäº†æœ¬æ–‡çš„ç›®æ ‡ï¼Œå³ç”Ÿæˆå…¼å…·æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼çš„é«˜åˆ†è¾¨ç‡è¯´è¯äººå¤´éƒ¨è§†é¢‘ã€‚</p>
</li>
<li>
<p>æ–¹æ³•ï¼š
ï¼ˆ1ï¼‰æ–‡æœ¬æ§åˆ¶çš„æƒ…ç»ªé£æ ¼è¿ç§»ï¼ˆStyle-Eï¼‰ï¼šå°†æ–‡æœ¬æ§åˆ¶çš„æƒ…ç»ªæ ‡ç­¾è½¬æ¢ä¸º 3DMM ç³»æ•°åºåˆ—ï¼Œå¹¶åˆ©ç”¨ StyleGAN ç”Ÿæˆå…·æœ‰ç›¸åº”æƒ…ç»ªé£æ ¼çš„å›¾åƒåºåˆ—ã€‚
ï¼ˆ2ï¼‰å›¾åƒæ§åˆ¶çš„è‰ºæœ¯é£æ ¼è¿ç§»ï¼ˆStyle-Aï¼‰ï¼šå¼•å…¥ ModResBlock è°ƒæ•´ StyleGAN çš„ç»“æ„é£æ ¼ï¼Œå¹¶åˆ©ç”¨è¿åŠ¨ç”Ÿæˆå™¨ Gm å°†é¢„æµ‹çš„è¿åŠ¨åºåˆ—è½¬æ¢ä¸ºç©ºé—´ç‰¹å¾å›¾ï¼Œä»è€Œå®ç°è‰ºæœ¯é£æ ¼çš„è¿ç§»ã€‚
ï¼ˆ3ï¼‰å†…å®¹ç¼–ç å™¨å’Œç»†åŒ–ç½‘ç»œï¼šé‡‡ç”¨å†…å®¹ç¼–ç å™¨ Ec æå–å¤šå°ºåº¦å†…å®¹ç‰¹å¾ï¼Œé€šè¿‡è·³è·ƒè¿æ¥è¡¥å……çº¹ç†ç»†èŠ‚ï¼›å¼•å…¥ç»†åŒ–ç½‘ç»œ R è°ƒæ•´ç©ºé—´ç‰¹å¾å›¾ï¼Œæ¶ˆé™¤é‡å½±ä¼ªå½±ã€‚</p>
</li>
<li>
<p>ç»“è®ºï¼š
ï¼ˆ1ï¼‰æœ¬å·¥ä½œçš„æ„ä¹‰ï¼šæå‡ºäº†ä¸€ç§åˆ›æ–°çš„éŸ³é¢‘é©±åŠ¨è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ–¹æ³• Style2Talkerï¼Œè¯¥æ–¹æ³•é€šè¿‡èåˆç›¸åº”çš„é£æ ¼æç¤ºï¼Œç”Ÿæˆå…¼å…·æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼çš„é«˜åˆ†è¾¨ç‡è¯´è¯äººå¤´éƒ¨è§†é¢‘ã€‚æˆ‘ä»¬åˆ©ç”¨åŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å…äººå·¥æ–‡æœ¬æ ‡æ³¨ç®¡é“ï¼Œä»æ–‡æœ¬è¾“å…¥ä¸­è·å–ç”¨äºå­¦ä¹ æƒ…ç»ªé£æ ¼çš„æ–‡æœ¬æè¿°ã€‚æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„å°è¯•èƒ½æ¿€å‘æ›´æ·±å…¥çš„ç ”ç©¶ï¼Œåˆ©ç”¨å‡ºè‰²çš„ã€å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ›´å®ç”¨ã€æ›´å¼•äººå…¥èƒœçš„æ¢ç´¢ã€‚ä¸ºäº†å°†æƒ…ç»ªé£æ ¼æ³¨å…¥åˆ° 3D è¿åŠ¨ç³»æ•°ä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªé«˜æ•ˆçš„æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…·æœ‰å¤šä¸ªç¼–ç å™¨ï¼Œç¡®ä¿ç”Ÿæˆé€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„é¢éƒ¨è¡¨æƒ…ã€‚æˆ‘ä»¬å°†ä¸€ä¸ªæƒ…ç»ªé©±åŠ¨æ¨¡å—å’Œä¸€ä¸ªé¢å¤–çš„è‰ºæœ¯é£æ ¼è·¯å¾„çº³å…¥ StyleGAN æ¶æ„ä¸­ï¼Œä»è€Œå®ç°ç³»æ•°é©±åŠ¨çš„è§†é¢‘ç”Ÿæˆï¼Œå¹¶å…·æœ‰æœŸæœ›çš„æƒ…ç»ªå’Œè‰ºæœ¯é£æ ¼ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºè§†è§‰è´¨é‡å¹¶æ¶ˆé™¤ä¼ªå½±ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å†…å®¹ç¼–ç å™¨å’Œç»†åŒ–ç½‘ç»œã€‚å®šæ€§å’Œå®šé‡å®éªŒè¡¨æ˜ï¼Œä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¯ä»¥ç”Ÿæˆæ›´å¤šé£æ ¼åŒ–çš„åŠ¨ç”»ç»“æœã€‚
ï¼ˆ2ï¼‰åˆ›æ–°ç‚¹ï¼š</p>
</li>
<li>æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬çš„å…äººå·¥æƒ…ç»ªæ ‡ç­¾è·å–ç®¡é“ï¼Œç”¨äºå­¦ä¹ æƒ…ç»ªé£æ ¼ã€‚</li>
<li>è®¾è®¡äº†ä¸€ä¸ªå¤šç¼–ç å™¨æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå°†æ–‡æœ¬æ§åˆ¶çš„æƒ…ç»ªæ ‡ç­¾è½¬æ¢ä¸º 3D è¿åŠ¨ç³»æ•°ï¼Œä»è€Œç”Ÿæˆé€¼çœŸä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„é¢éƒ¨è¡¨æƒ…ã€‚</li>
<li>åœ¨ StyleGAN æ¶æ„ä¸­èåˆäº†ä¸€ä¸ªæƒ…ç»ªé©±åŠ¨æ¨¡å—å’Œä¸€ä¸ªé¢å¤–çš„è‰ºæœ¯é£æ ¼è·¯å¾„ï¼Œå®ç°ç³»æ•°é©±åŠ¨çš„è§†é¢‘ç”Ÿæˆï¼Œå¹¶å…·æœ‰æœŸæœ›çš„æƒ…ç»ªå’Œè‰ºæœ¯é£æ ¼ã€‚</li>
<li>é‡‡ç”¨äº†ä¸€ä¸ªå†…å®¹ç¼–ç å™¨å’Œä¸€ä¸ªç»†åŒ–ç½‘ç»œï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºè§†è§‰è´¨é‡å¹¶æ¶ˆé™¤ä¼ªå½±ã€‚
æ€§èƒ½ï¼š</li>
<li>åœ¨éŸ³é¢‘å”‡å½¢åŒæ­¥ã€æƒ…ç»ªé£æ ¼å’Œè‰ºæœ¯é£æ ¼æ–¹é¢ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚
å·¥ä½œé‡ï¼š</li>
<li>æ–‡æœ¬æ ‡æ³¨å·¥ä½œé‡ä½ï¼Œå› ä¸ºåˆ©ç”¨äº†åŸºäºå¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹çš„å…äººå·¥æ–‡æœ¬æ ‡æ³¨ç®¡é“ã€‚</li>
<li>æ¨¡å‹è®­ç»ƒå’Œæ¨ç†æˆæœ¬è¾ƒé«˜ï¼Œå› ä¸ºä½¿ç”¨äº† StyleGAN å’Œæ‰©æ•£æ¨¡å‹ç­‰å¤æ‚æ¨¡å‹ã€‚</li>
</ol>


<details>
  <summary>ç‚¹æ­¤æŸ¥çœ‹è®ºæ–‡æˆªå›¾</summary>
<img src="https://pic1.zhimg.com/v2-d09922b44587a2c7a0d9914314bc2819.jpg" align="middle">
<img src="https://pica.zhimg.com/v2-7a916164c4c80e4c155763e1f38efcd1.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-0049142b2593b96773c9362d691fff94.jpg" align="middle">
<img src="https://picx.zhimg.com/v2-3380ba10087f173dca5f8c5d5df37735.jpg" align="middle">
</details>




]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>Talking Head Generation</tag>
      </tags>
  </entry>
</search>
